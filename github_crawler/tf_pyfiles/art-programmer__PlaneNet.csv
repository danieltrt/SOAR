file_path,api_count,code
RecordReaderAll.py,51,"b""import tensorflow as tf\nimport numpy as np\nimport threading\nimport PIL.Image as Image\nfrom functools import partial\nfrom multiprocessing import Pool\nimport cv2\n\nimport sys\nimport os\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom modules import *\n\n\nHEIGHT=192\nWIDTH=256\nNUM_PLANES = 20\nNUM_THREADS = 4\n\n\n\nclass RecordReaderAll():\n    def __init__(self):\n        return\n\n    def getBatch(self, filename_queue, numOutputPlanes = 20, batchSize = 16, min_after_dequeue = 1000, random=True, getLocal=False, getSegmentation=False, test=True):\n        reader = tf.TFRecordReader()\n        _, serialized_example = reader.read(filename_queue)\n\n        features = tf.parse_single_example(\n            serialized_example,\n            # Defaults are not specified since both keys are required.\n            features={\n                #'height': tf.FixedLenFeature([], tf.int64),\n                #'width': tf.FixedLenFeature([], tf.int64),\n                'image_raw': tf.FixedLenFeature([], tf.string),\n                'image_path': tf.FixedLenFeature([], tf.string),\n                'num_planes': tf.FixedLenFeature([], tf.int64),\n                'plane': tf.FixedLenFeature([NUM_PLANES * 3], tf.float32),\n                #'plane_relation': tf.FixedLenFeature([NUM_PLANES * NUM_PLANES], tf.float32),\n                'segmentation_raw': tf.FixedLenFeature([], tf.string),\n                'depth': tf.FixedLenFeature([HEIGHT * WIDTH], tf.float32),\n                'normal': tf.FixedLenFeature([HEIGHT * WIDTH * 3], tf.float32),\n                'semantics_raw': tf.FixedLenFeature([], tf.string),                \n                'boundary_raw': tf.FixedLenFeature([], tf.string),\n                'info': tf.FixedLenFeature([4 * 4 + 4], tf.float32),                \n            })\n\n        # Convert from a scalar string tensor (whose single string has\n        # length mnist.IMAGE_PIXELS) to a uint8 tensor with shape\n        # [mnist.IMAGE_PIXELS].\n        image = tf.decode_raw(features['image_raw'], tf.uint8)\n        image = tf.cast(image, tf.float32) * (1. / 255) - 0.5\n        image = tf.reshape(image, [HEIGHT, WIDTH, 3])\n\n        \n        depth = features['depth']\n        depth = tf.reshape(depth, [HEIGHT, WIDTH, 1])\n\n        normal = features['normal']\n        normal = tf.reshape(normal, [HEIGHT, WIDTH, 3])\n        \n        normal = tf.nn.l2_normalize(normal, dim=2)\n        \n        #normal = tf.stack([normal[:, :, 1], normal[:, :, 0], normal[:, :, 2]], axis=2)\n\n\n        semantics = tf.decode_raw(features['semantics_raw'], tf.uint8)\n        semantics = tf.cast(tf.reshape(semantics, [HEIGHT, WIDTH]), tf.int32)\n\n        numPlanes = tf.minimum(tf.cast(features['num_planes'], tf.int32), numOutputPlanes)\n\n        numPlanesOri = numPlanes\n        numPlanes = tf.maximum(numPlanes, 1)\n        \n        planes = features['plane']\n        planes = tf.reshape(planes, [NUM_PLANES, 3])\n        planes = tf.slice(planes, [0, 0], [numPlanes, 3])\n\n        #shuffle_inds = tf.one_hot(tf.random_shuffle(tf.range(numPlanes)), depth = numPlanes)\n        shuffle_inds = tf.one_hot(tf.range(numPlanes), numPlanes)\n        \n        planes = tf.transpose(tf.matmul(tf.transpose(planes), shuffle_inds))\n        planes = tf.reshape(planes, [numPlanes, 3])\n        planes = tf.concat([planes, tf.zeros([numOutputPlanes - numPlanes, 3])], axis=0)\n        planes = tf.reshape(planes, [numOutputPlanes, 3])\n\n        \n        boundary = tf.decode_raw(features['boundary_raw'], tf.uint8)\n        boundary = tf.cast(tf.reshape(boundary, (HEIGHT, WIDTH, 2)), tf.float32)\n\n        #boundary = tf.decode_raw(features['boundary_raw'], tf.float64)\n        #boundary = tf.cast(tf.reshape(boundary, (HEIGHT, WIDTH, 3)), tf.float32)        \n        #boundary = tf.slice(boundary, [0, 0, 0], [HEIGHT, WIDTH, 2])\n\n        segmentation = tf.decode_raw(features['segmentation_raw'], tf.uint8)\n        segmentation = tf.reshape(segmentation, [HEIGHT, WIDTH, 1])\n\n\n        \n        coef = tf.range(numPlanes)\n        coef = tf.reshape(tf.matmul(tf.reshape(coef, [-1, numPlanes]), tf.cast(shuffle_inds, tf.int32)), [1, 1, numPlanes])\n        \n        plane_masks = tf.cast(tf.equal(segmentation, tf.cast(coef, tf.uint8)), tf.float32)\n        plane_masks = tf.concat([plane_masks, tf.zeros([HEIGHT, WIDTH, numOutputPlanes - numPlanes])], axis=2)\n        plane_masks = tf.reshape(plane_masks, [HEIGHT, WIDTH, numOutputPlanes])\n\n        #non_plane_mask = tf.cast(tf.equal(segmentation, tf.cast(numOutputPlanes, tf.uint8)), tf.float32)\n        non_plane_mask = 1 - tf.reduce_max(plane_masks, axis=2, keep_dims=True)\n        #tf.cast(tf.equal(segmentation, tf.cast(numOutputPlanes, tf.uint8)), tf.float32)\n\n        \n        if random:\n            image_inp, plane_inp, depth_gt, normal_gt, semantics_gt, plane_masks_gt, boundary_gt, num_planes_gt, non_plane_mask_gt, image_path, info = tf.train.shuffle_batch([image, planes, depth, normal, semantics, plane_masks, boundary, numPlanesOri, non_plane_mask, features['image_path'], features['info']], batch_size=batchSize, capacity=min_after_dequeue + (NUM_THREADS + 2) * batchSize, num_threads=NUM_THREADS, min_after_dequeue=min_after_dequeue)\n        else:\n            image_inp, plane_inp, depth_gt, normal_gt, semantics_gt, plane_masks_gt, boundary_gt, num_planes_gt, non_plane_mask_gt, image_path, info = tf.train.batch([image, planes, depth, normal, semantics, plane_masks, boundary, numPlanesOri, non_plane_mask, features['image_path'], features['info']], batch_size=batchSize, capacity=(NUM_THREADS + 2) * batchSize, num_threads=1)\n            pass\n        global_gt_dict = {'plane': plane_inp, 'depth': depth_gt, 'normal': normal_gt, 'semantics': semantics_gt, 'segmentation': plane_masks_gt, 'boundary': boundary_gt, 'num_planes': num_planes_gt, 'non_plane_mask': non_plane_mask_gt, 'image_path': image_path, 'info': info}\n        return image_inp, global_gt_dict, {}\n"""
evaluate.py,69,"b'import tensorflow as tf\nimport numpy as np\nnp.set_printoptions(precision=2, linewidth=200)\nimport cv2\nimport os\nimport time\nimport sys\n#import tf_nndistance\nimport argparse\nimport glob\nimport PIL\nimport scipy.ndimage as ndimage\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom utils import *\n#from plane_utils import *\nfrom modules import *\n\nfrom train_planenet import build_graph\n#from train_sample import build_graph as build_graph_sample\nfrom planenet import PlaneNet\nfrom RecordReaderAll import *\n#from SegmentationRefinement import *\nfrom crfasrnn.crfasrnn_layer import CrfRnnLayer\n\n#ALL_TITLES = [\'planenet\', \'pixelwise\', \'pixelwise+RANSAC\', \'depth observation+RANSAC\', \'pixelwise+semantics+RANSAC\', \'gt\']\n#ALL_METHODS = [(\'bl2_ll1_bw0.5_pb_pp_sm0\', \'\'), (\'pb_pp\', \'pixelwise_1\'), (\'pb_pp\', \'pixelwise_2\'), (\'pb_pp\', \'pixelwise_3\'), (\'pb_pp\', \'semantics\'), (\'pb_pp\', \'gt\')]\n\nALL_TITLES = [\'PlaneNet\', \'Oracle NYU toolbox\', \'NYU toolbox\', \'Oracle Manhattan\', \'Manhattan\', \'Oracle Piecewise\', \'Piecewise\']\n#ALL_TITLES = [\'PlaneNet\', \'[25] + depth\', \'[25]\', \'[9] + depth\', \'[9]\', \'[26] + depth\', \'[26]\']\n#ALL_METHODS = [(\'bl0_dl0_bw0.5_pb_pp_ps_sm0\', \'\'), (\'ll1_pb_pp\', \'\'), (\'bl0_ll1_bw0.5_pb_pp_ps_sm0\', \'\'), (\'ll1_bw0.5_pb_pp_sm0\', \'\')]\n#ALL_METHODS = [(\'bl0_dl0_ll1_bw0.5_pb_pp_sm0\', \'\'), (\'bl0_dl0_ll1_pb_pp_sm0\', \'\'), (\'bl0_dl0_ll1_pb_pp_ps\', \'\'), (\'bl0_dl0_ll1_ds0_pb_pp\', \'\')]\n\n#ALL_METHODS = [(\'bl0_dl0_ll1_pb_pp_sm0\', \'\'), (\'bl0_dl0_ll1_pb_pp_sm0\', \'pixelwise_2\'), (\'bl0_dl0_ll1_pb_pp_sm0\', \'pixelwise_3\'), (\'bl0_dl0_ll1_pb_pp_sm0\', \'pixelwise_6\'), (\'bl0_dl0_ll1_pb_pp_sm0\', \'pixelwise_5\')]\n#ALL_METHODS = [(\'bl0_dl0_ll1_pb_pp_sm0\', \'\'), (\'bl0_dl0_crfrnn10_sm0\', \'\'), (\'bl0_dl0_ll1_pp_sm0\', \'\'), (\'bl0_dl0_ll1_pb_pp_sm0\', \'\'), (\'bl0_dl0_ll1_pb_pp_sm0\', \'\')]\n\n#ALL_METHODS = [(\'bl0_dl0_ll1_pb_pp_sm0\', \'\', 0), (\'bl0_dl0_ll1_pb_pp_sm0\', \'crfrnn\', 0), (\'bl0_dl0_crfrnn10_sm0\', \'\')]\n\n#ALL_METHODS = [[\'planenet_hybrid3_bl0_dl0_ll1_pb_pp_sm0\', \'\', 0, 0], [\'planenet_hybrid3_bl0_dl0_ll1_pb_pp_ps_sm0\', \'pixelwise_2\', 1, 0], [\'\', \'pixelwise_3\', 1, 0], [\'\', \'pixelwise_4\', 1, 0], [\'\', \'pixelwise_5\', 1, 0], [\'\', \'pixelwise_6\', 1, 0], [\'\', \'pixelwise_7\', 1, 0]]\n#ALL_METHODS = [[\'planenet_hybrid3_bl0_dl0_ll1_pb_pp_sm0\', \'\', 0, 0], [\'planenet_hybrid3_bl0_dl0_ll1_pb_pp_ps_sm0\', \'pixelwise_2\', 1, 0], [\'\', \'pixelwise_3\', 1, 0], [\'\', \'pixelwise_4\', 1, 0], [\'\', \'pixelwise_5\', 1, 0], [\'\', \'pixelwise_6\', 1, 0], [\'\', \'pixelwise_7\', 1, 0]]\nALL_METHODS = [[\'sample_np10_hybrid3_bl0_dl0_ds0_crfrnn5_sm0\', \'\', 0, 0], [\'planenet_hybrid3_bl0_dl0_ll1_pb_pp_ps_sm0\', \'pixelwise_2\', 1, 0], [\'\', \'pixelwise_3\', 1, 0], [\'\', \'pixelwise_4\', 1, 0], [\'\', \'pixelwise_5\', 1, 0], [\'\', \'pixelwise_6\', 1, 0], [\'\', \'pixelwise_7\', 1, 0]]\n\n#ALL_METHODS = [(\'ll1_pb_pp\', \'pixelwise_1\'), (\'crf1_pb_pp\', \'pixelwise_2\'), (\'bl0_ll1_bw0.5_pb_pp_ps_sm0\', \'pixelwise_3\'), (\'ll1_bw0.5_pb_pp_sm0\', \'pixelwise_4\')]\n\n\n#ALL_TITLES = [\'planenet\', \'pixelwise\']\n#ALL_METHODS = [(\'bl0_ll1_bw0.5_pb_pp_ps_sm0\', \'\'), (\'bl0_ll1_bw0.5_pb_pp_ps_sm0\', \'pixelwise_1\')]\n#ALL_TITLES = [\'crf\', \'different matching\']\n#ALL_METHODS = [(\'pb_pp_sm0\', \'crf\'), (\'pb_pp_sm0\', \'\')]\n\ndef writeHTML(options):\n    from html import HTML\n\n    titles = options.titles\n\n    h = HTML(\'html\')\n    h.p(\'Results\')\n    h.br()\n    path = \'.\'\n    #methods = [\'planenet\', \'pixelwise\', \'pixelwise+RANSAC\', \'GT+RANSAC\', \'planenet+crf\', \'pixelwise+semantics+RANSAC\']\n    #methods = [\'planenet\', \'pixelwise\', \'pixelwise+RANSAC\', \'GT+RANSAC\']\n\n    for index in xrange(options.numImages):\n\n        t = h.table(border=\'1\')\n        r_inp = t.tr()\n        r_inp.td(\'input \' + str(index))\n        r_inp.td().img(src=path + \'/\' + str(index) + \'_image.png\')\n        r_inp.td().img(src=path + \'/\' + str(index) + \'_depth_gt.png\')\n        r_inp.td().img(src=path + \'/\' + str(index) + \'_segmentation_gt.png\')\n        r_inp.td().img(src=path + \'/\' + str(index) + \'_semantics_gt.png\')                \n        r_inp.td().img(src=path + \'/\' + str(index) + \'_depth_gt_plane.png\')\n        r_inp.td().img(src=path + \'/\' + str(index) + \'_depth_gt_diff.png\')        \n        # r = t.tr()\n        # r.td(\'PlaneNet prediction\')\n        # r.td().img(src=firstFolder + \'/\' + str(index) + \'_segmentation_pred.png\')\n        # r.td().img(src=firstFolder + \'/\' + str(index) + \'_depth_pred.png\')\n\n        r = t.tr()\n        r.td(\'methods\')\n        for method_index, method in enumerate(titles):\n            r.td(method)\n            continue\n        \n        r = t.tr()\n        r.td(\'segmentation\')\n        for method_index, method in enumerate(titles):\n            r.td().img(src=path + \'/\' + str(index) + \'_segmentation_pred_\' + str(method_index) + \'.png\')\n            continue\n\n        r = t.tr()\n        r.td(\'depth\')\n        for method_index, method in enumerate(titles):\n            r.td().img(src=path + \'/\' + str(index) + \'_depth_pred_\' + str(method_index) + \'.png\')\n            continue\n        h.br()\n        continue\n\n    metric_titles = [\'depth error 0.1\', \'depth error 0.2\', \'depth error 0.3\', \'IOU 0.3\', \'IOU 0.5\', \'IOU 0.7\']\n\n    h.p(\'Curves on plane accuracy\')\n    for title in metric_titles:\n        h.img(src=\'curve_plane_\' + title.replace(\' \', \'_\') + \'.png\')\n        continue\n    \n    h.p(\'Curves on pixel coverage\')\n    for title in metric_titles:\n        h.img(src=\'curve_pixel_\' + title.replace(\' \', \'_\') + \'.png\')\n        continue\n    \n    \n    html_file = open(options.test_dir + \'/index.html\', \'w\')\n    html_file.write(str(h))\n    html_file.close()\n    return\n\ndef evaluatePlanes(options):\n    #writeHTML(options)\n    #exit(1)\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n    \n    results = getResults(options)\n    \n    gt_dict = results[\'gt\']\n    predictions = results[\'pred\']\n\n\n    saving = True\n    if gt_dict[\'image\'].shape[0] != options.numImages or options.useCache == 1:\n        saving = False\n        pass\n        \n    \n    for key, value in gt_dict.iteritems():\n        if options.imageIndex >= 0:\n            gt_dict[key] = value[options.imageIndex:options.imageIndex + 1]\n        elif value.shape[0] > options.numImages:\n            gt_dict[key] = value[:options.numImages]\n            pass\n        continue\n    for pred_dict in predictions:\n        for key, value in pred_dict.iteritems():\n            if options.imageIndex >= 0:\n                pred_dict[key] = value[options.imageIndex:options.imageIndex + 1]\n            elif value.shape[0] > options.numImages:\n                pred_dict[key] = value[:options.numImages]\n                pass\n            continue\n        continue\n\n    #methods = [\'planenet\', \'pixelwise+RANSAC\', \'GT+RANSAC\']\n\n\n            \n    #predictions[2] = predictions[3]\n\n\n\n    \n    for image_index in xrange(options.visualizeImages):\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_image.png\', gt_dict[\'image\'][image_index])\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_gt.png\', drawDepthImage(gt_dict[\'depth\'][image_index]))\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_normal_gt.png\', drawNormalImage(gt_dict[\'normal\'][image_index]))        \n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_gt.png\', drawSegmentationImage(np.concatenate([gt_dict[\'segmentation\'][image_index], 1 - np.expand_dims(gt_dict[\'plane_mask\'][image_index], -1)], axis=2), blackIndex=options.numOutputPlanes))\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_semantics_gt.png\', drawSegmentationImage(gt_dict[\'semantics\'][image_index], blackIndex=0))\n\n        \n        plane_depths = calcPlaneDepths(gt_dict[\'plane\'][image_index], WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n        all_depths = np.concatenate([plane_depths, np.expand_dims(gt_dict[\'depth\'][image_index], -1)], axis=2)\n        depth = np.sum(all_depths * np.concatenate([gt_dict[\'segmentation\'][image_index], 1 - np.expand_dims(gt_dict[\'plane_mask\'][image_index], -1)], axis=2), axis=2)\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_gt_plane.png\', drawDepthImage(depth))\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_gt_diff.png\', drawMaskImage((depth - gt_dict[\'depth\'][image_index]) * 5 + 0.5))        \n\n\n        for method_index, pred_dict in enumerate(predictions):\n            cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_dict[\'depth\'][image_index]))\n\n            #if \'pixelwise\' in options.methods[method_index][1]:\n            #continue\n            segmentation = pred_dict[\'segmentation\'][image_index]\n            #segmentation = np.concatenate([segmentation, pred_dict[\'np_mask\'][image_index]], axis=2)\n            numPlanes = options.numOutputPlanes\n            if \'pixelwise\' in options.methods[method_index][1]:\n                numPlanes = pred_dict[\'plane\'][image_index].shape[0]\n                #print(numPlanes)\n                pass\n            cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(segmentation, blackIndex=numPlanes))\n            continue\n        continue\n\n    \n    #post processing\n    for method_index, method in enumerate(options.methods):\n        if method[1] == \'\':\n            continue\n        if len(method) < 4 or method[3] == 0:\n            continue\n        if len(method) >= 3 and method[2] >= 0:\n            pred_dict = predictions[method[2]]\n        else:\n            pred_dict = predictions[method_index]\n            pass\n        \n        if method[1] == \'graphcut\':\n            #pred_dict = gt_dict\n            predSegmentations = []\n            predDepths = []\n            for image_index in xrange(options.numImages):\n                #if image_index != 3:\n                #continue\n                print(\'graph cut \' + str(image_index))\n\n                segmentation = np.argmax(np.concatenate([pred_dict[\'segmentation\'][image_index], 1 - np.expand_dims(pred_dict[\'plane_mask\'][image_index], -1)], axis=2), axis=2)\n                #pred_s = getSegmentationsGraphCut(pred_dict[\'plane\'][image_index], gt_dict[\'image\'][image_index], pred_dict[\'depth\'][image_index], pred_dict[\'normal\'][image_index], segmentation, pred_dict[\'semantics\'][image_index], pred_dict[\'info\'][image_index], gt_dict[\'num_planes\'][image_index])\n\n                pred_p, pred_s, numPlanes = removeSmallSegments(pred_dict[\'plane\'][image_index], gt_dict[\'image\'][image_index], pred_dict[\'depth\'][image_index], pred_dict[\'normal\'][image_index], segmentation, pred_dict[\'semantics\'][image_index], pred_dict[\'info\'][image_index], gt_dict[\'num_planes\'][image_index])\n                #pred_p, pred_s, numPlanes = pred_dict[\'plane\'][image_index], segmentation, gt_dict[\'num_planes\'][image_index]\n                print((gt_dict[\'num_planes\'][image_index], numPlanes))\n                planeDepths = calcPlaneDepths(pred_p, WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n                allDepths = np.concatenate([planeDepths, np.expand_dims(pred_dict[\'depth\'][image_index], -1)], axis=2)\n                pred_d = allDepths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), pred_s.reshape(-1)].reshape(HEIGHT, WIDTH)\n\n                predSegmentations.append(pred_s)\n                predDepths.append(pred_d)\n\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_d))                            \n                cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(pred_s, blackIndex=options.numOutputPlanes))\n                continue    \n            new_pred_dict = {}\n            for key, value in pred_dict.iteritems():\n                new_pred_dict[key] = value\n                continue\n            new_pred_dict[\'segmentation\'] = np.array(predSegmentations)\n            if method_index < len(predictions):\n                predictions[method_index] = new_pred_dict\n            else:\n                predictions.append(new_pred_dict)\n                pass\n        if method[1] == \'crf_tf\':\n            predSegmentations = []\n            predDepths = []\n\n            image_inp = tf.placeholder(tf.float32, shape=[1, HEIGHT, WIDTH, 3], name=\'image\')\n            segmentation_inp = tf.placeholder(tf.float32, shape=[1, HEIGHT, WIDTH, options.numOutputPlanes + 1], name=\'segmentation\')\n            plane_inp = tf.placeholder(tf.float32, shape=[1, options.numOutputPlanes, 3], name=\'plane\')\n            non_plane_depth_inp = tf.placeholder(tf.float32, shape=[1, HEIGHT, WIDTH, 1], name=\'non_plane_depth\')\n            info_inp = tf.placeholder(tf.float32, shape=[20], name=\'info\')\n\n            \n            plane_parameters = tf.reshape(plane_inp, (-1, 3))\n            plane_depths = planeDepthsModule(plane_parameters, WIDTH, HEIGHT, info_inp)\n            plane_depths = tf.transpose(tf.reshape(plane_depths, [HEIGHT, WIDTH, -1, options.numOutputPlanes]), [2, 0, 1, 3])\n            all_depths = tf.concat([plane_depths, non_plane_depth_inp], axis=3)\n\n            planesY = plane_inp[:, :, 1]\n            planesD = tf.maximum(tf.norm(plane_inp, axis=-1), 1e-4)\n            planesY /= planesD\n            planesY = tf.concat([planesY, tf.ones((1, 1))], axis=1)\n\n            #refined_segmentation = crfModule(segmentation_inp, plane_inp, non_plane_depth_inp, info_inp, numOutputPlanes = options.numOutputPlanes, numIterations=5)\n\n            imageDiff = calcImageDiff(image_inp)\n            #refined_segmentation, debug_dict = segmentationRefinementModule(segmentation_inp, all_depths, planesY, imageDiff, numOutputPlanes = options.numOutputPlanes + 1, numIterations=5)\n            refined_segmentation, debug_dict = meanfieldModule(segmentation_inp, all_depths, planesY, imageDiff, numOutputPlanes = options.numOutputPlanes + 1, maxDepthDiff=0.2, varDepthDiff=pow(0.2, 2))\n            \n            config=tf.ConfigProto()\n            config.gpu_options.allow_growth=True\n            config.allow_soft_placement=True\n\n            init_op = tf.group(tf.global_variables_initializer(),\n                               tf.local_variables_initializer())\n            with tf.Session(config=config) as sess:\n                sess.run(init_op)\n                for image_index in xrange(options.numImages):\n                    #if image_index != 1:\n                    #continue\n                    print(\'crf tf \' + str(image_index))\n                    allSegmentations = np.concatenate([pred_dict[\'segmentation\'][image_index], pred_dict[\'np_mask\'][image_index]], axis=2)\n                    allSegmentations = softmax(allSegmentations)\n                    pred_s, debug = sess.run([refined_segmentation, debug_dict], feed_dict={segmentation_inp: np.expand_dims(allSegmentations, 0), plane_inp: np.expand_dims(pred_dict[\'plane\'][image_index], 0), non_plane_depth_inp: np.expand_dims(pred_dict[\'np_depth\'][image_index], 0), info_inp: gt_dict[\'info\'][image_index], image_inp: gt_dict[\'image\'][image_index:image_index + 1]})\n\n                    pred_s = pred_s[0]\n                    planeDepths = calcPlaneDepths(pred_dict[\'plane\'][image_index], WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n                    allDepths = np.concatenate([planeDepths, pred_dict[\'np_depth\'][image_index]], axis=2)\n                    pred_d = np.sum(allDepths * pred_s, axis=-1)\n                    \n                    predSegmentations.append(pred_s)\n                    predDepths.append(pred_d)\n            \n                    cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_d))            \n                    cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(pred_s, blackIndex=options.numOutputPlanes))\n\n                    if \'diff\' in debug:\n                        segmentation = np.argmax(allSegmentations, axis=-1)\n                        for planeIndex in xrange(options.numOutputPlanes + 1):\n                            cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(allSegmentations[:, :, planeIndex]))\n                            continue\n                    \n                        for planeIndex in xrange(debug[\'diff\'].shape[-1]):\n                            cv2.imwrite(\'test/cost_mask_\' + str(planeIndex) + \'.png\', drawMaskImage(debug[\'diff\'][0, :, :, planeIndex] / 2))\n                            continue\n                        exit(1)                        \n                        pass\n                    continue\n                pass\n            new_pred_dict = {}\n            for key, value in pred_dict.iteritems():\n                new_pred_dict[key] = value\n                continue\n            segmentations = np.array(predSegmentations)\n            new_pred_dict[\'segmentation\'] = segmentations[:, :, :, :options.numOutputPlanes]\n            new_pred_dict[\'non_plane_mask\'] = segmentations[:, :, :, options.numOutputPlanes:options.numOutputPlanes + 1]\n            #new_pred_dict[\'non_plane_mask\'] = segmentations[:, :, :, :options.numOutputPlanes]\n            new_pred_dict[\'depth\'] = np.array(predDepths)\n            if method_index < len(predictions):\n                predictions[method_index] = new_pred_dict\n            else:\n                predictions.append(new_pred_dict)\n                pass\n            pass\n                  \n        if method[1] == \'crf\':\n            predSegmentations = []\n            predDepths = []\n            for image_index in xrange(options.numImages):\n                print(\'crf \' + str(image_index))\n                boundaries = pred_dict[\'boundary\'][image_index]\n                boundaries = sigmoid(boundaries)\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_boundary.png\', drawMaskImage(np.concatenate([boundaries, np.zeros((HEIGHT, WIDTH, 1))], axis=2)))\n                                      \n                allSegmentations = np.concatenate([pred_dict[\'segmentation\'][image_index], pred_dict[\'np_mask\'][image_index]], axis=2)\n                allSegmentations = softmax(allSegmentations)\n                planeDepths = calcPlaneDepths(pred_dict[\'plane\'][image_index], WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n                allDepths = np.concatenate([planeDepths, pred_dict[\'np_depth\'][image_index]], axis=2)\n                #boundaries = np.concatenate([np.ones((allSegmentations.shape[0], allSegmentations.shape[1], 1)), -np.ones((allSegmentations.shape[0], allSegmentations.shape[1], 1))], axis=2)\n                #if options.imageIndex >= 0:\n                #boundaries = cv2.imread(options.test_dir + \'/\' + str(options.imageIndex) + \'_boundary.png\')                \n                #else:\n                #boundaries = cv2.imread(options.test_dir + \'/\' + str(image_index) + \'_boundary.png\')\n                #pass\n                #boundaries = (boundaries > 128).astype(np.float32)[:, :, :2]\n\n                allDepths[:, :, options.numOutputPlanes] = 0\n                pred_s = refineSegmentation(gt_dict[\'image\'][image_index], allSegmentations, allDepths, boundaries, numOutputPlanes = 20, numIterations=20, numProposals=5)\n                pred_d = allDepths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), pred_s.reshape(-1)].reshape(HEIGHT, WIDTH)\n            \n                predSegmentations.append(pred_s)\n                predDepths.append(pred_d)\n            \n                cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_d))            \n                cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(pred_s, blackIndex=options.numOutputPlanes))\n\n                #segmentation = np.argmax(allSegmentations, axis=-1)\n                # for planeIndex in xrange(options.numOutputPlanes + 1):\n                #     cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(allSegmentations[:, :, planeIndex]))\n                #     continue\n                #cv2.imwrite(options.test_dir + \'/mask_\' + str(21) + \'.png\', drawDepthImage(pred_dict[\'np_depth\'][0]))\n                #for plane_index in xrange(options.numOutputPlanes + 1):\n                #cv2.imwrite(options.test_dir + \'/mask_\' + str(plane_index) + \'.png\', drawMaskImage(pred_s == plane_index))\n                #continue\n                #exit(1)\n                continue\n                \n            new_pred_dict = {}\n            for key, value in pred_dict.iteritems():\n                new_pred_dict[key] = value\n                continue\n            new_pred_dict[\'segmentation\'] = np.array(predSegmentations)\n            new_pred_dict[\'depth\'] = np.array(predDepths)\n            if method_index < len(predictions):\n                predictions[method_index] = new_pred_dict\n            else:\n                predictions.append(new_pred_dict)\n                pass\n            pass\n        \n\n        if \'pixelwise\' in method[1]:\n            predPlanes = []\n            predSegmentations = []\n            predDepths = []\n            predNumPlanes = []\n            for image_index in xrange(options.numImages):\n                pred_d = pred_dict[\'np_depth\'][image_index].squeeze()\n                pred_n = pred_dict[\'np_normal\'][image_index].squeeze()                \n                if \'_1\' in method[1]:\n                    pred_s = np.zeros(pred_dict[\'segmentation\'][image_index].shape)\n                    pred_p = np.zeros(pred_dict[\'plane\'][image_index].shape)\n                elif \'_2\' in method[1]:\n                    parameters = {\'distanceCostThreshold\': 0.1, \'smoothnessWeight\': 0.05, \'semantics\': True}\n                    pred_p, pred_s = fitPlanesNYU(gt_dict[\'image\'], gt_dict[\'depth\'][image_index].squeeze(), gt_dict[\'normal\'][image_index], gt_dict[\'semantics\'][image_index], gt_dict[\'info\'][image_index], numOutputPlanes=options.numOutputPlanes, parameters=parameters)\n                elif \'_3\' in method[1]:\n                    parameters = {\'distanceCostThreshold\': 0.1, \'smoothnessWeight\': 0.03, \'semantics\': True, \'distanceThreshold\': 0.05}\n                    pred_p, pred_s = fitPlanesNYU(gt_dict[\'image\'], pred_d, pred_n, pred_dict[\'semantics\'][image_index], gt_dict[\'info\'][image_index], numOutputPlanes=options.numOutputPlanes, parameters=parameters)\n                elif \'_4\' in method[1]:\n                    parameters = {\'numProposals\': 5, \'distanceCostThreshold\': 0.1, \'smoothnessWeight\': 30, \'dominantLineThreshold\': 3, \'offsetGap\': 0.1}\n                    pred_p, pred_s = fitPlanesManhattan(gt_dict[\'image\'][image_index], gt_dict[\'depth\'][image_index].squeeze(), gt_dict[\'normal\'][image_index], gt_dict[\'info\'][image_index], numOutputPlanes=options.numOutputPlanes, parameters=parameters)\n                    pred_d = np.zeros((HEIGHT, WIDTH))\n                elif \'_5\' in method[1]:\n                    parameters = {\'numProposals\': 5, \'distanceCostThreshold\': 0.1, \'smoothnessWeight\': 100, \'dominantLineThreshold\': 3, \'offsetGap\': 0.6}\n                    pred_p, pred_s = fitPlanesManhattan(gt_dict[\'image\'][image_index], pred_d, pred_n, gt_dict[\'info\'][image_index], numOutputPlanes=options.numOutputPlanes, parameters=parameters)\n                    pred_d = np.zeros((HEIGHT, WIDTH))\n                elif \'_6\' in method[1]:\n                    parameters = {\'distanceCostThreshold\': 0.1, \'smoothnessWeight\': 300, \'numProposals\': 5, \'normalWeight\': 1, \'meanshift\': 0.2}\n                    pred_p, pred_s = fitPlanesPiecewise(gt_dict[\'image\'][image_index], gt_dict[\'depth\'][image_index].squeeze(), gt_dict[\'normal\'][image_index], gt_dict[\'info\'][image_index], numOutputPlanes=options.numOutputPlanes, parameters=parameters)\n                    pred_d = np.zeros((HEIGHT, WIDTH))\n                elif \'_7\' in method[1]:\n                    parameters = {\'numProposals\': 5, \'distanceCostThreshold\': 0.1, \'smoothnessWeight\': 300, \'normalWeight\': 1, \'meanshift\': 0.2}\n                    pred_p, pred_s = fitPlanesPiecewise(gt_dict[\'image\'][image_index], pred_d, pred_n, gt_dict[\'info\'][image_index], numOutputPlanes=options.numOutputPlanes, parameters=parameters)\n                    pred_d = np.zeros((HEIGHT, WIDTH))\n                    pass\n                predPlanes.append(pred_p)                \n                predSegmentations.append(pred_s)\n                predDepths.append(pred_d)\n                predNumPlanes.append(pred_p.shape[0])                    \n\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_d))\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(pred_s, blackIndex=pred_p.shape[0]))\n                #exit(1)\n                continue\n            new_pred_dict = {}\n            for key, value in pred_dict.iteritems():\n                new_pred_dict[key] = value\n                continue\n            new_pred_dict[\'plane\'] = np.array(predPlanes)            \n            new_pred_dict[\'segmentation\'] = np.array(predSegmentations)\n            new_pred_dict[\'depth\'] = np.array(predDepths)\n            new_pred_dict[\'num_planes\'] = np.array(predNumPlanes)\n            if method_index < len(predictions):\n                predictions[method_index] = new_pred_dict\n            else:\n                predictions.append(new_pred_dict)\n                pass\n            #titles.append(\'pixelwise+semantics+RANSAC\')\n            pass\n\n        if method[1] == \'crfrnn\':\n            predSegmentations = []\n            predDepths = []\n\n            image_inp = tf.placeholder(tf.float32, shape=[1, HEIGHT, WIDTH, 3], name=\'image\')\n            segmentation_inp = tf.placeholder(tf.float32, shape=[1, HEIGHT, WIDTH, options.numOutputPlanes + 1], name=\'segmentation\')\n            \n            refined_segmentation = CrfRnnLayer(image_dims=(HEIGHT, WIDTH), num_classes=21, theta_alpha=120., theta_beta=3., theta_gamma=3., num_iterations=10, name=\'crfrnn\')([segmentation_inp, image_inp])\n            \n            config=tf.ConfigProto()\n            config.gpu_options.allow_growth=True\n            config.allow_soft_placement=True\n\n            init_op = tf.group(tf.global_variables_initializer(),\n                               tf.local_variables_initializer())\n            with tf.Session(config=config) as sess:\n                sess.run(init_op)\n                for image_index in xrange(options.numImages):\n                    #if image_index != 1:\n                    #continue\n                    print(\'crf rnn \' + str(image_index))\n                    allSegmentations = np.concatenate([pred_dict[\'segmentation\'][image_index], pred_dict[\'np_mask\'][image_index]], axis=2)\n                    img = gt_dict[\'image\'][image_index:image_index + 1].astype(np.float32) - 128\n\n                    \n                    pred_s = sess.run(refined_segmentation, feed_dict={segmentation_inp: np.expand_dims(allSegmentations, 0), image_inp: img})\n\n                    # print(pred_s.shape)\n                    # print(pred_s[0].max())\n                    # print(pred_s.sum(-1).max())                    \n                    # exit(1)\n                    pred_s = pred_s[0]\n                    # print(allSegmentations.max())\n                    # print(pred_s.max())\n                    # print(img.max())\n                    # print(img.min())                    \n                    # print(np.abs(pred_s - allSegmentations).max())\n                    # print(np.abs(np.argmax(pred_s, axis=-1) - np.argmax(allSegmentations, axis=-1)).max())\n                    pred_s = one_hot(np.argmax(pred_s, axis=-1), options.numOutputPlanes + 1)\n\n                    \n                    planeDepths = calcPlaneDepths(pred_dict[\'plane\'][image_index], WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n                    allDepths = np.concatenate([planeDepths, pred_dict[\'np_depth\'][image_index]], axis=2)\n                    pred_d = np.sum(allDepths * pred_s, axis=-1)\n                    \n                    predSegmentations.append(pred_s)\n                    predDepths.append(pred_d)\n            \n                    cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_d))            \n                    cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(pred_s, blackIndex=options.numOutputPlanes))\n\n                    continue\n                pass\n            new_pred_dict = {}\n            for key, value in pred_dict.iteritems():\n                new_pred_dict[key] = value\n                continue\n            segmentations = np.array(predSegmentations)\n            new_pred_dict[\'segmentation\'] = segmentations[:, :, :, :options.numOutputPlanes]\n            new_pred_dict[\'non_plane_mask\'] = segmentations[:, :, :, options.numOutputPlanes:options.numOutputPlanes + 1]\n            #new_pred_dict[\'non_plane_mask\'] = segmentations[:, :, :, :options.numOutputPlanes]\n            new_pred_dict[\'depth\'] = np.array(predDepths)\n            if method_index < len(predictions):\n                predictions[method_index] = new_pred_dict\n            else:\n                predictions.append(new_pred_dict)\n                pass\n            pass\n        if saving:\n            np.save(options.result_filename, {\'gt\': gt_dict, \'pred\': predictions})\n            pass\n        continue\n    \n    #exit(1)\n    \n    #print(results)\n\n    # depth = gt_dict[\'depth\'][4]\n    # cv2.imwrite(options.test_dir + \'/test_depth_gt.png\', drawDepthImage(depth))\n    # pred_p, pred_s, pred_d = fitPlanes(depth, getSUNCGCamera(), numPlanes=20, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=0.2)\n    # cv2.imwrite(options.test_dir + \'/test_depth.png\', drawDepthImage(pred_d))\n    # cv2.imwrite(options.test_dir + \'/test_segmentation.png\', drawSegmentationImage(pred_s))\n    # exit(1)\n    \n    \n    #plotResults(gt_dict, predictions, options)\n    if options.numImages > gt_dict[\'image\'].shape[0]:\n        plotAll(options)\n    else:\n        plotResults(gt_dict, predictions, options)\n        pass\n    writeHTML(options)\n    return\n\ndef plotAll(options):\n    result_filenames = glob.glob(options.test_dir + \'/results_*.npy\')\n    assert(len(result_filenames) > 0)\n    results = np.load(result_filenames[0])\n    results = results[()]\n    gt_dict = results[\'gt\']\n    predictions = results[\'pred\']\n\n    for index in xrange(1, len(result_filenames)):\n        other_results = np.load(result_filenames[index])\n        other_results = other_results[()]\n        other_gt_dict = other_results[\'gt\']\n        other_predictions = other_results[\'pred\']\n        for k, v in other_gt_dict.iteritems():\n            gt_dict[k] = np.concatenate([gt_dict[k], v], axis=0)\n            continue\n        for methodIndex, other_pred_dict in enumerate(other_predictions):\n            if methodIndex == 1:\n                continue\n            for k, v in other_pred_dict.iteritems():\n                print(methodIndex, k)\n                print(predictions[methodIndex][k].shape)\n                print(v.shape)\n                predictions[methodIndex][k] = np.concatenate([predictions[methodIndex][k], v], axis=0)\n                continue\n            continue\n        continue\n    \n    plotResults(gt_dict, predictions, options)\n    return\n\n\ndef plotResults(gt_dict, predictions, options):\n    titles = options.titles    \n\n    pixel_metric_curves = []\n    plane_metric_curves = []\n    for method_index, pred_dict in enumerate(predictions):\n        if titles[method_index] == \'pixelwise\':\n            continue\n        segmentations = pred_dict[\'segmentation\']\n        #if method_index == 0:\n        #segmentations = softmax(segmentations)\n        #pass\n        #pixel_curves, plane_curves = evaluatePlaneSegmentation(pred_dict[\'plane\'], segmentations, gt_dict[\'plane\'], gt_dict[\'segmentation\'], gt_dict[\'num_planes\'], numOutputPlanes = options.numOutputPlanes)\n\n        pixel_curves = np.zeros((6, 13))\n        plane_curves = np.zeros((6, 13, 3))\n        numImages = segmentations.shape[0]\n        for image_index in xrange(numImages):\n            gtDepths = calcPlaneDepths(gt_dict[\'plane\'][image_index], WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n            predDepths = calcPlaneDepths(pred_dict[\'plane\'][image_index], WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n            if \'num_planes\' in pred_dict:\n                predNumPlanes = pred_dict[\'num_planes\'][image_index]\n            else:\n                predNumPlanes = options.numOutputPlanes\n                pass\n\n            #if image_index != 2:\n            #continue\n            \n            pixelStatistics, planeStatistics = evaluatePlanePrediction(predDepths, segmentations[image_index], predNumPlanes, gtDepths, gt_dict[\'segmentation\'][image_index], gt_dict[\'num_planes\'][image_index])\n\n            # for planeIndex in xrange(options.numOutputPlanes):\n            #     cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(gt_dict[\'segmentation\'][image_index][:, :, planeIndex]))\n            #     continue\n            \n            # mask_1 = segmentations[image_index] == 8\n            # mask_2 = gt_dict[\'segmentation\'][image_index][:, :, 3]\n            # print(mask_1.sum())\n            # print(mask_2.sum())\n            # cv2.imwrite(\'test/mask_pred.png\', drawMaskImage(mask_1))\n            # cv2.imwrite(\'test/mask_gt.png\', drawMaskImage(mask_2))\n            # cv2.imwrite(\'test/mask_intersection.png\', drawMaskImage(mask_2 * mask_1 > 0.5))\n            # cv2.imwrite(\'test/mask_union.png\', drawMaskImage((mask_2 + mask_1) > 0.5))\n            # print((mask_2 * mask_1 > 0.5).sum())\n            # print(((mask_2 + mask_1) > 0.5).sum())\n            #print(image_index, planeStatistics[4][5])\n            #exit(1)\n            # print(pred_dict[\'plane\'][image_index])\n            # for planeIndex in xrange(options.numOutputPlanes):\n            #     print((segmentations[image_index] == planeIndex).sum())\n            #     continue\n            #exit(1)\n            pixel_curves += np.array(pixelStatistics)\n            plane_curves += np.array(planeStatistics)\n            continue\n\n\n        if len(pixel_metric_curves) == 0:\n            for metric_index, pixel_curve in enumerate(pixel_curves):\n                pixel_metric_curves.append([])\n                plane_metric_curves.append([])\n                continue\n            pass\n        \n        for metric_index, pixel_curve in enumerate(pixel_curves):\n            pixel_metric_curves[metric_index].append(pixel_curve / numImages)\n            continue\n        for metric_index, plane_curve in enumerate(plane_curves):\n            #planeScore = plane_curve[:, 0] / plane_curve[:, 1]\n            plane_metric_curves[metric_index].append(plane_curve)\n            continue\n        continue\n\n    \n    #np.save(options.test_dir + \'/pixel_curves.npy\', np.array(pixel_metric_curves))\n    #np.save(options.test_dir + \'/plane_curves.npy\', np.array(plane_metric_curves))    \n\n    \n    xs = []\n    xs.append((np.arange(13) * 0.1).tolist())\n    xs.append((np.arange(13) * 0.1).tolist())\n    xs.append((np.arange(13) * 0.1).tolist())    \n    xs.append((np.arange(13) * 0.05).tolist())\n    xs.append((np.arange(13) * 0.05).tolist())\n    xs.append((np.arange(13) * 0.05).tolist())\n    xlabels = [\'IOU threshold\', \'IOU threshold\', \'IOU threshold\', \'depth threshold\', \'depth threshold\', \'depth threshold\']\n    curve_titles = [\'depth threshold 0.1\', \'depth threshold 0.2\', \'depth threshold 0.3\', \'IOU 0.3\', \'IOU 0.5\', \'IOU 0.7\']\n    curve_labels = [title for title in titles if title != \'pixelwise\']\n\n\n    # metric_index = 4\n    # filename = options.test_dir + \'/curves\'\n    # pixel_curves = pixel_metric_curves[metric_index]\n    # plane_curves = plane_metric_curves[metric_index]\n    # plane_curves = [plane_curve[:, 0] / plane_curve[:, 1] for plane_curve in plane_curves]\n    # plotCurvesSubplot(xs[metric_index], [plane_curves, pixel_curves], filenames = [filename + \'.png\', filename + \'_oracle.png\'], xlabel=xlabels[metric_index], ylabels=[\'Per-plane recall\', \'Per-pixel recall\'], labels=curve_labels)\n    # return\n    \n    for metric_index, curves in enumerate(pixel_metric_curves):\n        if metric_index not in [4]:\n            continue\n        #filename = options.test_dir + \'/curve_pixel_\' + curve_titles[metric_index].replace(\' \', \'_\') + \'.png\'\n        #plotCurves(xs[metric_index], curves, filename = filename, xlabel=xlabels[metric_index], ylabel=\'pixel coverage\', title=curve_titles[metric_index], labels=curve_labels)\n\n        filename = options.test_dir + \'/curve_pixel_\' + curve_titles[metric_index].replace(\' \', \'_\').replace(\'.\', \'\')\n        plotCurvesSplit(xs[metric_index], curves, filenames = [filename + \'.png\', filename + \'_oracle.png\'], xlabel=xlabels[metric_index], ylabel=\'Per-pixel recall\', title=curve_titles[metric_index], labels=curve_labels)\n\n        #plotCurvesSubplot(xs[metric_index], curves, filename = filename + \'.png\', xlabel=xlabels[metric_index], ylabel=\'Per-pixel recall\', title=curve_titles[metric_index], labels=curve_labels)\n        \n        continue\n    for metric_index, curves in enumerate(plane_metric_curves):\n        if metric_index not in [4]:\n            continue\n        \n        curves = [curve[:, 0] / curve[:, 1] for curve in curves]\n\n        #filename = options.test_dir + \'/curve_plane_\' + curve_titles[metric_index].replace(\' \', \'_\') + \'.png\'        \n        #plotCurves(xs[metric_index], curves, filename = filename, xlabel=xlabels[metric_index], ylabel=\'Per-plane recall\', title=curve_titles[metric_index], labels=curve_labels)\n\n        filename = options.test_dir + \'/curve_plane_\' + curve_titles[metric_index].replace(\' \', \'_\').replace(\'.\', \'\')\n        plotCurvesSplit(xs[metric_index], curves, filenames = [filename + \'.png\', filename + \'_oracle.png\'], xlabel=xlabels[metric_index], ylabel=\'Per-plane recall\', title=curve_titles[metric_index], labels=curve_labels)\n        continue\n\n    \ndef gridSearch(options):\n    #writeHTML(options)\n    #exit(1)\n\n    if os.path.exists(options.result_filename):\n        results = np.load(options.result_filename)\n        results = results[()]\n    else:\n        assert(False)\n        pass\n    \n    gt_dict = results[\'gt\']\n    predictions = results[\'pred\']\n\n    for key, value in gt_dict.iteritems():\n        if options.imageIndex >= 0:\n            gt_dict[key] = value[options.imageIndex:options.imageIndex + 1]\n        elif value.shape[0] > options.numImages:\n            gt_dict[key] = value[:options.numImages]\n            pass\n        continue\n    for pred_dict in predictions:\n        for key, value in pred_dict.iteritems():\n            if options.imageIndex >= 0:\n                pred_dict[key] = value[options.imageIndex:options.imageIndex + 1]\n            elif value.shape[0] > options.numImages:\n                pred_dict[key] = value[:options.numImages]\n                pass\n            continue\n        continue\n\n    #methods = [\'planenet\', \'pixelwise+RANSAC\', \'GT+RANSAC\']\n    titles = options.titles\n\n\n    \n    for image_index in xrange(options.visualizeImages):\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_image.png\', gt_dict[\'image\'][image_index])\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_gt.png\', drawDepthImage(gt_dict[\'depth\'][image_index]))\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_normal_gt.png\', drawNormalImage(gt_dict[\'normal\'][image_index]))        \n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_gt.png\', drawSegmentationImage(np.concatenate([gt_dict[\'segmentation\'][image_index], 1 - np.expand_dims(gt_dict[\'plane_mask\'][image_index], -1)], axis=2), blackIndex=options.numOutputPlanes))\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_semantics_gt.png\', drawSegmentationImage(gt_dict[\'semantics\'][image_index], blackIndex=0))\n        \n        plane_depths = calcPlaneDepths(gt_dict[\'plane\'][image_index], WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n        all_depths = np.concatenate([plane_depths, np.expand_dims(gt_dict[\'depth\'][image_index], -1)], axis=2)\n        depth = np.sum(all_depths * np.concatenate([gt_dict[\'segmentation\'][image_index], 1 - np.expand_dims(gt_dict[\'plane_mask\'][image_index], -1)], axis=2), axis=2)\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_gt_plane.png\', drawDepthImage(depth))\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_gt_diff.png\', drawMaskImage((depth - gt_dict[\'depth\'][image_index]) * 5 + 0.5))        \n        \n        for method_index, pred_dict in enumerate(predictions):\n            cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_dict[\'depth\'][image_index]))\n\n            if \'pixelwise\' in options.methods[method_index][1]:\n                continue\n            segmentation = pred_dict[\'segmentation\'][image_index]\n            segmentation = np.concatenate([segmentation, pred_dict[\'np_mask\'][image_index]], axis=2)\n            cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(segmentation, blackIndex=options.numOutputPlanes))\n            continue\n        continue\n\n\n    #post processing\n    for method_index, method in enumerate(options.methods):\n        if len(method) == 3:\n            pred_dict = predictions[method[2]]\n        else:\n            pred_dict = predictions[method_index]\n            pass\n\n        if \'pixelwise_2\' in method[1] or \'pixelwise_3\' in method[1]:\n            bestScore = 0\n            configurationIndex = 0\n            for distanceCostThreshold in [0.3]:\n                for smoothnessWeight in [0.01, 0.03, 0.05]:\n                    for distanceThreshold in [0.2]:\n                        parameters = {\'distanceCostThreshold\': distanceCostThreshold, \'smoothnessWeight\': smoothnessWeight, \'distanceThreshold\': distanceThreshold, \'semantics\': True}\n                        score = 0\n                        for image_index in xrange(options.numImages):\n                            #cv2.imwrite(\'test/normal.png\', drawNormalImage(gt_dict[\'normal\'][image_index]))\n                            if \'_2\' in method[1]:\n                                pred_p, pred_s = fitPlanesNYU(gt_dict[\'image\'][image_index], gt_dict[\'depth\'][image_index].squeeze(), gt_dict[\'normal\'][image_index], gt_dict[\'semantics\'][image_index], gt_dict[\'info\'][image_index], numOutputPlanes=options.numOutputPlanes, parameters=parameters)\n                            else:\n                                pred_d = pred_dict[\'np_depth\'][image_index].squeeze()\n                                pred_n = pred_dict[\'np_normal\'][image_index].squeeze()\n                                pred_p, pred_s = fitPlanesNYU(gt_dict[\'image\'][image_index], pred_d, pred_n, pred_dict[\'semantics\'][image_index], gt_dict[\'info\'][image_index], numOutputPlanes=options.numOutputPlanes, parameters=parameters)\n                                pass\n\n                            predNumPlanes = pred_p.shape[0]\n                            gtDepths = calcPlaneDepths(gt_dict[\'plane\'][image_index], WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n                            planeDepths = calcPlaneDepths(pred_p, WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n                            pixelStatistics, planeStatistics = evaluatePlanePrediction(planeDepths, pred_s, predNumPlanes, gtDepths, gt_dict[\'segmentation\'][image_index], gt_dict[\'num_planes\'][image_index])\n                            #print(pixelStatistics)\n                            #exit(1)\n                            #planeStatistics = np.array(planeStatistics)[1]\n                            #accuracy = (planeStatistics[3:8, 0].astype(np.float32) / np.maximum(planeStatistics[3:8, 1], 1e-4)).mean()\n\n                            pixelStatistics = np.array(pixelStatistics)[1]\n                            accuracy = pixelStatistics[3:8].mean()\n                            score += accuracy\n\n                            #cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_d))            \n                            cv2.imwrite(\'test/segmentation_pred_\' + str(image_index) + \'.png\', drawSegmentationImage(pred_s, blackIndex=options.numOutputPlanes))\n                            #exit(1)\n                            continue\n                        score /= options.numImages\n                        print(score, parameters)\n                        configurationIndex += 1                    \n                        #exit(1)\n                        if score > bestScore:\n                            bestScore = score\n                            bestParameters = parameters\n                            pass\n                        continue\n                    continue\n                continue\n            print(bestScore)\n            print(bestParameters)\n            exit(1)\n                    \n        if \'pixelwise_4\' in method[1] or \'pixelwise_5\' in method[1]:\n            bestScore = 0\n            configurationIndex = 0\n            for distanceCostThreshold in [0.05]:\n                for smoothnessWeight in [30]:\n                    for offsetGap in [-0.1]:\n                        parameters = {\'distanceCostThreshold\': distanceCostThreshold, \'smoothnessWeight\': smoothnessWeight, \'offsetGap\': abs(offsetGap), \'meanshift\': offsetGap}\n\n                        score = 0\n                        for image_index in xrange(options.numImages):\n                            if \'_4\' in method[1]:\n                                pred_p, pred_s = fitPlanesManhattan(gt_dict[\'image\'][image_index], gt_dict[\'depth\'][image_index].squeeze(), gt_dict[\'normal\'][image_index], gt_dict[\'info\'][image_index], numOutputPlanes=options.numOutputPlanes, parameters=parameters)\n                            else:\n                                pred_d = pred_dict[\'np_depth\'][image_index].squeeze()\n                                pred_n = pred_dict[\'np_normal\'][image_index].squeeze()\n                                pred_p, pred_s = fitPlanesManhattan(gt_dict[\'image\'][image_index], pred_d, pred_n, gt_dict[\'info\'][image_index], numOutputPlanes=options.numOutputPlanes, parameters=parameters)\n                                pass\n\n                            predNumPlanes = pred_p.shape[0]\n                            gtDepths = calcPlaneDepths(gt_dict[\'plane\'][image_index], WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n                            planeDepths = calcPlaneDepths(pred_p, WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n                            pixelStatistics, planeStatistics = evaluatePlanePrediction(planeDepths, pred_s, predNumPlanes, gtDepths, gt_dict[\'segmentation\'][image_index], gt_dict[\'num_planes\'][image_index])\n                            #print(pixelStatistics)\n                            #exit(1)\n                            #planeStatistics = np.array(planeStatistics)[1]\n                            #accuracy = (planeStatistics[3:8, 0].astype(np.float32) / np.maximum(planeStatistics[3:8, 1], 1e-4)).mean()\n\n                            pixelStatistics = np.array(pixelStatistics)[1]\n                            accuracy = pixelStatistics[3:8].mean()\n                            score += accuracy\n\n                            #cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_d))            \n                            #cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(pred_s, blackIndex=options.numOutputPlanes))\n                            #exit(1)\n                            continue\n                        score /= options.numImages\n                        print(score, parameters)\n                        configurationIndex += 1                    \n                        #exit(1)\n                        if score > bestScore:\n                            bestScore = score\n                            bestParameters = parameters\n                            pass\n                        continue\n                    continue\n                continue\n            print(bestScore)\n            print(bestParameters)\n            exit(1)\n\n        if \'pixelwise_6\' in method[1] or \'pixelwise_7\' in method[1]:\n            bestScore = 0\n            configurationIndex = 0            \n            for distanceCostThreshold in [0.1]:\n                for smoothnessWeight in [300]:\n                    for normalWeight in [1]:\n                        for offset in [0.2]:\n                            parameters = {\'distanceCostThreshold\': distanceCostThreshold, \'smoothnessWeight\': smoothnessWeight, \'numProposals\': 5, \'normalWeight\': normalWeight, \'offsetGap\': abs(offset), \'meanshift\': offset}\n\n                            score = 0\n                            for image_index in xrange(options.numImages):\n                                if \'_6\' in method[1]:\n                                    pred_p, pred_s = fitPlanesPiecewise(gt_dict[\'image\'][image_index], gt_dict[\'depth\'][image_index].squeeze(), gt_dict[\'normal\'][image_index], gt_dict[\'info\'][image_index], numOutputPlanes=options.numOutputPlanes, parameters=parameters)\n                                else:\n                                    pred_d = pred_dict[\'np_depth\'][image_index].squeeze()                \n                                    pred_n = pred_dict[\'np_normal\'][image_index].squeeze()                \n                                    pred_p, pred_s = fitPlanesPiecewise(gt_dict[\'image\'][image_index], pred_d, pred_n, gt_dict[\'info\'][image_index], numOutputPlanes=options.numOutputPlanes, parameters=parameters)\n                                    pass\n\n                                predNumPlanes = pred_p.shape[0]\n                                gtDepths = calcPlaneDepths(gt_dict[\'plane\'][image_index], WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n                                planeDepths = calcPlaneDepths(pred_p, WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n                                pixelStatistics, planeStatistics = evaluatePlanePrediction(planeDepths, pred_s, predNumPlanes, gtDepths, gt_dict[\'segmentation\'][image_index], gt_dict[\'num_planes\'][image_index])\n                                #print(pixelStatistics)\n                                #exit(1)\n                                #planeStatistics = np.array(planeStatistics)[1]\n                                #accuracy = (planeStatistics[3:8, 0].astype(np.float32) / np.maximum(planeStatistics[3:8, 1], 1e-4)).mean()\n\n                                pixelStatistics = np.array(pixelStatistics)[1]\n                                accuracy = pixelStatistics[3:8].mean()\n                                score += accuracy\n\n                                #cv2.imwrite(\'test/depth_pred_\' + str(configurationIndex) + \'.png\', drawDepthImage(pred_d))\n                                cv2.imwrite(\'test/segmentation_pred_\' + str(image_index) + \'.png\', drawSegmentationImage(pred_s, blackIndex=options.numOutputPlanes))\n                                #exit(1)\n                                continue\n                            score /= options.numImages\n                            print(score, parameters)\n                            configurationIndex += 1\n\n                            #exit(1)\n                            if score > bestScore:\n                                bestScore = score\n                                bestParameters = parameters\n                                pass\n                            continue\n                        continue\n                    continue\n                continue\n            print(bestScore)\n            print(bestParameters)\n            exit(1)            \n\n        if method[1] == \'crfrnn\':\n\n            parameterConfigurations = []\n            for alpha in [15]:\n                for beta in [10]:\n                    for gamma in [3]:\n                        parameterConfigurations.append((alpha, beta, gamma))\n                        continue\n                    continue\n                continue\n            print(parameterConfigurations)\n\n            bestScore = 0\n            for parameters in parameterConfigurations:\n                tf.reset_default_graph()\n                image_inp = tf.placeholder(tf.float32, shape=[1, HEIGHT, WIDTH, 3], name=\'image\')\n                segmentation_inp = tf.placeholder(tf.float32, shape=[1, HEIGHT, WIDTH, options.numOutputPlanes + 1], name=\'segmentation\')\n            \n                refined_segmentation = CrfRnnLayer(image_dims=(HEIGHT, WIDTH), num_classes=21, theta_alpha=parameters[0], theta_beta=parameters[1], theta_gamma=parameters[2], num_iterations=10, name=\'crfrnn\')([segmentation_inp, image_inp])\n            \n                config=tf.ConfigProto()\n                config.gpu_options.allow_growth=True\n                config.allow_soft_placement=True\n\n                init_op = tf.group(tf.global_variables_initializer(),\n                                   tf.local_variables_initializer())\n                with tf.Session(config=config) as sess:\n                    sess.run(init_op)\n\n                    score = 0.\n                    for image_index in xrange(options.numImages):\n                        #if image_index != 1:\n                        #continue\n                        print(\'crf as rnn\', image_index)\n                        allSegmentations = np.concatenate([pred_dict[\'segmentation\'][image_index], pred_dict[\'np_mask\'][image_index]], axis=2)\n                        img = gt_dict[\'image\'][image_index:image_index + 1].astype(np.float32) - 128\n\n                        pred_s = sess.run(refined_segmentation, feed_dict={segmentation_inp: np.expand_dims(allSegmentations, 0), image_inp: img})\n                        pred_s = pred_s[0]\n\n                        #pred_s = allSegmentations\n                        \n                        pred_s = one_hot(np.argmax(pred_s, axis=-1), options.numOutputPlanes + 1)\n\n\n                        planeDepths = calcPlaneDepths(pred_dict[\'plane\'][image_index], WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n                        allDepths = np.concatenate([planeDepths, pred_dict[\'np_depth\'][image_index]], axis=2)\n                        pred_d = np.sum(allDepths * pred_s, axis=-1)\n\n\n                        # for planeIndex in xrange(options.numOutputPlanes):\n                        #     cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(pred_s[:, :, planeIndex]))\n                        #     cv2.imwrite(\'test/gt_mask_\' + str(planeIndex) + \'.png\', drawMaskImage(gt_dict[\'segmentation\'][image_index][:, :, planeIndex]))\n                        #     continue\n                        # cv2.imwrite(\'test/depth_pred.png\', drawDepthImage(pred_d))\n                        # cv2.imwrite(\'test/depth_gt.png\', drawDepthImage(gt_dict[\'depth\'][image_index]))                        \n                        # cv2.imwrite(\'test/depth_diff.png\', drawMaskImage(np.abs(pred_d - gt_dict[\'depth\'][image_index]) * 5))\n                        # exit(1)\n                        predNumPlanes = options.numOutputPlanes\n                        gtDepths = calcPlaneDepths(gt_dict[\'plane\'][image_index], WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n                        pixelStatistics, planeStatistics = evaluatePlanePrediction(planeDepths, pred_s[:, :, :options.numOutputPlanes], predNumPlanes, gtDepths, gt_dict[\'segmentation\'][image_index], gt_dict[\'num_planes\'][image_index])\n                        #print(pixelStatistics)\n                        #exit(1)\n                        #planeStatistics = np.array(planeStatistics)[1]\n                        #accuracy = (planeStatistics[3:8, 0].astype(np.float32) / np.maximum(planeStatistics[3:8, 1], 1e-4)).mean()\n                        pixelStatistics = np.array(pixelStatistics)[1]\n                        # print(pixelStatistics)\n                        # pixelStatistics[3:8].mean()\n                        # exit(1)\n                        accuracy = pixelStatistics[3:8].mean()\n                        score += accuracy\n                        \n                        #cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_d))            \n                        #cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(pred_s, blackIndex=options.numOutputPlanes))\n                        #exit(1)\n                        continue\n                    score /= options.numImages\n                    print(score, parameters)\n                    #exit(1)\n                    if score > bestScore:\n                        bestScore = score\n                        bestParameters = parameters\n                        pass\n                    pass\n                continue\n            print(bestScore, bestParameters)\n            pass\n        continue\n    return\n\n\ndef evaluateDepthPrediction(options):\n\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n\n    if options.useCache == 1 and os.path.exists(options.result_filename):\n        results = np.load(options.result_filename)\n        results = results[()]\n    else:\n        results = getResults(options)\n        if options.useCache != -2:\n            np.save(options.result_filename, results)\n            pass\n        pass\n    \n    gt_dict = results[\'gt\']\n    predictions = results[\'pred\']\n\n    for key, value in gt_dict.iteritems():\n        if options.imageIndex >= 0:\n            gt_dict[key] = value[options.imageIndex:options.imageIndex + 1]\n        elif value.shape[0] > options.numImages:\n            gt_dict[key] = value[:options.numImages]\n            pass\n        continue\n    for pred_dict in predictions:\n        for key, value in pred_dict.iteritems():\n            if options.imageIndex >= 0:\n                pred_dict[key] = value[options.imageIndex:options.imageIndex + 1]\n            elif value.shape[0] > options.numImages:\n                pred_dict[key] = value[:options.numImages]\n                pass\n            continue\n        continue\n\n    titles = options.titles\n\n\n    for image_index in xrange(options.visualizeImages):\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_image.png\', gt_dict[\'image\'][image_index])\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_gt.png\', drawDepthImage(gt_dict[\'depth\'][image_index]))\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_gt.png\', drawSegmentationImage(np.concatenate([gt_dict[\'segmentation\'][image_index], 1 - np.expand_dims(gt_dict[\'plane_mask\'][image_index], -1)], axis=2), blackIndex=options.numOutputPlanes))\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_semantics_gt.png\', drawSegmentationImage(gt_dict[\'semantics\'][image_index], blackIndex=0))\n\n        \n        # plane_depths = calcPlaneDepths(gt_dict[\'plane\'][image_index], WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n        # all_depths = np.concatenate([plane_depths, np.expand_dims(gt_dict[\'depth\'][image_index], -1)], axis=2)\n        # depth = np.sum(all_depths * np.concatenate([gt_dict[\'segmentation\'][image_index], 1 - np.expand_dims(gt_dict[\'plane_mask\'][image_index], -1)], axis=2), axis=2)\n        # cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_gt_plane.png\', drawDepthImage(depth))\n        \n        for method_index, pred_dict in enumerate(predictions):\n            cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_dict[\'depth\'][image_index]))\n\n            if titles[method_index] == \'pixelwise\':\n                continue\n            segmentation = pred_dict[\'segmentation\'][image_index]\n            segmentation = np.concatenate([segmentation, pred_dict[\'np_mask\'][image_index]], axis=2)\n            cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(segmentation, blackIndex=options.numOutputPlanes))\n            continue\n        continue\n    \n\n    #post processing\n    for method_index, method in enumerate(options.methods):\n        if method[1] == \'graphcut\':\n            pred_dict = gt_dict\n            predSegmentations = []\n            predDepths = []\n            for image_index in xrange(options.numImages):\n                #if image_index != 3:\n                #continue\n                print(\'graph cut \' + str(image_index))\n\n                segmentation = np.argmax(np.concatenate([pred_dict[\'segmentation\'][image_index], 1 - np.expand_dims(pred_dict[\'plane_mask\'][image_index], -1)], axis=2), axis=2)\n                #pred_s = getSegmentationsGraphCut(pred_dict[\'plane\'][image_index], gt_dict[\'image\'][image_index], pred_dict[\'depth\'][image_index], pred_dict[\'normal\'][image_index], segmentation, pred_dict[\'semantics\'][image_index], pred_dict[\'info\'][image_index], gt_dict[\'num_planes\'][image_index])\n\n                pred_p, pred_s, numPlanes = removeSmallSegments(pred_dict[\'plane\'][image_index], gt_dict[\'image\'][image_index], pred_dict[\'depth\'][image_index], pred_dict[\'normal\'][image_index], segmentation, pred_dict[\'semantics\'][image_index], pred_dict[\'info\'][image_index], gt_dict[\'num_planes\'][image_index])\n                #pred_p, pred_s, numPlanes = pred_dict[\'plane\'][image_index], segmentation, gt_dict[\'num_planes\'][image_index]\n                print((gt_dict[\'num_planes\'][image_index], numPlanes))\n                planeDepths = calcPlaneDepths(pred_p, WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n                allDepths = np.concatenate([planeDepths, np.expand_dims(pred_dict[\'depth\'][image_index], -1)], axis=2)\n                pred_d = allDepths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), pred_s.reshape(-1)].reshape(HEIGHT, WIDTH)\n\n                predSegmentations.append(pred_s)\n                predDepths.append(pred_d)\n\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_d))                            \n                cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(pred_s, blackIndex=options.numOutputPlanes))\n                continue    \n            new_pred_dict = {}\n            for key, value in pred_dict.iteritems():\n                new_pred_dict[key] = value\n                continue\n            new_pred_dict[\'segmentation\'] = np.array(predSegmentations)\n            predictions[method_index] = new_pred_dict\n        if method[1] == \'crf_tf\':\n            pred_dict = predictions[method_index]\n            predSegmentations = []\n            predDepths = []\n\n            image_inp = tf.placeholder(tf.float32, shape=[1, HEIGHT, WIDTH, 3], name=\'image\')\n            segmentation_inp = tf.placeholder(tf.float32, shape=[1, HEIGHT, WIDTH, options.numOutputPlanes + 1], name=\'segmentation\')\n            plane_inp = tf.placeholder(tf.float32, shape=[1, options.numOutputPlanes, 3], name=\'plane\')\n            non_plane_depth_inp = tf.placeholder(tf.float32, shape=[1, HEIGHT, WIDTH, 1], name=\'non_plane_depth\')\n            info_inp = tf.placeholder(tf.float32, shape=[20], name=\'info\')\n\n            \n            plane_parameters = tf.reshape(plane_inp, (-1, 3))\n            plane_depths = planeDepthsModule(plane_parameters, WIDTH, HEIGHT, info_inp)\n            plane_depths = tf.transpose(tf.reshape(plane_depths, [HEIGHT, WIDTH, -1, options.numOutputPlanes]), [2, 0, 1, 3])\n            all_depths = tf.concat([plane_depths, non_plane_depth_inp], axis=3)\n\n            planesY = plane_inp[:, :, 1]\n            planesD = tf.maximum(tf.norm(plane_inp, axis=-1), 1e-4)\n            planesY /= planesD\n            planesY = tf.concat([planesY, tf.ones((1, 1))], axis=1)\n\n            #refined_segmentation = crfModule(segmentation_inp, plane_inp, non_plane_depth_inp, info_inp, numOutputPlanes = options.numOutputPlanes, numIterations=5)\n\n            imageDiff = calcImageDiff(image_inp)\n            #refined_segmentation, debug_dict = segmentationRefinementModule(segmentation_inp, all_depths, planesY, imageDiff, numOutputPlanes = options.numOutputPlanes + 1, numIterations=5)\n            refined_segmentation, debug_dict = meanfieldModule(segmentation_inp, all_depths, planesY, imageDiff, numOutputPlanes = options.numOutputPlanes + 1, maxDepthDiff=0.2, varDepthDiff=pow(0.2, 2))\n            \n            config=tf.ConfigProto()\n            config.gpu_options.allow_growth=True\n            config.allow_soft_placement=True\n\n            init_op = tf.group(tf.global_variables_initializer(),\n                               tf.local_variables_initializer())\n            with tf.Session(config=config) as sess:\n                sess.run(init_op)\n                for image_index in xrange(options.numImages):\n                    #if image_index != 1:\n                    #continue\n                    print(\'crf tf \' + str(image_index))\n                    allSegmentations = np.concatenate([pred_dict[\'segmentation\'][image_index], pred_dict[\'np_mask\'][image_index]], axis=2)\n                    allSegmentations = softmax(allSegmentations)\n                    pred_s, debug = sess.run([refined_segmentation, debug_dict], feed_dict={segmentation_inp: np.expand_dims(allSegmentations, 0), plane_inp: np.expand_dims(pred_dict[\'plane\'][image_index], 0), non_plane_depth_inp: np.expand_dims(pred_dict[\'np_depth\'][image_index], 0), info_inp: gt_dict[\'info\'][image_index], image_inp: gt_dict[\'image\'][image_index:image_index + 1]})\n\n                    pred_s = pred_s[0]\n                    planeDepths = calcPlaneDepths(pred_dict[\'plane\'][image_index], WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n                    allDepths = np.concatenate([planeDepths, pred_dict[\'np_depth\'][image_index]], axis=2)\n                    pred_d = np.sum(allDepths * pred_s, axis=-1)\n                    \n                    predSegmentations.append(pred_s)\n                    predDepths.append(pred_d)\n            \n                    cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_d))            \n                    cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(pred_s, blackIndex=options.numOutputPlanes))\n\n                    if \'diff\' in debug:\n                        segmentation = np.argmax(allSegmentations, axis=-1)\n                        for planeIndex in xrange(options.numOutputPlanes + 1):\n                            cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(allSegmentations[:, :, planeIndex]))\n                            continue\n                    \n                        for planeIndex in xrange(debug[\'diff\'].shape[-1]):\n                            cv2.imwrite(\'test/cost_mask_\' + str(planeIndex) + \'.png\', drawMaskImage(debug[\'diff\'][0, :, :, planeIndex] / 2))\n                            continue\n                        exit(1)                        \n                        pass\n                    continue\n                pass\n            new_pred_dict = {}\n            for key, value in pred_dict.iteritems():\n                new_pred_dict[key] = value\n                continue\n            segmentations = np.array(predSegmentations)\n            new_pred_dict[\'segmentation\'] = segmentations[:, :, :, :options.numOutputPlanes]\n            new_pred_dict[\'non_plane_mask\'] = segmentations[:, :, :, options.numOutputPlanes:options.numOutputPlanes + 1]\n            #new_pred_dict[\'non_plane_mask\'] = segmentations[:, :, :, :options.numOutputPlanes]\n            new_pred_dict[\'depth\'] = np.array(predDepths)\n            predictions[method_index] = new_pred_dict\n            pass\n                  \n        if method[1] == \'crf\':\n            pred_dict = predictions[method_index]\n            predSegmentations = []\n            predDepths = []\n            for image_index in xrange(options.numImages):\n                print(\'crf \' + str(image_index))\n                boundaries = pred_dict[\'boundary\'][image_index]\n                boundaries = sigmoid(boundaries)\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_boundary.png\', drawMaskImage(np.concatenate([boundaries, np.zeros((HEIGHT, WIDTH, 1))], axis=2)))\n                                      \n                allSegmentations = np.concatenate([pred_dict[\'segmentation\'][image_index], pred_dict[\'np_mask\'][image_index]], axis=2)\n                allSegmentations = softmax(allSegmentations)\n                planeDepths = calcPlaneDepths(pred_dict[\'plane\'][image_index], WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n                allDepths = np.concatenate([planeDepths, pred_dict[\'np_depth\'][image_index]], axis=2)\n                #boundaries = np.concatenate([np.ones((allSegmentations.shape[0], allSegmentations.shape[1], 1)), -np.ones((allSegmentations.shape[0], allSegmentations.shape[1], 1))], axis=2)\n                #if options.imageIndex >= 0:\n                #boundaries = cv2.imread(options.test_dir + \'/\' + str(options.imageIndex) + \'_boundary.png\')                \n                #else:\n                #boundaries = cv2.imread(options.test_dir + \'/\' + str(image_index) + \'_boundary.png\')\n                #pass\n                #boundaries = (boundaries > 128).astype(np.float32)[:, :, :2]\n\n                allDepths[:, :, options.numOutputPlanes] = 0\n                pred_s = refineSegmentation(gt_dict[\'image\'][image_index], allSegmentations, allDepths, boundaries, numOutputPlanes = options.numOutputPlanes, numIterations=20, numProposals=5)\n                pred_d = allDepths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), pred_s.reshape(-1)].reshape(HEIGHT, WIDTH)\n            \n                predSegmentations.append(pred_s)\n                predDepths.append(pred_d)\n            \n                cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_d))            \n                cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(pred_s, blackIndex=options.numOutputPlanes))\n\n                #segmentation = np.argmax(allSegmentations, axis=-1)\n                for planeIndex in xrange(options.numOutputPlanes + 1):\n                    cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(allSegmentations[:, :, planeIndex]))\n                    continue\n                #cv2.imwrite(options.test_dir + \'/mask_\' + str(21) + \'.png\', drawDepthImage(pred_dict[\'np_depth\'][0]))\n                #for plane_index in xrange(options.numOutputPlanes + 1):\n                #cv2.imwrite(options.test_dir + \'/mask_\' + str(plane_index) + \'.png\', drawMaskImage(pred_s == plane_index))\n                #continue\n                #exit(1)\n                continue\n                \n            new_pred_dict = {}\n            for key, value in pred_dict.iteritems():\n                new_pred_dict[key] = value\n                continue\n            new_pred_dict[\'segmentation\'] = np.array(predSegmentations)\n            new_pred_dict[\'depth\'] = np.array(predDepths)\n            predictions[method_index] = new_pred_dict\n            pass\n        \n\n        if \'pixelwise\' in method[1]:\n            pred_dict = predictions[method_index]\n            predPlanes = []\n            predSegmentations = []\n            predDepths = []        \n            for image_index in xrange(options.numImages):\n                pred_d = pred_dict[\'np_depth\'][image_index].squeeze()\n                if \'_1\' in method[1]:\n                    pred_s = np.zeros(pred_dict[\'segmentation\'][image_index].shape)\n                    pred_p = np.zeros(pred_dict[\'plane\'][image_index].shape)    \n                elif \'_2\' in methods[1]:\n                    pred_p, pred_s, pred_d = fitPlanes(pred_d, gt_dict[\'info\'][image_index], numPlanes=options.numOutputPlanes, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=0.2)\n                elif \'_3\' in methods[1]:\n                    pred_p, pred_s, pred_d = fitPlanes(pred_d, gt_dict[\'info\'][image_index], numPlanes=options.numOutputPlanes, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=0.2)\n                elif \'_4\' in methods[1]:\n                    pred_p, pred_s, pred_d = fitPlanesSegmentation(pred_d, pred_dict[\'semantics\'][image_index], gt_dict[\'info\'][image_index], numPlanes=options.numOutputPlanes, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=0.2)\n                    pass\n                predPlanes.append(pred_p)                \n                predSegmentations.append(pred_s)\n                predDepths.append(pred_d)\n\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_d))\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(pred_s))\n                continue\n            new_pred_dict = {}\n            for key, value in pred_dict.iteritems():\n                new_pred_dict[key] = value\n                continue\n            new_pred_dict[\'plane\'] = np.array(predPlanes)            \n            new_pred_dict[\'segmentation\'] = np.array(predSegmentations)\n            new_pred_dict[\'depth\'] = np.array(predDepths)\n            predictions[method_index] = new_pred_dict\n            #titles.append(\'pixelwise+semantics+RANSAC\')\n            pass\n        continue\n\n\n    \n    for method_index, pred_dict in enumerate(predictions):\n        print(titles[method_index])\n        evaluateDepths(pred_dict[\'depth\'], gt_dict[\'depth\'], np.ones(gt_dict[\'depth\'].shape))\n        continue\n    return\n\ndef getResults(options):\n    checkpoint_prefix = \'checkpoint/\'\n\n    methods = options.methods\n    predictions = []\n\n    if os.path.exists(options.result_filename):\n        if options.useCache == 1:\n            results = np.load(options.result_filename)\n            results = results[()]\n            return results\n        elif options.useCache == 2:\n            results = np.load(options.result_filename)\n            results = results[()]\n            gt_dict = results[\'gt\']\n            predictions = results[\'pred\']\n        else:\n            gt_dict = getGroundTruth(options)\n            pass\n    else:\n        gt_dict = getGroundTruth(options)\n        pass\n    \n    \n\n    for method_index, method in enumerate(methods):\n        if len(method) < 4 or method[3] < 2:\n            continue\n        if method[0] == \'\':\n            continue\n\n\n        method_options = copy.deepcopy(options)\n        if \'ds0\' not in method[0]:\n            method_options.deepSupervisionLayers = [\'res4b22_relu\', ]\n        else:\n            method_options.deepSupervisionLayers = []\n            pass\n        method_options.predictConfidence = 0\n        method_options.predictLocal = 0\n        method_options.predictPixelwise = 1\n        method_options.predictBoundary = int(\'pb\' in method[0])\n        method_options.anchorPlanes = 0\n        if \'ps\' in method[0]:\n            method_options.predictSemantics = 1\n        else:\n            method_options.predictSemantics = 0\n            pass\n        if \'crfrnn\' in method[0]:\n            method_options.crfrnn = int(method[0].split(\'crfrnn\')[1].split(\'_\')[0])\n        else:\n            method_options.crfrnn = 0\n            pass\n        if \'ap1\' in method[0]:\n            method_options.anchorPlanes = 1            \n            pass\n\n        method_options.numOutputPlanes = 20\n        if \'np10\' in method[0]:\n            method_options.numOutputPlanes = 10\n        elif \'np15\' in method[0]:\n            method_options.numOutputPlanes = 15\n            pass\n\n        \n        method_options.checkpoint_dir = checkpoint_prefix + method[0]\n        print(method_options.checkpoint_dir)\n        \n        method_options.suffix = method[1]\n\n        method_names = [previous_method[0] for previous_method in methods[:method_index]]\n\n        if method[0] in method_names:\n            pred_dict = predictions[method_names.index(method[0])]\n        elif method[0] == \'gt\':\n            pred_dict = gt_dict\n        else:\n            pred_dict = getPrediction(method_options)\n            pass\n\n        # for image_index in xrange(options.visualizeImages):\n        #     cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_dict[\'depth\'][image_index]))\n        #     cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage())\n        #     continue\n\n        if len(method) >= 4 and method[3] == 3:\n            predictions.insert(0, pred_dict)\n        else:\n            if method_index < len(predictions):\n                predictions[method_index] = pred_dict\n            else:\n                predictions.append(pred_dict)\n                pass\n            pass\n        continue\n    #np.save(options.test_dir + \'/curves.npy\', curves)\n    results = {\'gt\': gt_dict, \'pred\': predictions}\n\n    if options.useCache != -1:\n        np.save(options.result_filename, results)\n        pass\n    pass\n    \n    return results\n\ndef getPrediction(options):\n    tf.reset_default_graph()\n    \n    options.batchSize = 1\n    min_after_dequeue = 1000\n\n    reader = RecordReaderAll()\n    if options.dataset == \'SUNCG\':\n        filename_queue = tf.train.string_input_producer([options.dataFolder + \'/planes_SUNCG_val.tfrecords\'], num_epochs=10000)\n    elif options.dataset == \'NYU_RGBD\':\n        filename_queue = tf.train.string_input_producer([options.dataFolder + \'/planes_nyu_rgbd_val.tfrecords\'], num_epochs=1)\n        options.deepSupervision = 0\n        options.predictLocal = 0\n    elif options.dataset == \'matterport\':\n        filename_queue = tf.train.string_input_producer([options.dataFolder + \'/planes_matterport_val.tfrecords\'], num_epochs=1)\n    else:\n        filename_queue = tf.train.string_input_producer([options.dataFolder + \'/planes_scannet_val.tfrecords\'], num_epochs=1)\n        pass\n\n    img_inp, global_gt_dict, local_gt_dict = reader.getBatch(filename_queue, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True, random=False)\n        \n\n    \n    training_flag = tf.constant(False, tf.bool)\n\n    options.gpu_id = 0\n    # if \'sample\' not in options.checkpoint_dir:\n    #     global_pred_dict, _, _ = build_graph(img_inp, img_inp, training_flag, options)\n    # else:\n    #     global_pred_dict, _, _ = build_graph_sample(img_inp, img_inp, training_flag, options)\n    global_pred_dict, _, _ = build_graph(img_inp, img_inp, training_flag, options)\n    \n    var_to_restore = tf.global_variables()\n\n\n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n    \n    pred_dict = {}\n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n        #var_to_restore = [v for v in var_to_restore if \'res4b22_relu_non_plane\' not in v.name]\n        loader = tf.train.Saver(var_to_restore)\n        loader.restore(sess, ""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n        #loader.restore(sess, options.fineTuningCheckpoint)\n        \n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n        \n        \n        try:\n            predDepths = []\n            predPlanes = []\n            predSegmentations = []\n            predSemantics = []            \n            predNonPlaneDepths = []\n            predNonPlaneNormals = []            \n            predNonPlaneMasks = []\n            predBoundaries = []            \n            for index in xrange(options.startIndex + options.numImages):\n                if index % 10 == 0:\n                    print((\'image\', index))\n                    pass\n                t0=time.time()\n\n                img, global_gt, global_pred = sess.run([img_inp, global_gt_dict, global_pred_dict])\n\n                if index < options.startIndex:\n                    continue                \n\n\n                pred_p = global_pred[\'plane\'][0]\n                pred_s = global_pred[\'segmentation\'][0]\n                \n                pred_np_m = global_pred[\'non_plane_mask\'][0]\n                pred_np_d = global_pred[\'non_plane_depth\'][0]\n                pred_np_n = global_pred[\'non_plane_normal\'][0]\n                \n                if global_gt[\'info\'][0][19] > 1 and global_gt[\'info\'][0][19] < 4 and False:\n                    pred_np_n = calcNormal(pred_np_d.squeeze(), global_gt[\'info\'][0])\n                    pass\n\n\n                pred_b = global_pred[\'boundary\'][0]\n                predNonPlaneMasks.append(pred_np_m)                    \n                predNonPlaneDepths.append(pred_np_d)\n                predNonPlaneNormals.append(pred_np_n)\n                predBoundaries.append(pred_b)\n                    \n                all_segmentations = np.concatenate([pred_s, pred_np_m], axis=2)\n                plane_depths = calcPlaneDepths(pred_p, WIDTH, HEIGHT, global_gt[\'info\'][0])\n                all_depths = np.concatenate([plane_depths, pred_np_d], axis=2)\n\n                segmentation = np.argmax(all_segmentations, 2)\n                pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape(HEIGHT, WIDTH)\n\n                if \'semantics\' in global_pred:\n                    #cv2.imwrite(\'test/semantics.png\', drawSegmentationImage(np.argmax(global_pred[\'semantics\'][0], axis=-1)))\n                    #exit(1)\n                    predSemantics.append(np.argmax(global_pred[\'semantics\'][0], axis=-1))\n                else:\n                    predSemantics.append(np.zeros((HEIGHT, WIDTH)))\n                    pass\n                                         \n                predDepths.append(pred_d)\n                predPlanes.append(pred_p)\n                #predSegmentations.append(pred_s)\n                predSegmentations.append(segmentation)\n                    \n                continue\n            pred_dict[\'plane\'] = np.array(predPlanes)\n            pred_dict[\'segmentation\'] = np.array(predSegmentations)\n            pred_dict[\'semantics\'] = np.array(predSemantics)            \n            pred_dict[\'depth\'] = np.array(predDepths)\n            pred_dict[\'np_depth\'] = np.array(predNonPlaneDepths)\n            pred_dict[\'np_normal\'] = np.array(predNonPlaneNormals)\n            pred_dict[\'np_mask\'] = np.array(predNonPlaneMasks)\n            pred_dict[\'boundary\'] = np.array(predBoundaries)\n            pass\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n        \n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return pred_dict\n\ndef getGroundTruth(options):    \n    options.batchSize = 1\n    min_after_dequeue = 1000\n\n    reader = RecordReaderAll()\n    if options.dataset == \'SUNCG\':\n        filename_queue = tf.train.string_input_producer([options.dataFolder + \'/planes_SUNCG_val.tfrecords\'], num_epochs=1)\n    elif options.dataset == \'NYU_RGBD\':\n        filename_queue = tf.train.string_input_producer([options.dataFolder + \'/planes_nyu_rgbd_val.tfrecords\'], num_epochs=1)\n        options.deepSupervision = 0\n        options.predictLocal = 0\n    elif options.dataset == \'matterport\':\n        filename_queue = tf.train.string_input_producer([options.dataFolder + \'/planes_matterport_val.tfrecords\'], num_epochs=1)\n    else:\n        filename_queue = tf.train.string_input_producer([options.dataFolder + \'/planes_scannet_val.tfrecords\'], num_epochs=1)\n        pass\n\n\n    img_inp, global_gt_dict, local_gt_dict = reader.getBatch(filename_queue, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True, random=False)\n    \n\n    training_flag = tf.constant(False, tf.bool)\n\n    # if options.dataset == \'NYU_RGBD\':\n    #     global_gt_dict[\'segmentation\'], global_gt_dict[\'plane_mask\'] = tf.ones((options.batchSize, HEIGHT, WIDTH, options.numOutputPlanes)), tf.ones((options.batchSize, HEIGHT, WIDTH, 1))\n    # elif options.dataset == \'SUNCG\':\n    #     normalDotThreshold = np.cos(np.deg2rad(5))\n    #     distanceThreshold = 0.05        \n    #     global_gt_dict[\'segmentation\'], global_gt_dict[\'plane_mask\'] = fitPlaneMasksModule(global_gt_dict[\'plane\'], global_gt_dict[\'depth\'], global_gt_dict[\'normal\'], width=WIDTH, height=HEIGHT, normalDotThreshold=normalDotThreshold, distanceThreshold=distanceThreshold, closing=True, one_hot=True)\n    # else:\n    #     global_gt_dict[\'plane_mask\'] = 1 - global_gt_dict[\'non_plane_mask\']\n    #     pass\n\n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n    gt_dict = {}\n    \n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n        \n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)        \n        \n        try:\n            gtDepths = []\n            gtNormals = []            \n            planeMasks = []\n            #predMasks = []\n            gtPlanes = []\n            gtSegmentations = []\n            gtSemantics = []            \n            gtInfo = []\n            gtNumPlanes = []            \n            images = []\n\n            for index in xrange(options.startIndex + options.numImages):\n                print((\'image\', index))\n                t0=time.time()\n\n                img, global_gt = sess.run([img_inp, global_gt_dict])\n\n                if index < options.startIndex:\n                    continue\n\n                \n                # print(global_gt[\'path\'])\n                # if index == 11:\n                #     cv2.imwrite(\'test/mask.png\', drawMaskImage(global_gt[\'non_plane_mask\'].squeeze()))\n                #     exit(1)\n                image = ((img[0] + 0.5) * 255).astype(np.uint8)\n                images.append(image)\n\n                #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_boundary.png\', drawMaskImage(np.concatenate([global_gt[\'boundary\'][0], np.zeros((HEIGHT, WIDTH, 1))], axis=2)))\n                \n                gt_d = global_gt[\'depth\'].squeeze()\n                gtDepths.append(gt_d)\n\n                if global_gt[\'info\'][0][19] == 3:\n                    gt_n = calcNormal(gt_d, global_gt[\'info\'][0])\n                    #cv2.imwrite(\'test/normal.png\', drawNormalImage(gt_n))\n                    #exit(1)\n                else:\n                    gt_n = global_gt[\'normal\'][0]\n                    pass    \n                gtNormals.append(gt_n)\n                \n                planeMask = np.squeeze(1 - global_gt[\'non_plane_mask\'])\n                planeMasks.append(planeMask)\n                \n                gt_p = global_gt[\'plane\'][0]\n                gtPlanes.append(gt_p)\n                gt_s = global_gt[\'segmentation\'][0]\n                gtSegmentations.append(gt_s)\n                gt_semantics = global_gt[\'semantics\'][0]\n                gtSemantics.append(gt_semantics)\n                gt_num_p = global_gt[\'num_planes\'][0]\n                gtNumPlanes.append(gt_num_p)\n                \n                gtInfo.append(global_gt[\'info\'][0])\n                continue\n\n            gt_dict[\'image\'] = np.array(images)\n            gt_dict[\'depth\'] = np.array(gtDepths)\n            gt_dict[\'normal\'] = np.array(gtNormals)\n            gt_dict[\'plane_mask\'] = np.array(planeMasks)\n            gt_dict[\'plane\'] = np.array(gtPlanes)\n            gt_dict[\'segmentation\'] = np.array(gtSegmentations)\n            gt_dict[\'semantics\'] = np.array(gtSemantics)\n            gt_dict[\'num_planes\'] = np.array(gtNumPlanes)\n            gt_dict[\'info\'] = np.array(gtInfo)\n\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n        \n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return gt_dict\n\n\nif __name__==\'__main__\':\n    """"""\n    Parse input arguments\n    """"""\n    parser = argparse.ArgumentParser(description=\'Planenet\')\n    parser.add_argument(\'--task\', dest=\'task\',\n                        help=\'task type\',\n                        default=\'plane\', type=str)\n    parser.add_argument(\'--numOutputPlanes\', dest=\'numOutputPlanes\',\n                        help=\'the number of output planes\',\n                        default=20, type=int)\n    parser.add_argument(\'--dataset\', dest=\'dataset\',\n                        help=\'dataset name\',\n                        default=\'ScanNet\', type=str)\n    parser.add_argument(\'--hybrid\', dest=\'hybrid\',\n                        help=\'hybrid\',\n                        default=\'3\', type=str)\n    parser.add_argument(\'--visualizeImages\', dest=\'visualizeImages\',\n                        help=\'visualize image\',\n                        default=30, type=int)    \n    parser.add_argument(\'--numImages\', dest=\'numImages\',\n                        help=\'the number of images\',\n                        default=30, type=int)\n    parser.add_argument(\'--startIndex\', dest=\'startIndex\',\n                        help=\'start index\',\n                        default=0, type=int)    \n    parser.add_argument(\'--useCache\', dest=\'useCache\',\n                        help=\'use cache\',\n                        default=-1, type=int)\n    # parser.add_argument(\'--useCRF\', dest=\'useCRF\',\n    #                     help=\'use crf\',\n    #                     default=0, type=int)\n    # parser.add_argument(\'--useSemantics\', dest=\'useSemantics\',\n    #                     help=\'use semantics\',\n    #                     default=0, type=int)\n    parser.add_argument(\'--useNonPlaneDepth\', dest=\'useNonPlaneDepth\',\n                        help=\'use non-plane depth\',\n                        default=0, type=int)\n    parser.add_argument(\'--imageIndex\', dest=\'imageIndex\',\n                        help=\'image index\',\n                        default=-1, type=int)\n    parser.add_argument(\'--methods\', dest=\'methods\',\n                        help=\'methods\',\n                        default=\'2000000\', type=str)\n    parser.add_argument(\'--dataFolder\', dest=\'dataFolder\',\n                        help=\'data folder\',\n                        default=\'/mnt/vision/PlaneNet/\', type=str)\n    \n    args = parser.parse_args()\n    #args.hybrid = \'hybrid\' + args.hybrid\n    args.test_dir = \'evaluate/\'\n    args.visualizeImages = min(args.visualizeImages, args.numImages)\n    if args.imageIndex >= 0:\n        args.visualizeImages = 1\n        args.numImages = 1            \n        pass\n\n    #args.titles = [ALL_TITLES[int(method)] for method in args.methods]\n    #args.methods = [ALL_METHODS[int(method)] for method in args.methods]\n    args.titles = ALL_TITLES\n    methods = ALL_METHODS\n    for methodIndex, flag in enumerate(args.methods):\n        methods[methodIndex][3] = int(flag)\n        pass\n    args.methods = methods\n    \n    args.result_filename = args.test_dir + \'/results_\' + str(args.startIndex) + \'.npy\'\n    print(args.titles)\n    \n    if args.task == \'plane\':\n        evaluatePlanes(args)\n    elif args.task == \'depth\':\n        evaluateDepthPrediction(args)\n    elif args.task == \'search\':\n        gridSearch(args)\n        pass\n'"
html.py,0,"b'# -*- encoding: utf8 -*-\n#\n# $Id: html.py 5409 2011-06-29 07:07:25Z rjones $\n# $HeadURL: svn+ssh://svn/svn/trunk/api/eklib/html.py $\n#\n\'\'\'Simple, elegant HTML, XHTML and XML generation.\n\nConstructing your HTML\n----------------------\n\nTo construct HTML start with an instance of ``html.HTML()``. Add\ntags by accessing the tag\'s attribute on that object. For example:\n\n>>> from html import HTML\n>>> h = HTML()\n>>> h.p(\'Hello, world!\')\n>>> print h                          # or print(h) in python 3+\n<p>Hello, world!</p>\n\nYou may supply a tag name and some text contents when creating a HTML\ninstance:\n\n>>> h = HTML(\'html\', \'text\')\n>>> print h\n<html>text</html>\n\nYou may also append text content later using the tag\'s ``.text()`` method\nor using augmented addition ``+=``. Any HTML-specific characters (``<>&""``)\nin the text will be escaped for HTML safety as appropriate unless\n``escape=False`` is passed. Each of the following examples uses a new\n``HTML`` instance:\n\n>>> p = h.p(\'hello world!\\\\n\')\n>>> p.br\n>>> p.text(\'more &rarr; text\', escape=False)\n>>> p += \' ... augmented\'\n>>> h.p\n>>> print h\n<p>hello, world!<br>more &rarr; text ... augmented</p>\n<p>\n\nNote also that the top-level ``HTML`` object adds newlines between tags by\ndefault. Finally in the above you\'ll see an empty paragraph tag - tags with\nno contents get no closing tag.\n\nIf the tag should have sub-tags you have two options. You may either add\nthe sub-tags directly on the tag:\n\n>>> l = h.ol\n>>> l.li(\'item 1\')\n>>> l.li.b(\'item 2 > 1\')\n>>> print h\n<ol>\n<li>item 1</li>\n<li><b>item 2 &gt; 1</b></li>\n</ol>\n\nNote that the default behavior with lists (and tables) is to add newlines\nbetween sub-tags to generate a nicer output. You can also see in that\nexample the chaining of tags in ``l.li.b``.\n\nTag attributes may be passed in as well:\n\n>>> t = h.table(border=\'1\')\n>>> for i in range(2):\n>>>   r = t.tr\n>>>   r.td(\'column 1\')\n>>>   r.td(\'column 2\')\n>>> print t\n<table border=""1"">\n<tr><td>column 1</td><td>column 2</td></tr>\n<tr><td>column 1</td><td>column 2</td></tr>\n</table>\n\nA variation on the above is to use a tag as a context variable. The\nfollowing is functionally identical to the first list construction but\nwith a slightly different sytax emphasising the HTML structure:\n\n>>> with h.ol as l:\n...   l.li(\'item 1\')\n...   l.li.b(\'item 2 > 1\')\n\nYou may turn off/on adding newlines by passing ``newlines=False`` or\n``True`` to the tag (or ``HTML`` instance) at creation time:\n\n>>> l = h.ol(newlines=False)\n>>> l.li(\'item 1\')\n>>> l.li(\'item 2\')\n>>> print h\n<ol><li>item 1</li><li>item 2</li></ol>\n\nSince we can\'t use ``class`` as a keyword, the library recognises ``klass``\nas a substitute:\n\n>>> print h.p(content, klass=""styled"")\n<p class=""styled"">content</p>\n\n\nUnicode\n-------\n\n``HTML`` will work with either regular strings **or** unicode strings, but\nnot **both at the same time**.\n\nObtain the final unicode string by calling ``unicode()`` on the ``HTML``\ninstance:\n\n>>> h = HTML()\n>>> h.p(u\'Some Euro: \xe2\x82\xac1.14\')\n>>> unicode(h)\nu\'<p>Some Euro: \xe2\x82\xac1.14</p>\'\n\nIf (under Python 2.x) you add non-unicode strings or attempt to get the\nresultant HTML source through any means other than ``unicode()`` then you\nwill most likely get one of the following errors raised:\n\nUnicodeDecodeError\n   Probably means you\'ve added non-unicode strings to your HTML.\nUnicodeEncodeError\n   Probably means you\'re trying to get the resultant HTML using ``print``\n   or ``str()`` (or ``%s``).\n\n\nHow generation works\n--------------------\n\nThe HTML document is generated when the ``HTML`` instance is ""stringified"".\nThis could be done either by invoking ``str()`` on it, or just printing it.\nIt may also be returned directly as the ""iterable content"" from a WSGI app\nfunction.\n\nYou may also render any tag or sub-tag at any time by stringifying it.\n\nTags with no contents (either text or sub-tags) will have no closing tag.\nThere is no ""special list"" of tags that must always have closing tags, so\nif you need to force a closing tag you\'ll need to provide some content,\neven if it\'s just a single space character.\n\nRendering doesn\'t affect the HTML document\'s state, so you can add to or\notherwise manipulate the HTML after you\'ve stringified it.\n\n\nCreating XHTML\n--------------\n\nTo construct XHTML start with an instance of ``html.XHTML()`` and use it\nas you would an ``HTML`` instance. Empty elements will now be rendered\nwith the appropriate XHTML minimized tag syntax. For example:\n\n>>> from html import XHTML\n>>> h = XHTML()\n>>> h.p\n>>> h.br\n>>> print h\n<p></p>\n<br />\n\n\nCreating XML\n------------\n\nA slight tweak to the ``html.XHTML()`` implementation allows us to generate\narbitrary XML using ``html.XML()``:\n\n>>> from html import XML\n>>> h = XML(\'xml\')\n>>> h.p\n>>> h.br(\'hi there\')\n>>> print h\n<xml>\n<p />\n<br>hi there</br>\n</xml>\n\n\nTags with difficult names\n-------------------------\n\nIf your tag name isn\'t a valid Python identifier name, or if it\'s called\n""text"" or ""raw_text"" you can add your tag slightly more manually:\n\n>>> from html import XML\n>>> h = XML(\'xml\')\n>>> h += XML(\'some-tag\', \'some text\')\n>>> h += XML(\'text\', \'some text\')\n>>> print h\n<xml>\n<some-tag>some text</some-tag>\n<text>some text</text>\n</xml>\n\n\nVersion History (in Brief)\n--------------------------\n\n- 1.16 detect and raise a more useful error when some WSGI frameworks\n  attempt to call HTML.read(). Also added ability to add new content using\n  the += operator.\n- 1.15 fix Python 3 compatibility (unit tests)\n- 1.14 added plain XML support\n- 1.13 allow adding (X)HTML instances (tags) as new document content\n- 1.12 fix handling of XHTML empty tags when generating unicode\n  output (thanks Carsten Eggers)\n- 1.11 remove setuptools dependency\n- 1.10 support plain ol\' distutils again\n- 1.9 added unicode support for Python 2.x\n- 1.8 added Python 3 compatibility\n- 1.7 added Python 2.5 compatibility and escape argument to tag\n  construction\n- 1.6 added .raw_text() and and WSGI compatibility\n- 1.5 added XHTML support\n- 1.3 added more documentation, more tests\n- 1.2 added special-case klass / class attribute\n- 1.1 added escaping control\n- 1.0 was the initial release\n\n----\n\nI would be interested to know whether this module is useful - if you use it\nplease indicate so at https://www.ohloh.net/p/pyhtml\n\nThis code is copyright 2009-2011 eKit.com Inc (http://www.ekit.com/)\nSee the end of the source file for the license of use.\nXHTML support was contributed by Michael Haubenwallner.\n\'\'\'\nfrom __future__ import with_statement\n__version__ = \'1.16\'\n\nimport sys\nimport cgi\nimport unittest\n\n\nclass HTML(object):\n    \'\'\'Easily generate HTML.\n\n    >>> print HTML(\'html\', \'some text\')\n    <html>some text</html>\n    >>> print HTML(\'html\').p(\'some text\')\n    <html><p>some text</p></html>\n\n    If a name is not passed in then the instance becomes a container for\n    other tags that itself generates no tag:\n\n    >>> h = HTML()\n    >>> h.p(\'text\')\n    >>> h.p(\'text\')\n    print h\n    <p>some text</p>\n    <p>some text</p>\n\n    \'\'\'\n    newline_default_on = set(\'table ol ul dl\'.split())\n\n    def __init__(self, name=None, text=None, stack=None, newlines=True,\n            escape=True):\n        self._name = name\n        self._content = []\n        self._attrs = {}\n        # insert newlines between content?\n        if stack is None:\n            stack = [self]\n            self._top = True\n            self._newlines = newlines\n        else:\n            self._top = False\n            self._newlines = name in self.newline_default_on\n        self._stack = stack\n        if text is not None:\n            self.text(text, escape)\n\n    def __getattr__(self, name):\n        # adding a new tag or newline\n        if name == \'newline\':\n            e = \'\\n\'\n        else:\n            e = self.__class__(name, stack=self._stack)\n        if self._top:\n            self._stack[-1]._content.append(e)\n        else:\n            self._content.append(e)\n        return e\n\n    def __iadd__(self, other):\n        if self._top:\n            self._stack[-1]._content.append(other)\n        else:\n            self._content.append(other)\n        return self\n\n    def text(self, text, escape=True):\n        \'\'\'Add text to the document. If ""escape"" is True any characters\n        special to HTML will be escaped.\n        \'\'\'\n        if escape:\n            text = cgi.escape(text)\n        # adding text\n        if self._top:\n            self._stack[-1]._content.append(text)\n        else:\n            self._content.append(text)\n\n    def raw_text(self, text):\n        \'\'\'Add raw, unescaped text to the document. This is useful for\n        explicitly adding HTML code or entities.\n        \'\'\'\n        return self.text(text, escape=False)\n\n    def __call__(self, *content, **kw):\n        if self._name == \'read\':\n            if len(content) == 1 and isinstance(content[0], int):\n                raise TypeError(\'you appear to be calling read(%d) on \'\n                    \'a HTML instance\' % content)\n            elif len(content) == 0:\n                raise TypeError(\'you appear to be calling read() on a \'\n                    \'HTML instance\')\n\n        # customising a tag with content or attributes\n        escape = kw.pop(\'escape\', True)\n        if content:\n            if escape:\n                self._content = list(map(cgi.escape, content))\n            else:\n                self._content = content\n        if \'newlines\' in kw:\n            # special-case to allow control over newlines\n            self._newlines = kw.pop(\'newlines\')\n        for k in kw:\n            if k == \'klass\':\n                self._attrs[\'class\'] = cgi.escape(kw[k], True)\n            else:\n                self._attrs[k] = cgi.escape(kw[k], True)\n        return self\n\n    def __enter__(self):\n        # we\'re now adding tags to me!\n        self._stack.append(self)\n        return self\n\n    def __exit__(self, exc_type, exc_value, exc_tb):\n        # we\'re done adding tags to me!\n        self._stack.pop()\n\n    def __repr__(self):\n        return \'<HTML %s 0x%x>\' % (self._name, id(self))\n\n    def _stringify(self, str_type):\n        # turn me and my content into text\n        join = \'\\n\' if self._newlines else \'\'\n        if self._name is None:\n            return join.join(map(str_type, self._content))\n        a = [\'%s=""%s""\' % i for i in self._attrs.items()]\n        l = [self._name] + a\n        s = \'<%s>%s\' % (\' \'.join(l), join)\n        if self._content:\n            s += join.join(map(str_type, self._content))\n            s += join + \'</%s>\' % self._name\n        return s\n\n    def __str__(self):\n        return self._stringify(str)\n\n    def __unicode__(self):\n        return self._stringify(unicode)\n\n    def __iter__(self):\n        return iter([str(self)])\n\n\nclass XHTML(HTML):\n    \'\'\'Easily generate XHTML.\n    \'\'\'\n    empty_elements = set(\'base meta link hr br param img area input col \\\n        colgroup basefont isindex frame\'.split())\n\n    def _stringify(self, str_type):\n        # turn me and my content into text\n        # honor empty and non-empty elements\n        join = \'\\n\' if self._newlines else \'\'\n        if self._name is None:\n            return join.join(map(str_type, self._content))\n        a = [\'%s=""%s""\' % i for i in self._attrs.items()]\n        l = [self._name] + a\n        s = \'<%s>%s\' % (\' \'.join(l), join)\n        if self._content or not(self._name.lower() in self.empty_elements):\n            s += join.join(map(str_type, self._content))\n            s += join + \'</%s>\' % self._name\n        else:\n            s = \'<%s />%s\' % (\' \'.join(l), join)\n        return s\n\n\nclass XML(XHTML):\n    \'\'\'Easily generate XML.\n\n    All tags with no contents are reduced to self-terminating tags.\n    \'\'\'\n    newline_default_on = set()          # no tags are special\n\n    def _stringify(self, str_type):\n        # turn me and my content into text\n        # honor empty and non-empty elements\n        join = \'\\n\' if self._newlines else \'\'\n        if self._name is None:\n            return join.join(map(str_type, self._content))\n        a = [\'%s=""%s""\' % i for i in self._attrs.items()]\n        l = [self._name] + a\n        s = \'<%s>%s\' % (\' \'.join(l), join)\n        if self._content:\n            s += join.join(map(str_type, self._content))\n            s += join + \'</%s>\' % self._name\n        else:\n            s = \'<%s />%s\' % (\' \'.join(l), join)\n        return s\n\n\nclass TestCase(unittest.TestCase):\n    def test_empty_tag(self):\n        \'generation of an empty HTML tag\'\n        self.assertEquals(str(HTML().br), \'<br>\')\n\n    def test_empty_tag_xml(self):\n        \'generation of an empty XHTML tag\'\n        self.assertEquals(str(XHTML().br), \'<br />\')\n\n    def test_tag_add(self):\n        \'test top-level tag creation\'\n        self.assertEquals(str(HTML(\'html\', \'text\')), \'<html>\\ntext\\n</html>\')\n\n    def test_tag_add_no_newline(self):\n        \'test top-level tag creation\'\n        self.assertEquals(str(HTML(\'html\', \'text\', newlines=False)),\n            \'<html>text</html>\')\n\n    def test_iadd_tag(self):\n        ""test iadd\'ing a tag""\n        h = XML(\'xml\')\n        h += XML(\'some-tag\', \'spam\', newlines=False)\n        h += XML(\'text\', \'spam\', newlines=False)\n        self.assertEquals(str(h),\n            \'<xml>\\n<some-tag>spam</some-tag>\\n<text>spam</text>\\n</xml>\')\n\n    def test_iadd_text(self):\n        ""test iadd\'ing text""\n        h = HTML(\'html\', newlines=False)\n        h += \'text\'\n        h += \'text\'\n        self.assertEquals(str(h), \'<html>texttext</html>\')\n\n    def test_xhtml_match_tag(self):\n        \'check forced generation of matching tag when empty\'\n        self.assertEquals(str(XHTML().p), \'<p></p>\')\n\n    if sys.version_info[0] == 2:\n        def test_empty_tag_unicode(self):\n            \'generation of an empty HTML tag\'\n            self.assertEquals(unicode(HTML().br), unicode(\'<br>\'))\n\n        def test_empty_tag_xml_unicode(self):\n            \'generation of an empty XHTML tag\'\n            self.assertEquals(unicode(XHTML().br), unicode(\'<br />\'))\n\n        def test_xhtml_match_tag_unicode(self):\n            \'check forced generation of matching tag when empty\'\n            self.assertEquals(unicode(XHTML().p), unicode(\'<p></p>\'))\n\n    def test_just_tag(self):\n        \'generate HTML for just one tag\'\n        self.assertEquals(str(HTML().br), \'<br>\')\n\n    def test_just_tag_xhtml(self):\n        \'generate XHTML for just one tag\'\n        self.assertEquals(str(XHTML().br), \'<br />\')\n\n    def test_xml(self):\n        \'generate XML\'\n        self.assertEquals(str(XML().br), \'<br />\')\n        self.assertEquals(str(XML().p), \'<p />\')\n        self.assertEquals(str(XML().br(\'text\')), \'<br>text</br>\')\n\n    def test_para_tag(self):\n        \'generation of a tag with contents\'\n        h = HTML()\n        h.p(\'hello\')\n        self.assertEquals(str(h), \'<p>hello</p>\')\n\n    def test_escape(self):\n        \'escaping of special HTML characters in text\'\n        h = HTML()\n        h.text(\'<>&\')\n        self.assertEquals(str(h), \'&lt;&gt;&amp;\')\n\n    def test_no_escape(self):\n        \'no escaping of special HTML characters in text\'\n        h = HTML()\n        h.text(\'<>&\', False)\n        self.assertEquals(str(h), \'<>&\')\n\n    def test_escape_attr(self):\n        \'escaping of special HTML characters in attributes\'\n        h = HTML()\n        h.br(id=\'<>&""\')\n        self.assertEquals(str(h), \'<br id=""&lt;&gt;&amp;&quot;"">\')\n\n    def test_subtag_context(self):\n        \'generation of sub-tags using ""with"" context\'\n        h = HTML()\n        with h.ol:\n            h.li(\'foo\')\n            h.li(\'bar\')\n        self.assertEquals(str(h), \'<ol>\\n<li>foo</li>\\n<li>bar</li>\\n</ol>\')\n\n    def test_subtag_direct(self):\n        \'generation of sub-tags directly on the parent tag\'\n        h = HTML()\n        l = h.ol\n        l.li(\'foo\')\n        l.li.b(\'bar\')\n        self.assertEquals(str(h),\n            \'<ol>\\n<li>foo</li>\\n<li><b>bar</b></li>\\n</ol>\')\n\n    def test_subtag_direct_context(self):\n        \'generation of sub-tags directly on the parent tag in ""with"" context\'\n        h = HTML()\n        with h.ol as l:\n            l.li(\'foo\')\n            l.li.b(\'bar\')\n        self.assertEquals(str(h),\n            \'<ol>\\n<li>foo</li>\\n<li><b>bar</b></li>\\n</ol>\')\n\n    def test_subtag_no_newlines(self):\n        \'prevent generation of newlines against default\'\n        h = HTML()\n        l = h.ol(newlines=False)\n        l.li(\'foo\')\n        l.li(\'bar\')\n        self.assertEquals(str(h), \'<ol><li>foo</li><li>bar</li></ol>\')\n\n    def test_add_text(self):\n        \'add text to a tag\'\n        h = HTML()\n        p = h.p(\'hello, world!\\n\')\n        p.text(\'more text\')\n        self.assertEquals(str(h), \'<p>hello, world!\\nmore text</p>\')\n\n    def test_add_text_newlines(self):\n        \'add text to a tag with newlines for prettiness\'\n        h = HTML()\n        p = h.p(\'hello, world!\', newlines=True)\n        p.text(\'more text\')\n        self.assertEquals(str(h), \'<p>\\nhello, world!\\nmore text\\n</p>\')\n\n    def test_doc_newlines(self):\n        \'default document adding newlines between tags\'\n        h = HTML()\n        h.br\n        h.br\n        self.assertEquals(str(h), \'<br>\\n<br>\')\n\n    def test_doc_no_newlines(self):\n        \'prevent document adding newlines between tags\'\n        h = HTML(newlines=False)\n        h.br\n        h.br\n        self.assertEquals(str(h), \'<br><br>\')\n\n    def test_unicode(self):\n        \'make sure unicode input works and results in unicode output\'\n        h = HTML(newlines=False)\n        # Python 3 compat\n        try:\n            unicode = unicode\n            TEST = \'euro \\xe2\\x82\\xac\'.decode(\'utf8\')\n        except:\n            unicode = str\n            TEST = \'euro \xe2\x82\xac\'\n        h.p(TEST)\n        self.assertEquals(unicode(h), \'<p>%s</p>\' % TEST)\n\n    def test_table(self):\n        \'multiple ""with"" context blocks\'\n        h = HTML()\n        with h.table(border=\'1\'):\n            for i in range(2):\n                with h.tr:\n                    h.td(\'column 1\')\n                    h.td(\'column 2\')\n        self.assertEquals(str(h), \'\'\'<table border=""1"">\n<tr><td>column 1</td><td>column 2</td></tr>\n<tr><td>column 1</td><td>column 2</td></tr>\n</table>\'\'\')\n\nif __name__ == \'__main__\':\n    unittest.main()\n\n\n# Copyright (c) 2009 eKit.com Inc (http://www.ekit.com/)\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the ""Software""), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n#  The above copyright notice and this permission notice shall be included in\n#  all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n# SOFTWARE.\n\n# vim: set filetype=python ts=4 sw=4 et si\n'"
layers.py,0,"b'import os\nimport numpy as np\n\n#DEBUG = False\n\nclass RangesLayer(object):\n  def __init__(self, width, height):\n\n    focalLength = 517.97\n    urange = np.arange(width).reshape(1, -1).repeat(height, 0) - width * 0.5\n    vrange = np.arange(height).reshape(-1, 1).repeat(width, 1) - height * 0.5\n    self.ranges = np.array([urange / focalLength / width * 640, np.ones(urange.shape), -vrange / focalLength / height * 480]).transpose([1, 2, 0])\n    return\n      \n  def forward(self):\n    return self.ranges\n\n\ndef PlaneDepthLayer(planes, ranges):\n  batchSize = 1\n  if len(planes.shape) == 3:\n    batchSize = planes.shape[0]\n    planes = planes.reshape(planes.shape[0] * planes.shape[1], planes.shape[2])\n    pass\n  \n  planesD = np.linalg.norm(planes, 2, 1)\n  planesD = np.maximum(planesD, 1e-4)\n  planesNormal = -planes / planesD.reshape(-1, 1).repeat(3, 1)\n\n  print(planesD, planesNormal)\n  print(ranges.min(), ranges.max())\n  normalXYZ = np.dot(ranges, planesNormal.transpose())\n  normalXYZ[normalXYZ == 0] = 1e-4\n  normalXYZ = 1 / normalXYZ\n  print(normalXYZ.min(), normalXYZ.max())\n  depths = -normalXYZ\n  depths[:, :] *= planesD\n  if batchSize > 1:\n    depths = depths.reshape(depths.shape[0], depths.shape[1], batchSize, -1).transpose([2, 0, 1, 3])\n    pass\n  depths[(depths < 0) + (depths > 10)] = 10\n  #depths[depths < 0] = 0\n  #depths[depths > 10] = 10\n  return depths\n\n\ndef PlaneNormalLayer(planes, ranges):\n  batchSize = 1\n  if len(planes.shape) == 3:\n    batchSize = planes.shape[0]\n    planes = planes.reshape(planes.shape[0] * planes.shape[1], planes.shape[2])\n    pass\n  planesD = np.linalg.norm(planes, 2, 1)\n  planesD = np.maximum(planesD, 1e-4)\n  planesNormal = -planes / planesD.reshape(-1, 1).repeat(3, 1)\n  normals = planesNormal.reshape(1, 1, -1, 3).repeat(ranges.shape[0], 0).repeat(ranges.shape[1], 1)\n  if batchSize > 1:\n    normals = normals.reshape(normals.shape[0], normals.shape[1], batchSize, -1, 3).transpose([2, 0, 1, 3, 4])\n    pass\n  return normals\n'"
modules.py,564,"b'import tensorflow as tf\nimport numpy as np\nimport os\n\n# def segmentationRefinementModule(segmentation, planeDepths, numOutputPlanes = 20, gpu_id = 0, coef = [1, 1, 1], beta = 10):\n#     with tf.device(\'/gpu:%d\'%gpu_id):\n#         S = segmentation\n#         #S = tf.one_hot(tf.argmax(S, 3), numOutputPlanes)\n#         D = tf.tile(tf.expand_dims(planeDepths, -1), [1, 1, 1, 1, numOutputPlanes])\n#         D_transpose = tf.tile(tf.expand_dims(planeDepths, 3), [1, 1, 1, numOutputPlanes, 1])\n#         D_diff = tf.abs(D - D_transpose)\n#         batchSize = int(segmentation.shape[0])\n#         height = int(segmentation.shape[1])\n#         width = int(segmentation.shape[2])\n#         S_neighbor_up = tf.concat([tf.zeros([batchSize, 1, width, numOutputPlanes]), tf.slice(S, [0, 0, 0, 0], [batchSize, height - 1, width, numOutputPlanes])], axis = 1)\n#         S_neighbor_down = tf.concat([tf.slice(S, [0, 1, 0, 0], [batchSize, height - 1, width, numOutputPlanes]), tf.zeros([batchSize, 1, width, numOutputPlanes]), ], axis = 1)\n#         S_neighbor_left = tf.concat([tf.zeros([batchSize, height, 1, numOutputPlanes]), tf.slice(S, [0, 0, 0, 0], [batchSize, height, width - 1, numOutputPlanes])], axis = 2)\n#         S_neighbor_right = tf.concat([tf.slice(S, [0, 0, 1, 0], [batchSize, height, width - 1, numOutputPlanes]), tf.zeros([batchSize, height, 1, numOutputPlanes]), ], axis = 2)\n#         #S_neighbors = tf.stack([S_neighbor_up, S_neighbor_down, S_neighbor_left, S_neighbor_right], axis = 4)\n#         S_neighbors = (S_neighbor_up + S_neighbor_down + S_neighbor_left + S_neighbor_right) / 4\n#         DS = tf.reduce_sum(tf.multiply(D_diff, tf.expand_dims(S_neighbors, 3)), axis=4)\n#         #test = tf.multiply(D_diff, tf.expand_dims(S_neighbors, 3))\n#         #S_diff = tf.tile(tf.reduce_sum(S_neighbors, axis=3, keep_dims=True), [1, 1, 1, numOutputPlanes]) - S_neighbors\n#         S_diff = tf.ones(S_neighbors.shape) - S_neighbors\n#         pass\n#     P = tf.clip_by_value(S, 1e-4, 1)\n#     DS = tf.clip_by_value(DS / 0.5, 1e-4, 1)\n#     S_diff = tf.clip_by_value(S_diff, 1e-4, 1)\n#     #return tf.nn.softmax(-beta * (-coef[0] * tf.log(P) + coef[1] * tf.log(DS) + coef[2] * tf.log(S_diff))), tf.nn.softmax(tf.log(P)), 1 - tf.clip_by_value(DS / 2, 0, 1), 1 - S_diff, 1 - tf.clip_by_value(tf.multiply(D_diff, tf.expand_dims(S_neighbors, 3)) / 2, 0, 1), S_neighbors, D_diff\n#     return tf.nn.softmax(-beta * (-coef[0] * tf.log(P) + coef[1] * tf.log(DS) + coef[2] * tf.log(S_diff)))\n\ndef planeDepthsModule(plane_parameters, width, height, info):\n    urange = (tf.range(width, dtype=tf.float32) / (width + 1) * (info[16] + 1) - info[2]) / info[0]\n    urange = tf.tile(tf.reshape(urange, [1, -1]), [height, 1])\n    vrange = (tf.range(height, dtype=tf.float32) / (height + 1) * (info[17] + 1) - info[6]) / info[5]\n    vrange = tf.tile(tf.reshape(vrange, [-1, 1]), [1, width])\n            \n    ranges = tf.stack([urange, np.ones([height, width]), -vrange], axis=2)\n    ranges = tf.reshape(ranges, [-1, 3])\n            \n    planesD = tf.norm(plane_parameters, axis=1, keep_dims=True)\n    planesD = tf.clip_by_value(planesD, 1e-5, 10)\n    planesNormal = tf.div(tf.negative(plane_parameters), tf.tile(planesD, [1, 3]))\n\n    normalXYZ = tf.matmul(ranges, planesNormal, transpose_b=True)\n    normalXYZ = tf.multiply(tf.sign(normalXYZ), tf.clip_by_value(tf.abs(normalXYZ), 1e-4, 1000000))\n    normalXYZ = tf.reciprocal(normalXYZ)\n    plane_depths = tf.negative(normalXYZ) * tf.reshape(planesD, [-1])\n    plane_depths = tf.reshape(plane_depths, [height, width, -1])\n\n    plane_depths = tf.clip_by_value(plane_depths, 0, 10)\n    \n    return plane_depths\n\ndef planeNormalsModule(plane_parameters, width, height):\n    planesD = tf.norm(plane_parameters, axis=-1, keep_dims=True)\n    planesD = tf.clip_by_value(planesD, 1e-4, 10)\n    planesNormal = tf.div(tf.negative(plane_parameters), planesD)\n\n    #plane_normals = tf.tile(tf.reshape(planesNormal, [1, 1, -1, 3]), [height, width, 1, 1])\n    #plane_normals = tf.reshape(planesNormal, [1, 1, -1, 3])\n    return planesNormal\n\ndef gaussian(k=5, sig=0):\n    """"""\n    creates gaussian kernel with side length l and a sigma of sig\n    """"""\n    if sig == 0:\n        sig = 0.3 * ((k - 1) * 0.5 - 1) + 0.8\n        pass\n    ax = np.arange(-k // 2 + 1., k // 2 + 1.)\n    xx, yy = np.meshgrid(ax, ax)\n\n    kernel = np.exp(-(xx**2 + yy**2) / (2. * sig**2))\n\n    return kernel / np.sum(kernel)\n\ndef meanfieldModuleLayer(layerSegmentations, planeDepths, numOutputPlanes = 20, numLayers=2, coef = [1, 1, 1], beta = 1, iteration = 0, sigmaDepthDiff = 0.5):\n    batchSize = int(planeSegmentations.shape[0])\n    height = int(planeSegmentations.shape[1])\n    width = int(planeSegmentations.shape[2])\n\n    minDepthDiff = 0.1\n    #P = planeSegmentations\n    #S = tf.one_hot(tf.argmax(planeSegmentations, 3), depth=numOutputPlanes)\n    kernel_size = 9\n    neighbor_kernel_array = gaussian(kernel_size)\n    neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n    neighbor_kernel_array /= neighbor_kernel_array.sum()\n    neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n    neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n\n\n    layerDepths = []\n    layerSs = []\n    for layer in xrange(numLayers):\n        S = tf.one_hot(tf.argmax(planeSegmentations, 3), depth=numOutputPlanes)\n        layerDepth = tf.reduce_sum(planeDepths * S, 3, keep_dims=True)\n        layerSs.append(S)\n        layerDepths.append(layerDepth)\n\n    DSs = []\n    conflictDs = []\n    conflictDepthThreshold = 0.1\n    \n    for layer in xrange(numLayers):        \n        DS_diff = tf.exp(-tf.pow(1 - tf.clip_by_value(tf.abs(planeDepths - layerDepths[layer]), 0, 1), 2) / sigmaDepthDiff) - tf.exp(-1 / sigmaDepthDiff) * layerSs[layer]\n        DS = tf.nn.depthwise_conv2d(DS_diff, tf.tile(neighbor_kernel, [1, 1, numOutputPlanes, 1]), strides=[1, 1, 1, 1], padding=\'SAME\')\n        DSs.append(DS)\n        \n        conflictD = tf.zeros((batchSize, height, width, 1))\n        if layer > 0:\n            minDepth = tf.min(tf.concat(layerDepths[:layer - 1], axis=3), axis=3, keep_dims=True)\n            conflictD = tf.maximum(conflictD, layerDepths[layer] - minDepth)\n            pass\n        if layer < numLayers - 1:\n            maxDepth = tf.max(tf.concat(layerDepths[layer + 1:], axis=3), axis=3, keep_dims=True)\n            conflictD = tf.maximum(conflictD, maxDepth -  layerDepths[layer])\n            pass\n        conflictDs.append(tf.cast(conflictD > conflictDepthThreshold, tf.float32))\n\n        \n    P = tf.clip_by_value(P, 1e-4, 1)\n    confidence = P * tf.exp(-coef[1] * DS)\n    refined_segmentation = tf.nn.softmax(tf.log(confidence))\n    return refined_segmentation\n\ndef calcImageDiff(images, kernel_size = 9):\n    neighbor_kernel_array = gaussian(kernel_size)\n    neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n    neighbor_kernel_array /= neighbor_kernel_array.sum()\n    neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = -1\n    neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n    neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n\n    image_diff = tf.nn.depthwise_conv2d(images, tf.tile(neighbor_kernel, [1, 1, 3, 1]), strides=[1, 1, 1, 1], padding=\'SAME\')\n    image_diff = tf.pow(image_diff, 2)\n    image_diff = tf.reduce_sum(image_diff, axis=3, keep_dims=True)\n    var_image_diff =  tf.reduce_mean(image_diff, axis=[1, 2, 3], keep_dims=True)\n    #image_diff = image_diff\n    #image_diff = tf.exp(-image_diff)\n    #image_diff = tf.nn.max_pool(image_diff, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\')\n    return image_diff, var_image_diff\n    \ndef meanfieldModule(planeSegmentations, planeDepths, planesY, imageDiff, numOutputPlanes = 20, coef = [1, 1, 1], beta = 1, iteration = 0, maxDepthDiff = 0.2, varDepthDiff = 0.5, kernel_size = 9):\n    batchSize = int(planeSegmentations.shape[0])\n    height = int(planeSegmentations.shape[1])\n    width = int(planeSegmentations.shape[2])\n\n    P = planeSegmentations\n\n\n    #minDepthDiff = 0.1\n    #normalDotThreshold = np.cos(np.deg2rad(30))\n    #N_diff = tf.matmul(planeNormals, planeNormals, transpose_b=True)\n    #N_diff_mask = tf.cast((N_diff < normalDotThreshold), tf.float) + tf.diag(tf.ones(numOutputPlanes))\n    #N_diff = tf.clip(N_diff, minDepthDiff, 1)\n    #N_diff_mask = tf.expand_dims(tf.expand_dims(N_diff_mask, 1), 1)\n\n    #D_diff = (D_diff - minDepthDiff) * N_diff_mask + minDepthDiff\n\n\n    #confidenceThreshold = 0.00\n    #P_truncated = P * (P >= confidenceThreshold).astype(tf.float)\n    S = tf.one_hot(tf.argmax(planeSegmentations, 3), depth=numOutputPlanes)\n\n    # D = tf.tile(tf.expand_dims(planeDepths, -1), [1, 1, 1, 1, numOutputPlanes])\n    # D_transpose = tf.tile(tf.expand_dims(planeDepths, 3), [1, 1, 1, numOutputPlanes, 1])\n    # D_diff = tf.abs(D - D_transpose)\n    # DS_weight = tf.exp(-tf.pow(tf.clip_by_value(1 - D_diff / maxDepthDiff, 0, 1), 2) / sigmaDepthDiff)\n    # DS_diff = tf.reduce_sum(DS_weight * tf.expand_dims(S, 3), axis=4) - tf.exp(-1 / sigmaDepthDiff) * S\n\n    \n    \n    \n    depthWeight = 50.0\n    colorWeight = 50.0\n    normalY = tf.reduce_sum(S * tf.reshape(planesY, [-1, 1, 1, numOutputPlanes]), axis=3, keep_dims=True)\n    depth_diff = (planeDepths - tf.reduce_sum(planeDepths * S, 3, keep_dims=True)) * normalY\n    depth_diff = tf.concat([depth_diff[:, :, :, :numOutputPlanes - 1], (1 - S[:, :, :, numOutputPlanes - 1:numOutputPlanes])], axis=3)\n    DS_diff = (1 - tf.exp(-tf.pow(tf.minimum(depth_diff, maxDepthDiff), 2) / varDepthDiff)) + (1 - S) * (1 / depthWeight + (colorWeight / depthWeight) * imageDiff)\n\n\n    #DS_diff = tf.exp(-tf.pow(1 - tf.clip_by_value(tf.abs(planeDepths - tf.reduce_sum(planeDepths * S, 3, keep_dims=True)), 0, 1), 2) / 0.5) - tf.exp(-1 / 0.5) * S\n\n    neighbor_kernel_array = gaussian(kernel_size)\n    neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n    neighbor_kernel_array /= neighbor_kernel_array.sum()\n    neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n    neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n    \n    DS = tf.nn.depthwise_conv2d(DS_diff, tf.tile(neighbor_kernel, [1, 1, numOutputPlanes, 1]), strides=[1, 1, 1, 1], padding=\'SAME\')\n    \n\n    P = tf.clip_by_value(P, 1e-4, 1)\n    confidence = P * tf.exp(-coef[1] * DS)\n    #confidence = coef[0] * P + tf.exp(-coef[1] * DS) + tf.exp(-coef[2] * S_diff)\n    #confidence[:, :, :, numOutputPlanes] = 1e-4\n    #confidence = tf.clip(confidence, 1e-4, 1)\n    refined_segmentation = tf.nn.softmax(tf.log(confidence))\n    return refined_segmentation, {\'diff\': DS}\n\n\ndef segmentationRefinementModule(planeSegmentations, planeDepths, planesY, imageDiff, numOutputPlanes = 20, numIterations=20, kernel_size = 9):\n\n    # kernel_size = 9\n    # neighbor_kernel_array = gaussian(kernel_size)\n    # neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n    # neighbor_kernel_array /= neighbor_kernel_array.sum()\n    # neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = -1\n    # neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n    # neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n\n    #maxDepthDiff = tf.Variable(0.3)\n    #sigmaDepthDiff = tf.Variable(0.5)\n    maxDepthDiff = 0.2\n    varDepthDiff = pow(0.2, 2)\n    \n    \n    refined_segmentation = planeSegmentations\n    for _ in xrange(numIterations):\n        refined_segmentation, _ = meanfieldModule(refined_segmentation, planeDepths, planesY, imageDiff, numOutputPlanes=numOutputPlanes, maxDepthDiff=maxDepthDiff, varDepthDiff=varDepthDiff, kernel_size = kernel_size)\n        continue\n    return refined_segmentation, {}\n\n\ndef meanfieldModuleBoundary(planeSegmentations, originalSegmentations, planeDepths, occlusionBoundary = 0, smoothBoundary = 0, numOutputPlanes = 20, coef = [1, 10, 1], beta = 1, iteration = 0, sigmaDepthDiff = 0.5):\n    batchSize = int(planeSegmentations.shape[0])\n    height = int(planeSegmentations.shape[1])\n    width = int(planeSegmentations.shape[2])\n\n    #S = tf.one_hot(tf.argmax(planeSegmentations, 3), depth=numOutputPlanes)\n    #D_diff = tf.clip_by_value(tf.abs(planeDepths - tf.reduce_sum(planeDepths * S, 3, keep_dims=True)), 0, 1) * smoothBoundary + tf.clip_by_value(1 - smoothBoundary - occlusionBoundary, 0, 1)\n    #DS_diff = tf.exp(-tf.pow(1 - D_diff, 2) / sigmaDepthDiff) - tf.exp(-1 / sigmaDepthDiff) * S\n    #DS_diff = DS_diff * smoothBoundary + (tf.exp(-1 / sigmaDepthDiff) * occlusionBoundary + tf.clip_by_value(1 - smoothBoundary - occlusionBoundary, 0, 1)) * (1 - S)\n\n    maxDepthDiff = 0.5\n    S = planeSegmentations\n    D_diff = tf.abs(planeDepths - tf.reduce_sum(planeDepths * S, 3, keep_dims=True))\n    DS_diff = tf.clip_by_value(D_diff / maxDepthDiff, 0, 1)\n    DS_diff = DS_diff * (1 - occlusionBoundary)\n    #+ (1 - S) * occlusionBoundary * 0.1\n    \n    kernel_size = 5\n    neighbor_kernel_array = gaussian(kernel_size)\n    neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n    neighbor_kernel_array /= neighbor_kernel_array.sum()\n    neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n    neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n\n    DS = tf.nn.depthwise_conv2d(DS_diff, tf.tile(neighbor_kernel, [1, 1, numOutputPlanes, 1]), strides=[1, 1, 1, 1], padding=\'VALID\')\n    padding = (kernel_size - 1) / 2\n    DS = tf.pad(DS, paddings = [[0, 0], [padding, padding], [padding, padding], [0, 0]])\n    \n    P = originalSegmentations\n    P = tf.clip_by_value(P, 1e-4, 1)\n    confidence = P * tf.exp(-coef[1] * DS)\n    #confidence = coef[0] * P + tf.exp(-coef[1] * DS) + tf.exp(-coef[2] * S_diff)\n    #confidence[:, :, :, numOutputPlanes] = 1e-4\n    #confidence = tf.clip(confidence, 1e-4, 1)\n    refined_segmentation = tf.nn.softmax(tf.log(confidence))\n    return refined_segmentation\n\n\ndef segmentationRefinementModuleBoundary(planeSegmentations, planeDepths, occlusionBoundary = 0, smoothBoundary = 0, numOutputPlanes = 20, numIterations=20):\n    #maxDepthDiff = tf.Variable(0.3)\n    #sigmaDepthDiff = tf.Variable(0.5)\n    maxDepthDiff = 0.3\n    sigmaDepthDiff = 0.5\n\n    refined_segmentation = planeSegmentations\n\n    #occlusionBoundary = tf.slice(boundaries, [0, 0, 0, 1], [boundaries.shape[0], boundaries.shape[1], boundaries.shape[2], 1])\n    #smoothBoundary = tf.slice(boundaries, [0, 0, 0, 2], [boundaries.shape[0], boundaries.shape[1], boundaries.shape[2], 1])\n    for _ in xrange(numIterations):\n        refined_segmentation = meanfieldModuleBoundary(refined_segmentation, planeSegmentations, planeDepths, occlusionBoundary=occlusionBoundary, smoothBoundary=smoothBoundary, numOutputPlanes=numOutputPlanes, sigmaDepthDiff=sigmaDepthDiff)\n        continue\n    return refined_segmentation\n\n\ndef planeMapModule(depth, normal, ranges):\n    #ranges = tf.reshape(ranges, [-1, 3])\n\n    planes = tf.reduce_sum(normal * ranges, 3, keep_dims=True) * depth * normal\n    return planes\n    \n# def planeFittingModule(depth, normal, numPlanes=50, numGlobalPlanes=20, planeAreaThreshold=3*4):\n#     width = int(depth.shape[2])\n#     height = int(depth.shape[1])\n\n#     focalLength = 517.97\n#     urange = (tf.range(width, dtype=tf.float32) / (width + 1) - 0.5) / focalLength * 641\n#     urange = tf.tile(tf.reshape(urange, [1, -1]), [height, 1])\n#     vrange = (tf.range(height, dtype=tf.float32) / (height + 1) - 0.5) / focalLength * 481\n#     vrange = tf.tile(tf.reshape(vrange, [-1, 1]), [1, width])\n            \n#     ranges = tf.stack([urange, tf.ones([height, width]), -vrange], axis=2)\n#     ranges = tf.expand_dims(ranges, 0)\n\n#     batchSize = int(depth.shape[0])\n#     planeDiffThreshold = 0.1\n#     #plane parameter for each pixel\n#     planeMap = planeMapModule(depth, normal, ranges)\n    \n#     kernel_size = 3\n#     neighbor_kernel_array = gaussian(kernel_size)\n#     neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n#     neighbor_kernel_array /= neighbor_kernel_array.sum()\n#     neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n#     neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n#     #smoothedPlaneMap = tf.nn.depthwise_conv2d(planeMap, tf.tile(neighbor_kernel, [1, 1, 3, 1]), strides=[1, 1, 1, 1], padding=\'SAME\')\n#     median_kernel_array = np.zeros((3, 3, 1, 9))\n#     for index in xrange(9):\n#         median_kernel_array[index / 3, index % 3, 0, index] = 1\n#         continue\n#     median_kernel = tf.constant(median_kernel_array.reshape(-1), shape=median_kernel_array.shape, dtype=tf.float32)\n#     smoothedPlaneMap = tf.nn.depthwise_conv2d(planeMap, tf.tile(median_kernel, [1, 1, 3, 1]), strides=[1, 1, 1, 1], padding=\'SAME\')\n#     smoothedPlaneMap, _ = tf.nn.top_k(tf.reshape(smoothedPlaneMap, [batchSize, height, width, 3, 9]), k=5)\n#     planeMap = tf.squeeze(tf.slice(smoothedPlaneMap, [0, 0, 0, 0, 4], [batchSize, height, width, 3, 1]), axis=4)\n\n#     #planeDiff = tf.norm(planeMap - tf.nn.depthwise_conv2d(planeMap, tf.tile(neighbor_kernel, [1, 1, 3, 1]), strides=[1, 1, 1, 1], padding=\'SAME\'), axis=3, keep_dims=True)\n#     smoothedPlaneMap = tf.nn.depthwise_conv2d(planeMap, tf.tile(median_kernel, [1, 1, 3, 1]), strides=[1, 1, 1, 1], padding=\'SAME\')\n#     planeDiff = tf.reduce_max(tf.norm(tf.expand_dims(planeMap, -1) - tf.reshape(smoothedPlaneMap, [batchSize, height, width, 3, 9]), axis=3, keep_dims=True), axis=4)\n#     boundaryMask = tf.cast(tf.less(planeDiff, planeDiffThreshold), tf.float32)\n    \n#     #opening\n#     erosionKernel = np.array([[-1, 0, -1], [0, 0, 0], [-1, 0, -1]], dtype=np.float32).reshape([3, 3, 1])\n#     dilationKernel = np.array([[-1, 0, -1], [0, 0, 0], [-1, 0, -1]], dtype=np.float32).reshape([3, 3, 1])\n#     boundaryMask = tf.nn.erosion2d(boundaryMask, kernel=erosionKernel, strides=[1, 1, 1, 1], rates=[1, 1, 1, 1], padding=\'SAME\')\n    \n#     #region indices\n#     assignment = tf.reshape(tf.range(batchSize * height * width, dtype=tf.float32) + 1, [batchSize, height, width, 1]) * boundaryMask\n#     with tf.variable_scope(""flooding"") as scope:\n#         scope.reuse_variables()\n#         for _ in xrange(width / 2):\n#             assignment = tf.nn.max_pool(assignment, ksize=[1, 5, 5, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\') * boundaryMask\n#             continue\n#         pass\n#     #inds, mask, count = tf.unique_with_counts(tf.concat([tf.constant(0, shape=[1], dtype=tf.float32), tf.reshape(assignment, [-1])], axis=0))\n#     #ignoredInds = tf.range(count.shape, dtype=tf.float32) * tf.less(count, planeAreaThreshold)\n#     assignment = tf.reshape(assignment, [-1])\n    \n#     #find unique regions\n#     inds, mask, count = tf.unique_with_counts(assignment)\n#     ignoredInds = tf.boolean_mask(inds, tf.less(count, planeAreaThreshold))\n#     assignment = assignment * (1 - tf.reduce_max(tf.cast(tf.equal(tf.expand_dims(assignment, -1), tf.expand_dims(ignoredInds, 0)), tf.float32), axis=1))\n#     inds, mask, count = tf.unique_with_counts(tf.concat([tf.constant(0, shape=[1], dtype=tf.float32), assignment], axis=0))\n        \n#     mask = tf.slice(mask, [1], [batchSize * height * width])\n#     mask = tf.reshape(mask, [batchSize, height, width, 1])\n#     #inds = tf.boolean_mask(inds, tf.greater(count, width * height / (16 * 16)))\n#     batchInds = tf.equal(tf.cast(tf.tile(tf.reshape(inds - 1, [1, -1]), [batchSize, 1]), tf.int32) / (width * height), tf.expand_dims(tf.range(batchSize), -1))\n#     counts = tf.count_nonzero(batchInds, axis=1)\n#     counts = tf.concat([tf.constant([1], dtype=tf.int64), counts], axis=0)\n#     counts = tf.slice(tf.cumsum(counts), [0], [batchSize])\n#     batchPlaneInds = tf.reshape(tf.range(numPlanes), [1, -1]) + tf.cast(tf.reshape(counts, [-1, 1]), tf.int32)\n#     #batchPlaneInds = tf.tile(tf.reshape(tf.range(numPlanes, dtype=tf.int32) + 1, [1, 1, 1, -1]), [batchSize, 1, 1, 1])\n#     planeMasks = tf.cast(tf.equal(mask, tf.reshape(batchPlaneInds, [batchSize, 1, 1, numPlanes])), tf.float32)\n\n#     planeMasks_test = planeMasks\n\n\n#     planeAreas = tf.clip_by_value(tf.reduce_sum(planeMasks, axis=[1, 2]), 1e-4, width * height)\n#     #planeAreas, sortInds = tf.nn.top_k(planeAreas, k=numPlanes)\n#     #sortMap = tf.one_hot(sortInds, depth=numPlanes, axis=1)\n#     #planeMasks = tf.reshape(tf.matmul(tf.reshape(planeMasks, [-1, height * width, numPlanes]), sortMap), [-1, height, width, numPlanes])\n\n#     #fit plane based on mask\n#     planesNormal = tf.reduce_sum(tf.expand_dims(normal, 3) * tf.expand_dims(planeMasks, -1), axis=[1, 2]) / tf.expand_dims(planeAreas, -1)\n#     planesNormal = tf.nn.l2_normalize(planesNormal, 2)\n\n#     weightedABC = tf.transpose(tf.reshape(tf.matmul(tf.reshape(ranges, [-1, 3]), tf.reshape(planesNormal, [-1, 3]), transpose_b=True), [height, width, batchSize, numPlanes]), [2, 0, 1, 3])\n#     planesD = tf.reduce_sum(weightedABC * depth * planeMasks, axis=[1, 2]) / planeAreas\n#     planesD = tf.expand_dims(planesD, -1)\n#     planes = planesNormal * planesD\n    \n#     #globalPlanes = tf.slice(planes, [0, 0, 0], [batchSize, numGlobalPlanes, 3])\n#     #planes = tf.transpose(tf.matmul(planes, sortMap, transpose_a=True), [0, 2, 1])\n#     #planesNormal = tf.slice(planesNormal, [0, 0, 0], [batchSize, numGlobalPlanes, 3])\n#     #planesD = tf.slice(planesD, [0, 0, 0], [batchSize, numGlobalPlanes, 1])\n\n#     normalDotThreshold = np.cos(np.deg2rad(5))\n#     distanceThreshold = 0.05\n#     X = depth * tf.expand_dims(urange, -1)\n#     Y = depth\n#     Z = -depth * tf.expand_dims(vrange, -1)\n#     XYZ = tf.concat([X, Y, Z], axis=3)\n#     XYZ = tf.reshape(XYZ, [-1, height * width, 3])\n    \n#     planesNormal = -planesNormal\n#     distance = tf.reshape(tf.abs(tf.matmul(XYZ, planesNormal, transpose_b=True) + tf.reshape(planesD, [-1, 1, numPlanes])), [-1, height, width, numPlanes])\n#     angle = tf.reshape(tf.abs(tf.matmul(tf.reshape(normal, [-1, height * width, 3]), planesNormal, transpose_b=True)), [-1, height, width, numPlanes])\n\n#     explainedPlaneMasks = tf.cast(tf.logical_and(tf.greater(angle, normalDotThreshold), tf.less(distance, distanceThreshold)), tf.float32)\n#     explainedPlaneMasks = tf.nn.dilation2d(explainedPlaneMasks, filter=np.tile(dilationKernel, [1, 1, numPlanes]), strides=[1, 1, 1, 1], rates=[1, 1, 1, 1], padding=\'SAME\')\n#     explainedPlaneMasks = tf.nn.erosion2d(explainedPlaneMasks, kernel=np.tile(erosionKernel, [1, 1, numPlanes]), strides=[1, 1, 1, 1], rates=[1, 1, 1, 1], padding=\'SAME\')    \n\n#     with tf.variable_scope(""expansion"") as scope:\n#         scope.reuse_variables()\n#         for _ in xrange(width / 6):\n#             planeMasks = tf.nn.max_pool(planeMasks, ksize=[1, 13, 13, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\') * explainedPlaneMasks\n#             continue\n#         pass\n        \n#     planeAreas = tf.reduce_sum(planeMasks, axis=[1, 2])\n#     planeAreas, sortInds = tf.nn.top_k(planeAreas, k=numPlanes)\n#     sortMap = tf.one_hot(sortInds, depth=numPlanes, axis=1)\n#     planeMasks = tf.reshape(tf.matmul(tf.reshape(planeMasks, [-1, height * width, numPlanes]), sortMap), [-1, height, width, numPlanes])\n#     planes = tf.transpose(tf.matmul(planes, sortMap, transpose_a=True), [0, 2, 1])\n\n#     #remove duplicate planes by expanding each plane mask, if two masks coincide, remove one of them\n#     substractionMatrix = -tf.cast(tf.less(tf.reshape(tf.range(numPlanes), [-1, 1]), tf.reshape(tf.range(numPlanes), [1, -1])), tf.float32) + tf.eye(numPlanes)\n#     substractionMatrix = tf.tile(tf.expand_dims(substractionMatrix, 0), [batchSize, 1, 1])\n#     planeMasks = tf.clip_by_value(tf.reshape(tf.matmul(tf.reshape(planeMasks, [-1, height * width, numPlanes]), substractionMatrix), [-1, height, width, numPlanes]), 0, 1)\n\n\n#     planeMasksWithoutBoundary = planeMasks * boundaryMask\n#     planeAreas = tf.reduce_sum(planeMasksWithoutBoundary, axis=[1, 2])\n#     maxMeanDepthThreshold = 10\n#     planeAreas = tf.clip_by_value(planeAreas, 1e-4, width * height)\n#     #validPlaneMask = tf.cast(tf.logical_and(tf.logical_or(tf.greater(planeAreas, planeAreaThreshold), tf.equal(tf.argmax(np.abs(planes), 2), 2)), tf.less(tf.reduce_sum(planeMasksWithoutBoundary * depth, axis=[1, 2]) / planeAreas, maxMeanDepthThreshold)), tf.float32)\n#     #validPlaneMask = tf.cast(tf.equal(tf.argmax(np.abs(planes), 2), 2), tf.float32)\n#     #planeAreas, sortInds = tf.nn.top_k(planeAreas, k=numPlanes)\n#     #sortMap = tf.one_hot(sortInds, depth=numPlanes, axis=1)\n#     #planeMasks = tf.reshape(tf.matmul(tf.reshape(planeMasks, [-1, height * width, numPlanes]), sortMap), [-1, height, width, numPlanes])\n\n#     if False:\n#         planes = tf.transpose(tf.matmul(planes, sortMap, transpose_a=True), [0, 2, 1])\n#     else:\n#         #fit planes based on merged masks\n#         planesNormal = tf.reduce_sum(tf.expand_dims(normal, 3) * tf.expand_dims(planeMasksWithoutBoundary, -1), axis=[1, 2]) / tf.expand_dims(planeAreas, -1)\n#         planesNormal = tf.nn.l2_normalize(planesNormal, 2)\n\n#         weightedABC = tf.transpose(tf.reshape(tf.matmul(tf.reshape(ranges, [-1, 3]), tf.reshape(planesNormal, [-1, 3]), transpose_b=True), [height, width, batchSize, numPlanes]), [2, 0, 1, 3])\n#         planesD = tf.reduce_sum(weightedABC * depth * planeMasksWithoutBoundary, axis=[1, 2]) / planeAreas\n#         planesD = tf.expand_dims(planesD, -1)\n#         planes = planesNormal * planesD\n#         pass\n\n#     validPlaneMask = tf.cast(tf.less(tf.reduce_sum(planeMasksWithoutBoundary * depth, axis=[1, 2]) / planeAreas, maxMeanDepthThreshold), tf.float32)\n#     planeMasks = planeMasks * tf.expand_dims(tf.expand_dims(validPlaneMask, 1), 1)\n#     planes = planes * tf.expand_dims(validPlaneMask, -1)\n#     planeAreas = planeAreas * validPlaneMask\n            \n\n#     # planeAreas = tf.reduce_sum(localPlaneMasks, axis=[1, 2])\n#     # planeAreas, sortInds = tf.nn.top_k(planeAreas, k=numPlanes)\n#     # sortMap = tf.one_hot(sortInds, depth=numPlanes, axis=1)\n#     # localPlaneMasks = tf.reshape(tf.matmul(tf.reshape(localPlaneMasks, [-1, height * width, numPlanes]), sortMap), [-1, height, width, numPlanes])\n#     # localPlanes = tf.transpose(tf.matmul(localPlanes, sortMap, transpose_a=True), [0, 2, 1])\n\n#     # substractionMatrix = -tf.cast(tf.less(tf.reshape(tf.range(numPlanes), [-1, 1]), tf.reshape(tf.range(numPlanes), [1, -1])), tf.float32) + tf.eye(numPlanes)\n#     # substractionMatrix = tf.tile(tf.expand_dims(substractionMatrix, 0), [batchSize, 1, 1])\n#     # localPlaneMasks = tf.clip_by_value(tf.reshape(tf.matmul(tf.reshape(localPlaneMasks, [-1, height * width, numPlanes]), substractionMatrix), [-1, height, width, numPlanes]), 0, 1)\n\n\n#     # planeMasksWithoutBoundary = localPlaneMasks * boundaryMask\n#     # planeAreas = tf.reduce_sum(planeMasksWithoutBoundary, axis=[1, 2])\n#     # maxMeanDepthThreshold = 10\n#     # #validPlaneMask = tf.cast(tf.logical_and(tf.logical_or(tf.greater(planeAreas, planeAreaThreshold), tf.equal(tf.argmax(np.abs(planes), 2), 2)), tf.less(tf.reduce_sum(planeMasksWithoutBoundary * depth, axis=[1, 2]) / planeAreas, maxMeanDepthThreshold)), tf.float32)\n#     # #validPlaneMask = tf.cast(tf.equal(tf.argmax(np.abs(planes), 2), 2), tf.float32)\n#     # validPlaneMask = tf.cast(tf.less(tf.reduce_sum(planeMasksWithoutBoundary * depth, axis=[1, 2]) / planeAreas, maxMeanDepthThreshold), tf.float32)\n#     # localPlanes = localPlanes * tf.expand_dims(validPlaneMask, -1)\n#     # localPlaneMasks = localPlaneMasks * tf.expand_dims(tf.expand_dims(validPlaneMask, 1), 1)\n#     # planeAreas = planeAreas * validPlaneMask\n#     # planeAreas, sortInds = tf.nn.top_k(planeAreas, k=numPlanes)\n#     # sortMap = tf.one_hot(sortInds, depth=numPlanes, axis=1)\n#     # localPlaneMasks = tf.reshape(tf.matmul(tf.reshape(localPlaneMasks, [-1, height * width, numPlanes]), sortMap), [-1, height, width, numPlanes])\n\n#     # planeMasksWithoutBoundary = localPlaneMasks * boundaryMask\n#     # planeAreas = tf.clip_by_value(planeAreas, 1e-4, width * height)\n#     # planesNormal = tf.reduce_sum(tf.expand_dims(normal, 3) * tf.expand_dims(planeMasksWithoutBoundary, -1), axis=[1, 2]) / tf.expand_dims(planeAreas, -1)\n#     # planesNormal = tf.nn.l2_normalize(planesNormal, 2)\n\n#     # weightedABC = tf.transpose(tf.reshape(tf.matmul(tf.reshape(ranges, [-1, 3]), tf.reshape(planesNormal, [-1, 3]), transpose_b=True), [height, width, batchSize, numPlanes]), [2, 0, 1, 3])\n#     # planesD = tf.reduce_sum(weightedABC * depth * planeMasksWithoutBoundary, axis=[1, 2]) / planeAreas\n#     # planesD = tf.expand_dims(planesD, -1)\n#     # localPlanes = planesNormal * planesD\n    \n\n#     #find local ground truth\n#     urange = tf.reshape(tf.range(width, dtype=tf.float32), [1, -1, 1])\n#     planeXs = tf.reduce_max(planeMasks, axis=1)\n#     planeMinX = width - tf.reduce_max(planeXs * (float(width) - urange), axis=1)\n#     planeMaxX = tf.reduce_max(planeXs * urange, axis=1)\n\n#     vrange = tf.reshape(tf.range(height, dtype=tf.float32), [1, -1, 1])\n#     planeYs = tf.reduce_max(planeMasks, axis=2)\n#     planeMinY = height - tf.reduce_max(planeYs * (float(height) - vrange), axis=1)\n#     planeMaxY = tf.reduce_max(planeYs * vrange, axis=1)\n\n#     planeBoxes = tf.stack([planeMinX, planeMaxX, planeMinY, planeMaxY], axis=2)\n\n#     localPlaneWidthThreshold = 64\n#     localPlaneHeightThreshold = 64\n#     globalPlaneAreaThreshold = 16 * 16\n#     globalPlaneWidthThreshold = 8\n    \n#     globalPlaneMask = tf.logical_or(tf.greater(planeMaxX - planeMinX, localPlaneWidthThreshold), tf.greater(planeMaxY - planeMinY, localPlaneHeightThreshold))\n#     globalPlaneMask = tf.logical_and(globalPlaneMask, tf.greater((planeMaxX - planeMinX) * (planeMaxY - planeMinY), globalPlaneAreaThreshold))\n#     globalPlaneMask = tf.logical_and(globalPlaneMask, tf.greater(planeAreas / (planeMaxY + 1 - planeMinY), globalPlaneWidthThreshold))\n#     #globalPlaneMask = tf.cast(tf.squeeze(globalPlaneMask, axis=[2]), tf.float32)\n#     globalPlaneMask = tf.cast(globalPlaneMask, tf.float32)\n#     weightedPlaneAreas = globalPlaneMask * (planeAreas + height * width) + (1 - globalPlaneMask) * planeAreas\n#     planeAreas, sortInds = tf.nn.top_k(weightedPlaneAreas, k=numPlanes)\n#     sortMap = tf.one_hot(sortInds, depth=numPlanes, axis=1)\n#     planeMasks = tf.reshape(tf.matmul(tf.reshape(planeMasks, [-1, height * width, numPlanes]), sortMap), [-1, height, width, numPlanes])\n#     planes = tf.transpose(tf.matmul(planes, sortMap, transpose_a=True), [0, 2, 1])\n#     planeBoxes = tf.transpose(tf.matmul(planeBoxes, sortMap, transpose_a=True), [0, 2, 1])\n#     globalPlaneMask = tf.squeeze(tf.matmul(tf.expand_dims(globalPlaneMask, 1), sortMap), axis=1)\n    \n\n\n#     #boundary ground truth\n#     boundary = tf.nn.max_pool(planeMasks, ksize=[1, 5, 5, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n    \n#     boundaryType = tf.cast(tf.round(tf.reduce_sum(boundary, axis=3, keep_dims=True)), tf.int32)\n#     singleBoundary = tf.cast(tf.equal(tf.reduce_sum(boundary - planeMasks, axis=3, keep_dims=True), 1), tf.float32)\n\n#     commonBoundary = tf.cast(tf.equal(boundaryType, 2), tf.float32)\n#     #boundary = boundary * commonBoundary\n#     boundaryCoef = tf.cast(tf.round(tf.cumsum(boundary, axis=3)), tf.float32)\n\n#     #boundary_1 = tf.cast(tf.equal(boundaryCoef, 1), tf.float32) * boundary\n#     #boundary_1 = tf.cast(tf.equal(boundaryCoef, 1), tf.float32) * boundary\n    \n#     boundaryPlane_1 = tf.reshape(tf.matmul(tf.reshape(tf.cast(tf.equal(boundaryCoef, 1), tf.float32) * boundary, [batchSize, height * width, numPlanes]), planes), [batchSize, height, width, 3])\n#     boundaryD_1 = tf.maximum(tf.norm(boundaryPlane_1, axis=3, keep_dims=True), 1e-4)\n#     boundaryNormal_1 = boundaryPlane_1 / boundaryD_1\n#     boundaryDepth_1 = boundaryD_1 / tf.maximum(tf.reduce_sum(boundaryNormal_1 * ranges, axis=3, keep_dims=True), 1e-4)\n\n#     boundaryPlane_2 = tf.reshape(tf.matmul(tf.reshape(tf.cast(tf.equal(boundaryCoef, 2), tf.float32) * boundary, [batchSize, height * width, numPlanes]), planes), [batchSize, height, width, 3])\n#     boundaryD_2 = tf.maximum(tf.norm(boundaryPlane_2, axis=3, keep_dims=True), 1e-4)\n#     boundaryNormal_2 = boundaryPlane_2 / boundaryD_2\n#     boundaryDepth_2 = boundaryD_2 / tf.maximum(tf.reduce_sum(boundaryNormal_2 * ranges, axis=3, keep_dims=True), 1e-4)\n\n#     depthDiffThreshold = 0.05\n#     #occlusionBoundary = tf.cast(tf.greater(tf.abs(boundaryDepth_1 - boundaryDepth_2), depthDiffThreshold), tf.float32) * commonBoundary\n#     largerMask = tf.nn.max_pool(tf.cast(tf.greater_equal(boundaryDepth_1, boundaryDepth_2), tf.float32) * commonBoundary, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\')\n#     smallerMask = tf.nn.max_pool(tf.cast(tf.less_equal(boundaryDepth_1, boundaryDepth_2), tf.float32) * commonBoundary, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\')\n#     smoothBoundary = tf.nn.max_pool(largerMask * smallerMask, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\')\n#     #depthDiff = tf.abs(depth - tf.nn.depthwise_conv2d(depth, neighbor_kernel, strides=[1, 1, 1, 1], padding=\'SAME\'))\n#     #occlusionBoundary = tf.cast(tf.greater(depthDiff, depthDiffThreshold), tf.float32) * commonBoundary\n    \n#     #boundaryConvexity = tf.cast(tf.less(tf.reduce_sum(boundaryNormal_1 * boundaryNormal_2, axis=3, keep_dims=True), 0), tf.float32)\n#     #convexBoundary = smoothBoundary * boundaryConvexity\n#     #concaveBoundary = smoothBoundary * (1 - boundaryConvexity)\n\n    \n#     occlusionBoundary = commonBoundary - smoothBoundary\n\n#     singleBoundary = tf.maximum(singleBoundary - tf.nn.max_pool(commonBoundary, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\'), 0)\n#     boundaries = tf.concat([singleBoundary, occlusionBoundary, smoothBoundary], axis=3)\n#     #boundaries = tf.concat([tf.maximum(tf.minimum((boundaryDepth_1 - boundaryDepth_2) + 0.5, 1), 0)], axis=3)\n#     #boundaries = tf.concat([tf.maximum(tf.minimum(boundaryDepth_1 / 10, 1), 0), tf.maximum(tf.minimum(boundaryDepth_2 / 10, 1), 0), tf.maximum(tf.minimum((boundaryDepth_1 - boundaryDepth_2) + 0.5, 1), 0)], axis=3)\n#     boundaries = 1 - tf.nn.max_pool(1 - boundaries, ksize=[1, 2, 2, 1], strides=[1, 1, 1, 1], padding=\'SAME\')\n    \n#     if True:\n#         coef = tf.pow(tf.constant(2, dtype=tf.float64), tf.range(numPlanes, dtype=tf.float64))\n#         planeMask = tf.cast(tf.round(tf.tensordot(tf.cast(planeMasks, tf.float64), coef, axes=[[3], [0]])), tf.int64)\n#         #localPlaneMask = tf.cast(tf.round(tf.tensordot(tf.cast(localPlaneMasks, tf.float64), coef, axes=[[3], [0]])), tf.int64)\n#         #coef = tf.pow(tf.constant(2, dtype=tf.float64), tf.range(numPlanes, dtype=tf.float64))\n#         #planeCroppedMask = tf.cast(tf.round(tf.tensordot(tf.cast(tf.greater(planeCroppedMasks, 0.5), tf.float64), coef, axes=[[3], [0]])), tf.int64)\n#         numGlobalPlanes = tf.reduce_sum(globalPlaneMask, axis=1)\n\n#         gridScores, gridPlanes, gridMasks = findLocalPlanes(planes, planeMasks)\n#         return planes, planeMask, numGlobalPlanes, boundaries, gridScores, gridPlanes, gridMasks\n\n    \n#     maskWidth = 32\n#     maskHeight = 32\n#     planeCroppedMasks = []\n#     for batchIndex in xrange(batchSize):\n#         boxes = planeBoxes[batchIndex]\n#         masks = tf.transpose(planeMasks[batchIndex], [2, 0, 1])\n#         croppedMasks = []\n#         for planeIndex in xrange(numPlanes):\n#         #for planeIndex in xrange(1):\n#             box = boxes[planeIndex]\n#             mask = masks[planeIndex]\n#             #minX = tf.cond(tf.less(planeIndex, tf.numValidPlanes[batchIndex]), lambda: tf.cast(box[0], tf.int32)\n#             minX = tf.cast(box[0], tf.int32)\n#             maxX = tf.cast(box[1], tf.int32)\n#             minY = tf.cast(box[2], tf.int32)\n#             maxY = tf.cast(box[3], tf.int32)\n#             minX = tf.minimum(minX, maxX)\n#             minY = tf.minimum(minY, maxY)\n#             croppedMask = tf.slice(mask, [minY, minX], [maxY - minY + 1, maxX - minX + 1])\n#             #croppedMask = tf.slice(mask, [0, 0], [height - 10, width - 10])\n#             croppedMask = tf.image.resize_bilinear(tf.expand_dims(tf.expand_dims(croppedMask, -1), 0), [maskHeight, maskWidth])\n#             croppedMasks.append(croppedMask)\n#             continue\n#         planeCroppedMasks.append(tf.squeeze(tf.concat(croppedMasks, axis=3)))\n#         continue\n#     planeCroppedMasks = tf.stack(planeCroppedMasks, axis=0)   \n\n#     gridMinX = []\n#     gridMaxX = []\n#     gridMinY = []\n#     gridMaxY = []\n#     for stride in [8, 16, 32]:\n#         boxSize = stride * 2\n#         xs = tf.tile(tf.expand_dims(tf.range(width / stride, dtype=tf.float32) * stride + stride / 2, 0), [height / stride, 1])\n#         ys = tf.tile(tf.expand_dims(tf.range(height / stride, dtype=tf.float32) * stride + stride / 2, 1), [1, width / stride])\n#         gridMinX.append(tf.reshape(xs - boxSize / 2, [1, -1, 1]))\n#         gridMaxX.append(tf.reshape(xs + boxSize / 2, [1, -1, 1]))\n#         gridMinY.append(tf.reshape(ys - boxSize / 2, [1, -1, 1]))\n#         gridMaxY.append(tf.reshape(ys + boxSize / 2, [1, -1, 1]))\n#         continue\n    \n#     gridMinX = tf.tile(tf.concat(gridMinX, axis=1), [batchSize, 1, 1])\n#     gridMaxX = tf.tile(tf.concat(gridMaxX, axis=1), [batchSize, 1, 1])\n#     gridMinY = tf.tile(tf.concat(gridMinY, axis=1), [batchSize, 1, 1])\n#     gridMaxY = tf.tile(tf.concat(gridMaxY, axis=1), [batchSize, 1, 1])\n\n#     planeMinX = tf.matmul(tf.reshape(planeMinX, [batchSize, 1, numPlanes]), sortMap)\n#     planeMaxX = tf.matmul(tf.reshape(planeMaxX, [batchSize, 1, numPlanes]), sortMap)\n#     planeMinY = tf.matmul(tf.reshape(planeMinY, [batchSize, 1, numPlanes]), sortMap)\n#     planeMaxY = tf.matmul(tf.reshape(planeMaxY, [batchSize, 1, numPlanes]), sortMap)\n\n#     intersection = tf.maximum(tf.minimum(gridMaxX, planeMaxX) - tf.maximum(gridMinX, planeMinX) + 1, 0.) * tf.maximum(tf.minimum(gridMaxY, planeMaxY) - tf.maximum(gridMinY, planeMinY) + 1, 0.)\n#     union = (gridMaxX - gridMinX + 1) * (gridMaxY - gridMinY + 1) + (planeMaxX - planeMinX + 1) * (planeMaxY - planeMinY + 1) - intersection\n#     IOU = intersection / union\n#     maxIOUInds = tf.argmax(IOU, axis=1)\n#     maxIOU = tf.reduce_max(IOU, axis=1)\n#     IOU = IOU * tf.one_hot(tf.argmax(IOU, 1), depth=IOU.shape[1], axis=1)\n#     #IOUThreshold = tf.concat([tf.ones((1, (width / 8) * (height / 8), 1)) * 0.2, tf.ones((1, (width / 16) * (height / 16), 1)) * 0.3, tf.ones((1, (width / 32) * (height / 32), 1)) * 0.7], axis=1)\n#     #activeGridMask = tf.one_hot(tf.argmax(IOU, 2), depth=IOU.shape[2], axis=2) * tf.cast(tf.greater(IOU, IOUThreshold), tf.float32)\n#     activeGridMask = tf.one_hot(tf.argmax(IOU, 2), depth=IOU.shape[2], axis=2) * (1 - tf.expand_dims(globalPlaneMask, 1))\n#     gridScores = tf.reduce_sum(activeGridMask, axis=2, keep_dims=True)\n#     activeGridMask = tf.expand_dims(activeGridMask, -1)\n#     gridPlanes = tf.reduce_sum(activeGridMask * tf.expand_dims(planes, 1), axis=2)\n#     gridMasks = tf.reduce_sum(activeGridMask * tf.expand_dims(tf.transpose(tf.reshape(planeCroppedMasks, [batchSize, -1, numPlanes]), [0, 2, 1]), 1), axis=2)\n\n#     activeGridMask = tf.squeeze(activeGridMask, axis=3)\n#     #gridBoxes = tf.reduce_sum(activeGridMask * tf.expand_dims(planeBoxes, 1), axis=2)\n#     gridPlaneMinX = tf.reduce_sum(activeGridMask * planeMinX, axis=2, keep_dims=True)\n#     gridPlaneMaxX = tf.reduce_sum(activeGridMask * planeMaxX, axis=2, keep_dims=True)\n#     gridPlaneMinY = tf.reduce_sum(activeGridMask * planeMinY, axis=2, keep_dims=True)\n#     gridPlaneMaxY = tf.reduce_sum(activeGridMask * planeMaxY, axis=2, keep_dims=True)\n#     gridWidths = gridMaxX - gridMinX\n#     gridHeights = gridMaxY - gridMinY\n\n#     gridOffsetX = ((gridPlaneMinX + gridPlaneMaxX) - (gridMinX + gridMaxX)) / 2 / gridWidths\n#     gridOffsetY = ((gridPlaneMinY + gridPlaneMaxY) - (gridMinY + gridMaxY)) / 2 / gridHeights\n#     gridW = (gridPlaneMaxX - gridPlaneMinX) / gridWidths\n#     gridH = (gridPlaneMaxY - gridPlaneMinY) / gridHeights\n#     gridBoxes = tf.concat([gridOffsetX, gridOffsetY, gridW, gridH], axis=2)\n    \n    \n#     offset = 0\n#     gridScoresArray = []\n#     gridPlanesArray = []\n#     gridBoxesArray = []\n#     gridMasksArray = []\n#     for stride in [8, 16, 32]:\n#         numGrids = (width / stride) * (height / stride)\n#         gridScoresArray.append(tf.reshape(tf.slice(gridScores, [0, offset, 0], [batchSize, numGrids, 1]), [batchSize, height / stride, width / stride, -1]))\n#         gridPlanesArray.append(tf.reshape(tf.slice(gridPlanes, [0, offset, 0], [batchSize, numGrids, 3]), [batchSize, height / stride, width / stride, -1]))\n#         gridBoxesArray.append(tf.reshape(tf.slice(gridBoxes, [0, offset, 0], [batchSize, numGrids, 4]), [batchSize, height / stride, width / stride, -1]))\n#         gridMasksArray.append(tf.reshape(tf.slice(gridMasks, [0, offset, 0], [batchSize, numGrids, maskWidth * maskHeight]), [batchSize, height / stride, width / stride, -1]))\n#         offset += numGrids\n#         continue\n\n    \n#     if True:\n#         coef = tf.pow(tf.constant(2, dtype=tf.float64), tf.range(numPlanes, dtype=tf.float64))\n#         planeMask = tf.cast(tf.round(tf.tensordot(tf.cast(planeMasks, tf.float64), coef, axes=[[3], [0]])), tf.int64)\n#         #localPlaneMask = tf.cast(tf.round(tf.tensordot(tf.cast(localPlaneMasks, tf.float64), coef, axes=[[3], [0]])), tf.int64)\n#         #coef = tf.pow(tf.constant(2, dtype=tf.float64), tf.range(numPlanes, dtype=tf.float64))\n#         planeCroppedMask = tf.cast(tf.round(tf.tensordot(tf.cast(tf.greater(planeCroppedMasks, 0.5), tf.float64), coef, axes=[[3], [0]])), tf.int64)\n#         numGlobalPlanes = tf.reduce_sum(globalPlaneMask, axis=1)\n\n#         return planes, planeMask, numGlobalPlanes, boundaries, planeBoxes, planeCroppedMask, gridScoresArray, gridPlanesArray, gridBoxesArray, gridMasksArray, maxIOU, maxIOUInds\n    \n#     # coef = tf.pow(tf.constant(0.9, dtype=tf.float64), tf.range(numPlanes, dtype=tf.float64))\n#     # coef = tf.tile(tf.reshape(coef, [1, 1, -1]), [batchSize, 1, 1])\n#     # coef = tf.matmul(coef, tf.cast(sortMap, tf.float64), transpose_b=True)\n#     # #planeMasks = tf.reshape(tf.matmul(tf.reshape(planeMasks, [-1, height * width, numPlanes]), sortMap), [-1, height, width, numPlanes])\n\n#     # assignment = tf.reduce_max(tf.cast(planeMasks, tf.float64) * tf.expand_dims(coef, axis=2), axis=3, keep_dims=True)\n#     # inds, mask, count = tf.unique_with_counts(tf.concat([tf.constant(0), tf.reshape(assignment, [-1])]))\n#     # mask = tf.reshape(tf.slice(mask, [1], [batchSize * height * width * 1], [batchSize, height, width, 1])\n\n#     # coef = tf.tile(tf.reshape(coef, [1, 1, -1]), [batchSize, 1, 1])\n#     # coef = tf.matmul(coef, tf.cast(sortMap, tf.float64), transpose_b=True)\n#     # coef = tf.reshape(tf.range(numPlanes)\n#     # planeMasks = tf.cast(tf.equal(mask, tf.tile(, [1, 1, 1, numPlanes]), [batchSize, 1, 1, 1])), tf.float32)\n    \n#     # planeAreas = tf.clip_by_value(tf.reduce_sum(planeMasks, axis=[1, 2]), 1e-4, width * height)\n#     # planeAreas, sortInds = tf.nn.top_k(planeAreas, k=numPlanes)\n#     # sortMap = tf.one_hot(sortInds, depth=numPlanes, axis=1)\n#     # planeMasks = tf.reshape(tf.matmul(tf.reshape(planeMasks, [-1, height * width, numPlanes]), sortMap), [-1, height, width, numPlanes])\n\n#     #planeAreas = tf.clip_by_value(tf.reduce_sum(planeMasks, axis=[1, 2]), 1e-4, width * height)\n    \n#     # planesNormal = tf.reduce_sum(tf.expand_dims(normal, 3) * tf.expand_dims(planeMasks, -1), axis=[1, 2]) / tf.expand_dims(planeAreas, -1)\n#     # planesNormal = tf.nn.l2_normalize(planesNormal, 2)\n#     # weightedABC = tf.reshape(tf.matmul(tf.reshape(ranges, [-1, 3]), tf.reshape(planesNormal, [-1, 3]), transpose_b=True), [batchSize, height, width, numPlanes])\n#     # planesD = tf.reduce_sum(weightedABC * depth * planeMasks, axis=[1, 2]) / planeAreas\n#     # planesD = tf.expand_dims(planesD, -1)\n#     # planes = planesNormal * planesD\n\n\n#     if True:\n#         planeMask = tf.cast(tf.round(tf.tensordot(tf.cast(planeMasks, tf.float64), coef, axes=[[3], [0]])), tf.int64)\n#         return planes, planeMask, tf.reduce_sum(validPlaneMask, axis=1)\n\n    \n#     globalPlanes = tf.slice(planes, [0, 0, 0], [batchSize, numGlobalPlanes, 3])\n#     globalPlaneMasks = tf.slice(planeMasks, [0, 0, 0, 0], [batchSize, height, width, numGlobalPlanes])\n\n#     if True:\n#         return planes, planeMasks, tf.reduce_sum(validPlaneMask, axis=1), planeMasks_test, boundaryMask\n#     #return globalPlanes, globalPlaneMasks, tf.reduce_sum(validPlaneMask, axis=1)\n    \n#     globalPlaneMask = tf.reduce_max(globalPlaneMasks, axis=3, keep_dims=True)\n#     smallPlaneMasks = tf.clip_by_value(tf.slice(planeMasks, [0, 0, 0, numGlobalPlanes], [batchSize, height, width, numPlanes - numGlobalPlanes]) - globalPlaneMask, 0, 1)\n#     smallPlaneMasks = tf.nn.dilation2d(smallPlaneMasks, filter=np.tile(dilationKernel, [1, 1, numPlanes - numGlobalPlanes]), strides=[1, 1, 1, 1], rates=[1, 1, 1, 1], padding=\'SAME\')\n#     smallPlaneMasks = tf.concat([globalPlaneMasks, smallPlaneMasks], axis=3)\n\n\n#     IOUThreshold = 0.9\n#     areaThreshold = 0.25\n\n#     blockSize = 16\n#     smallPlaneInds = tf.nn.avg_pool(smallPlaneMasks, ksize=[1, blockSize, blockSize, 1], strides=[1, blockSize, blockSize, 1], padding=\'VALID\')\n#     smallPlaneAreas = tf.clip_by_value(tf.reduce_sum(smallPlaneInds, axis=[1, 2], keep_dims=True), 1e-4, width * height)    \n#     IOU = smallPlaneInds / smallPlaneAreas\n#     inds = smallPlaneInds\n#     smallPlaneInds = tf.one_hot(tf.argmax(smallPlaneInds, 3), depth=numPlanes) * tf.cast(tf.greater_equal(IOU, IOUThreshold), tf.float32) * tf.cast(tf.greater(smallPlaneInds, areaThreshold), tf.float32)\n\n#     blockSmallPlaneMasks_16 = tf.reshape(tf.space_to_depth(smallPlaneMasks, block_size=blockSize), [batchSize, height / blockSize, width / blockSize, blockSize * blockSize, numPlanes])\n#     blockSmallPlanes_16 = tf.reduce_sum(tf.expand_dims(smallPlaneInds, -1) * tf.expand_dims(tf.expand_dims(planes, 1), 1), axis=3)\n#     blockSmallPlaneMasks_16 = tf.reduce_sum(tf.expand_dims(smallPlaneInds, 3) * blockSmallPlaneMasks_16, axis=4)\n#     blockPlaneIndicators_16 = tf.reduce_max(smallPlaneInds, axis=3, keep_dims=True)\n\n    \n#     blockSize = 32\n#     smallPlaneInds = tf.nn.avg_pool(smallPlaneMasks, ksize=[1, blockSize, blockSize, 1], strides=[1, blockSize, blockSize, 1], padding=\'VALID\')\n#     smallPlaneAreas = tf.clip_by_value(tf.reduce_sum(smallPlaneInds, axis=[1, 2], keep_dims=True), 1e-4, width * height)    \n#     IOU = smallPlaneInds / smallPlaneAreas\n#     inds = smallPlaneInds\n#     smallPlaneInds = tf.one_hot(tf.argmax(smallPlaneInds, 3), depth=numPlanes) * tf.cast(tf.greater_equal(IOU, IOUThreshold), tf.float32) * tf.cast(tf.greater(smallPlaneInds, areaThreshold), tf.float32)\n    \n#     blockSmallPlaneMasks_32 = tf.reshape(tf.space_to_depth(smallPlaneMasks, block_size=blockSize), [batchSize, height / blockSize, width / blockSize, blockSize * blockSize, numPlanes])\n#     blockSmallPlanes_32 = tf.reduce_sum(tf.expand_dims(smallPlaneInds, -1) * tf.expand_dims(tf.expand_dims(planes, 1), 1), axis=3)\n#     blockSmallPlaneMasks_32 = tf.reduce_sum(tf.expand_dims(smallPlaneInds, 3) * blockSmallPlaneMasks_32, axis=4)\n#     blockPlaneIndicators_32 = tf.reduce_max(smallPlaneInds, axis=3, keep_dims=True)\n\n#     return globalPlanes, globalPlaneMasks, blockSmallPlanes_16, blockSmallPlaneMasks_16, blockPlaneIndicators_16, blockSmallPlanes_32, blockSmallPlaneMasks_32, blockPlaneIndicators_32, tf.depth_to_space(blockSmallPlaneMasks_16 * blockPlaneIndicators_16, 16), tf.depth_to_space(blockSmallPlaneMasks_32 * blockPlaneIndicators_32, 32), planeMasks_test, planeDiff, boundaryMask\n\n\n# def planeFittingDepthModule(depth)\n#     width = int(depth.shape[2])\n#     height = int(depth.shape[1])\n\n#     focalLength = 517.97\n#     urange = (tf.range(width, dtype=tf.float32) / (width + 1) - 0.5) / focalLength * 641\n#     urange = tf.tile(tf.reshape(urange, [1, -1]), [height, 1])\n#     vrange = (tf.range(height, dtype=tf.float32) / (height + 1) - 0.5) / focalLength * 481\n#     vrange = tf.tile(tf.reshape(vrange, [-1, 1]), [1, width])\n            \n#     ranges = tf.stack([urange, tf.ones([height, width]), -vrange], axis=2)\n#     ranges = tf.expand_dims(ranges, 0)\n\n#     batchSize = int(depth.shape[0])\n\n#     X = depth * tf.expand_dims(urange, -1)\n#     Y = depth\n#     Z = -depth * tf.expand_dims(vrange, -1)\n#     XYZ = tf.concat([X, Y, Z], axis=3)\n#     XYZ = tf.reshape(XYZ, [-1, height * width, 3])\n\n\t\n\t\ndef findLocalPlanes(planes, planeMasks):\n    batchSize = int(planeMasks.shape[0])\n    height = int(planeMasks.shape[1])\n    width = int(planeMasks.shape[2])\n    numPlanes = int(planeMasks.shape[3])\n    \n    maskWidth = 16\n    maskHeight = 16\n\n    urange = tf.reshape(tf.range(width, dtype=tf.float32), [1, -1, 1])\n    planeXs = tf.reduce_max(planeMasks, axis=1)\n    planeMinX = float(width) - tf.reduce_max(planeXs * (float(width) - urange), axis=1)\n    planeMaxX = tf.reduce_max(planeXs * urange, axis=1)\n\n    vrange = tf.reshape(tf.range(height, dtype=tf.float32), [1, -1, 1])\n    planeYs = tf.reduce_max(planeMasks, axis=2)\n    planeMinY = float(height) - tf.reduce_max(planeYs * (float(height) - vrange), axis=1)\n    planeMaxY = tf.reduce_max(planeYs * vrange, axis=1)\n\n\n    localPlaneWidthThreshold = 64\n    localPlaneHeightThreshold = 64\n    localPlaneMask = tf.logical_and(tf.less(planeMaxX - planeMinX, localPlaneWidthThreshold), tf.less(planeMaxY - planeMinY, localPlaneHeightThreshold))\n\n    \n    stride = 8\n    boxSize = 64\n    xs = tf.tile(tf.expand_dims(tf.range(width / stride, dtype=tf.float32) * stride + stride / 2, 0), [height / stride, 1])\n    ys = tf.tile(tf.expand_dims(tf.range(height / stride, dtype=tf.float32) * stride + stride / 2, 1), [1, width / stride])\n    gridMinX = tf.reshape(xs - boxSize / 2, [1, -1, 1])\n    gridMaxX = tf.reshape(xs + boxSize / 2, [1, -1, 1])\n    gridMinY = tf.reshape(ys - boxSize / 2, [1, -1, 1])\n    gridMaxY = tf.reshape(ys + boxSize / 2, [1, -1, 1])\n    \n    gridMinX = tf.tile(gridMinX, [batchSize, 1, 1])\n    gridMaxX = tf.tile(gridMaxX, [batchSize, 1, 1])\n    gridMinY = tf.tile(gridMinY, [batchSize, 1, 1])\n    gridMaxY = tf.tile(gridMaxY, [batchSize, 1, 1])\n\n    padding = boxSize / 2 + 1\n    padding = boxSize / 2 + 1\n    paddedPlaneMasks = tf.concat([tf.zeros([batchSize, height, padding, numPlanes]), planeMasks, tf.zeros([batchSize, height, padding, numPlanes])], axis=2)\n    paddedPlaneMasks = tf.concat([tf.zeros([batchSize, padding, width + padding * 2, numPlanes]), paddedPlaneMasks, tf.zeros([batchSize, padding, width + padding * 2, numPlanes])], axis=1)\n\n    gridPlaneMasks = []\n    for gridY in xrange(height / stride):\n        for gridX in xrange(width / stride):\n            localPlaneMasks = tf.slice(paddedPlaneMasks, [0, gridY * stride + stride / 2 - boxSize / 2 + padding, gridX * stride + stride / 2 - boxSize / 2 + padding, 0], [batchSize, boxSize, boxSize, numPlanes])\n            gridPlaneMasks.append(tf.image.resize_bilinear(localPlaneMasks, [maskHeight, maskWidth]))\n            continue\n        continue\n    gridPlaneMasks = tf.stack(gridPlaneMasks, axis=1)\n    gridPlaneMasks = tf.reshape(gridPlaneMasks, [batchSize, -1, maskHeight * maskWidth, numPlanes])\n\n    planeMinX = tf.expand_dims(planeMinX, 1)\n    planeMaxX = tf.expand_dims(planeMaxX, 1)\n    planeMinY = tf.expand_dims(planeMinY, 1)\n    planeMaxY = tf.expand_dims(planeMaxY, 1)    \n    intersection = tf.maximum(tf.minimum(gridMaxX, planeMaxX) - tf.maximum(gridMinX, planeMinX) + 1, 0.) * tf.maximum(tf.minimum(gridMaxY, planeMaxY) - tf.maximum(gridMinY, planeMinY) + 1, 0.)\n    union = (gridMaxX - gridMinX + 1) * (gridMaxY - gridMinY + 1) + (planeMaxX - planeMinX + 1) * (planeMaxY - planeMinY + 1) - intersection\n    IOU = intersection / union\n    #maxIOUInds = tf.argmax(IOU, axis=1)\n    #maxIOU = tf.reduce_max(IOU, axis=1)\n    IOU = IOU * tf.expand_dims(tf.cast(localPlaneMask, tf.float32), 1)\n    IOU = IOU * tf.one_hot(tf.argmax(IOU, 1), depth=IOU.shape[1], axis=1)\n    IOUThreshold = 1.0 / pow(boxSize / stride, 2)\n    activeGridMask = tf.one_hot(tf.argmax(IOU, 2), depth=IOU.shape[2], axis=2) * tf.cast(tf.greater(IOU, IOUThreshold), tf.float32)\n    \n    #activeGridMask = tf.one_hot(tf.ones((batchSize, IOU.shape[1]), dtype=tf.int32), depth=IOU.shape[2], axis=2)\n    \n    gridScores = tf.reduce_sum(activeGridMask, axis=2, keep_dims=True)\n    activeGridMask = tf.expand_dims(activeGridMask, -1)\n    gridPlanes = tf.reduce_sum(activeGridMask * tf.expand_dims(planes, 1), axis=2)\n    gridMasks = tf.reduce_sum(activeGridMask * tf.transpose(gridPlaneMasks, [0, 1, 3, 2]), axis=2)\n\n    gridScores = tf.reshape(gridScores, [batchSize, height / stride, width / stride, -1])\n    gridPlanes = tf.reshape(gridPlanes, [batchSize, height / stride, width / stride, -1])\n    gridMasks = tf.reshape(gridMasks, [batchSize, height / stride, width / stride, -1])\n    \n    return gridScores, gridPlanes, gridMasks\n\n\ndef findBoundaries(planes, planeMasks):\n    height = int(planeMasks.shape[0])\n    width = int(planeMasks.shape[1])\n    \n    planesD = tf.norm(planes, axis=1, keep_dims=True)\n    planesD = tf.clip_by_value(planesD, 1e-5, 10)\n    planesNormal = planes / planesD\n\n    ND = tf.expand_dims(planesNormal, 0) * tf.expand_dims(planesD, 1)\n    ND_diff = tf.reshape(ND - tf.transpose(ND, [1, 0, 2]), [-1, 3])\n    coefX, coefY, coefZ = tf.unstack(ND_diff, axis=1)\n\n    pixels = []\n    focalLength = 517.97\n    urange = tf.range(width, dtype=tf.float32) / focalLength\n    ones = tf.ones(urange.shape)\n    vs = (coefX * urange + coefY * ones) / coefZ\n    pixels.append(tf.stack([tf.floor(vs), urange], axis=1))\n    pixels.append(tf.stack([tf.ceil(vs), urange], axis=1))\n    \n    vrange = tf.range(height, dtype=tf.float32) / focalLength\n    ones = tf.ones(vrange.shape)\n    us = -(coefY * ones - coefZ * vrange) / coefX\n    pixels.append(tf.stack([vrange, tf.floor(us)], axis=1))\n    pixels.append(tf.stack([vrange, tf.ceil(us)], axis=1))\n\n    v, u = tf.unstack(pixels, axis=1)\n    validMask = tf.logical_and(tf.less(u, width), tf.less(v, height))\n    validMask = tf.logical_and(validMask, tf.greater_equal(u, 0))\n    validMask = tf.logical_and(validMask, tf.greater_equal(v, 0))\n    \n    pixels *= tf.expand_dims(invalidMask, -1)\n    \n    boundary = tf.sparse_to_dense(pixels, output_shape=[height, width], sparse_values=1)\n    return boundary\n\n\ndef fitPlaneMasksModule(planes, depth, normal, width = 640, height = 480, numPlanes = 20, normalDotThreshold = np.cos(np.deg2rad(5)), distanceThreshold = 0.05, closing=True, one_hot=True):\n    focalLength = 517.97\n    urange = (tf.range(width, dtype=tf.float32) / (width + 1) - 0.5) / focalLength * 641\n    urange = tf.tile(tf.reshape(urange, [1, -1]), [height, 1])\n    vrange = (tf.range(height, dtype=tf.float32) / (height + 1) - 0.5) / focalLength * 481\n    vrange = tf.tile(tf.reshape(vrange, [-1, 1]), [1, width])\n        \n    X = depth * tf.expand_dims(urange, -1)\n    Y = depth\n    Z = -depth * tf.expand_dims(vrange, -1)\n    XYZ = tf.concat([X, Y, Z], axis=3)\n    XYZ = tf.reshape(XYZ, [-1, height * width, 3])\n    plane_parameters = planes\n    planesD = tf.norm(plane_parameters, axis=2, keep_dims=True)\n    planesNormal = tf.div(tf.negative(plane_parameters), tf.clip_by_value(planesD, 1e-4, 10))\n\n    distance = tf.reshape(tf.abs(tf.matmul(XYZ, planesNormal, transpose_b=True) + tf.reshape(planesD, [-1, 1, numPlanes])), [-1, height, width, numPlanes])\n    angle = tf.reshape(np.abs(tf.matmul(tf.reshape(normal, [-1, height * width, 3]), planesNormal, transpose_b=True)), [-1, height, width, numPlanes])\n\n    planeMasks = tf.cast(tf.logical_and(tf.greater(angle, normalDotThreshold), tf.less(distance, distanceThreshold)), tf.float32)\n\n    if closing:\n        #morphological closing\n        planeMasks = tf.nn.max_pool(planeMasks, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n        pass\n    plane_mask = tf.reduce_max(planeMasks, axis=3, keep_dims=True)\n    if one_hot:\n        if closing:\n            plane_mask = 1 - tf.nn.max_pool(1 - plane_mask, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n            pass\n        #one-hot encoding\n        planeMasks = tf.one_hot(tf.argmax(planeMasks * (distanceThreshold - distance), axis=3), depth=numPlanes) * plane_mask\n        pass\n    \n    return planeMasks, plane_mask\n    \n\ndef depthToNormalModule(depth):\n    batchSize = int(depth.shape[0])\n    height = int(depth.shape[1])\n    width = int(depth.shape[2])\n    \n    focalLength = 517.97\n    urange = (tf.range(width, dtype=tf.float32) / width - 0.5) / focalLength * 640\n    urange = tf.tile(tf.reshape(urange, [1, -1]), [height, 1])\n    vrange = (tf.range(height, dtype=tf.float32) / height - 0.5) / focalLength * 480\n    vrange = tf.tile(tf.reshape(vrange, [-1, 1]), [1, width])\n        \n    X = depth * tf.expand_dims(urange, -1)\n    Y = depth\n    Z = -depth * tf.expand_dims(vrange, -1)\n    XYZ = tf.concat([X, Y, Z], axis=3)\n    #XYZ = tf.reshape(XYZ, [-1, height * width, 3])\n\n    \n    kernel_array = np.zeros((3, 3, 1, 4))\n    kernel_array[0, 1, 0, 0] = 1\n    kernel_array[1, 0, 0, 1] = 1\n    kernel_array[2, 1, 0, 2] = 1\n    kernel_array[1, 2, 0, 3] = 1\n    kernel_array[1, 1, 0, 0] = -1\n    kernel_array[1, 1, 0, 1] = -1\n    kernel_array[1, 1, 0, 2] = -1\n    kernel_array[1, 1, 0, 3] = -1\n    kernel = tf.constant(kernel_array.reshape(-1), shape=kernel_array.shape, dtype=tf.float32)\n    XYZ_diff = tf.nn.depthwise_conv2d(tf.pad(XYZ, [[0, 0], [1, 1], [1, 1], [0, 0]], mode=\'REFLECT\'), tf.tile(kernel, [1, 1, 3, 1]), strides=[1, 1, 1, 1], padding=\'VALID\')\n    XYZ_diff = tf.reshape(XYZ_diff, [-1, height, width, 3, 4])\n    XYZ_diff_2 = tf.concat([tf.slice(XYZ_diff, [0, 0, 0, 0, 1], [batchSize, height, width, 3, 3]), tf.slice(XYZ_diff, [0, 0, 0, 0, 0], [batchSize, height, width, 3, 1])], axis=4)\n    XYZ_diff_1 = tf.unstack(XYZ_diff, axis=3)\n    XYZ_diff_2 = tf.unstack(XYZ_diff_2, axis=3)\n\n    normal_X = XYZ_diff_1[1] * XYZ_diff_2[2] - XYZ_diff_1[2] * XYZ_diff_2[1]\n    normal_Y = XYZ_diff_1[2] * XYZ_diff_2[0] - XYZ_diff_1[0] * XYZ_diff_2[2]\n    normal_Z = XYZ_diff_1[0] * XYZ_diff_2[1] - XYZ_diff_1[1] * XYZ_diff_2[0]\n\n    normal_X = tf.reduce_sum(normal_X, axis=[3])\n    normal_Y = tf.reduce_sum(normal_Y, axis=[3])\n    normal_Z = tf.reduce_sum(normal_Z, axis=[3])\n    normal = tf.stack([normal_X, normal_Y, normal_Z], axis=3)\n\n    kernel_size = 5\n    padding = (kernel_size - 1) / 2\n    neighbor_kernel_array = gaussian(kernel_size)\n    #neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n    neighbor_kernel_array /= neighbor_kernel_array.sum()\n    neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n    neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n    normal = tf.nn.depthwise_conv2d(tf.pad(normal, [[0, 0], [padding, padding], [padding, padding], [0, 0]], mode=\'REFLECT\'), tf.tile(neighbor_kernel, [1, 1, 3, 1]), strides=[1, 1, 1, 1], padding=\'VALID\')\n    \n    normal = normal / tf.norm(normal, axis=3, keep_dims=True)\n    return normal\n\ndef findBoundaryModule(depth, normal, segmentation, plane_mask, max_depth_diff = 0.1, max_normal_diff = np.sqrt(2 * (1 - np.cos(np.deg2rad(20))))):\n    kernel_size = 3\n    padding = (kernel_size - 1) / 2\n    neighbor_kernel_array = gaussian(kernel_size)\n    neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n    neighbor_kernel_array /= neighbor_kernel_array.sum()\n    neighbor_kernel_array *= -1\n    neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 1\n    neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n    neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n        \n    depth_diff = tf.abs(tf.nn.depthwise_conv2d(depth, neighbor_kernel, strides=[1, 1, 1, 1], padding=\'VALID\'))\n    depth_diff = tf.pad(depth_diff, paddings = [[0, 0], [padding, padding], [padding, padding], [0, 0]])\n    max_depth_diff = 0.1\n    depth_boundary = tf.greater(depth_diff, max_depth_diff)\n\n    normal_diff = tf.norm(tf.nn.depthwise_conv2d(normal, tf.tile(neighbor_kernel, [1, 1, 3, 1]), strides=[1, 1, 1, 1], padding=\'VALID\'), axis=3, keep_dims=True)\n    normal_diff = tf.pad(normal_diff, paddings = [[0, 0], [padding, padding], [padding, padding], [0, 0]])\n    max_normal_diff = np.sqrt(2 * (1 - np.cos(np.deg2rad(20))))\n    normal_boundary = tf.greater(normal_diff, max_normal_diff)\n\n    plane_region = tf.nn.max_pool(plane_mask, ksize=[1, kernel_size, kernel_size, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n    segmentation_eroded = 1 - tf.nn.max_pool(1 - segmentation, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n    plane_region -= tf.reduce_max(segmentation_eroded, axis=3, keep_dims=True)\n    boundary = tf.cast(tf.logical_or(depth_boundary, normal_boundary), tf.float32) * plane_region\n    #boundary = plane_region\n    #smooth_boundary = tf.cast(tf.less_equal(depth_diff, max_depth_diff), tf.float32) * boundary\n    smooth_boundary = tf.cast(tf.logical_and(normal_boundary, tf.less_equal(depth_diff, max_depth_diff)), tf.float32)\n    smooth_boundary = tf.nn.max_pool(smooth_boundary, ksize=[1, kernel_size, kernel_size, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\') * boundary\n    #smooth_boundary = smooth_boundary * boundary\n    boundary_gt = tf.concat([smooth_boundary, boundary - smooth_boundary], axis=3)\n    return boundary_gt\n\n\ndef findBoundaryModuleSmooth(depth, segmentation, plane_mask, smooth_boundary, max_depth_diff = 0.1, max_normal_diff = np.sqrt(2 * (1 - np.cos(np.deg2rad(20))))):\n    kernel_size = 3\n    padding = (kernel_size - 1) / 2\n    neighbor_kernel_array = gaussian(kernel_size)\n    neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n    neighbor_kernel_array /= neighbor_kernel_array.sum()\n    neighbor_kernel_array *= -1\n    neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 1\n    neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n    neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n        \n    depth_diff = tf.abs(tf.nn.depthwise_conv2d(depth, neighbor_kernel, strides=[1, 1, 1, 1], padding=\'VALID\'))\n    depth_diff = tf.pad(depth_diff, paddings = [[0, 0], [padding, padding], [padding, padding], [0, 0]])\n    max_depth_diff = 0.1\n    depth_boundary = tf.greater(depth_diff, max_depth_diff)\n\n\n    plane_region = tf.nn.max_pool(plane_mask, ksize=[1, kernel_size, kernel_size, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n    segmentation_eroded = 1 - tf.nn.max_pool(1 - segmentation, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n    plane_region -= tf.reduce_max(segmentation_eroded, axis=3, keep_dims=True)\n    occlusion_boundary = tf.cast(depth_boundary, tf.float32) * plane_region\n    #boundary = plane_region\n    #smooth_boundary = tf.cast(tf.less_equal(depth_diff, max_depth_diff), tf.float32) * boundary\n    smooth_boundary = smooth_boundary * plane_region\n    smooth_boundary_dilated = tf.nn.max_pool(smooth_boundary, ksize=[1, kernel_size, kernel_size, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\') * plane_region\n    #smooth_boundary = smooth_boundary * boundary\n    boundary_gt = tf.concat([smooth_boundary, tf.maximum(occlusion_boundary - smooth_boundary_dilated, 0)], axis=3)\n    return boundary_gt\n\n\ndef crfModule(segmentations, planes, non_plane_depth, info, numOutputPlanes=20, numIterations=20, kernel_size = 9):\n    width = int(segmentations.shape[2])\n    height = int(segmentations.shape[1])\n    \n    #maxDepthDiff = tf.Variable(0.3)\n    #sigmaDepthDiff = tf.Variable(0.5)\n    maxDepthDiff = 0.3\n    sigmaDepthDiff = 0.5\n\n    plane_parameters = tf.reshape(planes, (-1, 3))\n    plane_depths = planeDepthsModule(plane_parameters, width, height, info)\n    plane_depths = tf.transpose(tf.reshape(plane_depths, [height, width, -1, numOutputPlanes]), [2, 0, 1, 3])\n    all_depths = tf.concat([plane_depths, non_plane_depth], axis=3)\n    \n    refined_segmentation = segmentations\n    for _ in xrange(numIterations):\n        refined_segmentation = meanfieldModule(refined_segmentation, all_depths, numOutputPlanes=numOutputPlanes + 1, sigmaDepthDiff=sigmaDepthDiff, kernel_size = kernel_size)\n        continue\n    return refined_segmentation\n\ndef divideLayers(segmentations, planes, non_plane_mask, info, num_planes, numOutputPlanes_0=5, validAreaRatio=0.95, distanceThreshold=0.05):\n    batchSize = int(planes.shape[0])    \n    numOutputPlanes = int(planes.shape[1])\n    width = int(segmentations.shape[2])\n    height = int(segmentations.shape[1])\n    \n    plane_parameters = tf.reshape(planes, (-1, 3))\n    plane_depths = planeDepthsModule(plane_parameters, width, height, info)\n    plane_depths = tf.transpose(tf.reshape(plane_depths, [height, width, -1, numOutputPlanes]), [2, 0, 1, 3])\n    depth = tf.reduce_sum(plane_depths * segmentations[:, :, :, :numOutputPlanes], axis=3, keep_dims=True)\n    #non_plane_mask = segmentations[:, :, :, numOutputPlanes:numOutputPlanes+1]\n    \n    background_mask = tf.logical_or(tf.logical_or(tf.less(plane_depths, 1e-4), tf.greater(plane_depths, depth - distanceThreshold)), tf.cast(non_plane_mask, tf.bool))\n    background_planes = tf.greater(tf.reduce_mean(tf.cast(background_mask, tf.float32), axis=[1, 2]), validAreaRatio)\n    validPlaneMask = tf.less(tf.tile(tf.expand_dims(tf.range(numOutputPlanes), 0), [batchSize, 1]), tf.expand_dims(num_planes, -1))\n    background_planes = tf.logical_and(background_planes, validPlaneMask)\n    background_planes = tf.cast(background_planes, tf.float32)\n    plane_areas = tf.reduce_sum(segmentations[:, :, :, :numOutputPlanes], axis=[1, 2])\n    \n    layer_plane_areas_0 = plane_areas * background_planes    \n    areas, sortInds = tf.nn.top_k(layer_plane_areas_0, k=numOutputPlanes_0)\n    sortMap = tf.one_hot(sortInds, depth=numOutputPlanes, axis=1)\n    validMask = tf.cast(tf.greater(areas, 1e-4), tf.float32)\n    sortMap *= tf.expand_dims(validMask, 1)\n    layer_segmentations_0 = tf.reshape(tf.matmul(tf.reshape(segmentations, [batchSize, height * width, -1]), sortMap), [batchSize, height, width, -1])\n    layer_planes_0 = tf.transpose(tf.matmul(planes, sortMap, transpose_a=True), [0, 2, 1])\n\n\n    layer_plane_areas_1 = plane_areas * (1 - background_planes)\n    areas, sortInds = tf.nn.top_k(layer_plane_areas_1, k=numOutputPlanes - numOutputPlanes_0)\n    sortMap = tf.one_hot(sortInds, depth=numOutputPlanes, axis=1)\n    validMask = tf.cast(tf.greater(areas, 1e-4), tf.float32)\n    sortMap *= tf.expand_dims(validMask, 1)\n    layer_segmentations_1 = tf.reshape(tf.matmul(tf.reshape(segmentations, [batchSize, height * width, -1]), sortMap), [batchSize, height, width, -1])\n    layer_planes_1 = tf.transpose(tf.matmul(planes, sortMap, transpose_a=True), [0, 2, 1])\n    \n    \n    return tf.concat([layer_segmentations_0, layer_segmentations_1], axis=3), tf.concat([layer_planes_0, layer_planes_1], axis=1)\n\n\n\ndef calcMessages(planeSegmentations, planeDepths, planesY, numOutputPlanes = 21, coef = [1, 1, 1], beta = 1, iteration = 0, maxDepthDiff = 0.2, varDepthDiff = 0.5, kernel_size = 9):\n    #images, varImageDiff\n    batchSize = int(planeSegmentations.shape[0])\n    height = int(planeSegmentations.shape[1])\n    width = int(planeSegmentations.shape[2])\n\n\n    n2 = tf.pow(tf.reshape(planesY, [batchSize, 1, 1, -1]), 2)\n    d2n2s = tf.reduce_sum(tf.pow(planeDepths, 2) * n2 * planeSegmentations, axis=-1, keep_dims=True)\n    dnsd = tf.reduce_sum(planeDepths * n2 * planeSegmentations, axis=-1, keep_dims=True) * planeDepths\n    n2sd2 = tf.reduce_sum(n2 * planeSegmentations, axis=-1, keep_dims=True) * tf.pow(planeDepths, 2)\n\n    messages = d2n2s - 2 * dnsd + n2sd2\n\n    maxDepthDiff = 0.2\n    messages = tf.minimum(messages / pow(maxDepthDiff, 2), 1)\n    \n    # vertical_padding = tf.zeros((batchSize, height, 1, numOutputPlanes))\n    # horizontal_padding = tf.zeros((batchSize, height, 1, numOutputPlanes))    \n\n\n    # neighbor_kernel_array = gaussian(kernel_size)\n    # neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n    # neighbor_kernel_array /= neighbor_kernel_array.sum()\n    # neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n    # neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n    \n    # messages = tf.nn.depthwise_conv2d(messages, tf.tile(neighbor_kernel, [1, 1, numOutputPlanes, 1]), strides=[1, 1, 1, 1], padding=\'SAME\')\n\n    return messages\n\n\ndef crfrnnModule(inputs, image_dims, num_classes, theta_alpha, theta_beta, theta_gamma, num_iterations):\n    current_path = os.path.dirname(os.path.realpath(__file__))\n    custom_module = tf.load_op_library(current_path + \'/crfasrnn/high_dim_filter.so\')\n    from crfasrnn import high_dim_filter_grad  # Register gradients for the custom op\n\n    if os.path.exists(\'weights.npy\'):\n        weights = np.load(\'weights.npy\')\n        weights = [weights[0], weights[1], weights[2]]\n    else:\n        weights = np.random.normal(size=(3, 21, 21)).astype(np.float32)\n        pass\n    \n    spatial_ker_weights = tf.Variable(weights[0][:num_classes, :num_classes], name=\'spatial_ker_weights\', trainable=True)\n    bilateral_ker_weights = tf.Variable(weights[1][:num_classes, :num_classes], name=\'bilateral_ker_weights\', trainable=True)\n    compatibility_matrix = tf.Variable(weights[2][:num_classes, :num_classes], name=\'compatibility_matrix\', trainable=True)    \n        \n\n    batchSize = int(inputs[0].shape[0])\n    c, h, w = num_classes, image_dims[0], image_dims[1]\n    all_ones = np.ones((c, h, w), dtype=np.float32)\n\n    outputs = []\n    for batchIndex in xrange(batchSize):\n        unaries = tf.transpose(inputs[0][batchIndex, :, :, :], perm=(2, 0, 1))\n        rgb = tf.transpose(inputs[1][batchIndex, :, :, :], perm=(2, 0, 1))\n\n\n        # Prepare filter normalization coefficients\n        spatial_norm_vals = custom_module.high_dim_filter(all_ones, rgb, bilateral=False,\n                                                          theta_gamma=theta_gamma)\n        bilateral_norm_vals = custom_module.high_dim_filter(all_ones, rgb, bilateral=True,\n                                                            theta_alpha=theta_alpha,\n                                                            theta_beta=theta_beta)\n        q_values = unaries\n\n        for i in range(num_iterations):\n            softmax_out = tf.nn.softmax(q_values, dim=0)\n\n            # Spatial filtering\n            spatial_out = custom_module.high_dim_filter(softmax_out, rgb, bilateral=False,\n                                                        theta_gamma=theta_gamma)\n            spatial_out = spatial_out / spatial_norm_vals\n\n            # Bilateral filtering\n            bilateral_out = custom_module.high_dim_filter(softmax_out, rgb, bilateral=True,\n                                                          theta_alpha=theta_alpha,\n                                                          theta_beta=theta_beta)\n            bilateral_out = bilateral_out / bilateral_norm_vals\n\n            # Weighting filter outputs\n            message_passing = (tf.matmul(spatial_ker_weights,\n                                         tf.reshape(spatial_out, (c, -1))) +\n                               tf.matmul(bilateral_ker_weights,\n                                         tf.reshape(bilateral_out, (c, -1))))\n\n            # Compatibility transform\n            pairwise = tf.matmul(compatibility_matrix, message_passing)\n\n            # Adding unary potentials\n            pairwise = tf.reshape(pairwise, (c, h, w))\n            q_values = unaries - pairwise\n            continue\n        outputs.append(tf.transpose(tf.reshape(q_values, (1, c, h, w)), perm=(0, 2, 3, 1)))\n        continue\n    outputs = tf.concat(outputs, axis=0)\n    return outputs\n'"
planenet.py,86,"b""# Converted to TensorFlow .caffemodel\n# with the DeepLab-ResNet configuration.\n# The batch normalisation layer is provided by\n# the slim library (https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim).\n\nfrom kaffe.tensorflow import Network\nimport tensorflow as tf\n\nclass PlaneNet(Network):\n    def setup(self, is_training, options):\n        '''Network definition.\n        \n        Args:\n          is_training: whether to update the running mean and variance of the batch normalisation layer.\n                       If the batch size is small, it is better to keep the running mean and variance of \n                       the-pretrained model frozen.\n          options: contains network configuration parameters\n        '''\n\n        nChannels_3 = 1024\n        nChannels_4 = 1024\n        nChannels_5 = 2048\n        if False: # Dilated Residual Networks change the first few layers to deal with the gridding issue\n            (self.feed('img_inp')\n                 .conv(7, 7, 64, 2, 2, biased=False, relu=False, name='conv1')\n                 .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn_conv1')\n                 .max_pool(3, 3, 2, 2, name='pool1'))\n            \n            (self.feed('pool1')\n                 .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res2a_branch1')\n                 .batch_normalization(is_training=is_training, activation_fn=None, name='bn2a_branch1'))\n                 \n            (self.feed('pool1')\n                 .conv(1, 1, 64, 1, 1, biased=False, relu=False, name='res2a_branch2a')\n                 .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn2a_branch2a')\n                 .conv(3, 3, 64, 1, 1, biased=False, relu=False, name='res2a_branch2b')\n                 .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn2a_branch2b')\n                 .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res2a_branch2c')\n                 .batch_normalization(is_training=is_training, activation_fn=None, name='bn2a_branch2c'))            \n        else:\n            with tf.variable_scope('degridding'):\n                (self.feed('img_inp')\n                     .conv(7, 7, 16, 1, 1, biased=False, relu=False, name='conv1')\n                     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn1')\n                     .conv(1, 1, 16, 2, 2, biased=False, relu=False, name='conv2_c')\n                     .batch_normalization(is_training=is_training, activation_fn=None, name='bn2c'))\n\n                (self.feed('bn1')\n                     .conv(3, 3, 16, 1, 1, biased=False, relu=False, name='conv2a')\n                     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn2a')\n                     .conv(3, 3, 16, 2, 2, biased=False, relu=False, name='conv2b')\n                     .batch_normalization(is_training=is_training, activation_fn=None, name='bn2b'))\n                \n                (self.feed('bn2b',\n                           'bn2c')\n                     .add(name='add1')\n                     .relu(name='relu1')\n                     .conv(1, 1, 32, 2, 2, biased=False, relu=False, name='conv3c')\n                     .batch_normalization(is_training=is_training, activation_fn=None, name='bn3c'))\n                (self.feed('relu1')\n                     .conv(3, 3, 32, 1, 1, biased=False, relu=False, name='conv3a')\n                     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3a')\n                     .conv(3, 3, 32, 2, 2, biased=False, relu=False, name='conv3b')\n                     .batch_normalization(is_training=is_training, activation_fn=None, name='bn3b'))\n                (self.feed('bn3b',\n                           'bn3c')\n                     .add(name='add2')\n                     .relu(name='pool1'))\n\n                pass\n            pass\n\n        (self.feed('pool1')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res2a_branch1')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn2a_branch1'))\n                 \n        (self.feed('pool1')\n             .conv(1, 1, 64, 1, 1, biased=False, relu=False, name='res2a_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn2a_branch2a')\n             .conv(3, 3, 64, 1, 1, biased=False, relu=False, name='res2a_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn2a_branch2b')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res2a_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn2a_branch2c'))\n\n        (self.feed('bn2a_branch1', \n                   'bn2a_branch2c')\n             .add(name='res2a')\n             .relu(name='res2a_relu')\n             .conv(1, 1, 64, 1, 1, biased=False, relu=False, name='res2b_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn2b_branch2a')\n             .conv(3, 3, 64, 1, 1, biased=False, relu=False, name='res2b_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn2b_branch2b')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res2b_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn2b_branch2c'))\n\n        (self.feed('res2a_relu', \n                   'bn2b_branch2c')\n             .add(name='res2b')\n             .relu(name='res2b_relu')\n             .conv(1, 1, 64, 1, 1, biased=False, relu=False, name='res2c_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn2c_branch2a')\n             .conv(3, 3, 64, 1, 1, biased=False, relu=False, name='res2c_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn2c_branch2b')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res2c_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn2c_branch2c'))\n\n        (self.feed('res2b_relu', \n                   'bn2c_branch2c')\n             .add(name='res2c')\n             .relu(name='res2c_relu')\n             .conv(1, 1, 512, 2, 2, biased=False, relu=False, name='res3a_branch1')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn3a_branch1'))\n\n        (self.feed('res2c_relu')\n             .conv(1, 1, 128, 2, 2, biased=False, relu=False, name='res3a_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3a_branch2a')\n             .conv(3, 3, 128, 1, 1, biased=False, relu=False, name='res3a_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3a_branch2b')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res3a_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn3a_branch2c'))\n\n        (self.feed('bn3a_branch1', \n                   'bn3a_branch2c')\n             .add(name='res3a')\n             .relu(name='res3a_relu')\n             .conv(1, 1, 128, 1, 1, biased=False, relu=False, name='res3b1_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3b1_branch2a')\n             .conv(3, 3, 128, 1, 1, biased=False, relu=False, name='res3b1_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3b1_branch2b')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res3b1_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn3b1_branch2c'))\n\n        (self.feed('res3a_relu', \n                   'bn3b1_branch2c')\n             .add(name='res3b1')\n             .relu(name='res3b1_relu')\n             .conv(1, 1, 128, 1, 1, biased=False, relu=False, name='res3b2_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3b2_branch2a')\n             .conv(3, 3, 128, 1, 1, biased=False, relu=False, name='res3b2_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3b2_branch2b')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res3b2_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn3b2_branch2c'))\n\n        (self.feed('res3b1_relu', \n                   'bn3b2_branch2c')\n             .add(name='res3b2')\n             .relu(name='res3b2_relu')\n             .conv(1, 1, 128, 1, 1, biased=False, relu=False, name='res3b3_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3b3_branch2a')\n             .conv(3, 3, 128, 1, 1, biased=False, relu=False, name='res3b3_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3b3_branch2b')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res3b3_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn3b3_branch2c'))\n\n        (self.feed('res3b2_relu', \n                   'bn3b3_branch2c')\n             .add(name='res3b3')\n             .relu(name='res3b3_relu')\n             .conv(1, 1, nChannels_3, 1, 1, biased=False, relu=False, name='res4a_branch1')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4a_branch1'))\n\n        (self.feed('res3b3_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4a_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4a_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4a_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4a_branch2b')\n             .conv(1, 1, nChannels_3, 1, 1, biased=False, relu=False, name='res4a_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4a_branch2c'))\n\n        (self.feed('bn4a_branch1', \n                   'bn4a_branch2c')\n             .add(name='res4a')\n             .relu(name='res4a_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b1_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b1_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b1_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b1_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b1_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b1_branch2c'))\n\n        (self.feed('res4a_relu', \n                   'bn4b1_branch2c')\n             .add(name='res4b1')\n             .relu(name='res4b1_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b2_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b2_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b2_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b2_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b2_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b2_branch2c'))\n\n        (self.feed('res4b1_relu', \n                   'bn4b2_branch2c')\n             .add(name='res4b2')\n             .relu(name='res4b2_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b3_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b3_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b3_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b3_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b3_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b3_branch2c'))\n\n        (self.feed('res4b2_relu', \n                   'bn4b3_branch2c')\n             .add(name='res4b3')\n             .relu(name='res4b3_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b4_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b4_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b4_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b4_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b4_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b4_branch2c'))\n\n        (self.feed('res4b3_relu', \n                   'bn4b4_branch2c')\n             .add(name='res4b4')\n             .relu(name='res4b4_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b5_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b5_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b5_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b5_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b5_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b5_branch2c'))\n\n        (self.feed('res4b4_relu', \n                   'bn4b5_branch2c')\n             .add(name='res4b5')\n             .relu(name='res4b5_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b6_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b6_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b6_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b6_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b6_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b6_branch2c'))\n\n        (self.feed('res4b5_relu', \n                   'bn4b6_branch2c')\n             .add(name='res4b6')\n             .relu(name='res4b6_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b7_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b7_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b7_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b7_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b7_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b7_branch2c'))\n\n        (self.feed('res4b6_relu', \n                   'bn4b7_branch2c')\n             .add(name='res4b7')\n             .relu(name='res4b7_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b8_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b8_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b8_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b8_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b8_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b8_branch2c'))\n\n        (self.feed('res4b7_relu', \n                   'bn4b8_branch2c')\n             .add(name='res4b8')\n             .relu(name='res4b8_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b9_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b9_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b9_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b9_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b9_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b9_branch2c'))\n\n        (self.feed('res4b8_relu', \n                   'bn4b9_branch2c')\n             .add(name='res4b9')\n             .relu(name='res4b9_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b10_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b10_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b10_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b10_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b10_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b10_branch2c'))\n\n        (self.feed('res4b9_relu', \n                   'bn4b10_branch2c')\n             .add(name='res4b10')\n             .relu(name='res4b10_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b11_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b11_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b11_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b11_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b11_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b11_branch2c'))\n\n        (self.feed('res4b10_relu', \n                   'bn4b11_branch2c')\n             .add(name='res4b11')\n             .relu(name='res4b11_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b12_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b12_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b12_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b12_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b12_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b12_branch2c'))\n\n        (self.feed('res4b11_relu', \n                   'bn4b12_branch2c')\n             .add(name='res4b12')\n             .relu(name='res4b12_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b13_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b13_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b13_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b13_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b13_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b13_branch2c'))\n\n        (self.feed('res4b12_relu', \n                   'bn4b13_branch2c')\n             .add(name='res4b13')\n             .relu(name='res4b13_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b14_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b14_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b14_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b14_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b14_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b14_branch2c'))\n\n        (self.feed('res4b13_relu', \n                   'bn4b14_branch2c')\n             .add(name='res4b14')\n             .relu(name='res4b14_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b15_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b15_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b15_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b15_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b15_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b15_branch2c'))\n\n        (self.feed('res4b14_relu', \n                   'bn4b15_branch2c')\n             .add(name='res4b15')\n             .relu(name='res4b15_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b16_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b16_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b16_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b16_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b16_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b16_branch2c'))\n\n        (self.feed('res4b15_relu', \n                   'bn4b16_branch2c')\n             .add(name='res4b16')\n             .relu(name='res4b16_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b17_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b17_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b17_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b17_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b17_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b17_branch2c'))\n\n        (self.feed('res4b16_relu', \n                   'bn4b17_branch2c')\n             .add(name='res4b17')\n             .relu(name='res4b17_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b18_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b18_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b18_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b18_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b18_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b18_branch2c'))\n\n        (self.feed('res4b17_relu', \n                   'bn4b18_branch2c')\n             .add(name='res4b18')\n             .relu(name='res4b18_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b19_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b19_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b19_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b19_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b19_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b19_branch2c'))\n\n        (self.feed('res4b18_relu', \n                   'bn4b19_branch2c')\n             .add(name='res4b19')\n             .relu(name='res4b19_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b20_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b20_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b20_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b20_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b20_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b20_branch2c'))\n\n        (self.feed('res4b19_relu', \n                   'bn4b20_branch2c')\n             .add(name='res4b20')\n             .relu(name='res4b20_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b21_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b21_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b21_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b21_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b21_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b21_branch2c'))\n\n        (self.feed('res4b20_relu', \n                   'bn4b21_branch2c')\n             .add(name='res4b21')\n             .relu(name='res4b21_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b22_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b22_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b22_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b22_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b22_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b22_branch2c'))\n\n        (self.feed('res4b21_relu', \n                   'bn4b22_branch2c')\n             .add(name='res4b22')\n             .relu(name='res4b22_relu')\n             .conv(1, 1, nChannels_5, 1, 1, biased=False, relu=False, name='res5a_branch1')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn5a_branch1'))\n\n        (self.feed('res4b22_relu')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res5a_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn5a_branch2a')\n             .atrous_conv(3, 3, 512, 4, padding='SAME', biased=False, relu=False, name='res5a_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn5a_branch2b')\n             .conv(1, 1, nChannels_5, 1, 1, biased=False, relu=False, name='res5a_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn5a_branch2c'))\n\n        (self.feed('bn5a_branch1', \n                   'bn5a_branch2c')\n             .add(name='res5a')\n             .relu(name='res5a_relu')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res5b_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn5b_branch2a')\n             .atrous_conv(3, 3, 512, 4, padding='SAME', biased=False, relu=False, name='res5b_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn5b_branch2b')\n             .conv(1, 1, nChannels_5, 1, 1, biased=False, relu=False, name='res5b_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn5b_branch2c'))\n\n        (self.feed('res5a_relu', \n                   'bn5b_branch2c')\n             .add(name='res5b')\n             .relu(name='res5b_relu')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res5c_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn5c_branch2a')\n             .atrous_conv(3, 3, 512, 4, padding='SAME', biased=False, relu=False, name='res5c_branch2b')\n             .batch_normalization(activation_fn=tf.nn.relu, name='bn5c_branch2b', is_training=is_training)\n             .conv(1, 1, nChannels_5, 1, 1, biased=False, relu=False, name='res5c_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn5c_branch2c'))\n\n        (self.feed('res5b_relu', \n                   'bn5c_branch2c')\n             .add(name='res5c')\n             .relu(name='res5c_relu'))\n\n        \n        \n        (self.feed('res5c_relu')\n             .avg_pool(24, 32, 24, 32, name='res5d_pool1')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res5d_pool1_conv')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='res5d_pool1_bn')\n             .resize_bilinear(size=[24, 32], name='res5d_upsample1'))\n\n        (self.feed('res5c_relu')\n             .avg_pool(12, 16, 12, 16, name='res5d_pool2')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res5d_pool2_conv')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='res5d_pool2_bn')\n             .resize_bilinear(size=[24, 32], name='res5d_upsample2'))\n\n        (self.feed('res5c_relu')\n             .avg_pool(6, 8, 6, 8, name='res5d_pool3')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res5d_pool3_conv')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='res5d_pool3_bn')\n             .resize_bilinear(size=[24, 32], name='res5d_upsample3'))\n\n        (self.feed('res5c_relu')\n             .avg_pool(3, 4, 3, 4, name='res5d_pool4')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res5d_pool4_conv')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='res5d_pool4_bn')\n             .resize_bilinear(size=[24, 32], name='res5d_upsample4'))\n\n\n        #deep supervision at layers in list options.deepSupervisionLayers\n        if len(options.deepSupervisionLayers) > 0:\n            with tf.variable_scope('deep_supervision'):\n                for layerIndex, layer in enumerate(options.deepSupervisionLayers):\n                    (self.feed(layer)\n                         .avg_pool(24, 32, 24, 32, name=layer+'_pool1')\n                         .conv(1, 1, 512, 1, 1, biased=False, relu=False, name=layer+'_pool1_conv')\n                         .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=layer+'_pool1_bn')\n                         .resize_bilinear(size=[24, 32], name=layer+'_upsample1'))\n            \n                    (self.feed(layer)\n                         .avg_pool(12, 16, 12, 16, name=layer+'_pool2')\n                         .conv(1, 1, 512, 1, 1, biased=False, relu=False, name=layer+'_pool2_conv')\n                         .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=layer+'_pool2_bn')\n                         .resize_bilinear(size=[24, 32], name=layer+'_upsample2'))\n            \n                    (self.feed(layer)\n                         .avg_pool(6, 8, 6, 8, name=layer+'_pool3')\n                         .conv(1, 1, 512, 1, 1, biased=False, relu=False, name=layer+'_pool3_conv')\n                         .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=layer+'_pool3_bn')\n                         .resize_bilinear(size=[24, 32], name=layer+'_upsample3'))\n\n                    (self.feed(layer)\n                         .avg_pool(3, 4, 3, 4, name=layer+'_pool4')\n                         .conv(1, 1, 512, 1, 1, biased=False, relu=False, name=layer+'_pool4_conv')\n                         .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=layer+'_pool4_bn')\n                         .resize_bilinear(size=[24, 32], name=layer+'_upsample4'))\n\n                    \n                    (self.feed(layer+'_pool1')\n                         .reshape(shape=[-1, nChannels_4], name=layer+'_plane_reshape1')\n                         .fc(num_out=options.numOutputPlanes * 3, name=layer+'_plane_fc', relu=False)\n                         .reshape(shape=[-1, options.numOutputPlanes, 3], name=layer+'_plane_pred'))\n\n                    if options.predictConfidence == 1:\n                        (self.feed(layer+'_plane_reshape1')\n                             .fc(num_out=options.numOutputPlanes, name=layer+'_plane_confidence_fc', relu=False)\n                             .reshape(shape=[-1, options.numOutputPlanes, 1], name=layer+'_plane_confidence_pred'))\n                        pass\n                    \n                    (self.feed(layer,\n                               layer+'_upsample1',\n                               layer+'_upsample2',\n                               layer+'_upsample3',\n                               layer+'_upsample4')\n                         .concat(axis=3, name=layer+'_segmentation_concat')\n                         .conv(3, 3, 512, 1, 1, biased=False, relu=False, name=layer+'_segmentation_conv1')\n                         .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=layer+'_segmentation_bn1')\n                         .dropout(keep_prob=0.9, name=layer+'_segmentation_dropout')\n                         .conv(1, 1, options.numOutputPlanes, 1, 1, relu=False, name=layer+'_segmentation_conv2')\n                         .resize_bilinear(size=[192, 256], name=layer+'_segmentation_pred'))\n\n                    (self.feed(layer+'_segmentation_dropout')\n                         .conv(1, 1, 1, 1, 1, relu=False, name=layer+'_non_plane_mask_conv2')\n                         .resize_bilinear(size=[192, 256], name=layer+'_non_plane_mask_pred'))\n                    # (self.feed(layer+'_segmentation_dropout')\n                    #      .conv(1, 1, 1, 1, 1, relu=False, name=layer+'_non_plane_depth_conv2')\n                    #      .resize_bilinear(size=[192, 256], name=layer+'_non_plane_depth_pred'))\n                    # (self.feed(layer+'_segmentation_dropout')\n                    #      .conv(1, 1, 3, 1, 1, relu=False, name=layer+'_non_plane_normal_conv2')\n                    #      .resize_bilinear(size=[192, 256], name=layer+'_non_plane_normal_pred'))\n                    continue\n                pass\n            pass\n            \n\n\n        (self.feed('res5d_pool1')\n             .reshape(shape=[-1, nChannels_5], name='plane_reshape1')\n             .fc(num_out=options.numOutputPlanes * 3, name='plane_fc', relu=False)\n             .reshape(shape=[-1, options.numOutputPlanes, 3], name='plane_pred'))\n\n        if options.predictConfidence == 1:\n            (self.feed('plane_reshape1')\n                 .fc(num_out=options.numOutputPlanes, name='plane_confidence_fc', relu=False)\n                 .reshape(shape=[-1, options.numOutputPlanes, 1], name='plane_confidence_pred'))\n            pass\n             \n        (self.feed('res5c_relu',\n                   'res5d_upsample1',\n                   'res5d_upsample2',\n                   'res5d_upsample3',\n                   'res5d_upsample4')\n             .concat(axis=3, name='segmentation_concat')\n             .conv(3, 3, 512, 1, 1, biased=False, relu=False, name='segmentation_conv1')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='segmentation_bn1')\n             .dropout(keep_prob=0.9, name='segmentation_dropout')\n             .conv(1, 1, options.numOutputPlanes, 1, 1, relu=False, name='segmentation_conv2')\n             .resize_bilinear(size=[192, 256], name='segmentation_pred'))\n        \n\n        (self.feed('segmentation_dropout')\n             .conv(1, 1, 1, 1, 1, relu=False, name='non_plane_mask_conv2')\n             .resize_bilinear(size=[192, 256], name='non_plane_mask_pred'))\n        (self.feed('segmentation_dropout')\n             .conv(1, 1, 1, 1, 1, relu=False, name='non_plane_depth_conv2')\n             .resize_bilinear(size=[192, 256], name='non_plane_depth_pred'))\n        (self.feed('segmentation_dropout')\n             .conv(1, 1, 3, 1, 1, relu=False, name='non_plane_normal_conv2')\n             .resize_bilinear(size=[192, 256], name='non_plane_normal_pred'))\n\n        if options.predictSemantics == 1:\n            (self.feed('segmentation_dropout')\n                 .conv(1, 1, 41, 1, 1, relu=False, name='semantics_conv2')\n                 .resize_bilinear(size=[192, 256], name='semantics_pred'))\n            pass\n        \n\n        #boundary prediction\n        if options.predictBoundary == 1:\n            (self.feed('segmentation_dropout')\n                 .conv(1, 1, 1, 1, 1, relu=False, name='boundary_smooth_conv5')\n                 .resize_bilinear(size=[192, 256], name='boundary_smooth_upsample5'))\n            (self.feed('segmentation_dropout')\n                 .conv(1, 1, 1, 1, 1, relu=False, name='boundary_occlusion_conv5')\n                 .resize_bilinear(size=[192, 256], name='boundary_occlusion_upsample5'))\n            (self.feed('bn1')\n                 .conv(1, 1, 1, 1, 1, relu=False, name='boundary_conv0')\n                 .resize_bilinear(size=[192, 256], name='boundary_upsample0'))\n            (self.feed('relu1')\n                 .conv(1, 1, 1, 1, 1, relu=False, name='boundary_conv1')\n                 .resize_bilinear(size=[192, 256], name='boundary_upsample1'))\n            (self.feed('res2c_relu')\n                 .conv(1, 1, 1, 1, 1, relu=False, name='boundary_conv2')\n                 .resize_bilinear(size=[192, 256], name='boundary_upsample2'))\n            (self.feed('res3b3_relu')\n                 .conv(1, 1, 1, 1, 1, relu=False, name='boundary_conv3')\n                 .resize_bilinear(size=[192, 256], name='boundary_upsample3'))\n            (self.feed('boundary_smooth_upsample5',\n                       'boundary_upsample0',                   \n                       'boundary_upsample1',\n                       'boundary_upsample2',\n                       'boundary_upsample3')\n                 .concat(axis=3, name='boundary_smooth_concat')         \n                 .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='boundary_smooth_bn')\n                 .conv(1, 1, 1, 1, 1, relu=False, name='boundary_smooth_pred'))\n            (self.feed('boundary_occlusion_upsample5',\n                       'boundary_upsample0',\n                       'boundary_upsample1',\n                       'boundary_upsample2',\n                       'boundary_upsample3')\n                 .concat(axis=3, name='boundary_occlusion_concat')\n                 .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='boundary_occlusion_bn')\n                 .conv(1, 1, 1, 1, 1, relu=False, name='boundary_occlusion_pred'))\n            (self.feed('boundary_smooth_pred',\n                       'boundary_occlusion_pred')\n                 .concat(axis=3, name='boundary_pred'))\n            pass\n\n        #local prediction\n        if options.predictLocal == 1:\n            (self.feed('segmentation_dropout')\n                 .conv(1, 1, 1, 1, 1, relu=False, name='local_score_pred'))\n            (self.feed('segmentation_dropout')\n                 .conv(1, 1, 3, 1, 1, relu=False, name='local_plane_pred'))\n            (self.feed('segmentation_dropout')\n                 .conv(1, 1, 16*16, 1, 1, relu=False, name='local_mask_pred'))\n            pass\n            \n"""
planenet_inference.py,9,"b'import tensorflow as tf\nimport numpy as np\nnp.set_printoptions(precision=2, linewidth=200)\nimport cv2\nimport os\nimport time\nimport sys\nimport argparse\nimport glob\n\n#sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n#from planenet_utils import calcPlaneDepths, drawSegmentationImage, drawDepthImage\nfrom PlaneNet.utils import calcPlaneDepths, drawSegmentationImage, drawDepthImage\n\nfrom train_planenet import build_graph, parse_args\n\nWIDTH = 256\nHEIGHT = 192\n\nALL_TITLES = [\'PlaneNet\']\nALL_METHODS = [(\'sample_np10_hybrid3_bl0_dl0_ds0_crfrnn5_sm0\', \'\', 0, 2)]\n\nclass PlaneNetDetector():\n    def __init__(self, batchSize=1):\n        tf.reset_default_graph()\n\n        self.img_inp = tf.placeholder(tf.float32, shape=[batchSize, HEIGHT, WIDTH, 3], name=\'image\')\n        training_flag = tf.constant(False, tf.bool)\n\n        self.options = parse_args()\n        self.global_pred_dict, _, _ = build_graph(self.img_inp, self.img_inp, training_flag, self.options)\n\n        var_to_restore = tf.global_variables()\n\n        config = tf.ConfigProto()\n        config.gpu_options.allow_growth = True\n        config.allow_soft_placement = True\n        init_op = tf.group(tf.global_variables_initializer(),\n                           tf.local_variables_initializer())\n\n\n        self.sess = tf.Session(config=config)\n        self.sess.run(init_op)\n        loader = tf.train.Saver(var_to_restore)\n        path = os.path.dirname(os.path.realpath(__file__))\n        checkpoint_dir = path + \'/checkpoint/sample_np10_hybrid3_bl0_dl0_ds0_crfrnn5_sm0\'\n        loader.restore(self.sess, ""%s/checkpoint.ckpt""%(checkpoint_dir))\n        return\n\n    def detect(self, image, estimateFocalLength=False):\n\n        pred_dict = {}\n        if True:\n            t0 = time.time()\n\n            #image_inp = np.array([cv2.resize(image, (WIDTH, HEIGHT)) for image in images])\n            image_inp = np.expand_dims(cv2.resize(image, (WIDTH, HEIGHT)), 0)\n            image_inp = image_inp.astype(np.float32) / 255 - 0.5\n            global_pred = self.sess.run(self.global_pred_dict, feed_dict={self.img_inp: image_inp})\n\n            pred_p = global_pred[\'plane\'][0]\n            pred_s = global_pred[\'segmentation\'][0]    \n            pred_np_m = global_pred[\'non_plane_mask\'][0]\n            pred_np_d = global_pred[\'non_plane_depth\'][0]\n            \n            all_segmentations = np.concatenate([pred_s, pred_np_m], axis=2)\n\n            info = np.zeros(20)\n            if estimateFocalLength:\n                focalLength = estimateFocalLength(img_ori)\n                info[0] = focalLength\n                info[5] = focalLength\n                info[2] = img_ori.shape[1] / 2\n                info[6] = img_ori.shape[0] / 2\n                info[16] = img_ori.shape[1]\n                info[17] = img_ori.shape[0]\n                info[10] = 1\n                info[15] = 1\n                info[18] = 1000\n                info[19] = 5\n            else:\n                info[0] = 571.87\n                info[2] = 320\n                info[5] = 571.87\n                info[6] = 240\n                info[16] = 640\n                info[17] = 480\n                info[10] = 1\n                info[15] = 1\n                info[18] = 1000\n                info[19] = 5\n                pass\n\n            #width_high_res = images[0].shape[1]\n            #height_high_res = images[0].shape[0]\n            width_high_res = 640\n            height_high_res = 480\n            \n            plane_depths = calcPlaneDepths(pred_p, width_high_res, height_high_res, info)\n\n            pred_np_d = np.expand_dims(cv2.resize(pred_np_d.squeeze(), (width_high_res, height_high_res)), -1)\n            all_depths = np.concatenate([plane_depths, pred_np_d], axis=2)\n\n            all_segmentations = np.stack([cv2.resize(all_segmentations[:, :, planeIndex], (width_high_res, height_high_res)) for planeIndex in xrange(all_segmentations.shape[-1])], axis=2)\n                \n            segmentation = np.argmax(all_segmentations, 2)\n            pred_d = all_depths.reshape(-1, self.options.numOutputPlanes + 1)[np.arange(height_high_res * width_high_res), segmentation.reshape(-1)].reshape(height_high_res, width_high_res)\n\n            #print(pred_p)\n            # for segmentIndex in range(segmentation.max() + 1):\n            #     cv2.imwrite(\'test/mask_\' + str(segmentIndex) + \'.png\', (segmentation == segmentIndex).astype(np.uint8) * 255)\n            #     print(all_depths[:, :, segmentIndex].min(), all_depths[:, :, segmentIndex].max())\n            #     cv2.imwrite(\'test/depth_\' + str(segmentIndex) + \'.png\', drawDepthImage(all_depths[:, :, segmentIndex]))\n            #     continue            \n            pred_dict[\'plane\'] = pred_p\n            pred_dict[\'segmentation\'] = segmentation\n            pred_dict[\'depth\'] = pred_d\n            pred_dict[\'info\'] = info\n        else:\n            print(\'prediction failed\')\n            pass        \n        return pred_dict\n'"
predict.py,27,"b'import tensorflow as tf\nimport numpy as np\nnp.set_printoptions(precision=2, linewidth=200)\nimport cv2\nimport os\nimport time\nimport sys\nfrom nndistance import tf_nndistance\nimport argparse\nimport glob\nimport PIL\nimport scipy.ndimage as ndimage\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom utils import *\nfrom modules import *\n\nfrom train_planenet import build_graph\nfrom planenet import PlaneNet\nfrom RecordReaderAll import *\nfrom crfasrnn.crfasrnn_layer import CrfRnnLayer\n\nWIDTH = 256\nHEIGHT = 192\n\nALL_TITLES = [\'PlaneNet\']\nALL_METHODS = [(\'sample_np10_hybrid3_bl0_dl0_ds0_crfrnn5_sm0\', \'\', 0, 2)]\n\n\ndef writeHTML(options):\n    from html import HTML\n\n    titles = options.titles\n\n    h = HTML(\'html\')\n    h.p(\'Results\')\n    h.br()\n    path = \'.\'\n    #methods = [\'planenet\', \'pixelwise\', \'pixelwise+RANSAC\', \'GT+RANSAC\', \'planenet+crf\', \'pixelwise+semantics+RANSAC\']\n    #methods = [\'planenet\', \'pixelwise\', \'pixelwise+RANSAC\', \'GT+RANSAC\']\n\n    for image_index in xrange(options.numImages):\n\n        t = h.table(border=\'1\')\n        r_inp = t.tr()\n        r_inp.td(\'input \' + str(image_index + options.startIndex))\n        r_inp.td().img(src=path + \'/\' + str(image_index + options.startIndex) + \'_image.png\')\n\n        r = t.tr()\n        r.td(\'methods\')\n        for method_index, method in enumerate(titles):\n            r.td(method)\n            continue\n        \n        r = t.tr()\n        r.td(\'segmentation\')\n        for method_index, method in enumerate(titles):\n            r.td().img(src=path + \'/\' + str(image_index + options.startIndex) + \'_segmentation_pred_\' + str(method_index) + \'.png\')\n            r.td().img(src=path + \'/\' + str(image_index + options.startIndex) + \'_segmentation_pred_blended_\' + str(method_index) + \'.png\')            \n            continue\n\n        r = t.tr()\n        r.td(\'depth\')\n        for method_index, method in enumerate(titles):\n            r.td().img(src=path + \'/\' + str(image_index + options.startIndex) + \'_depth_pred_\' + str(method_index) + \'.png\')\n            continue\n        h.br()\n        continue\n\n    metric_titles = [\'depth error 0.1\', \'depth error 0.2\', \'depth error 0.3\', \'IOU 0.3\', \'IOU 0.5\', \'IOU 0.7\']\n\n    h.p(\'Curves on plane accuracy\')\n    for title in metric_titles:\n        h.img(src=\'curve_plane_\' + title.replace(\' \', \'_\') + \'.png\')\n        continue\n    \n    h.p(\'Curves on pixel coverage\')\n    for title in metric_titles:\n        h.img(src=\'curve_pixel_\' + title.replace(\' \', \'_\') + \'.png\')\n        continue\n    \n    \n    html_file = open(options.test_dir + \'/index.html\', \'w\')\n    html_file.write(str(h))\n    html_file.close()\n    return\n\ndef evaluatePlanes(options):\n    #writeHTML(options)\n    #exit(1)\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n    \n    predictions = getResults(options)\n    \n\n    saving = True\n    if predictions[0][\'image\'].shape[0] != options.numImages:\n        saving = False\n        pass\n    options.numImages = min(options.numImages, predictions[0][\'image\'].shape[0])\n    options.visualizeImages = min(options.visualizeImages, predictions[0][\'image\'].shape[0])        \n    \n    for pred_dict in predictions:\n        for key, value in pred_dict.iteritems():\n            if value.shape[0] > options.numImages:\n                pred_dict[key] = value[:options.numImages]\n                pass\n            continue\n        continue\n\n\n    if options.applicationType == \'grids\':\n        image_list = glob.glob(options.test_dir + \'/*_image.png\')\n        print(len(image_list))\n        gridImage = writeGridImage(image_list[80:336], 3200, 1800, (16, 16))\n        cv2.imwrite(options.test_dir + \'/grid_images/grid_1616.png\', gridImage)\n        exit(1)\n        pass\n    \n    for image_index in xrange(options.visualizeImages):\n        if options.imageIndex >= 0 and image_index + options.startIndex != options.imageIndex:\n            continue\n        if options.applicationType == \'grids\':\n            cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_image.png\', pred_dict[\'image\'][image_index])\n            segmentation = predictions[0][\'segmentation\'][image_index]\n            #segmentation = np.argmax(np.concatenate([segmentation, pred_dict[\'np_mask\'][image_index]], axis=2), -1)\n            segmentationImage = drawSegmentationImage(segmentation, blackIndex=options.numOutputPlanes)\n            #cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_segmentation_pred_\' + str(0) + \'.png\', segmentationImage)\n            segmentationImageBlended = (segmentationImage * 0.7 + pred_dict[\'image\'][image_index] * 0.3).astype(np.uint8)\n            cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_segmentation_pred_blended_\' + str(0) + \'.png\', segmentationImageBlended)\n            continue\n\n            \n        cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_image.png\', pred_dict[\'image\'][image_index])\n        \n        info = pred_dict[\'info\'][image_index]\n\n        for method_index, pred_dict in enumerate(predictions):\n            cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_dict[\'depth\'][image_index]))\n\n            if \'pixelwise\' in options.methods[method_index][1]:\n                continue\n            allSegmentations = pred_dict[\'segmentation\'][image_index]\n            segmentation = np.argmax(allSegmentations, axis=-1)\n            #segmentation = np.argmax(np.concatenate([segmentation, pred_dict[\'np_mask\'][image_index]], axis=2), -1)\n            segmentationImage = drawSegmentationImage(segmentation, blackIndex=options.numOutputPlanes)\n            cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_segmentation_pred_\' + str(method_index) + \'.png\', segmentationImage)\n            segmentationImageBlended = (segmentationImage * 0.7 + pred_dict[\'image\'][image_index] * 0.3).astype(np.uint8)\n            cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_segmentation_pred_blended_\' + str(method_index) + \'.png\', segmentationImageBlended)\n\n            segmentationImageBlended = np.minimum(segmentationImage * 0.3 + pred_dict[\'image\'][image_index] * 0.7, 255).astype(np.uint8)\n\n            if options.imageIndex >= 0:\n                for planeIndex in xrange(options.numOutputPlanes):\n                    cv2.imwrite(options.test_dir + \'/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(segmentation == planeIndex))\n                    continue\n                \n                if options.applicationType == \'logo_video\':\n                    copyLogoVideo(options.textureImageFilename, options.test_dir, image_index + options.startIndex, pred_dict[\'image\'][image_index], pred_dict[\'depth\'][image_index], pred_dict[\'plane\'][image_index], segmentation, pred_dict[\'info\'][image_index], textureType=\'logo\')\n                elif options.applicationType == \'wall_video\':\n                    if options.wallIndices == \'\':\n                        print(\'please specify wall indices\')\n                        exit(1)\n                        pass\n                    wallIndices = [int(value) for value in options.wallIndices.split(\',\')]\n                    copyLogoVideo(options.textureImageFilename, options.test_dir, image_index + options.startIndex, pred_dict[\'image\'][image_index], pred_dict[\'depth\'][image_index], pred_dict[\'plane\'][image_index], segmentation, pred_dict[\'info\'][image_index], textureType=\'wall\', wallInds=wallIndices)\n                elif options.applicationType == \'ruler\':\n                    if options.startPixel == \'\' or options.endPixel == \'\':\n                        print(\'please specify start pixel and end pixel\')\n                        exit(1)\n                        pass                    \n                    startPixel = tuple([int(value) for value in options.startPixel.split(\',\')])\n                    endPixel = tuple([int(value) for value in options.endPixel.split(\',\')])\n                    addRulerComplete(options.textureImageFilename, options.test_dir, image_index + options.startIndex, pred_dict[\'image\'][image_index], pred_dict[\'depth\'][image_index], pred_dict[\'plane\'][image_index], segmentation, pred_dict[\'info\'][image_index], startPixel=startPixel, endPixel=endPixel, fixedEndPoint=True, numFrames=1000)\n                elif options.applicationType == \'logo_texture\':\n                    resultImage = copyLogo(options.textureImageFilename, options.test_dir, image_index + options.startIndex, pred_dict[\'image\'][image_index], pred_dict[\'depth\'][image_index], pred_dict[\'plane\'][image_index], segmentation, pred_dict[\'info\'][image_index])\n                    cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_result.png\', resultImage)\n                elif options.applicationType == \'wall_texture\':\n                    if options.wallIndices == \'\':\n                        print(\'please specify wall indices\')\n                        exit(1)\n                        pass                    \n                    wallIndices = [int(value) for value in options.wallIndices.split(\',\')]\n                    resultImage = copyWallTexture(options.textureImageFilename, options.test_dir, image_index + options.startIndex, pred_dict[\'image\'][image_index], pred_dict[\'depth\'][image_index], pred_dict[\'plane\'][image_index], segmentation, pred_dict[\'info\'][image_index], wallPlanes=wallIndices)\n                    cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_result.png\', resultImage)                    \n                elif options.applicationType == \'TV\':\n                    if options.wallIndices == \'\':\n                        print(\'please specify wall indices\')\n                        exit(1)\n                        pass                    \n                    wallIndices = [int(value) for value in options.wallIndices.split(\',\')]\n                    copyLogoVideo(options.textureImageFilename, options.test_dir, image_index + options.startIndex, pred_dict[\'image\'][image_index], pred_dict[\'depth\'][image_index], pred_dict[\'plane\'][image_index], segmentation, pred_dict[\'info\'][image_index], textureType=\'TV\', wallInds=wallIndices)\n                elif options.applicationType == \'pool\':\n                    print(\'dump\')\n                    newPlanes = []\n                    newSegmentation = np.full(segmentation.shape, -1)\n                    newPlaneIndex = 0\n                    planes = pred_dict[\'plane\'][image_index]\n                    for planeIndex in xrange(options.numOutputPlanes):\n                        mask = segmentation == planeIndex\n                        if mask.sum() > 0:\n                            newPlanes.append(planes[planeIndex])\n                            newSegmentation[mask] = newPlaneIndex\n                            newPlaneIndex += 1\n                            pass\n                        continue\n\n                    np.save(\'pool/dump/\' + str(image_index + options.startIndex) + \'_planes.npy\', np.stack(newPlanes, axis=0))\n                    #print(global_gt[\'non_plane_mask\'].shape)\n                    np.save(\'pool/dump/\' + str(image_index + options.startIndex) + \'_segmentation.npy\', newSegmentation)\n                    cv2.imwrite(\'pool/dump/\' + str(image_index + options.startIndex) + \'_image.png\', pred_dict[\'image\'][image_index])\n                    depth = pred_dict[\'depth\'][image_index]\n                    np.save(\'pool/dump/\' + str(image_index + options.startIndex) + \'_depth.npy\', depth)\n                    info = pred_dict[\'info\'][image_index]\n                    #normal = calcNormal(depth, info)\n                    #np.save(\'test/\' + str(image_index + options.startIndex) + \'_normal.npy\', normal)\n                    np.save(\'pool/dump/\' + str(image_index + options.startIndex) + \'_info.npy\', info)\n                    exit(1)\n                else:\n                    print(\'please specify application type\')\n                    # np_mask = (segmentation == options.numOutputPlanes).astype(np.float32)\n                    # np_depth = pred_dict[\'np_depth\'][image_index].squeeze()\n                    # np_depth = cv2.resize(np_depth, (np_mask.shape[1], np_mask.shape[0]))\n                    # cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_np_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(np_depth * np_mask))\n                    # writePLYFile(options.test_dir, image_index + options.startIndex, segmentationImageBlended, pred_dict[\'depth\'][image_index], segmentation, pred_dict[\'plane\'][image_index], pred_dict[\'info\'][image_index])\n                    pass\n                exit(1)\n                pass\n            continue\n        continue\n\n    writeHTML(options)\n    return\n\n\ndef getResults(options):\n    checkpoint_prefix = \'checkpoint/\'\n\n    methods = options.methods\n    predictions = []\n\n    if os.path.exists(options.result_filename) and options.useCache == 1:\n        predictions = np.load(options.result_filename)\n        return predictions\n    \n\n    for method_index, method in enumerate(methods):\n        if len(method) < 4 or method[3] < 2:\n            continue\n        if method[0] == \'\':\n            continue\n        \n        if \'ds0\' not in method[0]:\n            options.deepSupervisionLayers = [\'res4b22_relu\', ]\n        else:\n            options.deepSupervisionLayers = []\n            pass\n        options.predictConfidence = 0\n        options.predictLocal = 0\n        options.predictPixelwise = 1\n        options.predictBoundary = int(\'pb\' in method[0])\n        options.anchorPlanes = 0\n        if \'ps\' in method[0]:\n            options.predictSemantics = 1\n        else:\n            options.predictSemantics = 0\n            pass\n        if \'crfrnn\' in method[0]:\n            options.crfrnn = 10\n        else:\n            options.crfrnn = 0\n            pass\n            \n        if \'ap1\' in method[0]:\n            options.anchorPlanes = 1            \n            pass\n        \n        options.checkpoint_dir = checkpoint_prefix + method[0]\n        print(options.checkpoint_dir)\n        \n        options.suffix = method[1]\n\n        method_names = [previous_method[0] for previous_method in methods[:method_index]]\n\n        if options.customImageFolder != \'\':\n            print(\'make predictions on custom images\')\n            pred_dict = getPredictionCustom(options)\n        elif options.dataFolder != \'\':\n            print(\'make predictions on ScanNet images\')            \n            pred_dict = getPredictionScanNet(options)\n        else:\n            print(\'please specify customImageFolder or dataFolder\')\n            exit(1)\n            pass\n        \n        predictions.append(pred_dict)\n        continue\n    #np.save(options.test_dir + \'/curves.npy\', curves)\n    results = predictions\n\n    #print(results)\n    \n    if options.useCache != -1:\n        np.save(options.result_filename, results)\n        pass\n    pass\n    \n    return results\n\n\ndef getPredictionScanNet(options):\n    tf.reset_default_graph()\n    \n    options.batchSize = 1\n    min_after_dequeue = 1000\n\n    reader = RecordReaderAll()\n    if options.dataset == \'SUNCG\':\n        filename_queue = tf.train.string_input_producer([options.dataFolder + \'/planes_SUNCG_val.tfrecords\'], num_epochs=10000)\n    elif options.dataset == \'NYU_RGBD\':\n        filename_queue = tf.train.string_input_producer([options.dataFolder + \'/planes_nyu_rgbd_val.tfrecords\'], num_epochs=1)\n        options.deepSupervision = 0\n        options.predictLocal = 0\n    elif options.dataset == \'matterport\':\n        filename_queue = tf.train.string_input_producer([options.dataFolder + \'/planes_matterport_val.tfrecords\'], num_epochs=1)\n    else:\n        filename_queue = tf.train.string_input_producer([options.dataFolder + \'/planes_scannet_val.tfrecords\'], num_epochs=1)\n        pass\n    \n    img_inp, global_gt_dict, local_gt_dict = reader.getBatch(filename_queue, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True, random=False)\n        \n\n    \n    training_flag = tf.constant(False, tf.bool)\n\n    options.gpu_id = 0\n    global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp, img_inp, training_flag, options)\n\n    var_to_restore = tf.global_variables()\n\n\n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n\n    width_high_res = 640\n    height_high_res = 480\n                \n    \n    pred_dict = {}\n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n        #var_to_restore = [v for v in var_to_restore if \'res4b22_relu_non_plane\' not in v.name]\n        loader = tf.train.Saver(var_to_restore)\n        loader.restore(sess, ""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n        #loader.restore(sess, options.fineTuningCheckpoint)\n        \n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n        \n        \n        try:\n            predDepths = []\n            predPlanes = []\n            predSegmentations = []\n            predNonPlaneDepths = []\n            predNonPlaneNormals = []            \n            predNonPlaneMasks = []\n            images = []\n            infos = []            \n            for index in xrange(options.startIndex + options.numImages):\n                if index % 10 == 0:\n                    print((\'image\', index))\n                    pass\n                t0=time.time()\n\n                img, global_gt, global_pred = sess.run([img_inp, global_gt_dict, global_pred_dict])\n\n                if index < options.startIndex:\n                    continue                \n\n\n                image = cv2.resize(((img[0] + 0.5) * 255).astype(np.uint8), (width_high_res, height_high_res))\n                images.append(image)\n                infos.append(global_gt[\'info\'][0])\n                \n                \n                pred_p = global_pred[\'plane\'][0]\n                pred_s = global_pred[\'segmentation\'][0]\n                \n                pred_np_m = global_pred[\'non_plane_mask\'][0]\n                pred_np_d = global_pred[\'non_plane_depth\'][0]\n                pred_np_n = global_pred[\'non_plane_normal\'][0]\n                \n                if global_gt[\'info\'][0][19] > 1 and global_gt[\'info\'][0][19] < 4 and False:\n                    pred_np_n = calcNormal(pred_np_d.squeeze(), global_gt[\'info\'][0])\n                    pass\n\n\n                #pred_b = global_pred[\'boundary\'][0]\n                predNonPlaneMasks.append(pred_np_m)                    \n                predNonPlaneDepths.append(pred_np_d)\n                predNonPlaneNormals.append(pred_np_n)\n                #predBoundaries.append(pred_b)\n                    \n                all_segmentations = np.concatenate([pred_s, pred_np_m], axis=2)\n\n                plane_depths = calcPlaneDepths(pred_p, width_high_res, height_high_res, global_gt[\'info\'][0])\n\n                pred_np_d = np.expand_dims(cv2.resize(pred_np_d.squeeze(), (width_high_res, height_high_res)), -1)\n                all_depths = np.concatenate([plane_depths, pred_np_d], axis=2)\n\n                all_segmentations = np.stack([cv2.resize(all_segmentations[:, :, planeIndex], (width_high_res, height_high_res)) for planeIndex in xrange(all_segmentations.shape[-1])], axis=2)\n                \n                segmentation = np.argmax(all_segmentations, 2)\n                pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(height_high_res * width_high_res), segmentation.reshape(-1)].reshape(height_high_res, width_high_res)\n\n                                         \n                predDepths.append(pred_d)\n                predPlanes.append(pred_p)\n                predSegmentations.append(all_segmentations)\n                continue\n\n            pred_dict[\'plane\'] = np.array(predPlanes)\n            pred_dict[\'segmentation\'] = np.array(predSegmentations)\n            pred_dict[\'depth\'] = np.array(predDepths)\n            #pred_dict[\'semantics\'] = np.array(predSemantics)                        \n            pred_dict[\'np_depth\'] = np.array(predNonPlaneDepths)\n            #pred_dict[\'np_normal\'] = np.array(predNonPlaneNormals)\n            pred_dict[\'np_mask\'] = np.array(predNonPlaneMasks)\n            pred_dict[\'image\'] = np.array(images)\n            pred_dict[\'info\'] = np.array(infos)\n            \n            pass\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n        \n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return pred_dict\n\ndef getPredictionCustom(options):\n    tf.reset_default_graph()\n    \n    options.batchSize = 1\n\n    img_inp = tf.placeholder(tf.float32, shape=[1, HEIGHT, WIDTH, 3], name=\'image\')\n    training_flag = tf.constant(False, tf.bool)\n\n    options.gpu_id = 0\n    global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp, img_inp, training_flag, options)\n\n    var_to_restore = tf.global_variables()\n\n\n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n\n    width_high_res = 640\n    height_high_res = 480\n                \n\n    #image_list = glob.glob(\'../my_images/*.jpg\') + glob.glob(\'../my_images/*.png\') + glob.glob(\'../my_images/*.JPG\')\n    #image_list = glob.glob(\'../my_images/TV/*.jpg\') + glob.glob(\'../my_images/TV/*.png\') + glob.glob(\'../my_images/TV/*.JPG\')\n    #image_list = glob.glob(\'../my_images/TV/*.jpg\') + glob.glob(\'../my_images/TV/*.png\') + glob.glob(\'../my_images/TV/*.JPG\')\n    image_list = glob.glob(options.customImageFolder + \'/*.jpg\') + glob.glob(options.customImageFolder + \'/*.png\') + glob.glob(options.customImageFolder + \'/*.JPG\')\n    options.visualizeImages = min(options.visualizeImages, len(image_list))\n    \n    pred_dict = {}\n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n        #var_to_restore = [v for v in var_to_restore if \'res4b22_relu_non_plane\' not in v.name]\n        loader = tf.train.Saver(var_to_restore)\n        loader.restore(sess, ""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n        #loader.restore(sess, options.fineTuningCheckpoint)\n        \n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n        \n        \n        try:\n            predDepths = []\n            predPlanes = []\n            predSegmentations = []\n            predSemantics = []            \n            predNonPlaneDepths = []\n            predNonPlaneNormals = []            \n            predNonPlaneMasks = []\n            predBoundaries = []\n            images = []\n            infos = []\n            for index in xrange(min(options.startIndex + options.numImages, len(image_list))):\n                if index % 10 == 0:\n                    print((\'image\', index))\n                    pass\n                t0=time.time()\n                \n                print((\'image\', index))\n                \n                img_ori = cv2.imread(image_list[index])\n                images.append(img_ori)\n                img = cv2.resize(img_ori, (WIDTH, HEIGHT))\n                img = img.astype(np.float32) / 255 - 0.5\n                img = np.expand_dims(img, 0)\n                global_pred = sess.run(global_pred_dict, feed_dict={img_inp: img})\n\n                if index < options.startIndex:\n                    continue                \n\n\n                pred_p = global_pred[\'plane\'][0]\n                pred_s = global_pred[\'segmentation\'][0]\n                \n                pred_np_m = global_pred[\'non_plane_mask\'][0]\n                pred_np_d = global_pred[\'non_plane_depth\'][0]\n                pred_np_n = global_pred[\'non_plane_normal\'][0]\n                \n                #if global_gt[\'info\'][0][19] > 1 and global_gt[\'info\'][0][19] < 4 and False:\n                #pred_np_n = calcNormal(pred_np_d.squeeze(), global_gt[\'info\'][0])\n                #pass\n\n\n                #pred_b = global_pred[\'boundary\'][0]\n                predNonPlaneMasks.append(pred_np_m)                    \n                predNonPlaneDepths.append(pred_np_d)\n                predNonPlaneNormals.append(pred_np_n)\n                #predBoundaries.append(pred_b)\n                    \n                all_segmentations = np.concatenate([pred_s, pred_np_m], axis=2)\n\n                info = np.zeros(20)\n                if options.estimateFocalLength:\n                    focalLength = estimateFocalLength(img_ori)\n                    info[0] = focalLength\n                    info[5] = focalLength\n                    info[2] = img_ori.shape[1] / 2\n                    info[6] = img_ori.shape[0] / 2\n                    info[16] = img_ori.shape[1]\n                    info[17] = img_ori.shape[0]\n                    info[10] = 1\n                    info[15] = 1\n                    info[18] = 1000\n                    info[19] = 5\n                else:\n                    info[0] = 2800.71\n                    info[2] = 1634.45\n                    info[5] = 2814.01\n                    info[6] = 1224.18\n                    info[16] = img_ori.shape[1]\n                    info[17] = img_ori.shape[0]\n                    info[10] = 1\n                    info[15] = 1\n                    info[18] = 1000\n                    info[19] = 5\n                    pass\n\n                # print(focalLength)\n                # cv2.imwrite(\'test/image.png\', ((img[0] + 0.5) * 255).astype(np.uint8))\n                # cv2.imwrite(\'test/segmentation.png\', drawSegmentationImage(pred_s, blackIndex=options.numOutputPlanes))\n                # exit(1)\n                infos.append(info)\n                width_high_res = img_ori.shape[1]\n                height_high_res = img_ori.shape[0]\n                \n                plane_depths = calcPlaneDepths(pred_p, width_high_res, height_high_res, info)\n\n                pred_np_d = np.expand_dims(cv2.resize(pred_np_d.squeeze(), (width_high_res, height_high_res)), -1)\n                all_depths = np.concatenate([plane_depths, pred_np_d], axis=2)\n\n                all_segmentations = np.stack([cv2.resize(all_segmentations[:, :, planeIndex], (width_high_res, height_high_res)) for planeIndex in xrange(all_segmentations.shape[-1])], axis=2)\n                \n                segmentation = np.argmax(all_segmentations, 2)\n                pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(height_high_res * width_high_res), segmentation.reshape(-1)].reshape(height_high_res, width_high_res)\n\n                if \'semantics\' in global_pred:\n                    #cv2.imwrite(\'test/semantics.png\', drawSegmentationImage(np.argmax(global_pred[\'semantics\'][0], axis=-1)))\n                    #exit(1)\n                    predSemantics.append(np.argmax(global_pred[\'semantics\'][0], axis=-1))\n                else:\n                    predSemantics.append(np.zeros((HEIGHT, WIDTH)))\n                    pass\n                                         \n                predDepths.append(pred_d)\n                predPlanes.append(pred_p)\n                predSegmentations.append(all_segmentations)\n                continue\n            pred_dict[\'plane\'] = np.array(predPlanes)\n            pred_dict[\'segmentation\'] = np.array(predSegmentations)\n            pred_dict[\'depth\'] = np.array(predDepths)\n            #pred_dict[\'semantics\'] = np.array(predSemantics)                        \n            pred_dict[\'np_depth\'] = np.array(predNonPlaneDepths)\n            #pred_dict[\'np_normal\'] = np.array(predNonPlaneNormals)\n            pred_dict[\'np_mask\'] = np.array(predNonPlaneMasks)\n            pred_dict[\'image\'] = np.array(images)\n            pred_dict[\'info\'] = np.array(infos)\n            #pred_dict[\'boundary\'] = np.array(predBoundaries)\n            pass\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n        \n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return pred_dict\n\n\n\nif __name__==\'__main__\':\n    """"""\n    Parse input arguments\n    """"""\n    parser = argparse.ArgumentParser(description=\'Planenet\')\n    parser.add_argument(\'--task\', dest=\'task\',\n                        help=\'task type\',\n                        default=\'predict\', type=str)\n    parser.add_argument(\'--numOutputPlanes\', dest=\'numOutputPlanes\',\n                        help=\'the number of output planes\',\n                        default=10, type=int)\n    parser.add_argument(\'--dataset\', dest=\'dataset\',\n                        help=\'dataset name\',\n                        default=\'ScanNet\', type=str)\n    parser.add_argument(\'--hybrid\', dest=\'hybrid\',\n                        help=\'hybrid\',\n                        default=\'3\', type=str)\n    parser.add_argument(\'--visualizeImages\', dest=\'visualizeImages\',\n                        help=\'visualize image\',\n                        default=30, type=int)    \n    parser.add_argument(\'--numImages\', dest=\'numImages\',\n                        help=\'the number of images\',\n                        default=30, type=int)\n    parser.add_argument(\'--startIndex\', dest=\'startIndex\',\n                        help=\'start index\',\n                        default=0, type=int)    \n    parser.add_argument(\'--useCache\', dest=\'useCache\',\n                        help=\'use cache\',\n                        default=0, type=int)\n    parser.add_argument(\'--useNonPlaneDepth\', dest=\'useNonPlaneDepth\',\n                        help=\'use non-plane depth\',\n                        default=0, type=int)\n    parser.add_argument(\'--imageIndex\', dest=\'imageIndex\',\n                        help=\'image index\',\n                        default=-1, type=int)\n    parser.add_argument(\'--methods\', dest=\'methods\',\n                        help=\'methods\',\n                        default=\'0\', type=str)\n    parser.add_argument(\'--applicationType\', dest=\'applicationType\',\n                        help=\'applicationType\',\n                        default=\'\', type=str)\n    parser.add_argument(\'--dataFolder\', dest=\'dataFolder\',\n                        help=\'data folder\',\n                        default=\'\', type=str)\n    parser.add_argument(\'--customImageFolder\', dest=\'customImageFolder\',\n                        help=\'custom image folder\',\n                        default=\'\', type=str)\n    parser.add_argument(\'--textureImageFilename\', dest=\'textureImageFilename\',\n                        help=\'texture image filename, [texture_images/ruler_36.png, texture_images/CVPR.jpg, texture_images/checkerboard.jpg]\',\n                        default=\'\', type=str)\n    parser.add_argument(\'--wallIndices\', dest=\'wallIndices\',\n                        help=\'wall indices for texture copying applications\',\n                        default=\'\', type=str)\n    parser.add_argument(\'--startPixel\', dest=\'startPixel\',\n                        help=\'start pixel for the ruler application\',\n                        default=\'\', type=str)\n    parser.add_argument(\'--endPixel\', dest=\'endPixel\',\n                        help=\'end pixel for the ruler application\',\n                        default=\'\', type=str)\n    parser.add_argument(\'--estimateFocalLength\', dest=\'estimateFocalLength\',\n                        help=\'estimate focal length from vanishing points or use calibrated camera parameters (iPhone 6)\',\n                        default=True, type=bool)\n    \n    args = parser.parse_args()\n    #args.hybrid = \'hybrid\' + args.hybrid\n    args.test_dir = \'predict/\'\n    args.visualizeImages = min(args.visualizeImages, args.numImages)\n\n    #args.titles = [ALL_TITLES[int(method)] for method in args.methods]\n    #args.methods = [ALL_METHODS[int(method)] for method in args.methods]\n    args.titles = ALL_TITLES\n    args.methods = [ALL_METHODS[int(args.methods[0])]]\n    \n    args.result_filename = args.test_dir + \'/results_\' + str(args.startIndex) + \'.npy\'\n\n    #if args.imageIndex >= 0 and args.suffix != \'\':\n    if args.applicationType != \'\':\n        args.test_dir += \'/\' + args.applicationType + \'/\'\n        pass\n    \n    print(args.titles)\n\n    if args.applicationType in [\'video\', \'wall_video\', \'ruler\', \'texture\']:\n        if args.imageIndex < 0:\n            print(\'image index not specified\')\n            exit(1)\n            pass\n        if args.textureImageFilename == \'\':\n            print(\'texture image not specified\')\n            exit(1)\n            pass            \n        pass\n    \n    evaluatePlanes(args)\n'"
train_finetuning.py,92,"b'import tensorflow as tf\nimport numpy as np\nnp.set_printoptions(precision=2, linewidth=200)\nimport cv2\nimport os\nimport time\nimport sys\nimport tf_nndistance\nimport argparse\nimport glob\nimport PIL\nimport scipy.ndimage as ndimage\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom utils import *\nfrom plane_utils import *\nfrom modules import *\n\n\nfrom planenet import PlaneNet\nfrom RecordReader import *\nfrom RecordReaderRGBD import *\nfrom RecordReader3D import *\nfrom RecordReaderAll import *\n#from SegmentationRefinement import *\n\n#training_flag: toggle dropout and batch normalization mode\n#it\'s true for training and false for validation, testing, prediction\n#it also controls which data batch to use (*_train or *_val)\n\n\ndef build_graph(img_inp_train, img_inp_val, training_flag, options):\n    with tf.device(\'/gpu:%d\'%options.gpu_id):\n        img_inp = tf.cond(training_flag, lambda: img_inp_train, lambda: img_inp_val)\n        \n        net = PlaneNet({\'img_inp\': img_inp}, is_training=training_flag, options=options)\n\n        #global predictions\n        plane_pred = net.layers[\'plane_pred\']\n        \n        segmentation_pred = net.layers[\'segmentation_pred\']\n        non_plane_mask_pred = net.layers[\'non_plane_mask_pred\']\n        non_plane_depth_pred = net.layers[\'non_plane_depth_pred\']\n        non_plane_normal_pred = net.layers[\'non_plane_normal_pred\']\n        non_plane_normal_pred = tf.nn.l2_normalize(non_plane_normal_pred, dim=-1)\n\n\n        if False:\n            plane_pred = gt_dict[\'plane\']\n            non_plane_mask_pred = gt_dict[\'non_plane_mask\'] * 10\n            non_plane_depth_pred = gt_dict[\'depth\']\n            non_plane_normal_pred = gt_dict[\'normal\']\n            segmentation_pred = gt_dict[\'segmentation\'][:, :, :, :20] * 10\n            pass\n        \n        \n        global_pred_dict = {\'plane\': plane_pred, \'segmentation\': segmentation_pred, \'non_plane_mask\': non_plane_mask_pred, \'non_plane_depth\': non_plane_depth_pred, \'non_plane_normal\': non_plane_normal_pred}\n\n        if options.predictBoundary:\n            global_pred_dict[\'boundary\'] = net.layers[\'boundary_pred\']\n            pass\n        if options.predictConfidence:\n            global_pred_dict[\'confidence\'] = net.layers[\'plane_confidence_pred\']\n            pass\n        if options.predictSemantics:\n            global_pred_dict[\'semantics\'] = net.layers[\'semantics_pred\']\n            pass\n\n        #local predictions\n        if options.predictLocal:\n            local_pred_dict = {\'score\': net.layers[\'local_score_pred\'], \'plane\': net.layers[\'local_plane_pred\'], \'mask\': net.layers[\'local_mask_pred\']}\n        else:\n            local_pred_dict = {}\n            pass\n\n        \n        #deep supervision\n        deep_pred_dicts = []\n        for layer in options.deepSupervisionLayers:\n            pred_dict = {\'plane\': net.layers[layer+\'_plane_pred\'], \'segmentation\': net.layers[layer+\'_segmentation_pred\'], \'non_plane_mask\': net.layers[layer+\'_non_plane_mask_pred\']}\n            #if options.predictConfidence:\n            #pred_dict[\'confidence\'] = net.layers[layer+\'_plane_confidence_pred\']\n            #pass\n            deep_pred_dicts.append(pred_dict)\n            continue\n\n        \n        if options.anchorPlanes:\n            anchors_np = np.load(\'dump/anchors_\' + options.hybrid + \'.npy\')\n            anchors = tf.reshape(tf.constant(anchors_np.reshape(-1)), anchors_np.shape)\n            anchors = tf.tile(tf.expand_dims(anchors, 0), [options.batchSize, 1, 1])\n            all_pred_dicts = deep_pred_dicts + [global_pred_dict]            \n            for pred_index, pred_dict in enumerate(all_pred_dicts):\n                all_pred_dicts[pred_index][\'plane\'] += anchors\n                continue\n            pass\n\n        pass\n    \n    return global_pred_dict, local_pred_dict, deep_pred_dicts\n\n\ndef build_loss(img_inp_train, img_inp_val, global_pred_dict, deep_pred_dicts, global_gt_dict_train, global_gt_dict_val, training_flag, options):\n    with tf.device(\'/gpu:%d\'%options.gpu_id):\n        debug_dict = {}\n\n        img_inp = tf.cond(training_flag, lambda: img_inp_train, lambda: img_inp_val)        \n        global_gt_dict = {}\n        for name in global_gt_dict_train.keys():\n            global_gt_dict[name] = tf.cond(training_flag, lambda: global_gt_dict_train[name], lambda: global_gt_dict_val[name])\n            continue\n        # local_gt_dict = {}\n        # for name in local_gt_dict_train.keys():\n        #     local_gt_dict[name] = tf.cond(tf.equal(training_flag % 2, 0), lambda: local_gt_dict_train[name], lambda: local_gt_dict_val[name])\n        #     continue\n\n        plane_parameters = tf.reshape(global_pred_dict[\'plane\'], (-1, 3))\n        info = global_gt_dict[\'info\'][0]\n        plane_depths = planeDepthsModule(plane_parameters, WIDTH, HEIGHT, info)\n        plane_depths = tf.transpose(tf.reshape(plane_depths, [HEIGHT, WIDTH, -1, options.numOutputPlanes]), [2, 0, 1, 3])\n\n        non_plane_depth = global_pred_dict[\'non_plane_depth\']\n        all_depths = tf.concat([plane_depths, non_plane_depth], axis=3)\n\n        \n\n        #if options.predictPixelwise == 1:\n        validDepthMask = tf.cast(tf.greater(global_gt_dict[\'depth\'], 1e-4), tf.float32)\n        numValidPixels = tf.reduce_sum(validDepthMask, axis=[1, 2, 3])        \n        depth_loss = tf.constant(0.0)\n        if True:\n            all_segmentations = tf.concat([global_pred_dict[\'segmentation\'], global_pred_dict[\'non_plane_mask\']], axis=3)\n            all_segmentations_softmax = tf.nn.softmax(all_segmentations)\n            depth_loss += tf.reduce_mean(tf.reduce_sum(tf.squared_difference(all_depths, global_gt_dict[\'depth\']) * all_segmentations_softmax, axis=3, keep_dims=True) * validDepthMask) * 10000\n        else:\n            depth_diff = global_pred_dict[\'non_plane_depth\'] - global_gt_dict[\'depth\']\n            depth_diff_gx = depth_diff - tf.concat([tf.ones([options.batchSize, HEIGHT, 1, 1]), depth_diff[:, :, :WIDTH - 1]], axis=2)\n            depth_diff_gy = depth_diff - tf.concat([tf.ones([options.batchSize, 1, WIDTH, 1]), depth_diff[:, :HEIGHT - 1]], axis=1)\n\n            depth_loss += tf.reduce_mean(tf.reduce_sum(tf.pow(depth_diff * validDepthMask, 2), axis=[1, 2, 3]) / numValidPixels - 0.5 * tf.pow(tf.reduce_sum(depth_diff * validDepthMask, axis=[1, 2, 3]) / numValidPixels, 2) + tf.reduce_sum((tf.pow(depth_diff_gx, 2) + tf.pow(depth_diff_gy, 2)) * validDepthMask, axis=[1, 2, 3]) / numValidPixels) * 1000\n            pass\n        \n        #depth_loss += tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_depth\'], global_gt_dict[\'depth\']) * validDepthMask) * 10000\n\n\n        # valid_normal_mask = tf.squeeze(tf.cast(tf.less(tf.slice(global_gt_dict[\'info\'], [0, 19], [options.batchSize, 1]), 2), tf.float32))\n        # normal_gt = tf.nn.l2_normalize(global_gt_dict[\'normal\'], dim=-1)\n        # normal_loss = tf.reduce_mean(tf.reduce_sum(-global_pred_dict[\'non_plane_normal\'] * normal_gt * validDepthMask, axis=[1, 2, 3]) / numValidPixels * valid_normal_mask) * 1000\n        # #normal_loss = tf.reduce_mean(tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_normal\'], global_gt_dict[\'normal\']) * validDepthMask, axis=[1, 2, 3]) * valid_normal_mask) * 1000\n        # valid_semantics_mask = tf.squeeze(tf.cast(tf.not_equal(tf.slice(global_gt_dict[\'info\'], [0, 19], [options.batchSize, 1]), 1), tf.float32))\n        # semantics_loss = tf.reduce_mean(tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=global_pred_dict[\'semantics\'], labels=global_gt_dict[\'semantics\']), axis=[1, 2]) * valid_semantics_mask) * 1000\n\n        normal_loss = tf.constant(0.0)\n        semantics_loss = tf.constant(0.0)        \n\n        l2_losses = tf.add_n([options.l2Weight * tf.nn.l2_loss(v) for v in tf.trainable_variables() if \'weights\' in v.name])\n\n\n        loss = depth_loss + l2_losses\n\n        #if options.pixelwiseLoss:\n        #normal_loss = tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_normal\'], global_gt_dict[\'normal\'])) * 1000\n        #depth_loss = tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_depth\'], global_gt_dict[\'depth\']) * validDepthMask) * 1000\n        #pass\n\n        loss_dict = {\'depth\': depth_loss, \'normal\': normal_loss, \'semantics\': semantics_loss}\n        pass\n    return loss, loss_dict, debug_dict\n\n\ndef main(options):\n    if not os.path.exists(options.checkpoint_dir):\n        os.system(""mkdir -p %s""%options.checkpoint_dir)\n        pass\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n    \n    min_after_dequeue = 1000\n\n\n    train_inputs = []\n    val_inputs = []\n    if \'0\' in options.hybrid:\n        train_inputs.append(options.rootFolder + \'/planes_SUNCG_train.tfrecords\')\n        val_inputs.append(options.rootFolder + \'/planes_SUNCG_val.tfrecords\')        \n        pass\n    if \'1\' in options.hybrid:\n        for _ in xrange(10):\n            train_inputs.append(options.rootFolder + \'/planes_nyu_rgbd_train.tfrecords\')\n            train_inputs.append(options.rootFolder + \'/planes_nyu_rgbd_labeled_train.tfrecords\')\n            val_inputs.append(options.rootFolder + \'/planes_nyu_rgbd_val.tfrecords\')\n            continue\n        pass\n    if \'2\' in options.hybrid:\n        train_inputs.append(options.rootFolder + \'/planes_matterport_train.tfrecords\')\n        val_inputs.append(options.rootFolder + \'/planes_matterport_val.tfrecords\')\n        pass\n    if \'3\' in options.hybrid:\n        train_inputs.append(options.rootFolder + \'/planes_scannet_train.tfrecords\')\n        val_inputs.append(options.rootFolder + \'/planes_scannet_val.tfrecords\')\n        pass\n    \n    reader_train = RecordReaderAll()\n    filename_queue_train = tf.train.string_input_producer(train_inputs, num_epochs=10000)    \n    img_inp_train, global_gt_dict_train, local_gt_dict_train = reader_train.getBatch(filename_queue_train, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True)\n\n    reader_val = RecordReaderAll()\n    filename_queue_val = tf.train.string_input_producer(val_inputs, num_epochs=10000)\n    img_inp_val, global_gt_dict_val, local_gt_dict_val = reader_val.getBatch(filename_queue_val, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True)\n    \n    training_flag = tf.placeholder(tf.bool, shape=[], name=\'training_flag\')\n    \n    #global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp_train, img_inp_val, img_inp_rgbd_train, img_inp_rgbd_val, img_inp_3d_train, img_inp_3d_val, training_flag, options)\n    global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp_train, img_inp_val, training_flag, options)\n    \n    \n    #loss, loss_dict, _ = build_loss(global_pred_dict, local_pred_dict, deep_pred_dicts, global_gt_dict_train, local_gt_dict_train, global_gt_dict_val, local_gt_dict_val, training_flag, options)\n    #loss_rgbd, loss_dict_rgbd, _ = build_loss_rgbd(global_pred_dict, deep_pred_dicts, global_gt_dict_rgbd_train, global_gt_dict_rgbd_val, training_flag, options)\n    loss, loss_dict, _ = build_loss(img_inp_train, img_inp_val, global_pred_dict, deep_pred_dicts, global_gt_dict_train, global_gt_dict_val, training_flag, options)    \n        \n    #loss = tf.cond(tf.less(training_flag, 2), lambda: loss, lambda: tf.cond(tf.less(training_flag, 4), lambda: loss_rgbd, lambda: loss_3d))\n\n    \n    #train_writer = tf.summary.FileWriter(options.log_dir + \'/train\')\n    #val_writer = tf.summary.FileWriter(options.log_dir + \'/val\')\n    #train_writer_rgbd = tf.summary.FileWriter(options.log_dir + \'/train_rgbd\')\n    #val_writer_rgbd = tf.summary.FileWriter(options.log_dir + \'/val_rgbd\')\n    #writers = [train_writer, val_writer, train_writer_rgbd, val_writer_rgbd]\n    \n\n    with tf.variable_scope(\'statistics\'):\n        batchno = tf.Variable(0, dtype=tf.int32, trainable=False, name=\'batchno\')\n        batchnoinc=batchno.assign(batchno+1)\n        pass\n\n\n    optimizer = tf.train.AdamOptimizer(options.LR)\n    train_op = optimizer.minimize(loss, global_step=batchno)\n\n    var_to_restore = [v for v in tf.global_variables()]\n\n    tf.summary.scalar(\'loss\', loss)\n    summary_op = tf.summary.merge_all()\n\n    \n    config=tf.ConfigProto()\n    config.allow_soft_placement=True    \n    #config.gpu_options.allow_growth=True\n    config.gpu_options.per_process_gpu_memory_fraction=0.9\n    saver=tf.train.Saver()\n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n    \n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n        if options.restore == 0:\n            #fine-tune from DeepLab model\n            var_to_restore = [v for v in var_to_restore if \'res5d\' not in v.name and \'segmentation\' not in v.name and \'plane\' not in v.name and \'deep_supervision\' not in v.name and \'local\' not in v.name and \'boundary\' not in v.name and \'degridding\' not in v.name and \'res2a_branch2a\' not in v.name and \'res2a_branch1\' not in v.name and \'Adam\' not in v.name and \'beta\' not in v.name and \'statistics\' not in v.name and \'semantics\' not in v.name]\n            pretrained_model_loader = tf.train.Saver(var_to_restore)\n            pretrained_model_loader.restore(sess,""../pretrained_models/deeplab_resnet.ckpt"")\n        elif options.restore == 1:\n            #restore the same model from checkpoint\n            loader = tf.train.Saver(var_to_restore)\n            loader.restore(sess,""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n            bno=sess.run(batchno)\n            print(bno)\n        elif options.restore == 2:            \n            #restore the same model from checkpoint but reset batchno to 1\n            loader = tf.train.Saver(var_to_restore)\n            loader.restore(sess,""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n            sess.run(batchno.assign(1))\n        elif options.restore == 3:            \n            #restore the same model from standard training\n            # if options.predictBoundary == 1:\n            #     var_to_restore = [v for v in var_to_restore if \'boundary\' not in v.name]\n            #     pass            \n            # if options.predictConfidence == 1:\n            #     var_to_restore = [v for v in var_to_restore if \'confidence\' not in v.name]\n            #     pass\n            if options.predictSemantics == 1:\n                var_to_restore = [v for v in var_to_restore if \'semantics\' not in v.name]\n                pass\n            loader = tf.train.Saver(var_to_restore)\n            #loader.restore(sess, options.rootFolder + \'/checkpoint/planenet_hybrid\' + hybrid + \'_bl0_ll1_bw0.5_pb_pp_ps_sm0/checkpoint.ckpt\')\n            loader.restore(sess, options.rootFolder + \'/checkpoint/planenet_hybrid3_bl0_dl0_ll1_pb_pp_sm0/checkpoint.ckpt\')            \n            #loader.restore(sess,""checkpoint/planenet/checkpoint.ckpt"")\n            sess.run(batchno.assign(1))\n        elif options.restore == 4:\n            #fine-tune another model\n            #var_to_restore = [v for v in var_to_restore if \'res4b22_relu_non_plane\' not in v.name]\n            loader = tf.train.Saver(var_to_restore)\n            loader.restore(sess, options.fineTuningCheckpoint)\n            sess.run(batchno.assign(1))\n            pass\n        # Start input enqueue threads.\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n        MOVING_AVERAGE_DECAY = 0.99\n        ema = [0., 0., 0., 0.]\n        ema_acc = [1e-10, 1e-10, 1e-10, 1e-10]\n        last_snapshot_time = time.time()\n        bno=sess.run(batchno)\n\n        try:\n            while bno<300000:\n                t0 = time.time()\n\n                batchIndexPeriod = bno % 100\n                if batchIndexPeriod < len(options.hybrid):\n                    #batchType = int(options.hybrid[batchIndexPeriod]) * 2 + 1\n                    batchType = 1\n                    _, total_loss, losses, summary_str, gt_dict = sess.run([batchnoinc, loss, loss_dict, summary_op, global_pred_dict], feed_dict = {training_flag: batchType == 0})\n                    \n                else:\n                    batchType = 0\n                    _, total_loss, losses, summary_str, gt_dict = sess.run([train_op, loss, loss_dict, summary_op, global_pred_dict], feed_dict = {training_flag: batchType == 0})\n                    pass\n\n                # for batchIndex in xrange(options.batchSize):\n                #     if np.isnan(global_gt[\'plane\'][batchIndex]).any():\n                #         #print(losses)\n                #         #print(global_gt[\'plane\'][batchIndex])\n                #         print(global_gt[\'num_planes\'][batchIndex])\n                #         for planeIndex in xrange(global_gt[\'num_planes\'][batchIndex]):\n                #             cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(global_gt[\'segmentation\'][batchIndex, :, :, planeIndex]))\n                #             continue\n                #         np.save(\'temp/plane.npy\', global_gt[\'plane\'][batchIndex])                        \n                #         np.save(\'temp/depth.npy\', global_gt[\'depth\'][batchIndex])\n                #         np.save(\'temp/segmentation.npy\', global_gt[\'segmentation\'][batchIndex])\n                #         np.save(\'temp/info.npy\', global_gt[\'info\'][batchIndex])\n                #         np.save(\'temp/num_planes.npy\', global_gt[\'num_planes\'][batchIndex])\n                #         planes, segmentation, numPlanes = removeSmallSegments(global_gt[\'plane\'][batchIndex], np.zeros((HEIGHT, WIDTH, 3)), global_gt[\'depth\'][batchIndex].squeeze(), np.zeros((HEIGHT, WIDTH, 3)), np.argmax(global_gt[\'segmentation\'][batchIndex], axis=-1), global_gt[\'semantics\'][batchIndex], global_gt[\'info\'][batchIndex], global_gt[\'num_planes\'][batchIndex])\n                #         print(planes)\n                #         exit(1)\n                #         pass\n                #     continue\n                #writers[batchType].add_summary(summary_str, bno)\n                ema[batchType] = ema[batchType] * MOVING_AVERAGE_DECAY + total_loss\n                ema_acc[batchType] = ema_acc[batchType] * MOVING_AVERAGE_DECAY + 1\n\n                bno = sess.run(batchno)\n                if time.time()-last_snapshot_time > options.saveInterval:\n                    print(\'save snapshot\')\n                    saver.save(sess,\'%s/checkpoint.ckpt\'%options.checkpoint_dir)\n                    last_snapshot_time = time.time()\n                    pass\n        \n                print bno,\'train\', ema[0] / ema_acc[0], \'val\', ema[1] / ema_acc[1], \'train rgbd\', ema[2] / ema_acc[2], \'val rgbd\', ema[3] / ema_acc[3], \'loss\', total_loss, \'time\', time.time()-t0\n\n                if np.random.random() < 0.01:\n                    print(losses)\n                    pass                \n                continue\n\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n        \n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return\n\n\ndef test(options):\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n\n    if options.dataset == \'\':\n        assert(len(options.hybrid) == 1)\n        if options.hybrid == \'0\':\n            options.dataset = \'SUNCG\'\n        elif options.hybrid == \'1\':\n            options.dataset = \'NYU_RGBD\'\n        elif options.hybrid == \'2\':\n            options.dataset = \'matterport\'\n        elif options.hybrid == \'3\':\n            options.dataset = \'ScanNet\'\n            \n        options.dataset\n    options.batchSize = 1\n    min_after_dequeue = 1000\n\n    reader = RecordReaderAll()\n    if options.dataset == \'SUNCG\':\n        filename_queue = tf.train.string_input_producer([options.rootFolder + \'/planes_SUNCG_val.tfrecords\'], num_epochs=10000)\n    elif options.dataset == \'NYU_RGBD\':\n        filename_queue = tf.train.string_input_producer([options.rootFolder + \'/planes_nyu_rgbd_val.tfrecords\'], num_epochs=1)\n        options.deepSupervision = 0\n        options.predictLocal = 0\n    elif options.dataset == \'matterport\':\n        filename_queue = tf.train.string_input_producer([options.rootFolder + \'/planes_matterport_val.tfrecords\'], num_epochs=1)\n    else:\n        filename_queue = tf.train.string_input_producer([options.rootFolder + \'/planes_scannet_train.tfrecords\'], num_epochs=1)\n        pass\n    img_inp, global_gt_dict, local_gt_dict = reader.getBatch(filename_queue, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True, random=False)\n\n    training_flag = tf.constant(False, tf.bool)\n\n    global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp, img_inp, global_gt_dict, training_flag, options)\n    var_to_restore = tf.global_variables()\n\n    loss, loss_dict, debug_dict = build_loss(img_inp, img_inp, global_pred_dict, deep_pred_dicts, global_gt_dict, global_gt_dict, training_flag, options)\n    \n\n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n    \n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n        #var_to_restore = [v for v in var_to_restore if \'res4b22_relu_non_plane\' not in v.name]\n        loader = tf.train.Saver(var_to_restore)\n        loader.restore(sess, ""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n        #loader.restore(sess, ""%s/checkpoint.ckpt""%(\'checkpoint/planenet_pb_pp_hybrid1\'))\n        #loader.restore(sess, options.fineTuningCheckpoint)\n        \n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n        \n        \n        try:\n            gtDepths = []\n            predDepths = []\n            planeMasks = []\n            #predMasks = []\n            gtPlanes = []\n            predPlanes = []\n            gtSegmentations = []\n            predSegmentations = []\n            gtNumPlanes = []\n            \n            imageWidth = WIDTH\n            imageHeight = HEIGHT\n            focalLength = 517.97\n            urange = np.arange(imageWidth).reshape(1, -1).repeat(imageHeight, 0) - imageWidth * 0.5\n            vrange = np.arange(imageHeight).reshape(-1, 1).repeat(imageWidth, 1) - imageHeight * 0.5\n            ranges = np.array([urange / imageWidth * 640 / focalLength, np.ones(urange.shape), -vrange / imageHeight * 480 / focalLength]).transpose([1, 2, 0])\n\n\n            for index in xrange(10):\n                print((\'image\', index))\n                t0=time.time()\n\n                img, global_gt, local_gt, global_pred, local_pred, deep_preds, total_loss, losses, debug = sess.run([img_inp, global_gt_dict, local_gt_dict, global_pred_dict, local_pred_dict, deep_pred_dicts, loss, loss_dict, debug_dict])\n\n                # print(options.test_dir)\n                # cv2.imwrite(options.test_dir + \'/depth.png\', drawDepthImage(debug[\'depth\'][0]))\n                # cv2.imwrite(options.test_dir + \'/normal.png\', drawNormalImage(debug[\'normal\'][0]))\n                # boundary = debug[\'boundary\'][0]\n                # boundary = np.concatenate([boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)\n                # cv2.imwrite(options.test_dir + \'/boundary.png\', drawMaskImage(boundary))\n                # cv2.imwrite(options.test_dir + \'/depth_gt.png\', drawDepthImage(debug[\'depth_gt\'][0].squeeze()))\n                # exit(1)\n\n                if \'pixelwise\' in options.suffix or True:\n                    image = ((img[0] + 0.5) * 255).astype(np.uint8)\n                    gt_d = global_gt[\'depth\'].squeeze()\n                    pred_d = global_pred[\'non_plane_depth\'].squeeze()\n                    #depth = global_gt[\'depth\'].squeeze()\n                    if \'_2\' in options.suffix:\n                        pred_p, pred_s, pred_d = fitPlanes(pred_d, numPlanes=20, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=0.2)\n                    elif \'_3\' in options.suffix:\n                        pred_p, pred_s, pred_d = fitPlanes(gt_d, numPlanes=20, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=0.2)\n                        pass\n\n                    # gt_p = global_gt[\'plane\'][0]\n                    # pred_p = planes\n                    # valid_mask = (np.linalg.norm(gt_p, axis=1) > 0).astype(np.float32)\n                    # diff = np.min(np.linalg.norm(np.expand_dims(gt_p, 1) - np.expand_dims(pred_p, 0), axis=2), 1)\n                    # num += valid_mask.sum()\n                    # lossSum += (diff * valid_mask).sum()\n                    if options.dataset == \'SUNCG\':\n                        planeMask = np.squeeze(debug[\'segmentation\']).sum(axis=2)\n                    else:\n                        planeMask = np.ones((HEIGHT, WIDTH))\n                        if \'_2\' in options.suffix or \'_3\' in options.suffix:\n                            planeMask *= (pred_s < 20).astype(np.float32)\n                        pass\n                    \n                    if index < 10:\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', image)\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth.png\', drawDepthImage(gt_d))\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n                        if \'_2\' in options.suffix or \'_3\' in options.suffix:\n                            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(pred_s))\n                            pass\n                        #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_plane_mask.png\', drawMaskImage(planeMask))                \n                        pass\n\n                        \n                    gtDepths.append(gt_d)\n                    predDepths.append(pred_d)\n                    planeMasks.append(planeMask)\n\n\n                    if options.dataset != \'NYU_RGBD\' and (\'_2\' in options.suffix or \'_3\' in options.suffix):\n                        gt_p = global_gt[\'plane\'][0]\n                        gt_s = global_gt[\'segmentation\'][0]\n                        gt_num_p = global_gt[\'num_planes\'][0]\n\n                        pred_s = (np.expand_dims(pred_s, -1) == np.reshape(np.arange(options.numOutputPlanes), [1, 1, -1])).astype(np.float32)\n                        gtPlanes.append(gt_p)\n                        predPlanes.append(pred_p)\n                        gtSegmentations.append(gt_s)\n                        gtNumPlanes.append(gt_num_p)\n                        predSegmentations.append(pred_s)\n                        pass\n                    \n                    #planeMasks.append((planeSegmentation < 20).astype(np.float32))\n                    continue\n                \n                print(losses)\n                print(total_loss)\n                #print(losses)\n                #exit(1)\n                im = img[0]\n                image = ((im + 0.5) * 255).astype(np.uint8)                \n\n                gt_d = global_gt[\'depth\'].squeeze()\n                                \n\n                if options.predictLocal:\n                    pred_local_s = 1 / (1 + np.exp(-local_pred[\'score\'][0]))\n                    pred_local_p = local_pred[\'plane\'][0]\n                    pred_local_m = local_pred[\'mask\'][0]\n                  \n                    gt_local_s = local_gt[\'score\'][0]\n                    gt_local_m = local_gt[\'mask\'][0]\n\n                    #visualize local plane prediction\n                    stride = 8\n                    boxSize = 64\n                    xs = np.arange(WIDTH / stride) * stride + stride / 2\n                    ys = np.arange(HEIGHT / stride) * stride + stride / 2\n                    padding = boxSize / 2 + 1\n                    maskImage = np.zeros((HEIGHT + padding * 2, WIDTH + padding * 2, 3), dtype=np.uint8)\n                    maskImage[padding:padding + HEIGHT, padding:padding + WIDTH, :] = image / 2\n                    for gridY, y in enumerate(ys):\n                        for gridX, x in enumerate(xs):\n                            score = pred_local_s[gridY][gridX]\n                            if score < 0.5:\n                                continue                              \n                            mask = pred_local_m[gridY][gridX].reshape([16, 16])        \n                            mask = cv2.resize(mask, (boxSize, boxSize))\n                            maskImage[y - boxSize / 2 + padding:y + boxSize / 2 + padding, x - boxSize / 2 + padding:x + boxSize / 2 + padding, 0][mask > 0.5] = 255\n                            continue\n                        continue\n                    for gridY, y in enumerate(ys):\n                        for gridX, x in enumerate(xs):\n                            score = gt_local_s[gridY][gridX]\n                            if score < 0.5:\n                                continue                              \n                            mask = gt_local_m[gridY][gridX].reshape([16, 16])        \n                            mask = cv2.resize(mask, (boxSize, boxSize))\n                            maskImage[y - boxSize / 2 + padding:y + boxSize / 2 + padding, x - boxSize / 2 + padding:x + boxSize / 2 + padding, 2][mask > 0.5] = 255\n                            continue\n                        continue\n                    pass\n\n                pred_p = global_pred[\'plane\'][0]\n                pred_s = global_pred[\'segmentation\'][0]\n\n                pred_np_m = global_pred[\'non_plane_mask\'][0]\n                pred_np_d = global_pred[\'non_plane_depth\'][0]\n                pred_np_n = global_pred[\'non_plane_normal\'][0]\n                \n                planeMask = 1 - global_gt[\'non_plane_mask\'][0]\n                info = global_gt[\'info\'][0]\n\n                \n                all_segmentations = np.concatenate([pred_s, pred_np_m], axis=2)\n                all_segmentations_softmax = softmax(all_segmentations)\n                segmentation = np.argmax(all_segmentations, 2)\n                \n                \n                #pred_p, segmentation, numPlanes = mergePlanes(global_gt[\'plane\'][0], np.concatenate([global_gt[\'segmentation\'][0], global_gt[\'non_plane_mask\'][0]], axis=2), global_gt[\'depth\'][0].squeeze(), global_gt[\'info\'][0], np.concatenate([pred_s, pred_np_m], axis=2))\n                \n\n                plane_depths = calcPlaneDepths(pred_p, WIDTH, HEIGHT, info)\n                all_depths = np.concatenate([plane_depths, pred_np_d], axis=2)\n                \n                pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape(HEIGHT, WIDTH)\n\n                plane_normals = calcPlaneNormals(pred_p, WIDTH, HEIGHT)\n                all_normals = np.concatenate([plane_normals, np.expand_dims(pred_np_n, 2)], axis=2)\n                pred_n = np.sum(all_normals * np.expand_dims(one_hot(segmentation, options.numOutputPlanes+1), -1), 2)\n                #pred_n = all_normals.reshape(-1, options.numOutputPlanes + 1, 3)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape((HEIGHT, WIDTH, 3))\n                \n\n                if False:\n                    gt_s = global_gt[\'segmentation\'][0]\n                    all_segmentations = np.concatenate([gt_s, 1 - planeMask], axis=2)\n                    gt_p = global_gt[\'plane\'][0]\n\n                    # valid_mask = (np.linalg.norm(gt_p, axis=1) > 0).astype(np.float32)\n                    # diff = np.min(np.linalg.norm(np.expand_dims(gt_p, 1) - np.expand_dims(pred_p, 0), axis=2), 1)\n                    # num += valid_mask.sum()\n                    # lossSum += (diff * valid_mask).sum()\n                    #gt_p = np.stack([-gt_p[:, 0], -gt_p[:, 2], -gt_p[:, 1]], axis=1)\n                    \n                    plane_depths = calcPlaneDepths(gt_p, WIDTH, HEIGHT, info)\n                    all_depths = np.concatenate([plane_depths, pred_np_d], axis=2)\n\n                    segmentation = np.argmax(all_segmentations, 2)\n                    pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape(HEIGHT, WIDTH)\n                    # print(gt_p)\n                    # for segmentIndex in xrange(options.numOutputPlanes):\n                    #     cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_mask_\' + str(segmentIndex) + \'.png\', drawMaskImage(segmentation == segmentIndex))\n                    #     continue\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n                    #exit(1)\n                    pass\n\n                \n\n                gt_p = global_gt[\'plane\'][0]\n                gt_s = global_gt[\'segmentation\'][0]\n                gt_num_p = global_gt[\'num_planes\'][0]\n                gtPlanes.append(gt_p)\n                predPlanes.append(pred_p)\n                gtSegmentations.append(gt_s)\n                gtNumPlanes.append(gt_num_p)\n                predSegmentations.append(pred_s)\n                \n            \n                gtDepths.append(gt_d)\n                planeMasks.append(planeMask.squeeze())\n                predDepths.append(pred_d)\n                evaluateDepths(predDepths[-1], gtDepths[-1], gtDepths[-1] > 0, planeMasks[-1])\n                \n                \n                if index >= 10:\n                    continue\n\n                if options.predictSemantics:\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_semantics_pred.png\', drawSegmentationImage(global_pred[\'semantics\'][0], blackIndex=0))\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_semantics_gt.png\', drawSegmentationImage(global_gt[\'semantics\'][0], blackIndex=0))\n                    pass\n\n                if \'cost_mask\' in debug:\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_cost_mask.png\', drawMaskImage(np.sum(debug[\'cost_mask\'][0], axis=-1)))\n\n                    for planeIndex in xrange(options.numOutputPlanes + 1):\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_cost_mask_\' + str(planeIndex) + \'.png\', drawMaskImage(debug[\'cost_mask\'][0, :, :, planeIndex]))\n                        continue\n                    all_segmentations = np.concatenate([pred_s, pred_np_m], axis=2)\n                    for planeIndex in xrange(options.numOutputPlanes + 1):\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred_\' + str(planeIndex) + \'.png\', drawMaskImage(all_segmentations[:, :, planeIndex]))\n                        continue\n                    exit(1)\n                    pass\n                \n                if \'normal\' in global_gt:\n                    gt_n = global_gt[\'normal\'][0]\n                    norm = np.linalg.norm(gt_n, axis=-1, keepdims=True)\n                    gt_n /= np.maximum(norm, 1e-4)\n                    \n                    #gt_n = np.stack([-gt_n[:, :, 0], -gt_n[:, :, 2], -gt_n[:, :, 1]], axis=2)\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_gt.png\', drawNormalImage(gt_n))\n                    #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_pred.png\', drawNormalImage(pred_np_n))\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_pred.png\', drawNormalImage(pred_n))\n                    pass\n                \n                if \'segmentation\' in global_gt:\n                    gt_s = global_gt[\'segmentation\'][0]\n                    gt_p = global_gt[\'plane\'][0]\n\n                    \n                    #for planeIndex in xrange(20):\n                    #cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(gt_s[:, :, planeIndex]))\n                    #continue\n                    \n                    \n                    # print(gt_p)\n                    # print(gt_n[109][129])\n                    # print(gt_n[166][245])\n                    # print(gt_s[109][129])\n                    # print(gt_s[166][245])\n                    # print(plane_normals[109][129])\n                    # print(plane_normals[166][245])                    \n                    # for planeIndex in xrange(20):\n                    #     cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(gt_s[:, :, planeIndex]))\n                    #     continue\n                    # exit(1)\n                    \n                    gt_s, gt_p = sortSegmentations(gt_s, gt_p, pred_p)\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_plane_mask_gt.png\', drawMaskImage(planeMask))  \n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_gt.png\', drawSegmentationImage(np.concatenate([gt_s, 1 - planeMask], axis=2), blackIndex=options.numOutputPlanes)\n)\n                    #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_test.png\', drawMaskImage(np.sum(np.concatenate([gt_s, 1 - planeMask], axis=2), axis=2)))\n                    #exit(1)\n                    #exit(1)\n                    pass\n\n\n                if options.predictConfidence == 1 and options.dataset == \'SUNCG\':\n                    assert(False)\n                    pred_p_c = global_pred[\'confidence\'][0]\n                    pred_p_c = 1 / (1 + np.exp(-pred_p_c))\n                    #print(pred_p_c)\n                    # print(losses)\n                    # print(debug[\'plane\'][0])\n                    # print(pred_p)\n                    # exit(1)\n                    numPlanes = global_gt[\'num_planes\'][0]\n                    print((numPlanes, (pred_p_c > 0.5).sum()))\n                    \n                    pred_p_c = (pred_p_c > 0.5).astype(np.float32)\n                    pred_p *= pred_p_c\n                    pred_s -= (1 - pred_p_c.reshape([1, 1, options.numOutputPlanes])) * 10\n                    pass\n                  \n                if False:\n                    #dump results for post processing\n                    if index >= 10:\n                        break\n                    np.save(options.dump_dir + \'/planes_\' + str(index) + \'.npy\', pred_p)\n                    np.save(options.dump_dir + \'/segmentations_\' + str(index) + \'.npy\', pred_s)\n                    np.save(options.dump_dir + \'/segmentations_gt_\' + str(index) + \'.npy\', gt_s)\n                    np.save(options.dump_dir + \'/non_plane_depth_\' + str(index) + \'.npy\', pred_np_d)\n                    np.save(options.dump_dir + \'/non_plane_segmentation_\' + str(index) + \'.npy\', pred_np_m)\n                    boundary = pred_boundary[0]\n                    boundary = 1 / (1 + np.exp(-boundary))\n                    boundary = np.concatenate([boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)                    \n                    cv2.imwrite(options.dump_dir + \'/boundary_\' + str(index) + \'.png\', drawMaskImage(boundary))\n                    cv2.imwrite(options.dump_dir + \'/image_\' + str(index) + \'.png\', cv2.resize(image, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR))\n                    np.save(options.dump_dir + \'/depth_\' + str(index) + \'.npy\', gt_d)\n                    continue                \n\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', image)\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth.png\', drawDepthImage(gt_d))\n                #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_overlay.png\', drawDepthImageOverlay(image, gt_d))\n                \n                if options.predictBoundary:\n                    pred_boundary = global_pred[\'boundary\'][0]\n                    pred_boundary = 1 / (1 + np.exp(-pred_boundary))\n                    boundary = np.concatenate([pred_boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_boundary_pred.png\', drawMaskImage(boundary))\n                    pass\n\n                if \'boundary\' in global_gt:\n                    gt_boundary = global_gt[\'boundary\'][0]\n                    boundary = np.concatenate([gt_boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)                \n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_boundary_gt.png\', drawMaskImage(boundary))\n                    pass\n\n                for layerIndex, layer in enumerate(options.deepSupervisionLayers):\n                    segmentation_deep = np.argmax(deep_preds[layerIndex][\'segmentation\'][0], 2)\n                    segmentation_deep[segmentation_deep == options.numOutputPlanes] = -1\n                    segmentation_deep += 1\n                \n                    plane_depths_deep = calcPlaneDepths(deep_preds[layerIndex][\'plane\'][0], WIDTH, HEIGHT, info)\n                    all_depths_deep = np.concatenate([pred_np_d, plane_depths_deep], axis=2)\n                    pred_d_deep = all_depths_deep.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation_deep.reshape(-1)].reshape(HEIGHT, WIDTH)\n                \n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred_\' + str(layerIndex) + \'.png\', drawSegmentationImage(deep_preds[layerIndex][\'segmentation\'][0]))\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred_\' + str(layerIndex) + \'.png\', drawDepthImage(pred_d_deep))\n                    pass\n\n\n                #print(pred_np_m)\n                #print(pred_s)\n                #print(global_gt[\'plane\'][0])\n                #print(pred_p)\n                #exit(1)\n\n                print(\'depth diff\', np.abs(pred_d - gt_d).mean())\n                \n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(all_segmentations, blackIndex=options.numOutputPlanes))\n                #exit(1)\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_diff.png\', drawMaskImage(np.abs(pred_d - gt_d) * planeMask.squeeze() / 0.2))\n                #exit(1)\n                \n                \n                #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_plane_mask.png\', drawMaskImage(planeMask))           \n\n                #print(np.concatenate([np.arange(options.numOutputPlanes).reshape(-1, 1), planes, pred_p, preds_p[0][0]], axis=1))\n\n                #print(np.concatenate([distance[0], preds_p[0][0], pred_p], axis=1))\n                            \n                #segmentation = np.argmax(pred_s, 2)\n                #writePLYFile(options.test_dir, index, image, pred_d, segmentation, np.zeros(pred_boundary[0].shape))\n                #writePLYFileParts(options.test_dir, index, image, pred_d, segmentation)\n                #gt_s_ori = gt_s_ori[0]\n\n\n                # if \'depth\' in debug:\n                #     cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred_1.png\', drawDepthImage(debug[\'depth\'][0]))\n                #     gt_s_ori = debug[\'segmentation\'][0]\n                #     cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_gt.png\', drawSegmentationImage(gt_s_ori, blackIndex=options.numOutputPlanes))\n                #     total_loss = 0\n                #     for planeIndex in xrange(gt_s_ori.shape[-1]):\n                #         mask_pred = all_segmentations_softmax[:, :, planeIndex]\n                #         loss = -(gt_s_ori[:, :, planeIndex] * np.log(np.maximum(all_segmentations_softmax[:, :, planeIndex], 1e-31))).mean() * 1000\n                #         print(planeIndex, loss)\n                #         total_loss += loss\n                #         cv2.imwrite(options.test_dir + \'/mask_pred_\' + str(planeIndex) + \'.png\', drawMaskImage(mask_pred))\n                #         cv2.imwrite(options.test_dir + \'/mask_gt_\' + str(planeIndex) + \'.png\', drawMaskImage(gt_s_ori[:, :, planeIndex]))\n                #         continue\n                #     print(total_loss)\n                #     print(gt_s_ori.sum(2).max())                    \n                #     exit(1)\n                #     pass\n\n                \n                if False:\n                    #distance = distance[0]\n                    print(distance)\n                    diff = np.linalg.norm(np.expand_dims(planes, 1) - np.expand_dims(pred_p, 0), axis=2)\n                    print(np.concatenate([planes, pred_p, pow(np.min(diff, axis=1, keepdims=True), 2), np.expand_dims(np.argmin(diff, axis=1), -1)], axis=1))\n                    print(pred_p_c)\n                    \n                    #print(distance[:, 6:8].sum(0))\n                    #print(pow(np.linalg.norm(distance[:, :3] - distance[:, 3:6], 2, 1), 2) * 100)\n                    #print(test)\n                    segmentation = np.argmax(all_segmentations, 2) - 1\n                    for planeIndex in xrange(options.numOutputPlanes):\n                        cv2.imwrite(options.test_dir + \'/segmentation_\' + str(planeIndex) + \'.png\', drawMaskImage(segmentation == planeIndex))\n                        cv2.imwrite(options.test_dir + \'/segmentation_\' + str(planeIndex) + \'_gt.png\', drawMaskImage(gt_s[:, :, planeIndex]))\n                        cv2.imwrite(options.test_dir + \'/segmentation_\' + str(planeIndex) + \'_gt_ori.png\', drawMaskImage(gt_s_ori[:, :, planeIndex]))\n                        continue\n                    exit(1)\n                continue\n\n            # if options.dataset == \'SUNCG\':\n            #     if \'pixelwise\' not in options.suffix:\n            #         evaluatePlaneSegmentation(np.array(predPlanes), np.array(predSegmentations), np.array(gtPlanes), np.array(gtSegmentations), np.array(gtNumPlanes), planeDistanceThreshold = 0.3, IOUThreshold = 0.5, prefix=\'test/planenet_\')\n            #     elif \'_2\' in options.suffix:\n            #         evaluatePlaneSegmentation(np.array(predPlanes), np.array(predSegmentations), np.array(gtPlanes), np.array(gtSegmentations), np.array(gtNumPlanes), planeDistanceThreshold = 0.3, IOUThreshold = 0.5, prefix=\'test/pixelwise_pred_\')\n            #     elif \'_3\' in options.suffix:\n            #         evaluatePlaneSegmentation(np.array(predPlanes), np.array(predSegmentations), np.array(gtPlanes), np.array(gtSegmentations), np.array(gtNumPlanes), planeDistanceThreshold = 0.3, IOUThreshold = 0.5, prefix=\'test/pixelwise_gt_\')\n            #         pass\n            #     pass\n            \n            predDepths = np.array(predDepths)\n            gtDepths = np.array(gtDepths)\n            planeMasks = np.array(planeMasks)\n            #predMasks = np.array(predMasks)\n            evaluateDepths(predDepths, gtDepths, gtDepths > 0, planeMasks)\n            exit(1)\n\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n        \n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return\n\n\n# def predict(options):\n#     options.test_dir += \'_predict\'\n#     if not os.path.exists(options.test_dir):\n#         os.system(""mkdir -p %s""%options.test_dir)\n#         pass\n\n#     batchSize = 1\n#     img_inp = tf.placeholder(tf.float32,shape=(batchSize,HEIGHT,WIDTH,3),name=\'img_inp\')\n#     plane_gt=tf.placeholder(tf.float32,shape=(batchSize,options.numOutputPlanes, 3),name=\'plane_inp\')\n#     validating_inp = tf.constant(0, tf.int32)\n\n#     global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp_train, img_inp_val, img_inp_rgbd_train, img_inp_rgbd_val, training_flag, options)\n\n#     var_to_restore = tf.global_variables()\n    \n \n#     config=tf.ConfigProto()\n#     config.gpu_options.allow_growth=True\n#     config.allow_soft_placement=True\n\n\n#     if dataset == \'SUNCG\':\n#         image_list_file = os.path.join(\'../PythonScripts/SUNCG/image_list_100_tail_500000.txt\')\n#         with open(image_list_file) as f:\n#             im_names = [{\'image\': im_name.strip().replace(\'plane_global.npy\', \'mlt.png\'), \'depth\': im_name.strip().replace(\'plane_global.npy\', \'depth.png\'), \'normal\': im_name.strip().replace(\'plane_global.npy\', \'norm_camera.png\'), \'valid\': im_name.strip().replace(\'plane_global.npy\', \'valid.png\'), \'plane\': im_name.strip()} for im_name in f.readlines()]\n#             pass\n#     else:\n#         im_names = glob.glob(\'../../Data/NYU_RGBD/*_color.png\')\n#         im_names = [{\'image\': im_name, \'depth\': im_name.replace(\'color.png\', \'depth.png\'), \'normal\': im_name.replace(\'color.png\', \'norm_camera.png\'), \'invalid_mask\': im_name.replace(\'color.png\', \'valid.png\')} for im_name in im_names]\n#         pass\n      \n#     if numImages > 0:\n#         im_names = im_names[:numImages]\n#         pass\n\n#     #if args.imageIndex > 0:\n#     #im_names = im_names[args.imageIndex:args.imageIndex + 1]\n#     #pass    \n\n#     init_op = tf.group(tf.global_variables_initializer(),\n#                        tf.local_variables_initializer())\n\n\n#     with tf.Session(config=config) as sess:\n#         saver = tf.train.Saver()\n#         #sess.run(tf.global_variables_initializer())\n#         saver.restore(sess,""%s/%s.ckpt""%(options.checkpoint_dir,keyname))\n\n#         gtDepths = []\n#         predDepths = []\n#         segmentationDepths = []\n#         predDepthsOneHot = []\n#         planeMasks = []\n#         predMasks = []\n\n#         imageWidth = WIDTH\n#         imageHeight = HEIGHT\n#         focalLength = 517.97\n#         urange = np.arange(imageWidth).reshape(1, -1).repeat(imageHeight, 0) - imageWidth * 0.5\n#         vrange = np.arange(imageHeight).reshape(-1, 1).repeat(imageWidth, 1) - imageHeight * 0.5\n#         ranges = np.array([urange / focalLength, np.ones(urange.shape), -vrange / focalLength]).transpose([1, 2, 0])\n        \n#         cv2.imwrite(options.test_dir + \'/one.png\', np.ones((HEIGHT, WIDTH), dtype=np.uint8) * 255)\n#         cv2.imwrite(options.test_dir + \'/zero.png\', np.zeros((HEIGHT, WIDTH), dtype=np.uint8) * 255)\n#         for index, im_name in enumerate(im_names):\n#             if index <= -1:\n#                 continue\n#             print(im_name[\'image\'])\n#             im = cv2.imread(im_name[\'image\'])\n#             image = im.astype(np.float32, copy=False)\n#             image = image / 255 - 0.5\n#             image = cv2.resize(image, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n\n#             #planes = np.load(im_name[\'plane\'])\n#             # numPlanes = planes.shape[0]\n#             # if numPlanes > options.numOutputPlanes:\n#             #     planeAreas = planes[:, 3:].sum(1)\n#             #     sortInds = np.argsort(planeAreas)[::-1]\n#             #     planes = planes[sortInds[:options.numOutputPlanes]]\n#             #     pass\n#             # gt_p = np.zeros((1, options.numOutputPlanes, 3))\n#             # gt_p[0, :numPlanes] = planes[:numPlanes, :3]\n\n#             normal = np.array(PIL.Image.open(im_name[\'normal\'])).astype(np.float) / 255 * 2 - 1\n#             norm = np.linalg.norm(normal, 2, 2)\n#             for c in xrange(3):\n#                 normal[:, :, c] /= norm\n#                 continue\n#             normal = cv2.resize(normal, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n            \n#             depth = np.array(PIL.Image.open(im_name[\'depth\'])).astype(np.float) / 1000\n#             depth = cv2.resize(depth, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n\n#             invalid_mask = cv2.resize(cv2.imread(im_name[\'invalid_mask\'], 0), (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR) > 128\n\n#             gtDepths.append(depth)\n\n            \n#             pred_p, pred_d, pred_n, pred_s, pred_np_m, pred_np_d, pred_np_n, pred_boundary, pred_local_score, pred_local_p, pred_local_mask = sess.run([plane_pred, depth_pred, normal_pred, segmentation_pred, non_plane_mask_pred, non_plane_depth_pred, non_plane_normal_pred, boundary_pred, local_score_pred, local_p_pred, local_mask_pred], feed_dict = {img_inp:np.expand_dims(image, 0), plane_gt: np.zeros((batchSize, options.numOutputPlanes, 3))})\n\n\n#             pred_s = pred_s[0] \n#             pred_p = pred_p[0]\n#             pred_np_m = pred_np_m[0]\n#             pred_np_d = pred_np_d[0]\n#             pred_np_n = pred_np_n[0]\n#             #pred_s = 1 / (1 + np.exp(-pred_s))\n\n#             plane_depths = calcPlaneDepths(pred_p, WIDTH, HEIGHT)\n#             all_depths = np.concatenate([pred_np_d, plane_depths], axis=2)\n\n#             all_segmentations = np.concatenate([pred_np_m, pred_s], axis=2)\n#             segmentation = np.argmax(all_segmentations, 2)\n#             if suffix != \'pixelwise\':\n#                 pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape(HEIGHT, WIDTH)\n#             else:\n#                 pred_d = np.squeeze(pred_np_d)\n#                 pass\n#             predDepths.append(pred_d)\n#             predMasks.append(segmentation != 0)\n#             planeMasks.append(invalid_mask)\n\n#             #depthError, normalError, occupancy, segmentationTest, reconstructedDepth, occupancyMask = evaluatePlanes(pred_p, im_name[\'image\'])\n#             #reconstructedDepth = cv2.resize(reconstructedDepth, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n            \n#             #evaluatePlanes(pred_p[0], im_name, options.test_dir, index)\n#             #print(pred_p)\n#             #print(gt_p)\n#             #print((pow(pred_d[0, :, :, 0] - depth, 2) * (gt_s.max(2) > 0.5)).mean())\n#             #print((depthError, normalError, occupancy))\n            \n#             evaluateDepths(predDepths[index], gtDepths[index], np.ones(planeMasks[index].shape), planeMasks[index])\n\n#             if index >= 10:\n#                 continue\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', cv2.resize(im, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR))\n#             #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_gt.png\', (minDepth / np.clip(depth, minDepth, 20) * 255).astype(np.uint8))\n#             #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', (minDepth / np.clip(pred_d[0, :, :, 0], minDepth, 20) * 255).astype(np.uint8))\n#             #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_plane.png\', (minDepth / np.clip(reconstructedDepth, minDepth, 20) * 255).astype(np.uint8))\n\n#             pred_boundary = pred_boundary[0]\n#             boundary = (1 / (1 + np.exp(-pred_boundary)) * 255).astype(np.uint8)\n#             boundary = np.concatenate([boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_boundary_pred.png\', boundary)\n            \n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_inp.png\', drawDepthImage(depth))\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n#             #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_plane.png\', drawDepthImage(reconstructedDepth))\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred_diff.png\', drawDiffImage(pred_d, depth, 0.5))\n#             #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_plane_diff.png\', np.minimum(np.abs(reconstructedDepth - depth) / 0.5 * 255, 255).astype(np.uint8))\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_inp.png\', drawNormalImage(normal))\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_pred.png\', drawNormalImage(pred_np_n))\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(all_segmentations, black=True))\n\n#             segmentation = np.argmax(pred_s, 2)\n#             #writePLYFile(options.test_dir, index, image, pred_p, segmentation)\n\n#             if index < 0:\n#                 for planeIndex in xrange(options.numOutputPlanes):\n#                     cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_\' + str(planeIndex) + \'.png\', drawMaskImage(pred_s[:, :, planeIndex]))\n#                     #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_\' + str(planeIndex) + \'_gt.png\', drawMaskImage(gt_s[:, :, planeIndex]))\n#                     continue\n#                 pass\n#             continue\n#         predDepths = np.array(predDepths)\n#         gtDepths = np.array(gtDepths)\n#         planeMasks = np.array(planeMasks)\n#         predMasks = np.array(predMasks)\n#         #evaluateDepths(predDepths, gtDepths, planeMasks, predMasks)\n#         evaluateDepths(predDepths, gtDepths, planeMasks, planeMasks)\n#         #exit(1)\n#         pass\n#     return\n\n\n# def fitPlanesRGBD(options):\n#     writeHTMLRGBD(\'../results/RANSAC_RGBD/index.html\', 10)\n#     exit(1)\n#     if not os.path.exists(options.checkpoint_dir):\n#         os.system(""mkdir -p %s""%options.checkpoint_dir)\n#         pass\n#     if not os.path.exists(options.test_dir):\n#         os.system(""mkdir -p %s""%options.test_dir)\n#         pass\n    \n#     min_after_dequeue = 1000\n\n#     reader_rgbd = RecordReaderRGBD()\n#     filename_queue_rgbd = tf.train.string_input_producer([\'../planes_nyu_rgbd_train.tfrecords\'], num_epochs=1)\n#     img_inp_rgbd, global_gt_dict_rgbd, local_gt_dict_rgbd = reader_rgbd.getBatch(filename_queue_rgbd, numOutputPlanes=options.numOutputPlanes, batchSize=1, min_after_dequeue=min_after_dequeue, getLocal=True)\n\n#     config=tf.ConfigProto()\n#     config.gpu_options.allow_growth=True\n#     config.allow_soft_placement=True\n\n#     init_op = tf.group(tf.global_variables_initializer(),\n#                        tf.local_variables_initializer())\n\n#     with tf.Session(config=config) as sess:\n#         sess.run(init_op)\n\n#         coord = tf.train.Coordinator()\n#         threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n#         try:\n#             gtDepths = []\n#             predDepths = []\n#             planeMasks = []\n#             for index in xrange(10):\n#                 image, depth, path = sess.run([img_inp_rgbd, global_gt_dict_rgbd[\'depth\'], global_gt_dict_rgbd[\'path\']])\n#                 image = ((image[0] + 0.5) * 255).astype(np.uint8)\n#                 depth = depth.squeeze()\n                \n#                 cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', image)\n#                 cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth.png\', drawDepthImage(depth))\n#                 #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_mask.png\', drawMaskImage(depth == 0))\n#                 planes, planeSegmentation, depthPred = fitPlanes(depth, numPlanes=20)                \n#                 cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(planeSegmentation))\n#                 cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(depthPred))\n\n#                 gtDepths.append(depth)\n#                 predDepths.append(depthPred)\n#                 planeMasks.append((planeSegmentation < 20).astype(np.float32))\n#                 continue\n#             predDepths = np.array(predDepths)\n#             gtDepths = np.array(gtDepths)\n#             planeMasks = np.array(planeMasks)\n#             evaluateDepths(predDepths, gtDepths, np.ones(planeMasks.shape, dtype=np.bool), planeMasks)            \n#         except tf.errors.OutOfRangeError:\n#             print(\'done fitting\')\n#         finally:\n#             # When done, ask the threads to stop.\n#             coord.request_stop()\n#             pass\n#     return\n\ndef writeInfo(options):\n    x = (np.arange(11) * 0.1).tolist()\n    ys = []\n    ys.append(np.load(\'test/planenet_pixel_IOU.npy\').tolist())\n    ys.append(np.load(\'test/pixelwise_pred_pixel_IOU.npy\').tolist())\n    ys.append(np.load(\'test/pixelwise_gt_pixel_IOU.npy\').tolist())\n    plotCurves(x, ys, filename = \'test/plane_comparison.png\', xlabel=\'IOU\', ylabel=\'pixel coverage\', labels=[\'planenet\', \'pixelwise+RANSAC\', \'GT+RANSAC\'])\n\n    x = (0.5 - np.arange(11) * 0.05).tolist()\n    ys = []\n    ys.append(np.load(\'test/planenet_pixel_diff.npy\').tolist())\n    ys.append(np.load(\'test/pixelwise_pred_pixel_diff.npy\').tolist())\n    ys.append(np.load(\'test/pixelwise_gt_pixel_diff.npy\').tolist())\n    plotCurves(x, ys, filename = \'test/plane_comparison_diff.png\', xlabel=\'diff\', ylabel=\'pixel coverage\', labels=[\'planenet\', \'pixelwise+RANSAC\', \'GT+RANSAC\'])\n    \n    return\n\ndef parse_args():\n    """"""\n    Parse input arguments\n    """"""\n    parser = argparse.ArgumentParser(description=\'Planenet\')\n    parser.add_argument(\'--gpu\', dest=\'gpu_id\',\n                        help=\'GPU device id to use [0]\',\n                        default=0, type=int)\n    #task: [train, test, predict]\n    parser.add_argument(\'--task\', dest=\'task\',\n                        help=\'task type: [train, test, predict]\',\n                        default=\'train\', type=str)\n    parser.add_argument(\'--restore\', dest=\'restore\',\n                        help=\'how to restore the model\',\n                        default=0, type=int)\n    parser.add_argument(\'--numOutputPlanes\', dest=\'numOutputPlanes\',\n                        help=\'the number of output planes\',\n                        default=20, type=int)\n    parser.add_argument(\'--batchSize\', dest=\'batchSize\',\n                        help=\'batch size\',\n                        default=16, type=int)\n    parser.add_argument(\'--dataset\', dest=\'dataset\',\n                        help=\'dataset name for test/predict\',\n                        default=\'\', type=str)\n    parser.add_argument(\'--numImages\', dest=\'numImages\',\n                        help=\'the number of images to test/predict\',\n                        default=10, type=int)\n    parser.add_argument(\'--boundaryLoss\', dest=\'boundaryLoss\',\n                        help=\'use boundary loss: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--diverseLoss\', dest=\'diverseLoss\',\n                        help=\'use diverse loss: [0, 1]\',\n                        default=1, type=int)\n    parser.add_argument(\'--labelLoss\', dest=\'labelLoss\',\n                        help=\'use label loss: [0, 1]\',\n                        default=1, type=int)    \n    parser.add_argument(\'--deepSupervision\', dest=\'deepSupervision\',\n                        help=\'deep supervision level: [0, 1, 2]\',\n                        default=1, type=int)\n    parser.add_argument(\'--sameMatching\', dest=\'sameMatching\',\n                        help=\'use the same matching for all deep supervision layers and the final prediction: [0, 1]\',\n                        default=0, type=int)    \n    parser.add_argument(\'--anchorPlanes\', dest=\'anchorPlanes\',\n                        help=\'use anchor planes for all deep supervision layers and the final prediction: [0, 1]\',\n                        default=0, type=int) \n    parser.add_argument(\'--crf\', dest=\'crf\',\n                        help=\'the number of CRF iterations\',\n                        default=0, type=int)\n    parser.add_argument(\'--backwardLossWeight\', dest=\'backwardLossWeight\',\n                        help=\'backward matching loss\',\n                        default=0.5, type=float)\n    parser.add_argument(\'--predictBoundary\', dest=\'predictBoundary\',\n                        help=\'whether predict boundary or not: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--predictSemantics\', dest=\'predictSemantics\',\n                        help=\'whether predict semantics or not: [0, 1]\',\n                        default=1, type=int)    \n    parser.add_argument(\'--predictLocal\', dest=\'predictLocal\',\n                        help=\'whether predict local planes or not: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--predictConfidence\', dest=\'predictConfidence\',\n                        help=\'whether predict plane confidence or not: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--predictPlanes\', dest=\'predictPlanes\',\n                        help=\'whether predict planes or not: [0, 1]\',\n                        default=0, type=int)    \n    parser.add_argument(\'--fineTuningCheckpoint\', dest=\'fineTuningCheckpoint\',\n                        help=\'specify the model for fine-tuning\',\n                        default=\'../PlaneSetGeneration/dump_planenet_diverse/train_planenet_diverse.ckpt\', type=str)\n    parser.add_argument(\'--suffix\', dest=\'suffix\',\n                        help=\'add a suffix to keyname to distinguish experiments\',\n                        default=\'\', type=str)\n    parser.add_argument(\'--l2Weight\', dest=\'l2Weight\',\n                        help=\'L2 regulation weight\',\n                        default=5e-4, type=float)\n    parser.add_argument(\'--LR\', dest=\'LR\',\n                        help=\'learning rate\',\n                        default=3e-5, type=float)\n    parser.add_argument(\'--hybrid\', dest=\'hybrid\',\n                        help=\'hybrid training\',\n                        default=\'3\', type=str)\n    parser.add_argument(\'--rootFolder\', dest=\'rootFolder\',\n                        help=\'root folder\',\n                        default=\'/mnt/vision/PlaneNet/\', type=str)\n    parser.add_argument(\'--dataFolder\', dest=\'dataFolder\',\n                        help=\'data folder\',\n                        default=\'/home/chenliu/Projects/PlaneNet/\', type=str)\n    parser.add_argument(\'--saveInterval\', dest=\'saveInterval\',\n                        help=\'save interval\',\n                        default=900, type=int)\n    \n\n    args = parser.parse_args()\n    args.keyname = os.path.basename(__file__).rstrip(\'.py\')\n    args.keyname = args.keyname.replace(\'train_\', \'\')\n\n    if args.numOutputPlanes != 20:\n        args.keyname += \'_np\' + str(args.numOutputPlanes)\n        pass\n    args.keyname += \'_hybrid\' + args.hybrid\n    \n    if args.deepSupervision != 1:\n        args.keyname += \'_ds\' + str(args.deepSupervision)\n        pass\n    if args.predictPlanes == 1:\n        args.keyname += \'_pp\'\n        pass\n    if args.predictSemantics == 1:\n        args.keyname += \'_ps\'\n        pass    \n\n    #args.predictSemantics = 0\n    #args.predictBoundary = 0\n    \n    args.checkpoint_dir = args.rootFolder + \'/checkpoint/\' + args.keyname\n    args.log_dir = \'log/\' + args.keyname\n    args.test_dir = \'test/\' + args.keyname + \'_\' + args.dataset\n    args.predict_dir = \'predict/\' + args.keyname + \'_\' + args.dataset\n    args.dump_dir = \'dump/\' + args.keyname\n    \n    #layers where deep supervision happens\n    args.deepSupervisionLayers = []\n    if args.deepSupervision >= 1:\n        args.deepSupervisionLayers.append(\'res4b22_relu\')\n        pass\n    if args.deepSupervision >= 2:\n        args.deepSupervisionLayers.append(\'res4b12_relu\')\n        pass\n    return args\n\n\nif __name__==\'__main__\':\n\n    # plane = np.load(\'temp/plane.npy\')\n    # depth = np.load(\'temp/depth.npy\')    \n    # segmentation = np.load(\'temp/segmentation.npy\')\n    # info = np.load(\'temp/info.npy\')\n    # num_planes = np.load(\'temp/num_planes.npy\')\n    # segmentation = np.argmax(segmentation, axis=-1)\n    # print(segmentation.shape)\n    # planes, segmentation, numPlanes = removeSmallSegments(plane, np.zeros((HEIGHT, WIDTH, 3)), depth.squeeze(), np.zeros((HEIGHT, WIDTH, 3)), segmentation, np.zeros((HEIGHT, WIDTH)), info, num_planes)\n    # print(planes)\n    # exit(1)\n    \n    args = parse_args()\n\n    print ""keyname=%s task=%s started""%(args.keyname, args.task)\n    try:\n        if args.task == ""train"":\n            main(args)\n        elif args.task == ""test"":\n            test(args)\n        elif args.task == ""predict"":\n            predict(args)\n        elif args.task == ""fit"":\n            fitPlanesRGBD(args)\n        elif args.task == ""write"":\n            writeInfo(args)\n        else:\n            assert False,""format wrong""\n            pass\n    finally:\n        pass\n\n'"
train_hybrid.py,151,"b'import tensorflow as tf\nimport numpy as np\nnp.set_printoptions(precision=2, linewidth=200)\nimport cv2\nimport os\nimport time\nimport sys\nimport tf_nndistance\nimport argparse\nimport glob\nimport PIL\nimport scipy.ndimage as ndimage\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom utils import *\nfrom plane_utils import *\nfrom modules import *\n\n\nfrom planenet import PlaneNet\nfrom RecordReader import *\nfrom RecordReaderRGBD import *\nfrom RecordReader3D import *\nfrom RecordReaderAll import *\nfrom crfasrnn_layer import CrfRnnLayer\nfrom train_sample import build_graph as build_graph\n\n#from SegmentationRefinement import *\n\n#training_flag: toggle dropout and batch normalization mode\n#it\'s true for training and false for validation, testing, prediction\n#it also controls which data batch to use (*_train or *_val)\n\n\ndef build_loss(img_inp_train, img_inp_val, global_pred_dict, deep_pred_dicts, global_gt_dict_train, global_gt_dict_val, training_flag, options):\n    with tf.device(\'/gpu:%d\'%options.gpu_id):\n        debug_dict = {}\n\n        img_inp = tf.cond(training_flag, lambda: img_inp_train, lambda: img_inp_val)\n        global_gt_dict = {}\n        for name in global_gt_dict_train.keys():\n            global_gt_dict[name] = tf.cond(training_flag, lambda: global_gt_dict_train[name], lambda: global_gt_dict_val[name])\n            continue\n        # local_gt_dict = {}\n        # for name in local_gt_dict_train.keys():\n        #     local_gt_dict[name] = tf.cond(tf.equal(training_flag % 2, 0), lambda: local_gt_dict_train[name], lambda: local_gt_dict_val[name])\n        #     continue\n\n        plane_parameters = tf.reshape(global_pred_dict[\'plane\'], (-1, 3))\n        info = global_gt_dict[\'info\'][0]\n        plane_depths = planeDepthsModule(plane_parameters, WIDTH, HEIGHT, info)\n        plane_depths = tf.transpose(tf.reshape(plane_depths, [HEIGHT, WIDTH, -1, options.numOutputPlanes]), [2, 0, 1, 3])\n\n        non_plane_depth = global_pred_dict[\'non_plane_depth\']\n        all_depths = tf.concat([plane_depths, non_plane_depth], axis=3)\n\n        \n        validPlaneMask = tf.cast(tf.less(tf.tile(tf.expand_dims(tf.range(options.numOutputPlanes), 0), [options.batchSize, 1]), tf.expand_dims(global_gt_dict[\'num_planes\'], -1)), tf.float32)        \n        backwardLossWeight = options.backwardLossWeight\n        \n        #plane loss and segmentation loss (summation over deep supervisions and final supervision)\n        all_pred_dicts = deep_pred_dicts + [global_pred_dict]\n        plane_loss = tf.constant(0.0)\n        segmentation_loss = tf.constant(0.0)\n        plane_confidence_loss = tf.constant(0.0)\n        diverse_loss = tf.constant(0.0)\n        \n        #keep forward map (segmentation gt) from previous supervision so that we can have same matching for all supervisions (options.sameMatching = 1)\n        previous_plane_gt = None\n        previous_plane_confidence_gt = None        \n        previous_segmentation_gt = None\n        if options.anchorPlanes:\n            anchors_np = np.load(\'dump/anchors_\' + options.hybrid + \'.npy\')\n            anchors = tf.reshape(tf.constant(anchors_np.reshape(-1)), anchors_np.shape)\n            anchors = tf.tile(tf.expand_dims(anchors, 0), [options.batchSize, 1, 1])\n            dists_forward, map_forward, dists_backward, _ = tf_nndistance.nn_distance(global_gt_dict[\'plane\'], anchors)\n                            \n            forward_map = tf.one_hot(map_forward, depth=options.numOutputPlanes, axis=-1)\n            forward_map *= tf.expand_dims(validPlaneMask, -1)\n                \n            #number of ground truth mapped for each prediction\n            num_matches = tf.transpose(tf.reduce_sum(forward_map, axis=1, keep_dims=True), [0, 2, 1])\n            previous_plane_gt = tf.transpose(tf.matmul(global_gt_dict[\'plane\'], forward_map, transpose_a=True), [0, 2, 1]) / tf.maximum(num_matches, 1e-4)\n            previous_plane_confidence_gt = tf.cast(num_matches > 0.5, tf.float32)\n\n            segmentation_gt_shuffled = tf.reshape(tf.matmul(tf.reshape(global_gt_dict[\'segmentation\'], [-1, HEIGHT * WIDTH, options.numOutputPlanes]), forward_map), [-1, HEIGHT, WIDTH, options.numOutputPlanes])\n            segmentation_gt_shuffled = tf.concat([segmentation_gt_shuffled, global_gt_dict[\'non_plane_mask\']], axis=3)\n            previous_segmentation_gt = segmentation_gt_shuffled\n            pass\n        \n        for pred_index, pred_dict in enumerate(all_pred_dicts):\n            if (options.sameMatching and pred_index > 0) or options.anchorPlanes:\n                #use matching from previous supervision and map ground truth planes based on the mapping\n\n                plane_loss += tf.reduce_mean(tf.squared_difference(pred_dict[\'plane\'], previous_plane_gt) * previous_plane_confidence_gt, axis=[1, 2, 3]) * 10000\n                \n                #all segmentations is the concatenation of plane segmentations and non plane mask\n                all_segmentations = tf.concat([pred_dict[\'segmentation\'], pred_dict[\'non_plane_mask\']], axis=3)\n\n                if options.crf > 0:\n                    all_segmentations_softmax = tf.nn.softmax(all_segmentations)          \n                    with tf.variable_scope(\'crf\'):\n                        planesY = global_pred_dict[\'plane\'][:, :, 1]\n                        planesD = tf.maximum(tf.norm(global_pred_dict[\'plane\'], axis=-1), 1e-4)\n                        planesY /= planesD\n                        planesY = tf.concat([planesY, tf.ones((options.batchSize, 1)) * 100], axis=1)\n\n                        imageDiff = calcImageDiff(img_inp)\n                        all_segmentations_softmax, _ = segmentationRefinementModule(all_segmentations_softmax, all_depths, planesY, imageDiff, numIterations=options.crf, numOutputPlanes=21)\n                        segmentation_loss += tf.reduce_mean(-tf.reduce_sum(previous_segmentation_gt* tf.log(tf.maximum(all_segmentations_softmax, 1e-31)), axis=-1), axis=[1, 2]) * 1000\n                        pass\n                    pass\n                else:\n                    segmentation_loss += tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=all_segmentations, labels=previous_segmentation_gt), axis=[1, 2]) * 1000\n                    pass\n            else:\n                #calculate new matching by finding nearest neighbors again\n                dists_forward, map_forward, dists_backward, _ = tf_nndistance.nn_distance(global_gt_dict[\'plane\'], pred_dict[\'plane\'])\n                dists_forward *= validPlaneMask\n                \n                dists_forward = tf.reduce_mean(dists_forward, axis=[1])\n                dists_backward = tf.reduce_mean(dists_backward, axis=[1])\n                plane_loss += (dists_forward + dists_backward * backwardLossWeight) * 10000\n\n                forward_map = tf.one_hot(map_forward, depth=options.numOutputPlanes, axis=-1)\n                forward_map *= tf.expand_dims(validPlaneMask, -1)\n                \n                #number of ground truth mapped for each prediction\n                num_matches = tf.transpose(tf.reduce_sum(forward_map, axis=1, keep_dims=True), [0, 2, 1])\n                previous_plane_gt = tf.transpose(tf.matmul(global_gt_dict[\'plane\'], forward_map, transpose_a=True), [0, 2, 1]) / tf.maximum(num_matches, 1e-4)\n                previous_plane_confidence_gt = tf.cast(num_matches > 0.5, tf.float32)\n                \n                                              \n                segmentation_gt_shuffled = tf.reshape(tf.matmul(tf.reshape(global_gt_dict[\'segmentation\'], [-1, HEIGHT * WIDTH, options.numOutputPlanes]), forward_map), [-1, HEIGHT, WIDTH, options.numOutputPlanes])\n                segmentation_gt_shuffled = tf.concat([segmentation_gt_shuffled, global_gt_dict[\'non_plane_mask\']], axis=3)\n                previous_segmentation_gt = segmentation_gt_shuffled\n                \n                all_segmentations = tf.concat([pred_dict[\'segmentation\'], pred_dict[\'non_plane_mask\']], axis=3)\n                segmentation_loss += tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=all_segmentations, labels=segmentation_gt_shuffled), axis=[1, 2]) * 1000\n                debug_dict[\'segmentation\'] = segmentation_gt_shuffled\n                pass\n\n            if options.diverseLoss:\n                plane_diff = tf.reduce_sum(tf.pow(tf.expand_dims(pred_dict[\'plane\'], 1) - tf.expand_dims(pred_dict[\'plane\'], 2), 2), axis=3)\n                plane_diff = tf.matrix_set_diag(plane_diff, tf.ones((options.batchSize, options.numOutputPlanes)))\n                minPlaneDiff = 0.1\n                diverse_loss += tf.reduce_mean(tf.clip_by_value(1 - plane_diff / minPlaneDiff, 0, 1), axis=[1, 2, 3]) * 10000\n                pass\n              \n            continue\n\n\n        if options.crf == 0:\n            all_segmentations_softmax = tf.nn.softmax(all_segmentations)\n            pass\n        \n        #depth loss\n        validDepthMask = tf.cast(tf.greater(global_gt_dict[\'depth\'], 1e-4), tf.float32)\n        depth_loss = tf.reduce_mean(tf.reduce_sum(tf.squared_difference(all_depths, global_gt_dict[\'depth\']) * all_segmentations_softmax, axis=3, keep_dims=True) * validDepthMask, axis=[1, 2, 3]) * 10000\n\n        if options.predictPixelwise == 1:\n            depth_diff = global_pred_dict[\'non_plane_depth\'] - global_gt_dict[\'depth\']\n            depth_diff_gx = depth_diff - tf.concat([tf.ones([options.batchSize, HEIGHT, 1, 1]), depth_diff[:, :, :WIDTH - 1]], axis=2)\n            depth_diff_gy = depth_diff - tf.concat([tf.ones([options.batchSize, 1, WIDTH, 1]), depth_diff[:, :HEIGHT - 1]], axis=1)\n\n            numValidPixels = tf.reduce_sum(validDepthMask, axis=[1, 2, 3])\n            depth_loss += (tf.reduce_sum(tf.pow(depth_diff * validDepthMask, 2), axis=[1, 2, 3]) / numValidPixels - 0.5 * tf.pow(tf.reduce_sum(depth_diff * validDepthMask, axis=[1, 2, 3]) / numValidPixels, 2) + tf.reduce_sum((tf.pow(depth_diff_gx, 2) + tf.pow(depth_diff_gy, 2)) * validDepthMask, axis=[1, 2, 3]) / numValidPixels) * 1000\n        \n            #depth_loss += tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_depth\'], global_gt_dict[\'depth\']) * validDepthMask) * 10000\n\n\n            valid_normal_mask = tf.squeeze(tf.cast(tf.less(tf.slice(global_gt_dict[\'info\'], [0, 19], [options.batchSize, 1]), 2), tf.float32))\n            normal_gt = tf.nn.l2_normalize(global_gt_dict[\'normal\'], dim=-1)\n            normal_loss = tf.reduce_sum(-global_pred_dict[\'non_plane_normal\'] * normal_gt * validDepthMask, axis=[1, 2, 3]) / numValidPixels * valid_normal_mask * 1000\n            #normal_loss = tf.reduce_mean(tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_normal\'], global_gt_dict[\'normal\']) * validDepthMask, axis=[1, 2, 3]) * valid_normal_mask) * 1000\n        else:\n            normal_loss = tf.constant(0.0)            \n            pass\n\n        if options.predictSemantics:\n            valid_semantics_mask = tf.squeeze(tf.cast(tf.not_equal(tf.slice(global_gt_dict[\'info\'], [0, 19], [options.batchSize, 1]), 1), tf.float32))\n            semantics_loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=global_pred_dict[\'semantics\'], labels=global_gt_dict[\'semantics\']), axis=[1, 2]) * valid_semantics_mask * 1000\n        else:\n            semantics_loss = tf.constant(0.0)\n            pass\n\n        local_score_loss = tf.constant(0.0)\n        local_plane_loss = tf.constant(0.0)\n        local_mask_loss = tf.constant(0.0)\n                \n        #boundary loss\n        boundary_loss = tf.constant(0.0)\n        \n        if False:\n            kernel_size = 3\n            padding = (kernel_size - 1) / 2\n            neighbor_kernel_array = gaussian(kernel_size, kernel_size)\n            neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n            neighbor_kernel_array /= neighbor_kernel_array.sum()\n            neighbor_kernel_array *= -1\n            neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 1\n            neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n            neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n            \n            #calculate boundary ground truth on-the-fly as the calculation is subject to change\n        \n            depth_diff = tf.abs(tf.nn.depthwise_conv2d(global_gt_dict[\'depth\'], neighbor_kernel, strides=[1, 1, 1, 1], padding=\'VALID\'))\n            depth_diff = tf.pad(depth_diff, paddings = [[0, 0], [padding, padding], [padding, padding], [0, 0]])\n            max_depth_diff = 0.1\n            depth_boundary = tf.greater(depth_diff, max_depth_diff)\n\n            plane_region = tf.nn.max_pool(1 - global_gt_dict[\'non_plane_mask\'], ksize=[1, kernel_size, kernel_size, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n            segmentation_eroded = 1 - tf.nn.max_pool(1 - global_gt_dict[\'segmentation\'], ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n            plane_region -= tf.reduce_max(segmentation_eroded, axis=3, keep_dims=True)\n            boundary = tf.cast(depth_boundary, tf.float32) * plane_region\n            smooth_boundary = global_gt_dict[\'smooth_boundary\']\n            boundary_gt = tf.concat([smooth_boundary, tf.maximum(boundary - smooth_boundary, 0)], axis=3)\n            pass\n\n\n        \n        if options.predictBoundary and False:\n            #we predict boundaries directly for post-processing purpose\n            boundary_loss += tf.reduce_mean(tf.losses.sigmoid_cross_entropy(logits=global_pred_dict[\'boundary\'], multi_class_labels=global_gt_dict[\'boundary\'], weights=tf.maximum(global_gt_dict[\'boundary\'] * 3, 1))) * 1000\n            pass\n\n\n        label_loss = tf.constant(0.0)\n        if options.labelLoss == 1:\n            #label_loss = tf.reduce_mean(tf.reduce_max(all_segmentations_softmax, axis=[1, 2]) * tf.concat([tf.cast(tf.equal(tf.squeeze(num_matches, axis=2), 0), tf.float32), tf.ones([options.batchSize, 1])], axis=1)) * 1000\n            #label_loss = tf.reduce_mean(tf.log(1 + tf.reduce_sum(all_segmentations_softmax, axis=[1, 2]))) * 100\n            label_loss = tf.reduce_mean(tf.sqrt(tf.reduce_sum(all_segmentations_softmax, axis=[1, 2])), axis=[1]) * 50\n            #label_loss = tf.reduce_mean(tf.reduce_max(all_segmentations_softmax, axis=[1, 2])) * 1000\n            pass\n        \n        #regularization\n        l2_losses = tf.add_n([options.l2Weight * tf.nn.l2_loss(v) for v in tf.trainable_variables() if \'weights\' in v.name])\n\n        if options.planeLoss == 0:\n            plane_loss = tf.constant(0.0)\n            pass\n\n        #loss_all = plane_loss + segmentation_loss + depth_loss + normal_loss + plane_confidence_loss + diverse_loss + boundary_loss + local_score_loss + local_plane_loss + local_mask_loss + label_loss + semantics_loss + l2_losses\n        #loss_pixelwise = depth_loss + normal_loss + semantics_loss + l2_losses\n\n        loss = tf.reduce_mean((depth_loss + normal_loss + semantics_loss) + (plane_loss + segmentation_loss + plane_confidence_loss + diverse_loss + boundary_loss + local_score_loss + local_plane_loss + local_mask_loss + label_loss) * tf.cast(tf.equal(tf.squeeze(tf.slice(global_gt_dict[\'info\'], [0, 19], [options.batchSize, 1])), 3), tf.float32)) + l2_losses\n        #if options.pixelwiseLoss:\n        #normal_loss = tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_normal\'], global_gt_dict[\'normal\'])) * 1000\n        #depth_loss = tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_depth\'], global_gt_dict[\'depth\']) * validDepthMask) * 1000\n        #pass\n\n        S = tf.one_hot(tf.argmax(all_segmentations, 3), depth=options.numOutputPlanes + 1)\n        depth_one_hot = tf.reduce_sum(all_depths * S, 3, keep_dims=True)\n        debug_dict[\'depth\'] = depth_one_hot\n        \n        loss_dict = {\'plane\': plane_loss, \'segmentation\': segmentation_loss, \'depth\': depth_loss, \'normal\': normal_loss, \'boundary\': boundary_loss, \'diverse\': diverse_loss, \'confidence\': plane_confidence_loss, \'local_score\': local_score_loss, \'local_plane\': local_plane_loss, \'local_mask\': local_mask_loss, \'label\': label_loss, \'semantics\': semantics_loss}\n        pass\n    return loss, loss_dict, debug_dict\n\n\ndef main(options):\n    if not os.path.exists(options.checkpoint_dir):\n        os.system(""mkdir -p %s""%options.checkpoint_dir)\n        pass\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n    \n    min_after_dequeue = 1000\n\n\n    train_inputs = []\n    val_inputs = []\n    if \'0\' in options.hybrid:\n        train_inputs.append(options.rootFolder + \'/planes_SUNCG_train.tfrecords\')\n        val_inputs.append(options.rootFolder + \'/planes_SUNCG_val.tfrecords\')        \n        pass\n    if \'1\' in options.hybrid:\n        train_inputs.append(options.rootFolder + \'/planes_nyu_rgbd_train.tfrecords\')\n        train_inputs.append(options.rootFolder + \'/planes_nyu_rgbd_labeled_train.tfrecords\')\n        val_inputs.append(options.rootFolder + \'/planes_nyu_rgbd_val.tfrecords\')\n        pass\n    if \'2\' in options.hybrid:\n        train_inputs.append(options.rootFolder + \'/planes_matterport_train.tfrecords\')\n        val_inputs.append(options.rootFolder + \'/planes_matterport_val.tfrecords\')\n        pass\n    if \'3\' in options.hybrid:\n        train_inputs.append(options.rootFolder + \'/planes_scannet_train.tfrecords\')\n        val_inputs.append(options.rootFolder + \'/planes_scannet_val.tfrecords\')\n        pass\n\n    \n    hybrid_flag = tf.placeholder(tf.bool, shape=[], name=\'hybrid_flag\')\n    \n    reader_train_nyu_rgbd = RecordReaderAll()\n    filename_queue_train_nyu_rgbd = tf.train.string_input_producer(train_inputs + [options.rootFolder + \'/planes_scannet_train.tfrecords\', ], num_epochs=10000)\n    img_inp_train_nyu_rgbd, global_gt_dict_train_nyu_rgbd, _ = reader_train_nyu_rgbd.getBatch(filename_queue_train_nyu_rgbd, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True)\n\n    # reader_train_scannet = RecordReaderAll()\n    # filename_queue_train_scannet = tf.train.string_input_producer([options.rootFolder + \'/planes_scannet_train.tfrecords\'], num_epochs=10000)\n    # img_inp_train_scannet, global_gt_dict_train_scannet, _ = reader_train_scannet.getBatch(filename_queue_train_scannet, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize / 2, min_after_dequeue=min_after_dequeue, getLocal=True)\n\n    # img_inp_train = tf.concat([img_inp_train_nyu_rgbd, img_inp_train_scannet], axis=0)\n    # global_gt_dict_train = {}\n    # for name in global_gt_dict_train_nyu_rgbd.keys():\n    #     global_gt_dict_train[name] = tf.concat([global_gt_dict_train_nyu_rgbd[name], global_gt_dict_train_scannet[name]], axis=0)\n    #     continue\n    # local_gt_dict_train = {}\n    \n    img_inp_train = img_inp_train_nyu_rgbd\n    global_gt_dict_train = global_gt_dict_train_nyu_rgbd\n    local_gt_dict_train = {}\n\n    \n    reader_val = RecordReaderAll()\n    filename_queue_val = tf.train.string_input_producer(val_inputs, num_epochs=10000)\n    img_inp_val, global_gt_dict_val, local_gt_dict_val = reader_val.getBatch(filename_queue_val, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True)\n    \n    training_flag = tf.placeholder(tf.bool, shape=[], name=\'training_flag\')\n    \n    #global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp_train, img_inp_val, img_inp_rgbd_train, img_inp_rgbd_val, img_inp_3d_train, img_inp_3d_val, training_flag, options)\n    global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp_train, img_inp_val, training_flag, options)\n    \n    \n    #loss, loss_dict, _ = build_loss(global_pred_dict, local_pred_dict, deep_pred_dicts, global_gt_dict_train, local_gt_dict_train, global_gt_dict_val, local_gt_dict_val, training_flag, options)\n    #loss_rgbd, loss_dict_rgbd, _ = build_loss_rgbd(global_pred_dict, deep_pred_dicts, global_gt_dict_rgbd_train, global_gt_dict_rgbd_val, training_flag, options)\n    loss, loss_dict, _ = build_loss(img_inp_train, img_inp_val, global_pred_dict, deep_pred_dicts, global_gt_dict_train, global_gt_dict_val, training_flag, options)    \n        \n    #loss = tf.cond(tf.less(training_flag, 2), lambda: loss, lambda: tf.cond(tf.less(training_flag, 4), lambda: loss_rgbd, lambda: loss_3d))\n\n    \n    #train_writer = tf.summary.FileWriter(options.log_dir + \'/train\')\n    #val_writer = tf.summary.FileWriter(options.log_dir + \'/val\')\n    #train_writer_rgbd = tf.summary.FileWriter(options.log_dir + \'/train_rgbd\')\n    #val_writer_rgbd = tf.summary.FileWriter(options.log_dir + \'/val_rgbd\')\n    #writers = [train_writer, val_writer, train_writer_rgbd, val_writer_rgbd]\n    \n\n    with tf.variable_scope(\'statistics\'):\n        batchno = tf.Variable(0, dtype=tf.int32, trainable=False, name=\'batchno\')\n        batchnoinc=batchno.assign(batchno+1)\n        pass\n\n\n    optimizer = tf.train.AdamOptimizer(options.LR)\n    if options.crfrnn >= 0:\n        train_op = optimizer.minimize(loss, global_step=batchno)\n    else:\n        var_to_train = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, ""crfrnn"")\n        print(var_to_train)\n        train_op = optimizer.minimize(loss, global_step=batchno, var_list=var_to_train)\n        pass\n    \n    var_to_restore = [v for v in tf.global_variables()]\n\n    tf.summary.scalar(\'loss\', loss)\n    summary_op = tf.summary.merge_all()\n\n    \n    config=tf.ConfigProto()\n    config.allow_soft_placement=True    \n    #config.gpu_options.allow_growth=True\n    config.gpu_options.per_process_gpu_memory_fraction=0.9\n    saver=tf.train.Saver()\n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n    \n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n        if options.restore == 0:\n            #fine-tune from DeepLab model\n            var_to_restore = [v for v in var_to_restore if \'res5d\' not in v.name and \'segmentation\' not in v.name and \'plane\' not in v.name and \'deep_supervision\' not in v.name and \'local\' not in v.name and \'boundary\' not in v.name and \'degridding\' not in v.name and \'res2a_branch2a\' not in v.name and \'res2a_branch1\' not in v.name and \'Adam\' not in v.name and \'beta\' not in v.name and \'statistics\' not in v.name and \'semantics\' not in v.name]\n            pretrained_model_loader = tf.train.Saver(var_to_restore)\n            pretrained_model_loader.restore(sess,""../pretrained_models/deeplab_resnet.ckpt"")\n        elif options.restore == 1:\n            #restore the same model from checkpoint\n            loader = tf.train.Saver(var_to_restore)\n            loader.restore(sess,""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n            bno=sess.run(batchno)\n            print(bno)\n        elif options.restore == 2:            \n            #restore the same model from checkpoint but reset batchno to 1\n            loader = tf.train.Saver(var_to_restore)\n            loader.restore(sess,""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n            sess.run(batchno.assign(1))\n        elif options.restore == 3:            \n            #restore the same model from standard training\n            # if options.predictBoundary == 1:\n            #     var_to_restore = [v for v in var_to_restore if \'boundary\' not in v.name]\n            #     pass            \n            # if options.predictConfidence == 1:\n            #     var_to_restore = [v for v in var_to_restore if \'confidence\' not in v.name]\n            #     pass\n            if options.predictSemantics == 1:\n                var_to_restore = [v for v in var_to_restore if \'semantics\' not in v.name]\n                pass\n            if np.abs(options.crfrnn) > 0:\n                var_to_restore = [v for v in var_to_restore if \'crfrnn\' not in v.name]\n                pass\n            \n            loader = tf.train.Saver(var_to_restore)\n            if len(options.hybrid) == 1:\n                hybrid = options.hybrid\n            else:\n                hybrid = str(3)\n                pass\n            #loader.restore(sess, options.rootFolder + \'/checkpoint/planenet_hybrid\' + hybrid + \'_bl0_ll1_bw0.5_pb_pp_ps_sm0/checkpoint.ckpt\')\n            #loader.restore(sess, options.rootFolder + \'/checkpoint/planenet_hybrid3_bl0_dl0_ll1_pb_pp_sm0/checkpoint.ckpt\')\n            loader.restore(sess, options.rootFolder + \'/checkpoint/sample_np10_hybrid3_bl0_dl0_hl2_ds0_crfrnn5_sm0/checkpoint.ckpt\')\n            #loader.restore(sess,""checkpoint/planenet/checkpoint.ckpt"")\n            sess.run(batchno.assign(1))\n        elif options.restore == 4:\n            #fine-tune another model\n            #var_to_restore = [v for v in var_to_restore if \'res4b22_relu_non_plane\' not in v.name]\n            loader = tf.train.Saver(var_to_restore)\n            loader.restore(sess, options.fineTuningCheckpoint)\n            sess.run(batchno.assign(1))\n            pass\n        elif options.restore == 5:\n            #fine-tune another model\n            #var_to_restore = [v for v in var_to_restore if \'res4b22_relu_non_plane\' not in v.name]\n            loader = tf.train.Saver(var_to_restore)\n            print(options.checkpoint_dir.replace(\'crfrnn\', \'crfrnn-\'))\n            #exit(1)\n            loader.restore(sess,""%s/checkpoint.ckpt""%(options.checkpoint_dir.replace(\'crfrnn\', \'crfrnn-\')))            \n            sess.run(batchno.assign(1))\n            pass\n        # Start input enqueue threads.\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n        MOVING_AVERAGE_DECAY = 0.99\n        ema = [0., 0., 0., 0.]\n        ema_acc = [1e-10, 1e-10, 1e-10, 1e-10]\n        last_snapshot_time = time.time()\n        bno=sess.run(batchno)\n\n        try:\n            while bno<300000:\n                t0 = time.time()\n\n                batchIndexPeriod = bno % 100\n                if batchIndexPeriod < len(options.hybrid):\n                    #batchType = int(options.hybrid[batchIndexPeriod]) * 2 + 1\n                    batchType = 1\n                    _, total_loss, losses, summary_str, debug = sess.run([batchnoinc, loss, loss_dict, summary_op, global_pred_dict], feed_dict = {training_flag: batchType == 0, hybrid_flag: np.random.randint(2) == 0})\n                else:\n                    batchType = 0\n                    _, total_loss, losses, summary_str, debug = sess.run([train_op, loss, loss_dict, summary_op, global_pred_dict], feed_dict = {training_flag: batchType == 0, hybrid_flag: np.random.randint(2) == 0})\n\n                    # for batchIndex in xrange(options.batchSize):\n                    #     print(losses)\n                    #     print(debug[\'plane\'][batchIndex])\n                    #     cv2.imwrite(\'test/image_\' + str(batchIndex) + \'.png\', ((img[batchIndex] + 0.5) * 255).astype(np.uint8))\n                    #     cv2.imwrite(\'test/segmentation_\' + str(batchIndex) + \'.png\', drawSegmentationImage(debug[\'segmentation\'][batchIndex]))\n                    #     continue\n                    # exit(1)\n                    \n                    pass\n\n                    \n                ema[batchType] = ema[batchType] * MOVING_AVERAGE_DECAY + total_loss\n                ema_acc[batchType] = ema_acc[batchType] * MOVING_AVERAGE_DECAY + 1\n\n                bno = sess.run(batchno)\n                if time.time()-last_snapshot_time > options.saveInterval:\n                    print(\'save snapshot\')\n                    saver.save(sess,\'%s/checkpoint.ckpt\'%options.checkpoint_dir)\n                    last_snapshot_time = time.time()\n                    pass\n        \n                print bno,\'train\', ema[0] / ema_acc[0], \'val\', ema[1] / ema_acc[1], \'train rgbd\', ema[2] / ema_acc[2], \'val rgbd\', ema[3] / ema_acc[3], \'loss\', total_loss, \'time\', time.time()-t0\n\n                if np.random.random() < 0.01:\n                    print(losses)\n                    pass                \n                continue\n\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n        \n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return\n\n\ndef test(options):\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n\n    if options.dataset == \'\':\n        assert(len(options.hybrid) == 1)\n        if options.hybrid == \'0\':\n            options.dataset = \'SUNCG\'\n        elif options.hybrid == \'1\':\n            options.dataset = \'NYU_RGBD\'\n        elif options.hybrid == \'2\':\n            options.dataset = \'matterport\'\n        elif options.hybrid == \'3\':\n            options.dataset = \'ScanNet\'\n            \n        options.dataset\n    options.batchSize = 1\n    min_after_dequeue = 1000\n\n    reader = RecordReaderAll()\n    if options.dataset == \'SUNCG\':\n        filename_queue = tf.train.string_input_producer([options.rootFolder + \'/planes_SUNCG_val.tfrecords\'], num_epochs=10000)\n    elif options.dataset == \'NYU_RGBD\':\n        filename_queue = tf.train.string_input_producer([options.rootFolder + \'/planes_nyu_rgbd_val.tfrecords\'], num_epochs=1)\n        options.deepSupervision = 0\n        options.predictLocal = 0\n    elif options.dataset == \'matterport\':\n        filename_queue = tf.train.string_input_producer([options.rootFolder + \'/planes_matterport_val.tfrecords\'], num_epochs=1)\n    else:\n        filename_queue = tf.train.string_input_producer([options.rootFolder + \'/planes_scannet_val.tfrecords\'], num_epochs=1)\n        pass\n    img_inp, global_gt_dict, local_gt_dict = reader.getBatch(filename_queue, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True, random=False)\n\n    training_flag = tf.constant(False, tf.bool)\n\n    global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp, img_inp, training_flag, options)\n    var_to_restore = tf.global_variables()\n\n    loss, loss_dict, debug_dict = build_loss(img_inp, img_inp, global_pred_dict, deep_pred_dicts, global_gt_dict, global_gt_dict, training_flag, options)\n    \n\n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n    \n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n        #var_to_restore = [v for v in var_to_restore if \'res4b22_relu_non_plane\' not in v.name]\n        loader = tf.train.Saver(var_to_restore)\n        loader.restore(sess, ""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n        #loader.restore(sess, ""%s/checkpoint.ckpt""%(\'checkpoint/planenet_pb_pp_hybrid1\'))\n        #loader.restore(sess, options.fineTuningCheckpoint)\n        \n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n        \n        \n        try:\n            gtDepths = []\n            predDepths = []\n            planeMasks = []\n            #predMasks = []\n            gtPlanes = []\n            predPlanes = []\n            gtSegmentations = []\n            predSegmentations = []\n            gtNumPlanes = []\n            \n            imageWidth = WIDTH\n            imageHeight = HEIGHT\n            focalLength = 517.97\n            urange = np.arange(imageWidth).reshape(1, -1).repeat(imageHeight, 0) - imageWidth * 0.5\n            vrange = np.arange(imageHeight).reshape(-1, 1).repeat(imageWidth, 1) - imageHeight * 0.5\n            ranges = np.array([urange / imageWidth * 640 / focalLength, np.ones(urange.shape), -vrange / imageHeight * 480 / focalLength]).transpose([1, 2, 0])\n\n\n            for index in xrange(10):\n                print((\'image\', index))\n                t0=time.time()\n\n                img, global_gt, local_gt, global_pred, local_pred, deep_preds, total_loss, losses, debug = sess.run([img_inp, global_gt_dict, local_gt_dict, global_pred_dict, local_pred_dict, deep_pred_dicts, loss, loss_dict, debug_dict])\n\n                # print(options.test_dir)\n                # cv2.imwrite(options.test_dir + \'/depth.png\', drawDepthImage(debug[\'depth\'][0]))\n                # cv2.imwrite(options.test_dir + \'/normal.png\', drawNormalImage(debug[\'normal\'][0]))\n                # boundary = debug[\'boundary\'][0]\n                # boundary = np.concatenate([boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)\n                # cv2.imwrite(options.test_dir + \'/boundary.png\', drawMaskImage(boundary))\n                # cv2.imwrite(options.test_dir + \'/depth_gt.png\', drawDepthImage(debug[\'depth_gt\'][0].squeeze()))\n                # exit(1)\n\n                if \'pixelwise\' in options.suffix:\n                    image = ((img[0] + 0.5) * 255).astype(np.uint8)\n                    gt_d = global_gt[\'depth\'].squeeze()\n                    pred_d = global_pred[\'non_plane_depth\'].squeeze()\n                    #depth = global_gt[\'depth\'].squeeze()\n                    if \'_2\' in options.suffix:\n                        pred_p, pred_s, pred_d = fitPlanes(pred_d, numPlanes=20, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=0.2)\n                    elif \'_3\' in options.suffix:\n                        pred_p, pred_s, pred_d = fitPlanes(gt_d, numPlanes=20, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=0.2)\n                        pass\n\n                    # gt_p = global_gt[\'plane\'][0]\n                    # pred_p = planes\n                    # valid_mask = (np.linalg.norm(gt_p, axis=1) > 0).astype(np.float32)\n                    # diff = np.min(np.linalg.norm(np.expand_dims(gt_p, 1) - np.expand_dims(pred_p, 0), axis=2), 1)\n                    # num += valid_mask.sum()\n                    # lossSum += (diff * valid_mask).sum()\n                    if options.dataset == \'SUNCG\':\n                        planeMask = np.squeeze(debug[\'segmentation\']).sum(axis=2)\n                    else:\n                        planeMask = np.ones((HEIGHT, WIDTH))\n                        if \'_2\' in options.suffix or \'_3\' in options.suffix:\n                            planeMask *= (pred_s < 20).astype(np.float32)\n                        pass\n                    \n                    if index < 10:\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', image)\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth.png\', drawDepthImage(gt_d))\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n                        if \'_2\' in options.suffix or \'_3\' in options.suffix:\n                            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(pred_s))\n                            pass\n                        #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_plane_mask.png\', drawMaskImage(planeMask))                \n                        pass\n\n                        \n                    gtDepths.append(gt_d)\n                    predDepths.append(pred_d)\n                    planeMasks.append(planeMask)\n\n\n                    if options.dataset != \'NYU_RGBD\' and (\'_2\' in options.suffix or \'_3\' in options.suffix):\n                        gt_p = global_gt[\'plane\'][0]\n                        gt_s = global_gt[\'segmentation\'][0]\n                        gt_num_p = global_gt[\'num_planes\'][0]\n\n                        pred_s = (np.expand_dims(pred_s, -1) == np.reshape(np.arange(options.numOutputPlanes), [1, 1, -1])).astype(np.float32)\n                        gtPlanes.append(gt_p)\n                        predPlanes.append(pred_p)\n                        gtSegmentations.append(gt_s)\n                        gtNumPlanes.append(gt_num_p)\n                        predSegmentations.append(pred_s)\n                        pass\n                    \n                    #planeMasks.append((planeSegmentation < 20).astype(np.float32))\n                    continue\n                \n                print(losses)\n                print(total_loss)\n                #print(losses)\n                #exit(1)\n                im = img[0]\n                image = ((im + 0.5) * 255).astype(np.uint8)                \n\n                gt_d = global_gt[\'depth\'].squeeze()\n                                \n\n                if options.predictLocal:\n                    pred_local_s = 1 / (1 + np.exp(-local_pred[\'score\'][0]))\n                    pred_local_p = local_pred[\'plane\'][0]\n                    pred_local_m = local_pred[\'mask\'][0]\n                  \n                    gt_local_s = local_gt[\'score\'][0]\n                    gt_local_m = local_gt[\'mask\'][0]\n\n                    #visualize local plane prediction\n                    stride = 8\n                    boxSize = 64\n                    xs = np.arange(WIDTH / stride) * stride + stride / 2\n                    ys = np.arange(HEIGHT / stride) * stride + stride / 2\n                    padding = boxSize / 2 + 1\n                    maskImage = np.zeros((HEIGHT + padding * 2, WIDTH + padding * 2, 3), dtype=np.uint8)\n                    maskImage[padding:padding + HEIGHT, padding:padding + WIDTH, :] = image / 2\n                    for gridY, y in enumerate(ys):\n                        for gridX, x in enumerate(xs):\n                            score = pred_local_s[gridY][gridX]\n                            if score < 0.5:\n                                continue                              \n                            mask = pred_local_m[gridY][gridX].reshape([16, 16])        \n                            mask = cv2.resize(mask, (boxSize, boxSize))\n                            maskImage[y - boxSize / 2 + padding:y + boxSize / 2 + padding, x - boxSize / 2 + padding:x + boxSize / 2 + padding, 0][mask > 0.5] = 255\n                            continue\n                        continue\n                    for gridY, y in enumerate(ys):\n                        for gridX, x in enumerate(xs):\n                            score = gt_local_s[gridY][gridX]\n                            if score < 0.5:\n                                continue                              \n                            mask = gt_local_m[gridY][gridX].reshape([16, 16])        \n                            mask = cv2.resize(mask, (boxSize, boxSize))\n                            maskImage[y - boxSize / 2 + padding:y + boxSize / 2 + padding, x - boxSize / 2 + padding:x + boxSize / 2 + padding, 2][mask > 0.5] = 255\n                            continue\n                        continue\n                    pass\n\n                pred_p = global_pred[\'plane\'][0]\n                pred_s = global_pred[\'segmentation\'][0]\n\n                pred_np_m = global_pred[\'non_plane_mask\'][0]\n                pred_np_d = global_pred[\'non_plane_depth\'][0]\n                pred_np_n = global_pred[\'non_plane_normal\'][0]\n                \n                planeMask = 1 - global_gt[\'non_plane_mask\'][0]\n                info = global_gt[\'info\'][0]\n\n                \n                all_segmentations = np.concatenate([pred_s, pred_np_m], axis=2)\n                all_segmentations_softmax = softmax(all_segmentations)\n                segmentation = np.argmax(all_segmentations, 2)\n                \n                \n                #pred_p, segmentation, numPlanes = mergePlanes(global_gt[\'plane\'][0], np.concatenate([global_gt[\'segmentation\'][0], global_gt[\'non_plane_mask\'][0]], axis=2), global_gt[\'depth\'][0].squeeze(), global_gt[\'info\'][0], np.concatenate([pred_s, pred_np_m], axis=2))\n                \n\n                plane_depths = calcPlaneDepths(pred_p, WIDTH, HEIGHT, info)\n                all_depths = np.concatenate([plane_depths, pred_np_d], axis=2)\n                \n                pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape(HEIGHT, WIDTH)\n\n                plane_normals = calcPlaneNormals(pred_p, WIDTH, HEIGHT)\n                all_normals = np.concatenate([plane_normals, np.expand_dims(pred_np_n, 2)], axis=2)\n                pred_n = np.sum(all_normals * np.expand_dims(one_hot(segmentation, options.numOutputPlanes+1), -1), 2)\n                #pred_n = all_normals.reshape(-1, options.numOutputPlanes + 1, 3)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape((HEIGHT, WIDTH, 3))\n                \n\n                if False:\n                    gt_s = global_gt[\'segmentation\'][0]\n                    all_segmentations = np.concatenate([gt_s, 1 - planeMask], axis=2)\n                    gt_p = global_gt[\'plane\'][0]\n\n                    # valid_mask = (np.linalg.norm(gt_p, axis=1) > 0).astype(np.float32)\n                    # diff = np.min(np.linalg.norm(np.expand_dims(gt_p, 1) - np.expand_dims(pred_p, 0), axis=2), 1)\n                    # num += valid_mask.sum()\n                    # lossSum += (diff * valid_mask).sum()\n                    #gt_p = np.stack([-gt_p[:, 0], -gt_p[:, 2], -gt_p[:, 1]], axis=1)\n                    \n                    plane_depths = calcPlaneDepths(gt_p, WIDTH, HEIGHT, info)\n                    all_depths = np.concatenate([plane_depths, pred_np_d], axis=2)\n\n                    segmentation = np.argmax(all_segmentations, 2)\n                    pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape(HEIGHT, WIDTH)\n                    # print(gt_p)\n                    # for segmentIndex in xrange(options.numOutputPlanes):\n                    #     cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_mask_\' + str(segmentIndex) + \'.png\', drawMaskImage(segmentation == segmentIndex))\n                    #     continue\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n                    #exit(1)\n                    pass\n\n                \n\n                gt_p = global_gt[\'plane\'][0]\n                gt_s = global_gt[\'segmentation\'][0]\n                gt_num_p = global_gt[\'num_planes\'][0]\n                gtPlanes.append(gt_p)\n                predPlanes.append(pred_p)\n                gtSegmentations.append(gt_s)\n                gtNumPlanes.append(gt_num_p)\n                predSegmentations.append(pred_s)\n                \n            \n                gtDepths.append(gt_d)\n                planeMasks.append(planeMask.squeeze())\n                predDepths.append(pred_d)\n                evaluateDepths(predDepths[-1], gtDepths[-1], gtDepths[-1] > 0, planeMasks[-1])\n                \n                \n                if index >= 10:\n                    continue\n\n                if options.predictSemantics:\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_semantics_pred.png\', drawSegmentationImage(global_pred[\'semantics\'][0], blackIndex=0))\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_semantics_gt.png\', drawSegmentationImage(global_gt[\'semantics\'][0], blackIndex=0))\n                    pass\n\n                if \'cost_mask\' in debug:\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_cost_mask.png\', drawMaskImage(np.sum(debug[\'cost_mask\'][0], axis=-1)))\n\n                    for planeIndex in xrange(options.numOutputPlanes + 1):\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_cost_mask_\' + str(planeIndex) + \'.png\', drawMaskImage(debug[\'cost_mask\'][0, :, :, planeIndex]))\n                        continue\n                    all_segmentations = np.concatenate([pred_s, pred_np_m], axis=2)\n                    for planeIndex in xrange(options.numOutputPlanes + 1):\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred_\' + str(planeIndex) + \'.png\', drawMaskImage(all_segmentations[:, :, planeIndex]))\n                        continue\n                    exit(1)\n                    pass\n                \n                if \'normal\' in global_gt:\n                    gt_n = global_gt[\'normal\'][0]\n                    norm = np.linalg.norm(gt_n, axis=-1, keepdims=True)\n                    gt_n /= np.maximum(norm, 1e-4)\n                    \n                    #gt_n = np.stack([-gt_n[:, :, 0], -gt_n[:, :, 2], -gt_n[:, :, 1]], axis=2)\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_gt.png\', drawNormalImage(gt_n))\n                    #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_pred.png\', drawNormalImage(pred_np_n))\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_pred.png\', drawNormalImage(pred_n))\n                    pass\n                \n                if \'segmentation\' in global_gt:\n                    gt_s = global_gt[\'segmentation\'][0]\n                    gt_p = global_gt[\'plane\'][0]\n\n                    \n                    #for planeIndex in xrange(20):\n                    #cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(gt_s[:, :, planeIndex]))\n                    #continue\n                    \n                    \n                    # print(gt_p)\n                    # print(gt_n[109][129])\n                    # print(gt_n[166][245])\n                    # print(gt_s[109][129])\n                    # print(gt_s[166][245])\n                    # print(plane_normals[109][129])\n                    # print(plane_normals[166][245])                    \n                    # for planeIndex in xrange(20):\n                    #     cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(gt_s[:, :, planeIndex]))\n                    #     continue\n                    # exit(1)\n                    \n                    gt_s, gt_p = sortSegmentations(gt_s, gt_p, pred_p)\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_plane_mask_gt.png\', drawMaskImage(planeMask))  \n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_gt.png\', drawSegmentationImage(np.concatenate([gt_s, 1 - planeMask], axis=2), blackIndex=options.numOutputPlanes)\n)\n                    #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_test.png\', drawMaskImage(np.sum(np.concatenate([gt_s, 1 - planeMask], axis=2), axis=2)))\n                    #exit(1)\n                    #exit(1)\n                    pass\n\n\n                if options.predictConfidence == 1 and options.dataset == \'SUNCG\':\n                    assert(False)\n                    pred_p_c = global_pred[\'confidence\'][0]\n                    pred_p_c = 1 / (1 + np.exp(-pred_p_c))\n                    #print(pred_p_c)\n                    # print(losses)\n                    # print(debug[\'plane\'][0])\n                    # print(pred_p)\n                    # exit(1)\n                    numPlanes = global_gt[\'num_planes\'][0]\n                    print((numPlanes, (pred_p_c > 0.5).sum()))\n                    \n                    pred_p_c = (pred_p_c > 0.5).astype(np.float32)\n                    pred_p *= pred_p_c\n                    pred_s -= (1 - pred_p_c.reshape([1, 1, options.numOutputPlanes])) * 10\n                    pass\n                  \n                if False:\n                    #dump results for post processing\n                    if index >= 10:\n                        break\n                    np.save(options.dump_dir + \'/planes_\' + str(index) + \'.npy\', pred_p)\n                    np.save(options.dump_dir + \'/segmentations_\' + str(index) + \'.npy\', pred_s)\n                    np.save(options.dump_dir + \'/segmentations_gt_\' + str(index) + \'.npy\', gt_s)\n                    np.save(options.dump_dir + \'/non_plane_depth_\' + str(index) + \'.npy\', pred_np_d)\n                    np.save(options.dump_dir + \'/non_plane_segmentation_\' + str(index) + \'.npy\', pred_np_m)\n                    boundary = pred_boundary[0]\n                    boundary = 1 / (1 + np.exp(-boundary))\n                    boundary = np.concatenate([boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)                    \n                    cv2.imwrite(options.dump_dir + \'/boundary_\' + str(index) + \'.png\', drawMaskImage(boundary))\n                    cv2.imwrite(options.dump_dir + \'/image_\' + str(index) + \'.png\', cv2.resize(image, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR))\n                    np.save(options.dump_dir + \'/depth_\' + str(index) + \'.npy\', gt_d)\n                    continue                \n\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', image)\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth.png\', drawDepthImage(gt_d))\n                #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_overlay.png\', drawDepthImageOverlay(image, gt_d))\n                \n                if options.predictBoundary:\n                    pred_boundary = global_pred[\'boundary\'][0]\n                    pred_boundary = 1 / (1 + np.exp(-pred_boundary))\n                    boundary = np.concatenate([pred_boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_boundary_pred.png\', drawMaskImage(boundary))\n                    pass\n\n                if \'boundary\' in global_gt:\n                    gt_boundary = global_gt[\'boundary\'][0]\n                    boundary = np.concatenate([gt_boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)                \n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_boundary_gt.png\', drawMaskImage(boundary))\n                    pass\n\n                for layerIndex, layer in enumerate(options.deepSupervisionLayers):\n                    segmentation_deep = np.argmax(deep_preds[layerIndex][\'segmentation\'][0], 2)\n                    segmentation_deep[segmentation_deep == options.numOutputPlanes] = -1\n                    segmentation_deep += 1\n                \n                    plane_depths_deep = calcPlaneDepths(deep_preds[layerIndex][\'plane\'][0], WIDTH, HEIGHT, info)\n                    all_depths_deep = np.concatenate([pred_np_d, plane_depths_deep], axis=2)\n                    pred_d_deep = all_depths_deep.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation_deep.reshape(-1)].reshape(HEIGHT, WIDTH)\n                \n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred_\' + str(layerIndex) + \'.png\', drawSegmentationImage(deep_preds[layerIndex][\'segmentation\'][0]))\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred_\' + str(layerIndex) + \'.png\', drawDepthImage(pred_d_deep))\n                    pass\n\n\n                #print(pred_np_m)\n                #print(pred_s)\n                #print(global_gt[\'plane\'][0])\n                #print(pred_p)\n                #exit(1)\n\n                print(\'depth diff\', np.abs(pred_d - gt_d).mean())\n                \n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(all_segmentations, blackIndex=options.numOutputPlanes))\n                #exit(1)\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_diff.png\', drawMaskImage(np.abs(pred_d - gt_d) * planeMask.squeeze() / 0.2))\n                #exit(1)\n                \n                \n                #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_plane_mask.png\', drawMaskImage(planeMask))           \n\n                #print(np.concatenate([np.arange(options.numOutputPlanes).reshape(-1, 1), planes, pred_p, preds_p[0][0]], axis=1))\n\n                #print(np.concatenate([distance[0], preds_p[0][0], pred_p], axis=1))\n                            \n                #segmentation = np.argmax(pred_s, 2)\n                #writePLYFile(options.test_dir, index, image, pred_d, segmentation, np.zeros(pred_boundary[0].shape))\n                #writePLYFileParts(options.test_dir, index, image, pred_d, segmentation)\n                #gt_s_ori = gt_s_ori[0]\n\n\n                # if \'depth\' in debug:\n                #     cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred_1.png\', drawDepthImage(debug[\'depth\'][0]))\n                #     gt_s_ori = debug[\'segmentation\'][0]\n                #     cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_gt.png\', drawSegmentationImage(gt_s_ori, blackIndex=options.numOutputPlanes))\n                #     total_loss = 0\n                #     for planeIndex in xrange(gt_s_ori.shape[-1]):\n                #         mask_pred = all_segmentations_softmax[:, :, planeIndex]\n                #         loss = -(gt_s_ori[:, :, planeIndex] * np.log(np.maximum(all_segmentations_softmax[:, :, planeIndex], 1e-31))).mean() * 1000\n                #         print(planeIndex, loss)\n                #         total_loss += loss\n                #         cv2.imwrite(options.test_dir + \'/mask_pred_\' + str(planeIndex) + \'.png\', drawMaskImage(mask_pred))\n                #         cv2.imwrite(options.test_dir + \'/mask_gt_\' + str(planeIndex) + \'.png\', drawMaskImage(gt_s_ori[:, :, planeIndex]))\n                #         continue\n                #     print(total_loss)\n                #     print(gt_s_ori.sum(2).max())                    \n                #     exit(1)\n                #     pass\n\n                \n                if False:\n                    #distance = distance[0]\n                    print(distance)\n                    diff = np.linalg.norm(np.expand_dims(planes, 1) - np.expand_dims(pred_p, 0), axis=2)\n                    print(np.concatenate([planes, pred_p, pow(np.min(diff, axis=1, keepdims=True), 2), np.expand_dims(np.argmin(diff, axis=1), -1)], axis=1))\n                    print(pred_p_c)\n                    \n                    #print(distance[:, 6:8].sum(0))\n                    #print(pow(np.linalg.norm(distance[:, :3] - distance[:, 3:6], 2, 1), 2) * 100)\n                    #print(test)\n                    segmentation = np.argmax(all_segmentations, 2) - 1\n                    for planeIndex in xrange(options.numOutputPlanes):\n                        cv2.imwrite(options.test_dir + \'/segmentation_\' + str(planeIndex) + \'.png\', drawMaskImage(segmentation == planeIndex))\n                        cv2.imwrite(options.test_dir + \'/segmentation_\' + str(planeIndex) + \'_gt.png\', drawMaskImage(gt_s[:, :, planeIndex]))\n                        cv2.imwrite(options.test_dir + \'/segmentation_\' + str(planeIndex) + \'_gt_ori.png\', drawMaskImage(gt_s_ori[:, :, planeIndex]))\n                        continue\n                    exit(1)\n                continue\n\n            # if options.dataset == \'SUNCG\':\n            #     if \'pixelwise\' not in options.suffix:\n            #         evaluatePlaneSegmentation(np.array(predPlanes), np.array(predSegmentations), np.array(gtPlanes), np.array(gtSegmentations), np.array(gtNumPlanes), planeDistanceThreshold = 0.3, IOUThreshold = 0.5, prefix=\'test/planenet_\')\n            #     elif \'_2\' in options.suffix:\n            #         evaluatePlaneSegmentation(np.array(predPlanes), np.array(predSegmentations), np.array(gtPlanes), np.array(gtSegmentations), np.array(gtNumPlanes), planeDistanceThreshold = 0.3, IOUThreshold = 0.5, prefix=\'test/pixelwise_pred_\')\n            #     elif \'_3\' in options.suffix:\n            #         evaluatePlaneSegmentation(np.array(predPlanes), np.array(predSegmentations), np.array(gtPlanes), np.array(gtSegmentations), np.array(gtNumPlanes), planeDistanceThreshold = 0.3, IOUThreshold = 0.5, prefix=\'test/pixelwise_gt_\')\n            #         pass\n            #     pass\n            \n            predDepths = np.array(predDepths)\n            gtDepths = np.array(gtDepths)\n            planeMasks = np.array(planeMasks)\n            #predMasks = np.array(predMasks)\n            evaluateDepths(predDepths, gtDepths, gtDepths > 0, planeMasks)\n            exit(1)\n\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n        \n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return\n\n\n# def predict(options):\n#     options.test_dir += \'_predict\'\n#     if not os.path.exists(options.test_dir):\n#         os.system(""mkdir -p %s""%options.test_dir)\n#         pass\n\n#     batchSize = 1\n#     img_inp = tf.placeholder(tf.float32,shape=(batchSize,HEIGHT,WIDTH,3),name=\'img_inp\')\n#     plane_gt=tf.placeholder(tf.float32,shape=(batchSize,options.numOutputPlanes, 3),name=\'plane_inp\')\n#     validating_inp = tf.constant(0, tf.int32)\n\n#     global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp_train, img_inp_val, img_inp_rgbd_train, img_inp_rgbd_val, training_flag, options)\n\n#     var_to_restore = tf.global_variables()\n    \n \n#     config=tf.ConfigProto()\n#     config.gpu_options.allow_growth=True\n#     config.allow_soft_placement=True\n\n\n#     if dataset == \'SUNCG\':\n#         image_list_file = os.path.join(\'../PythonScripts/SUNCG/image_list_100_tail_500000.txt\')\n#         with open(image_list_file) as f:\n#             im_names = [{\'image\': im_name.strip().replace(\'plane_global.npy\', \'mlt.png\'), \'depth\': im_name.strip().replace(\'plane_global.npy\', \'depth.png\'), \'normal\': im_name.strip().replace(\'plane_global.npy\', \'norm_camera.png\'), \'valid\': im_name.strip().replace(\'plane_global.npy\', \'valid.png\'), \'plane\': im_name.strip()} for im_name in f.readlines()]\n#             pass\n#     else:\n#         im_names = glob.glob(\'../../Data/NYU_RGBD/*_color.png\')\n#         im_names = [{\'image\': im_name, \'depth\': im_name.replace(\'color.png\', \'depth.png\'), \'normal\': im_name.replace(\'color.png\', \'norm_camera.png\'), \'invalid_mask\': im_name.replace(\'color.png\', \'valid.png\')} for im_name in im_names]\n#         pass\n      \n#     if numImages > 0:\n#         im_names = im_names[:numImages]\n#         pass\n\n#     #if args.imageIndex > 0:\n#     #im_names = im_names[args.imageIndex:args.imageIndex + 1]\n#     #pass    \n\n#     init_op = tf.group(tf.global_variables_initializer(),\n#                        tf.local_variables_initializer())\n\n\n#     with tf.Session(config=config) as sess:\n#         saver = tf.train.Saver()\n#         #sess.run(tf.global_variables_initializer())\n#         saver.restore(sess,""%s/%s.ckpt""%(options.checkpoint_dir,keyname))\n\n#         gtDepths = []\n#         predDepths = []\n#         segmentationDepths = []\n#         predDepthsOneHot = []\n#         planeMasks = []\n#         predMasks = []\n\n#         imageWidth = WIDTH\n#         imageHeight = HEIGHT\n#         focalLength = 517.97\n#         urange = np.arange(imageWidth).reshape(1, -1).repeat(imageHeight, 0) - imageWidth * 0.5\n#         vrange = np.arange(imageHeight).reshape(-1, 1).repeat(imageWidth, 1) - imageHeight * 0.5\n#         ranges = np.array([urange / focalLength, np.ones(urange.shape), -vrange / focalLength]).transpose([1, 2, 0])\n        \n#         cv2.imwrite(options.test_dir + \'/one.png\', np.ones((HEIGHT, WIDTH), dtype=np.uint8) * 255)\n#         cv2.imwrite(options.test_dir + \'/zero.png\', np.zeros((HEIGHT, WIDTH), dtype=np.uint8) * 255)\n#         for index, im_name in enumerate(im_names):\n#             if index <= -1:\n#                 continue\n#             print(im_name[\'image\'])\n#             im = cv2.imread(im_name[\'image\'])\n#             image = im.astype(np.float32, copy=False)\n#             image = image / 255 - 0.5\n#             image = cv2.resize(image, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n\n#             #planes = np.load(im_name[\'plane\'])\n#             # numPlanes = planes.shape[0]\n#             # if numPlanes > options.numOutputPlanes:\n#             #     planeAreas = planes[:, 3:].sum(1)\n#             #     sortInds = np.argsort(planeAreas)[::-1]\n#             #     planes = planes[sortInds[:options.numOutputPlanes]]\n#             #     pass\n#             # gt_p = np.zeros((1, options.numOutputPlanes, 3))\n#             # gt_p[0, :numPlanes] = planes[:numPlanes, :3]\n\n#             normal = np.array(PIL.Image.open(im_name[\'normal\'])).astype(np.float) / 255 * 2 - 1\n#             norm = np.linalg.norm(normal, 2, 2)\n#             for c in xrange(3):\n#                 normal[:, :, c] /= norm\n#                 continue\n#             normal = cv2.resize(normal, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n            \n#             depth = np.array(PIL.Image.open(im_name[\'depth\'])).astype(np.float) / 1000\n#             depth = cv2.resize(depth, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n\n#             invalid_mask = cv2.resize(cv2.imread(im_name[\'invalid_mask\'], 0), (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR) > 128\n\n#             gtDepths.append(depth)\n\n            \n#             pred_p, pred_d, pred_n, pred_s, pred_np_m, pred_np_d, pred_np_n, pred_boundary, pred_local_score, pred_local_p, pred_local_mask = sess.run([plane_pred, depth_pred, normal_pred, segmentation_pred, non_plane_mask_pred, non_plane_depth_pred, non_plane_normal_pred, boundary_pred, local_score_pred, local_p_pred, local_mask_pred], feed_dict = {img_inp:np.expand_dims(image, 0), plane_gt: np.zeros((batchSize, options.numOutputPlanes, 3))})\n\n\n#             pred_s = pred_s[0] \n#             pred_p = pred_p[0]\n#             pred_np_m = pred_np_m[0]\n#             pred_np_d = pred_np_d[0]\n#             pred_np_n = pred_np_n[0]\n#             #pred_s = 1 / (1 + np.exp(-pred_s))\n\n#             plane_depths = calcPlaneDepths(pred_p, WIDTH, HEIGHT)\n#             all_depths = np.concatenate([pred_np_d, plane_depths], axis=2)\n\n#             all_segmentations = np.concatenate([pred_np_m, pred_s], axis=2)\n#             segmentation = np.argmax(all_segmentations, 2)\n#             if suffix != \'pixelwise\':\n#                 pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape(HEIGHT, WIDTH)\n#             else:\n#                 pred_d = np.squeeze(pred_np_d)\n#                 pass\n#             predDepths.append(pred_d)\n#             predMasks.append(segmentation != 0)\n#             planeMasks.append(invalid_mask)\n\n#             #depthError, normalError, occupancy, segmentationTest, reconstructedDepth, occupancyMask = evaluatePlanes(pred_p, im_name[\'image\'])\n#             #reconstructedDepth = cv2.resize(reconstructedDepth, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n            \n#             #evaluatePlanes(pred_p[0], im_name, options.test_dir, index)\n#             #print(pred_p)\n#             #print(gt_p)\n#             #print((pow(pred_d[0, :, :, 0] - depth, 2) * (gt_s.max(2) > 0.5)).mean())\n#             #print((depthError, normalError, occupancy))\n            \n#             evaluateDepths(predDepths[index], gtDepths[index], np.ones(planeMasks[index].shape), planeMasks[index])\n\n#             if index >= 10:\n#                 continue\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', cv2.resize(im, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR))\n#             #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_gt.png\', (minDepth / np.clip(depth, minDepth, 20) * 255).astype(np.uint8))\n#             #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', (minDepth / np.clip(pred_d[0, :, :, 0], minDepth, 20) * 255).astype(np.uint8))\n#             #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_plane.png\', (minDepth / np.clip(reconstructedDepth, minDepth, 20) * 255).astype(np.uint8))\n\n#             pred_boundary = pred_boundary[0]\n#             boundary = (1 / (1 + np.exp(-pred_boundary)) * 255).astype(np.uint8)\n#             boundary = np.concatenate([boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_boundary_pred.png\', boundary)\n            \n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_inp.png\', drawDepthImage(depth))\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n#             #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_plane.png\', drawDepthImage(reconstructedDepth))\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred_diff.png\', drawDiffImage(pred_d, depth, 0.5))\n#             #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_plane_diff.png\', np.minimum(np.abs(reconstructedDepth - depth) / 0.5 * 255, 255).astype(np.uint8))\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_inp.png\', drawNormalImage(normal))\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_pred.png\', drawNormalImage(pred_np_n))\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(all_segmentations, black=True))\n\n#             segmentation = np.argmax(pred_s, 2)\n#             #writePLYFile(options.test_dir, index, image, pred_p, segmentation)\n\n#             if index < 0:\n#                 for planeIndex in xrange(options.numOutputPlanes):\n#                     cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_\' + str(planeIndex) + \'.png\', drawMaskImage(pred_s[:, :, planeIndex]))\n#                     #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_\' + str(planeIndex) + \'_gt.png\', drawMaskImage(gt_s[:, :, planeIndex]))\n#                     continue\n#                 pass\n#             continue\n#         predDepths = np.array(predDepths)\n#         gtDepths = np.array(gtDepths)\n#         planeMasks = np.array(planeMasks)\n#         predMasks = np.array(predMasks)\n#         #evaluateDepths(predDepths, gtDepths, planeMasks, predMasks)\n#         evaluateDepths(predDepths, gtDepths, planeMasks, planeMasks)\n#         #exit(1)\n#         pass\n#     return\n\n\n# def fitPlanesRGBD(options):\n#     writeHTMLRGBD(\'../results/RANSAC_RGBD/index.html\', 10)\n#     exit(1)\n#     if not os.path.exists(options.checkpoint_dir):\n#         os.system(""mkdir -p %s""%options.checkpoint_dir)\n#         pass\n#     if not os.path.exists(options.test_dir):\n#         os.system(""mkdir -p %s""%options.test_dir)\n#         pass\n    \n#     min_after_dequeue = 1000\n\n#     reader_rgbd = RecordReaderRGBD()\n#     filename_queue_rgbd = tf.train.string_input_producer([\'../planes_nyu_rgbd_train.tfrecords\'], num_epochs=1)\n#     img_inp_rgbd, global_gt_dict_rgbd, local_gt_dict_rgbd = reader_rgbd.getBatch(filename_queue_rgbd, numOutputPlanes=options.numOutputPlanes, batchSize=1, min_after_dequeue=min_after_dequeue, getLocal=True)\n\n#     config=tf.ConfigProto()\n#     config.gpu_options.allow_growth=True\n#     config.allow_soft_placement=True\n\n#     init_op = tf.group(tf.global_variables_initializer(),\n#                        tf.local_variables_initializer())\n\n#     with tf.Session(config=config) as sess:\n#         sess.run(init_op)\n\n#         coord = tf.train.Coordinator()\n#         threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n#         try:\n#             gtDepths = []\n#             predDepths = []\n#             planeMasks = []\n#             for index in xrange(10):\n#                 image, depth, path = sess.run([img_inp_rgbd, global_gt_dict_rgbd[\'depth\'], global_gt_dict_rgbd[\'path\']])\n#                 image = ((image[0] + 0.5) * 255).astype(np.uint8)\n#                 depth = depth.squeeze()\n                \n#                 cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', image)\n#                 cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth.png\', drawDepthImage(depth))\n#                 #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_mask.png\', drawMaskImage(depth == 0))\n#                 planes, planeSegmentation, depthPred = fitPlanes(depth, numPlanes=20)                \n#                 cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(planeSegmentation))\n#                 cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(depthPred))\n\n#                 gtDepths.append(depth)\n#                 predDepths.append(depthPred)\n#                 planeMasks.append((planeSegmentation < 20).astype(np.float32))\n#                 continue\n#             predDepths = np.array(predDepths)\n#             gtDepths = np.array(gtDepths)\n#             planeMasks = np.array(planeMasks)\n#             evaluateDepths(predDepths, gtDepths, np.ones(planeMasks.shape, dtype=np.bool), planeMasks)            \n#         except tf.errors.OutOfRangeError:\n#             print(\'done fitting\')\n#         finally:\n#             # When done, ask the threads to stop.\n#             coord.request_stop()\n#             pass\n#     return\n\ndef writeInfo(options):\n    x = (np.arange(11) * 0.1).tolist()\n    ys = []\n    ys.append(np.load(\'test/planenet_pixel_IOU.npy\').tolist())\n    ys.append(np.load(\'test/pixelwise_pred_pixel_IOU.npy\').tolist())\n    ys.append(np.load(\'test/pixelwise_gt_pixel_IOU.npy\').tolist())\n    plotCurves(x, ys, filename = \'test/plane_comparison.png\', xlabel=\'IOU\', ylabel=\'pixel coverage\', labels=[\'planenet\', \'pixelwise+RANSAC\', \'GT+RANSAC\'])\n\n    x = (0.5 - np.arange(11) * 0.05).tolist()\n    ys = []\n    ys.append(np.load(\'test/planenet_pixel_diff.npy\').tolist())\n    ys.append(np.load(\'test/pixelwise_pred_pixel_diff.npy\').tolist())\n    ys.append(np.load(\'test/pixelwise_gt_pixel_diff.npy\').tolist())\n    plotCurves(x, ys, filename = \'test/plane_comparison_diff.png\', xlabel=\'diff\', ylabel=\'pixel coverage\', labels=[\'planenet\', \'pixelwise+RANSAC\', \'GT+RANSAC\'])\n    \n    return\n\ndef parse_args():\n    """"""\n    Parse input arguments\n    """"""\n    parser = argparse.ArgumentParser(description=\'Planenet\')\n    parser.add_argument(\'--gpu\', dest=\'gpu_id\',\n                        help=\'GPU device id to use [0]\',\n                        default=0, type=int)\n    #task: [train, test, predict]\n    parser.add_argument(\'--task\', dest=\'task\',\n                        help=\'task type: [train, test, predict]\',\n                        default=\'train\', type=str)\n    parser.add_argument(\'--restore\', dest=\'restore\',\n                        help=\'how to restore the model\',\n                        default=0, type=int)\n    parser.add_argument(\'--numOutputPlanes\', dest=\'numOutputPlanes\',\n                        help=\'the number of output planes\',\n                        default=20, type=int)\n    parser.add_argument(\'--batchSize\', dest=\'batchSize\',\n                        help=\'batch size\',\n                        default=16, type=int)\n    parser.add_argument(\'--dataset\', dest=\'dataset\',\n                        help=\'dataset name for test/predict\',\n                        default=\'\', type=str)\n    parser.add_argument(\'--numImages\', dest=\'numImages\',\n                        help=\'the number of images to test/predict\',\n                        default=10, type=int)\n    parser.add_argument(\'--boundaryLoss\', dest=\'boundaryLoss\',\n                        help=\'use boundary loss: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--diverseLoss\', dest=\'diverseLoss\',\n                        help=\'use diverse loss: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--labelLoss\', dest=\'labelLoss\',\n                        help=\'use label loss: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--planeLoss\', dest=\'planeLoss\',\n                        help=\'use plane loss: [0, 1]\',\n                        default=1, type=int)        \n    parser.add_argument(\'--deepSupervision\', dest=\'deepSupervision\',\n                        help=\'deep supervision level: [0, 1, 2]\',\n                        default=0, type=int)\n    parser.add_argument(\'--sameMatching\', dest=\'sameMatching\',\n                        help=\'use the same matching for all deep supervision layers and the final prediction: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--anchorPlanes\', dest=\'anchorPlanes\',\n                        help=\'use anchor planes for all deep supervision layers and the final prediction: [0, 1]\',\n                        default=0, type=int) \n    parser.add_argument(\'--crf\', dest=\'crf\',\n                        help=\'the number of CRF iterations\',\n                        default=0, type=int)\n    parser.add_argument(\'--crfrnn\', dest=\'crfrnn\',\n                        help=\'the number of CRF (as RNN) iterations\',\n                        default=0, type=int)    \n    parser.add_argument(\'--backwardLossWeight\', dest=\'backwardLossWeight\',\n                        help=\'backward matching loss\',\n                        default=0, type=float)\n    parser.add_argument(\'--predictBoundary\', dest=\'predictBoundary\',\n                        help=\'whether predict boundary or not: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--predictSemantics\', dest=\'predictSemantics\',\n                        help=\'whether predict semantics or not: [0, 1]\',\n                        default=0, type=int)    \n    parser.add_argument(\'--predictLocal\', dest=\'predictLocal\',\n                        help=\'whether predict local planes or not: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--predictConfidence\', dest=\'predictConfidence\',\n                        help=\'whether predict plane confidence or not: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--predictPixelwise\', dest=\'predictPixelwise\',\n                        help=\'whether predict pixelwise depth or not: [0, 1]\',\n                        default=0, type=int)    \n    parser.add_argument(\'--fineTuningCheckpoint\', dest=\'fineTuningCheckpoint\',\n                        help=\'specify the model for fine-tuning\',\n                        default=\'../PlaneSetGeneration/dump_planenet_diverse/train_planenet_diverse.ckpt\', type=str)\n    parser.add_argument(\'--suffix\', dest=\'suffix\',\n                        help=\'add a suffix to keyname to distinguish experiments\',\n                        default=\'\', type=str)\n    parser.add_argument(\'--l2Weight\', dest=\'l2Weight\',\n                        help=\'L2 regulation weight\',\n                        default=5e-4, type=float)\n    parser.add_argument(\'--LR\', dest=\'LR\',\n                        help=\'learning rate\',\n                        default=3e-5, type=float)\n    parser.add_argument(\'--hybrid\', dest=\'hybrid\',\n                        help=\'hybrid training\',\n                        default=\'1\', type=str)\n    parser.add_argument(\'--rootFolder\', dest=\'rootFolder\',\n                        help=\'root folder\',\n                        default=\'/mnt/vision/PlaneNet/\', type=str)\n    parser.add_argument(\'--dataFolder\', dest=\'dataFolder\',\n                        help=\'data folder\',\n                        default=\'/home/chenliu/Projects/PlaneNet/\', type=str)\n    parser.add_argument(\'--saveInterval\', dest=\'saveInterval\',\n                        help=\'save interval\',\n                        default=900, type=int)\n    \n\n    args = parser.parse_args()\n    args.keyname = os.path.basename(__file__).rstrip(\'.py\')\n    args.keyname = args.keyname.replace(\'train_\', \'\')\n\n    if args.numOutputPlanes != 20:\n        args.keyname += \'_np\' + str(args.numOutputPlanes)\n        pass\n    args.keyname += \'_hybrid\' + args.hybrid\n    \n    if args.boundaryLoss != 1:\n        args.keyname += \'_bl\' + str(args.boundaryLoss)\n        pass\n    if args.diverseLoss == 0:\n        args.keyname += \'_dl0\'\n        pass\n    if args.labelLoss == 1:\n        args.keyname += \'_ll1\'\n        pass    \n    if args.planeLoss == 0:\n        args.keyname += \'_pl0\'\n        pass\n    if args.deepSupervision != 1:\n        args.keyname += \'_ds\' + str(args.deepSupervision)\n        pass\n    if args.crf > 0:\n        args.keyname += \'_crf\' + str(args.crf)\n        pass\n    if args.crfrnn != 0:\n        args.keyname += \'_crfrnn\' + str(args.crfrnn)\n        pass\n    if args.backwardLossWeight > 0:\n        args.keyname += \'_bw\' + str(args.backwardLossWeight)\n        pass\n    if args.predictBoundary == 1:\n        args.keyname += \'_pb\'\n        pass\n    if args.predictConfidence == 1:\n        args.keyname += \'_pc\'\n        pass        \n    # if args.predictLocal == 1:\n    #     args.keyname += \'_pl\'\n    #     pass\n    if args.predictPixelwise == 1:\n        args.keyname += \'_pp\'\n        pass\n    if args.predictSemantics == 1:\n        args.keyname += \'_ps\'\n        pass    \n    if args.sameMatching == 0:\n        args.keyname += \'_sm0\'\n        pass\n    if args.anchorPlanes == 1:\n        args.keyname += \'_ap1\'\n        pass\n\n    #args.predictSemantics = 0\n    #args.predictBoundary = 0\n    \n    args.checkpoint_dir = args.rootFolder + \'/checkpoint/\' + args.keyname\n    args.log_dir = \'log/\' + args.keyname\n    args.test_dir = \'test/\' + args.keyname + \'_\' + args.dataset\n    args.predict_dir = \'predict/\' + args.keyname + \'_\' + args.dataset\n    args.dump_dir = \'dump/\' + args.keyname\n    \n    #layers where deep supervision happens\n    args.deepSupervisionLayers = []\n    if args.deepSupervision >= 1:\n        args.deepSupervisionLayers.append(\'res4b22_relu\')\n        pass\n    if args.deepSupervision >= 2:\n        args.deepSupervisionLayers.append(\'res4b12_relu\')\n        pass\n    \n    args.predictSemantics = 0\n    args.predictPixelwise = 0    \n    return args\n\n\nif __name__==\'__main__\':\n\n    # plane = np.load(\'temp/plane.npy\')\n    # depth = np.load(\'temp/depth.npy\')    \n    # segmentation = np.load(\'temp/segmentation.npy\')\n    # info = np.load(\'temp/info.npy\')\n    # num_planes = np.load(\'temp/num_planes.npy\')\n    # segmentation = np.argmax(segmentation, axis=-1)\n    # print(segmentation.shape)\n    # planes, segmentation, numPlanes = removeSmallSegments(plane, np.zeros((HEIGHT, WIDTH, 3)), depth.squeeze(), np.zeros((HEIGHT, WIDTH, 3)), segmentation, np.zeros((HEIGHT, WIDTH)), info, num_planes)\n    # print(planes)\n    # exit(1)\n    \n    args = parse_args()\n\n    print ""keyname=%s task=%s started""%(args.keyname, args.task)\n    try:\n        if args.task == ""train"":\n            main(args)\n        elif args.task == ""test"":\n            test(args)\n        elif args.task == ""predict"":\n            predict(args)\n        elif args.task == ""fit"":\n            fitPlanesRGBD(args)\n        elif args.task == ""write"":\n            writeInfo(args)\n        else:\n            assert False,""format wrong""\n            pass\n    finally:\n        pass\n\n'"
train_pixelwise.py,91,"b'import tensorflow as tf\nimport numpy as np\nnp.set_printoptions(precision=2, linewidth=200)\nimport cv2\nimport os\nimport time\nimport sys\nimport tf_nndistance\nimport argparse\nimport glob\nimport PIL\nimport scipy.ndimage as ndimage\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom utils import *\nfrom plane_utils import *\nfrom modules import *\n\n\nfrom planenet import PlaneNet\nfrom RecordReader import *\nfrom RecordReaderRGBD import *\nfrom RecordReader3D import *\nfrom RecordReaderAll import *\n#from SegmentationRefinement import *\n\n#training_flag: toggle dropout and batch normalization mode\n#it\'s true for training and false for validation, testing, prediction\n#it also controls which data batch to use (*_train or *_val)\n\n\ndef build_graph(img_inp_train, img_inp_val, training_flag, options):\n    with tf.device(\'/gpu:%d\'%options.gpu_id):\n        img_inp = tf.cond(training_flag, lambda: img_inp_train, lambda: img_inp_val)\n        \n        net = PlaneNet({\'img_inp\': img_inp}, is_training=training_flag, options=options)\n\n        #global predictions\n        plane_pred = net.layers[\'plane_pred\']\n        \n        segmentation_pred = net.layers[\'segmentation_pred\']\n        non_plane_mask_pred = net.layers[\'non_plane_mask_pred\']\n        non_plane_depth_pred = net.layers[\'non_plane_depth_pred\']\n        non_plane_normal_pred = net.layers[\'non_plane_normal_pred\']\n        non_plane_normal_pred = tf.nn.l2_normalize(non_plane_normal_pred, dim=-1)\n\n\n        if False:\n            plane_pred = gt_dict[\'plane\']\n            non_plane_mask_pred = gt_dict[\'non_plane_mask\'] * 10\n            non_plane_depth_pred = gt_dict[\'depth\']\n            non_plane_normal_pred = gt_dict[\'normal\']\n            segmentation_pred = gt_dict[\'segmentation\'][:, :, :, :20] * 10\n            pass\n        \n        \n        global_pred_dict = {\'plane\': plane_pred, \'segmentation\': segmentation_pred, \'non_plane_mask\': non_plane_mask_pred, \'non_plane_depth\': non_plane_depth_pred, \'non_plane_normal\': non_plane_normal_pred}\n\n        if options.predictBoundary:\n            global_pred_dict[\'boundary\'] = net.layers[\'boundary_pred\']\n            pass\n        if options.predictConfidence:\n            global_pred_dict[\'confidence\'] = net.layers[\'plane_confidence_pred\']\n            pass\n        if options.predictSemantics:\n            global_pred_dict[\'semantics\'] = net.layers[\'semantics_pred\']\n            pass\n\n        #local predictions\n        if options.predictLocal:\n            local_pred_dict = {\'score\': net.layers[\'local_score_pred\'], \'plane\': net.layers[\'local_plane_pred\'], \'mask\': net.layers[\'local_mask_pred\']}\n        else:\n            local_pred_dict = {}\n            pass\n\n        \n        #deep supervision\n        deep_pred_dicts = []\n        for layer in options.deepSupervisionLayers:\n            pred_dict = {\'plane\': net.layers[layer+\'_plane_pred\'], \'segmentation\': net.layers[layer+\'_segmentation_pred\'], \'non_plane_mask\': net.layers[layer+\'_non_plane_mask_pred\']}\n            #if options.predictConfidence:\n            #pred_dict[\'confidence\'] = net.layers[layer+\'_plane_confidence_pred\']\n            #pass\n            deep_pred_dicts.append(pred_dict)\n            continue\n\n        \n        if options.anchorPlanes:\n            anchors_np = np.load(\'dump/anchors_\' + options.hybrid + \'.npy\')\n            anchors = tf.reshape(tf.constant(anchors_np.reshape(-1)), anchors_np.shape)\n            anchors = tf.tile(tf.expand_dims(anchors, 0), [options.batchSize, 1, 1])\n            all_pred_dicts = deep_pred_dicts + [global_pred_dict]            \n            for pred_index, pred_dict in enumerate(all_pred_dicts):\n                all_pred_dicts[pred_index][\'plane\'] += anchors\n                continue\n            pass\n\n        pass\n    \n    return global_pred_dict, local_pred_dict, deep_pred_dicts\n\n\ndef build_loss(img_inp_train, img_inp_val, global_pred_dict, deep_pred_dicts, global_gt_dict_train, global_gt_dict_val, training_flag, options):\n    with tf.device(\'/gpu:%d\'%options.gpu_id):\n        debug_dict = {}\n\n        img_inp = tf.cond(training_flag, lambda: img_inp_train, lambda: img_inp_val)        \n        global_gt_dict = {}\n        for name in global_gt_dict_train.keys():\n            global_gt_dict[name] = tf.cond(training_flag, lambda: global_gt_dict_train[name], lambda: global_gt_dict_val[name])\n            continue\n        # local_gt_dict = {}\n        # for name in local_gt_dict_train.keys():\n        #     local_gt_dict[name] = tf.cond(tf.equal(training_flag % 2, 0), lambda: local_gt_dict_train[name], lambda: local_gt_dict_val[name])\n        #     continue\n\n        plane_parameters = tf.reshape(global_pred_dict[\'plane\'], (-1, 3))\n        info = global_gt_dict[\'info\'][0]\n        plane_depths = planeDepthsModule(plane_parameters, WIDTH, HEIGHT, info)\n        plane_depths = tf.transpose(tf.reshape(plane_depths, [HEIGHT, WIDTH, -1, options.numOutputPlanes]), [2, 0, 1, 3])\n\n        non_plane_depth = global_pred_dict[\'non_plane_depth\']\n        all_depths = tf.concat([plane_depths, non_plane_depth], axis=3)\n\n        \n\n        #if options.predictPixelwise == 1:\n        validDepthMask = tf.cast(tf.greater(global_gt_dict[\'depth\'], 1e-4), tf.float32)\n        numValidPixels = tf.reduce_sum(validDepthMask, axis=[1, 2, 3])        \n        depth_loss = tf.constant(0.0)\n        if options.predictPlanes == 1:\n            all_segmentations = tf.concat([global_pred_dict[\'segmentation\'], global_pred_dict[\'non_plane_mask\']], axis=3)\n            all_segmentations_softmax = tf.nn.softmax(all_segmentations)\n            depth_loss += tf.reduce_mean(tf.reduce_sum(tf.squared_difference(all_depths, global_gt_dict[\'depth\']) * all_segmentations_softmax, axis=3, keep_dims=True) * validDepthMask) * 10000\n        else:\n            depth_diff = global_pred_dict[\'non_plane_depth\'] - global_gt_dict[\'depth\']\n            depth_diff_gx = depth_diff - tf.concat([tf.ones([options.batchSize, HEIGHT, 1, 1]), depth_diff[:, :, :WIDTH - 1]], axis=2)\n            depth_diff_gy = depth_diff - tf.concat([tf.ones([options.batchSize, 1, WIDTH, 1]), depth_diff[:, :HEIGHT - 1]], axis=1)\n\n            depth_loss += tf.reduce_mean(tf.reduce_sum(tf.pow(depth_diff * validDepthMask, 2), axis=[1, 2, 3]) / numValidPixels - 0.5 * tf.pow(tf.reduce_sum(depth_diff * validDepthMask, axis=[1, 2, 3]) / numValidPixels, 2) + tf.reduce_sum((tf.pow(depth_diff_gx, 2) + tf.pow(depth_diff_gy, 2)) * validDepthMask, axis=[1, 2, 3]) / numValidPixels) * 1000\n            pass\n        \n        #depth_loss += tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_depth\'], global_gt_dict[\'depth\']) * validDepthMask) * 10000\n\n\n        valid_normal_mask = tf.squeeze(tf.cast(tf.less(tf.slice(global_gt_dict[\'info\'], [0, 19], [options.batchSize, 1]), 2), tf.float32))\n        normal_gt = tf.nn.l2_normalize(global_gt_dict[\'normal\'], dim=-1)\n        normal_loss = tf.reduce_mean(tf.reduce_sum(-global_pred_dict[\'non_plane_normal\'] * normal_gt * validDepthMask, axis=[1, 2, 3]) / numValidPixels * valid_normal_mask) * 1000\n        #normal_loss = tf.reduce_mean(tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_normal\'], global_gt_dict[\'normal\']) * validDepthMask, axis=[1, 2, 3]) * valid_normal_mask) * 1000\n        #normal_loss = tf.constant(0.0)\n\n        valid_semantics_mask = tf.squeeze(tf.cast(tf.not_equal(tf.slice(global_gt_dict[\'info\'], [0, 19], [options.batchSize, 1]), 1), tf.float32))\n        semantics_loss = tf.reduce_mean(tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=global_pred_dict[\'semantics\'], labels=global_gt_dict[\'semantics\']), axis=[1, 2]) * valid_semantics_mask) * 1000\n        \n\n        l2_losses = tf.add_n([options.l2Weight * tf.nn.l2_loss(v) for v in tf.trainable_variables() if \'weights\' in v.name])\n\n\n        loss = depth_loss + normal_loss + semantics_loss + l2_losses\n\n        #if options.pixelwiseLoss:\n        #normal_loss = tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_normal\'], global_gt_dict[\'normal\'])) * 1000\n        #depth_loss = tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_depth\'], global_gt_dict[\'depth\']) * validDepthMask) * 1000\n        #pass\n\n        loss_dict = {\'depth\': depth_loss, \'normal\': normal_loss, \'semantics\': semantics_loss}\n        pass\n    return loss, loss_dict, debug_dict\n\n\ndef main(options):\n    if not os.path.exists(options.checkpoint_dir):\n        os.system(""mkdir -p %s""%options.checkpoint_dir)\n        pass\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n    \n    min_after_dequeue = 1000\n\n\n    train_inputs = []\n    val_inputs = []\n    if \'0\' in options.hybrid:\n        train_inputs.append(options.rootFolder + \'/planes_SUNCG_train.tfrecords\')\n        val_inputs.append(options.rootFolder + \'/planes_SUNCG_val.tfrecords\')        \n        pass\n    if \'1\' in options.hybrid:\n        for _ in xrange(10):\n            train_inputs.append(options.rootFolder + \'/planes_nyu_rgbd_train.tfrecords\')\n            train_inputs.append(options.rootFolder + \'/planes_nyu_rgbd_labeled_train.tfrecords\')\n            val_inputs.append(options.rootFolder + \'/planes_nyu_rgbd_val.tfrecords\')\n            continue\n        pass\n    if \'2\' in options.hybrid:\n        train_inputs.append(options.rootFolder + \'/planes_matterport_train.tfrecords\')\n        val_inputs.append(options.rootFolder + \'/planes_matterport_val.tfrecords\')\n        pass\n    if \'3\' in options.hybrid:\n        train_inputs.append(options.rootFolder + \'/planes_scannet_train.tfrecords\')\n        val_inputs.append(options.rootFolder + \'/planes_scannet_val.tfrecords\')\n        pass\n    \n    reader_train = RecordReaderAll()\n    filename_queue_train = tf.train.string_input_producer(train_inputs, num_epochs=10000)    \n    img_inp_train, global_gt_dict_train, local_gt_dict_train = reader_train.getBatch(filename_queue_train, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True)\n\n    reader_val = RecordReaderAll()\n    filename_queue_val = tf.train.string_input_producer(val_inputs, num_epochs=10000)\n    img_inp_val, global_gt_dict_val, local_gt_dict_val = reader_val.getBatch(filename_queue_val, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True)\n    \n    training_flag = tf.placeholder(tf.bool, shape=[], name=\'training_flag\')\n    \n    #global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp_train, img_inp_val, img_inp_rgbd_train, img_inp_rgbd_val, img_inp_3d_train, img_inp_3d_val, training_flag, options)\n    global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp_train, img_inp_val, training_flag, options)\n    \n    \n    #loss, loss_dict, _ = build_loss(global_pred_dict, local_pred_dict, deep_pred_dicts, global_gt_dict_train, local_gt_dict_train, global_gt_dict_val, local_gt_dict_val, training_flag, options)\n    #loss_rgbd, loss_dict_rgbd, _ = build_loss_rgbd(global_pred_dict, deep_pred_dicts, global_gt_dict_rgbd_train, global_gt_dict_rgbd_val, training_flag, options)\n    loss, loss_dict, _ = build_loss(img_inp_train, img_inp_val, global_pred_dict, deep_pred_dicts, global_gt_dict_train, global_gt_dict_val, training_flag, options)    \n        \n    #loss = tf.cond(tf.less(training_flag, 2), lambda: loss, lambda: tf.cond(tf.less(training_flag, 4), lambda: loss_rgbd, lambda: loss_3d))\n\n    \n    #train_writer = tf.summary.FileWriter(options.log_dir + \'/train\')\n    #val_writer = tf.summary.FileWriter(options.log_dir + \'/val\')\n    #train_writer_rgbd = tf.summary.FileWriter(options.log_dir + \'/train_rgbd\')\n    #val_writer_rgbd = tf.summary.FileWriter(options.log_dir + \'/val_rgbd\')\n    #writers = [train_writer, val_writer, train_writer_rgbd, val_writer_rgbd]\n    \n\n    with tf.variable_scope(\'statistics\'):\n        batchno = tf.Variable(0, dtype=tf.int32, trainable=False, name=\'batchno\')\n        batchnoinc=batchno.assign(batchno+1)\n        pass\n\n\n    optimizer = tf.train.AdamOptimizer(options.LR)\n    train_op = optimizer.minimize(loss, global_step=batchno)\n\n    var_to_restore = [v for v in tf.global_variables()]\n\n    tf.summary.scalar(\'loss\', loss)\n    summary_op = tf.summary.merge_all()\n\n    \n    config=tf.ConfigProto()\n    config.allow_soft_placement=True    \n    #config.gpu_options.allow_growth=True\n    config.gpu_options.per_process_gpu_memory_fraction=0.9\n    saver=tf.train.Saver()\n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n    \n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n        if options.restore == 0:\n            #fine-tune from DeepLab model\n            var_to_restore = [v for v in var_to_restore if \'res5d\' not in v.name and \'segmentation\' not in v.name and \'plane\' not in v.name and \'deep_supervision\' not in v.name and \'local\' not in v.name and \'boundary\' not in v.name and \'degridding\' not in v.name and \'res2a_branch2a\' not in v.name and \'res2a_branch1\' not in v.name and \'Adam\' not in v.name and \'beta\' not in v.name and \'statistics\' not in v.name and \'semantics\' not in v.name]\n            pretrained_model_loader = tf.train.Saver(var_to_restore)\n            pretrained_model_loader.restore(sess,""../pretrained_models/deeplab_resnet.ckpt"")\n        elif options.restore == 1:\n            #restore the same model from checkpoint\n            loader = tf.train.Saver(var_to_restore)\n            loader.restore(sess,""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n            bno=sess.run(batchno)\n            print(bno)\n        elif options.restore == 2:            \n            #restore the same model from checkpoint but reset batchno to 1\n            loader = tf.train.Saver(var_to_restore)\n            loader.restore(sess,""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n            sess.run(batchno.assign(1))\n        elif options.restore == 3:            \n            #restore the same model from standard training\n            # if options.predictBoundary == 1:\n            #     var_to_restore = [v for v in var_to_restore if \'boundary\' not in v.name]\n            #     pass            \n            # if options.predictConfidence == 1:\n            #     var_to_restore = [v for v in var_to_restore if \'confidence\' not in v.name]\n            #     pass\n            if options.predictSemantics == 1:\n                var_to_restore = [v for v in var_to_restore if \'semantics\' not in v.name]\n                pass\n            \n            loader = tf.train.Saver(var_to_restore)\n            if len(options.hybrid) == 1:\n                hybrid = options.hybrid\n            else:\n                hybrid = str(3)\n                pass\n            #loader.restore(sess, options.rootFolder + \'/checkpoint/planenet_hybrid\' + hybrid + \'_bl0_ll1_bw0.5_pb_pp_ps_sm0/checkpoint.ckpt\')\n            loader.restore(sess, options.rootFolder + \'/checkpoint/planenet_hybrid\' + hybrid + \'_bl0_dl0_ll1_bw0.5_pb_pp/checkpoint.ckpt\')            \n            #loader.restore(sess,""checkpoint/planenet/checkpoint.ckpt"")\n            sess.run(batchno.assign(1))\n        elif options.restore == 4:\n            #fine-tune another model\n            #var_to_restore = [v for v in var_to_restore if \'res4b22_relu_non_plane\' not in v.name]\n            loader = tf.train.Saver(var_to_restore)\n            loader.restore(sess, options.fineTuningCheckpoint)\n            sess.run(batchno.assign(1))\n            pass\n        # Start input enqueue threads.\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n        MOVING_AVERAGE_DECAY = 0.99\n        ema = [0., 0., 0., 0.]\n        ema_acc = [1e-10, 1e-10, 1e-10, 1e-10]\n        last_snapshot_time = time.time()\n        bno=sess.run(batchno)\n\n        try:\n            while bno<300000:\n                t0 = time.time()\n\n                batchIndexPeriod = bno % 100\n                if batchIndexPeriod < len(options.hybrid):\n                    #batchType = int(options.hybrid[batchIndexPeriod]) * 2 + 1\n                    batchType = 1\n                    _, total_loss, losses, summary_str, gt_dict = sess.run([batchnoinc, loss, loss_dict, summary_op, global_pred_dict], feed_dict = {training_flag: batchType == 0})\n                    \n                else:\n                    batchType = 0\n                    _, total_loss, losses, summary_str, gt_dict = sess.run([train_op, loss, loss_dict, summary_op, global_pred_dict], feed_dict = {training_flag: batchType == 0})\n                    pass\n\n                # for batchIndex in xrange(options.batchSize):\n                #     if np.isnan(global_gt[\'plane\'][batchIndex]).any():\n                #         #print(losses)\n                #         #print(global_gt[\'plane\'][batchIndex])\n                #         print(global_gt[\'num_planes\'][batchIndex])\n                #         for planeIndex in xrange(global_gt[\'num_planes\'][batchIndex]):\n                #             cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(global_gt[\'segmentation\'][batchIndex, :, :, planeIndex]))\n                #             continue\n                #         np.save(\'temp/plane.npy\', global_gt[\'plane\'][batchIndex])                        \n                #         np.save(\'temp/depth.npy\', global_gt[\'depth\'][batchIndex])\n                #         np.save(\'temp/segmentation.npy\', global_gt[\'segmentation\'][batchIndex])\n                #         np.save(\'temp/info.npy\', global_gt[\'info\'][batchIndex])\n                #         np.save(\'temp/num_planes.npy\', global_gt[\'num_planes\'][batchIndex])\n                #         planes, segmentation, numPlanes = removeSmallSegments(global_gt[\'plane\'][batchIndex], np.zeros((HEIGHT, WIDTH, 3)), global_gt[\'depth\'][batchIndex].squeeze(), np.zeros((HEIGHT, WIDTH, 3)), np.argmax(global_gt[\'segmentation\'][batchIndex], axis=-1), global_gt[\'semantics\'][batchIndex], global_gt[\'info\'][batchIndex], global_gt[\'num_planes\'][batchIndex])\n                #         print(planes)\n                #         exit(1)\n                #         pass\n                #     continue\n                #writers[batchType].add_summary(summary_str, bno)\n                ema[batchType] = ema[batchType] * MOVING_AVERAGE_DECAY + total_loss\n                ema_acc[batchType] = ema_acc[batchType] * MOVING_AVERAGE_DECAY + 1\n\n                bno = sess.run(batchno)\n                if time.time()-last_snapshot_time > options.saveInterval:\n                    print(\'save snapshot\')\n                    saver.save(sess,\'%s/checkpoint.ckpt\'%options.checkpoint_dir)\n                    last_snapshot_time = time.time()\n                    pass\n        \n                print bno,\'train\', ema[0] / ema_acc[0], \'val\', ema[1] / ema_acc[1], \'train rgbd\', ema[2] / ema_acc[2], \'val rgbd\', ema[3] / ema_acc[3], \'loss\', total_loss, \'time\', time.time()-t0\n\n                if np.random.random() < 0.01:\n                    print(losses)\n                    pass                \n                continue\n\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n        \n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return\n\n\ndef test(options):\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n\n    if options.dataset == \'\':\n        assert(len(options.hybrid) == 1)\n        if options.hybrid == \'0\':\n            options.dataset = \'SUNCG\'\n        elif options.hybrid == \'1\':\n            options.dataset = \'NYU_RGBD\'\n        elif options.hybrid == \'2\':\n            options.dataset = \'matterport\'\n        elif options.hybrid == \'3\':\n            options.dataset = \'ScanNet\'\n            \n        options.dataset\n    options.batchSize = 1\n    min_after_dequeue = 1000\n\n    reader = RecordReaderAll()\n    if options.dataset == \'SUNCG\':\n        filename_queue = tf.train.string_input_producer([options.rootFolder + \'/planes_SUNCG_val.tfrecords\'], num_epochs=10000)\n    elif options.dataset == \'NYU_RGBD\':\n        filename_queue = tf.train.string_input_producer([options.rootFolder + \'/planes_nyu_rgbd_val.tfrecords\'], num_epochs=1)\n        options.deepSupervision = 0\n        options.predictLocal = 0\n    elif options.dataset == \'matterport\':\n        filename_queue = tf.train.string_input_producer([options.rootFolder + \'/planes_matterport_val.tfrecords\'], num_epochs=1)\n    else:\n        filename_queue = tf.train.string_input_producer([options.rootFolder + \'/planes_scannet_train.tfrecords\'], num_epochs=1)\n        pass\n    img_inp, global_gt_dict, local_gt_dict = reader.getBatch(filename_queue, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True, random=False)\n\n    training_flag = tf.constant(False, tf.bool)\n\n    global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp, img_inp, global_gt_dict, training_flag, options)\n    var_to_restore = tf.global_variables()\n\n    loss, loss_dict, debug_dict = build_loss(img_inp, img_inp, global_pred_dict, deep_pred_dicts, global_gt_dict, global_gt_dict, training_flag, options)\n    \n\n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n    \n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n        #var_to_restore = [v for v in var_to_restore if \'res4b22_relu_non_plane\' not in v.name]\n        loader = tf.train.Saver(var_to_restore)\n        loader.restore(sess, ""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n        #loader.restore(sess, ""%s/checkpoint.ckpt""%(\'checkpoint/planenet_pb_pp_hybrid1\'))\n        #loader.restore(sess, options.fineTuningCheckpoint)\n        \n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n        \n        \n        try:\n            gtDepths = []\n            predDepths = []\n            planeMasks = []\n            #predMasks = []\n            gtPlanes = []\n            predPlanes = []\n            gtSegmentations = []\n            predSegmentations = []\n            gtNumPlanes = []\n            \n            imageWidth = WIDTH\n            imageHeight = HEIGHT\n            focalLength = 517.97\n            urange = np.arange(imageWidth).reshape(1, -1).repeat(imageHeight, 0) - imageWidth * 0.5\n            vrange = np.arange(imageHeight).reshape(-1, 1).repeat(imageWidth, 1) - imageHeight * 0.5\n            ranges = np.array([urange / imageWidth * 640 / focalLength, np.ones(urange.shape), -vrange / imageHeight * 480 / focalLength]).transpose([1, 2, 0])\n\n\n            for index in xrange(10):\n                print((\'image\', index))\n                t0=time.time()\n\n                img, global_gt, local_gt, global_pred, local_pred, deep_preds, total_loss, losses, debug = sess.run([img_inp, global_gt_dict, local_gt_dict, global_pred_dict, local_pred_dict, deep_pred_dicts, loss, loss_dict, debug_dict])\n\n                # print(options.test_dir)\n                # cv2.imwrite(options.test_dir + \'/depth.png\', drawDepthImage(debug[\'depth\'][0]))\n                # cv2.imwrite(options.test_dir + \'/normal.png\', drawNormalImage(debug[\'normal\'][0]))\n                # boundary = debug[\'boundary\'][0]\n                # boundary = np.concatenate([boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)\n                # cv2.imwrite(options.test_dir + \'/boundary.png\', drawMaskImage(boundary))\n                # cv2.imwrite(options.test_dir + \'/depth_gt.png\', drawDepthImage(debug[\'depth_gt\'][0].squeeze()))\n                # exit(1)\n\n                if \'pixelwise\' in options.suffix or True:\n                    image = ((img[0] + 0.5) * 255).astype(np.uint8)\n                    gt_d = global_gt[\'depth\'].squeeze()\n                    pred_d = global_pred[\'non_plane_depth\'].squeeze()\n                    #depth = global_gt[\'depth\'].squeeze()\n                    if \'_2\' in options.suffix:\n                        pred_p, pred_s, pred_d = fitPlanes(pred_d, numPlanes=20, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=0.2)\n                    elif \'_3\' in options.suffix:\n                        pred_p, pred_s, pred_d = fitPlanes(gt_d, numPlanes=20, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=0.2)\n                        pass\n\n                    # gt_p = global_gt[\'plane\'][0]\n                    # pred_p = planes\n                    # valid_mask = (np.linalg.norm(gt_p, axis=1) > 0).astype(np.float32)\n                    # diff = np.min(np.linalg.norm(np.expand_dims(gt_p, 1) - np.expand_dims(pred_p, 0), axis=2), 1)\n                    # num += valid_mask.sum()\n                    # lossSum += (diff * valid_mask).sum()\n                    if options.dataset == \'SUNCG\':\n                        planeMask = np.squeeze(debug[\'segmentation\']).sum(axis=2)\n                    else:\n                        planeMask = np.ones((HEIGHT, WIDTH))\n                        if \'_2\' in options.suffix or \'_3\' in options.suffix:\n                            planeMask *= (pred_s < 20).astype(np.float32)\n                        pass\n                    \n                    if index < 10:\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', image)\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth.png\', drawDepthImage(gt_d))\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n                        if \'_2\' in options.suffix or \'_3\' in options.suffix:\n                            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(pred_s))\n                            pass\n                        #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_plane_mask.png\', drawMaskImage(planeMask))                \n                        pass\n\n                        \n                    gtDepths.append(gt_d)\n                    predDepths.append(pred_d)\n                    planeMasks.append(planeMask)\n\n\n                    if options.dataset != \'NYU_RGBD\' and (\'_2\' in options.suffix or \'_3\' in options.suffix):\n                        gt_p = global_gt[\'plane\'][0]\n                        gt_s = global_gt[\'segmentation\'][0]\n                        gt_num_p = global_gt[\'num_planes\'][0]\n\n                        pred_s = (np.expand_dims(pred_s, -1) == np.reshape(np.arange(options.numOutputPlanes), [1, 1, -1])).astype(np.float32)\n                        gtPlanes.append(gt_p)\n                        predPlanes.append(pred_p)\n                        gtSegmentations.append(gt_s)\n                        gtNumPlanes.append(gt_num_p)\n                        predSegmentations.append(pred_s)\n                        pass\n                    \n                    #planeMasks.append((planeSegmentation < 20).astype(np.float32))\n                    continue\n                \n                print(losses)\n                print(total_loss)\n                #print(losses)\n                #exit(1)\n                im = img[0]\n                image = ((im + 0.5) * 255).astype(np.uint8)                \n\n                gt_d = global_gt[\'depth\'].squeeze()\n                                \n\n                if options.predictLocal:\n                    pred_local_s = 1 / (1 + np.exp(-local_pred[\'score\'][0]))\n                    pred_local_p = local_pred[\'plane\'][0]\n                    pred_local_m = local_pred[\'mask\'][0]\n                  \n                    gt_local_s = local_gt[\'score\'][0]\n                    gt_local_m = local_gt[\'mask\'][0]\n\n                    #visualize local plane prediction\n                    stride = 8\n                    boxSize = 64\n                    xs = np.arange(WIDTH / stride) * stride + stride / 2\n                    ys = np.arange(HEIGHT / stride) * stride + stride / 2\n                    padding = boxSize / 2 + 1\n                    maskImage = np.zeros((HEIGHT + padding * 2, WIDTH + padding * 2, 3), dtype=np.uint8)\n                    maskImage[padding:padding + HEIGHT, padding:padding + WIDTH, :] = image / 2\n                    for gridY, y in enumerate(ys):\n                        for gridX, x in enumerate(xs):\n                            score = pred_local_s[gridY][gridX]\n                            if score < 0.5:\n                                continue                              \n                            mask = pred_local_m[gridY][gridX].reshape([16, 16])        \n                            mask = cv2.resize(mask, (boxSize, boxSize))\n                            maskImage[y - boxSize / 2 + padding:y + boxSize / 2 + padding, x - boxSize / 2 + padding:x + boxSize / 2 + padding, 0][mask > 0.5] = 255\n                            continue\n                        continue\n                    for gridY, y in enumerate(ys):\n                        for gridX, x in enumerate(xs):\n                            score = gt_local_s[gridY][gridX]\n                            if score < 0.5:\n                                continue                              \n                            mask = gt_local_m[gridY][gridX].reshape([16, 16])        \n                            mask = cv2.resize(mask, (boxSize, boxSize))\n                            maskImage[y - boxSize / 2 + padding:y + boxSize / 2 + padding, x - boxSize / 2 + padding:x + boxSize / 2 + padding, 2][mask > 0.5] = 255\n                            continue\n                        continue\n                    pass\n\n                pred_p = global_pred[\'plane\'][0]\n                pred_s = global_pred[\'segmentation\'][0]\n\n                pred_np_m = global_pred[\'non_plane_mask\'][0]\n                pred_np_d = global_pred[\'non_plane_depth\'][0]\n                pred_np_n = global_pred[\'non_plane_normal\'][0]\n                \n                planeMask = 1 - global_gt[\'non_plane_mask\'][0]\n                info = global_gt[\'info\'][0]\n\n                \n                all_segmentations = np.concatenate([pred_s, pred_np_m], axis=2)\n                all_segmentations_softmax = softmax(all_segmentations)\n                segmentation = np.argmax(all_segmentations, 2)\n                \n                \n                #pred_p, segmentation, numPlanes = mergePlanes(global_gt[\'plane\'][0], np.concatenate([global_gt[\'segmentation\'][0], global_gt[\'non_plane_mask\'][0]], axis=2), global_gt[\'depth\'][0].squeeze(), global_gt[\'info\'][0], np.concatenate([pred_s, pred_np_m], axis=2))\n                \n\n                plane_depths = calcPlaneDepths(pred_p, WIDTH, HEIGHT, info)\n                all_depths = np.concatenate([plane_depths, pred_np_d], axis=2)\n                \n                pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape(HEIGHT, WIDTH)\n\n                plane_normals = calcPlaneNormals(pred_p, WIDTH, HEIGHT)\n                all_normals = np.concatenate([plane_normals, np.expand_dims(pred_np_n, 2)], axis=2)\n                pred_n = np.sum(all_normals * np.expand_dims(one_hot(segmentation, options.numOutputPlanes+1), -1), 2)\n                #pred_n = all_normals.reshape(-1, options.numOutputPlanes + 1, 3)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape((HEIGHT, WIDTH, 3))\n                \n\n                if False:\n                    gt_s = global_gt[\'segmentation\'][0]\n                    all_segmentations = np.concatenate([gt_s, 1 - planeMask], axis=2)\n                    gt_p = global_gt[\'plane\'][0]\n\n                    # valid_mask = (np.linalg.norm(gt_p, axis=1) > 0).astype(np.float32)\n                    # diff = np.min(np.linalg.norm(np.expand_dims(gt_p, 1) - np.expand_dims(pred_p, 0), axis=2), 1)\n                    # num += valid_mask.sum()\n                    # lossSum += (diff * valid_mask).sum()\n                    #gt_p = np.stack([-gt_p[:, 0], -gt_p[:, 2], -gt_p[:, 1]], axis=1)\n                    \n                    plane_depths = calcPlaneDepths(gt_p, WIDTH, HEIGHT, info)\n                    all_depths = np.concatenate([plane_depths, pred_np_d], axis=2)\n\n                    segmentation = np.argmax(all_segmentations, 2)\n                    pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape(HEIGHT, WIDTH)\n                    # print(gt_p)\n                    # for segmentIndex in xrange(options.numOutputPlanes):\n                    #     cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_mask_\' + str(segmentIndex) + \'.png\', drawMaskImage(segmentation == segmentIndex))\n                    #     continue\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n                    #exit(1)\n                    pass\n\n                \n\n                gt_p = global_gt[\'plane\'][0]\n                gt_s = global_gt[\'segmentation\'][0]\n                gt_num_p = global_gt[\'num_planes\'][0]\n                gtPlanes.append(gt_p)\n                predPlanes.append(pred_p)\n                gtSegmentations.append(gt_s)\n                gtNumPlanes.append(gt_num_p)\n                predSegmentations.append(pred_s)\n                \n            \n                gtDepths.append(gt_d)\n                planeMasks.append(planeMask.squeeze())\n                predDepths.append(pred_d)\n                evaluateDepths(predDepths[-1], gtDepths[-1], gtDepths[-1] > 0, planeMasks[-1])\n                \n                \n                if index >= 10:\n                    continue\n\n                if options.predictSemantics:\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_semantics_pred.png\', drawSegmentationImage(global_pred[\'semantics\'][0], blackIndex=0))\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_semantics_gt.png\', drawSegmentationImage(global_gt[\'semantics\'][0], blackIndex=0))\n                    pass\n\n                if \'cost_mask\' in debug:\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_cost_mask.png\', drawMaskImage(np.sum(debug[\'cost_mask\'][0], axis=-1)))\n\n                    for planeIndex in xrange(options.numOutputPlanes + 1):\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_cost_mask_\' + str(planeIndex) + \'.png\', drawMaskImage(debug[\'cost_mask\'][0, :, :, planeIndex]))\n                        continue\n                    all_segmentations = np.concatenate([pred_s, pred_np_m], axis=2)\n                    for planeIndex in xrange(options.numOutputPlanes + 1):\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred_\' + str(planeIndex) + \'.png\', drawMaskImage(all_segmentations[:, :, planeIndex]))\n                        continue\n                    exit(1)\n                    pass\n                \n                if \'normal\' in global_gt:\n                    gt_n = global_gt[\'normal\'][0]\n                    norm = np.linalg.norm(gt_n, axis=-1, keepdims=True)\n                    gt_n /= np.maximum(norm, 1e-4)\n                    \n                    #gt_n = np.stack([-gt_n[:, :, 0], -gt_n[:, :, 2], -gt_n[:, :, 1]], axis=2)\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_gt.png\', drawNormalImage(gt_n))\n                    #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_pred.png\', drawNormalImage(pred_np_n))\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_pred.png\', drawNormalImage(pred_n))\n                    pass\n                \n                if \'segmentation\' in global_gt:\n                    gt_s = global_gt[\'segmentation\'][0]\n                    gt_p = global_gt[\'plane\'][0]\n\n                    \n                    #for planeIndex in xrange(20):\n                    #cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(gt_s[:, :, planeIndex]))\n                    #continue\n                    \n                    \n                    # print(gt_p)\n                    # print(gt_n[109][129])\n                    # print(gt_n[166][245])\n                    # print(gt_s[109][129])\n                    # print(gt_s[166][245])\n                    # print(plane_normals[109][129])\n                    # print(plane_normals[166][245])                    \n                    # for planeIndex in xrange(20):\n                    #     cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(gt_s[:, :, planeIndex]))\n                    #     continue\n                    # exit(1)\n                    \n                    gt_s, gt_p = sortSegmentations(gt_s, gt_p, pred_p)\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_plane_mask_gt.png\', drawMaskImage(planeMask))  \n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_gt.png\', drawSegmentationImage(np.concatenate([gt_s, 1 - planeMask], axis=2), blackIndex=options.numOutputPlanes)\n)\n                    #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_test.png\', drawMaskImage(np.sum(np.concatenate([gt_s, 1 - planeMask], axis=2), axis=2)))\n                    #exit(1)\n                    #exit(1)\n                    pass\n\n\n                if options.predictConfidence == 1 and options.dataset == \'SUNCG\':\n                    assert(False)\n                    pred_p_c = global_pred[\'confidence\'][0]\n                    pred_p_c = 1 / (1 + np.exp(-pred_p_c))\n                    #print(pred_p_c)\n                    # print(losses)\n                    # print(debug[\'plane\'][0])\n                    # print(pred_p)\n                    # exit(1)\n                    numPlanes = global_gt[\'num_planes\'][0]\n                    print((numPlanes, (pred_p_c > 0.5).sum()))\n                    \n                    pred_p_c = (pred_p_c > 0.5).astype(np.float32)\n                    pred_p *= pred_p_c\n                    pred_s -= (1 - pred_p_c.reshape([1, 1, options.numOutputPlanes])) * 10\n                    pass\n                  \n                if False:\n                    #dump results for post processing\n                    if index >= 10:\n                        break\n                    np.save(options.dump_dir + \'/planes_\' + str(index) + \'.npy\', pred_p)\n                    np.save(options.dump_dir + \'/segmentations_\' + str(index) + \'.npy\', pred_s)\n                    np.save(options.dump_dir + \'/segmentations_gt_\' + str(index) + \'.npy\', gt_s)\n                    np.save(options.dump_dir + \'/non_plane_depth_\' + str(index) + \'.npy\', pred_np_d)\n                    np.save(options.dump_dir + \'/non_plane_segmentation_\' + str(index) + \'.npy\', pred_np_m)\n                    boundary = pred_boundary[0]\n                    boundary = 1 / (1 + np.exp(-boundary))\n                    boundary = np.concatenate([boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)                    \n                    cv2.imwrite(options.dump_dir + \'/boundary_\' + str(index) + \'.png\', drawMaskImage(boundary))\n                    cv2.imwrite(options.dump_dir + \'/image_\' + str(index) + \'.png\', cv2.resize(image, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR))\n                    np.save(options.dump_dir + \'/depth_\' + str(index) + \'.npy\', gt_d)\n                    continue                \n\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', image)\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth.png\', drawDepthImage(gt_d))\n                #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_overlay.png\', drawDepthImageOverlay(image, gt_d))\n                \n                if options.predictBoundary:\n                    pred_boundary = global_pred[\'boundary\'][0]\n                    pred_boundary = 1 / (1 + np.exp(-pred_boundary))\n                    boundary = np.concatenate([pred_boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_boundary_pred.png\', drawMaskImage(boundary))\n                    pass\n\n                if \'boundary\' in global_gt:\n                    gt_boundary = global_gt[\'boundary\'][0]\n                    boundary = np.concatenate([gt_boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)                \n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_boundary_gt.png\', drawMaskImage(boundary))\n                    pass\n\n                for layerIndex, layer in enumerate(options.deepSupervisionLayers):\n                    segmentation_deep = np.argmax(deep_preds[layerIndex][\'segmentation\'][0], 2)\n                    segmentation_deep[segmentation_deep == options.numOutputPlanes] = -1\n                    segmentation_deep += 1\n                \n                    plane_depths_deep = calcPlaneDepths(deep_preds[layerIndex][\'plane\'][0], WIDTH, HEIGHT, info)\n                    all_depths_deep = np.concatenate([pred_np_d, plane_depths_deep], axis=2)\n                    pred_d_deep = all_depths_deep.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation_deep.reshape(-1)].reshape(HEIGHT, WIDTH)\n                \n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred_\' + str(layerIndex) + \'.png\', drawSegmentationImage(deep_preds[layerIndex][\'segmentation\'][0]))\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred_\' + str(layerIndex) + \'.png\', drawDepthImage(pred_d_deep))\n                    pass\n\n\n                #print(pred_np_m)\n                #print(pred_s)\n                #print(global_gt[\'plane\'][0])\n                #print(pred_p)\n                #exit(1)\n\n                print(\'depth diff\', np.abs(pred_d - gt_d).mean())\n                \n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(all_segmentations, blackIndex=options.numOutputPlanes))\n                #exit(1)\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_diff.png\', drawMaskImage(np.abs(pred_d - gt_d) * planeMask.squeeze() / 0.2))\n                #exit(1)\n                \n                \n                #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_plane_mask.png\', drawMaskImage(planeMask))           \n\n                #print(np.concatenate([np.arange(options.numOutputPlanes).reshape(-1, 1), planes, pred_p, preds_p[0][0]], axis=1))\n\n                #print(np.concatenate([distance[0], preds_p[0][0], pred_p], axis=1))\n                            \n                #segmentation = np.argmax(pred_s, 2)\n                #writePLYFile(options.test_dir, index, image, pred_d, segmentation, np.zeros(pred_boundary[0].shape))\n                #writePLYFileParts(options.test_dir, index, image, pred_d, segmentation)\n                #gt_s_ori = gt_s_ori[0]\n\n\n                # if \'depth\' in debug:\n                #     cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred_1.png\', drawDepthImage(debug[\'depth\'][0]))\n                #     gt_s_ori = debug[\'segmentation\'][0]\n                #     cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_gt.png\', drawSegmentationImage(gt_s_ori, blackIndex=options.numOutputPlanes))\n                #     total_loss = 0\n                #     for planeIndex in xrange(gt_s_ori.shape[-1]):\n                #         mask_pred = all_segmentations_softmax[:, :, planeIndex]\n                #         loss = -(gt_s_ori[:, :, planeIndex] * np.log(np.maximum(all_segmentations_softmax[:, :, planeIndex], 1e-31))).mean() * 1000\n                #         print(planeIndex, loss)\n                #         total_loss += loss\n                #         cv2.imwrite(options.test_dir + \'/mask_pred_\' + str(planeIndex) + \'.png\', drawMaskImage(mask_pred))\n                #         cv2.imwrite(options.test_dir + \'/mask_gt_\' + str(planeIndex) + \'.png\', drawMaskImage(gt_s_ori[:, :, planeIndex]))\n                #         continue\n                #     print(total_loss)\n                #     print(gt_s_ori.sum(2).max())                    \n                #     exit(1)\n                #     pass\n\n                \n                if False:\n                    #distance = distance[0]\n                    print(distance)\n                    diff = np.linalg.norm(np.expand_dims(planes, 1) - np.expand_dims(pred_p, 0), axis=2)\n                    print(np.concatenate([planes, pred_p, pow(np.min(diff, axis=1, keepdims=True), 2), np.expand_dims(np.argmin(diff, axis=1), -1)], axis=1))\n                    print(pred_p_c)\n                    \n                    #print(distance[:, 6:8].sum(0))\n                    #print(pow(np.linalg.norm(distance[:, :3] - distance[:, 3:6], 2, 1), 2) * 100)\n                    #print(test)\n                    segmentation = np.argmax(all_segmentations, 2) - 1\n                    for planeIndex in xrange(options.numOutputPlanes):\n                        cv2.imwrite(options.test_dir + \'/segmentation_\' + str(planeIndex) + \'.png\', drawMaskImage(segmentation == planeIndex))\n                        cv2.imwrite(options.test_dir + \'/segmentation_\' + str(planeIndex) + \'_gt.png\', drawMaskImage(gt_s[:, :, planeIndex]))\n                        cv2.imwrite(options.test_dir + \'/segmentation_\' + str(planeIndex) + \'_gt_ori.png\', drawMaskImage(gt_s_ori[:, :, planeIndex]))\n                        continue\n                    exit(1)\n                continue\n\n            # if options.dataset == \'SUNCG\':\n            #     if \'pixelwise\' not in options.suffix:\n            #         evaluatePlaneSegmentation(np.array(predPlanes), np.array(predSegmentations), np.array(gtPlanes), np.array(gtSegmentations), np.array(gtNumPlanes), planeDistanceThreshold = 0.3, IOUThreshold = 0.5, prefix=\'test/planenet_\')\n            #     elif \'_2\' in options.suffix:\n            #         evaluatePlaneSegmentation(np.array(predPlanes), np.array(predSegmentations), np.array(gtPlanes), np.array(gtSegmentations), np.array(gtNumPlanes), planeDistanceThreshold = 0.3, IOUThreshold = 0.5, prefix=\'test/pixelwise_pred_\')\n            #     elif \'_3\' in options.suffix:\n            #         evaluatePlaneSegmentation(np.array(predPlanes), np.array(predSegmentations), np.array(gtPlanes), np.array(gtSegmentations), np.array(gtNumPlanes), planeDistanceThreshold = 0.3, IOUThreshold = 0.5, prefix=\'test/pixelwise_gt_\')\n            #         pass\n            #     pass\n            \n            predDepths = np.array(predDepths)\n            gtDepths = np.array(gtDepths)\n            planeMasks = np.array(planeMasks)\n            #predMasks = np.array(predMasks)\n            evaluateDepths(predDepths, gtDepths, gtDepths > 0, planeMasks)\n            exit(1)\n\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n        \n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return\n\n\n# def predict(options):\n#     options.test_dir += \'_predict\'\n#     if not os.path.exists(options.test_dir):\n#         os.system(""mkdir -p %s""%options.test_dir)\n#         pass\n\n#     batchSize = 1\n#     img_inp = tf.placeholder(tf.float32,shape=(batchSize,HEIGHT,WIDTH,3),name=\'img_inp\')\n#     plane_gt=tf.placeholder(tf.float32,shape=(batchSize,options.numOutputPlanes, 3),name=\'plane_inp\')\n#     validating_inp = tf.constant(0, tf.int32)\n\n#     global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp_train, img_inp_val, img_inp_rgbd_train, img_inp_rgbd_val, training_flag, options)\n\n#     var_to_restore = tf.global_variables()\n    \n \n#     config=tf.ConfigProto()\n#     config.gpu_options.allow_growth=True\n#     config.allow_soft_placement=True\n\n\n#     if dataset == \'SUNCG\':\n#         image_list_file = os.path.join(\'../PythonScripts/SUNCG/image_list_100_tail_500000.txt\')\n#         with open(image_list_file) as f:\n#             im_names = [{\'image\': im_name.strip().replace(\'plane_global.npy\', \'mlt.png\'), \'depth\': im_name.strip().replace(\'plane_global.npy\', \'depth.png\'), \'normal\': im_name.strip().replace(\'plane_global.npy\', \'norm_camera.png\'), \'valid\': im_name.strip().replace(\'plane_global.npy\', \'valid.png\'), \'plane\': im_name.strip()} for im_name in f.readlines()]\n#             pass\n#     else:\n#         im_names = glob.glob(\'../../Data/NYU_RGBD/*_color.png\')\n#         im_names = [{\'image\': im_name, \'depth\': im_name.replace(\'color.png\', \'depth.png\'), \'normal\': im_name.replace(\'color.png\', \'norm_camera.png\'), \'invalid_mask\': im_name.replace(\'color.png\', \'valid.png\')} for im_name in im_names]\n#         pass\n      \n#     if numImages > 0:\n#         im_names = im_names[:numImages]\n#         pass\n\n#     #if args.imageIndex > 0:\n#     #im_names = im_names[args.imageIndex:args.imageIndex + 1]\n#     #pass    \n\n#     init_op = tf.group(tf.global_variables_initializer(),\n#                        tf.local_variables_initializer())\n\n\n#     with tf.Session(config=config) as sess:\n#         saver = tf.train.Saver()\n#         #sess.run(tf.global_variables_initializer())\n#         saver.restore(sess,""%s/%s.ckpt""%(options.checkpoint_dir,keyname))\n\n#         gtDepths = []\n#         predDepths = []\n#         segmentationDepths = []\n#         predDepthsOneHot = []\n#         planeMasks = []\n#         predMasks = []\n\n#         imageWidth = WIDTH\n#         imageHeight = HEIGHT\n#         focalLength = 517.97\n#         urange = np.arange(imageWidth).reshape(1, -1).repeat(imageHeight, 0) - imageWidth * 0.5\n#         vrange = np.arange(imageHeight).reshape(-1, 1).repeat(imageWidth, 1) - imageHeight * 0.5\n#         ranges = np.array([urange / focalLength, np.ones(urange.shape), -vrange / focalLength]).transpose([1, 2, 0])\n        \n#         cv2.imwrite(options.test_dir + \'/one.png\', np.ones((HEIGHT, WIDTH), dtype=np.uint8) * 255)\n#         cv2.imwrite(options.test_dir + \'/zero.png\', np.zeros((HEIGHT, WIDTH), dtype=np.uint8) * 255)\n#         for index, im_name in enumerate(im_names):\n#             if index <= -1:\n#                 continue\n#             print(im_name[\'image\'])\n#             im = cv2.imread(im_name[\'image\'])\n#             image = im.astype(np.float32, copy=False)\n#             image = image / 255 - 0.5\n#             image = cv2.resize(image, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n\n#             #planes = np.load(im_name[\'plane\'])\n#             # numPlanes = planes.shape[0]\n#             # if numPlanes > options.numOutputPlanes:\n#             #     planeAreas = planes[:, 3:].sum(1)\n#             #     sortInds = np.argsort(planeAreas)[::-1]\n#             #     planes = planes[sortInds[:options.numOutputPlanes]]\n#             #     pass\n#             # gt_p = np.zeros((1, options.numOutputPlanes, 3))\n#             # gt_p[0, :numPlanes] = planes[:numPlanes, :3]\n\n#             normal = np.array(PIL.Image.open(im_name[\'normal\'])).astype(np.float) / 255 * 2 - 1\n#             norm = np.linalg.norm(normal, 2, 2)\n#             for c in xrange(3):\n#                 normal[:, :, c] /= norm\n#                 continue\n#             normal = cv2.resize(normal, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n            \n#             depth = np.array(PIL.Image.open(im_name[\'depth\'])).astype(np.float) / 1000\n#             depth = cv2.resize(depth, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n\n#             invalid_mask = cv2.resize(cv2.imread(im_name[\'invalid_mask\'], 0), (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR) > 128\n\n#             gtDepths.append(depth)\n\n            \n#             pred_p, pred_d, pred_n, pred_s, pred_np_m, pred_np_d, pred_np_n, pred_boundary, pred_local_score, pred_local_p, pred_local_mask = sess.run([plane_pred, depth_pred, normal_pred, segmentation_pred, non_plane_mask_pred, non_plane_depth_pred, non_plane_normal_pred, boundary_pred, local_score_pred, local_p_pred, local_mask_pred], feed_dict = {img_inp:np.expand_dims(image, 0), plane_gt: np.zeros((batchSize, options.numOutputPlanes, 3))})\n\n\n#             pred_s = pred_s[0] \n#             pred_p = pred_p[0]\n#             pred_np_m = pred_np_m[0]\n#             pred_np_d = pred_np_d[0]\n#             pred_np_n = pred_np_n[0]\n#             #pred_s = 1 / (1 + np.exp(-pred_s))\n\n#             plane_depths = calcPlaneDepths(pred_p, WIDTH, HEIGHT)\n#             all_depths = np.concatenate([pred_np_d, plane_depths], axis=2)\n\n#             all_segmentations = np.concatenate([pred_np_m, pred_s], axis=2)\n#             segmentation = np.argmax(all_segmentations, 2)\n#             if suffix != \'pixelwise\':\n#                 pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape(HEIGHT, WIDTH)\n#             else:\n#                 pred_d = np.squeeze(pred_np_d)\n#                 pass\n#             predDepths.append(pred_d)\n#             predMasks.append(segmentation != 0)\n#             planeMasks.append(invalid_mask)\n\n#             #depthError, normalError, occupancy, segmentationTest, reconstructedDepth, occupancyMask = evaluatePlanes(pred_p, im_name[\'image\'])\n#             #reconstructedDepth = cv2.resize(reconstructedDepth, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n            \n#             #evaluatePlanes(pred_p[0], im_name, options.test_dir, index)\n#             #print(pred_p)\n#             #print(gt_p)\n#             #print((pow(pred_d[0, :, :, 0] - depth, 2) * (gt_s.max(2) > 0.5)).mean())\n#             #print((depthError, normalError, occupancy))\n            \n#             evaluateDepths(predDepths[index], gtDepths[index], np.ones(planeMasks[index].shape), planeMasks[index])\n\n#             if index >= 10:\n#                 continue\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', cv2.resize(im, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR))\n#             #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_gt.png\', (minDepth / np.clip(depth, minDepth, 20) * 255).astype(np.uint8))\n#             #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', (minDepth / np.clip(pred_d[0, :, :, 0], minDepth, 20) * 255).astype(np.uint8))\n#             #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_plane.png\', (minDepth / np.clip(reconstructedDepth, minDepth, 20) * 255).astype(np.uint8))\n\n#             pred_boundary = pred_boundary[0]\n#             boundary = (1 / (1 + np.exp(-pred_boundary)) * 255).astype(np.uint8)\n#             boundary = np.concatenate([boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_boundary_pred.png\', boundary)\n            \n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_inp.png\', drawDepthImage(depth))\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n#             #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_plane.png\', drawDepthImage(reconstructedDepth))\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred_diff.png\', drawDiffImage(pred_d, depth, 0.5))\n#             #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_plane_diff.png\', np.minimum(np.abs(reconstructedDepth - depth) / 0.5 * 255, 255).astype(np.uint8))\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_inp.png\', drawNormalImage(normal))\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_pred.png\', drawNormalImage(pred_np_n))\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(all_segmentations, black=True))\n\n#             segmentation = np.argmax(pred_s, 2)\n#             #writePLYFile(options.test_dir, index, image, pred_p, segmentation)\n\n#             if index < 0:\n#                 for planeIndex in xrange(options.numOutputPlanes):\n#                     cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_\' + str(planeIndex) + \'.png\', drawMaskImage(pred_s[:, :, planeIndex]))\n#                     #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_\' + str(planeIndex) + \'_gt.png\', drawMaskImage(gt_s[:, :, planeIndex]))\n#                     continue\n#                 pass\n#             continue\n#         predDepths = np.array(predDepths)\n#         gtDepths = np.array(gtDepths)\n#         planeMasks = np.array(planeMasks)\n#         predMasks = np.array(predMasks)\n#         #evaluateDepths(predDepths, gtDepths, planeMasks, predMasks)\n#         evaluateDepths(predDepths, gtDepths, planeMasks, planeMasks)\n#         #exit(1)\n#         pass\n#     return\n\n\n# def fitPlanesRGBD(options):\n#     writeHTMLRGBD(\'../results/RANSAC_RGBD/index.html\', 10)\n#     exit(1)\n#     if not os.path.exists(options.checkpoint_dir):\n#         os.system(""mkdir -p %s""%options.checkpoint_dir)\n#         pass\n#     if not os.path.exists(options.test_dir):\n#         os.system(""mkdir -p %s""%options.test_dir)\n#         pass\n    \n#     min_after_dequeue = 1000\n\n#     reader_rgbd = RecordReaderRGBD()\n#     filename_queue_rgbd = tf.train.string_input_producer([\'../planes_nyu_rgbd_train.tfrecords\'], num_epochs=1)\n#     img_inp_rgbd, global_gt_dict_rgbd, local_gt_dict_rgbd = reader_rgbd.getBatch(filename_queue_rgbd, numOutputPlanes=options.numOutputPlanes, batchSize=1, min_after_dequeue=min_after_dequeue, getLocal=True)\n\n#     config=tf.ConfigProto()\n#     config.gpu_options.allow_growth=True\n#     config.allow_soft_placement=True\n\n#     init_op = tf.group(tf.global_variables_initializer(),\n#                        tf.local_variables_initializer())\n\n#     with tf.Session(config=config) as sess:\n#         sess.run(init_op)\n\n#         coord = tf.train.Coordinator()\n#         threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n#         try:\n#             gtDepths = []\n#             predDepths = []\n#             planeMasks = []\n#             for index in xrange(10):\n#                 image, depth, path = sess.run([img_inp_rgbd, global_gt_dict_rgbd[\'depth\'], global_gt_dict_rgbd[\'path\']])\n#                 image = ((image[0] + 0.5) * 255).astype(np.uint8)\n#                 depth = depth.squeeze()\n                \n#                 cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', image)\n#                 cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth.png\', drawDepthImage(depth))\n#                 #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_mask.png\', drawMaskImage(depth == 0))\n#                 planes, planeSegmentation, depthPred = fitPlanes(depth, numPlanes=20)                \n#                 cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(planeSegmentation))\n#                 cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(depthPred))\n\n#                 gtDepths.append(depth)\n#                 predDepths.append(depthPred)\n#                 planeMasks.append((planeSegmentation < 20).astype(np.float32))\n#                 continue\n#             predDepths = np.array(predDepths)\n#             gtDepths = np.array(gtDepths)\n#             planeMasks = np.array(planeMasks)\n#             evaluateDepths(predDepths, gtDepths, np.ones(planeMasks.shape, dtype=np.bool), planeMasks)            \n#         except tf.errors.OutOfRangeError:\n#             print(\'done fitting\')\n#         finally:\n#             # When done, ask the threads to stop.\n#             coord.request_stop()\n#             pass\n#     return\n\ndef writeInfo(options):\n    x = (np.arange(11) * 0.1).tolist()\n    ys = []\n    ys.append(np.load(\'test/planenet_pixel_IOU.npy\').tolist())\n    ys.append(np.load(\'test/pixelwise_pred_pixel_IOU.npy\').tolist())\n    ys.append(np.load(\'test/pixelwise_gt_pixel_IOU.npy\').tolist())\n    plotCurves(x, ys, filename = \'test/plane_comparison.png\', xlabel=\'IOU\', ylabel=\'pixel coverage\', labels=[\'planenet\', \'pixelwise+RANSAC\', \'GT+RANSAC\'])\n\n    x = (0.5 - np.arange(11) * 0.05).tolist()\n    ys = []\n    ys.append(np.load(\'test/planenet_pixel_diff.npy\').tolist())\n    ys.append(np.load(\'test/pixelwise_pred_pixel_diff.npy\').tolist())\n    ys.append(np.load(\'test/pixelwise_gt_pixel_diff.npy\').tolist())\n    plotCurves(x, ys, filename = \'test/plane_comparison_diff.png\', xlabel=\'diff\', ylabel=\'pixel coverage\', labels=[\'planenet\', \'pixelwise+RANSAC\', \'GT+RANSAC\'])\n    \n    return\n\ndef parse_args():\n    """"""\n    Parse input arguments\n    """"""\n    parser = argparse.ArgumentParser(description=\'Planenet\')\n    parser.add_argument(\'--gpu\', dest=\'gpu_id\',\n                        help=\'GPU device id to use [0]\',\n                        default=0, type=int)\n    #task: [train, test, predict]\n    parser.add_argument(\'--task\', dest=\'task\',\n                        help=\'task type: [train, test, predict]\',\n                        default=\'train\', type=str)\n    parser.add_argument(\'--restore\', dest=\'restore\',\n                        help=\'how to restore the model\',\n                        default=0, type=int)\n    parser.add_argument(\'--numOutputPlanes\', dest=\'numOutputPlanes\',\n                        help=\'the number of output planes\',\n                        default=20, type=int)\n    parser.add_argument(\'--batchSize\', dest=\'batchSize\',\n                        help=\'batch size\',\n                        default=16, type=int)\n    parser.add_argument(\'--dataset\', dest=\'dataset\',\n                        help=\'dataset name for test/predict\',\n                        default=\'\', type=str)\n    parser.add_argument(\'--numImages\', dest=\'numImages\',\n                        help=\'the number of images to test/predict\',\n                        default=10, type=int)\n    parser.add_argument(\'--boundaryLoss\', dest=\'boundaryLoss\',\n                        help=\'use boundary loss: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--diverseLoss\', dest=\'diverseLoss\',\n                        help=\'use diverse loss: [0, 1]\',\n                        default=1, type=int)\n    parser.add_argument(\'--labelLoss\', dest=\'labelLoss\',\n                        help=\'use label loss: [0, 1]\',\n                        default=1, type=int)    \n    parser.add_argument(\'--deepSupervision\', dest=\'deepSupervision\',\n                        help=\'deep supervision level: [0, 1, 2]\',\n                        default=1, type=int)\n    parser.add_argument(\'--sameMatching\', dest=\'sameMatching\',\n                        help=\'use the same matching for all deep supervision layers and the final prediction: [0, 1]\',\n                        default=0, type=int)    \n    parser.add_argument(\'--anchorPlanes\', dest=\'anchorPlanes\',\n                        help=\'use anchor planes for all deep supervision layers and the final prediction: [0, 1]\',\n                        default=0, type=int) \n    parser.add_argument(\'--crf\', dest=\'crf\',\n                        help=\'the number of CRF iterations\',\n                        default=0, type=int)\n    parser.add_argument(\'--backwardLossWeight\', dest=\'backwardLossWeight\',\n                        help=\'backward matching loss\',\n                        default=0.5, type=float)\n    parser.add_argument(\'--predictBoundary\', dest=\'predictBoundary\',\n                        help=\'whether predict boundary or not: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--predictSemantics\', dest=\'predictSemantics\',\n                        help=\'whether predict semantics or not: [0, 1]\',\n                        default=1, type=int)    \n    parser.add_argument(\'--predictLocal\', dest=\'predictLocal\',\n                        help=\'whether predict local planes or not: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--predictConfidence\', dest=\'predictConfidence\',\n                        help=\'whether predict plane confidence or not: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--predictPlanes\', dest=\'predictPlanes\',\n                        help=\'whether predict planes or not: [0, 1]\',\n                        default=0, type=int)    \n    parser.add_argument(\'--fineTuningCheckpoint\', dest=\'fineTuningCheckpoint\',\n                        help=\'specify the model for fine-tuning\',\n                        default=\'../PlaneSetGeneration/dump_planenet_diverse/train_planenet_diverse.ckpt\', type=str)\n    parser.add_argument(\'--suffix\', dest=\'suffix\',\n                        help=\'add a suffix to keyname to distinguish experiments\',\n                        default=\'\', type=str)\n    parser.add_argument(\'--l2Weight\', dest=\'l2Weight\',\n                        help=\'L2 regulation weight\',\n                        default=5e-4, type=float)\n    parser.add_argument(\'--LR\', dest=\'LR\',\n                        help=\'learning rate\',\n                        default=3e-5, type=float)\n    parser.add_argument(\'--hybrid\', dest=\'hybrid\',\n                        help=\'hybrid training\',\n                        default=\'3\', type=str)\n    parser.add_argument(\'--rootFolder\', dest=\'rootFolder\',\n                        help=\'root folder\',\n                        default=\'/mnt/vision/PlaneNet/\', type=str)\n    parser.add_argument(\'--dataFolder\', dest=\'dataFolder\',\n                        help=\'data folder\',\n                        default=\'/home/chenliu/Projects/PlaneNet/\', type=str)\n    parser.add_argument(\'--saveInterval\', dest=\'saveInterval\',\n                        help=\'save interval\',\n                        default=900, type=int)\n    \n\n    args = parser.parse_args()\n    args.keyname = os.path.basename(__file__).rstrip(\'.py\')\n    args.keyname = args.keyname.replace(\'train_\', \'\')\n\n    if args.numOutputPlanes != 20:\n        args.keyname += \'_np\' + str(args.numOutputPlanes)\n        pass\n    args.keyname += \'_hybrid\' + args.hybrid\n    \n    if args.deepSupervision != 1:\n        args.keyname += \'_ds\' + str(args.deepSupervision)\n        pass\n    if args.predictPlanes == 1:\n        args.keyname += \'_pp\'\n        pass\n    if args.predictSemantics == 1:\n        args.keyname += \'_ps\'\n        pass    \n\n    #args.predictSemantics = 0\n    #args.predictBoundary = 0\n    \n    args.checkpoint_dir = args.rootFolder + \'/checkpoint/\' + args.keyname\n    args.log_dir = \'log/\' + args.keyname\n    args.test_dir = \'test/\' + args.keyname + \'_\' + args.dataset\n    args.predict_dir = \'predict/\' + args.keyname + \'_\' + args.dataset\n    args.dump_dir = \'dump/\' + args.keyname\n    \n    #layers where deep supervision happens\n    args.deepSupervisionLayers = []\n    if args.deepSupervision >= 1:\n        args.deepSupervisionLayers.append(\'res4b22_relu\')\n        pass\n    if args.deepSupervision >= 2:\n        args.deepSupervisionLayers.append(\'res4b12_relu\')\n        pass\n    return args\n\n\nif __name__==\'__main__\':\n\n    # plane = np.load(\'temp/plane.npy\')\n    # depth = np.load(\'temp/depth.npy\')    \n    # segmentation = np.load(\'temp/segmentation.npy\')\n    # info = np.load(\'temp/info.npy\')\n    # num_planes = np.load(\'temp/num_planes.npy\')\n    # segmentation = np.argmax(segmentation, axis=-1)\n    # print(segmentation.shape)\n    # planes, segmentation, numPlanes = removeSmallSegments(plane, np.zeros((HEIGHT, WIDTH, 3)), depth.squeeze(), np.zeros((HEIGHT, WIDTH, 3)), segmentation, np.zeros((HEIGHT, WIDTH)), info, num_planes)\n    # print(planes)\n    # exit(1)\n    \n    args = parse_args()\n\n    print ""keyname=%s task=%s started""%(args.keyname, args.task)\n    try:\n        if args.task == ""train"":\n            main(args)\n        elif args.task == ""test"":\n            test(args)\n        elif args.task == ""predict"":\n            predict(args)\n        elif args.task == ""fit"":\n            fitPlanesRGBD(args)\n        elif args.task == ""write"":\n            writeInfo(args)\n        else:\n            assert False,""format wrong""\n            pass\n    finally:\n        pass\n\n'"
train_planenet.py,180,"b'import tensorflow as tf\nimport numpy as np\nnp.set_printoptions(precision=2, linewidth=200)\nimport cv2\nimport os\nimport time\nimport sys\nimport argparse\nimport glob\nimport PIL\nimport scipy.ndimage as ndimage\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom utils import *\nfrom modules import *\n\n\nfrom planenet import PlaneNet\nfrom RecordReaderAll import *\nfrom crfasrnn.crfasrnn_layer import CrfRnnLayer\n\n#from SegmentationRefinement import *\n\n#training_flag: toggle dropout and batch normalization mode\n#it\'s true for training and false for validation, testing, prediction\n#it also controls which data batch to use (*_train or *_val)\n\n\ndef build_graph(img_inp_train, img_inp_val, training_flag, options):\n    with tf.device(\'/gpu:%d\'%options.gpu_id):\n        img_inp = tf.cond(training_flag, lambda: img_inp_train, lambda: img_inp_val)\n\n        net = PlaneNet({\'img_inp\': img_inp}, is_training=training_flag, options=options)\n\n        #global predictions\n        plane_pred = net.layers[\'plane_pred\']\n\n        segmentation_pred = net.layers[\'segmentation_pred\']\n        non_plane_mask_pred = net.layers[\'non_plane_mask_pred\']\n        non_plane_depth_pred = net.layers[\'non_plane_depth_pred\']\n        non_plane_normal_pred = net.layers[\'non_plane_normal_pred\']\n        non_plane_normal_pred = tf.nn.l2_normalize(non_plane_normal_pred, dim=-1)\n\n\n        if False:\n            plane_pred = gt_dict[\'plane\']\n            non_plane_mask_pred = gt_dict[\'non_plane_mask\'] * 10\n            non_plane_depth_pred = gt_dict[\'depth\']\n            non_plane_normal_pred = gt_dict[\'normal\']\n            segmentation_pred = gt_dict[\'segmentation\'][:, :, :, :options.numOutputPlanes] * 10\n            pass\n\n\n        if abs(options.crfrnn) > 0:\n            with tf.variable_scope(\'crfrnn\'):\n                all_segmentations = crfrnnModule([tf.concat([segmentation_pred, non_plane_mask_pred], axis=3), img_inp * 255], image_dims=(HEIGHT, WIDTH), num_classes=options.numOutputPlanes + 1, theta_alpha=30, theta_beta=10, theta_gamma=1, num_iterations=abs(options.crfrnn))\n                #all_segmentations = CrfRnnLayer(image_dims=(HEIGHT, WIDTH), num_classes=options.numOutputPlanes + 1, theta_alpha=80., theta_beta=3., theta_gamma=3., num_iterations=abs(options.crfrnn), name=\'crfrnn\')([tf.concat([segmentation_pred, non_plane_mask_pred], axis=3), img_inp * 255])\n                segmentation_pred = all_segmentations[:, :, :, :options.numOutputPlanes]\n                non_plane_mask_pred = all_segmentations[:, :, :, options.numOutputPlanes:]\n                pass\n            pass\n\n        global_pred_dict = {\'plane\': plane_pred, \'segmentation\': segmentation_pred, \'non_plane_mask\': non_plane_mask_pred, \'non_plane_depth\': non_plane_depth_pred, \'non_plane_normal\': non_plane_normal_pred}\n\n        if options.predictBoundary:\n            global_pred_dict[\'boundary\'] = net.layers[\'boundary_pred\']\n        else:\n            global_pred_dict[\'boundary\'] = tf.zeros((options.batchSize, HEIGHT, WIDTH, 2))\n            pass\n        if options.predictConfidence:\n            global_pred_dict[\'confidence\'] = net.layers[\'plane_confidence_pred\']\n            pass\n        if options.predictSemantics:\n            global_pred_dict[\'semantics\'] = net.layers[\'semantics_pred\']\n            pass\n\n        #local predictions\n        if options.predictLocal:\n            local_pred_dict = {\'score\': net.layers[\'local_score_pred\'], \'plane\': net.layers[\'local_plane_pred\'], \'mask\': net.layers[\'local_mask_pred\']}\n        else:\n            local_pred_dict = {}\n            pass\n\n\n        #deep supervision\n        deep_pred_dicts = []\n        for layer in options.deepSupervisionLayers:\n            pred_dict = {\'plane\': net.layers[layer+\'_plane_pred\'], \'segmentation\': net.layers[layer+\'_segmentation_pred\'], \'non_plane_mask\': net.layers[layer+\'_non_plane_mask_pred\']}\n            #if options.predictConfidence:\n            #pred_dict[\'confidence\'] = net.layers[layer+\'_plane_confidence_pred\']\n            #pass\n            deep_pred_dicts.append(pred_dict)\n            continue\n\n\n        if options.anchorPlanes:\n            anchors_np = np.load(\'dump/anchors_\' + options.hybrid + \'.npy\')\n            anchors = tf.reshape(tf.constant(anchors_np.reshape(-1)), anchors_np.shape)\n            anchors = tf.tile(tf.expand_dims(anchors, 0), [options.batchSize, 1, 1])\n            all_pred_dicts = deep_pred_dicts + [global_pred_dict]\n            for pred_index, pred_dict in enumerate(all_pred_dicts):\n                all_pred_dicts[pred_index][\'plane\'] += anchors\n                continue\n            pass\n\n        pass\n\n    return global_pred_dict, local_pred_dict, deep_pred_dicts\n\n\ndef build_loss(img_inp_train, img_inp_val, global_pred_dict, deep_pred_dicts, global_gt_dict_train, global_gt_dict_val, training_flag, options):\n    from nndistance import tf_nndistance\n\n    with tf.device(\'/gpu:%d\'%options.gpu_id):\n        debug_dict = {}\n\n        img_inp = tf.cond(training_flag, lambda: img_inp_train, lambda: img_inp_val)\n        global_gt_dict = {}\n        for name in global_gt_dict_train.keys():\n            global_gt_dict[name] = tf.cond(training_flag, lambda: global_gt_dict_train[name], lambda: global_gt_dict_val[name])\n            continue\n        # local_gt_dict = {}\n        # for name in local_gt_dict_train.keys():\n        #     local_gt_dict[name] = tf.cond(tf.equal(training_flag % 2, 0), lambda: local_gt_dict_train[name], lambda: local_gt_dict_val[name])\n        #     continue\n\n        plane_parameters = tf.reshape(global_pred_dict[\'plane\'], (-1, 3))\n        info = global_gt_dict[\'info\'][0]\n        plane_depths = planeDepthsModule(plane_parameters, WIDTH, HEIGHT, info)\n        plane_depths = tf.transpose(tf.reshape(plane_depths, [HEIGHT, WIDTH, -1, options.numOutputPlanes]), [2, 0, 1, 3])\n\n        non_plane_depth = global_pred_dict[\'non_plane_depth\']\n        all_depths = tf.concat([plane_depths, non_plane_depth], axis=3)\n\n\n        validPlaneMask = tf.cast(tf.less(tf.tile(tf.expand_dims(tf.range(options.numOutputPlanes), 0), [options.batchSize, 1]), tf.expand_dims(global_gt_dict[\'num_planes\'], -1)), tf.float32)\n        backwardLossWeight = options.backwardLossWeight\n\n        #plane loss and segmentation loss (summation over deep supervisions and final supervision)\n        all_pred_dicts = deep_pred_dicts + [global_pred_dict]\n        plane_loss = tf.constant(0.0)\n        segmentation_loss = tf.constant(0.0)\n        plane_confidence_loss = tf.constant(0.0)\n        diverse_loss = tf.constant(0.0)\n\n        #keep forward map (segmentation gt) from previous supervision so that we can have same matching for all supervisions (options.sameMatching = 1)\n        previous_plane_gt = None\n        previous_plane_confidence_gt = None\n        previous_segmentation_gt = None\n        if options.anchorPlanes:\n            anchors_np = np.load(\'dump/anchors_\' + options.hybrid + \'.npy\')\n            anchors = tf.reshape(tf.constant(anchors_np.reshape(-1)), anchors_np.shape)\n            anchors = tf.tile(tf.expand_dims(anchors, 0), [options.batchSize, 1, 1])\n            dists_forward, map_forward, dists_backward, _ = tf_nndistance.nn_distance(global_gt_dict[\'plane\'], anchors)\n\n            forward_map = tf.one_hot(map_forward, depth=options.numOutputPlanes, axis=-1)\n            forward_map *= tf.expand_dims(validPlaneMask, -1)\n\n            #number of ground truth mapped for each prediction\n            num_matches = tf.transpose(tf.reduce_sum(forward_map, axis=1, keep_dims=True), [0, 2, 1])\n            previous_plane_gt = tf.transpose(tf.matmul(global_gt_dict[\'plane\'], forward_map, transpose_a=True), [0, 2, 1]) / tf.maximum(num_matches, 1e-4)\n            previous_plane_confidence_gt = tf.cast(num_matches > 0.5, tf.float32)\n\n            segmentation_gt_shuffled = tf.reshape(tf.matmul(tf.reshape(global_gt_dict[\'segmentation\'], [-1, HEIGHT * WIDTH, options.numOutputPlanes]), forward_map), [-1, HEIGHT, WIDTH, options.numOutputPlanes])\n            segmentation_gt_shuffled = tf.concat([segmentation_gt_shuffled, global_gt_dict[\'non_plane_mask\']], axis=3)\n            previous_segmentation_gt = segmentation_gt_shuffled\n            pass\n\n        for pred_index, pred_dict in enumerate(all_pred_dicts):\n            if (options.sameMatching and pred_index > 0) or options.anchorPlanes:\n                #use matching from previous supervision and map ground truth planes based on the mapping\n\n                plane_loss += tf.reduce_mean(tf.squared_difference(pred_dict[\'plane\'], previous_plane_gt) * previous_plane_confidence_gt) * 10000\n\n                #all segmentations is the concatenation of plane segmentations and non plane mask\n                all_segmentations = tf.concat([pred_dict[\'segmentation\'], pred_dict[\'non_plane_mask\']], axis=3)\n\n                if options.crf > 0:\n                    all_segmentations_softmax = tf.nn.softmax(all_segmentations)\n                    with tf.variable_scope(\'crf\'):\n                        planesY = global_pred_dict[\'plane\'][:, :, 1]\n                        planesD = tf.maximum(tf.norm(global_pred_dict[\'plane\'], axis=-1), 1e-4)\n                        planesY /= planesD\n                        planesY = tf.concat([planesY, tf.ones((options.batchSize, 1)) * 100], axis=1)\n\n                        imageDiff = calcImageDiff(img_inp)\n                        all_segmentations_softmax, _ = segmentationRefinementModule(all_segmentations_softmax, all_depths, planesY, imageDiff, numIterations=options.crf, numOutputPlanes=21)\n                        segmentation_loss += tf.reduce_mean(-tf.reduce_sum(previous_segmentation_gt* tf.log(tf.maximum(all_segmentations_softmax, 1e-31)), axis=-1)) * 1000\n                        pass\n                    pass\n                else:\n                    segmentation_loss += tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=all_segmentations, labels=previous_segmentation_gt)) * 1000\n                    pass\n            else:\n                #calculate new matching by finding nearest neighbors again\n                dists_forward, map_forward, dists_backward, _ = tf_nndistance.nn_distance(global_gt_dict[\'plane\'], pred_dict[\'plane\'])\n                dists_forward *= validPlaneMask\n\n                dists_forward = tf.reduce_mean(dists_forward)\n                dists_backward = tf.reduce_mean(dists_backward)\n                plane_loss += (dists_forward + dists_backward * backwardLossWeight) * 10000\n\n                forward_map = tf.one_hot(map_forward, depth=options.numOutputPlanes, axis=-1)\n                forward_map *= tf.expand_dims(validPlaneMask, -1)\n\n                #number of ground truth mapped for each prediction\n                num_matches = tf.transpose(tf.reduce_sum(forward_map, axis=1, keep_dims=True), [0, 2, 1])\n                previous_plane_gt = tf.transpose(tf.matmul(global_gt_dict[\'plane\'], forward_map, transpose_a=True), [0, 2, 1]) / tf.maximum(num_matches, 1e-4)\n                previous_plane_confidence_gt = tf.cast(num_matches > 0.5, tf.float32)\n\n\n                segmentation_gt_shuffled = tf.reshape(tf.matmul(tf.reshape(global_gt_dict[\'segmentation\'], [-1, HEIGHT * WIDTH, options.numOutputPlanes]), forward_map), [-1, HEIGHT, WIDTH, options.numOutputPlanes])\n                segmentation_gt_shuffled = tf.concat([segmentation_gt_shuffled, global_gt_dict[\'non_plane_mask\']], axis=3)\n                previous_segmentation_gt = segmentation_gt_shuffled\n\n                all_segmentations = tf.concat([pred_dict[\'segmentation\'], pred_dict[\'non_plane_mask\']], axis=3)\n                segmentation_loss += tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=all_segmentations, labels=segmentation_gt_shuffled)) * 1000\n                debug_dict[\'segmentation\'] = segmentation_gt_shuffled\n                pass\n\n            if options.diverseLoss:\n                plane_diff = tf.reduce_sum(tf.pow(tf.expand_dims(pred_dict[\'plane\'], 1) - tf.expand_dims(pred_dict[\'plane\'], 2), 2), axis=3)\n                plane_diff = tf.matrix_set_diag(plane_diff, tf.ones((options.batchSize, options.numOutputPlanes)))\n                minPlaneDiff = 0.5\n                diverse_loss += tf.reduce_mean(tf.clip_by_value(1 - plane_diff / minPlaneDiff, 0, 1)) * 10000\n                pass\n\n            continue\n\n\n        if options.crf == 0:\n            all_segmentations_softmax = tf.nn.softmax(all_segmentations)\n            pass\n\n        #depth loss\n        validDepthMask = tf.cast(tf.greater(global_gt_dict[\'depth\'], 1e-4), tf.float32)\n\n        depth_loss = tf.constant(0.0)\n        if options.depthLoss == 1:\n            depth_loss += tf.reduce_mean(tf.reduce_sum(tf.squared_difference(all_depths, global_gt_dict[\'depth\']) * all_segmentations_softmax, axis=3, keep_dims=True) * validDepthMask) * 20000\n        elif options.depthLoss == 2:\n            depthDiff = tf.abs(all_depths - global_gt_dict[\'depth\'])\n            c = 0.3\n            absMask = tf.cast(tf.less(depthDiff, c), tf.float32)\n            depthDiff = depthDiff * absMask + (tf.pow(depthDiff, 2) + tf.pow(c, 2)) / (2 * c) * (1 - absMask)\n            depth_loss += tf.reduce_mean(tf.reduce_sum(depthDiff * all_segmentations_softmax, axis=3, keep_dims=True) * validDepthMask) * 10000\n        elif options.depthLoss == 3:\n            depth_softmax = tf.reduce_sum(all_depths * all_segmentations_softmax, axis=3, keep_dims=True)\n            depthDiff = tf.abs(depth_softmax - global_gt_dict[\'depth\'])\n            c = 0.3\n            absMask = tf.cast(tf.less(depthDiff, c), tf.float32)\n            depthDiff = depthDiff * absMask + (tf.pow(depthDiff, 2) + tf.pow(c, 2)) / (2 * c) * (1 - absMask)\n            depth_loss += tf.reduce_mean(depthDiff * validDepthMask) * 10000\n        elif options.depthLoss == 4:\n            S = tf.one_hot(tf.argmax(all_segmentations, 3), depth=options.numOutputPlanes + 1)\n            depth_one_hot = tf.reduce_sum(all_depths * S, axis=3, keep_dims=True)\n            depthDiff = tf.abs(depth_one_hot - global_gt_dict[\'depth\'])\n            c = 0.3\n            absMask = tf.cast(tf.less(depthDiff, c), tf.float32)\n            depthDiff = depthDiff * absMask + (tf.pow(depthDiff, 2) + tf.pow(c, 2)) / (2 * c) * (1 - absMask)\n            depth_loss += tf.reduce_mean(depthDiff * validDepthMask) * 10000\n            pass\n\n        if options.predictPixelwise == 1:\n            depth_diff = global_pred_dict[\'non_plane_depth\'] - global_gt_dict[\'depth\']\n            depth_diff_gx = depth_diff - tf.concat([tf.ones([options.batchSize, HEIGHT, 1, 1]), depth_diff[:, :, :WIDTH - 1]], axis=2)\n            depth_diff_gy = depth_diff - tf.concat([tf.ones([options.batchSize, 1, WIDTH, 1]), depth_diff[:, :HEIGHT - 1]], axis=1)\n\n            numValidPixels = tf.reduce_sum(validDepthMask, axis=[1, 2, 3])\n            depth_loss += tf.reduce_mean(tf.reduce_sum(tf.pow(depth_diff * validDepthMask, 2), axis=[1, 2, 3]) / numValidPixels - 0.5 * tf.pow(tf.reduce_sum(depth_diff * validDepthMask, axis=[1, 2, 3]) / numValidPixels, 2) + tf.reduce_sum((tf.pow(depth_diff_gx, 2) + tf.pow(depth_diff_gy, 2)) * validDepthMask, axis=[1, 2, 3]) / numValidPixels) * 1000\n\n            #depth_loss += tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_depth\'], global_gt_dict[\'depth\']) * validDepthMask) * 10000\n\n\n            valid_normal_mask = tf.squeeze(tf.cast(tf.less(tf.slice(global_gt_dict[\'info\'], [0, 19], [options.batchSize, 1]), 2), tf.float32))\n            normal_gt = tf.nn.l2_normalize(global_gt_dict[\'normal\'], dim=-1)\n            normal_loss = tf.reduce_mean(tf.reduce_sum(-global_pred_dict[\'non_plane_normal\'] * normal_gt * validDepthMask, axis=[1, 2, 3]) / numValidPixels * valid_normal_mask) * 1000\n            #normal_loss = tf.reduce_mean(tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_normal\'], global_gt_dict[\'normal\']) * validDepthMask, axis=[1, 2, 3]) * valid_normal_mask) * 1000\n        else:\n            normal_loss = tf.constant(0.0)\n            pass\n\n        if options.predictSemantics:\n            valid_semantics_mask = tf.squeeze(tf.cast(tf.not_equal(tf.slice(global_gt_dict[\'info\'], [0, 19], [options.batchSize, 1]), 1), tf.float32))\n            semantics_loss = tf.reduce_mean(tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=global_pred_dict[\'semantics\'], labels=global_gt_dict[\'semantics\']), axis=[1, 2]) * valid_semantics_mask) * 1000\n        else:\n            semantics_loss = tf.constant(0.0)\n            pass\n\n        local_score_loss = tf.constant(0.0)\n        local_plane_loss = tf.constant(0.0)\n        local_mask_loss = tf.constant(0.0)\n\n        #boundary loss\n        boundary_loss = tf.constant(0.0)\n\n        if False:\n            kernel_size = 3\n            padding = (kernel_size - 1) / 2\n            neighbor_kernel_array = gaussian(kernel_size, kernel_size)\n            neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n            neighbor_kernel_array /= neighbor_kernel_array.sum()\n            neighbor_kernel_array *= -1\n            neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 1\n            neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n            neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n\n            #calculate boundary ground truth on-the-fly as the calculation is subject to change\n\n            depth_diff = tf.abs(tf.nn.depthwise_conv2d(global_gt_dict[\'depth\'], neighbor_kernel, strides=[1, 1, 1, 1], padding=\'VALID\'))\n            depth_diff = tf.pad(depth_diff, paddings = [[0, 0], [padding, padding], [padding, padding], [0, 0]])\n            max_depth_diff = 0.1\n            depth_boundary = tf.greater(depth_diff, max_depth_diff)\n\n            plane_region = tf.nn.max_pool(1 - global_gt_dict[\'non_plane_mask\'], ksize=[1, kernel_size, kernel_size, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n            segmentation_eroded = 1 - tf.nn.max_pool(1 - global_gt_dict[\'segmentation\'], ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n            plane_region -= tf.reduce_max(segmentation_eroded, axis=3, keep_dims=True)\n            boundary = tf.cast(depth_boundary, tf.float32) * plane_region\n            smooth_boundary = global_gt_dict[\'smooth_boundary\']\n            boundary_gt = tf.concat([smooth_boundary, tf.maximum(boundary - smooth_boundary, 0)], axis=3)\n            pass\n\n\n        if options.boundaryLoss == 1 and False:\n\n            all_segmentations_pred = all_segmentations_softmax\n            all_segmentations_min = 1 - tf.nn.max_pool(1 - all_segmentations_pred, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\')\n            segmentation_diff = tf.reduce_max(all_segmentations_pred - all_segmentations_min, axis=3, keep_dims=True)\n\n            depth_pred = tf.reduce_sum(tf.multiply(all_depths, all_segmentations_pred), axis=3, keep_dims=True)\n            depth_neighbor = tf.nn.depthwise_conv2d(depth_pred, neighbor_kernel, strides=[1, 1, 1, 1], padding=\'SAME\')\n            minDepthDiff = 0.02\n            depth_diff = tf.clip_by_value(tf.squared_difference(depth_pred, depth_neighbor) - pow(minDepthDiff, 2), 0, 1)\n\n            boundary = tf.reduce_max(global_gt_dict[\'boundary\'], axis=3, keep_dims=True)\n            smooth_boundary = tf.slice(boundary_gt, [0, 0, 0, 0], [options.batchSize, HEIGHT, WIDTH, 1])\n            smooth_mask = segmentation_diff + boundary - 2 * segmentation_diff * boundary + depth_diff * smooth_boundary\n            margin = 0.0\n            smooth_mask = tf.nn.relu(smooth_mask - margin)\n            #boundary_loss += tf.reduce_mean(smooth_mask * plane_mask) * 1000\n            boundary_loss += tf.reduce_mean(smooth_mask) * 1000\n        elif options.boundaryLoss == 3:\n            S = tf.one_hot(tf.argmax(all_segmentations, 3), depth=options.numOutputPlanes + 1)\n            #sigmaDepthDiff = 0.5\n            #DS_diff = tf.exp(-tf.pow(1 - tf.clip_by_value(tf.abs(all_depths - tf.reduce_sum(all_depths * S, 3, keep_dims=True)), 0, 1), 2) / sigmaDepthDiff) - tf.exp(-1 / sigmaDepthDiff) * S\n            planesY = tf.slice(global_pred_dict[\'plane\'], [0, 0, 1], [options.batchSize, options.numOutputPlanes, 1])\n            planesD = tf.maximum(tf.norm(global_pred_dict[\'plane\'], axis=-1, keep_dims=True), 1e-4)\n            planesY /= planesD\n            #normalY = tf.reduce_sum(tf.slice(S, [0, 0, 0, 0], [options.batchSize, HEIGHT, WIDTH, options.numOutputPlanes]) * tf.reshape(planesY, [options.batchSize, 1, 1, options.numOutputPlanes]), axis=3, keep_dims=True)\n            planesY = tf.concat([planesY, tf.ones((options.batchSize, 1, 1)) * 100], axis=1)\n            normalY = tf.reduce_sum(S * tf.reshape(planesY, [options.batchSize, 1, 1, -1]), axis=3, keep_dims=True)\n\n            maxDepthDiff = 0.1\n            labelDiffWeight = 0.05\n            depth_one_hot = tf.reduce_sum(all_depths * S, 3, keep_dims=True)\n            depth_diff = tf.clip_by_value(tf.pow((plane_depths - depth_one_hot) * normalY / maxDepthDiff, 2), 0, 1)\n            #depth_diff *= normalY\n            depth_diff = tf.concat([depth_diff, 1 - tf.slice(S, [0, 0, 0, options.numOutputPlanes], [options.batchSize, HEIGHT, WIDTH, 1])], axis=3)\n            DS_diff = (1 + labelDiffWeight) - tf.exp(-depth_diff) - S * labelDiffWeight\n            kernel_size = 3\n            neighbor_kernel_array = gaussian(kernel_size)\n            neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n            neighbor_kernel_array /= neighbor_kernel_array.sum()\n            neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n            neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n\n            DS = tf.nn.depthwise_conv2d(DS_diff, tf.tile(neighbor_kernel, [1, 1, options.numOutputPlanes + 1, 1]), strides=[1, 1, 1, 1], padding=\'SAME\')\n            boundary_loss += tf.reduce_mean(DS * all_segmentations_softmax) * 100000\n\n            debug_dict[\'cost_mask\'] = tf.reduce_sum(DS * all_segmentations_softmax, axis=3)\n            #debug_dict[\'cost_mask\'] = DS * all_segmentations_softmax\n            #debug_dict[\'cost_mask\'] = tf.reduce_sum(DS * S, axis=3)\n        elif options.boundaryLoss == 2:\n            planesY = global_pred_dict[\'plane\'][:, :, 1]\n            planesD = tf.maximum(tf.norm(global_pred_dict[\'plane\'], axis=-1), 1e-4)\n            planesY /= planesD\n            planesY = tf.concat([planesY, tf.ones((options.batchSize, 1)) * 100], axis=1)\n\n            #imageDiff = calcImageDiff(img_inp)\n            #all_segmentations_softmax, _ = segmentationRefinementModule(all_segmentations_softmax, all_depths, planesY, imageDiff, numIterations=options.crf, numOutputPlanes=21)\n            messages = calcMessages(all_segmentations_softmax, all_depths, planesY, numOutputPlanes=21)\n            boundary_loss += tf.reduce_mean(messages * all_segmentations_softmax) * 100000\n            debug_dict[\'cost_mask\'] = messages\n            pass\n\n\n        if options.predictBoundary and False:\n            #we predict boundaries directly for post-processing purpose\n            boundary_loss += tf.reduce_mean(tf.losses.sigmoid_cross_entropy(logits=global_pred_dict[\'boundary\'], multi_class_labels=global_gt_dict[\'boundary\'], weights=tf.maximum(global_gt_dict[\'boundary\'] * 3, 1))) * 1000\n            pass\n\n\n        label_loss = tf.constant(0.0)\n        if options.labelLoss == 1:\n            #label_loss = tf.reduce_mean(tf.reduce_max(all_segmentations_softmax, axis=[1, 2]) * tf.concat([tf.cast(tf.equal(tf.squeeze(num_matches, axis=2), 0), tf.float32), tf.ones([options.batchSize, 1])], axis=1)) * 1000\n            #label_loss = tf.reduce_mean(tf.log(1 + tf.reduce_sum(all_segmentations_softmax, axis=[1, 2]))) * 100\n            segmentations_gt = tf.concat([global_gt_dict[\'segmentation\'], global_gt_dict[\'non_plane_mask\']], axis=3)\n            label_loss = tf.reduce_mean(tf.maximum(tf.reduce_sum(tf.sqrt(tf.reduce_sum(all_segmentations_softmax, axis=[1, 2])), axis=1) - tf.reduce_sum(tf.sqrt(tf.reduce_sum(segmentations_gt, axis=[1, 2])), axis=1), 0)) * 5\n            #label_loss = tf.reduce_mean(tf.reduce_max(all_segmentations_softmax, axis=[1, 2])) * 1000\n            pass\n\n        #regularization\n        l2_losses = tf.add_n([options.l2Weight * tf.nn.l2_loss(v) for v in tf.trainable_variables() if \'weights\' in v.name])\n\n        if options.planeLoss == 0:\n            plane_loss = tf.constant(0.0)\n            pass\n\n        loss = plane_loss + segmentation_loss + depth_loss + normal_loss + plane_confidence_loss + diverse_loss + boundary_loss + local_score_loss + local_plane_loss + local_mask_loss + label_loss + semantics_loss + l2_losses\n\n        #if options.pixelwiseLoss:\n        #normal_loss = tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_normal\'], global_gt_dict[\'normal\'])) * 1000\n        #depth_loss = tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_depth\'], global_gt_dict[\'depth\']) * validDepthMask) * 1000\n        #pass\n\n        S = tf.one_hot(tf.argmax(all_segmentations, 3), depth=options.numOutputPlanes + 1)\n        depth_one_hot = tf.reduce_sum(all_depths * S, 3, keep_dims=True)\n        debug_dict[\'depth\'] = depth_one_hot\n\n        loss_dict = {\'plane\': plane_loss, \'segmentation\': segmentation_loss, \'depth\': depth_loss, \'normal\': normal_loss, \'boundary\': boundary_loss, \'diverse\': diverse_loss, \'confidence\': plane_confidence_loss, \'local_score\': local_score_loss, \'local_plane\': local_plane_loss, \'local_mask\': local_mask_loss, \'label\': label_loss, \'semantics\': semantics_loss}\n        pass\n    return loss, loss_dict, debug_dict\n\n\ndef main(options):\n    if not os.path.exists(options.checkpoint_dir):\n        os.system(""mkdir -p %s""%options.checkpoint_dir)\n        pass\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n\n    min_after_dequeue = 1000\n\n\n    train_inputs = []\n    val_inputs = []\n    if \'0\' in options.hybrid:\n        train_inputs.append(options.dataFolder + \'/planes_SUNCG_train.tfrecords\')\n        val_inputs.append(options.dataFolder + \'/planes_SUNCG_val.tfrecords\')\n        pass\n    if \'1\' in options.hybrid:\n        for _ in xrange(10):\n            train_inputs.append(options.dataFolder + \'/planes_nyu_rgbd_train.tfrecords\')\n            train_inputs.append(options.dataFolder + \'/planes_nyu_rgbd_labeled_train.tfrecords\')\n            val_inputs.append(options.dataFolder + \'/planes_nyu_rgbd_val.tfrecords\')\n            continue\n        pass\n    if \'2\' in options.hybrid:\n        train_inputs.append(options.dataFolder + \'/planes_matterport_train.tfrecords\')\n        val_inputs.append(options.dataFolder + \'/planes_matterport_val.tfrecords\')\n        pass\n    if \'3\' in options.hybrid:\n        train_inputs.append(options.dataFolder + \'/planes_scannet_train.tfrecords\')\n        val_inputs.append(options.dataFolder + \'/planes_scannet_val.tfrecords\')\n        pass\n\n    reader_train = RecordReaderAll()\n    filename_queue_train = tf.train.string_input_producer(train_inputs, num_epochs=10000)\n    img_inp_train, global_gt_dict_train, local_gt_dict_train = reader_train.getBatch(filename_queue_train, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True)\n\n    reader_val = RecordReaderAll()\n    filename_queue_val = tf.train.string_input_producer(val_inputs, num_epochs=10000)\n    img_inp_val, global_gt_dict_val, local_gt_dict_val = reader_val.getBatch(filename_queue_val, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True)\n\n    training_flag = tf.placeholder(tf.bool, shape=[], name=\'training_flag\')\n\n    #global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp_train, img_inp_val, img_inp_rgbd_train, img_inp_rgbd_val, img_inp_3d_train, img_inp_3d_val, training_flag, options)\n    global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp_train, img_inp_val, training_flag, options)\n\n\n    #loss, loss_dict, _ = build_loss(global_pred_dict, local_pred_dict, deep_pred_dicts, global_gt_dict_train, local_gt_dict_train, global_gt_dict_val, local_gt_dict_val, training_flag, options)\n    #loss_rgbd, loss_dict_rgbd, _ = build_loss_rgbd(global_pred_dict, deep_pred_dicts, global_gt_dict_rgbd_train, global_gt_dict_rgbd_val, training_flag, options)\n    loss, loss_dict, debug_dict = build_loss(img_inp_train, img_inp_val, global_pred_dict, deep_pred_dicts, global_gt_dict_train, global_gt_dict_val, training_flag, options)\n\n    #loss = tf.cond(tf.less(training_flag, 2), lambda: loss, lambda: tf.cond(tf.less(training_flag, 4), lambda: loss_rgbd, lambda: loss_3d))\n\n\n    #train_writer = tf.summary.FileWriter(options.log_dir + \'/train\')\n    #val_writer = tf.summary.FileWriter(options.log_dir + \'/val\')\n    #train_writer_rgbd = tf.summary.FileWriter(options.log_dir + \'/train_rgbd\')\n    #val_writer_rgbd = tf.summary.FileWriter(options.log_dir + \'/val_rgbd\')\n    #writers = [train_writer, val_writer, train_writer_rgbd, val_writer_rgbd]\n\n\n    with tf.variable_scope(\'statistics\'):\n        batchno = tf.Variable(0, dtype=tf.int32, trainable=False, name=\'batchno\')\n        batchnoinc=batchno.assign(batchno+1)\n        pass\n\n\n    optimizer = tf.train.AdamOptimizer(options.LR)\n    if options.crfrnn >= 0:\n        train_op = optimizer.minimize(loss, global_step=batchno)\n    else:\n        var_to_train = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, ""crfrnn"")\n        print(var_to_train)\n        train_op = optimizer.minimize(loss, global_step=batchno, var_list=var_to_train)\n        pass\n\n    var_to_restore = [v for v in tf.global_variables()]\n\n    tf.summary.scalar(\'loss\', loss)\n    summary_op = tf.summary.merge_all()\n\n\n    config=tf.ConfigProto()\n    config.allow_soft_placement=True\n    #config.gpu_options.allow_growth=True\n    config.gpu_options.per_process_gpu_memory_fraction=0.9\n    saver=tf.train.Saver()\n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n        if options.restore == 0:\n            #fine-tune from DeepLab model\n            var_to_restore = [v for v in var_to_restore if \'res5d\' not in v.name and \'segmentation\' not in v.name and \'plane\' not in v.name and \'deep_supervision\' not in v.name and \'local\' not in v.name and \'boundary\' not in v.name and \'degridding\' not in v.name and \'res2a_branch2a\' not in v.name and \'res2a_branch1\' not in v.name and \'Adam\' not in v.name and \'beta\' not in v.name and \'statistics\' not in v.name and \'semantics\' not in v.name and \'crfrnn\' not in v.name]\n            pretrained_model_loader = tf.train.Saver(var_to_restore)\n            pretrained_model_loader.restore(sess, options.modelPathDeepLab)\n        elif options.restore == 1:\n            #restore the same model from checkpoint\n            loader = tf.train.Saver(var_to_restore)\n            loader.restore(sess,""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n            bno=sess.run(batchno)\n            print(bno)\n            pass\n        # Start input enqueue threads.\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n        MOVING_AVERAGE_DECAY = 0.99\n        ema = [0., 0., 0., 0.]\n        ema_acc = [1e-10, 1e-10, 1e-10, 1e-10]\n        last_snapshot_time = time.time()\n        bno=sess.run(batchno)\n\n        try:\n            while bno<300000:\n                t0 = time.time()\n\n                batchIndexPeriod = bno % 100\n                if batchIndexPeriod < len(options.hybrid):\n                    #batchType = int(options.hybrid[batchIndexPeriod]) * 2 + 1\n                    batchType = 1\n                    _, total_loss, losses, summary_str, pred = sess.run([batchnoinc, loss, loss_dict, summary_op, global_pred_dict], feed_dict = {training_flag: batchType == 0})\n                else:\n                    batchType = 0\n                    _, total_loss, losses, summary_str, pred, debug, img, gt = sess.run([train_op, loss, loss_dict, summary_op, global_pred_dict, debug_dict, img_inp_train, global_gt_dict_train], feed_dict = {training_flag: batchType == 0})\n\n                    if bno % (100 + 400 * int(options.crfrnn == 0)) == 50:\n                        for batchIndex in xrange(options.batchSize):\n                            #print(losses)\n                            #print(debug[\'plane\'][batchIndex])\n                            cv2.imwrite(\'test/\' + str(batchIndex) + \'_image.png\', ((img[batchIndex] + 0.5) * 255).astype(np.uint8))\n                            cv2.imwrite(\'test/\' + str(batchIndex) + \'_segmentation_pred.png\', drawSegmentationImage(np.concatenate([pred[\'segmentation\'][batchIndex], pred[\'non_plane_mask\'][batchIndex]], axis=2), blackIndex=options.numOutputPlanes))\n                            cv2.imwrite(\'test/\' + str(batchIndex) + \'_segmentation_gt.png\', drawSegmentationImage(np.concatenate([gt[\'segmentation\'][batchIndex], gt[\'non_plane_mask\'][batchIndex]], axis=2), blackIndex=options.numOutputPlanes))\n                            cv2.imwrite(\'test/\' + str(batchIndex) + \'_depth.png\', drawDepthImage(debug[\'depth\'][batchIndex].squeeze()))\n                            continue\n                        #exit(1)\n                        pass\n                    pass\n\n\n                ema[batchType] = ema[batchType] * MOVING_AVERAGE_DECAY + total_loss\n                ema_acc[batchType] = ema_acc[batchType] * MOVING_AVERAGE_DECAY + 1\n\n                bno = sess.run(batchno)\n                if time.time()-last_snapshot_time > options.saveInterval:\n                    print(\'save snapshot\')\n                    saver.save(sess,\'%s/checkpoint.ckpt\'%options.checkpoint_dir)\n                    last_snapshot_time = time.time()\n                    pass\n\n                print bno,\'train\', ema[0] / ema_acc[0], \'val\', ema[1] / ema_acc[1], \'train rgbd\', ema[2] / ema_acc[2], \'val rgbd\', ema[3] / ema_acc[3], \'loss\', total_loss, \'time\', time.time()-t0\n\n                if np.random.random() < 0.01:\n                    print(losses)\n                    pass\n                continue\n\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n\n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return\n\n\ndef test(options):\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n\n    if options.dataset == \'\':\n        assert(len(options.hybrid) == 1)\n        if options.hybrid == \'0\':\n            options.dataset = \'SUNCG\'\n        elif options.hybrid == \'1\':\n            options.dataset = \'NYU_RGBD\'\n        elif options.hybrid == \'2\':\n            options.dataset = \'matterport\'\n        elif options.hybrid == \'3\':\n            options.dataset = \'ScanNet\'\n\n        options.dataset\n    options.batchSize = 1\n    min_after_dequeue = 1000\n\n    reader = RecordReaderAll()\n    if options.dataset == \'SUNCG\':\n        filename_queue = tf.train.string_input_producer([options.dataFolder + \'/planes_SUNCG_val.tfrecords\'], num_epochs=10000)\n    elif options.dataset == \'NYU_RGBD\':\n        filename_queue = tf.train.string_input_producer([options.dataFolder + \'/planes_nyu_rgbd_val.tfrecords\'], num_epochs=1)\n        options.deepSupervision = 0\n        options.predictLocal = 0\n    elif options.dataset == \'matterport\':\n        filename_queue = tf.train.string_input_producer([options.dataFolder + \'/planes_matterport_val.tfrecords\'], num_epochs=1)\n    else:\n        filename_queue = tf.train.string_input_producer([options.dataFolder + \'/planes_scannet_val.tfrecords\'], num_epochs=1)\n        pass\n    img_inp, global_gt_dict, local_gt_dict = reader.getBatch(filename_queue, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True, random=False)\n\n    training_flag = tf.constant(False, tf.bool)\n\n    global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp, img_inp, training_flag, options)\n    var_to_restore = tf.global_variables()\n\n    loss, loss_dict, debug_dict = build_loss(img_inp, img_inp, global_pred_dict, deep_pred_dicts, global_gt_dict, global_gt_dict, training_flag, options)\n\n\n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n        #var_to_restore = [v for v in var_to_restore if \'res4b22_relu_non_plane\' not in v.name]\n        loader = tf.train.Saver(var_to_restore)\n        loader.restore(sess, ""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n        #loader.restore(sess, ""%s/checkpoint.ckpt""%(\'checkpoint/planenet_pb_pp_hybrid1\'))\n        #loader.restore(sess, options.fineTuningCheckpoint)\n\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n\n        try:\n            gtDepths = []\n            predDepths = []\n            planeMasks = []\n            #predMasks = []\n            gtPlanes = []\n            predPlanes = []\n            gtSegmentations = []\n            predSegmentations = []\n            gtNumPlanes = []\n\n            imageWidth = WIDTH\n            imageHeight = HEIGHT\n            focalLength = 517.97\n            urange = np.arange(imageWidth).reshape(1, -1).repeat(imageHeight, 0) - imageWidth * 0.5\n            vrange = np.arange(imageHeight).reshape(-1, 1).repeat(imageWidth, 1) - imageHeight * 0.5\n            ranges = np.array([urange / imageWidth * 640 / focalLength, np.ones(urange.shape), -vrange / imageHeight * 480 / focalLength]).transpose([1, 2, 0])\n\n\n            for index in xrange(10):\n                print((\'image\', index))\n                t0=time.time()\n\n                img, global_gt, local_gt, global_pred, local_pred, deep_preds, total_loss, losses, debug = sess.run([img_inp, global_gt_dict, local_gt_dict, global_pred_dict, local_pred_dict, deep_pred_dicts, loss, loss_dict, debug_dict])\n\n                # print(options.test_dir)\n                # cv2.imwrite(options.test_dir + \'/depth.png\', drawDepthImage(debug[\'depth\'][0]))\n                # cv2.imwrite(options.test_dir + \'/normal.png\', drawNormalImage(debug[\'normal\'][0]))\n                # boundary = debug[\'boundary\'][0]\n                # boundary = np.concatenate([boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)\n                # cv2.imwrite(options.test_dir + \'/boundary.png\', drawMaskImage(boundary))\n                # cv2.imwrite(options.test_dir + \'/depth_gt.png\', drawDepthImage(debug[\'depth_gt\'][0].squeeze()))\n                # exit(1)\n\n                if \'pixelwise\' in options.suffix:\n                    image = ((img[0] + 0.5) * 255).astype(np.uint8)\n                    gt_d = global_gt[\'depth\'].squeeze()\n                    pred_d = global_pred[\'non_plane_depth\'].squeeze()\n                    #depth = global_gt[\'depth\'].squeeze()\n                    if \'_2\' in options.suffix:\n                        pred_p, pred_s, pred_d = fitPlanes(pred_d, numPlanes=options.numOutputPlanes, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=0.2)\n                    elif \'_3\' in options.suffix:\n                        pred_p, pred_s, pred_d = fitPlanes(gt_d, numPlanes=options.numOutputPlanes, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=0.2)\n                        pass\n\n                    # gt_p = global_gt[\'plane\'][0]\n                    # pred_p = planes\n                    # valid_mask = (np.linalg.norm(gt_p, axis=1) > 0).astype(np.float32)\n                    # diff = np.min(np.linalg.norm(np.expand_dims(gt_p, 1) - np.expand_dims(pred_p, 0), axis=2), 1)\n                    # num += valid_mask.sum()\n                    # lossSum += (diff * valid_mask).sum()\n                    if options.dataset == \'SUNCG\':\n                        planeMask = np.squeeze(debug[\'segmentation\']).sum(axis=2)\n                    else:\n                        planeMask = np.ones((HEIGHT, WIDTH))\n                        if \'_2\' in options.suffix or \'_3\' in options.suffix:\n                            planeMask *= (pred_s < options.numOutputPlanes).astype(np.float32)\n                        pass\n\n                    if index < 10:\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', image)\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth.png\', drawDepthImage(gt_d))\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n                        if \'_2\' in options.suffix or \'_3\' in options.suffix:\n                            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(pred_s))\n                            pass\n                        #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_plane_mask.png\', drawMaskImage(planeMask))\n                        pass\n\n\n                    gtDepths.append(gt_d)\n                    predDepths.append(pred_d)\n                    planeMasks.append(planeMask)\n\n\n                    if options.dataset != \'NYU_RGBD\' and (\'_2\' in options.suffix or \'_3\' in options.suffix):\n                        gt_p = global_gt[\'plane\'][0]\n                        gt_s = global_gt[\'segmentation\'][0]\n                        gt_num_p = global_gt[\'num_planes\'][0]\n\n                        pred_s = (np.expand_dims(pred_s, -1) == np.reshape(np.arange(options.numOutputPlanes), [1, 1, -1])).astype(np.float32)\n                        gtPlanes.append(gt_p)\n                        predPlanes.append(pred_p)\n                        gtSegmentations.append(gt_s)\n                        gtNumPlanes.append(gt_num_p)\n                        predSegmentations.append(pred_s)\n                        pass\n\n                    #planeMasks.append((planeSegmentation < options.numOutputPlanes).astype(np.float32))\n                    continue\n\n                print(losses)\n                print(total_loss)\n                #print(losses)\n                #exit(1)\n                im = img[0]\n                image = ((im + 0.5) * 255).astype(np.uint8)\n\n                gt_d = global_gt[\'depth\'].squeeze()\n\n\n                if options.predictLocal:\n                    pred_local_s = 1 / (1 + np.exp(-local_pred[\'score\'][0]))\n                    pred_local_p = local_pred[\'plane\'][0]\n                    pred_local_m = local_pred[\'mask\'][0]\n\n                    gt_local_s = local_gt[\'score\'][0]\n                    gt_local_m = local_gt[\'mask\'][0]\n\n                    #visualize local plane prediction\n                    stride = 8\n                    boxSize = 64\n                    xs = np.arange(WIDTH / stride) * stride + stride / 2\n                    ys = np.arange(HEIGHT / stride) * stride + stride / 2\n                    padding = boxSize / 2 + 1\n                    maskImage = np.zeros((HEIGHT + padding * 2, WIDTH + padding * 2, 3), dtype=np.uint8)\n                    maskImage[padding:padding + HEIGHT, padding:padding + WIDTH, :] = image / 2\n                    for gridY, y in enumerate(ys):\n                        for gridX, x in enumerate(xs):\n                            score = pred_local_s[gridY][gridX]\n                            if score < 0.5:\n                                continue\n                            mask = pred_local_m[gridY][gridX].reshape([16, 16])\n                            mask = cv2.resize(mask, (boxSize, boxSize))\n                            maskImage[y - boxSize / 2 + padding:y + boxSize / 2 + padding, x - boxSize / 2 + padding:x + boxSize / 2 + padding, 0][mask > 0.5] = 255\n                            continue\n                        continue\n                    for gridY, y in enumerate(ys):\n                        for gridX, x in enumerate(xs):\n                            score = gt_local_s[gridY][gridX]\n                            if score < 0.5:\n                                continue\n                            mask = gt_local_m[gridY][gridX].reshape([16, 16])\n                            mask = cv2.resize(mask, (boxSize, boxSize))\n                            maskImage[y - boxSize / 2 + padding:y + boxSize / 2 + padding, x - boxSize / 2 + padding:x + boxSize / 2 + padding, 2][mask > 0.5] = 255\n                            continue\n                        continue\n                    pass\n\n                pred_p = global_pred[\'plane\'][0]\n                pred_s = global_pred[\'segmentation\'][0]\n\n                pred_np_m = global_pred[\'non_plane_mask\'][0]\n                pred_np_d = global_pred[\'non_plane_depth\'][0]\n                pred_np_n = global_pred[\'non_plane_normal\'][0]\n\n                planeMask = 1 - global_gt[\'non_plane_mask\'][0]\n                info = global_gt[\'info\'][0]\n\n\n                all_segmentations = np.concatenate([pred_s, pred_np_m], axis=2)\n                all_segmentations_softmax = softmax(all_segmentations)\n                segmentation = np.argmax(all_segmentations, 2)\n\n\n                #pred_p, segmentation, numPlanes = mergePlanes(global_gt[\'plane\'][0], np.concatenate([global_gt[\'segmentation\'][0], global_gt[\'non_plane_mask\'][0]], axis=2), global_gt[\'depth\'][0].squeeze(), global_gt[\'info\'][0], np.concatenate([pred_s, pred_np_m], axis=2))\n\n\n                plane_depths = calcPlaneDepths(pred_p, WIDTH, HEIGHT, info)\n                all_depths = np.concatenate([plane_depths, pred_np_d], axis=2)\n\n                pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape(HEIGHT, WIDTH)\n\n                plane_normals = calcPlaneNormals(pred_p, WIDTH, HEIGHT)\n                all_normals = np.concatenate([plane_normals, np.expand_dims(pred_np_n, 2)], axis=2)\n                pred_n = np.sum(all_normals * np.expand_dims(one_hot(segmentation, options.numOutputPlanes+1), -1), 2)\n                #pred_n = all_normals.reshape(-1, options.numOutputPlanes + 1, 3)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape((HEIGHT, WIDTH, 3))\n\n\n                if False:\n                    gt_s = global_gt[\'segmentation\'][0]\n                    all_segmentations = np.concatenate([gt_s, 1 - planeMask], axis=2)\n                    gt_p = global_gt[\'plane\'][0]\n\n                    # valid_mask = (np.linalg.norm(gt_p, axis=1) > 0).astype(np.float32)\n                    # diff = np.min(np.linalg.norm(np.expand_dims(gt_p, 1) - np.expand_dims(pred_p, 0), axis=2), 1)\n                    # num += valid_mask.sum()\n                    # lossSum += (diff * valid_mask).sum()\n                    #gt_p = np.stack([-gt_p[:, 0], -gt_p[:, 2], -gt_p[:, 1]], axis=1)\n\n                    plane_depths = calcPlaneDepths(gt_p, WIDTH, HEIGHT, info)\n                    all_depths = np.concatenate([plane_depths, pred_np_d], axis=2)\n\n                    segmentation = np.argmax(all_segmentations, 2)\n                    pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape(HEIGHT, WIDTH)\n                    # print(gt_p)\n                    # for segmentIndex in xrange(options.numOutputPlanes):\n                    #     cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_mask_\' + str(segmentIndex) + \'.png\', drawMaskImage(segmentation == segmentIndex))\n                    #     continue\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n                    #exit(1)\n                    pass\n\n\n\n                gt_p = global_gt[\'plane\'][0]\n                gt_s = global_gt[\'segmentation\'][0]\n                gt_num_p = global_gt[\'num_planes\'][0]\n                gtPlanes.append(gt_p)\n                predPlanes.append(pred_p)\n                gtSegmentations.append(gt_s)\n                gtNumPlanes.append(gt_num_p)\n                predSegmentations.append(pred_s)\n\n\n                gtDepths.append(gt_d)\n                planeMasks.append(planeMask.squeeze())\n                predDepths.append(pred_d)\n                evaluateDepths(predDepths[-1], gtDepths[-1], gtDepths[-1] > 0, planeMasks[-1])\n\n\n                if index >= 10:\n                    continue\n\n                if options.predictSemantics:\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_semantics_pred.png\', drawSegmentationImage(global_pred[\'semantics\'][0], blackIndex=0))\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_semantics_gt.png\', drawSegmentationImage(global_gt[\'semantics\'][0], blackIndex=0))\n                    pass\n\n                if \'cost_mask\' in debug:\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_cost_mask.png\', drawMaskImage(np.sum(debug[\'cost_mask\'][0], axis=-1)))\n\n                    for planeIndex in xrange(options.numOutputPlanes + 1):\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_cost_mask_\' + str(planeIndex) + \'.png\', drawMaskImage(debug[\'cost_mask\'][0, :, :, planeIndex]))\n                        continue\n                    all_segmentations = np.concatenate([pred_s, pred_np_m], axis=2)\n                    for planeIndex in xrange(options.numOutputPlanes + 1):\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred_\' + str(planeIndex) + \'.png\', drawMaskImage(all_segmentations[:, :, planeIndex]))\n                        continue\n                    exit(1)\n                    pass\n\n                if \'normal\' in global_gt:\n                    gt_n = global_gt[\'normal\'][0]\n                    norm = np.linalg.norm(gt_n, axis=-1, keepdims=True)\n                    gt_n /= np.maximum(norm, 1e-4)\n\n                    #gt_n = np.stack([-gt_n[:, :, 0], -gt_n[:, :, 2], -gt_n[:, :, 1]], axis=2)\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_gt.png\', drawNormalImage(gt_n))\n                    #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_pred.png\', drawNormalImage(pred_np_n))\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_pred.png\', drawNormalImage(pred_n))\n                    pass\n\n                if \'segmentation\' in global_gt:\n                    gt_s = global_gt[\'segmentation\'][0]\n                    gt_p = global_gt[\'plane\'][0]\n\n\n                    #for planeIndex in xrange(options.numOutputPlanes):\n                    #cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(gt_s[:, :, planeIndex]))\n                    #continue\n\n\n                    # print(gt_p)\n                    # print(gt_n[109][129])\n                    # print(gt_n[166][245])\n                    # print(gt_s[109][129])\n                    # print(gt_s[166][245])\n                    # print(plane_normals[109][129])\n                    # print(plane_normals[166][245])\n                    # for planeIndex in xrange(options.numOutputPlanes):\n                    #     cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(gt_s[:, :, planeIndex]))\n                    #     continue\n                    # exit(1)\n\n                    gt_s, gt_p = sortSegmentations(gt_s, gt_p, pred_p)\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_plane_mask_gt.png\', drawMaskImage(planeMask))\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_gt.png\', drawSegmentationImage(np.concatenate([gt_s, 1 - planeMask], axis=2), blackIndex=options.numOutputPlanes)\n)\n                    #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_test.png\', drawMaskImage(np.sum(np.concatenate([gt_s, 1 - planeMask], axis=2), axis=2)))\n                    #exit(1)\n                    #exit(1)\n                    pass\n\n\n                if options.predictConfidence == 1 and options.dataset == \'SUNCG\':\n                    assert(False)\n                    pred_p_c = global_pred[\'confidence\'][0]\n                    pred_p_c = 1 / (1 + np.exp(-pred_p_c))\n                    #print(pred_p_c)\n                    # print(losses)\n                    # print(debug[\'plane\'][0])\n                    # print(pred_p)\n                    # exit(1)\n                    numPlanes = global_gt[\'num_planes\'][0]\n                    print((numPlanes, (pred_p_c > 0.5).sum()))\n\n                    pred_p_c = (pred_p_c > 0.5).astype(np.float32)\n                    pred_p *= pred_p_c\n                    pred_s -= (1 - pred_p_c.reshape([1, 1, options.numOutputPlanes])) * 10\n                    pass\n\n                if False:\n                    #dump results for post processing\n                    if index >= 10:\n                        break\n                    np.save(options.dump_dir + \'/planes_\' + str(index) + \'.npy\', pred_p)\n                    np.save(options.dump_dir + \'/segmentations_\' + str(index) + \'.npy\', pred_s)\n                    np.save(options.dump_dir + \'/segmentations_gt_\' + str(index) + \'.npy\', gt_s)\n                    np.save(options.dump_dir + \'/non_plane_depth_\' + str(index) + \'.npy\', pred_np_d)\n                    np.save(options.dump_dir + \'/non_plane_segmentation_\' + str(index) + \'.npy\', pred_np_m)\n                    boundary = pred_boundary[0]\n                    boundary = 1 / (1 + np.exp(-boundary))\n                    boundary = np.concatenate([boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)\n                    cv2.imwrite(options.dump_dir + \'/boundary_\' + str(index) + \'.png\', drawMaskImage(boundary))\n                    cv2.imwrite(options.dump_dir + \'/image_\' + str(index) + \'.png\', cv2.resize(image, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR))\n                    np.save(options.dump_dir + \'/depth_\' + str(index) + \'.npy\', gt_d)\n                    continue\n\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', image)\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth.png\', drawDepthImage(gt_d))\n                #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_overlay.png\', drawDepthImageOverlay(image, gt_d))\n\n                if options.predictBoundary:\n                    pred_boundary = global_pred[\'boundary\'][0]\n                    pred_boundary = 1 / (1 + np.exp(-pred_boundary))\n                    boundary = np.concatenate([pred_boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_boundary_pred.png\', drawMaskImage(boundary))\n                    pass\n\n                if \'boundary\' in global_gt:\n                    gt_boundary = global_gt[\'boundary\'][0]\n                    boundary = np.concatenate([gt_boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_boundary_gt.png\', drawMaskImage(boundary))\n                    pass\n\n                for layerIndex, layer in enumerate(options.deepSupervisionLayers):\n                    segmentation_deep = np.argmax(deep_preds[layerIndex][\'segmentation\'][0], 2)\n                    segmentation_deep[segmentation_deep == options.numOutputPlanes] = -1\n                    segmentation_deep += 1\n\n                    plane_depths_deep = calcPlaneDepths(deep_preds[layerIndex][\'plane\'][0], WIDTH, HEIGHT, info)\n                    all_depths_deep = np.concatenate([pred_np_d, plane_depths_deep], axis=2)\n                    pred_d_deep = all_depths_deep.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation_deep.reshape(-1)].reshape(HEIGHT, WIDTH)\n\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred_\' + str(layerIndex) + \'.png\', drawSegmentationImage(deep_preds[layerIndex][\'segmentation\'][0]))\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred_\' + str(layerIndex) + \'.png\', drawDepthImage(pred_d_deep))\n                    pass\n\n\n                #print(pred_np_m)\n                #print(pred_s)\n                #print(global_gt[\'plane\'][0])\n                #print(pred_p)\n                #exit(1)\n\n                print(\'depth diff\', np.abs(pred_d - gt_d).mean())\n\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(all_segmentations, blackIndex=options.numOutputPlanes))\n                #exit(1)\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_diff.png\', drawMaskImage(np.abs(pred_d - gt_d) * planeMask.squeeze() / 0.2))\n                #exit(1)\n\n\n                #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_plane_mask.png\', drawMaskImage(planeMask))\n\n                #print(np.concatenate([np.arange(options.numOutputPlanes).reshape(-1, 1), planes, pred_p, preds_p[0][0]], axis=1))\n\n                #print(np.concatenate([distance[0], preds_p[0][0], pred_p], axis=1))\n\n                #segmentation = np.argmax(pred_s, 2)\n                #writePLYFile(options.test_dir, index, image, pred_d, segmentation, np.zeros(pred_boundary[0].shape))\n                #writePLYFileParts(options.test_dir, index, image, pred_d, segmentation)\n                #gt_s_ori = gt_s_ori[0]\n\n\n                # if \'depth\' in debug:\n                #     cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred_1.png\', drawDepthImage(debug[\'depth\'][0]))\n                #     gt_s_ori = debug[\'segmentation\'][0]\n                #     cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_gt.png\', drawSegmentationImage(gt_s_ori, blackIndex=options.numOutputPlanes))\n                #     total_loss = 0\n                #     for planeIndex in xrange(gt_s_ori.shape[-1]):\n                #         mask_pred = all_segmentations_softmax[:, :, planeIndex]\n                #         loss = -(gt_s_ori[:, :, planeIndex] * np.log(np.maximum(all_segmentations_softmax[:, :, planeIndex], 1e-31))).mean() * 1000\n                #         print(planeIndex, loss)\n                #         total_loss += loss\n                #         cv2.imwrite(options.test_dir + \'/mask_pred_\' + str(planeIndex) + \'.png\', drawMaskImage(mask_pred))\n                #         cv2.imwrite(options.test_dir + \'/mask_gt_\' + str(planeIndex) + \'.png\', drawMaskImage(gt_s_ori[:, :, planeIndex]))\n                #         continue\n                #     print(total_loss)\n                #     print(gt_s_ori.sum(2).max())\n                #     exit(1)\n                #     pass\n\n\n                if False:\n                    #distance = distance[0]\n                    print(distance)\n                    diff = np.linalg.norm(np.expand_dims(planes, 1) - np.expand_dims(pred_p, 0), axis=2)\n                    print(np.concatenate([planes, pred_p, pow(np.min(diff, axis=1, keepdims=True), 2), np.expand_dims(np.argmin(diff, axis=1), -1)], axis=1))\n                    print(pred_p_c)\n\n                    #print(distance[:, 6:8].sum(0))\n                    #print(pow(np.linalg.norm(distance[:, :3] - distance[:, 3:6], 2, 1), 2) * 100)\n                    #print(test)\n                    segmentation = np.argmax(all_segmentations, 2) - 1\n                    for planeIndex in xrange(options.numOutputPlanes):\n                        cv2.imwrite(options.test_dir + \'/segmentation_\' + str(planeIndex) + \'.png\', drawMaskImage(segmentation == planeIndex))\n                        cv2.imwrite(options.test_dir + \'/segmentation_\' + str(planeIndex) + \'_gt.png\', drawMaskImage(gt_s[:, :, planeIndex]))\n                        cv2.imwrite(options.test_dir + \'/segmentation_\' + str(planeIndex) + \'_gt_ori.png\', drawMaskImage(gt_s_ori[:, :, planeIndex]))\n                        continue\n                    exit(1)\n                continue\n\n            # if options.dataset == \'SUNCG\':\n            #     if \'pixelwise\' not in options.suffix:\n            #         evaluatePlaneSegmentation(np.array(predPlanes), np.array(predSegmentations), np.array(gtPlanes), np.array(gtSegmentations), np.array(gtNumPlanes), planeDistanceThreshold = 0.3, IOUThreshold = 0.5, prefix=\'test/planenet_\')\n            #     elif \'_2\' in options.suffix:\n            #         evaluatePlaneSegmentation(np.array(predPlanes), np.array(predSegmentations), np.array(gtPlanes), np.array(gtSegmentations), np.array(gtNumPlanes), planeDistanceThreshold = 0.3, IOUThreshold = 0.5, prefix=\'test/pixelwise_pred_\')\n            #     elif \'_3\' in options.suffix:\n            #         evaluatePlaneSegmentation(np.array(predPlanes), np.array(predSegmentations), np.array(gtPlanes), np.array(gtSegmentations), np.array(gtNumPlanes), planeDistanceThreshold = 0.3, IOUThreshold = 0.5, prefix=\'test/pixelwise_gt_\')\n            #         pass\n            #     pass\n\n            predDepths = np.array(predDepths)\n            gtDepths = np.array(gtDepths)\n            planeMasks = np.array(planeMasks)\n            #predMasks = np.array(predMasks)\n            evaluateDepths(predDepths, gtDepths, gtDepths > 0, planeMasks)\n            exit(1)\n\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n\n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return\n\n\ndef writeInfo(options):\n    x = (np.arange(11) * 0.1).tolist()\n    ys = []\n    ys.append(np.load(\'test/planenet_pixel_IOU.npy\').tolist())\n    ys.append(np.load(\'test/pixelwise_pred_pixel_IOU.npy\').tolist())\n    ys.append(np.load(\'test/pixelwise_gt_pixel_IOU.npy\').tolist())\n    plotCurves(x, ys, filename = \'test/plane_comparison.png\', xlabel=\'IOU\', ylabel=\'pixel coverage\', labels=[\'planenet\', \'pixelwise+RANSAC\', \'GT+RANSAC\'])\n\n    x = (0.5 - np.arange(11) * 0.05).tolist()\n    ys = []\n    ys.append(np.load(\'test/planenet_pixel_diff.npy\').tolist())\n    ys.append(np.load(\'test/pixelwise_pred_pixel_diff.npy\').tolist())\n    ys.append(np.load(\'test/pixelwise_gt_pixel_diff.npy\').tolist())\n    plotCurves(x, ys, filename = \'test/plane_comparison_diff.png\', xlabel=\'diff\', ylabel=\'pixel coverage\', labels=[\'planenet\', \'pixelwise+RANSAC\', \'GT+RANSAC\'])\n\n    return\n\ndef parse_args():\n    """"""\n    Parse input arguments\n    """"""\n    parser = argparse.ArgumentParser(description=\'Planenet\')\n    parser.add_argument(\'--gpu\', dest=\'gpu_id\',\n                        help=\'GPU device id to use [0]\',\n                        default=0, type=int)\n    #task: [train, test, predict]\n    parser.add_argument(\'--task\', dest=\'task\',\n                        help=\'task type: [train, test, predict]\',\n                        default=\'train\', type=str)\n    parser.add_argument(\'--restore\', dest=\'restore\',\n                        help=\'how to restore the model\',\n                        default=0, type=int)\n    parser.add_argument(\'--numOutputPlanes\', dest=\'numOutputPlanes\',\n                        help=\'the number of output planes\',\n                        default=10, type=int)\n    parser.add_argument(\'--batchSize\', dest=\'batchSize\',\n                        help=\'batch size\',\n                        default=8, type=int)\n    parser.add_argument(\'--dataset\', dest=\'dataset\',\n                        help=\'dataset name for test/predict\',\n                        default=\'\', type=str)\n    parser.add_argument(\'--numImages\', dest=\'numImages\',\n                        help=\'the number of images to test/predict\',\n                        default=10, type=int)\n    parser.add_argument(\'--boundaryLoss\', dest=\'boundaryLoss\',\n                        help=\'use boundary loss: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--diverseLoss\', dest=\'diverseLoss\',\n                        help=\'use diverse loss: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--labelLoss\', dest=\'labelLoss\',\n                        help=\'use label loss: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--planeLoss\', dest=\'planeLoss\',\n                        help=\'use plane loss: [0, 1]\',\n                        default=1, type=int)\n    parser.add_argument(\'--depthLoss\', dest=\'depthLoss\',\n                        help=\'use depth loss: [0, 1, 2]\',\n                        default=1, type=int)\n    parser.add_argument(\'--deepSupervision\', dest=\'deepSupervision\',\n                        help=\'deep supervision level: [0, 1, 2]\',\n                        default=0, type=int)\n    parser.add_argument(\'--sameMatching\', dest=\'sameMatching\',\n                        help=\'use the same matching for all deep supervision layers and the final prediction: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--anchorPlanes\', dest=\'anchorPlanes\',\n                        help=\'use anchor planes for all deep supervision layers and the final prediction: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--crf\', dest=\'crf\',\n                        help=\'the number of CRF iterations\',\n                        default=0, type=int)\n    parser.add_argument(\'--crfrnn\', dest=\'crfrnn\',\n                        help=\'the number of CRF (as RNN) iterations\',\n                        default=5, type=int)\n    parser.add_argument(\'--backwardLossWeight\', dest=\'backwardLossWeight\',\n                        help=\'backward matching loss\',\n                        default=0, type=float)\n    parser.add_argument(\'--predictBoundary\', dest=\'predictBoundary\',\n                        help=\'whether predict boundary or not: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--predictSemantics\', dest=\'predictSemantics\',\n                        help=\'whether predict semantics or not: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--predictLocal\', dest=\'predictLocal\',\n                        help=\'whether predict local planes or not: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--predictConfidence\', dest=\'predictConfidence\',\n                        help=\'whether predict plane confidence or not: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--predictPixelwise\', dest=\'predictPixelwise\',\n                        help=\'whether predict pixelwise depth or not: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--fineTuningCheckpoint\', dest=\'fineTuningCheckpoint\',\n                        help=\'specify the model for fine-tuning\',\n                        default=\'../PlaneSetGeneration/dump_planenet_diverse/train_planenet_diverse.ckpt\', type=str)\n    parser.add_argument(\'--suffix\', dest=\'suffix\',\n                        help=\'add a suffix to keyname to distinguish experiments\',\n                        default=\'\', type=str)\n    parser.add_argument(\'--l2Weight\', dest=\'l2Weight\',\n                        help=\'L2 regulation weight\',\n                        default=5e-4, type=float)\n    parser.add_argument(\'--LR\', dest=\'LR\',\n                        help=\'learning rate\',\n                        default=3e-5, type=float)\n    parser.add_argument(\'--hybrid\', dest=\'hybrid\',\n                        help=\'hybrid training\',\n                        default=\'3\', type=str)\n    parser.add_argument(\'--dataFolder\', dest=\'dataFolder\',\n                        help=\'data folder\',\n                        default=\'/home/chenliu/Projects/PlaneNet/\', type=str)\n    parser.add_argument(\'--saveInterval\', dest=\'saveInterval\',\n                        help=\'save interval\',\n                        default=900, type=int)\n    parser.add_argument(\'--modelPathDeepLab\', dest=\'modelPathDeepLab\',\n                        help=\'DeepLab model path\',\n                        default=\'../PretrainedModels/deeplab_resnet.ckpt\', type=str)\n\n    args = parser.parse_args()\n    args.keyname = os.path.basename(__file__).rstrip(\'.py\')\n    args.keyname = args.keyname.replace(\'train_\', \'\')\n    args.keyname = \'sample\'\n\n    if args.numOutputPlanes != 20:\n        args.keyname += \'_np\' + str(args.numOutputPlanes)\n        pass\n    args.keyname += \'_hybrid\' + args.hybrid\n\n    if args.boundaryLoss != 1:\n        args.keyname += \'_bl\' + str(args.boundaryLoss)\n        pass\n    if args.diverseLoss == 0:\n        args.keyname += \'_dl0\'\n        pass\n    if args.labelLoss == 1:\n        args.keyname += \'_ll1\'\n        pass\n    if args.planeLoss == 0:\n        args.keyname += \'_pl0\'\n        pass\n    if args.depthLoss != 1:\n        args.keyname += \'_hl\' + str(args.depthLoss)\n        pass\n    if args.deepSupervision != 1:\n        args.keyname += \'_ds\' + str(args.deepSupervision)\n        pass\n    if args.crf > 0:\n        args.keyname += \'_crf\' + str(args.crf)\n        pass\n    if args.crfrnn != 0:\n        args.keyname += \'_crfrnn\' + str(args.crfrnn)\n        pass\n    if args.backwardLossWeight > 0:\n        args.keyname += \'_bw\' + str(args.backwardLossWeight)\n        pass\n    if args.predictBoundary == 1:\n        args.keyname += \'_pb\'\n        pass\n    if args.predictConfidence == 1:\n        args.keyname += \'_pc\'\n        pass\n    # if args.predictLocal == 1:\n    #     args.keyname += \'_pl\'\n    #     pass\n    if args.predictPixelwise == 1:\n        args.keyname += \'_pp\'\n        pass\n    if args.predictSemantics == 1:\n        args.keyname += \'_ps\'\n        pass\n    if args.sameMatching == 0:\n        args.keyname += \'_sm0\'\n        pass\n    if args.anchorPlanes == 1:\n        args.keyname += \'_ap1\'\n        pass\n\n    #args.predictSemantics = 0\n    #args.predictBoundary = 0\n\n    args.checkpoint_dir = \'checkpoint/\' + args.keyname\n    args.log_dir = \'log/\' + args.keyname\n    args.test_dir = \'test/\' + args.keyname + \'_\' + args.dataset\n    args.predict_dir = \'predict/\' + args.keyname + \'_\' + args.dataset\n    args.dump_dir = \'dump/\' + args.keyname\n\n    #layers where deep supervision happens\n    args.deepSupervisionLayers = []\n    if args.deepSupervision >= 1:\n        args.deepSupervisionLayers.append(\'res4b22_relu\')\n        pass\n    if args.deepSupervision >= 2:\n        args.deepSupervisionLayers.append(\'res4b12_relu\')\n        pass\n    return args\n\n\nif __name__==\'__main__\':\n\n    # plane = np.load(\'temp/plane.npy\')\n    # depth = np.load(\'temp/depth.npy\')\n    # segmentation = np.load(\'temp/segmentation.npy\')\n    # info = np.load(\'temp/info.npy\')\n    # num_planes = np.load(\'temp/num_planes.npy\')\n    # segmentation = np.argmax(segmentation, axis=-1)\n    # print(segmentation.shape)\n    # planes, segmentation, numPlanes = removeSmallSegments(plane, np.zeros((HEIGHT, WIDTH, 3)), depth.squeeze(), np.zeros((HEIGHT, WIDTH, 3)), segmentation, np.zeros((HEIGHT, WIDTH)), info, num_planes)\n    # print(planes)\n    # exit(1)\n\n    args = parse_args()\n\n    print ""keyname=%s task=%s started""%(args.keyname, args.task)\n    try:\n        if args.task == ""train"":\n            main(args)\n        elif args.task == ""test"":\n            test(args)\n        elif args.task == ""predict"":\n            predict(args)\n        elif args.task == ""fit"":\n            fitPlanesRGBD(args)\n        elif args.task == ""write"":\n            writeInfo(args)\n        else:\n            assert False,""format wrong""\n            pass\n    finally:\n        pass\n'"
utils.py,0,"b'import numpy as np\nimport PIL.Image\nimport copy\nimport sys\nimport os\nimport cv2\nimport scipy.ndimage as ndimage\n#import pydensecrf.densecrf as dcrf\n#from pydensecrf.utils import compute_unary, create_pairwise_bilateral, \\\n    #create_pairwise_gaussian, unary_from_softmax\nfrom skimage import segmentation\n#from skimage.future import graph\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom layers import PlaneDepthLayer\n#from layers import PlaneNormalLayer\n#from SegmentationRefinement import *\n\nclass ColorPalette:\n    def __init__(self, numColors):\n        #np.random.seed(2)\n        #self.colorMap = np.random.randint(255, size = (numColors, 3))\n        #self.colorMap[0] = 0\n\n        \n        self.colorMap = np.array([[255, 0, 0],\n                                  [0, 255, 0],\n                                  [0, 0, 255],\n                                  [80, 128, 255],\n                                  [255, 230, 180],\n                                  [255, 0, 255],\n                                  [0, 255, 255],\n                                  [100, 0, 0],\n                                  [0, 100, 0],                                   \n                                  [255, 255, 0],                                  \n                                  [50, 150, 0],\n                                  [200, 255, 255],\n                                  [255, 200, 255],\n                                  [128, 128, 80],\n                                  [0, 50, 128],                                  \n                                  [0, 100, 100],\n                                  [0, 255, 128],                                  \n                                  [0, 128, 255],\n                                  [255, 0, 128],                                  \n                                  [128, 0, 255],\n                                  [255, 128, 0],                                  \n                                  [128, 255, 0],                                                                    \n        ])\n\n        if numColors > self.colorMap.shape[0]:\n            self.colorMap = np.random.randint(255, size = (numColors, 3))\n            pass\n        \n        return\n\n    def getColorMap(self):\n        return self.colorMap\n    \n    def getColor(self, index):\n        if index >= colorMap.shape[0]:\n            return np.random.randint(255, size = (3))\n        else:\n            return self.colorMap[index]\n            pass\n\ndef writePointCloud(filename, pointCloud, color = [255, 255, 255]):\n    with open(filename, \'w\') as f:\n        header = """"""ply\nformat ascii 1.0\nelement vertex """"""\n        header += str(pointCloud.shape[0])\n        header += """"""\nproperty float x\nproperty float y\nproperty float z\nproperty uchar red                                     { start of vertex color }\nproperty uchar green\nproperty uchar blue\nend_header\n""""""\n        f.write(header)\n        for point in pointCloud:\n            for value in point:\n                f.write(str(value) + \' \')\n                continue\n            for value in color:\n                f.write(str(value) + \' \')\n                continue\n            f.write(\'\\n\')\n            continue\n        f.close()\n        pass\n    return\n\n\ndef writeClusteringPointCloud(filename, pointCloud, clusters):\n    with open(filename, \'w\') as f:\n        header = """"""ply\nformat ascii 1.0\nelement vertex """"""\n        header += str(pointCloud.shape[0])\n        header += """"""\nproperty float x\nproperty float y\nproperty float z\nproperty uchar red                                     { start of vertex color }\nproperty uchar green\nproperty uchar blue\nend_header\n""""""\n        colorMap = np.random.randint(255, size = clusters.shape)\n        assignment = np.argmin(np.linalg.norm(pointCloud.reshape(-1, 1, 3).repeat(clusters.shape[0], 1)[:] - clusters, 2, 2), 1)\n        f.write(header)\n        for pointIndex, point in enumerate(pointCloud):\n            for value in point:\n                f.write(str(value) + \' \')\n                continue\n            color = colorMap[assignment[pointIndex]]\n            for value in color:\n                f.write(str(value) + \' \')\n                continue\n            f.write(\'\\n\')\n            continue\n        f.close()\n        pass\n    return\n\n\ndef writeNearestNeighbors(filename, pointCloudSource, pointCloudTarget):\n    with open(filename, \'w\') as f:\n        header = """"""ply\nformat ascii 1.0\nelement vertex """"""\n        header += str((pointCloudSource.shape[0] + pointCloudTarget.shape[0] + pointCloudSource.shape[0]) * 4)\n        header += """"""\nproperty float x\nproperty float y\nproperty float z\nproperty uchar red\nproperty uchar green\nproperty uchar blue\nelement face """"""\n        header += str(pointCloudSource.shape[0] + pointCloudTarget.shape[0] + pointCloudSource.shape[0])\n        header += """"""\nproperty list uchar int vertex_index\nend_header\n""""""\n        f.write(header)\n        \n        sourceColor = [0, 255, 0]\n        targetColor = [0, 0, 255]\n        colorMap = np.random.randint(255, size = pointCloudSource.shape)\n        \n        # for pointIndex, point in enumerate(pointCloudSource):\n        #     for value in point:\n        #         f.write(str(value) + \' \')\n        #         continue\n        #     color = sourceColor\n        #     for value in color:\n        #         f.write(str(value) + \' \')\n        #         continue\n        #     f.write(\'\\n\')\n        #     continue\n\n        # for pointIndex, point in enumerate(pointCloudTarget):\n        #     for value in point:\n        #         f.write(str(value) + \' \')\n        #         continue\n        #     color = targetColor\n        #     for value in color:\n        #         f.write(str(value) + \' \')\n        #         continue\n        #     f.write(\'\\n\')\n        #     continue        \n\n        planeSize = 0.1\n        for planeType, planes in enumerate([pointCloudSource, pointCloudTarget]):\n            for planeIndex, plane in enumerate(planes):\n                planeD = np.linalg.norm(plane)\n                planeNormal = -plane / planeD\n\n                maxNormalDim = np.argmax(np.abs(plane))\n                allDims = [0, 1, 2]\n                allDims.remove(maxNormalDim)\n                dim_1, dim_2 = allDims\n                for delta_1, delta_2 in [(-planeSize, -planeSize), (planeSize, -planeSize), (planeSize, planeSize), (-planeSize, planeSize)]:\n                    point = copy.deepcopy(plane)\n                    point[dim_1] += delta_1\n                    point[dim_2] += delta_2\n                    point[maxNormalDim] = (-planeD - planeNormal[dim_1] * point[dim_1] - planeNormal[dim_2] * point[dim_2]) / planeNormal[maxNormalDim]\n\n                    for value in point:\n                        f.write(str(value) + \' \')\n                        continue\n                    if planeType == 0:\n                        color = sourceColor\n                    else:\n                        color = targetColor\n                        pass\n                    \n                    for value in color:\n                        f.write(str(value) + \' \')\n                        continue\n                    f.write(\'\\n\')\n                    continue\n                continue\n            continue\n\n        assignment = np.argmin(np.linalg.norm(pointCloudSource.reshape(-1, 1, 3).repeat(pointCloudTarget.shape[0], 1)[:] - pointCloudTarget, 2, 2), 1)\n\n        planeSize = 0.01\n        lineColor = [255, 0, 0]\n        for planeIndex, planeSource in enumerate(pointCloudSource):\n            planeD = np.linalg.norm(planeSource)\n            planeNormal = -planeSource / planeD            \n\n            maxNormalDim = np.argmax(np.abs(planeSource))\n            allDims = [0, 1, 2]\n            allDims.remove(maxNormalDim)\n            dim_1, dim_2 = allDims\n            minNormalDim = np.argmin(np.abs(planeSource))\n\n            for delta in [-planeSize, planeSize]:\n                point = copy.deepcopy(planeSource)\n                point[minNormalDim] += delta\n                point[maxNormalDim] = (-planeD - planeNormal[dim_1] * point[dim_1] - planeNormal[dim_2] * point[dim_2]) / planeNormal[maxNormalDim]\n                for value in point:\n                    f.write(str(value) + \' \')\n                    continue\n                color = lineColor\n                for value in color:\n                    f.write(str(value) + \' \')\n                    continue\n                f.write(\'\\n\')\n                continue\n\n            planeTarget = pointCloudTarget[assignment[planeIndex]]\n            planeDTarget = np.linalg.norm(plane)\n            planeNormalTarget = -plane / planeD\n            planeD = np.linalg.norm(planeTarget)\n            planeNormal = -planeTarget / planeD            \n\n            for delta in [planeSize, -planeSize]:\n                point = copy.deepcopy(planeTarget)\n                point[minNormalDim] += delta\n                point[maxNormalDim] = (-planeD - planeNormal[dim_1] * point[dim_1] - planeNormal[dim_2] * point[dim_2]) / planeNormal[maxNormalDim]\n                for value in point:\n                    f.write(str(value) + \' \')\n                    continue\n                color = lineColor\n                for value in color:\n                    f.write(str(value) + \' \')\n                    continue\n                f.write(\'\\n\')\n                continue\n            continue\n\n        for index in xrange(pointCloudSource.shape[0] + pointCloudTarget.shape[0] + pointCloudSource.shape[0]):\n            planeIndex = index * 4\n            f.write(\'4 \' + str(planeIndex + 0) + \' \' + str(planeIndex + 1) + \' \' + str(planeIndex + 2) + \' \' + str(planeIndex + 3) + \'\\n\')\n            continue\n\n        # for pointIndexSource, point in enumerate(pointCloudSource):\n    #     pointIndexTarget = assignment[pointIndexSource]\n#     f.write(str(pointIndexSource) + \' \' + str(pointIndexTarget + pointCloudSource.shape[0]) + \' \')\n        #     color = colorMap[pointIndexSource]\n    #     for value in color:\n#         f.write(str(value) + \' \')\n        #         continue\n    #     f.write(\'\\n\')\n#     continue\n\n\n        f.close()\n        pass\n    return\n\n\n# def evaluatePlanes(planes, filename = None, depths = None, normals = None, invalidMask = None, outputFolder = None, outputIndex = 0, colorMap = None):\n#     if filename != None:\n#         if \'mlt\' not in filename:\n#             filename = filename.replace(\'color\', \'mlt\')\n#             pass\n#         normalFilename = filename.replace(\'mlt\', \'norm_camera\')\n#         normals = np.array(PIL.Image.open(normalFilename)).astype(np.float) / 255 * 2 - 1\n#         norm = np.linalg.norm(normals, 2, 2)\n#         for c in xrange(3):\n#             normals[:, :, c] /= norm\n#             continue\n        \n#         depthFilename = filename.replace(\'mlt\', \'depth\')\n#         depths = np.array(PIL.Image.open(depthFilename)).astype(np.float) / 1000\n#         # if len(depths.shape) == 3:\n#         #     depths = depths.mean(2)\n#         #     pass\n#         maskFilename = filename.replace(\'mlt\', \'valid\')    \n#         invalidMask = np.array(PIL.Image.open(maskFilename))\n#         invalidMask = invalidMask < 128\n#         invalidMask += depths > 10\n#         pass\n\n#     height = normals.shape[0]\n#     width = normals.shape[1]\n#     focalLength = 517.97\n#     urange = np.arange(width).reshape(1, -1).repeat(height, 0) - width * 0.5\n#     vrange = np.arange(height).reshape(-1, 1).repeat(width, 1) - height * 0.5\n#     ranges = np.array([urange / focalLength, np.ones(urange.shape), -vrange / focalLength]).transpose([1, 2, 0])\n    \n#     X = depths / focalLength * urange\n#     Y = depths\n#     Z = -depths / focalLength * vrange\n#     d = -(normals[:, :, 0] * X + normals[:, :, 1] * Y + normals[:, :, 2] * Z)    \n\n\n#     normalDotThreshold = np.cos(np.deg2rad(30))\n#     distanceThreshold = 50000\n    \n#     reconstructedNormals = np.zeros(normals.shape)\n#     reconstructedDepths = np.zeros(depths.shape)\n#     segmentationImage = np.zeros((height, width, 3))\n#     distanceMap = np.ones((height, width)) * distanceThreshold\n#     occupancyMask = np.zeros((height, width)).astype(np.bool)\n#     segmentationTest = np.zeros((height, width))\n#     y = 297\n#     x = 540\n#     for planeIndex, plane in enumerate(planes):\n#         planeD = np.linalg.norm(plane)\n#         planeNormal = -plane / planeD\n\n#         normalXYZ = np.dot(ranges, planeNormal)\n#         normalXYZ = np.reciprocal(normalXYZ)\n#         planeY = -normalXYZ * planeD\n\n#         distance = np.abs(planeNormal[0] * X + planeNormal[1] * Y + planeNormal[2] * Z + planeD) / np.abs(np.dot(normals, planeNormal))\n#         #distance = np.abs(planeY - depths)\n        \n#         mask = (distance < distanceMap) * (planeY > 0) * (np.abs(np.dot(normals, planeNormal)) > normalDotThreshold) * (np.abs(planeY - depths) < 0.5)\n#         occupancyMask += mask\n        \n#         reconstructedNormals[mask] = planeNormal\n        \n        \n#         #if planeNormal[2] > 0.9:\n#         #print(planeD)\n#         #print(planeNormal)\n#         # minDepth = depths.min()\n#         # maxDepth = depths.max()\n#         # print(depths[300][300])\n#         # print(planeY[300][300])\n#         # print(depths[350][350])\n#         # print(planeY[350][350])\n#         # PIL.Image.fromarray((np.maximum(np.minimum((planeY - minDepth) / (maxDepth - minDepth), 1), 0) * 255).astype(np.uint8)).save(outputFolder + \'/plane.png\')\n#         # exit(1)\n#         #pass\n#         reconstructedDepths[mask] = planeY[mask]\n#         if colorMap != None and planeIndex in colorMap:\n#             segmentationImage[mask] = colorMap[planeIndex]\n#         else:\n#             segmentationImage[mask] = np.random.randint(255, size=(3,))\n#             pass\n#         distanceMap[mask] = distance[mask]\n#         segmentationTest[mask] = planeIndex + 1\n#         #print((planeIndex, planeY[y][x], distance[y][x], np.abs(np.dot(normals, planeNormal))[y][x]))\n#         continue\n\n#     # print(distanceMap.mean())\n# # print(distanceMap.max())\n#     # print(np.abs(reconstructedDepths - depths)[occupancyMask].max())\n# # print(pow(reconstructedDepths - depths, 2)[True - invalidMask].mean())\n#     # exit(1)\n\n#     # planeIndex = segmentationTest[y][x]\n# # print(normals[y][x])\n#     # plane = planes[int(planeIndex)]\n# # planeD = np.linalg.norm(plane)\n#     # planeNormal = -plane / planeD\n# # print((planeNormal, planeD))\n#     # print(depths[y][x])\n# # print(reconstructedDepths[y][x])\n#     # print(segmentationTest[y][x])\n\n#     if outputFolder != None:\n#         depths[invalidMask] = 0\n#         normals[invalidMask] = 0\n#         reconstructedDepths[invalidMask] = 0\n#         reconstructedNormals[invalidMask] = 0\n#         minDepth = depths.min()\n#         maxDepth = depths.max()\n#         #print(minDepth)\n#         #print(maxDepth)\n#         PIL.Image.fromarray(((depths - minDepth) / (maxDepth - minDepth) * 255).astype(np.uint8)).save(outputFolder + \'/\' + str(outputIndex) + \'_depth.png\')\n#         PIL.Image.fromarray((np.maximum(np.minimum((reconstructedDepths - minDepth) / (maxDepth - minDepth), 1), 0) * 255).astype(np.uint8)).save(outputFolder + \'/\' + str(outputIndex) + \'_depth_reconstructed.png\')\n#         #PIL.Image.fromarray((np.maximum(np.minimum((reconstructedDepths - depths) / (distanceThreshold), 1), 0) * 255).astype(np.uint8)).save(outputFolder + \'/depth_\' + str(outputIndex) + \'_diff.png\')\n#         PIL.Image.fromarray(((normals + 1) / 2 * 255).astype(np.uint8)).save(outputFolder + \'/\' + str(outputIndex) + \'_normal_.png\')\n#         PIL.Image.fromarray(((reconstructedNormals + 1) / 2 * 255).astype(np.uint8)).save(outputFolder + \'/\' + str(outputIndex) + \'_normal_reconstructed.png\')\n#         PIL.Image.fromarray(segmentationImage.astype(np.uint8)).save(outputFolder + \'/\' + str(outputIndex) + \'_plane_segmentation.png\')\n#         #depthImage = ((depths - minDepth) / (maxDepth - minDepth) * 255).astype(np.uint8)\n#         #PIL.Image.fromarray((invalidMask * 255).astype(np.uint8)).save(outputFolder + \'/mask.png\')\n#         #exit(1)\n#     else:\n#         occupancy = (occupancyMask > 0.5).astype(np.float32).sum() / (1 - invalidMask).sum()\n#         invalidMask += np.invert(occupancyMask)\n#         #PIL.Image.fromarray(invalidMask.astype(np.uint8) * 255).save(outputFolder + \'/mask.png\')\n#         reconstructedDepths = np.maximum(np.minimum(reconstructedDepths, 10), 0)\n#         depthError = pow(reconstructedDepths - depths, 2)[np.invert(invalidMask)].mean()\n#         #depthError = distanceMap.mean()\n#         normalError = np.arccos(np.maximum(np.minimum(np.sum(reconstructedNormals * normals, 2), 1), -1))[np.invert(invalidMask)].mean()\n#         #normalError = pow(np.linalg.norm(reconstructedNormals - normals, 2, 2), 2)[True - invalidMask].mean()\n#         #print((depthError, normalError, occupancy))\n#         # print(depths.max())\n#         # print(depths.min())\n#         # print(reconstructedDepths.max())\n#         # print(reconstructedDepths.min())\n#         # print(occupancy)\n#         # exit(1)\n        \n#         #reconstructedDepths[np.invert(occupancyMask)] = depths[np.invert(occupancyMask)]\n#         return depthError, normalError, occupancy, segmentationTest, reconstructedDepths, occupancyMask\n#     return\n\n\n# def evaluatePlanesSeparately(planes, filename, outputFolder = None, outputIndex = 0):\n#     if \'mlt\' not in filename:\n#         filename = filename.replace(\'color\', \'mlt\')\n#         pass\n#     colorImage = np.array(PIL.Image.open(filename))\n#     normalFilename = filename.replace(\'mlt\', \'norm_camera\')\n#     normals = np.array(PIL.Image.open(normalFilename)).astype(np.float) / 255 * 2 - 1\n#     height = normals.shape[0]\n#     width = normals.shape[1]\n#     norm = np.linalg.norm(normals, 2, 2)\n#     for c in xrange(3):\n#         normals[:, :, c] /= norm\n#         continue\n\n    \n#     depthFilename = filename.replace(\'mlt\', \'depth\')\n#     depths = np.array(PIL.Image.open(depthFilename)).astype(np.float) / 1000\n#     # if len(depths.shape) == 3:\n#     #     depths = depths.mean(2)\n#     #     pass\n    \n#     focalLength = 517.97\n#     urange = np.arange(width).reshape(1, -1).repeat(height, 0) - width * 0.5\n#     vrange = np.arange(height).reshape(-1, 1).repeat(width, 1) - height * 0.5\n#     ranges = np.array([urange / focalLength, np.ones(urange.shape), -vrange / focalLength]).transpose([1, 2, 0])\n#     X = depths / focalLength * urange\n#     Y = depths\n#     Z = -depths / focalLength * vrange\n#     d = -(normals[:, :, 0] * X + normals[:, :, 1] * Y + normals[:, :, 2] * Z)\n\n    \n#     maskFilename = filename.replace(\'mlt\', \'valid\')    \n#     invalidMask = np.array(PIL.Image.open(maskFilename))\n#     # if len(invalidMask.shape) == 3:\n#     #     invalidMask = invalidMask.mean(2)\n#     #     pass\n#     invalidMask = invalidMask < 128\n#     invalidMask += depths > 10\n\n\n#     normalDotThreshold = np.cos(np.deg2rad(15))\n#     distanceThreshold = 0.15\n#     colorPalette = ColorPalette(len(planes))\n#     for planeIndex, plane in enumerate(planes):\n#         planeD = np.linalg.norm(plane)\n#         planeNormal = -plane / planeD\n\n#         distance = np.abs(planeNormal[0] * X + planeNormal[1] * Y + planeNormal[2] * Z + planeD)\n\n#         normalXYZ = np.dot(ranges, planeNormal)\n#         normalXYZ = np.reciprocal(normalXYZ)\n#         planeY = -normalXYZ * planeD\n        \n#         mask = (planeY > 0) * (np.abs(np.dot(normals, planeNormal)) > normalDotThreshold) * (distance < distanceThreshold)\n\n#         maxDepth = 10\n#         minDepth = 0\n#         #PIL.Image.fromarray((np.minimum(np.maximum((planeY - minDepth) / (maxDepth - minDepth), 0), 1) * 255).astype(np.uint8)).save(outputFolder + \'/plane_depth_\' + str(planeIndex) + \'.png\')\n#         #PIL.Image.fromarray(((planeNormal.reshape(1, 1, 3).repeat(height, 0).repeat(width, 1) + 1) / 2 * 255).astype(np.uint8)).save(outputFolder + \'/plane_normal_\' + str(planeIndex) + \'.png\')\n#         planeImage = colorImage * 0.3\n#         planeImage[mask] += colorPalette.getColor(planeIndex) * 0.7\n#         PIL.Image.fromarray(planeImage.astype(np.uint8)).save(outputFolder + \'/plane_mask_\' + str(planeIndex) + \'_\' + str(outputIndex) + \'.png\')\n#         #PIL.Image.fromarray(mask.astype(np.uint8) * 255).save(outputFolder + \'/mask_\' + str(planeIndex) + \'.png\')\n#         continue\n#     return\n\ndef residual2Planes(residualPlanes, predefinedPlanes):\n    numClusters = predefinedPlanes.shape[0]\n    planes = []\n    for residualPlane in residualPlanes:\n        gridIndex = int(residualPlane[0]) / numClusters\n        planeIndex = int(residualPlane[0]) % numClusters\n        planes.append(predefinedPlanes[planeIndex] + residualPlane[1:])\n        continue\n    return planes\n\ndef residual2PlanesGlobal(residualPlanes, predefinedPlanes):\n    numClusters = predefinedPlanes.shape[0]\n    planes = []\n    for residualPlane in residualPlanes:\n        planeIndex = int(residualPlane[0])\n        planes.append(predefinedPlanes[planeIndex] + residualPlane[1:])\n        continue\n    return planes\n\n\ndef getPlaneInfo(planes):\n    imageWidth = 640\n    imageHeight = 480\n    focalLength = 517.97\n    urange = np.arange(imageWidth).reshape(1, -1).repeat(imageHeight, 0) - imageWidth * 0.5\n    vrange = np.arange(imageHeight).reshape(-1, 1).repeat(imageWidth, 1) - imageHeight * 0.5\n    ranges = np.array([urange / focalLength, np.ones(urange.shape), -vrange / focalLength]).transpose([1, 2, 0])\n    \n    planeDepths = PlaneDepthLayer(planes, ranges)\n    planeNormals = PlaneNormalLayer(planes, ranges)\n    return planeDepths, planeNormals\n\ndef getProbability(image, segmentation):\n    width = image.shape[1]\n    height = image.shape[0]\n    numPlanes = segmentation.shape[0]\n    probabilities = np.exp(segmentation)\n    probabilities = probabilities / probabilities.sum(0)\n    # The input should be the negative of the logarithm of probability values\n    # Look up the definition of the softmax_to_unary for more information\n    unary = unary_from_softmax(probabilities)\n\n    # The inputs should be C-continious -- we are using Cython wrapper\n    unary = np.ascontiguousarray(unary)\n\n    d = dcrf.DenseCRF(height * width, numPlanes)\n    \n    d.setUnaryEnergy(unary)\n\n    # This potential penalizes small pieces of segmentation that are\n    # spatially isolated -- enforces more spatially consistent segmentations\n    # feats = create_pairwise_gaussian(sdims=(10, 10), shape=(height, width))\n    # d.addPairwiseEnergy(feats, compat=300,\n    #                                         kernel=dcrf.DIAG_KERNEL,\n    #                                         normalization=dcrf.NORMALIZE_SYMMETRIC)\n\n    # This creates the color-dependent features --\n    # because the segmentation that we get from CNN are too coarse\n    # and we can use local color features to refine them\n        \n    feats = create_pairwise_bilateral(sdims=(50, 50), schan=(20, 20, 20),\n                                      img=image, chdim=2)\n    d.addPairwiseEnergy(feats, compat=10,\n                        kernel=dcrf.DIAG_KERNEL,\n                        normalization=dcrf.NORMALIZE_SYMMETRIC)\n        \n    Q = d.inference(50)\n\n    inds = np.argmax(Q, axis=0).reshape((height, width))\n    probabilities = np.zeros((height * width, numPlanes))\n    probabilities[np.arange(height * width), inds.reshape(-1)] = 1\n    probabilities = probabilities.reshape([height, width, -1])\n    #print(res.shape)\n    return probabilities\n\ndef getProbabilityMax(segmentation):\n    width = segmentation.shape[2]\n    height = segmentation.shape[1]\n    numPlanes = segmentation.shape[0]\n    inds = np.argmax(segmentation.reshape([-1, height * width]), axis=0)\n    probabilities = np.zeros((height * width, numPlanes))\n    probabilities[np.arange(height * width), inds] = 1\n    probabilities = probabilities.reshape([height, width, -1])\n    return probabilities\n\ndef evaluateNormal(predNormal, gtSegmentations, numPlanes):\n    numImages = predNormal.shape[0]\n    normal = np.linalg.norm(predNormal, axis=-1)\n    errors = []\n    for imageIndex in xrange(numImages):\n        var = 0\n        count = 0\n        \n        invalidNormalMask = np.linalg.norm(predNormal[imageIndex], axis=-1) > 1 - 1e-4\n        for planeIndex in xrange(numPlanes[imageIndex]):\n            #mask = gtSegmentations[imageIndex, :, :, planeIndex].astype(np.bool)\n            mask = gtSegmentations[imageIndex] == planeIndex\n            mask = cv2.erode(mask.astype(np.float32), np.ones((5, 5))) > 0.5\n            mask = np.logical_and(mask, invalidNormalMask)\n            if mask.sum() == 0:\n                continue\n            normals = predNormal[imageIndex][mask]\n            averageNormal = np.mean(normals, axis=0, keepdims=True)\n            averageNormal /= np.linalg.norm(averageNormal)\n            degrees = np.rad2deg(np.arccos(np.minimum(np.sum(normals * averageNormal, axis=-1), 1)))\n            #degrees = np.rad2deg(np.arccos(np.sum(normals * averageNormal, axis=-1)))\n            degrees = np.minimum(degrees, 180 - degrees)\n            var += degrees.sum()\n            count += degrees.shape[0]\n            #var += degrees.mean()\n            #totalNumPlanes += 1\n            #print(np.sum(normals * averageNormal, axis=-1))\n            print(planeIndex, degrees.sum() / degrees.shape[0])\n            cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(mask))\n            #print(normals)\n            # if planeIndex == 4:\n            #     for normal in normals:\n            #         print(normal)\n            #         continue\n            #     print(normals.mean(0))\n            #     exit(1)\n            # print(degrees)\n            # print(planeIndex, averageNormal, degrees.mean())\n            # print(normals[degrees > 90])\n            \n            continue\n        var /= count\n        errors.append(var)\n        #print(var / totalNumPlanes)\n        #exit(1)\n        continue\n    var = np.array(errors).mean()\n    print(var)\n    return var\n        \ndef evaluateDepths(predDepths, gtDepths, validMasks, planeMasks=True, printInfo=True):\n    masks = np.logical_and(np.logical_and(validMasks, planeMasks), gtDepths > 1e-4)\n    \n    numPixels = float(masks.sum())\n    \n    rmse = np.sqrt((pow(predDepths - gtDepths, 2) * masks).sum() / numPixels)\n    rmse_log = np.sqrt((pow(np.log(predDepths) - np.log(gtDepths), 2) * masks).sum() / numPixels)\n    log10 = (np.abs(np.log10(np.maximum(predDepths, 1e-4)) - np.log10(np.maximum(gtDepths, 1e-4))) * masks).sum() / numPixels\n    rel = (np.abs(predDepths - gtDepths) / np.maximum(gtDepths, 1e-4) * masks).sum() / numPixels\n    rel_sqr = (pow(predDepths - gtDepths, 2) / np.maximum(gtDepths, 1e-4) * masks).sum() / numPixels    \n    deltas = np.maximum(predDepths / np.maximum(gtDepths, 1e-4), gtDepths / np.maximum(predDepths, 1e-4)) + (1 - masks.astype(np.float32)) * 10000\n    accuracy_1 = (deltas < 1.25).sum() / numPixels\n    accuracy_2 = (deltas < pow(1.25, 2)).sum() / numPixels\n    accuracy_3 = (deltas < pow(1.25, 3)).sum() / numPixels\n    recall = float(masks.sum()) / validMasks.sum()\n    #print((rms, recall))\n    if printInfo:\n        print((\'evaluate\', rel, rel_sqr, log10, rmse, rmse_log, accuracy_1, accuracy_2, accuracy_3, recall))\n        pass\n    return rel, rel_sqr, log10, rmse, rmse_log, accuracy_1, accuracy_2, accuracy_3, recall\n    #return rel, log10, rms, accuracy_1, accuracy_2, accuracy_3, recall\n\ndef drawDepthImage(depth):\n    #return cv2.applyColorMap(np.clip(depth / 10 * 255, 0, 255).astype(np.uint8), cv2.COLORMAP_JET)\n    return 255 - np.clip(depth / 5 * 255, 0, 255).astype(np.uint8)\n\ndef drawDepthImageOverlay(image, depth):\n    #return cv2.applyColorMap(np.clip(depth / 10 * 255, 0, 255).astype(np.uint8), cv2.COLORMAP_JET)\n    depth = np.clip(depth / min(np.max(depth), 10) * 255, 0, 255).astype(np.uint8)\n    imageOverlay = np.stack([image[:, :, 1], depth, image[:, :, 2]], axis=2)\n    return imageOverlay \n    \ndef drawNormalImage(normal):\n    return ((normal + 1) / 2 * 255).astype(np.uint8)\n    \ndef drawSegmentationImage(segmentations, randomColor=None, numColors=22, blackIndex=-1):\n    if segmentations.ndim == 2:\n        numColors = max(numColors, segmentations.max() + 2, blackIndex + 1)\n    else:\n        numColors = max(numColors, segmentations.shape[2] + 2, blackIndex + 1)\n        pass\n    randomColor = ColorPalette(numColors).getColorMap()\n    if blackIndex >= 0:\n        randomColor[blackIndex] = 0\n        pass\n    width = segmentations.shape[1]\n    height = segmentations.shape[0]\n    if segmentations.ndim == 3:\n        #segmentation = (np.argmax(segmentations, 2) + 1) * (np.max(segmentations, 2) > 0.5)\n        segmentation = np.argmax(segmentations, 2)\n    else:\n        segmentation = segmentations\n        pass\n    segmentation = segmentation.astype(np.int)\n    return randomColor[segmentation.reshape(-1)].reshape((height, width, 3))\n\ndef drawMaskImage(mask):\n    return (np.clip(mask * 255, 0, 255)).astype(np.uint8)\n\ndef drawDiffImage(values_1, values_2, threshold):\n    #return cv2.applyColorMap(np.clip(np.abs(values_1 - values_2) / threshold * 255, 0, 255).astype(np.uint8), cv2.COLORMAP_JET)\n    return np.clip(np.abs(values_1 - values_2) / threshold * 255, 0, 255).astype(np.uint8)\n\n\ndef getSuperpixels(depth, normal, width, height, numPlanes=50, numGlobalPlanes = 10):\n    depth = np.expand_dims(depth, -1)\n\n    urange = (np.arange(width, dtype=np.float32) / (width + 1) - 0.5) / focalLength * 641\n    urange = np.tile(np.reshape(urange, [1, -1]), [height, 1])\n    vrange = (np.arange(height, dtype=np.float32) / (height + 1) - 0.5) / focalLength * 481\n    vrange = np.tile(np.reshape(vrange, [-1, 1]), [1, width])\n    \n    ranges = np.stack([urange, np.ones([height, width]), -vrange], axis=2)\n    #ranges = np.expand_dims(ranges, 0)\n\n    planeImage = np.sum(normal * ranges, axis=2, keepdims=True) * depth * normal\n    planeImage = planeImage / 10 * 1000\n\n    superpixels = segmentation.slic(planeImage, compactness=30, n_segments=400)\n    g = graph.rag_mean_color(planeImage, superpixels, mode=\'similarity\')\n    planeSegmentation = graph.cut_normalized(superpixels, g)\n    return planeSegmentation, superpixels\n\n\ndef calcPlaneDepths(planes, width, height, info):\n    urange = np.arange(width, dtype=np.float32).reshape(1, -1).repeat(height, 0) / (width + 1) * (info[16] + 1) - info[2]\n    vrange = np.arange(height, dtype=np.float32).reshape(-1, 1).repeat(width, 1) / (height + 1) * (info[17] + 1) - info[6]\n    ranges = np.array([urange / info[0], np.ones(urange.shape), -vrange / info[5]]).transpose([1, 2, 0])\n    planeDepths = PlaneDepthLayer(planes, ranges)\n    return planeDepths\n\ndef calcPlaneNormals(planes, width, height):\n    planeNormals = -planes / np.maximum(np.linalg.norm(planes, axis=-1, keepdims=True), 1e-4)\n    return np.tile(planeNormals.reshape([1, 1, -1, 3]), [height, width, 1, 1])\n\n\ndef writePLYFile(folder, index, image, depth, segmentation, planes, info):\n    imageFilename = str(index) + \'_model_texture.png\'\n    cv2.imwrite(folder + \'/\' + imageFilename, image)\n\n    width = image.shape[1]\n    height = image.shape[0]\n    \n    numPlanes = planes.shape[0]\n    \n    camera = getCameraFromInfo(info)\n\n    #camera = getNYURGBDCamera()\n    #camera = getSUNCGCamera()\n\n    urange = (np.arange(width, dtype=np.float32) / width * camera[\'width\'] - camera[\'cx\']) / camera[\'fx\']\n    urange = urange.reshape(1, -1).repeat(height, 0)\n    vrange = (np.arange(height, dtype=np.float32) / height * camera[\'height\'] - camera[\'cy\']) / camera[\'fy\']\n    vrange = vrange.reshape(-1, 1).repeat(width, 1)\n    X = depth * urange\n    Y = depth\n    Z = -depth * vrange\n\n    XYZ = np.stack([X, Y, Z], axis=2)\n\n    \n    #focalLength = 517.97\n        \n    faces = []\n    #minDepthDiff = 0.15\n    #maxDepthDiff = 0.3\n    #occlusionBoundary = boundaries[:, :, 1]\n    betweenRegionThreshold = 0.1\n    nonPlanarRegionThreshold = 0.02\n    \n    planesD = np.linalg.norm(planes, axis=1, keepdims=True)\n    planeNormals = -planes / np.maximum(planesD, 1e-4)    \n\n    croppingRatio = -0.05\n    dotThreshold = np.cos(np.deg2rad(30))\n    \n    for y in xrange(height - 1):\n        for x in xrange(width - 1):\n            if y < height * croppingRatio or y > height * (1 - croppingRatio) or x < width * croppingRatio or x > width * (1 - croppingRatio):\n                continue\n            \n            segmentIndex = segmentation[y][x]\n            if segmentIndex == -1:\n                continue    \n\n            point = XYZ[y][x]\n            #neighborPixels = []\n            validNeighborPixels = []\n            for neighborPixel in [(x, y + 1), (x + 1, y), (x + 1, y + 1)]:\n                neighborSegmentIndex = segmentation[neighborPixel[1]][neighborPixel[0]]\n                if neighborSegmentIndex == segmentIndex:\n                    if segmentIndex < numPlanes:\n                        validNeighborPixels.append(neighborPixel)\n                    else:\n                        neighborPoint = XYZ[neighborPixel[1]][neighborPixel[0]]\n                        if np.linalg.norm(neighborPoint - point) < nonPlanarRegionThreshold:\n                            validNeighborPixels.append(neighborPixel)\n                            pass\n                        pass\n                else:\n                    neighborPoint = XYZ[neighborPixel[1]][neighborPixel[0]]\n                    if segmentIndex < numPlanes and neighborSegmentIndex < numPlanes:\n                        if (abs(np.dot(planeNormals[segmentIndex], neighborPoint) + planesD[segmentIndex]) < betweenRegionThreshold or abs(np.dot(planeNormals[neighborSegmentIndex], point) + planesD[neighborSegmentIndex]) < betweenRegionThreshold) and np.abs(np.dot(planeNormals[segmentIndex], planeNormals[neighborSegmentIndex])) < dotThreshold:\n                            validNeighborPixels.append(neighborPixel)\n                            pass\n                    else:\n                        if np.linalg.norm(neighborPoint - point) < betweenRegionThreshold:\n                            validNeighborPixels.append(neighborPixel)\n                            pass\n                        pass                            \n                    pass\n                continue\n            if len(validNeighborPixels) == 3:\n                faces.append((x, y, x + 1, y + 1, x + 1, y))\n                faces.append((x, y, x, y + 1, x + 1, y + 1))\n            elif len(validNeighborPixels) == 2 and segmentIndex < numPlanes:\n                faces.append((x, y, validNeighborPixels[0][0], validNeighborPixels[0][1], validNeighborPixels[1][0], validNeighborPixels[1][1]))\n                pass\n            continue\n        continue\n    \n    with open(folder + \'/\' + str(index) + \'_model.ply\', \'w\') as f:\n        header = """"""ply\nformat ascii 1.0\ncomment VCGLIB generated\ncomment TextureFile """"""\n        header += imageFilename\n        header += """"""\nelement vertex """"""\n        header += str(width * height)\n        header += """"""\nproperty float x\nproperty float y\nproperty float z\nelement face """"""\n        header += str(len(faces))\n        header += """"""\nproperty list uchar int vertex_indices\nproperty list uchar float texcoord\nend_header\n""""""\n        f.write(header)\n        for y in xrange(height):\n            for x in xrange(width):\n                segmentIndex = segmentation[y][x]\n                if segmentIndex == -1:\n                    f.write(""0.0 0.0 0.0\\n"")\n                    continue\n                point = XYZ[y][x]\n                X = point[0]\n                Y = point[1]\n                Z = point[2]\n                #Y = depth[y][x]\n                #X = Y / focalLength * (x - width / 2) / width * 640\n                #Z = -Y / focalLength * (y - height / 2) / height * 480\n                f.write(str(X) + \' \' +    str(Z) + \' \' + str(-Y) + \'\\n\')\n                continue\n            continue\n\n\n        for face in faces:\n            f.write(\'3 \')\n            for c in xrange(3):\n                f.write(str(face[c * 2 + 1] * width + face[c * 2]) + \' \')\n                continue\n            f.write(\'6 \')                     \n            for c in xrange(3):\n                f.write(str(float(face[c * 2]) / width) + \' \' + str(1 - float(face[c * 2 + 1]) / height) + \' \')\n                continue\n            f.write(\'\\n\')\n            continue\n        f.close()\n        pass\n    return  \n\ndef writePLYFileDepth(folder, index, image, depth, segmentation, planes, info):\n    imageFilename = str(index) + \'_segmentation_pred_blended_0.png\'\n    #cv2.imwrite(folder + \'/\' + imageFilename, image)\n    \n    numPlanes = planes.shape[0]\n\n    camera = getCameraFromInfo(info)\n\n    #camera = getNYURGBDCamera()\n    #camera = getSUNCGCamera()\n\n    urange = (np.arange(width, dtype=np.float32) / width * camera[\'width\'] - camera[\'cx\']) / camera[\'fx\']\n    urange = urange.reshape(1, -1).repeat(height, 0)\n    vrange = (np.arange(height, dtype=np.float32) / height * camera[\'height\'] - camera[\'cy\']) / camera[\'fy\']\n    vrange = vrange.reshape(-1, 1).repeat(width, 1)\n    X = depth * urange\n    Y = depth\n    Z = -depth * vrange\n\n    XYZ = np.stack([X, Y, Z], axis=2).reshape(-1, 3)\n\n    \n    #focalLength = 517.97\n    width = image.shape[1]\n    height = image.shape[0]\n        \n    faces = []\n    minDepthDiff = 0.15\n    maxDepthDiff = 0.3\n    #occlusionBoundary = boundaries[:, :, 1]\n        \n    for y in xrange(height - 1):\n        for x in xrange(width - 1):\n            segmentIndex = segmentation[y][x]\n            if segmentIndex == -1:\n                continue\n            #if segmentIndex == 0:\n            #continue\n            #depths = [depth[y][x], depth[y + 1][x], depth[y + 1][x + 1]]\n            # if segmentIndex >= 0 or (max([occlusionBoundary[y][x], occlusionBoundary[y + 1][x], occlusionBoundary[y + 1][x + 1]]) < 0.5 and (max(depths) - min(depths)) < maxDepthDiff):\n            #     if segmentation[y + 1][x] == segmentIndex and segmentation[y + 1][x + 1] == segmentIndex:\n            #         if min(depths) > 0 and max(depths) < 10:\n            #             faces.append((x, y, x, y + 1, x + 1, y + 1))\n            #             pass\n            #         pass\n            #     elif max(depths) - min(depths) < minDepthDiff:\n            #         faces.append((x, y, x, y + 1, x + 1, y + 1))\n            #         pass\n            #     pass\n\n\n            if segmentation[y + 1][x] == segmentIndex and segmentation[y + 1][x + 1] == segmentIndex and min(depths) > 0 and max(depths) < 10:\n                faces.append((x, y, x, y + 1, x + 1, y + 1))\n                pass\n            \n                \n            depths = [depth[y][x], depth[y][x + 1], depth[y + 1][x + 1]]                        \n            # if segmentIndex > 0 or (max([occlusionBoundary[y][x], occlusionBoundary[y][x + 1], occlusionBoundary[y + 1][x + 1]]) < 0.5 and (max(depths) - min(depths)) < maxDepthDiff):\n            #     if segmentation[y][x + 1] == segmentIndex and segmentation[y + 1][x + 1] == segmentIndex:\n            #         if min(depths) > 0 and max(depths) < 10:\n            #             faces.append((x, y, x + 1, y + 1, x + 1, y))\n            #             pass\n            #         pass\n            #     elif max(depths) - min(depths) < minDepthDiff:\n            #         faces.append((x, y, x + 1, y + 1, x + 1, y))\n            #         pass\n            #     pass\n            if segmentation[y][x + 1] == segmentIndex and segmentation[y + 1][x + 1] == segmentIndex and min(depths) > 0 and max(depths) < 10:\n                faces.append((x, y, x + 1, y + 1, x + 1, y))\n                pass\n            continue\n        continue\n\n    #print(len(faces))\n    print(folder)\n    with open(folder + \'/\' + str(index) + \'_model.ply\', \'w\') as f:\n        header = """"""ply\nformat ascii 1.0\ncomment VCGLIB generated\ncomment TextureFile """"""\n        header += imageFilename\n        header += """"""\nelement vertex """"""\n        header += str(width * height)\n        header += """"""\nproperty float x\nproperty float y\nproperty float z\nelement face """"""\n        header += str(len(faces))\n        header += """"""\nproperty list uchar int vertex_indices\nproperty list uchar float texcoord\nend_header\n""""""\n        f.write(header)\n        for y in xrange(height):\n            for x in xrange(width):\n                segmentIndex = segmentation[y][x]\n                if segmentIndex == -1:\n                    f.write(""0.0 0.0 0.0\\n"")\n                    continue\n                Y = depth[y][x]\n                X = Y / focalLength * (x - width / 2) / width * 640\n                Z = -Y / focalLength * (y - height / 2) / height * 480\n                f.write(str(X) + \' \' +    str(Z) + \' \' + str(-Y) + \'\\n\')\n                continue\n            continue\n\n\n        for face in faces:\n            f.write(\'3 \')\n            for c in xrange(3):\n                f.write(str(face[c * 2 + 1] * width + face[c * 2]) + \' \')\n                continue\n            f.write(\'6 \')                     \n            for c in xrange(3):\n                f.write(str(float(face[c * 2]) / width) + \' \' + str(1 - float(face[c * 2 + 1]) / height) + \' \')\n                continue\n            f.write(\'\\n\')\n            continue\n        f.close()\n        pass\n\treturn  \n\ndef writeHTML(folder, numImages):\n    from html import HTML\n\n    h = HTML(\'html\')\n    h.p(\'Results\')\n    h.br()\n    #suffixes = [\'\', \'_crf_1\']\n    #folders = [\'test_all_resnet_v2\' + suffix + \'/\' for suffix in suffixes]\n    for index in xrange(numImages):\n        t = h.table(border=\'1\')\n        r_inp = t.tr()\n        r_inp.td(\'input\')\n        r_inp.td().img(src=str(index) + \'_image.png\')\n        r_inp.td().img(src=\'one.png\')\n        r_inp.td().img(src=\'one.png\')\n        #r_inp.td().img(src=\'one.png\')\n        r_inp.td().img(src=str(index) + \'_model.png\')\n\n        r_gt = t.tr()\n        r_gt.td(\'gt\')\n        r_gt.td().img(src=str(index) + \'_segmentation_gt.png\')\n        r_gt.td().img(src=str(index) + \'_depth.png\')\n        r_gt.td().img(src=\'one.png\')\n        r_gt.td().img(src=str(index) + \'_normal.png\')\n                \n        #r_gt.td().img(src=folders[0] + str(index) + \'_depth_gt.png\')\n        #r_gt.td().img(src=folders[0] + \'_depth_gt_diff.png\')\n        #r_gt.td().img(src=folders[0] + str(index) + \'_normal_gt.png\')\n\n        r_pred = t.tr()\n        r_pred.td(\'pred\')\n        r_pred.td().img(src=str(index) + \'_segmentation_pred.png\')\n        r_pred.td().img(src=str(index) + \'_depth_pred.png\')\n        r_pred.td().img(src=str(index) + \'_depth_pred_diff.png\')\n        r_pred.td().img(src=str(index) + \'_normal_pred.png\')\n\n        h.br()\n        continue\n\n    html_file = open(folder + \'/index.html\', \'w\')\n    html_file.write(str(h))\n    html_file.close()\n    return\n\n\ndef writeHTMLRGBD(filename, numImages=10):\n    from html import HTML\n\n    #0.227 0.194 0.163 0.157 0.100\n    #0.196 0.150 0.143 0.488 0.082\n    h = HTML(\'html\')\n    h.p(\'Results\')\n    h.br()\n    path = \'\'\n    folders = [\'pred\', \'local_02\', \'local_05\', \'local_07\', \'local_10\', \'local_12\']\n    second_folders = [\'pred_local_02\', \'pred_local_05\', \'pred_local_07\', \'pred_local_10\', \'pred_local_12\']\n    for index in xrange(numImages):\n        firstFolder = path + folders[0]\n        t = h.table(border=\'1\')\n        r_inp = t.tr()\n        r_inp.td(\'input\')\n        r_inp.td().img(src=firstFolder + \'/\' + str(index) + \'_image.png\')\n        r_inp.td().img(src=firstFolder + \'/\' + str(index) + \'_depth.png\')\n\n        r = t.tr()\n        r.td(\'PlaneNet prediction\')\n        r.td().img(src=firstFolder + \'/\' + str(index) + \'_segmentation_pred.png\')\n        r.td().img(src=firstFolder + \'/\' + str(index) + \'_depth_pred.png\')\n\n        r = t.tr()\n        r.td(\'segmentation\')\n        for folder in folders[1:6]:\n            r.td().img(src=folder + \'/\' + str(index) + \'_segmentation_pred.png\')\n            continue\n\n        r = t.tr()\n        r.td(\'depth\')\n        for folder in folders[1:6]:\n            folder = path + folder\n            r.td().img(src=folder + \'/\' + str(index) + \'_depth_pred.png\')\n            continue\n\n        r = t.tr()\n        r.td(\'pixelwise prediction\')\n        r.td().img(src=path + second_folders[0] + \'/\' + str(index) + \'_depth.png\')\n\n        r = t.tr()\n        r.td(\'segmentation\')\n        for folder in second_folders[0:5]:\n            r.td().img(src=folder + \'/\' + str(index) + \'_segmentation_pred.png\')\n            continue\n\n        r = t.tr()\n        r.td(\'depth\')\n        for folder in second_folders[0:5]:\n            folder = path + folder\n            r.td().img(src=folder + \'/\' + str(index) + \'_depth_pred.png\')\n            continue\n        \n        h.br()\n        continue\n\n    html_file = open(filename, \'w\')\n    html_file.write(str(h))\n    html_file.close()\n    return\n\ndef writeHTMLPlane(filename, numImages=10):\n    from html import HTML\n\n    #0.227 0.194 0.163 0.157 0.100\n    #0.196 0.150 0.143 0.488 0.082\n    h = HTML(\'html\')\n    h.p(\'Results\')\n    h.br()\n    path = \'\'\n    folders = [\'PlaneNet_hybrid\', \'PlaneNet\', \'GT_RANSAC\', \'pixelwise_RANSAC\']\n    for index in xrange(numImages):\n        firstFolder = path + folders[0]\n        t = h.table(border=\'1\')\n        r_inp = t.tr()\n        r_inp.td(\'input\')\n        r_inp.td().img(src=firstFolder + \'/\' + str(index) + \'_image.png\')\n        r_inp.td().img(src=firstFolder + \'/\' + str(index) + \'_depth.png\')\n\n        # r = t.tr()\n        # r.td(\'PlaneNet prediction\')\n        # r.td().img(src=firstFolder + \'/\' + str(index) + \'_segmentation_pred.png\')\n        # r.td().img(src=firstFolder + \'/\' + str(index) + \'_depth_pred.png\')\n\n        r = t.tr()\n        r.td(\'segmentation\')\n        for folder in folders[0:6]:\n            r.td().img(src=folder + \'/\' + str(index) + \'_segmentation_pred.png\')\n            continue\n\n        r = t.tr()\n        r.td(\'depth\')\n        for folder in folders[0:6]:\n            folder = path + folder\n            r.td().img(src=folder + \'/\' + str(index) + \'_depth_pred.png\')\n            continue\n        \n        h.br()\n        continue\n\n    html_file = open(filename, \'w\')\n    html_file.write(str(h))\n    html_file.close()\n    return\n\ndef getNYURGBDCamera():\n    camera = {}\n    camera[\'fx\'] = 5.1885790117450188e+02\n    camera[\'fy\'] = 5.1946961112127485e+02\n    camera[\'cx\'] = 3.2558244941119034e+02 - 40\n    camera[\'cy\'] = 2.5373616633400465e+02 - 44\n    camera[\'width\'] = 561\n    camera[\'height\'] = 427\n    camera[\'depth_shift\'] = 1000    \n    return camera\n\ndef getSUNCGCamera():\n    camera = {}\n    camera[\'fx\'] = 517.97\n    camera[\'fy\'] = 517.97\n    camera[\'cx\'] = 320\n    camera[\'cy\'] = 240\n    camera[\'width\'] = 640\n    camera[\'height\'] = 480\n    camera[\'depth_shift\'] = 1000    \n    return camera\n\ndef get3DCamera():\n    camera = {}\n    camera[\'fx\'] = 1075\n    camera[\'fy\'] = 1075\n    camera[\'cx\'] = 637\n    camera[\'cy\'] = 508\n    camera[\'width\'] = 1280\n    camera[\'height\'] = 1024\n    camera[\'depth_shift\'] = 4000    \n    return camera\n\ndef getCameraFromInfo(info):\n    camera = {}\n    camera[\'fx\'] = info[0]\n    camera[\'fy\'] = info[5]\n    camera[\'cx\'] = info[2]\n    camera[\'cy\'] = info[6]\n    camera[\'width\'] = info[16]\n    camera[\'height\'] = info[17]\n    camera[\'depth_shift\'] = info[18]    \n    return camera\n\ndef fitPlane(points):\n    if points.shape[0] == points.shape[1]:\n        return np.linalg.solve(points, np.ones(points.shape[0]))\n    else:\n        return np.linalg.lstsq(points, np.ones(points.shape[0]))[0]\n\ndef fitPlanes(depth, info, numPlanes=50, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=-1):\n    camera = getCameraFromInfo(info)\n    width = depth.shape[1]\n    height = depth.shape[0]\n\n    #camera = getNYURGBDCamera()\n    #camera = getSUNCGCamera()\n\n    urange = (np.arange(width, dtype=np.float32) / width * camera[\'width\'] - camera[\'cx\']) / camera[\'fx\']\n    urange = urange.reshape(1, -1).repeat(height, 0)\n    vrange = (np.arange(height, dtype=np.float32) / height * camera[\'height\'] - camera[\'cy\']) / camera[\'fy\']\n    vrange = vrange.reshape(-1, 1).repeat(width, 1)\n    X = depth * urange\n    Y = depth\n    Z = -depth * vrange\n\n    # print(depth[:10, :10])\n    # print(X[:10, :10])\n    # print(Z[:10, :10])\n    # print(urange[:10, :10])\n    # print(vrange[:10, :10])\n    # exit(1)\n    XYZ = np.stack([X, Y, Z], axis=2).reshape(-1, 3)\n    XYZ = XYZ[depth.reshape(-1) != 0]\n    planes = []\n    planePointsArray = []\n    for planeIndex in xrange(numPlanes):\n        maxNumInliers = planeAreaThreshold\n        for iteration in xrange(numIterations):\n            if local > 0:\n                sampledPoint = XYZ[np.random.randint(XYZ.shape[0], size=(1))]\n                sampledPoints = XYZ[np.linalg.norm(XYZ - sampledPoint, 2, 1) < local]\n                if sampledPoints.shape[0] < 3:\n                    continue\n                elif sampledPoints.shape[0] > 3:\n                    sampledPoints = sampledPoints[np.random.choice(np.arange(sampledPoints.shape[0]), size=(3))]\n                    pass\n            else:\n                sampledPoints = XYZ[np.random.choice(np.arange(XYZ.shape[0]), size=(3))]\n                pass\n            \n            try:\n                plane = fitPlane(sampledPoints)\n                pass\n            except:\n                continue\n            diff = np.abs(np.matmul(XYZ, plane) - np.ones(XYZ.shape[0])) / np.linalg.norm(plane)\n            numInliers = np.sum(diff < distanceThreshold)\n            if numInliers > maxNumInliers:\n                maxNumInliers = numInliers\n                bestPlane = plane\n                pass\n            continue\n        if maxNumInliers == planeAreaThreshold:\n            break\n        planes.append(bestPlane)\n\n        diff = np.abs(np.matmul(XYZ, bestPlane) - np.ones(XYZ.shape[0])) / np.linalg.norm(bestPlane)\n        inlierIndices = diff < distanceThreshold\n        inliersPoints = XYZ[inlierIndices]\n        planePointsArray.append(inliersPoints)\n        XYZ = XYZ[np.logical_not(inlierIndices)]\n        if XYZ.shape[0] < planeAreaThreshold:\n            break\n        continue\n\n    planes = np.array(planes)\n    if len(planes.shape) == 0:\n        planes = np.zeros((numPlanes, 3))\n        pass\n    if len(planes.shape) == 1:\n        if planes.shape[0] == 3:\n            planes = np.expand_dims(planes, 0)\n        else:\n            planes = np.zeros((numPlanes, 3))\n            pass\n        pass\n    \n    planeSegmentation = np.ones(depth.shape) * numPlanes\n    for planeIndex, planePoints in enumerate(planePointsArray):\n        planeDepth = planePoints[:, 1]\n        u = np.round((planePoints[:, 0] / planeDepth * camera[\'fx\'] + camera[\'cx\']) / camera[\'width\'] * width).astype(np.int32)\n        v = np.round((-planePoints[:, 2] / planeDepth * camera[\'fy\'] + camera[\'cy\']) / camera[\'height\'] * height).astype(np.int32)\n        planeSegmentation[v, u] = planeIndex\n        continue\n\n\n    planesD = 1 / np.linalg.norm(planes, 2, axis=1, keepdims=True)\n    planes *= pow(planesD, 2)\n\n    if planes.shape[0] < numPlanes:\n        #print(planes.shape)\n        planes = np.concatenate([planes, np.zeros((numPlanes - planes.shape[0], 3))], axis=0)\n        pass\n\n    planeDepths = calcPlaneDepths(planes, width, height, info)\n    \n    allDepths = np.concatenate([planeDepths, np.zeros((height, width, 1))], axis=2)\n    depthPred = allDepths.reshape(-1, numPlanes + 1)[np.arange(width * height), planeSegmentation.astype(np.int32).reshape(-1)].reshape(height, width)\n\n    return planes, planeSegmentation, depthPred\n\n\ndef fitPlanesSegmentation(depth, segmentation, info, numPlanes=50, numPlanesPerSegment=3, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=-1):\n    \n    camera = getCameraFromInfo(info)\n    width = depth.shape[1]\n    height = depth.shape[0]\n\n    urange = (np.arange(width, dtype=np.float32) / width * camera[\'width\'] - camera[\'cx\']) / camera[\'fx\']\n    urange = urange.reshape(1, -1).repeat(height, 0)\n    vrange = (np.arange(height, dtype=np.float32) / height * camera[\'height\'] - camera[\'cy\']) / camera[\'fy\']\n    vrange = vrange.reshape(-1, 1).repeat(width, 1)\n    X = depth * urange\n    Y = depth\n    Z = -depth * vrange\n\n    allXYZ = np.stack([X, Y, Z], axis=2).reshape(-1, 3)\n\n    planes = []\n    planePointIndices = []\n\n    for segmentIndex in xrange(segmentation.max()):\n        segmentMask = np.logical_and(segmentation == segmentIndex, depth != 0)\n        XYZ = allXYZ[segmentMask.reshape(-1)]\n        if XYZ.shape[0] < planeAreaThreshold:\n            continue\n        for planeIndex in xrange(numPlanesPerSegment):\n            maxNumInliers = planeAreaThreshold\n            for iteration in xrange(numIterations):\n                if local > 0:\n                    sampledPoint = XYZ[np.random.randint(XYZ.shape[0], size=(1))]\n                    sampledPoints = XYZ[np.linalg.norm(XYZ - sampledPoint, 2, 1) < local]\n\n                    if sampledPoints.shape[0] < 3:\n                        continue\n                    elif sampledPoints.shape[0] > 3:\n                        sampledPoints = sampledPoints[np.random.choice(np.arange(sampledPoints.shape[0]), size=(3))]\n                        pass\n                else:\n                    sampledPoints = XYZ[np.random.choice(np.arange(XYZ.shape[0]), size=(3))]\n                    pass\n                \n                try:\n                    plane = fitPlane(sampledPoints)\n                    pass\n                except:\n                    continue\n                diff = np.abs(np.matmul(XYZ, plane) - np.ones(XYZ.shape[0])) / np.linalg.norm(plane)\n                numInliers = np.sum(diff < distanceThreshold)\n                if numInliers > maxNumInliers:\n                    maxNumInliers = numInliers\n                    bestPlane = plane\n                    pass\n                continue\n            if maxNumInliers == planeAreaThreshold:\n                break\n            planes.append(bestPlane)\n\n            diff = np.abs(np.matmul(XYZ, bestPlane) - np.ones(XYZ.shape[0])) / np.linalg.norm(bestPlane)\n            inlierIndices = diff < distanceThreshold\n            inliersPoints = XYZ[inlierIndices]\n            planePointIndices.append(inliersPoints)\n            XYZ = XYZ[np.logical_not(inlierIndices)]\n            if XYZ.shape[0] < planeAreaThreshold:\n                break\n            continue\n        continue\n\n    if len(planes) > numPlanes:\n        planeList = zip(planes, planePointIndices)\n        planeList = sorted(planeList, key=lambda x:-len(x[1]))\n        planeList = planeList[:numPlanes]\n        planes, planePointIndices = zip(*planeList)\n        pass\n\n    \n    \n    planeSegmentation = np.ones(depth.shape) * numPlanes\n    for planeIndex, planePoints in enumerate(planePointIndices):\n        planeDepth = planePoints[:, 1]\n        u = np.round((planePoints[:, 0] / planeDepth * camera[\'fx\'] + camera[\'cx\']) / camera[\'width\'] * width).astype(np.int32)\n        v = np.round((-planePoints[:, 2] / planeDepth * camera[\'fy\'] + camera[\'cy\']) / camera[\'height\'] * height).astype(np.int32)\n        planeSegmentation[v, u] = planeIndex\n        continue\n\n    planes = np.array(planes)    \n    planesD = 1 / np.linalg.norm(planes, 2, 1, keepdims=True)\n    planes *= pow(planesD, 2)\n    if planes.shape[0] < numPlanes:\n        planes = np.concatenate([planes, np.zeros((numPlanes - planes.shape[0], 3))], axis=0)\n        pass\n\n    planeDepths = calcPlaneDepths(planes, width, height, info)\n\n    \n    allDepths = np.concatenate([planeDepths, np.zeros((height, width, 1))], axis=2)\n    depthPred = allDepths.reshape([height * width, numPlanes + 1])[np.arange(width * height), planeSegmentation.astype(np.int32).reshape(-1)].reshape(height, width)\n\n    return planes, planeSegmentation, depthPred\n\n\ndef fitPlanesNYU(image, depth, normal, semantics, info, numOutputPlanes=20, local=-1, parameters={}):\n    camera = getCameraFromInfo(info)\n    width = depth.shape[1]\n    height = depth.shape[0]\n\n    #camera = getNYURGBDCamera()\n    #camera = getSUNCGCamera()\n\n    urange = (np.arange(width, dtype=np.float32) / width * camera[\'width\'] - camera[\'cx\']) / camera[\'fx\']\n    urange = urange.reshape(1, -1).repeat(height, 0)\n    vrange = (np.arange(height, dtype=np.float32) / height * camera[\'height\'] - camera[\'cy\']) / camera[\'fy\']\n    vrange = vrange.reshape(-1, 1).repeat(width, 1)\n    X = depth * urange\n    Y = depth\n    Z = -depth * vrange\n\n    # print(depth[:10, :10])\n    # print(X[:10, :10])\n    # print(Z[:10, :10])\n    # print(urange[:10, :10])\n    # print(vrange[:10, :10])\n    # exit(1)\n    XYZ = np.stack([X, Y, Z], axis=2).reshape(-1, 3)\n    #XYZ = XYZ[depth.reshape(-1) != 0]\n    planes = []\n    planeMasks = []\n    invalidDepthMask = depth < 1e-4\n\n    if \'planeAreaThreshold\' in parameters:\n        planeAreaThreshold = parameters[\'planeAreaThreshold\']\n    else:\n        planeAreaThreshold = 500\n        pass\n    if \'distanceThreshold\' in parameters:\n        distanceThreshold = parameters[\'distanceThreshold\']\n    else:\n        distanceThreshold = 0.05\n        pass\n    if \'local\' in parameters:\n        local = parameters[\'local\']\n    else:\n        local = 0.2\n        pass\n    \n    for y in xrange(5, height, 10):\n        for x in xrange(5, width, 10):\n            if invalidDepthMask[y][x]:\n                continue\n            sampledPoint = XYZ[y * width + x]\n            sampledPoints = XYZ[np.linalg.norm(XYZ - sampledPoint, 2, 1) < local]\n            if sampledPoints.shape[0] < 3:\n                continue\n            sampledPoints = sampledPoints[np.random.choice(np.arange(sampledPoints.shape[0]), size=(3))]\n            try:\n                plane = fitPlane(sampledPoints)\n                pass\n            except:\n                continue\n            \n            diff = np.abs(np.matmul(XYZ, plane) - np.ones(XYZ.shape[0])) / np.linalg.norm(plane)\n            inlierIndices = diff < distanceThreshold\n            #print(np.sum(inlierIndices), planeAreaThreshold)\n            if np.sum(inlierIndices) < planeAreaThreshold:\n                continue\n            \n            planes.append(plane)\n            planeMasks.append(inlierIndices.reshape((height, width)))\n            continue\n        continue\n    \n    planes = np.array(planes)\n\n    planeList = zip(planes, planeMasks)\n    planeList = sorted(planeList, key=lambda x:-x[1].sum())\n    planes, planeMasks = zip(*planeList)\n\n    \n    invalidMask = np.zeros((height, width), np.bool)\n    validPlanes = []\n    validPlaneMasks = []\n    \n    for planeIndex, plane in enumerate(planes):\n        planeMask = planeMasks[planeIndex]\n        if np.logical_and(planeMask, invalidMask).sum() > planeMask.sum() * 0.5:\n            continue\n        # if len(validPlanes) > 0:\n        #     cv2.imwrite(\'test/mask_\' + str(len(validPlanes) - 1) + \'_available.png\', drawMaskImage(1 - invalidMask))\n        #     pass\n        validPlanes.append(plane)\n        validPlaneMasks.append(planeMask)\n        invalidMask = np.logical_or(invalidMask, planeMask)\n        continue\n    planes = np.array(validPlanes)\n    planesD = 1 / np.maximum(np.linalg.norm(planes, 2, 1, keepdims=True), 1e-4)\n    planes *= pow(planesD, 2)\n    \n    planeMasks = np.stack(validPlaneMasks, axis=2)\n    \n    cv2.imwrite(\'test/depth.png\', drawDepthImage(depth))\n    for planeIndex in xrange(planes.shape[0]):\n        cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(planeMasks[:, :, planeIndex]))\n        continue\n\n    print(\'number of planes: \' + str(planes.shape[0]))\n    \n    planeSegmentation = getSegmentationsGraphCut(planes, image, depth, normal, semantics, info, parameters=parameters)\n\n    cv2.imwrite(\'test/segmentation_refined.png\', drawSegmentationImage(planeSegmentation, blackIndex=planes.shape[0]))\n    \n    #planeSegmentation[planes.shape[0]] = numOutputPlanes\n\n    \n    return planes, planeSegmentation\n\n\ndef limitPlaneNumber(planes, planeSegmentation, numOutputPlanes):\n    if planes.shape[0] > numOutputPlanes:\n        planeInfo = []\n        for planeIndex in xrange(planes.shape[0]):\n            mask = planeSegmentation == planeIndex\n            planeInfo.append((planes[planeIndex], mask))\n            continue\n        planeInfo = sorted(planeInfo, key=lambda x: -x[1].sum())\n        newPlanes = []\n        newPlaneSegmentation = np.full(planeSegmentation.shape, numOutputPlanes)\n        for planeIndex in xrange(numOutputPlanes):\n            newPlanes.append(planeInfo[planeIndex][0])\n            newPlaneSegmentation[planeInfo[planeIndex][1]] = planeIndex\n            continue\n        newPlanes = np.array(newPlanes)\n        return newPlanes, newPlaneSegmentation\n    else:\n        planeSegmentation[planeSegmentation == planes.shape[0]] = numOutputPlanes\n        planes = np.concatenate([planes, np.zeros((numOutputPlanes - planes.shape[0], 3))], axis=0)\n        return planes, planeSegmentation\n    return\n\ndef removeSmallPlanes(planes, planeSegmentation, planeAreaThreshold):\n    planeInfo = []\n    for planeIndex in xrange(planes.shape[0]):\n        mask = planeSegmentation == planeIndex\n        planeInfo.append((planes[planeIndex], mask, mask.sum()))\n        continue\n    planeInfo = sorted(planeInfo, key=lambda x: -x[2])\n    newPlanes = []\n    newPlaneSegmentation = np.full(planeSegmentation.shape, numOutputPlanes)\n    for planeIndex, info in enumerate(planeInfo):\n        if info[2] < planeAreaThreshold:\n            break\n        newPlanes.append(info[0])\n        newPlaneSegmentation[info[1]] = planeIndex\n        continue\n    newPlanes = np.array(newPlanes)\n    return newPlanes, newPlaneSegmentation\n\ndef calcDepthFromPlanes(planes, planeSegmentation, info, nonPlaneInfo = {}):\n    width = planeSegmentation.shape[1]\n    height = planeSegmentation.shape[0]    \n    planeDepths = calcPlaneDepths(planes, width, height, info)\n\n    if \'depth\' in nonPlaneInfo:\n        allDepths = np.concatenate([planeDepths, np.expand_dims(nonPlaneInfo[\'depth\'], -1)], axis=2)\n    else:\n        allDepths = planeDepths\n        pass\n    \n    depthPred = allDepths.reshape([height * width, -1])[np.arange(width * height), planeSegmentation.astype(np.int32).reshape(-1)].reshape(height, width)\n    return depthPred\n\ndef calcNormalFromPlanes(planes, planeSegmentation, info, nonPlaneInfo = {}):\n    width = planeSegmentation.shape[1]\n    height = planeSegmentation.shape[0]        \n    planeNormals = calcPlaneNormals(planes, width, height)\n    \n    if \'normal\' in nonPlaneInfo:\n        allNormals = np.concatenate([planeNormals, np.expand_dims(nonPlaneInfo[\'normal\'], 2), ], axis=2)\n    else:\n        allNormals = planeNormals\n        pass\n    normalPred = allNormals.reshape(width * height, -1, 3)[np.arange(width * height), planeSegmentation.reshape(-1)].reshape((height, width, 3))\n    return normalPred\n\n\n\ndef fitPlanesPoints(points, segmentation, groupSegments, numPlanes=50, numPlanesPerSegment=3, numPlanesPerGroup=8, segmentRatio=0.1, planeAreaThreshold=100, numIterations=100, distanceThreshold=0.05, local=-1):\n    allXYZ = points.reshape(-1, 3)\n\n    \n    # planeDiffThreshold = distanceThreshold    \n    # planes = np.load(\'test/planes.pny.npy\')\n    # planePointIndices = np.load(\'test/plane_indices.pny.npy\')\n    # planeIndex_1 = 1\n    # planeIndex_2 = 2\n    # for planeIndex_1 in [1, ]:\n    #     for planeIndex_2 in [2, 5, 7, 10]:\n    #         plane_1 = planes[planeIndex_1]\n    #         plane_2 = planes[planeIndex_2]\n    #         points_1 = allXYZ[planePointIndices[planeIndex_1]]\n    #         points_2 = allXYZ[planePointIndices[planeIndex_2]]\n\n    #         diff_1 = np.abs(np.matmul(points_2, plane_1) - np.ones(points_2.shape[0])) / np.linalg.norm(plane_1)\n    #         diff_2 = np.abs(np.matmul(points_1, plane_2) - np.ones(points_1.shape[0])) / np.linalg.norm(plane_2)\n    #         print(np.sum(diff_1 < planeDiffThreshold), diff_1.shape[0])\n    #         print(np.sum(diff_2 < planeDiffThreshold), diff_2.shape[0])\n    #         print((diff_1.mean(), diff_2.mean()))\n    #         # if np.sum(diff_1 < planeDiffThreshold) > diff_1.shape[0] * inlierThreshold or np.sum(diff_2 < planeDiffThreshold) > diff_2.shape[0] * inlierThreshold:\n    #         #     planesDiff[planeIndex][otherPlaneIndex] = 1\n    #         #     planesDiff[otherPlaneIndex][planeIndex] = 1\n    #         #     pass\n\n            \n    #         # if min(diff_1.mean(), diff_2.mean()) < planeDiffThreshold:\n    #         #     planesDiff[planeIndex][otherPlaneIndex] = 1\n    #         #     planesDiff[otherPlaneIndex][planeIndex] = 1\n    #         #     pass\n            \n    #         continue\n    #     continue\n    \n    # print(planes / np.linalg.norm(planes, axis=1, keepdims=True))\n    # exit(1)\n    \n    planes = []\n    planePointIndices = []\n    groupNumPlanes = []\n    for groupIndex, group in enumerate(groupSegments):\n        groupPlanes = []\n        groupPlanePointIndices = []\n        for segmentIndex in group:\n            segmentMask = segmentation == segmentIndex\n            # planes.append(np.ones(3))\n            # planePointIndices.append(segmentMask.nonzero()[0])\n            # continue\n\n            XYZ = allXYZ[segmentMask.reshape(-1)]\n            numPoints = XYZ.shape[0]\n\n            if numPoints <= planeAreaThreshold:\n                if numPoints > 0:\n                    groupPlanes.append(np.random.random(3))\n                    groupPlanePointIndices.append(segmentMask.nonzero()[0])\n                    pass\n                continue\n\n            for planeIndex in xrange(numPlanesPerSegment):\n                maxNumInliers = 0\n                for iteration in xrange(numIterations):\n                    if local > 0:\n                        sampledPoint = XYZ[np.random.randint(XYZ.shape[0], size=(1))]\n                        sampledPoints = XYZ[np.linalg.norm(XYZ - sampledPoint, axis=1) < local]\n\n                        if sampledPoints.shape[0] < 3:\n                            continue\n                        elif sampledPoints.shape[0] > 3:\n                            sampledPoints = sampledPoints[np.random.choice(np.arange(sampledPoints.shape[0]), size=(3))]\n                            pass\n                        pass\n                    else:\n                        sampledPoints = XYZ[np.random.choice(np.arange(XYZ.shape[0]), size=(3))]\n                        pass\n                \n                    try:\n                        plane = fitPlane(sampledPoints)\n                        pass\n                    except:\n                        continue\n                    diff = np.abs(np.matmul(XYZ, plane) - np.ones(XYZ.shape[0])) / np.linalg.norm(plane)\n                    numInliers = np.sum(diff < distanceThreshold)\n                    if numInliers > maxNumInliers:\n                        maxNumInliers = numInliers\n                        bestPlane = plane\n                        pass\n                    continue\n\n                groupPlanes.append(bestPlane)\n            \n                diff = np.abs(np.matmul(XYZ, bestPlane) - np.ones(XYZ.shape[0])) / np.linalg.norm(bestPlane)\n                inlierIndices = diff < distanceThreshold\n                if inlierIndices.sum() > numPoints * (1 - segmentRatio):\n                    inlierIndices = np.ones(diff.shape, dtype=np.bool)\n                    pass\n                pointIndices = segmentMask.nonzero()[0][inlierIndices]\n                groupPlanePointIndices.append(pointIndices)\n                segmentMask[pointIndices] = 0\n                \n                XYZ = XYZ[np.logical_not(inlierIndices)]\n                if XYZ.shape[0] <= planeAreaThreshold:\n                    if XYZ.shape[0] > 0:\n                        groupPlanes.append(np.random.random(3))\n                        groupPlanePointIndices.append(segmentMask.nonzero()[0])\n                        pass\n                    break\n                continue\n            continue\n        if len(groupPlanes) == 0:\n            continue\n        \n        # planeList = zip(groupPlanes, groupPlanePointIndices)\n        # planeList = sorted(planeList, key=lambda x:-len(x[1]))\n        # groupPlanes, groupPlanePointIndices = zip(*planeList)\n\n        # groupMask = np.zeros(segmentation.shape, np.bool)\n        # for segmentIndex in group:\n        #     groupMask = np.logical_or(groupMask, segmentation == segmentIndex)\n        #     continue\n\n        # groupPlanePointIndices = []\n        # for plane in groupPlanes:\n        #     groupPoints = allXYZ[groupMask]\n        #     diff = np.abs(np.matmul(groupPoints, plane) - np.ones(groupPoints.shape[0])) / np.linalg.norm(plane)\n        #     inlierIndices = diff < distanceThreshold\n        #     pointIndices = groupMask.nonzero()[0][inlierIndices]\n        #     groupPlanePointIndices.append(pointIndices)\n        #     groupMask[pointIndices] = 0\n        #     continue\n\n        # if len(groupPlanes) > numPlanesPerGroup:\n        #     planeList = zip(groupPlanes, groupPlanePointIndices)\n        #     planeList = sorted(planeList, key=lambda x:-len(x[1]))\n        #     planeList = planeList[:numPlanesPerGroup]\n        #     groupPlanes, groupPlanePointIndices = zip(*planeList)\n        #     pass\n\n        \n        numPointsOri = 0\n        for indices in groupPlanePointIndices:\n            numPointsOri += len(indices)\n            continue\n        \n        groupPlanes, groupPlanePointIndices = mergePlanes(points, groupPlanes, groupPlanePointIndices, planeDiffThreshold=distanceThreshold, planeAreaThreshold=planeAreaThreshold)\n        if len(groupPlanes) > 1:\n            groupPlanes, groupPlanePointIndices = mergePlanes(points, groupPlanes, groupPlanePointIndices, planeDiffThreshold=distanceThreshold, planeAreaThreshold=planeAreaThreshold)\n            pass\n        #groupPlanes, groupPlanePointIndices = mergePlanes(points, groupPlanes, groupPlanePointIndices, planeDiffThreshold=distanceThreshold)\n        \n        # if groupIndex == 14:\n        #     groupPlanes, groupPlanePointIndices = mergePlanes(points, groupPlanes, groupPlanePointIndices, planeDiffThreshold=distanceThreshold)\n        #     planesTest = np.array(groupPlanes)\n        #     np.save(\'test/planes.npy\', planesTest)\n        #     np.save(\'test/plane_indices.npy\', groupPlanePointIndices)\n        #     print(planesTest / np.linalg.norm(planesTest, axis=1, keepdims=True))\n        #     #exit(1)\n        #     pass\n\n        numPoints = 0\n        for indices in groupPlanePointIndices:\n            numPoints += len(indices)\n            continue\n        planes += groupPlanes\n        planePointIndices += groupPlanePointIndices\n        groupNumPlanes.append(len(groupPlanes))\n        #planeSegmentation[groupPlaneSegmentation >= 0] = groupPlaneSegmentation[groupPlaneSegmentation >= 0] + numPlanes\n        continue\n\n    #planes = np.concatenate(planes, axis=0)\n\n    # if len(planes) > numPlanes:\n    #     planeList = zip(planes, planePointsArray)\n    #     planeList = sorted(planeList, key=lambda x:-len(x[1]))\n    #     planeList = planeList[:numPlanes]\n    #     planes, planePointsArray = zip(*planeList)\n    #     pass\n\n\n    # if len(planes) > numPlanes:\n    #     planeList = zip(planes, planePointIndices)\n    #     planeList = sorted(planeList, key=lambda x:-len(x[1]))\n    #     planeList = planeList[:numPlanes]\n    #     planes, planePointIndices = zip(*planeList)\n    #     pass\n\n\n    if len(planes) == 0:\n        return np.array([]), np.ones(segmentation.shape).astype(np.int32) * (-1), []\n    \n    planes = np.array(planes)\n    print(\'number of planes: \' + str(planes.shape[0]))\n\n    # print(planes)\n    # for v in planePointsArray:\n    #     print(len(v))\n    # if planes.shape[0] < numPlanes:\n    #     planes = np.concatenate([planes, np.zeros((numPlanes - planes.shape[0], 3))], axis=0)\n    #     pass\n    \n    \n    planeSegmentation = np.ones(segmentation.shape) * (-1)\n    for planeIndex, planePoints in enumerate(planePointIndices):\n        planeSegmentation[planePoints] = planeIndex\n        continue\n\n    planesD = 1 / np.linalg.norm(planes, 2, 1, keepdims=True)\n    planes *= pow(planesD, 2)\n\n    return planes, planeSegmentation, groupNumPlanes\n\ndef mergePlanes3D(points, planes, planePointIndices, planeDiffThreshold = 0.05, planeAngleThreshold = 30, inlierThreshold = 0.9, planeAreaThreshold = 100):\n\n    # planesD = np.linalg.norm(planes, axis=1, keepdims=True)\n    # planes = planes / pow(planesD, 2)\n    # planesDiff = (np.linalg.norm(np.expand_dims(planes, 1) - np.expand_dims(planes, 0), axis=2) < planeDiffThreshold).astype(np.int32)\n\n    planeList = zip(planes, planePointIndices)\n    planeList = sorted(planeList, key=lambda x:-len(x[1]))\n    planes, planePointIndices = zip(*planeList)\n\n    groupedPlanes = []\n    groupedPlanePointIndices = []\n    \n    numPlanes = len(planes)\n    usedPlaneConfidence = np.ones(numPlanes, np.float32) * (-1)\n    usedPlaneMap = np.ones(numPlanes, np.int32) * (-1)\n    \n    for planeIndex, plane in enumerate(planes):\n        if usedPlaneConfidence[planeIndex] > 0:\n            continue\n        usedPlaneConfidence[planeIndex] = 1\n        usedPlaneMap[planeIndex] = planeIndex\n        XYZ = points[planePointIndices[planeIndex]]\n        for otherPlaneIndex in xrange(planeIndex + 1, numPlanes):\n            #if planeIndex not in [0, 1, 2, ]:\n            #break\n            #if usedPlanes[otherPlaneIndex]:\n            #continue\n            #otherPlane = planes[otherPlaneIndex]\n            #if np.abs(np.dot(plane, otherPlane)) / (np.linalg.norm(plane) * np.linalg.norm(otherPlane)) < np.cos(np.deg2rad(planeAngleThreshold)):\n            #continue\n\n            otherXYZ = points[planePointIndices[otherPlaneIndex]]\n\n            diff_1 = np.abs(np.matmul(otherXYZ, plane) - np.ones(otherXYZ.shape[0])) / np.linalg.norm(plane)\n            #diff_2 = np.abs(np.matmul(XYZ, otherPlane) - np.ones(XYZ.shape[0])) / np.linalg.norm(otherPlane)\n            ratio = float(np.sum(diff_1 < planeDiffThreshold)) / diff_1.shape[0]\n            if ratio > max(inlierThreshold, usedPlaneConfidence[otherPlaneIndex]):\n                usedPlaneConfidence[otherPlaneIndex] = ratio\n                usedPlaneMap[otherPlaneIndex] = planeIndex\n                pass\n            continue\n        continue\n\n    for planeIndex in xrange(numPlanes):\n        mergedPlanes = (usedPlaneMap == planeIndex).nonzero()[0].tolist()\n        if len(mergedPlanes) == 0:\n            continue\n        pointIndices = []\n        for mergedPlaneIndex in mergedPlanes:\n            pointIndices += planePointIndices[mergedPlaneIndex].tolist()\n            continue\n        if len(pointIndices) <= planeAreaThreshold:\n            continue\n        XYZ = points[pointIndices]\n        ranges = XYZ.max(0) - XYZ.min(0)\n        ranges.sort()\n        #print((planeIndex, ranges.tolist() + XYZ.mean(0).tolist()))\n        if ranges[1] < 0.2:\n            continue\n        #continue\n        #print(XYZ.shape[0])\n        #print(ranges)\n        #if ranges.max() * 5 >= XYZ.shape[0]:\n        #continue\n        plane = fitPlane(XYZ)\n        groupedPlanes.append(plane)\n        groupedPlanePointIndices.append(np.array(pointIndices))\n        continue\n    \n    return groupedPlanes, groupedPlanePointIndices\n\ndef mergePlanesBackup(points, planes, planePointIndices, planeDiffThreshold = 0.05, planeAngleThreshold = 30, inlierThreshold = 0.8):\n\n    # planesD = np.linalg.norm(planes, axis=1, keepdims=True)\n    # planes = planes / pow(planesD, 2)\n    # planesDiff = (np.linalg.norm(np.expand_dims(planes, 1) - np.expand_dims(planes, 0), axis=2) < planeDiffThreshold).astype(np.int32)\n    numPlanes = len(planes)\n    planesDiff = np.diag(np.ones(numPlanes))\n    for planeIndex, plane in enumerate(planes):\n        for otherPlaneIndex in xrange(planeIndex + 1, numPlanes):\n            otherPlane = planes[otherPlaneIndex]\n            if np.abs(np.dot(plane, otherPlane)) / (np.linalg.norm(plane) * np.linalg.norm(otherPlane)) < np.cos(np.deg2rad(planeAngleThreshold)):\n                continue\n            XYZ = points[planePointIndices[planeIndex]]\n            otherXYZ = points[planePointIndices[otherPlaneIndex]]\n            diff_1 = np.abs(np.matmul(otherXYZ, plane) - np.ones(otherXYZ.shape[0])) / np.linalg.norm(plane)\n            diff_2 = np.abs(np.matmul(XYZ, otherPlane) - np.ones(XYZ.shape[0])) / np.linalg.norm(otherPlane)\n\n            if np.sum(diff_1 < planeDiffThreshold) > diff_1.shape[0] * inlierThreshold or np.sum(diff_2 < planeDiffThreshold) > diff_2.shape[0] * inlierThreshold:\n                planesDiff[planeIndex][otherPlaneIndex] = 1\n                planesDiff[otherPlaneIndex][planeIndex] = 1\n                pass\n\n            \n            # if min(diff_1.mean(), diff_2.mean()) < planeDiffThreshold:\n            #     planesDiff[planeIndex][otherPlaneIndex] = 1\n            #     planesDiff[otherPlaneIndex][planeIndex] = 1\n            #     pass\n            \n            \n            # if diff_1.mean() < planeDiffThreshold:\n            #     planesDiff[planeIndex][otherPlaneIndex] = 1\n            #     pass\n            # if diff_2.mean() < planeDiffThreshold:\n            #     planesDiff[otherPlaneIndex][planeIndex] = 1\n            #     pass\n            continue\n        continue\n\n    # while True:\n    #     #nextPlanesDiff = (np.matmul(planesDiff, planesDiff) > 0.5).astype(np.int32)\n    #     nextPlanesDiff = ((planesDiff + np.matmul(np.transpose(planesDiff), planesDiff)) > 0.5).astype(np.int32)\n    #     if np.all(nextPlanesDiff == planesDiff):\n    #         break\n    #     planesDiff = nextPlanesDiff\n    #     continue\n\n    #print(planesDiff)\n    usedPlanes = np.zeros(planesDiff.shape[0])\n    uniquePlanesDiff = []\n    for planeIndex in xrange(planesDiff.shape[0]):\n        planesMask = np.maximum(planesDiff[planeIndex] - usedPlanes, 0)\n        if planesMask[planeIndex] > 0:\n            uniquePlanesDiff.append(planesMask)\n            usedPlanes += planesMask\n            pass\n        continue\n    planesDiff = np.array(uniquePlanesDiff)\n    #print(planesDiff)\n\n    \n    # diffMatrix = np.diag(np.ones(planesDiff.shape[0])).astype(np.float64)\n    # diffMatrix -= np.tril(np.ones(planesDiff.shape), -1)\n    # planesDiff = np.maximum(np.matmul(diffMatrix, planesDiff), 0)\n    # planesDiff *= np.expand_dims(np.diag(planesDiff), -1)\n    # planesDiff = np.unique(planesDiff, axis=0)\n    \n    groupedPlanes = []\n    groupedPlanePointIndices = []\n    for groupIndex in xrange(planesDiff.shape[0]):\n        if planesDiff[groupIndex].sum() == 0:\n            continue\n        segmentIndices = planesDiff[groupIndex].nonzero()[0]\n        pointIndices = []\n        for segmentIndex in segmentIndices.tolist():\n            pointIndices += planePointIndices[segmentIndex].tolist()\n            continue\n        XYZ = points[pointIndices]\n        plane = fitPlane(XYZ)\n        groupedPlanes.append(plane)\n        groupedPlanePointIndices.append(np.array(pointIndices))\n        continue\n    \n    return groupedPlanes, groupedPlanePointIndices\n\n\n# def evaluatePlaneSegmentation(predPlanes, predSegmentations, gtPlanes, gtSegmentations, gtNumPlanes, prefix = \'\', numOutputPlanes = 20):\n#     if len(gtSegmentations.shape) == 3:\n#         gtSegmentations = (np.expand_dims(gtSegmentations, -1) == np.arange(numOutputPlanes)).astype(np.float32)\n#         pass\n#     if len(predSegmentations.shape) == 3:\n#         predSegmentations = (np.expand_dims(predSegmentations, -1) == np.arange(numOutputPlanes)).astype(np.float32)\n#         pass\n    \n#     width = predSegmentations.shape[2]\n#     height = predSegmentations.shape[1]\n\n#     planeDiffs = np.linalg.norm(np.expand_dims(gtPlanes, 2) - np.expand_dims(predPlanes, 1), axis=3)\n#     #print(gtPlanes[0])\n#     #print(predPlanes[0])\n#     #print(planeDiffs[0])\n\n#     planeAreas = np.sum(np.sum(gtSegmentations, axis=1), axis=1)\n#     intersection = np.sum((np.expand_dims(gtSegmentations, -1) * np.expand_dims(predSegmentations, 3) > 0.5).astype(np.float32), axis=(1, 2))\n#     union = np.sum((np.expand_dims(gtSegmentations, -1) + np.expand_dims(predSegmentations, 3) > 0.5).astype(np.float32), axis=(1, 2))\n#     planeIOUs = intersection / np.maximum(union, 1e-4)\n\n#     planeMask = np.expand_dims(np.arange(predPlanes.shape[1]), 0) < np.expand_dims(gtNumPlanes, 1)\n#     for index, numPlanes in enumerate(gtNumPlanes.tolist()):\n#         planeDiffs[index, numPlanes:] = 1000000\n#         planeIOUs[index, numPlanes:] = -1\n#         pass\n    \n#     totalNumPlanes = gtNumPlanes.sum()\n\n#     numPixels = planeAreas.sum(1)\n    \n#     # planeDistanceThreshold = 0.5\n#     # diffMask = (planeDiffs < planeDistanceThreshold).astype(np.float32)\n#     # maxIOU = np.max(planeIOUs * diffMask, axis=2)\n#     # IOU = 0.5\n#     # print(maxIOU[0])\n#     # print(planeMask[0])\n#     # print(((maxIOU >= IOU) * planeMask).sum(1).astype(np.float32))\n#     # print(gtNumPlanes)\n#     # print(float(((maxIOU >= IOU) * planeMask).sum()) / totalNumPlanes)\n    \n#     # exit(1)\n    \n#     pixel_curves = []\n#     plane_curves = []\n#     for planeDistanceThreshold in [0.1, 0.3, 0.5]:\n#         diffMask = (planeDiffs < planeDistanceThreshold).astype(np.float32)\n#         maxIOU = np.max(planeIOUs * diffMask, axis=2)\n#         stride = 0.1\n#         planeRecalls = []\n#         pixelRecalls = []\n#         for step in xrange(int(1 / stride + 1)):\n#             IOU = step * stride\n#             pixelRecalls.append((np.minimum((intersection * (planeIOUs >= IOU).astype(np.float32) * diffMask).sum(2), planeAreas).sum(1) / numPixels).mean())\n#             planeRecalls.append(float(((maxIOU >= IOU) * planeMask).sum()) / totalNumPlanes)            \n#             continue\n        \n#         pixel_curves.append(pixelRecalls)\n#         plane_curves.append(planeRecalls)\n#         pass\n    \n#     for IOUThreshold in [0.3, 0.5, 0.7]:\n#         IOUMask = (planeIOUs > IOUThreshold).astype(np.float32)\n#         minDiff = np.min(planeDiffs * IOUMask + 1000000 * (1 - IOUMask), axis=2)\n#         stride = 0.05\n#         planeRecalls = []\n#         pixelRecalls = []\n#         for step in xrange(int(0.5 / stride + 1)):\n#             diff = step * stride\n#             pixelRecalls.append((np.minimum((intersection * (planeDiffs <= diff).astype(np.float32) * IOUMask).sum(2), planeAreas).sum(1) / numPixels).mean())\n#             planeRecalls.append(float(((minDiff <= diff) * planeMask).sum()) / totalNumPlanes)\n#             continue\n#         pixel_curves.append(pixelRecalls)\n#         plane_curves.append(planeRecalls)\n#         pass\n\n    \n#     if prefix == \'\':\n#         return pixel_curves, plane_curves\n#     else:\n#         np.save(prefix + \'curves.npy\', pixel_curves + plane_curves)\n#         return\n\n\n# def evaluatePlanes(predDepths, predSegmentations, predNumPlanes, gtDepths, gtSegmentations, gtNumPlanes, prefix = \'\'):\n#     if len(gtSegmentations.shape) == 3:\n#         gtSegmentations = (np.expand_dims(gtSegmentations, -1) == np.arange(gtNumPlanes)).astype(np.float32)\n#         pass\n#     if len(predSegmentations.shape) == 3:\n#         predSegmentations = (np.expand_dims(predSegmentations, -1) == np.arange(predNumPlanes)).astype(np.float32)\n#         pass\n    \n#     width = predSegmentations.shape[2]\n#     height = predSegmentations.shape[1]\n\n    \n#     #print(gtPlanes[0])\n#     #print(predPlanes[0])\n#     #print(planeDiffs[0])\n\n#     planeAreas = np.sum(np.sum(gtSegmentations, axis=1), axis=1)\n#     intersectionMask = np.expand_dims(gtSegmentations, -1) * np.expand_dims(predSegmentations, 3) > 0.5\n#     depthDiffs = np.expand_dims(gtDepths, -1) - np.expand_dims(predDepths, 3)\n#     intersection = np.sum((intersectionMask).astype(np.float32), axis=(1, 2))\n    \n#     planeDiffs = np.abs(depthDiffs * intersectionMask).sum(1).sum(1) / np.maximum(intersection, 1e-4)\n\n#     union = np.sum((np.expand_dims(gtSegmentations, -1) + np.expand_dims(predSegmentations, 3) > 0.5).astype(np.float32), axis=(1, 2))\n#     planeIOUs = intersection / np.maximum(union, 1e-4)\n\n    \n#     for index, numPlanes in enumerate(gtNumPlanes.tolist()):\n#         planeDiffs[index, numPlanes:] = 1000000\n#         planeIOUs[index, numPlanes:] = -1\n#         pass\n    \n#     totalNumPlanes = gtNumPlanes.sum()\n#     totalNumPredictions = predSegmentations.max(1).max(1).sum()\n\n#     numPixels = planeAreas.sum(1)\n    \n#     # planeDistanceThreshold = 0.5\n#     # diffMask = (planeDiffs < planeDistanceThreshold).astype(np.float32)\n#     # maxIOU = np.max(planeIOUs * diffMask, axis=2)\n#     # IOU = 0.5\n#     # print(maxIOU[0])\n#     # print(planeMask[0])\n#     # print(((maxIOU >= IOU) * planeMask).sum(1).astype(np.float32))\n#     # print(gtNumPlanes)\n#     # print(float(((maxIOU >= IOU) * planeMask).sum()) / totalNumPlanes)\n    \n#     # exit(1)\n    \n#     pixel_curves = []\n#     plane_curves = []\n\n#     validPlaneMask = np.expand_dims(np.arange(gtNumPlanes), 0) < np.expand_dims(gtNumPlanes, 1)    \n#     for planeDistanceThreshold in [0.05, 0.10, 0.15]:\n#         diffMask = (planeDiffs < planeDistanceThreshold).astype(np.float32)\n#         maxIOU = np.max(planeIOUs * diffMask, axis=2)\n#         stride = 0.1\n#         planeStatistics = []        \n#         pixelRecalls = []\n#         for step in xrange(int(1 / stride + 1)):\n#             IOU = step * stride\n#             pixelRecalls.append((np.minimum((intersection * (planeIOUs >= IOU).astype(np.float32) * diffMask).sum(2), planeAreas).sum(1) / numPixels).mean())\n#             planeStatistics.append((float((((maxIOU >= IOU) * validPlaneMask)).sum()), totalNumPlanes, totalNumPredictions))\n#             continue\n        \n#         pixel_curves.append(pixelRecalls)\n#         plane_curves.append(planeStatistics)\n#         pass\n\n\n#     for IOUThreshold in [0.3, 0.5, 0.7]:\n#         IOUMask = (planeIOUs > IOUThreshold).astype(np.float32)\n#         minDiff = np.min(planeDiffs * IOUMask + 1000000 * (1 - IOUMask), axis=2)\n#         stride = 0.02\n#         planeStatistics = []\n#         pixelRecalls = []\n#         for step in xrange(int(0.2 / stride + 1)):\n#             diff = step * stride\n#             pixelRecalls.append((np.minimum((intersection * (planeDiffs <= diff).astype(np.float32) * IOUMask).sum(2), planeAreas).sum(1) / numPixels).mean())\n#             planeStatistics.append(((((minDiff <= diff) * validPlaneMask).sum()), totalNumPlanes, totalNumPredictions))\n#             continue\n#         pixel_curves.append(pixelRecalls)\n#         plane_curves.append(planeStatistics)\n#         pass\n\n    \n#     if prefix == \'\':\n#         return pixel_curves, plane_curves\n#     else:\n#         np.save(prefix + \'curves.npy\', pixel_curves + plane_curves)\n#         return\n\ndef evaluatePlanePrediction(predDepths, predSegmentations, predNumPlanes, gtDepths, gtSegmentations, gtNumPlanes, prefix = \'\'):\n    if len(gtSegmentations.shape) == 2:\n        gtSegmentations = (np.expand_dims(gtSegmentations, -1) == np.arange(gtNumPlanes)).astype(np.float32)\n        pass\n    if len(predSegmentations.shape) == 2:\n        predSegmentations = (np.expand_dims(predSegmentations, -1) == np.arange(predNumPlanes)).astype(np.float32)\n        pass\n    \n    width = predSegmentations.shape[1]\n    height = predSegmentations.shape[0]\n\n    \n    #print(gtPlanes[0])\n    #print(predPlanes[0])\n    #print(planeDiffs[0])\n\n    planeAreas = gtSegmentations.sum(axis=(0, 1))\n    intersectionMask = np.expand_dims(gtSegmentations, -1) * np.expand_dims(predSegmentations, 2) > 0.5\n    depthDiffs = np.expand_dims(gtDepths, -1) - np.expand_dims(predDepths, 2)\n    intersection = np.sum((intersectionMask).astype(np.float32), axis=(0, 1))\n    \n    planeDiffs = np.abs(depthDiffs * intersectionMask).sum(axis=(0, 1)) / np.maximum(intersection, 1e-4)\n    \n    #planeDiffs = np.linalg.norm(np.expand_dims(gtPlanes, 1) - np.expand_dims(predPlanes, 0), axis=2)\n    \n    planeDiffs[intersection < 1e-4] = 1\n    \n    union = np.sum(((np.expand_dims(gtSegmentations, -1) + np.expand_dims(predSegmentations, 2)) > 0.5).astype(np.float32), axis=(0, 1))\n    planeIOUs = intersection / np.maximum(union, 1e-4)\n\n    \n    planeDiffs[gtNumPlanes:] = 1000000\n    planeIOUs[gtNumPlanes:] = -1\n\n    numPredictions = int(predSegmentations.max(axis=(0, 1)).sum())\n    \n    numPixels = planeAreas.sum()\n    \n\n    # print(gtNumPlanes)\n    # #print(\'IOU\')\n    # print(np.stack([planeIOUs.max(1), planeIOUs.argmax(1)], axis=1))\n    # print(\'diff\')\n    # #print(np.abs(depthDiffs * intersectionMask).sum(axis=(0, 1)))\n    # #print(np.maximum(intersection, 1e-4))\n    # #print(np.stack([depthDiffs.min(1), depthDiffs.argmin(1)], axis=1))\n    # print(np.stack([planeDiffs.min(1) * 10000, planeDiffs.argmin(1)], axis=1))\n    # print(planeDiffs)\n    # #exit(1)\n    \n    pixel_curves = []\n    plane_curves = []\n\n    for planeDistanceThreshold in [0.1, 0.2, 0.3]:\n        diffMask = (planeDiffs < planeDistanceThreshold).astype(np.float32)\n        maxIOU = np.max(planeIOUs * diffMask, axis=1)\n        stride = 0.1\n        planeStatistics = []        \n        pixelRecalls = []\n        for step in xrange(int(1.21 / stride + 1)):\n            IOU = step * stride\n            pixelRecalls.append(np.minimum((intersection * (planeIOUs >= IOU).astype(np.float32) * diffMask).sum(1), planeAreas).sum(0) / numPixels)\n            planeStatistics.append((((maxIOU >= IOU)[:gtNumPlanes]).sum(), gtNumPlanes, numPredictions))\n            continue\n\n        pixel_curves.append(pixelRecalls)\n        plane_curves.append(planeStatistics)\n        pass\n\n\n    for IOUThreshold in [0.3, 0.5, 0.7]:\n        IOUMask = (planeIOUs > IOUThreshold).astype(np.float32)\n        minDiff = np.min(planeDiffs * IOUMask + 1000000 * (1 - IOUMask), axis=1)\n        stride = 0.05\n        planeStatistics = []\n        pixelRecalls = []\n        for step in xrange(int(0.61 / stride + 1)):\n            diff = step * stride\n            pixelRecalls.append(np.minimum((intersection * (planeDiffs <= diff).astype(np.float32) * IOUMask).sum(1), planeAreas).sum() / numPixels)\n            planeStatistics.append((((minDiff <= diff)[:gtNumPlanes]).sum(), gtNumPlanes, numPredictions))\n            continue\n        pixel_curves.append(pixelRecalls)\n        plane_curves.append(planeStatistics)\n        pass\n\n    \n    if prefix == \'\':\n        return pixel_curves, plane_curves\n    else:\n        np.save(prefix + \'curves.npy\', pixel_curves + plane_curves)\n        return\n\n    \ndef plotCurves(x, ys, filename = \'test/test.png\', xlabel=\'\', ylabel=\'\', title=\'\', labels=[]):\n    import matplotlib.pyplot as plt\n    fig = plt.figure()\n    ax = plt.gca()\n    colors = []\n    markers = []\n    sizes = []\n    for label in labels:\n        if \'PlaneNet\' in label:\n            colors.append(\'blue\')\n        elif \'NYU\' in label:\n            colors.append(\'red\')\n        elif \'Manhattan\' in label:\n            colors.append(\'orange\')\n        else:\n            colors.append(\'brown\')\n            pass\n        if \'Oracle\' in label:\n            markers.append(\'o\')\n        else:\n            markers.append(\'\')\n            pass\n        if \'PlaneNet\' in label:\n            sizes.append(2)\n        else:\n            sizes.append(1)\n            pass        \n        continue\n\n    ordering = [1, 2, 3, 4, 5, 6, 0]\n    final_labels = [\'PlaneNet\', \'[25]+depth\', \'[25]\', \'[9]+depth\', \'[9]\', \'[26]+depth\', \'[26]\'] \n    \n    #for index, y in enumerate(ys):\n    for order in ordering:\n        plt.plot(x, ys[order], figure=fig, label=final_labels[order], color=colors[order], marker=markers[order], linewidth=sizes[order])\n        continue\n    #plt.legend(loc=\'upper right\')\n    plt.legend(loc=\'upper center\', bbox_to_anchor=(0.5, 1.05), ncol=4, fancybox=True, shadow=True, handletextpad=0.1)\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel + \' %\')\n    ax.set_yticklabels(np.arange(0, 101, 20))\n    ax.spines[\'top\'].set_visible(False)\n    ax.spines[\'right\'].set_visible(False)\n    ax.get_xaxis().tick_bottom()\n    ax.get_yaxis().tick_left()    \n    #ax.xaxis.set_label_coords(1.1, -0.025)\n    #plt.title(title)\n    plt.xlim((x[0], x[-1] + 0.01))\n    plt.ylim((0, 1))\n    plt.tight_layout(w_pad=0.3)\n    plt.savefig(filename)\n    return\n\n\ndef plotCurvesSplit(x, ys, filenames, xlabel=\'\', ylabel=\'\', title=\'\', labels=[]):\n    import matplotlib\n    matplotlib.rcParams.update({\'font.size\': 16})\n    matplotlib.rcParams.update({\'font.family\': \'Times New Roman\'})\n    #font = {\'size\'   : 22}\n    #matplotlib.rc(\'font\', **font)\n    #matplotlib.rc(\'xtick\', labelsize=22)\n    #matplotlib.rc(\'ytick\', labelsize=22)\n    #matplotlib.rc(\'xticklabels\', fontsize=22)\n    #matplotlib.rc(\'yticklabels\', fontsize=22)    \n    #matplotlib.rc(\'xlabel\', size=22)\n    #matplotlib.rc(\'xlabel\', size=22)    \n    import matplotlib.pyplot as plt\n\n    #plt.rcParams.update({\'font.size\': 16})\n\n    drawLegend = True\n    \n    colors = []\n    markers = []\n    sizes = []\n    for label in labels:\n        if \'PlaneNet\' in label:\n            colors.append(\'blue\')\n        elif \'NYU\' in label:\n            colors.append(\'red\')\n        elif \'Manhattan\' in label:\n            colors.append(\'orange\')\n        else:\n            colors.append(\'brown\')\n            pass\n        if \'Oracle\' in label:\n            markers.append(\'o\')\n        else:\n            markers.append(\'\')\n            pass\n        if \'PlaneNet\' in label:\n            sizes.append(3)\n        else:\n            sizes.append(2)\n            pass        \n        continue\n    \n    final_labels = [\'PlaneNet\', \'[30] + GT depth\', \'[30] + Inferred depth\', \'[12] + GT depth\', \'[12] + Inferred depth\', \'[31] + GT depth\', \'[31] + Inferred depth\'] \n\n    if drawLegend:\n        fig = plt.figure(figsize=(12, 6))\n    else:\n        fig = plt.figure()\n        pass\n    \n    ax = plt.gca()\n    \n    ordering = [2, 4, 6, 0]\n    \n    #for index, y in enumerate(ys):\n    for order in ordering:\n        if drawLegend:\n            plt.plot(x, np.zeros(ys[order].shape), figure=fig, label=final_labels[order], color=colors[order], marker=markers[order], linewidth=sizes[order])\n        else:\n            plt.plot(x, ys[order], figure=fig, label=final_labels[order], color=colors[order], marker=markers[order], linewidth=sizes[order])\n            pass\n        continue\n\n    if drawLegend:\n        plt.legend(loc=\'upper right\')\n        pass\n    #plt.legend(loc=\'upper center\', bbox_to_anchor=(0.5, 1.05), ncol=4, fancybox=True, shadow=True, handletextpad=0.1)\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel + \' %\')\n\n    for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n                 ax.get_xticklabels() + ax.get_yticklabels()):\n        item.set_fontsize(22)\n    \n    ax.set_yticklabels(np.arange(0, 101, 20))\n    ax.spines[\'top\'].set_visible(False)\n    ax.spines[\'right\'].set_visible(False)\n    ax.spines[\'bottom\'].set_linewidth(2)\n    ax.spines[\'left\'].set_linewidth(2)\n    ax.tick_params(width=2, length=8)\n    ax.get_xaxis().tick_bottom()\n    ax.get_yaxis().tick_left()    \n    #ax.xaxis.set_label_coords(1.1, -0.025)\n    #plt.title(title)\n    plt.xlim((x[0], x[-1] + 0.01))\n    plt.ylim((0, 1))\n    plt.tight_layout(w_pad=0.3)\n    plt.savefig(filenames[0])\n\n    \n    if drawLegend:\n        fig = plt.figure(figsize=(12, 6))\n    else:\n        fig = plt.figure()\n        pass\n    \n    ax = plt.gca()\n    \n    ordering = [1, 3, 5, 0]\n    \n    #for index, y in enumerate(ys):\n    for order in ordering:\n        if drawLegend:\n            plt.plot(x, np.zeros(ys[order].shape), figure=fig, label=final_labels[order], color=colors[order], marker=markers[order], linewidth=sizes[order])\n        else:\n            plt.plot(x, ys[order], figure=fig, label=final_labels[order], color=colors[order], marker=markers[order], linewidth=sizes[order])\n            pass\n        continue\n\n    if drawLegend:\n        plt.legend(loc=\'upper right\')\n        pass\n    #plt.legend(loc=\'upper center\', bbox_to_anchor=(0.5, 1.05), ncol=4, fancybox=True, shadow=True, handletextpad=0.1)\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel + \' %\')\n\n    for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n                 ax.get_xticklabels() + ax.get_yticklabels()):\n        item.set_fontsize(22)\n        \n    ax.set_yticklabels(np.arange(0, 101, 20))\n    ax.spines[\'top\'].set_visible(False)\n    ax.spines[\'right\'].set_visible(False)\n    ax.spines[\'bottom\'].set_linewidth(2)\n    ax.spines[\'left\'].set_linewidth(2)\n    ax.tick_params(width=2, length=8)    \n    ax.get_xaxis().tick_bottom()\n    ax.get_yaxis().tick_left()    \n    #ax.xaxis.set_label_coords(1.1, -0.025)\n    #plt.title(title)\n    plt.xlim((x[0], x[-1] + 0.01))\n    plt.ylim((0, 1))\n    plt.tight_layout(w_pad=0.3)\n    plt.savefig(filenames[1])\n    return\n\n\ndef plotCurvesSubplot(x, ysArray, filenames, xlabel=\'\', ylabels=[], labels=[]):\n    import matplotlib.pyplot as plt\n\n    plt.rcParams.update({\'font.size\': 14})\n\n    colors = []\n    markers = []\n    sizes = []\n    for label in labels:\n        if \'PlaneNet\' in label:\n            colors.append(\'blue\')\n        elif \'NYU\' in label:\n            colors.append(\'red\')\n        elif \'Manhattan\' in label:\n            colors.append(\'orange\')\n        else:\n            colors.append(\'brown\')\n            pass\n        if \'Oracle\' in label:\n            markers.append(\'o\')\n        else:\n            markers.append(\'\')\n            pass\n        if \'PlaneNet\' in label:\n            sizes.append(2)\n        else:\n            sizes.append(1)\n            pass        \n        continue\n    final_labels = [\'PlaneNet\', \'[25]+GT depth\', \'[25]\', \'[9]+GT depth\', \'[9]\', \'[26]+GT depth\', \'[26]\'] \n\n    orderingArray = [[2, 4, 6, 0], [1, 3, 5, 0]]\n\n    for groupIndex in xrange(2):\n        fig = plt.figure(groupIndex)\n        ax = plt.gca()\n\n        ordering = orderingArray[groupIndex]\n        for metricIndex in xrange(2):\n            plt.subplot(1, 2, metricIndex + 1)\n            #for index, y in enumerate(ys):\n            ys = ysArray[metricIndex]\n            for order in ordering:\n                plt.plot(x, ys[order], figure=fig, label=final_labels[order], color=colors[order], marker=markers[order], linewidth=sizes[order])\n                continue\n            plt.xlabel(xlabel)\n            plt.ylabel(ylabels[metricIndex] + \' %\')\n\n            ax.set_yticklabels(np.arange(0, 101, 20))\n            ax.spines[\'top\'].set_visible(False)\n            ax.spines[\'right\'].set_visible(False)\n            ax.get_xaxis().tick_bottom()\n            ax.get_yaxis().tick_left()    \n            #ax.xaxis.set_label_coords(1.1, -0.025)\n            #plt.title(title)\n\n            plt.xlim((x[0], x[-1] + 0.01))\n            plt.ylim((0, 1))\n            \n            continue\n\n        plt.legend(loc=\'upper center\', bbox_to_anchor=(0.5, -0.15), ncol=4, fancybox=True, shadow=True, handletextpad=0.1)\n\n        plt.tight_layout(w_pad=0.3)\n        plt.savefig(filenames[groupIndex])\n        \n        continue\n    #plt.legend(loc=\'upper right\')\n    return\n\n\ndef plotCurvesSimple(x, ys, filename = \'test/test.png\', xlabel=\'\', ylabel=\'\', title=\'\', labels=[]):\n    import matplotlib.pyplot as plt\n    fig = plt.figure()\n    ax = plt.gca()\n\n    ordering = np.arange(len(labels)).tolist()\n    final_labels = labels\n        \n    #for index, y in enumerate(ys):\n    for order in ordering:\n        plt.plot(x, ys[order], figure=fig, label=final_labels[order])\n        continue\n    plt.legend(loc=\'upper right\', ncol=2)\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel + \' %\')\n    ax.set_yticklabels(np.arange(0, 101, 20))\n    ax.spines[\'top\'].set_visible(False)\n    ax.spines[\'right\'].set_visible(False)\n    ax.get_xaxis().tick_bottom()\n    ax.get_yaxis().tick_left()    \n    #ax.xaxis.set_label_coords(1.1, -0.025)\n    #plt.title(title)\n    plt.xlim((x[0], x[-1] + 0.01))\n    plt.ylim((0, 1))\n    plt.tight_layout(w_pad=0.3)\n    plt.savefig(filename)\n    return\n    \ndef transformPlanes(planes, transformation):\n    \n    centers = planes\n    planesD = np.maximum(np.linalg.norm(planes, axis=1, keepdims=True), 1e-4)\n    refPoints = centers - planes / planesD\n    \n    centers = np.concatenate([centers, np.ones((planes.shape[0], 1))], axis=1)\n    refPoints = np.concatenate([refPoints, np.ones((planes.shape[0], 1))], axis=1)\n    \n    newCenters = np.transpose(np.matmul(transformation, np.transpose(centers)))\n    newRefPoints = np.transpose(np.matmul(transformation, np.transpose(refPoints)))\n\n    newCenters = newCenters[:, :3] / newCenters[:, 3:4]\n    newRefPoints = newRefPoints[:, :3] / newRefPoints[:, 3:4]\n\n    planeNormals = newRefPoints - newCenters\n    planesD = -np.sum(newCenters * planeNormals, axis=1, keepdims=True)\n    newPlanes = -planeNormals * planesD\n    return newPlanes\n\n\ndef softmax(values):\n    exp = np.exp(values - values.max())\n    return exp / exp.sum(-1, keepdims=True)\n\ndef one_hot(values, depth):\n    maxInds = values.reshape(-1)\n    results = np.zeros([maxInds.shape[0], depth])\n    results[np.arange(maxInds.shape[0]), maxInds] = 1\n    results = results.reshape(list(values.shape) + [depth])\n    return results\n\ndef sigmoid(values):\n    return 1 / (1 + np.exp(-values))\n\ndef normalize(values):\n    return values / np.maximum(np.linalg.norm(values, axis=-1, keepdims=True), 1e-4)\n\n\n\ndef sortSegmentations(segmentations, planes, planesTarget):\n    diff = np.linalg.norm(np.expand_dims(planes, 1) - np.expand_dims(planesTarget, 0), axis=2)\n    planeMap = one_hot(np.argmin(diff, axis=-1), depth=diff.shape[-1])\n    #print(planeMap)\n    segmentationsTarget = np.matmul(segmentations, planeMap)\n    return segmentationsTarget, np.matmul(planes.transpose(), planeMap).transpose()\n\ndef refitPlanes(planes, segmentation, depth, info, numOutputPlanes=20, planeAreaThreshold=6*8):\n    camera = getCameraFromInfo(info)\n    width = depth.shape[1]\n    height = depth.shape[0]\n\n    #camera = getNYURGBDCamera()\n    #camera = getSUNCGCamera()\n\n    urange = (np.arange(width, dtype=np.float32) / width * camera[\'width\'] - camera[\'cx\']) / camera[\'fx\']\n    urange = urange.reshape(1, -1).repeat(height, 0)\n    vrange = (np.arange(height, dtype=np.float32) / height * camera[\'height\'] - camera[\'cy\']) / camera[\'fy\']\n    vrange = vrange.reshape(-1, 1).repeat(width, 1)\n    X = depth * urange\n    Y = depth\n    Z = -depth * vrange\n\n    XYZ = np.stack([X, Y, Z], axis=2)\n    \n    validDepthMask = depth > 1e-4\n    \n    newPlaneInfo = []\n    for planeIndex in xrange(numOutputPlanes):\n        mask = segmentation == planeIndex\n        points = XYZ[np.logical_and(cv2.erode(mask.astype(np.float32), np.ones((3, 3))) > 0.5, validDepthMask)]\n        if points.shape[0] >= 3:\n            try:\n                plane = fitPlane(points)\n                plane /= pow(np.linalg.norm(plane), 2)\n                newPlaneInfo.append((plane, mask, points.shape[0]))\n                #newPlaneInfo.append((planes[planeIndex], mask, points.shape[0]))                \n            except:\n                pass\n            pass\n        continue\n\n    newPlaneInfo = sorted(newPlaneInfo, key=lambda x: -x[2])\n\n    newPlanes = []\n    newSegmentation = np.ones(segmentation.shape, dtype=np.uint8) * numOutputPlanes\n    for planeIndex, planeInfo in enumerate(newPlaneInfo):\n        newPlanes.append(planeInfo[0])\n        newSegmentation[planeInfo[1]] = planeIndex\n        continue\n    \n    numPlanes = len(newPlaneInfo)\n    if numPlanes == 0:\n        return np.zeros((numOutputPlanes, 3)), newSegmentation, numPlanes    \n    \n    newPlanes = np.array(newPlanes)\n    if numPlanes < numOutputPlanes:\n        newPlanes = np.concatenate([newPlanes, np.zeros((numOutputPlanes - numPlanes, 3))], axis=0)\n        pass\n    \n    return newPlanes, newSegmentation, numPlanes\n\n# def filterPlanesPred(planes, segmentations, depth, info, segmentationsTarget, numOutputPlanes=20, nonPlaneRatioThreshold=0.7, coveredPlaneRatioThreshold=0.5, planeDistanceThreshold=0.05, planeAngleThreshold=np.cos(np.deg2rad(20))):\n\n#     camera = getCameraFromInfo(info)\n#     width = depth.shape[1]\n#     height = depth.shape[0]\n\n#     #camera = getNYURGBDCamera()\n#     #camera = getSUNCGCamera()\n\n#     urange = (np.arange(width, dtype=np.float32) / width * camera[\'width\'] - camera[\'cx\']) / camera[\'fx\']\n#     urange = urange.reshape(1, -1).repeat(height, 0)\n#     vrange = (np.arange(height, dtype=np.float32) / height * camera[\'height\'] - camera[\'cy\']) / camera[\'fy\']\n#     vrange = vrange.reshape(-1, 1).repeat(width, 1)\n#     X = depth * urange\n#     Y = depth\n#     Z = -depth * vrange\n\n#     XYZ = np.stack([X, Y, Z], axis=2)\n    \n#     validDepthMask = depth > 1e-4\n    \n#     #numPlanes = planes.shape[0]\n#     validPlaneInfo = []\n#     emptyMaskTarget = segmentationsTarget[:, :, numOutputPlanes]\n#     emptyMask = segmentations[:, :, numOutputPlanes]    \n#     for planeIndex in xrange(numOutputPlanes):\n#         mask = segmentations[:, :, planeIndex]\n#         if (emptyMaskTarget * mask).sum() < mask.sum() * nonPlaneRatioThreshold:\n#             points = XYZ[np.logical_and(cv2.erode(mask, np.ones((3, 3))) > 0.5, validDepthMask)]\n#             if points.shape[0] >= 3:\n#                 try:\n#                     plane = fitPlane(points)\n#                     plane /= pow(np.linalg.norm(plane), 2)\n#                     validPlaneInfo.append((plane, mask, points))                    \n#                 except:\n#                     emptyMask += mask\n#                 pass\n#             else:\n#                 emptyMask += mask\n#         else:\n#             emptyMask += mask\n#             pass\n#         continue\n    \n#     #validPlaneInfo = sorted(validPlaneInfo, key=lambda x:-x[2])\n\n#     for planeIndex, planeInfo in enumerate(validPlaneInfo):\n#         cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(planeInfo[1]))\n#         print(planeIndex, planeInfo[0])\n#         continue\n    \n#     emptyMask = (emptyMask > 0.5).astype(np.float32)\n#     for planeIndexTarget in xrange(numOutputPlanes):\n#         maskTarget = segmentationsTarget[:, :, planeIndexTarget]\n#         excludedMask = ((maskTarget + emptyMask) > 0.5).astype(np.float32)\n#         coveredPlanes = []\n#         for planeIndex, planeInfo in enumerate(validPlaneInfo):\n#             mask = planeInfo[1]\n#             area = mask.sum()\n#             if (maskTarget * mask).sum() / area > coveredPlaneRatioThreshold:\n#                 coveredPlanes.append((planeIndex, planeInfo[0], planeInfo[2]))\n#                 pass\n#             continue\n#         if len(coveredPlanes) <= 1:\n#             continue\n        \n#         coveredPlanes = sorted(coveredPlanes, key=lambda x:-x[2].shape[0])\n\n        \n#         majorPlane = coveredPlanes[0][1]\n#         majorPlaneD = np.linalg.norm(majorPlane)\n#         majorPlaneNormal = majorPlane / majorPlaneD\n#         mergedPlanes = [coveredPlanes[0][0], ]\n#         for planeInfo in coveredPlanes[1:]:\n#             #if np.linalg.norm(planeInfo[1] - majorPlane) < planeDistanceThreshold:\n#             distance = np.abs(np.sum(planeInfo[2] * majorPlaneNormal, axis=-1) - majorPlaneD)\n#             print(distance.mean())\n#             print(distance.max())\n#             planeNormal = planeInfo[1] / np.linalg.norm(planeInfo[1])            \n#             print(np.sum(planeNormal * majorPlaneNormal), planeAngleThreshold)\n#             exit(1)\n#             if distance.mean() < planeDistanceThreshold and np.sum(planeNormal * majorPlaneNormal) > planeAngleThreshold:\n#                 mergedPlanes.append(planeInfo[0])\n#                 pass\n#             continue\n#         if mergedPlanes <= 1:\n#             continue\n#         newValidPlaneInfo = []\n#         mergedPlaneMask = np.zeros(emptyMask.shape)\n#         for planeIndex, planeInfo in enumerate(validPlaneInfo):\n#             if planeIndex not in mergedPlanes:\n#                 if (excludedMask * planeInfo[1]).sum() < planeInfo[1].sum() * nonPlaneRatioThreshold:\n#                     newValidPlaneInfo.append(planeInfo)\n#                     pass\n#             else:\n#                 mergedPlaneMask += planeInfo[1]\n#                 pass\n#             continue\n#         cv2.erode(mergedPlaneMask, np.ones((3, 3)))        \n#         mergedPlaneMask = mergedPlaneMask > 0.5\n#         points = XYZ[np.logical_and(mergedPlaneMask, validDepthMask)]\n#         if points.shape[0] >= 3:\n#             try:\n#                 mergedPlane = fitPlane(points)\n#                 mergedPlane = mergedPlane / pow(np.linalg.norm(mergedPlane), 2)\n#                 newValidPlaneInfo.append((mergedPlane, mergedPlaneMask.astype(np.float32), points))\n#             except:\n#                 pass\n#             pass\n#         validPlaneInfo = newValidPlaneInfo\n#         continue\n\n#     validPlaneInfo = sorted(validPlaneInfo, key=lambda x: -x[1].sum())\n    \n#     newPlanes = []\n#     newSegmentation = np.ones(emptyMask.shape) * numOutputPlanes\n#     for planeIndex, planeInfo in enumerate(validPlaneInfo):\n#         newPlanes.append(planeInfo[0])\n#         newSegmentation[planeInfo[1].astype(np.bool)] = planeIndex\n#         continue\n#     numPlanes = len(newPlanes)\n#     if numPlanes == 0:\n#         return np.zeros((numOutputPlanes, 3)), newSegmentation, numPlanes\n    \n#     newPlanes = np.array(newPlanes)\n#     if numPlanes < numOutputPlanes:\n#         newPlanes = np.concatenate([newPlanes, np.zeros((numOutputPlanes - numPlanes, 3))], axis=0)\n#         pass\n    \n#     return newPlanes, newSegmentation.astype(np.uint8), numPlanes\n\ndef filterPlanes(planes, segmentations, depth, info, numOutputPlanes=20, coveredPlaneRatioThreshold=0.5, planeDistanceThreshold=0.05, normalDotThreshold=np.cos(np.deg2rad(20)), planeFittingThreshold = 0.03):\n\n    camera = getCameraFromInfo(info)\n    width = depth.shape[1]\n    height = depth.shape[0]\n\n    #camera = getNYURGBDCamera()\n    #camera = getSUNCGCamera()\n\n    urange = (np.arange(width, dtype=np.float32) / width * camera[\'width\'] - camera[\'cx\']) / camera[\'fx\']\n    urange = urange.reshape(1, -1).repeat(height, 0)\n    vrange = (np.arange(height, dtype=np.float32) / height * camera[\'height\'] - camera[\'cy\']) / camera[\'fy\']\n    vrange = vrange.reshape(-1, 1).repeat(width, 1)\n    X = depth * urange\n    Y = depth\n    Z = -depth * vrange\n\n    XYZ = np.stack([X, Y, Z], axis=2)\n    \n    validDepthMask = depth > 1e-4\n\n    \n    \n    #numPlanes = planes.shape[0]\n    validPlaneInfo = []\n    for planeIndex in xrange(numOutputPlanes):\n        mask = segmentations[:, :, planeIndex]\n        points = XYZ[np.logical_and(cv2.erode(mask, np.ones((3, 3)), 2) > 0.5, validDepthMask)]\n        if points.shape[0] >= 3:\n            try:\n                plane = fitPlane(points)\n                plane /= pow(np.linalg.norm(plane), 2)\n                #plane = planes[planeIndex]\n                \n                #planeD = np.linalg.norm(plane)\n                #diff = np.abs(np.sum(points * (plane / planeD), axis=-1) - planeD).mean()\n                #validMask = np.abs(np.sum(points * (plane / planeD), axis=-1) - planeD) < planeDistanceThreshold\n\n                #diff = (np.abs((np.sum(points * plane, axis=-1) - 1) / np.linalg.norm(plane)) > 0.05).astype(np.float32).mean()\n\n                #print(planeIndex, diff, mask.sum())\n                #cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(mask))                \n                #if diff < planeFittingThreshold:\n                validPlaneInfo.append((plane, mask, points))\n                #    pass\n            except:\n                pass\n            pass\n        continue\n\n    #validPlaneInfo = sorted(validPlaneInfo, key=lambda x:-x[2])\n\n    validPlaneInfo = sorted(validPlaneInfo, key=lambda x: -x[2].shape[0])\n\n    if False:\n        for planeIndex, planeInfo in enumerate(validPlaneInfo):\n            cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(planeInfo[1]))\n            print(planeIndex, planeInfo[0], planeInfo[3], planeInfo[1].sum())\n            continue\n        pass\n\n    newPlaneInfo = []\n    usedPlaneMask = np.zeros(len(validPlaneInfo), dtype=np.bool)\n    for majorPlaneIndex, majorPlaneInfo in enumerate(validPlaneInfo):\n        if usedPlaneMask[majorPlaneIndex]:\n            continue\n        usedPlaneMask[majorPlaneIndex] = True\n        \n        majorPlane = majorPlaneInfo[0]\n        majorPlaneD = np.linalg.norm(majorPlane)\n        majorPlaneNormal = majorPlane / majorPlaneD\n\n        mergedPlaneMask = majorPlaneInfo[1].copy()\n        planeMerged = False\n        for planeIndex, planeInfo in enumerate(validPlaneInfo):\n            if planeIndex <= majorPlaneIndex or usedPlaneMask[planeIndex]:\n                continue\n            \n            fittingDiff = np.abs(np.sum(planeInfo[2] * majorPlaneNormal, axis=-1) - majorPlaneD)\n            planeNormal = planeInfo[0] / np.linalg.norm(planeInfo[0])\n            normalDot = np.sum(planeNormal * majorPlaneNormal)\n            \n            #print(majorPlaneIndex, planeIndex)\n            #print(majorPlane, planeInfo[0])\n            #print(fittingDiff.mean(), (fittingDiff < 0.05).astype(np.float32).mean(), normalDot, normalDotThreshold)\n\n            if fittingDiff.mean() < planeDistanceThreshold and normalDot > normalDotThreshold:\n                #print(\'merge\', majorPlaneIndex, planeIndex)\n                mergedPlaneMask += planeInfo[1]\n                usedPlaneMask[planeIndex] = True                                \n                planeMerged = True\n                pass\n            continue\n\n        if planeMerged:\n            mergedPlaneMask = (mergedPlaneMask > 0.5).astype(np.float32)\n            pass\n        \n        newPlaneInfo.append((majorPlaneInfo[0], mergedPlaneMask))\n        continue\n\n    newPlaneInfo = sorted(newPlaneInfo, key=lambda x: -x[1].sum())\n    \n    newPlanes = []\n    newSegmentation = np.ones((height, width), dtype=np.uint8) * numOutputPlanes\n    for planeIndex, planeInfo in enumerate(newPlaneInfo):\n        area = planeInfo[1].sum()\n        xs = planeInfo[1].max(0).nonzero()[0]\n        ys = planeInfo[1].max(1).nonzero()[0]\n        length = np.sqrt(pow(xs.max() - xs.min() + 1, 2) + pow(ys.max() - ys.min() + 1, 2))\n        if area < (width * height / 100.) or area / length < 10:\n            continue\n        newSegmentation[planeInfo[1].astype(np.bool)] = len(newPlanes)        \n        newPlanes.append(planeInfo[0])\n        continue\n    numPlanes = len(newPlanes)\n    if numPlanes == 0:\n        return np.zeros((numOutputPlanes, 3)), newSegmentation, numPlanes\n    \n    newPlanes = np.array(newPlanes)\n    if numPlanes < numOutputPlanes:\n        newPlanes = np.concatenate([newPlanes, np.zeros((numOutputPlanes - numPlanes, 3))], axis=0)\n        pass\n    \n    return newPlanes, newSegmentation, numPlanes\n\n\ndef getSegmentationsTRWS(planes, image, depth, normal, semantics, info, useSemantics=False, numPlanes=20, numProposals = 3):\n    from pystruct.inference import get_installed, inference_ogm, inference_dispatch\n    \n    numOutputPlanes = planes.shape[0]\n    height = depth.shape[0]\n    width = depth.shape[1]\n\n\n    camera = getCameraFromInfo(info)\n    urange = (np.arange(width, dtype=np.float32) / (width) * (camera[\'width\']) - camera[\'cx\']) / camera[\'fx\']\n    urange = urange.reshape(1, -1).repeat(height, 0)\n    vrange = (np.arange(height, dtype=np.float32) / (height) * (camera[\'height\']) - camera[\'cy\']) / camera[\'fy\']\n    vrange = vrange.reshape(-1, 1).repeat(width, 1)\n    \n    X = depth * urange\n    Y = depth\n    Z = -depth * vrange\n    points = np.stack([X, Y, Z], axis=2)\n\n    planes = planes[:numPlanes]\n    planesD = np.linalg.norm(planes, axis=1, keepdims=True)\n    planeNormals = planes / np.maximum(planesD, 1e-4)\n\n    distanceCostThreshold = 0.05\n    distanceCost = np.abs(np.tensordot(points, planeNormals, axes=([2, 1])) - np.reshape(planesD, [1, 1, -1])) / distanceCostThreshold\n    distanceCost = np.concatenate([distanceCost, np.ones((height, width, 1))], axis=2)\n    #cv2.imwrite(\'test/mask.png\', drawMaskImage(np.minimum(distanceCost[:, :, 2] /  5, 1)))\n    #distanceCost[:, :, numPlanes:numOutputPlanes] = 10000\n    normalCostThreshold = 1 - np.cos(np.deg2rad(30))        \n    normalCost = (1 - np.tensordot(normal, planeNormals, axes=([2, 1]))) / normalCostThreshold\n    #normalCost[:, :, numPlanes:] = 10000\n    normalCost = np.concatenate([normalCost, np.ones((height, width, 1))], axis=2)\n\n\n    unaryCost = distanceCost\n    \n    if useSemantics:    \n        planeMasks = []\n        for planeIndex in xrange(numPlanes):\n            #print(np.bincount(semantics[segmentation == planeIndex]))\n            planeMaskOri = segmentation == planeIndex\n            semantic = np.bincount(semantics[planeMaskOri]).argmax()\n            #print(semantic)\n            planeMask = cv2.dilate((np.logical_and(np.logical_or(semantics == semantic, planeMaskOri), distanceCost[:, :, planeIndex])).astype(np.uint8), np.ones((3, 3), dtype=np.uint8)).astype(np.float32)\n            planeMasks.append(planeMask)\n            #cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(segmentation == planeIndex))\n            #cv2.imwrite(\'test/mask_2.png\', drawMaskImage(semantics == semantic))\n            continue\n        planeMasks = np.stack(planeMasks, 2)        \n        unaryCost += (1 - planeMasks) * 10000\n        pass\n    \n    unaryCost = np.concatenate([unaryCost, np.ones((height, width, 1))], axis=2)\n\n\n    proposals = np.argpartition(unaryCost, numProposals)[:, :, :numProposals]\n    unaries = -readProposalInfo(unaryCost, proposals).reshape((-1, numProposals))\n\n    # refined_segmentation = np.argmax(unaries, axis=1)\n    # refined_segmentation = refined_segmentation.reshape([height, width, 1])\n    # refined_segmentation = readProposalInfo(proposals, refined_segmentation)\n    # refined_segmentation = refined_segmentation.reshape([height, width])\n    # refined_segmentation[refined_segmentation == numPlanes] = numOutputPlanes\n    \n\n    proposals = proposals.reshape((-1, numProposals))\n    #cv2.imwrite(\'test/segmentation.png\', drawSegmentationImage(unaries.reshape((height, width, -1)), blackIndex=numOutputPlanes))\n\n    nodes = np.arange(height * width).reshape((height, width))\n\n    image = image.astype(np.float32)\n    colors = image.reshape((-1, 3))\n    deltas = [(0, 1), (1, 0), (-1, 1), (1, 1)]    \n    intensityDifferenceSum = 0.0\n    intensityDifferenceCount = 0\n    for delta in deltas:\n        deltaX = delta[0]\n        deltaY = delta[1]\n        partial_nodes = nodes[max(-deltaY, 0):min(height - deltaY, height), max(-deltaX, 0):min(width - deltaX, width)].reshape(-1)\n        intensityDifferenceSum += np.sum(pow(colors[partial_nodes] - colors[partial_nodes + (deltaY * width + deltaX)], 2))\n        intensityDifferenceCount += partial_nodes.shape[0]\n        continue\n    intensityDifference = intensityDifferenceSum / intensityDifferenceCount\n\n    \n    edges = []\n    edges_features = []\n\n    for delta in deltas:\n        deltaX = delta[0]\n        deltaY = delta[1]\n        partial_nodes = nodes[max(-deltaY, 0):min(height - deltaY, height), max(-deltaX, 0):min(width - deltaX, width)].reshape(-1)\n        edges.append(np.stack([partial_nodes, partial_nodes + (deltaY * width + deltaX)], axis=1))\n\n        labelDiff = (np.expand_dims(proposals[partial_nodes], -1) != np.expand_dims(proposals[partial_nodes + (deltaY * width + deltaX)], 1)).astype(np.float32)\n        colorDiff = np.sum(pow(colors[partial_nodes] - colors[partial_nodes + (deltaY * width + deltaX)], 2), axis=1)\n        pairwise_cost = labelDiff * np.reshape(1 + 45 * np.exp(-colorDiff / intensityDifference), [-1, 1, 1])\n        #pairwise_cost = np.expand_dims(pairwise_matrix, 0) * np.ones(np.reshape(1 + 45 * np.exp(-colorDiff / np.maximum(intensityDifference[partial_nodes], 1e-4)), [-1, 1, 1]).shape)\n        edges_features.append(-pairwise_cost)\n        continue\n\n    edges = np.concatenate(edges, axis=0)\n    edges_features = np.concatenate(edges_features, axis=0)\n\n    refined_segmentation = inference_ogm(unaries * 10, edges_features, edges, return_energy=False, alg=\'trw\')\n    #print(pairwise_matrix)\n    #refined_segmentation = inference_ogm(unaries * 5, -pairwise_matrix, edges, return_energy=False, alg=\'alphaexp\')\n    refined_segmentation = refined_segmentation.reshape([height, width, 1])    \n    refined_segmentation = readProposalInfo(proposals, refined_segmentation)\n    refined_segmentation = refined_segmentation.reshape([height, width])\n    refined_segmentation[refined_segmentation == numPlanes] = numOutputPlanes\n    return refined_segmentation\n\ndef getSegmentationsGraphCut(planes, image, depth, normal, semantics, info, parameters={}):\n\n    height = depth.shape[0]\n    width = depth.shape[1]\n\n    # planeMap = []\n    # planeMasks = []\n    # for planeIndex in xrange(numPlanes):\n    #     planeMask = segmentation == planeIndex\n    #     if planeMask.sum() < 6 * 8:\n    #         continue\n    #     planeMap.append(planeIndex)\n    #     semantic = np.bincount(semantics[planeMask]).argmax()\n    #     for _ in xrange(2):\n    #         planeMask = cv2.dilate(planeMask.astype(np.float32), np.ones((3, 3), dtype=np.float32))\n    #         continue        \n    #     planeMask = np.logical_and(np.logical_or(semantics == semantic, semantics == 0), planeMask).astype(np.float32)\n    #     for _ in xrange(1):\n    #         planeMask = cv2.dilate(planeMask, np.ones((3, 3), dtype=np.float32))\n    #         continue\n    #     planeMasks.append(planeMask)\n    #     continue\n    # planeMap = one_hot(np.array(planeMap), depth=planes.shape[0])\n    #planes = np.matmul(planeMap, planes)\n    #planeMasks = np.stack(planeMasks, 2).reshape((-1, numPlanes))\n\n    numPlanes = planes.shape[0]\n    \n    #if numPlanes < numOutputPlanes:\n    #planeMasks = np.concatenate([planeMasks, np.zeros((height, width, numOutputPlanes - numPlanes))], axis=2)\n    #pass\n    \n    #print(info)\n    camera = getCameraFromInfo(info)\n    urange = (np.arange(width, dtype=np.float32) / (width) * (camera[\'width\']) - camera[\'cx\']) / camera[\'fx\']\n    urange = urange.reshape(1, -1).repeat(height, 0)\n    vrange = (np.arange(height, dtype=np.float32) / (height) * (camera[\'height\']) - camera[\'cy\']) / camera[\'fy\']\n    vrange = vrange.reshape(-1, 1).repeat(width, 1)\n    \n    X = depth * urange\n    Y = depth\n    Z = -depth * vrange\n\n    points = np.stack([X, Y, Z], axis=2)\n    planes = planes[:numPlanes]\n    planesD = np.linalg.norm(planes, axis=1, keepdims=True)\n    planeNormals = planes / np.maximum(planesD, 1e-4)\n\n    if \'distanceCostThreshold\' in parameters:\n        distanceCostThreshold = parameters[\'distanceCostThreshold\']\n    else:\n        distanceCostThreshold = 0.05\n        pass\n\n    #distanceCost = 1 - np.exp(-np.abs(np.tensordot(points, planeNormals, axes=([2, 1])) - np.reshape(planesD, [1, 1, -1])) / distanceCostThreshold)\n    #distanceCost = np.concatenate([distanceCost, np.ones((height, width, 1)) * (1 - np.exp(-1))], axis=2)\n    distanceCost = np.abs(np.tensordot(points, planeNormals, axes=([2, 1])) - np.reshape(planesD, [1, 1, -1])) / distanceCostThreshold\n    distanceCost = np.concatenate([distanceCost, np.ones((height, width, 1))], axis=2)\n    #cv2.imwrite(\'test/mask.png\', drawMaskImage(np.minimum(distanceCost[:, :, 2] /  5, 1)))\n    #distanceCost[:, :, numPlanes:numOutputPlanes] = 10000\n\n    normalCostThreshold = 1 - np.cos(np.deg2rad(30))\n    normalCost = (1 - np.abs(np.tensordot(normal, planeNormals, axes=([2, 1])))) / normalCostThreshold\n    #normalCost[:, :, numPlanes:] = 10000\n    normalCost = np.concatenate([normalCost, np.ones((height, width, 1))], axis=2)\n\n\n    unaryCost = distanceCost + normalCost\n    unaryCost *= np.expand_dims((depth > 1e-4).astype(np.float32), -1)\n    unaries = -unaryCost.reshape((-1, numPlanes + 1))\n\n    cv2.imwrite(\'test/distance_cost.png\', drawSegmentationImage(-distanceCost.reshape((height, width, -1)), unaryCost.shape[-1] - 1))\n    cv2.imwrite(\'test/normal_cost.png\', drawSegmentationImage(-normalCost.reshape((height, width, -1)), unaryCost.shape[-1] - 1))\n    cv2.imwrite(\'test/unary_cost.png\', drawSegmentationImage(-unaryCost.reshape((height, width, -1)), blackIndex=unaryCost.shape[-1] - 1))\n    \n    \n    #unaries[:, :numPlanes] -= (1 - planeMasks) * 10000\n    \n    #print(planes)\n    #print(distanceCost[150][200])\n    #print(unaryCost[150][200])\n    # print(np.argmax(-unaryCost[60][150]))\n\n    #cv2.imwrite(\'test/depth.png\', drawDepthImage(depth))\n    cv2.imwrite(\'test/segmentation.png\', drawSegmentationImage(unaries.reshape((height, width, -1)), blackIndex=numPlanes))\n    #cv2.imwrite(\'test/mask.png\', drawSegmentationImage(planeMasks.reshape((height, width, -1))))\n    #exit(1)\n\n\n    nodes = np.arange(height * width).reshape((height, width))\n\n    image = image.astype(np.float32)\n    colors = image.reshape((-1, 3))    \n\n    deltas = [(0, 1), (1, 0), (-1, 1), (1, 1)]    \n    \n    intensityDifferenceSum = 0.0\n    intensityDifferenceCount = 0\n    for delta in deltas:\n        deltaX = delta[0]\n        deltaY = delta[1]\n        partial_nodes = nodes[max(-deltaY, 0):min(height - deltaY, height), max(-deltaX, 0):min(width - deltaX, width)].reshape(-1)\n        intensityDifferenceSum += np.sum(pow(colors[partial_nodes] - colors[partial_nodes + (deltaY * width + deltaX)], 2))\n        intensityDifferenceCount += partial_nodes.shape[0]\n        continue\n    intensityDifference = intensityDifferenceSum / intensityDifferenceCount\n\n    \n    edges = []\n    edges_features = []\n    pairwise_matrix = 1 - np.diag(np.ones(numPlanes + 1))\n\n    for delta in deltas:\n        deltaX = delta[0]\n        deltaY = delta[1]\n        partial_nodes = nodes[max(-deltaY, 0):min(height - deltaY, height), max(-deltaX, 0):min(width - deltaX, width)].reshape(-1)\n        edges.append(np.stack([partial_nodes, partial_nodes + (deltaY * width + deltaX)], axis=1))\n\n        colorDiff = np.sum(pow(colors[partial_nodes] - colors[partial_nodes + (deltaY * width + deltaX)], 2), axis=1)\n        \n        pairwise_cost = np.expand_dims(pairwise_matrix, 0) * np.reshape(1 + 45 * np.exp(-colorDiff / intensityDifference), [-1, 1, 1])\n        #pairwise_cost = np.expand_dims(pairwise_matrix, 0) * np.ones(np.reshape(1 + 45 * np.exp(-colorDiff / np.maximum(intensityDifference[partial_nodes], 1e-4)), [-1, 1, 1]).shape)\n        edges_features.append(pairwise_cost)\n        continue\n\n    edges = np.concatenate(edges, axis=0)\n    edges_features = np.concatenate(edges_features, axis=0)\n\n    if \'smoothnessWeight\' in parameters:\n        smoothnessWeight = parameters[\'smoothnessWeight\']\n    else:\n        smoothnessWeight = 0.02\n        pass\n    \n    refined_segmentation = inference_ogm(unaries, -edges_features * smoothnessWeight, edges, return_energy=False, alg=\'alphaexp\')    \n    #print(pairwise_matrix)\n    #refined_segmentation = inference_ogm(unaries * 5, -pairwise_matrix, edges, return_energy=False, alg=\'alphaexp\')\n    refined_segmentation = refined_segmentation.reshape([height, width])\n\n    if \'semantics\' in parameters and parameters[\'semantics\']:\n        for semanticIndex in xrange(semantics.max() + 1):\n            mask = semantics == semanticIndex\n            segmentInds = refined_segmentation[mask]\n            uniqueSegments, counts = np.unique(segmentInds, return_counts=True)\n            for index, count in enumerate(counts):\n                if count > segmentInds.shape[0] * 0.9:\n                    refined_segmentation[mask] = uniqueSegments[index]\n                    pass\n                continue\n            continue\n        pass\n    \n    return refined_segmentation\n\ndef calcNormal(depth, info):\n\n    height = depth.shape[0]\n    width = depth.shape[1]\n\n    camera = getCameraFromInfo(info)\n    urange = (np.arange(width, dtype=np.float32) / (width) * (camera[\'width\']) - camera[\'cx\']) / camera[\'fx\']\n    urange = urange.reshape(1, -1).repeat(height, 0)\n    vrange = (np.arange(height, dtype=np.float32) / (height) * (camera[\'height\']) - camera[\'cy\']) / camera[\'fy\']\n    vrange = vrange.reshape(-1, 1).repeat(width, 1)\n    \n    X = depth * urange\n    Y = depth\n    Z = -depth * vrange\n\n    points = np.stack([X, Y, Z], axis=2).reshape(-1, 3)\n\n    if width > 300:\n        grids = np.array([-9, -6, -3, -1, 0, 1, 3, 6, 9])\n    else:\n        grids = np.array([-5, -3, -1, 0, 1, 3, 5])\n\n    normals = []\n    for index in xrange(width * height):\n        us = index % width + grids\n        us = us[np.logical_and(us >= 0, us < width)]\n        vs = index / width + grids\n        vs = vs[np.logical_and(vs >= 0, vs < height)]\n        indices = (np.expand_dims(vs, -1) * width + np.expand_dims(us, 0)).reshape(-1)\n        planePoints = points[indices]\n        planePoints = planePoints[np.linalg.norm(planePoints, axis=-1) > 1e-4]\n\n        planePoints = planePoints[np.abs(planePoints[:, 1] - points[index][1]) < 0.05]\n        # if index == 53 * width + 183 or index == 58 * width + 183:\n        #     print(np.stack([indices % width, indices / width], axis=-1))\n        #     print(index)\n        #     print(planePoints)\n        #     print(planePoints.shape)\n        #     plane = fitPlane(planePoints)\n        #     print(plane)\n        #     print(plane / np.maximum(np.linalg.norm(plane), 1e-4))\n        #     pass\n            \n        try:\n            plane = fitPlane(planePoints)\n            normals.append(-plane / np.maximum(np.linalg.norm(plane), 1e-4))\n        except:\n            if len(normals) > 0:\n                normals.append(normals[-1])\n            else:\n                normals.append([0, -1, 0])\n                pass\n            pass\n        continue\n    normal = np.array(normals).reshape((height, width, 3))\n    return normal\n\n\ndef readProposalInfo(info, proposals):\n    numProposals = proposals.shape[-1]\n    outputShape = list(info.shape)\n    outputShape[-1] = numProposals\n    info = info.reshape([-1, info.shape[-1]])\n    proposals = proposals.reshape([-1, proposals.shape[-1]])\n    proposalInfo = []\n\n    for proposal in xrange(numProposals):\n        proposalInfo.append(info[np.arange(info.shape[0]), proposals[:, proposal]])\n        continue\n    proposalInfo = np.stack(proposalInfo, axis=1).reshape(outputShape)\n    return proposalInfo\n\n\ndef fitPlanesManhattan(image, depth, normal, info, numOutputPlanes=20, imageIndex=1, parameters={}):\n    if \'meanshift\' in parameters and parameters[\'meanshift\'] > 0:\n        import sklearn.cluster\n        meanshift = sklearn.cluster.MeanShift(parameters[\'meanshift\'])\n        pass\n\n    \n    height = depth.shape[0]\n    width = depth.shape[1]\n\n    camera = getCameraFromInfo(info)\n    urange = (np.arange(width, dtype=np.float32) / (width) * (camera[\'width\']) - camera[\'cx\']) / camera[\'fx\']\n    urange = urange.reshape(1, -1).repeat(height, 0)\n    vrange = (np.arange(height, dtype=np.float32) / (height) * (camera[\'height\']) - camera[\'cy\']) / camera[\'fy\']\n    vrange = vrange.reshape(-1, 1).repeat(width, 1)\n    \n    X = depth * urange\n    Y = depth\n    Z = -depth * vrange\n\n\n    normals = normal.reshape((-1, 3))\n    normals = normals / np.maximum(np.linalg.norm(normals, axis=-1, keepdims=True), 1e-4)\n\n    validMask = np.logical_and(np.linalg.norm(normals, axis=-1) > 1e-4, depth.reshape(-1) > 1e-4)\n    \n    valid_normals = normals[validMask]\n\n    \n    points = np.stack([X, Y, Z], axis=2).reshape(-1, 3)\n    valid_points = points[validMask]\n\n    polarAngles = np.arange(16) * np.pi / 2 / 16\n    azimuthalAngles = np.arange(64) * np.pi * 2 / 64\n    polarAngles = np.expand_dims(polarAngles, -1)\n    azimuthalAngles = np.expand_dims(azimuthalAngles, 0)\n\n    normalBins = np.stack([np.sin(polarAngles) * np.cos(azimuthalAngles), np.tile(np.cos(polarAngles), [1, azimuthalAngles.shape[1]]), -np.sin(polarAngles) * np.sin(azimuthalAngles)], axis=2)\n    normalBins = np.reshape(normalBins, [-1, 3])\n    numBins = normalBins.shape[0]\n    \n    \n    normalDiff = np.tensordot(valid_normals, normalBins, axes=([1], [1]))\n    normalDiffSign = np.sign(normalDiff)\n    normalDiff = np.maximum(normalDiff, -normalDiff)\n    normalMask = one_hot(np.argmax(normalDiff, axis=-1), numBins)\n    bins = normalMask.sum(0)\n    np.expand_dims(valid_normals, 1) * np.expand_dims(normalMask, -1)\n\n    maxNormals = np.expand_dims(valid_normals, 1) * np.expand_dims(normalMask, -1)\n    maxNormals *= np.expand_dims(normalDiffSign, -1)\n    averageNormals = maxNormals.sum(0) / np.maximum(np.expand_dims(bins, -1), 1e-4)\n    averageNormals /= np.maximum(np.linalg.norm(averageNormals, axis=-1, keepdims=True), 1e-4)\n    #print(bins.nonzero())\n    dominantNormal_1 = averageNormals[np.argmax(bins)]\n\n    dotThreshold_1 = np.cos(np.deg2rad(100))\n    dotThreshold_2 = np.cos(np.deg2rad(80))\n    \n    dot_1 = np.tensordot(normalBins, dominantNormal_1, axes=([1], [0]))\n    bins[np.logical_or(dot_1 < dotThreshold_1, dot_1 > dotThreshold_2)] = 0\n    dominantNormal_2 = averageNormals[np.argmax(bins)]\n    #print(normalBins[np.argmax(bins)])\n    #print(dominantNormal_2)\n    #exit(1)\n    dot_2 = np.tensordot(normalBins, dominantNormal_2, axes=([1], [0]))\n    bins[np.logical_or(dot_2 < dotThreshold_1, dot_2 > dotThreshold_2)] = 0\n    \n    dominantNormal_3 = averageNormals[np.argmax(bins)]\n\n\n    dominantNormals = np.stack([dominantNormal_1, dominantNormal_2, dominantNormal_3], axis=0)\n\n    dominantNormalImage = np.abs(np.matmul(normal, dominantNormals.transpose()))\n    cv2.imwrite(\'test/dominant_normal.png\', drawMaskImage(dominantNormalImage))\n    \n    planeHypothesisAreaThreshold = width * height * 0.01\n\n    \n    planes = []\n    \n    if \'offsetGap\' in parameters:\n        offsetGap = parameters[\'offsetGap\']\n    else:\n        offsetGap = 0.1\n        pass\n    for dominantNormal in dominantNormals:\n        offsets = np.tensordot(valid_points, dominantNormal, axes=([1], [0]))\n        #offsets = np.sort(offsets)\n\n        if \'meanshift\' in parameters and parameters[\'meanshift\'] > 0:\n            sampleInds = np.arange(offsets.shape[0])\n            np.random.shuffle(sampleInds)\n            meanshift.fit(np.expand_dims(offsets[sampleInds[:int(offsets.shape[0] * 0.02)]], -1))\n            for offset in meanshift.cluster_centers_:\n                planes.append(dominantNormal * offset)\n                continue\n            \n        #clusters = meanshift.fit_predict(offsets)\n        #print(clusters.score_samples(offsets))\n        #print(offsets)\n        #print(np.argmax(offsets))\n        #print(clusters.score_samples(np.array([[offsets.max()]])))\n        #print(clusters.sample(10))\n        #exit(1)\n        # for clusterIndex in xrange(clusters.max()):\n        #     clusterMask = clusters == clusterIndex\n        #     print(clusterMask.sum())\n        #     if clusterMask.sum() < planeHypothesisAreaThreshold:\n        #         continue\n        #     planeD = offsets[clusterMask].mean()\n        #     planes.append(dominantNormal * planeD)\n        #     continue\n        \n        offset = offsets.min()\n        maxOffset = offsets.max()\n        while offset < maxOffset:\n            planeMask = np.logical_and(offsets >= offset, offsets < offset + offsetGap)\n            segmentOffsets = offsets[np.logical_and(offsets >= offset, offsets < offset + offsetGap)]\n            if segmentOffsets.shape[0] < planeHypothesisAreaThreshold:\n                offset += offsetGap\n                continue\n            planeD = segmentOffsets.mean()\n            planes.append(dominantNormal * planeD)\n            offset = planeD + offsetGap\n            #print(planeD, segmentOffsets.shape[0])            \n            #cv2.imwrite(\'test/mask_\' + str(len(planes) - 1) + \'.png\', drawMaskImage(planeMask.reshape((height, width))))\n            continue\n        continue\n    \n    if len(planes) == 0:\n        return np.array([]), np.zeros(segmentation.shape).astype(np.int32)\n    \n    planes = np.array(planes)\n    print(\'number of planes \', planes.shape[0])\n\n    #transformedDominantNormals = np.matmul(info[:16].reshape(4, 4), np.transpose([np.concatenate(dominantNormals, np.ones((3, 1))], axis=1)))\n    vanishingPoints = np.stack([dominantNormals[:, 0] / np.maximum(dominantNormals[:, 1], 1e-4) * info[0] + info[2], -dominantNormals[:, 2] / np.maximum(dominantNormals[:, 1], 1e-4) * info[5] + info[6]], axis=1)\n    vanishingPoints[:, 0] *= width / info[16]\n    vanishingPoints[:, 1] *= height / info[17]\n\n    #print(dominantNormals)\n    #print(vanishingPoints)\n    #us = np.tile(np.expand_dims(np.arange(width), 0), [height, 1])\n    #vs = np.tile(np.expand_dims(np.arange(height), -1), [1, width])\n    indices = np.arange(width * height, dtype=np.int32)\n    uv = np.stack([indices % width, indices / width], axis=1)\n    colors = image.reshape((-1, 3))\n    windowW = 9\n    windowH = 3\n    dominantLineMaps = []\n    for vanishingPointIndex, vanishingPoint in enumerate(vanishingPoints):\n        horizontalDirection = uv - np.expand_dims(vanishingPoint, 0)\n        horizontalDirection = horizontalDirection / np.maximum(np.linalg.norm(horizontalDirection, axis=1, keepdims=True), 1e-4)\n        verticalDirection = np.stack([horizontalDirection[:, 1], -horizontalDirection[:, 0]], axis=1)\n\n        colorDiffs = []\n        for directionIndex, direction in enumerate([horizontalDirection, verticalDirection]):\n            neighbors = uv + direction\n            neighborsX = neighbors[:, 0]\n            neighborsY = neighbors[:, 1]\n            neighborsMinX = np.maximum(np.minimum(np.floor(neighborsX).astype(np.int32), width - 1), 0)\n            neighborsMaxX = np.maximum(np.minimum(np.ceil(neighborsX).astype(np.int32), width - 1), 0)\n            neighborsMinY = np.maximum(np.minimum(np.floor(neighborsY).astype(np.int32), height - 1), 0)\n            neighborsMaxY = np.maximum(np.minimum(np.ceil(neighborsY).astype(np.int32), height - 1), 0)\n            indices_1 = neighborsMinY * width + neighborsMinX\n            indices_2 = neighborsMaxY * width + neighborsMinX\n            indices_3 = neighborsMinY * width + neighborsMaxX            \n            indices_4 = neighborsMaxY * width + neighborsMaxX\n            areas_1 = (neighborsMaxX - neighborsX) * (neighborsMaxY - neighborsY)\n            areas_2 = (neighborsMaxX - neighborsX) * (neighborsY - neighborsMinY)\n            areas_3 = (neighborsX - neighborsMinX) * (neighborsMaxY - neighborsY)\n            areas_4 = (neighborsX - neighborsMinX) * (neighborsY - neighborsMinY)\n\n            neighborsColor = colors[indices_1] * np.expand_dims(areas_1, -1) + colors[indices_2] * np.expand_dims(areas_2, -1) + colors[indices_3] * np.expand_dims(areas_3, -1) + colors[indices_4] * np.expand_dims(areas_4, -1)\n            colorDiff = np.linalg.norm(neighborsColor - colors, axis=-1)\n\n            #cv2.imwrite(\'test/color_diff_\' + str(vanishingPointIndex) + \'_\' + str(directionIndex) + \'.png\', drawMaskImage(colorDiff.reshape((height, width)) / 100))\n            colorDiffs.append(colorDiff)\n            continue\n        colorDiffs = np.stack(colorDiffs, 1)\n\n        deltaUs, deltaVs = np.meshgrid(np.arange(windowW) - (windowW - 1) / 2, np.arange(windowH) - (windowH - 1) / 2)\n        deltas = deltaUs.reshape((1, -1, 1)) * np.expand_dims(horizontalDirection, axis=1) + deltaVs.reshape((1, -1, 1)) * np.expand_dims(verticalDirection, axis=1)\n        \n        windowIndices = np.expand_dims(uv, 1) - deltas\n        windowIndices = (np.minimum(np.maximum(np.round(windowIndices[:, :, 1]), 0), height - 1) * width + np.minimum(np.maximum(np.round(windowIndices[:, :, 0]), 0), width - 1)).astype(np.int32)\n        \n        dominantLineMap = []\n\n        # index = 361 * width + 146\n        # mask = np.zeros((height * width))\n        # mask[windowIndices[index]] = 1\n        # cv2.imwrite(\'test/mask.png\', drawMaskImage(mask.reshape((height, width))))\n        # exit(1)\n        for pixels in windowIndices:\n            gradientSums = colorDiffs[pixels].sum(0)\n            dominantLineMap.append(gradientSums[1] / max(gradientSums[0], 1e-4))\n            continue\n        dominantLineMaps.append(np.array(dominantLineMap).reshape((height, width)))\n        # dominantLines = []\n        # for pixel in uv:\n        #     sums = colorDiffs[:, max(pixel[1] - windowSize, 0):min(pixel[1] + windowSize + 1, height - 1), max(pixel[0] - windowSize, 0):min(pixel[0] + windowSize + 1, width - 1)].sum(1).sum(1)\n        #     dominantLines.append(sums[1] / np.maximum(sums[0], 1e-4))\n        #     continue\n        # dominantLines = np.array(dominantLines).reshape((height, width))\n        # smoothnessWeightMask = np.logical_or(smoothnessWeightMask, dominantLines > 5)\n        \n        #cv2.imwrite(\'test/dominant_lines_\' + str(vanishingPointIndex) + \'.png\', drawMaskImage(dominantLines / 5))        \n        continue\n    dominantLineMaps = np.stack(dominantLineMaps, axis=2)\n    #cv2.imwrite(\'test/dominant_lines.png\', drawMaskImage(dominantLineMaps / 5))\n    if \'dominantLineThreshold\' in parameters:\n        dominantLineThreshold = parameters[\'dominantLineThreshold\']\n    else:\n        dominantLineThreshold = 3\n        pass\n    \n    if imageIndex >= 0:\n        cv2.imwrite(\'test/\' + str(imageIndex) + \'_dominant_lines.png\', drawMaskImage(dominantLineMaps / dominantLineThreshold))\n    else:\n        cv2.imwrite(\'test/dominant_lines.png\', drawMaskImage(dominantLineMaps / dominantLineThreshold))\n        pass\n    \n    smoothnessWeightMask = dominantLineMaps.max(2) > dominantLineThreshold\n    cv2.imwrite(\'test/dominant_lines_mask.png\', drawMaskImage(smoothnessWeightMask))    \n    \n    planesD = np.linalg.norm(planes, axis=1, keepdims=True)\n    planeNormals = planes / np.maximum(planesD, 1e-4)\n\n\n    if \'distanceCostThreshold\' in parameters:\n        distanceCostThreshold = parameters[\'distanceCostThreshold\']\n    else:\n        distanceCostThreshold = 0.05\n        pass\n    \n    distanceCost = np.abs(np.tensordot(points, planeNormals, axes=([1, 1])) - np.reshape(planesD, [1, -1])) / distanceCostThreshold\n    #distanceCost = np.concatenate([distanceCost, np.ones((height * width, 1))], axis=1)\n\n    normalCost = 0\n    normalCostThreshold = 1 - np.cos(np.deg2rad(30))        \n    normalCost = (1 - np.abs(np.tensordot(normals, planeNormals, axes=([1, 1])))) / normalCostThreshold\n    \n    unaryCost = distanceCost + normalCost\n    unaryCost *= np.expand_dims(validMask.astype(np.float32), -1)\n    unaries = unaryCost.reshape((width * height, -1))\n\n    cv2.imwrite(\'test/distance_cost.png\', drawSegmentationImage(-distanceCost.reshape((height, width, -1)), unaryCost.shape[-1] - 1))\n    cv2.imwrite(\'test/normal_cost.png\', drawSegmentationImage(-normalCost.reshape((height, width, -1)), unaryCost.shape[-1] - 1))\n    cv2.imwrite(\'test/unary_cost.png\', drawSegmentationImage(-unaryCost.reshape((height, width, -1)), blackIndex=unaryCost.shape[-1] - 1))\n\n    cv2.imwrite(\'test/segmentation.png\', drawSegmentationImage(-unaries.reshape((height, width, -1)), blackIndex=unaries.shape[-1]))\n    \n    #cv2.imwrite(\'test/mask.png\', drawSegmentationImage(planeMasks.reshape((height, width, -1))))\n    #exit(1)\n\n    if \'numProposals\' in parameters:\n        numProposals = parameters[\'numProposals\']\n    else:\n        numProposals = 3\n        pass\n    numProposals = min(numProposals, unaries.shape[-1] - 1)\n    proposals = np.argpartition(unaries, numProposals)[:, :numProposals]\n    proposals[np.logical_not(validMask)] = 0\n    \n    unaries = -readProposalInfo(unaries, proposals).reshape((-1, numProposals))\n    \n    nodes = np.arange(height * width).reshape((height, width))\n\n    #deltas = [(0, 1), (1, 0), (-1, 1), (1, 1)]\n    deltas = [(0, 1), (1, 0)]\n    \n    edges = []\n    edges_features = []\n    smoothnessWeights = 1 - 0.99 * smoothnessWeightMask.astype(np.float32)\n    \n    #edges_features = np.concatenate(edges_features, axis=0)\n    #print(proposals.shape)\n    #print(unaries.shape)    \n    #print(width * height)\n    for delta in deltas:\n        deltaX = delta[0]\n        deltaY = delta[1]\n        partial_nodes = nodes[max(-deltaY, 0):min(height - deltaY, height), max(-deltaX, 0):min(width - deltaX, width)].reshape(-1)\n        edges.append(np.stack([partial_nodes, partial_nodes + (deltaY * width + deltaX)], axis=1))\n\n        labelDiff = (np.expand_dims(proposals[partial_nodes], -1) != np.expand_dims(proposals[partial_nodes + (deltaY * width + deltaX)], 1)).astype(np.float32)\n        #labelDiff = labelDiff.transpose([0, 2, 1])\n        #print(labelDiff.shape)\n        edges_features.append(labelDiff * smoothnessWeights.reshape((width * height, -1))[partial_nodes].reshape(-1, 1, 1))\n        continue\n\n    #exit(1)\n\n    edges = np.concatenate(edges, axis=0)\n    edges_features = np.concatenate(edges_features, axis=0)\n\n\n    # y = 71\n    # x = 145\n    # print(proposals[y * width + x])\n    # print(unaries[y * width + x] * 10000)\n    # print(proposals[(y + 1) * width + x])\n    # print(unaries[(y + 1) * width + x] * 10000)    \n    # print(edges_features[y * width + x])\n\n    if \'smoothnessWeight\' in parameters:\n        smoothnessWeight = parameters[\'smoothnessWeight\']\n    else:\n        smoothnessWeight = 40\n        pass\n    \n    refined_segmentation = inference_ogm(unaries, -edges_features * smoothnessWeight, edges, return_energy=False, alg=\'trw\')\n\n    refined_segmentation = refined_segmentation.reshape([height, width, 1])\n    refined_segmentation = readProposalInfo(proposals, refined_segmentation)\n    #print(pairwise_matrix)\n    #refined_segmentation = inference_ogm(unaries * 5, -pairwise_matrix, edges, return_energy=False, alg=\'alphaexp\')\n    planeSegmentation = refined_segmentation.reshape([height, width])\n\n    planeSegmentation[np.logical_not(validMask.reshape((height, width)))] = planes.shape[0]\n\n    cv2.imwrite(\'test/segmentation_refined.png\', drawSegmentationImage(planeSegmentation))\n    #exit(1)\n\n    # if planes.shape[0] > numOutputPlanes:\n    #     planeInfo = []\n    #     for planeIndex in xrange(planes.shape[0]):\n    #         mask = planeSegmentation == planeIndex\n    #         planeInfo.append((planes[planeIndex], mask))\n    #         continue\n    #     planeInfo = sorted(planeInfo, key=lambda x: -x[1].sum())\n    #     newPlanes = []\n    #     newPlaneSegmentation = np.full(planeSegmentation.shape, numOutputPlanes)\n    #     for planeIndex in xrange(numOutputPlanes):\n    #         newPlanes.append(planeInfo[planeIndex][0])\n    #         newPlaneSegmentation[planeInfo[planeIndex][1]] = planeIndex\n    #         continue\n    #     planeSegmentation = newPlaneSegmentation\n    #     planes = np.array(newPlanes)\n    # else:\n    #     planeSegmentation[planeSegmentation == planes.shape[0]] = numOutputPlanes\n    #     pass\n\n    # if planes.shape[0] < numOutputPlanes:\n    #     planes = np.concatenate([planes, np.zeros((numOutputPlanes - planes.shape[0], 3))], axis=0)\n    #     pass\n\n    \n    # planeDepths = calcPlaneDepths(planes, width, height, info)\n    \n    # allDepths = np.concatenate([planeDepths, np.expand_dims(depth, -1)], axis=2)\n    # depthPred = allDepths.reshape([height * width, planes.shape[0] + 1])[np.arange(width * height), planeSegmentation.astype(np.int32).reshape(-1)].reshape(height, width)\n\n\n    # planeNormals = calcPlaneNormals(planes, width, height)\n    # allNormals = np.concatenate([planeNormals, np.expand_dims(normal, 2)], axis=2)\n    # normalPred = allNormals.reshape(-1, planes.shape[0] + 1, 3)[np.arange(width * height), planeSegmentation.reshape(-1)].reshape((height, width, 3))\n    \n    return planes, planeSegmentation\n\n\ndef calcVanishingPoint(lines):\n    points = lines[:, :2]\n    normals = lines[:, 2:4] - lines[:, :2]\n    normals /= np.maximum(np.linalg.norm(normals, axis=-1, keepdims=True), 1e-4)\n    normals = np.stack([normals[:, 1], -normals[:, 0]], axis=1)\n    normalPointDot = (normals * points).sum(1)\n\n    if lines.shape[0] == 2:\n        VP = np.linalg.solve(normals, normalPointDot)\n    else:\n        VP = np.linalg.lstsq(normals, normalPointDot)[0]\n        pass\n    \n    # print(lines)\n    # print(points)\n    # print(normals)\n    # print(VP)\n    # exit(1)\n    return VP\n    \ndef calcVanishingPoints(allLines, numVPs):\n    distanceThreshold = np.sin(np.deg2rad(5))\n    lines = allLines.copy()\n    VPs = []\n    VPLines = []\n    for VPIndex in xrange(numVPs):\n        points = lines[:, :2]\n        lengths = np.linalg.norm(lines[:, 2:4] - lines[:, :2], axis=-1)\n        normals = lines[:, 2:4] - lines[:, :2]\n        normals /= np.maximum(np.linalg.norm(normals, axis=-1, keepdims=True), 1e-4)\n        normals = np.stack([normals[:, 1], -normals[:, 0]], axis=1)\n        maxNumInliers = 0\n        bestVP = np.zeros(2)\n        #for _ in xrange(int(np.sqrt(lines.shape[0]))):\n        for _ in xrange(min(pow(lines.shape[0], 2), 100)):\n            sampledInds = np.random.choice(lines.shape[0], 2)\n            if sampledInds[0] == sampledInds[1]:\n                continue\n            sampledLines = lines[sampledInds]\n            try:\n                VP = calcVanishingPoint(sampledLines)\n            except:\n                continue\n\n            inliers = np.abs(((np.expand_dims(VP, 0) - points) * normals).sum(-1)) / np.linalg.norm(np.expand_dims(VP, 0) - points, axis=-1) < distanceThreshold\n            # print(sampledLines)\n            # print(VP)\n            # print(normals[inliers])\n            # exit(1)\n            \n            #numInliers = inliers.sum()\n            numInliers = lengths[inliers].sum()\n            if numInliers > maxNumInliers:\n                maxNumInliers = numInliers\n                bestVP = VP\n                bestVPInliers = inliers\n                pass\n            continue\n        if maxNumInliers > 0:\n            inlierLines = lines[bestVPInliers]\n            VP = calcVanishingPoint(inlierLines)\n            VPs.append(VP)\n            #print(bestVP)\n            #print(inlierLines)\n            #print(VP)\n            #exit(1)\n            VPLines.append(inlierLines)\n            lines = lines[np.logical_not(bestVPInliers)]\n            pass\n        continue\n    VPs = np.stack(VPs, axis=0)\n    return VPs, VPLines, lines\n    \ndef fitPlanesPiecewise(image, depth, normal, info, numOutputPlanes=20, imageIndex=1, parameters={}):\n    if \'meanshift\' in parameters and parameters[\'meanshift\'] > 0:\n        import sklearn.cluster\n        meanshift = sklearn.cluster.MeanShift(parameters[\'meanshift\'])\n        pass\n    \n    #import sklearn.neighbors    \n    #meanshift = sklearn.neighbors.KernelDensity(0.05)\n    from pylsd import lsd\n    \n    height = depth.shape[0]\n    width = depth.shape[1]\n\n    camera = getCameraFromInfo(info)\n    urange = (np.arange(width, dtype=np.float32) / (width) * (camera[\'width\']) - camera[\'cx\']) / camera[\'fx\']\n    urange = urange.reshape(1, -1).repeat(height, 0)\n    vrange = (np.arange(height, dtype=np.float32) / (height) * (camera[\'height\']) - camera[\'cy\']) / camera[\'fy\']\n    vrange = vrange.reshape(-1, 1).repeat(width, 1)\n    \n    X = depth * urange\n    Y = depth\n    Z = -depth * vrange\n\n\n    normals = normal.reshape((-1, 3))\n    normals = normals / np.maximum(np.linalg.norm(normals, axis=-1, keepdims=True), 1e-4)\n    validMask = np.logical_and(np.linalg.norm(normals, axis=-1) > 1e-4, depth.reshape(-1) > 1e-4)\n    \n    points = np.stack([X, Y, Z], axis=2).reshape(-1, 3)\n    valid_points = points[validMask]\n    \n    lines = lsd(image.mean(2))\n\n    lineImage = image.copy()\n    for line in lines:\n        cv2.line(lineImage, (int(line[0]), int(line[1])), (int(line[2]), int(line[3])), (0, 0, 255), int(np.ceil(line[4] / 2)))\n        continue\n    cv2.imwrite(\'test/lines.png\', lineImage)\n\n    numVPs = 3\n    VPs, VPLines, remainingLines = calcVanishingPoints(lines, numVPs=numVPs)\n\n    lineImage = image.copy()    \n    for VPIndex, lines in enumerate(VPLines):\n        for line in lines:\n            cv2.line(lineImage, (int(line[0]), int(line[1])), (int(line[2]), int(line[3])), ((VPIndex == 0) * 255, (VPIndex == 1) * 255, (VPIndex == 2) * 255), int(np.ceil(line[4] / 2)))\n            continue\n        continue\n    cv2.imwrite(\'test/lines_vp.png\', lineImage)    \n    #exit(1)\n\n    dominantNormals = np.stack([(VPs[:, 0] * info[16] / width - info[2]) / info[0], np.ones(numVPs), -(VPs[:, 1] * info[17] / height - info[6]) / info[5]], axis=1)\n    dominantNormals /= np.maximum(np.linalg.norm(dominantNormals, axis=1, keepdims=True), 1e-4)\n\n    dotThreshold = np.cos(np.deg2rad(20))\n    for normalIndex, crossNormals in enumerate([[1, 2], [2, 0], [0, 1]]):\n        normal = np.cross(dominantNormals[crossNormals[0]], dominantNormals[crossNormals[1]])\n        normal = normalize(normal)\n        if np.dot(normal, dominantNormals[normalIndex]) < dotThreshold:\n            dominantNormals = np.concatenate([dominantNormals, np.expand_dims(normal, 0)], axis=0)\n            pass\n        continue\n\n    print(VPs)\n    print(dominantNormals)\n    \n    dominantNormalImage = np.abs(np.matmul(normal, dominantNormals.transpose()))\n    cv2.imwrite(\'test/dominant_normal.png\', drawMaskImage(dominantNormalImage))\n    #exit(1)\n    \n    planeHypothesisAreaThreshold = width * height * 0.01\n    \n    planes = []\n    vpPlaneIndices = []\n    if \'offsetGap\' in parameters:\n        offsetGap = parameters[\'offsetGap\']\n    else:\n        offsetGap = 0.1\n        pass\n    planeIndexOffset = 0\n\n    for dominantNormal in dominantNormals:\n        if np.linalg.norm(dominantNormal) < 1e-4:\n            continue\n        offsets = np.tensordot(valid_points, dominantNormal, axes=([1], [0]))\n\n        if \'meanshift\' in parameters and parameters[\'meanshift\'] > 0:\n            sampleInds = np.arange(offsets.shape[0])\n            np.random.shuffle(sampleInds)\n            meanshift.fit(np.expand_dims(offsets[sampleInds[:int(offsets.shape[0] * 0.02)]], -1))\n            for offset in meanshift.cluster_centers_:\n                planes.append(dominantNormal * offset)\n                continue\n        else:\n            offset = offsets.min()\n            maxOffset = offsets.max()\n            while offset < maxOffset:\n                planeMask = np.logical_and(offsets >= offset, offsets < offset + offsetGap)\n                segmentOffsets = offsets[np.logical_and(offsets >= offset, offsets < offset + offsetGap)]\n                if segmentOffsets.shape[0] < planeHypothesisAreaThreshold:\n                    offset += offsetGap\n                    continue\n                planeD = segmentOffsets.mean()\n                planes.append(dominantNormal * planeD)\n                offset = planeD + offsetGap\n\n                #print(planeD, segmentOffsets.shape[0])            \n                #cv2.imwrite(\'test/mask_\' + str(len(planes) - 1) + \'.png\', drawMaskImage(planeMask.reshape((height, width))))\n                continue\n            pass\n        \n\n        vpPlaneIndices.append(np.arange(planeIndexOffset, len(planes)))\n        planeIndexOffset = len(planes)\n        continue\n\n    if len(planes) == 0:\n        return np.array([]), np.zeros(segmentation.shape).astype(np.int32)    \n    planes = np.array(planes)\n\n    \n    \n    planesD = np.linalg.norm(planes, axis=1, keepdims=True)\n    planeNormals = planes / np.maximum(planesD, 1e-4)\n\n    if \'distanceCostThreshold\' in parameters:\n        distanceCostThreshold = parameters[\'distanceCostThreshold\']\n    else:\n        distanceCostThreshold = 0.05\n        pass\n\n    # print(planes)\n    # print(np.abs(np.tensordot(points, planeNormals, axes=([1, 1])) - np.reshape(planesD, [1, -1])).max())\n    # print(np.abs(np.tensordot(points, planeNormals, axes=([1, 1])) - np.reshape(planesD, [1, -1])).min())\n    # print(distanceCostThreshold)\n\n    distanceCost = np.abs(np.tensordot(points, planeNormals, axes=([1, 1])) - np.reshape(planesD, [1, -1])) / distanceCostThreshold\n    #distanceCost = np.concatenate([distanceCost, np.ones((height * width, 1))], axis=1)\n\n\n    #valid_normals = normals[validMask]\n    normalCostThreshold = 1 - np.cos(np.deg2rad(30))        \n    normalCost = (1 - np.abs(np.tensordot(normals, planeNormals, axes=([1, 1])))) / normalCostThreshold\n\n    if \'normalWeight\' in parameters:\n        normalWeight = parameters[\'normalWeight\']\n    else:\n        normalWeight = 1\n        pass\n    \n    unaryCost = distanceCost + normalCost * normalWeight\n    unaryCost *= np.expand_dims(validMask.astype(np.float32), -1)    \n    unaries = unaryCost.reshape((width * height, -1))\n    \n    \n    print(\'number of planes \', planes.shape[0])\n    cv2.imwrite(\'test/distance_cost.png\', drawSegmentationImage(-distanceCost.reshape((height, width, -1)), unaryCost.shape[-1] - 1))\n\n    cv2.imwrite(\'test/normal_cost.png\', drawSegmentationImage(-normalCost.reshape((height, width, -1)), unaryCost.shape[-1] - 1))\n\n    cv2.imwrite(\'test/unary_cost.png\', drawSegmentationImage(-unaryCost.reshape((height, width, -1)), blackIndex=unaryCost.shape[-1] - 1))\n\n    cv2.imwrite(\'test/segmentation.png\', drawSegmentationImage(-unaries.reshape((height, width, -1)), blackIndex=unaries.shape[-1]))\n    \n    #cv2.imwrite(\'test/mask.png\', drawSegmentationImage(planeMasks.reshape((height, width, -1))))\n    #exit(1)\n\n\n    if \'numProposals\' in parameters:\n        numProposals = parameters[\'numProposals\']\n    else:\n        numProposals = 3\n        pass\n\n    numProposals = min(numProposals, unaries.shape[-1] - 1)\n    \n    proposals = np.argpartition(unaries, numProposals)[:, :numProposals]\n    unaries = -readProposalInfo(unaries, proposals).reshape((-1, numProposals))\n    \n    nodes = np.arange(height * width).reshape((height, width))\n\n    #deltas = [(0, 1), (1, 0), (-1, 1), (1, 1)]\n    deltas = [(0, 1), (1, 0)]\n    \n    edges = []\n    edges_features = []\n            \n                \n    #edges_features = np.concatenate(edges_features, axis=0)\n    for delta in deltas:\n        deltaX = delta[0]\n        deltaY = delta[1]\n        partial_nodes = nodes[max(-deltaY, 0):min(height - deltaY, height), max(-deltaX, 0):min(width - deltaX, width)].reshape(-1)\n        edges.append(np.stack([partial_nodes, partial_nodes + (deltaY * width + deltaX)], axis=1))\n\n        labelDiff = (np.expand_dims(proposals[partial_nodes], -1) != np.expand_dims(proposals[partial_nodes + (deltaY * width + deltaX)], 1)).astype(np.float32)\n\n        \n        edges_features.append(labelDiff)\n        continue\n\n    edges = np.concatenate(edges, axis=0)\n    edges_features = np.concatenate(edges_features, axis=0)\n\n\n    if \'edgeWeights\' in parameters:\n        edgeWeights = parameters[\'edgeWeights\']\n    else:\n        edgeWeights = [0.5, 0.6, 0.6]\n        pass    \n    \n    lineSets = np.zeros((height * width, 3))\n    creaseLines = np.expand_dims(np.stack([planeNormals[:, 0] / info[0], planeNormals[:, 1], -planeNormals[:, 2] / info[5]], axis=1), 1) * planesD.reshape((1, -1, 1))\n    creaseLines = creaseLines - np.transpose(creaseLines, [1, 0, 2])    \n    for planeIndex_1 in xrange(planes.shape[0]):\n        for planeIndex_2 in xrange(planeIndex_1 + 1, planes.shape[0]):\n            creaseLine = creaseLines[planeIndex_1, planeIndex_2]\n            if abs(creaseLine[0]) > abs(creaseLine[2]):\n                vs = np.arange(height)\n                us = -(creaseLine[1] + (vs - info[6]) * creaseLine[2]) / creaseLine[0] + info[2]\n                minUs = np.floor(us).astype(np.int32)\n                maxUs = minUs + 1\n                validIndicesMask = np.logical_and(minUs >= 0, maxUs < width)\n                if validIndicesMask.sum() == 0:\n                    continue\n                vs = vs[validIndicesMask]\n                minUs = minUs[validIndicesMask]\n                maxUs = maxUs[validIndicesMask]\n                edgeIndices = (height - 1) * width + (vs * (width - 1) + minUs)\n                for index, edgeIndex in enumerate(edgeIndices):\n                    pixel_1 = vs[index] * width + minUs[index]\n                    pixel_2 = vs[index] * width + maxUs[index]\n                    proposals_1 = proposals[pixel_1]\n                    proposals_2 = proposals[pixel_2]                    \n                    if planeIndex_1 in proposals_1 and planeIndex_2 in proposals_2:\n                        proposalIndex_1 = np.where(proposals_1 == planeIndex_1)[0][0]\n                        proposalIndex_2 = np.where(proposals_2 == planeIndex_2)[0][0]\n                        edges_features[edgeIndex, proposalIndex_1, proposalIndex_2] *= edgeWeights[0]\n                        pass\n                    if planeIndex_2 in proposals_1 and planeIndex_1 in proposals_2:\n                        proposalIndex_1 = np.where(proposals_1 == planeIndex_2)[0][0]\n                        proposalIndex_2 = np.where(proposals_2 == planeIndex_1)[0][0]\n                        edges_features[edgeIndex, proposalIndex_1, proposalIndex_2] *= edgeWeights[0]\n                        pass\n                    continue\n\n                lineSets[vs * width + minUs, 0] = 1\n                lineSets[vs * width + maxUs, 0] = 1\n            else:\n                us = np.arange(width)\n                vs = -(creaseLine[1] + (us - info[2]) * creaseLine[0]) / creaseLine[2] + info[6]\n                minVs = np.floor(vs).astype(np.int32)\n                maxVs = minVs + 1\n                validIndicesMask = np.logical_and(minVs >= 0, maxVs < height)\n                if validIndicesMask.sum() == 0:\n                    continue                \n                us = us[validIndicesMask]\n                minVs = minVs[validIndicesMask]\n                maxVs = maxVs[validIndicesMask]                \n                edgeIndices = (minVs * width + us)\n                for index, edgeIndex in enumerate(edgeIndices):\n                    pixel_1 = minVs[index] * width + us[index]\n                    pixel_2 = maxVs[index] * width + us[index]\n                    proposals_1 = proposals[pixel_1]\n                    proposals_2 = proposals[pixel_2]                    \n                    if planeIndex_1 in proposals_1 and planeIndex_2 in proposals_2:\n                        proposalIndex_1 = np.where(proposals_1 == planeIndex_1)[0][0]\n                        proposalIndex_2 = np.where(proposals_2 == planeIndex_2)[0][0]\n                        edges_features[edgeIndex, proposalIndex_1, proposalIndex_2] *= edgeWeights[0]\n                        pass\n                    if planeIndex_2 in proposals_1 and planeIndex_1 in proposals_2:\n                        proposalIndex_1 = np.where(proposals_1 == planeIndex_2)[0][0]\n                        proposalIndex_2 = np.where(proposals_2 == planeIndex_1)[0][0]\n                        edges_features[edgeIndex, proposalIndex_1, proposalIndex_2] *= edgeWeights[0]\n                        pass\n                    continue\n                lineSets[minVs * width + us, 0] = 1\n                lineSets[maxVs * width + us, 0] = 1                \n                pass\n            continue\n        continue\n\n\n    \n    planeDepths = calcPlaneDepths(planes, width, height, info).reshape((height * width, -1))\n    planeDepths = readProposalInfo(planeDepths, proposals).reshape((-1, numProposals))\n\n    planeHorizontalVPMask = np.ones((planes.shape[0], 3), dtype=np.bool)\n    for VPIndex, planeIndices in enumerate(vpPlaneIndices):\n        planeHorizontalVPMask[planeIndices] = False\n        continue\n\n    \n    for VPIndex, lines in enumerate(VPLines):\n        lp = lines[:, :2]\n        ln = lines[:, 2:4] - lines[:, :2]\n        ln /= np.maximum(np.linalg.norm(ln, axis=-1, keepdims=True), 1e-4)\n        ln = np.stack([ln[:, 1], -ln[:, 0]], axis=1)\n        lnp = (ln * lp).sum(1, keepdims=True)\n        occlusionLines = np.concatenate([ln, lnp], axis=1)\n        for occlusionLine in occlusionLines:\n            if abs(occlusionLine[0]) > abs(occlusionLine[1]):\n                vs = np.arange(height)\n                us = (occlusionLine[2] - vs * occlusionLine[1]) / occlusionLine[0]\n                minUs = np.floor(us).astype(np.int32)\n                maxUs = minUs + 1\n                validIndicesMask = np.logical_and(minUs >= 0, maxUs < width)\n                vs = vs[validIndicesMask]\n                minUs = minUs[validIndicesMask]\n                maxUs = maxUs[validIndicesMask]                \n                edgeIndices = (height - 1) * width + (vs * (width - 1) + minUs)\n                for index, edgeIndex in enumerate(edgeIndices):\n                    pixel_1 = vs[index] * width + minUs[index]\n                    pixel_2 = vs[index] * width + maxUs[index]\n                    proposals_1 = proposals[pixel_1]\n                    proposals_2 = proposals[pixel_2]                    \n                    for proposalIndex_1, planeIndex_1 in enumerate(proposals_1):\n                        if not planeHorizontalVPMask[planeIndex_1][VPIndex]:\n                            continue\n                        planeDepth_1 = planeDepths[pixel_1][proposalIndex_1]\n                        for proposalIndex_2, planeIndex_2 in enumerate(proposals_2):\n                            if planeDepths[pixel_2][proposalIndex_2] > planeDepth_1:\n                                edges_features[edgeIndex, proposalIndex_1, proposalIndex_2] *= edgeWeights[1]\n                                pass\n                            continue\n                        continue\n                    continue\n                lineSets[vs * width + minUs, 1] = 1\n                lineSets[vs * width + maxUs, 1] = 1\n            else:\n                us = np.arange(width)\n                vs = (occlusionLine[2] - us * occlusionLine[0]) / occlusionLine[1]\n                \n                minVs = np.floor(vs).astype(np.int32)\n                maxVs = minVs + 1\n                validIndicesMask = np.logical_and(minVs >= 0, maxVs < height)\n                us = us[validIndicesMask]\n                minVs = minVs[validIndicesMask]\n                maxVs = maxVs[validIndicesMask]                \n                edgeIndices = (minVs * width + us)\n                for index, edgeIndex in enumerate(edgeIndices):\n                    pixel_1 = minVs[index] * width + us[index]\n                    pixel_2 = maxVs[index] * width + us[index]\n                    proposals_1 = proposals[pixel_1]\n                    proposals_2 = proposals[pixel_2]                    \n                    for proposalIndex_1, planeIndex_1 in enumerate(proposals_1):\n                        if not planeHorizontalVPMask[planeIndex_1][VPIndex]:\n                            continue\n                        planeDepth_1 = planeDepths[pixel_1][proposalIndex_1]\n                        for proposalIndex_2, planeIndex_2 in enumerate(proposals_2):\n                            if planeDepths[pixel_2][proposalIndex_2] > planeDepth_1:\n                                edges_features[edgeIndex, proposalIndex_1, proposalIndex_2] *= edgeWeights[1]\n                                pass\n                            continue\n                        continue\n                    continue\n                lineSets[minVs * width + us, 1] = 1\n                lineSets[maxVs * width + us, 1] = 1                \n                pass\n            continue\n        continue\n\n    # lp = remainingLines[:, :2]\n    # ln = remainingLines[:, 2:4] - remainingLines[:, :2]\n    # ln /= np.maximum(np.linalg.norm(ln, axis=-1, keepdims=True), 1e-4)\n    # ln = np.stack([ln[:, 1], -ln[:, 0]], axis=1)\n    # lnp = (ln * lp).sum(1, keepdims=True)\n    # occusionLines = np.concatenate([ln, lnp], axis=1)\n\n    for line in remainingLines:\n        if abs(line[3] - line[1]) > abs(line[2] - line[0]):\n            if line[3] < line[1]:\n                line = np.array([line[2], line[3], line[0], line[1]])\n                pass\n            vs = np.arange(line[1], line[3] + 1, dtype=np.int32)\n            us = line[0] + (vs - line[1]) / (line[3] - line[1]) * (line[2] - line[0])\n            minUs = np.floor(us).astype(np.int32)\n            maxUs = minUs + 1\n            validIndicesMask = np.logical_and(minUs >= 0, maxUs < width)\n            vs = vs[validIndicesMask]\n            minUs = minUs[validIndicesMask]\n            maxUs = maxUs[validIndicesMask]                \n            edgeIndices = (height - 1) * width + (vs * (width - 1) + minUs)\n            for edgeIndex in edgeIndices:\n                edges_features[edgeIndex] *= edgeWeights[2]\n                continue\n            lineSets[(vs * width + minUs), 2] = 1\n            lineSets[(vs * width + maxUs), 2] = 1            \n        else:\n            if line[2] < line[0]:\n                line = np.array([line[2], line[3], line[0], line[1]])\n                pass\n            us = np.arange(line[0], line[2] + 1, dtype=np.int32)\n            vs = line[1] + (us - line[0]) / (line[2] - line[0]) * (line[3] - line[1])\n            \n            minVs = np.floor(vs).astype(np.int32)\n            maxVs = minVs + 1\n            validIndicesMask = np.logical_and(minVs >= 0, maxVs < height)\n            us = us[validIndicesMask]\n            minVs = minVs[validIndicesMask]\n            maxVs = maxVs[validIndicesMask]\n            edgeIndices = (minVs * width + us)\n            for edgeIndex in edgeIndices:\n                edges_features[edgeIndex] *= edgeWeights[2]\n                continue\n            lineSets[minVs * width + us, 2] = 1\n            lineSets[maxVs * width + us, 2] = 1\n            continue\n        continue\n    cv2.imwrite(\'test/line_sets.png\', drawMaskImage(lineSets.reshape((height, width, 3))))\n    \n\n    if \'smoothnessWeight\' in parameters:\n        smoothnessWeight = parameters[\'smoothnessWeight\']\n    else:\n        smoothnessWeight = 4\n        pass\n    \n    refined_segmentation = inference_ogm(unaries, -edges_features * smoothnessWeight, edges, return_energy=False, alg=\'trw\')\n    refined_segmentation = refined_segmentation.reshape([height, width, 1])    \n    refined_segmentation = readProposalInfo(proposals, refined_segmentation)\n    #print(pairwise_matrix)\n    #refined_segmentation = inference_ogm(unaries * 5, -pairwise_matrix, edges, return_energy=False, alg=\'alphaexp\')\n    planeSegmentation = refined_segmentation.reshape([height, width])\n\n    planeSegmentation[np.logical_not(validMask.reshape((height, width)))] = planes.shape[0]    \n    cv2.imwrite(\'test/segmentation_refined.png\', drawSegmentationImage(planeSegmentation))\n    #exit(1)\n\n    # if planes.shape[0] > numOutputPlanes:\n    #     planeInfo = []\n    #     for planeIndex in xrange(planes.shape[0]):\n    #         mask = planeSegmentation == planeIndex\n    #         planeInfo.append((planes[planeIndex], mask))\n    #         continue\n    #     planeInfo = sorted(planeInfo, key=lambda x: -x[1].sum())\n    #     newPlanes = []\n    #     newPlaneSegmentation = np.full(planeSegmentation.shape, numOutputPlanes)\n    #     for planeIndex in xrange(numOutputPlanes):\n    #         newPlanes.append(planeInfo[planeIndex][0])\n    #         newPlaneSegmentation[planeInfo[planeIndex][1]] = planeIndex\n    #         continue\n    #     planeSegmentation = newPlaneSegmentation\n    #     planes = np.array(newPlanes)\n    # else:\n    #     planeSegmentation[planeSegmentation == planes.shape[0]] = numOutputPlanes\n    #     pass\n\n    # if planes.shape[0] < numOutputPlanes:\n    #     planes = np.concatenate([planes, np.zeros((numOutputPlanes - planes.shape[0], 3))], axis=0)\n    #     pass\n\n    # planeDepths = calcPlaneDepths(planes, width, height, info)\n    \n    # allDepths = np.concatenate([planeDepths, np.expand_dims(depth, -1)], axis=2)\n    # depthPred = allDepths.reshape([height * width, numOutputPlanes + 1])[np.arange(width * height), planeSegmentation.astype(np.int32).reshape(-1)].reshape(height, width)\n\n\n    # planeNormals = calcPlaneNormals(planes, width, height)\n    # allNormals = np.concatenate([np.expand_dims(normal, 2), planeNormals], axis=2)\n    # normalPred = allNormals.reshape(-1, numOutputPlanes + 1, 3)[np.arange(width * height), planeSegmentation.reshape(-1)].reshape((height, width, 3))\n    \n    return planes, planeSegmentation\n\n\ndef testPlaneExtraction():\n    depth = cv2.imread(\'../../Data/SUNCG/0004d52d1aeeb8ae6de39d6bd993e992/000000_depth.png\', -1).astype(np.float32) / 1000\n    normal = (cv2.imread(\'../../Data/SUNCG/0004d52d1aeeb8ae6de39d6bd993e992/000000_norm_camera.png\').astype(np.float32) / 255) * 2 - 1\n    normal = np.stack([normal[:, :, 2], normal[:, :, 1], normal[:, :, 0]], axis=2)\n    image = cv2.imread(\'../../Data/SUNCG/0004d52d1aeeb8ae6de39d6bd993e992/000000_mlt.png\')\n\n    cv2.imwrite(\'test/depth.png\', drawDepthImage(depth))\n    cv2.imwrite(\'test/normal.png\', drawNormalImage(normal))\n    cv2.imwrite(\'test/image.png\', image)\n\n    info = np.zeros(20)\n    info[0] = 517.97\n    info[2] = 320\n    info[5] = 517.97\n    info[6] = 240\n    info[10] = 1\n    info[15] = 1\n    info[16] = 640\n    info[17] = 480\n    info[18] = 1000\n    info[19] = 0\n\n    parameters = {\'distanceCostThreshold\': 0.05, \'numProposals\': 3, \'smoothnessWeight\': 30, \'offsetGap\': 0.05},    \n    #pred_p, pred_s, pred_d, pred_n = fitPlanesManhattan(image, depth, normal, info, numOutputPlanes=20, imageIndex=-1, parameters=parameters)\n    pred_p, pred_s, pred_d, pred_n = fitPlanesPiecewise(image, depth, normal, info, numOutputPlanes=20, imageIndex=-1, parameters=parameters)    \n    exit(1)\n    return\n\ndef estimateFocalLength(image):\n    from pylsd import lsd\n    \n    height = image.shape[0]\n    width = image.shape[1]\n\n    lines = lsd(image.mean(2))\n\n    lineImage = image.copy()\n    for line in lines:\n        cv2.line(lineImage, (int(line[0]), int(line[1])), (int(line[2]), int(line[3])), (0, 0, 255), int(np.ceil(line[4] / 2)))\n        continue\n    cv2.imwrite(\'test/lines.png\', lineImage)\n\n    numVPs = 3\n    VPs, VPLines, remainingLines = calcVanishingPoints(lines, numVPs=numVPs)\n    #focalLength = (np.sqrt(np.linalg.norm(np.cross(VPs[0], VPs[1]))) + np.sqrt(np.linalg.norm(np.cross(VPs[0], VPs[2]))) + np.sqrt(np.linalg.norm(np.cross(VPs[1], VPs[2])))) / 3\n    focalLength = (np.sqrt(np.abs(np.dot(VPs[0], VPs[1]))) + np.sqrt(np.abs(np.dot(VPs[0], VPs[2]))) + np.sqrt(np.abs(np.dot(VPs[1], VPs[2])))) / 3\n    return focalLength\n\ndef calcEdgeMap(segmentation, edgeWidth=3):\n    edges = np.zeros(segmentation.shape, np.bool)\n    for shift in [-1, 1]:\n        for c in [0, 1]:\n            edges = np.logical_or(edges, segmentation != np.roll(segmentation, shift, axis=c))\n            continue\n        continue\n    edges = edges.astype(np.float32)\n    edges[0] = 0\n    edges[-1] = 0\n    edges[:, 0] = 0\n    edges[:, -1] = 0\n    edges = cv2.dilate(edges, np.ones((3, 3)), iterations=edgeWidth)\n    return edges > 0.5\n            \n#testPlaneExtraction()\n\ndef findFloorPlane(planes, segmentation):\n    minZ = 0\n    minZPlaneIndex = -1\n    minFloorArea = 32 * 24\n    for planeIndex, plane in enumerate(planes):\n        if plane[2] < 0 and abs(plane[2]) > max(abs(plane[0]), abs(plane[1])) and plane[2] < minZ and (segmentation == planeIndex).sum() > minFloorArea:\n            minZPlaneIndex = planeIndex\n            minZ = plane[2]\n            pass\n        continue\n    return minZPlaneIndex\n\ndef findCornerPoints(plane, depth, mask, info, axis=2, rectangle=True):\n    width = depth.shape[1]\n    height = depth.shape[0]\n    \n    camera = getCameraFromInfo(info)\n\n    #camera = getNYURGBDCamera()\n    #camera = getSUNCGCamera()\n\n    urange = (np.arange(width, dtype=np.float32) / width * camera[\'width\'] - camera[\'cx\']) / camera[\'fx\']\n    urange = urange.reshape(1, -1).repeat(height, 0)\n    vrange = (np.arange(height, dtype=np.float32) / height * camera[\'height\'] - camera[\'cy\']) / camera[\'fy\']\n    vrange = vrange.reshape(-1, 1).repeat(width, 1)\n    X = depth * urange\n    Y = depth\n    Z = -depth * vrange\n\n    XYZ = np.stack([X, Y, Z], axis=2)\n    XYZ = XYZ.reshape((-1, 3))\n    \n    maxs = XYZ.max(0)\n    mins = XYZ.min(0)\n\n    planeD = np.linalg.norm(plane)\n    planeNormal = plane / np.maximum(planeD, 1e-4)\n    \n    if axis == 2:\n        points = np.array([[mins[0], mins[1]], [mins[0], maxs[1]], [maxs[0], mins[1]], [maxs[0], maxs[1]]])\n        pointsZ = (planeD - planeNormal[0] * points[:, 0] - planeNormal[1] * points[:, 1]) / planeNormal[2]\n        points = np.concatenate([points, np.expand_dims(pointsZ, -1)], axis=1)\n        pass\n    \n    u = (points[:, 0] / points[:, 1] * camera[\'fx\'] + camera[\'cx\']) / camera[\'width\'] * width\n    v = (-points[:, 2] / points[:, 1] * camera[\'fy\'] + camera[\'cy\']) / camera[\'height\'] * height\n\n    if rectangle:\n        minU = u.min()\n        maxU = u.max()\n        minV = v.min()\n        maxV = v.max()\n        uv = np.array([[minU, minV], [minU, maxV], [maxU, minV], [maxU, maxV]])\n    else:\n        uv = np.stack([u, v], axis=1)\n        pass\n    return uv\n\ndef findCornerPoints2D(mask):\n    from pylsd import lsd\n    lines = lsd(mask)\n\n    #lineImage = mask.copy()\n    lineImage = np.zeros(mask.shape + (3, ))\n    print(lines.shape)\n    print(lines)\n    for line in lines:\n        cv2.line(lineImage, (int(line[0]), int(line[1])), (int(line[2]), int(line[3])), (0, 0, 255), int(np.ceil(line[4] / 2)))\n        continue\n    cv2.imwrite(\'test/lines.png\', lineImage)\n    exit(1)\n    \n\n# def copyTexture(image, planes, segmentation, info, denotedPlaneIndex=-1, textureIndex=-1):\n#     import glob\n    \n#     width = segmentation.shape[1]\n#     height = segmentation.shape[0]\n    \n#     plane_depths = calcPlaneDepths(planes, width, height, info)\n    \n#     texture_image_names = glob.glob(\'../texture_images/*.png\') + glob.glob(\'../texture_images/*.jpg\')\n#     if textureIndex >= 0:\n#         texture_image_names = [texture_image_names[textureIndex]]\n#         pass\n    \n#     resultImages = []\n#     for texture_index, texture_image_name in enumerate(texture_image_names):\n#         textureImage = cv2.imread(texture_image_name)\n#         #textureImage = cv2.imread(\'../textures/texture_2.jpg\')\n#         textureImage = cv2.resize(textureImage, (width, height), interpolation=cv2.INTER_LINEAR)\n\n#         if denotedPlaneIndex < 0:\n#             denotedPlaneIndex = findFloorPlane(planes, segmentation)\n#             pass\n        \n#         mask = segmentation == denotedPlaneIndex\n#         #mask = cv2.resize(mask.astype(np.float32), (width, height), interpolation=cv2.INTER_LINEAR) > 0.5\n#         #plane_depths = calcPlaneDepths(pred_p, width, height)\n#         depth = plane_depths[:, :, denotedPlaneIndex]\n#         #depth = cv2.resize(depth, (width, height), interpolation=cv2.INTER_LINEAR) > 0.5\n#         #uv = findCornerPoints(planes[denotedPlaneIndex], depth, mask, info)\n#         uv = findCornerPoints2D(mask.astype(np.uint8) * 255)\n#         #print(uv)\n#         source_uv = np.array([[0, 0], [0, height], [width, 0], [width, height]])\n\n#         h, status = cv2.findHomography(source_uv, uv)\n#         #textureImageWarped = cv2.warpPerspective(textureImage, h, (WIDTH, HEIGHT))\n#         textureImageWarped = cv2.warpPerspective(textureImage, h, (width, height))\n#         resultImage = image.copy()\n\n#         resultImage[mask] = textureImageWarped[mask]\n#         resultImages.append(resultImage)\n#         #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_texture.png\', textureImageWarped)\n#         #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_result_\' + str(texture_index) + \'.png\', resultImage)\n#         continue\n#     return resultImages\n\n\n# the logo copying application\ndef copyLogo(textureImageFilename, folder, index, image, depth, planes, segmentation, info):\n    from sklearn.cluster import KMeans\n    from skimage import measure\n    #from sklearn.decomposition import PCA\n    \n    width = segmentation.shape[1]\n    height = segmentation.shape[0]\n\n    camera = getCameraFromInfo(info)\n\n    # calculate corresponding 3D position for each pixel\n    urange = (np.arange(width, dtype=np.float32) / width * camera[\'width\'] - camera[\'cx\']) / camera[\'fx\']\n    urange = urange.reshape(1, -1).repeat(height, 0)\n    vrange = (np.arange(height, dtype=np.float32) / height * camera[\'height\'] - camera[\'cy\']) / camera[\'fy\']\n    vrange = vrange.reshape(-1, 1).repeat(width, 1)\n    X = depth * urange\n    Y = depth\n    Z = -depth * vrange\n    XYZ = np.stack([X, Y, Z], axis=2)    \n    #plane_depths = calcPlaneDepths(planes, width, height, info)\n\n    # calculate plane offsets and normals\n    planesD = np.linalg.norm(planes, axis=-1, keepdims=True)\n    planesNormal = planes / np.maximum(planesD, 1e-4)\n\n    planeAreaThreshold = width * height / 100\n    \n    normals = []\n    for planeIndex in xrange(planes.shape[0]):\n        mask = segmentation == planeIndex\n        if mask.sum() < planeAreaThreshold:\n            continue\n        normals.append(planesNormal[planeIndex])\n        continue\n    normals = np.stack(normals, axis=0)\n    normals[normals[:, 1] < 0] *= -1\n        \n    # find dominant directions\n    kmeans = KMeans(n_clusters=3).fit(normals)\n    dominantNormals = kmeans.cluster_centers_\n    dominantNormals = dominantNormals / np.maximum(np.linalg.norm(dominantNormals, axis=-1, keepdims=True), 1e-4)\n\n    normals = planesNormal.copy()\n    normals[normals[:, 1] < 0] *= -1    \n    planeClusters = kmeans.predict(normals)\n    \n    #texture_image_names = glob.glob(\'../texture_images/*.png\') + glob.glob(\'../texture_images/*.jpg\')\n    \n    #imageFilename = \'/home/chenliu/Projects/PlaneNet/texture_images/CVPR.jpg\'\n    #textureImage = cv2.imread(imageFilename)\n\n    #textureImage = cv2.imread(\'../texture_images/CVPR_transparent.png\')\n    textureImage = cv2.imread(textureImageFilename)\n    imageFilename = \'CVPR.png\'\n    cv2.imwrite(folder + \'/\' + imageFilename, textureImage)\n\n    backgroundMask = textureImage.mean(2) > 224\n    #backgroundMask = cv2.erode(backgroundMask.astype(np.uint8), np.ones((3, 3)))\n    #cv2.imwrite(\'test/mask.png\', drawMaskImage(background))\n    #exit(1)\n\n    textureHeight = textureImage.shape[0]\n    textureWidth = textureImage.shape[1]\n    textureRatio = float(textureHeight) / textureWidth\n    #textureImage = cv2.imread(\'../textures/texture_2.jpg\')\n    #textureImage = cv2.resize(textureImage, (width, height), interpolation=cv2.INTER_LINEAR)\n\n    # copy the texture image in 3D\n    faces = []\n    texcoords = []        \n    #maskImage = np.full(segmentation.shape, planes.shape[0])\n    maskImage = image.copy()\n    for planeIndex in xrange(planes.shape[0]):\n        globalMask = segmentation == planeIndex\n        if globalMask.sum() < planeAreaThreshold:\n            continue\n        \n        masks = measure.label(globalMask.astype(np.int32), background=0)\n        #print(masks.max())\n        #print(masks.min())        \n        #cv2.imwrite(\'test/mask.png\', drawSegmentationImage(masks, blackIndex=planes.shape[0]))\n        #exit(1)\n        for maskIndex in xrange(masks.min() + 1, masks.max() + 1):\n            mask = masks == maskIndex\n            if mask.sum() < planeAreaThreshold:\n                continue\n\n            planeNormal = planesNormal[planeIndex]\n\n            # maxs = points.max(0)\n            # mins = points.min(0)\n\n            # planeNormal = planesNormal[planeIndex]\n            # maxAxis = np.argmax(np.abs(planeNormal))\n            # center = points.mean(0)\n            # if maxAxis != 2:\n            #     direction_u = np.cross(planeNormal, np.array([0, 0, 1]))\n            #     direction_u = direction_u / np.maximum(np.linalg.norm(direction_u), 1e-4)\n            #     direction_v = np.cross(planeNormal, direction_u)\n            #     direction_v = direction_v / np.maximum(np.linalg.norm(direction_v), 1e-4)\n            # else:\n            #     pca = PCA(n_components=1)\n            #     pca.fit(points[:, :2])\n            #     direction = np.concatenate([pca.components_[0], np.zeros(1)], axis=0)\n\n            #     direction_u = np.cross(planeNormal, direction)\n            #     direction_u = direction_u / np.maximum(np.linalg.norm(direction_u), 1e-4)\n            #     direction_v = np.cross(planeNormal, direction_u)\n            #     direction_v = direction_v / np.maximum(np.linalg.norm(direction_v), 1e-4)\n            #     pass\n\n            cluster = planeClusters[planeIndex]\n            dominantNormal = dominantNormals[(cluster + 1) % 3]\n            direction_u = np.cross(planeNormal, dominantNormal)\n            direction_u = direction_u / np.maximum(np.linalg.norm(direction_u), 1e-4)\n            direction_v = np.cross(planeNormal, direction_u)\n            direction_v = direction_v / np.maximum(np.linalg.norm(direction_v), 1e-4)\n\n            points = XYZ[mask]        \n            projection_u = np.tensordot(points, direction_u, axes=([1], [0]))\n            range_u = [projection_u.min(), projection_u.max()]       \n            projection_v = np.tensordot(points, direction_v, axes=([1], [0]))                \n            range_v = [projection_v.min(), projection_v.max()]\n            if range_v[1] - range_v[0] > range_u[1] - range_u[0]:\n                range_u, range_v = range_v, range_u\n                direction_u, direction_v = direction_v, direction_u\n                pass\n\n            if (np.argmax(np.abs(direction_v)) == 2 and direction_v[2] < 0) or (np.argmax(np.abs(direction_v)) != 2 and np.dot(np.array([0, 1, 0]), direction_v) < 0):\n                direction_v *= -1\n                projection_v *= -1\n                range_v = [-range_v[1], -range_v[0]]\n                pass\n            if np.dot(np.cross(planeNormal, direction_v), direction_u) < 0:\n                direction_u *= -1\n                projection_u *= -1\n                range_u = [-range_u[1], -range_u[0]]\n                pass\n\n            print(planeIndex, dominantNormal, direction_u, direction_v)\n\n\n            length_u = range_u[1] - range_u[0]\n            length_v = range_v[1] - range_v[0]\n            if length_u * textureRatio > length_v:\n                length_u = length_v / textureRatio\n            else:\n                length_v = length_u * textureRatio\n                pass\n\n            logoSize = 0.35\n            \n            center_u = (range_u[0] + range_u[1]) / 2\n            range_u = [center_u - length_u * logoSize, center_u + length_u * logoSize]\n\n            center_v = (range_v[0] + range_v[1]) / 2\n            range_v = [center_v - length_v * logoSize, center_v + length_v * logoSize]\n\n            projection_u = np.tensordot(XYZ, direction_u, axes=([2], [0]))\n            projection_v = np.tensordot(XYZ, direction_v, axes=([2], [0]))\n            projection_u = (projection_u - range_u[0]) / (range_u[1] - range_u[0])\n            projection_v = (projection_v - range_v[0]) / (range_v[1] - range_v[0])\n            rectangleMask = np.logical_and(np.logical_and(projection_u >= 0, projection_u <= 1), np.logical_and(projection_v >= 0, projection_v <= 1))\n\n            rectangleMask = np.logical_and(rectangleMask, mask)\n            #maskImage[rectangleMask] = planeIndex\n\n            for y in xrange(height - 1):\n                for x in xrange(width - 1):\n                    facePixels = []\n                    for pixel in [(x, y), (x + 1, y), (x + 1, y + 1), (x, y + 1)]:\n                        if rectangleMask[pixel[1]][pixel[0]]:\n                            u = projection_u[pixel[1]][pixel[0]]\n                            v = projection_v[pixel[1]][pixel[0]]\n                            u = min(max(int(round(u * textureWidth)), 0), textureWidth - 1)\n                            v = min(max(textureHeight - 1 - int(round(v * textureHeight)), 0), textureHeight - 1)\n                            if backgroundMask[v][u] == False:\n                                facePixels.append(pixel)\n\n                                if pixel == (x, y):\n                                    maskImage[y][x] = textureImage[v][u]\n                                    pass\n                                pass\n                            pass\n                        continue\n                    \n                    if len(facePixels) == 3:\n                        faces.append(facePixels[0] + facePixels[1] + facePixels[2])\n                        vt = []\n                        for c in [0, 1, 2]:\n                            vt.append(projection_u[facePixels[c][1]][facePixels[c][0]])\n                            vt.append(projection_v[facePixels[c][1]][facePixels[c][0]])\n                            continue\n                        texcoords.append(vt)\n                    elif len(facePixels) == 4:\n                        faces.append(facePixels[0] + facePixels[1] + facePixels[2])\n                        vt = []\n                        for c in [0, 1, 2]:\n                            vt.append(projection_u[facePixels[c][1]][facePixels[c][0]])\n                            vt.append(projection_v[facePixels[c][1]][facePixels[c][0]])\n                            continue\n                        texcoords.append(vt)                    \n                        faces.append(facePixels[0] + facePixels[2] + facePixels[3])\n                        vt = []\n                        for c in [0, 2, 3]:\n                            vt.append(projection_u[facePixels[c][1]][facePixels[c][0]])\n                            vt.append(projection_v[facePixels[c][1]][facePixels[c][0]])\n                            continue\n                        texcoords.append(vt)                    \n                        pass\n                    continue\n                continue\n            continue\n        continue\n\n    #cv2.imwrite(\'test/mask.png\', drawSegmentationImage(maskImage, blackIndex=planes.shape[0]))\n    #cv2.imwrite(\'test/mask.png\', drawSegmentationImage(maskImage, blackIndex=planes.shape[0]))\n    \n\n    # write a .ply file\n    with open(folder + \'/\' + str(index) + \'_logo.ply\', \'w\') as f:\n        header = """"""ply\nformat ascii 1.0\ncomment VCGLIB generated\ncomment TextureFile """"""\n        header += imageFilename\n        header += """"""\nelement vertex """"""\n        header += str(width * height)\n        header += """"""\nproperty float x\nproperty float y\nproperty float z\nelement face """"""\n        header += str(len(faces))\n        header += """"""\nproperty list uchar int vertex_indices\nproperty list uchar float texcoord\nend_header\n""""""\n        f.write(header)\n        for y in xrange(height):\n            for x in xrange(width):\n                segmentIndex = segmentation[y][x]\n                if segmentIndex == -1:\n                    f.write(""0.0 0.0 0.0\\n"")\n                    continue\n                point = XYZ[y][x]\n                X = point[0] * 0.9999\n                Y = point[1] * 0.9999\n                Z = point[2] * 0.9999\n                #Y = depth[y][x]\n                #X = Y / focalLength * (x - width / 2) / width * 640\n                #Z = -Y / focalLength * (y - height / 2) / height * 480\n                f.write(str(X) + \' \' +    str(Z) + \' \' + str(-Y) + \'\\n\')\n                continue\n            continue\n\n\n        for faceIndex, face in enumerate(faces):\n            f.write(\'3 \')\n            for c in xrange(3):\n                f.write(str(face[c * 2 + 1] * width + face[c * 2]) + \' \')\n                continue\n            f.write(\'6 \')\n            vt = texcoords[faceIndex]\n            for value in vt:\n                f.write(str(value) + \' \')\n                continue\n            # for c in xrange(3):\n            #     f.write(str(float(face[c * 2]) / width) + \' \' + str(1 - float(face[c * 2 + 1]) / height) + \' \')\n            #     continue\n            f.write(\'\\n\')\n            continue\n        f.close()\n        pass\n    return maskImage\n\n\n# the wall texture copying application, similar with the logo copying application\ndef copyWallTexture(textureImageFilename, folder, index, image, depth, planes, segmentation, info, wallPlanes=[]):\n    from sklearn.cluster import KMeans\n    from skimage import measure\n    #from sklearn.decomposition import PCA\n    \n    width = segmentation.shape[1]\n    height = segmentation.shape[0]\n\n    camera = getCameraFromInfo(info)\n\n    # calculate corresponding 3D position for each pixel\n    urange = (np.arange(width, dtype=np.float32) / width * camera[\'width\'] - camera[\'cx\']) / camera[\'fx\']\n    urange = urange.reshape(1, -1).repeat(height, 0)\n    vrange = (np.arange(height, dtype=np.float32) / height * camera[\'height\'] - camera[\'cy\']) / camera[\'fy\']\n    vrange = vrange.reshape(-1, 1).repeat(width, 1)\n    X = depth * urange\n    Y = depth\n    Z = -depth * vrange\n    XYZ = np.stack([X, Y, Z], axis=2)    \n    #plane_depths = calcPlaneDepths(planes, width, height, info)\n\n    # calculate plane offsets and normals\n    planesD = np.linalg.norm(planes, axis=-1, keepdims=True)\n    planesNormal = planes / np.maximum(planesD, 1e-4)\n\n    planeAreaThreshold = width * height / 100\n    \n    normals = []\n    for planeIndex in xrange(planes.shape[0]):\n        mask = segmentation == planeIndex\n        if mask.sum() < planeAreaThreshold:\n            continue\n        normals.append(planesNormal[planeIndex])\n        continue\n    normals = np.stack(normals, axis=0)\n    normals[normals[:, 1] < 0] *= -1\n        \n    # find dominant directions\n    kmeans = KMeans(n_clusters=3).fit(normals)\n    dominantNormals = kmeans.cluster_centers_\n    dominantNormals = dominantNormals / np.maximum(np.linalg.norm(dominantNormals, axis=-1, keepdims=True), 1e-4)\n\n    normals = planesNormal.copy()\n    normals[normals[:, 1] < 0] *= -1    \n    planeClusters = kmeans.predict(normals)\n    \n    #texture_image_names = glob.glob(\'../texture_images/*.png\') + glob.glob(\'../texture_images/*.jpg\')\n    \n    #imageFilename = \'/home/chenliu/Projects/PlaneNet/texture_images/CVPR.jpg\'\n    #textureImage = cv2.imread(imageFilename)\n\n    #textureImage = cv2.imread(\'../texture_images/CVPR_transparent.png\')\n    #textureImage = cv2.imread(\'../texture_images/checkerboard.jpg\')\n    textureImage = cv2.imread(textureImageFilename)\n    imageFilename = \'texture.png\'\n    cv2.imwrite(folder + \'/\' + imageFilename, textureImage)\n\n    #background = textureImage.mean(2) > 224\n    #background = cv2.erode(background.astype(np.uint8), np.ones((3, 3)))\n    #cv2.imwrite(\'test/mask.png\', drawMaskImage(background))\n    #exit(1)\n\n    textureHeight = textureImage.shape[0]\n    textureWidth = textureImage.shape[1]\n    textureRatio = float(textureHeight) / textureWidth\n    #textureImage = cv2.imread(\'../textures/texture_2.jpg\')\n    #textureImage = cv2.resize(textureImage, (width, height), interpolation=cv2.INTER_LINEAR)\n\n    # copy wall texture in 3D\n    faces = []\n    texcoords = []        \n    #maskImage = np.full(segmentation.shape, planes.shape[0])\n    maskImage = image.copy()\n    for planeIndex in xrange(planes.shape[0]):\n        if planeIndex not in wallPlanes:\n            continue\n        globalMask = segmentation == planeIndex\n        if globalMask.sum() < planeAreaThreshold:\n            continue\n        \n        masks = measure.label(globalMask.astype(np.int32), background=0)\n        #print(masks.max())\n        #print(masks.min())        \n        cv2.imwrite(\'test/mask.png\', drawSegmentationImage(masks, blackIndex=planes.shape[0]))\n        #print((masks == 1).sum(), planeAreaThreshold)\n        #print(planeAreaThreshold)\n        #exit(1)\n        for maskIndex in xrange(masks.min() + 1, masks.max() + 1):\n            mask = masks == maskIndex\n            if mask.sum() < planeAreaThreshold:\n                continue\n\n            planeNormal = planesNormal[planeIndex]\n\n            # maxs = points.max(0)\n            # mins = points.min(0)\n\n            # planeNormal = planesNormal[planeIndex]\n            # maxAxis = np.argmax(np.abs(planeNormal))\n            # center = points.mean(0)\n            # if maxAxis != 2:\n            #     direction_u = np.cross(planeNormal, np.array([0, 0, 1]))\n            #     direction_u = direction_u / np.maximum(np.linalg.norm(direction_u), 1e-4)\n            #     direction_v = np.cross(planeNormal, direction_u)\n            #     direction_v = direction_v / np.maximum(np.linalg.norm(direction_v), 1e-4)\n            # else:\n            #     pca = PCA(n_components=1)\n            #     pca.fit(points[:, :2])\n            #     direction = np.concatenate([pca.components_[0], np.zeros(1)], axis=0)\n\n            #     direction_u = np.cross(planeNormal, direction)\n            #     direction_u = direction_u / np.maximum(np.linalg.norm(direction_u), 1e-4)\n            #     direction_v = np.cross(planeNormal, direction_u)\n            #     direction_v = direction_v / np.maximum(np.linalg.norm(direction_v), 1e-4)\n            #     pass\n\n            cluster = planeClusters[planeIndex]\n            dominantNormal = dominantNormals[(cluster + 1) % 3]\n            direction_u = np.cross(planeNormal, dominantNormal)\n            direction_u = direction_u / np.maximum(np.linalg.norm(direction_u), 1e-4)\n            direction_v = np.cross(planeNormal, direction_u)\n            direction_v = direction_v / np.maximum(np.linalg.norm(direction_v), 1e-4)\n\n            points = XYZ[mask]        \n            projection_u = np.tensordot(points, direction_u, axes=([1], [0]))\n            range_u = [projection_u.min(), projection_u.max()]       \n            projection_v = np.tensordot(points, direction_v, axes=([1], [0]))                \n            range_v = [projection_v.min(), projection_v.max()]\n            if range_v[1] - range_v[0] > range_u[1] - range_u[0]:\n                range_u, range_v = range_v, range_u\n                direction_u, direction_v = direction_v, direction_u\n                pass\n\n            if (np.argmax(np.abs(direction_v)) == 2 and direction_v[2] < 0) or (np.argmax(np.abs(direction_v)) != 2 and np.dot(np.array([0, 1, 0]), direction_v) < 0):\n                direction_v *= -1\n                projection_v *= -1\n                range_v = [-range_v[1], -range_v[0]]\n                pass\n            if np.dot(np.cross(planeNormal, direction_v), direction_u) < 0:\n                direction_u *= -1\n                projection_u *= -1\n                range_u = [-range_u[1], -range_u[0]]\n                pass\n\n            print(planeIndex, dominantNormal, direction_u, direction_v)\n\n\n            length_u = range_u[1] - range_u[0]\n            length_v = range_v[1] - range_v[0]\n            if length_u * textureRatio > length_v:\n                length_u = length_v / textureRatio\n            else:\n                length_v = length_u * textureRatio\n                pass\n\n            #logoSize = 0.35\n            \n            # center_u = (range_u[0] + range_u[1]) / 2\n            # range_u = [center_u - length_u * logoSize, center_u + length_u * logoSize]\n\n            # center_v = (range_v[0] + range_v[1]) / 2\n            # range_v = [center_v - length_v * logoSize, center_v + length_v * logoSize]\n\n            projection_u = np.tensordot(XYZ, direction_u, axes=([2], [0]))\n            projection_v = np.tensordot(XYZ, direction_v, axes=([2], [0]))\n            #projection_u = (projection_u - range_u[0]) / (range_u[1] - range_u[0])\n            #projection_v = (projection_v - range_v[0]) / (range_v[1] - range_v[0])\n            \n            #rectangleMask = np.logical_and(np.logical_and(projection_u >= 0, projection_u <= 1), np.logical_and(projection_v >= 0, projection_v <= 1))\n            #rectangleMask = np.logical_and(rectangleMask, mask)\n\n            textureSize = 1\n            projection_u = (projection_u / textureSize) % 1\n            projection_v = (projection_v / textureSize) % 1\n            rectangleMask = mask\n\n            #maskImage[rectangleMask] = planeIndex\n            \n            for y in xrange(height - 1):\n                for x in xrange(width - 1):\n                    facePixels = []\n                    for pixel in [(x, y), (x + 1, y), (x + 1, y + 1), (x, y + 1)]:\n                        if rectangleMask[pixel[1]][pixel[0]]:\n                            # u = projection_u[pixel[1]][pixel[0]]\n                            # v = projection_v[pixel[1]][pixel[0]]\n                            # u = min(max(int(round(u * textureWidth)), 0), textureWidth - 1)\n                            # v = min(max(textureHeight - 1 - int(round(v * textureHeight)), 0), textureHeight - 1)\n                            # if background[v][u] == False:\n                            facePixels.append(pixel)\n\n                            #print(pixel, (x, y))\n                            if pixel == (x, y):\n                                u = projection_u[pixel[1]][pixel[0]]\n                                v = projection_v[pixel[1]][pixel[0]]\n                                u = min(max(int(round(u * textureWidth)), 0), textureWidth - 1)\n                                v = min(max(textureHeight - 1 - int(round(v * textureHeight)), 0), textureHeight - 1)\n\n                                #print(x, y)\n                                #print(u, v)\n                                \n                                maskImage[y][x] = textureImage[v][u]\n                                pass\n                            pass\n                        continue\n                    \n                    if len(facePixels) == 3:\n                        faces.append(facePixels[0] + facePixels[1] + facePixels[2])\n                        vt = []\n                        for c in [0, 1, 2]:\n                            vt.append(projection_u[facePixels[c][1]][facePixels[c][0]])\n                            vt.append(projection_v[facePixels[c][1]][facePixels[c][0]])\n                            continue\n                        texcoords.append(vt)\n                    elif len(facePixels) == 4:\n                        faces.append(facePixels[0] + facePixels[1] + facePixels[2])\n                        vt = []\n                        for c in [0, 1, 2]:\n                            vt.append(projection_u[facePixels[c][1]][facePixels[c][0]])\n                            vt.append(projection_v[facePixels[c][1]][facePixels[c][0]])\n                            continue\n                        texcoords.append(vt)                    \n                        faces.append(facePixels[0] + facePixels[2] + facePixels[3])\n                        vt = []\n                        for c in [0, 2, 3]:\n                            vt.append(projection_u[facePixels[c][1]][facePixels[c][0]])\n                            vt.append(projection_v[facePixels[c][1]][facePixels[c][0]])\n                            continue\n                        texcoords.append(vt)                    \n                        pass\n                    continue\n                continue\n            continue\n        continue\n\n    #cv2.imwrite(\'test/mask.png\', drawSegmentationImage(maskImage, blackIndex=planes.shape[0]))\n    \n\n    # write a .ply file\n    with open(folder + \'/\' + str(index) + \'_logo.ply\', \'w\') as f:\n        header = """"""ply\nformat ascii 1.0\ncomment VCGLIB generated\ncomment TextureFile """"""\n        header += imageFilename\n        header += """"""\nelement vertex """"""\n        header += str(width * height)\n        header += """"""\nproperty float x\nproperty float y\nproperty float z\nelement face """"""\n        header += str(len(faces))\n        header += """"""\nproperty list uchar int vertex_indices\nproperty list uchar float texcoord\nend_header\n""""""\n        f.write(header)\n        for y in xrange(height):\n            for x in xrange(width):\n                segmentIndex = segmentation[y][x]\n                if segmentIndex == -1:\n                    f.write(""0.0 0.0 0.0\\n"")\n                    continue\n                point = XYZ[y][x]\n                X = point[0] * 0.9999\n                Y = point[1] * 0.9999\n                Z = point[2] * 0.9999\n                #Y = depth[y][x]\n                #X = Y / focalLength * (x - width / 2) / width * 640\n                #Z = -Y / focalLength * (y - height / 2) / height * 480\n                f.write(str(X) + \' \' +    str(Z) + \' \' + str(-Y) + \'\\n\')\n                continue\n            continue\n\n\n        for faceIndex, face in enumerate(faces):\n            f.write(\'3 \')\n            for c in xrange(3):\n                f.write(str(face[c * 2 + 1] * width + face[c * 2]) + \' \')\n                continue\n            f.write(\'6 \')\n            vt = texcoords[faceIndex]\n            for value in vt:\n                f.write(str(value) + \' \')\n                continue\n            # for c in xrange(3):\n            #     f.write(str(float(face[c * 2]) / width) + \' \' + str(1 - float(face[c * 2 + 1]) / height) + \' \')\n            #     continue\n            f.write(\'\\n\')\n            continue\n        f.close()\n        pass\n    return maskImage\n\n\n# video applications (extension the logo/texture copying application)\ndef copyLogoVideo(textureImageFilename, folder, index, image, depth, planes, segmentation, info, textureType=\'logo\', wallInds=[]):\n    from sklearn.cluster import KMeans\n    from skimage import measure\n    #from sklearn.decomposition import PCA\n    \n    width = segmentation.shape[1]\n    height = segmentation.shape[0]\n\n    camera = getCameraFromInfo(info)\n    \n    urange = (np.arange(width, dtype=np.float32) / width * camera[\'width\'] - camera[\'cx\']) / camera[\'fx\']\n    urange = urange.reshape(1, -1).repeat(height, 0)\n    vrange = (np.arange(height, dtype=np.float32) / height * camera[\'height\'] - camera[\'cy\']) / camera[\'fy\']\n    vrange = vrange.reshape(-1, 1).repeat(width, 1)\n    X = depth * urange\n    Y = depth\n    Z = -depth * vrange\n    XYZ = np.stack([X, Y, Z], axis=2)    \n    #plane_depths = calcPlaneDepths(planes, width, height, info)\n\n    planesD = np.linalg.norm(planes, axis=-1, keepdims=True)\n    planesNormal = planes / np.maximum(planesD, 1e-4)\n\n    planeAreaThreshold = width * height / 100\n    normals = []\n    for planeIndex in xrange(planes.shape[0]):\n        mask = segmentation == planeIndex\n        if mask.sum() < planeAreaThreshold:\n            continue\n        normals.append(planesNormal[planeIndex])\n        continue\n\n    normals = np.stack(normals, axis=0)\n    normals[normals[:, 1] < 0] *= -1\n\n    kmeans = KMeans(n_clusters=3).fit(normals)\n    dominantNormals = kmeans.cluster_centers_\n    dominantNormals = dominantNormals / np.maximum(np.linalg.norm(dominantNormals, axis=-1, keepdims=True), 1e-4)\n\n    normals = planesNormal.copy()\n    normals[normals[:, 1] < 0] *= -1    \n    planeClusters = kmeans.predict(normals)\n\n    \n    #texture_image_names = glob.glob(\'../texture_images/*.png\') + glob.glob(\'../texture_images/*.jpg\')\n    \n    #imageFilename = \'/home/chenliu/Projects/PlaneNet/texture_images/CVPR.jpg\'\n    #textureImage = cv2.imread(imageFilename)\n\n    #textureImage = cv2.imread(\'../texture_images/CVPR_transparent.png\')\n\n    # either copy a logo or a wall texture or a TV screen\n    if textureType == \'wall\':\n        textureImage = cv2.imread(textureImageFilename)\n        alphaMask = np.ones((textureImage.shape[0], textureImage.shape[1], 1))\n    elif textureType == \'logo\':\n        textureImage = cv2.imread(textureImageFilename)\n        alphaMask = (textureImage.mean(2) < 224).astype(np.float32)\n        alphaMask = np.expand_dims(alphaMask, -1)\n    else:\n        textureVideo = cv2.VideoCapture(textureImageFilename)\n        ret, textureImage = textureVideo.read()\n        # numFrames = 0\n        # for i in xrange(500):\n        #     ret, textureImage = textureVideo.read()\n        #     if not ret:\n        #         break\n        #     numFrames += 1\n        #     print(i, textureImage.shape)\n        #     continue\n        # print(numFrames)\n        # print(textureImage.shape)\n        # exit(1)\n        alphaMask = np.ones((textureImage.shape[0], textureImage.shape[1], 1))\n        pass\n\n\n    #backgroundMask = cv2.erode(backgroundMask.astype(np.uint8), np.ones((3, 3)))\n    #cv2.imwrite(\'test/mask.png\', drawMaskImage(background))\n    #exit(1)\n\n    textureHeight = float(textureImage.shape[0])\n    textureWidth = float(textureImage.shape[1])\n    textureRatio = textureHeight / textureWidth\n    textureSizes2D = np.array([textureWidth, textureHeight])\n        \n    textureSizeU = 0.75\n    textureSizeV = textureSizeU * textureRatio\n    textureSizes = np.array([textureSizeU, textureSizeV])\n\n\n    # calculate projection information\n    planeMasks = []\n    planeProjections = []\n    planeRanges = []\n    for planeIndex in xrange(planes.shape[0]):\n        if textureType != \'logo\' and planeIndex not in wallInds:\n            continue            \n        \n        globalMask = segmentation == planeIndex\n        if globalMask.sum() < planeAreaThreshold:\n            continue\n        \n        masks = measure.label(globalMask.astype(np.int32), background=0)\n        #print(masks.max())\n        #print(masks.min())        \n        #cv2.imwrite(\'test/mask.png\', drawSegmentationImage(masks, blackIndex=planes.shape[0]))\n        #exit(1)\n        for maskIndex in xrange(masks.min() + 1, masks.max() + 1):\n            mask = masks == maskIndex\n            if mask.sum() < planeAreaThreshold:\n                continue\n\n            planeNormal = planesNormal[planeIndex]\n\n            cluster = planeClusters[planeIndex]\n            dominantNormal = dominantNormals[(cluster + 1) % 3]\n            direction_u = np.cross(planeNormal, dominantNormal)\n            direction_u = direction_u / np.maximum(np.linalg.norm(direction_u), 1e-4)\n            direction_v = np.cross(planeNormal, direction_u)\n            direction_v = direction_v / np.maximum(np.linalg.norm(direction_v), 1e-4)\n\n            points = XYZ[mask]        \n            projection_u = np.tensordot(points, direction_u, axes=([1], [0]))\n            range_u = [projection_u.min(), projection_u.max()]       \n            projection_v = np.tensordot(points, direction_v, axes=([1], [0]))                \n            range_v = [projection_v.min(), projection_v.max()]\n            if textureType != \'wall\' and range_v[1] - range_v[0] > range_u[1] - range_u[0]:\n                range_u, range_v = range_v, range_u\n                direction_u, direction_v = direction_v, direction_u\n                pass\n            if textureType != \'wall\' and abs(direction_u[2]) > abs(direction_v[2]):\n                range_u, range_v = range_v, range_u\n                direction_u, direction_v = direction_v, direction_u\n                pass\n            \n            if (np.argmax(np.abs(direction_v)) == 2 and direction_v[2] < 0) or (np.argmax(np.abs(direction_v)) != 2 and np.dot(np.array([0, 1, 0]), direction_v) < 0):\n                direction_v *= -1\n                projection_v *= -1\n                range_v = [-range_v[1], -range_v[0]]\n                pass\n            if np.dot(np.cross(planeNormal, direction_v), direction_u) < 0:\n                direction_u *= -1\n                projection_u *= -1\n                range_u = [-range_u[1], -range_u[0]]\n                pass\n\n            #print(planeIndex, dominantNormal, direction_u, direction_v)\n            projection_u = np.tensordot(XYZ, direction_u, axes=([2], [0]))\n            projection_v = np.tensordot(XYZ, direction_v, axes=([2], [0]))\n            planeProjections.append(np.stack([projection_u, projection_v], axis=-1).reshape((-1, 2)))\n            ranges = np.stack([range_u, range_v], axis=-1)\n            ranges = np.stack([ranges.mean(0) - (ranges[1] - ranges[0]) * 0.35, ranges.mean(0) + (ranges[1] - ranges[0]) * 0.35], axis=0)\n            planeRanges.append(ranges)\n            planeMasks.append(mask.reshape(-1))\n            continue\n        continue\n    \n    numMasks = len(planeProjections)\n    print(\'the number of masks\', numMasks)\n                \n    #maskImage = np.full(segmentation.shape, planes.shape[0])\n    #ratios = np.full(2, 0.5)\n\n    # move textures around\n    planeRatios = np.random.random((numMasks, 2))\n    randomDirection = np.random.random((numMasks, 2))\n    if textureType == \'wall\':\n        randomDirection = np.stack([np.ones(numMasks), np.zeros(numMasks)], axis=1)\n        randomDirection[0] *= -1\n        pass\n    randomDirection = randomDirection / np.linalg.norm(randomDirection)\n    stride = 0.01\n\n\n    # write a sequence of images\n    numFrames = 500\n    for frameIndex in xrange(numFrames):\n\n        # different ways of moving textures for different applications\n        if textureType != \'TV\':\n            planeRatios += randomDirection * stride\n        else:\n\n            # tweak planeDynamicRanges and TVSize for better visualization\n            ranges = np.array(planeRanges)\n            planeDynamicRanges = np.concatenate([ranges[:, 0], ranges[:, 1]], axis=1)\n            TVSize = ranges[:, 1] - ranges[:, 0]\n            \n            for planeIndex in xrange(2):\n                planeDynamicRanges[planeIndex, 2:] = planeDynamicRanges[planeIndex, :2] + max(min(float(frameIndex - numFrames / 2 * planeIndex) / (numFrames / 3), 1.0), 0.0) * TVSize[planeIndex]\n                continue\n            ret, textureImage = textureVideo.read()\n            if not ret:\n                textureVideo.set(cv2.cv.CV_CAP_PROP_POS_FRAMES, 0)\n                continue\n                #break\n            pass\n        \n        if textureType == \'logo\':\n            invalidMask = np.logical_or(planeRatios >= 1, planeRatios <= 0)\n            planeRatios = np.maximum(np.minimum(planeRatios, 1), 0)\n            randomDirection[invalidMask] *= -1\n            pass\n        \n        resultImage = image.copy().reshape((-1, 3))\n        for planeIndex in xrange(numMasks):\n            mask = planeMasks[planeIndex]\n            ranges = planeRanges[planeIndex]\n            projections = planeProjections[planeIndex]\n            ratios = planeRatios[planeIndex]\n            \n            offsets = ranges[0] + (ranges[1] - ranges[0]) * ratios - textureSizes / 2\n\n            #print(projections.max(0), projections.min(0))\n            if textureType == \'TV\':\n                projectionsMoved = (projections - planeDynamicRanges[planeIndex, :2]) / np.maximum(planeDynamicRanges[planeIndex, 2:] - planeDynamicRanges[planeIndex, :2], 1e-4)\n            else:\n                projectionsMoved = (projections - offsets) / textureSizes\n                pass\n\n            if textureType == \'wall\':\n                rectangleMask = mask\n            else:\n                rectangleMask = np.logical_and(projectionsMoved >= 0, projectionsMoved <= 1)\n                rectangleMask = np.logical_and(rectangleMask[:, 0], rectangleMask[:, 1])\n                rectangleMask = np.logical_and(rectangleMask, mask)\n                pass\n            \n            rectangleIndices = rectangleMask.nonzero()[0]\n            \n            uv = projectionsMoved[rectangleIndices] * textureSizes2D\n            uv[:, 1] = textureSizes2D[1] - 1 - uv[:, 1]\n            if textureType == \'wall\':\n                uv = uv % (textureSizes2D - 1)\n            else:\n                uv = np.maximum(np.minimum(uv, textureSizes2D - 1), 0)\n                pass\n\n            u = uv[:, 0]\n            v = uv[:, 1]\n            u_min = np.floor(u).astype(np.int32)\n            u_max = np.ceil(u).astype(np.int32)\n            v_min = np.floor(v).astype(np.int32)\n            v_max = np.ceil(v).astype(np.int32)\n\n            area_11 = (u_max - u) * (v_max - v)\n            area_12 = (u_max - u) * (v - v_min)\n            area_21 = (u - u_min) * (v_max - v)\n            area_22 = (u - u_min) * (v - v_min)\n\n            area_11 = np.expand_dims(area_11, -1)\n            area_12 = np.expand_dims(area_12, -1)\n            area_21 = np.expand_dims(area_21, -1)\n            area_22 = np.expand_dims(area_22, -1)\n\n            \n            colors_11 = textureImage[v_min, u_min]\n            colors_12 = textureImage[v_max, u_min]\n            colors_21 = textureImage[v_min, u_max]\n            colors_22 = textureImage[v_max, u_max]\n\n            alphas_11 = alphaMask[v_min, u_min]\n            alphas_12 = alphaMask[v_max, u_min]\n            alphas_21 = alphaMask[v_min, u_max]\n            alphas_22 = alphaMask[v_max, u_max]\n            \n            colors = colors_11 * area_11 + colors_12 * area_12 + colors_21 * area_21 + colors_22 * area_22\n            alphas = alphas_11 * area_11 + alphas_12 * area_12 + alphas_21 * area_21 + alphas_22 * area_22\n            #alphas = np.expand_dims(alphas, -1)\n            #foreground = foregroundMask[uv[:, 1], uv[:, 0]]\n            #indices = rectangleIndices[foreground]\n            #uv = uv[foreground]\n            \n            #rectangleMask = np.logical_and(rectangleMask, foreground)\n\n            resultImage[rectangleIndices] = resultImage[rectangleIndices] * (1 - alphas) + colors * alphas\n            continue\n        cv2.imwrite(folder + \'/\' + (\'%04d\' % frameIndex) + \'.png\', resultImage.reshape(image.shape))\n        continue\n    #cv2.imwrite(\'test/mask.png\', drawSegmentationImage(maskImage, blackIndex=planes.shape[0]))\n    #cv2.imwrite(\'test/mask.png\', drawSegmentationImage(maskImage, blackIndex=planes.shape[0]))\n    \n    return \n\n\n# the ruler application\ndef addRulerPlane(textureImageFilename, folder, index, image, depth, planes, segmentation, info, startPixel, endPixel, fixedEndPoint=False):\n\n    width = segmentation.shape[1]\n    height = segmentation.shape[0]\n\n    camera = getCameraFromInfo(info)\n\n    # calculate corresponding 3D position for each pixel\n    urange = (np.arange(width, dtype=np.float32) / width * camera[\'width\'] - camera[\'cx\']) / camera[\'fx\']\n    urange = urange.reshape(1, -1).repeat(height, 0)\n    vrange = (np.arange(height, dtype=np.float32) / height * camera[\'height\'] - camera[\'cy\']) / camera[\'fy\']\n    vrange = vrange.reshape(-1, 1).repeat(width, 1)\n    X = depth * urange\n    Y = depth\n    Z = -depth * vrange\n    XYZ = np.stack([X, Y, Z], axis=2)    \n    #plane_depths = calcPlaneDepths(planes, width, height, info)\n\n    # calculate plane offsets and normals\n    planesD = np.linalg.norm(planes, axis=-1, keepdims=True)\n    planesNormal = planes / np.maximum(planesD, 1e-4)\n\n    planeAreaThreshold = width * height / 100\n    \n    normals = []\n    for planeIndex in xrange(planes.shape[0]):\n        mask = segmentation == planeIndex\n        if mask.sum() < planeAreaThreshold:\n            continue\n        normals.append(planesNormal[planeIndex])\n        continue\n    normals = np.stack(normals, axis=0)\n    normals[normals[:, 1] < 0] *= -1\n\n\n    #texture_image_names = glob.glob(\'../texture_images/*.png\') + glob.glob(\'../texture_images/*.jpg\')\n    \n    #imageFilename = \'/home/chenliu/Projects/PlaneNet/texture_images/CVPR.jpg\'\n    #textureImage = cv2.imread(imageFilename)\n\n    #textureImage = cv2.imread(\'../texture_images/CVPR_transparent.png\')\n    textureImage = cv2.imread(textureImageFilename)\n    alphaMask = np.ones((textureImage.shape[0], textureImage.shape[1], 1), dtype=np.float32)\n    #alphaMask = (textureImage.mean(2) < 224).astype(np.float32)\n    #alphaMask = np.expand_dims(alphaMask, -1)\n    \n    #backgroundMask = cv2.erode(backgroundMask.astype(np.uint8), np.ones((3, 3)))\n    #cv2.imwrite(\'test/mask.png\', drawMaskImage(background))\n    #exit(1)\n\n    textureHeight = float(textureImage.shape[0])\n    textureWidth = float(textureImage.shape[1])\n    textureRatio = textureHeight / textureWidth\n    textureSizes2D = np.array([textureWidth, textureHeight])\n    \n    textureSizeU = 0.96\n    textureSizeV = textureSizeU * textureRatio\n    textureSizes = np.array([textureSizeU, textureSizeV])\n    #textureImage = cv2.imread(\'../textures/texture_2.jpg\')\n    #textureImage = cv2.resize(textureImage, (width, height), interpolation=cv2.INTER_LINEAR)\n\n\n    # find the starting plane, the ending plane, and the boundary point\n    startPlaneIndex = segmentation[startPixel[1]][startPixel[0]]\n    endPlaneIndex = segmentation[endPixel[1]][endPixel[0]]\n    assert(startPlaneIndex < planes.shape[0] and endPlaneIndex < planes.shape[0])\n    startPoint = XYZ[startPixel[1]][startPixel[0]]\n    endPoint = XYZ[endPixel[1]][endPixel[0]]\n\n    mask = (segmentation == startPlaneIndex).astype(np.uint8)\n\n    if startPlaneIndex != endPlaneIndex:\n        boundary = mask - cv2.erode(mask, np.ones((3, 3), dtype=np.uint8))\n        boundaryPoints = XYZ[boundary.nonzero()]\n        if fixedEndPoint:\n            distances = np.linalg.norm(boundaryPoints - startPoint, axis=-1) + np.linalg.norm(boundaryPoints - endPoint, axis=-1)\n            boundaryPoint = boundaryPoints[np.argmin(distances)]\n        else:\n            endPlane = planes[endPlaneIndex]\n            endPlaneD = np.linalg.norm(endPlane)\n            endPlaneNormal = endPlane / endPlaneD\n            endDistances = endPlaneD - np.tensordot(boundaryPoints, endPlaneNormal, axes=(1, 0))\n            distances = np.linalg.norm(boundaryPoints - startPoint, axis=-1) + np.abs(endDistances)\n            boundaryPointIndex = np.argmin(distances)\n            boundaryPoint = boundaryPoints[boundaryPointIndex]\n            endDistance = endDistances[boundaryPointIndex]\n            endPoint = boundaryPoint + endDistance * endPlaneNormal\n            pass\n    else:\n        boundaryPoint = startPoint\n        pass\n\n    \n    # find planes which the ruler passes by on the image domain\n    passbyPlaneInds = []\n    for offset in np.arange(0.1, 1, 0.1):\n        point = boundaryPoint + (endPoint - boundaryPoint) * offset\n        u = int(round(point[0] / point[1] * camera[\'fx\'] + camera[\'cx\']))\n        v = int(round(-point[2] / point[1] * camera[\'fy\'] + camera[\'cy\']))\n        planeIndex = segmentation[v][u]\n        if planeIndex != startPlaneIndex and planeIndex < planes.shape[0] and planeIndex not in passbyPlaneInds:\n            passbyPlaneInds.append(planeIndex)\n            pass\n        continue\n    print(passbyPlaneInds)\n    if len(passbyPlaneInds):\n        passbyPlaneNormal = planesNormal[passbyPlaneInds[0]]\n    else:\n        passbyPlaneNormal = np.array([0, 1, 0])\n        pass\n\n    \n    resultImage = image.copy().reshape((-1, 3))    \n    distanceOffset = 0\n\n    # draw two segments of ruler (from the starting point to the boundary point and from the boundary point to the ending point)\n    for point_1, point_2, planeNormal, planeInds in [(startPoint, boundaryPoint, planesNormal[startPlaneIndex], [startPlaneIndex]), (boundaryPoint, endPoint, passbyPlaneNormal, passbyPlaneInds)]:\n        if point_1[0] == point_2[0] and point_1[1] == point_2[1]:\n            continue\n    \n        direction_u = point_2 - point_1\n        direction_u = direction_u / np.maximum(np.linalg.norm(direction_u), 1e-4)\n        direction_v = -np.cross(planeNormal, direction_u)\n        direction_v = direction_v / np.maximum(np.linalg.norm(direction_v), 1e-4)\n        projection_u = np.tensordot(XYZ, direction_u, axes=([2], [0])).reshape(-1)\n        projection_v = np.tensordot(XYZ, direction_v, axes=([2], [0])).reshape(-1)\n\n        offset_u = np.dot(point_1, direction_u)\n        offset_v = np.dot(point_1, direction_v)\n\n        projection_u = (projection_u - offset_u) / textureSizeU\n        projection_v = (projection_v - offset_v) / textureSizeV\n        \n        rectangleMask = np.logical_and(np.logical_and(projection_u >= distanceOffset / textureSizeU, projection_u <= (distanceOffset + np.linalg.norm(point_2 - point_1)) / textureSizeU), np.logical_and(projection_v >= 0, projection_v <= 1))\n\n        if len(planeInds) > 0:\n            validMask = np.zeros(segmentation.shape, dtype=np.bool)\n            for planeIndex in planeInds:\n                validMask = np.logical_or(validMask, segmentation == planeIndex)\n                continue\n            rectangleMask = np.logical_and(rectangleMask, validMask.reshape(-1))\n            pass\n        \n        rectangleIndices = rectangleMask.nonzero()[0]\n\n        projections = np.stack([projection_u[rectangleIndices], projection_v[rectangleIndices]], axis=1)\n        uv = projections * textureSizes2D\n        \n        uv[:, 1] = textureSizes2D[1] - 1 - uv[:, 1]\n        uv = np.maximum(np.minimum(uv, textureSizes2D - 1), 0)\n\n\n        u = uv[:, 0]\n        v = uv[:, 1]\n        u_min = np.floor(u).astype(np.int32)\n        u_max = np.ceil(u).astype(np.int32)\n        v_min = np.floor(v).astype(np.int32)\n        v_max = np.ceil(v).astype(np.int32)\n\n        area_11 = (u_max - u) * (v_max - v)\n        area_12 = (u_max - u) * (v - v_min)\n        area_21 = (u - u_min) * (v_max - v)\n        area_22 = (u - u_min) * (v - v_min)\n\n        area_11 = np.expand_dims(area_11, -1)\n        area_12 = np.expand_dims(area_12, -1)\n        area_21 = np.expand_dims(area_21, -1)\n        area_22 = np.expand_dims(area_22, -1)\n\n\n        colors_11 = textureImage[v_min, u_min]\n        colors_12 = textureImage[v_max, u_min]\n        colors_21 = textureImage[v_min, u_max]\n        colors_22 = textureImage[v_max, u_max]\n\n        alphas_11 = alphaMask[v_min, u_min]\n        alphas_12 = alphaMask[v_max, u_min]\n        alphas_21 = alphaMask[v_min, u_max]\n        alphas_22 = alphaMask[v_max, u_max]\n\n        colors = colors_11 * area_11 + colors_12 * area_12 + colors_21 * area_21 + colors_22 * area_22\n        alphas = alphas_11 * area_11 + alphas_12 * area_12 + alphas_21 * area_21 + alphas_22 * area_22\n\n        resultImage[rectangleIndices] = resultImage[rectangleIndices] * (1 - alphas) + colors * alphas\n\n        distanceOffset += np.linalg.norm(point_2 - point_1)\n        print(point_1, point_2)\n        print(direction_u)\n        print(direction_v)\n        cv2.imwrite(\'test/result.png\', resultImage.reshape(image.shape))\n        exit(1)\n        continue\n    return\n\n# the ruler application (video version)\ndef addRuler(textureImage, folder, indexOffset, image, depth, planes, segmentation, info, startPoint, endPoint, boundaryPoints, startPlaneIndex, fixedEndPoint=False, numFrames=1):\n    width = segmentation.shape[1]\n    height = segmentation.shape[0]\n\n    #info[0] -= 40\n    #info[5] -= 40\n    \n    camera = getCameraFromInfo(info)\n\n    # calculate plane offsets and normals\n    planesD = np.linalg.norm(planes, axis=-1, keepdims=True)\n    planesNormal = planes / np.maximum(planesD, 1e-4)\n    \n    alphaMask = np.ones((textureImage.shape[0], textureImage.shape[1], 1), dtype=np.float32)\n    #alphaMask = (textureImage.mean(2) < 224).astype(np.float32)\n    #alphaMask = np.expand_dims(alphaMask, -1)\n    \n    #backgroundMask = cv2.erode(backgroundMask.astype(np.uint8), np.ones((3, 3)))\n    #cv2.imwrite(\'test/mask.png\', drawMaskImage(background))\n    #exit(1)\n    \n    textureHeight = float(textureImage.shape[0])\n    textureWidth = float(textureImage.shape[1])\n    textureRatio = textureHeight / textureWidth\n    textureSizes2D = np.array([textureWidth, textureHeight])\n    \n    #textureSizeU = 0.96\n    #textureSizeU = 0.3048\n    textureSizeU = 0.9144\n    #textureSizeU = 0.78\n    textureSizeV = textureSizeU * textureRatio\n    textureSizes = np.array([textureSizeU, textureSizeV])\n    #textureImage = cv2.imread(\'../textures/texture_2.jpg\')\n    #textureImage = cv2.resize(textureImage, (width, height), interpolation=cv2.INTER_LINEAR)\n\n\n    # find the boundary point\n    distances = np.linalg.norm(boundaryPoints - startPoint, axis=-1) + np.linalg.norm(boundaryPoints - endPoint, axis=-1)\n    boundaryPoint = boundaryPoints[np.argmin(distances)]\n\n    print(startPoint)\n    print(startPoint[0] / startPoint[1] * camera[\'fx\'] + camera[\'cx\'], -startPoint[2] / startPoint[1] * camera[\'fy\'] + camera[\'cy\'])    \n    print(boundaryPoint)\n    print(boundaryPoint[0] / boundaryPoint[1] * camera[\'fx\'] + camera[\'cx\'], -boundaryPoint[2] / boundaryPoint[1] * camera[\'fy\'] + camera[\'cy\'])\n\n    boundaryPointNeighbors = boundaryPoints[np.linalg.norm(boundaryPoints - boundaryPoint, axis=-1) < 0.05]\n    boundaryDirections = []\n    for boundaryPointNeighbor in boundaryPointNeighbors:\n        boundaryDirection = boundaryPointNeighbor - boundaryPoint\n        norm = np.linalg.norm(boundaryDirection, axis=-1)\n        if norm < 1e-4:\n            continue\n        boundaryDirection /= norm\n        if np.dot(np.cross(boundaryPoint - startPoint, planesNormal[startPlaneIndex]), boundaryDirection) > 0:\n            boundaryDirections.append(boundaryDirection)\n        else:\n            boundaryDirections.append(-boundaryDirection)\n            pass\n        continue\n\n    \n    if len(boundaryDirections) == 0:\n        distances = np.argmin(np.linalg.norm(boundaryPoints - boundaryPoint, axis=-1))\n        neighborIndex = np.argpartition(distances, 2)[1]\n        boundaryNeighbor = boundaryPoints[neighborIndex]\n        boundaryDirection = boundaryPointNeighbor - boundaryPoint\n        norm = np.linalg.norm(boundaryDirection, axis=-1)\n        boundaryDirection /= norm\n        boundaryDirections.append(boundaryDirection)\n        pass\n    \n    boundaryDirections = np.array(boundaryDirections)\n\n    boundaryDirection = boundaryDirections.mean(0)\n    boundaryDirection /= np.linalg.norm(boundaryDirection)\n\n\n    boundaryNormal = np.cross(boundaryDirection, endPoint - boundaryPoint)\n    boundaryNormal /= np.linalg.norm(boundaryNormal)\n\n    totalLength = np.linalg.norm(endPoint - boundaryPoint) + np.linalg.norm(boundaryPoint - startPoint)\n    distanceOffset = 0\n\n    resultImage = image.copy().reshape((-1, 3))    \n\n    camera = getCameraFromInfo(info)\n    #print(camera)\n    #print(\'total length\', totalLength, np.linalg.norm(endPoint - boundaryPoint), np.linalg.norm(boundaryPoint - startPoint))\n    #exit(1)\n    firstSegment = True\n\n    #IBL = IBL.reshape((width * height, -1))\n\n    # draw two segments of ruler (from the starting point to the boundary point and from the boundary point to the ending point)\n    for point_1, point_2, planeNormal in [(startPoint, boundaryPoint, planesNormal[startPlaneIndex]), (boundaryPoint, endPoint, boundaryNormal)]:\n        if point_1[0] == point_2[0] and point_1[1] == point_2[1]:\n            continue\n\n        #planeNormal = np.cross(endPoint - startPoint, verticalDirection)\n        #planeNormal = planeNormal / np.linalg.norm(planeNormal)\n        planeD = np.dot(point_1, planeNormal)\n    \n        urange = (np.arange(width, dtype=np.float32) / width * camera[\'width\'] - camera[\'cx\']) / camera[\'fx\']\n        urange = urange.reshape(1, -1).repeat(height, 0)\n        vrange = (np.arange(height, dtype=np.float32) / height * camera[\'height\'] - camera[\'cy\']) / camera[\'fy\']\n        vrange = vrange.reshape(-1, 1).repeat(width, 1)\n\n        coef = urange * planeNormal[0] + planeNormal[1] + (-vrange) * planeNormal[2]\n        Y = planeD / coef\n        X = urange * Y\n        Z = -vrange * Y\n        XYZ = np.stack([X, Y, Z], axis=2)    \n\n\n        direction_u = point_2 - point_1\n        direction_u = direction_u / np.maximum(np.linalg.norm(direction_u), 1e-4)\n        direction_v = -np.cross(planeNormal, direction_u)\n        direction_v = direction_v / np.maximum(np.linalg.norm(direction_v), 1e-4)\n\n        \n        offset_v = np.dot(point_1, direction_v)\n\n        if firstSegment:\n            direction_u *= 0.6\n            #point_2 -= direction_u * 0.001\n            offset_v -= 0.002\n        else:\n            distanceOffset -= 0.02\n            pass\n\n        offset_u = np.dot(point_1, direction_u)\n        \n        projection_u = np.tensordot(XYZ, direction_u, axes=([2], [0])).reshape(-1)\n        projection_v = np.tensordot(XYZ, direction_v, axes=([2], [0])).reshape(-1)\n\n        \n        projection_u = (projection_u - offset_u + distanceOffset) / textureSizeU\n        projection_v = (projection_v - offset_v) / textureSizeV\n\n        # print(\'u\', projection_u[850 * width + 1050])\n        # print(\'u\', projection_u[958 * width + 1060])\n        # print(\'u\', projection_u[1064 * width + 1074])                \n        # print(point_1, point_2, planeNormal)\n        # print(np.dot(planeNormal, point_2 - point_1))\n        # print(np.dot(point_1, planeNormal) - planeD, np.dot(point_2, planeNormal) - planeD)\n\n        \n        for frameIndex in xrange(numFrames):\n            maxOffset = min(float(frameIndex + 1) / numFrames * totalLength, distanceOffset + np.linalg.norm(point_2 - point_1))\n            minOffset = max(float(frameIndex) / numFrames * totalLength, distanceOffset)\n            #print(minOffset, maxOffset)\n            if minOffset >= maxOffset:\n                continue\n\n            if firstSegment:\n                maxOffset = min(maxOffset, distanceOffset + np.linalg.norm(point_2 - point_1) - 0.018)\n                pass\n            \n            rectangleMask = np.logical_and(np.logical_and(projection_u >= minOffset / textureSizeU, projection_u < maxOffset / textureSizeU), np.logical_and(projection_v >= 0, projection_v <= 1))\n\n            rectangleIndices = rectangleMask.nonzero()[0]\n\n            projections = np.stack([projection_u[rectangleIndices], projection_v[rectangleIndices]], axis=1)\n            uv = projections * textureSizes2D\n        \n            uv[:, 1] = textureSizes2D[1] - 1 - uv[:, 1]\n            uv = np.maximum(np.minimum(uv, textureSizes2D - 1), 0)\n\n\n            u = uv[:, 0]\n            v = uv[:, 1]\n            u_min = np.floor(u).astype(np.int32)\n            u_max = np.ceil(u).astype(np.int32)\n            v_min = np.floor(v).astype(np.int32)\n            v_max = np.ceil(v).astype(np.int32)\n\n            area_11 = (u_max - u) * (v_max - v)\n            area_12 = (u_max - u) * (v - v_min)\n            area_21 = (u - u_min) * (v_max - v)\n            area_22 = (u - u_min) * (v - v_min)\n\n            area_11 = np.expand_dims(area_11, -1)\n            area_12 = np.expand_dims(area_12, -1)\n            area_21 = np.expand_dims(area_21, -1)\n            area_22 = np.expand_dims(area_22, -1)\n\n\n            colors_11 = textureImage[v_min, u_min]\n            colors_12 = textureImage[v_max, u_min]\n            colors_21 = textureImage[v_min, u_max]\n            colors_22 = textureImage[v_max, u_max]\n\n            alphas_11 = alphaMask[v_min, u_min]\n            alphas_12 = alphaMask[v_max, u_min]\n            alphas_21 = alphaMask[v_min, u_max]\n            alphas_22 = alphaMask[v_max, u_max]\n\n            colors = colors_11 * area_11 + colors_12 * area_12 + colors_21 * area_21 + colors_22 * area_22\n            alphas = alphas_11 * area_11 + alphas_12 * area_12 + alphas_21 * area_21 + alphas_22 * area_22\n\n\n            #print(np.expand_dims(IBL[rectangleIndices], -1))\n\n            resultImage[rectangleIndices] = np.minimum(resultImage[rectangleIndices] * (1 - alphas) + colors * alphas, 255).astype(np.uint8)\n            cv2.imwrite(folder + (\'/%04d.png\' % (indexOffset + frameIndex)), resultImage.reshape(image.shape))\n            continue\n\n        distanceOffset += np.linalg.norm(point_2 - point_1)\n        #print(point_1, point_2)\n        #print(direction_u)\n        #print(direction_v)\n        firstSegment = False\n\n        continue\n    return\n\ndef addRulerComplete(textureImageFilename, folder, indexOffset, image, depth, planes, segmentation, info, startPixel, endPixel, fixedEndPoint=False, numFrames=1):\n    width = segmentation.shape[1]\n    height = segmentation.shape[0]\n\n    #IBL = cv2.imread(\'../ibl_output/IMG_0103_IBL.exr\', -1)\n    # print(IBL.shape)\n    # print(IBL.max())\n    # print(IBL.min())\n    # print(IBL.dtype)\n    #IBL = cv2.resize(IBL, (width, height))    \n    #exit(1)\n    \n    #info[0] += 200\n    #info[5] += 200\n    #info[6] = height - info[6]\n    \n    camera = getCameraFromInfo(info)\n\n    # calculate corresponding 3D position for each pixel\n    urange = (np.arange(width, dtype=np.float32) / width * camera[\'width\'] - camera[\'cx\']) / camera[\'fx\']\n    urange = urange.reshape(1, -1).repeat(height, 0)\n    vrange = (np.arange(height, dtype=np.float32) / height * camera[\'height\'] - camera[\'cy\']) / camera[\'fy\']\n    vrange = vrange.reshape(-1, 1).repeat(width, 1)\n    X = depth * urange\n    Y = depth\n    Z = -depth * vrange\n    XYZ = np.stack([X, Y, Z], axis=2)    \n    #plane_depths = calcPlaneDepths(planes, width, height, info)\n\n    planesD = np.linalg.norm(planes, axis=-1, keepdims=True)\n    planesNormal = planes / np.maximum(planesD, 1e-4)\n\n    # find the starting plane, the ending plane, and the boundary point\n    startPlaneIndex = segmentation[startPixel[1]][startPixel[0]]\n    endPlaneIndex = segmentation[endPixel[1]][endPixel[0]]\n    assert(startPlaneIndex < planes.shape[0] and endPlaneIndex < planes.shape[0])\n    startPoint = XYZ[startPixel[1]][startPixel[0]]\n    endPoint = XYZ[endPixel[1]][endPixel[0]]\n\n\n    mask = (segmentation == startPlaneIndex).astype(np.uint8)\n\n    boundary = mask - cv2.erode(mask, np.ones((3, 3), dtype=np.uint8))\n    boundaryPoints = XYZ[boundary.nonzero()]\n    boundaryPoints = boundaryPoints[boundaryPoints[:, 1] < startPoint[1]]\n    \n    endPlane = planes[endPlaneIndex]\n    endPlaneD = np.linalg.norm(endPlane)\n    endPlaneNormal = endPlane / endPlaneD\n    endDistances = endPlaneD - np.tensordot(boundaryPoints, endPlaneNormal, axes=(1, 0))\n    distances = np.linalg.norm(boundaryPoints - startPoint, axis=-1) + np.abs(endDistances)\n    boundaryPointIndex = np.argmin(distances)\n    boundaryPoint = boundaryPoints[boundaryPointIndex]\n    endDistance = endDistances[boundaryPointIndex]\n    #finalEndPoint = boundaryPoint + endDistance * endPlaneNormal\n    #finalEndPoint = boundaryPoint + 0.30 * planesNormal[startPlaneIndex]\n    finalEndPoint = endPoint\n\n    print(\'points\', startPoint, boundaryPoint, endPoint)\n    print(startPoint[0] / startPoint[1] * camera[\'fx\'] + camera[\'cx\'], -startPoint[2] / startPoint[1] * camera[\'fy\'] + camera[\'cy\'])    \n    print(boundaryPoint[0] / boundaryPoint[1] * camera[\'fx\'] + camera[\'cx\'], -boundaryPoint[2] / boundaryPoint[1] * camera[\'fy\'] + camera[\'cy\'])\n    print(finalEndPoint)\n    print(finalEndPoint[0] / finalEndPoint[1] * camera[\'fx\'] + camera[\'cx\'], -finalEndPoint[2] / finalEndPoint[1] * camera[\'fy\'] + camera[\'cy\'])\n\n    print(np.dot(planesNormal[startPlaneIndex], boundaryPoint - startPoint))\n    print(startPlaneIndex, endPlaneIndex)\n    print(planes)\n    print(planesNormal[startPlaneIndex])\n    print(planesD)\n    #exit(1)\n    \n    #exit(1)    \n    #numExtendingFrames = 1000\n    #numAdjustFrames = 100\n    numExtendingFrames = 200\n\n    textureImage = cv2.imread(textureImageFilename)\n\n    #draw the image sequence\n    addRuler(textureImage, folder, 0, image, depth, planes, segmentation, info, startPoint, endPoint, boundaryPoints, startPlaneIndex=startPlaneIndex, fixedEndPoint=True, numFrames=numExtendingFrames)\n\n    # numAdjustFrames = 0    \n    # for frameIndex in xrange(numAdjustFrames):\n    #     newEndPoint = endPoint + (finalEndPoint - endPoint) * (frameIndex + 1) / numAdjustFrames\n    #     addRuler(textureImage, folder, numExtendingFrames + frameIndex, image, depth, planes, segmentation, info, startPoint, newEndPoint, boundaryPoints, startPlaneIndex=startPlaneIndex, fixedEndPoint=True, numFrames=1)\n    #     continue\n    return\n\n    \ndef writeGridImage(image_list, width, height, gridSize):\n    gridImage = np.zeros((height, width, 3))\n    gapX = 0.1\n    gapBetween = 0.08\n    imageWidth = float(width) / (gridSize[0] * 2 + gridSize[0] * gapBetween + (gridSize[0] + 1) * gapX)\n    gapX *= imageWidth\n    gapBetween *= imageWidth\n\n    imageHeight = imageWidth * 3 / 4\n\n    imageWidth = int(round(imageWidth))\n    imageHeight = int(round(imageHeight))\n    gapX = int(round(gapX))\n    gapBetween = int(round(gapBetween))\n    gapY = int(round(float(height - imageHeight * gridSize[1]) / (gridSize[1] + 1)))\n\n    for gridY in xrange(gridSize[1]):\n        for gridX in xrange(gridSize[0]):\n            image_filename = image_list[gridY * gridSize[0] + gridX]\n            image = cv2.imread(image_filename)\n            image = cv2.resize(image, (imageWidth, imageHeight))\n            offsetY = gapY * (gridY + 1) + imageHeight * gridY\n            offsetX = gapX * (gridX + 1) + imageWidth * gridX * 2 + gapBetween * gridX            \n            gridImage[offsetY:offsetY + imageHeight, offsetX:offsetX + imageWidth] = image\n\n            segmentation_filename = image_filename.replace(\'image\', \'segmentation_pred_blended_0\')\n            segmentation = cv2.imread(segmentation_filename)\n            segmentation = cv2.resize(segmentation, (imageWidth, imageHeight))\n\n            offsetX = gapX * (gridX + 1) + imageWidth * gridX * 2 + gapBetween * gridX + imageWidth + gapBetween\n            print(offsetX, imageWidth)\n            gridImage[offsetY:offsetY + imageHeight, offsetX:offsetX + imageWidth] = segmentation\n            continue\n        continue\n    return gridImage\n'"
PlaneSetGeneration/RecordReader.py,115,"b""import tensorflow as tf\nimport numpy as np\nimport threading\nimport PIL.Image as Image\nfrom functools import partial\nfrom multiprocessing import Pool\nimport cv2\n\nimport sys\nimport os\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom modules import *\n\n\nFETCH_BATCH_SIZE=32\nBATCH_SIZE=32\nHEIGHT=192\nWIDTH=256\nNUM_PLANES = 50\nNUM_THREADS = 4\n\n\nclass RecordReader():\n    def __init__(self):\n        return\n\n\n    def getBatch(self, filename_queue, numOutputPlanes = 20, batchSize = BATCH_SIZE, min_after_dequeue = 1000, random=True, getLocal=False, getSegmentation=False, test=True, suffix='forward'):\n        reader = tf.TFRecordReader()\n        _, serialized_example = reader.read(filename_queue)\n\n        features = tf.parse_single_example(\n            serialized_example,\n            # Defaults are not specified since both keys are required.\n            features={\n                #'height': tf.FixedLenFeature([], tf.int64),\n                #'width': tf.FixedLenFeature([], tf.int64),\n                'image_raw': tf.FixedLenFeature([], tf.string),\n                'num_planes': tf.FixedLenFeature([], tf.int64),\n                'plane': tf.FixedLenFeature([NUM_PLANES * 3], tf.float32),\n                'plane_mask': tf.FixedLenFeature([HEIGHT * WIDTH], tf.int64),\n                #'validating': tf.FixedLenFeature([], tf.int64)\n                'depth': tf.FixedLenFeature([HEIGHT * WIDTH], tf.float32),\n                'normal': tf.FixedLenFeature([HEIGHT * WIDTH * 3], tf.float32),\n                'boundary_raw': tf.FixedLenFeature([], tf.string),\n                'grid_s': tf.FixedLenFeature([HEIGHT / 8  * WIDTH / 8 * 1], tf.float32),\n                'grid_p': tf.FixedLenFeature([HEIGHT / 8  * WIDTH / 8 * 3], tf.float32),\n                'grid_m_raw': tf.FixedLenFeature([], tf.string),\n            })\n\n        # Convert from a scalar string tensor (whose single string has\n        # length mnist.IMAGE_PIXELS) to a uint8 tensor with shape\n        # [mnist.IMAGE_PIXELS].\n        image = tf.decode_raw(features['image_raw'], tf.uint8)\n        image = tf.cast(image, tf.float32) * (1. / 255) - 0.5\n        image = tf.reshape(image, [HEIGHT, WIDTH, 3])\n        \n        depth = features['depth']\n        depth = tf.reshape(depth, [HEIGHT, WIDTH, 1])\n\n        normal = features['normal']\n        normal = tf.reshape(normal, [HEIGHT, WIDTH, 3])\n\n\n        # planeAreaThreshold = 12 * 16\n        # inds, _, counts = tf.unique_with_counts(plane_masks)\n        # counts = counts * tf.cast(tf.greater(inds, 0), tf.int32)\n        # numPlanes = tf.minimum(tf.reduce_sum(tf.cast(counts > planeAreaThreshold, tf.int32)), numOutputPlanes)\n\n\n        if '_32' not in suffix and False:\n            numPlanes = tf.minimum(tf.cast(features['num_planes'], tf.int32), numOutputPlanes)\n            planes = features['plane']\n            planes = tf.reshape(planes, [NUM_PLANES, 3])\n            planes = tf.slice(planes, [0, 0], [numPlanes, 3])\n\n            plane_masks = tf.cast(features['plane_mask'], tf.int64)  \n            plane_masks = tf.reshape(plane_masks, [HEIGHT, WIDTH, 1])\n            plane_mask_array = tf.tile(plane_masks, [1, 1, NUM_PLANES])\n            coef = tf.range(tf.cast(NUM_PLANES, tf.int64), dtype=tf.int64)\n            coef = tf.pow(tf.constant(2, tf.int64), coef)\n            planeMasks = tf.reshape(tf.cast(tf.div(plane_mask_array, coef) % 2, tf.float32), [HEIGHT, WIDTH, NUM_PLANES])\n\n            #planeMasks = tf.zeros([HEIGHT, WIDTH, numOutputPlanes])\n        else:\n            numPlanes = 30\n            planes = features['plane']\n            planes = tf.reshape(planes, [NUM_PLANES, 3])\n            planes = tf.slice(planes, [0, 0], [numPlanes, 3])\n        \n            plane_masks = tf.cast(features['plane_mask'], tf.int64)  \n        \n            plane_masks = tf.reshape(plane_masks, [HEIGHT, WIDTH, 1])\n            plane_mask_array = tf.tile(plane_masks, [1, 1, numPlanes])\n            coef = tf.range(numPlanes, dtype=tf.int64)\n            coef = tf.pow(tf.constant(2, tf.int64), coef)\n            #coef = tf.reshape(tf.matmul(tf.reshape(coef, [-1, numPlanes]), tf.cast(shuffle_inds, tf.int32)), [numPlanes])\n            #coef = tf.cast(coef, tf.int64)\n            planeMasks = tf.cast(tf.div(plane_mask_array, coef) % 2, tf.float32)\n        \n            urange = tf.reshape(tf.range(WIDTH, dtype=tf.float32), [-1, 1])\n            planeXs = tf.reduce_max(planeMasks, axis=0)\n            planeMinX = WIDTH - tf.reduce_max(planeXs * (float(WIDTH) - urange), axis=0)\n            planeMaxX = tf.reduce_max(planeXs * urange, axis=0)\n\n            vrange = tf.reshape(tf.range(HEIGHT, dtype=tf.float32), [-1, 1])\n            planeYs = tf.reduce_max(planeMasks, axis=1)\n            planeMinY = HEIGHT - tf.reduce_max(planeYs * (float(HEIGHT) - vrange), axis=0)\n            planeMaxY = tf.reduce_max(planeYs * vrange, axis=0)\n\n            planeMaxX = tf.maximum(planeMinX, planeMaxX)\n            planeMaxY = tf.maximum(planeMinY, planeMaxY)\n\n            planeAreas = tf.reduce_sum(planeMasks, axis=[0, 1])\n        \n            localPlaneWidthThreshold = 32\n            localPlaneHeightThreshold = 32\n            globalPlaneAreaThreshold = 16 * 16\n            globalPlaneWidthThreshold = 8\n\n\n            globalPlaneMask = tf.logical_or(tf.greater(planeMaxX - planeMinX, localPlaneWidthThreshold), tf.greater(planeMaxY - planeMinY, localPlaneHeightThreshold))\n            globalPlaneMask = tf.logical_and(globalPlaneMask, tf.greater((planeMaxX - planeMinX) * (planeMaxY - planeMinY), globalPlaneAreaThreshold))\n            globalPlaneMask = tf.logical_and(globalPlaneMask, tf.greater(planeAreas / tf.sqrt(tf.pow(planeMaxX + 1 - planeMinX, 2) + tf.pow(planeMaxY + 1 - planeMinY, 2)), globalPlaneWidthThreshold))\n            #globalPlaneMask = tf.logical_or(globalPlaneMask, tf.less(tf.range(numPlanes), tf.cast(features['num_planes'], tf.int32)))\n            #globalPlaneMask = tf.cast(tf.squeeze(globalPlaneMask, axis=[2]), tf.float32)\n            globalPlaneMask = tf.cast(globalPlaneMask, tf.float32)\n\n            weightedPlaneAreas = globalPlaneMask * (planeAreas + HEIGHT * WIDTH) + (1 - globalPlaneMask) * planeAreas\n\n            #test = tf.reshape(tf.stack([globalPlaneMask, planeAreas, weightedPlaneAreas, planeMinX, planeMaxX, planeMinY, planeMaxY], axis=0), [7, numPlanes])\n            \n            planeAreas, sortInds = tf.nn.top_k(weightedPlaneAreas, k=numPlanes)\n            sortMap = tf.one_hot(sortInds, depth=numPlanes, axis=0)\n\n            planeMasks = tf.reshape(tf.matmul(tf.reshape(planeMasks, [HEIGHT * WIDTH, numPlanes]), sortMap), [HEIGHT, WIDTH, numPlanes])\n            planes = tf.transpose(tf.matmul(planes, sortMap, transpose_a=True), [1, 0])\n        \n            numPlanes = tf.minimum(tf.cast(tf.round(tf.reduce_sum(globalPlaneMask)), tf.int32), numOutputPlanes)\n            \n            planes = tf.slice(planes, [0, 0], [numPlanes, 3])\n            planeMasks = tf.slice(planeMasks, [0, 0, 0], [HEIGHT, WIDTH, numPlanes])\n            planeMasks = tf.reshape(tf.concat([planeMasks, tf.zeros([HEIGHT, WIDTH, numOutputPlanes - numPlanes])], axis=2), [HEIGHT, WIDTH, numOutputPlanes])\n            pass\n\n        # planeMasks_expanded = tf.expand_dims(planeMasks, 0)\n        # boundary = tf.reduce_max(tf.nn.max_pool(planeMasks_expanded, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding='SAME', name='max_pool') - planeMasks_expanded, axis=3, keep_dims=True)\n        # max_depth_diff = 0.1\n        # depth_expanded = tf.expand_dims(depth, 0)\n        # kernel_size = 5\n        # padding = (kernel_size - 1) / 2\n        # neighbor_kernel_array = gaussian(kernel_size, kernel_size)\n        # neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n        # neighbor_kernel_array /= neighbor_kernel_array.sum()\n        # neighbor_kernel_array *= -1\n        # neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 1\n        # neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n        # neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n        \n        # depth_diff = tf.abs(tf.nn.depthwise_conv2d(depth_expanded, neighbor_kernel, strides=[1, 1, 1, 1], padding='VALID'))\n        # depth_diff = tf.pad(depth_diff, paddings = [[0, 0], [padding, padding], [padding, padding], [0, 0]])\n        # smooth_boundary = boundary * tf.cast(tf.less(depth_diff, max_depth_diff), tf.float32)\n        # occlusion_boundary = boundary - smooth_boundary\n        # boundary = tf.squeeze(tf.concat([smooth_boundary, occlusion_boundary], axis=3), axis=0)\n\n        \n        #validating = tf.cast(features['validating'], tf.float32)        \n        shuffle_inds = tf.one_hot(tf.random_shuffle(tf.range(numPlanes)), depth = numPlanes)\n        #shuffle_inds = tf.one_hot(tf.range(numPlanes), depth = numPlanes)\n        \n        #shuffle_inds = tf.concat([shuffle_inds, tf.zeros((numPlanes, numOutputPlanes - numPlanes))], axis=1)\n        #shuffle_inds = tf.concat([shuffle_inds, tf.concat([tf.zeros((numOutputPlanes - numPlanes, numPlanes)), tf.diag(tf.ones([numOutputPlanes - numPlanes]))], axis=1)], axis=0)\n        planes = tf.transpose(tf.matmul(tf.transpose(planes), shuffle_inds))\n        planes = tf.reshape(planes, [numPlanes, 3])\n        planes = tf.concat([planes, tf.zeros([numOutputPlanes - numPlanes, 3])], axis=0)\n        planes = tf.reshape(planes, [numOutputPlanes, 3])\n\n        \n        boundary = tf.decode_raw(features['boundary_raw'], tf.uint8)\n        boundary = tf.cast(boundary > 128, tf.float32)\n        boundary = tf.reshape(boundary, [HEIGHT, WIDTH, 2])\n        #boundary = tf.slice(tf.reshape(boundary, [HEIGHT, WIDTH, 3]), [0, 0, 0], [HEIGHT, WIDTH, 2])\n\n        grid_s = tf.reshape(features['grid_s'], [HEIGHT / 8, WIDTH / 8, 1])       \n        grid_p = tf.reshape(features['grid_p'], [HEIGHT / 8, WIDTH / 8, 3])\n        \n        grid_m = tf.decode_raw(features['grid_m_raw'], tf.uint8)\n        grid_m = tf.cast(tf.reshape(grid_m, [HEIGHT / 8, WIDTH / 8, 16 * 16]), tf.float32)\n\n        if getLocal:\n            if random:\n                image_inp, plane_inp, depth_gt, normal_gt, plane_mask_inp, boundary_gt, grid_s_gt, grid_p_gt, grid_m_gt, num_planes_gt = tf.train.shuffle_batch([image, planes, depth, normal, planeMasks, boundary, grid_s, grid_p, grid_m, numPlanes], batch_size=batchSize, capacity=min_after_dequeue + (NUM_THREADS + 2) * batchSize, num_threads=NUM_THREADS, min_after_dequeue=min_after_dequeue)\n            else:\n                image_inp, plane_inp, depth_gt, normal_gt, plane_mask_inp, boundary_gt, grid_s_gt, grid_p_gt, grid_m_gt, num_planes_gt = tf.train.batch([image, planes, depth, normal, planeMasks, boundary, grid_s, grid_p, grid_m, numPlanes], batch_size=batchSize, capacity=(NUM_THREADS + 2) * batchSize, num_threads=1)\n                pass\n            return image_inp, plane_inp, depth_gt, normal_gt, plane_mask_inp, boundary_gt, grid_s_gt, grid_p_gt, grid_m_gt, num_planes_gt\n\n        \n        if not getSegmentation:\n            if random:\n                image_inp, plane_inp, depth_gt, normal_gt, plane_mask_inp = tf.train.shuffle_batch([image, planes, depth, normal, tf.zeros([HEIGHT, WIDTH, numOutputPlanes])], batch_size=batchSize, capacity=min_after_dequeue + (NUM_THREADS + 2) * batchSize, num_threads=NUM_THREADS, min_after_dequeue=min_after_dequeue)\n            else:\n                image_inp, plane_inp, depth_gt, normal_gt, plane_mask_inp = tf.train.batch([image, planes, depth, normal, tf.zeros([HEIGHT, WIDTH, numOutputPlanes])], batch_size=batchSize, capacity=(NUM_THREADS + 2) * batchSize, num_threads=NUM_THREADS)\n                pass\n            return image_inp, plane_inp, depth_gt, normal_gt, plane_mask_inp\n\n\n        plane_masks = tf.cast(features['plane_mask'], tf.int64)  \n        \n        plane_masks = tf.reshape(plane_masks, [HEIGHT, WIDTH, 1])\n        plane_mask_array = tf.tile(plane_masks, [1, 1, numPlanes])\n        coef = tf.range(numPlanes, dtype=tf.int64)\n        coef = tf.pow(2, coef)\n        coef = tf.reshape(tf.matmul(tf.reshape(coef, [-1, numPlanes]), tf.cast(shuffle_inds, tf.int64)), [numPlanes])\n        coef = tf.cast(coef, tf.int64)\n        plane_mask_array = tf.cast(tf.div(plane_mask_array, coef) % 2, tf.float32)\n        plane_mask_array = tf.concat([plane_mask_array, tf.zeros([HEIGHT, WIDTH, numOutputPlanes - numPlanes])], axis=2)\n        plane_mask_array = tf.reshape(plane_mask_array, [HEIGHT, WIDTH, numOutputPlanes])\n        #num_planes_array = tf.concat([tf.ones([numPlanes], dtype=np.float32) / tf.cast(numPlanes * BATCH_SIZE, np.float32), tf.zeros([numOutputPlanes - numPlanes])], axis=0)\n\n        #image_inp, plane_inp, depth_gt, normal_gt, plane_mask_inp, num_planes, mask = tf.train.shuffle_batch([image, planes, depth, normal, plane_mask_array, numPlanes, plane_masks_test], batch_size=batchSize, capacity=min_after_dequeue + (NUM_THREADS + 2) * batchSize, num_threads=NUM_THREADS, min_after_dequeue=min_after_dequeue)\n\n        # if True:\n        #     image_inp, plane_inp, depth_gt, normal_gt, plane_mask_inp = tf.train.batch([image, planes, tf.ones((HEIGHT, WIDTH, 1)), tf.ones((HEIGHT, WIDTH, 3)), plane_mask_array], batch_size=batchSize, capacity=(NUM_THREADS + 2) * batchSize, num_threads=NUM_THREADS)\n        #     return image_inp, plane_inp, depth_gt, normal_gt, plane_mask_inp\n\n        if random:\n            image_inp, plane_inp, depth_gt, normal_gt, plane_mask_inp, boundary_gt, grid_s_gt, grid_p_gt, grid_m_gt, num_planes_gt = tf.train.shuffle_batch([image, planes, depth, normal, plane_mask_array, boundary, grid_s, grid_p, grid_m, numPlanes], batch_size=batchSize, capacity=min_after_dequeue + (NUM_THREADS + 2) * batchSize, num_threads=NUM_THREADS, min_after_dequeue=min_after_dequeue)            \n            image_inp, plane_inp, depth_gt, normal_gt, plane_mask_gt, boundary_gt, num_planes_gt = tf.train.shuffle_batch([image, planes, depth, normal, plane_mask_array, boundary, numPlanes], batch_size=batchSize, capacity=min_after_dequeue + (NUM_THREADS + 2) * batchSize, num_threads=NUM_THREADS, min_after_dequeue=min_after_dequeue)\n        else:\n            image_inp, plane_inp, depth_gt, normal_gt, plane_mask_inp, boundary_gt, grid_s_gt, grid_p_gt, grid_m_gt, num_planes_gt = tf.train.batch([image, planes, depth, normal, plane_mask_array, boundary, grid_s, grid_p, grid_m, numPlanes], batch_size=batchSize, capacity=(NUM_THREADS + 2) * batchSize, num_threads=1)            \n            pass\n        return image_inp, plane_inp, depth_gt, normal_gt, plane_mask_inp, boundary_gt, grid_s_gt, grid_p_gt, grid_m_gt, num_planes_gt\n"""
PlaneSetGeneration/layers.py,0,"b'import os\nimport numpy as np\n\n#DEBUG = False\n\nclass RangesLayer(object):\n  def __init__(self, width, height):\n\n    focalLength = 517.97\n    urange = np.arange(width).reshape(1, -1).repeat(height, 0) - width * 0.5\n    vrange = np.arange(height).reshape(-1, 1).repeat(width, 1) - height * 0.5\n    self.ranges = np.array([urange / focalLength / width * 640, np.ones(urange.shape), -vrange / focalLength / height * 480]).transpose([1, 2, 0])\n    return\n      \n  def forward(self):\n    return self.ranges\n\n\ndef PlaneDepthLayer(planes, ranges):\n  batchSize = 1\n  if len(planes.shape) == 3:\n    batchSize = planes.shape[0]\n    planes = planes.reshape(planes.shape[0] * planes.shape[1], planes.shape[2])\n    pass\n  \n  planesD = np.linalg.norm(planes, 2, 1)\n  planesD = np.maximum(planesD, 1e-4)\n  planesNormal = -planes / planesD.reshape(-1, 1).repeat(3, 1)\n\n  normalXYZ = np.dot(ranges, planesNormal.transpose())\n  normalXYZ[normalXYZ == 0] = 1e-4\n  normalXYZ = 1 / normalXYZ\n  depths = -normalXYZ\n  depths[:, :] *= planesD\n  if batchSize > 1:\n    depths = depths.reshape(depths.shape[0], depths.shape[1], batchSize, -1).transpose([2, 0, 1, 3])\n    pass\n  depths[(depths < 0) + (depths > 10)] = 10\n  #depths[depths < 0] = 0\n  #depths[depths > 10] = 10\n  return depths\n\n\ndef PlaneNormalLayer(planes, ranges):\n  batchSize = 1\n  if len(planes.shape) == 3:\n    batchSize = planes.shape[0]\n    planes = planes.reshape(planes.shape[0] * planes.shape[1], planes.shape[2])\n    pass\n  planesD = np.linalg.norm(planes, 2, 1)\n  planesD = np.maximum(planesD, 1e-4)\n  planesNormal = -planes / planesD.reshape(-1, 1).repeat(3, 1)\n  normals = planesNormal.reshape(1, 1, -1, 3).repeat(ranges.shape[0], 0).repeat(ranges.shape[1], 1)\n  if batchSize > 1:\n    normals = normals.reshape(normals.shape[0], normals.shape[1], batchSize, -1, 3).transpose([2, 0, 1, 3, 4])\n    pass\n  return normals\n'"
PlaneSetGeneration/modules.py,448,"b'import tensorflow as tf\nimport numpy as np\n\ndef segmentationRefinementModule(segmentation, planeDepths, numOutputPlanes = 20, gpu_id = 0, coef = [1, 1, 1], beta = 10):\n    with tf.device(\'/gpu:%d\'%gpu_id):\n        S = segmentation\n        #S = tf.one_hot(tf.argmax(S, 3), numOutputPlanes)\n        D = tf.tile(tf.expand_dims(planeDepths, -1), [1, 1, 1, 1, numOutputPlanes])\n        D_transpose = tf.tile(tf.expand_dims(planeDepths, 3), [1, 1, 1, numOutputPlanes, 1])\n        D_diff = tf.abs(D - D_transpose)\n        batchSize = int(segmentation.shape[0])\n        height = int(segmentation.shape[1])\n        width = int(segmentation.shape[2])\n        S_neighbor_up = tf.concat([tf.zeros([batchSize, 1, width, numOutputPlanes]), tf.slice(S, [0, 0, 0, 0], [batchSize, height - 1, width, numOutputPlanes])], axis = 1)\n        S_neighbor_down = tf.concat([tf.slice(S, [0, 1, 0, 0], [batchSize, height - 1, width, numOutputPlanes]), tf.zeros([batchSize, 1, width, numOutputPlanes]), ], axis = 1)\n        S_neighbor_left = tf.concat([tf.zeros([batchSize, height, 1, numOutputPlanes]), tf.slice(S, [0, 0, 0, 0], [batchSize, height, width - 1, numOutputPlanes])], axis = 2)\n        S_neighbor_right = tf.concat([tf.slice(S, [0, 0, 1, 0], [batchSize, height, width - 1, numOutputPlanes]), tf.zeros([batchSize, height, 1, numOutputPlanes]), ], axis = 2)\n        #S_neighbors = tf.stack([S_neighbor_up, S_neighbor_down, S_neighbor_left, S_neighbor_right], axis = 4)\n        S_neighbors = (S_neighbor_up + S_neighbor_down + S_neighbor_left + S_neighbor_right) / 4\n        DS = tf.reduce_sum(tf.multiply(D_diff, tf.expand_dims(S_neighbors, 3)), axis=4)\n        #test = tf.multiply(D_diff, tf.expand_dims(S_neighbors, 3))\n        #S_diff = tf.tile(tf.reduce_sum(S_neighbors, axis=3, keep_dims=True), [1, 1, 1, numOutputPlanes]) - S_neighbors\n        S_diff = tf.ones(S_neighbors.shape) - S_neighbors\n        pass\n    P = tf.clip_by_value(S, 1e-4, 1)\n    DS = tf.clip_by_value(DS / 0.5, 1e-4, 1)\n    S_diff = tf.clip_by_value(S_diff, 1e-4, 1)\n    #return tf.nn.softmax(-beta * (-coef[0] * tf.log(P) + coef[1] * tf.log(DS) + coef[2] * tf.log(S_diff))), tf.nn.softmax(tf.log(P)), 1 - tf.clip_by_value(DS / 2, 0, 1), 1 - S_diff, 1 - tf.clip_by_value(tf.multiply(D_diff, tf.expand_dims(S_neighbors, 3)) / 2, 0, 1), S_neighbors, D_diff\n    return tf.nn.softmax(-beta * (-coef[0] * tf.log(P) + coef[1] * tf.log(DS) + coef[2] * tf.log(S_diff)))\n\ndef planeDepthsModule(plane_parameters, width, height):\n    focalLength = 517.97\n    urange = (tf.range(width, dtype=tf.float32) / (width + 1) - 0.5) / focalLength * 641\n    urange = tf.tile(tf.reshape(urange, [1, -1]), [height, 1])\n    vrange = (tf.range(height, dtype=tf.float32) / (height + 1) - 0.5) / focalLength * 481\n    vrange = tf.tile(tf.reshape(vrange, [-1, 1]), [1, width])\n            \n    ranges = tf.stack([urange, np.ones([height, width]), -vrange], axis=2)\n    ranges = tf.reshape(ranges, [-1, 3])\n            \n    planesD = tf.norm(plane_parameters, axis=1, keep_dims=True)\n    planesD = tf.clip_by_value(planesD, 1e-5, 10)\n    planesNormal = tf.div(tf.negative(plane_parameters), tf.tile(planesD, [1, 3]))\n\n    normalXYZ = tf.matmul(ranges, planesNormal, transpose_b=True)\n    normalXYZ = tf.multiply(tf.sign(normalXYZ), tf.clip_by_value(tf.abs(normalXYZ), 1e-4, 1000000))\n    normalXYZ = tf.reciprocal(normalXYZ)\n    plane_depths = tf.negative(normalXYZ) * tf.reshape(planesD, [-1])\n    plane_depths = tf.reshape(plane_depths, [height, width, -1])\n\n    plane_depths = tf.clip_by_value(plane_depths, 0, 10)\n    \n    return plane_depths\n\ndef planeNormalsModule(plane_parameters, width, height):\n    planesD = tf.norm(plane_parameters, axis=1, keep_dims=True)\n    planesD = tf.clip_by_value(planesD, 1e-5, 10)\n    planesNormal = tf.div(tf.negative(plane_parameters), planesD)\n\n    #plane_normals = tf.tile(tf.reshape(planesNormal, [1, 1, -1, 3]), [height, width, 1, 1])\n    #plane_normals = tf.reshape(planesNormal, [1, 1, -1, 3])\n    return planesNormal\n\ndef gaussian(k=5, sig=1.):\n    """"""\n    creates gaussian kernel with side length l and a sigma of sig\n    """"""\n\n    ax = np.arange(-k // 2 + 1., k // 2 + 1.)\n    xx, yy = np.meshgrid(ax, ax)\n\n    kernel = np.exp(-(xx**2 + yy**2) / (2. * sig**2))\n\n    return kernel / np.sum(kernel)\n\ndef meanfieldModuleLayer(layerSegmentations, planeDepths, numOutputPlanes = 20, numLayers=2, coef = [1, 1, 1], beta = 1, iteration = 0, sigmaDepthDiff = 0.5):\n    batchSize = int(planeSegmentations.shape[0])\n    height = int(planeSegmentations.shape[1])\n    width = int(planeSegmentations.shape[2])\n\n    minDepthDiff = 0.1\n    #P = planeSegmentations\n    #S = tf.one_hot(tf.argmax(planeSegmentations, 3), depth=numOutputPlanes)\n    kernel_size = 9\n    neighbor_kernel_array = gaussian(kernel_size, kernel_size)\n    neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n    neighbor_kernel_array /= neighbor_kernel_array.sum()\n    neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n    neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n\n\n    layerDepths = []\n    layerSs = []\n    for layer in xrange(numLayers):\n        S = tf.one_hot(tf.argmax(planeSegmentations, 3), depth=numOutputPlanes)\n        layerDepth = tf.reduce_sum(planeDepths * S, 3, keep_dims=True)\n        layerSs.append(S)\n        layerDepths.append(layerDepth)\n\n    DSs = []\n    conflictDs = []\n    conflictDepthThreshold = 0.1\n    \n    for layer in xrange(numLayers):        \n        DS_diff = tf.exp(-tf.pow(1 - tf.clip_by_value(tf.abs(planeDepths - layerDepths[layer]), 0, 1), 2) / sigmaDepthDiff) - tf.exp(-1 / sigmaDepthDiff) * layerSs[layer]\n        DS = tf.nn.depthwise_conv2d(DS_diff, tf.tile(neighbor_kernel, [1, 1, numOutputPlanes, 1]), strides=[1, 1, 1, 1], padding=\'SAME\')\n        DSs.append(DS)\n        \n        conflictD = tf.zeros((batchSize, height, width, 1))\n        if layer > 0:\n            minDepth = tf.min(tf.concat(layerDepths[:layer - 1], axis=3), axis=3, keep_dims=True)\n            conflictD = tf.maximum(conflictD, layerDepths[layer] - minDepth)\n            pass\n        if layer < numLayers - 1:\n            maxDepth = tf.max(tf.concat(layerDepths[layer + 1:], axis=3), axis=3, keep_dims=True)\n            conflictD = tf.maximum(conflictD, maxDepth -  layerDepths[layer])\n            pass\n        conflictDs.append(tf.cast(conflictD > conflictDepthThreshold, tf.float32))\n\n        \n    P = tf.clip_by_value(P, 1e-4, 1)\n    confidence = P * tf.exp(-coef[1] * DS)\n    refined_segmentation = tf.nn.softmax(tf.log(confidence))\n    return refined_segmentation\n  \ndef meanfieldModule(planeSegmentations, planeDepths, numOutputPlanes = 20, coef = [1, 1, 1], beta = 1, iteration = 0, sigmaDepthDiff = 0.5):\n    batchSize = int(planeSegmentations.shape[0])\n    height = int(planeSegmentations.shape[1])\n    width = int(planeSegmentations.shape[2])\n\n    minDepthDiff = 0.1\n    P = planeSegmentations\n\n    \n    #normalDotThreshold = np.cos(np.deg2rad(30))\n    #N_diff = tf.matmul(planeNormals, planeNormals, transpose_b=True)\n    #N_diff_mask = tf.cast((N_diff < normalDotThreshold), tf.float) + tf.diag(tf.ones(numOutputPlanes))\n    #N_diff = tf.clip(N_diff, minDepthDiff, 1)\n    #N_diff_mask = tf.expand_dims(tf.expand_dims(N_diff_mask, 1), 1)\n\n    #D_diff = (D_diff - minDepthDiff) * N_diff_mask + minDepthDiff\n\n\n    #confidenceThreshold = 0.00\n    #P_truncated = P * (P >= confidenceThreshold).astype(tf.float)\n    S = tf.one_hot(tf.argmax(planeSegmentations, 3), depth=numOutputPlanes)\n\n    # D = tf.tile(tf.expand_dims(planeDepths, -1), [1, 1, 1, 1, numOutputPlanes])\n    # D_transpose = tf.tile(tf.expand_dims(planeDepths, 3), [1, 1, 1, numOutputPlanes, 1])\n    # D_diff = tf.abs(D - D_transpose)\n    # DS_weight = tf.exp(-tf.pow(tf.clip_by_value(1 - D_diff / maxDepthDiff, 0, 1), 2) / sigmaDepthDiff)\n    # DS_diff = tf.reduce_sum(DS_weight * tf.expand_dims(S, 3), axis=4) - tf.exp(-1 / sigmaDepthDiff) * S\n\n    DS_diff = tf.exp(-tf.pow(1 - tf.clip_by_value(tf.abs(planeDepths - tf.reduce_sum(planeDepths * S, 3, keep_dims=True)), 0, 1), 2) / sigmaDepthDiff) - tf.exp(-1 / sigmaDepthDiff) * S\n    \n    kernel_size = 9\n    neighbor_kernel_array = gaussian(kernel_size, kernel_size)\n    neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n    neighbor_kernel_array /= neighbor_kernel_array.sum()\n    neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n    neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n\n    DS = tf.nn.depthwise_conv2d(DS_diff, tf.tile(neighbor_kernel, [1, 1, numOutputPlanes, 1]), strides=[1, 1, 1, 1], padding=\'SAME\')\n    \n\n    P = tf.clip_by_value(P, 1e-4, 1)\n    confidence = P * tf.exp(-coef[1] * DS)\n    #confidence = coef[0] * P + tf.exp(-coef[1] * DS) + tf.exp(-coef[2] * S_diff)\n    #confidence[:, :, :, numOutputPlanes] = 1e-4\n    #confidence = tf.clip(confidence, 1e-4, 1)\n    refined_segmentation = tf.nn.softmax(tf.log(confidence))\n    return refined_segmentation\n\n\ndef segmentationRefinementModule(planeSegmentations, planeDepths, numOutputPlanes = 20, numIterations=20):\n    #maxDepthDiff = tf.Variable(0.3)\n    #sigmaDepthDiff = tf.Variable(0.5)\n    maxDepthDiff = 0.3\n    sigmaDepthDiff = 0.5\n\n    refined_segmentation = planeSegmentations\n    for _ in xrange(numIterations):\n        refined_segmentation = meanfieldModule(refined_segmentation, planeDepths, numOutputPlanes=numOutputPlanes, sigmaDepthDiff=sigmaDepthDiff)\n        continue\n    return refined_segmentation\n\n\ndef meanfieldModuleBoundary(planeSegmentations, originalSegmentations, planeDepths, occlusionBoundary = 0, smoothBoundary = 0, numOutputPlanes = 20, coef = [1, 10, 1], beta = 1, iteration = 0, sigmaDepthDiff = 0.5):\n    batchSize = int(planeSegmentations.shape[0])\n    height = int(planeSegmentations.shape[1])\n    width = int(planeSegmentations.shape[2])\n\n    #S = tf.one_hot(tf.argmax(planeSegmentations, 3), depth=numOutputPlanes)\n    #D_diff = tf.clip_by_value(tf.abs(planeDepths - tf.reduce_sum(planeDepths * S, 3, keep_dims=True)), 0, 1) * smoothBoundary + tf.clip_by_value(1 - smoothBoundary - occlusionBoundary, 0, 1)\n    #DS_diff = tf.exp(-tf.pow(1 - D_diff, 2) / sigmaDepthDiff) - tf.exp(-1 / sigmaDepthDiff) * S\n    #DS_diff = DS_diff * smoothBoundary + (tf.exp(-1 / sigmaDepthDiff) * occlusionBoundary + tf.clip_by_value(1 - smoothBoundary - occlusionBoundary, 0, 1)) * (1 - S)\n\n    maxDepthDiff = 0.5\n    S = planeSegmentations\n    D_diff = tf.abs(planeDepths - tf.reduce_sum(planeDepths * S, 3, keep_dims=True))\n    DS_diff = tf.clip_by_value(D_diff / maxDepthDiff, 0, 1)\n    DS_diff = DS_diff * (1 - occlusionBoundary)\n    #+ (1 - S) * occlusionBoundary * 0.1\n    \n    kernel_size = 5\n    neighbor_kernel_array = gaussian(kernel_size, kernel_size)\n    neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n    neighbor_kernel_array /= neighbor_kernel_array.sum()\n    neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n    neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n\n    DS = tf.nn.depthwise_conv2d(DS_diff, tf.tile(neighbor_kernel, [1, 1, numOutputPlanes, 1]), strides=[1, 1, 1, 1], padding=\'VALID\')\n    padding = (kernel_size - 1) / 2\n    DS = tf.pad(DS, paddings = [[0, 0], [padding, padding], [padding, padding], [0, 0]])\n    \n    P = originalSegmentations\n    P = tf.clip_by_value(P, 1e-4, 1)\n    confidence = P * tf.exp(-coef[1] * DS)\n    #confidence = coef[0] * P + tf.exp(-coef[1] * DS) + tf.exp(-coef[2] * S_diff)\n    #confidence[:, :, :, numOutputPlanes] = 1e-4\n    #confidence = tf.clip(confidence, 1e-4, 1)\n    refined_segmentation = tf.nn.softmax(tf.log(confidence))\n    return refined_segmentation\n\n\ndef segmentationRefinementModuleBoundary(planeSegmentations, planeDepths, occlusionBoundary = 0, smoothBoundary = 0, numOutputPlanes = 20, numIterations=20):\n    #maxDepthDiff = tf.Variable(0.3)\n    #sigmaDepthDiff = tf.Variable(0.5)\n    maxDepthDiff = 0.3\n    sigmaDepthDiff = 0.5\n\n    refined_segmentation = planeSegmentations\n\n    #occlusionBoundary = tf.slice(boundaries, [0, 0, 0, 1], [boundaries.shape[0], boundaries.shape[1], boundaries.shape[2], 1])\n    #smoothBoundary = tf.slice(boundaries, [0, 0, 0, 2], [boundaries.shape[0], boundaries.shape[1], boundaries.shape[2], 1])\n    for _ in xrange(numIterations):\n        refined_segmentation = meanfieldModuleBoundary(refined_segmentation, planeSegmentations, planeDepths, occlusionBoundary=occlusionBoundary, smoothBoundary=smoothBoundary, numOutputPlanes=numOutputPlanes, sigmaDepthDiff=sigmaDepthDiff)\n        continue\n    return refined_segmentation\n\n\ndef planeMapModule(depth, normal, ranges):\n    #ranges = tf.reshape(ranges, [-1, 3])\n\n    planes = tf.reduce_sum(normal * ranges, 3, keep_dims=True) * depth * normal\n    return planes\n    \ndef planeFittingModule(depth, normal, numPlanes=50, numGlobalPlanes=20, planeAreaThreshold=3*4):\n    width = int(depth.shape[2])\n    height = int(depth.shape[1])\n\n    focalLength = 517.97\n    urange = (tf.range(width, dtype=tf.float32) / (width + 1) - 0.5) / focalLength * 641\n    urange = tf.tile(tf.reshape(urange, [1, -1]), [height, 1])\n    vrange = (tf.range(height, dtype=tf.float32) / (height + 1) - 0.5) / focalLength * 481\n    vrange = tf.tile(tf.reshape(vrange, [-1, 1]), [1, width])\n            \n    ranges = tf.stack([urange, tf.ones([height, width]), -vrange], axis=2)\n    ranges = tf.expand_dims(ranges, 0)\n\n    batchSize = int(depth.shape[0])\n    planeDiffThreshold = 0.1\n    #plane parameter for each pixel\n    planeMap = planeMapModule(depth, normal, ranges)\n    \n    kernel_size = 3\n    neighbor_kernel_array = gaussian(kernel_size, kernel_size)\n    neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n    neighbor_kernel_array /= neighbor_kernel_array.sum()\n    neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n    neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n    #smoothedPlaneMap = tf.nn.depthwise_conv2d(planeMap, tf.tile(neighbor_kernel, [1, 1, 3, 1]), strides=[1, 1, 1, 1], padding=\'SAME\')\n    median_kernel_array = np.zeros((3, 3, 1, 9))\n    for index in xrange(9):\n        median_kernel_array[index / 3, index % 3, 0, index] = 1\n        continue\n    median_kernel = tf.constant(median_kernel_array.reshape(-1), shape=median_kernel_array.shape, dtype=tf.float32)\n    smoothedPlaneMap = tf.nn.depthwise_conv2d(planeMap, tf.tile(median_kernel, [1, 1, 3, 1]), strides=[1, 1, 1, 1], padding=\'SAME\')\n    smoothedPlaneMap, _ = tf.nn.top_k(tf.reshape(smoothedPlaneMap, [batchSize, height, width, 3, 9]), k=5)\n    planeMap = tf.squeeze(tf.slice(smoothedPlaneMap, [0, 0, 0, 0, 4], [batchSize, height, width, 3, 1]), axis=4)\n\n    #planeDiff = tf.norm(planeMap - tf.nn.depthwise_conv2d(planeMap, tf.tile(neighbor_kernel, [1, 1, 3, 1]), strides=[1, 1, 1, 1], padding=\'SAME\'), axis=3, keep_dims=True)\n    smoothedPlaneMap = tf.nn.depthwise_conv2d(planeMap, tf.tile(median_kernel, [1, 1, 3, 1]), strides=[1, 1, 1, 1], padding=\'SAME\')\n    planeDiff = tf.reduce_max(tf.norm(tf.expand_dims(planeMap, -1) - tf.reshape(smoothedPlaneMap, [batchSize, height, width, 3, 9]), axis=3, keep_dims=True), axis=4)\n    boundaryMask = tf.cast(tf.less(planeDiff, planeDiffThreshold), tf.float32)\n    \n    #opening\n    erosionKernel = np.array([[-1, 0, -1], [0, 0, 0], [-1, 0, -1]], dtype=np.float32).reshape([3, 3, 1])\n    dilationKernel = np.array([[-1, 0, -1], [0, 0, 0], [-1, 0, -1]], dtype=np.float32).reshape([3, 3, 1])\n    boundaryMask = tf.nn.erosion2d(boundaryMask, kernel=erosionKernel, strides=[1, 1, 1, 1], rates=[1, 1, 1, 1], padding=\'SAME\')\n    \n    #region indices\n    assignment = tf.reshape(tf.range(batchSize * height * width, dtype=tf.float32) + 1, [batchSize, height, width, 1]) * boundaryMask\n    with tf.variable_scope(""flooding"") as scope:\n        scope.reuse_variables()\n        for _ in xrange(width / 2):\n            assignment = tf.nn.max_pool(assignment, ksize=[1, 5, 5, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\') * boundaryMask\n            continue\n        pass\n    #inds, mask, count = tf.unique_with_counts(tf.concat([tf.constant(0, shape=[1], dtype=tf.float32), tf.reshape(assignment, [-1])], axis=0))\n    #ignoredInds = tf.range(count.shape, dtype=tf.float32) * tf.less(count, planeAreaThreshold)\n    assignment = tf.reshape(assignment, [-1])\n    \n    #find unique regions\n    inds, mask, count = tf.unique_with_counts(assignment)\n    ignoredInds = tf.boolean_mask(inds, tf.less(count, planeAreaThreshold))\n    assignment = assignment * (1 - tf.reduce_max(tf.cast(tf.equal(tf.expand_dims(assignment, -1), tf.expand_dims(ignoredInds, 0)), tf.float32), axis=1))\n    inds, mask, count = tf.unique_with_counts(tf.concat([tf.constant(0, shape=[1], dtype=tf.float32), assignment], axis=0))\n        \n    mask = tf.slice(mask, [1], [batchSize * height * width])\n    mask = tf.reshape(mask, [batchSize, height, width, 1])\n    #inds = tf.boolean_mask(inds, tf.greater(count, width * height / (16 * 16)))\n    batchInds = tf.equal(tf.cast(tf.tile(tf.reshape(inds - 1, [1, -1]), [batchSize, 1]), tf.int32) / (width * height), tf.expand_dims(tf.range(batchSize), -1))\n    counts = tf.count_nonzero(batchInds, axis=1)\n    counts = tf.concat([tf.constant([1], dtype=tf.int64), counts], axis=0)\n    counts = tf.slice(tf.cumsum(counts), [0], [batchSize])\n    batchPlaneInds = tf.reshape(tf.range(numPlanes), [1, -1]) + tf.cast(tf.reshape(counts, [-1, 1]), tf.int32)\n    #batchPlaneInds = tf.tile(tf.reshape(tf.range(numPlanes, dtype=tf.int32) + 1, [1, 1, 1, -1]), [batchSize, 1, 1, 1])\n    planeMasks = tf.cast(tf.equal(mask, tf.reshape(batchPlaneInds, [batchSize, 1, 1, numPlanes])), tf.float32)\n\n    planeMasks_test = planeMasks\n\n\n    planeAreas = tf.clip_by_value(tf.reduce_sum(planeMasks, axis=[1, 2]), 1e-4, width * height)\n    #planeAreas, sortInds = tf.nn.top_k(planeAreas, k=numPlanes)\n    #sortMap = tf.one_hot(sortInds, depth=numPlanes, axis=1)\n    #planeMasks = tf.reshape(tf.matmul(tf.reshape(planeMasks, [-1, height * width, numPlanes]), sortMap), [-1, height, width, numPlanes])\n\n    #fit plane based on mask\n    planesNormal = tf.reduce_sum(tf.expand_dims(normal, 3) * tf.expand_dims(planeMasks, -1), axis=[1, 2]) / tf.expand_dims(planeAreas, -1)\n    planesNormal = tf.nn.l2_normalize(planesNormal, 2)\n\n    weightedABC = tf.transpose(tf.reshape(tf.matmul(tf.reshape(ranges, [-1, 3]), tf.reshape(planesNormal, [-1, 3]), transpose_b=True), [height, width, batchSize, numPlanes]), [2, 0, 1, 3])\n    planesD = tf.reduce_sum(weightedABC * depth * planeMasks, axis=[1, 2]) / planeAreas\n    planesD = tf.expand_dims(planesD, -1)\n    planes = planesNormal * planesD\n    \n    #globalPlanes = tf.slice(planes, [0, 0, 0], [batchSize, numGlobalPlanes, 3])\n    #planes = tf.transpose(tf.matmul(planes, sortMap, transpose_a=True), [0, 2, 1])\n    #planesNormal = tf.slice(planesNormal, [0, 0, 0], [batchSize, numGlobalPlanes, 3])\n    #planesD = tf.slice(planesD, [0, 0, 0], [batchSize, numGlobalPlanes, 1])\n\n    normalDotThreshold = np.cos(np.deg2rad(5))\n    distanceThreshold = 0.05\n    X = depth * tf.expand_dims(urange, -1)\n    Y = depth\n    Z = -depth * tf.expand_dims(vrange, -1)\n    XYZ = tf.concat([X, Y, Z], axis=3)\n    XYZ = tf.reshape(XYZ, [-1, height * width, 3])\n    \n    planesNormal = -planesNormal\n    distance = tf.reshape(tf.abs(tf.matmul(XYZ, planesNormal, transpose_b=True) + tf.reshape(planesD, [-1, 1, numPlanes])), [-1, height, width, numPlanes])\n    angle = tf.reshape(tf.abs(tf.matmul(tf.reshape(normal, [-1, height * width, 3]), planesNormal, transpose_b=True)), [-1, height, width, numPlanes])\n\n    explainedPlaneMasks = tf.cast(tf.logical_and(tf.greater(angle, normalDotThreshold), tf.less(distance, distanceThreshold)), tf.float32)\n    explainedPlaneMasks = tf.nn.dilation2d(explainedPlaneMasks, filter=np.tile(dilationKernel, [1, 1, numPlanes]), strides=[1, 1, 1, 1], rates=[1, 1, 1, 1], padding=\'SAME\')\n    explainedPlaneMasks = tf.nn.erosion2d(explainedPlaneMasks, kernel=np.tile(erosionKernel, [1, 1, numPlanes]), strides=[1, 1, 1, 1], rates=[1, 1, 1, 1], padding=\'SAME\')    \n\n    with tf.variable_scope(""expansion"") as scope:\n        scope.reuse_variables()\n        for _ in xrange(width / 6):\n            planeMasks = tf.nn.max_pool(planeMasks, ksize=[1, 13, 13, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\') * explainedPlaneMasks\n            continue\n        pass\n        \n    planeAreas = tf.reduce_sum(planeMasks, axis=[1, 2])\n    planeAreas, sortInds = tf.nn.top_k(planeAreas, k=numPlanes)\n    sortMap = tf.one_hot(sortInds, depth=numPlanes, axis=1)\n    planeMasks = tf.reshape(tf.matmul(tf.reshape(planeMasks, [-1, height * width, numPlanes]), sortMap), [-1, height, width, numPlanes])\n    planes = tf.transpose(tf.matmul(planes, sortMap, transpose_a=True), [0, 2, 1])\n\n    #remove duplicate planes by expanding each plane mask, if two masks coincide, remove one of them\n    substractionMatrix = -tf.cast(tf.less(tf.reshape(tf.range(numPlanes), [-1, 1]), tf.reshape(tf.range(numPlanes), [1, -1])), tf.float32) + tf.eye(numPlanes)\n    substractionMatrix = tf.tile(tf.expand_dims(substractionMatrix, 0), [batchSize, 1, 1])\n    planeMasks = tf.clip_by_value(tf.reshape(tf.matmul(tf.reshape(planeMasks, [-1, height * width, numPlanes]), substractionMatrix), [-1, height, width, numPlanes]), 0, 1)\n\n\n    planeMasksWithoutBoundary = planeMasks * boundaryMask\n    planeAreas = tf.reduce_sum(planeMasksWithoutBoundary, axis=[1, 2])\n    maxMeanDepthThreshold = 10\n    planeAreas = tf.clip_by_value(planeAreas, 1e-4, width * height)\n    #validPlaneMask = tf.cast(tf.logical_and(tf.logical_or(tf.greater(planeAreas, planeAreaThreshold), tf.equal(tf.argmax(np.abs(planes), 2), 2)), tf.less(tf.reduce_sum(planeMasksWithoutBoundary * depth, axis=[1, 2]) / planeAreas, maxMeanDepthThreshold)), tf.float32)\n    #validPlaneMask = tf.cast(tf.equal(tf.argmax(np.abs(planes), 2), 2), tf.float32)\n    #planeAreas, sortInds = tf.nn.top_k(planeAreas, k=numPlanes)\n    #sortMap = tf.one_hot(sortInds, depth=numPlanes, axis=1)\n    #planeMasks = tf.reshape(tf.matmul(tf.reshape(planeMasks, [-1, height * width, numPlanes]), sortMap), [-1, height, width, numPlanes])\n\n    if False:\n        planes = tf.transpose(tf.matmul(planes, sortMap, transpose_a=True), [0, 2, 1])\n    else:\n        #fit planes based on merged masks\n        planesNormal = tf.reduce_sum(tf.expand_dims(normal, 3) * tf.expand_dims(planeMasksWithoutBoundary, -1), axis=[1, 2]) / tf.expand_dims(planeAreas, -1)\n        planesNormal = tf.nn.l2_normalize(planesNormal, 2)\n\n        weightedABC = tf.transpose(tf.reshape(tf.matmul(tf.reshape(ranges, [-1, 3]), tf.reshape(planesNormal, [-1, 3]), transpose_b=True), [height, width, batchSize, numPlanes]), [2, 0, 1, 3])\n        planesD = tf.reduce_sum(weightedABC * depth * planeMasksWithoutBoundary, axis=[1, 2]) / planeAreas\n        planesD = tf.expand_dims(planesD, -1)\n        planes = planesNormal * planesD\n        pass\n\n    validPlaneMask = tf.cast(tf.less(tf.reduce_sum(planeMasksWithoutBoundary * depth, axis=[1, 2]) / planeAreas, maxMeanDepthThreshold), tf.float32)\n    planeMasks = planeMasks * tf.expand_dims(tf.expand_dims(validPlaneMask, 1), 1)\n    planes = planes * tf.expand_dims(validPlaneMask, -1)\n    planeAreas = planeAreas * validPlaneMask\n            \n\n    # planeAreas = tf.reduce_sum(localPlaneMasks, axis=[1, 2])\n    # planeAreas, sortInds = tf.nn.top_k(planeAreas, k=numPlanes)\n    # sortMap = tf.one_hot(sortInds, depth=numPlanes, axis=1)\n    # localPlaneMasks = tf.reshape(tf.matmul(tf.reshape(localPlaneMasks, [-1, height * width, numPlanes]), sortMap), [-1, height, width, numPlanes])\n    # localPlanes = tf.transpose(tf.matmul(localPlanes, sortMap, transpose_a=True), [0, 2, 1])\n\n    # substractionMatrix = -tf.cast(tf.less(tf.reshape(tf.range(numPlanes), [-1, 1]), tf.reshape(tf.range(numPlanes), [1, -1])), tf.float32) + tf.eye(numPlanes)\n    # substractionMatrix = tf.tile(tf.expand_dims(substractionMatrix, 0), [batchSize, 1, 1])\n    # localPlaneMasks = tf.clip_by_value(tf.reshape(tf.matmul(tf.reshape(localPlaneMasks, [-1, height * width, numPlanes]), substractionMatrix), [-1, height, width, numPlanes]), 0, 1)\n\n\n    # planeMasksWithoutBoundary = localPlaneMasks * boundaryMask\n    # planeAreas = tf.reduce_sum(planeMasksWithoutBoundary, axis=[1, 2])\n    # maxMeanDepthThreshold = 10\n    # #validPlaneMask = tf.cast(tf.logical_and(tf.logical_or(tf.greater(planeAreas, planeAreaThreshold), tf.equal(tf.argmax(np.abs(planes), 2), 2)), tf.less(tf.reduce_sum(planeMasksWithoutBoundary * depth, axis=[1, 2]) / planeAreas, maxMeanDepthThreshold)), tf.float32)\n    # #validPlaneMask = tf.cast(tf.equal(tf.argmax(np.abs(planes), 2), 2), tf.float32)\n    # validPlaneMask = tf.cast(tf.less(tf.reduce_sum(planeMasksWithoutBoundary * depth, axis=[1, 2]) / planeAreas, maxMeanDepthThreshold), tf.float32)\n    # localPlanes = localPlanes * tf.expand_dims(validPlaneMask, -1)\n    # localPlaneMasks = localPlaneMasks * tf.expand_dims(tf.expand_dims(validPlaneMask, 1), 1)\n    # planeAreas = planeAreas * validPlaneMask\n    # planeAreas, sortInds = tf.nn.top_k(planeAreas, k=numPlanes)\n    # sortMap = tf.one_hot(sortInds, depth=numPlanes, axis=1)\n    # localPlaneMasks = tf.reshape(tf.matmul(tf.reshape(localPlaneMasks, [-1, height * width, numPlanes]), sortMap), [-1, height, width, numPlanes])\n\n    # planeMasksWithoutBoundary = localPlaneMasks * boundaryMask\n    # planeAreas = tf.clip_by_value(planeAreas, 1e-4, width * height)\n    # planesNormal = tf.reduce_sum(tf.expand_dims(normal, 3) * tf.expand_dims(planeMasksWithoutBoundary, -1), axis=[1, 2]) / tf.expand_dims(planeAreas, -1)\n    # planesNormal = tf.nn.l2_normalize(planesNormal, 2)\n\n    # weightedABC = tf.transpose(tf.reshape(tf.matmul(tf.reshape(ranges, [-1, 3]), tf.reshape(planesNormal, [-1, 3]), transpose_b=True), [height, width, batchSize, numPlanes]), [2, 0, 1, 3])\n    # planesD = tf.reduce_sum(weightedABC * depth * planeMasksWithoutBoundary, axis=[1, 2]) / planeAreas\n    # planesD = tf.expand_dims(planesD, -1)\n    # localPlanes = planesNormal * planesD\n    \n\n    #find local ground truth\n    urange = tf.reshape(tf.range(width, dtype=tf.float32), [1, -1, 1])\n    planeXs = tf.reduce_max(planeMasks, axis=1)\n    planeMinX = width - tf.reduce_max(planeXs * (float(width) - urange), axis=1)\n    planeMaxX = tf.reduce_max(planeXs * urange, axis=1)\n\n    vrange = tf.reshape(tf.range(height, dtype=tf.float32), [1, -1, 1])\n    planeYs = tf.reduce_max(planeMasks, axis=2)\n    planeMinY = height - tf.reduce_max(planeYs * (float(height) - vrange), axis=1)\n    planeMaxY = tf.reduce_max(planeYs * vrange, axis=1)\n\n    planeBoxes = tf.stack([planeMinX, planeMaxX, planeMinY, planeMaxY], axis=2)\n\n    localPlaneWidthThreshold = 64\n    localPlaneHeightThreshold = 64\n    globalPlaneAreaThreshold = 16 * 16\n    globalPlaneWidthThreshold = 8\n    \n    globalPlaneMask = tf.logical_or(tf.greater(planeMaxX - planeMinX, localPlaneWidthThreshold), tf.greater(planeMaxY - planeMinY, localPlaneHeightThreshold))\n    globalPlaneMask = tf.logical_and(globalPlaneMask, tf.greater((planeMaxX - planeMinX) * (planeMaxY - planeMinY), globalPlaneAreaThreshold))\n    globalPlaneMask = tf.logical_and(globalPlaneMask, tf.greater(planeAreas / (planeMaxY + 1 - planeMinY), globalPlaneWidthThreshold))\n    #globalPlaneMask = tf.cast(tf.squeeze(globalPlaneMask, axis=[2]), tf.float32)\n    globalPlaneMask = tf.cast(globalPlaneMask, tf.float32)\n    weightedPlaneAreas = globalPlaneMask * (planeAreas + height * width) + (1 - globalPlaneMask) * planeAreas\n    planeAreas, sortInds = tf.nn.top_k(weightedPlaneAreas, k=numPlanes)\n    sortMap = tf.one_hot(sortInds, depth=numPlanes, axis=1)\n    planeMasks = tf.reshape(tf.matmul(tf.reshape(planeMasks, [-1, height * width, numPlanes]), sortMap), [-1, height, width, numPlanes])\n    planes = tf.transpose(tf.matmul(planes, sortMap, transpose_a=True), [0, 2, 1])\n    planeBoxes = tf.transpose(tf.matmul(planeBoxes, sortMap, transpose_a=True), [0, 2, 1])\n    globalPlaneMask = tf.squeeze(tf.matmul(tf.expand_dims(globalPlaneMask, 1), sortMap), axis=1)\n    \n\n\n    #boundary ground truth\n    boundary = tf.nn.max_pool(planeMasks, ksize=[1, 5, 5, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n    \n    boundaryType = tf.cast(tf.round(tf.reduce_sum(boundary, axis=3, keep_dims=True)), tf.int32)\n    singleBoundary = tf.cast(tf.equal(tf.reduce_sum(boundary - planeMasks, axis=3, keep_dims=True), 1), tf.float32)\n\n    commonBoundary = tf.cast(tf.equal(boundaryType, 2), tf.float32)\n    #boundary = boundary * commonBoundary\n    boundaryCoef = tf.cast(tf.round(tf.cumsum(boundary, axis=3)), tf.float32)\n\n    #boundary_1 = tf.cast(tf.equal(boundaryCoef, 1), tf.float32) * boundary\n    #boundary_1 = tf.cast(tf.equal(boundaryCoef, 1), tf.float32) * boundary\n    \n    boundaryPlane_1 = tf.reshape(tf.matmul(tf.reshape(tf.cast(tf.equal(boundaryCoef, 1), tf.float32) * boundary, [batchSize, height * width, numPlanes]), planes), [batchSize, height, width, 3])\n    boundaryD_1 = tf.maximum(tf.norm(boundaryPlane_1, axis=3, keep_dims=True), 1e-4)\n    boundaryNormal_1 = boundaryPlane_1 / boundaryD_1\n    boundaryDepth_1 = boundaryD_1 / tf.maximum(tf.reduce_sum(boundaryNormal_1 * ranges, axis=3, keep_dims=True), 1e-4)\n\n    boundaryPlane_2 = tf.reshape(tf.matmul(tf.reshape(tf.cast(tf.equal(boundaryCoef, 2), tf.float32) * boundary, [batchSize, height * width, numPlanes]), planes), [batchSize, height, width, 3])\n    boundaryD_2 = tf.maximum(tf.norm(boundaryPlane_2, axis=3, keep_dims=True), 1e-4)\n    boundaryNormal_2 = boundaryPlane_2 / boundaryD_2\n    boundaryDepth_2 = boundaryD_2 / tf.maximum(tf.reduce_sum(boundaryNormal_2 * ranges, axis=3, keep_dims=True), 1e-4)\n\n    depthDiffThreshold = 0.05\n    #occlusionBoundary = tf.cast(tf.greater(tf.abs(boundaryDepth_1 - boundaryDepth_2), depthDiffThreshold), tf.float32) * commonBoundary\n    largerMask = tf.nn.max_pool(tf.cast(tf.greater_equal(boundaryDepth_1, boundaryDepth_2), tf.float32) * commonBoundary, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\')\n    smallerMask = tf.nn.max_pool(tf.cast(tf.less_equal(boundaryDepth_1, boundaryDepth_2), tf.float32) * commonBoundary, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\')\n    smoothBoundary = tf.nn.max_pool(largerMask * smallerMask, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\')\n    #depthDiff = tf.abs(depth - tf.nn.depthwise_conv2d(depth, neighbor_kernel, strides=[1, 1, 1, 1], padding=\'SAME\'))\n    #occlusionBoundary = tf.cast(tf.greater(depthDiff, depthDiffThreshold), tf.float32) * commonBoundary\n    \n    #boundaryConvexity = tf.cast(tf.less(tf.reduce_sum(boundaryNormal_1 * boundaryNormal_2, axis=3, keep_dims=True), 0), tf.float32)\n    #convexBoundary = smoothBoundary * boundaryConvexity\n    #concaveBoundary = smoothBoundary * (1 - boundaryConvexity)\n\n    \n    occlusionBoundary = commonBoundary - smoothBoundary\n\n    singleBoundary = tf.maximum(singleBoundary - tf.nn.max_pool(commonBoundary, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\'), 0)\n    boundaries = tf.concat([singleBoundary, occlusionBoundary, smoothBoundary], axis=3)\n    #boundaries = tf.concat([tf.maximum(tf.minimum((boundaryDepth_1 - boundaryDepth_2) + 0.5, 1), 0)], axis=3)\n    #boundaries = tf.concat([tf.maximum(tf.minimum(boundaryDepth_1 / 10, 1), 0), tf.maximum(tf.minimum(boundaryDepth_2 / 10, 1), 0), tf.maximum(tf.minimum((boundaryDepth_1 - boundaryDepth_2) + 0.5, 1), 0)], axis=3)\n    boundaries = 1 - tf.nn.max_pool(1 - boundaries, ksize=[1, 2, 2, 1], strides=[1, 1, 1, 1], padding=\'SAME\')\n    \n    if True:\n        coef = tf.pow(tf.constant(2, dtype=tf.float64), tf.range(numPlanes, dtype=tf.float64))\n        planeMask = tf.cast(tf.round(tf.tensordot(tf.cast(planeMasks, tf.float64), coef, axes=[[3], [0]])), tf.int64)\n        #localPlaneMask = tf.cast(tf.round(tf.tensordot(tf.cast(localPlaneMasks, tf.float64), coef, axes=[[3], [0]])), tf.int64)\n        #coef = tf.pow(tf.constant(2, dtype=tf.float64), tf.range(numPlanes, dtype=tf.float64))\n        #planeCroppedMask = tf.cast(tf.round(tf.tensordot(tf.cast(tf.greater(planeCroppedMasks, 0.5), tf.float64), coef, axes=[[3], [0]])), tf.int64)\n        numGlobalPlanes = tf.reduce_sum(globalPlaneMask, axis=1)\n\n        gridScores, gridPlanes, gridMasks = findLocalPlanes(planes, planeMasks)\n        return planes, planeMask, numGlobalPlanes, boundaries, gridScores, gridPlanes, gridMasks\n\n    \n    maskWidth = 32\n    maskHeight = 32\n    planeCroppedMasks = []\n    for batchIndex in xrange(batchSize):\n        boxes = planeBoxes[batchIndex]\n        masks = tf.transpose(planeMasks[batchIndex], [2, 0, 1])\n        croppedMasks = []\n        for planeIndex in xrange(numPlanes):\n        #for planeIndex in xrange(1):\n            box = boxes[planeIndex]\n            mask = masks[planeIndex]\n            #minX = tf.cond(tf.less(planeIndex, tf.numValidPlanes[batchIndex]), lambda: tf.cast(box[0], tf.int32)\n            minX = tf.cast(box[0], tf.int32)\n            maxX = tf.cast(box[1], tf.int32)\n            minY = tf.cast(box[2], tf.int32)\n            maxY = tf.cast(box[3], tf.int32)\n            minX = tf.minimum(minX, maxX)\n            minY = tf.minimum(minY, maxY)\n            croppedMask = tf.slice(mask, [minY, minX], [maxY - minY + 1, maxX - minX + 1])\n            #croppedMask = tf.slice(mask, [0, 0], [height - 10, width - 10])\n            croppedMask = tf.image.resize_bilinear(tf.expand_dims(tf.expand_dims(croppedMask, -1), 0), [maskHeight, maskWidth])\n            croppedMasks.append(croppedMask)\n            continue\n        planeCroppedMasks.append(tf.squeeze(tf.concat(croppedMasks, axis=3)))\n        continue\n    planeCroppedMasks = tf.stack(planeCroppedMasks, axis=0)   \n\n    gridMinX = []\n    gridMaxX = []\n    gridMinY = []\n    gridMaxY = []\n    for stride in [8, 16, 32]:\n        boxSize = stride * 2\n        xs = tf.tile(tf.expand_dims(tf.range(width / stride, dtype=tf.float32) * stride + stride / 2, 0), [height / stride, 1])\n        ys = tf.tile(tf.expand_dims(tf.range(height / stride, dtype=tf.float32) * stride + stride / 2, 1), [1, width / stride])\n        gridMinX.append(tf.reshape(xs - boxSize / 2, [1, -1, 1]))\n        gridMaxX.append(tf.reshape(xs + boxSize / 2, [1, -1, 1]))\n        gridMinY.append(tf.reshape(ys - boxSize / 2, [1, -1, 1]))\n        gridMaxY.append(tf.reshape(ys + boxSize / 2, [1, -1, 1]))\n        continue\n    \n    gridMinX = tf.tile(tf.concat(gridMinX, axis=1), [batchSize, 1, 1])\n    gridMaxX = tf.tile(tf.concat(gridMaxX, axis=1), [batchSize, 1, 1])\n    gridMinY = tf.tile(tf.concat(gridMinY, axis=1), [batchSize, 1, 1])\n    gridMaxY = tf.tile(tf.concat(gridMaxY, axis=1), [batchSize, 1, 1])\n\n    planeMinX = tf.matmul(tf.reshape(planeMinX, [batchSize, 1, numPlanes]), sortMap)\n    planeMaxX = tf.matmul(tf.reshape(planeMaxX, [batchSize, 1, numPlanes]), sortMap)\n    planeMinY = tf.matmul(tf.reshape(planeMinY, [batchSize, 1, numPlanes]), sortMap)\n    planeMaxY = tf.matmul(tf.reshape(planeMaxY, [batchSize, 1, numPlanes]), sortMap)\n\n    intersection = tf.maximum(tf.minimum(gridMaxX, planeMaxX) - tf.maximum(gridMinX, planeMinX) + 1, 0.) * tf.maximum(tf.minimum(gridMaxY, planeMaxY) - tf.maximum(gridMinY, planeMinY) + 1, 0.)\n    union = (gridMaxX - gridMinX + 1) * (gridMaxY - gridMinY + 1) + (planeMaxX - planeMinX + 1) * (planeMaxY - planeMinY + 1) - intersection\n    IOU = intersection / union\n    maxIOUInds = tf.argmax(IOU, axis=1)\n    maxIOU = tf.reduce_max(IOU, axis=1)\n    IOU = IOU * tf.one_hot(tf.argmax(IOU, 1), depth=IOU.shape[1], axis=1)\n    #IOUThreshold = tf.concat([tf.ones((1, (width / 8) * (height / 8), 1)) * 0.2, tf.ones((1, (width / 16) * (height / 16), 1)) * 0.3, tf.ones((1, (width / 32) * (height / 32), 1)) * 0.7], axis=1)\n    #activeGridMask = tf.one_hot(tf.argmax(IOU, 2), depth=IOU.shape[2], axis=2) * tf.cast(tf.greater(IOU, IOUThreshold), tf.float32)\n    activeGridMask = tf.one_hot(tf.argmax(IOU, 2), depth=IOU.shape[2], axis=2) * (1 - tf.expand_dims(globalPlaneMask, 1))\n    gridScores = tf.reduce_sum(activeGridMask, axis=2, keep_dims=True)\n    activeGridMask = tf.expand_dims(activeGridMask, -1)\n    gridPlanes = tf.reduce_sum(activeGridMask * tf.expand_dims(planes, 1), axis=2)\n    gridMasks = tf.reduce_sum(activeGridMask * tf.expand_dims(tf.transpose(tf.reshape(planeCroppedMasks, [batchSize, -1, numPlanes]), [0, 2, 1]), 1), axis=2)\n\n    activeGridMask = tf.squeeze(activeGridMask, axis=3)\n    #gridBoxes = tf.reduce_sum(activeGridMask * tf.expand_dims(planeBoxes, 1), axis=2)\n    gridPlaneMinX = tf.reduce_sum(activeGridMask * planeMinX, axis=2, keep_dims=True)\n    gridPlaneMaxX = tf.reduce_sum(activeGridMask * planeMaxX, axis=2, keep_dims=True)\n    gridPlaneMinY = tf.reduce_sum(activeGridMask * planeMinY, axis=2, keep_dims=True)\n    gridPlaneMaxY = tf.reduce_sum(activeGridMask * planeMaxY, axis=2, keep_dims=True)\n    gridWidths = gridMaxX - gridMinX\n    gridHeights = gridMaxY - gridMinY\n\n    gridOffsetX = ((gridPlaneMinX + gridPlaneMaxX) - (gridMinX + gridMaxX)) / 2 / gridWidths\n    gridOffsetY = ((gridPlaneMinY + gridPlaneMaxY) - (gridMinY + gridMaxY)) / 2 / gridHeights\n    gridW = (gridPlaneMaxX - gridPlaneMinX) / gridWidths\n    gridH = (gridPlaneMaxY - gridPlaneMinY) / gridHeights\n    gridBoxes = tf.concat([gridOffsetX, gridOffsetY, gridW, gridH], axis=2)\n    \n    \n    offset = 0\n    gridScoresArray = []\n    gridPlanesArray = []\n    gridBoxesArray = []\n    gridMasksArray = []\n    for stride in [8, 16, 32]:\n        numGrids = (width / stride) * (height / stride)\n        gridScoresArray.append(tf.reshape(tf.slice(gridScores, [0, offset, 0], [batchSize, numGrids, 1]), [batchSize, height / stride, width / stride, -1]))\n        gridPlanesArray.append(tf.reshape(tf.slice(gridPlanes, [0, offset, 0], [batchSize, numGrids, 3]), [batchSize, height / stride, width / stride, -1]))\n        gridBoxesArray.append(tf.reshape(tf.slice(gridBoxes, [0, offset, 0], [batchSize, numGrids, 4]), [batchSize, height / stride, width / stride, -1]))\n        gridMasksArray.append(tf.reshape(tf.slice(gridMasks, [0, offset, 0], [batchSize, numGrids, maskWidth * maskHeight]), [batchSize, height / stride, width / stride, -1]))\n        offset += numGrids\n        continue\n\n    \n    if True:\n        coef = tf.pow(tf.constant(2, dtype=tf.float64), tf.range(numPlanes, dtype=tf.float64))\n        planeMask = tf.cast(tf.round(tf.tensordot(tf.cast(planeMasks, tf.float64), coef, axes=[[3], [0]])), tf.int64)\n        #localPlaneMask = tf.cast(tf.round(tf.tensordot(tf.cast(localPlaneMasks, tf.float64), coef, axes=[[3], [0]])), tf.int64)\n        #coef = tf.pow(tf.constant(2, dtype=tf.float64), tf.range(numPlanes, dtype=tf.float64))\n        planeCroppedMask = tf.cast(tf.round(tf.tensordot(tf.cast(tf.greater(planeCroppedMasks, 0.5), tf.float64), coef, axes=[[3], [0]])), tf.int64)\n        numGlobalPlanes = tf.reduce_sum(globalPlaneMask, axis=1)\n\n        return planes, planeMask, numGlobalPlanes, boundaries, planeBoxes, planeCroppedMask, gridScoresArray, gridPlanesArray, gridBoxesArray, gridMasksArray, maxIOU, maxIOUInds\n    \n    # coef = tf.pow(tf.constant(0.9, dtype=tf.float64), tf.range(numPlanes, dtype=tf.float64))\n    # coef = tf.tile(tf.reshape(coef, [1, 1, -1]), [batchSize, 1, 1])\n    # coef = tf.matmul(coef, tf.cast(sortMap, tf.float64), transpose_b=True)\n    # #planeMasks = tf.reshape(tf.matmul(tf.reshape(planeMasks, [-1, height * width, numPlanes]), sortMap), [-1, height, width, numPlanes])\n\n    # assignment = tf.reduce_max(tf.cast(planeMasks, tf.float64) * tf.expand_dims(coef, axis=2), axis=3, keep_dims=True)\n    # inds, mask, count = tf.unique_with_counts(tf.concat([tf.constant(0), tf.reshape(assignment, [-1])]))\n    # mask = tf.reshape(tf.slice(mask, [1], [batchSize * height * width * 1], [batchSize, height, width, 1])\n\n    # coef = tf.tile(tf.reshape(coef, [1, 1, -1]), [batchSize, 1, 1])\n    # coef = tf.matmul(coef, tf.cast(sortMap, tf.float64), transpose_b=True)\n    # coef = tf.reshape(tf.range(numPlanes)\n    # planeMasks = tf.cast(tf.equal(mask, tf.tile(, [1, 1, 1, numPlanes]), [batchSize, 1, 1, 1])), tf.float32)\n    \n    # planeAreas = tf.clip_by_value(tf.reduce_sum(planeMasks, axis=[1, 2]), 1e-4, width * height)\n    # planeAreas, sortInds = tf.nn.top_k(planeAreas, k=numPlanes)\n    # sortMap = tf.one_hot(sortInds, depth=numPlanes, axis=1)\n    # planeMasks = tf.reshape(tf.matmul(tf.reshape(planeMasks, [-1, height * width, numPlanes]), sortMap), [-1, height, width, numPlanes])\n\n    #planeAreas = tf.clip_by_value(tf.reduce_sum(planeMasks, axis=[1, 2]), 1e-4, width * height)\n    \n    # planesNormal = tf.reduce_sum(tf.expand_dims(normal, 3) * tf.expand_dims(planeMasks, -1), axis=[1, 2]) / tf.expand_dims(planeAreas, -1)\n    # planesNormal = tf.nn.l2_normalize(planesNormal, 2)\n    # weightedABC = tf.reshape(tf.matmul(tf.reshape(ranges, [-1, 3]), tf.reshape(planesNormal, [-1, 3]), transpose_b=True), [batchSize, height, width, numPlanes])\n    # planesD = tf.reduce_sum(weightedABC * depth * planeMasks, axis=[1, 2]) / planeAreas\n    # planesD = tf.expand_dims(planesD, -1)\n    # planes = planesNormal * planesD\n\n\n    if True:\n        planeMask = tf.cast(tf.round(tf.tensordot(tf.cast(planeMasks, tf.float64), coef, axes=[[3], [0]])), tf.int64)\n        return planes, planeMask, tf.reduce_sum(validPlaneMask, axis=1)\n\n    \n    globalPlanes = tf.slice(planes, [0, 0, 0], [batchSize, numGlobalPlanes, 3])\n    globalPlaneMasks = tf.slice(planeMasks, [0, 0, 0, 0], [batchSize, height, width, numGlobalPlanes])\n\n    if True:\n        return planes, planeMasks, tf.reduce_sum(validPlaneMask, axis=1), planeMasks_test, boundaryMask\n    #return globalPlanes, globalPlaneMasks, tf.reduce_sum(validPlaneMask, axis=1)\n    \n    globalPlaneMask = tf.reduce_max(globalPlaneMasks, axis=3, keep_dims=True)\n    smallPlaneMasks = tf.clip_by_value(tf.slice(planeMasks, [0, 0, 0, numGlobalPlanes], [batchSize, height, width, numPlanes - numGlobalPlanes]) - globalPlaneMask, 0, 1)\n    smallPlaneMasks = tf.nn.dilation2d(smallPlaneMasks, filter=np.tile(dilationKernel, [1, 1, numPlanes - numGlobalPlanes]), strides=[1, 1, 1, 1], rates=[1, 1, 1, 1], padding=\'SAME\')\n    smallPlaneMasks = tf.concat([globalPlaneMasks, smallPlaneMasks], axis=3)\n\n\n    IOUThreshold = 0.9\n    areaThreshold = 0.25\n\n    blockSize = 16\n    smallPlaneInds = tf.nn.avg_pool(smallPlaneMasks, ksize=[1, blockSize, blockSize, 1], strides=[1, blockSize, blockSize, 1], padding=\'VALID\')\n    smallPlaneAreas = tf.clip_by_value(tf.reduce_sum(smallPlaneInds, axis=[1, 2], keep_dims=True), 1e-4, width * height)    \n    IOU = smallPlaneInds / smallPlaneAreas\n    inds = smallPlaneInds\n    smallPlaneInds = tf.one_hot(tf.argmax(smallPlaneInds, 3), depth=numPlanes) * tf.cast(tf.greater_equal(IOU, IOUThreshold), tf.float32) * tf.cast(tf.greater(smallPlaneInds, areaThreshold), tf.float32)\n\n    blockSmallPlaneMasks_16 = tf.reshape(tf.space_to_depth(smallPlaneMasks, block_size=blockSize), [batchSize, height / blockSize, width / blockSize, blockSize * blockSize, numPlanes])\n    blockSmallPlanes_16 = tf.reduce_sum(tf.expand_dims(smallPlaneInds, -1) * tf.expand_dims(tf.expand_dims(planes, 1), 1), axis=3)\n    blockSmallPlaneMasks_16 = tf.reduce_sum(tf.expand_dims(smallPlaneInds, 3) * blockSmallPlaneMasks_16, axis=4)\n    blockPlaneIndicators_16 = tf.reduce_max(smallPlaneInds, axis=3, keep_dims=True)\n\n    \n    blockSize = 32\n    smallPlaneInds = tf.nn.avg_pool(smallPlaneMasks, ksize=[1, blockSize, blockSize, 1], strides=[1, blockSize, blockSize, 1], padding=\'VALID\')\n    smallPlaneAreas = tf.clip_by_value(tf.reduce_sum(smallPlaneInds, axis=[1, 2], keep_dims=True), 1e-4, width * height)    \n    IOU = smallPlaneInds / smallPlaneAreas\n    inds = smallPlaneInds\n    smallPlaneInds = tf.one_hot(tf.argmax(smallPlaneInds, 3), depth=numPlanes) * tf.cast(tf.greater_equal(IOU, IOUThreshold), tf.float32) * tf.cast(tf.greater(smallPlaneInds, areaThreshold), tf.float32)\n    \n    blockSmallPlaneMasks_32 = tf.reshape(tf.space_to_depth(smallPlaneMasks, block_size=blockSize), [batchSize, height / blockSize, width / blockSize, blockSize * blockSize, numPlanes])\n    blockSmallPlanes_32 = tf.reduce_sum(tf.expand_dims(smallPlaneInds, -1) * tf.expand_dims(tf.expand_dims(planes, 1), 1), axis=3)\n    blockSmallPlaneMasks_32 = tf.reduce_sum(tf.expand_dims(smallPlaneInds, 3) * blockSmallPlaneMasks_32, axis=4)\n    blockPlaneIndicators_32 = tf.reduce_max(smallPlaneInds, axis=3, keep_dims=True)\n\n    return globalPlanes, globalPlaneMasks, blockSmallPlanes_16, blockSmallPlaneMasks_16, blockPlaneIndicators_16, blockSmallPlanes_32, blockSmallPlaneMasks_32, blockPlaneIndicators_32, tf.depth_to_space(blockSmallPlaneMasks_16 * blockPlaneIndicators_16, 16), tf.depth_to_space(blockSmallPlaneMasks_32 * blockPlaneIndicators_32, 32), planeMasks_test, planeDiff, boundaryMask\n\n\n# def planeFittingDepthModule(depth)\n#     width = int(depth.shape[2])\n#     height = int(depth.shape[1])\n\n#     focalLength = 517.97\n#     urange = (tf.range(width, dtype=tf.float32) / (width + 1) - 0.5) / focalLength * 641\n#     urange = tf.tile(tf.reshape(urange, [1, -1]), [height, 1])\n#     vrange = (tf.range(height, dtype=tf.float32) / (height + 1) - 0.5) / focalLength * 481\n#     vrange = tf.tile(tf.reshape(vrange, [-1, 1]), [1, width])\n            \n#     ranges = tf.stack([urange, tf.ones([height, width]), -vrange], axis=2)\n#     ranges = tf.expand_dims(ranges, 0)\n\n#     batchSize = int(depth.shape[0])\n\n#     X = depth * tf.expand_dims(urange, -1)\n#     Y = depth\n#     Z = -depth * tf.expand_dims(vrange, -1)\n#     XYZ = tf.concat([X, Y, Z], axis=3)\n#     XYZ = tf.reshape(XYZ, [-1, height * width, 3])\n\n\t\n\t\ndef findLocalPlanes(planes, planeMasks):\n    batchSize = int(planeMasks.shape[0])\n    height = int(planeMasks.shape[1])\n    width = int(planeMasks.shape[2])\n    numPlanes = int(planeMasks.shape[3])\n    \n    maskWidth = 16\n    maskHeight = 16\n\n    urange = tf.reshape(tf.range(width, dtype=tf.float32), [1, -1, 1])\n    planeXs = tf.reduce_max(planeMasks, axis=1)\n    planeMinX = float(width) - tf.reduce_max(planeXs * (float(width) - urange), axis=1)\n    planeMaxX = tf.reduce_max(planeXs * urange, axis=1)\n\n    vrange = tf.reshape(tf.range(height, dtype=tf.float32), [1, -1, 1])\n    planeYs = tf.reduce_max(planeMasks, axis=2)\n    planeMinY = float(height) - tf.reduce_max(planeYs * (float(height) - vrange), axis=1)\n    planeMaxY = tf.reduce_max(planeYs * vrange, axis=1)\n\n\n    localPlaneWidthThreshold = 64\n    localPlaneHeightThreshold = 64\n    localPlaneMask = tf.logical_and(tf.less(planeMaxX - planeMinX, localPlaneWidthThreshold), tf.less(planeMaxY - planeMinY, localPlaneHeightThreshold))\n\n    \n    stride = 8\n    boxSize = 64\n    xs = tf.tile(tf.expand_dims(tf.range(width / stride, dtype=tf.float32) * stride + stride / 2, 0), [height / stride, 1])\n    ys = tf.tile(tf.expand_dims(tf.range(height / stride, dtype=tf.float32) * stride + stride / 2, 1), [1, width / stride])\n    gridMinX = tf.reshape(xs - boxSize / 2, [1, -1, 1])\n    gridMaxX = tf.reshape(xs + boxSize / 2, [1, -1, 1])\n    gridMinY = tf.reshape(ys - boxSize / 2, [1, -1, 1])\n    gridMaxY = tf.reshape(ys + boxSize / 2, [1, -1, 1])\n    \n    gridMinX = tf.tile(gridMinX, [batchSize, 1, 1])\n    gridMaxX = tf.tile(gridMaxX, [batchSize, 1, 1])\n    gridMinY = tf.tile(gridMinY, [batchSize, 1, 1])\n    gridMaxY = tf.tile(gridMaxY, [batchSize, 1, 1])\n\n    padding = boxSize / 2 + 1\n    padding = boxSize / 2 + 1\n    paddedPlaneMasks = tf.concat([tf.zeros([batchSize, height, padding, numPlanes]), planeMasks, tf.zeros([batchSize, height, padding, numPlanes])], axis=2)\n    paddedPlaneMasks = tf.concat([tf.zeros([batchSize, padding, width + padding * 2, numPlanes]), paddedPlaneMasks, tf.zeros([batchSize, padding, width + padding * 2, numPlanes])], axis=1)\n\n    gridPlaneMasks = []\n    for gridY in xrange(height / stride):\n        for gridX in xrange(width / stride):\n            localPlaneMasks = tf.slice(paddedPlaneMasks, [0, gridY * stride + stride / 2 - boxSize / 2 + padding, gridX * stride + stride / 2 - boxSize / 2 + padding, 0], [batchSize, boxSize, boxSize, numPlanes])\n            gridPlaneMasks.append(tf.image.resize_bilinear(localPlaneMasks, [maskHeight, maskWidth]))\n            continue\n        continue\n    gridPlaneMasks = tf.stack(gridPlaneMasks, axis=1)\n    gridPlaneMasks = tf.reshape(gridPlaneMasks, [batchSize, -1, maskHeight * maskWidth, numPlanes])\n\n    planeMinX = tf.expand_dims(planeMinX, 1)\n    planeMaxX = tf.expand_dims(planeMaxX, 1)\n    planeMinY = tf.expand_dims(planeMinY, 1)\n    planeMaxY = tf.expand_dims(planeMaxY, 1)    \n    intersection = tf.maximum(tf.minimum(gridMaxX, planeMaxX) - tf.maximum(gridMinX, planeMinX) + 1, 0.) * tf.maximum(tf.minimum(gridMaxY, planeMaxY) - tf.maximum(gridMinY, planeMinY) + 1, 0.)\n    union = (gridMaxX - gridMinX + 1) * (gridMaxY - gridMinY + 1) + (planeMaxX - planeMinX + 1) * (planeMaxY - planeMinY + 1) - intersection\n    IOU = intersection / union\n    #maxIOUInds = tf.argmax(IOU, axis=1)\n    #maxIOU = tf.reduce_max(IOU, axis=1)\n    IOU = IOU * tf.expand_dims(tf.cast(localPlaneMask, tf.float32), 1)\n    IOU = IOU * tf.one_hot(tf.argmax(IOU, 1), depth=IOU.shape[1], axis=1)\n    IOUThreshold = 1.0 / pow(boxSize / stride, 2)\n    activeGridMask = tf.one_hot(tf.argmax(IOU, 2), depth=IOU.shape[2], axis=2) * tf.cast(tf.greater(IOU, IOUThreshold), tf.float32)\n    \n    #activeGridMask = tf.one_hot(tf.ones((batchSize, IOU.shape[1]), dtype=tf.int32), depth=IOU.shape[2], axis=2)\n    \n    gridScores = tf.reduce_sum(activeGridMask, axis=2, keep_dims=True)\n    activeGridMask = tf.expand_dims(activeGridMask, -1)\n    gridPlanes = tf.reduce_sum(activeGridMask * tf.expand_dims(planes, 1), axis=2)\n    gridMasks = tf.reduce_sum(activeGridMask * tf.transpose(gridPlaneMasks, [0, 1, 3, 2]), axis=2)\n\n    gridScores = tf.reshape(gridScores, [batchSize, height / stride, width / stride, -1])\n    gridPlanes = tf.reshape(gridPlanes, [batchSize, height / stride, width / stride, -1])\n    gridMasks = tf.reshape(gridMasks, [batchSize, height / stride, width / stride, -1])\n    \n    return gridScores, gridPlanes, gridMasks\n\n\ndef findBoundaries(planes, planeMasks):\n    height = int(planeMasks.shape[0])\n    width = int(planeMasks.shape[1])\n    \n    planesD = tf.norm(planes, axis=1, keep_dims=True)\n    planesD = tf.clip_by_value(planesD, 1e-5, 10)\n    planesNormal = planes / planesD\n\n    ND = tf.expand_dims(planesNormal, 0) * tf.expand_dims(planesD, 1)\n    ND_diff = tf.reshape(ND - tf.transpose(ND, [1, 0, 2]), [-1, 3])\n    coefX, coefY, coefZ = tf.unstack(ND_diff, axis=1)\n\n    pixels = []\n    focalLength = 517.97\n    urange = tf.range(width, dtype=tf.float32) / focalLength\n    ones = tf.ones(urange.shape)\n    vs = (coefX * urange + coefY * ones) / coefZ\n    pixels.append(tf.stack([tf.floor(vs), urange], axis=1))\n    pixels.append(tf.stack([tf.ceil(vs), urange], axis=1))\n    \n    vrange = tf.range(height, dtype=tf.float32) / focalLength\n    ones = tf.ones(vrange.shape)\n    us = -(coefY * ones - coefZ * vrange) / coefX\n    pixels.append(tf.stack([vrange, tf.floor(us)], axis=1))\n    pixels.append(tf.stack([vrange, tf.ceil(us)], axis=1))\n\n    v, u = tf.unstack(pixels, axis=1)\n    validMask = tf.logical_and(tf.less(u, width), tf.less(v, height))\n    validMask = tf.logical_and(validMask, tf.greater_equal(u, 0))\n    validMask = tf.logical_and(validMask, tf.greater_equal(v, 0))\n    \n    pixels *= tf.expand_dims(invalidMask, -1)\n    \n    boundary = tf.sparse_to_dense(pixels, output_shape=[height, width], sparse_values=1)\n    return boundary\n\n\ndef fitPlaneMasksModule(planes, depth, normal, width = 640, height = 480, numPlanes = 20, normalDotThreshold = np.cos(np.deg2rad(5)), distanceThreshold = 0.05, closing=True, one_hot=True):\n    focalLength = 517.97\n    urange = (tf.range(width, dtype=tf.float32) / width - 0.5) / focalLength * 640\n    urange = tf.tile(tf.reshape(urange, [1, -1]), [height, 1])\n    vrange = (tf.range(height, dtype=tf.float32) / height - 0.5) / focalLength * 480\n    vrange = tf.tile(tf.reshape(vrange, [-1, 1]), [1, width])\n        \n    X = depth * tf.expand_dims(urange, -1)\n    Y = depth\n    Z = -depth * tf.expand_dims(vrange, -1)\n    XYZ = tf.concat([X, Y, Z], axis=3)\n    XYZ = tf.reshape(XYZ, [-1, height * width, 3])\n    plane_parameters = planes\n    planesD = tf.norm(plane_parameters, axis=2, keep_dims=True)\n    planesNormal = tf.div(tf.negative(plane_parameters), tf.clip_by_value(planesD, 1e-4, 10))\n\n    distance = tf.reshape(tf.abs(tf.matmul(XYZ, planesNormal, transpose_b=True) + tf.reshape(planesD, [-1, 1, numPlanes])), [-1, height, width, numPlanes])\n    angle = tf.reshape(np.abs(tf.matmul(tf.reshape(normal, [-1, height * width, 3]), planesNormal, transpose_b=True)), [-1, height, width, numPlanes])\n\n    planeMasks = tf.cast(tf.logical_and(tf.greater(angle, normalDotThreshold), tf.less(distance, distanceThreshold)), tf.float32)\n\n    if closing:\n        #morphological closing\n        planeMasks = tf.nn.max_pool(planeMasks, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n        pass\n    plane_mask = tf.reduce_max(planeMasks, axis=3, keep_dims=True)\n    if closing:\n        plane_mask = 1 - tf.nn.max_pool(1 - plane_mask, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n        pass\n    if one_hot:\n        #one-hot encoding\n        planeMasks = tf.one_hot(tf.argmax(planeMasks * (distanceThreshold - distance), axis=3), depth=numPlanes) * plane_mask\n        pass\n    \n    return planeMasks, plane_mask\n    \n'"
PlaneSetGeneration/planenet.py,84,"b""# Converted to TensorFlow .caffemodel\n# with the DeepLab-ResNet configuration.\n# The batch normalisation layer is provided by\n# the slim library (https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim).\n\nfrom kaffe.tensorflow import Network\nimport tensorflow as tf\n\nclass PlaneNet(Network):\n    def setup(self, is_training, numGlobalPlanes, networkType='grid', deepSupervisionLayers=[]):\n        '''Network definition.\n        \n        Args:\n          is_training: whether to update the running mean and variance of the batch normalisation layer.\n                       If the batch size is small, it is better to keep the running mean and variance of \n                       the-pretrained model frozen.\n          num_classes: number of classes to predict (including background).\n        '''\n\n        if False:\n            (self.feed('img_inp')\n                 .conv(7, 7, 64, 2, 2, biased=False, relu=False, name='conv1')\n                 .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn_conv1')\n                 .max_pool(3, 3, 2, 2, name='pool1'))\n            \n        else:\n            with tf.variable_scope('degridding'):\n                (self.feed('img_inp')\n                     .conv(7, 7, 16, 1, 1, biased=False, relu=False, name='conv1')\n                     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn1')\n                     .conv(1, 1, 16, 2, 2, biased=False, relu=False, name='conv2_c')\n                     .batch_normalization(is_training=is_training, activation_fn=None, name='bn2c'))\n\n                (self.feed('bn1')\n                     .conv(3, 3, 16, 1, 1, biased=False, relu=False, name='conv2a')\n                     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn2a')\n                     .conv(3, 3, 16, 2, 2, biased=False, relu=False, name='conv2b')\n                     .batch_normalization(is_training=is_training, activation_fn=None, name='bn2b'))\n                \n                (self.feed('bn2b',\n                           'bn2c')\n                     .add(name='add1')\n                     .relu(name='relu1')\n                     .conv(1, 1, 32, 2, 2, biased=False, relu=False, name='conv3c')\n                     .batch_normalization(is_training=is_training, activation_fn=None, name='bn3c'))\n                (self.feed('relu1')\n                     .conv(3, 3, 32, 1, 1, biased=False, relu=False, name='conv3a')\n                     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3a')\n                     .conv(3, 3, 32, 2, 2, biased=False, relu=False, name='conv3b')\n                     .batch_normalization(is_training=is_training, activation_fn=None, name='bn3b'))\n                (self.feed('bn3b',\n                           'bn3c')\n                     .add(name='add2')\n                     .relu(name='pool1'))\n                pass\n            pass\n\n        (self.feed('pool1')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res2a_branch1')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn2a_branch1'))\n                 \n        (self.feed('pool1')\n             .conv(1, 1, 64, 1, 1, biased=False, relu=False, name='res2a_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn2a_branch2a')\n             .conv(3, 3, 64, 1, 1, biased=False, relu=False, name='res2a_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn2a_branch2b')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res2a_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn2a_branch2c'))\n\n        (self.feed('bn2a_branch1', \n                   'bn2a_branch2c')\n             .add(name='res2a')\n             .relu(name='res2a_relu')\n             .conv(1, 1, 64, 1, 1, biased=False, relu=False, name='res2b_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn2b_branch2a')\n             .conv(3, 3, 64, 1, 1, biased=False, relu=False, name='res2b_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn2b_branch2b')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res2b_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn2b_branch2c'))\n\n        (self.feed('res2a_relu', \n                   'bn2b_branch2c')\n             .add(name='res2b')\n             .relu(name='res2b_relu')\n             .conv(1, 1, 64, 1, 1, biased=False, relu=False, name='res2c_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn2c_branch2a')\n             .conv(3, 3, 64, 1, 1, biased=False, relu=False, name='res2c_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn2c_branch2b')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res2c_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn2c_branch2c'))\n\n        (self.feed('res2b_relu', \n                   'bn2c_branch2c')\n             .add(name='res2c')\n             .relu(name='res2c_relu')\n             .conv(1, 1, 512, 2, 2, biased=False, relu=False, name='res3a_branch1')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn3a_branch1'))\n\n        (self.feed('res2c_relu')\n             .conv(1, 1, 128, 2, 2, biased=False, relu=False, name='res3a_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3a_branch2a')\n             .conv(3, 3, 128, 1, 1, biased=False, relu=False, name='res3a_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3a_branch2b')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res3a_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn3a_branch2c'))\n\n        (self.feed('bn3a_branch1', \n                   'bn3a_branch2c')\n             .add(name='res3a')\n             .relu(name='res3a_relu')\n             .conv(1, 1, 128, 1, 1, biased=False, relu=False, name='res3b1_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3b1_branch2a')\n             .conv(3, 3, 128, 1, 1, biased=False, relu=False, name='res3b1_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3b1_branch2b')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res3b1_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn3b1_branch2c'))\n\n        (self.feed('res3a_relu', \n                   'bn3b1_branch2c')\n             .add(name='res3b1')\n             .relu(name='res3b1_relu')\n             .conv(1, 1, 128, 1, 1, biased=False, relu=False, name='res3b2_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3b2_branch2a')\n             .conv(3, 3, 128, 1, 1, biased=False, relu=False, name='res3b2_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3b2_branch2b')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res3b2_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn3b2_branch2c'))\n\n        (self.feed('res3b1_relu', \n                   'bn3b2_branch2c')\n             .add(name='res3b2')\n             .relu(name='res3b2_relu')\n             .conv(1, 1, 128, 1, 1, biased=False, relu=False, name='res3b3_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3b3_branch2a')\n             .conv(3, 3, 128, 1, 1, biased=False, relu=False, name='res3b3_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3b3_branch2b')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res3b3_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn3b3_branch2c'))\n\n        (self.feed('res3b2_relu', \n                   'bn3b3_branch2c')\n             .add(name='res3b3')\n             .relu(name='res3b3_relu')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4a_branch1')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4a_branch1'))\n\n        (self.feed('res3b3_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4a_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4a_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4a_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4a_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4a_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4a_branch2c'))\n\n        (self.feed('bn4a_branch1', \n                   'bn4a_branch2c')\n             .add(name='res4a')\n             .relu(name='res4a_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b1_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b1_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b1_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b1_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b1_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b1_branch2c'))\n\n        (self.feed('res4a_relu', \n                   'bn4b1_branch2c')\n             .add(name='res4b1')\n             .relu(name='res4b1_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b2_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b2_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b2_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b2_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b2_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b2_branch2c'))\n\n        (self.feed('res4b1_relu', \n                   'bn4b2_branch2c')\n             .add(name='res4b2')\n             .relu(name='res4b2_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b3_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b3_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b3_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b3_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b3_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b3_branch2c'))\n\n        (self.feed('res4b2_relu', \n                   'bn4b3_branch2c')\n             .add(name='res4b3')\n             .relu(name='res4b3_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b4_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b4_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b4_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b4_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b4_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b4_branch2c'))\n\n        (self.feed('res4b3_relu', \n                   'bn4b4_branch2c')\n             .add(name='res4b4')\n             .relu(name='res4b4_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b5_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b5_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b5_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b5_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b5_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b5_branch2c'))\n\n        (self.feed('res4b4_relu', \n                   'bn4b5_branch2c')\n             .add(name='res4b5')\n             .relu(name='res4b5_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b6_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b6_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b6_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b6_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b6_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b6_branch2c'))\n\n        (self.feed('res4b5_relu', \n                   'bn4b6_branch2c')\n             .add(name='res4b6')\n             .relu(name='res4b6_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b7_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b7_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b7_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b7_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b7_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b7_branch2c'))\n\n        (self.feed('res4b6_relu', \n                   'bn4b7_branch2c')\n             .add(name='res4b7')\n             .relu(name='res4b7_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b8_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b8_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b8_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b8_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b8_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b8_branch2c'))\n\n        (self.feed('res4b7_relu', \n                   'bn4b8_branch2c')\n             .add(name='res4b8')\n             .relu(name='res4b8_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b9_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b9_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b9_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b9_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b9_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b9_branch2c'))\n\n        (self.feed('res4b8_relu', \n                   'bn4b9_branch2c')\n             .add(name='res4b9')\n             .relu(name='res4b9_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b10_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b10_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b10_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b10_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b10_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b10_branch2c'))\n\n        (self.feed('res4b9_relu', \n                   'bn4b10_branch2c')\n             .add(name='res4b10')\n             .relu(name='res4b10_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b11_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b11_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b11_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b11_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b11_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b11_branch2c'))\n\n        (self.feed('res4b10_relu', \n                   'bn4b11_branch2c')\n             .add(name='res4b11')\n             .relu(name='res4b11_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b12_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b12_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b12_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b12_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b12_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b12_branch2c'))\n\n        (self.feed('res4b11_relu', \n                   'bn4b12_branch2c')\n             .add(name='res4b12')\n             .relu(name='res4b12_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b13_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b13_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b13_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b13_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b13_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b13_branch2c'))\n\n        (self.feed('res4b12_relu', \n                   'bn4b13_branch2c')\n             .add(name='res4b13')\n             .relu(name='res4b13_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b14_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b14_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b14_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b14_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b14_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b14_branch2c'))\n\n        (self.feed('res4b13_relu', \n                   'bn4b14_branch2c')\n             .add(name='res4b14')\n             .relu(name='res4b14_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b15_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b15_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b15_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b15_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b15_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b15_branch2c'))\n\n        (self.feed('res4b14_relu', \n                   'bn4b15_branch2c')\n             .add(name='res4b15')\n             .relu(name='res4b15_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b16_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b16_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b16_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b16_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b16_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b16_branch2c'))\n\n        (self.feed('res4b15_relu', \n                   'bn4b16_branch2c')\n             .add(name='res4b16')\n             .relu(name='res4b16_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b17_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b17_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b17_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b17_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b17_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b17_branch2c'))\n\n        (self.feed('res4b16_relu', \n                   'bn4b17_branch2c')\n             .add(name='res4b17')\n             .relu(name='res4b17_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b18_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b18_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b18_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b18_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b18_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b18_branch2c'))\n\n        (self.feed('res4b17_relu', \n                   'bn4b18_branch2c')\n             .add(name='res4b18')\n             .relu(name='res4b18_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b19_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b19_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b19_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b19_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b19_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b19_branch2c'))\n\n        (self.feed('res4b18_relu', \n                   'bn4b19_branch2c')\n             .add(name='res4b19')\n             .relu(name='res4b19_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b20_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b20_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b20_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b20_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b20_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b20_branch2c'))\n\n        (self.feed('res4b19_relu', \n                   'bn4b20_branch2c')\n             .add(name='res4b20')\n             .relu(name='res4b20_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b21_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b21_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b21_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b21_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b21_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b21_branch2c'))\n\n        (self.feed('res4b20_relu', \n                   'bn4b21_branch2c')\n             .add(name='res4b21')\n             .relu(name='res4b21_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b22_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b22_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b22_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b22_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b22_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b22_branch2c'))\n\n        (self.feed('res4b21_relu', \n                   'bn4b22_branch2c')\n             .add(name='res4b22')\n             .relu(name='res4b22_relu')\n             .conv(1, 1, 2048, 1, 1, biased=False, relu=False, name='res5a_branch1')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn5a_branch1'))\n\n        (self.feed('res4b22_relu')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res5a_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn5a_branch2a')\n             .atrous_conv(3, 3, 512, 4, padding='SAME', biased=False, relu=False, name='res5a_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn5a_branch2b')\n             .conv(1, 1, 2048, 1, 1, biased=False, relu=False, name='res5a_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn5a_branch2c'))\n\n        (self.feed('bn5a_branch1', \n                   'bn5a_branch2c')\n             .add(name='res5a')\n             .relu(name='res5a_relu')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res5b_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn5b_branch2a')\n             .atrous_conv(3, 3, 512, 4, padding='SAME', biased=False, relu=False, name='res5b_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn5b_branch2b')\n             .conv(1, 1, 2048, 1, 1, biased=False, relu=False, name='res5b_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn5b_branch2c'))\n\n        (self.feed('res5a_relu', \n                   'bn5b_branch2c')\n             .add(name='res5b')\n             .relu(name='res5b_relu')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res5c_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn5c_branch2a')\n             .atrous_conv(3, 3, 512, 4, padding='SAME', biased=False, relu=False, name='res5c_branch2b')\n             .batch_normalization(activation_fn=tf.nn.relu, name='bn5c_branch2b', is_training=is_training)\n             .conv(1, 1, 2048, 1, 1, biased=False, relu=False, name='res5c_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn5c_branch2c'))\n\n        (self.feed('res5b_relu', \n                   'bn5c_branch2c')\n             .add(name='res5c')\n             .relu(name='res5c_relu'))\n\n        \n        \n        (self.feed('res5c_relu')\n             .avg_pool(24, 32, 24, 32, name='res5d_pool1')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res5d_pool1_conv')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='res5d_pool1_bn')\n             .resize_bilinear(size=[24, 32], name='res5d_upsample1'))\n\n        (self.feed('res5c_relu')\n             .avg_pool(12, 16, 12, 16, name='res5d_pool2')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res5d_pool2_conv')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='res5d_pool2_bn')\n             .resize_bilinear(size=[24, 32], name='res5d_upsample2'))\n\n        (self.feed('res5c_relu')\n             .avg_pool(6, 8, 6, 8, name='res5d_pool3')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res5d_pool3_conv')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='res5d_pool3_bn')\n             .resize_bilinear(size=[24, 32], name='res5d_upsample3'))\n\n        (self.feed('res5c_relu')\n             .avg_pool(3, 4, 3, 4, name='res5d_pool4')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res5d_pool4_conv')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='res5d_pool4_bn')\n             .resize_bilinear(size=[24, 32], name='res5d_upsample4'))\n\n\n        if len(deepSupervisionLayers) > 0:\n            with tf.variable_scope('deep_supervision'):\n                for layer in deepSupervisionLayers:\n                    (self.feed(layer)\n                         .avg_pool(24, 32, 24, 32, name=layer+'_pool1')\n                         .conv(1, 1, 512, 1, 1, biased=False, relu=False, name=layer+'_pool1_conv')\n                         .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=layer+'_pool1_bn')\n                         .resize_bilinear(size=[24, 32], name=layer+'_upsample1'))\n            \n                    (self.feed(layer)\n                         .avg_pool(12, 16, 12, 16, name=layer+'_pool2')\n                         .conv(1, 1, 512, 1, 1, biased=False, relu=False, name=layer+'_pool2_conv')\n                         .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=layer+'_pool2_bn')\n                         .resize_bilinear(size=[24, 32], name=layer+'_upsample2'))\n            \n                    (self.feed(layer)\n                         .avg_pool(6, 8, 6, 8, name=layer+'_pool3')\n                         .conv(1, 1, 512, 1, 1, biased=False, relu=False, name=layer+'_pool3_conv')\n                         .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=layer+'_pool3_bn')\n                         .resize_bilinear(size=[24, 32], name=layer+'_upsample3'))\n\n                    (self.feed(layer)\n                         .avg_pool(3, 4, 3, 4, name=layer+'_pool4')\n                         .conv(1, 1, 512, 1, 1, biased=False, relu=False, name=layer+'_pool4_conv')\n                         .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=layer+'_pool4_bn')\n                         .resize_bilinear(size=[24, 32], name=layer+'_upsample4'))\n          \n                    (self.feed(layer+'_pool1')\n                         .reshape(shape=[-1, 1024], name=layer+'_plane_reshape1')\n                         #.fc(num_out=512, name='plane_fc_1', relu=True)\n                         #.dropout(keep_prob=0.9, name=layer+'_plane_dropout')\n                         .fc(num_out=numGlobalPlanes * 3, name=layer+'_plane_fc', relu=False)\n                         .reshape(shape=[-1, numGlobalPlanes, 3], name=layer+'_plane_pred'))\n \n                    (self.feed(layer,\n                               layer+'_upsample1',\n                               layer+'_upsample2',\n                               layer+'_upsample3',\n                               layer+'_upsample4')\n                         .concat(axis=3, name=layer+'_segmentation_concat')\n                         .conv(3, 3, 512, 1, 1, biased=False, relu=False, name=layer+'_segmentation_conv1')\n                         .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=layer+'_segmentation_bn1')\n                         .dropout(keep_prob=0.9, name=layer+'_segmentation_dropout'))\n         \n                    (self.feed(layer+'_segmentation_dropout')\n                         .conv(1, 1, numGlobalPlanes, 1, 1, relu=False, name=layer+'_segmentation_conv2')\n                         .resize_bilinear(size=[192, 256], name=layer+'_segmentation_pred'))\n                    continue\n                pass\n            pass\n            \n\n\n        if False:\n            (self.feed('res5d_pool2_bn')\n                 .avg_pool(2, 2, 2, 2, name='res5d_downsample2'))        \n            (self.feed('res5d_pool3_bn')\n                 .avg_pool(4, 4, 4, 4, name='res5d_downsample3'))\n            (self.feed('res5d_pool4_bn')\n                 .avg_pool(8, 8, 8, 8, name='res5d_downsample4'))\n            (self.feed('res5d_pool1_bn',\n                       'res5d_downsample2',\n                       'res5d_downsample3',\n                       'res5d_downsample4')\n                 .reshape(shape=[-1, 2048], name='plane_reshape1')\n                 .fc(num_out=numGlobalPlanes * 3, name='plane_fc', relu=False)\n                 .reshape(shape=[-1, numGlobalPlanes, 3], name='plane_pred'))\n        else:\n            if False:\n                (self.feed('res5d_pool1')\n                     .reshape(shape=[-1, 2048], name='plane_reshape1')\n                     .fc(num_out=512, name='plane_fc_1', relu=True)\n                     .fc(num_out=numGlobalPlanes * 3, name='plane_fc_2', relu=False)\n                     .reshape(shape=[-1, numGlobalPlanes, 3], name='plane_pred'))\n            else:\n                (self.feed('res5d_pool1')\n                     .reshape(shape=[-1, 2048], name='plane_reshape1')\n                     .fc(num_out=numGlobalPlanes * 3, name='plane_fc', relu=False)\n                     .reshape(shape=[-1, numGlobalPlanes, 3], name='plane_pred'))\n                \n                if 'confidence' in networkType or 'deep' in networkType:\n                    (self.feed('plane_reshape1')\n                         .fc(num_out=512, name='plane_confidence_fc1', relu=True)\n                         .fc(num_out=numGlobalPlanes, name='plane_confidence_fc', relu=False)\n                         .reshape(shape=[-1, numGlobalPlanes, 1], name='plane_confidence_pred'))\n                    pass\n            pass\n\n             \n        (self.feed('res5c_relu',\n                   'res5d_upsample1',\n                   'res5d_upsample2',\n                   'res5d_upsample3',\n                   'res5d_upsample4')\n             .concat(axis=3, name='segmentation_concat')\n             .conv(3, 3, 512, 1, 1, biased=False, relu=False, name='segmentation_conv1')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='segmentation_bn1')\n             .dropout(keep_prob=0.9, name='segmentation_dropout'))\n\n         \n        (self.feed('segmentation_dropout')\n             .conv(1, 1, numGlobalPlanes, 1, 1, relu=False, name='segmentation_conv2')\n             .resize_bilinear(size=[192, 256], name='segmentation_pred'))\n\n\n        if 'planenet' in networkType:\n            (self.feed('segmentation_dropout')\n                 .conv(1, 1, 1, 1, 1, relu=False, name='non_plane_mask_conv2')\n                 .resize_bilinear(size=[192, 256], name='non_plane_mask_pred'))\n            (self.feed('segmentation_dropout')\n                 .conv(1, 1, 1, 1, 1, relu=False, name='non_plane_depth_conv2')\n                 .resize_bilinear(size=[192, 256], name='non_plane_depth_pred'))\n            (self.feed('segmentation_dropout')\n                 .conv(1, 1, 3, 1, 1, relu=False, name='non_plane_normal_conv2')\n                 .resize_bilinear(size=[192, 256], name='non_plane_normal_pred'))\n            pass\n\n        if 'global' in networkType:\n            return\n\n        # (self.feed('segmentation_dropout')\n        #      .conv(1, 1, 3, 1, 1, relu=False, name='boundary_conv2')\n        #      .resize_bilinear(size=[192, 256], name='boundary_pred'))\n          \n        (self.feed('segmentation_dropout')\n             .conv(1, 1, 1, 1, 1, relu=False, name='boundary_smooth_conv5')\n             .resize_bilinear(size=[192, 256], name='boundary_smooth_upsample5'))\n        (self.feed('segmentation_dropout')\n             .conv(1, 1, 1, 1, 1, relu=False, name='boundary_occlusion_conv5')\n             .resize_bilinear(size=[192, 256], name='boundary_occlusion_upsample5'))\n        (self.feed('bn1')\n             .conv(1, 1, 1, 1, 1, relu=False, name='boundary_conv0')\n             .resize_bilinear(size=[192, 256], name='boundary_upsample0'))\n        (self.feed('relu1')\n        #(self.feed('bn_conv1')        \n             .conv(1, 1, 1, 1, 1, relu=False, name='boundary_conv1')\n             .resize_bilinear(size=[192, 256], name='boundary_upsample1'))\n        (self.feed('res2c_relu')\n             .conv(1, 1, 1, 1, 1, relu=False, name='boundary_conv2')\n             .resize_bilinear(size=[192, 256], name='boundary_upsample2'))\n        (self.feed('res3b3_relu')\n             .conv(1, 1, 1, 1, 1, relu=False, name='boundary_conv3')\n             .resize_bilinear(size=[192, 256], name='boundary_upsample3'))\n        (self.feed('boundary_smooth_upsample5',\n                   'boundary_upsample0',                   \n                   'boundary_upsample1',\n                   'boundary_upsample2',\n                   'boundary_upsample3')\n             .concat(axis=3, name='boundary_smooth_concat')         \n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='boundary_smooth_bn')\n             .conv(1, 1, 1, 1, 1, relu=False, name='boundary_smooth_pred'))\n        (self.feed('boundary_occlusion_upsample5',\n                   'boundary_upsample0',\n                   'boundary_upsample1',\n                   'boundary_upsample2',\n                   'boundary_upsample3')\n             .concat(axis=3, name='boundary_occlusion_concat')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='boundary_occlusion_bn')\n             .conv(1, 1, 1, 1, 1, relu=False, name='boundary_occlusion_pred'))\n        (self.feed('boundary_smooth_pred',\n                   'boundary_occlusion_pred')\n             .concat(axis=3, name='boundary_pred'))\n\n        \n        (self.feed('segmentation_dropout')\n             .conv(1, 1, 1, 1, 1, relu=False, name='s_8_pred'))\n        (self.feed('segmentation_dropout')\n             .conv(1, 1, 3, 1, 1, relu=False, name='p_8_pred'))\n\n        if 'local' in networkType:\n            (self.feed('segmentation_dropout')\n                 .conv(1, 1, 4, 1, 1, relu=False, name='b_8_pred'))\n        else:\n            (self.feed('segmentation_dropout')\n                 .conv(1, 1, 16*16, 1, 1, relu=False, name='m_8_pred'))\n            pass\n            \n"""
PlaneSetGeneration/tf_nndistance.py,11,"b""import tensorflow as tf\nfrom tensorflow.python.framework import ops\nnn_distance_module=tf.load_op_library('./tf_nndistance_so.so')\n\ndef nn_distance(xyz1,xyz2):\n\t'''\nComputes the distance of nearest neighbors for a pair of point clouds\ninput: xyz1: (batch_size,#points_1,3)  the first point cloud\ninput: xyz2: (batch_size,#points_2,3)  the second point cloud\noutput: dist1: (batch_size,#point_1)   distance from first to second\noutput: idx1:  (batch_size,#point_1)   nearest neighbor from first to second\noutput: dist2: (batch_size,#point_2)   distance from second to first\noutput: idx2:  (batch_size,#point_2)   nearest neighbor from second to first\n\t'''\n        return nn_distance_module.nn_distance(xyz1,xyz2)\n#@tf.RegisterShape('NnDistance')\n#def _nn_distance_shape(op):\n\t#shape1=op.inputs[0].get_shape().with_rank(3)\n\t#shape2=op.inputs[1].get_shape().with_rank(3)\n\t#return [tf.TensorShape([shape1.dims[0],shape1.dims[1]]),tf.TensorShape([shape1.dims[0],shape1.dims[1]]),\n\t\t#tf.TensorShape([shape2.dims[0],shape2.dims[1]]),tf.TensorShape([shape2.dims[0],shape2.dims[1]])]\n@ops.RegisterGradient('NnDistance')\ndef _nn_distance_grad(op,grad_dist1,grad_idx1,grad_dist2,grad_idx2):\n\txyz1=op.inputs[0]\n\txyz2=op.inputs[1]\n\tidx1=op.outputs[1]\n\tidx2=op.outputs[3]\n\treturn nn_distance_module.nn_distance_grad(xyz1,xyz2,grad_dist1,idx1,grad_dist2,idx2)\n\n\nif __name__=='__main__':\n\timport numpy as np\n\timport random\n\timport time\n\tfrom tensorflow.python.ops.gradient_checker import compute_gradient\n\trandom.seed(100)\n\tnp.random.seed(100)\n\twith tf.Session('') as sess:\n\t\txyz1=np.random.randn(32,16384,3).astype('float32')\n\t\txyz2=np.random.randn(32,1024,3).astype('float32')\n\t\t#with tf.device('/gpu:0'):\n\t\tif True:\n\t\t\tinp1=tf.Variable(xyz1)\n\t\t\tinp2=tf.constant(xyz2)\n\t\t\treta,retb,retc,retd=nn_distance(inp1,inp2)\n\t\t\tloss=tf.reduce_sum(reta)+tf.reduce_sum(retc)\n\t\t\ttrain=tf.train.GradientDescentOptimizer(learning_rate=0.05).minimize(loss)\n\t\tsess.run(tf.global_variables_initializer())\n\t\tt0=time.time()\n\t\tt1=t0\n\t\tbest=1e100\n\t\tfor i in xrange(100):\n\t\t\ttrainloss,_=sess.run([loss,train])\n\t\t\tnewt=time.time()\n\t\t\tbest=min(best,newt-t1)\n\t\t\tprint i,trainloss,(newt-t0)/(i+1),best\n\t\t\tt1=newt\n\t\t#print sess.run([inp1,retb,inp2,retd])\n\t\t#grads=compute_gradient([inp1,inp2],[(16,32,3),(16,32,3)],loss,(1,),[xyz1,xyz2])\n\t\t#for i,j in grads:\n\t\t\t#print i.shape,j.shape,np.mean(np.abs(i-j)),np.mean(np.abs(i)),np.mean(np.abs(j))\n\t\t#for i in xrange(10):\n\t\t\t#t0=time.time()\n\t\t\t#a,b,c,d=sess.run([reta,retb,retc,retd],feed_dict={inp1:xyz1,inp2:xyz2})\n\t\t\t#print 'time',time.time()-t0\n\t\t#print a.shape,b.shape,c.shape,d.shape\n\t\t#print a.dtype,b.dtype,c.dtype,d.dtype\n\t\t#samples=np.array(random.sample(range(xyz2.shape[1]),100),dtype='int32')\n\t\t#dist1=((xyz1[:,samples,None,:]-xyz2[:,None,:,:])**2).sum(axis=-1).min(axis=-1)\n\t\t#idx1=((xyz1[:,samples,None,:]-xyz2[:,None,:,:])**2).sum(axis=-1).argmin(axis=-1)\n\t\t#print np.abs(dist1-a[:,samples]).max()\n\t\t#print np.abs(idx1-b[:,samples]).max()\n\t\t#dist2=((xyz2[:,samples,None,:]-xyz1[:,None,:,:])**2).sum(axis=-1).min(axis=-1)\n\t\t#idx2=((xyz2[:,samples,None,:]-xyz1[:,None,:,:])**2).sum(axis=-1).argmin(axis=-1)\n\t\t#print np.abs(dist2-c[:,samples]).max()\n\t\t#print np.abs(idx2-d[:,samples]).max()\n\n"""
PlaneSetGeneration/train_planenet.py,251,"b'import sys\nimport tensorflow as tf\nimport numpy as np\nimport cv2\nimport os\nimport time\nimport sys\nimport tf_nndistance\nimport argparse\nimport glob\nimport PIL\n\n#from SegmentationBatchFetcherV2 import *\nfrom RecordReader import *\n\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom utils import *\nfrom layers import PlaneDepthLayer, PlaneNormalLayer\nfrom modules import *\n\n#from resnet import inference as resnet\n#from resnet import fc as fc, conv as conv, block_transpose as block_transpose, conv_transpose as conv_transpose, bn as bn, UPDATE_OPS_COLLECTION\n#from config import Config\nfrom modules import *\nimport scipy.ndimage as ndimage\nfrom planenet import PlaneNet\n#from SegmentationRefinement import refineSegmentation\n\nnp.set_printoptions(precision=2, linewidth=200)\n\nMOVING_AVERAGE_DECAY = 0.99\n                          \ndeepSupervisionLayers=[\'res4b22_relu\']\n#deepSupervisionLayers=[]\n\ndef build_graph(img_inp_train, img_inp_val, plane_gt_train, plane_gt_val, validating_inp, is_training=True, numOutputPlanes=20, gpu_id = 0, useCRF= 0, suffix=\'forward\'):\n    if suffix == \'12_22\':\n        deepSupervisionLayers.append(\'res4b12_relu\')\n        pass\n    \n    with tf.device(\'/gpu:%d\'%gpu_id):\n        training_flag = tf.logical_not(validating_inp)\n        #training_flag = tf.convert_to_tensor(True, dtype=\'bool\', name=\'is_training\')\n        #training_flag = tf.convert_to_tensor(is_training, dtype=\'bool\', name=\'is_training\')\n        \n        img_inp = tf.cond(validating_inp, lambda: img_inp_val, lambda: img_inp_train)\n        plane_gt = tf.cond(validating_inp, lambda: plane_gt_val, lambda: plane_gt_train)\n\n        net = PlaneNet({\'img_inp\': img_inp}, is_training=training_flag, numGlobalPlanes=numOutputPlanes, deepSupervisionLayers=deepSupervisionLayers, networkType=\'planenet_\' + suffix)\n        segmentation_pred = net.layers[\'segmentation_pred\']\n        plane_pred = net.layers[\'plane_pred\']\n        boundary_pred = net.layers[\'boundary_pred\']\n        grid_s_pred = net.layers[\'s_8_pred\']\n        grid_p_pred = net.layers[\'p_8_pred\']\n        grid_m_pred = net.layers[\'m_8_pred\']\n\n\n        non_plane_mask_pred = net.layers[\'non_plane_mask_pred\']\n        non_plane_depth_pred = net.layers[\'non_plane_depth_pred\']\n        non_plane_normal_pred = net.layers[\'non_plane_normal_pred\']\n\n        if suffix == \'confidence\' or suffix == \'deep\':\n            plane_confidence_pred = net.layers[\'plane_confidence_pred\']\n        else:\n            plane_confidence_pred = tf.zeros((int(plane_pred.shape[0]), numOutputPlanes, 1))\n            pass\n\n\n        # dists_forward, map_forward, dists_backward, map_backward = tf_nndistance.nn_distance(plane_gt, plane_pred)\n        # plane_map = tf.one_hot(map_forward, depth=numOutputPlanes, axis=-1)\n        # plane_pred = tf.transpose(tf.matmul(plane_gt, plane_map, transpose_a=True), [0, 2, 1])\n        #plane_pred = tf.tile(tf.slice(plane_gt, [0, 11, 0], [int(plane_gt.shape[0]), 1, 3]), [1, numOutputPlanes, 1])\n        \n        if not is_training and False:\n            with tf.variable_scope(\'depth\'):\n                plane_parameters = tf.reshape(plane_pred, (-1, 3))\n                plane_depths = planeDepthsModule(plane_parameters, WIDTH, HEIGHT)\n                plane_depths = tf.transpose(tf.reshape(plane_depths, [HEIGHT, WIDTH, -1, numOutputPlanes]), [2, 0, 1, 3])\n\n                segmentation = segmentation_pred\n                # if useCRF > 0:\n                #     segmentation = tf.nn.softmax(segmentation)\n                #     with tf.variable_scope(\'crf\'):\n                #         segmentation = segmentationRefinementModule(segmentation, plane_depths, numIterations=useCRF)\n                #         pass\n                #     pass\n                # else:\n                #     #segmentation = tf.one_hot(tf.argmax(segmentation, 3), depth=numOutputPlanes)\n                #     segmentation = tf.nn.softmax(segmentation)\n                #     pass\n                segmentation = tf.nn.softmax(segmentation)\n                \n                #segmentation = segmentationRefinementModuleBoundary(segmentation, plane_depths, numIterations=1)\n                segmentation = tf.cond(training_flag, lambda: segmentation, lambda: tf.one_hot(tf.argmax(segmentation, 3), depth=numOutputPlanes))\n\n                \n                #plane_depths = tf.concat([plane_depths, non_plane_depth], 3)\n                #segmentation = tf.concat([segmentation, tf.ones(non_plane_depth.shape) * 0.5], 3)            \n                depth_pred = tf.reduce_sum(tf.multiply(plane_depths, segmentation), axis=3, keep_dims=True)\n                pass\n\n            with tf.variable_scope(\'normal\'):\n                plane_normals = planeNormalsModule(plane_parameters, WIDTH, HEIGHT)\n                plane_normals = tf.reshape(plane_normals, [-1, 1, 1, numOutputPlanes, 3])\n                normal_pred = tf.reduce_sum(tf.multiply(plane_normals, tf.expand_dims(segmentation, -1)), axis=3)\n                pass\n            pass\n        else:\n            depth_pred = tf.zeros((plane_pred.shape[0], HEIGHT, WIDTH, 1))\n            normal_pred = tf.zeros((plane_pred.shape[0], HEIGHT, WIDTH, 1))\n            segmentation = tf.zeros((plane_pred.shape[0], HEIGHT, WIDTH, numOutputPlanes))\n            pass\n\n    plane_preds = []\n    segmentation_preds = []\n    for layer in deepSupervisionLayers:\n        plane_preds.append(net.layers[layer+\'_plane_pred\'])\n        segmentation_preds.append(net.layers[layer+\'_segmentation_pred\'])\n        continue\n      \n    return plane_pred, plane_confidence_pred, depth_pred, normal_pred, segmentation_pred, non_plane_mask_pred, non_plane_depth_pred, non_plane_normal_pred, boundary_pred, grid_s_pred, grid_p_pred, grid_m_pred, plane_preds, segmentation_preds, segmentation\n\ndef build_loss(plane_pred, plane_confidence_pred, depth_pred, normal_pred, segmentation_pred, non_plane_mask_pred, non_plane_depth_pred, non_plane_normal_pred, boundary_pred, grid_s_pred, grid_p_pred, grid_m_pred, plane_preds, segmentation_preds, plane_gt_train, depth_gt_train, normal_gt_train, segmentation_gt_train, boundary_gt_train, grid_s_gt_train, grid_p_gt_train, grid_m_gt_train, num_planes_gt_train, plane_gt_val, depth_gt_val, normal_gt_val, segmentation_gt_val, boundary_gt_val, grid_s_gt_val, grid_p_gt_val, grid_m_gt_val, num_planes_gt_val, validating_inp, numOutputPlanes = 20, gpu_id = 0, useCRF= 0, suffix=\'forward\'):\n\n    with tf.device(\'/gpu:%d\'%gpu_id):    \n        plane_gt = tf.cond(validating_inp, lambda: plane_gt_val, lambda: plane_gt_train)\n        depth_gt = tf.cond(validating_inp, lambda: depth_gt_val, lambda: depth_gt_train)\n        normal_gt = tf.cond(validating_inp, lambda: normal_gt_val, lambda: normal_gt_train)\n        grid_s_gt = tf.cond(validating_inp, lambda: grid_s_gt_val, lambda: grid_s_gt_train)\n        grid_p_gt = tf.cond(validating_inp, lambda: grid_p_gt_val, lambda: grid_p_gt_train)\n        grid_m_gt = tf.cond(validating_inp, lambda: grid_m_gt_val, lambda: grid_m_gt_train)\n        num_planes_gt = tf.cond(validating_inp, lambda: num_planes_gt_val, lambda: num_planes_gt_train)\n\n        #if \'confidence\' in suffix:\n        #distr = tf.contrib.distributions.Bernoulli(logits = tf.ones(plane_confidence_pred.shape) * 100)\n        #plane_pred *= tf.cast(tf.stop_gradient(tf.contrib.distributions.Bernoulli(probs = tf.sigmoid(plane_confidence_pred)).sample()), tf.float32)\n        #sparsity_loss = tf.reduce_mean(1 - tf.sigmoid(plane_confidence_pred)) * 100\n        #pass\n\n        #segmentation_gt = tf.cond(validating_inp, lambda: segmentation_gt_val, lambda: segmentation_gt_train)\n        normalDotThreshold = np.cos(np.deg2rad(5))\n        distanceThreshold = 0.05\n\n        focalLength = 517.97\n        urange = (tf.range(WIDTH, dtype=tf.float32) / (WIDTH + 1) - 0.5) / focalLength * 641\n        urange = tf.tile(tf.reshape(urange, [1, -1]), [HEIGHT, 1])\n        vrange = (tf.range(HEIGHT, dtype=tf.float32) / (HEIGHT + 1) - 0.5) / focalLength * 481\n        vrange = tf.tile(tf.reshape(vrange, [-1, 1]), [1, WIDTH])\n        \n        X = depth_gt * tf.expand_dims(urange, -1)\n        Y = depth_gt\n        Z = -depth_gt * tf.expand_dims(vrange, -1)\n        XYZ = tf.concat([X, Y, Z], axis=3)\n        XYZ = tf.reshape(XYZ, [-1, HEIGHT * WIDTH, 3])\n        #ranges = tf.stack([urange, np.ones([height, width]), -vrange], axis=2)\n        #ranges = tf.reshape(ranges, [-1, 3])\n        #plane_parameters = tf.reshape(plane_gt, [-1, 3])\n        plane_parameters = plane_gt\n        planesD = tf.norm(plane_parameters, axis=2, keep_dims=True)\n        planesD = tf.clip_by_value(planesD, 1e-5, 10)\n        planesNormal = tf.div(tf.negative(plane_parameters), planesD)\n\n        distance = tf.reshape(tf.abs(tf.matmul(XYZ, planesNormal, transpose_b=True) + tf.reshape(planesD, [-1, 1, numOutputPlanes])), [-1, HEIGHT, WIDTH, numOutputPlanes])\n        angle = tf.reshape(np.abs(tf.matmul(tf.reshape(normal_gt, [-1, HEIGHT * WIDTH, 3]), planesNormal, transpose_b=True)), [-1, HEIGHT, WIDTH, numOutputPlanes])\n\n        segmentation_gt = tf.cast(tf.logical_and(tf.greater(angle, normalDotThreshold), tf.less(distance, distanceThreshold)), tf.float32)        \n        segmentation_gt = tf.nn.max_pool(segmentation_gt, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n        plane_mask = tf.reduce_max(segmentation_gt, axis=3, keep_dims=True)\n        plane_mask = 1 - tf.nn.max_pool(1 - plane_mask, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n        segmentation_gt = tf.one_hot(tf.argmax(segmentation_gt * (distanceThreshold - distance), axis=3), depth=numOutputPlanes) * plane_mask\n\n        validPlaneMask = tf.cast(tf.less(tf.tile(tf.expand_dims(tf.range(numOutputPlanes), 0), [int(plane_pred.shape[0]), 1]), tf.expand_dims(num_planes_gt, -1)), tf.float32)        \n\n        \n        if suffix == \'depth_sum\':\n            useBackward = 1\n        else:\n            useBackward = 0\n            pass\n        \n        deep_supervision_loss = tf.constant(0.0)          \n        if \'shallow\' not in suffix:\n            for layer, pred_p in enumerate(plane_preds):\n                dists_forward_deep, map_forward_deep, dists_backward_deep, _ = tf_nndistance.nn_distance(plane_gt, pred_p)\n                #plane_map = tf.one_hot(map_forward, depth=numOutputPlanes, axis=-1)\n                #shuffled_planes = tf.transpose(tf.matmul(pred_p, plane_map, transpose_a=True, transpose_b=True), [0, 2, 1])\n                #dists = tf.concat([dists, shuffled_planes, tf.expand_dims(dists_forward, -1)], axis=2)            \n\n                dists_forward_deep *= validPlaneMask\n                \n                dists_forward_deep = tf.reduce_mean(dists_forward_deep)\n                dists_backward_deep = tf.reduce_mean(dists_backward_deep)\n                deep_supervision_loss += (dists_forward_deep + dists_backward_deep / 2.0 * useBackward) * 10000\n            \n                #loss_p_0 = (dists_forward + dists_backward / 2.0 * useBackward) * 10000\n\n                pred_s = segmentation_preds[layer]\n                forward_map_deep = tf.one_hot(map_forward_deep, depth=numOutputPlanes, axis=-1)\n\n                segmentation_gt_shuffled_deep = tf.reshape(tf.matmul(tf.reshape(segmentation_gt, [-1, HEIGHT * WIDTH, numOutputPlanes]), forward_map_deep), [-1, HEIGHT, WIDTH, numOutputPlanes])\n                segmentation_gt_shuffled_deep = tf.concat([segmentation_gt_shuffled_deep, 1 - plane_mask], axis=3)\n\n                all_segmentations_deep = pred_s\n                all_segmentations_deep = tf.concat([pred_s, non_plane_mask_pred], axis=3)\n                deep_supervision_loss += tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=all_segmentations_deep, labels=segmentation_gt_shuffled_deep)) * 1000\n                \n                continue\n            pass\n\n\n        if suffix == \'deep\':\n            forward_map = forward_map_deep\n            valid_forward_map = forward_map * tf.expand_dims(validPlaneMask, -1)\n            plane_confidence_gt = tf.transpose(tf.reduce_max(valid_forward_map, axis=1, keep_dims=True), [0, 2, 1])\n            plane_confidence_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=plane_confidence_pred, labels=plane_confidence_gt)) * 1000\n            \n            plane_pred += plane_preds[-1]\n            plane_gt_shuffled = tf.transpose(tf.matmul(plane_gt, forward_map_deep, transpose_a=True), [0, 2, 1])\n            plane_loss = tf.reduce_mean(tf.squared_difference(plane_pred, plane_gt_shuffled) * plane_confidence_gt) * 1000\n\n            all_segmentations = tf.concat([segmentation_pred, non_plane_mask_pred], axis=3)\n            all_segmentations += segmentation_preds[-1]\n            \n            segmentation_gt_shuffled = segmentation_gt_shuffled_deep\n            segmentation_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=all_segmentations, labels=segmentation_gt_shuffled)) * 1000\n            dists = plane_confidence_gt\n            pass\n        else:\n            dists_forward, map_forward, dists_backward, map_backward = tf_nndistance.nn_distance(plane_gt, plane_pred)\n            forward_map = tf.one_hot(map_forward, depth=numOutputPlanes, axis=-1)\n            \n            if suffix == \'confidence\':\n                valid_forward_map = forward_map * tf.expand_dims(validPlaneMask, -1)\n                plane_confidence_gt = tf.transpose(tf.reduce_max(valid_forward_map, axis=1, keep_dims=True), [0, 2, 1])\n                plane_confidence_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=plane_confidence_pred, labels=plane_confidence_gt)) * 1000\n                #plane_confidence_loss = tf.reduce_mean(tf.squared_difference(plane_confidence_pred, plane_confidence_gt)) * 1000\n                #plane_confidence_loss = tf.reduce_mean(tf.squared_difference(plane_pred * plane_confidence_gt))) * 1000\n                dists = plane_confidence_gt\n            else:\n                plane_confidence_loss = tf.constant(0.0)\n                plane_confidence_gt = tf.ones(plane_confidence_pred.shape)\n                pass\n\n\n            dists_forward *= validPlaneMask        \n            dists_forward = tf.reduce_mean(dists_forward)\n            dists_backward = tf.reduce_mean(dists_backward)\n            plane_loss = (dists_forward + dists_backward / 2.0 * useBackward) * 10000\n\n\n            #plane_map = tf.one_hot(map_forward, depth=numOutputPlanes, axis=-1)\n            #shuffled_planes = tf.transpose(tf.matmul(plane_pred, plane_map, transpose_a=True, transpose_b=True), [0, 2, 1])\n\n            #dists = tf.concat([plane_gt, plane_pred, tf.expand_dims(dists_forward, -1), tf.expand_dims(dists_backward, -1), tf.expand_dims(tf.cast(map_forward, tf.float32), -1), tf.expand_dims(tf.cast(map_backward, tf.float32), -1)], axis=2)\n            dists = tf.expand_dims(dists_forward, -1)\n            \n            if \'regression\' in suffix:\n                plane_mask = tf.reduce_max(segmentation_gt, axis=3, keep_dims=True)\n            \n                segmentation_map = tf.one_hot(map_forward, depth=numOutputPlanes, axis=-1)\n                segmentation_gt_shuffled = tf.reshape(tf.matmul(tf.reshape(segmentation_gt, [-1, HEIGHT * WIDTH, numOutputPlanes]), segmentation_map), [-1, HEIGHT, WIDTH, numOutputPlanes])\n                segmentation_gt_shuffled = tf.cast(segmentation_gt_shuffled > 0.5, tf.float32)\n                segmentation_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=segmentation_pred, labels=segmentation_gt_shuffled)) * 1000\n            else:\n                segmentation_gt_shuffled = tf.reshape(tf.matmul(tf.reshape(segmentation_gt, [-1, HEIGHT * WIDTH, numOutputPlanes]), forward_map), [-1, HEIGHT, WIDTH, numOutputPlanes])\n                #segmentation_gt_shuffled = tf.cast(segmentation_gt_shuffled > 0.5, tf.float32)\n                segmentation_gt_shuffled = tf.concat([segmentation_gt_shuffled, 1 - plane_mask], axis=3)\n                all_segmentations = tf.concat([segmentation_pred, non_plane_mask_pred], axis=3)\n                segmentation_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=all_segmentations, labels=segmentation_gt_shuffled)) * 1000\n                pass\n          \n            pass\n        \n        segmentation_test = segmentation_gt_shuffled\n        \n\n        errorMask = tf.zeros(depth_gt.shape)\n\n        plane_parameters = tf.reshape(plane_pred, (-1, 3))\n        plane_depths = planeDepthsModule(plane_parameters, WIDTH, HEIGHT)\n        plane_depths = tf.transpose(tf.reshape(plane_depths, [HEIGHT, WIDTH, -1, numOutputPlanes]), [2, 0, 1, 3])\n\n        all_segmentations_softmax = tf.nn.softmax(all_segmentations)\n        all_depths = tf.concat([plane_depths, non_plane_depth_pred], axis=3)\n        depth_loss = tf.reduce_mean(tf.reduce_sum(tf.squared_difference(all_depths, depth_gt) * all_segmentations_softmax, axis=3, keep_dims=True) * tf.cast(tf.greater(depth_gt, 1e-4), tf.float32)) * 1000\n        #depth_loss = tf.reduce_mean(tf.reduce_sum(tf.squared_difference(plane_depths, depth_gt) * segmentation, axis=3, keep_dims=True) * plane_mask) * 1000\n\n\n        #plane_normals = planeNormalsModule(plane_parameters, WIDTH, HEIGHT)\n        #plane_normals = tf.reshape(plane_normals, [-1, 1, 1, numOutputPlanes, 3])\n        #normal_pred = tf.reduce_sum(tf.multiply(plane_normals, tf.expand_dims(segmentation, -1)), axis=3)\n            \n        #normal_loss = tf.reduce_mean(tf.reduce_mean(tf.squared_difference(plane_normals, tf.expand_dims(normal_gt, 3)) * tf.expand_dims(segmentation, -1), axis=3) * plane_mask) * 1000\n        normal_loss = tf.reduce_mean(tf.squared_difference(non_plane_normal_pred, normal_gt) * (1 - plane_mask)) * 1000\n        \n    \n        #s_8_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=s_8_pred, labels=s_8_gt)) * 1000\n        grid_s_loss = tf.reduce_mean(tf.losses.sigmoid_cross_entropy(logits=grid_s_pred, multi_class_labels=grid_s_gt, weights=tf.maximum(grid_s_gt * 10, 1))) * 1000\n        grid_p_loss = tf.reduce_mean(tf.squared_difference(grid_p_pred, grid_p_gt) * grid_s_gt) * 10000\n        grid_m_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=grid_m_pred, labels=grid_m_gt) * grid_s_gt) * 10000\n\n        if suffix == \'boundary\':\n            boundary_gt = tf.cond(validating_inp, lambda: boundary_gt_val, lambda: boundary_gt_train)\n            boundary_loss = tf.reduce_mean(tf.losses.sigmoid_cross_entropy(logits=boundary_pred, multi_class_labels=boundary_gt, weights=tf.maximum(boundary_gt * 5, 1))) * 1000\n        else:\n            if True:\n                kernel_size = 3\n                padding = (kernel_size - 1) / 2\n                neighbor_kernel_array = gaussian(kernel_size, kernel_size)\n                neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n                neighbor_kernel_array /= neighbor_kernel_array.sum()\n                neighbor_kernel_array *= -1\n                neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 1\n                neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n                neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n        \n                depth_diff = tf.abs(tf.nn.depthwise_conv2d(depth_gt, neighbor_kernel, strides=[1, 1, 1, 1], padding=\'VALID\'))\n                depth_diff = tf.pad(depth_diff, paddings = [[0, 0], [padding, padding], [padding, padding], [0, 0]])\n                max_depth_diff = 0.1\n                depth_boundary = tf.greater(depth_diff, max_depth_diff)\n\n                normal_diff = tf.norm(tf.nn.depthwise_conv2d(normal_gt, tf.tile(neighbor_kernel, [1, 1, 3, 1]), strides=[1, 1, 1, 1], padding=\'VALID\'), axis=3, keep_dims=True)\n                normal_diff = tf.pad(normal_diff, paddings = [[0, 0], [padding, padding], [padding, padding], [0, 0]])\n                max_normal_diff = np.sqrt(2 * (1 - np.cos(np.deg2rad(20))))\n                normal_boundary = tf.greater(normal_diff, max_normal_diff)\n\n                #kernel_size = 7\n                #segmentation_dilated = tf.nn.max_pool(segmentation_gt, ksize=[1, kernel_size, kernel_size, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n                #segmentation_eroded = 1 - tf.nn.max_pool(1 - segmentation_gt, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n                #overlap_region = tf.greater_equal(tf.reduce_sum(segmentation_dilated - segmentation_eroded, axis=3, keep_dims=True), 2)\n                plane_region = tf.nn.max_pool(plane_mask, ksize=[1, kernel_size, kernel_size, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n                segmentation_eroded = 1 - tf.nn.max_pool(1 - segmentation_gt, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n                plane_region -= tf.reduce_max(segmentation_eroded, axis=3, keep_dims=True)\n                boundary = tf.cast(tf.logical_or(depth_boundary, normal_boundary), tf.float32) * plane_region\n                smooth_boundary = tf.cast(tf.logical_and(normal_boundary, tf.less_equal(depth_diff, max_depth_diff)), tf.float32) * plane_region\n                boundary_gt = tf.concat([smooth_boundary, boundary - smooth_boundary], axis=3)\n            else:\n                segmentation_dilated = tf.nn.max_pool(segmentation_gt, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n                #segmentation_eroded = 1 - tf.nn.max_pool(1 - segmentation_gt, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n                boundary = tf.reduce_max(segmentation_dilated - segmentation_gt, axis=3, keep_dims=True)\n                max_depth_diff = 0.1\n                kernel_size = 5\n                padding = (kernel_size - 1) / 2\n                neighbor_kernel_array = gaussian(kernel_size, kernel_size)\n                neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n                neighbor_kernel_array /= neighbor_kernel_array.sum()\n                neighbor_kernel_array *= -1\n                neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 1\n                neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n                neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n        \n                depth_diff = tf.abs(tf.nn.depthwise_conv2d(depth_gt, neighbor_kernel, strides=[1, 1, 1, 1], padding=\'VALID\'))\n                depth_diff = tf.pad(depth_diff, paddings = [[0, 0], [padding, padding], [padding, padding], [0, 0]])\n\n                smooth_boundary = boundary * tf.cast(tf.less(depth_diff, max_depth_diff), tf.float32)\n                # occlusion_boundary = boundary - smooth_boundary\n                # boundary = tf.squeeze(tf.concat([smooth_boundary, occlusion_boundary], axis=3), axis=0)\n                boundary_gt = tf.concat([smooth_boundary, boundary - smooth_boundary], axis=3) * plane_mask\n                pass\n\n            \n            all_segmentations_one_hot = all_segmentations_softmax\n                          \n            all_segmentations_min = 1 - tf.nn.max_pool(1 - all_segmentations_one_hot, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\')\n            segmentation_diff = tf.reduce_max(all_segmentations_softmax - all_segmentations_min, axis=3, keep_dims=True)\n            #occlusion_boundary = tf.slice(boundary_gt, [0, 0, 0, 1], [int(boundary_gt.shape[0]), HEIGHT, WIDTH, 1])\n            \n            #boundary = tf.reduce_sum(boundary_gt, axis=3, keep_dims=True)\n            #smooth_boundary = tf.slice(boundary_gt, [0, 0, 0, 0], [int(boundary_gt.shape[0]), HEIGHT, WIDTH, 1])\n            \n            #occlusion_boundary = occlusion_boundary * 2 - 1\n            #segmentation_diff = segmentation_diff * 2 - 1\n\n            depth_one_hot = tf.reduce_sum(tf.multiply(all_depths, all_segmentations_one_hot), axis=3, keep_dims=True)\n            depth_neighbor = tf.nn.depthwise_conv2d(depth_one_hot, neighbor_kernel, strides=[1, 1, 1, 1], padding=\'SAME\')\n            #depth_neighbor = tf.pad(depth_neighbor, paddings = [[0, 0], [padding, padding], [padding, padding], [0, 0]])\n            #maxDepthDiff = 0.1\n            minDepthDiff = 0.02\n            depth_diff = tf.clip_by_value(tf.squared_difference(depth_one_hot, depth_neighbor) - pow(minDepthDiff, 2), 0, 1)\n            \n            smooth_mask = segmentation_diff + boundary - 2 * segmentation_diff * boundary + depth_diff * smooth_boundary\n            margin = 0.0\n            smooth_mask = tf.nn.relu(smooth_mask - margin)\n            errorMask = smooth_mask\n            #errorMask = segmentation_diff\n            \n            boundary_loss = tf.reduce_mean(smooth_mask * plane_mask) * 1000\n            \n            #if suffix == \'boundary_pred\':\n            boundary_loss += tf.reduce_mean(tf.losses.sigmoid_cross_entropy(logits=boundary_pred, multi_class_labels=boundary_gt, weights=tf.maximum(boundary_gt * 3, 1))) * 1000\n            pass\n\n\n        if \'diverse\' in suffix:\n            plane_diff = tf.reduce_sum(tf.pow(tf.expand_dims(plane_pred, 1) - tf.expand_dims(plane_pred, 2), 2), axis=3)\n            plane_diff = tf.matrix_set_diag(plane_diff, tf.ones((int(plane_diff.shape[0]), numOutputPlanes)))\n            minPlaneDiff = 0.1\n            diverse_loss = tf.reduce_mean(tf.clip_by_value(1 - plane_diff / minPlaneDiff, 0, 1)) * 10000\n        else:\n            diverse_loss = tf.constant(0.0)\n            pass          \n\n\n        l2_losses = tf.add_n([5e-4 * tf.nn.l2_loss(v) for v in tf.trainable_variables() if \'weights\' in v.name])\n        #loss = plane_loss + segmentation_loss + depth_loss + normal_loss + l2_losses\n        loss = plane_loss + segmentation_loss + depth_loss + normal_loss + l2_losses + grid_s_loss + grid_p_loss + grid_m_loss + boundary_loss + plane_confidence_loss + diverse_loss + deep_supervision_loss\n        #loss = plane_loss + segmentation_loss + depth_loss + normal_loss + l2_losses\n      \n        if suffix == \'pixelwise\':\n            normal_loss = tf.reduce_mean(tf.squared_difference(non_plane_normal_pred, normal_gt)) * 1000\n            depth_loss = tf.reduce_mean(tf.squared_difference(non_plane_depth_pred, depth_gt) * tf.cast(tf.greater(depth_gt, 1e-4), tf.float32)) * 1000\n            loss = normal_loss + depth_loss\n            pass\n        \n    return loss, plane_loss, segmentation_loss + depth_loss + normal_loss + grid_s_loss + grid_p_loss + grid_m_loss + boundary_loss, deep_supervision_loss, diverse_loss + plane_confidence_loss, segmentation_test, boundary_gt, plane_mask, errorMask, dists\n    #return loss, plane_loss, depth_loss + grid_s_loss + grid_p_loss + grid_m_loss + boundary_loss, forward_loss, backward_loss, segmentation_gt, plane_mask, errorMask, dists\n    #return loss, plane_loss, segmentation_loss, loss_p_0, depth_loss, segmentation_test, plane_mask, errorMask, dists\n\n\ndef main(gpu_id, dumpdir, logdir, testdir, keyname, restore, numOutputPlanes=20, useCRF=0, batchSize=16, suffix=\'forward\'):\n    if not os.path.exists(dumpdir):\n        os.system(""mkdir -p %s""%dumpdir)\n        pass\n    if not os.path.exists(testdir):\n        os.system(""mkdir -p %s""%testdir)\n        pass\n    \n    min_after_dequeue = 1000\n\n    if False:\n        reader_train = RecordReaderAll()\n        filename_queue_train = tf.train.string_input_producer([\'../planes_all_100000.tfrecords\'], num_epochs=10000)    \n        img_inp_train, plane_gt_train, depth_gt_train, normal_gt_train, num_planes_gt_train, _ = reader_train.getBatch(filename_queue_train, numOutputPlanes=numOutputPlanes, batchSize=batchSize, min_after_dequeue=min_after_dequeue)\n        segmentation_gt_train = tf.ones((batchSize, HEIGHT, WIDTH, numOutputPlanes))\n\n        reader_val = RecordReaderAll()\n        filename_queue_val = tf.train.string_input_producer([\'../planes_all_1000_100000.tfrecords\'], num_epochs=10000)    \n        img_inp_val, plane_gt_val, depth_gt_val, normal_gt_val, num_planes_gt_val, _ = reader_val.getBatch(filename_queue_val, numOutputPlanes=numOutputPlanes, batchSize=batchSize, min_after_dequeue=min_after_dequeue)\n        segmentation_gt_val = tf.ones((batchSize, HEIGHT, WIDTH, numOutputPlanes))\n    elif True:\n        reader_train = RecordReader()\n        filename_queue_train = tf.train.string_input_producer([\'/mnt/vision/SUNCG_plane/planes_test_450000.tfrecords\'], num_epochs=10000)\n        img_inp_train, plane_gt_train, depth_gt_train, normal_gt_train, segmentation_gt_train, boundary_gt_train, grid_s_gt_train, grid_p_gt_train, grid_m_gt_train, num_planes_gt_train = reader_train.getBatch(filename_queue_train, numOutputPlanes=numOutputPlanes, batchSize=batchSize, min_after_dequeue=min_after_dequeue, getLocal=True, test=False, suffix=suffix, random=False)\n\n        reader_val = RecordReader()\n        filename_queue_val = tf.train.string_input_producer([\'/mnt/vision/SUNCG_plane/planes_test_1000_450000.tfrecords\'], num_epochs=10000)\n        img_inp_val, plane_gt_val, depth_gt_val, normal_gt_val, segmentation_gt_val, boundary_gt_val, grid_s_gt_val, grid_p_gt_val, grid_m_gt_val, num_planes_gt_val = reader_val.getBatch(filename_queue_val, numOutputPlanes=numOutputPlanes, batchSize=batchSize, min_after_dequeue=min_after_dequeue, getLocal=True, suffix=suffix)\n    else:\n        reader_rgbd_train = RecordReaderRGBD()\n        filename_queue_rgbd_train = tf.train.string_input_producer([\'../planes_nyu_rgbd_train.tfrecords\'], num_epochs=10000)\n        img_inp_rgbd_train, global_gt_dict_rgbd_train, local_gt_dict_rgbd_train = reader_rgbd_train.getBatch(filename_queue_rgbd_train, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue)\n        #img_inp, global_gt_dict, local_gt_dict = reader.getBatch(filename_queue, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True, random=False)\n    \n        reader_rgbd_val = RecordReaderRGBD()\n        filename_queue_rgbd_val = tf.train.string_input_producer([\'../planes_nyu_rgbd_val.tfrecords\'], num_epochs=10000)\n        img_inp_rgbd_val, global_gt_dict_rgbd_val, local_gt_dict_rgbd_val = reader_rgbd_val.getBatch(filename_queue_rgbd_val, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue)\n        pass\n    \n    \n    validating_inp = tf.placeholder(tf.bool, shape=[], name=\'validating_inp\')\n    plane_pred, plane_confidence_pred, depth_pred, normal_pred, segmentation_pred, non_plane_mask_pred, non_plane_depth_pred, non_plane_normal_pred, boundary_pred, grid_s_pred, grid_p_pred, grid_m_pred, plane_preds, segmentation_preds, _ = build_graph(img_inp_train, img_inp_val, plane_gt_train, plane_gt_val, validating_inp, numOutputPlanes=numOutputPlanes, useCRF=useCRF, suffix=suffix)\n\n    #var_to_restore = [v for v in tf.global_variables() if \'planes\' not in v.name and \'segmentation\' not in v.name and \'moving_\' not in v.name and \'connection\' not in v.name]\n    var_to_restore = [v for v in tf.global_variables()]\n    #for op in tf.get_default_graph().get_operations():\n    #print str(op)\n    #continue\n\n    loss, plane_loss, depth_loss, normal_loss, segmentation_loss, segmentation_gt, boundary_gt, plane_mask_gt, _, plane_confidence_gt = build_loss(plane_pred, plane_confidence_pred, depth_pred, normal_pred, segmentation_pred, non_plane_mask_pred, non_plane_depth_pred, non_plane_normal_pred, boundary_pred, grid_s_pred, grid_p_pred, grid_m_pred, plane_preds, segmentation_preds, plane_gt_train, depth_gt_train, normal_gt_train, segmentation_gt_train, boundary_gt_train, grid_s_gt_train, grid_p_gt_train, grid_m_gt_train, num_planes_gt_train, plane_gt_val, depth_gt_val, normal_gt_val, segmentation_gt_val, boundary_gt_val, grid_s_gt_val, grid_p_gt_val, grid_m_gt_val, num_planes_gt_val, validating_inp, numOutputPlanes = numOutputPlanes, gpu_id = gpu_id, useCRF=useCRF, suffix=suffix)\n\n    train_writer = tf.summary.FileWriter(logdir + \'/train\', graph=tf.get_default_graph())\n    val_writer = tf.summary.FileWriter(logdir + \'/val\')\n    tf.summary.scalar(\'loss\', loss)\n    tf.summary.scalar(\'plane_loss\', plane_loss)\n    #tf.summary.scalar(\'depth_loss\', depth_loss)\n    #tf.summary.scalar(\'normal_loss\', normal_loss)\n    tf.summary.scalar(\'segmentation_loss\', segmentation_loss)    \n    summary_op = tf.summary.merge_all()\n\n    with tf.variable_scope(\'statistics\'):\n        batchno = tf.Variable(0, dtype=tf.int32, trainable=False, name=\'batchno\')\n        batchnoinc=batchno.assign(batchno+1)\n        pass\n\n    #update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n    #update_ops = tf.get_collection(UPDATE_OPS_COLLECTION)\n    #with tf.control_dependencies(update_ops):\n    optimizer = tf.train.AdamOptimizer(3e-5*BATCH_SIZE/FETCH_BATCH_SIZE)\n    train_op = optimizer.minimize(loss, global_step=batchno)\n    #var_to_train = [v for v in var_to_restore if \'plane\' in v.name or \'res5d\' in v.name]\n    #train_op = optimizer.minimize(loss, global_step=batchno, var_list=var_to_train)\n    \n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n    saver=tf.train.Saver()\n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n        if restore == 1:\n            loader = tf.train.Saver(var_to_restore)\n            loader.restore(sess,""%s/%s.ckpt""%(dumpdir, keyname))\n            bno=sess.run(batchno)\n            print(bno)\n        elif restore == 0:\n            var_to_restore = [v for v in var_to_restore if \'res5d\' not in v.name and \'segmentation\' not in v.name and \'plane\' not in v.name and \'depth\' not in v.name and \'normal\' not in v.name]\n            resnet_loader = tf.train.Saver(var_to_restore)\n            resnet_loader.restore(sess,""../pretrained_models/deeplab_resnet.ckpt"")\n        elif restore == 2:\n            var_to_restore = [v for v in tf.global_variables() if \'non_plane\' not in v.name]\n            resnet_loader = tf.train.Saver(var_to_restore)\n            resnet_loader.restore(sess,""dump_supervision_deeplab_forward/train_supervision_deeplab_forward.ckpt"")\n            sess.run(batchno.assign(0))\n        elif restore == 3:\n            #var_to_restore = [v for v in tf.global_variables() if \'deep_supervision/res4b22_relu_segmentation_conv2\' not in v.name]\n            #var_to_restore = [v for v in tf.global_variables() if \'empty_mask\' not in v.name]\n            var_to_restore = [v for v in tf.global_variables() if \'plane_confidence\' not in v.name]\n            #var_to_restore = [v for v in tf.global_variables() if \'boundary\' not in v.name]\n            original_saver = tf.train.Saver(var_to_restore)\n            original_saver.restore(sess,""dump_planenet_deep/train_planenet_deep.ckpt"")\n            #original_saver.restore(sess,""%s/%s.ckpt""%(dumpdir, keyname))\n            sess.run(batchno.assign(1))\n            pass\n        elif restore == 4:\n            var_to_restore_1 = [v for v in var_to_restore if \'deep_supervision\' not in v.name]\n            resnet_loader = tf.train.Saver(var_to_restore_1)\n            resnet_loader.restore(sess,""dump_grid_deeplab_degridding/train_grid_deeplab_degridding.ckpt"")\n            sess.run(batchno.assign(1))\n        elif restore == 5:\n            #saver.restore(sess,""dump_all_resnet_v2/train_all_resnet_v2.ckpt"")\n            #var_to_restore = [v for v in var_to_restore if \'plane\' not in v.name and \'segmentation\' not in v.name]\n            var_to_restore = [v for v in var_to_restore]\n            loader = tf.train.Saver(var_to_restore)\n            loader.restore(sess,""%s/%s.ckpt""%(dumpdir, keyname))\n            sess.run(batchno.assign(1))\n            pass\n        # Start input enqueue threads.\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n        \n        ema = [0., 0.]\n        ema_acc = [1e-10, 1e-10]\n        last_snapshot_time = time.time()\n        bno=sess.run(batchno)\n        #fetchworker.bno=bno//(FETCH_BATCH_SIZE/BATCH_SIZE)\n        #fetchworker.start()\n        try:\n            while bno<300000:\n                t0=time.time()\n                #_, total_loss, train_loss, val_loss, summary_str, pred, gt, images, planes = sess.run([train_op, loss, training_loss, validation_loss, summary_op, segmentation_pred, segmentation_gt, img_inp, plane_inp])\n                if bno % 100 > 0:\n                    _, total_loss, loss_1, loss_2, loss_3, loss_4, summary_str = sess.run([train_op, loss, plane_loss, depth_loss, normal_loss, segmentation_loss, summary_op], feed_dict = {validating_inp:False})\n\n                    #print(pred[0])\n                    #print(gt[0])\n                    #exit(1)\n                    \n                    # print(pred_map[0])\n                    # print(pred_p[0])\n                    # print(gt_p[0])\n                    # print(num_planes[0])\n                    # exit(1)\n                    # print(pred_d.max())\n                    # print(pred_d.min())\n                    # print(gt_d.max())\n                    # print(gt_d.min())\n                    # exit(1)\n                    train_writer.add_summary(summary_str, bno)\n                    ema[0] = ema[0] * MOVING_AVERAGE_DECAY + total_loss\n                    #ema[0] = ema[0] * MOVING_AVERAGE_DECAY + (loss_1 + loss_2 + loss_3 + loss_4)\n                    ema_acc[0] = ema_acc[0] * MOVING_AVERAGE_DECAY + 1\n                else:\n                    _, total_loss, loss_1, loss_2, loss_3, loss_4, summary_str = sess.run([batchnoinc, loss, plane_loss, depth_loss, normal_loss, segmentation_loss, summary_op], feed_dict = {validating_inp:True})\n                    val_writer.add_summary(summary_str, bno)\n                    ema[1] = ema[1] * MOVING_AVERAGE_DECAY + total_loss\n                    #ema[1] = ema[1] * MOVING_AVERAGE_DECAY + (loss_1 + loss_2 + loss_3 + loss_4)\n                    ema_acc[1] = ema_acc[1] * MOVING_AVERAGE_DECAY + 1\n                    pass\n                #loss_3 = 0\n                \n\n                #images, planes, segmentation, normal, depth, num_planes, mask = sess.run([img_inp_train, plane_gt_train, segmentation_gt_train, normal_gt_train, depth_gt_train, num_planes_train, mask_train], feed_dict = {validating_inp:False})\n                # images, planes, segmentation, normal, depth, num_planes = sess.run([img_inp_val, plane_gt_val, segmentation_gt_val, normal_gt_val, depth_gt_val, num_planes_gt_val], feed_dict = {validating_inp:False})\n\n                # cv2.imwrite(testdir + \'/segmentation_image.png\', ((images[0] + 0.5) * 255).astype(np.uint8))\n                # cv2.imwrite(testdir + \'/segmentation_normal.png\', np.minimum(np.maximum((normal[0] + 1) / 2 * 255, 0), 255).astype(np.uint8))\n                # cv2.imwrite(testdir + \'/segmentation_depth.png\', np.minimum(np.maximum(depth[0, :, :, 0] / 10 * 255, 0), 255).astype(np.uint8))\n                # print(planes[0])\n                # exit(1)\n                #cv2.imwrite(testdir + \'/segmentation_background.png\', (mask[0] == 0).astype(np.uint8) * 255)\n                #unique_values = np.unique(mask[0].reshape([-1]))\n                #print(unique_values)\n                #for value in unique_values:\n                #cv2.imwrite(testdir + \'/segmentation_mask_\' + str(value) + \'.png\', ((mask[0] == value) * 255).astype(np.uint8))\n                #continue                  \n                # for planeIndex in xrange(numOutputPlanes):\n                #     print((planeIndex, planes[0, planeIndex]))\n                #     cv2.imwrite(testdir + \'/segmentation_\' + str(planeIndex) + \'_segmentation.png\', (segmentation[0, :, :, planeIndex] * 255).astype(np.uint8))\n                #     continue\n                # exit(1)\n\n                bno=sess.run(batchno)\n                if time.time()-last_snapshot_time > 200:\n                    print(\'save snapshot\')\n                    saver.save(sess,\'%s/\'%dumpdir+keyname+"".ckpt"")\n                    last_snapshot_time = time.time()\n                    pass\n        \n                print bno,\'train\', ema[0] / ema_acc[0], \'val\', ema[1] / ema_acc[1], \'loss\', total_loss, loss_1, loss_2, loss_3, loss_4, \'time\', time.time()-t0\n                continue\n\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n            saver.save(sess,\'%s/\'%dumpdir+keyname+"".ckpt"")\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n        \n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return\n\n\ndef test(gpu_id, dumpdir, logdir, testdir, keyname, restore, numOutputPlanes=20, useCRF=0, suffix=\'forward\'):\n    if not os.path.exists(testdir):\n        os.system(""mkdir -p %s""%testdir)\n        pass\n\n\n    # reader_train = RecordReader()\n    # filename_queue_train = tf.train.string_input_producer([\'../planes_all_1000_450000.tfrecords\'], num_epochs=1)\n    # img_inp, depth_gt, normal_gt, invalid_mask_gt, image_path_inp = reader_train.getBatch(filename_queue_train, numOutputPlanes=numOutputPlanes, batchSize=1, random=False)\n\n    # init_op = tf.group(tf.global_variables_initializer(),\n    #                    tf.local_variables_initializer())\n\n    # with tf.Session() as sess:\n    #     sess.run(init_op)\n \n    #     coord = tf.train.Coordinator()\n    #     threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n        \n    #     try:\n    #         for index in xrange(50):\n    #             print((\'image\', index))\n    #             t0=time.time()\n\n    #             depth, invalid_mask = sess.run([depth_gt, invalid_mask_gt])\n    #             depth = depth.squeeze()\n    #             invalid_mask = invalid_mask.squeeze()\n\n\n    #             if index < 10:\n    #                 continue\n    #             #print(depth[51][12])\n    #             #print(depth[51][100])\n    #             #print(depth[84][22])\n    #             cv2.imwrite(testdir + \'/\' + str(index) + \'_depth.png\', drawDepthImage(depth))\n    #             cv2.imwrite(testdir + \'/\' + str(index) + \'_invalid_mask.png\', drawMaskImage(invalid_mask))\n    #             continue\n        \n    #     except tf.errors.OutOfRangeError:\n    #         print(\'Done training -- epoch limit reached\')\n    #     finally:\n    #         # When done, ask the threads to stop.\n    #         coord.request_stop()\n    #         pass\n          \n    #     # Wait for threads to finish.\n    #     coord.join(threads)\n    #     sess.close()\n    #     pass\n    # exit(1)\n    \n    batchSize = 1\n    \n    min_after_dequeue = 1000\n\n    reader_val = RecordReader()\n    filename_queue_val = tf.train.string_input_producer([\'/mnt/vision/SUNCG_plane/planes_test_1000_450000.tfrecords\'], num_epochs=10000)\n    img_inp, plane_gt, depth_gt, normal_gt, segmentation_gt_original, boundary_gt, grid_s_gt, grid_p_gt, grid_m_gt, num_planes_gt = reader_val.getBatch(filename_queue_val, numOutputPlanes=numOutputPlanes, batchSize=batchSize, min_after_dequeue=min_after_dequeue, random=False, getLocal=True, getSegmentation=False, suffix=suffix)\n    #img_inp, plane_gt, depth_gt, normal_gt, segmentation_gt, boundary_gt, s_8_gt = reader_val.getBatch(filename_queue_val, numOutputPlanes=numOutputPlanes, batchSize=batchSize, min_after_dequeue=min_after_dequeue, random=False, getLocal=True)\n\n    validating_inp = tf.placeholder(tf.bool, shape=[], name=\'validating_inp\')\n\n    plane_pred, plane_confidence_pred, depth_pred, normal_pred, segmentation_pred, non_plane_mask_pred, non_plane_depth_pred, non_plane_normal_pred, boundary_pred, grid_s_pred, grid_p_pred, grid_m_pred, plane_preds, segmentation_preds, refined_segmentation = build_graph(img_inp, img_inp, plane_gt, plane_gt, validating_inp, numOutputPlanes=numOutputPlanes, useCRF=useCRF, is_training=False, suffix=suffix)\n\n    var_to_restore = tf.global_variables()\n    \n    loss, plane_loss, depth_loss, normal_loss, segmentation_loss, segmentation_gt, boundary_gt, plane_mask_gt, error_mask, dists = build_loss(plane_pred, plane_confidence_pred, depth_pred, normal_pred, segmentation_pred, non_plane_mask_pred, non_plane_depth_pred, non_plane_normal_pred, boundary_pred, grid_s_pred, grid_p_pred, grid_m_pred, plane_preds, segmentation_preds, plane_gt, depth_gt, normal_gt, segmentation_gt_original, boundary_gt, grid_s_gt, grid_p_gt, grid_m_gt, num_planes_gt, plane_gt, depth_gt, normal_gt, segmentation_gt_original, boundary_gt, grid_s_gt, grid_p_gt, grid_m_gt, num_planes_gt, validating_inp, numOutputPlanes=numOutputPlanes, gpu_id=gpu_id, useCRF=useCRF, suffix=suffix)\n        \n\n    errorSum = np.zeros(4)\n    \n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n    \n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n        loader = tf.train.Saver(var_to_restore)\n        loader.restore(sess,""%s/%s.ckpt""%(dumpdir, keyname))\n        \n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n        \n        randomColor = np.random.randint(255, size=(50 + 1, 3)).astype(np.uint8)\n        randomColor[0] = 0\n        \n        try:\n            gtDepths = []\n            predDepths = []\n            planeMasks = []\n            #predMasks = []\n            \n            imageWidth = WIDTH\n            imageHeight = HEIGHT\n            focalLength = 517.97\n            urange = np.arange(imageWidth).reshape(1, -1).repeat(imageHeight, 0) - imageWidth * 0.5\n            vrange = np.arange(imageHeight).reshape(-1, 1).repeat(imageWidth, 1) - imageHeight * 0.5\n            ranges = np.array([urange / imageWidth * 640 / focalLength, np.ones(urange.shape), -vrange / imageHeight * 480 / focalLength]).transpose([1, 2, 0])\n\n\n            for index in xrange(10):\n                print((\'image\', index))\n                t0=time.time()\n                #im, planes, depth, normal, boundary, s_8, p_8, b_8, s_16, p_16, b_16, s_32, p_32, b_32 = sess.run([img_inp, plane_gt, depth_gt, normal_gt, boundary_gt, s_8_gt, p_8_gt, b_8_gt, s_16_gt, p_16_gt, b_16_gt, s_32_gt, p_32_gt, b_32_gt])\n\n\n                pred_p, pred_p_c, pred_d, pred_n, pred_s, loss_p, loss_d, loss_n, loss_s, im, gt_p, gt_d, gt_n, pred_np_m, pred_np_d, pred_np_n, gt_s, gt_plane_mask, pred_boundary, grid_s, grid_p, grid_m, gt_grid_s, gt_grid_m, refined_s, mask_e, preds_p, preds_s, distance, numPlanes, gt_s_ori, gt_boundary = sess.run([plane_pred, plane_confidence_pred, depth_pred, normal_pred, segmentation_pred, plane_loss, depth_loss, normal_loss, segmentation_loss, img_inp, plane_gt, depth_gt, normal_gt, non_plane_mask_pred, non_plane_depth_pred, non_plane_normal_pred, segmentation_gt, plane_mask_gt, boundary_pred, grid_s_pred, grid_p_pred, grid_m_pred, grid_s_gt, grid_m_gt, refined_segmentation, error_mask, plane_preds, segmentation_preds, dists, num_planes_gt, segmentation_gt_original, boundary_gt], feed_dict = {validating_inp:True})\n\n                #if index != 8:\n                #continue\n                \n                im = im[0]\n                image = ((im + 0.5) * 255).astype(np.uint8)\n\n                planes = gt_p[0]                \n                gt_d = gt_d.squeeze()\n                gt_n = gt_n[0]\n                #grid_s = [s_8, s_16, s_32]\n                #grid_p = [p_8, p_16, p_32]\n                #grid_b = [b_8, b_16, b_32]\n\n                # if index < 5:\n                #     continue                \n                # print(depth[51][12])\n                # print(depth[51][100])\n                # print(depth[84][22])\n                # cv2.imwrite(testdir + \'/depth.png\', drawDepthImage(depth))\n                # exit(1)\n                \n                grid_s = 1 / (1 + np.exp(-grid_s))\n                grid_s = grid_s[0]\n                grid_p = grid_p[0]\n                grid_m = grid_m[0]\n                gt_grid_s = gt_grid_s[0]\n                gt_grid_m = gt_grid_m[0]                \n                #grid_s = gt_grid_s\n                #grid_m = gt_grid_m                \n\n                \n                gt_s = gt_s[0]\n                pred_p = pred_p[0]\n                pred_d = pred_d.squeeze()\n                pred_n = pred_n[0]\n                pred_s = pred_s[0]\n                refined_s = refined_s[0]\n\n                pred_np_m = pred_np_m[0]\n                pred_np_d = pred_np_d[0]\n                pred_np_n = pred_np_n[0]\n\n                pred_p_c = pred_p_c[0]\n \n\n                if False:\n                    if index >= 10:\n                        break\n                    np.save(dumpdir + \'/planes_\' + str(index) + \'.npy\', pred_p)\n                    np.save(dumpdir + \'/segmentations_\' + str(index) + \'.npy\', pred_s)\n                    np.save(dumpdir + \'/segmentations_gt_\' + str(index) + \'.npy\', gt_s)\n                    np.save(dumpdir + \'/non_plane_depth_\' + str(index) + \'.npy\', pred_np_d)\n                    np.save(dumpdir + \'/non_plane_segmentation_\' + str(index) + \'.npy\', pred_np_m)\n                    boundary = pred_boundary[0]\n                    boundary = 1 / (1 + np.exp(-boundary))\n                    boundary = np.concatenate([boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)                    \n                    cv2.imwrite(dumpdir + \'/boundary_\' + str(index) + \'.png\', drawMaskImage(boundary))\n                    cv2.imwrite(dumpdir + \'/image_\' + str(index) + \'.png\', cv2.resize(image, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR))\n                    np.save(dumpdir + \'/depth_\' + str(index) + \'.npy\', gt_d)\n                    #continue\n\n                  \n                stride = 8\n                boxSize = 64\n                xs = np.arange(WIDTH / stride) * stride + stride / 2\n                ys = np.arange(HEIGHT / stride) * stride + stride / 2\n                padding = boxSize / 2 + 1\n                maskImage = np.zeros((HEIGHT + padding * 2, WIDTH + padding * 2, 3), dtype=np.uint8)\n                maskImage[padding:padding + HEIGHT, padding:padding + WIDTH, :] = image / 2\n                for gridY, y in enumerate(ys):\n                    for gridX, x in enumerate(xs):\n                        score = grid_s[gridY][gridX]\n                        if score < 0.5:\n                            continue                              \n                        mask = grid_m[gridY][gridX].reshape([16, 16])        \n                        mask = cv2.resize(mask, (boxSize, boxSize))\n                        maskImage[y - boxSize / 2 + padding:y + boxSize / 2 + padding, x - boxSize / 2 + padding:x + boxSize / 2 + padding, 0][mask > 0.5] = 255\n                        continue\n                    continue\n                for gridY, y in enumerate(ys):\n                    for gridX, x in enumerate(xs):\n                        score = gt_grid_s[gridY][gridX]\n                        if score < 0.5:\n                            continue                              \n                        mask = gt_grid_m[gridY][gridX].reshape([16, 16])        \n                        mask = cv2.resize(mask, (boxSize, boxSize))\n                        maskImage[y - boxSize / 2 + padding:y + boxSize / 2 + padding, x - boxSize / 2 + padding:x + boxSize / 2 + padding, 2][mask > 0.5] = 255\n                        continue\n                    continue\n\n                #print((grid_s > 0.5).astype(np.int8).sum())\n                #print(grid_s[gt_grid_s.astype(np.bool)])\n\n                \n                pred_p_c = 1 / (1 + np.exp(-pred_p_c))\n                print((loss_p, loss_d, loss_n, loss_s, numPlanes[0], (pred_p_c > 0.5).sum()))\n \n                errorSum += np.array([loss_p, loss_d, loss_n, loss_s])\n                #planeMask = np.max(gt_s, 2) > 0.5\n                planeMask = np.squeeze(gt_plane_mask)\n                \n                #predMasks.append(np.max(pred_s, 2) > 0.5)\n\n                #cv2.imwrite(testdir + \'/\' + str(index) + \'_image.png\', ((im + 0.5) * 255).astype(np.uint8))\n                #cv2.imwrite(testdir + \'/\' + str(index) + \'_depth_inp.png\', drawDepthImage(depth))\n                #cv2.imwrite(testdir + \'/\' + str(index) + \'_normal_inp.png\', drawNormalImage(normal))\n                \n                #cv2.imwrite(testdir + \'/\' + str(index) + \'_depth_gt.png\', drawDepthImage(gt_d))\n                #cv2.imwrite(testdir + \'/\' + str(index) + \'_depth_gt_diff.png\', drawDiffImage(gt_d, depth, 0.5))\n\n\n                if index >= 10:\n                    #cv2.imwrite(testdir + \'/\' + str(index) + \'_depth.png\', drawDepthImage(depth))\n                    continue\n\n\n\n                #segmentation = np.argmax(pred_s, 2)\n                #pred_d = plane_depths.reshape(-1, numOutputPlanes)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape(HEIGHT, WIDTH)\n\n\n                \n                #cv2.imwrite(testdir + \'/\' + str(index) + \'_error_mask.png\', drawMaskImage(np.clip(np.squeeze(mask_e) / 1, 0, 1)))\n                #exit(1)\n                cv2.imwrite(testdir + \'/\' + str(index) + \'_image.png\', image)\n                cv2.imwrite(testdir + \'/\' + str(index) + \'_depth.png\', drawDepthImage(gt_d))\n                cv2.imwrite(testdir + \'/\' + str(index) + \'_normal.png\', drawNormalImage(gt_n))\n\n                if suffix == \'boundary_pred\':\n                    pred_boundary = pred_boundary[0]\n                    pred_boundary = 1 / (1 + np.exp(-pred_boundary))\n                    boundary = np.concatenate([pred_boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)\n                    cv2.imwrite(testdir + \'/\' + str(index) + \'_boundary_pred.png\', drawMaskImage(boundary))\n                    pass\n                \n                gt_boundary = gt_boundary[0]\n                boundary = np.concatenate([gt_boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)                \n                cv2.imwrite(testdir + \'/\' + str(index) + \'_boundary_gt.png\', drawMaskImage(boundary))\n                                  \n                #cv2.imwrite(testdir + \'/\' + str(index) + \'_grid_mask.png\', maskImage)\n                \n\n                #cv2.imwrite(testdir + \'/\' + str(index) + \'_depth_pred_diff.png\', drawDiffImage(pred_d * planeMask, depth * planeMask, 0.5))\n\n                #cv2.imwrite(testdir + \'/\' + str(index) + \'_normal_gt.png\', drawNormalImage(gt_n))\n                #cv2.imwrite(testdir + \'/\' + str(index) + \'_normal_pred.png\', drawNormalImage(np.clip(pred_np_n, 0, 1)))\n                \n                #cv2.imwrite(testdir + \'/\' + str(index) + \'_segmentation_refined.png\', drawSegmentationImage(refined_s))\n                cv2.imwrite(testdir + \'/\' + str(index) + \'_segmentation_gt.png\', drawSegmentationImage(gt_s, planeMask=planeMask, numColors = 51))\n\n\n\n                segmentation_deep = np.argmax(preds_s[0][0], 2)\n                segmentation_deep[segmentation_deep == numOutputPlanes] = -1\n                segmentation_deep += 1\n                \n                plane_depths_deep = calcPlaneDepths(preds_p[0][0], WIDTH, HEIGHT)\n                all_depths_deep = np.concatenate([pred_np_d, plane_depths_deep], axis=2)\n                pred_d_deep = all_depths_deep.reshape(-1, numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation_deep.reshape(-1)].reshape(HEIGHT, WIDTH)\n                \n                cv2.imwrite(testdir + \'/\' + str(index) + \'_segmentation_pred_0.png\', drawSegmentationImage(np.roll(preds_s[0][0], 1, axis=2), black=True))\n                cv2.imwrite(testdir + \'/\' + str(index) + \'_depth_pred_0.png\', drawDepthImage(pred_d_deep))\n\n\n                if suffix == \'confidence\':\n                    pred_s -= np.reshape(np.squeeze(pred_p_c < 0.5), [1, 1, -1]) * 100\n                    pass\n\n                #print(pred_np_m)\n                #print(pred_s\n                #print(planes)\n                #print(pred_p)\n                #exit(1)\n                all_segmentations = np.concatenate([pred_np_m, pred_s], axis=2)\n                if suffix == \'deep\':\n                    pred_p += preds_p[0][0]\n                    #all_segmentations += preds_s[0][0]\n                    all_segmentations[:, :, 0] += preds_s[0][0][:, :, numOutputPlanes]\n                    all_segmentations[:, :, 1:numOutputPlanes + 1] += preds_s[0][0][:, :, :numOutputPlanes]\n                    pass\n                plane_depths = calcPlaneDepths(pred_p, WIDTH, HEIGHT)\n                all_depths = np.concatenate([pred_np_d, plane_depths], axis=2)\n\n\n                segmentation = np.argmax(all_segmentations, 2)\n                if suffix != \'pixelwise\':\n                    pred_d = all_depths.reshape(-1, numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape(HEIGHT, WIDTH)\n                else:\n                    pred_d = np.squeeze(pred_np_d)\n                    cv2.imwrite(testdir + \'/\' + str(index) + \'_normal_pred.png\', drawNormalImage(np.clip(pred_np_n, -1, 1)))\n                    segmentation = np.zeros(segmentation.shape)\n                    pass\n                \n                \n                cv2.imwrite(testdir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(all_segmentations, black=True))\n                cv2.imwrite(testdir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n\n                gtDepths.append(gt_d)\n                planeMasks.append(planeMask)\n                predDepths.append(pred_d)\n                evaluateDepths(predDepths[-1], gtDepths[-1], np.ones(planeMasks[-1].shape), planeMasks[-1])\n                \n                #print(np.concatenate([np.arange(numOutputPlanes).reshape(-1, 1), planes, pred_p, preds_p[0][0]], axis=1))\n\n                #print(np.concatenate([distance[0], preds_p[0][0], pred_p], axis=1))\n                            \n                #segmentation = np.argmax(pred_s, 2)\n                writePLYFile(testdir, index, image, pred_d, segmentation, np.zeros(pred_boundary[0].shape))\n                #writePLYFileParts(testdir, index, image, pred_d, segmentation)\n                gt_s_ori = gt_s_ori[0]\n                cv2.imwrite(testdir + \'/\' + str(index) + \'_segmentation_gt_ori.png\', drawSegmentationImage(gt_s_ori, planeMask=np.max(gt_s_ori, 2) > 0.5, numColors=51))\n\n                if False:\n                    #distance = distance[0]\n                    print(distance)\n                    diff = np.linalg.norm(np.expand_dims(planes, 1) - np.expand_dims(pred_p, 0), axis=2)\n                    print(np.concatenate([planes, pred_p, pow(np.min(diff, axis=1, keepdims=True), 2), np.expand_dims(np.argmin(diff, axis=1), -1)], axis=1))\n                    print(pred_p_c)\n                    \n                    #print(distance[:, 6:8].sum(0))\n                    #print(pow(np.linalg.norm(distance[:, :3] - distance[:, 3:6], 2, 1), 2) * 100)\n                    #print(test)\n                    segmentation = np.argmax(all_segmentations, 2) - 1\n                    for planeIndex in xrange(numOutputPlanes):\n                        cv2.imwrite(testdir + \'/segmentation_\' + str(planeIndex) + \'.png\', drawMaskImage(segmentation == planeIndex))\n                        cv2.imwrite(testdir + \'/segmentation_\' + str(planeIndex) + \'_gt.png\', drawMaskImage(gt_s[:, :, planeIndex]))\n                        cv2.imwrite(testdir + \'/segmentation_\' + str(planeIndex) + \'_gt_ori.png\', drawMaskImage(gt_s_ori[:, :, planeIndex]))\n                        continue\n                    exit(1)\n                continue\n\n            predDepths = np.array(predDepths)\n            gtDepths = np.array(gtDepths)\n            planeMasks = np.array(planeMasks)\n            #predMasks = np.array(predMasks)\n            evaluateDepths(predDepths, gtDepths, np.ones(planeMasks.shape, dtype=np.bool), planeMasks)\n            print(errorSum)\n            exit(1)\n\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n        \n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return\n\n\ndef findBadImages(gpu_id, dumpdir, logdir, testdir, keyname, restore, numOutputPlanes=20, useCRF=0, suffix=\'forward\'):\n    if not os.path.exists(testdir):\n        os.system(""mkdir -p %s""%testdir)\n        pass\n    \n    batchSize = 1\n    \n    min_after_dequeue = 1000\n\n    reader_val = RecordReader()\n    filename_queue_val = tf.train.string_input_producer([\'../planes_test_1000_450000.tfrecords\'], num_epochs=10000)\n    img_inp, plane_gt, depth_gt, normal_gt, segmentation_gt_original, boundary_gt, grid_s_gt, grid_p_gt, grid_m_gt, num_planes_gt = reader_val.getBatch(filename_queue_val, numOutputPlanes=numOutputPlanes, batchSize=batchSize, min_after_dequeue=min_after_dequeue, random=False, getLocal=False, getSegmentation=True, suffix=suffix)\n    #img_inp, plane_gt, depth_gt, normal_gt, segmentation_gt, boundary_gt, s_8_gt = reader_val.getBatch(filename_queue_val, numOutputPlanes=numOutputPlanes, batchSize=batchSize, min_after_dequeue=min_after_dequeue, random=False, getLocal=True)\n\n    validating_inp = tf.placeholder(tf.bool, shape=[], name=\'validating_inp\')\n\n    plane_pred, plane_confidence_pred, depth_pred, normal_pred, segmentation_pred, non_plane_mask_pred, non_plane_depth_pred, non_plane_normal_pred, boundary_pred, grid_s_pred, grid_p_pred, grid_m_pred, plane_preds, segmentation_preds, refined_segmentation = build_graph(img_inp, img_inp, plane_gt, plane_gt, validating_inp, numOutputPlanes=numOutputPlanes, useCRF=useCRF, is_training=False, suffix=suffix)\n\n    var_to_restore = tf.global_variables()\n    \n    loss, plane_loss, depth_loss, normal_loss, segmentation_loss, segmentation_gt, boundary_gt, plane_mask_gt, error_mask, dists = build_loss(plane_pred, plane_confidence_pred, depth_pred, normal_pred, segmentation_pred, non_plane_mask_pred, non_plane_depth_pred, non_plane_normal_pred, boundary_pred, grid_s_pred, grid_p_pred, grid_m_pred, plane_preds, segmentation_preds, plane_gt, depth_gt, normal_gt, segmentation_gt_original, boundary_gt, grid_s_gt, grid_p_gt, grid_m_gt, plane_gt, depth_gt, normal_gt, segmentation_gt_original, boundary_gt, grid_s_gt, grid_p_gt, grid_m_gt, validating_inp, numOutputPlanes=numOutputPlanes, gpu_id=gpu_id, useCRF=useCRF, suffix=suffix)   \n\n    \n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n    badImages = []\n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n        loader = tf.train.Saver(var_to_restore)\n        loader.restore(sess,""%s/%s.ckpt""%(dumpdir, keyname))\n        \n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n        \n        randomColor = np.random.randint(255, size=(numOutputPlanes + 1, 3)).astype(np.uint8)\n        randomColor[0] = 0\n        \n        try:\n            gtDepths = []\n            predDepths = []\n            planeMasks = []\n            #predMasks = []\n            \n            imageWidth = WIDTH\n            imageHeight = HEIGHT\n            focalLength = 517.97\n            urange = np.arange(imageWidth).reshape(1, -1).repeat(imageHeight, 0) - imageWidth * 0.5\n            vrange = np.arange(imageHeight).reshape(-1, 1).repeat(imageWidth, 1) - imageHeight * 0.5\n            ranges = np.array([urange / imageWidth * 640 / focalLength, np.ones(urange.shape), -vrange / imageHeight * 480 / focalLength]).transpose([1, 2, 0])\n\n\n            for index in xrange(1000):\n                if index % 10 == 0:\n                    print((\'image\', index))\n                t0=time.time()\n                #im, planes, depth, normal, boundary, s_8, p_8, b_8, s_16, p_16, b_16, s_32, p_32, b_32 = sess.run([img_inp, plane_gt, depth_gt, normal_gt, boundary_gt, s_8_gt, p_8_gt, b_8_gt, s_16_gt, p_16_gt, b_16_gt, s_32_gt, p_32_gt, b_32_gt])\n                \n                pred_d, im, depth, normal, gt_plane_mask = sess.run([depth_pred, img_inp, depth_gt, normal_gt, plane_mask_gt], feed_dict = {validating_inp:True})\n\n                im = im[0]\n                image = ((im + 0.5) * 255).astype(np.uint8)\n\n                depth = depth.squeeze()\n                normal = normal[0]\n                \n                \n                pred_d = pred_d.squeeze()\n                #pred_s = pred_s[0]\n                #refined_s = refined_s[0]\n                #pred_s = 1 / (1 + np.exp(-pred_s))\n\n                planeMask = np.squeeze(gt_plane_mask)\n\n                rms, accuracy = evaluateDepths(pred_d, depth, np.ones(planeMask.shape), planeMask, printInfo=False)\n                if rms > 0.8 or accuracy < 0.7:\n                    print((len(badImages), rms, accuracy))\n                    cv2.imwrite(testdir + \'/\' + str(len(badImages)) + \'_image.png\', image)\n                    cv2.imwrite(testdir + \'/\' + str(len(badImages)) + \'_depth.png\', drawDepthImage(depth))\n                    cv2.imwrite(testdir + \'/\' + str(len(badImages)) + \'_normal.png\', drawNormalImage(normal))\n                    cv2.imwrite(testdir + \'/\' + str(len(badImages)) + \'_depth_pred.png\', drawDepthImage(pred_d))\n                    badImages.append(index)\n                    pass\n                continue\n            print(badImages)\n\n            exit(1)\n\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n        \n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return\n\ndef predict(dumpdir, testdir, keyname, numOutputPlanes, useCRF=0, dataset=\'SUNCG\', numImages=100, suffix=\'forward\'):\n    testdir += \'_predict\'\n    if not os.path.exists(testdir):\n        os.system(""mkdir -p %s""%testdir)\n        pass\n\n    batchSize = 1\n    img_inp = tf.placeholder(tf.float32,shape=(batchSize,HEIGHT,WIDTH,3),name=\'img_inp\')\n    plane_gt=tf.placeholder(tf.float32,shape=(batchSize,numOutputPlanes, 3),name=\'plane_inp\')\n    validating_inp = tf.constant(True, tf.bool)\n \n\n    plane_pred, plane_confidence_pred, depth_pred, normal_pred, segmentation_pred, non_plane_mask_pred, non_plane_depth_pred, non_plane_normal_pred, boundary_pred, grid_s_pred, grid_p_pred, grid_m_pred, plane_preds, segmentation_preds, refined_segmentation = build_graph(img_inp, img_inp, plane_gt, plane_gt, validating_inp, numOutputPlanes=numOutputPlanes, useCRF=useCRF, is_training=False, suffix=suffix)\n\n    var_to_restore = tf.global_variables()\n    \n \n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n\n\n    if dataset == \'SUNCG\':\n        image_list_file = os.path.join(\'../PythonScripts/SUNCG/image_list_100_tail_500000.txt\')\n        with open(image_list_file) as f:\n            im_names = [{\'image\': im_name.strip().replace(\'plane_global.npy\', \'mlt.png\'), \'depth\': im_name.strip().replace(\'plane_global.npy\', \'depth.png\'), \'normal\': im_name.strip().replace(\'plane_global.npy\', \'norm_camera.png\'), \'valid\': im_name.strip().replace(\'plane_global.npy\', \'valid.png\'), \'plane\': im_name.strip()} for im_name in f.readlines()]\n            pass\n    else:\n        im_names = glob.glob(\'../../Data/NYU_RGBD/*_color.png\')\n        im_names = [{\'image\': im_name, \'depth\': im_name.replace(\'color.png\', \'depth.png\'), \'normal\': im_name.replace(\'color.png\', \'norm_camera.png\'), \'invalid_mask\': im_name.replace(\'color.png\', \'valid.png\')} for im_name in im_names]\n        pass\n      \n    if numImages > 0:\n        im_names = im_names[:numImages]\n        pass\n\n    #if args.imageIndex > 0:\n    #im_names = im_names[args.imageIndex:args.imageIndex + 1]\n    #pass    \n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n\n    with tf.Session(config=config) as sess:\n        saver = tf.train.Saver()\n        #sess.run(tf.global_variables_initializer())\n        saver.restore(sess,""%s/%s.ckpt""%(dumpdir,keyname))\n\n\n        randomColor = np.random.randint(255, size=(numOutputPlanes + 1, 3)).astype(np.uint8)\n        randomColor[0] = 0\n        gtDepths = []\n        predDepths = []\n        segmentationDepths = []\n        predDepthsOneHot = []\n        planeMasks = []\n        predMasks = []\n\n        imageWidth = WIDTH\n        imageHeight = HEIGHT\n        focalLength = 517.97\n        urange = np.arange(imageWidth).reshape(1, -1).repeat(imageHeight, 0) - imageWidth * 0.5\n        vrange = np.arange(imageHeight).reshape(-1, 1).repeat(imageWidth, 1) - imageHeight * 0.5\n        ranges = np.array([urange / focalLength, np.ones(urange.shape), -vrange / focalLength]).transpose([1, 2, 0])\n        \n        cv2.imwrite(testdir + \'/one.png\', np.ones((HEIGHT, WIDTH), dtype=np.uint8) * 255)\n        cv2.imwrite(testdir + \'/zero.png\', np.zeros((HEIGHT, WIDTH), dtype=np.uint8) * 255)\n        for index, im_name in enumerate(im_names):\n            if index <= -1:\n                continue\n            print(im_name[\'image\'])\n            im = cv2.imread(im_name[\'image\'])\n            image = im.astype(np.float32, copy=False)\n            image = image / 255 - 0.5\n            image = cv2.resize(image, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n\n            #planes = np.load(im_name[\'plane\'])\n            # numPlanes = planes.shape[0]\n            # if numPlanes > numOutputPlanes:\n            #     planeAreas = planes[:, 3:].sum(1)\n            #     sortInds = np.argsort(planeAreas)[::-1]\n            #     planes = planes[sortInds[:numOutputPlanes]]\n            #     pass\n            # gt_p = np.zeros((1, numOutputPlanes, 3))\n            # gt_p[0, :numPlanes] = planes[:numPlanes, :3]\n\n            normal = np.array(PIL.Image.open(im_name[\'normal\'])).astype(np.float) / 255 * 2 - 1\n            norm = np.linalg.norm(normal, 2, 2)\n            for c in xrange(3):\n                normal[:, :, c] /= norm\n                continue\n            normal = cv2.resize(normal, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n            \n            depth = np.array(PIL.Image.open(im_name[\'depth\'])).astype(np.float) / 1000\n            depth = cv2.resize(depth, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n\n            invalid_mask = cv2.resize(cv2.imread(im_name[\'invalid_mask\'], 0), (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR) > 128\n\n            gtDepths.append(depth)\n\n            \n            pred_p, pred_d, pred_n, pred_s, pred_np_m, pred_np_d, pred_np_n, pred_boundary, pred_grid_s, pred_grid_p, pred_grid_m = sess.run([plane_pred, depth_pred, normal_pred, segmentation_pred, non_plane_mask_pred, non_plane_depth_pred, non_plane_normal_pred, boundary_pred, grid_s_pred, grid_p_pred, grid_m_pred], feed_dict = {img_inp:np.expand_dims(image, 0), plane_gt: np.zeros((batchSize, numOutputPlanes, 3))})\n\n            if True:\n                depth = global_pred[\'non_plane_depth\'].squeeze()\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', image)\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth.png\', drawDepthImage(depth))\n                planes, planeSegmentation, depthPred = fitPlanes(depth, numPlanes=20)\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(planeSegmentation))\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(depthPred))\n\n                gtDepths.append(global_gt[\'depth\'].squeeze())\n                predDepths.append(depthPred)\n                planeMasks.append((planeSegmentation < 20).astype(np.float32))\n                continue\n            \n\n            pred_s = pred_s[0] \n            pred_p = pred_p[0]\n            pred_np_m = pred_np_m[0]\n            pred_np_d = pred_np_d[0]\n            pred_np_n = pred_np_n[0]\n            #pred_s = 1 / (1 + np.exp(-pred_s))\n\n            plane_depths = calcPlaneDepths(pred_p, WIDTH, HEIGHT)\n            all_depths = np.concatenate([pred_np_d, plane_depths], axis=2)\n\n            all_segmentations = np.concatenate([pred_np_m, pred_s], axis=2)\n            segmentation = np.argmax(all_segmentations, 2)\n            if suffix != \'pixelwise\':\n                pred_d = all_depths.reshape(-1, numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape(HEIGHT, WIDTH)\n            else:\n                pred_d = np.squeeze(pred_np_d)\n                pass\n            predDepths.append(pred_d)\n            predMasks.append(segmentation != 0)\n            planeMasks.append(invalid_mask)\n\n            #depthError, normalError, occupancy, segmentationTest, reconstructedDepth, occupancyMask = evaluatePlanes(pred_p, im_name[\'image\'])\n            #reconstructedDepth = cv2.resize(reconstructedDepth, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n            \n            #evaluatePlanes(pred_p[0], im_name, testdir, index)\n            #print(pred_p)\n            #print(gt_p)\n            #print((pow(pred_d[0, :, :, 0] - depth, 2) * (gt_s.max(2) > 0.5)).mean())\n            #print((depthError, normalError, occupancy))\n            \n            evaluateDepths(predDepths[index], gtDepths[index], np.ones(planeMasks[index].shape), planeMasks[index])\n\n            if index >= 10:\n                continue\n            cv2.imwrite(testdir + \'/\' + str(index) + \'_image.png\', cv2.resize(im, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR))\n            #cv2.imwrite(testdir + \'/\' + str(index) + \'_depth_gt.png\', (minDepth / np.clip(depth, minDepth, 20) * 255).astype(np.uint8))\n            #cv2.imwrite(testdir + \'/\' + str(index) + \'_depth_pred.png\', (minDepth / np.clip(pred_d[0, :, :, 0], minDepth, 20) * 255).astype(np.uint8))\n            #cv2.imwrite(testdir + \'/\' + str(index) + \'_depth_plane.png\', (minDepth / np.clip(reconstructedDepth, minDepth, 20) * 255).astype(np.uint8))\n\n            pred_boundary = pred_boundary[0]\n            boundary = (1 / (1 + np.exp(-pred_boundary)) * 255).astype(np.uint8)\n            boundary = np.concatenate([boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)\n            cv2.imwrite(testdir + \'/\' + str(index) + \'_boundary_pred.png\', boundary)\n            \n            cv2.imwrite(testdir + \'/\' + str(index) + \'_depth_inp.png\', drawDepthImage(depth))\n            cv2.imwrite(testdir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n            #cv2.imwrite(testdir + \'/\' + str(index) + \'_depth_plane.png\', drawDepthImage(reconstructedDepth))\n            cv2.imwrite(testdir + \'/\' + str(index) + \'_depth_pred_diff.png\', drawDiffImage(pred_d, depth, 0.5))\n            #cv2.imwrite(testdir + \'/\' + str(index) + \'_depth_plane_diff.png\', np.minimum(np.abs(reconstructedDepth - depth) / 0.5 * 255, 255).astype(np.uint8))\n            cv2.imwrite(testdir + \'/\' + str(index) + \'_normal_inp.png\', drawNormalImage(normal))\n            cv2.imwrite(testdir + \'/\' + str(index) + \'_normal_pred.png\', drawNormalImage(pred_np_n))\n            cv2.imwrite(testdir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(all_segmentations, black=True))\n\n            segmentation = np.argmax(pred_s, 2)\n            #writePLYFile(testdir, index, image, pred_p, segmentation)\n\n            if index < 0:\n                for planeIndex in xrange(numOutputPlanes):\n                    cv2.imwrite(testdir + \'/\' + str(index) + \'_segmentation_\' + str(planeIndex) + \'.png\', drawMaskImage(pred_s[:, :, planeIndex]))\n                    #cv2.imwrite(testdir + \'/\' + str(index) + \'_segmentation_\' + str(planeIndex) + \'_gt.png\', drawMaskImage(gt_s[:, :, planeIndex]))\n                    continue\n                pass\n            continue\n        predDepths = np.array(predDepths)\n        gtDepths = np.array(gtDepths)\n        planeMasks = np.array(planeMasks)\n        predMasks = np.array(predMasks)\n        #evaluateDepths(predDepths, gtDepths, planeMasks, predMasks)\n        print(planeMasks.shape)\n        print(np.ones(planeMasks.shape, dtype=np.bool).sum())\n        evaluateDepths(predDepths, gtDepths, np.ones(planeMasks.shape, dtype=np.bool), planeMasks)\n        #exit(1)\n        pass\n    return\n\ndef parse_args():\n    """"""\n    Parse input arguments\n    """"""\n    parser = argparse.ArgumentParser(description=\'Planenet\')\n    parser.add_argument(\'--gpu\', dest=\'gpu_id\',\n                        help=\'GPU device id to use [0]\',\n                        default=0, type=int)\n    parser.add_argument(\'--task\', dest=\'task\',\n                        help=\'task type\',\n                        default=\'train\', type=str)\n    parser.add_argument(\'--restore\', dest=\'restore\',\n                        help=\'how to restore\',\n                        default=0, type=int)\n    parser.add_argument(\'--numOutputPlanes\', dest=\'numOutputPlanes\',\n                        help=\'the number of output planes\',\n                        default=20, type=int)\n    parser.add_argument(\'--batchSize\', dest=\'batchSize\',\n                        help=\'batch size\',\n                        default=16, type=int)\n    parser.add_argument(\'--useCRF\', dest=\'useCRF\',\n                        help=\'the number of CRF iterations\',\n                        default=0, type=int)\n    parser.add_argument(\'--suffix\', dest=\'suffix\',\n                        help=\'keyname suffix\',\n                        default=\'\', type=str)\n    parser.add_argument(\'--dataset\', dest=\'dataset\',\n                        help=\'dataset name\',\n                        default=\'NYUV2\', type=str)\n    parser.add_argument(\'--numImages\', dest=\'numImages\',\n                        help=\'the number of images to test\',\n                        default=100, type=int)\n    #if len(sys.argv) == 1:\n    #parser.print_help()     \n\n    args = parser.parse_args()\n    args.keyname = os.path.basename(__file__).rstrip(\'.py\')\n    if args.numOutputPlanes != 20:\n        args.keyname += \'_\' + str(args.numOutputPlanes)\n        pass\n    if args.useCRF > 0:\n        args.suffix = \'crf_\' + str(args.useCRF)\n        pass\n    if args.suffix != \'\':\n        args.keyname += \'_\' + args.suffix\n        pass\n    args.dumpdir = args.keyname.replace(\'train\', \'dump\')\n    args.logdir = args.keyname.replace(\'train\', \'log\')\n    args.testdir = args.keyname.replace(\'train\', \'test\')\n    #if args.useCRF > 0 and args.task == \'predict\':\n    #args.testdir += \'_crf_\' + str(1)\n    #pass\n    return args\n\n\nif __name__==\'__main__\':\n    args = parse_args()\n\n    print ""dumpdir=%s task=%s started""%(args.dumpdir, args.task)\n    #fetchworker=BatchFetcher()    \n    try:\n        if args.task == ""train"":\n            main(args.gpu_id, args.dumpdir, args.logdir, args.testdir, args.keyname, args.restore, args.numOutputPlanes, useCRF=args.useCRF, batchSize=args.batchSize, suffix=args.suffix)\n        elif args.task == ""test"":\n            test(args.gpu_id, args.dumpdir, args.logdir, args.testdir, args.keyname, args.restore, args.numOutputPlanes, useCRF=args.useCRF, suffix=args.suffix)\n        elif args.task == ""predict"":\n            predict(args.dumpdir, args.testdir, args.keyname, args.numOutputPlanes, useCRF=args.useCRF, dataset=args.dataset, numImages=args.numImages, suffix=args.suffix)\n        elif args.task == ""testCRF"":\n            testCRF(args.dumpdir, args.testdir, args.keyname)\n        elif args.task == ""testNearestNeighbors"":\n            testNearestNeighbors(args.dumpdir, args.testdir, args.keyname)\n        elif args.task == ""filter"":\n            findBadImages(args.gpu_id, args.dumpdir, args.logdir, \'bad_images\', args.keyname, args.restore, args.numOutputPlanes, useCRF=args.useCRF)\n        else:\n            assert False,""format wrong""\n            pass\n    finally:\n        pass\n        #stop_fetcher()\n\n'"
PlaneSetGeneration/utils.py,0,"b'import numpy as np\nimport PIL.Image\nimport copy\nimport sys\nimport os\nimport cv2\nimport scipy.ndimage as ndimage\n#import pydensecrf.densecrf as dcrf\n#from pydensecrf.utils import compute_unary, create_pairwise_bilateral, \\\n    #create_pairwise_gaussian, unary_from_softmax\nfrom skimage import segmentation\n#from skimage.future import graph\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom layers import PlaneDepthLayer\n#from layers import PlaneNormalLayer\n#from html import HTML\n\nclass ColorPalette:\n    def __init__(self, numColors):\n        np.random.seed(1)\n        self.colorMap = np.random.randint(255, size = (numColors, 3))\n        self.colorMap[0] = 0\n        return\n\n    def getColorMap(self):\n        return self.colorMap\n    \n    def getColor(self, index):\n        if index >= colorMap.shape[0]:\n            return np.random.randint(255, size = (3))\n        else:\n            return self.colorMap[index]\n            pass\n\ndef writePointCloud(filename, pointCloud, color = [255, 255, 255]):\n    with open(filename, \'w\') as f:\n        header = """"""ply\nformat ascii 1.0\nelement vertex """"""\n        header += str(pointCloud.shape[0])\n        header += """"""\nproperty float x\nproperty float y\nproperty float z\nproperty uchar red                                     { start of vertex color }\nproperty uchar green\nproperty uchar blue\nend_header\n""""""\n        f.write(header)\n        for point in pointCloud:\n            for value in point:\n                f.write(str(value) + \' \')\n                continue\n            for value in color:\n                f.write(str(value) + \' \')\n                continue\n            f.write(\'\\n\')\n            continue\n        f.close()\n        pass\n    return\n\n\ndef writeClusteringPointCloud(filename, pointCloud, clusters):\n    with open(filename, \'w\') as f:\n        header = """"""ply\nformat ascii 1.0\nelement vertex """"""\n        header += str(pointCloud.shape[0])\n        header += """"""\nproperty float x\nproperty float y\nproperty float z\nproperty uchar red                                     { start of vertex color }\nproperty uchar green\nproperty uchar blue\nend_header\n""""""\n        colorMap = np.random.randint(255, size = clusters.shape)\n        assignment = np.argmin(np.linalg.norm(pointCloud.reshape(-1, 1, 3).repeat(clusters.shape[0], 1)[:] - clusters, 2, 2), 1)\n        f.write(header)\n        for pointIndex, point in enumerate(pointCloud):\n            for value in point:\n                f.write(str(value) + \' \')\n                continue\n            color = colorMap[assignment[pointIndex]]\n            for value in color:\n                f.write(str(value) + \' \')\n                continue\n            f.write(\'\\n\')\n            continue\n        f.close()\n        pass\n    return\n\n\ndef writeNearestNeighbors(filename, pointCloudSource, pointCloudTarget):\n    with open(filename, \'w\') as f:\n        header = """"""ply\nformat ascii 1.0\nelement vertex """"""\n        header += str((pointCloudSource.shape[0] + pointCloudTarget.shape[0] + pointCloudSource.shape[0]) * 4)\n        header += """"""\nproperty float x\nproperty float y\nproperty float z\nproperty uchar red\nproperty uchar green\nproperty uchar blue\nelement face """"""\n        header += str(pointCloudSource.shape[0] + pointCloudTarget.shape[0] + pointCloudSource.shape[0])\n        header += """"""\nproperty list uchar int vertex_index\nend_header\n""""""\n        f.write(header)\n        \n        sourceColor = [0, 255, 0]\n        targetColor = [0, 0, 255]\n        colorMap = np.random.randint(255, size = pointCloudSource.shape)\n        \n        # for pointIndex, point in enumerate(pointCloudSource):\n        #     for value in point:\n        #         f.write(str(value) + \' \')\n        #         continue\n        #     color = sourceColor\n        #     for value in color:\n        #         f.write(str(value) + \' \')\n        #         continue\n        #     f.write(\'\\n\')\n        #     continue\n\n        # for pointIndex, point in enumerate(pointCloudTarget):\n        #     for value in point:\n        #         f.write(str(value) + \' \')\n        #         continue\n        #     color = targetColor\n        #     for value in color:\n        #         f.write(str(value) + \' \')\n        #         continue\n        #     f.write(\'\\n\')\n        #     continue        \n\n        planeSize = 0.1\n        for planeType, planes in enumerate([pointCloudSource, pointCloudTarget]):\n            for planeIndex, plane in enumerate(planes):\n                planeD = np.linalg.norm(plane)\n                planeNormal = -plane / planeD\n\n                maxNormalDim = np.argmax(np.abs(plane))\n                allDims = [0, 1, 2]\n                allDims.remove(maxNormalDim)\n                dim_1, dim_2 = allDims\n                for delta_1, delta_2 in [(-planeSize, -planeSize), (planeSize, -planeSize), (planeSize, planeSize), (-planeSize, planeSize)]:\n                    point = copy.deepcopy(plane)\n                    point[dim_1] += delta_1\n                    point[dim_2] += delta_2\n                    point[maxNormalDim] = (-planeD - planeNormal[dim_1] * point[dim_1] - planeNormal[dim_2] * point[dim_2]) / planeNormal[maxNormalDim]\n\n                    for value in point:\n                        f.write(str(value) + \' \')\n                        continue\n                    if planeType == 0:\n                        color = sourceColor\n                    else:\n                        color = targetColor\n                        pass\n                    \n                    for value in color:\n                        f.write(str(value) + \' \')\n                        continue\n                    f.write(\'\\n\')\n                    continue\n                continue\n            continue\n\n        assignment = np.argmin(np.linalg.norm(pointCloudSource.reshape(-1, 1, 3).repeat(pointCloudTarget.shape[0], 1)[:] - pointCloudTarget, 2, 2), 1)\n\n        planeSize = 0.01\n        lineColor = [255, 0, 0]\n        for planeIndex, planeSource in enumerate(pointCloudSource):\n            planeD = np.linalg.norm(planeSource)\n            planeNormal = -planeSource / planeD            \n\n            maxNormalDim = np.argmax(np.abs(planeSource))\n            allDims = [0, 1, 2]\n            allDims.remove(maxNormalDim)\n            dim_1, dim_2 = allDims\n            minNormalDim = np.argmin(np.abs(planeSource))\n\n            for delta in [-planeSize, planeSize]:\n                point = copy.deepcopy(planeSource)\n                point[minNormalDim] += delta\n                point[maxNormalDim] = (-planeD - planeNormal[dim_1] * point[dim_1] - planeNormal[dim_2] * point[dim_2]) / planeNormal[maxNormalDim]\n                for value in point:\n                    f.write(str(value) + \' \')\n                    continue\n                color = lineColor\n                for value in color:\n                    f.write(str(value) + \' \')\n                    continue\n                f.write(\'\\n\')\n                continue\n\n            planeTarget = pointCloudTarget[assignment[planeIndex]]\n            planeDTarget = np.linalg.norm(plane)\n            planeNormalTarget = -plane / planeD\n            planeD = np.linalg.norm(planeTarget)\n            planeNormal = -planeTarget / planeD            \n\n            for delta in [planeSize, -planeSize]:\n                point = copy.deepcopy(planeTarget)\n                point[minNormalDim] += delta\n                point[maxNormalDim] = (-planeD - planeNormal[dim_1] * point[dim_1] - planeNormal[dim_2] * point[dim_2]) / planeNormal[maxNormalDim]\n                for value in point:\n                    f.write(str(value) + \' \')\n                    continue\n                color = lineColor\n                for value in color:\n                    f.write(str(value) + \' \')\n                    continue\n                f.write(\'\\n\')\n                continue\n            continue\n\n        for index in xrange(pointCloudSource.shape[0] + pointCloudTarget.shape[0] + pointCloudSource.shape[0]):\n            planeIndex = index * 4\n            f.write(\'4 \' + str(planeIndex + 0) + \' \' + str(planeIndex + 1) + \' \' + str(planeIndex + 2) + \' \' + str(planeIndex + 3) + \'\\n\')\n            continue\n\n        # for pointIndexSource, point in enumerate(pointCloudSource):\n    #     pointIndexTarget = assignment[pointIndexSource]\n#     f.write(str(pointIndexSource) + \' \' + str(pointIndexTarget + pointCloudSource.shape[0]) + \' \')\n        #     color = colorMap[pointIndexSource]\n    #     for value in color:\n#         f.write(str(value) + \' \')\n        #         continue\n    #     f.write(\'\\n\')\n#     continue\n\n\n        f.close()\n        pass\n    return\n\n\ndef evaluatePlanes(planes, filename = None, depths = None, normals = None, invalidMask = None, outputFolder = None, outputIndex = 0, colorMap = None):\n    if filename != None:\n        if \'mlt\' not in filename:\n            filename = filename.replace(\'color\', \'mlt\')\n            pass\n        normalFilename = filename.replace(\'mlt\', \'norm_camera\')\n        normals = np.array(PIL.Image.open(normalFilename)).astype(np.float) / 255 * 2 - 1\n        norm = np.linalg.norm(normals, 2, 2)\n        for c in xrange(3):\n            normals[:, :, c] /= norm\n            continue\n        \n        depthFilename = filename.replace(\'mlt\', \'depth\')\n        depths = np.array(PIL.Image.open(depthFilename)).astype(np.float) / 1000\n        # if len(depths.shape) == 3:\n        #     depths = depths.mean(2)\n        #     pass\n        maskFilename = filename.replace(\'mlt\', \'valid\')    \n        invalidMask = np.array(PIL.Image.open(maskFilename))\n        invalidMask = invalidMask < 128\n        invalidMask += depths > 10\n        pass\n\n    height = normals.shape[0]\n    width = normals.shape[1]\n    focalLength = 517.97\n    urange = np.arange(width).reshape(1, -1).repeat(height, 0) - width * 0.5\n    vrange = np.arange(height).reshape(-1, 1).repeat(width, 1) - height * 0.5\n    ranges = np.array([urange / focalLength, np.ones(urange.shape), -vrange / focalLength]).transpose([1, 2, 0])\n    \n    X = depths / focalLength * urange\n    Y = depths\n    Z = -depths / focalLength * vrange\n    d = -(normals[:, :, 0] * X + normals[:, :, 1] * Y + normals[:, :, 2] * Z)    \n\n\n    normalDotThreshold = np.cos(np.deg2rad(30))\n    distanceThreshold = 50000\n    \n    reconstructedNormals = np.zeros(normals.shape)\n    reconstructedDepths = np.zeros(depths.shape)\n    segmentationImage = np.zeros((height, width, 3))\n    distanceMap = np.ones((height, width)) * distanceThreshold\n    occupancyMask = np.zeros((height, width)).astype(np.bool)\n    segmentationTest = np.zeros((height, width))\n    y = 297\n    x = 540\n    for planeIndex, plane in enumerate(planes):\n        planeD = np.linalg.norm(plane)\n        planeNormal = -plane / planeD\n\n        normalXYZ = np.dot(ranges, planeNormal)\n        normalXYZ = np.reciprocal(normalXYZ)\n        planeY = -normalXYZ * planeD\n\n        distance = np.abs(planeNormal[0] * X + planeNormal[1] * Y + planeNormal[2] * Z + planeD) / np.abs(np.dot(normals, planeNormal))\n        #distance = np.abs(planeY - depths)\n        \n        mask = (distance < distanceMap) * (planeY > 0) * (np.abs(np.dot(normals, planeNormal)) > normalDotThreshold) * (np.abs(planeY - depths) < 0.5)\n        occupancyMask += mask\n        \n        reconstructedNormals[mask] = planeNormal\n        \n        \n        #if planeNormal[2] > 0.9:\n        #print(planeD)\n        #print(planeNormal)\n        # minDepth = depths.min()\n        # maxDepth = depths.max()\n        # print(depths[300][300])\n        # print(planeY[300][300])\n        # print(depths[350][350])\n        # print(planeY[350][350])\n        # PIL.Image.fromarray((np.maximum(np.minimum((planeY - minDepth) / (maxDepth - minDepth), 1), 0) * 255).astype(np.uint8)).save(outputFolder + \'/plane.png\')\n        # exit(1)\n        #pass\n        reconstructedDepths[mask] = planeY[mask]\n        if colorMap != None and planeIndex in colorMap:\n            segmentationImage[mask] = colorMap[planeIndex]\n        else:\n            segmentationImage[mask] = np.random.randint(255, size=(3,))\n            pass\n        distanceMap[mask] = distance[mask]\n        segmentationTest[mask] = planeIndex + 1\n        #print((planeIndex, planeY[y][x], distance[y][x], np.abs(np.dot(normals, planeNormal))[y][x]))\n        continue\n\n    # print(distanceMap.mean())\n# print(distanceMap.max())\n    # print(np.abs(reconstructedDepths - depths)[occupancyMask].max())\n# print(pow(reconstructedDepths - depths, 2)[True - invalidMask].mean())\n    # exit(1)\n\n    # planeIndex = segmentationTest[y][x]\n# print(normals[y][x])\n    # plane = planes[int(planeIndex)]\n# planeD = np.linalg.norm(plane)\n    # planeNormal = -plane / planeD\n# print((planeNormal, planeD))\n    # print(depths[y][x])\n# print(reconstructedDepths[y][x])\n    # print(segmentationTest[y][x])\n\n    if outputFolder != None:\n        depths[invalidMask] = 0\n        normals[invalidMask] = 0\n        reconstructedDepths[invalidMask] = 0\n        reconstructedNormals[invalidMask] = 0\n        minDepth = depths.min()\n        maxDepth = depths.max()\n        #print(minDepth)\n        #print(maxDepth)\n        PIL.Image.fromarray(((depths - minDepth) / (maxDepth - minDepth) * 255).astype(np.uint8)).save(outputFolder + \'/\' + str(outputIndex) + \'_depth.png\')\n        PIL.Image.fromarray((np.maximum(np.minimum((reconstructedDepths - minDepth) / (maxDepth - minDepth), 1), 0) * 255).astype(np.uint8)).save(outputFolder + \'/\' + str(outputIndex) + \'_depth_reconstructed.png\')\n        #PIL.Image.fromarray((np.maximum(np.minimum((reconstructedDepths - depths) / (distanceThreshold), 1), 0) * 255).astype(np.uint8)).save(outputFolder + \'/depth_\' + str(outputIndex) + \'_diff.png\')\n        PIL.Image.fromarray(((normals + 1) / 2 * 255).astype(np.uint8)).save(outputFolder + \'/\' + str(outputIndex) + \'_normal_.png\')\n        PIL.Image.fromarray(((reconstructedNormals + 1) / 2 * 255).astype(np.uint8)).save(outputFolder + \'/\' + str(outputIndex) + \'_normal_reconstructed.png\')\n        PIL.Image.fromarray(segmentationImage.astype(np.uint8)).save(outputFolder + \'/\' + str(outputIndex) + \'_plane_segmentation.png\')\n        #depthImage = ((depths - minDepth) / (maxDepth - minDepth) * 255).astype(np.uint8)\n        #PIL.Image.fromarray((invalidMask * 255).astype(np.uint8)).save(outputFolder + \'/mask.png\')\n        #exit(1)\n    else:\n        occupancy = (occupancyMask > 0.5).astype(np.float32).sum() / (1 - invalidMask).sum()\n        invalidMask += np.invert(occupancyMask)\n        #PIL.Image.fromarray(invalidMask.astype(np.uint8) * 255).save(outputFolder + \'/mask.png\')\n        reconstructedDepths = np.maximum(np.minimum(reconstructedDepths, 10), 0)\n        depthError = pow(reconstructedDepths - depths, 2)[np.invert(invalidMask)].mean()\n        #depthError = distanceMap.mean()\n        normalError = np.arccos(np.maximum(np.minimum(np.sum(reconstructedNormals * normals, 2), 1), -1))[np.invert(invalidMask)].mean()\n        #normalError = pow(np.linalg.norm(reconstructedNormals - normals, 2, 2), 2)[True - invalidMask].mean()\n        #print((depthError, normalError, occupancy))\n        # print(depths.max())\n        # print(depths.min())\n        # print(reconstructedDepths.max())\n        # print(reconstructedDepths.min())\n        # print(occupancy)\n        # exit(1)\n        \n        #reconstructedDepths[np.invert(occupancyMask)] = depths[np.invert(occupancyMask)]\n        return depthError, normalError, occupancy, segmentationTest, reconstructedDepths, occupancyMask\n    return\n\n\ndef evaluatePlanesSeparately(planes, filename, outputFolder = None, outputIndex = 0):\n    if \'mlt\' not in filename:\n        filename = filename.replace(\'color\', \'mlt\')\n        pass\n    colorImage = np.array(PIL.Image.open(filename))\n    normalFilename = filename.replace(\'mlt\', \'norm_camera\')\n    normals = np.array(PIL.Image.open(normalFilename)).astype(np.float) / 255 * 2 - 1\n    height = normals.shape[0]\n    width = normals.shape[1]\n    norm = np.linalg.norm(normals, 2, 2)\n    for c in xrange(3):\n        normals[:, :, c] /= norm\n        continue\n\n    \n    depthFilename = filename.replace(\'mlt\', \'depth\')\n    depths = np.array(PIL.Image.open(depthFilename)).astype(np.float) / 1000\n    # if len(depths.shape) == 3:\n    #     depths = depths.mean(2)\n    #     pass\n    \n    focalLength = 517.97\n    urange = np.arange(width).reshape(1, -1).repeat(height, 0) - width * 0.5\n    vrange = np.arange(height).reshape(-1, 1).repeat(width, 1) - height * 0.5\n    ranges = np.array([urange / focalLength, np.ones(urange.shape), -vrange / focalLength]).transpose([1, 2, 0])\n    X = depths / focalLength * urange\n    Y = depths\n    Z = -depths / focalLength * vrange\n    d = -(normals[:, :, 0] * X + normals[:, :, 1] * Y + normals[:, :, 2] * Z)\n\n    \n    maskFilename = filename.replace(\'mlt\', \'valid\')    \n    invalidMask = np.array(PIL.Image.open(maskFilename))\n    # if len(invalidMask.shape) == 3:\n    #     invalidMask = invalidMask.mean(2)\n    #     pass\n    invalidMask = invalidMask < 128\n    invalidMask += depths > 10\n\n\n    normalDotThreshold = np.cos(np.deg2rad(15))\n    distanceThreshold = 0.15\n    colorPalette = ColorPalette(len(planes))\n    for planeIndex, plane in enumerate(planes):\n        planeD = np.linalg.norm(plane)\n        planeNormal = -plane / planeD\n\n        distance = np.abs(planeNormal[0] * X + planeNormal[1] * Y + planeNormal[2] * Z + planeD)\n\n        normalXYZ = np.dot(ranges, planeNormal)\n        normalXYZ = np.reciprocal(normalXYZ)\n        planeY = -normalXYZ * planeD\n        \n        mask = (planeY > 0) * (np.abs(np.dot(normals, planeNormal)) > normalDotThreshold) * (distance < distanceThreshold)\n\n        maxDepth = 10\n        minDepth = 0\n        #PIL.Image.fromarray((np.minimum(np.maximum((planeY - minDepth) / (maxDepth - minDepth), 0), 1) * 255).astype(np.uint8)).save(outputFolder + \'/plane_depth_\' + str(planeIndex) + \'.png\')\n        #PIL.Image.fromarray(((planeNormal.reshape(1, 1, 3).repeat(height, 0).repeat(width, 1) + 1) / 2 * 255).astype(np.uint8)).save(outputFolder + \'/plane_normal_\' + str(planeIndex) + \'.png\')\n        planeImage = colorImage * 0.3\n        planeImage[mask] += colorPalette.getColor(planeIndex) * 0.7\n        PIL.Image.fromarray(planeImage.astype(np.uint8)).save(outputFolder + \'/plane_mask_\' + str(planeIndex) + \'_\' + str(outputIndex) + \'.png\')\n        #PIL.Image.fromarray(mask.astype(np.uint8) * 255).save(outputFolder + \'/mask_\' + str(planeIndex) + \'.png\')\n        continue\n    return\n\ndef residual2Planes(residualPlanes, predefinedPlanes):\n    numClusters = predefinedPlanes.shape[0]\n    planes = []\n    for residualPlane in residualPlanes:\n        gridIndex = int(residualPlane[0]) / numClusters\n        planeIndex = int(residualPlane[0]) % numClusters\n        planes.append(predefinedPlanes[planeIndex] + residualPlane[1:])\n        continue\n    return planes\n\ndef residual2PlanesGlobal(residualPlanes, predefinedPlanes):\n    numClusters = predefinedPlanes.shape[0]\n    planes = []\n    for residualPlane in residualPlanes:\n        planeIndex = int(residualPlane[0])\n        planes.append(predefinedPlanes[planeIndex] + residualPlane[1:])\n        continue\n    return planes\n\n\ndef getPlaneInfo(planes):\n    imageWidth = 640\n    imageHeight = 480\n    focalLength = 517.97\n    urange = np.arange(imageWidth).reshape(1, -1).repeat(imageHeight, 0) - imageWidth * 0.5\n    vrange = np.arange(imageHeight).reshape(-1, 1).repeat(imageWidth, 1) - imageHeight * 0.5\n    ranges = np.array([urange / focalLength, np.ones(urange.shape), -vrange / focalLength]).transpose([1, 2, 0])\n    \n    planeDepths = PlaneDepthLayer(planes, ranges)\n    planeNormals = PlaneNormalLayer(planes, ranges)\n    return planeDepths, planeNormals\n\ndef getProbability(image, segmentation):\n    width = image.shape[1]\n    height = image.shape[0]\n    numPlanes = segmentation.shape[0]\n    probabilities = np.exp(segmentation)\n    probabilities = probabilities / probabilities.sum(0)\n    # The input should be the negative of the logarithm of probability values\n    # Look up the definition of the softmax_to_unary for more information\n    unary = unary_from_softmax(probabilities)\n\n    # The inputs should be C-continious -- we are using Cython wrapper\n    unary = np.ascontiguousarray(unary)\n\n    d = dcrf.DenseCRF(height * width, numPlanes)\n    \n    d.setUnaryEnergy(unary)\n\n    # This potential penalizes small pieces of segmentation that are\n    # spatially isolated -- enforces more spatially consistent segmentations\n    # feats = create_pairwise_gaussian(sdims=(10, 10), shape=(height, width))\n    # d.addPairwiseEnergy(feats, compat=300,\n    #                                         kernel=dcrf.DIAG_KERNEL,\n    #                                         normalization=dcrf.NORMALIZE_SYMMETRIC)\n\n    # This creates the color-dependent features --\n    # because the segmentation that we get from CNN are too coarse\n    # and we can use local color features to refine them\n        \n    feats = create_pairwise_bilateral(sdims=(50, 50), schan=(20, 20, 20),\n                                      img=image, chdim=2)\n    d.addPairwiseEnergy(feats, compat=10,\n                        kernel=dcrf.DIAG_KERNEL,\n                        normalization=dcrf.NORMALIZE_SYMMETRIC)\n        \n    Q = d.inference(50)\n\n    inds = np.argmax(Q, axis=0).reshape((height, width))\n    probabilities = np.zeros((height * width, numPlanes))\n    probabilities[np.arange(height * width), inds.reshape(-1)] = 1\n    probabilities = probabilities.reshape([height, width, -1])\n    #print(res.shape)\n    return probabilities\n\ndef getProbabilityMax(segmentation):\n    width = segmentation.shape[2]\n    height = segmentation.shape[1]\n    numPlanes = segmentation.shape[0]\n    inds = np.argmax(segmentation.reshape([-1, height * width]), axis=0)\n    probabilities = np.zeros((height * width, numPlanes))\n    probabilities[np.arange(height * width), inds] = 1\n    probabilities = probabilities.reshape([height, width, -1])\n    return probabilities\n    \n\n\n\n\n    \n\n\n    \n\ndef evaluateDepths(predDepths, gtDepths, validMasks, planeMasks=True, printInfo=True):\n    masks = np.logical_and(np.logical_and(validMasks, planeMasks), gtDepths > 1e-4)\n    \n    numPixels = float(masks.sum())\n    rms = np.sqrt((pow(predDepths - gtDepths, 2) * masks).sum() / numPixels)\n    #log10 = (np.abs(np.log10(np.maximum(predDepths, 1e-4)) - np.log10(np.maximum(gtDepths, 1e-4))) * masks).sum() / numPixels\n    #rel = (np.abs(predDepths - gtDepths) / np.maximum(gtDepths, 1e-4) * masks).sum() / numPixels\n    deltas = np.maximum(predDepths / np.maximum(gtDepths, 1e-4), gtDepths / np.maximum(predDepths, 1e-4)) + (1 - masks.astype(np.float32)) * 10000\n    accuracy_1 = (deltas < 1.25).sum() / numPixels\n    accuracy_2 = (deltas < pow(1.25, 2)).sum() / numPixels\n    accuracy_3 = (deltas < pow(1.25, 3)).sum() / numPixels\n    recall = float(masks.sum()) / validMasks.sum()\n    #print((rms, recall))\n    if printInfo:\n        print((\'evaluate\', rms, accuracy_1, accuracy_2, accuracy_3, recall))\n        pass\n    return rms, accuracy_1\n    #return rel, log10, rms, accuracy_1, accuracy_2, accuracy_3, recall\n\ndef drawDepthImage(depth):\n    #return cv2.applyColorMap(np.clip(depth / 10 * 255, 0, 255).astype(np.uint8), cv2.COLORMAP_JET)\n    return 255 - np.clip(depth / 10 * 255, 0, 255).astype(np.uint8)\n    \ndef drawNormalImage(normal):\n    return ((normal + 1) / 2 * 255).astype(np.uint8)\n    \ndef drawSegmentationImage(segmentations, randomColor=None, numColors=22, planeMask=1, offset=1, black=False):\n    randomColor = ColorPalette(numColors).getColorMap()\n    if black:\n        randomColor[0] = 0\n        pass\n    width = segmentations.shape[1]\n    height = segmentations.shape[0]\n    if segmentations.ndim == 2:\n        segmentation = (segmentations + offset) * planeMask\n    else:\n        #segmentation = (np.argmax(segmentations, 2) + 1) * (np.max(segmentations, 2) > 0.5)\n        if black:\n            segmentation = np.argmax(segmentations, 2)\n        else:\n            segmentation = (np.argmax(segmentations, 2) + 1) * planeMask\n            pass\n        pass\n    segmentation = segmentation.astype(np.int)\n    return randomColor[segmentation.reshape(-1)].reshape((height, width, 3))\n\ndef drawMaskImage(mask):\n    return (mask * 255).astype(np.uint8)\n\ndef drawDiffImage(values_1, values_2, threshold):\n    #return cv2.applyColorMap(np.clip(np.abs(values_1 - values_2) / threshold * 255, 0, 255).astype(np.uint8), cv2.COLORMAP_JET)\n    return np.clip(np.abs(values_1 - values_2) / threshold * 255, 0, 255).astype(np.uint8)\n\n\ndef getSuperpixels(depth, normal, width, height, numPlanes=50, numGlobalPlanes = 10):\n    depth = np.expand_dims(depth, -1)\n\n    urange = (np.arange(width, dtype=np.float32) / (width + 1) - 0.5) / focalLength * 641\n    urange = np.tile(np.reshape(urange, [1, -1]), [height, 1])\n    vrange = (np.arange(height, dtype=np.float32) / (height + 1) - 0.5) / focalLength * 481\n    vrange = np.tile(np.reshape(vrange, [-1, 1]), [1, width])\n    \n    ranges = np.stack([urange, np.ones([height, width]), -vrange], axis=2)\n    #ranges = np.expand_dims(ranges, 0)\n\n    planeImage = np.sum(normal * ranges, axis=2, keepdims=True) * depth * normal\n    planeImage = planeImage / 10 * 1000\n\n    superpixels = segmentation.slic(planeImage, compactness=30, n_segments=400)\n    g = graph.rag_mean_color(planeImage, superpixels, mode=\'similarity\')\n    planeSegmentation = graph.cut_normalized(superpixels, g)\n    return planeSegmentation, superpixels\n\n\ndef calcPlaneDepths(planes, width, height):\n    focalLength = 517.97\n    urange = np.arange(width).reshape(1, -1).repeat(height, 0) - width * 0.5\n    vrange = np.arange(height).reshape(-1, 1).repeat(width, 1) - height * 0.5\n    ranges = np.array([urange / width * 640 / focalLength, np.ones(urange.shape), -vrange / height * 480 / focalLength]).transpose([1, 2, 0])\n    \n    planeDepths = PlaneDepthLayer(planes, ranges)\n    return planeDepths\n\n\ndef writePLYFile(folder, index, image, depth, segmentation, boundaries):\n    imageFilename = str(index) + \'_image.png\'\n    cv2.imwrite(folder + \'/\' + imageFilename, image)\n\n    focalLength = 517.97\n    width = image.shape[1]\n    height = image.shape[0]\n        \n    faces = []\n    minDepthDiff = 0.15\n    maxDepthDiff = 0.3\n    occlusionBoundary = boundaries[:, :, 1]\n        \n    for y in xrange(height - 1):\n        for x in xrange(width - 1):\n            segmentIndex = segmentation[y][x]\n            if segmentIndex == -1:\n                continue\n            if segmentIndex == 0:\n                continue\n            depths = [depth[y][x], depth[y + 1][x], depth[y + 1][x + 1]]\n            if segmentIndex > 0 or (max([occlusionBoundary[y][x], occlusionBoundary[y + 1][x], occlusionBoundary[y + 1][x + 1]]) < 0.5 and (max(depths) - min(depths)) < maxDepthDiff):\n                if segmentation[y + 1][x] == segmentIndex and segmentation[y + 1][x + 1] == segmentIndex:\n                    if min(depths) > 0 and max(depths) < 10:\n                        faces.append((x, y, x, y + 1, x + 1, y + 1))\n                        pass\n                    pass\n                elif max(depths) - min(depths) < minDepthDiff:\n                    faces.append((x, y, x, y + 1, x + 1, y + 1))\n                    pass\n                pass\n\n                        \n            depths = [depth[y][x], depth[y][x + 1], depth[y + 1][x + 1]]                        \n            if segmentIndex > 0 or (max([occlusionBoundary[y][x], occlusionBoundary[y][x + 1], occlusionBoundary[y + 1][x + 1]]) < 0.5 and (max(depths) - min(depths)) < maxDepthDiff):\n                if segmentation[y][x + 1] == segmentIndex and segmentation[y + 1][x + 1] == segmentIndex:\n                    if min(depths) > 0 and max(depths) < 10:\n                        faces.append((x, y, x + 1, y + 1, x + 1, y))\n                        pass\n                    pass\n                elif max(depths) - min(depths) < minDepthDiff:\n                    faces.append((x, y, x + 1, y + 1, x + 1, y))\n                    pass\n                pass\n            continue\n        continue\n\n    #print(len(faces))\n    with open(folder + \'/\' + str(index) + \'_model.ply\', \'w\') as f:\n        header = """"""ply\nformat ascii 1.0\ncomment VCGLIB generated\ncomment TextureFile """"""\n        header += imageFilename\n        header += """"""\nelement vertex """"""\n        header += str(width * height)\n        header += """"""\nproperty float x\nproperty float y\nproperty float z\nelement face """"""\n        header += str(len(faces))\n        header += """"""\nproperty list uchar int vertex_indices\nproperty list uchar float texcoord\nend_header\n""""""\n        f.write(header)\n        for y in xrange(height):\n            for x in xrange(width):\n                segmentIndex = segmentation[y][x]\n                if segmentIndex == -1:\n                    f.write(""0.0 0.0 0.0\\n"")\n                    continue\n                Y = depth[y][x]\n                X = Y / focalLength * (x - width / 2) / width * 640\n                Z = -Y / focalLength * (y - height / 2) / height * 480\n                f.write(str(X) + \' \' +    str(Z) + \' \' + str(-Y) + \'\\n\')\n                continue\n            continue\n\n\n        for face in faces:\n            f.write(\'3 \')\n            for c in xrange(3):\n                f.write(str(face[c * 2 + 1] * width + face[c * 2]) + \' \')\n                continue\n            f.write(\'6 \')                     \n            for c in xrange(3):\n                f.write(str(float(face[c * 2]) / width) + \' \' + str(1 - float(face[c * 2 + 1]) / height) + \' \')\n                continue\n            f.write(\'\\n\')\n            continue\n        f.close()\n        pass\n\treturn  \n\ndef writeHTML(folder, numImages):\n    return\n    h = HTML(\'html\')\n    h.p(\'Results\')\n    h.br()\n    #suffixes = [\'\', \'_crf_1\']\n    #folders = [\'test_all_resnet_v2\' + suffix + \'/\' for suffix in suffixes]\n    for index in xrange(numImages):\n        t = h.table(border=\'1\')\n        r_inp = t.tr()\n        r_inp.td(\'input\')\n        r_inp.td().img(src=str(index) + \'_image.png\')\n        r_inp.td().img(src=\'one.png\')\n        r_inp.td().img(src=\'one.png\')\n        #r_inp.td().img(src=\'one.png\')\n        r_inp.td().img(src=str(index) + \'_model.png\')\n\n        r_gt = t.tr()\n        r_gt.td(\'gt\')\n        r_gt.td().img(src=str(index) + \'_segmentation_gt.png\')\n        r_gt.td().img(src=str(index) + \'_depth.png\')\n        r_gt.td().img(src=\'one.png\')\n        r_gt.td().img(src=str(index) + \'_normal.png\')\n                \n        #r_gt.td().img(src=folders[0] + str(index) + \'_depth_gt.png\')\n        #r_gt.td().img(src=folders[0] + \'_depth_gt_diff.png\')\n        #r_gt.td().img(src=folders[0] + str(index) + \'_normal_gt.png\')\n\n        r_pred = t.tr()\n        r_pred.td(\'pred\')\n        r_pred.td().img(src=str(index) + \'_segmentation_pred.png\')\n        r_pred.td().img(src=str(index) + \'_depth_pred.png\')\n        r_pred.td().img(src=str(index) + \'_depth_pred_diff.png\')\n        r_pred.td().img(src=str(index) + \'_normal_pred.png\')\n\n        h.br()\n        continue\n\n    html_file = open(folder + \'/index.html\', \'w\')\n    html_file.write(str(h))\n    html_file.close()\n    return\n\n\n\n'"
code/CopyTexture.py,9,"b'import tensorflow as tf\nimport numpy as np\nnp.set_printoptions(precision=2, linewidth=200)\nimport cv2\nimport os\nimport time\nimport sys\nimport tf_nndistance\nimport argparse\nimport glob\nimport PIL\nimport scipy.ndimage as ndimage\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom utils import *\nfrom plane_utils import *\nfrom modules import *\n\nfrom train_sample import build_graph\nfrom planenet import PlaneNet\nfrom RecordReaderAll import *\nfrom SegmentationRefinement import *\nfrom crfasrnn_layer import CrfRnnLayer\n\nnp.set_printoptions(precision=2, linewidth=200)\n\n\ndef findFloorPlane(planes, segmentation):\n    minZ = 0\n    minZPlaneIndex = -1\n    minFloorArea = 32 * 24\n    for planeIndex, plane in enumerate(planes):\n        if plane[2] < 0 and abs(plane[2]) > max(abs(plane[0]), abs(plane[1])) and plane[2] < minZ and (segmentation == planeIndex).sum() > minFloorArea:\n            minZPlaneIndex = planeIndex\n            minZ = plane[2]\n            pass\n        continue\n    return minZPlaneIndex\n\ndef findCornerPoints(plane, depth, mask, axis=2, rectangle=True):\n    focalLength = 517.97\n    width = depth.shape[1]\n    height = depth.shape[0]\n    urange = (np.arange(width).reshape(1, -1).repeat(height, 0) - width * 0.5) / width * 640\n    vrange = (np.arange(height).reshape(-1, 1).repeat(width, 1) - height * 0.5) / height * 480\n    ranges = np.stack([urange / focalLength, np.ones(urange.shape), -vrange / focalLength], axis=2)\n\n    XYZ = ranges * np.expand_dims(depth, -1)\n    XYZ = XYZ[mask].reshape(-1, 3)\n\n    maxs = XYZ.max(0)\n    mins = XYZ.min(0)\n\n    planeD = np.linalg.norm(plane)\n    planeNormal = plane / planeD\n    if axis == 2:\n        points = np.array([[mins[0], mins[1]], [mins[0], maxs[1]], [maxs[0], mins[1]], [maxs[0], maxs[1]]])\n        pointsZ = (planeD - planeNormal[0] * points[:, 0] - planeNormal[1] * points[:, 1]) / planeNormal[2]\n        points = np.concatenate([points, np.expand_dims(pointsZ, -1)], axis=1)\n        pass\n    u = points[:, 0] / points[:, 1] * focalLength / 640 * width + width / 2\n    v = -points[:, 2] / points[:, 1] * focalLength / 480 * height + height / 2\n\n    if rectangle:\n        minU = u.min()\n        maxU = u.max()\n        minV = v.min()\n        maxV = v.max()\n        uv = np.array([[minU, minV], [minU, maxV], [maxU, minV], [maxU, maxV]])\n    else:\n        uv = np.stack([u, v], axis=1)\n        pass\n    return uv\n\ndef copyTextureTest(options):\n    testdir = \'texture_test/\'\n    for index in xrange(1):\n        planes = np.load(testdir + \'/planes_\' + str(index) + \'.npy\')\n        image = cv2.imread(testdir + \'/image_\' + str(index) + \'.png\')\n        segmentations = np.load(testdir + \'/segmentations_\' + str(index) + \'.npy\')\n        segmentation = np.argmax(segmentations, axis=2)\n        plane_depths = calcPlaneDepths(planes, WIDTH, HEIGHT)\n        \n        textureImage = cv2.imread(\'../textures/texture_0.jpg\')\n        textureImage = cv2.resize(textureImage, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n        floorPlaneIndex = findFloorPlane(planes, segmentation)\n        if floorPlaneIndex == -1:\n            continue\n        mask = segmentation == floorPlaneIndex\n        uv = findCornerPoints(planes[floorPlaneIndex], plane_depths[:, :, floorPlaneIndex], mask)\n        source_uv = np.array([[0, 0], [0, HEIGHT], [WIDTH, 0], [WIDTH, HEIGHT]])\n\n        h, status = cv2.findHomography(source_uv, uv)\n        textureImageWarped = cv2.warpPerspective(textureImage, h, (WIDTH, HEIGHT))\n        image[mask] = textureImageWarped[mask]\n        cv2.imwrite(testdir + \'/\' + str(index) + \'_texture.png\', textureImageWarped)\n        cv2.imwrite(testdir + \'/\' + str(index) + \'_result.png\', image)\n        continue\n    return\n\n\ndef copyTexture(options):\n\n    if os.path.exists(options.result_filename) and options.useCache == 1:\n        pred_dict = np.load(options.result_filename)\n        pred_dict = pred_dict[()]\n    else:\n        pred_dict = getResults(options)\n        np.save(options.result_filename, pred_dict)        \n        pass\n\n\n    texture_image_names = glob.glob(\'../textures/*.png\') + glob.glob(\'../textures/*.jpg\')\n    \n    for image_index in xrange(options.numImages):\n        planes = pred_dict[\'plane\'][image_index]\n        segmentation = pred_dict[\'segmentation\'][image_index]\n        image = pred_dict[\'image\'][image_index]\n        plane_depths = pred_dict[\'plane_depth\'][image_index]\n\n        #writePLYFile(options.test_dir, index, image, pred_d, segmentation, np.zeros(pred_boundary.shape))\n        oriWidth = image.shape[1]\n        oriHeight = image.shape[0]\n        \n        for texture_index, texture_image_name in enumerate(texture_image_names):\n            textureImage = cv2.imread(texture_image_name)\n            #textureImage = cv2.imread(\'../textures/texture_2.jpg\')\n            textureImage = cv2.resize(textureImage, (oriWidth, oriHeight), interpolation=cv2.INTER_LINEAR)\n            floorPlaneIndex = findFloorPlane(planes, segmentation)\n            mask = segmentation == floorPlaneIndex\n            #mask = cv2.resize(mask.astype(np.float32), (oriWidth, oriHeight), interpolation=cv2.INTER_LINEAR) > 0.5\n            #plane_depths = calcPlaneDepths(pred_p, oriWidth, oriHeight)\n            depth = plane_depths[:, :, floorPlaneIndex]\n            #depth = cv2.resize(depth, (oriWidth, oriHeight), interpolation=cv2.INTER_LINEAR) > 0.5\n            uv = findCornerPoints(planes[floorPlaneIndex], depth, mask)\n            print(uv)\n            source_uv = np.array([[0, 0], [0, oriHeight], [oriWidth, 0], [oriWidth, oriHeight]])\n                \n            h, status = cv2.findHomography(source_uv, uv)\n            #textureImageWarped = cv2.warpPerspective(textureImage, h, (WIDTH, HEIGHT))\n            textureImageWarped = cv2.warpPerspective(textureImage, h, (oriWidth, oriHeight))\n            resultImage = image.copy()\n\n            resultImage[mask] = textureImageWarped[mask]\n            #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_texture.png\', textureImageWarped)\n            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_result_\' + str(texture_index) + \'.png\', resultImage)\n            continue\n        continue\n    return\n\n    \ndef getResults(options):\n\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n\n    checkpoint_prefix = options.rootFolder + \'/checkpoint/\'\n\n\n    image_list = glob.glob(\'testing_images/*.png\') + glob.glob(\'testing_images/*.jpg\')\n    #print(image_list)\n    #exit(1)\n    \n    method = (\'hybrid_hybrid1_bl0_dl0_ll1_sm0\', \'\')\n    #method = (\'finetuning_hybrid1_ps\', \'\')\n    #method = (\'planenet_hybrid1_bl0_ll1_ds0_pp_ps\', \'\')\n    # left_walls = [0, 5, 6, 11, 18]\n    # right_walls = [4, 10, 7, 19]\n    # floors = [14]\n    # ceilings = []    \n    # layout_planes = [ceilings, floors, left_walls + right_walls]\n\n    #method = (\'sample_np10_hybrid3_bl0_dl0_hl2_ds0_crfrnn5_sm0\', \'\')\n    #method = (\'planenet_np10_hybrid3_bl0_dl0_crfrnn-10_sm0\', \'\')\n    # left_walls = [0, 5, 6, 11, 18]\n    # right_walls = [4, 10]\n    # floors = [14]\n    # ceilings = []    \n    # layout_planes = [ceilings, floors, left_walls + right_walls]\n    \n    \n    if \'ds0\' not in method[0]:\n        options.deepSupervisionLayers = [\'res4b22_relu\', ]\n    else:\n        options.deepSupervisionLayers = []\n        pass\n    options.predictConfidence = 0\n    options.predictLocal = 0\n    options.predictPixelwise = 1\n    options.predictBoundary = int(\'pb\' in method[0])\n    options.anchorPlanes = 0\n    options.predictSemantics = 0\n    options.batchSize = 1\n\n    if \'crfrnn\' in method[0]:\n        options.crfrnn = 10\n    else:\n        options.crfrnn = 0\n        pass    \n    if \'ap1\' in method[0]:\n        options.anchorPlanes = 1\n        pass\n        \n    options.checkpoint_dir = checkpoint_prefix + method[0]\n    print(options.checkpoint_dir)\n    \n    options.suffix = method[1]\n\n    \n    batchSize = 1\n    img_inp = tf.placeholder(tf.float32,shape=(batchSize, HEIGHT, WIDTH, 3),name=\'img_inp\')\n    training_flag = tf.constant(True, tf.bool)\n \n\n    options.gpu_id = 0\n    if \'sample\' in options.checkpoint_dir:\n        global_pred_dict, _, _ = build_graph_sample(img_inp, img_inp, training_flag, options)\n    else:\n        global_pred_dict, _, _ = build_graph(img_inp, img_inp, training_flag, options)\n        pass\n\n    var_to_restore = tf.global_variables()\n    \n \n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n\n\n    #im_names = glob.glob(\'../AdobeImages/*.png\') + glob.glob(\'../AdobeImages/*.jpg\')\n\n      \n    if options.numImages > 0:\n        image_list = image_list[:options.numImages]\n        pass\n\n    if options.imageIndex >= 0:\n        image_list = [image_list[args.imageIndex:args.imageIndex]]\n    pass    \n\n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n\n    pred_dict = {}    \n    with tf.Session(config=config) as sess:\n        loader = tf.train.Saver()\n        #sess.run(tf.global_variables_initializer())\n        loader.restore(sess, ""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n        #saver.restore(sess,""dump_planenet/train_planenet.ckpt"")\n\n        images = []\n        predPlanes = []\n        predSegmentations = []\n        predDepths = []        \n        predPlaneDepths = []\n\n        # imageWidth = WIDTH\n        # imageHeight = HEIGHT\n        # focalLength = 517.97\n        # urange = np.arange(imageWidth).reshape(1, -1).repeat(imageHeight, 0) - imageWidth * 0.5\n        # vrange = np.arange(imageHeight).reshape(-1, 1).repeat(imageWidth, 1) - imageHeight * 0.5\n        # ranges = np.array([urange / focalLength, np.ones(urange.shape), -vrange / focalLength]).transpose([1, 2, 0])\n        \n        for index, image_filename in enumerate(image_list):\n            if index <= -1:\n                continue\n            print(image_filename)\n            im = cv2.imread(image_filename)\n            im_resized = cv2.resize(im, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', im)\n            #continue\n            width_high_res = im.shape[1]\n            height_high_res = im.shape[0]\n            image = im.astype(np.float32, copy=False)\n            image = image / 255 - 0.5\n            image = cv2.resize(image, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n\n            global_pred = sess.run(global_pred_dict, feed_dict={img_inp: np.expand_dims(image, 0)})\n\n            pred_p = global_pred[\'plane\'][0]\n            pred_s = global_pred[\'segmentation\'][0]\n                \n            pred_np_m = global_pred[\'non_plane_mask\'][0]\n            pred_np_d = global_pred[\'non_plane_depth\'][0]\n            pred_np_n = global_pred[\'non_plane_normal\'][0]\n            \n\n            info = np.zeros(info.shape)\n            focalLength = estimateFocalLength(im)\n            info[0] = focalLength\n            info[5] = focalLength\n            info[2] = im.shape[1] / 2\n            info[6] = im.shape[0] / 2\n            info[16] = im.shape[1]\n            info[17] = im.shape[0]\n            info[10] = 1\n            info[15] = 1\n            info[18] = 1000\n            info[19] = 5\n            \n            all_segmentations = np.concatenate([pred_s, pred_np_m], axis=2)\n            plane_depths = calcPlaneDepths(pred_p, width_high_res, height_high_res, info)\n\n            pred_np_d = np.expand_dims(cv2.resize(pred_np_d.squeeze(), (width_high_res, height_high_res)), -1)\n            all_depths = np.concatenate([plane_depths, pred_np_d], axis=2)\n\n            all_segmentations = np.stack([cv2.resize(all_segmentations[:, :, planeIndex], (width_high_res, height_high_res)) for planeIndex in xrange(all_segmentations.shape[-1])], axis=2)\n                \n            segmentation = np.argmax(all_segmentations, 2)\n            pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(height_high_res * width_high_res), segmentation.reshape(-1)].reshape(height_high_res, width_high_res)\n            \n            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(all_segmentations, black=True))\n\n\n            images.append(im)\n            predDepths.append(pred_d)\n            predPlanes.append(pred_p)\n            predSegmentations.append(segmentation)\n            predPlaneDepths.append(plane_depths)\n            continue\n\n        pred_dict[\'image\'] = np.array(images)\n        pred_dict[\'plane\'] = np.array(predPlanes)\n        pred_dict[\'segmentation\'] = np.array(predSegmentations)\n        pred_dict[\'depth\'] = np.array(predDepths)\n        pred_dict[\'plane_depth\'] = np.array(predPlaneDepths)\n        pass\n    return pred_dict\n\n\n\nif __name__==\'__main__\':\n    """"""\n    Parse input arguments\n    """"""\n    parser = argparse.ArgumentParser(description=\'Planenet\')\n    parser.add_argument(\'--task\', dest=\'task\',\n                        help=\'task type\',\n                        default=\'texture\', type=str)\n    parser.add_argument(\'--numOutputPlanes\', dest=\'numOutputPlanes\',\n                        help=\'the number of output planes\',\n                        default=20, type=int)\n    parser.add_argument(\'--dataset\', dest=\'dataset\',\n                        help=\'dataset name\',\n                        default=\'NYU_RGBD\', type=str)\n    parser.add_argument(\'--hybrid\', dest=\'hybrid\',\n                        help=\'hybrid\',\n                        default=\'3\', type=str)\n    parser.add_argument(\'--visualizeImages\', dest=\'visualizeImages\',\n                        help=\'visualize image\',\n                        default=30, type=int)    \n    parser.add_argument(\'--numImages\', dest=\'numImages\',\n                        help=\'the number of images\',\n                        default=30, type=int)\n    parser.add_argument(\'--startIndex\', dest=\'startIndex\',\n                        help=\'start index\',\n                        default=0, type=int)    \n    parser.add_argument(\'--useCache\', dest=\'useCache\',\n                        help=\'use cache\',\n                        default=1, type=int)\n    # parser.add_argument(\'--useCRF\', dest=\'useCRF\',\n    #                     help=\'use crf\',\n    #                     default=0, type=int)\n    # parser.add_argument(\'--useSemantics\', dest=\'useSemantics\',\n    #                     help=\'use semantics\',\n    #                     default=0, type=int)\n    parser.add_argument(\'--useNonPlaneDepth\', dest=\'useNonPlaneDepth\',\n                        help=\'use non-plane depth\',\n                        default=0, type=int)\n    parser.add_argument(\'--imageIndex\', dest=\'imageIndex\',\n                        help=\'image index\',\n                        default=-1, type=int)\n    parser.add_argument(\'--methods\', dest=\'methods\',\n                        help=\'methods\',\n                        default=\'0123\', type=str)\n    parser.add_argument(\'--rootFolder\', dest=\'rootFolder\',\n                        help=\'root folder\',\n                        default=\'/mnt/vision/PlaneNet/\', type=str)\n    \n    args = parser.parse_args()\n    #args.hybrid = \'hybrid\' + args.hybrid\n    args.test_dir = \'evaluate/\' + args.task + \'/\'\n    args.visualizeImages = args.numImages\n    args.result_filename = args.test_dir + \'/results.npy\'\n    \n    # image = cv2.imread(\'evaluate/layout/ScanNet/hybrid3/22_image.png\')\n    # focal_length = estimateFocalLength(image)\n    # print(focal_length)\n    # exit(1)\n    copyTexture(args)\n'"
code/LayeredSceneDecomposition.py,0,"b""import numpy as np\nfrom pystruct.inference import get_installed, inference_ogm, inference_dispatch\nfrom utils import *\n\ndef drawSolution(layeredSegmentations, numPlanes, index):\n    for layer in xrange(layeredSegmentations.shape[-1]):\n        segmentation = layeredSegmentations[:, :, layer]\n        if index >= 0:\n            cv2.imwrite('test/' + str(index) + '_segmentation_' + str(layer) + '.png', drawSegmentationImage(segmentation, blackIndex=numPlanes))\n        else:\n            cv2.imwrite('test/segmentation_' + str(layer) + '.png', drawSegmentationImage(segmentation, blackIndex=numPlanes))\n            pass\n        continue\n    return\n\ndef getConcaveHullProposal(solution, depth, segmentations, planeDepths, NUM_LAYERS=3, NUM_PLANES=15, height=192, width=256):\n    layoutPlanes = []\n    if False:\n        LEFT_WALLS = [0, 5, 6, 11, 18]\n        RIGHT_WALLS = [4, 10, 7, 19]\n        FLOORS = [14]\n        CEILINGS = []    \n        LAYOUT_PLANES = [CEILINGS, FLOORS, LEFT_WALLS + RIGHT_WALLS]\n\n        planeAreaThresholds = [WIDTH * HEIGHT / 400, WIDTH * HEIGHT / 400, WIDTH * HEIGHT / 400]\n\n        for layoutIndex, planeInds in enumerate(LAYOUT_PLANES):\n            planeCandidates = []\n            for planeIndex in planeInds:\n                area = (segmentations[:, :, planeIndex]).sum()\n                #area = (segmentation == planeIndex).sum()\n                if area > planeAreaThresholds[layoutIndex]:\n                    planeCandidates.append(planeIndex)\n                    pass\n                continue\n            if len(planeCandidates) == 0:\n                continue\n            numSelectedPlanes = min(int(layoutIndex == 2) * 2 + 1, len(planeCandidates))\n            planeInds = np.random.choice(planeCandidates, numSelectedPlanes, replace=np.random.random() > 0.5)\n            layoutPlanes += planeInds.tolist()\n            continue    \n    else:\n        conflictAreaThreshold = width * height / 100\n        depthGap = 0.05\n        bestPlaneIndex = -1\n        minNumConflict = width * height\n        for planeIndex in xrange(planeDepths.shape[-1]):\n            planeDepth = planeDepths[:, :, planeIndex]\n            numConflicts = np.logical_and(np.logical_and(planeDepth < depth - depthGap, depth > 1e-4), planeDepth > 1e-4).sum()\n            if numConflicts < conflictAreaThreshold:\n                layoutPlanes.append(planeIndex)\n                pass\n            if numConflicts <= minNumConflict:\n                minNumConflict = numConflicts\n                bestPlaneIndex = planeIndex\n                pass\n            continue\n        if len(layoutPlanes) == 0:\n            layoutPlanes.append(bestPlaneIndex)\n            pass\n        layoutPlanes = np.random.choice(layoutPlanes, min(5 - int(np.floor(pow(np.random.random(), 2) * 5)), len(layoutPlanes)), replace=False)\n        pass\n\n\n    layoutPlanes = np.array(layoutPlanes)\n    layoutPlaneDepths = planeDepths[:, :, layoutPlanes]\n    layoutSegmentation = np.argmin(layoutPlaneDepths, axis=-1)\n    \n    #remainingPlaneInds = np.arange(numPlanes).tolist()\n    proposal = np.split(solution.copy(), NUM_LAYERS, axis=2)\n    proposal = [np.squeeze(v) for v in proposal]\n\n    backgroundMask = np.zeros((height, width), dtype=np.bool)\n    newLayoutSegmentation = layoutSegmentation.copy()\n    for layoutIndex, planeIndex in enumerate(layoutPlanes):\n        print(layoutIndex, planeIndex)\n        newLayoutSegmentation[layoutSegmentation == layoutIndex] = planeIndex\n        for layer in xrange(1, NUM_LAYERS):\n            proposal[layer][proposal[layer] == planeIndex] = NUM_PLANES\n            continue\n        backgroundMask = np.logical_or(backgroundMask, proposal[0] == planeIndex)\n        #remainingPlaneInds.remove(planeIndex)\n        continue\n\n    \n    backgroundMask = np.logical_not(backgroundMask)\n    if backgroundMask.sum() > 0:\n        for layer in xrange(NUM_LAYERS - 1, 0, -1):\n            proposal[layer][backgroundMask] = proposal[layer - 1][backgroundMask]\n            continue\n        pass\n\n    # cv2.imwrite('test/segmentation_0.png', drawSegmentationImage(layoutSegmentation, blackIndex=numPlanes))    \n    # cv2.imwrite('test/segmentation_2.png', drawSegmentationImage(solution[:, :, 0], blackIndex=numPlanes))    \n    # cv2.imwrite('test/segmentation_1.png', drawSegmentationImage(proposal[1], blackIndex=numPlanes))    \n    # exit(1)\n\n    proposal[0] = newLayoutSegmentation\n    proposal = np.stack(proposal, axis=2)\n    return proposal\n\ndef getExpansionProposals(solution, depth, segmentations, planeDepths, NUM_LAYERS=3, NUM_PLANES=15, height=192, width=256):\n \n    layoutPlanes = np.unique(solution[:, :, 0])\n    if NUM_PLANES in layoutPlanes:\n        assert(False)\n        #layoutPlanes = np.delete(layoutPlanes, np.argwhere(layoutPlanes == NUM_PLANES))   \n        pass\n\n    #print((solution[:, :, 0] == 2).sum())\n    #drawSolution(solution, NUM_PLANES, -1)\n    #exit(1)\n    \n    # layoutDepth = np.zeros((height, width))\n    # for layoutPlane in layoutPlanes:\n    #     mask = solution[:, :, 0] == layoutPlane\n    #     layoutDepth[mask] = planeDepths[:, :, layoutPlane][mask]\n    #     continue\n\n    # depthGap = 0.1\n    # smoothLayout = True\n    # if len(layoutPlanes) > 1:\n    #     smoothLayout = ((np.abs(layoutDepth[1:] - layoutDepth[:-1]) > depthGap).sum() + (np.abs(layoutDepth[:, 1:] - layoutDepth[:, :-1]) > depthGap).sum()) > 0\n    #     pass\n\n    # print(smoothLayout)\n    \n    # if smoothLayout == True:\n    #     if len(layoutPlanes) == NUM_PLANES:\n    #         return []\n    #     while True:\n    #         selectedPlaneIndex = np.random.randint(NUM_PLANES)\n    #         if selectedPlaneIndex in layoutPlanes:\n    #             continue\n    #         break\n    # else:\n    if True:\n        #selectedPlaneIndex = np.random.randint(NUM_PLANES)\n        #selectedPlaneIndex = 3\n        layoutProposal = getConcaveHullProposal(solution, depth, segmentations, planeDepths, NUM_LAYERS=3, NUM_PLANES=15, height=192, width=256)\n        validLayoutPlanes = np.unique(layoutProposal[:, :, 0])\n\n\n        if len(validLayoutPlanes) == len(layoutPlanes):\n            while True:\n                selectedPlaneIndex = np.random.randint(NUM_PLANES)\n                if selectedPlaneIndex in layoutPlanes:\n                    continue\n                break\n            smoothLayout = True\n        else:\n            invalidLayoutPlanes = []\n            for planeIndex in layoutPlanes:\n                if planeIndex not in validLayoutPlanes:\n                    invalidLayoutPlanes.append(planeIndex)\n                    pass\n                continue\n            selectedPlaneIndex = np.random.choice(invalidLayoutPlanes)\n\n            print('expand layout plane', selectedPlaneIndex)\n            proposals = [layoutProposal, ]\n            for layer in xrange(1, NUM_LAYERS):\n                proposal = np.split(layoutProposal.copy(), NUM_LAYERS, axis=2)    \n                proposal = [np.squeeze(v) for v in proposal]\n\n                for otherLayer in xrange(1, NUM_LAYERS):\n                    if otherLayer == layer:\n                        continue\n                    mask = proposal[otherLayer] == selectedPlaneIndex\n                    if mask.sum() == 0:\n                        continue\n                    proposal[otherLayer][mask] = NUM_PLANES\n                    continue\n                proposal[layer].fill(selectedPlaneIndex)\n                proposals.append(np.stack(proposal, axis=-1))\n                continue\n            return proposals\n        pass\n\n    print('expand plane', selectedPlaneIndex)\n    \n    \n    proposals = []\n    for layer in xrange(NUM_LAYERS):\n        proposal = np.split(solution.copy(), NUM_LAYERS, axis=2)    \n        proposal = [np.squeeze(v) for v in proposal]\n\n        for otherLayer in xrange(NUM_LAYERS):\n            if otherLayer == layer:\n                continue\n            mask = proposal[otherLayer] == selectedPlaneIndex\n            if mask.sum() == 0:\n                continue\n            if otherLayer == 0:\n                layoutPlanes = np.delete(layoutPlanes, np.argwhere(layoutPlanes == selectedPlaneIndex))\n                layoutPlaneDepths = planeDepths[:, :, layoutPlanes]\n                layoutSegmentation = np.argmin(layoutPlaneDepths, axis=-1)\n                newLayoutSegmentation = layoutSegmentation.copy()\n                for layoutIndex, planeIndex in enumerate(layoutPlanes):\n                    newLayoutSegmentation[layoutSegmentation == layoutIndex] = planeIndex\n                    continue\n                proposal[0] = newLayoutSegmentation\n            else:\n                proposal[otherLayer][mask] = NUM_PLANES\n                pass\n            continue\n        proposal[layer].fill(selectedPlaneIndex)\n        proposals.append(np.stack(proposal, axis=-1))\n        continue\n    \n    return proposals\n\ndef getLayerSwapProposals(solution, NUM_LAYERS=3, NUM_PLANES=15, height=192, width=256):\n    proposals = []\n    for layer in xrange(1, NUM_LAYERS):\n        proposal = np.split(solution.copy(), NUM_LAYERS, axis=2)    \n        proposal = [np.squeeze(v) for v in proposal]\n\n        layerPlanes = np.unique(proposal[layer])\n        if len(layerPlanes) == 0:\n            continue\n        selectedPlaneIndex = np.random.choice(layerPlanes)\n        while True:\n            otherLayer = np.random.randint(NUM_LAYERS)\n            if otherLayer == layer:\n                continue\n            break\n        \n        if layer != 1:\n            continue\n        else:\n            selectedPlaneIndex = 2\n            otherLayer = 2\n            pass\n\n            \n        mask = proposal[layer] == selectedPlaneIndex\n        proposal[layer][mask] = NUM_PLANES\n        proposal[otherLayer][mask] = selectedPlaneIndex\n        proposals.append(np.stack(proposal, axis=-1))\n        continue\n    \n    return proposals\n    \n\n    \ndef getProposals(solution, planes, segmentation, segmentations, planeDepths, iteration, NUM_LAYERS=3, NUM_PLANES=15, height=192, width=256):\n\n    numProposals = 3\n    if iteration == 0:\n        proposal = np.full((height, width, NUM_LAYERS), NUM_PLANES)\n        proposal[:, :, 0] = segmentation\n        return [proposal, ]\n    elif iteration == 1:\n        return [solution, getConcaveHullProposal(solution, depth, segmentations, planeDepths, NUM_LAYERS, NUM_PLANES, height, width)]\n    elif iteration == 2:\n        return [solution] + getExpansionProposals(solution, depth, segmentations, planeDepths, NUM_LAYERS, NUM_PLANES, height, width)\n    elif iteration == 3:\n        return [solution] + getLayerSwapProposals(solution, NUM_LAYERS, NUM_PLANES, height, width)\n    elif iteration == 4:\n        return [solution] + getExpansionProposals(solution, depth, segmentations, planeDepths, NUM_LAYERS, NUM_PLANES, height, width)\n    elif iteration == 5:\n        return [solution] + getLayerSwapProposals(solution, NUM_LAYERS, NUM_PLANES, height, width)\n    return\n    \ndef decompose(image, depth, normal, info, planes, segmentation):\n    NUM_PLANES = planes.shape[0]\n    #segmentation[segmentation == numPlanes] = \n    NUM_LAYERS = 3\n    \n    height = depth.shape[0]\n    width = depth.shape[1]\n    \n    segmentations = (np.expand_dims(segmentation, -1) == np.arange(NUM_PLANES).reshape([1, 1, -1])).astype(np.float32)\n    \n    planeDepths = calcPlaneDepths(planes, width, height, info)\n\n    # for planeIndex in xrange(NUM_PLANES):\n    #     cv2.imwrite('test/depth_' + str(planeIndex) + '.png', drawDepthImage(planeDepths[:, :, planeIndex]))\n    #     continue\n    \n    allDepths = np.concatenate([planeDepths, np.zeros((height, width, 1))], axis=2)\n    \n    camera = getCameraFromInfo(info)\n    urange = (np.arange(width, dtype=np.float32) / (width) * (camera['width']) - camera['cx']) / camera['fx']\n    urange = urange.reshape(1, -1).repeat(height, 0)\n    vrange = (np.arange(height, dtype=np.float32) / (height) * (camera['height']) - camera['cy']) / camera['fy']\n    vrange = vrange.reshape(-1, 1).repeat(width, 1)\n    \n    X = depth * urange\n    Y = depth\n    Z = -depth * vrange\n\n\n    normals = normal.reshape((-1, 3))\n    normals = normals / np.maximum(np.linalg.norm(normals, axis=-1, keepdims=True), 1e-4)\n    validMask = np.logical_and(np.linalg.norm(normals, axis=-1) > 1e-4, depth.reshape(-1) > 1e-4)\n    \n    points = np.stack([X, Y, Z], axis=2).reshape(-1, 3)\n    \n    planesD = np.linalg.norm(planes, axis=1, keepdims=True)\n    planeNormals = planes / np.maximum(planesD, 1e-4)\n\n    distanceCostThreshold = 0.1\n    distanceCost = np.abs(np.tensordot(points, planeNormals, axes=([1, 1])) - np.reshape(planesD, [1, -1])) / distanceCostThreshold\n\n    #valid_normals = normals[validMask]\n    normalCostThreshold = 1 - np.cos(np.deg2rad(30))        \n    normalCost = (1 - np.abs(np.tensordot(normals, planeNormals, axes=([1, 1])))) / normalCostThreshold\n\n    normalWeight = 1    \n    \n    unaryCost = distanceCost + normalCost * normalWeight\n    unaryCost *= np.expand_dims(validMask.astype(np.float32), -1)\n    unaryCost = np.concatenate([unaryCost, np.full((unaryCost.shape[0], 1), 100)], axis=1)\n    #unaryCost = unaryCost.reshape((height * width, -1))\n\n\n    nodes = np.arange(height * width).reshape((height, width))    \n    \n    image = image.astype(np.float32)\n    colors = image.reshape((-1, 3))\n    deltas = [(0, 1), (1, 0)]    \n    intensityDifferenceSum = 0.0\n    intensityDifferenceCount = 0\n    for delta in deltas:\n        deltaX = delta[0]\n        deltaY = delta[1]\n        partial_nodes = nodes[max(-deltaY, 0):min(height - deltaY, height), max(-deltaX, 0):min(width - deltaX, width)].reshape(-1)\n        intensityDifferenceSum += np.sum(pow(colors[partial_nodes] - colors[partial_nodes + (deltaY * width + deltaX)], 2))\n        intensityDifferenceCount += partial_nodes.shape[0]\n        continue\n    intensityDifference = intensityDifferenceSum / intensityDifferenceCount\n    maxDepthDiff = 0.3\n    depthGap = 0.05\n    \n    solution = []\n    for iteration in xrange(6):\n        if os.path.exists('test/solution_' + str(iteration) + '.npy') and iteration <= 4:\n            solution = np.load('test/solution_' + str(iteration) + '.npy')\n            continue\n\n        proposals = getProposals(solution, planes, segmentation, segmentations, planeDepths, iteration, NUM_LAYERS=NUM_LAYERS, NUM_PLANES=NUM_PLANES, height=height, width=width)\n\n        numProposals = len(proposals)\n\n        if numProposals == 1:\n            solution = proposals[0]\n            continue\n        \n        proposals = [proposals[0]]\n        numProposals = len(proposals)\n                \n        for proposalIndex, proposal in enumerate(proposals):\n            drawSolution(proposal, NUM_PLANES, proposalIndex)\n            continue\n\n        #if iteration == 2:\n        #exit(1)\n            \n        visibleSegmentations = []\n        for proposal in proposals:\n            visibleSegmentation = proposal[:, :, 0].copy()\n            for layer in xrange(1, NUM_LAYERS):\n                mask = proposal[:, :, layer] < NUM_PLANES\n                visibleSegmentation[mask] = proposal[:, :, layer][mask]\n                continue\n            visibleSegmentations.append(visibleSegmentation)\n            continue\n        visibleSegmentations = np.stack(visibleSegmentations, axis=-1).reshape((-1, numProposals))\n\n        #cv2.imwrite('test/segmentation_0.png', drawSegmentationImage(visibleSegmentations[:, 0].reshape((height, width)), blackIndex=NUM_PLANES))\n        #cv2.imwrite('test/segmentation_1.png', drawSegmentationImage(visibleSegmentations[:, 1].reshape((height, width)), blackIndex=NUM_PLANES))        \n        \n        unaries = readProposalInfo(unaryCost, visibleSegmentations)\n\n        proposalDepths = []\n        for proposal in proposals:\n            proposalDepths.append(readProposalInfo(allDepths, proposal))\n            continue\n        proposalDepths = np.stack(proposalDepths, axis=-1)\n        proposalDepths = proposalDepths.reshape((width * height, NUM_LAYERS, numProposals))\n\n        conflictDepthMask = np.zeros((width * height, numProposals), dtype=np.bool)\n        for layer in xrange(1, NUM_LAYERS):\n            conflictDepthMask = np.logical_or(conflictDepthMask, np.logical_and(proposalDepths[:, layer, :] > proposalDepths[:, layer - 1, :] + depthGap, proposalDepths[:, layer - 1, :] > 1e-4))\n            continue\n        unaries += conflictDepthMask.astype(np.float32) * 100\n        \n        #cv2.imwrite('test/mask_0.png', drawMaskImage((unaries[:, 1] - unaries[:, 0]).reshape((height, width)) / 2 + 0.5))\n        #exit(1)\n        #print((unaries[:, 1] - unaries[:, 0]).min())        \n\n        \n        #print((unaries[:, 1] - unaries[:, 0]).max())\n        #print((unaries[:, 1] - unaries[:, 0]).min())        \n        \n        proposals = np.stack(proposals, axis=-1).reshape((width * height, NUM_LAYERS, numProposals))\n\n        #empty background cost\n        unaries += (proposals[:, 0, :] == NUM_PLANES).astype(np.float32) * 100\n\n        #print((unaries[:, 1] - unaries[:, 0]).max())\n        #print((unaries[:, 1] - unaries[:, 0]).min())        \n        #exit(1)\n        #cv2.imwrite('test/segmentation.png', drawSegmentationImage(unaries.reshape((height, width, -1)), blackIndex=numOutputPlanes))\n        #cv2.imwrite('test/mask_0.png', drawMaskImage((unaries[:, 1] - unaries[:, 0]).reshape((height, width)) / 2 + 0.5))\n        #exit(1)\n        \n        edges = []\n        edges_features = []\n\n        for deltaIndex, delta in enumerate(deltas):\n            deltaX = delta[0]\n            deltaY = delta[1]\n            partial_nodes = nodes[max(-deltaY, 0):min(height - deltaY, height), max(-deltaX, 0):min(width - deltaX, width)].reshape(-1)\n            edges.append(np.stack([partial_nodes, partial_nodes + (deltaY * width + deltaX)], axis=1))\n\n            \n            #pairwise_cost = np.zeros((partial_nodes.shape[0], numProposals, numProposals))\n\n            labels_1 = np.expand_dims(proposals[partial_nodes], -1)\n            labels_2 = np.expand_dims(proposals[partial_nodes + (deltaY * width + deltaX)], -2)\n            labelDiff = (labels_1 != labels_2).astype(np.float32)\n\n            depth_1 = np.expand_dims(proposalDepths[partial_nodes], -1)\n            depth_2 = np.expand_dims(proposalDepths[partial_nodes + (deltaY * width + deltaX)], -2)\n\n            visibleLabels_1 = np.expand_dims(visibleSegmentations[partial_nodes], -1)\n            visibleLabels_2 = np.expand_dims(visibleSegmentations[partial_nodes + (deltaY * width + deltaX)], -2)\n            \n            \n            emptyMask_1 = np.logical_and(depth_1 > 1e-4, depth_2 < 1e-4)\n            emptyMask_2 = np.logical_and(depth_1 < 1e-4, depth_2 > 1e-4)\n            emptyMask = np.logical_or(emptyMask_1, emptyMask_2)\n\n            cutMask = (labelDiff - (np.expand_dims(labels_1, -3) != np.expand_dims(labels_2, -4)).astype(np.float32).min(-3)) * (labels_1 < NUM_PLANES).astype(np.float32)\n\n            \n            visibleEmptyMask = np.logical_or(np.logical_and(emptyMask_1, (labels_1 == np.expand_dims(visibleLabels_1, -3))), np.logical_and(emptyMask_2, (labels_2 == np.expand_dims(visibleLabels_2, -3))))\n            invisibleEmptyMask = np.logical_and(emptyMask, np.logical_not(visibleEmptyMask))\n            \n            depthDiff = np.abs(depth_1 - depth_2) / maxDepthDiff * (1 - emptyMask) + invisibleEmptyMask * (0.05 / maxDepthDiff)\n\n\n            visibleLabelDiff = (visibleLabels_1 != visibleLabels_2)\n            visibleLabelDiff = np.logical_or(visibleEmptyMask.max(1), visibleLabelDiff).astype(np.float32)\n            \n            colorDiff = np.sum(pow(colors[partial_nodes] - colors[partial_nodes + (deltaY * width + deltaX)], 2), axis=-1)\n            #depth_diff = np.clip(np.abs(depth_diff) / maxDepthDiff, 0, 1)\n            #depth_2_2 = proposalDepths[max(deltaY, 0):min(height + deltaY, height), max(deltaX, 0):min(width + deltaX, width)].reshape((-1, numProposals))\n            \n            pairwise_cost = (labelDiff * depthDiff).sum(1) + visibleLabelDiff * np.reshape(0.02 + np.exp(-colorDiff / intensityDifference), [-1, 1, 1])\n            np.reshape(1 + 45 * np.exp(-colorDiff / intensityDifference), [-1, 1, 1])\n            #pairwise_cost = np.expand_dims(pairwise_matrix, 0) * np.ones(np.reshape(1 + 45 * np.exp(-colorDiff / np.maximum(intensityDifference[partial_nodes], 1e-4)), [-1, 1, 1]).shape)\n            edges_features.append(-pairwise_cost)\n\n            #print(pairwise_cost.shape)\n            #print(pairwise_cost.max())\n\n            debug = False\n            if debug:\n                cv2.imwrite('test/cost_diff.png', drawMaskImage((unaries[:, 1] - unaries[:, 0]).reshape((height, width)) / 2 + 0.5))\n\n                #exit(1)\n                if deltaIndex == 0:\n                    cv2.imwrite('test/cost_color.png', drawMaskImage((visibleLabelDiff * np.reshape(0.02 + np.exp(-colorDiff / intensityDifference), (-1, 1, 1)))[:, 0, 1].reshape((height - 1, width))))\n\n                    #cv2.imwrite('test/segmentation.png', drawSegmentationImage(proposals[partial_nodes, 0, 1].reshape((height - 1, width))))\n                    #diff = (labelDiff * depthDiff).reshape((height - 1, width, NUM_LAYERS, numProposals, numProposals))\n                    diff = (invisibleEmptyMask).reshape((height - 1, width, NUM_LAYERS, numProposals, numProposals))\n                    #diff = (labelDiff).reshape((height - 1, width, NUM_LAYERS, numProposals, numProposals))\n\n                    for proposalIndex_1 in xrange(numProposals):\n                        for proposalIndex_2 in xrange(numProposals):\n                            for layer in xrange(NUM_LAYERS):\n                                cv2.imwrite('test/cost_' + str(proposalIndex_1) + str(proposalIndex_2) + str(layer) + str(deltaIndex) + '.png', drawMaskImage(diff[:, :, layer, proposalIndex_1, proposalIndex_2]))\n                                continue\n                            continue\n                        continue\n                if deltaIndex == 1 and True:\n                    #cv2.imwrite('test/segmentation.png', drawSegmentationImage(proposals[partial_nodes, 0, 1].reshape((height - 1, width))))\n                    \n                    #diff = (labelDiff * depthDiff).reshape((height, width - 1, NUM_LAYERS, numProposals, numProposals))\n                    diff = (invisibleEmptyMask).reshape((height, width - 1, NUM_LAYERS, numProposals, numProposals))\n                    #diff = (labelDiff).reshape((height - 1, width, NUM_LAYERS, numProposals, numProposals))\n\n                    for proposalIndex_1 in xrange(numProposals):\n                        for proposalIndex_2 in xrange(numProposals):\n                            for layer in xrange(NUM_LAYERS):\n                                cv2.imwrite('test/cost_' + str(proposalIndex_1) + str(proposalIndex_2) + str(layer) + str(deltaIndex) + '.png', drawMaskImage(diff[:, :, layer, proposalIndex_1, proposalIndex_2]))\n                                continue\n                            continue\n                        continue\n                    #exit(1)\n                pass\n            continue\n        \n        edges = np.concatenate(edges, axis=0)\n        edges_features = np.concatenate(edges_features, axis=0)\n\n\n        labelCost = True\n        if labelCost and numProposals > 1:\n            labelCosts = np.full(NUM_PLANES * NUM_LAYERS, numProposals, 10000)\n            labelCosts[:, 0] = 0\n            labelCosts[:, 1] = 1000\n            unaries = np.concatenate([unaries, labelCosts], axis=0)\n\n        solution, energy = inference_ogm(-unaries * 0.1, edges_features, edges, return_energy=True, alg='trw')\n        print(energy)\n\n        cv2.imwrite('test/solution_' + str(iteration) + '.png', drawSegmentationImage(solution.reshape((height, width))))\n        \n        solution = np.tile(solution.reshape([height * width, 1, 1]), [1, NUM_LAYERS, 1])\n        solution = readProposalInfo(proposals, solution).reshape((height, width, NUM_LAYERS))\n\n        np.save('test/solution_' + str(iteration) + '.npy', solution)\n        continue\n    \n    return solution\n\n\nplanes = np.load('test/planes.npy')\nsegmentation = np.load('test/segmentation.npy')\nimage = cv2.imread('test/image.png')\ndepth = np.load('test/depth.npy')\nnormal = np.load('test/normal.npy')\ninfo = np.load('test/info.npy')\nnumPlanes = planes.shape[0]\n# cv2.imwrite('test/segmentation.png', drawSegmentationImage(segmentation, blackIndex=numPlanes))\n# cv2.imwrite('test/depth.png', drawDepthImage(depth))\n# for planeIndex in xrange(numPlanes):\n#     cv2.imwrite('test/mask_' + str(planeIndex) + '.png', drawMaskImage(segmentation == planeIndex))\n#     continue\n# exit(1)\nwidth = 256\nheight = 192\nsegmentation = cv2.resize(segmentation, (width, height), interpolation=cv2.INTER_NEAREST)\ndepth = cv2.resize(depth, (width, height))\nnormal = cv2.resize(normal, (width, height))\nimage = cv2.resize(image, (width, height))\nlayeredSegmentations = decompose(image, depth, normal, info, planes, segmentation)\ndrawSolution(layeredSegmentations, numPlanes, -1)\n"""
code/PlaneStatisticsGlobal.py,0,"b""import numpy as np\nimport PIL.Image\nimport random\nimport scipy.ndimage as ndimage\nimport pickle\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\nimport copy\nimport skimage.measure\nimport os\n\nclass PlaneStatistics:\n  def __init__(self, width, height, stride):\n    self.width = width\n    self.height = height\n    self.stride = stride\n    self.planeParametersArray = []\n    self.predefinedPlanes = []\n    self.residualImages = np.zeros((4, self.height, self.width))\n    self.positivePlaneThreshold = self.stride * self.stride * 0.3\n    self.planeAreaThreshold = 40 * 30\n    return\n  \n  def addPlaneInfo(self, normalFilename, maskFilename, depthFilename):\n    normals = np.array(PIL.Image.open(normalFilename)).astype(np.float) / 255 * 2 - 1\n    norm = np.linalg.norm(normals, 2, 2)\n    for c in xrange(3):\n      normals[:, :, c] /= norm\n      continue\n    \n    invalidMask = (np.array(PIL.Image.open(maskFilename)) < 128)\n\n    sampleRatio = 3\n    azimuthAngleImage = (-np.round(np.rad2deg(np.arctan2(normals[:, :, 1], normals[:, :, 0])) / sampleRatio).astype(np.int) * sampleRatio + 360) % 360\n\n    altitudeAngleImage = (np.round(np.rad2deg(np.arctan2(np.sign(-normals[:, :, 1]) * np.linalg.norm(normals[:, :, :2], 2, 2), normals[:, :, 2])) / sampleRatio).astype(np.int) * sampleRatio + 360) % 360\n\n    orthogonalThreshold = 5\n    orthogonalAzimuthMask_1 = ((azimuthAngleImage - 0) < orthogonalThreshold) + ((360 - azimuthAngleImage) < orthogonalThreshold)\n    orthogonalAzimuthMask_2 = np.abs(azimuthAngleImage - 180) < orthogonalThreshold\n    azimuthAngleImage[orthogonalAzimuthMask_1] = 0\n    azimuthAngleImage[orthogonalAzimuthMask_2] = 180\n    altitudeAngleImage[orthogonalAzimuthMask_1 + orthogonalAzimuthMask_2] = 0\n\n    orthogonalAltitudeMask_1 = ((altitudeAngleImage - 0) < orthogonalThreshold) + ((360 - altitudeAngleImage) < orthogonalThreshold)\n    orthogonalAltitudeMask_2 = np.abs(altitudeAngleImage - 180) < orthogonalThreshold\n    altitudeAngleImage[orthogonalAltitudeMask_1] = 0\n    altitudeAngleImage[orthogonalAltitudeMask_2] = 180\n    azimuthAngleImage[orthogonalAltitudeMask_1 + orthogonalAltitudeMask_2] = 0\n\n    azimuthAngleImage[invalidMask] = 360\n    altitudeAngleImage[invalidMask] = 360\n    \n    \n    sampleRatio = 5\n    depths = np.array(PIL.Image.open(depthFilename)).astype(np.float) / 1000\n    focalLength = 517.97\n    urange = np.arange(self.width).reshape(1, -1).repeat(self.height, 0) - self.width * 0.5\n    vrange = np.arange(self.height).reshape(-1, 1).repeat(self.width, 1) - self.height * 0.5\n    X = depths / focalLength * urange\n    Y = depths\n    Z = -depths / focalLength * vrange\n    d = -(normals[:, :, 0] * X + normals[:, :, 1] * Y + normals[:, :, 2] * Z)\n    dImage = np.round(d / (10. / 360) / sampleRatio).astype(np.int) * sampleRatio\n    dImage[dImage < 0] = 0\n    dImage[dImage > 360] = 360\n    dImage[invalidMask] = 360    \n\n    valueMaps = [azimuthAngleImage, altitudeAngleImage, dImage]\n    planes = []\n    values_1, counts_1 = np.unique(valueMaps[0], return_counts=True)\n\n    self.mask = np.zeros((self.height, self.width)) == 1\n    \n    for index_1, value_1 in enumerate(values_1):\n      if counts_1[index_1] < self.planeAreaThreshold or value_1 == 360:\n        continue\n      mask_1 = valueMaps[0] == value_1\n\n      values_2, counts_2 = np.unique(valueMaps[1][mask_1], return_counts=True)\n      for index_2, value_2 in enumerate(values_2):\n        if counts_2[index_2] < self.planeAreaThreshold or value_2 == 360:\n          continue\n        mask_2 = mask_1 * (valueMaps[1] == value_2)\n        values_3, counts_3 = np.unique(valueMaps[2][mask_2], return_counts=True)\n        for index_3, value_3 in enumerate(values_3):\n          if counts_3[index_3] < self.planeAreaThreshold or value_3 == 360:\n            continue\n          mask_3 = mask_2 * (valueMaps[2] == value_3)\n          mask_3 = ndimage.binary_erosion(mask_3).astype(mask_3.dtype)\n          if mask_3.sum() < self.planeAreaThreshold:\n            continue\n\n          normal = np.array([normals[:, :, 0][mask_3].mean(), normals[:, :, 1][mask_3].mean(), normals[:, :, 2][mask_3].mean()])\n          normal /= np.linalg.norm(normal, 2)\n          dPlane = (-(normal[0] * X + normal[1] * Y + normal[2] * Z))[mask_3].mean()\n\n          self.mask += mask_3\n          \n          azimuth = np.arctan2(-normal[1], normal[0])\n          altitude = np.arctan2(np.sign(-normal[1]) * np.linalg.norm(normal[:2]), normal[2])\n          #planes.append(((azimuth, altitude, dPlane), mask_3))\n          planes.append(((-normal[0] * dPlane, -normal[1] * dPlane, -normal[2] * dPlane), mask_3))\n          \n          # azimuthAngleImage = np.arctan2(-normals[:, :, 1], normals[:, :, 0])\n          # altitudeAngleImage = np.arctan2(np.sign(-normals[:, :, 1]) * np.linalg.norm(normals[:, :, :2], 2, 2), normals[:, :, 2])\n\n          # dImage = -(normals[:, :, 0] * X + normals[:, :, 1] * Y + normals[:, :, 2] * Z)\n          # dImage *= self.depthScaleFactor\n\n          #PIL.Image.fromarray(mask_1.astype(np.uint8) * 255).save('test/mask_1.png')\n          #PIL.Image.fromarray(mask_2.astype(np.uint8) * 255).save('test/mask_2.png')\n          #PIL.Image.fromarray(mask_3.astype(np.uint8) * 255).save('test/mask_3.png')\n          continue\n        continue\n      continue\n\n    for plane in planes:\n      planeParameters = plane[0]\n      self.planeParametersArray.append(planeParameters)      \n      continue\n\n\n\n    if False:\n      self.planeParametersArray = np.array(self.planeParametersArray)\n      planeNormals = copy.deepcopy(self.planeParametersArray)\n      planeD = np.linalg.norm(planeNormals, 2, 1)\n      for c in xrange(3):\n        planeNormals[:, c] /= planeD\n        continue\n      \n      normalXYZ = np.array([urange / focalLength, np.ones(urange.shape), -vrange / focalLength])\n\n      normalXYZ = np.dot(normalXYZ.transpose([1, 2, 0]), planeNormals.transpose())\n      normalXYZ = np.reciprocal(normalXYZ)\n\n      XYZ = np.array([X, Y, Z])\n      planeXYZ = np.zeros(XYZ.shape)\n      for i in xrange(self.planeParametersArray.shape[0]):\n\n        mask = planes[i][1]\n        planeY = normalXYZ[:, :, i] * planeD[i]\n        planeX = planeY * urange / focalLength\n        planeZ = -planeY * vrange / focalLength\n\n        planeXYZ[0][mask] = planeX[mask]\n        planeXYZ[1][mask] = planeY[mask]\n        planeXYZ[2][mask] = planeZ[mask]\n        continue\n\n      for c in xrange(3):\n        inputImage = XYZ[c]\n        cMin = inputImage.min()\n        cMax = inputImage.max()\n        PIL.Image.fromarray(((inputImage - cMin) / (cMax - cMin) * 255).astype(np.uint8)).save('test/' + str(c) + '.png')\n        reconstructed = planeXYZ[c]\n        PIL.Image.fromarray(((reconstructed - cMin) / (cMax - cMin) * 255).astype(np.uint8)).save('test/' + str(c) + '_reconstructed.png')\n        continue\n\n\n      planeImage = np.zeros((self.height, self.width, 3))\n      for plane in planes:\n        mask = plane[1]\n        for c in xrange(3):\n          planeImage[:, :, c][mask] = random.randint(0, 255)\n          #planeImage[:, :, c][mask] = max(min(round((plane[0][c] + 1) / 2 * 255), 255), 0)\n          continue\n        continue\n      PIL.Image.fromarray(planeImage.astype(np.uint8)).save('test/plane.png')\n      exit(1)\n      pass\n    \n  def generatePlaneGroundTruthFitting(self, normalFilename, maskFilename, depthFilename, useGlobal = True):\n    normals = np.array(PIL.Image.open(normalFilename)).astype(np.float) / 255 * 2 - 1\n\n    height = self.height\n    width = self.width\n    \n    norm = np.linalg.norm(normals, 2, 2)\n    for c in xrange(3):\n      normals[:, :, c] /= norm\n      continue\n\n\n    depths = np.array(PIL.Image.open(depthFilename)).astype(np.float) / 1000\n    focalLength = 517.97\n    urange = np.arange(width).reshape(1, -1).repeat(height, 0) - width * 0.5\n    vrange = np.arange(height).reshape(-1, 1).repeat(width, 1) - height * 0.5\n    X = depths / focalLength * urange\n    Y = depths\n    Z = -depths / focalLength * vrange\n\n    invalidMask = (np.array(PIL.Image.open(maskFilename)) < 128)\n    invalidMask += depths > 10\n  \n    #if outputFolder != None:\n    #XYZ = np.array([X, Y, Z])\n    diffNormals = np.ones((height, width)) * (-1)\n    segmentationNormals = np.zeros((height, width))\n\n    diffDepths = np.ones(depths.shape) * 1000000\n    segmentationDepths = np.zeros((height, width))\n\n    diffD = np.ones((height, width)) * 1000000\n    segmentationD = np.zeros((height, width))\n    \n    ranges = np.array([urange / focalLength, np.ones(urange.shape), -vrange / focalLength]).transpose([1, 2, 0])\n\n    predefinedPlanes = self.predefinedPlanes\n    for planeIndex, plane in enumerate(predefinedPlanes):\n      planeD = np.linalg.norm(plane)\n      planeNormal = -plane / planeD\n\n      mask = np.dot(normals, planeNormal) > diffNormals\n      diffNormals[mask] = np.dot(normals, planeNormal)[mask]\n      segmentationNormals[mask] = planeIndex\n      \n      normalXYZ = np.dot(ranges, planeNormal)\n      normalXYZ = np.reciprocal(normalXYZ)\n      planeY = -normalXYZ * planeD\n\n      mask = pow(planeY - depths, 2) < diffDepths\n      diffDepths[mask] = pow(planeY - depths, 2)[mask]\n      segmentationDepths[mask] = planeIndex\n\n      D = pow(X * planeNormal[0] + Y * planeNormal[1] + Z * planeNormal[2] + planeD, 2)\n      mask = D < diffD\n      diffD[mask] = D[mask]\n      segmentationD[mask] = planeIndex\n      continue\n\n    segmentation = segmentationD\n\n    residualPlanes = []\n    segmentationImage = np.zeros((self.height, self.width, 3))\n    for clusterIndex in xrange(self.numClusters):\n      mask = segmentation == clusterIndex\n      mask = ndimage.binary_erosion(mask).astype(mask.dtype)\n      if mask.sum() < self.planeAreaThreshold:\n        continue\n      normal = np.array([normals[:, :, 0][mask].mean(), normals[:, :, 1][mask].mean(), normals[:, :, 2][mask].mean()])\n      normal /= np.linalg.norm(normal, 2)\n      dPlane = (-(normal[0] * X + normal[1] * Y + normal[2] * Z))[mask].mean()\n      predefinedPlane = predefinedPlanes[clusterIndex]\n      residualPlanes.append((clusterIndex, -normal[0] * dPlane - predefinedPlane[0], -normal[1] * dPlane - predefinedPlane[1], -normal[2] * dPlane - predefinedPlane[2]))\n      segmentationImage[mask] = np.random.randint(255, size = (3, ))\n      continue\n    PIL.Image.fromarray(segmentationImage.astype(np.uint8)).save('test/segmentation.png')\n    exit(1)\n    planeFilename = normalFilename.replace('norm_camera.png', 'plane_global.npy')\n    np.save(planeFilename, residualPlanes)\n\n    return\n  \n\n  def generatePlaneGroundTruth(self, normalFilename, maskFilename, depthFilename, useGlobal = True):\n    planeFilename = normalFilename.replace('norm_camera.png', 'plane_global.npy')\n    if os.path.exists(planeFilename):\n      self.planeFilenames.append(planeFilename)\n      return\n    \n    normals = np.array(PIL.Image.open(normalFilename)).astype(np.float) / 255 * 2 - 1\n    norm = np.linalg.norm(normals, 2, 2)\n    for c in xrange(3):\n      normals[:, :, c] /= norm\n      continue\n    \n    invalidMask = (np.array(PIL.Image.open(maskFilename)) < 128)\n\n    sampleRatio = 3\n    azimuthAngleImage = (-np.round(np.rad2deg(np.arctan2(normals[:, :, 1], normals[:, :, 0])) / sampleRatio).astype(np.int) * sampleRatio + 360) % 360\n\n    altitudeAngleImage = (np.round(np.rad2deg(np.arctan2(np.sign(-normals[:, :, 1]) * np.linalg.norm(normals[:, :, :2], 2, 2), normals[:, :, 2])) / sampleRatio).astype(np.int) * sampleRatio + 360) % 360\n\n    orthogonalThreshold = 5\n    orthogonalAzimuthMask_1 = ((azimuthAngleImage - 0) < orthogonalThreshold) + ((360 - azimuthAngleImage) < orthogonalThreshold)\n    orthogonalAzimuthMask_2 = np.abs(azimuthAngleImage - 180) < orthogonalThreshold\n    azimuthAngleImage[orthogonalAzimuthMask_1] = 0\n    azimuthAngleImage[orthogonalAzimuthMask_2] = 180\n    altitudeAngleImage[orthogonalAzimuthMask_1 + orthogonalAzimuthMask_2] = 0\n\n    orthogonalAltitudeMask_1 = ((altitudeAngleImage - 0) < orthogonalThreshold) + ((360 - altitudeAngleImage) < orthogonalThreshold)\n    orthogonalAltitudeMask_2 = np.abs(altitudeAngleImage - 180) < orthogonalThreshold\n    altitudeAngleImage[orthogonalAltitudeMask_1] = 0\n    altitudeAngleImage[orthogonalAltitudeMask_2] = 180\n    azimuthAngleImage[orthogonalAltitudeMask_1 + orthogonalAltitudeMask_2] = 0\n\n    azimuthAngleImage[invalidMask] = 360\n    altitudeAngleImage[invalidMask] = 360\n    \n    sampleRatio = 5\n    depths = np.array(PIL.Image.open(depthFilename)).astype(np.float) / 1000\n    focalLength = 517.97\n    urange = np.arange(self.width).reshape(1, -1).repeat(self.height, 0) - self.width * 0.5\n    vrange = np.arange(self.height).reshape(-1, 1).repeat(self.width, 1) - self.height * 0.5\n    X = depths / focalLength * urange\n    Y = depths\n    Z = -depths / focalLength * vrange\n    d = -(normals[:, :, 0] * X + normals[:, :, 1] * Y + normals[:, :, 2] * Z)\n    dImage = np.round(d / (10. / 360) / sampleRatio).astype(np.int) * sampleRatio\n    dImage[dImage < 0] = 0\n    dImage[dImage > 360] = 360\n    dImage[invalidMask] = 360    \n\n    valueMaps = [azimuthAngleImage, altitudeAngleImage, dImage]\n    planes = []\n    values_1, counts_1 = np.unique(valueMaps[0], return_counts=True)\n\n    for index_1, value_1 in enumerate(values_1):\n      if counts_1[index_1] < self.planeAreaThreshold or value_1 == 360:\n        continue\n      mask_1 = valueMaps[0] == value_1\n\n      values_2, counts_2 = np.unique(valueMaps[1][mask_1], return_counts=True)\n      for index_2, value_2 in enumerate(values_2):\n        if counts_2[index_2] < self.planeAreaThreshold or value_2 == 360:\n          continue\n        mask_2 = mask_1 * (valueMaps[1] == value_2)\n        values_3, counts_3 = np.unique(valueMaps[2][mask_2], return_counts=True)\n        for index_3, value_3 in enumerate(values_3):\n          if counts_3[index_3] < self.planeAreaThreshold or value_3 == 360:\n            continue\n          mask_3 = mask_2 * (valueMaps[2] == value_3)\n          mask_3 = ndimage.binary_erosion(mask_3).astype(mask_3.dtype)\n          if mask_3.sum() < self.planeAreaThreshold:\n            continue\n\n          normal = np.array([normals[:, :, 0][mask_3].mean(), normals[:, :, 1][mask_3].mean(), normals[:, :, 2][mask_3].mean()])\n          normal /= np.linalg.norm(normal, 2)\n          dPlane = (-(normal[0] * X + normal[1] * Y + normal[2] * Z))[mask_3].mean()\n          planes.append(((-normal[0] * dPlane, -normal[1] * dPlane, -normal[2] * dPlane), mask_3))\n          continue\n        continue\n      continue\n\n    if False:\n      planeImage = np.zeros((self.height, self.width, 3))\n      for plane in planes:\n        mask = plane[1]\n        for c in xrange(3):\n          planeImage[:, :, c][mask] = random.randint(0, 255)\n          #planeImage[:, :, c][mask] = max(min(round((plane[0][c] + 1) / 2 * 255), 255), 0)\n          continue\n        continue\n      PIL.Image.fromarray(planeImage.astype(np.uint8)).save('test/plane.png')\n      exit(1)\n      \n    #planes = [planes[0]]\n    residualPlanes = []\n    if True:\n      for plane in planes:\n        mask = skimage.measure.block_reduce(plane[1], (32, 32), np.mean).reshape(-1)\n        residualPlanes.append(np.append(plane[0], mask))\n        continue\n      pass\n    elif useGlobal:\n      residualPlaneMap = {}\n      for plane in planes:\n        planeParameters = np.array(plane[0])\n        predefinedPlanes = self.predefinedPlanes\n        diff = planeParameters.reshape(1, 3).repeat(predefinedPlanes.shape[0], 0) - predefinedPlanes\n        diffSum = np.linalg.norm(diff, 2, 1)\n        #diffSum = np.abs(diff[:, 1])\n        planeIndex = np.argmin(diffSum)\n        \n        planeArea = plane[1].sum()\n        if planeIndex not in residualPlaneMap or planeArea > residualPlaneMap[planeIndex][1]:\n          residualPlaneMap[planeIndex] = (diff[planeIndex].tolist(), planeArea)\n          pass\n        continue\n      for planeIndex, residualPlane in residualPlaneMap.items():\n        residualPlanes.append([planeIndex, ] + residualPlane[0])\n        continue\n      pass\n    else:\n      for plane in planes:\n        planeParameters = np.array(plane[0])\n        mask = plane[1]\n        for cell in xrange(self.width * self.width / (self.stride * self.stride)):\n          gridX = int(cell) % (self.width / self.stride)\n          gridY = int(cell) / (self.width / self.stride)\n          intersection = mask[gridY * self.stride:(gridY + 1) * self.stride, gridX * self.stride:(gridX + 1) * self.stride].sum()\n          if intersection > self.positivePlaneThreshold:\n            predefinedPlanes = self.predefinedPlanes\n            diff = planeParameters.reshape(1, 3).repeat(predefinedPlanes.shape[0], 0) - predefinedPlanes\n            diffSum = np.linalg.norm(diff, 2, 1)\n            #diffSum = np.abs(diff[:, 1])\n            planeIndex = np.argmin(diffSum)\n            index = cell * self.numClusters + planeIndex\n            residualPlanes.append([index, ] + diff[planeIndex].tolist())\n            pass\n          continue\n        continue\n      pass\n\n    residualPlanes = np.array(residualPlanes)\n    #planeFilename = normalFilename.replace('norm_camera.png', 'plane_global.npy')\n    np.save(planeFilename, residualPlanes)\n    self.planeFilenames.append(planeFilename)\n\n\n    if False:\n      invalidMask += Y > 10\n      X[invalidMask] = 0\n      Y[invalidMask] = 3\n      Z[invalidMask] = 0\n      \n      planeParametersArray = []\n      for plane in planes:\n        planeParametersArray.append(plane[0])\n        continue\n      planeParametersArray = np.array(planeParametersArray)\n      planeNormals = copy.deepcopy(planeParametersArray)\n      planeD = np.linalg.norm(planeNormals, 2, 1)\n      for c in xrange(3):\n        planeNormals[:, c] /= planeD\n        continue\n      \n      normalXYZ = np.array([urange / focalLength, np.ones(urange.shape), -vrange / focalLength])\n\n      normalXYZ = np.dot(normalXYZ.transpose([1, 2, 0]), planeNormals.transpose())\n      normalXYZ = np.reciprocal(normalXYZ)\n\n      XYZ = np.array([X, Y, Z])\n      planeXYZ = np.zeros(XYZ.shape)\n      for i in xrange(planeParametersArray.shape[0]):\n\n        mask = planes[i][1]\n        planeY = normalXYZ[:, :, i] * planeD[i]\n        planeX = planeY * urange / focalLength\n        planeZ = -planeY * vrange / focalLength\n\n        planeXYZ[0][mask] = planeX[mask]\n        planeXYZ[1][mask] = planeY[mask]\n        planeXYZ[2][mask] = planeZ[mask]\n        continue\n\n      for c in xrange(3):\n        inputImage = XYZ[c]\n        cMin = inputImage.min()\n        cMax = inputImage.max()\n        PIL.Image.fromarray(((inputImage - cMin) / (cMax - cMin) * 255).astype(np.uint8)).save('test/' + str(c) + '.png')\n        reconstructed = planeXYZ[c]\n        PIL.Image.fromarray(((reconstructed - cMin) / (cMax - cMin) * 255).astype(np.uint8)).save('test/' + str(c) + '_reconstructed.png')\n        continue\n\n\n      planeImage = np.zeros((self.height, self.width, 3))\n      for plane in planes:\n        mask = plane[1]\n        for c in xrange(3):\n          planeImage[:, :, c][mask] = random.randint(0, 255)\n          #planeImage[:, :, c][mask] = max(min(round((plane[0][c] + 1) / 2 * 255), 255), 0)\n          continue\n        continue\n      PIL.Image.fromarray(planeImage.astype(np.uint8)).save('test/plane.png')\n      exit(1)\n      pass\n\n    return\n\n  def evaluatePredefinedPlanes(self, normalFilename, maskFilename, depthFilename):\n    normals = np.array(PIL.Image.open(normalFilename)).astype(np.float) / 255 * 2 - 1\n    norm = np.linalg.norm(normals, 2, 2)\n    for c in xrange(3):\n      normals[:, :, c] /= norm\n      continue\n    \n    invalidMask = (np.array(PIL.Image.open(maskFilename)) < 128)\n\n    azimuthAngleImage = np.arctan2(-normals[:, :, 1], normals[:, :, 0])\n    altitudeAngleImage = np.arctan2(np.sign(-normals[:, :, 1]) * np.linalg.norm(normals[:, :, :2], 2, 2), normals[:, :, 2])\n\n\n    depths = np.array(PIL.Image.open(depthFilename)).astype(np.float) / 1000\n    focalLength = 517.97\n    urange = np.arange(self.width).reshape(1, -1).repeat(self.height, 0) - self.width * 0.5\n    vrange = np.arange(self.height).reshape(-1, 1).repeat(self.width, 1) - self.height * 0.5\n    X = depths / focalLength * urange\n    Y = depths\n    Z = -depths / focalLength * vrange\n    d = -(normals[:, :, 0] * X + normals[:, :, 1] * Y + normals[:, :, 2] * Z)\n    #d *= self.depthScaleFactor\n\n\n    inputParameters = np.array([X, Y, Z]).reshape(-1, self.height, self.width, 1).repeat(self.numClusters, 3)\n\n    #invalidMask += (True - self.mask)\n\n    diff = inputParameters - self.predefinedPlanesImage\n    diff = pow(diff, 2)\n    for c in xrange(diff.shape[0]):\n      diff[c][invalidMask] = 0\n      continue\n\n    for c in xrange(diff.shape[0]):\n      self.residualImages[c] += diff[c].min(2)\n      continue\n    self.residualImages[3] += np.linalg.norm(diff, 2, 0).min(2)\n\n\n\n    if True:\n      PIL.Image.fromarray((invalidMask * 255).astype(np.uint8)).save('test/mask.png')\n      XYZ = np.array([X, Y, Z])\n      for c in xrange(3):\n        inputImage = XYZ[c]\n        cMin = inputImage.min()\n        cMax = inputImage.max()\n        inputImage[invalidMask] = 0\n        PIL.Image.fromarray(((inputImage - cMin) / (cMax - cMin) * 255).astype(np.uint8)).save('test/' + str(c) + '.png')\n        reconstructed = np.zeros(inputImage.shape)\n        diffImage = np.ones(inputImage.shape) * 10000\n        segmentation = np.zeros((self.height, self.width, 3)).astype(np.uint8)\n        for clusterIndex in xrange(self.numClusters):\n          planeImage = self.predefinedPlanesImage[c, :, :, clusterIndex]\n          mask = np.abs(planeImage - inputImage) < diffImage\n          reconstructed[mask] = planeImage[mask]\n          diffImage[mask] = np.abs(planeImage - inputImage)[mask]\n          segmentation[mask] = (np.random.rand(3) * 255).astype(np.uint8)\n          continue\n        reconstructed[invalidMask] = 0\n        PIL.Image.fromarray(((reconstructed - cMin) / (cMax - cMin) * 255).astype(np.uint8)).save('test/' + str(c) + '_reconstructed_2.png')\n        PIL.Image.fromarray(segmentation).save('test/' + str(c) + '_segmentation_2.png')\n        continue\n\n      #assignment = np.argmin(diff.sum(0), 2).reshape(-1)\n\n      for c in xrange(3):\n        assignment = np.argmin(diff[c], 2)\n        cMin = XYZ[c].min()\n        cMax = XYZ[c].max()\n        planesImage = self.predefinedPlanesImage[c]\n        #reconstructed = .reshape(-1, self.numClusters)[np.arange(self.height * self.width), assignment].reshape(self.height, self.width)\n        #cImage = self.predefinedPlanesImage[c][assignment]\n        reconstructed = np.zeros(XYZ[c].shape)\n        segmentation = np.zeros((self.height, self.width, 3)).astype(np.uint8)\n        for clusterIndex in xrange(self.numClusters):\n          mask = assignment == clusterIndex\n          reconstructed[mask] = planesImage[:, :, clusterIndex][mask]\n          segmentation[mask] = (np.random.rand(3) * 255).astype(np.uint8)\n          continue\n        inputImage[invalidMask] = 0\n        reconstructed[invalidMask] = 0\n        PIL.Image.fromarray(((XYZ[c] - cMin) / (cMax - cMin) * 255).astype(np.uint8)).save('test/' + str(c) + '.png')\n        PIL.Image.fromarray((np.maximum(np.minimum((reconstructed - cMin) / (cMax - cMin), 1), 0) * 255).astype(np.uint8)).save('test/' + str(c) + '_reconstructed.png')\n        PIL.Image.fromarray(segmentation).save('test/' + str(c) + '_segmentation.png')\n        continue\n      exit(1)\n      pass\n \n    return\n\n  def finishAddingPlaneInfo(self):\n    self.planeParametersArray = np.array(self.planeParametersArray)\n    return\n\n  def finishEvaluatingPredefinedPlanes(self, numImages):\n    self.residualImages /= numImages\n    return\n\n  def savePlaneInfo(self, folder):\n    np.save(folder + '/plane_parameters', self.planeParametersArray)\n    return\n\n  def loadPlaneInfo(self, folder):\n    self.planeParametersArray = np.load(folder + '/plane_parameters.npy')\n\n    if self.planeParametersArray.shape[1] == 4:\n      for c in xrange(3):\n        self.planeParametersArray[:, c] *= -self.planeParametersArray[:, 3]\n        continue\n      self.planeParametersArray = self.planeParametersArray[:, :3]\n      pass\n\n    return\n\n  def saveResiduals(self, folder):\n    np.save(folder + '/residual', self.residualImages)\n    return\n\n  def loadResiduals(self, folder):\n    self.residualImages = np.load(folder + '/residual.npy')\n    return\n\n  def savePredefinedPlanes(self, folder, numClusters):\n    np.save(folder + '/predefined_planes_' + str(numClusters), self.predefinedPlanes)\n    return\n\n  def loadPredefinedPlanes(self, folder, numClusters):\n    self.predefinedPlanes = np.load(folder + '/predefined_planes_' + str(numClusters) + '.npy')\n    self.numClusters = self.predefinedPlanes.shape[0]\n    return\n\n  def clusterPlanes(self, numClusters):\n    self.numClusters = numClusters\n\n    planeParameters = copy.deepcopy(self.planeParametersArray)    \n    \n    kmeans = KMeans(n_clusters = self.numClusters).fit(planeParameters)\n    \n    self.predefinedPlanes = np.array(kmeans.cluster_centers_)\n    return\n\n  def startEvaluatingPredefinedPlanes(self):\n    normals = copy.deepcopy(self.predefinedPlanes)\n    d = np.linalg.norm(normals, 2, 1)\n    for c in xrange(3):\n      normals[:, c] /= d\n      continue\n    #normals *= -1\n    \n    focalLength = 517.97\n    urange = np.arange(self.width).reshape(1, -1).repeat(self.height, 0) - self.width * 0.5\n    vrange = np.arange(self.height).reshape(-1, 1).repeat(self.width, 1) - self.height * 0.5\n    XYZ = np.array([urange / focalLength, np.ones(urange.shape), -vrange / focalLength])\n\n    normalXYZ = np.dot(XYZ.transpose([1, 2, 0]), normals.transpose())    \n    Y = np.reciprocal(normalXYZ)\n    X = np.zeros(Y.shape)\n    Z = np.zeros(Y.shape)\n    \n    for i in xrange(self.numClusters):\n      clusterY = Y[:, :, i] * d[i]\n      Y[:, :, i] = clusterY\n      X[:, :, i] = clusterY * urange / focalLength\n      Z[:, :, i] = -clusterY * vrange / focalLength\n      continue\n\n    self.predefinedPlanesImage = np.array([X, Y, Z])\n    \n    # for i in xrange(self.numClusters):\n    #   for c in xrange(3):\n    #     if c == 1:\n    #       PIL.Image.fromarray((np.minimum(self.predefinedPlanesImage[c, :, :, i] * 0.25, 1) * 255).astype(np.uint8)).save('test/' + str(i) + '_' + str(c) + '.png')\n    #     else:\n    #       PIL.Image.fromarray((np.maximum(np.minimum((self.predefinedPlanesImage[c, :, :, i] + 4) * 0.125, 1), 0) * 255).astype(np.uint8)).save('test/' + str(i) + '_' + str(c) + '.png')\n    #       pass\n    #     continue\n    #   continue\n    \n          \n    # dImage = np.linalg.norm(self.predefinedPlanesImage, 2, 0)\n    # normalImage = np.zeros((self.height, self.width, 3, self.numClusters))\n    # for c in xrange(3):\n    #   normalImage[:, :, c, :] = self.predefinedPlanesImage[c] / d\n    #   continue\n    \n    # for i in xrange(self.numClusters):\n    #   print(normalImage[0, 0, :, i])\n    #   print(dImage[0, 0, i])\n    #   PIL.Image.fromarray(((normalImage[:, :, :, i] + 1) / 2 * 255).astype(np.uint8)).save('test/normal_' + str(i) + '.png')\n    #   PIL.Image.fromarray((np.minimum(dImage[:, :, i] * 0.3, 1) * 255).astype(np.uint8)).save('test/d_' + str(i) + '.png')\n    #   continue\n    # exit(1)\n    # #self.predefinedPlanesImage = self.predefinedPlanes.reshape(3, 1, 1, self.numClusters).repeat(self.height, 1).repeat(self.width, 2)\n\n    return\n\n  def startGeneratingPlaneGfroundTruth(self):\n    self.planeFilenames = []\n\n  def finishGeneratingPlaneGroundTruth(self, folder):\n    with open(folder + '/image_list.txt', 'w') as f:\n      for filename in self.planeFilenames:\n        f.write(filename)\n        f.write('\\n')\n        continue\n      f.close()\n      pass\n    return\n\n  def evaluatePlaneGroundTruth(self, normalFilename, maskFilename, depthFilename, planeFilename):\n    \n    normals = np.array(PIL.Image.open(normalFilename)).astype(np.float) / 255 * 2 - 1\n    norm = np.linalg.norm(normals, 2, 2)\n    for c in xrange(3):\n      normals[:, :, c] /= norm\n      continue\n    \n    invalidMask = (np.array(PIL.Image.open(maskFilename)) < 128)\n\n    depths = np.array(PIL.Image.open(depthFilename)).astype(np.float) / 1000\n    focalLength = 517.97\n    urange = np.arange(self.width).reshape(1, -1).repeat(self.height, 0) - self.width * 0.5\n    vrange = np.arange(self.height).reshape(-1, 1).repeat(self.width, 1) - self.height * 0.5\n    X = depths / focalLength * urange\n    Y = depths\n    Z = -depths / focalLength * vrange\n    #d = -(normals[:, :, 0] * X + normals[:, :, 1] * Y + normals[:, :, 2] * Z)\n\n    residualPlanes = np.load(planeFilename)\n\n    XYZ = np.array([X, Y, Z])\n    planesXYZ = np.zeros(XYZ.shape)\n    diffImage = np.ones(XYZ.shape) * 10000\n    ranges = np.array([urange / focalLength, np.ones(urange.shape), -vrange / focalLength]).transpose([1, 2, 0])\n\n\n    for residualPlane in residualPlanes:\n      #residualPlane[1:] = 0\n      gridIndex = int(residualPlane[0]) / self.numClusters\n      planeIndex = int(residualPlane[0]) % self.numClusters\n      plane = self.predefinedPlanes[planeIndex] + residualPlane[1:]\n      #print(plane)\n      planeD = np.linalg.norm(plane)\n      planeNormal = plane / planeD\n\n      \n      normalXYZ = np.dot(ranges, planeNormal)\n      normalXYZ = np.reciprocal(normalXYZ)\n\n      planeY = normalXYZ * planeD\n      planeX = planeY * urange / focalLength\n      planeZ = -planeY * vrange / focalLength\n      \n      planeXYZ = [planeX, planeY, planeZ]\n      for c in xrange(3):\n        mask = np.abs(planeXYZ[c] - XYZ[c]) < diffImage[c]\n        planesXYZ[c][mask] = planeXYZ[c][mask]\n        diffImage[c][mask] = np.abs(planeXYZ[c] - XYZ[c])[mask]\n        continue\n      continue\n    \n    for c in xrange(3):\n      inputImage = XYZ[c]\n      cMin = inputImage.min()\n      cMax = inputImage.max()\n      PIL.Image.fromarray(((inputImage - cMin) / (cMax - cMin) * 255).astype(np.uint8)).save('test/' + str(c) + '.png')\n      reconstructed = planesXYZ[c]\n      PIL.Image.fromarray(((reconstructed - cMin) / (cMax - cMin) * 255).astype(np.uint8)).save('test/' + str(c) + '_reconstructed.png')\n      continue\n\n    return\n\n  \ndef evaluatePlanes(planes, filename, outputFolder = None):\n  normalFilename = filename.replace('mlt', 'norm_camera')\n  normals = np.array(PIL.Image.open(normalFilename)).astype(np.float) / 255 * 2 - 1\n  height = normals.shape[0]\n  width = normals.shape[1]\n  norm = np.linalg.norm(normals, 2, 2)\n  for c in xrange(3):\n    normals[:, :, c] /= norm\n    continue\n\n  \n  depthFilename = filename.replace('mlt', 'depth')\n  depths = np.array(PIL.Image.open(depthFilename)).astype(np.float) / 1000\n  focalLength = 517.97\n  urange = np.arange(width).reshape(1, -1).repeat(height, 0) - width * 0.5\n  vrange = np.arange(height).reshape(-1, 1).repeat(width, 1) - height * 0.5\n  X = depths / focalLength * urange\n  Y = depths\n  Z = -depths / focalLength * vrange\n  d = -(normals[:, :, 0] * X + normals[:, :, 1] * Y + normals[:, :, 2] * Z)\n\n  \n  maskFilename = filename.replace('mlt', 'valid')\n  invalidMask = (np.array(PIL.Image.open(maskFilename)) < 128)\n  invalidMask += depths > 10\n\n  \n  #if outputFolder != None:\n  #XYZ = np.array([X, Y, Z])\n  reconstructedNormals = np.zeros(normals.shape)\n  diffNormals = np.ones((height, width)) * (-1)\n  segmentationNormals = np.zeros((height, width, 3))\n  reconstructedDepths = np.zeros(depths.shape)\n  diffDepths = np.ones(depths.shape) * 1000000\n  segmentationDepths = np.zeros((height, width, 3))\n  \n  ranges = np.array([urange / focalLength, np.ones(urange.shape), -vrange / focalLength]).transpose([1, 2, 0])\n\n  for planeIndex, plane in enumerate(planes):\n    planeD = np.linalg.norm(plane)\n    planeNormal = -plane / planeD\n\n\n    mask = np.dot(normals, planeNormal) > diffNormals\n    reconstructedNormals[mask] = planeNormal\n    diffNormals[mask] = np.dot(normals, planeNormal)[mask]\n    segmentationNormals[mask] = np.random.randint(255, size=(3,))\n    \n    normalXYZ = np.dot(ranges, planeNormal)\n    normalXYZ = np.reciprocal(normalXYZ)\n\n    planeY = -normalXYZ * planeD\n\n    #if planeNormal[2] > 0.9:\n    #print(planeD)\n    #print(planeNormal)\n    # minDepth = depths.min()\n    # maxDepth = depths.max()\n    # print(depths[300][300])\n    # print(planeY[300][300])\n    # print(depths[350][350])\n    # print(planeY[350][350])\n    # PIL.Image.fromarray((np.maximum(np.minimum((planeY - minDepth) / (maxDepth - minDepth), 1), 0) * 255).astype(np.uint8)).save(outputFolder + '/plane.png')\n    # exit(1)\n    #pass\n    if planeIndex in [1, 4]:\n      print(planeY[113][251])\n      continue\n    mask = pow(planeY - Y, 2) < diffDepths\n    reconstructedDepths[mask] = planeY[mask]\n    diffDepths[mask] = pow(planeY - Y, 2)[mask]\n    segmentationDepths[mask] = np.random.randint(255, size=(3,))\n    continue\n\n  \n  if outputFolder != None:\n    depths[invalidMask] = 0\n    normals[invalidMask] = 0\n    reconstructedDepths[invalidMask] = 0\n    reconstructedNormals[invalidMask] = 0\n    minDepth = depths.min()\n    maxDepth = depths.max()\n    print(minDepth)\n    print(maxDepth)\n    PIL.Image.fromarray(((depths - minDepth) / (maxDepth - minDepth) * 255).astype(np.uint8)).save(outputFolder + '/depth.png')\n    PIL.Image.fromarray((np.maximum(np.minimum((reconstructedDepths - minDepth) / (maxDepth - minDepth), 1), 0) * 255).astype(np.uint8)).save(outputFolder + '/depth_reconstructed.png')\n    PIL.Image.fromarray(segmentationDepths.astype(np.uint8)).save(outputFolder + '/depth_segmentation.png')\n    PIL.Image.fromarray(((normals + 1) / 2 * 255).astype(np.uint8)).save(outputFolder + '/normal.png')\n    PIL.Image.fromarray(((reconstructedNormals + 1) / 2 * 255).astype(np.uint8)).save(outputFolder + '/normal_reconstructed.png')\n    PIL.Image.fromarray(segmentationNormals.astype(np.uint8)).save(outputFolder + '/normal_segmentation.png')\n    depthImage = ((depths - minDepth) / (maxDepth - minDepth) * 255).astype(np.uint8)\n    #PIL.Image.fromarray((invalidMask * 255).astype(np.uint8)).save(outputFolder + '/mask.png')\n    exit(1)\n    pass\n  return diffDepths.mean(), diffNormals.mean()\n  \n"""
code/RecordChecker.py,17,"b""import tensorflow as tf\nimport numpy as np\nimport cv2\nimport random\nimport PIL.Image\nimport sys\nimport os\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom modules import *\nfrom utils import *\nfrom RecordReaderAll import *\nfrom SegmentationRefinement import *\n\nHEIGHT=192\nWIDTH=256\nNUM_PLANES = 20\n\ndef _bytes_feature(value):\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _int64_feature(value):\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n\ndef _float_feature(value):\n    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n\n\ndef writeRecordFile(split, dataset):\n    \n    batchSize = 8\n    numOutputPlanes = 20\n    if split == 'train':\n        reader = RecordReaderAll()\n        filename_queue = tf.train.string_input_producer(['/mnt/vision/PlaneNet/planes_' + dataset + '_train.tfrecords'], num_epochs=1)\n        img_inp, global_gt_dict, _ = reader.getBatch(filename_queue, numOutputPlanes=numOutputPlanes, batchSize=batchSize, random=False, getLocal=True)\n        writer = tf.python_io.TFRecordWriter('/mnt/vision/PlaneNet/planes_' + dataset + '_train_temp.tfrecords')\n        numImages = 50000\n    else:\n        reader = RecordReaderAll()\n        filename_queue = tf.train.string_input_producer(['/mnt/vision/PlaneNet/planes_' + dataset + '_val.tfrecords'], num_epochs=1)\n        img_inp, global_gt_dict, _ = reader.getBatch(filename_queue, numOutputPlanes=numOutputPlanes, batchSize=batchSize, random=False, getLocal=True)\n        writer = tf.python_io.TFRecordWriter('/mnt/vision/PlaneNet/planes_' + dataset + '_val_temp.tfrecords')\n        numImages = 1000\n        pass\n    \n        \n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n    #segmentation_gt, plane_mask = fitPlaneMasksModule(global_gt_dict['plane'], global_gt_dict['depth'], global_gt_dict['normal'], width=WIDTH, height=HEIGHT, normalDotThreshold=np.cos(np.deg2rad(5)), distanceThreshold=0.05, closing=True, one_hot=True)\n    #global_gt_dict['segmentation'] = tf.argmax(tf.concat([segmentation_gt, 1 - plane_mask], axis=3), axis=3)\n\n    #segmentation_gt = tf.cast(tf.equal(global_gt_dict['segmentation'], tf.reshape(tf.range(NUM_PLANES), (1, 1, 1, -1))), tf.float32)\n    #plane_mask = tf.cast(tf.less(global_gt_dict['segmentation'], NUM_PLANES), tf.float32)\n    #global_gt_dict['boundary'] = findBoundaryModuleSmooth(global_gt_dict['depth'], segmentation_gt, plane_mask, global_gt_dict['smooth_boundary'], max_depth_diff = 0.1, max_normal_diff = np.sqrt(2 * (1 - np.cos(np.deg2rad(20)))))\n    \n    \n    with tf.Session() as sess:\n        sess.run(init_op)\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n        try:\n            for _ in xrange(numImages / batchSize):\n                img, global_gt = sess.run([img_inp, global_gt_dict])\n                \n                for batchIndex in xrange(batchSize):\n                    numPlanes = global_gt['num_planes'][batchIndex]\n                    if numPlanes == 0:\n                        print(_)\n                        print('no plane')\n                        continue\n                    \n                    image = ((img[batchIndex] + 0.5) * 255).astype(np.uint8)\n                    \n                    segmentation = np.argmax(np.concatenate([global_gt['segmentation'][batchIndex], global_gt['non_plane_mask'][batchIndex]], axis=-1), axis=-1).astype(np.uint8).squeeze()\n                    boundary = global_gt['boundary'][batchIndex].astype(np.uint8)\n                    semantics = global_gt['semantics'][batchIndex].astype(np.uint8)\n\n\n                    planes = global_gt['plane'][batchIndex]\n                    if np.isnan(planes).any():\n                        print(global_gt['image_path'][batchIndex])\n                        planes, segmentation, numPlanes = removeSmallSegments(planes, np.zeros((HEIGHT, WIDTH, 3)), global_gt['depth'][batchIndex].squeeze(), np.zeros((HEIGHT, WIDTH, 3)), np.argmax(global_gt['segmentation'][batchIndex], axis=-1), global_gt['semantics'][batchIndex], global_gt['info'][batchIndex], global_gt['num_planes'][batchIndex])\n                        if np.isnan(planes).any():\n                            np.save('temp/plane.npy', global_gt['plane'][batchIndex])                        \n                            np.save('temp/depth.npy', global_gt['depth'][batchIndex])\n                            np.save('temp/segmentation.npy', global_gt['segmentation'][batchIndex])\n                            np.save('temp/info.npy', global_gt['info'][batchIndex])\n                            np.save('temp/num_planes.npy', global_gt['num_planes'][batchIndex])\n                            print('why')\n                            exit(1)\n                        pass\n\n                    \n                    example = tf.train.Example(features=tf.train.Features(feature={\n                        'image_path': _bytes_feature(global_gt['image_path'][batchIndex]),\n                        'image_raw': _bytes_feature(image.tostring()),\n                        'depth': _float_feature(global_gt['depth'][batchIndex].reshape(-1)),\n                        'normal': _float_feature(np.zeros((HEIGHT * WIDTH * 3))),\n                        'semantics_raw': _bytes_feature(semantics.tostring()),\n                        'plane': _float_feature(planes.reshape(-1)),\n                        'num_planes': _int64_feature([numPlanes]),\n                        'segmentation_raw': _bytes_feature(segmentation.tostring()),\n                        'boundary_raw': _bytes_feature(boundary.tostring()),\n                        #'plane_relation': _float_feature(planeRelations.reshape(-1)),\n                        'info': _float_feature(global_gt['info'][batchIndex]),\n                    }))\n                    \n                    writer.write(example.SerializeToString())\n                    continue\n                continue\n            pass\n        except tf.errors.OutOfRangeError:\n            print('Done training -- epoch limit reached')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n        \n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()    \n    return\n\n    \nif __name__=='__main__':\n    #writeRecordFile('val', 'matterport')\n    #writeRecordFile('val', 'scannet')\n    # writeRecordFile('train', 'matterport')    \n    #writeRecordFile('train', 'scannet')\n    #writeRecordFile('train', 'nyu_rgbd')\n    writeRecordFile('val', 'nyu_rgbd')    \n\n"""
code/RecordConverter.py,16,"b""import tensorflow as tf\nimport numpy as np\nimport cv2\nimport random\nimport PIL.Image\nimport sys\nimport os\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom modules import *\nfrom utils import *\nfrom RecordReader import *\n\nHEIGHT=192\nWIDTH=256\nNUM_PLANES = 20\n\ndef _bytes_feature(value):\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _int64_feature(value):\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n\ndef _float_feature(value):\n    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n\n\ndef writeRecordFile(split):\n    \n    batchSize = 8\n    numOutputPlanes = 20\n    if split == 'train':\n        reader = RecordReader()\n        #filename_queue = tf.train.string_input_producer(['/media/chenliu/My Passport/planes_test_450000.tfrecords'], num_epochs=1)\n        filename_queue = tf.train.string_input_producer(['/mnt/vision/PlaneNet/planes_SUNCG_train.tfrecords'], num_epochs=1)        \n        img_inp, global_gt_dict, _ = reader.getBatch(filename_queue, numOutputPlanes=numOutputPlanes, batchSize=batchSize, random=False, getLocal=True)\n        writer = tf.python_io.TFRecordWriter('/mnt/vision/PlaneNet/planes_SUNCG_train.tfrecords')\n        numImages = 50000\n    else:\n        reader = RecordReader()\n        filename_queue = tf.train.string_input_producer(['/mnt/vision/SUNCG_plane/planes_test_1000_450000.tfrecords'], num_epochs=1)\n        img_inp, global_gt_dict, _ = reader.getBatch(filename_queue, numOutputPlanes=numOutputPlanes, batchSize=batchSize, random=False, getLocal=True)\n        writer = tf.python_io.TFRecordWriter('/mnt/vision/PlaneNet/planes_SUNCG_val.tfrecords')\n        numImages = 1000\n        pass\n    \n        \n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n    segmentation_gt, plane_mask = fitPlaneMasksModule(global_gt_dict['plane'], global_gt_dict['depth'], global_gt_dict['normal'], width=WIDTH, height=HEIGHT, normalDotThreshold=np.cos(np.deg2rad(5)), distanceThreshold=0.05, closing=True, one_hot=True)\n    global_gt_dict['segmentation'] = tf.argmax(tf.concat([segmentation_gt, 1 - plane_mask], axis=3), axis=3)\n\n    global_gt_dict['boundary'] = findBoundaryModule(global_gt_dict['depth'], global_gt_dict['normal'], segmentation_gt, plane_mask, max_depth_diff = 0.1, max_normal_diff = np.sqrt(2 * (1 - np.cos(np.deg2rad(20)))))\n    \n    testdir = 'test/'\n\n\n    with tf.Session() as sess:\n        sess.run(init_op)\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n        try:\n            for _ in xrange(numImages / batchSize):\n                print(_)\n                img, global_gt = sess.run([img_inp, global_gt_dict])\n                for batchIndex in xrange(batchSize):\n                    image = ((img[batchIndex] + 0.5) * 255).astype(np.uint8)\n                    \n                    segmentation = global_gt['segmentation'][batchIndex].astype(np.uint8)\n                    boundary = global_gt['boundary'][batchIndex].astype(np.uint8)\n                    info = np.zeros(20)\n                    info[0] = 517.97\n                    info[2] = 320\n                    info[5] = 517.97\n                    info[6] = 240\n                    info[10] = 1\n                    info[15] = 1\n                    info[16] = 640\n                    info[17] = 480\n                    info[18] = 1000\n                    info[19] = 0\n                    \n                    #cv2.imwrite('test/segmentation_' + str(batchIndex) + '.png', drawSegmentationImage(segmentation, planeMask = segmentation < 20, black=True))\n                    #boundary = np.concatenate([boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)                \n                    #cv2.imwrite('test/boundary_' + str(batchIndex) + '.png', drawMaskImage(boundary))\n                    \n                    example = tf.train.Example(features=tf.train.Features(feature={\n                        'image_path': _bytes_feature(global_gt['image_path'][batchIndex]),\n                        'image_raw': _bytes_feature(image.tostring()),\n                        'depth': _float_feature(global_gt['depth'][batchIndex].reshape(-1)),\n                        'normal': _float_feature(global_gt['normal'][batchIndex].reshape(-1)),\n                        'plane': _float_feature(global_gt['plane'][batchIndex].reshape(-1)),\n                        'num_planes': _int64_feature([global_gt['num_planes'][batchIndex]]),\n                        'segmentation_raw': _bytes_feature(segmentation.tostring()),        \n                        'boundary_raw': _bytes_feature(boundary.tostring()),\n                        #'plane_relation': _float_feature(planeRelations.reshape(-1)),\n                        'info': _float_feature(info.reshape(-1)),\n                    }))\n                    \n                    writer.write(example.SerializeToString())\n                    continue\n                #exit(1)\n                continue\n            pass\n        except tf.errors.OutOfRangeError:\n            print('Done training -- epoch limit reached')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n        \n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()    \n    return\n\n    \nif __name__=='__main__':\n    writeRecordFile('train')\n    writeRecordFile('val')\n"""
code/RecordConverter3D.py,19,"b""import tensorflow as tf\nimport numpy as np\nimport cv2\nimport random\nimport PIL.Image\nimport sys\nimport os\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom modules import *\nfrom utils import *\nfrom RecordReader3D import *\nfrom SegmentationRefinement import *\n\nHEIGHT=192\nWIDTH=256\nNUM_PLANES = 20\n\ndef _bytes_feature(value):\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _int64_feature(value):\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n\ndef _float_feature(value):\n    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n\n\ndef writeRecordFile(split, dataset):\n    \n    batchSize = 8\n    numOutputPlanes = 20\n    if split == 'train':\n        reader = RecordReader3D()\n        #filename_queue = tf.train.string_input_producer(['../planes_' + dataset + '_train.tfrecords'], num_epochs=1)\n        filename_queue = tf.train.string_input_producer(['/mnt/vision/PlaneNet/planes_' + dataset + '_train_raw.tfrecords', '/mnt/vision/PlaneNet/planes_' + dataset + '_train_raw_2.tfrecords'], num_epochs=1)\n        img_inp, global_gt_dict, _ = reader.getBatch(filename_queue, numOutputPlanes=numOutputPlanes, batchSize=batchSize, random=False, getLocal=True)\n        #writer = tf.python_io.TFRecordWriter('/mnt/vision/PlaneNet/planes_' + dataset + '_train.tfrecords')\n        writer = tf.python_io.TFRecordWriter('/mnt/vision/PlaneNet/planes_' + dataset + '_train_new.tfrecords')\n        numImages = 50000\n    else:\n        reader = RecordReader3D()\n        filename_queue = tf.train.string_input_producer(['../planes_' + dataset + '_val.tfrecords'], num_epochs=1)\n        img_inp, global_gt_dict, _ = reader.getBatch(filename_queue, numOutputPlanes=numOutputPlanes, batchSize=batchSize, random=False, getLocal=True)\n        writer = tf.python_io.TFRecordWriter('/mnt/vision/PlaneNet/planes_' + dataset + '_val.tfrecords')\n        numImages = 1000\n        pass\n    \n        \n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n    #segmentation_gt, plane_mask = fitPlaneMasksModule(global_gt_dict['plane'], global_gt_dict['depth'], global_gt_dict['normal'], width=WIDTH, height=HEIGHT, normalDotThreshold=np.cos(np.deg2rad(5)), distanceThreshold=0.05, closing=True, one_hot=True)\n    #global_gt_dict['segmentation'] = tf.argmax(tf.concat([segmentation_gt, 1 - plane_mask], axis=3), axis=3)\n\n    segmentation_gt = tf.cast(tf.equal(global_gt_dict['segmentation'], tf.reshape(tf.range(NUM_PLANES), (1, 1, 1, -1))), tf.float32)\n    plane_mask = tf.cast(tf.less(global_gt_dict['segmentation'], NUM_PLANES), tf.float32)\n    global_gt_dict['boundary'] = findBoundaryModuleSmooth(global_gt_dict['depth'], segmentation_gt, plane_mask, global_gt_dict['smooth_boundary'], max_depth_diff = 0.1, max_normal_diff = np.sqrt(2 * (1 - np.cos(np.deg2rad(20)))))\n    \n    \n    # info = np.zeros(20)\n    # info[0] = 5.1885790117450188e+02\n    # info[2] = 3.2558244941119034e+02 - 40\n    # info[5] = 5.1946961112127485e+02\n    # info[6] = 2.5373616633400465e+02 - 44\n    # info[10] = 1\n    # info[15] = 1\n    # info[16] = 561\n    # info[17] = 427\n    # info[18] = 1000\n    # info[19] = 1\n    \n    with tf.Session() as sess:\n        sess.run(init_op)\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n        try:\n            for _ in xrange(numImages / batchSize):\n                print(_)\n                img, global_gt = sess.run([img_inp, global_gt_dict])\n                for batchIndex in xrange(batchSize):\n                    image = ((img[batchIndex] + 0.5) * 255).astype(np.uint8)\n                    segmentation = global_gt['segmentation'][batchIndex].astype(np.uint8).squeeze()\n                    boundary = global_gt['boundary'][batchIndex].astype(np.uint8)\n\n                 \n                    #boundary = np.concatenate([boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)\n\n                    info = global_gt['info'][batchIndex]\n                    datasetIndex = 2\n                    if dataset == 'scannet':\n                        datasetIndex = 3\n                        pass\n                    info = np.concatenate([info[3:], info[:3], np.ones(1) * datasetIndex])\n\n                    imagePath = global_gt['image_path'][batchIndex]\n                    if '/home/chenliu' in imagePath:\n                        imagePath = imagePath.replace('/home/chenliu/Projects/Data/', '/mnt/vision/')\n                        pass\n                    depthFilename = imagePath.replace('color.jpg', 'depth.pgm')\n                    \n                    depth = np.array(PIL.Image.open(depthFilename)).astype(np.float32) / info[18]\n                    invalidMask = (depth < 1e-4).astype(np.float32)\n                    invalidMask = (cv2.resize(invalidMask, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR) > 1e-4).astype(np.bool)\n                    depth = cv2.resize(depth, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n                    #cv2.imwrite('test/depth_ori_' + str(batchIndex) + '.png', drawDepthImage(depth))\n                    depth[invalidMask] = 0\n\n\n                    semanticsFilename = imagePath.replace('color.jpg', 'segmentation.png').replace('frames', 'annotation/semantics')\n                    semantics = cv2.imread(semanticsFilename, -1)\n                    semantics = cv2.resize(semantics, (WIDTH, HEIGHT), interpolation=cv2.INTER_NEAREST)\n                    #cv2.imwrite('test/segmentation_' + str(batchIndex) + '.png', drawSegmentationImage(semantics, blackIndex=0))\n                    #cv2.imwrite('test/depth_' + str(batchIndex) + '.png', drawDepthImage(depth))\n                    # cv2.imwrite('test/boundary_' + str(batchIndex) + '.png', drawMaskImage(boundary))\n                    # cv2.imwrite('test/image_' + str(batchIndex) + '.png', image)               \n\n                    planes, segmentation, numPlanes = removeSmallSegments(global_gt['plane'][batchIndex], image, depth, np.zeros((HEIGHT * WIDTH * 3)), segmentation, semantics, info, global_gt['num_planes'][batchIndex])\n                    \n                    example = tf.train.Example(features=tf.train.Features(feature={\n                        'image_path': _bytes_feature(global_gt['image_path'][batchIndex]),\n                        'image_raw': _bytes_feature(image.tostring()),\n                        'depth': _float_feature(depth.reshape(-1)),\n                        'normal': _float_feature(np.zeros((HEIGHT * WIDTH * 3))),\n                        'semantics_raw': _bytes_feature(semantics.tostring()),\n                        'plane': _float_feature(planes.reshape(-1)),\n                        'num_planes': _int64_feature([numPlanes]),\n                        'segmentation_raw': _bytes_feature(segmentation.tostring()),\n                        'boundary_raw': _bytes_feature(boundary.tostring()),\n                        #'plane_relation': _float_feature(planeRelations.reshape(-1)),\n                        'info': _float_feature(info),\n                    }))\n                    \n                    writer.write(example.SerializeToString())\n                    continue\n                continue\n            pass\n        except tf.errors.OutOfRangeError:\n            print('Done training -- epoch limit reached')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n        \n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()    \n    return\n\n    \nif __name__=='__main__':\n    #writeRecordFile('val', 'matterport')\n    #writeRecordFile('val', 'scannet')\n    # writeRecordFile('train', 'matterport')    \n    writeRecordFile('train', 'scannet')    \n\n"""
code/RecordConverterRGBD.py,17,"b""import tensorflow as tf\nimport numpy as np\nimport cv2\nimport random\nimport PIL.Image\nimport sys\nimport os\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom modules import *\nfrom utils import *\nfrom RecordReaderRGBD import *\n\nHEIGHT=192\nWIDTH=256\nNUM_PLANES = 20\n\ndef _bytes_feature(value):\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _int64_feature(value):\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n\ndef _float_feature(value):\n    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n\n\ndef writeRecordFile(split):\n    \n    batchSize = 8\n    numOutputPlanes = 20\n    if split == 'train':\n        reader = RecordReaderRGBD()\n        filename_queue = tf.train.string_input_producer(['../planes_nyu_rgbd_train.tfrecords', '../planes_nyu_rgbd_val.tfrecords'], num_epochs=1)\n        img_inp, global_gt_dict, _ = reader.getBatch(filename_queue, numOutputPlanes=numOutputPlanes, batchSize=batchSize, random=False, getLocal=True)\n        writer = tf.python_io.TFRecordWriter('/mnt/vision/PlaneNet/planes_nyu_rgbd_train.tfrecords')\n        numImages = 50000\n    else:\n        reader = RecordReaderRGBD()\n        filename_queue = tf.train.string_input_producer(['../planes_nyu_rgbd_val.tfrecords'], num_epochs=1)\n        img_inp, global_gt_dict, _ = reader.getBatch(filename_queue, numOutputPlanes=numOutputPlanes, batchSize=batchSize, random=False, getLocal=True)\n        writer = tf.python_io.TFRecordWriter('/mnt/vision/PlaneNet/planes_nyu_rgbd_val.tfrecords')\n        numImages = 1000\n        pass\n    \n        \n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n    #segmentation_gt, plane_mask = fitPlaneMasksModule(global_gt_dict['plane'], global_gt_dict['depth'], global_gt_dict['normal'], width=WIDTH, height=HEIGHT, normalDotThreshold=np.cos(np.deg2rad(5)), distanceThreshold=0.05, closing=True, one_hot=True)\n    #global_gt_dict['segmentation'] = tf.argmax(tf.concat([segmentation_gt, 1 - plane_mask], axis=3), axis=3)\n\n    segmentation_gt = tf.cast(tf.equal(global_gt_dict['segmentation'], tf.reshape(tf.range(NUM_PLANES), (1, 1, 1, -1))), tf.float32)\n    plane_mask = tf.cast(tf.less(global_gt_dict['segmentation'], NUM_PLANES), tf.float32)\n    global_gt_dict['boundary'] = findBoundaryModule(global_gt_dict['depth'], global_gt_dict['normal'], segmentation_gt, plane_mask, max_depth_diff = 0.1, max_normal_diff = np.sqrt(2 * (1 - np.cos(np.deg2rad(20)))))\n    \n    \n    info = np.zeros(20)\n    info[0] = 5.1885790117450188e+02\n    info[2] = 3.2558244941119034e+02 - 40\n    info[5] = 5.1946961112127485e+02\n    info[6] = 2.5373616633400465e+02 - 44\n    info[10] = 1\n    info[15] = 1\n    info[16] = 561\n    info[17] = 427\n    info[18] = 1000\n    info[19] = 1\n\n    #numPlanesArray = []\n    \n    with tf.Session() as sess:\n        sess.run(init_op)\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n        try:\n            for _ in xrange(numImages / batchSize):\n                print(_)\n                img, global_gt = sess.run([img_inp, global_gt_dict])\n                for batchIndex in xrange(batchSize):\n                    if global_gt['num_planes'][batchIndex] == 0:\n                        print('no plane')\n                        continue\n                    \n                    image = ((img[batchIndex] + 0.5) * 255).astype(np.uint8)\n                    segmentation = global_gt['segmentation'][batchIndex].astype(np.uint8).squeeze()\n                    boundary = global_gt['boundary'][batchIndex].astype(np.uint8)\n\n                    planes = global_gt['plane'][batchIndex]\n                    planes = np.stack([-planes[:, 0], -planes[:, 2], -planes[:, 1]], axis=1)\n\n                    numPlanes = global_gt['num_planes'][batchIndex]\n\n                    planes, segmentation, numPlanes = refitPlanes(planes, segmentation, global_gt['depth'][batchIndex].squeeze(), info, numOutputPlanes=20, planeAreaThreshold=6*8)\n                    #print(global_gt['num_planes'][batchIndex], numPlanes)\n                    #numPlanesArray.append(numPlanes)\n\n                    if numPlanes == 0:\n                        continue\n                    \n                    normal = global_gt['normal'][batchIndex]\n                    normal = np.stack([-normal[:, :, 2], -normal[:, :, 0], -normal[:, :, 1]], axis=2)\n                    \n                    #cv2.imwrite('test/segmentation_' + str(batchIndex) + '.png', drawSegmentationImage(segmentation, planeMask = segmentation < 20, black=True))\n                    #boundary = np.concatenate([boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)                \n                    #cv2.imwrite('test/boundary_' + str(batchIndex) + '.png', drawMaskImage(boundary))\n                    #cv2.imwrite('test/image_' + str(batchIndex) + '.png', image)                    \n                    #cv2.imwrite('test/plane_mask_' + str(batchIndex) + '.png', drawMaskImage(segmentation == 20))                    \n                    \n                    example = tf.train.Example(features=tf.train.Features(feature={\n                        'image_path': _bytes_feature(global_gt['image_path'][batchIndex]),\n                        'image_raw': _bytes_feature(image.tostring()),\n                        'depth': _float_feature(global_gt['depth'][batchIndex].reshape(-1)),\n                        'normal': _float_feature(normal.reshape(-1)),\n                        'plane': _float_feature(planes.reshape(-1)),\n                        'num_planes': _int64_feature([numPlanes]),\n                        'segmentation_raw': _bytes_feature(segmentation.tostring()),\n                        'semantics_raw': _bytes_feature(np.zeros((HEIGHT, WIDTH), np.uint8).tostring()),                \n                        'boundary_raw': _bytes_feature(boundary.tostring()),\n                        #'plane_relation': _float_feature(planeRelations.reshape(-1)),\n                        'info': _float_feature(info),\n                    }))\n                    \n                    writer.write(example.SerializeToString())\n                    continue\n                continue\n            pass\n        except tf.errors.OutOfRangeError:\n            print('Done training -- epoch limit reached')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n        \n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    #numPlanesArray = np.array(numPlanesArray)\n    #np.save('results/num_planes.npy', numPlanesArray)\n    return\n\n    \nif __name__=='__main__':\n    writeRecordFile('train')\n    writeRecordFile('val')\n"""
code/RecordFilter.py,18,"b""import tensorflow as tf\nimport numpy as np\nnp.set_printoptions(precision=2, linewidth=200)\nimport cv2\nimport os\nimport time\nimport sys\nimport tf_nndistance\nimport argparse\nimport glob\nimport PIL\nimport scipy.ndimage as ndimage\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom utils import *\nfrom plane_utils import *\nfrom modules import *\n\nfrom train_planenet import *\nfrom planenet import PlaneNet\nfrom RecordReaderAll import *\n#from SegmentationRefinement import *\n\nHEIGHT=192\nWIDTH=256\nNUM_PLANES = 20\n\ndef _bytes_feature(value):\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _int64_feature(value):\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n\ndef _float_feature(value):\n    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n\n\ndef writeRecordFile(split, dataset):\n    \n    batchSize = 8\n    numOutputPlanes = 20\n    if split == 'train':\n        reader = RecordReaderAll()\n        filename_queue = tf.train.string_input_producer(['/mnt/vision/PlaneNet/planes_' + dataset + '_train_new.tfrecords'], num_epochs=1)\n        img_inp, global_gt_dict, _ = reader.getBatch(filename_queue, numOutputPlanes=numOutputPlanes, batchSize=batchSize, random=False, getLocal=True)\n        writer = tf.python_io.TFRecordWriter('/mnt/vision/PlaneNet/planes_' + dataset + '_train_temp.tfrecords')\n        numImages = 50000\n    else:\n        reader = RecordReaderAll()\n        filename_queue = tf.train.string_input_producer(['/mnt/vision/PlaneNet/planes_' + dataset + '_val.tfrecords'], num_epochs=1)\n        img_inp, global_gt_dict, _ = reader.getBatch(filename_queue, numOutputPlanes=numOutputPlanes, batchSize=batchSize, random=False, getLocal=True)\n        writer = tf.python_io.TFRecordWriter('/mnt/vision/PlaneNet/planes_' + dataset + '_val_temp.tfrecords')\n        numImages = 1000\n        pass\n    \n\n    # parser = argparse.ArgumentParser(description='Planenet')\n    # options = parser.parse_args()\n    # options.deepSupervisionLayers = ['res4b22_relu', ]\n    # options.predictConfidence = 0\n    # options.predictLocal = 0\n    # options.predictPixelwise = 1\n    # options.predictBoundary = 1\n    # options.predictSemantics = 0    \n    # options.anchorPlanes = 0\n    # options.numOutputPlanes = 20\n    # options.batchSize = 8\n    # options.useNonPlaneDepth = 1\n    \n\n    #training_flag = tf.constant(False, tf.bool)\n    \n    #options.gpu_id = 0\n    #global_pred_dict, _, _ = build_graph(img_inp, img_inp, training_flag, options)    \n\n    #var_to_restore = [v for v in tf.global_variables()]\n\n    config=tf.ConfigProto()\n    config.allow_soft_placement=True    \n    #config.gpu_options.allow_growth=True\n    config.gpu_options.per_process_gpu_memory_fraction=0.9    \n    \n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n    #numPlanesArray = []\n    \n    with tf.Session(config=config) as sess:\n        sess.run(init_op)        \n        #loader = tf.train.Saver(var_to_restore)\n        #loader.restore(sess, '/mnt/vision/PlaneNet/checkpoint/planenet_hybrid3_ll1_pb_pp/checkpoint.ckpt')\n        \n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n        try:\n            for _ in xrange(numImages / batchSize):\n                img, global_gt = sess.run([img_inp, global_gt_dict])\n\n                print(_)                \n                for batchIndex in xrange(batchSize):\n                    numPlanes = global_gt['num_planes'][batchIndex]\n                    if numPlanes == 0:\n                        print(_)\n                        print('no plane')\n                        continue\n                    \n                    image = ((img[batchIndex] + 0.5) * 255).astype(np.uint8)\n\n                    gt_s = np.concatenate([global_gt['segmentation'][batchIndex], global_gt['non_plane_mask'][batchIndex]], axis=-1)\n                    segmentation = np.argmax(gt_s, axis=-1).astype(np.uint8).squeeze()\n                    boundary = global_gt['boundary'][batchIndex].astype(np.uint8)\n                    semantics = global_gt['semantics'][batchIndex].astype(np.uint8)\n\n\n                    planes = global_gt['plane'][batchIndex]\n                    if np.isnan(planes).any():\n                        print(global_gt['image_path'][batchIndex])\n                        planes, segmentation, numPlanes = removeSmallSegments(planes, np.zeros((HEIGHT, WIDTH, 3)), global_gt['depth'][batchIndex].squeeze(), np.zeros((HEIGHT, WIDTH, 3)), np.argmax(global_gt['segmentation'][batchIndex], axis=-1), global_gt['semantics'][batchIndex], global_gt['info'][batchIndex], global_gt['num_planes'][batchIndex])\n                        if np.isnan(planes).any():\n                            np.save('temp/plane.npy', global_gt['plane'][batchIndex])                        \n                            np.save('temp/depth.npy', global_gt['depth'][batchIndex])\n                            np.save('temp/segmentation.npy', global_gt['segmentation'][batchIndex])\n                            np.save('temp/info.npy', global_gt['info'][batchIndex])\n                            np.save('temp/num_planes.npy', global_gt['num_planes'][batchIndex])\n                            print('why')\n                            exit(1)                            \n                            pass\n                        pass\n\n                    \n                    #if _ * batchSize + batchIndex < 29:\n                    #continue\n                    \n                    \n                    #pred_s = np.concatenate([pred_dict['segmentation'][batchIndex], pred_dict['non_plane_mask'][batchIndex]], axis=-1)\n                    #pred_s[:, :, numOutputPlanes] -= 0.1\n                    #pred_s = one_hot(np.argmax(pred_s, axis=-1), numOutputPlanes + 1)\n                    #planes, segmentation, numPlanes = filterPlanes(planes, gt_s, global_gt['depth'][batchIndex].squeeze(), global_gt['info'][batchIndex], pred_s)\n                    planes, segmentation, numPlanes = filterPlanes(planes, gt_s, global_gt['depth'][batchIndex].squeeze(), global_gt['info'][batchIndex])\n\n\n                    #cv2.imwrite('test/segmentation_' + str(batchIndex) + '_ori.png', drawSegmentationImage(gt_s, blackIndex=20))\n                    #cv2.imwrite('test/segmentation_' + str(batchIndex) + '_pred.png', drawSegmentationImage(pred_s, blackIndex=20))\n                    #cv2.imwrite('test/segmentation_' + str(batchIndex) + '_new.png', drawSegmentationImage(segmentation, blackIndex=20))\n\n                    # plane_depths = calcPlaneDepths(planes, WIDTH, HEIGHT, global_gt['info'][batchIndex])\n                    # all_depths = np.concatenate([plane_depths, global_gt['depth'][batchIndex]], axis=2)\n                    # depth = np.sum(all_depths * one_hot(segmentation.astype(np.int32), numOutputPlanes + 1), axis=2)\n                    # cv2.imwrite('test/segmentation_' + str(batchIndex) + '_depth.png', drawDepthImage(depth))\n\n\n                    # if batchIndex == 6:\n                    #     print(planes)\n                    #     exit(1)\n                    #continue\n\n                    if numPlanes == 0:\n                        continue\n\n                    #print(global_gt['num_planes'][batchIndex], numPlanes)\n                    #numPlanesArray.append(numPlanes)\n                    \n                    example = tf.train.Example(features=tf.train.Features(feature={\n                        'image_path': _bytes_feature(global_gt['image_path'][batchIndex]),\n                        'image_raw': _bytes_feature(image.tostring()),\n                        'depth': _float_feature(global_gt['depth'][batchIndex].reshape(-1)),\n                        'normal': _float_feature(global_gt['normal'][batchIndex].reshape(-1)),\n                        'semantics_raw': _bytes_feature(semantics.tostring()),\n                        'plane': _float_feature(planes.reshape(-1)),\n                        'num_planes': _int64_feature([numPlanes]),\n                        'segmentation_raw': _bytes_feature(segmentation.tostring()),\n                        'boundary_raw': _bytes_feature(boundary.tostring()),\n                        #'plane_relation': _float_feature(planeRelations.reshape(-1)),\n                        'info': _float_feature(global_gt['info'][batchIndex])}))\n                    \n                    writer.write(example.SerializeToString())\n                    continue\n                continue\n            pass\n        except tf.errors.OutOfRangeError:\n            print('Done training -- epoch limit reached')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n        \n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    #np.save('results/num_planes.npy', np.array(numPlanesArray))\n    return\n\n    \nif __name__=='__main__':\n    #writeRecordFile('val', 'matterport')\n    #writeRecordFile('val', 'scannet')\n    # writeRecordFile('train', 'matterport')    \n    #writeRecordFile('train', 'scannet')\n    #writeRecordFile('train', 'nyu_rgbd')\n    writeRecordFile('train', 'scannet')\n\n"""
code/RecordReader.py,114,"b""import tensorflow as tf\nimport numpy as np\nimport threading\nimport PIL.Image as Image\nfrom functools import partial\nfrom multiprocessing import Pool\nimport cv2\n\nimport sys\nimport os\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom modules import *\n\n\nHEIGHT=192\nWIDTH=256\nNUM_PLANES = 50\nNUM_THREADS = 4\n\n\n\n\n\nclass RecordReader():\n    def __init__(self):\n        return\n\n\n    def getBatch(self, filename_queue, numOutputPlanes = 20, batchSize = 16, min_after_dequeue = 1000, random=True, getLocal=False, getSegmentation=False, test=True):\n        reader = tf.TFRecordReader()\n        _, serialized_example = reader.read(filename_queue)\n\n        features = tf.parse_single_example(\n            serialized_example,\n            # Defaults are not specified since both keys are required.\n            features={\n                #'height': tf.FixedLenFeature([], tf.int64),\n                #'width': tf.FixedLenFeature([], tf.int64),\n                'image_raw': tf.FixedLenFeature([], tf.string),\n                'num_planes': tf.FixedLenFeature([], tf.int64),\n                'plane': tf.FixedLenFeature([NUM_PLANES * 3], tf.float32),\n                'plane_mask': tf.FixedLenFeature([HEIGHT * WIDTH], tf.int64),\n                #'validating': tf.FixedLenFeature([], tf.int64)\n                'depth': tf.FixedLenFeature([HEIGHT * WIDTH], tf.float32),\n                'normal': tf.FixedLenFeature([HEIGHT * WIDTH * 3], tf.float32),\n                'boundary_raw': tf.FixedLenFeature([], tf.string),\n                'grid_s': tf.FixedLenFeature([HEIGHT / 8  * WIDTH / 8 * 1], tf.float32),\n                'grid_p': tf.FixedLenFeature([HEIGHT / 8  * WIDTH / 8 * 3], tf.float32),\n                'grid_m_raw': tf.FixedLenFeature([], tf.string),\n                'image_path': tf.FixedLenFeature([], tf.string),                \n            })\n\n        # Convert from a scalar string tensor (whose single string has\n        # length mnist.IMAGE_PIXELS) to a uint8 tensor with shape\n        # [mnist.IMAGE_PIXELS].\n        image = tf.decode_raw(features['image_raw'], tf.uint8)\n        image = tf.cast(image, tf.float32) * (1. / 255) - 0.5\n        image = tf.reshape(image, [HEIGHT, WIDTH, 3])\n        \n        depth = features['depth']\n        depth = tf.reshape(depth, [HEIGHT, WIDTH, 1])\n\n        normal = features['normal']\n        normal = tf.reshape(normal, [HEIGHT, WIDTH, 3])\n\n\n        # planeAreaThreshold = 12 * 16\n        # inds, _, counts = tf.unique_with_counts(plane_masks)\n        # counts = counts * tf.cast(tf.greater(inds, 0), tf.int32)\n        # numPlanes = tf.minimum(tf.reduce_sum(tf.cast(counts > planeAreaThreshold, tf.int32)), numOutputPlanes)\n\n\n        if False:\n            numPlanes = tf.minimum(tf.cast(features['num_planes'], tf.int32), numOutputPlanes)\n            planes = features['plane']\n            planes = tf.reshape(planes, [NUM_PLANES, 3])\n            planes = tf.slice(planes, [0, 0], [numPlanes, 3])\n\n            plane_masks = tf.cast(features['plane_mask'], tf.int64)  \n            plane_masks = tf.reshape(plane_masks, [HEIGHT, WIDTH, 1])\n            plane_mask_array = tf.tile(plane_masks, [1, 1, NUM_PLANES])\n            coef = tf.range(tf.cast(NUM_PLANES, tf.int64), dtype=tf.int64)\n            coef = tf.pow(tf.constant(2, tf.int64), coef)\n            planeMasks = tf.reshape(tf.cast(tf.div(plane_mask_array, coef) % 2, tf.float32), [HEIGHT, WIDTH, NUM_PLANES])\n\n            #planeMasks = tf.zeros([HEIGHT, WIDTH, numOutputPlanes])\n        else:\n            numPlanes = 30\n            planes = features['plane']\n            planes = tf.reshape(planes, [NUM_PLANES, 3])\n            planes = tf.slice(planes, [0, 0], [numPlanes, 3])\n        \n            plane_masks = tf.cast(features['plane_mask'], tf.int64)  \n        \n            plane_masks = tf.reshape(plane_masks, [HEIGHT, WIDTH, 1])\n            plane_mask_array = tf.tile(plane_masks, [1, 1, numPlanes])\n            coef = tf.range(numPlanes, dtype=tf.int64)\n            coef = tf.pow(tf.constant(2, tf.int64), coef)\n            #coef = tf.reshape(tf.matmul(tf.reshape(coef, [-1, numPlanes]), tf.cast(shuffle_inds, tf.int32)), [numPlanes])\n            #coef = tf.cast(coef, tf.int64)\n            planeMasks = tf.cast(tf.div(plane_mask_array, coef) % 2, tf.float32)\n        \n            urange = tf.reshape(tf.range(WIDTH, dtype=tf.float32), [-1, 1])\n            planeXs = tf.reduce_max(planeMasks, axis=0)\n            planeMinX = WIDTH - tf.reduce_max(planeXs * (float(WIDTH) - urange), axis=0)\n            planeMaxX = tf.reduce_max(planeXs * urange, axis=0)\n\n            vrange = tf.reshape(tf.range(HEIGHT, dtype=tf.float32), [-1, 1])\n            planeYs = tf.reduce_max(planeMasks, axis=1)\n            planeMinY = HEIGHT - tf.reduce_max(planeYs * (float(HEIGHT) - vrange), axis=0)\n            planeMaxY = tf.reduce_max(planeYs * vrange, axis=0)\n\n            planeMaxX = tf.maximum(planeMinX, planeMaxX)\n            planeMaxY = tf.maximum(planeMinY, planeMaxY)\n\n            planeAreas = tf.reduce_sum(planeMasks, axis=[0, 1])\n        \n            localPlaneWidthThreshold = 32\n            localPlaneHeightThreshold = 32\n            globalPlaneAreaThreshold = 16 * 16\n            globalPlaneWidthThreshold = 8\n\n\n            globalPlaneMask = tf.logical_or(tf.greater(planeMaxX - planeMinX, localPlaneWidthThreshold), tf.greater(planeMaxY - planeMinY, localPlaneHeightThreshold))\n            globalPlaneMask = tf.logical_and(globalPlaneMask, tf.greater((planeMaxX - planeMinX) * (planeMaxY - planeMinY), globalPlaneAreaThreshold))\n            globalPlaneMask = tf.logical_and(globalPlaneMask, tf.greater(planeAreas / tf.sqrt(tf.pow(planeMaxX + 1 - planeMinX, 2) + tf.pow(planeMaxY + 1 - planeMinY, 2)), globalPlaneWidthThreshold))\n            #globalPlaneMask = tf.logical_or(globalPlaneMask, tf.less(tf.range(numPlanes), tf.cast(features['num_planes'], tf.int32)))\n            #globalPlaneMask = tf.cast(tf.squeeze(globalPlaneMask, axis=[2]), tf.float32)\n            globalPlaneMask = tf.cast(globalPlaneMask, tf.float32)\n\n            weightedPlaneAreas = globalPlaneMask * (planeAreas + HEIGHT * WIDTH) + (1 - globalPlaneMask) * planeAreas\n\n            #test = tf.reshape(tf.stack([globalPlaneMask, planeAreas, weightedPlaneAreas, planeMinX, planeMaxX, planeMinY, planeMaxY], axis=0), [7, numPlanes])\n            \n            planeAreas, sortInds = tf.nn.top_k(weightedPlaneAreas, k=numPlanes)\n            sortMap = tf.one_hot(sortInds, depth=numPlanes, axis=0)\n\n            planeMasks = tf.reshape(tf.matmul(tf.reshape(planeMasks, [HEIGHT * WIDTH, numPlanes]), sortMap), [HEIGHT, WIDTH, numPlanes])\n            planes = tf.transpose(tf.matmul(planes, sortMap, transpose_a=True), [1, 0])\n        \n            numPlanes = tf.minimum(tf.cast(tf.round(tf.reduce_sum(globalPlaneMask)), tf.int32), numOutputPlanes)\n            \n            planes = tf.slice(planes, [0, 0], [numPlanes, 3])\n            planeMasks = tf.slice(planeMasks, [0, 0, 0], [HEIGHT, WIDTH, numPlanes])\n            planeMasks = tf.reshape(tf.concat([planeMasks, tf.zeros([HEIGHT, WIDTH, numOutputPlanes - numPlanes])], axis=2), [HEIGHT, WIDTH, numOutputPlanes])\n            pass\n\n        # planeMasks_expanded = tf.expand_dims(planeMasks, 0)\n        # boundary = tf.reduce_max(tf.nn.max_pool(planeMasks_expanded, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding='SAME', name='max_pool') - planeMasks_expanded, axis=3, keep_dims=True)\n        # max_depth_diff = 0.1\n        # depth_expanded = tf.expand_dims(depth, 0)\n        # kernel_size = 5\n        # padding = (kernel_size - 1) / 2\n        # neighbor_kernel_array = gaussian(kernel_size, kernel_size)\n        # neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n        # neighbor_kernel_array /= neighbor_kernel_array.sum()\n        # neighbor_kernel_array *= -1\n        # neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 1\n        # neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n        # neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n        \n        # depth_diff = tf.abs(tf.nn.depthwise_conv2d(depth_expanded, neighbor_kernel, strides=[1, 1, 1, 1], padding='VALID'))\n        # depth_diff = tf.pad(depth_diff, paddings = [[0, 0], [padding, padding], [padding, padding], [0, 0]])\n        # smooth_boundary = boundary * tf.cast(tf.less(depth_diff, max_depth_diff), tf.float32)\n        # occlusion_boundary = boundary - smooth_boundary\n        # boundary = tf.squeeze(tf.concat([smooth_boundary, occlusion_boundary], axis=3), axis=0)\n\n        \n        #validating = tf.cast(features['validating'], tf.float32)        \n        shuffle_inds = tf.one_hot(tf.random_shuffle(tf.range(numPlanes)), depth = numPlanes)\n        #shuffle_inds = tf.one_hot(tf.range(numPlanes), depth = numPlanes)\n        \n        #shuffle_inds = tf.concat([shuffle_inds, tf.zeros((numPlanes, numOutputPlanes - numPlanes))], axis=1)\n        #shuffle_inds = tf.concat([shuffle_inds, tf.concat([tf.zeros((numOutputPlanes - numPlanes, numPlanes)), tf.diag(tf.ones([numOutputPlanes - numPlanes]))], axis=1)], axis=0)\n        planes = tf.transpose(tf.matmul(tf.transpose(planes), shuffle_inds))\n        planes = tf.reshape(planes, [numPlanes, 3])\n        planes = tf.concat([planes, tf.zeros([numOutputPlanes - numPlanes, 3])], axis=0)\n        planes = tf.reshape(planes, [numOutputPlanes, 3])\n\n        \n        boundary = tf.decode_raw(features['boundary_raw'], tf.uint8)\n        boundary = tf.cast(boundary > 128, tf.float32)\n        boundary = tf.reshape(boundary, [HEIGHT, WIDTH, 2])\n        #boundary = tf.slice(tf.reshape(boundary, [HEIGHT, WIDTH, 3]), [0, 0, 0], [HEIGHT, WIDTH, 2])\n\n        grid_s = tf.reshape(features['grid_s'], [HEIGHT / 8, WIDTH / 8, 1])       \n        grid_p = tf.reshape(features['grid_p'], [HEIGHT / 8, WIDTH / 8, 3])\n        \n        grid_m = tf.decode_raw(features['grid_m_raw'], tf.uint8)\n        grid_m = tf.cast(tf.reshape(grid_m, [HEIGHT / 8, WIDTH / 8, 16 * 16]), tf.float32)\n\n        if getLocal:\n            if random:\n                image_inp, plane_inp, depth_gt, normal_gt, plane_mask_inp, boundary_gt, grid_s_gt, grid_p_gt, grid_m_gt, num_planes_gt, image_path_gt = tf.train.shuffle_batch([image, planes, depth, normal, planeMasks, boundary, grid_s, grid_p, grid_m, numPlanes, features['image_path']], batch_size=batchSize, capacity=min_after_dequeue + (NUM_THREADS + 2) * batchSize, num_threads=NUM_THREADS, min_after_dequeue=min_after_dequeue)\n            else:\n                image_inp, plane_inp, depth_gt, normal_gt, plane_mask_inp, boundary_gt, grid_s_gt, grid_p_gt, grid_m_gt, num_planes_gt, image_path_gt = tf.train.batch([image, planes, depth, normal, planeMasks, boundary, grid_s, grid_p, grid_m, numPlanes, features['image_path']], batch_size=batchSize, capacity=(NUM_THREADS + 2) * batchSize, num_threads=1)\n                pass\n            global_gt_dict = {'plane': plane_inp, 'depth': depth_gt, 'normal': normal_gt, 'segmentation': plane_mask_inp, 'boundary': boundary_gt, 'num_planes': num_planes_gt, 'image_path': image_path_gt}\n            local_gt_dict = {'score': grid_s_gt, 'plane': grid_p_gt, 'mask': grid_m_gt}\n            return image_inp, global_gt_dict, local_gt_dict\n\n\n        plane_masks = tf.cast(features['plane_mask'], tf.int64)  \n        \n        plane_masks = tf.reshape(plane_masks, [HEIGHT, WIDTH, 1])\n        plane_mask_array = tf.tile(plane_masks, [1, 1, numPlanes])\n        coef = tf.range(numPlanes, dtype=tf.int64)\n        coef = tf.pow(2, coef)\n        coef = tf.reshape(tf.matmul(tf.reshape(coef, [-1, numPlanes]), tf.cast(shuffle_inds, tf.int64)), [numPlanes])\n        coef = tf.cast(coef, tf.int64)\n        plane_mask_array = tf.cast(tf.div(plane_mask_array, coef) % 2, tf.float32)\n        plane_mask_array = tf.concat([plane_mask_array, tf.zeros([HEIGHT, WIDTH, numOutputPlanes - numPlanes])], axis=2)\n        plane_mask_array = tf.reshape(plane_mask_array, [HEIGHT, WIDTH, numOutputPlanes])\n        #num_planes_array = tf.concat([tf.ones([numPlanes], dtype=np.float32) / tf.cast(numPlanes * BATCH_SIZE, np.float32), tf.zeros([numOutputPlanes - numPlanes])], axis=0)\n\n        #image_inp, plane_inp, depth_gt, normal_gt, plane_mask_inp, num_planes, mask = tf.train.shuffle_batch([image, planes, depth, normal, plane_mask_array, numPlanes, plane_masks_test], batch_size=batchSize, capacity=min_after_dequeue + (NUM_THREADS + 2) * batchSize, num_threads=NUM_THREADS, min_after_dequeue=min_after_dequeue)\n\n        # if True:\n        #     image_inp, plane_inp, depth_gt, normal_gt, plane_mask_inp = tf.train.batch([image, planes, tf.ones((HEIGHT, WIDTH, 1)), tf.ones((HEIGHT, WIDTH, 3)), plane_mask_array], batch_size=batchSize, capacity=(NUM_THREADS + 2) * batchSize, num_threads=NUM_THREADS)\n        #     return image_inp, plane_inp, depth_gt, normal_gt, plane_mask_inp\n\n        if random:\n            image_inp, plane_inp, depth_gt, normal_gt, plane_mask_inp, boundary_gt, grid_s_gt, grid_p_gt, grid_m_gt, num_planes_gt = tf.train.shuffle_batch([image, planes, depth, normal, plane_mask_array, boundary, grid_s, grid_p, grid_m, numPlanes], batch_size=batchSize, capacity=min_after_dequeue + (NUM_THREADS + 2) * batchSize, num_threads=NUM_THREADS, min_after_dequeue=min_after_dequeue)            \n            image_inp, plane_inp, depth_gt, normal_gt, plane_mask_gt, boundary_gt, num_planes_gt = tf.train.shuffle_batch([image, planes, depth, normal, plane_mask_array, boundary, numPlanes], batch_size=batchSize, capacity=min_after_dequeue + (NUM_THREADS + 2) * batchSize, num_threads=NUM_THREADS, min_after_dequeue=min_after_dequeue)\n        else:\n            image_inp, plane_inp, depth_gt, normal_gt, plane_mask_inp, boundary_gt, grid_s_gt, grid_p_gt, grid_m_gt, num_planes_gt = tf.train.batch([image, planes, depth, normal, plane_mask_array, boundary, grid_s, grid_p, grid_m, numPlanes], batch_size=batchSize, capacity=(NUM_THREADS + 2) * batchSize, num_threads=1)            \n            pass\n\n        #segmentation and boundary ground truth is not used, and they are calculated on-the-fly as the implementation is subject to change\n        global_gt_dict = {'plane': plane_inp, 'depth': depth_gt, 'normal': normal_gt, 'segmentation': plane_mask_inp, 'boundary': boundary_gt, 'num_planes': num_planes_gt}\n        local_gt_dict = {'score': grid_s_gt, 'plane': grid_p_gt, 'mask': grid_m_gt}\n        return image_inp, global_gt_dict, local_gt_dict\n"""
code/RecordReader3D.py,42,"b""import tensorflow as tf\nimport numpy as np\nimport threading\nimport PIL.Image as Image\nfrom functools import partial\nfrom multiprocessing import Pool\nimport cv2\n\nimport sys\nimport os\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom modules import *\n\n\nHEIGHT=192\nWIDTH=256\nNUM_PLANES = 20\nNUM_THREADS = 4\n\n\n\nclass RecordReader3D():\n    def __init__(self):\n        return\n\n\n    def getBatch(self, filename_queue, numOutputPlanes = 20, batchSize = 16, min_after_dequeue = 1000, random=True, getLocal=False, getSegmentation=False, test=True):\n        reader = tf.TFRecordReader()\n        _, serialized_example = reader.read(filename_queue)\n\n        features = tf.parse_single_example(\n            serialized_example,\n            # Defaults are not specified since both keys are required.\n            features={\n                #'height': tf.FixedLenFeature([], tf.int64),\n                #'width': tf.FixedLenFeature([], tf.int64),\n                'image_raw': tf.FixedLenFeature([], tf.string),\n                'image_path': tf.FixedLenFeature([], tf.string),\n                'num_planes': tf.FixedLenFeature([], tf.int64),\n                'plane': tf.FixedLenFeature([NUM_PLANES * 3], tf.float32),\n                'plane_relation': tf.FixedLenFeature([NUM_PLANES * NUM_PLANES], tf.float32),\n                'segmentation_raw': tf.FixedLenFeature([], tf.string),\n                'depth': tf.FixedLenFeature([HEIGHT * WIDTH], tf.float32),\n                'smooth_boundary_raw': tf.FixedLenFeature([], tf.string),\n                'info': tf.FixedLenFeature([3 + 4*4], tf.float32),                \n            })\n\n        # Convert from a scalar string tensor (whose single string has\n        # length mnist.IMAGE_PIXELS) to a uint8 tensor with shape\n        # [mnist.IMAGE_PIXELS].\n        image = tf.decode_raw(features['image_raw'], tf.uint8)\n        image = tf.cast(image, tf.float32) * (1. / 255) - 0.5\n        image = tf.reshape(image, [HEIGHT, WIDTH, 3])\n        \n        depth = features['depth']\n        depth = tf.reshape(depth, [HEIGHT, WIDTH, 1])\n\n        numPlanes = tf.minimum(tf.cast(features['num_planes'], tf.int32), numOutputPlanes)\n        \n        planes = features['plane']\n        planes = tf.reshape(planes, [NUM_PLANES, 3])\n        \n        # planes = tf.slice(planes, [0, 0], [numPlanes, 3])\n        # #shuffle_inds = tf.one_hot(tf.random_shuffle(tf.range(numPlanes)), depth = numPlanes)\n        # shuffle_inds = tf.one_hot(tf.range(numPlanes), depth = numPlanes)\n        \n        # planes = tf.transpose(tf.matmul(tf.transpose(planes), shuffle_inds))\n        # planes = tf.reshape(planes, [numPlanes, 3])\n        # planes = tf.concat([planes, tf.zeros([numOutputPlanes - numPlanes, 3])], axis=0)\n        # planes = tf.reshape(planes, [numOutputPlanes, 3])\n\n        \n        smooth_boundary = tf.decode_raw(features['smooth_boundary_raw'], tf.uint8)\n        smooth_boundary = tf.cast(smooth_boundary, tf.float32)\n        smooth_boundary = tf.reshape(smooth_boundary, [HEIGHT, WIDTH, 1])\n\n        segmentation = tf.decode_raw(features['segmentation_raw'], tf.uint8)\n        segmentation = tf.cast(tf.reshape(segmentation, [HEIGHT, WIDTH, 1]), tf.int32)\n        #segmentation = segmentation + tf.cast(tf.equal(segmentation, 19), tf.int32)\n        plane_masks = segmentation\n\n        # coef = tf.range(numPlanes)\n        # coef = tf.reshape(tf.matmul(tf.reshape(coef, [-1, numPlanes]), tf.cast(shuffle_inds, tf.int32)), [1, 1, numPlanes])\n        \n        # plane_masks = tf.cast(tf.equal(segmentation, tf.cast(coef, tf.uint8)), tf.float32)\n        # plane_masks = tf.concat([plane_masks, tf.zeros([HEIGHT, WIDTH, numOutputPlanes - numPlanes])], axis=2)\n        # plane_masks = tf.reshape(plane_masks, [HEIGHT, WIDTH, numOutputPlanes])\n\n        \n        #non_plane_mask = tf.cast(tf.equal(segmentation, tf.cast(numOutputPlanes, tf.uint8)), tf.float32)\n        #non_plane_mask = 1 - tf.reduce_max(plane_masks, axis=2, keep_dims=True)\n        \n        #tf.cast(tf.equal(segmentation, tf.cast(numOutputPlanes, tf.uint8)), tf.float32)\n        \n        if random:\n            image_inp, plane_inp, depth_gt, plane_masks_gt, smooth_boundary_gt, num_planes_gt, image_path, info = tf.train.shuffle_batch([image, planes, depth, plane_masks, smooth_boundary, numPlanes, features['image_path'], features['info']], batch_size=batchSize, capacity=min_after_dequeue + (NUM_THREADS + 2) * batchSize, num_threads=NUM_THREADS, min_after_dequeue=min_after_dequeue)\n        else:\n            image_inp, plane_inp, depth_gt, plane_masks_gt, smooth_boundary_gt, num_planes_gt, image_path, info = tf.train.batch([image, planes, depth, plane_masks, smooth_boundary, numPlanes, features['image_path'], features['info']], batch_size=batchSize, capacity=(NUM_THREADS + 2) * batchSize, num_threads=1)\n            pass\n        global_gt_dict = {'plane': plane_inp, 'depth': depth_gt, 'segmentation': plane_masks_gt, 'smooth_boundary': smooth_boundary_gt, 'num_planes': num_planes_gt, 'image_path': image_path, 'info': info}\n        return image_inp, global_gt_dict, {}\n"""
code/RecordReaderAll.py,51,"b""import tensorflow as tf\nimport numpy as np\nimport threading\nimport PIL.Image as Image\nfrom functools import partial\nfrom multiprocessing import Pool\nimport cv2\n\nimport sys\nimport os\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom modules import *\n\n\nHEIGHT=192\nWIDTH=256\nNUM_PLANES = 20\nNUM_THREADS = 4\n\n\n\nclass RecordReaderAll():\n    def __init__(self):\n        return\n\n    def getBatch(self, filename_queue, numOutputPlanes = 20, batchSize = 16, min_after_dequeue = 1000, random=True, getLocal=False, getSegmentation=False, test=True):\n        reader = tf.TFRecordReader()\n        _, serialized_example = reader.read(filename_queue)\n\n        features = tf.parse_single_example(\n            serialized_example,\n            # Defaults are not specified since both keys are required.\n            features={\n                #'height': tf.FixedLenFeature([], tf.int64),\n                #'width': tf.FixedLenFeature([], tf.int64),\n                'image_raw': tf.FixedLenFeature([], tf.string),\n                'image_path': tf.FixedLenFeature([], tf.string),\n                'num_planes': tf.FixedLenFeature([], tf.int64),\n                'plane': tf.FixedLenFeature([NUM_PLANES * 3], tf.float32),\n                #'plane_relation': tf.FixedLenFeature([NUM_PLANES * NUM_PLANES], tf.float32),\n                'segmentation_raw': tf.FixedLenFeature([], tf.string),\n                'depth': tf.FixedLenFeature([HEIGHT * WIDTH], tf.float32),\n                'normal': tf.FixedLenFeature([HEIGHT * WIDTH * 3], tf.float32),\n                'semantics_raw': tf.FixedLenFeature([], tf.string),                \n                'boundary_raw': tf.FixedLenFeature([], tf.string),\n                'info': tf.FixedLenFeature([4 * 4 + 4], tf.float32),                \n            })\n\n        # Convert from a scalar string tensor (whose single string has\n        # length mnist.IMAGE_PIXELS) to a uint8 tensor with shape\n        # [mnist.IMAGE_PIXELS].\n        image = tf.decode_raw(features['image_raw'], tf.uint8)\n        image = tf.cast(image, tf.float32) * (1. / 255) - 0.5\n        image = tf.reshape(image, [HEIGHT, WIDTH, 3])\n\n        \n        depth = features['depth']\n        depth = tf.reshape(depth, [HEIGHT, WIDTH, 1])\n\n        normal = features['normal']\n        normal = tf.reshape(normal, [HEIGHT, WIDTH, 3])\n        \n        normal = tf.nn.l2_normalize(normal, dim=2)\n        \n        #normal = tf.stack([normal[:, :, 1], normal[:, :, 0], normal[:, :, 2]], axis=2)\n\n\n        semantics = tf.decode_raw(features['semantics_raw'], tf.uint8)\n        semantics = tf.cast(tf.reshape(semantics, [HEIGHT, WIDTH]), tf.int32)\n\n        numPlanes = tf.minimum(tf.cast(features['num_planes'], tf.int32), numOutputPlanes)\n\n        numPlanesOri = numPlanes\n        numPlanes = tf.maximum(numPlanes, 1)\n        \n        planes = features['plane']\n        planes = tf.reshape(planes, [NUM_PLANES, 3])\n        planes = tf.slice(planes, [0, 0], [numPlanes, 3])\n\n        #shuffle_inds = tf.one_hot(tf.random_shuffle(tf.range(numPlanes)), depth = numPlanes)\n        shuffle_inds = tf.one_hot(tf.range(numPlanes), numPlanes)\n        \n        planes = tf.transpose(tf.matmul(tf.transpose(planes), shuffle_inds))\n        planes = tf.reshape(planes, [numPlanes, 3])\n        planes = tf.concat([planes, tf.zeros([numOutputPlanes - numPlanes, 3])], axis=0)\n        planes = tf.reshape(planes, [numOutputPlanes, 3])\n\n        \n        boundary = tf.decode_raw(features['boundary_raw'], tf.uint8)\n        boundary = tf.cast(tf.reshape(boundary, (HEIGHT, WIDTH, 2)), tf.float32)\n\n        #boundary = tf.decode_raw(features['boundary_raw'], tf.float64)\n        #boundary = tf.cast(tf.reshape(boundary, (HEIGHT, WIDTH, 3)), tf.float32)        \n        #boundary = tf.slice(boundary, [0, 0, 0], [HEIGHT, WIDTH, 2])\n\n        segmentation = tf.decode_raw(features['segmentation_raw'], tf.uint8)\n        segmentation = tf.reshape(segmentation, [HEIGHT, WIDTH, 1])\n\n\n        \n        coef = tf.range(numPlanes)\n        coef = tf.reshape(tf.matmul(tf.reshape(coef, [-1, numPlanes]), tf.cast(shuffle_inds, tf.int32)), [1, 1, numPlanes])\n        \n        plane_masks = tf.cast(tf.equal(segmentation, tf.cast(coef, tf.uint8)), tf.float32)\n        plane_masks = tf.concat([plane_masks, tf.zeros([HEIGHT, WIDTH, numOutputPlanes - numPlanes])], axis=2)\n        plane_masks = tf.reshape(plane_masks, [HEIGHT, WIDTH, numOutputPlanes])\n\n        #non_plane_mask = tf.cast(tf.equal(segmentation, tf.cast(numOutputPlanes, tf.uint8)), tf.float32)\n        non_plane_mask = 1 - tf.reduce_max(plane_masks, axis=2, keep_dims=True)\n        #tf.cast(tf.equal(segmentation, tf.cast(numOutputPlanes, tf.uint8)), tf.float32)\n\n        \n        if random:\n            image_inp, plane_inp, depth_gt, normal_gt, semantics_gt, plane_masks_gt, boundary_gt, num_planes_gt, non_plane_mask_gt, image_path, info = tf.train.shuffle_batch([image, planes, depth, normal, semantics, plane_masks, boundary, numPlanesOri, non_plane_mask, features['image_path'], features['info']], batch_size=batchSize, capacity=min_after_dequeue + (NUM_THREADS + 2) * batchSize, num_threads=NUM_THREADS, min_after_dequeue=min_after_dequeue)\n        else:\n            image_inp, plane_inp, depth_gt, normal_gt, semantics_gt, plane_masks_gt, boundary_gt, num_planes_gt, non_plane_mask_gt, image_path, info = tf.train.batch([image, planes, depth, normal, semantics, plane_masks, boundary, numPlanesOri, non_plane_mask, features['image_path'], features['info']], batch_size=batchSize, capacity=(NUM_THREADS + 2) * batchSize, num_threads=1)\n            pass\n        global_gt_dict = {'plane': plane_inp, 'depth': depth_gt, 'normal': normal_gt, 'semantics': semantics_gt, 'segmentation': plane_masks_gt, 'boundary': boundary_gt, 'num_planes': num_planes_gt, 'non_plane_mask': non_plane_mask_gt, 'image_path': image_path, 'info': info}\n        return image_inp, global_gt_dict, {}\n"""
code/RecordReaderRGBD.py,28,"b""import tensorflow as tf\nimport numpy as np\nimport threading\nimport PIL.Image as Image\nfrom functools import partial\nfrom multiprocessing import Pool\nimport cv2\n\nimport sys\nimport os\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom modules import *\n\n\nHEIGHT=192\nWIDTH=256\nNUM_PLANES = 20\nNUM_THREADS = 4\n\n\n\nclass RecordReaderRGBD():\n    def __init__(self):\n        return\n\n\n    def getBatch(self, filename_queue, numOutputPlanes = 20, batchSize = 16, min_after_dequeue = 1000, random=True, getLocal=False, getSegmentation=False, test=True):\n        reader = tf.TFRecordReader()\n        _, serialized_example = reader.read(filename_queue)\n\n        features = tf.parse_single_example(\n            serialized_example,\n            # Defaults are not specified since both keys are required.\n            features={\n                #'height': tf.FixedLenFeature([], tf.int64),\n                #'width': tf.FixedLenFeature([], tf.int64),\n                'image_path': tf.FixedLenFeature([], tf.string),                \n                'image_raw': tf.FixedLenFeature([], tf.string),\n                'depth': tf.FixedLenFeature([HEIGHT * WIDTH], tf.float32),\n                'normal': tf.FixedLenFeature([HEIGHT * WIDTH * 3], tf.float32),\n                #'normal': tf.FixedLenFeature([427 * 561 * 3], tf.float32),                \n                'plane': tf.FixedLenFeature([NUM_PLANES * 3], tf.float32),\n                'num_planes': tf.FixedLenFeature([], tf.int64),                \n                #'plane_relation': tf.FixedLenFeature([NUM_PLANES * NUM_PLANES], tf.float32),\n                'segmentation_raw': tf.FixedLenFeature([], tf.string),\n                #'smooth_boundary_raw': tf.FixedLenFeature([], tf.string),\n                #'info': tf.FixedLenFeature([3 + 4*4], tf.float32),                \n            })\n\n        # Convert from a scalar string tensor (whose single string has\n        # length mnist.IMAGE_PIXELS) to a uint8 tensor with shape\n        # [mnist.IMAGE_PIXELS].\n        image = tf.decode_raw(features['image_raw'], tf.uint8)\n        image = tf.cast(image, tf.float32) * (1. / 255) - 0.5\n        image = tf.reshape(image, [HEIGHT, WIDTH, 3])\n        \n        depth = features['depth']\n        depth = tf.reshape(depth, [HEIGHT, WIDTH, 1])\n\n        normal = features['normal']\n        normal = tf.reshape(normal, [HEIGHT, WIDTH, 3])\n        \n        #normal = tf.reshape(normal, [427, 561, 3])\n        #normal = tf.image.resize_images(normal, [HEIGHT, WIDTH])\n        \n        numPlanes = tf.minimum(tf.cast(features['num_planes'], tf.int32), numOutputPlanes)\n        \n        planes = features['plane']\n        planes = tf.reshape(planes, [NUM_PLANES, 3])\n\n        segmentation = tf.decode_raw(features['segmentation_raw'], tf.int32)\n        segmentation = tf.cast(tf.reshape(segmentation, [HEIGHT, WIDTH, 1]), tf.int32)\n\n\n        info = np.zeros(20)\n        info[0] = 5.1885790117450188e+02\n        info[2] = 3.2558244941119034e+02 - 40\n        info[5] = 5.1946961112127485e+02\n        info[6] = 2.5373616633400465e+02 - 44\n        info[10] = 1\n        info[15] = 1\n        info[16] = 561\n        info[17] = 427\n        info[18] = 1000\n        info[19] = 1\n        \n        if random:\n            image_inp, plane_inp, depth_gt, normal_gt, segmentation_gt, num_planes_gt, image_path, info_gt = tf.train.shuffle_batch([image, planes, depth, normal, segmentation, numPlanes, features['image_path'], info], batch_size=batchSize, capacity=min_after_dequeue + (NUM_THREADS + 2) * batchSize, num_threads=NUM_THREADS, min_after_dequeue=min_after_dequeue)\n        else:\n            image_inp, plane_inp, depth_gt, normal_gt, segmentation_gt, num_planes_gt, image_path, info_gt = tf.train.batch([image, planes, depth, normal, segmentation, numPlanes, features['image_path'], info], batch_size=batchSize, capacity = (NUM_THREADS + 2) * batchSize, num_threads=1)\n            pass\n        \n        global_gt_dict = {'plane': plane_inp, 'depth': depth_gt, 'normal': normal_gt, 'segmentation': segmentation_gt, 'num_planes': num_planes_gt, 'image_path': image_path, 'info': info_gt}\n        return image_inp, global_gt_dict, {}\n"""
code/RecordReaderWithoutPlane.py,18,"b""import tensorflow as tf\nimport numpy as np\nimport threading\nimport PIL.Image as Image\nfrom functools import partial\nfrom multiprocessing import Pool\nimport cv2\n\nFETCH_BATCH_SIZE=32\nBATCH_SIZE=32\nHEIGHT=192\nWIDTH=256\nNUM_PLANES = 50\nNUM_THREADS = 4\n\n\ndef loadImagePaths():\n    image_set_file = '../PythonScripts/SUNCG/image_list_500000.txt'\n    with open(image_set_file) as f:\n        filenames = [x.strip().replace('plane_global.npy', '') for x in f.readlines()]\n        image_paths = [{'image': x + 'mlt.png', 'plane': x + 'plane_global.npy', 'normal': x + 'norm_camera.png', 'depth': x + 'depth.png', 'mask': x + 'valid.png', 'masks': x + 'masks.npy'} for x in filenames]\n        pass\n    return image_paths\n\n\nclass RecordReader():\n    def __init__(self):\n        self.imagePaths = loadImagePaths()\n        self.imagePaths = self.imagePaths[:100000]\n        self.numImages = len(self.imagePaths)\n        self.trainingPercentage = 0.9\n        self.numTrainingImages = int(self.numImages * self.trainingPercentage)\n        return\n\n\n    def getBatch(self, filename_queue, numOutputPlanes = 20, batchSize = BATCH_SIZE, min_after_dequeue = 1000, random=True, getLocal=False, getSegmentation=False):\n        reader = tf.TFRecordReader()\n        _, serialized_example = reader.read(filename_queue)\n\n        features = tf.parse_single_example(\n            serialized_example,\n            # Defaults are not specified since both keys are required.\n            features={\n                #'height': tf.FixedLenFeature([], tf.int64),\n                #'width': tf.FixedLenFeature([], tf.int64),\n                'image_path': tf.FixedLenFeature([], tf.string),\n                'image_raw': tf.FixedLenFeature([], tf.string),\n                'depth': tf.FixedLenFeature([HEIGHT * WIDTH], tf.float32),\n                'normal': tf.FixedLenFeature([HEIGHT * WIDTH * 3], tf.float32),\n                'invalid_mask_raw': tf.FixedLenFeature([], tf.string),\n            })\n\n        # Convert from a scalar string tensor (whose single string has\n        # length mnist.IMAGE_PIXELS) to a uint8 tensor with shape\n        # [mnist.IMAGE_PIXELS].\n        image = tf.decode_raw(features['image_raw'], tf.uint8)\n        image = tf.cast(image, tf.float32) * (1. / 255) - 0.5\n        image = tf.reshape(image, [HEIGHT, WIDTH, 3])\n        \n        depth = features['depth']\n        depth = tf.reshape(depth, [HEIGHT, WIDTH, 1])\n\n        normal = features['normal']\n        normal = tf.reshape(normal, [HEIGHT, WIDTH, 3])\n\n        invalid_mask = tf.decode_raw(features['invalid_mask_raw'], tf.uint8)\n        invalid_mask = tf.cast(invalid_mask > 128, tf.float32)\n        invalid_mask = tf.reshape(invalid_mask, [HEIGHT, WIDTH, 1])\n        \n        image_path = features['image_path']\n        \n        image_inp, depth_gt, normal_gt, invalid_mask_gt, image_path_inp = tf.train.batch([image, depth, normal, invalid_mask, image_path], batch_size=batchSize, capacity=(NUM_THREADS + 2) * batchSize, num_threads=NUM_THREADS)\n        return image_inp, depth_gt, normal_gt, invalid_mask_gt, image_path_inp\n"""
code/RecordSampler.py,14,"b""import tensorflow as tf\nimport numpy as np\nimport cv2\nimport random\nimport PIL.Image\nimport sys\nimport os\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom modules import *\nfrom utils import *\nfrom RecordReaderAll import *\nfrom SegmentationRefinement import *\n\nHEIGHT=192\nWIDTH=256\nNUM_PLANES = 20\n\ndef _bytes_feature(value):\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _int64_feature(value):\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n\ndef _float_feature(value):\n    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n\n\ndef writeRecordFile(split, dataset):\n    \n    batchSize = 8\n    numOutputPlanes = 20\n    if split == 'train':\n        reader = RecordReaderAll()\n        filename_queue = tf.train.string_input_producer(['/mnt/vision/PlaneNet/planes_' + dataset + '_train.tfrecords'], num_epochs=1)\n        img_inp, global_gt_dict, _ = reader.getBatch(filename_queue, numOutputPlanes=numOutputPlanes, batchSize=batchSize, random=False, getLocal=True)\n        numImages = 5000\n        writer = tf.python_io.TFRecordWriter('/mnt/vision/PlaneNet/planes_' + dataset + '_train_sample_' + str(numImages) + '.tfrecords')\n\n    else:\n        reader = RecordReaderAll()\n        filename_queue = tf.train.string_input_producer(['/mnt/vision/PlaneNet/planes_' + dataset + '_val.tfrecords'], num_epochs=1)\n        img_inp, global_gt_dict, _ = reader.getBatch(filename_queue, numOutputPlanes=numOutputPlanes, batchSize=batchSize, random=False, getLocal=True)\n        writer = tf.python_io.TFRecordWriter('/mnt/vision/PlaneNet/planes_' + dataset + '_val_sample.tfrecords')\n        numImages = 100\n        pass\n    \n        \n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n    \n    with tf.Session() as sess:\n        sess.run(init_op)\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n        try:\n            for _ in xrange(numImages / batchSize):\n                print(_)\n                img, global_gt = sess.run([img_inp, global_gt_dict])\n                for batchIndex in xrange(batchSize):\n                    image = ((img[batchIndex] + 0.5) * 255).astype(np.uint8)\n                    \n                    segmentation = np.argmax(np.concatenate([global_gt['segmentation'][batchIndex], global_gt['non_plane_mask'][batchIndex]], axis=-1), axis=-1).astype(np.uint8).squeeze()\n                    #boundary = global_gt['boundary'][batchIndex].astype(np.uint8)\n                    semantics = global_gt['semantics'][batchIndex].astype(np.uint8)\n                    boundary = global_gt['boundary'][batchIndex].astype(np.uint8)\n\n                    planes = global_gt['plane'][batchIndex]\n                    numPlanes = global_gt['num_planes'][batchIndex]\n\n                    # cv2.imwrite('test/image.png', image)\n                    # cv2.imwrite('test/segmentation.png', drawSegmentationImage(segmentation))\n                    # exit(1)\n                    \n                    example = tf.train.Example(features=tf.train.Features(feature={\n                        'image_path': _bytes_feature(global_gt['image_path'][batchIndex]),\n                        'image_raw': _bytes_feature(image.tostring()),\n                        'depth': _float_feature(global_gt['depth'][batchIndex].reshape(-1)),\n                        'normal': _float_feature(global_gt['normal'][batchIndex].reshape(-1)),\n                        'semantics_raw': _bytes_feature(semantics.tostring()),\n                        'plane': _float_feature(planes.reshape(-1)),\n                        'num_planes': _int64_feature([numPlanes]),\n                        'segmentation_raw': _bytes_feature(segmentation.tostring()),\n                        'boundary_raw': _bytes_feature(boundary.tostring()),\n                        #'plane_relation': _float_feature(planeRelations.reshape(-1)),\n                        'info': _float_feature(global_gt['info'][batchIndex]),\n                    }))\n                    \n                    writer.write(example.SerializeToString())\n                    continue\n                continue\n            pass\n        except tf.errors.OutOfRangeError:\n            print('Done training -- epoch limit reached')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n        \n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()    \n    return\n\n    \nif __name__=='__main__':\n    #writeRecordFile('val', 'matterport')\n    #writeRecordFile('val', 'scannet')\n    # writeRecordFile('train', 'matterport')    \n    writeRecordFile('train', 'scannet')    \n\n"""
code/RecordWriter.py,140,"b'import tensorflow as tf\nimport numpy as np\nimport cv2\nimport random\nimport PIL.Image\nimport sys\nimport os\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom modules import *\nfrom utils import *\nfrom RecordReaderV5 import *\n\nfrom planenet import PlaneNet\nimport tf_nndistance\n\nnp.set_printoptions(precision=2, linewidth=200)\n\n\nHEIGHT=192\nWIDTH=256\nNUM_PLANES = 20\n\nMOVING_AVERAGE_DECAY = 0.99\n                          \ndeepSupervisionLayers=[\'res4b22_relu\']\n\ndef build_graph(img_inp_train, img_inp_val, plane_gt_train, plane_gt_val, validating_inp, is_training=True, numOutputPlanes=20, gpu_id = 0, without_segmentation=False, without_plane=False, without_depth=False, useCRF=0):\n    \n    with tf.device(\'/gpu:%d\'%gpu_id):\n        training_flag = tf.logical_not(validating_inp)\n        #training_flag = tf.convert_to_tensor(True, dtype=\'bool\', name=\'is_training\')\n        #training_flag = tf.convert_to_tensor(is_training, dtype=\'bool\', name=\'is_training\')\n        \n        img_inp = tf.cond(validating_inp, lambda: img_inp_val, lambda: img_inp_train)\n        plane_gt = tf.cond(validating_inp, lambda: plane_gt_val, lambda: plane_gt_train)\n\n        net = PlaneNet({\'img_inp\': img_inp}, is_training=training_flag, numGlobalPlanes=numOutputPlanes, deepSupervisionLayers=deepSupervisionLayers)\n        segmentation_pred = net.layers[\'segmentation_pred\']\n        plane_pred = net.layers[\'plane_pred\']\n        boundary_pred = net.layers[\'boundary_pred\']\n        grid_s_pred = net.layers[\'s_8_pred\']\n        grid_p_pred = net.layers[\'p_8_pred\']\n        grid_m_pred = net.layers[\'m_8_pred\']\n\n\n        # dists_forward, map_forward, dists_backward, map_backward = tf_nndistance.nn_distance(plane_gt, plane_pred)\n        # plane_map = tf.one_hot(map_forward, depth=numOutputPlanes, axis=-1)\n        # plane_pred = tf.transpose(tf.matmul(plane_gt, plane_map, transpose_a=True), [0, 2, 1])\n        #plane_pred = tf.tile(tf.slice(plane_gt, [0, 11, 0], [int(plane_gt.shape[0]), 1, 3]), [1, numOutputPlanes, 1])\n        \n        if not is_training:\n            with tf.variable_scope(\'depth\'):\n                plane_parameters = tf.reshape(plane_pred, (-1, 3))\n                plane_depths = planeDepthsModule(plane_parameters, WIDTH, HEIGHT)\n                plane_depths = tf.transpose(tf.reshape(plane_depths, [HEIGHT, WIDTH, -1, numOutputPlanes]), [2, 0, 1, 3])\n\n                segmentation = segmentation_pred\n                # if useCRF > 0:\n                #     segmentation = tf.nn.softmax(segmentation)\n                #     with tf.variable_scope(\'crf\'):\n                #         segmentation = segmentationRefinementModule(segmentation, plane_depths, numIterations=useCRF)\n                #         pass\n                #     pass\n                # else:\n                #     #segmentation = tf.one_hot(tf.argmax(segmentation, 3), depth=numOutputPlanes)\n                #     segmentation = tf.nn.softmax(segmentation)\n                #     pass\n                segmentation = tf.nn.softmax(segmentation)\n                \n                segmentation = tf.cond(training_flag, lambda: segmentation, lambda: tf.one_hot(tf.argmax(segmentation, 3), depth=numOutputPlanes))\n                #plane_depths = tf.concat([plane_depths, non_plane_depth], 3)\n                #segmentation = tf.concat([segmentation, tf.ones(non_plane_depth.shape) * 0.5], 3)            \n                depth_pred = tf.reduce_sum(tf.multiply(plane_depths, segmentation), axis=3, keep_dims=True)\n                pass\n\n            with tf.variable_scope(\'normal\'):\n                plane_normals = planeNormalsModule(plane_parameters, WIDTH, HEIGHT)\n                plane_normals = tf.reshape(plane_normals, [-1, 1, 1, numOutputPlanes, 3])\n                normal_pred = tf.reduce_sum(tf.multiply(plane_normals, tf.expand_dims(segmentation, -1)), axis=3)\n                pass\n            pass\n        else:\n            depth_pred = tf.zeros((plane_pred.shape[0], HEIGHT, WIDTH, 1))\n            normal_pred = tf.zeros((plane_pred.shape[0], HEIGHT, WIDTH, 1))\n            segmentation = tf.zeros((plane_pred.shape[0], HEIGHT, WIDTH, numOutputPlanes))\n            pass\n\n    plane_preds = []\n    segmentation_preds = []\n    for layer in deepSupervisionLayers:\n        plane_preds.append(net.layers[layer+\'_plane_pred\'])\n        segmentation_preds.append(net.layers[layer+\'_segmentation_pred\'])\n        continue\n      \n    return plane_pred, depth_pred, normal_pred, segmentation_pred, boundary_pred, grid_s_pred, grid_p_pred, grid_m_pred, plane_preds, segmentation_preds, segmentation\n\ndef build_loss(plane_pred, depth_pred, normal_pred, segmentation_pred, boundary_pred, grid_s_pred, grid_p_pred, grid_m_pred, plane_preds, segmentation_preds, plane_gt_train, depth_gt_train, normal_gt_train, segmentation_gt_train, boundary_gt_train, grid_s_gt_train, grid_p_gt_train, grid_m_gt_train, plane_gt_val, depth_gt_val, normal_gt_val, segmentation_gt_val, boundary_gt_val, grid_s_gt_val, grid_p_gt_val, grid_m_gt_val, validating_inp, numOutputPlanes = 20, gpu_id = 0, without_segmentation=False, without_depth=False, useCRF=False):\n    with tf.device(\'/gpu:%d\'%gpu_id):\n        plane_gt = tf.cond(validating_inp, lambda: plane_gt_val, lambda: plane_gt_train)\n        depth_gt = tf.cond(validating_inp, lambda: depth_gt_val, lambda: depth_gt_train)\n        normal_gt = tf.cond(validating_inp, lambda: normal_gt_val, lambda: normal_gt_train)\n        boundary_gt = tf.cond(validating_inp, lambda: boundary_gt_val, lambda: boundary_gt_train)\n        grid_s_gt = tf.cond(validating_inp, lambda: grid_s_gt_val, lambda: grid_s_gt_train)\n        grid_p_gt = tf.cond(validating_inp, lambda: grid_p_gt_val, lambda: grid_p_gt_train)\n        grid_m_gt = tf.cond(validating_inp, lambda: grid_m_gt_val, lambda: grid_m_gt_train)\n        \n        dists_forward, map_forward, dists_backward, map_backward = tf_nndistance.nn_distance(plane_gt, plane_pred)\n        plane_map = tf.one_hot(map_forward, depth=numOutputPlanes, axis=-1)\n        shuffled_planes = tf.transpose(tf.matmul(plane_pred, plane_map, transpose_a=True, transpose_b=True), [0, 2, 1])\n        dists = tf.concat([plane_gt, shuffled_planes, tf.expand_dims(dists_forward, -1), tf.expand_dims(dists_backward, -1), tf.expand_dims(tf.cast(map_forward, tf.float32), -1), tf.expand_dims(tf.cast(map_backward, tf.float32), -1)], axis=2)\n\n        \n        useBackward = 0\n        \n        dists_forward = tf.reduce_mean(dists_forward)\n        dists_backward = tf.reduce_mean(dists_backward)\n        plane_loss = (dists_forward + dists_backward / 2.0 * useBackward) * 10000\n\n        forward_loss = dists_forward * 10000\n        backward_loss = dists_backward / 2.0 * 10000\n\n        \n        if False:\n            segmentation_gt = tf.cond(validating_inp, lambda: segmentation_gt_val, lambda: segmentation_gt_train)\n        else:\n            normalDotThreshold = np.cos(np.deg2rad(1))\n            distanceThreshold = 0.1\n\n            focalLength = 517.97\n            urange = (tf.range(WIDTH, dtype=tf.float32) / (WIDTH + 1) - 0.5) / focalLength * 641\n            urange = tf.tile(tf.reshape(urange, [1, -1]), [HEIGHT, 1])\n            vrange = (tf.range(HEIGHT, dtype=tf.float32) / (HEIGHT + 1) - 0.5) / focalLength * 481\n            vrange = tf.tile(tf.reshape(vrange, [-1, 1]), [1, WIDTH])\n        \n            X = depth_gt * tf.expand_dims(urange, -1)\n            Y = depth_gt\n            Z = -depth_gt * tf.expand_dims(vrange, -1)\n            XYZ = tf.concat([X, Y, Z], axis=3)\n            XYZ = tf.reshape(XYZ, [-1, HEIGHT * WIDTH, 3])\n            #ranges = tf.stack([urange, np.ones([height, width]), -vrange], axis=2)\n            #ranges = tf.reshape(ranges, [-1, 3])\n            #plane_parameters = tf.reshape(plane_gt, [-1, 3])\n            plane_parameters = plane_gt\n            planesD = tf.norm(plane_parameters, axis=2, keep_dims=True)\n            planesD = tf.clip_by_value(planesD, 1e-5, 10)\n            planesNormal = tf.div(tf.negative(plane_parameters), planesD)\n\n            distance = tf.reshape(tf.abs(tf.matmul(XYZ, planesNormal, transpose_b=True) + tf.reshape(planesD, [-1, 1, numOutputPlanes])), [-1, HEIGHT, WIDTH, numOutputPlanes])\n            angle = tf.reshape(np.abs(tf.matmul(tf.reshape(normal_gt, [-1, HEIGHT * WIDTH, 3]), planesNormal, transpose_b=True)), [-1, HEIGHT, WIDTH, numOutputPlanes])\n            segmentation_gt = tf.cast(tf.logical_and(tf.greater(angle, normalDotThreshold), tf.less(distance, distanceThreshold)), tf.float32)\n            pass\n        \n\n        segmentation_map = tf.one_hot(map_forward, depth=numOutputPlanes, axis=-1)\n        segmentation_gt_shuffled = tf.reshape(tf.matmul(tf.reshape(segmentation_gt, [-1, HEIGHT * WIDTH, numOutputPlanes]), segmentation_map), [-1, HEIGHT, WIDTH, numOutputPlanes])\n        segmentation_gt_shuffled = tf.cast(segmentation_gt_shuffled > 0.5, tf.float32)\n        segmentation_test = segmentation_gt_shuffled\n        \n        segmentation_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=segmentation_pred, labels=segmentation_gt_shuffled)) * 1000\n\n        plane_mask = tf.reduce_max(segmentation_gt, axis=3)\n        plane_mask = tf.expand_dims(plane_mask, -1)\n\n        errorMask = tf.zeros(depth_gt.shape)\n        if not without_depth and False:\n            depth_loss = tf.reduce_mean(tf.squared_difference(depth_pred, depth_gt) * plane_mask) * 1000\n            normal_loss = tf.reduce_mean(tf.squared_difference(normal_pred, normal_gt) * plane_mask) * 1000\n        else:\n            if False:\n                depth_loss = 0\n            else:\n                plane_parameters = tf.reshape(plane_pred, (-1, 3))\n                plane_depths = planeDepthsModule(plane_parameters, WIDTH, HEIGHT)\n                plane_depths = tf.transpose(tf.reshape(plane_depths, [HEIGHT, WIDTH, -1, numOutputPlanes]), [2, 0, 1, 3])\n\n                segmentation = segmentation_pred\n                # if useCRF > 0:\n                #     segmentation = tf.nn.softmax(segmentation)\n                #     with tf.variable_scope(\'crf\'):\n                #         segmentation = segmentationRefinementModule(segmentation, plane_depths, numIterations=useCRF)\n                #         pass\n                #     pass\n                # else:\n                #     #segmentation = tf.one_hot(tf.argmax(segmentation, 3), depth=numOutputPlanes)\n                #     segmentation = tf.nn.softmax(segmentation)\n                #     pass\n                segmentation = tf.nn.softmax(segmentation)\n                depth_loss = tf.reduce_mean(tf.reduce_sum(tf.squared_difference(plane_depths, depth_gt) * segmentation, axis=3, keep_dims=True) * plane_mask) * 1000\n                pass\n\n            plane_normals = planeNormalsModule(plane_parameters, WIDTH, HEIGHT)\n            plane_normals = tf.reshape(plane_normals, [-1, 1, 1, numOutputPlanes, 3])\n            #normal_pred = tf.reduce_sum(tf.multiply(plane_normals, tf.expand_dims(segmentation, -1)), axis=3)\n            \n            #normal_loss = tf.reduce_mean(tf.reduce_mean(tf.squared_difference(plane_normals, tf.expand_dims(normal_gt, 3)) * tf.expand_dims(segmentation, -1), axis=3) * plane_mask) * 1000\n            normal_loss = 0\n            \n            if useCRF:\n                kernel_size = 5\n                padding = (kernel_size - 1) / 2\n                neighbor_kernel_array = gaussian(kernel_size, kernel_size)\n                neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n                neighbor_kernel_array /= neighbor_kernel_array.sum()\n                #neighbor_kernel_array *= -1\n                #neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 1\n                neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n                neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n\n                #DS_diff = tf.clip_by_value(tf.abs(plane_depths - depth_pred), 0, 1)\n                #DS_diff = tf.clip_by_value(tf.abs(plane_depths - depth_pred), 0, 1) * tf.cast(tf.greater(tf.sigmoid(tf.slice(boundary_pred, [0, 0, 0, 0], [int(boundary_pred.shape[0]), HEIGHT, WIDTH, 1])),  0.5), tf.float32)\n                #DS = tf.nn.depthwise_conv2d(DS_diff, tf.tile(neighbor_kernel, [1, 1, numOutputPlanes, 1]), strides=[1, 1, 1, 1], padding=\'VALID\')\n                #DS = tf.pad(DS, paddings = [[0, 0], [padding, padding], [padding, padding], [0, 0]])\n\n\n                max_depth_diff = 0.2\n                #depth_diff_cost = 0.2\n\n                depth_neighbor = tf.nn.depthwise_conv2d(depth_gt, neighbor_kernel, strides=[1, 1, 1, 1], padding=\'VALID\')\n                depth_neighbor = tf.pad(depth_neighbor, paddings = [[0, 0], [padding, padding], [padding, padding], [0, 0]])\n                #depth_diff = tf.abs(plane_depths - depth_neighbor)\n                #depth_diff = tf.clip_by_value(tf.pow(depth_diff / max_depth_diff, 2), 0, 1)\n                depth_diff = tf.reduce_sum(tf.squared_difference(plane_depths, depth_neighbor) * segmentation, axis=3, keep_dims=True)\n\n                neighbor_kernel_array *= -1\n                neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 1\n                neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n                neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])                \n                #segmentation = tf.one_hot(tf.argmax(segmentation, 3), depth=numOutputPlanes)\n                segmentation_diff = tf.nn.depthwise_conv2d(segmentation, tf.tile(neighbor_kernel, [1, 1, numOutputPlanes, 1]), strides=[1, 1, 1, 1], padding=\'VALID\')\n                segmentation_diff = tf.pad(segmentation_diff, paddings = [[0, 0], [padding, padding], [padding, padding], [0, 0]])\n                segmentation_diff = tf.clip_by_value(tf.reduce_sum(tf.abs(segmentation_diff), axis=3, keep_dims=True), 0, 1)\n                \n                #smooth_boundary = tf.sigmoid(tf.slice(boundary_pred, [0, 0, 0, 0], [int(boundary_pred.shape[0]), HEIGHT, WIDTH, 1]))\n                #occlusion_boundary = tf.sigmoid(tf.slice(boundary_pred, [0, 0, 0, 1], [int(boundary_pred.shape[0]), HEIGHT, WIDTH, 1]))\n                smooth_boundary = tf.slice(boundary_gt, [0, 0, 0, 0], [int(boundary_gt.shape[0]), HEIGHT, WIDTH, 1])\n                occlusion_boundary = tf.slice(boundary_gt, [0, 0, 0, 1], [int(boundary_gt.shape[0]), HEIGHT, WIDTH, 1])\n                smooth_mask = depth_diff * smooth_boundary + segmentation_diff * tf.clip_by_value(1 - smooth_boundary - occlusion_boundary, 0, 1)\n                #smooth_mask = segmentation_diff * tf.clip_by_value(1 - smooth_boundary - occlusion_boundary, 0, 1)\n                #smooth_mask = tf.clip_by_value(1 - smooth_boundary - occlusion_boundary, 0, 1)\n                #smooth_mask = depth_diff * smooth_boundary\n                smooth_loss = tf.reduce_mean(smooth_mask) * 10000\n                \n                errorMask = smooth_mask\n                #errorMask = (1 - tf.sigmoid(tf.slice(boundary_pred, [0, 0, 0, 1], [int(boundary_pred.shape[0]), HEIGHT, WIDTH, 1])))\n            else:\n                smooth_loss = tf.constant(0.0)\n            pass\n        \n        #s_8_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=s_8_pred, labels=s_8_gt)) * 1000\n        grid_s_loss = tf.reduce_mean(tf.losses.sigmoid_cross_entropy(logits=grid_s_pred, multi_class_labels=grid_s_gt, weights=tf.maximum(grid_s_gt * 10, 1))) * 1000\n        grid_p_loss = tf.reduce_mean(tf.squared_difference(grid_p_pred, grid_p_gt) * grid_s_gt) * 10000\n        grid_m_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=grid_m_pred, labels=grid_m_gt) * grid_s_gt) * 10000\n        boundary_loss = tf.reduce_mean(tf.losses.sigmoid_cross_entropy(logits=boundary_pred, multi_class_labels=boundary_gt, weights=tf.maximum(boundary_gt * 5, 1))) * 1000\n        \n        l2_losses = tf.add_n([5e-4 * tf.nn.l2_loss(v) for v in tf.trainable_variables() if \'weights\' in v.name])\n        #loss = plane_loss + segmentation_loss + depth_loss + normal_loss + l2_losses\n        loss = plane_loss + segmentation_loss + depth_loss + normal_loss + l2_losses + grid_s_loss + grid_p_loss + grid_m_loss + boundary_loss + smooth_loss\n        #loss = plane_loss + segmentation_loss + depth_loss + normal_loss + l2_losses\n        pass\n\n\n    if True:\n        for layer, pred_p in enumerate(plane_preds):\n            dists_forward, map_forward, dists_backward, _ = tf_nndistance.nn_distance(plane_gt, pred_p)\n            plane_map = tf.one_hot(map_forward, depth=numOutputPlanes, axis=-1)\n            shuffled_planes = tf.transpose(tf.matmul(pred_p, plane_map, transpose_a=True, transpose_b=True), [0, 2, 1])\n            #dists = tf.concat([dists, shuffled_planes, tf.expand_dims(dists_forward, -1)], axis=2)            \n\n            dists_forward = tf.reduce_mean(dists_forward)\n            dists_backward = tf.reduce_mean(dists_backward)\n            loss += (dists_forward + dists_backward / 2.0 * useBackward) * 10000\n            \n            loss_p_0 = (dists_forward + dists_backward / 2.0 * useBackward) * 10000\n\n            segmentation_map = tf.one_hot(map_forward, depth=numOutputPlanes, axis=-1)\n            segmentation_gt_shuffled = tf.reshape(tf.matmul(tf.reshape(segmentation_gt, [-1, HEIGHT * WIDTH, numOutputPlanes]), segmentation_map), [-1, HEIGHT, WIDTH, numOutputPlanes])\n            segmentation_gt_shuffled = tf.cast(segmentation_gt_shuffled > 0.5, tf.float32)\n            \n            pred_s = segmentation_preds[layer]\n            loss += tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=pred_s, labels=segmentation_gt_shuffled)) * 1000\n            loss_s_0 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=pred_s, labels=segmentation_gt_shuffled)) * 1000\n            pass\n        pass\n\n    return loss, plane_loss, segmentation_loss + depth_loss + normal_loss + grid_s_loss + grid_p_loss + grid_m_loss, boundary_loss, smooth_loss, segmentation_gt, plane_mask, errorMask, dists\n\n\ndef _bytes_feature(value):\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _int64_feature(value):\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n\ndef _float_feature(value):\n    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n\n\ndef writeRecordFile(split):\n    \n    batchSize = 8\n    numOutputPlanes = 20\n    if split == \'train\':\n        reader_train = RecordReader()\n        filename_queue_train = tf.train.string_input_producer([\'../planes_new_450000.tfrecords\'], num_epochs=1)\n        img_inp, plane_gt, depth_gt, normal_gt, plane_mask_gt, boundary_gt, grid_s_gt, grid_p_gt, grid_m_gt, num_planes_gt, image_path_inp = reader_train.getBatch(filename_queue_train, batchSize=batchSize, random=False)\n        writer = tf.python_io.TFRecordWriter(\'../planes_temp_450000.tfrecords\')\n    else:\n        reader_val = RecordReader()\n        filename_queue_val = tf.train.string_input_producer([\'../planes_new_1000_450000.tfrecords\'], num_epochs=1)\n        img_inp, plane_gt, depth_gt, normal_gt, plane_mask_gt, boundary_gt, grid_s_gt, grid_p_gt, grid_m_gt, num_planes_gt, image_path_inp = reader_val.getBatch(filename_queue_val, batchSize=batchSize, random=False)\n        writer = tf.python_io.TFRecordWriter(\'../planes_temp_1000_450000.tfrecords\')\n        pass\n\n\n    validating_inp = tf.placeholder(tf.bool, shape=[], name=\'validating_inp\')\n    plane_pred, depth_pred, normal_pred, segmentation_pred, boundary_pred, grid_s_pred, grid_p_pred, grid_m_pred, plane_preds, segmentation_preds, refined_segmentation = build_graph(img_inp, img_inp, plane_gt, plane_gt, validating_inp, without_segmentation=False, without_plane=False, useCRF=False, is_training=False)\n    var_to_restore = tf.global_variables()    \n    loss, plane_loss, depth_loss, normal_loss, segmentation_loss, segmentation_gt, mask_gt, error_mask, dists = build_loss(plane_pred, depth_pred, normal_pred, segmentation_pred, boundary_pred, grid_s_pred, grid_p_pred, grid_m_pred, plane_preds, segmentation_preds, tf.slice(plane_gt, [0, 0, 0], [batchSize, numOutputPlanes, 3]), depth_gt, normal_gt, plane_mask_gt, boundary_gt, grid_s_gt, grid_p_gt, grid_m_gt, tf.slice(plane_gt, [0, 0, 0], [batchSize, numOutputPlanes, 3]), depth_gt, normal_gt, plane_mask_gt, boundary_gt, grid_s_gt, grid_p_gt, grid_m_gt, validating_inp, gpu_id=0, without_segmentation=False, useCRF=False, without_depth=True)   \n    \n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n    testdir = \'test_all_resnet_v2/\'\n    \n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n        loader = tf.train.Saver(var_to_restore)\n        loader.restore(sess,""dump_supervision_deeplab_forward/train_supervision_deeplab_forward.ckpt"")\n\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n        try:\n            for _ in xrange(100000):\n                print(_)\n                images, global_p, depths, normals, global_m, boundaries, grid_s, grid_p, grid_m, num_planes, image_paths, pred_d, gt_mask = sess.run([img_inp, plane_gt, depth_gt, normal_gt, plane_mask_gt, boundary_gt, grid_s_gt, grid_p_gt, grid_m_gt, num_planes_gt, image_path_inp, depth_pred, mask_gt], feed_dict = {validating_inp:True})\n                for batchIndex in xrange(batchSize):\n                    # print(global_p[batchIndex])\n                    # print(original_p[batchIndex])\n                    # exit(1)\n\n                    image = ((images[batchIndex] + 0.5) * 255).astype(np.uint8)\n                    img_raw = image.tostring()\n                    depth = depths[batchIndex]\n                    normal = normals[batchIndex]\n                    numPlanes = int(num_planes[batchIndex])\n                    planes = global_p[batchIndex]\n                    planeMask = global_m[batchIndex]\n                    boundary = boundaries[batchIndex]\n                    boundary_raw = (boundary * 255).astype(np.uint8).tostring()\n                    \n                    grid_scores = grid_s[batchIndex]\n                    grid_planes = grid_p[batchIndex]\n                    grid_masks = grid_m[batchIndex]\n                    \n                    grid_masks = (grid_masks > 0.5).astype(np.uint8)\n                    grid_masks_raw = grid_masks.reshape(-1).tostring()\n                    image_path = image_paths[batchIndex]\n\n                    rms, accuracy = evaluateDepths(pred_d[batchIndex], depth, np.ones(gt_mask[batchIndex].shape), gt_mask[batchIndex], printInfo=False)\n                    if (rms < 0.8 and accuracy > 0.7) or (rms < 1 and accuracy > 0.85):\n                        example = tf.train.Example(features=tf.train.Features(feature={\n                            \'num_planes\': _int64_feature([numPlanes]),\n                            \'image_raw\': _bytes_feature(img_raw),\n                            \'image_path\': _bytes_feature(image_path),\n                            \'normal\': _float_feature(normal.reshape(-1)),\n                            \'depth\': _float_feature(depth.reshape(-1)),\n                            #\'invalid_mask_raw\': _bytes_feature(invalid_mask_raw),\n                            \'plane\': _float_feature(planes.reshape(-1)),\n                            \'plane_mask\': _int64_feature(planeMask.reshape(-1)),\n                            \'boundary_raw\': _bytes_feature(boundary_raw),\n                            #\'local_box\': _float_feature(boxes.reshape(-1)),\n                            \'grid_s\': _float_feature(grid_scores.astype(np.float).reshape(-1)),\n                            \'grid_p\': _float_feature(grid_planes.astype(np.float).reshape(-1)),\n                            \'grid_m_raw\': _bytes_feature(grid_masks_raw),\n                        }))\n                        writer.write(example.SerializeToString())\n                        pass\n                    continue\n                continue\n            pass\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n        \n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()    \n    return\n\n    \nif __name__==\'__main__\':\n    writeRecordFile(\'train\')\n'"
code/RecordWriter3D.py,10,"b""import tensorflow as tf\nimport numpy as np\nimport cv2\nimport random\nimport PIL.Image\nimport glob\nfrom utils import *\n\nHEIGHT=192\nWIDTH=256\nNUM_PLANES = 20\n\ndef _bytes_feature(value):\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _int64_feature(value):\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n\ndef _float_feature(value):\n    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n\ndef writeExample(writer, imagePath):\n    #img = np.array(Image.open(imagePath['image']))\n    img = cv2.imread(imagePath['image'])\n    img = cv2.resize(img, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n\n    height = img.shape[0]\n    width = img.shape[1]\n    img_raw = img.tostring()\n\n\n    with open(imagePath['info']) as info_file:\n        #with open('/mnt/vision/ScanNet/scene') as pose_file:\n        info = np.zeros(3 + 4 * 4)\n        line_index = 0\n        for line in info_file:\n            line = line.split(' ')\n            if line[0] == 'm_depthWidth':\n                info[0] = int(line[2])\n            elif line[0] == 'm_depthHeight':\n                info[1] = int(line[2])\n            elif line[0] == 'm_depthShift':\n                info[2] = int(line[2])\n            elif line[0] == 'm_calibrationDepthIntrinsic':\n                for i in xrange(16):\n                    info[3 + i] = float(line[2 + i])\n                    continue\n                pass\n            line_index += 1\n            continue\n        pass\n    \n    depth = np.array(PIL.Image.open(imagePath['depth'])).astype(np.float32) / info[2]\n    depth = cv2.resize(depth, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n\n    globalSegmentation = cv2.imread(imagePath['segmentation'])\n    mask = globalSegmentation.sum(axis=2)\n    non_plane_mask = mask == 255 * 3\n    boundary_mask = (mask == 0).astype(np.uint8)\n\n    if non_plane_mask.sum() + boundary_mask.sum() > mask.shape[0] * mask.shape[1] * 0.5:\n        return\n    \n    globalSegmentation = globalSegmentation[:, :, 2] * (256 * 256) + globalSegmentation[:, :, 1] * 256 + globalSegmentation[:, :, 0]\n    globalSegmentation = (np.round(globalSegmentation.astype(np.float32) / 100) - 1).astype(np.int32)\n\n    segments, unique_counts = np.unique(globalSegmentation, return_counts=True)\n    segments = segments.tolist()\n    unique_counts.tolist()\n\n    #print(segments)\n\n    segmentList = zip(segments, unique_counts)\n    segmentList = [segment for segment in segmentList if segment[0] not in [-1, 167771]]\n\n    if len(segmentList) == 0 or len(segmentList) > NUM_PLANES:\n        if len(segmentList) > NUM_PLANES and False:\n            print('num planes ' + str(len(segmentList)))\n            cv2.imwrite('test/image.png', img)            \n            cv2.imwrite('test/segmentation.png', drawSegmentationImage(globalSegmentation))\n            cv2.imwrite('test/boundary.png', drawMaskImage(boundary_mask))\n            cv2.imwrite('test/non_plane.png', drawMaskImage(non_plane_mask))\n            cv2.imwrite('test/depth.png', drawDepthImage(depth))\n            print(imagePath['segmentation'])\n            exit(1)\n            pass\n        return\n        \n    #segmentList = sorted(segmentList, key=lambda x:-x[1])\n    #segmentList = segmentList[:min(len(segmentList), NUM_PLANES)]\n    segments, unique_counts = zip(*segmentList)\n    segments = list(segments)\n    unique_counts = list(unique_counts)\n\n    \n    globalPlanes = np.load(imagePath['plane'])\n    numGlobalPlanes = globalPlanes.shape[0]\n    globalPlaneRelations = np.load(imagePath['plane_relation'])\n    segmentation = np.zeros(globalSegmentation.shape)\n    planes = []\n    for segmentIndex, globalSegmentIndex in enumerate(segments):\n        segmentation[globalSegmentation == globalSegmentIndex] = segmentIndex + 1\n        planes.append(globalPlanes[globalSegmentIndex])\n        continue\n    planes = np.array(planes)\n    numPlanes = planes.shape[0]\n    planeMapping = np.zeros((NUM_PLANES, numGlobalPlanes))\n    planeMapping[np.arange(numPlanes), segments] = 1\n    planeRelations = np.matmul(planeMapping, np.matmul(globalPlaneRelations, np.transpose(planeMapping)))\n\n    segmentation = segmentation.astype(np.uint8)\n    segmentation[non_plane_mask] = NUM_PLANES + 1\n    \n    kernel = np.ones((3, 3), np.uint8)\n    kernel[0][0] = kernel[2][0] = kernel[0][2] = kernel[2][2] = 0\n\n    ori_boundary_mask = boundary_mask\n    for _ in xrange(2):\n        segmentation = segmentation + cv2.dilate(segmentation, kernel) * boundary_mask\n        boundary_mask = boundary_mask * (segmentation == 0)\n        continue\n    smooth_boundary = cv2.resize(np.maximum(ori_boundary_mask - boundary_mask, 0), (WIDTH, HEIGHT), interpolation=cv2.INTER_NEAREST)\n    \n    segmentation -= 1\n    segmentation = cv2.resize(segmentation, (WIDTH, HEIGHT), interpolation=cv2.INTER_NEAREST)\n\n    \n    with open(imagePath['pose']) as pose_file:\n        #with open('/mnt/vision/ScanNet/scene') as pose_file:\n        pose = []\n        for line in pose_file:\n            line = line.split(' ')\n            for value in line:\n                pose.append(float(value))\n                continue\n            continue\n        pose = np.array(pose).reshape([4, 4])\n        pass\n\n    pose = np.linalg.inv(pose)\n    temp = pose[1].copy()\n    pose[1] = pose[2]\n    pose[2] = -temp\n\n    planes = transformPlanes(planes, pose)\n\n    if numPlanes < NUM_PLANES:\n        planes = np.concatenate([planes, np.zeros((NUM_PLANES - numPlanes, 3))], axis=0)\n        pass\n\n    \n    example = tf.train.Example(features=tf.train.Features(feature={\n        'image_path': _bytes_feature(imagePath['image']),\n        'image_raw': _bytes_feature(img_raw),\n        'depth': _float_feature(depth.reshape(-1)),\n        'plane': _float_feature(planes.reshape(-1)),\n        'num_planes': _int64_feature([numPlanes]),\n        'segmentation_raw': _bytes_feature(segmentation.tostring()),        \n        'smooth_boundary_raw': _bytes_feature(smooth_boundary.tostring()),        \n        'plane_relation': _float_feature(planeRelations.reshape(-1)),\n        'info': _float_feature(info.reshape(-1)),        \n    }))\n    writer.write(example.SerializeToString())\n    return\n\n\ndef writeRecordFile(tfrecords_filename, imagePaths):\n    writer = tf.python_io.TFRecordWriter(tfrecords_filename)\n    for index, imagePath in enumerate(imagePaths):\n        if index % 100 == 0:\n            print(index)            \n            pass\n        writeExample(writer, imagePath)\n        continue\n    writer.close()\n    return\n\n\nif __name__=='__main__':\n    #imagePaths = glob.glob('/home/chenliu/Projects/Data/ScanNet/*/annotation/segmentation/frame-*.segmentation.png')\n    #imagePaths = glob.glob('/mnt/vision/ScanNet/*/annotation/segmentation/frame-*.segmentation.png')\n\n    #datasets = {'scannet': '/mnt/vision/ScanNet/data/', 'matterport': '/mnt/vision/matterport/data/v1/scans/'}\n    datasets = {'scannet': '/home/chenliu/Projects/Data/ScanNet/data/', 'matterport': '/mnt/vision/matterport/data/v1/scans/'}\n\n    for dataset, ROOT_FOLDER in datasets.iteritems():\n        if dataset == 'matterport':\n            continue\n        all_scene_ids = os.listdir(ROOT_FOLDER)\n\n        for split in ['val', 'train']:\n            if split == 'val':\n                continue\n            if split == 'val':\n                scene_ids = all_scene_ids[int(len(all_scene_ids) * 0.9):]\n            else:\n                scene_ids = all_scene_ids[:int(len(all_scene_ids) * 0.9)]\n                pass\n\n            segmentationPaths = []\n            for scene_id in scene_ids:\n                segmentationPaths += glob.glob(ROOT_FOLDER + scene_id + '/annotation/segmentation*/frame-*.segmentation.png')\n                continue\n\n            imagePaths = []\n            for segmentationPath in segmentationPaths:\n                framePath = segmentationPath.replace('annotation/segmentation', 'frames')\n                imagePath = {'image': framePath.replace('segmentation.png', 'color.jpg'), 'depth': framePath.replace('segmentation.png', 'depth.pgm'), 'segmentation': segmentationPath, 'plane': '/'.join(segmentationPath.split('/')[:-2]) + '/planes.npy', 'plane_relation': '/'.join(segmentationPath.split('/')[:-2]) + '/plane_relations.npy', 'pose': framePath.replace('segmentation.png', 'pose.txt'), 'info': '/'.join(framePath.split('/')[:-1]) + '/_info.txt'}\n                imagePaths.append(imagePath)\n                continue\n            random.shuffle(imagePaths)\n            if split == 'val':\n                imagePaths = imagePaths[:2000]\n            else:\n                imagePaths = imagePaths[100000:]\n                pass\n            print('num images', len(imagePaths))\n                \n            #writeRecordFile('/mnt/vision/PlaneNet/planes_' + dataset + '_' + split + '_raw.tfrecords', imagePaths)\n            writeRecordFile('/home/chenliu/Projects/Data/PlaneNet/planes_' + dataset + '_' + split + '_raw_2.tfrecords', imagePaths)\n            continue\n        continue\n\n\n    # # The op for initializing the variables.\n    # init_op = tf.group(tf.global_variables_initializer(),\n    #                    tf.local_variables_initializer())\n\n    # with tf.Session()  as sess:\n\n    #     sess.run(init_op)\n\n    #     coord = tf.train.Coordinator()\n    #     threads = tf.train.start_queue_runners(coord=coord)\n\n    #     for i in xrange(3):\n    #         image, plane, plane_mask = sess.run([image_inp, plane_inp, plane_mask_inp])\n    #         print(image.shape)\n    #         print(plane)\n    #         print(plane_mask.shape)\n    #         for index in xrange(image.shape[0]):\n    #             print(plane[index])\n    #             cv2.imwrite('test/record_' + str(index) + '_image.png', ((image[index] + 0.5) * 255).astype(np.uint8))\n    #             cv2.imwrite('test/record_' + str(index) + '_mask.png', (plane_mask[index, :, :, 0] * 255).astype(np.uint8))\n    #             continue\n    #         exit(1)\n    #         continue\n    #     pass\n    # exit(1)\n\n#func = partial(writeExample, writer, 1)\n#pool.map(func, self.imagePaths[self.numTrainingImages:])\n#pool.close()\n#pool.join()\n#writer.close()\n"""
code/RecordWriterRGBD.py,10,"b""import tensorflow as tf\nimport numpy as np\nimport cv2\nimport random\nimport PIL.Image\nimport glob\nimport scipy.io as sio\nfrom utils import *\n\nHEIGHT=192\nWIDTH=256\nNUM_PLANES = 20\n\ndef _bytes_feature(value):\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _int64_feature(value):\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n\ndef _float_feature(value):\n    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n\ndef writeExample(writer, imagePath):\n    #img = np.array(Image.open(imagePath['image']))\n    #img = cv2.imread(imagePath['image'])\n\n\n    #img = sio.loadmat(imagePath['image'])['imgRgb']\n    #img = cv2.resize(img, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)    \n    #depth = sio.loadmat(imagePath['depth'])['imgDepth']\n    #depth = cv2.resize(depth, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n    #normal = sio.loadmat(imagePath['normal'])['imgNormals']\n    #normal = cv2.resize(normal, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n\n\n    img = cv2.imread(imagePath['image'])\n    img = cv2.resize(img, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)    \n    \n    height = img.shape[0]\n    width = img.shape[1]\n    img_raw = img.tostring()\n    \n    depth = cv2.imread(imagePath['depth'], -1).astype(np.float32) / 255 * 10\n    invalidMask = (depth < 1e-4).astype(np.float32)\n    invalidMask = (cv2.resize(invalidMask, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR) > 1e-4).astype(np.bool)\n    depth = cv2.resize(depth, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n    depth[invalidMask] = 0\n    \n    normal = cv2.imread(imagePath['normal']).astype(np.float32) / (255 / 2) - 1\n    normal = cv2.resize(normal, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)    \n\n    try:\n        plane_data = sio.loadmat(imagePath['plane'])['planeData']\n    except:\n        return\n    \n    segmentation = (plane_data[0][0][0] - 1).astype(np.int32)\n    \n    segmentation = cv2.resize(segmentation, (WIDTH, HEIGHT), interpolation=cv2.INTER_NEAREST)\n    #print(segmentation.shape)\n    planes = plane_data[0][0][1]\n    planes = planes[:, :3] * planes[:, 3:4]\n    numPlanes = planes.shape[0]\n    if numPlanes > NUM_PLANES:\n        return\n    \n    if numPlanes < NUM_PLANES:\n        segmentation[segmentation == numPlanes] = NUM_PLANES\n        planes = np.concatenate([planes, np.zeros((NUM_PLANES - numPlanes, 3))], axis=0)\n        pass\n\n\n    info = np.zeros(20)\n    info[0] = 5.1885790117450188e+02\n    info[2] = 3.2558244941119034e+02 - 40\n    info[5] = 5.1946961112127485e+02\n    info[6] = 2.5373616633400465e+02 - 44\n    info[10] = 1\n    info[15] = 1\n    info[16] = 561\n    info[17] = 427\n    info[18] = 1000\n    info[19] = 1\n    \n    #print(segmentation.shape)\n    #exit(1)\n    example = tf.train.Example(features=tf.train.Features(feature={\n        'image_path': _bytes_feature(imagePath['image']),\n        'image_raw': _bytes_feature(img_raw),\n        'depth': _float_feature(depth.reshape(-1)),\n        'normal': _float_feature(normal.reshape(-1)),\n        'plane': _float_feature(planes.reshape(-1)),\n        'num_planes': _int64_feature([numPlanes]),\n        'segmentation_raw': _bytes_feature(segmentation.tostring()),\n        'info': _float_feature(info),\n    }))\n    writer.write(example.SerializeToString())\n    return\n\n\ndef writeRecordFile(tfrecords_filename, imagePaths):\n    writer = tf.python_io.TFRecordWriter(tfrecords_filename)\n    for index, imagePath in enumerate(imagePaths):\n        #print(imagePath['plane'])\n        if index % 100 == 0:\n            print(index)\n            pass\n        writeExample(writer, imagePath)\n        #cv2.imwrite('test/image_' + str(index) + '.png', img)\n        #cv2.imwrite('test/segmentation_' + str(index) + '.png', drawSegmentationImage(segmentation, planeMask=segmentation < segmentation.max(), black=True))\n        #if index == 10:\n        #break\n        continue\n    writer.close()\n    return\n\n\nif __name__=='__main__':\n    imagePaths = glob.glob('/mnt/md0/NYU_RGBD/val/color_*.png')\n    imagePaths = [{'image': imagePath, 'depth': imagePath.replace('color', 'depth'), 'normal': imagePath.replace('color', 'normal'), 'plane': imagePath.replace('color', 'plane').replace('png', 'mat')} for imagePath in imagePaths]\n    \n    # splits = sio.loadmat('/mnt/vision/NYU_RGBD/splits.mat')\n    # trainInds = splits['trainNdxs'].reshape(-1).tolist()\n    # imagePaths = []\n    # for index in trainInds:\n    #     imagePath = '/mnt/vision/NYU_RGBD/images_rgb/rgb_%06d.mat' % (index)\n    #     imagePaths.append({'image': imagePath, 'depth': imagePath.replace('rgb', 'depth'), 'normal': imagePath.replace('images_rgb', 'surface_normals').replace('rgb', 'surface_normals'), 'plane': imagePath.replace('images_rgb', 'planes').replace('rgb', 'plane_data')})\n    #     continue\n        \n    print(len(imagePaths))\n    # #exit(1)\n    random.shuffle(imagePaths)\n    writeRecordFile('../planes_nyu_rgbd_val.tfrecords', imagePaths)\n    #exit(1)\n    \n    # testInds = splits['testNdxs'].reshape(-1).tolist()\n    # imagePaths = []\n    # for index in testInds:\n    #     imagePath = '/mnt/vision/NYU_RGBD/images_rgb/rgb_%06d.mat' % (index)\n    #     imagePaths.append({'image': imagePath, 'depth': imagePath.replace('rgb', 'depth'), 'normal': imagePath.replace('images_rgb', 'surface_normals').replace('rgb', 'surface_normals'), 'plane': imagePath.replace('images_rgb', 'planes').replace('rgb', 'plane_data')})\n    #     continue\n        \n    # print(len(imagePaths))\n    # #exit(1)\n    # random.shuffle(imagePaths)\n    # writeRecordFile('../planes_nyu_rgbd_val.tfrecords', imagePaths)\n\n    \n    \n    #reader.readRecordFile()\n\n\n    # # The op for initializing the variables.\n    # init_op = tf.group(tf.global_variables_initializer(),\n    #                    tf.local_variables_initializer())\n\n    # with tf.Session()  as sess:\n\n    #     sess.run(init_op)\n\n    #     coord = tf.train.Coordinator()\n    #     threads = tf.train.start_queue_runners(coord=coord)\n\n    #     for i in xrange(3):\n    #         image, plane, plane_mask = sess.run([image_inp, plane_inp, plane_mask_inp])\n    #         print(image.shape)\n    #         print(plane)\n    #         print(plane_mask.shape)\n    #         for index in xrange(image.shape[0]):\n    #             print(plane[index])\n    #             cv2.imwrite('test/record_' + str(index) + '_image.png', ((image[index] + 0.5) * 255).astype(np.uint8))\n    #             cv2.imwrite('test/record_' + str(index) + '_mask.png', (plane_mask[index, :, :, 0] * 255).astype(np.uint8))\n    #             continue\n    #         exit(1)\n    #         continue\n    #     pass\n    # exit(1)\n\n#func = partial(writeExample, writer, 1)\n#pool.map(func, self.imagePaths[self.numTrainingImages:])\n#pool.close()\n#pool.join()\n#writer.close()\n"""
code/RecordWriterRGBD_backup.py,10,"b""import tensorflow as tf\nimport numpy as np\nimport cv2\nimport random\nimport PIL.Image\nimport glob\n\nHEIGHT=192\nWIDTH=256\nNUM_PLANES = 20\n\ndef _bytes_feature(value):\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _int64_feature(value):\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n\ndef _float_feature(value):\n    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n\ndef writeExample(writer, imagePath):\n    #img = np.array(Image.open(imagePath['image']))\n    img = cv2.imread(imagePath['image'])\n    img = cv2.resize(img, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n\n    height = img.shape[0]\n    width = img.shape[1]\n    img_raw = img.tostring()\n\n    depth = np.array(PIL.Image.open(imagePath['depth'])).astype(np.float32) / 255 * 10\n    depth = cv2.resize(depth, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n\n\n    example = tf.train.Example(features=tf.train.Features(feature={\n        'image_path': _bytes_feature(imagePath['image']),\n        'image_raw': _bytes_feature(img_raw),\n        'depth': _float_feature(depth.reshape(-1)),\n    }))\n    writer.write(example.SerializeToString())\n    return\n\ndef loadImagePaths():\n    image_set_file = '../PythonScripts/SUNCG/image_list_500000.txt'\n    with open(image_set_file) as f:\n        filenames = [x.strip().replace('plane_global.npy', '') for x in f.readlines()]\n        image_paths = [{'image': x + 'mlt.png', 'plane': x + 'plane_global.npy', 'normal': x + 'norm_camera.png', 'depth': x + 'depth.png', 'mask': x + 'valid.png', 'masks': x + 'masks.npy'} for x in filenames]\n        pass\n    return image_paths\n\n\ndef writeRecordFile(tfrecords_filename, imagePaths):\n    writer = tf.python_io.TFRecordWriter(tfrecords_filename)\n    for index, imagePath in enumerate(imagePaths):\n        if index % 100 == 0:\n            print(index)\n            pass\n        writeExample(writer, imagePath)\n        continue\n    writer.close()\n    return\n\n\nif __name__=='__main__':\n    imagePaths = glob.glob('/home/chenliu/Projects/Data/NYU_RGBD/raw/train/color_*.png')\n    imagePaths = [{'image': imagePath, 'depth': imagePath.replace('color', 'depth')} for imagePath in imagePaths]\n    print(len(imagePaths))\n    #exit(1)\n    random.shuffle(imagePaths)\n    writeRecordFile('../planes_nyu_rgbd_train.tfrecords', imagePaths)\n    #reader.readRecordFile()\n\n\n    # # The op for initializing the variables.\n    # init_op = tf.group(tf.global_variables_initializer(),\n    #                    tf.local_variables_initializer())\n\n    # with tf.Session()  as sess:\n\n    #     sess.run(init_op)\n\n    #     coord = tf.train.Coordinator()\n    #     threads = tf.train.start_queue_runners(coord=coord)\n\n    #     for i in xrange(3):\n    #         image, plane, plane_mask = sess.run([image_inp, plane_inp, plane_mask_inp])\n    #         print(image.shape)\n    #         print(plane)\n    #         print(plane_mask.shape)\n    #         for index in xrange(image.shape[0]):\n    #             print(plane[index])\n    #             cv2.imwrite('test/record_' + str(index) + '_image.png', ((image[index] + 0.5) * 255).astype(np.uint8))\n    #             cv2.imwrite('test/record_' + str(index) + '_mask.png', (plane_mask[index, :, :, 0] * 255).astype(np.uint8))\n    #             continue\n    #         exit(1)\n    #         continue\n    #     pass\n    # exit(1)\n\n#func = partial(writeExample, writer, 1)\n#pool.map(func, self.imagePaths[self.numTrainingImages:])\n#pool.close()\n#pool.join()\n#writer.close()\n"""
code/RecordWriterWithoutPlane.py,12,"b""import tensorflow as tf\nimport numpy as np\nimport cv2\nimport random\nimport PIL.Image\n\nHEIGHT=192\nWIDTH=256\nNUM_PLANES = 20\n\ndef _bytes_feature(value):\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _int64_feature(value):\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n\ndef _float_feature(value):\n    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n\ndef writeExample(writer, validating, imagePath):\n    img = cv2.imread(imagePath['image'])\n    img = cv2.resize(img, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n\n    height = img.shape[0]\n    width = img.shape[1]\n    img_raw = img.tostring()\n\n    normal = np.array(PIL.Image.open(imagePath['normal'])).astype(np.float32) / 255 * 2 - 1\n    normal = cv2.resize(normal, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n    norm = np.linalg.norm(normal, 2, 2)\n    for c in xrange(3):\n        normal[:, :, c] /= norm\n        continue\n\n    depth = np.array(PIL.Image.open(imagePath['depth'])).astype(np.float32) / 1000\n    depth = cv2.resize(depth, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n\n\n    invalid_mask = cv2.imread(imagePath['mask'], 0)\n    invalid_mask = cv2.resize(invalid_mask, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n    invalid_mask = (invalid_mask < 128).astype(np.uint8)\n    invalid_mask_raw = invalid_mask.tostring()\n\n\n    # planeGlobal = np.load(imagePath['plane'])[:, :3]\n    # numPlanes = planeGlobal.shape[0]\n    # if numPlanes > NUM_PLANES:\n    #     planeGlobal = planeGlobal[:NUM_PLANES]\n    # elif numPlanes < NUM_PLANES:\n    #     planeGlobal = np.concatenate([planeGlobal, np.zeros((NUM_PLANES - numPlanes, 3))])\n    #     pass\n\n    #masks = np.load(imagePath['masks'])\n    #masks = cv2.resize(masks, (WIDTH, HEIGHT), interpolation=cv2.INTER_NEAREST)\n\n    example = tf.train.Example(features=tf.train.Features(feature={\n        #'height': _int64_feature([height]),\n        #'width': _int64_feature([width]),\n        #'num_planes': _int64_feature([numPlanes]),\n        'image_path': _bytes_feature(imagePath['image']),\n        'image_raw': _bytes_feature(img_raw),\n        'normal': _float_feature(normal.reshape(-1)),\n        'depth': _float_feature(depth.reshape(-1)),\n        'invalid_mask_raw': _bytes_feature(invalid_mask_raw),\n        #'plane': _float_feature(planeGlobal.reshape(-1)),\n        #'plane_mask': _int64_feature(masks.reshape(-1)),\n        #'validating': _int64_feature([validating])\n    }))\n    writer.write(example.SerializeToString())\n    return\n\ndef loadImagePaths():\n    image_set_file = '../PythonScripts/SUNCG/image_list_500000.txt'\n    with open(image_set_file) as f:\n        filenames = [x.strip().replace('plane_global.npy', '') for x in f.readlines()]\n        image_paths = [{'image': x + 'mlt.png', 'plane': x + 'plane_global.npy', 'normal': x + 'norm_camera.png', 'depth': x + 'depth.png', 'mask': x + 'valid.png', 'masks': x + 'masks.npy'} for x in filenames]\n        pass\n    return image_paths\n\n\ndef readRecordFile():\n    tfrecords_filename = '../planes.tfrecords'\n    record_iterator = tf.python_io.tf_record_iterator(path=tfrecords_filename)\n\n    for string_record in record_iterator:\n\n        example = tf.train.Example()\n        example.ParseFromString(string_record)\n        height = int(example.features.feature['height']\n                     .int64_list\n                     .value[0])\n\n        width = int(example.features.feature['width']\n                        .int64_list\n                        .value[0])\n\n        img_string = (example.features.feature['image_raw']\n                      .bytes_list\n                      .value[0])\n\n        plane = (example.features.feature['plane_raw']\n                 .float_list\n                 .value)\n\n        plane_mask = (example.features.feature['plane_mask_raw']\n                      .int64_list\n                      .value)\n\n        img_1d = np.fromstring(img_string, dtype=np.uint8)\n        reconstructed_img = img_1d.reshape((height, width, -1))\n        print(np.array(plane).shape)\n        print(np.array(plane_mask).shape)\n        exit(1)\n        continue\n    return\n\n\ndef writeRecordFile(tfrecords_filename, imagePaths, validating):\n    writer = tf.python_io.TFRecordWriter(tfrecords_filename)\n    for index, imagePath in enumerate(imagePaths):\n        if index % 100 == 0:\n            print(index)\n            pass\n        writeExample(writer, validating, imagePath)\n        continue\n    writer.close()\n    return\n\n\nif __name__=='__main__':\n    imagePaths = loadImagePaths()\n    imagePaths = imagePaths[450000:450000 + 1000]\n    random.shuffle(imagePaths)\n    writeRecordFile('../planes_all_1000_450000.tfrecords', imagePaths, 1)\n    #reader.readRecordFile()\n\n\n    # # The op for initializing the variables.\n    # init_op = tf.group(tf.global_variables_initializer(),\n    #                    tf.local_variables_initializer())\n\n    # with tf.Session()  as sess:\n\n    #     sess.run(init_op)\n\n    #     coord = tf.train.Coordinator()\n    #     threads = tf.train.start_queue_runners(coord=coord)\n\n    #     for i in xrange(3):\n    #         image, plane, plane_mask = sess.run([image_inp, plane_inp, plane_mask_inp])\n    #         print(image.shape)\n    #         print(plane)\n    #         print(plane_mask.shape)\n    #         for index in xrange(image.shape[0]):\n    #             print(plane[index])\n    #             cv2.imwrite('test/record_' + str(index) + '_image.png', ((image[index] + 0.5) * 255).astype(np.uint8))\n    #             cv2.imwrite('test/record_' + str(index) + '_mask.png', (plane_mask[index, :, :, 0] * 255).astype(np.uint8))\n    #             continue\n    #         exit(1)\n    #         continue\n    #     pass\n    # exit(1)\n\n#func = partial(writeExample, writer, 1)\n#pool.map(func, self.imagePaths[self.numTrainingImages:])\n#pool.close()\n#pool.join()\n#writer.close()\n"""
code/SegmentationRefinement.py,0,"b""import numpy as np\nfrom pystruct.inference import get_installed, inference_ogm, inference_dispatch\nfrom utils import *\n\ndef findProposals(segmentations, numProposals = 5):\n    height = segmentations.shape[0]\n    width = segmentations.shape[1]\n    segmentationsNeighbors = []\n    windowSize = 5\n    segmentationsPadded = np.pad(segmentations, ((windowSize, windowSize), (windowSize, windowSize), (0, 0)), mode='constant')\n    for shiftX in xrange(windowSize * 2 + 1):\n        for shiftY in xrange(windowSize * 2 + 1):\n            segmentationsNeighbors.append(segmentationsPadded[shiftY:shiftY + height, shiftX:shiftX + width, :])\n            continue\n        continue\n    segmentationsNeighbors = np.max(np.stack(segmentationsNeighbors, axis=3), axis=3)\n    proposals = np.argpartition(-segmentationsNeighbors, numProposals)[:, :, :numProposals]\n    return proposals\n\n\ndef refineSegmentation(image, allSegmentations, allDepths, boundaries, numOutputPlanes=20, numIterations=20, numProposals=5):\n    height = allSegmentations.shape[0]\n    width = allSegmentations.shape[1]\n\n    #allSegmentations = np.concatenate([planeSegmentations, nonPlaneSegmentation], axis=2)\n    #allDepths = np.concatenate([planeDepths, nonPlaneDepth], axis=2)\n    proposals = findProposals(allSegmentations, numProposals=numProposals)\n    #proposals = np.sort(proposals, axis=-1)\n    proposalSegmentations = readProposalInfo(allSegmentations, proposals)\n    proposalDepths = readProposalInfo(allDepths, proposals)\n\n    # print(allDepths[80][75])\n    # print(proposals[80][75])    \n    # print(proposalDepths[80][75])\n    # exit(1)\n    proposals = proposals.reshape((-1, numProposals))\n    proposalDepths = proposalDepths.reshape((-1, numProposals))\n    smoothBoundaries = boundaries[:, :, 0].reshape(-1)\n    occlusionBoundaries = boundaries[:, :, 1].reshape(-1)\n    \n    maxDepthDiff = 0.1\n    unaries = proposalSegmentations.reshape((-1, numProposals))\n    nodes = np.arange(height * width).reshape((height, width))\n    #deltas = [(0, 1), (0, -1), (1, 0), (-1, 0), (1, 1), (1, -1), (-1, 1), (-1, -1)]\n\n    deltas = [(0, 1), (1, 0), (-1, 1), (1, 1)]\n    edges = []\n    edges_features = []\n    colors = image.reshape((-1, 3)).astype(np.float32)\n\n    intensityDifferenceSum = 0.0\n    intensityDifferenceCount = 0\n    for delta in deltas:\n        deltaX = delta[0]\n        deltaY = delta[1]\n        partial_nodes = nodes[max(-deltaY, 0):min(height - deltaY, height), max(-deltaX, 0):min(width - deltaX, width)].reshape(-1)\n        intensityDifferenceSum += np.sum(pow(colors[partial_nodes] - colors[partial_nodes + (deltaY * width + deltaX)], 2))\n        intensityDifferenceCount += partial_nodes.shape[0]\n        continue\n    intensityDifference = intensityDifferenceSum / intensityDifferenceCount\n    \n    for delta in deltas:\n        deltaX = delta[0]\n        deltaY = delta[1]\n        partial_nodes = nodes[max(-deltaY, 0):min(height - deltaY, height), max(-deltaX, 0):min(width - deltaX, width)].reshape(-1)\n        neighbor_nodes = partial_nodes + (deltaY * width + deltaX)\n        edges.append(np.stack([partial_nodes, neighbor_nodes], axis=1))\n\n        #depth_1_1 = proposalDepths[max(-deltaY, 0):min(height - deltaY, height), max(-deltaX, 0):min(width - deltaX, width)].reshape((-1, numProposals))\n        #depth_2_2 = proposalDepths[max(deltaY, 0):min(height + deltaY, height), max(deltaX, 0):min(width + deltaX, width)].reshape((-1, numProposals))\n\n        #label_1 = proposals[max(-deltaY, 0):min(height - deltaY, height), max(-deltaX, 0):min(width - deltaX, width)].reshape((-1, numProposals))\n        #label_2 = proposals[max(deltaY, 0):min(height + deltaY, height), max(deltaX, 0):min(width + deltaX, width)].reshape((-1, numProposals))\n        \n        #smooth_boundary = np.maximum(boundaries[max(-deltaY, 0):min(height - deltaY, height), max(-deltaX, 0):min(width - deltaX, width), 0].reshape(-1), boundaries[max(deltaY, 0):min(height + deltaY, height), max(deltaX, 0):min(width + deltaX, width), 0].reshape((-1)))\n        #occlusion_boundary = np.maximum(boundaries[max(-deltaY, 0):min(height - deltaY, height), max(-deltaX, 0):min(width - deltaX, width), 1].reshape(-1), boundaries[max(deltaY, 0):min(height + deltaY, height), max(deltaX, 0):min(width + deltaX, width), 1].reshape((-1)))\n\n        depth_1_1 = proposalDepths[partial_nodes]\n        depth_2_2 = proposalDepths[neighbor_nodes]        \n        depth_diff = np.abs(np.expand_dims(depth_1_1, -1) - np.expand_dims(depth_2_2, 1))\n        depth_diff = np.clip(np.abs(depth_diff) / maxDepthDiff, 0, 1)\n        \n        label_1 = proposals[partial_nodes]\n        label_2 = proposals[neighbor_nodes]\n        label_diff = (np.expand_dims(label_1, -1) != np.expand_dims(label_2, 1)).astype(np.float32)\n        #label_diff = np.clip(np.abs(label_diff), 0, 1)\n\n        color_1 = colors[partial_nodes]\n        color_2 = colors[neighbor_nodes]\n        color_diff = pow(color_1 - color_2, 2).sum(1).reshape((-1, 1, 1))\n        smooth_boundary = np.maximum(smoothBoundaries[partial_nodes], smoothBoundaries[neighbor_nodes])\n        occlusion_boundary = np.maximum(occlusionBoundaries[partial_nodes], occlusionBoundaries[neighbor_nodes])\n\n        #pairwise_cost = label_diff * depth_diff * smooth_boundary.reshape((-1, 1, 1)) + label_diff * np.clip(1 - smooth_boundary - occlusion_boundary, 0.1, 1).reshape((-1, 1, 1))\n\n        pairwise_cost = label_diff * (1 + 50 * depth_diff + 20 * np.exp(-color_diff / intensityDifference))\n\n        x = 75\n        y = 88\n        print((y - deltaY, x - deltaX))\n        print(proposals[(y - deltaY) * width + (x - deltaX)])\n        print(proposals[y * width + x])\n        #index = neighbor_nodes == y * width + x\n        index = partial_nodes == y * width + x\n        print(pairwise_cost[index])\n        print(depth_diff[index])\n        print(depth_1_1[index])\n        print(depth_2_2[index])                \n        print(color_diff[index])\n        \n        #print(intensityDifference)\n        #exit(1)\n        edges_features.append(pairwise_cost)\n        #print((edges[-1][partial_nodes == y * width + x][0][1] % width, edges[-1][partial_nodes == y * width + x][0][1] / width))\n        #print(edges_features[-1][partial_nodes == y * width + x])\n        #mask = edges[-1][:, 1] == y * width + x\n        #print((edges[-1][mask][0][0] % width, edges[-1][mask][0][0] / width))\n        #print(edges_features[-1][mask])\n        continue\n\n    \n    edges = np.concatenate(edges, axis=0)\n    edges_features = np.concatenate(edges_features, axis=0)\n    refined_segmentation = inference_ogm(unaries * 10, edges_features, edges, return_energy=False, alg='trw')\n    #refined_segmentation = inference_dispatch(unaries, edges_features * 0, edges, ('unary'))\n    #refined_segmentation = np.argmin(unaries, axis=1)\n\n    refined_segmentation = refined_segmentation.reshape([height, width, 1])\n    refined_segmentation = readProposalInfo(proposals, refined_segmentation)\n    refined_segmentation = refined_segmentation.reshape([height, width])\n\n    # print((x, y))\n    # print(proposals[y][x])\n    # print((x + 1, y))\n    # print(proposals[y][x + 1])\n    # print((x - 1, y + 1))\n    # print(proposals[y + 1][x - 1])\n    # print((x, y + 1))\n    # print(proposals[y + 1][x])\n    # print((x + 1, y + 1))\n    # print(proposals[y + 1][x + 1])\n    # print(unaries[y * width + x])\n    # print(refined_segmentation[y][x])\n    return refined_segmentation\n    #return proposals.reshape([height, width])\n\n\ndef getSegmentationsTRWS(planes, image, depth, normal, segmentation, semantics, info, numPlanes):\n    numOutputPlanes = planes.shape[0]\n    height = depth.shape[0]\n    width = depth.shape[1]\n    numProposals = 3\n\n\n    camera = getCameraFromInfo(info)\n    urange = (np.arange(width, dtype=np.float32) / (width) * (camera['width']) - camera['cx']) / camera['fx']\n    urange = urange.reshape(1, -1).repeat(height, 0)\n    vrange = (np.arange(height, dtype=np.float32) / (height) * (camera['height']) - camera['cy']) / camera['fy']\n    vrange = vrange.reshape(-1, 1).repeat(width, 1)\n    \n    X = depth * urange\n    Y = depth\n    Z = -depth * vrange\n    points = np.stack([X, Y, Z], axis=2)\n\n    planes = planes[:numPlanes]\n    planesD = np.linalg.norm(planes, axis=1, keepdims=True)\n    planeNormals = planes / np.maximum(planesD, 1e-4)\n\n    distanceCostThreshold = 0.05\n    distanceCost = np.abs(np.tensordot(points, planeNormals, axes=([2, 1])) - np.reshape(planesD, [1, 1, -1])) / distanceCostThreshold\n\n    normalCost = 0\n    if info[19] <= 1:\n        normalCostThreshold = 1 - np.cos(20)        \n        normalCost = (1 - np.tensordot(normal, planeNormals, axes=([2, 1]))) / normalCostThreshold\n        pass\n    \n    planeMasks = []\n    for planeIndex in xrange(numPlanes):\n        #print(np.bincount(semantics[segmentation == planeIndex]))\n        planeMaskOri = segmentation == planeIndex\n        semantic = np.bincount(semantics[planeMaskOri]).argmax()\n        #print(semantic)\n        planeMask = cv2.dilate((np.logical_and(np.logical_or(semantics == semantic, planeMaskOri), distanceCost[:, :, planeIndex])).astype(np.uint8), np.ones((3, 3), dtype=np.uint8)).astype(np.float32)\n        planeMasks.append(planeMask)\n        #cv2.imwrite('test/mask_' + str(planeIndex) + '.png', drawMaskImage(segmentation == planeIndex))\n        #cv2.imwrite('test/mask_2.png', drawMaskImage(semantics == semantic))\n        continue\n    \n    planeMasks = np.stack(planeMasks, 2)\n\n    unaryCost = distanceCost + (1 - planeMasks) * 10000\n    unaryCost = np.concatenate([unaryCost, np.ones((height, width, 1))], axis=2)\n\n    proposals = np.argpartition(unaryCost, numProposals)[:, :, :numProposals]\n    unaries = -readProposalInfo(unaryCost, proposals).reshape((-1, numProposals))\n\n    # refined_segmentation = np.argmax(unaries, axis=1)\n    # refined_segmentation = refined_segmentation.reshape([height, width, 1])\n    # refined_segmentation = readProposalInfo(proposals, refined_segmentation)\n    # refined_segmentation = refined_segmentation.reshape([height, width])\n    # refined_segmentation[refined_segmentation == numPlanes] = numOutputPlanes\n    \n\n    proposals = proposals.reshape((-1, numProposals))\n    #cv2.imwrite('test/segmentation.png', drawSegmentationImage(unaries.reshape((height, width, -1)), blackIndex=numOutputPlanes))\n\n    nodes = np.arange(height * width).reshape((height, width))\n\n    image = image.astype(np.float32)\n    colors = image.reshape((-1, 3))\n    deltas = [(0, 1), (1, 0), (-1, 1), (1, 1)]    \n    intensityDifferenceSum = 0.0\n    intensityDifferenceCount = 0\n    for delta in deltas:\n        deltaX = delta[0]\n        deltaY = delta[1]\n        partial_nodes = nodes[max(-deltaY, 0):min(height - deltaY, height), max(-deltaX, 0):min(width - deltaX, width)].reshape(-1)\n        intensityDifferenceSum += np.sum(pow(colors[partial_nodes] - colors[partial_nodes + (deltaY * width + deltaX)], 2))\n        intensityDifferenceCount += partial_nodes.shape[0]\n        continue\n    intensityDifference = intensityDifferenceSum / intensityDifferenceCount\n\n    \n    edges = []\n    edges_features = []\n\n    for delta in deltas:\n        deltaX = delta[0]\n        deltaY = delta[1]\n        partial_nodes = nodes[max(-deltaY, 0):min(height - deltaY, height), max(-deltaX, 0):min(width - deltaX, width)].reshape(-1)\n        edges.append(np.stack([partial_nodes, partial_nodes + (deltaY * width + deltaX)], axis=1))\n\n        labelDiff = (np.expand_dims(proposals[partial_nodes], -1) != np.expand_dims(proposals[partial_nodes + (deltaY * width + deltaX)], 1)).astype(np.float32)\n        colorDiff = np.sum(pow(colors[partial_nodes] - colors[partial_nodes + (deltaY * width + deltaX)], 2), axis=1)\n        pairwise_cost = labelDiff * np.reshape(1 + 45 * np.exp(-colorDiff / intensityDifference), [-1, 1, 1])\n        #pairwise_cost = np.expand_dims(pairwise_matrix, 0) * np.ones(np.reshape(1 + 45 * np.exp(-colorDiff / np.maximum(intensityDifference[partial_nodes], 1e-4)), [-1, 1, 1]).shape)\n        edges_features.append(-pairwise_cost)\n        continue\n\n    edges = np.concatenate(edges, axis=0)\n    edges_features = np.concatenate(edges_features, axis=0)\n\n    refined_segmentation = inference_ogm(unaries * 10, edges_features, edges, return_energy=False, alg='trw')\n    #print(pairwise_matrix)\n    #refined_segmentation = inference_ogm(unaries * 5, -pairwise_matrix, edges, return_energy=False, alg='alphaexp')\n    refined_segmentation = refined_segmentation.reshape([height, width, 1])    \n    refined_segmentation = readProposalInfo(proposals, refined_segmentation)\n    refined_segmentation = refined_segmentation.reshape([height, width])\n    refined_segmentation[refined_segmentation == numPlanes] = numOutputPlanes\n    return refined_segmentation\n\n\ndef removeSmallSegments(planes, image, depth, normal, segmentation, semantics, info, numPlanes, planeAreaThreshold = 100, useAllEmpty=False):\n    from skimage import measure\n    \n    numOutputPlanes = planes.shape[0]\n    height = depth.shape[0]\n    width = depth.shape[1]\n    \n    validDepthMask = (depth > 1e-4).astype(np.float32)\n\n    camera = getCameraFromInfo(info)\n    urange = (np.arange(width, dtype=np.float32) / (width) * (camera['width']) - camera['cx']) / camera['fx']\n    urange = urange.reshape(1, -1).repeat(height, 0)\n    vrange = (np.arange(height, dtype=np.float32) / (height) * (camera['height']) - camera['cy']) / camera['fy']\n    vrange = vrange.reshape(-1, 1).repeat(width, 1)\n    \n    X = depth * urange\n    Y = depth\n    Z = -depth * vrange\n\n    points = np.stack([X, Y, Z], axis=2)\n    \n    \n    planeMap = []\n    planeMasks = []\n    planeScopes = []    \n    emptyMask = segmentation == numOutputPlanes\n\n    newSegmentation = np.ones((height, width), dtype=np.uint8) * numOutputPlanes\n    for planeIndex in xrange(numPlanes):\n        planeMask = segmentation == planeIndex\n        planeMaskDilated = cv2.dilate(planeMask.astype(np.uint8), np.ones((3, 3), dtype=np.uint8)).astype(np.bool)\n        planeMaskDilated = planeMaskDilated\n        \n        components = measure.label(planeMaskDilated, background=0)\n        isValid = False\n        for label in xrange(components.max() + 1):\n            mask = components == label\n            maskEroded = cv2.erode(mask.astype(np.float32), np.ones((3, 3), dtype=np.float32), iterations=2)\n            #print((planeIndex, maskEroded.sum()))\n            if maskEroded.sum() < planeAreaThreshold:\n                mask = np.logical_and(mask, planeMask)\n                emptyMask[mask] = True\n                planeMask = np.logical_and(planeMask, np.logical_not(mask))\n                #     cv2.imwrite('test/component_' + str(label) + '.png', drawMaskImage(mask))  \n                #     cv2.imwrite('test/component_' + str(label) + '_removed.png', drawMaskImage(planeMask))\n                #     pass\n            else:\n                isValid = True\n                pass\n            continue\n        planeScope = planeMask.astype(np.float32)\n        planeMask = np.logical_and(planeMask, validDepthMask)\n        if not isValid or planeMask.sum() < planeAreaThreshold:\n            continue\n        \n        newSegmentation[planeMask] = len(planeMap)\n        planeMap.append(planeIndex)\n        planeMasks.append(planeMask)\n        \n        #semantic = np.bincount(semantics[planeMask]).argmax()\n        #planeScope = np.logical_and(np.logical_or(semantics == semantic, semantics == 0), planeMaskDilated).astype(np.float32)\n        planeScope = cv2.dilate(planeScope, np.ones((3, 3), dtype=np.float32), iterations=3)\n        planeScopes.append(planeScope)\n\n        # if planeIndex == 9:\n        #     cv2.imwrite('test/mask_' + str(len(planeMap) - 1) + '_dilated.png', drawMaskImage(planeMaskDilated))\n        #     cv2.imwrite('test/mask_' + str(len(planeMap) - 1) + '.png', drawMaskImage(planeMask))\n        #     exit(1)\n                \n        continue\n    if len(planeMap) == 0:\n        return np.zeros((numOutputPlanes, 3)), np.ones((height, width)) * numOutputPlanes\n    \n    #planeMap = one_hot(np.array(planeMap), depth=planes.shape[0])\n    #planes = np.matmul(planeMap, planes)\n    planes = []\n    for planeIndex, planeMask in enumerate(planeMasks):\n        plane = fitPlane(points[planeMask])\n        plane = plane / pow(np.linalg.norm(plane), 2)\n        planes.append(plane)\n        # if planeIndex == 1:\n        #     print(points[planeMask])\n        #     print(plane)\n        #     cv2.imwrite('test/mask_' + str(planeIndex) + '.png', drawMaskImage(planeMask))\n        #     exit(1)\n        continue\n    \n    planes = np.array(planes)\n    #print(planes.shape)\n    numPlanes = planes.shape[0]\n    planeMasks = np.stack(planeMasks, 2)\n    planeScopes = np.stack(planeScopes, 2)\n\n    if useAllEmpty:\n        #planeScopes = np.expand_dims(emptyMask, -1)\n        planeScopes = np.ones((height, width, 1))\n        pass\n\n    planes = planes[:numPlanes]\n    planesD = np.linalg.norm(planes, axis=1, keepdims=True)\n    planeNormals = planes / np.maximum(planesD, 1e-4)\n\n    distanceThreshold = 0.1\n    distance = np.abs(np.tensordot(points, planeNormals, axes=([2, 1])) - np.reshape(planesD, [1, 1, -1]))\n    #invalidFittingMask = (distance.reshape((-1, numPlanes))[np.arange(width * height), newSegmentation.reshape(-1)] > distanceThreshold).reshape((height, width))\n    invalidFittingMask = np.sum(distance * planeMasks, axis=2) > distanceThreshold\n    #invalidFittingMask = np.argmin(distance, axis=-1) != newSegmentation\n    emptyMask += np.logical_and(invalidFittingMask, validDepthMask)\n    distance = distance + (1 - planeScopes) * 10000\n    distance = np.concatenate([distance, np.expand_dims(emptyMask.astype(np.float32), -1) * distanceThreshold], axis=2)\n    #cv2.imwrite('test/mask.png', drawMaskImage(emptyMask))\n    filledSegmentation = np.argmin(distance[emptyMask], axis=-1)\n    filledSegmentation[filledSegmentation == numPlanes] = numOutputPlanes\n    newSegmentation[emptyMask] = filledSegmentation\n    \n    planes = np.concatenate([planes, np.zeros((numOutputPlanes - planes.shape[0], 3))], axis=0)\n\n    return planes, newSegmentation, numPlanes\n"""
code/cluster.py,15,"b'import tensorflow as tf\nimport numpy as np\nnp.set_printoptions(precision=2, linewidth=200)\nimport cv2\nimport os\nimport time\nimport sys\nimport tf_nndistance\nimport argparse\nimport glob\nimport PIL\nimport scipy.ndimage as ndimage\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom utils import *\nfrom plane_utils import *\nfrom modules import *\n\nfrom train_planenet import *\nfrom planenet import PlaneNet\nfrom RecordReaderAll import *\n#from SegmentationRefinement import refineSegmentation\n\n\ndef clusterPlanes(options):\n    tf.reset_default_graph()\n    \n    options.batchSize = 1\n    min_after_dequeue = 1000\n\n    reader = RecordReaderAll()\n    if options.dataset == \'SUNCG\':\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_SUNCG_val.tfrecords\'], num_epochs=10000)\n    elif options.dataset == \'NYU_RGBD\':\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_nyu_rgbd_val.tfrecords\'], num_epochs=1)\n        options.deepSupervision = 0\n        options.predictLocal = 0\n    elif options.dataset == \'matterport\':\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_matterport_val.tfrecords\'], num_epochs=1)\n    else:\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_scannet_val.tfrecords\'], num_epochs=1)\n        pass\n    \n    img_inp, global_gt_dict, local_gt_dict = reader.getBatch(filename_queue, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True, random=False)\n        \n\n    \n    training_flag = tf.constant(False, tf.bool)\n\n    options.gpu_id = 0\n    global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp, img_inp, training_flag, options)\n\n    var_to_restore = tf.global_variables()\n\n\n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n    pred_dict = {}\n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n        #var_to_restore = [v for v in var_to_restore if \'res4b22_relu_non_plane\' not in v.name]\n        loader = tf.train.Saver(var_to_restore)\n        loader.restore(sess, ""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n        #loader.restore(sess, options.fineTuningCheckpoint)\n        \n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n        \n        \n        try:\n            predPlanes = []\n            for index in xrange(options.numImages):\n                if index % 10 == 0:\n                    print((\'image\', index))\n                    pass\n                t0=time.time()\n\n                img, global_gt, global_pred = sess.run([img_inp, global_gt_dict, global_pred_dict])\n\n                predPlanes.append(global_pred[\'plane\'][0])\n                continue\n            predPlanes = np.array(predPlanes)\n            print(predPlanes.shape)\n            predPlanes = np.mean(predPlanes, axis=0)\n            np.save(\'dump/plane.npy\', predPlanes)\n            pass\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n        \n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return pred_dict\n\n\nif __name__==\'__main__\':\n    """"""\n    Parse input arguments\n    """"""\n    parser = argparse.ArgumentParser(description=\'Planenet\')\n    parser.add_argument(\'--task\', dest=\'task\',\n                        help=\'task type\',\n                        default=\'plane\', type=str)\n    parser.add_argument(\'--numOutputPlanes\', dest=\'numOutputPlanes\',\n                        help=\'the number of output planes\',\n                        default=20, type=int)\n    parser.add_argument(\'--dataset\', dest=\'dataset\',\n                        help=\'dataset name\',\n                        default=\'SUNCG\', type=str)\n    parser.add_argument(\'--hybrid\', dest=\'hybrid\',\n                        help=\'hybrid\',\n                        default=\'0\', type=str)\n    parser.add_argument(\'--visualizeImages\', dest=\'visualizeImages\',\n                        help=\'visualize image\',\n                        default=10, type=int)    \n    parser.add_argument(\'--numImages\', dest=\'numImages\',\n                        help=\'the number of images\',\n                        default=10, type=int)\n    parser.add_argument(\'--useCache\', dest=\'useCache\',\n                        help=\'use cache\',\n                        default=1, type=int)\n    parser.add_argument(\'--useCRF\', dest=\'useCRF\',\n                        help=\'use crf\',\n                        default=0, type=int)\n    parser.add_argument(\'--useSemantics\', dest=\'useSemantics\',\n                        help=\'use semantics\',\n                        default=0, type=int)\n    parser.add_argument(\'--useNonPlaneDepth\', dest=\'useNonPlaneDepth\',\n                        help=\'use non-plane depth\',\n                        default=0, type=int)\n    parser.add_argument(\'--imageIndex\', dest=\'imageIndex\',\n                        help=\'image index\',\n                        default=-1, type=int)\n    parser.add_argument(\'--methods\', dest=\'methods\',\n                        help=\'methods\',\n                        default=\'012345\', type=str)\n    parser.add_argument(\'--rootFolder\', dest=\'rootFolder\',\n                        help=\'root folder\',\n                        default=\'/mnt/vision/PlaneNet/\', type=str)\n    \n    args = parser.parse_args()\n    args.hybrid = \'hybrid\' + args.hybrid\n    args.test_dir = \'evaluate/\' + args.task + \'/\' + args.dataset + \'/\' + args.hybrid + \'/\'\n    args.visualizeImages = min(args.visualizeImages, args.numImages)\n    if args.imageIndex >= 0:\n        args.visualizeImages = 1\n        args.numImages = 1            \n        pass\n\n    if args.dataset == \'SUNCG\':\n        args.camera = getSUNCGCamera()\n    elif args.dataset == \'NYU_RGBD\':\n        args.camera = getNYURGBDCamera()\n    else:\n        args.camera = get3DCamera()\n        pass\n\n\n    args.deepSupervisionLayers = [\'res4b22_relu\', ]\n    args.predictConfidence = 0\n    args.predictLocal = 0\n    args.predictPixelwise = 1\n    args.predictBoundary = 1\n\n    checkpoint_prefix = args.rootFolder + \'/checkpoint/planenet_\'\n    args.checkpoint_dir = checkpoint_prefix + args.hybrid + \'_pb_pp\'\n    \n    clusterPlanes(args)\n    \n'"
code/compare.py,41,"b'import tensorflow as tf\nimport numpy as np\n#np.set_printoptions(precision=2, linewidth=200)\nimport cv2\nimport os\nimport time\nimport sys\nimport tf_nndistance\nimport argparse\nimport glob\nimport PIL\nimport scipy.ndimage as ndimage\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom utils import *\nfrom plane_utils import *\nfrom modules import *\n\nfrom train_planenet import build_graph\nfrom train_sample import build_graph as build_graph_sample\nfrom planenet import PlaneNet\nfrom RecordReaderAll import *\nfrom SegmentationRefinement import *\nfrom crfasrnn_layer import CrfRnnLayer\n\n#ALL_METHODS = [(\'\', \'\'), (\'pb_pp\', \'pixelwise_1\'), (\'pb_pp\', \'pixelwise_2\'), (\'pb_pp\', \'pixelwise_3\'), (\'pb_pp\', \'semantics\'), (\'pb_pp\', \'gt\')]\n\nALL_TITLES = [\'PlaneNet\', \'Oracle NYU toolbox\', \'NYU toolbox\', \'Oracle Manhattan\', \'Manhattan\', \'Piecewise\', \'Oracle Piecewise\']\n\n#bl0_dl0_ll1_pb_pp_sm0\n#bl0_dl0_ll1_ds0_pb_pp\n#ll1_pb_pp\n#bl0_dl0_ll1_ds0_pb_pp\n#ll1_pb_pp\n#bl0_dl0_crfrnn10_sm0\n#bl0_dl0_crfrnn-10_sm0\n#bl2_ll1_bw0.5_pb_pp_sm0\n#crf1_pb_pp\n#bl0_dl0_bw0.5_pb_pp_ps_sm0\n#planenet_hybrid3_bl0_ll1_bw0.5_pb_pp_ps_sm0\n#planenet_hybrid3_ll1_pb_pp\n#planenet_hybrid3_bl0_dl0_ll1_ds0_pb_pp\n\n#bl0_dl0_bw0.5_pb_pp_ps_sm0\n#bl0_ll1_bw0.5_pb_pp_ps_sm0\n#ll1_bw0.5_pb_pp_sm0\n#pb_pp_sm0\n#bl0_dl0_ll1_bw0.5_pb_pp_sm0\n#pb_pp\n\nALL_METHODS = [[\'planenet_hybrid3_bl0_dl0_ll1_pb_pp_sm0\', \'\', 0, 0], [\'planenet_hybrid3_bl0_dl0_crfrnn-10_sm0\', \'\', 1, 0], [\'sample_np10_hybrid3_bl0_dl0_ll1_hl2_ds0_crfrnn5_sm0\', \'\', 1, 0], [\'sample_np10_hybrid3_bl0_dl0_hl2_crfrnn5_sm0\', \'\', 1, 0], [\'sample_np10_hybrid3_bl0_dl0_hl2_ds0_crfrnn5_sm0\', \'\', 1, 0], [\'planenet_hybrid3_bl0_dl0_ds0_crfrnn5_sm0\', \'\', 1, 0], [\'sample_np10_hybrid3_bl0_dl0_ds0_crfrnn5_sm0\', \'\', 1, 0]]\n\n\ndef writeHTML(options):\n    from html import HTML\n\n    titles = options.titles\n\n    h = HTML(\'html\')\n    h.p(\'Results\')\n    h.br()\n    path = \'.\'\n    #methods = [\'planenet\', \'pixelwise\', \'pixelwise+RANSAC\', \'GT+RANSAC\', \'planenet+crf\', \'pixelwise+semantics+RANSAC\']\n    #methods = [\'planenet\', \'pixelwise\', \'pixelwise+RANSAC\', \'GT+RANSAC\']\n\n    for index in xrange(options.numImages):\n\n        t = h.table(border=\'1\')\n        r_inp = t.tr()\n        r_inp.td(\'input \' + str(index))\n        r_inp.td().img(src=path + \'/\' + str(index) + \'_image.png\')\n        r_inp.td().img(src=path + \'/\' + str(index) + \'_depth_gt.png\')\n        r_inp.td().img(src=path + \'/\' + str(index) + \'_segmentation_gt.png\')\n        r_inp.td().img(src=path + \'/\' + str(index) + \'_semantics_gt.png\')                \n        r_inp.td().img(src=path + \'/\' + str(index) + \'_depth_gt_plane.png\')\n        r_inp.td().img(src=path + \'/\' + str(index) + \'_depth_gt_diff.png\')        \n        # r = t.tr()\n        # r.td(\'PlaneNet prediction\')\n        # r.td().img(src=firstFolder + \'/\' + str(index) + \'_segmentation_pred.png\')\n        # r.td().img(src=firstFolder + \'/\' + str(index) + \'_depth_pred.png\')\n\n        r = t.tr()\n        r.td(\'methods\')\n        for method_index, method in enumerate(titles):\n            r.td(method)\n            continue\n        \n        r = t.tr()\n        r.td(\'segmentation\')\n        for method_index, method in enumerate(titles):\n            r.td().img(src=path + \'/\' + str(index) + \'_segmentation_pred_\' + str(method_index) + \'.png\')\n            continue\n\n        r = t.tr()\n        r.td(\'depth\')\n        for method_index, method in enumerate(titles):\n            r.td().img(src=path + \'/\' + str(index) + \'_depth_pred_\' + str(method_index) + \'.png\')\n            continue\n        h.br()\n        continue\n\n    metric_titles = [\'depth error 0.1\', \'depth error 0.2\', \'depth error 0.3\', \'IOU 0.3\', \'IOU 0.5\', \'IOU 0.7\']\n\n    h.p(\'Curves on plane accuracy\')\n    for title in metric_titles:\n        h.img(src=\'curve_plane_\' + title.replace(\' \', \'_\') + \'.png\')\n        continue\n    \n    h.p(\'Curves on pixel coverage\')\n    for title in metric_titles:\n        h.img(src=\'curve_pixel_\' + title.replace(\' \', \'_\') + \'.png\')\n        continue\n    \n    \n    html_file = open(options.test_dir + \'/index.html\', \'w\')\n    html_file.write(str(h))\n    html_file.close()\n    return\n\ndef evaluatePlanes(options):\n    #writeHTML(options)\n    #exit(1)\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n    \n    results = getResults(options)\n    \n    gt_dict = results[\'gt\']\n    predictions = results[\'pred\']\n\n\n    saving = True\n    if gt_dict[\'image\'].shape[0] != options.numImages:\n        saving = False\n        pass\n        \n    \n    for key, value in gt_dict.iteritems():\n        if options.imageIndex >= 0:\n            gt_dict[key] = value[options.imageIndex:options.imageIndex + 1]\n        elif value.shape[0] > options.numImages:\n            gt_dict[key] = value[:options.numImages]\n            pass\n        continue\n    for pred_dict in predictions:\n        for key, value in pred_dict.iteritems():\n            if options.imageIndex >= 0:\n                pred_dict[key] = value[options.imageIndex:options.imageIndex + 1]\n            elif value.shape[0] > options.numImages:\n                pred_dict[key] = value[:options.numImages]\n                pass\n            continue\n        continue\n\n    #methods = [\'planenet\', \'pixelwise+RANSAC\', \'GT+RANSAC\']\n\n\n            \n    #predictions[2] = predictions[3]\n\n\n            \n    \n    for image_index in xrange(options.visualizeImages):\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_image.png\', gt_dict[\'image\'][image_index])\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_gt.png\', drawDepthImage(gt_dict[\'depth\'][image_index]))\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_normal_gt.png\', drawNormalImage(gt_dict[\'normal\'][image_index]))        \n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_gt.png\', drawSegmentationImage(np.concatenate([gt_dict[\'segmentation\'][image_index], 1 - np.expand_dims(gt_dict[\'plane_mask\'][image_index], -1)], axis=2), blackIndex=options.numOutputPlanes))\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_semantics_gt.png\', drawSegmentationImage(gt_dict[\'semantics\'][image_index], blackIndex=0))\n\n        \n        plane_depths = calcPlaneDepths(gt_dict[\'plane\'][image_index], WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n        all_depths = np.concatenate([plane_depths, np.expand_dims(gt_dict[\'depth\'][image_index], -1)], axis=2)\n        depth = np.sum(all_depths * np.concatenate([gt_dict[\'segmentation\'][image_index], 1 - np.expand_dims(gt_dict[\'plane_mask\'][image_index], -1)], axis=2), axis=2)\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_gt_plane.png\', drawDepthImage(depth))\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_gt_diff.png\', drawMaskImage((depth - gt_dict[\'depth\'][image_index]) * 5 + 0.5))        \n        \n        for method_index, pred_dict in enumerate(predictions):\n            cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_dict[\'depth\'][image_index]))\n\n            if \'pixelwise\' in options.methods[method_index][1]:\n                continue\n            segmentation = pred_dict[\'segmentation\'][image_index]\n            segmentation = np.concatenate([segmentation, pred_dict[\'np_mask\'][image_index]], axis=2)\n            numPlanes = options.numOutputPlanes\n            if \'np10\' in options.methods[method_index][0]:\n                numPlanes = 10\n            elif \'np15\' in options.methods[method_index][0]:\n                numPlanes = 15\n                pass\n            cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(segmentation, blackIndex=numPlanes))\n            continue\n        continue\n\n\n    #post processing\n    for method_index, method in enumerate(options.methods):\n        if method[1] == \'\':\n            continue\n        if len(method) < 4 or method[3] == 0:\n            continue\n        if len(method) >= 3 and method[2] >= 0:\n            pred_dict = predictions[method[2]]\n        else:\n            pred_dict = predictions[method_index]\n            pass\n        \n\n        if \'pixelwise\' in method[1]:\n            predPlanes = []\n            predSegmentations = []\n            predDepths = []\n            predNumPlanes = []\n            for image_index in xrange(options.numImages):\n                pred_d = pred_dict[\'np_depth\'][image_index].squeeze()\n                pred_n = pred_dict[\'np_normal\'][image_index].squeeze()                \n                if \'_1\' in method[1]:\n                    pred_s = np.zeros(pred_dict[\'segmentation\'][image_index].shape)\n                    pred_p = np.zeros(pred_dict[\'plane\'][image_index].shape)\n                elif \'_2\' in method[1]:\n                    parameters = {\'distanceCostThreshold\': 0.1, \'smoothnessWeight\': 0.05, \'semantics\': True}\n                    pred_p, pred_s = fitPlanesNYU(gt_dict[\'image\'], gt_dict[\'depth\'][image_index].squeeze(), gt_dict[\'normal\'][image_index], gt_dict[\'semantics\'][image_index], gt_dict[\'info\'][image_index], numOutputPlanes=20, parameters=parameters)\n                elif \'_3\' in method[1]:\n                    parameters = {\'distanceCostThreshold\': 0.1, \'smoothnessWeight\': 0.03, \'semantics\': True, \'distanceThreshold\': 0.2}\n                    pred_p, pred_s = fitPlanesNYU(gt_dict[\'image\'], pred_d, pred_n, pred_dict[\'semantics\'][image_index], gt_dict[\'info\'][image_index], numOutputPlanes=20, parameters=parameters)\n                elif \'_4\' in method[1]:\n                    parameters = {\'numProposals\': 5, \'distanceCostThreshold\': 0.1, \'smoothnessWeight\': 30, \'dominantLineThreshold\': 3, \'offsetGap\': 0.1}\n                    pred_p, pred_s = fitPlanesManhattan(gt_dict[\'image\'][image_index], gt_dict[\'depth\'][image_index].squeeze(), gt_dict[\'normal\'][image_index], gt_dict[\'info\'][image_index], numOutputPlanes=20, parameters=parameters)\n                    pred_d = np.zeros((HEIGHT, WIDTH))\n                elif \'_5\' in method[1]:\n                    parameters = {\'numProposals\': 5, \'distanceCostThreshold\': 0.1, \'smoothnessWeight\': 100, \'dominantLineThreshold\': 3, \'offsetGap\': 0.6}\n                    pred_p, pred_s = fitPlanesManhattan(gt_dict[\'image\'][image_index], pred_d, pred_n, gt_dict[\'info\'][image_index], numOutputPlanes=20, parameters=parameters)\n                    pred_d = np.zeros((HEIGHT, WIDTH))\n                elif \'_6\' in method[1]:\n                    parameters = {\'distanceCostThreshold\': 0.1, \'smoothnessWeight\': 300, \'numProposals\': 5, \'normalWeight\': 1, \'meanshift\': 0.2}\n                    pred_p, pred_s = fitPlanesPiecewise(gt_dict[\'image\'][image_index], gt_dict[\'depth\'][image_index].squeeze(), gt_dict[\'normal\'][image_index], gt_dict[\'info\'][image_index], numOutputPlanes=20, parameters=parameters)\n                    pred_d = np.zeros((HEIGHT, WIDTH))\n                elif \'_7\' in method[1]:\n                    parameters = {\'numProposals\': 5, \'distanceCostThreshold\': 0.1, \'smoothnessWeight\': 300, \'normalWeight\': 1, \'meanshift\': 0.2}\n                    pred_p, pred_s = fitPlanesPiecewise(gt_dict[\'image\'][image_index], pred_d, pred_n, gt_dict[\'info\'][image_index], numOutputPlanes=20, parameters=parameters)\n                    pred_d = np.zeros((HEIGHT, WIDTH))\n                    pass\n                predPlanes.append(pred_p)                \n                predSegmentations.append(pred_s)\n                predDepths.append(pred_d)\n                predNumPlanes.append(pred_p.shape[0])                    \n\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_d))\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(pred_s))\n                #exit(1)\n                continue\n            new_pred_dict = {}\n            for key, value in pred_dict.iteritems():\n                new_pred_dict[key] = value\n                continue\n            new_pred_dict[\'plane\'] = np.array(predPlanes)            \n            new_pred_dict[\'segmentation\'] = np.array(predSegmentations)\n            new_pred_dict[\'depth\'] = np.array(predDepths)\n            new_pred_dict[\'num_planes\'] = np.array(predNumPlanes)\n            if method_index < len(predictions):\n                predictions[method_index] = new_pred_dict\n            else:\n                predictions.append(new_pred_dict)\n                pass\n            #titles.append(\'pixelwise+semantics+RANSAC\')\n            pass\n\n        if method[1] == \'crfrnn\':\n            numPlanes = options.numOutputPlanes\n            if \'np10\' in method[0]:\n                numPlanes = 10\n            elif \'np15\' in method[0]:\n                numPlanes = 15\n                pass\n            \n            predSegmentations = []\n            predDepths = []\n\n            image_inp = tf.placeholder(tf.float32, shape=[1, HEIGHT, WIDTH, 3], name=\'image\')\n            segmentation_inp = tf.placeholder(tf.float32, shape=[1, HEIGHT, WIDTH, numPlanes + 1], name=\'segmentation\')\n            \n            refined_segmentation = CrfRnnLayer(image_dims=(HEIGHT, WIDTH), num_classes=21, theta_alpha=120., theta_beta=3., theta_gamma=3., num_iterations=10, name=\'crfrnn\')([segmentation_inp, image_inp])\n            \n            config=tf.ConfigProto()\n            config.gpu_options.allow_growth=True\n            config.allow_soft_placement=True\n\n            init_op = tf.group(tf.global_variables_initializer(),\n                               tf.local_variables_initializer())\n            with tf.Session(config=config) as sess:\n                sess.run(init_op)\n                for image_index in xrange(options.numImages):\n                    #if image_index != 1:\n                    #continue\n                    print(\'crf rnn \' + str(image_index))\n                    allSegmentations = np.concatenate([pred_dict[\'segmentation\'][image_index], pred_dict[\'np_mask\'][image_index]], axis=2)\n                    img = gt_dict[\'image\'][image_index:image_index + 1].astype(np.float32) - 128\n\n                    \n                    pred_s = sess.run(refined_segmentation, feed_dict={segmentation_inp: np.expand_dims(allSegmentations, 0), image_inp: img})\n\n                    # print(pred_s.shape)\n                    # print(pred_s[0].max())\n                    # print(pred_s.sum(-1).max())                    \n                    # exit(1)\n                    pred_s = pred_s[0]\n                    # print(allSegmentations.max())\n                    # print(pred_s.max())\n                    # print(img.max())\n                    # print(img.min())                    \n                    # print(np.abs(pred_s - allSegmentations).max())\n                    # print(np.abs(np.argmax(pred_s, axis=-1) - np.argmax(allSegmentations, axis=-1)).max())\n                    pred_s = one_hot(np.argmax(pred_s, axis=-1), numPlanes + 1)\n\n                    \n                    planeDepths = calcPlaneDepths(pred_dict[\'plane\'][image_index], WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n                    allDepths = np.concatenate([planeDepths, pred_dict[\'np_depth\'][image_index]], axis=2)\n                    pred_d = np.sum(allDepths * pred_s, axis=-1)\n                    \n                    predSegmentations.append(pred_s)\n                    predDepths.append(pred_d)\n            \n                    cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_d))            \n                    cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(pred_s, blackIndex=numPlanes))\n\n                    continue\n                pass\n            new_pred_dict = {}\n            for key, value in pred_dict.iteritems():\n                new_pred_dict[key] = value\n                continue\n            segmentations = np.array(predSegmentations)\n            new_pred_dict[\'segmentation\'] = segmentations[:, :, :, :numPlanes]\n            new_pred_dict[\'non_plane_mask\'] = segmentations[:, :, :, numPlanes:numPlanes + 1]\n            #new_pred_dict[\'non_plane_mask\'] = segmentations[:, :, :, :options.numOutputPlanes]\n            new_pred_dict[\'depth\'] = np.array(predDepths)\n            if method_index < len(predictions):\n                predictions[method_index] = new_pred_dict\n            else:\n                predictions.append(new_pred_dict)\n                pass\n            pass\n        if saving:\n            np.save(options.result_filename, {\'gt\': gt_dict, \'pred\': predictions})\n            pass\n        continue\n    \n    #exit(1)\n    \n    #print(results)\n\n    # depth = gt_dict[\'depth\'][4]\n    # cv2.imwrite(options.test_dir + \'/test_depth_gt.png\', drawDepthImage(depth))\n    # pred_p, pred_s, pred_d = fitPlanes(depth, getSUNCGCamera(), numPlanes=20, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=0.2)\n    # cv2.imwrite(options.test_dir + \'/test_depth.png\', drawDepthImage(pred_d))\n    # cv2.imwrite(options.test_dir + \'/test_segmentation.png\', drawSegmentationImage(pred_s))\n    # exit(1)\n    \n    \n    plotResults(gt_dict, predictions, options)\n    writeHTML(options)\n    return\n\ndef plotAll():\n    result_filenames = glob.glob(options.test_dir + \'/results_*.npy\')\n    assert(len(result_filenames) > 0)\n    results = np.load(result_filenames[0])\n    results = results[()]\n    gt_dict = results[\'gt\']\n    predictions = results[\'pred\']\n\n    for index in xrange(1, len(result_filenames)):\n        other_results = np.load(result_filenames[index])\n        other_results = other_results[()]\n        other_gt_dict = other_results[\'gt\']\n        other_predictions = other_results[\'pred\']\n\n        for k, v in other_gt_dict.iteritems():\n            gt_dict[k] = np.concatenate([gt_dict[k], v], axis=0)\n            continue\n        for methodIndex, other_pred_dict in enumerate(other_predictions):\n            for k, v in other_pred_dict.iteritems():\n                predictions[methodIndex][k] = np.concatenate([predictions[methodIndex][k], v], axis=0)\n                continue\n            continue\n        continue\n    \n    plotResults(gt_dict, predictions, options)\n    return\n\n\ndef plotResults(gt_dict, predictions, options):\n    titles = options.titles    \n\n    pixel_metric_curves = []\n    plane_metric_curves = []\n    for method_index, pred_dict in enumerate(predictions):\n        if titles[method_index] == \'pixelwise\':\n            continue\n        #if method_index != 6:\n        #continue\n        \n        numPlanes = pred_dict[\'segmentation\'].shape[-1]\n        segmentations = one_hot(np.argmax(np.concatenate([pred_dict[\'segmentation\'], pred_dict[\'np_mask\']], axis=3), axis=-1), numPlanes + 1)\n        segmentations = segmentations[:, :, :, :numPlanes]\n        #if method_index == 0:\n        #segmentations = softmax(segmentations)\n        #pass\n        #pixel_curves, plane_curves = evaluatePlaneSegmentation(pred_dict[\'plane\'], segmentations, gt_dict[\'plane\'], gt_dict[\'segmentation\'], gt_dict[\'num_planes\'], numOutputPlanes = options.numOutputPlanes)\n\n        pixel_curves = np.zeros((6, 11))\n        plane_curves = np.zeros((6, 11, 3))\n        numImages = segmentations.shape[0]\n        for image_index in xrange(numImages):\n            gtDepths = calcPlaneDepths(gt_dict[\'plane\'][image_index], WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n            predDepths = calcPlaneDepths(pred_dict[\'plane\'][image_index], WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n            if \'num_planes\' in pred_dict:\n                predNumPlanes = pred_dict[\'num_planes\'][image_index]\n            else:\n                predNumPlanes = options.numOutputPlanes\n                if \'np10\' in options.methods[method_index][0]:\n                    predNumPlanes = 10\n                elif \'np15\' in options.methods[method_index][0]:\n                    predNumPlanes = 15\n                    pass\n                pass\n\n            # for planeIndex in xrange(gtDepths.shape[-1]):\n            #     cv2.imwrite(\'test/depth_gt_\' + str(planeIndex) + \'.png\', drawDepthImage(gtDepths[:, :, planeIndex]))\n            #     cv2.imwrite(\'test/mask_gt_\' + str(planeIndex) + \'.png\', drawMaskImage(gt_dict[\'segmentation\'][image_index][:, :, planeIndex]))\n            #     continue\n            # for planeIndex in xrange(predDepths.shape[-1]):\n            #     cv2.imwrite(\'test/depth_pred_\' + str(planeIndex) + \'.png\', drawDepthImage(predDepths[:, :, planeIndex]))\n            #     cv2.imwrite(\'test/mask_pred_\' + str(planeIndex) + \'.png\', drawMaskImage(segmentations[image_index][:, :, planeIndex]))\n            #     continue\n            \n            # cv2.imwrite(\'test/depth_diff_0.png\', drawMaskImage(np.abs(gt_dict[\'depth\'][image_index] - predDepths[:, :, 6]) * gt_dict[\'segmentation\'][image_index][:, :, 0] * segmentations[image_index][:, :, 6] / 0.5))\n            # cv2.imwrite(\'test/depth_diff_1.png\', drawMaskImage(np.abs(gt_dict[\'depth\'][image_index] - predDepths[:, :, 4]) * gt_dict[\'segmentation\'][image_index][:, :, 0] * segmentations[image_index][:, :, 4] / 0.5))\n            # cv2.imwrite(\'test/mask_0.png\', drawMaskImage(gt_dict[\'segmentation\'][image_index][:, :, 0] * segmentations[image_index][:, :, 6] > 0.5))\n            # cv2.imwrite(\'test/mask_1.png\', drawMaskImage(gt_dict[\'segmentation\'][image_index][:, :, 0] * segmentations[image_index][:, :, 4] > 0.5))\n            # print(np.abs(gt_dict[\'depth\'][image_index] - predDepths[:, :, 6])[gt_dict[\'segmentation\'][image_index][:, :, 0] * segmentations[image_index][:, :, 6] > 0.5].mean())\n            # print(np.abs(gt_dict[\'depth\'][image_index] - predDepths[:, :, 4])[gt_dict[\'segmentation\'][image_index][:, :, 3] * segmentations[image_index][:, :, 4] > 0.5].mean())\n            # print(np.abs(gt_dict[\'depth\'][image_index] - predDepths[:, :, 5])[gt_dict[\'segmentation\'][image_index][:, :, 1] * segmentations[image_index][:, :, 5] > 0.5].mean())            \n            # exit(1)\n            #pixelStatistics, planeStatistics = evaluatePlanePrediction(predDepths, segmentations[image_index], predNumPlanes, gtDepths, gt_dict[\'segmentation\'][image_index], gt_dict[\'num_planes\'][image_index], gtPlanes=gt_dict[\'plane\'][image_index], predPlanes=pred_dict[\'plane\'][image_index])\n\n            #if method_index != 6:\n            #continue\n            pixelStatistics, planeStatistics = evaluatePlanePrediction(predDepths, segmentations[image_index], predNumPlanes, gtDepths, gt_dict[\'segmentation\'][image_index], gt_dict[\'num_planes\'][image_index])\n            #print(predNumPlanes, gt_dict[\'num_planes\'][image_index])\n            #print(image_index, planeStatistics[4][5])\n            #print(pred_dict[\'plane\'][image_index])\n            #print(segmentations[image_index].sum(axis=(0, 1)))\n            #exit(1)\n            #print(method_index)\n            #print(planeStatistics[2][5])\n\n            pixel_curves += np.array(pixelStatistics)\n            plane_curves += np.array(planeStatistics)\n            continue\n        \n        if len(pixel_metric_curves) == 0:\n            for metric_index, pixel_curve in enumerate(pixel_curves):\n                pixel_metric_curves.append([])\n                plane_metric_curves.append([])\n                continue\n            pass\n        \n        for metric_index, pixel_curve in enumerate(pixel_curves):\n            pixel_metric_curves[metric_index].append(pixel_curve / numImages)\n            continue\n        for metric_index, plane_curve in enumerate(plane_curves):\n            #planeScore = plane_curve[:, 0] / plane_curve[:, 1]\n            plane_metric_curves[metric_index].append(plane_curve)\n            continue\n        continue\n\n    #exit(1)\n    \n    np.save(options.test_dir + \'/pixel_curves.npy\', np.array(pixel_metric_curves))\n    np.save(options.test_dir + \'/plane_curves.npy\', np.array(plane_metric_curves))    \n\n    \n    xs = []\n    xs.append((np.arange(11) * 0.1).tolist())\n    xs.append((np.arange(11) * 0.1).tolist())\n    xs.append((np.arange(11) * 0.1).tolist())    \n    xs.append((np.arange(11) * 0.05).tolist())\n    xs.append((np.arange(11) * 0.05).tolist())\n    xs.append((np.arange(11) * 0.05).tolist())\n    xlabels = [\'IOU\', \'IOU\', \'IOU\', \'plane diff\', \'plane diff\', \'plane diff\']\n    curve_titles = [\'depth error 0.1\', \'depth error 0.2\', \'depth error 0.3\', \'IOU 0.3\', \'IOU 0.5\', \'IOU 0.7\']\n    curve_labels = [title for title in titles if title != \'pixelwise\']\n    #print(curve_labels)\n    for metric_index, curves in enumerate(pixel_metric_curves):\n        filename = options.test_dir + \'/curve_pixel_\' + curve_titles[metric_index].replace(\' \', \'_\') + \'.png\'\n        #print(metric_index)\n        #print(curves)\n        plotCurvesSimple(xs[metric_index], curves, filename = filename, xlabel=xlabels[metric_index], ylabel=\'pixel coverage\', title=curve_titles[metric_index], labels=curve_labels)\n        continue\n    for metric_index, curves in enumerate(plane_metric_curves):\n        filename = options.test_dir + \'/curve_plane_\' + curve_titles[metric_index].replace(\' \', \'_\') + \'.png\'\n        curves = [curve[:, 0] / curve[:, 1] for curve in curves]\n        plotCurvesSimple(xs[metric_index], curves, filename = filename, xlabel=xlabels[metric_index], ylabel=\'plane accuracy\', title=curve_titles[metric_index], labels=curve_labels)\n        continue\n\n    \ndef gridSearch(options):\n    #writeHTML(options)\n    #exit(1)\n\n    if os.path.exists(options.result_filename):\n        results = np.load(options.result_filename)\n        results = results[()]\n    else:\n        assert(False)\n        pass\n    \n    gt_dict = results[\'gt\']\n    predictions = results[\'pred\']\n\n    for key, value in gt_dict.iteritems():\n        if options.imageIndex >= 0:\n            gt_dict[key] = value[options.imageIndex:options.imageIndex + 1]\n        elif value.shape[0] > options.numImages:\n            gt_dict[key] = value[:options.numImages]\n            pass\n        continue\n    for pred_dict in predictions:\n        for key, value in pred_dict.iteritems():\n            if options.imageIndex >= 0:\n                pred_dict[key] = value[options.imageIndex:options.imageIndex + 1]\n            elif value.shape[0] > options.numImages:\n                pred_dict[key] = value[:options.numImages]\n                pass\n            continue\n        continue\n\n    #methods = [\'planenet\', \'pixelwise+RANSAC\', \'GT+RANSAC\']\n    titles = options.titles\n\n\n    \n    for image_index in xrange(options.visualizeImages):\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_image.png\', gt_dict[\'image\'][image_index])\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_gt.png\', drawDepthImage(gt_dict[\'depth\'][image_index]))\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_normal_gt.png\', drawNormalImage(gt_dict[\'normal\'][image_index]))        \n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_gt.png\', drawSegmentationImage(np.concatenate([gt_dict[\'segmentation\'][image_index], 1 - np.expand_dims(gt_dict[\'plane_mask\'][image_index], -1)], axis=2), blackIndex=options.numOutputPlanes))\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_semantics_gt.png\', drawSegmentationImage(gt_dict[\'semantics\'][image_index], blackIndex=0))\n        \n        plane_depths = calcPlaneDepths(gt_dict[\'plane\'][image_index], WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n        all_depths = np.concatenate([plane_depths, np.expand_dims(gt_dict[\'depth\'][image_index], -1)], axis=2)\n        depth = np.sum(all_depths * np.concatenate([gt_dict[\'segmentation\'][image_index], 1 - np.expand_dims(gt_dict[\'plane_mask\'][image_index], -1)], axis=2), axis=2)\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_gt_plane.png\', drawDepthImage(depth))\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_gt_diff.png\', drawMaskImage((depth - gt_dict[\'depth\'][image_index]) * 5 + 0.5))        \n        \n        for method_index, pred_dict in enumerate(predictions):\n            cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_dict[\'depth\'][image_index]))\n\n            if \'pixelwise\' in options.methods[method_index][1]:\n                continue\n            segmentation = pred_dict[\'segmentation\'][image_index]\n            segmentation = np.concatenate([segmentation, pred_dict[\'np_mask\'][image_index]], axis=2)\n\n            numPlanes = options.numOutputPlanes\n            if \'np10\' in options.methods[method_index][0]:\n                numPlanes = 10\n            elif \'np15\' in options.methods[method_index][0]:\n                numPlanes = 15                \n                pass\n            cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(segmentation, blackIndex=numPlanes))\n            continue\n        continue\n\n\n    #post processing\n    for method_index, method in enumerate(options.methods):\n        if len(method) == 3:\n            pred_dict = predictions[method[2]]\n        else:\n            pred_dict = predictions[method_index]\n            pass\n\n        if \'pixelwise_2\' in method[1] or \'pixelwise_3\' in method[1]:\n            bestScore = 0\n            configurationIndex = 0\n            for distanceCostThreshold in [0.3]:\n                for smoothnessWeight in [0.01, 0.03, 0.05]:\n                    for distanceThreshold in [0.2]:\n                        parameters = {\'distanceCostThreshold\': distanceCostThreshold, \'smoothnessWeight\': smoothnessWeight, \'distanceThreshold\': distanceThreshold, \'semantics\': True}\n                        score = 0\n                        for image_index in xrange(options.numImages):\n                            #cv2.imwrite(\'test/normal.png\', drawNormalImage(gt_dict[\'normal\'][image_index]))\n                            if \'_2\' in method[1]:\n                                pred_p, pred_s = fitPlanesNYU(gt_dict[\'image\'][image_index], gt_dict[\'depth\'][image_index].squeeze(), gt_dict[\'normal\'][image_index], gt_dict[\'semantics\'][image_index], gt_dict[\'info\'][image_index], numOutputPlanes=20, parameters=parameters)\n                            else:\n                                pred_d = pred_dict[\'np_depth\'][image_index].squeeze()\n                                pred_n = pred_dict[\'np_normal\'][image_index].squeeze()\n                                pred_p, pred_s = fitPlanesNYU(gt_dict[\'image\'][image_index], pred_d, pred_n, pred_dict[\'semantics\'][image_index], gt_dict[\'info\'][image_index], numOutputPlanes=20, parameters=parameters)\n                                pass\n\n                            predNumPlanes = pred_p.shape[0]\n                            gtDepths = calcPlaneDepths(gt_dict[\'plane\'][image_index], WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n                            planeDepths = calcPlaneDepths(pred_p, WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n                            pixelStatistics, planeStatistics = evaluatePlanePrediction(planeDepths, pred_s, predNumPlanes, gtDepths, gt_dict[\'segmentation\'][image_index], gt_dict[\'num_planes\'][image_index])\n                            #print(pixelStatistics)\n                            #exit(1)\n                            #planeStatistics = np.array(planeStatistics)[1]\n                            #accuracy = (planeStatistics[3:8, 0].astype(np.float32) / np.maximum(planeStatistics[3:8, 1], 1e-4)).mean()\n\n                            pixelStatistics = np.array(pixelStatistics)[1]\n                            accuracy = pixelStatistics[3:8].mean()\n                            score += accuracy\n\n                            #cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_d))            \n                            cv2.imwrite(\'test/segmentation_pred_\' + str(image_index) + \'.png\', drawSegmentationImage(pred_s, blackIndex=options.numOutputPlanes))\n                            #exit(1)\n                            continue\n                        score /= options.numImages\n                        print(score, parameters)\n                        configurationIndex += 1                    \n                        #exit(1)\n                        if score > bestScore:\n                            bestScore = score\n                            bestParameters = parameters\n                            pass\n                        continue\n                    continue\n                continue\n            print(bestScore)\n            print(bestParameters)\n            exit(1)\n                    \n        if \'pixelwise_4\' in method[1] or \'pixelwise_5\' in method[1]:\n            bestScore = 0\n            configurationIndex = 0\n            for distanceCostThreshold in [0.05]:\n                for smoothnessWeight in [30]:\n                    for offsetGap in [-0.1]:\n                        parameters = {\'distanceCostThreshold\': distanceCostThreshold, \'smoothnessWeight\': smoothnessWeight, \'offsetGap\': abs(offsetGap), \'meanshift\': offsetGap}\n\n                        score = 0\n                        for image_index in xrange(options.numImages):\n                            if \'_4\' in method[1]:\n                                pred_p, pred_s = fitPlanesManhattan(gt_dict[\'image\'][image_index], gt_dict[\'depth\'][image_index].squeeze(), gt_dict[\'normal\'][image_index], gt_dict[\'info\'][image_index], numOutputPlanes=20, parameters=parameters)\n                            else:\n                                pred_d = pred_dict[\'np_depth\'][image_index].squeeze()\n                                pred_n = pred_dict[\'np_normal\'][image_index].squeeze()\n                                pred_p, pred_s = fitPlanesManhattan(gt_dict[\'image\'][image_index], pred_d, pred_n, gt_dict[\'info\'][image_index], numOutputPlanes=20, parameters=parameters)\n                                pass\n\n                            predNumPlanes = pred_p.shape[0]\n                            gtDepths = calcPlaneDepths(gt_dict[\'plane\'][image_index], WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n                            planeDepths = calcPlaneDepths(pred_p, WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n                            pixelStatistics, planeStatistics = evaluatePlanePrediction(planeDepths, pred_s, predNumPlanes, gtDepths, gt_dict[\'segmentation\'][image_index], gt_dict[\'num_planes\'][image_index])\n                            #print(pixelStatistics)\n                            #exit(1)\n                            #planeStatistics = np.array(planeStatistics)[1]\n                            #accuracy = (planeStatistics[3:8, 0].astype(np.float32) / np.maximum(planeStatistics[3:8, 1], 1e-4)).mean()\n\n                            pixelStatistics = np.array(pixelStatistics)[1]\n                            accuracy = pixelStatistics[3:8].mean()\n                            score += accuracy\n\n                            #cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_d))            \n                            #cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(pred_s, blackIndex=options.numOutputPlanes))\n                            #exit(1)\n                            continue\n                        score /= options.numImages\n                        print(score, parameters)\n                        configurationIndex += 1                    \n                        #exit(1)\n                        if score > bestScore:\n                            bestScore = score\n                            bestParameters = parameters\n                            pass\n                        continue\n                    continue\n                continue\n            print(bestScore)\n            print(bestParameters)\n            exit(1)\n\n        if \'pixelwise_6\' in method[1] or \'pixelwise_7\' in method[1]:\n            bestScore = 0\n            configurationIndex = 0            \n            for distanceCostThreshold in [0.1]:\n                for smoothnessWeight in [300]:\n                    for normalWeight in [1]:\n                        for offset in [0.2]:\n                            parameters = {\'distanceCostThreshold\': distanceCostThreshold, \'smoothnessWeight\': smoothnessWeight, \'numProposals\': 5, \'normalWeight\': normalWeight, \'offsetGap\': abs(offset), \'meanshift\': offset}\n\n                            score = 0\n                            for image_index in xrange(options.numImages):\n                                if \'_6\' in method[1]:\n                                    pred_p, pred_s = fitPlanesPiecewise(gt_dict[\'image\'][image_index], gt_dict[\'depth\'][image_index].squeeze(), gt_dict[\'normal\'][image_index], gt_dict[\'info\'][image_index], numOutputPlanes=20, parameters=parameters)\n                                else:\n                                    pred_d = pred_dict[\'np_depth\'][image_index].squeeze()                \n                                    pred_n = pred_dict[\'np_normal\'][image_index].squeeze()                \n                                    pred_p, pred_s = fitPlanesPiecewise(gt_dict[\'image\'][image_index], pred_d, pred_n, gt_dict[\'info\'][image_index], numOutputPlanes=20, parameters=parameters)\n                                    pass\n\n                                predNumPlanes = pred_p.shape[0]\n                                gtDepths = calcPlaneDepths(gt_dict[\'plane\'][image_index], WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n                                planeDepths = calcPlaneDepths(pred_p, WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n                                pixelStatistics, planeStatistics = evaluatePlanePrediction(planeDepths, pred_s, predNumPlanes, gtDepths, gt_dict[\'segmentation\'][image_index], gt_dict[\'num_planes\'][image_index])\n                                #print(pixelStatistics)\n                                #exit(1)\n                                #planeStatistics = np.array(planeStatistics)[1]\n                                #accuracy = (planeStatistics[3:8, 0].astype(np.float32) / np.maximum(planeStatistics[3:8, 1], 1e-4)).mean()\n\n                                pixelStatistics = np.array(pixelStatistics)[1]\n                                accuracy = pixelStatistics[3:8].mean()\n                                score += accuracy\n\n                                #cv2.imwrite(\'test/depth_pred_\' + str(configurationIndex) + \'.png\', drawDepthImage(pred_d))\n                                cv2.imwrite(\'test/segmentation_pred_\' + str(image_index) + \'.png\', drawSegmentationImage(pred_s, blackIndex=options.numOutputPlanes))\n                                #exit(1)\n                                continue\n                            score /= options.numImages\n                            print(score, parameters)\n                            configurationIndex += 1\n\n                            #exit(1)\n                            if score > bestScore:\n                                bestScore = score\n                                bestParameters = parameters\n                                pass\n                            continue\n                        continue\n                    continue\n                continue\n            print(bestScore)\n            print(bestParameters)\n            exit(1)            \n\n        if method[1] == \'crfrnn\':\n\n            parameterConfigurations = [(160., 3., 3.), (80., 3., 3.), (40., 3., 3.), (120., 3., 3.)]\n\n            bestScore = 0\n            for parameters in parameterConfigurations:\n                tf.reset_default_graph()\n                image_inp = tf.placeholder(tf.float32, shape=[1, HEIGHT, WIDTH, 3], name=\'image\')\n                segmentation_inp = tf.placeholder(tf.float32, shape=[1, HEIGHT, WIDTH, options.numOutputPlanes + 1], name=\'segmentation\')\n            \n                refined_segmentation = CrfRnnLayer(image_dims=(HEIGHT, WIDTH), num_classes=21, theta_alpha=parameters[0], theta_beta=parameters[1], theta_gamma=parameters[2], num_iterations=10, name=\'crfrnn\')([segmentation_inp, image_inp])\n            \n                config=tf.ConfigProto()\n                config.gpu_options.allow_growth=True\n                config.allow_soft_placement=True\n\n                init_op = tf.group(tf.global_variables_initializer(),\n                                   tf.local_variables_initializer())\n                with tf.Session(config=config) as sess:\n                    sess.run(init_op)\n\n                    score = 0.\n                    for image_index in xrange(options.numImages):\n                        #if image_index != 1:\n                        #continue\n                        print(\'crf as rnn\', image_index)\n                        allSegmentations = np.concatenate([pred_dict[\'segmentation\'][image_index], pred_dict[\'np_mask\'][image_index]], axis=2)\n                        img = gt_dict[\'image\'][image_index:image_index + 1].astype(np.float32) - 128\n\n                        pred_s = sess.run(refined_segmentation, feed_dict={segmentation_inp: np.expand_dims(allSegmentations, 0), image_inp: img})\n                        pred_s = pred_s[0]\n\n                        #pred_s = allSegmentations\n                        \n                        pred_s = one_hot(np.argmax(pred_s, axis=-1), options.numOutputPlanes + 1)\n\n\n                        planeDepths = calcPlaneDepths(pred_dict[\'plane\'][image_index], WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n                        allDepths = np.concatenate([planeDepths, pred_dict[\'np_depth\'][image_index]], axis=2)\n                        pred_d = np.sum(allDepths * pred_s, axis=-1)\n\n\n                        # for planeIndex in xrange(options.numOutputPlanes):\n                        #     cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(pred_s[:, :, planeIndex]))\n                        #     cv2.imwrite(\'test/gt_mask_\' + str(planeIndex) + \'.png\', drawMaskImage(gt_dict[\'segmentation\'][image_index][:, :, planeIndex]))\n                        #     continue\n                        # cv2.imwrite(\'test/depth_pred.png\', drawDepthImage(pred_d))\n                        # cv2.imwrite(\'test/depth_gt.png\', drawDepthImage(gt_dict[\'depth\'][image_index]))                        \n                        # cv2.imwrite(\'test/depth_diff.png\', drawMaskImage(np.abs(pred_d - gt_dict[\'depth\'][image_index]) * 5))\n                        # exit(1)\n                        predNumPlanes = options.numOutputPlanes\n                        gtDepths = calcPlaneDepths(gt_dict[\'plane\'][image_index], WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n                        pixelStatistics, planeStatistics = evaluatePlanePrediction(planeDepths, pred_s[:, :, :options.numOutputPlanes], predNumPlanes, gtDepths, gt_dict[\'segmentation\'][image_index], gt_dict[\'num_planes\'][image_index])\n                        #print(pixelStatistics)\n                        #exit(1)\n                        #planeStatistics = np.array(planeStatistics)[1]\n                        #accuracy = (planeStatistics[3:8, 0].astype(np.float32) / np.maximum(planeStatistics[3:8, 1], 1e-4)).mean()\n                        pixelStatistics = np.array(pixelStatistics)[1]\n                        # print(pixelStatistics)\n                        # pixelStatistics[3:8].mean()\n                        # exit(1)\n                        accuracy = pixelStatistics[3:8].mean()\n                        score += accuracy\n                        \n                        #cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_d))            \n                        #cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(pred_s, blackIndex=options.numOutputPlanes))\n                        #exit(1)\n                        continue\n                    score /= options.numImages\n                    print(score)\n                    #exit(1)\n                    if score > bestScore:\n                        bestScore = score\n                        bestParameters = parameters\n                        pass\n                    pass\n                continue\n            print(bestScore)\n            print(bestParameters)\n            pass\n        continue\n    return\n\n\n\n\ndef getResults(options):\n    checkpoint_prefix = options.rootFolder + \'/checkpoint/\'\n\n    methods = options.methods\n    predictions = []\n\n    if os.path.exists(options.result_filename):\n        if options.useCache == 1:\n            results = np.load(options.result_filename)\n            results = results[()]\n            return results\n        elif options.useCache == 2:\n            results = np.load(options.result_filename)\n            results = results[()]\n            gt_dict = results[\'gt\']\n            predictions = results[\'pred\']\n        else:\n            gt_dict = getGroundTruth(options)\n            pass\n    else:\n        gt_dict = getGroundTruth(options)\n        pass\n    \n    \n\n    for method_index, method in enumerate(methods):\n        if options.useCache == 2 and (len(method) < 4 or method[3] < 2):\n            continue\n        if method[0] == \'\':\n            continue\n\n        method_options = copy.deepcopy(options)\n        if \'ds0\' not in method[0]:\n            method_options.deepSupervisionLayers = [\'res4b22_relu\', ]\n        else:\n            method_options.deepSupervisionLayers = []\n            pass\n        method_options.predictConfidence = 0\n        method_options.predictLocal = 0\n        method_options.predictPixelwise = 1\n        method_options.predictBoundary = int(\'pb\' in method[0])\n        method_options.anchorPlanes = 0\n        if \'ps\' in method[0]:\n            method_options.predictSemantics = 1\n        else:\n            method_options.predictSemantics = 0\n            pass\n        if \'crfrnn\' in method[0]:\n            method_options.crfrnn = 5\n        else:\n            method_options.crfrnn = 0\n            pass\n            \n        if \'ap1\' in method[0]:\n            method_options.anchorPlanes = 1            \n            pass\n\n        method_options.numOutputPlanes = 20\n        if \'np10\' in method[0]:\n            method_options.numOutputPlanes = 10\n        elif \'np15\' in method[0]:\n            method_options.numOutputPlanes = 15\n            pass\n        \n        method_options.checkpoint_dir = checkpoint_prefix + method[0]\n        print(method_options.checkpoint_dir)\n        \n        method_options.suffix = method[1]\n\n        method_names = [previous_method[0] for previous_method in methods[:method_index]]\n\n        if method[0] in method_names:\n            pred_dict = predictions[method_names.index(method[0])]\n        elif method[0] == \'gt\':\n            pred_dict = gt_dict\n        else:\n            while True:\n                try:\n                    pred_dict = getPrediction(method_options)\n                    break\n                except:\n                    continue\n                continue\n            pass\n\n        # for image_index in xrange(method_options.visualizeImages):\n        #     cv2.imwrite(method_options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_dict[\'depth\'][image_index]))\n        #     cv2.imwrite(method_options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage())\n        #     continue\n\n        if len(method) >= 4 and method[3] == 3:\n            predictions.insert(0, pred_dict)\n        else:\n            if method_index < len(predictions):\n                predictions[method_index] = pred_dict\n            else:\n                predictions.append(pred_dict)\n                pass\n            pass\n        continue\n    #np.save(method_options.test_dir + \'/curves.npy\', curves)\n    results = {\'gt\': gt_dict, \'pred\': predictions}\n\n    if options.useCache != -1:\n        np.save(options.result_filename, results)\n        pass\n    pass\n    \n    return results\n\ndef getPrediction(options):\n    tf.reset_default_graph()\n    \n    options.batchSize = 1\n    min_after_dequeue = 1000\n\n    reader = RecordReaderAll()\n    if options.dataset == \'SUNCG\':\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_SUNCG_val.tfrecords\'], num_epochs=10000)\n    elif options.dataset == \'NYU_RGBD\':\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_nyu_rgbd_val.tfrecords\'], num_epochs=1)\n        options.deepSupervision = 0\n        options.predictLocal = 0\n    elif options.dataset == \'matterport\':\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_matterport_val.tfrecords\'], num_epochs=1)\n    else:\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_scannet_val.tfrecords\'], num_epochs=1)\n        pass\n\n\n    img_inp, global_gt_dict, local_gt_dict = reader.getBatch(filename_queue, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True, random=False)\n        \n\n    \n    training_flag = tf.constant(False, tf.bool)\n\n    options.gpu_id = 0\n    if \'sample\' not in options.checkpoint_dir:\n        global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp, img_inp, training_flag, options)\n    else:\n        global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph_sample(img_inp, img_inp, training_flag, options)\n        pass\n        \n    var_to_restore = tf.global_variables()\n\n\n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n    \n    pred_dict = {}\n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n        #var_to_restore = [v for v in var_to_restore if \'res4b22_relu_non_plane\' not in v.name]\n        loader = tf.train.Saver(var_to_restore)\n        loader.restore(sess, ""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n        #loader.restore(sess, options.fineTuningCheckpoint)\n        \n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n        \n        \n        try:\n            predDepths = []\n            predPlanes = []\n            predSegmentations = []\n            predSemantics = []            \n            predNonPlaneDepths = []\n            predNonPlaneNormals = []            \n            predNonPlaneMasks = []\n            predBoundaries = []            \n            for index in xrange(options.startIndex + options.numImages):\n                if index % 10 == 0:\n                    print((\'image\', index))\n                    pass\n                t0=time.time()\n\n                img, global_gt, global_pred = sess.run([img_inp, global_gt_dict, global_pred_dict])\n\n                if index < options.startIndex:\n                    continue                \n\n\n                pred_p = global_pred[\'plane\'][0]\n                pred_s = global_pred[\'segmentation\'][0]\n                \n                pred_np_m = global_pred[\'non_plane_mask\'][0]\n                pred_np_d = global_pred[\'non_plane_depth\'][0]\n                pred_np_n = global_pred[\'non_plane_normal\'][0]\n                \n                if global_gt[\'info\'][0][19] > 1 and global_gt[\'info\'][0][19] < 4 and False:\n                    pred_np_n = calcNormal(pred_np_d.squeeze(), global_gt[\'info\'][0])\n                    pass\n\n\n                pred_b = global_pred[\'boundary\'][0]\n                predNonPlaneMasks.append(pred_np_m)                    \n                predNonPlaneDepths.append(pred_np_d)\n                predNonPlaneNormals.append(pred_np_n)\n                predBoundaries.append(pred_b)\n                    \n                all_segmentations = np.concatenate([pred_np_m, pred_s], axis=2)\n                plane_depths = calcPlaneDepths(pred_p, WIDTH, HEIGHT, global_gt[\'info\'][0])\n                all_depths = np.concatenate([pred_np_d, plane_depths], axis=2)\n\n                segmentation = np.argmax(all_segmentations, 2)\n                pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape(HEIGHT, WIDTH)\n\n                if \'semantics\' in global_pred:\n                    #cv2.imwrite(\'test/semantics.png\', drawSegmentationImage(np.argmax(global_pred[\'semantics\'][0], axis=-1)))\n                    #exit(1)\n                    predSemantics.append(np.argmax(global_pred[\'semantics\'][0], axis=-1))\n                else:\n                    predSemantics.append(np.zeros((HEIGHT, WIDTH)))\n                    pass\n                                         \n                predDepths.append(pred_d)\n                predPlanes.append(pred_p)\n                predSegmentations.append(pred_s)\n                    \n                continue\n            pred_dict[\'plane\'] = np.array(predPlanes)\n            pred_dict[\'segmentation\'] = np.array(predSegmentations)\n            pred_dict[\'semantics\'] = np.array(predSemantics)            \n            pred_dict[\'depth\'] = np.array(predDepths)\n            pred_dict[\'np_depth\'] = np.array(predNonPlaneDepths)\n            pred_dict[\'np_normal\'] = np.array(predNonPlaneNormals)\n            pred_dict[\'np_mask\'] = np.array(predNonPlaneMasks)\n            pred_dict[\'boundary\'] = np.array(predBoundaries)\n            pass\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n        \n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return pred_dict\n\ndef getGroundTruth(options):    \n    options.batchSize = 1\n    min_after_dequeue = 1000\n\n    reader = RecordReaderAll()\n    if options.dataset == \'SUNCG\':\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_SUNCG_val.tfrecords\'], num_epochs=10000)\n    elif options.dataset == \'NYU_RGBD\':\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_nyu_rgbd_val.tfrecords\'], num_epochs=1)\n        options.deepSupervision = 0\n        options.predictLocal = 0\n    elif options.dataset == \'matterport\':\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_matterport_val.tfrecords\'], num_epochs=1)\n    else:\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_scannet_val.tfrecords\'], num_epochs=1)\n        pass\n    \n    img_inp, global_gt_dict, local_gt_dict = reader.getBatch(filename_queue, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True, random=False)\n    \n\n    training_flag = tf.constant(False, tf.bool)\n\n    # if options.dataset == \'NYU_RGBD\':\n    #     global_gt_dict[\'segmentation\'], global_gt_dict[\'plane_mask\'] = tf.ones((options.batchSize, HEIGHT, WIDTH, options.numOutputPlanes)), tf.ones((options.batchSize, HEIGHT, WIDTH, 1))\n    # elif options.dataset == \'SUNCG\':\n    #     normalDotThreshold = np.cos(np.deg2rad(5))\n    #     distanceThreshold = 0.05        \n    #     global_gt_dict[\'segmentation\'], global_gt_dict[\'plane_mask\'] = fitPlaneMasksModule(global_gt_dict[\'plane\'], global_gt_dict[\'depth\'], global_gt_dict[\'normal\'], width=WIDTH, height=HEIGHT, normalDotThreshold=normalDotThreshold, distanceThreshold=distanceThreshold, closing=True, one_hot=True)\n    # else:\n    #     global_gt_dict[\'plane_mask\'] = 1 - global_gt_dict[\'non_plane_mask\']\n    #     pass\n\n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n    gt_dict = {}\n    \n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n        \n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)        \n        \n        try:\n            gtDepths = []\n            gtNormals = []            \n            planeMasks = []\n            #predMasks = []\n            gtPlanes = []\n            gtSegmentations = []\n            gtSemantics = []            \n            gtInfo = []\n            gtNumPlanes = []            \n            images = []\n\n            for index in xrange(options.startIndex + options.numImages):\n                print((\'image\', index))\n                t0=time.time()\n\n                img, global_gt = sess.run([img_inp, global_gt_dict])\n\n                if index < options.startIndex:\n                    continue\n\n                \n                # print(global_gt[\'path\'])\n                # if index == 11:\n                #     cv2.imwrite(\'test/mask.png\', drawMaskImage(global_gt[\'non_plane_mask\'].squeeze()))\n                #     exit(1)\n                image = ((img[0] + 0.5) * 255).astype(np.uint8)\n                images.append(image)\n\n                #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_boundary.png\', drawMaskImage(np.concatenate([global_gt[\'boundary\'][0], np.zeros((HEIGHT, WIDTH, 1))], axis=2)))\n                \n                gt_d = global_gt[\'depth\'].squeeze()\n                gtDepths.append(gt_d)\n\n                if global_gt[\'info\'][0][19] == 3 and False:\n                    gt_n = calcNormal(gt_d, global_gt[\'info\'][0])\n                    #cv2.imwrite(\'test/normal.png\', drawNormalImage(gt_n))\n                    #exit(1)\n                else:\n                    gt_n = global_gt[\'normal\'][0]\n                    pass    \n                gtNormals.append(gt_n)\n                \n                planeMask = np.squeeze(1 - global_gt[\'non_plane_mask\'])\n                planeMasks.append(planeMask)\n                \n                gt_p = global_gt[\'plane\'][0]\n                gtPlanes.append(gt_p)\n                gt_s = global_gt[\'segmentation\'][0]\n                gtSegmentations.append(gt_s)\n                gt_semantics = global_gt[\'semantics\'][0]\n                gtSemantics.append(gt_semantics)\n                gt_num_p = global_gt[\'num_planes\'][0]\n                gtNumPlanes.append(gt_num_p)\n                \n                gtInfo.append(global_gt[\'info\'][0])\n                continue\n\n            gt_dict[\'image\'] = np.array(images)\n            gt_dict[\'depth\'] = np.array(gtDepths)\n            gt_dict[\'normal\'] = np.array(gtNormals)\n            gt_dict[\'plane_mask\'] = np.array(planeMasks)\n            gt_dict[\'plane\'] = np.array(gtPlanes)\n            gt_dict[\'segmentation\'] = np.array(gtSegmentations)\n            gt_dict[\'semantics\'] = np.array(gtSemantics)\n            gt_dict[\'num_planes\'] = np.array(gtNumPlanes)\n            gt_dict[\'info\'] = np.array(gtInfo)\n            \n\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n        \n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return gt_dict\n\n\nif __name__==\'__main__\':\n    """"""\n    Parse input arguments\n    """"""\n    parser = argparse.ArgumentParser(description=\'Planenet\')\n    parser.add_argument(\'--task\', dest=\'task\',\n                        help=\'task type\',\n                        default=\'compare\', type=str)\n    parser.add_argument(\'--numOutputPlanes\', dest=\'numOutputPlanes\',\n                        help=\'the number of output planes\',\n                        default=20, type=int)\n    parser.add_argument(\'--dataset\', dest=\'dataset\',\n                        help=\'dataset name\',\n                        default=\'ScanNet\', type=str)\n    parser.add_argument(\'--hybrid\', dest=\'hybrid\',\n                        help=\'hybrid\',\n                        default=\'3\', type=str)\n    parser.add_argument(\'--visualizeImages\', dest=\'visualizeImages\',\n                        help=\'visualize image\',\n                        default=30, type=int)    \n    parser.add_argument(\'--numImages\', dest=\'numImages\',\n                        help=\'the number of images\',\n                        default=30, type=int)\n    parser.add_argument(\'--startIndex\', dest=\'startIndex\',\n                        help=\'start index\',\n                        default=0, type=int)    \n    parser.add_argument(\'--useCache\', dest=\'useCache\',\n                        help=\'use cache\',\n                        default=0, type=int)\n    # parser.add_argument(\'--useCRF\', dest=\'useCRF\',\n    #                     help=\'use crf\',\n    #                     default=0, type=int)\n    # parser.add_argument(\'--useSemantics\', dest=\'useSemantics\',\n    #                     help=\'use semantics\',\n    #                     default=0, type=int)\n    parser.add_argument(\'--useNonPlaneDepth\', dest=\'useNonPlaneDepth\',\n                        help=\'use non-plane depth\',\n                        default=0, type=int)\n    parser.add_argument(\'--imageIndex\', dest=\'imageIndex\',\n                        help=\'image index\',\n                        default=-1, type=int)\n    parser.add_argument(\'--methods\', dest=\'methods\',\n                        help=\'methods\',\n                        default=\'1111111\', type=str)\n    parser.add_argument(\'--rootFolder\', dest=\'rootFolder\',\n                        help=\'root folder\',\n                        default=\'/mnt/vision/PlaneNet/\', type=str)\n    \n    args = parser.parse_args()\n    #args.hybrid = \'hybrid\' + args.hybrid\n    args.test_dir = \'evaluate/\' + args.task + \'/\' + args.dataset + \'/hybrid\' + args.hybrid + \'/\'\n    args.visualizeImages = min(args.visualizeImages, args.numImages)\n    if args.imageIndex >= 0:\n        args.visualizeImages = 1\n        args.numImages = 1            \n        pass\n\n    #args.titles = [ALL_TITLES[int(method)] for method in args.methods]\n    #args.methods = [ALL_METHODS[int(method)] for method in args.methods]\n    titles = []\n    for methodIndex, flag in enumerate(args.methods):\n        if int(flag) == 0:\n            continue\n        titles.append(ALL_TITLES[methodIndex])\n        pass\n    args.titles = titles\n\n    methods = []\n    for methodIndex, flag in enumerate(args.methods):\n        if int(flag) == 0:\n            continue\n        method = ALL_METHODS[methodIndex]\n        method[3] = int(flag)\n        methods.append(method)\n        pass\n    args.methods = methods\n    \n    args.result_filename = args.test_dir + \'/results_\' + str(0) + \'.npy\'\n    print(args.titles)\n    \n    if args.task == \'compare\':\n        evaluatePlanes(args)\n    elif args.task == \'depth\':\n        evaluateDepthPrediction(args)\n    elif args.task == \'search\':\n        gridSearch(args)\n        pass\n'"
code/crfasrnn_layer.py,18,"b'""""""\nMIT License\nCopyright (c) 2017 Sadeep Jayasumana\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the ""Software""), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n""""""\n\nimport numpy as np\nimport tensorflow as tf\nfrom keras.engine.topology import Layer\ncustom_module = tf.load_op_library(\'./cpp/high_dim_filter.so\')\nimport high_dim_filter_grad  # Register gradients for the custom op\n\n\nclass CrfRnnLayer(Layer):\n    """""" Implements the CRF-RNN layer described in:\n    Conditional Random Fields as Recurrent Neural Networks,\n    S. Zheng, S. Jayasumana, B. Romera-Paredes, V. Vineet, Z. Su, D. Du, C. Huang and P. Torr,\n    ICCV 2015\n    """"""\n\n    def __init__(self, image_dims, num_classes,\n                 theta_alpha, theta_beta, theta_gamma,\n                 num_iterations, **kwargs):\n        self.image_dims = image_dims\n        self.num_classes = num_classes\n        self.theta_alpha = theta_alpha\n        self.theta_beta = theta_beta\n        self.theta_gamma = theta_gamma\n        self.num_iterations = num_iterations\n        self.spatial_ker_weights = None\n        self.bilateral_ker_weights = None\n        self.compatibility_matrix = None\n        super(CrfRnnLayer, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        # # Weights of the spatial kernel\n        # self.spatial_ker_weights = self.add_weight(name=\'spatial_ker_weights\',\n        #                                            shape=(self.num_classes, self.num_classes),\n        #                                            initializer=\'uniform\',\n        #                                            trainable=True)\n\n        # # Weights of the bilateral kernel\n        # self.bilateral_ker_weights = self.add_weight(name=\'bilateral_ker_weights\',\n        #                                              shape=(self.num_classes, self.num_classes),\n        #                                              initializer=\'uniform\',\n        #                                              trainable=True)\n\n        # # Compatibility matrix\n        # self.compatibility_matrix = self.add_weight(name=\'compatibility_matrix\',\n        #                                             shape=(self.num_classes, self.num_classes),\n        #                                             initializer=\'uniform\',\n        #                                             trainable=True)\n\n\n        weights = np.load(\'weights.npy\')\n        weights = [weights[0], weights[1], weights[2]]\n        self.spatial_ker_weights = tf.Variable(weights[0][:self.num_classes, :self.num_classes], name=\'spatial_ker_weights\', trainable=True)\n        self.bilateral_ker_weights = tf.Variable(weights[1][:self.num_classes, :self.num_classes], name=\'bilateral_ker_weights\', trainable=True)\n        self.compatibility_matrix = tf.Variable(weights[2][:self.num_classes, :self.num_classes], name=\'compatibility_matrix\', trainable=True)\n\n        \n        # self.spatial_ker_weights = tf.constant(weights[0].reshape(-1), name=\'spatial_ker_weights\', shape=(self.num_classes, self.num_classes))\n        # self.bilateral_ker_weights = tf.constant(weights[1].reshape(-1), name=\'bilateral_ker_weights\', shape=(self.num_classes, self.num_classes))\n        # self.compatibility_ker_weights = tf.constant(weights[2].reshape(-1), name=\'compatibility_ker_weights\', shape=(self.num_classes, self.num_classes))\n        \n        \n        super(CrfRnnLayer, self).build(input_shape)\n\n\n    def call(self, inputs):\n        batchSize = int(inputs[0].shape[0])\n        c, h, w = self.num_classes, self.image_dims[0], self.image_dims[1]\n        all_ones = np.ones((c, h, w), dtype=np.float32)\n\n        outputs = []\n        for batchIndex in xrange(batchSize):\n            unaries = tf.transpose(inputs[0][batchIndex, :, :, :], perm=(2, 0, 1))\n            rgb = tf.transpose(inputs[1][batchIndex, :, :, :], perm=(2, 0, 1))\n\n\n            # Prepare filter normalization coefficients\n            spatial_norm_vals = custom_module.high_dim_filter(all_ones, rgb, bilateral=False,\n                                                              theta_gamma=self.theta_gamma)\n            bilateral_norm_vals = custom_module.high_dim_filter(all_ones, rgb, bilateral=True,\n                                                                theta_alpha=self.theta_alpha,\n                                                                theta_beta=self.theta_beta)\n            q_values = unaries\n\n            for i in range(self.num_iterations):\n                softmax_out = tf.nn.softmax(q_values, dim=0)\n\n                # Spatial filtering\n                spatial_out = custom_module.high_dim_filter(softmax_out, rgb, bilateral=False,\n                                                            theta_gamma=self.theta_gamma)\n                spatial_out = spatial_out / spatial_norm_vals\n\n                # Bilateral filtering\n                bilateral_out = custom_module.high_dim_filter(softmax_out, rgb, bilateral=True,\n                                                              theta_alpha=self.theta_alpha,\n                                                              theta_beta=self.theta_beta)\n                bilateral_out = bilateral_out / bilateral_norm_vals\n\n                # Weighting filter outputs\n                message_passing = (tf.matmul(self.spatial_ker_weights,\n                                             tf.reshape(spatial_out, (c, -1))) +\n                                   tf.matmul(self.bilateral_ker_weights,\n                                             tf.reshape(bilateral_out, (c, -1))))\n\n                # Compatibility transform\n                pairwise = tf.matmul(self.compatibility_matrix, message_passing)\n\n                # Adding unary potentials\n                pairwise = tf.reshape(pairwise, (c, h, w))\n                q_values = unaries - pairwise\n                continue\n            outputs.append(tf.transpose(tf.reshape(q_values, (1, c, h, w)), perm=(0, 2, 3, 1)))\n            continue\n        outputs = tf.concat(outputs, axis=0)\n        return outputs\n\n    def compute_output_shape(self, input_shape):\n        return input_shape\n'"
code/evaluate.py,69,"b'import tensorflow as tf\nimport numpy as np\nnp.set_printoptions(precision=2, linewidth=200)\nimport cv2\nimport os\nimport time\nimport sys\n#import tf_nndistance\nimport argparse\nimport glob\nimport PIL\nimport scipy.ndimage as ndimage\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom utils import *\nfrom plane_utils import *\nfrom modules import *\n\nfrom train_planenet import build_graph\nfrom train_sample import build_graph as build_graph_sample\nfrom planenet import PlaneNet\nfrom RecordReaderAll import *\nfrom SegmentationRefinement import *\nfrom crfasrnn_layer import CrfRnnLayer\n\n#[\'/mnt/vision/ScanNet/data/scene0164_01/frames/frame-000068.color.jpg\']\n\n#ALL_TITLES = [\'planenet\', \'pixelwise\', \'pixelwise+RANSAC\', \'depth observation+RANSAC\', \'pixelwise+semantics+RANSAC\', \'gt\']\n#ALL_METHODS = [(\'bl2_ll1_bw0.5_pb_pp_sm0\', \'\'), (\'pb_pp\', \'pixelwise_1\'), (\'pb_pp\', \'pixelwise_2\'), (\'pb_pp\', \'pixelwise_3\'), (\'pb_pp\', \'semantics\'), (\'pb_pp\', \'gt\')]\n\nALL_TITLES = [\'PlaneNet\', \'Oracle NYU toolbox\', \'NYU toolbox\', \'Oracle Manhattan\', \'Manhattan\', \'Oracle Piecewise\', \'Piecewise\']\n#ALL_TITLES = [\'PlaneNet\', \'[25] + depth\', \'[25]\', \'[9] + depth\', \'[9]\', \'[26] + depth\', \'[26]\']\n#ALL_METHODS = [(\'bl0_dl0_bw0.5_pb_pp_ps_sm0\', \'\'), (\'ll1_pb_pp\', \'\'), (\'bl0_ll1_bw0.5_pb_pp_ps_sm0\', \'\'), (\'ll1_bw0.5_pb_pp_sm0\', \'\')]\n#ALL_METHODS = [(\'bl0_dl0_ll1_bw0.5_pb_pp_sm0\', \'\'), (\'bl0_dl0_ll1_pb_pp_sm0\', \'\'), (\'bl0_dl0_ll1_pb_pp_ps\', \'\'), (\'bl0_dl0_ll1_ds0_pb_pp\', \'\')]\n\n#ALL_METHODS = [(\'bl0_dl0_ll1_pb_pp_sm0\', \'\'), (\'bl0_dl0_ll1_pb_pp_sm0\', \'pixelwise_2\'), (\'bl0_dl0_ll1_pb_pp_sm0\', \'pixelwise_3\'), (\'bl0_dl0_ll1_pb_pp_sm0\', \'pixelwise_6\'), (\'bl0_dl0_ll1_pb_pp_sm0\', \'pixelwise_5\')]\n#ALL_METHODS = [(\'bl0_dl0_ll1_pb_pp_sm0\', \'\'), (\'bl0_dl0_crfrnn10_sm0\', \'\'), (\'bl0_dl0_ll1_pp_sm0\', \'\'), (\'bl0_dl0_ll1_pb_pp_sm0\', \'\'), (\'bl0_dl0_ll1_pb_pp_sm0\', \'\')]\n\n#ALL_METHODS = [(\'bl0_dl0_ll1_pb_pp_sm0\', \'\', 0), (\'bl0_dl0_ll1_pb_pp_sm0\', \'crfrnn\', 0), (\'bl0_dl0_crfrnn10_sm0\', \'\')]\n\n#ALL_METHODS = [[\'planenet_hybrid3_bl0_dl0_ll1_pb_pp_sm0\', \'\', 0, 0], [\'planenet_hybrid3_bl0_dl0_ll1_pb_pp_ps_sm0\', \'pixelwise_2\', 1, 0], [\'\', \'pixelwise_3\', 1, 0], [\'\', \'pixelwise_4\', 1, 0], [\'\', \'pixelwise_5\', 1, 0], [\'\', \'pixelwise_6\', 1, 0], [\'\', \'pixelwise_7\', 1, 0]]\n#ALL_METHODS = [[\'planenet_hybrid3_bl0_dl0_ll1_pb_pp_sm0\', \'\', 0, 0], [\'planenet_hybrid3_bl0_dl0_ll1_pb_pp_ps_sm0\', \'pixelwise_2\', 1, 0], [\'\', \'pixelwise_3\', 1, 0], [\'\', \'pixelwise_4\', 1, 0], [\'\', \'pixelwise_5\', 1, 0], [\'\', \'pixelwise_6\', 1, 0], [\'\', \'pixelwise_7\', 1, 0]]\nALL_METHODS = [[\'sample_np10_hybrid3_bl0_dl0_ds0_crfrnn5_sm0\', \'\', 0, 0], [\'planenet_hybrid3_bl0_dl0_ll1_pb_pp_ps_sm0\', \'pixelwise_2\', 1, 0], [\'\', \'pixelwise_3\', 1, 0], [\'\', \'pixelwise_4\', 1, 0], [\'\', \'pixelwise_5\', 1, 0], [\'\', \'pixelwise_6\', 1, 0], [\'\', \'pixelwise_7\', 1, 0]]\n\n#ALL_METHODS = [(\'ll1_pb_pp\', \'pixelwise_1\'), (\'crf1_pb_pp\', \'pixelwise_2\'), (\'bl0_ll1_bw0.5_pb_pp_ps_sm0\', \'pixelwise_3\'), (\'ll1_bw0.5_pb_pp_sm0\', \'pixelwise_4\')]\n\n\n#ALL_TITLES = [\'planenet\', \'pixelwise\']\n#ALL_METHODS = [(\'bl0_ll1_bw0.5_pb_pp_ps_sm0\', \'\'), (\'bl0_ll1_bw0.5_pb_pp_ps_sm0\', \'pixelwise_1\')]\n#ALL_TITLES = [\'crf\', \'different matching\']\n#ALL_METHODS = [(\'pb_pp_sm0\', \'crf\'), (\'pb_pp_sm0\', \'\')]\n\ndef writeHTML(options):\n    from html import HTML\n\n    titles = options.titles\n\n    h = HTML(\'html\')\n    h.p(\'Results\')\n    h.br()\n    path = \'.\'\n    #methods = [\'planenet\', \'pixelwise\', \'pixelwise+RANSAC\', \'GT+RANSAC\', \'planenet+crf\', \'pixelwise+semantics+RANSAC\']\n    #methods = [\'planenet\', \'pixelwise\', \'pixelwise+RANSAC\', \'GT+RANSAC\']\n\n    for index in xrange(options.numImages):\n\n        t = h.table(border=\'1\')\n        r_inp = t.tr()\n        r_inp.td(\'input \' + str(index))\n        r_inp.td().img(src=path + \'/\' + str(index) + \'_image.png\')\n        r_inp.td().img(src=path + \'/\' + str(index) + \'_depth_gt.png\')\n        r_inp.td().img(src=path + \'/\' + str(index) + \'_segmentation_gt.png\')\n        r_inp.td().img(src=path + \'/\' + str(index) + \'_semantics_gt.png\')\n        r_inp.td().img(src=path + \'/\' + str(index) + \'_depth_gt_plane.png\')\n        r_inp.td().img(src=path + \'/\' + str(index) + \'_depth_gt_diff.png\')\n        # r = t.tr()\n        # r.td(\'PlaneNet prediction\')\n        # r.td().img(src=firstFolder + \'/\' + str(index) + \'_segmentation_pred.png\')\n        # r.td().img(src=firstFolder + \'/\' + str(index) + \'_depth_pred.png\')\n\n        r = t.tr()\n        r.td(\'methods\')\n        for method_index, method in enumerate(titles):\n            r.td(method)\n            continue\n\n        r = t.tr()\n        r.td(\'segmentation\')\n        for method_index, method in enumerate(titles):\n            r.td().img(src=path + \'/\' + str(index) + \'_segmentation_pred_\' + str(method_index) + \'.png\')\n            continue\n\n        r = t.tr()\n        r.td(\'depth\')\n        for method_index, method in enumerate(titles):\n            r.td().img(src=path + \'/\' + str(index) + \'_depth_pred_\' + str(method_index) + \'.png\')\n            continue\n        h.br()\n        continue\n\n    metric_titles = [\'depth error 0.1\', \'depth error 0.2\', \'depth error 0.3\', \'IOU 0.3\', \'IOU 0.5\', \'IOU 0.7\']\n\n    h.p(\'Curves on plane accuracy\')\n    for title in metric_titles:\n        h.img(src=\'curve_plane_\' + title.replace(\' \', \'_\') + \'.png\')\n        continue\n\n    h.p(\'Curves on pixel coverage\')\n    for title in metric_titles:\n        h.img(src=\'curve_pixel_\' + title.replace(\' \', \'_\') + \'.png\')\n        continue\n\n\n    html_file = open(options.test_dir + \'/index.html\', \'w\')\n    html_file.write(str(h))\n    html_file.close()\n    return\n\ndef evaluatePlanes(options):\n    #writeHTML(options)\n    #exit(1)\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n\n    results = getResults(options)\n\n    gt_dict = results[\'gt\']\n    predictions = results[\'pred\']\n\n\n    saving = True\n    if gt_dict[\'image\'].shape[0] != options.numImages or options.useCache == 1:\n        saving = False\n        pass\n\n\n    for key, value in gt_dict.iteritems():\n        if options.imageIndex >= 0:\n            gt_dict[key] = value[options.imageIndex:options.imageIndex + 1]\n        elif value.shape[0] > options.numImages:\n            gt_dict[key] = value[:options.numImages]\n            pass\n        continue\n    for pred_dict in predictions:\n        for key, value in pred_dict.iteritems():\n            if options.imageIndex >= 0:\n                pred_dict[key] = value[options.imageIndex:options.imageIndex + 1]\n            elif value.shape[0] > options.numImages:\n                pred_dict[key] = value[:options.numImages]\n                pass\n            continue\n        continue\n\n    #methods = [\'planenet\', \'pixelwise+RANSAC\', \'GT+RANSAC\']\n\n\n\n    #predictions[2] = predictions[3]\n\n\n\n\n    for image_index in xrange(options.visualizeImages):\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_image.png\', gt_dict[\'image\'][image_index])\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_gt.png\', drawDepthImage(gt_dict[\'depth\'][image_index]))\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_normal_gt.png\', drawNormalImage(gt_dict[\'normal\'][image_index]))\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_gt.png\', drawSegmentationImage(np.concatenate([gt_dict[\'segmentation\'][image_index], 1 - np.expand_dims(gt_dict[\'plane_mask\'][image_index], -1)], axis=2), blackIndex=options.numOutputPlanes))\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_semantics_gt.png\', drawSegmentationImage(gt_dict[\'semantics\'][image_index], blackIndex=0))\n\n\n        plane_depths = calcPlaneDepths(gt_dict[\'plane\'][image_index], WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n        all_depths = np.concatenate([plane_depths, np.expand_dims(gt_dict[\'depth\'][image_index], -1)], axis=2)\n        depth = np.sum(all_depths * np.concatenate([gt_dict[\'segmentation\'][image_index], 1 - np.expand_dims(gt_dict[\'plane_mask\'][image_index], -1)], axis=2), axis=2)\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_gt_plane.png\', drawDepthImage(depth))\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_gt_diff.png\', drawMaskImage((depth - gt_dict[\'depth\'][image_index]) * 5 + 0.5))\n\n\n        for method_index, pred_dict in enumerate(predictions):\n            cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_dict[\'depth\'][image_index]))\n\n            #if \'pixelwise\' in options.methods[method_index][1]:\n            #continue\n            segmentation = pred_dict[\'segmentation\'][image_index]\n            #segmentation = np.concatenate([segmentation, pred_dict[\'np_mask\'][image_index]], axis=2)\n            numPlanes = options.numOutputPlanes\n            if \'pixelwise\' in options.methods[method_index][1]:\n                numPlanes = pred_dict[\'plane\'][image_index].shape[0]\n                #print(numPlanes)\n                pass\n            cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(segmentation, blackIndex=numPlanes))\n            continue\n        continue\n\n    exit(1)\n\n    #post processing\n    for method_index, method in enumerate(options.methods):\n        if method[1] == \'\':\n            continue\n        if len(method) < 4 or method[3] == 0:\n            continue\n        if len(method) >= 3 and method[2] >= 0:\n            pred_dict = predictions[method[2]]\n        else:\n            pred_dict = predictions[method_index]\n            pass\n\n        if method[1] == \'graphcut\':\n            #pred_dict = gt_dict\n            predSegmentations = []\n            predDepths = []\n            for image_index in xrange(options.numImages):\n                #if image_index != 3:\n                #continue\n                print(\'graph cut \' + str(image_index))\n\n                segmentation = np.argmax(np.concatenate([pred_dict[\'segmentation\'][image_index], 1 - np.expand_dims(pred_dict[\'plane_mask\'][image_index], -1)], axis=2), axis=2)\n                #pred_s = getSegmentationsGraphCut(pred_dict[\'plane\'][image_index], gt_dict[\'image\'][image_index], pred_dict[\'depth\'][image_index], pred_dict[\'normal\'][image_index], segmentation, pred_dict[\'semantics\'][image_index], pred_dict[\'info\'][image_index], gt_dict[\'num_planes\'][image_index])\n\n                pred_p, pred_s, numPlanes = removeSmallSegments(pred_dict[\'plane\'][image_index], gt_dict[\'image\'][image_index], pred_dict[\'depth\'][image_index], pred_dict[\'normal\'][image_index], segmentation, pred_dict[\'semantics\'][image_index], pred_dict[\'info\'][image_index], gt_dict[\'num_planes\'][image_index])\n                #pred_p, pred_s, numPlanes = pred_dict[\'plane\'][image_index], segmentation, gt_dict[\'num_planes\'][image_index]\n                print((gt_dict[\'num_planes\'][image_index], numPlanes))\n                planeDepths = calcPlaneDepths(pred_p, WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n                allDepths = np.concatenate([planeDepths, np.expand_dims(pred_dict[\'depth\'][image_index], -1)], axis=2)\n                pred_d = allDepths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), pred_s.reshape(-1)].reshape(HEIGHT, WIDTH)\n\n                predSegmentations.append(pred_s)\n                predDepths.append(pred_d)\n\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_d))\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(pred_s, blackIndex=options.numOutputPlanes))\n                continue\n            new_pred_dict = {}\n            for key, value in pred_dict.iteritems():\n                new_pred_dict[key] = value\n                continue\n            new_pred_dict[\'segmentation\'] = np.array(predSegmentations)\n            if method_index < len(predictions):\n                predictions[method_index] = new_pred_dict\n            else:\n                predictions.append(new_pred_dict)\n                pass\n        if method[1] == \'crf_tf\':\n            predSegmentations = []\n            predDepths = []\n\n            image_inp = tf.placeholder(tf.float32, shape=[1, HEIGHT, WIDTH, 3], name=\'image\')\n            segmentation_inp = tf.placeholder(tf.float32, shape=[1, HEIGHT, WIDTH, options.numOutputPlanes + 1], name=\'segmentation\')\n            plane_inp = tf.placeholder(tf.float32, shape=[1, options.numOutputPlanes, 3], name=\'plane\')\n            non_plane_depth_inp = tf.placeholder(tf.float32, shape=[1, HEIGHT, WIDTH, 1], name=\'non_plane_depth\')\n            info_inp = tf.placeholder(tf.float32, shape=[20], name=\'info\')\n\n\n            plane_parameters = tf.reshape(plane_inp, (-1, 3))\n            plane_depths = planeDepthsModule(plane_parameters, WIDTH, HEIGHT, info_inp)\n            plane_depths = tf.transpose(tf.reshape(plane_depths, [HEIGHT, WIDTH, -1, options.numOutputPlanes]), [2, 0, 1, 3])\n            all_depths = tf.concat([plane_depths, non_plane_depth_inp], axis=3)\n\n            planesY = plane_inp[:, :, 1]\n            planesD = tf.maximum(tf.norm(plane_inp, axis=-1), 1e-4)\n            planesY /= planesD\n            planesY = tf.concat([planesY, tf.ones((1, 1))], axis=1)\n\n            #refined_segmentation = crfModule(segmentation_inp, plane_inp, non_plane_depth_inp, info_inp, numOutputPlanes = options.numOutputPlanes, numIterations=5)\n\n            imageDiff = calcImageDiff(image_inp)\n            #refined_segmentation, debug_dict = segmentationRefinementModule(segmentation_inp, all_depths, planesY, imageDiff, numOutputPlanes = options.numOutputPlanes + 1, numIterations=5)\n            refined_segmentation, debug_dict = meanfieldModule(segmentation_inp, all_depths, planesY, imageDiff, numOutputPlanes = options.numOutputPlanes + 1, maxDepthDiff=0.2, varDepthDiff=pow(0.2, 2))\n\n            config=tf.ConfigProto()\n            config.gpu_options.allow_growth=True\n            config.allow_soft_placement=True\n\n            init_op = tf.group(tf.global_variables_initializer(),\n                               tf.local_variables_initializer())\n            with tf.Session(config=config) as sess:\n                sess.run(init_op)\n                for image_index in xrange(options.numImages):\n                    #if image_index != 1:\n                    #continue\n                    print(\'crf tf \' + str(image_index))\n                    allSegmentations = np.concatenate([pred_dict[\'segmentation\'][image_index], pred_dict[\'np_mask\'][image_index]], axis=2)\n                    allSegmentations = softmax(allSegmentations)\n                    pred_s, debug = sess.run([refined_segmentation, debug_dict], feed_dict={segmentation_inp: np.expand_dims(allSegmentations, 0), plane_inp: np.expand_dims(pred_dict[\'plane\'][image_index], 0), non_plane_depth_inp: np.expand_dims(pred_dict[\'np_depth\'][image_index], 0), info_inp: gt_dict[\'info\'][image_index], image_inp: gt_dict[\'image\'][image_index:image_index + 1]})\n\n                    pred_s = pred_s[0]\n                    planeDepths = calcPlaneDepths(pred_dict[\'plane\'][image_index], WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n                    allDepths = np.concatenate([planeDepths, pred_dict[\'np_depth\'][image_index]], axis=2)\n                    pred_d = np.sum(allDepths * pred_s, axis=-1)\n\n                    predSegmentations.append(pred_s)\n                    predDepths.append(pred_d)\n\n                    cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_d))\n                    cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(pred_s, blackIndex=options.numOutputPlanes))\n\n                    if \'diff\' in debug:\n                        segmentation = np.argmax(allSegmentations, axis=-1)\n                        for planeIndex in xrange(options.numOutputPlanes + 1):\n                            cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(allSegmentations[:, :, planeIndex]))\n                            continue\n\n                        for planeIndex in xrange(debug[\'diff\'].shape[-1]):\n                            cv2.imwrite(\'test/cost_mask_\' + str(planeIndex) + \'.png\', drawMaskImage(debug[\'diff\'][0, :, :, planeIndex] / 2))\n                            continue\n                        exit(1)\n                        pass\n                    continue\n                pass\n            new_pred_dict = {}\n            for key, value in pred_dict.iteritems():\n                new_pred_dict[key] = value\n                continue\n            segmentations = np.array(predSegmentations)\n            new_pred_dict[\'segmentation\'] = segmentations[:, :, :, :options.numOutputPlanes]\n            new_pred_dict[\'non_plane_mask\'] = segmentations[:, :, :, options.numOutputPlanes:options.numOutputPlanes + 1]\n            #new_pred_dict[\'non_plane_mask\'] = segmentations[:, :, :, :options.numOutputPlanes]\n            new_pred_dict[\'depth\'] = np.array(predDepths)\n            if method_index < len(predictions):\n                predictions[method_index] = new_pred_dict\n            else:\n                predictions.append(new_pred_dict)\n                pass\n            pass\n\n        if method[1] == \'crf\':\n            predSegmentations = []\n            predDepths = []\n            for image_index in xrange(options.numImages):\n                print(\'crf \' + str(image_index))\n                boundaries = pred_dict[\'boundary\'][image_index]\n                boundaries = sigmoid(boundaries)\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_boundary.png\', drawMaskImage(np.concatenate([boundaries, np.zeros((HEIGHT, WIDTH, 1))], axis=2)))\n\n                allSegmentations = np.concatenate([pred_dict[\'segmentation\'][image_index], pred_dict[\'np_mask\'][image_index]], axis=2)\n                allSegmentations = softmax(allSegmentations)\n                planeDepths = calcPlaneDepths(pred_dict[\'plane\'][image_index], WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n                allDepths = np.concatenate([planeDepths, pred_dict[\'np_depth\'][image_index]], axis=2)\n                #boundaries = np.concatenate([np.ones((allSegmentations.shape[0], allSegmentations.shape[1], 1)), -np.ones((allSegmentations.shape[0], allSegmentations.shape[1], 1))], axis=2)\n                #if options.imageIndex >= 0:\n                #boundaries = cv2.imread(options.test_dir + \'/\' + str(options.imageIndex) + \'_boundary.png\')\n                #else:\n                #boundaries = cv2.imread(options.test_dir + \'/\' + str(image_index) + \'_boundary.png\')\n                #pass\n                #boundaries = (boundaries > 128).astype(np.float32)[:, :, :2]\n\n                allDepths[:, :, options.numOutputPlanes] = 0\n                pred_s = refineSegmentation(gt_dict[\'image\'][image_index], allSegmentations, allDepths, boundaries, numOutputPlanes = 20, numIterations=20, numProposals=5)\n                pred_d = allDepths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), pred_s.reshape(-1)].reshape(HEIGHT, WIDTH)\n\n                predSegmentations.append(pred_s)\n                predDepths.append(pred_d)\n\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_d))\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(pred_s, blackIndex=options.numOutputPlanes))\n\n                #segmentation = np.argmax(allSegmentations, axis=-1)\n                # for planeIndex in xrange(options.numOutputPlanes + 1):\n                #     cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(allSegmentations[:, :, planeIndex]))\n                #     continue\n                #cv2.imwrite(options.test_dir + \'/mask_\' + str(21) + \'.png\', drawDepthImage(pred_dict[\'np_depth\'][0]))\n                #for plane_index in xrange(options.numOutputPlanes + 1):\n                #cv2.imwrite(options.test_dir + \'/mask_\' + str(plane_index) + \'.png\', drawMaskImage(pred_s == plane_index))\n                #continue\n                #exit(1)\n                continue\n\n            new_pred_dict = {}\n            for key, value in pred_dict.iteritems():\n                new_pred_dict[key] = value\n                continue\n            new_pred_dict[\'segmentation\'] = np.array(predSegmentations)\n            new_pred_dict[\'depth\'] = np.array(predDepths)\n            if method_index < len(predictions):\n                predictions[method_index] = new_pred_dict\n            else:\n                predictions.append(new_pred_dict)\n                pass\n            pass\n\n\n        if \'pixelwise\' in method[1]:\n            predPlanes = []\n            predSegmentations = []\n            predDepths = []\n            predNumPlanes = []\n            for image_index in xrange(options.numImages):\n                pred_d = pred_dict[\'np_depth\'][image_index].squeeze()\n                pred_n = pred_dict[\'np_normal\'][image_index].squeeze()\n                if \'_1\' in method[1]:\n                    pred_s = np.zeros(pred_dict[\'segmentation\'][image_index].shape)\n                    pred_p = np.zeros(pred_dict[\'plane\'][image_index].shape)\n                elif \'_2\' in method[1]:\n                    parameters = {\'distanceCostThreshold\': 0.1, \'smoothnessWeight\': 0.05, \'semantics\': True}\n                    pred_p, pred_s = fitPlanesNYU(gt_dict[\'image\'], gt_dict[\'depth\'][image_index].squeeze(), gt_dict[\'normal\'][image_index], gt_dict[\'semantics\'][image_index], gt_dict[\'info\'][image_index], numOutputPlanes=options.numOutputPlanes, parameters=parameters)\n                elif \'_3\' in method[1]:\n                    parameters = {\'distanceCostThreshold\': 0.1, \'smoothnessWeight\': 0.03, \'semantics\': True, \'distanceThreshold\': 0.05}\n                    pred_p, pred_s = fitPlanesNYU(gt_dict[\'image\'], pred_d, pred_n, pred_dict[\'semantics\'][image_index], gt_dict[\'info\'][image_index], numOutputPlanes=options.numOutputPlanes, parameters=parameters)\n                elif \'_4\' in method[1]:\n                    parameters = {\'numProposals\': 5, \'distanceCostThreshold\': 0.1, \'smoothnessWeight\': 30, \'dominantLineThreshold\': 3, \'offsetGap\': 0.1}\n                    pred_p, pred_s = fitPlanesManhattan(gt_dict[\'image\'][image_index], gt_dict[\'depth\'][image_index].squeeze(), gt_dict[\'normal\'][image_index], gt_dict[\'info\'][image_index], numOutputPlanes=options.numOutputPlanes, parameters=parameters)\n                    pred_d = np.zeros((HEIGHT, WIDTH))\n                elif \'_5\' in method[1]:\n                    parameters = {\'numProposals\': 5, \'distanceCostThreshold\': 0.1, \'smoothnessWeight\': 100, \'dominantLineThreshold\': 3, \'offsetGap\': 0.6}\n                    pred_p, pred_s = fitPlanesManhattan(gt_dict[\'image\'][image_index], pred_d, pred_n, gt_dict[\'info\'][image_index], numOutputPlanes=options.numOutputPlanes, parameters=parameters)\n                    pred_d = np.zeros((HEIGHT, WIDTH))\n                elif \'_6\' in method[1]:\n                    parameters = {\'distanceCostThreshold\': 0.1, \'smoothnessWeight\': 300, \'numProposals\': 5, \'normalWeight\': 1, \'meanshift\': 0.2}\n                    pred_p, pred_s = fitPlanesPiecewise(gt_dict[\'image\'][image_index], gt_dict[\'depth\'][image_index].squeeze(), gt_dict[\'normal\'][image_index], gt_dict[\'info\'][image_index], numOutputPlanes=options.numOutputPlanes, parameters=parameters)\n                    pred_d = np.zeros((HEIGHT, WIDTH))\n                elif \'_7\' in method[1]:\n                    parameters = {\'numProposals\': 5, \'distanceCostThreshold\': 0.1, \'smoothnessWeight\': 300, \'normalWeight\': 1, \'meanshift\': 0.2}\n                    pred_p, pred_s = fitPlanesPiecewise(gt_dict[\'image\'][image_index], pred_d, pred_n, gt_dict[\'info\'][image_index], numOutputPlanes=options.numOutputPlanes, parameters=parameters)\n                    pred_d = np.zeros((HEIGHT, WIDTH))\n                    pass\n                predPlanes.append(pred_p)\n                predSegmentations.append(pred_s)\n                predDepths.append(pred_d)\n                predNumPlanes.append(pred_p.shape[0])\n\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_d))\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(pred_s, blackIndex=pred_p.shape[0]))\n                #exit(1)\n                continue\n            new_pred_dict = {}\n            for key, value in pred_dict.iteritems():\n                new_pred_dict[key] = value\n                continue\n            new_pred_dict[\'plane\'] = np.array(predPlanes)\n            new_pred_dict[\'segmentation\'] = np.array(predSegmentations)\n            new_pred_dict[\'depth\'] = np.array(predDepths)\n            new_pred_dict[\'num_planes\'] = np.array(predNumPlanes)\n            if method_index < len(predictions):\n                predictions[method_index] = new_pred_dict\n            else:\n                predictions.append(new_pred_dict)\n                pass\n            #titles.append(\'pixelwise+semantics+RANSAC\')\n            pass\n\n        if method[1] == \'crfrnn\':\n            predSegmentations = []\n            predDepths = []\n\n            image_inp = tf.placeholder(tf.float32, shape=[1, HEIGHT, WIDTH, 3], name=\'image\')\n            segmentation_inp = tf.placeholder(tf.float32, shape=[1, HEIGHT, WIDTH, options.numOutputPlanes + 1], name=\'segmentation\')\n\n            refined_segmentation = CrfRnnLayer(image_dims=(HEIGHT, WIDTH), num_classes=21, theta_alpha=120., theta_beta=3., theta_gamma=3., num_iterations=10, name=\'crfrnn\')([segmentation_inp, image_inp])\n\n            config=tf.ConfigProto()\n            config.gpu_options.allow_growth=True\n            config.allow_soft_placement=True\n\n            init_op = tf.group(tf.global_variables_initializer(),\n                               tf.local_variables_initializer())\n            with tf.Session(config=config) as sess:\n                sess.run(init_op)\n                for image_index in xrange(options.numImages):\n                    #if image_index != 1:\n                    #continue\n                    print(\'crf rnn \' + str(image_index))\n                    allSegmentations = np.concatenate([pred_dict[\'segmentation\'][image_index], pred_dict[\'np_mask\'][image_index]], axis=2)\n                    img = gt_dict[\'image\'][image_index:image_index + 1].astype(np.float32) - 128\n\n\n                    pred_s = sess.run(refined_segmentation, feed_dict={segmentation_inp: np.expand_dims(allSegmentations, 0), image_inp: img})\n\n                    # print(pred_s.shape)\n                    # print(pred_s[0].max())\n                    # print(pred_s.sum(-1).max())\n                    # exit(1)\n                    pred_s = pred_s[0]\n                    # print(allSegmentations.max())\n                    # print(pred_s.max())\n                    # print(img.max())\n                    # print(img.min())\n                    # print(np.abs(pred_s - allSegmentations).max())\n                    # print(np.abs(np.argmax(pred_s, axis=-1) - np.argmax(allSegmentations, axis=-1)).max())\n                    pred_s = one_hot(np.argmax(pred_s, axis=-1), options.numOutputPlanes + 1)\n\n\n                    planeDepths = calcPlaneDepths(pred_dict[\'plane\'][image_index], WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n                    allDepths = np.concatenate([planeDepths, pred_dict[\'np_depth\'][image_index]], axis=2)\n                    pred_d = np.sum(allDepths * pred_s, axis=-1)\n\n                    predSegmentations.append(pred_s)\n                    predDepths.append(pred_d)\n\n                    cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_d))\n                    cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(pred_s, blackIndex=options.numOutputPlanes))\n\n                    continue\n                pass\n            new_pred_dict = {}\n            for key, value in pred_dict.iteritems():\n                new_pred_dict[key] = value\n                continue\n            segmentations = np.array(predSegmentations)\n            new_pred_dict[\'segmentation\'] = segmentations[:, :, :, :options.numOutputPlanes]\n            new_pred_dict[\'non_plane_mask\'] = segmentations[:, :, :, options.numOutputPlanes:options.numOutputPlanes + 1]\n            #new_pred_dict[\'non_plane_mask\'] = segmentations[:, :, :, :options.numOutputPlanes]\n            new_pred_dict[\'depth\'] = np.array(predDepths)\n            if method_index < len(predictions):\n                predictions[method_index] = new_pred_dict\n            else:\n                predictions.append(new_pred_dict)\n                pass\n            pass\n        if saving:\n            np.save(options.result_filename, {\'gt\': gt_dict, \'pred\': predictions})\n            pass\n        continue\n\n    #exit(1)\n\n    #print(results)\n\n    # depth = gt_dict[\'depth\'][4]\n    # cv2.imwrite(options.test_dir + \'/test_depth_gt.png\', drawDepthImage(depth))\n    # pred_p, pred_s, pred_d = fitPlanes(depth, getSUNCGCamera(), numPlanes=20, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=0.2)\n    # cv2.imwrite(options.test_dir + \'/test_depth.png\', drawDepthImage(pred_d))\n    # cv2.imwrite(options.test_dir + \'/test_segmentation.png\', drawSegmentationImage(pred_s))\n    # exit(1)\n\n\n    #plotResults(gt_dict, predictions, options)\n    if options.numImages > gt_dict[\'image\'].shape[0]:\n        plotAll(options)\n    else:\n        plotResults(gt_dict, predictions, options)\n        pass\n    writeHTML(options)\n    return\n\ndef plotAll(options):\n    result_filenames = glob.glob(options.test_dir + \'/results_*.npy\')\n    assert(len(result_filenames) > 0)\n    results = np.load(result_filenames[0])\n    results = results[()]\n    gt_dict = results[\'gt\']\n    predictions = results[\'pred\']\n\n    for index in xrange(1, len(result_filenames)):\n        other_results = np.load(result_filenames[index])\n        other_results = other_results[()]\n        other_gt_dict = other_results[\'gt\']\n        other_predictions = other_results[\'pred\']\n        for k, v in other_gt_dict.iteritems():\n            gt_dict[k] = np.concatenate([gt_dict[k], v], axis=0)\n            continue\n        for methodIndex, other_pred_dict in enumerate(other_predictions):\n            if methodIndex == 1:\n                continue\n            for k, v in other_pred_dict.iteritems():\n                print(methodIndex, k)\n                print(predictions[methodIndex][k].shape)\n                print(v.shape)\n                predictions[methodIndex][k] = np.concatenate([predictions[methodIndex][k], v], axis=0)\n                continue\n            continue\n        continue\n\n    plotResults(gt_dict, predictions, options)\n    return\n\n\ndef plotResults(gt_dict, predictions, options):\n    titles = options.titles\n\n    pixel_metric_curves = []\n    plane_metric_curves = []\n    for method_index, pred_dict in enumerate(predictions):\n        if titles[method_index] == \'pixelwise\':\n            continue\n        segmentations = pred_dict[\'segmentation\']\n        #if method_index == 0:\n        #segmentations = softmax(segmentations)\n        #pass\n        #pixel_curves, plane_curves = evaluatePlaneSegmentation(pred_dict[\'plane\'], segmentations, gt_dict[\'plane\'], gt_dict[\'segmentation\'], gt_dict[\'num_planes\'], numOutputPlanes = options.numOutputPlanes)\n\n        pixel_curves = np.zeros((6, 13))\n        plane_curves = np.zeros((6, 13, 3))\n        numImages = segmentations.shape[0]\n        for image_index in xrange(numImages):\n            gtDepths = calcPlaneDepths(gt_dict[\'plane\'][image_index], WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n            predDepths = calcPlaneDepths(pred_dict[\'plane\'][image_index], WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n            if \'num_planes\' in pred_dict:\n                predNumPlanes = pred_dict[\'num_planes\'][image_index]\n            else:\n                predNumPlanes = options.numOutputPlanes\n                pass\n\n            #if image_index != 2:\n            #continue\n\n            pixelStatistics, planeStatistics = evaluatePlanePrediction(predDepths, segmentations[image_index], predNumPlanes, gtDepths, gt_dict[\'segmentation\'][image_index], gt_dict[\'num_planes\'][image_index])\n\n            # for planeIndex in xrange(options.numOutputPlanes):\n            #     cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(gt_dict[\'segmentation\'][image_index][:, :, planeIndex]))\n            #     continue\n\n            # mask_1 = segmentations[image_index] == 8\n            # mask_2 = gt_dict[\'segmentation\'][image_index][:, :, 3]\n            # print(mask_1.sum())\n            # print(mask_2.sum())\n            # cv2.imwrite(\'test/mask_pred.png\', drawMaskImage(mask_1))\n            # cv2.imwrite(\'test/mask_gt.png\', drawMaskImage(mask_2))\n            # cv2.imwrite(\'test/mask_intersection.png\', drawMaskImage(mask_2 * mask_1 > 0.5))\n            # cv2.imwrite(\'test/mask_union.png\', drawMaskImage((mask_2 + mask_1) > 0.5))\n            # print((mask_2 * mask_1 > 0.5).sum())\n            # print(((mask_2 + mask_1) > 0.5).sum())\n            #print(image_index, planeStatistics[4][5])\n            #exit(1)\n            # print(pred_dict[\'plane\'][image_index])\n            # for planeIndex in xrange(options.numOutputPlanes):\n            #     print((segmentations[image_index] == planeIndex).sum())\n            #     continue\n            #exit(1)\n            pixel_curves += np.array(pixelStatistics)\n            plane_curves += np.array(planeStatistics)\n            continue\n\n\n        if len(pixel_metric_curves) == 0:\n            for metric_index, pixel_curve in enumerate(pixel_curves):\n                pixel_metric_curves.append([])\n                plane_metric_curves.append([])\n                continue\n            pass\n\n        for metric_index, pixel_curve in enumerate(pixel_curves):\n            pixel_metric_curves[metric_index].append(pixel_curve / numImages)\n            continue\n        for metric_index, plane_curve in enumerate(plane_curves):\n            #planeScore = plane_curve[:, 0] / plane_curve[:, 1]\n            plane_metric_curves[metric_index].append(plane_curve)\n            continue\n        continue\n\n\n    #np.save(options.test_dir + \'/pixel_curves.npy\', np.array(pixel_metric_curves))\n    #np.save(options.test_dir + \'/plane_curves.npy\', np.array(plane_metric_curves))\n\n\n    xs = []\n    xs.append((np.arange(13) * 0.1).tolist())\n    xs.append((np.arange(13) * 0.1).tolist())\n    xs.append((np.arange(13) * 0.1).tolist())\n    xs.append((np.arange(13) * 0.05).tolist())\n    xs.append((np.arange(13) * 0.05).tolist())\n    xs.append((np.arange(13) * 0.05).tolist())\n    xlabels = [\'IOU threshold\', \'IOU threshold\', \'IOU threshold\', \'depth threshold\', \'depth threshold\', \'depth threshold\']\n    curve_titles = [\'depth threshold 0.1\', \'depth threshold 0.2\', \'depth threshold 0.3\', \'IOU 0.3\', \'IOU 0.5\', \'IOU 0.7\']\n    curve_labels = [title for title in titles if title != \'pixelwise\']\n\n\n    # metric_index = 4\n    # filename = options.test_dir + \'/curves\'\n    # pixel_curves = pixel_metric_curves[metric_index]\n    # plane_curves = plane_metric_curves[metric_index]\n    # plane_curves = [plane_curve[:, 0] / plane_curve[:, 1] for plane_curve in plane_curves]\n    # plotCurvesSubplot(xs[metric_index], [plane_curves, pixel_curves], filenames = [filename + \'.png\', filename + \'_oracle.png\'], xlabel=xlabels[metric_index], ylabels=[\'Per-plane recall\', \'Per-pixel recall\'], labels=curve_labels)\n    # return\n\n    for metric_index, curves in enumerate(pixel_metric_curves):\n        if metric_index not in [4]:\n            continue\n        #filename = options.test_dir + \'/curve_pixel_\' + curve_titles[metric_index].replace(\' \', \'_\') + \'.png\'\n        #plotCurves(xs[metric_index], curves, filename = filename, xlabel=xlabels[metric_index], ylabel=\'pixel coverage\', title=curve_titles[metric_index], labels=curve_labels)\n\n        filename = options.test_dir + \'/curve_pixel_\' + curve_titles[metric_index].replace(\' \', \'_\').replace(\'.\', \'\')\n        plotCurvesSplit(xs[metric_index], curves, filenames = [filename + \'.png\', filename + \'_oracle.png\'], xlabel=xlabels[metric_index], ylabel=\'Per-pixel recall\', title=curve_titles[metric_index], labels=curve_labels)\n\n        #plotCurvesSubplot(xs[metric_index], curves, filename = filename + \'.png\', xlabel=xlabels[metric_index], ylabel=\'Per-pixel recall\', title=curve_titles[metric_index], labels=curve_labels)\n\n        continue\n    for metric_index, curves in enumerate(plane_metric_curves):\n        if metric_index not in [4]:\n            continue\n\n        curves = [curve[:, 0] / curve[:, 1] for curve in curves]\n\n        #filename = options.test_dir + \'/curve_plane_\' + curve_titles[metric_index].replace(\' \', \'_\') + \'.png\'\n        #plotCurves(xs[metric_index], curves, filename = filename, xlabel=xlabels[metric_index], ylabel=\'Per-plane recall\', title=curve_titles[metric_index], labels=curve_labels)\n\n        filename = options.test_dir + \'/curve_plane_\' + curve_titles[metric_index].replace(\' \', \'_\').replace(\'.\', \'\')\n        plotCurvesSplit(xs[metric_index], curves, filenames = [filename + \'.png\', filename + \'_oracle.png\'], xlabel=xlabels[metric_index], ylabel=\'Per-plane recall\', title=curve_titles[metric_index], labels=curve_labels)\n        continue\n\n\ndef gridSearch(options):\n    #writeHTML(options)\n    #exit(1)\n\n    if os.path.exists(options.result_filename):\n        results = np.load(options.result_filename)\n        results = results[()]\n    else:\n        assert(False)\n        pass\n\n    gt_dict = results[\'gt\']\n    predictions = results[\'pred\']\n\n    for key, value in gt_dict.iteritems():\n        if options.imageIndex >= 0:\n            gt_dict[key] = value[options.imageIndex:options.imageIndex + 1]\n        elif value.shape[0] > options.numImages:\n            gt_dict[key] = value[:options.numImages]\n            pass\n        continue\n    for pred_dict in predictions:\n        for key, value in pred_dict.iteritems():\n            if options.imageIndex >= 0:\n                pred_dict[key] = value[options.imageIndex:options.imageIndex + 1]\n            elif value.shape[0] > options.numImages:\n                pred_dict[key] = value[:options.numImages]\n                pass\n            continue\n        continue\n\n    #methods = [\'planenet\', \'pixelwise+RANSAC\', \'GT+RANSAC\']\n    titles = options.titles\n\n\n\n    for image_index in xrange(options.visualizeImages):\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_image.png\', gt_dict[\'image\'][image_index])\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_gt.png\', drawDepthImage(gt_dict[\'depth\'][image_index]))\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_normal_gt.png\', drawNormalImage(gt_dict[\'normal\'][image_index]))\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_gt.png\', drawSegmentationImage(np.concatenate([gt_dict[\'segmentation\'][image_index], 1 - np.expand_dims(gt_dict[\'plane_mask\'][image_index], -1)], axis=2), blackIndex=options.numOutputPlanes))\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_semantics_gt.png\', drawSegmentationImage(gt_dict[\'semantics\'][image_index], blackIndex=0))\n\n        plane_depths = calcPlaneDepths(gt_dict[\'plane\'][image_index], WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n        all_depths = np.concatenate([plane_depths, np.expand_dims(gt_dict[\'depth\'][image_index], -1)], axis=2)\n        depth = np.sum(all_depths * np.concatenate([gt_dict[\'segmentation\'][image_index], 1 - np.expand_dims(gt_dict[\'plane_mask\'][image_index], -1)], axis=2), axis=2)\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_gt_plane.png\', drawDepthImage(depth))\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_gt_diff.png\', drawMaskImage((depth - gt_dict[\'depth\'][image_index]) * 5 + 0.5))\n\n        for method_index, pred_dict in enumerate(predictions):\n            cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_dict[\'depth\'][image_index]))\n\n            if \'pixelwise\' in options.methods[method_index][1]:\n                continue\n            segmentation = pred_dict[\'segmentation\'][image_index]\n            segmentation = np.concatenate([segmentation, pred_dict[\'np_mask\'][image_index]], axis=2)\n            cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(segmentation, blackIndex=options.numOutputPlanes))\n            continue\n        continue\n\n\n    #post processing\n    for method_index, method in enumerate(options.methods):\n        if len(method) == 3:\n            pred_dict = predictions[method[2]]\n        else:\n            pred_dict = predictions[method_index]\n            pass\n\n        if \'pixelwise_2\' in method[1] or \'pixelwise_3\' in method[1]:\n            bestScore = 0\n            configurationIndex = 0\n            for distanceCostThreshold in [0.3]:\n                for smoothnessWeight in [0.01, 0.03, 0.05]:\n                    for distanceThreshold in [0.2]:\n                        parameters = {\'distanceCostThreshold\': distanceCostThreshold, \'smoothnessWeight\': smoothnessWeight, \'distanceThreshold\': distanceThreshold, \'semantics\': True}\n                        score = 0\n                        for image_index in xrange(options.numImages):\n                            #cv2.imwrite(\'test/normal.png\', drawNormalImage(gt_dict[\'normal\'][image_index]))\n                            if \'_2\' in method[1]:\n                                pred_p, pred_s = fitPlanesNYU(gt_dict[\'image\'][image_index], gt_dict[\'depth\'][image_index].squeeze(), gt_dict[\'normal\'][image_index], gt_dict[\'semantics\'][image_index], gt_dict[\'info\'][image_index], numOutputPlanes=options.numOutputPlanes, parameters=parameters)\n                            else:\n                                pred_d = pred_dict[\'np_depth\'][image_index].squeeze()\n                                pred_n = pred_dict[\'np_normal\'][image_index].squeeze()\n                                pred_p, pred_s = fitPlanesNYU(gt_dict[\'image\'][image_index], pred_d, pred_n, pred_dict[\'semantics\'][image_index], gt_dict[\'info\'][image_index], numOutputPlanes=options.numOutputPlanes, parameters=parameters)\n                                pass\n\n                            predNumPlanes = pred_p.shape[0]\n                            gtDepths = calcPlaneDepths(gt_dict[\'plane\'][image_index], WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n                            planeDepths = calcPlaneDepths(pred_p, WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n                            pixelStatistics, planeStatistics = evaluatePlanePrediction(planeDepths, pred_s, predNumPlanes, gtDepths, gt_dict[\'segmentation\'][image_index], gt_dict[\'num_planes\'][image_index])\n                            #print(pixelStatistics)\n                            #exit(1)\n                            #planeStatistics = np.array(planeStatistics)[1]\n                            #accuracy = (planeStatistics[3:8, 0].astype(np.float32) / np.maximum(planeStatistics[3:8, 1], 1e-4)).mean()\n\n                            pixelStatistics = np.array(pixelStatistics)[1]\n                            accuracy = pixelStatistics[3:8].mean()\n                            score += accuracy\n\n                            #cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_d))\n                            cv2.imwrite(\'test/segmentation_pred_\' + str(image_index) + \'.png\', drawSegmentationImage(pred_s, blackIndex=options.numOutputPlanes))\n                            #exit(1)\n                            continue\n                        score /= options.numImages\n                        print(score, parameters)\n                        configurationIndex += 1\n                        #exit(1)\n                        if score > bestScore:\n                            bestScore = score\n                            bestParameters = parameters\n                            pass\n                        continue\n                    continue\n                continue\n            print(bestScore)\n            print(bestParameters)\n            exit(1)\n\n        if \'pixelwise_4\' in method[1] or \'pixelwise_5\' in method[1]:\n            bestScore = 0\n            configurationIndex = 0\n            for distanceCostThreshold in [0.05]:\n                for smoothnessWeight in [30]:\n                    for offsetGap in [-0.1]:\n                        parameters = {\'distanceCostThreshold\': distanceCostThreshold, \'smoothnessWeight\': smoothnessWeight, \'offsetGap\': abs(offsetGap), \'meanshift\': offsetGap}\n\n                        score = 0\n                        for image_index in xrange(options.numImages):\n                            if \'_4\' in method[1]:\n                                pred_p, pred_s = fitPlanesManhattan(gt_dict[\'image\'][image_index], gt_dict[\'depth\'][image_index].squeeze(), gt_dict[\'normal\'][image_index], gt_dict[\'info\'][image_index], numOutputPlanes=options.numOutputPlanes, parameters=parameters)\n                            else:\n                                pred_d = pred_dict[\'np_depth\'][image_index].squeeze()\n                                pred_n = pred_dict[\'np_normal\'][image_index].squeeze()\n                                pred_p, pred_s = fitPlanesManhattan(gt_dict[\'image\'][image_index], pred_d, pred_n, gt_dict[\'info\'][image_index], numOutputPlanes=options.numOutputPlanes, parameters=parameters)\n                                pass\n\n                            predNumPlanes = pred_p.shape[0]\n                            gtDepths = calcPlaneDepths(gt_dict[\'plane\'][image_index], WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n                            planeDepths = calcPlaneDepths(pred_p, WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n                            pixelStatistics, planeStatistics = evaluatePlanePrediction(planeDepths, pred_s, predNumPlanes, gtDepths, gt_dict[\'segmentation\'][image_index], gt_dict[\'num_planes\'][image_index])\n                            #print(pixelStatistics)\n                            #exit(1)\n                            #planeStatistics = np.array(planeStatistics)[1]\n                            #accuracy = (planeStatistics[3:8, 0].astype(np.float32) / np.maximum(planeStatistics[3:8, 1], 1e-4)).mean()\n\n                            pixelStatistics = np.array(pixelStatistics)[1]\n                            accuracy = pixelStatistics[3:8].mean()\n                            score += accuracy\n\n                            #cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_d))\n                            #cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(pred_s, blackIndex=options.numOutputPlanes))\n                            #exit(1)\n                            continue\n                        score /= options.numImages\n                        print(score, parameters)\n                        configurationIndex += 1\n                        #exit(1)\n                        if score > bestScore:\n                            bestScore = score\n                            bestParameters = parameters\n                            pass\n                        continue\n                    continue\n                continue\n            print(bestScore)\n            print(bestParameters)\n            exit(1)\n\n        if \'pixelwise_6\' in method[1] or \'pixelwise_7\' in method[1]:\n            bestScore = 0\n            configurationIndex = 0\n            for distanceCostThreshold in [0.1]:\n                for smoothnessWeight in [300]:\n                    for normalWeight in [1]:\n                        for offset in [0.2]:\n                            parameters = {\'distanceCostThreshold\': distanceCostThreshold, \'smoothnessWeight\': smoothnessWeight, \'numProposals\': 5, \'normalWeight\': normalWeight, \'offsetGap\': abs(offset), \'meanshift\': offset}\n\n                            score = 0\n                            for image_index in xrange(options.numImages):\n                                if \'_6\' in method[1]:\n                                    pred_p, pred_s = fitPlanesPiecewise(gt_dict[\'image\'][image_index], gt_dict[\'depth\'][image_index].squeeze(), gt_dict[\'normal\'][image_index], gt_dict[\'info\'][image_index], numOutputPlanes=options.numOutputPlanes, parameters=parameters)\n                                else:\n                                    pred_d = pred_dict[\'np_depth\'][image_index].squeeze()\n                                    pred_n = pred_dict[\'np_normal\'][image_index].squeeze()\n                                    pred_p, pred_s = fitPlanesPiecewise(gt_dict[\'image\'][image_index], pred_d, pred_n, gt_dict[\'info\'][image_index], numOutputPlanes=options.numOutputPlanes, parameters=parameters)\n                                    pass\n\n                                predNumPlanes = pred_p.shape[0]\n                                gtDepths = calcPlaneDepths(gt_dict[\'plane\'][image_index], WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n                                planeDepths = calcPlaneDepths(pred_p, WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n                                pixelStatistics, planeStatistics = evaluatePlanePrediction(planeDepths, pred_s, predNumPlanes, gtDepths, gt_dict[\'segmentation\'][image_index], gt_dict[\'num_planes\'][image_index])\n                                #print(pixelStatistics)\n                                #exit(1)\n                                #planeStatistics = np.array(planeStatistics)[1]\n                                #accuracy = (planeStatistics[3:8, 0].astype(np.float32) / np.maximum(planeStatistics[3:8, 1], 1e-4)).mean()\n\n                                pixelStatistics = np.array(pixelStatistics)[1]\n                                accuracy = pixelStatistics[3:8].mean()\n                                score += accuracy\n\n                                #cv2.imwrite(\'test/depth_pred_\' + str(configurationIndex) + \'.png\', drawDepthImage(pred_d))\n                                cv2.imwrite(\'test/segmentation_pred_\' + str(image_index) + \'.png\', drawSegmentationImage(pred_s, blackIndex=options.numOutputPlanes))\n                                #exit(1)\n                                continue\n                            score /= options.numImages\n                            print(score, parameters)\n                            configurationIndex += 1\n\n                            #exit(1)\n                            if score > bestScore:\n                                bestScore = score\n                                bestParameters = parameters\n                                pass\n                            continue\n                        continue\n                    continue\n                continue\n            print(bestScore)\n            print(bestParameters)\n            exit(1)\n\n        if method[1] == \'crfrnn\':\n\n            parameterConfigurations = []\n            for alpha in [15]:\n                for beta in [10]:\n                    for gamma in [3]:\n                        parameterConfigurations.append((alpha, beta, gamma))\n                        continue\n                    continue\n                continue\n            print(parameterConfigurations)\n\n            bestScore = 0\n            for parameters in parameterConfigurations:\n                tf.reset_default_graph()\n                image_inp = tf.placeholder(tf.float32, shape=[1, HEIGHT, WIDTH, 3], name=\'image\')\n                segmentation_inp = tf.placeholder(tf.float32, shape=[1, HEIGHT, WIDTH, options.numOutputPlanes + 1], name=\'segmentation\')\n\n                refined_segmentation = CrfRnnLayer(image_dims=(HEIGHT, WIDTH), num_classes=21, theta_alpha=parameters[0], theta_beta=parameters[1], theta_gamma=parameters[2], num_iterations=10, name=\'crfrnn\')([segmentation_inp, image_inp])\n\n                config=tf.ConfigProto()\n                config.gpu_options.allow_growth=True\n                config.allow_soft_placement=True\n\n                init_op = tf.group(tf.global_variables_initializer(),\n                                   tf.local_variables_initializer())\n                with tf.Session(config=config) as sess:\n                    sess.run(init_op)\n\n                    score = 0.\n                    for image_index in xrange(options.numImages):\n                        #if image_index != 1:\n                        #continue\n                        print(\'crf as rnn\', image_index)\n                        allSegmentations = np.concatenate([pred_dict[\'segmentation\'][image_index], pred_dict[\'np_mask\'][image_index]], axis=2)\n                        img = gt_dict[\'image\'][image_index:image_index + 1].astype(np.float32) - 128\n\n                        pred_s = sess.run(refined_segmentation, feed_dict={segmentation_inp: np.expand_dims(allSegmentations, 0), image_inp: img})\n                        pred_s = pred_s[0]\n\n                        #pred_s = allSegmentations\n\n                        pred_s = one_hot(np.argmax(pred_s, axis=-1), options.numOutputPlanes + 1)\n\n\n                        planeDepths = calcPlaneDepths(pred_dict[\'plane\'][image_index], WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n                        allDepths = np.concatenate([planeDepths, pred_dict[\'np_depth\'][image_index]], axis=2)\n                        pred_d = np.sum(allDepths * pred_s, axis=-1)\n\n\n                        # for planeIndex in xrange(options.numOutputPlanes):\n                        #     cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(pred_s[:, :, planeIndex]))\n                        #     cv2.imwrite(\'test/gt_mask_\' + str(planeIndex) + \'.png\', drawMaskImage(gt_dict[\'segmentation\'][image_index][:, :, planeIndex]))\n                        #     continue\n                        # cv2.imwrite(\'test/depth_pred.png\', drawDepthImage(pred_d))\n                        # cv2.imwrite(\'test/depth_gt.png\', drawDepthImage(gt_dict[\'depth\'][image_index]))\n                        # cv2.imwrite(\'test/depth_diff.png\', drawMaskImage(np.abs(pred_d - gt_dict[\'depth\'][image_index]) * 5))\n                        # exit(1)\n                        predNumPlanes = options.numOutputPlanes\n                        gtDepths = calcPlaneDepths(gt_dict[\'plane\'][image_index], WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n                        pixelStatistics, planeStatistics = evaluatePlanePrediction(planeDepths, pred_s[:, :, :options.numOutputPlanes], predNumPlanes, gtDepths, gt_dict[\'segmentation\'][image_index], gt_dict[\'num_planes\'][image_index])\n                        #print(pixelStatistics)\n                        #exit(1)\n                        #planeStatistics = np.array(planeStatistics)[1]\n                        #accuracy = (planeStatistics[3:8, 0].astype(np.float32) / np.maximum(planeStatistics[3:8, 1], 1e-4)).mean()\n                        pixelStatistics = np.array(pixelStatistics)[1]\n                        # print(pixelStatistics)\n                        # pixelStatistics[3:8].mean()\n                        # exit(1)\n                        accuracy = pixelStatistics[3:8].mean()\n                        score += accuracy\n\n                        #cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_d))\n                        #cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(pred_s, blackIndex=options.numOutputPlanes))\n                        #exit(1)\n                        continue\n                    score /= options.numImages\n                    print(score, parameters)\n                    #exit(1)\n                    if score > bestScore:\n                        bestScore = score\n                        bestParameters = parameters\n                        pass\n                    pass\n                continue\n            print(bestScore, bestParameters)\n            pass\n        continue\n    return\n\n\ndef evaluateDepthPrediction(options):\n\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n\n    if options.useCache == 1 and os.path.exists(options.result_filename):\n        results = np.load(options.result_filename)\n        results = results[()]\n    else:\n        results = getResults(options)\n        if options.useCache != -2:\n            np.save(options.result_filename, results)\n            pass\n        pass\n\n    gt_dict = results[\'gt\']\n    predictions = results[\'pred\']\n\n    for key, value in gt_dict.iteritems():\n        if options.imageIndex >= 0:\n            gt_dict[key] = value[options.imageIndex:options.imageIndex + 1]\n        elif value.shape[0] > options.numImages:\n            gt_dict[key] = value[:options.numImages]\n            pass\n        continue\n    for pred_dict in predictions:\n        for key, value in pred_dict.iteritems():\n            if options.imageIndex >= 0:\n                pred_dict[key] = value[options.imageIndex:options.imageIndex + 1]\n            elif value.shape[0] > options.numImages:\n                pred_dict[key] = value[:options.numImages]\n                pass\n            continue\n        continue\n\n    titles = options.titles\n\n\n    for image_index in xrange(options.visualizeImages):\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_image.png\', gt_dict[\'image\'][image_index])\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_gt.png\', drawDepthImage(gt_dict[\'depth\'][image_index]))\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_gt.png\', drawSegmentationImage(np.concatenate([gt_dict[\'segmentation\'][image_index], 1 - np.expand_dims(gt_dict[\'plane_mask\'][image_index], -1)], axis=2), blackIndex=options.numOutputPlanes))\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_semantics_gt.png\', drawSegmentationImage(gt_dict[\'semantics\'][image_index], blackIndex=0))\n\n\n        # plane_depths = calcPlaneDepths(gt_dict[\'plane\'][image_index], WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n        # all_depths = np.concatenate([plane_depths, np.expand_dims(gt_dict[\'depth\'][image_index], -1)], axis=2)\n        # depth = np.sum(all_depths * np.concatenate([gt_dict[\'segmentation\'][image_index], 1 - np.expand_dims(gt_dict[\'plane_mask\'][image_index], -1)], axis=2), axis=2)\n        # cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_gt_plane.png\', drawDepthImage(depth))\n\n        for method_index, pred_dict in enumerate(predictions):\n            cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_dict[\'depth\'][image_index]))\n\n            if titles[method_index] == \'pixelwise\':\n                continue\n            segmentation = pred_dict[\'segmentation\'][image_index]\n            segmentation = np.concatenate([segmentation, pred_dict[\'np_mask\'][image_index]], axis=2)\n            cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(segmentation, blackIndex=options.numOutputPlanes))\n            continue\n        continue\n\n\n    #post processing\n    for method_index, method in enumerate(options.methods):\n        if method[1] == \'graphcut\':\n            pred_dict = gt_dict\n            predSegmentations = []\n            predDepths = []\n            for image_index in xrange(options.numImages):\n                #if image_index != 3:\n                #continue\n                print(\'graph cut \' + str(image_index))\n\n                segmentation = np.argmax(np.concatenate([pred_dict[\'segmentation\'][image_index], 1 - np.expand_dims(pred_dict[\'plane_mask\'][image_index], -1)], axis=2), axis=2)\n                #pred_s = getSegmentationsGraphCut(pred_dict[\'plane\'][image_index], gt_dict[\'image\'][image_index], pred_dict[\'depth\'][image_index], pred_dict[\'normal\'][image_index], segmentation, pred_dict[\'semantics\'][image_index], pred_dict[\'info\'][image_index], gt_dict[\'num_planes\'][image_index])\n\n                pred_p, pred_s, numPlanes = removeSmallSegments(pred_dict[\'plane\'][image_index], gt_dict[\'image\'][image_index], pred_dict[\'depth\'][image_index], pred_dict[\'normal\'][image_index], segmentation, pred_dict[\'semantics\'][image_index], pred_dict[\'info\'][image_index], gt_dict[\'num_planes\'][image_index])\n                #pred_p, pred_s, numPlanes = pred_dict[\'plane\'][image_index], segmentation, gt_dict[\'num_planes\'][image_index]\n                print((gt_dict[\'num_planes\'][image_index], numPlanes))\n                planeDepths = calcPlaneDepths(pred_p, WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n                allDepths = np.concatenate([planeDepths, np.expand_dims(pred_dict[\'depth\'][image_index], -1)], axis=2)\n                pred_d = allDepths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), pred_s.reshape(-1)].reshape(HEIGHT, WIDTH)\n\n                predSegmentations.append(pred_s)\n                predDepths.append(pred_d)\n\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_d))\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(pred_s, blackIndex=options.numOutputPlanes))\n                continue\n            new_pred_dict = {}\n            for key, value in pred_dict.iteritems():\n                new_pred_dict[key] = value\n                continue\n            new_pred_dict[\'segmentation\'] = np.array(predSegmentations)\n            predictions[method_index] = new_pred_dict\n        if method[1] == \'crf_tf\':\n            pred_dict = predictions[method_index]\n            predSegmentations = []\n            predDepths = []\n\n            image_inp = tf.placeholder(tf.float32, shape=[1, HEIGHT, WIDTH, 3], name=\'image\')\n            segmentation_inp = tf.placeholder(tf.float32, shape=[1, HEIGHT, WIDTH, options.numOutputPlanes + 1], name=\'segmentation\')\n            plane_inp = tf.placeholder(tf.float32, shape=[1, options.numOutputPlanes, 3], name=\'plane\')\n            non_plane_depth_inp = tf.placeholder(tf.float32, shape=[1, HEIGHT, WIDTH, 1], name=\'non_plane_depth\')\n            info_inp = tf.placeholder(tf.float32, shape=[20], name=\'info\')\n\n\n            plane_parameters = tf.reshape(plane_inp, (-1, 3))\n            plane_depths = planeDepthsModule(plane_parameters, WIDTH, HEIGHT, info_inp)\n            plane_depths = tf.transpose(tf.reshape(plane_depths, [HEIGHT, WIDTH, -1, options.numOutputPlanes]), [2, 0, 1, 3])\n            all_depths = tf.concat([plane_depths, non_plane_depth_inp], axis=3)\n\n            planesY = plane_inp[:, :, 1]\n            planesD = tf.maximum(tf.norm(plane_inp, axis=-1), 1e-4)\n            planesY /= planesD\n            planesY = tf.concat([planesY, tf.ones((1, 1))], axis=1)\n\n            #refined_segmentation = crfModule(segmentation_inp, plane_inp, non_plane_depth_inp, info_inp, numOutputPlanes = options.numOutputPlanes, numIterations=5)\n\n            imageDiff = calcImageDiff(image_inp)\n            #refined_segmentation, debug_dict = segmentationRefinementModule(segmentation_inp, all_depths, planesY, imageDiff, numOutputPlanes = options.numOutputPlanes + 1, numIterations=5)\n            refined_segmentation, debug_dict = meanfieldModule(segmentation_inp, all_depths, planesY, imageDiff, numOutputPlanes = options.numOutputPlanes + 1, maxDepthDiff=0.2, varDepthDiff=pow(0.2, 2))\n\n            config=tf.ConfigProto()\n            config.gpu_options.allow_growth=True\n            config.allow_soft_placement=True\n\n            init_op = tf.group(tf.global_variables_initializer(),\n                               tf.local_variables_initializer())\n            with tf.Session(config=config) as sess:\n                sess.run(init_op)\n                for image_index in xrange(options.numImages):\n                    #if image_index != 1:\n                    #continue\n                    print(\'crf tf \' + str(image_index))\n                    allSegmentations = np.concatenate([pred_dict[\'segmentation\'][image_index], pred_dict[\'np_mask\'][image_index]], axis=2)\n                    allSegmentations = softmax(allSegmentations)\n                    pred_s, debug = sess.run([refined_segmentation, debug_dict], feed_dict={segmentation_inp: np.expand_dims(allSegmentations, 0), plane_inp: np.expand_dims(pred_dict[\'plane\'][image_index], 0), non_plane_depth_inp: np.expand_dims(pred_dict[\'np_depth\'][image_index], 0), info_inp: gt_dict[\'info\'][image_index], image_inp: gt_dict[\'image\'][image_index:image_index + 1]})\n\n                    pred_s = pred_s[0]\n                    planeDepths = calcPlaneDepths(pred_dict[\'plane\'][image_index], WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n                    allDepths = np.concatenate([planeDepths, pred_dict[\'np_depth\'][image_index]], axis=2)\n                    pred_d = np.sum(allDepths * pred_s, axis=-1)\n\n                    predSegmentations.append(pred_s)\n                    predDepths.append(pred_d)\n\n                    cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_d))\n                    cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(pred_s, blackIndex=options.numOutputPlanes))\n\n                    if \'diff\' in debug:\n                        segmentation = np.argmax(allSegmentations, axis=-1)\n                        for planeIndex in xrange(options.numOutputPlanes + 1):\n                            cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(allSegmentations[:, :, planeIndex]))\n                            continue\n\n                        for planeIndex in xrange(debug[\'diff\'].shape[-1]):\n                            cv2.imwrite(\'test/cost_mask_\' + str(planeIndex) + \'.png\', drawMaskImage(debug[\'diff\'][0, :, :, planeIndex] / 2))\n                            continue\n                        exit(1)\n                        pass\n                    continue\n                pass\n            new_pred_dict = {}\n            for key, value in pred_dict.iteritems():\n                new_pred_dict[key] = value\n                continue\n            segmentations = np.array(predSegmentations)\n            new_pred_dict[\'segmentation\'] = segmentations[:, :, :, :options.numOutputPlanes]\n            new_pred_dict[\'non_plane_mask\'] = segmentations[:, :, :, options.numOutputPlanes:options.numOutputPlanes + 1]\n            #new_pred_dict[\'non_plane_mask\'] = segmentations[:, :, :, :options.numOutputPlanes]\n            new_pred_dict[\'depth\'] = np.array(predDepths)\n            predictions[method_index] = new_pred_dict\n            pass\n\n        if method[1] == \'crf\':\n            pred_dict = predictions[method_index]\n            predSegmentations = []\n            predDepths = []\n            for image_index in xrange(options.numImages):\n                print(\'crf \' + str(image_index))\n                boundaries = pred_dict[\'boundary\'][image_index]\n                boundaries = sigmoid(boundaries)\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_boundary.png\', drawMaskImage(np.concatenate([boundaries, np.zeros((HEIGHT, WIDTH, 1))], axis=2)))\n\n                allSegmentations = np.concatenate([pred_dict[\'segmentation\'][image_index], pred_dict[\'np_mask\'][image_index]], axis=2)\n                allSegmentations = softmax(allSegmentations)\n                planeDepths = calcPlaneDepths(pred_dict[\'plane\'][image_index], WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n                allDepths = np.concatenate([planeDepths, pred_dict[\'np_depth\'][image_index]], axis=2)\n                #boundaries = np.concatenate([np.ones((allSegmentations.shape[0], allSegmentations.shape[1], 1)), -np.ones((allSegmentations.shape[0], allSegmentations.shape[1], 1))], axis=2)\n                #if options.imageIndex >= 0:\n                #boundaries = cv2.imread(options.test_dir + \'/\' + str(options.imageIndex) + \'_boundary.png\')\n                #else:\n                #boundaries = cv2.imread(options.test_dir + \'/\' + str(image_index) + \'_boundary.png\')\n                #pass\n                #boundaries = (boundaries > 128).astype(np.float32)[:, :, :2]\n\n                allDepths[:, :, options.numOutputPlanes] = 0\n                pred_s = refineSegmentation(gt_dict[\'image\'][image_index], allSegmentations, allDepths, boundaries, numOutputPlanes = options.numOutputPlanes, numIterations=20, numProposals=5)\n                pred_d = allDepths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), pred_s.reshape(-1)].reshape(HEIGHT, WIDTH)\n\n                predSegmentations.append(pred_s)\n                predDepths.append(pred_d)\n\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_d))\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(pred_s, blackIndex=options.numOutputPlanes))\n\n                #segmentation = np.argmax(allSegmentations, axis=-1)\n                for planeIndex in xrange(options.numOutputPlanes + 1):\n                    cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(allSegmentations[:, :, planeIndex]))\n                    continue\n                #cv2.imwrite(options.test_dir + \'/mask_\' + str(21) + \'.png\', drawDepthImage(pred_dict[\'np_depth\'][0]))\n                #for plane_index in xrange(options.numOutputPlanes + 1):\n                #cv2.imwrite(options.test_dir + \'/mask_\' + str(plane_index) + \'.png\', drawMaskImage(pred_s == plane_index))\n                #continue\n                #exit(1)\n                continue\n\n            new_pred_dict = {}\n            for key, value in pred_dict.iteritems():\n                new_pred_dict[key] = value\n                continue\n            new_pred_dict[\'segmentation\'] = np.array(predSegmentations)\n            new_pred_dict[\'depth\'] = np.array(predDepths)\n            predictions[method_index] = new_pred_dict\n            pass\n\n\n        if \'pixelwise\' in method[1]:\n            pred_dict = predictions[method_index]\n            predPlanes = []\n            predSegmentations = []\n            predDepths = []\n            for image_index in xrange(options.numImages):\n                pred_d = pred_dict[\'np_depth\'][image_index].squeeze()\n                if \'_1\' in method[1]:\n                    pred_s = np.zeros(pred_dict[\'segmentation\'][image_index].shape)\n                    pred_p = np.zeros(pred_dict[\'plane\'][image_index].shape)\n                elif \'_2\' in methods[1]:\n                    pred_p, pred_s, pred_d = fitPlanes(pred_d, gt_dict[\'info\'][image_index], numPlanes=options.numOutputPlanes, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=0.2)\n                elif \'_3\' in methods[1]:\n                    pred_p, pred_s, pred_d = fitPlanes(pred_d, gt_dict[\'info\'][image_index], numPlanes=options.numOutputPlanes, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=0.2)\n                elif \'_4\' in methods[1]:\n                    pred_p, pred_s, pred_d = fitPlanesSegmentation(pred_d, pred_dict[\'semantics\'][image_index], gt_dict[\'info\'][image_index], numPlanes=options.numOutputPlanes, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=0.2)\n                    pass\n                predPlanes.append(pred_p)\n                predSegmentations.append(pred_s)\n                predDepths.append(pred_d)\n\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_d))\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(pred_s))\n                continue\n            new_pred_dict = {}\n            for key, value in pred_dict.iteritems():\n                new_pred_dict[key] = value\n                continue\n            new_pred_dict[\'plane\'] = np.array(predPlanes)\n            new_pred_dict[\'segmentation\'] = np.array(predSegmentations)\n            new_pred_dict[\'depth\'] = np.array(predDepths)\n            predictions[method_index] = new_pred_dict\n            #titles.append(\'pixelwise+semantics+RANSAC\')\n            pass\n        continue\n\n\n\n    for method_index, pred_dict in enumerate(predictions):\n        print(titles[method_index])\n        evaluateDepths(pred_dict[\'depth\'], gt_dict[\'depth\'], np.ones(gt_dict[\'depth\'].shape))\n        continue\n    return\n\ndef getResults(options):\n    checkpoint_prefix = options.rootFolder + \'/checkpoint/\'\n\n    methods = options.methods\n    predictions = []\n\n    if os.path.exists(options.result_filename):\n        if options.useCache == 1:\n            results = np.load(options.result_filename)\n            results = results[()]\n            return results\n        elif options.useCache == 2:\n            results = np.load(options.result_filename)\n            results = results[()]\n            gt_dict = results[\'gt\']\n            predictions = results[\'pred\']\n        else:\n            gt_dict = getGroundTruth(options)\n            pass\n    else:\n        gt_dict = getGroundTruth(options)\n        pass\n\n\n\n    for method_index, method in enumerate(methods):\n        if len(method) < 4 or method[3] < 2:\n            continue\n        if method[0] == \'\':\n            continue\n\n\n        method_options = copy.deepcopy(options)\n        if \'ds0\' not in method[0]:\n            method_options.deepSupervisionLayers = [\'res4b22_relu\', ]\n        else:\n            method_options.deepSupervisionLayers = []\n            pass\n        method_options.predictConfidence = 0\n        method_options.predictLocal = 0\n        method_options.predictPixelwise = 1\n        method_options.predictBoundary = int(\'pb\' in method[0])\n        method_options.anchorPlanes = 0\n        if \'ps\' in method[0]:\n            method_options.predictSemantics = 1\n        else:\n            method_options.predictSemantics = 0\n            pass\n        if \'crfrnn\' in method[0]:\n            method_options.crfrnn = 10\n        else:\n            method_options.crfrnn = 0\n            pass\n        if \'ap1\' in method[0]:\n            method_options.anchorPlanes = 1\n            pass\n\n        method_options.numOutputPlanes = 20\n        if \'np10\' in method[0]:\n            method_options.numOutputPlanes = 10\n        elif \'np15\' in method[0]:\n            method_options.numOutputPlanes = 15\n            pass\n\n\n        method_options.checkpoint_dir = checkpoint_prefix + method[0]\n        print(method_options.checkpoint_dir)\n\n        method_options.suffix = method[1]\n\n        method_names = [previous_method[0] for previous_method in methods[:method_index]]\n\n        if method[0] in method_names:\n            pred_dict = predictions[method_names.index(method[0])]\n        elif method[0] == \'gt\':\n            pred_dict = gt_dict\n        else:\n            pred_dict = getPrediction(method_options)\n            pass\n\n        # for image_index in xrange(options.visualizeImages):\n        #     cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_dict[\'depth\'][image_index]))\n        #     cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage())\n        #     continue\n\n        if len(method) >= 4 and method[3] == 3:\n            predictions.insert(0, pred_dict)\n        else:\n            if method_index < len(predictions):\n                predictions[method_index] = pred_dict\n            else:\n                predictions.append(pred_dict)\n                pass\n            pass\n        continue\n    #np.save(options.test_dir + \'/curves.npy\', curves)\n    results = {\'gt\': gt_dict, \'pred\': predictions}\n\n    if options.useCache != -1:\n        np.save(options.result_filename, results)\n        pass\n    pass\n\n    return results\n\ndef getPrediction(options):\n    tf.reset_default_graph()\n\n    options.batchSize = 1\n    min_after_dequeue = 1000\n\n    reader = RecordReaderAll()\n    if options.dataset == \'SUNCG\':\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_SUNCG_val.tfrecords\'], num_epochs=10000)\n    elif options.dataset == \'NYU_RGBD\':\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_nyu_rgbd_val.tfrecords\'], num_epochs=1)\n        options.deepSupervision = 0\n        options.predictLocal = 0\n    elif options.dataset == \'matterport\':\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_matterport_val.tfrecords\'], num_epochs=1)\n    else:\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/Data/PlaneNet/planes_scannet_val.tfrecords\'], num_epochs=1)\n        pass\n\n    img_inp, global_gt_dict, local_gt_dict = reader.getBatch(filename_queue, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True, random=False)\n\n\n\n    training_flag = tf.constant(False, tf.bool)\n\n    options.gpu_id = 0\n    if \'sample\' not in options.checkpoint_dir:\n        global_pred_dict, _, _ = build_graph(img_inp, img_inp, training_flag, options)\n    else:\n        global_pred_dict, _, _ = build_graph_sample(img_inp, img_inp, training_flag, options)\n        pass\n\n    var_to_restore = tf.global_variables()\n\n\n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n\n    pred_dict = {}\n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n        #var_to_restore = [v for v in var_to_restore if \'res4b22_relu_non_plane\' not in v.name]\n        loader = tf.train.Saver(var_to_restore)\n        loader.restore(sess, ""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n        #loader.restore(sess, options.fineTuningCheckpoint)\n\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n\n        try:\n            predDepths = []\n            predPlanes = []\n            predSegmentations = []\n            predSemantics = []\n            predNonPlaneDepths = []\n            predNonPlaneNormals = []\n            predNonPlaneMasks = []\n            predBoundaries = []\n            for index in xrange(options.startIndex + options.numImages):\n                if index % 10 == 0:\n                    print((\'image\', index))\n                    pass\n                t0=time.time()\n\n                img, global_gt, global_pred = sess.run([img_inp, global_gt_dict, global_pred_dict])\n\n                if index < options.startIndex:\n                    continue\n\n\n                pred_p = global_pred[\'plane\'][0]\n                pred_s = global_pred[\'segmentation\'][0]\n\n                pred_np_m = global_pred[\'non_plane_mask\'][0]\n                pred_np_d = global_pred[\'non_plane_depth\'][0]\n                pred_np_n = global_pred[\'non_plane_normal\'][0]\n\n                if global_gt[\'info\'][0][19] > 1 and global_gt[\'info\'][0][19] < 4 and False:\n                    pred_np_n = calcNormal(pred_np_d.squeeze(), global_gt[\'info\'][0])\n                    pass\n\n\n                pred_b = global_pred[\'boundary\'][0]\n                predNonPlaneMasks.append(pred_np_m)\n                predNonPlaneDepths.append(pred_np_d)\n                predNonPlaneNormals.append(pred_np_n)\n                predBoundaries.append(pred_b)\n\n                all_segmentations = np.concatenate([pred_s, pred_np_m], axis=2)\n                plane_depths = calcPlaneDepths(pred_p, WIDTH, HEIGHT, global_gt[\'info\'][0])\n                all_depths = np.concatenate([plane_depths, pred_np_d], axis=2)\n\n                segmentation = np.argmax(all_segmentations, 2)\n                pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape(HEIGHT, WIDTH)\n\n                if \'semantics\' in global_pred:\n                    #cv2.imwrite(\'test/semantics.png\', drawSegmentationImage(np.argmax(global_pred[\'semantics\'][0], axis=-1)))\n                    #exit(1)\n                    predSemantics.append(np.argmax(global_pred[\'semantics\'][0], axis=-1))\n                else:\n                    predSemantics.append(np.zeros((HEIGHT, WIDTH)))\n                    pass\n\n                predDepths.append(pred_d)\n                predPlanes.append(pred_p)\n                #predSegmentations.append(pred_s)\n                predSegmentations.append(segmentation)\n\n                continue\n            pred_dict[\'plane\'] = np.array(predPlanes)\n            pred_dict[\'segmentation\'] = np.array(predSegmentations)\n            pred_dict[\'semantics\'] = np.array(predSemantics)\n            pred_dict[\'depth\'] = np.array(predDepths)\n            pred_dict[\'np_depth\'] = np.array(predNonPlaneDepths)\n            pred_dict[\'np_normal\'] = np.array(predNonPlaneNormals)\n            pred_dict[\'np_mask\'] = np.array(predNonPlaneMasks)\n            pred_dict[\'boundary\'] = np.array(predBoundaries)\n            pass\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n\n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return pred_dict\n\ndef getGroundTruth(options):\n    options.batchSize = 1\n    min_after_dequeue = 1000\n\n    reader = RecordReaderAll()\n    if options.dataset == \'SUNCG\':\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_SUNCG_val.tfrecords\'], num_epochs=1)\n    elif options.dataset == \'NYU_RGBD\':\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_nyu_rgbd_val.tfrecords\'], num_epochs=1)\n        options.deepSupervision = 0\n        options.predictLocal = 0\n    elif options.dataset == \'matterport\':\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_matterport_val.tfrecords\'], num_epochs=1)\n    else:\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/Data/PlaneNet/planes_scannet_val.tfrecords\'], num_epochs=1)\n        pass\n\n\n    img_inp, global_gt_dict, local_gt_dict = reader.getBatch(filename_queue, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True, random=False)\n\n\n    training_flag = tf.constant(False, tf.bool)\n\n    # if options.dataset == \'NYU_RGBD\':\n    #     global_gt_dict[\'segmentation\'], global_gt_dict[\'plane_mask\'] = tf.ones((options.batchSize, HEIGHT, WIDTH, options.numOutputPlanes)), tf.ones((options.batchSize, HEIGHT, WIDTH, 1))\n    # elif options.dataset == \'SUNCG\':\n    #     normalDotThreshold = np.cos(np.deg2rad(5))\n    #     distanceThreshold = 0.05\n    #     global_gt_dict[\'segmentation\'], global_gt_dict[\'plane_mask\'] = fitPlaneMasksModule(global_gt_dict[\'plane\'], global_gt_dict[\'depth\'], global_gt_dict[\'normal\'], width=WIDTH, height=HEIGHT, normalDotThreshold=normalDotThreshold, distanceThreshold=distanceThreshold, closing=True, one_hot=True)\n    # else:\n    #     global_gt_dict[\'plane_mask\'] = 1 - global_gt_dict[\'non_plane_mask\']\n    #     pass\n\n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n    gt_dict = {}\n\n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n        try:\n            gtDepths = []\n            gtNormals = []\n            planeMasks = []\n            #predMasks = []\n            gtPlanes = []\n            gtSegmentations = []\n            gtSemantics = []\n            gtInfo = []\n            gtNumPlanes = []\n            images = []\n\n            for index in xrange(options.startIndex + options.numImages):\n                print((\'image\', index))\n                t0=time.time()\n\n                img, global_gt = sess.run([img_inp, global_gt_dict])\n\n                if index < options.startIndex:\n                    continue\n\n                if index == 100:\n                    print(global_gt[\'image_path\'])\n                    exit(1)\n                    pass\n                continue\n                # if index == 11:\n                #     cv2.imwrite(\'test/mask.png\', drawMaskImage(global_gt[\'non_plane_mask\'].squeeze()))\n                #     exit(1)\n                image = ((img[0] + 0.5) * 255).astype(np.uint8)\n                images.append(image)\n\n                #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_boundary.png\', drawMaskImage(np.concatenate([global_gt[\'boundary\'][0], np.zeros((HEIGHT, WIDTH, 1))], axis=2)))\n\n                gt_d = global_gt[\'depth\'].squeeze()\n                gtDepths.append(gt_d)\n\n                if global_gt[\'info\'][0][19] == 3:\n                    gt_n = calcNormal(gt_d, global_gt[\'info\'][0])\n                    #cv2.imwrite(\'test/normal.png\', drawNormalImage(gt_n))\n                    #exit(1)\n                else:\n                    gt_n = global_gt[\'normal\'][0]\n                    pass\n                gtNormals.append(gt_n)\n\n                planeMask = np.squeeze(1 - global_gt[\'non_plane_mask\'])\n                planeMasks.append(planeMask)\n\n                gt_p = global_gt[\'plane\'][0]\n                gtPlanes.append(gt_p)\n                gt_s = global_gt[\'segmentation\'][0]\n                gtSegmentations.append(gt_s)\n                gt_semantics = global_gt[\'semantics\'][0]\n                gtSemantics.append(gt_semantics)\n                gt_num_p = global_gt[\'num_planes\'][0]\n                gtNumPlanes.append(gt_num_p)\n\n                gtInfo.append(global_gt[\'info\'][0])\n                continue\n\n            gt_dict[\'image\'] = np.array(images)\n            gt_dict[\'depth\'] = np.array(gtDepths)\n            gt_dict[\'normal\'] = np.array(gtNormals)\n            gt_dict[\'plane_mask\'] = np.array(planeMasks)\n            gt_dict[\'plane\'] = np.array(gtPlanes)\n            gt_dict[\'segmentation\'] = np.array(gtSegmentations)\n            gt_dict[\'semantics\'] = np.array(gtSemantics)\n            gt_dict[\'num_planes\'] = np.array(gtNumPlanes)\n            gt_dict[\'info\'] = np.array(gtInfo)\n\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n\n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return gt_dict\n\n\nif __name__==\'__main__\':\n    """"""\n    Parse input arguments\n    """"""\n    parser = argparse.ArgumentParser(description=\'Planenet\')\n    parser.add_argument(\'--task\', dest=\'task\',\n                        help=\'task type\',\n                        default=\'plane\', type=str)\n    parser.add_argument(\'--numOutputPlanes\', dest=\'numOutputPlanes\',\n                        help=\'the number of output planes\',\n                        default=20, type=int)\n    parser.add_argument(\'--dataset\', dest=\'dataset\',\n                        help=\'dataset name\',\n                        default=\'ScanNet\', type=str)\n    parser.add_argument(\'--hybrid\', dest=\'hybrid\',\n                        help=\'hybrid\',\n                        default=\'3\', type=str)\n    parser.add_argument(\'--visualizeImages\', dest=\'visualizeImages\',\n                        help=\'visualize image\',\n                        default=30, type=int)\n    parser.add_argument(\'--numImages\', dest=\'numImages\',\n                        help=\'the number of images\',\n                        default=30, type=int)\n    parser.add_argument(\'--startIndex\', dest=\'startIndex\',\n                        help=\'start index\',\n                        default=0, type=int)\n    parser.add_argument(\'--useCache\', dest=\'useCache\',\n                        help=\'use cache\',\n                        default=0, type=int)\n    # parser.add_argument(\'--useCRF\', dest=\'useCRF\',\n    #                     help=\'use crf\',\n    #                     default=0, type=int)\n    # parser.add_argument(\'--useSemantics\', dest=\'useSemantics\',\n    #                     help=\'use semantics\',\n    #                     default=0, type=int)\n    parser.add_argument(\'--useNonPlaneDepth\', dest=\'useNonPlaneDepth\',\n                        help=\'use non-plane depth\',\n                        default=0, type=int)\n    parser.add_argument(\'--imageIndex\', dest=\'imageIndex\',\n                        help=\'image index\',\n                        default=-1, type=int)\n    parser.add_argument(\'--methods\', dest=\'methods\',\n                        help=\'methods\',\n                        default=\'0000000\', type=str)\n    parser.add_argument(\'--rootFolder\', dest=\'rootFolder\',\n                        help=\'root folder\',\n                        default=\'/mnt/vision/PlaneNet/\', type=str)\n\n    args = parser.parse_args()\n    #args.hybrid = \'hybrid\' + args.hybrid\n    args.test_dir = \'evaluate/\' + args.task.replace(\'search\', \'plane\') + \'/\' + args.dataset + \'/hybrid\' + args.hybrid + \'/\'\n    args.visualizeImages = min(args.visualizeImages, args.numImages)\n    if args.imageIndex >= 0:\n        args.visualizeImages = 1\n        args.numImages = 1\n        pass\n\n    #args.titles = [ALL_TITLES[int(method)] for method in args.methods]\n    #args.methods = [ALL_METHODS[int(method)] for method in args.methods]\n    args.titles = ALL_TITLES\n    methods = ALL_METHODS\n    for methodIndex, flag in enumerate(args.methods):\n        methods[methodIndex][3] = int(flag)\n        pass\n    args.methods = methods\n\n    args.result_filename = args.test_dir + \'/results_\' + str(args.startIndex) + \'.npy\'\n    print(args.titles)\n\n    if args.task == \'plane\':\n        evaluatePlanes(args)\n    elif args.task == \'depth\':\n        evaluateDepthPrediction(args)\n    elif args.task == \'search\':\n        gridSearch(args)\n        pass\n'"
code/evaluate_depth.py,107,"b'import tensorflow as tf\nimport numpy as np\nnp.set_printoptions(precision=2, linewidth=200)\nimport cv2\nimport os\nimport time\nimport sys\nimport tf_nndistance\nimport argparse\nimport glob\nimport PIL\nimport scipy.ndimage as ndimage\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom utils import *\nfrom plane_utils import *\nfrom modules import *\n\nfrom train_planenet import build_graph\nfrom train_sample import build_graph as build_graph_sample\nfrom planenet import PlaneNet\nfrom RecordReaderAll import *\nfrom RecordReaderMake3D import *\n#from RecordReaderRGBD import *\nfrom SegmentationRefinement import *\nimport scipy.io as sio\nimport csv\n\n#ALL_TITLES = [\'planenet\', \'pixelwise\', \'pixelwise+RANSAC\', \'depth observation+RANSAC\', \'pixelwise+semantics+RANSAC\', \'gt\']\n#ALL_METHODS = [(\'bl2_ll1_bw0.5_pb_pp_sm0\', \'\'), (\'pb_pp\', \'pixelwise_1\'), (\'pb_pp\', \'pixelwise_2\'), (\'pb_pp\', \'pixelwise_3\'), (\'pb_pp\', \'semantics\'), (\'pb_pp\', \'gt\')]\n\n#ALL_TITLES = [\'planenet label loss\', \'planenet crf\', \'planenet label backward\', \'planenet different matching\']\n#ALL_METHODS = [(\'ll1_pb_pp\', \'\'), (\'crf1_pb_pp\', \'\'), (\'bl0_ll1_bw0.5_pb_pp_ps_sm0\', \'\'), (\'ll1_bw0.5_pb_pp_sm0\', \'\')]\n\n#ALL_METHODS = [(\'ll1_pb_pp\', \'pixelwise_1\'), (\'crf1_pb_pp\', \'pixelwise_2\'), (\'bl0_ll1_bw0.5_pb_pp_ps_sm0\', \'pixelwise_3\'), (\'ll1_bw0.5_pb_pp_sm0\', \'pixelwise_4\')]\n\n\nALL_TITLES = [\'planenet\', \'pixelwise\', \'fine-tuning\', \'ScanNet\', \'Make3D\']\n#ALL_METHODS = [(\'bl0_ll1_bw0.5_pp_ps_sm0\', \'\'), (\'bl0_ll1_bw0.5_pp_ps_sm0\', \'pixelwise_1\')]\n#ALL_METHODS = [(\'planenet_hybrid1_bl0_ll1_ds0_pp_ps\', \'\'), (\'pixelwise_hybrid1_ps\', \'pixelwise_1\')]\n#ALL_TITLES = [\'crf\', \'different matching\']\n#ALL_METHODS = [(\'pb_pp_sm0\', \'crf\'), (\'pb_pp_sm0\', \'\')]\n\n#ALL_METHODS = [(\'planenet_hybrid1_bl0_ll1_ds0_pp_ps\', \'\'), (\'pixelwise_hybrid1_ps\', \'\')]\nALL_METHODS = [(\'pixelwise_np10_hybrid1_ds0\', \'\'), (\'finetuning_hybrid1_ps\', \'\'), (\'finetuning_np10_hybrid1_ds0_ps\', \'\'), (\'sample_np10_hybrid3_bl0_dl0_ds0_crfrnn5_sm0\', \'\'), (\'finetuning_np10_hybrid4_ds0\', \'\')]\n\ndef writeHTML(options):\n    from html import HTML\n\n    titles = options.titles\n\n    h = HTML(\'html\')\n    h.p(\'Results\')\n    h.br()\n    path = \'.\'\n    #methods = [\'planenet\', \'pixelwise\', \'pixelwise+RANSAC\', \'GT+RANSAC\', \'planenet+crf\', \'pixelwise+semantics+RANSAC\']\n    #methods = [\'planenet\', \'pixelwise\', \'pixelwise+RANSAC\', \'GT+RANSAC\']\n\n    for index in xrange(options.numImages):\n\n        t = h.table(border=\'1\')\n        r_inp = t.tr()\n        r_inp.td(\'input\')\n        r_inp.td().img(src=path + \'/\' + str(index) + \'_image.png\')\n        r_inp.td().img(src=path + \'/\' + str(index) + \'_depth_gt.png\')\n        #r_inp.td().img(src=path + \'/\' + str(index) + \'_depth_gt_plane.png\')\n        r_inp.td().img(src=path + \'/\' + str(index) + \'_normal_gt.png\')\n        #r_inp.td().img(src=path + \'/\' + str(index) + \'_segmentation_gt.png\')\n        r_inp.td().img(src=\'/home/chenliu/Projects/PlaneNet/code/test/\' + str(index) + \'_dominant_lines.png\')\n        #r_inp.td().img(src=path + \'/\' + str(index) + \'_semantics_gt.png\')\n\n        # r = t.tr()\n        # r.td(\'PlaneNet prediction\')\n        # r.td().img(src=firstFolder + \'/\' + str(index) + \'_segmentation_pred.png\')\n        # r.td().img(src=firstFolder + \'/\' + str(index) + \'_depth_pred.png\')\n\n        r = t.tr()\n        r.td(\'methods\')\n        for method_index, method in enumerate(titles):\n            r.td(method)\n            continue\n\n        r = t.tr()\n        r.td(\'segmentation\')\n        for method_index, method in enumerate(titles):\n            r.td().img(src=path + \'/\' + str(index) + \'_segmentation_pred_\' + str(method_index) + \'.png\')\n            continue\n\n        continue\n\n        r = t.tr()\n        r.td(\'depth\')\n        for method_index, method in enumerate(titles):\n            r.td().img(src=path + \'/\' + str(index) + \'_depth_pred_\' + str(method_index) + \'.png\')\n            continue\n\n        r = t.tr()\n        r.td(\'depth_diff\')\n        for method_index, method in enumerate(titles):\n            r.td().img(src=path + \'/\' + str(index) + \'_depth_diff_\' + str(method_index) + \'.png\')\n            continue\n\n        r = t.tr()\n        r.td(\'normal\')\n        for method_index, method in enumerate(titles):\n            r.td().img(src=path + \'/\' + str(index) + \'_normal_pred_\' + str(method_index) + \'.png\')\n            continue\n\n        # r = t.tr()\n        # r.td(\'depth_normal\')\n        # for method_index, method in enumerate(titles):\n        #     r.td().img(src=path + \'/\' + str(index) + \'_depth_normal_pred_\' + str(method_index) + \'.png\')\n        #     continue\n\n        h.br()\n        continue\n\n    metric_titles = [\'plane diff 0.1\', \'plane diff 0.3\', \'plane diff 0.5\', \'IOU 0.3\', \'IOU 0.5\', \'IOU 0.7\']\n\n    h.p(\'Curves on plane accuracy\')\n    for title in metric_titles:\n        h.img(src=\'curve_plane_\' + title.replace(\' \', \'_\') + \'.png\')\n        continue\n\n    h.p(\'Curves on pixel coverage\')\n    for title in metric_titles:\n        h.img(src=\'curve_pixel_\' + title.replace(\' \', \'_\') + \'.png\')\n        continue\n\n\n    html_file = open(options.test_dir + \'/index.html\', \'w\')\n    html_file.write(str(h))\n    html_file.close()\n    return\n\n\ndef evaluatePlanePrediction(options):\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n\n    if options.useCache == 1 and os.path.exists(options.test_dir + \'/results.npy\'):\n        results = np.load(options.test_dir + \'/results.npy\')\n        results = results[()]\n    else:\n        results = getResults(options)\n        if options.useCache != -1:\n            np.save(options.test_dir + \'/results.npy\', results)\n            pass\n        pass\n\n    gt_dict = results[\'gt\']\n    predictions = results[\'pred\']\n\n    for key, value in gt_dict.iteritems():\n        if options.imageIndex >= 0:\n            gt_dict[key] = value[options.imageIndex:options.imageIndex + 1]\n        elif value.shape[0] > options.numImages:\n            gt_dict[key] = value[:options.numImages]\n            pass\n        continue\n    for pred_dict in predictions:\n        for key, value in pred_dict.iteritems():\n            if options.imageIndex >= 0:\n                pred_dict[key] = value[options.imageIndex:options.imageIndex + 1]\n            elif value.shape[0] > options.numImages:\n                pred_dict[key] = value[:options.numImages]\n                pass\n            continue\n        continue\n\n    #methods = [\'planenet\', \'pixelwise+RANSAC\', \'GT+RANSAC\']\n    titles = options.titles\n\n\n\n\n    #predictions[2] = predictions[3]\n\n\n\n\n    for image_index in xrange(options.visualizeImages):\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_image.png\', gt_dict[\'image\'][image_index])\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_gt.png\', drawDepthImage(gt_dict[\'depth\'][image_index]))\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_normal_gt.png\', drawNormalImage(gt_dict[\'normal\'][image_index]))\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_gt.png\', drawSegmentationImage(gt_dict[\'segmentation\'][image_index], blackIndex=options.numOutputPlanes))\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_semantics_gt.png\', drawSegmentationImage(gt_dict[\'semantics\'][image_index], blackIndex=0))\n\n\n        # plane_depths = calcPlaneDepths(gt_dict[\'plane\'][image_index], options.width, options.height, gt_dict[\'info\'][image_index])\n        # all_depths = np.concatenate([plane_depths, np.expand_dims(gt_dict[\'depth\'][image_index], -1)], axis=2)\n        # depth = np.sum(all_depths * np.concatenate([gt_dict[\'segmentation\'][image_index], 1 - np.expand_dims(gt_dict[\'plane_mask\'][image_index], -1)], axis=2), axis=2)\n        # cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_gt_plane.png\', drawDepthImage(depth))\n\n        for method_index, pred_dict in enumerate(predictions):\n            cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_dict[\'depth\'][image_index]))\n\n            if titles[method_index] == \'pixelwise\':\n                continue\n            segmentation = pred_dict[\'segmentation\'][image_index]\n            cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(segmentation, blackIndex=options.numOutputPlanes))\n            cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(pred_dict[\'semantics\'][image_index], blackIndex=0))\n            continue\n        continue\n\n\n    #post processing\n    for method_index, method in enumerate(options.methods):\n        if method[1] == \'graphcut\':\n            pred_dict = gt_dict\n            predSegmentations = []\n            predDepths = []\n            for image_index in xrange(options.numImages):\n                #if image_index != 3:\n                #continue\n                print(\'graph cut \' + str(image_index))\n\n                segmentation = pred_dict[\'segmentation\'][image_index]\n                #pred_s = getSegmentationsGraphCut(pred_dict[\'plane\'][image_index], gt_dict[\'image\'][image_index], pred_dict[\'depth\'][image_index], pred_dict[\'normal\'][image_index], segmentation, pred_dict[\'semantics\'][image_index], pred_dict[\'info\'][image_index], gt_dict[\'num_planes\'][image_index])\n\n                pred_p, pred_s, numPlanes = removeSmallSegments(pred_dict[\'plane\'][image_index], gt_dict[\'image\'][image_index], pred_dict[\'depth\'][image_index], pred_dict[\'normal\'][image_index], segmentation, pred_dict[\'semantics\'][image_index], pred_dict[\'info\'][image_index], gt_dict[\'num_planes\'][image_index])\n                #pred_p, pred_s, numPlanes = pred_dict[\'plane\'][image_index], segmentation, gt_dict[\'num_planes\'][image_index]\n                print((gt_dict[\'num_planes\'][image_index], numPlanes))\n                planeDepths = calcPlaneDepths(pred_p, options.width, options.height, gt_dict[\'info\'][image_index])\n                allDepths = np.concatenate([planeDepths, np.expand_dims(pred_dict[\'depth\'][image_index], -1)], axis=2)\n                pred_d = allDepths.reshape(-1, options.numOutputPlanes + 1)[np.arange(options.width * options.height), pred_s.reshape(-1)].reshape(options.height, options.width)\n\n                predSegmentations.append(pred_s)\n                predDepths.append(pred_d)\n\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_d))\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(pred_s, blackIndex=options.numOutputPlanes))\n                continue\n            new_pred_dict = {}\n            for key, value in pred_dict.iteritems():\n                new_pred_dict[key] = value\n                continue\n            new_pred_dict[\'segmentation\'] = np.array(predSegmentations)\n            predictions[method_index] = new_pred_dict\n        if method[1] == \'crf_tf\':\n            pred_dict = predictions[method_index]\n            predSegmentations = []\n            predDepths = []\n\n            image_inp = tf.placeholder(tf.float32, shape=[1, options.height, options.width, 3], name=\'image\')\n            segmentation_inp = tf.placeholder(tf.float32, shape=[1, options.height, options.width, options.numOutputPlanes + 1], name=\'segmentation\')\n            plane_inp = tf.placeholder(tf.float32, shape=[1, options.numOutputPlanes, 3], name=\'plane\')\n            non_plane_depth_inp = tf.placeholder(tf.float32, shape=[1, options.height, options.width, 1], name=\'non_plane_depth\')\n            info_inp = tf.placeholder(tf.float32, shape=[20], name=\'info\')\n\n\n            plane_parameters = tf.reshape(plane_inp, (-1, 3))\n            plane_depths = planeDepthsModule(plane_parameters, options.width, options.height, info_inp)\n            plane_depths = tf.transpose(tf.reshape(plane_depths, [options.height, options.width, -1, options.numOutputPlanes]), [2, 0, 1, 3])\n            all_depths = tf.concat([plane_depths, non_plane_depth_inp], axis=3)\n\n            planesY = plane_inp[:, :, 1]\n            planesD = tf.maximum(tf.norm(plane_inp, axis=-1), 1e-4)\n            planesY /= planesD\n            planesY = tf.concat([planesY, tf.ones((1, 1))], axis=1)\n\n            #refined_segmentation = crfModule(segmentation_inp, plane_inp, non_plane_depth_inp, info_inp, numOutputPlanes = options.numOutputPlanes, numIterations=5)\n\n            imageDiff = calcImageDiff(image_inp)\n            #refined_segmentation, debug_dict = segmentationRefinementModule(segmentation_inp, all_depths, planesY, imageDiff, numOutputPlanes = options.numOutputPlanes + 1, numIterations=5)\n            refined_segmentation, debug_dict = meanfieldModule(segmentation_inp, all_depths, planesY, imageDiff, numOutputPlanes = options.numOutputPlanes + 1, maxDepthDiff=0.2, varDepthDiff=pow(0.2, 2))\n\n            config=tf.ConfigProto()\n            config.gpu_options.allow_growth=True\n            config.allow_soft_placement=True\n\n            init_op = tf.group(tf.global_variables_initializer(),\n                               tf.local_variables_initializer())\n            with tf.Session(config=config) as sess:\n                sess.run(init_op)\n                for image_index in xrange(options.numImages):\n                    #if image_index != 1:\n                    #continue\n                    print(\'crf tf \' + str(image_index))\n                    allSegmentations = np.concatenate([pred_dict[\'segmentation\'][image_index], pred_dict[\'np_mask\'][image_index]], axis=2)\n                    allSegmentations = softmax(allSegmentations)\n                    pred_s, debug = sess.run([refined_segmentation, debug_dict], feed_dict={segmentation_inp: np.expand_dims(allSegmentations, 0), plane_inp: np.expand_dims(pred_dict[\'plane\'][image_index], 0), non_plane_depth_inp: np.expand_dims(pred_dict[\'np_depth\'][image_index], 0), info_inp: gt_dict[\'info\'][image_index], image_inp: gt_dict[\'image\'][image_index:image_index + 1]})\n\n                    pred_s = pred_s[0]\n                    planeDepths = calcPlaneDepths(pred_dict[\'plane\'][image_index], options.width, options.height, gt_dict[\'info\'][image_index])\n                    allDepths = np.concatenate([planeDepths, pred_dict[\'np_depth\'][image_index]], axis=2)\n                    pred_d = np.sum(allDepths * pred_s, axis=-1)\n\n                    predSegmentations.append(pred_s)\n                    predDepths.append(pred_d)\n\n                    cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_d))\n                    cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(pred_s, blackIndex=options.numOutputPlanes))\n\n                    if \'diff\' in debug:\n                        segmentation = np.argmax(allSegmentations, axis=-1)\n                        for planeIndex in xrange(options.numOutputPlanes + 1):\n                            cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(allSegmentations[:, :, planeIndex]))\n                            continue\n\n                        for planeIndex in xrange(debug[\'diff\'].shape[-1]):\n                            cv2.imwrite(\'test/cost_mask_\' + str(planeIndex) + \'.png\', drawMaskImage(debug[\'diff\'][0, :, :, planeIndex] / 2))\n                            continue\n                        #exit(1)\n                        pass\n                    continue\n                pass\n            new_pred_dict = {}\n            for key, value in pred_dict.iteritems():\n                new_pred_dict[key] = value\n                continue\n            segmentations = np.array(predSegmentations)\n            new_pred_dict[\'segmentation\'] = segmentations[:, :, :, :options.numOutputPlanes]\n            #new_pred_dict[\'non_plane_mask\'] = segmentations[:, :, :, options.numOutputPlanes:options.numOutputPlanes + 1]\n            #new_pred_dict[\'non_plane_mask\'] = segmentations[:, :, :, :options.numOutputPlanes]\n            new_pred_dict[\'depth\'] = np.array(predDepths)\n            predictions[method_index] = new_pred_dict\n            pass\n\n        if method[1] == \'crf\':\n            pred_dict = predictions[method_index]\n            predSegmentations = []\n            predDepths = []\n            for image_index in xrange(options.numImages):\n                print(\'crf \' + str(image_index))\n                boundaries = pred_dict[\'boundary\'][image_index]\n                boundaries = sigmoid(boundaries)\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_boundary.png\', drawMaskImage(np.concatenate([boundaries, np.zeros((options.height, options.width, 1))], axis=2)))\n\n                allSegmentations = np.concatenate([pred_dict[\'segmentation\'][image_index], pred_dict[\'np_mask\'][image_index]], axis=2)\n                allSegmentations = softmax(allSegmentations)\n                planeDepths = calcPlaneDepths(pred_dict[\'plane\'][image_index], options.width, options.height, gt_dict[\'info\'][image_index])\n                allDepths = np.concatenate([planeDepths, pred_dict[\'np_depth\'][image_index]], axis=2)\n                #boundaries = np.concatenate([np.ones((allSegmentations.shape[0], allSegmentations.shape[1], 1)), -np.ones((allSegmentations.shape[0], allSegmentations.shape[1], 1))], axis=2)\n                #if options.imageIndex >= 0:\n                #boundaries = cv2.imread(options.test_dir + \'/\' + str(options.imageIndex) + \'_boundary.png\')\n                #else:\n                #boundaries = cv2.imread(options.test_dir + \'/\' + str(image_index) + \'_boundary.png\')\n                #pass\n                #boundaries = (boundaries > 128).astype(np.float32)[:, :, :2]\n\n                allDepths[:, :, options.numOutputPlanes] = 0\n                pred_s = refineSegmentation(gt_dict[\'image\'][image_index], allSegmentations, allDepths, boundaries, numOutputPlanes = 20, numIterations=20, numProposals=5)\n                pred_d = allDepths.reshape(-1, options.numOutputPlanes + 1)[np.arange(options.width * options.height), pred_s.reshape(-1)].reshape(options.height, options.width)\n\n                predSegmentations.append(pred_s)\n                predDepths.append(pred_d)\n\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_d))\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(pred_s, blackIndex=options.numOutputPlanes))\n\n                #segmentation = np.argmax(allSegmentations, axis=-1)\n                for planeIndex in xrange(options.numOutputPlanes + 1):\n                    cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(allSegmentations[:, :, planeIndex]))\n                    continue\n                #cv2.imwrite(options.test_dir + \'/mask_\' + str(21) + \'.png\', drawDepthImage(pred_dict[\'np_depth\'][0]))\n                #for plane_index in xrange(options.numOutputPlanes + 1):\n                #cv2.imwrite(options.test_dir + \'/mask_\' + str(plane_index) + \'.png\', drawMaskImage(pred_s == plane_index))\n                #continue\n                #exit(1)\n                continue\n\n            new_pred_dict = {}\n            for key, value in pred_dict.iteritems():\n                new_pred_dict[key] = value\n                continue\n            new_pred_dict[\'segmentation\'] = np.array(predSegmentations)\n            new_pred_dict[\'depth\'] = np.array(predDepths)\n            predictions[method_index] = new_pred_dict\n            pass\n\n\n        if \'pixelwise\' in method[1]:\n            pred_dict = predictions[method_index]\n            predPlanes = []\n            predSegmentations = []\n            predDepths = []\n            for image_index in xrange(options.numImages):\n                print(\'pixelwise \', image_index)\n                pred_d = pred_dict[\'np_depth\'][image_index].squeeze()\n                if \'_1\' in method[1]:\n                    pred_s = np.zeros(pred_dict[\'segmentation\'][image_index].shape)\n                    pred_p = np.zeros(pred_dict[\'plane\'][image_index].shape)\n                elif \'_2\' in methods[1]:\n                    pred_p, pred_s, pred_d = fitPlanes(pred_d, gt_dict[\'info\'][image_index], numPlanes=20, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=0.2)\n                elif \'_3\' in methods[1]:\n                    pred_p, pred_s, pred_d = fitPlanes(pred_d, gt_dict[\'info\'][image_index], numPlanes=20, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=0.2)\n                elif \'_4\' in methods[1]:\n                    pred_p, pred_s, pred_d = fitPlanesSegmentation(pred_d, pred_dict[\'semantics\'][image_index], gt_dict[\'info\'][image_index], numOutputPlanes=20, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=0.2)\n                    pass\n                predPlanes.append(pred_p)\n                predSegmentations.append(pred_s)\n                predDepths.append(pred_d)\n\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_d))\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(pred_s))\n                continue\n            new_pred_dict = {}\n            for key, value in pred_dict.iteritems():\n                new_pred_dict[key] = value\n                continue\n            new_pred_dict[\'plane\'] = np.array(predPlanes)\n            new_pred_dict[\'segmentation\'] = np.array(predSegmentations)\n            new_pred_dict[\'depth\'] = np.array(predDepths)\n            predictions[method_index] = new_pred_dict\n            #titles.append(\'pixelwise+semantics+RANSAC\')\n            pass\n        continue\n\n\n    #exit(1)\n\n    #print(results)\n\n    # depth = gt_dict[\'depth\'][4]\n    # cv2.imwrite(options.test_dir + \'/test_depth_gt.png\', drawDepthImage(depth))\n    # pred_p, pred_s, pred_d = fitPlanes(depth, getSUNCGCamera(), numPlanes=20, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=0.2)\n    # cv2.imwrite(options.test_dir + \'/test_depth.png\', drawDepthImage(pred_d))\n    # cv2.imwrite(options.test_dir + \'/test_segmentation.png\', drawSegmentationImage(pred_s))\n    # exit(1)\n\n\n\n\n    pixel_metric_curves = [[], [], [], [], [], []]\n    plane_metric_curves = [[], [], [], [], [], []]\n    for method_index, pred_dict in enumerate(predictions):\n        if titles[method_index] == \'pixelwise\':\n            continue\n        segmentations = pred_dict[\'segmentation\']\n        if method_index == 0:\n            segmentations = softmax(segmentations)\n            pass\n        pixel_curves, plane_curves = evaluatePlaneSegmentation(pred_dict[\'plane\'], segmentations, gt_dict[\'plane\'], gt_dict[\'segmentation\'], gt_dict[\'num_planes\'], numOutputPlanes = options.numOutputPlanes)\n\n        for metric_index, pixel_curve in enumerate(pixel_curves):\n            pixel_metric_curves[metric_index].append(pixel_curve)\n            continue\n        for metric_index, plane_curve in enumerate(plane_curves):\n            plane_metric_curves[metric_index].append(plane_curve)\n            continue\n        continue\n\n    xs = []\n    xs.append((np.arange(11) * 0.1).tolist())\n    xs.append((np.arange(11) * 0.1).tolist())\n    xs.append((np.arange(11) * 0.1).tolist())\n    xs.append((np.arange(11) * 0.05).tolist())\n    xs.append((np.arange(11) * 0.05).tolist())\n    xs.append((np.arange(11) * 0.05).tolist())\n    xlabels = [\'IOU\', \'IOU\', \'IOU\', \'plane diff\', \'plane diff\', \'plane diff\']\n    curve_titles = [\'plane diff 0.1\', \'plane diff 0.3\', \'plane diff 0.5\', \'IOU 0.3\', \'IOU 0.5\', \'IOU 0.7\']\n    curve_labels = [title for title in titles if title != \'pixelwise\']\n    for metric_index, curves in enumerate(pixel_metric_curves):\n        filename = options.test_dir + \'/curve_pixel_\' + curve_titles[metric_index].replace(\' \', \'_\') + \'.png\'\n        plotCurves(xs[metric_index], curves, filename = filename, xlabel=xlabels[metric_index], ylabel=\'pixel coverage\', title=curve_titles[metric_index], labels=curve_labels)\n        continue\n    for metric_index, curves in enumerate(plane_metric_curves):\n        filename = options.test_dir + \'/curve_plane_\' + curve_titles[metric_index].replace(\' \', \'_\') + \'.png\'\n        plotCurves(xs[metric_index], curves, filename = filename, xlabel=xlabels[metric_index], ylabel=\'plane accuracy\', title=curve_titles[metric_index], labels=curve_labels)\n        continue\n\n    writeHTML(options)\n    return\n\ndef evaluateDepthPrediction(options):\n\n\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n\n    if options.useCache == 1 and os.path.exists(options.test_dir + \'/results.npy\'):\n        results = np.load(options.test_dir + \'/results.npy\')\n        results = results[()]\n    else:\n        results = getResults(options)\n        if options.useCache != -1:\n            np.save(options.test_dir + \'/results.npy\', results)\n            pass\n        pass\n\n    gt_dict = results[\'gt\']\n    predictions = results[\'pred\']\n\n    for key, value in gt_dict.iteritems():\n        if options.imageIndex >= 0:\n            gt_dict[key] = value[options.imageIndex:options.imageIndex + 1]\n        elif value.shape[0] > options.numImages:\n            gt_dict[key] = value[:options.numImages]\n            pass\n        continue\n    for pred_dict in predictions:\n        for key, value in pred_dict.iteritems():\n            if options.imageIndex >= 0:\n                pred_dict[key] = value[options.imageIndex:options.imageIndex + 1]\n            elif value.shape[0] > options.numImages:\n                pred_dict[key] = value[:options.numImages]\n                pass\n            continue\n        continue\n\n    titles = options.titles\n\n\n    for image_index in xrange(options.visualizeImages):\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_image.png\', gt_dict[\'image\'][image_index])\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_gt.png\', drawDepthImage(gt_dict[\'depth\'][image_index]))\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_normal_gt.png\', drawNormalImage(gt_dict[\'normal\'][image_index]))\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_gt.png\', drawSegmentationImage(gt_dict[\'segmentation\'][image_index], blackIndex=options.numOutputPlanes))\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_semantics_gt.png\', drawSegmentationImage(gt_dict[\'semantics\'][image_index], blackIndex=0))\n\n\n        #plane_depths = calcPlaneDepths(gt_dict[\'plane\'][image_index], options.width, options.height, gt_dict[\'info\'][image_index])\n        #all_depths = np.concatenate([plane_depths, np.expand_dims(gt_dict[\'depth\'][image_index], -1)], axis=2)\n        #depth = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(options.width * options.height), gt_dict[\'segmentation\'][image_index].reshape(-1)].reshape(options.height, options.width)\n        #cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_gt_plane.png\', drawDepthImage(depth))\n\n        #cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_gt_plane.png\', drawMaskImage((depth - gt_dict[\'depth\'][image_index]) * 10 + 0.5))\n\n        # plane_depths = calcPlaneDepths(gt_dict[\'plane\'][image_index], options.width, options.height, gt_dict[\'info\'][image_index])\n        # all_depths = np.concatenate([plane_depths, np.expand_dims(gt_dict[\'depth\'][image_index], -1)], axis=2)\n        # depth = np.sum(all_depths * np.concatenate([gt_dict[\'segmentation\'][image_index], 1 - np.expand_dims(gt_dict[\'plane_mask\'][image_index], -1)], axis=2), axis=2)\n        # cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_gt_plane.png\', drawDepthImage(depth))\n\n        for method_index, pred_dict in enumerate(predictions):\n            cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_dict[\'depth\'][image_index]))\n\n            cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_diff_\' + str(method_index) + \'.png\', drawMaskImage(np.abs(pred_dict[\'depth\'][image_index] - gt_dict[\'depth\'][image_index]) * 1))\n\n            cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_normal_pred_\' + str(method_index) + \'.png\', drawNormalImage(pred_dict[\'normal\'][image_index]))\n\n            #normal = calcNormal(pred_dict[\'depth\'][image_index], gt_dict[\'info\'][image_index])\n            #cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_normal_pred_\' + str(method_index) + \'.png\', drawNormalImage(pred_dict[\'depth_normal\'][image_index]))\n            #exit(1)\n            if titles[method_index] == \'pixelwise\':\n                continue\n            segmentation = pred_dict[\'segmentation\'][image_index]\n            cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(segmentation, blackIndex=options.numOutputPlanes))\n            continue\n        continue\n\n\n    #post processing\n    for method_index, method in enumerate(options.methods):\n        if method[1] == \'graphcut\':\n            pred_dict = gt_dict\n            predSegmentations = []\n            predDepths = []\n            for image_index in xrange(options.numImages):\n                #if image_index != 3:\n                #continue\n                print(\'graph cut \' + str(image_index))\n\n                segmentation = np.argmax(np.concatenate([pred_dict[\'segmentation\'][image_index], 1 - np.expand_dims(pred_dict[\'plane_mask\'][image_index], -1)], axis=2), axis=2)\n                #pred_s = getSegmentationsGraphCut(pred_dict[\'plane\'][image_index], gt_dict[\'image\'][image_index], pred_dict[\'depth\'][image_index], pred_dict[\'normal\'][image_index], segmentation, pred_dict[\'semantics\'][image_index], pred_dict[\'info\'][image_index], gt_dict[\'num_planes\'][image_index])\n\n                pred_p, pred_s, numPlanes = removeSmallSegments(pred_dict[\'plane\'][image_index], gt_dict[\'image\'][image_index], pred_dict[\'depth\'][image_index], pred_dict[\'normal\'][image_index], segmentation, pred_dict[\'semantics\'][image_index], pred_dict[\'info\'][image_index], gt_dict[\'num_planes\'][image_index])\n                #pred_p, pred_s, numPlanes = pred_dict[\'plane\'][image_index], segmentation, gt_dict[\'num_planes\'][image_index]\n                print((gt_dict[\'num_planes\'][image_index], numPlanes))\n                planeDepths = calcPlaneDepths(pred_p, options.width, options.height, gt_dict[\'info\'][image_index])\n                allDepths = np.concatenate([planeDepths, np.expand_dims(pred_dict[\'depth\'][image_index], -1)], axis=2)\n                pred_d = allDepths.reshape(-1, options.numOutputPlanes + 1)[np.arange(options.width * options.height), pred_s.reshape(-1)].reshape(options.height, options.width)\n\n                predSegmentations.append(pred_s)\n                predDepths.append(pred_d)\n\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_d))\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(pred_s, blackIndex=options.numOutputPlanes))\n                continue\n            new_pred_dict = {}\n            for key, value in pred_dict.iteritems():\n                new_pred_dict[key] = value\n                continue\n            new_pred_dict[\'segmentation\'] = np.array(predSegmentations)\n            predictions[method_index] = new_pred_dict\n        if method[1] == \'crf_tf\':\n            pred_dict = predictions[method_index]\n            predSegmentations = []\n            predDepths = []\n\n            image_inp = tf.placeholder(tf.float32, shape=[1, options.height, options.width, 3], name=\'image\')\n            segmentation_inp = tf.placeholder(tf.float32, shape=[1, options.height, options.width, options.numOutputPlanes + 1], name=\'segmentation\')\n            plane_inp = tf.placeholder(tf.float32, shape=[1, options.numOutputPlanes, 3], name=\'plane\')\n            non_plane_depth_inp = tf.placeholder(tf.float32, shape=[1, options.height, options.width, 1], name=\'non_plane_depth\')\n            info_inp = tf.placeholder(tf.float32, shape=[20], name=\'info\')\n\n\n            plane_parameters = tf.reshape(plane_inp, (-1, 3))\n            plane_depths = planeDepthsModule(plane_parameters, options.width, options.height, info_inp)\n            plane_depths = tf.transpose(tf.reshape(plane_depths, [options.height, options.width, -1, options.numOutputPlanes]), [2, 0, 1, 3])\n            all_depths = tf.concat([plane_depths, non_plane_depth_inp], axis=3)\n\n            planesY = plane_inp[:, :, 1]\n            planesD = tf.maximum(tf.norm(plane_inp, axis=-1), 1e-4)\n            planesY /= planesD\n            planesY = tf.concat([planesY, tf.ones((1, 1))], axis=1)\n\n            #refined_segmentation = crfModule(segmentation_inp, plane_inp, non_plane_depth_inp, info_inp, numOutputPlanes = options.numOutputPlanes, numIterations=5)\n\n            imageDiff = calcImageDiff(image_inp)\n            #refined_segmentation, debug_dict = segmentationRefinementModule(segmentation_inp, all_depths, planesY, imageDiff, numOutputPlanes = options.numOutputPlanes + 1, numIterations=5)\n            refined_segmentation, debug_dict = meanfieldModule(segmentation_inp, all_depths, planesY, imageDiff, numOutputPlanes = options.numOutputPlanes + 1, maxDepthDiff=0.2, varDepthDiff=pow(0.2, 2))\n\n            config=tf.ConfigProto()\n            config.gpu_options.allow_growth=True\n            config.allow_soft_placement=True\n\n            init_op = tf.group(tf.global_variables_initializer(),\n                               tf.local_variables_initializer())\n            with tf.Session(config=config) as sess:\n                sess.run(init_op)\n                for image_index in xrange(options.numImages):\n                    #if image_index != 1:\n                    #continue\n                    print(\'crf tf \' + str(image_index))\n                    allSegmentations = np.concatenate([pred_dict[\'segmentation\'][image_index], pred_dict[\'np_mask\'][image_index]], axis=2)\n                    allSegmentations = softmax(allSegmentations)\n                    pred_s, debug = sess.run([refined_segmentation, debug_dict], feed_dict={segmentation_inp: np.expand_dims(allSegmentations, 0), plane_inp: np.expand_dims(pred_dict[\'plane\'][image_index], 0), non_plane_depth_inp: np.expand_dims(pred_dict[\'np_depth\'][image_index], 0), info_inp: gt_dict[\'info\'][image_index], image_inp: gt_dict[\'image\'][image_index:image_index + 1]})\n\n                    pred_s = pred_s[0]\n                    planeDepths = calcPlaneDepths(pred_dict[\'plane\'][image_index], options.width, options.height, gt_dict[\'info\'][image_index])\n                    allDepths = np.concatenate([planeDepths, pred_dict[\'np_depth\'][image_index]], axis=2)\n                    pred_d = np.sum(allDepths * pred_s, axis=-1)\n\n                    predSegmentations.append(pred_s)\n                    predDepths.append(pred_d)\n\n                    cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_d))\n                    cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(pred_s, blackIndex=options.numOutputPlanes))\n\n                    if \'diff\' in debug:\n                        segmentation = np.argmax(allSegmentations, axis=-1)\n                        for planeIndex in xrange(options.numOutputPlanes + 1):\n                            cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(allSegmentations[:, :, planeIndex]))\n                            continue\n\n                        for planeIndex in xrange(debug[\'diff\'].shape[-1]):\n                            cv2.imwrite(\'test/cost_mask_\' + str(planeIndex) + \'.png\', drawMaskImage(debug[\'diff\'][0, :, :, planeIndex] / 2))\n                            continue\n                        exit(1)\n                        pass\n                    continue\n                pass\n            new_pred_dict = {}\n            for key, value in pred_dict.iteritems():\n                new_pred_dict[key] = value\n                continue\n            segmentations = np.array(predSegmentations)\n            new_pred_dict[\'segmentation\'] = segmentations[:, :, :, :options.numOutputPlanes]\n            #new_pred_dict[\'non_plane_mask\'] = segmentations[:, :, :, options.numOutputPlanes:options.numOutputPlanes + 1]\n            #new_pred_dict[\'non_plane_mask\'] = segmentations[:, :, :, :options.numOutputPlanes]\n            new_pred_dict[\'depth\'] = np.array(predDepths)\n            predictions[method_index] = new_pred_dict\n            pass\n\n        if method[1] == \'crf\':\n            pred_dict = predictions[method_index]\n            predSegmentations = []\n            predDepths = []\n            for image_index in xrange(options.numImages):\n                print(\'crf \' + str(image_index))\n                boundaries = pred_dict[\'boundary\'][image_index]\n                boundaries = sigmoid(boundaries)\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_boundary.png\', drawMaskImage(np.concatenate([boundaries, np.zeros((options.height, options.width, 1))], axis=2)))\n\n                allSegmentations = np.concatenate([pred_dict[\'segmentation\'][image_index], pred_dict[\'np_mask\'][image_index]], axis=2)\n                allSegmentations = softmax(allSegmentations)\n                planeDepths = calcPlaneDepths(pred_dict[\'plane\'][image_index], options.width, options.height, gt_dict[\'info\'][image_index])\n                allDepths = np.concatenate([planeDepths, pred_dict[\'np_depth\'][image_index]], axis=2)\n                #boundaries = np.concatenate([np.ones((allSegmentations.shape[0], allSegmentations.shape[1], 1)), -np.ones((allSegmentations.shape[0], allSegmentations.shape[1], 1))], axis=2)\n                #if options.imageIndex >= 0:\n                #boundaries = cv2.imread(options.test_dir + \'/\' + str(options.imageIndex) + \'_boundary.png\')\n                #else:\n                #boundaries = cv2.imread(options.test_dir + \'/\' + str(image_index) + \'_boundary.png\')\n                #pass\n                #boundaries = (boundaries > 128).astype(np.float32)[:, :, :2]\n\n                allDepths[:, :, options.numOutputPlanes] = 0\n                pred_s = refineSegmentation(gt_dict[\'image\'][image_index], allSegmentations, allDepths, boundaries, numOutputPlanes = 20, numIterations=20, numProposals=5)\n                pred_d = allDepths.reshape(-1, options.numOutputPlanes + 1)[np.arange(options.width * options.height), pred_s.reshape(-1)].reshape(options.height, options.width)\n\n                predSegmentations.append(pred_s)\n                predDepths.append(pred_d)\n\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_d))\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(pred_s, blackIndex=options.numOutputPlanes))\n\n                #segmentation = np.argmax(allSegmentations, axis=-1)\n                for planeIndex in xrange(options.numOutputPlanes + 1):\n                    cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(allSegmentations[:, :, planeIndex]))\n                    continue\n                #cv2.imwrite(options.test_dir + \'/mask_\' + str(21) + \'.png\', drawDepthImage(pred_dict[\'np_depth\'][0]))\n                #for plane_index in xrange(options.numOutputPlanes + 1):\n                #cv2.imwrite(options.test_dir + \'/mask_\' + str(plane_index) + \'.png\', drawMaskImage(pred_s == plane_index))\n                #continue\n                #exit(1)\n                continue\n\n            new_pred_dict = {}\n            for key, value in pred_dict.iteritems():\n                new_pred_dict[key] = value\n                continue\n            new_pred_dict[\'segmentation\'] = np.array(predSegmentations)\n            new_pred_dict[\'depth\'] = np.array(predDepths)\n            predictions[method_index] = new_pred_dict\n            pass\n\n\n        if \'pixelwise\' in method[1]:\n            pred_dict = predictions[method_index]\n            predPlanes = []\n            predSegmentations = []\n            predDepths = []\n            predNormals = []\n            for image_index in xrange(options.numImages):\n                pred_d = pred_dict[\'np_depth\'][image_index].squeeze()\n                pred_n = pred_dict[\'np_normal\'][image_index]\n                if \'_1\' in method[1]:\n                    pred_s = np.zeros(pred_dict[\'segmentation\'][image_index].shape)\n                    pred_p = np.zeros((options.numOutputPlanes, 3))\n                elif \'_2\' in method[1]:\n                    #pred_p, pred_s, pred_d, pred_n = fitPlanes(pred_d, gt_dict[\'info\'][image_index], numPlanes=20, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=0.2)\n                    pred_p, pred_s, pred_d, pred_n = fitPlanesNYU(gt_dict[\'image\'], gt_dict[\'depth\'][image_index].squeeze(), gt_dict[\'normal\'][image_index], gt_dict[\'semantics\'], gt_dict[\'info\'][image_index], numOutputPlanes=20, planeAreaThreshold=3*4, distanceThreshold=0.05, local=0.2)\n                elif \'_3\' in method[1]:\n                    #pred_p, pred_s, pred_d, pred_n = fitPlanes(pred_d, gt_dict[\'info\'][image_index], numPlanes=20, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=0.2)\n                    pred_p, pred_s, pred_d, pred_n = fitPlanesNYU(gt_dict[\'image\'], pred_d, pred_n, gt_dict[\'semantics\'], gt_dict[\'info\'][image_index], numOutputPlanes=20, planeAreaThreshold=3*4, distanceThreshold=0.05, local=0.2)\n                elif \'_4\' in method[1]:\n                    pred_p, pred_s, pred_d, pred_n = fitPlanesSegmentation(pred_d, pred_dict[\'semantics\'][image_index], gt_dict[\'info\'][image_index], numPlanes=20, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=0.2)\n                elif \'_5\' in method[1]:\n\n                    # print(gt_dict[\'plane\'][image_index] / np.linalg.norm(gt_dict[\'plane\'][image_index], axis=-1, keepdims=True))\n                    # cv2.imwrite(\'test/image.png\', gt_dict[\'image\'][image_index])\n                    # for planeIndex in xrange(20):\n                    #     cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(gt_dict[\'segmentation\'][image_index][:, :, planeIndex]))\n                    #     continue\n\n                    pred_p, pred_s, pred_d, pred_n = fitPlanesManhattan(gt_dict[\'image\'][image_index], pred_d, pred_n, gt_dict[\'info\'][image_index], numOutputPlanes=20)\n                elif \'_6\' in method[1]:\n\n                    # print(gt_dict[\'plane\'][image_index] / np.linalg.norm(gt_dict[\'plane\'][image_index], axis=-1, keepdims=True))\n                    # cv2.imwrite(\'test/depth.png\', drawDepthImage(gt_dict[\'depth\'][image_index]))\n                    # cv2.imwrite(\'test/image.png\', gt_dict[\'image\'][image_index])\n                    # for planeIndex in xrange(20):\n                    #     cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(gt_dict[\'segmentation\'][image_index][:, :, planeIndex]))\n                    #     continue\n\n                    pred_p, pred_s, pred_d, pred_n = fitPlanesManhattan(gt_dict[\'image\'][image_index], gt_dict[\'depth\'][image_index].squeeze(), gt_dict[\'normal\'][image_index], gt_dict[\'info\'][image_index], numOutputPlanes=20, imageIndex=image_index)\n                    exit(1)\n\n                    pass\n                predPlanes.append(pred_p)\n                predSegmentations.append(pred_s)\n                predDepths.append(pred_d)\n                predNormals.append(pred_n)\n\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_d))\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_normal_pred_\' + str(method_index) + \'.png\', drawNormalImage(pred_n))\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(pred_s))\n                #exit(1)\n                continue\n            new_pred_dict = {}\n            for key, value in pred_dict.iteritems():\n                new_pred_dict[key] = value\n                continue\n            new_pred_dict[\'plane\'] = np.array(predPlanes)\n            new_pred_dict[\'segmentation\'] = np.array(predSegmentations)\n            new_pred_dict[\'depth\'] = np.array(predDepths)\n            new_pred_dict[\'normal\'] = np.array(predNormals)\n            predictions[method_index] = new_pred_dict\n            #titles.append(\'pixelwise+semantics+RANSAC\')\n            pass\n\n        if \'gt\' in method[1]:\n            pred_dict = predictions[method_index]\n            predPlanes = []\n            predSegmentations = []\n            predDepths = []\n            predNormals = []\n            for image_index in xrange(options.numImages):\n                if \'_s\' in method[1]:\n                    pred_s = np.argmax(np.concatenate([gt_dict[\'segmentation\'][image_index], 1 - np.expand_dims(gt_dict[\'plane_mask\'][image_index], -1)], axis=-1), axis=-1)\n                else:\n                    pred_s = np.argmax(np.concatenate([pred_dict[\'segmentation\'][image_index], pred_dict[\'np_mask\'][image_index]], axis=-1), axis=-1)\n                    pass\n                if \'_p\' in method[1]:\n                    pred_p = gt_dict[\'plane\'][image_index]\n                else:\n                    pred_p = pred_dict[\'plane\'][image_index]\n                    pass\n\n                planeDepths = calcPlaneDepths(pred_p, options.width, options.height, gt_dict[\'info\'][image_index])\n                allDepths = np.concatenate([planeDepths, np.expand_dims(pred_dict[\'depth\'][image_index], -1)], axis=2)\n                pred_d = allDepths.reshape(-1, options.numOutputPlanes + 1)[np.arange(options.width * options.height), pred_s.reshape(-1)].reshape(options.height, options.width)\n\n                plane_normals = calcPlaneNormals(pred_p, options.width, options.height)\n                all_normals = np.concatenate([plane_normals, np.expand_dims(pred_dict[\'np_normal\'][image_index], 2)], axis=2)\n                pred_n = all_normals.reshape(-1, options.numOutputPlanes + 1, 3)[np.arange(options.width * options.height), pred_s.reshape(-1)].reshape((options.height, options.width, 3))\n\n                predPlanes.append(pred_p)\n                predSegmentations.append(pred_s)\n                predDepths.append(pred_d)\n                predNormals.append(pred_n)\n\n\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_d))\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_normal_pred_\' + str(method_index) + \'.png\', drawNormalImage(pred_n))\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(pred_s, blackIndex=options.numOutputPlanes))\n                continue\n\n            new_pred_dict = {}\n            for key, value in pred_dict.iteritems():\n                new_pred_dict[key] = value\n                continue\n            new_pred_dict[\'segmentation\'] = np.array(predSegmentations)\n            new_pred_dict[\'plane\'] = np.array(predPlanes)\n            new_pred_dict[\'depth\'] = np.array(predDepths)\n            new_pred_dict[\'normal\'] = np.array(predNormals)\n            predictions[method_index] = new_pred_dict\n        continue\n\n\n\n    for method_index, pred_dict in enumerate(predictions):\n        print(titles[method_index])\n        evaluateDepths(pred_dict[\'depth\'], gt_dict[\'depth\'], np.ones(gt_dict[\'depth\'].shape))\n        evaluateDepths(pred_dict[\'depth\'], gt_dict[\'depth\'], np.ones(gt_dict[\'depth\'].shape), planeMasks=gt_dict[\'segmentation\'] < options.numOutputPlanes)\n\n        #boundaries = gt_dict[\'semantics\']\n        #evaluateDepths(pred_dict[\'depth\'], gt_dict[\'depth\'], np.ones(gt_dict[\'depth\'].shape), planeMasks=)\n\n        #evaluateNormal(pred_dict[\'normal\'], gt_dict[\'segmentation\'], gt_dict[\'num_planes\'], gt_dict[\'plane\'])\n        #evaluateNormal(pred_dict[\'depth_normal\'], gt_dict[\'segmentation\'])\n        #evaluateNormal(pred_dict[\'np_normal\'], gt_dict[\'segmentation\'], gt_dict[\'num_planes\'], gt_dict[\'plane\'])\n        #evaluateNormal(gt_dict[\'normal\'], gt_dict[\'segmentation\'], gt_dict[\'num_planes\'], gt_dict[\'plane\'])\n        continue\n\n    writeHTML(options)\n    return\n\ndef getResults(options):\n    checkpoint_prefix = options.rootFolder + \'/checkpoint/\'\n\n    methods = options.methods\n\n    if options.highRes == 1:\n        gt_dict = getGroundTruthHighRes(options)\n    else:\n        gt_dict = getGroundTruth(options)\n        pass\n\n    predictions = []\n\n\n    for method_index, method in enumerate(methods):\n        if \'ds0\' not in method[0]:\n            options.deepSupervisionLayers = [\'res4b22_relu\', ]\n        else:\n            options.deepSupervisionLayers = []\n            pass\n        options.predictConfidence = 0\n        options.predictLocal = 0\n        options.predictPixelwise = 1\n        options.predictBoundary = 0\n        options.anchorPlanes = 0\n        if \'ps\' in method[0] and \'hybrid_\' not in method[0]:\n            options.predictSemantics = 1\n        else:\n            options.predictSemantics = 0\n            pass\n        if \'crfrnn\' in method[0]:\n            options.crfrnn = 10\n        else:\n            options.crfrnn = 0\n            pass\n\n        if \'ap1\' in method[0]:\n            options.anchorPlanes = 1\n            pass\n\n        options.checkpoint_dir = checkpoint_prefix + method[0]\n        if options.hybrid != \'1\':\n            options.checkpoint_dir = options.checkpoint_dir.replace(\'hybrid1\', \'hybrid\' + str(options.hybrid))\n            pass\n\n        print(options.checkpoint_dir)\n\n        options.suffix = method[1]\n\n        method_names = [previous_method[0] for previous_method in methods[:method_index]]\n\n        if method[0] in method_names:\n            pred_dict = predictions[method_names.index(method[0])]\n        elif method[0] == \'gt\':\n            pred_dict = gt_dict\n        else:\n            if options.highRes == 1:\n                pred_dict = getPredictionHighRes(options)\n            else:\n                pred_dict = getPrediction(options)\n                pass\n            pass\n\n        # for image_index in xrange(options.visualizeImages):\n        #     cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_dict[\'depth\'][image_index]))\n        #     cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage())\n        #     continue\n\n        predictions.append(pred_dict)\n        continue\n    #np.save(options.test_dir + \'/curves.npy\', curves)\n    results = {\'gt\': gt_dict, \'pred\': predictions}\n    return results\n\ndef getPrediction(options):\n    tf.reset_default_graph()\n\n    options.batchSize = 1\n    min_after_dequeue = 1000\n\n    reader = RecordReaderAll()\n    if options.dataset == \'SUNCG\':\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_SUNCG_val.tfrecords\'], num_epochs=10000)\n    elif options.dataset == \'NYU_RGBD_raw\':\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_nyu_rgbd_val.tfrecords\'], num_epochs=1)\n        options.deepSupervision = 0\n        options.predictLocal = 0\n    elif options.dataset == \'matterport\':\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_matterport_val.tfrecords\'], num_epochs=1)\n    elif options.dataset == \'ScanNet\':\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_scannet_val.tfrecords\'], num_epochs=1)\n    elif options.dataset == \'NYU_RGBD\':\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_nyu_rgbd_labeled_val.tfrecords\'], num_epochs=1)\n        pass\n\n    img_inp, global_gt_dict, local_gt_dict = reader.getBatch(filename_queue, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True, random=False)\n\n\n\n    training_flag = tf.constant(False, tf.bool)\n\n    options.gpu_id = 0\n    if \'sample\' not in options.checkpoint_dir:\n        global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp, img_inp, training_flag, options)\n    else:\n        print(\'sample\')\n        global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph_sample(img_inp, img_inp, training_flag, options)\n        pass\n\n    var_to_restore = tf.global_variables()\n\n\n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n    print(options)\n\n    pred_dict = {}\n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n        #var_to_restore = [v for v in var_to_restore if \'res4b22_relu_non_plane\' not in v.name]\n        loader = tf.train.Saver(var_to_restore)\n        loader.restore(sess, ""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n        #loader.restore(sess, options.fineTuningCheckpoint)\n\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n\n        try:\n            predDepths = []\n            predNormals = []\n            predPlanes = []\n            predSegmentations = []\n            predNonPlaneDepths = []\n            predNonPlaneMasks = []\n            predNonPlaneNormals = []\n            predBoundaries = []\n            predDepthNormals = []\n            for index in xrange(options.startIndex + options.numImages):\n                if index % 10 == 0:\n                    print((\'image\', index))\n                    pass\n                t0=time.time()\n\n                img, global_gt, global_pred = sess.run([img_inp, global_gt_dict, global_pred_dict])\n\n                if index < options.startIndex:\n                    continue\n\n\n                pred_p = global_pred[\'plane\'][0]\n                pred_s = global_pred[\'segmentation\'][0]\n\n                pred_np_m = global_pred[\'non_plane_mask\'][0]\n                pred_np_d = global_pred[\'non_plane_depth\'][0]\n                pred_np_n = global_pred[\'non_plane_normal\'][0]\n\n                #pred_b = global_pred[\'boundary\'][0]\n                predNonPlaneMasks.append(pred_np_m)\n                predNonPlaneDepths.append(pred_np_d)\n                predNonPlaneNormals.append(pred_np_n)\n                #predBoundaries.append(pred_b)\n\n                all_segmentations = np.concatenate([pred_np_m, pred_s], axis=2)\n                plane_depths = calcPlaneDepths(pred_p, options.width, options.height, global_gt[\'info\'][0])\n                all_depths = np.concatenate([pred_np_d, plane_depths], axis=2)\n\n                segmentation = np.argmax(all_segmentations, 2)\n                pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(options.width * options.height), segmentation.reshape(-1)].reshape(options.height, options.width)\n\n                plane_normals = calcPlaneNormals(pred_p, options.width, options.height)\n                all_normals = np.concatenate([np.expand_dims(pred_np_n, 2), plane_normals], axis=2)\n                pred_n = all_normals.reshape(-1, options.numOutputPlanes + 1, 3)[np.arange(options.width * options.height), segmentation.reshape(-1)].reshape((options.height, options.width, 3))\n\n                predDepths.append(pred_d)\n                predNormals.append(pred_n)\n                predPlanes.append(pred_p)\n                predSegmentations.append(pred_s)\n                predDepthNormals.append(calcNormal(pred_d, global_gt[\'info\'][0]))\n                pass\n\n                continue\n            pred_dict[\'plane\'] = np.array(predPlanes)\n            pred_dict[\'segmentation\'] = np.array(predSegmentations)\n            pred_dict[\'depth\'] = np.array(predDepths)\n            pred_dict[\'normal\'] = np.array(predNormals)\n            pred_dict[\'np_depth\'] = np.array(predNonPlaneDepths)\n            pred_dict[\'np_mask\'] = np.array(predNonPlaneMasks)\n            pred_dict[\'np_normal\'] = np.array(predNonPlaneNormals)\n            pred_dict[\'depth_normal\'] = np.array(predDepthNormals)\n            #pred_dict[\'boundary\'] = np.array(predBoundaries)\n            pass\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n\n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return pred_dict\n\ndef getPredictionHighRes(options):\n    tf.reset_default_graph()\n\n    options.batchSize = 1\n    min_after_dequeue = 1000\n\n    if options.dataset == \'SUNCG\':\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_SUNCG_val.tfrecords\'], num_epochs=10000)\n    elif options.dataset == \'NYU_RGBD_raw\':\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_nyu_rgbd_val.tfrecords\'], num_epochs=1)\n        options.deepSupervision = 0\n        options.predictLocal = 0\n    elif options.dataset == \'matterport\':\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_matterport_val.tfrecords\'], num_epochs=1)\n    elif options.dataset == \'ScanNet\':\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_scannet_val.tfrecords\'], num_epochs=1)\n    elif options.dataset == \'NYU_RGBD\':\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_nyu_rgbd_labeled_val.tfrecords\'], num_epochs=1)\n    elif options.dataset == \'Make3D\':\n        filename_queue = tf.train.string_input_producer([\'../planes_make3d_val.tfrecords\'], num_epochs=1)\n        pass\n\n    if options.dataset != \'Make3D\':\n        reader = RecordReaderAll()\n    else:\n        reader = RecordReaderMake3D()\n        pass\n\n    img_inp, global_gt_dict, local_gt_dict = reader.getBatch(filename_queue, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True, random=False)\n\n\n\n    training_flag = tf.constant(False, tf.bool)\n\n    options.gpu_id = 0\n\n    global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp, img_inp, training_flag, options)\n\n    var_to_restore = tf.global_variables()\n\n\n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n    print(options)\n\n    pred_dict = {}\n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n        #var_to_restore = [v for v in var_to_restore if \'res4b22_relu_non_plane\' not in v.name]\n        loader = tf.train.Saver(var_to_restore)\n        loader.restore(sess, ""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n        #loader.restore(sess, options.fineTuningCheckpoint)\n\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n\n        try:\n            predDepths = []\n            predNormals = []\n            predPlanes = []\n            predSegmentations = []\n            predNonPlaneDepths = []\n            predNonPlaneMasks = []\n            predNonPlaneNormals = []\n            predBoundaries = []\n            predDepthNormals = []\n            for index in xrange(options.startIndex + options.numImages):\n                if index % 10 == 0:\n                    print((\'image\', index))\n                    pass\n                t0=time.time()\n\n                img, global_gt, global_pred = sess.run([img_inp, global_gt_dict, global_pred_dict])\n\n                if index < options.startIndex:\n                    continue\n\n                info = global_gt[\'info\'][0]\n\n                width_high_res = int(info[16])\n                height_high_res = int(info[17])\n\n                pred_p = global_pred[\'plane\'][0]\n                pred_s = global_pred[\'segmentation\'][0]\n\n                pred_np_m = global_pred[\'non_plane_mask\'].squeeze()\n                pred_np_d = global_pred[\'non_plane_depth\'].squeeze()\n                pred_np_n = global_pred[\'non_plane_normal\'][0]\n\n                pred_np_m = cv2.resize(pred_np_m, (width_high_res, height_high_res), interpolation=cv2.INTER_LINEAR)\n                pred_np_m = np.expand_dims(pred_np_m, -1)\n\n                pred_np_d = cv2.resize(pred_np_d, (width_high_res, height_high_res), interpolation=cv2.INTER_LINEAR)\n                pred_np_n = cv2.resize(pred_np_n, (width_high_res, height_high_res), interpolation=cv2.INTER_LINEAR)\n                pred_np_d = np.expand_dims(pred_np_d, -1)\n\n                pred_s_high_res = []\n                for planeIndex in xrange(pred_s.shape[-1]):\n                    pred_s_high_res.append(cv2.resize(pred_s[:, :, planeIndex], (width_high_res, height_high_res), interpolation=cv2.INTER_LINEAR))\n                    continue\n                pred_s = np.stack(pred_s_high_res, axis=2)\n                #pred_b = global_pred[\'boundary\'][0]\n\n                predNonPlaneDepths.append(pred_np_d)\n                predNonPlaneNormals.append(pred_np_n)\n                #predBoundaries.append(pred_b)\n\n                all_segmentations = np.concatenate([pred_np_m, pred_s], axis=2)\n                plane_depths = calcPlaneDepths(pred_p, width_high_res, height_high_res, info)\n                all_depths = np.concatenate([pred_np_d, plane_depths], axis=2)\n\n                segmentation = np.argmax(all_segmentations, 2)\n                pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(width_high_res * height_high_res), segmentation.reshape(-1)].reshape((height_high_res, width_high_res))\n\n                plane_normals = calcPlaneNormals(pred_p, width_high_res, height_high_res)\n                all_normals = np.concatenate([np.expand_dims(pred_np_n, 2), plane_normals], axis=2)\n                pred_n = all_normals.reshape(-1, options.numOutputPlanes + 1, 3)[np.arange(width_high_res * height_high_res), segmentation.reshape(-1)].reshape((height_high_res, width_high_res, 3))\n\n                predDepths.append(pred_d)\n                predNormals.append(pred_n)\n                predPlanes.append(pred_p)\n                predSegmentations.append(segmentation)\n                #predDepthNormals.append(calcNormal(pred_d, info))\n                continue\n\n            #pred_dict[\'plane\'] = np.array(predPlanes)\n            pred_dict[\'segmentation\'] = np.array(predSegmentations)\n            pred_dict[\'depth\'] = np.array(predDepths)\n            pred_dict[\'normal\'] = np.array(predNormals)\n            pred_dict[\'np_depth\'] = np.array(predNonPlaneDepths)\n            #pred_dict[\'np_mask\'] = np.array(predNonPlaneMasks)\n            pred_dict[\'np_normal\'] = np.array(predNonPlaneNormals)\n            #pred_dict[\'depth_normal\'] = np.array(predDepthNormals)\n            #pred_dict[\'boundary\'] = np.array(predBoundaries)\n            pass\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n\n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return pred_dict\n\n\ndef getGroundTruth(options):\n    options.batchSize = 1\n    min_after_dequeue = 1000\n\n    reader = RecordReaderAll()\n    if options.dataset == \'SUNCG\':\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_SUNCG_val.tfrecords\'], num_epochs=10000)\n    elif options.dataset == \'NYU_RGBD_raw\':\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_nyu_rgbd_val.tfrecords\'], num_epochs=1)\n        options.deepSupervision = 0\n        options.predictLocal = 0\n    elif options.dataset == \'matterport\':\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_matterport_val.tfrecords\'], num_epochs=1)\n    elif options.dataset == \'ScanNet\':\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_scannet_val.tfrecords\'], num_epochs=1)\n    elif options.dataset == \'NYU_RGBD\':\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_nyu_rgbd_labeled_val.tfrecords\'], num_epochs=1)\n        pass\n\n\n    img_inp, global_gt_dict, local_gt_dict = reader.getBatch(filename_queue, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True, random=False)\n\n\n    training_flag = tf.constant(False, tf.bool)\n\n    # if options.dataset == \'NYU_RGBD\':\n    #     global_gt_dict[\'segmentation\'], global_gt_dict[\'plane_mask\'] = tf.ones((options.batchSize, options.height, options.width, options.numOutputPlanes)), tf.ones((options.batchSize, options.height, options.width, 1))\n    # elif options.dataset == \'SUNCG\':\n    #     normalDotThreshold = np.cos(np.deg2rad(5))\n    #     distanceThreshold = 0.05\n    #     global_gt_dict[\'segmentation\'], global_gt_dict[\'plane_mask\'] = fitPlaneMasksModule(global_gt_dict[\'plane\'], global_gt_dict[\'depth\'], global_gt_dict[\'normal\'], width=options.width, height=options.height, normalDotThreshold=normalDotThreshold, distanceThreshold=distanceThreshold, closing=True, one_hot=True)\n    # else:\n    #     global_gt_dict[\'plane_mask\'] = 1 - global_gt_dict[\'non_plane_mask\']\n    #     pass\n\n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n    gt_dict = {}\n\n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n        try:\n            gtDepths = []\n            gtNormals = []\n            planeMasks = []\n            #predMasks = []\n            gtPlanes = []\n            gtSegmentations = []\n            gtSemantics = []\n            gtInfo = []\n            gtNumPlanes = []\n            images = []\n\n            for index in xrange(options.startIndex + options.numImages):\n                print((\'image\', index))\n                t0=time.time()\n\n                img, global_gt = sess.run([img_inp, global_gt_dict])\n\n                if index < options.startIndex:\n                    continue\n\n\n                # if index == 11:\n                #     cv2.imwrite(\'test/mask.png\', drawMaskImage(global_gt[\'non_plane_mask\'].squeeze()))\n                #     exit(1)\n                image = ((img[0] + 0.5) * 255).astype(np.uint8)\n                images.append(image)\n\n                #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_boundary.png\', drawMaskImage(np.concatenate([global_gt[\'boundary\'][0], np.zeros((options.height, options.width, 1))], axis=2)))\n\n                gt_d = global_gt[\'depth\'].squeeze()\n                gtDepths.append(gt_d)\n\n                gt_n = global_gt[\'normal\'][0]\n                gtNormals.append(gt_n)\n\n                planeMask = np.squeeze(1 - global_gt[\'non_plane_mask\'])\n                planeMasks.append(planeMask)\n\n                gt_p = global_gt[\'plane\'][0]\n                gtPlanes.append(gt_p)\n\n                gt_s = global_gt[\'segmentation\'][0]\n                gtSegmentations.append(gt_s)\n\n\n                # if options.dataset != \'NYU_RGBD\':\n                #gt_s = global_gt[\'segmentation\'][0] == np.arange(options.numOutputPlanes).reshape([1, 1, -1]).astype(np.float32)\n                #planeMask = 1 - np.squeeze(global_gt[\'segmentation\'] == options.numOutputPlanes).astype(np.float32)\n                #     gt_semantics = global_gt[\'semantics\'][0]\n                # else:\n                #     semantics_path = global_gt[\'image_path\'][0].replace(\'images_rgb\', \'labels_objects\').replace(\'rgb\', \'labels\')\n                #     semantics_data = sio.loadmat(semantics_path)\n                #     gt_semantics = semantics_data[\'imgObjectLabels\']\n                #     gt_semantics = cv2.resize(gt_semantics, (options.height, options.width))\n                #     pass\n\n                gt_semantics = global_gt[\'semantics\'][0]\n                gtSemantics.append(gt_semantics)\n\n                gt_num_p = global_gt[\'num_planes\'][0]\n                gtNumPlanes.append(gt_num_p)\n\n                gtInfo.append(global_gt[\'info\'][0])\n                continue\n\n            gt_dict[\'image\'] = np.array(images)\n            gt_dict[\'depth\'] = np.array(gtDepths)\n            gt_dict[\'normal\'] = np.array(gtNormals)\n            gt_dict[\'plane_mask\'] = np.array(planeMasks)\n            gt_dict[\'plane\'] = np.array(gtPlanes)\n            gt_dict[\'segmentation\'] = np.array(gtSegmentations)\n            gt_dict[\'semantics\'] = np.array(gtSemantics)\n            gt_dict[\'num_planes\'] = np.array(gtNumPlanes)\n            gt_dict[\'info\'] = np.array(gtInfo)\n\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n\n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return gt_dict\n\n\ndef getGroundTruthHighRes(options):\n    options.batchSize = 1\n    min_after_dequeue = 1000\n\n    if options.dataset == \'SUNCG\':\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_SUNCG_val.tfrecords\'], num_epochs=10000)\n    elif options.dataset == \'NYU_RGBD_raw\':\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_nyu_rgbd_val.tfrecords\'], num_epochs=1)\n        options.deepSupervision = 0\n        options.predictLocal = 0\n    elif options.dataset == \'matterport\':\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_matterport_val.tfrecords\'], num_epochs=1)\n    elif options.dataset == \'ScanNet\':\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_scannet_val.tfrecords\'], num_epochs=1)\n    elif options.dataset == \'NYU_RGBD\':\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_nyu_rgbd_labeled_val.tfrecords\'], num_epochs=1)\n    elif options.dataset == \'Make3D\':\n        filename_queue = tf.train.string_input_producer([\'../planes_make3d_val.tfrecords\'], num_epochs=1)\n        pass\n\n    if options.dataset != \'Make3D\':\n        reader = RecordReaderAll()\n    else:\n        reader = RecordReaderMake3D()\n        pass\n\n\n    img_inp, global_gt_dict, local_gt_dict = reader.getBatch(filename_queue, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True, random=False)\n\n\n    training_flag = tf.constant(False, tf.bool)\n\n    # if options.dataset == \'NYU_RGBD\':\n    #     global_gt_dict[\'segmentation\'], global_gt_dict[\'plane_mask\'] = tf.ones((options.batchSize, options.height, options.width, options.numOutputPlanes)), tf.ones((options.batchSize, options.height, options.width, 1))\n    # elif options.dataset == \'SUNCG\':\n    #     normalDotThreshold = np.cos(np.deg2rad(5))\n    #     distanceThreshold = 0.05\n    #     global_gt_dict[\'segmentation\'], global_gt_dict[\'plane_mask\'] = fitPlaneMasksModule(global_gt_dict[\'plane\'], global_gt_dict[\'depth\'], global_gt_dict[\'normal\'], width=options.width, height=options.height, normalDotThreshold=normalDotThreshold, distanceThreshold=distanceThreshold, closing=True, one_hot=True)\n    # else:\n    #     global_gt_dict[\'plane_mask\'] = 1 - global_gt_dict[\'non_plane_mask\']\n    #     pass\n\n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n    gt_dict = {}\n\n\n    id_map = np.zeros(1300, dtype=np.uint8)\n    with open(\'../../Data/ScanNet/tasks/scannet-labels.combined.tsv\') as label_file:\n        label_reader = csv.reader(label_file, delimiter=\'\\t\')\n        for line_index, line in enumerate(label_reader):\n            if line_index > 0 and line[3] != \'\' and line[4] != \'\':\n                id_map[int(line[3])] = int(line[4])\n                pass\n            continue\n        pass\n\n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n        try:\n            gtDepths = []\n            gtNormals = []\n            planeMasks = []\n            #predMasks = []\n            gtSegmentations = []\n            gtSemantics = []\n            gtInfo = []\n            gtNumPlanes = []\n            images = []\n\n            for index in xrange(options.startIndex + options.numImages):\n                print((\'image\', index))\n                t0=time.time()\n\n                img, global_gt = sess.run([img_inp, global_gt_dict])\n\n                if index < options.startIndex:\n                    continue\n\n\n                imagePath = global_gt[\'image_path\'][0]\n\n\n                if options.dataset == \'NYU_RGBD\':\n                    image = sio.loadmat(imagePath)[\'imgRgb\']\n                    gt_d = sio.loadmat(imagePath.replace(\'rgb\', \'depth\'))[\'imgDepth\']\n                    gt_n = sio.loadmat(imagePath.replace(\'images_rgb\', \'surface_normals\').replace(\'rgb\', \'surface_normals\'))[\'imgNormals\']\n                elif options.dataset == \'Make3D\':\n                    image = ((img[0] + 0.5) * 255).astype(np.uint8)\n                    gt_d = sio.loadmat(imagePath.replace(\'images\', \'depths\').replace(\'img\', \'depth\').replace(\'.jpg\', \'.mat\'))[\'depthMap\']\n                    gt_n = global_gt[\'normal\']\n                else:\n                    image = ((img[0] + 0.5) * 255).astype(np.uint8)\n                    gt_d = global_gt[\'depth\']\n                    gt_n = global_gt[\'normal\']\n                    pass\n\n                images.append(image)\n                gtDepths.append(gt_d)\n                gtNormals.append(gt_n)\n\n                plane_data = sio.loadmat(imagePath.replace(\'images_rgb\', \'planes\').replace(\'rgb\', \'plane_data\'))[\'planeData\']\n                gt_s = (plane_data[0][0][0] - 1).astype(np.int32)\n                planes = plane_data[0][0][1]\n                numPlanes = planes.shape[0]\n                gt_s[gt_s == numPlanes] = options.numOutputPlanes\n\n                # print(gt_s.max())\n                # print(gt_s.min())\n                # print(numPlanes)\n\n                # print(NUM_PLANES)\n                # for planeIndex in xrange(numPlanes + 1):\n                #     cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(gt_s == planeIndex))\n                #     continue\n                #cv2.imwrite(\'test/segmentation.png\', drawSegmentationImage(gt_s, blackIndex=options.numOutputPlanes))\n                #exit(1)\n\n                gtSegmentations.append(gt_s)\n\n                gt_semantics = sio.loadmat(imagePath.replace(\'images_rgb\', \'labels_objects\').replace(\'rgb\', \'labels\'))[\'imgObjectLabels\']\n                gt_semantics = id_map[gt_semantics]\n                gtSemantics.append(gt_semantics)\n\n                gtNumPlanes.append(numPlanes)\n                continue\n\n            gt_dict[\'image\'] = np.array(images)\n            gt_dict[\'depth\'] = np.array(gtDepths)\n            gt_dict[\'normal\'] = np.array(gtNormals)\n            gt_dict[\'segmentation\'] = np.array(gtSegmentations)\n            gt_dict[\'semantics\'] = np.array(gtSemantics)\n            gt_dict[\'num_planes\'] = np.array(gtNumPlanes)\n\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n\n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return gt_dict\n\ndef evaluateAll(options):\n\n\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n\n    checkpoint_prefix = options.rootFolder + \'/checkpoint/\'\n\n    method = options.methods[0]\n\n\n    if \'ds0\' not in method[0]:\n        options.deepSupervisionLayers = [\'res4b22_relu\', ]\n    else:\n        options.deepSupervisionLayers = []\n        pass\n    options.predictConfidence = 0\n    options.predictLocal = 0\n    options.predictPixelwise = 1\n    options.predictBoundary = 0\n    options.anchorPlanes = 0\n    if \'ps\' in method[0] and \'hybrid_\' not in method[0]:\n        options.predictSemantics = 1\n    else:\n        options.predictSemantics = 0\n        pass\n    if \'crfrnn\' in method[0]:\n        options.crfrnn = 10\n    else:\n        options.crfrnn = 0\n        pass\n    if \'ap1\' in method[0]:\n        options.anchorPlanes = 1\n        pass\n\n    options.checkpoint_dir = checkpoint_prefix + method[0]\n    if options.hybrid != \'1\':\n        options.checkpoint_dir = options.checkpoint_dir.replace(\'hybrid1\', \'hybrid\' + str(options.hybrid))\n        pass\n\n    print(options.checkpoint_dir)\n\n    tf.reset_default_graph()\n\n    options.batchSize = 1\n    min_after_dequeue = 1000\n\n    if options.dataset == \'SUNCG\':\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_SUNCG_val.tfrecords\'], num_epochs=10000)\n    elif options.dataset == \'NYU_RGBD_raw\':\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_nyu_rgbd_val.tfrecords\'], num_epochs=1)\n        options.deepSupervision = 0\n        options.predictLocal = 0\n    elif options.dataset == \'matterport\':\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_matterport_val.tfrecords\'], num_epochs=1)\n    elif options.dataset == \'ScanNet\':\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_scannet_val.tfrecords\'], num_epochs=1)\n    elif options.dataset == \'NYU_RGBD\':\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_nyu_rgbd_labeled_val.tfrecords\'], num_epochs=1)\n    elif options.dataset == \'Make3D\':\n        filename_queue = tf.train.string_input_producer([\'../planes_make3d_val.tfrecords\'], num_epochs=1)\n        pass\n\n    if options.dataset != \'Make3D\':\n        reader = RecordReaderAll()\n    else:\n        reader = RecordReaderMake3D()\n        pass\n\n    img_inp, global_gt_dict, local_gt_dict = reader.getBatch(filename_queue, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True, random=False)\n\n\n\n    training_flag = tf.constant(False, tf.bool)\n\n    options.gpu_id = 0\n    global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp, img_inp, training_flag, options)\n\n    var_to_restore = tf.global_variables()\n\n\n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n    print(options)\n\n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n        #var_to_restore = [v for v in var_to_restore if \'res4b22_relu_non_plane\' not in v.name]\n        loader = tf.train.Saver(var_to_restore)\n        loader.restore(sess, ""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n        #loader.restore(sess, options.fineTuningCheckpoint)\n\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n\n        planenet_results = []\n        pixelwise_results = []\n\n        if options.useCache == 1:\n            planenet_results = np.load(options.test_dir + \'/planenet_results.npy\').tolist()\n            pixelwise_results = np.load(options.test_dir + \'/pixelwise_results.npy\').tolist()\n            pass\n\n        try:\n            predDepths = []\n            predNormals = []\n            predPlanes = []\n            predSegmentations = []\n            predNonPlaneDepths = []\n            predNonPlaneMasks = []\n            predNonPlaneNormals = []\n            predBoundaries = []\n            predDepthNormals = []\n            for index in xrange(options.startIndex + options.numImages):\n                if options.useCache == 1 and index < len(planenet_results):\n                    continue\n                if index % 10 == 0:\n                    print((\'image\', index))\n                    pass\n                t0=time.time()\n\n                img, global_gt, global_pred = sess.run([img_inp, global_gt_dict, global_pred_dict])\n\n                if index < options.startIndex:\n                    continue\n\n\n                info = global_gt[\'info\'][0]\n\n                width_high_res = int(info[16])\n                height_high_res = int(info[17])\n\n                pred_p = global_pred[\'plane\'][0]\n                pred_s = global_pred[\'segmentation\'][0]\n\n                pred_np_m = global_pred[\'non_plane_mask\'].squeeze()\n                pred_np_d = global_pred[\'non_plane_depth\'].squeeze()\n                pred_np_n = global_pred[\'non_plane_normal\'][0]\n\n                pred_np_m = cv2.resize(pred_np_m, (width_high_res, height_high_res), interpolation=cv2.INTER_LINEAR)\n                pred_np_m = np.expand_dims(pred_np_m, -1)\n\n                pred_np_d = cv2.resize(pred_np_d, (width_high_res, height_high_res), interpolation=cv2.INTER_LINEAR)\n                pred_np_n = cv2.resize(pred_np_n, (width_high_res, height_high_res), interpolation=cv2.INTER_LINEAR)\n                pred_np_d = np.expand_dims(pred_np_d, -1)\n\n                pred_s_high_res = []\n                for planeIndex in xrange(pred_s.shape[-1]):\n                    pred_s_high_res.append(cv2.resize(pred_s[:, :, planeIndex], (width_high_res, height_high_res), interpolation=cv2.INTER_LINEAR))\n                    continue\n                pred_s = np.stack(pred_s_high_res, axis=2)\n                #pred_b = global_pred[\'boundary\'][0]\n\n                #predNonPlaneDepths.append(pred_np_d)\n                #predNonPlaneNormals.append(pred_np_n)\n                #predBoundaries.append(pred_b)\n\n                all_segmentations = np.concatenate([pred_s, pred_np_m], axis=2)\n                plane_depths = calcPlaneDepths(pred_p, width_high_res, height_high_res, info)\n                all_depths = np.concatenate([plane_depths, pred_np_d], axis=2)\n\n                segmentation = np.argmax(all_segmentations, 2)\n                pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(width_high_res * height_high_res), segmentation.reshape(-1)].reshape((height_high_res, width_high_res))\n\n                #plane_normals = calcPlaneNormals(pred_p, width_high_res, height_high_res)\n                #all_normals = np.concatenate([plane_normals, np.expand_dims(pred_np_n, 2)], axis=2)\n                #pred_n = all_normals.reshape(-1, options.numOutputPlanes + 1, 3)[np.arange(width_high_res * height_high_res), segmentation.reshape(-1)].reshape((height_high_res, width_high_res, 3))\n\n\n                imagePath = global_gt[\'image_path\'][0]\n\n                #image = sio.loadmat(imagePath)[\'imgRgb\']\n\n\n                if options.dataset == \'NYU_RGBD\':\n                    gt_d = sio.loadmat(imagePath.replace(\'rgb\', \'depth\'))[\'imgDepth\']\n                elif options.dataset == \'Make3D\':\n                    gt_d = sio.loadmat(imagePath.replace(\'images\', \'depths\').replace(\'img\', \'depth\').replace(\'.jpg\', \'.mat\'))[\'depthMap\']\n                    planenet_result = []\n                    pred_d = cv2.resize(pred_d, (gt_d.shape[1], gt_d.shape[0]))\n                    planenet_result.append(evaluateDepths(pred_d, gt_d, np.ones(gt_d.shape)))\n                    planenet_results.append(planenet_result)\n                    continue\n                else:\n                    gt_d = global_gt[\'depth\']\n                    pass\n\n                if index < options.visualizeImages:\n                    img = sio.loadmat(imagePath)[\'imgRgb\']\n                    #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', ((img[0] + 0.5) * 255).astype(np.uint8))\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', img.astype(np.uint8))\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation.png\', drawSegmentationImage(segmentation, blackIndex=options.numOutputPlanes))\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_gt.png\', drawDepthImage(gt_d))\n                    pass\n\n                #gt_d = sio.loadmat(imagePath.replace(\'rgb\', \'depth\'))[\'imgDepth\']\n\n\n                #gt_n = sio.loadmat(imagePath.replace(\'images_rgb\', \'surface_normals\').replace(\'rgb\', \'surface_normals\'))[\'imgNormals\']\n\n                # images.append(image)\n                # gtDepths.append(gt_d)\n                # gtNormals.append(gt_n)\n\n                plane_data = sio.loadmat(imagePath.replace(\'images_rgb\', \'planes\').replace(\'rgb\', \'plane_data\'))[\'planeData\']\n                gt_s = (plane_data[0][0][0] - 1).astype(np.int32)\n                planes = plane_data[0][0][1]\n                numPlanes = planes.shape[0]\n                gt_s[gt_s == numPlanes] = options.numOutputPlanes\n\n                planeMask = gt_s < options.numOutputPlanes\n                edgeMap = calcEdgeMap(gt_s, edgeWidth=5)\n                if edgeMap.sum() == 0:\n                    edgeMap[0] = True\n                    edgeMap[-1] = True\n                    edgeMap[:, 0] = True\n                    edgeMap[:, -1] = True\n                    pass\n\n                planenet_result = []\n                print(\'image\')\n                planenet_result.append(evaluateDepths(pred_d, gt_d, np.ones(gt_d.shape)))\n                print(\'plane\')\n                planenet_result.append(evaluateDepths(pred_d, gt_d, np.ones(gt_d.shape), planeMask))\n                print(\'edge\')\n                planenet_result.append(evaluateDepths(pred_d, gt_d, np.ones(gt_d.shape), planeMasks=edgeMap))\n                planenet_results.append(planenet_result)\n\n                pixelwise_result = []\n                pred_np_d = np.squeeze(pred_np_d)\n                print(\'pixelwise\')\n                pixelwise_result.append(evaluateDepths(pred_np_d, gt_d, np.ones(gt_d.shape)))\n                pixelwise_result.append(evaluateDepths(pred_np_d, gt_d, np.ones(gt_d.shape), planeMasks=planeMask))\n                pixelwise_result.append(evaluateDepths(pred_np_d, gt_d, np.ones(gt_d.shape), planeMasks=edgeMap))\n                pixelwise_results.append(pixelwise_result)\n                #exit(1)\n\n                #cv2.imwrite(\'test/mask.png\', drawMaskImage(edgeMap))\n\n                #predDepthNormals.append(calcNormal(pred_d, info))\n                continue\n\n            #pred_dict[\'plane\'] = np.array(predPlanes)\n            #pred_dict[\'segmentation\'] = np.array(predSegmentations)\n            #pred_dict[\'depth\'] = np.array(predDepths)\n            #pred_dict[\'normal\'] = np.array(predNormals)\n            #pred_dict[\'np_depth\'] = np.array(predNonPlaneDepths)\n            #pred_dict[\'np_mask\'] = np.array(predNonPlaneMasks)\n            #pred_dict[\'np_normal\'] = np.array(predNonPlaneNormals)\n            #pred_dict[\'depth_normal\'] = np.array(predDepthNormals)\n            #pred_dict[\'boundary\'] = np.array(predBoundaries)\n            pass\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n            # if len(planenet_results) > 0:\n            #     np.save(options.test_dir + \'/planenet_results.npy\', np.array(planenet_results))\n            #     np.save(options.test_dir + \'/pixelwise_results.npy\', np.array(pixelwise_results))\n            #     pass\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n\n        planenet_results = np.array(planenet_results)\n        pixelwise_results = np.array(pixelwise_results)\n        np.save(options.test_dir + \'/planenet_results.npy\', planenet_results)\n        np.save(options.test_dir + \'/pixelwise_results.npy\', pixelwise_results)\n        print(planenet_results.mean(0))\n        print(pixelwise_results.mean(0))\n\n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return\n\nif __name__==\'__main__\':\n    """"""\n    Parse input arguments\n    """"""\n    parser = argparse.ArgumentParser(description=\'Planenet\')\n    parser.add_argument(\'--task\', dest=\'task\',\n                        help=\'task type\',\n                        default=\'all\', type=str)\n    parser.add_argument(\'--numOutputPlanes\', dest=\'numOutputPlanes\',\n                        help=\'the number of output planes\',\n                        default=20, type=int)\n    parser.add_argument(\'--dataset\', dest=\'dataset\',\n                        help=\'dataset name\',\n                        default=\'NYU_RGBD\', type=str)\n    parser.add_argument(\'--hybrid\', dest=\'hybrid\',\n                        help=\'hybrid\',\n                        default=\'1\', type=str)\n    parser.add_argument(\'--visualizeImages\', dest=\'visualizeImages\',\n                        help=\'visualize image\',\n                        default=10, type=int)\n    parser.add_argument(\'--numImages\', dest=\'numImages\',\n                        help=\'the number of images\',\n                        default=30, type=int)\n    parser.add_argument(\'--startIndex\', dest=\'startIndex\',\n                        help=\'start index\',\n                        default=0, type=int)\n    parser.add_argument(\'--useCache\', dest=\'useCache\',\n                        help=\'use cache\',\n                        default=0, type=int)\n    # parser.add_argument(\'--useCRF\', dest=\'useCRF\',\n    #                     help=\'use crf\',\n    #                     default=0, type=int)\n    # parser.add_argument(\'--useSemantics\', dest=\'useSemantics\',\n    #                     help=\'use semantics\',\n    #                     default=0, type=int)\n    parser.add_argument(\'--useNonPlaneDepth\', dest=\'useNonPlaneDepth\',\n                        help=\'use non-plane depth\',\n                        default=0, type=int)\n    parser.add_argument(\'--imageIndex\', dest=\'imageIndex\',\n                        help=\'image index\',\n                        default=-1, type=int)\n    parser.add_argument(\'--methods\', dest=\'methods\',\n                        help=\'methods\',\n                        default=\'2\', type=str)\n    parser.add_argument(\'--rootFolder\', dest=\'rootFolder\',\n                        help=\'root folder\',\n                        default=\'/mnt/vision/PlaneNet/\', type=str)\n    parser.add_argument(\'--highRes\', dest=\'highRes\',\n                        help=\'evaluate on high resolution\',\n                        default=1, type=str)\n\n    args = parser.parse_args()\n    #args.hybrid = \'hybrid\' + args.hybrid\n    args.test_dir = \'evaluate/\' + args.task + \'/\' + args.dataset + \'/hybrid\' + args.hybrid + \'_\' + args.methods\n    if args.highRes == 1:\n        args.test_dir += \'_high_res\'\n        args.width = 561\n        args.height = 427\n    else:\n        args.width = 256\n        args.height = 192\n        pass\n    args.test_dir += \'/\'\n\n    #args.visualizeImages = max(args.visualizeImages, args.numImages)\n    args.visualizeImages = args.numImages\n    if args.imageIndex >= 0:\n        args.visualizeImages = 1\n        args.numImages = 1\n        pass\n\n    args.titles = [ALL_TITLES[int(method)] for method in args.methods]\n    args.methods = [ALL_METHODS[int(method)] for method in args.methods]\n    print(args.titles)\n\n    if args.task == \'plane\':\n        evaluatePlanePrediction(args)\n    elif args.task == \'depth\':\n        evaluateDepthPrediction(args)\n    elif args.task == \'all\':\n        evaluateAll(args)\n        pass\n'"
code/evaluate_separate.py,26,"b'import tensorflow as tf\nimport numpy as np\nnp.set_printoptions(precision=2, linewidth=200)\nimport cv2\nimport os\nimport time\nimport sys\nimport tf_nndistance\nimport argparse\nimport glob\nimport PIL\nimport scipy.ndimage as ndimage\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom utils import *\nfrom plane_utils import *\nfrom modules import *\n\nfrom train_planenet import *\nfrom planenet import PlaneNet\nfrom RecordReader import *\nfrom RecordReaderRGBD import *\nfrom RecordReader3D import *\nfrom SegmentationRefinement import refineSegmentation\n\nALL_TITLES = [\'planenet\', \'pixelwise\', \'pixelwise+RANSAC\', \'depth observation+RANSAC\', \'planenet+crf\', \'pixelwise+semantics+RANSAC\', \'gt\']\nALL_METHODS = [(\'pb_pp_hybrid1\', \'\'), (\'pb_pp_hybrid1\', \'pixelwise_1\'), (\'pb_pp_hybrid1\', \'pixelwise_2\'), (\'pb_pp_hybrid1\', \'pixelwise_3\'), (\'pb_pp_hybrid1\', \'crf\'), (\'pb_pp_hybrid1\', \'pixelwise_4\'), (\'pb_pp_hybrid1\', \'gt\')]\n\ndef writeHTML(options):\n\n    from html import HTML\n    \n    h = HTML(\'html\')\n    h.p(\'Results\')\n    h.br()\n    path = \'.\'\n    #methods = [\'planenet\', \'pixelwise\', \'pixelwise+RANSAC\', \'GT+RANSAC\', \'planenet+crf\', \'pixelwise+semantics+RANSAC\']\n    #methods = [\'planenet\', \'pixelwise\', \'pixelwise+RANSAC\', \'GT+RANSAC\']\n    titles = options.titles\n    for index in xrange(options.numImages):\n\n        t = h.table(border=\'1\')\n        r_inp = t.tr()\n        r_inp.td(\'input\')\n        r_inp.td().img(src=path + \'/\' + str(index) + \'_image.png\')\n        r_inp.td().img(src=path + \'/\' + str(index) + \'_depth_gt.png\')\n        r_inp.td().img(src=path + \'/\' + str(index) + \'_segmentation_gt.png\')        \n\n        # r = t.tr()\n        # r.td(\'PlaneNet prediction\')\n        # r.td().img(src=firstFolder + \'/\' + str(index) + \'_segmentation_pred.png\')\n        # r.td().img(src=firstFolder + \'/\' + str(index) + \'_depth_pred.png\')\n\n        r = t.tr()\n        r.td(\'methods\')\n        for method_index, method in enumerate(methods):\n            r.td(method)\n            continue\n        \n        r = t.tr()\n        r.td(\'segmentation\')\n        for method_index, method in enumerate(methods):\n            r.td().img(src=path + \'/\' + str(index) + \'_segmentation_pred_\' + str(method_index) + \'.png\')\n            continue\n\n        r = t.tr()\n        r.td(\'depth\')\n        for method_index, method in enumerate(methods):\n            r.td().img(src=path + \'/\' + str(index) + \'_depth_pred_\' + str(method_index) + \'.png\')\n            continue\n        h.br()\n        continue\n\n    titles = [\'plane diff 0.1\', \'plane diff 0.3\', \'plane diff 0.5\', \'IOU 0.3\', \'IOU 0.5\', \'IOU 0.7\']\n\n    h.p(\'Curves on plane accuracy\')\n    for title in titles:\n        h.img(src=\'curve_plane_\' + title.replace(\' \', \'_\') + \'.png\')\n        continue\n    \n    h.p(\'Curves on pixel coverage\')\n    for title in titles:\n        h.img(src=\'curve_pixel_\' + title.replace(\' \', \'_\') + \'.png\')\n        continue\n    \n    \n    html_file = open(options.test_dir + \'/index.html\', \'w\')\n    html_file.write(str(h))\n    html_file.close()\n    return\n\ndef evaluatePlanePrediction(options):\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n\n    if options.useCache == 1 and os.path.exists(options.test_dir + \'/results.npy\'):\n        results = np.load(options.test_dir + \'/results.npy\')\n        results = results[()]\n    else:\n        results = getResults(options)\n        if options.useCache != -1:\n            np.save(options.test_dir + \'/results.npy\', results)\n            pass\n        pass\n    \n    gt_dict = results[\'gt\']\n    predictions = results[\'pred\']\n\n    for key, value in gt_dict.iteritems():\n        if options.imageIndex >= 0:\n            gt_dict[key] = value[options.imageIndex:options.imageIndex + 1]\n        elif value.shape[0] > options.numImages:\n            gt_dict[key] = value[:options.numImages]\n            pass\n        continue\n    for pred_dict in predictions:\n        for key, value in pred_dict.iteritems():\n            if options.imageIndex >= 0:\n                pred_dict[key] = value[options.imageIndex:options.imageIndex + 1]\n            elif value.shape[0] > options.numImages:\n                pred_dict[key] = value[:options.numImages]\n                pass\n            continue\n        continue\n\n    #methods = [\'planenet\', \'pixelwise+RANSAC\', \'GT+RANSAC\']\n    titles = options.titles\n\n    for image_index in xrange(options.visualizeImages):\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_image.png\', gt_dict[\'image\'][image_index])\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_gt.png\', drawDepthImage(gt_dict[\'depth\'][image_index]))\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_gt.png\', drawSegmentationImage(gt_dict[\'segmentation\'][image_index], planeMask=gt_dict[\'segmentation\'][image_index] < options.numOutputPlanes, black=True))\n\n        for method_index, pred_dict in enumerate(predictions):\n            cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_dict[\'depth\'][image_index]))\n\n            segmentation = pred_dict[\'segmentation\'][image_index]\n            if \'planenet\' in args.titles[method_index]:\n                segmentation = np.concatenate([segmentation, pred_dict[\'np_mask\'][image_index]], axis=2)\n                pass\n            cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(segmentation))\n            continue\n        continue\n    \n    if options.useCRF:\n        pred_dict = predictions[0]\n        predSegmentations = []\n        predDepths = []\n        for image_index in xrange(options.numImages):\n            #boundaries = pred_dict[\'boundary\'][image_index]            \n            #cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_boundary.png\', drawMaskImage(np.concatenate([boundaries, np.zeros((HEIGHT, WIDTH, 1))], axis=2)))\n\n            allSegmentations = np.concatenate([pred_dict[\'segmentation\'][image_index], pred_dict[\'np_mask\'][image_index]], axis=2)\n            planeDepths = calcPlaneDepths(pred_dict[\'plane\'][image_index], WIDTH, HEIGHT)\n            allDepths = np.concatenate([planeDepths, pred_dict[\'np_depth\'][image_index]], axis=2)\n            #boundaries = np.concatenate([np.ones((allSegmentations.shape[0], allSegmentations.shape[1], 1)), -np.ones((allSegmentations.shape[0], allSegmentations.shape[1], 1))], axis=2)\n            if options.imageIndex >= 0:\n                boundaries = cv2.imread(options.test_dir + \'/\' + str(options.imageIndex) + \'_boundary.png\')                \n            else:\n                boundaries = cv2.imread(options.test_dir + \'/\' + str(image_index) + \'_boundary.png\')\n                pass\n            boundaries = (boundaries > 128).astype(np.float32)[:, :, :2]\n            \n            pred_s = refineSegmentation(allSegmentations, allDepths, boundaries, numOutputPlanes = 20, numIterations=20, numProposals=5)\n            pred_d = allDepths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), pred_s.reshape(-1)].reshape(HEIGHT, WIDTH)\n            \n            predSegmentations.append(pred_s)\n            predDepths.append(pred_d)\n            \n            cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(4) + \'.png\', drawDepthImage(pred_d))            \n            cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(4) + \'.png\', drawSegmentationImage(pred_s))\n\n            cv2.imwrite(options.test_dir + \'/mask_\' + str(21) + \'.png\', drawDepthImage(pred_dict[\'np_depth\'][0]))\n            for plane_index in xrange(options.numOutputPlanes + 1):\n                cv2.imwrite(options.test_dir + \'/mask_\' + str(plane_index) + \'.png\', drawMaskImage(pred_s == plane_index))\n                continue\n            continue\n        \n        new_pred_dict = {}\n        for key, value in pred_dict.iteritems():\n            new_pred_dict[key] = value\n            continue\n        new_pred_dict[\'segmentation\'] = np.array(predSegmentations)\n        new_pred_dict[\'depth\'] = np.array(predDepths)\n        predictions.append(new_pred_dict)\n        methods.append(\'planenet+CRF\')\n        pass\n\n    if options.useSemantics:\n        pred_dict = predictions[1]\n        predPlanes = []        \n        predSegmentations = []\n        predDepths = []        \n        for image_index in xrange(options.numImages):\n            depth = pred_dict[\'depth\'][image_index]\n            semantics = cv2.imread(options.test_dir + \'/\' + str(image_index) + \'_semantics.png\', 0)\n            semantics = np.round(semantics.astype(np.float32) / 5)\n            if \'info\' in gt_dict:\n                options.camera = getCameraFromInfo(gt_dict[\'info\'][0])\n                pass\n            \n            pred_p, pred_s, pred_d = fitPlanesSegmentation(depth, semantics, options.camera, numPlanes=20, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=0.2)\n            predPlanes.append(pred_p)\n            predSegmentations.append(pred_s)\n            predDepths.append(pred_d)\n            \n            cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(5) + \'.png\', drawDepthImage(pred_d))\n            cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(5) + \'.png\', drawSegmentationImage(pred_s))\n            continue\n        new_pred_dict = {}\n        for key, value in pred_dict.iteritems():\n            new_pred_dict[key] = value\n            continue\n        new_pred_dict[\'segmentation\'] = np.array(predSegmentations)\n        new_pred_dict[\'depth\'] = np.array(predDepths)\n        new_pred_dict[\'plane\'] = np.array(predPlanes)\n        predictions.append(new_pred_dict)\n        methods.append(\'pixelwise+semantics+RANSAC\')\n        pass    \n    \n    #print(results)\n\n    # depth = gt_dict[\'depth\'][4]\n    # cv2.imwrite(options.test_dir + \'/test_depth_gt.png\', drawDepthImage(depth))\n    # pred_p, pred_s, pred_d = fitPlanes(depth, getSUNCGCamera(), numPlanes=20, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=0.2)\n    # cv2.imwrite(options.test_dir + \'/test_depth.png\', drawDepthImage(pred_d))\n    # cv2.imwrite(options.test_dir + \'/test_segmentation.png\', drawSegmentationImage(pred_s))\n    # exit(1)\n   \n    \n    pixel_metric_curves = [[], [], [], [], [], []]\n    plane_metric_curves = [[], [], [], [], [], []]\n    for method_index, pred_dict in enumerate(predictions):\n        if method_index == 1:\n            continue\n        segmentations = pred_dict[\'segmentation\']\n        if method_index == 0:\n            segmentations = softmax(segmentations)\n            pass\n        pixel_curves, plane_curves = evaluatePlaneSegmentation(pred_dict[\'plane\'], segmentations, gt_dict[\'plane\'], gt_dict[\'segmentation\'], gt_dict[\'num_planes\'], numOutputPlanes = options.numOutputPlanes)\n\n        for metric_index, pixel_curve in enumerate(pixel_curves):\n            pixel_metric_curves[metric_index].append(pixel_curve)\n            continue\n        for metric_index, plane_curve in enumerate(plane_curves):\n            plane_metric_curves[metric_index].append(plane_curve)\n            continue\n        continue\n\n    xs = []\n    xs.append((np.arange(11) * 0.1).tolist())\n    xs.append((np.arange(11) * 0.1).tolist())\n    xs.append((np.arange(11) * 0.1).tolist())    \n    xs.append((np.arange(11) * 0.05).tolist())\n    xs.append((np.arange(11) * 0.05).tolist())\n    xs.append((np.arange(11) * 0.05).tolist())    \n    xlabels = [\'IOU\', \'IOU\', \'IOU\', \'plane diff\', \'plane diff\', \'plane diff\']\n    titles = [\'plane diff 0.1\', \'plane diff 0.3\', \'plane diff 0.5\', \'IOU 0.3\', \'IOU 0.5\', \'IOU 0.7\']\n    for metric_index, curves in enumerate(pixel_metric_curves):\n        filename = options.test_dir + \'/curve_pixel_\' + titles[metric_index].replace(\' \', \'_\') + \'.png\'\n        plotCurves(xs[metric_index], curves, filename = filename, xlabel=xlabels[metric_index], ylabel=\'pixel coverage\', title=titles[metric_index], labels=titles)\n        continue\n    for metric_index, curves in enumerate(plane_metric_curves):\n        filename = options.test_dir + \'/curve_plane_\' + titles[metric_index].replace(\' \', \'_\') + \'.png\'\n        plotCurves(xs[metric_index], curves, filename = filename, xlabel=xlabels[metric_index], ylabel=\'plane accuracy\', title=titles[metric_index], labels=titles)\n        continue\n\n    \n    return\n\n\ndef evaluateDepthPrediction(options):\n    writeHTML(options)\n    return\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n\n    if options.useCache == 1 and os.path.exists(options.test_dir + \'/results.npy\'):\n        results = np.load(options.test_dir + \'/results.npy\')\n        results = results[()]\n    else:\n        results = getResults(options)\n        if options.useCache != -1:\n            np.save(options.test_dir + \'/results.npy\', results)\n            pass\n        pass\n    \n    gt_dict = results[\'gt\']\n    predictions = results[\'pred\']\n\n    for key, value in gt_dict.iteritems():\n        if options.imageIndex >= 0:\n            gt_dict[key] = value[options.imageIndex:options.imageIndex + 1]\n        elif value.shape[0] > options.numImages:\n            gt_dict[key] = value[:options.numImages]\n            pass\n        continue\n    for pred_dict in predictions:\n        for key, value in pred_dict.iteritems():\n            if options.imageIndex >= 0:\n                pred_dict[key] = value[options.imageIndex:options.imageIndex + 1]\n            elif value.shape[0] > options.numImages:\n                pred_dict[key] = value[:options.numImages]\n                pass\n            continue\n        continue\n\n    titles = options.titles\n\n\n    for image_index in xrange(options.visualizeImages):\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_image.png\', gt_dict[\'image\'][image_index])\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_gt.png\', drawDepthImage(gt_dict[\'depth\'][image_index]))\n        #cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_gt.png\', drawSegmentationImage(gt_dict[\'segmentation\'][image_index]))\n\n        for method_index, pred_dict in enumerate(predictions):\n            cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_dict[\'depth\'][image_index]))\n\n            # segmentation = pred_dict[\'segmentation\'][image_index]\n            # if method_index == 0:\n            #     segmentation = np.concatenate([segmentation, pred_dict[\'np_mask\'][image_index]], axis=2)\n            #     pass\n            # cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(segmentation))\n            continue\n        continue\n    \n    if options.useCRF:\n        pred_dict = predictions[0]\n        predSegmentations = []\n        predDepths = []\n        for image_index in xrange(options.numImages):\n            #boundaries = pred_dict[\'boundary\'][image_index]            \n            #cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_boundary.png\', drawMaskImage(np.concatenate([boundaries, np.zeros((HEIGHT, WIDTH, 1))], axis=2)))\n\n            allSegmentations = np.concatenate([pred_dict[\'segmentation\'][image_index], pred_dict[\'np_mask\'][image_index]], axis=2)\n            planeDepths = calcPlaneDepths(pred_dict[\'plane\'][image_index], WIDTH, HEIGHT)\n            allDepths = np.concatenate([planeDepths, pred_dict[\'np_depth\'][image_index]], axis=2)\n            #boundaries = np.concatenate([np.ones((allSegmentations.shape[0], allSegmentations.shape[1], 1)), -np.ones((allSegmentations.shape[0], allSegmentations.shape[1], 1))], axis=2)\n            if options.imageIndex >= 0:\n                boundaries = cv2.imread(options.test_dir + \'/\' + str(options.imageIndex) + \'_boundary.png\')                \n            else:\n                boundaries = cv2.imread(options.test_dir + \'/\' + str(image_index) + \'_boundary.png\')\n                pass\n            boundaries = (boundaries > 128).astype(np.float32)[:, :, :2]\n            \n            pred_s = refineSegmentation(allSegmentations, allDepths, boundaries, numOutputPlanes = 20, numIterations=20, numProposals=5)\n            pred_d = allDepths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), pred_s.reshape(-1)].reshape(HEIGHT, WIDTH)\n            \n            predSegmentations.append(pred_s)\n            predDepths.append(pred_d)\n            \n            cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(4) + \'.png\', drawDepthImage(pred_d))            \n            cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(4) + \'.png\', drawSegmentationImage(pred_s))\n\n            cv2.imwrite(options.test_dir + \'/mask_\' + str(21) + \'.png\', drawDepthImage(pred_dict[\'np_depth\'][0]))\n            for plane_index in xrange(options.numOutputPlanes + 1):\n                cv2.imwrite(options.test_dir + \'/mask_\' + str(plane_index) + \'.png\', drawMaskImage(pred_s == plane_index))\n                continue\n            continue\n        \n        new_pred_dict = {}\n        for key, value in pred_dict.iteritems():\n            new_pred_dict[key] = value\n            continue\n        new_pred_dict[\'segmentation\'] = np.array(predSegmentations)\n        new_pred_dict[\'depth\'] = np.array(predDepths)\n        predictions.append(new_pred_dict)\n        methods.append(\'planenet+CRF\')\n        pass\n\n    if options.useSemantics:\n        pred_dict = predictions[1]\n        predPlanes = []        \n        predSegmentations = []\n        predDepths = []        \n        for image_index in xrange(options.numImages):\n            depth = pred_dict[\'depth\'][image_index]\n            semantics = cv2.imread(options.test_dir + \'/\' + str(image_index) + \'_semantics.png\', 0)\n            semantics = np.round(semantics.astype(np.float32) / 5)\n            pred_p, pred_s, pred_d = fitPlanesSegmentation(depth, semantics, options.camera, numPlanes=20, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=0.2)\n            predPlanes.append(pred_p)\n            predSegmentations.append(pred_s)\n            predDepths.append(pred_d)\n            \n            cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(5) + \'.png\', drawDepthImage(pred_d))\n            cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(5) + \'.png\', drawSegmentationImage(pred_s))\n            continue\n        new_pred_dict = {}\n        for key, value in pred_dict.iteritems():\n            new_pred_dict[key] = value\n            continue\n        new_pred_dict[\'segmentation\'] = np.array(predSegmentations)\n        new_pred_dict[\'depth\'] = np.array(predDepths)\n        new_pred_dict[\'plane\'] = np.array(predPlanes)\n        predictions.append(new_pred_dict)\n        methods.append(\'pixelwise+semantics+RANSAC\')\n        pass    \n    \n    #print(results)\n\n    # depth = gt_dict[\'depth\'][4]\n    # cv2.imwrite(options.test_dir + \'/test_depth_gt.png\', drawDepthImage(depth))\n    # pred_p, pred_s, pred_d = fitPlanes(depth, getSUNCGCamera(), numPlanes=20, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=0.2)\n    # cv2.imwrite(options.test_dir + \'/test_depth.png\', drawDepthImage(pred_d))\n    # cv2.imwrite(options.test_dir + \'/test_segmentation.png\', drawSegmentationImage(pred_s))\n    # exit(1)\n\n    for method_index, pred_dict in enumerate(predictions):\n        print(methods[method_index])\n        evaluateDepths(pred_dict[\'depth\'], gt_dict[\'depth\'], np.ones(gt_dict[\'depth\'].shape))\n        continue\n    return\n\ndef getResults(options):\n    checkpoint_prefix = \'checkpoint/planenet_\'\n\n    methods = options.methods\n    \n    gt_dict = getGroundTruth(options)\n\n    \n    options.deepSupervisionLayers = [\'res4b22_relu\', ]\n    options.predictConfidence = 0\n    options.predictLocal = 0\n    options.predictPixelwise = 1\n    options.predictBoundary = 1\n\n    predictions = []\n    for method_index, method in enumerate(methods):\n        options.checkpoint_dir = checkpoint_prefix + method[0]\n        options.suffix = method[1]\n\n        pred_dict = getPrediction(options)\n\n        # for image_index in xrange(options.visualizeImages):\n        #     cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_dict[\'depth\'][image_index]))\n        #     cv2.imwrite(options.test_dir + \'/\' + str(image_index) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage())\n        #     continue\n        \n        predictions.append(pred_dict)\n        continue\n    #np.save(options.test_dir + \'/curves.npy\', curves)\n    results = {\'gt\': gt_dict, \'pred\': predictions}\n    return results\n\ndef getPrediction(options):\n    tf.reset_default_graph()\n    \n    options.batchSize = 1\n    min_after_dequeue = 1000\n\n    if options.dataset == \'SUNCG\':\n        reader = RecordReader()\n        filename_queue = tf.train.string_input_producer([\'/home/chenliu/Projects/Data/SUNCG_plane/planes_test_1000_450000.tfrecords\'], num_epochs=10000)\n        img_inp, global_gt_dict, local_gt_dict = reader.getBatch(filename_queue, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True, random=False)\n    elif options.dataset == \'NYU_RGBD\':\n        reader = RecordReaderRGBD()\n        filename_queue = tf.train.string_input_producer([\'../planes_nyu_rgbd_val.tfrecords\'], num_epochs=1)\n        img_inp, global_gt_dict, local_gt_dict = reader.getBatch(filename_queue, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True, random=False)\n\n        options.deepSupervision = 0\n        options.predictLocal = 0\n    else:\n        reader = RecordReader3D()\n        filename_queue = tf.train.string_input_producer([\'../planes_matterport_val.tfrecords\'], num_epochs=1)\n        img_inp, global_gt_dict, local_gt_dict = reader.getBatch(filename_queue, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True, random=False)\n        \n        options.deepSupervision = 0\n        options.predictLocal = 0\n        pass\n\n    \n    training_flag = tf.constant(1, tf.int32)\n\n    options.gpu_id = 0\n    global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp, img_inp, img_inp, img_inp, img_inp, img_inp, training_flag, options)\n\n    var_to_restore = tf.global_variables()\n\n\n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n    pred_dict = {}\n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n        #var_to_restore = [v for v in var_to_restore if \'res4b22_relu_non_plane\' not in v.name]\n        loader = tf.train.Saver(var_to_restore)\n        loader.restore(sess, ""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n        #loader.restore(sess, options.fineTuningCheckpoint)\n        \n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n        \n        \n        try:\n            predDepths = []\n            predPlanes = []\n            predSegmentations = []\n            predNonPlaneDepths = []\n            predNonPlaneMasks = []\n            predBoundaries = []            \n            for index in xrange(options.numImages):\n                if index % 10 == 0:\n                    print((\'image\', index))\n                    pass\n                t0=time.time()\n\n                img, global_gt, global_pred = sess.run([img_inp, global_gt_dict, global_pred_dict])\n\n                if \'info\' in global_gt:\n                    options.camera = getCameraFromInfo(global_gt[\'info\'][0])\n                    pass\n                \n                if \'pixelwise\' in options.suffix:\n                    pred_d = global_pred[\'non_plane_depth\'].squeeze()\n                    #depth = global_gt[\'depth\'].squeeze()\n                    if \'_1\' in options.suffix:\n                        predDepths.append(pred_d)\n                        continue\n                    elif \'_2\' in options.suffix:\n                        pred_p, pred_s, pred_d = fitPlanes(pred_d, options.camera, numPlanes=20, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=0.2)\n                    elif \'_3\' in options.suffix:\n                        pred_p, pred_s, pred_d = fitPlanes(global_gt[\'depth\'].squeeze(), options.camera, numPlanes=20, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=0.2)\n                    else:\n                        pred_p = np.zeros((options.numOutputPlanes, 3))\n                        pred_s = np.zeros((HEIGHT, WIDTH, options.numOutputPlanes))\n                        pass\n                    pass\n                elif options.suffix == \'gt\':\n                    pred_p = global_gt[\'plane\'][0]\n                    pred_s = global_gt[\'segmentation\'][0]\n                    \n                    pred_np_m = global_gt[\'non_plane_mask\'][0]\n                    pred_np_d = global_gt[\'depth\'][0]\n\n                    #pred_b = global_gt[\'boundary\'][0]\n                    #predBoundaries.append(pred_b)\n                    \n                    all_segmentations = np.concatenate([pred_np_m, pred_s], axis=2)\n                    plane_depths = calcPlaneDepths(pred_p, WIDTH, HEIGHT)\n                    all_depths = np.concatenate([pred_np_d, plane_depths], axis=2)\n\n                    segmentation = np.argmax(all_segmentations, 2)\n                    pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape(HEIGHT, WIDTH)                    \n                else:\n                    pred_p = global_pred[\'plane\'][0]\n                    pred_s = global_pred[\'segmentation\'][0]\n                        \n                    pred_np_m = global_pred[\'non_plane_mask\'][0]\n                    pred_np_d = global_pred[\'non_plane_depth\'][0]\n                    pred_np_n = global_pred[\'non_plane_normal\'][0]\n\n                    pred_b = global_pred[\'boundary\'][0]\n                    predNonPlaneMasks.append(pred_np_m)                    \n                    predNonPlaneDepths.append(pred_np_d)\n                    predBoundaries.append(pred_b)\n                    \n                    all_segmentations = np.concatenate([pred_np_m, pred_s], axis=2)\n                    plane_depths = calcPlaneDepths(pred_p, WIDTH, HEIGHT)\n                    all_depths = np.concatenate([pred_np_d, plane_depths], axis=2)\n\n                    segmentation = np.argmax(all_segmentations, 2)\n                    pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape(HEIGHT, WIDTH)\n                    pass\n                \n                predDepths.append(pred_d)\n                predPlanes.append(pred_p)\n                predSegmentations.append(pred_s)\n                pass\n                    \n                continue\n            pred_dict[\'plane\'] = np.array(predPlanes)\n            pred_dict[\'segmentation\'] = np.array(predSegmentations)\n            pred_dict[\'depth\'] = np.array(predDepths)\n            pred_dict[\'np_depth\'] = np.array(predNonPlaneDepths)\n            pred_dict[\'np_mask\'] = np.array(predNonPlaneMasks)\n            pred_dict[\'boundary\'] = np.array(predBoundaries)\n            pass\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n        \n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return pred_dict\n\ndef getGroundTruth(options):    \n    options.batchSize = 1\n    min_after_dequeue = 1000\n\n    if options.dataset == \'SUNCG\':\n        reader = RecordReader()\n        filename_queue = tf.train.string_input_producer([\'/home/chenliu/Projects/Data/SUNCG_plane/planes_test_1000_450000.tfrecords\'], num_epochs=10000)\n        img_inp, global_gt_dict, local_gt_dict = reader.getBatch(filename_queue, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True, random=False)\n    elif options.dataset == \'NYU_RGBD\':\n        reader = RecordReaderRGBD()\n        filename_queue = tf.train.string_input_producer([\'../planes_nyu_rgbd_val.tfrecords\'], num_epochs=1)\n        img_inp, global_gt_dict, local_gt_dict = reader.getBatch(filename_queue, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True, random=False)\n\n        options.deepSupervision = 0\n        options.predictLocal = 0\n    else:\n        reader = RecordReader3D()\n        filename_queue = tf.train.string_input_producer([\'../planes_matterport_val.tfrecords\'], num_epochs=1)\n        img_inp, global_gt_dict, local_gt_dict = reader.getBatch(filename_queue, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True, random=False)\n        \n        options.deepSupervision = 0\n        options.predictLocal = 0        \n        pass\n\n    training_flag = tf.constant(1, tf.int32)\n\n    if options.dataset == \'NYU_RGBD\':\n        global_gt_dict[\'segmentation\'], global_gt_dict[\'plane_mask\'] = tf.ones((options.batchSize, HEIGHT, WIDTH, options.numOutputPlanes)), tf.ones((options.batchSize, HEIGHT, WIDTH, 1))\n    elif options.dataset == \'SUNCG\':\n        normalDotThreshold = np.cos(np.deg2rad(5))\n        distanceThreshold = 0.05        \n        global_gt_dict[\'segmentation\'], global_gt_dict[\'plane_mask\'] = fitPlaneMasksModule(global_gt_dict[\'plane\'], global_gt_dict[\'depth\'], global_gt_dict[\'normal\'], width=WIDTH, height=HEIGHT, normalDotThreshold=normalDotThreshold, distanceThreshold=distanceThreshold, closing=True, one_hot=True)\n    else:\n        global_gt_dict[\'plane_mask\'] = 1 - global_gt_dict[\'non_plane_mask\']\n        pass\n\n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n    gt_dict = {}\n    \n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n        \n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)        \n        \n        try:\n            gtDepths = []\n            planeMasks = []\n            #predMasks = []\n            gtPlanes = []\n            gtSegmentations = []\n            gtInfo = []\n            gtNumPlanes = []            \n            images = []\n\n            for index in xrange(options.numImages):\n                print((\'image\', index))\n                t0=time.time()\n\n                img, global_gt = sess.run([img_inp, global_gt_dict])\n\n                image = ((img[0] + 0.5) * 255).astype(np.uint8)\n                images.append(image)\n\n                #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_boundary.png\', drawMaskImage(np.concatenate([global_gt[\'boundary\'][0], np.zeros((HEIGHT, WIDTH, 1))], axis=2)))\n                \n                gt_d = global_gt[\'depth\'].squeeze()\n                gtDepths.append(gt_d)\n\n                planeMask = np.squeeze(global_gt[\'plane_mask\'])                    \n                planeMasks.append(planeMask)\n                \n                if options.dataset != \'NYU_RGBD\':\n                    gt_p = global_gt[\'plane\'][0]\n                    gtPlanes.append(gt_p)\n                    \n                    gt_s = global_gt[\'segmentation\'][0]\n                    gtSegmentations.append(gt_s)\n                \n                    gt_num_p = global_gt[\'num_planes\'][0]\n                    gtNumPlanes.append(gt_num_p)\n                    pass\n                if \'info\' in global_gt:\n                    gtInfo.append(global_gt[\'info\'][0])\n                    pass\n                continue\n\n            gt_dict[\'image\'] = np.array(images)\n            gt_dict[\'depth\'] = np.array(gtDepths)\n            gt_dict[\'plane_mask\'] = np.array(planeMasks)\n            gt_dict[\'plane\'] = np.array(gtPlanes)\n            gt_dict[\'segmentation\'] = np.array(gtSegmentations)\n            gt_dict[\'num_planes\'] = np.array(gtNumPlanes)\n            gt_dict[\'info\'] = np.array(gtInfo)\n\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n        \n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return gt_dict\n\n\nif __name__==\'__main__\':\n    """"""\n    Parse input arguments\n    """"""\n    parser = argparse.ArgumentParser(description=\'Planenet\')\n    parser.add_argument(\'--task\', dest=\'task\',\n                        help=\'task type\',\n                        default=\'plane\', type=str)\n    parser.add_argument(\'--numOutputPlanes\', dest=\'numOutputPlanes\',\n                        help=\'the number of output planes\',\n                        default=20, type=int)\n    parser.add_argument(\'--dataset\', dest=\'dataset\',\n                        help=\'dataset name\',\n                        default=\'SUNCG\', type=str)\n    parser.add_argument(\'--visualizeImages\', dest=\'visualizeImages\',\n                        help=\'visualize image\',\n                        default=10, type=int)    \n    parser.add_argument(\'--numImages\', dest=\'numImages\',\n                        help=\'the number of images\',\n                        default=10, type=int)\n    parser.add_argument(\'--useCache\', dest=\'useCache\',\n                        help=\'use cache\',\n                        default=1, type=int)\n    parser.add_argument(\'--useCRF\', dest=\'useCRF\',\n                        help=\'use crf\',\n                        default=0, type=int)\n    parser.add_argument(\'--useSemantics\', dest=\'useSemantics\',\n                        help=\'use semantics\',\n                        default=0, type=int)\n    parser.add_argument(\'--useNonPlaneDepth\', dest=\'useNonPlaneDepth\',\n                        help=\'use non-plane depth\',\n                        default=0, type=int)\n    parser.add_argument(\'--imageIndex\', dest=\'imageIndex\',\n                        help=\'image index\',\n                        default=-1, type=int)\n    parser.add_argument(\'--methods\', dest=\'methods\',\n                        help=\'methods\',\n                        default=\'0 1 2 3 4 5\', type=str)\n    \n    args = parser.parse_args()\n    args.test_dir = \'evaluate/\' + args.task + \'/\' + args.dataset + \'/\'\n    args.visualizeImages = min(args.visualizeImages, args.numImages)\n    if args.imageIndex >= 0:\n        args.visualizeImages = 1\n        args.numImages = 1            \n        pass\n\n    if args.dataset == \'SUNCG\':\n        args.camera = getSUNCGCamera()\n    elif args.dataset == \'NYU_RGBD\':\n        args.camera = getNYURGBDCamera()\n    else:\n        args.camera = get3DCamera()\n        pass\n\n    args.titles = [ALL_TITLES[int(method)] for method in args.methods.split(\' \')]\n    args.methods = [ALL_METHODS[int(method)] for method in args.methods.split(\' \')]\n    \n    print(args.titles)\n    \n    if args.task == \'plane\':\n        evaluatePlanePrediction(args)\n    elif args.task == \'depth\':\n        evaluateDepthPrediction(args)\n        pass\n\n        pass\n'"
code/high_dim_filter_grad.py,2,"b'""""""\nMIT License\n\nCopyright (c) 2017 Sadeep Jayasumana\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the ""Software""), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n""""""\n\nimport tensorflow as tf\nfrom tensorflow.python.framework import ops\ncustom_module = tf.load_op_library(\'./cpp/high_dim_filter.so\')\n\n\n@ops.RegisterGradient(""HighDimFilter"")\ndef _high_dim_filter_grad(op, grad):\n    """""" Gradients for the HighDimFilter op. We only need to calculate the gradients\n    w.r.t. the first input (unaries) as we never need to backprop errors to the\n    second input (RGB values of the image).\n\n    Args:\n    op: The `high_dim_filter` operation that we are differentiating.\n    grad: Gradients with respect to the output of the `high_dim_filter` op.\n\n    Returns:\n    Gradients with respect to the input of `high_dim_filter`.\n    """"""\n\n    rgb = op.inputs[1]\n    grad_vals = custom_module.high_dim_filter(grad, rgb,\n                                              bilateral=op.get_attr(""bilateral""),\n                                              theta_alpha=op.get_attr(""theta_alpha""),\n                                              theta_beta=op.get_attr(""theta_beta""),\n                                              theta_gamma=op.get_attr(""theta_gamma""),\n                                              backwards=True)\n\n    return [grad_vals, tf.zeros_like(rgb)]\n'"
code/html.py,0,"b'# -*- encoding: utf8 -*-\n#\n# $Id: html.py 5409 2011-06-29 07:07:25Z rjones $\n# $HeadURL: svn+ssh://svn/svn/trunk/api/eklib/html.py $\n#\n\'\'\'Simple, elegant HTML, XHTML and XML generation.\n\nConstructing your HTML\n----------------------\n\nTo construct HTML start with an instance of ``html.HTML()``. Add\ntags by accessing the tag\'s attribute on that object. For example:\n\n>>> from html import HTML\n>>> h = HTML()\n>>> h.p(\'Hello, world!\')\n>>> print h                          # or print(h) in python 3+\n<p>Hello, world!</p>\n\nYou may supply a tag name and some text contents when creating a HTML\ninstance:\n\n>>> h = HTML(\'html\', \'text\')\n>>> print h\n<html>text</html>\n\nYou may also append text content later using the tag\'s ``.text()`` method\nor using augmented addition ``+=``. Any HTML-specific characters (``<>&""``)\nin the text will be escaped for HTML safety as appropriate unless\n``escape=False`` is passed. Each of the following examples uses a new\n``HTML`` instance:\n\n>>> p = h.p(\'hello world!\\\\n\')\n>>> p.br\n>>> p.text(\'more &rarr; text\', escape=False)\n>>> p += \' ... augmented\'\n>>> h.p\n>>> print h\n<p>hello, world!<br>more &rarr; text ... augmented</p>\n<p>\n\nNote also that the top-level ``HTML`` object adds newlines between tags by\ndefault. Finally in the above you\'ll see an empty paragraph tag - tags with\nno contents get no closing tag.\n\nIf the tag should have sub-tags you have two options. You may either add\nthe sub-tags directly on the tag:\n\n>>> l = h.ol\n>>> l.li(\'item 1\')\n>>> l.li.b(\'item 2 > 1\')\n>>> print h\n<ol>\n<li>item 1</li>\n<li><b>item 2 &gt; 1</b></li>\n</ol>\n\nNote that the default behavior with lists (and tables) is to add newlines\nbetween sub-tags to generate a nicer output. You can also see in that\nexample the chaining of tags in ``l.li.b``.\n\nTag attributes may be passed in as well:\n\n>>> t = h.table(border=\'1\')\n>>> for i in range(2):\n>>>   r = t.tr\n>>>   r.td(\'column 1\')\n>>>   r.td(\'column 2\')\n>>> print t\n<table border=""1"">\n<tr><td>column 1</td><td>column 2</td></tr>\n<tr><td>column 1</td><td>column 2</td></tr>\n</table>\n\nA variation on the above is to use a tag as a context variable. The\nfollowing is functionally identical to the first list construction but\nwith a slightly different sytax emphasising the HTML structure:\n\n>>> with h.ol as l:\n...   l.li(\'item 1\')\n...   l.li.b(\'item 2 > 1\')\n\nYou may turn off/on adding newlines by passing ``newlines=False`` or\n``True`` to the tag (or ``HTML`` instance) at creation time:\n\n>>> l = h.ol(newlines=False)\n>>> l.li(\'item 1\')\n>>> l.li(\'item 2\')\n>>> print h\n<ol><li>item 1</li><li>item 2</li></ol>\n\nSince we can\'t use ``class`` as a keyword, the library recognises ``klass``\nas a substitute:\n\n>>> print h.p(content, klass=""styled"")\n<p class=""styled"">content</p>\n\n\nUnicode\n-------\n\n``HTML`` will work with either regular strings **or** unicode strings, but\nnot **both at the same time**.\n\nObtain the final unicode string by calling ``unicode()`` on the ``HTML``\ninstance:\n\n>>> h = HTML()\n>>> h.p(u\'Some Euro: \xe2\x82\xac1.14\')\n>>> unicode(h)\nu\'<p>Some Euro: \xe2\x82\xac1.14</p>\'\n\nIf (under Python 2.x) you add non-unicode strings or attempt to get the\nresultant HTML source through any means other than ``unicode()`` then you\nwill most likely get one of the following errors raised:\n\nUnicodeDecodeError\n   Probably means you\'ve added non-unicode strings to your HTML.\nUnicodeEncodeError\n   Probably means you\'re trying to get the resultant HTML using ``print``\n   or ``str()`` (or ``%s``).\n\n\nHow generation works\n--------------------\n\nThe HTML document is generated when the ``HTML`` instance is ""stringified"".\nThis could be done either by invoking ``str()`` on it, or just printing it.\nIt may also be returned directly as the ""iterable content"" from a WSGI app\nfunction.\n\nYou may also render any tag or sub-tag at any time by stringifying it.\n\nTags with no contents (either text or sub-tags) will have no closing tag.\nThere is no ""special list"" of tags that must always have closing tags, so\nif you need to force a closing tag you\'ll need to provide some content,\neven if it\'s just a single space character.\n\nRendering doesn\'t affect the HTML document\'s state, so you can add to or\notherwise manipulate the HTML after you\'ve stringified it.\n\n\nCreating XHTML\n--------------\n\nTo construct XHTML start with an instance of ``html.XHTML()`` and use it\nas you would an ``HTML`` instance. Empty elements will now be rendered\nwith the appropriate XHTML minimized tag syntax. For example:\n\n>>> from html import XHTML\n>>> h = XHTML()\n>>> h.p\n>>> h.br\n>>> print h\n<p></p>\n<br />\n\n\nCreating XML\n------------\n\nA slight tweak to the ``html.XHTML()`` implementation allows us to generate\narbitrary XML using ``html.XML()``:\n\n>>> from html import XML\n>>> h = XML(\'xml\')\n>>> h.p\n>>> h.br(\'hi there\')\n>>> print h\n<xml>\n<p />\n<br>hi there</br>\n</xml>\n\n\nTags with difficult names\n-------------------------\n\nIf your tag name isn\'t a valid Python identifier name, or if it\'s called\n""text"" or ""raw_text"" you can add your tag slightly more manually:\n\n>>> from html import XML\n>>> h = XML(\'xml\')\n>>> h += XML(\'some-tag\', \'some text\')\n>>> h += XML(\'text\', \'some text\')\n>>> print h\n<xml>\n<some-tag>some text</some-tag>\n<text>some text</text>\n</xml>\n\n\nVersion History (in Brief)\n--------------------------\n\n- 1.16 detect and raise a more useful error when some WSGI frameworks\n  attempt to call HTML.read(). Also added ability to add new content using\n  the += operator.\n- 1.15 fix Python 3 compatibility (unit tests)\n- 1.14 added plain XML support\n- 1.13 allow adding (X)HTML instances (tags) as new document content\n- 1.12 fix handling of XHTML empty tags when generating unicode\n  output (thanks Carsten Eggers)\n- 1.11 remove setuptools dependency\n- 1.10 support plain ol\' distutils again\n- 1.9 added unicode support for Python 2.x\n- 1.8 added Python 3 compatibility\n- 1.7 added Python 2.5 compatibility and escape argument to tag\n  construction\n- 1.6 added .raw_text() and and WSGI compatibility\n- 1.5 added XHTML support\n- 1.3 added more documentation, more tests\n- 1.2 added special-case klass / class attribute\n- 1.1 added escaping control\n- 1.0 was the initial release\n\n----\n\nI would be interested to know whether this module is useful - if you use it\nplease indicate so at https://www.ohloh.net/p/pyhtml\n\nThis code is copyright 2009-2011 eKit.com Inc (http://www.ekit.com/)\nSee the end of the source file for the license of use.\nXHTML support was contributed by Michael Haubenwallner.\n\'\'\'\nfrom __future__ import with_statement\n__version__ = \'1.16\'\n\nimport sys\nimport cgi\nimport unittest\n\n\nclass HTML(object):\n    \'\'\'Easily generate HTML.\n\n    >>> print HTML(\'html\', \'some text\')\n    <html>some text</html>\n    >>> print HTML(\'html\').p(\'some text\')\n    <html><p>some text</p></html>\n\n    If a name is not passed in then the instance becomes a container for\n    other tags that itself generates no tag:\n\n    >>> h = HTML()\n    >>> h.p(\'text\')\n    >>> h.p(\'text\')\n    print h\n    <p>some text</p>\n    <p>some text</p>\n\n    \'\'\'\n    newline_default_on = set(\'table ol ul dl\'.split())\n\n    def __init__(self, name=None, text=None, stack=None, newlines=True,\n            escape=True):\n        self._name = name\n        self._content = []\n        self._attrs = {}\n        # insert newlines between content?\n        if stack is None:\n            stack = [self]\n            self._top = True\n            self._newlines = newlines\n        else:\n            self._top = False\n            self._newlines = name in self.newline_default_on\n        self._stack = stack\n        if text is not None:\n            self.text(text, escape)\n\n    def __getattr__(self, name):\n        # adding a new tag or newline\n        if name == \'newline\':\n            e = \'\\n\'\n        else:\n            e = self.__class__(name, stack=self._stack)\n        if self._top:\n            self._stack[-1]._content.append(e)\n        else:\n            self._content.append(e)\n        return e\n\n    def __iadd__(self, other):\n        if self._top:\n            self._stack[-1]._content.append(other)\n        else:\n            self._content.append(other)\n        return self\n\n    def text(self, text, escape=True):\n        \'\'\'Add text to the document. If ""escape"" is True any characters\n        special to HTML will be escaped.\n        \'\'\'\n        if escape:\n            text = cgi.escape(text)\n        # adding text\n        if self._top:\n            self._stack[-1]._content.append(text)\n        else:\n            self._content.append(text)\n\n    def raw_text(self, text):\n        \'\'\'Add raw, unescaped text to the document. This is useful for\n        explicitly adding HTML code or entities.\n        \'\'\'\n        return self.text(text, escape=False)\n\n    def __call__(self, *content, **kw):\n        if self._name == \'read\':\n            if len(content) == 1 and isinstance(content[0], int):\n                raise TypeError(\'you appear to be calling read(%d) on \'\n                    \'a HTML instance\' % content)\n            elif len(content) == 0:\n                raise TypeError(\'you appear to be calling read() on a \'\n                    \'HTML instance\')\n\n        # customising a tag with content or attributes\n        escape = kw.pop(\'escape\', True)\n        if content:\n            if escape:\n                self._content = list(map(cgi.escape, content))\n            else:\n                self._content = content\n        if \'newlines\' in kw:\n            # special-case to allow control over newlines\n            self._newlines = kw.pop(\'newlines\')\n        for k in kw:\n            if k == \'klass\':\n                self._attrs[\'class\'] = cgi.escape(kw[k], True)\n            else:\n                self._attrs[k] = cgi.escape(kw[k], True)\n        return self\n\n    def __enter__(self):\n        # we\'re now adding tags to me!\n        self._stack.append(self)\n        return self\n\n    def __exit__(self, exc_type, exc_value, exc_tb):\n        # we\'re done adding tags to me!\n        self._stack.pop()\n\n    def __repr__(self):\n        return \'<HTML %s 0x%x>\' % (self._name, id(self))\n\n    def _stringify(self, str_type):\n        # turn me and my content into text\n        join = \'\\n\' if self._newlines else \'\'\n        if self._name is None:\n            return join.join(map(str_type, self._content))\n        a = [\'%s=""%s""\' % i for i in self._attrs.items()]\n        l = [self._name] + a\n        s = \'<%s>%s\' % (\' \'.join(l), join)\n        if self._content:\n            s += join.join(map(str_type, self._content))\n            s += join + \'</%s>\' % self._name\n        return s\n\n    def __str__(self):\n        return self._stringify(str)\n\n    def __unicode__(self):\n        return self._stringify(unicode)\n\n    def __iter__(self):\n        return iter([str(self)])\n\n\nclass XHTML(HTML):\n    \'\'\'Easily generate XHTML.\n    \'\'\'\n    empty_elements = set(\'base meta link hr br param img area input col \\\n        colgroup basefont isindex frame\'.split())\n\n    def _stringify(self, str_type):\n        # turn me and my content into text\n        # honor empty and non-empty elements\n        join = \'\\n\' if self._newlines else \'\'\n        if self._name is None:\n            return join.join(map(str_type, self._content))\n        a = [\'%s=""%s""\' % i for i in self._attrs.items()]\n        l = [self._name] + a\n        s = \'<%s>%s\' % (\' \'.join(l), join)\n        if self._content or not(self._name.lower() in self.empty_elements):\n            s += join.join(map(str_type, self._content))\n            s += join + \'</%s>\' % self._name\n        else:\n            s = \'<%s />%s\' % (\' \'.join(l), join)\n        return s\n\n\nclass XML(XHTML):\n    \'\'\'Easily generate XML.\n\n    All tags with no contents are reduced to self-terminating tags.\n    \'\'\'\n    newline_default_on = set()          # no tags are special\n\n    def _stringify(self, str_type):\n        # turn me and my content into text\n        # honor empty and non-empty elements\n        join = \'\\n\' if self._newlines else \'\'\n        if self._name is None:\n            return join.join(map(str_type, self._content))\n        a = [\'%s=""%s""\' % i for i in self._attrs.items()]\n        l = [self._name] + a\n        s = \'<%s>%s\' % (\' \'.join(l), join)\n        if self._content:\n            s += join.join(map(str_type, self._content))\n            s += join + \'</%s>\' % self._name\n        else:\n            s = \'<%s />%s\' % (\' \'.join(l), join)\n        return s\n\n\nclass TestCase(unittest.TestCase):\n    def test_empty_tag(self):\n        \'generation of an empty HTML tag\'\n        self.assertEquals(str(HTML().br), \'<br>\')\n\n    def test_empty_tag_xml(self):\n        \'generation of an empty XHTML tag\'\n        self.assertEquals(str(XHTML().br), \'<br />\')\n\n    def test_tag_add(self):\n        \'test top-level tag creation\'\n        self.assertEquals(str(HTML(\'html\', \'text\')), \'<html>\\ntext\\n</html>\')\n\n    def test_tag_add_no_newline(self):\n        \'test top-level tag creation\'\n        self.assertEquals(str(HTML(\'html\', \'text\', newlines=False)),\n            \'<html>text</html>\')\n\n    def test_iadd_tag(self):\n        ""test iadd\'ing a tag""\n        h = XML(\'xml\')\n        h += XML(\'some-tag\', \'spam\', newlines=False)\n        h += XML(\'text\', \'spam\', newlines=False)\n        self.assertEquals(str(h),\n            \'<xml>\\n<some-tag>spam</some-tag>\\n<text>spam</text>\\n</xml>\')\n\n    def test_iadd_text(self):\n        ""test iadd\'ing text""\n        h = HTML(\'html\', newlines=False)\n        h += \'text\'\n        h += \'text\'\n        self.assertEquals(str(h), \'<html>texttext</html>\')\n\n    def test_xhtml_match_tag(self):\n        \'check forced generation of matching tag when empty\'\n        self.assertEquals(str(XHTML().p), \'<p></p>\')\n\n    if sys.version_info[0] == 2:\n        def test_empty_tag_unicode(self):\n            \'generation of an empty HTML tag\'\n            self.assertEquals(unicode(HTML().br), unicode(\'<br>\'))\n\n        def test_empty_tag_xml_unicode(self):\n            \'generation of an empty XHTML tag\'\n            self.assertEquals(unicode(XHTML().br), unicode(\'<br />\'))\n\n        def test_xhtml_match_tag_unicode(self):\n            \'check forced generation of matching tag when empty\'\n            self.assertEquals(unicode(XHTML().p), unicode(\'<p></p>\'))\n\n    def test_just_tag(self):\n        \'generate HTML for just one tag\'\n        self.assertEquals(str(HTML().br), \'<br>\')\n\n    def test_just_tag_xhtml(self):\n        \'generate XHTML for just one tag\'\n        self.assertEquals(str(XHTML().br), \'<br />\')\n\n    def test_xml(self):\n        \'generate XML\'\n        self.assertEquals(str(XML().br), \'<br />\')\n        self.assertEquals(str(XML().p), \'<p />\')\n        self.assertEquals(str(XML().br(\'text\')), \'<br>text</br>\')\n\n    def test_para_tag(self):\n        \'generation of a tag with contents\'\n        h = HTML()\n        h.p(\'hello\')\n        self.assertEquals(str(h), \'<p>hello</p>\')\n\n    def test_escape(self):\n        \'escaping of special HTML characters in text\'\n        h = HTML()\n        h.text(\'<>&\')\n        self.assertEquals(str(h), \'&lt;&gt;&amp;\')\n\n    def test_no_escape(self):\n        \'no escaping of special HTML characters in text\'\n        h = HTML()\n        h.text(\'<>&\', False)\n        self.assertEquals(str(h), \'<>&\')\n\n    def test_escape_attr(self):\n        \'escaping of special HTML characters in attributes\'\n        h = HTML()\n        h.br(id=\'<>&""\')\n        self.assertEquals(str(h), \'<br id=""&lt;&gt;&amp;&quot;"">\')\n\n    def test_subtag_context(self):\n        \'generation of sub-tags using ""with"" context\'\n        h = HTML()\n        with h.ol:\n            h.li(\'foo\')\n            h.li(\'bar\')\n        self.assertEquals(str(h), \'<ol>\\n<li>foo</li>\\n<li>bar</li>\\n</ol>\')\n\n    def test_subtag_direct(self):\n        \'generation of sub-tags directly on the parent tag\'\n        h = HTML()\n        l = h.ol\n        l.li(\'foo\')\n        l.li.b(\'bar\')\n        self.assertEquals(str(h),\n            \'<ol>\\n<li>foo</li>\\n<li><b>bar</b></li>\\n</ol>\')\n\n    def test_subtag_direct_context(self):\n        \'generation of sub-tags directly on the parent tag in ""with"" context\'\n        h = HTML()\n        with h.ol as l:\n            l.li(\'foo\')\n            l.li.b(\'bar\')\n        self.assertEquals(str(h),\n            \'<ol>\\n<li>foo</li>\\n<li><b>bar</b></li>\\n</ol>\')\n\n    def test_subtag_no_newlines(self):\n        \'prevent generation of newlines against default\'\n        h = HTML()\n        l = h.ol(newlines=False)\n        l.li(\'foo\')\n        l.li(\'bar\')\n        self.assertEquals(str(h), \'<ol><li>foo</li><li>bar</li></ol>\')\n\n    def test_add_text(self):\n        \'add text to a tag\'\n        h = HTML()\n        p = h.p(\'hello, world!\\n\')\n        p.text(\'more text\')\n        self.assertEquals(str(h), \'<p>hello, world!\\nmore text</p>\')\n\n    def test_add_text_newlines(self):\n        \'add text to a tag with newlines for prettiness\'\n        h = HTML()\n        p = h.p(\'hello, world!\', newlines=True)\n        p.text(\'more text\')\n        self.assertEquals(str(h), \'<p>\\nhello, world!\\nmore text\\n</p>\')\n\n    def test_doc_newlines(self):\n        \'default document adding newlines between tags\'\n        h = HTML()\n        h.br\n        h.br\n        self.assertEquals(str(h), \'<br>\\n<br>\')\n\n    def test_doc_no_newlines(self):\n        \'prevent document adding newlines between tags\'\n        h = HTML(newlines=False)\n        h.br\n        h.br\n        self.assertEquals(str(h), \'<br><br>\')\n\n    def test_unicode(self):\n        \'make sure unicode input works and results in unicode output\'\n        h = HTML(newlines=False)\n        # Python 3 compat\n        try:\n            unicode = unicode\n            TEST = \'euro \\xe2\\x82\\xac\'.decode(\'utf8\')\n        except:\n            unicode = str\n            TEST = \'euro \xe2\x82\xac\'\n        h.p(TEST)\n        self.assertEquals(unicode(h), \'<p>%s</p>\' % TEST)\n\n    def test_table(self):\n        \'multiple ""with"" context blocks\'\n        h = HTML()\n        with h.table(border=\'1\'):\n            for i in range(2):\n                with h.tr:\n                    h.td(\'column 1\')\n                    h.td(\'column 2\')\n        self.assertEquals(str(h), \'\'\'<table border=""1"">\n<tr><td>column 1</td><td>column 2</td></tr>\n<tr><td>column 1</td><td>column 2</td></tr>\n</table>\'\'\')\n\nif __name__ == \'__main__\':\n    unittest.main()\n\n\n# Copyright (c) 2009 eKit.com Inc (http://www.ekit.com/)\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the ""Software""), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n#  The above copyright notice and this permission notice shall be included in\n#  all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n# SOFTWARE.\n\n# vim: set filetype=python ts=4 sw=4 et si\n'"
code/layers.py,0,"b'import os\nimport numpy as np\n\n#DEBUG = False\n\nclass RangesLayer(object):\n  def __init__(self, width, height):\n\n    focalLength = 517.97\n    urange = np.arange(width).reshape(1, -1).repeat(height, 0) - width * 0.5\n    vrange = np.arange(height).reshape(-1, 1).repeat(width, 1) - height * 0.5\n    self.ranges = np.array([urange / focalLength / width * 640, np.ones(urange.shape), -vrange / focalLength / height * 480]).transpose([1, 2, 0])\n    return\n      \n  def forward(self):\n    return self.ranges\n\n\ndef PlaneDepthLayer(planes, ranges):\n  batchSize = 1\n  if len(planes.shape) == 3:\n    batchSize = planes.shape[0]\n    planes = planes.reshape(planes.shape[0] * planes.shape[1], planes.shape[2])\n    pass\n  \n  planesD = np.linalg.norm(planes, 2, 1)\n  planesD = np.maximum(planesD, 1e-4)\n  planesNormal = -planes / planesD.reshape(-1, 1).repeat(3, 1)\n\n  normalXYZ = np.dot(ranges, planesNormal.transpose())\n  normalXYZ[normalXYZ == 0] = 1e-4\n  normalXYZ = 1 / normalXYZ\n  depths = -normalXYZ\n  depths[:, :] *= planesD\n  if batchSize > 1:\n    depths = depths.reshape(depths.shape[0], depths.shape[1], batchSize, -1).transpose([2, 0, 1, 3])\n    pass\n  depths[(depths < 0) + (depths > 10)] = 10\n  #depths[depths < 0] = 0\n  #depths[depths > 10] = 10\n  return depths\n\n\ndef PlaneNormalLayer(planes, ranges):\n  batchSize = 1\n  if len(planes.shape) == 3:\n    batchSize = planes.shape[0]\n    planes = planes.reshape(planes.shape[0] * planes.shape[1], planes.shape[2])\n    pass\n  planesD = np.linalg.norm(planes, 2, 1)\n  planesD = np.maximum(planesD, 1e-4)\n  planesNormal = -planes / planesD.reshape(-1, 1).repeat(3, 1)\n  normals = planesNormal.reshape(1, 1, -1, 3).repeat(ranges.shape[0], 0).repeat(ranges.shape[1], 1)\n  if batchSize > 1:\n    normals = normals.reshape(normals.shape[0], normals.shape[1], batchSize, -1, 3).transpose([2, 0, 1, 3, 4])\n    pass\n  return normals\n'"
code/modules.py,564,"b'import tensorflow as tf\nimport numpy as np\n\n# def segmentationRefinementModule(segmentation, planeDepths, numOutputPlanes = 20, gpu_id = 0, coef = [1, 1, 1], beta = 10):\n#     with tf.device(\'/gpu:%d\'%gpu_id):\n#         S = segmentation\n#         #S = tf.one_hot(tf.argmax(S, 3), numOutputPlanes)\n#         D = tf.tile(tf.expand_dims(planeDepths, -1), [1, 1, 1, 1, numOutputPlanes])\n#         D_transpose = tf.tile(tf.expand_dims(planeDepths, 3), [1, 1, 1, numOutputPlanes, 1])\n#         D_diff = tf.abs(D - D_transpose)\n#         batchSize = int(segmentation.shape[0])\n#         height = int(segmentation.shape[1])\n#         width = int(segmentation.shape[2])\n#         S_neighbor_up = tf.concat([tf.zeros([batchSize, 1, width, numOutputPlanes]), tf.slice(S, [0, 0, 0, 0], [batchSize, height - 1, width, numOutputPlanes])], axis = 1)\n#         S_neighbor_down = tf.concat([tf.slice(S, [0, 1, 0, 0], [batchSize, height - 1, width, numOutputPlanes]), tf.zeros([batchSize, 1, width, numOutputPlanes]), ], axis = 1)\n#         S_neighbor_left = tf.concat([tf.zeros([batchSize, height, 1, numOutputPlanes]), tf.slice(S, [0, 0, 0, 0], [batchSize, height, width - 1, numOutputPlanes])], axis = 2)\n#         S_neighbor_right = tf.concat([tf.slice(S, [0, 0, 1, 0], [batchSize, height, width - 1, numOutputPlanes]), tf.zeros([batchSize, height, 1, numOutputPlanes]), ], axis = 2)\n#         #S_neighbors = tf.stack([S_neighbor_up, S_neighbor_down, S_neighbor_left, S_neighbor_right], axis = 4)\n#         S_neighbors = (S_neighbor_up + S_neighbor_down + S_neighbor_left + S_neighbor_right) / 4\n#         DS = tf.reduce_sum(tf.multiply(D_diff, tf.expand_dims(S_neighbors, 3)), axis=4)\n#         #test = tf.multiply(D_diff, tf.expand_dims(S_neighbors, 3))\n#         #S_diff = tf.tile(tf.reduce_sum(S_neighbors, axis=3, keep_dims=True), [1, 1, 1, numOutputPlanes]) - S_neighbors\n#         S_diff = tf.ones(S_neighbors.shape) - S_neighbors\n#         pass\n#     P = tf.clip_by_value(S, 1e-4, 1)\n#     DS = tf.clip_by_value(DS / 0.5, 1e-4, 1)\n#     S_diff = tf.clip_by_value(S_diff, 1e-4, 1)\n#     #return tf.nn.softmax(-beta * (-coef[0] * tf.log(P) + coef[1] * tf.log(DS) + coef[2] * tf.log(S_diff))), tf.nn.softmax(tf.log(P)), 1 - tf.clip_by_value(DS / 2, 0, 1), 1 - S_diff, 1 - tf.clip_by_value(tf.multiply(D_diff, tf.expand_dims(S_neighbors, 3)) / 2, 0, 1), S_neighbors, D_diff\n#     return tf.nn.softmax(-beta * (-coef[0] * tf.log(P) + coef[1] * tf.log(DS) + coef[2] * tf.log(S_diff)))\n\ndef planeDepthsModule(plane_parameters, width, height, info):\n    urange = (tf.range(width, dtype=tf.float32) / (width + 1) * (info[16] + 1) - info[2]) / info[0]\n    urange = tf.tile(tf.reshape(urange, [1, -1]), [height, 1])\n    vrange = (tf.range(height, dtype=tf.float32) / (height + 1) * (info[17] + 1) - info[6]) / info[5]\n    vrange = tf.tile(tf.reshape(vrange, [-1, 1]), [1, width])\n            \n    ranges = tf.stack([urange, np.ones([height, width]), -vrange], axis=2)\n    ranges = tf.reshape(ranges, [-1, 3])\n            \n    planesD = tf.norm(plane_parameters, axis=1, keep_dims=True)\n    planesD = tf.clip_by_value(planesD, 1e-5, 10)\n    planesNormal = tf.div(tf.negative(plane_parameters), tf.tile(planesD, [1, 3]))\n\n    normalXYZ = tf.matmul(ranges, planesNormal, transpose_b=True)\n    normalXYZ = tf.multiply(tf.sign(normalXYZ), tf.clip_by_value(tf.abs(normalXYZ), 1e-4, 1000000))\n    normalXYZ = tf.reciprocal(normalXYZ)\n    plane_depths = tf.negative(normalXYZ) * tf.reshape(planesD, [-1])\n    plane_depths = tf.reshape(plane_depths, [height, width, -1])\n\n    plane_depths = tf.clip_by_value(plane_depths, 0, 10)\n    \n    return plane_depths\n\ndef planeNormalsModule(plane_parameters, width, height):\n    planesD = tf.norm(plane_parameters, axis=-1, keep_dims=True)\n    planesD = tf.clip_by_value(planesD, 1e-4, 10)\n    planesNormal = tf.div(tf.negative(plane_parameters), planesD)\n\n    #plane_normals = tf.tile(tf.reshape(planesNormal, [1, 1, -1, 3]), [height, width, 1, 1])\n    #plane_normals = tf.reshape(planesNormal, [1, 1, -1, 3])\n    return planesNormal\n\ndef gaussian(k=5, sig=0):\n    """"""\n    creates gaussian kernel with side length l and a sigma of sig\n    """"""\n    if sig == 0:\n        sig = 0.3 * ((k - 1) * 0.5 - 1) + 0.8\n        pass\n    ax = np.arange(-k // 2 + 1., k // 2 + 1.)\n    xx, yy = np.meshgrid(ax, ax)\n\n    kernel = np.exp(-(xx**2 + yy**2) / (2. * sig**2))\n\n    return kernel / np.sum(kernel)\n\ndef meanfieldModuleLayer(layerSegmentations, planeDepths, numOutputPlanes = 20, numLayers=2, coef = [1, 1, 1], beta = 1, iteration = 0, sigmaDepthDiff = 0.5):\n    batchSize = int(planeSegmentations.shape[0])\n    height = int(planeSegmentations.shape[1])\n    width = int(planeSegmentations.shape[2])\n\n    minDepthDiff = 0.1\n    #P = planeSegmentations\n    #S = tf.one_hot(tf.argmax(planeSegmentations, 3), depth=numOutputPlanes)\n    kernel_size = 9\n    neighbor_kernel_array = gaussian(kernel_size)\n    neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n    neighbor_kernel_array /= neighbor_kernel_array.sum()\n    neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n    neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n\n\n    layerDepths = []\n    layerSs = []\n    for layer in xrange(numLayers):\n        S = tf.one_hot(tf.argmax(planeSegmentations, 3), depth=numOutputPlanes)\n        layerDepth = tf.reduce_sum(planeDepths * S, 3, keep_dims=True)\n        layerSs.append(S)\n        layerDepths.append(layerDepth)\n\n    DSs = []\n    conflictDs = []\n    conflictDepthThreshold = 0.1\n    \n    for layer in xrange(numLayers):        \n        DS_diff = tf.exp(-tf.pow(1 - tf.clip_by_value(tf.abs(planeDepths - layerDepths[layer]), 0, 1), 2) / sigmaDepthDiff) - tf.exp(-1 / sigmaDepthDiff) * layerSs[layer]\n        DS = tf.nn.depthwise_conv2d(DS_diff, tf.tile(neighbor_kernel, [1, 1, numOutputPlanes, 1]), strides=[1, 1, 1, 1], padding=\'SAME\')\n        DSs.append(DS)\n        \n        conflictD = tf.zeros((batchSize, height, width, 1))\n        if layer > 0:\n            minDepth = tf.min(tf.concat(layerDepths[:layer - 1], axis=3), axis=3, keep_dims=True)\n            conflictD = tf.maximum(conflictD, layerDepths[layer] - minDepth)\n            pass\n        if layer < numLayers - 1:\n            maxDepth = tf.max(tf.concat(layerDepths[layer + 1:], axis=3), axis=3, keep_dims=True)\n            conflictD = tf.maximum(conflictD, maxDepth -  layerDepths[layer])\n            pass\n        conflictDs.append(tf.cast(conflictD > conflictDepthThreshold, tf.float32))\n\n        \n    P = tf.clip_by_value(P, 1e-4, 1)\n    confidence = P * tf.exp(-coef[1] * DS)\n    refined_segmentation = tf.nn.softmax(tf.log(confidence))\n    return refined_segmentation\n\ndef calcImageDiff(images, kernel_size = 9):\n    neighbor_kernel_array = gaussian(kernel_size)\n    neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n    neighbor_kernel_array /= neighbor_kernel_array.sum()\n    neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = -1\n    neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n    neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n\n    image_diff = tf.nn.depthwise_conv2d(images, tf.tile(neighbor_kernel, [1, 1, 3, 1]), strides=[1, 1, 1, 1], padding=\'SAME\')\n    image_diff = tf.pow(image_diff, 2)\n    image_diff = tf.reduce_sum(image_diff, axis=3, keep_dims=True)\n    var_image_diff =  tf.reduce_mean(image_diff, axis=[1, 2, 3], keep_dims=True)\n    #image_diff = image_diff\n    #image_diff = tf.exp(-image_diff)\n    #image_diff = tf.nn.max_pool(image_diff, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\')\n    return image_diff, var_image_diff\n    \ndef meanfieldModule(planeSegmentations, planeDepths, planesY, imageDiff, numOutputPlanes = 20, coef = [1, 1, 1], beta = 1, iteration = 0, maxDepthDiff = 0.2, varDepthDiff = 0.5, kernel_size = 9):\n    batchSize = int(planeSegmentations.shape[0])\n    height = int(planeSegmentations.shape[1])\n    width = int(planeSegmentations.shape[2])\n\n    P = planeSegmentations\n\n\n    #minDepthDiff = 0.1\n    #normalDotThreshold = np.cos(np.deg2rad(30))\n    #N_diff = tf.matmul(planeNormals, planeNormals, transpose_b=True)\n    #N_diff_mask = tf.cast((N_diff < normalDotThreshold), tf.float) + tf.diag(tf.ones(numOutputPlanes))\n    #N_diff = tf.clip(N_diff, minDepthDiff, 1)\n    #N_diff_mask = tf.expand_dims(tf.expand_dims(N_diff_mask, 1), 1)\n\n    #D_diff = (D_diff - minDepthDiff) * N_diff_mask + minDepthDiff\n\n\n    #confidenceThreshold = 0.00\n    #P_truncated = P * (P >= confidenceThreshold).astype(tf.float)\n    S = tf.one_hot(tf.argmax(planeSegmentations, 3), depth=numOutputPlanes)\n\n    # D = tf.tile(tf.expand_dims(planeDepths, -1), [1, 1, 1, 1, numOutputPlanes])\n    # D_transpose = tf.tile(tf.expand_dims(planeDepths, 3), [1, 1, 1, numOutputPlanes, 1])\n    # D_diff = tf.abs(D - D_transpose)\n    # DS_weight = tf.exp(-tf.pow(tf.clip_by_value(1 - D_diff / maxDepthDiff, 0, 1), 2) / sigmaDepthDiff)\n    # DS_diff = tf.reduce_sum(DS_weight * tf.expand_dims(S, 3), axis=4) - tf.exp(-1 / sigmaDepthDiff) * S\n\n    \n    \n    \n    depthWeight = 50.0\n    colorWeight = 50.0\n    normalY = tf.reduce_sum(S * tf.reshape(planesY, [-1, 1, 1, numOutputPlanes]), axis=3, keep_dims=True)\n    depth_diff = (planeDepths - tf.reduce_sum(planeDepths * S, 3, keep_dims=True)) * normalY\n    depth_diff = tf.concat([depth_diff[:, :, :, :numOutputPlanes - 1], (1 - S[:, :, :, numOutputPlanes - 1:numOutputPlanes])], axis=3)\n    DS_diff = (1 - tf.exp(-tf.pow(tf.minimum(depth_diff, maxDepthDiff), 2) / varDepthDiff)) + (1 - S) * (1 / depthWeight + (colorWeight / depthWeight) * imageDiff)\n\n\n    #DS_diff = tf.exp(-tf.pow(1 - tf.clip_by_value(tf.abs(planeDepths - tf.reduce_sum(planeDepths * S, 3, keep_dims=True)), 0, 1), 2) / 0.5) - tf.exp(-1 / 0.5) * S\n\n    neighbor_kernel_array = gaussian(kernel_size)\n    neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n    neighbor_kernel_array /= neighbor_kernel_array.sum()\n    neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n    neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n    \n    DS = tf.nn.depthwise_conv2d(DS_diff, tf.tile(neighbor_kernel, [1, 1, numOutputPlanes, 1]), strides=[1, 1, 1, 1], padding=\'SAME\')\n    \n\n    P = tf.clip_by_value(P, 1e-4, 1)\n    confidence = P * tf.exp(-coef[1] * DS)\n    #confidence = coef[0] * P + tf.exp(-coef[1] * DS) + tf.exp(-coef[2] * S_diff)\n    #confidence[:, :, :, numOutputPlanes] = 1e-4\n    #confidence = tf.clip(confidence, 1e-4, 1)\n    refined_segmentation = tf.nn.softmax(tf.log(confidence))\n    return refined_segmentation, {\'diff\': DS}\n\n\ndef segmentationRefinementModule(planeSegmentations, planeDepths, planesY, imageDiff, numOutputPlanes = 20, numIterations=20, kernel_size = 9):\n\n    # kernel_size = 9\n    # neighbor_kernel_array = gaussian(kernel_size)\n    # neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n    # neighbor_kernel_array /= neighbor_kernel_array.sum()\n    # neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = -1\n    # neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n    # neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n\n    #maxDepthDiff = tf.Variable(0.3)\n    #sigmaDepthDiff = tf.Variable(0.5)\n    maxDepthDiff = 0.2\n    varDepthDiff = pow(0.2, 2)\n    \n    \n    refined_segmentation = planeSegmentations\n    for _ in xrange(numIterations):\n        refined_segmentation, _ = meanfieldModule(refined_segmentation, planeDepths, planesY, imageDiff, numOutputPlanes=numOutputPlanes, maxDepthDiff=maxDepthDiff, varDepthDiff=varDepthDiff, kernel_size = kernel_size)\n        continue\n    return refined_segmentation, {}\n\n\ndef meanfieldModuleBoundary(planeSegmentations, originalSegmentations, planeDepths, occlusionBoundary = 0, smoothBoundary = 0, numOutputPlanes = 20, coef = [1, 10, 1], beta = 1, iteration = 0, sigmaDepthDiff = 0.5):\n    batchSize = int(planeSegmentations.shape[0])\n    height = int(planeSegmentations.shape[1])\n    width = int(planeSegmentations.shape[2])\n\n    #S = tf.one_hot(tf.argmax(planeSegmentations, 3), depth=numOutputPlanes)\n    #D_diff = tf.clip_by_value(tf.abs(planeDepths - tf.reduce_sum(planeDepths * S, 3, keep_dims=True)), 0, 1) * smoothBoundary + tf.clip_by_value(1 - smoothBoundary - occlusionBoundary, 0, 1)\n    #DS_diff = tf.exp(-tf.pow(1 - D_diff, 2) / sigmaDepthDiff) - tf.exp(-1 / sigmaDepthDiff) * S\n    #DS_diff = DS_diff * smoothBoundary + (tf.exp(-1 / sigmaDepthDiff) * occlusionBoundary + tf.clip_by_value(1 - smoothBoundary - occlusionBoundary, 0, 1)) * (1 - S)\n\n    maxDepthDiff = 0.5\n    S = planeSegmentations\n    D_diff = tf.abs(planeDepths - tf.reduce_sum(planeDepths * S, 3, keep_dims=True))\n    DS_diff = tf.clip_by_value(D_diff / maxDepthDiff, 0, 1)\n    DS_diff = DS_diff * (1 - occlusionBoundary)\n    #+ (1 - S) * occlusionBoundary * 0.1\n    \n    kernel_size = 5\n    neighbor_kernel_array = gaussian(kernel_size)\n    neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n    neighbor_kernel_array /= neighbor_kernel_array.sum()\n    neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n    neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n\n    DS = tf.nn.depthwise_conv2d(DS_diff, tf.tile(neighbor_kernel, [1, 1, numOutputPlanes, 1]), strides=[1, 1, 1, 1], padding=\'VALID\')\n    padding = (kernel_size - 1) / 2\n    DS = tf.pad(DS, paddings = [[0, 0], [padding, padding], [padding, padding], [0, 0]])\n    \n    P = originalSegmentations\n    P = tf.clip_by_value(P, 1e-4, 1)\n    confidence = P * tf.exp(-coef[1] * DS)\n    #confidence = coef[0] * P + tf.exp(-coef[1] * DS) + tf.exp(-coef[2] * S_diff)\n    #confidence[:, :, :, numOutputPlanes] = 1e-4\n    #confidence = tf.clip(confidence, 1e-4, 1)\n    refined_segmentation = tf.nn.softmax(tf.log(confidence))\n    return refined_segmentation\n\n\ndef segmentationRefinementModuleBoundary(planeSegmentations, planeDepths, occlusionBoundary = 0, smoothBoundary = 0, numOutputPlanes = 20, numIterations=20):\n    #maxDepthDiff = tf.Variable(0.3)\n    #sigmaDepthDiff = tf.Variable(0.5)\n    maxDepthDiff = 0.3\n    sigmaDepthDiff = 0.5\n\n    refined_segmentation = planeSegmentations\n\n    #occlusionBoundary = tf.slice(boundaries, [0, 0, 0, 1], [boundaries.shape[0], boundaries.shape[1], boundaries.shape[2], 1])\n    #smoothBoundary = tf.slice(boundaries, [0, 0, 0, 2], [boundaries.shape[0], boundaries.shape[1], boundaries.shape[2], 1])\n    for _ in xrange(numIterations):\n        refined_segmentation = meanfieldModuleBoundary(refined_segmentation, planeSegmentations, planeDepths, occlusionBoundary=occlusionBoundary, smoothBoundary=smoothBoundary, numOutputPlanes=numOutputPlanes, sigmaDepthDiff=sigmaDepthDiff)\n        continue\n    return refined_segmentation\n\n\ndef planeMapModule(depth, normal, ranges):\n    #ranges = tf.reshape(ranges, [-1, 3])\n\n    planes = tf.reduce_sum(normal * ranges, 3, keep_dims=True) * depth * normal\n    return planes\n    \n# def planeFittingModule(depth, normal, numPlanes=50, numGlobalPlanes=20, planeAreaThreshold=3*4):\n#     width = int(depth.shape[2])\n#     height = int(depth.shape[1])\n\n#     focalLength = 517.97\n#     urange = (tf.range(width, dtype=tf.float32) / (width + 1) - 0.5) / focalLength * 641\n#     urange = tf.tile(tf.reshape(urange, [1, -1]), [height, 1])\n#     vrange = (tf.range(height, dtype=tf.float32) / (height + 1) - 0.5) / focalLength * 481\n#     vrange = tf.tile(tf.reshape(vrange, [-1, 1]), [1, width])\n            \n#     ranges = tf.stack([urange, tf.ones([height, width]), -vrange], axis=2)\n#     ranges = tf.expand_dims(ranges, 0)\n\n#     batchSize = int(depth.shape[0])\n#     planeDiffThreshold = 0.1\n#     #plane parameter for each pixel\n#     planeMap = planeMapModule(depth, normal, ranges)\n    \n#     kernel_size = 3\n#     neighbor_kernel_array = gaussian(kernel_size)\n#     neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n#     neighbor_kernel_array /= neighbor_kernel_array.sum()\n#     neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n#     neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n#     #smoothedPlaneMap = tf.nn.depthwise_conv2d(planeMap, tf.tile(neighbor_kernel, [1, 1, 3, 1]), strides=[1, 1, 1, 1], padding=\'SAME\')\n#     median_kernel_array = np.zeros((3, 3, 1, 9))\n#     for index in xrange(9):\n#         median_kernel_array[index / 3, index % 3, 0, index] = 1\n#         continue\n#     median_kernel = tf.constant(median_kernel_array.reshape(-1), shape=median_kernel_array.shape, dtype=tf.float32)\n#     smoothedPlaneMap = tf.nn.depthwise_conv2d(planeMap, tf.tile(median_kernel, [1, 1, 3, 1]), strides=[1, 1, 1, 1], padding=\'SAME\')\n#     smoothedPlaneMap, _ = tf.nn.top_k(tf.reshape(smoothedPlaneMap, [batchSize, height, width, 3, 9]), k=5)\n#     planeMap = tf.squeeze(tf.slice(smoothedPlaneMap, [0, 0, 0, 0, 4], [batchSize, height, width, 3, 1]), axis=4)\n\n#     #planeDiff = tf.norm(planeMap - tf.nn.depthwise_conv2d(planeMap, tf.tile(neighbor_kernel, [1, 1, 3, 1]), strides=[1, 1, 1, 1], padding=\'SAME\'), axis=3, keep_dims=True)\n#     smoothedPlaneMap = tf.nn.depthwise_conv2d(planeMap, tf.tile(median_kernel, [1, 1, 3, 1]), strides=[1, 1, 1, 1], padding=\'SAME\')\n#     planeDiff = tf.reduce_max(tf.norm(tf.expand_dims(planeMap, -1) - tf.reshape(smoothedPlaneMap, [batchSize, height, width, 3, 9]), axis=3, keep_dims=True), axis=4)\n#     boundaryMask = tf.cast(tf.less(planeDiff, planeDiffThreshold), tf.float32)\n    \n#     #opening\n#     erosionKernel = np.array([[-1, 0, -1], [0, 0, 0], [-1, 0, -1]], dtype=np.float32).reshape([3, 3, 1])\n#     dilationKernel = np.array([[-1, 0, -1], [0, 0, 0], [-1, 0, -1]], dtype=np.float32).reshape([3, 3, 1])\n#     boundaryMask = tf.nn.erosion2d(boundaryMask, kernel=erosionKernel, strides=[1, 1, 1, 1], rates=[1, 1, 1, 1], padding=\'SAME\')\n    \n#     #region indices\n#     assignment = tf.reshape(tf.range(batchSize * height * width, dtype=tf.float32) + 1, [batchSize, height, width, 1]) * boundaryMask\n#     with tf.variable_scope(""flooding"") as scope:\n#         scope.reuse_variables()\n#         for _ in xrange(width / 2):\n#             assignment = tf.nn.max_pool(assignment, ksize=[1, 5, 5, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\') * boundaryMask\n#             continue\n#         pass\n#     #inds, mask, count = tf.unique_with_counts(tf.concat([tf.constant(0, shape=[1], dtype=tf.float32), tf.reshape(assignment, [-1])], axis=0))\n#     #ignoredInds = tf.range(count.shape, dtype=tf.float32) * tf.less(count, planeAreaThreshold)\n#     assignment = tf.reshape(assignment, [-1])\n    \n#     #find unique regions\n#     inds, mask, count = tf.unique_with_counts(assignment)\n#     ignoredInds = tf.boolean_mask(inds, tf.less(count, planeAreaThreshold))\n#     assignment = assignment * (1 - tf.reduce_max(tf.cast(tf.equal(tf.expand_dims(assignment, -1), tf.expand_dims(ignoredInds, 0)), tf.float32), axis=1))\n#     inds, mask, count = tf.unique_with_counts(tf.concat([tf.constant(0, shape=[1], dtype=tf.float32), assignment], axis=0))\n        \n#     mask = tf.slice(mask, [1], [batchSize * height * width])\n#     mask = tf.reshape(mask, [batchSize, height, width, 1])\n#     #inds = tf.boolean_mask(inds, tf.greater(count, width * height / (16 * 16)))\n#     batchInds = tf.equal(tf.cast(tf.tile(tf.reshape(inds - 1, [1, -1]), [batchSize, 1]), tf.int32) / (width * height), tf.expand_dims(tf.range(batchSize), -1))\n#     counts = tf.count_nonzero(batchInds, axis=1)\n#     counts = tf.concat([tf.constant([1], dtype=tf.int64), counts], axis=0)\n#     counts = tf.slice(tf.cumsum(counts), [0], [batchSize])\n#     batchPlaneInds = tf.reshape(tf.range(numPlanes), [1, -1]) + tf.cast(tf.reshape(counts, [-1, 1]), tf.int32)\n#     #batchPlaneInds = tf.tile(tf.reshape(tf.range(numPlanes, dtype=tf.int32) + 1, [1, 1, 1, -1]), [batchSize, 1, 1, 1])\n#     planeMasks = tf.cast(tf.equal(mask, tf.reshape(batchPlaneInds, [batchSize, 1, 1, numPlanes])), tf.float32)\n\n#     planeMasks_test = planeMasks\n\n\n#     planeAreas = tf.clip_by_value(tf.reduce_sum(planeMasks, axis=[1, 2]), 1e-4, width * height)\n#     #planeAreas, sortInds = tf.nn.top_k(planeAreas, k=numPlanes)\n#     #sortMap = tf.one_hot(sortInds, depth=numPlanes, axis=1)\n#     #planeMasks = tf.reshape(tf.matmul(tf.reshape(planeMasks, [-1, height * width, numPlanes]), sortMap), [-1, height, width, numPlanes])\n\n#     #fit plane based on mask\n#     planesNormal = tf.reduce_sum(tf.expand_dims(normal, 3) * tf.expand_dims(planeMasks, -1), axis=[1, 2]) / tf.expand_dims(planeAreas, -1)\n#     planesNormal = tf.nn.l2_normalize(planesNormal, 2)\n\n#     weightedABC = tf.transpose(tf.reshape(tf.matmul(tf.reshape(ranges, [-1, 3]), tf.reshape(planesNormal, [-1, 3]), transpose_b=True), [height, width, batchSize, numPlanes]), [2, 0, 1, 3])\n#     planesD = tf.reduce_sum(weightedABC * depth * planeMasks, axis=[1, 2]) / planeAreas\n#     planesD = tf.expand_dims(planesD, -1)\n#     planes = planesNormal * planesD\n    \n#     #globalPlanes = tf.slice(planes, [0, 0, 0], [batchSize, numGlobalPlanes, 3])\n#     #planes = tf.transpose(tf.matmul(planes, sortMap, transpose_a=True), [0, 2, 1])\n#     #planesNormal = tf.slice(planesNormal, [0, 0, 0], [batchSize, numGlobalPlanes, 3])\n#     #planesD = tf.slice(planesD, [0, 0, 0], [batchSize, numGlobalPlanes, 1])\n\n#     normalDotThreshold = np.cos(np.deg2rad(5))\n#     distanceThreshold = 0.05\n#     X = depth * tf.expand_dims(urange, -1)\n#     Y = depth\n#     Z = -depth * tf.expand_dims(vrange, -1)\n#     XYZ = tf.concat([X, Y, Z], axis=3)\n#     XYZ = tf.reshape(XYZ, [-1, height * width, 3])\n    \n#     planesNormal = -planesNormal\n#     distance = tf.reshape(tf.abs(tf.matmul(XYZ, planesNormal, transpose_b=True) + tf.reshape(planesD, [-1, 1, numPlanes])), [-1, height, width, numPlanes])\n#     angle = tf.reshape(tf.abs(tf.matmul(tf.reshape(normal, [-1, height * width, 3]), planesNormal, transpose_b=True)), [-1, height, width, numPlanes])\n\n#     explainedPlaneMasks = tf.cast(tf.logical_and(tf.greater(angle, normalDotThreshold), tf.less(distance, distanceThreshold)), tf.float32)\n#     explainedPlaneMasks = tf.nn.dilation2d(explainedPlaneMasks, filter=np.tile(dilationKernel, [1, 1, numPlanes]), strides=[1, 1, 1, 1], rates=[1, 1, 1, 1], padding=\'SAME\')\n#     explainedPlaneMasks = tf.nn.erosion2d(explainedPlaneMasks, kernel=np.tile(erosionKernel, [1, 1, numPlanes]), strides=[1, 1, 1, 1], rates=[1, 1, 1, 1], padding=\'SAME\')    \n\n#     with tf.variable_scope(""expansion"") as scope:\n#         scope.reuse_variables()\n#         for _ in xrange(width / 6):\n#             planeMasks = tf.nn.max_pool(planeMasks, ksize=[1, 13, 13, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\') * explainedPlaneMasks\n#             continue\n#         pass\n        \n#     planeAreas = tf.reduce_sum(planeMasks, axis=[1, 2])\n#     planeAreas, sortInds = tf.nn.top_k(planeAreas, k=numPlanes)\n#     sortMap = tf.one_hot(sortInds, depth=numPlanes, axis=1)\n#     planeMasks = tf.reshape(tf.matmul(tf.reshape(planeMasks, [-1, height * width, numPlanes]), sortMap), [-1, height, width, numPlanes])\n#     planes = tf.transpose(tf.matmul(planes, sortMap, transpose_a=True), [0, 2, 1])\n\n#     #remove duplicate planes by expanding each plane mask, if two masks coincide, remove one of them\n#     substractionMatrix = -tf.cast(tf.less(tf.reshape(tf.range(numPlanes), [-1, 1]), tf.reshape(tf.range(numPlanes), [1, -1])), tf.float32) + tf.eye(numPlanes)\n#     substractionMatrix = tf.tile(tf.expand_dims(substractionMatrix, 0), [batchSize, 1, 1])\n#     planeMasks = tf.clip_by_value(tf.reshape(tf.matmul(tf.reshape(planeMasks, [-1, height * width, numPlanes]), substractionMatrix), [-1, height, width, numPlanes]), 0, 1)\n\n\n#     planeMasksWithoutBoundary = planeMasks * boundaryMask\n#     planeAreas = tf.reduce_sum(planeMasksWithoutBoundary, axis=[1, 2])\n#     maxMeanDepthThreshold = 10\n#     planeAreas = tf.clip_by_value(planeAreas, 1e-4, width * height)\n#     #validPlaneMask = tf.cast(tf.logical_and(tf.logical_or(tf.greater(planeAreas, planeAreaThreshold), tf.equal(tf.argmax(np.abs(planes), 2), 2)), tf.less(tf.reduce_sum(planeMasksWithoutBoundary * depth, axis=[1, 2]) / planeAreas, maxMeanDepthThreshold)), tf.float32)\n#     #validPlaneMask = tf.cast(tf.equal(tf.argmax(np.abs(planes), 2), 2), tf.float32)\n#     #planeAreas, sortInds = tf.nn.top_k(planeAreas, k=numPlanes)\n#     #sortMap = tf.one_hot(sortInds, depth=numPlanes, axis=1)\n#     #planeMasks = tf.reshape(tf.matmul(tf.reshape(planeMasks, [-1, height * width, numPlanes]), sortMap), [-1, height, width, numPlanes])\n\n#     if False:\n#         planes = tf.transpose(tf.matmul(planes, sortMap, transpose_a=True), [0, 2, 1])\n#     else:\n#         #fit planes based on merged masks\n#         planesNormal = tf.reduce_sum(tf.expand_dims(normal, 3) * tf.expand_dims(planeMasksWithoutBoundary, -1), axis=[1, 2]) / tf.expand_dims(planeAreas, -1)\n#         planesNormal = tf.nn.l2_normalize(planesNormal, 2)\n\n#         weightedABC = tf.transpose(tf.reshape(tf.matmul(tf.reshape(ranges, [-1, 3]), tf.reshape(planesNormal, [-1, 3]), transpose_b=True), [height, width, batchSize, numPlanes]), [2, 0, 1, 3])\n#         planesD = tf.reduce_sum(weightedABC * depth * planeMasksWithoutBoundary, axis=[1, 2]) / planeAreas\n#         planesD = tf.expand_dims(planesD, -1)\n#         planes = planesNormal * planesD\n#         pass\n\n#     validPlaneMask = tf.cast(tf.less(tf.reduce_sum(planeMasksWithoutBoundary * depth, axis=[1, 2]) / planeAreas, maxMeanDepthThreshold), tf.float32)\n#     planeMasks = planeMasks * tf.expand_dims(tf.expand_dims(validPlaneMask, 1), 1)\n#     planes = planes * tf.expand_dims(validPlaneMask, -1)\n#     planeAreas = planeAreas * validPlaneMask\n            \n\n#     # planeAreas = tf.reduce_sum(localPlaneMasks, axis=[1, 2])\n#     # planeAreas, sortInds = tf.nn.top_k(planeAreas, k=numPlanes)\n#     # sortMap = tf.one_hot(sortInds, depth=numPlanes, axis=1)\n#     # localPlaneMasks = tf.reshape(tf.matmul(tf.reshape(localPlaneMasks, [-1, height * width, numPlanes]), sortMap), [-1, height, width, numPlanes])\n#     # localPlanes = tf.transpose(tf.matmul(localPlanes, sortMap, transpose_a=True), [0, 2, 1])\n\n#     # substractionMatrix = -tf.cast(tf.less(tf.reshape(tf.range(numPlanes), [-1, 1]), tf.reshape(tf.range(numPlanes), [1, -1])), tf.float32) + tf.eye(numPlanes)\n#     # substractionMatrix = tf.tile(tf.expand_dims(substractionMatrix, 0), [batchSize, 1, 1])\n#     # localPlaneMasks = tf.clip_by_value(tf.reshape(tf.matmul(tf.reshape(localPlaneMasks, [-1, height * width, numPlanes]), substractionMatrix), [-1, height, width, numPlanes]), 0, 1)\n\n\n#     # planeMasksWithoutBoundary = localPlaneMasks * boundaryMask\n#     # planeAreas = tf.reduce_sum(planeMasksWithoutBoundary, axis=[1, 2])\n#     # maxMeanDepthThreshold = 10\n#     # #validPlaneMask = tf.cast(tf.logical_and(tf.logical_or(tf.greater(planeAreas, planeAreaThreshold), tf.equal(tf.argmax(np.abs(planes), 2), 2)), tf.less(tf.reduce_sum(planeMasksWithoutBoundary * depth, axis=[1, 2]) / planeAreas, maxMeanDepthThreshold)), tf.float32)\n#     # #validPlaneMask = tf.cast(tf.equal(tf.argmax(np.abs(planes), 2), 2), tf.float32)\n#     # validPlaneMask = tf.cast(tf.less(tf.reduce_sum(planeMasksWithoutBoundary * depth, axis=[1, 2]) / planeAreas, maxMeanDepthThreshold), tf.float32)\n#     # localPlanes = localPlanes * tf.expand_dims(validPlaneMask, -1)\n#     # localPlaneMasks = localPlaneMasks * tf.expand_dims(tf.expand_dims(validPlaneMask, 1), 1)\n#     # planeAreas = planeAreas * validPlaneMask\n#     # planeAreas, sortInds = tf.nn.top_k(planeAreas, k=numPlanes)\n#     # sortMap = tf.one_hot(sortInds, depth=numPlanes, axis=1)\n#     # localPlaneMasks = tf.reshape(tf.matmul(tf.reshape(localPlaneMasks, [-1, height * width, numPlanes]), sortMap), [-1, height, width, numPlanes])\n\n#     # planeMasksWithoutBoundary = localPlaneMasks * boundaryMask\n#     # planeAreas = tf.clip_by_value(planeAreas, 1e-4, width * height)\n#     # planesNormal = tf.reduce_sum(tf.expand_dims(normal, 3) * tf.expand_dims(planeMasksWithoutBoundary, -1), axis=[1, 2]) / tf.expand_dims(planeAreas, -1)\n#     # planesNormal = tf.nn.l2_normalize(planesNormal, 2)\n\n#     # weightedABC = tf.transpose(tf.reshape(tf.matmul(tf.reshape(ranges, [-1, 3]), tf.reshape(planesNormal, [-1, 3]), transpose_b=True), [height, width, batchSize, numPlanes]), [2, 0, 1, 3])\n#     # planesD = tf.reduce_sum(weightedABC * depth * planeMasksWithoutBoundary, axis=[1, 2]) / planeAreas\n#     # planesD = tf.expand_dims(planesD, -1)\n#     # localPlanes = planesNormal * planesD\n    \n\n#     #find local ground truth\n#     urange = tf.reshape(tf.range(width, dtype=tf.float32), [1, -1, 1])\n#     planeXs = tf.reduce_max(planeMasks, axis=1)\n#     planeMinX = width - tf.reduce_max(planeXs * (float(width) - urange), axis=1)\n#     planeMaxX = tf.reduce_max(planeXs * urange, axis=1)\n\n#     vrange = tf.reshape(tf.range(height, dtype=tf.float32), [1, -1, 1])\n#     planeYs = tf.reduce_max(planeMasks, axis=2)\n#     planeMinY = height - tf.reduce_max(planeYs * (float(height) - vrange), axis=1)\n#     planeMaxY = tf.reduce_max(planeYs * vrange, axis=1)\n\n#     planeBoxes = tf.stack([planeMinX, planeMaxX, planeMinY, planeMaxY], axis=2)\n\n#     localPlaneWidthThreshold = 64\n#     localPlaneHeightThreshold = 64\n#     globalPlaneAreaThreshold = 16 * 16\n#     globalPlaneWidthThreshold = 8\n    \n#     globalPlaneMask = tf.logical_or(tf.greater(planeMaxX - planeMinX, localPlaneWidthThreshold), tf.greater(planeMaxY - planeMinY, localPlaneHeightThreshold))\n#     globalPlaneMask = tf.logical_and(globalPlaneMask, tf.greater((planeMaxX - planeMinX) * (planeMaxY - planeMinY), globalPlaneAreaThreshold))\n#     globalPlaneMask = tf.logical_and(globalPlaneMask, tf.greater(planeAreas / (planeMaxY + 1 - planeMinY), globalPlaneWidthThreshold))\n#     #globalPlaneMask = tf.cast(tf.squeeze(globalPlaneMask, axis=[2]), tf.float32)\n#     globalPlaneMask = tf.cast(globalPlaneMask, tf.float32)\n#     weightedPlaneAreas = globalPlaneMask * (planeAreas + height * width) + (1 - globalPlaneMask) * planeAreas\n#     planeAreas, sortInds = tf.nn.top_k(weightedPlaneAreas, k=numPlanes)\n#     sortMap = tf.one_hot(sortInds, depth=numPlanes, axis=1)\n#     planeMasks = tf.reshape(tf.matmul(tf.reshape(planeMasks, [-1, height * width, numPlanes]), sortMap), [-1, height, width, numPlanes])\n#     planes = tf.transpose(tf.matmul(planes, sortMap, transpose_a=True), [0, 2, 1])\n#     planeBoxes = tf.transpose(tf.matmul(planeBoxes, sortMap, transpose_a=True), [0, 2, 1])\n#     globalPlaneMask = tf.squeeze(tf.matmul(tf.expand_dims(globalPlaneMask, 1), sortMap), axis=1)\n    \n\n\n#     #boundary ground truth\n#     boundary = tf.nn.max_pool(planeMasks, ksize=[1, 5, 5, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n    \n#     boundaryType = tf.cast(tf.round(tf.reduce_sum(boundary, axis=3, keep_dims=True)), tf.int32)\n#     singleBoundary = tf.cast(tf.equal(tf.reduce_sum(boundary - planeMasks, axis=3, keep_dims=True), 1), tf.float32)\n\n#     commonBoundary = tf.cast(tf.equal(boundaryType, 2), tf.float32)\n#     #boundary = boundary * commonBoundary\n#     boundaryCoef = tf.cast(tf.round(tf.cumsum(boundary, axis=3)), tf.float32)\n\n#     #boundary_1 = tf.cast(tf.equal(boundaryCoef, 1), tf.float32) * boundary\n#     #boundary_1 = tf.cast(tf.equal(boundaryCoef, 1), tf.float32) * boundary\n    \n#     boundaryPlane_1 = tf.reshape(tf.matmul(tf.reshape(tf.cast(tf.equal(boundaryCoef, 1), tf.float32) * boundary, [batchSize, height * width, numPlanes]), planes), [batchSize, height, width, 3])\n#     boundaryD_1 = tf.maximum(tf.norm(boundaryPlane_1, axis=3, keep_dims=True), 1e-4)\n#     boundaryNormal_1 = boundaryPlane_1 / boundaryD_1\n#     boundaryDepth_1 = boundaryD_1 / tf.maximum(tf.reduce_sum(boundaryNormal_1 * ranges, axis=3, keep_dims=True), 1e-4)\n\n#     boundaryPlane_2 = tf.reshape(tf.matmul(tf.reshape(tf.cast(tf.equal(boundaryCoef, 2), tf.float32) * boundary, [batchSize, height * width, numPlanes]), planes), [batchSize, height, width, 3])\n#     boundaryD_2 = tf.maximum(tf.norm(boundaryPlane_2, axis=3, keep_dims=True), 1e-4)\n#     boundaryNormal_2 = boundaryPlane_2 / boundaryD_2\n#     boundaryDepth_2 = boundaryD_2 / tf.maximum(tf.reduce_sum(boundaryNormal_2 * ranges, axis=3, keep_dims=True), 1e-4)\n\n#     depthDiffThreshold = 0.05\n#     #occlusionBoundary = tf.cast(tf.greater(tf.abs(boundaryDepth_1 - boundaryDepth_2), depthDiffThreshold), tf.float32) * commonBoundary\n#     largerMask = tf.nn.max_pool(tf.cast(tf.greater_equal(boundaryDepth_1, boundaryDepth_2), tf.float32) * commonBoundary, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\')\n#     smallerMask = tf.nn.max_pool(tf.cast(tf.less_equal(boundaryDepth_1, boundaryDepth_2), tf.float32) * commonBoundary, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\')\n#     smoothBoundary = tf.nn.max_pool(largerMask * smallerMask, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\')\n#     #depthDiff = tf.abs(depth - tf.nn.depthwise_conv2d(depth, neighbor_kernel, strides=[1, 1, 1, 1], padding=\'SAME\'))\n#     #occlusionBoundary = tf.cast(tf.greater(depthDiff, depthDiffThreshold), tf.float32) * commonBoundary\n    \n#     #boundaryConvexity = tf.cast(tf.less(tf.reduce_sum(boundaryNormal_1 * boundaryNormal_2, axis=3, keep_dims=True), 0), tf.float32)\n#     #convexBoundary = smoothBoundary * boundaryConvexity\n#     #concaveBoundary = smoothBoundary * (1 - boundaryConvexity)\n\n    \n#     occlusionBoundary = commonBoundary - smoothBoundary\n\n#     singleBoundary = tf.maximum(singleBoundary - tf.nn.max_pool(commonBoundary, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\'), 0)\n#     boundaries = tf.concat([singleBoundary, occlusionBoundary, smoothBoundary], axis=3)\n#     #boundaries = tf.concat([tf.maximum(tf.minimum((boundaryDepth_1 - boundaryDepth_2) + 0.5, 1), 0)], axis=3)\n#     #boundaries = tf.concat([tf.maximum(tf.minimum(boundaryDepth_1 / 10, 1), 0), tf.maximum(tf.minimum(boundaryDepth_2 / 10, 1), 0), tf.maximum(tf.minimum((boundaryDepth_1 - boundaryDepth_2) + 0.5, 1), 0)], axis=3)\n#     boundaries = 1 - tf.nn.max_pool(1 - boundaries, ksize=[1, 2, 2, 1], strides=[1, 1, 1, 1], padding=\'SAME\')\n    \n#     if True:\n#         coef = tf.pow(tf.constant(2, dtype=tf.float64), tf.range(numPlanes, dtype=tf.float64))\n#         planeMask = tf.cast(tf.round(tf.tensordot(tf.cast(planeMasks, tf.float64), coef, axes=[[3], [0]])), tf.int64)\n#         #localPlaneMask = tf.cast(tf.round(tf.tensordot(tf.cast(localPlaneMasks, tf.float64), coef, axes=[[3], [0]])), tf.int64)\n#         #coef = tf.pow(tf.constant(2, dtype=tf.float64), tf.range(numPlanes, dtype=tf.float64))\n#         #planeCroppedMask = tf.cast(tf.round(tf.tensordot(tf.cast(tf.greater(planeCroppedMasks, 0.5), tf.float64), coef, axes=[[3], [0]])), tf.int64)\n#         numGlobalPlanes = tf.reduce_sum(globalPlaneMask, axis=1)\n\n#         gridScores, gridPlanes, gridMasks = findLocalPlanes(planes, planeMasks)\n#         return planes, planeMask, numGlobalPlanes, boundaries, gridScores, gridPlanes, gridMasks\n\n    \n#     maskWidth = 32\n#     maskHeight = 32\n#     planeCroppedMasks = []\n#     for batchIndex in xrange(batchSize):\n#         boxes = planeBoxes[batchIndex]\n#         masks = tf.transpose(planeMasks[batchIndex], [2, 0, 1])\n#         croppedMasks = []\n#         for planeIndex in xrange(numPlanes):\n#         #for planeIndex in xrange(1):\n#             box = boxes[planeIndex]\n#             mask = masks[planeIndex]\n#             #minX = tf.cond(tf.less(planeIndex, tf.numValidPlanes[batchIndex]), lambda: tf.cast(box[0], tf.int32)\n#             minX = tf.cast(box[0], tf.int32)\n#             maxX = tf.cast(box[1], tf.int32)\n#             minY = tf.cast(box[2], tf.int32)\n#             maxY = tf.cast(box[3], tf.int32)\n#             minX = tf.minimum(minX, maxX)\n#             minY = tf.minimum(minY, maxY)\n#             croppedMask = tf.slice(mask, [minY, minX], [maxY - minY + 1, maxX - minX + 1])\n#             #croppedMask = tf.slice(mask, [0, 0], [height - 10, width - 10])\n#             croppedMask = tf.image.resize_bilinear(tf.expand_dims(tf.expand_dims(croppedMask, -1), 0), [maskHeight, maskWidth])\n#             croppedMasks.append(croppedMask)\n#             continue\n#         planeCroppedMasks.append(tf.squeeze(tf.concat(croppedMasks, axis=3)))\n#         continue\n#     planeCroppedMasks = tf.stack(planeCroppedMasks, axis=0)   \n\n#     gridMinX = []\n#     gridMaxX = []\n#     gridMinY = []\n#     gridMaxY = []\n#     for stride in [8, 16, 32]:\n#         boxSize = stride * 2\n#         xs = tf.tile(tf.expand_dims(tf.range(width / stride, dtype=tf.float32) * stride + stride / 2, 0), [height / stride, 1])\n#         ys = tf.tile(tf.expand_dims(tf.range(height / stride, dtype=tf.float32) * stride + stride / 2, 1), [1, width / stride])\n#         gridMinX.append(tf.reshape(xs - boxSize / 2, [1, -1, 1]))\n#         gridMaxX.append(tf.reshape(xs + boxSize / 2, [1, -1, 1]))\n#         gridMinY.append(tf.reshape(ys - boxSize / 2, [1, -1, 1]))\n#         gridMaxY.append(tf.reshape(ys + boxSize / 2, [1, -1, 1]))\n#         continue\n    \n#     gridMinX = tf.tile(tf.concat(gridMinX, axis=1), [batchSize, 1, 1])\n#     gridMaxX = tf.tile(tf.concat(gridMaxX, axis=1), [batchSize, 1, 1])\n#     gridMinY = tf.tile(tf.concat(gridMinY, axis=1), [batchSize, 1, 1])\n#     gridMaxY = tf.tile(tf.concat(gridMaxY, axis=1), [batchSize, 1, 1])\n\n#     planeMinX = tf.matmul(tf.reshape(planeMinX, [batchSize, 1, numPlanes]), sortMap)\n#     planeMaxX = tf.matmul(tf.reshape(planeMaxX, [batchSize, 1, numPlanes]), sortMap)\n#     planeMinY = tf.matmul(tf.reshape(planeMinY, [batchSize, 1, numPlanes]), sortMap)\n#     planeMaxY = tf.matmul(tf.reshape(planeMaxY, [batchSize, 1, numPlanes]), sortMap)\n\n#     intersection = tf.maximum(tf.minimum(gridMaxX, planeMaxX) - tf.maximum(gridMinX, planeMinX) + 1, 0.) * tf.maximum(tf.minimum(gridMaxY, planeMaxY) - tf.maximum(gridMinY, planeMinY) + 1, 0.)\n#     union = (gridMaxX - gridMinX + 1) * (gridMaxY - gridMinY + 1) + (planeMaxX - planeMinX + 1) * (planeMaxY - planeMinY + 1) - intersection\n#     IOU = intersection / union\n#     maxIOUInds = tf.argmax(IOU, axis=1)\n#     maxIOU = tf.reduce_max(IOU, axis=1)\n#     IOU = IOU * tf.one_hot(tf.argmax(IOU, 1), depth=IOU.shape[1], axis=1)\n#     #IOUThreshold = tf.concat([tf.ones((1, (width / 8) * (height / 8), 1)) * 0.2, tf.ones((1, (width / 16) * (height / 16), 1)) * 0.3, tf.ones((1, (width / 32) * (height / 32), 1)) * 0.7], axis=1)\n#     #activeGridMask = tf.one_hot(tf.argmax(IOU, 2), depth=IOU.shape[2], axis=2) * tf.cast(tf.greater(IOU, IOUThreshold), tf.float32)\n#     activeGridMask = tf.one_hot(tf.argmax(IOU, 2), depth=IOU.shape[2], axis=2) * (1 - tf.expand_dims(globalPlaneMask, 1))\n#     gridScores = tf.reduce_sum(activeGridMask, axis=2, keep_dims=True)\n#     activeGridMask = tf.expand_dims(activeGridMask, -1)\n#     gridPlanes = tf.reduce_sum(activeGridMask * tf.expand_dims(planes, 1), axis=2)\n#     gridMasks = tf.reduce_sum(activeGridMask * tf.expand_dims(tf.transpose(tf.reshape(planeCroppedMasks, [batchSize, -1, numPlanes]), [0, 2, 1]), 1), axis=2)\n\n#     activeGridMask = tf.squeeze(activeGridMask, axis=3)\n#     #gridBoxes = tf.reduce_sum(activeGridMask * tf.expand_dims(planeBoxes, 1), axis=2)\n#     gridPlaneMinX = tf.reduce_sum(activeGridMask * planeMinX, axis=2, keep_dims=True)\n#     gridPlaneMaxX = tf.reduce_sum(activeGridMask * planeMaxX, axis=2, keep_dims=True)\n#     gridPlaneMinY = tf.reduce_sum(activeGridMask * planeMinY, axis=2, keep_dims=True)\n#     gridPlaneMaxY = tf.reduce_sum(activeGridMask * planeMaxY, axis=2, keep_dims=True)\n#     gridWidths = gridMaxX - gridMinX\n#     gridHeights = gridMaxY - gridMinY\n\n#     gridOffsetX = ((gridPlaneMinX + gridPlaneMaxX) - (gridMinX + gridMaxX)) / 2 / gridWidths\n#     gridOffsetY = ((gridPlaneMinY + gridPlaneMaxY) - (gridMinY + gridMaxY)) / 2 / gridHeights\n#     gridW = (gridPlaneMaxX - gridPlaneMinX) / gridWidths\n#     gridH = (gridPlaneMaxY - gridPlaneMinY) / gridHeights\n#     gridBoxes = tf.concat([gridOffsetX, gridOffsetY, gridW, gridH], axis=2)\n    \n    \n#     offset = 0\n#     gridScoresArray = []\n#     gridPlanesArray = []\n#     gridBoxesArray = []\n#     gridMasksArray = []\n#     for stride in [8, 16, 32]:\n#         numGrids = (width / stride) * (height / stride)\n#         gridScoresArray.append(tf.reshape(tf.slice(gridScores, [0, offset, 0], [batchSize, numGrids, 1]), [batchSize, height / stride, width / stride, -1]))\n#         gridPlanesArray.append(tf.reshape(tf.slice(gridPlanes, [0, offset, 0], [batchSize, numGrids, 3]), [batchSize, height / stride, width / stride, -1]))\n#         gridBoxesArray.append(tf.reshape(tf.slice(gridBoxes, [0, offset, 0], [batchSize, numGrids, 4]), [batchSize, height / stride, width / stride, -1]))\n#         gridMasksArray.append(tf.reshape(tf.slice(gridMasks, [0, offset, 0], [batchSize, numGrids, maskWidth * maskHeight]), [batchSize, height / stride, width / stride, -1]))\n#         offset += numGrids\n#         continue\n\n    \n#     if True:\n#         coef = tf.pow(tf.constant(2, dtype=tf.float64), tf.range(numPlanes, dtype=tf.float64))\n#         planeMask = tf.cast(tf.round(tf.tensordot(tf.cast(planeMasks, tf.float64), coef, axes=[[3], [0]])), tf.int64)\n#         #localPlaneMask = tf.cast(tf.round(tf.tensordot(tf.cast(localPlaneMasks, tf.float64), coef, axes=[[3], [0]])), tf.int64)\n#         #coef = tf.pow(tf.constant(2, dtype=tf.float64), tf.range(numPlanes, dtype=tf.float64))\n#         planeCroppedMask = tf.cast(tf.round(tf.tensordot(tf.cast(tf.greater(planeCroppedMasks, 0.5), tf.float64), coef, axes=[[3], [0]])), tf.int64)\n#         numGlobalPlanes = tf.reduce_sum(globalPlaneMask, axis=1)\n\n#         return planes, planeMask, numGlobalPlanes, boundaries, planeBoxes, planeCroppedMask, gridScoresArray, gridPlanesArray, gridBoxesArray, gridMasksArray, maxIOU, maxIOUInds\n    \n#     # coef = tf.pow(tf.constant(0.9, dtype=tf.float64), tf.range(numPlanes, dtype=tf.float64))\n#     # coef = tf.tile(tf.reshape(coef, [1, 1, -1]), [batchSize, 1, 1])\n#     # coef = tf.matmul(coef, tf.cast(sortMap, tf.float64), transpose_b=True)\n#     # #planeMasks = tf.reshape(tf.matmul(tf.reshape(planeMasks, [-1, height * width, numPlanes]), sortMap), [-1, height, width, numPlanes])\n\n#     # assignment = tf.reduce_max(tf.cast(planeMasks, tf.float64) * tf.expand_dims(coef, axis=2), axis=3, keep_dims=True)\n#     # inds, mask, count = tf.unique_with_counts(tf.concat([tf.constant(0), tf.reshape(assignment, [-1])]))\n#     # mask = tf.reshape(tf.slice(mask, [1], [batchSize * height * width * 1], [batchSize, height, width, 1])\n\n#     # coef = tf.tile(tf.reshape(coef, [1, 1, -1]), [batchSize, 1, 1])\n#     # coef = tf.matmul(coef, tf.cast(sortMap, tf.float64), transpose_b=True)\n#     # coef = tf.reshape(tf.range(numPlanes)\n#     # planeMasks = tf.cast(tf.equal(mask, tf.tile(, [1, 1, 1, numPlanes]), [batchSize, 1, 1, 1])), tf.float32)\n    \n#     # planeAreas = tf.clip_by_value(tf.reduce_sum(planeMasks, axis=[1, 2]), 1e-4, width * height)\n#     # planeAreas, sortInds = tf.nn.top_k(planeAreas, k=numPlanes)\n#     # sortMap = tf.one_hot(sortInds, depth=numPlanes, axis=1)\n#     # planeMasks = tf.reshape(tf.matmul(tf.reshape(planeMasks, [-1, height * width, numPlanes]), sortMap), [-1, height, width, numPlanes])\n\n#     #planeAreas = tf.clip_by_value(tf.reduce_sum(planeMasks, axis=[1, 2]), 1e-4, width * height)\n    \n#     # planesNormal = tf.reduce_sum(tf.expand_dims(normal, 3) * tf.expand_dims(planeMasks, -1), axis=[1, 2]) / tf.expand_dims(planeAreas, -1)\n#     # planesNormal = tf.nn.l2_normalize(planesNormal, 2)\n#     # weightedABC = tf.reshape(tf.matmul(tf.reshape(ranges, [-1, 3]), tf.reshape(planesNormal, [-1, 3]), transpose_b=True), [batchSize, height, width, numPlanes])\n#     # planesD = tf.reduce_sum(weightedABC * depth * planeMasks, axis=[1, 2]) / planeAreas\n#     # planesD = tf.expand_dims(planesD, -1)\n#     # planes = planesNormal * planesD\n\n\n#     if True:\n#         planeMask = tf.cast(tf.round(tf.tensordot(tf.cast(planeMasks, tf.float64), coef, axes=[[3], [0]])), tf.int64)\n#         return planes, planeMask, tf.reduce_sum(validPlaneMask, axis=1)\n\n    \n#     globalPlanes = tf.slice(planes, [0, 0, 0], [batchSize, numGlobalPlanes, 3])\n#     globalPlaneMasks = tf.slice(planeMasks, [0, 0, 0, 0], [batchSize, height, width, numGlobalPlanes])\n\n#     if True:\n#         return planes, planeMasks, tf.reduce_sum(validPlaneMask, axis=1), planeMasks_test, boundaryMask\n#     #return globalPlanes, globalPlaneMasks, tf.reduce_sum(validPlaneMask, axis=1)\n    \n#     globalPlaneMask = tf.reduce_max(globalPlaneMasks, axis=3, keep_dims=True)\n#     smallPlaneMasks = tf.clip_by_value(tf.slice(planeMasks, [0, 0, 0, numGlobalPlanes], [batchSize, height, width, numPlanes - numGlobalPlanes]) - globalPlaneMask, 0, 1)\n#     smallPlaneMasks = tf.nn.dilation2d(smallPlaneMasks, filter=np.tile(dilationKernel, [1, 1, numPlanes - numGlobalPlanes]), strides=[1, 1, 1, 1], rates=[1, 1, 1, 1], padding=\'SAME\')\n#     smallPlaneMasks = tf.concat([globalPlaneMasks, smallPlaneMasks], axis=3)\n\n\n#     IOUThreshold = 0.9\n#     areaThreshold = 0.25\n\n#     blockSize = 16\n#     smallPlaneInds = tf.nn.avg_pool(smallPlaneMasks, ksize=[1, blockSize, blockSize, 1], strides=[1, blockSize, blockSize, 1], padding=\'VALID\')\n#     smallPlaneAreas = tf.clip_by_value(tf.reduce_sum(smallPlaneInds, axis=[1, 2], keep_dims=True), 1e-4, width * height)    \n#     IOU = smallPlaneInds / smallPlaneAreas\n#     inds = smallPlaneInds\n#     smallPlaneInds = tf.one_hot(tf.argmax(smallPlaneInds, 3), depth=numPlanes) * tf.cast(tf.greater_equal(IOU, IOUThreshold), tf.float32) * tf.cast(tf.greater(smallPlaneInds, areaThreshold), tf.float32)\n\n#     blockSmallPlaneMasks_16 = tf.reshape(tf.space_to_depth(smallPlaneMasks, block_size=blockSize), [batchSize, height / blockSize, width / blockSize, blockSize * blockSize, numPlanes])\n#     blockSmallPlanes_16 = tf.reduce_sum(tf.expand_dims(smallPlaneInds, -1) * tf.expand_dims(tf.expand_dims(planes, 1), 1), axis=3)\n#     blockSmallPlaneMasks_16 = tf.reduce_sum(tf.expand_dims(smallPlaneInds, 3) * blockSmallPlaneMasks_16, axis=4)\n#     blockPlaneIndicators_16 = tf.reduce_max(smallPlaneInds, axis=3, keep_dims=True)\n\n    \n#     blockSize = 32\n#     smallPlaneInds = tf.nn.avg_pool(smallPlaneMasks, ksize=[1, blockSize, blockSize, 1], strides=[1, blockSize, blockSize, 1], padding=\'VALID\')\n#     smallPlaneAreas = tf.clip_by_value(tf.reduce_sum(smallPlaneInds, axis=[1, 2], keep_dims=True), 1e-4, width * height)    \n#     IOU = smallPlaneInds / smallPlaneAreas\n#     inds = smallPlaneInds\n#     smallPlaneInds = tf.one_hot(tf.argmax(smallPlaneInds, 3), depth=numPlanes) * tf.cast(tf.greater_equal(IOU, IOUThreshold), tf.float32) * tf.cast(tf.greater(smallPlaneInds, areaThreshold), tf.float32)\n    \n#     blockSmallPlaneMasks_32 = tf.reshape(tf.space_to_depth(smallPlaneMasks, block_size=blockSize), [batchSize, height / blockSize, width / blockSize, blockSize * blockSize, numPlanes])\n#     blockSmallPlanes_32 = tf.reduce_sum(tf.expand_dims(smallPlaneInds, -1) * tf.expand_dims(tf.expand_dims(planes, 1), 1), axis=3)\n#     blockSmallPlaneMasks_32 = tf.reduce_sum(tf.expand_dims(smallPlaneInds, 3) * blockSmallPlaneMasks_32, axis=4)\n#     blockPlaneIndicators_32 = tf.reduce_max(smallPlaneInds, axis=3, keep_dims=True)\n\n#     return globalPlanes, globalPlaneMasks, blockSmallPlanes_16, blockSmallPlaneMasks_16, blockPlaneIndicators_16, blockSmallPlanes_32, blockSmallPlaneMasks_32, blockPlaneIndicators_32, tf.depth_to_space(blockSmallPlaneMasks_16 * blockPlaneIndicators_16, 16), tf.depth_to_space(blockSmallPlaneMasks_32 * blockPlaneIndicators_32, 32), planeMasks_test, planeDiff, boundaryMask\n\n\n# def planeFittingDepthModule(depth)\n#     width = int(depth.shape[2])\n#     height = int(depth.shape[1])\n\n#     focalLength = 517.97\n#     urange = (tf.range(width, dtype=tf.float32) / (width + 1) - 0.5) / focalLength * 641\n#     urange = tf.tile(tf.reshape(urange, [1, -1]), [height, 1])\n#     vrange = (tf.range(height, dtype=tf.float32) / (height + 1) - 0.5) / focalLength * 481\n#     vrange = tf.tile(tf.reshape(vrange, [-1, 1]), [1, width])\n            \n#     ranges = tf.stack([urange, tf.ones([height, width]), -vrange], axis=2)\n#     ranges = tf.expand_dims(ranges, 0)\n\n#     batchSize = int(depth.shape[0])\n\n#     X = depth * tf.expand_dims(urange, -1)\n#     Y = depth\n#     Z = -depth * tf.expand_dims(vrange, -1)\n#     XYZ = tf.concat([X, Y, Z], axis=3)\n#     XYZ = tf.reshape(XYZ, [-1, height * width, 3])\n\n\t\n\t\ndef findLocalPlanes(planes, planeMasks):\n    batchSize = int(planeMasks.shape[0])\n    height = int(planeMasks.shape[1])\n    width = int(planeMasks.shape[2])\n    numPlanes = int(planeMasks.shape[3])\n    \n    maskWidth = 16\n    maskHeight = 16\n\n    urange = tf.reshape(tf.range(width, dtype=tf.float32), [1, -1, 1])\n    planeXs = tf.reduce_max(planeMasks, axis=1)\n    planeMinX = float(width) - tf.reduce_max(planeXs * (float(width) - urange), axis=1)\n    planeMaxX = tf.reduce_max(planeXs * urange, axis=1)\n\n    vrange = tf.reshape(tf.range(height, dtype=tf.float32), [1, -1, 1])\n    planeYs = tf.reduce_max(planeMasks, axis=2)\n    planeMinY = float(height) - tf.reduce_max(planeYs * (float(height) - vrange), axis=1)\n    planeMaxY = tf.reduce_max(planeYs * vrange, axis=1)\n\n\n    localPlaneWidthThreshold = 64\n    localPlaneHeightThreshold = 64\n    localPlaneMask = tf.logical_and(tf.less(planeMaxX - planeMinX, localPlaneWidthThreshold), tf.less(planeMaxY - planeMinY, localPlaneHeightThreshold))\n\n    \n    stride = 8\n    boxSize = 64\n    xs = tf.tile(tf.expand_dims(tf.range(width / stride, dtype=tf.float32) * stride + stride / 2, 0), [height / stride, 1])\n    ys = tf.tile(tf.expand_dims(tf.range(height / stride, dtype=tf.float32) * stride + stride / 2, 1), [1, width / stride])\n    gridMinX = tf.reshape(xs - boxSize / 2, [1, -1, 1])\n    gridMaxX = tf.reshape(xs + boxSize / 2, [1, -1, 1])\n    gridMinY = tf.reshape(ys - boxSize / 2, [1, -1, 1])\n    gridMaxY = tf.reshape(ys + boxSize / 2, [1, -1, 1])\n    \n    gridMinX = tf.tile(gridMinX, [batchSize, 1, 1])\n    gridMaxX = tf.tile(gridMaxX, [batchSize, 1, 1])\n    gridMinY = tf.tile(gridMinY, [batchSize, 1, 1])\n    gridMaxY = tf.tile(gridMaxY, [batchSize, 1, 1])\n\n    padding = boxSize / 2 + 1\n    padding = boxSize / 2 + 1\n    paddedPlaneMasks = tf.concat([tf.zeros([batchSize, height, padding, numPlanes]), planeMasks, tf.zeros([batchSize, height, padding, numPlanes])], axis=2)\n    paddedPlaneMasks = tf.concat([tf.zeros([batchSize, padding, width + padding * 2, numPlanes]), paddedPlaneMasks, tf.zeros([batchSize, padding, width + padding * 2, numPlanes])], axis=1)\n\n    gridPlaneMasks = []\n    for gridY in xrange(height / stride):\n        for gridX in xrange(width / stride):\n            localPlaneMasks = tf.slice(paddedPlaneMasks, [0, gridY * stride + stride / 2 - boxSize / 2 + padding, gridX * stride + stride / 2 - boxSize / 2 + padding, 0], [batchSize, boxSize, boxSize, numPlanes])\n            gridPlaneMasks.append(tf.image.resize_bilinear(localPlaneMasks, [maskHeight, maskWidth]))\n            continue\n        continue\n    gridPlaneMasks = tf.stack(gridPlaneMasks, axis=1)\n    gridPlaneMasks = tf.reshape(gridPlaneMasks, [batchSize, -1, maskHeight * maskWidth, numPlanes])\n\n    planeMinX = tf.expand_dims(planeMinX, 1)\n    planeMaxX = tf.expand_dims(planeMaxX, 1)\n    planeMinY = tf.expand_dims(planeMinY, 1)\n    planeMaxY = tf.expand_dims(planeMaxY, 1)    \n    intersection = tf.maximum(tf.minimum(gridMaxX, planeMaxX) - tf.maximum(gridMinX, planeMinX) + 1, 0.) * tf.maximum(tf.minimum(gridMaxY, planeMaxY) - tf.maximum(gridMinY, planeMinY) + 1, 0.)\n    union = (gridMaxX - gridMinX + 1) * (gridMaxY - gridMinY + 1) + (planeMaxX - planeMinX + 1) * (planeMaxY - planeMinY + 1) - intersection\n    IOU = intersection / union\n    #maxIOUInds = tf.argmax(IOU, axis=1)\n    #maxIOU = tf.reduce_max(IOU, axis=1)\n    IOU = IOU * tf.expand_dims(tf.cast(localPlaneMask, tf.float32), 1)\n    IOU = IOU * tf.one_hot(tf.argmax(IOU, 1), depth=IOU.shape[1], axis=1)\n    IOUThreshold = 1.0 / pow(boxSize / stride, 2)\n    activeGridMask = tf.one_hot(tf.argmax(IOU, 2), depth=IOU.shape[2], axis=2) * tf.cast(tf.greater(IOU, IOUThreshold), tf.float32)\n    \n    #activeGridMask = tf.one_hot(tf.ones((batchSize, IOU.shape[1]), dtype=tf.int32), depth=IOU.shape[2], axis=2)\n    \n    gridScores = tf.reduce_sum(activeGridMask, axis=2, keep_dims=True)\n    activeGridMask = tf.expand_dims(activeGridMask, -1)\n    gridPlanes = tf.reduce_sum(activeGridMask * tf.expand_dims(planes, 1), axis=2)\n    gridMasks = tf.reduce_sum(activeGridMask * tf.transpose(gridPlaneMasks, [0, 1, 3, 2]), axis=2)\n\n    gridScores = tf.reshape(gridScores, [batchSize, height / stride, width / stride, -1])\n    gridPlanes = tf.reshape(gridPlanes, [batchSize, height / stride, width / stride, -1])\n    gridMasks = tf.reshape(gridMasks, [batchSize, height / stride, width / stride, -1])\n    \n    return gridScores, gridPlanes, gridMasks\n\n\ndef findBoundaries(planes, planeMasks):\n    height = int(planeMasks.shape[0])\n    width = int(planeMasks.shape[1])\n    \n    planesD = tf.norm(planes, axis=1, keep_dims=True)\n    planesD = tf.clip_by_value(planesD, 1e-5, 10)\n    planesNormal = planes / planesD\n\n    ND = tf.expand_dims(planesNormal, 0) * tf.expand_dims(planesD, 1)\n    ND_diff = tf.reshape(ND - tf.transpose(ND, [1, 0, 2]), [-1, 3])\n    coefX, coefY, coefZ = tf.unstack(ND_diff, axis=1)\n\n    pixels = []\n    focalLength = 517.97\n    urange = tf.range(width, dtype=tf.float32) / focalLength\n    ones = tf.ones(urange.shape)\n    vs = (coefX * urange + coefY * ones) / coefZ\n    pixels.append(tf.stack([tf.floor(vs), urange], axis=1))\n    pixels.append(tf.stack([tf.ceil(vs), urange], axis=1))\n    \n    vrange = tf.range(height, dtype=tf.float32) / focalLength\n    ones = tf.ones(vrange.shape)\n    us = -(coefY * ones - coefZ * vrange) / coefX\n    pixels.append(tf.stack([vrange, tf.floor(us)], axis=1))\n    pixels.append(tf.stack([vrange, tf.ceil(us)], axis=1))\n\n    v, u = tf.unstack(pixels, axis=1)\n    validMask = tf.logical_and(tf.less(u, width), tf.less(v, height))\n    validMask = tf.logical_and(validMask, tf.greater_equal(u, 0))\n    validMask = tf.logical_and(validMask, tf.greater_equal(v, 0))\n    \n    pixels *= tf.expand_dims(invalidMask, -1)\n    \n    boundary = tf.sparse_to_dense(pixels, output_shape=[height, width], sparse_values=1)\n    return boundary\n\n\ndef fitPlaneMasksModule(planes, depth, normal, width = 640, height = 480, numPlanes = 20, normalDotThreshold = np.cos(np.deg2rad(5)), distanceThreshold = 0.05, closing=True, one_hot=True):\n    focalLength = 517.97\n    urange = (tf.range(width, dtype=tf.float32) / (width + 1) - 0.5) / focalLength * 641\n    urange = tf.tile(tf.reshape(urange, [1, -1]), [height, 1])\n    vrange = (tf.range(height, dtype=tf.float32) / (height + 1) - 0.5) / focalLength * 481\n    vrange = tf.tile(tf.reshape(vrange, [-1, 1]), [1, width])\n        \n    X = depth * tf.expand_dims(urange, -1)\n    Y = depth\n    Z = -depth * tf.expand_dims(vrange, -1)\n    XYZ = tf.concat([X, Y, Z], axis=3)\n    XYZ = tf.reshape(XYZ, [-1, height * width, 3])\n    plane_parameters = planes\n    planesD = tf.norm(plane_parameters, axis=2, keep_dims=True)\n    planesNormal = tf.div(tf.negative(plane_parameters), tf.clip_by_value(planesD, 1e-4, 10))\n\n    distance = tf.reshape(tf.abs(tf.matmul(XYZ, planesNormal, transpose_b=True) + tf.reshape(planesD, [-1, 1, numPlanes])), [-1, height, width, numPlanes])\n    angle = tf.reshape(np.abs(tf.matmul(tf.reshape(normal, [-1, height * width, 3]), planesNormal, transpose_b=True)), [-1, height, width, numPlanes])\n\n    planeMasks = tf.cast(tf.logical_and(tf.greater(angle, normalDotThreshold), tf.less(distance, distanceThreshold)), tf.float32)\n\n    if closing:\n        #morphological closing\n        planeMasks = tf.nn.max_pool(planeMasks, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n        pass\n    plane_mask = tf.reduce_max(planeMasks, axis=3, keep_dims=True)\n    if one_hot:\n        if closing:\n            plane_mask = 1 - tf.nn.max_pool(1 - plane_mask, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n            pass\n        #one-hot encoding\n        planeMasks = tf.one_hot(tf.argmax(planeMasks * (distanceThreshold - distance), axis=3), depth=numPlanes) * plane_mask\n        pass\n    \n    return planeMasks, plane_mask\n    \n\ndef depthToNormalModule(depth):\n    batchSize = int(depth.shape[0])\n    height = int(depth.shape[1])\n    width = int(depth.shape[2])\n    \n    focalLength = 517.97\n    urange = (tf.range(width, dtype=tf.float32) / width - 0.5) / focalLength * 640\n    urange = tf.tile(tf.reshape(urange, [1, -1]), [height, 1])\n    vrange = (tf.range(height, dtype=tf.float32) / height - 0.5) / focalLength * 480\n    vrange = tf.tile(tf.reshape(vrange, [-1, 1]), [1, width])\n        \n    X = depth * tf.expand_dims(urange, -1)\n    Y = depth\n    Z = -depth * tf.expand_dims(vrange, -1)\n    XYZ = tf.concat([X, Y, Z], axis=3)\n    #XYZ = tf.reshape(XYZ, [-1, height * width, 3])\n\n    \n    kernel_array = np.zeros((3, 3, 1, 4))\n    kernel_array[0, 1, 0, 0] = 1\n    kernel_array[1, 0, 0, 1] = 1\n    kernel_array[2, 1, 0, 2] = 1\n    kernel_array[1, 2, 0, 3] = 1\n    kernel_array[1, 1, 0, 0] = -1\n    kernel_array[1, 1, 0, 1] = -1\n    kernel_array[1, 1, 0, 2] = -1\n    kernel_array[1, 1, 0, 3] = -1\n    kernel = tf.constant(kernel_array.reshape(-1), shape=kernel_array.shape, dtype=tf.float32)\n    XYZ_diff = tf.nn.depthwise_conv2d(tf.pad(XYZ, [[0, 0], [1, 1], [1, 1], [0, 0]], mode=\'REFLECT\'), tf.tile(kernel, [1, 1, 3, 1]), strides=[1, 1, 1, 1], padding=\'VALID\')\n    XYZ_diff = tf.reshape(XYZ_diff, [-1, height, width, 3, 4])\n    XYZ_diff_2 = tf.concat([tf.slice(XYZ_diff, [0, 0, 0, 0, 1], [batchSize, height, width, 3, 3]), tf.slice(XYZ_diff, [0, 0, 0, 0, 0], [batchSize, height, width, 3, 1])], axis=4)\n    XYZ_diff_1 = tf.unstack(XYZ_diff, axis=3)\n    XYZ_diff_2 = tf.unstack(XYZ_diff_2, axis=3)\n\n    normal_X = XYZ_diff_1[1] * XYZ_diff_2[2] - XYZ_diff_1[2] * XYZ_diff_2[1]\n    normal_Y = XYZ_diff_1[2] * XYZ_diff_2[0] - XYZ_diff_1[0] * XYZ_diff_2[2]\n    normal_Z = XYZ_diff_1[0] * XYZ_diff_2[1] - XYZ_diff_1[1] * XYZ_diff_2[0]\n\n    normal_X = tf.reduce_sum(normal_X, axis=[3])\n    normal_Y = tf.reduce_sum(normal_Y, axis=[3])\n    normal_Z = tf.reduce_sum(normal_Z, axis=[3])\n    normal = tf.stack([normal_X, normal_Y, normal_Z], axis=3)\n\n    kernel_size = 5\n    padding = (kernel_size - 1) / 2\n    neighbor_kernel_array = gaussian(kernel_size)\n    #neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n    neighbor_kernel_array /= neighbor_kernel_array.sum()\n    neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n    neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n    normal = tf.nn.depthwise_conv2d(tf.pad(normal, [[0, 0], [padding, padding], [padding, padding], [0, 0]], mode=\'REFLECT\'), tf.tile(neighbor_kernel, [1, 1, 3, 1]), strides=[1, 1, 1, 1], padding=\'VALID\')\n    \n    normal = normal / tf.norm(normal, axis=3, keep_dims=True)\n    return normal\n\ndef findBoundaryModule(depth, normal, segmentation, plane_mask, max_depth_diff = 0.1, max_normal_diff = np.sqrt(2 * (1 - np.cos(np.deg2rad(20))))):\n    kernel_size = 3\n    padding = (kernel_size - 1) / 2\n    neighbor_kernel_array = gaussian(kernel_size)\n    neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n    neighbor_kernel_array /= neighbor_kernel_array.sum()\n    neighbor_kernel_array *= -1\n    neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 1\n    neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n    neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n        \n    depth_diff = tf.abs(tf.nn.depthwise_conv2d(depth, neighbor_kernel, strides=[1, 1, 1, 1], padding=\'VALID\'))\n    depth_diff = tf.pad(depth_diff, paddings = [[0, 0], [padding, padding], [padding, padding], [0, 0]])\n    max_depth_diff = 0.1\n    depth_boundary = tf.greater(depth_diff, max_depth_diff)\n\n    normal_diff = tf.norm(tf.nn.depthwise_conv2d(normal, tf.tile(neighbor_kernel, [1, 1, 3, 1]), strides=[1, 1, 1, 1], padding=\'VALID\'), axis=3, keep_dims=True)\n    normal_diff = tf.pad(normal_diff, paddings = [[0, 0], [padding, padding], [padding, padding], [0, 0]])\n    max_normal_diff = np.sqrt(2 * (1 - np.cos(np.deg2rad(20))))\n    normal_boundary = tf.greater(normal_diff, max_normal_diff)\n\n    plane_region = tf.nn.max_pool(plane_mask, ksize=[1, kernel_size, kernel_size, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n    segmentation_eroded = 1 - tf.nn.max_pool(1 - segmentation, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n    plane_region -= tf.reduce_max(segmentation_eroded, axis=3, keep_dims=True)\n    boundary = tf.cast(tf.logical_or(depth_boundary, normal_boundary), tf.float32) * plane_region\n    #boundary = plane_region\n    #smooth_boundary = tf.cast(tf.less_equal(depth_diff, max_depth_diff), tf.float32) * boundary\n    smooth_boundary = tf.cast(tf.logical_and(normal_boundary, tf.less_equal(depth_diff, max_depth_diff)), tf.float32)\n    smooth_boundary = tf.nn.max_pool(smooth_boundary, ksize=[1, kernel_size, kernel_size, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\') * boundary\n    #smooth_boundary = smooth_boundary * boundary\n    boundary_gt = tf.concat([smooth_boundary, boundary - smooth_boundary], axis=3)\n    return boundary_gt\n\n\ndef findBoundaryModuleSmooth(depth, segmentation, plane_mask, smooth_boundary, max_depth_diff = 0.1, max_normal_diff = np.sqrt(2 * (1 - np.cos(np.deg2rad(20))))):\n    kernel_size = 3\n    padding = (kernel_size - 1) / 2\n    neighbor_kernel_array = gaussian(kernel_size)\n    neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n    neighbor_kernel_array /= neighbor_kernel_array.sum()\n    neighbor_kernel_array *= -1\n    neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 1\n    neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n    neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n        \n    depth_diff = tf.abs(tf.nn.depthwise_conv2d(depth, neighbor_kernel, strides=[1, 1, 1, 1], padding=\'VALID\'))\n    depth_diff = tf.pad(depth_diff, paddings = [[0, 0], [padding, padding], [padding, padding], [0, 0]])\n    max_depth_diff = 0.1\n    depth_boundary = tf.greater(depth_diff, max_depth_diff)\n\n\n    plane_region = tf.nn.max_pool(plane_mask, ksize=[1, kernel_size, kernel_size, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n    segmentation_eroded = 1 - tf.nn.max_pool(1 - segmentation, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n    plane_region -= tf.reduce_max(segmentation_eroded, axis=3, keep_dims=True)\n    occlusion_boundary = tf.cast(depth_boundary, tf.float32) * plane_region\n    #boundary = plane_region\n    #smooth_boundary = tf.cast(tf.less_equal(depth_diff, max_depth_diff), tf.float32) * boundary\n    smooth_boundary = smooth_boundary * plane_region\n    smooth_boundary_dilated = tf.nn.max_pool(smooth_boundary, ksize=[1, kernel_size, kernel_size, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\') * plane_region\n    #smooth_boundary = smooth_boundary * boundary\n    boundary_gt = tf.concat([smooth_boundary, tf.maximum(occlusion_boundary - smooth_boundary_dilated, 0)], axis=3)\n    return boundary_gt\n\n\ndef crfModule(segmentations, planes, non_plane_depth, info, numOutputPlanes=20, numIterations=20, kernel_size = 9):\n    width = int(segmentations.shape[2])\n    height = int(segmentations.shape[1])\n    \n    #maxDepthDiff = tf.Variable(0.3)\n    #sigmaDepthDiff = tf.Variable(0.5)\n    maxDepthDiff = 0.3\n    sigmaDepthDiff = 0.5\n\n    plane_parameters = tf.reshape(planes, (-1, 3))\n    plane_depths = planeDepthsModule(plane_parameters, width, height, info)\n    plane_depths = tf.transpose(tf.reshape(plane_depths, [height, width, -1, numOutputPlanes]), [2, 0, 1, 3])\n    all_depths = tf.concat([plane_depths, non_plane_depth], axis=3)\n    \n    refined_segmentation = segmentations\n    for _ in xrange(numIterations):\n        refined_segmentation = meanfieldModule(refined_segmentation, all_depths, numOutputPlanes=numOutputPlanes + 1, sigmaDepthDiff=sigmaDepthDiff, kernel_size = kernel_size)\n        continue\n    return refined_segmentation\n\ndef divideLayers(segmentations, planes, non_plane_mask, info, num_planes, numOutputPlanes_0=5, validAreaRatio=0.95, distanceThreshold=0.05):\n    batchSize = int(planes.shape[0])    \n    numOutputPlanes = int(planes.shape[1])\n    width = int(segmentations.shape[2])\n    height = int(segmentations.shape[1])\n    \n    plane_parameters = tf.reshape(planes, (-1, 3))\n    plane_depths = planeDepthsModule(plane_parameters, width, height, info)\n    plane_depths = tf.transpose(tf.reshape(plane_depths, [height, width, -1, numOutputPlanes]), [2, 0, 1, 3])\n    depth = tf.reduce_sum(plane_depths * segmentations[:, :, :, :numOutputPlanes], axis=3, keep_dims=True)\n    #non_plane_mask = segmentations[:, :, :, numOutputPlanes:numOutputPlanes+1]\n    \n    background_mask = tf.logical_or(tf.logical_or(tf.less(plane_depths, 1e-4), tf.greater(plane_depths, depth - distanceThreshold)), tf.cast(non_plane_mask, tf.bool))\n    background_planes = tf.greater(tf.reduce_mean(tf.cast(background_mask, tf.float32), axis=[1, 2]), validAreaRatio)\n    validPlaneMask = tf.less(tf.tile(tf.expand_dims(tf.range(numOutputPlanes), 0), [batchSize, 1]), tf.expand_dims(num_planes, -1))\n    background_planes = tf.logical_and(background_planes, validPlaneMask)\n    background_planes = tf.cast(background_planes, tf.float32)\n    plane_areas = tf.reduce_sum(segmentations[:, :, :, :numOutputPlanes], axis=[1, 2])\n    \n    layer_plane_areas_0 = plane_areas * background_planes    \n    areas, sortInds = tf.nn.top_k(layer_plane_areas_0, k=numOutputPlanes_0)\n    sortMap = tf.one_hot(sortInds, depth=numOutputPlanes, axis=1)\n    validMask = tf.cast(tf.greater(areas, 1e-4), tf.float32)\n    sortMap *= tf.expand_dims(validMask, 1)\n    layer_segmentations_0 = tf.reshape(tf.matmul(tf.reshape(segmentations, [batchSize, height * width, -1]), sortMap), [batchSize, height, width, -1])\n    layer_planes_0 = tf.transpose(tf.matmul(planes, sortMap, transpose_a=True), [0, 2, 1])\n\n\n    layer_plane_areas_1 = plane_areas * (1 - background_planes)\n    areas, sortInds = tf.nn.top_k(layer_plane_areas_1, k=numOutputPlanes - numOutputPlanes_0)\n    sortMap = tf.one_hot(sortInds, depth=numOutputPlanes, axis=1)\n    validMask = tf.cast(tf.greater(areas, 1e-4), tf.float32)\n    sortMap *= tf.expand_dims(validMask, 1)\n    layer_segmentations_1 = tf.reshape(tf.matmul(tf.reshape(segmentations, [batchSize, height * width, -1]), sortMap), [batchSize, height, width, -1])\n    layer_planes_1 = tf.transpose(tf.matmul(planes, sortMap, transpose_a=True), [0, 2, 1])\n    \n    \n    return tf.concat([layer_segmentations_0, layer_segmentations_1], axis=3), tf.concat([layer_planes_0, layer_planes_1], axis=1)\n\n\n\ndef calcMessages(planeSegmentations, planeDepths, planesY, numOutputPlanes = 21, coef = [1, 1, 1], beta = 1, iteration = 0, maxDepthDiff = 0.2, varDepthDiff = 0.5, kernel_size = 9):\n    #images, varImageDiff\n    batchSize = int(planeSegmentations.shape[0])\n    height = int(planeSegmentations.shape[1])\n    width = int(planeSegmentations.shape[2])\n\n\n    n2 = tf.pow(tf.reshape(planesY, [batchSize, 1, 1, -1]), 2)\n    d2n2s = tf.reduce_sum(tf.pow(planeDepths, 2) * n2 * planeSegmentations, axis=-1, keep_dims=True)\n    dnsd = tf.reduce_sum(planeDepths * n2 * planeSegmentations, axis=-1, keep_dims=True) * planeDepths\n    n2sd2 = tf.reduce_sum(n2 * planeSegmentations, axis=-1, keep_dims=True) * tf.pow(planeDepths, 2)\n\n    messages = d2n2s - 2 * dnsd + n2sd2\n\n    maxDepthDiff = 0.2\n    messages = tf.minimum(messages / pow(maxDepthDiff, 2), 1)\n    \n    # vertical_padding = tf.zeros((batchSize, height, 1, numOutputPlanes))\n    # horizontal_padding = tf.zeros((batchSize, height, 1, numOutputPlanes))    \n\n\n    # neighbor_kernel_array = gaussian(kernel_size)\n    # neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n    # neighbor_kernel_array /= neighbor_kernel_array.sum()\n    # neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n    # neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n    \n    # messages = tf.nn.depthwise_conv2d(messages, tf.tile(neighbor_kernel, [1, 1, numOutputPlanes, 1]), strides=[1, 1, 1, 1], padding=\'SAME\')\n\n    return messages\n\n\ndef crfrnnModule(inputs, image_dims, num_classes, theta_alpha, theta_beta, theta_gamma, num_iterations):\n    custom_module = tf.load_op_library(\'./cpp/high_dim_filter.so\')\n    import high_dim_filter_grad  # Register gradients for the custom op\n\n    weights = np.load(\'weights.npy\')\n    weights = [weights[0], weights[1], weights[2]]\n    spatial_ker_weights = tf.Variable(weights[0][:num_classes, :num_classes], name=\'spatial_ker_weights\', trainable=True)\n    bilateral_ker_weights = tf.Variable(weights[1][:num_classes, :num_classes], name=\'bilateral_ker_weights\', trainable=True)\n    compatibility_matrix = tf.Variable(weights[2][:num_classes, :num_classes], name=\'compatibility_matrix\', trainable=True)\n    \n\n    batchSize = int(inputs[0].shape[0])\n    c, h, w = num_classes, image_dims[0], image_dims[1]\n    all_ones = np.ones((c, h, w), dtype=np.float32)\n\n    outputs = []\n    for batchIndex in xrange(batchSize):\n        unaries = tf.transpose(inputs[0][batchIndex, :, :, :], perm=(2, 0, 1))\n        rgb = tf.transpose(inputs[1][batchIndex, :, :, :], perm=(2, 0, 1))\n\n\n        # Prepare filter normalization coefficients\n        spatial_norm_vals = custom_module.high_dim_filter(all_ones, rgb, bilateral=False,\n                                                          theta_gamma=theta_gamma)\n        bilateral_norm_vals = custom_module.high_dim_filter(all_ones, rgb, bilateral=True,\n                                                            theta_alpha=theta_alpha,\n                                                            theta_beta=theta_beta)\n        q_values = unaries\n\n        for i in range(num_iterations):\n            softmax_out = tf.nn.softmax(q_values, dim=0)\n\n            # Spatial filtering\n            spatial_out = custom_module.high_dim_filter(softmax_out, rgb, bilateral=False,\n                                                        theta_gamma=theta_gamma)\n            spatial_out = spatial_out / spatial_norm_vals\n\n            # Bilateral filtering\n            bilateral_out = custom_module.high_dim_filter(softmax_out, rgb, bilateral=True,\n                                                          theta_alpha=theta_alpha,\n                                                          theta_beta=theta_beta)\n            bilateral_out = bilateral_out / bilateral_norm_vals\n\n            # Weighting filter outputs\n            message_passing = (tf.matmul(spatial_ker_weights,\n                                         tf.reshape(spatial_out, (c, -1))) +\n                               tf.matmul(bilateral_ker_weights,\n                                         tf.reshape(bilateral_out, (c, -1))))\n\n            # Compatibility transform\n            pairwise = tf.matmul(compatibility_matrix, message_passing)\n\n            # Adding unary potentials\n            pairwise = tf.reshape(pairwise, (c, h, w))\n            q_values = unaries - pairwise\n            continue\n        outputs.append(tf.transpose(tf.reshape(q_values, (1, c, h, w)), perm=(0, 2, 3, 1)))\n        continue\n    outputs = tf.concat(outputs, axis=0)\n    return outputs\n'"
code/plane_utils.py,0,b''
code/planenet.py,86,"b""# Converted to TensorFlow .caffemodel\n# with the DeepLab-ResNet configuration.\n# The batch normalisation layer is provided by\n# the slim library (https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim).\n\nfrom kaffe.tensorflow import Network\nimport tensorflow as tf\n\nclass PlaneNet(Network):\n    def setup(self, is_training, options):\n        '''Network definition.\n        \n        Args:\n          is_training: whether to update the running mean and variance of the batch normalisation layer.\n                       If the batch size is small, it is better to keep the running mean and variance of \n                       the-pretrained model frozen.\n          options: contains network configuration parameters\n        '''\n\n        nChannels_3 = 1024\n        nChannels_4 = 1024\n        nChannels_5 = 2048\n        if False: # Dilated Residual Networks change the first few layers to deal with the gridding issue\n            (self.feed('img_inp')\n                 .conv(7, 7, 64, 2, 2, biased=False, relu=False, name='conv1')\n                 .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn_conv1')\n                 .max_pool(3, 3, 2, 2, name='pool1'))\n            \n            (self.feed('pool1')\n                 .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res2a_branch1')\n                 .batch_normalization(is_training=is_training, activation_fn=None, name='bn2a_branch1'))\n                 \n            (self.feed('pool1')\n                 .conv(1, 1, 64, 1, 1, biased=False, relu=False, name='res2a_branch2a')\n                 .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn2a_branch2a')\n                 .conv(3, 3, 64, 1, 1, biased=False, relu=False, name='res2a_branch2b')\n                 .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn2a_branch2b')\n                 .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res2a_branch2c')\n                 .batch_normalization(is_training=is_training, activation_fn=None, name='bn2a_branch2c'))            \n        else:\n            with tf.variable_scope('degridding'):\n                (self.feed('img_inp')\n                     .conv(7, 7, 16, 1, 1, biased=False, relu=False, name='conv1')\n                     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn1')\n                     .conv(1, 1, 16, 2, 2, biased=False, relu=False, name='conv2_c')\n                     .batch_normalization(is_training=is_training, activation_fn=None, name='bn2c'))\n\n                (self.feed('bn1')\n                     .conv(3, 3, 16, 1, 1, biased=False, relu=False, name='conv2a')\n                     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn2a')\n                     .conv(3, 3, 16, 2, 2, biased=False, relu=False, name='conv2b')\n                     .batch_normalization(is_training=is_training, activation_fn=None, name='bn2b'))\n                \n                (self.feed('bn2b',\n                           'bn2c')\n                     .add(name='add1')\n                     .relu(name='relu1')\n                     .conv(1, 1, 32, 2, 2, biased=False, relu=False, name='conv3c')\n                     .batch_normalization(is_training=is_training, activation_fn=None, name='bn3c'))\n                (self.feed('relu1')\n                     .conv(3, 3, 32, 1, 1, biased=False, relu=False, name='conv3a')\n                     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3a')\n                     .conv(3, 3, 32, 2, 2, biased=False, relu=False, name='conv3b')\n                     .batch_normalization(is_training=is_training, activation_fn=None, name='bn3b'))\n                (self.feed('bn3b',\n                           'bn3c')\n                     .add(name='add2')\n                     .relu(name='pool1'))\n\n                pass\n            pass\n\n        (self.feed('pool1')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res2a_branch1')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn2a_branch1'))\n                 \n        (self.feed('pool1')\n             .conv(1, 1, 64, 1, 1, biased=False, relu=False, name='res2a_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn2a_branch2a')\n             .conv(3, 3, 64, 1, 1, biased=False, relu=False, name='res2a_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn2a_branch2b')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res2a_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn2a_branch2c'))\n\n        (self.feed('bn2a_branch1', \n                   'bn2a_branch2c')\n             .add(name='res2a')\n             .relu(name='res2a_relu')\n             .conv(1, 1, 64, 1, 1, biased=False, relu=False, name='res2b_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn2b_branch2a')\n             .conv(3, 3, 64, 1, 1, biased=False, relu=False, name='res2b_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn2b_branch2b')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res2b_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn2b_branch2c'))\n\n        (self.feed('res2a_relu', \n                   'bn2b_branch2c')\n             .add(name='res2b')\n             .relu(name='res2b_relu')\n             .conv(1, 1, 64, 1, 1, biased=False, relu=False, name='res2c_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn2c_branch2a')\n             .conv(3, 3, 64, 1, 1, biased=False, relu=False, name='res2c_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn2c_branch2b')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res2c_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn2c_branch2c'))\n\n        (self.feed('res2b_relu', \n                   'bn2c_branch2c')\n             .add(name='res2c')\n             .relu(name='res2c_relu')\n             .conv(1, 1, 512, 2, 2, biased=False, relu=False, name='res3a_branch1')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn3a_branch1'))\n\n        (self.feed('res2c_relu')\n             .conv(1, 1, 128, 2, 2, biased=False, relu=False, name='res3a_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3a_branch2a')\n             .conv(3, 3, 128, 1, 1, biased=False, relu=False, name='res3a_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3a_branch2b')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res3a_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn3a_branch2c'))\n\n        (self.feed('bn3a_branch1', \n                   'bn3a_branch2c')\n             .add(name='res3a')\n             .relu(name='res3a_relu')\n             .conv(1, 1, 128, 1, 1, biased=False, relu=False, name='res3b1_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3b1_branch2a')\n             .conv(3, 3, 128, 1, 1, biased=False, relu=False, name='res3b1_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3b1_branch2b')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res3b1_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn3b1_branch2c'))\n\n        (self.feed('res3a_relu', \n                   'bn3b1_branch2c')\n             .add(name='res3b1')\n             .relu(name='res3b1_relu')\n             .conv(1, 1, 128, 1, 1, biased=False, relu=False, name='res3b2_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3b2_branch2a')\n             .conv(3, 3, 128, 1, 1, biased=False, relu=False, name='res3b2_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3b2_branch2b')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res3b2_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn3b2_branch2c'))\n\n        (self.feed('res3b1_relu', \n                   'bn3b2_branch2c')\n             .add(name='res3b2')\n             .relu(name='res3b2_relu')\n             .conv(1, 1, 128, 1, 1, biased=False, relu=False, name='res3b3_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3b3_branch2a')\n             .conv(3, 3, 128, 1, 1, biased=False, relu=False, name='res3b3_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3b3_branch2b')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res3b3_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn3b3_branch2c'))\n\n        (self.feed('res3b2_relu', \n                   'bn3b3_branch2c')\n             .add(name='res3b3')\n             .relu(name='res3b3_relu')\n             .conv(1, 1, nChannels_3, 1, 1, biased=False, relu=False, name='res4a_branch1')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4a_branch1'))\n\n        (self.feed('res3b3_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4a_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4a_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4a_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4a_branch2b')\n             .conv(1, 1, nChannels_3, 1, 1, biased=False, relu=False, name='res4a_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4a_branch2c'))\n\n        (self.feed('bn4a_branch1', \n                   'bn4a_branch2c')\n             .add(name='res4a')\n             .relu(name='res4a_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b1_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b1_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b1_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b1_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b1_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b1_branch2c'))\n\n        (self.feed('res4a_relu', \n                   'bn4b1_branch2c')\n             .add(name='res4b1')\n             .relu(name='res4b1_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b2_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b2_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b2_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b2_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b2_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b2_branch2c'))\n\n        (self.feed('res4b1_relu', \n                   'bn4b2_branch2c')\n             .add(name='res4b2')\n             .relu(name='res4b2_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b3_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b3_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b3_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b3_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b3_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b3_branch2c'))\n\n        (self.feed('res4b2_relu', \n                   'bn4b3_branch2c')\n             .add(name='res4b3')\n             .relu(name='res4b3_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b4_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b4_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b4_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b4_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b4_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b4_branch2c'))\n\n        (self.feed('res4b3_relu', \n                   'bn4b4_branch2c')\n             .add(name='res4b4')\n             .relu(name='res4b4_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b5_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b5_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b5_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b5_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b5_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b5_branch2c'))\n\n        (self.feed('res4b4_relu', \n                   'bn4b5_branch2c')\n             .add(name='res4b5')\n             .relu(name='res4b5_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b6_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b6_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b6_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b6_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b6_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b6_branch2c'))\n\n        (self.feed('res4b5_relu', \n                   'bn4b6_branch2c')\n             .add(name='res4b6')\n             .relu(name='res4b6_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b7_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b7_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b7_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b7_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b7_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b7_branch2c'))\n\n        (self.feed('res4b6_relu', \n                   'bn4b7_branch2c')\n             .add(name='res4b7')\n             .relu(name='res4b7_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b8_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b8_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b8_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b8_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b8_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b8_branch2c'))\n\n        (self.feed('res4b7_relu', \n                   'bn4b8_branch2c')\n             .add(name='res4b8')\n             .relu(name='res4b8_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b9_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b9_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b9_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b9_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b9_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b9_branch2c'))\n\n        (self.feed('res4b8_relu', \n                   'bn4b9_branch2c')\n             .add(name='res4b9')\n             .relu(name='res4b9_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b10_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b10_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b10_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b10_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b10_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b10_branch2c'))\n\n        (self.feed('res4b9_relu', \n                   'bn4b10_branch2c')\n             .add(name='res4b10')\n             .relu(name='res4b10_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b11_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b11_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b11_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b11_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b11_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b11_branch2c'))\n\n        (self.feed('res4b10_relu', \n                   'bn4b11_branch2c')\n             .add(name='res4b11')\n             .relu(name='res4b11_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b12_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b12_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b12_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b12_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b12_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b12_branch2c'))\n\n        (self.feed('res4b11_relu', \n                   'bn4b12_branch2c')\n             .add(name='res4b12')\n             .relu(name='res4b12_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b13_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b13_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b13_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b13_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b13_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b13_branch2c'))\n\n        (self.feed('res4b12_relu', \n                   'bn4b13_branch2c')\n             .add(name='res4b13')\n             .relu(name='res4b13_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b14_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b14_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b14_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b14_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b14_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b14_branch2c'))\n\n        (self.feed('res4b13_relu', \n                   'bn4b14_branch2c')\n             .add(name='res4b14')\n             .relu(name='res4b14_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b15_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b15_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b15_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b15_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b15_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b15_branch2c'))\n\n        (self.feed('res4b14_relu', \n                   'bn4b15_branch2c')\n             .add(name='res4b15')\n             .relu(name='res4b15_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b16_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b16_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b16_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b16_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b16_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b16_branch2c'))\n\n        (self.feed('res4b15_relu', \n                   'bn4b16_branch2c')\n             .add(name='res4b16')\n             .relu(name='res4b16_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b17_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b17_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b17_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b17_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b17_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b17_branch2c'))\n\n        (self.feed('res4b16_relu', \n                   'bn4b17_branch2c')\n             .add(name='res4b17')\n             .relu(name='res4b17_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b18_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b18_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b18_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b18_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b18_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b18_branch2c'))\n\n        (self.feed('res4b17_relu', \n                   'bn4b18_branch2c')\n             .add(name='res4b18')\n             .relu(name='res4b18_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b19_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b19_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b19_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b19_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b19_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b19_branch2c'))\n\n        (self.feed('res4b18_relu', \n                   'bn4b19_branch2c')\n             .add(name='res4b19')\n             .relu(name='res4b19_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b20_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b20_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b20_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b20_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b20_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b20_branch2c'))\n\n        (self.feed('res4b19_relu', \n                   'bn4b20_branch2c')\n             .add(name='res4b20')\n             .relu(name='res4b20_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b21_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b21_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b21_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b21_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b21_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b21_branch2c'))\n\n        (self.feed('res4b20_relu', \n                   'bn4b21_branch2c')\n             .add(name='res4b21')\n             .relu(name='res4b21_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b22_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b22_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b22_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b22_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b22_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b22_branch2c'))\n\n        (self.feed('res4b21_relu', \n                   'bn4b22_branch2c')\n             .add(name='res4b22')\n             .relu(name='res4b22_relu')\n             .conv(1, 1, nChannels_5, 1, 1, biased=False, relu=False, name='res5a_branch1')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn5a_branch1'))\n\n        (self.feed('res4b22_relu')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res5a_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn5a_branch2a')\n             .atrous_conv(3, 3, 512, 4, padding='SAME', biased=False, relu=False, name='res5a_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn5a_branch2b')\n             .conv(1, 1, nChannels_5, 1, 1, biased=False, relu=False, name='res5a_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn5a_branch2c'))\n\n        (self.feed('bn5a_branch1', \n                   'bn5a_branch2c')\n             .add(name='res5a')\n             .relu(name='res5a_relu')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res5b_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn5b_branch2a')\n             .atrous_conv(3, 3, 512, 4, padding='SAME', biased=False, relu=False, name='res5b_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn5b_branch2b')\n             .conv(1, 1, nChannels_5, 1, 1, biased=False, relu=False, name='res5b_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn5b_branch2c'))\n\n        (self.feed('res5a_relu', \n                   'bn5b_branch2c')\n             .add(name='res5b')\n             .relu(name='res5b_relu')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res5c_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn5c_branch2a')\n             .atrous_conv(3, 3, 512, 4, padding='SAME', biased=False, relu=False, name='res5c_branch2b')\n             .batch_normalization(activation_fn=tf.nn.relu, name='bn5c_branch2b', is_training=is_training)\n             .conv(1, 1, nChannels_5, 1, 1, biased=False, relu=False, name='res5c_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn5c_branch2c'))\n\n        (self.feed('res5b_relu', \n                   'bn5c_branch2c')\n             .add(name='res5c')\n             .relu(name='res5c_relu'))\n\n        \n        \n        (self.feed('res5c_relu')\n             .avg_pool(24, 32, 24, 32, name='res5d_pool1')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res5d_pool1_conv')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='res5d_pool1_bn')\n             .resize_bilinear(size=[24, 32], name='res5d_upsample1'))\n\n        (self.feed('res5c_relu')\n             .avg_pool(12, 16, 12, 16, name='res5d_pool2')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res5d_pool2_conv')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='res5d_pool2_bn')\n             .resize_bilinear(size=[24, 32], name='res5d_upsample2'))\n\n        (self.feed('res5c_relu')\n             .avg_pool(6, 8, 6, 8, name='res5d_pool3')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res5d_pool3_conv')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='res5d_pool3_bn')\n             .resize_bilinear(size=[24, 32], name='res5d_upsample3'))\n\n        (self.feed('res5c_relu')\n             .avg_pool(3, 4, 3, 4, name='res5d_pool4')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res5d_pool4_conv')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='res5d_pool4_bn')\n             .resize_bilinear(size=[24, 32], name='res5d_upsample4'))\n\n\n        #deep supervision at layers in list options.deepSupervisionLayers\n        if len(options.deepSupervisionLayers) > 0:\n            with tf.variable_scope('deep_supervision'):\n                for layerIndex, layer in enumerate(options.deepSupervisionLayers):\n                    (self.feed(layer)\n                         .avg_pool(24, 32, 24, 32, name=layer+'_pool1')\n                         .conv(1, 1, 512, 1, 1, biased=False, relu=False, name=layer+'_pool1_conv')\n                         .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=layer+'_pool1_bn')\n                         .resize_bilinear(size=[24, 32], name=layer+'_upsample1'))\n            \n                    (self.feed(layer)\n                         .avg_pool(12, 16, 12, 16, name=layer+'_pool2')\n                         .conv(1, 1, 512, 1, 1, biased=False, relu=False, name=layer+'_pool2_conv')\n                         .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=layer+'_pool2_bn')\n                         .resize_bilinear(size=[24, 32], name=layer+'_upsample2'))\n            \n                    (self.feed(layer)\n                         .avg_pool(6, 8, 6, 8, name=layer+'_pool3')\n                         .conv(1, 1, 512, 1, 1, biased=False, relu=False, name=layer+'_pool3_conv')\n                         .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=layer+'_pool3_bn')\n                         .resize_bilinear(size=[24, 32], name=layer+'_upsample3'))\n\n                    (self.feed(layer)\n                         .avg_pool(3, 4, 3, 4, name=layer+'_pool4')\n                         .conv(1, 1, 512, 1, 1, biased=False, relu=False, name=layer+'_pool4_conv')\n                         .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=layer+'_pool4_bn')\n                         .resize_bilinear(size=[24, 32], name=layer+'_upsample4'))\n\n                    \n                    (self.feed(layer+'_pool1')\n                         .reshape(shape=[-1, nChannels_4], name=layer+'_plane_reshape1')\n                         .fc(num_out=options.numOutputPlanes * 3, name=layer+'_plane_fc', relu=False)\n                         .reshape(shape=[-1, options.numOutputPlanes, 3], name=layer+'_plane_pred'))\n\n                    if options.predictConfidence == 1:\n                        (self.feed(layer+'_plane_reshape1')\n                             .fc(num_out=options.numOutputPlanes, name=layer+'_plane_confidence_fc', relu=False)\n                             .reshape(shape=[-1, options.numOutputPlanes, 1], name=layer+'_plane_confidence_pred'))\n                        pass\n                    \n                    (self.feed(layer,\n                               layer+'_upsample1',\n                               layer+'_upsample2',\n                               layer+'_upsample3',\n                               layer+'_upsample4')\n                         .concat(axis=3, name=layer+'_segmentation_concat')\n                         .conv(3, 3, 512, 1, 1, biased=False, relu=False, name=layer+'_segmentation_conv1')\n                         .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=layer+'_segmentation_bn1')\n                         .dropout(keep_prob=0.9, name=layer+'_segmentation_dropout')\n                         .conv(1, 1, options.numOutputPlanes, 1, 1, relu=False, name=layer+'_segmentation_conv2')\n                         .resize_bilinear(size=[192, 256], name=layer+'_segmentation_pred'))\n\n                    (self.feed(layer+'_segmentation_dropout')\n                         .conv(1, 1, 1, 1, 1, relu=False, name=layer+'_non_plane_mask_conv2')\n                         .resize_bilinear(size=[192, 256], name=layer+'_non_plane_mask_pred'))\n                    # (self.feed(layer+'_segmentation_dropout')\n                    #      .conv(1, 1, 1, 1, 1, relu=False, name=layer+'_non_plane_depth_conv2')\n                    #      .resize_bilinear(size=[192, 256], name=layer+'_non_plane_depth_pred'))\n                    # (self.feed(layer+'_segmentation_dropout')\n                    #      .conv(1, 1, 3, 1, 1, relu=False, name=layer+'_non_plane_normal_conv2')\n                    #      .resize_bilinear(size=[192, 256], name=layer+'_non_plane_normal_pred'))\n                    continue\n                pass\n            pass\n            \n\n\n        (self.feed('res5d_pool1')\n             .reshape(shape=[-1, nChannels_5], name='plane_reshape1')\n             .fc(num_out=options.numOutputPlanes * 3, name='plane_fc', relu=False)\n             .reshape(shape=[-1, options.numOutputPlanes, 3], name='plane_pred'))\n\n        if options.predictConfidence == 1:\n            (self.feed('plane_reshape1')\n                 .fc(num_out=options.numOutputPlanes, name='plane_confidence_fc', relu=False)\n                 .reshape(shape=[-1, options.numOutputPlanes, 1], name='plane_confidence_pred'))\n            pass\n             \n        (self.feed('res5c_relu',\n                   'res5d_upsample1',\n                   'res5d_upsample2',\n                   'res5d_upsample3',\n                   'res5d_upsample4')\n             .concat(axis=3, name='segmentation_concat')\n             .conv(3, 3, 512, 1, 1, biased=False, relu=False, name='segmentation_conv1')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='segmentation_bn1')\n             .dropout(keep_prob=0.9, name='segmentation_dropout')\n             .conv(1, 1, options.numOutputPlanes, 1, 1, relu=False, name='segmentation_conv2')\n             .resize_bilinear(size=[192, 256], name='segmentation_pred'))\n        \n\n        (self.feed('segmentation_dropout')\n             .conv(1, 1, 1, 1, 1, relu=False, name='non_plane_mask_conv2')\n             .resize_bilinear(size=[192, 256], name='non_plane_mask_pred'))\n        (self.feed('segmentation_dropout')\n             .conv(1, 1, 1, 1, 1, relu=False, name='non_plane_depth_conv2')\n             .resize_bilinear(size=[192, 256], name='non_plane_depth_pred'))\n        (self.feed('segmentation_dropout')\n             .conv(1, 1, 3, 1, 1, relu=False, name='non_plane_normal_conv2')\n             .resize_bilinear(size=[192, 256], name='non_plane_normal_pred'))\n\n        if options.predictSemantics == 1:\n            (self.feed('segmentation_dropout')\n                 .conv(1, 1, 41, 1, 1, relu=False, name='semantics_conv2')\n                 .resize_bilinear(size=[192, 256], name='semantics_pred'))\n            pass\n        \n\n        #boundary prediction\n        if options.predictBoundary == 1:\n            (self.feed('segmentation_dropout')\n                 .conv(1, 1, 1, 1, 1, relu=False, name='boundary_smooth_conv5')\n                 .resize_bilinear(size=[192, 256], name='boundary_smooth_upsample5'))\n            (self.feed('segmentation_dropout')\n                 .conv(1, 1, 1, 1, 1, relu=False, name='boundary_occlusion_conv5')\n                 .resize_bilinear(size=[192, 256], name='boundary_occlusion_upsample5'))\n            (self.feed('bn1')\n                 .conv(1, 1, 1, 1, 1, relu=False, name='boundary_conv0')\n                 .resize_bilinear(size=[192, 256], name='boundary_upsample0'))\n            (self.feed('relu1')\n                 .conv(1, 1, 1, 1, 1, relu=False, name='boundary_conv1')\n                 .resize_bilinear(size=[192, 256], name='boundary_upsample1'))\n            (self.feed('res2c_relu')\n                 .conv(1, 1, 1, 1, 1, relu=False, name='boundary_conv2')\n                 .resize_bilinear(size=[192, 256], name='boundary_upsample2'))\n            (self.feed('res3b3_relu')\n                 .conv(1, 1, 1, 1, 1, relu=False, name='boundary_conv3')\n                 .resize_bilinear(size=[192, 256], name='boundary_upsample3'))\n            (self.feed('boundary_smooth_upsample5',\n                       'boundary_upsample0',                   \n                       'boundary_upsample1',\n                       'boundary_upsample2',\n                       'boundary_upsample3')\n                 .concat(axis=3, name='boundary_smooth_concat')         \n                 .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='boundary_smooth_bn')\n                 .conv(1, 1, 1, 1, 1, relu=False, name='boundary_smooth_pred'))\n            (self.feed('boundary_occlusion_upsample5',\n                       'boundary_upsample0',\n                       'boundary_upsample1',\n                       'boundary_upsample2',\n                       'boundary_upsample3')\n                 .concat(axis=3, name='boundary_occlusion_concat')\n                 .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='boundary_occlusion_bn')\n                 .conv(1, 1, 1, 1, 1, relu=False, name='boundary_occlusion_pred'))\n            (self.feed('boundary_smooth_pred',\n                       'boundary_occlusion_pred')\n                 .concat(axis=3, name='boundary_pred'))\n            pass\n\n        #local prediction\n        if options.predictLocal == 1:\n            (self.feed('segmentation_dropout')\n                 .conv(1, 1, 1, 1, 1, relu=False, name='local_score_pred'))\n            (self.feed('segmentation_dropout')\n                 .conv(1, 1, 3, 1, 1, relu=False, name='local_plane_pred'))\n            (self.feed('segmentation_dropout')\n                 .conv(1, 1, 16*16, 1, 1, relu=False, name='local_mask_pred'))\n            pass\n            \n"""
code/planenet_group.py,86,"b""# Converted to TensorFlow .caffemodel\n# with the DeepLab-ResNet configuration.\n# The batch normalisation layer is provided by\n# the slim library (https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim).\n\nfrom kaffe.tensorflow import Network\nimport tensorflow as tf\n\nclass PlaneNet(Network):\n    def setup(self, is_training, options):\n        '''Network definition.\n        \n        Args:\n          is_training: whether to update the running mean and variance of the batch normalisation layer.\n                       If the batch size is small, it is better to keep the running mean and variance of \n                       the-pretrained model frozen.\n          options: contains network configuration parameters\n        '''\n\n        if False: # Dilated Residual Networks change the first few layers to deal with the gridding issue\n            (self.feed('img_inp')\n                 .conv(7, 7, 64, 2, 2, biased=False, relu=False, name='conv1')\n                 .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn_conv1')\n                 .max_pool(3, 3, 2, 2, name='pool1'))\n            \n            (self.feed('pool1')\n                 .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res2a_branch1')\n                 .batch_normalization(is_training=is_training, activation_fn=None, name='bn2a_branch1'))\n                 \n            (self.feed('pool1')\n                 .conv(1, 1, 64, 1, 1, biased=False, relu=False, name='res2a_branch2a')\n                 .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn2a_branch2a')\n                 .conv(3, 3, 64, 1, 1, biased=False, relu=False, name='res2a_branch2b')\n                 .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn2a_branch2b')\n                 .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res2a_branch2c')\n                 .batch_normalization(is_training=is_training, activation_fn=None, name='bn2a_branch2c'))            \n        else:\n            with tf.variable_scope('degridding'):\n                (self.feed('img_inp')\n                     .conv(7, 7, 16, 1, 1, biased=False, relu=False, name='conv1')\n                     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn1')\n                     .conv(1, 1, 16, 2, 2, biased=False, relu=False, name='conv2_c')\n                     .batch_normalization(is_training=is_training, activation_fn=None, name='bn2c'))\n\n                (self.feed('bn1')\n                     .conv(3, 3, 16, 1, 1, biased=False, relu=False, name='conv2a')\n                     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn2a')\n                     .conv(3, 3, 16, 2, 2, biased=False, relu=False, name='conv2b')\n                     .batch_normalization(is_training=is_training, activation_fn=None, name='bn2b'))\n                \n                (self.feed('bn2b',\n                           'bn2c')\n                     .add(name='add1')\n                     .relu(name='relu1')\n                     .conv(1, 1, 32, 2, 2, biased=False, relu=False, name='conv3c')\n                     .batch_normalization(is_training=is_training, activation_fn=None, name='bn3c'))\n                (self.feed('relu1')\n                     .conv(3, 3, 32, 1, 1, biased=False, relu=False, name='conv3a')\n                     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3a')\n                     .conv(3, 3, 32, 2, 2, biased=False, relu=False, name='conv3b')\n                     .batch_normalization(is_training=is_training, activation_fn=None, name='bn3b'))\n                (self.feed('bn3b',\n                           'bn3c')\n                     .add(name='add2')\n                     .relu(name='pool1'))\n\n                pass\n            pass\n\n        (self.feed('pool1')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res2a_branch1')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn2a_branch1'))\n                 \n        (self.feed('pool1')\n             .conv(1, 1, 64, 1, 1, biased=False, relu=False, name='res2a_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn2a_branch2a')\n             .conv(3, 3, 64, 1, 1, biased=False, relu=False, name='res2a_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn2a_branch2b')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res2a_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn2a_branch2c'))\n\n        (self.feed('bn2a_branch1', \n                   'bn2a_branch2c')\n             .add(name='res2a')\n             .relu(name='res2a_relu')\n             .conv(1, 1, 64, 1, 1, biased=False, relu=False, name='res2b_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn2b_branch2a')\n             .conv(3, 3, 64, 1, 1, biased=False, relu=False, name='res2b_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn2b_branch2b')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res2b_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn2b_branch2c'))\n\n        (self.feed('res2a_relu', \n                   'bn2b_branch2c')\n             .add(name='res2b')\n             .relu(name='res2b_relu')\n             .conv(1, 1, 64, 1, 1, biased=False, relu=False, name='res2c_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn2c_branch2a')\n             .conv(3, 3, 64, 1, 1, biased=False, relu=False, name='res2c_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn2c_branch2b')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res2c_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn2c_branch2c'))\n\n        (self.feed('res2b_relu', \n                   'bn2c_branch2c')\n             .add(name='res2c')\n             .relu(name='res2c_relu')\n             .conv(1, 1, 512, 2, 2, biased=False, relu=False, name='res3a_branch1')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn3a_branch1'))\n\n        (self.feed('res2c_relu')\n             .conv(1, 1, 128, 2, 2, biased=False, relu=False, name='res3a_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3a_branch2a')\n             .conv(3, 3, 128, 1, 1, biased=False, relu=False, name='res3a_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3a_branch2b')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res3a_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn3a_branch2c'))\n\n        (self.feed('bn3a_branch1', \n                   'bn3a_branch2c')\n             .add(name='res3a')\n             .relu(name='res3a_relu')\n             .conv(1, 1, 128, 1, 1, biased=False, relu=False, name='res3b1_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3b1_branch2a')\n             .conv(3, 3, 128, 1, 1, biased=False, relu=False, name='res3b1_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3b1_branch2b')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res3b1_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn3b1_branch2c'))\n\n        (self.feed('res3a_relu', \n                   'bn3b1_branch2c')\n             .add(name='res3b1')\n             .relu(name='res3b1_relu')\n             .conv(1, 1, 128, 1, 1, biased=False, relu=False, name='res3b2_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3b2_branch2a')\n             .conv(3, 3, 128, 1, 1, biased=False, relu=False, name='res3b2_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3b2_branch2b')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res3b2_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn3b2_branch2c'))\n\n        (self.feed('res3b1_relu', \n                   'bn3b2_branch2c')\n             .add(name='res3b2')\n             .relu(name='res3b2_relu')\n             .conv(1, 1, 128, 1, 1, biased=False, relu=False, name='res3b3_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3b3_branch2a')\n             .conv(3, 3, 128, 1, 1, biased=False, relu=False, name='res3b3_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3b3_branch2b')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res3b3_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn3b3_branch2c'))\n\n        (self.feed('res3b2_relu', \n                   'bn3b3_branch2c')\n             .add(name='res3b3')\n             .relu(name='res3b3_relu')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4a_branch1')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4a_branch1'))\n\n        (self.feed('res3b3_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4a_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4a_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4a_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4a_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4a_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4a_branch2c'))\n\n        (self.feed('bn4a_branch1', \n                   'bn4a_branch2c')\n             .add(name='res4a')\n             .relu(name='res4a_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b1_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b1_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b1_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b1_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b1_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b1_branch2c'))\n\n        (self.feed('res4a_relu', \n                   'bn4b1_branch2c')\n             .add(name='res4b1')\n             .relu(name='res4b1_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b2_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b2_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b2_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b2_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b2_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b2_branch2c'))\n\n        (self.feed('res4b1_relu', \n                   'bn4b2_branch2c')\n             .add(name='res4b2')\n             .relu(name='res4b2_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b3_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b3_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b3_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b3_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b3_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b3_branch2c'))\n\n        (self.feed('res4b2_relu', \n                   'bn4b3_branch2c')\n             .add(name='res4b3')\n             .relu(name='res4b3_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b4_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b4_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b4_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b4_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b4_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b4_branch2c'))\n\n        (self.feed('res4b3_relu', \n                   'bn4b4_branch2c')\n             .add(name='res4b4')\n             .relu(name='res4b4_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b5_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b5_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b5_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b5_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b5_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b5_branch2c'))\n\n        (self.feed('res4b4_relu', \n                   'bn4b5_branch2c')\n             .add(name='res4b5')\n             .relu(name='res4b5_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b6_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b6_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b6_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b6_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b6_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b6_branch2c'))\n\n        (self.feed('res4b5_relu', \n                   'bn4b6_branch2c')\n             .add(name='res4b6')\n             .relu(name='res4b6_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b7_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b7_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b7_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b7_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b7_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b7_branch2c'))\n\n        (self.feed('res4b6_relu', \n                   'bn4b7_branch2c')\n             .add(name='res4b7')\n             .relu(name='res4b7_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b8_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b8_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b8_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b8_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b8_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b8_branch2c'))\n\n        (self.feed('res4b7_relu', \n                   'bn4b8_branch2c')\n             .add(name='res4b8')\n             .relu(name='res4b8_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b9_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b9_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b9_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b9_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b9_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b9_branch2c'))\n\n        (self.feed('res4b8_relu', \n                   'bn4b9_branch2c')\n             .add(name='res4b9')\n             .relu(name='res4b9_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b10_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b10_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b10_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b10_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b10_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b10_branch2c'))\n\n        (self.feed('res4b9_relu', \n                   'bn4b10_branch2c')\n             .add(name='res4b10')\n             .relu(name='res4b10_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b11_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b11_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b11_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b11_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b11_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b11_branch2c'))\n\n        (self.feed('res4b10_relu', \n                   'bn4b11_branch2c')\n             .add(name='res4b11')\n             .relu(name='res4b11_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b12_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b12_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b12_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b12_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b12_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b12_branch2c'))\n\n        (self.feed('res4b11_relu', \n                   'bn4b12_branch2c')\n             .add(name='res4b12')\n             .relu(name='res4b12_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b13_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b13_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b13_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b13_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b13_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b13_branch2c'))\n\n        (self.feed('res4b12_relu', \n                   'bn4b13_branch2c')\n             .add(name='res4b13')\n             .relu(name='res4b13_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b14_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b14_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b14_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b14_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b14_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b14_branch2c'))\n\n        (self.feed('res4b13_relu', \n                   'bn4b14_branch2c')\n             .add(name='res4b14')\n             .relu(name='res4b14_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b15_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b15_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b15_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b15_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b15_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b15_branch2c'))\n\n        (self.feed('res4b14_relu', \n                   'bn4b15_branch2c')\n             .add(name='res4b15')\n             .relu(name='res4b15_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b16_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b16_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b16_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b16_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b16_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b16_branch2c'))\n\n        (self.feed('res4b15_relu', \n                   'bn4b16_branch2c')\n             .add(name='res4b16')\n             .relu(name='res4b16_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b17_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b17_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b17_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b17_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b17_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b17_branch2c'))\n\n        (self.feed('res4b16_relu', \n                   'bn4b17_branch2c')\n             .add(name='res4b17')\n             .relu(name='res4b17_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b18_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b18_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b18_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b18_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b18_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b18_branch2c'))\n\n        (self.feed('res4b17_relu', \n                   'bn4b18_branch2c')\n             .add(name='res4b18')\n             .relu(name='res4b18_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b19_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b19_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b19_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b19_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b19_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b19_branch2c'))\n\n        (self.feed('res4b18_relu', \n                   'bn4b19_branch2c')\n             .add(name='res4b19')\n             .relu(name='res4b19_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b20_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b20_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b20_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b20_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b20_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b20_branch2c'))\n\n        (self.feed('res4b19_relu', \n                   'bn4b20_branch2c')\n             .add(name='res4b20')\n             .relu(name='res4b20_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b21_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b21_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b21_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b21_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b21_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b21_branch2c'))\n\n        (self.feed('res4b20_relu', \n                   'bn4b21_branch2c')\n             .add(name='res4b21')\n             .relu(name='res4b21_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b22_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b22_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b22_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b22_branch2b')\n             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b22_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b22_branch2c'))\n\n        (self.feed('res4b21_relu', \n                   'bn4b22_branch2c')\n             .add(name='res4b22')\n             .relu(name='res4b22_relu')\n             .conv(1, 1, 2048, 1, 1, biased=False, relu=False, name='res5a_branch1')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn5a_branch1'))\n\n        (self.feed('res4b22_relu')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res5a_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn5a_branch2a')\n             .atrous_conv(3, 3, 512, 4, padding='SAME', biased=False, relu=False, name='res5a_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn5a_branch2b')\n             .conv(1, 1, 2048, 1, 1, biased=False, relu=False, name='res5a_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn5a_branch2c'))\n\n        (self.feed('bn5a_branch1', \n                   'bn5a_branch2c')\n             .add(name='res5a')\n             .relu(name='res5a_relu')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res5b_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn5b_branch2a')\n             .atrous_conv(3, 3, 512, 4, padding='SAME', biased=False, relu=False, name='res5b_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn5b_branch2b')\n             .conv(1, 1, 2048, 1, 1, biased=False, relu=False, name='res5b_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn5b_branch2c'))\n\n        (self.feed('res5a_relu', \n                   'bn5b_branch2c')\n             .add(name='res5b')\n             .relu(name='res5b_relu')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res5c_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn5c_branch2a')\n             .atrous_conv(3, 3, 512, 4, padding='SAME', biased=False, relu=False, name='res5c_branch2b')\n             .batch_normalization(activation_fn=tf.nn.relu, name='bn5c_branch2b', is_training=is_training)\n             .conv(1, 1, 2048, 1, 1, biased=False, relu=False, name='res5c_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn5c_branch2c'))\n\n        (self.feed('res5b_relu', \n                   'bn5c_branch2c')\n             .add(name='res5c')\n             .relu(name='res5c_relu'))\n\n        \n        \n        (self.feed('res5c_relu')\n             .avg_pool(24, 32, 24, 32, name='res5d_pool1')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res5d_pool1_conv')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='res5d_pool1_bn')\n             .resize_bilinear(size=[24, 32], name='res5d_upsample1'))\n\n        (self.feed('res5c_relu')\n             .avg_pool(12, 16, 12, 16, name='res5d_pool2')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res5d_pool2_conv')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='res5d_pool2_bn')\n             .resize_bilinear(size=[24, 32], name='res5d_upsample2'))\n\n        (self.feed('res5c_relu')\n             .avg_pool(6, 8, 6, 8, name='res5d_pool3')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res5d_pool3_conv')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='res5d_pool3_bn')\n             .resize_bilinear(size=[24, 32], name='res5d_upsample3'))\n\n        (self.feed('res5c_relu')\n             .avg_pool(3, 4, 3, 4, name='res5d_pool4')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res5d_pool4_conv')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='res5d_pool4_bn')\n             .resize_bilinear(size=[24, 32], name='res5d_upsample4'))\n\n\n        #deep supervision at layers in list options.deepSupervisionLayers\n        if len(options.deepSupervisionLayers) > 0:\n            with tf.variable_scope('deep_supervision'):\n                for layerIndex, layer in enumerate(options.deepSupervisionLayers):\n                    (self.feed(layer)\n                         .avg_pool(24, 32, 24, 32, name=layer+'_pool1')\n                         .conv(1, 1, 512, 1, 1, biased=False, relu=False, name=layer+'_pool1_conv')\n                         .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=layer+'_pool1_bn')\n                         .resize_bilinear(size=[24, 32], name=layer+'_upsample1'))\n            \n                    (self.feed(layer)\n                         .avg_pool(12, 16, 12, 16, name=layer+'_pool2')\n                         .conv(1, 1, 512, 1, 1, biased=False, relu=False, name=layer+'_pool2_conv')\n                         .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=layer+'_pool2_bn')\n                         .resize_bilinear(size=[24, 32], name=layer+'_upsample2'))\n            \n                    (self.feed(layer)\n                         .avg_pool(6, 8, 6, 8, name=layer+'_pool3')\n                         .conv(1, 1, 512, 1, 1, biased=False, relu=False, name=layer+'_pool3_conv')\n                         .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=layer+'_pool3_bn')\n                         .resize_bilinear(size=[24, 32], name=layer+'_upsample3'))\n\n                    (self.feed(layer)\n                         .avg_pool(3, 4, 3, 4, name=layer+'_pool4')\n                         .conv(1, 1, 512, 1, 1, biased=False, relu=False, name=layer+'_pool4_conv')\n                         .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=layer+'_pool4_bn')\n                         .resize_bilinear(size=[24, 32], name=layer+'_upsample4'))\n\n                    \n                    (self.feed(layer+'_pool1')\n                         .reshape(shape=[-1, 1024], name=layer+'_plane_reshape1')\n                         .fc(num_out=options.numOutputPlanes * 3, name=layer+'_plane_fc', relu=False)\n                         .reshape(shape=[-1, options.numOutputPlanes, 3], name=layer+'_plane_pred'))\n\n                    if options.predictConfidence == 1 and layerIndex > 0:\n                        (self.feed(layer+'_plane_reshape1')\n                             .fc(num_out=options.numOutputPlanes, name=layer+'_plane_confidence_fc', relu=False)\n                             .reshape(shape=[-1, options.numOutputPlanes, 1], name=layer+'_plane_confidence_pred'))\n                        pass\n                    \n                    (self.feed(layer,\n                               layer+'_upsample1',\n                               layer+'_upsample2',\n                               layer+'_upsample3',\n                               layer+'_upsample4')\n                         .concat(axis=3, name=layer+'_segmentation_concat')\n                         .conv(3, 3, 512, 1, 1, biased=False, relu=False, name=layer+'_segmentation_conv1')\n                         .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=layer+'_segmentation_bn1')\n                         .dropout(keep_prob=0.9, name=layer+'_segmentation_dropout')\n                         .conv(1, 1, options.numConcaveGroups + options.numConvexGroups, 1, 1, relu=False, name=layer+'_segmentation_conv2')\n                         .resize_bilinear(size=[192, 256], name=layer+'_segmentation_pred'))\n\n                    (self.feed(layer+'_segmentation_dropout')\n                         .conv(1, 1, 1, 1, 1, relu=False, name=layer+'_non_plane_mask_conv2')\n                         .resize_bilinear(size=[192, 256], name=layer+'_non_plane_mask_pred'))\n                    # (self.feed(layer+'_segmentation_dropout')\n                    #      .conv(1, 1, 1, 1, 1, relu=False, name=layer+'_non_plane_depth_conv2')\n                    #      .resize_bilinear(size=[192, 256], name=layer+'_non_plane_depth_pred'))\n                    # (self.feed(layer+'_segmentation_dropout')\n                    #      .conv(1, 1, 3, 1, 1, relu=False, name=layer+'_non_plane_normal_conv2')\n                    #      .resize_bilinear(size=[192, 256], name=layer+'_non_plane_normal_pred'))\n                    continue\n                pass\n            pass\n            \n\n\n        (self.feed('res5d_pool1')\n             .reshape(shape=[-1, 2048], name='plane_reshape1')\n             .fc(num_out=options.numOutputPlanes * 3, name='plane_fc', relu=False)\n             .reshape(shape=[-1, options.numOutputPlanes, 3], name='plane_pred'))\n\n        if options.predictConfidence == 1:\n            (self.feed('plane_reshape1')\n                 .fc(num_out=options.numOutputPlanes, name='plane_confidence_fc', relu=False)\n                 .reshape(shape=[-1, options.numOutputPlanes, 1], name='plane_confidence_pred'))\n            pass\n             \n        (self.feed('res5c_relu',\n                   'res5d_upsample1',\n                   'res5d_upsample2',\n                   'res5d_upsample3',\n                   'res5d_upsample4')\n             .concat(axis=3, name='segmentation_concat')\n             .conv(3, 3, 512, 1, 1, biased=False, relu=False, name='segmentation_conv1')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='segmentation_bn1')\n             .dropout(keep_prob=0.9, name='segmentation_dropout')\n             .conv(1, 1, options.numConcaveGroups + options.numConvexGroups, 1, 1, relu=False, name='segmentation_conv2')\n             .resize_bilinear(size=[192, 256], name='segmentation_pred'))\n        \n\n        (self.feed('segmentation_dropout')\n             .conv(1, 1, 1, 1, 1, relu=False, name='non_plane_mask_conv2')\n             .resize_bilinear(size=[192, 256], name='non_plane_mask_pred'))\n        (self.feed('segmentation_dropout')\n             .conv(1, 1, 1, 1, 1, relu=False, name='non_plane_depth_conv2')\n             .resize_bilinear(size=[192, 256], name='non_plane_depth_pred'))\n        (self.feed('segmentation_dropout')\n             .conv(1, 1, 3, 1, 1, relu=False, name='non_plane_normal_conv2')\n             .resize_bilinear(size=[192, 256], name='non_plane_normal_pred'))\n\n\n        #boundary prediction\n        if options.predictBoundary == 1:\n            (self.feed('segmentation_dropout')\n                 .conv(1, 1, 1, 1, 1, relu=False, name='boundary_smooth_conv5')\n                 .resize_bilinear(size=[192, 256], name='boundary_smooth_upsample5'))\n            (self.feed('segmentation_dropout')\n                 .conv(1, 1, 1, 1, 1, relu=False, name='boundary_occlusion_conv5')\n                 .resize_bilinear(size=[192, 256], name='boundary_occlusion_upsample5'))\n            (self.feed('bn1')\n                 .conv(1, 1, 1, 1, 1, relu=False, name='boundary_conv0')\n                 .resize_bilinear(size=[192, 256], name='boundary_upsample0'))\n            (self.feed('relu1')\n                 .conv(1, 1, 1, 1, 1, relu=False, name='boundary_conv1')\n                 .resize_bilinear(size=[192, 256], name='boundary_upsample1'))\n            (self.feed('res2c_relu')\n                 .conv(1, 1, 1, 1, 1, relu=False, name='boundary_conv2')\n                 .resize_bilinear(size=[192, 256], name='boundary_upsample2'))\n            (self.feed('res3b3_relu')\n                 .conv(1, 1, 1, 1, 1, relu=False, name='boundary_conv3')\n                 .resize_bilinear(size=[192, 256], name='boundary_upsample3'))\n            (self.feed('boundary_smooth_upsample5',\n                       'boundary_upsample0',                   \n                       'boundary_upsample1',\n                       'boundary_upsample2',\n                       'boundary_upsample3')\n                 .concat(axis=3, name='boundary_smooth_concat')         \n                 .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='boundary_smooth_bn')\n                 .conv(1, 1, 1, 1, 1, relu=False, name='boundary_smooth_pred'))\n            (self.feed('boundary_occlusion_upsample5',\n                       'boundary_upsample0',\n                       'boundary_upsample1',\n                       'boundary_upsample2',\n                       'boundary_upsample3')\n                 .concat(axis=3, name='boundary_occlusion_concat')\n                 .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='boundary_occlusion_bn')\n                 .conv(1, 1, 1, 1, 1, relu=False, name='boundary_occlusion_pred'))\n            (self.feed('boundary_smooth_pred',\n                       'boundary_occlusion_pred')\n                 .concat(axis=3, name='boundary_pred'))\n            pass\n\n        #local prediction\n        if options.predictLocal == 1:\n            (self.feed('segmentation_dropout')\n                 .conv(1, 1, 1, 1, 1, relu=False, name='local_score_pred'))\n            (self.feed('segmentation_dropout')\n                 .conv(1, 1, 3, 1, 1, relu=False, name='local_plane_pred'))\n            (self.feed('segmentation_dropout')\n                 .conv(1, 1, 16*16, 1, 1, relu=False, name='local_mask_pred'))\n            pass\n            \n"""
code/planenet_layer.py,86,"b""# Converted to TensorFlow .caffemodel\n# with the DeepLab-ResNet configuration.\n# The batch normalisation layer is provided by\n# the slim library (https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim).\n\nfrom kaffe.tensorflow import Network\nimport tensorflow as tf\n\nclass PlaneNet(Network):\n    def setup(self, is_training, options):\n        '''Network definition.\n        \n        Args:\n          is_training: whether to update the running mean and variance of the batch normalisation layer.\n                       If the batch size is small, it is better to keep the running mean and variance of \n                       the-pretrained model frozen.\n          options: contains network configuration parameters\n        '''\n\n        nChannels_3 = 1024\n        nChannels_4 = 1024\n        nChannels_5 = 2048\n        if False: # Dilated Residual Networks change the first few layers to deal with the gridding issue\n            (self.feed('img_inp')\n                 .conv(7, 7, 64, 2, 2, biased=False, relu=False, name='conv1')\n                 .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn_conv1')\n                 .max_pool(3, 3, 2, 2, name='pool1'))\n            \n            (self.feed('pool1')\n                 .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res2a_branch1')\n                 .batch_normalization(is_training=is_training, activation_fn=None, name='bn2a_branch1'))\n                 \n            (self.feed('pool1')\n                 .conv(1, 1, 64, 1, 1, biased=False, relu=False, name='res2a_branch2a')\n                 .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn2a_branch2a')\n                 .conv(3, 3, 64, 1, 1, biased=False, relu=False, name='res2a_branch2b')\n                 .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn2a_branch2b')\n                 .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res2a_branch2c')\n                 .batch_normalization(is_training=is_training, activation_fn=None, name='bn2a_branch2c'))            \n        else:\n            with tf.variable_scope('degridding'):\n                (self.feed('img_inp')\n                     .conv(7, 7, 16, 1, 1, biased=False, relu=False, name='conv1')\n                     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn1')\n                     .conv(1, 1, 16, 2, 2, biased=False, relu=False, name='conv2_c')\n                     .batch_normalization(is_training=is_training, activation_fn=None, name='bn2c'))\n\n                (self.feed('bn1')\n                     .conv(3, 3, 16, 1, 1, biased=False, relu=False, name='conv2a')\n                     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn2a')\n                     .conv(3, 3, 16, 2, 2, biased=False, relu=False, name='conv2b')\n                     .batch_normalization(is_training=is_training, activation_fn=None, name='bn2b'))\n                \n                (self.feed('bn2b',\n                           'bn2c')\n                     .add(name='add1')\n                     .relu(name='relu1')\n                     .conv(1, 1, 32, 2, 2, biased=False, relu=False, name='conv3c')\n                     .batch_normalization(is_training=is_training, activation_fn=None, name='bn3c'))\n                (self.feed('relu1')\n                     .conv(3, 3, 32, 1, 1, biased=False, relu=False, name='conv3a')\n                     .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3a')\n                     .conv(3, 3, 32, 2, 2, biased=False, relu=False, name='conv3b')\n                     .batch_normalization(is_training=is_training, activation_fn=None, name='bn3b'))\n                (self.feed('bn3b',\n                           'bn3c')\n                     .add(name='add2')\n                     .relu(name='pool1'))\n\n                pass\n            pass\n\n        (self.feed('pool1')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res2a_branch1')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn2a_branch1'))\n                 \n        (self.feed('pool1')\n             .conv(1, 1, 64, 1, 1, biased=False, relu=False, name='res2a_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn2a_branch2a')\n             .conv(3, 3, 64, 1, 1, biased=False, relu=False, name='res2a_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn2a_branch2b')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res2a_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn2a_branch2c'))\n\n        (self.feed('bn2a_branch1', \n                   'bn2a_branch2c')\n             .add(name='res2a')\n             .relu(name='res2a_relu')\n             .conv(1, 1, 64, 1, 1, biased=False, relu=False, name='res2b_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn2b_branch2a')\n             .conv(3, 3, 64, 1, 1, biased=False, relu=False, name='res2b_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn2b_branch2b')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res2b_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn2b_branch2c'))\n\n        (self.feed('res2a_relu', \n                   'bn2b_branch2c')\n             .add(name='res2b')\n             .relu(name='res2b_relu')\n             .conv(1, 1, 64, 1, 1, biased=False, relu=False, name='res2c_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn2c_branch2a')\n             .conv(3, 3, 64, 1, 1, biased=False, relu=False, name='res2c_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn2c_branch2b')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res2c_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn2c_branch2c'))\n\n        (self.feed('res2b_relu', \n                   'bn2c_branch2c')\n             .add(name='res2c')\n             .relu(name='res2c_relu')\n             .conv(1, 1, 512, 2, 2, biased=False, relu=False, name='res3a_branch1')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn3a_branch1'))\n\n        (self.feed('res2c_relu')\n             .conv(1, 1, 128, 2, 2, biased=False, relu=False, name='res3a_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3a_branch2a')\n             .conv(3, 3, 128, 1, 1, biased=False, relu=False, name='res3a_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3a_branch2b')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res3a_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn3a_branch2c'))\n\n        (self.feed('bn3a_branch1', \n                   'bn3a_branch2c')\n             .add(name='res3a')\n             .relu(name='res3a_relu')\n             .conv(1, 1, 128, 1, 1, biased=False, relu=False, name='res3b1_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3b1_branch2a')\n             .conv(3, 3, 128, 1, 1, biased=False, relu=False, name='res3b1_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3b1_branch2b')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res3b1_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn3b1_branch2c'))\n\n        (self.feed('res3a_relu', \n                   'bn3b1_branch2c')\n             .add(name='res3b1')\n             .relu(name='res3b1_relu')\n             .conv(1, 1, 128, 1, 1, biased=False, relu=False, name='res3b2_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3b2_branch2a')\n             .conv(3, 3, 128, 1, 1, biased=False, relu=False, name='res3b2_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3b2_branch2b')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res3b2_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn3b2_branch2c'))\n\n        (self.feed('res3b1_relu', \n                   'bn3b2_branch2c')\n             .add(name='res3b2')\n             .relu(name='res3b2_relu')\n             .conv(1, 1, 128, 1, 1, biased=False, relu=False, name='res3b3_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3b3_branch2a')\n             .conv(3, 3, 128, 1, 1, biased=False, relu=False, name='res3b3_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn3b3_branch2b')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res3b3_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn3b3_branch2c'))\n\n        (self.feed('res3b2_relu', \n                   'bn3b3_branch2c')\n             .add(name='res3b3')\n             .relu(name='res3b3_relu')\n             .conv(1, 1, nChannels_3, 1, 1, biased=False, relu=False, name='res4a_branch1')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4a_branch1'))\n\n        (self.feed('res3b3_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4a_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4a_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4a_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4a_branch2b')\n             .conv(1, 1, nChannels_3, 1, 1, biased=False, relu=False, name='res4a_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4a_branch2c'))\n\n        (self.feed('bn4a_branch1', \n                   'bn4a_branch2c')\n             .add(name='res4a')\n             .relu(name='res4a_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b1_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b1_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b1_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b1_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b1_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b1_branch2c'))\n\n        (self.feed('res4a_relu', \n                   'bn4b1_branch2c')\n             .add(name='res4b1')\n             .relu(name='res4b1_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b2_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b2_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b2_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b2_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b2_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b2_branch2c'))\n\n        (self.feed('res4b1_relu', \n                   'bn4b2_branch2c')\n             .add(name='res4b2')\n             .relu(name='res4b2_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b3_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b3_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b3_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b3_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b3_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b3_branch2c'))\n\n        (self.feed('res4b2_relu', \n                   'bn4b3_branch2c')\n             .add(name='res4b3')\n             .relu(name='res4b3_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b4_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b4_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b4_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b4_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b4_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b4_branch2c'))\n\n        (self.feed('res4b3_relu', \n                   'bn4b4_branch2c')\n             .add(name='res4b4')\n             .relu(name='res4b4_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b5_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b5_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b5_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b5_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b5_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b5_branch2c'))\n\n        (self.feed('res4b4_relu', \n                   'bn4b5_branch2c')\n             .add(name='res4b5')\n             .relu(name='res4b5_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b6_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b6_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b6_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b6_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b6_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b6_branch2c'))\n\n        (self.feed('res4b5_relu', \n                   'bn4b6_branch2c')\n             .add(name='res4b6')\n             .relu(name='res4b6_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b7_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b7_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b7_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b7_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b7_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b7_branch2c'))\n\n        (self.feed('res4b6_relu', \n                   'bn4b7_branch2c')\n             .add(name='res4b7')\n             .relu(name='res4b7_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b8_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b8_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b8_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b8_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b8_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b8_branch2c'))\n\n        (self.feed('res4b7_relu', \n                   'bn4b8_branch2c')\n             .add(name='res4b8')\n             .relu(name='res4b8_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b9_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b9_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b9_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b9_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b9_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b9_branch2c'))\n\n        (self.feed('res4b8_relu', \n                   'bn4b9_branch2c')\n             .add(name='res4b9')\n             .relu(name='res4b9_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b10_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b10_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b10_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b10_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b10_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b10_branch2c'))\n\n        (self.feed('res4b9_relu', \n                   'bn4b10_branch2c')\n             .add(name='res4b10')\n             .relu(name='res4b10_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b11_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b11_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b11_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b11_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b11_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b11_branch2c'))\n\n        (self.feed('res4b10_relu', \n                   'bn4b11_branch2c')\n             .add(name='res4b11')\n             .relu(name='res4b11_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b12_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b12_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b12_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b12_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b12_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b12_branch2c'))\n\n        (self.feed('res4b11_relu', \n                   'bn4b12_branch2c')\n             .add(name='res4b12')\n             .relu(name='res4b12_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b13_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b13_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b13_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b13_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b13_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b13_branch2c'))\n\n        (self.feed('res4b12_relu', \n                   'bn4b13_branch2c')\n             .add(name='res4b13')\n             .relu(name='res4b13_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b14_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b14_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b14_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b14_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b14_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b14_branch2c'))\n\n        (self.feed('res4b13_relu', \n                   'bn4b14_branch2c')\n             .add(name='res4b14')\n             .relu(name='res4b14_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b15_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b15_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b15_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b15_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b15_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b15_branch2c'))\n\n        (self.feed('res4b14_relu', \n                   'bn4b15_branch2c')\n             .add(name='res4b15')\n             .relu(name='res4b15_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b16_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b16_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b16_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b16_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b16_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b16_branch2c'))\n\n        (self.feed('res4b15_relu', \n                   'bn4b16_branch2c')\n             .add(name='res4b16')\n             .relu(name='res4b16_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b17_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b17_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b17_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b17_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b17_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b17_branch2c'))\n\n        (self.feed('res4b16_relu', \n                   'bn4b17_branch2c')\n             .add(name='res4b17')\n             .relu(name='res4b17_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b18_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b18_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b18_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b18_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b18_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b18_branch2c'))\n\n        (self.feed('res4b17_relu', \n                   'bn4b18_branch2c')\n             .add(name='res4b18')\n             .relu(name='res4b18_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b19_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b19_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b19_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b19_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b19_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b19_branch2c'))\n\n        (self.feed('res4b18_relu', \n                   'bn4b19_branch2c')\n             .add(name='res4b19')\n             .relu(name='res4b19_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b20_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b20_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b20_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b20_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b20_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b20_branch2c'))\n\n        (self.feed('res4b19_relu', \n                   'bn4b20_branch2c')\n             .add(name='res4b20')\n             .relu(name='res4b20_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b21_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b21_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b21_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b21_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b21_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b21_branch2c'))\n\n        (self.feed('res4b20_relu', \n                   'bn4b21_branch2c')\n             .add(name='res4b21')\n             .relu(name='res4b21_relu')\n             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b22_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b22_branch2a')\n             .atrous_conv(3, 3, 256, 2, padding='SAME', biased=False, relu=False, name='res4b22_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn4b22_branch2b')\n             .conv(1, 1, nChannels_4, 1, 1, biased=False, relu=False, name='res4b22_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn4b22_branch2c'))\n\n        (self.feed('res4b21_relu', \n                   'bn4b22_branch2c')\n             .add(name='res4b22')\n             .relu(name='res4b22_relu')\n             .conv(1, 1, nChannels_5, 1, 1, biased=False, relu=False, name='res5a_branch1')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn5a_branch1'))\n\n        (self.feed('res4b22_relu')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res5a_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn5a_branch2a')\n             .atrous_conv(3, 3, 512, 4, padding='SAME', biased=False, relu=False, name='res5a_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn5a_branch2b')\n             .conv(1, 1, nChannels_5, 1, 1, biased=False, relu=False, name='res5a_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn5a_branch2c'))\n\n        (self.feed('bn5a_branch1', \n                   'bn5a_branch2c')\n             .add(name='res5a')\n             .relu(name='res5a_relu')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res5b_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn5b_branch2a')\n             .atrous_conv(3, 3, 512, 4, padding='SAME', biased=False, relu=False, name='res5b_branch2b')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn5b_branch2b')\n             .conv(1, 1, nChannels_5, 1, 1, biased=False, relu=False, name='res5b_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn5b_branch2c'))\n\n        (self.feed('res5a_relu', \n                   'bn5b_branch2c')\n             .add(name='res5b')\n             .relu(name='res5b_relu')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res5c_branch2a')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='bn5c_branch2a')\n             .atrous_conv(3, 3, 512, 4, padding='SAME', biased=False, relu=False, name='res5c_branch2b')\n             .batch_normalization(activation_fn=tf.nn.relu, name='bn5c_branch2b', is_training=is_training)\n             .conv(1, 1, nChannels_5, 1, 1, biased=False, relu=False, name='res5c_branch2c')\n             .batch_normalization(is_training=is_training, activation_fn=None, name='bn5c_branch2c'))\n\n        (self.feed('res5b_relu', \n                   'bn5c_branch2c')\n             .add(name='res5c')\n             .relu(name='res5c_relu'))\n\n        \n        \n        (self.feed('res5c_relu')\n             .avg_pool(24, 32, 24, 32, name='res5d_pool1')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res5d_pool1_conv')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='res5d_pool1_bn')\n             .resize_bilinear(size=[24, 32], name='res5d_upsample1'))\n\n        (self.feed('res5c_relu')\n             .avg_pool(12, 16, 12, 16, name='res5d_pool2')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res5d_pool2_conv')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='res5d_pool2_bn')\n             .resize_bilinear(size=[24, 32], name='res5d_upsample2'))\n\n        (self.feed('res5c_relu')\n             .avg_pool(6, 8, 6, 8, name='res5d_pool3')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res5d_pool3_conv')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='res5d_pool3_bn')\n             .resize_bilinear(size=[24, 32], name='res5d_upsample3'))\n\n        (self.feed('res5c_relu')\n             .avg_pool(3, 4, 3, 4, name='res5d_pool4')\n             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res5d_pool4_conv')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='res5d_pool4_bn')\n             .resize_bilinear(size=[24, 32], name='res5d_upsample4'))\n\n\n        #deep supervision at layers in list options.deepSupervisionLayers\n        if len(options.deepSupervisionLayers) > 0:\n            with tf.variable_scope('deep_supervision'):\n                for layerIndex, layer in enumerate(options.deepSupervisionLayers):\n                    (self.feed(layer)\n                         .avg_pool(24, 32, 24, 32, name=layer+'_pool1')\n                         .conv(1, 1, 512, 1, 1, biased=False, relu=False, name=layer+'_pool1_conv')\n                         .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=layer+'_pool1_bn')\n                         .resize_bilinear(size=[24, 32], name=layer+'_upsample1'))\n            \n                    (self.feed(layer)\n                         .avg_pool(12, 16, 12, 16, name=layer+'_pool2')\n                         .conv(1, 1, 512, 1, 1, biased=False, relu=False, name=layer+'_pool2_conv')\n                         .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=layer+'_pool2_bn')\n                         .resize_bilinear(size=[24, 32], name=layer+'_upsample2'))\n            \n                    (self.feed(layer)\n                         .avg_pool(6, 8, 6, 8, name=layer+'_pool3')\n                         .conv(1, 1, 512, 1, 1, biased=False, relu=False, name=layer+'_pool3_conv')\n                         .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=layer+'_pool3_bn')\n                         .resize_bilinear(size=[24, 32], name=layer+'_upsample3'))\n\n                    (self.feed(layer)\n                         .avg_pool(3, 4, 3, 4, name=layer+'_pool4')\n                         .conv(1, 1, 512, 1, 1, biased=False, relu=False, name=layer+'_pool4_conv')\n                         .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=layer+'_pool4_bn')\n                         .resize_bilinear(size=[24, 32], name=layer+'_upsample4'))\n\n                    \n                    (self.feed(layer+'_pool1')\n                         .reshape(shape=[-1, nChannels_4], name=layer+'_plane_reshape1')\n                         .fc(num_out=options.numOutputPlanes * 3, name=layer+'_plane_fc', relu=False)\n                         .reshape(shape=[-1, options.numOutputPlanes, 3], name=layer+'_plane_pred'))\n\n                    if options.predictConfidence == 1:\n                        (self.feed(layer+'_plane_reshape1')\n                             .fc(num_out=options.numOutputPlanes, name=layer+'_plane_confidence_fc', relu=False)\n                             .reshape(shape=[-1, options.numOutputPlanes, 1], name=layer+'_plane_confidence_pred'))\n                        pass\n                    \n                    (self.feed(layer,\n                               layer+'_upsample1',\n                               layer+'_upsample2',\n                               layer+'_upsample3',\n                               layer+'_upsample4')\n                         .concat(axis=3, name=layer+'_segmentation_concat')\n                         .conv(3, 3, 512, 1, 1, biased=False, relu=False, name=layer+'_segmentation_conv1')\n                         .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name=layer+'_segmentation_bn1')\n                         .dropout(keep_prob=0.9, name=layer+'_segmentation_dropout')\n                         .conv(1, 1, options.numOutputPlanes, 1, 1, relu=False, name=layer+'_segmentation_conv2')\n                         .resize_bilinear(size=[192, 256], name=layer+'_segmentation_pred'))\n\n                    (self.feed(layer+'_segmentation_dropout')\n                         .conv(1, 1, 1, 1, 1, relu=False, name=layer+'_non_plane_mask_conv2')\n                         .resize_bilinear(size=[192, 256], name=layer+'_non_plane_mask_pred'))\n                    # (self.feed(layer+'_segmentation_dropout')\n                    #      .conv(1, 1, 1, 1, 1, relu=False, name=layer+'_non_plane_depth_conv2')\n                    #      .resize_bilinear(size=[192, 256], name=layer+'_non_plane_depth_pred'))\n                    # (self.feed(layer+'_segmentation_dropout')\n                    #      .conv(1, 1, 3, 1, 1, relu=False, name=layer+'_non_plane_normal_conv2')\n                    #      .resize_bilinear(size=[192, 256], name=layer+'_non_plane_normal_pred'))\n                    continue\n                pass\n            pass\n            \n\n\n        (self.feed('res5d_pool1')\n             .reshape(shape=[-1, nChannels_5], name='plane_reshape1')\n             .fc(num_out=options.numOutputPlanes * 3, name='plane_fc', relu=False)\n             .reshape(shape=[-1, options.numOutputPlanes, 3], name='plane_pred'))\n\n        if options.predictConfidence == 1:\n            (self.feed('plane_reshape1')\n                 .fc(num_out=options.numOutputPlanes, name='plane_confidence_fc', relu=False)\n                 .reshape(shape=[-1, options.numOutputPlanes, 1], name='plane_confidence_pred'))\n            pass\n             \n        (self.feed('res5c_relu',\n                   'res5d_upsample1',\n                   'res5d_upsample2',\n                   'res5d_upsample3',\n                   'res5d_upsample4')\n             .concat(axis=3, name='segmentation_concat')\n             .conv(3, 3, 512, 1, 1, biased=False, relu=False, name='segmentation_conv1')\n             .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='segmentation_bn1')\n             .dropout(keep_prob=0.9, name='segmentation_dropout')\n             .conv(1, 1, options.numOutputPlanes, 1, 1, relu=False, name='segmentation_conv2')\n             .resize_bilinear(size=[192, 256], name='segmentation_pred'))\n        \n\n        (self.feed('segmentation_dropout')\n             .conv(1, 1, 1, 1, 1, relu=False, name='non_plane_mask_conv2')\n             .resize_bilinear(size=[192, 256], name='non_plane_mask_pred'))\n        (self.feed('segmentation_dropout')\n             .conv(1, 1, 1, 1, 1, relu=False, name='non_plane_depth_conv2')\n             .resize_bilinear(size=[192, 256], name='non_plane_depth_pred'))\n        (self.feed('segmentation_dropout')\n             .conv(1, 1, 3, 1, 1, relu=False, name='non_plane_normal_conv2')\n             .resize_bilinear(size=[192, 256], name='non_plane_normal_pred'))\n\n        (self.feed('segmentation_dropout')\n             .conv(1, 1, 1, 1, 1, relu=False, name='empty_mask_conv2')\n             .resize_bilinear(size=[192, 256], name='empty_mask_pred'))\n        \n\n        #boundary prediction\n        if options.predictBoundary == 1:\n            (self.feed('segmentation_dropout')\n                 .conv(1, 1, 1, 1, 1, relu=False, name='boundary_smooth_conv5')\n                 .resize_bilinear(size=[192, 256], name='boundary_smooth_upsample5'))\n            (self.feed('segmentation_dropout')\n                 .conv(1, 1, 1, 1, 1, relu=False, name='boundary_occlusion_conv5')\n                 .resize_bilinear(size=[192, 256], name='boundary_occlusion_upsample5'))\n            (self.feed('bn1')\n                 .conv(1, 1, 1, 1, 1, relu=False, name='boundary_conv0')\n                 .resize_bilinear(size=[192, 256], name='boundary_upsample0'))\n            (self.feed('relu1')\n                 .conv(1, 1, 1, 1, 1, relu=False, name='boundary_conv1')\n                 .resize_bilinear(size=[192, 256], name='boundary_upsample1'))\n            (self.feed('res2c_relu')\n                 .conv(1, 1, 1, 1, 1, relu=False, name='boundary_conv2')\n                 .resize_bilinear(size=[192, 256], name='boundary_upsample2'))\n            (self.feed('res3b3_relu')\n                 .conv(1, 1, 1, 1, 1, relu=False, name='boundary_conv3')\n                 .resize_bilinear(size=[192, 256], name='boundary_upsample3'))\n            (self.feed('boundary_smooth_upsample5',\n                       'boundary_upsample0',                   \n                       'boundary_upsample1',\n                       'boundary_upsample2',\n                       'boundary_upsample3')\n                 .concat(axis=3, name='boundary_smooth_concat')         \n                 .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='boundary_smooth_bn')\n                 .conv(1, 1, 1, 1, 1, relu=False, name='boundary_smooth_pred'))\n            (self.feed('boundary_occlusion_upsample5',\n                       'boundary_upsample0',\n                       'boundary_upsample1',\n                       'boundary_upsample2',\n                       'boundary_upsample3')\n                 .concat(axis=3, name='boundary_occlusion_concat')\n                 .batch_normalization(is_training=is_training, activation_fn=tf.nn.relu, name='boundary_occlusion_bn')\n                 .conv(1, 1, 1, 1, 1, relu=False, name='boundary_occlusion_pred'))\n            (self.feed('boundary_smooth_pred',\n                       'boundary_occlusion_pred')\n                 .concat(axis=3, name='boundary_pred'))\n            pass\n\n        #local prediction\n        if options.predictLocal == 1:\n            (self.feed('segmentation_dropout')\n                 .conv(1, 1, 1, 1, 1, relu=False, name='local_score_pred'))\n            (self.feed('segmentation_dropout')\n                 .conv(1, 1, 3, 1, 1, relu=False, name='local_plane_pred'))\n            (self.feed('segmentation_dropout')\n                 .conv(1, 1, 16*16, 1, 1, relu=False, name='local_mask_pred'))\n            pass\n            \n"""
code/predict.py,62,"b'import tensorflow as tf\nimport numpy as np\nnp.set_printoptions(precision=2, linewidth=200)\nimport cv2\nimport os\nimport time\nimport sys\nimport tf_nndistance\nimport argparse\nimport glob\nimport PIL\nimport scipy.ndimage as ndimage\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom utils import *\nfrom plane_utils import *\nfrom modules import *\n\nfrom train_sample import build_graph\nfrom planenet import PlaneNet\nfrom RecordReaderAll import *\nfrom SegmentationRefinement import *\nfrom crfasrnn_layer import CrfRnnLayer\n\nWIDTH = 256\nHEIGHT = 192\n\nALL_TITLES = [\'PlaneNet\']\nALL_METHODS = [(\'sample_np10_hybrid3_bl0_dl0_ds0_crfrnn5_sm0\', \'\', 0, 2), (\'planenet_hybrid3_crf1_pb_pp\', \'\', 1, 2), (\'sample_np10_hybrid3_bl0_dl0_hl2_ds0_crfrnn5_sm0\', \'\', 1, 2), (\'\', \'\', 1, 2), (\'\', \'\', 1, 2), (\'\', \'\', 1, 2), (\'\', \'\', 1, 2)]\n\n\ndef writeHTML(options):\n    from html import HTML\n\n    titles = options.titles\n\n    h = HTML(\'html\')\n    h.p(\'Results\')\n    h.br()\n    path = \'.\'\n    #methods = [\'planenet\', \'pixelwise\', \'pixelwise+RANSAC\', \'GT+RANSAC\', \'planenet+crf\', \'pixelwise+semantics+RANSAC\']\n    #methods = [\'planenet\', \'pixelwise\', \'pixelwise+RANSAC\', \'GT+RANSAC\']\n\n    for image_index in xrange(options.numImages):\n\n        t = h.table(border=\'1\')\n        r_inp = t.tr()\n        r_inp.td(\'input \' + str(image_index + options.startIndex))\n        r_inp.td().img(src=path + \'/\' + str(image_index + options.startIndex) + \'_image.png\')\n        r_inp.td().img(src=path + \'/\' + str(image_index + options.startIndex) + \'_depth_gt.png\')\n        r_inp.td().img(src=path + \'/\' + str(image_index + options.startIndex) + \'_segmentation_gt.png\')\n        r_inp.td().img(src=path + \'/\' + str(image_index + options.startIndex) + \'_semantics_gt.png\')\n        r_inp.td().img(src=path + \'/\' + str(image_index + options.startIndex) + \'_depth_gt_plane.png\')\n        r_inp.td().img(src=path + \'/\' + str(image_index + options.startIndex) + \'_depth_gt_diff.png\')\n        # r = t.tr()\n        # r.td(\'PlaneNet prediction\')\n        # r.td().img(src=firstFolder + \'/\' + str(index) + \'_segmentation_pred.png\')\n        # r.td().img(src=firstFolder + \'/\' + str(index) + \'_depth_pred.png\')\n\n        r = t.tr()\n        r.td(\'methods\')\n        for method_index, method in enumerate(titles):\n            r.td(method)\n            continue\n\n        r = t.tr()\n        r.td(\'segmentation\')\n        for method_index, method in enumerate(titles):\n            r.td().img(src=path + \'/\' + str(image_index + options.startIndex) + \'_segmentation_pred_\' + str(method_index) + \'.png\')\n            r.td().img(src=path + \'/\' + str(image_index + options.startIndex) + \'_segmentation_pred_blended_\' + str(method_index) + \'.png\')\n            continue\n\n        r = t.tr()\n        r.td(\'depth\')\n        for method_index, method in enumerate(titles):\n            r.td().img(src=path + \'/\' + str(image_index + options.startIndex) + \'_depth_pred_\' + str(method_index) + \'.png\')\n            continue\n        h.br()\n        continue\n\n    metric_titles = [\'depth error 0.1\', \'depth error 0.2\', \'depth error 0.3\', \'IOU 0.3\', \'IOU 0.5\', \'IOU 0.7\']\n\n    h.p(\'Curves on plane accuracy\')\n    for title in metric_titles:\n        h.img(src=\'curve_plane_\' + title.replace(\' \', \'_\') + \'.png\')\n        continue\n\n    h.p(\'Curves on pixel coverage\')\n    for title in metric_titles:\n        h.img(src=\'curve_pixel_\' + title.replace(\' \', \'_\') + \'.png\')\n        continue\n\n\n    html_file = open(options.test_dir + \'/index.html\', \'w\')\n    html_file.write(str(h))\n    html_file.close()\n    return\n\ndef evaluatePlanes(options):\n    #writeHTML(options)\n    #exit(1)\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n\n    results = getResults(options)\n\n    gt_dict = results[\'gt\']\n    predictions = results[\'pred\']\n\n\n    saving = True\n    if gt_dict[\'image\'].shape[0] != options.numImages:\n        saving = False\n        pass\n\n\n    for key, value in gt_dict.iteritems():\n        if value.shape[0] > options.numImages:\n            gt_dict[key] = value[:options.numImages]\n            pass\n        continue\n    for pred_dict in predictions:\n        for key, value in pred_dict.iteritems():\n            if value.shape[0] > options.numImages:\n                pred_dict[key] = value[:options.numImages]\n                pass\n            continue\n        continue\n\n    #methods = [\'planenet\', \'pixelwise+RANSAC\', \'GT+RANSAC\']\n\n\n\n    #predictions[2] = predictions[3]\n\n    if options.suffix == \'grids\':\n        image_list = glob.glob(options.test_dir + \'/*_image.png\')\n        print(len(image_list))\n        gridImage = writeGridImage(image_list[80:336], 3200, 1800, (16, 16))\n        cv2.imwrite(options.test_dir + \'/grid_images/grid_1616.png\', gridImage)\n        exit(1)\n\n    for image_index in xrange(options.visualizeImages):\n        if options.imageIndex >= 0 and image_index + options.startIndex != options.imageIndex:\n            continue\n        if options.suffix == \'grids\':\n            cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_image.png\', gt_dict[\'image\'][image_index])\n            segmentation = predictions[0][\'segmentation\'][image_index]\n            #segmentation = np.argmax(np.concatenate([segmentation, pred_dict[\'np_mask\'][image_index]], axis=2), -1)\n            segmentationImage = drawSegmentationImage(segmentation, blackIndex=options.numOutputPlanes)\n            #cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_segmentation_pred_\' + str(0) + \'.png\', segmentationImage)\n            segmentationImageBlended = (segmentationImage * 0.7 + gt_dict[\'image\'][image_index] * 0.3).astype(np.uint8)\n            cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_segmentation_pred_blended_\' + str(0) + \'.png\', segmentationImageBlended)\n            continue\n\n\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_image.png\', gt_dict[\'image\'][image_index])\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_depth_gt.png\', drawDepthImage(gt_dict[\'depth\'][image_index]))\n        #cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_normal_gt.png\', drawNormalImage(gt_dict[\'normal\'][image_index]))\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_segmentation_gt.png\', drawSegmentationImage(np.concatenate([gt_dict[\'segmentation\'][image_index], 1 - np.expand_dims(gt_dict[\'plane_mask\'][image_index], -1)], axis=2), blackIndex=options.numOutputPlanes))\n        #cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_semantics_gt.png\', drawSegmentationImage(gt_dict[\'semantics\'][image_index], blackIndex=0))\n\n\n        #plane_depths = calcPlaneDepths(gt_dict[\'plane\'][image_index], WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n        #all_depths = np.concatenate([plane_depths, np.expand_dims(gt_dict[\'depth\'][image_index], -1)], axis=2)\n        #depth = np.sum(all_depths * np.concatenate([gt_dict[\'segmentation\'][image_index], 1 - np.expand_dims(gt_dict[\'plane_mask\'][image_index], -1)], axis=2), axis=2)\n        #cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_depth_gt_plane.png\', drawDepthImage(depth))\n        #cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_depth_gt_diff.png\', drawMaskImage((depth - gt_dict[\'depth\'][image_index]) * 5 + 0.5))\n\n        info = gt_dict[\'info\'][image_index]\n        #print(info)\n        #print(np.rad2deg(np.arctan(info[16] / 2 / info[0])) * 2)\n        for method_index, pred_dict in enumerate(predictions):\n            cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_dict[\'depth\'][image_index]))\n\n            if \'pixelwise\' in options.methods[method_index][1]:\n                continue\n            segmentation = pred_dict[\'segmentation\'][image_index]\n            #segmentation = np.argmax(np.concatenate([segmentation, pred_dict[\'np_mask\'][image_index]], axis=2), -1)\n            segmentationImage = drawSegmentationImage(segmentation, blackIndex=options.numOutputPlanes)\n            cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_segmentation_pred_\' + str(method_index) + \'.png\', segmentationImage)\n            segmentationImageBlended = (segmentationImage * 0.7 + gt_dict[\'image\'][image_index] * 0.3).astype(np.uint8)\n            cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_segmentation_pred_blended_\' + str(method_index) + \'.png\', segmentationImageBlended)\n\n            segmentationImageBlended = np.minimum(segmentationImage * 0.3 + gt_dict[\'image\'][image_index] * 0.7, 255).astype(np.uint8)\n            if options.imageIndex >= 0:\n                if options.suffix == \'video\':\n                    copyLogoVideo(options.test_dir, image_index + options.startIndex, gt_dict[\'image\'][image_index], pred_dict[\'depth\'][image_index], pred_dict[\'plane\'][image_index], segmentation, gt_dict[\'info\'][image_index], wallTexture=False)\n                elif options.suffix == \'wall_video\':\n                    copyLogoVideo(options.test_dir, image_index + options.startIndex, gt_dict[\'image\'][image_index], pred_dict[\'depth\'][image_index], pred_dict[\'plane\'][image_index], segmentation, gt_dict[\'info\'][image_index], wallTexture=True, wallInds=[7, 9])\n                elif options.suffix == \'ruler\':\n                    addRulerComplete(options.test_dir, image_index + options.startIndex, gt_dict[\'image\'][image_index], pred_dict[\'depth\'][image_index], pred_dict[\'plane\'][image_index], segmentation, gt_dict[\'info\'][image_index], startPixel=(280, 190), endPixel=(380, 390), fixedEndPoint=True, numFrames=1000)\n                elif options.suffix == \'texture\':\n                    for planeIndex in xrange(options.numOutputPlanes):\n                        cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(segmentation == planeIndex))\n                        continue\n                    #resultImages = copyTexture(gt_dict[\'image\'][image_index], pred_dict[\'plane\'][image_index], segmentation, gt_dict[\'info\'][image_index], 6)\n                    #for resultIndex, resultImage in enumerate(resultImages):\n                    #cv2.imwrite(\'test/texture_\' + str(image_index + options.startIndex) + \'_\' + str(resultIndex) + \'.png\', resultImage)\n                    #continue\n\n\n                    resultImage = copyLogo(options.test_dir, image_index + options.startIndex, gt_dict[\'image\'][image_index], pred_dict[\'depth\'][image_index], pred_dict[\'plane\'][image_index], segmentation, gt_dict[\'info\'][image_index])\n                    #resultImage = copyWallTexture(options.test_dir, image_index + options.startIndex, gt_dict[\'image\'][image_index], pred_dict[\'depth\'][image_index], pred_dict[\'plane\'][image_index], segmentation, gt_dict[\'info\'][image_index], [7, 9])\n                    cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_result.png\', resultImage)\n                    writePLYFile(options.test_dir, image_index + options.startIndex, gt_dict[\'image\'][image_index], pred_dict[\'depth\'][image_index], segmentation, pred_dict[\'plane\'][image_index], gt_dict[\'info\'][image_index])\n                elif options.suffix == \'dump\':\n                    planes = pred_dict[\'plane\']\n                    planes /= np.linalg.norm(planes, axis=-1, keepdims=True)\n                    print([(planeIndex, plane) for planeIndex, plane in enumerate(planes[0])])\n                    for planeIndex in xrange(options.numOutputPlanes):\n                        cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(segmentation == planeIndex))\n                        continue\n                    print(\'dump\')\n                    newPlanes = []\n                    newSegmentation = np.full(segmentation.shape, -1)\n                    newPlaneIndex = 0\n                    planes = pred_dict[\'plane\'][image_index]\n                    for planeIndex in xrange(options.numOutputPlanes):\n                        mask = segmentation == planeIndex\n                        if mask.sum() > 0:\n                            newPlanes.append(planes[planeIndex])\n                            newSegmentation[mask] = newPlaneIndex\n                            newPlaneIndex += 1\n                            pass\n                        continue\n\n                    np.save(\'test/\' + str(image_index + options.startIndex) + \'_planes.npy\', np.stack(newPlanes, axis=0))\n                    #print(global_gt[\'non_plane_mask\'].shape)\n                    np.save(\'test/\' + str(image_index + options.startIndex) + \'_segmentation.npy\', newSegmentation)\n                    print(newSegmentation.max(), newSegmentation.min())\n                    cv2.imwrite(\'test/\' + str(image_index + options.startIndex) + \'_image.png\', gt_dict[\'image\'][image_index])\n                    depth = pred_dict[\'depth\'][image_index]\n                    np.save(\'test/\' + str(image_index + options.startIndex) + \'_depth.npy\', depth)\n                    info = gt_dict[\'info\'][image_index]\n                    #normal = calcNormal(depth, info)\n                    #np.save(\'test/\' + str(image_index + options.startIndex) + \'_normal.npy\', normal)\n                    np.save(\'test/\' + str(image_index + options.startIndex) + \'_info.npy\', info)\n                    exit(1)\n\n                else:\n                    np_mask = (segmentation == options.numOutputPlanes).astype(np.float32)\n                    np_depth = pred_dict[\'np_depth\'][image_index].squeeze()\n                    np_depth = cv2.resize(np_depth, (np_mask.shape[1], np_mask.shape[0]))\n                    cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_np_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(np_depth * np_mask))\n                    writePLYFile(options.test_dir, image_index + options.startIndex, segmentationImageBlended, pred_dict[\'depth\'][image_index], segmentation, pred_dict[\'plane\'][image_index], gt_dict[\'info\'][image_index])\n                    pass\n                exit(1)\n                pass\n            continue\n        continue\n\n    writeHTML(options)\n    exit(1)\n\n    #post processing\n    for method_index, method in enumerate(options.methods):\n        if method[1] == \'\':\n            continue\n        if len(method) < 4 or method[3] == 0:\n            continue\n        if len(method) >= 3 and method[2] >= 0:\n            pred_dict = predictions[method[2]]\n        else:\n            pred_dict = predictions[method_index]\n            pass\n\n        if method[1] == \'graphcut\':\n            #pred_dict = gt_dict\n            predSegmentations = []\n            predDepths = []\n            for image_index in xrange(options.numImages):\n                #if image_index != 3:\n                #continue\n                print(\'graph cut \' + str(image_index + options.startIndex))\n\n                segmentation = np.argmax(np.concatenate([pred_dict[\'segmentation\'][image_index], 1 - np.expand_dims(pred_dict[\'plane_mask\'][image_index], -1)], axis=2), axis=2)\n                #pred_s = getSegmentationsGraphCut(pred_dict[\'plane\'][image_index], gt_dict[\'image\'][image_index], pred_dict[\'depth\'][image_index], pred_dict[\'normal\'][image_index], segmentation, pred_dict[\'semantics\'][image_index], pred_dict[\'info\'][image_index], gt_dict[\'num_planes\'][image_index])\n\n                pred_p, pred_s, numPlanes = removeSmallSegments(pred_dict[\'plane\'][image_index], gt_dict[\'image\'][image_index], pred_dict[\'depth\'][image_index], pred_dict[\'normal\'][image_index], segmentation, pred_dict[\'semantics\'][image_index], pred_dict[\'info\'][image_index], gt_dict[\'num_planes\'][image_index])\n                #pred_p, pred_s, numPlanes = pred_dict[\'plane\'][image_index], segmentation, gt_dict[\'num_planes\'][image_index]\n                print((gt_dict[\'num_planes\'][image_index], numPlanes))\n                planeDepths = calcPlaneDepths(pred_p, WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n                allDepths = np.concatenate([planeDepths, np.expand_dims(pred_dict[\'depth\'][image_index], -1)], axis=2)\n                pred_d = allDepths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), pred_s.reshape(-1)].reshape(HEIGHT, WIDTH)\n\n                predSegmentations.append(pred_s)\n                predDepths.append(pred_d)\n\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_d))\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(pred_s, blackIndex=options.numOutputPlanes))\n                continue\n            new_pred_dict = {}\n            for key, value in pred_dict.iteritems():\n                new_pred_dict[key] = value\n                continue\n            new_pred_dict[\'segmentation\'] = np.array(predSegmentations)\n            if method_index < len(predictions):\n                predictions[method_index] = new_pred_dict\n            else:\n                predictions.append(new_pred_dict)\n                pass\n        if method[1] == \'crf_tf\':\n            predSegmentations = []\n            predDepths = []\n\n            image_inp = tf.placeholder(tf.float32, shape=[1, HEIGHT, WIDTH, 3], name=\'image\')\n            segmentation_inp = tf.placeholder(tf.float32, shape=[1, HEIGHT, WIDTH, options.numOutputPlanes + 1], name=\'segmentation\')\n            plane_inp = tf.placeholder(tf.float32, shape=[1, options.numOutputPlanes, 3], name=\'plane\')\n            non_plane_depth_inp = tf.placeholder(tf.float32, shape=[1, HEIGHT, WIDTH, 1], name=\'non_plane_depth\')\n            info_inp = tf.placeholder(tf.float32, shape=[20], name=\'info\')\n\n\n            plane_parameters = tf.reshape(plane_inp, (-1, 3))\n            plane_depths = planeDepthsModule(plane_parameters, WIDTH, HEIGHT, info_inp)\n            plane_depths = tf.transpose(tf.reshape(plane_depths, [HEIGHT, WIDTH, -1, options.numOutputPlanes]), [2, 0, 1, 3])\n            all_depths = tf.concat([plane_depths, non_plane_depth_inp], axis=3)\n\n            planesY = plane_inp[:, :, 1]\n            planesD = tf.maximum(tf.norm(plane_inp, axis=-1), 1e-4)\n            planesY /= planesD\n            planesY = tf.concat([planesY, tf.ones((1, 1))], axis=1)\n\n            #refined_segmentation = crfModule(segmentation_inp, plane_inp, non_plane_depth_inp, info_inp, numOutputPlanes = options.numOutputPlanes, numIterations=5)\n\n            imageDiff = calcImageDiff(image_inp)\n            #refined_segmentation, debug_dict = segmentationRefinementModule(segmentation_inp, all_depths, planesY, imageDiff, numOutputPlanes = options.numOutputPlanes + 1, numIterations=5)\n            refined_segmentation, debug_dict = meanfieldModule(segmentation_inp, all_depths, planesY, imageDiff, numOutputPlanes = options.numOutputPlanes + 1, maxDepthDiff=0.2, varDepthDiff=pow(0.2, 2))\n\n            config=tf.ConfigProto()\n            config.gpu_options.allow_growth=True\n            config.allow_soft_placement=True\n\n            init_op = tf.group(tf.global_variables_initializer(),\n                               tf.local_variables_initializer())\n            with tf.Session(config=config) as sess:\n                sess.run(init_op)\n                for image_index in xrange(options.numImages):\n                    #if image_index != 1:\n                    #continue\n                    print(\'crf tf \' + str(image_index + options.startIndex))\n                    allSegmentations = np.concatenate([pred_dict[\'segmentation\'][image_index], pred_dict[\'np_mask\'][image_index]], axis=2)\n                    allSegmentations = softmax(allSegmentations)\n                    pred_s, debug = sess.run([refined_segmentation, debug_dict], feed_dict={segmentation_inp: np.expand_dims(allSegmentations, 0), plane_inp: np.expand_dims(pred_dict[\'plane\'][image_index], 0), non_plane_depth_inp: np.expand_dims(pred_dict[\'np_depth\'][image_index], 0), info_inp: gt_dict[\'info\'][image_index], image_inp: gt_dict[\'image\'][image_index:image_index + 1]})\n\n                    pred_s = pred_s[0]\n                    planeDepths = calcPlaneDepths(pred_dict[\'plane\'][image_index], WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n                    allDepths = np.concatenate([planeDepths, pred_dict[\'np_depth\'][image_index]], axis=2)\n                    pred_d = np.sum(allDepths * pred_s, axis=-1)\n\n                    predSegmentations.append(pred_s)\n                    predDepths.append(pred_d)\n\n                    cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_d))\n                    cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(pred_s, blackIndex=options.numOutputPlanes))\n\n                    if \'diff\' in debug:\n                        segmentation = np.argmax(allSegmentations, axis=-1)\n                        for planeIndex in xrange(options.numOutputPlanes + 1):\n                            cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(allSegmentations[:, :, planeIndex]))\n                            continue\n\n                        for planeIndex in xrange(debug[\'diff\'].shape[-1]):\n                            cv2.imwrite(\'test/cost_mask_\' + str(planeIndex) + \'.png\', drawMaskImage(debug[\'diff\'][0, :, :, planeIndex] / 2))\n                            continue\n                        exit(1)\n                        pass\n                    continue\n                pass\n            new_pred_dict = {}\n            for key, value in pred_dict.iteritems():\n                new_pred_dict[key] = value\n                continue\n            segmentations = np.array(predSegmentations)\n            new_pred_dict[\'segmentation\'] = segmentations[:, :, :, :options.numOutputPlanes]\n            new_pred_dict[\'non_plane_mask\'] = segmentations[:, :, :, options.numOutputPlanes:options.numOutputPlanes + 1]\n            #new_pred_dict[\'non_plane_mask\'] = segmentations[:, :, :, :options.numOutputPlanes]\n            new_pred_dict[\'depth\'] = np.array(predDepths)\n            if method_index < len(predictions):\n                predictions[method_index] = new_pred_dict\n            else:\n                predictions.append(new_pred_dict)\n                pass\n            pass\n\n        if method[1] == \'crf\':\n            predSegmentations = []\n            predDepths = []\n            for image_index in xrange(options.numImages):\n                print(\'crf \' + str(image_index + options.startIndex))\n                boundaries = pred_dict[\'boundary\'][image_index]\n                boundaries = sigmoid(boundaries)\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_boundary.png\', drawMaskImage(np.concatenate([boundaries, np.zeros((HEIGHT, WIDTH, 1))], axis=2)))\n\n                allSegmentations = np.concatenate([pred_dict[\'segmentation\'][image_index], pred_dict[\'np_mask\'][image_index]], axis=2)\n                allSegmentations = softmax(allSegmentations)\n                planeDepths = calcPlaneDepths(pred_dict[\'plane\'][image_index], WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n                allDepths = np.concatenate([planeDepths, pred_dict[\'np_depth\'][image_index]], axis=2)\n                #boundaries = np.concatenate([np.ones((allSegmentations.shape[0], allSegmentations.shape[1], 1)), -np.ones((allSegmentations.shape[0], allSegmentations.shape[1], 1))], axis=2)\n                #if options.imageIndex >= 0:\n                #boundaries = cv2.imread(options.test_dir + \'/\' + str(options.imageIndex) + \'_boundary.png\')\n                #else:\n                #boundaries = cv2.imread(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_boundary.png\')\n                #pass\n                #boundaries = (boundaries > 128).astype(np.float32)[:, :, :2]\n\n                allDepths[:, :, options.numOutputPlanes] = 0\n                pred_s = refineSegmentation(gt_dict[\'image\'][image_index], allSegmentations, allDepths, boundaries, numOutputPlanes = 20, numIterations=20, numProposals=5)\n                pred_d = allDepths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), pred_s.reshape(-1)].reshape(HEIGHT, WIDTH)\n\n                predSegmentations.append(pred_s)\n                predDepths.append(pred_d)\n\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_d))\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(pred_s, blackIndex=options.numOutputPlanes))\n\n                #segmentation = np.argmax(allSegmentations, axis=-1)\n                for planeIndex in xrange(options.numOutputPlanes + 1):\n                    cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(allSegmentations[:, :, planeIndex]))\n                    continue\n                #cv2.imwrite(options.test_dir + \'/mask_\' + str(21) + \'.png\', drawDepthImage(pred_dict[\'np_depth\'][0]))\n                #for plane_index in xrange(options.numOutputPlanes + 1):\n                #cv2.imwrite(options.test_dir + \'/mask_\' + str(plane_index) + \'.png\', drawMaskImage(pred_s == plane_index))\n                #continue\n                #exit(1)\n                continue\n\n            new_pred_dict = {}\n            for key, value in pred_dict.iteritems():\n                new_pred_dict[key] = value\n                continue\n            new_pred_dict[\'segmentation\'] = np.array(predSegmentations)\n            new_pred_dict[\'depth\'] = np.array(predDepths)\n            if method_index < len(predictions):\n                predictions[method_index] = new_pred_dict\n            else:\n                predictions.append(new_pred_dict)\n                pass\n            pass\n\n\n        if \'pixelwise\' in method[1]:\n            predPlanes = []\n            predSegmentations = []\n            predDepths = []\n            predNumPlanes = []\n            for image_index in xrange(options.numImages):\n                pred_d = pred_dict[\'np_depth\'][image_index].squeeze()\n                pred_n = pred_dict[\'np_normal\'][image_index].squeeze()\n                if \'_1\' in method[1]:\n                    pred_s = np.zeros(pred_dict[\'segmentation\'][image_index].shape)\n                    pred_p = np.zeros(pred_dict[\'plane\'][image_index].shape)\n                elif \'_2\' in method[1]:\n                    parameters = {\'distanceCostThreshold\': 0.1, \'smoothnessWeight\': 0.05, \'semantics\': True}\n                    pred_p, pred_s = fitPlanesNYU(gt_dict[\'image\'], gt_dict[\'depth\'][image_index].squeeze(), gt_dict[\'normal\'][image_index], gt_dict[\'semantics\'][image_index], gt_dict[\'info\'][image_index], numOutputPlanes=20, parameters=parameters)\n                elif \'_3\' in method[1]:\n                    parameters = {\'distanceCostThreshold\': 0.1, \'smoothnessWeight\': 0.03, \'semantics\': True, \'distanceThreshold\': 0.2}\n                    pred_p, pred_s = fitPlanesNYU(gt_dict[\'image\'], pred_d, pred_n, pred_dict[\'semantics\'][image_index], gt_dict[\'info\'][image_index], numOutputPlanes=20, parameters=parameters)\n                elif \'_4\' in method[1]:\n                    parameters = {\'numProposals\': 5, \'distanceCostThreshold\': 0.1, \'smoothnessWeight\': 30, \'dominantLineThreshold\': 3, \'offsetGap\': 0.1}\n                    pred_p, pred_s = fitPlanesManhattan(gt_dict[\'image\'][image_index], gt_dict[\'depth\'][image_index].squeeze(), gt_dict[\'normal\'][image_index], gt_dict[\'info\'][image_index], numOutputPlanes=20, parameters=parameters)\n                    pred_d = np.zeros((HEIGHT, WIDTH))\n                elif \'_5\' in method[1]:\n                    parameters = {\'numProposals\': 5, \'distanceCostThreshold\': 0.1, \'smoothnessWeight\': 100, \'dominantLineThreshold\': 3, \'offsetGap\': 0.6}\n                    pred_p, pred_s = fitPlanesManhattan(gt_dict[\'image\'][image_index], pred_d, pred_n, gt_dict[\'info\'][image_index], numOutputPlanes=20, parameters=parameters)\n                    pred_d = np.zeros((HEIGHT, WIDTH))\n                elif \'_6\' in method[1]:\n                    parameters = {\'distanceCostThreshold\': 0.1, \'smoothnessWeight\': 300, \'numProposals\': 5, \'normalWeight\': 1, \'meanshift\': 0.2}\n                    pred_p, pred_s = fitPlanesPiecewise(gt_dict[\'image\'][image_index], gt_dict[\'depth\'][image_index].squeeze(), gt_dict[\'normal\'][image_index], gt_dict[\'info\'][image_index], numOutputPlanes=20, parameters=parameters)\n                    pred_d = np.zeros((HEIGHT, WIDTH))\n                elif \'_7\' in method[1]:\n                    parameters = {\'numProposals\': 5, \'distanceCostThreshold\': 0.1, \'smoothnessWeight\': 300, \'normalWeight\': 1, \'meanshift\': 0.2}\n                    pred_p, pred_s = fitPlanesPiecewise(gt_dict[\'image\'][image_index], pred_d, pred_n, gt_dict[\'info\'][image_index], numOutputPlanes=20, parameters=parameters)\n                    pred_d = np.zeros((HEIGHT, WIDTH))\n                    pass\n                predPlanes.append(pred_p)\n                predSegmentations.append(pred_s)\n                predDepths.append(pred_d)\n                predNumPlanes.append(pred_p.shape[0])\n\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_d))\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(pred_s))\n                #exit(1)\n                continue\n            new_pred_dict = {}\n            for key, value in pred_dict.iteritems():\n                new_pred_dict[key] = value\n                continue\n            new_pred_dict[\'plane\'] = np.array(predPlanes)\n            new_pred_dict[\'segmentation\'] = np.array(predSegmentations)\n            new_pred_dict[\'depth\'] = np.array(predDepths)\n            new_pred_dict[\'num_planes\'] = np.array(predNumPlanes)\n            if method_index < len(predictions):\n                predictions[method_index] = new_pred_dict\n            else:\n                predictions.append(new_pred_dict)\n                pass\n            #titles.append(\'pixelwise+semantics+RANSAC\')\n            pass\n\n        if method[1] == \'crfrnn\':\n            predSegmentations = []\n            predDepths = []\n\n            image_inp = tf.placeholder(tf.float32, shape=[1, HEIGHT, WIDTH, 3], name=\'image\')\n            segmentation_inp = tf.placeholder(tf.float32, shape=[1, HEIGHT, WIDTH, options.numOutputPlanes + 1], name=\'segmentation\')\n\n            refined_segmentation = CrfRnnLayer(image_dims=(HEIGHT, WIDTH), num_classes=21, theta_alpha=120., theta_beta=3., theta_gamma=3., num_iterations=10, name=\'crfrnn\')([segmentation_inp, image_inp])\n\n            config=tf.ConfigProto()\n            config.gpu_options.allow_growth=True\n            config.allow_soft_placement=True\n\n            init_op = tf.group(tf.global_variables_initializer(),\n                               tf.local_variables_initializer())\n            with tf.Session(config=config) as sess:\n                sess.run(init_op)\n                for image_index in xrange(options.numImages):\n                    #if image_index != 1:\n                    #continue\n                    print(\'crf rnn \' + str(image_index + options.startIndex))\n                    allSegmentations = np.concatenate([pred_dict[\'segmentation\'][image_index], pred_dict[\'np_mask\'][image_index]], axis=2)\n                    img = gt_dict[\'image\'][image_index:image_index + 1].astype(np.float32) - 128\n\n\n                    pred_s = sess.run(refined_segmentation, feed_dict={segmentation_inp: np.expand_dims(allSegmentations, 0), image_inp: img})\n\n                    # print(pred_s.shape)\n                    # print(pred_s[0].max())\n                    # print(pred_s.sum(-1).max())\n                    # exit(1)\n                    pred_s = pred_s[0]\n                    # print(allSegmentations.max())\n                    # print(pred_s.max())\n                    # print(img.max())\n                    # print(img.min())\n                    # print(np.abs(pred_s - allSegmentations).max())\n                    # print(np.abs(np.argmax(pred_s, axis=-1) - np.argmax(allSegmentations, axis=-1)).max())\n                    pred_s = one_hot(np.argmax(pred_s, axis=-1), options.numOutputPlanes + 1)\n\n\n                    planeDepths = calcPlaneDepths(pred_dict[\'plane\'][image_index], WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n                    allDepths = np.concatenate([planeDepths, pred_dict[\'np_depth\'][image_index]], axis=2)\n                    pred_d = np.sum(allDepths * pred_s, axis=-1)\n\n                    predSegmentations.append(pred_s)\n                    predDepths.append(pred_d)\n\n                    cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_d))\n                    cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(pred_s, blackIndex=options.numOutputPlanes))\n\n                    continue\n                pass\n            new_pred_dict = {}\n            for key, value in pred_dict.iteritems():\n                new_pred_dict[key] = value\n                continue\n            segmentations = np.array(predSegmentations)\n            new_pred_dict[\'segmentation\'] = segmentations[:, :, :, :options.numOutputPlanes]\n            new_pred_dict[\'non_plane_mask\'] = segmentations[:, :, :, options.numOutputPlanes:options.numOutputPlanes + 1]\n            #new_pred_dict[\'non_plane_mask\'] = segmentations[:, :, :, :options.numOutputPlanes]\n            new_pred_dict[\'depth\'] = np.array(predDepths)\n            if method_index < len(predictions):\n                predictions[method_index] = new_pred_dict\n            else:\n                predictions.append(new_pred_dict)\n                pass\n            pass\n        if saving:\n            np.save(options.result_filename, {\'gt\': gt_dict, \'pred\': predictions})\n            pass\n        continue\n\n\n    #plotResults(gt_dict, predictions, options)\n    writeHTML(options)\n    return\n\ndef plotAll():\n    result_filenames = glob.glob(options.test_dir + \'/results_*.npy\')\n    assert(len(result_filenames) > 0)\n    results = np.load(result_filenames[0])\n    results = results[()]\n    gt_dict = results[\'gt\']\n    predictions = results[\'pred\']\n\n    for index in xrange(1, len(result_filenames)):\n        other_results = np.load(result_filenames[index])\n        other_results = other_results[()]\n        other_gt_dict = other_results[\'gt\']\n        other_predictions = other_results[\'pred\']\n\n        for k, v in other_gt_dict.iteritems():\n            gt_dict[k] = np.concatenate([gt_dict[k], v], axis=0)\n            continue\n        for methodIndex, other_pred_dict in enumerate(other_predictions):\n            for k, v in other_pred_dict.iteritems():\n                predictions[methodIndex][k] = np.concatenate([predictions[methodIndex][k], v], axis=0)\n                continue\n            continue\n        continue\n\n    plotResults(gt_dict, predictions, options)\n    return\n\n\ndef plotResults(gt_dict, predictions, options):\n    titles = options.titles\n\n    pixel_metric_curves = []\n    plane_metric_curves = []\n    for method_index, pred_dict in enumerate(predictions):\n        if titles[method_index] == \'pixelwise\':\n            continue\n        segmentations = pred_dict[\'segmentation\']\n        #if method_index == 0:\n        #segmentations = softmax(segmentations)\n        #pass\n        #pixel_curves, plane_curves = evaluatePlaneSegmentation(pred_dict[\'plane\'], segmentations, gt_dict[\'plane\'], gt_dict[\'segmentation\'], gt_dict[\'num_planes\'], numOutputPlanes = options.numOutputPlanes)\n\n        pixel_curves = np.zeros((6, 11))\n        plane_curves = np.zeros((6, 11, 3))\n        numImages = segmentations.shape[0]\n        for image_index in xrange(numImages):\n            gtDepths = calcPlaneDepths(gt_dict[\'plane\'][image_index], WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n            predDepths = calcPlaneDepths(pred_dict[\'plane\'][image_index], WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n            if \'num_planes\' in pred_dict:\n                predNumPlanes = pred_dict[\'num_planes\'][image_index]\n            else:\n                predNumPlanes = options.numOutputPlanes\n                pass\n            pixelStatistics, planeStatistics = evaluatePlanePrediction(predDepths, segmentations[image_index], predNumPlanes, gtDepths, gt_dict[\'segmentation\'][image_index], gt_dict[\'num_planes\'][image_index])\n\n            pixel_curves += np.array(pixelStatistics)\n            plane_curves += np.array(planeStatistics)\n            continue\n\n        if len(pixel_metric_curves) == 0:\n            for metric_index, pixel_curve in enumerate(pixel_curves):\n                pixel_metric_curves.append([])\n                plane_metric_curves.append([])\n                continue\n            pass\n\n        for metric_index, pixel_curve in enumerate(pixel_curves):\n            pixel_metric_curves[metric_index].append(pixel_curve / numImages)\n            continue\n        for metric_index, plane_curve in enumerate(plane_curves):\n            #planeScore = plane_curve[:, 0] / plane_curve[:, 1]\n            plane_metric_curves[metric_index].append(plane_curve)\n            continue\n        continue\n\n\n    np.save(options.test_dir + \'/pixel_curves.npy\', np.array(pixel_curves))\n    np.save(options.test_dir + \'/plane_curves.npy\', np.array(plane_curves))\n\n\n    xs = []\n    xs.append((np.arange(11) * 0.1).tolist())\n    xs.append((np.arange(11) * 0.1).tolist())\n    xs.append((np.arange(11) * 0.1).tolist())\n    xs.append((np.arange(11) * 0.05).tolist())\n    xs.append((np.arange(11) * 0.05).tolist())\n    xs.append((np.arange(11) * 0.05).tolist())\n    xlabels = [\'IOU\', \'IOU\', \'IOU\', \'plane diff\', \'plane diff\', \'plane diff\']\n    curve_titles = [\'depth error 0.1\', \'depth error 0.2\', \'depth error 0.3\', \'IOU 0.3\', \'IOU 0.5\', \'IOU 0.7\']\n    curve_labels = [title for title in titles if title != \'pixelwise\']\n    for metric_index, curves in enumerate(pixel_metric_curves):\n        filename = options.test_dir + \'/curve_pixel_\' + curve_titles[metric_index].replace(\' \', \'_\') + \'.png\'\n        plotCurves(xs[metric_index], curves, filename = filename, xlabel=xlabels[metric_index], ylabel=\'pixel coverage\', title=curve_titles[metric_index], labels=curve_labels)\n        continue\n    for metric_index, curves in enumerate(plane_metric_curves):\n        filename = options.test_dir + \'/curve_plane_\' + curve_titles[metric_index].replace(\' \', \'_\') + \'.png\'\n        curves = [curve[:, 0] / curve[:, 1] for curve in curves]\n        plotCurves(xs[metric_index], curves, filename = filename, xlabel=xlabels[metric_index], ylabel=\'plane accuracy\', title=curve_titles[metric_index], labels=curve_labels)\n        continue\n\n\ndef evaluateDepthPrediction(options):\n\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n\n    if options.useCache == 1 and os.path.exists(options.result_filename):\n        results = np.load(options.result_filename)\n        results = results[()]\n    else:\n        results = getResults(options)\n        if options.useCache != -2:\n            np.save(options.result_filename, results)\n            pass\n        pass\n\n    gt_dict = results[\'gt\']\n    predictions = results[\'pred\']\n\n    for key, value in gt_dict.iteritems():\n        if value.shape[0] > options.numImages:\n            gt_dict[key] = value[:options.numImages]\n            pass\n        continue\n    for pred_dict in predictions:\n        for key, value in pred_dict.iteritems():\n            if value.shape[0] > options.numImages:\n                pred_dict[key] = value[:options.numImages]\n                pass\n            continue\n        continue\n\n    titles = options.titles\n\n\n    for image_index in xrange(options.visualizeImages):\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_image.png\', gt_dict[\'image\'][image_index])\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_depth_gt.png\', drawDepthImage(gt_dict[\'depth\'][image_index]))\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_segmentation_gt.png\', drawSegmentationImage(np.concatenate([gt_dict[\'segmentation\'][image_index], 1 - np.expand_dims(gt_dict[\'plane_mask\'][image_index], -1)], axis=2), blackIndex=options.numOutputPlanes))\n        cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_semantics_gt.png\', drawSegmentationImage(gt_dict[\'semantics\'][image_index], blackIndex=0))\n\n\n\n        # plane_depths = calcPlaneDepths(gt_dict[\'plane\'][image_index], WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n        # all_depths = np.concatenate([plane_depths, np.expand_dims(gt_dict[\'depth\'][image_index], -1)], axis=2)\n        # depth = np.sum(all_depths * np.concatenate([gt_dict[\'segmentation\'][image_index], 1 - np.expand_dims(gt_dict[\'plane_mask\'][image_index], -1)], axis=2), axis=2)\n        # cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_depth_gt_plane.png\', drawDepthImage(depth))\n\n        for method_index, pred_dict in enumerate(predictions):\n            cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_dict[\'depth\'][image_index]))\n\n            if titles[method_index] == \'pixelwise\':\n                continue\n            segmentation = pred_dict[\'segmentation\'][image_index]\n            segmentation = np.concatenate([segmentation, pred_dict[\'np_mask\'][image_index]], axis=2)\n            cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(segmentation, blackIndex=options.numOutputPlanes))\n            continue\n        continue\n\n    #post processing\n    for method_index, method in enumerate(options.methods):\n        if method[1] == \'graphcut\':\n            pred_dict = gt_dict\n            predSegmentations = []\n            predDepths = []\n            for image_index in xrange(options.numImages):\n                #if image_index != 3:\n                #continue\n                print(\'graph cut \' + str(image_index + options.startIndex))\n\n                segmentation = np.argmax(np.concatenate([pred_dict[\'segmentation\'][image_index], 1 - np.expand_dims(pred_dict[\'plane_mask\'][image_index], -1)], axis=2), axis=2)\n                #pred_s = getSegmentationsGraphCut(pred_dict[\'plane\'][image_index], gt_dict[\'image\'][image_index], pred_dict[\'depth\'][image_index], pred_dict[\'normal\'][image_index], segmentation, pred_dict[\'semantics\'][image_index], pred_dict[\'info\'][image_index], gt_dict[\'num_planes\'][image_index])\n\n                pred_p, pred_s, numPlanes = removeSmallSegments(pred_dict[\'plane\'][image_index], gt_dict[\'image\'][image_index], pred_dict[\'depth\'][image_index], pred_dict[\'normal\'][image_index], segmentation, pred_dict[\'semantics\'][image_index], pred_dict[\'info\'][image_index], gt_dict[\'num_planes\'][image_index])\n                #pred_p, pred_s, numPlanes = pred_dict[\'plane\'][image_index], segmentation, gt_dict[\'num_planes\'][image_index]\n                print((gt_dict[\'num_planes\'][image_index], numPlanes))\n                planeDepths = calcPlaneDepths(pred_p, WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n                allDepths = np.concatenate([planeDepths, np.expand_dims(pred_dict[\'depth\'][image_index], -1)], axis=2)\n                pred_d = allDepths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), pred_s.reshape(-1)].reshape(HEIGHT, WIDTH)\n\n                predSegmentations.append(pred_s)\n                predDepths.append(pred_d)\n\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_d))\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(pred_s, blackIndex=options.numOutputPlanes))\n                continue\n            new_pred_dict = {}\n            for key, value in pred_dict.iteritems():\n                new_pred_dict[key] = value\n                continue\n            new_pred_dict[\'segmentation\'] = np.array(predSegmentations)\n            predictions[method_index] = new_pred_dict\n        if method[1] == \'crf_tf\':\n            pred_dict = predictions[method_index]\n            predSegmentations = []\n            predDepths = []\n\n            image_inp = tf.placeholder(tf.float32, shape=[1, HEIGHT, WIDTH, 3], name=\'image\')\n            segmentation_inp = tf.placeholder(tf.float32, shape=[1, HEIGHT, WIDTH, options.numOutputPlanes + 1], name=\'segmentation\')\n            plane_inp = tf.placeholder(tf.float32, shape=[1, options.numOutputPlanes, 3], name=\'plane\')\n            non_plane_depth_inp = tf.placeholder(tf.float32, shape=[1, HEIGHT, WIDTH, 1], name=\'non_plane_depth\')\n            info_inp = tf.placeholder(tf.float32, shape=[20], name=\'info\')\n\n\n            plane_parameters = tf.reshape(plane_inp, (-1, 3))\n            plane_depths = planeDepthsModule(plane_parameters, WIDTH, HEIGHT, info_inp)\n            plane_depths = tf.transpose(tf.reshape(plane_depths, [HEIGHT, WIDTH, -1, options.numOutputPlanes]), [2, 0, 1, 3])\n            all_depths = tf.concat([plane_depths, non_plane_depth_inp], axis=3)\n\n            planesY = plane_inp[:, :, 1]\n            planesD = tf.maximum(tf.norm(plane_inp, axis=-1), 1e-4)\n            planesY /= planesD\n            planesY = tf.concat([planesY, tf.ones((1, 1))], axis=1)\n\n            #refined_segmentation = crfModule(segmentation_inp, plane_inp, non_plane_depth_inp, info_inp, numOutputPlanes = options.numOutputPlanes, numIterations=5)\n\n            imageDiff = calcImageDiff(image_inp)\n            #refined_segmentation, debug_dict = segmentationRefinementModule(segmentation_inp, all_depths, planesY, imageDiff, numOutputPlanes = options.numOutputPlanes + 1, numIterations=5)\n            refined_segmentation, debug_dict = meanfieldModule(segmentation_inp, all_depths, planesY, imageDiff, numOutputPlanes = options.numOutputPlanes + 1, maxDepthDiff=0.2, varDepthDiff=pow(0.2, 2))\n\n            config=tf.ConfigProto()\n            config.gpu_options.allow_growth=True\n            config.allow_soft_placement=True\n\n            init_op = tf.group(tf.global_variables_initializer(),\n                               tf.local_variables_initializer())\n            with tf.Session(config=config) as sess:\n                sess.run(init_op)\n                for image_index in xrange(options.numImages):\n                    #if image_index != 1:\n                    #continue\n                    print(\'crf tf \' + str(image_index + options.startIndex))\n                    allSegmentations = np.concatenate([pred_dict[\'segmentation\'][image_index], pred_dict[\'np_mask\'][image_index]], axis=2)\n                    allSegmentations = softmax(allSegmentations)\n                    pred_s, debug = sess.run([refined_segmentation, debug_dict], feed_dict={segmentation_inp: np.expand_dims(allSegmentations, 0), plane_inp: np.expand_dims(pred_dict[\'plane\'][image_index], 0), non_plane_depth_inp: np.expand_dims(pred_dict[\'np_depth\'][image_index], 0), info_inp: gt_dict[\'info\'][image_index], image_inp: gt_dict[\'image\'][image_index:image_index + 1]})\n\n                    pred_s = pred_s[0]\n                    planeDepths = calcPlaneDepths(pred_dict[\'plane\'][image_index], WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n                    allDepths = np.concatenate([planeDepths, pred_dict[\'np_depth\'][image_index]], axis=2)\n                    pred_d = np.sum(allDepths * pred_s, axis=-1)\n\n                    predSegmentations.append(pred_s)\n                    predDepths.append(pred_d)\n\n                    cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_d))\n                    cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(pred_s, blackIndex=options.numOutputPlanes))\n\n                    if \'diff\' in debug:\n                        segmentation = np.argmax(allSegmentations, axis=-1)\n                        for planeIndex in xrange(options.numOutputPlanes + 1):\n                            cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(allSegmentations[:, :, planeIndex]))\n                            continue\n\n                        for planeIndex in xrange(debug[\'diff\'].shape[-1]):\n                            cv2.imwrite(\'test/cost_mask_\' + str(planeIndex) + \'.png\', drawMaskImage(debug[\'diff\'][0, :, :, planeIndex] / 2))\n                            continue\n                        exit(1)\n                        pass\n                    continue\n                pass\n            new_pred_dict = {}\n            for key, value in pred_dict.iteritems():\n                new_pred_dict[key] = value\n                continue\n            segmentations = np.array(predSegmentations)\n            new_pred_dict[\'segmentation\'] = segmentations[:, :, :, :options.numOutputPlanes]\n            new_pred_dict[\'non_plane_mask\'] = segmentations[:, :, :, options.numOutputPlanes:options.numOutputPlanes + 1]\n            #new_pred_dict[\'non_plane_mask\'] = segmentations[:, :, :, :options.numOutputPlanes]\n            new_pred_dict[\'depth\'] = np.array(predDepths)\n            predictions[method_index] = new_pred_dict\n            pass\n\n        if method[1] == \'crf\':\n            pred_dict = predictions[method_index]\n            predSegmentations = []\n            predDepths = []\n            for image_index in xrange(options.numImages):\n                print(\'crf \' + str(image_index + options.startIndex))\n                boundaries = pred_dict[\'boundary\'][image_index]\n                boundaries = sigmoid(boundaries)\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_boundary.png\', drawMaskImage(np.concatenate([boundaries, np.zeros((HEIGHT, WIDTH, 1))], axis=2)))\n\n                allSegmentations = np.concatenate([pred_dict[\'segmentation\'][image_index], pred_dict[\'np_mask\'][image_index]], axis=2)\n                allSegmentations = softmax(allSegmentations)\n                planeDepths = calcPlaneDepths(pred_dict[\'plane\'][image_index], WIDTH, HEIGHT, gt_dict[\'info\'][image_index])\n                allDepths = np.concatenate([planeDepths, pred_dict[\'np_depth\'][image_index]], axis=2)\n                #boundaries = np.concatenate([np.ones((allSegmentations.shape[0], allSegmentations.shape[1], 1)), -np.ones((allSegmentations.shape[0], allSegmentations.shape[1], 1))], axis=2)\n                #if options.imageIndex >= 0:\n                #boundaries = cv2.imread(options.test_dir + \'/\' + str(options.imageIndex) + \'_boundary.png\')\n                #else:\n                #boundaries = cv2.imread(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_boundary.png\')\n                #pass\n                #boundaries = (boundaries > 128).astype(np.float32)[:, :, :2]\n\n                allDepths[:, :, options.numOutputPlanes] = 0\n                pred_s = refineSegmentation(gt_dict[\'image\'][image_index], allSegmentations, allDepths, boundaries, numOutputPlanes = 20, numIterations=20, numProposals=5)\n                pred_d = allDepths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), pred_s.reshape(-1)].reshape(HEIGHT, WIDTH)\n\n                predSegmentations.append(pred_s)\n                predDepths.append(pred_d)\n\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_d))\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(pred_s, blackIndex=options.numOutputPlanes))\n\n                #segmentation = np.argmax(allSegmentations, axis=-1)\n                for planeIndex in xrange(options.numOutputPlanes + 1):\n                    cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(allSegmentations[:, :, planeIndex]))\n                    continue\n                #cv2.imwrite(options.test_dir + \'/mask_\' + str(21) + \'.png\', drawDepthImage(pred_dict[\'np_depth\'][0]))\n                #for plane_index in xrange(options.numOutputPlanes + 1):\n                #cv2.imwrite(options.test_dir + \'/mask_\' + str(plane_index) + \'.png\', drawMaskImage(pred_s == plane_index))\n                #continue\n                #exit(1)\n                continue\n\n            new_pred_dict = {}\n            for key, value in pred_dict.iteritems():\n                new_pred_dict[key] = value\n                continue\n            new_pred_dict[\'segmentation\'] = np.array(predSegmentations)\n            new_pred_dict[\'depth\'] = np.array(predDepths)\n            predictions[method_index] = new_pred_dict\n            pass\n\n\n        if \'pixelwise\' in method[1]:\n            pred_dict = predictions[method_index]\n            predPlanes = []\n            predSegmentations = []\n            predDepths = []\n            for image_index in xrange(options.numImages):\n                pred_d = pred_dict[\'np_depth\'][image_index].squeeze()\n                if \'_1\' in method[1]:\n                    pred_s = np.zeros(pred_dict[\'segmentation\'][image_index].shape)\n                    pred_p = np.zeros(pred_dict[\'plane\'][image_index].shape)\n                elif \'_2\' in methods[1]:\n                    pred_p, pred_s, pred_d = fitPlanes(pred_d, gt_dict[\'info\'][image_index], numPlanes=20, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=0.2)\n                elif \'_3\' in methods[1]:\n                    pred_p, pred_s, pred_d = fitPlanes(pred_d, gt_dict[\'info\'][image_index], numPlanes=20, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=0.2)\n                elif \'_4\' in methods[1]:\n                    pred_p, pred_s, pred_d = fitPlanesSegmentation(pred_d, pred_dict[\'semantics\'][image_index], gt_dict[\'info\'][image_index], numPlanes=20, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=0.2)\n                    pass\n                predPlanes.append(pred_p)\n                predSegmentations.append(pred_s)\n                predDepths.append(pred_d)\n\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_d))\n                cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage(pred_s))\n                continue\n            new_pred_dict = {}\n            for key, value in pred_dict.iteritems():\n                new_pred_dict[key] = value\n                continue\n            new_pred_dict[\'plane\'] = np.array(predPlanes)\n            new_pred_dict[\'segmentation\'] = np.array(predSegmentations)\n            new_pred_dict[\'depth\'] = np.array(predDepths)\n            predictions[method_index] = new_pred_dict\n            #titles.append(\'pixelwise+semantics+RANSAC\')\n            pass\n        continue\n\n\n\n    for method_index, pred_dict in enumerate(predictions):\n        print(titles[method_index])\n        evaluateDepths(pred_dict[\'depth\'], gt_dict[\'depth\'], np.ones(gt_dict[\'depth\'].shape))\n        continue\n    return\n\ndef getResults(options):\n    checkpoint_prefix = options.rootFolder + \'/checkpoint/\'\n\n    methods = options.methods\n    predictions = []\n\n    if os.path.exists(options.result_filename):\n        if options.useCache == 1:\n            results = np.load(options.result_filename)\n            results = results[()]\n            return results\n        elif options.useCache == 2:\n            results = np.load(options.result_filename)\n            results = results[()]\n            gt_dict = results[\'gt\']\n            predictions = results[\'pred\']\n        else:\n            gt_dict = getGroundTruth(options)\n            pass\n    else:\n        gt_dict = getGroundTruth(options)\n        pass\n\n\n\n    for method_index, method in enumerate(methods):\n        if len(method) < 4 or method[3] < 2:\n            continue\n        if method[0] == \'\':\n            continue\n\n        if \'ds0\' not in method[0]:\n            options.deepSupervisionLayers = [\'res4b22_relu\', ]\n        else:\n            options.deepSupervisionLayers = []\n            pass\n        options.predictConfidence = 0\n        options.predictLocal = 0\n        options.predictPixelwise = 1\n        options.predictBoundary = int(\'pb\' in method[0])\n        options.anchorPlanes = 0\n        if \'ps\' in method[0]:\n            options.predictSemantics = 1\n        else:\n            options.predictSemantics = 0\n            pass\n        if \'crfrnn\' in method[0]:\n            options.crfrnn = 10\n        else:\n            options.crfrnn = 0\n            pass\n\n        if \'ap1\' in method[0]:\n            options.anchorPlanes = 1\n            pass\n\n        options.checkpoint_dir = checkpoint_prefix + method[0]\n        print(options.checkpoint_dir)\n\n        #options.suffix = method[1]\n\n        method_names = [previous_method[0] for previous_method in methods[:method_index]]\n\n        if method[0] in method_names:\n            pred_dict = predictions[method_names.index(method[0])]\n        elif method[0] == \'gt\':\n            pred_dict = gt_dict\n        else:\n            pred_dict = getPrediction(options)\n            pass\n\n        # for image_index in xrange(options.visualizeImages):\n        #     cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_dict[\'depth\'][image_index]))\n        #     cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage())\n        #     continue\n\n        if len(method) >= 4 and method[3] == 3:\n            predictions.insert(0, pred_dict)\n        else:\n            if method_index < len(predictions):\n                predictions[method_index] = pred_dict\n            else:\n                predictions.append(pred_dict)\n                pass\n            pass\n        continue\n    #np.save(options.test_dir + \'/curves.npy\', curves)\n    results = {\'gt\': gt_dict, \'pred\': predictions}\n\n    if options.useCache != -1:\n        np.save(options.result_filename, results)\n        pass\n    pass\n\n    return results\n\ndef getPrediction(options):\n    tf.reset_default_graph()\n\n    options.batchSize = 1\n    min_after_dequeue = 1000\n\n    reader = RecordReaderAll()\n    if options.dataset == \'SUNCG\':\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_SUNCG_val.tfrecords\'], num_epochs=10000)\n    elif options.dataset == \'NYU_RGBD\':\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_nyu_rgbd_val.tfrecords\'], num_epochs=1)\n        options.deepSupervision = 0\n        options.predictLocal = 0\n    elif options.dataset == \'matterport\':\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_matterport_val.tfrecords\'], num_epochs=1)\n    else:\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_scannet_val.tfrecords\'], num_epochs=1)\n        pass\n\n    img_inp, global_gt_dict, local_gt_dict = reader.getBatch(filename_queue, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True, random=False)\n\n\n\n    training_flag = tf.constant(False, tf.bool)\n\n    options.gpu_id = 0\n    global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp, img_inp, training_flag, options)\n\n    var_to_restore = tf.global_variables()\n\n\n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n\n    width_high_res = 640\n    height_high_res = 480\n\n\n    pred_dict = {}\n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n        #var_to_restore = [v for v in var_to_restore if \'res4b22_relu_non_plane\' not in v.name]\n        loader = tf.train.Saver(var_to_restore)\n        loader.restore(sess, ""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n        #loader.restore(sess, options.fineTuningCheckpoint)\n\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n\n        try:\n            predDepths = []\n            predPlanes = []\n            predSegmentations = []\n            predSemantics = []\n            predNonPlaneDepths = []\n            predNonPlaneNormals = []\n            predNonPlaneMasks = []\n            predBoundaries = []\n            for index in xrange(options.startIndex + options.numImages):\n                if index % 10 == 0:\n                    print((\'image\', index))\n                    pass\n                t0=time.time()\n\n                img, global_gt, global_pred = sess.run([img_inp, global_gt_dict, global_pred_dict])\n\n                if index < options.startIndex:\n                    continue\n\n\n                pred_p = global_pred[\'plane\'][0]\n                pred_s = global_pred[\'segmentation\'][0]\n\n                pred_np_m = global_pred[\'non_plane_mask\'][0]\n                pred_np_d = global_pred[\'non_plane_depth\'][0]\n                pred_np_n = global_pred[\'non_plane_normal\'][0]\n\n                if global_gt[\'info\'][0][19] > 1 and global_gt[\'info\'][0][19] < 4 and False:\n                    pred_np_n = calcNormal(pred_np_d.squeeze(), global_gt[\'info\'][0])\n                    pass\n\n\n                #pred_b = global_pred[\'boundary\'][0]\n                predNonPlaneMasks.append(pred_np_m)\n                predNonPlaneDepths.append(pred_np_d)\n                predNonPlaneNormals.append(pred_np_n)\n                #predBoundaries.append(pred_b)\n\n                all_segmentations = np.concatenate([pred_s, pred_np_m], axis=2)\n\n                plane_depths = calcPlaneDepths(pred_p, width_high_res, height_high_res, global_gt[\'info\'][0])\n\n                pred_np_d = np.expand_dims(cv2.resize(pred_np_d.squeeze(), (width_high_res, height_high_res)), -1)\n                all_depths = np.concatenate([plane_depths, pred_np_d], axis=2)\n\n                all_segmentations = np.stack([cv2.resize(all_segmentations[:, :, planeIndex], (width_high_res, height_high_res)) for planeIndex in xrange(all_segmentations.shape[-1])], axis=2)\n\n                segmentation = np.argmax(all_segmentations, 2)\n                pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(height_high_res * width_high_res), segmentation.reshape(-1)].reshape(height_high_res, width_high_res)\n\n                if \'semantics\' in global_pred:\n                    #cv2.imwrite(\'test/semantics.png\', drawSegmentationImage(np.argmax(global_pred[\'semantics\'][0], axis=-1)))\n                    #exit(1)\n                    predSemantics.append(np.argmax(global_pred[\'semantics\'][0], axis=-1))\n                else:\n                    predSemantics.append(np.zeros((HEIGHT, WIDTH)))\n                    pass\n\n                predDepths.append(pred_d)\n                predPlanes.append(pred_p)\n                predSegmentations.append(segmentation)\n                continue\n            pred_dict[\'plane\'] = np.array(predPlanes)\n            pred_dict[\'segmentation\'] = np.array(predSegmentations)\n            pred_dict[\'depth\'] = np.array(predDepths)\n            #pred_dict[\'semantics\'] = np.array(predSemantics)\n            pred_dict[\'np_depth\'] = np.array(predNonPlaneDepths)\n            #pred_dict[\'np_normal\'] = np.array(predNonPlaneNormals)\n            pred_dict[\'np_mask\'] = np.array(predNonPlaneMasks)\n            #pred_dict[\'boundary\'] = np.array(predBoundaries)\n            pass\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n\n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return pred_dict\n\ndef getGroundTruth(options):\n    options.batchSize = 1\n    min_after_dequeue = 1000\n\n    reader = RecordReaderAll()\n    if options.dataset == \'SUNCG\':\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_SUNCG_val.tfrecords\'], num_epochs=10000)\n    elif options.dataset == \'NYU_RGBD\':\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_nyu_rgbd_val.tfrecords\'], num_epochs=1)\n        options.deepSupervision = 0\n        options.predictLocal = 0\n    elif options.dataset == \'matterport\':\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_matterport_val.tfrecords\'], num_epochs=1)\n    else:\n        filename_queue = tf.train.string_input_producer([\'/mnt/vision/PlaneNet/planes_scannet_val.tfrecords\'], num_epochs=1)\n        pass\n\n    img_inp, global_gt_dict, local_gt_dict = reader.getBatch(filename_queue, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True, random=False)\n\n\n    training_flag = tf.constant(False, tf.bool)\n\n    # if options.dataset == \'NYU_RGBD\':\n    #     global_gt_dict[\'segmentation\'], global_gt_dict[\'plane_mask\'] = tf.ones((options.batchSize, HEIGHT, WIDTH, options.numOutputPlanes)), tf.ones((options.batchSize, HEIGHT, WIDTH, 1))\n    # elif options.dataset == \'SUNCG\':\n    #     normalDotThreshold = np.cos(np.deg2rad(5))\n    #     distanceThreshold = 0.05\n    #     global_gt_dict[\'segmentation\'], global_gt_dict[\'plane_mask\'] = fitPlaneMasksModule(global_gt_dict[\'plane\'], global_gt_dict[\'depth\'], global_gt_dict[\'normal\'], width=WIDTH, height=HEIGHT, normalDotThreshold=normalDotThreshold, distanceThreshold=distanceThreshold, closing=True, one_hot=True)\n    # else:\n    #     global_gt_dict[\'plane_mask\'] = 1 - global_gt_dict[\'non_plane_mask\']\n    #     pass\n\n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n    gt_dict = {}\n\n    width_high_res = 640\n    height_high_res = 480\n\n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n        try:\n            gtDepths = []\n            gtNormals = []\n            planeMasks = []\n            #predMasks = []\n            gtPlanes = []\n            gtSegmentations = []\n            gtSemantics = []\n            gtInfo = []\n            gtNumPlanes = []\n            images = []\n\n            for index in xrange(options.startIndex + options.numImages):\n                print((\'image\', index))\n                t0=time.time()\n\n                img, global_gt = sess.run([img_inp, global_gt_dict])\n\n                if index < options.startIndex:\n                    continue\n\n\n                imagePath = global_gt[\'image_path\'][0]\n                #exit(1)\n                # if index == 11:\n                #     cv2.imwrite(\'test/mask.png\', drawMaskImage(global_gt[\'non_plane_mask\'].squeeze()))\n                #     exit(1)\n\n                #image = ((img[0] + 0.5) * 255).astype(np.uint8)\n                image = cv2.imread(imagePath)\n                image = cv2.resize(image, (width_high_res, height_high_res))\n                images.append(image)\n\n                #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_boundary.png\', drawMaskImage(np.concatenate([global_gt[\'boundary\'][0], np.zeros((HEIGHT, WIDTH, 1))], axis=2)))\n\n                #gt_d = global_gt[\'depth\'].squeeze()\n                gt_d = np.array(PIL.Image.open(imagePath.replace(\'color.jpg\', \'depth.pgm\'))).astype(np.float32) / global_gt[\'info\'][0][18]\n                gt_d = cv2.resize(gt_d, (width_high_res, height_high_res), interpolation=cv2.INTER_LINEAR)\n                gtDepths.append(gt_d)\n\n                if global_gt[\'info\'][0][19] == 3 and False:\n                    gt_n = calcNormal(gt_d, global_gt[\'info\'][0])\n                    #cv2.imwrite(\'test/normal.png\', drawNormalImage(gt_n))\n                    #exit(1)\n                else:\n                    gt_n = global_gt[\'normal\'][0]\n                    pass\n                gtNormals.append(gt_n)\n\n                planeMask = np.squeeze(1 - global_gt[\'non_plane_mask\'])\n                planeMasks.append(planeMask)\n\n                gt_p = global_gt[\'plane\'][0]\n                gtPlanes.append(gt_p)\n                gt_s = global_gt[\'segmentation\'][0]\n                gtSegmentations.append(gt_s)\n                gt_semantics = global_gt[\'semantics\'][0]\n                gtSemantics.append(gt_semantics)\n                gt_num_p = global_gt[\'num_planes\'][0]\n                gtNumPlanes.append(gt_num_p)\n\n                gtInfo.append(global_gt[\'info\'][0])\n                continue\n\n            gt_dict[\'image\'] = np.array(images)\n            gt_dict[\'depth\'] = np.array(gtDepths)\n            gt_dict[\'normal\'] = np.array(gtNormals)\n            gt_dict[\'plane_mask\'] = np.array(planeMasks)\n            gt_dict[\'plane\'] = np.array(gtPlanes)\n            gt_dict[\'segmentation\'] = np.array(gtSegmentations)\n            gt_dict[\'semantics\'] = np.array(gtSemantics)\n            gt_dict[\'num_planes\'] = np.array(gtNumPlanes)\n            gt_dict[\'info\'] = np.array(gtInfo)\n\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n\n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return gt_dict\n\n\nif __name__==\'__main__\':\n    """"""\n    Parse input arguments\n    """"""\n    parser = argparse.ArgumentParser(description=\'Planenet\')\n    parser.add_argument(\'--task\', dest=\'task\',\n                        help=\'task type\',\n                        default=\'predict\', type=str)\n    parser.add_argument(\'--numOutputPlanes\', dest=\'numOutputPlanes\',\n                        help=\'the number of output planes\',\n                        default=20, type=int)\n    parser.add_argument(\'--dataset\', dest=\'dataset\',\n                        help=\'dataset name\',\n                        default=\'ScanNet\', type=str)\n    parser.add_argument(\'--hybrid\', dest=\'hybrid\',\n                        help=\'hybrid\',\n                        default=\'3\', type=str)\n    parser.add_argument(\'--visualizeImages\', dest=\'visualizeImages\',\n                        help=\'visualize image\',\n                        default=30, type=int)\n    parser.add_argument(\'--numImages\', dest=\'numImages\',\n                        help=\'the number of images\',\n                        default=30, type=int)\n    parser.add_argument(\'--startIndex\', dest=\'startIndex\',\n                        help=\'start index\',\n                        default=0, type=int)\n    parser.add_argument(\'--useCache\', dest=\'useCache\',\n                        help=\'use cache\',\n                        default=0, type=int)\n    # parser.add_argument(\'--useCRF\', dest=\'useCRF\',\n    #                     help=\'use crf\',\n    #                     default=0, type=int)\n    # parser.add_argument(\'--useSemantics\', dest=\'useSemantics\',\n    #                     help=\'use semantics\',\n    #                     default=0, type=int)\n    parser.add_argument(\'--useNonPlaneDepth\', dest=\'useNonPlaneDepth\',\n                        help=\'use non-plane depth\',\n                        default=0, type=int)\n    parser.add_argument(\'--imageIndex\', dest=\'imageIndex\',\n                        help=\'image index\',\n                        default=-1, type=int)\n    parser.add_argument(\'--methods\', dest=\'methods\',\n                        help=\'methods\',\n                        default=\'0\', type=str)\n    parser.add_argument(\'--suffix\', dest=\'suffix\',\n                        help=\'suffix\',\n                        default=\'\', type=str)\n    parser.add_argument(\'--rootFolder\', dest=\'rootFolder\',\n                        help=\'root folder\',\n                        default=\'/mnt/vision/PlaneNet/\', type=str)\n\n    args = parser.parse_args()\n    #args.hybrid = \'hybrid\' + args.hybrid\n    args.test_dir = \'evaluate/\' + args.task + \'/\' + args.dataset + \'/hybrid\' + args.hybrid + \'/\'\n    args.visualizeImages = min(args.visualizeImages, args.numImages)\n\n    #args.titles = [ALL_TITLES[int(method)] for method in args.methods]\n    #args.methods = [ALL_METHODS[int(method)] for method in args.methods]\n    args.titles = ALL_TITLES\n    args.methods = [ALL_METHODS[int(args.methods[0])]]\n\n    args.result_filename = args.test_dir + \'/results_\' + str(args.startIndex) + \'.npy\'\n\n    #if args.imageIndex >= 0 and args.suffix != \'\':\n    if args.suffix != \'\':\n        args.test_dir += \'/\' + args.suffix + \'/\'\n        pass\n\n    print(args.titles)\n\n    if args.task == \'predict\':\n        evaluatePlanes(args)\n    elif args.task == \'depth\':\n        evaluateDepthPrediction(args)\n    elif args.task == \'search\':\n        gridSearch(args)\n        pass\n'"
code/predict_custom.py,12,"b'import tensorflow as tf\nimport numpy as np\n#np.set_printoptions(precision=2, linewidth=200)\nimport cv2\nimport os\nimport time\nimport sys\nimport tf_nndistance\nimport argparse\nimport glob\nimport PIL\nimport scipy.ndimage as ndimage\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom utils import *\nfrom plane_utils import *\nfrom modules import *\n\nfrom train_sample import build_graph\nfrom planenet import PlaneNet\nfrom RecordReaderAll import *\nfrom SegmentationRefinement import *\nfrom crfasrnn_layer import CrfRnnLayer\n\nWIDTH = 256\nHEIGHT = 192\n\nALL_TITLES = [\'PlaneNet\']\n#ALL_METHODS = [(\'sample_np10_hybrid3_bl0_dl0_ds0_crfrnn5_sm0\', \'\', 0, 2), (\'planenet_hybrid3_crf1_pb_pp\', \'\', 1, 2), (\'sample_np10_hybrid3_bl0_dl0_hl2_ds0_crfrnn5_sm0\', \'\', 1, 2), (\'\', \'\', 1, 2), (\'\', \'\', 1, 2), (\'\', \'\', 1, 2), (\'\', \'\', 1, 2)]\nALL_METHODS = [(\'sample_np10_hybrid3_bl0_dl0_ds0_crfrnn5_sm0\', \'\', 0, 2), (\'planenet_hybrid3_bl0_dl0_ll1_pb_pp_ps_sm0\', \'\', 0, 2), (\'pixelwise_hybrid3_ps\', \'\', 1, 2), (\'planenet_hybrid3_bl0_dl0_bw0.5_pb_pp_ps\', \'\', 1, 2), (\'\', \'\', 1, 2), (\'\', \'\', 1, 2), (\'\', \'\', 1, 2), (\'\', \'\', 1, 2)]\n\n\ndef writeHTML(options):\n    from html import HTML\n\n    titles = options.titles\n\n    h = HTML(\'html\')\n    h.p(\'Results\')\n    h.br()\n    path = \'.\'\n    #methods = [\'planenet\', \'pixelwise\', \'pixelwise+RANSAC\', \'GT+RANSAC\', \'planenet+crf\', \'pixelwise+semantics+RANSAC\']\n    #methods = [\'planenet\', \'pixelwise\', \'pixelwise+RANSAC\', \'GT+RANSAC\']\n\n    for image_index in xrange(options.numImages):\n\n        t = h.table(border=\'1\')\n        r_inp = t.tr()\n        r_inp.td(\'input \' + str(image_index + options.startIndex))\n        r_inp.td().img(src=path + \'/\' + str(image_index + options.startIndex) + \'_image.png\')\n        # r = t.tr()\n        # r.td(\'PlaneNet prediction\')\n        # r.td().img(src=firstFolder + \'/\' + str(index) + \'_segmentation_pred.png\')\n        # r.td().img(src=firstFolder + \'/\' + str(index) + \'_depth_pred.png\')\n\n        r = t.tr()\n        r.td(\'methods\')\n        for method_index, method in enumerate(titles):\n            r.td(method)\n            continue\n\n        r = t.tr()\n        r.td(\'segmentation\')\n        for method_index, method in enumerate(titles):\n            r.td().img(src=path + \'/\' + str(image_index + options.startIndex) + \'_segmentation_pred_\' + str(method_index) + \'.png\')\n            r.td().img(src=path + \'/\' + str(image_index + options.startIndex) + \'_segmentation_pred_blended_\' + str(method_index) + \'.png\')\n            continue\n\n        r = t.tr()\n        r.td(\'depth\')\n        for method_index, method in enumerate(titles):\n            r.td().img(src=path + \'/\' + str(image_index + options.startIndex) + \'_depth_pred_\' + str(method_index) + \'.png\')\n            continue\n        h.br()\n        continue\n\n    metric_titles = [\'depth error 0.1\', \'depth error 0.2\', \'depth error 0.3\', \'IOU 0.3\', \'IOU 0.5\', \'IOU 0.7\']\n\n    h.p(\'Curves on plane accuracy\')\n    for title in metric_titles:\n        h.img(src=\'curve_plane_\' + title.replace(\' \', \'_\') + \'.png\')\n        continue\n\n    h.p(\'Curves on pixel coverage\')\n    for title in metric_titles:\n        h.img(src=\'curve_pixel_\' + title.replace(\' \', \'_\') + \'.png\')\n        continue\n\n\n    html_file = open(options.test_dir + \'/index.html\', \'w\')\n    html_file.write(str(h))\n    html_file.close()\n    return\n\ndef evaluatePlanes(options):\n    #writeHTML(options)\n    #exit(1)\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n\n    predictions = getResults(options)\n\n    saving = True\n    if predictions[0][\'image\'].shape[0] != options.numImages:\n        saving = False\n        pass\n    options.numImages = min(options.numImages, predictions[0][\'image\'].shape[0])\n\n\n    for pred_dict in predictions:\n        for key, value in pred_dict.iteritems():\n            if value.shape[0] > options.numImages:\n                pred_dict[key] = value[:options.numImages]\n                pass\n            continue\n        continue\n\n    #methods = [\'planenet\', \'pixelwise+RANSAC\', \'GT+RANSAC\']\n\n\n\n    #predictions[2] = predictions[3]\n\n\n\n    for image_index in xrange(options.visualizeImages):\n        if args.imageIndex >= 0 and image_index + options.startIndex != args.imageIndex:\n            continue\n        #print(info)\n        #print(np.rad2deg(np.arctan(info[16] / 2 / info[0])) * 2)\n        for method_index, pred_dict in enumerate(predictions):\n            if image_index >= pred_dict[\'image\'].shape[0]:\n                break\n            print(pred_dict[\'info\'][image_index])\n\n            cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_image.png\', pred_dict[\'image\'][image_index])\n            info = pred_dict[\'info\'][image_index]\n            cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_dict[\'depth\'][image_index]))\n\n            if \'pixelwise\' in options.methods[method_index][1]:\n                continue\n            allSegmentations = pred_dict[\'segmentation\'][image_index]\n            segmentation = np.argmax(allSegmentations, axis=-1)\n            #segmentation = np.argmax(np.concatenate([segmentation, pred_dict[\'np_mask\'][image_index]], axis=2), -1)\n            segmentationImage = drawSegmentationImage(segmentation, blackIndex=options.numOutputPlanes)\n            cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_segmentation_pred_\' + str(method_index) + \'_complete.png\', drawSegmentationImage(allSegmentations[:, :, :-1]))\n            cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_segmentation_pred_\' + str(method_index) + \'.png\', segmentationImage)\n            segmentationImageBlended = (segmentationImage * 0.7 + pred_dict[\'image\'][image_index] * 0.3).astype(np.uint8)\n            cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_segmentation_pred_blended_\' + str(method_index) + \'.png\', segmentationImageBlended)\n\n            segmentationImageBlended = np.minimum(segmentationImage * 0.3 + pred_dict[\'image\'][image_index] * 0.7, 255).astype(np.uint8)\n\n            if options.imageIndex >= 0:\n                for planeIndex in xrange(options.numOutputPlanes):\n                    cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(segmentation == planeIndex))\n                    continue\n\n                if options.suffix == \'texture\':\n\n                    resultImage = copyLogo(options.test_dir, image_index + options.startIndex, pred_dict[\'image\'][image_index], pred_dict[\'depth\'][image_index], pred_dict[\'plane\'][image_index], segmentation, pred_dict[\'info\'][image_index])\n                    #resultImage = copyWallTexture(options.test_dir, image_index + options.startIndex, gt_dict[\'image\'][image_index], pred_dict[\'depth\'][image_index], pred_dict[\'plane\'][image_index], segmentation, gt_dict[\'info\'][image_index], [7, 9])\n                    cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_result.png\', resultImage)\n                    writePLYFile(options.test_dir, image_index + options.startIndex, pred_dict[\'image\'][image_index], pred_dict[\'depth\'][image_index], segmentation, pred_dict[\'plane\'][image_index], pred_dict[\'info\'][image_index])\n                elif options.suffix == \'ruler\':\n                    addRulerComplete(options.test_dir, image_index + options.startIndex, pred_dict[\'image\'][image_index], pred_dict[\'depth\'][image_index], pred_dict[\'plane\'][image_index], segmentation, pred_dict[\'info\'][image_index], startPixel=(950, 444), endPixel=(1120, 2220), fixedEndPoint=True, numFrames=1000)\n                    #addRulerComplete(options.test_dir, image_index + options.startIndex, pred_dict[\'image\'][image_index], pred_dict[\'depth\'][image_index], pred_dict[\'plane\'][image_index], segmentation, pred_dict[\'info\'][image_index], startPixel=(950, 444), endPixel=(1120, 2220), fixedEndPoint=True, numFrames=1)\n                    #addRulerComplete(options.test_dir, image_index + options.startIndex, pred_dict[\'image\'][image_index], pred_dict[\'depth\'][image_index], pred_dict[\'plane\'][image_index], segmentation, pred_dict[\'info\'][image_index], startPixel=(1150, 616), endPixel=(1340, 2100), fixedEndPoint=True, numFrames=1)\n                    #addRulerComplete(options.test_dir, image_index + options.startIndex, pred_dict[\'image\'][image_index], pred_dict[\'depth\'][image_index], pred_dict[\'plane\'][image_index], segmentation, pred_dict[\'info\'][image_index], startPixel=(1357, 451), endPixel=(1437, 2175), fixedEndPoint=True, numFrames=1)\n                    #addRulerComplete(options.test_dir, image_index + options.startIndex, pred_dict[\'image\'][image_index], pred_dict[\'depth\'][image_index], pred_dict[\'plane\'][image_index], segmentation, pred_dict[\'info\'][image_index], startPixel=(1149, 609), endPixel=(1330, 2100), fixedEndPoint=True, numFrames=1)\n                    #addRulerComplete(options.test_dir, image_index + options.startIndex, pred_dict[\'image\'][image_index], pred_dict[\'depth\'][image_index], pred_dict[\'plane\'][image_index], segmentation, pred_dict[\'info\'][image_index], startPixel=(1285, 621), endPixel=(1425, 1940), fixedEndPoint=True, numFrames=1)\n                elif options.suffix == \'TV\':\n                    copyLogoVideo(options.test_dir, image_index + options.startIndex, pred_dict[\'image\'][image_index], pred_dict[\'depth\'][image_index], pred_dict[\'plane\'][image_index], segmentation, pred_dict[\'info\'][image_index], textureType=\'TV\', wallInds=[2, 9])\n                elif options.suffix == \'character\':\n                    addCharacter(options.test_dir, image_index + options.startIndex, pred_dict[\'image\'][image_index])\n                elif options.suffix == \'dump\':\n                    planes = pred_dict[\'plane\']\n                    planes /= np.linalg.norm(planes, axis=-1, keepdims=True)\n                    print([(planeIndex, plane) for planeIndex, plane in enumerate(planes[0])])\n                    for planeIndex in xrange(options.numOutputPlanes):\n                        cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(segmentation == planeIndex))\n                        continue\n\n                    print(\'dump\')\n                    newPlanes = []\n                    newSegmentation = np.full(segmentation.shape, -1)\n                    newPlaneIndex = 0\n                    planes = pred_dict[\'plane\'][image_index]\n                    for planeIndex in xrange(options.numOutputPlanes):\n                        mask = segmentation == planeIndex\n                        if mask.sum() > 0:\n                            newPlanes.append(planes[planeIndex])\n                            newSegmentation[mask] = newPlaneIndex\n                            newPlaneIndex += 1\n                            pass\n                        continue\n\n                    np.save(\'test/\' + str(image_index + options.startIndex) + \'_planes.npy\', np.stack(newPlanes, axis=0))\n                    #print(global_gt[\'non_plane_mask\'].shape)\n                    np.save(\'test/\' + str(image_index + options.startIndex) + \'_segmentation.npy\', newSegmentation)\n                    cv2.imwrite(\'test/\' + str(image_index + options.startIndex) + \'_image.png\', pred_dict[\'image\'][image_index])\n                    depth = pred_dict[\'depth\'][image_index]\n                    np.save(\'test/\' + str(image_index + options.startIndex) + \'_depth.npy\', depth)\n                    info = pred_dict[\'info\'][image_index]\n                    #normal = calcNormal(depth, info)\n                    #np.save(\'test/\' + str(image_index + options.startIndex) + \'_normal.npy\', normal)\n                    np.save(\'test/\' + str(image_index + options.startIndex) + \'_info.npy\', info)\n                    exit(1)\n                else:\n                    np_mask = (segmentation == options.numOutputPlanes).astype(np.float32)\n                    np_depth = pred_dict[\'np_depth\'][image_index].squeeze()\n                    np_depth = cv2.resize(np_depth, (np_mask.shape[1], np_mask.shape[0]))\n                    cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_np_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(np_depth * np_mask))\n                    writePLYFile(options.test_dir, image_index + options.startIndex, segmentationImageBlended, pred_dict[\'depth\'][image_index], segmentation, pred_dict[\'plane\'][image_index], pred_dict[\'info\'][image_index])\n                    pass\n                exit(1)\n                pass\n            continue\n        continue\n\n    writeHTML(options)\n    exit(1)\n    return\n\n\ndef getResults(options):\n    checkpoint_prefix = options.rootFolder + \'/checkpoint/\'\n\n    methods = options.methods\n    predictions = []\n\n    if os.path.exists(options.result_filename) and options.useCache == 1:\n        predictions = np.load(options.result_filename)\n        return predictions\n\n\n\n    for method_index, method in enumerate(methods):\n        if len(method) < 4 or method[3] < 2:\n            continue\n        if method[0] == \'\':\n            continue\n\n        if \'ds0\' not in method[0]:\n            options.deepSupervisionLayers = [\'res4b22_relu\', ]\n        else:\n            options.deepSupervisionLayers = []\n            pass\n        options.predictConfidence = 0\n        options.predictLocal = 0\n        options.predictPixelwise = 1\n        options.predictBoundary = int(\'pb\' in method[0])\n        options.anchorPlanes = 0\n        if \'ps\' in method[0]:\n            options.predictSemantics = 1\n        else:\n            options.predictSemantics = 0\n            pass\n        if \'crfrnn\' in method[0]:\n            options.crfrnn = 10\n        else:\n            options.crfrnn = 0\n            pass\n\n        if \'ap1\' in method[0]:\n            options.anchorPlanes = 1\n            pass\n\n        options.checkpoint_dir = checkpoint_prefix + method[0]\n        print(options.checkpoint_dir)\n\n        options.suffix = method[1]\n\n        method_names = [previous_method[0] for previous_method in methods[:method_index]]\n\n        if method[0] in method_names:\n            pred_dict = predictions[method_names.index(method[0])]\n        elif method[0] == \'gt\':\n            pred_dict = gt_dict\n        else:\n            pred_dict = getPrediction(options)\n            pass\n\n        # for image_index in xrange(options.visualizeImages):\n        #     cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_depth_pred_\' + str(method_index) + \'.png\', drawDepthImage(pred_dict[\'depth\'][image_index]))\n        #     cv2.imwrite(options.test_dir + \'/\' + str(image_index + options.startIndex) + \'_segmentation_pred_\' + str(method_index) + \'.png\', drawSegmentationImage())\n        #     continue\n\n        if len(method) >= 4 and method[3] == 3:\n            predictions.insert(0, pred_dict)\n        else:\n            if method_index < len(predictions):\n                predictions[method_index] = pred_dict\n            else:\n                predictions.append(pred_dict)\n                pass\n            pass\n        continue\n    #np.save(options.test_dir + \'/curves.npy\', curves)\n    results = predictions\n\n    #print(results)\n\n    if options.useCache != -1:\n        np.save(options.result_filename, results)\n        pass\n    pass\n\n    return results\n\ndef getPrediction(options):\n    tf.reset_default_graph()\n\n    options.batchSize = 1\n\n    img_inp = tf.placeholder(tf.float32, shape=[1, HEIGHT, WIDTH, 3], name=\'image\')\n    training_flag = tf.constant(False, tf.bool)\n\n    options.gpu_id = 0\n    global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp, img_inp, training_flag, options)\n\n    var_to_restore = tf.global_variables()\n\n\n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n\n    width_high_res = 640\n    height_high_res = 480\n\n\n    #image_list = glob.glob(\'../my_images/*.jpg\') + glob.glob(\'../my_images/*.png\') + glob.glob(\'../my_images/*.JPG\')\n    #image_list = glob.glob(\'../my_images/TV/*.jpg\') + glob.glob(\'../my_images/TV/*.png\') + glob.glob(\'../my_images/TV/*.JPG\')\n    #image_list = glob.glob(\'../my_images/Courthouse/*.jpg\')\n    #image_list = glob.glob(\'/mnt/vision/Floorplan/floorplan/PointCloudSegmentation2/dump_segmentation_images/*.png\')\n    image_list = glob.glob(\'../my_images/SUNCG/*.jpg\') + glob.glob(\'../my_images/SUNCG/*.png\') + glob.glob(\'../my_images/SUNCG/*.JPG\')\n\n    pred_dict = {}\n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n        #var_to_restore = [v for v in var_to_restore if \'res4b22_relu_non_plane\' not in v.name]\n        loader = tf.train.Saver(var_to_restore)\n        loader.restore(sess, ""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n        #loader.restore(sess, options.fineTuningCheckpoint)\n\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n\n        try:\n            predDepths = []\n            predPlanes = []\n            predSegmentations = []\n            predSemantics = []\n            predNonPlaneDepths = []\n            predNonPlaneNormals = []\n            predNonPlaneMasks = []\n            predBoundaries = []\n            images = []\n            infos = []\n            for index in xrange(min(options.startIndex + options.numImages, len(image_list))):\n                if index % 10 == 0:\n                    print((\'image\', index))\n                    pass\n                t0=time.time()\n\n                print((\'image\', index))\n\n                img_ori = cv2.imread(image_list[index])\n                images.append(img_ori)\n                img = cv2.resize(img_ori, (WIDTH, HEIGHT))\n                img = img.astype(np.float32) / 255 - 0.5\n                img = np.expand_dims(img, 0)\n                global_pred = sess.run(global_pred_dict, feed_dict={img_inp: img})\n\n                if index < options.startIndex:\n                    continue\n\n\n                pred_p = global_pred[\'plane\'][0]\n                pred_s = global_pred[\'segmentation\'][0]\n\n                pred_np_m = global_pred[\'non_plane_mask\'][0]\n                pred_np_d = global_pred[\'non_plane_depth\'][0]\n                pred_np_n = global_pred[\'non_plane_normal\'][0]\n\n                #if global_gt[\'info\'][0][19] > 1 and global_gt[\'info\'][0][19] < 4 and False:\n                #pred_np_n = calcNormal(pred_np_d.squeeze(), global_gt[\'info\'][0])\n                #pass\n\n\n                #pred_b = global_pred[\'boundary\'][0]\n                predNonPlaneMasks.append(pred_np_m)\n                predNonPlaneDepths.append(pred_np_d)\n                predNonPlaneNormals.append(pred_np_n)\n                #predBoundaries.append(pred_b)\n\n                all_segmentations = np.concatenate([pred_s, pred_np_m], axis=2)\n\n                info = np.zeros(20)\n                #focalLength = estimateFocalLength(img_ori)\n                # info[0] = focalLength\n                # info[5] = focalLength\n                # info[2] = img_ori.shape[1] / 2\n                # info[6] = img_ori.shape[0] / 2\n                # info[16] = img_ori.shape[1]\n                # info[17] = img_ori.shape[0]\n                # info[10] = 1\n                # info[15] = 1\n                # info[18] = 1000\n                # info[19] = 5\n\n                info[0] = 2800.71\n                info[2] = 1634.45\n                info[5] = 2814.01\n                info[6] = 1224.18\n                info[16] = img_ori.shape[1]\n                info[17] = img_ori.shape[0]\n                info[10] = 1\n                info[15] = 1\n                info[18] = 1000\n                info[19] = 6\n\n                # print(focalLength)\n                # cv2.imwrite(\'test/image.png\', ((img[0] + 0.5) * 255).astype(np.uint8))\n                # cv2.imwrite(\'test/segmentation.png\', drawSegmentationImage(pred_s, blackIndex=options.numOutputPlanes))\n                # exit(1)\n                infos.append(info)\n                width_high_res = img_ori.shape[1]\n                height_high_res = img_ori.shape[0]\n\n                plane_depths = calcPlaneDepths(pred_p, width_high_res, height_high_res, info)\n\n                pred_np_d = np.expand_dims(cv2.resize(pred_np_d.squeeze(), (width_high_res, height_high_res)), -1)\n                all_depths = np.concatenate([plane_depths, pred_np_d], axis=2)\n\n                all_segmentations = np.stack([cv2.resize(all_segmentations[:, :, planeIndex], (width_high_res, height_high_res)) for planeIndex in xrange(all_segmentations.shape[-1])], axis=2)\n\n                segmentation = np.argmax(all_segmentations, 2)\n                pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(height_high_res * width_high_res), segmentation.reshape(-1)].reshape(height_high_res, width_high_res)\n\n                if \'semantics\' in global_pred:\n                    cv2.imwrite(\'test/semantics_\' + str(index) + \'.png\', drawSegmentationImage(np.argmax(global_pred[\'semantics\'][0], axis=-1)))\n                    cv2.imwrite(\'test/image_\' + str(index) + \'.png\', img_ori)\n                    predSemantics.append(np.argmax(global_pred[\'semantics\'][0], axis=-1))\n                else:\n                    predSemantics.append(np.zeros((HEIGHT, WIDTH)))\n                    pass\n\n                predDepths.append(pred_d)\n                predPlanes.append(pred_p)\n                predSegmentations.append(all_segmentations)\n                continue\n            pred_dict[\'plane\'] = np.array(predPlanes)\n            pred_dict[\'segmentation\'] = np.array(predSegmentations)\n            pred_dict[\'depth\'] = np.array(predDepths)\n            #pred_dict[\'semantics\'] = np.array(predSemantics)\n            pred_dict[\'np_depth\'] = np.array(predNonPlaneDepths)\n            #pred_dict[\'np_normal\'] = np.array(predNonPlaneNormals)\n            pred_dict[\'np_mask\'] = np.array(predNonPlaneMasks)\n            pred_dict[\'image\'] = np.array(images)\n            pred_dict[\'info\'] = np.array(infos)\n            #pred_dict[\'boundary\'] = np.array(predBoundaries)\n            pass\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n\n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return pred_dict\n\n\nif __name__==\'__main__\':\n    """"""\n    Parse input arguments\n    """"""\n    parser = argparse.ArgumentParser(description=\'Planenet\')\n    parser.add_argument(\'--task\', dest=\'task\',\n                        help=\'task type\',\n                        default=\'custom\', type=str)\n    parser.add_argument(\'--numOutputPlanes\', dest=\'numOutputPlanes\',\n                        help=\'the number of output planes\',\n                        default=20, type=int)\n    parser.add_argument(\'--dataset\', dest=\'dataset\',\n                        help=\'dataset name\',\n                        default=\'ScanNet\', type=str)\n    parser.add_argument(\'--hybrid\', dest=\'hybrid\',\n                        help=\'hybrid\',\n                        default=\'3\', type=str)\n    parser.add_argument(\'--visualizeImages\', dest=\'visualizeImages\',\n                        help=\'visualize image\',\n                        default=30, type=int)\n    parser.add_argument(\'--numImages\', dest=\'numImages\',\n                        help=\'the number of images\',\n                        default=30, type=int)\n    parser.add_argument(\'--startIndex\', dest=\'startIndex\',\n                        help=\'start index\',\n                        default=0, type=int)\n    parser.add_argument(\'--useCache\', dest=\'useCache\',\n                        help=\'use cache\',\n                        default=0, type=int)\n    # parser.add_argument(\'--useCRF\', dest=\'useCRF\',\n    #                     help=\'use crf\',\n    #                     default=0, type=int)\n    # parser.add_argument(\'--useSemantics\', dest=\'useSemantics\',\n    #                     help=\'use semantics\',\n    #                     default=0, type=int)\n    parser.add_argument(\'--useNonPlaneDepth\', dest=\'useNonPlaneDepth\',\n                        help=\'use non-plane depth\',\n                        default=0, type=int)\n    parser.add_argument(\'--imageIndex\', dest=\'imageIndex\',\n                        help=\'image index\',\n                        default=-1, type=int)\n    parser.add_argument(\'--methods\', dest=\'methods\',\n                        help=\'methods\',\n                        default=\'0\', type=str)\n    parser.add_argument(\'--suffix\', dest=\'suffix\',\n                        help=\'suffix\',\n                        default=\'\', type=str)\n    parser.add_argument(\'--rootFolder\', dest=\'rootFolder\',\n                        help=\'root folder\',\n                        default=\'/mnt/vision/PlaneNet/\', type=str)\n\n    args = parser.parse_args()\n    #args.hybrid = \'hybrid\' + args.hybrid\n    args.test_dir = \'evaluate/\' + args.task + \'/\' + args.dataset + \'/hybrid\' + args.hybrid + \'/\'\n    args.visualizeImages = min(args.visualizeImages, args.numImages)\n\n    #args.titles = [ALL_TITLES[int(method)] for method in args.methods]\n    #args.methods = [ALL_METHODS[int(method)] for method in args.methods]\n    args.titles = ALL_TITLES\n    args.methods = [ALL_METHODS[int(args.methods[0])]]\n\n    args.result_filename = args.test_dir + \'/results_\' + str(args.startIndex) + \'.npy\'\n\n    if args.imageIndex >= 0 and args.suffix != \'\':\n        args.test_dir += \'/\' + args.suffix + \'/\'\n        pass\n\n    print(args.titles)\n\n    if args.task == \'custom\':\n        evaluatePlanes(args)\n    elif args.task == \'depth\':\n        evaluateDepthPrediction(args)\n    elif args.task == \'search\':\n        gridSearch(args)\n        pass\n'"
code/room_layout.py,12,"b'import tensorflow as tf\nimport numpy as np\nnp.set_printoptions(precision=2, linewidth=200)\nimport cv2\nimport os\nimport time\nimport sys\nimport tf_nndistance\nimport argparse\nimport glob\nimport PIL\nimport scipy.ndimage as ndimage\nimport itertools\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom utils import *\nfrom plane_utils import *\nfrom modules import *\n\nfrom train_planenet import build_graph\nfrom train_sample import build_graph as build_graph_sample\nfrom planenet import PlaneNet\nHEIGHT=192\nWIDTH=256\n\ndef getGroundTruth(options):\n    if options.useCache == 1 and os.path.exists(options.test_dir + \'/room_layout_gt.npy\'):\n        results = np.load(options.test_dir + \'/room_layout_gt.npy\')\n        results = results[()]\n        return results[\'index\'], results[\'layout\']\n\n    import scipy.io as sio\n    if options.dataset == \'NYU_RGBD\':\n        image_indices = sio.loadmat(\'../../Data/NYU_RGBD/room_layout/index_303.mat\')[\'index\'].squeeze()\n        print(image_indices.shape)\n        test_indices = sio.loadmat(\'../../Data/NYU_RGBD/room_layout/data_split.mat\')[\'test\'].squeeze()\n        train_indices = sio.loadmat(\'../../Data/NYU_RGBD/room_layout/data_split.mat\')[\'train\'].squeeze()\n        indices = image_indices.nonzero()[0][test_indices - 1]\n        room_layouts = sio.loadmat(\'../../Data/NYU_RGBD/room_layout/layout_GT.mat\')[\'layout_GT\'].squeeze()\n        room_layouts = room_layouts[:, :, test_indices - 1]\n        room_layouts = np.transpose(room_layouts, [2, 0, 1])\n    else:\n        filenames = glob.glob(\'/mnt/vision/RoomLayout_Hedau/*.mat\')\n        room_layouts = []\n        indices = []\n        for filename in filenames:\n            room_layout = sio.loadmat(filename)\n            if \'fields\' not in room_layout:\n                continue\n            room_layout = room_layout[\'fields\'].squeeze()\n            new_room_layout = np.zeros(room_layout.shape)\n            new_room_layout[room_layout == 5] = 1\n            new_room_layout[room_layout == 1] = 2\n            new_room_layout[room_layout == 4] = 3\n            new_room_layout[room_layout == 2] = 4\n            new_room_layout[room_layout == 3] = 5\n            \n            room_layouts.append(new_room_layout)\n            indices.append(filename)\n            continue\n        pass\n        \n    np.save(options.test_dir + \'/room_layout_gt.npy\', {\'index\': indices, \'layout\': room_layouts})\n    #print(room_layouts.shape)\n    #print(room_layouts.max())\n    #print(room_layouts.min())        \n    return indices, room_layouts\n    \n\ndef getResults(options):\n\n    \n    checkpoint_prefix = options.rootFolder + \'/checkpoint/\'\n\n    \n    #method = (\'hybrid_hybrid1_bl0_dl0_ll1_sm0\', \'\')\n    #method = (\'finetuning_hybrid1_ps\', \'\')\n    #method = (\'planenet_hybrid1_bl0_ll1_ds0_pp_ps\', \'\')\n    left_walls = [0, 5, 6, 11, 18]\n    right_walls = [4, 10, 7, 19]\n    floors = [14]\n    ceilings = []    \n\n    #method = (\'hybrid_np10_hybrid1_bl0_dl0_ds0_crfrnn5_sm0\', \'\')\n    method = (\'finetuning_np10_hybrid1_ds0_ps\', \'\')\n    #method = (\'sample_np10_hybrid3_bl0_dl0_ds0_crfrnn5_sm0\', \'\')\n    left_walls = [2]\n    right_walls = [3, 7]\n    floors = [5]\n    ceilings = []    \n    #method = (\'sample_np10_hybrid3_bl0_dl0_hl2_ds0_crfrnn5_sm0\', \'\')\n    #method = (\'planenet_np10_hybrid3_bl0_dl0_crfrnn-10_sm0\', \'\')\n    # left_walls = [0, 5, 6, 11, 18]\n    # right_walls = [4, 10]\n    # floors = [14]\n    # ceilings = []    \n    # layout_planes = [ceilings, floors, left_walls + right_walls]    \n    layout_planes = [ceilings, floors, left_walls + right_walls]\n    \n    \n    if \'ds0\' not in method[0]:\n        options.deepSupervisionLayers = [\'res4b22_relu\', ]\n    else:\n        options.deepSupervisionLayers = []\n        pass\n    options.predictConfidence = 0\n    options.predictLocal = 0\n    options.predictPixelwise = 1\n    options.predictBoundary = int(\'pb\' in method[0])\n    options.anchorPlanes = 0\n    options.predictSemantics = 0\n    options.batchSize = 1\n\n    if \'crfrnn\' in method[0]:\n        options.crfrnn = 10\n    else:\n        options.crfrnn = 0\n        pass    \n    if \'ap1\' in method[0]:\n        options.anchorPlanes = 1\n        pass\n        \n    options.checkpoint_dir = checkpoint_prefix + method[0]\n    print(options.checkpoint_dir)\n    \n    options.suffix = method[1]\n\n\n    pred_dict = getPrediction(options, layout_planes)\n    #np.save(options.test_dir + \'/curves.npy\', curves)\n    return\n\ndef getPrediction(options, layout_planes):\n    print(options.test_dir)\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n\n    indices, room_layouts = getGroundTruth(options)\n    \n    \n    #image_list = glob.glob(\'/home/chenliu/Projects/Data/LSUN/images/*.jpg\')\n    #image_list = glob.glob(\'/mnt/vision/NYU_RGBD/images/*.png\')\n\n\n    if options.dataset == \'NYU_RGBD\':\n        image_list = [\'/mnt/vision/NYU_RGBD/images/\' + (\'%08d\' % (image_index + 1)) + \'.png\' for image_index in indices]\n    else:\n        image_list = [filename.replace(\'RoomLayout_Hedau\', \'RoomLayout_Hedau/Images\').replace(\'_labels.mat\', \'.jpg\') for filename in indices]\n        #image_list = glob.glob(\'/mnt/vision/RoomLayout_Hedau/Images/*.png\') + glob.glob(\'/mnt/vision/RoomLayout_Hedau/Images/*.jpg\')\n        pass\n    #print(len(image_list))\n    #exit(1)\n    options.numImages = min(options.numImages, len(image_list))\n\n    \n    tf.reset_default_graph()    \n\n    \n    training_flag = tf.constant(False, tf.bool)\n\n    img_inp = tf.placeholder(tf.float32, shape=[1, HEIGHT, WIDTH, 3], name=\'image\')\n    \n    options.gpu_id = 0\n    if \'sample\' or \'hybrid_\' in options.checkpoint_dir:\n        global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph_sample(img_inp, img_inp, training_flag, options)\n    else:\n        global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp, img_inp, training_flag, options)\n        pass\n\n    var_to_restore = tf.global_variables()\n\n\n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n\n    info = np.zeros(20)\n    info[0] = 5.1885790117450188e+02\n    info[2] = 3.2558244941119034e+02\n    info[5] = 5.1946961112127485e+02\n    info[6] = 2.5373616633400465e+02\n    info[10] = 1\n    info[15] = 1\n    info[16] = 640\n    info[17] = 480\n    info[18] = 1000\n    info[19] = 1\n    \n    pred_dict = {}\n\n    print(np.concatenate([np.expand_dims(np.arange(22), 1), ColorPalette(22).getColorMap()], axis=1))\n\n    planeAreaThresholds = [WIDTH * HEIGHT / 400, WIDTH * HEIGHT / 400, WIDTH * HEIGHT / 400]\n    dotThreshold = np.cos(np.deg2rad(60))\n    width_high_res = 640\n    height_high_res = 480\n    \n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n        #var_to_restore = [v for v in var_to_restore if \'res4b22_relu_non_plane\' not in v.name]\n        loader = tf.train.Saver(var_to_restore)\n        loader.restore(sess, ""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n        #loader.restore(sess, options.fineTuningCheckpoint)\n        \n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n        \n        try:\n            total_accuracy = 0\n            predSegmentations = []\n            predPlaneDepths = []\n            predAllSegmentations = []\n            predNormals = []\n            for index in xrange(options.startIndex + options.numImages):\n                if index < options.startIndex:\n                    continue\n                if options.imageIndex >= 0 and index != options.imageIndex:\n                    continue\n                if index % 10 == 0:\n                    print((\'image\', index))\n                    pass\n\n                # print(image_list[index])\n                # import PIL.Image\n                # img = PIL.Image.open(image_list[index])\n                # print(img._getexif())\n                # print(img.shape)\n                # exit(1)\n\n                #print(image_list[index])\n                img_ori = cv2.imread(image_list[index])\n\n                img = cv2.resize(img_ori, (WIDTH, HEIGHT))\n                img = img.astype(np.float32) / 255 - 0.5\n                \n                t0=time.time()\n\n                global_pred = sess.run(global_pred_dict, feed_dict={img_inp: np.expand_dims(img, 0)})\n\n\n\n                pred_p = global_pred[\'plane\'][0]\n                pred_s = global_pred[\'segmentation\'][0]\n                \n                pred_np_m = global_pred[\'non_plane_mask\'][0]\n                pred_np_d = global_pred[\'non_plane_depth\'][0]\n                pred_np_n = global_pred[\'non_plane_normal\'][0]\n\n                pred_b = global_pred[\'boundary\'][0]\n\n\n                if options.dataset != \'NYU_RGBD\':\n                    info = np.zeros(info.shape)\n                    focalLength = estimateFocalLength(img_ori)\n                    info[0] = focalLength\n                    info[5] = focalLength\n                    info[2] = img_ori.shape[1] / 2\n                    info[6] = img_ori.shape[0] / 2\n                    info[16] = img_ori.shape[1]\n                    info[17] = img_ori.shape[0]\n                    info[10] = 1\n                    info[15] = 1\n                    info[18] = 1000\n                    info[19] = 5\n                    width_high_res = img_ori.shape[1]\n                    height_high_res = img_ori.shape[0]\n                    pass\n                    \n                #all_segmentations = np.concatenate([pred_s, pred_np_m], axis=2)\n                all_segmentations = pred_s\n                plane_depths = calcPlaneDepths(pred_p, width_high_res, height_high_res, info)\n\n                all_segmentations = softmax(all_segmentations)\n                #segmentation = np.argmax(all_segmentations[:, :, :pred_s.shape[-1]], 2)\n                segmentation = np.argmax(all_segmentations, 2)\n\n                \n                planeNormals = pred_p / np.maximum(np.linalg.norm(pred_p, axis=-1, keepdims=True), 1e-4)\n                predSegmentations.append(segmentation)\n                predPlaneDepths.append(plane_depths)\n                predAllSegmentations.append(all_segmentations)\n                predNormals.append(planeNormals)\n                continue\n\n                #print(pred_p)\n                if True:\n\n                    #all_depths = np.concatenate([plane_depths, np.expand_dims(cv2.resize(pred_np_d.squeeze(), (width_high_res, height_high_res)), -1)], axis=2)\n                    #pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape(HEIGHT, WIDTH)                    \n                    #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n                    if options.imageIndex >= 0:\n                        for planeIndex in xrange(options.numOutputPlanes):\n                            cv2.imwrite(options.test_dir + \'/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(all_segmentations[:, :, planeIndex]))\n                            #cv2.imwrite(options.test_dir + \'/mask_\' + str(planeIndex) + \'_depth.png\', drawDepthImage(plane_depths[:, :, planeIndex]))                        \n                            continue\n                        pass\n                    \n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(all_segmentations[:, :, :options.numOutputPlanes], blackIndex=options.numOutputPlanes))\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', img_ori)\n\n                    layout_plane_inds = []\n                    for layoutIndex, planeInds in enumerate(layout_planes[:2]):\n                        maxArea = 0\n                        for planeIndex in planeInds:\n                            area = (all_segmentations[:, :, planeIndex]).sum()\n                            #area = (segmentation == planeIndex).sum()\n                            if area > maxArea:\n                                layout_plane_index = planeIndex\n                                maxArea = area\n                                pass\n                            continue\n                        if maxArea > planeAreaThresholds[layoutIndex]:\n                            layout_plane_inds.append(layout_plane_index)\n                        else:\n                            layout_plane_inds.append(-1)\n                            pass\n                        continue\n\n                    # wallPlanes = []\n                    # for planeIndex in layout_planes[2]:\n                    #     area = (all_segmentations[:, :, planeIndex]).sum()                        \n                    #     #area = (segmentation == planeIndex).sum()\n                    #     if area > planeAreaThresholds[2]:\n                    #         wallPlanes.append([planeIndex, area])\n                    #         pass\n                    #     #print(planeIndex, area)\n                    #     continue\n\n\n                    # if options.imageIndex >= 0:\n                    #     print(wallPlanes)\n                    #     pass\n                    \n                    # wallPlanes = sorted(wallPlanes, key=lambda x: -x[1])\n                    # while True:\n                    #     hasChange = False\n                    #     for wallPlaneIndex, wallPlane in enumerate(wallPlanes):\n                    #         newWallPlanes = []\n                    #         for otherWallPlane in wallPlanes[wallPlaneIndex + 1:]:\n                    #             if np.dot(planeNormals[otherWallPlane[0]], planeNormals[wallPlane[0]]) > dotThreshold:\n                    #                 if options.imageIndex >= 0:\n                    #                     print(\'invalid\', wallPlane, otherWallPlane)\n                    #                     pass\n                    #                 hasChange = True\n                    #                 continue\n                    #             newWallPlanes.append(otherWallPlane)\n                    #             continue\n                    #         if hasChange:\n                    #             wallPlanes = wallPlanes[:wallPlaneIndex + 1] + newWallPlanes\n                    #             break\n                    #         continue\n                    #     if not hasChange:\n                    #         break\n                    #     continue\n\n                    # if options.imageIndex >= 0:\n                    #     print(wallPlanes)                        \n                    #     print(all_segmentations.sum(axis=(0, 1)))\n                    #     print(wallPlanes)\n                    #     print(planeNormals)\n                    #     pass\n                    \n                    # if len(wallPlanes) > 3:\n                    #     wallPlanes = wallPlanes[:3]\n                    #     pass\n                    # angleWallPlanes = []\n                    # for wallPlane in wallPlanes:\n                    #     planeNormal = planeNormals[wallPlane[0]]\n                    #     angle = np.rad2deg(np.arctan2(planeNormal[1], planeNormal[0]))\n                    #     angleWallPlanes.append((angle, wallPlane))\n                    #     #direction = min(max(int(angle / 45), 0), 3)\n                    #     #directionPlaneMask[direction] = wallPlane[0]\n                    #     continue\n\n                    # walls = [-1, -1, -1]\n                    # minAngleDiff = 90\n                    # for angle, wallPlane in angleWallPlanes:\n                    #     if abs(angle - 90) < minAngleDiff:\n                    #         walls[1] = wallPlane[0]\n                    #         minAngleDiff = abs(angle - 90)\n                    #         middleAngle = angle\n                    #         pass\n                    #     continue\n                    # if walls[1] >= 0:\n                    #     maxScore = 0\n                    #     for angle, wallPlane in angleWallPlanes:\n                    #         if angle > middleAngle + 1e-4:\n                    #             if wallPlane[1] > maxScore:\n                    #                 walls[0] = wallPlane[0]\n                    #                 maxScore = wallPlane[1]\n                    #                 pass\n                    #             pass\n                    #         continue\n                    #     maxScore = 0\n                    #     for angle, wallPlane in angleWallPlanes:\n                    #         if angle < middleAngle - 1e-4:\n                    #             if wallPlane[1] > maxScore:\n                    #                 walls[2] = wallPlane[0]\n                    #                 maxScore = wallPlane[1]\n                    #                 pass\n                    #             pass\n                    #         continue\n                    #     pass\n\n                    walls = []\n                    for planeIndex in layout_planes[2]:\n                        area = (all_segmentations[:, :, planeIndex]).sum()                        \n                        #area = (segmentation == planeIndex).sum()\n                        if area > planeAreaThresholds[2]:\n                            walls.append(planeIndex)\n                            pass\n                        #print(planeIndex, area)\n                        continue\n                    \n                    best_layout_plane_inds = layout_plane_inds + walls\n                    bestScore = 0\n                    for numWalls in xrange(1, min(len(walls), 3) + 1):\n                        for selectedWalls in itertools.combinations(walls, numWalls):\n                            selected_plane_inds = np.array(layout_plane_inds + list(selectedWalls))\n                            depths = []\n                            for wall in selected_plane_inds:\n                                depths.append(plane_depths[:, :, wall])\n                                continue\n                            depths.append(np.full((height, width), 10))\n                            depths = np.stack(depths, axis=2)\n                            selected_plane_segmentation = np.argmin(depths, 2)\n                            emptyMask = selected_plane_segmentation == depths.shape[-1] - 1\n                            selected_plane_segmentation = selected_plane_inds[np.minimum(selected_plane_segmentation.reshape(-1), selected_plane_inds.shape[0] - 1)].reshape(selected_plane_segmentation.shape)\n                            selected_plane_segmentation[emptyMask] = -1\n                            #overlap = (selected_plane_segmentation == segmentation).sum()\n                            overlap = 0\n                            for planeIndex in xrange(options.numOutputPlanes):\n                                overlap += segmentations[:, :, planeIndex][selected_plane_segmentation == planeIndex].sum()\n                                continue\n                            if overlap > bestScore:\n                                best_layout_plane_inds = selected_plane_inds\n                                bestScore = overlap\n                                pass\n                            continue\n                        continue\n                    layout_plane_inds = best_layout_plane_inds\n                    layout_plane_depths = []\n                    for planeIndex in layout_plane_inds:\n                        if planeIndex >= 0:\n                            layout_plane_depths.append(plane_depths[:, :, planeIndex])\n                        else:\n                            layout_plane_depths.append(np.ones((height_high_res, width_high_res)) * 10)\n                            pass\n                        continue\n\n                    # walls = [-1, -1, -1]\n                    # if directionPlaneMask[0] >= 0:\n                    #     if directionPlaneMask[1] >= 0:\n                    #         if directionPlaneMask[2] >= 0:\n                    #             walls = [directionPlaneMask[0], directionPlaneMask[1], directionPlaneMask[2]]\n                    #         elif directionPlaneMask[3] >= 0:\n                    #             walls = [directionPlaneMask[0], directionPlaneMask[1], directionPlaneMask[3]]\n                    #         else:\n                    #             walls = [directionPlaneMask[0], directionPlaneMask[1], -1]\n                    #             pass\n                    #     else:\n                    #         if directionPlaneMask[2] >= 0:\n                    #             if directionPlaneMask[3] >= 0:\n                    #                 walls = [directionPlaneMask[0], directionPlaneMask[2], directionPlaneMask[3]]\n                    #             else:\n                    #                 walls = [directionPlaneMask[0], directionPlaneMask[2], -1]\n                    #                 pass\n                    #         else:\n                    #             if directionPlaneMask[3] >= 0:\n                    #                 walls = [directionPlaneMask[0], -1, directionPlaneMask[3]]\n                    #             else:\n                    #                 walls = [directionPlaneMask[0], -1, -1]\n                    #                 pass\n                        \n                        \n                    layout_plane_depths = np.stack(layout_plane_depths, axis=2)\n                    #print(layout_plane_depths.shape)\n                    #print(np.argmin(layout_plane_depths, axis=-1).shape)\n                    layout_pred = np.argmin(layout_plane_depths, axis=-1) + 1\n                    layout_gt = room_layouts[index]\n\n                    layout_pred_img = drawSegmentationImage(layout_pred)\n                    #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_layout_pred.png\', layout_pred_img)\n                    #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_layout_pred.png\', img_ori / 2 + layout_pred_img / 2)\n                    layout_plane_inds = np.array(layout_plane_inds)\n                    \n                    layout_segmentation_img = layout_plane_inds[layout_pred.reshape(-1) - 1].reshape(layout_pred.shape)\n                    layout_segmentation_img[layout_segmentation_img == -1] = options.numOutputPlanes\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_layout_pred.png\', drawSegmentationImage(layout_segmentation_img, blackIndex=options.numOutputPlanes))\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_layout_gt.png\', drawSegmentationImage(layout_gt, blackIndex=0))\n\n                    pred_d = plane_depths.reshape(-1, options.numOutputPlanes)[np.arange(width_high_res * height_high_res), cv2.resize(segmentation, (width_high_res, height_high_res), interpolation=cv2.INTER_NEAREST).reshape(-1)].reshape(height_high_res, width_high_res)\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))                    \n                    #continue\n                \n                    # numWalls = 0\n                    # for wall in walls:\n                    #     if wall >= 0:\n                    #         numWalls += 1\n                    #         pass\n                    #     continue\n                    numWalls = layout_plane_inds.shape[0] - 2\n                    if numWalls == 2:\n                        gtMiddleWallMask = layout_gt == 4\n                        leftWallScore = np.logical_and(layout_pred == 3, gtMiddleWallMask).sum()\n                        middleWallScore = np.logical_and(layout_pred == 4, gtMiddleWallMask).sum()                        \n                        rightWallScore = np.logical_and(layout_pred == 5, gtMiddleWallMask).sum()\n\n                        if leftWallScore > middleWallScore:\n                            layout_pred[layout_pred >= 3] += 1\n                            pass\n                        if rightWallScore > middleWallScore:                        \n                            layout_pred[layout_pred >= 3] -= 1\n                            pass\n                        pass\n                    if numWalls == 1:\n                        layout_pred[layout_pred == 3] += 1\n                        pass\n\n                    # leftWallMask = layout_gt == 3\n                    # middleWallMask = layout_gt == 4\n                    # rightWallMask = layout_gt == 5\n                    # if leftWallMask.sum() > middleWallMask.sum() and rightWallMask.sum() == 0:\n                    #     layout_gt[np.logical_or(leftWallMask, middleWallMask)] += 1\n                    #     pass\n                    # if rightWallMask.sum() > middleWallMask.sum() and leftWallMask.sum() == 0:\n                    #     layout_gt[np.logical_or(rightWallMask, middleWallMask)] -= 1\n                    #     pass\n                    # pass\n\n                    accuracy = float((layout_pred == layout_gt).sum()) / (width_high_res * height_high_res)\n                    print((index, accuracy))\n                    total_accuracy += accuracy                    \n                    pass\n                if options.imageIndex >= 0:                    \n                    exit(1)\n                    pass\n                continue\n            segmentations = np.array(predSegmentations)\n            np.save(\'test/segmentation.npy\', segmentations)\n            planeDepths = np.array(predPlaneDepths)\n            np.save(\'test/plane_depths.npy\', planeDepths)\n            predAllSegmentations = np.array(predAllSegmentations)\n            np.save(\'test/all_segmentations.npy\', predAllSegmentations)\n            predNormals = np.array(predNormals)\n            np.save(\'test/normals.npy\', predNormals) \n            print(\'accuracy\', total_accuracy / options.numImages)\n            pass\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n        \n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return pred_dict\n\n\ndef testRoomLayout(options):\n    left_walls = [2, 9]\n    right_walls = [3, 7, 8]\n    floors = [5]\n    ceilings = [1]\n    layout_planes = [ceilings, floors, left_walls + right_walls]\n    \n    #planeAreaThresholds = [WIDTH * HEIGHT / 400, WIDTH * HEIGHT / 400, WIDTH * HEIGHT / 400]\n    planeAreaThresholds = [0, 0, 0]\n\n    indices, room_layouts = getGroundTruth(options)    \n    if options.dataset == \'NYU_RGBD\':\n        image_list = [\'/mnt/vision/NYU_RGBD/images/\' + (\'%08d\' % (image_index + 1)) + \'.png\' for image_index in indices]\n    else:\n        image_list = [filename.replace(\'RoomLayout_Hedau\', \'RoomLayout_Hedau/Images\').replace(\'_labels.mat\', \'.jpg\') for filename in indices]\n        #image_list = glob.glob(\'/mnt/vision/RoomLayout_Hedau/Images/*.png\') + glob.glob(\'/mnt/vision/RoomLayout_Hedau/Images/*.jpg\')\n        pass\n    options.numImages = min(options.numImages, len(image_list))\n    dotThreshold = np.cos(np.deg2rad(60))\n    width_high_res = 640\n    height_high_res = 480\n    \n    predSegmentations = np.load(\'test/segmentation.npy\')\n    predAllSegmentations = np.load(\'test/all_segmentations.npy\')    \n    predPlaneDepths = np.load(\'test/plane_depths.npy\')\n    predNormals = np.load(\'test/normals.npy\')\n    \n    total_accuracy = 0\n    \n    for index in xrange(predSegmentations.shape[0]):\n        if index < options.startIndex:\n            continue\n        if options.imageIndex >= 0 and index != options.imageIndex:\n            continue\n\n        \n        segmentation = predSegmentations[index]\n        plane_depths = predPlaneDepths[index]\n        img_ori = cv2.imread(image_list[index])\n\n        if options.dataset != \'NYU_RGBD\':\n            width_high_res = img_ori.shape[1]\n            height_high_res = img_ori.shape[0]\n            pass\n                    \n        \n        all_segmentations = predAllSegmentations[index]\n        planeNormals = predNormals[index]\n        if options.imageIndex >= 0:\n            for planeIndex in xrange(options.numOutputPlanes):\n                #cv2.imwrite(options.test_dir + \'/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(all_segmentations[:, :, planeIndex]))\n                cv2.imwrite(options.test_dir + \'/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(segmentation == planeIndex))\n                #cv2.imwrite(options.test_dir + \'/mask_\' + str(planeIndex) + \'_depth.png\', drawDepthImage(plane_depths[:, :, planeIndex]))\n                continue\n            pass\n                    \n        #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(all_segmentations[:, :, :options.numOutputPlanes], blackIndex=options.numOutputPlanes))\n        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(segmentation, blackIndex=options.numOutputPlanes))\n        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', img_ori)\n\n        layout_plane_inds = []\n        for layoutIndex, planeInds in enumerate(layout_planes[:2]):\n            maxArea = 0\n            for planeIndex in planeInds:\n                #area = (all_segmentations[:, :, planeIndex]).sum()\n                area = (segmentation == planeIndex).sum()\n                if area > maxArea:\n                    layout_plane_index = planeIndex\n                    maxArea = area\n                    pass\n                continue\n            if maxArea > planeAreaThresholds[layoutIndex]:\n                layout_plane_inds.append(layout_plane_index)\n            else:\n                layout_plane_inds.append(-1)\n                pass\n            continue\n\n\n        walls = []\n        for planeIndex in layout_planes[2]:\n            #area = (all_segmentations[:, :, planeIndex]).sum()                        \n            area = (segmentation == planeIndex).sum()\n            if area > planeAreaThresholds[2]:\n                walls.append(planeIndex)\n                pass\n            #print(planeIndex, area)\n            continue\n\n        best_layout_plane_inds = layout_plane_inds + walls\n        bestScore = 0\n        layout_plane_inds_array = [layout_plane_inds]\n        if layout_plane_inds[0] != -1:\n            layout_plane_inds_array.append([-1, layout_plane_inds[1]])\n            pass\n        for layout_plane_inds in layout_plane_inds_array:\n            for numWalls in xrange(1, min(len(walls), 3) + 1):\n                for combinationIndex, selectedWalls in enumerate(itertools.combinations(walls, numWalls)):\n                    invalidCombination = False\n                    for wallPlaneIndex, wallPlane in enumerate(selectedWalls):\n                        for otherWallPlane in selectedWalls[wallPlaneIndex + 1:]:\n                            if np.dot(planeNormals[otherWallPlane], planeNormals[wallPlane]) > dotThreshold:\n                                invalidCombination = True\n                                break\n                                pass\n                            continue\n                        if invalidCombination:\n                            break\n                        continue\n                    if invalidCombination:\n                        continue\n                    selected_plane_inds = np.array(layout_plane_inds + list(selectedWalls))\n                    depths = []\n                    for wall in selected_plane_inds:\n                        if wall >= 0:\n                            depths.append(plane_depths[:, :, wall])\n                        else:\n                            depths.append(np.full((height_high_res, width_high_res), 10))\n                        continue\n                    depths.append(np.full((height_high_res, width_high_res), 10))\n                    depths = np.stack(depths, axis=2)\n                    selected_plane_segmentation = np.argmin(depths, 2)\n                    emptyMask = selected_plane_segmentation == depths.shape[-1] - 1\n                    selected_plane_segmentation = selected_plane_inds[np.minimum(selected_plane_segmentation.reshape(-1), selected_plane_inds.shape[0] - 1)].reshape(selected_plane_segmentation.shape)\n                    selected_plane_segmentation[emptyMask] = -1\n\n                    selected_plane_segmentation = cv2.resize(selected_plane_segmentation, (WIDTH, HEIGHT), interpolation=cv2.INTER_NEAREST)\n\n                    overlap = (selected_plane_segmentation == segmentation).sum()\n                    # overlap = 0\n                    # for planeIndex in xrange(options.numOutputPlanes):\n                    #     overlap += all_segmentations[:, :, planeIndex][selected_plane_segmentation == planeIndex].sum()\n                    #     continue\n\n                    if options.imageIndex >= 0:\n                        if layout_plane_inds[0] == -1:\n                            cv2.imwrite(\'test/segmentation_\' + str(numWalls) + \'_\' + str(combinationIndex) + \'.png\', drawSegmentationImage(selected_plane_segmentation, blackIndex=options.numOutputPlanes))\n                        else:\n                            cv2.imwrite(\'test/segmentation_\' + str(numWalls) + \'_\' + str(combinationIndex) + \'_1.png\', drawSegmentationImage(selected_plane_segmentation, blackIndex=options.numOutputPlanes))\n                            pass\n                        print(combinationIndex, selectedWalls, selected_plane_inds, depths.shape, overlap)\n                        pass\n                    if overlap > bestScore:\n                        best_layout_plane_inds = selected_plane_inds\n                        bestScore = overlap\n                        pass\n                    continue\n                continue\n            continue\n        layout_plane_inds = best_layout_plane_inds\n\n        if options.imageIndex >= 0:\n            print(walls)\n            print(layout_plane_inds)\n            #exit(1)\n            pass\n        \n        layout_plane_depths = []\n        for planeIndex in layout_plane_inds:\n            if planeIndex >= 0:\n                layout_plane_depths.append(plane_depths[:, :, planeIndex])\n            else:\n                layout_plane_depths.append(np.ones((height_high_res, width_high_res)) * 10)\n                pass\n            continue\n\n        layout_plane_depths = np.stack(layout_plane_depths, axis=2)\n        #print(layout_plane_depths.shape)\n        #print(np.argmin(layout_plane_depths, axis=-1).shape)\n        layout_pred = np.argmin(layout_plane_depths, axis=-1) + 1\n        layout_gt = room_layouts[index]\n\n        layout_pred_img = drawSegmentationImage(layout_pred)\n        #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_layout_pred.png\', layout_pred_img)\n        #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_layout_pred.png\', img_ori / 2 + layout_pred_img / 2)\n        layout_plane_inds = np.array(layout_plane_inds)\n\n        layout_segmentation_img = layout_plane_inds[layout_pred.reshape(-1) - 1].reshape(layout_pred.shape)\n        layout_segmentation_img[layout_segmentation_img == -1] = options.numOutputPlanes\n        edgeMap = calcEdgeMap(layout_segmentation_img, edgeWidth=2)\n        layout_segmentation_img = drawSegmentationImage(layout_segmentation_img, blackIndex=options.numOutputPlanes)\n        layout_segmentation_img = (img_ori * 0.7 + layout_segmentation_img * 0.3).astype(np.uint8)\n        layout_segmentation_img[edgeMap > 0.5] = 255\n        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_layout_pred.png\', layout_segmentation_img)\n        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_layout_gt.png\', drawSegmentationImage(layout_gt, blackIndex=0))\n\n        pred_d = plane_depths.reshape(-1, options.numOutputPlanes)[np.arange(width_high_res * height_high_res), cv2.resize(segmentation, (width_high_res, height_high_res), interpolation=cv2.INTER_NEAREST).reshape(-1)].reshape(height_high_res, width_high_res)\n        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))                    \n        #continue\n\n        # numWalls = 0\n        # for wall in walls:\n        #     if wall >= 0:\n        #         numWalls += 1\n        #         pass\n        #     continue\n        numWalls = layout_plane_inds.shape[0] - 2\n        if numWalls == 2:\n            gtMiddleWallMask = layout_gt == 4\n            leftWallScore = np.logical_and(layout_pred == 3, gtMiddleWallMask).sum()\n            middleWallScore = np.logical_and(layout_pred == 4, gtMiddleWallMask).sum()                        \n            rightWallScore = np.logical_and(layout_pred == 5, gtMiddleWallMask).sum()\n\n            if leftWallScore > middleWallScore:\n                layout_pred[layout_pred >= 3] += 1\n                pass\n            if rightWallScore > middleWallScore:                        \n                layout_pred[layout_pred >= 3] -= 1\n                pass\n            pass\n        if numWalls == 1:\n            layout_pred[layout_pred == 3] += 1\n            pass\n\n        # leftWallMask = layout_gt == 3\n        # middleWallMask = layout_gt == 4\n        # rightWallMask = layout_gt == 5\n        # if leftWallMask.sum() > middleWallMask.sum() and rightWallMask.sum() == 0:\n        #     layout_gt[np.logical_or(leftWallMask, middleWallMask)] += 1\n        #     pass\n        # if rightWallMask.sum() > middleWallMask.sum() and leftWallMask.sum() == 0:\n        #     layout_gt[np.logical_or(rightWallMask, middleWallMask)] -= 1\n        #     pass\n        # pass\n\n        accuracy = float((layout_pred == layout_gt).sum()) / (width_high_res * height_high_res)\n        print((index, accuracy))\n        total_accuracy += accuracy                    \n        if options.imageIndex >= 0:                    \n            exit(1)\n            pass\n        continue\n    print(\'accuracy\', total_accuracy / options.numImages)\n    return\n\n\n\ndef testRoomNet(options):\n    import csv\n    from skimage import measure\n    \n    cornerConfigurations = [[[2, 1, 7, 8], [6, 5, 3, 4], [4, 3, 1, 2], [1, 3, 5, 7, 1], [8, 7, 5, 6]],\n                            [[], [6, 4, 1, 3], [3, 1, 2], [2, 1, 4, 5], [5, 4, 6]],\n                            [[2, 1, 4, 5], [], [3, 1, 2], [1, 3, 6, 4], [5, 4, 6]],\n                            [[2, 1, 4], [], [3, 1, 2], [4, 1, 3], []],\n                            [[], [4, 1, 2], [2, 1, 3], [3, 1, 4], []],\n                            [[2, 1, 3], [6, 4, 5], [5, 4, 1, 2], [3, 1, 4, 6], []],\n                            [[1, 2], [4, 3], [], [(3, 4), (2, 1)], []],\n                            [[], [], [2, 1], [(1, 2), (4, 3)], [3, 4]],\n                            [[1, 2], [], [], [2, 1], []],\n                            [[], [2, 1], [], [1, 2], []],\n                            [[], [], [2, 1], [1, 2], []]]\n    \n    \n    #planeAreaThresholds = [WIDTH * HEIGHT / 400, WIDTH * HEIGHT / 400, WIDTH * HEIGHT / 400]\n    planeAreaThresholds = [0, 0, 0]\n\n    indices, room_layouts = getGroundTruth(options)    \n    if options.dataset == \'NYU_RGBD\':\n        image_list = [\'/mnt/vision/NYU_RGBD/images/\' + (\'%08d\' % (image_index + 1)) + \'.png\' for image_index in indices]\n    else:\n        image_list = [filename.replace(\'RoomLayout_Hedau\', \'RoomLayout_Hedau/Images\').replace(\'_labels.mat\', \'.jpg\') for filename in indices]\n        #image_list = glob.glob(\'/mnt/vision/RoomLayout_Hedau/Images/*.png\') + glob.glob(\'/mnt/vision/RoomLayout_Hedau/Images/*.jpg\')\n        pass\n    options.numImages = min(options.numImages, len(image_list))\n    dotThreshold = np.cos(np.deg2rad(60))\n\n    \n    predSegmentations = np.load(\'test/segmentation.npy\')\n    predAllSegmentations = np.load(\'test/all_segmentations.npy\')    \n    predPlaneDepths = np.load(\'test/plane_depths.npy\')\n    predNormals = np.load(\'test/normals.npy\')\n    width_high_res = 640\n    height_high_res = 480        \n    \n    total_accuracy = 0\n\n    numImages = 0\n    for index in xrange(predSegmentations.shape[0]):\n        if index < options.startIndex:\n            continue\n        if options.imageIndex >= 0 and index != options.imageIndex:\n            continue        \n\n        img_ori = cv2.imread(image_list[index])\n        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', img_ori)\n        \n        predictionFilename = \'roomnet_predictions/\' + str(index) + \'_image.txt\'\n        roomType = -1\n        corners = []\n        with open(predictionFilename) as predictionFile:\n            predictionLoader = csv.reader(predictionFile, delimiter=\' \')\n            for lineIndex, line in enumerate(predictionLoader):\n                if lineIndex == 0:\n                    roomType = int(line[0])\n                else:\n                    corners.append((round(float(line[1]) / 320 * width_high_res), round(float(line[0]) / 320 * height_high_res)))\n                    pass\n                continue\n            pass\n\n        assert(roomType >= 1)\n        cornerConfiguration = cornerConfigurations[roomType - 1]\n\n        layout_pred = np.full((height_high_res, width_high_res), -1, dtype=np.int32)\n        for layoutIndex, cornerInds in enumerate(cornerConfiguration):\n            if len(cornerInds) == 0:\n                continue\n            indices = np.arange(width_high_res * height_high_res)\n            us = indices % width_high_res\n            vs = np.floor(indices / width_high_res)\n            mask = np.ones(indices.shape, dtype=np.bool)\n            for i in xrange(len(cornerInds) - 1):\n                assert(not isinstance(cornerInds[i], tuple))\n                assert(not isinstance(cornerInds[i + 1], tuple))                \n                corner_1 = corners[cornerInds[i] - 1]\n                corner_2 = corners[cornerInds[i + 1] - 1]\n                if abs(corner_1[0] - corner_2[0]) <= 1 and abs(corner_1[1] - corner_2[1]) <= 1:\n                    continue\n                lineNormal = np.array([-(corner_1[1] - corner_2[1]), corner_1[0] - corner_2[0]])\n                lineNormal = lineNormal / max(np.linalg.norm(lineNormal), 1e-4)\n                lineOffset = lineNormal[0] * corner_1[0] + lineNormal[1] * corner_1[1]\n                offsets = lineNormal[0] * us + lineNormal[1] * vs\n                mask = np.logical_and(mask, offsets >= lineOffset)\n                continue\n            mask = mask.reshape((height_high_res, width_high_res))\n            layout_pred[mask] = layoutIndex\n            #cv2.imwrite(\'test/mask.png\', drawMaskImage(mask))\n            #exit(1)            \n            continue\n\n        \n        #if roomType != 5:\n        #continue\n        #print(index, corners)\n            \n        if options.imageIndex >= 0:\n            print((layout_pred == 0).sum())\n            print(roomType, cornerConfiguration)\n            print(corners)\n            pass\n            #exit(1)            \n        layout_pred = layout_pred + 1\n        layout_gt = room_layouts[index]\n\n        numWalls = int((layout_pred == 3).max()) + int((layout_pred == 4).max()) + int((layout_pred == 5).max())\n        if numWalls == 2:\n            gtMiddleWallMask = layout_gt == 4\n            leftWallScore = np.logical_and(layout_pred == 3, gtMiddleWallMask).sum()\n            middleWallScore = np.logical_and(layout_pred == 4, gtMiddleWallMask).sum()                        \n            rightWallScore = np.logical_and(layout_pred == 5, gtMiddleWallMask).sum()\n\n            if leftWallScore > middleWallScore:\n                layout_pred[layout_pred >= 3] += 1\n                pass\n            if rightWallScore > middleWallScore:                        \n                layout_pred[layout_pred >= 3] -= 1\n                pass\n            pass\n        if numWalls == 1:\n            mask = layout_pred >= 3\n            bestScore = 0\n            bestLayoutIndex = 4\n            for layoutIndex in xrange(3, 6):\n                score = np.logical_and(mask, layout_gt == layoutIndex).sum()\n                if score > bestScore:\n                    bestLayoutIndex = layoutIndex\n                    bestScore = score\n                    pass\n                continue\n            layout_pred[mask] = bestLayoutIndex\n            pass\n\n        emptyMask = layout_pred == 0\n        if emptyMask.sum() > 0:\n            print(index, emptyMask.sum())\n            masks = measure.label(emptyMask, background=0)\n            for maskIndex in xrange(masks.min() + 1, masks.max() + 1):\n                mask = masks == maskIndex\n                bestScore = 0\n                bestLayoutIndex = 4\n                for layoutIndex in xrange(1, 6):\n                    score = np.logical_and(mask, layout_gt == layoutIndex).sum()\n                    if score > bestScore:\n                        bestLayoutIndex = layoutIndex\n                        bestScore = score\n                        pass\n                    continue\n                layout_pred[mask] = bestLayoutIndex\n                continue\n            pass\n\n        layout_pred_img = drawSegmentationImage(layout_pred, blackIndex=0)\n        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_layout_pred.png\', layout_pred_img)\n        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_layout_gt.png\', drawSegmentationImage(layout_gt, blackIndex=0))\n        \n        accuracy = float((layout_pred == layout_gt).sum()) / (width_high_res * height_high_res)\n        numImages += 1\n        print((index, accuracy))\n        total_accuracy += accuracy                    \n        if options.imageIndex >= 0:                    \n            exit(1)\n            pass\n        continue\n    print(\'accuracy\', total_accuracy / numImages)\n    return\n\nif __name__==\'__main__\':\n    """"""\n    Parse input arguments\n    """"""\n    parser = argparse.ArgumentParser(description=\'Planenet\')\n    parser.add_argument(\'--task\', dest=\'task\',\n                        help=\'task type\',\n                        default=\'layout\', type=str)\n    parser.add_argument(\'--numOutputPlanes\', dest=\'numOutputPlanes\',\n                        help=\'the number of output planes\',\n                        default=20, type=int)\n    parser.add_argument(\'--dataset\', dest=\'dataset\',\n                        help=\'dataset name\',\n                        default=\'NYU_RGBD\', type=str)\n    parser.add_argument(\'--hybrid\', dest=\'hybrid\',\n                        help=\'hybrid\',\n                        default=\'3\', type=str)\n    parser.add_argument(\'--visualizeImages\', dest=\'visualizeImages\',\n                        help=\'visualize image\',\n                        default=30, type=int)    \n    parser.add_argument(\'--numImages\', dest=\'numImages\',\n                        help=\'the number of images\',\n                        default=30, type=int)\n    parser.add_argument(\'--startIndex\', dest=\'startIndex\',\n                        help=\'start index\',\n                        default=0, type=int)    \n    parser.add_argument(\'--useCache\', dest=\'useCache\',\n                        help=\'use cache\',\n                        default=1, type=int)\n    # parser.add_argument(\'--useCRF\', dest=\'useCRF\',\n    #                     help=\'use crf\',\n    #                     default=0, type=int)\n    # parser.add_argument(\'--useSemantics\', dest=\'useSemantics\',\n    #                     help=\'use semantics\',\n    #                     default=0, type=int)\n    parser.add_argument(\'--useNonPlaneDepth\', dest=\'useNonPlaneDepth\',\n                        help=\'use non-plane depth\',\n                        default=0, type=int)\n    parser.add_argument(\'--imageIndex\', dest=\'imageIndex\',\n                        help=\'image index\',\n                        default=-1, type=int)\n    parser.add_argument(\'--methods\', dest=\'methods\',\n                        help=\'methods\',\n                        default=\'0123\', type=str)\n    parser.add_argument(\'--rootFolder\', dest=\'rootFolder\',\n                        help=\'root folder\',\n                        default=\'/mnt/vision/PlaneNet/\', type=str)\n    parser.add_argument(\'--suffix\', dest=\'suffix\',\n                        help=\'suffix\',\n                        default=\'\', type=str)\n    \n    args = parser.parse_args()\n    #args.hybrid = \'hybrid\' + args.hybrid\n    args.test_dir = \'evaluate/\' + args.task + \'/\' + args.dataset + \'/hybrid\' + args.hybrid + \'/\'\n    args.visualizeImages = args.numImages\n\n    # image = cv2.imread(\'evaluate/layout/ScanNet/hybrid3/22_image.png\')\n    # focal_length = estimateFocalLength(image)\n    # print(focal_length)\n    # exit(1)\n\n    if args.suffix == \'\':\n        getResults(args)\n    elif args.suffix == \'roomnet\':\n        testRoomNet(args)\n    else:\n        testRoomLayout(args)\n        pass\n'"
code/script.py,0,"b""import os\n\ndef resultsFigure():\n    #for image_index in [4, 10, 22, 23, 50, 53, 56, 58, 59, 67, 71, 73, 74, 90, 100, 118, 134, 145]:\n    #for image_index in [4, 13, 17, 27, 34, 42, 56, 57, 65, 66, 66, 90, 91, 100, 103, 136]:\n    for image_index in [3, 10, 17, 34, 43, 50, 71, 80, 97, 119, 125, 159, 174, 175, 184, 215, 220, 224, 256, 252, 253, 257, 259, 267]:    \n        command = 'python predict.py --methods=2 --numOutputPlanes=10 --useCache=1 --startIndex=' + str(int(image_index / 30) * 30) + ' --imageIndex=' + str(image_index) + ' --suffix=final'\n        os.system(command)\n        continue\n    return\n\n\ndef failureCases():\n    for image_index in [20, 21]:    \n        command = 'python predict.py --methods=2 --numOutputPlanes=10 --useCache=1 --startIndex=' + str(int(image_index / 30) * 30) + ' --imageIndex=' + str(image_index) + ' --suffix=failure'\n        os.system(command)\n        continue\n    return\n\n\nresultsFigure()\n#failureCases()\n"""
code/test_bernoulli.py,20,"b'# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Simple examples of the REINFORCE algorithm.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\n\ndistributions = tf.contrib.distributions\nsg = tf.contrib.bayesflow.stochastic_graph\nst = tf.contrib.bayesflow.stochastic_tensor\n\n\ndef split_apply_merge(inp, partitions, fns):\n  """"""Split input according to partitions.  Pass results through fns and merge.\n  Args:\n    inp: the input vector\n    partitions: tensor of same length as input vector, having values 0, 1\n    fns: the two functions.\n  Returns:\n    the vector routed, where routed[i] = fns[partitions[i]](inp[i])\n  """"""\n  new_inputs = tf.dynamic_partition(inp, partitions, len(fns))\n  new_outputs = [fns[i](x) for i, x in enumerate(new_inputs)]\n  new_indices = tf.dynamic_partition(\n      tf.range(0, inp.get_shape()[0]), partitions, len(fns))\n  return tf.dynamic_stitch(new_indices, new_outputs)\n\n\ndef plus_1(inputs):\n  return inputs + 1.0\n\n\ndef minus_1(inputs):\n  return inputs - 1.0\n\n\ndef build_split_apply_merge_model():\n  """"""Build the Split-Apply-Merge Model.\n  Route each value of input [-1, -1, 1, 1] through one of the\n  functions, plus_1, minus_1.  The decision for routing is made by\n  4 Bernoulli R.V.s whose parameters are determined by a neural network\n  applied to the input.  REINFORCE is used to update the NN parameters.\n  Returns:\n    The 3-tuple (route_selection, routing_loss, final_loss), where:\n      - route_selection is an int 4-vector\n      - routing_loss is a float 4-vector\n      - final_loss is a float scalar.\n  """"""\n  inputs = tf.constant([[-1.0], [-1.0], [1.0], [1.0]])\n  targets = tf.constant([[0.0], [0.0], [0.0], [0.0]])\n  paths = [plus_1, minus_1]\n  weights = tf.get_variable(""w"", [1, 2])\n  bias = tf.get_variable(""b"", [1, 1])\n  logits = tf.matmul(inputs, weights) + bias\n\n  # REINFORCE forward step\n  route_selection = st.StochasticTensor(\n      distributions.Categorical(logits=logits))\n\n  # Accessing route_selection as a Tensor below forces a sample of\n  # the Categorical distribution based on its logits.\n  # This is equivalent to calling route_selection.value().\n  #\n  # route_selection.value() returns an int32 4-vector with random\n  # values in {0, 1}\n  # COPY+ROUTE+PASTE\n  outputs = split_apply_merge(inputs, route_selection, paths)\n\n  # flatten routing_loss to a row vector (from a column vector)\n  routing_loss = tf.reshape(tf.square(outputs - targets), shape=[-1])\n\n  # Total loss: score function loss + routing loss.\n  # The score function loss (through `route_selection.loss(routing_loss)`)\n  # returns:\n  #  [stop_gradient(routing_loss) *\n  #   route_selection.log_pmf(stop_gradient(route_selection.value()))],\n  # where log_pmf has gradients going all the way back to weights and bias.\n  # In this case, the routing_loss depends on the variables only through\n  # ""route_selection"", which has a stop_gradient on it.  So the\n  # gradient of the loss really come through the score function\n  surrogate_loss = sg.surrogate_loss([routing_loss])\n  final_loss = tf.reduce_sum(surrogate_loss)\n\n  return (route_selection, routing_loss, final_loss)\n\n\nclass REINFORCESimpleExample(tf.test.TestCase):\n\n  def testSplitApplyMerge(self):\n    # Repeatability.  SGD has a tendency to jump around, even here.\n    tf.set_random_seed(1)\n\n    with self.test_session() as sess:\n      # Use sampling to train REINFORCE\n      with st.value_type(st.SampleValue()):\n        (route_selection,\n         routing_loss,\n         final_loss) = build_split_apply_merge_model()\n\n      sgd = tf.train.GradientDescentOptimizer(1.0).minimize(final_loss)\n\n      tf.global_variables_initializer().run()\n\n      for i in range(10):\n        # Run loss and inference step.  This toy problem converges VERY quickly.\n        (routing_loss_v, final_loss_v, route_selection_v, _) = sess.run(\n            [routing_loss, final_loss, tf.identity(route_selection), sgd])\n        print(\n            ""Iteration %d, routing loss: %s, final_loss: %s, ""\n            ""route selection: %s""\n            % (i, routing_loss_v, final_loss_v, route_selection_v))\n\n      self.assertAllEqual([0, 0, 1, 1], route_selection_v)\n      self.assertAllClose([0.0, 0.0, 0.0, 0.0], routing_loss_v)\n      self.assertAllClose(0.0, final_loss_v)\n\n\nif __name__ == ""__main__"":\n  tf.test.main()\n'"
code/test_sampling.py,21,"b""import tensorflow as tf\nimport numpy as np\n\nsg = tf.contrib.bayesflow.stochastic_graph\nst = tf.contrib.bayesflow.stochastic_tensor\n\ndef createModel(x):\n    f = tf.contrib.layers.fully_connected(x, 10)\n    y = tf.contrib.layers.fully_connected(f, 10, activation_fn=None)\n    c = tf.contrib.layers.fully_connected(f, 10, activation_fn=None)    \n    return y, c\n\ndef buildLoss(x, y, c):\n    selection = st.StochasticTensor(tf.contrib.distributions.Bernoulli(logits=c))\n    yc = y * tf.cast(selection, tf.float32)\n    #distr = tf.contrib.distributions.Bernoulli(logits = c)\n    #yc = y * tf.cast(tf.contrib.distributions.Bernoulli(probs = tf.sigmoid(c)).sample(), tf.float32)\n    #yc = tf.concat([x, x], axis=1) * tf.cast(tf.contrib.distributions.Bernoulli(probs = tf.sigmoid(c)).sample(), tf.float32)\n    #sparsity_loss = tf.reduce_mean(1 - tf.sigmoid(plane_confidence_pred)) * 100\n    \n    diff = tf.abs(tf.expand_dims(x, -1) - tf.expand_dims(yc, -2))\n    diff_loss = tf.reduce_mean(tf.reduce_min(diff, axis=-1), axis=1, keep_dims=True)\n    confidence_loss = tf.reduce_mean(tf.sigmoid(c))\n    #loss = diff_loss + confidence_loss\n    diff_loss = sg.surrogate_loss([diff_loss])\n    diff_loss = tf.reduce_mean(diff_loss)\n    loss = diff_loss * 100 + confidence_loss\n    #loss = tf.reduce_mean(sg.surrogate_loss([diff_loss])) + confidence_loss\n    return loss, diff_loss, confidence_loss, yc\n\nif __name__=='__main__':\n    batchSize = 16\n    with st.value_type(st.SampleValue()):\n    #with True:\n        x = tf.placeholder(tf.float32,shape=(batchSize, 5),name='x')\n        y, c = createModel(x)\n        loss, diff_loss, confidence_loss, yc = buildLoss(x, y, c)\n        pass\n    \n\n    optimizer = tf.train.AdamOptimizer(1e-4)\n    train_op = optimizer.minimize(loss)\n\n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n    with tf.Session() as sess:\n        sess.run(init_op)\n        for i in xrange(10000):\n            _, total_loss, loss_1, loss_2 = sess.run([train_op, loss, diff_loss, confidence_loss], feed_dict = {x: np.random.random((batchSize, 5))})\n            if i % 100 == 0:\n                print((total_loss, loss_1, loss_2))\n                pass\n            continue\n        _, total_loss, x_, y_, c_, yc_ = sess.run([train_op, loss, x, y, c, yc], feed_dict = {x: np.tile(np.expand_dims(np.arange(5) + 1, 0), [batchSize, 1])})\n        print(x_[0])\n        print(y_[0])\n        print(c_[0])\n        print(yc_[0])        \n        pass\n        \n"""
code/tf_nndistance.py,11,"b""import tensorflow as tf\nfrom tensorflow.python.framework import ops\nnn_distance_module=tf.load_op_library('./tf_nndistance_so.so')\n\ndef nn_distance(xyz1,xyz2):\n\t'''\nComputes the distance of nearest neighbors for a pair of point clouds\ninput: xyz1: (batch_size,#points_1,3)  the first point cloud\ninput: xyz2: (batch_size,#points_2,3)  the second point cloud\noutput: dist1: (batch_size,#point_1)   distance from first to second\noutput: idx1:  (batch_size,#point_1)   nearest neighbor from first to second\noutput: dist2: (batch_size,#point_2)   distance from second to first\noutput: idx2:  (batch_size,#point_2)   nearest neighbor from second to first\n\t'''\n        return nn_distance_module.nn_distance(xyz1,xyz2)\n#@tf.RegisterShape('NnDistance')\n#def _nn_distance_shape(op):\n\t#shape1=op.inputs[0].get_shape().with_rank(3)\n\t#shape2=op.inputs[1].get_shape().with_rank(3)\n\t#return [tf.TensorShape([shape1.dims[0],shape1.dims[1]]),tf.TensorShape([shape1.dims[0],shape1.dims[1]]),\n\t\t#tf.TensorShape([shape2.dims[0],shape2.dims[1]]),tf.TensorShape([shape2.dims[0],shape2.dims[1]])]\n@ops.RegisterGradient('NnDistance')\ndef _nn_distance_grad(op,grad_dist1,grad_idx1,grad_dist2,grad_idx2):\n\txyz1=op.inputs[0]\n\txyz2=op.inputs[1]\n\tidx1=op.outputs[1]\n\tidx2=op.outputs[3]\n\treturn nn_distance_module.nn_distance_grad(xyz1,xyz2,grad_dist1,idx1,grad_dist2,idx2)\n\n\nif __name__=='__main__':\n\timport numpy as np\n\timport random\n\timport time\n\tfrom tensorflow.python.ops.gradient_checker import compute_gradient\n\trandom.seed(100)\n\tnp.random.seed(100)\n\twith tf.Session('') as sess:\n\t\txyz1=np.random.randn(32,16384,3).astype('float32')\n\t\txyz2=np.random.randn(32,1024,3).astype('float32')\n\t\t#with tf.device('/gpu:0'):\n\t\tif True:\n\t\t\tinp1=tf.Variable(xyz1)\n\t\t\tinp2=tf.constant(xyz2)\n\t\t\treta,retb,retc,retd=nn_distance(inp1,inp2)\n\t\t\tloss=tf.reduce_sum(reta)+tf.reduce_sum(retc)\n\t\t\ttrain=tf.train.GradientDescentOptimizer(learning_rate=0.05).minimize(loss)\n\t\tsess.run(tf.global_variables_initializer())\n\t\tt0=time.time()\n\t\tt1=t0\n\t\tbest=1e100\n\t\tfor i in xrange(100):\n\t\t\ttrainloss,_=sess.run([loss,train])\n\t\t\tnewt=time.time()\n\t\t\tbest=min(best,newt-t1)\n\t\t\tprint i,trainloss,(newt-t0)/(i+1),best\n\t\t\tt1=newt\n\t\t#print sess.run([inp1,retb,inp2,retd])\n\t\t#grads=compute_gradient([inp1,inp2],[(16,32,3),(16,32,3)],loss,(1,),[xyz1,xyz2])\n\t\t#for i,j in grads:\n\t\t\t#print i.shape,j.shape,np.mean(np.abs(i-j)),np.mean(np.abs(i)),np.mean(np.abs(j))\n\t\t#for i in xrange(10):\n\t\t\t#t0=time.time()\n\t\t\t#a,b,c,d=sess.run([reta,retb,retc,retd],feed_dict={inp1:xyz1,inp2:xyz2})\n\t\t\t#print 'time',time.time()-t0\n\t\t#print a.shape,b.shape,c.shape,d.shape\n\t\t#print a.dtype,b.dtype,c.dtype,d.dtype\n\t\t#samples=np.array(random.sample(range(xyz2.shape[1]),100),dtype='int32')\n\t\t#dist1=((xyz1[:,samples,None,:]-xyz2[:,None,:,:])**2).sum(axis=-1).min(axis=-1)\n\t\t#idx1=((xyz1[:,samples,None,:]-xyz2[:,None,:,:])**2).sum(axis=-1).argmin(axis=-1)\n\t\t#print np.abs(dist1-a[:,samples]).max()\n\t\t#print np.abs(idx1-b[:,samples]).max()\n\t\t#dist2=((xyz2[:,samples,None,:]-xyz1[:,None,:,:])**2).sum(axis=-1).min(axis=-1)\n\t\t#idx2=((xyz2[:,samples,None,:]-xyz1[:,None,:,:])**2).sum(axis=-1).argmin(axis=-1)\n\t\t#print np.abs(dist2-c[:,samples]).max()\n\t\t#print np.abs(idx2-d[:,samples]).max()\n\n"""
code/train_finetuning.py,87,"b'import tensorflow as tf\nimport numpy as np\nnp.set_printoptions(precision=2, linewidth=200)\nimport cv2\nimport os\nimport time\nimport sys\nimport tf_nndistance\nimport argparse\nimport glob\nimport PIL\nimport scipy.ndimage as ndimage\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom utils import *\nfrom plane_utils import *\nfrom modules import *\n\n\nfrom planenet import PlaneNet\nfrom RecordReader import *\nfrom RecordReaderRGBD import *\nfrom RecordReader3D import *\nfrom RecordReaderAll import *\nfrom RecordReaderMake3D import *\n#from SegmentationRefinement import *\n\n#training_flag: toggle dropout and batch normalization mode\n#it\'s true for training and false for validation, testing, prediction\n#it also controls which data batch to use (*_train or *_val)\n\n\nfrom train_sample import build_graph as build_graph\n\n\ndef build_loss(img_inp_train, img_inp_val, global_pred_dict, deep_pred_dicts, global_gt_dict_train, global_gt_dict_val, training_flag, options):\n    with tf.device(\'/gpu:%d\'%options.gpu_id):\n        debug_dict = {}\n\n        img_inp = tf.cond(training_flag, lambda: img_inp_train, lambda: img_inp_val)\n        global_gt_dict = {}\n        for name in global_gt_dict_train.keys():\n            global_gt_dict[name] = tf.cond(training_flag, lambda: global_gt_dict_train[name], lambda: global_gt_dict_val[name])\n            continue\n        # local_gt_dict = {}\n        # for name in local_gt_dict_train.keys():\n        #     local_gt_dict[name] = tf.cond(tf.equal(training_flag % 2, 0), lambda: local_gt_dict_train[name], lambda: local_gt_dict_val[name])\n        #     continue\n\n        plane_parameters = tf.reshape(global_pred_dict[\'plane\'], (-1, 3))\n        info = global_gt_dict[\'info\'][0]\n        plane_depths = planeDepthsModule(plane_parameters, WIDTH, HEIGHT, info)\n        plane_depths = tf.transpose(tf.reshape(plane_depths, [HEIGHT, WIDTH, -1, options.numOutputPlanes]), [2, 0, 1, 3])\n\n        non_plane_depth = global_pred_dict[\'non_plane_depth\']\n        all_depths = tf.concat([plane_depths, non_plane_depth], axis=3)\n\n\n\n        #if options.predictPixelwise == 1:\n        validDepthMask = tf.cast(tf.greater(global_gt_dict[\'depth\'], 1e-4), tf.float32)\n        numValidPixels = tf.reduce_sum(validDepthMask, axis=[1, 2, 3])\n        depth_loss = tf.constant(0.0)\n        if True:\n            all_segmentations = tf.concat([global_pred_dict[\'segmentation\'], global_pred_dict[\'non_plane_mask\']], axis=3)\n            all_segmentations_softmax = tf.nn.softmax(all_segmentations)\n            depth_loss += tf.reduce_mean(tf.reduce_sum(tf.squared_difference(all_depths, global_gt_dict[\'depth\']) * all_segmentations_softmax, axis=3, keep_dims=True) * validDepthMask) * 10000\n        else:\n            depth_diff = global_pred_dict[\'non_plane_depth\'] - global_gt_dict[\'depth\']\n            depth_diff_gx = depth_diff - tf.concat([tf.ones([options.batchSize, HEIGHT, 1, 1]), depth_diff[:, :, :WIDTH - 1]], axis=2)\n            depth_diff_gy = depth_diff - tf.concat([tf.ones([options.batchSize, 1, WIDTH, 1]), depth_diff[:, :HEIGHT - 1]], axis=1)\n\n            depth_loss += tf.reduce_mean(tf.reduce_sum(tf.pow(depth_diff * validDepthMask, 2), axis=[1, 2, 3]) / numValidPixels - 0.5 * tf.pow(tf.reduce_sum(depth_diff * validDepthMask, axis=[1, 2, 3]) / numValidPixels, 2) + tf.reduce_sum((tf.pow(depth_diff_gx, 2) + tf.pow(depth_diff_gy, 2)) * validDepthMask, axis=[1, 2, 3]) / numValidPixels) * 1000\n            pass\n\n        #depth_loss += tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_depth\'], global_gt_dict[\'depth\']) * validDepthMask) * 10000\n\n\n        # valid_normal_mask = tf.squeeze(tf.cast(tf.less(tf.slice(global_gt_dict[\'info\'], [0, 19], [options.batchSize, 1]), 2), tf.float32))\n        # normal_gt = tf.nn.l2_normalize(global_gt_dict[\'normal\'], dim=-1)\n        # normal_loss = tf.reduce_mean(tf.reduce_sum(-global_pred_dict[\'non_plane_normal\'] * normal_gt * validDepthMask, axis=[1, 2, 3]) / numValidPixels * valid_normal_mask) * 1000\n        # #normal_loss = tf.reduce_mean(tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_normal\'], global_gt_dict[\'normal\']) * validDepthMask, axis=[1, 2, 3]) * valid_normal_mask) * 1000\n        # valid_semantics_mask = tf.squeeze(tf.cast(tf.not_equal(tf.slice(global_gt_dict[\'info\'], [0, 19], [options.batchSize, 1]), 1), tf.float32))\n        # semantics_loss = tf.reduce_mean(tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=global_pred_dict[\'semantics\'], labels=global_gt_dict[\'semantics\']), axis=[1, 2]) * valid_semantics_mask) * 1000\n\n        normal_loss = tf.constant(0.0)\n        semantics_loss = tf.constant(0.0)\n\n        l2_losses = tf.add_n([options.l2Weight * tf.nn.l2_loss(v) for v in tf.trainable_variables() if \'weights\' in v.name])\n\n\n        loss = depth_loss + l2_losses\n\n        #if options.pixelwiseLoss:\n        #normal_loss = tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_normal\'], global_gt_dict[\'normal\'])) * 1000\n        #depth_loss = tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_depth\'], global_gt_dict[\'depth\']) * validDepthMask) * 1000\n        #pass\n\n        loss_dict = {\'depth\': depth_loss, \'normal\': normal_loss, \'semantics\': semantics_loss}\n        pass\n    return loss, loss_dict, debug_dict\n\n\ndef main(options):\n    if not os.path.exists(options.checkpoint_dir):\n        os.system(""mkdir -p %s""%options.checkpoint_dir)\n        pass\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n\n    min_after_dequeue = 1000\n\n\n    train_inputs = []\n    val_inputs = []\n    if \'0\' in options.hybrid:\n        train_inputs.append(options.rootFolder + \'/planes_SUNCG_train.tfrecords\')\n        val_inputs.append(options.rootFolder + \'/planes_SUNCG_val.tfrecords\')\n        pass\n    if \'1\' in options.hybrid:\n        for _ in xrange(10):\n            train_inputs.append(options.rootFolder + \'/planes_nyu_rgbd_train.tfrecords\')\n            train_inputs.append(options.rootFolder + \'/planes_nyu_rgbd_labeled_train.tfrecords\')\n            val_inputs.append(options.rootFolder + \'/planes_nyu_rgbd_val.tfrecords\')\n            continue\n        pass\n    if \'2\' in options.hybrid:\n        train_inputs.append(options.rootFolder + \'/planes_matterport_train.tfrecords\')\n        val_inputs.append(options.rootFolder + \'/planes_matterport_val.tfrecords\')\n        pass\n    if \'3\' in options.hybrid:\n        train_inputs.append(options.rootFolder + \'/planes_scannet_train.tfrecords\')\n        val_inputs.append(options.rootFolder + \'/planes_scannet_val.tfrecords\')\n        pass\n    if \'4\' in options.hybrid:\n        train_inputs.append(options.rootFolder + \'/planes_scannet_train.tfrecords\')\n        val_inputs.append(options.rootFolder + \'/planes_scannet_val.tfrecords\')\n        pass\n\n    if \'4\' not in options.hybrid:\n        reader_train = RecordReaderAll()\n        reader_val = RecordReaderAll()\n    else:\n        reader_train = RecordReaderMake3D()\n        reader_val = RecordReaderMake3D()\n        pass\n\n    filename_queue_train = tf.train.string_input_producer(train_inputs, num_epochs=10000)\n    img_inp_train, global_gt_dict_train, local_gt_dict_train = reader_train.getBatch(filename_queue_train, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True)\n    filename_queue_val = tf.train.string_input_producer(val_inputs, num_epochs=10000)\n    img_inp_val, global_gt_dict_val, local_gt_dict_val = reader_val.getBatch(filename_queue_val, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True)\n\n\n    training_flag = tf.placeholder(tf.bool, shape=[], name=\'training_flag\')\n\n    #global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp_train, img_inp_val, img_inp_rgbd_train, img_inp_rgbd_val, img_inp_3d_train, img_inp_3d_val, training_flag, options)\n    global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp_train, img_inp_val, training_flag, options)\n\n\n    #loss, loss_dict, _ = build_loss(global_pred_dict, local_pred_dict, deep_pred_dicts, global_gt_dict_train, local_gt_dict_train, global_gt_dict_val, local_gt_dict_val, training_flag, options)\n    #loss_rgbd, loss_dict_rgbd, _ = build_loss_rgbd(global_pred_dict, deep_pred_dicts, global_gt_dict_rgbd_train, global_gt_dict_rgbd_val, training_flag, options)\n    loss, loss_dict, _ = build_loss(img_inp_train, img_inp_val, global_pred_dict, deep_pred_dicts, global_gt_dict_train, global_gt_dict_val, training_flag, options)\n\n    #loss = tf.cond(tf.less(training_flag, 2), lambda: loss, lambda: tf.cond(tf.less(training_flag, 4), lambda: loss_rgbd, lambda: loss_3d))\n\n\n    #train_writer = tf.summary.FileWriter(options.log_dir + \'/train\')\n    #val_writer = tf.summary.FileWriter(options.log_dir + \'/val\')\n    #train_writer_rgbd = tf.summary.FileWriter(options.log_dir + \'/train_rgbd\')\n    #val_writer_rgbd = tf.summary.FileWriter(options.log_dir + \'/val_rgbd\')\n    #writers = [train_writer, val_writer, train_writer_rgbd, val_writer_rgbd]\n\n\n    with tf.variable_scope(\'statistics\'):\n        batchno = tf.Variable(0, dtype=tf.int32, trainable=False, name=\'batchno\')\n        batchnoinc=batchno.assign(batchno+1)\n        pass\n\n\n    optimizer = tf.train.AdamOptimizer(options.LR)\n    train_op = optimizer.minimize(loss, global_step=batchno)\n\n    var_to_restore = [v for v in tf.global_variables()]\n\n    tf.summary.scalar(\'loss\', loss)\n    summary_op = tf.summary.merge_all()\n\n\n    config=tf.ConfigProto()\n    config.allow_soft_placement=True\n    #config.gpu_options.allow_growth=True\n    config.gpu_options.per_process_gpu_memory_fraction=0.9\n    saver=tf.train.Saver()\n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n        if options.restore == 0:\n            #fine-tune from DeepLab model\n            var_to_restore = [v for v in var_to_restore if \'res5d\' not in v.name and \'segmentation\' not in v.name and \'plane\' not in v.name and \'deep_supervision\' not in v.name and \'local\' not in v.name and \'boundary\' not in v.name and \'degridding\' not in v.name and \'res2a_branch2a\' not in v.name and \'res2a_branch1\' not in v.name and \'Adam\' not in v.name and \'beta\' not in v.name and \'statistics\' not in v.name and \'semantics\' not in v.name]\n            pretrained_model_loader = tf.train.Saver(var_to_restore)\n            pretrained_model_loader.restore(sess,""../pretrained_models/deeplab_resnet.ckpt"")\n        elif options.restore == 1:\n            #restore the same model from checkpoint\n            loader = tf.train.Saver(var_to_restore)\n            loader.restore(sess,""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n            bno=sess.run(batchno)\n            print(bno)\n        elif options.restore == 2:\n            #restore the same model from checkpoint but reset batchno to 1\n            loader = tf.train.Saver(var_to_restore)\n            loader.restore(sess,""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n            sess.run(batchno.assign(1))\n        elif options.restore == 3:\n            #restore the same model from standard training\n            # if options.predictBoundary == 1:\n            #     var_to_restore = [v for v in var_to_restore if \'boundary\' not in v.name]\n            #     pass\n            # if options.predictConfidence == 1:\n            #     var_to_restore = [v for v in var_to_restore if \'confidence\' not in v.name]\n            #     pass\n            if options.predictSemantics == 1:\n                var_to_restore = [v for v in var_to_restore if \'semantics\' not in v.name]\n                pass\n            loader = tf.train.Saver(var_to_restore)\n            #loader.restore(sess, options.rootFolder + \'/checkpoint/planenet_hybrid\' + hybrid + \'_bl0_ll1_bw0.5_pb_pp_ps_sm0/checkpoint.ckpt\')\n            #loader.restore(sess, options.rootFolder + \'/checkpoint/planenet_hybrid3_bl0_dl0_ll1_pb_pp_sm0/checkpoint.ckpt\')\n            loader.restore(sess, options.rootFolder + \'/checkpoint/sample_np10_hybrid3_bl0_dl0_hl2_ds0_crfrnn5_sm0/checkpoint.ckpt\')\n            #loader.restore(sess,""checkpoint/planenet/checkpoint.ckpt"")\n            sess.run(batchno.assign(1))\n        elif options.restore == 4:\n            #fine-tune another model\n            #var_to_restore = [v for v in var_to_restore if \'res4b22_relu_non_plane\' not in v.name]\n            loader = tf.train.Saver(var_to_restore)\n            loader.restore(sess, options.fineTuningCheckpoint)\n            sess.run(batchno.assign(1))\n            pass\n        # Start input enqueue threads.\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n        MOVING_AVERAGE_DECAY = 0.99\n        ema = [0., 0., 0., 0.]\n        ema_acc = [1e-10, 1e-10, 1e-10, 1e-10]\n        last_snapshot_time = time.time()\n        bno=sess.run(batchno)\n\n        try:\n            while bno<300000:\n                t0 = time.time()\n\n                batchIndexPeriod = bno % 100\n                if batchIndexPeriod < len(options.hybrid):\n                    #batchType = int(options.hybrid[batchIndexPeriod]) * 2 + 1\n                    batchType = 1\n                    _, total_loss, losses, summary_str, gt_dict = sess.run([batchnoinc, loss, loss_dict, summary_op, global_pred_dict], feed_dict = {training_flag: batchType == 0})\n\n                else:\n                    batchType = 0\n                    _, total_loss, losses, summary_str, gt_dict = sess.run([train_op, loss, loss_dict, summary_op, global_pred_dict], feed_dict = {training_flag: batchType == 0})\n                    pass\n\n                # for batchIndex in xrange(options.batchSize):\n                #     if np.isnan(global_gt[\'plane\'][batchIndex]).any():\n                #         #print(losses)\n                #         #print(global_gt[\'plane\'][batchIndex])\n                #         print(global_gt[\'num_planes\'][batchIndex])\n                #         for planeIndex in xrange(global_gt[\'num_planes\'][batchIndex]):\n                #             cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(global_gt[\'segmentation\'][batchIndex, :, :, planeIndex]))\n                #             continue\n                #         np.save(\'temp/plane.npy\', global_gt[\'plane\'][batchIndex])\n                #         np.save(\'temp/depth.npy\', global_gt[\'depth\'][batchIndex])\n                #         np.save(\'temp/segmentation.npy\', global_gt[\'segmentation\'][batchIndex])\n                #         np.save(\'temp/info.npy\', global_gt[\'info\'][batchIndex])\n                #         np.save(\'temp/num_planes.npy\', global_gt[\'num_planes\'][batchIndex])\n                #         planes, segmentation, numPlanes = removeSmallSegments(global_gt[\'plane\'][batchIndex], np.zeros((HEIGHT, WIDTH, 3)), global_gt[\'depth\'][batchIndex].squeeze(), np.zeros((HEIGHT, WIDTH, 3)), np.argmax(global_gt[\'segmentation\'][batchIndex], axis=-1), global_gt[\'semantics\'][batchIndex], global_gt[\'info\'][batchIndex], global_gt[\'num_planes\'][batchIndex])\n                #         print(planes)\n                #         exit(1)\n                #         pass\n                #     continue\n                #writers[batchType].add_summary(summary_str, bno)\n                ema[batchType] = ema[batchType] * MOVING_AVERAGE_DECAY + total_loss\n                ema_acc[batchType] = ema_acc[batchType] * MOVING_AVERAGE_DECAY + 1\n\n                bno = sess.run(batchno)\n                if time.time()-last_snapshot_time > options.saveInterval:\n                    print(\'save snapshot\')\n                    saver.save(sess,\'%s/checkpoint.ckpt\'%options.checkpoint_dir)\n                    last_snapshot_time = time.time()\n                    pass\n\n                print bno,\'train\', ema[0] / ema_acc[0], \'val\', ema[1] / ema_acc[1], \'train rgbd\', ema[2] / ema_acc[2], \'val rgbd\', ema[3] / ema_acc[3], \'loss\', total_loss, \'time\', time.time()-t0\n\n                if np.random.random() < 0.01:\n                    print(losses)\n                    pass\n                continue\n\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n\n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return\n\n\ndef test(options):\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n\n    if options.dataset == \'\':\n        assert(len(options.hybrid) == 1)\n        if options.hybrid == \'0\':\n            options.dataset = \'SUNCG\'\n        elif options.hybrid == \'1\':\n            options.dataset = \'NYU_RGBD\'\n        elif options.hybrid == \'2\':\n            options.dataset = \'matterport\'\n        elif options.hybrid == \'3\':\n            options.dataset = \'ScanNet\'\n\n        options.dataset\n    options.batchSize = 1\n    min_after_dequeue = 1000\n\n    reader = RecordReaderAll()\n    if options.dataset == \'SUNCG\':\n        filename_queue = tf.train.string_input_producer([options.rootFolder + \'/planes_SUNCG_val.tfrecords\'], num_epochs=10000)\n    elif options.dataset == \'NYU_RGBD\':\n        filename_queue = tf.train.string_input_producer([options.rootFolder + \'/planes_nyu_rgbd_val.tfrecords\'], num_epochs=1)\n        options.deepSupervision = 0\n        options.predictLocal = 0\n    elif options.dataset == \'matterport\':\n        filename_queue = tf.train.string_input_producer([options.rootFolder + \'/planes_matterport_val.tfrecords\'], num_epochs=1)\n    else:\n        filename_queue = tf.train.string_input_producer([options.rootFolder + \'/planes_scannet_train.tfrecords\'], num_epochs=1)\n        pass\n    img_inp, global_gt_dict, local_gt_dict = reader.getBatch(filename_queue, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True, random=False)\n\n    training_flag = tf.constant(False, tf.bool)\n\n    global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp, img_inp, global_gt_dict, training_flag, options)\n    var_to_restore = tf.global_variables()\n\n    loss, loss_dict, debug_dict = build_loss(img_inp, img_inp, global_pred_dict, deep_pred_dicts, global_gt_dict, global_gt_dict, training_flag, options)\n\n\n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n        #var_to_restore = [v for v in var_to_restore if \'res4b22_relu_non_plane\' not in v.name]\n        loader = tf.train.Saver(var_to_restore)\n        loader.restore(sess, ""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n        #loader.restore(sess, ""%s/checkpoint.ckpt""%(\'checkpoint/planenet_pb_pp_hybrid1\'))\n        #loader.restore(sess, options.fineTuningCheckpoint)\n\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n\n        try:\n            gtDepths = []\n            predDepths = []\n            planeMasks = []\n            #predMasks = []\n            gtPlanes = []\n            predPlanes = []\n            gtSegmentations = []\n            predSegmentations = []\n            gtNumPlanes = []\n\n            imageWidth = WIDTH\n            imageHeight = HEIGHT\n            focalLength = 517.97\n            urange = np.arange(imageWidth).reshape(1, -1).repeat(imageHeight, 0) - imageWidth * 0.5\n            vrange = np.arange(imageHeight).reshape(-1, 1).repeat(imageWidth, 1) - imageHeight * 0.5\n            ranges = np.array([urange / imageWidth * 640 / focalLength, np.ones(urange.shape), -vrange / imageHeight * 480 / focalLength]).transpose([1, 2, 0])\n\n\n            for index in xrange(10):\n                print((\'image\', index))\n                t0=time.time()\n\n                img, global_gt, local_gt, global_pred, local_pred, deep_preds, total_loss, losses, debug = sess.run([img_inp, global_gt_dict, local_gt_dict, global_pred_dict, local_pred_dict, deep_pred_dicts, loss, loss_dict, debug_dict])\n\n                # print(options.test_dir)\n                # cv2.imwrite(options.test_dir + \'/depth.png\', drawDepthImage(debug[\'depth\'][0]))\n                # cv2.imwrite(options.test_dir + \'/normal.png\', drawNormalImage(debug[\'normal\'][0]))\n                # boundary = debug[\'boundary\'][0]\n                # boundary = np.concatenate([boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)\n                # cv2.imwrite(options.test_dir + \'/boundary.png\', drawMaskImage(boundary))\n                # cv2.imwrite(options.test_dir + \'/depth_gt.png\', drawDepthImage(debug[\'depth_gt\'][0].squeeze()))\n                # exit(1)\n\n                if \'pixelwise\' in options.suffix or True:\n                    image = ((img[0] + 0.5) * 255).astype(np.uint8)\n                    gt_d = global_gt[\'depth\'].squeeze()\n                    pred_d = global_pred[\'non_plane_depth\'].squeeze()\n                    #depth = global_gt[\'depth\'].squeeze()\n                    if \'_2\' in options.suffix:\n                        pred_p, pred_s, pred_d = fitPlanes(pred_d, numPlanes=20, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=0.2)\n                    elif \'_3\' in options.suffix:\n                        pred_p, pred_s, pred_d = fitPlanes(gt_d, numPlanes=20, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=0.2)\n                        pass\n\n                    # gt_p = global_gt[\'plane\'][0]\n                    # pred_p = planes\n                    # valid_mask = (np.linalg.norm(gt_p, axis=1) > 0).astype(np.float32)\n                    # diff = np.min(np.linalg.norm(np.expand_dims(gt_p, 1) - np.expand_dims(pred_p, 0), axis=2), 1)\n                    # num += valid_mask.sum()\n                    # lossSum += (diff * valid_mask).sum()\n                    if options.dataset == \'SUNCG\':\n                        planeMask = np.squeeze(debug[\'segmentation\']).sum(axis=2)\n                    else:\n                        planeMask = np.ones((HEIGHT, WIDTH))\n                        if \'_2\' in options.suffix or \'_3\' in options.suffix:\n                            planeMask *= (pred_s < 20).astype(np.float32)\n                        pass\n\n                    if index < 10:\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', image)\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth.png\', drawDepthImage(gt_d))\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n                        if \'_2\' in options.suffix or \'_3\' in options.suffix:\n                            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(pred_s))\n                            pass\n                        #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_plane_mask.png\', drawMaskImage(planeMask))\n                        pass\n\n\n                    gtDepths.append(gt_d)\n                    predDepths.append(pred_d)\n                    planeMasks.append(planeMask)\n\n\n                    if options.dataset != \'NYU_RGBD\' and (\'_2\' in options.suffix or \'_3\' in options.suffix):\n                        gt_p = global_gt[\'plane\'][0]\n                        gt_s = global_gt[\'segmentation\'][0]\n                        gt_num_p = global_gt[\'num_planes\'][0]\n\n                        pred_s = (np.expand_dims(pred_s, -1) == np.reshape(np.arange(options.numOutputPlanes), [1, 1, -1])).astype(np.float32)\n                        gtPlanes.append(gt_p)\n                        predPlanes.append(pred_p)\n                        gtSegmentations.append(gt_s)\n                        gtNumPlanes.append(gt_num_p)\n                        predSegmentations.append(pred_s)\n                        pass\n\n                    #planeMasks.append((planeSegmentation < 20).astype(np.float32))\n                    continue\n\n                print(losses)\n                print(total_loss)\n                #print(losses)\n                #exit(1)\n                im = img[0]\n                image = ((im + 0.5) * 255).astype(np.uint8)\n\n                gt_d = global_gt[\'depth\'].squeeze()\n\n\n                if options.predictLocal:\n                    pred_local_s = 1 / (1 + np.exp(-local_pred[\'score\'][0]))\n                    pred_local_p = local_pred[\'plane\'][0]\n                    pred_local_m = local_pred[\'mask\'][0]\n\n                    gt_local_s = local_gt[\'score\'][0]\n                    gt_local_m = local_gt[\'mask\'][0]\n\n                    #visualize local plane prediction\n                    stride = 8\n                    boxSize = 64\n                    xs = np.arange(WIDTH / stride) * stride + stride / 2\n                    ys = np.arange(HEIGHT / stride) * stride + stride / 2\n                    padding = boxSize / 2 + 1\n                    maskImage = np.zeros((HEIGHT + padding * 2, WIDTH + padding * 2, 3), dtype=np.uint8)\n                    maskImage[padding:padding + HEIGHT, padding:padding + WIDTH, :] = image / 2\n                    for gridY, y in enumerate(ys):\n                        for gridX, x in enumerate(xs):\n                            score = pred_local_s[gridY][gridX]\n                            if score < 0.5:\n                                continue\n                            mask = pred_local_m[gridY][gridX].reshape([16, 16])\n                            mask = cv2.resize(mask, (boxSize, boxSize))\n                            maskImage[y - boxSize / 2 + padding:y + boxSize / 2 + padding, x - boxSize / 2 + padding:x + boxSize / 2 + padding, 0][mask > 0.5] = 255\n                            continue\n                        continue\n                    for gridY, y in enumerate(ys):\n                        for gridX, x in enumerate(xs):\n                            score = gt_local_s[gridY][gridX]\n                            if score < 0.5:\n                                continue\n                            mask = gt_local_m[gridY][gridX].reshape([16, 16])\n                            mask = cv2.resize(mask, (boxSize, boxSize))\n                            maskImage[y - boxSize / 2 + padding:y + boxSize / 2 + padding, x - boxSize / 2 + padding:x + boxSize / 2 + padding, 2][mask > 0.5] = 255\n                            continue\n                        continue\n                    pass\n\n                pred_p = global_pred[\'plane\'][0]\n                pred_s = global_pred[\'segmentation\'][0]\n\n                pred_np_m = global_pred[\'non_plane_mask\'][0]\n                pred_np_d = global_pred[\'non_plane_depth\'][0]\n                pred_np_n = global_pred[\'non_plane_normal\'][0]\n\n                planeMask = 1 - global_gt[\'non_plane_mask\'][0]\n                info = global_gt[\'info\'][0]\n\n\n                all_segmentations = np.concatenate([pred_s, pred_np_m], axis=2)\n                all_segmentations_softmax = softmax(all_segmentations)\n                segmentation = np.argmax(all_segmentations, 2)\n\n\n                #pred_p, segmentation, numPlanes = mergePlanes(global_gt[\'plane\'][0], np.concatenate([global_gt[\'segmentation\'][0], global_gt[\'non_plane_mask\'][0]], axis=2), global_gt[\'depth\'][0].squeeze(), global_gt[\'info\'][0], np.concatenate([pred_s, pred_np_m], axis=2))\n\n\n                plane_depths = calcPlaneDepths(pred_p, WIDTH, HEIGHT, info)\n                all_depths = np.concatenate([plane_depths, pred_np_d], axis=2)\n\n                pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape(HEIGHT, WIDTH)\n\n                plane_normals = calcPlaneNormals(pred_p, WIDTH, HEIGHT)\n                all_normals = np.concatenate([plane_normals, np.expand_dims(pred_np_n, 2)], axis=2)\n                pred_n = np.sum(all_normals * np.expand_dims(one_hot(segmentation, options.numOutputPlanes+1), -1), 2)\n                #pred_n = all_normals.reshape(-1, options.numOutputPlanes + 1, 3)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape((HEIGHT, WIDTH, 3))\n\n\n                if False:\n                    gt_s = global_gt[\'segmentation\'][0]\n                    all_segmentations = np.concatenate([gt_s, 1 - planeMask], axis=2)\n                    gt_p = global_gt[\'plane\'][0]\n\n                    # valid_mask = (np.linalg.norm(gt_p, axis=1) > 0).astype(np.float32)\n                    # diff = np.min(np.linalg.norm(np.expand_dims(gt_p, 1) - np.expand_dims(pred_p, 0), axis=2), 1)\n                    # num += valid_mask.sum()\n                    # lossSum += (diff * valid_mask).sum()\n                    #gt_p = np.stack([-gt_p[:, 0], -gt_p[:, 2], -gt_p[:, 1]], axis=1)\n\n                    plane_depths = calcPlaneDepths(gt_p, WIDTH, HEIGHT, info)\n                    all_depths = np.concatenate([plane_depths, pred_np_d], axis=2)\n\n                    segmentation = np.argmax(all_segmentations, 2)\n                    pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape(HEIGHT, WIDTH)\n                    # print(gt_p)\n                    # for segmentIndex in xrange(options.numOutputPlanes):\n                    #     cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_mask_\' + str(segmentIndex) + \'.png\', drawMaskImage(segmentation == segmentIndex))\n                    #     continue\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n                    #exit(1)\n                    pass\n\n\n\n                gt_p = global_gt[\'plane\'][0]\n                gt_s = global_gt[\'segmentation\'][0]\n                gt_num_p = global_gt[\'num_planes\'][0]\n                gtPlanes.append(gt_p)\n                predPlanes.append(pred_p)\n                gtSegmentations.append(gt_s)\n                gtNumPlanes.append(gt_num_p)\n                predSegmentations.append(pred_s)\n\n\n                gtDepths.append(gt_d)\n                planeMasks.append(planeMask.squeeze())\n                predDepths.append(pred_d)\n                evaluateDepths(predDepths[-1], gtDepths[-1], gtDepths[-1] > 0, planeMasks[-1])\n\n\n                if index >= 10:\n                    continue\n\n                if options.predictSemantics:\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_semantics_pred.png\', drawSegmentationImage(global_pred[\'semantics\'][0], blackIndex=0))\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_semantics_gt.png\', drawSegmentationImage(global_gt[\'semantics\'][0], blackIndex=0))\n                    pass\n\n                if \'cost_mask\' in debug:\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_cost_mask.png\', drawMaskImage(np.sum(debug[\'cost_mask\'][0], axis=-1)))\n\n                    for planeIndex in xrange(options.numOutputPlanes + 1):\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_cost_mask_\' + str(planeIndex) + \'.png\', drawMaskImage(debug[\'cost_mask\'][0, :, :, planeIndex]))\n                        continue\n                    all_segmentations = np.concatenate([pred_s, pred_np_m], axis=2)\n                    for planeIndex in xrange(options.numOutputPlanes + 1):\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred_\' + str(planeIndex) + \'.png\', drawMaskImage(all_segmentations[:, :, planeIndex]))\n                        continue\n                    exit(1)\n                    pass\n\n                if \'normal\' in global_gt:\n                    gt_n = global_gt[\'normal\'][0]\n                    norm = np.linalg.norm(gt_n, axis=-1, keepdims=True)\n                    gt_n /= np.maximum(norm, 1e-4)\n\n                    #gt_n = np.stack([-gt_n[:, :, 0], -gt_n[:, :, 2], -gt_n[:, :, 1]], axis=2)\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_gt.png\', drawNormalImage(gt_n))\n                    #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_pred.png\', drawNormalImage(pred_np_n))\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_pred.png\', drawNormalImage(pred_n))\n                    pass\n\n                if \'segmentation\' in global_gt:\n                    gt_s = global_gt[\'segmentation\'][0]\n                    gt_p = global_gt[\'plane\'][0]\n\n\n                    #for planeIndex in xrange(20):\n                    #cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(gt_s[:, :, planeIndex]))\n                    #continue\n\n\n                    # print(gt_p)\n                    # print(gt_n[109][129])\n                    # print(gt_n[166][245])\n                    # print(gt_s[109][129])\n                    # print(gt_s[166][245])\n                    # print(plane_normals[109][129])\n                    # print(plane_normals[166][245])\n                    # for planeIndex in xrange(20):\n                    #     cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(gt_s[:, :, planeIndex]))\n                    #     continue\n                    # exit(1)\n\n                    gt_s, gt_p = sortSegmentations(gt_s, gt_p, pred_p)\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_plane_mask_gt.png\', drawMaskImage(planeMask))\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_gt.png\', drawSegmentationImage(np.concatenate([gt_s, 1 - planeMask], axis=2), blackIndex=options.numOutputPlanes)\n)\n                    #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_test.png\', drawMaskImage(np.sum(np.concatenate([gt_s, 1 - planeMask], axis=2), axis=2)))\n                    #exit(1)\n                    #exit(1)\n                    pass\n\n\n                if options.predictConfidence == 1 and options.dataset == \'SUNCG\':\n                    assert(False)\n                    pred_p_c = global_pred[\'confidence\'][0]\n                    pred_p_c = 1 / (1 + np.exp(-pred_p_c))\n                    #print(pred_p_c)\n                    # print(losses)\n                    # print(debug[\'plane\'][0])\n                    # print(pred_p)\n                    # exit(1)\n                    numPlanes = global_gt[\'num_planes\'][0]\n                    print((numPlanes, (pred_p_c > 0.5).sum()))\n\n                    pred_p_c = (pred_p_c > 0.5).astype(np.float32)\n                    pred_p *= pred_p_c\n                    pred_s -= (1 - pred_p_c.reshape([1, 1, options.numOutputPlanes])) * 10\n                    pass\n\n                if False:\n                    #dump results for post processing\n                    if index >= 10:\n                        break\n                    np.save(options.dump_dir + \'/planes_\' + str(index) + \'.npy\', pred_p)\n                    np.save(options.dump_dir + \'/segmentations_\' + str(index) + \'.npy\', pred_s)\n                    np.save(options.dump_dir + \'/segmentations_gt_\' + str(index) + \'.npy\', gt_s)\n                    np.save(options.dump_dir + \'/non_plane_depth_\' + str(index) + \'.npy\', pred_np_d)\n                    np.save(options.dump_dir + \'/non_plane_segmentation_\' + str(index) + \'.npy\', pred_np_m)\n                    boundary = pred_boundary[0]\n                    boundary = 1 / (1 + np.exp(-boundary))\n                    boundary = np.concatenate([boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)\n                    cv2.imwrite(options.dump_dir + \'/boundary_\' + str(index) + \'.png\', drawMaskImage(boundary))\n                    cv2.imwrite(options.dump_dir + \'/image_\' + str(index) + \'.png\', cv2.resize(image, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR))\n                    np.save(options.dump_dir + \'/depth_\' + str(index) + \'.npy\', gt_d)\n                    continue\n\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', image)\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth.png\', drawDepthImage(gt_d))\n                #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_overlay.png\', drawDepthImageOverlay(image, gt_d))\n\n                if options.predictBoundary:\n                    pred_boundary = global_pred[\'boundary\'][0]\n                    pred_boundary = 1 / (1 + np.exp(-pred_boundary))\n                    boundary = np.concatenate([pred_boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_boundary_pred.png\', drawMaskImage(boundary))\n                    pass\n\n                if \'boundary\' in global_gt:\n                    gt_boundary = global_gt[\'boundary\'][0]\n                    boundary = np.concatenate([gt_boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_boundary_gt.png\', drawMaskImage(boundary))\n                    pass\n\n                for layerIndex, layer in enumerate(options.deepSupervisionLayers):\n                    segmentation_deep = np.argmax(deep_preds[layerIndex][\'segmentation\'][0], 2)\n                    segmentation_deep[segmentation_deep == options.numOutputPlanes] = -1\n                    segmentation_deep += 1\n\n                    plane_depths_deep = calcPlaneDepths(deep_preds[layerIndex][\'plane\'][0], WIDTH, HEIGHT, info)\n                    all_depths_deep = np.concatenate([pred_np_d, plane_depths_deep], axis=2)\n                    pred_d_deep = all_depths_deep.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation_deep.reshape(-1)].reshape(HEIGHT, WIDTH)\n\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred_\' + str(layerIndex) + \'.png\', drawSegmentationImage(deep_preds[layerIndex][\'segmentation\'][0]))\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred_\' + str(layerIndex) + \'.png\', drawDepthImage(pred_d_deep))\n                    pass\n\n\n                #print(pred_np_m)\n                #print(pred_s)\n                #print(global_gt[\'plane\'][0])\n                #print(pred_p)\n                #exit(1)\n\n                print(\'depth diff\', np.abs(pred_d - gt_d).mean())\n\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(all_segmentations, blackIndex=options.numOutputPlanes))\n                #exit(1)\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_diff.png\', drawMaskImage(np.abs(pred_d - gt_d) * planeMask.squeeze() / 0.2))\n                #exit(1)\n\n\n                #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_plane_mask.png\', drawMaskImage(planeMask))\n\n                #print(np.concatenate([np.arange(options.numOutputPlanes).reshape(-1, 1), planes, pred_p, preds_p[0][0]], axis=1))\n\n                #print(np.concatenate([distance[0], preds_p[0][0], pred_p], axis=1))\n\n                #segmentation = np.argmax(pred_s, 2)\n                #writePLYFile(options.test_dir, index, image, pred_d, segmentation, np.zeros(pred_boundary[0].shape))\n                #writePLYFileParts(options.test_dir, index, image, pred_d, segmentation)\n                #gt_s_ori = gt_s_ori[0]\n\n\n                # if \'depth\' in debug:\n                #     cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred_1.png\', drawDepthImage(debug[\'depth\'][0]))\n                #     gt_s_ori = debug[\'segmentation\'][0]\n                #     cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_gt.png\', drawSegmentationImage(gt_s_ori, blackIndex=options.numOutputPlanes))\n                #     total_loss = 0\n                #     for planeIndex in xrange(gt_s_ori.shape[-1]):\n                #         mask_pred = all_segmentations_softmax[:, :, planeIndex]\n                #         loss = -(gt_s_ori[:, :, planeIndex] * np.log(np.maximum(all_segmentations_softmax[:, :, planeIndex], 1e-31))).mean() * 1000\n                #         print(planeIndex, loss)\n                #         total_loss += loss\n                #         cv2.imwrite(options.test_dir + \'/mask_pred_\' + str(planeIndex) + \'.png\', drawMaskImage(mask_pred))\n                #         cv2.imwrite(options.test_dir + \'/mask_gt_\' + str(planeIndex) + \'.png\', drawMaskImage(gt_s_ori[:, :, planeIndex]))\n                #         continue\n                #     print(total_loss)\n                #     print(gt_s_ori.sum(2).max())\n                #     exit(1)\n                #     pass\n\n\n                if False:\n                    #distance = distance[0]\n                    print(distance)\n                    diff = np.linalg.norm(np.expand_dims(planes, 1) - np.expand_dims(pred_p, 0), axis=2)\n                    print(np.concatenate([planes, pred_p, pow(np.min(diff, axis=1, keepdims=True), 2), np.expand_dims(np.argmin(diff, axis=1), -1)], axis=1))\n                    print(pred_p_c)\n\n                    #print(distance[:, 6:8].sum(0))\n                    #print(pow(np.linalg.norm(distance[:, :3] - distance[:, 3:6], 2, 1), 2) * 100)\n                    #print(test)\n                    segmentation = np.argmax(all_segmentations, 2) - 1\n                    for planeIndex in xrange(options.numOutputPlanes):\n                        cv2.imwrite(options.test_dir + \'/segmentation_\' + str(planeIndex) + \'.png\', drawMaskImage(segmentation == planeIndex))\n                        cv2.imwrite(options.test_dir + \'/segmentation_\' + str(planeIndex) + \'_gt.png\', drawMaskImage(gt_s[:, :, planeIndex]))\n                        cv2.imwrite(options.test_dir + \'/segmentation_\' + str(planeIndex) + \'_gt_ori.png\', drawMaskImage(gt_s_ori[:, :, planeIndex]))\n                        continue\n                    exit(1)\n                continue\n\n            # if options.dataset == \'SUNCG\':\n            #     if \'pixelwise\' not in options.suffix:\n            #         evaluatePlaneSegmentation(np.array(predPlanes), np.array(predSegmentations), np.array(gtPlanes), np.array(gtSegmentations), np.array(gtNumPlanes), planeDistanceThreshold = 0.3, IOUThreshold = 0.5, prefix=\'test/planenet_\')\n            #     elif \'_2\' in options.suffix:\n            #         evaluatePlaneSegmentation(np.array(predPlanes), np.array(predSegmentations), np.array(gtPlanes), np.array(gtSegmentations), np.array(gtNumPlanes), planeDistanceThreshold = 0.3, IOUThreshold = 0.5, prefix=\'test/pixelwise_pred_\')\n            #     elif \'_3\' in options.suffix:\n            #         evaluatePlaneSegmentation(np.array(predPlanes), np.array(predSegmentations), np.array(gtPlanes), np.array(gtSegmentations), np.array(gtNumPlanes), planeDistanceThreshold = 0.3, IOUThreshold = 0.5, prefix=\'test/pixelwise_gt_\')\n            #         pass\n            #     pass\n\n            predDepths = np.array(predDepths)\n            gtDepths = np.array(gtDepths)\n            planeMasks = np.array(planeMasks)\n            #predMasks = np.array(predMasks)\n            evaluateDepths(predDepths, gtDepths, gtDepths > 0, planeMasks)\n            exit(1)\n\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n\n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return\n\n\n# def predict(options):\n#     options.test_dir += \'_predict\'\n#     if not os.path.exists(options.test_dir):\n#         os.system(""mkdir -p %s""%options.test_dir)\n#         pass\n\n#     batchSize = 1\n#     img_inp = tf.placeholder(tf.float32,shape=(batchSize,HEIGHT,WIDTH,3),name=\'img_inp\')\n#     plane_gt=tf.placeholder(tf.float32,shape=(batchSize,options.numOutputPlanes, 3),name=\'plane_inp\')\n#     validating_inp = tf.constant(0, tf.int32)\n\n#     global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp_train, img_inp_val, img_inp_rgbd_train, img_inp_rgbd_val, training_flag, options)\n\n#     var_to_restore = tf.global_variables()\n\n\n#     config=tf.ConfigProto()\n#     config.gpu_options.allow_growth=True\n#     config.allow_soft_placement=True\n\n\n#     if dataset == \'SUNCG\':\n#         image_list_file = os.path.join(\'../PythonScripts/SUNCG/image_list_100_tail_500000.txt\')\n#         with open(image_list_file) as f:\n#             im_names = [{\'image\': im_name.strip().replace(\'plane_global.npy\', \'mlt.png\'), \'depth\': im_name.strip().replace(\'plane_global.npy\', \'depth.png\'), \'normal\': im_name.strip().replace(\'plane_global.npy\', \'norm_camera.png\'), \'valid\': im_name.strip().replace(\'plane_global.npy\', \'valid.png\'), \'plane\': im_name.strip()} for im_name in f.readlines()]\n#             pass\n#     else:\n#         im_names = glob.glob(\'../../Data/NYU_RGBD/*_color.png\')\n#         im_names = [{\'image\': im_name, \'depth\': im_name.replace(\'color.png\', \'depth.png\'), \'normal\': im_name.replace(\'color.png\', \'norm_camera.png\'), \'invalid_mask\': im_name.replace(\'color.png\', \'valid.png\')} for im_name in im_names]\n#         pass\n\n#     if numImages > 0:\n#         im_names = im_names[:numImages]\n#         pass\n\n#     #if args.imageIndex > 0:\n#     #im_names = im_names[args.imageIndex:args.imageIndex + 1]\n#     #pass\n\n#     init_op = tf.group(tf.global_variables_initializer(),\n#                        tf.local_variables_initializer())\n\n\n#     with tf.Session(config=config) as sess:\n#         saver = tf.train.Saver()\n#         #sess.run(tf.global_variables_initializer())\n#         saver.restore(sess,""%s/%s.ckpt""%(options.checkpoint_dir,keyname))\n\n#         gtDepths = []\n#         predDepths = []\n#         segmentationDepths = []\n#         predDepthsOneHot = []\n#         planeMasks = []\n#         predMasks = []\n\n#         imageWidth = WIDTH\n#         imageHeight = HEIGHT\n#         focalLength = 517.97\n#         urange = np.arange(imageWidth).reshape(1, -1).repeat(imageHeight, 0) - imageWidth * 0.5\n#         vrange = np.arange(imageHeight).reshape(-1, 1).repeat(imageWidth, 1) - imageHeight * 0.5\n#         ranges = np.array([urange / focalLength, np.ones(urange.shape), -vrange / focalLength]).transpose([1, 2, 0])\n\n#         cv2.imwrite(options.test_dir + \'/one.png\', np.ones((HEIGHT, WIDTH), dtype=np.uint8) * 255)\n#         cv2.imwrite(options.test_dir + \'/zero.png\', np.zeros((HEIGHT, WIDTH), dtype=np.uint8) * 255)\n#         for index, im_name in enumerate(im_names):\n#             if index <= -1:\n#                 continue\n#             print(im_name[\'image\'])\n#             im = cv2.imread(im_name[\'image\'])\n#             image = im.astype(np.float32, copy=False)\n#             image = image / 255 - 0.5\n#             image = cv2.resize(image, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n\n#             #planes = np.load(im_name[\'plane\'])\n#             # numPlanes = planes.shape[0]\n#             # if numPlanes > options.numOutputPlanes:\n#             #     planeAreas = planes[:, 3:].sum(1)\n#             #     sortInds = np.argsort(planeAreas)[::-1]\n#             #     planes = planes[sortInds[:options.numOutputPlanes]]\n#             #     pass\n#             # gt_p = np.zeros((1, options.numOutputPlanes, 3))\n#             # gt_p[0, :numPlanes] = planes[:numPlanes, :3]\n\n#             normal = np.array(PIL.Image.open(im_name[\'normal\'])).astype(np.float) / 255 * 2 - 1\n#             norm = np.linalg.norm(normal, 2, 2)\n#             for c in xrange(3):\n#                 normal[:, :, c] /= norm\n#                 continue\n#             normal = cv2.resize(normal, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n\n#             depth = np.array(PIL.Image.open(im_name[\'depth\'])).astype(np.float) / 1000\n#             depth = cv2.resize(depth, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n\n#             invalid_mask = cv2.resize(cv2.imread(im_name[\'invalid_mask\'], 0), (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR) > 128\n\n#             gtDepths.append(depth)\n\n\n#             pred_p, pred_d, pred_n, pred_s, pred_np_m, pred_np_d, pred_np_n, pred_boundary, pred_local_score, pred_local_p, pred_local_mask = sess.run([plane_pred, depth_pred, normal_pred, segmentation_pred, non_plane_mask_pred, non_plane_depth_pred, non_plane_normal_pred, boundary_pred, local_score_pred, local_p_pred, local_mask_pred], feed_dict = {img_inp:np.expand_dims(image, 0), plane_gt: np.zeros((batchSize, options.numOutputPlanes, 3))})\n\n\n#             pred_s = pred_s[0]\n#             pred_p = pred_p[0]\n#             pred_np_m = pred_np_m[0]\n#             pred_np_d = pred_np_d[0]\n#             pred_np_n = pred_np_n[0]\n#             #pred_s = 1 / (1 + np.exp(-pred_s))\n\n#             plane_depths = calcPlaneDepths(pred_p, WIDTH, HEIGHT)\n#             all_depths = np.concatenate([pred_np_d, plane_depths], axis=2)\n\n#             all_segmentations = np.concatenate([pred_np_m, pred_s], axis=2)\n#             segmentation = np.argmax(all_segmentations, 2)\n#             if suffix != \'pixelwise\':\n#                 pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape(HEIGHT, WIDTH)\n#             else:\n#                 pred_d = np.squeeze(pred_np_d)\n#                 pass\n#             predDepths.append(pred_d)\n#             predMasks.append(segmentation != 0)\n#             planeMasks.append(invalid_mask)\n\n#             #depthError, normalError, occupancy, segmentationTest, reconstructedDepth, occupancyMask = evaluatePlanes(pred_p, im_name[\'image\'])\n#             #reconstructedDepth = cv2.resize(reconstructedDepth, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n\n#             #evaluatePlanes(pred_p[0], im_name, options.test_dir, index)\n#             #print(pred_p)\n#             #print(gt_p)\n#             #print((pow(pred_d[0, :, :, 0] - depth, 2) * (gt_s.max(2) > 0.5)).mean())\n#             #print((depthError, normalError, occupancy))\n\n#             evaluateDepths(predDepths[index], gtDepths[index], np.ones(planeMasks[index].shape), planeMasks[index])\n\n#             if index >= 10:\n#                 continue\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', cv2.resize(im, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR))\n#             #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_gt.png\', (minDepth / np.clip(depth, minDepth, 20) * 255).astype(np.uint8))\n#             #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', (minDepth / np.clip(pred_d[0, :, :, 0], minDepth, 20) * 255).astype(np.uint8))\n#             #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_plane.png\', (minDepth / np.clip(reconstructedDepth, minDepth, 20) * 255).astype(np.uint8))\n\n#             pred_boundary = pred_boundary[0]\n#             boundary = (1 / (1 + np.exp(-pred_boundary)) * 255).astype(np.uint8)\n#             boundary = np.concatenate([boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_boundary_pred.png\', boundary)\n\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_inp.png\', drawDepthImage(depth))\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n#             #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_plane.png\', drawDepthImage(reconstructedDepth))\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred_diff.png\', drawDiffImage(pred_d, depth, 0.5))\n#             #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_plane_diff.png\', np.minimum(np.abs(reconstructedDepth - depth) / 0.5 * 255, 255).astype(np.uint8))\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_inp.png\', drawNormalImage(normal))\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_pred.png\', drawNormalImage(pred_np_n))\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(all_segmentations, black=True))\n\n#             segmentation = np.argmax(pred_s, 2)\n#             #writePLYFile(options.test_dir, index, image, pred_p, segmentation)\n\n#             if index < 0:\n#                 for planeIndex in xrange(options.numOutputPlanes):\n#                     cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_\' + str(planeIndex) + \'.png\', drawMaskImage(pred_s[:, :, planeIndex]))\n#                     #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_\' + str(planeIndex) + \'_gt.png\', drawMaskImage(gt_s[:, :, planeIndex]))\n#                     continue\n#                 pass\n#             continue\n#         predDepths = np.array(predDepths)\n#         gtDepths = np.array(gtDepths)\n#         planeMasks = np.array(planeMasks)\n#         predMasks = np.array(predMasks)\n#         #evaluateDepths(predDepths, gtDepths, planeMasks, predMasks)\n#         evaluateDepths(predDepths, gtDepths, planeMasks, planeMasks)\n#         #exit(1)\n#         pass\n#     return\n\n\n# def fitPlanesRGBD(options):\n#     writeHTMLRGBD(\'../results/RANSAC_RGBD/index.html\', 10)\n#     exit(1)\n#     if not os.path.exists(options.checkpoint_dir):\n#         os.system(""mkdir -p %s""%options.checkpoint_dir)\n#         pass\n#     if not os.path.exists(options.test_dir):\n#         os.system(""mkdir -p %s""%options.test_dir)\n#         pass\n\n#     min_after_dequeue = 1000\n\n#     reader_rgbd = RecordReaderRGBD()\n#     filename_queue_rgbd = tf.train.string_input_producer([\'../planes_nyu_rgbd_train.tfrecords\'], num_epochs=1)\n#     img_inp_rgbd, global_gt_dict_rgbd, local_gt_dict_rgbd = reader_rgbd.getBatch(filename_queue_rgbd, numOutputPlanes=options.numOutputPlanes, batchSize=1, min_after_dequeue=min_after_dequeue, getLocal=True)\n\n#     config=tf.ConfigProto()\n#     config.gpu_options.allow_growth=True\n#     config.allow_soft_placement=True\n\n#     init_op = tf.group(tf.global_variables_initializer(),\n#                        tf.local_variables_initializer())\n\n#     with tf.Session(config=config) as sess:\n#         sess.run(init_op)\n\n#         coord = tf.train.Coordinator()\n#         threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n#         try:\n#             gtDepths = []\n#             predDepths = []\n#             planeMasks = []\n#             for index in xrange(10):\n#                 image, depth, path = sess.run([img_inp_rgbd, global_gt_dict_rgbd[\'depth\'], global_gt_dict_rgbd[\'path\']])\n#                 image = ((image[0] + 0.5) * 255).astype(np.uint8)\n#                 depth = depth.squeeze()\n\n#                 cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', image)\n#                 cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth.png\', drawDepthImage(depth))\n#                 #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_mask.png\', drawMaskImage(depth == 0))\n#                 planes, planeSegmentation, depthPred = fitPlanes(depth, numPlanes=20)\n#                 cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(planeSegmentation))\n#                 cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(depthPred))\n\n#                 gtDepths.append(depth)\n#                 predDepths.append(depthPred)\n#                 planeMasks.append((planeSegmentation < 20).astype(np.float32))\n#                 continue\n#             predDepths = np.array(predDepths)\n#             gtDepths = np.array(gtDepths)\n#             planeMasks = np.array(planeMasks)\n#             evaluateDepths(predDepths, gtDepths, np.ones(planeMasks.shape, dtype=np.bool), planeMasks)\n#         except tf.errors.OutOfRangeError:\n#             print(\'done fitting\')\n#         finally:\n#             # When done, ask the threads to stop.\n#             coord.request_stop()\n#             pass\n#     return\n\ndef writeInfo(options):\n    x = (np.arange(11) * 0.1).tolist()\n    ys = []\n    ys.append(np.load(\'test/planenet_pixel_IOU.npy\').tolist())\n    ys.append(np.load(\'test/pixelwise_pred_pixel_IOU.npy\').tolist())\n    ys.append(np.load(\'test/pixelwise_gt_pixel_IOU.npy\').tolist())\n    plotCurves(x, ys, filename = \'test/plane_comparison.png\', xlabel=\'IOU\', ylabel=\'pixel coverage\', labels=[\'planenet\', \'pixelwise+RANSAC\', \'GT+RANSAC\'])\n\n    x = (0.5 - np.arange(11) * 0.05).tolist()\n    ys = []\n    ys.append(np.load(\'test/planenet_pixel_diff.npy\').tolist())\n    ys.append(np.load(\'test/pixelwise_pred_pixel_diff.npy\').tolist())\n    ys.append(np.load(\'test/pixelwise_gt_pixel_diff.npy\').tolist())\n    plotCurves(x, ys, filename = \'test/plane_comparison_diff.png\', xlabel=\'diff\', ylabel=\'pixel coverage\', labels=[\'planenet\', \'pixelwise+RANSAC\', \'GT+RANSAC\'])\n\n    return\n\ndef parse_args():\n    """"""\n    Parse input arguments\n    """"""\n    parser = argparse.ArgumentParser(description=\'Planenet\')\n    parser.add_argument(\'--gpu\', dest=\'gpu_id\',\n                        help=\'GPU device id to use [0]\',\n                        default=0, type=int)\n    #task: [train, test, predict]\n    parser.add_argument(\'--task\', dest=\'task\',\n                        help=\'task type: [train, test, predict]\',\n                        default=\'train\', type=str)\n    parser.add_argument(\'--restore\', dest=\'restore\',\n                        help=\'how to restore the model\',\n                        default=0, type=int)\n    parser.add_argument(\'--numOutputPlanes\', dest=\'numOutputPlanes\',\n                        help=\'the number of output planes\',\n                        default=20, type=int)\n    parser.add_argument(\'--batchSize\', dest=\'batchSize\',\n                        help=\'batch size\',\n                        default=8, type=int)\n    parser.add_argument(\'--dataset\', dest=\'dataset\',\n                        help=\'dataset name for test/predict\',\n                        default=\'\', type=str)\n    parser.add_argument(\'--numImages\', dest=\'numImages\',\n                        help=\'the number of images to test/predict\',\n                        default=10, type=int)\n    parser.add_argument(\'--boundaryLoss\', dest=\'boundaryLoss\',\n                        help=\'use boundary loss: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--diverseLoss\', dest=\'diverseLoss\',\n                        help=\'use diverse loss: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--labelLoss\', dest=\'labelLoss\',\n                        help=\'use label loss: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--deepSupervision\', dest=\'deepSupervision\',\n                        help=\'deep supervision level: [0, 1, 2]\',\n                        default=0, type=int)\n    parser.add_argument(\'--sameMatching\', dest=\'sameMatching\',\n                        help=\'use the same matching for all deep supervision layers and the final prediction: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--anchorPlanes\', dest=\'anchorPlanes\',\n                        help=\'use anchor planes for all deep supervision layers and the final prediction: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--crf\', dest=\'crf\',\n                        help=\'the number of CRF iterations\',\n                        default=0, type=int)\n    parser.add_argument(\'--crfrnn\', dest=\'crfrnn\',\n                        help=\'the number of CRF (as RNN) iterations\',\n                        default=0, type=int)\n    parser.add_argument(\'--backwardLossWeight\', dest=\'backwardLossWeight\',\n                        help=\'backward matching loss\',\n                        default=0.5, type=float)\n    parser.add_argument(\'--predictBoundary\', dest=\'predictBoundary\',\n                        help=\'whether predict boundary or not: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--predictSemantics\', dest=\'predictSemantics\',\n                        help=\'whether predict semantics or not: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--predictLocal\', dest=\'predictLocal\',\n                        help=\'whether predict local planes or not: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--predictConfidence\', dest=\'predictConfidence\',\n                        help=\'whether predict plane confidence or not: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--predictPlanes\', dest=\'predictPlanes\',\n                        help=\'whether predict planes or not: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--fineTuningCheckpoint\', dest=\'fineTuningCheckpoint\',\n                        help=\'specify the model for fine-tuning\',\n                        default=\'../PlaneSetGeneration/dump_planenet_diverse/train_planenet_diverse.ckpt\', type=str)\n    parser.add_argument(\'--suffix\', dest=\'suffix\',\n                        help=\'add a suffix to keyname to distinguish experiments\',\n                        default=\'\', type=str)\n    parser.add_argument(\'--l2Weight\', dest=\'l2Weight\',\n                        help=\'L2 regulation weight\',\n                        default=5e-4, type=float)\n    parser.add_argument(\'--LR\', dest=\'LR\',\n                        help=\'learning rate\',\n                        default=3e-5, type=float)\n    parser.add_argument(\'--hybrid\', dest=\'hybrid\',\n                        help=\'hybrid training\',\n                        default=\'1\', type=str)\n    parser.add_argument(\'--rootFolder\', dest=\'rootFolder\',\n                        help=\'root folder\',\n                        default=\'/mnt/vision/PlaneNet/\', type=str)\n    parser.add_argument(\'--dataFolder\', dest=\'dataFolder\',\n                        help=\'data folder\',\n                        default=\'/home/chenliu/Projects/PlaneNet/\', type=str)\n    parser.add_argument(\'--saveInterval\', dest=\'saveInterval\',\n                        help=\'save interval\',\n                        default=900, type=int)\n\n\n    args = parser.parse_args()\n    args.keyname = os.path.basename(__file__).rstrip(\'.py\')\n    args.keyname = args.keyname.replace(\'train_\', \'\')\n\n    if args.numOutputPlanes != 20:\n        args.keyname += \'_np\' + str(args.numOutputPlanes)\n        pass\n    args.keyname += \'_hybrid\' + args.hybrid\n\n    if args.deepSupervision != 1:\n        args.keyname += \'_ds\' + str(args.deepSupervision)\n        pass\n    if args.predictPlanes == 1:\n        args.keyname += \'_pp\'\n        pass\n    if args.predictSemantics == 1:\n        args.keyname += \'_ps\'\n        pass\n    if args.crfrnn != 0:\n        args.keyname += \'_crfrnn\' + str(args.crfrnn)\n        pass\n\n    #args.predictSemantics = 0\n    #args.predictBoundary = 0\n\n    args.checkpoint_dir = args.rootFolder + \'/checkpoint/\' + args.keyname\n    args.log_dir = \'log/\' + args.keyname\n    args.test_dir = \'test/\' + args.keyname + \'_\' + args.dataset\n    args.predict_dir = \'predict/\' + args.keyname + \'_\' + args.dataset\n    args.dump_dir = \'dump/\' + args.keyname\n\n    #layers where deep supervision happens\n    args.deepSupervisionLayers = []\n    if args.deepSupervision >= 1:\n        args.deepSupervisionLayers.append(\'res4b22_relu\')\n        pass\n    if args.deepSupervision >= 2:\n        args.deepSupervisionLayers.append(\'res4b12_relu\')\n        pass\n    return args\n\n\nif __name__==\'__main__\':\n\n    # plane = np.load(\'temp/plane.npy\')\n    # depth = np.load(\'temp/depth.npy\')\n    # segmentation = np.load(\'temp/segmentation.npy\')\n    # info = np.load(\'temp/info.npy\')\n    # num_planes = np.load(\'temp/num_planes.npy\')\n    # segmentation = np.argmax(segmentation, axis=-1)\n    # print(segmentation.shape)\n    # planes, segmentation, numPlanes = removeSmallSegments(plane, np.zeros((HEIGHT, WIDTH, 3)), depth.squeeze(), np.zeros((HEIGHT, WIDTH, 3)), segmentation, np.zeros((HEIGHT, WIDTH)), info, num_planes)\n    # print(planes)\n    # exit(1)\n\n    args = parse_args()\n\n    print ""keyname=%s task=%s started""%(args.keyname, args.task)\n    try:\n        if args.task == ""train"":\n            main(args)\n        elif args.task == ""test"":\n            test(args)\n        elif args.task == ""predict"":\n            predict(args)\n        elif args.task == ""fit"":\n            fitPlanesRGBD(args)\n        elif args.task == ""write"":\n            writeInfo(args)\n        else:\n            assert False,""format wrong""\n            pass\n    finally:\n        pass\n'"
code/train_group.py,154,"b'import tensorflow as tf\nimport numpy as np\nnp.set_printoptions(precision=2, linewidth=200)\nimport cv2\nimport os\nimport time\nimport sys\nimport tf_nndistance\nimport argparse\nimport glob\nimport PIL\nimport scipy.ndimage as ndimage\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom utils import *\nfrom plane_utils import *\nfrom modules import *\n\n\nfrom planenet import PlaneNet\nfrom RecordReader import *\nfrom RecordReaderRGBD import *\n\n#training_flag: toggle dropout and batch normalization mode\n#it\'s true for training and false for validation, testing, prediction\n#it also controls which data batch to use (*_train or *_val)\n\ndef calcGroupMap(options):\n    group_map_array = np.zeros(options.numOutputPlanes, options.numConcaveGroups + options.numConvexGroups)\n    planeIndex = 0\n    for groupIndex in xrange(options.numConcaveGroups):\n        group_map_array[planeIndex:planeIndex + 5, groupIndex] = 1\n        planeIndex += 5\n        continue\n    for groupIndex in xrange(options.numConvexGroups):\n        group_map_array[planeIndex:planeIndex + 3, groupIndex + options.numConcaveGroups] = 1\n        planeIndex += 3\n        continue\n    group_map = tf.tile(tf.constant(group_map_array.reshape(-1), shape=(1, options.numOutputPlanes, options.numConcaveGroups + options.numConvexGroups)), [options.batchSize, 1, 1])\n    return group_map\n\ndef calcGroupDepths(plane_depths, options):\n    group_map = calcGroupMap(options)\n    group_map = tf.expand_dims(tf.expand_dims(group_map, 1), 1)\n    group_plane_depths = tf.expand_dims(plane_depths, -1) * group_map\n    concave_group_depths = tf.squeeze(tf.min(tf.slice(group_plane_depths, [0, 0, 0, 0, 0], [options.batchSize, HEIGHT, WIDTH, options.numOutputPlanes, options.numConcaveGroups]), axis=3))\n    convex_group_depths = tf.squeeze(tf.max(tf.slice(group_plane_depths, [0, 0, 0, 0, options.numConcaveGroups], [options.batchSize, HEIGHT, WIDTH, options.numOutputPlanes, options.numConcaveGroups + options.numConvexGroups]), axis=3))\n    group_depths = tf.concat([concave_group_depths, convex_group_depths] axis=3)\n    return group_depths, group_plane_depths\n\n    \ndef build_graph(img_inp_train, img_inp_val, img_inp_rgbd_train, img_inp_rgbd_val, training_flag, options):\n    with tf.device(\'/gpu:%d\'%options.gpu_id):\n        img_inp_rgbd = tf.cond(tf.equal(training_flag % 2, 0), lambda: img_inp_rgbd_train, lambda: img_inp_rgbd_val)\n        img_inp = tf.cond(tf.less(training_flag, 2), lambda: tf.cond(tf.equal(training_flag % 2, 0), lambda: img_inp_train, lambda: img_inp_val), lambda: img_inp_rgbd)\n        \n        net = PlaneNet({\'img_inp\': img_inp}, is_training=tf.equal(training_flag % 2, 0), options=options)\n\n        #global predictions\n        plane_pred = net.layers[\'plane_pred\']\n        \n        segmentation_pred = net.layers[\'segmentation_pred\']\n        non_plane_mask_pred = net.layers[\'non_plane_mask_pred\']\n        non_plane_depth_pred = net.layers[\'non_plane_depth_pred\']\n        non_plane_normal_pred = net.layers[\'non_plane_normal_pred\']\n        \n        global_pred_dict = {\'plane\': plane_pred, \'segmentation\': segmentation_pred, \'non_plane_mask\': non_plane_mask_pred, \'non_plane_depth\': non_plane_depth_pred, \'non_plane_normal\': non_plane_normal_pred}\n\n        if options.predictBoundary:\n            global_pred_dict[\'boundary\'] = net.layers[\'boundary_pred\']\n            pass\n        if options.predictConfidence:\n            global_pred_dict[\'confidence\'] = net.layers[\'plane_confidence_pred\']\n            pass\n        \n        #local predictions\n        if options.predictLocal:\n            local_pred_dict = {\'score\': net.layers[\'local_score_pred\'], \'plane\': net.layers[\'local_plane_pred\'], \'mask\': net.layers[\'local_mask_pred\']}\n        else:\n            local_pred_dict = {}\n            pass\n\n        \n        #deep supervision\n        deep_pred_dicts = []\n        for layer in options.deepSupervisionLayers:\n            pred_dict = {\'plane\': net.layers[layer+\'_plane_pred\'], \'segmentation\': net.layers[layer+\'_segmentation_pred\'], \'non_plane_mask\': net.layers[layer+\'_non_plane_mask_pred\']}\n            if options.predictConfidence:\n                pred_dict[\'confidence\'] = net.layers[layer+\'_plane_confidence_pred\']\n                pass\n            deep_pred_dicts.append(pred_dict)\n            continue\n        pass\n    \n    return global_pred_dict, local_pred_dict, deep_pred_dicts\n\n\ndef build_loss_rgbd(global_pred_dict, local_pred_dict, deep_pred_dicts, global_gt_dict_train, local_gt_dict_train, global_gt_dict_val, local_gt_dict_val, training_flag, options):\n    with tf.device(\'/gpu:%d\'%options.gpu_id):\n        global_gt_dict = {}\n        for name in global_gt_dict_train.keys():\n            global_gt_dict[name] = tf.cond(tf.equal(training_flag % 2, 0), lambda: global_gt_dict_train[name], lambda: global_gt_dict_val[name])\n            continue\n        local_gt_dict = {}\n        for name in local_gt_dict_train.keys():\n            local_gt_dict[name] = tf.cond(tf.equal(training_flag % 2, 0), lambda: local_gt_dict_train[name], lambda: local_gt_dict_val[name])\n            continue\n\n        #depth loss\n        plane_parameters = tf.reshape(global_pred_dict[\'plane\'], (-1, 3))\n        plane_depths = planeDepthsModule(plane_parameters, WIDTH, HEIGHT)\n        plane_depths = tf.transpose(tf.reshape(plane_depths, [HEIGHT, WIDTH, -1, options.numOutputPlanes]), [2, 0, 1, 3])\n\n        all_segmentations = tf.concat([global_pred_dict[\'segmentation\'], global_pred_dict[\'non_plane_mask\']], axis=3)\n        all_segmentations_softmax = tf.nn.softmax(all_segmentations)\n        all_depths = tf.concat([plane_depths, global_pred_dict[\'non_plane_depth\']], axis=3)\n        validDepthMask = tf.cast(tf.greater(global_gt_dict[\'depth\'], 1e-4), tf.float32)\n        depth_loss = tf.reduce_mean(tf.reduce_sum(tf.squared_difference(all_depths, global_gt_dict[\'depth\']) * all_segmentations_softmax, axis=3, keep_dims=True) * validDepthMask) * 1000\n\n        l2_losses = tf.add_n([options.l2Weight * tf.nn.l2_loss(v) for v in tf.trainable_variables() if \'weights\' in v.name])\n        loss = depth_loss + l2_losses\n        loss_dict = {\'depth\': depth_loss, \'plane\': tf.constant(0.0), \'segmentation\': tf.constant(0.0)}\n        debug_dict = {}\n        pass\n    return loss, loss_dict, debug_dict\n\n\ndef build_loss(global_pred_dict, local_pred_dict, deep_pred_dicts, global_gt_dict_train, local_gt_dict_train, global_gt_dict_val, local_gt_dict_val, training_flag, options):\n    \n    with tf.device(\'/gpu:%d\'%options.gpu_id):\n        global_gt_dict = {}\n        for name in global_gt_dict_train.keys():\n            global_gt_dict[name] = tf.cond(tf.equal(training_flag % 2, 0), lambda: global_gt_dict_train[name], lambda: global_gt_dict_val[name])\n            continue\n        local_gt_dict = {}\n        for name in local_gt_dict_train.keys():\n            local_gt_dict[name] = tf.cond(tf.equal(training_flag % 2, 0), lambda: local_gt_dict_train[name], lambda: local_gt_dict_val[name])\n            continue\n\n        normalDotThreshold = np.cos(np.deg2rad(5))\n        distanceThreshold = 0.05\n        segmentation_gt, plane_mask = fitPlaneMasksModule(global_gt_dict[\'plane\'], global_gt_dict[\'depth\'], global_gt_dict[\'normal\'], width=WIDTH, height=HEIGHT, normalDotThreshold=normalDotThreshold, distanceThreshold=distanceThreshold, closing=True, one_hot=True)\n        \n        validPlaneMask = tf.cast(tf.less(tf.tile(tf.expand_dims(tf.range(options.numOutputPlanes), 0), [options.batchSize, 1]), tf.expand_dims(global_gt_dict[\'num_planes\'], -1)), tf.float32)        \n        \n        backwardLossWeight = options.backwardLossWeight\n\n\n        plane_depths = planeDepthsModule(plane_parameters, WIDTH, HEIGHT)\n        group_depths = calcGroupDepths(plane_depths, options)\n        group_segmentations = tf.sigmoid(pred_dict[\'segmentation\'])\n        group_segmentations_binary = tf.cast(tf.greater(group_segmentations, 0.5), tf.float32)\n        depth_pred = tf.reduce_min(group_depths * group_segmentations_binary, axis=3, keep_dims=True) + pred_dict[\'non_plane_depth\'] * (1 - tf.reduce_max(group_segmentations_binary, axis=3, keep_dims=True))\n\n        #plane loss and segmentation loss (summation over deep supervisions and final supervision)\n        all_pred_dicts = deep_pred_dicts + [global_pred_dict]\n        plane_loss = tf.constant(0.0)\n        segmentation_loss = tf.constant(0.0)\n        plane_confidence_loss = tf.constant(0.0)\n        diverse_loss = tf.constant(0.0)\n        \n        #keep forward map (segmentation gt) from previous supervision so that we can have same matching for all supervisions (options.sameMatching = 1)\n        previous_forward_map = None\n        previous_segmentation_gt = None\n        for pred_index, pred_dict in enumerate(all_pred_dicts):\n            if options.sameMatching and pred_index > 0:\n                #use matching from previous supervision and map ground truth planes based on the mapping\n                forward_map = previous_forward_map\n\n                #number of ground truth mapped for each prediction\n                num_matches = tf.transpose(tf.reduce_sum(forward_map, axis=1, keep_dims=True), [0, 2, 1])\n\n                #predictions with at least one matches\n                plane_confidence_gt = tf.cast(num_matches > 0.5, tf.float32)\n\n\n                plane_gt_shuffled = tf.transpose(tf.matmul(global_gt_dict[\'plane\'], forward_map, transpose_a=True), [0, 2, 1]) / tf.maximum(num_matches, 1e-4)\n                plane_loss += tf.reduce_mean(tf.squared_difference(pred_dict[\'plane\'], plane_gt_shuffled) * plane_confidence_gt) * 1000\n\n\n                if options.predictConfidence:\n                    plane_confidence_loss += tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=pred_dict[\'confidence\'], labels=plane_confidence_gt)) * 1000\n                    pass\n\n                #all segmentations is the concatenation of plane segmentations and non plane mask\n                all_segmentations = tf.concat([pred_dict[\'segmentation\'], pred_dict[\'non_plane_mask\']], axis=3)\n                segmentation_gt_shuffled = previous_segmentation_gt\n                segmentation_loss += tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=all_segmentations, labels=segmentation_gt_shuffled)) * 1000\n                \n            else:\n                #calculate new matching by finding nearest neighbors again\n                dists_forward, map_forward, dists_backward, _ = tf_nndistance.nn_distance(global_gt_dict[\'plane\'], pred_dict[\'plane\'])\n                dists_forward *= validPlaneMask\n                \n                dists_forward = tf.reduce_mean(dists_forward)\n                dists_backward = tf.reduce_mean(dists_backward)\n                plane_loss += (dists_forward + dists_backward * backwardLossWeight) * 10000\n\n                forward_map = tf.one_hot(map_forward, depth=options.numOutputPlanes, axis=-1)\n                forward_map *= tf.expand_dims(validPlaneMask, -1)\n\n                previous_forward_map = forward_map\n\n\n                #segmentation loss\n                group_map = calcGroupMap(options)\n                group_forward_map = forward_map * group_map\n                segmentation_gt_shuffled = tf.reshape(tf.matmul(tf.reshape(segmentation_gt, [-1, HEIGHT * WIDTH, options.numOutputPlanes]), forward_map), [-1, HEIGHT, WIDTH, options.numOutputPlanes])\n                segmentation_gt_shuffled = tf.concat([segmentation_gt_shuffled, 1 - plane_mask], axis=3)\n\n                previous_segmentation_gt = segmentation_gt_shuffled\n                \n                all_segmentations = tf.concat([pred_dict[\'segmentation\'], pred_dict[\'non_plane_mask\']], axis=3)\n                all_depths = tf.concat([group_depths, global_pred_dict[\'non_plane_depth\']], axis=3)\n                segmentation_loss += tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=all_segmentations, labels=segmentation_gt_shuffled) * tf.abs(all_depths - depth_pred) < 1e-2) * 1000\n                pass\n\n            if options.diverseLoss:\n                plane_diff = tf.reduce_sum(tf.pow(tf.expand_dims(pred_dict[\'plane\'], 1) - tf.expand_dims(pred_dict[\'plane\'], 2), 2), axis=3)\n                plane_diff = tf.matrix_set_diag(plane_diff, tf.ones((options.batchSize, options.numOutputPlanes)))\n                minPlaneDiff = 0.1\n                diverse_loss += tf.reduce_mean(tf.clip_by_value(1 - plane_diff / minPlaneDiff, 0, 1)) * 10000\n                pass\n            continue\n\n\n        #depth loss\n        plane_parameters = tf.reshape(global_pred_dict[\'plane\'], (-1, 3))\n        plane_depths = tf.transpose(tf.reshape(plane_depths, [HEIGHT, WIDTH, -1, options.numOutputPlanes]), [2, 0, 1, 3])\n\n        #all_segmentations_softmax = tf.nn.softmax(all_segmentations)\n        #all_depths = tf.concat([plane_depths, global_pred_dict[\'non_plane_depth\']], axis=3)\n        #validDepthMask = tf.cast(tf.greater(global_gt_dict[\'depth\'], 1e-4), tf.float32)\n        #depth_loss = tf.reduce_mean(tf.reduce_sum(tf.squared_difference(all_depths, global_gt_dict[\'depth\']) * all_segmentations_softmax, axis=3, keep_dims=True) * validDepthMask) * 1000\n        depth_loss = tf.reduce_mean(tf.squared_difference(depth_pred, global_gt_dict[\'depth\']) * validDepthMask) * 1000\n        \n        #normal loss for non-plane region\n        normal_loss = tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_normal\'], global_gt_dict[\'normal\']) * (1 - plane_mask)) * 1000\n        \n\n        #local loss\n        if options.predictLocal:\n            local_score_loss = tf.reduce_mean(tf.losses.sigmoid_cross_entropy(logits=local_pred_dict[\'score\'], multi_class_labels=local_gt_dict[\'score\'], weights=tf.maximum(local_gt_dict[\'score\'] * 10, 1))) * 1000\n            local_plane_loss = tf.reduce_mean(tf.squared_difference(local_pred_dict[\'plane\'], local_gt_dict[\'plane\']) * local_gt_dict[\'score\']) * 10000\n            local_mask_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=local_pred_dict[\'mask\'], labels=local_gt_dict[\'mask\']) * local_gt_dict[\'score\']) * 10000\n        else:\n            local_score_loss = tf.constant(0.0)\n            local_plane_loss = tf.constant(0.0)\n            local_mask_loss = tf.constant(0.0)\n            pass\n        \n        \n        #boundary loss\n        boundary_loss = tf.constant(0.0)\n        #load or calculate boundary ground truth\n        if False:\n            #load from dataset\n            boundary_gt = tf.cond(training_flag, lambda: boundary_gt_train, lambda: boundary_gt_val)\n        else:\n            #calculate boundary ground truth on-the-fly as the calculation is subject to change\n            kernel_size = 3\n            padding = (kernel_size - 1) / 2\n            neighbor_kernel_array = gaussian(kernel_size, kernel_size)\n            neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n            neighbor_kernel_array /= neighbor_kernel_array.sum()\n            neighbor_kernel_array *= -1\n            neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 1\n            neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n            neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n        \n            depth_diff = tf.abs(tf.nn.depthwise_conv2d(global_gt_dict[\'depth\'], neighbor_kernel, strides=[1, 1, 1, 1], padding=\'VALID\'))\n            depth_diff = tf.pad(depth_diff, paddings = [[0, 0], [padding, padding], [padding, padding], [0, 0]])\n            max_depth_diff = 0.1\n            depth_boundary = tf.greater(depth_diff, max_depth_diff)\n\n            normal_diff = tf.norm(tf.nn.depthwise_conv2d(global_gt_dict[\'normal\'], tf.tile(neighbor_kernel, [1, 1, 3, 1]), strides=[1, 1, 1, 1], padding=\'VALID\'), axis=3, keep_dims=True)\n            normal_diff = tf.pad(normal_diff, paddings = [[0, 0], [padding, padding], [padding, padding], [0, 0]])\n            max_normal_diff = np.sqrt(2 * (1 - np.cos(np.deg2rad(20))))\n            normal_boundary = tf.greater(normal_diff, max_normal_diff)\n\n            plane_region = tf.nn.max_pool(plane_mask, ksize=[1, kernel_size, kernel_size, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n            segmentation_eroded = 1 - tf.nn.max_pool(1 - segmentation_gt, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n            plane_region -= tf.reduce_max(segmentation_eroded, axis=3, keep_dims=True)\n            boundary = tf.cast(tf.logical_or(depth_boundary, normal_boundary), tf.float32) * plane_region\n            smooth_boundary = tf.cast(tf.logical_and(normal_boundary, tf.less_equal(depth_diff, max_depth_diff)), tf.float32) * plane_region\n            boundary_gt = tf.concat([smooth_boundary, boundary - smooth_boundary], axis=3)\n            pass\n\n\n        if options.boundaryLoss:\n            all_segmentations_pred = group_segmentations\n            all_segmentations_min = 1 - tf.nn.max_pool(1 - all_segmentations_pred, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\')\n            segmentation_diff = tf.reduce_max(all_segmentations_pred - all_segmentations_min, axis=3, keep_dims=True)\n\n\n            group_neighbor_map = np.zeros(options.numOutputPlanes, 4)\n            neighbor_plane_depth\n\n            smooth_boundary = tf.slice(boundary_gt, [0, 0, 0, 0], [options.batchSize, HEIGHT, WIDTH, 1])\n            occlusion_boundary = tf.slice(boundary_gt, [0, 0, 0, 1], [options.batchSize, HEIGHT, WIDTH, 1])\n            smooth_mask = segmentation_diff + occlusion_boundary - 2 * segmentation_diff * occlusion_boundary + depth_diff * smooth_boundary\n            margin = 0.0\n            smooth_mask = tf.nn.relu(smooth_mask - margin)\n            boundary_loss += tf.reduce_mean(smooth_mask * plane_mask) * 1000            \n            pass\n          \n        if options.predictBoundary:\n            #we predict boundaries directly for post-processing purpose\n            boundary_loss += tf.reduce_mean(tf.losses.sigmoid_cross_entropy(logits=global_pred_dict[\'boundary\'], multi_class_labels=boundary_gt, weights=tf.maximum(global_gt_dict[\'boundary\'] * 3, 1))) * 1000\n\n\n        if options.diverseLoss:\n            plane_diff = tf.reduce_sum(tf.pow(tf.expand_dims(global_pred_dict[\'plane\'], 1) - tf.expand_dims(global_pred_dict[\'plane\'], 2), 2), axis=3)\n            plane_diff = tf.matrix_set_diag(plane_diff, tf.ones((options.batchSize, options.numOutputPlanes)))\n            minPlaneDiff = 0.1\n            diverse_loss += tf.reduce_mean(tf.clip_by_value(1 - plane_diff / minPlaneDiff, 0, 1)) * 10000\n            pass\n\n          \n        #regularization\n        l2_losses = tf.add_n([options.l2Weight * tf.nn.l2_loss(v) for v in tf.trainable_variables() if \'weights\' in v.name])\n\n\n        loss = plane_loss + segmentation_loss + depth_loss + normal_loss + plane_confidence_loss + diverse_loss + boundary_loss + local_score_loss + local_plane_loss + local_mask_loss + l2_losses\n\n        #if options.pixelwiseLoss:\n        #normal_loss = tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_normal\'], global_gt_dict[\'normal\'])) * 1000\n        #depth_loss = tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_depth\'], global_gt_dict[\'depth\']) * validDepthMask) * 1000\n        #pass\n\n        loss_dict = {\'plane\': plane_loss, \'segmentation\': segmentation_loss, \'depth\': depth_loss, \'normal\': normal_loss, \'boundary\': boundary_loss, \'diverse\': diverse_loss, \'confidence\': plane_confidence_loss, \'local_score\': local_score_loss, \'local_plane\': local_plane_loss, \'local_mask\': local_mask_loss}\n        debug_dict = {\'segmentation\': segmentation_gt, \'boundary\': boundary_gt}\n        pass\n    return loss, loss_dict, debug_dict\n    #return loss, plane_loss, depth_loss + local_score_loss + local_p_loss + local_mask_loss + boundary_loss, forward_loss, backward_loss, segmentation_gt, plane_mask, errorMask, dists\n    #return loss, plane_loss, segmentation_loss, loss_p_0, depth_loss, segmentation_test, plane_mask, errorMask, dists\n\n\ndef main(options):\n    if not os.path.exists(options.checkpoint_dir):\n        os.system(""mkdir -p %s""%options.checkpoint_dir)\n        pass\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n    \n    min_after_dequeue = 1000\n\n    reader_train = RecordReader()\n    filename_queue_train = tf.train.string_input_producer([\'/mnt/vision/SUNCG_plane/planes_test_450000.tfrecords\'], num_epochs=10000)\n    img_inp_train, global_gt_dict_train, local_gt_dict_train = reader_train.getBatch(filename_queue_train, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True, random=False)\n\n    reader_val = RecordReader()\n    filename_queue_val = tf.train.string_input_producer([\'/home/chenliu/Projects/Data/SUNCG_plane/planes_test_1000_450000.tfrecords\'], num_epochs=10000)\n    img_inp_val, global_gt_dict_val, local_gt_dict_val = reader_val.getBatch(filename_queue_val, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True)\n\n    reader_rgbd_train = RecordReaderRGBD()\n    filename_queue_rgbd_train = tf.train.string_input_producer([\'../planes_nyu_rgbd_train.tfrecords\'], num_epochs=10000)\n    img_inp_rgbd_train, global_gt_dict_rgbd_train, local_gt_dict_rgbd_train = reader_rgbd_train.getBatch(filename_queue_rgbd_train, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True)\n\n    reader_rgbd_val = RecordReaderRGBD()\n    filename_queue_rgbd_val = tf.train.string_input_producer([\'../planes_nyu_rgbd_train.tfrecords\'], num_epochs=10000)\n    img_inp_rgbd_val, global_gt_dict_rgbd_val, local_gt_dict_rgbd_val = reader_rgbd_val.getBatch(filename_queue_rgbd_val, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True)\n\n    \n    training_flag = tf.placeholder(tf.int32, shape=[], name=\'training_flag\')\n    \n    global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp_train, img_inp_val, img_inp_rgbd_train, img_inp_rgbd_val, training_flag, options)\n\n    var_to_restore = [v for v in tf.global_variables()]\n\n    \n    loss, loss_dict, _ = build_loss(global_pred_dict, local_pred_dict, deep_pred_dicts, global_gt_dict_train, local_gt_dict_train, global_gt_dict_val, local_gt_dict_val, training_flag, options)\n    loss_rgbd, loss_dict_rgbd, _ = build_loss_rgbd(global_pred_dict, local_pred_dict, deep_pred_dicts, global_gt_dict_rgbd_train, local_gt_dict_rgbd_train, global_gt_dict_rgbd_val, local_gt_dict_rgbd_val, training_flag, options)\n    \n    loss = tf.cond(tf.less(training_flag, 2), lambda: loss, lambda: loss_rgbd)\n\n    \n    train_writer = tf.summary.FileWriter(options.log_dir + \'/train\')\n    val_writer = tf.summary.FileWriter(options.log_dir + \'/val\')\n    train_writer_rgbd = tf.summary.FileWriter(options.log_dir + \'/train_rgbd\')\n    val_writer_rgbd = tf.summary.FileWriter(options.log_dir + \'/val_rgbd\')\n    writers = [train_writer, val_writer, train_writer_rgbd, val_writer_rgbd]\n    \n    tf.summary.scalar(\'loss\', loss)\n    summary_op = tf.summary.merge_all()\n\n    with tf.variable_scope(\'statistics\'):\n        batchno = tf.Variable(0, dtype=tf.int32, trainable=False, name=\'batchno\')\n        batchnoinc=batchno.assign(batchno+1)\n        pass\n\n\n    optimizer = tf.train.AdamOptimizer(options.LR)\n    train_op = optimizer.minimize(loss, global_step=batchno)\n\n    \n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n    saver=tf.train.Saver()\n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n        if options.restore == 0:\n            #fine-tune from DeepLab model\n            var_to_restore = [v for v in var_to_restore if \'res5d\' not in v.name and \'segmentation\' not in v.name and \'plane\' not in v.name and \'deep_supervision\' not in v.name and \'local\' not in v.name and \'boundary\' not in v.name and \'degridding\' not in v.name]\n            pretrained_model_loader = tf.train.Saver(var_to_restore)\n            pretrained_model_loader.restore(sess,""../pretrained_models/deeplab_resnet.ckpt"")\n        elif options.restore == 1:\n            #restore the same model from checkpoint\n            loader = tf.train.Saver(var_to_restore)\n            loader.restore(sess,""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n            bno=sess.run(batchno)\n            print(bno)\n        elif options.restore == 2:            \n            #restore the same model from checkpoint but reset batchno to 1\n            loader = tf.train.Saver(var_to_restore)\n            loader.restore(sess,""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n            sess.run(batchno.assign(1))\n        elif options.restore == 3:\n            #restore the same model from standard training\n            loader = tf.train.Saver(var_to_restore)\n            loader.restore(sess,""checkpoint/planenet/checkpoint.ckpt"")\n            sess.run(batchno.assign(1))\n        elif options.restore == 4:\n            #fine-tune another model\n            var_to_restore = [v for v in var_to_restore if \'res4b22_relu_non_plane\' not in v.name]\n            loader = tf.train.Saver(var_to_restore)\n            loader.restore(sess, options.fineTuningCheckpoint)\n            sess.run(batchno.assign(1))\n            pass\n        # Start input enqueue threads.\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n        MOVING_AVERAGE_DECAY = 0.99\n        ema = [0., 0., 0., 0.]\n        ema_acc = [1e-10, 1e-10, 1e-10, 1e-10]\n        last_snapshot_time = time.time()\n        bno=sess.run(batchno)\n\n        try:\n            while bno<300000:\n                t0 = time.time()\n\n                batchIndexPeriod = bno % 100\n                if batchIndexPeriod == 0:\n                    batchType = 1\n                elif batchIndexPeriod == 1:\n                    if options.hybrid == 0:\n                        batchType = 1\n                    else:\n                        batchType = 3\n                        pass\n                elif batchIndexPeriod % 10 == 0:\n                    if options.hybrid == 0:\n                        batchType = 0\n                    else:\n                        batchType = 2\n                        pass\n                else:\n                    batchType = 0\n                    pass\n\n                _, total_loss, losses, summary_str = sess.run([train_op, loss, loss_dict, summary_op], feed_dict = {training_flag: batchType})\n                writers[batchType].add_summary(summary_str, bno)\n                ema[batchType] = ema[batchType] * MOVING_AVERAGE_DECAY + total_loss\n                ema_acc[batchType] = ema_acc[batchType] * MOVING_AVERAGE_DECAY + 1\n\n                bno = sess.run(batchno)\n                if time.time()-last_snapshot_time > 900:\n                    print(\'save snapshot\')\n                    saver.save(sess,\'%s/checkpoint.ckpt\'%options.checkpoint_dir)\n                    last_snapshot_time = time.time()\n                    pass\n        \n                print bno,\'train\', ema[0] / ema_acc[0], \'val\', ema[1] / ema_acc[1], \'train rgbd\', ema[2] / ema_acc[2], \'val rgbd\', ema[3] / ema_acc[3], \'loss\', total_loss, \'time\', time.time()-t0\n                continue\n\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n        \n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return\n\n\ndef test(options):\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n    \n    options.batchSize = 1\n    min_after_dequeue = 1000\n\n    if options.dataset == \'SUNCG\':\n        reader = RecordReader()\n        filename_queue = tf.train.string_input_producer([\'/home/chenliu/Projects/Data/SUNCG_plane/planes_test_1000_450000.tfrecords\'], num_epochs=10000)\n        img_inp, global_gt_dict, local_gt_dict = reader.getBatch(filename_queue, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True, random=False)\n    else:\n        reader = RecordReaderRGBD()\n        filename_queue = tf.train.string_input_producer([\'../planes_nyu_rgbd_train.tfrecords\'], num_epochs=1)\n        img_inp, global_gt_dict, local_gt_dict = reader.getBatch(filename_queue, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True, random=False)\n\n        options.deepSupervision = 0\n        options.predictLocal = 0\n        pass\n\n    training_flag = tf.constant(1, tf.int32)\n\n    global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp, img_inp, img_inp, img_inp, training_flag, options)\n    var_to_restore = tf.global_variables()\n\n    if options.dataset == \'SUNCG\':\n        loss, loss_dict, debug_dict = build_loss(global_pred_dict, local_pred_dict, deep_pred_dicts, global_gt_dict, local_gt_dict, global_gt_dict, local_gt_dict, training_flag, options)\n    else:\n        loss, loss_dict, debug_dict = build_loss_rgbd(global_pred_dict, local_pred_dict, deep_pred_dicts, global_gt_dict, local_gt_dict, global_gt_dict, local_gt_dict, training_flag, options)\n        pass\n\n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n    \n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n        #var_to_restore = [v for v in var_to_restore if \'res4b22_relu_non_plane\' not in v.name]\n        loader = tf.train.Saver(var_to_restore)\n        loader.restore(sess, ""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n        #loader.restore(sess, options.fineTuningCheckpoint)\n        \n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n        \n        \n        try:\n            gtDepths = []\n            predDepths = []\n            planeMasks = []\n            #predMasks = []\n            \n            imageWidth = WIDTH\n            imageHeight = HEIGHT\n            focalLength = 517.97\n            urange = np.arange(imageWidth).reshape(1, -1).repeat(imageHeight, 0) - imageWidth * 0.5\n            vrange = np.arange(imageHeight).reshape(-1, 1).repeat(imageWidth, 1) - imageHeight * 0.5\n            ranges = np.array([urange / imageWidth * 640 / focalLength, np.ones(urange.shape), -vrange / imageHeight * 480 / focalLength]).transpose([1, 2, 0])\n\n\n            for index in xrange(10):\n                print((\'image\', index))\n                t0=time.time()\n\n                img, global_gt, local_gt, global_pred, local_pred, deep_preds, total_loss, losses, debug = sess.run([img_inp, global_gt_dict, local_gt_dict, global_pred_dict, local_pred_dict, deep_pred_dicts, loss, loss_dict, debug_dict])\n\n                if False:\n                    image = ((img[0] + 0.5) * 255).astype(np.uint8)\n                    depth = global_pred[\'non_plane_depth\'].squeeze()\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', image)\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth.png\', drawDepthImage(depth))\n                    planes, planeSegmentation, depthPred = fitPlanes(depth, numPlanes=20)\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(planeSegmentation))\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(depthPred))\n\n                    gtDepths.append(global_gt[\'depth\'].squeeze())\n                    predDepths.append(depthPred)\n                    planeMasks.append((planeSegmentation < 20).astype(np.float32))\n                    continue        \n                print((losses[\'plane\'], losses[\'segmentation\'], losses[\'depth\']))\n                if index >= 10:\n                    continue\n                  \n                im = img[0]\n                image = ((im + 0.5) * 255).astype(np.uint8)                \n\n                gt_d = global_gt[\'depth\'].squeeze()\n                \n                if \'normal\' in global_gt:\n                    gt_n = global_gt[\'normal\'][0]\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal.png\', drawNormalImage(gt_n))\n                    pass\n                  \n\n                if options.predictLocal:\n                    pred_local_s = 1 / (1 + np.exp(-local_pred[\'score\'][0]))\n                    pred_local_p = local_pred[\'plane\'][0]\n                    pred_local_m = local_pred[\'mask\'][0]\n                  \n                    gt_local_s = local_gt[\'score\'][0]\n                    gt_local_m = local_gt[\'mask\'][0]\n\n                    #visualize local plane prediction\n                    stride = 8\n                    boxSize = 64\n                    xs = np.arange(WIDTH / stride) * stride + stride / 2\n                    ys = np.arange(HEIGHT / stride) * stride + stride / 2\n                    padding = boxSize / 2 + 1\n                    maskImage = np.zeros((HEIGHT + padding * 2, WIDTH + padding * 2, 3), dtype=np.uint8)\n                    maskImage[padding:padding + HEIGHT, padding:padding + WIDTH, :] = image / 2\n                    for gridY, y in enumerate(ys):\n                        for gridX, x in enumerate(xs):\n                            score = pred_local_s[gridY][gridX]\n                            if score < 0.5:\n                                continue                              \n                            mask = pred_local_m[gridY][gridX].reshape([16, 16])        \n                            mask = cv2.resize(mask, (boxSize, boxSize))\n                            maskImage[y - boxSize / 2 + padding:y + boxSize / 2 + padding, x - boxSize / 2 + padding:x + boxSize / 2 + padding, 0][mask > 0.5] = 255\n                            continue\n                        continue\n                    for gridY, y in enumerate(ys):\n                        for gridX, x in enumerate(xs):\n                            score = gt_local_s[gridY][gridX]\n                            if score < 0.5:\n                                continue                              \n                            mask = gt_local_m[gridY][gridX].reshape([16, 16])        \n                            mask = cv2.resize(mask, (boxSize, boxSize))\n                            maskImage[y - boxSize / 2 + padding:y + boxSize / 2 + padding, x - boxSize / 2 + padding:x + boxSize / 2 + padding, 2][mask > 0.5] = 255\n                            continue\n                        continue\n                    pass\n\n                pred_p = global_pred[\'plane\'][0]\n                pred_s = global_pred[\'segmentation\'][0]\n\n                pred_np_m = global_pred[\'non_plane_mask\'][0]\n                pred_np_d = global_pred[\'non_plane_depth\'][0]\n                pred_np_n = global_pred[\'non_plane_normal\'][0]\n                \n                if \'plane_mask\' in debug:\n                    planeMask = np.squeeze(debug[\'plane_mask\'])\n                else:\n                    #planeMask = np.ones((HEIGHT, WIDTH))\n                    planeMask = (np.max(pred_s, axis=2) > pred_np_m.squeeze()).astype(np.float32)\n                    pass\n                \n                if \'segmentation\' in global_gt:\n                    gt_s = global_gt[\'segmentation\'][0]\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_gt.png\', drawSegmentationImage(gt_s, planeMask=planeMask, numColors = 51))\n                    pass\n                  \n\n\n                if options.predictConfidence:\n                    pred_p_c = global_pred[\'confidence\'][0]\n                    pred_p_c = 1 / (1 + np.exp(-pred_p_c))\n                    numPlanes = global_gt[\'num_planes\'][0]\n                    print((numPlanes, (pred_p_c > 0.5).sum()))\n                    pass\n                  \n                if False:\n                    #dump results for post processing\n                    if index >= 10:\n                        break\n                    np.save(options.dump_dir + \'/planes_\' + str(index) + \'.npy\', pred_p)\n                    np.save(options.dump_dir + \'/segmentations_\' + str(index) + \'.npy\', pred_s)\n                    np.save(options.dump_dir + \'/segmentations_gt_\' + str(index) + \'.npy\', gt_s)\n                    np.save(options.dump_dir + \'/non_plane_depth_\' + str(index) + \'.npy\', pred_np_d)\n                    np.save(options.dump_dir + \'/non_plane_segmentation_\' + str(index) + \'.npy\', pred_np_m)\n                    boundary = pred_boundary[0]\n                    boundary = 1 / (1 + np.exp(-boundary))\n                    boundary = np.concatenate([boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)                    \n                    cv2.imwrite(options.dump_dir + \'/boundary_\' + str(index) + \'.png\', drawMaskImage(boundary))\n                    cv2.imwrite(options.dump_dir + \'/image_\' + str(index) + \'.png\', cv2.resize(image, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR))\n                    np.save(options.dump_dir + \'/depth_\' + str(index) + \'.npy\', gt_d)\n                    continue                \n\n                  \n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', image)\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth.png\', drawDepthImage(gt_d))\n\n                if options.predictBoundary:\n                    pred_boundary = global_pred[\'boundary\'][0]\n                    pred_boundary = 1 / (1 + np.exp(-pred_boundary))\n                    boundary = np.concatenate([pred_boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_boundary_pred.png\', drawMaskImage(boundary))\n                    pass\n\n                if \'boundary\' in debug:\n                    gt_boundary = debug[\'boundary\'][0]\n                    boundary = np.concatenate([gt_boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)                \n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_boundary_gt.png\', drawMaskImage(boundary))\n                    pass\n\n\n                if options.deepSupervision >= 1:\n                    segmentation_deep = np.argmax(deep_preds[0][\'segmentation\'][0], 2)\n                    segmentation_deep[segmentation_deep == options.numOutputPlanes] = -1\n                    segmentation_deep += 1\n                \n                    plane_depths_deep = calcPlaneDepths(deep_preds[0][\'plane\'][0], WIDTH, HEIGHT)\n                    all_depths_deep = np.concatenate([pred_np_d, plane_depths_deep], axis=2)\n                    pred_d_deep = all_depths_deep.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation_deep.reshape(-1)].reshape(HEIGHT, WIDTH)\n                \n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred_0.png\', drawSegmentationImage(deep_preds[0][\'segmentation\'][0]))\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred_0.png\', drawDepthImage(pred_d_deep))\n                    pass\n\n\n                #print(pred_np_m)\n                #print(pred_s)\n                #print(global_gt[\'plane\'][0])\n                #print(pred_p)\n                #exit(1)                \n                all_segmentations = np.concatenate([pred_np_m, pred_s], axis=2)\n                plane_depths = calcPlaneDepths(pred_p, WIDTH, HEIGHT)\n                all_depths = np.concatenate([pred_np_d, plane_depths], axis=2)\n\n\n                segmentation = np.argmax(all_segmentations, 2)\n                pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape(HEIGHT, WIDTH)\n \n                \n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(all_segmentations, black=True))\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))                \n\n                gtDepths.append(gt_d)\n                planeMasks.append(planeMask)\n                predDepths.append(pred_d)\n                evaluateDepths(predDepths[-1], gtDepths[-1], np.ones(planeMasks[-1].shape), planeMasks[-1])\n                \n                #print(np.concatenate([np.arange(options.numOutputPlanes).reshape(-1, 1), planes, pred_p, preds_p[0][0]], axis=1))\n\n                #print(np.concatenate([distance[0], preds_p[0][0], pred_p], axis=1))\n                            \n                #segmentation = np.argmax(pred_s, 2)\n                #writePLYFile(options.test_dir, index, image, pred_d, segmentation, np.zeros(pred_boundary[0].shape))\n                #writePLYFileParts(options.test_dir, index, image, pred_d, segmentation)\n                #gt_s_ori = gt_s_ori[0]\n                #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_gt_ori.png\', drawSegmentationImage(gt_s_ori, planeMask=np.max(gt_s_ori, 2) > 0.5, numColors=51))\n                \n                if False:\n                    #distance = distance[0]\n                    print(distance)\n                    diff = np.linalg.norm(np.expand_dims(planes, 1) - np.expand_dims(pred_p, 0), axis=2)\n                    print(np.concatenate([planes, pred_p, pow(np.min(diff, axis=1, keepdims=True), 2), np.expand_dims(np.argmin(diff, axis=1), -1)], axis=1))\n                    print(pred_p_c)\n                    \n                    #print(distance[:, 6:8].sum(0))\n                    #print(pow(np.linalg.norm(distance[:, :3] - distance[:, 3:6], 2, 1), 2) * 100)\n                    #print(test)\n                    segmentation = np.argmax(all_segmentations, 2) - 1\n                    for planeIndex in xrange(options.numOutputPlanes):\n                        cv2.imwrite(options.test_dir + \'/segmentation_\' + str(planeIndex) + \'.png\', drawMaskImage(segmentation == planeIndex))\n                        cv2.imwrite(options.test_dir + \'/segmentation_\' + str(planeIndex) + \'_gt.png\', drawMaskImage(gt_s[:, :, planeIndex]))\n                        cv2.imwrite(options.test_dir + \'/segmentation_\' + str(planeIndex) + \'_gt_ori.png\', drawMaskImage(gt_s_ori[:, :, planeIndex]))\n                        continue\n                    exit(1)\n                continue\n\n            predDepths = np.array(predDepths)\n            gtDepths = np.array(gtDepths)\n            planeMasks = np.array(planeMasks)\n            #predMasks = np.array(predMasks)\n            evaluateDepths(predDepths, gtDepths, np.ones(planeMasks.shape, dtype=np.bool), planeMasks)\n            exit(1)\n\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n        \n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return\n\n\ndef predict(options):\n    options.test_dir += \'_predict\'\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n\n    batchSize = 1\n    img_inp = tf.placeholder(tf.float32,shape=(batchSize,HEIGHT,WIDTH,3),name=\'img_inp\')\n    plane_gt=tf.placeholder(tf.float32,shape=(batchSize,options.numOutputPlanes, 3),name=\'plane_inp\')\n    validating_inp = tf.constant(0, tf.int32)\n\n    global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp_train, img_inp_val, img_inp_rgbd_train, img_inp_rgbd_val, training_flag, options)\n\n    var_to_restore = tf.global_variables()\n    \n \n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n\n\n    if dataset == \'SUNCG\':\n        image_list_file = os.path.join(\'../PythonScripts/SUNCG/image_list_100_tail_500000.txt\')\n        with open(image_list_file) as f:\n            im_names = [{\'image\': im_name.strip().replace(\'plane_global.npy\', \'mlt.png\'), \'depth\': im_name.strip().replace(\'plane_global.npy\', \'depth.png\'), \'normal\': im_name.strip().replace(\'plane_global.npy\', \'norm_camera.png\'), \'valid\': im_name.strip().replace(\'plane_global.npy\', \'valid.png\'), \'plane\': im_name.strip()} for im_name in f.readlines()]\n            pass\n    else:\n        im_names = glob.glob(\'../../Data/NYU_RGBD/*_color.png\')\n        im_names = [{\'image\': im_name, \'depth\': im_name.replace(\'color.png\', \'depth.png\'), \'normal\': im_name.replace(\'color.png\', \'norm_camera.png\'), \'invalid_mask\': im_name.replace(\'color.png\', \'valid.png\')} for im_name in im_names]\n        pass\n      \n    if numImages > 0:\n        im_names = im_names[:numImages]\n        pass\n\n    #if args.imageIndex > 0:\n    #im_names = im_names[args.imageIndex:args.imageIndex + 1]\n    #pass    \n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n\n    with tf.Session(config=config) as sess:\n        saver = tf.train.Saver()\n        #sess.run(tf.global_variables_initializer())\n        saver.restore(sess,""%s/%s.ckpt""%(options.checkpoint_dir,keyname))\n\n        gtDepths = []\n        predDepths = []\n        segmentationDepths = []\n        predDepthsOneHot = []\n        planeMasks = []\n        predMasks = []\n\n        imageWidth = WIDTH\n        imageHeight = HEIGHT\n        focalLength = 517.97\n        urange = np.arange(imageWidth).reshape(1, -1).repeat(imageHeight, 0) - imageWidth * 0.5\n        vrange = np.arange(imageHeight).reshape(-1, 1).repeat(imageWidth, 1) - imageHeight * 0.5\n        ranges = np.array([urange / focalLength, np.ones(urange.shape), -vrange / focalLength]).transpose([1, 2, 0])\n        \n        cv2.imwrite(options.test_dir + \'/one.png\', np.ones((HEIGHT, WIDTH), dtype=np.uint8) * 255)\n        cv2.imwrite(options.test_dir + \'/zero.png\', np.zeros((HEIGHT, WIDTH), dtype=np.uint8) * 255)\n        for index, im_name in enumerate(im_names):\n            if index <= -1:\n                continue\n            print(im_name[\'image\'])\n            im = cv2.imread(im_name[\'image\'])\n            image = im.astype(np.float32, copy=False)\n            image = image / 255 - 0.5\n            image = cv2.resize(image, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n\n            #planes = np.load(im_name[\'plane\'])\n            # numPlanes = planes.shape[0]\n            # if numPlanes > options.numOutputPlanes:\n            #     planeAreas = planes[:, 3:].sum(1)\n            #     sortInds = np.argsort(planeAreas)[::-1]\n            #     planes = planes[sortInds[:options.numOutputPlanes]]\n            #     pass\n            # gt_p = np.zeros((1, options.numOutputPlanes, 3))\n            # gt_p[0, :numPlanes] = planes[:numPlanes, :3]\n\n            normal = np.array(PIL.Image.open(im_name[\'normal\'])).astype(np.float) / 255 * 2 - 1\n            norm = np.linalg.norm(normal, 2, 2)\n            for c in xrange(3):\n                normal[:, :, c] /= norm\n                continue\n            normal = cv2.resize(normal, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n            \n            depth = np.array(PIL.Image.open(im_name[\'depth\'])).astype(np.float) / 1000\n            depth = cv2.resize(depth, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n\n            invalid_mask = cv2.resize(cv2.imread(im_name[\'invalid_mask\'], 0), (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR) > 128\n\n            gtDepths.append(depth)\n\n            \n            pred_p, pred_d, pred_n, pred_s, pred_np_m, pred_np_d, pred_np_n, pred_boundary, pred_local_score, pred_local_p, pred_local_mask = sess.run([plane_pred, depth_pred, normal_pred, segmentation_pred, non_plane_mask_pred, non_plane_depth_pred, non_plane_normal_pred, boundary_pred, local_score_pred, local_p_pred, local_mask_pred], feed_dict = {img_inp:np.expand_dims(image, 0), plane_gt: np.zeros((batchSize, options.numOutputPlanes, 3))})\n\n\n            pred_s = pred_s[0] \n            pred_p = pred_p[0]\n            pred_np_m = pred_np_m[0]\n            pred_np_d = pred_np_d[0]\n            pred_np_n = pred_np_n[0]\n            #pred_s = 1 / (1 + np.exp(-pred_s))\n\n            plane_depths = calcPlaneDepths(pred_p, WIDTH, HEIGHT)\n            all_depths = np.concatenate([pred_np_d, plane_depths], axis=2)\n\n            all_segmentations = np.concatenate([pred_np_m, pred_s], axis=2)\n            segmentation = np.argmax(all_segmentations, 2)\n            if suffix != \'pixelwise\':\n                pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape(HEIGHT, WIDTH)\n            else:\n                pred_d = np.squeeze(pred_np_d)\n                pass\n            predDepths.append(pred_d)\n            predMasks.append(segmentation != 0)\n            planeMasks.append(invalid_mask)\n\n            #depthError, normalError, occupancy, segmentationTest, reconstructedDepth, occupancyMask = evaluatePlanes(pred_p, im_name[\'image\'])\n            #reconstructedDepth = cv2.resize(reconstructedDepth, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n            \n            #evaluatePlanes(pred_p[0], im_name, options.test_dir, index)\n            #print(pred_p)\n            #print(gt_p)\n            #print((pow(pred_d[0, :, :, 0] - depth, 2) * (gt_s.max(2) > 0.5)).mean())\n            #print((depthError, normalError, occupancy))\n            \n            evaluateDepths(predDepths[index], gtDepths[index], np.ones(planeMasks[index].shape), planeMasks[index])\n\n            if index >= 10:\n                continue\n            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', cv2.resize(im, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR))\n            #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_gt.png\', (minDepth / np.clip(depth, minDepth, 20) * 255).astype(np.uint8))\n            #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', (minDepth / np.clip(pred_d[0, :, :, 0], minDepth, 20) * 255).astype(np.uint8))\n            #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_plane.png\', (minDepth / np.clip(reconstructedDepth, minDepth, 20) * 255).astype(np.uint8))\n\n            pred_boundary = pred_boundary[0]\n            boundary = (1 / (1 + np.exp(-pred_boundary)) * 255).astype(np.uint8)\n            boundary = np.concatenate([boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)\n            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_boundary_pred.png\', boundary)\n            \n            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_inp.png\', drawDepthImage(depth))\n            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n            #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_plane.png\', drawDepthImage(reconstructedDepth))\n            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred_diff.png\', drawDiffImage(pred_d, depth, 0.5))\n            #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_plane_diff.png\', np.minimum(np.abs(reconstructedDepth - depth) / 0.5 * 255, 255).astype(np.uint8))\n            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_inp.png\', drawNormalImage(normal))\n            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_pred.png\', drawNormalImage(pred_np_n))\n            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(all_segmentations, black=True))\n\n            segmentation = np.argmax(pred_s, 2)\n            #writePLYFile(options.test_dir, index, image, pred_p, segmentation)\n\n            if index < 0:\n                for planeIndex in xrange(options.numOutputPlanes):\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_\' + str(planeIndex) + \'.png\', drawMaskImage(pred_s[:, :, planeIndex]))\n                    #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_\' + str(planeIndex) + \'_gt.png\', drawMaskImage(gt_s[:, :, planeIndex]))\n                    continue\n                pass\n            continue\n        predDepths = np.array(predDepths)\n        gtDepths = np.array(gtDepths)\n        planeMasks = np.array(planeMasks)\n        predMasks = np.array(predMasks)\n        #evaluateDepths(predDepths, gtDepths, planeMasks, predMasks)\n        evaluateDepths(predDepths, gtDepths, planeMasks, planeMasks)\n        #exit(1)\n        pass\n    return\n\n\ndef fitPlanesRGBD(options):\n    writeHTMLRGBD(\'../results/RANSAC_RGBD/index.html\', 10)\n    exit(1)\n    if not os.path.exists(options.checkpoint_dir):\n        os.system(""mkdir -p %s""%options.checkpoint_dir)\n        pass\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n    \n    min_after_dequeue = 1000\n\n    reader_rgbd = RecordReaderRGBD()\n    filename_queue_rgbd = tf.train.string_input_producer([\'../planes_nyu_rgbd_train.tfrecords\'], num_epochs=1)\n    img_inp_rgbd, global_gt_dict_rgbd, local_gt_dict_rgbd = reader_rgbd.getBatch(filename_queue_rgbd, numOutputPlanes=options.numOutputPlanes, batchSize=1, min_after_dequeue=min_after_dequeue, getLocal=True)\n\n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n        try:\n            gtDepths = []\n            predDepths = []\n            planeMasks = []\n            for index in xrange(10):\n                image, depth, path = sess.run([img_inp_rgbd, global_gt_dict_rgbd[\'depth\'], global_gt_dict_rgbd[\'path\']])\n                image = ((image[0] + 0.5) * 255).astype(np.uint8)\n                depth = depth.squeeze()\n                \n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', image)\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth.png\', drawDepthImage(depth))\n                #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_mask.png\', drawMaskImage(depth == 0))\n                planes, planeSegmentation, depthPred = fitPlanes(depth, numPlanes=20)                \n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(planeSegmentation))\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(depthPred))\n\n                gtDepths.append(depth)\n                predDepths.append(depthPred)\n                planeMasks.append((planeSegmentation < 20).astype(np.float32))\n                continue\n            predDepths = np.array(predDepths)\n            gtDepths = np.array(gtDepths)\n            planeMasks = np.array(planeMasks)\n            evaluateDepths(predDepths, gtDepths, np.ones(planeMasks.shape, dtype=np.bool), planeMasks)            \n        except tf.errors.OutOfRangeError:\n            print(\'done fitting\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n    return\n\ndef parse_args():\n    """"""\n    Parse input arguments\n    """"""\n    parser = argparse.ArgumentParser(description=\'Planenet\')\n    parser.add_argument(\'--gpu\', dest=\'gpu_id\',\n                        help=\'GPU device id to use [0]\',\n                        default=0, type=int)\n    #task: [train, test, predict]\n    parser.add_argument(\'--task\', dest=\'task\',\n                        help=\'task type: [train, test, predict]\',\n                        default=\'train\', type=str)\n    parser.add_argument(\'--restore\', dest=\'restore\',\n                        help=\'how to restore the model\',\n                        default=0, type=int)\n    parser.add_argument(\'--numOutputPlanes\', dest=\'numOutputPlanes\',\n                        help=\'the number of output planes\',\n                        default=30, type=int)\n    parser.add_argument(\'--numConcaveGroups\', dest=\'numConcaveGroups\',\n                        help=\'the number of concave groups\',\n                        default=3, type=int)\n    parser.add_argument(\'--numConvexGroups\', dest=\'numConvexGroups\',\n                        help=\'the number of convex groups\',\n                        default=5, type=int)\n    parser.add_argument(\'--batchSize\', dest=\'batchSize\',\n                        help=\'batch size\',\n                        default=16, type=int)\n    parser.add_argument(\'--dataset\', dest=\'dataset\',\n                        help=\'dataset name for test/predict\',\n                        default=\'SUNCG\', type=str)\n    parser.add_argument(\'--numImages\', dest=\'numImages\',\n                        help=\'the number of images to test/predict\',\n                        default=100, type=int)\n    parser.add_argument(\'--boundaryLoss\', dest=\'boundaryLoss\',\n                        help=\'use boundary loss: [0, 1]\',\n                        default=1, type=int)\n    parser.add_argument(\'--diverseLoss\', dest=\'diverseLoss\',\n                        help=\'use diverse loss: [0, 1]\',\n                        default=1, type=int)\n    parser.add_argument(\'--deepSupervision\', dest=\'deepSupervision\',\n                        help=\'deep supervision level: [0, 1, 2]\',\n                        default=1, type=int)\n    parser.add_argument(\'--sameMatching\', dest=\'sameMatching\',\n                        help=\'use the matching for all deep supervision layers and the final prediction: [0, 1]\',\n                        default=1, type=int)    \n    parser.add_argument(\'--crf\', dest=\'crf\',\n                        help=\'the number of CRF iterations\',\n                        default=0, type=int)\n    parser.add_argument(\'--backwardLossWeight\', dest=\'backwardLossWeight\',\n                        help=\'backward matching loss\',\n                        default=0, type=float)\n    parser.add_argument(\'--predictBoundary\', dest=\'predictBoundary\',\n                        help=\'whether predict boundary or not: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--predictLocal\', dest=\'predictLocal\',\n                        help=\'whether predict local planes or not: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--predictConfidence\', dest=\'predictConfidence\',\n                        help=\'whether predict plane confidence or not: [0, 1]\',\n                        default=0, type=int)        \n    parser.add_argument(\'--fineTuningCheckpoint\', dest=\'fineTuningCheckpoint\',\n                        help=\'specify the model for fine-tuning\',\n                        default=\'../PlaneSetGeneration/dump_planenet_diverse/train_planenet_diverse.ckpt\', type=str)\n    parser.add_argument(\'--suffix\', dest=\'suffix\',\n                        help=\'add a suffix to keyname to distinguish experiments\',\n                        default=\'\', type=str)\n    parser.add_argument(\'--l2Weight\', dest=\'l2Weight\',\n                        help=\'L2 regulation weight\',\n                        default=5e-4, type=float)\n    parser.add_argument(\'--LR\', dest=\'LR\',\n                        help=\'learning rate\',\n                        default=3e-5, type=float)\n    parser.add_argument(\'--hybrid\', dest=\'hybrid\',\n                        help=\'hybrid training\',\n                        default=0, type=int)\n    \n\n    args = parser.parse_args()\n    args.keyname = os.path.basename(__file__).rstrip(\'.py\')\n    args.keyname = args.keyname.replace(\'train_\', \'\')\n\n    if args.numOutputPlanes != 30:\n        args.keyname += \'_np\' + str(args.numOutputPlanes)\n        pass\n    if args.boundaryLoss == 0:\n        args.keyname += \'_bl0\'\n        pass\n    if args.diverseLoss == 0:\n        args.keyname += \'_dl0\'\n        pass\n    if args.deepSupervision != 1:\n        args.keyname += \'_ds\' + str(args.deepSupervision)\n        pass\n    if args.crf > 0:\n        args.keyname += \'_crf\' + str(args.crf)\n        pass\n    if args.backwardLossWeight > 0:\n        args.keyname += \'_bw\'\n        pass    \n    if args.predictBoundary == 1:\n        args.keyname += \'_pb\'\n        pass\n    if args.predictLocal == 1:\n        args.keyname += \'_pl\'\n        pass\n    if args.predictConfidence == 1:\n        args.keyname += \'_pc\'\n        pass    \n    if args.sameMatching == 0:\n        args.keyname += \'_sm0\'\n        pass\n    if args.hybrid > 0:\n        args.keyname += \'_hybrid\' + str(args.hybrid)\n        pass\n    \n    args.checkpoint_dir = \'checkpoint/\' + args.keyname\n    args.log_dir = \'log/\' + args.keyname\n    args.test_dir = \'test/\' + args.keyname + \'_\' + args.dataset\n    args.predict_dir = \'predict/\' + args.keyname + \'_\' + args.dataset\n    args.dump_dir = \'dump/\' + args.keyname\n    \n    #layers where deep supervision happens\n    args.deepSupervisionLayers = []\n    if args.deepSupervision >= 1:\n        args.deepSupervisionLayers.append(\'res4b22_relu\')\n        pass\n    if args.deepSupervision >= 2:\n        args.deepSupervisionLayers.append(\'res4b12_relu\')\n        pass\n    return args\n\n\nif __name__==\'__main__\':\n    args = parse_args()\n\n    print ""keyname=%s task=%s started""%(args.keyname, args.task)\n    try:\n        if args.task == ""train"":\n            main(args)\n        elif args.task == ""test"":\n            test(args)\n        elif args.task == ""predict"":\n            predict(args)\n        elif args.task == ""fit"":\n            fitPlanesRGBD(args)\n        else:\n            assert False,""format wrong""\n            pass\n    finally:\n        pass\n\n'"
code/train_hybrid.py,151,"b'import tensorflow as tf\nimport numpy as np\nnp.set_printoptions(precision=2, linewidth=200)\nimport cv2\nimport os\nimport time\nimport sys\nimport tf_nndistance\nimport argparse\nimport glob\nimport PIL\nimport scipy.ndimage as ndimage\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom utils import *\nfrom plane_utils import *\nfrom modules import *\n\n\nfrom planenet import PlaneNet\nfrom RecordReader import *\nfrom RecordReaderRGBD import *\nfrom RecordReader3D import *\nfrom RecordReaderAll import *\nfrom crfasrnn_layer import CrfRnnLayer\nfrom train_sample import build_graph as build_graph\n\n#from SegmentationRefinement import *\n\n#training_flag: toggle dropout and batch normalization mode\n#it\'s true for training and false for validation, testing, prediction\n#it also controls which data batch to use (*_train or *_val)\n\n\ndef build_loss(img_inp_train, img_inp_val, global_pred_dict, deep_pred_dicts, global_gt_dict_train, global_gt_dict_val, training_flag, options):\n    with tf.device(\'/gpu:%d\'%options.gpu_id):\n        debug_dict = {}\n\n        img_inp = tf.cond(training_flag, lambda: img_inp_train, lambda: img_inp_val)\n        global_gt_dict = {}\n        for name in global_gt_dict_train.keys():\n            global_gt_dict[name] = tf.cond(training_flag, lambda: global_gt_dict_train[name], lambda: global_gt_dict_val[name])\n            continue\n        # local_gt_dict = {}\n        # for name in local_gt_dict_train.keys():\n        #     local_gt_dict[name] = tf.cond(tf.equal(training_flag % 2, 0), lambda: local_gt_dict_train[name], lambda: local_gt_dict_val[name])\n        #     continue\n\n        plane_parameters = tf.reshape(global_pred_dict[\'plane\'], (-1, 3))\n        info = global_gt_dict[\'info\'][0]\n        plane_depths = planeDepthsModule(plane_parameters, WIDTH, HEIGHT, info)\n        plane_depths = tf.transpose(tf.reshape(plane_depths, [HEIGHT, WIDTH, -1, options.numOutputPlanes]), [2, 0, 1, 3])\n\n        non_plane_depth = global_pred_dict[\'non_plane_depth\']\n        all_depths = tf.concat([plane_depths, non_plane_depth], axis=3)\n\n        \n        validPlaneMask = tf.cast(tf.less(tf.tile(tf.expand_dims(tf.range(options.numOutputPlanes), 0), [options.batchSize, 1]), tf.expand_dims(global_gt_dict[\'num_planes\'], -1)), tf.float32)        \n        backwardLossWeight = options.backwardLossWeight\n        \n        #plane loss and segmentation loss (summation over deep supervisions and final supervision)\n        all_pred_dicts = deep_pred_dicts + [global_pred_dict]\n        plane_loss = tf.constant(0.0)\n        segmentation_loss = tf.constant(0.0)\n        plane_confidence_loss = tf.constant(0.0)\n        diverse_loss = tf.constant(0.0)\n        \n        #keep forward map (segmentation gt) from previous supervision so that we can have same matching for all supervisions (options.sameMatching = 1)\n        previous_plane_gt = None\n        previous_plane_confidence_gt = None        \n        previous_segmentation_gt = None\n        if options.anchorPlanes:\n            anchors_np = np.load(\'dump/anchors_\' + options.hybrid + \'.npy\')\n            anchors = tf.reshape(tf.constant(anchors_np.reshape(-1)), anchors_np.shape)\n            anchors = tf.tile(tf.expand_dims(anchors, 0), [options.batchSize, 1, 1])\n            dists_forward, map_forward, dists_backward, _ = tf_nndistance.nn_distance(global_gt_dict[\'plane\'], anchors)\n                            \n            forward_map = tf.one_hot(map_forward, depth=options.numOutputPlanes, axis=-1)\n            forward_map *= tf.expand_dims(validPlaneMask, -1)\n                \n            #number of ground truth mapped for each prediction\n            num_matches = tf.transpose(tf.reduce_sum(forward_map, axis=1, keep_dims=True), [0, 2, 1])\n            previous_plane_gt = tf.transpose(tf.matmul(global_gt_dict[\'plane\'], forward_map, transpose_a=True), [0, 2, 1]) / tf.maximum(num_matches, 1e-4)\n            previous_plane_confidence_gt = tf.cast(num_matches > 0.5, tf.float32)\n\n            segmentation_gt_shuffled = tf.reshape(tf.matmul(tf.reshape(global_gt_dict[\'segmentation\'], [-1, HEIGHT * WIDTH, options.numOutputPlanes]), forward_map), [-1, HEIGHT, WIDTH, options.numOutputPlanes])\n            segmentation_gt_shuffled = tf.concat([segmentation_gt_shuffled, global_gt_dict[\'non_plane_mask\']], axis=3)\n            previous_segmentation_gt = segmentation_gt_shuffled\n            pass\n        \n        for pred_index, pred_dict in enumerate(all_pred_dicts):\n            if (options.sameMatching and pred_index > 0) or options.anchorPlanes:\n                #use matching from previous supervision and map ground truth planes based on the mapping\n\n                plane_loss += tf.reduce_mean(tf.squared_difference(pred_dict[\'plane\'], previous_plane_gt) * previous_plane_confidence_gt, axis=[1, 2, 3]) * 10000\n                \n                #all segmentations is the concatenation of plane segmentations and non plane mask\n                all_segmentations = tf.concat([pred_dict[\'segmentation\'], pred_dict[\'non_plane_mask\']], axis=3)\n\n                if options.crf > 0:\n                    all_segmentations_softmax = tf.nn.softmax(all_segmentations)          \n                    with tf.variable_scope(\'crf\'):\n                        planesY = global_pred_dict[\'plane\'][:, :, 1]\n                        planesD = tf.maximum(tf.norm(global_pred_dict[\'plane\'], axis=-1), 1e-4)\n                        planesY /= planesD\n                        planesY = tf.concat([planesY, tf.ones((options.batchSize, 1)) * 100], axis=1)\n\n                        imageDiff = calcImageDiff(img_inp)\n                        all_segmentations_softmax, _ = segmentationRefinementModule(all_segmentations_softmax, all_depths, planesY, imageDiff, numIterations=options.crf, numOutputPlanes=21)\n                        segmentation_loss += tf.reduce_mean(-tf.reduce_sum(previous_segmentation_gt* tf.log(tf.maximum(all_segmentations_softmax, 1e-31)), axis=-1), axis=[1, 2]) * 1000\n                        pass\n                    pass\n                else:\n                    segmentation_loss += tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=all_segmentations, labels=previous_segmentation_gt), axis=[1, 2]) * 1000\n                    pass\n            else:\n                #calculate new matching by finding nearest neighbors again\n                dists_forward, map_forward, dists_backward, _ = tf_nndistance.nn_distance(global_gt_dict[\'plane\'], pred_dict[\'plane\'])\n                dists_forward *= validPlaneMask\n                \n                dists_forward = tf.reduce_mean(dists_forward, axis=[1])\n                dists_backward = tf.reduce_mean(dists_backward, axis=[1])\n                plane_loss += (dists_forward + dists_backward * backwardLossWeight) * 10000\n\n                forward_map = tf.one_hot(map_forward, depth=options.numOutputPlanes, axis=-1)\n                forward_map *= tf.expand_dims(validPlaneMask, -1)\n                \n                #number of ground truth mapped for each prediction\n                num_matches = tf.transpose(tf.reduce_sum(forward_map, axis=1, keep_dims=True), [0, 2, 1])\n                previous_plane_gt = tf.transpose(tf.matmul(global_gt_dict[\'plane\'], forward_map, transpose_a=True), [0, 2, 1]) / tf.maximum(num_matches, 1e-4)\n                previous_plane_confidence_gt = tf.cast(num_matches > 0.5, tf.float32)\n                \n                                              \n                segmentation_gt_shuffled = tf.reshape(tf.matmul(tf.reshape(global_gt_dict[\'segmentation\'], [-1, HEIGHT * WIDTH, options.numOutputPlanes]), forward_map), [-1, HEIGHT, WIDTH, options.numOutputPlanes])\n                segmentation_gt_shuffled = tf.concat([segmentation_gt_shuffled, global_gt_dict[\'non_plane_mask\']], axis=3)\n                previous_segmentation_gt = segmentation_gt_shuffled\n                \n                all_segmentations = tf.concat([pred_dict[\'segmentation\'], pred_dict[\'non_plane_mask\']], axis=3)\n                segmentation_loss += tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=all_segmentations, labels=segmentation_gt_shuffled), axis=[1, 2]) * 1000\n                debug_dict[\'segmentation\'] = segmentation_gt_shuffled\n                pass\n\n            if options.diverseLoss:\n                plane_diff = tf.reduce_sum(tf.pow(tf.expand_dims(pred_dict[\'plane\'], 1) - tf.expand_dims(pred_dict[\'plane\'], 2), 2), axis=3)\n                plane_diff = tf.matrix_set_diag(plane_diff, tf.ones((options.batchSize, options.numOutputPlanes)))\n                minPlaneDiff = 0.1\n                diverse_loss += tf.reduce_mean(tf.clip_by_value(1 - plane_diff / minPlaneDiff, 0, 1), axis=[1, 2, 3]) * 10000\n                pass\n              \n            continue\n\n\n        if options.crf == 0:\n            all_segmentations_softmax = tf.nn.softmax(all_segmentations)\n            pass\n        \n        #depth loss\n        validDepthMask = tf.cast(tf.greater(global_gt_dict[\'depth\'], 1e-4), tf.float32)\n        depth_loss = tf.reduce_mean(tf.reduce_sum(tf.squared_difference(all_depths, global_gt_dict[\'depth\']) * all_segmentations_softmax, axis=3, keep_dims=True) * validDepthMask, axis=[1, 2, 3]) * 10000\n\n        if options.predictPixelwise == 1:\n            depth_diff = global_pred_dict[\'non_plane_depth\'] - global_gt_dict[\'depth\']\n            depth_diff_gx = depth_diff - tf.concat([tf.ones([options.batchSize, HEIGHT, 1, 1]), depth_diff[:, :, :WIDTH - 1]], axis=2)\n            depth_diff_gy = depth_diff - tf.concat([tf.ones([options.batchSize, 1, WIDTH, 1]), depth_diff[:, :HEIGHT - 1]], axis=1)\n\n            numValidPixels = tf.reduce_sum(validDepthMask, axis=[1, 2, 3])\n            depth_loss += (tf.reduce_sum(tf.pow(depth_diff * validDepthMask, 2), axis=[1, 2, 3]) / numValidPixels - 0.5 * tf.pow(tf.reduce_sum(depth_diff * validDepthMask, axis=[1, 2, 3]) / numValidPixels, 2) + tf.reduce_sum((tf.pow(depth_diff_gx, 2) + tf.pow(depth_diff_gy, 2)) * validDepthMask, axis=[1, 2, 3]) / numValidPixels) * 1000\n        \n            #depth_loss += tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_depth\'], global_gt_dict[\'depth\']) * validDepthMask) * 10000\n\n\n            valid_normal_mask = tf.squeeze(tf.cast(tf.less(tf.slice(global_gt_dict[\'info\'], [0, 19], [options.batchSize, 1]), 2), tf.float32))\n            normal_gt = tf.nn.l2_normalize(global_gt_dict[\'normal\'], dim=-1)\n            normal_loss = tf.reduce_sum(-global_pred_dict[\'non_plane_normal\'] * normal_gt * validDepthMask, axis=[1, 2, 3]) / numValidPixels * valid_normal_mask * 1000\n            #normal_loss = tf.reduce_mean(tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_normal\'], global_gt_dict[\'normal\']) * validDepthMask, axis=[1, 2, 3]) * valid_normal_mask) * 1000\n        else:\n            normal_loss = tf.constant(0.0)            \n            pass\n\n        if options.predictSemantics:\n            valid_semantics_mask = tf.squeeze(tf.cast(tf.not_equal(tf.slice(global_gt_dict[\'info\'], [0, 19], [options.batchSize, 1]), 1), tf.float32))\n            semantics_loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=global_pred_dict[\'semantics\'], labels=global_gt_dict[\'semantics\']), axis=[1, 2]) * valid_semantics_mask * 1000\n        else:\n            semantics_loss = tf.constant(0.0)\n            pass\n\n        local_score_loss = tf.constant(0.0)\n        local_plane_loss = tf.constant(0.0)\n        local_mask_loss = tf.constant(0.0)\n                \n        #boundary loss\n        boundary_loss = tf.constant(0.0)\n        \n        if False:\n            kernel_size = 3\n            padding = (kernel_size - 1) / 2\n            neighbor_kernel_array = gaussian(kernel_size, kernel_size)\n            neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n            neighbor_kernel_array /= neighbor_kernel_array.sum()\n            neighbor_kernel_array *= -1\n            neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 1\n            neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n            neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n            \n            #calculate boundary ground truth on-the-fly as the calculation is subject to change\n        \n            depth_diff = tf.abs(tf.nn.depthwise_conv2d(global_gt_dict[\'depth\'], neighbor_kernel, strides=[1, 1, 1, 1], padding=\'VALID\'))\n            depth_diff = tf.pad(depth_diff, paddings = [[0, 0], [padding, padding], [padding, padding], [0, 0]])\n            max_depth_diff = 0.1\n            depth_boundary = tf.greater(depth_diff, max_depth_diff)\n\n            plane_region = tf.nn.max_pool(1 - global_gt_dict[\'non_plane_mask\'], ksize=[1, kernel_size, kernel_size, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n            segmentation_eroded = 1 - tf.nn.max_pool(1 - global_gt_dict[\'segmentation\'], ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n            plane_region -= tf.reduce_max(segmentation_eroded, axis=3, keep_dims=True)\n            boundary = tf.cast(depth_boundary, tf.float32) * plane_region\n            smooth_boundary = global_gt_dict[\'smooth_boundary\']\n            boundary_gt = tf.concat([smooth_boundary, tf.maximum(boundary - smooth_boundary, 0)], axis=3)\n            pass\n\n\n        \n        if options.predictBoundary and False:\n            #we predict boundaries directly for post-processing purpose\n            boundary_loss += tf.reduce_mean(tf.losses.sigmoid_cross_entropy(logits=global_pred_dict[\'boundary\'], multi_class_labels=global_gt_dict[\'boundary\'], weights=tf.maximum(global_gt_dict[\'boundary\'] * 3, 1))) * 1000\n            pass\n\n\n        label_loss = tf.constant(0.0)\n        if options.labelLoss == 1:\n            #label_loss = tf.reduce_mean(tf.reduce_max(all_segmentations_softmax, axis=[1, 2]) * tf.concat([tf.cast(tf.equal(tf.squeeze(num_matches, axis=2), 0), tf.float32), tf.ones([options.batchSize, 1])], axis=1)) * 1000\n            #label_loss = tf.reduce_mean(tf.log(1 + tf.reduce_sum(all_segmentations_softmax, axis=[1, 2]))) * 100\n            label_loss = tf.reduce_mean(tf.sqrt(tf.reduce_sum(all_segmentations_softmax, axis=[1, 2])), axis=[1]) * 50\n            #label_loss = tf.reduce_mean(tf.reduce_max(all_segmentations_softmax, axis=[1, 2])) * 1000\n            pass\n        \n        #regularization\n        l2_losses = tf.add_n([options.l2Weight * tf.nn.l2_loss(v) for v in tf.trainable_variables() if \'weights\' in v.name])\n\n        if options.planeLoss == 0:\n            plane_loss = tf.constant(0.0)\n            pass\n\n        #loss_all = plane_loss + segmentation_loss + depth_loss + normal_loss + plane_confidence_loss + diverse_loss + boundary_loss + local_score_loss + local_plane_loss + local_mask_loss + label_loss + semantics_loss + l2_losses\n        #loss_pixelwise = depth_loss + normal_loss + semantics_loss + l2_losses\n\n        loss = tf.reduce_mean((depth_loss + normal_loss + semantics_loss) + (plane_loss + segmentation_loss + plane_confidence_loss + diverse_loss + boundary_loss + local_score_loss + local_plane_loss + local_mask_loss + label_loss) * tf.cast(tf.equal(tf.squeeze(tf.slice(global_gt_dict[\'info\'], [0, 19], [options.batchSize, 1])), 3), tf.float32)) + l2_losses\n        #if options.pixelwiseLoss:\n        #normal_loss = tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_normal\'], global_gt_dict[\'normal\'])) * 1000\n        #depth_loss = tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_depth\'], global_gt_dict[\'depth\']) * validDepthMask) * 1000\n        #pass\n\n        S = tf.one_hot(tf.argmax(all_segmentations, 3), depth=options.numOutputPlanes + 1)\n        depth_one_hot = tf.reduce_sum(all_depths * S, 3, keep_dims=True)\n        debug_dict[\'depth\'] = depth_one_hot\n        \n        loss_dict = {\'plane\': plane_loss, \'segmentation\': segmentation_loss, \'depth\': depth_loss, \'normal\': normal_loss, \'boundary\': boundary_loss, \'diverse\': diverse_loss, \'confidence\': plane_confidence_loss, \'local_score\': local_score_loss, \'local_plane\': local_plane_loss, \'local_mask\': local_mask_loss, \'label\': label_loss, \'semantics\': semantics_loss}\n        pass\n    return loss, loss_dict, debug_dict\n\n\ndef main(options):\n    if not os.path.exists(options.checkpoint_dir):\n        os.system(""mkdir -p %s""%options.checkpoint_dir)\n        pass\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n    \n    min_after_dequeue = 1000\n\n\n    train_inputs = []\n    val_inputs = []\n    if \'0\' in options.hybrid:\n        train_inputs.append(options.rootFolder + \'/planes_SUNCG_train.tfrecords\')\n        val_inputs.append(options.rootFolder + \'/planes_SUNCG_val.tfrecords\')        \n        pass\n    if \'1\' in options.hybrid:\n        train_inputs.append(options.rootFolder + \'/planes_nyu_rgbd_train.tfrecords\')\n        train_inputs.append(options.rootFolder + \'/planes_nyu_rgbd_labeled_train.tfrecords\')\n        val_inputs.append(options.rootFolder + \'/planes_nyu_rgbd_val.tfrecords\')\n        pass\n    if \'2\' in options.hybrid:\n        train_inputs.append(options.rootFolder + \'/planes_matterport_train.tfrecords\')\n        val_inputs.append(options.rootFolder + \'/planes_matterport_val.tfrecords\')\n        pass\n    if \'3\' in options.hybrid:\n        train_inputs.append(options.rootFolder + \'/planes_scannet_train.tfrecords\')\n        val_inputs.append(options.rootFolder + \'/planes_scannet_val.tfrecords\')\n        pass\n\n    \n    hybrid_flag = tf.placeholder(tf.bool, shape=[], name=\'hybrid_flag\')\n    \n    reader_train_nyu_rgbd = RecordReaderAll()\n    filename_queue_train_nyu_rgbd = tf.train.string_input_producer(train_inputs + [options.rootFolder + \'/planes_scannet_train.tfrecords\', ], num_epochs=10000)\n    img_inp_train_nyu_rgbd, global_gt_dict_train_nyu_rgbd, _ = reader_train_nyu_rgbd.getBatch(filename_queue_train_nyu_rgbd, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True)\n\n    # reader_train_scannet = RecordReaderAll()\n    # filename_queue_train_scannet = tf.train.string_input_producer([options.rootFolder + \'/planes_scannet_train.tfrecords\'], num_epochs=10000)\n    # img_inp_train_scannet, global_gt_dict_train_scannet, _ = reader_train_scannet.getBatch(filename_queue_train_scannet, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize / 2, min_after_dequeue=min_after_dequeue, getLocal=True)\n\n    # img_inp_train = tf.concat([img_inp_train_nyu_rgbd, img_inp_train_scannet], axis=0)\n    # global_gt_dict_train = {}\n    # for name in global_gt_dict_train_nyu_rgbd.keys():\n    #     global_gt_dict_train[name] = tf.concat([global_gt_dict_train_nyu_rgbd[name], global_gt_dict_train_scannet[name]], axis=0)\n    #     continue\n    # local_gt_dict_train = {}\n    \n    img_inp_train = img_inp_train_nyu_rgbd\n    global_gt_dict_train = global_gt_dict_train_nyu_rgbd\n    local_gt_dict_train = {}\n\n    \n    reader_val = RecordReaderAll()\n    filename_queue_val = tf.train.string_input_producer(val_inputs, num_epochs=10000)\n    img_inp_val, global_gt_dict_val, local_gt_dict_val = reader_val.getBatch(filename_queue_val, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True)\n    \n    training_flag = tf.placeholder(tf.bool, shape=[], name=\'training_flag\')\n    \n    #global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp_train, img_inp_val, img_inp_rgbd_train, img_inp_rgbd_val, img_inp_3d_train, img_inp_3d_val, training_flag, options)\n    global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp_train, img_inp_val, training_flag, options)\n    \n    \n    #loss, loss_dict, _ = build_loss(global_pred_dict, local_pred_dict, deep_pred_dicts, global_gt_dict_train, local_gt_dict_train, global_gt_dict_val, local_gt_dict_val, training_flag, options)\n    #loss_rgbd, loss_dict_rgbd, _ = build_loss_rgbd(global_pred_dict, deep_pred_dicts, global_gt_dict_rgbd_train, global_gt_dict_rgbd_val, training_flag, options)\n    loss, loss_dict, _ = build_loss(img_inp_train, img_inp_val, global_pred_dict, deep_pred_dicts, global_gt_dict_train, global_gt_dict_val, training_flag, options)    \n        \n    #loss = tf.cond(tf.less(training_flag, 2), lambda: loss, lambda: tf.cond(tf.less(training_flag, 4), lambda: loss_rgbd, lambda: loss_3d))\n\n    \n    #train_writer = tf.summary.FileWriter(options.log_dir + \'/train\')\n    #val_writer = tf.summary.FileWriter(options.log_dir + \'/val\')\n    #train_writer_rgbd = tf.summary.FileWriter(options.log_dir + \'/train_rgbd\')\n    #val_writer_rgbd = tf.summary.FileWriter(options.log_dir + \'/val_rgbd\')\n    #writers = [train_writer, val_writer, train_writer_rgbd, val_writer_rgbd]\n    \n\n    with tf.variable_scope(\'statistics\'):\n        batchno = tf.Variable(0, dtype=tf.int32, trainable=False, name=\'batchno\')\n        batchnoinc=batchno.assign(batchno+1)\n        pass\n\n\n    optimizer = tf.train.AdamOptimizer(options.LR)\n    if options.crfrnn >= 0:\n        train_op = optimizer.minimize(loss, global_step=batchno)\n    else:\n        var_to_train = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, ""crfrnn"")\n        print(var_to_train)\n        train_op = optimizer.minimize(loss, global_step=batchno, var_list=var_to_train)\n        pass\n    \n    var_to_restore = [v for v in tf.global_variables()]\n\n    tf.summary.scalar(\'loss\', loss)\n    summary_op = tf.summary.merge_all()\n\n    \n    config=tf.ConfigProto()\n    config.allow_soft_placement=True    \n    #config.gpu_options.allow_growth=True\n    config.gpu_options.per_process_gpu_memory_fraction=0.9\n    saver=tf.train.Saver()\n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n    \n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n        if options.restore == 0:\n            #fine-tune from DeepLab model\n            var_to_restore = [v for v in var_to_restore if \'res5d\' not in v.name and \'segmentation\' not in v.name and \'plane\' not in v.name and \'deep_supervision\' not in v.name and \'local\' not in v.name and \'boundary\' not in v.name and \'degridding\' not in v.name and \'res2a_branch2a\' not in v.name and \'res2a_branch1\' not in v.name and \'Adam\' not in v.name and \'beta\' not in v.name and \'statistics\' not in v.name and \'semantics\' not in v.name]\n            pretrained_model_loader = tf.train.Saver(var_to_restore)\n            pretrained_model_loader.restore(sess,""../pretrained_models/deeplab_resnet.ckpt"")\n        elif options.restore == 1:\n            #restore the same model from checkpoint\n            loader = tf.train.Saver(var_to_restore)\n            loader.restore(sess,""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n            bno=sess.run(batchno)\n            print(bno)\n        elif options.restore == 2:            \n            #restore the same model from checkpoint but reset batchno to 1\n            loader = tf.train.Saver(var_to_restore)\n            loader.restore(sess,""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n            sess.run(batchno.assign(1))\n        elif options.restore == 3:            \n            #restore the same model from standard training\n            # if options.predictBoundary == 1:\n            #     var_to_restore = [v for v in var_to_restore if \'boundary\' not in v.name]\n            #     pass            \n            # if options.predictConfidence == 1:\n            #     var_to_restore = [v for v in var_to_restore if \'confidence\' not in v.name]\n            #     pass\n            if options.predictSemantics == 1:\n                var_to_restore = [v for v in var_to_restore if \'semantics\' not in v.name]\n                pass\n            if np.abs(options.crfrnn) > 0:\n                var_to_restore = [v for v in var_to_restore if \'crfrnn\' not in v.name]\n                pass\n            \n            loader = tf.train.Saver(var_to_restore)\n            if len(options.hybrid) == 1:\n                hybrid = options.hybrid\n            else:\n                hybrid = str(3)\n                pass\n            #loader.restore(sess, options.rootFolder + \'/checkpoint/planenet_hybrid\' + hybrid + \'_bl0_ll1_bw0.5_pb_pp_ps_sm0/checkpoint.ckpt\')\n            #loader.restore(sess, options.rootFolder + \'/checkpoint/planenet_hybrid3_bl0_dl0_ll1_pb_pp_sm0/checkpoint.ckpt\')\n            loader.restore(sess, options.rootFolder + \'/checkpoint/sample_np10_hybrid3_bl0_dl0_hl2_ds0_crfrnn5_sm0/checkpoint.ckpt\')\n            #loader.restore(sess,""checkpoint/planenet/checkpoint.ckpt"")\n            sess.run(batchno.assign(1))\n        elif options.restore == 4:\n            #fine-tune another model\n            #var_to_restore = [v for v in var_to_restore if \'res4b22_relu_non_plane\' not in v.name]\n            loader = tf.train.Saver(var_to_restore)\n            loader.restore(sess, options.fineTuningCheckpoint)\n            sess.run(batchno.assign(1))\n            pass\n        elif options.restore == 5:\n            #fine-tune another model\n            #var_to_restore = [v for v in var_to_restore if \'res4b22_relu_non_plane\' not in v.name]\n            loader = tf.train.Saver(var_to_restore)\n            print(options.checkpoint_dir.replace(\'crfrnn\', \'crfrnn-\'))\n            #exit(1)\n            loader.restore(sess,""%s/checkpoint.ckpt""%(options.checkpoint_dir.replace(\'crfrnn\', \'crfrnn-\')))            \n            sess.run(batchno.assign(1))\n            pass\n        # Start input enqueue threads.\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n        MOVING_AVERAGE_DECAY = 0.99\n        ema = [0., 0., 0., 0.]\n        ema_acc = [1e-10, 1e-10, 1e-10, 1e-10]\n        last_snapshot_time = time.time()\n        bno=sess.run(batchno)\n\n        try:\n            while bno<300000:\n                t0 = time.time()\n\n                batchIndexPeriod = bno % 100\n                if batchIndexPeriod < len(options.hybrid):\n                    #batchType = int(options.hybrid[batchIndexPeriod]) * 2 + 1\n                    batchType = 1\n                    _, total_loss, losses, summary_str, debug = sess.run([batchnoinc, loss, loss_dict, summary_op, global_pred_dict], feed_dict = {training_flag: batchType == 0, hybrid_flag: np.random.randint(2) == 0})\n                else:\n                    batchType = 0\n                    _, total_loss, losses, summary_str, debug = sess.run([train_op, loss, loss_dict, summary_op, global_pred_dict], feed_dict = {training_flag: batchType == 0, hybrid_flag: np.random.randint(2) == 0})\n\n                    # for batchIndex in xrange(options.batchSize):\n                    #     print(losses)\n                    #     print(debug[\'plane\'][batchIndex])\n                    #     cv2.imwrite(\'test/image_\' + str(batchIndex) + \'.png\', ((img[batchIndex] + 0.5) * 255).astype(np.uint8))\n                    #     cv2.imwrite(\'test/segmentation_\' + str(batchIndex) + \'.png\', drawSegmentationImage(debug[\'segmentation\'][batchIndex]))\n                    #     continue\n                    # exit(1)\n                    \n                    pass\n\n                    \n                ema[batchType] = ema[batchType] * MOVING_AVERAGE_DECAY + total_loss\n                ema_acc[batchType] = ema_acc[batchType] * MOVING_AVERAGE_DECAY + 1\n\n                bno = sess.run(batchno)\n                if time.time()-last_snapshot_time > options.saveInterval:\n                    print(\'save snapshot\')\n                    saver.save(sess,\'%s/checkpoint.ckpt\'%options.checkpoint_dir)\n                    last_snapshot_time = time.time()\n                    pass\n        \n                print bno,\'train\', ema[0] / ema_acc[0], \'val\', ema[1] / ema_acc[1], \'train rgbd\', ema[2] / ema_acc[2], \'val rgbd\', ema[3] / ema_acc[3], \'loss\', total_loss, \'time\', time.time()-t0\n\n                if np.random.random() < 0.01:\n                    print(losses)\n                    pass                \n                continue\n\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n        \n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return\n\n\ndef test(options):\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n\n    if options.dataset == \'\':\n        assert(len(options.hybrid) == 1)\n        if options.hybrid == \'0\':\n            options.dataset = \'SUNCG\'\n        elif options.hybrid == \'1\':\n            options.dataset = \'NYU_RGBD\'\n        elif options.hybrid == \'2\':\n            options.dataset = \'matterport\'\n        elif options.hybrid == \'3\':\n            options.dataset = \'ScanNet\'\n            \n        options.dataset\n    options.batchSize = 1\n    min_after_dequeue = 1000\n\n    reader = RecordReaderAll()\n    if options.dataset == \'SUNCG\':\n        filename_queue = tf.train.string_input_producer([options.rootFolder + \'/planes_SUNCG_val.tfrecords\'], num_epochs=10000)\n    elif options.dataset == \'NYU_RGBD\':\n        filename_queue = tf.train.string_input_producer([options.rootFolder + \'/planes_nyu_rgbd_val.tfrecords\'], num_epochs=1)\n        options.deepSupervision = 0\n        options.predictLocal = 0\n    elif options.dataset == \'matterport\':\n        filename_queue = tf.train.string_input_producer([options.rootFolder + \'/planes_matterport_val.tfrecords\'], num_epochs=1)\n    else:\n        filename_queue = tf.train.string_input_producer([options.rootFolder + \'/planes_scannet_val.tfrecords\'], num_epochs=1)\n        pass\n    img_inp, global_gt_dict, local_gt_dict = reader.getBatch(filename_queue, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True, random=False)\n\n    training_flag = tf.constant(False, tf.bool)\n\n    global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp, img_inp, training_flag, options)\n    var_to_restore = tf.global_variables()\n\n    loss, loss_dict, debug_dict = build_loss(img_inp, img_inp, global_pred_dict, deep_pred_dicts, global_gt_dict, global_gt_dict, training_flag, options)\n    \n\n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n    \n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n        #var_to_restore = [v for v in var_to_restore if \'res4b22_relu_non_plane\' not in v.name]\n        loader = tf.train.Saver(var_to_restore)\n        loader.restore(sess, ""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n        #loader.restore(sess, ""%s/checkpoint.ckpt""%(\'checkpoint/planenet_pb_pp_hybrid1\'))\n        #loader.restore(sess, options.fineTuningCheckpoint)\n        \n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n        \n        \n        try:\n            gtDepths = []\n            predDepths = []\n            planeMasks = []\n            #predMasks = []\n            gtPlanes = []\n            predPlanes = []\n            gtSegmentations = []\n            predSegmentations = []\n            gtNumPlanes = []\n            \n            imageWidth = WIDTH\n            imageHeight = HEIGHT\n            focalLength = 517.97\n            urange = np.arange(imageWidth).reshape(1, -1).repeat(imageHeight, 0) - imageWidth * 0.5\n            vrange = np.arange(imageHeight).reshape(-1, 1).repeat(imageWidth, 1) - imageHeight * 0.5\n            ranges = np.array([urange / imageWidth * 640 / focalLength, np.ones(urange.shape), -vrange / imageHeight * 480 / focalLength]).transpose([1, 2, 0])\n\n\n            for index in xrange(10):\n                print((\'image\', index))\n                t0=time.time()\n\n                img, global_gt, local_gt, global_pred, local_pred, deep_preds, total_loss, losses, debug = sess.run([img_inp, global_gt_dict, local_gt_dict, global_pred_dict, local_pred_dict, deep_pred_dicts, loss, loss_dict, debug_dict])\n\n                # print(options.test_dir)\n                # cv2.imwrite(options.test_dir + \'/depth.png\', drawDepthImage(debug[\'depth\'][0]))\n                # cv2.imwrite(options.test_dir + \'/normal.png\', drawNormalImage(debug[\'normal\'][0]))\n                # boundary = debug[\'boundary\'][0]\n                # boundary = np.concatenate([boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)\n                # cv2.imwrite(options.test_dir + \'/boundary.png\', drawMaskImage(boundary))\n                # cv2.imwrite(options.test_dir + \'/depth_gt.png\', drawDepthImage(debug[\'depth_gt\'][0].squeeze()))\n                # exit(1)\n\n                if \'pixelwise\' in options.suffix:\n                    image = ((img[0] + 0.5) * 255).astype(np.uint8)\n                    gt_d = global_gt[\'depth\'].squeeze()\n                    pred_d = global_pred[\'non_plane_depth\'].squeeze()\n                    #depth = global_gt[\'depth\'].squeeze()\n                    if \'_2\' in options.suffix:\n                        pred_p, pred_s, pred_d = fitPlanes(pred_d, numPlanes=20, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=0.2)\n                    elif \'_3\' in options.suffix:\n                        pred_p, pred_s, pred_d = fitPlanes(gt_d, numPlanes=20, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=0.2)\n                        pass\n\n                    # gt_p = global_gt[\'plane\'][0]\n                    # pred_p = planes\n                    # valid_mask = (np.linalg.norm(gt_p, axis=1) > 0).astype(np.float32)\n                    # diff = np.min(np.linalg.norm(np.expand_dims(gt_p, 1) - np.expand_dims(pred_p, 0), axis=2), 1)\n                    # num += valid_mask.sum()\n                    # lossSum += (diff * valid_mask).sum()\n                    if options.dataset == \'SUNCG\':\n                        planeMask = np.squeeze(debug[\'segmentation\']).sum(axis=2)\n                    else:\n                        planeMask = np.ones((HEIGHT, WIDTH))\n                        if \'_2\' in options.suffix or \'_3\' in options.suffix:\n                            planeMask *= (pred_s < 20).astype(np.float32)\n                        pass\n                    \n                    if index < 10:\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', image)\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth.png\', drawDepthImage(gt_d))\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n                        if \'_2\' in options.suffix or \'_3\' in options.suffix:\n                            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(pred_s))\n                            pass\n                        #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_plane_mask.png\', drawMaskImage(planeMask))                \n                        pass\n\n                        \n                    gtDepths.append(gt_d)\n                    predDepths.append(pred_d)\n                    planeMasks.append(planeMask)\n\n\n                    if options.dataset != \'NYU_RGBD\' and (\'_2\' in options.suffix or \'_3\' in options.suffix):\n                        gt_p = global_gt[\'plane\'][0]\n                        gt_s = global_gt[\'segmentation\'][0]\n                        gt_num_p = global_gt[\'num_planes\'][0]\n\n                        pred_s = (np.expand_dims(pred_s, -1) == np.reshape(np.arange(options.numOutputPlanes), [1, 1, -1])).astype(np.float32)\n                        gtPlanes.append(gt_p)\n                        predPlanes.append(pred_p)\n                        gtSegmentations.append(gt_s)\n                        gtNumPlanes.append(gt_num_p)\n                        predSegmentations.append(pred_s)\n                        pass\n                    \n                    #planeMasks.append((planeSegmentation < 20).astype(np.float32))\n                    continue\n                \n                print(losses)\n                print(total_loss)\n                #print(losses)\n                #exit(1)\n                im = img[0]\n                image = ((im + 0.5) * 255).astype(np.uint8)                \n\n                gt_d = global_gt[\'depth\'].squeeze()\n                                \n\n                if options.predictLocal:\n                    pred_local_s = 1 / (1 + np.exp(-local_pred[\'score\'][0]))\n                    pred_local_p = local_pred[\'plane\'][0]\n                    pred_local_m = local_pred[\'mask\'][0]\n                  \n                    gt_local_s = local_gt[\'score\'][0]\n                    gt_local_m = local_gt[\'mask\'][0]\n\n                    #visualize local plane prediction\n                    stride = 8\n                    boxSize = 64\n                    xs = np.arange(WIDTH / stride) * stride + stride / 2\n                    ys = np.arange(HEIGHT / stride) * stride + stride / 2\n                    padding = boxSize / 2 + 1\n                    maskImage = np.zeros((HEIGHT + padding * 2, WIDTH + padding * 2, 3), dtype=np.uint8)\n                    maskImage[padding:padding + HEIGHT, padding:padding + WIDTH, :] = image / 2\n                    for gridY, y in enumerate(ys):\n                        for gridX, x in enumerate(xs):\n                            score = pred_local_s[gridY][gridX]\n                            if score < 0.5:\n                                continue                              \n                            mask = pred_local_m[gridY][gridX].reshape([16, 16])        \n                            mask = cv2.resize(mask, (boxSize, boxSize))\n                            maskImage[y - boxSize / 2 + padding:y + boxSize / 2 + padding, x - boxSize / 2 + padding:x + boxSize / 2 + padding, 0][mask > 0.5] = 255\n                            continue\n                        continue\n                    for gridY, y in enumerate(ys):\n                        for gridX, x in enumerate(xs):\n                            score = gt_local_s[gridY][gridX]\n                            if score < 0.5:\n                                continue                              \n                            mask = gt_local_m[gridY][gridX].reshape([16, 16])        \n                            mask = cv2.resize(mask, (boxSize, boxSize))\n                            maskImage[y - boxSize / 2 + padding:y + boxSize / 2 + padding, x - boxSize / 2 + padding:x + boxSize / 2 + padding, 2][mask > 0.5] = 255\n                            continue\n                        continue\n                    pass\n\n                pred_p = global_pred[\'plane\'][0]\n                pred_s = global_pred[\'segmentation\'][0]\n\n                pred_np_m = global_pred[\'non_plane_mask\'][0]\n                pred_np_d = global_pred[\'non_plane_depth\'][0]\n                pred_np_n = global_pred[\'non_plane_normal\'][0]\n                \n                planeMask = 1 - global_gt[\'non_plane_mask\'][0]\n                info = global_gt[\'info\'][0]\n\n                \n                all_segmentations = np.concatenate([pred_s, pred_np_m], axis=2)\n                all_segmentations_softmax = softmax(all_segmentations)\n                segmentation = np.argmax(all_segmentations, 2)\n                \n                \n                #pred_p, segmentation, numPlanes = mergePlanes(global_gt[\'plane\'][0], np.concatenate([global_gt[\'segmentation\'][0], global_gt[\'non_plane_mask\'][0]], axis=2), global_gt[\'depth\'][0].squeeze(), global_gt[\'info\'][0], np.concatenate([pred_s, pred_np_m], axis=2))\n                \n\n                plane_depths = calcPlaneDepths(pred_p, WIDTH, HEIGHT, info)\n                all_depths = np.concatenate([plane_depths, pred_np_d], axis=2)\n                \n                pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape(HEIGHT, WIDTH)\n\n                plane_normals = calcPlaneNormals(pred_p, WIDTH, HEIGHT)\n                all_normals = np.concatenate([plane_normals, np.expand_dims(pred_np_n, 2)], axis=2)\n                pred_n = np.sum(all_normals * np.expand_dims(one_hot(segmentation, options.numOutputPlanes+1), -1), 2)\n                #pred_n = all_normals.reshape(-1, options.numOutputPlanes + 1, 3)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape((HEIGHT, WIDTH, 3))\n                \n\n                if False:\n                    gt_s = global_gt[\'segmentation\'][0]\n                    all_segmentations = np.concatenate([gt_s, 1 - planeMask], axis=2)\n                    gt_p = global_gt[\'plane\'][0]\n\n                    # valid_mask = (np.linalg.norm(gt_p, axis=1) > 0).astype(np.float32)\n                    # diff = np.min(np.linalg.norm(np.expand_dims(gt_p, 1) - np.expand_dims(pred_p, 0), axis=2), 1)\n                    # num += valid_mask.sum()\n                    # lossSum += (diff * valid_mask).sum()\n                    #gt_p = np.stack([-gt_p[:, 0], -gt_p[:, 2], -gt_p[:, 1]], axis=1)\n                    \n                    plane_depths = calcPlaneDepths(gt_p, WIDTH, HEIGHT, info)\n                    all_depths = np.concatenate([plane_depths, pred_np_d], axis=2)\n\n                    segmentation = np.argmax(all_segmentations, 2)\n                    pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape(HEIGHT, WIDTH)\n                    # print(gt_p)\n                    # for segmentIndex in xrange(options.numOutputPlanes):\n                    #     cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_mask_\' + str(segmentIndex) + \'.png\', drawMaskImage(segmentation == segmentIndex))\n                    #     continue\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n                    #exit(1)\n                    pass\n\n                \n\n                gt_p = global_gt[\'plane\'][0]\n                gt_s = global_gt[\'segmentation\'][0]\n                gt_num_p = global_gt[\'num_planes\'][0]\n                gtPlanes.append(gt_p)\n                predPlanes.append(pred_p)\n                gtSegmentations.append(gt_s)\n                gtNumPlanes.append(gt_num_p)\n                predSegmentations.append(pred_s)\n                \n            \n                gtDepths.append(gt_d)\n                planeMasks.append(planeMask.squeeze())\n                predDepths.append(pred_d)\n                evaluateDepths(predDepths[-1], gtDepths[-1], gtDepths[-1] > 0, planeMasks[-1])\n                \n                \n                if index >= 10:\n                    continue\n\n                if options.predictSemantics:\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_semantics_pred.png\', drawSegmentationImage(global_pred[\'semantics\'][0], blackIndex=0))\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_semantics_gt.png\', drawSegmentationImage(global_gt[\'semantics\'][0], blackIndex=0))\n                    pass\n\n                if \'cost_mask\' in debug:\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_cost_mask.png\', drawMaskImage(np.sum(debug[\'cost_mask\'][0], axis=-1)))\n\n                    for planeIndex in xrange(options.numOutputPlanes + 1):\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_cost_mask_\' + str(planeIndex) + \'.png\', drawMaskImage(debug[\'cost_mask\'][0, :, :, planeIndex]))\n                        continue\n                    all_segmentations = np.concatenate([pred_s, pred_np_m], axis=2)\n                    for planeIndex in xrange(options.numOutputPlanes + 1):\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred_\' + str(planeIndex) + \'.png\', drawMaskImage(all_segmentations[:, :, planeIndex]))\n                        continue\n                    exit(1)\n                    pass\n                \n                if \'normal\' in global_gt:\n                    gt_n = global_gt[\'normal\'][0]\n                    norm = np.linalg.norm(gt_n, axis=-1, keepdims=True)\n                    gt_n /= np.maximum(norm, 1e-4)\n                    \n                    #gt_n = np.stack([-gt_n[:, :, 0], -gt_n[:, :, 2], -gt_n[:, :, 1]], axis=2)\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_gt.png\', drawNormalImage(gt_n))\n                    #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_pred.png\', drawNormalImage(pred_np_n))\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_pred.png\', drawNormalImage(pred_n))\n                    pass\n                \n                if \'segmentation\' in global_gt:\n                    gt_s = global_gt[\'segmentation\'][0]\n                    gt_p = global_gt[\'plane\'][0]\n\n                    \n                    #for planeIndex in xrange(20):\n                    #cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(gt_s[:, :, planeIndex]))\n                    #continue\n                    \n                    \n                    # print(gt_p)\n                    # print(gt_n[109][129])\n                    # print(gt_n[166][245])\n                    # print(gt_s[109][129])\n                    # print(gt_s[166][245])\n                    # print(plane_normals[109][129])\n                    # print(plane_normals[166][245])                    \n                    # for planeIndex in xrange(20):\n                    #     cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(gt_s[:, :, planeIndex]))\n                    #     continue\n                    # exit(1)\n                    \n                    gt_s, gt_p = sortSegmentations(gt_s, gt_p, pred_p)\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_plane_mask_gt.png\', drawMaskImage(planeMask))  \n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_gt.png\', drawSegmentationImage(np.concatenate([gt_s, 1 - planeMask], axis=2), blackIndex=options.numOutputPlanes)\n)\n                    #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_test.png\', drawMaskImage(np.sum(np.concatenate([gt_s, 1 - planeMask], axis=2), axis=2)))\n                    #exit(1)\n                    #exit(1)\n                    pass\n\n\n                if options.predictConfidence == 1 and options.dataset == \'SUNCG\':\n                    assert(False)\n                    pred_p_c = global_pred[\'confidence\'][0]\n                    pred_p_c = 1 / (1 + np.exp(-pred_p_c))\n                    #print(pred_p_c)\n                    # print(losses)\n                    # print(debug[\'plane\'][0])\n                    # print(pred_p)\n                    # exit(1)\n                    numPlanes = global_gt[\'num_planes\'][0]\n                    print((numPlanes, (pred_p_c > 0.5).sum()))\n                    \n                    pred_p_c = (pred_p_c > 0.5).astype(np.float32)\n                    pred_p *= pred_p_c\n                    pred_s -= (1 - pred_p_c.reshape([1, 1, options.numOutputPlanes])) * 10\n                    pass\n                  \n                if False:\n                    #dump results for post processing\n                    if index >= 10:\n                        break\n                    np.save(options.dump_dir + \'/planes_\' + str(index) + \'.npy\', pred_p)\n                    np.save(options.dump_dir + \'/segmentations_\' + str(index) + \'.npy\', pred_s)\n                    np.save(options.dump_dir + \'/segmentations_gt_\' + str(index) + \'.npy\', gt_s)\n                    np.save(options.dump_dir + \'/non_plane_depth_\' + str(index) + \'.npy\', pred_np_d)\n                    np.save(options.dump_dir + \'/non_plane_segmentation_\' + str(index) + \'.npy\', pred_np_m)\n                    boundary = pred_boundary[0]\n                    boundary = 1 / (1 + np.exp(-boundary))\n                    boundary = np.concatenate([boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)                    \n                    cv2.imwrite(options.dump_dir + \'/boundary_\' + str(index) + \'.png\', drawMaskImage(boundary))\n                    cv2.imwrite(options.dump_dir + \'/image_\' + str(index) + \'.png\', cv2.resize(image, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR))\n                    np.save(options.dump_dir + \'/depth_\' + str(index) + \'.npy\', gt_d)\n                    continue                \n\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', image)\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth.png\', drawDepthImage(gt_d))\n                #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_overlay.png\', drawDepthImageOverlay(image, gt_d))\n                \n                if options.predictBoundary:\n                    pred_boundary = global_pred[\'boundary\'][0]\n                    pred_boundary = 1 / (1 + np.exp(-pred_boundary))\n                    boundary = np.concatenate([pred_boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_boundary_pred.png\', drawMaskImage(boundary))\n                    pass\n\n                if \'boundary\' in global_gt:\n                    gt_boundary = global_gt[\'boundary\'][0]\n                    boundary = np.concatenate([gt_boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)                \n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_boundary_gt.png\', drawMaskImage(boundary))\n                    pass\n\n                for layerIndex, layer in enumerate(options.deepSupervisionLayers):\n                    segmentation_deep = np.argmax(deep_preds[layerIndex][\'segmentation\'][0], 2)\n                    segmentation_deep[segmentation_deep == options.numOutputPlanes] = -1\n                    segmentation_deep += 1\n                \n                    plane_depths_deep = calcPlaneDepths(deep_preds[layerIndex][\'plane\'][0], WIDTH, HEIGHT, info)\n                    all_depths_deep = np.concatenate([pred_np_d, plane_depths_deep], axis=2)\n                    pred_d_deep = all_depths_deep.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation_deep.reshape(-1)].reshape(HEIGHT, WIDTH)\n                \n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred_\' + str(layerIndex) + \'.png\', drawSegmentationImage(deep_preds[layerIndex][\'segmentation\'][0]))\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred_\' + str(layerIndex) + \'.png\', drawDepthImage(pred_d_deep))\n                    pass\n\n\n                #print(pred_np_m)\n                #print(pred_s)\n                #print(global_gt[\'plane\'][0])\n                #print(pred_p)\n                #exit(1)\n\n                print(\'depth diff\', np.abs(pred_d - gt_d).mean())\n                \n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(all_segmentations, blackIndex=options.numOutputPlanes))\n                #exit(1)\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_diff.png\', drawMaskImage(np.abs(pred_d - gt_d) * planeMask.squeeze() / 0.2))\n                #exit(1)\n                \n                \n                #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_plane_mask.png\', drawMaskImage(planeMask))           \n\n                #print(np.concatenate([np.arange(options.numOutputPlanes).reshape(-1, 1), planes, pred_p, preds_p[0][0]], axis=1))\n\n                #print(np.concatenate([distance[0], preds_p[0][0], pred_p], axis=1))\n                            \n                #segmentation = np.argmax(pred_s, 2)\n                #writePLYFile(options.test_dir, index, image, pred_d, segmentation, np.zeros(pred_boundary[0].shape))\n                #writePLYFileParts(options.test_dir, index, image, pred_d, segmentation)\n                #gt_s_ori = gt_s_ori[0]\n\n\n                # if \'depth\' in debug:\n                #     cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred_1.png\', drawDepthImage(debug[\'depth\'][0]))\n                #     gt_s_ori = debug[\'segmentation\'][0]\n                #     cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_gt.png\', drawSegmentationImage(gt_s_ori, blackIndex=options.numOutputPlanes))\n                #     total_loss = 0\n                #     for planeIndex in xrange(gt_s_ori.shape[-1]):\n                #         mask_pred = all_segmentations_softmax[:, :, planeIndex]\n                #         loss = -(gt_s_ori[:, :, planeIndex] * np.log(np.maximum(all_segmentations_softmax[:, :, planeIndex], 1e-31))).mean() * 1000\n                #         print(planeIndex, loss)\n                #         total_loss += loss\n                #         cv2.imwrite(options.test_dir + \'/mask_pred_\' + str(planeIndex) + \'.png\', drawMaskImage(mask_pred))\n                #         cv2.imwrite(options.test_dir + \'/mask_gt_\' + str(planeIndex) + \'.png\', drawMaskImage(gt_s_ori[:, :, planeIndex]))\n                #         continue\n                #     print(total_loss)\n                #     print(gt_s_ori.sum(2).max())                    \n                #     exit(1)\n                #     pass\n\n                \n                if False:\n                    #distance = distance[0]\n                    print(distance)\n                    diff = np.linalg.norm(np.expand_dims(planes, 1) - np.expand_dims(pred_p, 0), axis=2)\n                    print(np.concatenate([planes, pred_p, pow(np.min(diff, axis=1, keepdims=True), 2), np.expand_dims(np.argmin(diff, axis=1), -1)], axis=1))\n                    print(pred_p_c)\n                    \n                    #print(distance[:, 6:8].sum(0))\n                    #print(pow(np.linalg.norm(distance[:, :3] - distance[:, 3:6], 2, 1), 2) * 100)\n                    #print(test)\n                    segmentation = np.argmax(all_segmentations, 2) - 1\n                    for planeIndex in xrange(options.numOutputPlanes):\n                        cv2.imwrite(options.test_dir + \'/segmentation_\' + str(planeIndex) + \'.png\', drawMaskImage(segmentation == planeIndex))\n                        cv2.imwrite(options.test_dir + \'/segmentation_\' + str(planeIndex) + \'_gt.png\', drawMaskImage(gt_s[:, :, planeIndex]))\n                        cv2.imwrite(options.test_dir + \'/segmentation_\' + str(planeIndex) + \'_gt_ori.png\', drawMaskImage(gt_s_ori[:, :, planeIndex]))\n                        continue\n                    exit(1)\n                continue\n\n            # if options.dataset == \'SUNCG\':\n            #     if \'pixelwise\' not in options.suffix:\n            #         evaluatePlaneSegmentation(np.array(predPlanes), np.array(predSegmentations), np.array(gtPlanes), np.array(gtSegmentations), np.array(gtNumPlanes), planeDistanceThreshold = 0.3, IOUThreshold = 0.5, prefix=\'test/planenet_\')\n            #     elif \'_2\' in options.suffix:\n            #         evaluatePlaneSegmentation(np.array(predPlanes), np.array(predSegmentations), np.array(gtPlanes), np.array(gtSegmentations), np.array(gtNumPlanes), planeDistanceThreshold = 0.3, IOUThreshold = 0.5, prefix=\'test/pixelwise_pred_\')\n            #     elif \'_3\' in options.suffix:\n            #         evaluatePlaneSegmentation(np.array(predPlanes), np.array(predSegmentations), np.array(gtPlanes), np.array(gtSegmentations), np.array(gtNumPlanes), planeDistanceThreshold = 0.3, IOUThreshold = 0.5, prefix=\'test/pixelwise_gt_\')\n            #         pass\n            #     pass\n            \n            predDepths = np.array(predDepths)\n            gtDepths = np.array(gtDepths)\n            planeMasks = np.array(planeMasks)\n            #predMasks = np.array(predMasks)\n            evaluateDepths(predDepths, gtDepths, gtDepths > 0, planeMasks)\n            exit(1)\n\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n        \n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return\n\n\n# def predict(options):\n#     options.test_dir += \'_predict\'\n#     if not os.path.exists(options.test_dir):\n#         os.system(""mkdir -p %s""%options.test_dir)\n#         pass\n\n#     batchSize = 1\n#     img_inp = tf.placeholder(tf.float32,shape=(batchSize,HEIGHT,WIDTH,3),name=\'img_inp\')\n#     plane_gt=tf.placeholder(tf.float32,shape=(batchSize,options.numOutputPlanes, 3),name=\'plane_inp\')\n#     validating_inp = tf.constant(0, tf.int32)\n\n#     global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp_train, img_inp_val, img_inp_rgbd_train, img_inp_rgbd_val, training_flag, options)\n\n#     var_to_restore = tf.global_variables()\n    \n \n#     config=tf.ConfigProto()\n#     config.gpu_options.allow_growth=True\n#     config.allow_soft_placement=True\n\n\n#     if dataset == \'SUNCG\':\n#         image_list_file = os.path.join(\'../PythonScripts/SUNCG/image_list_100_tail_500000.txt\')\n#         with open(image_list_file) as f:\n#             im_names = [{\'image\': im_name.strip().replace(\'plane_global.npy\', \'mlt.png\'), \'depth\': im_name.strip().replace(\'plane_global.npy\', \'depth.png\'), \'normal\': im_name.strip().replace(\'plane_global.npy\', \'norm_camera.png\'), \'valid\': im_name.strip().replace(\'plane_global.npy\', \'valid.png\'), \'plane\': im_name.strip()} for im_name in f.readlines()]\n#             pass\n#     else:\n#         im_names = glob.glob(\'../../Data/NYU_RGBD/*_color.png\')\n#         im_names = [{\'image\': im_name, \'depth\': im_name.replace(\'color.png\', \'depth.png\'), \'normal\': im_name.replace(\'color.png\', \'norm_camera.png\'), \'invalid_mask\': im_name.replace(\'color.png\', \'valid.png\')} for im_name in im_names]\n#         pass\n      \n#     if numImages > 0:\n#         im_names = im_names[:numImages]\n#         pass\n\n#     #if args.imageIndex > 0:\n#     #im_names = im_names[args.imageIndex:args.imageIndex + 1]\n#     #pass    \n\n#     init_op = tf.group(tf.global_variables_initializer(),\n#                        tf.local_variables_initializer())\n\n\n#     with tf.Session(config=config) as sess:\n#         saver = tf.train.Saver()\n#         #sess.run(tf.global_variables_initializer())\n#         saver.restore(sess,""%s/%s.ckpt""%(options.checkpoint_dir,keyname))\n\n#         gtDepths = []\n#         predDepths = []\n#         segmentationDepths = []\n#         predDepthsOneHot = []\n#         planeMasks = []\n#         predMasks = []\n\n#         imageWidth = WIDTH\n#         imageHeight = HEIGHT\n#         focalLength = 517.97\n#         urange = np.arange(imageWidth).reshape(1, -1).repeat(imageHeight, 0) - imageWidth * 0.5\n#         vrange = np.arange(imageHeight).reshape(-1, 1).repeat(imageWidth, 1) - imageHeight * 0.5\n#         ranges = np.array([urange / focalLength, np.ones(urange.shape), -vrange / focalLength]).transpose([1, 2, 0])\n        \n#         cv2.imwrite(options.test_dir + \'/one.png\', np.ones((HEIGHT, WIDTH), dtype=np.uint8) * 255)\n#         cv2.imwrite(options.test_dir + \'/zero.png\', np.zeros((HEIGHT, WIDTH), dtype=np.uint8) * 255)\n#         for index, im_name in enumerate(im_names):\n#             if index <= -1:\n#                 continue\n#             print(im_name[\'image\'])\n#             im = cv2.imread(im_name[\'image\'])\n#             image = im.astype(np.float32, copy=False)\n#             image = image / 255 - 0.5\n#             image = cv2.resize(image, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n\n#             #planes = np.load(im_name[\'plane\'])\n#             # numPlanes = planes.shape[0]\n#             # if numPlanes > options.numOutputPlanes:\n#             #     planeAreas = planes[:, 3:].sum(1)\n#             #     sortInds = np.argsort(planeAreas)[::-1]\n#             #     planes = planes[sortInds[:options.numOutputPlanes]]\n#             #     pass\n#             # gt_p = np.zeros((1, options.numOutputPlanes, 3))\n#             # gt_p[0, :numPlanes] = planes[:numPlanes, :3]\n\n#             normal = np.array(PIL.Image.open(im_name[\'normal\'])).astype(np.float) / 255 * 2 - 1\n#             norm = np.linalg.norm(normal, 2, 2)\n#             for c in xrange(3):\n#                 normal[:, :, c] /= norm\n#                 continue\n#             normal = cv2.resize(normal, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n            \n#             depth = np.array(PIL.Image.open(im_name[\'depth\'])).astype(np.float) / 1000\n#             depth = cv2.resize(depth, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n\n#             invalid_mask = cv2.resize(cv2.imread(im_name[\'invalid_mask\'], 0), (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR) > 128\n\n#             gtDepths.append(depth)\n\n            \n#             pred_p, pred_d, pred_n, pred_s, pred_np_m, pred_np_d, pred_np_n, pred_boundary, pred_local_score, pred_local_p, pred_local_mask = sess.run([plane_pred, depth_pred, normal_pred, segmentation_pred, non_plane_mask_pred, non_plane_depth_pred, non_plane_normal_pred, boundary_pred, local_score_pred, local_p_pred, local_mask_pred], feed_dict = {img_inp:np.expand_dims(image, 0), plane_gt: np.zeros((batchSize, options.numOutputPlanes, 3))})\n\n\n#             pred_s = pred_s[0] \n#             pred_p = pred_p[0]\n#             pred_np_m = pred_np_m[0]\n#             pred_np_d = pred_np_d[0]\n#             pred_np_n = pred_np_n[0]\n#             #pred_s = 1 / (1 + np.exp(-pred_s))\n\n#             plane_depths = calcPlaneDepths(pred_p, WIDTH, HEIGHT)\n#             all_depths = np.concatenate([pred_np_d, plane_depths], axis=2)\n\n#             all_segmentations = np.concatenate([pred_np_m, pred_s], axis=2)\n#             segmentation = np.argmax(all_segmentations, 2)\n#             if suffix != \'pixelwise\':\n#                 pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape(HEIGHT, WIDTH)\n#             else:\n#                 pred_d = np.squeeze(pred_np_d)\n#                 pass\n#             predDepths.append(pred_d)\n#             predMasks.append(segmentation != 0)\n#             planeMasks.append(invalid_mask)\n\n#             #depthError, normalError, occupancy, segmentationTest, reconstructedDepth, occupancyMask = evaluatePlanes(pred_p, im_name[\'image\'])\n#             #reconstructedDepth = cv2.resize(reconstructedDepth, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n            \n#             #evaluatePlanes(pred_p[0], im_name, options.test_dir, index)\n#             #print(pred_p)\n#             #print(gt_p)\n#             #print((pow(pred_d[0, :, :, 0] - depth, 2) * (gt_s.max(2) > 0.5)).mean())\n#             #print((depthError, normalError, occupancy))\n            \n#             evaluateDepths(predDepths[index], gtDepths[index], np.ones(planeMasks[index].shape), planeMasks[index])\n\n#             if index >= 10:\n#                 continue\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', cv2.resize(im, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR))\n#             #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_gt.png\', (minDepth / np.clip(depth, minDepth, 20) * 255).astype(np.uint8))\n#             #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', (minDepth / np.clip(pred_d[0, :, :, 0], minDepth, 20) * 255).astype(np.uint8))\n#             #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_plane.png\', (minDepth / np.clip(reconstructedDepth, minDepth, 20) * 255).astype(np.uint8))\n\n#             pred_boundary = pred_boundary[0]\n#             boundary = (1 / (1 + np.exp(-pred_boundary)) * 255).astype(np.uint8)\n#             boundary = np.concatenate([boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_boundary_pred.png\', boundary)\n            \n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_inp.png\', drawDepthImage(depth))\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n#             #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_plane.png\', drawDepthImage(reconstructedDepth))\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred_diff.png\', drawDiffImage(pred_d, depth, 0.5))\n#             #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_plane_diff.png\', np.minimum(np.abs(reconstructedDepth - depth) / 0.5 * 255, 255).astype(np.uint8))\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_inp.png\', drawNormalImage(normal))\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_pred.png\', drawNormalImage(pred_np_n))\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(all_segmentations, black=True))\n\n#             segmentation = np.argmax(pred_s, 2)\n#             #writePLYFile(options.test_dir, index, image, pred_p, segmentation)\n\n#             if index < 0:\n#                 for planeIndex in xrange(options.numOutputPlanes):\n#                     cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_\' + str(planeIndex) + \'.png\', drawMaskImage(pred_s[:, :, planeIndex]))\n#                     #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_\' + str(planeIndex) + \'_gt.png\', drawMaskImage(gt_s[:, :, planeIndex]))\n#                     continue\n#                 pass\n#             continue\n#         predDepths = np.array(predDepths)\n#         gtDepths = np.array(gtDepths)\n#         planeMasks = np.array(planeMasks)\n#         predMasks = np.array(predMasks)\n#         #evaluateDepths(predDepths, gtDepths, planeMasks, predMasks)\n#         evaluateDepths(predDepths, gtDepths, planeMasks, planeMasks)\n#         #exit(1)\n#         pass\n#     return\n\n\n# def fitPlanesRGBD(options):\n#     writeHTMLRGBD(\'../results/RANSAC_RGBD/index.html\', 10)\n#     exit(1)\n#     if not os.path.exists(options.checkpoint_dir):\n#         os.system(""mkdir -p %s""%options.checkpoint_dir)\n#         pass\n#     if not os.path.exists(options.test_dir):\n#         os.system(""mkdir -p %s""%options.test_dir)\n#         pass\n    \n#     min_after_dequeue = 1000\n\n#     reader_rgbd = RecordReaderRGBD()\n#     filename_queue_rgbd = tf.train.string_input_producer([\'../planes_nyu_rgbd_train.tfrecords\'], num_epochs=1)\n#     img_inp_rgbd, global_gt_dict_rgbd, local_gt_dict_rgbd = reader_rgbd.getBatch(filename_queue_rgbd, numOutputPlanes=options.numOutputPlanes, batchSize=1, min_after_dequeue=min_after_dequeue, getLocal=True)\n\n#     config=tf.ConfigProto()\n#     config.gpu_options.allow_growth=True\n#     config.allow_soft_placement=True\n\n#     init_op = tf.group(tf.global_variables_initializer(),\n#                        tf.local_variables_initializer())\n\n#     with tf.Session(config=config) as sess:\n#         sess.run(init_op)\n\n#         coord = tf.train.Coordinator()\n#         threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n#         try:\n#             gtDepths = []\n#             predDepths = []\n#             planeMasks = []\n#             for index in xrange(10):\n#                 image, depth, path = sess.run([img_inp_rgbd, global_gt_dict_rgbd[\'depth\'], global_gt_dict_rgbd[\'path\']])\n#                 image = ((image[0] + 0.5) * 255).astype(np.uint8)\n#                 depth = depth.squeeze()\n                \n#                 cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', image)\n#                 cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth.png\', drawDepthImage(depth))\n#                 #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_mask.png\', drawMaskImage(depth == 0))\n#                 planes, planeSegmentation, depthPred = fitPlanes(depth, numPlanes=20)                \n#                 cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(planeSegmentation))\n#                 cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(depthPred))\n\n#                 gtDepths.append(depth)\n#                 predDepths.append(depthPred)\n#                 planeMasks.append((planeSegmentation < 20).astype(np.float32))\n#                 continue\n#             predDepths = np.array(predDepths)\n#             gtDepths = np.array(gtDepths)\n#             planeMasks = np.array(planeMasks)\n#             evaluateDepths(predDepths, gtDepths, np.ones(planeMasks.shape, dtype=np.bool), planeMasks)            \n#         except tf.errors.OutOfRangeError:\n#             print(\'done fitting\')\n#         finally:\n#             # When done, ask the threads to stop.\n#             coord.request_stop()\n#             pass\n#     return\n\ndef writeInfo(options):\n    x = (np.arange(11) * 0.1).tolist()\n    ys = []\n    ys.append(np.load(\'test/planenet_pixel_IOU.npy\').tolist())\n    ys.append(np.load(\'test/pixelwise_pred_pixel_IOU.npy\').tolist())\n    ys.append(np.load(\'test/pixelwise_gt_pixel_IOU.npy\').tolist())\n    plotCurves(x, ys, filename = \'test/plane_comparison.png\', xlabel=\'IOU\', ylabel=\'pixel coverage\', labels=[\'planenet\', \'pixelwise+RANSAC\', \'GT+RANSAC\'])\n\n    x = (0.5 - np.arange(11) * 0.05).tolist()\n    ys = []\n    ys.append(np.load(\'test/planenet_pixel_diff.npy\').tolist())\n    ys.append(np.load(\'test/pixelwise_pred_pixel_diff.npy\').tolist())\n    ys.append(np.load(\'test/pixelwise_gt_pixel_diff.npy\').tolist())\n    plotCurves(x, ys, filename = \'test/plane_comparison_diff.png\', xlabel=\'diff\', ylabel=\'pixel coverage\', labels=[\'planenet\', \'pixelwise+RANSAC\', \'GT+RANSAC\'])\n    \n    return\n\ndef parse_args():\n    """"""\n    Parse input arguments\n    """"""\n    parser = argparse.ArgumentParser(description=\'Planenet\')\n    parser.add_argument(\'--gpu\', dest=\'gpu_id\',\n                        help=\'GPU device id to use [0]\',\n                        default=0, type=int)\n    #task: [train, test, predict]\n    parser.add_argument(\'--task\', dest=\'task\',\n                        help=\'task type: [train, test, predict]\',\n                        default=\'train\', type=str)\n    parser.add_argument(\'--restore\', dest=\'restore\',\n                        help=\'how to restore the model\',\n                        default=0, type=int)\n    parser.add_argument(\'--numOutputPlanes\', dest=\'numOutputPlanes\',\n                        help=\'the number of output planes\',\n                        default=20, type=int)\n    parser.add_argument(\'--batchSize\', dest=\'batchSize\',\n                        help=\'batch size\',\n                        default=16, type=int)\n    parser.add_argument(\'--dataset\', dest=\'dataset\',\n                        help=\'dataset name for test/predict\',\n                        default=\'\', type=str)\n    parser.add_argument(\'--numImages\', dest=\'numImages\',\n                        help=\'the number of images to test/predict\',\n                        default=10, type=int)\n    parser.add_argument(\'--boundaryLoss\', dest=\'boundaryLoss\',\n                        help=\'use boundary loss: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--diverseLoss\', dest=\'diverseLoss\',\n                        help=\'use diverse loss: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--labelLoss\', dest=\'labelLoss\',\n                        help=\'use label loss: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--planeLoss\', dest=\'planeLoss\',\n                        help=\'use plane loss: [0, 1]\',\n                        default=1, type=int)        \n    parser.add_argument(\'--deepSupervision\', dest=\'deepSupervision\',\n                        help=\'deep supervision level: [0, 1, 2]\',\n                        default=0, type=int)\n    parser.add_argument(\'--sameMatching\', dest=\'sameMatching\',\n                        help=\'use the same matching for all deep supervision layers and the final prediction: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--anchorPlanes\', dest=\'anchorPlanes\',\n                        help=\'use anchor planes for all deep supervision layers and the final prediction: [0, 1]\',\n                        default=0, type=int) \n    parser.add_argument(\'--crf\', dest=\'crf\',\n                        help=\'the number of CRF iterations\',\n                        default=0, type=int)\n    parser.add_argument(\'--crfrnn\', dest=\'crfrnn\',\n                        help=\'the number of CRF (as RNN) iterations\',\n                        default=0, type=int)    \n    parser.add_argument(\'--backwardLossWeight\', dest=\'backwardLossWeight\',\n                        help=\'backward matching loss\',\n                        default=0, type=float)\n    parser.add_argument(\'--predictBoundary\', dest=\'predictBoundary\',\n                        help=\'whether predict boundary or not: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--predictSemantics\', dest=\'predictSemantics\',\n                        help=\'whether predict semantics or not: [0, 1]\',\n                        default=0, type=int)    \n    parser.add_argument(\'--predictLocal\', dest=\'predictLocal\',\n                        help=\'whether predict local planes or not: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--predictConfidence\', dest=\'predictConfidence\',\n                        help=\'whether predict plane confidence or not: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--predictPixelwise\', dest=\'predictPixelwise\',\n                        help=\'whether predict pixelwise depth or not: [0, 1]\',\n                        default=0, type=int)    \n    parser.add_argument(\'--fineTuningCheckpoint\', dest=\'fineTuningCheckpoint\',\n                        help=\'specify the model for fine-tuning\',\n                        default=\'../PlaneSetGeneration/dump_planenet_diverse/train_planenet_diverse.ckpt\', type=str)\n    parser.add_argument(\'--suffix\', dest=\'suffix\',\n                        help=\'add a suffix to keyname to distinguish experiments\',\n                        default=\'\', type=str)\n    parser.add_argument(\'--l2Weight\', dest=\'l2Weight\',\n                        help=\'L2 regulation weight\',\n                        default=5e-4, type=float)\n    parser.add_argument(\'--LR\', dest=\'LR\',\n                        help=\'learning rate\',\n                        default=3e-5, type=float)\n    parser.add_argument(\'--hybrid\', dest=\'hybrid\',\n                        help=\'hybrid training\',\n                        default=\'1\', type=str)\n    parser.add_argument(\'--rootFolder\', dest=\'rootFolder\',\n                        help=\'root folder\',\n                        default=\'/mnt/vision/PlaneNet/\', type=str)\n    parser.add_argument(\'--dataFolder\', dest=\'dataFolder\',\n                        help=\'data folder\',\n                        default=\'/home/chenliu/Projects/PlaneNet/\', type=str)\n    parser.add_argument(\'--saveInterval\', dest=\'saveInterval\',\n                        help=\'save interval\',\n                        default=900, type=int)\n    \n\n    args = parser.parse_args()\n    args.keyname = os.path.basename(__file__).rstrip(\'.py\')\n    args.keyname = args.keyname.replace(\'train_\', \'\')\n\n    if args.numOutputPlanes != 20:\n        args.keyname += \'_np\' + str(args.numOutputPlanes)\n        pass\n    args.keyname += \'_hybrid\' + args.hybrid\n    \n    if args.boundaryLoss != 1:\n        args.keyname += \'_bl\' + str(args.boundaryLoss)\n        pass\n    if args.diverseLoss == 0:\n        args.keyname += \'_dl0\'\n        pass\n    if args.labelLoss == 1:\n        args.keyname += \'_ll1\'\n        pass    \n    if args.planeLoss == 0:\n        args.keyname += \'_pl0\'\n        pass\n    if args.deepSupervision != 1:\n        args.keyname += \'_ds\' + str(args.deepSupervision)\n        pass\n    if args.crf > 0:\n        args.keyname += \'_crf\' + str(args.crf)\n        pass\n    if args.crfrnn != 0:\n        args.keyname += \'_crfrnn\' + str(args.crfrnn)\n        pass\n    if args.backwardLossWeight > 0:\n        args.keyname += \'_bw\' + str(args.backwardLossWeight)\n        pass\n    if args.predictBoundary == 1:\n        args.keyname += \'_pb\'\n        pass\n    if args.predictConfidence == 1:\n        args.keyname += \'_pc\'\n        pass        \n    # if args.predictLocal == 1:\n    #     args.keyname += \'_pl\'\n    #     pass\n    if args.predictPixelwise == 1:\n        args.keyname += \'_pp\'\n        pass\n    if args.predictSemantics == 1:\n        args.keyname += \'_ps\'\n        pass    \n    if args.sameMatching == 0:\n        args.keyname += \'_sm0\'\n        pass\n    if args.anchorPlanes == 1:\n        args.keyname += \'_ap1\'\n        pass\n\n    #args.predictSemantics = 0\n    #args.predictBoundary = 0\n    \n    args.checkpoint_dir = args.rootFolder + \'/checkpoint/\' + args.keyname\n    args.log_dir = \'log/\' + args.keyname\n    args.test_dir = \'test/\' + args.keyname + \'_\' + args.dataset\n    args.predict_dir = \'predict/\' + args.keyname + \'_\' + args.dataset\n    args.dump_dir = \'dump/\' + args.keyname\n    \n    #layers where deep supervision happens\n    args.deepSupervisionLayers = []\n    if args.deepSupervision >= 1:\n        args.deepSupervisionLayers.append(\'res4b22_relu\')\n        pass\n    if args.deepSupervision >= 2:\n        args.deepSupervisionLayers.append(\'res4b12_relu\')\n        pass\n    \n    args.predictSemantics = 0\n    args.predictPixelwise = 0    \n    return args\n\n\nif __name__==\'__main__\':\n\n    # plane = np.load(\'temp/plane.npy\')\n    # depth = np.load(\'temp/depth.npy\')    \n    # segmentation = np.load(\'temp/segmentation.npy\')\n    # info = np.load(\'temp/info.npy\')\n    # num_planes = np.load(\'temp/num_planes.npy\')\n    # segmentation = np.argmax(segmentation, axis=-1)\n    # print(segmentation.shape)\n    # planes, segmentation, numPlanes = removeSmallSegments(plane, np.zeros((HEIGHT, WIDTH, 3)), depth.squeeze(), np.zeros((HEIGHT, WIDTH, 3)), segmentation, np.zeros((HEIGHT, WIDTH)), info, num_planes)\n    # print(planes)\n    # exit(1)\n    \n    args = parse_args()\n\n    print ""keyname=%s task=%s started""%(args.keyname, args.task)\n    try:\n        if args.task == ""train"":\n            main(args)\n        elif args.task == ""test"":\n            test(args)\n        elif args.task == ""predict"":\n            predict(args)\n        elif args.task == ""fit"":\n            fitPlanesRGBD(args)\n        elif args.task == ""write"":\n            writeInfo(args)\n        else:\n            assert False,""format wrong""\n            pass\n    finally:\n        pass\n\n'"
code/train_pixelwise.py,86,"b'import tensorflow as tf\nimport numpy as np\nnp.set_printoptions(precision=2, linewidth=200)\nimport cv2\nimport os\nimport time\nimport sys\nimport tf_nndistance\nimport argparse\nimport glob\nimport PIL\nimport scipy.ndimage as ndimage\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom utils import *\nfrom plane_utils import *\nfrom modules import *\n\n\nfrom train_sample import build_graph as build_graph\nfrom planenet import PlaneNet\nfrom RecordReader import *\nfrom RecordReaderRGBD import *\nfrom RecordReader3D import *\nfrom RecordReaderAll import *\n#from SegmentationRefinement import *\n#training_flag: toggle dropout and batch normalization mode\n#it\'s true for training and false for validation, testing, prediction\n#it also controls which data batch to use (*_train or *_val)\n\n\n\ndef build_loss(img_inp_train, img_inp_val, global_pred_dict, deep_pred_dicts, global_gt_dict_train, global_gt_dict_val, training_flag, options):\n    with tf.device(\'/gpu:%d\'%options.gpu_id):\n        debug_dict = {}\n\n        img_inp = tf.cond(training_flag, lambda: img_inp_train, lambda: img_inp_val)        \n        global_gt_dict = {}\n        for name in global_gt_dict_train.keys():\n            global_gt_dict[name] = tf.cond(training_flag, lambda: global_gt_dict_train[name], lambda: global_gt_dict_val[name])\n            continue\n        # local_gt_dict = {}\n        # for name in local_gt_dict_train.keys():\n        #     local_gt_dict[name] = tf.cond(tf.equal(training_flag % 2, 0), lambda: local_gt_dict_train[name], lambda: local_gt_dict_val[name])\n        #     continue\n\n        plane_parameters = tf.reshape(global_pred_dict[\'plane\'], (-1, 3))\n        info = global_gt_dict[\'info\'][0]\n        plane_depths = planeDepthsModule(plane_parameters, WIDTH, HEIGHT, info)\n        plane_depths = tf.transpose(tf.reshape(plane_depths, [HEIGHT, WIDTH, -1, options.numOutputPlanes]), [2, 0, 1, 3])\n\n        non_plane_depth = global_pred_dict[\'non_plane_depth\']\n        all_depths = tf.concat([plane_depths, non_plane_depth], axis=3)\n\n        \n\n        #if options.predictPixelwise == 1:\n        validDepthMask = tf.cast(tf.greater(global_gt_dict[\'depth\'], 1e-4), tf.float32)\n        numValidPixels = tf.reduce_sum(validDepthMask, axis=[1, 2, 3])        \n        depth_loss = tf.constant(0.0)\n        if options.predictPlanes == 1:\n            all_segmentations = tf.concat([global_pred_dict[\'segmentation\'], global_pred_dict[\'non_plane_mask\']], axis=3)\n            all_segmentations_softmax = tf.nn.softmax(all_segmentations)\n            depth_loss += tf.reduce_mean(tf.reduce_sum(tf.squared_difference(all_depths, global_gt_dict[\'depth\']) * all_segmentations_softmax, axis=3, keep_dims=True) * validDepthMask) * 10000\n        else:\n            depth_diff = global_pred_dict[\'non_plane_depth\'] - global_gt_dict[\'depth\']\n            depth_diff_gx = depth_diff - tf.concat([tf.ones([options.batchSize, HEIGHT, 1, 1]), depth_diff[:, :, :WIDTH - 1]], axis=2)\n            depth_diff_gy = depth_diff - tf.concat([tf.ones([options.batchSize, 1, WIDTH, 1]), depth_diff[:, :HEIGHT - 1]], axis=1)\n\n            depth_loss += tf.reduce_mean(tf.reduce_sum(tf.pow(depth_diff * validDepthMask, 2), axis=[1, 2, 3]) / numValidPixels - 0.5 * tf.pow(tf.reduce_sum(depth_diff * validDepthMask, axis=[1, 2, 3]) / numValidPixels, 2) + tf.reduce_sum((tf.pow(depth_diff_gx, 2) + tf.pow(depth_diff_gy, 2)) * validDepthMask, axis=[1, 2, 3]) / numValidPixels) * 1000\n            pass\n        \n        #depth_loss += tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_depth\'], global_gt_dict[\'depth\']) * validDepthMask) * 10000\n\n\n        valid_normal_mask = tf.squeeze(tf.cast(tf.less(tf.slice(global_gt_dict[\'info\'], [0, 19], [options.batchSize, 1]), 2), tf.float32))\n        normal_gt = tf.nn.l2_normalize(global_gt_dict[\'normal\'], dim=-1)\n        normal_loss = tf.reduce_mean(tf.reduce_sum(-global_pred_dict[\'non_plane_normal\'] * normal_gt * validDepthMask, axis=[1, 2, 3]) / numValidPixels * valid_normal_mask) * 1000\n        #normal_loss = tf.reduce_mean(tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_normal\'], global_gt_dict[\'normal\']) * validDepthMask, axis=[1, 2, 3]) * valid_normal_mask) * 1000\n        #normal_loss = tf.constant(0.0)\n\n        if options.predictSemantics:\n            valid_semantics_mask = tf.squeeze(tf.cast(tf.not_equal(tf.slice(global_gt_dict[\'info\'], [0, 19], [options.batchSize, 1]), 1), tf.float32))\n            semantics_loss = tf.reduce_mean(tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=global_pred_dict[\'semantics\'], labels=global_gt_dict[\'semantics\']), axis=[1, 2]) * valid_semantics_mask) * 1000\n            pass\n        \n\n        l2_losses = tf.add_n([options.l2Weight * tf.nn.l2_loss(v) for v in tf.trainable_variables() if \'weights\' in v.name])\n\n\n        #loss = depth_loss + normal_loss + semantics_loss + l2_losses\n        loss = depth_loss + l2_losses\n\n        #if options.pixelwiseLoss:\n        #normal_loss = tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_normal\'], global_gt_dict[\'normal\'])) * 1000\n        #depth_loss = tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_depth\'], global_gt_dict[\'depth\']) * validDepthMask) * 1000\n        #pass\n\n        #loss_dict = {\'depth\': depth_loss, \'normal\': normal_loss, \'semantics\': semantics_loss}\n        loss_dict = {\'depth\': depth_loss}\n        pass\n    return loss, loss_dict, debug_dict\n\n\ndef main(options):\n    if not os.path.exists(options.checkpoint_dir):\n        os.system(""mkdir -p %s""%options.checkpoint_dir)\n        pass\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n    \n    min_after_dequeue = 1000\n\n\n    train_inputs = []\n    val_inputs = []\n    if \'0\' in options.hybrid:\n        train_inputs.append(options.rootFolder + \'/planes_SUNCG_train.tfrecords\')\n        val_inputs.append(options.rootFolder + \'/planes_SUNCG_val.tfrecords\')        \n        pass\n    if \'1\' in options.hybrid:\n        for _ in xrange(10):\n            train_inputs.append(options.rootFolder + \'/planes_nyu_rgbd_train.tfrecords\')\n            train_inputs.append(options.rootFolder + \'/planes_nyu_rgbd_labeled_train.tfrecords\')\n            val_inputs.append(options.rootFolder + \'/planes_nyu_rgbd_val.tfrecords\')\n            continue\n        pass\n    if \'2\' in options.hybrid:\n        train_inputs.append(options.rootFolder + \'/planes_matterport_train.tfrecords\')\n        val_inputs.append(options.rootFolder + \'/planes_matterport_val.tfrecords\')\n        pass\n    if \'3\' in options.hybrid:\n        train_inputs.append(options.rootFolder + \'/planes_scannet_train.tfrecords\')\n        val_inputs.append(options.rootFolder + \'/planes_scannet_val.tfrecords\')\n        pass\n    \n    reader_train = RecordReaderAll()\n    filename_queue_train = tf.train.string_input_producer(train_inputs, num_epochs=10000)    \n    img_inp_train, global_gt_dict_train, local_gt_dict_train = reader_train.getBatch(filename_queue_train, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True)\n\n    reader_val = RecordReaderAll()\n    filename_queue_val = tf.train.string_input_producer(val_inputs, num_epochs=10000)\n    img_inp_val, global_gt_dict_val, local_gt_dict_val = reader_val.getBatch(filename_queue_val, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True)\n    \n    training_flag = tf.placeholder(tf.bool, shape=[], name=\'training_flag\')\n    \n    #global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp_train, img_inp_val, img_inp_rgbd_train, img_inp_rgbd_val, img_inp_3d_train, img_inp_3d_val, training_flag, options)\n    global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp_train, img_inp_val, training_flag, options)\n    \n    \n    #loss, loss_dict, _ = build_loss(global_pred_dict, local_pred_dict, deep_pred_dicts, global_gt_dict_train, local_gt_dict_train, global_gt_dict_val, local_gt_dict_val, training_flag, options)\n    #loss_rgbd, loss_dict_rgbd, _ = build_loss_rgbd(global_pred_dict, deep_pred_dicts, global_gt_dict_rgbd_train, global_gt_dict_rgbd_val, training_flag, options)\n    loss, loss_dict, _ = build_loss(img_inp_train, img_inp_val, global_pred_dict, deep_pred_dicts, global_gt_dict_train, global_gt_dict_val, training_flag, options)    \n        \n    #loss = tf.cond(tf.less(training_flag, 2), lambda: loss, lambda: tf.cond(tf.less(training_flag, 4), lambda: loss_rgbd, lambda: loss_3d))\n\n    \n    #train_writer = tf.summary.FileWriter(options.log_dir + \'/train\')\n    #val_writer = tf.summary.FileWriter(options.log_dir + \'/val\')\n    #train_writer_rgbd = tf.summary.FileWriter(options.log_dir + \'/train_rgbd\')\n    #val_writer_rgbd = tf.summary.FileWriter(options.log_dir + \'/val_rgbd\')\n    #writers = [train_writer, val_writer, train_writer_rgbd, val_writer_rgbd]\n    \n\n    with tf.variable_scope(\'statistics\'):\n        batchno = tf.Variable(0, dtype=tf.int32, trainable=False, name=\'batchno\')\n        batchnoinc=batchno.assign(batchno+1)\n        pass\n\n\n    optimizer = tf.train.AdamOptimizer(options.LR)\n    train_op = optimizer.minimize(loss, global_step=batchno)\n\n    var_to_restore = [v for v in tf.global_variables()]\n\n    tf.summary.scalar(\'loss\', loss)\n    summary_op = tf.summary.merge_all()\n\n    \n    config=tf.ConfigProto()\n    config.allow_soft_placement=True    \n    #config.gpu_options.allow_growth=True\n    config.gpu_options.per_process_gpu_memory_fraction=0.9\n    saver=tf.train.Saver()\n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n    \n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n        if options.restore == 0:\n            #fine-tune from DeepLab model\n            var_to_restore = [v for v in var_to_restore if \'res5d\' not in v.name and \'segmentation\' not in v.name and \'plane\' not in v.name and \'deep_supervision\' not in v.name and \'local\' not in v.name and \'boundary\' not in v.name and \'degridding\' not in v.name and \'res2a_branch2a\' not in v.name and \'res2a_branch1\' not in v.name and \'Adam\' not in v.name and \'beta\' not in v.name and \'statistics\' not in v.name and \'semantics\' not in v.name]\n            pretrained_model_loader = tf.train.Saver(var_to_restore)\n            pretrained_model_loader.restore(sess,""../pretrained_models/deeplab_resnet.ckpt"")\n        elif options.restore == 1:\n            #restore the same model from checkpoint\n            loader = tf.train.Saver(var_to_restore)\n            loader.restore(sess,""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n            bno=sess.run(batchno)\n            print(bno)\n        elif options.restore == 2:            \n            #restore the same model from checkpoint but reset batchno to 1\n            loader = tf.train.Saver(var_to_restore)\n            loader.restore(sess,""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n            sess.run(batchno.assign(1))\n        elif options.restore == 3:            \n            #restore the same model from standard training\n            # if options.predictBoundary == 1:\n            #     var_to_restore = [v for v in var_to_restore if \'boundary\' not in v.name]\n            #     pass            \n            # if options.predictConfidence == 1:\n            #     var_to_restore = [v for v in var_to_restore if \'confidence\' not in v.name]\n            #     pass\n            if options.predictSemantics == 1:\n                var_to_restore = [v for v in var_to_restore if \'semantics\' not in v.name]\n                pass\n\n            loader = tf.train.Saver(var_to_restore)\n            if len(options.hybrid) == 1:\n                hybrid = options.hybrid\n            else:\n                hybrid = str(3)\n                pass\n            #loader.restore(sess, options.rootFolder + \'/checkpoint/planenet_hybrid\' + hybrid + \'_bl0_ll1_bw0.5_pb_pp_ps_sm0/checkpoint.ckpt\')\n            #loader.restore(sess, options.rootFolder + \'/checkpoint/planenet_hybrid\' + hybrid + \'_bl0_dl0_ll1_bw0.5_pb_pp/checkpoint.ckpt\')\n            loader.restore(sess, options.rootFolder + \'/checkpoint/sample_np10_hybrid3_bl0_dl0_hl2_ds0_crfrnn5_sm0/checkpoint.ckpt\')            \n            #loader.restore(sess,""checkpoint/planenet/checkpoint.ckpt"")\n            sess.run(batchno.assign(1))\n        elif options.restore == 4:\n            #fine-tune another model\n            #var_to_restore = [v for v in var_to_restore if \'res4b22_relu_non_plane\' not in v.name]\n            loader = tf.train.Saver(var_to_restore)\n            loader.restore(sess, options.fineTuningCheckpoint)\n            sess.run(batchno.assign(1))\n            pass\n        # Start input enqueue threads.\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n        MOVING_AVERAGE_DECAY = 0.99\n        ema = [0., 0., 0., 0.]\n        ema_acc = [1e-10, 1e-10, 1e-10, 1e-10]\n        last_snapshot_time = time.time()\n        bno=sess.run(batchno)\n\n        try:\n            while bno<300000:\n                t0 = time.time()\n\n                batchIndexPeriod = bno % 100\n                if batchIndexPeriod < len(options.hybrid):\n                    #batchType = int(options.hybrid[batchIndexPeriod]) * 2 + 1\n                    batchType = 1\n                    _, total_loss, losses, summary_str, gt_dict = sess.run([batchnoinc, loss, loss_dict, summary_op, global_pred_dict], feed_dict = {training_flag: batchType == 0})\n                    \n                else:\n                    batchType = 0\n                    _, total_loss, losses, summary_str, gt_dict = sess.run([train_op, loss, loss_dict, summary_op, global_pred_dict], feed_dict = {training_flag: batchType == 0})\n                    pass\n\n                # for batchIndex in xrange(options.batchSize):\n                #     if np.isnan(global_gt[\'plane\'][batchIndex]).any():\n                #         #print(losses)\n                #         #print(global_gt[\'plane\'][batchIndex])\n                #         print(global_gt[\'num_planes\'][batchIndex])\n                #         for planeIndex in xrange(global_gt[\'num_planes\'][batchIndex]):\n                #             cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(global_gt[\'segmentation\'][batchIndex, :, :, planeIndex]))\n                #             continue\n                #         np.save(\'temp/plane.npy\', global_gt[\'plane\'][batchIndex])                        \n                #         np.save(\'temp/depth.npy\', global_gt[\'depth\'][batchIndex])\n                #         np.save(\'temp/segmentation.npy\', global_gt[\'segmentation\'][batchIndex])\n                #         np.save(\'temp/info.npy\', global_gt[\'info\'][batchIndex])\n                #         np.save(\'temp/num_planes.npy\', global_gt[\'num_planes\'][batchIndex])\n                #         planes, segmentation, numPlanes = removeSmallSegments(global_gt[\'plane\'][batchIndex], np.zeros((HEIGHT, WIDTH, 3)), global_gt[\'depth\'][batchIndex].squeeze(), np.zeros((HEIGHT, WIDTH, 3)), np.argmax(global_gt[\'segmentation\'][batchIndex], axis=-1), global_gt[\'semantics\'][batchIndex], global_gt[\'info\'][batchIndex], global_gt[\'num_planes\'][batchIndex])\n                #         print(planes)\n                #         exit(1)\n                #         pass\n                #     continue\n                #writers[batchType].add_summary(summary_str, bno)\n                ema[batchType] = ema[batchType] * MOVING_AVERAGE_DECAY + total_loss\n                ema_acc[batchType] = ema_acc[batchType] * MOVING_AVERAGE_DECAY + 1\n\n                bno = sess.run(batchno)\n                if time.time()-last_snapshot_time > options.saveInterval:\n                    print(\'save snapshot\')\n                    saver.save(sess,\'%s/checkpoint.ckpt\'%options.checkpoint_dir)\n                    last_snapshot_time = time.time()\n                    pass\n        \n                print bno,\'train\', ema[0] / ema_acc[0], \'val\', ema[1] / ema_acc[1], \'train rgbd\', ema[2] / ema_acc[2], \'val rgbd\', ema[3] / ema_acc[3], \'loss\', total_loss, \'time\', time.time()-t0\n\n                if np.random.random() < 0.01:\n                    print(losses)\n                    pass                \n                continue\n\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n        \n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return\n\n\ndef test(options):\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n\n    if options.dataset == \'\':\n        assert(len(options.hybrid) == 1)\n        if options.hybrid == \'0\':\n            options.dataset = \'SUNCG\'\n        elif options.hybrid == \'1\':\n            options.dataset = \'NYU_RGBD\'\n        elif options.hybrid == \'2\':\n            options.dataset = \'matterport\'\n        elif options.hybrid == \'3\':\n            options.dataset = \'ScanNet\'\n            \n        options.dataset\n    options.batchSize = 1\n    min_after_dequeue = 1000\n\n    reader = RecordReaderAll()\n    if options.dataset == \'SUNCG\':\n        filename_queue = tf.train.string_input_producer([options.rootFolder + \'/planes_SUNCG_val.tfrecords\'], num_epochs=10000)\n    elif options.dataset == \'NYU_RGBD\':\n        filename_queue = tf.train.string_input_producer([options.rootFolder + \'/planes_nyu_rgbd_val.tfrecords\'], num_epochs=1)\n        options.deepSupervision = 0\n        options.predictLocal = 0\n    elif options.dataset == \'matterport\':\n        filename_queue = tf.train.string_input_producer([options.rootFolder + \'/planes_matterport_val.tfrecords\'], num_epochs=1)\n    else:\n        filename_queue = tf.train.string_input_producer([options.rootFolder + \'/planes_scannet_train.tfrecords\'], num_epochs=1)\n        pass\n    img_inp, global_gt_dict, local_gt_dict = reader.getBatch(filename_queue, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True, random=False)\n\n    training_flag = tf.constant(False, tf.bool)\n\n    global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp, img_inp, global_gt_dict, training_flag, options)\n    var_to_restore = tf.global_variables()\n\n    loss, loss_dict, debug_dict = build_loss(img_inp, img_inp, global_pred_dict, deep_pred_dicts, global_gt_dict, global_gt_dict, training_flag, options)\n    \n\n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n    \n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n        #var_to_restore = [v for v in var_to_restore if \'res4b22_relu_non_plane\' not in v.name]\n        loader = tf.train.Saver(var_to_restore)\n        loader.restore(sess, ""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n        #loader.restore(sess, ""%s/checkpoint.ckpt""%(\'checkpoint/planenet_pb_pp_hybrid1\'))\n        #loader.restore(sess, options.fineTuningCheckpoint)\n        \n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n        \n        \n        try:\n            gtDepths = []\n            predDepths = []\n            planeMasks = []\n            #predMasks = []\n            gtPlanes = []\n            predPlanes = []\n            gtSegmentations = []\n            predSegmentations = []\n            gtNumPlanes = []\n            \n            imageWidth = WIDTH\n            imageHeight = HEIGHT\n            focalLength = 517.97\n            urange = np.arange(imageWidth).reshape(1, -1).repeat(imageHeight, 0) - imageWidth * 0.5\n            vrange = np.arange(imageHeight).reshape(-1, 1).repeat(imageWidth, 1) - imageHeight * 0.5\n            ranges = np.array([urange / imageWidth * 640 / focalLength, np.ones(urange.shape), -vrange / imageHeight * 480 / focalLength]).transpose([1, 2, 0])\n\n\n            for index in xrange(10):\n                print((\'image\', index))\n                t0=time.time()\n\n                img, global_gt, local_gt, global_pred, local_pred, deep_preds, total_loss, losses, debug = sess.run([img_inp, global_gt_dict, local_gt_dict, global_pred_dict, local_pred_dict, deep_pred_dicts, loss, loss_dict, debug_dict])\n\n                # print(options.test_dir)\n                # cv2.imwrite(options.test_dir + \'/depth.png\', drawDepthImage(debug[\'depth\'][0]))\n                # cv2.imwrite(options.test_dir + \'/normal.png\', drawNormalImage(debug[\'normal\'][0]))\n                # boundary = debug[\'boundary\'][0]\n                # boundary = np.concatenate([boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)\n                # cv2.imwrite(options.test_dir + \'/boundary.png\', drawMaskImage(boundary))\n                # cv2.imwrite(options.test_dir + \'/depth_gt.png\', drawDepthImage(debug[\'depth_gt\'][0].squeeze()))\n                # exit(1)\n\n                if \'pixelwise\' in options.suffix or True:\n                    image = ((img[0] + 0.5) * 255).astype(np.uint8)\n                    gt_d = global_gt[\'depth\'].squeeze()\n                    pred_d = global_pred[\'non_plane_depth\'].squeeze()\n                    #depth = global_gt[\'depth\'].squeeze()\n                    if \'_2\' in options.suffix:\n                        pred_p, pred_s, pred_d = fitPlanes(pred_d, numPlanes=20, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=0.2)\n                    elif \'_3\' in options.suffix:\n                        pred_p, pred_s, pred_d = fitPlanes(gt_d, numPlanes=20, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=0.2)\n                        pass\n\n                    # gt_p = global_gt[\'plane\'][0]\n                    # pred_p = planes\n                    # valid_mask = (np.linalg.norm(gt_p, axis=1) > 0).astype(np.float32)\n                    # diff = np.min(np.linalg.norm(np.expand_dims(gt_p, 1) - np.expand_dims(pred_p, 0), axis=2), 1)\n                    # num += valid_mask.sum()\n                    # lossSum += (diff * valid_mask).sum()\n                    if options.dataset == \'SUNCG\':\n                        planeMask = np.squeeze(debug[\'segmentation\']).sum(axis=2)\n                    else:\n                        planeMask = np.ones((HEIGHT, WIDTH))\n                        if \'_2\' in options.suffix or \'_3\' in options.suffix:\n                            planeMask *= (pred_s < 20).astype(np.float32)\n                        pass\n                    \n                    if index < 10:\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', image)\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth.png\', drawDepthImage(gt_d))\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n                        if \'_2\' in options.suffix or \'_3\' in options.suffix:\n                            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(pred_s))\n                            pass\n                        #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_plane_mask.png\', drawMaskImage(planeMask))                \n                        pass\n\n                        \n                    gtDepths.append(gt_d)\n                    predDepths.append(pred_d)\n                    planeMasks.append(planeMask)\n\n\n                    if options.dataset != \'NYU_RGBD\' and (\'_2\' in options.suffix or \'_3\' in options.suffix):\n                        gt_p = global_gt[\'plane\'][0]\n                        gt_s = global_gt[\'segmentation\'][0]\n                        gt_num_p = global_gt[\'num_planes\'][0]\n\n                        pred_s = (np.expand_dims(pred_s, -1) == np.reshape(np.arange(options.numOutputPlanes), [1, 1, -1])).astype(np.float32)\n                        gtPlanes.append(gt_p)\n                        predPlanes.append(pred_p)\n                        gtSegmentations.append(gt_s)\n                        gtNumPlanes.append(gt_num_p)\n                        predSegmentations.append(pred_s)\n                        pass\n                    \n                    #planeMasks.append((planeSegmentation < 20).astype(np.float32))\n                    continue\n                \n                print(losses)\n                print(total_loss)\n                #print(losses)\n                #exit(1)\n                im = img[0]\n                image = ((im + 0.5) * 255).astype(np.uint8)                \n\n                gt_d = global_gt[\'depth\'].squeeze()\n                                \n\n                if options.predictLocal:\n                    pred_local_s = 1 / (1 + np.exp(-local_pred[\'score\'][0]))\n                    pred_local_p = local_pred[\'plane\'][0]\n                    pred_local_m = local_pred[\'mask\'][0]\n                  \n                    gt_local_s = local_gt[\'score\'][0]\n                    gt_local_m = local_gt[\'mask\'][0]\n\n                    #visualize local plane prediction\n                    stride = 8\n                    boxSize = 64\n                    xs = np.arange(WIDTH / stride) * stride + stride / 2\n                    ys = np.arange(HEIGHT / stride) * stride + stride / 2\n                    padding = boxSize / 2 + 1\n                    maskImage = np.zeros((HEIGHT + padding * 2, WIDTH + padding * 2, 3), dtype=np.uint8)\n                    maskImage[padding:padding + HEIGHT, padding:padding + WIDTH, :] = image / 2\n                    for gridY, y in enumerate(ys):\n                        for gridX, x in enumerate(xs):\n                            score = pred_local_s[gridY][gridX]\n                            if score < 0.5:\n                                continue                              \n                            mask = pred_local_m[gridY][gridX].reshape([16, 16])        \n                            mask = cv2.resize(mask, (boxSize, boxSize))\n                            maskImage[y - boxSize / 2 + padding:y + boxSize / 2 + padding, x - boxSize / 2 + padding:x + boxSize / 2 + padding, 0][mask > 0.5] = 255\n                            continue\n                        continue\n                    for gridY, y in enumerate(ys):\n                        for gridX, x in enumerate(xs):\n                            score = gt_local_s[gridY][gridX]\n                            if score < 0.5:\n                                continue                              \n                            mask = gt_local_m[gridY][gridX].reshape([16, 16])        \n                            mask = cv2.resize(mask, (boxSize, boxSize))\n                            maskImage[y - boxSize / 2 + padding:y + boxSize / 2 + padding, x - boxSize / 2 + padding:x + boxSize / 2 + padding, 2][mask > 0.5] = 255\n                            continue\n                        continue\n                    pass\n\n                pred_p = global_pred[\'plane\'][0]\n                pred_s = global_pred[\'segmentation\'][0]\n\n                pred_np_m = global_pred[\'non_plane_mask\'][0]\n                pred_np_d = global_pred[\'non_plane_depth\'][0]\n                pred_np_n = global_pred[\'non_plane_normal\'][0]\n                \n                planeMask = 1 - global_gt[\'non_plane_mask\'][0]\n                info = global_gt[\'info\'][0]\n\n                \n                all_segmentations = np.concatenate([pred_s, pred_np_m], axis=2)\n                all_segmentations_softmax = softmax(all_segmentations)\n                segmentation = np.argmax(all_segmentations, 2)\n                \n                \n                #pred_p, segmentation, numPlanes = mergePlanes(global_gt[\'plane\'][0], np.concatenate([global_gt[\'segmentation\'][0], global_gt[\'non_plane_mask\'][0]], axis=2), global_gt[\'depth\'][0].squeeze(), global_gt[\'info\'][0], np.concatenate([pred_s, pred_np_m], axis=2))\n                \n\n                plane_depths = calcPlaneDepths(pred_p, WIDTH, HEIGHT, info)\n                all_depths = np.concatenate([plane_depths, pred_np_d], axis=2)\n                \n                pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape(HEIGHT, WIDTH)\n\n                plane_normals = calcPlaneNormals(pred_p, WIDTH, HEIGHT)\n                all_normals = np.concatenate([plane_normals, np.expand_dims(pred_np_n, 2)], axis=2)\n                pred_n = np.sum(all_normals * np.expand_dims(one_hot(segmentation, options.numOutputPlanes+1), -1), 2)\n                #pred_n = all_normals.reshape(-1, options.numOutputPlanes + 1, 3)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape((HEIGHT, WIDTH, 3))\n                \n\n                if False:\n                    gt_s = global_gt[\'segmentation\'][0]\n                    all_segmentations = np.concatenate([gt_s, 1 - planeMask], axis=2)\n                    gt_p = global_gt[\'plane\'][0]\n\n                    # valid_mask = (np.linalg.norm(gt_p, axis=1) > 0).astype(np.float32)\n                    # diff = np.min(np.linalg.norm(np.expand_dims(gt_p, 1) - np.expand_dims(pred_p, 0), axis=2), 1)\n                    # num += valid_mask.sum()\n                    # lossSum += (diff * valid_mask).sum()\n                    #gt_p = np.stack([-gt_p[:, 0], -gt_p[:, 2], -gt_p[:, 1]], axis=1)\n                    \n                    plane_depths = calcPlaneDepths(gt_p, WIDTH, HEIGHT, info)\n                    all_depths = np.concatenate([plane_depths, pred_np_d], axis=2)\n\n                    segmentation = np.argmax(all_segmentations, 2)\n                    pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape(HEIGHT, WIDTH)\n                    # print(gt_p)\n                    # for segmentIndex in xrange(options.numOutputPlanes):\n                    #     cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_mask_\' + str(segmentIndex) + \'.png\', drawMaskImage(segmentation == segmentIndex))\n                    #     continue\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n                    #exit(1)\n                    pass\n\n                \n\n                gt_p = global_gt[\'plane\'][0]\n                gt_s = global_gt[\'segmentation\'][0]\n                gt_num_p = global_gt[\'num_planes\'][0]\n                gtPlanes.append(gt_p)\n                predPlanes.append(pred_p)\n                gtSegmentations.append(gt_s)\n                gtNumPlanes.append(gt_num_p)\n                predSegmentations.append(pred_s)\n                \n            \n                gtDepths.append(gt_d)\n                planeMasks.append(planeMask.squeeze())\n                predDepths.append(pred_d)\n                evaluateDepths(predDepths[-1], gtDepths[-1], gtDepths[-1] > 0, planeMasks[-1])\n                \n                \n                if index >= 10:\n                    continue\n\n                if options.predictSemantics:\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_semantics_pred.png\', drawSegmentationImage(global_pred[\'semantics\'][0], blackIndex=0))\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_semantics_gt.png\', drawSegmentationImage(global_gt[\'semantics\'][0], blackIndex=0))\n                    pass\n\n                if \'cost_mask\' in debug:\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_cost_mask.png\', drawMaskImage(np.sum(debug[\'cost_mask\'][0], axis=-1)))\n\n                    for planeIndex in xrange(options.numOutputPlanes + 1):\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_cost_mask_\' + str(planeIndex) + \'.png\', drawMaskImage(debug[\'cost_mask\'][0, :, :, planeIndex]))\n                        continue\n                    all_segmentations = np.concatenate([pred_s, pred_np_m], axis=2)\n                    for planeIndex in xrange(options.numOutputPlanes + 1):\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred_\' + str(planeIndex) + \'.png\', drawMaskImage(all_segmentations[:, :, planeIndex]))\n                        continue\n                    exit(1)\n                    pass\n                \n                if \'normal\' in global_gt:\n                    gt_n = global_gt[\'normal\'][0]\n                    norm = np.linalg.norm(gt_n, axis=-1, keepdims=True)\n                    gt_n /= np.maximum(norm, 1e-4)\n                    \n                    #gt_n = np.stack([-gt_n[:, :, 0], -gt_n[:, :, 2], -gt_n[:, :, 1]], axis=2)\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_gt.png\', drawNormalImage(gt_n))\n                    #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_pred.png\', drawNormalImage(pred_np_n))\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_pred.png\', drawNormalImage(pred_n))\n                    pass\n                \n                if \'segmentation\' in global_gt:\n                    gt_s = global_gt[\'segmentation\'][0]\n                    gt_p = global_gt[\'plane\'][0]\n\n                    \n                    #for planeIndex in xrange(20):\n                    #cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(gt_s[:, :, planeIndex]))\n                    #continue\n                    \n                    \n                    # print(gt_p)\n                    # print(gt_n[109][129])\n                    # print(gt_n[166][245])\n                    # print(gt_s[109][129])\n                    # print(gt_s[166][245])\n                    # print(plane_normals[109][129])\n                    # print(plane_normals[166][245])                    \n                    # for planeIndex in xrange(20):\n                    #     cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(gt_s[:, :, planeIndex]))\n                    #     continue\n                    # exit(1)\n                    \n                    gt_s, gt_p = sortSegmentations(gt_s, gt_p, pred_p)\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_plane_mask_gt.png\', drawMaskImage(planeMask))  \n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_gt.png\', drawSegmentationImage(np.concatenate([gt_s, 1 - planeMask], axis=2), blackIndex=options.numOutputPlanes)\n)\n                    #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_test.png\', drawMaskImage(np.sum(np.concatenate([gt_s, 1 - planeMask], axis=2), axis=2)))\n                    #exit(1)\n                    #exit(1)\n                    pass\n\n\n                if options.predictConfidence == 1 and options.dataset == \'SUNCG\':\n                    assert(False)\n                    pred_p_c = global_pred[\'confidence\'][0]\n                    pred_p_c = 1 / (1 + np.exp(-pred_p_c))\n                    #print(pred_p_c)\n                    # print(losses)\n                    # print(debug[\'plane\'][0])\n                    # print(pred_p)\n                    # exit(1)\n                    numPlanes = global_gt[\'num_planes\'][0]\n                    print((numPlanes, (pred_p_c > 0.5).sum()))\n                    \n                    pred_p_c = (pred_p_c > 0.5).astype(np.float32)\n                    pred_p *= pred_p_c\n                    pred_s -= (1 - pred_p_c.reshape([1, 1, options.numOutputPlanes])) * 10\n                    pass\n                  \n                if False:\n                    #dump results for post processing\n                    if index >= 10:\n                        break\n                    np.save(options.dump_dir + \'/planes_\' + str(index) + \'.npy\', pred_p)\n                    np.save(options.dump_dir + \'/segmentations_\' + str(index) + \'.npy\', pred_s)\n                    np.save(options.dump_dir + \'/segmentations_gt_\' + str(index) + \'.npy\', gt_s)\n                    np.save(options.dump_dir + \'/non_plane_depth_\' + str(index) + \'.npy\', pred_np_d)\n                    np.save(options.dump_dir + \'/non_plane_segmentation_\' + str(index) + \'.npy\', pred_np_m)\n                    boundary = pred_boundary[0]\n                    boundary = 1 / (1 + np.exp(-boundary))\n                    boundary = np.concatenate([boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)                    \n                    cv2.imwrite(options.dump_dir + \'/boundary_\' + str(index) + \'.png\', drawMaskImage(boundary))\n                    cv2.imwrite(options.dump_dir + \'/image_\' + str(index) + \'.png\', cv2.resize(image, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR))\n                    np.save(options.dump_dir + \'/depth_\' + str(index) + \'.npy\', gt_d)\n                    continue                \n\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', image)\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth.png\', drawDepthImage(gt_d))\n                #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_overlay.png\', drawDepthImageOverlay(image, gt_d))\n                \n                if options.predictBoundary:\n                    pred_boundary = global_pred[\'boundary\'][0]\n                    pred_boundary = 1 / (1 + np.exp(-pred_boundary))\n                    boundary = np.concatenate([pred_boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_boundary_pred.png\', drawMaskImage(boundary))\n                    pass\n\n                if \'boundary\' in global_gt:\n                    gt_boundary = global_gt[\'boundary\'][0]\n                    boundary = np.concatenate([gt_boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)                \n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_boundary_gt.png\', drawMaskImage(boundary))\n                    pass\n\n                for layerIndex, layer in enumerate(options.deepSupervisionLayers):\n                    segmentation_deep = np.argmax(deep_preds[layerIndex][\'segmentation\'][0], 2)\n                    segmentation_deep[segmentation_deep == options.numOutputPlanes] = -1\n                    segmentation_deep += 1\n                \n                    plane_depths_deep = calcPlaneDepths(deep_preds[layerIndex][\'plane\'][0], WIDTH, HEIGHT, info)\n                    all_depths_deep = np.concatenate([pred_np_d, plane_depths_deep], axis=2)\n                    pred_d_deep = all_depths_deep.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation_deep.reshape(-1)].reshape(HEIGHT, WIDTH)\n                \n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred_\' + str(layerIndex) + \'.png\', drawSegmentationImage(deep_preds[layerIndex][\'segmentation\'][0]))\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred_\' + str(layerIndex) + \'.png\', drawDepthImage(pred_d_deep))\n                    pass\n\n\n                #print(pred_np_m)\n                #print(pred_s)\n                #print(global_gt[\'plane\'][0])\n                #print(pred_p)\n                #exit(1)\n\n                print(\'depth diff\', np.abs(pred_d - gt_d).mean())\n                \n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(all_segmentations, blackIndex=options.numOutputPlanes))\n                #exit(1)\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_diff.png\', drawMaskImage(np.abs(pred_d - gt_d) * planeMask.squeeze() / 0.2))\n                #exit(1)\n                \n                \n                #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_plane_mask.png\', drawMaskImage(planeMask))           \n\n                #print(np.concatenate([np.arange(options.numOutputPlanes).reshape(-1, 1), planes, pred_p, preds_p[0][0]], axis=1))\n\n                #print(np.concatenate([distance[0], preds_p[0][0], pred_p], axis=1))\n                            \n                #segmentation = np.argmax(pred_s, 2)\n                #writePLYFile(options.test_dir, index, image, pred_d, segmentation, np.zeros(pred_boundary[0].shape))\n                #writePLYFileParts(options.test_dir, index, image, pred_d, segmentation)\n                #gt_s_ori = gt_s_ori[0]\n\n\n                # if \'depth\' in debug:\n                #     cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred_1.png\', drawDepthImage(debug[\'depth\'][0]))\n                #     gt_s_ori = debug[\'segmentation\'][0]\n                #     cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_gt.png\', drawSegmentationImage(gt_s_ori, blackIndex=options.numOutputPlanes))\n                #     total_loss = 0\n                #     for planeIndex in xrange(gt_s_ori.shape[-1]):\n                #         mask_pred = all_segmentations_softmax[:, :, planeIndex]\n                #         loss = -(gt_s_ori[:, :, planeIndex] * np.log(np.maximum(all_segmentations_softmax[:, :, planeIndex], 1e-31))).mean() * 1000\n                #         print(planeIndex, loss)\n                #         total_loss += loss\n                #         cv2.imwrite(options.test_dir + \'/mask_pred_\' + str(planeIndex) + \'.png\', drawMaskImage(mask_pred))\n                #         cv2.imwrite(options.test_dir + \'/mask_gt_\' + str(planeIndex) + \'.png\', drawMaskImage(gt_s_ori[:, :, planeIndex]))\n                #         continue\n                #     print(total_loss)\n                #     print(gt_s_ori.sum(2).max())                    \n                #     exit(1)\n                #     pass\n\n                \n                if False:\n                    #distance = distance[0]\n                    print(distance)\n                    diff = np.linalg.norm(np.expand_dims(planes, 1) - np.expand_dims(pred_p, 0), axis=2)\n                    print(np.concatenate([planes, pred_p, pow(np.min(diff, axis=1, keepdims=True), 2), np.expand_dims(np.argmin(diff, axis=1), -1)], axis=1))\n                    print(pred_p_c)\n                    \n                    #print(distance[:, 6:8].sum(0))\n                    #print(pow(np.linalg.norm(distance[:, :3] - distance[:, 3:6], 2, 1), 2) * 100)\n                    #print(test)\n                    segmentation = np.argmax(all_segmentations, 2) - 1\n                    for planeIndex in xrange(options.numOutputPlanes):\n                        cv2.imwrite(options.test_dir + \'/segmentation_\' + str(planeIndex) + \'.png\', drawMaskImage(segmentation == planeIndex))\n                        cv2.imwrite(options.test_dir + \'/segmentation_\' + str(planeIndex) + \'_gt.png\', drawMaskImage(gt_s[:, :, planeIndex]))\n                        cv2.imwrite(options.test_dir + \'/segmentation_\' + str(planeIndex) + \'_gt_ori.png\', drawMaskImage(gt_s_ori[:, :, planeIndex]))\n                        continue\n                    exit(1)\n                continue\n\n            # if options.dataset == \'SUNCG\':\n            #     if \'pixelwise\' not in options.suffix:\n            #         evaluatePlaneSegmentation(np.array(predPlanes), np.array(predSegmentations), np.array(gtPlanes), np.array(gtSegmentations), np.array(gtNumPlanes), planeDistanceThreshold = 0.3, IOUThreshold = 0.5, prefix=\'test/planenet_\')\n            #     elif \'_2\' in options.suffix:\n            #         evaluatePlaneSegmentation(np.array(predPlanes), np.array(predSegmentations), np.array(gtPlanes), np.array(gtSegmentations), np.array(gtNumPlanes), planeDistanceThreshold = 0.3, IOUThreshold = 0.5, prefix=\'test/pixelwise_pred_\')\n            #     elif \'_3\' in options.suffix:\n            #         evaluatePlaneSegmentation(np.array(predPlanes), np.array(predSegmentations), np.array(gtPlanes), np.array(gtSegmentations), np.array(gtNumPlanes), planeDistanceThreshold = 0.3, IOUThreshold = 0.5, prefix=\'test/pixelwise_gt_\')\n            #         pass\n            #     pass\n            \n            predDepths = np.array(predDepths)\n            gtDepths = np.array(gtDepths)\n            planeMasks = np.array(planeMasks)\n            #predMasks = np.array(predMasks)\n            evaluateDepths(predDepths, gtDepths, gtDepths > 0, planeMasks)\n            exit(1)\n\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n        \n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return\n\n\n# def predict(options):\n#     options.test_dir += \'_predict\'\n#     if not os.path.exists(options.test_dir):\n#         os.system(""mkdir -p %s""%options.test_dir)\n#         pass\n\n#     batchSize = 1\n#     img_inp = tf.placeholder(tf.float32,shape=(batchSize,HEIGHT,WIDTH,3),name=\'img_inp\')\n#     plane_gt=tf.placeholder(tf.float32,shape=(batchSize,options.numOutputPlanes, 3),name=\'plane_inp\')\n#     validating_inp = tf.constant(0, tf.int32)\n\n#     global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp_train, img_inp_val, img_inp_rgbd_train, img_inp_rgbd_val, training_flag, options)\n\n#     var_to_restore = tf.global_variables()\n    \n \n#     config=tf.ConfigProto()\n#     config.gpu_options.allow_growth=True\n#     config.allow_soft_placement=True\n\n\n#     if dataset == \'SUNCG\':\n#         image_list_file = os.path.join(\'../PythonScripts/SUNCG/image_list_100_tail_500000.txt\')\n#         with open(image_list_file) as f:\n#             im_names = [{\'image\': im_name.strip().replace(\'plane_global.npy\', \'mlt.png\'), \'depth\': im_name.strip().replace(\'plane_global.npy\', \'depth.png\'), \'normal\': im_name.strip().replace(\'plane_global.npy\', \'norm_camera.png\'), \'valid\': im_name.strip().replace(\'plane_global.npy\', \'valid.png\'), \'plane\': im_name.strip()} for im_name in f.readlines()]\n#             pass\n#     else:\n#         im_names = glob.glob(\'../../Data/NYU_RGBD/*_color.png\')\n#         im_names = [{\'image\': im_name, \'depth\': im_name.replace(\'color.png\', \'depth.png\'), \'normal\': im_name.replace(\'color.png\', \'norm_camera.png\'), \'invalid_mask\': im_name.replace(\'color.png\', \'valid.png\')} for im_name in im_names]\n#         pass\n      \n#     if numImages > 0:\n#         im_names = im_names[:numImages]\n#         pass\n\n#     #if args.imageIndex > 0:\n#     #im_names = im_names[args.imageIndex:args.imageIndex + 1]\n#     #pass    \n\n#     init_op = tf.group(tf.global_variables_initializer(),\n#                        tf.local_variables_initializer())\n\n\n#     with tf.Session(config=config) as sess:\n#         saver = tf.train.Saver()\n#         #sess.run(tf.global_variables_initializer())\n#         saver.restore(sess,""%s/%s.ckpt""%(options.checkpoint_dir,keyname))\n\n#         gtDepths = []\n#         predDepths = []\n#         segmentationDepths = []\n#         predDepthsOneHot = []\n#         planeMasks = []\n#         predMasks = []\n\n#         imageWidth = WIDTH\n#         imageHeight = HEIGHT\n#         focalLength = 517.97\n#         urange = np.arange(imageWidth).reshape(1, -1).repeat(imageHeight, 0) - imageWidth * 0.5\n#         vrange = np.arange(imageHeight).reshape(-1, 1).repeat(imageWidth, 1) - imageHeight * 0.5\n#         ranges = np.array([urange / focalLength, np.ones(urange.shape), -vrange / focalLength]).transpose([1, 2, 0])\n        \n#         cv2.imwrite(options.test_dir + \'/one.png\', np.ones((HEIGHT, WIDTH), dtype=np.uint8) * 255)\n#         cv2.imwrite(options.test_dir + \'/zero.png\', np.zeros((HEIGHT, WIDTH), dtype=np.uint8) * 255)\n#         for index, im_name in enumerate(im_names):\n#             if index <= -1:\n#                 continue\n#             print(im_name[\'image\'])\n#             im = cv2.imread(im_name[\'image\'])\n#             image = im.astype(np.float32, copy=False)\n#             image = image / 255 - 0.5\n#             image = cv2.resize(image, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n\n#             #planes = np.load(im_name[\'plane\'])\n#             # numPlanes = planes.shape[0]\n#             # if numPlanes > options.numOutputPlanes:\n#             #     planeAreas = planes[:, 3:].sum(1)\n#             #     sortInds = np.argsort(planeAreas)[::-1]\n#             #     planes = planes[sortInds[:options.numOutputPlanes]]\n#             #     pass\n#             # gt_p = np.zeros((1, options.numOutputPlanes, 3))\n#             # gt_p[0, :numPlanes] = planes[:numPlanes, :3]\n\n#             normal = np.array(PIL.Image.open(im_name[\'normal\'])).astype(np.float) / 255 * 2 - 1\n#             norm = np.linalg.norm(normal, 2, 2)\n#             for c in xrange(3):\n#                 normal[:, :, c] /= norm\n#                 continue\n#             normal = cv2.resize(normal, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n            \n#             depth = np.array(PIL.Image.open(im_name[\'depth\'])).astype(np.float) / 1000\n#             depth = cv2.resize(depth, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n\n#             invalid_mask = cv2.resize(cv2.imread(im_name[\'invalid_mask\'], 0), (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR) > 128\n\n#             gtDepths.append(depth)\n\n            \n#             pred_p, pred_d, pred_n, pred_s, pred_np_m, pred_np_d, pred_np_n, pred_boundary, pred_local_score, pred_local_p, pred_local_mask = sess.run([plane_pred, depth_pred, normal_pred, segmentation_pred, non_plane_mask_pred, non_plane_depth_pred, non_plane_normal_pred, boundary_pred, local_score_pred, local_p_pred, local_mask_pred], feed_dict = {img_inp:np.expand_dims(image, 0), plane_gt: np.zeros((batchSize, options.numOutputPlanes, 3))})\n\n\n#             pred_s = pred_s[0] \n#             pred_p = pred_p[0]\n#             pred_np_m = pred_np_m[0]\n#             pred_np_d = pred_np_d[0]\n#             pred_np_n = pred_np_n[0]\n#             #pred_s = 1 / (1 + np.exp(-pred_s))\n\n#             plane_depths = calcPlaneDepths(pred_p, WIDTH, HEIGHT)\n#             all_depths = np.concatenate([pred_np_d, plane_depths], axis=2)\n\n#             all_segmentations = np.concatenate([pred_np_m, pred_s], axis=2)\n#             segmentation = np.argmax(all_segmentations, 2)\n#             if suffix != \'pixelwise\':\n#                 pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape(HEIGHT, WIDTH)\n#             else:\n#                 pred_d = np.squeeze(pred_np_d)\n#                 pass\n#             predDepths.append(pred_d)\n#             predMasks.append(segmentation != 0)\n#             planeMasks.append(invalid_mask)\n\n#             #depthError, normalError, occupancy, segmentationTest, reconstructedDepth, occupancyMask = evaluatePlanes(pred_p, im_name[\'image\'])\n#             #reconstructedDepth = cv2.resize(reconstructedDepth, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n            \n#             #evaluatePlanes(pred_p[0], im_name, options.test_dir, index)\n#             #print(pred_p)\n#             #print(gt_p)\n#             #print((pow(pred_d[0, :, :, 0] - depth, 2) * (gt_s.max(2) > 0.5)).mean())\n#             #print((depthError, normalError, occupancy))\n            \n#             evaluateDepths(predDepths[index], gtDepths[index], np.ones(planeMasks[index].shape), planeMasks[index])\n\n#             if index >= 10:\n#                 continue\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', cv2.resize(im, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR))\n#             #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_gt.png\', (minDepth / np.clip(depth, minDepth, 20) * 255).astype(np.uint8))\n#             #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', (minDepth / np.clip(pred_d[0, :, :, 0], minDepth, 20) * 255).astype(np.uint8))\n#             #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_plane.png\', (minDepth / np.clip(reconstructedDepth, minDepth, 20) * 255).astype(np.uint8))\n\n#             pred_boundary = pred_boundary[0]\n#             boundary = (1 / (1 + np.exp(-pred_boundary)) * 255).astype(np.uint8)\n#             boundary = np.concatenate([boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_boundary_pred.png\', boundary)\n            \n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_inp.png\', drawDepthImage(depth))\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n#             #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_plane.png\', drawDepthImage(reconstructedDepth))\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred_diff.png\', drawDiffImage(pred_d, depth, 0.5))\n#             #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_plane_diff.png\', np.minimum(np.abs(reconstructedDepth - depth) / 0.5 * 255, 255).astype(np.uint8))\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_inp.png\', drawNormalImage(normal))\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_pred.png\', drawNormalImage(pred_np_n))\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(all_segmentations, black=True))\n\n#             segmentation = np.argmax(pred_s, 2)\n#             #writePLYFile(options.test_dir, index, image, pred_p, segmentation)\n\n#             if index < 0:\n#                 for planeIndex in xrange(options.numOutputPlanes):\n#                     cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_\' + str(planeIndex) + \'.png\', drawMaskImage(pred_s[:, :, planeIndex]))\n#                     #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_\' + str(planeIndex) + \'_gt.png\', drawMaskImage(gt_s[:, :, planeIndex]))\n#                     continue\n#                 pass\n#             continue\n#         predDepths = np.array(predDepths)\n#         gtDepths = np.array(gtDepths)\n#         planeMasks = np.array(planeMasks)\n#         predMasks = np.array(predMasks)\n#         #evaluateDepths(predDepths, gtDepths, planeMasks, predMasks)\n#         evaluateDepths(predDepths, gtDepths, planeMasks, planeMasks)\n#         #exit(1)\n#         pass\n#     return\n\n\n# def fitPlanesRGBD(options):\n#     writeHTMLRGBD(\'../results/RANSAC_RGBD/index.html\', 10)\n#     exit(1)\n#     if not os.path.exists(options.checkpoint_dir):\n#         os.system(""mkdir -p %s""%options.checkpoint_dir)\n#         pass\n#     if not os.path.exists(options.test_dir):\n#         os.system(""mkdir -p %s""%options.test_dir)\n#         pass\n    \n#     min_after_dequeue = 1000\n\n#     reader_rgbd = RecordReaderRGBD()\n#     filename_queue_rgbd = tf.train.string_input_producer([\'../planes_nyu_rgbd_train.tfrecords\'], num_epochs=1)\n#     img_inp_rgbd, global_gt_dict_rgbd, local_gt_dict_rgbd = reader_rgbd.getBatch(filename_queue_rgbd, numOutputPlanes=options.numOutputPlanes, batchSize=1, min_after_dequeue=min_after_dequeue, getLocal=True)\n\n#     config=tf.ConfigProto()\n#     config.gpu_options.allow_growth=True\n#     config.allow_soft_placement=True\n\n#     init_op = tf.group(tf.global_variables_initializer(),\n#                        tf.local_variables_initializer())\n\n#     with tf.Session(config=config) as sess:\n#         sess.run(init_op)\n\n#         coord = tf.train.Coordinator()\n#         threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n#         try:\n#             gtDepths = []\n#             predDepths = []\n#             planeMasks = []\n#             for index in xrange(10):\n#                 image, depth, path = sess.run([img_inp_rgbd, global_gt_dict_rgbd[\'depth\'], global_gt_dict_rgbd[\'path\']])\n#                 image = ((image[0] + 0.5) * 255).astype(np.uint8)\n#                 depth = depth.squeeze()\n                \n#                 cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', image)\n#                 cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth.png\', drawDepthImage(depth))\n#                 #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_mask.png\', drawMaskImage(depth == 0))\n#                 planes, planeSegmentation, depthPred = fitPlanes(depth, numPlanes=20)                \n#                 cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(planeSegmentation))\n#                 cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(depthPred))\n\n#                 gtDepths.append(depth)\n#                 predDepths.append(depthPred)\n#                 planeMasks.append((planeSegmentation < 20).astype(np.float32))\n#                 continue\n#             predDepths = np.array(predDepths)\n#             gtDepths = np.array(gtDepths)\n#             planeMasks = np.array(planeMasks)\n#             evaluateDepths(predDepths, gtDepths, np.ones(planeMasks.shape, dtype=np.bool), planeMasks)            \n#         except tf.errors.OutOfRangeError:\n#             print(\'done fitting\')\n#         finally:\n#             # When done, ask the threads to stop.\n#             coord.request_stop()\n#             pass\n#     return\n\ndef writeInfo(options):\n    x = (np.arange(11) * 0.1).tolist()\n    ys = []\n    ys.append(np.load(\'test/planenet_pixel_IOU.npy\').tolist())\n    ys.append(np.load(\'test/pixelwise_pred_pixel_IOU.npy\').tolist())\n    ys.append(np.load(\'test/pixelwise_gt_pixel_IOU.npy\').tolist())\n    plotCurves(x, ys, filename = \'test/plane_comparison.png\', xlabel=\'IOU\', ylabel=\'pixel coverage\', labels=[\'planenet\', \'pixelwise+RANSAC\', \'GT+RANSAC\'])\n\n    x = (0.5 - np.arange(11) * 0.05).tolist()\n    ys = []\n    ys.append(np.load(\'test/planenet_pixel_diff.npy\').tolist())\n    ys.append(np.load(\'test/pixelwise_pred_pixel_diff.npy\').tolist())\n    ys.append(np.load(\'test/pixelwise_gt_pixel_diff.npy\').tolist())\n    plotCurves(x, ys, filename = \'test/plane_comparison_diff.png\', xlabel=\'diff\', ylabel=\'pixel coverage\', labels=[\'planenet\', \'pixelwise+RANSAC\', \'GT+RANSAC\'])\n    \n    return\n\ndef parse_args():\n    """"""\n    Parse input arguments\n    """"""\n    parser = argparse.ArgumentParser(description=\'Planenet\')\n    parser.add_argument(\'--gpu\', dest=\'gpu_id\',\n                        help=\'GPU device id to use [0]\',\n                        default=0, type=int)\n    #task: [train, test, predict]\n    parser.add_argument(\'--task\', dest=\'task\',\n                        help=\'task type: [train, test, predict]\',\n                        default=\'train\', type=str)\n    parser.add_argument(\'--restore\', dest=\'restore\',\n                        help=\'how to restore the model\',\n                        default=0, type=int)\n    parser.add_argument(\'--numOutputPlanes\', dest=\'numOutputPlanes\',\n                        help=\'the number of output planes\',\n                        default=20, type=int)\n    parser.add_argument(\'--batchSize\', dest=\'batchSize\',\n                        help=\'batch size\',\n                        default=16, type=int)\n    parser.add_argument(\'--dataset\', dest=\'dataset\',\n                        help=\'dataset name for test/predict\',\n                        default=\'\', type=str)\n    parser.add_argument(\'--numImages\', dest=\'numImages\',\n                        help=\'the number of images to test/predict\',\n                        default=10, type=int)\n    parser.add_argument(\'--boundaryLoss\', dest=\'boundaryLoss\',\n                        help=\'use boundary loss: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--diverseLoss\', dest=\'diverseLoss\',\n                        help=\'use diverse loss: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--labelLoss\', dest=\'labelLoss\',\n                        help=\'use label loss: [0, 1]\',\n                        default=0, type=int)    \n    parser.add_argument(\'--deepSupervision\', dest=\'deepSupervision\',\n                        help=\'deep supervision level: [0, 1, 2]\',\n                        default=0, type=int)\n    parser.add_argument(\'--sameMatching\', dest=\'sameMatching\',\n                        help=\'use the same matching for all deep supervision layers and the final prediction: [0, 1]\',\n                        default=0, type=int)    \n    parser.add_argument(\'--anchorPlanes\', dest=\'anchorPlanes\',\n                        help=\'use anchor planes for all deep supervision layers and the final prediction: [0, 1]\',\n                        default=0, type=int) \n    parser.add_argument(\'--crf\', dest=\'crf\',\n                        help=\'the number of CRF iterations\',\n                        default=0, type=int)\n    parser.add_argument(\'--crfrnn\', dest=\'crfrnn\',\n                        help=\'the number of CRF (as RNN) iterations\',\n                        default=0, type=int)    \n    parser.add_argument(\'--backwardLossWeight\', dest=\'backwardLossWeight\',\n                        help=\'backward matching loss\',\n                        default=0.5, type=float)\n    parser.add_argument(\'--predictBoundary\', dest=\'predictBoundary\',\n                        help=\'whether predict boundary or not: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--predictSemantics\', dest=\'predictSemantics\',\n                        help=\'whether predict semantics or not: [0, 1]\',\n                        default=0, type=int)    \n    parser.add_argument(\'--predictLocal\', dest=\'predictLocal\',\n                        help=\'whether predict local planes or not: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--predictConfidence\', dest=\'predictConfidence\',\n                        help=\'whether predict plane confidence or not: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--predictPlanes\', dest=\'predictPlanes\',\n                        help=\'whether predict planes or not: [0, 1]\',\n                        default=0, type=int)    \n    parser.add_argument(\'--fineTuningCheckpoint\', dest=\'fineTuningCheckpoint\',\n                        help=\'specify the model for fine-tuning\',\n                        default=\'../PlaneSetGeneration/dump_planenet_diverse/train_planenet_diverse.ckpt\', type=str)\n    parser.add_argument(\'--suffix\', dest=\'suffix\',\n                        help=\'add a suffix to keyname to distinguish experiments\',\n                        default=\'\', type=str)\n    parser.add_argument(\'--l2Weight\', dest=\'l2Weight\',\n                        help=\'L2 regulation weight\',\n                        default=5e-4, type=float)\n    parser.add_argument(\'--LR\', dest=\'LR\',\n                        help=\'learning rate\',\n                        default=3e-5, type=float)\n    parser.add_argument(\'--hybrid\', dest=\'hybrid\',\n                        help=\'hybrid training\',\n                        default=\'1\', type=str)\n    parser.add_argument(\'--rootFolder\', dest=\'rootFolder\',\n                        help=\'root folder\',\n                        default=\'/mnt/vision/PlaneNet/\', type=str)\n    parser.add_argument(\'--dataFolder\', dest=\'dataFolder\',\n                        help=\'data folder\',\n                        default=\'/home/chenliu/Projects/PlaneNet/\', type=str)\n    parser.add_argument(\'--saveInterval\', dest=\'saveInterval\',\n                        help=\'save interval\',\n                        default=900, type=int)\n    \n\n    args = parser.parse_args()\n    args.keyname = os.path.basename(__file__).rstrip(\'.py\')\n    args.keyname = args.keyname.replace(\'train_\', \'\')\n\n    if args.numOutputPlanes != 20:\n        args.keyname += \'_np\' + str(args.numOutputPlanes)\n        pass\n    args.keyname += \'_hybrid\' + args.hybrid\n    \n    if args.deepSupervision != 1:\n        args.keyname += \'_ds\' + str(args.deepSupervision)\n        pass\n    if args.predictPlanes == 1:\n        args.keyname += \'_pp\'\n        pass\n    if args.predictSemantics == 1:\n        args.keyname += \'_ps\'\n        pass    \n    if args.crf > 0:\n        args.keyname += \'_crf\' + str(args.crf)\n        pass\n\n    #args.predictSemantics = 0\n    #args.predictBoundary = 0\n    \n    args.checkpoint_dir = args.rootFolder + \'/checkpoint/\' + args.keyname\n    args.log_dir = \'log/\' + args.keyname\n    args.test_dir = \'test/\' + args.keyname + \'_\' + args.dataset\n    args.predict_dir = \'predict/\' + args.keyname + \'_\' + args.dataset\n    args.dump_dir = \'dump/\' + args.keyname\n    \n    #layers where deep supervision happens\n    args.deepSupervisionLayers = []\n    if args.deepSupervision >= 1:\n        args.deepSupervisionLayers.append(\'res4b22_relu\')\n        pass\n    if args.deepSupervision >= 2:\n        args.deepSupervisionLayers.append(\'res4b12_relu\')\n        pass\n    return args\n\n\nif __name__==\'__main__\':\n\n    # plane = np.load(\'temp/plane.npy\')\n    # depth = np.load(\'temp/depth.npy\')    \n    # segmentation = np.load(\'temp/segmentation.npy\')\n    # info = np.load(\'temp/info.npy\')\n    # num_planes = np.load(\'temp/num_planes.npy\')\n    # segmentation = np.argmax(segmentation, axis=-1)\n    # print(segmentation.shape)\n    # planes, segmentation, numPlanes = removeSmallSegments(plane, np.zeros((HEIGHT, WIDTH, 3)), depth.squeeze(), np.zeros((HEIGHT, WIDTH, 3)), segmentation, np.zeros((HEIGHT, WIDTH)), info, num_planes)\n    # print(planes)\n    # exit(1)\n    \n    args = parse_args()\n\n    print ""keyname=%s task=%s started""%(args.keyname, args.task)\n    try:\n        if args.task == ""train"":\n            main(args)\n        elif args.task == ""test"":\n            test(args)\n        elif args.task == ""predict"":\n            predict(args)\n        elif args.task == ""fit"":\n            fitPlanesRGBD(args)\n        elif args.task == ""write"":\n            writeInfo(args)\n        else:\n            assert False,""format wrong""\n            pass\n    finally:\n        pass\n\n'"
code/train_planenet.py,185,"b'import tensorflow as tf\nimport numpy as np\nnp.set_printoptions(precision=2, linewidth=200)\nimport cv2\nimport os\nimport time\nimport sys\nimport argparse\nimport glob\nimport PIL\nimport scipy.ndimage as ndimage\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom utils import *\nfrom plane_utils import *\nfrom modules import *\n\n\nfrom planenet import PlaneNet\nfrom RecordReader import *\nfrom RecordReaderRGBD import *\nfrom RecordReader3D import *\nfrom RecordReaderAll import *\nfrom crfasrnn_layer import CrfRnnLayer\n\n#from SegmentationRefinement import *\n\n#training_flag: toggle dropout and batch normalization mode\n#it\'s true for training and false for validation, testing, prediction\n#it also controls which data batch to use (*_train or *_val)\n\n\ndef build_graph(img_inp_train, img_inp_val, training_flag, options):\n    with tf.device(\'/gpu:%d\'%options.gpu_id):\n        img_inp = tf.cond(training_flag, lambda: img_inp_train, lambda: img_inp_val)\n\n        net = PlaneNet({\'img_inp\': img_inp}, is_training=training_flag, options=options)\n\n        #global predictions\n        plane_pred = net.layers[\'plane_pred\']\n\n        segmentation_pred = net.layers[\'segmentation_pred\']\n        non_plane_mask_pred = net.layers[\'non_plane_mask_pred\']\n        non_plane_depth_pred = net.layers[\'non_plane_depth_pred\']\n        non_plane_normal_pred = net.layers[\'non_plane_normal_pred\']\n        non_plane_normal_pred = tf.nn.l2_normalize(non_plane_normal_pred, dim=-1)\n\n\n        if False:\n            plane_pred = gt_dict[\'plane\']\n            non_plane_mask_pred = gt_dict[\'non_plane_mask\'] * 10\n            non_plane_depth_pred = gt_dict[\'depth\']\n            non_plane_normal_pred = gt_dict[\'normal\']\n            segmentation_pred = gt_dict[\'segmentation\'][:, :, :, :20] * 10\n            pass\n\n\n        if abs(options.crfrnn) > 0:\n            with tf.variable_scope(\'crfrnn\'):\n                all_segmentations = crfrnnModule([tf.concat([segmentation_pred, non_plane_mask_pred], axis=3), img_inp * 255], image_dims=(HEIGHT, WIDTH), num_classes=options.numOutputPlanes + 1, theta_alpha=30, theta_beta=10, theta_gamma=1, num_iterations=abs(options.crfrnn))\n                #all_segmentations = CrfRnnLayer(image_dims=(HEIGHT, WIDTH), num_classes=options.numOutputPlanes + 1, theta_alpha=15., theta_beta=10., theta_gamma=3., num_iterations=abs(options.crfrnn), name=\'crfrnn\')([tf.concat([segmentation_pred, non_plane_mask_pred], axis=3), img_inp * 255])\n                segmentation_pred = all_segmentations[:, :, :, :options.numOutputPlanes]\n                non_plane_mask_pred = all_segmentations[:, :, :, options.numOutputPlanes:]\n                pass\n            pass\n\n        global_pred_dict = {\'plane\': plane_pred, \'segmentation\': segmentation_pred, \'non_plane_mask\': non_plane_mask_pred, \'non_plane_depth\': non_plane_depth_pred, \'non_plane_normal\': non_plane_normal_pred}\n\n        if options.predictBoundary:\n            global_pred_dict[\'boundary\'] = net.layers[\'boundary_pred\']\n        else:\n            global_pred_dict[\'boundary\'] = tf.zeros((options.batchSize, HEIGHT, WIDTH, 2))\n            pass\n        if options.predictConfidence:\n            global_pred_dict[\'confidence\'] = net.layers[\'plane_confidence_pred\']\n            pass\n        if options.predictSemantics:\n            global_pred_dict[\'semantics\'] = net.layers[\'semantics_pred\']\n            pass\n\n        #local predictions\n        if options.predictLocal:\n            local_pred_dict = {\'score\': net.layers[\'local_score_pred\'], \'plane\': net.layers[\'local_plane_pred\'], \'mask\': net.layers[\'local_mask_pred\']}\n        else:\n            local_pred_dict = {}\n            pass\n\n\n        #deep supervision\n        deep_pred_dicts = []\n        for layer in options.deepSupervisionLayers:\n            pred_dict = {\'plane\': net.layers[layer+\'_plane_pred\'], \'segmentation\': net.layers[layer+\'_segmentation_pred\'], \'non_plane_mask\': net.layers[layer+\'_non_plane_mask_pred\']}\n            #if options.predictConfidence:\n            #pred_dict[\'confidence\'] = net.layers[layer+\'_plane_confidence_pred\']\n            #pass\n            deep_pred_dicts.append(pred_dict)\n            continue\n\n\n        if options.anchorPlanes:\n            anchors_np = np.load(\'dump/anchors_\' + options.hybrid + \'.npy\')\n            anchors = tf.reshape(tf.constant(anchors_np.reshape(-1)), anchors_np.shape)\n            anchors = tf.tile(tf.expand_dims(anchors, 0), [options.batchSize, 1, 1])\n            all_pred_dicts = deep_pred_dicts + [global_pred_dict]\n            for pred_index, pred_dict in enumerate(all_pred_dicts):\n                all_pred_dicts[pred_index][\'plane\'] += anchors\n                continue\n            pass\n\n        pass\n\n    return global_pred_dict, local_pred_dict, deep_pred_dicts\n\n\ndef build_loss(img_inp_train, img_inp_val, global_pred_dict, deep_pred_dicts, global_gt_dict_train, global_gt_dict_val, training_flag, options):\n    import tf_nndistance\n    with tf.device(\'/gpu:%d\'%options.gpu_id):\n        debug_dict = {}\n\n        img_inp = tf.cond(training_flag, lambda: img_inp_train, lambda: img_inp_val)\n        global_gt_dict = {}\n        for name in global_gt_dict_train.keys():\n            global_gt_dict[name] = tf.cond(training_flag, lambda: global_gt_dict_train[name], lambda: global_gt_dict_val[name])\n            continue\n        # local_gt_dict = {}\n        # for name in local_gt_dict_train.keys():\n        #     local_gt_dict[name] = tf.cond(tf.equal(training_flag % 2, 0), lambda: local_gt_dict_train[name], lambda: local_gt_dict_val[name])\n        #     continue\n\n        plane_parameters = tf.reshape(global_pred_dict[\'plane\'], (-1, 3))\n        info = global_gt_dict[\'info\'][0]\n        plane_depths = planeDepthsModule(plane_parameters, WIDTH, HEIGHT, info)\n        plane_depths = tf.transpose(tf.reshape(plane_depths, [HEIGHT, WIDTH, -1, options.numOutputPlanes]), [2, 0, 1, 3])\n\n        non_plane_depth = global_pred_dict[\'non_plane_depth\']\n        all_depths = tf.concat([plane_depths, non_plane_depth], axis=3)\n\n\n        validPlaneMask = tf.cast(tf.less(tf.tile(tf.expand_dims(tf.range(options.numOutputPlanes), 0), [options.batchSize, 1]), tf.expand_dims(global_gt_dict[\'num_planes\'], -1)), tf.float32)\n        backwardLossWeight = options.backwardLossWeight\n\n        #plane loss and segmentation loss (summation over deep supervisions and final supervision)\n        all_pred_dicts = deep_pred_dicts + [global_pred_dict]\n        plane_loss = tf.constant(0.0)\n        segmentation_loss = tf.constant(0.0)\n        plane_confidence_loss = tf.constant(0.0)\n        diverse_loss = tf.constant(0.0)\n\n        #keep forward map (segmentation gt) from previous supervision so that we can have same matching for all supervisions (options.sameMatching = 1)\n        previous_plane_gt = None\n        previous_plane_confidence_gt = None\n        previous_segmentation_gt = None\n        if options.anchorPlanes:\n            anchors_np = np.load(\'dump/anchors_\' + options.hybrid + \'.npy\')\n            anchors = tf.reshape(tf.constant(anchors_np.reshape(-1)), anchors_np.shape)\n            anchors = tf.tile(tf.expand_dims(anchors, 0), [options.batchSize, 1, 1])\n            dists_forward, map_forward, dists_backward, _ = tf_nndistance.nn_distance(global_gt_dict[\'plane\'], anchors)\n\n            forward_map = tf.one_hot(map_forward, depth=options.numOutputPlanes, axis=-1)\n            forward_map *= tf.expand_dims(validPlaneMask, -1)\n\n            #number of ground truth mapped for each prediction\n            num_matches = tf.transpose(tf.reduce_sum(forward_map, axis=1, keep_dims=True), [0, 2, 1])\n            previous_plane_gt = tf.transpose(tf.matmul(global_gt_dict[\'plane\'], forward_map, transpose_a=True), [0, 2, 1]) / tf.maximum(num_matches, 1e-4)\n            previous_plane_confidence_gt = tf.cast(num_matches > 0.5, tf.float32)\n\n            segmentation_gt_shuffled = tf.reshape(tf.matmul(tf.reshape(global_gt_dict[\'segmentation\'], [-1, HEIGHT * WIDTH, options.numOutputPlanes]), forward_map), [-1, HEIGHT, WIDTH, options.numOutputPlanes])\n            segmentation_gt_shuffled = tf.concat([segmentation_gt_shuffled, global_gt_dict[\'non_plane_mask\']], axis=3)\n            previous_segmentation_gt = segmentation_gt_shuffled\n            pass\n\n        for pred_index, pred_dict in enumerate(all_pred_dicts):\n            if (options.sameMatching and pred_index > 0) or options.anchorPlanes:\n                #use matching from previous supervision and map ground truth planes based on the mapping\n\n                plane_loss += tf.reduce_mean(tf.squared_difference(pred_dict[\'plane\'], previous_plane_gt) * previous_plane_confidence_gt) * 10000\n\n                #all segmentations is the concatenation of plane segmentations and non plane mask\n                all_segmentations = tf.concat([pred_dict[\'segmentation\'], pred_dict[\'non_plane_mask\']], axis=3)\n\n                if options.crf > 0:\n                    all_segmentations_softmax = tf.nn.softmax(all_segmentations)\n                    with tf.variable_scope(\'crf\'):\n                        planesY = global_pred_dict[\'plane\'][:, :, 1]\n                        planesD = tf.maximum(tf.norm(global_pred_dict[\'plane\'], axis=-1), 1e-4)\n                        planesY /= planesD\n                        planesY = tf.concat([planesY, tf.ones((options.batchSize, 1)) * 100], axis=1)\n\n                        imageDiff = calcImageDiff(img_inp)\n                        all_segmentations_softmax, _ = segmentationRefinementModule(all_segmentations_softmax, all_depths, planesY, imageDiff, numIterations=options.crf, numOutputPlanes=21)\n                        segmentation_loss += tf.reduce_mean(-tf.reduce_sum(previous_segmentation_gt* tf.log(tf.maximum(all_segmentations_softmax, 1e-31)), axis=-1)) * 1000\n                        pass\n                    pass\n                else:\n                    segmentation_loss += tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=all_segmentations, labels=previous_segmentation_gt)) * 1000\n                    pass\n            else:\n                #calculate new matching by finding nearest neighbors again\n                dists_forward, map_forward, dists_backward, _ = tf_nndistance.nn_distance(global_gt_dict[\'plane\'], pred_dict[\'plane\'])\n                dists_forward *= validPlaneMask\n\n                dists_forward = tf.reduce_mean(dists_forward)\n                dists_backward = tf.reduce_mean(dists_backward)\n                plane_loss += (dists_forward + dists_backward * backwardLossWeight) * 10000\n\n                forward_map = tf.one_hot(map_forward, depth=options.numOutputPlanes, axis=-1)\n                forward_map *= tf.expand_dims(validPlaneMask, -1)\n\n                #number of ground truth mapped for each prediction\n                num_matches = tf.transpose(tf.reduce_sum(forward_map, axis=1, keep_dims=True), [0, 2, 1])\n                previous_plane_gt = tf.transpose(tf.matmul(global_gt_dict[\'plane\'], forward_map, transpose_a=True), [0, 2, 1]) / tf.maximum(num_matches, 1e-4)\n                previous_plane_confidence_gt = tf.cast(num_matches > 0.5, tf.float32)\n\n\n                segmentation_gt_shuffled = tf.reshape(tf.matmul(tf.reshape(global_gt_dict[\'segmentation\'], [-1, HEIGHT * WIDTH, options.numOutputPlanes]), forward_map), [-1, HEIGHT, WIDTH, options.numOutputPlanes])\n                segmentation_gt_shuffled = tf.concat([segmentation_gt_shuffled, global_gt_dict[\'non_plane_mask\']], axis=3)\n                previous_segmentation_gt = segmentation_gt_shuffled\n\n                all_segmentations = tf.concat([pred_dict[\'segmentation\'], pred_dict[\'non_plane_mask\']], axis=3)\n                segmentation_loss += tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=all_segmentations, labels=segmentation_gt_shuffled)) * 1000\n                debug_dict[\'segmentation\'] = segmentation_gt_shuffled\n                pass\n\n            if options.diverseLoss:\n                plane_diff = tf.reduce_sum(tf.pow(tf.expand_dims(pred_dict[\'plane\'], 1) - tf.expand_dims(pred_dict[\'plane\'], 2), 2), axis=3)\n                plane_diff = tf.matrix_set_diag(plane_diff, tf.ones((options.batchSize, options.numOutputPlanes)))\n                minPlaneDiff = 0.1\n                diverse_loss += tf.reduce_mean(tf.clip_by_value(1 - plane_diff / minPlaneDiff, 0, 1)) * 10000\n                pass\n\n            continue\n\n\n        if options.crf == 0:\n            all_segmentations_softmax = tf.nn.softmax(all_segmentations)\n            pass\n\n        #depth loss\n        validDepthMask = tf.cast(tf.greater(global_gt_dict[\'depth\'], 1e-4), tf.float32)\n        depth_loss = tf.reduce_mean(tf.reduce_sum(tf.squared_difference(all_depths, global_gt_dict[\'depth\']) * all_segmentations_softmax, axis=3, keep_dims=True) * validDepthMask) * 10000\n\n        if options.predictPixelwise == 1:\n            depth_diff = global_pred_dict[\'non_plane_depth\'] - global_gt_dict[\'depth\']\n            depth_diff_gx = depth_diff - tf.concat([tf.ones([options.batchSize, HEIGHT, 1, 1]), depth_diff[:, :, :WIDTH - 1]], axis=2)\n            depth_diff_gy = depth_diff - tf.concat([tf.ones([options.batchSize, 1, WIDTH, 1]), depth_diff[:, :HEIGHT - 1]], axis=1)\n\n            numValidPixels = tf.reduce_sum(validDepthMask, axis=[1, 2, 3])\n            depth_loss += tf.reduce_mean(tf.reduce_sum(tf.pow(depth_diff * validDepthMask, 2), axis=[1, 2, 3]) / numValidPixels - 0.5 * tf.pow(tf.reduce_sum(depth_diff * validDepthMask, axis=[1, 2, 3]) / numValidPixels, 2) + tf.reduce_sum((tf.pow(depth_diff_gx, 2) + tf.pow(depth_diff_gy, 2)) * validDepthMask, axis=[1, 2, 3]) / numValidPixels) * 1000\n\n            #depth_loss += tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_depth\'], global_gt_dict[\'depth\']) * validDepthMask) * 10000\n\n\n            valid_normal_mask = tf.squeeze(tf.cast(tf.less(tf.slice(global_gt_dict[\'info\'], [0, 19], [options.batchSize, 1]), 2), tf.float32))\n            normal_gt = tf.nn.l2_normalize(global_gt_dict[\'normal\'], dim=-1)\n            normal_loss = tf.reduce_mean(tf.reduce_sum(-global_pred_dict[\'non_plane_normal\'] * normal_gt * validDepthMask, axis=[1, 2, 3]) / numValidPixels * valid_normal_mask) * 1000\n            #normal_loss = tf.reduce_mean(tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_normal\'], global_gt_dict[\'normal\']) * validDepthMask, axis=[1, 2, 3]) * valid_normal_mask) * 1000\n        else:\n            normal_loss = tf.constant(0.0)\n            pass\n\n        if options.predictSemantics:\n            valid_semantics_mask = tf.squeeze(tf.cast(tf.not_equal(tf.slice(global_gt_dict[\'info\'], [0, 19], [options.batchSize, 1]), 1), tf.float32))\n            semantics_loss = tf.reduce_mean(tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=global_pred_dict[\'semantics\'], labels=global_gt_dict[\'semantics\']), axis=[1, 2]) * valid_semantics_mask) * 1000\n        else:\n            semantics_loss = tf.constant(0.0)\n            pass\n\n        local_score_loss = tf.constant(0.0)\n        local_plane_loss = tf.constant(0.0)\n        local_mask_loss = tf.constant(0.0)\n\n        #boundary loss\n        boundary_loss = tf.constant(0.0)\n\n        if False:\n            kernel_size = 3\n            padding = (kernel_size - 1) / 2\n            neighbor_kernel_array = gaussian(kernel_size, kernel_size)\n            neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n            neighbor_kernel_array /= neighbor_kernel_array.sum()\n            neighbor_kernel_array *= -1\n            neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 1\n            neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n            neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n\n            #calculate boundary ground truth on-the-fly as the calculation is subject to change\n\n            depth_diff = tf.abs(tf.nn.depthwise_conv2d(global_gt_dict[\'depth\'], neighbor_kernel, strides=[1, 1, 1, 1], padding=\'VALID\'))\n            depth_diff = tf.pad(depth_diff, paddings = [[0, 0], [padding, padding], [padding, padding], [0, 0]])\n            max_depth_diff = 0.1\n            depth_boundary = tf.greater(depth_diff, max_depth_diff)\n\n            plane_region = tf.nn.max_pool(1 - global_gt_dict[\'non_plane_mask\'], ksize=[1, kernel_size, kernel_size, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n            segmentation_eroded = 1 - tf.nn.max_pool(1 - global_gt_dict[\'segmentation\'], ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n            plane_region -= tf.reduce_max(segmentation_eroded, axis=3, keep_dims=True)\n            boundary = tf.cast(depth_boundary, tf.float32) * plane_region\n            smooth_boundary = global_gt_dict[\'smooth_boundary\']\n            boundary_gt = tf.concat([smooth_boundary, tf.maximum(boundary - smooth_boundary, 0)], axis=3)\n            pass\n\n\n        if options.boundaryLoss == 1 and False:\n\n            all_segmentations_pred = all_segmentations_softmax\n            all_segmentations_min = 1 - tf.nn.max_pool(1 - all_segmentations_pred, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\')\n            segmentation_diff = tf.reduce_max(all_segmentations_pred - all_segmentations_min, axis=3, keep_dims=True)\n\n            depth_pred = tf.reduce_sum(tf.multiply(all_depths, all_segmentations_pred), axis=3, keep_dims=True)\n            depth_neighbor = tf.nn.depthwise_conv2d(depth_pred, neighbor_kernel, strides=[1, 1, 1, 1], padding=\'SAME\')\n            minDepthDiff = 0.02\n            depth_diff = tf.clip_by_value(tf.squared_difference(depth_pred, depth_neighbor) - pow(minDepthDiff, 2), 0, 1)\n\n            boundary = tf.reduce_max(global_gt_dict[\'boundary\'], axis=3, keep_dims=True)\n            smooth_boundary = tf.slice(boundary_gt, [0, 0, 0, 0], [options.batchSize, HEIGHT, WIDTH, 1])\n            smooth_mask = segmentation_diff + boundary - 2 * segmentation_diff * boundary + depth_diff * smooth_boundary\n            margin = 0.0\n            smooth_mask = tf.nn.relu(smooth_mask - margin)\n            #boundary_loss += tf.reduce_mean(smooth_mask * plane_mask) * 1000\n            boundary_loss += tf.reduce_mean(smooth_mask) * 1000\n        elif options.boundaryLoss == 3:\n            S = tf.one_hot(tf.argmax(all_segmentations, 3), depth=options.numOutputPlanes + 1)\n            #sigmaDepthDiff = 0.5\n            #DS_diff = tf.exp(-tf.pow(1 - tf.clip_by_value(tf.abs(all_depths - tf.reduce_sum(all_depths * S, 3, keep_dims=True)), 0, 1), 2) / sigmaDepthDiff) - tf.exp(-1 / sigmaDepthDiff) * S\n            planesY = tf.slice(global_pred_dict[\'plane\'], [0, 0, 1], [options.batchSize, options.numOutputPlanes, 1])\n            planesD = tf.maximum(tf.norm(global_pred_dict[\'plane\'], axis=-1, keep_dims=True), 1e-4)\n            planesY /= planesD\n            #normalY = tf.reduce_sum(tf.slice(S, [0, 0, 0, 0], [options.batchSize, HEIGHT, WIDTH, options.numOutputPlanes]) * tf.reshape(planesY, [options.batchSize, 1, 1, options.numOutputPlanes]), axis=3, keep_dims=True)\n            planesY = tf.concat([planesY, tf.ones((options.batchSize, 1, 1)) * 100], axis=1)\n            normalY = tf.reduce_sum(S * tf.reshape(planesY, [options.batchSize, 1, 1, -1]), axis=3, keep_dims=True)\n\n            maxDepthDiff = 0.1\n            labelDiffWeight = 0.05\n            depth_one_hot = tf.reduce_sum(all_depths * S, 3, keep_dims=True)\n            depth_diff = tf.clip_by_value(tf.pow((plane_depths - depth_one_hot) * normalY / maxDepthDiff, 2), 0, 1)\n            #depth_diff *= normalY\n            depth_diff = tf.concat([depth_diff, 1 - tf.slice(S, [0, 0, 0, options.numOutputPlanes], [options.batchSize, HEIGHT, WIDTH, 1])], axis=3)\n            DS_diff = (1 + labelDiffWeight) - tf.exp(-depth_diff) - S * labelDiffWeight\n            kernel_size = 3\n            neighbor_kernel_array = gaussian(kernel_size)\n            neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n            neighbor_kernel_array /= neighbor_kernel_array.sum()\n            neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n            neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n\n            DS = tf.nn.depthwise_conv2d(DS_diff, tf.tile(neighbor_kernel, [1, 1, options.numOutputPlanes + 1, 1]), strides=[1, 1, 1, 1], padding=\'SAME\')\n            boundary_loss += tf.reduce_mean(DS * all_segmentations_softmax) * 100000\n\n            debug_dict[\'cost_mask\'] = tf.reduce_sum(DS * all_segmentations_softmax, axis=3)\n            #debug_dict[\'cost_mask\'] = DS * all_segmentations_softmax\n            #debug_dict[\'cost_mask\'] = tf.reduce_sum(DS * S, axis=3)\n        elif options.boundaryLoss == 2:\n            planesY = global_pred_dict[\'plane\'][:, :, 1]\n            planesD = tf.maximum(tf.norm(global_pred_dict[\'plane\'], axis=-1), 1e-4)\n            planesY /= planesD\n            planesY = tf.concat([planesY, tf.ones((options.batchSize, 1)) * 100], axis=1)\n\n            #imageDiff = calcImageDiff(img_inp)\n            #all_segmentations_softmax, _ = segmentationRefinementModule(all_segmentations_softmax, all_depths, planesY, imageDiff, numIterations=options.crf, numOutputPlanes=21)\n            messages = calcMessages(all_segmentations_softmax, all_depths, planesY, numOutputPlanes=21)\n            boundary_loss += tf.reduce_mean(messages * all_segmentations_softmax) * 100000\n            debug_dict[\'cost_mask\'] = messages\n            pass\n\n\n        if options.predictBoundary and False:\n            #we predict boundaries directly for post-processing purpose\n            boundary_loss += tf.reduce_mean(tf.losses.sigmoid_cross_entropy(logits=global_pred_dict[\'boundary\'], multi_class_labels=global_gt_dict[\'boundary\'], weights=tf.maximum(global_gt_dict[\'boundary\'] * 3, 1))) * 1000\n            pass\n\n\n        label_loss = tf.constant(0.0)\n        if options.labelLoss == 1:\n            #label_loss = tf.reduce_mean(tf.reduce_max(all_segmentations_softmax, axis=[1, 2]) * tf.concat([tf.cast(tf.equal(tf.squeeze(num_matches, axis=2), 0), tf.float32), tf.ones([options.batchSize, 1])], axis=1)) * 1000\n            #label_loss = tf.reduce_mean(tf.log(1 + tf.reduce_sum(all_segmentations_softmax, axis=[1, 2]))) * 100\n            label_loss = tf.reduce_mean(tf.sqrt(tf.reduce_sum(all_segmentations_softmax, axis=[1, 2]))) * 50\n            #label_loss = tf.reduce_mean(tf.reduce_max(all_segmentations_softmax, axis=[1, 2])) * 1000\n            pass\n\n        #regularization\n        l2_losses = tf.add_n([options.l2Weight * tf.nn.l2_loss(v) for v in tf.trainable_variables() if \'weights\' in v.name])\n\n        if options.planeLoss == 0:\n            plane_loss = tf.constant(0.0)\n            pass\n\n        loss = plane_loss + segmentation_loss + depth_loss + normal_loss + plane_confidence_loss + diverse_loss + boundary_loss + local_score_loss + local_plane_loss + local_mask_loss + label_loss + semantics_loss + l2_losses\n\n        #if options.pixelwiseLoss:\n        #normal_loss = tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_normal\'], global_gt_dict[\'normal\'])) * 1000\n        #depth_loss = tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_depth\'], global_gt_dict[\'depth\']) * validDepthMask) * 1000\n        #pass\n\n        S = tf.one_hot(tf.argmax(all_segmentations, 3), depth=options.numOutputPlanes + 1)\n        depth_one_hot = tf.reduce_sum(all_depths * S, 3, keep_dims=True)\n        debug_dict[\'depth\'] = depth_one_hot\n\n        loss_dict = {\'plane\': plane_loss, \'segmentation\': segmentation_loss, \'depth\': depth_loss, \'normal\': normal_loss, \'boundary\': boundary_loss, \'diverse\': diverse_loss, \'confidence\': plane_confidence_loss, \'local_score\': local_score_loss, \'local_plane\': local_plane_loss, \'local_mask\': local_mask_loss, \'label\': label_loss, \'semantics\': semantics_loss}\n        pass\n    return loss, loss_dict, debug_dict\n\n\ndef main(options):\n    if not os.path.exists(options.checkpoint_dir):\n        os.system(""mkdir -p %s""%options.checkpoint_dir)\n        pass\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n\n    min_after_dequeue = 1000\n\n\n    train_inputs = []\n    val_inputs = []\n    if \'0\' in options.hybrid:\n        train_inputs.append(options.rootFolder + \'/planes_SUNCG_train.tfrecords\')\n        val_inputs.append(options.rootFolder + \'/planes_SUNCG_val.tfrecords\')\n        pass\n    if \'1\' in options.hybrid:\n        for _ in xrange(10):\n            train_inputs.append(options.rootFolder + \'/planes_nyu_rgbd_train.tfrecords\')\n            train_inputs.append(options.rootFolder + \'/planes_nyu_rgbd_labeled_train.tfrecords\')\n            val_inputs.append(options.rootFolder + \'/planes_nyu_rgbd_val.tfrecords\')\n            continue\n        pass\n    if \'2\' in options.hybrid:\n        train_inputs.append(options.rootFolder + \'/planes_matterport_train.tfrecords\')\n        val_inputs.append(options.rootFolder + \'/planes_matterport_val.tfrecords\')\n        pass\n    if \'3\' in options.hybrid:\n        train_inputs.append(options.rootFolder + \'/planes_scannet_train.tfrecords\')\n        val_inputs.append(options.rootFolder + \'/planes_scannet_val.tfrecords\')\n        pass\n\n    reader_train = RecordReaderAll()\n    filename_queue_train = tf.train.string_input_producer(train_inputs, num_epochs=10000)\n    img_inp_train, global_gt_dict_train, local_gt_dict_train = reader_train.getBatch(filename_queue_train, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True)\n\n    reader_val = RecordReaderAll()\n    filename_queue_val = tf.train.string_input_producer(val_inputs, num_epochs=10000)\n    img_inp_val, global_gt_dict_val, local_gt_dict_val = reader_val.getBatch(filename_queue_val, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True)\n\n    training_flag = tf.placeholder(tf.bool, shape=[], name=\'training_flag\')\n\n    #global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp_train, img_inp_val, img_inp_rgbd_train, img_inp_rgbd_val, img_inp_3d_train, img_inp_3d_val, training_flag, options)\n    global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp_train, img_inp_val, training_flag, options)\n\n\n    #loss, loss_dict, _ = build_loss(global_pred_dict, local_pred_dict, deep_pred_dicts, global_gt_dict_train, local_gt_dict_train, global_gt_dict_val, local_gt_dict_val, training_flag, options)\n    #loss_rgbd, loss_dict_rgbd, _ = build_loss_rgbd(global_pred_dict, deep_pred_dicts, global_gt_dict_rgbd_train, global_gt_dict_rgbd_val, training_flag, options)\n    loss, loss_dict, _ = build_loss(img_inp_train, img_inp_val, global_pred_dict, deep_pred_dicts, global_gt_dict_train, global_gt_dict_val, training_flag, options)\n\n    #loss = tf.cond(tf.less(training_flag, 2), lambda: loss, lambda: tf.cond(tf.less(training_flag, 4), lambda: loss_rgbd, lambda: loss_3d))\n\n\n    #train_writer = tf.summary.FileWriter(options.log_dir + \'/train\')\n    #val_writer = tf.summary.FileWriter(options.log_dir + \'/val\')\n    #train_writer_rgbd = tf.summary.FileWriter(options.log_dir + \'/train_rgbd\')\n    #val_writer_rgbd = tf.summary.FileWriter(options.log_dir + \'/val_rgbd\')\n    #writers = [train_writer, val_writer, train_writer_rgbd, val_writer_rgbd]\n\n\n    with tf.variable_scope(\'statistics\'):\n        batchno = tf.Variable(0, dtype=tf.int32, trainable=False, name=\'batchno\')\n        batchnoinc=batchno.assign(batchno+1)\n        pass\n\n\n    optimizer = tf.train.AdamOptimizer(options.LR)\n    if options.crfrnn >= 0:\n        train_op = optimizer.minimize(loss, global_step=batchno)\n    else:\n        var_to_train = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, ""crfrnn"")\n        print(var_to_train)\n        train_op = optimizer.minimize(loss, global_step=batchno, var_list=var_to_train)\n        pass\n\n    var_to_restore = [v for v in tf.global_variables()]\n\n    tf.summary.scalar(\'loss\', loss)\n    summary_op = tf.summary.merge_all()\n\n\n    config=tf.ConfigProto()\n    config.allow_soft_placement=True\n    #config.gpu_options.allow_growth=True\n    config.gpu_options.per_process_gpu_memory_fraction=0.9\n    saver=tf.train.Saver()\n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n        if options.restore == 0:\n            #fine-tune from DeepLab model\n            var_to_restore = [v for v in var_to_restore if \'res5d\' not in v.name and \'segmentation\' not in v.name and \'plane\' not in v.name and \'deep_supervision\' not in v.name and \'local\' not in v.name and \'boundary\' not in v.name and \'degridding\' not in v.name and \'res2a_branch2a\' not in v.name and \'res2a_branch1\' not in v.name and \'Adam\' not in v.name and \'beta\' not in v.name and \'statistics\' not in v.name and \'semantics\' not in v.name]\n            pretrained_model_loader = tf.train.Saver(var_to_restore)\n            pretrained_model_loader.restore(sess,""../pretrained_models/deeplab_resnet.ckpt"")\n        elif options.restore == 1:\n            #restore the same model from checkpoint\n            loader = tf.train.Saver(var_to_restore)\n            loader.restore(sess,""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n            bno=sess.run(batchno)\n            print(bno)\n        elif options.restore == 2:\n            #restore the same model from checkpoint but reset batchno to 1\n            loader = tf.train.Saver(var_to_restore)\n            loader.restore(sess,""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n            sess.run(batchno.assign(1))\n        elif options.restore == 3:\n            #restore the same model from standard training\n            # if options.predictBoundary == 1:\n            #     var_to_restore = [v for v in var_to_restore if \'boundary\' not in v.name]\n            #     pass\n            # if options.predictConfidence == 1:\n            #     var_to_restore = [v for v in var_to_restore if \'confidence\' not in v.name]\n            #     pass\n            if options.predictSemantics == 1:\n                var_to_restore = [v for v in var_to_restore if \'semantics\' not in v.name]\n                pass\n            if np.abs(options.crfrnn) > 0:\n                var_to_restore = [v for v in var_to_restore if \'crfrnn\' not in v.name]\n                pass\n\n            loader = tf.train.Saver(var_to_restore)\n            if len(options.hybrid) == 1:\n                hybrid = options.hybrid\n            else:\n                hybrid = str(3)\n                pass\n            #loader.restore(sess, options.rootFolder + \'/checkpoint/planenet_hybrid\' + hybrid + \'_bl0_ll1_bw0.5_pb_pp_ps_sm0/checkpoint.ckpt\')\n            loader.restore(sess, options.rootFolder + \'/checkpoint/planenet_hybrid\' + hybrid + \'_bl0_dl0_ll1_pb_pp_sm0/checkpoint.ckpt\')\n            #loader.restore(sess,""checkpoint/planenet/checkpoint.ckpt"")\n            sess.run(batchno.assign(1))\n        elif options.restore == 4:\n            #fine-tune another model\n            #var_to_restore = [v for v in var_to_restore if \'res4b22_relu_non_plane\' not in v.name]\n            loader = tf.train.Saver(var_to_restore)\n            loader.restore(sess, options.fineTuningCheckpoint)\n            sess.run(batchno.assign(1))\n            pass\n        elif options.restore == 5:\n            #fine-tune another model\n            #var_to_restore = [v for v in var_to_restore if \'res4b22_relu_non_plane\' not in v.name]\n            loader = tf.train.Saver(var_to_restore)\n            print(options.checkpoint_dir.replace(\'crfrnn\', \'crfrnn-\'))\n            #exit(1)\n            loader.restore(sess,""%s/checkpoint.ckpt""%(options.checkpoint_dir.replace(\'crfrnn\', \'crfrnn-\')))\n            sess.run(batchno.assign(1))\n            pass\n        # Start input enqueue threads.\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n        MOVING_AVERAGE_DECAY = 0.99\n        ema = [0., 0., 0., 0.]\n        ema_acc = [1e-10, 1e-10, 1e-10, 1e-10]\n        last_snapshot_time = time.time()\n        bno=sess.run(batchno)\n\n        try:\n            while bno<300000:\n                t0 = time.time()\n\n                batchIndexPeriod = bno % 100\n                if batchIndexPeriod < len(options.hybrid):\n                    #batchType = int(options.hybrid[batchIndexPeriod]) * 2 + 1\n                    batchType = 1\n                    _, total_loss, losses, summary_str, debug = sess.run([batchnoinc, loss, loss_dict, summary_op, global_pred_dict], feed_dict = {training_flag: batchType == 0})\n                else:\n                    batchType = 0\n                    _, total_loss, losses, summary_str, debug = sess.run([train_op, loss, loss_dict, summary_op, global_pred_dict], feed_dict = {training_flag: batchType == 0})\n\n                    # for batchIndex in xrange(options.batchSize):\n                    #     print(losses)\n                    #     print(debug[\'plane\'][batchIndex])\n                    #     cv2.imwrite(\'test/image_\' + str(batchIndex) + \'.png\', ((img[batchIndex] + 0.5) * 255).astype(np.uint8))\n                    #     cv2.imwrite(\'test/segmentation_\' + str(batchIndex) + \'.png\', drawSegmentationImage(debug[\'segmentation\'][batchIndex]))\n                    #     continue\n                    # exit(1)\n\n                    pass\n\n\n                ema[batchType] = ema[batchType] * MOVING_AVERAGE_DECAY + total_loss\n                ema_acc[batchType] = ema_acc[batchType] * MOVING_AVERAGE_DECAY + 1\n\n                bno = sess.run(batchno)\n                if time.time()-last_snapshot_time > options.saveInterval:\n                    print(\'save snapshot\')\n                    saver.save(sess,\'%s/checkpoint.ckpt\'%options.checkpoint_dir)\n                    last_snapshot_time = time.time()\n                    pass\n\n                print bno,\'train\', ema[0] / ema_acc[0], \'val\', ema[1] / ema_acc[1], \'train rgbd\', ema[2] / ema_acc[2], \'val rgbd\', ema[3] / ema_acc[3], \'loss\', total_loss, \'time\', time.time()-t0\n\n                if np.random.random() < 0.01:\n                    print(losses)\n                    pass\n                continue\n\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n\n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return\n\n\ndef test(options):\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n\n    if options.dataset == \'\':\n        assert(len(options.hybrid) == 1)\n        if options.hybrid == \'0\':\n            options.dataset = \'SUNCG\'\n        elif options.hybrid == \'1\':\n            options.dataset = \'NYU_RGBD\'\n        elif options.hybrid == \'2\':\n            options.dataset = \'matterport\'\n        elif options.hybrid == \'3\':\n            options.dataset = \'ScanNet\'\n\n        options.dataset\n    options.batchSize = 1\n    min_after_dequeue = 1000\n\n    reader = RecordReaderAll()\n    if options.dataset == \'SUNCG\':\n        filename_queue = tf.train.string_input_producer([options.rootFolder + \'/planes_SUNCG_val.tfrecords\'], num_epochs=10000)\n    elif options.dataset == \'NYU_RGBD\':\n        filename_queue = tf.train.string_input_producer([options.rootFolder + \'/planes_nyu_rgbd_val.tfrecords\'], num_epochs=1)\n        options.deepSupervision = 0\n        options.predictLocal = 0\n    elif options.dataset == \'matterport\':\n        filename_queue = tf.train.string_input_producer([options.rootFolder + \'/planes_matterport_val.tfrecords\'], num_epochs=1)\n    else:\n        filename_queue = tf.train.string_input_producer([options.rootFolder + \'/planes_scannet_val.tfrecords\'], num_epochs=1)\n        pass\n    img_inp, global_gt_dict, local_gt_dict = reader.getBatch(filename_queue, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True, random=False)\n\n    training_flag = tf.constant(False, tf.bool)\n\n    global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp, img_inp, training_flag, options)\n    var_to_restore = tf.global_variables()\n\n    loss, loss_dict, debug_dict = build_loss(img_inp, img_inp, global_pred_dict, deep_pred_dicts, global_gt_dict, global_gt_dict, training_flag, options)\n\n\n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n        #var_to_restore = [v for v in var_to_restore if \'res4b22_relu_non_plane\' not in v.name]\n        loader = tf.train.Saver(var_to_restore)\n        loader.restore(sess, ""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n        #loader.restore(sess, ""%s/checkpoint.ckpt""%(\'checkpoint/planenet_pb_pp_hybrid1\'))\n        #loader.restore(sess, options.fineTuningCheckpoint)\n\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n\n        try:\n            gtDepths = []\n            predDepths = []\n            planeMasks = []\n            #predMasks = []\n            gtPlanes = []\n            predPlanes = []\n            gtSegmentations = []\n            predSegmentations = []\n            gtNumPlanes = []\n\n            imageWidth = WIDTH\n            imageHeight = HEIGHT\n            focalLength = 517.97\n            urange = np.arange(imageWidth).reshape(1, -1).repeat(imageHeight, 0) - imageWidth * 0.5\n            vrange = np.arange(imageHeight).reshape(-1, 1).repeat(imageWidth, 1) - imageHeight * 0.5\n            ranges = np.array([urange / imageWidth * 640 / focalLength, np.ones(urange.shape), -vrange / imageHeight * 480 / focalLength]).transpose([1, 2, 0])\n\n\n            segmentationCorrectSums = np.zeros(41)\n            segmentationCounts = np.zeros(41)\n\n            for index in xrange(options.numImages):\n                print((\'image\', index))\n                t0=time.time()\n\n                img, global_gt, local_gt, global_pred, local_pred, deep_preds, total_loss, losses, debug = sess.run([img_inp, global_gt_dict, local_gt_dict, global_pred_dict, local_pred_dict, deep_pred_dicts, loss, loss_dict, debug_dict])\n\n                # print(options.test_dir)\n                # cv2.imwrite(options.test_dir + \'/depth.png\', drawDepthImage(debug[\'depth\'][0]))\n                # cv2.imwrite(options.test_dir + \'/normal.png\', drawNormalImage(debug[\'normal\'][0]))\n                # boundary = debug[\'boundary\'][0]\n                # boundary = np.concatenate([boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)\n                # cv2.imwrite(options.test_dir + \'/boundary.png\', drawMaskImage(boundary))\n                # cv2.imwrite(options.test_dir + \'/depth_gt.png\', drawDepthImage(debug[\'depth_gt\'][0].squeeze()))\n                # exit(1)\n\n                if \'pixelwise\' in options.suffix:\n                    image = ((img[0] + 0.5) * 255).astype(np.uint8)\n                    gt_d = global_gt[\'depth\'].squeeze()\n                    pred_d = global_pred[\'non_plane_depth\'].squeeze()\n                    #depth = global_gt[\'depth\'].squeeze()\n                    if \'_2\' in options.suffix:\n                        pred_p, pred_s, pred_d = fitPlanes(pred_d, numPlanes=20, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=0.2)\n                    elif \'_3\' in options.suffix:\n                        pred_p, pred_s, pred_d = fitPlanes(gt_d, numPlanes=20, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=0.2)\n                        pass\n\n                    # gt_p = global_gt[\'plane\'][0]\n                    # pred_p = planes\n                    # valid_mask = (np.linalg.norm(gt_p, axis=1) > 0).astype(np.float32)\n                    # diff = np.min(np.linalg.norm(np.expand_dims(gt_p, 1) - np.expand_dims(pred_p, 0), axis=2), 1)\n                    # num += valid_mask.sum()\n                    # lossSum += (diff * valid_mask).sum()\n                    if options.dataset == \'SUNCG\':\n                        planeMask = np.squeeze(debug[\'segmentation\']).sum(axis=2)\n                    else:\n                        planeMask = np.ones((HEIGHT, WIDTH))\n                        if \'_2\' in options.suffix or \'_3\' in options.suffix:\n                            planeMask *= (pred_s < 20).astype(np.float32)\n                        pass\n\n                    if index < 10:\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', image)\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth.png\', drawDepthImage(gt_d))\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n                        if \'_2\' in options.suffix or \'_3\' in options.suffix:\n                            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(pred_s))\n                            pass\n                        #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_plane_mask.png\', drawMaskImage(planeMask))\n                        pass\n\n\n                    gtDepths.append(gt_d)\n                    predDepths.append(pred_d)\n                    planeMasks.append(planeMask)\n\n\n                    if options.dataset != \'NYU_RGBD\' and (\'_2\' in options.suffix or \'_3\' in options.suffix):\n                        gt_p = global_gt[\'plane\'][0]\n                        gt_s = global_gt[\'segmentation\'][0]\n                        gt_num_p = global_gt[\'num_planes\'][0]\n\n                        pred_s = (np.expand_dims(pred_s, -1) == np.reshape(np.arange(options.numOutputPlanes), [1, 1, -1])).astype(np.float32)\n                        gtPlanes.append(gt_p)\n                        predPlanes.append(pred_p)\n                        gtSegmentations.append(gt_s)\n                        gtNumPlanes.append(gt_num_p)\n                        predSegmentations.append(pred_s)\n                        pass\n\n                    #planeMasks.append((planeSegmentation < 20).astype(np.float32))\n                    continue\n\n                print(losses)\n                print(total_loss)\n                #print(losses)\n                #exit(1)\n                im = img[0]\n                image = ((im + 0.5) * 255).astype(np.uint8)\n\n                gt_d = global_gt[\'depth\'].squeeze()\n\n\n                if options.predictLocal:\n                    pred_local_s = 1 / (1 + np.exp(-local_pred[\'score\'][0]))\n                    pred_local_p = local_pred[\'plane\'][0]\n                    pred_local_m = local_pred[\'mask\'][0]\n\n                    gt_local_s = local_gt[\'score\'][0]\n                    gt_local_m = local_gt[\'mask\'][0]\n\n                    #visualize local plane prediction\n                    stride = 8\n                    boxSize = 64\n                    xs = np.arange(WIDTH / stride) * stride + stride / 2\n                    ys = np.arange(HEIGHT / stride) * stride + stride / 2\n                    padding = boxSize / 2 + 1\n                    maskImage = np.zeros((HEIGHT + padding * 2, WIDTH + padding * 2, 3), dtype=np.uint8)\n                    maskImage[padding:padding + HEIGHT, padding:padding + WIDTH, :] = image / 2\n                    for gridY, y in enumerate(ys):\n                        for gridX, x in enumerate(xs):\n                            score = pred_local_s[gridY][gridX]\n                            if score < 0.5:\n                                continue\n                            mask = pred_local_m[gridY][gridX].reshape([16, 16])\n                            mask = cv2.resize(mask, (boxSize, boxSize))\n                            maskImage[y - boxSize / 2 + padding:y + boxSize / 2 + padding, x - boxSize / 2 + padding:x + boxSize / 2 + padding, 0][mask > 0.5] = 255\n                            continue\n                        continue\n                    for gridY, y in enumerate(ys):\n                        for gridX, x in enumerate(xs):\n                            score = gt_local_s[gridY][gridX]\n                            if score < 0.5:\n                                continue\n                            mask = gt_local_m[gridY][gridX].reshape([16, 16])\n                            mask = cv2.resize(mask, (boxSize, boxSize))\n                            maskImage[y - boxSize / 2 + padding:y + boxSize / 2 + padding, x - boxSize / 2 + padding:x + boxSize / 2 + padding, 2][mask > 0.5] = 255\n                            continue\n                        continue\n                    pass\n\n                pred_p = global_pred[\'plane\'][0]\n                pred_s = global_pred[\'segmentation\'][0]\n\n                pred_np_m = global_pred[\'non_plane_mask\'][0]\n                pred_np_d = global_pred[\'non_plane_depth\'][0]\n                pred_np_n = global_pred[\'non_plane_normal\'][0]\n\n                planeMask = 1 - global_gt[\'non_plane_mask\'][0]\n                info = global_gt[\'info\'][0]\n\n\n                all_segmentations = np.concatenate([pred_s, pred_np_m], axis=2)\n                all_segmentations_softmax = softmax(all_segmentations)\n                segmentation = np.argmax(all_segmentations, 2)\n\n\n                #pred_p, segmentation, numPlanes = mergePlanes(global_gt[\'plane\'][0], np.concatenate([global_gt[\'segmentation\'][0], global_gt[\'non_plane_mask\'][0]], axis=2), global_gt[\'depth\'][0].squeeze(), global_gt[\'info\'][0], np.concatenate([pred_s, pred_np_m], axis=2))\n\n\n                plane_depths = calcPlaneDepths(pred_p, WIDTH, HEIGHT, info)\n                all_depths = np.concatenate([plane_depths, pred_np_d], axis=2)\n\n                pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape(HEIGHT, WIDTH)\n\n                plane_normals = calcPlaneNormals(pred_p, WIDTH, HEIGHT)\n                all_normals = np.concatenate([plane_normals, np.expand_dims(pred_np_n, 2)], axis=2)\n                pred_n = np.sum(all_normals * np.expand_dims(one_hot(segmentation, options.numOutputPlanes+1), -1), 2)\n                #pred_n = all_normals.reshape(-1, options.numOutputPlanes + 1, 3)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape((HEIGHT, WIDTH, 3))\n\n\n                if False:\n                    gt_s = global_gt[\'segmentation\'][0]\n                    all_segmentations = np.concatenate([gt_s, 1 - planeMask], axis=2)\n                    gt_p = global_gt[\'plane\'][0]\n\n                    # valid_mask = (np.linalg.norm(gt_p, axis=1) > 0).astype(np.float32)\n                    # diff = np.min(np.linalg.norm(np.expand_dims(gt_p, 1) - np.expand_dims(pred_p, 0), axis=2), 1)\n                    # num += valid_mask.sum()\n                    # lossSum += (diff * valid_mask).sum()\n                    #gt_p = np.stack([-gt_p[:, 0], -gt_p[:, 2], -gt_p[:, 1]], axis=1)\n\n                    plane_depths = calcPlaneDepths(gt_p, WIDTH, HEIGHT, info)\n                    all_depths = np.concatenate([plane_depths, pred_np_d], axis=2)\n\n                    segmentation = np.argmax(all_segmentations, 2)\n                    pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape(HEIGHT, WIDTH)\n                    # print(gt_p)\n                    # for segmentIndex in xrange(options.numOutputPlanes):\n                    #     cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_mask_\' + str(segmentIndex) + \'.png\', drawMaskImage(segmentation == segmentIndex))\n                    #     continue\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n                    #exit(1)\n                    pass\n\n\n\n                gt_p = global_gt[\'plane\'][0]\n                gt_s = global_gt[\'segmentation\'][0]\n                gt_num_p = global_gt[\'num_planes\'][0]\n                gtPlanes.append(gt_p)\n                predPlanes.append(pred_p)\n                gtSegmentations.append(gt_s)\n                gtNumPlanes.append(gt_num_p)\n                predSegmentations.append(pred_s)\n\n\n                gtDepths.append(gt_d)\n                planeMasks.append(planeMask.squeeze())\n                predDepths.append(pred_d)\n                evaluateDepths(predDepths[-1], gtDepths[-1], gtDepths[-1] > 0, planeMasks[-1])\n\n\n\n                if options.predictSemantics:\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_semantics_pred.png\', drawSegmentationImage(global_pred[\'semantics\'][0], blackIndex=0))\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_semantics_gt.png\', drawSegmentationImage(global_gt[\'semantics\'][0], blackIndex=0))\n\n                    pred = np.argmax(global_pred[\'semantics\'][0], axis=-1)\n                    gt = global_gt[\'semantics\'][0]\n                    correctMask = pred == gt\n                    for label in xrange(41):\n                        mask = gt == label\n                        segmentationCorrectSums[label] += correctMask[mask].sum()\n                        segmentationCounts[label] += mask.sum()\n                        continue\n                    pass\n\n                if index >= 10:\n                    continue\n\n                if \'cost_mask\' in debug and False:\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_cost_mask.png\', drawMaskImage(np.sum(debug[\'cost_mask\'][0], axis=-1)))\n\n                    for planeIndex in xrange(options.numOutputPlanes + 1):\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_cost_mask_\' + str(planeIndex) + \'.png\', drawMaskImage(debug[\'cost_mask\'][0, :, :, planeIndex]))\n                        continue\n                    all_segmentations = np.concatenate([pred_s, pred_np_m], axis=2)\n                    for planeIndex in xrange(options.numOutputPlanes + 1):\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred_\' + str(planeIndex) + \'.png\', drawMaskImage(all_segmentations[:, :, planeIndex]))\n                        continue\n                    exit(1)\n                    pass\n\n                if \'normal\' in global_gt:\n                    gt_n = global_gt[\'normal\'][0]\n                    norm = np.linalg.norm(gt_n, axis=-1, keepdims=True)\n                    gt_n /= np.maximum(norm, 1e-4)\n\n                    #gt_n = np.stack([-gt_n[:, :, 0], -gt_n[:, :, 2], -gt_n[:, :, 1]], axis=2)\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_gt.png\', drawNormalImage(gt_n))\n                    #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_pred.png\', drawNormalImage(pred_np_n))\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_pred.png\', drawNormalImage(pred_n))\n                    pass\n\n                if \'segmentation\' in global_gt:\n                    gt_s = global_gt[\'segmentation\'][0]\n                    gt_p = global_gt[\'plane\'][0]\n\n\n                    #for planeIndex in xrange(20):\n                    #cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(gt_s[:, :, planeIndex]))\n                    #continue\n\n\n                    # print(gt_p)\n                    # print(gt_n[109][129])\n                    # print(gt_n[166][245])\n                    # print(gt_s[109][129])\n                    # print(gt_s[166][245])\n                    # print(plane_normals[109][129])\n                    # print(plane_normals[166][245])\n                    # for planeIndex in xrange(20):\n                    #     cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(gt_s[:, :, planeIndex]))\n                    #     continue\n                    # exit(1)\n\n                    gt_s, gt_p = sortSegmentations(gt_s, gt_p, pred_p)\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_plane_mask_gt.png\', drawMaskImage(planeMask))\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_gt.png\', drawSegmentationImage(np.concatenate([gt_s, 1 - planeMask], axis=2), blackIndex=options.numOutputPlanes)\n)\n                    #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_test.png\', drawMaskImage(np.sum(np.concatenate([gt_s, 1 - planeMask], axis=2), axis=2)))\n                    #exit(1)\n                    #exit(1)\n                    pass\n\n\n                if options.predictConfidence == 1 and options.dataset == \'SUNCG\':\n                    assert(False)\n                    pred_p_c = global_pred[\'confidence\'][0]\n                    pred_p_c = 1 / (1 + np.exp(-pred_p_c))\n                    #print(pred_p_c)\n                    # print(losses)\n                    # print(debug[\'plane\'][0])\n                    # print(pred_p)\n                    # exit(1)\n                    numPlanes = global_gt[\'num_planes\'][0]\n                    print((numPlanes, (pred_p_c > 0.5).sum()))\n\n                    pred_p_c = (pred_p_c > 0.5).astype(np.float32)\n                    pred_p *= pred_p_c\n                    pred_s -= (1 - pred_p_c.reshape([1, 1, options.numOutputPlanes])) * 10\n                    pass\n\n                if False:\n                    #dump results for post processing\n                    if index >= 10:\n                        break\n                    np.save(options.dump_dir + \'/planes_\' + str(index) + \'.npy\', pred_p)\n                    np.save(options.dump_dir + \'/segmentations_\' + str(index) + \'.npy\', pred_s)\n                    np.save(options.dump_dir + \'/segmentations_gt_\' + str(index) + \'.npy\', gt_s)\n                    np.save(options.dump_dir + \'/non_plane_depth_\' + str(index) + \'.npy\', pred_np_d)\n                    np.save(options.dump_dir + \'/non_plane_segmentation_\' + str(index) + \'.npy\', pred_np_m)\n                    boundary = pred_boundary[0]\n                    boundary = 1 / (1 + np.exp(-boundary))\n                    boundary = np.concatenate([boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)\n                    cv2.imwrite(options.dump_dir + \'/boundary_\' + str(index) + \'.png\', drawMaskImage(boundary))\n                    cv2.imwrite(options.dump_dir + \'/image_\' + str(index) + \'.png\', cv2.resize(image, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR))\n                    np.save(options.dump_dir + \'/depth_\' + str(index) + \'.npy\', gt_d)\n                    continue\n\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', image)\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth.png\', drawDepthImage(gt_d))\n                #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_overlay.png\', drawDepthImageOverlay(image, gt_d))\n\n                if options.predictBoundary:\n                    pred_boundary = global_pred[\'boundary\'][0]\n                    pred_boundary = 1 / (1 + np.exp(-pred_boundary))\n                    boundary = np.concatenate([pred_boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_boundary_pred.png\', drawMaskImage(boundary))\n                    pass\n\n                if \'boundary\' in global_gt:\n                    gt_boundary = global_gt[\'boundary\'][0]\n                    boundary = np.concatenate([gt_boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_boundary_gt.png\', drawMaskImage(boundary))\n                    pass\n\n                for layerIndex, layer in enumerate(options.deepSupervisionLayers):\n                    segmentation_deep = np.argmax(deep_preds[layerIndex][\'segmentation\'][0], 2)\n                    segmentation_deep[segmentation_deep == options.numOutputPlanes] = -1\n                    segmentation_deep += 1\n\n                    plane_depths_deep = calcPlaneDepths(deep_preds[layerIndex][\'plane\'][0], WIDTH, HEIGHT, info)\n                    all_depths_deep = np.concatenate([pred_np_d, plane_depths_deep], axis=2)\n                    pred_d_deep = all_depths_deep.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation_deep.reshape(-1)].reshape(HEIGHT, WIDTH)\n\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred_\' + str(layerIndex) + \'.png\', drawSegmentationImage(deep_preds[layerIndex][\'segmentation\'][0]))\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred_\' + str(layerIndex) + \'.png\', drawDepthImage(pred_d_deep))\n                    pass\n\n\n                #print(pred_np_m)\n                #print(pred_s)\n                #print(global_gt[\'plane\'][0])\n                #print(pred_p)\n                #exit(1)\n\n                print(\'depth diff\', np.abs(pred_d - gt_d).mean())\n\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(all_segmentations, blackIndex=options.numOutputPlanes))\n                #exit(1)\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_diff.png\', drawMaskImage(np.abs(pred_d - gt_d) * planeMask.squeeze() / 0.2))\n                #exit(1)\n\n\n                #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_plane_mask.png\', drawMaskImage(planeMask))\n\n                #print(np.concatenate([np.arange(options.numOutputPlanes).reshape(-1, 1), planes, pred_p, preds_p[0][0]], axis=1))\n\n                #print(np.concatenate([distance[0], preds_p[0][0], pred_p], axis=1))\n\n                #segmentation = np.argmax(pred_s, 2)\n                #writePLYFile(options.test_dir, index, image, pred_d, segmentation, np.zeros(pred_boundary[0].shape))\n                #writePLYFileParts(options.test_dir, index, image, pred_d, segmentation)\n                #gt_s_ori = gt_s_ori[0]\n\n\n                # if \'depth\' in debug:\n                #     cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred_1.png\', drawDepthImage(debug[\'depth\'][0]))\n                #     gt_s_ori = debug[\'segmentation\'][0]\n                #     cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_gt.png\', drawSegmentationImage(gt_s_ori, blackIndex=options.numOutputPlanes))\n                #     total_loss = 0\n                #     for planeIndex in xrange(gt_s_ori.shape[-1]):\n                #         mask_pred = all_segmentations_softmax[:, :, planeIndex]\n                #         loss = -(gt_s_ori[:, :, planeIndex] * np.log(np.maximum(all_segmentations_softmax[:, :, planeIndex], 1e-31))).mean() * 1000\n                #         print(planeIndex, loss)\n                #         total_loss += loss\n                #         cv2.imwrite(options.test_dir + \'/mask_pred_\' + str(planeIndex) + \'.png\', drawMaskImage(mask_pred))\n                #         cv2.imwrite(options.test_dir + \'/mask_gt_\' + str(planeIndex) + \'.png\', drawMaskImage(gt_s_ori[:, :, planeIndex]))\n                #         continue\n                #     print(total_loss)\n                #     print(gt_s_ori.sum(2).max())\n                #     exit(1)\n                #     pass\n\n\n                if False:\n                    #distance = distance[0]\n                    print(distance)\n                    diff = np.linalg.norm(np.expand_dims(planes, 1) - np.expand_dims(pred_p, 0), axis=2)\n                    print(np.concatenate([planes, pred_p, pow(np.min(diff, axis=1, keepdims=True), 2), np.expand_dims(np.argmin(diff, axis=1), -1)], axis=1))\n                    print(pred_p_c)\n\n                    #print(distance[:, 6:8].sum(0))\n                    #print(pow(np.linalg.norm(distance[:, :3] - distance[:, 3:6], 2, 1), 2) * 100)\n                    #print(test)\n                    segmentation = np.argmax(all_segmentations, 2) - 1\n                    for planeIndex in xrange(options.numOutputPlanes):\n                        cv2.imwrite(options.test_dir + \'/segmentation_\' + str(planeIndex) + \'.png\', drawMaskImage(segmentation == planeIndex))\n                        cv2.imwrite(options.test_dir + \'/segmentation_\' + str(planeIndex) + \'_gt.png\', drawMaskImage(gt_s[:, :, planeIndex]))\n                        cv2.imwrite(options.test_dir + \'/segmentation_\' + str(planeIndex) + \'_gt_ori.png\', drawMaskImage(gt_s_ori[:, :, planeIndex]))\n                        continue\n                    exit(1)\n                continue\n\n            # if options.dataset == \'SUNCG\':\n            #     if \'pixelwise\' not in options.suffix:\n            #         evaluatePlaneSegmentation(np.array(predPlanes), np.array(predSegmentations), np.array(gtPlanes), np.array(gtSegmentations), np.array(gtNumPlanes), planeDistanceThreshold = 0.3, IOUThreshold = 0.5, prefix=\'test/planenet_\')\n            #     elif \'_2\' in options.suffix:\n            #         evaluatePlaneSegmentation(np.array(predPlanes), np.array(predSegmentations), np.array(gtPlanes), np.array(gtSegmentations), np.array(gtNumPlanes), planeDistanceThreshold = 0.3, IOUThreshold = 0.5, prefix=\'test/pixelwise_pred_\')\n            #     elif \'_3\' in options.suffix:\n            #         evaluatePlaneSegmentation(np.array(predPlanes), np.array(predSegmentations), np.array(gtPlanes), np.array(gtSegmentations), np.array(gtNumPlanes), planeDistanceThreshold = 0.3, IOUThreshold = 0.5, prefix=\'test/pixelwise_gt_\')\n            #         pass\n            #     pass\n\n            print(\'segmentation accuracy\', segmentationCorrectSums / segmentationCounts, segmentationCorrectSums.sum() / segmentationCounts.sum())\n\n            predDepths = np.array(predDepths)\n            gtDepths = np.array(gtDepths)\n            planeMasks = np.array(planeMasks)\n            #predMasks = np.array(predMasks)\n            evaluateDepths(predDepths, gtDepths, gtDepths > 0, planeMasks)\n            exit(1)\n\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n\n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return\n\n\n# def predict(options):\n#     options.test_dir += \'_predict\'\n#     if not os.path.exists(options.test_dir):\n#         os.system(""mkdir -p %s""%options.test_dir)\n#         pass\n\n#     batchSize = 1\n#     img_inp = tf.placeholder(tf.float32,shape=(batchSize,HEIGHT,WIDTH,3),name=\'img_inp\')\n#     plane_gt=tf.placeholder(tf.float32,shape=(batchSize,options.numOutputPlanes, 3),name=\'plane_inp\')\n#     validating_inp = tf.constant(0, tf.int32)\n\n#     global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp_train, img_inp_val, img_inp_rgbd_train, img_inp_rgbd_val, training_flag, options)\n\n#     var_to_restore = tf.global_variables()\n\n\n#     config=tf.ConfigProto()\n#     config.gpu_options.allow_growth=True\n#     config.allow_soft_placement=True\n\n\n#     if dataset == \'SUNCG\':\n#         image_list_file = os.path.join(\'../PythonScripts/SUNCG/image_list_100_tail_500000.txt\')\n#         with open(image_list_file) as f:\n#             im_names = [{\'image\': im_name.strip().replace(\'plane_global.npy\', \'mlt.png\'), \'depth\': im_name.strip().replace(\'plane_global.npy\', \'depth.png\'), \'normal\': im_name.strip().replace(\'plane_global.npy\', \'norm_camera.png\'), \'valid\': im_name.strip().replace(\'plane_global.npy\', \'valid.png\'), \'plane\': im_name.strip()} for im_name in f.readlines()]\n#             pass\n#     else:\n#         im_names = glob.glob(\'../../Data/NYU_RGBD/*_color.png\')\n#         im_names = [{\'image\': im_name, \'depth\': im_name.replace(\'color.png\', \'depth.png\'), \'normal\': im_name.replace(\'color.png\', \'norm_camera.png\'), \'invalid_mask\': im_name.replace(\'color.png\', \'valid.png\')} for im_name in im_names]\n#         pass\n\n#     if numImages > 0:\n#         im_names = im_names[:numImages]\n#         pass\n\n#     #if args.imageIndex > 0:\n#     #im_names = im_names[args.imageIndex:args.imageIndex + 1]\n#     #pass\n\n#     init_op = tf.group(tf.global_variables_initializer(),\n#                        tf.local_variables_initializer())\n\n\n#     with tf.Session(config=config) as sess:\n#         saver = tf.train.Saver()\n#         #sess.run(tf.global_variables_initializer())\n#         saver.restore(sess,""%s/%s.ckpt""%(options.checkpoint_dir,keyname))\n\n#         gtDepths = []\n#         predDepths = []\n#         segmentationDepths = []\n#         predDepthsOneHot = []\n#         planeMasks = []\n#         predMasks = []\n\n#         imageWidth = WIDTH\n#         imageHeight = HEIGHT\n#         focalLength = 517.97\n#         urange = np.arange(imageWidth).reshape(1, -1).repeat(imageHeight, 0) - imageWidth * 0.5\n#         vrange = np.arange(imageHeight).reshape(-1, 1).repeat(imageWidth, 1) - imageHeight * 0.5\n#         ranges = np.array([urange / focalLength, np.ones(urange.shape), -vrange / focalLength]).transpose([1, 2, 0])\n\n#         cv2.imwrite(options.test_dir + \'/one.png\', np.ones((HEIGHT, WIDTH), dtype=np.uint8) * 255)\n#         cv2.imwrite(options.test_dir + \'/zero.png\', np.zeros((HEIGHT, WIDTH), dtype=np.uint8) * 255)\n#         for index, im_name in enumerate(im_names):\n#             if index <= -1:\n#                 continue\n#             print(im_name[\'image\'])\n#             im = cv2.imread(im_name[\'image\'])\n#             image = im.astype(np.float32, copy=False)\n#             image = image / 255 - 0.5\n#             image = cv2.resize(image, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n\n#             #planes = np.load(im_name[\'plane\'])\n#             # numPlanes = planes.shape[0]\n#             # if numPlanes > options.numOutputPlanes:\n#             #     planeAreas = planes[:, 3:].sum(1)\n#             #     sortInds = np.argsort(planeAreas)[::-1]\n#             #     planes = planes[sortInds[:options.numOutputPlanes]]\n#             #     pass\n#             # gt_p = np.zeros((1, options.numOutputPlanes, 3))\n#             # gt_p[0, :numPlanes] = planes[:numPlanes, :3]\n\n#             normal = np.array(PIL.Image.open(im_name[\'normal\'])).astype(np.float) / 255 * 2 - 1\n#             norm = np.linalg.norm(normal, 2, 2)\n#             for c in xrange(3):\n#                 normal[:, :, c] /= norm\n#                 continue\n#             normal = cv2.resize(normal, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n\n#             depth = np.array(PIL.Image.open(im_name[\'depth\'])).astype(np.float) / 1000\n#             depth = cv2.resize(depth, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n\n#             invalid_mask = cv2.resize(cv2.imread(im_name[\'invalid_mask\'], 0), (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR) > 128\n\n#             gtDepths.append(depth)\n\n\n#             pred_p, pred_d, pred_n, pred_s, pred_np_m, pred_np_d, pred_np_n, pred_boundary, pred_local_score, pred_local_p, pred_local_mask = sess.run([plane_pred, depth_pred, normal_pred, segmentation_pred, non_plane_mask_pred, non_plane_depth_pred, non_plane_normal_pred, boundary_pred, local_score_pred, local_p_pred, local_mask_pred], feed_dict = {img_inp:np.expand_dims(image, 0), plane_gt: np.zeros((batchSize, options.numOutputPlanes, 3))})\n\n\n#             pred_s = pred_s[0]\n#             pred_p = pred_p[0]\n#             pred_np_m = pred_np_m[0]\n#             pred_np_d = pred_np_d[0]\n#             pred_np_n = pred_np_n[0]\n#             #pred_s = 1 / (1 + np.exp(-pred_s))\n\n#             plane_depths = calcPlaneDepths(pred_p, WIDTH, HEIGHT)\n#             all_depths = np.concatenate([pred_np_d, plane_depths], axis=2)\n\n#             all_segmentations = np.concatenate([pred_np_m, pred_s], axis=2)\n#             segmentation = np.argmax(all_segmentations, 2)\n#             if suffix != \'pixelwise\':\n#                 pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape(HEIGHT, WIDTH)\n#             else:\n#                 pred_d = np.squeeze(pred_np_d)\n#                 pass\n#             predDepths.append(pred_d)\n#             predMasks.append(segmentation != 0)\n#             planeMasks.append(invalid_mask)\n\n#             #depthError, normalError, occupancy, segmentationTest, reconstructedDepth, occupancyMask = evaluatePlanes(pred_p, im_name[\'image\'])\n#             #reconstructedDepth = cv2.resize(reconstructedDepth, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n\n#             #evaluatePlanes(pred_p[0], im_name, options.test_dir, index)\n#             #print(pred_p)\n#             #print(gt_p)\n#             #print((pow(pred_d[0, :, :, 0] - depth, 2) * (gt_s.max(2) > 0.5)).mean())\n#             #print((depthError, normalError, occupancy))\n\n#             evaluateDepths(predDepths[index], gtDepths[index], np.ones(planeMasks[index].shape), planeMasks[index])\n\n#             if index >= 10:\n#                 continue\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', cv2.resize(im, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR))\n#             #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_gt.png\', (minDepth / np.clip(depth, minDepth, 20) * 255).astype(np.uint8))\n#             #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', (minDepth / np.clip(pred_d[0, :, :, 0], minDepth, 20) * 255).astype(np.uint8))\n#             #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_plane.png\', (minDepth / np.clip(reconstructedDepth, minDepth, 20) * 255).astype(np.uint8))\n\n#             pred_boundary = pred_boundary[0]\n#             boundary = (1 / (1 + np.exp(-pred_boundary)) * 255).astype(np.uint8)\n#             boundary = np.concatenate([boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_boundary_pred.png\', boundary)\n\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_inp.png\', drawDepthImage(depth))\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n#             #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_plane.png\', drawDepthImage(reconstructedDepth))\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred_diff.png\', drawDiffImage(pred_d, depth, 0.5))\n#             #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_plane_diff.png\', np.minimum(np.abs(reconstructedDepth - depth) / 0.5 * 255, 255).astype(np.uint8))\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_inp.png\', drawNormalImage(normal))\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_pred.png\', drawNormalImage(pred_np_n))\n#             cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(all_segmentations, black=True))\n\n#             segmentation = np.argmax(pred_s, 2)\n#             #writePLYFile(options.test_dir, index, image, pred_p, segmentation)\n\n#             if index < 0:\n#                 for planeIndex in xrange(options.numOutputPlanes):\n#                     cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_\' + str(planeIndex) + \'.png\', drawMaskImage(pred_s[:, :, planeIndex]))\n#                     #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_\' + str(planeIndex) + \'_gt.png\', drawMaskImage(gt_s[:, :, planeIndex]))\n#                     continue\n#                 pass\n#             continue\n#         predDepths = np.array(predDepths)\n#         gtDepths = np.array(gtDepths)\n#         planeMasks = np.array(planeMasks)\n#         predMasks = np.array(predMasks)\n#         #evaluateDepths(predDepths, gtDepths, planeMasks, predMasks)\n#         evaluateDepths(predDepths, gtDepths, planeMasks, planeMasks)\n#         #exit(1)\n#         pass\n#     return\n\n\n# def fitPlanesRGBD(options):\n#     writeHTMLRGBD(\'../results/RANSAC_RGBD/index.html\', 10)\n#     exit(1)\n#     if not os.path.exists(options.checkpoint_dir):\n#         os.system(""mkdir -p %s""%options.checkpoint_dir)\n#         pass\n#     if not os.path.exists(options.test_dir):\n#         os.system(""mkdir -p %s""%options.test_dir)\n#         pass\n\n#     min_after_dequeue = 1000\n\n#     reader_rgbd = RecordReaderRGBD()\n#     filename_queue_rgbd = tf.train.string_input_producer([\'../planes_nyu_rgbd_train.tfrecords\'], num_epochs=1)\n#     img_inp_rgbd, global_gt_dict_rgbd, local_gt_dict_rgbd = reader_rgbd.getBatch(filename_queue_rgbd, numOutputPlanes=options.numOutputPlanes, batchSize=1, min_after_dequeue=min_after_dequeue, getLocal=True)\n\n#     config=tf.ConfigProto()\n#     config.gpu_options.allow_growth=True\n#     config.allow_soft_placement=True\n\n#     init_op = tf.group(tf.global_variables_initializer(),\n#                        tf.local_variables_initializer())\n\n#     with tf.Session(config=config) as sess:\n#         sess.run(init_op)\n\n#         coord = tf.train.Coordinator()\n#         threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n#         try:\n#             gtDepths = []\n#             predDepths = []\n#             planeMasks = []\n#             for index in xrange(10):\n#                 image, depth, path = sess.run([img_inp_rgbd, global_gt_dict_rgbd[\'depth\'], global_gt_dict_rgbd[\'path\']])\n#                 image = ((image[0] + 0.5) * 255).astype(np.uint8)\n#                 depth = depth.squeeze()\n\n#                 cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', image)\n#                 cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth.png\', drawDepthImage(depth))\n#                 #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_mask.png\', drawMaskImage(depth == 0))\n#                 planes, planeSegmentation, depthPred = fitPlanes(depth, numPlanes=20)\n#                 cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(planeSegmentation))\n#                 cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(depthPred))\n\n#                 gtDepths.append(depth)\n#                 predDepths.append(depthPred)\n#                 planeMasks.append((planeSegmentation < 20).astype(np.float32))\n#                 continue\n#             predDepths = np.array(predDepths)\n#             gtDepths = np.array(gtDepths)\n#             planeMasks = np.array(planeMasks)\n#             evaluateDepths(predDepths, gtDepths, np.ones(planeMasks.shape, dtype=np.bool), planeMasks)\n#         except tf.errors.OutOfRangeError:\n#             print(\'done fitting\')\n#         finally:\n#             # When done, ask the threads to stop.\n#             coord.request_stop()\n#             pass\n#     return\n\ndef writeInfo(options):\n    x = (np.arange(11) * 0.1).tolist()\n    ys = []\n    ys.append(np.load(\'test/planenet_pixel_IOU.npy\').tolist())\n    ys.append(np.load(\'test/pixelwise_pred_pixel_IOU.npy\').tolist())\n    ys.append(np.load(\'test/pixelwise_gt_pixel_IOU.npy\').tolist())\n    plotCurves(x, ys, filename = \'test/plane_comparison.png\', xlabel=\'IOU\', ylabel=\'pixel coverage\', labels=[\'planenet\', \'pixelwise+RANSAC\', \'GT+RANSAC\'])\n\n    x = (0.5 - np.arange(11) * 0.05).tolist()\n    ys = []\n    ys.append(np.load(\'test/planenet_pixel_diff.npy\').tolist())\n    ys.append(np.load(\'test/pixelwise_pred_pixel_diff.npy\').tolist())\n    ys.append(np.load(\'test/pixelwise_gt_pixel_diff.npy\').tolist())\n    plotCurves(x, ys, filename = \'test/plane_comparison_diff.png\', xlabel=\'diff\', ylabel=\'pixel coverage\', labels=[\'planenet\', \'pixelwise+RANSAC\', \'GT+RANSAC\'])\n\n    return\n\ndef parse_args():\n    """"""\n    Parse input arguments\n    """"""\n    parser = argparse.ArgumentParser(description=\'Planenet\')\n    parser.add_argument(\'--gpu\', dest=\'gpu_id\',\n                        help=\'GPU device id to use [0]\',\n                        default=0, type=int)\n    #task: [train, test, predict]\n    parser.add_argument(\'--task\', dest=\'task\',\n                        help=\'task type: [train, test, predict]\',\n                        default=\'train\', type=str)\n    parser.add_argument(\'--restore\', dest=\'restore\',\n                        help=\'how to restore the model\',\n                        default=0, type=int)\n    parser.add_argument(\'--numOutputPlanes\', dest=\'numOutputPlanes\',\n                        help=\'the number of output planes\',\n                        default=20, type=int)\n    parser.add_argument(\'--batchSize\', dest=\'batchSize\',\n                        help=\'batch size\',\n                        default=16, type=int)\n    parser.add_argument(\'--dataset\', dest=\'dataset\',\n                        help=\'dataset name for test/predict\',\n                        default=\'\', type=str)\n    parser.add_argument(\'--numImages\', dest=\'numImages\',\n                        help=\'the number of images to test/predict\',\n                        default=10, type=int)\n    parser.add_argument(\'--boundaryLoss\', dest=\'boundaryLoss\',\n                        help=\'use boundary loss: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--diverseLoss\', dest=\'diverseLoss\',\n                        help=\'use diverse loss: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--labelLoss\', dest=\'labelLoss\',\n                        help=\'use label loss: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--planeLoss\', dest=\'planeLoss\',\n                        help=\'use plane loss: [0, 1]\',\n                        default=1, type=int)\n    parser.add_argument(\'--deepSupervision\', dest=\'deepSupervision\',\n                        help=\'deep supervision level: [0, 1, 2]\',\n                        default=0, type=int)\n    parser.add_argument(\'--sameMatching\', dest=\'sameMatching\',\n                        help=\'use the same matching for all deep supervision layers and the final prediction: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--anchorPlanes\', dest=\'anchorPlanes\',\n                        help=\'use anchor planes for all deep supervision layers and the final prediction: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--crf\', dest=\'crf\',\n                        help=\'the number of CRF iterations\',\n                        default=0, type=int)\n    parser.add_argument(\'--crfrnn\', dest=\'crfrnn\',\n                        help=\'the number of CRF (as RNN) iterations\',\n                        default=0, type=int)\n    parser.add_argument(\'--backwardLossWeight\', dest=\'backwardLossWeight\',\n                        help=\'backward matching loss\',\n                        default=0, type=float)\n    parser.add_argument(\'--predictBoundary\', dest=\'predictBoundary\',\n                        help=\'whether predict boundary or not: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--predictSemantics\', dest=\'predictSemantics\',\n                        help=\'whether predict semantics or not: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--predictLocal\', dest=\'predictLocal\',\n                        help=\'whether predict local planes or not: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--predictConfidence\', dest=\'predictConfidence\',\n                        help=\'whether predict plane confidence or not: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--predictPixelwise\', dest=\'predictPixelwise\',\n                        help=\'whether predict pixelwise depth or not: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--fineTuningCheckpoint\', dest=\'fineTuningCheckpoint\',\n                        help=\'specify the model for fine-tuning\',\n                        default=\'../PlaneSetGeneration/dump_planenet_diverse/train_planenet_diverse.ckpt\', type=str)\n    parser.add_argument(\'--suffix\', dest=\'suffix\',\n                        help=\'add a suffix to keyname to distinguish experiments\',\n                        default=\'\', type=str)\n    parser.add_argument(\'--l2Weight\', dest=\'l2Weight\',\n                        help=\'L2 regulation weight\',\n                        default=5e-4, type=float)\n    parser.add_argument(\'--LR\', dest=\'LR\',\n                        help=\'learning rate\',\n                        default=3e-5, type=float)\n    parser.add_argument(\'--hybrid\', dest=\'hybrid\',\n                        help=\'hybrid training\',\n                        default=\'3\', type=str)\n    parser.add_argument(\'--rootFolder\', dest=\'rootFolder\',\n                        help=\'root folder\',\n                        default=\'/mnt/vision/PlaneNet/\', type=str)\n    parser.add_argument(\'--dataFolder\', dest=\'dataFolder\',\n                        help=\'data folder\',\n                        default=\'/home/chenliu/Projects/PlaneNet/\', type=str)\n    parser.add_argument(\'--saveInterval\', dest=\'saveInterval\',\n                        help=\'save interval\',\n                        default=900, type=int)\n\n\n    args = parser.parse_args()\n    args.keyname = os.path.basename(__file__).rstrip(\'.py\')\n    args.keyname = args.keyname.replace(\'train_\', \'\')\n\n    if args.numOutputPlanes != 20:\n        args.keyname += \'_np\' + str(args.numOutputPlanes)\n        pass\n    args.keyname += \'_hybrid\' + args.hybrid\n\n    if args.boundaryLoss != 1:\n        args.keyname += \'_bl\' + str(args.boundaryLoss)\n        pass\n    if args.diverseLoss == 0:\n        args.keyname += \'_dl0\'\n        pass\n    if args.labelLoss == 1:\n        args.keyname += \'_ll1\'\n        pass\n    if args.planeLoss == 0:\n        args.keyname += \'_pl0\'\n        pass\n    if args.deepSupervision != 1:\n        args.keyname += \'_ds\' + str(args.deepSupervision)\n        pass\n    if args.crf > 0:\n        args.keyname += \'_crf\' + str(args.crf)\n        pass\n    if args.crfrnn != 0:\n        args.keyname += \'_crfrnn\' + str(args.crfrnn)\n        pass\n    if args.backwardLossWeight > 0:\n        args.keyname += \'_bw\' + str(args.backwardLossWeight)\n        pass\n    if args.predictBoundary == 1:\n        args.keyname += \'_pb\'\n        pass\n    if args.predictConfidence == 1:\n        args.keyname += \'_pc\'\n        pass\n    # if args.predictLocal == 1:\n    #     args.keyname += \'_pl\'\n    #     pass\n    if args.predictPixelwise == 1:\n        args.keyname += \'_pp\'\n        pass\n    if args.predictSemantics == 1:\n        args.keyname += \'_ps\'\n        pass\n    if args.sameMatching == 0:\n        args.keyname += \'_sm0\'\n        pass\n    if args.anchorPlanes == 1:\n        args.keyname += \'_ap1\'\n        pass\n\n    #args.predictSemantics = 0\n    #args.predictBoundary = 0\n\n    args.checkpoint_dir = args.rootFolder + \'/checkpoint/\' + args.keyname\n    args.log_dir = \'log/\' + args.keyname\n    args.test_dir = \'test/\' + args.keyname + \'_\' + args.dataset\n    args.predict_dir = \'predict/\' + args.keyname + \'_\' + args.dataset\n    args.dump_dir = \'dump/\' + args.keyname\n\n    #layers where deep supervision happens\n    args.deepSupervisionLayers = []\n    if args.deepSupervision >= 1:\n        args.deepSupervisionLayers.append(\'res4b22_relu\')\n        pass\n    if args.deepSupervision >= 2:\n        args.deepSupervisionLayers.append(\'res4b12_relu\')\n        pass\n    return args\n\n\nif __name__==\'__main__\':\n    args = parse_args()\n\n    print ""keyname=%s task=%s started""%(args.keyname, args.task)\n    try:\n        if args.task == ""train"":\n            main(args)\n        elif args.task == ""test"":\n            test(args)\n        elif args.task == ""predict"":\n            predict(args)\n        elif args.task == ""fit"":\n            fitPlanesRGBD(args)\n        elif args.task == ""write"":\n            writeInfo(args)\n        else:\n            assert False,""format wrong""\n            pass\n    finally:\n        pass\n'"
code/train_planenet_backup.py,157,"b'import tensorflow as tf\nimport numpy as np\nnp.set_printoptions(precision=2, linewidth=200)\nimport cv2\nimport os\nimport time\nimport sys\nimport tf_nndistance\nimport argparse\nimport glob\nimport PIL\nimport scipy.ndimage as ndimage\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom utils import *\nfrom plane_utils import *\nfrom modules import *\n\n\nfrom planenet import PlaneNet\nfrom RecordReader import *\nfrom RecordReaderRGBD import *\nfrom RecordReaderScanNet import *\n\n#training_flag: toggle dropout and batch normalization mode\n#it\'s true for training and false for validation, testing, prediction\n#it also controls which data batch to use (*_train or *_val)\n\n\ndef build_graph(img_inp_train, img_inp_val, img_inp_rgbd_train, img_inp_rgbd_val, training_flag, options):\n    with tf.device(\'/gpu:%d\'%options.gpu_id):\n        img_inp_rgbd = tf.cond(tf.equal(training_flag % 2, 0), lambda: img_inp_rgbd_train, lambda: img_inp_rgbd_val)\n        img_inp = tf.cond(tf.equal(training_flag % 2, 0), lambda: img_inp_train, lambda: img_inp_val)\n        img_inp = tf.cond(tf.less(training_flag, 2), lambda: img_inp, lambda: img_inp_rgbd)\n        \n        net = PlaneNet({\'img_inp\': img_inp}, is_training=tf.equal(training_flag % 2, 0), options=options)\n\n        #global predictions\n        plane_pred = net.layers[\'plane_pred\']\n        \n        segmentation_pred = net.layers[\'segmentation_pred\']\n        non_plane_mask_pred = net.layers[\'non_plane_mask_pred\']\n        non_plane_depth_pred = net.layers[\'non_plane_depth_pred\']\n        non_plane_normal_pred = net.layers[\'non_plane_normal_pred\']\n        \n        global_pred_dict = {\'plane\': plane_pred, \'segmentation\': segmentation_pred, \'non_plane_mask\': non_plane_mask_pred, \'non_plane_depth\': non_plane_depth_pred, \'non_plane_normal\': non_plane_normal_pred}\n\n        if options.predictBoundary:\n            global_pred_dict[\'boundary\'] = net.layers[\'boundary_pred\']\n            pass\n        if options.predictConfidence:\n            global_pred_dict[\'confidence\'] = net.layers[\'plane_confidence_pred\']\n            pass\n        \n        #local predictions\n        if options.predictLocal:\n            local_pred_dict = {\'score\': net.layers[\'local_score_pred\'], \'plane\': net.layers[\'local_plane_pred\'], \'mask\': net.layers[\'local_mask_pred\']}\n        else:\n            local_pred_dict = {}\n            pass\n\n        \n        #deep supervision\n        deep_pred_dicts = []\n        for layer in options.deepSupervisionLayers:\n            pred_dict = {\'plane\': net.layers[layer+\'_plane_pred\'], \'segmentation\': net.layers[layer+\'_segmentation_pred\'], \'non_plane_mask\': net.layers[layer+\'_non_plane_mask_pred\']}\n            #if options.predictConfidence:\n            #pred_dict[\'confidence\'] = net.layers[layer+\'_plane_confidence_pred\']\n            #pass\n            deep_pred_dicts.append(pred_dict)\n            continue\n        pass\n    \n    return global_pred_dict, local_pred_dict, deep_pred_dicts\n\n\ndef build_loss_rgbd(global_pred_dict, local_pred_dict, deep_pred_dicts, global_gt_dict_train, local_gt_dict_train, global_gt_dict_val, local_gt_dict_val, training_flag, options):\n    with tf.device(\'/gpu:%d\'%options.gpu_id):\n        global_gt_dict = {}\n        for name in global_gt_dict_train.keys():\n            global_gt_dict[name] = tf.cond(tf.equal(training_flag % 2, 0), lambda: global_gt_dict_train[name], lambda: global_gt_dict_val[name])\n            continue\n        local_gt_dict = {}\n        for name in local_gt_dict_train.keys():\n            local_gt_dict[name] = tf.cond(tf.equal(training_flag % 2, 0), lambda: local_gt_dict_train[name], lambda: local_gt_dict_val[name])\n            continue\n\n        #depth loss\n        plane_parameters = tf.reshape(global_pred_dict[\'plane\'], (-1, 3))\n        plane_depths = planeDepthsModule(plane_parameters, WIDTH, HEIGHT)\n        plane_depths = tf.transpose(tf.reshape(plane_depths, [HEIGHT, WIDTH, -1, options.numOutputPlanes]), [2, 0, 1, 3])\n\n        all_segmentations = tf.concat([global_pred_dict[\'segmentation\'], global_pred_dict[\'non_plane_mask\']], axis=3)\n        all_segmentations_softmax = tf.nn.softmax(all_segmentations)\n        all_depths = tf.concat([plane_depths, global_pred_dict[\'non_plane_depth\']], axis=3)\n        validDepthMask = tf.cast(tf.greater(global_gt_dict[\'depth\'], 1e-4), tf.float32)\n        depth_loss = tf.reduce_mean(tf.reduce_sum(tf.squared_difference(all_depths, global_gt_dict[\'depth\']) * all_segmentations_softmax, axis=3, keep_dims=True) * validDepthMask) * 1000\n\n        if options.predictPixelwise == 1:\n            depth_loss += tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_mask\'], global_gt_dict[\'depth\']) * validDepthMask) * 1000\n            pass\n        \n        #non plane mask loss\n        segmentation_loss = tf.reduce_mean(tf.slice(all_segmentations_softmax, [0, 0, 0, options.numOutputPlanes], [options.batchSize, HEIGHT, WIDTH, 1])) * 100\n        \n        l2_losses = tf.add_n([options.l2Weight * tf.nn.l2_loss(v) for v in tf.trainable_variables() if \'weights\' in v.name])\n        loss = depth_loss + segmentation_loss + l2_losses\n        loss_dict = {\'depth\': depth_loss, \'plane\': tf.constant(0.0), \'segmentation\': segmentation_loss}\n        debug_dict = {}\n        pass\n    return loss, loss_dict, debug_dict\n\n\ndef build_loss(global_pred_dict, local_pred_dict, deep_pred_dicts, global_gt_dict_train, local_gt_dict_train, global_gt_dict_val, local_gt_dict_val, training_flag, options):\n    \n    with tf.device(\'/gpu:%d\'%options.gpu_id):\n        global_gt_dict = {}\n        for name in global_gt_dict_train.keys():\n            global_gt_dict[name] = tf.cond(tf.equal(training_flag % 2, 0), lambda: global_gt_dict_train[name], lambda: global_gt_dict_val[name])\n            continue\n        local_gt_dict = {}\n        for name in local_gt_dict_train.keys():\n            local_gt_dict[name] = tf.cond(tf.equal(training_flag % 2, 0), lambda: local_gt_dict_train[name], lambda: local_gt_dict_val[name])\n            continue\n\n        normalDotThreshold = np.cos(np.deg2rad(5))\n        distanceThreshold = 0.05\n        segmentation_gt, plane_mask = fitPlaneMasksModule(global_gt_dict[\'plane\'], global_gt_dict[\'depth\'], global_gt_dict[\'normal\'], width=WIDTH, height=HEIGHT, normalDotThreshold=normalDotThreshold, distanceThreshold=distanceThreshold, closing=True, one_hot=True)\n        \n        validPlaneMask = tf.cast(tf.less(tf.tile(tf.expand_dims(tf.range(options.numOutputPlanes), 0), [options.batchSize, 1]), tf.expand_dims(global_gt_dict[\'num_planes\'], -1)), tf.float32)        \n\n        \n        backwardLossWeight = options.backwardLossWeight\n        \n\n        #plane loss and segmentation loss (summation over deep supervisions and final supervision)\n        all_pred_dicts = deep_pred_dicts + [global_pred_dict]\n        plane_loss = tf.constant(0.0)\n        segmentation_loss = tf.constant(0.0)\n        plane_confidence_loss = tf.constant(0.0)\n        diverse_loss = tf.constant(0.0)\n        \n        #keep forward map (segmentation gt) from previous supervision so that we can have same matching for all supervisions (options.sameMatching = 1)\n        previous_forward_map = None\n        previous_segmentation_gt = None\n        for pred_index, pred_dict in enumerate(all_pred_dicts):\n            if options.sameMatching and pred_index > 0:\n                #use matching from previous supervision and map ground truth planes based on the mapping\n                forward_map = previous_forward_map\n\n                #number of ground truth mapped for each prediction\n                num_matches = tf.transpose(tf.reduce_sum(forward_map, axis=1, keep_dims=True), [0, 2, 1])\n\n\n                plane_gt_shuffled = tf.transpose(tf.matmul(global_gt_dict[\'plane\'], forward_map, transpose_a=True), [0, 2, 1]) / tf.maximum(num_matches, 1e-4)\n                plane_confidence_gt = tf.cast(num_matches > 0.5, tf.float32)\n                plane_loss += tf.reduce_mean(tf.squared_difference(pred_dict[\'plane\'], plane_gt_shuffled) * plane_confidence_gt) * 10000\n\n                \n                #all segmentations is the concatenation of plane segmentations and non plane mask\n                all_segmentations = tf.concat([pred_dict[\'segmentation\'], pred_dict[\'non_plane_mask\']], axis=3)\n                segmentation_gt_shuffled = previous_segmentation_gt\n                segmentation_loss += tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=all_segmentations, labels=segmentation_gt_shuffled)) * 1000\n                \n            else:\n                #calculate new matching by finding nearest neighbors again\n                dists_forward, map_forward, dists_backward, _ = tf_nndistance.nn_distance(global_gt_dict[\'plane\'], pred_dict[\'plane\'])\n                dists_forward *= validPlaneMask\n                \n                dists_forward = tf.reduce_mean(dists_forward)\n                dists_backward = tf.reduce_mean(dists_backward)\n                plane_loss += (dists_forward + dists_backward * backwardLossWeight) * 10000\n\n                forward_map = tf.one_hot(map_forward, depth=options.numOutputPlanes, axis=-1)\n                forward_map *= tf.expand_dims(validPlaneMask, -1)\n\n                previous_forward_map = forward_map\n                \n                segmentation_gt_shuffled = tf.reshape(tf.matmul(tf.reshape(segmentation_gt, [-1, HEIGHT * WIDTH, options.numOutputPlanes]), forward_map), [-1, HEIGHT, WIDTH, options.numOutputPlanes])\n                segmentation_gt_shuffled = tf.concat([segmentation_gt_shuffled, 1 - plane_mask], axis=3)\n                previous_segmentation_gt = segmentation_gt_shuffled\n                \n                all_segmentations = tf.concat([pred_dict[\'segmentation\'], pred_dict[\'non_plane_mask\']], axis=3)\n                segmentation_loss += tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=all_segmentations, labels=segmentation_gt_shuffled)) * 1000\n                pass\n\n            if options.diverseLoss:\n                plane_diff = tf.reduce_sum(tf.pow(tf.expand_dims(pred_dict[\'plane\'], 1) - tf.expand_dims(pred_dict[\'plane\'], 2), 2), axis=3)\n                plane_diff = tf.matrix_set_diag(plane_diff, tf.ones((options.batchSize, options.numOutputPlanes)))\n                minPlaneDiff = 0.1\n                diverse_loss += tf.reduce_mean(tf.clip_by_value(1 - plane_diff / minPlaneDiff, 0, 1)) * 10000\n                pass\n              \n            continue\n\n\n\n        #depth loss\n        plane_parameters = tf.reshape(global_pred_dict[\'plane\'], (-1, 3))\n        plane_depths = planeDepthsModule(plane_parameters, WIDTH, HEIGHT)\n        plane_depths = tf.transpose(tf.reshape(plane_depths, [HEIGHT, WIDTH, -1, options.numOutputPlanes]), [2, 0, 1, 3])\n\n        all_segmentations_softmax = tf.nn.softmax(all_segmentations)\n        non_plane_depth = global_pred_dict[\'non_plane_depth\']\n        all_depths = tf.concat([plane_depths, non_plane_depth], axis=3)\n        validDepthMask = tf.cast(tf.greater(global_gt_dict[\'depth\'], 1e-4), tf.float32)\n        depth_loss = tf.reduce_mean(tf.reduce_sum(tf.squared_difference(all_depths, global_gt_dict[\'depth\']) * all_segmentations_softmax, axis=3, keep_dims=True) * validDepthMask) * 1000\n\n        if options.predictPixelwise == 1:\n            depth_loss += tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_mask\'], global_gt_dict[\'depth\']) * validDepthMask) * 1000\n            normal_loss = tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_normal\'], global_gt_dict[\'normal\']) * validDepthMask) * 1000\n        else:\n            #normal loss for non-plane region\n            normal_loss = tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_normal\'], global_gt_dict[\'normal\']) * (1 - plane_mask)) * 1000\n            pass\n        \n\n        #local loss\n        if options.predictLocal:\n            local_score_loss = tf.reduce_mean(tf.losses.sigmoid_cross_entropy(logits=local_pred_dict[\'score\'], multi_class_labels=local_gt_dict[\'score\'], weights=tf.maximum(local_gt_dict[\'score\'] * 10, 1))) * 1000\n            local_plane_loss = tf.reduce_mean(tf.squared_difference(local_pred_dict[\'plane\'], local_gt_dict[\'plane\']) * local_gt_dict[\'score\']) * 10000\n            local_mask_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=local_pred_dict[\'mask\'], labels=local_gt_dict[\'mask\']) * local_gt_dict[\'score\']) * 10000\n        else:\n            local_score_loss = tf.constant(0.0)\n            local_plane_loss = tf.constant(0.0)\n            local_mask_loss = tf.constant(0.0)\n            pass\n        \n        \n        #boundary loss\n        boundary_loss = tf.constant(0.0)\n        #load or calculate boundary ground truth\n        if False:\n            #load from dataset\n            boundary_gt = tf.cond(training_flag, lambda: boundary_gt_train, lambda: boundary_gt_val)\n        else:\n            #calculate boundary ground truth on-the-fly as the calculation is subject to change\n            kernel_size = 3\n            padding = (kernel_size - 1) / 2\n            neighbor_kernel_array = gaussian(kernel_size, kernel_size)\n            neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n            neighbor_kernel_array /= neighbor_kernel_array.sum()\n            neighbor_kernel_array *= -1\n            neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 1\n            neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n            neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n        \n            depth_diff = tf.abs(tf.nn.depthwise_conv2d(global_gt_dict[\'depth\'], neighbor_kernel, strides=[1, 1, 1, 1], padding=\'VALID\'))\n            depth_diff = tf.pad(depth_diff, paddings = [[0, 0], [padding, padding], [padding, padding], [0, 0]])\n            max_depth_diff = 0.1\n            depth_boundary = tf.greater(depth_diff, max_depth_diff)\n\n            normal_diff = tf.norm(tf.nn.depthwise_conv2d(global_gt_dict[\'normal\'], tf.tile(neighbor_kernel, [1, 1, 3, 1]), strides=[1, 1, 1, 1], padding=\'VALID\'), axis=3, keep_dims=True)\n            normal_diff = tf.pad(normal_diff, paddings = [[0, 0], [padding, padding], [padding, padding], [0, 0]])\n            max_normal_diff = np.sqrt(2 * (1 - np.cos(np.deg2rad(20))))\n            normal_boundary = tf.greater(normal_diff, max_normal_diff)\n\n            plane_region = tf.nn.max_pool(plane_mask, ksize=[1, kernel_size, kernel_size, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n            segmentation_eroded = 1 - tf.nn.max_pool(1 - segmentation_gt, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n            plane_region -= tf.reduce_max(segmentation_eroded, axis=3, keep_dims=True)\n            boundary = tf.cast(tf.logical_or(depth_boundary, normal_boundary), tf.float32) * plane_region\n            smooth_boundary = tf.cast(tf.logical_and(normal_boundary, tf.less_equal(depth_diff, max_depth_diff)), tf.float32) * plane_region\n            boundary_gt = tf.concat([smooth_boundary, boundary - smooth_boundary], axis=3)\n            pass\n\n\n        if options.boundaryLoss == 1:\n            all_segmentations_pred = all_segmentations_softmax\n            all_segmentations_min = 1 - tf.nn.max_pool(1 - all_segmentations_pred, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\')\n            segmentation_diff = tf.reduce_max(all_segmentations_pred - all_segmentations_min, axis=3, keep_dims=True)\n\n            depth_pred = tf.reduce_sum(tf.multiply(all_depths, all_segmentations_pred), axis=3, keep_dims=True)\n            depth_neighbor = tf.nn.depthwise_conv2d(depth_pred, neighbor_kernel, strides=[1, 1, 1, 1], padding=\'SAME\')\n            minDepthDiff = 0.02\n            depth_diff = tf.clip_by_value(tf.squared_difference(depth_pred, depth_neighbor) - pow(minDepthDiff, 2), 0, 1)\n\n            boundary = tf.reduce_max(boundary_gt, axis=3, keep_dims=True)\n            smooth_boundary = tf.slice(boundary_gt, [0, 0, 0, 0], [options.batchSize, HEIGHT, WIDTH, 1])\n            smooth_mask = segmentation_diff + boundary - 2 * segmentation_diff * boundary + depth_diff * smooth_boundary\n            margin = 0.0\n            smooth_mask = tf.nn.relu(smooth_mask - margin)\n            boundary_loss += tf.reduce_mean(smooth_mask * plane_mask) * 1000            \n            pass\n        elif options.boundaryLoss == 2:\n            all_segmentations_pred = all_segmentations_softmax\n            all_segmentations_min = 1 - tf.nn.max_pool(1 - all_segmentations_pred, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\')\n            segmentation_diff = tf.reduce_max(all_segmentations_pred - all_segmentations_min, axis=3, keep_dims=True)\n\n            depth_pred = tf.reduce_sum(tf.multiply(all_depths, all_segmentations_pred), axis=3, keep_dims=True)\n            depth_neighbor = tf.nn.depthwise_conv2d(depth_pred, neighbor_kernel, strides=[1, 1, 1, 1], padding=\'SAME\')\n            minDepthDiff = 0.02\n            depth_diff = tf.clip_by_value(tf.squared_difference(depth_pred, depth_neighbor) - pow(minDepthDiff, 2), 0, 1)\n\n            boundary = tf.reduce_max(boundary_gt, axis=3, keep_dims=True)\n            #smooth_boundary = tf.slice(boundary_gt, [0, 0, 0, 0], [options.batchSize, HEIGHT, WIDTH, 1])\n            occlusion_boundary = tf.slice(boundary_gt, [0, 0, 0, 1], [options.batchSize, HEIGHT, WIDTH, 1])\n            smooth_mask = segmentation_diff + boundary - 2 * segmentation_diff * boundary + depth_diff * (boundary - occlusion_boundary)\n            margin = 0.0\n            smooth_mask = tf.nn.relu(smooth_mask - margin)\n            boundary_loss += tf.reduce_mean(smooth_mask) * 1000            \n            pass\n          \n        if options.predictBoundary:\n            #we predict boundaries directly for post-processing purpose\n            boundary_loss += tf.reduce_mean(tf.losses.sigmoid_cross_entropy(logits=global_pred_dict[\'boundary\'], multi_class_labels=boundary_gt, weights=tf.maximum(global_gt_dict[\'boundary\'] * 3, 1))) * 1000\n\n          \n        #regularization\n        l2_losses = tf.add_n([options.l2Weight * tf.nn.l2_loss(v) for v in tf.trainable_variables() if \'weights\' in v.name])\n\n\n        loss = plane_loss + segmentation_loss + depth_loss + normal_loss + plane_confidence_loss + diverse_loss + boundary_loss + local_score_loss + local_plane_loss + local_mask_loss + l2_losses\n\n        #if options.pixelwiseLoss:\n        #normal_loss = tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_normal\'], global_gt_dict[\'normal\'])) * 1000\n        #depth_loss = tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_depth\'], global_gt_dict[\'depth\']) * validDepthMask) * 1000\n        #pass\n\n        loss_dict = {\'plane\': plane_loss, \'segmentation\': segmentation_loss, \'depth\': depth_loss, \'normal\': normal_loss, \'boundary\': boundary_loss, \'diverse\': diverse_loss, \'confidence\': plane_confidence_loss, \'local_score\': local_score_loss, \'local_plane\': local_plane_loss, \'local_mask\': local_mask_loss}\n        debug_dict = {\'segmentation\': segmentation_gt, \'boundary\': boundary_gt}\n        pass\n    return loss, loss_dict, debug_dict\n    #return loss, plane_loss, depth_loss + local_score_loss + local_p_loss + local_mask_loss + boundary_loss, forward_loss, backward_loss, segmentation_gt, plane_mask, errorMask, dists\n    #return loss, plane_loss, segmentation_loss, loss_p_0, depth_loss, segmentation_test, plane_mask, errorMask, dists\n\n\ndef main(options):\n    if not os.path.exists(options.checkpoint_dir):\n        os.system(""mkdir -p %s""%options.checkpoint_dir)\n        pass\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n    \n    min_after_dequeue = 1000\n\n    reader_train = RecordReader()\n    filename_queue_train = tf.train.string_input_producer([\'/mnt/vision/SUNCG_plane/planes_test_450000.tfrecords\'], num_epochs=10000)\n    img_inp_train, global_gt_dict_train, local_gt_dict_train = reader_train.getBatch(filename_queue_train, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True, random=False)\n\n    reader_val = RecordReader()\n    filename_queue_val = tf.train.string_input_producer([\'/home/chenliu/Projects/Data/SUNCG_plane/planes_test_1000_450000.tfrecords\'], num_epochs=10000)\n    img_inp_val, global_gt_dict_val, local_gt_dict_val = reader_val.getBatch(filename_queue_val, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True)\n\n    reader_rgbd_train = RecordReaderRGBD()\n    filename_queue_rgbd_train = tf.train.string_input_producer([\'../planes_nyu_rgbd_train.tfrecords\'], num_epochs=10000)\n    img_inp_rgbd_train, global_gt_dict_rgbd_train, local_gt_dict_rgbd_train = reader_rgbd_train.getBatch(filename_queue_rgbd_train, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True)\n\n    reader_rgbd_val = RecordReaderRGBD()\n    filename_queue_rgbd_val = tf.train.string_input_producer([\'../planes_nyu_rgbd_val.tfrecords\'], num_epochs=10000)\n    img_inp_rgbd_val, global_gt_dict_rgbd_val, local_gt_dict_rgbd_val = reader_rgbd_val.getBatch(filename_queue_rgbd_val, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True)\n\n    \n    training_flag = tf.placeholder(tf.int32, shape=[], name=\'training_flag\')\n    \n    global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp_train, img_inp_val, img_inp_rgbd_train, img_inp_rgbd_val, training_flag, options)\n\n    var_to_restore = [v for v in tf.global_variables()]\n\n    \n    loss, loss_dict, _ = build_loss(global_pred_dict, local_pred_dict, deep_pred_dicts, global_gt_dict_train, local_gt_dict_train, global_gt_dict_val, local_gt_dict_val, training_flag, options)\n    loss_rgbd, loss_dict_rgbd, _ = build_loss_rgbd(global_pred_dict, local_pred_dict, deep_pred_dicts, global_gt_dict_rgbd_train, local_gt_dict_rgbd_train, global_gt_dict_rgbd_val, local_gt_dict_rgbd_val, training_flag, options)\n    \n    loss = tf.cond(tf.less(training_flag, 2), lambda: loss, lambda: loss_rgbd)\n\n    \n    train_writer = tf.summary.FileWriter(options.log_dir + \'/train\')\n    val_writer = tf.summary.FileWriter(options.log_dir + \'/val\')\n    train_writer_rgbd = tf.summary.FileWriter(options.log_dir + \'/train_rgbd\')\n    val_writer_rgbd = tf.summary.FileWriter(options.log_dir + \'/val_rgbd\')\n    writers = [train_writer, val_writer, train_writer_rgbd, val_writer_rgbd]\n    \n    tf.summary.scalar(\'loss\', loss)\n    summary_op = tf.summary.merge_all()\n\n    with tf.variable_scope(\'statistics\'):\n        batchno = tf.Variable(0, dtype=tf.int32, trainable=False, name=\'batchno\')\n        batchnoinc=batchno.assign(batchno+1)\n        pass\n\n\n    optimizer = tf.train.AdamOptimizer(options.LR)\n    train_op = optimizer.minimize(loss, global_step=batchno)\n\n    \n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n    saver=tf.train.Saver()\n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n        if options.restore == 0:\n            #fine-tune from DeepLab model\n            var_to_restore = [v for v in var_to_restore if \'res5d\' not in v.name and \'segmentation\' not in v.name and \'plane\' not in v.name and \'deep_supervision\' not in v.name and \'local\' not in v.name and \'boundary\' not in v.name and \'degridding\' not in v.name and \'res2a_branch2a\' not in v.name and \'res2a_branch1\' not in v.name]\n            pretrained_model_loader = tf.train.Saver(var_to_restore)\n            pretrained_model_loader.restore(sess,""../pretrained_models/deeplab_resnet.ckpt"")\n        elif options.restore == 1:\n            #restore the same model from checkpoint\n            loader = tf.train.Saver(var_to_restore)\n            loader.restore(sess,""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n            bno=sess.run(batchno)\n            print(bno)\n        elif options.restore == 2:            \n            #restore the same model from checkpoint but reset batchno to 1\n            loader = tf.train.Saver(var_to_restore)\n            loader.restore(sess,""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n            sess.run(batchno.assign(1))\n        elif options.restore == 3:            \n            #restore the same model from standard training\n            if options.predictBoundary == 1:\n                var_to_restore = [v for v in var_to_restore if \'boundary\' not in v.name]\n                pass            \n            if options.predictConfidence == 1:\n                var_to_restore = [v for v in var_to_restore if \'confidence\' not in v.name]\n                pass\n            loader = tf.train.Saver(var_to_restore)\n            loader.restore(sess,""checkpoint/planenet/checkpoint.ckpt"")\n            sess.run(batchno.assign(1))\n        elif options.restore == 4:\n            #fine-tune another model\n            var_to_restore = [v for v in var_to_restore if \'res4b22_relu_non_plane\' not in v.name]\n            loader = tf.train.Saver(var_to_restore)\n            loader.restore(sess, options.fineTuningCheckpoint)\n            sess.run(batchno.assign(1))\n            pass\n        # Start input enqueue threads.\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n        MOVING_AVERAGE_DECAY = 0.99\n        ema = [0., 0., 0., 0.]\n        ema_acc = [1e-10, 1e-10, 1e-10, 1e-10]\n        last_snapshot_time = time.time()\n        bno=sess.run(batchno)\n\n        try:\n            while bno<300000:\n                t0 = time.time()\n\n                batchIndexPeriod = bno % 100\n                if batchIndexPeriod == 0:\n                    batchType = 1\n                elif batchIndexPeriod == 1:\n                    if options.hybrid == 0:\n                        batchType = 1\n                    else:\n                        batchType = 3\n                        pass\n                elif batchIndexPeriod % 10 == 0:\n                    if options.hybrid == 0:\n                        batchType = 0\n                    else:\n                        batchType = 2\n                        pass\n                else:\n                    batchType = 0\n                    pass\n\n\n                _, total_loss, losses, losses_rgbd, summary_str = sess.run([train_op, loss, loss_dict, loss_dict_rgbd, summary_op], feed_dict = {training_flag: batchType})\n                writers[batchType].add_summary(summary_str, bno)\n                ema[batchType] = ema[batchType] * MOVING_AVERAGE_DECAY + total_loss\n                ema_acc[batchType] = ema_acc[batchType] * MOVING_AVERAGE_DECAY + 1\n\n                bno = sess.run(batchno)\n                if time.time()-last_snapshot_time > 900:\n                    print(\'save snapshot\')\n                    saver.save(sess,\'%s/checkpoint.ckpt\'%options.checkpoint_dir)\n                    last_snapshot_time = time.time()\n                    pass\n        \n                print bno,\'train\', ema[0] / ema_acc[0], \'val\', ema[1] / ema_acc[1], \'train rgbd\', ema[2] / ema_acc[2], \'val rgbd\', ema[3] / ema_acc[3], \'loss\', total_loss, \'time\', time.time()-t0\n\n                if np.random.random() < 0.01:\n                    if batchType < 2:\n                        print(losses)\n                    else:\n                        print(losses_rgbd)\n                        pass\n                    pass                \n                continue\n\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n        \n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return\n\n\ndef test(options):\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n    \n    options.batchSize = 1\n    min_after_dequeue = 1000\n\n    if options.dataset == \'SUNCG\':\n        reader = RecordReader()\n        filename_queue = tf.train.string_input_producer([\'/home/chenliu/Projects/Data/SUNCG_plane/planes_test_1000_450000.tfrecords\'], num_epochs=10000)\n        img_inp, global_gt_dict, local_gt_dict = reader.getBatch(filename_queue, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True, random=False)\n    else:\n        reader = RecordReaderRGBD()\n        filename_queue = tf.train.string_input_producer([\'../planes_nyu_rgbd_val.tfrecords\'], num_epochs=1)\n        img_inp, global_gt_dict, local_gt_dict = reader.getBatch(filename_queue, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True, random=False)\n\n        options.deepSupervision = 0\n        options.predictLocal = 0\n        pass\n\n    training_flag = tf.constant(1, tf.int32)\n\n    global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp, img_inp, img_inp, img_inp, training_flag, options)\n    var_to_restore = tf.global_variables()\n\n    if options.dataset == \'SUNCG\':\n        loss, loss_dict, debug_dict = build_loss(global_pred_dict, local_pred_dict, deep_pred_dicts, global_gt_dict, local_gt_dict, global_gt_dict, local_gt_dict, training_flag, options)\n    else:\n        loss, loss_dict, debug_dict = build_loss_rgbd(global_pred_dict, local_pred_dict, deep_pred_dicts, global_gt_dict, local_gt_dict, global_gt_dict, local_gt_dict, training_flag, options)\n        pass\n\n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n    \n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n        #var_to_restore = [v for v in var_to_restore if \'res4b22_relu_non_plane\' not in v.name]\n        loader = tf.train.Saver(var_to_restore)\n        loader.restore(sess, ""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n        #loader.restore(sess, options.fineTuningCheckpoint)\n        \n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n        \n        \n        try:\n            gtDepths = []\n            predDepths = []\n            planeMasks = []\n            #predMasks = []\n            \n            imageWidth = WIDTH\n            imageHeight = HEIGHT\n            focalLength = 517.97\n            urange = np.arange(imageWidth).reshape(1, -1).repeat(imageHeight, 0) - imageWidth * 0.5\n            vrange = np.arange(imageHeight).reshape(-1, 1).repeat(imageWidth, 1) - imageHeight * 0.5\n            ranges = np.array([urange / imageWidth * 640 / focalLength, np.ones(urange.shape), -vrange / imageHeight * 480 / focalLength]).transpose([1, 2, 0])\n\n\n            for index in xrange(10):\n                print((\'image\', index))\n                t0=time.time()\n\n                img, global_gt, local_gt, global_pred, local_pred, deep_preds, total_loss, losses, debug = sess.run([img_inp, global_gt_dict, local_gt_dict, global_pred_dict, local_pred_dict, deep_pred_dicts, loss, loss_dict, debug_dict])\n                if False:\n                    image = ((img[0] + 0.5) * 255).astype(np.uint8)\n                    depth = global_pred[\'non_plane_depth\'].squeeze()\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', image)\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth.png\', drawDepthImage(depth))\n                    planes, planeSegmentation, depthPred = fitPlanes(depth, numPlanes=20)\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(planeSegmentation))\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(depthPred))\n\n                    gtDepths.append(global_gt[\'depth\'].squeeze())\n                    predDepths.append(depthPred)\n                    planeMasks.append((planeSegmentation < 20).astype(np.float32))\n                    continue        \n                print((losses[\'plane\'], losses[\'segmentation\'], losses[\'depth\']))\n                if index >= 10:\n                    continue\n                  \n                im = img[0]\n                image = ((im + 0.5) * 255).astype(np.uint8)                \n\n                gt_d = global_gt[\'depth\'].squeeze()\n                \n                if \'normal\' in global_gt:\n                    gt_n = global_gt[\'normal\'][0]\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal.png\', drawNormalImage(gt_n))\n                    pass\n                  \n\n                if options.predictLocal:\n                    pred_local_s = 1 / (1 + np.exp(-local_pred[\'score\'][0]))\n                    pred_local_p = local_pred[\'plane\'][0]\n                    pred_local_m = local_pred[\'mask\'][0]\n                  \n                    gt_local_s = local_gt[\'score\'][0]\n                    gt_local_m = local_gt[\'mask\'][0]\n\n                    #visualize local plane prediction\n                    stride = 8\n                    boxSize = 64\n                    xs = np.arange(WIDTH / stride) * stride + stride / 2\n                    ys = np.arange(HEIGHT / stride) * stride + stride / 2\n                    padding = boxSize / 2 + 1\n                    maskImage = np.zeros((HEIGHT + padding * 2, WIDTH + padding * 2, 3), dtype=np.uint8)\n                    maskImage[padding:padding + HEIGHT, padding:padding + WIDTH, :] = image / 2\n                    for gridY, y in enumerate(ys):\n                        for gridX, x in enumerate(xs):\n                            score = pred_local_s[gridY][gridX]\n                            if score < 0.5:\n                                continue                              \n                            mask = pred_local_m[gridY][gridX].reshape([16, 16])        \n                            mask = cv2.resize(mask, (boxSize, boxSize))\n                            maskImage[y - boxSize / 2 + padding:y + boxSize / 2 + padding, x - boxSize / 2 + padding:x + boxSize / 2 + padding, 0][mask > 0.5] = 255\n                            continue\n                        continue\n                    for gridY, y in enumerate(ys):\n                        for gridX, x in enumerate(xs):\n                            score = gt_local_s[gridY][gridX]\n                            if score < 0.5:\n                                continue                              \n                            mask = gt_local_m[gridY][gridX].reshape([16, 16])        \n                            mask = cv2.resize(mask, (boxSize, boxSize))\n                            maskImage[y - boxSize / 2 + padding:y + boxSize / 2 + padding, x - boxSize / 2 + padding:x + boxSize / 2 + padding, 2][mask > 0.5] = 255\n                            continue\n                        continue\n                    pass\n\n                pred_p = global_pred[\'plane\'][0]\n                pred_s = global_pred[\'segmentation\'][0]\n\n                pred_np_m = global_pred[\'non_plane_mask\'][0]\n                pred_np_d = global_pred[\'non_plane_depth\'][0]\n                pred_np_n = global_pred[\'non_plane_normal\'][0]\n                \n                if \'plane_mask\' in debug:\n                    planeMask = np.squeeze(debug[\'plane_mask\'])\n                else:\n                    #planeMask = np.ones((HEIGHT, WIDTH))\n                    planeMask = (np.max(pred_s, axis=2) > pred_np_m.squeeze()).astype(np.float32)\n                    pass\n                \n                if \'segmentation\' in global_gt:\n                    gt_s = global_gt[\'segmentation\'][0]\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_gt.png\', drawSegmentationImage(gt_s, planeMask=planeMask, numColors = 51))\n                    pass\n                  \n\n\n                if options.predictConfidence:\n                    pred_p_c = global_pred[\'confidence\'][0]\n                    pred_p_c = 1 / (1 + np.exp(-pred_p_c))\n                    numPlanes = global_gt[\'num_planes\'][0]\n                    print((numPlanes, (pred_p_c > 0.5).sum()))\n                    pass\n                  \n                if False:\n                    #dump results for post processing\n                    if index >= 10:\n                        break\n                    np.save(options.dump_dir + \'/planes_\' + str(index) + \'.npy\', pred_p)\n                    np.save(options.dump_dir + \'/segmentations_\' + str(index) + \'.npy\', pred_s)\n                    np.save(options.dump_dir + \'/segmentations_gt_\' + str(index) + \'.npy\', gt_s)\n                    np.save(options.dump_dir + \'/non_plane_depth_\' + str(index) + \'.npy\', pred_np_d)\n                    np.save(options.dump_dir + \'/non_plane_segmentation_\' + str(index) + \'.npy\', pred_np_m)\n                    boundary = pred_boundary[0]\n                    boundary = 1 / (1 + np.exp(-boundary))\n                    boundary = np.concatenate([boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)                    \n                    cv2.imwrite(options.dump_dir + \'/boundary_\' + str(index) + \'.png\', drawMaskImage(boundary))\n                    cv2.imwrite(options.dump_dir + \'/image_\' + str(index) + \'.png\', cv2.resize(image, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR))\n                    np.save(options.dump_dir + \'/depth_\' + str(index) + \'.npy\', gt_d)\n                    continue                \n\n                  \n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', image)\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth.png\', drawDepthImage(gt_d))\n\n                if options.predictBoundary:\n                    pred_boundary = global_pred[\'boundary\'][0]\n                    pred_boundary = 1 / (1 + np.exp(-pred_boundary))\n                    boundary = np.concatenate([pred_boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_boundary_pred.png\', drawMaskImage(boundary))\n                    pass\n\n                if \'boundary\' in debug:\n                    gt_boundary = debug[\'boundary\'][0]\n                    boundary = np.concatenate([gt_boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)                \n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_boundary_gt.png\', drawMaskImage(boundary))\n                    pass\n\n\n                if options.deepSupervision >= 1:\n                    segmentation_deep = np.argmax(deep_preds[0][\'segmentation\'][0], 2)\n                    segmentation_deep[segmentation_deep == options.numOutputPlanes] = -1\n                    segmentation_deep += 1\n                \n                    plane_depths_deep = calcPlaneDepths(deep_preds[0][\'plane\'][0], WIDTH, HEIGHT)\n                    all_depths_deep = np.concatenate([pred_np_d, plane_depths_deep], axis=2)\n                    pred_d_deep = all_depths_deep.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation_deep.reshape(-1)].reshape(HEIGHT, WIDTH)\n                \n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred_0.png\', drawSegmentationImage(deep_preds[0][\'segmentation\'][0]))\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred_0.png\', drawDepthImage(pred_d_deep))\n                    pass\n\n\n                #print(pred_np_m)\n                #print(pred_s)\n                #print(global_gt[\'plane\'][0])\n                #print(pred_p)\n                #exit(1)                \n                all_segmentations = np.concatenate([pred_np_m, pred_s], axis=2)\n                plane_depths = calcPlaneDepths(pred_p, WIDTH, HEIGHT)\n                all_depths = np.concatenate([pred_np_d, plane_depths], axis=2)\n\n\n                segmentation = np.argmax(all_segmentations, 2)\n                pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape(HEIGHT, WIDTH)\n \n                \n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(all_segmentations, black=True))\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))                \n\n                gtDepths.append(gt_d)\n                planeMasks.append(planeMask)\n                predDepths.append(pred_d)\n                evaluateDepths(predDepths[-1], gtDepths[-1], np.ones(planeMasks[-1].shape), planeMasks[-1])\n                \n                #print(np.concatenate([np.arange(options.numOutputPlanes).reshape(-1, 1), planes, pred_p, preds_p[0][0]], axis=1))\n\n                #print(np.concatenate([distance[0], preds_p[0][0], pred_p], axis=1))\n                            \n                #segmentation = np.argmax(pred_s, 2)\n                #writePLYFile(options.test_dir, index, image, pred_d, segmentation, np.zeros(pred_boundary[0].shape))\n                #writePLYFileParts(options.test_dir, index, image, pred_d, segmentation)\n                #gt_s_ori = gt_s_ori[0]\n                #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_gt_ori.png\', drawSegmentationImage(gt_s_ori, planeMask=np.max(gt_s_ori, 2) > 0.5, numColors=51))\n                \n                if False:\n                    #distance = distance[0]\n                    print(distance)\n                    diff = np.linalg.norm(np.expand_dims(planes, 1) - np.expand_dims(pred_p, 0), axis=2)\n                    print(np.concatenate([planes, pred_p, pow(np.min(diff, axis=1, keepdims=True), 2), np.expand_dims(np.argmin(diff, axis=1), -1)], axis=1))\n                    print(pred_p_c)\n                    \n                    #print(distance[:, 6:8].sum(0))\n                    #print(pow(np.linalg.norm(distance[:, :3] - distance[:, 3:6], 2, 1), 2) * 100)\n                    #print(test)\n                    segmentation = np.argmax(all_segmentations, 2) - 1\n                    for planeIndex in xrange(options.numOutputPlanes):\n                        cv2.imwrite(options.test_dir + \'/segmentation_\' + str(planeIndex) + \'.png\', drawMaskImage(segmentation == planeIndex))\n                        cv2.imwrite(options.test_dir + \'/segmentation_\' + str(planeIndex) + \'_gt.png\', drawMaskImage(gt_s[:, :, planeIndex]))\n                        cv2.imwrite(options.test_dir + \'/segmentation_\' + str(planeIndex) + \'_gt_ori.png\', drawMaskImage(gt_s_ori[:, :, planeIndex]))\n                        continue\n                    exit(1)\n                continue\n\n            predDepths = np.array(predDepths)\n            gtDepths = np.array(gtDepths)\n            planeMasks = np.array(planeMasks)\n            #predMasks = np.array(predMasks)\n            evaluateDepths(predDepths, gtDepths, np.ones(planeMasks.shape, dtype=np.bool), planeMasks)\n            exit(1)\n\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n        \n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return\n\n\ndef predict(options):\n    options.test_dir += \'_predict\'\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n\n    batchSize = 1\n    img_inp = tf.placeholder(tf.float32,shape=(batchSize,HEIGHT,WIDTH,3),name=\'img_inp\')\n    plane_gt=tf.placeholder(tf.float32,shape=(batchSize,options.numOutputPlanes, 3),name=\'plane_inp\')\n    validating_inp = tf.constant(0, tf.int32)\n\n    global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp_train, img_inp_val, img_inp_rgbd_train, img_inp_rgbd_val, training_flag, options)\n\n    var_to_restore = tf.global_variables()\n    \n \n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n\n\n    if dataset == \'SUNCG\':\n        image_list_file = os.path.join(\'../PythonScripts/SUNCG/image_list_100_tail_500000.txt\')\n        with open(image_list_file) as f:\n            im_names = [{\'image\': im_name.strip().replace(\'plane_global.npy\', \'mlt.png\'), \'depth\': im_name.strip().replace(\'plane_global.npy\', \'depth.png\'), \'normal\': im_name.strip().replace(\'plane_global.npy\', \'norm_camera.png\'), \'valid\': im_name.strip().replace(\'plane_global.npy\', \'valid.png\'), \'plane\': im_name.strip()} for im_name in f.readlines()]\n            pass\n    else:\n        im_names = glob.glob(\'../../Data/NYU_RGBD/*_color.png\')\n        im_names = [{\'image\': im_name, \'depth\': im_name.replace(\'color.png\', \'depth.png\'), \'normal\': im_name.replace(\'color.png\', \'norm_camera.png\'), \'invalid_mask\': im_name.replace(\'color.png\', \'valid.png\')} for im_name in im_names]\n        pass\n      \n    if numImages > 0:\n        im_names = im_names[:numImages]\n        pass\n\n    #if args.imageIndex > 0:\n    #im_names = im_names[args.imageIndex:args.imageIndex + 1]\n    #pass    \n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n\n    with tf.Session(config=config) as sess:\n        saver = tf.train.Saver()\n        #sess.run(tf.global_variables_initializer())\n        saver.restore(sess,""%s/%s.ckpt""%(options.checkpoint_dir,keyname))\n\n        gtDepths = []\n        predDepths = []\n        segmentationDepths = []\n        predDepthsOneHot = []\n        planeMasks = []\n        predMasks = []\n\n        imageWidth = WIDTH\n        imageHeight = HEIGHT\n        focalLength = 517.97\n        urange = np.arange(imageWidth).reshape(1, -1).repeat(imageHeight, 0) - imageWidth * 0.5\n        vrange = np.arange(imageHeight).reshape(-1, 1).repeat(imageWidth, 1) - imageHeight * 0.5\n        ranges = np.array([urange / focalLength, np.ones(urange.shape), -vrange / focalLength]).transpose([1, 2, 0])\n        \n        cv2.imwrite(options.test_dir + \'/one.png\', np.ones((HEIGHT, WIDTH), dtype=np.uint8) * 255)\n        cv2.imwrite(options.test_dir + \'/zero.png\', np.zeros((HEIGHT, WIDTH), dtype=np.uint8) * 255)\n        for index, im_name in enumerate(im_names):\n            if index <= -1:\n                continue\n            print(im_name[\'image\'])\n            im = cv2.imread(im_name[\'image\'])\n            image = im.astype(np.float32, copy=False)\n            image = image / 255 - 0.5\n            image = cv2.resize(image, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n\n            #planes = np.load(im_name[\'plane\'])\n            # numPlanes = planes.shape[0]\n            # if numPlanes > options.numOutputPlanes:\n            #     planeAreas = planes[:, 3:].sum(1)\n            #     sortInds = np.argsort(planeAreas)[::-1]\n            #     planes = planes[sortInds[:options.numOutputPlanes]]\n            #     pass\n            # gt_p = np.zeros((1, options.numOutputPlanes, 3))\n            # gt_p[0, :numPlanes] = planes[:numPlanes, :3]\n\n            normal = np.array(PIL.Image.open(im_name[\'normal\'])).astype(np.float) / 255 * 2 - 1\n            norm = np.linalg.norm(normal, 2, 2)\n            for c in xrange(3):\n                normal[:, :, c] /= norm\n                continue\n            normal = cv2.resize(normal, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n            \n            depth = np.array(PIL.Image.open(im_name[\'depth\'])).astype(np.float) / 1000\n            depth = cv2.resize(depth, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n\n            invalid_mask = cv2.resize(cv2.imread(im_name[\'invalid_mask\'], 0), (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR) > 128\n\n            gtDepths.append(depth)\n\n            \n            pred_p, pred_d, pred_n, pred_s, pred_np_m, pred_np_d, pred_np_n, pred_boundary, pred_local_score, pred_local_p, pred_local_mask = sess.run([plane_pred, depth_pred, normal_pred, segmentation_pred, non_plane_mask_pred, non_plane_depth_pred, non_plane_normal_pred, boundary_pred, local_score_pred, local_p_pred, local_mask_pred], feed_dict = {img_inp:np.expand_dims(image, 0), plane_gt: np.zeros((batchSize, options.numOutputPlanes, 3))})\n\n\n            pred_s = pred_s[0] \n            pred_p = pred_p[0]\n            pred_np_m = pred_np_m[0]\n            pred_np_d = pred_np_d[0]\n            pred_np_n = pred_np_n[0]\n            #pred_s = 1 / (1 + np.exp(-pred_s))\n\n            plane_depths = calcPlaneDepths(pred_p, WIDTH, HEIGHT)\n            all_depths = np.concatenate([pred_np_d, plane_depths], axis=2)\n\n            all_segmentations = np.concatenate([pred_np_m, pred_s], axis=2)\n            segmentation = np.argmax(all_segmentations, 2)\n            if suffix != \'pixelwise\':\n                pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape(HEIGHT, WIDTH)\n            else:\n                pred_d = np.squeeze(pred_np_d)\n                pass\n            predDepths.append(pred_d)\n            predMasks.append(segmentation != 0)\n            planeMasks.append(invalid_mask)\n\n            #depthError, normalError, occupancy, segmentationTest, reconstructedDepth, occupancyMask = evaluatePlanes(pred_p, im_name[\'image\'])\n            #reconstructedDepth = cv2.resize(reconstructedDepth, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n            \n            #evaluatePlanes(pred_p[0], im_name, options.test_dir, index)\n            #print(pred_p)\n            #print(gt_p)\n            #print((pow(pred_d[0, :, :, 0] - depth, 2) * (gt_s.max(2) > 0.5)).mean())\n            #print((depthError, normalError, occupancy))\n            \n            evaluateDepths(predDepths[index], gtDepths[index], np.ones(planeMasks[index].shape), planeMasks[index])\n\n            if index >= 10:\n                continue\n            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', cv2.resize(im, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR))\n            #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_gt.png\', (minDepth / np.clip(depth, minDepth, 20) * 255).astype(np.uint8))\n            #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', (minDepth / np.clip(pred_d[0, :, :, 0], minDepth, 20) * 255).astype(np.uint8))\n            #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_plane.png\', (minDepth / np.clip(reconstructedDepth, minDepth, 20) * 255).astype(np.uint8))\n\n            pred_boundary = pred_boundary[0]\n            boundary = (1 / (1 + np.exp(-pred_boundary)) * 255).astype(np.uint8)\n            boundary = np.concatenate([boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)\n            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_boundary_pred.png\', boundary)\n            \n            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_inp.png\', drawDepthImage(depth))\n            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n            #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_plane.png\', drawDepthImage(reconstructedDepth))\n            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred_diff.png\', drawDiffImage(pred_d, depth, 0.5))\n            #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_plane_diff.png\', np.minimum(np.abs(reconstructedDepth - depth) / 0.5 * 255, 255).astype(np.uint8))\n            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_inp.png\', drawNormalImage(normal))\n            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_pred.png\', drawNormalImage(pred_np_n))\n            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(all_segmentations, black=True))\n\n            segmentation = np.argmax(pred_s, 2)\n            #writePLYFile(options.test_dir, index, image, pred_p, segmentation)\n\n            if index < 0:\n                for planeIndex in xrange(options.numOutputPlanes):\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_\' + str(planeIndex) + \'.png\', drawMaskImage(pred_s[:, :, planeIndex]))\n                    #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_\' + str(planeIndex) + \'_gt.png\', drawMaskImage(gt_s[:, :, planeIndex]))\n                    continue\n                pass\n            continue\n        predDepths = np.array(predDepths)\n        gtDepths = np.array(gtDepths)\n        planeMasks = np.array(planeMasks)\n        predMasks = np.array(predMasks)\n        #evaluateDepths(predDepths, gtDepths, planeMasks, predMasks)\n        evaluateDepths(predDepths, gtDepths, planeMasks, planeMasks)\n        #exit(1)\n        pass\n    return\n\n\ndef fitPlanesRGBD(options):\n    writeHTMLRGBD(\'../results/RANSAC_RGBD/index.html\', 10)\n    exit(1)\n    if not os.path.exists(options.checkpoint_dir):\n        os.system(""mkdir -p %s""%options.checkpoint_dir)\n        pass\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n    \n    min_after_dequeue = 1000\n\n    reader_rgbd = RecordReaderRGBD()\n    filename_queue_rgbd = tf.train.string_input_producer([\'../planes_nyu_rgbd_train.tfrecords\'], num_epochs=1)\n    img_inp_rgbd, global_gt_dict_rgbd, local_gt_dict_rgbd = reader_rgbd.getBatch(filename_queue_rgbd, numOutputPlanes=options.numOutputPlanes, batchSize=1, min_after_dequeue=min_after_dequeue, getLocal=True)\n\n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n        try:\n            gtDepths = []\n            predDepths = []\n            planeMasks = []\n            for index in xrange(10):\n                image, depth, path = sess.run([img_inp_rgbd, global_gt_dict_rgbd[\'depth\'], global_gt_dict_rgbd[\'path\']])\n                image = ((image[0] + 0.5) * 255).astype(np.uint8)\n                depth = depth.squeeze()\n                \n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', image)\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth.png\', drawDepthImage(depth))\n                #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_mask.png\', drawMaskImage(depth == 0))\n                planes, planeSegmentation, depthPred = fitPlanes(depth, numPlanes=20)                \n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(planeSegmentation))\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(depthPred))\n\n                gtDepths.append(depth)\n                predDepths.append(depthPred)\n                planeMasks.append((planeSegmentation < 20).astype(np.float32))\n                continue\n            predDepths = np.array(predDepths)\n            gtDepths = np.array(gtDepths)\n            planeMasks = np.array(planeMasks)\n            evaluateDepths(predDepths, gtDepths, np.ones(planeMasks.shape, dtype=np.bool), planeMasks)            \n        except tf.errors.OutOfRangeError:\n            print(\'done fitting\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n    return\n\ndef parse_args():\n    """"""\n    Parse input arguments\n    """"""\n    parser = argparse.ArgumentParser(description=\'Planenet\')\n    parser.add_argument(\'--gpu\', dest=\'gpu_id\',\n                        help=\'GPU device id to use [0]\',\n                        default=0, type=int)\n    #task: [train, test, predict]\n    parser.add_argument(\'--task\', dest=\'task\',\n                        help=\'task type: [train, test, predict]\',\n                        default=\'train\', type=str)\n    parser.add_argument(\'--restore\', dest=\'restore\',\n                        help=\'how to restore the model\',\n                        default=0, type=int)\n    parser.add_argument(\'--numOutputPlanes\', dest=\'numOutputPlanes\',\n                        help=\'the number of output planes\',\n                        default=20, type=int)\n    parser.add_argument(\'--batchSize\', dest=\'batchSize\',\n                        help=\'batch size\',\n                        default=16, type=int)\n    parser.add_argument(\'--dataset\', dest=\'dataset\',\n                        help=\'dataset name for test/predict\',\n                        default=\'SUNCG\', type=str)\n    parser.add_argument(\'--numImages\', dest=\'numImages\',\n                        help=\'the number of images to test/predict\',\n                        default=100, type=int)\n    parser.add_argument(\'--boundaryLoss\', dest=\'boundaryLoss\',\n                        help=\'use boundary loss: [0, 1]\',\n                        default=1, type=int)\n    parser.add_argument(\'--diverseLoss\', dest=\'diverseLoss\',\n                        help=\'use diverse loss: [0, 1]\',\n                        default=1, type=int)\n    parser.add_argument(\'--deepSupervision\', dest=\'deepSupervision\',\n                        help=\'deep supervision level: [0, 1, 2]\',\n                        default=1, type=int)\n    parser.add_argument(\'--sameMatching\', dest=\'sameMatching\',\n                        help=\'use the matching for all deep supervision layers and the final prediction: [0, 1]\',\n                        default=1, type=int)    \n    parser.add_argument(\'--crf\', dest=\'crf\',\n                        help=\'the number of CRF iterations\',\n                        default=0, type=int)\n    parser.add_argument(\'--backwardLossWeight\', dest=\'backwardLossWeight\',\n                        help=\'backward matching loss\',\n                        default=0, type=float)\n    parser.add_argument(\'--predictBoundary\', dest=\'predictBoundary\',\n                        help=\'whether predict boundary or not: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--predictLocal\', dest=\'predictLocal\',\n                        help=\'whether predict local planes or not: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--predictConfidence\', dest=\'predictConfidence\',\n                        help=\'whether predict plane confidence or not: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--predictPixelwise\', dest=\'predictPixelwise\',\n                        help=\'whether predict pixelwise depth or not: [0, 1]\',\n                        default=0, type=int)    \n    parser.add_argument(\'--fineTuningCheckpoint\', dest=\'fineTuningCheckpoint\',\n                        help=\'specify the model for fine-tuning\',\n                        default=\'../PlaneSetGeneration/dump_planenet_diverse/train_planenet_diverse.ckpt\', type=str)\n    parser.add_argument(\'--suffix\', dest=\'suffix\',\n                        help=\'add a suffix to keyname to distinguish experiments\',\n                        default=\'\', type=str)\n    parser.add_argument(\'--l2Weight\', dest=\'l2Weight\',\n                        help=\'L2 regulation weight\',\n                        default=5e-4, type=float)\n    parser.add_argument(\'--LR\', dest=\'LR\',\n                        help=\'learning rate\',\n                        default=3e-5, type=float)\n    parser.add_argument(\'--hybrid\', dest=\'hybrid\',\n                        help=\'hybrid training\',\n                        default=0, type=int)\n    \n\n    args = parser.parse_args()\n    args.keyname = os.path.basename(__file__).rstrip(\'.py\')\n    args.keyname = args.keyname.replace(\'train_\', \'\')\n\n    if args.numOutputPlanes != 20:\n        args.keyname += \'_np\' + str(args.numOutputPlanes)\n        pass\n    if args.boundaryLoss != 1:\n        args.keyname += \'_bl\' + str(args.boundaryLoss)\n        pass\n    if args.diverseLoss == 0:\n        args.keyname += \'_dl0\'\n        pass\n    if args.deepSupervision != 1:\n        args.keyname += \'_ds\' + str(args.deepSupervision)\n        pass\n    if args.crf > 0:\n        args.keyname += \'_crf\' + str(args.crf)\n        pass\n    if args.backwardLossWeight > 0:\n        args.keyname += \'_bw\'\n        pass    \n    if args.predictBoundary == 1:\n        args.keyname += \'_pb\'\n        pass\n    if args.predictLocal == 1:\n        args.keyname += \'_pl\'\n        pass\n    if args.predictConfidence == 1:\n        args.keyname += \'_pc\'\n        pass    \n    if args.predictPixelwise == 1:\n        args.keyname += \'_pp\'\n        pass    \n    if args.sameMatching == 0:\n        args.keyname += \'_sm0\'\n        pass\n    if args.hybrid > 0:\n        args.keyname += \'_hybrid\' + str(args.hybrid)\n        pass\n    \n    args.checkpoint_dir = \'checkpoint/\' + args.keyname\n    args.log_dir = \'log/\' + args.keyname\n    args.test_dir = \'test/\' + args.keyname + \'_\' + args.dataset\n    args.predict_dir = \'predict/\' + args.keyname + \'_\' + args.dataset\n    args.dump_dir = \'dump/\' + args.keyname\n    \n    #layers where deep supervision happens\n    args.deepSupervisionLayers = []\n    if args.deepSupervision >= 1:\n        args.deepSupervisionLayers.append(\'res4b22_relu\')\n        pass\n    if args.deepSupervision >= 2:\n        args.deepSupervisionLayers.append(\'res4b12_relu\')\n        pass\n    return args\n\n\nif __name__==\'__main__\':\n    args = parse_args()\n\n    print ""keyname=%s task=%s started""%(args.keyname, args.task)\n    try:\n        if args.task == ""train"":\n            main(args)\n        elif args.task == ""test"":\n            test(args)\n        elif args.task == ""predict"":\n            predict(args)\n        elif args.task == ""fit"":\n            fitPlanesRGBD(args)\n        else:\n            assert False,""format wrong""\n            pass\n    finally:\n        pass\n\n'"
code/train_planenet_confidence.py,198,"b'import tensorflow as tf\nimport numpy as np\nnp.set_printoptions(precision=2, linewidth=200)\nimport cv2\nimport os\nimport time\nimport sys\nimport tf_nndistance\nimport argparse\nimport glob\nimport PIL\nimport scipy.ndimage as ndimage\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom utils import *\nfrom plane_utils import *\nfrom modules import *\n\n\nfrom planenet import PlaneNet\nfrom RecordReader import *\nfrom RecordReaderRGBD import *\n\n#training_flag: toggle dropout and batch normalization mode\n#it\'s true for training and false for validation, testing, prediction\n#it also controls which data batch to use (*_train or *_val)\n\nsg = tf.contrib.bayesflow.stochastic_graph\nst = tf.contrib.bayesflow.stochastic_tensor\n\ndef build_graph(img_inp_train, img_inp_val, img_inp_rgbd_train, img_inp_rgbd_val, training_flag, options):\n    with tf.device(\'/gpu:%d\'%options.gpu_id):\n        img_inp_rgbd = tf.cond(tf.equal(training_flag % 2, 0), lambda: img_inp_rgbd_train, lambda: img_inp_rgbd_val)\n        img_inp = tf.cond(tf.less(training_flag, 2), lambda: tf.cond(tf.equal(training_flag % 2, 0), lambda: img_inp_train, lambda: img_inp_val), lambda: img_inp_rgbd)\n        \n        net = PlaneNet({\'img_inp\': img_inp}, is_training=tf.equal(training_flag % 2, 0), options=options)\n        #net = PlaneNet({\'img_inp\': img_inp}, is_training=tf.equal(0, 0), options=options)\n        #global predictions\n        plane_pred = net.layers[\'plane_pred\']\n\n        segmentation_pred = net.layers[\'segmentation_pred\']\n        non_plane_mask_pred = net.layers[\'non_plane_mask_pred\']\n        non_plane_depth_pred = net.layers[\'non_plane_depth_pred\']\n        non_plane_normal_pred = net.layers[\'non_plane_normal_pred\']\n\n        # if options.predictConfidence:\n        #     plane_sampling = tf.cast(st.StochasticTensor(tf.contrib.distributions.Bernoulli(logits=net.layers[\'plane_confidence_pred\'])), tf.float32)\n        #     plane_pred *= plane_sampling\n        #     segmentation_pred *= tf.reshape(plane_sampling, [options.batchSize, 1, 1, options.numOutputPlanes])\n        #     pass\n\n        \n        global_pred_dict = {\'plane\': plane_pred, \'segmentation\': segmentation_pred, \'non_plane_mask\': non_plane_mask_pred, \'non_plane_depth\': non_plane_depth_pred, \'non_plane_normal\': non_plane_normal_pred}\n\n        if options.predictBoundary:\n            global_pred_dict[\'boundary\'] = net.layers[\'boundary_pred\']\n            pass\n        if options.predictConfidence:\n            global_pred_dict[\'confidence\'] = net.layers[\'plane_confidence_pred\']\n            #global_pred_dict[\'confidence\'] = -tf.ones(net.layers[\'plane_confidence_pred\'].shape) * 1\n            pass\n        \n        \n        #local predictions\n        if options.predictLocal:\n            local_pred_dict = {\'score\': net.layers[\'local_score_pred\'], \'plane\': net.layers[\'local_plane_pred\'], \'mask\': net.layers[\'local_mask_pred\']}\n        else:\n            local_pred_dict = {}\n            pass\n\n        \n        #deep supervision\n        deep_pred_dicts = []\n        for layer in options.deepSupervisionLayers:\n            pred_dict = {\'plane\': net.layers[layer+\'_plane_pred\'], \'segmentation\': net.layers[layer+\'_segmentation_pred\'], \'non_plane_mask\': net.layers[layer+\'_non_plane_mask_pred\']}\n            if options.predictConfidence:\n                pred_dict[\'confidence\'] = net.layers[layer+\'_plane_confidence_pred\']\n                pass\n            deep_pred_dicts.append(pred_dict)\n            continue\n        pass\n    \n    return global_pred_dict, local_pred_dict, deep_pred_dicts\n\n\ndef build_loss_rgbd(global_pred_dict, local_pred_dict, deep_pred_dicts, global_gt_dict_train, local_gt_dict_train, global_gt_dict_val, local_gt_dict_val, training_flag, options):\n    with tf.device(\'/gpu:%d\'%options.gpu_id):\n        global_gt_dict = {}\n        for name in global_gt_dict_train.keys():\n            global_gt_dict[name] = tf.cond(tf.equal(training_flag % 2, 0), lambda: global_gt_dict_train[name], lambda: global_gt_dict_val[name])\n            continue\n        local_gt_dict = {}\n        for name in local_gt_dict_train.keys():\n            local_gt_dict[name] = tf.cond(tf.equal(training_flag % 2, 0), lambda: local_gt_dict_train[name], lambda: local_gt_dict_val[name])\n            continue\n\n        #depth loss\n        plane_parameters = tf.reshape(global_pred_dict[\'plane\'], (-1, 3))\n        plane_depths = planeDepthsModule(plane_parameters, WIDTH, HEIGHT)\n        plane_depths = tf.transpose(tf.reshape(plane_depths, [HEIGHT, WIDTH, -1, options.numOutputPlanes]), [2, 0, 1, 3])\n\n        all_segmentations = tf.concat([global_pred_dict[\'segmentation\'], global_pred_dict[\'non_plane_mask\']], axis=3)\n        all_segmentations_softmax = tf.nn.softmax(all_segmentations)\n        all_depths = tf.concat([plane_depths, global_pred_dict[\'non_plane_depth\']], axis=3)\n        validDepthMask = tf.cast(tf.greater(global_gt_dict[\'depth\'], 1e-4), tf.float32)\n        depth_loss = tf.reduce_mean(tf.reduce_sum(tf.squared_difference(all_depths, global_gt_dict[\'depth\']) * all_segmentations_softmax, axis=3, keep_dims=True) * validDepthMask) * 1000\n\n        if options.predictPixelwise == 1:\n            depth_loss += tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_mask\'], global_gt_dict[\'depth\']) * validDepthMask) * 1000\n            pass\n            \n        #non plane mask loss\n        segmentation_loss = tf.reduce_mean(tf.slice(all_segmentations_softmax, [0, 0, 0, options.numOutputPlanes], [options.batchSize, HEIGHT, WIDTH, 1])) * 100\n\n        boundary_loss = tf.constant(0.0)\n        # #load or calculate boundary ground truth\n        # if False:\n        #     #load from dataset\n        #     boundary_gt = tf.cond(training_flag, lambda: boundary_gt_train, lambda: boundary_gt_val)\n        # else:\n        #     #calculate boundary ground truth on-the-fly as the calculation is subject to change\n        #     global_gt_dict[\'normal\'] = depthToNormalModule(global_gt_dict[\'depth\'])\n\n        #     kernel_size = 3\n        #     padding = (kernel_size - 1) / 2\n        #     neighbor_kernel_array = gaussian(kernel_size, kernel_size)\n        #     neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n        #     neighbor_kernel_array /= neighbor_kernel_array.sum()\n        #     neighbor_kernel_array *= -1\n        #     neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 1\n        #     neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n        #     neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n\n\n        #     kernel_array = np.zeros((3, 3, 1, 4))\n        #     kernel_array[0, 1, 0, 0] = 1\n        #     kernel_array[1, 0, 0, 1] = 1\n        #     kernel_array[2, 1, 0, 2] = 1\n        #     kernel_array[1, 2, 0, 3] = 1\n        #     kernel_array[1, 1, 0, 0] = -1\n        #     kernel_array[1, 1, 0, 1] = -1\n        #     kernel_array[1, 1, 0, 2] = -1\n        #     kernel_array[1, 1, 0, 3] = -1\n        #     kernel = tf.constant(kernel_array.reshape(-1), shape=kernel_array.shape, dtype=tf.float32)\n            \n        #     #depth_diff = tf.abs(tf.nn.depthwise_conv2d(global_gt_dict[\'depth\'], neighbor_kernel, strides=[1, 1, 1, 1], padding=\'VALID\'))\n        #     depth_diff = tf.reduce_max(tf.abs(tf.nn.depthwise_conv2d(global_gt_dict[\'depth\'], kernel, strides=[1, 1, 1, 1], padding=\'VALID\')), axis=3, keep_dims=True)\n        #     depth_diff = tf.pad(depth_diff, paddings = [[0, 0], [padding, padding], [padding, padding], [0, 0]])\n        #     max_depth_diff = 0.2\n        #     depth_boundary = tf.greater(depth_diff, max_depth_diff)\n\n        #     #normal_diff = tf.norm(tf.nn.depthwise_conv2d(global_gt_dict[\'normal\'], tf.tile(neighbor_kernel, [1, 1, 3, 1]), strides=[1, 1, 1, 1], padding=\'VALID\'), axis=3, keep_dims=True)\n        #     #normal_diff = tf.pad(normal_diff, paddings = [[0, 0], [padding, padding], [padding, padding], [0, 0]])\n        #     normal_diff = tf.nn.depthwise_conv2d(global_gt_dict[\'normal\'], tf.tile(kernel, [1, 1, 3, 1]), strides=[1, 1, 1, 1], padding=\'VALID\')\n        #     normal_diff = tf.pad(normal_diff, paddings = [[0, 0], [padding, padding], [padding, padding], [0, 0]])            \n        #     normal_diff = tf.reduce_max(tf.norm(tf.reshape(normal_diff, [options.batchSize, HEIGHT, WIDTH, 3, -1]), axis=3, keep_dims=False), axis=3, keep_dims=True)\n\n        #     max_normal_diff = np.sqrt(2 * (1 - np.cos(np.deg2rad(30))))\n        #     normal_boundary = tf.greater(normal_diff, max_normal_diff)\n\n        #     boundary = tf.cast(tf.logical_or(depth_boundary, normal_boundary), tf.float32)\n        #     #boundary = tf.cast(normal_boundary, tf.float32)\n        #     smooth_boundary = tf.cast(tf.logical_and(normal_boundary, tf.less_equal(depth_diff, max_depth_diff)), tf.float32)\n        #     boundary_gt = tf.concat([smooth_boundary, boundary - smooth_boundary], axis=3)\n        #     pass\n\n\n        # if options.boundaryLoss == 1:\n        #     all_segmentations_pred = all_segmentations_softmax\n        #     all_segmentations_min = 1 - tf.nn.max_pool(1 - all_segmentations_pred, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\')\n        #     segmentation_diff = tf.reduce_max(all_segmentations_pred - all_segmentations_min, axis=3, keep_dims=True)\n\n        #     depth_pred = tf.reduce_sum(tf.multiply(all_depths, all_segmentations_pred), axis=3, keep_dims=True)\n        #     depth_neighbor = tf.nn.depthwise_conv2d(depth_pred, neighbor_kernel, strides=[1, 1, 1, 1], padding=\'SAME\')\n        #     minDepthDiff = 0.02\n        #     depth_diff = tf.clip_by_value(tf.squared_difference(depth_pred, depth_neighbor) - pow(minDepthDiff, 2), 0, 1)\n\n        #     #boundary = tf.reduce_max(boundary_gt, axis=3, keep_dims=True)\n        #     #smooth_boundary = tf.slice(boundary_gt, [0, 0, 0, 0], [options.batchSize, HEIGHT, WIDTH, 1])\n        #     #smooth_mask = segmentation_diff + boundary - 2 * segmentation_diff * boundary + depth_diff * smooth_boundary\n        #     occlusion_boundary = tf.slice(boundary_gt, [0, 0, 0, 1], [options.batchSize, HEIGHT, WIDTH, 1])\n        #     smooth_mask = tf.clip_by_value(occlusion_boundary - segmentation_diff, 0, 1)\n        #     margin = 0.0\n        #     smooth_mask = tf.nn.relu(smooth_mask - margin)\n        #     boundary_loss += tf.reduce_mean(smooth_mask) * 1000\n        #     pass\n\n        \n        l2_losses = tf.add_n([options.l2Weight * tf.nn.l2_loss(v) for v in tf.trainable_variables() if \'weights\' in v.name])\n        loss = depth_loss + segmentation_loss + boundary_loss + l2_losses\n        loss_dict = {\'depth\': depth_loss, \'plane\': tf.constant(0.0), \'segmentation\': segmentation_loss, \'boundary\': boundary_loss}\n        debug_dict = {}\n\n        #depth_pred = tf.reduce_sum(all_depths * all_segmentations_softmax, axis=3, keep_dims=False)\n        # debug_dict[\'depth\'] = depth_pred\n        # debug_dict[\'normal\'] = global_gt_dict[\'normal\']\n        # debug_dict[\'depth_gt\'] = global_gt_dict[\'depth\']\n        # debug_dict[\'boundary\'] = boundary_gt\n        # debug_dict[\'segmentation\'] = global_pred_dict[\'segmentation\']\n        pass\n    return loss, loss_dict, debug_dict\n\n\ndef build_loss(global_pred_dict, local_pred_dict, deep_pred_dicts, global_gt_dict_train, local_gt_dict_train, global_gt_dict_val, local_gt_dict_val, training_flag, options):\n    \n    with tf.device(\'/gpu:%d\'%options.gpu_id):\n        debug_dict = {}\n        \n        global_gt_dict = {}\n        for name in global_gt_dict_train.keys():\n            global_gt_dict[name] = tf.cond(tf.equal(training_flag % 2, 0), lambda: global_gt_dict_train[name], lambda: global_gt_dict_val[name])\n            continue\n        local_gt_dict = {}\n        for name in local_gt_dict_train.keys():\n            local_gt_dict[name] = tf.cond(tf.equal(training_flag % 2, 0), lambda: local_gt_dict_train[name], lambda: local_gt_dict_val[name])\n            continue\n\n        normalDotThreshold = np.cos(np.deg2rad(5))\n        distanceThreshold = 0.05\n        segmentation_gt, plane_mask = fitPlaneMasksModule(global_gt_dict[\'plane\'], global_gt_dict[\'depth\'], global_gt_dict[\'normal\'], width=WIDTH, height=HEIGHT, normalDotThreshold=normalDotThreshold, distanceThreshold=distanceThreshold, closing=True, one_hot=True)\n        \n        validPlaneMask = tf.cast(tf.less(tf.tile(tf.expand_dims(tf.range(options.numOutputPlanes), 0), [options.batchSize, 1]), tf.expand_dims(global_gt_dict[\'num_planes\'], -1)), tf.float32)        \n\n        \n        backwardLossWeight = options.backwardLossWeight\n        \n\n        #plane loss and segmentation loss (summation over deep supervisions and final supervision)\n        all_pred_dicts = deep_pred_dicts + [global_pred_dict]\n        plane_loss = tf.constant(0.0)\n        segmentation_loss = tf.constant(0.0)\n        plane_confidence_loss = tf.constant(0.0)\n        diverse_loss = tf.constant(0.0)\n        \n        #keep forward map (segmentation gt) from previous supervision so that we can have same matching for all supervisions (options.sameMatching = 1)\n        previous_forward_map = None\n        previous_segmentation_gt = None\n        for pred_index, pred_dict in enumerate(all_pred_dicts):\n            plane_pred = pred_dict[\'plane\']\n            if options.predictConfidence == 1:\n                plane_confidence_loss += tf.reduce_mean(tf.sigmoid(pred_dict[\'confidence\'])) * 10\n\n                plane_sampling = tf.cast(st.StochasticTensor(tf.contrib.distributions.Bernoulli(logits=pred_dict[\'confidence\'])), tf.float32)\n                plane_pred *= plane_sampling\n                pass\n            \n            if options.sameMatching and pred_index > 0 and options.predictConfidence == 0:\n                #use matching from previous supervision and map ground truth planes based on the mapping\n                forward_map = previous_forward_map\n\n                #number of ground truth mapped for each prediction\n                num_matches = tf.transpose(tf.reduce_sum(forward_map, axis=1, keep_dims=True), [0, 2, 1])\n\n                plane_gt_shuffled = tf.transpose(tf.matmul(global_gt_dict[\'plane\'], forward_map, transpose_a=True), [0, 2, 1]) / tf.maximum(num_matches, 1e-4)\n\n                if options.predictConfidence:\n                    plane_sampled_loss = tf.reduce_mean(tf.squared_difference(plane_pred, plane_gt_shuffled), [1, 2])\n                    plane_loss += tf.reduce_mean(sg.surrogate_loss([plane_sampled_loss])) * 10000\n                    #debug_dict[\'plane\'] = plane_pred\n                    #debug_dict[\'loss\'] = plane_sampled_loss\n                    #debug_dict[\'confidence\'] = pred_dict[\'confidence\']                    \n                else:\n                    plane_confidence_gt = tf.cast(num_matches > 0.5, tf.float32)\n                    plane_loss += tf.reduce_mean(tf.squared_difference(pred_dict[\'plane\'], plane_gt_shuffled) * plane_confidence_gt) * 10000\n                    pass\n\n                \n                #all segmentations is the concatenation of plane segmentations and non plane mask\n                segmentation_gt_shuffled = previous_segmentation_gt\n            else:\n                #calculate new matching by finding nearest neighbors again\n                dists_forward, map_forward, dists_backward, _ = tf_nndistance.nn_distance(global_gt_dict[\'plane\'], plane_pred)\n                dists_forward *= validPlaneMask\n\n                if options.predictConfidence == 1:\n                    dists_forward = tf.reduce_mean(dists_forward, axis = [1])\n                    dists_backward = tf.reduce_mean(dists_backward, axis = [1])\n                    plane_sampled_loss = tf.reshape(dists_forward + dists_backward * backwardLossWeight, [options.batchSize])\n                    plane_loss += tf.reduce_mean(sg.surrogate_loss([plane_sampled_loss])) * 10000\n                else:\n                    dists_forward = tf.reduce_mean(dists_forward)\n                    dists_backward = tf.reduce_mean(dists_backward)\n                    plane_loss += (dists_forward + dists_backward * backwardLossWeight) * 10000\n                    pass\n\n\n                forward_map = tf.one_hot(map_forward, depth=options.numOutputPlanes, axis=-1)\n                forward_map *= tf.expand_dims(validPlaneMask, -1)\n\n                previous_forward_map = forward_map\n                \n                segmentation_gt_shuffled = tf.reshape(tf.matmul(tf.reshape(segmentation_gt, [-1, HEIGHT * WIDTH, options.numOutputPlanes]), forward_map), [-1, HEIGHT, WIDTH, options.numOutputPlanes])\n                segmentation_gt_shuffled = tf.concat([segmentation_gt_shuffled, 1 - plane_mask], axis=3)\n                previous_segmentation_gt = segmentation_gt_shuffled\n                \n                pass\n\n            all_segmentations = tf.concat([pred_dict[\'segmentation\'], pred_dict[\'non_plane_mask\']], axis=3)            \n            if options.predictConfidence == 1:\n                sampled_segmentation_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=all_segmentations, labels=segmentation_gt_shuffled), axis=[1, 2])\n                segmentation_loss += tf.reduce_mean(sg.surrogate_loss([sampled_segmentation_loss])) * 1000\n            else:\n                segmentation_loss += tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=all_segmentations, labels=segmentation_gt_shuffled)) * 1000\n                pass\n\n            if options.diverseLoss and options.predictConfidence == 0:\n                plane_diff = tf.reduce_sum(tf.pow(tf.expand_dims(pred_dict[\'plane\'], 1) - tf.expand_dims(pred_dict[\'plane\'], 2), 2), axis=3)\n                plane_diff = tf.matrix_set_diag(plane_diff, tf.ones((options.batchSize, options.numOutputPlanes)))\n                minPlaneDiff = 0.1\n                diverse_loss += tf.reduce_mean(tf.clip_by_value(1 - plane_diff / minPlaneDiff, 0, 1)) * 10000\n                pass\n              \n            continue\n\n\n\n        #depth loss\n        plane_parameters = tf.reshape(global_pred_dict[\'plane\'], (-1, 3))\n        plane_depths = planeDepthsModule(plane_parameters, WIDTH, HEIGHT)\n        plane_depths = tf.transpose(tf.reshape(plane_depths, [HEIGHT, WIDTH, -1, options.numOutputPlanes]), [2, 0, 1, 3])\n\n        if options.predictConfidence == 1:\n            plane_depths *= tf.reshape(plane_sampling, [options.batchSize, 1, 1, options.numOutputPlanes])\n            pass\n        \n        all_segmentations_softmax = tf.nn.softmax(all_segmentations)\n        non_plane_depth = global_pred_dict[\'non_plane_depth\']\n        all_depths = tf.concat([plane_depths, non_plane_depth], axis=3)\n        validDepthMask = tf.cast(tf.greater(global_gt_dict[\'depth\'], 1e-4), tf.float32)\n\n        if options.predictConfidence == 1:\n            sampled_depth_loss= tf.reduce_mean(tf.reduce_sum(tf.squared_difference(all_depths, global_gt_dict[\'depth\']) * all_segmentations_softmax, axis=3, keep_dims=True) * validDepthMask, axis=[1, 2, 3])\n            depth_loss = tf.reduce_mean(sg.surrogate_loss([sampled_depth_loss])) * 1000\n        else:\n            depth_loss = tf.reduce_mean(tf.reduce_sum(tf.squared_difference(all_depths, global_gt_dict[\'depth\']) * all_segmentations_softmax, axis=3, keep_dims=True) * validDepthMask) * 1000\n            pass\n\n\n        if options.predictPixelwise == 1:\n            depth_loss += tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_mask\'], global_gt_dict[\'depth\']) * validDepthMask) * 1000\n            normal_loss = tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_normal\'], global_gt_dict[\'normal\']) * validDepthMask) * 1000\n        else:\n            #normal loss for non-plane region\n            normal_loss = tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_normal\'], global_gt_dict[\'normal\']) * (1 - plane_mask)) * 1000\n            pass\n        \n        #local loss\n        if options.predictLocal:\n            local_score_loss = tf.reduce_mean(tf.losses.sigmoid_cross_entropy(logits=local_pred_dict[\'score\'], multi_class_labels=local_gt_dict[\'score\'], weights=tf.maximum(local_gt_dict[\'score\'] * 10, 1))) * 1000\n            local_plane_loss = tf.reduce_mean(tf.squared_difference(local_pred_dict[\'plane\'], local_gt_dict[\'plane\']) * local_gt_dict[\'score\']) * 10000\n            local_mask_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=local_pred_dict[\'mask\'], labels=local_gt_dict[\'mask\']) * local_gt_dict[\'score\']) * 10000\n        else:\n            local_score_loss = tf.constant(0.0)\n            local_plane_loss = tf.constant(0.0)\n            local_mask_loss = tf.constant(0.0)\n            pass\n        \n        \n        #boundary loss\n        boundary_loss = tf.constant(0.0)\n        #load or calculate boundary ground truth\n        if False:\n            #load from dataset\n            boundary_gt = tf.cond(training_flag, lambda: boundary_gt_train, lambda: boundary_gt_val)\n        else:\n            #calculate boundary ground truth on-the-fly as the calculation is subject to change\n            kernel_size = 3\n            padding = (kernel_size - 1) / 2\n            neighbor_kernel_array = gaussian(kernel_size, kernel_size)\n            neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n            neighbor_kernel_array /= neighbor_kernel_array.sum()\n            neighbor_kernel_array *= -1\n            neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 1\n            neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n            neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n        \n            depth_diff = tf.abs(tf.nn.depthwise_conv2d(global_gt_dict[\'depth\'], neighbor_kernel, strides=[1, 1, 1, 1], padding=\'VALID\'))\n            depth_diff = tf.pad(depth_diff, paddings = [[0, 0], [padding, padding], [padding, padding], [0, 0]])\n            max_depth_diff = 0.1\n            depth_boundary = tf.greater(depth_diff, max_depth_diff)\n\n            normal_diff = tf.norm(tf.nn.depthwise_conv2d(global_gt_dict[\'normal\'], tf.tile(neighbor_kernel, [1, 1, 3, 1]), strides=[1, 1, 1, 1], padding=\'VALID\'), axis=3, keep_dims=True)\n            normal_diff = tf.pad(normal_diff, paddings = [[0, 0], [padding, padding], [padding, padding], [0, 0]])\n            max_normal_diff = np.sqrt(2 * (1 - np.cos(np.deg2rad(20))))\n            normal_boundary = tf.greater(normal_diff, max_normal_diff)\n\n            plane_region = tf.nn.max_pool(plane_mask, ksize=[1, kernel_size, kernel_size, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n            segmentation_eroded = 1 - tf.nn.max_pool(1 - segmentation_gt, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n            plane_region -= tf.reduce_max(segmentation_eroded, axis=3, keep_dims=True)\n            boundary = tf.cast(tf.logical_or(depth_boundary, normal_boundary), tf.float32) * plane_region\n            smooth_boundary = tf.cast(tf.logical_and(normal_boundary, tf.less_equal(depth_diff, max_depth_diff)), tf.float32) * plane_region\n            boundary_gt = tf.concat([smooth_boundary, boundary - smooth_boundary], axis=3)\n            pass\n\n\n        if options.boundaryLoss == 1:\n            all_segmentations_pred = all_segmentations_softmax\n            all_segmentations_min = 1 - tf.nn.max_pool(1 - all_segmentations_pred, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\')\n            segmentation_diff = tf.reduce_max(all_segmentations_pred - all_segmentations_min, axis=3, keep_dims=True)\n\n            depth_pred = tf.reduce_sum(tf.multiply(all_depths, all_segmentations_pred), axis=3, keep_dims=True)\n            depth_neighbor = tf.nn.depthwise_conv2d(depth_pred, neighbor_kernel, strides=[1, 1, 1, 1], padding=\'SAME\')\n            minDepthDiff = 0.02\n            depth_diff = tf.clip_by_value(tf.squared_difference(depth_pred, depth_neighbor) - pow(minDepthDiff, 2), 0, 1)\n\n            boundary = tf.reduce_max(boundary_gt, axis=3, keep_dims=True)\n            smooth_boundary = tf.slice(boundary_gt, [0, 0, 0, 0], [options.batchSize, HEIGHT, WIDTH, 1])\n            smooth_mask = segmentation_diff + boundary - 2 * segmentation_diff * boundary + depth_diff * smooth_boundary\n            margin = 0.0\n            smooth_mask = tf.nn.relu(smooth_mask - margin)\n            boundary_loss += tf.reduce_mean(smooth_mask * plane_mask) * 1000            \n            pass\n        \n          \n        if options.predictBoundary:\n            #we predict boundaries directly for post-processing purpose\n            boundary_loss += tf.reduce_mean(tf.losses.sigmoid_cross_entropy(logits=global_pred_dict[\'boundary\'], multi_class_labels=boundary_gt, weights=tf.maximum(global_gt_dict[\'boundary\'] * 3, 1))) * 1000\n\n          \n        #regularization\n        l2_losses = tf.add_n([options.l2Weight * tf.nn.l2_loss(v) for v in tf.trainable_variables() if \'weights\' in v.name])\n\n\n        loss = plane_loss + segmentation_loss + depth_loss + normal_loss + plane_confidence_loss + diverse_loss + boundary_loss + local_score_loss + local_plane_loss + local_mask_loss + l2_losses\n\n        #if options.pixelwiseLoss:\n        #normal_loss = tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_normal\'], global_gt_dict[\'normal\'])) * 1000\n        #depth_loss = tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_depth\'], global_gt_dict[\'depth\']) * validDepthMask) * 1000\n        #pass\n\n        loss_dict = {\'plane\': plane_loss, \'segmentation\': segmentation_loss, \'depth\': depth_loss, \'normal\': normal_loss, \'boundary\': boundary_loss, \'diverse\': diverse_loss, \'confidence\': plane_confidence_loss, \'local_score\': local_score_loss, \'local_plane\': local_plane_loss, \'local_mask\': local_mask_loss}\n        \n        #debug_dict[\'segmentation\'] = segmentation_gt\n        #debug_dict[\'plane_mask\'] = plane_mask\n        #debug_dict[\'boundary\'] = boundary_gt\n\n        pass\n    return loss, loss_dict, debug_dict\n    #return loss, plane_loss, depth_loss + local_score_loss + local_p_loss + local_mask_loss + boundary_loss, forward_loss, backward_loss, segmentation_gt, plane_mask, errorMask, dists\n    #return loss, plane_loss, segmentation_loss, loss_p_0, depth_loss, segmentation_test, plane_mask, errorMask, dists\n\n\ndef main(options):\n    print(options)\n    if not os.path.exists(options.checkpoint_dir):\n        os.system(""mkdir -p %s""%options.checkpoint_dir)\n        pass\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n    \n    min_after_dequeue = 1000\n\n    reader_train = RecordReader()\n    filename_queue_train = tf.train.string_input_producer([\'/mnt/vision/SUNCG_plane/planes_test_450000.tfrecords\'], num_epochs=10000)\n    img_inp_train, global_gt_dict_train, local_gt_dict_train = reader_train.getBatch(filename_queue_train, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True)\n\n    reader_val = RecordReader()\n    filename_queue_val = tf.train.string_input_producer([\'/home/chenliu/Projects/Data/SUNCG_plane/planes_test_1000_450000.tfrecords\'], num_epochs=10000)\n    img_inp_val, global_gt_dict_val, local_gt_dict_val = reader_val.getBatch(filename_queue_val, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True)\n\n    reader_rgbd_train = RecordReaderRGBD()\n    filename_queue_rgbd_train = tf.train.string_input_producer([\'../planes_nyu_rgbd_train.tfrecords\'], num_epochs=10000)\n    img_inp_rgbd_train, global_gt_dict_rgbd_train, local_gt_dict_rgbd_train = reader_rgbd_train.getBatch(filename_queue_rgbd_train, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue)\n    #img_inp, global_gt_dict, local_gt_dict = reader.getBatch(filename_queue, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True, random=False)\n    \n    reader_rgbd_val = RecordReaderRGBD()\n    filename_queue_rgbd_val = tf.train.string_input_producer([\'../planes_nyu_rgbd_val.tfrecords\'], num_epochs=10000)\n    img_inp_rgbd_val, global_gt_dict_rgbd_val, local_gt_dict_rgbd_val = reader_rgbd_val.getBatch(filename_queue_rgbd_val, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue)\n\n\n    if options.predictConfidence == 1:\n        with st.value_type(st.SampleValue()):\n            training_flag = tf.placeholder(tf.int32, shape=[], name=\'training_flag\')\n    \n            global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp_train, img_inp_val, img_inp_rgbd_train, img_inp_rgbd_val, training_flag, options)\n\n            var_to_restore = [v for v in tf.global_variables()]\n\n    \n            loss, loss_dict, debug_dict = build_loss(global_pred_dict, local_pred_dict, deep_pred_dicts, global_gt_dict_train, local_gt_dict_train, global_gt_dict_val, local_gt_dict_val, training_flag, options)\n            loss_rgbd, loss_dict_rgbd, debug_dict_rgbd = build_loss_rgbd(global_pred_dict, local_pred_dict, deep_pred_dicts, global_gt_dict_rgbd_train, local_gt_dict_rgbd_train, global_gt_dict_rgbd_val, local_gt_dict_rgbd_val, training_flag, options)\n    \n            loss = tf.cond(tf.less(training_flag, 2), lambda: loss, lambda: loss_rgbd)\n            pass\n    else:\n        training_flag = tf.placeholder(tf.int32, shape=[], name=\'training_flag\')\n    \n        global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp_train, img_inp_val, img_inp_rgbd_train, img_inp_rgbd_val, training_flag, options)\n\n        var_to_restore = [v for v in tf.global_variables()]\n    \n        loss, loss_dict, _ = build_loss(global_pred_dict, local_pred_dict, deep_pred_dicts, global_gt_dict_train, local_gt_dict_train, global_gt_dict_val, local_gt_dict_val, training_flag, options)\n        loss_rgbd, loss_dict_rgbd, _ = build_loss_rgbd(global_pred_dict, local_pred_dict, deep_pred_dicts, global_gt_dict_rgbd_train, local_gt_dict_rgbd_train, global_gt_dict_rgbd_val, local_gt_dict_rgbd_val, training_flag, options)\n    \n        loss = tf.cond(tf.less(training_flag, 2), lambda: loss, lambda: loss_rgbd)\n        pass\n\n    \n    # train_writer = tf.summary.FileWriter(options.log_dir + \'/train\')\n    # val_writer = tf.summary.FileWriter(options.log_dir + \'/val\')\n    # train_writer_rgbd = tf.summary.FileWriter(options.log_dir + \'/train_rgbd\')\n    # val_writer_rgbd = tf.summary.FileWriter(options.log_dir + \'/val_rgbd\')\n    # writers = [train_writer, val_writer, train_writer_rgbd, val_writer_rgbd]\n    \n    tf.summary.scalar(\'loss\', loss)\n    summary_op = tf.summary.merge_all()\n\n    with tf.variable_scope(\'statistics\'):\n        batchno = tf.Variable(0, dtype=tf.int32, trainable=False, name=\'batchno\')\n        batchnoinc=batchno.assign(batchno+1)\n        pass\n\n\n    optimizer = tf.train.AdamOptimizer(options.LR)\n    train_op = optimizer.minimize(loss, global_step=batchno)\n\n    \n    config=tf.ConfigProto()\n    #config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n    saver=tf.train.Saver()\n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n        if options.restore == 0:\n            #fine-tune from DeepLab model\n            var_to_restore = [v for v in var_to_restore if \'res5d\' not in v.name and \'segmentation\' not in v.name and \'plane\' not in v.name and \'deep_supervision\' not in v.name and \'local\' not in v.name and \'boundary\' not in v.name and \'degridding\' not in v.name and \'res2a_branch2a\' not in v.name and \'res2a_branch1\' not in v.name]\n            pretrained_model_loader = tf.train.Saver(var_to_restore)\n            pretrained_model_loader.restore(sess,""../pretrained_models/deeplab_resnet.ckpt"")\n        elif options.restore == 1:\n            #restore the same model from checkpoint\n            loader = tf.train.Saver(var_to_restore)\n            loader.restore(sess,""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n            bno=sess.run(batchno)\n            print(bno)\n        elif options.restore == 2:            \n            #restore the same model from checkpoint but reset batchno to 1\n            loader = tf.train.Saver(var_to_restore)\n            loader.restore(sess,""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n            sess.run(batchno.assign(1))\n        elif options.restore == 3:\n            #restore the same model from standard training\n            if options.predictConfidence == 1:\n                var_to_restore = [v for v in var_to_restore if \'confidence\' not in v.name]\n                pass\n            if options.predictBoundary == 1:\n                var_to_restore = [v for v in var_to_restore if \'boundary\' not in v.name]\n                pass\n            loader = tf.train.Saver(var_to_restore)\n            if options.hybrid == 1:\n                loader.restore(sess,""checkpoint/planenet_hybrid1/checkpoint.ckpt"")\n            else:\n                loader.restore(sess,""checkpoint/planenet/checkpoint.ckpt"")\n                pass\n            sess.run(batchno.assign(1))\n        elif options.restore == 4:\n            #fine-tune another model\n            var_to_restore = [v for v in var_to_restore if \'res4b22_relu_non_plane\' not in v.name]\n            loader = tf.train.Saver(var_to_restore)\n            loader.restore(sess, options.fineTuningCheckpoint)\n            sess.run(batchno.assign(1))\n            pass\n        # Start input enqueue threads.\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n        MOVING_AVERAGE_DECAY = 0.99\n        ema = [0., 0., 0., 0.]\n        ema_acc = [1e-10, 1e-10, 1e-10, 1e-10]\n        last_snapshot_time = time.time()\n        bno=sess.run(batchno)\n\n        try:\n            while bno<300000:\n                t0 = time.time()\n\n                batchIndexPeriod = bno % 100\n                if batchIndexPeriod == 0:\n                    if options.hybrid == 2:\n                        batchType = 3\n                    else:\n                        batchType = 1\n                        pass\n                elif batchIndexPeriod == 1:\n                    if options.hybrid == 0:\n                        batchType = 1\n                    else:\n                        batchType = 3\n                        pass\n                elif batchIndexPeriod % 10 == 0:\n                    if options.hybrid == 0:\n                        batchType = 0\n                    else:\n                        batchType = 2\n                        pass\n                else:\n                    if options.hybrid == 2:\n                        batchType = 2\n                    else:\n                        batchType = 0\n                        pass                    \n                    pass\n\n                _, total_loss, losses, losses_rgbd, summary_str = sess.run([train_op, loss, loss_dict, loss_dict_rgbd, summary_op], feed_dict = {training_flag: batchType})\n\n                print(losses)\n                print(losses_rgbd)\n                if bno == 2 and False:\n                    print(batchType)\n                    cv2.imwrite(options.test_dir + \'/depth.png\', drawDepthImage(debug[\'depth\'][0]))\n                    cv2.imwrite(options.test_dir + \'/depth_gt.png\', drawDepthImage(debug[\'depth_gt\'][0].squeeze()))\n                    cv2.imwrite(options.test_dir + \'/segmentation.png\', drawSegmentationImage(debug[\'segmentation\'][0]))\n                    print(losses_rgbd)\n                    exit(1)\n                \n                # print(debug[\'plane\'][0])\n                # print(debug[\'loss\'][0])\n                # print(debug[\'loss0\'])                \n                #print(debug[\'confidence\'])\n                \n                #writers[batchType].add_summary(summary_str, bno)\n                ema[batchType] = ema[batchType] * MOVING_AVERAGE_DECAY + total_loss\n                ema_acc[batchType] = ema_acc[batchType] * MOVING_AVERAGE_DECAY + 1\n                bno = sess.run(batchno)\n                if time.time()-last_snapshot_time > 200:\n                    print(\'save snapshot\')\n                    for v in var_to_restore:\n                        print(v)\n                        continue\n                    saver.save(sess,\'%s/checkpoint.ckpt\'%options.checkpoint_dir)\n                    last_snapshot_time = time.time()\n                    pass\n        \n                print bno,\'train\', ema[0] / ema_acc[0], \'val\', ema[1] / ema_acc[1], \'train rgbd\', ema[2] / ema_acc[2], \'val rgbd\', ema[3] / ema_acc[3], \'loss\', total_loss, \'time\', time.time()-t0\n                \n                if np.random.random() < 0.01:\n                    if batchType < 2:\n                        print(losses)\n                    else:\n                        print(losses_rgbd)\n                        pass\n                    pass\n                \n                continue\n\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n        \n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return\n\n\ndef test(options):\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n    \n    options.batchSize = 1\n    min_after_dequeue = 1000\n\n    if options.dataset == \'SUNCG\':\n        reader = RecordReader()\n        filename_queue = tf.train.string_input_producer([\'/home/chenliu/Projects/Data/SUNCG_plane/planes_test_1000_450000.tfrecords\'], num_epochs=10000)\n        img_inp, global_gt_dict, local_gt_dict = reader.getBatch(filename_queue, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True, random=False)\n    else:\n        reader = RecordReaderRGBD()\n        filename_queue = tf.train.string_input_producer([\'../planes_nyu_rgbd_val.tfrecords\'], num_epochs=1)\n        img_inp, global_gt_dict, local_gt_dict = reader.getBatch(filename_queue, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True, random=False)\n\n        options.deepSupervision = 0\n        options.predictLocal = 0\n        pass\n\n    training_flag = tf.constant(1, tf.int32)\n\n    global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp, img_inp, img_inp, img_inp, training_flag, options)\n    var_to_restore = tf.global_variables()\n\n    if options.dataset == \'SUNCG\':\n        loss, loss_dict, debug_dict = build_loss(global_pred_dict, local_pred_dict, deep_pred_dicts, global_gt_dict, local_gt_dict, global_gt_dict, local_gt_dict, training_flag, options)\n    else:\n        loss, loss_dict, debug_dict = build_loss_rgbd(global_pred_dict, local_pred_dict, deep_pred_dicts, global_gt_dict, local_gt_dict, global_gt_dict, local_gt_dict, training_flag, options)\n        pass\n\n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n    \n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n        if options.suffix == \'pixelwise\':\n            var_to_restore = [v for v in var_to_restore if \'res4b22_relu_non_plane\' not in v.name]\n            loader = tf.train.Saver(var_to_restore)\n            loader.restore(sess, \'../PlaneSetGeneration/dump_planenet_pixelwise/train_planenet_pixelwise.ckpt\')\n        else:\n            #var_to_restore = [v for v in var_to_restore if \'res4b22_relu_non_plane\' not in v.name]\n            loader = tf.train.Saver(var_to_restore)\n            loader.restore(sess, ""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n            #loader.restore(sess, options.fineTuningCheckpoint)\n            pass\n        \n\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n        \n        \n        try:\n            gtDepths = []\n            predDepths = []\n            planeMasks = []\n            #predMasks = []\n            lossSum = 0\n            num = 0\n            \n            imageWidth = WIDTH\n            imageHeight = HEIGHT\n            focalLength = 517.97\n            urange = np.arange(imageWidth).reshape(1, -1).repeat(imageHeight, 0) - imageWidth * 0.5\n            vrange = np.arange(imageHeight).reshape(-1, 1).repeat(imageWidth, 1) - imageHeight * 0.5\n            ranges = np.array([urange / imageWidth * 640 / focalLength, np.ones(urange.shape), -vrange / imageHeight * 480 / focalLength]).transpose([1, 2, 0])\n\n\n            for index in xrange(10):\n                print((\'image\', index))\n                t0=time.time()\n\n                img, global_gt, local_gt, global_pred, local_pred, deep_preds, total_loss, losses, debug = sess.run([img_inp, global_gt_dict, local_gt_dict, global_pred_dict, local_pred_dict, deep_pred_dicts, loss, loss_dict, debug_dict])\n\n                # print(options.test_dir)\n                # cv2.imwrite(options.test_dir + \'/depth.png\', drawDepthImage(debug[\'depth\'][0]))\n                # cv2.imwrite(options.test_dir + \'/normal.png\', drawNormalImage(debug[\'normal\'][0]))\n                # boundary = debug[\'boundary\'][0]\n                # boundary = np.concatenate([boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)\n                # cv2.imwrite(options.test_dir + \'/boundary.png\', drawMaskImage(boundary))\n                # cv2.imwrite(options.test_dir + \'/depth_gt.png\', drawDepthImage(debug[\'depth_gt\'][0].squeeze()))\n                # cv2.imwrite(options.test_dir + \'/segmentation.png\', drawSegmentationImage(debug[\'segmentation\'][0]))\n                # exit(1)\n\n                if options.suffix == \'pixelwise\':\n                    image = ((img[0] + 0.5) * 255).astype(np.uint8)\n                    depth = global_pred[\'non_plane_depth\'].squeeze()\n                    #depth = global_gt[\'depth\'].squeeze()\n                    planes, planeSegmentation, depthPred = fitPlanes(depth, numPlanes=20)\n\n                    # gt_p = global_gt[\'plane\'][0]\n                    # pred_p = planes\n                    # valid_mask = (np.linalg.norm(gt_p, axis=1) > 0).astype(np.float32)\n                    # diff = np.min(np.linalg.norm(np.expand_dims(gt_p, 1) - np.expand_dims(pred_p, 0), axis=2), 1)\n                    # num += valid_mask.sum()\n                    # lossSum += (diff * valid_mask).sum()\n                    if options.dataset == \'SUNCG\':\n                        planeMask = np.squeeze(debug[\'plane_mask\'])\n                    else:\n                        planeMask = np.ones((HEIGHT, WIDTH))\n                    if index < 10:\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', image)\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth.png\', drawDepthImage(depth))                    \n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(planeSegmentation))\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(depthPred))\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_plane_mask.png\', drawMaskImage(planeMask))                \n                        pass\n\n                    gtDepths.append(global_gt[\'depth\'].squeeze())\n                    predDepths.append(depth)\n                    planeMasks.append(planeMask * (planeSegmentation < 20).astype(np.float32))\n                    #planeMasks.append((planeSegmentation < 20).astype(np.float32))\n                    continue\n                \n                print((losses[\'plane\'], losses[\'segmentation\'], losses[\'depth\']))\n                  \n                im = img[0]\n                image = ((im + 0.5) * 255).astype(np.uint8)                \n\n                gt_d = global_gt[\'depth\'].squeeze()\n                \n                if \'normal\' in global_gt:\n                    gt_n = global_gt[\'normal\'][0]\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal.png\', drawNormalImage(gt_n))\n                    pass\n                  \n\n                if options.predictLocal:\n                    pred_local_s = 1 / (1 + np.exp(-local_pred[\'score\'][0]))\n                    pred_local_p = local_pred[\'plane\'][0]\n                    pred_local_m = local_pred[\'mask\'][0]\n                  \n                    gt_local_s = local_gt[\'score\'][0]\n                    gt_local_m = local_gt[\'mask\'][0]\n\n                    #visualize local plane prediction\n                    stride = 8\n                    boxSize = 64\n                    xs = np.arange(WIDTH / stride) * stride + stride / 2\n                    ys = np.arange(HEIGHT / stride) * stride + stride / 2\n                    padding = boxSize / 2 + 1\n                    maskImage = np.zeros((HEIGHT + padding * 2, WIDTH + padding * 2, 3), dtype=np.uint8)\n                    maskImage[padding:padding + HEIGHT, padding:padding + WIDTH, :] = image / 2\n                    for gridY, y in enumerate(ys):\n                        for gridX, x in enumerate(xs):\n                            score = pred_local_s[gridY][gridX]\n                            if score < 0.5:\n                                continue                              \n                            mask = pred_local_m[gridY][gridX].reshape([16, 16])        \n                            mask = cv2.resize(mask, (boxSize, boxSize))\n                            maskImage[y - boxSize / 2 + padding:y + boxSize / 2 + padding, x - boxSize / 2 + padding:x + boxSize / 2 + padding, 0][mask > 0.5] = 255\n                            continue\n                        continue\n                    for gridY, y in enumerate(ys):\n                        for gridX, x in enumerate(xs):\n                            score = gt_local_s[gridY][gridX]\n                            if score < 0.5:\n                                continue                              \n                            mask = gt_local_m[gridY][gridX].reshape([16, 16])        \n                            mask = cv2.resize(mask, (boxSize, boxSize))\n                            maskImage[y - boxSize / 2 + padding:y + boxSize / 2 + padding, x - boxSize / 2 + padding:x + boxSize / 2 + padding, 2][mask > 0.5] = 255\n                            continue\n                        continue\n                    pass\n\n                pred_p = global_pred[\'plane\'][0]\n                pred_s = global_pred[\'segmentation\'][0]\n\n                pred_np_m = global_pred[\'non_plane_mask\'][0]\n                pred_np_d = global_pred[\'non_plane_depth\'][0]\n                pred_np_n = global_pred[\'non_plane_normal\'][0]\n                \n                if \'plane_mask\' in debug:\n                    planeMask = np.squeeze(debug[\'plane_mask\'])\n                else:\n                    #planeMask = np.ones((HEIGHT, WIDTH))\n                    planeMask = (np.max(pred_s, axis=2) > pred_np_m.squeeze()).astype(np.float32)\n                    pass\n\n\n\n                all_segmentations = np.concatenate([pred_np_m, pred_s], axis=2)\n                plane_depths = calcPlaneDepths(pred_p, WIDTH, HEIGHT)\n                all_depths = np.concatenate([pred_np_d, plane_depths], axis=2)\n\n                segmentation = np.argmax(all_segmentations, 2)\n                pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape(HEIGHT, WIDTH)\n\n\n                if False:\n                    gt_s = debug[\'segmentation\'][0]\n                    all_segmentations = np.concatenate([pred_np_m, gt_s], axis=2)\n                    gt_p = global_gt[\'plane\'][0]\n\n                    valid_mask = (np.linalg.norm(gt_p, axis=1) > 0).astype(np.float32)\n                    diff = np.min(np.linalg.norm(np.expand_dims(gt_p, 1) - np.expand_dims(pred_p, 0), axis=2), 1)\n                    num += valid_mask.sum()\n                    lossSum += (diff * valid_mask).sum()\n                    \n                    plane_depths = calcPlaneDepths(gt_p, WIDTH, HEIGHT)\n                    all_depths = np.concatenate([pred_np_d, plane_depths], axis=2)\n\n                    segmentation = np.argmax(all_segmentations, 2)\n                    pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape(HEIGHT, WIDTH)\n                    pass\n                    \n                gtDepths.append(gt_d)\n                #planeMask = np.ones(planeMask.shape)\n                planeMasks.append(planeMask)\n                predDepths.append(pred_d)\n                evaluateDepths(predDepths[-1], gtDepths[-1], np.ones(planeMasks[-1].shape), planeMasks[-1])\n                \n                \n                if index >= 10:\n                    continue\n                \n                if \'segmentation\' in global_gt:\n                    gt_s = global_gt[\'segmentation\'][0]\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_gt.png\', drawSegmentationImage(gt_s, planeMask=planeMask, numColors = 51))\n                    pass\n                  \n\n\n                if options.predictConfidence == 1 and options.dataset == \'SUNCG\':\n                    pred_p_c = global_pred[\'confidence\'][0]\n                    pred_p_c = 1 / (1 + np.exp(-pred_p_c))\n                    #print(pred_p_c)\n                    # print(losses)\n                    # print(debug[\'plane\'][0])\n                    # print(pred_p)\n                    # exit(1)\n                    numPlanes = global_gt[\'num_planes\'][0]\n                    print((numPlanes, (pred_p_c > 0.5).sum()))\n                    \n                    pred_p_c = (pred_p_c > 0.5).astype(np.float32)\n                    pred_p *= pred_p_c\n                    pred_s -= (1 - pred_p_c.reshape([1, 1, options.numOutputPlanes])) * 10\n                    pass\n                  \n                if False:\n                    #dump results for post processing\n                    if index >= 10:\n                        break\n                    np.save(options.dump_dir + \'/planes_\' + str(index) + \'.npy\', pred_p)\n                    np.save(options.dump_dir + \'/segmentations_\' + str(index) + \'.npy\', pred_s)\n                    np.save(options.dump_dir + \'/segmentations_gt_\' + str(index) + \'.npy\', gt_s)\n                    np.save(options.dump_dir + \'/non_plane_depth_\' + str(index) + \'.npy\', pred_np_d)\n                    np.save(options.dump_dir + \'/non_plane_segmentation_\' + str(index) + \'.npy\', pred_np_m)\n                    boundary = pred_boundary[0]\n                    boundary = 1 / (1 + np.exp(-boundary))\n                    boundary = np.concatenate([boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)                    \n                    cv2.imwrite(options.dump_dir + \'/boundary_\' + str(index) + \'.png\', drawMaskImage(boundary))\n                    cv2.imwrite(options.dump_dir + \'/image_\' + str(index) + \'.png\', cv2.resize(image, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR))\n                    np.save(options.dump_dir + \'/depth_\' + str(index) + \'.npy\', gt_d)\n                    continue                \n\n                  \n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', image)\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth.png\', drawDepthImage(gt_d))\n\n                if options.predictBoundary:\n                    pred_boundary = global_pred[\'boundary\'][0]\n                    pred_boundary = 1 / (1 + np.exp(-pred_boundary))\n                    boundary = np.concatenate([pred_boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_boundary_pred.png\', drawMaskImage(boundary))\n                    pass\n\n                if \'boundary\' in debug:\n                    gt_boundary = debug[\'boundary\'][0]\n                    boundary = np.concatenate([gt_boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)                \n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_boundary_gt.png\', drawMaskImage(boundary))\n                    pass\n\n\n                if options.deepSupervision >= 1:\n                    segmentation_deep = np.argmax(deep_preds[0][\'segmentation\'][0], 2)\n                    segmentation_deep[segmentation_deep == options.numOutputPlanes] = -1\n                    segmentation_deep += 1\n                \n                    plane_depths_deep = calcPlaneDepths(deep_preds[0][\'plane\'][0], WIDTH, HEIGHT)\n                    all_depths_deep = np.concatenate([pred_np_d, plane_depths_deep], axis=2)\n                    pred_d_deep = all_depths_deep.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation_deep.reshape(-1)].reshape(HEIGHT, WIDTH)\n                \n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred_0.png\', drawSegmentationImage(deep_preds[0][\'segmentation\'][0]))\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred_0.png\', drawDepthImage(pred_d_deep))\n                    pass\n\n\n                #print(pred_np_m)\n                #print(pred_s)\n                #print(global_gt[\'plane\'][0])\n                #print(pred_p)\n                #exit(1)\n                \n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(all_segmentations, black=True))\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_plane_mask.png\', drawMaskImage(planeMask))                \n\n                #print(np.concatenate([np.arange(options.numOutputPlanes).reshape(-1, 1), planes, pred_p, preds_p[0][0]], axis=1))\n\n                #print(np.concatenate([distance[0], preds_p[0][0], pred_p], axis=1))\n                            \n                #segmentation = np.argmax(pred_s, 2)\n                #writePLYFile(options.test_dir, index, image, pred_d, segmentation, np.zeros(pred_boundary[0].shape))\n                #writePLYFileParts(options.test_dir, index, image, pred_d, segmentation)\n                #gt_s_ori = gt_s_ori[0]\n                #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_gt_ori.png\', drawSegmentationImage(gt_s_ori, planeMask=np.max(gt_s_ori, 2) > 0.5, numColors=51))\n                \n                if False:\n                    #distance = distance[0]\n                    print(distance)\n                    diff = np.linalg.norm(np.expand_dims(planes, 1) - np.expand_dims(pred_p, 0), axis=2)\n                    print(np.concatenate([planes, pred_p, pow(np.min(diff, axis=1, keepdims=True), 2), np.expand_dims(np.argmin(diff, axis=1), -1)], axis=1))\n                    print(pred_p_c)\n                    \n                    #print(distance[:, 6:8].sum(0))\n                    #print(pow(np.linalg.norm(distance[:, :3] - distance[:, 3:6], 2, 1), 2) * 100)\n                    #print(test)\n                    segmentation = np.argmax(all_segmentations, 2) - 1\n                    for planeIndex in xrange(options.numOutputPlanes):\n                        cv2.imwrite(options.test_dir + \'/segmentation_\' + str(planeIndex) + \'.png\', drawMaskImage(segmentation == planeIndex))\n                        cv2.imwrite(options.test_dir + \'/segmentation_\' + str(planeIndex) + \'_gt.png\', drawMaskImage(gt_s[:, :, planeIndex]))\n                        cv2.imwrite(options.test_dir + \'/segmentation_\' + str(planeIndex) + \'_gt_ori.png\', drawMaskImage(gt_s_ori[:, :, planeIndex]))\n                        continue\n                    exit(1)\n                continue\n\n            predDepths = np.array(predDepths)\n            gtDepths = np.array(gtDepths)\n            planeMasks = np.array(planeMasks)\n            #predMasks = np.array(predMasks)\n            evaluateDepths(predDepths, gtDepths, np.ones(planeMasks.shape, dtype=np.bool), planeMasks)\n            #print(lossSum / num)\n            exit(1)\n\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n        \n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return\n\n\ndef predict(options):\n    options.test_dir += \'_predict\'\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n\n    batchSize = 1\n    img_inp = tf.placeholder(tf.float32,shape=(batchSize,HEIGHT,WIDTH,3),name=\'img_inp\')\n    plane_gt=tf.placeholder(tf.float32,shape=(batchSize,options.numOutputPlanes, 3),name=\'plane_inp\')\n    validating_inp = tf.constant(0, tf.int32)\n\n    global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp_train, img_inp_val, img_inp_rgbd_train, img_inp_rgbd_val, training_flag, options)\n\n    var_to_restore = tf.global_variables()\n    \n \n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n\n\n    if dataset == \'SUNCG\':\n        image_list_file = os.path.join(\'../PythonScripts/SUNCG/image_list_100_tail_500000.txt\')\n        with open(image_list_file) as f:\n            im_names = [{\'image\': im_name.strip().replace(\'plane_global.npy\', \'mlt.png\'), \'depth\': im_name.strip().replace(\'plane_global.npy\', \'depth.png\'), \'normal\': im_name.strip().replace(\'plane_global.npy\', \'norm_camera.png\'), \'valid\': im_name.strip().replace(\'plane_global.npy\', \'valid.png\'), \'plane\': im_name.strip()} for im_name in f.readlines()]\n            pass\n    else:\n        im_names = glob.glob(\'../../Data/NYU_RGBD/*_color.png\')\n        im_names = [{\'image\': im_name, \'depth\': im_name.replace(\'color.png\', \'depth.png\'), \'normal\': im_name.replace(\'color.png\', \'norm_camera.png\'), \'invalid_mask\': im_name.replace(\'color.png\', \'valid.png\')} for im_name in im_names]\n        pass\n      \n    if numImages > 0:\n        im_names = im_names[:numImages]\n        pass\n\n    #if args.imageIndex > 0:\n    #im_names = im_names[args.imageIndex:args.imageIndex + 1]\n    #pass    \n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n\n    with tf.Session(config=config) as sess:\n        saver = tf.train.Saver()\n        #sess.run(tf.global_variables_initializer())\n        saver.restore(sess,""%s/%s.ckpt""%(options.checkpoint_dir,keyname))\n\n        gtDepths = []\n        predDepths = []\n        segmentationDepths = []\n        predDepthsOneHot = []\n        planeMasks = []\n        predMasks = []\n\n        imageWidth = WIDTH\n        imageHeight = HEIGHT\n        focalLength = 517.97\n        urange = np.arange(imageWidth).reshape(1, -1).repeat(imageHeight, 0) - imageWidth * 0.5\n        vrange = np.arange(imageHeight).reshape(-1, 1).repeat(imageWidth, 1) - imageHeight * 0.5\n        ranges = np.array([urange / focalLength, np.ones(urange.shape), -vrange / focalLength]).transpose([1, 2, 0])\n        \n        cv2.imwrite(options.test_dir + \'/one.png\', np.ones((HEIGHT, WIDTH), dtype=np.uint8) * 255)\n        cv2.imwrite(options.test_dir + \'/zero.png\', np.zeros((HEIGHT, WIDTH), dtype=np.uint8) * 255)\n        for index, im_name in enumerate(im_names):\n            if index <= -1:\n                continue\n            print(im_name[\'image\'])\n            im = cv2.imread(im_name[\'image\'])\n            image = im.astype(np.float32, copy=False)\n            image = image / 255 - 0.5\n            image = cv2.resize(image, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n\n            #planes = np.load(im_name[\'plane\'])\n            # numPlanes = planes.shape[0]\n            # if numPlanes > options.numOutputPlanes:\n            #     planeAreas = planes[:, 3:].sum(1)\n            #     sortInds = np.argsort(planeAreas)[::-1]\n            #     planes = planes[sortInds[:options.numOutputPlanes]]\n            #     pass\n            # gt_p = np.zeros((1, options.numOutputPlanes, 3))\n            # gt_p[0, :numPlanes] = planes[:numPlanes, :3]\n\n            normal = np.array(PIL.Image.open(im_name[\'normal\'])).astype(np.float) / 255 * 2 - 1\n            norm = np.linalg.norm(normal, 2, 2)\n            for c in xrange(3):\n                normal[:, :, c] /= norm\n                continue\n            normal = cv2.resize(normal, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n            \n            depth = np.array(PIL.Image.open(im_name[\'depth\'])).astype(np.float) / 1000\n            depth = cv2.resize(depth, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n\n            invalid_mask = cv2.resize(cv2.imread(im_name[\'invalid_mask\'], 0), (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR) > 128\n\n            gtDepths.append(depth)\n\n            \n            pred_p, pred_d, pred_n, pred_s, pred_np_m, pred_np_d, pred_np_n, pred_boundary, pred_local_score, pred_local_p, pred_local_mask = sess.run([plane_pred, depth_pred, normal_pred, segmentation_pred, non_plane_mask_pred, non_plane_depth_pred, non_plane_normal_pred, boundary_pred, local_score_pred, local_p_pred, local_mask_pred], feed_dict = {img_inp:np.expand_dims(image, 0), plane_gt: np.zeros((batchSize, options.numOutputPlanes, 3))})\n\n\n            pred_s = pred_s[0] \n            pred_p = pred_p[0]\n            pred_np_m = pred_np_m[0]\n            pred_np_d = pred_np_d[0]\n            pred_np_n = pred_np_n[0]\n            #pred_s = 1 / (1 + np.exp(-pred_s))\n\n            plane_depths = calcPlaneDepths(pred_p, WIDTH, HEIGHT)\n            all_depths = np.concatenate([pred_np_d, plane_depths], axis=2)\n\n            all_segmentations = np.concatenate([pred_np_m, pred_s], axis=2)\n            segmentation = np.argmax(all_segmentations, 2)\n            if suffix != \'pixelwise\':\n                pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape(HEIGHT, WIDTH)\n            else:\n                pred_d = np.squeeze(pred_np_d)\n                pass\n            predDepths.append(pred_d)\n            predMasks.append(segmentation != 0)\n            planeMasks.append(invalid_mask)\n\n            #depthError, normalError, occupancy, segmentationTest, reconstructedDepth, occupancyMask = evaluatePlanes(pred_p, im_name[\'image\'])\n            #reconstructedDepth = cv2.resize(reconstructedDepth, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n            \n            #evaluatePlanes(pred_p[0], im_name, options.test_dir, index)\n            #print(pred_p)\n            #print(gt_p)\n            #print((pow(pred_d[0, :, :, 0] - depth, 2) * (gt_s.max(2) > 0.5)).mean())\n            #print((depthError, normalError, occupancy))\n            \n            evaluateDepths(predDepths[index], gtDepths[index], np.ones(planeMasks[index].shape), planeMasks[index])\n\n            if index >= 10:\n                continue\n            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', cv2.resize(im, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR))\n            #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_gt.png\', (minDepth / np.clip(depth, minDepth, 20) * 255).astype(np.uint8))\n            #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', (minDepth / np.clip(pred_d[0, :, :, 0], minDepth, 20) * 255).astype(np.uint8))\n            #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_plane.png\', (minDepth / np.clip(reconstructedDepth, minDepth, 20) * 255).astype(np.uint8))\n\n            pred_boundary = pred_boundary[0]\n            boundary = (1 / (1 + np.exp(-pred_boundary)) * 255).astype(np.uint8)\n            boundary = np.concatenate([boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)\n            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_boundary_pred.png\', boundary)\n            \n            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_inp.png\', drawDepthImage(depth))\n            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n            #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_plane.png\', drawDepthImage(reconstructedDepth))\n            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred_diff.png\', drawDiffImage(pred_d, depth, 0.5))\n            #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_plane_diff.png\', np.minimum(np.abs(reconstructedDepth - depth) / 0.5 * 255, 255).astype(np.uint8))\n            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_inp.png\', drawNormalImage(normal))\n            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_pred.png\', drawNormalImage(pred_np_n))\n            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(all_segmentations, black=True))\n\n            segmentation = np.argmax(pred_s, 2)\n            #writePLYFile(options.test_dir, index, image, pred_p, segmentation)\n\n            if index < 0:\n                for planeIndex in xrange(options.numOutputPlanes):\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_\' + str(planeIndex) + \'.png\', drawMaskImage(pred_s[:, :, planeIndex]))\n                    #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_\' + str(planeIndex) + \'_gt.png\', drawMaskImage(gt_s[:, :, planeIndex]))\n                    continue\n                pass\n            continue\n        predDepths = np.array(predDepths)\n        gtDepths = np.array(gtDepths)\n        planeMasks = np.array(planeMasks)\n        predMasks = np.array(predMasks)\n        #evaluateDepths(predDepths, gtDepths, planeMasks, predMasks)\n        evaluateDepths(predDepths, gtDepths, planeMasks, planeMasks)\n        #exit(1)\n        pass\n    return\n\n\ndef fitPlanesRGBD(options):\n    #writeHTMLRGBD(\'../results/RANSAC_RGBD/index.html\', 10)\n    writeHTMLPlane(\'../results/RGBD/index.html\', 10)\n    exit(1)\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n    \n    min_after_dequeue = 1000\n\n    reader_rgbd = RecordReaderRGBD()\n    filename_queue_rgbd = tf.train.string_input_producer([\'../planes_nyu_rgbd_train.tfrecords\'], num_epochs=1)\n    img_inp_rgbd, global_gt_dict_rgbd, local_gt_dict_rgbd = reader_rgbd.getBatch(filename_queue_rgbd, numOutputPlanes=options.numOutputPlanes, batchSize=1, min_after_dequeue=min_after_dequeue, getLocal=True)\n\n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n        try:\n            gtDepths = []\n            predDepths = []\n            planeMasks = []\n            for index in xrange(10):\n                image, depth, path = sess.run([img_inp_rgbd, global_gt_dict_rgbd[\'depth\'], global_gt_dict_rgbd[\'path\']])\n                image = ((image[0] + 0.5) * 255).astype(np.uint8)\n                depth = depth.squeeze()\n                \n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', image)\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth.png\', drawDepthImage(depth))\n                #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_mask.png\', drawMaskImage(depth == 0))\n                planes, planeSegmentation, depthPred = fitPlanes(depth, numPlanes=20)                \n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(planeSegmentation))\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(depthPred))\n\n                gtDepths.append(depth)\n                predDepths.append(depthPred)\n                planeMasks.append((planeSegmentation < 20).astype(np.float32))\n                continue\n            predDepths = np.array(predDepths)\n            gtDepths = np.array(gtDepths)\n            planeMasks = np.array(planeMasks)\n            evaluateDepths(predDepths, gtDepths, np.ones(planeMasks.shape, dtype=np.bool), planeMasks)            \n        except tf.errors.OutOfRangeError:\n            print(\'done fitting\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n    return\n\n\ndef fitPlanesSceneNN(options):\n    #writeHTMLRGBD(\'../results/RANSAC_RGBD/index.html\', 10)\n    #exit(1)\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n\n    scene_id = \'032\'\n    path = \'/home/chenliu/Projects/Data/SceneNN/scenenn/download/scenenn_data/\' + scene_id + \'/\'\n\n    # tree = ET.parse(path + scene_id + \'.xml\')\n    # root = tree.getroot()\n    # boxes = []\n    # for child in root:\n    #     box = [float(value) for value in child.attrib[\'obbox\'].split(\' \')]\n    #     boxes.append(box)\n    #     continue\n    # boxes = np.array(boxes)\n\n    # image_indices, poses = readTrajectory(scene_index)\n    \n    if True:\n            gtDepths = []\n            predDepths = []\n            planeMasks = []\n            for index in xrange(10):\n\n                image_index = index * 100 + 1\n                image_id = \'%05d\'%image_index\n                image = cv2.imread(path + \'image/image\' + image_id + \'.png\')\n                depth = cv2.imread(path + \'depth/depth\' + image_id + \'.png\', -1).astype(np.float32) / 1000\n                image = cv2.resize(image, (256, 192), interpolation=cv2.INTER_LINEAR)\n                depth = cv2.resize(depth, (256, 192), interpolation=cv2.INTER_LINEAR)\n                \n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', image)\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth.png\', drawDepthImage(depth))\n                #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_mask.png\', drawMaskImage(depth == 0))\n                planes, planeSegmentation, depthPred = fitPlanes(depth, numPlanes=20)                \n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(planeSegmentation))\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(depthPred))\n\n                gtDepths.append(depth)\n                predDepths.append(depthPred)\n                planeMasks.append((planeSegmentation < 20).astype(np.float32))\n                continue\n            predDepths = np.array(predDepths)\n            gtDepths = np.array(gtDepths)\n            planeMasks = np.array(planeMasks)\n            evaluateDepths(predDepths, gtDepths, np.ones(planeMasks.shape, dtype=np.bool), planeMasks)\n            pass\n    return\n\n\ndef fitPlanesScanNet(options):\n    #writeHTMLRGBD(\'../results/RANSAC_RGBD/index.html\', 10)\n    #exit(1)\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n\n    scene_id = \'0000_00\'\n    path = \'/home/chenliu/Projects/Data/ScanNet/scene\' + scene_id + \'/\'\n    \n    if True:\n            gtDepths = []\n            predDepths = []\n            planeMasks = []\n            for index in xrange(10):\n                image_index = index * 100 + 1\n                image_id = \'%06d\'%image_index\n                image = cv2.imread(path + \'frames/frame-\' + image_id + \'.color.jpg\')\n                depth = cv2.imread(path + \'frames/frame-\' + image_id + \'.depth.pgm\', -1).astype(np.float32) / 1000\n                segmentation = cv2.imread(path + \'instance-filt/\' + str(image_index) + \'.png\', 0)\n                \n                image = cv2.resize(image, (256, 192), interpolation=cv2.INTER_LINEAR)\n                depth = cv2.resize(depth, (256, 192), interpolation=cv2.INTER_LINEAR)\n                segmentation = cv2.resize(segmentation, (256, 192), interpolation=cv2.INTER_NEAREST)    \n                \n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', image)\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth.png\', drawDepthImage(depth))\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation.png\', drawSegmentationImage(segmentation, numColors=100))\n                #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_mask.png\', drawMaskImage(depth == 0))\n                planes, planeSegmentation, depthPred = fitPlanesSegmentation(depth, segmentation, numPlanes=20, numPlanesPerSegment=3)\n                \n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(planeSegmentation))\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(depthPred))\n\n                gtDepths.append(depth)\n                predDepths.append(depthPred)\n                planeMasks.append((planeSegmentation < 20).astype(np.float32))\n                continue\n            predDepths = np.array(predDepths)\n            gtDepths = np.array(gtDepths)\n            planeMasks = np.array(planeMasks)\n            evaluateDepths(predDepths, gtDepths, np.ones(planeMasks.shape, dtype=np.bool), planeMasks)\n            pass\n    return\n\ndef parse_args():\n    """"""\n    Parse input arguments\n    """"""\n    parser = argparse.ArgumentParser(description=\'Planenet\')\n    parser.add_argument(\'--gpu\', dest=\'gpu_id\',\n                        help=\'GPU device id to use [0]\',\n                        default=0, type=int)\n    #task: [train, test, predict]\n    parser.add_argument(\'--task\', dest=\'task\',\n                        help=\'task type: [train, test, predict]\',\n                        default=\'train\', type=str)\n    parser.add_argument(\'--restore\', dest=\'restore\',\n                        help=\'how to restore the model\',\n                        default=0, type=int)\n    parser.add_argument(\'--numOutputPlanes\', dest=\'numOutputPlanes\',\n                        help=\'the number of output planes\',\n                        default=20, type=int)\n    parser.add_argument(\'--batchSize\', dest=\'batchSize\',\n                        help=\'batch size\',\n                        default=16, type=int)\n    parser.add_argument(\'--dataset\', dest=\'dataset\',\n                        help=\'dataset name for test/predict\',\n                        default=\'SUNCG\', type=str)\n    parser.add_argument(\'--numImages\', dest=\'numImages\',\n                        help=\'the number of images to test/predict\',\n                        default=100, type=int)\n    parser.add_argument(\'--boundaryLoss\', dest=\'boundaryLoss\',\n                        help=\'use boundary loss: [0, 1]\',\n                        default=1, type=int)\n    parser.add_argument(\'--diverseLoss\', dest=\'diverseLoss\',\n                        help=\'use diverse loss: [0, 1]\',\n                        default=1, type=int)\n    parser.add_argument(\'--deepSupervision\', dest=\'deepSupervision\',\n                        help=\'deep supervision level: [0, 1, 2]\',\n                        default=1, type=int)\n    parser.add_argument(\'--sameMatching\', dest=\'sameMatching\',\n                        help=\'use the matching for all deep supervision layers and the final prediction: [0, 1]\',\n                        default=1, type=int)    \n    parser.add_argument(\'--crf\', dest=\'crf\',\n                        help=\'the number of CRF iterations\',\n                        default=0, type=int)\n    parser.add_argument(\'--backwardLossWeight\', dest=\'backwardLossWeight\',\n                        help=\'backward matching loss\',\n                        default=0, type=float)\n    parser.add_argument(\'--predictBoundary\', dest=\'predictBoundary\',\n                        help=\'whether predict boundary or not: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--predictLocal\', dest=\'predictLocal\',\n                        help=\'whether predict local planes or not: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--predictConfidence\', dest=\'predictConfidence\',\n                        help=\'whether predict plane confidence or not: [0, 1]\',\n                        default=0, type=int)        \n    parser.add_argument(\'--predictPixelwise\', dest=\'predictPixelwise\',\n                        help=\'whether predict pixelwise depth or not: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--fineTuningCheckpoint\', dest=\'fineTuningCheckpoint\',\n                        help=\'specify the model for fine-tuning\',\n                        default=\'../PlaneSetGeneration/dump_planenet_diverse/train_planenet_diverse.ckpt\', type=str)\n    parser.add_argument(\'--suffix\', dest=\'suffix\',\n                        help=\'add a suffix to keyname to distinguish experiments\',\n                        default=\'\', type=str)\n    parser.add_argument(\'--l2Weight\', dest=\'l2Weight\',\n                        help=\'L2 regulation weight\',\n                        default=5e-4, type=float)\n    parser.add_argument(\'--LR\', dest=\'LR\',\n                        help=\'learning rate\',\n                        default=3e-5, type=float)\n    parser.add_argument(\'--hybrid\', dest=\'hybrid\',\n                        help=\'hybrid training\',\n                        default=0, type=int)\n    \n\n    args = parser.parse_args()\n    args.keyname = os.path.basename(__file__).rstrip(\'.py\')\n    args.keyname = args.keyname.replace(\'train_\', \'\')\n    args.keyname = args.keyname.replace(\'_confidence\', \'\')\n    \n    if args.numOutputPlanes != 20:\n        args.keyname += \'_np\' + str(args.numOutputPlanes)\n        pass\n    if args.boundaryLoss != 1:\n        args.keyname += \'_bl\' + str(args.boundaryLoss)\n        pass\n    if args.diverseLoss == 0:\n        args.keyname += \'_dl0\'\n        pass\n    if args.deepSupervision != 1:\n        args.keyname += \'_ds\' + str(args.deepSupervision)\n        pass\n    if args.crf > 0:\n        args.keyname += \'_crf\' + str(args.crf)\n        pass\n    if args.backwardLossWeight > 0:\n        args.keyname += \'_bw\'\n        pass    \n    if args.predictBoundary == 1:\n        args.keyname += \'_pb\'\n        pass\n    if args.predictLocal == 1:\n        args.keyname += \'_pl\'\n        pass\n    if args.predictConfidence == 1:\n        args.keyname += \'_pc\'\n        pass    \n    if args.predictPixelwise == 1:\n        args.keyname += \'_pp\'\n        pass    \n    if args.sameMatching == 0:\n        args.keyname += \'_sm0\'\n        pass\n    if args.hybrid > 0:\n        args.keyname += \'_hybrid\' + str(args.hybrid)\n        pass\n    \n    args.checkpoint_dir = \'checkpoint/\' + args.keyname\n    args.log_dir = \'log/\' + args.keyname\n    args.test_dir = \'test/\' + args.keyname + \'_\' + args.dataset\n    args.predict_dir = \'predict/\' + args.keyname + \'_\' + args.dataset\n    args.dump_dir = \'dump/\' + args.keyname\n    \n    #layers where deep supervision happens\n    args.deepSupervisionLayers = []\n    if args.deepSupervision >= 1:\n        args.deepSupervisionLayers.append(\'res4b22_relu\')\n        pass\n    if args.deepSupervision >= 2:\n        args.deepSupervisionLayers.append(\'res4b12_relu\')\n        pass\n    return args\n\n\nif __name__==\'__main__\':\n    args = parse_args()\n    print ""keyname=%s task=%s started""%(args.keyname, args.task)\n    \n    try:\n        if args.task == ""train"":\n            main(args)\n        elif args.task == ""test"":\n            test(args)\n        elif args.task == ""predict"":\n            predict(args)\n        elif args.task == ""rgbd"":\n            args.test_dir = \'test/RGBD\'\n            fitPlanesRGBD(args)\n        elif args.task == ""scenenn"":\n            args.test_dir = \'test/SceneNN\'\n            fitPlanesSceneNN(args)\n        elif args.task == ""scannet"":\n            args.test_dir = \'test/ScanNet\'\n            fitPlanesScanNet(args)\n        else:\n            assert False,""format wrong""\n            pass\n    finally:\n        pass\n\n'"
code/train_planenet_layer.py,201,"b'import tensorflow as tf\nimport numpy as np\nnp.set_printoptions(precision=2, linewidth=200)\nimport cv2\nimport os\nimport time\nimport sys\nimport tf_nndistance\nimport argparse\nimport glob\nimport PIL\nimport scipy.ndimage as ndimage\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom utils import *\nfrom plane_utils import *\nfrom modules import *\n\n\nfrom planenet_layer import PlaneNet\nfrom RecordReader import *\nfrom RecordReaderRGBD import *\nfrom RecordReader3D import *\nfrom RecordReaderAll import *\nfrom SegmentationRefinement import *\n\n#training_flag: toggle dropout and batch normalization mode\n#it\'s true for training and false for validation, testing, prediction\n#it also controls which data batch to use (*_train or *_val)\n\n\ndef build_graph(img_inp_train, img_inp_val, training_flag, options):\n    with tf.device(\'/gpu:%d\'%options.gpu_id):\n        img_inp = tf.cond(training_flag, lambda: img_inp_train, lambda: img_inp_val)\n\n        if options.suffix == \'sample\':\n            training_flag = tf.constant(True)\n            pass\n        \n        net = PlaneNet({\'img_inp\': img_inp}, is_training=training_flag, options=options)\n\n        #global predictions\n        plane_pred = net.layers[\'plane_pred\']\n        \n        segmentation_pred = net.layers[\'segmentation_pred\']\n        non_plane_mask_pred = net.layers[\'non_plane_mask_pred\']\n        non_plane_depth_pred = net.layers[\'non_plane_depth_pred\']\n        non_plane_normal_pred = net.layers[\'non_plane_normal_pred\']\n        \n        empty_mask_pred = net.layers[\'empty_mask_pred\']\n        \n\n        if False:\n            mask_5_np = (cv2.imread(options.test_dir + \'/mask_5.png\', 0) > 128).astype(np.float32)\n            mask_5 = tf.constant(mask_5_np.reshape(-1), shape=[options.batchSize, HEIGHT, WIDTH, 1])\n            mask_14_np = (cv2.imread(options.test_dir + \'/mask_14.png\', 0) > 128).astype(np.float32)\n            mask_14 = tf.constant(mask_14_np.reshape(-1), shape=[options.batchSize, HEIGHT, WIDTH, 1])        \n            mask_empty_np = (cv2.imread(options.test_dir + \'/mask_empty.png\', 0) > 128).astype(np.float32)\n            #mask_empty_np = np.logical_or(cv2.imread(options.test_dir + \'/mask_gt_0.png\', 0) > 128, cv2.imread(options.test_dir + \'/mask_gt_1.png\', 0) > 128).astype(np.float32)\n            mask_empty = tf.constant(mask_empty_np.reshape(-1), shape=[options.batchSize, HEIGHT, WIDTH, 1])\n\n            segmentation_pred = tf.concat([mask_5 * 100, mask_14 * 100, tf.zeros([options.batchSize, HEIGHT, WIDTH, 3]), tf.ones([options.batchSize, HEIGHT, WIDTH, 1]) * -100, segmentation_pred[:, :, :, 6:14], tf.ones([options.batchSize, HEIGHT, WIDTH, 1]) * -100, segmentation_pred[:, :, :, 15:]], axis=3)\n            plane_pred = tf.concat([plane_pred[:, 5:6, :], plane_pred[:, 14:15, :], plane_pred[:, 2:, :]], axis=1)\n            empty_mask_pred = mask_empty * 100\n            pass\n\n        \n        if False:\n            planeAreas = tf.reduce_sum(global_gt_dict[\'segmentation\'], axis=[1, 2])\n            _, sortInds = tf.nn.top_k(planeAreas, k = options.numOutputPlanes - options.numOutputPlanes_0)\n            sortMap = tf.one_hot(sortInds, depth=options.numOutputPlanes, axis=1)\n            gt_s = tf.reshape(tf.matmul(tf.reshape(global_gt_dict[\'segmentation\'], [-1, HEIGHT * WIDTH, options.numOutputPlanes]), sortMap), [-1, HEIGHT, WIDTH, options.numOutputPlanes - options.numOutputPlanes_0])\n            gt_p = tf.transpose(tf.matmul(tf.transpose(global_gt_dict[\'plane\'], [0, 2, 1]), sortMap), [0, 2, 1])\n            \n            segmentation_pred = tf.concat([tf.zeros([options.batchSize, HEIGHT, WIDTH, 5]), gt_s * 100], axis=3)\n            plane_pred = tf.concat([tf.zeros([options.batchSize, 5, 3]), gt_p], axis=1)\n\n            \n            mask_5_np = (cv2.imread(options.test_dir + \'/mask_5.png\', 0) > 128).astype(np.float32)\n            mask_5 = tf.constant(mask_5_np.reshape(-1), shape=[options.batchSize, HEIGHT, WIDTH, 1])\n            mask_14_np = (cv2.imread(options.test_dir + \'/mask_14.png\', 0) > 128).astype(np.float32)\n            mask_14 = tf.constant(mask_14_np.reshape(-1), shape=[options.batchSize, HEIGHT, WIDTH, 1])        \n            mask_empty_np = (cv2.imread(options.test_dir + \'/mask_empty.png\', 0) > 128).astype(np.float32)\n            mask_empty = tf.constant(mask_empty_np.reshape(-1), shape=[options.batchSize, HEIGHT, WIDTH, 1])  \n            empty_mask_pred = mask_empty * 100\n\n            \n            segmentation_pred = tf.concat([mask_5 * 100, mask_14 * 100, segmentation_pred[:, :, :, :6], segmentation_pred[:, :, :, 8:]], axis=3)\n            plane_pred = tf.concat([plane_pred[:, 6:8, :], plane_pred[:, :6, :], plane_pred[:, 8:, :]], axis=1)\n\n            #empty_mask_pred = tf.ones((options.batchSize, HEIGHT, WIDTH, 1)) * (-100)\n            non_plane_mask_pred = global_gt_dict[\'non_plane_mask\'] * 100\n            non_plane_depth_pred = global_gt_dict[\'depth\']\n            pass\n\n        if False:\n            positive = tf.ones((options.batchSize, HEIGHT, WIDTH, 1)) * 100\n            negative = tf.ones((options.batchSize, HEIGHT, WIDTH, 1)) * -100\n            layer_segmentations_softmax_0 = tf.nn.softmax(segmentation_pred[:, :, :, :5])\n            mask_7 = layer_segmentations_softmax_0[:, :, :, 0:1] * empty_mask_pred\n            empty_mask_pred = segmentation_pred[:, :, :, 7:8]\n            segmentation_pred = tf.concat([positive, tf.tile(negative, [1, 1, 1, 4]), segmentation_pred[:, :, :, 5:7], mask_7, segmentation_pred[:, :, :, 8:]], axis=3)\n            plane_pred = tf.concat([plane_pred[:, 7:8, :], plane_pred[:, 1:7, :], plane_pred[:, 0:1, :], plane_pred[:, 8:, :]], axis=1)\n            pass\n\n        if False:\n            segmentation_pred = tf.concat([segmentation_pred[:, :, :, 0:1], tf.minimum(segmentation_pred[:, :, :, 1:2], segmentation_pred[:, :, :, 3:4]), segmentation_pred[:, :, :, 2:3], tf.maximum(segmentation_pred[:, :, :, 1:2], segmentation_pred[:, :, :, 3:4]), segmentation_pred[:, :, :, 4:]], axis=3)\n            pass\n        \n        #segmentation_pred = tf.concat([np.ones((options.batchSize, HEIGHT, WIDTH, 1)) * 100, np.zeros((options.batchSize, HEIGHT, WIDTH, 4)), segmentation_pred[:, :, :, 5:]], axis=3)\n\n        \n        global_pred_dict = {\'plane\': plane_pred, \'segmentation\': segmentation_pred, \'non_plane_mask\': non_plane_mask_pred, \'non_plane_depth\': non_plane_depth_pred, \'non_plane_normal\': non_plane_normal_pred, \'empty_mask\': empty_mask_pred}\n\n        if options.predictBoundary:\n            global_pred_dict[\'boundary\'] = net.layers[\'boundary_pred\']\n            pass\n        if options.predictConfidence:\n            global_pred_dict[\'confidence\'] = net.layers[\'plane_confidence_pred\']\n            pass\n        \n        #local predictions\n        if options.predictLocal:\n            local_pred_dict = {\'score\': net.layers[\'local_score_pred\'], \'plane\': net.layers[\'local_plane_pred\'], \'mask\': net.layers[\'local_mask_pred\']}\n        else:\n            local_pred_dict = {}\n            pass\n\n        \n        #deep supervision\n        deep_pred_dicts = []\n        for layer in options.deepSupervisionLayers:\n            pred_dict = {\'plane\': net.layers[layer+\'_plane_pred\'], \'segmentation\': net.layers[layer+\'_segmentation_pred\'], \'non_plane_mask\': net.layers[layer+\'_non_plane_mask_pred\']}\n            #if options.predictConfidence:\n            #pred_dict[\'confidence\'] = net.layers[layer+\'_plane_confidence_pred\']\n            #pass\n            deep_pred_dicts.append(pred_dict)\n            continue\n\n        \n        if options.anchorPlanes:\n            anchors_np = np.load(\'dump/anchors_\' + options.hybrid + \'.npy\')\n            anchors = tf.reshape(tf.constant(anchors_np.reshape(-1)), anchors_np.shape)\n            anchors = tf.tile(tf.expand_dims(anchors, 0), [options.batchSize, 1, 1])\n            all_pred_dicts = deep_pred_dicts + [global_pred_dict]            \n            for pred_index, pred_dict in enumerate(all_pred_dicts):\n                all_pred_dicts[pred_index][\'plane\'] += anchors\n                continue\n            pass\n\n        pass\n    \n    return global_pred_dict, local_pred_dict, deep_pred_dicts\n\n\ndef build_loss(global_pred_dict, deep_pred_dicts, global_gt_dict_train, global_gt_dict_val, training_flag, options):\n    with tf.device(\'/gpu:%d\'%options.gpu_id):\n        debug_dict = {}\n        \n        global_gt_dict = {}\n        for name in global_gt_dict_train.keys():\n            global_gt_dict[name] = tf.cond(training_flag, lambda: global_gt_dict_train[name], lambda: global_gt_dict_val[name])\n            continue\n        # local_gt_dict = {}\n        # for name in local_gt_dict_train.keys():\n        #     local_gt_dict[name] = tf.cond(tf.equal(training_flag % 2, 0), lambda: local_gt_dict_train[name], lambda: local_gt_dict_val[name])\n        #     continue\n        \n        layerSupervision = False\n        if layerSupervision:\n            segmentations, planes = divideLayers(global_gt_dict[\'segmentation\'], global_gt_dict[\'plane\'], global_gt_dict[\'non_plane_mask\'], global_gt_dict[\'info\'][0], global_gt_dict[\'num_planes\'])        \n            global_gt_dict[\'segmentation\'] = segmentations\n            global_gt_dict[\'plane\'] = planes\n            pass\n        \n        plane_parameters = tf.reshape(global_pred_dict[\'plane\'], (-1, 3))\n        info = global_gt_dict[\'info\'][0]\n        plane_depths = planeDepthsModule(plane_parameters, WIDTH, HEIGHT, info)\n        plane_depths = tf.transpose(tf.reshape(plane_depths, [HEIGHT, WIDTH, -1, options.numOutputPlanes]), [2, 0, 1, 3])\n\n        non_plane_depth = global_pred_dict[\'non_plane_depth\']\n        all_depths = tf.concat([plane_depths, non_plane_depth], axis=3)\n\n        layer_segmentations_0 = global_pred_dict[\'segmentation\'][:, :, :, :options.numOutputPlanes_0]\n        layer_segmentations_1 = global_pred_dict[\'segmentation\'][:, :, :, options.numOutputPlanes_0:options.numOutputPlanes]\n        layer_segmentations_softmax_0 = tf.nn.softmax(layer_segmentations_0)\n        layer_segmentations_softmax_1 = tf.nn.softmax(layer_segmentations_1)\n        empty_mask = tf.sigmoid(global_pred_dict[\'empty_mask\'])\n        non_plane_mask = tf.sigmoid(global_pred_dict[\'non_plane_mask\'])\n        all_segmentations_softmax = tf.concat([tf.concat([layer_segmentations_softmax_0 * empty_mask, layer_segmentations_softmax_1 * (1 - empty_mask)], axis=3) * (1 - non_plane_mask), non_plane_mask], axis=3)\n        \n        \n        validPlaneMask = tf.cast(tf.less(tf.tile(tf.expand_dims(tf.range(options.numOutputPlanes), 0), [options.batchSize, 1]), tf.expand_dims(global_gt_dict[\'num_planes\'], -1)), tf.float32)        \n        backwardLossWeight = options.backwardLossWeight\n        \n        #plane loss and segmentation loss (summation over deep supervisions and final supervision)\n        all_pred_dicts = deep_pred_dicts + [global_pred_dict]\n        plane_loss = tf.constant(0.0)\n        segmentation_loss = tf.constant(0.0)\n        plane_confidence_loss = tf.constant(0.0)\n        diverse_loss = tf.constant(0.0)\n        \n        #keep forward map (segmentation gt) from previous supervision so that we can have same matching for all supervisions (options.sameMatching = 1)\n        previous_plane_gt = None\n        previous_plane_confidence_gt = None        \n        previous_segmentation_gt = None\n        if options.anchorPlanes:\n            anchors_np = np.load(\'dump/anchors_\' + options.hybrid + \'.npy\')\n            anchors = tf.reshape(tf.constant(anchors_np.reshape(-1)), anchors_np.shape)\n            anchors = tf.tile(tf.expand_dims(anchors, 0), [options.batchSize, 1, 1])\n            dists_forward, map_forward, dists_backward, _ = tf_nndistance.nn_distance(global_gt_dict[\'plane\'], anchors)\n                            \n            forward_map = tf.one_hot(map_forward, depth=options.numOutputPlanes, axis=-1)\n            forward_map *= tf.expand_dims(validPlaneMask, -1)\n                \n            #number of ground truth mapped for each prediction\n            num_matches = tf.transpose(tf.reduce_sum(forward_map, axis=1, keep_dims=True), [0, 2, 1])\n            previous_plane_gt = tf.transpose(tf.matmul(global_gt_dict[\'plane\'], forward_map, transpose_a=True), [0, 2, 1]) / tf.maximum(num_matches, 1e-4)\n            previous_plane_confidence_gt = tf.cast(num_matches > 0.5, tf.float32)\n\n            segmentation_gt_shuffled = tf.reshape(tf.matmul(tf.reshape(global_gt_dict[\'segmentation\'], [-1, HEIGHT * WIDTH, options.numOutputPlanes]), forward_map), [-1, HEIGHT, WIDTH, options.numOutputPlanes])\n            segmentation_gt_shuffled = tf.concat([segmentation_gt_shuffled, global_gt_dict[\'non_plane_mask\']], axis=3)\n            previous_segmentation_gt = segmentation_gt_shuffled\n            pass\n\n        \n        assert(len(all_pred_dicts) == 1)\n        for pred_index, pred_dict in enumerate(all_pred_dicts):\n            if (options.sameMatching and pred_index > 0) or options.anchorPlanes:\n                assert(False)\n                #use matching from previous supervision and map ground truth planes based on the mapping\n\n                plane_loss += tf.reduce_mean(tf.squared_difference(pred_dict[\'plane\'], previous_plane_gt) * previous_plane_confidence_gt) * 10000\n                \n                #all segmentations is the concatenation of plane segmentations and non plane mask\n                #all_segmentations = tf.concat([pred_dict[\'segmentation\'], pred_dict[\'non_plane_mask\']], axis=3)\n\n                if options.crf > 0:\n                    all_segmentations_softmax = tf.nn.softmax(all_segmentations_softmax)          \n                    with tf.variable_scope(\'crf\'):\n                        all_segmentations_softmax = segmentationRefinementModule(all_segmentations_softmax, all_depths, numIterations=options.crf, numOutputPlanes=21)\n                        segmentation_loss += tf.reduce_mean(-tf.reduce_sum(previous_segmentation_gt, tf.log(all_segmentations), axis=-1))\n                        pass\n                    pass\n                else:\n                    segmentation_loss += tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=all_segmentations, labels=previous_segmentation_gt)) * 1000\n                    pass\n            else:\n                #calculate new matching by finding nearest neighbors again\n                if not layerSupervision:\n                    dists_forward, map_forward, dists_backward, _ = tf_nndistance.nn_distance(global_gt_dict[\'plane\'], pred_dict[\'plane\'])\n                    dists_forward *= validPlaneMask\n\n                    dists = tf.concat([global_gt_dict[\'plane\'], pred_dict[\'plane\'], tf.stack([dists_forward, tf.cast(map_forward, tf.float32), dists_backward, tf.cast(_, tf.float32)], axis=2)], axis=2)\n                    dists_forward = tf.reduce_mean(dists_forward)\n                    dists_backward = tf.reduce_mean(dists_backward)\n                    plane_loss += (dists_forward + dists_backward * backwardLossWeight) * 10000\n\n                    forward_map = tf.one_hot(map_forward, depth=options.numOutputPlanes, axis=-1)\n                    forward_map *= tf.expand_dims(validPlaneMask, -1)\n                else:\n                    dists_forward, map_forward, dists_backward, _ = tf_nndistance.nn_distance(global_gt_dict[\'plane\'][:, :options.numOutputPlanes_0, :], pred_dict[\'plane\'][:, :options.numOutputPlanes_0, :])\n                    #dists_forward *= validPlaneMask\n                \n                    dists_forward = tf.reduce_mean(dists_forward)\n                    dists_backward = tf.reduce_mean(dists_backward)\n                    plane_loss += (dists_forward + dists_backward * backwardLossWeight) * 10000\n                    \n                    forward_map = tf.one_hot(map_forward, depth=options.numOutputPlanes, axis=-1)\n                    \n                    dists_forward, map_forward, dists_backward, _ = tf_nndistance.nn_distance(global_gt_dict[\'plane\'][:, options.numOutputPlanes_0:, :], pred_dict[\'plane\'][:, options.numOutputPlanes_0:, :])\n                    #dists_forward *= validPlaneMask\n                \n                    dists_forward = tf.reduce_mean(dists_forward)\n                    dists_backward = tf.reduce_mean(dists_backward)\n                    plane_loss += (dists_forward + dists_backward * backwardLossWeight) * 10000\n                    \n                    forward_map = tf.concat([forward_map, tf.one_hot(map_forward + options.numOutputPlanes_0, depth=options.numOutputPlanes, axis=-1)], axis=1)\n                    #forward_map *= tf.expand_dims(validPlaneMask, -1)\n                    \n    \n                #number of ground truth mapped for each prediction\n                num_matches = tf.transpose(tf.reduce_sum(forward_map, axis=1, keep_dims=True), [0, 2, 1])\n                previous_plane_gt = tf.transpose(tf.matmul(global_gt_dict[\'plane\'], forward_map, transpose_a=True), [0, 2, 1]) / tf.maximum(num_matches, 1e-4)\n                previous_plane_confidence_gt = tf.cast(num_matches > 0.5, tf.float32)\n                \n                                              \n                segmentation_gt_shuffled = tf.reshape(tf.matmul(tf.reshape(global_gt_dict[\'segmentation\'], [-1, HEIGHT * WIDTH, options.numOutputPlanes]), forward_map), [-1, HEIGHT, WIDTH, options.numOutputPlanes])\n                segmentation_gt_shuffled = tf.concat([segmentation_gt_shuffled, global_gt_dict[\'non_plane_mask\']], axis=3)\n                previous_segmentation_gt = segmentation_gt_shuffled\n                \n                #all_segmentations = tf.concat([pred_dict[\'segmentation\'], pred_dict[\'non_plane_mask\']], axis=3)\n                \n                #segmentation_loss += tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=all_segmentations, labels=segmentation_gt_shuffled)) * 1000\n                segmentation_loss += tf.reduce_mean(-segmentation_gt_shuffled * tf.log(tf.maximum(all_segmentations_softmax, 1e-15))) * 1000 * 20\n                pass\n\n            if options.diverseLoss and False:\n                plane_diff = tf.reduce_sum(tf.pow(tf.expand_dims(pred_dict[\'plane\'], 1) - tf.expand_dims(pred_dict[\'plane\'], 2), 2), axis=3)\n                plane_diff = tf.matrix_set_diag(plane_diff, tf.ones((options.batchSize, options.numOutputPlanes)))\n                minPlaneDiff = 0.1\n                diverse_loss += tf.reduce_mean(tf.clip_by_value(1 - plane_diff / minPlaneDiff, 0, 1)) * 10000\n                pass\n              \n            continue\n\n\n        #if options.crf == 0:\n        #all_segmentations_softmax = tf.nn.softmax(all_segmentations)\n        #pass\n        \n        #depth loss\n        validDepthMask = tf.cast(tf.greater(global_gt_dict[\'depth\'], 1e-4), tf.float32)\n        depth_loss = tf.reduce_mean(tf.reduce_sum(tf.squared_difference(all_depths, global_gt_dict[\'depth\']) * all_segmentations_softmax, axis=3, keep_dims=True) * validDepthMask) * 10000\n\n        debug_dict[\'depth\'] = tf.squared_difference(all_depths, global_gt_dict[\'depth\']) * all_segmentations_softmax\n\n        \n        #if options.predictPixelwise == 1:\n        depth_loss += tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_depth\'], global_gt_dict[\'depth\']) * validDepthMask) * 1000\n\n        valid_normal_mask = tf.cast(tf.less(global_gt_dict[\'info\'][0, 19], 2), tf.float32)\n        normal_loss = tf.reduce_mean(tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_normal\'], global_gt_dict[\'normal\']) * validDepthMask, axis=[1, 2, 3]) * valid_normal_mask) * 1000        \n        #normal_loss = tf.constant(0.0)\n        \n\n        local_score_loss = tf.constant(0.0)\n        local_plane_loss = tf.constant(0.0)\n        local_mask_loss = tf.constant(0.0)\n                \n        #boundary loss\n        boundary_loss = tf.constant(0.0)\n        \n        if False:\n            kernel_size = 3\n            padding = (kernel_size - 1) / 2\n            neighbor_kernel_array = gaussian(kernel_size, kernel_size)\n            neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n            neighbor_kernel_array /= neighbor_kernel_array.sum()\n            neighbor_kernel_array *= -1\n            neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 1\n            neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n            neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n            \n            #calculate boundary ground truth on-the-fly as the calculation is subject to change\n        \n            depth_diff = tf.abs(tf.nn.depthwise_conv2d(global_gt_dict[\'depth\'], neighbor_kernel, strides=[1, 1, 1, 1], padding=\'VALID\'))\n            depth_diff = tf.pad(depth_diff, paddings = [[0, 0], [padding, padding], [padding, padding], [0, 0]])\n            max_depth_diff = 0.1\n            depth_boundary = tf.greater(depth_diff, max_depth_diff)\n\n            plane_region = tf.nn.max_pool(1 - global_gt_dict[\'non_plane_mask\'], ksize=[1, kernel_size, kernel_size, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n            segmentation_eroded = 1 - tf.nn.max_pool(1 - global_gt_dict[\'segmentation\'], ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n            plane_region -= tf.reduce_max(segmentation_eroded, axis=3, keep_dims=True)\n            boundary = tf.cast(depth_boundary, tf.float32) * plane_region\n            smooth_boundary = global_gt_dict[\'smooth_boundary\']\n            boundary_gt = tf.concat([smooth_boundary, tf.maximum(boundary - smooth_boundary, 0)], axis=3)\n            pass\n\n\n        if True:\n            kernel_size = 9\n            # neighbor_kernel_array = gaussian(kernel_size)\n            # neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n            # neighbor_kernel_array /= neighbor_kernel_array.sum()\n            # neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n            # neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n            neighbor_kernel = tf.ones([kernel_size, kernel_size, 1, 1])\n\n            #sigmaDepthDiff = 0.5\n            #maxDepthDiff = 0.1\n            labelWeight = 0.05\n            emptyDepthDiff = pow(0.03, 2)\n            nonPlaneDepthDiff = pow(1, 2)\n            depthDiffVar = pow(0.2, 2)\n            \n            planesY = global_pred_dict[\'plane\'][:, :, 1]\n            planesD = tf.maximum(tf.norm(global_pred_dict[\'plane\'], axis=-1), 1e-4)\n            planesY /= planesD\n            planesY = tf.concat([planesY, tf.ones((options.batchSize, 1)) * 100], axis=1)\n            \n            all_segmentations_onehot = tf.one_hot(tf.argmax(all_segmentations_softmax, 3), depth=options.numOutputPlanes + 1)\n            normalY = tf.reduce_sum(all_segmentations_onehot * tf.reshape(planesY, [options.batchSize, 1, 1, -1]), axis=3, keep_dims=True)            \n            depth_onehot = tf.reduce_sum(all_depths * all_segmentations_onehot, 3, keep_dims=True)\n\n            \n            layer_depths_0 = all_depths[:, :, :, :options.numOutputPlanes_0]\n            layer_segmentations_onehot_0 = tf.one_hot(tf.argmax(layer_segmentations_0, 3), depth=options.numOutputPlanes_0)\n            depth_diff_0 = layer_depths_0 - tf.reduce_sum(layer_depths_0 * layer_segmentations_onehot_0, 3, keep_dims=True)\n            depth_diff_0 = tf.pow(depth_diff_0 * normalY, 2)\n            DS_diff_0 = (1 + labelWeight) - tf.exp(-depth_diff_0 / depthDiffVar) - layer_segmentations_onehot_0 * labelWeight\n            DS_0 = tf.nn.depthwise_conv2d(DS_diff_0, tf.tile(neighbor_kernel, [1, 1, options.numOutputPlanes_0, 1]), strides=[1, 1, 1, 1], padding=\'SAME\')\n            \n            \n            depth_diff_1 = plane_depths[:, :, :, options.numOutputPlanes_0:options.numOutputPlanes] - depth_onehot\n            depth_diff_1 = tf.pow(depth_diff_1 * normalY, 2)\n            #empty_mask_onehot = tf.reduce_sum(all_segmentations_onehot[:, :, :, :options.numOutputPlanes_0], axis=3, keep_dims=True)\n\n            #depth_diff_1 = depth_diff_1 * (1 - empty_mask_onehot) + empty_mask_onehot * emptyDepthDiff\n            #depth_diff_1 = tf.concat([(1 - empty_mask_onehot) * emptyDepthDiff, depth_diff_1, 1 - all_segmentations_onehot[:, :, :, options.numOutputPlanes:options.numOutputPlanes+1]], axis=3)\n            depth_diff_1 = tf.concat([depth_diff_1, (1 - all_segmentations_onehot[:, :, :, options.numOutputPlanes:options.numOutputPlanes + 1]) * nonPlaneDepthDiff], axis=3)\n            \n            layer_segmentations_onehot_1 = all_segmentations_onehot[:, :, :, options.numOutputPlanes_0:options.numOutputPlanes + 1]\n            DS_diff_1 = (1 + labelWeight) - tf.exp(-depth_diff_1 / depthDiffVar) - layer_segmentations_onehot_1 * labelWeight\n\n            \n            DS_1 = tf.nn.depthwise_conv2d(DS_diff_1, tf.tile(neighbor_kernel, [1, 1, options.numOutputPlanes + 1 - options.numOutputPlanes_0, 1]), strides=[1, 1, 1, 1], padding=\'SAME\')\n\n            #empty_mask_softmax = tf.reduce_sum(all_segmentations_softmax[:, :, :, :options.numOutputPlanes_0], axis=-1, keep_dims=True)            \n            #layer_segmentations_softmax_1 = tf.concat([empty_mask_softmax, all_segmentations_softmax[:, :, :, options.numOutputPlanes_0:]], axis=3)\n            layer_segmentations_softmax_1 = all_segmentations_softmax[:, :, :, options.numOutputPlanes_0:]\n            \n            boundary_loss += tf.reduce_mean(tf.concat([DS_0 * layer_segmentations_softmax_0 * 10, DS_1 * layer_segmentations_softmax_1], axis=3)) * 5000\n\n            \n            debug_dict[\'cost_mask\'] = tf.concat([DS_0 * layer_segmentations_softmax_0, DS_1 * layer_segmentations_softmax_1], axis=3)\n            #debug_dict[\'cost_mask\'] = tf.reduce_sum(DS_0 * layer_segmentations_softmax_0, axis=3)\n            #debug_dict[\'cost_mask\'] = DS_1 * layer_segmentations_softmax_1\n            #debug_dict[\'cost_mask\'] = DS_1 * layer_segmentations_softmax_1\n            #debug_dict[\'cost_mask\'] = layer_segmentations_softmax_0\n            pass\n          \n        if options.predictBoundary and False:\n            #we predict boundaries directly for post-processing purpose\n            boundary_loss += tf.reduce_mean(tf.losses.sigmoid_cross_entropy(logits=global_pred_dict[\'boundary\'], multi_class_labels=global_gt_dict[\'boundary\'], weights=tf.maximum(global_gt_dict[\'boundary\'] * 3, 1))) * 1000\n            pass\n\n\n        label_loss = tf.constant(0.0)\n        if options.labelLoss == 1:\n            #label_loss = tf.reduce_mean(tf.reduce_max(all_segmentations_softmax[:, :, :, 5:], axis=[1, 2])) * 1000\n            \n            #label_loss += tf.reduce_mean(tf.maximum(1 - tf.reduce_sum(tf.reduce_max(all_segmentations_softmax[:, :, :, :5], axis=[1, 2]), axis=1), 0)) * 100000\n            #label_loss += tf.reduce_mean(tf.maximum(layer_depths_0 - 10, 0) * layer_segmentations_softmax_0) * 1000\n            #label_loss += tf.reduce_mean(tf.maximum(depth_onehot - layer_depths_0, 0) * layer_segmentations_softmax_0 * (1 - global_gt_dict[\'non_plane_mask\'])) * 1000\n            #label_loss = tf.reduce_mean(tf.reduce_max(all_segmentations_softmax, axis=[1, 2])) * 1000\n            pass\n        \n        #regularization\n        l2_losses = tf.add_n([options.l2Weight * tf.nn.l2_loss(v) for v in tf.trainable_variables() if \'weights\' in v.name])\n\n\n        loss = plane_loss + segmentation_loss + depth_loss + normal_loss + plane_confidence_loss + diverse_loss + boundary_loss + local_score_loss + local_plane_loss + local_mask_loss + label_loss + l2_losses * 0\n\n        #if options.pixelwiseLoss:\n        #normal_loss = tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_normal\'], global_gt_dict[\'normal\'])) * 1000\n        #depth_loss = tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_depth\'], global_gt_dict[\'depth\']) * validDepthMask) * 1000\n        #pass\n\n        loss_dict = {\'plane\': plane_loss, \'segmentation\': segmentation_loss, \'depth\': depth_loss, \'normal\': normal_loss, \'boundary\': boundary_loss, \'diverse\': diverse_loss, \'confidence\': plane_confidence_loss, \'local_score\': local_score_loss, \'local_plane\': local_plane_loss, \'local_mask\': local_mask_loss, \'label\': label_loss}\n\n        \n        debug_dict[\'segmentation_pred\'] = all_segmentations_softmax\n        debug_dict[\'segmentation\'] = segmentation_gt_shuffled\n        debug_dict[\'dists\'] = dists\n        #debug_dict[\'background\'] = background_planes\n        pass\n    return loss, loss_dict, debug_dict\n\n\ndef main(options):\n    if not os.path.exists(options.checkpoint_dir):\n        os.system(""mkdir -p %s""%options.checkpoint_dir)\n        pass\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n    \n    min_after_dequeue = 1000\n\n\n    train_inputs = []\n    val_inputs = []\n    if \'0\' in options.hybrid:\n        train_inputs.append(options.rootFolder + \'/planes_SUNCG_train.tfrecords\')\n        val_inputs.append(options.rootFolder + \'/planes_SUNCG_val.tfrecords\')        \n        pass\n    if \'1\' in options.hybrid:\n        for _ in xrange(10):\n            train_inputs.append(options.rootFolder + \'/planes_nyu_rgbd_train.tfrecords\')\n            val_inputs.append(options.rootFolder + \'/planes_nyu_rgbd_val.tfrecords\')\n            continue\n        pass\n    if \'2\' in options.hybrid:\n        train_inputs.append(options.rootFolder + \'/planes_matterport_train.tfrecords\')\n        val_inputs.append(options.rootFolder + \'/planes_matterport_val.tfrecords\')\n        pass\n    if \'3\' in options.hybrid:\n        if options.suffix == \'sample\':\n            train_inputs.append(\'../planes_scannet_train_sample.tfrecords\')        \n            val_inputs.append(\'../planes_scannet_train_sample.tfrecords\')\n        else:\n            train_inputs.append(options.rootFolder + \'/planes_scannet_train.tfrecords\')\n            val_inputs.append(options.rootFolder + \'/planes_scannet_val.tfrecords\')\n            pass\n        pass\n    \n    reader_train = RecordReaderAll()\n    filename_queue_train = tf.train.string_input_producer(train_inputs, num_epochs=1000000)    \n    img_inp_train, global_gt_dict_train, local_gt_dict_train = reader_train.getBatch(filename_queue_train, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True)\n\n    reader_val = RecordReaderAll()\n    filename_queue_val = tf.train.string_input_producer(val_inputs, num_epochs=1000000)\n    img_inp_val, global_gt_dict_val, local_gt_dict_val = reader_val.getBatch(filename_queue_val, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True)\n    \n    training_flag = tf.placeholder(tf.bool, shape=[], name=\'training_flag\')\n    \n    #global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp_train, img_inp_val, img_inp_rgbd_train, img_inp_rgbd_val, img_inp_3d_train, img_inp_3d_val, training_flag, options)\n    global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp_train, img_inp_val, training_flag, options)\n    \n    var_to_restore = [v for v in tf.global_variables()]\n    \n    #loss, loss_dict, _ = build_loss(global_pred_dict, local_pred_dict, deep_pred_dicts, global_gt_dict_train, local_gt_dict_train, global_gt_dict_val, local_gt_dict_val, training_flag, options)\n    #loss_rgbd, loss_dict_rgbd, _ = build_loss_rgbd(global_pred_dict, deep_pred_dicts, global_gt_dict_rgbd_train, global_gt_dict_rgbd_val, training_flag, options)\n    loss, loss_dict, _ = build_loss(global_pred_dict, deep_pred_dicts, global_gt_dict_train, global_gt_dict_val, training_flag, options)    \n        \n    #loss = tf.cond(tf.less(training_flag, 2), lambda: loss, lambda: tf.cond(tf.less(training_flag, 4), lambda: loss_rgbd, lambda: loss_3d))\n\n    \n    #train_writer = tf.summary.FileWriter(options.log_dir + \'/train\')\n    #val_writer = tf.summary.FileWriter(options.log_dir + \'/val\')\n    #train_writer_rgbd = tf.summary.FileWriter(options.log_dir + \'/train_rgbd\')\n    #val_writer_rgbd = tf.summary.FileWriter(options.log_dir + \'/val_rgbd\')\n    #writers = [train_writer, val_writer, train_writer_rgbd, val_writer_rgbd]\n    \n    tf.summary.scalar(\'loss\', loss)\n    summary_op = tf.summary.merge_all()\n\n    with tf.variable_scope(\'statistics\'):\n        batchno = tf.Variable(0, dtype=tf.int32, trainable=False, name=\'batchno\')\n        batchnoinc=batchno.assign(batchno+1)\n        pass\n\n\n    optimizer = tf.train.AdamOptimizer(options.LR)\n    train_op = optimizer.minimize(loss, global_step=batchno)\n\n    \n    config=tf.ConfigProto()\n    config.allow_soft_placement=True    \n    #config.gpu_options.allow_growth=True\n    config.gpu_options.per_process_gpu_memory_fraction=0.9\n    saver=tf.train.Saver()\n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n    \n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n        if options.restore == 0:\n            #fine-tune from DeepLab model\n            var_to_restore = [v for v in var_to_restore if \'res5d\' not in v.name and \'segmentation\' not in v.name and \'plane\' not in v.name and \'deep_supervision\' not in v.name and \'local\' not in v.name and \'boundary\' not in v.name and \'degridding\' not in v.name and \'res2a_branch2a\' not in v.name and \'res2a_branch1\' not in v.name and \'empty\' not in v.name]\n            pretrained_model_loader = tf.train.Saver(var_to_restore)\n            pretrained_model_loader.restore(sess,""../pretrained_models/deeplab_resnet.ckpt"")\n        elif options.restore == 1:\n            #restore the same model from checkpoint\n            loader = tf.train.Saver(var_to_restore)\n            loader.restore(sess,""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n            bno=sess.run(batchno)\n            print(bno)\n        elif options.restore == 2:            \n            #restore the same model from checkpoint but reset batchno to 1\n            loader = tf.train.Saver(var_to_restore)\n            loader.restore(sess,""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n            sess.run(batchno.assign(1))\n        elif options.restore == 3:            \n            #restore the same model from standard training\n            # if options.predictBoundary == 1:\n            #     var_to_restore = [v for v in var_to_restore if \'boundary\' not in v.name]\n            #     pass            \n            # if options.predictConfidence == 1:\n            #     var_to_restore = [v for v in var_to_restore if \'confidence\' not in v.name]\n            #     pass\n            var_to_restore = [v for v in var_to_restore if \'empty\' not in v.name]\n            loader = tf.train.Saver(var_to_restore)\n            loader.restore(sess, options.rootFolder + \'/checkpoint/planenet_hybrid\' + options.hybrid + \'_ll1_bw0.5_pb_pp_sm0/checkpoint.ckpt\')\n            #loader.restore(sess,""checkpoint/planenet/checkpoint.ckpt"")\n            sess.run(batchno.assign(1))\n        elif options.restore == 4:\n            #fine-tune another model\n            #var_to_restore = [v for v in var_to_restore if \'res4b22_relu_non_plane\' not in v.name]\n            loader = tf.train.Saver(var_to_restore)\n            loader.restore(sess, options.fineTuningCheckpoint)\n            sess.run(batchno.assign(1))\n            pass\n        # Start input enqueue threads.\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n        MOVING_AVERAGE_DECAY = 0.99\n        ema = [0., 0., 0., 0.]\n        ema_acc = [1e-10, 1e-10, 1e-10, 1e-10]\n        last_snapshot_time = time.time()\n        bno=sess.run(batchno)\n\n        try:\n            while bno<300000:\n                t0 = time.time()\n\n                batchIndexPeriod = bno % 100\n                if batchIndexPeriod < len(options.hybrid):\n                    #batchType = int(options.hybrid[batchIndexPeriod]) * 2 + 1\n                    batchType = 1\n                else:\n                    batchType = 0\n                    pass\n\n                _, total_loss, losses, summary_str, global_gt = sess.run([train_op, loss, loss_dict, summary_op, global_gt_dict_train], feed_dict = {training_flag: batchType == 0})\n                for batchIndex in xrange(options.batchSize):\n                    if np.isnan(global_gt[\'plane\'][batchIndex]).any():\n                        #print(losses)\n                        #print(global_gt[\'plane\'][batchIndex])\n                        print(global_gt[\'num_planes\'][batchIndex])\n                        for planeIndex in xrange(global_gt[\'num_planes\'][batchIndex]):\n                            cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(global_gt[\'segmentation\'][batchIndex, :, :, planeIndex]))\n                            continue\n                        np.save(\'temp/plane.npy\', global_gt[\'plane\'][batchIndex])                        \n                        np.save(\'temp/depth.npy\', global_gt[\'depth\'][batchIndex])\n                        np.save(\'temp/segmentation.npy\', global_gt[\'segmentation\'][batchIndex])\n                        np.save(\'temp/info.npy\', global_gt[\'info\'][batchIndex])\n                        np.save(\'temp/num_planes.npy\', global_gt[\'num_planes\'][batchIndex])\n                        planes, segmentation, numPlanes = removeSmallSegments(global_gt[\'plane\'][batchIndex], np.zeros((HEIGHT, WIDTH, 3)), global_gt[\'depth\'][batchIndex].squeeze(), np.zeros((HEIGHT, WIDTH, 3)), np.argmax(global_gt[\'segmentation\'][batchIndex], axis=-1), global_gt[\'semantics\'][batchIndex], global_gt[\'info\'][batchIndex], global_gt[\'num_planes\'][batchIndex])\n                        print(planes)\n                        exit(1)\n                        pass\n                    continue\n                #writers[batchType].add_summary(summary_str, bno)\n                ema[batchType] = ema[batchType] * MOVING_AVERAGE_DECAY + total_loss\n                ema_acc[batchType] = ema_acc[batchType] * MOVING_AVERAGE_DECAY + 1\n\n                bno = sess.run(batchno)\n                if time.time()-last_snapshot_time > 900:\n                    print(\'save snapshot\')\n                    saver.save(sess,\'%s/checkpoint.ckpt\'%options.checkpoint_dir)\n                    last_snapshot_time = time.time()\n                    pass\n        \n                print bno,\'train\', ema[0] / ema_acc[0], \'val\', ema[1] / ema_acc[1], \'train rgbd\', ema[2] / ema_acc[2], \'val rgbd\', ema[3] / ema_acc[3], \'loss\', total_loss, \'time\', time.time()-t0\n\n                if np.random.random() < 0.01 or True:\n                    print(losses)\n                    pass                \n                continue\n\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n        \n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return\n\n\ndef test(options):\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n\n    if options.dataset == \'\':\n        assert(len(options.hybrid) == 1)\n        if options.hybrid == \'0\':\n            options.dataset = \'SUNCG\'\n        elif options.hybrid == \'1\':\n            options.dataset = \'NYU_RGBD\'\n        elif options.hybrid == \'2\':\n            options.dataset = \'matterport\'\n        elif options.hybrid == \'3\':\n            options.dataset = \'ScanNet\'\n            \n        options.dataset\n    options.batchSize = 1\n    min_after_dequeue = 1000\n\n    reader = RecordReaderAll()\n    if options.dataset == \'SUNCG\':\n        filename_queue = tf.train.string_input_producer([options.rootFolder + \'/planes_SUNCG_val.tfrecords\'], num_epochs=10000)\n    elif options.dataset == \'NYU_RGBD\':\n        filename_queue = tf.train.string_input_producer([options.rootFolder + \'/planes_nyu_rgbd_train.tfrecords\'], num_epochs=1)\n        options.deepSupervision = 0\n        options.predictLocal = 0\n    elif options.dataset == \'matterport\':\n        filename_queue = tf.train.string_input_producer([options.rootFolder + \'/planes_matterport_val.tfrecords\'], num_epochs=1)\n    else:\n        if options.suffix == \'sample\':\n            filename_queue = tf.train.string_input_producer([\'../planes_scannet_train_sample.tfrecords\'], num_epochs=1)\n        else:\n            filename_queue = tf.train.string_input_producer([options.rootFolder + \'/planes_scannet_val.tfrecords\'], num_epochs=1)\n            pass\n        pass\n    img_inp, global_gt_dict, local_gt_dict = reader.getBatch(filename_queue, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True, random=False)\n\n    if options.suffix == \'sample\':\n        training_flag = tf.constant(True, tf.bool)\n    else:\n        training_flag = tf.constant(False, tf.bool)\n        pass\n    \n    global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp, img_inp, training_flag, options)\n    var_to_restore = tf.global_variables()\n\n    loss, loss_dict, debug_dict = build_loss(global_pred_dict, deep_pred_dicts, global_gt_dict, global_gt_dict, training_flag, options)\n    \n\n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n    \n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n        #var_to_restore = [v for v in var_to_restore if \'res4b22_relu_non_plane\' not in v.name]\n        loader = tf.train.Saver(var_to_restore)\n        loader.restore(sess, ""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n        #loader.restore(sess, ""%s/checkpoint.ckpt""%(\'checkpoint/planenet_pb_pp_hybrid1\'))\n        #loader.restore(sess, options.fineTuningCheckpoint)\n        \n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n        \n        \n        try:\n            gtDepths = []\n            predDepths = []\n            planeMasks = []\n            #predMasks = []\n            gtPlanes = []\n            predPlanes = []\n            gtSegmentations = []\n            predSegmentations = []\n            gtNumPlanes = []\n            \n            imageWidth = WIDTH\n            imageHeight = HEIGHT\n            focalLength = 517.97\n            urange = np.arange(imageWidth).reshape(1, -1).repeat(imageHeight, 0) - imageWidth * 0.5\n            vrange = np.arange(imageHeight).reshape(-1, 1).repeat(imageWidth, 1) - imageHeight * 0.5\n            ranges = np.array([urange / imageWidth * 640 / focalLength, np.ones(urange.shape), -vrange / imageHeight * 480 / focalLength]).transpose([1, 2, 0])\n\n\n            for index in xrange(10):\n                print((\'image\', index))\n                t0=time.time()\n\n                img, global_gt, local_gt, global_pred, local_pred, deep_preds, total_loss, losses, debug = sess.run([img_inp, global_gt_dict, local_gt_dict, global_pred_dict, local_pred_dict, deep_pred_dicts, loss, loss_dict, debug_dict])\n\n                # print(options.test_dir)\n                # cv2.imwrite(options.test_dir + \'/depth.png\', drawDepthImage(debug[\'depth\'][0]))\n                # cv2.imwrite(options.test_dir + \'/normal.png\', drawNormalImage(debug[\'normal\'][0]))\n                # boundary = debug[\'boundary\'][0]\n                # boundary = np.concatenate([boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)\n                # cv2.imwrite(options.test_dir + \'/boundary.png\', drawMaskImage(boundary))\n                # cv2.imwrite(options.test_dir + \'/depth_gt.png\', drawDepthImage(debug[\'depth_gt\'][0].squeeze()))\n                # exit(1)\n\n                if \'pixelwise\' in options.suffix:\n                    image = ((img[0] + 0.5) * 255).astype(np.uint8)\n                    gt_d = global_gt[\'depth\'].squeeze()\n                    pred_d = global_pred[\'non_plane_depth\'].squeeze()\n                    #depth = global_gt[\'depth\'].squeeze()\n                    if \'_2\' in options.suffix:\n                        pred_p, pred_s, pred_d = fitPlanes(pred_d, numPlanes=20, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=0.2)\n                    elif \'_3\' in options.suffix:\n                        pred_p, pred_s, pred_d = fitPlanes(gt_d, numPlanes=20, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=0.2)\n                        pass\n\n                    # gt_p = global_gt[\'plane\'][0]\n                    # pred_p = planes\n                    # valid_mask = (np.linalg.norm(gt_p, axis=1) > 0).astype(np.float32)\n                    # diff = np.min(np.linalg.norm(np.expand_dims(gt_p, 1) - np.expand_dims(pred_p, 0), axis=2), 1)\n                    # num += valid_mask.sum()\n                    # lossSum += (diff * valid_mask).sum()\n                    if options.dataset == \'SUNCG\':\n                        planeMask = np.squeeze(debug[\'segmentation\']).sum(axis=2)\n                    else:\n                        planeMask = np.ones((HEIGHT, WIDTH))\n                        if \'_2\' in options.suffix or \'_3\' in options.suffix:\n                            planeMask *= (pred_s < 20).astype(np.float32)\n                        pass\n                    \n                    if index < 10:\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', image)\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth.png\', drawDepthImage(gt_d))\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n                        if \'_2\' in options.suffix or \'_3\' in options.suffix:\n                            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(pred_s))\n                            pass\n                        #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_plane_mask.png\', drawMaskImage(planeMask))                \n                        pass\n\n                        \n                    gtDepths.append(gt_d)\n                    predDepths.append(pred_d)\n                    planeMasks.append(planeMask)\n\n\n                    if options.dataset != \'NYU_RGBD\' and (\'_2\' in options.suffix or \'_3\' in options.suffix):\n                        gt_p = global_gt[\'plane\'][0]\n                        gt_s = global_gt[\'segmentation\'][0]\n                        gt_num_p = global_gt[\'num_planes\'][0]\n\n                        pred_s = (np.expand_dims(pred_s, -1) == np.reshape(np.arange(options.numOutputPlanes), [1, 1, -1])).astype(np.float32)\n                        gtPlanes.append(gt_p)\n                        predPlanes.append(pred_p)\n                        gtSegmentations.append(gt_s)\n                        gtNumPlanes.append(gt_num_p)\n                        predSegmentations.append(pred_s)\n                        pass\n                    \n                    #planeMasks.append((planeSegmentation < 20).astype(np.float32))\n                    continue\n                \n                print(losses)\n                print(total_loss)\n                #print(losses)\n                #exit(1)\n                im = img[0]\n                image = ((im + 0.5) * 255).astype(np.uint8)                \n\n                gt_d = global_gt[\'depth\'].squeeze()\n                                \n\n                if options.predictLocal:\n                    pred_local_s = 1 / (1 + np.exp(-local_pred[\'score\'][0]))\n                    pred_local_p = local_pred[\'plane\'][0]\n                    pred_local_m = local_pred[\'mask\'][0]\n                  \n                    gt_local_s = local_gt[\'score\'][0]\n                    gt_local_m = local_gt[\'mask\'][0]\n\n                    #visualize local plane prediction\n                    stride = 8\n                    boxSize = 64\n                    xs = np.arange(WIDTH / stride) * stride + stride / 2\n                    ys = np.arange(HEIGHT / stride) * stride + stride / 2\n                    padding = boxSize / 2 + 1\n                    maskImage = np.zeros((HEIGHT + padding * 2, WIDTH + padding * 2, 3), dtype=np.uint8)\n                    maskImage[padding:padding + HEIGHT, padding:padding + WIDTH, :] = image / 2\n                    for gridY, y in enumerate(ys):\n                        for gridX, x in enumerate(xs):\n                            score = pred_local_s[gridY][gridX]\n                            if score < 0.5:\n                                continue                              \n                            mask = pred_local_m[gridY][gridX].reshape([16, 16])        \n                            mask = cv2.resize(mask, (boxSize, boxSize))\n                            maskImage[y - boxSize / 2 + padding:y + boxSize / 2 + padding, x - boxSize / 2 + padding:x + boxSize / 2 + padding, 0][mask > 0.5] = 255\n                            continue\n                        continue\n                    for gridY, y in enumerate(ys):\n                        for gridX, x in enumerate(xs):\n                            score = gt_local_s[gridY][gridX]\n                            if score < 0.5:\n                                continue                              \n                            mask = gt_local_m[gridY][gridX].reshape([16, 16])        \n                            mask = cv2.resize(mask, (boxSize, boxSize))\n                            maskImage[y - boxSize / 2 + padding:y + boxSize / 2 + padding, x - boxSize / 2 + padding:x + boxSize / 2 + padding, 2][mask > 0.5] = 255\n                            continue\n                        continue\n                    pass\n\n                pred_p = global_pred[\'plane\'][0]\n                pred_s = global_pred[\'segmentation\'][0]\n\n                pred_np_m = global_pred[\'non_plane_mask\'][0]\n                pred_np_d = global_pred[\'non_plane_depth\'][0]\n                pred_np_n = global_pred[\'non_plane_normal\'][0]\n                \n                planeMask = 1 - global_gt[\'non_plane_mask\'][0]\n                info = global_gt[\'info\'][0]\n\n\n                layer_segmentations_0 = pred_s[:, :, :options.numOutputPlanes_0]\n                layer_segmentations_softmax_0 = softmax(layer_segmentations_0)\n                layer_segmentations_1 = pred_s[:, :, options.numOutputPlanes_0:options.numOutputPlanes]\n                layer_segmentations_softmax_1 = softmax(layer_segmentations_1)\n                #all_segmentations = np.concatenate([layer_segmentations_softmax_0 * global_pred[\'empty_mask\'][0], layer_segmentations_1, pred_np_m], axis=2)\n                #all_segmentations_softmax = softmax(all_segmentations)\n                empty_mask = sigmoid(global_pred[\'empty_mask\'][0])\n                non_plane_mask = sigmoid(pred_np_m)\n                all_segmentations_softmax = np.concatenate([layer_segmentations_softmax_0 * empty_mask * (1 - non_plane_mask), layer_segmentations_softmax_1 * (1 - empty_mask) * (1 - non_plane_mask), non_plane_mask], axis=2)\n                \n                plane_depths = calcPlaneDepths(pred_p, WIDTH, HEIGHT, info)\n                all_depths = np.concatenate([plane_depths, pred_np_d], axis=2)\n\n                segmentation = np.argmax(all_segmentations_softmax, 2)\n                pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape(HEIGHT, WIDTH)\n\n\n                if False:\n                    gt_s = global_gt[\'segmentation\'][0]\n                    all_segmentations = np.concatenate([gt_s, 1 - planeMask], axis=2)\n                    gt_p = global_gt[\'plane\'][0]\n\n                    # valid_mask = (np.linalg.norm(gt_p, axis=1) > 0).astype(np.float32)\n                    # diff = np.min(np.linalg.norm(np.expand_dims(gt_p, 1) - np.expand_dims(pred_p, 0), axis=2), 1)\n                    # num += valid_mask.sum()\n                    # lossSum += (diff * valid_mask).sum()\n                    #gt_p = np.stack([-gt_p[:, 0], -gt_p[:, 2], -gt_p[:, 1]], axis=1)\n                    \n                    plane_depths = calcPlaneDepths(gt_p, WIDTH, HEIGHT, info)\n                    all_depths = np.concatenate([plane_depths, pred_np_d], axis=2)\n\n                    segmentation = np.argmax(all_segmentations, 2)\n                    pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape(HEIGHT, WIDTH)\n                    # print(gt_p)\n                    # for segmentIndex in xrange(options.numOutputPlanes):\n                    #     cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_mask_\' + str(segmentIndex) + \'.png\', drawMaskImage(segmentation == segmentIndex))\n                    #     continue\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n                    #exit(1)\n                    pass\n\n                \n\n                if options.dataset != \'NYU_RGBD\':\n                    gt_p = global_gt[\'plane\'][0]\n                    gt_s = global_gt[\'segmentation\'][0]\n                    gt_num_p = global_gt[\'num_planes\'][0]\n                    gtPlanes.append(gt_p)\n                    predPlanes.append(pred_p)\n                    gtSegmentations.append(gt_s)\n                    gtNumPlanes.append(gt_num_p)\n                    predSegmentations.append(pred_s)\n                    pass\n            \n                gtDepths.append(gt_d)\n                planeMasks.append(planeMask.squeeze())\n                predDepths.append(pred_d)\n                evaluateDepths(predDepths[-1], gtDepths[-1], gtDepths[-1] > 0, planeMasks[-1])\n                \n                \n                if index >= 10:\n                    continue\n\n\n                if \'normal\' in global_gt and global_gt[\'info\'][0][19] < 2:\n                    gt_n = global_gt[\'normal\'][0]\n                    #gt_n = np.stack([-gt_n[:, :, 0], -gt_n[:, :, 2], -gt_n[:, :, 1]], axis=2)\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_gt.png\', drawNormalImage(gt_n))\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_pred.png\', drawNormalImage(pred_np_n))\n                    pass\n                \n                if \'segmentation\' in global_gt:\n                    gt_s_ori = global_gt[\'segmentation\'][0]\n                    gt_s, gt_p = sortSegmentations(gt_s_ori, gt_p, pred_p)\n                    #print(np.concatenate([pred_p, gt_p], axis=1))\n                    #print(pow(np.linalg.norm(pred_p - gt_p, axis=1), 2).mean() * 10000)\n                    #print(debug[\'dists\'])\n                    #exit(1)\n                    #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_plane_mask_gt.png\', drawMaskImage(planeMask))  \n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_gt.png\', drawSegmentationImage(np.concatenate([gt_s, 1 - planeMask], axis=2), blackIndex=options.numOutputPlanes)\n)\n                    #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_test.png\', drawMaskImage(np.sum(np.concatenate([gt_s, 1 - planeMask], axis=2), axis=2)))\n                    #exit(1)\n                    #exit(1)\n                    pass\n\n\n                if options.predictConfidence == 1 and options.dataset == \'SUNCG\':\n                    pred_p_c = global_pred[\'confidence\'][0]\n                    pred_p_c = 1 / (1 + np.exp(-pred_p_c))\n                    #print(pred_p_c)\n                    # print(losses)\n                    # print(debug[\'plane\'][0])\n                    # print(pred_p)\n                    # exit(1)\n                    numPlanes = global_gt[\'num_planes\'][0]\n                    print((numPlanes, (pred_p_c > 0.5).sum()))\n                    \n                    pred_p_c = (pred_p_c > 0.5).astype(np.float32)\n                    pred_p *= pred_p_c\n                    pred_s -= (1 - pred_p_c.reshape([1, 1, options.numOutputPlanes])) * 10\n                    pass\n                  \n                if False:\n                    #dump results for post processing\n                    if index >= 10:\n                        break\n                    np.save(options.dump_dir + \'/planes_\' + str(index) + \'.npy\', pred_p)\n                    np.save(options.dump_dir + \'/segmentations_\' + str(index) + \'.npy\', pred_s)\n                    np.save(options.dump_dir + \'/segmentations_gt_\' + str(index) + \'.npy\', gt_s)\n                    np.save(options.dump_dir + \'/non_plane_depth_\' + str(index) + \'.npy\', pred_np_d)\n                    np.save(options.dump_dir + \'/non_plane_segmentation_\' + str(index) + \'.npy\', pred_np_m)\n                    boundary = pred_boundary[0]\n                    boundary = 1 / (1 + np.exp(-boundary))\n                    boundary = np.concatenate([boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)                    \n                    cv2.imwrite(options.dump_dir + \'/boundary_\' + str(index) + \'.png\', drawMaskImage(boundary))\n                    cv2.imwrite(options.dump_dir + \'/image_\' + str(index) + \'.png\', cv2.resize(image, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR))\n                    np.save(options.dump_dir + \'/depth_\' + str(index) + \'.npy\', gt_d)\n                    continue                \n\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', image)\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth.png\', drawDepthImage(gt_d))\n                #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_overlay.png\', drawDepthImageOverlay(image, gt_d))\n                \n                if options.predictBoundary:\n                    pred_boundary = global_pred[\'boundary\'][0]\n                    pred_boundary = 1 / (1 + np.exp(-pred_boundary))\n                    boundary = np.concatenate([pred_boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_boundary_pred.png\', drawMaskImage(boundary))\n                    pass\n\n                if \'boundary\' in global_gt:\n                    gt_boundary = global_gt[\'boundary\'][0]\n                    boundary = np.concatenate([gt_boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)                \n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_boundary_gt.png\', drawMaskImage(boundary))\n                    pass\n\n\n                if options.deepSupervision >= 1 and False:\n                    segmentation_deep = np.argmax(deep_preds[0][\'segmentation\'][0], 2)\n                    segmentation_deep[segmentation_deep == options.numOutputPlanes] = -1\n                    segmentation_deep += 1\n                \n                    plane_depths_deep = calcPlaneDepths(deep_preds[0][\'plane\'][0], WIDTH, HEIGHT, info)\n                    all_depths_deep = np.concatenate([pred_np_d, plane_depths_deep], axis=2)\n                    pred_d_deep = all_depths_deep.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation_deep.reshape(-1)].reshape(HEIGHT, WIDTH)\n                \n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred_0.png\', drawSegmentationImage(deep_preds[0][\'segmentation\'][0]))\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred_0.png\', drawDepthImage(pred_d_deep))\n                    pass\n\n\n                #print(pred_np_m)\n                #print(pred_s)\n                #print(global_gt[\'plane\'][0])\n                #print(pred_p)\n                #exit(1)\n\n                segmentation = np.argmax(layer_segmentations_0, axis=-1)\n                layer_depth_0 = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape(HEIGHT, WIDTH) \n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred_0.png\', drawDepthImage(layer_depth_0))\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred_0.png\', drawSegmentationImage(segmentation))\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(all_segmentations_softmax, blackIndex=options.numOutputPlanes))\n                #exit(1)\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n\n\n                if \'cost_mask\' in debug:\n                    #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_cost_mask.png\', drawMaskImage(debug[\'cost_mask\'][0]))\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_cost_mask.png\', drawMaskImage(debug[\'cost_mask\'][0].sum(2)))\n\n\n                    for planeIndex in xrange(debug[\'depth\'].shape[-1]):\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_cost_depth_\' + str(planeIndex) + \'.png\', drawMaskImage(debug[\'depth\'][0, :, :, planeIndex]))\n                        print(planeIndex, debug[\'depth\'][0, :, :, planeIndex].mean())\n                        continue\n                        \n                    total_loss = 0\n                    for planeIndex in xrange(debug[\'cost_mask\'].shape[-1]):\n                        print((planeIndex, debug[\'cost_mask\'][0, :, :, planeIndex].max(), debug[\'cost_mask\'][0, :, :, planeIndex].min(), debug[\'cost_mask\'][0, :, :, planeIndex].mean() * 200000. / 22))\n                        total_loss += debug[\'cost_mask\'][0, :, :, planeIndex].mean() * 200000. / 22\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_cost_mask_\' + str(planeIndex) + \'.png\', drawMaskImage(debug[\'cost_mask\'][0, :, :, planeIndex]))\n                        continue\n                    print(total_loss)\n                    \n                    for planeIndex in xrange(options.numOutputPlanes + 1):\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_mask_\' + str(planeIndex) + \'.png\', drawMaskImage(all_segmentations_softmax[:, :, planeIndex]))\n                        continue\n\n                    for planeIndex in xrange(options.numOutputPlanes_0):\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_layer_mask_\' + str(planeIndex) + \'.png\', drawMaskImage(layer_segmentations_softmax_0[:, :, planeIndex]))\n                        continue\n\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_gt.png\', drawSegmentationImage(np.concatenate([gt_s_ori, 1 - planeMask], axis=2), blackIndex=options.numOutputPlanes))\n                    gt_s_ori = debug[\'segmentation\'][0]\n                    for planeIndex in xrange(options.numOutputPlanes):\n                        cv2.imwrite(options.test_dir + \'/mask_gt_\' + str(planeIndex) + \'.png\', drawMaskImage(gt_s[:, :, planeIndex]))\n                        #cv2.imwrite(options.test_dir + \'/mask_background_\' + str(planeIndex) + \'.png\', drawMaskImage(debug[\'background\'][0, :, :, planeIndex]))\n                        continue\n                    #print(debug[\'background\'][0])\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_empty_mask_pred.png\', drawMaskImage(all_segmentations_softmax[:, :, :options.numOutputPlanes_0].sum(2)))                    \n                    #exit(1)\n                    \n\n\n                    print(pred_p)\n                    \n                    # print(pred_s.max(0).max(0))\n                    # print(pred_s.min(0).min(0))\n                    # print(all_segmentations_softmax.max(0).max(0))\n                    # print(all_segmentations_softmax.min(0).min(0))\n\n                    print(pred_s[150][150])\n                    print(all_segmentations_softmax[150][150])\n                    print(layer_segmentations_softmax_0[150][150])\n                    print(global_pred[\'empty_mask\'][0][150][150])\n                    #cv2.imwrite(options.test_dir + \'/mask_empty.png\', drawMaskImage(gt_s[:, :, 5] + gt_s[:, :, 14]))\n                    # plane_depths = calcPlaneDepths(gt_p, WIDTH, HEIGHT, global_gt[\'info\'][0])\n                    # mask_5 = plane_depths[:, :, 5] < plane_depths[:, :, 14]\n                    # mask_14 = plane_depths[:, :, 5] > plane_depths[:, :, 14]\n                    # mask_5[gt_s[:, :, 5].astype(np.bool)] = True\n                    # mask_14[gt_s[:, :, 5].astype(np.bool)] = False\n                    # mask_5[gt_s[:, :, 14].astype(np.bool)] = False\n                    # mask_14[gt_s[:, :, 14].astype(np.bool)] = True\n                    # cv2.imwrite(options.test_dir + \'/mask_5.png\', drawMaskImage(mask_5))\n                    # cv2.imwrite(options.test_dir + \'/mask_14.png\', drawMaskImage(plane_depths[:, :, 5] > plane_depths[:, :, 14]))\n                    # print(debug[\'segmentation_loss\'].shape)\n\n                    pred_s = debug[\'segmentation_pred\'][0]\n                    gt_s = debug[\'segmentation\'][0]\n                    #all_segmentations_softmax = softmax(pred_s)\n                    all_segmentations_softmax = pred_s\n                    print(gt_s.sum(2).max(), gt_s.sum(2).min(), all_segmentations_softmax.sum(2).max(), all_segmentations_softmax.sum(2).min(), all_segmentations_softmax.max(), all_segmentations_softmax.min())\n                    #print(gt_s[:, :, 7].max())\n                    total_loss = 0\n                    for planeIndex in xrange(options.numOutputPlanes + 1):                    \n                        #print(debug[\'segmentation_loss\'][0, planeIndex].mean())\n                        if planeIndex < options.numOutputPlanes:\n                            loss = -(gt_s[:, :, planeIndex] * np.log(np.maximum(all_segmentations_softmax[:, :, planeIndex], 1e-31))).mean() * 1000\n                        else:\n                            loss = -(global_gt[\'non_plane_mask\'][0, :, :, 0] * np.log(np.maximum(all_segmentations_softmax[:, :, planeIndex], 1e-10))).mean() * 1000\n                            pass\n                        print(loss)\n                        total_loss += loss\n                        continue\n                    print(total_loss)\n                    exit(1)\n                    pass\n                    \n                continue\n\n            # if options.dataset == \'SUNCG\':\n            #     if \'pixelwise\' not in options.suffix:\n            #         evaluatePlaneSegmentation(np.array(predPlanes), np.array(predSegmentations), np.array(gtPlanes), np.array(gtSegmentations), np.array(gtNumPlanes), planeDistanceThreshold = 0.3, IOUThreshold = 0.5, prefix=\'test/planenet_\')\n            #     elif \'_2\' in options.suffix:\n            #         evaluatePlaneSegmentation(np.array(predPlanes), np.array(predSegmentations), np.array(gtPlanes), np.array(gtSegmentations), np.array(gtNumPlanes), planeDistanceThreshold = 0.3, IOUThreshold = 0.5, prefix=\'test/pixelwise_pred_\')\n            #     elif \'_3\' in options.suffix:\n            #         evaluatePlaneSegmentation(np.array(predPlanes), np.array(predSegmentations), np.array(gtPlanes), np.array(gtSegmentations), np.array(gtNumPlanes), planeDistanceThreshold = 0.3, IOUThreshold = 0.5, prefix=\'test/pixelwise_gt_\')\n            #         pass\n            #     pass\n            \n            predDepths = np.array(predDepths)\n            gtDepths = np.array(gtDepths)\n            planeMasks = np.array(planeMasks)\n            #predMasks = np.array(predMasks)\n            evaluateDepths(predDepths, gtDepths, gtDepths > 0, planeMasks)\n            exit(1)\n\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n        \n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return\n\n\ndef predict(options):\n    options.test_dir += \'_predict\'\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n\n    batchSize = 1\n    img_inp = tf.placeholder(tf.float32,shape=(batchSize,HEIGHT,WIDTH,3),name=\'img_inp\')\n    plane_gt=tf.placeholder(tf.float32,shape=(batchSize,options.numOutputPlanes, 3),name=\'plane_inp\')\n    validating_inp = tf.constant(0, tf.int32)\n\n    global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp_train, img_inp_val, img_inp_rgbd_train, img_inp_rgbd_val, training_flag, options)\n\n    var_to_restore = tf.global_variables()\n    \n \n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n\n\n    if dataset == \'SUNCG\':\n        image_list_file = os.path.join(\'../PythonScripts/SUNCG/image_list_100_tail_500000.txt\')\n        with open(image_list_file) as f:\n            im_names = [{\'image\': im_name.strip().replace(\'plane_global.npy\', \'mlt.png\'), \'depth\': im_name.strip().replace(\'plane_global.npy\', \'depth.png\'), \'normal\': im_name.strip().replace(\'plane_global.npy\', \'norm_camera.png\'), \'valid\': im_name.strip().replace(\'plane_global.npy\', \'valid.png\'), \'plane\': im_name.strip()} for im_name in f.readlines()]\n            pass\n    else:\n        im_names = glob.glob(\'../../Data/NYU_RGBD/*_color.png\')\n        im_names = [{\'image\': im_name, \'depth\': im_name.replace(\'color.png\', \'depth.png\'), \'normal\': im_name.replace(\'color.png\', \'norm_camera.png\'), \'invalid_mask\': im_name.replace(\'color.png\', \'valid.png\')} for im_name in im_names]\n        pass\n      \n    if numImages > 0:\n        im_names = im_names[:numImages]\n        pass\n\n    #if args.imageIndex > 0:\n    #im_names = im_names[args.imageIndex:args.imageIndex + 1]\n    #pass    \n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n\n    with tf.Session(config=config) as sess:\n        saver = tf.train.Saver()\n        #sess.run(tf.global_variables_initializer())\n        saver.restore(sess,""%s/%s.ckpt""%(options.checkpoint_dir,keyname))\n\n        gtDepths = []\n        predDepths = []\n        segmentationDepths = []\n        predDepthsOneHot = []\n        planeMasks = []\n        predMasks = []\n\n        imageWidth = WIDTH\n        imageHeight = HEIGHT\n        focalLength = 517.97\n        urange = np.arange(imageWidth).reshape(1, -1).repeat(imageHeight, 0) - imageWidth * 0.5\n        vrange = np.arange(imageHeight).reshape(-1, 1).repeat(imageWidth, 1) - imageHeight * 0.5\n        ranges = np.array([urange / focalLength, np.ones(urange.shape), -vrange / focalLength]).transpose([1, 2, 0])\n        \n        cv2.imwrite(options.test_dir + \'/one.png\', np.ones((HEIGHT, WIDTH), dtype=np.uint8) * 255)\n        cv2.imwrite(options.test_dir + \'/zero.png\', np.zeros((HEIGHT, WIDTH), dtype=np.uint8) * 255)\n        for index, im_name in enumerate(im_names):\n            if index <= -1:\n                continue\n            print(im_name[\'image\'])\n            im = cv2.imread(im_name[\'image\'])\n            image = im.astype(np.float32, copy=False)\n            image = image / 255 - 0.5\n            image = cv2.resize(image, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n\n            #planes = np.load(im_name[\'plane\'])\n            # numPlanes = planes.shape[0]\n            # if numPlanes > options.numOutputPlanes:\n            #     planeAreas = planes[:, 3:].sum(1)\n            #     sortInds = np.argsort(planeAreas)[::-1]\n            #     planes = planes[sortInds[:options.numOutputPlanes]]\n            #     pass\n            # gt_p = np.zeros((1, options.numOutputPlanes, 3))\n            # gt_p[0, :numPlanes] = planes[:numPlanes, :3]\n\n            normal = np.array(PIL.Image.open(im_name[\'normal\'])).astype(np.float) / 255 * 2 - 1\n            norm = np.linalg.norm(normal, 2, 2)\n            for c in xrange(3):\n                normal[:, :, c] /= norm\n                continue\n            normal = cv2.resize(normal, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n            \n            depth = np.array(PIL.Image.open(im_name[\'depth\'])).astype(np.float) / 1000\n            depth = cv2.resize(depth, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n\n            invalid_mask = cv2.resize(cv2.imread(im_name[\'invalid_mask\'], 0), (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR) > 128\n\n            gtDepths.append(depth)\n\n            \n            pred_p, pred_d, pred_n, pred_s, pred_np_m, pred_np_d, pred_np_n, pred_boundary, pred_local_score, pred_local_p, pred_local_mask = sess.run([plane_pred, depth_pred, normal_pred, segmentation_pred, non_plane_mask_pred, non_plane_depth_pred, non_plane_normal_pred, boundary_pred, local_score_pred, local_p_pred, local_mask_pred], feed_dict = {img_inp:np.expand_dims(image, 0), plane_gt: np.zeros((batchSize, options.numOutputPlanes, 3))})\n\n\n            pred_s = pred_s[0] \n            pred_p = pred_p[0]\n            pred_np_m = pred_np_m[0]\n            pred_np_d = pred_np_d[0]\n            pred_np_n = pred_np_n[0]\n            #pred_s = 1 / (1 + np.exp(-pred_s))\n\n            plane_depths = calcPlaneDepths(pred_p, WIDTH, HEIGHT)\n            all_depths = np.concatenate([pred_np_d, plane_depths], axis=2)\n\n            all_segmentations = np.concatenate([pred_np_m, pred_s], axis=2)\n            segmentation = np.argmax(all_segmentations, 2)\n            if suffix != \'pixelwise\':\n                pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape(HEIGHT, WIDTH)\n            else:\n                pred_d = np.squeeze(pred_np_d)\n                pass\n            predDepths.append(pred_d)\n            predMasks.append(segmentation != 0)\n            planeMasks.append(invalid_mask)\n\n            #depthError, normalError, occupancy, segmentationTest, reconstructedDepth, occupancyMask = evaluatePlanes(pred_p, im_name[\'image\'])\n            #reconstructedDepth = cv2.resize(reconstructedDepth, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n            \n            #evaluatePlanes(pred_p[0], im_name, options.test_dir, index)\n            #print(pred_p)\n            #print(gt_p)\n            #print((pow(pred_d[0, :, :, 0] - depth, 2) * (gt_s.max(2) > 0.5)).mean())\n            #print((depthError, normalError, occupancy))\n            \n            evaluateDepths(predDepths[index], gtDepths[index], np.ones(planeMasks[index].shape), planeMasks[index])\n\n            if index >= 10:\n                continue\n            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', cv2.resize(im, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR))\n            #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_gt.png\', (minDepth / np.clip(depth, minDepth, 20) * 255).astype(np.uint8))\n            #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', (minDepth / np.clip(pred_d[0, :, :, 0], minDepth, 20) * 255).astype(np.uint8))\n            #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_plane.png\', (minDepth / np.clip(reconstructedDepth, minDepth, 20) * 255).astype(np.uint8))\n\n            pred_boundary = pred_boundary[0]\n            boundary = (1 / (1 + np.exp(-pred_boundary)) * 255).astype(np.uint8)\n            boundary = np.concatenate([boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)\n            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_boundary_pred.png\', boundary)\n            \n            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_inp.png\', drawDepthImage(depth))\n            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n            #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_plane.png\', drawDepthImage(reconstructedDepth))\n            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred_diff.png\', drawDiffImage(pred_d, depth, 0.5))\n            #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_plane_diff.png\', np.minimum(np.abs(reconstructedDepth - depth) / 0.5 * 255, 255).astype(np.uint8))\n            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_inp.png\', drawNormalImage(normal))\n            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_pred.png\', drawNormalImage(pred_np_n))\n            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(all_segmentations, black=True))\n\n            segmentation = np.argmax(pred_s, 2)\n            #writePLYFile(options.test_dir, index, image, pred_p, segmentation)\n\n            if index < 0:\n                for planeIndex in xrange(options.numOutputPlanes):\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_\' + str(planeIndex) + \'.png\', drawMaskImage(pred_s[:, :, planeIndex]))\n                    #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_\' + str(planeIndex) + \'_gt.png\', drawMaskImage(gt_s[:, :, planeIndex]))\n                    continue\n                pass\n            continue\n        predDepths = np.array(predDepths)\n        gtDepths = np.array(gtDepths)\n        planeMasks = np.array(planeMasks)\n        predMasks = np.array(predMasks)\n        #evaluateDepths(predDepths, gtDepths, planeMasks, predMasks)\n        evaluateDepths(predDepths, gtDepths, planeMasks, planeMasks)\n        #exit(1)\n        pass\n    return\n\n\ndef fitPlanesRGBD(options):\n    writeHTMLRGBD(\'../results/RANSAC_RGBD/index.html\', 10)\n    exit(1)\n    if not os.path.exists(options.checkpoint_dir):\n        os.system(""mkdir -p %s""%options.checkpoint_dir)\n        pass\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n    \n    min_after_dequeue = 1000\n\n    reader_rgbd = RecordReaderRGBD()\n    filename_queue_rgbd = tf.train.string_input_producer([\'../planes_nyu_rgbd_train.tfrecords\'], num_epochs=1)\n    img_inp_rgbd, global_gt_dict_rgbd, local_gt_dict_rgbd = reader_rgbd.getBatch(filename_queue_rgbd, numOutputPlanes=options.numOutputPlanes, batchSize=1, min_after_dequeue=min_after_dequeue, getLocal=True)\n\n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n        try:\n            gtDepths = []\n            predDepths = []\n            planeMasks = []\n            for index in xrange(10):\n                image, depth, path = sess.run([img_inp_rgbd, global_gt_dict_rgbd[\'depth\'], global_gt_dict_rgbd[\'path\']])\n                image = ((image[0] + 0.5) * 255).astype(np.uint8)\n                depth = depth.squeeze()\n                \n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', image)\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth.png\', drawDepthImage(depth))\n                #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_mask.png\', drawMaskImage(depth == 0))\n                planes, planeSegmentation, depthPred = fitPlanes(depth, numPlanes=20)                \n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(planeSegmentation))\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(depthPred))\n\n                gtDepths.append(depth)\n                predDepths.append(depthPred)\n                planeMasks.append((planeSegmentation < 20).astype(np.float32))\n                continue\n            predDepths = np.array(predDepths)\n            gtDepths = np.array(gtDepths)\n            planeMasks = np.array(planeMasks)\n            evaluateDepths(predDepths, gtDepths, np.ones(planeMasks.shape, dtype=np.bool), planeMasks)            \n        except tf.errors.OutOfRangeError:\n            print(\'done fitting\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n    return\n\ndef writeInfo(options):\n    x = (np.arange(11) * 0.1).tolist()\n    ys = []\n    ys.append(np.load(\'test/planenet_pixel_IOU.npy\').tolist())\n    ys.append(np.load(\'test/pixelwise_pred_pixel_IOU.npy\').tolist())\n    ys.append(np.load(\'test/pixelwise_gt_pixel_IOU.npy\').tolist())\n    plotCurves(x, ys, filename = \'test/plane_comparison.png\', xlabel=\'IOU\', ylabel=\'pixel coverage\', labels=[\'planenet\', \'pixelwise+RANSAC\', \'GT+RANSAC\'])\n\n    x = (0.5 - np.arange(11) * 0.05).tolist()\n    ys = []\n    ys.append(np.load(\'test/planenet_pixel_diff.npy\').tolist())\n    ys.append(np.load(\'test/pixelwise_pred_pixel_diff.npy\').tolist())\n    ys.append(np.load(\'test/pixelwise_gt_pixel_diff.npy\').tolist())\n    plotCurves(x, ys, filename = \'test/plane_comparison_diff.png\', xlabel=\'diff\', ylabel=\'pixel coverage\', labels=[\'planenet\', \'pixelwise+RANSAC\', \'GT+RANSAC\'])\n    \n    return\n\ndef parse_args():\n    """"""\n    Parse input arguments\n    """"""\n    parser = argparse.ArgumentParser(description=\'Planenet\')\n    parser.add_argument(\'--gpu\', dest=\'gpu_id\',\n                        help=\'GPU device id to use [0]\',\n                        default=0, type=int)\n    #task: [train, test, predict]\n    parser.add_argument(\'--task\', dest=\'task\',\n                        help=\'task type: [train, test, predict]\',\n                        default=\'train\', type=str)\n    parser.add_argument(\'--restore\', dest=\'restore\',\n                        help=\'how to restore the model\',\n                        default=0, type=int)\n    parser.add_argument(\'--numOutputPlanes\', dest=\'numOutputPlanes\',\n                        help=\'the number of output planes\',\n                        default=20, type=int)\n    parser.add_argument(\'--numOutputPlanes_0\', dest=\'numOutputPlanes_0\',\n                        help=\'the number of output planes\',\n                        default=5, type=int)    \n    parser.add_argument(\'--batchSize\', dest=\'batchSize\',\n                        help=\'batch size\',\n                        default=16, type=int)\n    parser.add_argument(\'--dataset\', dest=\'dataset\',\n                        help=\'dataset name for test/predict\',\n                        default=\'\', type=str)\n    parser.add_argument(\'--numImages\', dest=\'numImages\',\n                        help=\'the number of images to test/predict\',\n                        default=100, type=int)\n    parser.add_argument(\'--boundaryLoss\', dest=\'boundaryLoss\',\n                        help=\'use boundary loss: [0, 1]\',\n                        default=1, type=int)\n    parser.add_argument(\'--diverseLoss\', dest=\'diverseLoss\',\n                        help=\'use diverse loss: [0, 1]\',\n                        default=1, type=int)\n    parser.add_argument(\'--labelLoss\', dest=\'labelLoss\',\n                        help=\'use label loss: [0, 1]\',\n                        default=0, type=int)    \n    parser.add_argument(\'--deepSupervision\', dest=\'deepSupervision\',\n                        help=\'deep supervision level: [0, 1, 2]\',\n                        default=1, type=int)\n    parser.add_argument(\'--sameMatching\', dest=\'sameMatching\',\n                        help=\'use the same matching for all deep supervision layers and the final prediction: [0, 1]\',\n                        default=1, type=int)    \n    parser.add_argument(\'--anchorPlanes\', dest=\'anchorPlanes\',\n                        help=\'use anchor planes for all deep supervision layers and the final prediction: [0, 1]\',\n                        default=0, type=int) \n    parser.add_argument(\'--crf\', dest=\'crf\',\n                        help=\'the number of CRF iterations\',\n                        default=0, type=int)\n    parser.add_argument(\'--backwardLossWeight\', dest=\'backwardLossWeight\',\n                        help=\'backward matching loss\',\n                        default=0, type=float)\n    parser.add_argument(\'--predictBoundary\', dest=\'predictBoundary\',\n                        help=\'whether predict boundary or not: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--predictLocal\', dest=\'predictLocal\',\n                        help=\'whether predict local planes or not: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--predictConfidence\', dest=\'predictConfidence\',\n                        help=\'whether predict plane confidence or not: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--predictPixelwise\', dest=\'predictPixelwise\',\n                        help=\'whether predict pixelwise depth or not: [0, 1]\',\n                        default=0, type=int)    \n    parser.add_argument(\'--fineTuningCheckpoint\', dest=\'fineTuningCheckpoint\',\n                        help=\'specify the model for fine-tuning\',\n                        default=\'../PlaneSetGeneration/dump_planenet_diverse/train_planenet_diverse.ckpt\', type=str)\n    parser.add_argument(\'--suffix\', dest=\'suffix\',\n                        help=\'add a suffix to keyname to distinguish experiments\',\n                        default=\'\', type=str)\n    parser.add_argument(\'--l2Weight\', dest=\'l2Weight\',\n                        help=\'L2 regulation weight\',\n                        default=5e-4, type=float)\n    parser.add_argument(\'--LR\', dest=\'LR\',\n                        help=\'learning rate\',\n                        default=3e-5, type=float)\n    parser.add_argument(\'--hybrid\', dest=\'hybrid\',\n                        help=\'hybrid training\',\n                        default=\'0\', type=str)\n    parser.add_argument(\'--rootFolder\', dest=\'rootFolder\',\n                        help=\'root folder\',\n                        default=\'/mnt/vision/PlaneNet/\', type=str)\n    \n\n    args = parser.parse_args()\n    args.keyname = os.path.basename(__file__).rstrip(\'.py\')\n    args.keyname = args.keyname.replace(\'train_\', \'\')\n\n    if args.numOutputPlanes != 20:\n        args.keyname += \'_np\' + str(args.numOutputPlanes)\n        pass\n    args.keyname += \'_hybrid\' + args.hybrid\n    \n    if args.boundaryLoss != 1:\n        args.keyname += \'_bl\' + str(args.boundaryLoss)\n        pass\n    if args.diverseLoss == 0:\n        args.keyname += \'_dl0\'\n        pass\n    if args.labelLoss == 1:\n        args.keyname += \'_ll1\'\n        pass    \n    if args.deepSupervision != 1:\n        args.keyname += \'_ds\' + str(args.deepSupervision)\n        pass\n    if args.crf > 0:\n        args.keyname += \'_crf\' + str(args.crf)\n        pass\n    if args.backwardLossWeight > 0:\n        args.keyname += \'_bw\' + str(args.backwardLossWeight)\n        pass\n    if args.predictBoundary == 1:\n        args.keyname += \'_pb\'\n        pass\n    if args.predictConfidence == 1:\n        args.keyname += \'_pc\'\n        pass        \n    if args.predictLocal == 1:\n        args.keyname += \'_pl\'\n        pass\n    if args.predictPixelwise == 1:\n        args.keyname += \'_pp\'\n        pass    \n    if args.sameMatching == 0:\n        args.keyname += \'_sm0\'\n        pass\n    if args.anchorPlanes == 1:\n        args.keyname += \'_ap1\'\n        pass\n\n    \n    args.checkpoint_dir = args.rootFolder + \'/checkpoint/\' + args.keyname\n    args.log_dir = \'log/\' + args.keyname\n    args.test_dir = \'test/\' + args.keyname + \'_\' + args.dataset\n    args.predict_dir = \'predict/\' + args.keyname + \'_\' + args.dataset\n    args.dump_dir = \'dump/\' + args.keyname\n    \n    #layers where deep supervision happens\n    args.deepSupervisionLayers = []\n    # if args.deepSupervision >= 1:\n    #     args.deepSupervisionLayers.append(\'res4b22_relu\')\n    #     pass\n    # if args.deepSupervision >= 2:\n    #     args.deepSupervisionLayers.append(\'res4b12_relu\')\n    #     pass\n    return args\n\n\nif __name__==\'__main__\':\n\n    # plane = np.load(\'temp/plane.npy\')\n    # depth = np.load(\'temp/depth.npy\')    \n    # segmentation = np.load(\'temp/segmentation.npy\')\n    # info = np.load(\'temp/info.npy\')\n    # num_planes = np.load(\'temp/num_planes.npy\')\n    # segmentation = np.argmax(segmentation, axis=-1)\n    # print(segmentation.shape)\n    # planes, segmentation, numPlanes = removeSmallSegments(plane, np.zeros((HEIGHT, WIDTH, 3)), depth.squeeze(), np.zeros((HEIGHT, WIDTH, 3)), segmentation, np.zeros((HEIGHT, WIDTH)), info, num_planes)\n    # print(planes)\n    # exit(1)\n    \n    args = parse_args()\n\n    print ""keyname=%s task=%s started""%(args.keyname, args.task)\n    try:\n        if args.task == ""train"":\n            main(args)\n        elif args.task == ""test"":\n            test(args)\n        elif args.task == ""predict"":\n            predict(args)\n        elif args.task == ""fit"":\n            fitPlanesRGBD(args)\n        elif args.task == ""write"":\n            writeInfo(args)\n        else:\n            assert False,""format wrong""\n            pass\n    finally:\n        pass\n\n'"
code/train_planenet_separate.py,206,"b'import tensorflow as tf\nimport numpy as np\nnp.set_printoptions(precision=2, linewidth=200)\nimport cv2\nimport os\nimport time\nimport sys\nimport tf_nndistance\nimport argparse\nimport glob\nimport PIL\nimport scipy.ndimage as ndimage\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom utils import *\nfrom plane_utils import *\nfrom modules import *\n\n\nfrom planenet import PlaneNet\nfrom RecordReader import *\nfrom RecordReaderRGBD import *\nfrom RecordReader3D import *\n\n#training_flag: toggle dropout and batch normalization mode\n#it\'s true for training and false for validation, testing, prediction\n#it also controls which data batch to use (*_train or *_val)\n\n\ndef build_graph(img_inp_train, img_inp_val, training_flag, options):\n    with tf.device(\'/gpu:%d\'%options.gpu_id):\n        img_inp = tf.cond(training_flag, lambda: img_inp_train, lambda: img_inp_val)\n        \n        net = PlaneNet({\'img_inp\': img_inp}, is_training=training_flag, options=options)\n\n        #global predictions\n        plane_pred = net.layers[\'plane_pred\']\n        \n        segmentation_pred = net.layers[\'segmentation_pred\']\n        non_plane_mask_pred = net.layers[\'non_plane_mask_pred\']\n        non_plane_depth_pred = net.layers[\'non_plane_depth_pred\']\n        non_plane_normal_pred = net.layers[\'non_plane_normal_pred\']\n        \n        global_pred_dict = {\'plane\': plane_pred, \'segmentation\': segmentation_pred, \'non_plane_mask\': non_plane_mask_pred, \'non_plane_depth\': non_plane_depth_pred, \'non_plane_normal\': non_plane_normal_pred}\n\n        if options.predictBoundary:\n            global_pred_dict[\'boundary\'] = net.layers[\'boundary_pred\']\n            pass\n        if options.predictConfidence:\n            global_pred_dict[\'confidence\'] = net.layers[\'plane_confidence_pred\']\n            pass\n        \n        #local predictions\n        if options.predictLocal:\n            local_pred_dict = {\'score\': net.layers[\'local_score_pred\'], \'plane\': net.layers[\'local_plane_pred\'], \'mask\': net.layers[\'local_mask_pred\']}\n        else:\n            local_pred_dict = {}\n            pass\n\n        \n        #deep supervision\n        deep_pred_dicts = []\n        for layer in options.deepSupervisionLayers:\n            pred_dict = {\'plane\': net.layers[layer+\'_plane_pred\'], \'segmentation\': net.layers[layer+\'_segmentation_pred\'], \'non_plane_mask\': net.layers[layer+\'_non_plane_mask_pred\']}\n            #if options.predictConfidence:\n            #pred_dict[\'confidence\'] = net.layers[layer+\'_plane_confidence_pred\']\n            #pass\n            deep_pred_dicts.append(pred_dict)\n            continue\n        pass\n    \n    return global_pred_dict, local_pred_dict, deep_pred_dicts\n\n\ndef build_loss(global_pred_dict, local_pred_dict, deep_pred_dicts, global_gt_dict_train, local_gt_dict_train, global_gt_dict_val, local_gt_dict_val, training_flag, options):\n    \n    with tf.device(\'/gpu:%d\'%options.gpu_id):\n        global_gt_dict = {}\n        for name in global_gt_dict_train.keys():\n            global_gt_dict[name] = tf.cond(training_flag, lambda: global_gt_dict_train[name], lambda: global_gt_dict_val[name])\n            continue\n        local_gt_dict = {}\n        for name in local_gt_dict_train.keys():\n            local_gt_dict[name] = tf.cond(training_flag, lambda: local_gt_dict_train[name], lambda: local_gt_dict_val[name])\n            continue\n\n        normalDotThreshold = np.cos(np.deg2rad(5))\n        distanceThreshold = 0.05\n        segmentation_gt, plane_mask = fitPlaneMasksModule(global_gt_dict[\'plane\'], global_gt_dict[\'depth\'], global_gt_dict[\'normal\'], width=WIDTH, height=HEIGHT, normalDotThreshold=normalDotThreshold, distanceThreshold=distanceThreshold, closing=True, one_hot=True)\n        \n        validPlaneMask = tf.cast(tf.less(tf.tile(tf.expand_dims(tf.range(options.numOutputPlanes), 0), [options.batchSize, 1]), tf.expand_dims(global_gt_dict[\'num_planes\'], -1)), tf.float32)        \n\n        \n        backwardLossWeight = options.backwardLossWeight\n        \n\n        #plane loss and segmentation loss (summation over deep supervisions and final supervision)\n        all_pred_dicts = deep_pred_dicts + [global_pred_dict]\n        plane_loss = tf.constant(0.0)\n        segmentation_loss = tf.constant(0.0)\n        plane_confidence_loss = tf.constant(0.0)\n        diverse_loss = tf.constant(0.0)\n        \n        #keep forward map (segmentation gt) from previous supervision so that we can have same matching for all supervisions (options.sameMatching = 1)\n        previous_forward_map = None\n        previous_segmentation_gt = None\n        for pred_index, pred_dict in enumerate(all_pred_dicts):\n            if options.sameMatching and pred_index > 0:\n                #use matching from previous supervision and map ground truth planes based on the mapping\n                forward_map = previous_forward_map\n\n                #number of ground truth mapped for each prediction\n                num_matches = tf.transpose(tf.reduce_sum(forward_map, axis=1, keep_dims=True), [0, 2, 1])\n\n\n                plane_gt_shuffled = tf.transpose(tf.matmul(global_gt_dict[\'plane\'], forward_map, transpose_a=True), [0, 2, 1]) / tf.maximum(num_matches, 1e-4)\n                plane_confidence_gt = tf.cast(num_matches > 0.5, tf.float32)\n                plane_loss += tf.reduce_mean(tf.squared_difference(pred_dict[\'plane\'], plane_gt_shuffled) * plane_confidence_gt) * 10000\n\n                \n                #all segmentations is the concatenation of plane segmentations and non plane mask\n                all_segmentations = tf.concat([pred_dict[\'segmentation\'], pred_dict[\'non_plane_mask\']], axis=3)\n                segmentation_gt_shuffled = previous_segmentation_gt\n\n                segmentation_loss += tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=all_segmentations, labels=segmentation_gt_shuffled)) * 1000\n                \n            else:\n                #calculate new matching by finding nearest neighbors again\n                dists_forward, map_forward, dists_backward, _ = tf_nndistance.nn_distance(global_gt_dict[\'plane\'], pred_dict[\'plane\'])\n                dists_forward *= validPlaneMask\n                \n                dists_forward = tf.reduce_mean(dists_forward)\n                dists_backward = tf.reduce_mean(dists_backward)\n                plane_loss += (dists_forward + dists_backward * backwardLossWeight) * 10000\n\n                forward_map = tf.one_hot(map_forward, depth=options.numOutputPlanes, axis=-1)\n                forward_map *= tf.expand_dims(validPlaneMask, -1)\n\n                previous_forward_map = forward_map\n                \n                segmentation_gt_shuffled = tf.reshape(tf.matmul(tf.reshape(segmentation_gt, [-1, HEIGHT * WIDTH, options.numOutputPlanes]), forward_map), [-1, HEIGHT, WIDTH, options.numOutputPlanes])\n                segmentation_gt_shuffled = tf.concat([segmentation_gt_shuffled, 1 - plane_mask], axis=3)\n                previous_segmentation_gt = segmentation_gt_shuffled\n                \n                all_segmentations = tf.concat([pred_dict[\'segmentation\'], pred_dict[\'non_plane_mask\']], axis=3)\n                segmentation_loss += tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=all_segmentations, labels=segmentation_gt_shuffled)) * 1000\n                pass\n\n            if options.diverseLoss:\n                plane_diff = tf.reduce_sum(tf.pow(tf.expand_dims(pred_dict[\'plane\'], 1) - tf.expand_dims(pred_dict[\'plane\'], 2), 2), axis=3)\n                plane_diff = tf.matrix_set_diag(plane_diff, tf.ones((options.batchSize, options.numOutputPlanes)))\n                minPlaneDiff = 0.1\n                diverse_loss += tf.reduce_mean(tf.clip_by_value(1 - plane_diff / minPlaneDiff, 0, 1)) * 10000\n                pass\n              \n            continue\n\n\n\n        #depth loss\n        plane_parameters = tf.reshape(global_pred_dict[\'plane\'], (-1, 3))\n        plane_depths = planeDepthsModule(plane_parameters, WIDTH, HEIGHT)\n        plane_depths = tf.transpose(tf.reshape(plane_depths, [HEIGHT, WIDTH, -1, options.numOutputPlanes]), [2, 0, 1, 3])\n\n        all_segmentations_softmax = tf.nn.softmax(all_segmentations)\n        non_plane_depth = global_pred_dict[\'non_plane_depth\']\n        all_depths = tf.concat([plane_depths, non_plane_depth], axis=3)\n        validDepthMask = tf.cast(tf.greater(global_gt_dict[\'depth\'], 1e-4), tf.float32)\n        depth_loss = tf.reduce_mean(tf.reduce_sum(tf.squared_difference(all_depths, global_gt_dict[\'depth\']) * all_segmentations_softmax, axis=3, keep_dims=True) * validDepthMask) * 1000\n\n        if options.predictPixelwise == 1:\n            depth_loss += tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_mask\'], global_gt_dict[\'depth\']) * validDepthMask) * 1000\n            normal_loss = tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_normal\'], global_gt_dict[\'normal\']) * validDepthMask) * 1000\n        else:\n            #normal loss for non-plane region\n            normal_loss = tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_normal\'], global_gt_dict[\'normal\']) * (1 - plane_mask)) * 1000\n            pass\n        \n\n        #local loss\n        if options.predictLocal:\n            local_score_loss = tf.reduce_mean(tf.losses.sigmoid_cross_entropy(logits=local_pred_dict[\'score\'], multi_class_labels=local_gt_dict[\'score\'], weights=tf.maximum(local_gt_dict[\'score\'] * 10, 1))) * 1000\n            local_plane_loss = tf.reduce_mean(tf.squared_difference(local_pred_dict[\'plane\'], local_gt_dict[\'plane\']) * local_gt_dict[\'score\']) * 10000\n            local_mask_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=local_pred_dict[\'mask\'], labels=local_gt_dict[\'mask\']) * local_gt_dict[\'score\']) * 10000\n        else:\n            local_score_loss = tf.constant(0.0)\n            local_plane_loss = tf.constant(0.0)\n            local_mask_loss = tf.constant(0.0)\n            pass\n        \n        \n        #boundary loss\n        boundary_loss = tf.constant(0.0)\n        #load or calculate boundary ground truth\n        if False:\n            pass\n            #load from dataset\n            #boundary_gt = tf.cond(training_flag, lambda: boundary_gt_train, lambda: boundary_gt_val)\n        else:\n            #calculate boundary ground truth on-the-fly as the calculation is subject to change\n            kernel_size = 3\n            padding = (kernel_size - 1) / 2\n            neighbor_kernel_array = gaussian(kernel_size, kernel_size)\n            neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n            neighbor_kernel_array /= neighbor_kernel_array.sum()\n            neighbor_kernel_array *= -1\n            neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 1\n            neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n            neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n\n            boundary_gt = findBoundaryModule(global_gt_dict[\'depth\'], global_gt_dict[\'normal\'], segmentation_gt, plane_mask, max_depth_diff = 0.1, max_normal_diff = np.sqrt(2 * (1 - np.cos(np.deg2rad(20)))))\n            pass\n\n\n        if options.boundaryLoss == 1:\n            all_segmentations_pred = all_segmentations_softmax\n            all_segmentations_min = 1 - tf.nn.max_pool(1 - all_segmentations_pred, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\')\n            segmentation_diff = tf.reduce_max(all_segmentations_pred - all_segmentations_min, axis=3, keep_dims=True)\n\n            depth_pred = tf.reduce_sum(tf.multiply(all_depths, all_segmentations_pred), axis=3, keep_dims=True)\n            depth_neighbor = tf.nn.depthwise_conv2d(depth_pred, neighbor_kernel, strides=[1, 1, 1, 1], padding=\'SAME\')\n            minDepthDiff = 0.02\n            depth_diff = tf.clip_by_value(tf.squared_difference(depth_pred, depth_neighbor) - pow(minDepthDiff, 2), 0, 1)\n\n            boundary = tf.reduce_max(boundary_gt, axis=3, keep_dims=True)\n            smooth_boundary = tf.slice(boundary_gt, [0, 0, 0, 0], [options.batchSize, HEIGHT, WIDTH, 1])\n            smooth_mask = segmentation_diff + boundary - 2 * segmentation_diff * boundary + depth_diff * smooth_boundary\n            margin = 0.0\n            smooth_mask = tf.nn.relu(smooth_mask - margin)\n            boundary_loss += tf.reduce_mean(smooth_mask * plane_mask) * 1000            \n            pass\n        elif options.boundaryLoss == 2:\n            all_segmentations_pred = all_segmentations_softmax\n            all_segmentations_min = 1 - tf.nn.max_pool(1 - all_segmentations_pred, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\')\n            segmentation_diff = tf.reduce_max(all_segmentations_pred - all_segmentations_min, axis=3, keep_dims=True)\n\n            depth_pred = tf.reduce_sum(tf.multiply(all_depths, all_segmentations_pred), axis=3, keep_dims=True)\n            depth_neighbor = tf.nn.depthwise_conv2d(depth_pred, neighbor_kernel, strides=[1, 1, 1, 1], padding=\'SAME\')\n            minDepthDiff = 0.02\n            depth_diff = tf.clip_by_value(tf.squared_difference(depth_pred, depth_neighbor) - pow(minDepthDiff, 2), 0, 1)\n\n            boundary = tf.reduce_max(boundary_gt, axis=3, keep_dims=True)\n            #smooth_boundary = tf.slice(boundary_gt, [0, 0, 0, 0], [options.batchSize, HEIGHT, WIDTH, 1])\n            occlusion_boundary = tf.slice(boundary_gt, [0, 0, 0, 1], [options.batchSize, HEIGHT, WIDTH, 1])\n            smooth_mask = segmentation_diff + boundary - 2 * segmentation_diff * boundary + depth_diff * (boundary - occlusion_boundary)\n            margin = 0.0\n            smooth_mask = tf.nn.relu(smooth_mask - margin)\n            boundary_loss += tf.reduce_mean(smooth_mask) * 1000            \n            pass\n          \n        if options.predictBoundary:\n            #we predict boundaries directly for post-processing purpose\n            boundary_loss += tf.reduce_mean(tf.losses.sigmoid_cross_entropy(logits=global_pred_dict[\'boundary\'], multi_class_labels=boundary_gt, weights=tf.maximum(boundary_gt * 3, 1))) * 1000\n            pass\n        \n          \n        #regularization\n        l2_losses = tf.add_n([options.l2Weight * tf.nn.l2_loss(v) for v in tf.trainable_variables() if \'weights\' in v.name])\n\n\n        loss = plane_loss + segmentation_loss + depth_loss + normal_loss + plane_confidence_loss + diverse_loss + boundary_loss + local_score_loss + local_plane_loss + local_mask_loss + l2_losses\n\n        #if options.pixelwiseLoss:\n        #normal_loss = tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_normal\'], global_gt_dict[\'normal\'])) * 1000\n        #depth_loss = tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_depth\'], global_gt_dict[\'depth\']) * validDepthMask) * 1000\n        #pass\n\n        loss_dict = {\'plane\': plane_loss, \'segmentation\': segmentation_loss, \'depth\': depth_loss, \'normal\': normal_loss, \'boundary\': boundary_loss, \'diverse\': diverse_loss, \'confidence\': plane_confidence_loss, \'local_score\': local_score_loss, \'local_plane\': local_plane_loss, \'local_mask\': local_mask_loss}\n        debug_dict = {\'segmentation\': segmentation_gt, \'boundary\': boundary_gt}\n        pass\n    return loss, loss_dict, debug_dict\n    #return loss, plane_loss, depth_loss + local_score_loss + local_p_loss + local_mask_loss + boundary_loss, forward_loss, backward_loss, segmentation_gt, plane_mask, errorMask, dists\n    #return loss, plane_loss, segmentation_loss, loss_p_0, depth_loss, segmentation_test, plane_mask, errorMask, dists\n\n\ndef build_loss_rgbd(global_pred_dict, deep_pred_dicts, global_gt_dict_train, global_gt_dict_val, training_flag, options):\n    with tf.device(\'/gpu:%d\'%options.gpu_id):\n        global_gt_dict = {}\n        for name in global_gt_dict_train.keys():\n            global_gt_dict[name] = tf.cond(training_flag, lambda: global_gt_dict_train[name], lambda: global_gt_dict_val[name])\n            continue\n\n        #depth loss\n        plane_parameters = tf.reshape(global_pred_dict[\'plane\'], (-1, 3))\n        plane_depths = planeDepthsModule(plane_parameters, WIDTH, HEIGHT)\n        plane_depths = tf.transpose(tf.reshape(plane_depths, [HEIGHT, WIDTH, -1, options.numOutputPlanes]), [2, 0, 1, 3])\n\n        all_segmentations = tf.concat([global_pred_dict[\'segmentation\'], global_pred_dict[\'non_plane_mask\']], axis=3)\n        all_segmentations_softmax = tf.nn.softmax(all_segmentations)\n        all_depths = tf.concat([plane_depths, global_pred_dict[\'non_plane_depth\']], axis=3)\n        validDepthMask = tf.cast(tf.greater(global_gt_dict[\'depth\'], 1e-4), tf.float32)\n        depth_loss = tf.reduce_mean(tf.reduce_sum(tf.squared_difference(all_depths, global_gt_dict[\'depth\']) * all_segmentations_softmax, axis=3, keep_dims=True) * validDepthMask) * 1000\n\n        if options.predictPixelwise == 1:\n            depth_loss += tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_mask\'], global_gt_dict[\'depth\']) * validDepthMask) * 1000\n            pass\n        \n        #non plane mask loss\n        segmentation_loss = tf.reduce_mean(tf.slice(all_segmentations_softmax, [0, 0, 0, options.numOutputPlanes], [options.batchSize, HEIGHT, WIDTH, 1])) * 100\n        \n        l2_losses = tf.add_n([options.l2Weight * tf.nn.l2_loss(v) for v in tf.trainable_variables() if \'weights\' in v.name])\n        loss = depth_loss + segmentation_loss + l2_losses\n        loss_dict = {\'depth\': depth_loss, \'plane\': tf.constant(0.0), \'segmentation\': segmentation_loss}\n        debug_dict = {}\n        pass\n    return loss, loss_dict, debug_dict\n\n\ndef build_loss_3d(global_pred_dict, deep_pred_dicts, global_gt_dict_train, global_gt_dict_val, training_flag, options):\n    with tf.device(\'/gpu:%d\'%options.gpu_id):\n        global_gt_dict = {}\n        for name in global_gt_dict_train.keys():\n            global_gt_dict[name] = tf.cond(training_flag, lambda: global_gt_dict_train[name], lambda: global_gt_dict_val[name])\n            continue\n        # local_gt_dict = {}\n        # for name in local_gt_dict_train.keys():\n        #     local_gt_dict[name] = tf.cond(tf.equal(training_flag % 2, 0), lambda: local_gt_dict_train[name], lambda: local_gt_dict_val[name])\n        #     continue\n\n        \n        validPlaneMask = tf.cast(tf.less(tf.tile(tf.expand_dims(tf.range(options.numOutputPlanes), 0), [options.batchSize, 1]), tf.expand_dims(global_gt_dict[\'num_planes\'], -1)), tf.float32)        \n        backwardLossWeight = options.backwardLossWeight\n        \n        #plane loss and segmentation loss (summation over deep supervisions and final supervision)\n        all_pred_dicts = deep_pred_dicts + [global_pred_dict]\n        plane_loss = tf.constant(0.0)\n        segmentation_loss = tf.constant(0.0)\n        plane_confidence_loss = tf.constant(0.0)\n        diverse_loss = tf.constant(0.0)\n        \n        #keep forward map (segmentation gt) from previous supervision so that we can have same matching for all supervisions (options.sameMatching = 1)\n        previous_forward_map = None\n        previous_segmentation_gt = None\n        for pred_index, pred_dict in enumerate(all_pred_dicts):\n            if options.sameMatching and pred_index > 0:\n                #use matching from previous supervision and map ground truth planes based on the mapping\n                forward_map = previous_forward_map\n\n                #number of ground truth mapped for each prediction\n                num_matches = tf.transpose(tf.reduce_sum(forward_map, axis=1, keep_dims=True), [0, 2, 1])\n\n\n                plane_gt_shuffled = tf.transpose(tf.matmul(global_gt_dict[\'plane\'], forward_map, transpose_a=True), [0, 2, 1]) / tf.maximum(num_matches, 1e-4)\n                plane_confidence_gt = tf.cast(num_matches > 0.5, tf.float32)\n                plane_loss += tf.reduce_mean(tf.squared_difference(pred_dict[\'plane\'], plane_gt_shuffled) * plane_confidence_gt) * 10000\n\n                \n                #all segmentations is the concatenation of plane segmentations and non plane mask\n                all_segmentations = tf.concat([pred_dict[\'segmentation\'], pred_dict[\'non_plane_mask\']], axis=3)\n                segmentation_gt_shuffled = previous_segmentation_gt\n                segmentation_loss += tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=all_segmentations, labels=segmentation_gt_shuffled)) * 1000\n                \n            else:\n                #calculate new matching by finding nearest neighbors again\n                dists_forward, map_forward, dists_backward, _ = tf_nndistance.nn_distance(global_gt_dict[\'plane\'], pred_dict[\'plane\'])\n                dists_forward *= validPlaneMask\n                \n                dists_forward = tf.reduce_mean(dists_forward)\n                dists_backward = tf.reduce_mean(dists_backward)\n                plane_loss += (dists_forward + dists_backward * backwardLossWeight) * 10000\n\n                forward_map = tf.one_hot(map_forward, depth=options.numOutputPlanes, axis=-1)\n                forward_map *= tf.expand_dims(validPlaneMask, -1)\n                \n                previous_forward_map = forward_map\n                                              \n                segmentation_gt_shuffled = tf.reshape(tf.matmul(tf.reshape(global_gt_dict[\'segmentation\'], [-1, HEIGHT * WIDTH, options.numOutputPlanes]), forward_map), [-1, HEIGHT, WIDTH, options.numOutputPlanes])\n                segmentation_gt_shuffled = tf.concat([segmentation_gt_shuffled, global_gt_dict[\'non_plane_mask\']], axis=3)\n                previous_segmentation_gt = segmentation_gt_shuffled\n                \n                all_segmentations = tf.concat([pred_dict[\'segmentation\'], pred_dict[\'non_plane_mask\']], axis=3)\n                segmentation_loss += tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=all_segmentations, labels=segmentation_gt_shuffled)) * 1000\n                pass\n\n            if options.diverseLoss:\n                plane_diff = tf.reduce_sum(tf.pow(tf.expand_dims(pred_dict[\'plane\'], 1) - tf.expand_dims(pred_dict[\'plane\'], 2), 2), axis=3)\n                plane_diff = tf.matrix_set_diag(plane_diff, tf.ones((options.batchSize, options.numOutputPlanes)))\n                minPlaneDiff = 0.1\n                diverse_loss += tf.reduce_mean(tf.clip_by_value(1 - plane_diff / minPlaneDiff, 0, 1)) * 10000\n                pass\n              \n            continue\n\n\n\n        #depth loss\n        plane_parameters = tf.reshape(global_pred_dict[\'plane\'], (-1, 3))\n        plane_depths = planeDepthsModule(plane_parameters, WIDTH, HEIGHT)\n        plane_depths = tf.transpose(tf.reshape(plane_depths, [HEIGHT, WIDTH, -1, options.numOutputPlanes]), [2, 0, 1, 3])\n\n        all_segmentations_softmax = tf.nn.softmax(all_segmentations)\n        non_plane_depth = global_pred_dict[\'non_plane_depth\']\n        all_depths = tf.concat([plane_depths, non_plane_depth], axis=3)\n        validDepthMask = tf.cast(tf.greater(global_gt_dict[\'depth\'], 1e-4), tf.float32)\n        depth_loss = tf.reduce_mean(tf.reduce_sum(tf.squared_difference(all_depths, global_gt_dict[\'depth\']) * all_segmentations_softmax, axis=3, keep_dims=True) * validDepthMask) * 1000\n\n        if options.predictPixelwise == 1:\n            depth_loss += tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_mask\'], global_gt_dict[\'depth\']) * validDepthMask) * 1000\n            pass\n        normal_loss = tf.constant(0.0)\n\n        \n\n        local_score_loss = tf.constant(0.0)\n        local_plane_loss = tf.constant(0.0)\n        local_mask_loss = tf.constant(0.0)\n                \n        #boundary loss\n        boundary_loss = tf.constant(0.0)\n        \n        if False:\n            #calculate boundary ground truth on-the-fly as the calculation is subject to change\n            kernel_size = 3\n            padding = (kernel_size - 1) / 2\n            neighbor_kernel_array = gaussian(kernel_size, kernel_size)\n            neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n            neighbor_kernel_array /= neighbor_kernel_array.sum()\n            neighbor_kernel_array *= -1\n            neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 1\n            neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n            neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n        \n            depth_diff = tf.abs(tf.nn.depthwise_conv2d(global_gt_dict[\'depth\'], neighbor_kernel, strides=[1, 1, 1, 1], padding=\'VALID\'))\n            depth_diff = tf.pad(depth_diff, paddings = [[0, 0], [padding, padding], [padding, padding], [0, 0]])\n            max_depth_diff = 0.1\n            depth_boundary = tf.greater(depth_diff, max_depth_diff)\n\n            plane_region = tf.nn.max_pool(1 - global_gt_dict[\'non_plane_mask\'], ksize=[1, kernel_size, kernel_size, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n            segmentation_eroded = 1 - tf.nn.max_pool(1 - global_gt_dict[\'segmentation\'], ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n            plane_region -= tf.reduce_max(segmentation_eroded, axis=3, keep_dims=True)\n            boundary = tf.cast(depth_boundary, tf.float32) * plane_region\n            smooth_boundary = global_gt_dict[\'smooth_boundary\']\n            boundary_gt = tf.concat([smooth_boundary, tf.maximum(boundary - smooth_boundary, 0)], axis=3)\n            pass\n\n\n        if options.boundaryLoss == 1 and False:\n            all_segmentations_pred = all_segmentations_softmax\n            all_segmentations_min = 1 - tf.nn.max_pool(1 - all_segmentations_pred, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\')\n            segmentation_diff = tf.reduce_max(all_segmentations_pred - all_segmentations_min, axis=3, keep_dims=True)\n\n            depth_pred = tf.reduce_sum(tf.multiply(all_depths, all_segmentations_pred), axis=3, keep_dims=True)\n            depth_neighbor = tf.nn.depthwise_conv2d(depth_pred, neighbor_kernel, strides=[1, 1, 1, 1], padding=\'SAME\')\n            minDepthDiff = 0.02\n            depth_diff = tf.clip_by_value(tf.squared_difference(depth_pred, depth_neighbor) - pow(minDepthDiff, 2), 0, 1)\n\n            boundary = tf.reduce_max(boundary_gt, axis=3, keep_dims=True)\n            smooth_boundary = tf.slice(boundary_gt, [0, 0, 0, 0], [options.batchSize, HEIGHT, WIDTH, 1])\n            smooth_mask = segmentation_diff + boundary - 2 * segmentation_diff * boundary + depth_diff * smooth_boundary\n            margin = 0.0\n            smooth_mask = tf.nn.relu(smooth_mask - margin)\n            #boundary_loss += tf.reduce_mean(smooth_mask * plane_mask) * 1000\n            boundary_loss += tf.reduce_mean(smooth_mask) * 1000            \n            pass\n          \n        # if options.predictBoundary:\n        #     #we predict boundaries directly for post-processing purpose\n        #     boundary_loss += tf.reduce_mean(tf.losses.sigmoid_cross_entropy(logits=global_pred_dict[\'boundary\'], multi_class_labels=boundary_gt, weights=tf.maximum(global_gt_dict[\'boundary\'] * 3, 1))) * 1000\n\n          \n        #regularization\n        l2_losses = tf.add_n([options.l2Weight * tf.nn.l2_loss(v) for v in tf.trainable_variables() if \'weights\' in v.name])\n\n\n        loss = plane_loss + segmentation_loss + depth_loss + normal_loss + plane_confidence_loss + diverse_loss + boundary_loss + local_score_loss + local_plane_loss + local_mask_loss + l2_losses\n\n        #if options.pixelwiseLoss:\n        #normal_loss = tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_normal\'], global_gt_dict[\'normal\'])) * 1000\n        #depth_loss = tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_depth\'], global_gt_dict[\'depth\']) * validDepthMask) * 1000\n        #pass\n\n        loss_dict = {\'plane\': plane_loss, \'segmentation\': segmentation_loss, \'depth\': depth_loss, \'normal\': normal_loss, \'boundary\': boundary_loss, \'diverse\': diverse_loss, \'confidence\': plane_confidence_loss, \'local_score\': local_score_loss, \'local_plane\': local_plane_loss, \'local_mask\': local_mask_loss}\n        debug_dict = {\'segmentation\': global_gt_dict[\'segmentation\']}\n        pass\n    return loss, loss_dict, debug_dict\n\n\ndef main(options):\n    if not os.path.exists(options.checkpoint_dir):\n        os.system(""mkdir -p %s""%options.checkpoint_dir)\n        pass\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n    \n    min_after_dequeue = 1000\n\n    # reader_train = RecordReader()\n    # #filename_queue_train = tf.train.string_input_producer([\'/mnt/vision/SUNCG_plane/planes_test_450000.tfrecords\'], num_epochs=10000)\n    # filename_queue_train = tf.train.string_input_producer([\'/media/chenliu/My Passport/planes_test_450000.tfrecords\'], num_epochs=10000)\n    # img_inp_train, global_gt_dict_train, local_gt_dict_train = reader_train.getBatch(filename_queue_train, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True)\n\n    # reader_val = RecordReader()\n    # filename_queue_val = tf.train.string_input_producer([\'/home/chenliu/Projects/Data/SUNCG_plane/planes_test_1000_450000.tfrecords\'], num_epochs=10000)\n    # img_inp_val, global_gt_dict_val, local_gt_dict_val = reader_val.getBatch(filename_queue_val, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True)\n\n    # reader_rgbd_train = RecordReaderRGBD()\n    # filename_queue_rgbd_train = tf.train.string_input_producer([\'../planes_nyu_rgbd_train.tfrecords\'], num_epochs=10000)\n    # img_inp_rgbd_train, global_gt_dict_rgbd_train, local_gt_dict_rgbd_train = reader_rgbd_train.getBatch(filename_queue_rgbd_train, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True)\n\n    # reader_rgbd_val = RecordReaderRGBD()\n    # filename_queue_rgbd_val = tf.train.string_input_producer([\'../planes_nyu_rgbd_val.tfrecords\'], num_epochs=10000)\n    # img_inp_rgbd_val, global_gt_dict_rgbd_val, local_gt_dict_rgbd_val = reader_rgbd_val.getBatch(filename_queue_rgbd_val, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True)\n\n\n    reader_train = RecordReader3D()\n    filename_queue_train = tf.train.string_input_producer([\'../planes_matterport_train.tfrecords\'], num_epochs=10000)    \n    img_inp_train, global_gt_dict_train, local_gt_dict_train = reader_train.getBatch(filename_queue_train, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True)\n\n    reader_val = RecordReader3D()\n    filename_queue_val = tf.train.string_input_producer([\'../planes_matterport_val.tfrecords\'], num_epochs=10000)    \n    img_inp_val, global_gt_dict_val, local_gt_dict_val = reader_val.getBatch(filename_queue_val, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True)\n\n    \n    training_flag = tf.placeholder(tf.bool, shape=[], name=\'training_flag\')\n    \n    #global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp_train, img_inp_val, img_inp_rgbd_train, img_inp_rgbd_val, img_inp_3d_train, img_inp_3d_val, training_flag, options)\n    global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp_train, img_inp_val, training_flag, options)\n    \n    var_to_restore = [v for v in tf.global_variables()]\n\n    \n    #loss, loss_dict, _ = build_loss(global_pred_dict, local_pred_dict, deep_pred_dicts, global_gt_dict_train, local_gt_dict_train, global_gt_dict_val, local_gt_dict_val, training_flag, options)\n    #loss_rgbd, loss_dict_rgbd, _ = build_loss_rgbd(global_pred_dict, deep_pred_dicts, global_gt_dict_rgbd_train, global_gt_dict_rgbd_val, training_flag, options)\n    loss, loss_dict, _ = build_loss_3d(global_pred_dict, deep_pred_dicts, global_gt_dict_train, global_gt_dict_val, training_flag, options)    \n        \n    #loss = tf.cond(tf.less(training_flag, 2), lambda: loss, lambda: tf.cond(tf.less(training_flag, 4), lambda: loss_rgbd, lambda: loss_3d))\n\n    \n    train_writer = tf.summary.FileWriter(options.log_dir + \'/train\')\n    val_writer = tf.summary.FileWriter(options.log_dir + \'/val\')\n    train_writer_rgbd = tf.summary.FileWriter(options.log_dir + \'/train_rgbd\')\n    val_writer_rgbd = tf.summary.FileWriter(options.log_dir + \'/val_rgbd\')\n    writers = [train_writer, val_writer, train_writer_rgbd, val_writer_rgbd]\n    \n    tf.summary.scalar(\'loss\', loss)\n    summary_op = tf.summary.merge_all()\n\n    with tf.variable_scope(\'statistics\'):\n        batchno = tf.Variable(0, dtype=tf.int32, trainable=False, name=\'batchno\')\n        batchnoinc=batchno.assign(batchno+1)\n        pass\n\n\n    optimizer = tf.train.AdamOptimizer(options.LR)\n    train_op = optimizer.minimize(loss, global_step=batchno)\n\n    \n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n    saver=tf.train.Saver()\n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n        if options.restore == 0:\n            #fine-tune from DeepLab model\n            var_to_restore = [v for v in var_to_restore if \'res5d\' not in v.name and \'segmentation\' not in v.name and \'plane\' not in v.name and \'deep_supervision\' not in v.name and \'local\' not in v.name and \'boundary\' not in v.name and \'degridding\' not in v.name and \'res2a_branch2a\' not in v.name and \'res2a_branch1\' not in v.name]\n            pretrained_model_loader = tf.train.Saver(var_to_restore)\n            pretrained_model_loader.restore(sess,""../pretrained_models/deeplab_resnet.ckpt"")\n        elif options.restore == 1:\n            #restore the same model from checkpoint\n            loader = tf.train.Saver(var_to_restore)\n            loader.restore(sess,""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n            bno=sess.run(batchno)\n            print(bno)\n        elif options.restore == 2:            \n            #restore the same model from checkpoint but reset batchno to 1\n            loader = tf.train.Saver(var_to_restore)\n            loader.restore(sess,""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n            sess.run(batchno.assign(1))\n        elif options.restore == 3:            \n            #restore the same model from standard training\n            if options.predictBoundary == 1:\n                var_to_restore = [v for v in var_to_restore if \'boundary\' not in v.name]\n                pass            \n            if options.predictConfidence == 1:\n                var_to_restore = [v for v in var_to_restore if \'confidence\' not in v.name]\n                pass\n            \n            loader = tf.train.Saver(var_to_restore)\n            loader.restore(sess,""checkpoint/planenet_hybrid1/checkpoint.ckpt"")\n            #loader.restore(sess,""checkpoint/planenet/checkpoint.ckpt"")\n            sess.run(batchno.assign(1))\n        elif options.restore == 4:\n            #fine-tune another model\n            var_to_restore = [v for v in var_to_restore if \'res4b22_relu_non_plane\' not in v.name]\n            loader = tf.train.Saver(var_to_restore)\n            loader.restore(sess, options.fineTuningCheckpoint)\n            sess.run(batchno.assign(1))\n            pass\n        # Start input enqueue threads.\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n        MOVING_AVERAGE_DECAY = 0.99\n        ema = [0., 0., 0., 0.]\n        ema_acc = [1e-10, 1e-10, 1e-10, 1e-10]\n        last_snapshot_time = time.time()\n        bno=sess.run(batchno)\n\n        try:\n            while bno<300000:\n                t0 = time.time()\n\n                batchIndexPeriod = bno % 100\n                if batchIndexPeriod < len(options.hybrid):\n                    #batchType = int(options.hybrid[batchIndexPeriod]) * 2 + 1\n                    batchType = 1\n                else:\n                    batchType = 0\n                    pass\n\n                _, total_loss, losses, summary_str = sess.run([train_op, loss, loss_dict, summary_op], feed_dict = {training_flag: batchType == 0})\n                writers[batchType].add_summary(summary_str, bno)\n                ema[batchType] = ema[batchType] * MOVING_AVERAGE_DECAY + total_loss\n                ema_acc[batchType] = ema_acc[batchType] * MOVING_AVERAGE_DECAY + 1\n\n                bno = sess.run(batchno)\n                if time.time()-last_snapshot_time > 900:\n                    print(\'save snapshot\')\n                    saver.save(sess,\'%s/checkpoint.ckpt\'%options.checkpoint_dir)\n                    last_snapshot_time = time.time()\n                    pass\n        \n                print bno,\'train\', ema[0] / ema_acc[0], \'val\', ema[1] / ema_acc[1], \'train rgbd\', ema[2] / ema_acc[2], \'val rgbd\', ema[3] / ema_acc[3], \'loss\', total_loss, \'time\', time.time()-t0\n\n                if np.random.random() < 0.01:\n                    print(losses)\n                    pass                \n                continue\n\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n        \n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return\n\n\ndef test(options):\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n    \n    options.batchSize = 1\n    min_after_dequeue = 1000\n\n    if options.dataset == \'SUNCG\':\n        reader = RecordReader()\n        filename_queue = tf.train.string_input_producer([\'/home/chenliu/Projects/Data/SUNCG_plane/planes_test_1000_450000.tfrecords\'], num_epochs=10000)\n        img_inp, global_gt_dict, local_gt_dict = reader.getBatch(filename_queue, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True, random=False)\n    elif options.dataset == \'NYU_RGBD\':\n        reader = RecordReaderRGBD()\n        filename_queue = tf.train.string_input_producer([\'../planes_nyu_rgbd_val.tfrecords\'], num_epochs=1)\n        img_inp, global_gt_dict, local_gt_dict = reader.getBatch(filename_queue, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True, random=False)\n\n        options.deepSupervision = 0\n        options.predictLocal = 0\n    else:\n        reader = RecordReader3D()\n        filename_queue = tf.train.string_input_producer([\'../planes_matterport_val.tfrecords\'], num_epochs=1)\n        img_inp, global_gt_dict, local_gt_dict = reader.getBatch(filename_queue, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True, random=False)\n        \n        options.deepSupervision = 0\n        options.predictLocal = 0        \n        pass\n\n    training_flag = tf.constant(False, tf.bool)\n\n    global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp, img_inp, training_flag, options)\n    var_to_restore = tf.global_variables()\n\n    if options.dataset == \'SUNCG\':\n        loss, loss_dict, debug_dict = build_loss(global_pred_dict, local_pred_dict, deep_pred_dicts, global_gt_dict, local_gt_dict, global_gt_dict, local_gt_dict, training_flag, options)\n    elif options.dataset == \'NYU_RGBD\':\n        loss, loss_dict, debug_dict = build_loss_rgbd(global_pred_dict, deep_pred_dicts, global_gt_dict, global_gt_dict, training_flag, options)\n    else:\n        loss, loss_dict, debug_dict = build_loss_3d(global_pred_dict, deep_pred_dicts, global_gt_dict, global_gt_dict, training_flag, options)\n        pass\n\n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n    \n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n        #var_to_restore = [v for v in var_to_restore if \'res4b22_relu_non_plane\' not in v.name]\n        loader = tf.train.Saver(var_to_restore)\n        loader.restore(sess, ""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n        #loader.restore(sess, options.fineTuningCheckpoint)\n        \n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n        \n        \n        try:\n            gtDepths = []\n            predDepths = []\n            planeMasks = []\n            #predMasks = []\n            gtPlanes = []\n            predPlanes = []\n            gtSegmentations = []\n            predSegmentations = []\n            gtNumPlanes = []\n            \n            imageWidth = WIDTH\n            imageHeight = HEIGHT\n            focalLength = 517.97\n            urange = np.arange(imageWidth).reshape(1, -1).repeat(imageHeight, 0) - imageWidth * 0.5\n            vrange = np.arange(imageHeight).reshape(-1, 1).repeat(imageWidth, 1) - imageHeight * 0.5\n            ranges = np.array([urange / imageWidth * 640 / focalLength, np.ones(urange.shape), -vrange / imageHeight * 480 / focalLength]).transpose([1, 2, 0])\n\n\n            for index in xrange(10):\n                print((\'image\', index))\n                t0=time.time()\n\n                img, global_gt, local_gt, global_pred, local_pred, deep_preds, total_loss, losses, debug = sess.run([img_inp, global_gt_dict, local_gt_dict, global_pred_dict, local_pred_dict, deep_pred_dicts, loss, loss_dict, debug_dict])\n\n                # print(options.test_dir)\n                # cv2.imwrite(options.test_dir + \'/depth.png\', drawDepthImage(debug[\'depth\'][0]))\n                # cv2.imwrite(options.test_dir + \'/normal.png\', drawNormalImage(debug[\'normal\'][0]))\n                # boundary = debug[\'boundary\'][0]\n                # boundary = np.concatenate([boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)\n                # cv2.imwrite(options.test_dir + \'/boundary.png\', drawMaskImage(boundary))\n                # cv2.imwrite(options.test_dir + \'/depth_gt.png\', drawDepthImage(debug[\'depth_gt\'][0].squeeze()))\n                # cv2.imwrite(options.test_dir + \'/segmentation.png\', drawSegmentationImage(debug[\'segmentation\'][0]))\n                # exit(1)\n\n                if \'pixelwise\' in options.suffix:\n                    image = ((img[0] + 0.5) * 255).astype(np.uint8)\n                    gt_d = global_gt[\'depth\'].squeeze()\n                    pred_d = global_pred[\'non_plane_depth\'].squeeze()\n                    #depth = global_gt[\'depth\'].squeeze()\n                    if \'_2\' in options.suffix:\n                        pred_p, pred_s, pred_d = fitPlanes(pred_d, numPlanes=20, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=0.2)\n                    elif \'_3\' in options.suffix:\n                        pred_p, pred_s, pred_d = fitPlanes(gt_d, numPlanes=20, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=0.2)\n                        pass\n\n                    # gt_p = global_gt[\'plane\'][0]\n                    # pred_p = planes\n                    # valid_mask = (np.linalg.norm(gt_p, axis=1) > 0).astype(np.float32)\n                    # diff = np.min(np.linalg.norm(np.expand_dims(gt_p, 1) - np.expand_dims(pred_p, 0), axis=2), 1)\n                    # num += valid_mask.sum()\n                    # lossSum += (diff * valid_mask).sum()\n                    if options.dataset == \'SUNCG\':\n                        planeMask = np.squeeze(debug[\'segmentation\']).sum(axis=2)\n                    else:\n                        planeMask = np.ones((HEIGHT, WIDTH))\n                        if \'_2\' in options.suffix or \'_3\' in options.suffix:\n                            planeMask *= (pred_s < 20).astype(np.float32)\n                        pass\n                    \n                    if index < 10:\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', image)\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth.png\', drawDepthImage(gt_d))\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n                        if \'_2\' in options.suffix or \'_3\' in options.suffix:\n                            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(pred_s))\n                            pass\n                        #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_plane_mask.png\', drawMaskImage(planeMask))                \n                        pass\n\n                        \n                    gtDepths.append(gt_d)\n                    predDepths.append(pred_d)\n                    planeMasks.append(planeMask)\n\n\n                    if options.dataset != \'NYU_RGBD\' and (\'_2\' in options.suffix or \'_3\' in options.suffix):\n                        gt_p = global_gt[\'plane\'][0]\n                        gt_s = debug[\'segmentation\'][0]\n                        gt_num_p = global_gt[\'num_planes\'][0]\n\n                        pred_s = (np.expand_dims(pred_s, -1) == np.reshape(np.arange(options.numOutputPlanes), [1, 1, -1])).astype(np.float32)\n                        gtPlanes.append(gt_p)\n                        predPlanes.append(pred_p)\n                        gtSegmentations.append(gt_s)\n                        gtNumPlanes.append(gt_num_p)\n                        predSegmentations.append(pred_s)\n                        pass\n                    \n                    #planeMasks.append((planeSegmentation < 20).astype(np.float32))\n                    continue\n                \n                print((losses[\'plane\'], losses[\'segmentation\'], losses[\'depth\']))\n                  \n                im = img[0]\n                image = ((im + 0.5) * 255).astype(np.uint8)                \n\n                gt_d = global_gt[\'depth\'].squeeze()\n                \n                if \'normal\' in global_gt:\n                    gt_n = global_gt[\'normal\'][0]\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal.png\', drawNormalImage(gt_n))\n                    pass\n                  \n\n                if options.predictLocal:\n                    pred_local_s = 1 / (1 + np.exp(-local_pred[\'score\'][0]))\n                    pred_local_p = local_pred[\'plane\'][0]\n                    pred_local_m = local_pred[\'mask\'][0]\n                  \n                    gt_local_s = local_gt[\'score\'][0]\n                    gt_local_m = local_gt[\'mask\'][0]\n\n                    #visualize local plane prediction\n                    stride = 8\n                    boxSize = 64\n                    xs = np.arange(WIDTH / stride) * stride + stride / 2\n                    ys = np.arange(HEIGHT / stride) * stride + stride / 2\n                    padding = boxSize / 2 + 1\n                    maskImage = np.zeros((HEIGHT + padding * 2, WIDTH + padding * 2, 3), dtype=np.uint8)\n                    maskImage[padding:padding + HEIGHT, padding:padding + WIDTH, :] = image / 2\n                    for gridY, y in enumerate(ys):\n                        for gridX, x in enumerate(xs):\n                            score = pred_local_s[gridY][gridX]\n                            if score < 0.5:\n                                continue                              \n                            mask = pred_local_m[gridY][gridX].reshape([16, 16])        \n                            mask = cv2.resize(mask, (boxSize, boxSize))\n                            maskImage[y - boxSize / 2 + padding:y + boxSize / 2 + padding, x - boxSize / 2 + padding:x + boxSize / 2 + padding, 0][mask > 0.5] = 255\n                            continue\n                        continue\n                    for gridY, y in enumerate(ys):\n                        for gridX, x in enumerate(xs):\n                            score = gt_local_s[gridY][gridX]\n                            if score < 0.5:\n                                continue                              \n                            mask = gt_local_m[gridY][gridX].reshape([16, 16])        \n                            mask = cv2.resize(mask, (boxSize, boxSize))\n                            maskImage[y - boxSize / 2 + padding:y + boxSize / 2 + padding, x - boxSize / 2 + padding:x + boxSize / 2 + padding, 2][mask > 0.5] = 255\n                            continue\n                        continue\n                    pass\n\n                pred_p = global_pred[\'plane\'][0]\n                pred_s = global_pred[\'segmentation\'][0]\n\n                pred_np_m = global_pred[\'non_plane_mask\'][0]\n                pred_np_d = global_pred[\'non_plane_depth\'][0]\n                pred_np_n = global_pred[\'non_plane_normal\'][0]\n                \n                if \'plane_mask\' in debug:\n                    planeMask = np.squeeze(debug[\'plane_mask\'])\n                else:\n                    #planeMask = np.ones((HEIGHT, WIDTH))\n                    planeMask = (np.max(pred_s, axis=2) > pred_np_m.squeeze()).astype(np.float32)\n                    pass\n\n\n\n                all_segmentations = np.concatenate([pred_np_m, pred_s], axis=2)\n                plane_depths = calcPlaneDepths(pred_p, WIDTH, HEIGHT)\n                all_depths = np.concatenate([pred_np_d, plane_depths], axis=2)\n\n                segmentation = np.argmax(all_segmentations, 2)\n                pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape(HEIGHT, WIDTH)\n\n                if False:\n                    gt_p = global_gt[\'plane\'][0]\n                    gt_s = debug[\'segmentation\'][0]\n                    gt_num_p = global_gt[\'num_planes\'][0]                    \n\n                    planesD = np.linalg.norm(gt_p, axis=1, keepdims=True)\n                    gt_p = gt_p / pow(np.maximum(planesD, 1e-4), 2)\n                    print(gt_p)\n                    gt_p = transformPlanes(gt_p, None)\n                    print(gt_p)\n                    plane_depths = calcPlaneDepths(gt_p, WIDTH, HEIGHT)\n                    segmentation = np.argmax(gt_s, 2)\n                    for planeIndex in xrange(options.numOutputPlanes):\n                        mask = gt_s[:, :, planeIndex]\n                        if mask.sum() > 0:\n                            cv2.imwrite(options.test_dir + \'/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(mask))\n                            pass\n                        continue\n                    pred_d = plane_depths.reshape(-1, options.numOutputPlanes)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape(HEIGHT, WIDTH)\n                    print(np.max(pred_d))\n                    print(pred_d[60][120])\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n                    exit(1)\n                    pass\n\n                if False:\n                    gt_s = debug[\'segmentation\'][0]\n                    all_segmentations = np.concatenate([pred_np_m, gt_s], axis=2)\n                    gt_p = global_gt[\'plane\'][0]\n\n                    valid_mask = (np.linalg.norm(gt_p, axis=1) > 0).astype(np.float32)\n                    diff = np.min(np.linalg.norm(np.expand_dims(gt_p, 1) - np.expand_dims(pred_p, 0), axis=2), 1)\n                    num += valid_mask.sum()\n                    lossSum += (diff * valid_mask).sum()\n                    \n                    plane_depths = calcPlaneDepths(gt_p, WIDTH, HEIGHT)\n                    all_depths = np.concatenate([pred_np_d, plane_depths], axis=2)\n\n                    segmentation = np.argmax(all_segmentations, 2)\n                    pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape(HEIGHT, WIDTH)\n                    pass\n\n                \n\n                if options.dataset != \'NYU_RGBD\':\n                    gt_p = global_gt[\'plane\'][0]\n                    gt_s = debug[\'segmentation\'][0]\n                    gt_num_p = global_gt[\'num_planes\'][0]\n                    gtPlanes.append(gt_p)\n                    predPlanes.append(pred_p)\n                    gtSegmentations.append(gt_s)\n                    gtNumPlanes.append(gt_num_p)\n                    predSegmentations.append(pred_s)\n                    pass\n            \n                gtDepths.append(gt_d)\n                #planeMask = np.ones(planeMask.shape)\n                planeMasks.append(planeMask)\n                predDepths.append(pred_d)\n                evaluateDepths(predDepths[-1], gtDepths[-1], np.ones(planeMasks[-1].shape), planeMasks[-1])\n                \n                \n                if index >= 10:\n                    continue\n                \n                if \'segmentation\' in global_gt:\n                    gt_s = global_gt[\'segmentation\'][0]\n                    #print(np.unique(np.argmax(global_gt[\'segmentation\'][0], axis=2)))\n                    #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_gt.png\', drawSegmentationImage(gt_s, planeMask=planeMask, numColors = 51))\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_gt.png\', drawSegmentationImage(gt_s))\n                    #exit(1)\n                    pass\n\n                if \'non_plane_mask\' in global_gt:\n                    gt_np_m = global_gt[\'non_plane_mask\'][0]\n                    #print(np.unique(np.argmax(global_gt[\'segmentation\'][0], axis=2)))\n                    #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_gt.png\', drawSegmentationImage(gt_s, planeMask=planeMask, numColors = 51))\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_non_plane_mask_gt.png\', drawMaskImage(gt_np_m))\n                    exit(1)\n                    pass\n                \n\n                if options.predictConfidence == 1 and options.dataset == \'SUNCG\':\n                    pred_p_c = global_pred[\'confidence\'][0]\n                    pred_p_c = 1 / (1 + np.exp(-pred_p_c))\n                    #print(pred_p_c)\n                    # print(losses)\n                    # print(debug[\'plane\'][0])\n                    # print(pred_p)\n                    # exit(1)\n                    numPlanes = global_gt[\'num_planes\'][0]\n                    print((numPlanes, (pred_p_c > 0.5).sum()))\n                    \n                    pred_p_c = (pred_p_c > 0.5).astype(np.float32)\n                    pred_p *= pred_p_c\n                    pred_s -= (1 - pred_p_c.reshape([1, 1, options.numOutputPlanes])) * 10\n                    pass\n                  \n                if False:\n                    #dump results for post processing\n                    if index >= 10:\n                        break\n                    np.save(options.dump_dir + \'/planes_\' + str(index) + \'.npy\', pred_p)\n                    np.save(options.dump_dir + \'/segmentations_\' + str(index) + \'.npy\', pred_s)\n                    np.save(options.dump_dir + \'/segmentations_gt_\' + str(index) + \'.npy\', gt_s)\n                    np.save(options.dump_dir + \'/non_plane_depth_\' + str(index) + \'.npy\', pred_np_d)\n                    np.save(options.dump_dir + \'/non_plane_segmentation_\' + str(index) + \'.npy\', pred_np_m)\n                    boundary = pred_boundary[0]\n                    boundary = 1 / (1 + np.exp(-boundary))\n                    boundary = np.concatenate([boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)                    \n                    cv2.imwrite(options.dump_dir + \'/boundary_\' + str(index) + \'.png\', drawMaskImage(boundary))\n                    cv2.imwrite(options.dump_dir + \'/image_\' + str(index) + \'.png\', cv2.resize(image, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR))\n                    np.save(options.dump_dir + \'/depth_\' + str(index) + \'.npy\', gt_d)\n                    continue                \n\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', image)\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth.png\', drawDepthImage(gt_d))\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_overlay.png\', drawDepthImageOverlay(image, gt_d))\n                \n                if options.predictBoundary:\n                    pred_boundary = global_pred[\'boundary\'][0]\n                    pred_boundary = 1 / (1 + np.exp(-pred_boundary))\n                    boundary = np.concatenate([pred_boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_boundary_pred.png\', drawMaskImage(boundary))\n                    pass\n\n                if \'boundary\' in debug:\n                    gt_boundary = debug[\'boundary\'][0]\n                    boundary = np.concatenate([gt_boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)                \n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_boundary_gt.png\', drawMaskImage(boundary))\n                    pass\n\n\n                if options.deepSupervision >= 1:\n                    segmentation_deep = np.argmax(deep_preds[0][\'segmentation\'][0], 2)\n                    segmentation_deep[segmentation_deep == options.numOutputPlanes] = -1\n                    segmentation_deep += 1\n                \n                    plane_depths_deep = calcPlaneDepths(deep_preds[0][\'plane\'][0], WIDTH, HEIGHT)\n                    all_depths_deep = np.concatenate([pred_np_d, plane_depths_deep], axis=2)\n                    pred_d_deep = all_depths_deep.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation_deep.reshape(-1)].reshape(HEIGHT, WIDTH)\n                \n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred_0.png\', drawSegmentationImage(deep_preds[0][\'segmentation\'][0]))\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred_0.png\', drawDepthImage(pred_d_deep))\n                    pass\n\n\n                #print(pred_np_m)\n                #print(pred_s)\n                #print(global_gt[\'plane\'][0])\n                #print(pred_p)\n                #exit(1)\n                \n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(all_segmentations))\n                exit(1)\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_plane_mask.png\', drawMaskImage(planeMask))                \n\n                #print(np.concatenate([np.arange(options.numOutputPlanes).reshape(-1, 1), planes, pred_p, preds_p[0][0]], axis=1))\n\n                #print(np.concatenate([distance[0], preds_p[0][0], pred_p], axis=1))\n                            \n                #segmentation = np.argmax(pred_s, 2)\n                #writePLYFile(options.test_dir, index, image, pred_d, segmentation, np.zeros(pred_boundary[0].shape))\n                #writePLYFileParts(options.test_dir, index, image, pred_d, segmentation)\n                #gt_s_ori = gt_s_ori[0]\n                #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_gt_ori.png\', drawSegmentationImage(gt_s_ori, planeMask=np.max(gt_s_ori, 2) > 0.5, numColors=51))\n                \n                if False:\n                    #distance = distance[0]\n                    print(distance)\n                    diff = np.linalg.norm(np.expand_dims(planes, 1) - np.expand_dims(pred_p, 0), axis=2)\n                    print(np.concatenate([planes, pred_p, pow(np.min(diff, axis=1, keepdims=True), 2), np.expand_dims(np.argmin(diff, axis=1), -1)], axis=1))\n                    print(pred_p_c)\n                    \n                    #print(distance[:, 6:8].sum(0))\n                    #print(pow(np.linalg.norm(distance[:, :3] - distance[:, 3:6], 2, 1), 2) * 100)\n                    #print(test)\n                    segmentation = np.argmax(all_segmentations, 2) - 1\n                    for planeIndex in xrange(options.numOutputPlanes):\n                        cv2.imwrite(options.test_dir + \'/segmentation_\' + str(planeIndex) + \'.png\', drawMaskImage(segmentation == planeIndex))\n                        cv2.imwrite(options.test_dir + \'/segmentation_\' + str(planeIndex) + \'_gt.png\', drawMaskImage(gt_s[:, :, planeIndex]))\n                        cv2.imwrite(options.test_dir + \'/segmentation_\' + str(planeIndex) + \'_gt_ori.png\', drawMaskImage(gt_s_ori[:, :, planeIndex]))\n                        continue\n                    exit(1)\n                continue\n\n            if options.dataset != \'NYU_RGBD\':\n                if \'pixelwise\' not in options.suffix:\n                    evaluatePlaneSegmentation(np.array(predPlanes), np.array(predSegmentations), np.array(gtPlanes), np.array(gtSegmentations), np.array(gtNumPlanes), planeDistanceThreshold = 0.3, IOUThreshold = 0.5, prefix=\'test/planenet_\')\n                elif \'_2\' in options.suffix:\n                    evaluatePlaneSegmentation(np.array(predPlanes), np.array(predSegmentations), np.array(gtPlanes), np.array(gtSegmentations), np.array(gtNumPlanes), planeDistanceThreshold = 0.3, IOUThreshold = 0.5, prefix=\'test/pixelwise_pred_\')\n                elif \'_3\' in options.suffix:\n                    evaluatePlaneSegmentation(np.array(predPlanes), np.array(predSegmentations), np.array(gtPlanes), np.array(gtSegmentations), np.array(gtNumPlanes), planeDistanceThreshold = 0.3, IOUThreshold = 0.5, prefix=\'test/pixelwise_gt_\')\n                    pass\n                pass\n            \n            predDepths = np.array(predDepths)\n            gtDepths = np.array(gtDepths)\n            planeMasks = np.array(planeMasks)\n            #predMasks = np.array(predMasks)\n            evaluateDepths(predDepths, gtDepths, np.ones(planeMasks.shape, dtype=np.bool), planeMasks)\n            exit(1)\n\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n        \n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return\n\n\ndef predict(options):\n    options.test_dir += \'_predict\'\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n\n    batchSize = 1\n    img_inp = tf.placeholder(tf.float32,shape=(batchSize,HEIGHT,WIDTH,3),name=\'img_inp\')\n    plane_gt=tf.placeholder(tf.float32,shape=(batchSize,options.numOutputPlanes, 3),name=\'plane_inp\')\n    validating_inp = tf.constant(0, tf.int32)\n\n    global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp_train, img_inp_val, img_inp_rgbd_train, img_inp_rgbd_val, training_flag, options)\n\n    var_to_restore = tf.global_variables()\n    \n \n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n\n\n    if dataset == \'SUNCG\':\n        image_list_file = os.path.join(\'../PythonScripts/SUNCG/image_list_100_tail_500000.txt\')\n        with open(image_list_file) as f:\n            im_names = [{\'image\': im_name.strip().replace(\'plane_global.npy\', \'mlt.png\'), \'depth\': im_name.strip().replace(\'plane_global.npy\', \'depth.png\'), \'normal\': im_name.strip().replace(\'plane_global.npy\', \'norm_camera.png\'), \'valid\': im_name.strip().replace(\'plane_global.npy\', \'valid.png\'), \'plane\': im_name.strip()} for im_name in f.readlines()]\n            pass\n    else:\n        im_names = glob.glob(\'../../Data/NYU_RGBD/*_color.png\')\n        im_names = [{\'image\': im_name, \'depth\': im_name.replace(\'color.png\', \'depth.png\'), \'normal\': im_name.replace(\'color.png\', \'norm_camera.png\'), \'invalid_mask\': im_name.replace(\'color.png\', \'valid.png\')} for im_name in im_names]\n        pass\n      \n    if numImages > 0:\n        im_names = im_names[:numImages]\n        pass\n\n    #if args.imageIndex > 0:\n    #im_names = im_names[args.imageIndex:args.imageIndex + 1]\n    #pass    \n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n\n    with tf.Session(config=config) as sess:\n        saver = tf.train.Saver()\n        #sess.run(tf.global_variables_initializer())\n        saver.restore(sess,""%s/%s.ckpt""%(options.checkpoint_dir,keyname))\n\n        gtDepths = []\n        predDepths = []\n        segmentationDepths = []\n        predDepthsOneHot = []\n        planeMasks = []\n        predMasks = []\n\n        imageWidth = WIDTH\n        imageHeight = HEIGHT\n        focalLength = 517.97\n        urange = np.arange(imageWidth).reshape(1, -1).repeat(imageHeight, 0) - imageWidth * 0.5\n        vrange = np.arange(imageHeight).reshape(-1, 1).repeat(imageWidth, 1) - imageHeight * 0.5\n        ranges = np.array([urange / focalLength, np.ones(urange.shape), -vrange / focalLength]).transpose([1, 2, 0])\n        \n        cv2.imwrite(options.test_dir + \'/one.png\', np.ones((HEIGHT, WIDTH), dtype=np.uint8) * 255)\n        cv2.imwrite(options.test_dir + \'/zero.png\', np.zeros((HEIGHT, WIDTH), dtype=np.uint8) * 255)\n        for index, im_name in enumerate(im_names):\n            if index <= -1:\n                continue\n            print(im_name[\'image\'])\n            im = cv2.imread(im_name[\'image\'])\n            image = im.astype(np.float32, copy=False)\n            image = image / 255 - 0.5\n            image = cv2.resize(image, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n\n            #planes = np.load(im_name[\'plane\'])\n            # numPlanes = planes.shape[0]\n            # if numPlanes > options.numOutputPlanes:\n            #     planeAreas = planes[:, 3:].sum(1)\n            #     sortInds = np.argsort(planeAreas)[::-1]\n            #     planes = planes[sortInds[:options.numOutputPlanes]]\n            #     pass\n            # gt_p = np.zeros((1, options.numOutputPlanes, 3))\n            # gt_p[0, :numPlanes] = planes[:numPlanes, :3]\n\n            normal = np.array(PIL.Image.open(im_name[\'normal\'])).astype(np.float) / 255 * 2 - 1\n            norm = np.linalg.norm(normal, 2, 2)\n            for c in xrange(3):\n                normal[:, :, c] /= norm\n                continue\n            normal = cv2.resize(normal, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n            \n            depth = np.array(PIL.Image.open(im_name[\'depth\'])).astype(np.float) / 1000\n            depth = cv2.resize(depth, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n\n            invalid_mask = cv2.resize(cv2.imread(im_name[\'invalid_mask\'], 0), (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR) > 128\n\n            gtDepths.append(depth)\n\n            \n            pred_p, pred_d, pred_n, pred_s, pred_np_m, pred_np_d, pred_np_n, pred_boundary, pred_local_score, pred_local_p, pred_local_mask = sess.run([plane_pred, depth_pred, normal_pred, segmentation_pred, non_plane_mask_pred, non_plane_depth_pred, non_plane_normal_pred, boundary_pred, local_score_pred, local_p_pred, local_mask_pred], feed_dict = {img_inp:np.expand_dims(image, 0), plane_gt: np.zeros((batchSize, options.numOutputPlanes, 3))})\n\n\n            pred_s = pred_s[0] \n            pred_p = pred_p[0]\n            pred_np_m = pred_np_m[0]\n            pred_np_d = pred_np_d[0]\n            pred_np_n = pred_np_n[0]\n            #pred_s = 1 / (1 + np.exp(-pred_s))\n\n            plane_depths = calcPlaneDepths(pred_p, WIDTH, HEIGHT)\n            all_depths = np.concatenate([pred_np_d, plane_depths], axis=2)\n\n            all_segmentations = np.concatenate([pred_np_m, pred_s], axis=2)\n            segmentation = np.argmax(all_segmentations, 2)\n            if suffix != \'pixelwise\':\n                pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape(HEIGHT, WIDTH)\n            else:\n                pred_d = np.squeeze(pred_np_d)\n                pass\n            predDepths.append(pred_d)\n            predMasks.append(segmentation != 0)\n            planeMasks.append(invalid_mask)\n\n            #depthError, normalError, occupancy, segmentationTest, reconstructedDepth, occupancyMask = evaluatePlanes(pred_p, im_name[\'image\'])\n            #reconstructedDepth = cv2.resize(reconstructedDepth, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR)\n            \n            #evaluatePlanes(pred_p[0], im_name, options.test_dir, index)\n            #print(pred_p)\n            #print(gt_p)\n            #print((pow(pred_d[0, :, :, 0] - depth, 2) * (gt_s.max(2) > 0.5)).mean())\n            #print((depthError, normalError, occupancy))\n            \n            evaluateDepths(predDepths[index], gtDepths[index], np.ones(planeMasks[index].shape), planeMasks[index])\n\n            if index >= 10:\n                continue\n            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', cv2.resize(im, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR))\n            #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_gt.png\', (minDepth / np.clip(depth, minDepth, 20) * 255).astype(np.uint8))\n            #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', (minDepth / np.clip(pred_d[0, :, :, 0], minDepth, 20) * 255).astype(np.uint8))\n            #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_plane.png\', (minDepth / np.clip(reconstructedDepth, minDepth, 20) * 255).astype(np.uint8))\n\n            pred_boundary = pred_boundary[0]\n            boundary = (1 / (1 + np.exp(-pred_boundary)) * 255).astype(np.uint8)\n            boundary = np.concatenate([boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)\n            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_boundary_pred.png\', boundary)\n            \n            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_inp.png\', drawDepthImage(depth))\n            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n            #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_plane.png\', drawDepthImage(reconstructedDepth))\n            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred_diff.png\', drawDiffImage(pred_d, depth, 0.5))\n            #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_plane_diff.png\', np.minimum(np.abs(reconstructedDepth - depth) / 0.5 * 255, 255).astype(np.uint8))\n            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_inp.png\', drawNormalImage(normal))\n            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_pred.png\', drawNormalImage(pred_np_n))\n            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(all_segmentations, black=True))\n\n            segmentation = np.argmax(pred_s, 2)\n            #writePLYFile(options.test_dir, index, image, pred_p, segmentation)\n\n            if index < 0:\n                for planeIndex in xrange(options.numOutputPlanes):\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_\' + str(planeIndex) + \'.png\', drawMaskImage(pred_s[:, :, planeIndex]))\n                    #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_\' + str(planeIndex) + \'_gt.png\', drawMaskImage(gt_s[:, :, planeIndex]))\n                    continue\n                pass\n            continue\n        predDepths = np.array(predDepths)\n        gtDepths = np.array(gtDepths)\n        planeMasks = np.array(planeMasks)\n        predMasks = np.array(predMasks)\n        #evaluateDepths(predDepths, gtDepths, planeMasks, predMasks)\n        evaluateDepths(predDepths, gtDepths, planeMasks, planeMasks)\n        #exit(1)\n        pass\n    return\n\n\ndef fitPlanesRGBD(options):\n    writeHTMLRGBD(\'../results/RANSAC_RGBD/index.html\', 10)\n    exit(1)\n    if not os.path.exists(options.checkpoint_dir):\n        os.system(""mkdir -p %s""%options.checkpoint_dir)\n        pass\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n    \n    min_after_dequeue = 1000\n\n    reader_rgbd = RecordReaderRGBD()\n    filename_queue_rgbd = tf.train.string_input_producer([\'../planes_nyu_rgbd_train.tfrecords\'], num_epochs=1)\n    img_inp_rgbd, global_gt_dict_rgbd, local_gt_dict_rgbd = reader_rgbd.getBatch(filename_queue_rgbd, numOutputPlanes=options.numOutputPlanes, batchSize=1, min_after_dequeue=min_after_dequeue, getLocal=True)\n\n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n        try:\n            gtDepths = []\n            predDepths = []\n            planeMasks = []\n            for index in xrange(10):\n                image, depth, path = sess.run([img_inp_rgbd, global_gt_dict_rgbd[\'depth\'], global_gt_dict_rgbd[\'path\']])\n                image = ((image[0] + 0.5) * 255).astype(np.uint8)\n                depth = depth.squeeze()\n                \n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', image)\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth.png\', drawDepthImage(depth))\n                #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_mask.png\', drawMaskImage(depth == 0))\n                planes, planeSegmentation, depthPred = fitPlanes(depth, numPlanes=20)                \n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(planeSegmentation))\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(depthPred))\n\n                gtDepths.append(depth)\n                predDepths.append(depthPred)\n                planeMasks.append((planeSegmentation < 20).astype(np.float32))\n                continue\n            predDepths = np.array(predDepths)\n            gtDepths = np.array(gtDepths)\n            planeMasks = np.array(planeMasks)\n            evaluateDepths(predDepths, gtDepths, np.ones(planeMasks.shape, dtype=np.bool), planeMasks)            \n        except tf.errors.OutOfRangeError:\n            print(\'done fitting\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n    return\n\ndef writeInfo(options):\n    x = (np.arange(11) * 0.1).tolist()\n    ys = []\n    ys.append(np.load(\'test/planenet_pixel_IOU.npy\').tolist())\n    ys.append(np.load(\'test/pixelwise_pred_pixel_IOU.npy\').tolist())\n    ys.append(np.load(\'test/pixelwise_gt_pixel_IOU.npy\').tolist())\n    plotCurves(x, ys, filename = \'test/plane_comparison.png\', xlabel=\'IOU\', ylabel=\'pixel coverage\', labels=[\'planenet\', \'pixelwise+RANSAC\', \'GT+RANSAC\'])\n\n    x = (0.5 - np.arange(11) * 0.05).tolist()\n    ys = []\n    ys.append(np.load(\'test/planenet_pixel_diff.npy\').tolist())\n    ys.append(np.load(\'test/pixelwise_pred_pixel_diff.npy\').tolist())\n    ys.append(np.load(\'test/pixelwise_gt_pixel_diff.npy\').tolist())\n    plotCurves(x, ys, filename = \'test/plane_comparison_diff.png\', xlabel=\'diff\', ylabel=\'pixel coverage\', labels=[\'planenet\', \'pixelwise+RANSAC\', \'GT+RANSAC\'])\n    \n    return\n\ndef parse_args():\n    """"""\n    Parse input arguments\n    """"""\n    parser = argparse.ArgumentParser(description=\'Planenet\')\n    parser.add_argument(\'--gpu\', dest=\'gpu_id\',\n                        help=\'GPU device id to use [0]\',\n                        default=0, type=int)\n    #task: [train, test, predict]\n    parser.add_argument(\'--task\', dest=\'task\',\n                        help=\'task type: [train, test, predict]\',\n                        default=\'train\', type=str)\n    parser.add_argument(\'--restore\', dest=\'restore\',\n                        help=\'how to restore the model\',\n                        default=0, type=int)\n    parser.add_argument(\'--numOutputPlanes\', dest=\'numOutputPlanes\',\n                        help=\'the number of output planes\',\n                        default=20, type=int)\n    parser.add_argument(\'--batchSize\', dest=\'batchSize\',\n                        help=\'batch size\',\n                        default=16, type=int)\n    parser.add_argument(\'--dataset\', dest=\'dataset\',\n                        help=\'dataset name for test/predict\',\n                        default=\'SUNCG\', type=str)\n    parser.add_argument(\'--numImages\', dest=\'numImages\',\n                        help=\'the number of images to test/predict\',\n                        default=100, type=int)\n    parser.add_argument(\'--boundaryLoss\', dest=\'boundaryLoss\',\n                        help=\'use boundary loss: [0, 1]\',\n                        default=1, type=int)\n    parser.add_argument(\'--diverseLoss\', dest=\'diverseLoss\',\n                        help=\'use diverse loss: [0, 1]\',\n                        default=1, type=int)\n    parser.add_argument(\'--deepSupervision\', dest=\'deepSupervision\',\n                        help=\'deep supervision level: [0, 1, 2]\',\n                        default=1, type=int)\n    parser.add_argument(\'--sameMatching\', dest=\'sameMatching\',\n                        help=\'use the matching for all deep supervision layers and the final prediction: [0, 1]\',\n                        default=1, type=int)    \n    parser.add_argument(\'--crf\', dest=\'crf\',\n                        help=\'the number of CRF iterations\',\n                        default=0, type=int)\n    parser.add_argument(\'--backwardLossWeight\', dest=\'backwardLossWeight\',\n                        help=\'backward matching loss\',\n                        default=0, type=float)\n    parser.add_argument(\'--predictBoundary\', dest=\'predictBoundary\',\n                        help=\'whether predict boundary or not: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--predictLocal\', dest=\'predictLocal\',\n                        help=\'whether predict local planes or not: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--predictConfidence\', dest=\'predictConfidence\',\n                        help=\'whether predict plane confidence or not: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--predictPixelwise\', dest=\'predictPixelwise\',\n                        help=\'whether predict pixelwise depth or not: [0, 1]\',\n                        default=0, type=int)    \n    parser.add_argument(\'--fineTuningCheckpoint\', dest=\'fineTuningCheckpoint\',\n                        help=\'specify the model for fine-tuning\',\n                        default=\'../PlaneSetGeneration/dump_planenet_diverse/train_planenet_diverse.ckpt\', type=str)\n    parser.add_argument(\'--suffix\', dest=\'suffix\',\n                        help=\'add a suffix to keyname to distinguish experiments\',\n                        default=\'\', type=str)\n    parser.add_argument(\'--l2Weight\', dest=\'l2Weight\',\n                        help=\'L2 regulation weight\',\n                        default=5e-4, type=float)\n    parser.add_argument(\'--LR\', dest=\'LR\',\n                        help=\'learning rate\',\n                        default=3e-5, type=float)\n    parser.add_argument(\'--hybrid\', dest=\'hybrid\',\n                        help=\'hybrid training\',\n                        default=\'0\', type=str)\n    \n\n    args = parser.parse_args()\n    args.keyname = os.path.basename(__file__).rstrip(\'.py\')\n    args.keyname = args.keyname.replace(\'train_\', \'\')\n\n    if args.numOutputPlanes != 20:\n        args.keyname += \'_np\' + str(args.numOutputPlanes)\n        pass\n    if args.boundaryLoss != 1:\n        args.keyname += \'_bl\' + str(args.boundaryLoss)\n        pass\n    if args.diverseLoss == 0:\n        args.keyname += \'_dl0\'\n        pass\n    if args.deepSupervision != 1:\n        args.keyname += \'_ds\' + str(args.deepSupervision)\n        pass\n    if args.crf > 0:\n        args.keyname += \'_crf\' + str(args.crf)\n        pass\n    if args.backwardLossWeight > 0:\n        args.keyname += \'_bw\'\n        pass    \n    if args.predictBoundary == 1:\n        args.keyname += \'_pb\'\n        pass\n    if args.predictLocal == 1:\n        args.keyname += \'_pl\'\n        pass\n    if args.predictConfidence == 1:\n        args.keyname += \'_pc\'\n        pass    \n    if args.predictPixelwise == 1:\n        args.keyname += \'_pp\'\n        pass    \n    if args.sameMatching == 0:\n        args.keyname += \'_sm0\'\n        pass\n    args.keyname += \'_hybrid\' + args.hybrid\n\n    \n    args.checkpoint_dir = \'checkpoint/\' + args.keyname\n    args.log_dir = \'log/\' + args.keyname\n    args.test_dir = \'test/\' + args.keyname + \'_\' + args.dataset\n    args.predict_dir = \'predict/\' + args.keyname + \'_\' + args.dataset\n    args.dump_dir = \'dump/\' + args.keyname\n    \n    #layers where deep supervision happens\n    args.deepSupervisionLayers = []\n    if args.deepSupervision >= 1:\n        args.deepSupervisionLayers.append(\'res4b22_relu\')\n        pass\n    if args.deepSupervision >= 2:\n        args.deepSupervisionLayers.append(\'res4b12_relu\')\n        pass\n    return args\n\n\nif __name__==\'__main__\':\n    args = parse_args()\n\n    print ""keyname=%s task=%s started""%(args.keyname, args.task)\n    try:\n        if args.task == ""train"":\n            main(args)\n        elif args.task == ""test"":\n            test(args)\n        elif args.task == ""predict"":\n            predict(args)\n        elif args.task == ""fit"":\n            fitPlanesRGBD(args)\n        elif args.task == ""write"":\n            writeInfo(args)\n        else:\n            assert False,""format wrong""\n            pass\n    finally:\n        pass\n\n'"
code/train_sample.py,185,"b'import tensorflow as tf\nimport numpy as np\nnp.set_printoptions(precision=2, linewidth=200)\nimport cv2\nimport os\nimport time\nimport sys\nimport argparse\nimport glob\nimport PIL\nimport scipy.ndimage as ndimage\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom utils import *\nfrom plane_utils import *\nfrom modules import *\n\n\nfrom planenet import PlaneNet\nfrom RecordReader import *\nfrom RecordReaderRGBD import *\nfrom RecordReader3D import *\nfrom RecordReaderAll import *\nfrom crfasrnn_layer import CrfRnnLayer\n\n#from SegmentationRefinement import *\n\n#training_flag: toggle dropout and batch normalization mode\n#it\'s true for training and false for validation, testing, prediction\n#it also controls which data batch to use (*_train or *_val)\n\n\ndef build_graph(img_inp_train, img_inp_val, training_flag, options):\n    with tf.device(\'/gpu:%d\'%options.gpu_id):\n        img_inp = tf.cond(training_flag, lambda: img_inp_train, lambda: img_inp_val)\n\n        net = PlaneNet({\'img_inp\': img_inp}, is_training=training_flag, options=options)\n\n        #global predictions\n        plane_pred = net.layers[\'plane_pred\']\n\n        segmentation_pred = net.layers[\'segmentation_pred\']\n        non_plane_mask_pred = net.layers[\'non_plane_mask_pred\']\n        non_plane_depth_pred = net.layers[\'non_plane_depth_pred\']\n        non_plane_normal_pred = net.layers[\'non_plane_normal_pred\']\n        non_plane_normal_pred = tf.nn.l2_normalize(non_plane_normal_pred, dim=-1)\n\n\n        if False:\n            plane_pred = gt_dict[\'plane\']\n            non_plane_mask_pred = gt_dict[\'non_plane_mask\'] * 10\n            non_plane_depth_pred = gt_dict[\'depth\']\n            non_plane_normal_pred = gt_dict[\'normal\']\n            segmentation_pred = gt_dict[\'segmentation\'][:, :, :, :options.numOutputPlanes] * 10\n            pass\n\n\n        if abs(options.crfrnn) > 0:\n            with tf.variable_scope(\'crfrnn\'):\n                all_segmentations = crfrnnModule([tf.concat([segmentation_pred, non_plane_mask_pred], axis=3), img_inp * 255], image_dims=(HEIGHT, WIDTH), num_classes=options.numOutputPlanes + 1, theta_alpha=30, theta_beta=10, theta_gamma=1, num_iterations=abs(options.crfrnn))\n                #all_segmentations = CrfRnnLayer(image_dims=(HEIGHT, WIDTH), num_classes=options.numOutputPlanes + 1, theta_alpha=80., theta_beta=3., theta_gamma=3., num_iterations=abs(options.crfrnn), name=\'crfrnn\')([tf.concat([segmentation_pred, non_plane_mask_pred], axis=3), img_inp * 255])\n                segmentation_pred = all_segmentations[:, :, :, :options.numOutputPlanes]\n                non_plane_mask_pred = all_segmentations[:, :, :, options.numOutputPlanes:]\n                pass\n            pass\n\n        global_pred_dict = {\'plane\': plane_pred, \'segmentation\': segmentation_pred, \'non_plane_mask\': non_plane_mask_pred, \'non_plane_depth\': non_plane_depth_pred, \'non_plane_normal\': non_plane_normal_pred}\n\n        if options.predictBoundary:\n            global_pred_dict[\'boundary\'] = net.layers[\'boundary_pred\']\n        else:\n            global_pred_dict[\'boundary\'] = tf.zeros((options.batchSize, HEIGHT, WIDTH, 2))\n            pass\n        if options.predictConfidence:\n            global_pred_dict[\'confidence\'] = net.layers[\'plane_confidence_pred\']\n            pass\n        if options.predictSemantics:\n            global_pred_dict[\'semantics\'] = net.layers[\'semantics_pred\']\n            pass\n\n        #local predictions\n        if options.predictLocal:\n            local_pred_dict = {\'score\': net.layers[\'local_score_pred\'], \'plane\': net.layers[\'local_plane_pred\'], \'mask\': net.layers[\'local_mask_pred\']}\n        else:\n            local_pred_dict = {}\n            pass\n\n\n        #deep supervision\n        deep_pred_dicts = []\n        for layer in options.deepSupervisionLayers:\n            pred_dict = {\'plane\': net.layers[layer+\'_plane_pred\'], \'segmentation\': net.layers[layer+\'_segmentation_pred\'], \'non_plane_mask\': net.layers[layer+\'_non_plane_mask_pred\']}\n            #if options.predictConfidence:\n            #pred_dict[\'confidence\'] = net.layers[layer+\'_plane_confidence_pred\']\n            #pass\n            deep_pred_dicts.append(pred_dict)\n            continue\n\n\n        if options.anchorPlanes:\n            anchors_np = np.load(\'dump/anchors_\' + options.hybrid + \'.npy\')\n            anchors = tf.reshape(tf.constant(anchors_np.reshape(-1)), anchors_np.shape)\n            anchors = tf.tile(tf.expand_dims(anchors, 0), [options.batchSize, 1, 1])\n            all_pred_dicts = deep_pred_dicts + [global_pred_dict]\n            for pred_index, pred_dict in enumerate(all_pred_dicts):\n                all_pred_dicts[pred_index][\'plane\'] += anchors\n                continue\n            pass\n\n        pass\n\n    return global_pred_dict, local_pred_dict, deep_pred_dicts\n\n\ndef build_loss(img_inp_train, img_inp_val, global_pred_dict, deep_pred_dicts, global_gt_dict_train, global_gt_dict_val, training_flag, options):\n    import tf_nndistance\n    with tf.device(\'/gpu:%d\'%options.gpu_id):\n        debug_dict = {}\n\n        img_inp = tf.cond(training_flag, lambda: img_inp_train, lambda: img_inp_val)\n        global_gt_dict = {}\n        for name in global_gt_dict_train.keys():\n            global_gt_dict[name] = tf.cond(training_flag, lambda: global_gt_dict_train[name], lambda: global_gt_dict_val[name])\n            continue\n        # local_gt_dict = {}\n        # for name in local_gt_dict_train.keys():\n        #     local_gt_dict[name] = tf.cond(tf.equal(training_flag % 2, 0), lambda: local_gt_dict_train[name], lambda: local_gt_dict_val[name])\n        #     continue\n\n        plane_parameters = tf.reshape(global_pred_dict[\'plane\'], (-1, 3))\n        info = global_gt_dict[\'info\'][0]\n        plane_depths = planeDepthsModule(plane_parameters, WIDTH, HEIGHT, info)\n        plane_depths = tf.transpose(tf.reshape(plane_depths, [HEIGHT, WIDTH, -1, options.numOutputPlanes]), [2, 0, 1, 3])\n\n        non_plane_depth = global_pred_dict[\'non_plane_depth\']\n        all_depths = tf.concat([plane_depths, non_plane_depth], axis=3)\n\n\n        validPlaneMask = tf.cast(tf.less(tf.tile(tf.expand_dims(tf.range(options.numOutputPlanes), 0), [options.batchSize, 1]), tf.expand_dims(global_gt_dict[\'num_planes\'], -1)), tf.float32)\n        backwardLossWeight = options.backwardLossWeight\n\n        #plane loss and segmentation loss (summation over deep supervisions and final supervision)\n        all_pred_dicts = deep_pred_dicts + [global_pred_dict]\n        plane_loss = tf.constant(0.0)\n        segmentation_loss = tf.constant(0.0)\n        plane_confidence_loss = tf.constant(0.0)\n        diverse_loss = tf.constant(0.0)\n\n        #keep forward map (segmentation gt) from previous supervision so that we can have same matching for all supervisions (options.sameMatching = 1)\n        previous_plane_gt = None\n        previous_plane_confidence_gt = None\n        previous_segmentation_gt = None\n        if options.anchorPlanes:\n            anchors_np = np.load(\'dump/anchors_\' + options.hybrid + \'.npy\')\n            anchors = tf.reshape(tf.constant(anchors_np.reshape(-1)), anchors_np.shape)\n            anchors = tf.tile(tf.expand_dims(anchors, 0), [options.batchSize, 1, 1])\n            dists_forward, map_forward, dists_backward, _ = tf_nndistance.nn_distance(global_gt_dict[\'plane\'], anchors)\n\n            forward_map = tf.one_hot(map_forward, depth=options.numOutputPlanes, axis=-1)\n            forward_map *= tf.expand_dims(validPlaneMask, -1)\n\n            #number of ground truth mapped for each prediction\n            num_matches = tf.transpose(tf.reduce_sum(forward_map, axis=1, keep_dims=True), [0, 2, 1])\n            previous_plane_gt = tf.transpose(tf.matmul(global_gt_dict[\'plane\'], forward_map, transpose_a=True), [0, 2, 1]) / tf.maximum(num_matches, 1e-4)\n            previous_plane_confidence_gt = tf.cast(num_matches > 0.5, tf.float32)\n\n            segmentation_gt_shuffled = tf.reshape(tf.matmul(tf.reshape(global_gt_dict[\'segmentation\'], [-1, HEIGHT * WIDTH, options.numOutputPlanes]), forward_map), [-1, HEIGHT, WIDTH, options.numOutputPlanes])\n            segmentation_gt_shuffled = tf.concat([segmentation_gt_shuffled, global_gt_dict[\'non_plane_mask\']], axis=3)\n            previous_segmentation_gt = segmentation_gt_shuffled\n            pass\n\n        for pred_index, pred_dict in enumerate(all_pred_dicts):\n            if (options.sameMatching and pred_index > 0) or options.anchorPlanes:\n                #use matching from previous supervision and map ground truth planes based on the mapping\n\n                plane_loss += tf.reduce_mean(tf.squared_difference(pred_dict[\'plane\'], previous_plane_gt) * previous_plane_confidence_gt) * 10000\n\n                #all segmentations is the concatenation of plane segmentations and non plane mask\n                all_segmentations = tf.concat([pred_dict[\'segmentation\'], pred_dict[\'non_plane_mask\']], axis=3)\n\n                if options.crf > 0:\n                    all_segmentations_softmax = tf.nn.softmax(all_segmentations)\n                    with tf.variable_scope(\'crf\'):\n                        planesY = global_pred_dict[\'plane\'][:, :, 1]\n                        planesD = tf.maximum(tf.norm(global_pred_dict[\'plane\'], axis=-1), 1e-4)\n                        planesY /= planesD\n                        planesY = tf.concat([planesY, tf.ones((options.batchSize, 1)) * 100], axis=1)\n\n                        imageDiff = calcImageDiff(img_inp)\n                        all_segmentations_softmax, _ = segmentationRefinementModule(all_segmentations_softmax, all_depths, planesY, imageDiff, numIterations=options.crf, numOutputPlanes=21)\n                        segmentation_loss += tf.reduce_mean(-tf.reduce_sum(previous_segmentation_gt* tf.log(tf.maximum(all_segmentations_softmax, 1e-31)), axis=-1)) * 1000\n                        pass\n                    pass\n                else:\n                    segmentation_loss += tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=all_segmentations, labels=previous_segmentation_gt)) * 1000\n                    pass\n            else:\n                #calculate new matching by finding nearest neighbors again\n                dists_forward, map_forward, dists_backward, _ = tf_nndistance.nn_distance(global_gt_dict[\'plane\'], pred_dict[\'plane\'])\n                dists_forward *= validPlaneMask\n\n                dists_forward = tf.reduce_mean(dists_forward)\n                dists_backward = tf.reduce_mean(dists_backward)\n                plane_loss += (dists_forward + dists_backward * backwardLossWeight) * 10000\n\n                forward_map = tf.one_hot(map_forward, depth=options.numOutputPlanes, axis=-1)\n                forward_map *= tf.expand_dims(validPlaneMask, -1)\n\n                #number of ground truth mapped for each prediction\n                num_matches = tf.transpose(tf.reduce_sum(forward_map, axis=1, keep_dims=True), [0, 2, 1])\n                previous_plane_gt = tf.transpose(tf.matmul(global_gt_dict[\'plane\'], forward_map, transpose_a=True), [0, 2, 1]) / tf.maximum(num_matches, 1e-4)\n                previous_plane_confidence_gt = tf.cast(num_matches > 0.5, tf.float32)\n\n\n                segmentation_gt_shuffled = tf.reshape(tf.matmul(tf.reshape(global_gt_dict[\'segmentation\'], [-1, HEIGHT * WIDTH, options.numOutputPlanes]), forward_map), [-1, HEIGHT, WIDTH, options.numOutputPlanes])\n                segmentation_gt_shuffled = tf.concat([segmentation_gt_shuffled, global_gt_dict[\'non_plane_mask\']], axis=3)\n                previous_segmentation_gt = segmentation_gt_shuffled\n\n                all_segmentations = tf.concat([pred_dict[\'segmentation\'], pred_dict[\'non_plane_mask\']], axis=3)\n                segmentation_loss += tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=all_segmentations, labels=segmentation_gt_shuffled)) * 1000\n                debug_dict[\'segmentation\'] = segmentation_gt_shuffled\n                pass\n\n            if options.diverseLoss:\n                plane_diff = tf.reduce_sum(tf.pow(tf.expand_dims(pred_dict[\'plane\'], 1) - tf.expand_dims(pred_dict[\'plane\'], 2), 2), axis=3)\n                plane_diff = tf.matrix_set_diag(plane_diff, tf.ones((options.batchSize, options.numOutputPlanes)))\n                minPlaneDiff = 0.5\n                diverse_loss += tf.reduce_mean(tf.clip_by_value(1 - plane_diff / minPlaneDiff, 0, 1)) * 10000\n                pass\n\n            continue\n\n\n        if options.crf == 0:\n            all_segmentations_softmax = tf.nn.softmax(all_segmentations)\n            pass\n\n        #depth loss\n        validDepthMask = tf.cast(tf.greater(global_gt_dict[\'depth\'], 1e-4), tf.float32)\n\n        depth_loss = tf.constant(0.0)\n        if options.depthLoss == 1:\n            depth_loss += tf.reduce_mean(tf.reduce_sum(tf.squared_difference(all_depths, global_gt_dict[\'depth\']) * all_segmentations_softmax, axis=3, keep_dims=True) * validDepthMask) * 20000\n        elif options.depthLoss == 2:\n            depthDiff = tf.abs(all_depths - global_gt_dict[\'depth\'])\n            c = 0.3\n            absMask = tf.cast(tf.less(depthDiff, c), tf.float32)\n            depthDiff = depthDiff * absMask + (tf.pow(depthDiff, 2) + tf.pow(c, 2)) / (2 * c) * (1 - absMask)\n            depth_loss += tf.reduce_mean(tf.reduce_sum(depthDiff * all_segmentations_softmax, axis=3, keep_dims=True) * validDepthMask) * 10000\n        elif options.depthLoss == 3:\n            depth_softmax = tf.reduce_sum(all_depths * all_segmentations_softmax, axis=3, keep_dims=True)\n            depthDiff = tf.abs(depth_softmax - global_gt_dict[\'depth\'])\n            c = 0.3\n            absMask = tf.cast(tf.less(depthDiff, c), tf.float32)\n            depthDiff = depthDiff * absMask + (tf.pow(depthDiff, 2) + tf.pow(c, 2)) / (2 * c) * (1 - absMask)\n            depth_loss += tf.reduce_mean(depthDiff * validDepthMask) * 10000\n        elif options.depthLoss == 4:\n            S = tf.one_hot(tf.argmax(all_segmentations, 3), depth=options.numOutputPlanes + 1)\n            depth_one_hot = tf.reduce_sum(all_depths * S, axis=3, keep_dims=True)\n            depthDiff = tf.abs(depth_one_hot - global_gt_dict[\'depth\'])\n            c = 0.3\n            absMask = tf.cast(tf.less(depthDiff, c), tf.float32)\n            depthDiff = depthDiff * absMask + (tf.pow(depthDiff, 2) + tf.pow(c, 2)) / (2 * c) * (1 - absMask)\n            depth_loss += tf.reduce_mean(depthDiff * validDepthMask) * 10000\n            pass\n\n        if options.predictPixelwise == 1:\n            depth_diff = global_pred_dict[\'non_plane_depth\'] - global_gt_dict[\'depth\']\n            depth_diff_gx = depth_diff - tf.concat([tf.ones([options.batchSize, HEIGHT, 1, 1]), depth_diff[:, :, :WIDTH - 1]], axis=2)\n            depth_diff_gy = depth_diff - tf.concat([tf.ones([options.batchSize, 1, WIDTH, 1]), depth_diff[:, :HEIGHT - 1]], axis=1)\n\n            numValidPixels = tf.reduce_sum(validDepthMask, axis=[1, 2, 3])\n            depth_loss += tf.reduce_mean(tf.reduce_sum(tf.pow(depth_diff * validDepthMask, 2), axis=[1, 2, 3]) / numValidPixels - 0.5 * tf.pow(tf.reduce_sum(depth_diff * validDepthMask, axis=[1, 2, 3]) / numValidPixels, 2) + tf.reduce_sum((tf.pow(depth_diff_gx, 2) + tf.pow(depth_diff_gy, 2)) * validDepthMask, axis=[1, 2, 3]) / numValidPixels) * 1000\n\n            #depth_loss += tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_depth\'], global_gt_dict[\'depth\']) * validDepthMask) * 10000\n\n\n            valid_normal_mask = tf.squeeze(tf.cast(tf.less(tf.slice(global_gt_dict[\'info\'], [0, 19], [options.batchSize, 1]), 2), tf.float32))\n            normal_gt = tf.nn.l2_normalize(global_gt_dict[\'normal\'], dim=-1)\n            normal_loss = tf.reduce_mean(tf.reduce_sum(-global_pred_dict[\'non_plane_normal\'] * normal_gt * validDepthMask, axis=[1, 2, 3]) / numValidPixels * valid_normal_mask) * 1000\n            #normal_loss = tf.reduce_mean(tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_normal\'], global_gt_dict[\'normal\']) * validDepthMask, axis=[1, 2, 3]) * valid_normal_mask) * 1000\n        else:\n            normal_loss = tf.constant(0.0)\n            pass\n\n        if options.predictSemantics:\n            valid_semantics_mask = tf.squeeze(tf.cast(tf.not_equal(tf.slice(global_gt_dict[\'info\'], [0, 19], [options.batchSize, 1]), 1), tf.float32))\n            semantics_loss = tf.reduce_mean(tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=global_pred_dict[\'semantics\'], labels=global_gt_dict[\'semantics\']), axis=[1, 2]) * valid_semantics_mask) * 1000\n        else:\n            semantics_loss = tf.constant(0.0)\n            pass\n\n        local_score_loss = tf.constant(0.0)\n        local_plane_loss = tf.constant(0.0)\n        local_mask_loss = tf.constant(0.0)\n\n        #boundary loss\n        boundary_loss = tf.constant(0.0)\n\n        if False:\n            kernel_size = 3\n            padding = (kernel_size - 1) / 2\n            neighbor_kernel_array = gaussian(kernel_size, kernel_size)\n            neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n            neighbor_kernel_array /= neighbor_kernel_array.sum()\n            neighbor_kernel_array *= -1\n            neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 1\n            neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n            neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n\n            #calculate boundary ground truth on-the-fly as the calculation is subject to change\n\n            depth_diff = tf.abs(tf.nn.depthwise_conv2d(global_gt_dict[\'depth\'], neighbor_kernel, strides=[1, 1, 1, 1], padding=\'VALID\'))\n            depth_diff = tf.pad(depth_diff, paddings = [[0, 0], [padding, padding], [padding, padding], [0, 0]])\n            max_depth_diff = 0.1\n            depth_boundary = tf.greater(depth_diff, max_depth_diff)\n\n            plane_region = tf.nn.max_pool(1 - global_gt_dict[\'non_plane_mask\'], ksize=[1, kernel_size, kernel_size, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n            segmentation_eroded = 1 - tf.nn.max_pool(1 - global_gt_dict[\'segmentation\'], ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n            plane_region -= tf.reduce_max(segmentation_eroded, axis=3, keep_dims=True)\n            boundary = tf.cast(depth_boundary, tf.float32) * plane_region\n            smooth_boundary = global_gt_dict[\'smooth_boundary\']\n            boundary_gt = tf.concat([smooth_boundary, tf.maximum(boundary - smooth_boundary, 0)], axis=3)\n            pass\n\n\n        if options.boundaryLoss == 1 and False:\n\n            all_segmentations_pred = all_segmentations_softmax\n            all_segmentations_min = 1 - tf.nn.max_pool(1 - all_segmentations_pred, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\')\n            segmentation_diff = tf.reduce_max(all_segmentations_pred - all_segmentations_min, axis=3, keep_dims=True)\n\n            depth_pred = tf.reduce_sum(tf.multiply(all_depths, all_segmentations_pred), axis=3, keep_dims=True)\n            depth_neighbor = tf.nn.depthwise_conv2d(depth_pred, neighbor_kernel, strides=[1, 1, 1, 1], padding=\'SAME\')\n            minDepthDiff = 0.02\n            depth_diff = tf.clip_by_value(tf.squared_difference(depth_pred, depth_neighbor) - pow(minDepthDiff, 2), 0, 1)\n\n            boundary = tf.reduce_max(global_gt_dict[\'boundary\'], axis=3, keep_dims=True)\n            smooth_boundary = tf.slice(boundary_gt, [0, 0, 0, 0], [options.batchSize, HEIGHT, WIDTH, 1])\n            smooth_mask = segmentation_diff + boundary - 2 * segmentation_diff * boundary + depth_diff * smooth_boundary\n            margin = 0.0\n            smooth_mask = tf.nn.relu(smooth_mask - margin)\n            #boundary_loss += tf.reduce_mean(smooth_mask * plane_mask) * 1000\n            boundary_loss += tf.reduce_mean(smooth_mask) * 1000\n        elif options.boundaryLoss == 3:\n            S = tf.one_hot(tf.argmax(all_segmentations, 3), depth=options.numOutputPlanes + 1)\n            #sigmaDepthDiff = 0.5\n            #DS_diff = tf.exp(-tf.pow(1 - tf.clip_by_value(tf.abs(all_depths - tf.reduce_sum(all_depths * S, 3, keep_dims=True)), 0, 1), 2) / sigmaDepthDiff) - tf.exp(-1 / sigmaDepthDiff) * S\n            planesY = tf.slice(global_pred_dict[\'plane\'], [0, 0, 1], [options.batchSize, options.numOutputPlanes, 1])\n            planesD = tf.maximum(tf.norm(global_pred_dict[\'plane\'], axis=-1, keep_dims=True), 1e-4)\n            planesY /= planesD\n            #normalY = tf.reduce_sum(tf.slice(S, [0, 0, 0, 0], [options.batchSize, HEIGHT, WIDTH, options.numOutputPlanes]) * tf.reshape(planesY, [options.batchSize, 1, 1, options.numOutputPlanes]), axis=3, keep_dims=True)\n            planesY = tf.concat([planesY, tf.ones((options.batchSize, 1, 1)) * 100], axis=1)\n            normalY = tf.reduce_sum(S * tf.reshape(planesY, [options.batchSize, 1, 1, -1]), axis=3, keep_dims=True)\n\n            maxDepthDiff = 0.1\n            labelDiffWeight = 0.05\n            depth_one_hot = tf.reduce_sum(all_depths * S, 3, keep_dims=True)\n            depth_diff = tf.clip_by_value(tf.pow((plane_depths - depth_one_hot) * normalY / maxDepthDiff, 2), 0, 1)\n            #depth_diff *= normalY\n            depth_diff = tf.concat([depth_diff, 1 - tf.slice(S, [0, 0, 0, options.numOutputPlanes], [options.batchSize, HEIGHT, WIDTH, 1])], axis=3)\n            DS_diff = (1 + labelDiffWeight) - tf.exp(-depth_diff) - S * labelDiffWeight\n            kernel_size = 3\n            neighbor_kernel_array = gaussian(kernel_size)\n            neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n            neighbor_kernel_array /= neighbor_kernel_array.sum()\n            neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n            neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n\n            DS = tf.nn.depthwise_conv2d(DS_diff, tf.tile(neighbor_kernel, [1, 1, options.numOutputPlanes + 1, 1]), strides=[1, 1, 1, 1], padding=\'SAME\')\n            boundary_loss += tf.reduce_mean(DS * all_segmentations_softmax) * 100000\n\n            debug_dict[\'cost_mask\'] = tf.reduce_sum(DS * all_segmentations_softmax, axis=3)\n            #debug_dict[\'cost_mask\'] = DS * all_segmentations_softmax\n            #debug_dict[\'cost_mask\'] = tf.reduce_sum(DS * S, axis=3)\n        elif options.boundaryLoss == 2:\n            planesY = global_pred_dict[\'plane\'][:, :, 1]\n            planesD = tf.maximum(tf.norm(global_pred_dict[\'plane\'], axis=-1), 1e-4)\n            planesY /= planesD\n            planesY = tf.concat([planesY, tf.ones((options.batchSize, 1)) * 100], axis=1)\n\n            #imageDiff = calcImageDiff(img_inp)\n            #all_segmentations_softmax, _ = segmentationRefinementModule(all_segmentations_softmax, all_depths, planesY, imageDiff, numIterations=options.crf, numOutputPlanes=21)\n            messages = calcMessages(all_segmentations_softmax, all_depths, planesY, numOutputPlanes=21)\n            boundary_loss += tf.reduce_mean(messages * all_segmentations_softmax) * 100000\n            debug_dict[\'cost_mask\'] = messages\n            pass\n\n\n        if options.predictBoundary and False:\n            #we predict boundaries directly for post-processing purpose\n            boundary_loss += tf.reduce_mean(tf.losses.sigmoid_cross_entropy(logits=global_pred_dict[\'boundary\'], multi_class_labels=global_gt_dict[\'boundary\'], weights=tf.maximum(global_gt_dict[\'boundary\'] * 3, 1))) * 1000\n            pass\n\n\n        label_loss = tf.constant(0.0)\n        if options.labelLoss == 1:\n            #label_loss = tf.reduce_mean(tf.reduce_max(all_segmentations_softmax, axis=[1, 2]) * tf.concat([tf.cast(tf.equal(tf.squeeze(num_matches, axis=2), 0), tf.float32), tf.ones([options.batchSize, 1])], axis=1)) * 1000\n            #label_loss = tf.reduce_mean(tf.log(1 + tf.reduce_sum(all_segmentations_softmax, axis=[1, 2]))) * 100\n            segmentations_gt = tf.concat([global_gt_dict[\'segmentation\'], global_gt_dict[\'non_plane_mask\']], axis=3)\n            label_loss = tf.reduce_mean(tf.maximum(tf.reduce_sum(tf.sqrt(tf.reduce_sum(all_segmentations_softmax, axis=[1, 2])), axis=1) - tf.reduce_sum(tf.sqrt(tf.reduce_sum(segmentations_gt, axis=[1, 2])), axis=1), 0)) * 5\n            #label_loss = tf.reduce_mean(tf.reduce_max(all_segmentations_softmax, axis=[1, 2])) * 1000\n            pass\n\n        #regularization\n        l2_losses = tf.add_n([options.l2Weight * tf.nn.l2_loss(v) for v in tf.trainable_variables() if \'weights\' in v.name])\n\n        if options.planeLoss == 0:\n            plane_loss = tf.constant(0.0)\n            pass\n\n        loss = plane_loss + segmentation_loss + depth_loss + normal_loss + plane_confidence_loss + diverse_loss + boundary_loss + local_score_loss + local_plane_loss + local_mask_loss + label_loss + semantics_loss + l2_losses\n\n        #if options.pixelwiseLoss:\n        #normal_loss = tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_normal\'], global_gt_dict[\'normal\'])) * 1000\n        #depth_loss = tf.reduce_mean(tf.squared_difference(global_pred_dict[\'non_plane_depth\'], global_gt_dict[\'depth\']) * validDepthMask) * 1000\n        #pass\n\n        S = tf.one_hot(tf.argmax(all_segmentations, 3), depth=options.numOutputPlanes + 1)\n        depth_one_hot = tf.reduce_sum(all_depths * S, 3, keep_dims=True)\n        debug_dict[\'depth\'] = depth_one_hot\n\n        loss_dict = {\'plane\': plane_loss, \'segmentation\': segmentation_loss, \'depth\': depth_loss, \'normal\': normal_loss, \'boundary\': boundary_loss, \'diverse\': diverse_loss, \'confidence\': plane_confidence_loss, \'local_score\': local_score_loss, \'local_plane\': local_plane_loss, \'local_mask\': local_mask_loss, \'label\': label_loss, \'semantics\': semantics_loss}\n        pass\n    return loss, loss_dict, debug_dict\n\n\ndef main(options):\n    if not os.path.exists(options.checkpoint_dir):\n        os.system(""mkdir -p %s""%options.checkpoint_dir)\n        pass\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n\n    min_after_dequeue = 1000\n\n\n    train_inputs = []\n    val_inputs = []\n    if \'0\' in options.hybrid:\n        train_inputs.append(options.rootFolder + \'/planes_SUNCG_train.tfrecords\')\n        val_inputs.append(options.rootFolder + \'/planes_SUNCG_val.tfrecords\')\n        pass\n    if \'1\' in options.hybrid:\n        for _ in xrange(10):\n            train_inputs.append(options.rootFolder + \'/planes_nyu_rgbd_train.tfrecords\')\n            train_inputs.append(options.rootFolder + \'/planes_nyu_rgbd_labeled_train.tfrecords\')\n            val_inputs.append(options.rootFolder + \'/planes_nyu_rgbd_val.tfrecords\')\n            continue\n        pass\n    if \'2\' in options.hybrid:\n        train_inputs.append(options.rootFolder + \'/planes_matterport_train.tfrecords\')\n        val_inputs.append(options.rootFolder + \'/planes_matterport_val.tfrecords\')\n        pass\n    if \'3\' in options.hybrid:\n        train_inputs.append(options.rootFolder + \'/planes_scannet_train.tfrecords\')\n        val_inputs.append(options.rootFolder + \'/planes_scannet_val.tfrecords\')\n        pass\n\n    reader_train = RecordReaderAll()\n    filename_queue_train = tf.train.string_input_producer(train_inputs, num_epochs=10000)\n    img_inp_train, global_gt_dict_train, local_gt_dict_train = reader_train.getBatch(filename_queue_train, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True)\n\n    reader_val = RecordReaderAll()\n    filename_queue_val = tf.train.string_input_producer(val_inputs, num_epochs=10000)\n    img_inp_val, global_gt_dict_val, local_gt_dict_val = reader_val.getBatch(filename_queue_val, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True)\n\n    training_flag = tf.placeholder(tf.bool, shape=[], name=\'training_flag\')\n\n    #global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp_train, img_inp_val, img_inp_rgbd_train, img_inp_rgbd_val, img_inp_3d_train, img_inp_3d_val, training_flag, options)\n    global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp_train, img_inp_val, training_flag, options)\n\n\n    #loss, loss_dict, _ = build_loss(global_pred_dict, local_pred_dict, deep_pred_dicts, global_gt_dict_train, local_gt_dict_train, global_gt_dict_val, local_gt_dict_val, training_flag, options)\n    #loss_rgbd, loss_dict_rgbd, _ = build_loss_rgbd(global_pred_dict, deep_pred_dicts, global_gt_dict_rgbd_train, global_gt_dict_rgbd_val, training_flag, options)\n    loss, loss_dict, debug_dict = build_loss(img_inp_train, img_inp_val, global_pred_dict, deep_pred_dicts, global_gt_dict_train, global_gt_dict_val, training_flag, options)\n\n    #loss = tf.cond(tf.less(training_flag, 2), lambda: loss, lambda: tf.cond(tf.less(training_flag, 4), lambda: loss_rgbd, lambda: loss_3d))\n\n\n    #train_writer = tf.summary.FileWriter(options.log_dir + \'/train\')\n    #val_writer = tf.summary.FileWriter(options.log_dir + \'/val\')\n    #train_writer_rgbd = tf.summary.FileWriter(options.log_dir + \'/train_rgbd\')\n    #val_writer_rgbd = tf.summary.FileWriter(options.log_dir + \'/val_rgbd\')\n    #writers = [train_writer, val_writer, train_writer_rgbd, val_writer_rgbd]\n\n\n    with tf.variable_scope(\'statistics\'):\n        batchno = tf.Variable(0, dtype=tf.int32, trainable=False, name=\'batchno\')\n        batchnoinc=batchno.assign(batchno+1)\n        pass\n\n\n    optimizer = tf.train.AdamOptimizer(options.LR)\n    if options.crfrnn >= 0:\n        train_op = optimizer.minimize(loss, global_step=batchno)\n    else:\n        var_to_train = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, ""crfrnn"")\n        print(var_to_train)\n        train_op = optimizer.minimize(loss, global_step=batchno, var_list=var_to_train)\n        pass\n\n    var_to_restore = [v for v in tf.global_variables()]\n\n    tf.summary.scalar(\'loss\', loss)\n    summary_op = tf.summary.merge_all()\n\n\n    config=tf.ConfigProto()\n    config.allow_soft_placement=True\n    #config.gpu_options.allow_growth=True\n    config.gpu_options.per_process_gpu_memory_fraction=0.9\n    saver=tf.train.Saver()\n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n        if options.restore == 0:\n            #fine-tune from DeepLab model\n            var_to_restore = [v for v in var_to_restore if \'res5d\' not in v.name and \'segmentation\' not in v.name and \'plane\' not in v.name and \'deep_supervision\' not in v.name and \'local\' not in v.name and \'boundary\' not in v.name and \'degridding\' not in v.name and \'res2a_branch2a\' not in v.name and \'res2a_branch1\' not in v.name and \'Adam\' not in v.name and \'beta\' not in v.name and \'statistics\' not in v.name and \'semantics\' not in v.name]\n            pretrained_model_loader = tf.train.Saver(var_to_restore)\n            pretrained_model_loader.restore(sess,""../pretrained_models/deeplab_resnet.ckpt"")\n        elif options.restore == 1:\n            #restore the same model from checkpoint\n            loader = tf.train.Saver(var_to_restore)\n            loader.restore(sess,""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n            bno=sess.run(batchno)\n            print(bno)\n        elif options.restore == 2:\n            var_to_restore = [v for v in var_to_restore if \'plane\' not in v.name and \'segmentation_conv2\' not in v.name and \'crfrnn\' not in v.name]\n            loader = tf.train.Saver(var_to_restore)\n            loader.restore(sess, options.rootFolder + \'/checkpoint/planenet_hybrid\' + options.hybrid + \'_bl0_dl0_ll1_pb_pp_sm0/checkpoint.ckpt\')\n            #restore the same model from checkpoint but reset batchno to 1\n            #loader = tf.train.Saver(var_to_restore)\n            #loader.restore(sess,""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n            #sess.run(batchno.assign(1))\n        elif options.restore == 3:\n            #restore the same model from standard training\n            # if options.predictBoundary == 1:\n            #     var_to_restore = [v for v in var_to_restore if \'boundary\' not in v.name]\n            #     pass\n            # if options.predictConfidence == 1:\n            #     var_to_restore = [v for v in var_to_restore if \'confidence\' not in v.name]\n            #     pass\n            # if options.predictSemantics == 1:\n            #     var_to_restore = [v for v in var_to_restore if \'semantics\' not in v.name]\n            #     pass\n            # if np.abs(options.crfrnn) > 0:\n            #     var_to_restore = [v for v in var_to_restore if \'crfrnn\' not in v.name]\n            #     pass\n\n            if options.deepSupervision == 1:\n                var_to_restore = [v for v in var_to_restore if \'deep_supervision\' not in v.name]\n                pass\n\n            loader = tf.train.Saver(var_to_restore)\n            if len(options.hybrid) == 1:\n                hybrid = options.hybrid\n            else:\n                hybrid = str(3)\n                pass\n            loader.restore(sess, options.rootFolder + \'/checkpoint/sample_np10_hybrid3_bl0_dl0_hl2_ds0_crfrnn5_sm0/checkpoint.ckpt\')\n            #loader.restore(sess,""checkpoint/planenet/checkpoint.ckpt"")\n            sess.run(batchno.assign(1))\n        elif options.restore == 4:\n            #fine-tune another model\n            #var_to_restore = [v for v in var_to_restore if \'res4b22_relu_non_plane\' not in v.name]\n            loader = tf.train.Saver(var_to_restore)\n            loader.restore(sess, options.fineTuningCheckpoint)\n            sess.run(batchno.assign(1))\n            pass\n        elif options.restore == 5:\n            #fine-tune another model\n            #var_to_restore = [v for v in var_to_restore if \'res4b22_relu_non_plane\' not in v.name]\n            loader = tf.train.Saver(var_to_restore)\n            print(options.checkpoint_dir.replace(\'crfrnn\', \'crfrnn-\'))\n            #exit(1)\n            loader.restore(sess,""%s/checkpoint.ckpt""%(options.checkpoint_dir.replace(\'crfrnn\', \'crfrnn-\')))\n            sess.run(batchno.assign(1))\n            pass\n        # Start input enqueue threads.\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n        MOVING_AVERAGE_DECAY = 0.99\n        ema = [0., 0., 0., 0.]\n        ema_acc = [1e-10, 1e-10, 1e-10, 1e-10]\n        last_snapshot_time = time.time()\n        bno=sess.run(batchno)\n\n        try:\n            while bno<300000:\n                t0 = time.time()\n\n                batchIndexPeriod = bno % 100\n                if batchIndexPeriod < len(options.hybrid):\n                    #batchType = int(options.hybrid[batchIndexPeriod]) * 2 + 1\n                    batchType = 1\n                    _, total_loss, losses, summary_str, pred = sess.run([batchnoinc, loss, loss_dict, summary_op, global_pred_dict], feed_dict = {training_flag: batchType == 0})\n                else:\n                    batchType = 0\n                    _, total_loss, losses, summary_str, pred, debug, img, gt = sess.run([train_op, loss, loss_dict, summary_op, global_pred_dict, debug_dict, img_inp_train, global_gt_dict_train], feed_dict = {training_flag: batchType == 0})\n\n                    if bno % (100 + 400 * int(options.crfrnn == 0)) == 50:\n                        for batchIndex in xrange(options.batchSize):\n                            #print(losses)\n                            #print(debug[\'plane\'][batchIndex])\n                            cv2.imwrite(\'test/\' + str(batchIndex) + \'_image.png\', ((img[batchIndex] + 0.5) * 255).astype(np.uint8))\n                            cv2.imwrite(\'test/\' + str(batchIndex) + \'_segmentation_pred.png\', drawSegmentationImage(np.concatenate([pred[\'segmentation\'][batchIndex], pred[\'non_plane_mask\'][batchIndex]], axis=2), blackIndex=options.numOutputPlanes))\n                            cv2.imwrite(\'test/\' + str(batchIndex) + \'_segmentation_gt.png\', drawSegmentationImage(np.concatenate([gt[\'segmentation\'][batchIndex], gt[\'non_plane_mask\'][batchIndex]], axis=2), blackIndex=options.numOutputPlanes))\n                            cv2.imwrite(\'test/\' + str(batchIndex) + \'_depth.png\', drawDepthImage(debug[\'depth\'][batchIndex].squeeze()))\n                            continue\n                        #exit(1)\n                        pass\n                    pass\n\n\n                ema[batchType] = ema[batchType] * MOVING_AVERAGE_DECAY + total_loss\n                ema_acc[batchType] = ema_acc[batchType] * MOVING_AVERAGE_DECAY + 1\n\n                bno = sess.run(batchno)\n                if time.time()-last_snapshot_time > options.saveInterval:\n                    print(\'save snapshot\')\n                    saver.save(sess,\'%s/checkpoint.ckpt\'%options.checkpoint_dir)\n                    last_snapshot_time = time.time()\n                    pass\n\n                print bno,\'train\', ema[0] / ema_acc[0], \'val\', ema[1] / ema_acc[1], \'train rgbd\', ema[2] / ema_acc[2], \'val rgbd\', ema[3] / ema_acc[3], \'loss\', total_loss, \'time\', time.time()-t0\n\n                if np.random.random() < 0.01:\n                    print(losses)\n                    pass\n                continue\n\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n\n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return\n\n\ndef test(options):\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n\n    if options.dataset == \'\':\n        assert(len(options.hybrid) == 1)\n        if options.hybrid == \'0\':\n            options.dataset = \'SUNCG\'\n        elif options.hybrid == \'1\':\n            options.dataset = \'NYU_RGBD\'\n        elif options.hybrid == \'2\':\n            options.dataset = \'matterport\'\n        elif options.hybrid == \'3\':\n            options.dataset = \'ScanNet\'\n\n        options.dataset\n    options.batchSize = 1\n    min_after_dequeue = 1000\n\n    reader = RecordReaderAll()\n    if options.dataset == \'SUNCG\':\n        filename_queue = tf.train.string_input_producer([options.rootFolder + \'/planes_SUNCG_val.tfrecords\'], num_epochs=10000)\n    elif options.dataset == \'NYU_RGBD\':\n        filename_queue = tf.train.string_input_producer([options.rootFolder + \'/planes_nyu_rgbd_val.tfrecords\'], num_epochs=1)\n        options.deepSupervision = 0\n        options.predictLocal = 0\n    elif options.dataset == \'matterport\':\n        filename_queue = tf.train.string_input_producer([options.rootFolder + \'/planes_matterport_val.tfrecords\'], num_epochs=1)\n    else:\n        filename_queue = tf.train.string_input_producer([options.rootFolder + \'/planes_scannet_val.tfrecords\'], num_epochs=1)\n        pass\n    img_inp, global_gt_dict, local_gt_dict = reader.getBatch(filename_queue, numOutputPlanes=options.numOutputPlanes, batchSize=options.batchSize, min_after_dequeue=min_after_dequeue, getLocal=True, random=False)\n\n    training_flag = tf.constant(False, tf.bool)\n\n    global_pred_dict, local_pred_dict, deep_pred_dicts = build_graph(img_inp, img_inp, training_flag, options)\n    var_to_restore = tf.global_variables()\n\n    loss, loss_dict, debug_dict = build_loss(img_inp, img_inp, global_pred_dict, deep_pred_dicts, global_gt_dict, global_gt_dict, training_flag, options)\n\n\n    config=tf.ConfigProto()\n    config.gpu_options.allow_growth=True\n    config.allow_soft_placement=True\n\n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n        #var_to_restore = [v for v in var_to_restore if \'res4b22_relu_non_plane\' not in v.name]\n        loader = tf.train.Saver(var_to_restore)\n        loader.restore(sess, ""%s/checkpoint.ckpt""%(options.checkpoint_dir))\n        #loader.restore(sess, ""%s/checkpoint.ckpt""%(\'checkpoint/planenet_pb_pp_hybrid1\'))\n        #loader.restore(sess, options.fineTuningCheckpoint)\n\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n\n        try:\n            gtDepths = []\n            predDepths = []\n            planeMasks = []\n            #predMasks = []\n            gtPlanes = []\n            predPlanes = []\n            gtSegmentations = []\n            predSegmentations = []\n            gtNumPlanes = []\n\n            imageWidth = WIDTH\n            imageHeight = HEIGHT\n            focalLength = 517.97\n            urange = np.arange(imageWidth).reshape(1, -1).repeat(imageHeight, 0) - imageWidth * 0.5\n            vrange = np.arange(imageHeight).reshape(-1, 1).repeat(imageWidth, 1) - imageHeight * 0.5\n            ranges = np.array([urange / imageWidth * 640 / focalLength, np.ones(urange.shape), -vrange / imageHeight * 480 / focalLength]).transpose([1, 2, 0])\n\n\n            for index in xrange(10):\n                print((\'image\', index))\n                t0=time.time()\n\n                img, global_gt, local_gt, global_pred, local_pred, deep_preds, total_loss, losses, debug = sess.run([img_inp, global_gt_dict, local_gt_dict, global_pred_dict, local_pred_dict, deep_pred_dicts, loss, loss_dict, debug_dict])\n\n                # print(options.test_dir)\n                # cv2.imwrite(options.test_dir + \'/depth.png\', drawDepthImage(debug[\'depth\'][0]))\n                # cv2.imwrite(options.test_dir + \'/normal.png\', drawNormalImage(debug[\'normal\'][0]))\n                # boundary = debug[\'boundary\'][0]\n                # boundary = np.concatenate([boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)\n                # cv2.imwrite(options.test_dir + \'/boundary.png\', drawMaskImage(boundary))\n                # cv2.imwrite(options.test_dir + \'/depth_gt.png\', drawDepthImage(debug[\'depth_gt\'][0].squeeze()))\n                # exit(1)\n\n                if \'pixelwise\' in options.suffix:\n                    image = ((img[0] + 0.5) * 255).astype(np.uint8)\n                    gt_d = global_gt[\'depth\'].squeeze()\n                    pred_d = global_pred[\'non_plane_depth\'].squeeze()\n                    #depth = global_gt[\'depth\'].squeeze()\n                    if \'_2\' in options.suffix:\n                        pred_p, pred_s, pred_d = fitPlanes(pred_d, numPlanes=options.numOutputPlanes, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=0.2)\n                    elif \'_3\' in options.suffix:\n                        pred_p, pred_s, pred_d = fitPlanes(gt_d, numPlanes=options.numOutputPlanes, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=0.2)\n                        pass\n\n                    # gt_p = global_gt[\'plane\'][0]\n                    # pred_p = planes\n                    # valid_mask = (np.linalg.norm(gt_p, axis=1) > 0).astype(np.float32)\n                    # diff = np.min(np.linalg.norm(np.expand_dims(gt_p, 1) - np.expand_dims(pred_p, 0), axis=2), 1)\n                    # num += valid_mask.sum()\n                    # lossSum += (diff * valid_mask).sum()\n                    if options.dataset == \'SUNCG\':\n                        planeMask = np.squeeze(debug[\'segmentation\']).sum(axis=2)\n                    else:\n                        planeMask = np.ones((HEIGHT, WIDTH))\n                        if \'_2\' in options.suffix or \'_3\' in options.suffix:\n                            planeMask *= (pred_s < options.numOutputPlanes).astype(np.float32)\n                        pass\n\n                    if index < 10:\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', image)\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth.png\', drawDepthImage(gt_d))\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n                        if \'_2\' in options.suffix or \'_3\' in options.suffix:\n                            cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(pred_s))\n                            pass\n                        #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_plane_mask.png\', drawMaskImage(planeMask))\n                        pass\n\n\n                    gtDepths.append(gt_d)\n                    predDepths.append(pred_d)\n                    planeMasks.append(planeMask)\n\n\n                    if options.dataset != \'NYU_RGBD\' and (\'_2\' in options.suffix or \'_3\' in options.suffix):\n                        gt_p = global_gt[\'plane\'][0]\n                        gt_s = global_gt[\'segmentation\'][0]\n                        gt_num_p = global_gt[\'num_planes\'][0]\n\n                        pred_s = (np.expand_dims(pred_s, -1) == np.reshape(np.arange(options.numOutputPlanes), [1, 1, -1])).astype(np.float32)\n                        gtPlanes.append(gt_p)\n                        predPlanes.append(pred_p)\n                        gtSegmentations.append(gt_s)\n                        gtNumPlanes.append(gt_num_p)\n                        predSegmentations.append(pred_s)\n                        pass\n\n                    #planeMasks.append((planeSegmentation < options.numOutputPlanes).astype(np.float32))\n                    continue\n\n                print(losses)\n                print(total_loss)\n                #print(losses)\n                #exit(1)\n                im = img[0]\n                image = ((im + 0.5) * 255).astype(np.uint8)\n\n                gt_d = global_gt[\'depth\'].squeeze()\n\n\n                if options.predictLocal:\n                    pred_local_s = 1 / (1 + np.exp(-local_pred[\'score\'][0]))\n                    pred_local_p = local_pred[\'plane\'][0]\n                    pred_local_m = local_pred[\'mask\'][0]\n\n                    gt_local_s = local_gt[\'score\'][0]\n                    gt_local_m = local_gt[\'mask\'][0]\n\n                    #visualize local plane prediction\n                    stride = 8\n                    boxSize = 64\n                    xs = np.arange(WIDTH / stride) * stride + stride / 2\n                    ys = np.arange(HEIGHT / stride) * stride + stride / 2\n                    padding = boxSize / 2 + 1\n                    maskImage = np.zeros((HEIGHT + padding * 2, WIDTH + padding * 2, 3), dtype=np.uint8)\n                    maskImage[padding:padding + HEIGHT, padding:padding + WIDTH, :] = image / 2\n                    for gridY, y in enumerate(ys):\n                        for gridX, x in enumerate(xs):\n                            score = pred_local_s[gridY][gridX]\n                            if score < 0.5:\n                                continue\n                            mask = pred_local_m[gridY][gridX].reshape([16, 16])\n                            mask = cv2.resize(mask, (boxSize, boxSize))\n                            maskImage[y - boxSize / 2 + padding:y + boxSize / 2 + padding, x - boxSize / 2 + padding:x + boxSize / 2 + padding, 0][mask > 0.5] = 255\n                            continue\n                        continue\n                    for gridY, y in enumerate(ys):\n                        for gridX, x in enumerate(xs):\n                            score = gt_local_s[gridY][gridX]\n                            if score < 0.5:\n                                continue\n                            mask = gt_local_m[gridY][gridX].reshape([16, 16])\n                            mask = cv2.resize(mask, (boxSize, boxSize))\n                            maskImage[y - boxSize / 2 + padding:y + boxSize / 2 + padding, x - boxSize / 2 + padding:x + boxSize / 2 + padding, 2][mask > 0.5] = 255\n                            continue\n                        continue\n                    pass\n\n                pred_p = global_pred[\'plane\'][0]\n                pred_s = global_pred[\'segmentation\'][0]\n\n                pred_np_m = global_pred[\'non_plane_mask\'][0]\n                pred_np_d = global_pred[\'non_plane_depth\'][0]\n                pred_np_n = global_pred[\'non_plane_normal\'][0]\n\n                planeMask = 1 - global_gt[\'non_plane_mask\'][0]\n                info = global_gt[\'info\'][0]\n\n\n                all_segmentations = np.concatenate([pred_s, pred_np_m], axis=2)\n                all_segmentations_softmax = softmax(all_segmentations)\n                segmentation = np.argmax(all_segmentations, 2)\n\n\n                #pred_p, segmentation, numPlanes = mergePlanes(global_gt[\'plane\'][0], np.concatenate([global_gt[\'segmentation\'][0], global_gt[\'non_plane_mask\'][0]], axis=2), global_gt[\'depth\'][0].squeeze(), global_gt[\'info\'][0], np.concatenate([pred_s, pred_np_m], axis=2))\n\n\n                plane_depths = calcPlaneDepths(pred_p, WIDTH, HEIGHT, info)\n                all_depths = np.concatenate([plane_depths, pred_np_d], axis=2)\n\n                pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape(HEIGHT, WIDTH)\n\n                plane_normals = calcPlaneNormals(pred_p, WIDTH, HEIGHT)\n                all_normals = np.concatenate([plane_normals, np.expand_dims(pred_np_n, 2)], axis=2)\n                pred_n = np.sum(all_normals * np.expand_dims(one_hot(segmentation, options.numOutputPlanes+1), -1), 2)\n                #pred_n = all_normals.reshape(-1, options.numOutputPlanes + 1, 3)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape((HEIGHT, WIDTH, 3))\n\n\n                if False:\n                    gt_s = global_gt[\'segmentation\'][0]\n                    all_segmentations = np.concatenate([gt_s, 1 - planeMask], axis=2)\n                    gt_p = global_gt[\'plane\'][0]\n\n                    # valid_mask = (np.linalg.norm(gt_p, axis=1) > 0).astype(np.float32)\n                    # diff = np.min(np.linalg.norm(np.expand_dims(gt_p, 1) - np.expand_dims(pred_p, 0), axis=2), 1)\n                    # num += valid_mask.sum()\n                    # lossSum += (diff * valid_mask).sum()\n                    #gt_p = np.stack([-gt_p[:, 0], -gt_p[:, 2], -gt_p[:, 1]], axis=1)\n\n                    plane_depths = calcPlaneDepths(gt_p, WIDTH, HEIGHT, info)\n                    all_depths = np.concatenate([plane_depths, pred_np_d], axis=2)\n\n                    segmentation = np.argmax(all_segmentations, 2)\n                    pred_d = all_depths.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation.reshape(-1)].reshape(HEIGHT, WIDTH)\n                    # print(gt_p)\n                    # for segmentIndex in xrange(options.numOutputPlanes):\n                    #     cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_mask_\' + str(segmentIndex) + \'.png\', drawMaskImage(segmentation == segmentIndex))\n                    #     continue\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n                    #exit(1)\n                    pass\n\n\n\n                gt_p = global_gt[\'plane\'][0]\n                gt_s = global_gt[\'segmentation\'][0]\n                gt_num_p = global_gt[\'num_planes\'][0]\n                gtPlanes.append(gt_p)\n                predPlanes.append(pred_p)\n                gtSegmentations.append(gt_s)\n                gtNumPlanes.append(gt_num_p)\n                predSegmentations.append(pred_s)\n\n\n                gtDepths.append(gt_d)\n                planeMasks.append(planeMask.squeeze())\n                predDepths.append(pred_d)\n                evaluateDepths(predDepths[-1], gtDepths[-1], gtDepths[-1] > 0, planeMasks[-1])\n\n\n                if index >= 10:\n                    continue\n\n                if options.predictSemantics:\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_semantics_pred.png\', drawSegmentationImage(global_pred[\'semantics\'][0], blackIndex=0))\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_semantics_gt.png\', drawSegmentationImage(global_gt[\'semantics\'][0], blackIndex=0))\n                    pass\n\n                if \'cost_mask\' in debug:\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_cost_mask.png\', drawMaskImage(np.sum(debug[\'cost_mask\'][0], axis=-1)))\n\n                    for planeIndex in xrange(options.numOutputPlanes + 1):\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_cost_mask_\' + str(planeIndex) + \'.png\', drawMaskImage(debug[\'cost_mask\'][0, :, :, planeIndex]))\n                        continue\n                    all_segmentations = np.concatenate([pred_s, pred_np_m], axis=2)\n                    for planeIndex in xrange(options.numOutputPlanes + 1):\n                        cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred_\' + str(planeIndex) + \'.png\', drawMaskImage(all_segmentations[:, :, planeIndex]))\n                        continue\n                    exit(1)\n                    pass\n\n                if \'normal\' in global_gt:\n                    gt_n = global_gt[\'normal\'][0]\n                    norm = np.linalg.norm(gt_n, axis=-1, keepdims=True)\n                    gt_n /= np.maximum(norm, 1e-4)\n\n                    #gt_n = np.stack([-gt_n[:, :, 0], -gt_n[:, :, 2], -gt_n[:, :, 1]], axis=2)\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_gt.png\', drawNormalImage(gt_n))\n                    #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_pred.png\', drawNormalImage(pred_np_n))\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_normal_pred.png\', drawNormalImage(pred_n))\n                    pass\n\n                if \'segmentation\' in global_gt:\n                    gt_s = global_gt[\'segmentation\'][0]\n                    gt_p = global_gt[\'plane\'][0]\n\n\n                    #for planeIndex in xrange(options.numOutputPlanes):\n                    #cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(gt_s[:, :, planeIndex]))\n                    #continue\n\n\n                    # print(gt_p)\n                    # print(gt_n[109][129])\n                    # print(gt_n[166][245])\n                    # print(gt_s[109][129])\n                    # print(gt_s[166][245])\n                    # print(plane_normals[109][129])\n                    # print(plane_normals[166][245])\n                    # for planeIndex in xrange(options.numOutputPlanes):\n                    #     cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(gt_s[:, :, planeIndex]))\n                    #     continue\n                    # exit(1)\n\n                    gt_s, gt_p = sortSegmentations(gt_s, gt_p, pred_p)\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_plane_mask_gt.png\', drawMaskImage(planeMask))\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_gt.png\', drawSegmentationImage(np.concatenate([gt_s, 1 - planeMask], axis=2), blackIndex=options.numOutputPlanes)\n)\n                    #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_test.png\', drawMaskImage(np.sum(np.concatenate([gt_s, 1 - planeMask], axis=2), axis=2)))\n                    #exit(1)\n                    #exit(1)\n                    pass\n\n\n                if options.predictConfidence == 1 and options.dataset == \'SUNCG\':\n                    assert(False)\n                    pred_p_c = global_pred[\'confidence\'][0]\n                    pred_p_c = 1 / (1 + np.exp(-pred_p_c))\n                    #print(pred_p_c)\n                    # print(losses)\n                    # print(debug[\'plane\'][0])\n                    # print(pred_p)\n                    # exit(1)\n                    numPlanes = global_gt[\'num_planes\'][0]\n                    print((numPlanes, (pred_p_c > 0.5).sum()))\n\n                    pred_p_c = (pred_p_c > 0.5).astype(np.float32)\n                    pred_p *= pred_p_c\n                    pred_s -= (1 - pred_p_c.reshape([1, 1, options.numOutputPlanes])) * 10\n                    pass\n\n                if False:\n                    #dump results for post processing\n                    if index >= 10:\n                        break\n                    np.save(options.dump_dir + \'/planes_\' + str(index) + \'.npy\', pred_p)\n                    np.save(options.dump_dir + \'/segmentations_\' + str(index) + \'.npy\', pred_s)\n                    np.save(options.dump_dir + \'/segmentations_gt_\' + str(index) + \'.npy\', gt_s)\n                    np.save(options.dump_dir + \'/non_plane_depth_\' + str(index) + \'.npy\', pred_np_d)\n                    np.save(options.dump_dir + \'/non_plane_segmentation_\' + str(index) + \'.npy\', pred_np_m)\n                    boundary = pred_boundary[0]\n                    boundary = 1 / (1 + np.exp(-boundary))\n                    boundary = np.concatenate([boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)\n                    cv2.imwrite(options.dump_dir + \'/boundary_\' + str(index) + \'.png\', drawMaskImage(boundary))\n                    cv2.imwrite(options.dump_dir + \'/image_\' + str(index) + \'.png\', cv2.resize(image, (WIDTH, HEIGHT), interpolation=cv2.INTER_LINEAR))\n                    np.save(options.dump_dir + \'/depth_\' + str(index) + \'.npy\', gt_d)\n                    continue\n\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_image.png\', image)\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth.png\', drawDepthImage(gt_d))\n                #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_overlay.png\', drawDepthImageOverlay(image, gt_d))\n\n                if options.predictBoundary:\n                    pred_boundary = global_pred[\'boundary\'][0]\n                    pred_boundary = 1 / (1 + np.exp(-pred_boundary))\n                    boundary = np.concatenate([pred_boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_boundary_pred.png\', drawMaskImage(boundary))\n                    pass\n\n                if \'boundary\' in global_gt:\n                    gt_boundary = global_gt[\'boundary\'][0]\n                    boundary = np.concatenate([gt_boundary, np.zeros((HEIGHT, WIDTH, 1))], axis=2)\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_boundary_gt.png\', drawMaskImage(boundary))\n                    pass\n\n                for layerIndex, layer in enumerate(options.deepSupervisionLayers):\n                    segmentation_deep = np.argmax(deep_preds[layerIndex][\'segmentation\'][0], 2)\n                    segmentation_deep[segmentation_deep == options.numOutputPlanes] = -1\n                    segmentation_deep += 1\n\n                    plane_depths_deep = calcPlaneDepths(deep_preds[layerIndex][\'plane\'][0], WIDTH, HEIGHT, info)\n                    all_depths_deep = np.concatenate([pred_np_d, plane_depths_deep], axis=2)\n                    pred_d_deep = all_depths_deep.reshape(-1, options.numOutputPlanes + 1)[np.arange(WIDTH * HEIGHT), segmentation_deep.reshape(-1)].reshape(HEIGHT, WIDTH)\n\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred_\' + str(layerIndex) + \'.png\', drawSegmentationImage(deep_preds[layerIndex][\'segmentation\'][0]))\n                    cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred_\' + str(layerIndex) + \'.png\', drawDepthImage(pred_d_deep))\n                    pass\n\n\n                #print(pred_np_m)\n                #print(pred_s)\n                #print(global_gt[\'plane\'][0])\n                #print(pred_p)\n                #exit(1)\n\n                print(\'depth diff\', np.abs(pred_d - gt_d).mean())\n\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_pred.png\', drawSegmentationImage(all_segmentations, blackIndex=options.numOutputPlanes))\n                #exit(1)\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred.png\', drawDepthImage(pred_d))\n                cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_diff.png\', drawMaskImage(np.abs(pred_d - gt_d) * planeMask.squeeze() / 0.2))\n                #exit(1)\n\n\n                #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_plane_mask.png\', drawMaskImage(planeMask))\n\n                #print(np.concatenate([np.arange(options.numOutputPlanes).reshape(-1, 1), planes, pred_p, preds_p[0][0]], axis=1))\n\n                #print(np.concatenate([distance[0], preds_p[0][0], pred_p], axis=1))\n\n                #segmentation = np.argmax(pred_s, 2)\n                #writePLYFile(options.test_dir, index, image, pred_d, segmentation, np.zeros(pred_boundary[0].shape))\n                #writePLYFileParts(options.test_dir, index, image, pred_d, segmentation)\n                #gt_s_ori = gt_s_ori[0]\n\n\n                # if \'depth\' in debug:\n                #     cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_depth_pred_1.png\', drawDepthImage(debug[\'depth\'][0]))\n                #     gt_s_ori = debug[\'segmentation\'][0]\n                #     cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_segmentation_gt.png\', drawSegmentationImage(gt_s_ori, blackIndex=options.numOutputPlanes))\n                #     total_loss = 0\n                #     for planeIndex in xrange(gt_s_ori.shape[-1]):\n                #         mask_pred = all_segmentations_softmax[:, :, planeIndex]\n                #         loss = -(gt_s_ori[:, :, planeIndex] * np.log(np.maximum(all_segmentations_softmax[:, :, planeIndex], 1e-31))).mean() * 1000\n                #         print(planeIndex, loss)\n                #         total_loss += loss\n                #         cv2.imwrite(options.test_dir + \'/mask_pred_\' + str(planeIndex) + \'.png\', drawMaskImage(mask_pred))\n                #         cv2.imwrite(options.test_dir + \'/mask_gt_\' + str(planeIndex) + \'.png\', drawMaskImage(gt_s_ori[:, :, planeIndex]))\n                #         continue\n                #     print(total_loss)\n                #     print(gt_s_ori.sum(2).max())\n                #     exit(1)\n                #     pass\n\n\n                if False:\n                    #distance = distance[0]\n                    print(distance)\n                    diff = np.linalg.norm(np.expand_dims(planes, 1) - np.expand_dims(pred_p, 0), axis=2)\n                    print(np.concatenate([planes, pred_p, pow(np.min(diff, axis=1, keepdims=True), 2), np.expand_dims(np.argmin(diff, axis=1), -1)], axis=1))\n                    print(pred_p_c)\n\n                    #print(distance[:, 6:8].sum(0))\n                    #print(pow(np.linalg.norm(distance[:, :3] - distance[:, 3:6], 2, 1), 2) * 100)\n                    #print(test)\n                    segmentation = np.argmax(all_segmentations, 2) - 1\n                    for planeIndex in xrange(options.numOutputPlanes):\n                        cv2.imwrite(options.test_dir + \'/segmentation_\' + str(planeIndex) + \'.png\', drawMaskImage(segmentation == planeIndex))\n                        cv2.imwrite(options.test_dir + \'/segmentation_\' + str(planeIndex) + \'_gt.png\', drawMaskImage(gt_s[:, :, planeIndex]))\n                        cv2.imwrite(options.test_dir + \'/segmentation_\' + str(planeIndex) + \'_gt_ori.png\', drawMaskImage(gt_s_ori[:, :, planeIndex]))\n                        continue\n                    exit(1)\n                continue\n\n            # if options.dataset == \'SUNCG\':\n            #     if \'pixelwise\' not in options.suffix:\n            #         evaluatePlaneSegmentation(np.array(predPlanes), np.array(predSegmentations), np.array(gtPlanes), np.array(gtSegmentations), np.array(gtNumPlanes), planeDistanceThreshold = 0.3, IOUThreshold = 0.5, prefix=\'test/planenet_\')\n            #     elif \'_2\' in options.suffix:\n            #         evaluatePlaneSegmentation(np.array(predPlanes), np.array(predSegmentations), np.array(gtPlanes), np.array(gtSegmentations), np.array(gtNumPlanes), planeDistanceThreshold = 0.3, IOUThreshold = 0.5, prefix=\'test/pixelwise_pred_\')\n            #     elif \'_3\' in options.suffix:\n            #         evaluatePlaneSegmentation(np.array(predPlanes), np.array(predSegmentations), np.array(gtPlanes), np.array(gtSegmentations), np.array(gtNumPlanes), planeDistanceThreshold = 0.3, IOUThreshold = 0.5, prefix=\'test/pixelwise_gt_\')\n            #         pass\n            #     pass\n\n            predDepths = np.array(predDepths)\n            gtDepths = np.array(gtDepths)\n            planeMasks = np.array(planeMasks)\n            #predMasks = np.array(predMasks)\n            evaluateDepths(predDepths, gtDepths, gtDepths > 0, planeMasks)\n            exit(1)\n\n        except tf.errors.OutOfRangeError:\n            print(\'Done training -- epoch limit reached\')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n\n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()\n        pass\n    return\n\n\ndef writeInfo(options):\n    x = (np.arange(11) * 0.1).tolist()\n    ys = []\n    ys.append(np.load(\'test/planenet_pixel_IOU.npy\').tolist())\n    ys.append(np.load(\'test/pixelwise_pred_pixel_IOU.npy\').tolist())\n    ys.append(np.load(\'test/pixelwise_gt_pixel_IOU.npy\').tolist())\n    plotCurves(x, ys, filename = \'test/plane_comparison.png\', xlabel=\'IOU\', ylabel=\'pixel coverage\', labels=[\'planenet\', \'pixelwise+RANSAC\', \'GT+RANSAC\'])\n\n    x = (0.5 - np.arange(11) * 0.05).tolist()\n    ys = []\n    ys.append(np.load(\'test/planenet_pixel_diff.npy\').tolist())\n    ys.append(np.load(\'test/pixelwise_pred_pixel_diff.npy\').tolist())\n    ys.append(np.load(\'test/pixelwise_gt_pixel_diff.npy\').tolist())\n    plotCurves(x, ys, filename = \'test/plane_comparison_diff.png\', xlabel=\'diff\', ylabel=\'pixel coverage\', labels=[\'planenet\', \'pixelwise+RANSAC\', \'GT+RANSAC\'])\n\n    return\n\ndef parse_args():\n    """"""\n    Parse input arguments\n    """"""\n    parser = argparse.ArgumentParser(description=\'Planenet\')\n    parser.add_argument(\'--gpu\', dest=\'gpu_id\',\n                        help=\'GPU device id to use [0]\',\n                        default=0, type=int)\n    #task: [train, test, predict]\n    parser.add_argument(\'--task\', dest=\'task\',\n                        help=\'task type: [train, test, predict]\',\n                        default=\'train\', type=str)\n    parser.add_argument(\'--restore\', dest=\'restore\',\n                        help=\'how to restore the model\',\n                        default=0, type=int)\n    parser.add_argument(\'--numOutputPlanes\', dest=\'numOutputPlanes\',\n                        help=\'the number of output planes\',\n                        default=20, type=int)\n    parser.add_argument(\'--batchSize\', dest=\'batchSize\',\n                        help=\'batch size\',\n                        default=16, type=int)\n    parser.add_argument(\'--dataset\', dest=\'dataset\',\n                        help=\'dataset name for test/predict\',\n                        default=\'\', type=str)\n    parser.add_argument(\'--numImages\', dest=\'numImages\',\n                        help=\'the number of images to test/predict\',\n                        default=10, type=int)\n    parser.add_argument(\'--boundaryLoss\', dest=\'boundaryLoss\',\n                        help=\'use boundary loss: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--diverseLoss\', dest=\'diverseLoss\',\n                        help=\'use diverse loss: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--labelLoss\', dest=\'labelLoss\',\n                        help=\'use label loss: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--planeLoss\', dest=\'planeLoss\',\n                        help=\'use plane loss: [0, 1]\',\n                        default=1, type=int)\n    parser.add_argument(\'--depthLoss\', dest=\'depthLoss\',\n                        help=\'use depth loss: [0, 1, 2]\',\n                        default=1, type=int)\n    parser.add_argument(\'--deepSupervision\', dest=\'deepSupervision\',\n                        help=\'deep supervision level: [0, 1, 2]\',\n                        default=0, type=int)\n    parser.add_argument(\'--sameMatching\', dest=\'sameMatching\',\n                        help=\'use the same matching for all deep supervision layers and the final prediction: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--anchorPlanes\', dest=\'anchorPlanes\',\n                        help=\'use anchor planes for all deep supervision layers and the final prediction: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--crf\', dest=\'crf\',\n                        help=\'the number of CRF iterations\',\n                        default=0, type=int)\n    parser.add_argument(\'--crfrnn\', dest=\'crfrnn\',\n                        help=\'the number of CRF (as RNN) iterations\',\n                        default=0, type=int)\n    parser.add_argument(\'--backwardLossWeight\', dest=\'backwardLossWeight\',\n                        help=\'backward matching loss\',\n                        default=0, type=float)\n    parser.add_argument(\'--predictBoundary\', dest=\'predictBoundary\',\n                        help=\'whether predict boundary or not: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--predictSemantics\', dest=\'predictSemantics\',\n                        help=\'whether predict semantics or not: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--predictLocal\', dest=\'predictLocal\',\n                        help=\'whether predict local planes or not: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--predictConfidence\', dest=\'predictConfidence\',\n                        help=\'whether predict plane confidence or not: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--predictPixelwise\', dest=\'predictPixelwise\',\n                        help=\'whether predict pixelwise depth or not: [0, 1]\',\n                        default=0, type=int)\n    parser.add_argument(\'--fineTuningCheckpoint\', dest=\'fineTuningCheckpoint\',\n                        help=\'specify the model for fine-tuning\',\n                        default=\'../PlaneSetGeneration/dump_planenet_diverse/train_planenet_diverse.ckpt\', type=str)\n    parser.add_argument(\'--suffix\', dest=\'suffix\',\n                        help=\'add a suffix to keyname to distinguish experiments\',\n                        default=\'\', type=str)\n    parser.add_argument(\'--l2Weight\', dest=\'l2Weight\',\n                        help=\'L2 regulation weight\',\n                        default=5e-4, type=float)\n    parser.add_argument(\'--LR\', dest=\'LR\',\n                        help=\'learning rate\',\n                        default=3e-5, type=float)\n    parser.add_argument(\'--hybrid\', dest=\'hybrid\',\n                        help=\'hybrid training\',\n                        default=\'3\', type=str)\n    parser.add_argument(\'--rootFolder\', dest=\'rootFolder\',\n                        help=\'root folder\',\n                        default=\'/mnt/vision/PlaneNet/\', type=str)\n    parser.add_argument(\'--dataFolder\', dest=\'dataFolder\',\n                        help=\'data folder\',\n                        default=\'/home/chenliu/Projects/PlaneNet/\', type=str)\n    parser.add_argument(\'--saveInterval\', dest=\'saveInterval\',\n                        help=\'save interval\',\n                        default=900, type=int)\n\n\n    args = parser.parse_args()\n    args.keyname = os.path.basename(__file__).rstrip(\'.py\')\n    args.keyname = args.keyname.replace(\'train_\', \'\')\n\n    if args.numOutputPlanes != 20:\n        args.keyname += \'_np\' + str(args.numOutputPlanes)\n        pass\n    args.keyname += \'_hybrid\' + args.hybrid\n\n    if args.boundaryLoss != 1:\n        args.keyname += \'_bl\' + str(args.boundaryLoss)\n        pass\n    if args.diverseLoss == 0:\n        args.keyname += \'_dl0\'\n        pass\n    if args.labelLoss == 1:\n        args.keyname += \'_ll1\'\n        pass\n    if args.planeLoss == 0:\n        args.keyname += \'_pl0\'\n        pass\n    if args.depthLoss != 1:\n        args.keyname += \'_hl\' + str(args.depthLoss)\n        pass\n    if args.deepSupervision != 1:\n        args.keyname += \'_ds\' + str(args.deepSupervision)\n        pass\n    if args.crf > 0:\n        args.keyname += \'_crf\' + str(args.crf)\n        pass\n    if args.crfrnn != 0:\n        args.keyname += \'_crfrnn\' + str(args.crfrnn)\n        pass\n    if args.backwardLossWeight > 0:\n        args.keyname += \'_bw\' + str(args.backwardLossWeight)\n        pass\n    if args.predictBoundary == 1:\n        args.keyname += \'_pb\'\n        pass\n    if args.predictConfidence == 1:\n        args.keyname += \'_pc\'\n        pass\n    # if args.predictLocal == 1:\n    #     args.keyname += \'_pl\'\n    #     pass\n    if args.predictPixelwise == 1:\n        args.keyname += \'_pp\'\n        pass\n    if args.predictSemantics == 1:\n        args.keyname += \'_ps\'\n        pass\n    if args.sameMatching == 0:\n        args.keyname += \'_sm0\'\n        pass\n    if args.anchorPlanes == 1:\n        args.keyname += \'_ap1\'\n        pass\n\n    #args.predictSemantics = 0\n    #args.predictBoundary = 0\n\n    args.checkpoint_dir = args.rootFolder + \'/checkpoint/\' + args.keyname\n    args.log_dir = \'log/\' + args.keyname\n    args.test_dir = \'test/\' + args.keyname + \'_\' + args.dataset\n    args.predict_dir = \'predict/\' + args.keyname + \'_\' + args.dataset\n    args.dump_dir = \'dump/\' + args.keyname\n\n    #layers where deep supervision happens\n    args.deepSupervisionLayers = []\n    if args.deepSupervision >= 1:\n        args.deepSupervisionLayers.append(\'res4b22_relu\')\n        pass\n    if args.deepSupervision >= 2:\n        args.deepSupervisionLayers.append(\'res4b12_relu\')\n        pass\n    return args\n\n\nif __name__==\'__main__\':\n\n    # plane = np.load(\'temp/plane.npy\')\n    # depth = np.load(\'temp/depth.npy\')\n    # segmentation = np.load(\'temp/segmentation.npy\')\n    # info = np.load(\'temp/info.npy\')\n    # num_planes = np.load(\'temp/num_planes.npy\')\n    # segmentation = np.argmax(segmentation, axis=-1)\n    # print(segmentation.shape)\n    # planes, segmentation, numPlanes = removeSmallSegments(plane, np.zeros((HEIGHT, WIDTH, 3)), depth.squeeze(), np.zeros((HEIGHT, WIDTH, 3)), segmentation, np.zeros((HEIGHT, WIDTH)), info, num_planes)\n    # print(planes)\n    # exit(1)\n\n    args = parse_args()\n\n    print ""keyname=%s task=%s started""%(args.keyname, args.task)\n    try:\n        if args.task == ""train"":\n            main(args)\n        elif args.task == ""test"":\n            test(args)\n        elif args.task == ""predict"":\n            predict(args)\n        elif args.task == ""fit"":\n            fitPlanesRGBD(args)\n        elif args.task == ""write"":\n            writeInfo(args)\n        else:\n            assert False,""format wrong""\n            pass\n    finally:\n        pass\n'"
code/utils.py,0,"b'import numpy as np\nimport PIL.Image\nimport copy\nimport sys\nimport os\nimport cv2\nimport scipy.ndimage as ndimage\n#import pydensecrf.densecrf as dcrf\n#from pydensecrf.utils import compute_unary, create_pairwise_bilateral, \\\n    #create_pairwise_gaussian, unary_from_softmax\nfrom skimage import segmentation\n#from skimage.future import graph\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom layers import PlaneDepthLayer\nfrom pystruct.inference import get_installed, inference_ogm, inference_dispatch\nimport glob\n#from layers import PlaneNormalLayer\n#from SegmentationRefinement import *\n\nclass ColorPalette:\n    def __init__(self, numColors):\n        np.random.seed(2)\n        #self.colorMap = np.random.randint(255, size = (numColors, 3))\n        #self.colorMap[0] = 0\n\n\n        self.colorMap = np.array([[255, 0, 0],\n                                  [0, 255, 0],\n                                  [0, 0, 255],\n                                  [80, 128, 255],\n                                  [255, 230, 180],\n                                  [255, 0, 255],\n                                  [0, 255, 255],\n                                  [100, 0, 0],\n                                  [0, 100, 0],\n                                  [255, 255, 0],\n                                  [50, 150, 0],\n                                  [200, 255, 255],\n                                  [255, 200, 255],\n                                  [128, 128, 80],\n                                  [0, 50, 128],\n                                  [0, 100, 100],\n                                  [0, 255, 128],\n                                  [0, 128, 255],\n                                  [255, 0, 128],\n                                  [128, 0, 255],\n                                  [255, 128, 0],\n                                  [128, 255, 0],\n        ])\n\n        if numColors > self.colorMap.shape[0]:\n            self.colorMap = np.concatenate([self.colorMap, np.random.randint(255, size = (numColors - self.colorMap.shape[0], 3))], axis=0)\n            pass\n\n        return\n\n    def getColorMap(self):\n        return self.colorMap\n\n    def getColor(self, index):\n        if index >= colorMap.shape[0]:\n            return np.random.randint(255, size = (3))\n        else:\n            return self.colorMap[index]\n            pass\n\ndef writePointCloud(filename, pointCloud, color = [255, 255, 255]):\n    with open(filename, \'w\') as f:\n        header = """"""ply\nformat ascii 1.0\nelement vertex """"""\n        header += str(pointCloud.shape[0])\n        header += """"""\nproperty float x\nproperty float y\nproperty float z\nproperty uchar red                                     { start of vertex color }\nproperty uchar green\nproperty uchar blue\nend_header\n""""""\n        f.write(header)\n        for point in pointCloud:\n            for value in point:\n                f.write(str(value) + \' \')\n                continue\n            for value in color:\n                f.write(str(value) + \' \')\n                continue\n            f.write(\'\\n\')\n            continue\n        f.close()\n        pass\n    return\n\n\ndef writeClusteringPointCloud(filename, pointCloud, clusters):\n    with open(filename, \'w\') as f:\n        header = """"""ply\nformat ascii 1.0\nelement vertex """"""\n        header += str(pointCloud.shape[0])\n        header += """"""\nproperty float x\nproperty float y\nproperty float z\nproperty uchar red                                     { start of vertex color }\nproperty uchar green\nproperty uchar blue\nend_header\n""""""\n        colorMap = np.random.randint(255, size = clusters.shape)\n        assignment = np.argmin(np.linalg.norm(pointCloud.reshape(-1, 1, 3).repeat(clusters.shape[0], 1)[:] - clusters, 2, 2), 1)\n        f.write(header)\n        for pointIndex, point in enumerate(pointCloud):\n            for value in point:\n                f.write(str(value) + \' \')\n                continue\n            color = colorMap[assignment[pointIndex]]\n            for value in color:\n                f.write(str(value) + \' \')\n                continue\n            f.write(\'\\n\')\n            continue\n        f.close()\n        pass\n    return\n\n\ndef writeNearestNeighbors(filename, pointCloudSource, pointCloudTarget):\n    with open(filename, \'w\') as f:\n        header = """"""ply\nformat ascii 1.0\nelement vertex """"""\n        header += str((pointCloudSource.shape[0] + pointCloudTarget.shape[0] + pointCloudSource.shape[0]) * 4)\n        header += """"""\nproperty float x\nproperty float y\nproperty float z\nproperty uchar red\nproperty uchar green\nproperty uchar blue\nelement face """"""\n        header += str(pointCloudSource.shape[0] + pointCloudTarget.shape[0] + pointCloudSource.shape[0])\n        header += """"""\nproperty list uchar int vertex_index\nend_header\n""""""\n        f.write(header)\n\n        sourceColor = [0, 255, 0]\n        targetColor = [0, 0, 255]\n        colorMap = np.random.randint(255, size = pointCloudSource.shape)\n\n        # for pointIndex, point in enumerate(pointCloudSource):\n        #     for value in point:\n        #         f.write(str(value) + \' \')\n        #         continue\n        #     color = sourceColor\n        #     for value in color:\n        #         f.write(str(value) + \' \')\n        #         continue\n        #     f.write(\'\\n\')\n        #     continue\n\n        # for pointIndex, point in enumerate(pointCloudTarget):\n        #     for value in point:\n        #         f.write(str(value) + \' \')\n        #         continue\n        #     color = targetColor\n        #     for value in color:\n        #         f.write(str(value) + \' \')\n        #         continue\n        #     f.write(\'\\n\')\n        #     continue\n\n        planeSize = 0.1\n        for planeType, planes in enumerate([pointCloudSource, pointCloudTarget]):\n            for planeIndex, plane in enumerate(planes):\n                planeD = np.linalg.norm(plane)\n                planeNormal = -plane / planeD\n\n                maxNormalDim = np.argmax(np.abs(plane))\n                allDims = [0, 1, 2]\n                allDims.remove(maxNormalDim)\n                dim_1, dim_2 = allDims\n                for delta_1, delta_2 in [(-planeSize, -planeSize), (planeSize, -planeSize), (planeSize, planeSize), (-planeSize, planeSize)]:\n                    point = copy.deepcopy(plane)\n                    point[dim_1] += delta_1\n                    point[dim_2] += delta_2\n                    point[maxNormalDim] = (-planeD - planeNormal[dim_1] * point[dim_1] - planeNormal[dim_2] * point[dim_2]) / planeNormal[maxNormalDim]\n\n                    for value in point:\n                        f.write(str(value) + \' \')\n                        continue\n                    if planeType == 0:\n                        color = sourceColor\n                    else:\n                        color = targetColor\n                        pass\n\n                    for value in color:\n                        f.write(str(value) + \' \')\n                        continue\n                    f.write(\'\\n\')\n                    continue\n                continue\n            continue\n\n        assignment = np.argmin(np.linalg.norm(pointCloudSource.reshape(-1, 1, 3).repeat(pointCloudTarget.shape[0], 1)[:] - pointCloudTarget, 2, 2), 1)\n\n        planeSize = 0.01\n        lineColor = [255, 0, 0]\n        for planeIndex, planeSource in enumerate(pointCloudSource):\n            planeD = np.linalg.norm(planeSource)\n            planeNormal = -planeSource / planeD\n\n            maxNormalDim = np.argmax(np.abs(planeSource))\n            allDims = [0, 1, 2]\n            allDims.remove(maxNormalDim)\n            dim_1, dim_2 = allDims\n            minNormalDim = np.argmin(np.abs(planeSource))\n\n            for delta in [-planeSize, planeSize]:\n                point = copy.deepcopy(planeSource)\n                point[minNormalDim] += delta\n                point[maxNormalDim] = (-planeD - planeNormal[dim_1] * point[dim_1] - planeNormal[dim_2] * point[dim_2]) / planeNormal[maxNormalDim]\n                for value in point:\n                    f.write(str(value) + \' \')\n                    continue\n                color = lineColor\n                for value in color:\n                    f.write(str(value) + \' \')\n                    continue\n                f.write(\'\\n\')\n                continue\n\n            planeTarget = pointCloudTarget[assignment[planeIndex]]\n            planeDTarget = np.linalg.norm(plane)\n            planeNormalTarget = -plane / planeD\n            planeD = np.linalg.norm(planeTarget)\n            planeNormal = -planeTarget / planeD\n\n            for delta in [planeSize, -planeSize]:\n                point = copy.deepcopy(planeTarget)\n                point[minNormalDim] += delta\n                point[maxNormalDim] = (-planeD - planeNormal[dim_1] * point[dim_1] - planeNormal[dim_2] * point[dim_2]) / planeNormal[maxNormalDim]\n                for value in point:\n                    f.write(str(value) + \' \')\n                    continue\n                color = lineColor\n                for value in color:\n                    f.write(str(value) + \' \')\n                    continue\n                f.write(\'\\n\')\n                continue\n            continue\n\n        for index in xrange(pointCloudSource.shape[0] + pointCloudTarget.shape[0] + pointCloudSource.shape[0]):\n            planeIndex = index * 4\n            f.write(\'4 \' + str(planeIndex + 0) + \' \' + str(planeIndex + 1) + \' \' + str(planeIndex + 2) + \' \' + str(planeIndex + 3) + \'\\n\')\n            continue\n\n        # for pointIndexSource, point in enumerate(pointCloudSource):\n    #     pointIndexTarget = assignment[pointIndexSource]\n#     f.write(str(pointIndexSource) + \' \' + str(pointIndexTarget + pointCloudSource.shape[0]) + \' \')\n        #     color = colorMap[pointIndexSource]\n    #     for value in color:\n#         f.write(str(value) + \' \')\n        #         continue\n    #     f.write(\'\\n\')\n#     continue\n\n\n        f.close()\n        pass\n    return\n\n\n# def evaluatePlanes(planes, filename = None, depths = None, normals = None, invalidMask = None, outputFolder = None, outputIndex = 0, colorMap = None):\n#     if filename != None:\n#         if \'mlt\' not in filename:\n#             filename = filename.replace(\'color\', \'mlt\')\n#             pass\n#         normalFilename = filename.replace(\'mlt\', \'norm_camera\')\n#         normals = np.array(PIL.Image.open(normalFilename)).astype(np.float) / 255 * 2 - 1\n#         norm = np.linalg.norm(normals, 2, 2)\n#         for c in xrange(3):\n#             normals[:, :, c] /= norm\n#             continue\n\n#         depthFilename = filename.replace(\'mlt\', \'depth\')\n#         depths = np.array(PIL.Image.open(depthFilename)).astype(np.float) / 1000\n#         # if len(depths.shape) == 3:\n#         #     depths = depths.mean(2)\n#         #     pass\n#         maskFilename = filename.replace(\'mlt\', \'valid\')\n#         invalidMask = np.array(PIL.Image.open(maskFilename))\n#         invalidMask = invalidMask < 128\n#         invalidMask += depths > 10\n#         pass\n\n#     height = normals.shape[0]\n#     width = normals.shape[1]\n#     focalLength = 517.97\n#     urange = np.arange(width).reshape(1, -1).repeat(height, 0) - width * 0.5\n#     vrange = np.arange(height).reshape(-1, 1).repeat(width, 1) - height * 0.5\n#     ranges = np.array([urange / focalLength, np.ones(urange.shape), -vrange / focalLength]).transpose([1, 2, 0])\n\n#     X = depths / focalLength * urange\n#     Y = depths\n#     Z = -depths / focalLength * vrange\n#     d = -(normals[:, :, 0] * X + normals[:, :, 1] * Y + normals[:, :, 2] * Z)\n\n\n#     normalDotThreshold = np.cos(np.deg2rad(30))\n#     distanceThreshold = 50000\n\n#     reconstructedNormals = np.zeros(normals.shape)\n#     reconstructedDepths = np.zeros(depths.shape)\n#     segmentationImage = np.zeros((height, width, 3))\n#     distanceMap = np.ones((height, width)) * distanceThreshold\n#     occupancyMask = np.zeros((height, width)).astype(np.bool)\n#     segmentationTest = np.zeros((height, width))\n#     y = 297\n#     x = 540\n#     for planeIndex, plane in enumerate(planes):\n#         planeD = np.linalg.norm(plane)\n#         planeNormal = -plane / planeD\n\n#         normalXYZ = np.dot(ranges, planeNormal)\n#         normalXYZ = np.reciprocal(normalXYZ)\n#         planeY = -normalXYZ * planeD\n\n#         distance = np.abs(planeNormal[0] * X + planeNormal[1] * Y + planeNormal[2] * Z + planeD) / np.abs(np.dot(normals, planeNormal))\n#         #distance = np.abs(planeY - depths)\n\n#         mask = (distance < distanceMap) * (planeY > 0) * (np.abs(np.dot(normals, planeNormal)) > normalDotThreshold) * (np.abs(planeY - depths) < 0.5)\n#         occupancyMask += mask\n\n#         reconstructedNormals[mask] = planeNormal\n\n\n#         #if planeNormal[2] > 0.9:\n#         #print(planeD)\n#         #print(planeNormal)\n#         # minDepth = depths.min()\n#         # maxDepth = depths.max()\n#         # print(depths[300][300])\n#         # print(planeY[300][300])\n#         # print(depths[350][350])\n#         # print(planeY[350][350])\n#         # PIL.Image.fromarray((np.maximum(np.minimum((planeY - minDepth) / (maxDepth - minDepth), 1), 0) * 255).astype(np.uint8)).save(outputFolder + \'/plane.png\')\n#         # exit(1)\n#         #pass\n#         reconstructedDepths[mask] = planeY[mask]\n#         if colorMap != None and planeIndex in colorMap:\n#             segmentationImage[mask] = colorMap[planeIndex]\n#         else:\n#             segmentationImage[mask] = np.random.randint(255, size=(3,))\n#             pass\n#         distanceMap[mask] = distance[mask]\n#         segmentationTest[mask] = planeIndex + 1\n#         #print((planeIndex, planeY[y][x], distance[y][x], np.abs(np.dot(normals, planeNormal))[y][x]))\n#         continue\n\n#     # print(distanceMap.mean())\n# # print(distanceMap.max())\n#     # print(np.abs(reconstructedDepths - depths)[occupancyMask].max())\n# # print(pow(reconstructedDepths - depths, 2)[True - invalidMask].mean())\n#     # exit(1)\n\n#     # planeIndex = segmentationTest[y][x]\n# # print(normals[y][x])\n#     # plane = planes[int(planeIndex)]\n# # planeD = np.linalg.norm(plane)\n#     # planeNormal = -plane / planeD\n# # print((planeNormal, planeD))\n#     # print(depths[y][x])\n# # print(reconstructedDepths[y][x])\n#     # print(segmentationTest[y][x])\n\n#     if outputFolder != None:\n#         depths[invalidMask] = 0\n#         normals[invalidMask] = 0\n#         reconstructedDepths[invalidMask] = 0\n#         reconstructedNormals[invalidMask] = 0\n#         minDepth = depths.min()\n#         maxDepth = depths.max()\n#         #print(minDepth)\n#         #print(maxDepth)\n#         PIL.Image.fromarray(((depths - minDepth) / (maxDepth - minDepth) * 255).astype(np.uint8)).save(outputFolder + \'/\' + str(outputIndex) + \'_depth.png\')\n#         PIL.Image.fromarray((np.maximum(np.minimum((reconstructedDepths - minDepth) / (maxDepth - minDepth), 1), 0) * 255).astype(np.uint8)).save(outputFolder + \'/\' + str(outputIndex) + \'_depth_reconstructed.png\')\n#         #PIL.Image.fromarray((np.maximum(np.minimum((reconstructedDepths - depths) / (distanceThreshold), 1), 0) * 255).astype(np.uint8)).save(outputFolder + \'/depth_\' + str(outputIndex) + \'_diff.png\')\n#         PIL.Image.fromarray(((normals + 1) / 2 * 255).astype(np.uint8)).save(outputFolder + \'/\' + str(outputIndex) + \'_normal_.png\')\n#         PIL.Image.fromarray(((reconstructedNormals + 1) / 2 * 255).astype(np.uint8)).save(outputFolder + \'/\' + str(outputIndex) + \'_normal_reconstructed.png\')\n#         PIL.Image.fromarray(segmentationImage.astype(np.uint8)).save(outputFolder + \'/\' + str(outputIndex) + \'_plane_segmentation.png\')\n#         #depthImage = ((depths - minDepth) / (maxDepth - minDepth) * 255).astype(np.uint8)\n#         #PIL.Image.fromarray((invalidMask * 255).astype(np.uint8)).save(outputFolder + \'/mask.png\')\n#         #exit(1)\n#     else:\n#         occupancy = (occupancyMask > 0.5).astype(np.float32).sum() / (1 - invalidMask).sum()\n#         invalidMask += np.invert(occupancyMask)\n#         #PIL.Image.fromarray(invalidMask.astype(np.uint8) * 255).save(outputFolder + \'/mask.png\')\n#         reconstructedDepths = np.maximum(np.minimum(reconstructedDepths, 10), 0)\n#         depthError = pow(reconstructedDepths - depths, 2)[np.invert(invalidMask)].mean()\n#         #depthError = distanceMap.mean()\n#         normalError = np.arccos(np.maximum(np.minimum(np.sum(reconstructedNormals * normals, 2), 1), -1))[np.invert(invalidMask)].mean()\n#         #normalError = pow(np.linalg.norm(reconstructedNormals - normals, 2, 2), 2)[True - invalidMask].mean()\n#         #print((depthError, normalError, occupancy))\n#         # print(depths.max())\n#         # print(depths.min())\n#         # print(reconstructedDepths.max())\n#         # print(reconstructedDepths.min())\n#         # print(occupancy)\n#         # exit(1)\n\n#         #reconstructedDepths[np.invert(occupancyMask)] = depths[np.invert(occupancyMask)]\n#         return depthError, normalError, occupancy, segmentationTest, reconstructedDepths, occupancyMask\n#     return\n\n\n# def evaluatePlanesSeparately(planes, filename, outputFolder = None, outputIndex = 0):\n#     if \'mlt\' not in filename:\n#         filename = filename.replace(\'color\', \'mlt\')\n#         pass\n#     colorImage = np.array(PIL.Image.open(filename))\n#     normalFilename = filename.replace(\'mlt\', \'norm_camera\')\n#     normals = np.array(PIL.Image.open(normalFilename)).astype(np.float) / 255 * 2 - 1\n#     height = normals.shape[0]\n#     width = normals.shape[1]\n#     norm = np.linalg.norm(normals, 2, 2)\n#     for c in xrange(3):\n#         normals[:, :, c] /= norm\n#         continue\n\n\n#     depthFilename = filename.replace(\'mlt\', \'depth\')\n#     depths = np.array(PIL.Image.open(depthFilename)).astype(np.float) / 1000\n#     # if len(depths.shape) == 3:\n#     #     depths = depths.mean(2)\n#     #     pass\n\n#     focalLength = 517.97\n#     urange = np.arange(width).reshape(1, -1).repeat(height, 0) - width * 0.5\n#     vrange = np.arange(height).reshape(-1, 1).repeat(width, 1) - height * 0.5\n#     ranges = np.array([urange / focalLength, np.ones(urange.shape), -vrange / focalLength]).transpose([1, 2, 0])\n#     X = depths / focalLength * urange\n#     Y = depths\n#     Z = -depths / focalLength * vrange\n#     d = -(normals[:, :, 0] * X + normals[:, :, 1] * Y + normals[:, :, 2] * Z)\n\n\n#     maskFilename = filename.replace(\'mlt\', \'valid\')\n#     invalidMask = np.array(PIL.Image.open(maskFilename))\n#     # if len(invalidMask.shape) == 3:\n#     #     invalidMask = invalidMask.mean(2)\n#     #     pass\n#     invalidMask = invalidMask < 128\n#     invalidMask += depths > 10\n\n\n#     normalDotThreshold = np.cos(np.deg2rad(15))\n#     distanceThreshold = 0.15\n#     colorPalette = ColorPalette(len(planes))\n#     for planeIndex, plane in enumerate(planes):\n#         planeD = np.linalg.norm(plane)\n#         planeNormal = -plane / planeD\n\n#         distance = np.abs(planeNormal[0] * X + planeNormal[1] * Y + planeNormal[2] * Z + planeD)\n\n#         normalXYZ = np.dot(ranges, planeNormal)\n#         normalXYZ = np.reciprocal(normalXYZ)\n#         planeY = -normalXYZ * planeD\n\n#         mask = (planeY > 0) * (np.abs(np.dot(normals, planeNormal)) > normalDotThreshold) * (distance < distanceThreshold)\n\n#         maxDepth = 10\n#         minDepth = 0\n#         #PIL.Image.fromarray((np.minimum(np.maximum((planeY - minDepth) / (maxDepth - minDepth), 0), 1) * 255).astype(np.uint8)).save(outputFolder + \'/plane_depth_\' + str(planeIndex) + \'.png\')\n#         #PIL.Image.fromarray(((planeNormal.reshape(1, 1, 3).repeat(height, 0).repeat(width, 1) + 1) / 2 * 255).astype(np.uint8)).save(outputFolder + \'/plane_normal_\' + str(planeIndex) + \'.png\')\n#         planeImage = colorImage * 0.3\n#         planeImage[mask] += colorPalette.getColor(planeIndex) * 0.7\n#         PIL.Image.fromarray(planeImage.astype(np.uint8)).save(outputFolder + \'/plane_mask_\' + str(planeIndex) + \'_\' + str(outputIndex) + \'.png\')\n#         #PIL.Image.fromarray(mask.astype(np.uint8) * 255).save(outputFolder + \'/mask_\' + str(planeIndex) + \'.png\')\n#         continue\n#     return\n\ndef residual2Planes(residualPlanes, predefinedPlanes):\n    numClusters = predefinedPlanes.shape[0]\n    planes = []\n    for residualPlane in residualPlanes:\n        gridIndex = int(residualPlane[0]) / numClusters\n        planeIndex = int(residualPlane[0]) % numClusters\n        planes.append(predefinedPlanes[planeIndex] + residualPlane[1:])\n        continue\n    return planes\n\ndef residual2PlanesGlobal(residualPlanes, predefinedPlanes):\n    numClusters = predefinedPlanes.shape[0]\n    planes = []\n    for residualPlane in residualPlanes:\n        planeIndex = int(residualPlane[0])\n        planes.append(predefinedPlanes[planeIndex] + residualPlane[1:])\n        continue\n    return planes\n\n\ndef getPlaneInfo(planes):\n    imageWidth = 640\n    imageHeight = 480\n    focalLength = 517.97\n    urange = np.arange(imageWidth).reshape(1, -1).repeat(imageHeight, 0) - imageWidth * 0.5\n    vrange = np.arange(imageHeight).reshape(-1, 1).repeat(imageWidth, 1) - imageHeight * 0.5\n    ranges = np.array([urange / focalLength, np.ones(urange.shape), -vrange / focalLength]).transpose([1, 2, 0])\n\n    planeDepths = PlaneDepthLayer(planes, ranges)\n    planeNormals = PlaneNormalLayer(planes, ranges)\n    return planeDepths, planeNormals\n\ndef getProbability(image, segmentation):\n    width = image.shape[1]\n    height = image.shape[0]\n    numPlanes = segmentation.shape[0]\n    probabilities = np.exp(segmentation)\n    probabilities = probabilities / probabilities.sum(0)\n    # The input should be the negative of the logarithm of probability values\n    # Look up the definition of the softmax_to_unary for more information\n    unary = unary_from_softmax(probabilities)\n\n    # The inputs should be C-continious -- we are using Cython wrapper\n    unary = np.ascontiguousarray(unary)\n\n    d = dcrf.DenseCRF(height * width, numPlanes)\n\n    d.setUnaryEnergy(unary)\n\n    # This potential penalizes small pieces of segmentation that are\n    # spatially isolated -- enforces more spatially consistent segmentations\n    # feats = create_pairwise_gaussian(sdims=(10, 10), shape=(height, width))\n    # d.addPairwiseEnergy(feats, compat=300,\n    #                                         kernel=dcrf.DIAG_KERNEL,\n    #                                         normalization=dcrf.NORMALIZE_SYMMETRIC)\n\n    # This creates the color-dependent features --\n    # because the segmentation that we get from CNN are too coarse\n    # and we can use local color features to refine them\n\n    feats = create_pairwise_bilateral(sdims=(50, 50), schan=(20, 20, 20),\n                                      img=image, chdim=2)\n    d.addPairwiseEnergy(feats, compat=10,\n                        kernel=dcrf.DIAG_KERNEL,\n                        normalization=dcrf.NORMALIZE_SYMMETRIC)\n\n    Q = d.inference(50)\n\n    inds = np.argmax(Q, axis=0).reshape((height, width))\n    probabilities = np.zeros((height * width, numPlanes))\n    probabilities[np.arange(height * width), inds.reshape(-1)] = 1\n    probabilities = probabilities.reshape([height, width, -1])\n    #print(res.shape)\n    return probabilities\n\ndef getProbabilityMax(segmentation):\n    width = segmentation.shape[2]\n    height = segmentation.shape[1]\n    numPlanes = segmentation.shape[0]\n    inds = np.argmax(segmentation.reshape([-1, height * width]), axis=0)\n    probabilities = np.zeros((height * width, numPlanes))\n    probabilities[np.arange(height * width), inds] = 1\n    probabilities = probabilities.reshape([height, width, -1])\n    return probabilities\n\ndef evaluateNormal(predNormal, gtSegmentations, numPlanes):\n    numImages = predNormal.shape[0]\n    normal = np.linalg.norm(predNormal, axis=-1)\n    errors = []\n    for imageIndex in xrange(numImages):\n        var = 0\n        count = 0\n\n        invalidNormalMask = np.linalg.norm(predNormal[imageIndex], axis=-1) > 1 - 1e-4\n        for planeIndex in xrange(numPlanes[imageIndex]):\n            #mask = gtSegmentations[imageIndex, :, :, planeIndex].astype(np.bool)\n            mask = gtSegmentations[imageIndex] == planeIndex\n            mask = cv2.erode(mask.astype(np.float32), np.ones((5, 5))) > 0.5\n            mask = np.logical_and(mask, invalidNormalMask)\n            if mask.sum() == 0:\n                continue\n            normals = predNormal[imageIndex][mask]\n            averageNormal = np.mean(normals, axis=0, keepdims=True)\n            averageNormal /= np.linalg.norm(averageNormal)\n            degrees = np.rad2deg(np.arccos(np.minimum(np.sum(normals * averageNormal, axis=-1), 1)))\n            #degrees = np.rad2deg(np.arccos(np.sum(normals * averageNormal, axis=-1)))\n            degrees = np.minimum(degrees, 180 - degrees)\n            var += degrees.sum()\n            count += degrees.shape[0]\n            #var += degrees.mean()\n            #totalNumPlanes += 1\n            #print(np.sum(normals * averageNormal, axis=-1))\n            print(planeIndex, degrees.sum() / degrees.shape[0])\n            cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(mask))\n            #print(normals)\n            # if planeIndex == 4:\n            #     for normal in normals:\n            #         print(normal)\n            #         continue\n            #     print(normals.mean(0))\n            #     exit(1)\n            # print(degrees)\n            # print(planeIndex, averageNormal, degrees.mean())\n            # print(normals[degrees > 90])\n\n            continue\n        var /= count\n        errors.append(var)\n        #print(var / totalNumPlanes)\n        #exit(1)\n        continue\n    var = np.array(errors).mean()\n    print(var)\n    return var\n\ndef evaluateDepths(predDepths, gtDepths, validMasks, planeMasks=True, printInfo=True):\n    masks = np.logical_and(np.logical_and(validMasks, planeMasks), gtDepths > 1e-4)\n\n    numPixels = float(masks.sum())\n\n    rmse = np.sqrt((pow(predDepths - gtDepths, 2) * masks).sum() / numPixels)\n    rmse_log = np.sqrt((pow(np.log(predDepths) - np.log(gtDepths), 2) * masks).sum() / numPixels)\n    log10 = (np.abs(np.log10(np.maximum(predDepths, 1e-4)) - np.log10(np.maximum(gtDepths, 1e-4))) * masks).sum() / numPixels\n    rel = (np.abs(predDepths - gtDepths) / np.maximum(gtDepths, 1e-4) * masks).sum() / numPixels\n    rel_sqr = (pow(predDepths - gtDepths, 2) / np.maximum(gtDepths, 1e-4) * masks).sum() / numPixels\n    deltas = np.maximum(predDepths / np.maximum(gtDepths, 1e-4), gtDepths / np.maximum(predDepths, 1e-4)) + (1 - masks.astype(np.float32)) * 10000\n    accuracy_1 = (deltas < 1.25).sum() / numPixels\n    accuracy_2 = (deltas < pow(1.25, 2)).sum() / numPixels\n    accuracy_3 = (deltas < pow(1.25, 3)).sum() / numPixels\n    recall = float(masks.sum()) / validMasks.sum()\n    #print((rms, recall))\n    if printInfo:\n        print((\'evaluate\', rel, rel_sqr, log10, rmse, rmse_log, accuracy_1, accuracy_2, accuracy_3, recall))\n        pass\n    return rel, rel_sqr, log10, rmse, rmse_log, accuracy_1, accuracy_2, accuracy_3, recall\n    #return rel, log10, rms, accuracy_1, accuracy_2, accuracy_3, recall\n\ndef drawDepthImage(depth):\n    #return cv2.applyColorMap(np.clip(depth / 10 * 255, 0, 255).astype(np.uint8), cv2.COLORMAP_JET)\n    return 255 - np.clip(depth / 5 * 255, 0, 255).astype(np.uint8)\n\ndef drawDepthImageOverlay(image, depth):\n    #return cv2.applyColorMap(np.clip(depth / 10 * 255, 0, 255).astype(np.uint8), cv2.COLORMAP_JET)\n    depth = np.clip(depth / min(np.max(depth), 10) * 255, 0, 255).astype(np.uint8)\n    imageOverlay = np.stack([image[:, :, 1], depth, image[:, :, 2]], axis=2)\n    return imageOverlay\n\ndef drawNormalImage(normal):\n    return ((normal + 1) / 2 * 255).astype(np.uint8)\n\ndef drawSegmentationImage(segmentations, randomColor=None, numColors=22, blackIndex=-1):\n    if segmentations.ndim == 2:\n        numColors = max(numColors, segmentations.max() + 2, blackIndex + 1)\n    else:\n        numColors = max(numColors, segmentations.shape[2] + 2, blackIndex + 1)\n        pass\n    randomColor = ColorPalette(numColors).getColorMap()\n    if blackIndex >= 0:\n        randomColor[blackIndex] = 0\n        pass\n    width = segmentations.shape[1]\n    height = segmentations.shape[0]\n    if segmentations.ndim == 3:\n        #segmentation = (np.argmax(segmentations, 2) + 1) * (np.max(segmentations, 2) > 0.5)\n        segmentation = np.argmax(segmentations, 2)\n    else:\n        segmentation = segmentations\n        pass\n    segmentation = segmentation.astype(np.int)\n    return randomColor[segmentation.reshape(-1)].reshape((height, width, 3))\n\ndef drawMaskImage(mask):\n    return (np.clip(mask * 255, 0, 255)).astype(np.uint8)\n\ndef drawDiffImage(values_1, values_2, threshold):\n    #return cv2.applyColorMap(np.clip(np.abs(values_1 - values_2) / threshold * 255, 0, 255).astype(np.uint8), cv2.COLORMAP_JET)\n    return np.clip(np.abs(values_1 - values_2) / threshold * 255, 0, 255).astype(np.uint8)\n\n\ndef getSuperpixels(depth, normal, width, height, numPlanes=50, numGlobalPlanes = 10):\n    depth = np.expand_dims(depth, -1)\n\n    urange = (np.arange(width, dtype=np.float32) / (width + 1) - 0.5) / focalLength * 641\n    urange = np.tile(np.reshape(urange, [1, -1]), [height, 1])\n    vrange = (np.arange(height, dtype=np.float32) / (height + 1) - 0.5) / focalLength * 481\n    vrange = np.tile(np.reshape(vrange, [-1, 1]), [1, width])\n\n    ranges = np.stack([urange, np.ones([height, width]), -vrange], axis=2)\n    #ranges = np.expand_dims(ranges, 0)\n\n    planeImage = np.sum(normal * ranges, axis=2, keepdims=True) * depth * normal\n    planeImage = planeImage / 10 * 1000\n\n    superpixels = segmentation.slic(planeImage, compactness=30, n_segments=400)\n    g = graph.rag_mean_color(planeImage, superpixels, mode=\'similarity\')\n    planeSegmentation = graph.cut_normalized(superpixels, g)\n    return planeSegmentation, superpixels\n\n\ndef calcPlaneDepths(planes, width, height, info):\n    urange = np.arange(width, dtype=np.float32).reshape(1, -1).repeat(height, 0) / (width + 1) * (info[16] + 1) - info[2]\n    vrange = np.arange(height, dtype=np.float32).reshape(-1, 1).repeat(width, 1) / (height + 1) * (info[17] + 1) - info[6]\n    ranges = np.array([urange / info[0], np.ones(urange.shape), -vrange / info[5]]).transpose([1, 2, 0])\n    planeDepths = PlaneDepthLayer(planes, ranges)\n    return planeDepths\n\ndef calcPlaneNormals(planes, width, height):\n    planeNormals = -planes / np.maximum(np.linalg.norm(planes, axis=-1, keepdims=True), 1e-4)\n    return np.tile(planeNormals.reshape([1, 1, -1, 3]), [height, width, 1, 1])\n\n\ndef writePLYFile(folder, index, image, depth, segmentation, planes, info):\n    imageFilename = str(index) + \'_model_texture.png\'\n    cv2.imwrite(folder + \'/\' + imageFilename, image)\n\n    width = image.shape[1]\n    height = image.shape[0]\n\n    numPlanes = planes.shape[0]\n\n    camera = getCameraFromInfo(info)\n\n    #camera = getNYURGBDCamera()\n    #camera = getSUNCGCamera()\n\n    urange = (np.arange(width, dtype=np.float32) / width * camera[\'width\'] - camera[\'cx\']) / camera[\'fx\']\n    urange = urange.reshape(1, -1).repeat(height, 0)\n    vrange = (np.arange(height, dtype=np.float32) / height * camera[\'height\'] - camera[\'cy\']) / camera[\'fy\']\n    vrange = vrange.reshape(-1, 1).repeat(width, 1)\n    X = depth * urange\n    Y = depth\n    Z = -depth * vrange\n\n    XYZ = np.stack([X, Y, Z], axis=2)\n\n\n    #focalLength = 517.97\n\n    faces = []\n    #minDepthDiff = 0.15\n    #maxDepthDiff = 0.3\n    #occlusionBoundary = boundaries[:, :, 1]\n    betweenRegionThreshold = 0.1\n    nonPlanarRegionThreshold = 0.02\n\n    planesD = np.linalg.norm(planes, axis=1, keepdims=True)\n    planeNormals = -planes / np.maximum(planesD, 1e-4)\n\n    croppingRatio = -0.05\n    dotThreshold = np.cos(np.deg2rad(30))\n\n    for y in xrange(height - 1):\n        for x in xrange(width - 1):\n            if y < height * croppingRatio or y > height * (1 - croppingRatio) or x < width * croppingRatio or x > width * (1 - croppingRatio):\n                continue\n\n            segmentIndex = segmentation[y][x]\n            if segmentIndex == -1:\n                continue\n\n            point = XYZ[y][x]\n            #neighborPixels = []\n            validNeighborPixels = []\n            for neighborPixel in [(x, y + 1), (x + 1, y), (x + 1, y + 1)]:\n                neighborSegmentIndex = segmentation[neighborPixel[1]][neighborPixel[0]]\n                if neighborSegmentIndex == segmentIndex:\n                    if segmentIndex < numPlanes:\n                        validNeighborPixels.append(neighborPixel)\n                    else:\n                        neighborPoint = XYZ[neighborPixel[1]][neighborPixel[0]]\n                        if np.linalg.norm(neighborPoint - point) < nonPlanarRegionThreshold:\n                            validNeighborPixels.append(neighborPixel)\n                            pass\n                        pass\n                else:\n                    neighborPoint = XYZ[neighborPixel[1]][neighborPixel[0]]\n                    if segmentIndex < numPlanes and neighborSegmentIndex < numPlanes:\n                        if (abs(np.dot(planeNormals[segmentIndex], neighborPoint) + planesD[segmentIndex]) < betweenRegionThreshold or abs(np.dot(planeNormals[neighborSegmentIndex], point) + planesD[neighborSegmentIndex]) < betweenRegionThreshold) and np.abs(np.dot(planeNormals[segmentIndex], planeNormals[neighborSegmentIndex])) < dotThreshold:\n                            validNeighborPixels.append(neighborPixel)\n                            pass\n                    else:\n                        if np.linalg.norm(neighborPoint - point) < betweenRegionThreshold:\n                            validNeighborPixels.append(neighborPixel)\n                            pass\n                        pass\n                    pass\n                continue\n            if len(validNeighborPixels) == 3:\n                faces.append((x, y, x + 1, y + 1, x + 1, y))\n                faces.append((x, y, x, y + 1, x + 1, y + 1))\n            elif len(validNeighborPixels) == 2 and segmentIndex < numPlanes:\n                faces.append((x, y, validNeighborPixels[0][0], validNeighborPixels[0][1], validNeighborPixels[1][0], validNeighborPixels[1][1]))\n                pass\n            continue\n        continue\n\n    with open(folder + \'/\' + str(index) + \'_model.ply\', \'w\') as f:\n        header = """"""ply\nformat ascii 1.0\ncomment VCGLIB generated\ncomment TextureFile """"""\n        header += imageFilename\n        header += """"""\nelement vertex """"""\n        header += str(width * height)\n        header += """"""\nproperty float x\nproperty float y\nproperty float z\nelement face """"""\n        header += str(len(faces))\n        header += """"""\nproperty list uchar int vertex_indices\nproperty list uchar float texcoord\nend_header\n""""""\n        f.write(header)\n        for y in xrange(height):\n            for x in xrange(width):\n                segmentIndex = segmentation[y][x]\n                if segmentIndex == -1:\n                    f.write(""0.0 0.0 0.0\\n"")\n                    continue\n                point = XYZ[y][x]\n                X = point[0]\n                Y = point[1]\n                Z = point[2]\n                #Y = depth[y][x]\n                #X = Y / focalLength * (x - width / 2) / width * 640\n                #Z = -Y / focalLength * (y - height / 2) / height * 480\n                f.write(str(X) + \' \' +    str(Z) + \' \' + str(-Y) + \'\\n\')\n                continue\n            continue\n\n\n        for face in faces:\n            f.write(\'3 \')\n            for c in xrange(3):\n                f.write(str(face[c * 2 + 1] * width + face[c * 2]) + \' \')\n                continue\n            f.write(\'6 \')\n            for c in xrange(3):\n                f.write(str(float(face[c * 2]) / width) + \' \' + str(1 - float(face[c * 2 + 1]) / height) + \' \')\n                continue\n            f.write(\'\\n\')\n            continue\n        f.close()\n        pass\n    return\n\ndef writePLYFileDepth(folder, index, image, depth, segmentation, planes, info):\n    imageFilename = str(index) + \'_segmentation_pred_blended_0.png\'\n    #cv2.imwrite(folder + \'/\' + imageFilename, image)\n\n    numPlanes = planes.shape[0]\n\n    camera = getCameraFromInfo(info)\n\n    #camera = getNYURGBDCamera()\n    #camera = getSUNCGCamera()\n\n    urange = (np.arange(width, dtype=np.float32) / width * camera[\'width\'] - camera[\'cx\']) / camera[\'fx\']\n    urange = urange.reshape(1, -1).repeat(height, 0)\n    vrange = (np.arange(height, dtype=np.float32) / height * camera[\'height\'] - camera[\'cy\']) / camera[\'fy\']\n    vrange = vrange.reshape(-1, 1).repeat(width, 1)\n    X = depth * urange\n    Y = depth\n    Z = -depth * vrange\n\n    XYZ = np.stack([X, Y, Z], axis=2).reshape(-1, 3)\n\n\n    #focalLength = 517.97\n    width = image.shape[1]\n    height = image.shape[0]\n\n    faces = []\n    minDepthDiff = 0.15\n    maxDepthDiff = 0.3\n    #occlusionBoundary = boundaries[:, :, 1]\n\n    for y in xrange(height - 1):\n        for x in xrange(width - 1):\n            segmentIndex = segmentation[y][x]\n            if segmentIndex == -1:\n                continue\n            #if segmentIndex == 0:\n            #continue\n            #depths = [depth[y][x], depth[y + 1][x], depth[y + 1][x + 1]]\n            # if segmentIndex >= 0 or (max([occlusionBoundary[y][x], occlusionBoundary[y + 1][x], occlusionBoundary[y + 1][x + 1]]) < 0.5 and (max(depths) - min(depths)) < maxDepthDiff):\n            #     if segmentation[y + 1][x] == segmentIndex and segmentation[y + 1][x + 1] == segmentIndex:\n            #         if min(depths) > 0 and max(depths) < 10:\n            #             faces.append((x, y, x, y + 1, x + 1, y + 1))\n            #             pass\n            #         pass\n            #     elif max(depths) - min(depths) < minDepthDiff:\n            #         faces.append((x, y, x, y + 1, x + 1, y + 1))\n            #         pass\n            #     pass\n\n\n            if segmentation[y + 1][x] == segmentIndex and segmentation[y + 1][x + 1] == segmentIndex and min(depths) > 0 and max(depths) < 10:\n                faces.append((x, y, x, y + 1, x + 1, y + 1))\n                pass\n\n\n            depths = [depth[y][x], depth[y][x + 1], depth[y + 1][x + 1]]\n            # if segmentIndex > 0 or (max([occlusionBoundary[y][x], occlusionBoundary[y][x + 1], occlusionBoundary[y + 1][x + 1]]) < 0.5 and (max(depths) - min(depths)) < maxDepthDiff):\n            #     if segmentation[y][x + 1] == segmentIndex and segmentation[y + 1][x + 1] == segmentIndex:\n            #         if min(depths) > 0 and max(depths) < 10:\n            #             faces.append((x, y, x + 1, y + 1, x + 1, y))\n            #             pass\n            #         pass\n            #     elif max(depths) - min(depths) < minDepthDiff:\n            #         faces.append((x, y, x + 1, y + 1, x + 1, y))\n            #         pass\n            #     pass\n            if segmentation[y][x + 1] == segmentIndex and segmentation[y + 1][x + 1] == segmentIndex and min(depths) > 0 and max(depths) < 10:\n                faces.append((x, y, x + 1, y + 1, x + 1, y))\n                pass\n            continue\n        continue\n\n    #print(len(faces))\n    print(folder)\n    with open(folder + \'/\' + str(index) + \'_model.ply\', \'w\') as f:\n        header = """"""ply\nformat ascii 1.0\ncomment VCGLIB generated\ncomment TextureFile """"""\n        header += imageFilename\n        header += """"""\nelement vertex """"""\n        header += str(width * height)\n        header += """"""\nproperty float x\nproperty float y\nproperty float z\nelement face """"""\n        header += str(len(faces))\n        header += """"""\nproperty list uchar int vertex_indices\nproperty list uchar float texcoord\nend_header\n""""""\n        f.write(header)\n        for y in xrange(height):\n            for x in xrange(width):\n                segmentIndex = segmentation[y][x]\n                if segmentIndex == -1:\n                    f.write(""0.0 0.0 0.0\\n"")\n                    continue\n                Y = depth[y][x]\n                X = Y / focalLength * (x - width / 2) / width * 640\n                Z = -Y / focalLength * (y - height / 2) / height * 480\n                f.write(str(X) + \' \' +    str(Z) + \' \' + str(-Y) + \'\\n\')\n                continue\n            continue\n\n\n        for face in faces:\n            f.write(\'3 \')\n            for c in xrange(3):\n                f.write(str(face[c * 2 + 1] * width + face[c * 2]) + \' \')\n                continue\n            f.write(\'6 \')\n            for c in xrange(3):\n                f.write(str(float(face[c * 2]) / width) + \' \' + str(1 - float(face[c * 2 + 1]) / height) + \' \')\n                continue\n            f.write(\'\\n\')\n            continue\n        f.close()\n        pass\n\treturn\n\ndef writeHTML(folder, numImages):\n    from html import HTML\n\n    h = HTML(\'html\')\n    h.p(\'Results\')\n    h.br()\n    #suffixes = [\'\', \'_crf_1\']\n    #folders = [\'test_all_resnet_v2\' + suffix + \'/\' for suffix in suffixes]\n    for index in xrange(numImages):\n        t = h.table(border=\'1\')\n        r_inp = t.tr()\n        r_inp.td(\'input\')\n        r_inp.td().img(src=str(index) + \'_image.png\')\n        r_inp.td().img(src=\'one.png\')\n        r_inp.td().img(src=\'one.png\')\n        #r_inp.td().img(src=\'one.png\')\n        r_inp.td().img(src=str(index) + \'_model.png\')\n\n        r_gt = t.tr()\n        r_gt.td(\'gt\')\n        r_gt.td().img(src=str(index) + \'_segmentation_gt.png\')\n        r_gt.td().img(src=str(index) + \'_depth.png\')\n        r_gt.td().img(src=\'one.png\')\n        r_gt.td().img(src=str(index) + \'_normal.png\')\n\n        #r_gt.td().img(src=folders[0] + str(index) + \'_depth_gt.png\')\n        #r_gt.td().img(src=folders[0] + \'_depth_gt_diff.png\')\n        #r_gt.td().img(src=folders[0] + str(index) + \'_normal_gt.png\')\n\n        r_pred = t.tr()\n        r_pred.td(\'pred\')\n        r_pred.td().img(src=str(index) + \'_segmentation_pred.png\')\n        r_pred.td().img(src=str(index) + \'_depth_pred.png\')\n        r_pred.td().img(src=str(index) + \'_depth_pred_diff.png\')\n        r_pred.td().img(src=str(index) + \'_normal_pred.png\')\n\n        h.br()\n        continue\n\n    html_file = open(folder + \'/index.html\', \'w\')\n    html_file.write(str(h))\n    html_file.close()\n    return\n\n\ndef writeHTMLRGBD(filename, numImages=10):\n    from html import HTML\n\n    #0.227 0.194 0.163 0.157 0.100\n    #0.196 0.150 0.143 0.488 0.082\n    h = HTML(\'html\')\n    h.p(\'Results\')\n    h.br()\n    path = \'\'\n    folders = [\'pred\', \'local_02\', \'local_05\', \'local_07\', \'local_10\', \'local_12\']\n    second_folders = [\'pred_local_02\', \'pred_local_05\', \'pred_local_07\', \'pred_local_10\', \'pred_local_12\']\n    for index in xrange(numImages):\n        firstFolder = path + folders[0]\n        t = h.table(border=\'1\')\n        r_inp = t.tr()\n        r_inp.td(\'input\')\n        r_inp.td().img(src=firstFolder + \'/\' + str(index) + \'_image.png\')\n        r_inp.td().img(src=firstFolder + \'/\' + str(index) + \'_depth.png\')\n\n        r = t.tr()\n        r.td(\'PlaneNet prediction\')\n        r.td().img(src=firstFolder + \'/\' + str(index) + \'_segmentation_pred.png\')\n        r.td().img(src=firstFolder + \'/\' + str(index) + \'_depth_pred.png\')\n\n        r = t.tr()\n        r.td(\'segmentation\')\n        for folder in folders[1:6]:\n            r.td().img(src=folder + \'/\' + str(index) + \'_segmentation_pred.png\')\n            continue\n\n        r = t.tr()\n        r.td(\'depth\')\n        for folder in folders[1:6]:\n            folder = path + folder\n            r.td().img(src=folder + \'/\' + str(index) + \'_depth_pred.png\')\n            continue\n\n        r = t.tr()\n        r.td(\'pixelwise prediction\')\n        r.td().img(src=path + second_folders[0] + \'/\' + str(index) + \'_depth.png\')\n\n        r = t.tr()\n        r.td(\'segmentation\')\n        for folder in second_folders[0:5]:\n            r.td().img(src=folder + \'/\' + str(index) + \'_segmentation_pred.png\')\n            continue\n\n        r = t.tr()\n        r.td(\'depth\')\n        for folder in second_folders[0:5]:\n            folder = path + folder\n            r.td().img(src=folder + \'/\' + str(index) + \'_depth_pred.png\')\n            continue\n\n        h.br()\n        continue\n\n    html_file = open(filename, \'w\')\n    html_file.write(str(h))\n    html_file.close()\n    return\n\ndef writeHTMLPlane(filename, numImages=10):\n    from html import HTML\n\n    #0.227 0.194 0.163 0.157 0.100\n    #0.196 0.150 0.143 0.488 0.082\n    h = HTML(\'html\')\n    h.p(\'Results\')\n    h.br()\n    path = \'\'\n    folders = [\'PlaneNet_hybrid\', \'PlaneNet\', \'GT_RANSAC\', \'pixelwise_RANSAC\']\n    for index in xrange(numImages):\n        firstFolder = path + folders[0]\n        t = h.table(border=\'1\')\n        r_inp = t.tr()\n        r_inp.td(\'input\')\n        r_inp.td().img(src=firstFolder + \'/\' + str(index) + \'_image.png\')\n        r_inp.td().img(src=firstFolder + \'/\' + str(index) + \'_depth.png\')\n\n        # r = t.tr()\n        # r.td(\'PlaneNet prediction\')\n        # r.td().img(src=firstFolder + \'/\' + str(index) + \'_segmentation_pred.png\')\n        # r.td().img(src=firstFolder + \'/\' + str(index) + \'_depth_pred.png\')\n\n        r = t.tr()\n        r.td(\'segmentation\')\n        for folder in folders[0:6]:\n            r.td().img(src=folder + \'/\' + str(index) + \'_segmentation_pred.png\')\n            continue\n\n        r = t.tr()\n        r.td(\'depth\')\n        for folder in folders[0:6]:\n            folder = path + folder\n            r.td().img(src=folder + \'/\' + str(index) + \'_depth_pred.png\')\n            continue\n\n        h.br()\n        continue\n\n    html_file = open(filename, \'w\')\n    html_file.write(str(h))\n    html_file.close()\n    return\n\ndef getNYURGBDCamera():\n    camera = {}\n    camera[\'fx\'] = 5.1885790117450188e+02\n    camera[\'fy\'] = 5.1946961112127485e+02\n    camera[\'cx\'] = 3.2558244941119034e+02 - 40\n    camera[\'cy\'] = 2.5373616633400465e+02 - 44\n    camera[\'width\'] = 561\n    camera[\'height\'] = 427\n    camera[\'depth_shift\'] = 1000\n    return camera\n\ndef getSUNCGCamera():\n    camera = {}\n    camera[\'fx\'] = 517.97\n    camera[\'fy\'] = 517.97\n    camera[\'cx\'] = 320\n    camera[\'cy\'] = 240\n    camera[\'width\'] = 640\n    camera[\'height\'] = 480\n    camera[\'depth_shift\'] = 1000\n    return camera\n\ndef get3DCamera():\n    camera = {}\n    camera[\'fx\'] = 1075\n    camera[\'fy\'] = 1075\n    camera[\'cx\'] = 637\n    camera[\'cy\'] = 508\n    camera[\'width\'] = 1280\n    camera[\'height\'] = 1024\n    camera[\'depth_shift\'] = 4000\n    return camera\n\ndef getCameraFromInfo(info):\n    camera = {}\n    camera[\'fx\'] = info[0]\n    camera[\'fy\'] = info[5]\n    camera[\'cx\'] = info[2]\n    camera[\'cy\'] = info[6]\n    camera[\'width\'] = info[16]\n    camera[\'height\'] = info[17]\n    camera[\'depth_shift\'] = info[18]\n    return camera\n\ndef fitPlane(points):\n    if points.shape[0] == points.shape[1]:\n        return np.linalg.solve(points, np.ones(points.shape[0]))\n    else:\n        return np.linalg.lstsq(points, np.ones(points.shape[0]), rcond=None)[0]\n\ndef fitPlanes(depth, info, numPlanes=50, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=-1):\n    camera = getCameraFromInfo(info)\n    width = depth.shape[1]\n    height = depth.shape[0]\n\n    #camera = getNYURGBDCamera()\n    #camera = getSUNCGCamera()\n\n    urange = (np.arange(width, dtype=np.float32) / width * camera[\'width\'] - camera[\'cx\']) / camera[\'fx\']\n    urange = urange.reshape(1, -1).repeat(height, 0)\n    vrange = (np.arange(height, dtype=np.float32) / height * camera[\'height\'] - camera[\'cy\']) / camera[\'fy\']\n    vrange = vrange.reshape(-1, 1).repeat(width, 1)\n    X = depth * urange\n    Y = depth\n    Z = -depth * vrange\n\n    # print(depth[:10, :10])\n    # print(X[:10, :10])\n    # print(Z[:10, :10])\n    # print(urange[:10, :10])\n    # print(vrange[:10, :10])\n    # exit(1)\n    XYZ = np.stack([X, Y, Z], axis=2).reshape(-1, 3)\n    XYZ = XYZ[depth.reshape(-1) != 0]\n    planes = []\n    planePointsArray = []\n    for planeIndex in xrange(numPlanes):\n        maxNumInliers = planeAreaThreshold\n        for iteration in xrange(numIterations):\n            if local > 0:\n                sampledPoint = XYZ[np.random.randint(XYZ.shape[0], size=(1))]\n                sampledPoints = XYZ[np.linalg.norm(XYZ - sampledPoint, 2, 1) < local]\n                if sampledPoints.shape[0] < 3:\n                    continue\n                elif sampledPoints.shape[0] > 3:\n                    sampledPoints = sampledPoints[np.random.choice(np.arange(sampledPoints.shape[0]), size=(3))]\n                    pass\n            else:\n                sampledPoints = XYZ[np.random.choice(np.arange(XYZ.shape[0]), size=(3))]\n                pass\n\n            try:\n                plane = fitPlane(sampledPoints)\n                pass\n            except:\n                continue\n            diff = np.abs(np.matmul(XYZ, plane) - np.ones(XYZ.shape[0])) / np.linalg.norm(plane)\n            numInliers = np.sum(diff < distanceThreshold)\n            if numInliers > maxNumInliers:\n                maxNumInliers = numInliers\n                bestPlane = plane\n                pass\n            continue\n        if maxNumInliers == planeAreaThreshold:\n            break\n        planes.append(bestPlane)\n\n        diff = np.abs(np.matmul(XYZ, bestPlane) - np.ones(XYZ.shape[0])) / np.linalg.norm(bestPlane)\n        inlierIndices = diff < distanceThreshold\n        inliersPoints = XYZ[inlierIndices]\n        planePointsArray.append(inliersPoints)\n        XYZ = XYZ[np.logical_not(inlierIndices)]\n        if XYZ.shape[0] < planeAreaThreshold:\n            break\n        continue\n\n    planes = np.array(planes)\n    if len(planes.shape) == 0:\n        planes = np.zeros((numPlanes, 3))\n        pass\n    if len(planes.shape) == 1:\n        if planes.shape[0] == 3:\n            planes = np.expand_dims(planes, 0)\n        else:\n            planes = np.zeros((numPlanes, 3))\n            pass\n        pass\n\n    planeSegmentation = np.ones(depth.shape) * numPlanes\n    for planeIndex, planePoints in enumerate(planePointsArray):\n        planeDepth = planePoints[:, 1]\n        u = np.round((planePoints[:, 0] / planeDepth * camera[\'fx\'] + camera[\'cx\']) / camera[\'width\'] * width).astype(np.int32)\n        v = np.round((-planePoints[:, 2] / planeDepth * camera[\'fy\'] + camera[\'cy\']) / camera[\'height\'] * height).astype(np.int32)\n        planeSegmentation[v, u] = planeIndex\n        continue\n\n\n    planesD = 1 / np.linalg.norm(planes, 2, axis=1, keepdims=True)\n    planes *= pow(planesD, 2)\n\n    if planes.shape[0] < numPlanes:\n        #print(planes.shape)\n        planes = np.concatenate([planes, np.zeros((numPlanes - planes.shape[0], 3))], axis=0)\n        pass\n\n    planeDepths = calcPlaneDepths(planes, width, height, info)\n\n    allDepths = np.concatenate([planeDepths, np.zeros((height, width, 1))], axis=2)\n    depthPred = allDepths.reshape(-1, numPlanes + 1)[np.arange(width * height), planeSegmentation.astype(np.int32).reshape(-1)].reshape(height, width)\n\n    return planes, planeSegmentation, depthPred\n\n\ndef fitPlanesSegmentation(depth, segmentation, info, numPlanes=50, numPlanesPerSegment=3, planeAreaThreshold=3*4, numIterations=100, distanceThreshold=0.05, local=-1):\n\n    camera = getCameraFromInfo(info)\n    width = depth.shape[1]\n    height = depth.shape[0]\n\n    urange = (np.arange(width, dtype=np.float32) / width * camera[\'width\'] - camera[\'cx\']) / camera[\'fx\']\n    urange = urange.reshape(1, -1).repeat(height, 0)\n    vrange = (np.arange(height, dtype=np.float32) / height * camera[\'height\'] - camera[\'cy\']) / camera[\'fy\']\n    vrange = vrange.reshape(-1, 1).repeat(width, 1)\n    X = depth * urange\n    Y = depth\n    Z = -depth * vrange\n\n    allXYZ = np.stack([X, Y, Z], axis=2).reshape(-1, 3)\n\n    planes = []\n    planePointIndices = []\n\n    for segmentIndex in xrange(segmentation.max()):\n        segmentMask = np.logical_and(segmentation == segmentIndex, depth != 0)\n        XYZ = allXYZ[segmentMask.reshape(-1)]\n        if XYZ.shape[0] < planeAreaThreshold:\n            continue\n        for planeIndex in xrange(numPlanesPerSegment):\n            maxNumInliers = planeAreaThreshold\n            for iteration in xrange(numIterations):\n                if local > 0:\n                    sampledPoint = XYZ[np.random.randint(XYZ.shape[0], size=(1))]\n                    sampledPoints = XYZ[np.linalg.norm(XYZ - sampledPoint, 2, 1) < local]\n\n                    if sampledPoints.shape[0] < 3:\n                        continue\n                    elif sampledPoints.shape[0] > 3:\n                        sampledPoints = sampledPoints[np.random.choice(np.arange(sampledPoints.shape[0]), size=(3))]\n                        pass\n                else:\n                    sampledPoints = XYZ[np.random.choice(np.arange(XYZ.shape[0]), size=(3))]\n                    pass\n\n                try:\n                    plane = fitPlane(sampledPoints)\n                    pass\n                except:\n                    continue\n                diff = np.abs(np.matmul(XYZ, plane) - np.ones(XYZ.shape[0])) / np.linalg.norm(plane)\n                numInliers = np.sum(diff < distanceThreshold)\n                if numInliers > maxNumInliers:\n                    maxNumInliers = numInliers\n                    bestPlane = plane\n                    pass\n                continue\n            if maxNumInliers == planeAreaThreshold:\n                break\n            planes.append(bestPlane)\n\n            diff = np.abs(np.matmul(XYZ, bestPlane) - np.ones(XYZ.shape[0])) / np.linalg.norm(bestPlane)\n            inlierIndices = diff < distanceThreshold\n            inliersPoints = XYZ[inlierIndices]\n            planePointIndices.append(inliersPoints)\n            XYZ = XYZ[np.logical_not(inlierIndices)]\n            if XYZ.shape[0] < planeAreaThreshold:\n                break\n            continue\n        continue\n\n    if len(planes) > numPlanes:\n        planeList = zip(planes, planePointIndices)\n        planeList = sorted(planeList, key=lambda x:-len(x[1]))\n        planeList = planeList[:numPlanes]\n        planes, planePointIndices = zip(*planeList)\n        pass\n\n\n\n    planeSegmentation = np.ones(depth.shape) * numPlanes\n    for planeIndex, planePoints in enumerate(planePointIndices):\n        planeDepth = planePoints[:, 1]\n        u = np.round((planePoints[:, 0] / planeDepth * camera[\'fx\'] + camera[\'cx\']) / camera[\'width\'] * width).astype(np.int32)\n        v = np.round((-planePoints[:, 2] / planeDepth * camera[\'fy\'] + camera[\'cy\']) / camera[\'height\'] * height).astype(np.int32)\n        planeSegmentation[v, u] = planeIndex\n        continue\n\n    planes = np.array(planes)\n    planesD = 1 / np.linalg.norm(planes, 2, 1, keepdims=True)\n    planes *= pow(planesD, 2)\n    if planes.shape[0] < numPlanes:\n        planes = np.concatenate([planes, np.zeros((numPlanes - planes.shape[0], 3))], axis=0)\n        pass\n\n    planeDepths = calcPlaneDepths(planes, width, height, info)\n\n\n    allDepths = np.concatenate([planeDepths, np.zeros((height, width, 1))], axis=2)\n    depthPred = allDepths.reshape([height * width, numPlanes + 1])[np.arange(width * height), planeSegmentation.astype(np.int32).reshape(-1)].reshape(height, width)\n\n    return planes, planeSegmentation, depthPred\n\n\ndef fitPlanesNYU(image, depth, normal, semantics, info, numOutputPlanes=20, local=-1, parameters={}):\n    camera = getCameraFromInfo(info)\n    width = depth.shape[1]\n    height = depth.shape[0]\n\n    #camera = getNYURGBDCamera()\n    #camera = getSUNCGCamera()\n\n    urange = (np.arange(width, dtype=np.float32) / width * camera[\'width\'] - camera[\'cx\']) / camera[\'fx\']\n    urange = urange.reshape(1, -1).repeat(height, 0)\n    vrange = (np.arange(height, dtype=np.float32) / height * camera[\'height\'] - camera[\'cy\']) / camera[\'fy\']\n    vrange = vrange.reshape(-1, 1).repeat(width, 1)\n    X = depth * urange\n    Y = depth\n    Z = -depth * vrange\n\n    # print(depth[:10, :10])\n    # print(X[:10, :10])\n    # print(Z[:10, :10])\n    # print(urange[:10, :10])\n    # print(vrange[:10, :10])\n    # exit(1)\n    XYZ = np.stack([X, Y, Z], axis=2).reshape(-1, 3)\n    #XYZ = XYZ[depth.reshape(-1) != 0]\n    planes = []\n    planeMasks = []\n    invalidDepthMask = depth < 1e-4\n\n    if \'planeAreaThreshold\' in parameters:\n        planeAreaThreshold = parameters[\'planeAreaThreshold\']\n    else:\n        planeAreaThreshold = 500\n        pass\n    if \'distanceThreshold\' in parameters:\n        distanceThreshold = parameters[\'distanceThreshold\']\n    else:\n        distanceThreshold = 0.05\n        pass\n    if \'local\' in parameters:\n        local = parameters[\'local\']\n    else:\n        local = 0.2\n        pass\n\n    for y in xrange(5, height, 10):\n        for x in xrange(5, width, 10):\n            if invalidDepthMask[y][x]:\n                continue\n            sampledPoint = XYZ[y * width + x]\n            sampledPoints = XYZ[np.linalg.norm(XYZ - sampledPoint, 2, 1) < local]\n            if sampledPoints.shape[0] < 3:\n                continue\n            sampledPoints = sampledPoints[np.random.choice(np.arange(sampledPoints.shape[0]), size=(3))]\n            try:\n                plane = fitPlane(sampledPoints)\n                pass\n            except:\n                continue\n\n            diff = np.abs(np.matmul(XYZ, plane) - np.ones(XYZ.shape[0])) / np.linalg.norm(plane)\n            inlierIndices = diff < distanceThreshold\n            #print(np.sum(inlierIndices), planeAreaThreshold)\n            if np.sum(inlierIndices) < planeAreaThreshold:\n                continue\n\n            planes.append(plane)\n            planeMasks.append(inlierIndices.reshape((height, width)))\n            continue\n        continue\n\n    planes = np.array(planes)\n\n    planeList = zip(planes, planeMasks)\n    planeList = sorted(planeList, key=lambda x:-x[1].sum())\n    planes, planeMasks = zip(*planeList)\n\n\n    invalidMask = np.zeros((height, width), np.bool)\n    validPlanes = []\n    validPlaneMasks = []\n\n    for planeIndex, plane in enumerate(planes):\n        planeMask = planeMasks[planeIndex]\n        if np.logical_and(planeMask, invalidMask).sum() > planeMask.sum() * 0.5:\n            continue\n        # if len(validPlanes) > 0:\n        #     cv2.imwrite(\'test/mask_\' + str(len(validPlanes) - 1) + \'_available.png\', drawMaskImage(1 - invalidMask))\n        #     pass\n        validPlanes.append(plane)\n        validPlaneMasks.append(planeMask)\n        invalidMask = np.logical_or(invalidMask, planeMask)\n        continue\n    planes = np.array(validPlanes)\n    planesD = 1 / np.maximum(np.linalg.norm(planes, 2, 1, keepdims=True), 1e-4)\n    planes *= pow(planesD, 2)\n\n    planeMasks = np.stack(validPlaneMasks, axis=2)\n\n    cv2.imwrite(\'test/depth.png\', drawDepthImage(depth))\n    for planeIndex in xrange(planes.shape[0]):\n        cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(planeMasks[:, :, planeIndex]))\n        continue\n\n    print(\'number of planes: \' + str(planes.shape[0]))\n\n    planeSegmentation = getSegmentationsGraphCut(planes, image, depth, normal, semantics, info, parameters=parameters)\n\n    cv2.imwrite(\'test/segmentation_refined.png\', drawSegmentationImage(planeSegmentation, blackIndex=planes.shape[0]))\n\n    #planeSegmentation[planes.shape[0]] = numOutputPlanes\n\n\n    return planes, planeSegmentation\n\n\ndef limitPlaneNumber(planes, planeSegmentation, numOutputPlanes):\n    if planes.shape[0] > numOutputPlanes:\n        planeInfo = []\n        for planeIndex in xrange(planes.shape[0]):\n            mask = planeSegmentation == planeIndex\n            planeInfo.append((planes[planeIndex], mask))\n            continue\n        planeInfo = sorted(planeInfo, key=lambda x: -x[1].sum())\n        newPlanes = []\n        newPlaneSegmentation = np.full(planeSegmentation.shape, numOutputPlanes)\n        for planeIndex in xrange(numOutputPlanes):\n            newPlanes.append(planeInfo[planeIndex][0])\n            newPlaneSegmentation[planeInfo[planeIndex][1]] = planeIndex\n            continue\n        newPlanes = np.array(newPlanes)\n        return newPlanes, newPlaneSegmentation\n    else:\n        planeSegmentation[planeSegmentation == planes.shape[0]] = numOutputPlanes\n        planes = np.concatenate([planes, np.zeros((numOutputPlanes - planes.shape[0], 3))], axis=0)\n        return planes, planeSegmentation\n    return\n\ndef removeSmallPlanes(planes, planeSegmentation, planeAreaThreshold):\n    planeInfo = []\n    for planeIndex in xrange(planes.shape[0]):\n        mask = planeSegmentation == planeIndex\n        planeInfo.append((planes[planeIndex], mask, mask.sum()))\n        continue\n    planeInfo = sorted(planeInfo, key=lambda x: -x[2])\n    newPlanes = []\n    newPlaneSegmentation = np.full(planeSegmentation.shape, numOutputPlanes)\n    for planeIndex, info in enumerate(planeInfo):\n        if info[2] < planeAreaThreshold:\n            break\n        newPlanes.append(info[0])\n        newPlaneSegmentation[info[1]] = planeIndex\n        continue\n    newPlanes = np.array(newPlanes)\n    return newPlanes, newPlaneSegmentation\n\ndef calcDepthFromPlanes(planes, planeSegmentation, info, nonPlaneInfo = {}):\n    width = planeSegmentation.shape[1]\n    height = planeSegmentation.shape[0]\n    planeDepths = calcPlaneDepths(planes, width, height, info)\n\n    if \'depth\' in nonPlaneInfo:\n        allDepths = np.concatenate([planeDepths, np.expand_dims(nonPlaneInfo[\'depth\'], -1)], axis=2)\n    else:\n        allDepths = planeDepths\n        pass\n\n    depthPred = allDepths.reshape([height * width, -1])[np.arange(width * height), planeSegmentation.astype(np.int32).reshape(-1)].reshape(height, width)\n    return depthPred\n\ndef calcNormalFromPlanes(planes, planeSegmentation, info, nonPlaneInfo = {}):\n    width = planeSegmentation.shape[1]\n    height = planeSegmentation.shape[0]\n    planeNormals = calcPlaneNormals(planes, width, height)\n\n    if \'normal\' in nonPlaneInfo:\n        allNormals = np.concatenate([planeNormals, np.expand_dims(nonPlaneInfo[\'normal\'], 2), ], axis=2)\n    else:\n        allNormals = planeNormals\n        pass\n    normalPred = allNormals.reshape(width * height, -1, 3)[np.arange(width * height), planeSegmentation.reshape(-1)].reshape((height, width, 3))\n    return normalPred\n\n\n\ndef fitPlanesPoints(points, segmentation, groupSegments, numPlanes=50, numPlanesPerSegment=3, numPlanesPerGroup=8, segmentRatio=0.1, planeAreaThreshold=100, numIterations=100, distanceThreshold=0.05, local=-1):\n    allXYZ = points.reshape(-1, 3)\n\n\n    # planeDiffThreshold = distanceThreshold\n    # planes = np.load(\'test/planes.pny.npy\')\n    # planePointIndices = np.load(\'test/plane_indices.pny.npy\')\n    # planeIndex_1 = 1\n    # planeIndex_2 = 2\n    # for planeIndex_1 in [1, ]:\n    #     for planeIndex_2 in [2, 5, 7, 10]:\n    #         plane_1 = planes[planeIndex_1]\n    #         plane_2 = planes[planeIndex_2]\n    #         points_1 = allXYZ[planePointIndices[planeIndex_1]]\n    #         points_2 = allXYZ[planePointIndices[planeIndex_2]]\n\n    #         diff_1 = np.abs(np.matmul(points_2, plane_1) - np.ones(points_2.shape[0])) / np.linalg.norm(plane_1)\n    #         diff_2 = np.abs(np.matmul(points_1, plane_2) - np.ones(points_1.shape[0])) / np.linalg.norm(plane_2)\n    #         print(np.sum(diff_1 < planeDiffThreshold), diff_1.shape[0])\n    #         print(np.sum(diff_2 < planeDiffThreshold), diff_2.shape[0])\n    #         print((diff_1.mean(), diff_2.mean()))\n    #         # if np.sum(diff_1 < planeDiffThreshold) > diff_1.shape[0] * inlierThreshold or np.sum(diff_2 < planeDiffThreshold) > diff_2.shape[0] * inlierThreshold:\n    #         #     planesDiff[planeIndex][otherPlaneIndex] = 1\n    #         #     planesDiff[otherPlaneIndex][planeIndex] = 1\n    #         #     pass\n\n\n    #         # if min(diff_1.mean(), diff_2.mean()) < planeDiffThreshold:\n    #         #     planesDiff[planeIndex][otherPlaneIndex] = 1\n    #         #     planesDiff[otherPlaneIndex][planeIndex] = 1\n    #         #     pass\n\n    #         continue\n    #     continue\n\n    # print(planes / np.linalg.norm(planes, axis=1, keepdims=True))\n    # exit(1)\n\n    planes = []\n    planePointIndices = []\n    groupNumPlanes = []\n    for groupIndex, group in enumerate(groupSegments):\n        groupPlanes = []\n        groupPlanePointIndices = []\n        for segmentIndex in group:\n            segmentMask = segmentation == segmentIndex\n            # planes.append(np.ones(3))\n            # planePointIndices.append(segmentMask.nonzero()[0])\n            # continue\n\n            XYZ = allXYZ[segmentMask.reshape(-1)]\n            numPoints = XYZ.shape[0]\n\n            if numPoints <= planeAreaThreshold:\n                if numPoints > 0:\n                    groupPlanes.append(np.random.random(3))\n                    groupPlanePointIndices.append(segmentMask.nonzero()[0])\n                    pass\n                continue\n\n            for planeIndex in xrange(numPlanesPerSegment):\n                maxNumInliers = 0\n                for iteration in xrange(numIterations):\n                    if local > 0:\n                        sampledPoint = XYZ[np.random.randint(XYZ.shape[0], size=(1))]\n                        sampledPoints = XYZ[np.linalg.norm(XYZ - sampledPoint, axis=1) < local]\n\n                        if sampledPoints.shape[0] < 3:\n                            continue\n                        elif sampledPoints.shape[0] > 3:\n                            sampledPoints = sampledPoints[np.random.choice(np.arange(sampledPoints.shape[0]), size=(3))]\n                            pass\n                        pass\n                    else:\n                        sampledPoints = XYZ[np.random.choice(np.arange(XYZ.shape[0]), size=(3))]\n                        pass\n\n                    try:\n                        plane = fitPlane(sampledPoints)\n                        pass\n                    except:\n                        continue\n                    diff = np.abs(np.matmul(XYZ, plane) - np.ones(XYZ.shape[0])) / np.linalg.norm(plane)\n                    numInliers = np.sum(diff < distanceThreshold)\n                    if numInliers > maxNumInliers:\n                        maxNumInliers = numInliers\n                        bestPlane = plane\n                        pass\n                    continue\n\n                groupPlanes.append(bestPlane)\n\n                diff = np.abs(np.matmul(XYZ, bestPlane) - np.ones(XYZ.shape[0])) / np.linalg.norm(bestPlane)\n                inlierIndices = diff < distanceThreshold\n                if inlierIndices.sum() > numPoints * (1 - segmentRatio):\n                    inlierIndices = np.ones(diff.shape, dtype=np.bool)\n                    pass\n                pointIndices = segmentMask.nonzero()[0][inlierIndices]\n                groupPlanePointIndices.append(pointIndices)\n                segmentMask[pointIndices] = 0\n\n                XYZ = XYZ[np.logical_not(inlierIndices)]\n                if XYZ.shape[0] <= planeAreaThreshold:\n                    if XYZ.shape[0] > 0:\n                        groupPlanes.append(np.random.random(3))\n                        groupPlanePointIndices.append(segmentMask.nonzero()[0])\n                        pass\n                    break\n                continue\n            continue\n        if len(groupPlanes) == 0:\n            continue\n\n        # planeList = zip(groupPlanes, groupPlanePointIndices)\n        # planeList = sorted(planeList, key=lambda x:-len(x[1]))\n        # groupPlanes, groupPlanePointIndices = zip(*planeList)\n\n        # groupMask = np.zeros(segmentation.shape, np.bool)\n        # for segmentIndex in group:\n        #     groupMask = np.logical_or(groupMask, segmentation == segmentIndex)\n        #     continue\n\n        # groupPlanePointIndices = []\n        # for plane in groupPlanes:\n        #     groupPoints = allXYZ[groupMask]\n        #     diff = np.abs(np.matmul(groupPoints, plane) - np.ones(groupPoints.shape[0])) / np.linalg.norm(plane)\n        #     inlierIndices = diff < distanceThreshold\n        #     pointIndices = groupMask.nonzero()[0][inlierIndices]\n        #     groupPlanePointIndices.append(pointIndices)\n        #     groupMask[pointIndices] = 0\n        #     continue\n\n        # if len(groupPlanes) > numPlanesPerGroup:\n        #     planeList = zip(groupPlanes, groupPlanePointIndices)\n        #     planeList = sorted(planeList, key=lambda x:-len(x[1]))\n        #     planeList = planeList[:numPlanesPerGroup]\n        #     groupPlanes, groupPlanePointIndices = zip(*planeList)\n        #     pass\n\n\n        numPointsOri = 0\n        for indices in groupPlanePointIndices:\n            numPointsOri += len(indices)\n            continue\n\n        groupPlanes, groupPlanePointIndices = mergePlanes3D(points, groupPlanes, groupPlanePointIndices, planeDiffThreshold=distanceThreshold, planeAreaThreshold=planeAreaThreshold)\n        if len(groupPlanes) > 1:\n            groupPlanes, groupPlanePointIndices = mergePlanes3D(points, groupPlanes, groupPlanePointIndices, planeDiffThreshold=distanceThreshold, planeAreaThreshold=planeAreaThreshold)\n            pass\n        #groupPlanes, groupPlanePointIndices = mergePlanes(points, groupPlanes, groupPlanePointIndices, planeDiffThreshold=distanceThreshold)\n\n        # if groupIndex == 14:\n        #     groupPlanes, groupPlanePointIndices = mergePlanes(points, groupPlanes, groupPlanePointIndices, planeDiffThreshold=distanceThreshold)\n        #     planesTest = np.array(groupPlanes)\n        #     np.save(\'test/planes.npy\', planesTest)\n        #     np.save(\'test/plane_indices.npy\', groupPlanePointIndices)\n        #     print(planesTest / np.linalg.norm(planesTest, axis=1, keepdims=True))\n        #     #exit(1)\n        #     pass\n\n        numPoints = 0\n        for indices in groupPlanePointIndices:\n            numPoints += len(indices)\n            continue\n        planes += groupPlanes\n        planePointIndices += groupPlanePointIndices\n        groupNumPlanes.append(len(groupPlanes))\n        #planeSegmentation[groupPlaneSegmentation >= 0] = groupPlaneSegmentation[groupPlaneSegmentation >= 0] + numPlanes\n        continue\n\n    #planes = np.concatenate(planes, axis=0)\n\n    # if len(planes) > numPlanes:\n    #     planeList = zip(planes, planePointsArray)\n    #     planeList = sorted(planeList, key=lambda x:-len(x[1]))\n    #     planeList = planeList[:numPlanes]\n    #     planes, planePointsArray = zip(*planeList)\n    #     pass\n\n\n    # if len(planes) > numPlanes:\n    #     planeList = zip(planes, planePointIndices)\n    #     planeList = sorted(planeList, key=lambda x:-len(x[1]))\n    #     planeList = planeList[:numPlanes]\n    #     planes, planePointIndices = zip(*planeList)\n    #     pass\n\n\n    if len(planes) == 0:\n        return np.array([]), np.ones(segmentation.shape).astype(np.int32) * (-1), []\n\n    planes = np.array(planes)\n    print(\'number of planes: \' + str(planes.shape[0]))\n\n    # print(planes)\n    # for v in planePointsArray:\n    #     print(len(v))\n    # if planes.shape[0] < numPlanes:\n    #     planes = np.concatenate([planes, np.zeros((numPlanes - planes.shape[0], 3))], axis=0)\n    #     pass\n\n\n    planeSegmentation = np.ones(segmentation.shape) * (-1)\n    for planeIndex, planePoints in enumerate(planePointIndices):\n        planeSegmentation[planePoints] = planeIndex\n        continue\n\n    planesD = 1 / np.linalg.norm(planes, 2, 1, keepdims=True)\n    planes *= pow(planesD, 2)\n\n    return planes, planeSegmentation, groupNumPlanes\n\ndef mergePlanes3D(points, planes, planePointIndices, planeDiffThreshold = 0.05, planeAngleThreshold = 30, inlierThreshold = 0.9, planeAreaThreshold = 100):\n\n    # planesD = np.linalg.norm(planes, axis=1, keepdims=True)\n    # planes = planes / pow(planesD, 2)\n    # planesDiff = (np.linalg.norm(np.expand_dims(planes, 1) - np.expand_dims(planes, 0), axis=2) < planeDiffThreshold).astype(np.int32)\n\n    planeList = zip(planes, planePointIndices)\n    planeList = sorted(planeList, key=lambda x:-len(x[1]))\n    planes, planePointIndices = zip(*planeList)\n\n    groupedPlanes = []\n    groupedPlanePointIndices = []\n\n    numPlanes = len(planes)\n    usedPlaneConfidence = np.ones(numPlanes, np.float32) * (-1)\n    usedPlaneMap = np.ones(numPlanes, np.int32) * (-1)\n\n    for planeIndex, plane in enumerate(planes):\n        if usedPlaneConfidence[planeIndex] > 0:\n            continue\n        usedPlaneConfidence[planeIndex] = 1\n        usedPlaneMap[planeIndex] = planeIndex\n        XYZ = points[planePointIndices[planeIndex]]\n        for otherPlaneIndex in xrange(planeIndex + 1, numPlanes):\n            #if planeIndex not in [0, 1, 2, ]:\n            #break\n            #if usedPlanes[otherPlaneIndex]:\n            #continue\n            #otherPlane = planes[otherPlaneIndex]\n            #if np.abs(np.dot(plane, otherPlane)) / (np.linalg.norm(plane) * np.linalg.norm(otherPlane)) < np.cos(np.deg2rad(planeAngleThreshold)):\n            #continue\n\n            otherXYZ = points[planePointIndices[otherPlaneIndex]]\n\n            diff_1 = np.abs(np.matmul(otherXYZ, plane) - np.ones(otherXYZ.shape[0])) / np.linalg.norm(plane)\n            #diff_2 = np.abs(np.matmul(XYZ, otherPlane) - np.ones(XYZ.shape[0])) / np.linalg.norm(otherPlane)\n            ratio = float(np.sum(diff_1 < planeDiffThreshold)) / diff_1.shape[0]\n            if ratio > max(inlierThreshold, usedPlaneConfidence[otherPlaneIndex]):\n                usedPlaneConfidence[otherPlaneIndex] = ratio\n                usedPlaneMap[otherPlaneIndex] = planeIndex\n                pass\n            continue\n        continue\n\n    for planeIndex in xrange(numPlanes):\n        mergedPlanes = (usedPlaneMap == planeIndex).nonzero()[0].tolist()\n        if len(mergedPlanes) == 0:\n            continue\n        pointIndices = []\n        for mergedPlaneIndex in mergedPlanes:\n            pointIndices += planePointIndices[mergedPlaneIndex].tolist()\n            continue\n        if len(pointIndices) <= planeAreaThreshold:\n            continue\n        XYZ = points[pointIndices]\n        ranges = XYZ.max(0) - XYZ.min(0)\n        ranges.sort()\n        #print((planeIndex, ranges.tolist() + XYZ.mean(0).tolist()))\n        if ranges[1] < 0.2:\n            continue\n        #continue\n        #print(XYZ.shape[0])\n        #print(ranges)\n        #if ranges.max() * 5 >= XYZ.shape[0]:\n        #continue\n        plane = fitPlane(XYZ)\n        groupedPlanes.append(plane)\n        groupedPlanePointIndices.append(np.array(pointIndices))\n        continue\n\n    return groupedPlanes, groupedPlanePointIndices\n\ndef mergePlanesBackup(points, planes, planePointIndices, planeDiffThreshold = 0.05, planeAngleThreshold = 30, inlierThreshold = 0.8):\n\n    # planesD = np.linalg.norm(planes, axis=1, keepdims=True)\n    # planes = planes / pow(planesD, 2)\n    # planesDiff = (np.linalg.norm(np.expand_dims(planes, 1) - np.expand_dims(planes, 0), axis=2) < planeDiffThreshold).astype(np.int32)\n    numPlanes = len(planes)\n    planesDiff = np.diag(np.ones(numPlanes))\n    for planeIndex, plane in enumerate(planes):\n        for otherPlaneIndex in xrange(planeIndex + 1, numPlanes):\n            otherPlane = planes[otherPlaneIndex]\n            if np.abs(np.dot(plane, otherPlane)) / (np.linalg.norm(plane) * np.linalg.norm(otherPlane)) < np.cos(np.deg2rad(planeAngleThreshold)):\n                continue\n            XYZ = points[planePointIndices[planeIndex]]\n            otherXYZ = points[planePointIndices[otherPlaneIndex]]\n            diff_1 = np.abs(np.matmul(otherXYZ, plane) - np.ones(otherXYZ.shape[0])) / np.linalg.norm(plane)\n            diff_2 = np.abs(np.matmul(XYZ, otherPlane) - np.ones(XYZ.shape[0])) / np.linalg.norm(otherPlane)\n\n            if np.sum(diff_1 < planeDiffThreshold) > diff_1.shape[0] * inlierThreshold or np.sum(diff_2 < planeDiffThreshold) > diff_2.shape[0] * inlierThreshold:\n                planesDiff[planeIndex][otherPlaneIndex] = 1\n                planesDiff[otherPlaneIndex][planeIndex] = 1\n                pass\n\n\n            # if min(diff_1.mean(), diff_2.mean()) < planeDiffThreshold:\n            #     planesDiff[planeIndex][otherPlaneIndex] = 1\n            #     planesDiff[otherPlaneIndex][planeIndex] = 1\n            #     pass\n\n\n            # if diff_1.mean() < planeDiffThreshold:\n            #     planesDiff[planeIndex][otherPlaneIndex] = 1\n            #     pass\n            # if diff_2.mean() < planeDiffThreshold:\n            #     planesDiff[otherPlaneIndex][planeIndex] = 1\n            #     pass\n            continue\n        continue\n\n    # while True:\n    #     #nextPlanesDiff = (np.matmul(planesDiff, planesDiff) > 0.5).astype(np.int32)\n    #     nextPlanesDiff = ((planesDiff + np.matmul(np.transpose(planesDiff), planesDiff)) > 0.5).astype(np.int32)\n    #     if np.all(nextPlanesDiff == planesDiff):\n    #         break\n    #     planesDiff = nextPlanesDiff\n    #     continue\n\n    #print(planesDiff)\n    usedPlanes = np.zeros(planesDiff.shape[0])\n    uniquePlanesDiff = []\n    for planeIndex in xrange(planesDiff.shape[0]):\n        planesMask = np.maximum(planesDiff[planeIndex] - usedPlanes, 0)\n        if planesMask[planeIndex] > 0:\n            uniquePlanesDiff.append(planesMask)\n            usedPlanes += planesMask\n            pass\n        continue\n    planesDiff = np.array(uniquePlanesDiff)\n    #print(planesDiff)\n\n\n    # diffMatrix = np.diag(np.ones(planesDiff.shape[0])).astype(np.float64)\n    # diffMatrix -= np.tril(np.ones(planesDiff.shape), -1)\n    # planesDiff = np.maximum(np.matmul(diffMatrix, planesDiff), 0)\n    # planesDiff *= np.expand_dims(np.diag(planesDiff), -1)\n    # planesDiff = np.unique(planesDiff, axis=0)\n\n    groupedPlanes = []\n    groupedPlanePointIndices = []\n    for groupIndex in xrange(planesDiff.shape[0]):\n        if planesDiff[groupIndex].sum() == 0:\n            continue\n        segmentIndices = planesDiff[groupIndex].nonzero()[0]\n        pointIndices = []\n        for segmentIndex in segmentIndices.tolist():\n            pointIndices += planePointIndices[segmentIndex].tolist()\n            continue\n        XYZ = points[pointIndices]\n        plane = fitPlane(XYZ)\n        groupedPlanes.append(plane)\n        groupedPlanePointIndices.append(np.array(pointIndices))\n        continue\n\n    return groupedPlanes, groupedPlanePointIndices\n\n\n# def evaluatePlaneSegmentation(predPlanes, predSegmentations, gtPlanes, gtSegmentations, gtNumPlanes, prefix = \'\', numOutputPlanes = 20):\n#     if len(gtSegmentations.shape) == 3:\n#         gtSegmentations = (np.expand_dims(gtSegmentations, -1) == np.arange(numOutputPlanes)).astype(np.float32)\n#         pass\n#     if len(predSegmentations.shape) == 3:\n#         predSegmentations = (np.expand_dims(predSegmentations, -1) == np.arange(numOutputPlanes)).astype(np.float32)\n#         pass\n\n#     width = predSegmentations.shape[2]\n#     height = predSegmentations.shape[1]\n\n#     planeDiffs = np.linalg.norm(np.expand_dims(gtPlanes, 2) - np.expand_dims(predPlanes, 1), axis=3)\n#     #print(gtPlanes[0])\n#     #print(predPlanes[0])\n#     #print(planeDiffs[0])\n\n#     planeAreas = np.sum(np.sum(gtSegmentations, axis=1), axis=1)\n#     intersection = np.sum((np.expand_dims(gtSegmentations, -1) * np.expand_dims(predSegmentations, 3) > 0.5).astype(np.float32), axis=(1, 2))\n#     union = np.sum((np.expand_dims(gtSegmentations, -1) + np.expand_dims(predSegmentations, 3) > 0.5).astype(np.float32), axis=(1, 2))\n#     planeIOUs = intersection / np.maximum(union, 1e-4)\n\n#     planeMask = np.expand_dims(np.arange(predPlanes.shape[1]), 0) < np.expand_dims(gtNumPlanes, 1)\n#     for index, numPlanes in enumerate(gtNumPlanes.tolist()):\n#         planeDiffs[index, numPlanes:] = 1000000\n#         planeIOUs[index, numPlanes:] = -1\n#         pass\n\n#     totalNumPlanes = gtNumPlanes.sum()\n\n#     numPixels = planeAreas.sum(1)\n\n#     # planeDistanceThreshold = 0.5\n#     # diffMask = (planeDiffs < planeDistanceThreshold).astype(np.float32)\n#     # maxIOU = np.max(planeIOUs * diffMask, axis=2)\n#     # IOU = 0.5\n#     # print(maxIOU[0])\n#     # print(planeMask[0])\n#     # print(((maxIOU >= IOU) * planeMask).sum(1).astype(np.float32))\n#     # print(gtNumPlanes)\n#     # print(float(((maxIOU >= IOU) * planeMask).sum()) / totalNumPlanes)\n\n#     # exit(1)\n\n#     pixel_curves = []\n#     plane_curves = []\n#     for planeDistanceThreshold in [0.1, 0.3, 0.5]:\n#         diffMask = (planeDiffs < planeDistanceThreshold).astype(np.float32)\n#         maxIOU = np.max(planeIOUs * diffMask, axis=2)\n#         stride = 0.1\n#         planeRecalls = []\n#         pixelRecalls = []\n#         for step in xrange(int(1 / stride + 1)):\n#             IOU = step * stride\n#             pixelRecalls.append((np.minimum((intersection * (planeIOUs >= IOU).astype(np.float32) * diffMask).sum(2), planeAreas).sum(1) / numPixels).mean())\n#             planeRecalls.append(float(((maxIOU >= IOU) * planeMask).sum()) / totalNumPlanes)\n#             continue\n\n#         pixel_curves.append(pixelRecalls)\n#         plane_curves.append(planeRecalls)\n#         pass\n\n#     for IOUThreshold in [0.3, 0.5, 0.7]:\n#         IOUMask = (planeIOUs > IOUThreshold).astype(np.float32)\n#         minDiff = np.min(planeDiffs * IOUMask + 1000000 * (1 - IOUMask), axis=2)\n#         stride = 0.05\n#         planeRecalls = []\n#         pixelRecalls = []\n#         for step in xrange(int(0.5 / stride + 1)):\n#             diff = step * stride\n#             pixelRecalls.append((np.minimum((intersection * (planeDiffs <= diff).astype(np.float32) * IOUMask).sum(2), planeAreas).sum(1) / numPixels).mean())\n#             planeRecalls.append(float(((minDiff <= diff) * planeMask).sum()) / totalNumPlanes)\n#             continue\n#         pixel_curves.append(pixelRecalls)\n#         plane_curves.append(planeRecalls)\n#         pass\n\n\n#     if prefix == \'\':\n#         return pixel_curves, plane_curves\n#     else:\n#         np.save(prefix + \'curves.npy\', pixel_curves + plane_curves)\n#         return\n\n\n# def evaluatePlanes(predDepths, predSegmentations, predNumPlanes, gtDepths, gtSegmentations, gtNumPlanes, prefix = \'\'):\n#     if len(gtSegmentations.shape) == 3:\n#         gtSegmentations = (np.expand_dims(gtSegmentations, -1) == np.arange(gtNumPlanes)).astype(np.float32)\n#         pass\n#     if len(predSegmentations.shape) == 3:\n#         predSegmentations = (np.expand_dims(predSegmentations, -1) == np.arange(predNumPlanes)).astype(np.float32)\n#         pass\n\n#     width = predSegmentations.shape[2]\n#     height = predSegmentations.shape[1]\n\n\n#     #print(gtPlanes[0])\n#     #print(predPlanes[0])\n#     #print(planeDiffs[0])\n\n#     planeAreas = np.sum(np.sum(gtSegmentations, axis=1), axis=1)\n#     intersectionMask = np.expand_dims(gtSegmentations, -1) * np.expand_dims(predSegmentations, 3) > 0.5\n#     depthDiffs = np.expand_dims(gtDepths, -1) - np.expand_dims(predDepths, 3)\n#     intersection = np.sum((intersectionMask).astype(np.float32), axis=(1, 2))\n\n#     planeDiffs = np.abs(depthDiffs * intersectionMask).sum(1).sum(1) / np.maximum(intersection, 1e-4)\n\n#     union = np.sum((np.expand_dims(gtSegmentations, -1) + np.expand_dims(predSegmentations, 3) > 0.5).astype(np.float32), axis=(1, 2))\n#     planeIOUs = intersection / np.maximum(union, 1e-4)\n\n\n#     for index, numPlanes in enumerate(gtNumPlanes.tolist()):\n#         planeDiffs[index, numPlanes:] = 1000000\n#         planeIOUs[index, numPlanes:] = -1\n#         pass\n\n#     totalNumPlanes = gtNumPlanes.sum()\n#     totalNumPredictions = predSegmentations.max(1).max(1).sum()\n\n#     numPixels = planeAreas.sum(1)\n\n#     # planeDistanceThreshold = 0.5\n#     # diffMask = (planeDiffs < planeDistanceThreshold).astype(np.float32)\n#     # maxIOU = np.max(planeIOUs * diffMask, axis=2)\n#     # IOU = 0.5\n#     # print(maxIOU[0])\n#     # print(planeMask[0])\n#     # print(((maxIOU >= IOU) * planeMask).sum(1).astype(np.float32))\n#     # print(gtNumPlanes)\n#     # print(float(((maxIOU >= IOU) * planeMask).sum()) / totalNumPlanes)\n\n#     # exit(1)\n\n#     pixel_curves = []\n#     plane_curves = []\n\n#     validPlaneMask = np.expand_dims(np.arange(gtNumPlanes), 0) < np.expand_dims(gtNumPlanes, 1)\n#     for planeDistanceThreshold in [0.05, 0.10, 0.15]:\n#         diffMask = (planeDiffs < planeDistanceThreshold).astype(np.float32)\n#         maxIOU = np.max(planeIOUs * diffMask, axis=2)\n#         stride = 0.1\n#         planeStatistics = []\n#         pixelRecalls = []\n#         for step in xrange(int(1 / stride + 1)):\n#             IOU = step * stride\n#             pixelRecalls.append((np.minimum((intersection * (planeIOUs >= IOU).astype(np.float32) * diffMask).sum(2), planeAreas).sum(1) / numPixels).mean())\n#             planeStatistics.append((float((((maxIOU >= IOU) * validPlaneMask)).sum()), totalNumPlanes, totalNumPredictions))\n#             continue\n\n#         pixel_curves.append(pixelRecalls)\n#         plane_curves.append(planeStatistics)\n#         pass\n\n\n#     for IOUThreshold in [0.3, 0.5, 0.7]:\n#         IOUMask = (planeIOUs > IOUThreshold).astype(np.float32)\n#         minDiff = np.min(planeDiffs * IOUMask + 1000000 * (1 - IOUMask), axis=2)\n#         stride = 0.02\n#         planeStatistics = []\n#         pixelRecalls = []\n#         for step in xrange(int(0.2 / stride + 1)):\n#             diff = step * stride\n#             pixelRecalls.append((np.minimum((intersection * (planeDiffs <= diff).astype(np.float32) * IOUMask).sum(2), planeAreas).sum(1) / numPixels).mean())\n#             planeStatistics.append(((((minDiff <= diff) * validPlaneMask).sum()), totalNumPlanes, totalNumPredictions))\n#             continue\n#         pixel_curves.append(pixelRecalls)\n#         plane_curves.append(planeStatistics)\n#         pass\n\n\n#     if prefix == \'\':\n#         return pixel_curves, plane_curves\n#     else:\n#         np.save(prefix + \'curves.npy\', pixel_curves + plane_curves)\n#         return\n\ndef evaluatePlanePrediction(predDepths, predSegmentations, predNumPlanes, gtDepths, gtSegmentations, gtNumPlanes, prefix = \'\'):\n    if len(gtSegmentations.shape) == 2:\n        gtSegmentations = (np.expand_dims(gtSegmentations, -1) == np.arange(gtNumPlanes)).astype(np.float32)\n        pass\n    if len(predSegmentations.shape) == 2:\n        predSegmentations = (np.expand_dims(predSegmentations, -1) == np.arange(predNumPlanes)).astype(np.float32)\n        pass\n\n    width = predSegmentations.shape[1]\n    height = predSegmentations.shape[0]\n\n\n    #print(gtPlanes[0])\n    #print(predPlanes[0])\n    #print(planeDiffs[0])\n\n    planeAreas = gtSegmentations.sum(axis=(0, 1))\n    intersectionMask = np.expand_dims(gtSegmentations, -1) * np.expand_dims(predSegmentations, 2) > 0.5\n    depthDiffs = np.expand_dims(gtDepths, -1) - np.expand_dims(predDepths, 2)\n    intersection = np.sum((intersectionMask).astype(np.float32), axis=(0, 1))\n\n    planeDiffs = np.abs(depthDiffs * intersectionMask).sum(axis=(0, 1)) / np.maximum(intersection, 1e-4)\n\n    #planeDiffs = np.linalg.norm(np.expand_dims(gtPlanes, 1) - np.expand_dims(predPlanes, 0), axis=2)\n\n    planeDiffs[intersection < 1e-4] = 1\n\n    union = np.sum(((np.expand_dims(gtSegmentations, -1) + np.expand_dims(predSegmentations, 2)) > 0.5).astype(np.float32), axis=(0, 1))\n    planeIOUs = intersection / np.maximum(union, 1e-4)\n\n\n    planeDiffs[gtNumPlanes:] = 1000000\n    planeIOUs[gtNumPlanes:] = -1\n\n    numPredictions = int(predSegmentations.max(axis=(0, 1)).sum())\n\n    numPixels = planeAreas.sum()\n\n\n    # print(gtNumPlanes)\n    # #print(\'IOU\')\n    # print(np.stack([planeIOUs.max(1), planeIOUs.argmax(1)], axis=1))\n    # print(\'diff\')\n    # #print(np.abs(depthDiffs * intersectionMask).sum(axis=(0, 1)))\n    # #print(np.maximum(intersection, 1e-4))\n    # #print(np.stack([depthDiffs.min(1), depthDiffs.argmin(1)], axis=1))\n    # print(np.stack([planeDiffs.min(1) * 10000, planeDiffs.argmin(1)], axis=1))\n    # print(planeDiffs)\n    # #exit(1)\n\n    pixel_curves = []\n    plane_curves = []\n\n    for planeDistanceThreshold in [0.1, 0.2, 0.3]:\n        diffMask = (planeDiffs < planeDistanceThreshold).astype(np.float32)\n        maxIOU = np.max(planeIOUs * diffMask, axis=1)\n        stride = 0.1\n        planeStatistics = []\n        pixelRecalls = []\n        for step in xrange(int(1.21 / stride + 1)):\n            IOU = step * stride\n            pixelRecalls.append(np.minimum((intersection * (planeIOUs >= IOU).astype(np.float32) * diffMask).sum(1), planeAreas).sum(0) / numPixels)\n            planeStatistics.append((((maxIOU >= IOU)[:gtNumPlanes]).sum(), gtNumPlanes, numPredictions))\n            continue\n\n        pixel_curves.append(pixelRecalls)\n        plane_curves.append(planeStatistics)\n        pass\n\n\n    for IOUThreshold in [0.3, 0.5, 0.7]:\n        IOUMask = (planeIOUs > IOUThreshold).astype(np.float32)\n        minDiff = np.min(planeDiffs * IOUMask + 1000000 * (1 - IOUMask), axis=1)\n        stride = 0.05\n        planeStatistics = []\n        pixelRecalls = []\n        for step in xrange(int(0.61 / stride + 1)):\n            diff = step * stride\n            pixelRecalls.append(np.minimum((intersection * (planeDiffs <= diff).astype(np.float32) * IOUMask).sum(1), planeAreas).sum() / numPixels)\n            planeStatistics.append((((minDiff <= diff)[:gtNumPlanes]).sum(), gtNumPlanes, numPredictions))\n            continue\n        pixel_curves.append(pixelRecalls)\n        plane_curves.append(planeStatistics)\n        pass\n\n\n    if prefix == \'\':\n        return pixel_curves, plane_curves\n    else:\n        np.save(prefix + \'curves.npy\', pixel_curves + plane_curves)\n        return\n\n\ndef plotCurves(x, ys, filename = \'test/test.png\', xlabel=\'\', ylabel=\'\', title=\'\', labels=[]):\n    import matplotlib.pyplot as plt\n    fig = plt.figure()\n    ax = plt.gca()\n    colors = []\n    markers = []\n    sizes = []\n    for label in labels:\n        if \'PlaneNet\' in label:\n            colors.append(\'blue\')\n        elif \'NYU\' in label:\n            colors.append(\'red\')\n        elif \'Manhattan\' in label:\n            colors.append(\'orange\')\n        else:\n            colors.append(\'brown\')\n            pass\n        if \'Oracle\' in label:\n            markers.append(\'o\')\n        else:\n            markers.append(\'\')\n            pass\n        if \'PlaneNet\' in label:\n            sizes.append(2)\n        else:\n            sizes.append(1)\n            pass\n        continue\n\n    ordering = [1, 2, 3, 4, 5, 6, 0]\n    final_labels = [\'PlaneNet\', \'[25]+depth\', \'[25]\', \'[9]+depth\', \'[9]\', \'[26]+depth\', \'[26]\']\n\n    #for index, y in enumerate(ys):\n    for order in ordering:\n        plt.plot(x, ys[order], figure=fig, label=final_labels[order], color=colors[order], marker=markers[order], linewidth=sizes[order])\n        continue\n    #plt.legend(loc=\'upper right\')\n    plt.legend(loc=\'upper center\', bbox_to_anchor=(0.5, 1.05), ncol=4, fancybox=True, shadow=True, handletextpad=0.1)\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel + \' %\')\n    ax.set_yticklabels(np.arange(0, 101, 20))\n    ax.spines[\'top\'].set_visible(False)\n    ax.spines[\'right\'].set_visible(False)\n    ax.get_xaxis().tick_bottom()\n    ax.get_yaxis().tick_left()\n    #ax.xaxis.set_label_coords(1.1, -0.025)\n    #plt.title(title)\n    plt.xlim((x[0], x[-1] + 0.01))\n    plt.ylim((0, 1))\n    plt.tight_layout(w_pad=0.3)\n    plt.savefig(filename)\n    return\n\n\ndef plotCurvesSplit(x, ys, filenames, xlabel=\'\', ylabel=\'\', title=\'\', labels=[]):\n    import matplotlib\n    matplotlib.rcParams.update({\'font.size\': 16})\n    matplotlib.rcParams.update({\'font.family\': \'Times New Roman\'})\n    #font = {\'size\'   : 22}\n    #matplotlib.rc(\'font\', **font)\n    #matplotlib.rc(\'xtick\', labelsize=22)\n    #matplotlib.rc(\'ytick\', labelsize=22)\n    #matplotlib.rc(\'xticklabels\', fontsize=22)\n    #matplotlib.rc(\'yticklabels\', fontsize=22)\n    #matplotlib.rc(\'xlabel\', size=22)\n    #matplotlib.rc(\'xlabel\', size=22)\n    import matplotlib.pyplot as plt\n\n    #plt.rcParams.update({\'font.size\': 16})\n\n    drawLegend = True\n\n    colors = []\n    markers = []\n    sizes = []\n    for label in labels:\n        if \'PlaneNet\' in label:\n            colors.append(\'blue\')\n        elif \'NYU\' in label:\n            colors.append(\'red\')\n        elif \'Manhattan\' in label:\n            colors.append(\'orange\')\n        else:\n            colors.append(\'brown\')\n            pass\n        if \'Oracle\' in label:\n            markers.append(\'o\')\n        else:\n            markers.append(\'\')\n            pass\n        if \'PlaneNet\' in label:\n            sizes.append(3)\n        else:\n            sizes.append(2)\n            pass\n        continue\n\n    final_labels = [\'PlaneNet\', \'[30] + GT depth\', \'[30] + Inferred depth\', \'[12] + GT depth\', \'[12] + Inferred depth\', \'[31] + GT depth\', \'[31] + Inferred depth\']\n\n    if drawLegend:\n        fig = plt.figure(figsize=(12, 6))\n    else:\n        fig = plt.figure()\n        pass\n\n    ax = plt.gca()\n\n    ordering = [2, 4, 6, 0]\n\n    #for index, y in enumerate(ys):\n    for order in ordering:\n        if drawLegend:\n            plt.plot(x, np.zeros(ys[order].shape), figure=fig, label=final_labels[order], color=colors[order], marker=markers[order], linewidth=sizes[order])\n        else:\n            plt.plot(x, ys[order], figure=fig, label=final_labels[order], color=colors[order], marker=markers[order], linewidth=sizes[order])\n            pass\n        continue\n\n    if drawLegend:\n        plt.legend(loc=\'upper right\')\n        pass\n    #plt.legend(loc=\'upper center\', bbox_to_anchor=(0.5, 1.05), ncol=4, fancybox=True, shadow=True, handletextpad=0.1)\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel + \' %\')\n\n    for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n                 ax.get_xticklabels() + ax.get_yticklabels()):\n        item.set_fontsize(22)\n\n    ax.set_yticklabels(np.arange(0, 101, 20))\n    ax.spines[\'top\'].set_visible(False)\n    ax.spines[\'right\'].set_visible(False)\n    ax.spines[\'bottom\'].set_linewidth(2)\n    ax.spines[\'left\'].set_linewidth(2)\n    ax.tick_params(width=2, length=8)\n    ax.get_xaxis().tick_bottom()\n    ax.get_yaxis().tick_left()\n    #ax.xaxis.set_label_coords(1.1, -0.025)\n    #plt.title(title)\n    plt.xlim((x[0], x[-1] + 0.01))\n    plt.ylim((0, 1))\n    plt.tight_layout(w_pad=0.3)\n    plt.savefig(filenames[0])\n\n\n    if drawLegend:\n        fig = plt.figure(figsize=(12, 6))\n    else:\n        fig = plt.figure()\n        pass\n\n    ax = plt.gca()\n\n    ordering = [1, 3, 5, 0]\n\n    #for index, y in enumerate(ys):\n    for order in ordering:\n        if drawLegend:\n            plt.plot(x, np.zeros(ys[order].shape), figure=fig, label=final_labels[order], color=colors[order], marker=markers[order], linewidth=sizes[order])\n        else:\n            plt.plot(x, ys[order], figure=fig, label=final_labels[order], color=colors[order], marker=markers[order], linewidth=sizes[order])\n            pass\n        continue\n\n    if drawLegend:\n        plt.legend(loc=\'upper right\')\n        pass\n    #plt.legend(loc=\'upper center\', bbox_to_anchor=(0.5, 1.05), ncol=4, fancybox=True, shadow=True, handletextpad=0.1)\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel + \' %\')\n\n    for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n                 ax.get_xticklabels() + ax.get_yticklabels()):\n        item.set_fontsize(22)\n\n    ax.set_yticklabels(np.arange(0, 101, 20))\n    ax.spines[\'top\'].set_visible(False)\n    ax.spines[\'right\'].set_visible(False)\n    ax.spines[\'bottom\'].set_linewidth(2)\n    ax.spines[\'left\'].set_linewidth(2)\n    ax.tick_params(width=2, length=8)\n    ax.get_xaxis().tick_bottom()\n    ax.get_yaxis().tick_left()\n    #ax.xaxis.set_label_coords(1.1, -0.025)\n    #plt.title(title)\n    plt.xlim((x[0], x[-1] + 0.01))\n    plt.ylim((0, 1))\n    plt.tight_layout(w_pad=0.3)\n    plt.savefig(filenames[1])\n    return\n\n\ndef plotCurvesSubplot(x, ysArray, filenames, xlabel=\'\', ylabels=[], labels=[]):\n    import matplotlib.pyplot as plt\n\n    plt.rcParams.update({\'font.size\': 14})\n\n    colors = []\n    markers = []\n    sizes = []\n    for label in labels:\n        if \'PlaneNet\' in label:\n            colors.append(\'blue\')\n        elif \'NYU\' in label:\n            colors.append(\'red\')\n        elif \'Manhattan\' in label:\n            colors.append(\'orange\')\n        else:\n            colors.append(\'brown\')\n            pass\n        if \'Oracle\' in label:\n            markers.append(\'o\')\n        else:\n            markers.append(\'\')\n            pass\n        if \'PlaneNet\' in label:\n            sizes.append(2)\n        else:\n            sizes.append(1)\n            pass\n        continue\n    final_labels = [\'PlaneNet\', \'[25]+GT depth\', \'[25]\', \'[9]+GT depth\', \'[9]\', \'[26]+GT depth\', \'[26]\']\n\n    orderingArray = [[2, 4, 6, 0], [1, 3, 5, 0]]\n\n    for groupIndex in xrange(2):\n        fig = plt.figure(groupIndex)\n        ax = plt.gca()\n\n        ordering = orderingArray[groupIndex]\n        for metricIndex in xrange(2):\n            plt.subplot(1, 2, metricIndex + 1)\n            #for index, y in enumerate(ys):\n            ys = ysArray[metricIndex]\n            for order in ordering:\n                plt.plot(x, ys[order], figure=fig, label=final_labels[order], color=colors[order], marker=markers[order], linewidth=sizes[order])\n                continue\n            plt.xlabel(xlabel)\n            plt.ylabel(ylabels[metricIndex] + \' %\')\n\n            ax.set_yticklabels(np.arange(0, 101, 20))\n            ax.spines[\'top\'].set_visible(False)\n            ax.spines[\'right\'].set_visible(False)\n            ax.get_xaxis().tick_bottom()\n            ax.get_yaxis().tick_left()\n            #ax.xaxis.set_label_coords(1.1, -0.025)\n            #plt.title(title)\n\n            plt.xlim((x[0], x[-1] + 0.01))\n            plt.ylim((0, 1))\n\n            continue\n\n        plt.legend(loc=\'upper center\', bbox_to_anchor=(0.5, -0.15), ncol=4, fancybox=True, shadow=True, handletextpad=0.1)\n\n        plt.tight_layout(w_pad=0.3)\n        plt.savefig(filenames[groupIndex])\n\n        continue\n    #plt.legend(loc=\'upper right\')\n    return\n\n\ndef plotCurvesSimple(x, ys, filename = \'test/test.png\', xlabel=\'\', ylabel=\'\', title=\'\', labels=[]):\n    import matplotlib.pyplot as plt\n    fig = plt.figure()\n    ax = plt.gca()\n\n    ordering = np.arange(len(labels)).tolist()\n    final_labels = labels\n\n    #for index, y in enumerate(ys):\n    for order in ordering:\n        plt.plot(x, ys[order], figure=fig, label=final_labels[order])\n        continue\n    plt.legend(loc=\'upper right\', ncol=2)\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel + \' %\')\n    ax.set_yticklabels(np.arange(0, 101, 20))\n    ax.spines[\'top\'].set_visible(False)\n    ax.spines[\'right\'].set_visible(False)\n    ax.get_xaxis().tick_bottom()\n    ax.get_yaxis().tick_left()\n    #ax.xaxis.set_label_coords(1.1, -0.025)\n    #plt.title(title)\n    plt.xlim((x[0], x[-1] + 0.01))\n    plt.ylim((0, 1))\n    plt.tight_layout(w_pad=0.3)\n    plt.savefig(filename)\n    return\n\ndef transformPlanes(planes, transformation):\n\n    centers = planes\n    planesD = np.maximum(np.linalg.norm(planes, axis=1, keepdims=True), 1e-4)\n    refPoints = centers - planes / planesD\n\n    centers = np.concatenate([centers, np.ones((planes.shape[0], 1))], axis=1)\n    refPoints = np.concatenate([refPoints, np.ones((planes.shape[0], 1))], axis=1)\n\n    newCenters = np.transpose(np.matmul(transformation, np.transpose(centers)))\n    newRefPoints = np.transpose(np.matmul(transformation, np.transpose(refPoints)))\n\n    newCenters = newCenters[:, :3] / newCenters[:, 3:4]\n    newRefPoints = newRefPoints[:, :3] / newRefPoints[:, 3:4]\n\n    planeNormals = newRefPoints - newCenters\n    planesD = -np.sum(newCenters * planeNormals, axis=1, keepdims=True)\n    newPlanes = -planeNormals * planesD\n    return newPlanes\n\n\ndef softmax(values):\n    exp = np.exp(values - values.max())\n    return exp / exp.sum(-1, keepdims=True)\n\ndef one_hot(values, depth):\n    maxInds = values.reshape(-1)\n    results = np.zeros([maxInds.shape[0], depth])\n    results[np.arange(maxInds.shape[0]), maxInds] = 1\n    results = results.reshape(list(values.shape) + [depth])\n    return results\n\ndef sigmoid(values):\n    return 1 / (1 + np.exp(-values))\n\ndef normalize(values):\n    return values / np.maximum(np.linalg.norm(values, axis=-1, keepdims=True), 1e-4)\n\n\n\ndef sortSegmentations(segmentations, planes, planesTarget):\n    diff = np.linalg.norm(np.expand_dims(planes, 1) - np.expand_dims(planesTarget, 0), axis=2)\n    planeMap = one_hot(np.argmin(diff, axis=-1), depth=diff.shape[-1])\n    #print(planeMap)\n    segmentationsTarget = np.matmul(segmentations, planeMap)\n    return segmentationsTarget, np.matmul(planes.transpose(), planeMap).transpose()\n\ndef refitPlanes(planes, segmentation, depth, info, numOutputPlanes=20, planeAreaThreshold=6*8):\n    camera = getCameraFromInfo(info)\n    width = depth.shape[1]\n    height = depth.shape[0]\n\n    #camera = getNYURGBDCamera()\n    #camera = getSUNCGCamera()\n\n    urange = (np.arange(width, dtype=np.float32) / width * camera[\'width\'] - camera[\'cx\']) / camera[\'fx\']\n    urange = urange.reshape(1, -1).repeat(height, 0)\n    vrange = (np.arange(height, dtype=np.float32) / height * camera[\'height\'] - camera[\'cy\']) / camera[\'fy\']\n    vrange = vrange.reshape(-1, 1).repeat(width, 1)\n    X = depth * urange\n    Y = depth\n    Z = -depth * vrange\n\n    XYZ = np.stack([X, Y, Z], axis=2)\n\n    validDepthMask = depth > 1e-4\n\n    newPlaneInfo = []\n    for planeIndex in xrange(numOutputPlanes):\n        mask = segmentation == planeIndex\n        points = XYZ[np.logical_and(cv2.erode(mask.astype(np.float32), np.ones((3, 3))) > 0.5, validDepthMask)]\n        if points.shape[0] >= 3:\n            try:\n                plane = fitPlane(points)\n                plane /= pow(np.linalg.norm(plane), 2)\n                newPlaneInfo.append((plane, mask, points.shape[0]))\n                #newPlaneInfo.append((planes[planeIndex], mask, points.shape[0]))\n            except:\n                pass\n            pass\n        continue\n\n    newPlaneInfo = sorted(newPlaneInfo, key=lambda x: -x[2])\n\n    newPlanes = []\n    newSegmentation = np.ones(segmentation.shape, dtype=np.uint8) * numOutputPlanes\n    for planeIndex, planeInfo in enumerate(newPlaneInfo):\n        newPlanes.append(planeInfo[0])\n        newSegmentation[planeInfo[1]] = planeIndex\n        continue\n\n    numPlanes = len(newPlaneInfo)\n    if numPlanes == 0:\n        return np.zeros((numOutputPlanes, 3)), newSegmentation, numPlanes\n\n    newPlanes = np.array(newPlanes)\n    if numPlanes < numOutputPlanes:\n        newPlanes = np.concatenate([newPlanes, np.zeros((numOutputPlanes - numPlanes, 3))], axis=0)\n        pass\n\n    return newPlanes, newSegmentation, numPlanes\n\n# def filterPlanesPred(planes, segmentations, depth, info, segmentationsTarget, numOutputPlanes=20, nonPlaneRatioThreshold=0.7, coveredPlaneRatioThreshold=0.5, planeDistanceThreshold=0.05, planeAngleThreshold=np.cos(np.deg2rad(20))):\n\n#     camera = getCameraFromInfo(info)\n#     width = depth.shape[1]\n#     height = depth.shape[0]\n\n#     #camera = getNYURGBDCamera()\n#     #camera = getSUNCGCamera()\n\n#     urange = (np.arange(width, dtype=np.float32) / width * camera[\'width\'] - camera[\'cx\']) / camera[\'fx\']\n#     urange = urange.reshape(1, -1).repeat(height, 0)\n#     vrange = (np.arange(height, dtype=np.float32) / height * camera[\'height\'] - camera[\'cy\']) / camera[\'fy\']\n#     vrange = vrange.reshape(-1, 1).repeat(width, 1)\n#     X = depth * urange\n#     Y = depth\n#     Z = -depth * vrange\n\n#     XYZ = np.stack([X, Y, Z], axis=2)\n\n#     validDepthMask = depth > 1e-4\n\n#     #numPlanes = planes.shape[0]\n#     validPlaneInfo = []\n#     emptyMaskTarget = segmentationsTarget[:, :, numOutputPlanes]\n#     emptyMask = segmentations[:, :, numOutputPlanes]\n#     for planeIndex in xrange(numOutputPlanes):\n#         mask = segmentations[:, :, planeIndex]\n#         if (emptyMaskTarget * mask).sum() < mask.sum() * nonPlaneRatioThreshold:\n#             points = XYZ[np.logical_and(cv2.erode(mask, np.ones((3, 3))) > 0.5, validDepthMask)]\n#             if points.shape[0] >= 3:\n#                 try:\n#                     plane = fitPlane(points)\n#                     plane /= pow(np.linalg.norm(plane), 2)\n#                     validPlaneInfo.append((plane, mask, points))\n#                 except:\n#                     emptyMask += mask\n#                 pass\n#             else:\n#                 emptyMask += mask\n#         else:\n#             emptyMask += mask\n#             pass\n#         continue\n\n#     #validPlaneInfo = sorted(validPlaneInfo, key=lambda x:-x[2])\n\n#     for planeIndex, planeInfo in enumerate(validPlaneInfo):\n#         cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(planeInfo[1]))\n#         print(planeIndex, planeInfo[0])\n#         continue\n\n#     emptyMask = (emptyMask > 0.5).astype(np.float32)\n#     for planeIndexTarget in xrange(numOutputPlanes):\n#         maskTarget = segmentationsTarget[:, :, planeIndexTarget]\n#         excludedMask = ((maskTarget + emptyMask) > 0.5).astype(np.float32)\n#         coveredPlanes = []\n#         for planeIndex, planeInfo in enumerate(validPlaneInfo):\n#             mask = planeInfo[1]\n#             area = mask.sum()\n#             if (maskTarget * mask).sum() / area > coveredPlaneRatioThreshold:\n#                 coveredPlanes.append((planeIndex, planeInfo[0], planeInfo[2]))\n#                 pass\n#             continue\n#         if len(coveredPlanes) <= 1:\n#             continue\n\n#         coveredPlanes = sorted(coveredPlanes, key=lambda x:-x[2].shape[0])\n\n\n#         majorPlane = coveredPlanes[0][1]\n#         majorPlaneD = np.linalg.norm(majorPlane)\n#         majorPlaneNormal = majorPlane / majorPlaneD\n#         mergedPlanes = [coveredPlanes[0][0], ]\n#         for planeInfo in coveredPlanes[1:]:\n#             #if np.linalg.norm(planeInfo[1] - majorPlane) < planeDistanceThreshold:\n#             distance = np.abs(np.sum(planeInfo[2] * majorPlaneNormal, axis=-1) - majorPlaneD)\n#             print(distance.mean())\n#             print(distance.max())\n#             planeNormal = planeInfo[1] / np.linalg.norm(planeInfo[1])\n#             print(np.sum(planeNormal * majorPlaneNormal), planeAngleThreshold)\n#             exit(1)\n#             if distance.mean() < planeDistanceThreshold and np.sum(planeNormal * majorPlaneNormal) > planeAngleThreshold:\n#                 mergedPlanes.append(planeInfo[0])\n#                 pass\n#             continue\n#         if mergedPlanes <= 1:\n#             continue\n#         newValidPlaneInfo = []\n#         mergedPlaneMask = np.zeros(emptyMask.shape)\n#         for planeIndex, planeInfo in enumerate(validPlaneInfo):\n#             if planeIndex not in mergedPlanes:\n#                 if (excludedMask * planeInfo[1]).sum() < planeInfo[1].sum() * nonPlaneRatioThreshold:\n#                     newValidPlaneInfo.append(planeInfo)\n#                     pass\n#             else:\n#                 mergedPlaneMask += planeInfo[1]\n#                 pass\n#             continue\n#         cv2.erode(mergedPlaneMask, np.ones((3, 3)))\n#         mergedPlaneMask = mergedPlaneMask > 0.5\n#         points = XYZ[np.logical_and(mergedPlaneMask, validDepthMask)]\n#         if points.shape[0] >= 3:\n#             try:\n#                 mergedPlane = fitPlane(points)\n#                 mergedPlane = mergedPlane / pow(np.linalg.norm(mergedPlane), 2)\n#                 newValidPlaneInfo.append((mergedPlane, mergedPlaneMask.astype(np.float32), points))\n#             except:\n#                 pass\n#             pass\n#         validPlaneInfo = newValidPlaneInfo\n#         continue\n\n#     validPlaneInfo = sorted(validPlaneInfo, key=lambda x: -x[1].sum())\n\n#     newPlanes = []\n#     newSegmentation = np.ones(emptyMask.shape) * numOutputPlanes\n#     for planeIndex, planeInfo in enumerate(validPlaneInfo):\n#         newPlanes.append(planeInfo[0])\n#         newSegmentation[planeInfo[1].astype(np.bool)] = planeIndex\n#         continue\n#     numPlanes = len(newPlanes)\n#     if numPlanes == 0:\n#         return np.zeros((numOutputPlanes, 3)), newSegmentation, numPlanes\n\n#     newPlanes = np.array(newPlanes)\n#     if numPlanes < numOutputPlanes:\n#         newPlanes = np.concatenate([newPlanes, np.zeros((numOutputPlanes - numPlanes, 3))], axis=0)\n#         pass\n\n#     return newPlanes, newSegmentation.astype(np.uint8), numPlanes\n\ndef filterPlanes(planes, segmentations, depth, info, numOutputPlanes=20, coveredPlaneRatioThreshold=0.5, planeDistanceThreshold=0.05, normalDotThreshold=np.cos(np.deg2rad(20)), planeFittingThreshold = 0.03):\n\n    camera = getCameraFromInfo(info)\n    width = depth.shape[1]\n    height = depth.shape[0]\n\n    #camera = getNYURGBDCamera()\n    #camera = getSUNCGCamera()\n\n    urange = (np.arange(width, dtype=np.float32) / width * camera[\'width\'] - camera[\'cx\']) / camera[\'fx\']\n    urange = urange.reshape(1, -1).repeat(height, 0)\n    vrange = (np.arange(height, dtype=np.float32) / height * camera[\'height\'] - camera[\'cy\']) / camera[\'fy\']\n    vrange = vrange.reshape(-1, 1).repeat(width, 1)\n    X = depth * urange\n    Y = depth\n    Z = -depth * vrange\n\n    XYZ = np.stack([X, Y, Z], axis=2)\n\n    validDepthMask = depth > 1e-4\n\n\n\n    #numPlanes = planes.shape[0]\n    validPlaneInfo = []\n    for planeIndex in xrange(numOutputPlanes):\n        mask = segmentations[:, :, planeIndex]\n        points = XYZ[np.logical_and(cv2.erode(mask, np.ones((3, 3)), 2) > 0.5, validDepthMask)]\n        if points.shape[0] >= 3:\n            try:\n                plane = fitPlane(points)\n                plane /= pow(np.linalg.norm(plane), 2)\n                #plane = planes[planeIndex]\n\n                #planeD = np.linalg.norm(plane)\n                #diff = np.abs(np.sum(points * (plane / planeD), axis=-1) - planeD).mean()\n                #validMask = np.abs(np.sum(points * (plane / planeD), axis=-1) - planeD) < planeDistanceThreshold\n\n                #diff = (np.abs((np.sum(points * plane, axis=-1) - 1) / np.linalg.norm(plane)) > 0.05).astype(np.float32).mean()\n\n                #print(planeIndex, diff, mask.sum())\n                #cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(mask))\n                #if diff < planeFittingThreshold:\n                validPlaneInfo.append((plane, mask, points))\n                #    pass\n            except:\n                pass\n            pass\n        continue\n\n    #validPlaneInfo = sorted(validPlaneInfo, key=lambda x:-x[2])\n\n    validPlaneInfo = sorted(validPlaneInfo, key=lambda x: -x[2].shape[0])\n\n    if False:\n        for planeIndex, planeInfo in enumerate(validPlaneInfo):\n            cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(planeInfo[1]))\n            print(planeIndex, planeInfo[0], planeInfo[3], planeInfo[1].sum())\n            continue\n        pass\n\n    newPlaneInfo = []\n    usedPlaneMask = np.zeros(len(validPlaneInfo), dtype=np.bool)\n    for majorPlaneIndex, majorPlaneInfo in enumerate(validPlaneInfo):\n        if usedPlaneMask[majorPlaneIndex]:\n            continue\n        usedPlaneMask[majorPlaneIndex] = True\n\n        majorPlane = majorPlaneInfo[0]\n        majorPlaneD = np.linalg.norm(majorPlane)\n        majorPlaneNormal = majorPlane / majorPlaneD\n\n        mergedPlaneMask = majorPlaneInfo[1].copy()\n        planeMerged = False\n        for planeIndex, planeInfo in enumerate(validPlaneInfo):\n            if planeIndex <= majorPlaneIndex or usedPlaneMask[planeIndex]:\n                continue\n\n            fittingDiff = np.abs(np.sum(planeInfo[2] * majorPlaneNormal, axis=-1) - majorPlaneD)\n            planeNormal = planeInfo[0] / np.linalg.norm(planeInfo[0])\n            normalDot = np.sum(planeNormal * majorPlaneNormal)\n\n            #print(majorPlaneIndex, planeIndex)\n            #print(majorPlane, planeInfo[0])\n            #print(fittingDiff.mean(), (fittingDiff < 0.05).astype(np.float32).mean(), normalDot, normalDotThreshold)\n\n            if fittingDiff.mean() < planeDistanceThreshold and normalDot > normalDotThreshold:\n                #print(\'merge\', majorPlaneIndex, planeIndex)\n                mergedPlaneMask += planeInfo[1]\n                usedPlaneMask[planeIndex] = True\n                planeMerged = True\n                pass\n            continue\n\n        if planeMerged:\n            mergedPlaneMask = (mergedPlaneMask > 0.5).astype(np.float32)\n            pass\n\n        newPlaneInfo.append((majorPlaneInfo[0], mergedPlaneMask))\n        continue\n\n    newPlaneInfo = sorted(newPlaneInfo, key=lambda x: -x[1].sum())\n\n    newPlanes = []\n    newSegmentation = np.ones((height, width), dtype=np.uint8) * numOutputPlanes\n    for planeIndex, planeInfo in enumerate(newPlaneInfo):\n        area = planeInfo[1].sum()\n        xs = planeInfo[1].max(0).nonzero()[0]\n        ys = planeInfo[1].max(1).nonzero()[0]\n        length = np.sqrt(pow(xs.max() - xs.min() + 1, 2) + pow(ys.max() - ys.min() + 1, 2))\n        if area < (width * height / 100.) or area / length < 10:\n            continue\n        newSegmentation[planeInfo[1].astype(np.bool)] = len(newPlanes)\n        newPlanes.append(planeInfo[0])\n        continue\n    numPlanes = len(newPlanes)\n    if numPlanes == 0:\n        return np.zeros((numOutputPlanes, 3)), newSegmentation, numPlanes\n\n    newPlanes = np.array(newPlanes)\n    if numPlanes < numOutputPlanes:\n        newPlanes = np.concatenate([newPlanes, np.zeros((numOutputPlanes - numPlanes, 3))], axis=0)\n        pass\n\n    return newPlanes, newSegmentation, numPlanes\n\n\ndef getSegmentationsTRWS(planes, image, depth, normal, semantics, info, useSemantics=False, numPlanes=20, numProposals = 3):\n    numOutputPlanes = planes.shape[0]\n    height = depth.shape[0]\n    width = depth.shape[1]\n\n\n    camera = getCameraFromInfo(info)\n    urange = (np.arange(width, dtype=np.float32) / (width) * (camera[\'width\']) - camera[\'cx\']) / camera[\'fx\']\n    urange = urange.reshape(1, -1).repeat(height, 0)\n    vrange = (np.arange(height, dtype=np.float32) / (height) * (camera[\'height\']) - camera[\'cy\']) / camera[\'fy\']\n    vrange = vrange.reshape(-1, 1).repeat(width, 1)\n\n    X = depth * urange\n    Y = depth\n    Z = -depth * vrange\n    points = np.stack([X, Y, Z], axis=2)\n\n    planes = planes[:numPlanes]\n    planesD = np.linalg.norm(planes, axis=1, keepdims=True)\n    planeNormals = planes / np.maximum(planesD, 1e-4)\n\n    distanceCostThreshold = 0.05\n    distanceCost = np.abs(np.tensordot(points, planeNormals, axes=([2, 1])) - np.reshape(planesD, [1, 1, -1])) / distanceCostThreshold\n    distanceCost = np.concatenate([distanceCost, np.ones((height, width, 1))], axis=2)\n    #cv2.imwrite(\'test/mask.png\', drawMaskImage(np.minimum(distanceCost[:, :, 2] /  5, 1)))\n    #distanceCost[:, :, numPlanes:numOutputPlanes] = 10000\n    normalCostThreshold = 1 - np.cos(np.deg2rad(30))\n    normalCost = (1 - np.tensordot(normal, planeNormals, axes=([2, 1]))) / normalCostThreshold\n    #normalCost[:, :, numPlanes:] = 10000\n    normalCost = np.concatenate([normalCost, np.ones((height, width, 1))], axis=2)\n\n\n    unaryCost = distanceCost\n\n    if useSemantics:\n        planeMasks = []\n        for planeIndex in xrange(numPlanes):\n            #print(np.bincount(semantics[segmentation == planeIndex]))\n            planeMaskOri = segmentation == planeIndex\n            semantic = np.bincount(semantics[planeMaskOri]).argmax()\n            #print(semantic)\n            planeMask = cv2.dilate((np.logical_and(np.logical_or(semantics == semantic, planeMaskOri), distanceCost[:, :, planeIndex])).astype(np.uint8), np.ones((3, 3), dtype=np.uint8)).astype(np.float32)\n            planeMasks.append(planeMask)\n            #cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', drawMaskImage(segmentation == planeIndex))\n            #cv2.imwrite(\'test/mask_2.png\', drawMaskImage(semantics == semantic))\n            continue\n        planeMasks = np.stack(planeMasks, 2)\n        unaryCost += (1 - planeMasks) * 10000\n        pass\n\n    unaryCost = np.concatenate([unaryCost, np.ones((height, width, 1))], axis=2)\n\n\n    proposals = np.argpartition(unaryCost, numProposals)[:, :, :numProposals]\n    unaries = -readProposalInfo(unaryCost, proposals).reshape((-1, numProposals))\n\n    # refined_segmentation = np.argmax(unaries, axis=1)\n    # refined_segmentation = refined_segmentation.reshape([height, width, 1])\n    # refined_segmentation = readProposalInfo(proposals, refined_segmentation)\n    # refined_segmentation = refined_segmentation.reshape([height, width])\n    # refined_segmentation[refined_segmentation == numPlanes] = numOutputPlanes\n\n\n    proposals = proposals.reshape((-1, numProposals))\n    #cv2.imwrite(\'test/segmentation.png\', drawSegmentationImage(unaries.reshape((height, width, -1)), blackIndex=numOutputPlanes))\n\n    nodes = np.arange(height * width).reshape((height, width))\n\n    image = image.astype(np.float32)\n    colors = image.reshape((-1, 3))\n    deltas = [(0, 1), (1, 0), (-1, 1), (1, 1)]\n    intensityDifferenceSum = 0.0\n    intensityDifferenceCount = 0\n    for delta in deltas:\n        deltaX = delta[0]\n        deltaY = delta[1]\n        partial_nodes = nodes[max(-deltaY, 0):min(height - deltaY, height), max(-deltaX, 0):min(width - deltaX, width)].reshape(-1)\n        intensityDifferenceSum += np.sum(pow(colors[partial_nodes] - colors[partial_nodes + (deltaY * width + deltaX)], 2))\n        intensityDifferenceCount += partial_nodes.shape[0]\n        continue\n    intensityDifference = intensityDifferenceSum / intensityDifferenceCount\n\n\n    edges = []\n    edges_features = []\n\n    for delta in deltas:\n        deltaX = delta[0]\n        deltaY = delta[1]\n        partial_nodes = nodes[max(-deltaY, 0):min(height - deltaY, height), max(-deltaX, 0):min(width - deltaX, width)].reshape(-1)\n        edges.append(np.stack([partial_nodes, partial_nodes + (deltaY * width + deltaX)], axis=1))\n\n        labelDiff = (np.expand_dims(proposals[partial_nodes], -1) != np.expand_dims(proposals[partial_nodes + (deltaY * width + deltaX)], 1)).astype(np.float32)\n        colorDiff = np.sum(pow(colors[partial_nodes] - colors[partial_nodes + (deltaY * width + deltaX)], 2), axis=1)\n        pairwise_cost = labelDiff * np.reshape(1 + 45 * np.exp(-colorDiff / intensityDifference), [-1, 1, 1])\n        #pairwise_cost = np.expand_dims(pairwise_matrix, 0) * np.ones(np.reshape(1 + 45 * np.exp(-colorDiff / np.maximum(intensityDifference[partial_nodes], 1e-4)), [-1, 1, 1]).shape)\n        edges_features.append(-pairwise_cost)\n        continue\n\n    edges = np.concatenate(edges, axis=0)\n    edges_features = np.concatenate(edges_features, axis=0)\n\n    refined_segmentation = inference_ogm(unaries * 10, edges_features, edges, return_energy=False, alg=\'trw\')\n    #print(pairwise_matrix)\n    #refined_segmentation = inference_ogm(unaries * 5, -pairwise_matrix, edges, return_energy=False, alg=\'alphaexp\')\n    refined_segmentation = refined_segmentation.reshape([height, width, 1])\n    refined_segmentation = readProposalInfo(proposals, refined_segmentation)\n    refined_segmentation = refined_segmentation.reshape([height, width])\n    refined_segmentation[refined_segmentation == numPlanes] = numOutputPlanes\n    return refined_segmentation\n\ndef getSegmentationsGraphCut(planes, image, depth, normal, semantics, info, parameters={}):\n\n    height = depth.shape[0]\n    width = depth.shape[1]\n\n    # planeMap = []\n    # planeMasks = []\n    # for planeIndex in xrange(numPlanes):\n    #     planeMask = segmentation == planeIndex\n    #     if planeMask.sum() < 6 * 8:\n    #         continue\n    #     planeMap.append(planeIndex)\n    #     semantic = np.bincount(semantics[planeMask]).argmax()\n    #     for _ in xrange(2):\n    #         planeMask = cv2.dilate(planeMask.astype(np.float32), np.ones((3, 3), dtype=np.float32))\n    #         continue\n    #     planeMask = np.logical_and(np.logical_or(semantics == semantic, semantics == 0), planeMask).astype(np.float32)\n    #     for _ in xrange(1):\n    #         planeMask = cv2.dilate(planeMask, np.ones((3, 3), dtype=np.float32))\n    #         continue\n    #     planeMasks.append(planeMask)\n    #     continue\n    # planeMap = one_hot(np.array(planeMap), depth=planes.shape[0])\n    #planes = np.matmul(planeMap, planes)\n    #planeMasks = np.stack(planeMasks, 2).reshape((-1, numPlanes))\n\n    numPlanes = planes.shape[0]\n\n    #if numPlanes < numOutputPlanes:\n    #planeMasks = np.concatenate([planeMasks, np.zeros((height, width, numOutputPlanes - numPlanes))], axis=2)\n    #pass\n\n    #print(info)\n    camera = getCameraFromInfo(info)\n    urange = (np.arange(width, dtype=np.float32) / (width) * (camera[\'width\']) - camera[\'cx\']) / camera[\'fx\']\n    urange = urange.reshape(1, -1).repeat(height, 0)\n    vrange = (np.arange(height, dtype=np.float32) / (height) * (camera[\'height\']) - camera[\'cy\']) / camera[\'fy\']\n    vrange = vrange.reshape(-1, 1).repeat(width, 1)\n\n    X = depth * urange\n    Y = depth\n    Z = -depth * vrange\n\n    points = np.stack([X, Y, Z], axis=2)\n    planes = planes[:numPlanes]\n    planesD = np.linalg.norm(planes, axis=1, keepdims=True)\n    planeNormals = planes / np.maximum(planesD, 1e-4)\n\n    if \'distanceCostThreshold\' in parameters:\n        distanceCostThreshold = parameters[\'distanceCostThreshold\']\n    else:\n        distanceCostThreshold = 0.05\n        pass\n\n    #distanceCost = 1 - np.exp(-np.abs(np.tensordot(points, planeNormals, axes=([2, 1])) - np.reshape(planesD, [1, 1, -1])) / distanceCostThreshold)\n    #distanceCost = np.concatenate([distanceCost, np.ones((height, width, 1)) * (1 - np.exp(-1))], axis=2)\n    distanceCost = np.abs(np.tensordot(points, planeNormals, axes=([2, 1])) - np.reshape(planesD, [1, 1, -1])) / distanceCostThreshold\n    distanceCost = np.concatenate([distanceCost, np.ones((height, width, 1))], axis=2)\n    #cv2.imwrite(\'test/mask.png\', drawMaskImage(np.minimum(distanceCost[:, :, 2] /  5, 1)))\n    #distanceCost[:, :, numPlanes:numOutputPlanes] = 10000\n\n    normalCostThreshold = 1 - np.cos(np.deg2rad(30))\n    normalCost = (1 - np.abs(np.tensordot(normal, planeNormals, axes=([2, 1])))) / normalCostThreshold\n    #normalCost[:, :, numPlanes:] = 10000\n    normalCost = np.concatenate([normalCost, np.ones((height, width, 1))], axis=2)\n\n\n    unaryCost = distanceCost + normalCost\n    unaryCost *= np.expand_dims((depth > 1e-4).astype(np.float32), -1)\n    unaries = -unaryCost.reshape((-1, numPlanes + 1))\n\n    cv2.imwrite(\'test/distance_cost.png\', drawSegmentationImage(-distanceCost.reshape((height, width, -1)), unaryCost.shape[-1] - 1))\n    cv2.imwrite(\'test/normal_cost.png\', drawSegmentationImage(-normalCost.reshape((height, width, -1)), unaryCost.shape[-1] - 1))\n    cv2.imwrite(\'test/unary_cost.png\', drawSegmentationImage(-unaryCost.reshape((height, width, -1)), blackIndex=unaryCost.shape[-1] - 1))\n\n\n    #unaries[:, :numPlanes] -= (1 - planeMasks) * 10000\n\n    #print(planes)\n    #print(distanceCost[150][200])\n    #print(unaryCost[150][200])\n    # print(np.argmax(-unaryCost[60][150]))\n\n    #cv2.imwrite(\'test/depth.png\', drawDepthImage(depth))\n    cv2.imwrite(\'test/segmentation.png\', drawSegmentationImage(unaries.reshape((height, width, -1)), blackIndex=numPlanes))\n    #cv2.imwrite(\'test/mask.png\', drawSegmentationImage(planeMasks.reshape((height, width, -1))))\n    #exit(1)\n\n\n    nodes = np.arange(height * width).reshape((height, width))\n\n    image = image.astype(np.float32)\n    colors = image.reshape((-1, 3))\n\n    deltas = [(0, 1), (1, 0), (-1, 1), (1, 1)]\n\n    intensityDifferenceSum = 0.0\n    intensityDifferenceCount = 0\n    for delta in deltas:\n        deltaX = delta[0]\n        deltaY = delta[1]\n        partial_nodes = nodes[max(-deltaY, 0):min(height - deltaY, height), max(-deltaX, 0):min(width - deltaX, width)].reshape(-1)\n        intensityDifferenceSum += np.sum(pow(colors[partial_nodes] - colors[partial_nodes + (deltaY * width + deltaX)], 2))\n        intensityDifferenceCount += partial_nodes.shape[0]\n        continue\n    intensityDifference = intensityDifferenceSum / intensityDifferenceCount\n\n\n    edges = []\n    edges_features = []\n    pairwise_matrix = 1 - np.diag(np.ones(numPlanes + 1))\n\n    for delta in deltas:\n        deltaX = delta[0]\n        deltaY = delta[1]\n        partial_nodes = nodes[max(-deltaY, 0):min(height - deltaY, height), max(-deltaX, 0):min(width - deltaX, width)].reshape(-1)\n        edges.append(np.stack([partial_nodes, partial_nodes + (deltaY * width + deltaX)], axis=1))\n\n        colorDiff = np.sum(pow(colors[partial_nodes] - colors[partial_nodes + (deltaY * width + deltaX)], 2), axis=1)\n\n        pairwise_cost = np.expand_dims(pairwise_matrix, 0) * np.reshape(1 + 45 * np.exp(-colorDiff / intensityDifference), [-1, 1, 1])\n        #pairwise_cost = np.expand_dims(pairwise_matrix, 0) * np.ones(np.reshape(1 + 45 * np.exp(-colorDiff / np.maximum(intensityDifference[partial_nodes], 1e-4)), [-1, 1, 1]).shape)\n        edges_features.append(pairwise_cost)\n        continue\n\n    edges = np.concatenate(edges, axis=0)\n    edges_features = np.concatenate(edges_features, axis=0)\n\n    if \'smoothnessWeight\' in parameters:\n        smoothnessWeight = parameters[\'smoothnessWeight\']\n    else:\n        smoothnessWeight = 0.02\n        pass\n\n    refined_segmentation = inference_ogm(unaries, -edges_features * smoothnessWeight, edges, return_energy=False, alg=\'alphaexp\')\n    #print(pairwise_matrix)\n    #refined_segmentation = inference_ogm(unaries * 5, -pairwise_matrix, edges, return_energy=False, alg=\'alphaexp\')\n    refined_segmentation = refined_segmentation.reshape([height, width])\n\n    if \'semantics\' in parameters and parameters[\'semantics\']:\n        for semanticIndex in xrange(semantics.max() + 1):\n            mask = semantics == semanticIndex\n            segmentInds = refined_segmentation[mask]\n            uniqueSegments, counts = np.unique(segmentInds, return_counts=True)\n            for index, count in enumerate(counts):\n                if count > segmentInds.shape[0] * 0.9:\n                    refined_segmentation[mask] = uniqueSegments[index]\n                    pass\n                continue\n            continue\n        pass\n\n    return refined_segmentation\n\ndef calcNormal(depth, info):\n\n    height = depth.shape[0]\n    width = depth.shape[1]\n\n    camera = getCameraFromInfo(info)\n    urange = (np.arange(width, dtype=np.float32) / (width) * (camera[\'width\']) - camera[\'cx\']) / camera[\'fx\']\n    urange = urange.reshape(1, -1).repeat(height, 0)\n    vrange = (np.arange(height, dtype=np.float32) / (height) * (camera[\'height\']) - camera[\'cy\']) / camera[\'fy\']\n    vrange = vrange.reshape(-1, 1).repeat(width, 1)\n\n    X = depth * urange\n    Y = depth\n    Z = -depth * vrange\n\n    points = np.stack([X, Y, Z], axis=2).reshape(-1, 3)\n\n    if width > 300:\n        grids = np.array([-9, -6, -3, -1, 0, 1, 3, 6, 9])\n    else:\n        grids = np.array([-5, -3, -1, 0, 1, 3, 5])\n\n    normals = []\n    for index in xrange(width * height):\n        us = index % width + grids\n        us = us[np.logical_and(us >= 0, us < width)]\n        vs = index / width + grids\n        vs = vs[np.logical_and(vs >= 0, vs < height)]\n        indices = (np.expand_dims(vs, -1) * width + np.expand_dims(us, 0)).reshape(-1)\n        planePoints = points[indices]\n        planePoints = planePoints[np.linalg.norm(planePoints, axis=-1) > 1e-4]\n\n        planePoints = planePoints[np.abs(planePoints[:, 1] - points[index][1]) < 0.05]\n        # if index == 53 * width + 183 or index == 58 * width + 183:\n        #     print(np.stack([indices % width, indices / width], axis=-1))\n        #     print(index)\n        #     print(planePoints)\n        #     print(planePoints.shape)\n        #     plane = fitPlane(planePoints)\n        #     print(plane)\n        #     print(plane / np.maximum(np.linalg.norm(plane), 1e-4))\n        #     pass\n\n        try:\n            plane = fitPlane(planePoints)\n            normals.append(-plane / np.maximum(np.linalg.norm(plane), 1e-4))\n        except:\n            if len(normals) > 0:\n                normals.append(normals[-1])\n            else:\n                normals.append([0, -1, 0])\n                pass\n            pass\n        continue\n    normal = np.array(normals).reshape((height, width, 3))\n    return normal\n\n\ndef readProposalInfo(info, proposals):\n    numProposals = proposals.shape[-1]\n    outputShape = list(info.shape)\n    outputShape[-1] = numProposals\n    info = info.reshape([-1, info.shape[-1]])\n    proposals = proposals.reshape([-1, proposals.shape[-1]])\n    proposalInfo = []\n\n    for proposal in xrange(numProposals):\n        proposalInfo.append(info[np.arange(info.shape[0]), proposals[:, proposal]])\n        continue\n    proposalInfo = np.stack(proposalInfo, axis=1).reshape(outputShape)\n    return proposalInfo\n\n\ndef fitPlanesManhattan(image, depth, normal, info, numOutputPlanes=20, imageIndex=1, parameters={}):\n    if \'meanshift\' in parameters and parameters[\'meanshift\'] > 0:\n        import sklearn.cluster\n        meanshift = sklearn.cluster.MeanShift(parameters[\'meanshift\'])\n        pass\n\n\n    height = depth.shape[0]\n    width = depth.shape[1]\n\n    camera = getCameraFromInfo(info)\n    urange = (np.arange(width, dtype=np.float32) / (width) * (camera[\'width\']) - camera[\'cx\']) / camera[\'fx\']\n    urange = urange.reshape(1, -1).repeat(height, 0)\n    vrange = (np.arange(height, dtype=np.float32) / (height) * (camera[\'height\']) - camera[\'cy\']) / camera[\'fy\']\n    vrange = vrange.reshape(-1, 1).repeat(width, 1)\n\n    X = depth * urange\n    Y = depth\n    Z = -depth * vrange\n\n\n    normals = normal.reshape((-1, 3))\n    normals = normals / np.maximum(np.linalg.norm(normals, axis=-1, keepdims=True), 1e-4)\n\n    validMask = np.logical_and(np.linalg.norm(normals, axis=-1) > 1e-4, depth.reshape(-1) > 1e-4)\n\n    valid_normals = normals[validMask]\n\n\n    points = np.stack([X, Y, Z], axis=2).reshape(-1, 3)\n    valid_points = points[validMask]\n\n    polarAngles = np.arange(16) * np.pi / 2 / 16\n    azimuthalAngles = np.arange(64) * np.pi * 2 / 64\n    polarAngles = np.expand_dims(polarAngles, -1)\n    azimuthalAngles = np.expand_dims(azimuthalAngles, 0)\n\n    normalBins = np.stack([np.sin(polarAngles) * np.cos(azimuthalAngles), np.tile(np.cos(polarAngles), [1, azimuthalAngles.shape[1]]), -np.sin(polarAngles) * np.sin(azimuthalAngles)], axis=2)\n    normalBins = np.reshape(normalBins, [-1, 3])\n    numBins = normalBins.shape[0]\n\n\n    normalDiff = np.tensordot(valid_normals, normalBins, axes=([1], [1]))\n    normalDiffSign = np.sign(normalDiff)\n    normalDiff = np.maximum(normalDiff, -normalDiff)\n    normalMask = one_hot(np.argmax(normalDiff, axis=-1), numBins)\n    bins = normalMask.sum(0)\n    np.expand_dims(valid_normals, 1) * np.expand_dims(normalMask, -1)\n\n    maxNormals = np.expand_dims(valid_normals, 1) * np.expand_dims(normalMask, -1)\n    maxNormals *= np.expand_dims(normalDiffSign, -1)\n    averageNormals = maxNormals.sum(0) / np.maximum(np.expand_dims(bins, -1), 1e-4)\n    averageNormals /= np.maximum(np.linalg.norm(averageNormals, axis=-1, keepdims=True), 1e-4)\n    #print(bins.nonzero())\n    dominantNormal_1 = averageNormals[np.argmax(bins)]\n\n    dotThreshold_1 = np.cos(np.deg2rad(100))\n    dotThreshold_2 = np.cos(np.deg2rad(80))\n\n    dot_1 = np.tensordot(normalBins, dominantNormal_1, axes=([1], [0]))\n    bins[np.logical_or(dot_1 < dotThreshold_1, dot_1 > dotThreshold_2)] = 0\n    dominantNormal_2 = averageNormals[np.argmax(bins)]\n    #print(normalBins[np.argmax(bins)])\n    #print(dominantNormal_2)\n    #exit(1)\n    dot_2 = np.tensordot(normalBins, dominantNormal_2, axes=([1], [0]))\n    bins[np.logical_or(dot_2 < dotThreshold_1, dot_2 > dotThreshold_2)] = 0\n\n    dominantNormal_3 = averageNormals[np.argmax(bins)]\n\n\n    dominantNormals = np.stack([dominantNormal_1, dominantNormal_2, dominantNormal_3], axis=0)\n\n    dominantNormalImage = np.abs(np.matmul(normal, dominantNormals.transpose()))\n    cv2.imwrite(\'test/dominant_normal.png\', drawMaskImage(dominantNormalImage))\n\n    planeHypothesisAreaThreshold = width * height * 0.01\n\n\n    planes = []\n\n    if \'offsetGap\' in parameters:\n        offsetGap = parameters[\'offsetGap\']\n    else:\n        offsetGap = 0.1\n        pass\n    for dominantNormal in dominantNormals:\n        offsets = np.tensordot(valid_points, dominantNormal, axes=([1], [0]))\n        #offsets = np.sort(offsets)\n\n        if \'meanshift\' in parameters and parameters[\'meanshift\'] > 0:\n            sampleInds = np.arange(offsets.shape[0])\n            np.random.shuffle(sampleInds)\n            meanshift.fit(np.expand_dims(offsets[sampleInds[:int(offsets.shape[0] * 0.02)]], -1))\n            for offset in meanshift.cluster_centers_:\n                planes.append(dominantNormal * offset)\n                continue\n\n        #clusters = meanshift.fit_predict(offsets)\n        #print(clusters.score_samples(offsets))\n        #print(offsets)\n        #print(np.argmax(offsets))\n        #print(clusters.score_samples(np.array([[offsets.max()]])))\n        #print(clusters.sample(10))\n        #exit(1)\n        # for clusterIndex in xrange(clusters.max()):\n        #     clusterMask = clusters == clusterIndex\n        #     print(clusterMask.sum())\n        #     if clusterMask.sum() < planeHypothesisAreaThreshold:\n        #         continue\n        #     planeD = offsets[clusterMask].mean()\n        #     planes.append(dominantNormal * planeD)\n        #     continue\n\n        offset = offsets.min()\n        maxOffset = offsets.max()\n        while offset < maxOffset:\n            planeMask = np.logical_and(offsets >= offset, offsets < offset + offsetGap)\n            segmentOffsets = offsets[np.logical_and(offsets >= offset, offsets < offset + offsetGap)]\n            if segmentOffsets.shape[0] < planeHypothesisAreaThreshold:\n                offset += offsetGap\n                continue\n            planeD = segmentOffsets.mean()\n            planes.append(dominantNormal * planeD)\n            offset = planeD + offsetGap\n            #print(planeD, segmentOffsets.shape[0])\n            #cv2.imwrite(\'test/mask_\' + str(len(planes) - 1) + \'.png\', drawMaskImage(planeMask.reshape((height, width))))\n            continue\n        continue\n\n    if len(planes) == 0:\n        return np.array([]), np.zeros(segmentation.shape).astype(np.int32)\n\n    planes = np.array(planes)\n    print(\'number of planes \', planes.shape[0])\n\n    #transformedDominantNormals = np.matmul(info[:16].reshape(4, 4), np.transpose([np.concatenate(dominantNormals, np.ones((3, 1))], axis=1)))\n    vanishingPoints = np.stack([dominantNormals[:, 0] / np.maximum(dominantNormals[:, 1], 1e-4) * info[0] + info[2], -dominantNormals[:, 2] / np.maximum(dominantNormals[:, 1], 1e-4) * info[5] + info[6]], axis=1)\n    vanishingPoints[:, 0] *= width / info[16]\n    vanishingPoints[:, 1] *= height / info[17]\n\n    #print(dominantNormals)\n    #print(vanishingPoints)\n    #us = np.tile(np.expand_dims(np.arange(width), 0), [height, 1])\n    #vs = np.tile(np.expand_dims(np.arange(height), -1), [1, width])\n    indices = np.arange(width * height, dtype=np.int32)\n    uv = np.stack([indices % width, indices / width], axis=1)\n    colors = image.reshape((-1, 3))\n    windowW = 9\n    windowH = 3\n    dominantLineMaps = []\n    for vanishingPointIndex, vanishingPoint in enumerate(vanishingPoints):\n        horizontalDirection = uv - np.expand_dims(vanishingPoint, 0)\n        horizontalDirection = horizontalDirection / np.maximum(np.linalg.norm(horizontalDirection, axis=1, keepdims=True), 1e-4)\n        verticalDirection = np.stack([horizontalDirection[:, 1], -horizontalDirection[:, 0]], axis=1)\n\n        colorDiffs = []\n        for directionIndex, direction in enumerate([horizontalDirection, verticalDirection]):\n            neighbors = uv + direction\n            neighborsX = neighbors[:, 0]\n            neighborsY = neighbors[:, 1]\n            neighborsMinX = np.maximum(np.minimum(np.floor(neighborsX).astype(np.int32), width - 1), 0)\n            neighborsMaxX = np.maximum(np.minimum(np.ceil(neighborsX).astype(np.int32), width - 1), 0)\n            neighborsMinY = np.maximum(np.minimum(np.floor(neighborsY).astype(np.int32), height - 1), 0)\n            neighborsMaxY = np.maximum(np.minimum(np.ceil(neighborsY).astype(np.int32), height - 1), 0)\n            indices_1 = neighborsMinY * width + neighborsMinX\n            indices_2 = neighborsMaxY * width + neighborsMinX\n            indices_3 = neighborsMinY * width + neighborsMaxX\n            indices_4 = neighborsMaxY * width + neighborsMaxX\n            areas_1 = (neighborsMaxX - neighborsX) * (neighborsMaxY - neighborsY)\n            areas_2 = (neighborsMaxX - neighborsX) * (neighborsY - neighborsMinY)\n            areas_3 = (neighborsX - neighborsMinX) * (neighborsMaxY - neighborsY)\n            areas_4 = (neighborsX - neighborsMinX) * (neighborsY - neighborsMinY)\n\n            neighborsColor = colors[indices_1] * np.expand_dims(areas_1, -1) + colors[indices_2] * np.expand_dims(areas_2, -1) + colors[indices_3] * np.expand_dims(areas_3, -1) + colors[indices_4] * np.expand_dims(areas_4, -1)\n            colorDiff = np.linalg.norm(neighborsColor - colors, axis=-1)\n\n            #cv2.imwrite(\'test/color_diff_\' + str(vanishingPointIndex) + \'_\' + str(directionIndex) + \'.png\', drawMaskImage(colorDiff.reshape((height, width)) / 100))\n            colorDiffs.append(colorDiff)\n            continue\n        colorDiffs = np.stack(colorDiffs, 1)\n\n        deltaUs, deltaVs = np.meshgrid(np.arange(windowW) - (windowW - 1) / 2, np.arange(windowH) - (windowH - 1) / 2)\n        deltas = deltaUs.reshape((1, -1, 1)) * np.expand_dims(horizontalDirection, axis=1) + deltaVs.reshape((1, -1, 1)) * np.expand_dims(verticalDirection, axis=1)\n\n        windowIndices = np.expand_dims(uv, 1) - deltas\n        windowIndices = (np.minimum(np.maximum(np.round(windowIndices[:, :, 1]), 0), height - 1) * width + np.minimum(np.maximum(np.round(windowIndices[:, :, 0]), 0), width - 1)).astype(np.int32)\n\n        dominantLineMap = []\n\n        # index = 361 * width + 146\n        # mask = np.zeros((height * width))\n        # mask[windowIndices[index]] = 1\n        # cv2.imwrite(\'test/mask.png\', drawMaskImage(mask.reshape((height, width))))\n        # exit(1)\n        for pixels in windowIndices:\n            gradientSums = colorDiffs[pixels].sum(0)\n            dominantLineMap.append(gradientSums[1] / max(gradientSums[0], 1e-4))\n            continue\n        dominantLineMaps.append(np.array(dominantLineMap).reshape((height, width)))\n        # dominantLines = []\n        # for pixel in uv:\n        #     sums = colorDiffs[:, max(pixel[1] - windowSize, 0):min(pixel[1] + windowSize + 1, height - 1), max(pixel[0] - windowSize, 0):min(pixel[0] + windowSize + 1, width - 1)].sum(1).sum(1)\n        #     dominantLines.append(sums[1] / np.maximum(sums[0], 1e-4))\n        #     continue\n        # dominantLines = np.array(dominantLines).reshape((height, width))\n        # smoothnessWeightMask = np.logical_or(smoothnessWeightMask, dominantLines > 5)\n\n        #cv2.imwrite(\'test/dominant_lines_\' + str(vanishingPointIndex) + \'.png\', drawMaskImage(dominantLines / 5))\n        continue\n    dominantLineMaps = np.stack(dominantLineMaps, axis=2)\n    #cv2.imwrite(\'test/dominant_lines.png\', drawMaskImage(dominantLineMaps / 5))\n    if \'dominantLineThreshold\' in parameters:\n        dominantLineThreshold = parameters[\'dominantLineThreshold\']\n    else:\n        dominantLineThreshold = 3\n        pass\n\n    if imageIndex >= 0:\n        cv2.imwrite(\'test/\' + str(imageIndex) + \'_dominant_lines.png\', drawMaskImage(dominantLineMaps / dominantLineThreshold))\n    else:\n        cv2.imwrite(\'test/dominant_lines.png\', drawMaskImage(dominantLineMaps / dominantLineThreshold))\n        pass\n\n    smoothnessWeightMask = dominantLineMaps.max(2) > dominantLineThreshold\n    cv2.imwrite(\'test/dominant_lines_mask.png\', drawMaskImage(smoothnessWeightMask))\n\n    planesD = np.linalg.norm(planes, axis=1, keepdims=True)\n    planeNormals = planes / np.maximum(planesD, 1e-4)\n\n\n    if \'distanceCostThreshold\' in parameters:\n        distanceCostThreshold = parameters[\'distanceCostThreshold\']\n    else:\n        distanceCostThreshold = 0.05\n        pass\n\n    distanceCost = np.abs(np.tensordot(points, planeNormals, axes=([1, 1])) - np.reshape(planesD, [1, -1])) / distanceCostThreshold\n    #distanceCost = np.concatenate([distanceCost, np.ones((height * width, 1))], axis=1)\n\n    normalCost = 0\n    normalCostThreshold = 1 - np.cos(np.deg2rad(30))\n    normalCost = (1 - np.abs(np.tensordot(normals, planeNormals, axes=([1, 1])))) / normalCostThreshold\n\n    unaryCost = distanceCost + normalCost\n    unaryCost *= np.expand_dims(validMask.astype(np.float32), -1)\n    unaries = unaryCost.reshape((width * height, -1))\n\n    cv2.imwrite(\'test/distance_cost.png\', drawSegmentationImage(-distanceCost.reshape((height, width, -1)), unaryCost.shape[-1] - 1))\n    cv2.imwrite(\'test/normal_cost.png\', drawSegmentationImage(-normalCost.reshape((height, width, -1)), unaryCost.shape[-1] - 1))\n    cv2.imwrite(\'test/unary_cost.png\', drawSegmentationImage(-unaryCost.reshape((height, width, -1)), blackIndex=unaryCost.shape[-1] - 1))\n\n    cv2.imwrite(\'test/segmentation.png\', drawSegmentationImage(-unaries.reshape((height, width, -1)), blackIndex=unaries.shape[-1]))\n\n    #cv2.imwrite(\'test/mask.png\', drawSegmentationImage(planeMasks.reshape((height, width, -1))))\n    #exit(1)\n\n    if \'numProposals\' in parameters:\n        numProposals = parameters[\'numProposals\']\n    else:\n        numProposals = 3\n        pass\n    numProposals = min(numProposals, unaries.shape[-1] - 1)\n    proposals = np.argpartition(unaries, numProposals)[:, :numProposals]\n    proposals[np.logical_not(validMask)] = 0\n\n    unaries = -readProposalInfo(unaries, proposals).reshape((-1, numProposals))\n\n    nodes = np.arange(height * width).reshape((height, width))\n\n    #deltas = [(0, 1), (1, 0), (-1, 1), (1, 1)]\n    deltas = [(0, 1), (1, 0)]\n\n    edges = []\n    edges_features = []\n    smoothnessWeights = 1 - 0.99 * smoothnessWeightMask.astype(np.float32)\n\n    #edges_features = np.concatenate(edges_features, axis=0)\n    #print(proposals.shape)\n    #print(unaries.shape)\n    #print(width * height)\n    for delta in deltas:\n        deltaX = delta[0]\n        deltaY = delta[1]\n        partial_nodes = nodes[max(-deltaY, 0):min(height - deltaY, height), max(-deltaX, 0):min(width - deltaX, width)].reshape(-1)\n        edges.append(np.stack([partial_nodes, partial_nodes + (deltaY * width + deltaX)], axis=1))\n\n        labelDiff = (np.expand_dims(proposals[partial_nodes], -1) != np.expand_dims(proposals[partial_nodes + (deltaY * width + deltaX)], 1)).astype(np.float32)\n        #labelDiff = labelDiff.transpose([0, 2, 1])\n        #print(labelDiff.shape)\n        edges_features.append(labelDiff * smoothnessWeights.reshape((width * height, -1))[partial_nodes].reshape(-1, 1, 1))\n        continue\n\n    #exit(1)\n\n    edges = np.concatenate(edges, axis=0)\n    edges_features = np.concatenate(edges_features, axis=0)\n\n\n    # y = 71\n    # x = 145\n    # print(proposals[y * width + x])\n    # print(unaries[y * width + x] * 10000)\n    # print(proposals[(y + 1) * width + x])\n    # print(unaries[(y + 1) * width + x] * 10000)\n    # print(edges_features[y * width + x])\n\n    if \'smoothnessWeight\' in parameters:\n        smoothnessWeight = parameters[\'smoothnessWeight\']\n    else:\n        smoothnessWeight = 40\n        pass\n\n    refined_segmentation = inference_ogm(unaries, -edges_features * smoothnessWeight, edges, return_energy=False, alg=\'trw\')\n\n    refined_segmentation = refined_segmentation.reshape([height, width, 1])\n    refined_segmentation = readProposalInfo(proposals, refined_segmentation)\n    #print(pairwise_matrix)\n    #refined_segmentation = inference_ogm(unaries * 5, -pairwise_matrix, edges, return_energy=False, alg=\'alphaexp\')\n    planeSegmentation = refined_segmentation.reshape([height, width])\n\n    planeSegmentation[np.logical_not(validMask.reshape((height, width)))] = planes.shape[0]\n\n    cv2.imwrite(\'test/segmentation_refined.png\', drawSegmentationImage(planeSegmentation))\n    #exit(1)\n\n    # if planes.shape[0] > numOutputPlanes:\n    #     planeInfo = []\n    #     for planeIndex in xrange(planes.shape[0]):\n    #         mask = planeSegmentation == planeIndex\n    #         planeInfo.append((planes[planeIndex], mask))\n    #         continue\n    #     planeInfo = sorted(planeInfo, key=lambda x: -x[1].sum())\n    #     newPlanes = []\n    #     newPlaneSegmentation = np.full(planeSegmentation.shape, numOutputPlanes)\n    #     for planeIndex in xrange(numOutputPlanes):\n    #         newPlanes.append(planeInfo[planeIndex][0])\n    #         newPlaneSegmentation[planeInfo[planeIndex][1]] = planeIndex\n    #         continue\n    #     planeSegmentation = newPlaneSegmentation\n    #     planes = np.array(newPlanes)\n    # else:\n    #     planeSegmentation[planeSegmentation == planes.shape[0]] = numOutputPlanes\n    #     pass\n\n    # if planes.shape[0] < numOutputPlanes:\n    #     planes = np.concatenate([planes, np.zeros((numOutputPlanes - planes.shape[0], 3))], axis=0)\n    #     pass\n\n\n    # planeDepths = calcPlaneDepths(planes, width, height, info)\n\n    # allDepths = np.concatenate([planeDepths, np.expand_dims(depth, -1)], axis=2)\n    # depthPred = allDepths.reshape([height * width, planes.shape[0] + 1])[np.arange(width * height), planeSegmentation.astype(np.int32).reshape(-1)].reshape(height, width)\n\n\n    # planeNormals = calcPlaneNormals(planes, width, height)\n    # allNormals = np.concatenate([planeNormals, np.expand_dims(normal, 2)], axis=2)\n    # normalPred = allNormals.reshape(-1, planes.shape[0] + 1, 3)[np.arange(width * height), planeSegmentation.reshape(-1)].reshape((height, width, 3))\n\n    return planes, planeSegmentation\n\n\ndef calcVanishingPoint(lines):\n    points = lines[:, :2]\n    normals = lines[:, 2:4] - lines[:, :2]\n    normals /= np.maximum(np.linalg.norm(normals, axis=-1, keepdims=True), 1e-4)\n    normals = np.stack([normals[:, 1], -normals[:, 0]], axis=1)\n    normalPointDot = (normals * points).sum(1)\n\n    if lines.shape[0] == 2:\n        VP = np.linalg.solve(normals, normalPointDot)\n    else:\n        VP = np.linalg.lstsq(normals, normalPointDot)[0]\n        pass\n\n    # print(lines)\n    # print(points)\n    # print(normals)\n    # print(VP)\n    # exit(1)\n    return VP\n\ndef calcVanishingPoints(allLines, numVPs):\n    distanceThreshold = np.sin(np.deg2rad(5))\n    lines = allLines.copy()\n    VPs = []\n    VPLines = []\n    for VPIndex in xrange(numVPs):\n        points = lines[:, :2]\n        lengths = np.linalg.norm(lines[:, 2:4] - lines[:, :2], axis=-1)\n        normals = lines[:, 2:4] - lines[:, :2]\n        normals /= np.maximum(np.linalg.norm(normals, axis=-1, keepdims=True), 1e-4)\n        normals = np.stack([normals[:, 1], -normals[:, 0]], axis=1)\n        maxNumInliers = 0\n        bestVP = np.zeros(2)\n        #for _ in xrange(int(np.sqrt(lines.shape[0]))):\n        for _ in xrange(min(pow(lines.shape[0], 2), 100)):\n            sampledInds = np.random.choice(lines.shape[0], 2)\n            if sampledInds[0] == sampledInds[1]:\n                continue\n            sampledLines = lines[sampledInds]\n            try:\n                VP = calcVanishingPoint(sampledLines)\n            except:\n                continue\n\n            inliers = np.abs(((np.expand_dims(VP, 0) - points) * normals).sum(-1)) / np.linalg.norm(np.expand_dims(VP, 0) - points, axis=-1) < distanceThreshold\n            # print(sampledLines)\n            # print(VP)\n            # print(normals[inliers])\n            # exit(1)\n\n            #numInliers = inliers.sum()\n            numInliers = lengths[inliers].sum()\n            if numInliers > maxNumInliers:\n                maxNumInliers = numInliers\n                bestVP = VP\n                bestVPInliers = inliers\n                pass\n            continue\n        if maxNumInliers > 0:\n            inlierLines = lines[bestVPInliers]\n            VP = calcVanishingPoint(inlierLines)\n            VPs.append(VP)\n            #print(bestVP)\n            #print(inlierLines)\n            #print(VP)\n            #exit(1)\n            VPLines.append(inlierLines)\n            lines = lines[np.logical_not(bestVPInliers)]\n            pass\n        continue\n    VPs = np.stack(VPs, axis=0)\n    return VPs, VPLines, lines\n\ndef fitPlanesPiecewise(image, depth, normal, info, numOutputPlanes=20, imageIndex=1, parameters={}):\n    if \'meanshift\' in parameters and parameters[\'meanshift\'] > 0:\n        import sklearn.cluster\n        meanshift = sklearn.cluster.MeanShift(parameters[\'meanshift\'])\n        pass\n\n    #import sklearn.neighbors\n    #meanshift = sklearn.neighbors.KernelDensity(0.05)\n    from pylsd import lsd\n\n    height = depth.shape[0]\n    width = depth.shape[1]\n\n    camera = getCameraFromInfo(info)\n    urange = (np.arange(width, dtype=np.float32) / (width) * (camera[\'width\']) - camera[\'cx\']) / camera[\'fx\']\n    urange = urange.reshape(1, -1).repeat(height, 0)\n    vrange = (np.arange(height, dtype=np.float32) / (height) * (camera[\'height\']) - camera[\'cy\']) / camera[\'fy\']\n    vrange = vrange.reshape(-1, 1).repeat(width, 1)\n\n    X = depth * urange\n    Y = depth\n    Z = -depth * vrange\n\n\n    normals = normal.reshape((-1, 3))\n    normals = normals / np.maximum(np.linalg.norm(normals, axis=-1, keepdims=True), 1e-4)\n    validMask = np.logical_and(np.linalg.norm(normals, axis=-1) > 1e-4, depth.reshape(-1) > 1e-4)\n\n    points = np.stack([X, Y, Z], axis=2).reshape(-1, 3)\n    valid_points = points[validMask]\n\n    lines = lsd(image.mean(2))\n\n    lineImage = image.copy()\n    for line in lines:\n        cv2.line(lineImage, (int(line[0]), int(line[1])), (int(line[2]), int(line[3])), (0, 0, 255), int(np.ceil(line[4] / 2)))\n        continue\n    cv2.imwrite(\'test/lines.png\', lineImage)\n\n    numVPs = 3\n    VPs, VPLines, remainingLines = calcVanishingPoints(lines, numVPs=numVPs)\n\n    lineImage = image.copy()\n    for VPIndex, lines in enumerate(VPLines):\n        for line in lines:\n            cv2.line(lineImage, (int(line[0]), int(line[1])), (int(line[2]), int(line[3])), ((VPIndex == 0) * 255, (VPIndex == 1) * 255, (VPIndex == 2) * 255), int(np.ceil(line[4] / 2)))\n            continue\n        continue\n    cv2.imwrite(\'test/lines_vp.png\', lineImage)\n    #exit(1)\n\n    dominantNormals = np.stack([(VPs[:, 0] * info[16] / width - info[2]) / info[0], np.ones(numVPs), -(VPs[:, 1] * info[17] / height - info[6]) / info[5]], axis=1)\n    dominantNormals /= np.maximum(np.linalg.norm(dominantNormals, axis=1, keepdims=True), 1e-4)\n\n    dotThreshold = np.cos(np.deg2rad(20))\n    for normalIndex, crossNormals in enumerate([[1, 2], [2, 0], [0, 1]]):\n        normal = np.cross(dominantNormals[crossNormals[0]], dominantNormals[crossNormals[1]])\n        normal = normalize(normal)\n        if np.dot(normal, dominantNormals[normalIndex]) < dotThreshold:\n            dominantNormals = np.concatenate([dominantNormals, np.expand_dims(normal, 0)], axis=0)\n            pass\n        continue\n\n    print(VPs)\n    print(dominantNormals)\n\n    dominantNormalImage = np.abs(np.matmul(normal, dominantNormals.transpose()))\n    cv2.imwrite(\'test/dominant_normal.png\', drawMaskImage(dominantNormalImage))\n    #exit(1)\n\n    planeHypothesisAreaThreshold = width * height * 0.01\n\n    planes = []\n    vpPlaneIndices = []\n    if \'offsetGap\' in parameters:\n        offsetGap = parameters[\'offsetGap\']\n    else:\n        offsetGap = 0.1\n        pass\n    planeIndexOffset = 0\n\n    for dominantNormal in dominantNormals:\n        if np.linalg.norm(dominantNormal) < 1e-4:\n            continue\n        offsets = np.tensordot(valid_points, dominantNormal, axes=([1], [0]))\n\n        if \'meanshift\' in parameters and parameters[\'meanshift\'] > 0:\n            sampleInds = np.arange(offsets.shape[0])\n            np.random.shuffle(sampleInds)\n            meanshift.fit(np.expand_dims(offsets[sampleInds[:int(offsets.shape[0] * 0.02)]], -1))\n            for offset in meanshift.cluster_centers_:\n                planes.append(dominantNormal * offset)\n                continue\n        else:\n            offset = offsets.min()\n            maxOffset = offsets.max()\n            while offset < maxOffset:\n                planeMask = np.logical_and(offsets >= offset, offsets < offset + offsetGap)\n                segmentOffsets = offsets[np.logical_and(offsets >= offset, offsets < offset + offsetGap)]\n                if segmentOffsets.shape[0] < planeHypothesisAreaThreshold:\n                    offset += offsetGap\n                    continue\n                planeD = segmentOffsets.mean()\n                planes.append(dominantNormal * planeD)\n                offset = planeD + offsetGap\n\n                #print(planeD, segmentOffsets.shape[0])\n                #cv2.imwrite(\'test/mask_\' + str(len(planes) - 1) + \'.png\', drawMaskImage(planeMask.reshape((height, width))))\n                continue\n            pass\n\n\n        vpPlaneIndices.append(np.arange(planeIndexOffset, len(planes)))\n        planeIndexOffset = len(planes)\n        continue\n\n    if len(planes) == 0:\n        return np.array([]), np.zeros(segmentation.shape).astype(np.int32)\n    planes = np.array(planes)\n\n\n\n    planesD = np.linalg.norm(planes, axis=1, keepdims=True)\n    planeNormals = planes / np.maximum(planesD, 1e-4)\n\n    if \'distanceCostThreshold\' in parameters:\n        distanceCostThreshold = parameters[\'distanceCostThreshold\']\n    else:\n        distanceCostThreshold = 0.05\n        pass\n\n    # print(planes)\n    # print(np.abs(np.tensordot(points, planeNormals, axes=([1, 1])) - np.reshape(planesD, [1, -1])).max())\n    # print(np.abs(np.tensordot(points, planeNormals, axes=([1, 1])) - np.reshape(planesD, [1, -1])).min())\n    # print(distanceCostThreshold)\n\n    distanceCost = np.abs(np.tensordot(points, planeNormals, axes=([1, 1])) - np.reshape(planesD, [1, -1])) / distanceCostThreshold\n    #distanceCost = np.concatenate([distanceCost, np.ones((height * width, 1))], axis=1)\n\n\n    #valid_normals = normals[validMask]\n    normalCostThreshold = 1 - np.cos(np.deg2rad(30))\n    normalCost = (1 - np.abs(np.tensordot(normals, planeNormals, axes=([1, 1])))) / normalCostThreshold\n\n    if \'normalWeight\' in parameters:\n        normalWeight = parameters[\'normalWeight\']\n    else:\n        normalWeight = 1\n        pass\n\n    unaryCost = distanceCost + normalCost * normalWeight\n    unaryCost *= np.expand_dims(validMask.astype(np.float32), -1)\n    unaries = unaryCost.reshape((width * height, -1))\n\n\n    print(\'number of planes \', planes.shape[0])\n    cv2.imwrite(\'test/distance_cost.png\', drawSegmentationImage(-distanceCost.reshape((height, width, -1)), unaryCost.shape[-1] - 1))\n\n    cv2.imwrite(\'test/normal_cost.png\', drawSegmentationImage(-normalCost.reshape((height, width, -1)), unaryCost.shape[-1] - 1))\n\n    cv2.imwrite(\'test/unary_cost.png\', drawSegmentationImage(-unaryCost.reshape((height, width, -1)), blackIndex=unaryCost.shape[-1] - 1))\n\n    cv2.imwrite(\'test/segmentation.png\', drawSegmentationImage(-unaries.reshape((height, width, -1)), blackIndex=unaries.shape[-1]))\n\n    #cv2.imwrite(\'test/mask.png\', drawSegmentationImage(planeMasks.reshape((height, width, -1))))\n    #exit(1)\n\n\n    if \'numProposals\' in parameters:\n        numProposals = parameters[\'numProposals\']\n    else:\n        numProposals = 3\n        pass\n\n    numProposals = min(numProposals, unaries.shape[-1] - 1)\n\n    proposals = np.argpartition(unaries, numProposals)[:, :numProposals]\n    unaries = -readProposalInfo(unaries, proposals).reshape((-1, numProposals))\n\n    nodes = np.arange(height * width).reshape((height, width))\n\n    #deltas = [(0, 1), (1, 0), (-1, 1), (1, 1)]\n    deltas = [(0, 1), (1, 0)]\n\n    edges = []\n    edges_features = []\n\n\n    #edges_features = np.concatenate(edges_features, axis=0)\n    for delta in deltas:\n        deltaX = delta[0]\n        deltaY = delta[1]\n        partial_nodes = nodes[max(-deltaY, 0):min(height - deltaY, height), max(-deltaX, 0):min(width - deltaX, width)].reshape(-1)\n        edges.append(np.stack([partial_nodes, partial_nodes + (deltaY * width + deltaX)], axis=1))\n\n        labelDiff = (np.expand_dims(proposals[partial_nodes], -1) != np.expand_dims(proposals[partial_nodes + (deltaY * width + deltaX)], 1)).astype(np.float32)\n\n\n        edges_features.append(labelDiff)\n        continue\n\n    edges = np.concatenate(edges, axis=0)\n    edges_features = np.concatenate(edges_features, axis=0)\n\n\n    if \'edgeWeights\' in parameters:\n        edgeWeights = parameters[\'edgeWeights\']\n    else:\n        edgeWeights = [0.5, 0.6, 0.6]\n        pass\n\n    lineSets = np.zeros((height * width, 3))\n    creaseLines = np.expand_dims(np.stack([planeNormals[:, 0] / info[0], planeNormals[:, 1], -planeNormals[:, 2] / info[5]], axis=1), 1) * planesD.reshape((1, -1, 1))\n    creaseLines = creaseLines - np.transpose(creaseLines, [1, 0, 2])\n    for planeIndex_1 in xrange(planes.shape[0]):\n        for planeIndex_2 in xrange(planeIndex_1 + 1, planes.shape[0]):\n            creaseLine = creaseLines[planeIndex_1, planeIndex_2]\n            if abs(creaseLine[0]) > abs(creaseLine[2]):\n                vs = np.arange(height)\n                us = -(creaseLine[1] + (vs - info[6]) * creaseLine[2]) / creaseLine[0] + info[2]\n                minUs = np.floor(us).astype(np.int32)\n                maxUs = minUs + 1\n                validIndicesMask = np.logical_and(minUs >= 0, maxUs < width)\n                if validIndicesMask.sum() == 0:\n                    continue\n                vs = vs[validIndicesMask]\n                minUs = minUs[validIndicesMask]\n                maxUs = maxUs[validIndicesMask]\n                edgeIndices = (height - 1) * width + (vs * (width - 1) + minUs)\n                for index, edgeIndex in enumerate(edgeIndices):\n                    pixel_1 = vs[index] * width + minUs[index]\n                    pixel_2 = vs[index] * width + maxUs[index]\n                    proposals_1 = proposals[pixel_1]\n                    proposals_2 = proposals[pixel_2]\n                    if planeIndex_1 in proposals_1 and planeIndex_2 in proposals_2:\n                        proposalIndex_1 = np.where(proposals_1 == planeIndex_1)[0][0]\n                        proposalIndex_2 = np.where(proposals_2 == planeIndex_2)[0][0]\n                        edges_features[edgeIndex, proposalIndex_1, proposalIndex_2] *= edgeWeights[0]\n                        pass\n                    if planeIndex_2 in proposals_1 and planeIndex_1 in proposals_2:\n                        proposalIndex_1 = np.where(proposals_1 == planeIndex_2)[0][0]\n                        proposalIndex_2 = np.where(proposals_2 == planeIndex_1)[0][0]\n                        edges_features[edgeIndex, proposalIndex_1, proposalIndex_2] *= edgeWeights[0]\n                        pass\n                    continue\n\n                lineSets[vs * width + minUs, 0] = 1\n                lineSets[vs * width + maxUs, 0] = 1\n            else:\n                us = np.arange(width)\n                vs = -(creaseLine[1] + (us - info[2]) * creaseLine[0]) / creaseLine[2] + info[6]\n                minVs = np.floor(vs).astype(np.int32)\n                maxVs = minVs + 1\n                validIndicesMask = np.logical_and(minVs >= 0, maxVs < height)\n                if validIndicesMask.sum() == 0:\n                    continue\n                us = us[validIndicesMask]\n                minVs = minVs[validIndicesMask]\n                maxVs = maxVs[validIndicesMask]\n                edgeIndices = (minVs * width + us)\n                for index, edgeIndex in enumerate(edgeIndices):\n                    pixel_1 = minVs[index] * width + us[index]\n                    pixel_2 = maxVs[index] * width + us[index]\n                    proposals_1 = proposals[pixel_1]\n                    proposals_2 = proposals[pixel_2]\n                    if planeIndex_1 in proposals_1 and planeIndex_2 in proposals_2:\n                        proposalIndex_1 = np.where(proposals_1 == planeIndex_1)[0][0]\n                        proposalIndex_2 = np.where(proposals_2 == planeIndex_2)[0][0]\n                        edges_features[edgeIndex, proposalIndex_1, proposalIndex_2] *= edgeWeights[0]\n                        pass\n                    if planeIndex_2 in proposals_1 and planeIndex_1 in proposals_2:\n                        proposalIndex_1 = np.where(proposals_1 == planeIndex_2)[0][0]\n                        proposalIndex_2 = np.where(proposals_2 == planeIndex_1)[0][0]\n                        edges_features[edgeIndex, proposalIndex_1, proposalIndex_2] *= edgeWeights[0]\n                        pass\n                    continue\n                lineSets[minVs * width + us, 0] = 1\n                lineSets[maxVs * width + us, 0] = 1\n                pass\n            continue\n        continue\n\n\n\n    planeDepths = calcPlaneDepths(planes, width, height, info).reshape((height * width, -1))\n    planeDepths = readProposalInfo(planeDepths, proposals).reshape((-1, numProposals))\n\n    planeHorizontalVPMask = np.ones((planes.shape[0], 3), dtype=np.bool)\n    for VPIndex, planeIndices in enumerate(vpPlaneIndices):\n        planeHorizontalVPMask[planeIndices] = False\n        continue\n\n\n    for VPIndex, lines in enumerate(VPLines):\n        lp = lines[:, :2]\n        ln = lines[:, 2:4] - lines[:, :2]\n        ln /= np.maximum(np.linalg.norm(ln, axis=-1, keepdims=True), 1e-4)\n        ln = np.stack([ln[:, 1], -ln[:, 0]], axis=1)\n        lnp = (ln * lp).sum(1, keepdims=True)\n        occlusionLines = np.concatenate([ln, lnp], axis=1)\n        for occlusionLine in occlusionLines:\n            if abs(occlusionLine[0]) > abs(occlusionLine[1]):\n                vs = np.arange(height)\n                us = (occlusionLine[2] - vs * occlusionLine[1]) / occlusionLine[0]\n                minUs = np.floor(us).astype(np.int32)\n                maxUs = minUs + 1\n                validIndicesMask = np.logical_and(minUs >= 0, maxUs < width)\n                vs = vs[validIndicesMask]\n                minUs = minUs[validIndicesMask]\n                maxUs = maxUs[validIndicesMask]\n                edgeIndices = (height - 1) * width + (vs * (width - 1) + minUs)\n                for index, edgeIndex in enumerate(edgeIndices):\n                    pixel_1 = vs[index] * width + minUs[index]\n                    pixel_2 = vs[index] * width + maxUs[index]\n                    proposals_1 = proposals[pixel_1]\n                    proposals_2 = proposals[pixel_2]\n                    for proposalIndex_1, planeIndex_1 in enumerate(proposals_1):\n                        if not planeHorizontalVPMask[planeIndex_1][VPIndex]:\n                            continue\n                        planeDepth_1 = planeDepths[pixel_1][proposalIndex_1]\n                        for proposalIndex_2, planeIndex_2 in enumerate(proposals_2):\n                            if planeDepths[pixel_2][proposalIndex_2] > planeDepth_1:\n                                edges_features[edgeIndex, proposalIndex_1, proposalIndex_2] *= edgeWeights[1]\n                                pass\n                            continue\n                        continue\n                    continue\n                lineSets[vs * width + minUs, 1] = 1\n                lineSets[vs * width + maxUs, 1] = 1\n            else:\n                us = np.arange(width)\n                vs = (occlusionLine[2] - us * occlusionLine[0]) / occlusionLine[1]\n\n                minVs = np.floor(vs).astype(np.int32)\n                maxVs = minVs + 1\n                validIndicesMask = np.logical_and(minVs >= 0, maxVs < height)\n                us = us[validIndicesMask]\n                minVs = minVs[validIndicesMask]\n                maxVs = maxVs[validIndicesMask]\n                edgeIndices = (minVs * width + us)\n                for index, edgeIndex in enumerate(edgeIndices):\n                    pixel_1 = minVs[index] * width + us[index]\n                    pixel_2 = maxVs[index] * width + us[index]\n                    proposals_1 = proposals[pixel_1]\n                    proposals_2 = proposals[pixel_2]\n                    for proposalIndex_1, planeIndex_1 in enumerate(proposals_1):\n                        if not planeHorizontalVPMask[planeIndex_1][VPIndex]:\n                            continue\n                        planeDepth_1 = planeDepths[pixel_1][proposalIndex_1]\n                        for proposalIndex_2, planeIndex_2 in enumerate(proposals_2):\n                            if planeDepths[pixel_2][proposalIndex_2] > planeDepth_1:\n                                edges_features[edgeIndex, proposalIndex_1, proposalIndex_2] *= edgeWeights[1]\n                                pass\n                            continue\n                        continue\n                    continue\n                lineSets[minVs * width + us, 1] = 1\n                lineSets[maxVs * width + us, 1] = 1\n                pass\n            continue\n        continue\n\n    # lp = remainingLines[:, :2]\n    # ln = remainingLines[:, 2:4] - remainingLines[:, :2]\n    # ln /= np.maximum(np.linalg.norm(ln, axis=-1, keepdims=True), 1e-4)\n    # ln = np.stack([ln[:, 1], -ln[:, 0]], axis=1)\n    # lnp = (ln * lp).sum(1, keepdims=True)\n    # occusionLines = np.concatenate([ln, lnp], axis=1)\n\n    for line in remainingLines:\n        if abs(line[3] - line[1]) > abs(line[2] - line[0]):\n            if line[3] < line[1]:\n                line = np.array([line[2], line[3], line[0], line[1]])\n                pass\n            vs = np.arange(line[1], line[3] + 1, dtype=np.int32)\n            us = line[0] + (vs - line[1]) / (line[3] - line[1]) * (line[2] - line[0])\n            minUs = np.floor(us).astype(np.int32)\n            maxUs = minUs + 1\n            validIndicesMask = np.logical_and(minUs >= 0, maxUs < width)\n            vs = vs[validIndicesMask]\n            minUs = minUs[validIndicesMask]\n            maxUs = maxUs[validIndicesMask]\n            edgeIndices = (height - 1) * width + (vs * (width - 1) + minUs)\n            for edgeIndex in edgeIndices:\n                edges_features[edgeIndex] *= edgeWeights[2]\n                continue\n            lineSets[(vs * width + minUs), 2] = 1\n            lineSets[(vs * width + maxUs), 2] = 1\n        else:\n            if line[2] < line[0]:\n                line = np.array([line[2], line[3], line[0], line[1]])\n                pass\n            us = np.arange(line[0], line[2] + 1, dtype=np.int32)\n            vs = line[1] + (us - line[0]) / (line[2] - line[0]) * (line[3] - line[1])\n\n            minVs = np.floor(vs).astype(np.int32)\n            maxVs = minVs + 1\n            validIndicesMask = np.logical_and(minVs >= 0, maxVs < height)\n            us = us[validIndicesMask]\n            minVs = minVs[validIndicesMask]\n            maxVs = maxVs[validIndicesMask]\n            edgeIndices = (minVs * width + us)\n            for edgeIndex in edgeIndices:\n                edges_features[edgeIndex] *= edgeWeights[2]\n                continue\n            lineSets[minVs * width + us, 2] = 1\n            lineSets[maxVs * width + us, 2] = 1\n            continue\n        continue\n    cv2.imwrite(\'test/line_sets.png\', drawMaskImage(lineSets.reshape((height, width, 3))))\n\n\n    if \'smoothnessWeight\' in parameters:\n        smoothnessWeight = parameters[\'smoothnessWeight\']\n    else:\n        smoothnessWeight = 4\n        pass\n\n    refined_segmentation = inference_ogm(unaries, -edges_features * smoothnessWeight, edges, return_energy=False, alg=\'trw\')\n    refined_segmentation = refined_segmentation.reshape([height, width, 1])\n    refined_segmentation = readProposalInfo(proposals, refined_segmentation)\n    #print(pairwise_matrix)\n    #refined_segmentation = inference_ogm(unaries * 5, -pairwise_matrix, edges, return_energy=False, alg=\'alphaexp\')\n    planeSegmentation = refined_segmentation.reshape([height, width])\n\n    planeSegmentation[np.logical_not(validMask.reshape((height, width)))] = planes.shape[0]\n    cv2.imwrite(\'test/segmentation_refined.png\', drawSegmentationImage(planeSegmentation))\n    #exit(1)\n\n    # if planes.shape[0] > numOutputPlanes:\n    #     planeInfo = []\n    #     for planeIndex in xrange(planes.shape[0]):\n    #         mask = planeSegmentation == planeIndex\n    #         planeInfo.append((planes[planeIndex], mask))\n    #         continue\n    #     planeInfo = sorted(planeInfo, key=lambda x: -x[1].sum())\n    #     newPlanes = []\n    #     newPlaneSegmentation = np.full(planeSegmentation.shape, numOutputPlanes)\n    #     for planeIndex in xrange(numOutputPlanes):\n    #         newPlanes.append(planeInfo[planeIndex][0])\n    #         newPlaneSegmentation[planeInfo[planeIndex][1]] = planeIndex\n    #         continue\n    #     planeSegmentation = newPlaneSegmentation\n    #     planes = np.array(newPlanes)\n    # else:\n    #     planeSegmentation[planeSegmentation == planes.shape[0]] = numOutputPlanes\n    #     pass\n\n    # if planes.shape[0] < numOutputPlanes:\n    #     planes = np.concatenate([planes, np.zeros((numOutputPlanes - planes.shape[0], 3))], axis=0)\n    #     pass\n\n    # planeDepths = calcPlaneDepths(planes, width, height, info)\n\n    # allDepths = np.concatenate([planeDepths, np.expand_dims(depth, -1)], axis=2)\n    # depthPred = allDepths.reshape([height * width, numOutputPlanes + 1])[np.arange(width * height), planeSegmentation.astype(np.int32).reshape(-1)].reshape(height, width)\n\n\n    # planeNormals = calcPlaneNormals(planes, width, height)\n    # allNormals = np.concatenate([np.expand_dims(normal, 2), planeNormals], axis=2)\n    # normalPred = allNormals.reshape(-1, numOutputPlanes + 1, 3)[np.arange(width * height), planeSegmentation.reshape(-1)].reshape((height, width, 3))\n\n    return planes, planeSegmentation\n\n\ndef testPlaneExtraction():\n    depth = cv2.imread(\'../../Data/SUNCG/0004d52d1aeeb8ae6de39d6bd993e992/000000_depth.png\', -1).astype(np.float32) / 1000\n    normal = (cv2.imread(\'../../Data/SUNCG/0004d52d1aeeb8ae6de39d6bd993e992/000000_norm_camera.png\').astype(np.float32) / 255) * 2 - 1\n    normal = np.stack([normal[:, :, 2], normal[:, :, 1], normal[:, :, 0]], axis=2)\n    image = cv2.imread(\'../../Data/SUNCG/0004d52d1aeeb8ae6de39d6bd993e992/000000_mlt.png\')\n\n    cv2.imwrite(\'test/depth.png\', drawDepthImage(depth))\n    cv2.imwrite(\'test/normal.png\', drawNormalImage(normal))\n    cv2.imwrite(\'test/image.png\', image)\n\n    info = np.zeros(20)\n    info[0] = 517.97\n    info[2] = 320\n    info[5] = 517.97\n    info[6] = 240\n    info[10] = 1\n    info[15] = 1\n    info[16] = 640\n    info[17] = 480\n    info[18] = 1000\n    info[19] = 0\n\n    parameters = {\'distanceCostThreshold\': 0.05, \'numProposals\': 3, \'smoothnessWeight\': 30, \'offsetGap\': 0.05},\n    #pred_p, pred_s, pred_d, pred_n = fitPlanesManhattan(image, depth, normal, info, numOutputPlanes=20, imageIndex=-1, parameters=parameters)\n    pred_p, pred_s, pred_d, pred_n = fitPlanesPiecewise(image, depth, normal, info, numOutputPlanes=20, imageIndex=-1, parameters=parameters)\n    exit(1)\n    return\n\ndef estimateFocalLength(image):\n    from pylsd import lsd\n\n    height = image.shape[0]\n    width = image.shape[1]\n\n    lines = lsd(image.mean(2))\n\n    lineImage = image.copy()\n    for line in lines:\n        cv2.line(lineImage, (int(line[0]), int(line[1])), (int(line[2]), int(line[3])), (0, 0, 255), int(np.ceil(line[4] / 2)))\n        continue\n    cv2.imwrite(\'test/lines.png\', lineImage)\n\n    numVPs = 3\n    VPs, VPLines, remainingLines = calcVanishingPoints(lines, numVPs=numVPs)\n    #focalLength = (np.sqrt(np.linalg.norm(np.cross(VPs[0], VPs[1]))) + np.sqrt(np.linalg.norm(np.cross(VPs[0], VPs[2]))) + np.sqrt(np.linalg.norm(np.cross(VPs[1], VPs[2])))) / 3\n    focalLength = (np.sqrt(np.abs(np.dot(VPs[0], VPs[1]))) + np.sqrt(np.abs(np.dot(VPs[0], VPs[2]))) + np.sqrt(np.abs(np.dot(VPs[1], VPs[2])))) / 3\n    return focalLength\n\ndef calcEdgeMap(segmentation, edgeWidth=3):\n    edges = np.zeros(segmentation.shape, np.bool)\n    for shift in [-1, 1]:\n        for c in [0, 1]:\n            edges = np.logical_or(edges, segmentation != np.roll(segmentation, shift, axis=c))\n            continue\n        continue\n    edges = edges.astype(np.float32)\n    edges[0] = 0\n    edges[-1] = 0\n    edges[:, 0] = 0\n    edges[:, -1] = 0\n    edges = cv2.dilate(edges, np.ones((3, 3)), iterations=edgeWidth)\n    return edges > 0.5\n\n#testPlaneExtraction()\n\ndef findFloorPlane(planes, segmentation):\n    minZ = 0\n    minZPlaneIndex = -1\n    minFloorArea = 32 * 24\n    for planeIndex, plane in enumerate(planes):\n        if plane[2] < 0 and abs(plane[2]) > max(abs(plane[0]), abs(plane[1])) and plane[2] < minZ and (segmentation == planeIndex).sum() > minFloorArea:\n            minZPlaneIndex = planeIndex\n            minZ = plane[2]\n            pass\n        continue\n    return minZPlaneIndex\n\ndef findCornerPoints(plane, depth, mask, info, axis=2, rectangle=True):\n    width = depth.shape[1]\n    height = depth.shape[0]\n\n    camera = getCameraFromInfo(info)\n\n    #camera = getNYURGBDCamera()\n    #camera = getSUNCGCamera()\n\n    urange = (np.arange(width, dtype=np.float32) / width * camera[\'width\'] - camera[\'cx\']) / camera[\'fx\']\n    urange = urange.reshape(1, -1).repeat(height, 0)\n    vrange = (np.arange(height, dtype=np.float32) / height * camera[\'height\'] - camera[\'cy\']) / camera[\'fy\']\n    vrange = vrange.reshape(-1, 1).repeat(width, 1)\n    X = depth * urange\n    Y = depth\n    Z = -depth * vrange\n\n    XYZ = np.stack([X, Y, Z], axis=2)\n    XYZ = XYZ.reshape((-1, 3))\n\n    maxs = XYZ.max(0)\n    mins = XYZ.min(0)\n\n    planeD = np.linalg.norm(plane)\n    planeNormal = plane / np.maximum(planeD, 1e-4)\n\n    if axis == 2:\n        points = np.array([[mins[0], mins[1]], [mins[0], maxs[1]], [maxs[0], mins[1]], [maxs[0], maxs[1]]])\n        pointsZ = (planeD - planeNormal[0] * points[:, 0] - planeNormal[1] * points[:, 1]) / planeNormal[2]\n        points = np.concatenate([points, np.expand_dims(pointsZ, -1)], axis=1)\n        pass\n\n    u = (points[:, 0] / points[:, 1] * camera[\'fx\'] + camera[\'cx\']) / camera[\'width\'] * width\n    v = (-points[:, 2] / points[:, 1] * camera[\'fy\'] + camera[\'cy\']) / camera[\'height\'] * height\n\n    if rectangle:\n        minU = u.min()\n        maxU = u.max()\n        minV = v.min()\n        maxV = v.max()\n        uv = np.array([[minU, minV], [minU, maxV], [maxU, minV], [maxU, maxV]])\n    else:\n        uv = np.stack([u, v], axis=1)\n        pass\n    return uv\n\ndef findCornerPoints2D(mask):\n    from pylsd import lsd\n    lines = lsd(mask)\n\n    #lineImage = mask.copy()\n    lineImage = np.zeros(mask.shape + (3, ))\n    print(lines.shape)\n    print(lines)\n    for line in lines:\n        cv2.line(lineImage, (int(line[0]), int(line[1])), (int(line[2]), int(line[3])), (0, 0, 255), int(np.ceil(line[4] / 2)))\n        continue\n    cv2.imwrite(\'test/lines.png\', lineImage)\n    exit(1)\n\n\ndef copyTexture(image, planes, segmentation, info, denotedPlaneIndex=-1, textureIndex=-1):\n    import glob\n\n    width = segmentation.shape[1]\n    height = segmentation.shape[0]\n\n    plane_depths = calcPlaneDepths(planes, width, height, info)\n\n    texture_image_names = glob.glob(\'../texture_images/*.png\') + glob.glob(\'../texture_images/*.jpg\')\n    if textureIndex >= 0:\n        texture_image_names = [texture_image_names[textureIndex]]\n        pass\n\n    resultImages = []\n    for texture_index, texture_image_name in enumerate(texture_image_names):\n        textureImage = cv2.imread(texture_image_name)\n        #textureImage = cv2.imread(\'../textures/texture_2.jpg\')\n        textureImage = cv2.resize(textureImage, (width, height), interpolation=cv2.INTER_LINEAR)\n\n        if denotedPlaneIndex < 0:\n            denotedPlaneIndex = findFloorPlane(planes, segmentation)\n            pass\n\n        mask = segmentation == denotedPlaneIndex\n        #mask = cv2.resize(mask.astype(np.float32), (width, height), interpolation=cv2.INTER_LINEAR) > 0.5\n        #plane_depths = calcPlaneDepths(pred_p, width, height)\n        depth = plane_depths[:, :, denotedPlaneIndex]\n        #depth = cv2.resize(depth, (width, height), interpolation=cv2.INTER_LINEAR) > 0.5\n        #uv = findCornerPoints(planes[denotedPlaneIndex], depth, mask, info)\n        uv = findCornerPoints2D(mask.astype(np.uint8) * 255)\n        #print(uv)\n        source_uv = np.array([[0, 0], [0, height], [width, 0], [width, height]])\n\n        h, status = cv2.findHomography(source_uv, uv)\n        #textureImageWarped = cv2.warpPerspective(textureImage, h, (WIDTH, HEIGHT))\n        textureImageWarped = cv2.warpPerspective(textureImage, h, (width, height))\n        resultImage = image.copy()\n\n        resultImage[mask] = textureImageWarped[mask]\n        resultImages.append(resultImage)\n        #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_texture.png\', textureImageWarped)\n        #cv2.imwrite(options.test_dir + \'/\' + str(index) + \'_result_\' + str(texture_index) + \'.png\', resultImage)\n        continue\n    return resultImages\n\n\ndef copyLogo(folder, index, image, depth, planes, segmentation, info):\n    import glob\n    from sklearn.cluster import KMeans\n    from skimage import measure\n    #from sklearn.decomposition import PCA\n\n    width = segmentation.shape[1]\n    height = segmentation.shape[0]\n\n    camera = getCameraFromInfo(info)\n\n    urange = (np.arange(width, dtype=np.float32) / width * camera[\'width\'] - camera[\'cx\']) / camera[\'fx\']\n    urange = urange.reshape(1, -1).repeat(height, 0)\n    vrange = (np.arange(height, dtype=np.float32) / height * camera[\'height\'] - camera[\'cy\']) / camera[\'fy\']\n    vrange = vrange.reshape(-1, 1).repeat(width, 1)\n    X = depth * urange\n    Y = depth\n    Z = -depth * vrange\n    XYZ = np.stack([X, Y, Z], axis=2)\n    #plane_depths = calcPlaneDepths(planes, width, height, info)\n\n    planesD = np.linalg.norm(planes, axis=-1, keepdims=True)\n    planesNormal = planes / np.maximum(planesD, 1e-4)\n\n    planeAreaThreshold = width * height / 100\n\n    normals = []\n    for planeIndex in xrange(planes.shape[0]):\n        mask = segmentation == planeIndex\n        if mask.sum() < planeAreaThreshold:\n            continue\n        normals.append(planesNormal[planeIndex])\n        continue\n    normals = np.stack(normals, axis=0)\n    normals[normals[:, 1] < 0] *= -1\n\n\n    kmeans = KMeans(n_clusters=3).fit(normals)\n    dominantNormals = kmeans.cluster_centers_\n    dominantNormals = dominantNormals / np.maximum(np.linalg.norm(dominantNormals, axis=-1, keepdims=True), 1e-4)\n\n    normals = planesNormal.copy()\n    normals[normals[:, 1] < 0] *= -1\n    planeClusters = kmeans.predict(normals)\n\n    #texture_image_names = glob.glob(\'../texture_images/*.png\') + glob.glob(\'../texture_images/*.jpg\')\n\n    #imageFilename = \'/home/chenliu/Projects/PlaneNet/texture_images/CVPR.jpg\'\n    #textureImage = cv2.imread(imageFilename)\n\n    #textureImage = cv2.imread(\'../texture_images/CVPR_transparent.png\')\n    textureImage = cv2.imread(\'../texture_images/CVPR.jpg\')\n    imageFilename = \'CVPR.png\'\n    cv2.imwrite(folder + \'/\' + imageFilename, textureImage)\n\n    backgroundMask = textureImage.mean(2) > 224\n    #backgroundMask = cv2.erode(backgroundMask.astype(np.uint8), np.ones((3, 3)))\n    #cv2.imwrite(\'test/mask.png\', drawMaskImage(background))\n    #exit(1)\n\n    textureHeight = textureImage.shape[0]\n    textureWidth = textureImage.shape[1]\n    textureRatio = float(textureHeight) / textureWidth\n    #textureImage = cv2.imread(\'../textures/texture_2.jpg\')\n    #textureImage = cv2.resize(textureImage, (width, height), interpolation=cv2.INTER_LINEAR)\n\n    faces = []\n    texcoords = []\n    #maskImage = np.full(segmentation.shape, planes.shape[0])\n    maskImage = image.copy()\n    for planeIndex in xrange(planes.shape[0]):\n        globalMask = segmentation == planeIndex\n        if globalMask.sum() < planeAreaThreshold:\n            continue\n\n        masks = measure.label(globalMask.astype(np.int32), background=0)\n        #print(masks.max())\n        #print(masks.min())\n        #cv2.imwrite(\'test/mask.png\', drawSegmentationImage(masks, blackIndex=planes.shape[0]))\n        #exit(1)\n        for maskIndex in xrange(masks.min() + 1, masks.max() + 1):\n            mask = masks == maskIndex\n            if mask.sum() < planeAreaThreshold:\n                continue\n\n            planeNormal = planesNormal[planeIndex]\n\n            # maxs = points.max(0)\n            # mins = points.min(0)\n\n            # planeNormal = planesNormal[planeIndex]\n            # maxAxis = np.argmax(np.abs(planeNormal))\n            # center = points.mean(0)\n            # if maxAxis != 2:\n            #     direction_u = np.cross(planeNormal, np.array([0, 0, 1]))\n            #     direction_u = direction_u / np.maximum(np.linalg.norm(direction_u), 1e-4)\n            #     direction_v = np.cross(planeNormal, direction_u)\n            #     direction_v = direction_v / np.maximum(np.linalg.norm(direction_v), 1e-4)\n            # else:\n            #     pca = PCA(n_components=1)\n            #     pca.fit(points[:, :2])\n            #     direction = np.concatenate([pca.components_[0], np.zeros(1)], axis=0)\n\n            #     direction_u = np.cross(planeNormal, direction)\n            #     direction_u = direction_u / np.maximum(np.linalg.norm(direction_u), 1e-4)\n            #     direction_v = np.cross(planeNormal, direction_u)\n            #     direction_v = direction_v / np.maximum(np.linalg.norm(direction_v), 1e-4)\n            #     pass\n\n            cluster = planeClusters[planeIndex]\n            dominantNormal = dominantNormals[(cluster + 1) % 3]\n            direction_u = np.cross(planeNormal, dominantNormal)\n            direction_u = direction_u / np.maximum(np.linalg.norm(direction_u), 1e-4)\n            direction_v = np.cross(planeNormal, direction_u)\n            direction_v = direction_v / np.maximum(np.linalg.norm(direction_v), 1e-4)\n\n            points = XYZ[mask]\n            projection_u = np.tensordot(points, direction_u, axes=([1], [0]))\n            range_u = [projection_u.min(), projection_u.max()]\n            projection_v = np.tensordot(points, direction_v, axes=([1], [0]))\n            range_v = [projection_v.min(), projection_v.max()]\n            if range_v[1] - range_v[0] > range_u[1] - range_u[0]:\n                range_u, range_v = range_v, range_u\n                direction_u, direction_v = direction_v, direction_u\n                pass\n\n            if (np.argmax(np.abs(direction_v)) == 2 and direction_v[2] < 0) or (np.argmax(np.abs(direction_v)) != 2 and np.dot(np.array([0, 1, 0]), direction_v) < 0):\n                direction_v *= -1\n                projection_v *= -1\n                range_v = [-range_v[1], -range_v[0]]\n                pass\n            if np.dot(np.cross(planeNormal, direction_v), direction_u) < 0:\n                direction_u *= -1\n                projection_u *= -1\n                range_u = [-range_u[1], -range_u[0]]\n                pass\n\n            print(planeIndex, dominantNormal, direction_u, direction_v)\n\n\n            length_u = range_u[1] - range_u[0]\n            length_v = range_v[1] - range_v[0]\n            if length_u * textureRatio > length_v:\n                length_u = length_v / textureRatio\n            else:\n                length_v = length_u * textureRatio\n                pass\n\n            logoSize = 0.35\n\n            center_u = (range_u[0] + range_u[1]) / 2\n            range_u = [center_u - length_u * logoSize, center_u + length_u * logoSize]\n\n            center_v = (range_v[0] + range_v[1]) / 2\n            range_v = [center_v - length_v * logoSize, center_v + length_v * logoSize]\n\n            projection_u = np.tensordot(XYZ, direction_u, axes=([2], [0]))\n            projection_v = np.tensordot(XYZ, direction_v, axes=([2], [0]))\n            projection_u = (projection_u - range_u[0]) / (range_u[1] - range_u[0])\n            projection_v = (projection_v - range_v[0]) / (range_v[1] - range_v[0])\n            rectangleMask = np.logical_and(np.logical_and(projection_u >= 0, projection_u <= 1), np.logical_and(projection_v >= 0, projection_v <= 1))\n\n            rectangleMask = np.logical_and(rectangleMask, mask)\n            #maskImage[rectangleMask] = planeIndex\n\n            for y in xrange(height - 1):\n                for x in xrange(width - 1):\n                    facePixels = []\n                    for pixel in [(x, y), (x + 1, y), (x + 1, y + 1), (x, y + 1)]:\n                        if rectangleMask[pixel[1]][pixel[0]]:\n                            u = projection_u[pixel[1]][pixel[0]]\n                            v = projection_v[pixel[1]][pixel[0]]\n                            u = min(max(int(round(u * textureWidth)), 0), textureWidth - 1)\n                            v = min(max(textureHeight - 1 - int(round(v * textureHeight)), 0), textureHeight - 1)\n                            if backgroundMask[v][u] == False:\n                                facePixels.append(pixel)\n\n                                if pixel == (x, y):\n                                    maskImage[y][x] = textureImage[v][u]\n                                    pass\n                                pass\n                            pass\n                        continue\n\n                    if len(facePixels) == 3:\n                        faces.append(facePixels[0] + facePixels[1] + facePixels[2])\n                        vt = []\n                        for c in [0, 1, 2]:\n                            vt.append(projection_u[facePixels[c][1]][facePixels[c][0]])\n                            vt.append(projection_v[facePixels[c][1]][facePixels[c][0]])\n                            continue\n                        texcoords.append(vt)\n                    elif len(facePixels) == 4:\n                        faces.append(facePixels[0] + facePixels[1] + facePixels[2])\n                        vt = []\n                        for c in [0, 1, 2]:\n                            vt.append(projection_u[facePixels[c][1]][facePixels[c][0]])\n                            vt.append(projection_v[facePixels[c][1]][facePixels[c][0]])\n                            continue\n                        texcoords.append(vt)\n                        faces.append(facePixels[0] + facePixels[2] + facePixels[3])\n                        vt = []\n                        for c in [0, 2, 3]:\n                            vt.append(projection_u[facePixels[c][1]][facePixels[c][0]])\n                            vt.append(projection_v[facePixels[c][1]][facePixels[c][0]])\n                            continue\n                        texcoords.append(vt)\n                        pass\n                    continue\n                continue\n            continue\n        continue\n\n    #cv2.imwrite(\'test/mask.png\', drawSegmentationImage(maskImage, blackIndex=planes.shape[0]))\n    #cv2.imwrite(\'test/mask.png\', drawSegmentationImage(maskImage, blackIndex=planes.shape[0]))\n\n\n    with open(folder + \'/\' + str(index) + \'_logo.ply\', \'w\') as f:\n        header = """"""ply\nformat ascii 1.0\ncomment VCGLIB generated\ncomment TextureFile """"""\n        header += imageFilename\n        header += """"""\nelement vertex """"""\n        header += str(width * height)\n        header += """"""\nproperty float x\nproperty float y\nproperty float z\nelement face """"""\n        header += str(len(faces))\n        header += """"""\nproperty list uchar int vertex_indices\nproperty list uchar float texcoord\nend_header\n""""""\n        f.write(header)\n        for y in xrange(height):\n            for x in xrange(width):\n                segmentIndex = segmentation[y][x]\n                if segmentIndex == -1:\n                    f.write(""0.0 0.0 0.0\\n"")\n                    continue\n                point = XYZ[y][x]\n                X = point[0] * 0.9999\n                Y = point[1] * 0.9999\n                Z = point[2] * 0.9999\n                #Y = depth[y][x]\n                #X = Y / focalLength * (x - width / 2) / width * 640\n                #Z = -Y / focalLength * (y - height / 2) / height * 480\n                f.write(str(X) + \' \' +    str(Z) + \' \' + str(-Y) + \'\\n\')\n                continue\n            continue\n\n\n        for faceIndex, face in enumerate(faces):\n            f.write(\'3 \')\n            for c in xrange(3):\n                f.write(str(face[c * 2 + 1] * width + face[c * 2]) + \' \')\n                continue\n            f.write(\'6 \')\n            vt = texcoords[faceIndex]\n            for value in vt:\n                f.write(str(value) + \' \')\n                continue\n            # for c in xrange(3):\n            #     f.write(str(float(face[c * 2]) / width) + \' \' + str(1 - float(face[c * 2 + 1]) / height) + \' \')\n            #     continue\n            f.write(\'\\n\')\n            continue\n        f.close()\n        pass\n    return maskImage\n\n\ndef copyWallTexture(folder, index, image, depth, planes, segmentation, info, wallPlanes=[]):\n    import glob\n    from sklearn.cluster import KMeans\n    from skimage import measure\n    #from sklearn.decomposition import PCA\n\n    width = segmentation.shape[1]\n    height = segmentation.shape[0]\n\n    camera = getCameraFromInfo(info)\n\n    urange = (np.arange(width, dtype=np.float32) / width * camera[\'width\'] - camera[\'cx\']) / camera[\'fx\']\n    urange = urange.reshape(1, -1).repeat(height, 0)\n    vrange = (np.arange(height, dtype=np.float32) / height * camera[\'height\'] - camera[\'cy\']) / camera[\'fy\']\n    vrange = vrange.reshape(-1, 1).repeat(width, 1)\n    X = depth * urange\n    Y = depth\n    Z = -depth * vrange\n    XYZ = np.stack([X, Y, Z], axis=2)\n    #plane_depths = calcPlaneDepths(planes, width, height, info)\n\n    planesD = np.linalg.norm(planes, axis=-1, keepdims=True)\n    planesNormal = planes / np.maximum(planesD, 1e-4)\n\n    planeAreaThreshold = width * height / 100\n\n    normals = []\n    for planeIndex in xrange(planes.shape[0]):\n        mask = segmentation == planeIndex\n        if mask.sum() < planeAreaThreshold:\n            continue\n        normals.append(planesNormal[planeIndex])\n        continue\n    normals = np.stack(normals, axis=0)\n    normals[normals[:, 1] < 0] *= -1\n\n\n    kmeans = KMeans(n_clusters=3).fit(normals)\n    dominantNormals = kmeans.cluster_centers_\n    dominantNormals = dominantNormals / np.maximum(np.linalg.norm(dominantNormals, axis=-1, keepdims=True), 1e-4)\n\n    normals = planesNormal.copy()\n    normals[normals[:, 1] < 0] *= -1\n    planeClusters = kmeans.predict(normals)\n\n    #texture_image_names = glob.glob(\'../texture_images/*.png\') + glob.glob(\'../texture_images/*.jpg\')\n\n    #imageFilename = \'/home/chenliu/Projects/PlaneNet/texture_images/CVPR.jpg\'\n    #textureImage = cv2.imread(imageFilename)\n\n    #textureImage = cv2.imread(\'../texture_images/CVPR_transparent.png\')\n    textureImage = cv2.imread(\'../texture_images/checkerboard.jpg\')\n    imageFilename = \'checkerboard.png\'\n    cv2.imwrite(folder + \'/\' + imageFilename, textureImage)\n\n    #background = textureImage.mean(2) > 224\n    #background = cv2.erode(background.astype(np.uint8), np.ones((3, 3)))\n    #cv2.imwrite(\'test/mask.png\', drawMaskImage(background))\n    #exit(1)\n\n    textureHeight = textureImage.shape[0]\n    textureWidth = textureImage.shape[1]\n    textureRatio = float(textureHeight) / textureWidth\n    #textureImage = cv2.imread(\'../textures/texture_2.jpg\')\n    #textureImage = cv2.resize(textureImage, (width, height), interpolation=cv2.INTER_LINEAR)\n\n    faces = []\n    texcoords = []\n    #maskImage = np.full(segmentation.shape, planes.shape[0])\n    maskImage = image.copy()\n    print(wallPlanes)\n    print(textureImage.shape)\n    for planeIndex in xrange(planes.shape[0]):\n        if planeIndex not in wallPlanes:\n            continue\n        globalMask = segmentation == planeIndex\n        if globalMask.sum() < planeAreaThreshold:\n            continue\n\n        masks = measure.label(globalMask.astype(np.int32), background=0)\n        #print(masks.max())\n        #print(masks.min())\n        cv2.imwrite(\'test/mask.png\', drawSegmentationImage(masks, blackIndex=planes.shape[0]))\n        #print((masks == 1).sum(), planeAreaThreshold)\n        #print(planeAreaThreshold)\n        #exit(1)\n        for maskIndex in xrange(masks.min() + 1, masks.max() + 1):\n            mask = masks == maskIndex\n            if mask.sum() < planeAreaThreshold:\n                continue\n\n            planeNormal = planesNormal[planeIndex]\n\n            # maxs = points.max(0)\n            # mins = points.min(0)\n\n            # planeNormal = planesNormal[planeIndex]\n            # maxAxis = np.argmax(np.abs(planeNormal))\n            # center = points.mean(0)\n            # if maxAxis != 2:\n            #     direction_u = np.cross(planeNormal, np.array([0, 0, 1]))\n            #     direction_u = direction_u / np.maximum(np.linalg.norm(direction_u), 1e-4)\n            #     direction_v = np.cross(planeNormal, direction_u)\n            #     direction_v = direction_v / np.maximum(np.linalg.norm(direction_v), 1e-4)\n            # else:\n            #     pca = PCA(n_components=1)\n            #     pca.fit(points[:, :2])\n            #     direction = np.concatenate([pca.components_[0], np.zeros(1)], axis=0)\n\n            #     direction_u = np.cross(planeNormal, direction)\n            #     direction_u = direction_u / np.maximum(np.linalg.norm(direction_u), 1e-4)\n            #     direction_v = np.cross(planeNormal, direction_u)\n            #     direction_v = direction_v / np.maximum(np.linalg.norm(direction_v), 1e-4)\n            #     pass\n\n            cluster = planeClusters[planeIndex]\n            dominantNormal = dominantNormals[(cluster + 1) % 3]\n            direction_u = np.cross(planeNormal, dominantNormal)\n            direction_u = direction_u / np.maximum(np.linalg.norm(direction_u), 1e-4)\n            direction_v = np.cross(planeNormal, direction_u)\n            direction_v = direction_v / np.maximum(np.linalg.norm(direction_v), 1e-4)\n\n            points = XYZ[mask]\n            projection_u = np.tensordot(points, direction_u, axes=([1], [0]))\n            range_u = [projection_u.min(), projection_u.max()]\n            projection_v = np.tensordot(points, direction_v, axes=([1], [0]))\n            range_v = [projection_v.min(), projection_v.max()]\n            if range_v[1] - range_v[0] > range_u[1] - range_u[0]:\n                range_u, range_v = range_v, range_u\n                direction_u, direction_v = direction_v, direction_u\n                pass\n\n            if (np.argmax(np.abs(direction_v)) == 2 and direction_v[2] < 0) or (np.argmax(np.abs(direction_v)) != 2 and np.dot(np.array([0, 1, 0]), direction_v) < 0):\n                direction_v *= -1\n                projection_v *= -1\n                range_v = [-range_v[1], -range_v[0]]\n                pass\n            if np.dot(np.cross(planeNormal, direction_v), direction_u) < 0:\n                direction_u *= -1\n                projection_u *= -1\n                range_u = [-range_u[1], -range_u[0]]\n                pass\n\n            print(planeIndex, dominantNormal, direction_u, direction_v)\n\n\n            length_u = range_u[1] - range_u[0]\n            length_v = range_v[1] - range_v[0]\n            if length_u * textureRatio > length_v:\n                length_u = length_v / textureRatio\n            else:\n                length_v = length_u * textureRatio\n                pass\n\n            #logoSize = 0.35\n\n            # center_u = (range_u[0] + range_u[1]) / 2\n            # range_u = [center_u - length_u * logoSize, center_u + length_u * logoSize]\n\n            # center_v = (range_v[0] + range_v[1]) / 2\n            # range_v = [center_v - length_v * logoSize, center_v + length_v * logoSize]\n\n            projection_u = np.tensordot(XYZ, direction_u, axes=([2], [0]))\n            projection_v = np.tensordot(XYZ, direction_v, axes=([2], [0]))\n            #projection_u = (projection_u - range_u[0]) / (range_u[1] - range_u[0])\n            #projection_v = (projection_v - range_v[0]) / (range_v[1] - range_v[0])\n\n            #rectangleMask = np.logical_and(np.logical_and(projection_u >= 0, projection_u <= 1), np.logical_and(projection_v >= 0, projection_v <= 1))\n            #rectangleMask = np.logical_and(rectangleMask, mask)\n\n            textureSize = 1\n            projection_u = (projection_u / textureSize) % 1\n            projection_v = (projection_v / textureSize) % 1\n            rectangleMask = mask\n\n            #maskImage[rectangleMask] = planeIndex\n\n            for y in xrange(height - 1):\n                for x in xrange(width - 1):\n                    facePixels = []\n                    for pixel in [(x, y), (x + 1, y), (x + 1, y + 1), (x, y + 1)]:\n                        if rectangleMask[pixel[1]][pixel[0]]:\n                            # u = projection_u[pixel[1]][pixel[0]]\n                            # v = projection_v[pixel[1]][pixel[0]]\n                            # u = min(max(int(round(u * textureWidth)), 0), textureWidth - 1)\n                            # v = min(max(textureHeight - 1 - int(round(v * textureHeight)), 0), textureHeight - 1)\n                            # if background[v][u] == False:\n                            facePixels.append(pixel)\n\n                            #print(pixel, (x, y))\n                            if pixel == (x, y):\n                                u = projection_u[pixel[1]][pixel[0]]\n                                v = projection_v[pixel[1]][pixel[0]]\n                                u = min(max(int(round(u * textureWidth)), 0), textureWidth - 1)\n                                v = min(max(textureHeight - 1 - int(round(v * textureHeight)), 0), textureHeight - 1)\n\n                                #print(x, y)\n                                #print(u, v)\n\n                                maskImage[y][x] = textureImage[v][u]\n                                pass\n                            pass\n                        continue\n\n                    if len(facePixels) == 3:\n                        faces.append(facePixels[0] + facePixels[1] + facePixels[2])\n                        vt = []\n                        for c in [0, 1, 2]:\n                            vt.append(projection_u[facePixels[c][1]][facePixels[c][0]])\n                            vt.append(projection_v[facePixels[c][1]][facePixels[c][0]])\n                            continue\n                        texcoords.append(vt)\n                    elif len(facePixels) == 4:\n                        faces.append(facePixels[0] + facePixels[1] + facePixels[2])\n                        vt = []\n                        for c in [0, 1, 2]:\n                            vt.append(projection_u[facePixels[c][1]][facePixels[c][0]])\n                            vt.append(projection_v[facePixels[c][1]][facePixels[c][0]])\n                            continue\n                        texcoords.append(vt)\n                        faces.append(facePixels[0] + facePixels[2] + facePixels[3])\n                        vt = []\n                        for c in [0, 2, 3]:\n                            vt.append(projection_u[facePixels[c][1]][facePixels[c][0]])\n                            vt.append(projection_v[facePixels[c][1]][facePixels[c][0]])\n                            continue\n                        texcoords.append(vt)\n                        pass\n                    continue\n                continue\n            continue\n        continue\n\n    #cv2.imwrite(\'test/mask.png\', drawSegmentationImage(maskImage, blackIndex=planes.shape[0]))\n\n\n    with open(folder + \'/\' + str(index) + \'_logo.ply\', \'w\') as f:\n        header = """"""ply\nformat ascii 1.0\ncomment VCGLIB generated\ncomment TextureFile """"""\n        header += imageFilename\n        header += """"""\nelement vertex """"""\n        header += str(width * height)\n        header += """"""\nproperty float x\nproperty float y\nproperty float z\nelement face """"""\n        header += str(len(faces))\n        header += """"""\nproperty list uchar int vertex_indices\nproperty list uchar float texcoord\nend_header\n""""""\n        f.write(header)\n        for y in xrange(height):\n            for x in xrange(width):\n                segmentIndex = segmentation[y][x]\n                if segmentIndex == -1:\n                    f.write(""0.0 0.0 0.0\\n"")\n                    continue\n                point = XYZ[y][x]\n                X = point[0] * 0.9999\n                Y = point[1] * 0.9999\n                Z = point[2] * 0.9999\n                #Y = depth[y][x]\n                #X = Y / focalLength * (x - width / 2) / width * 640\n                #Z = -Y / focalLength * (y - height / 2) / height * 480\n                f.write(str(X) + \' \' +    str(Z) + \' \' + str(-Y) + \'\\n\')\n                continue\n            continue\n\n\n        for faceIndex, face in enumerate(faces):\n            f.write(\'3 \')\n            for c in xrange(3):\n                f.write(str(face[c * 2 + 1] * width + face[c * 2]) + \' \')\n                continue\n            f.write(\'6 \')\n            vt = texcoords[faceIndex]\n            for value in vt:\n                f.write(str(value) + \' \')\n                continue\n            # for c in xrange(3):\n            #     f.write(str(float(face[c * 2]) / width) + \' \' + str(1 - float(face[c * 2 + 1]) / height) + \' \')\n            #     continue\n            f.write(\'\\n\')\n            continue\n        f.close()\n        pass\n    return maskImage\n\n\n\ndef copyLogoVideo(folder, index, image, depth, planes, segmentation, info, textureType=\'logo\', wallInds=[]):\n    import glob\n    from sklearn.cluster import KMeans\n    from skimage import measure\n    #from sklearn.decomposition import PCA\n\n    width = segmentation.shape[1]\n    height = segmentation.shape[0]\n\n    camera = getCameraFromInfo(info)\n\n    urange = (np.arange(width, dtype=np.float32) / width * camera[\'width\'] - camera[\'cx\']) / camera[\'fx\']\n    urange = urange.reshape(1, -1).repeat(height, 0)\n    vrange = (np.arange(height, dtype=np.float32) / height * camera[\'height\'] - camera[\'cy\']) / camera[\'fy\']\n    vrange = vrange.reshape(-1, 1).repeat(width, 1)\n    X = depth * urange\n    Y = depth\n    Z = -depth * vrange\n    XYZ = np.stack([X, Y, Z], axis=2)\n    #plane_depths = calcPlaneDepths(planes, width, height, info)\n\n    planesD = np.linalg.norm(planes, axis=-1, keepdims=True)\n    planesNormal = planes / np.maximum(planesD, 1e-4)\n\n    planeAreaThreshold = width * height / 100\n\n    normals = []\n    for planeIndex in xrange(planes.shape[0]):\n        mask = segmentation == planeIndex\n        if mask.sum() < planeAreaThreshold:\n            continue\n        normals.append(planesNormal[planeIndex])\n        continue\n    normals = np.stack(normals, axis=0)\n    normals[normals[:, 1] < 0] *= -1\n\n    kmeans = KMeans(n_clusters=3).fit(normals)\n    dominantNormals = kmeans.cluster_centers_\n    dominantNormals = dominantNormals / np.maximum(np.linalg.norm(dominantNormals, axis=-1, keepdims=True), 1e-4)\n\n    normals = planesNormal.copy()\n    normals[normals[:, 1] < 0] *= -1\n    planeClusters = kmeans.predict(normals)\n\n\n    #texture_image_names = glob.glob(\'../texture_images/*.png\') + glob.glob(\'../texture_images/*.jpg\')\n\n    #imageFilename = \'/home/chenliu/Projects/PlaneNet/texture_images/CVPR.jpg\'\n    #textureImage = cv2.imread(imageFilename)\n\n    #textureImage = cv2.imread(\'../texture_images/CVPR_transparent.png\')\n    if textureType == \'wall\':\n        textureImage = cv2.imread(\'../texture_images/checkerboard.jpg\')\n        alphaMask = np.ones((textureImage.shape[0], textureImage.shape[1], 1))\n    elif textureType == \'logo\':\n        textureImage = cv2.imread(\'../texture_images/CVPR.jpg\')\n        alphaMask = (textureImage.mean(2) < 224).astype(np.float32)\n        alphaMask = np.expand_dims(alphaMask, -1)\n    elif textureType == \'TV\':\n        textureVideo = cv2.VideoCapture(\'../texture_images/TV.mp4\')\n        ret, textureImage = textureVideo.read()\n        # numFrames = 0\n        # for i in xrange(500):\n        #     ret, textureImage = textureVideo.read()\n        #     if not ret:\n        #         break\n        #     numFrames += 1\n        #     print(i, textureImage.shape)\n        #     continue\n        # print(numFrames)\n        # exit(1)\n        alphaMask = np.ones((textureImage.shape[0], textureImage.shape[1], 1))\n        pass\n\n\n    #backgroundMask = cv2.erode(backgroundMask.astype(np.uint8), np.ones((3, 3)))\n    #cv2.imwrite(\'test/mask.png\', drawMaskImage(background))\n    #exit(1)\n\n    textureHeight = float(textureImage.shape[0])\n    textureWidth = float(textureImage.shape[1])\n    textureRatio = textureHeight / textureWidth\n    textureSizes2D = np.array([textureWidth, textureHeight])\n\n    textureSizeU = 0.75\n    textureSizeV = textureSizeU * textureRatio\n    textureSizes = np.array([textureSizeU, textureSizeV])\n\n\n\n    planeMasks = []\n    planeProjections = []\n    planeRanges = []\n    for planeIndex in xrange(planes.shape[0]):\n        if textureType != \'logo\' and planeIndex not in wallInds:\n            continue\n\n        globalMask = segmentation == planeIndex\n        if globalMask.sum() < planeAreaThreshold:\n            continue\n\n        masks = measure.label(globalMask.astype(np.int32), background=0)\n        #print(masks.max())\n        #print(masks.min())\n        #cv2.imwrite(\'test/mask.png\', drawSegmentationImage(masks, blackIndex=planes.shape[0]))\n        #exit(1)\n        for maskIndex in xrange(masks.min() + 1, masks.max() + 1):\n            mask = masks == maskIndex\n            if mask.sum() < planeAreaThreshold:\n                continue\n\n            planeNormal = planesNormal[planeIndex]\n\n            cluster = planeClusters[planeIndex]\n            dominantNormal = dominantNormals[(cluster + 1) % 3]\n            direction_u = np.cross(planeNormal, dominantNormal)\n            direction_u = direction_u / np.maximum(np.linalg.norm(direction_u), 1e-4)\n            direction_v = np.cross(planeNormal, direction_u)\n            direction_v = direction_v / np.maximum(np.linalg.norm(direction_v), 1e-4)\n\n            points = XYZ[mask]\n            projection_u = np.tensordot(points, direction_u, axes=([1], [0]))\n            range_u = [projection_u.min(), projection_u.max()]\n            projection_v = np.tensordot(points, direction_v, axes=([1], [0]))\n            range_v = [projection_v.min(), projection_v.max()]\n            if textureType != \'wall\' and range_v[1] - range_v[0] > range_u[1] - range_u[0]:\n                range_u, range_v = range_v, range_u\n                direction_u, direction_v = direction_v, direction_u\n                pass\n            if textureType != \'wall\' and abs(direction_u[2]) > abs(direction_v[2]):\n                range_u, range_v = range_v, range_u\n                direction_u, direction_v = direction_v, direction_u\n                pass\n\n            if (np.argmax(np.abs(direction_v)) == 2 and direction_v[2] < 0) or (np.argmax(np.abs(direction_v)) != 2 and np.dot(np.array([0, 1, 0]), direction_v) < 0):\n                direction_v *= -1\n                projection_v *= -1\n                range_v = [-range_v[1], -range_v[0]]\n                pass\n            if np.dot(np.cross(planeNormal, direction_v), direction_u) < 0:\n                direction_u *= -1\n                projection_u *= -1\n                range_u = [-range_u[1], -range_u[0]]\n                pass\n\n            #print(planeIndex, dominantNormal, direction_u, direction_v)\n            projection_u = np.tensordot(XYZ, direction_u, axes=([2], [0]))\n            projection_v = np.tensordot(XYZ, direction_v, axes=([2], [0]))\n            planeProjections.append(np.stack([projection_u, projection_v], axis=-1).reshape((-1, 2)))\n            ranges = np.stack([range_u, range_v], axis=-1)\n            ranges = np.stack([ranges.mean(0) - (ranges[1] - ranges[0]) * 0.35, ranges.mean(0) + (ranges[1] - ranges[0]) * 0.35], axis=0)\n            planeRanges.append(ranges)\n            planeMasks.append(mask.reshape(-1))\n            continue\n        continue\n\n    numMasks = len(planeProjections)\n\n    #maskImage = np.full(segmentation.shape, planes.shape[0])\n    #ratios = np.full(2, 0.5)\n    planeRatios = np.random.random((numMasks, 2))\n    randomDirection = np.random.random((numMasks, 2))\n    if textureType == \'wall\':\n        randomDirection = np.stack([np.ones(numMasks), np.zeros(numMasks)], axis=1)\n        randomDirection[0] *= -1\n        pass\n    randomDirection = randomDirection / np.linalg.norm(randomDirection)\n    stride = 0.01\n\n    #textureImage = textureImage.reshape((-1, 3))\n\n    #for frameIndex in xrange(1000):\n    numFrames = 500\n    for frameIndex in xrange(numFrames):\n\n        if textureType != \'TV\':\n            planeRatios += randomDirection * stride\n        else:\n            #planeDynamicRanges = np.array([[0.55, -0.33, 0, 0], [-1.45, -0.395, 0, 0], [1.2, -0.6, 0, 0]])\n            planeDynamicRanges = np.array([[0.55, -0.33, 0, 0], [1.2, -0.6, 0, 0]])\n            TVSize = np.array([[0.4, 0.3], [0.4, 0.3], [0.4, 0.3]])\n            for planeIndex in xrange(2):\n                planeDynamicRanges[planeIndex, 2:] = planeDynamicRanges[planeIndex, :2] + max(min(float(frameIndex - numFrames / 2 * planeIndex) / (numFrames / 3), 1.0), 0.0) * TVSize[planeIndex]\n                continue\n            ret, textureImage = textureVideo.read()\n            if not ret:\n                textureVideo.set(cv2.cv.CV_CAP_PROP_POS_FRAMES, 0)\n                continue\n                #break\n            pass\n\n        if textureType == \'logo\':\n            invalidMask = np.logical_or(planeRatios >= 1, planeRatios <= 0)\n            planeRatios = np.maximum(np.minimum(planeRatios, 1), 0)\n            randomDirection[invalidMask] *= -1\n            pass\n\n        resultImage = image.copy().reshape((-1, 3))\n        for planeIndex in xrange(numMasks):\n            mask = planeMasks[planeIndex]\n            ranges = planeRanges[planeIndex]\n            projections = planeProjections[planeIndex]\n            ratios = planeRatios[planeIndex]\n\n            offsets = ranges[0] + (ranges[1] - ranges[0]) * ratios - textureSizes / 2\n\n            print(projections.max(0), projections.min(0))\n            if textureType == \'TV\':\n                projectionsMoved = (projections - planeDynamicRanges[planeIndex, :2]) / np.maximum(planeDynamicRanges[planeIndex, 2:] - planeDynamicRanges[planeIndex, :2], 1e-4)\n            else:\n                projectionsMoved = (projections - offsets) / textureSizes\n                pass\n\n            if textureType == \'wall\':\n                rectangleMask = mask\n            else:\n                rectangleMask = np.logical_and(projectionsMoved >= 0, projectionsMoved <= 1)\n                rectangleMask = np.logical_and(rectangleMask[:, 0], rectangleMask[:, 1])\n                rectangleMask = np.logical_and(rectangleMask, mask)\n                pass\n\n            rectangleIndices = rectangleMask.nonzero()[0]\n\n            uv = projectionsMoved[rectangleIndices] * textureSizes2D\n            uv[:, 1] = textureSizes2D[1] - 1 - uv[:, 1]\n            if textureType == \'wall\':\n                uv = uv % (textureSizes2D - 1)\n            else:\n                uv = np.maximum(np.minimum(uv, textureSizes2D - 1), 0)\n                pass\n\n            u = uv[:, 0]\n            v = uv[:, 1]\n            u_min = np.floor(u).astype(np.int32)\n            u_max = np.ceil(u).astype(np.int32)\n            v_min = np.floor(v).astype(np.int32)\n            v_max = np.ceil(v).astype(np.int32)\n\n            area_11 = (u_max - u) * (v_max - v)\n            area_12 = (u_max - u) * (v - v_min)\n            area_21 = (u - u_min) * (v_max - v)\n            area_22 = (u - u_min) * (v - v_min)\n\n            area_11 = np.expand_dims(area_11, -1)\n            area_12 = np.expand_dims(area_12, -1)\n            area_21 = np.expand_dims(area_21, -1)\n            area_22 = np.expand_dims(area_22, -1)\n\n\n            colors_11 = textureImage[v_min, u_min]\n            colors_12 = textureImage[v_max, u_min]\n            colors_21 = textureImage[v_min, u_max]\n            colors_22 = textureImage[v_max, u_max]\n\n            alphas_11 = alphaMask[v_min, u_min]\n            alphas_12 = alphaMask[v_max, u_min]\n            alphas_21 = alphaMask[v_min, u_max]\n            alphas_22 = alphaMask[v_max, u_max]\n\n            colors = colors_11 * area_11 + colors_12 * area_12 + colors_21 * area_21 + colors_22 * area_22\n            alphas = alphas_11 * area_11 + alphas_12 * area_12 + alphas_21 * area_21 + alphas_22 * area_22\n            #alphas = np.expand_dims(alphas, -1)\n            #foreground = foregroundMask[uv[:, 1], uv[:, 0]]\n            #indices = rectangleIndices[foreground]\n            #uv = uv[foreground]\n\n            #rectangleMask = np.logical_and(rectangleMask, foreground)\n\n            resultImage[rectangleIndices] = resultImage[rectangleIndices] * (1 - alphas) + colors * alphas\n            continue\n        cv2.imwrite(folder + \'/\' + (\'%04d\' % frameIndex) + \'.png\', resultImage.reshape(image.shape))\n        continue\n    #cv2.imwrite(\'test/mask.png\', drawSegmentationImage(maskImage, blackIndex=planes.shape[0]))\n    #cv2.imwrite(\'test/mask.png\', drawSegmentationImage(maskImage, blackIndex=planes.shape[0]))\n\n    return\n\ndef addCharacter(folder, index, image):\n    from skimage import measure\n\n    textureImages = []\n    alphaMasks = []\n    corner_1 = [30, 220]\n    corner_2 = [530, 470]\n    characterCorner_1 = [460, 170]\n    characterCorner_2 = [780, 330]\n    for i in xrange(1, 121):\n        textureImage = cv2.imread(\'../texture_images/Warrok1/%04d.png\'%(i))\n        textureImage = textureImage[characterCorner_1[1]:characterCorner_2[1], characterCorner_1[0]:characterCorner_2[0]]\n        #textureImage = np.concatenate([textureImage[:, -100:], textureImage[:, 150:-100], textureImage[:, :150]], axis=1)\n        alphaMask = np.maximum(textureImage[:, :, 0] < 250, textureImage[:, :, 1] > 5, textureImage[:, :, 2] > 5).astype(np.float32)\n        alphaMask = cv2.erode(alphaMask, np.ones((3, 3)))\n        #masks = measure.label(alphaMask.astype(np.int32), background=0)\n        #alphaMask = (masks != alphaMask[0][0]).astype(np.float32)\n        textureImages.append(cv2.resize(textureImage, (corner_2[0] - corner_1[0] + 1, corner_2[1] - corner_1[1] + 1)))\n        alphaMasks.append(np.expand_dims(cv2.resize(alphaMask, (corner_2[0] - corner_1[0] + 1, corner_2[1] - corner_1[1] + 1)), axis=-1))\n        continue\n\n    numFrames = 120\n    for frameIndex in xrange(numFrames):\n        textureImage = textureImages[frameIndex]\n        alphaMask = alphaMasks[frameIndex]\n        resultImage = image.copy()\n        resultImage[corner_1[1]:corner_2[1] + 1, corner_1[0]:corner_2[0] + 1] = resultImage[corner_1[1]:corner_2[1] + 1, corner_1[0]:corner_2[0] + 1] * (1 - alphaMask) + textureImage * alphaMask\n        resultImage.astype(np.uint8)\n        cv2.imwrite(folder + \'/\' + (\'%04d\' % frameIndex) + \'.png\', resultImage)\n        continue\n    return\n\n\ndef addRulerPlane(folder, index, image, depth, planes, segmentation, info, startPixel, endPixel, fixedEndPoint=False):\n\n    width = segmentation.shape[1]\n    height = segmentation.shape[0]\n\n    camera = getCameraFromInfo(info)\n\n    urange = (np.arange(width, dtype=np.float32) / width * camera[\'width\'] - camera[\'cx\']) / camera[\'fx\']\n    urange = urange.reshape(1, -1).repeat(height, 0)\n    vrange = (np.arange(height, dtype=np.float32) / height * camera[\'height\'] - camera[\'cy\']) / camera[\'fy\']\n    vrange = vrange.reshape(-1, 1).repeat(width, 1)\n    X = depth * urange\n    Y = depth\n    Z = -depth * vrange\n    XYZ = np.stack([X, Y, Z], axis=2)\n    #plane_depths = calcPlaneDepths(planes, width, height, info)\n\n    planesD = np.linalg.norm(planes, axis=-1, keepdims=True)\n    planesNormal = planes / np.maximum(planesD, 1e-4)\n\n    planeAreaThreshold = width * height / 100\n\n    normals = []\n    for planeIndex in xrange(planes.shape[0]):\n        mask = segmentation == planeIndex\n        if mask.sum() < planeAreaThreshold:\n            continue\n        normals.append(planesNormal[planeIndex])\n        continue\n    normals = np.stack(normals, axis=0)\n    normals[normals[:, 1] < 0] *= -1\n\n\n\n    #texture_image_names = glob.glob(\'../texture_images/*.png\') + glob.glob(\'../texture_images/*.jpg\')\n\n    #imageFilename = \'/home/chenliu/Projects/PlaneNet/texture_images/CVPR.jpg\'\n    #textureImage = cv2.imread(imageFilename)\n\n    #textureImage = cv2.imread(\'../texture_images/CVPR_transparent.png\')\n    textureImage = cv2.imread(\'../texture_images/ruler.png\')\n    alphaMask = np.ones((textureImage.shape[0], textureImage.shape[1], 1), dtype=np.float32)\n    #alphaMask = (textureImage.mean(2) < 224).astype(np.float32)\n    #alphaMask = np.expand_dims(alphaMask, -1)\n\n    #backgroundMask = cv2.erode(backgroundMask.astype(np.uint8), np.ones((3, 3)))\n    #cv2.imwrite(\'test/mask.png\', drawMaskImage(background))\n    #exit(1)\n\n    textureHeight = float(textureImage.shape[0])\n    textureWidth = float(textureImage.shape[1])\n    textureRatio = textureHeight / textureWidth\n    textureSizes2D = np.array([textureWidth, textureHeight])\n\n    textureSizeU = 0.96\n    textureSizeV = textureSizeU * textureRatio\n    textureSizes = np.array([textureSizeU, textureSizeV])\n    #textureImage = cv2.imread(\'../textures/texture_2.jpg\')\n    #textureImage = cv2.resize(textureImage, (width, height), interpolation=cv2.INTER_LINEAR)\n\n\n    startPlaneIndex = segmentation[startPixel[1]][startPixel[0]]\n    endPlaneIndex = segmentation[endPixel[1]][endPixel[0]]\n    assert(startPlaneIndex < planes.shape[0] and endPlaneIndex < planes.shape[0])\n    startPoint = XYZ[startPixel[1]][startPixel[0]]\n    endPoint = XYZ[endPixel[1]][endPixel[0]]\n\n    mask = (segmentation == startPlaneIndex).astype(np.uint8)\n\n    if startPlaneIndex != endPlaneIndex:\n        boundary = mask - cv2.erode(mask, np.ones((3, 3), dtype=np.uint8))\n        boundaryPoints = XYZ[boundary.nonzero()]\n        if fixedEndPoint:\n            distances = np.linalg.norm(boundaryPoints - startPoint, axis=-1) + np.linalg.norm(boundaryPoints - endPoint, axis=-1)\n            boundaryPoint = boundaryPoints[np.argmin(distances)]\n        else:\n            endPlane = planes[endPlaneIndex]\n            endPlaneD = np.linalg.norm(endPlane)\n            endPlaneNormal = endPlane / endPlaneD\n            endDistances = endPlaneD - np.tensordot(boundaryPoints, endPlaneNormal, axes=(1, 0))\n            distances = np.linalg.norm(boundaryPoints - startPoint, axis=-1) + np.abs(endDistances)\n            boundaryPointIndex = np.argmin(distances)\n            boundaryPoint = boundaryPoints[boundaryPointIndex]\n            endDistance = endDistances[boundaryPointIndex]\n            endPoint = boundaryPoint + endDistance * endPlaneNormal\n            pass\n    else:\n        boundaryPoint = startPoint\n        pass\n\n\n    passbyPlaneInds = []\n    for offset in np.arange(0.1, 1, 0.1):\n        point = boundaryPoint + (endPoint - boundaryPoint) * offset\n        u = int(round(point[0] / point[1] * camera[\'fx\'] + camera[\'cx\']))\n        v = int(round(-point[2] / point[1] * camera[\'fy\'] + camera[\'cy\']))\n        planeIndex = segmentation[v][u]\n        if planeIndex != startPlaneIndex and planeIndex < planes.shape[0] and planeIndex not in passbyPlaneInds:\n            passbyPlaneInds.append(planeIndex)\n            pass\n        continue\n    print(passbyPlaneInds)\n    if len(passbyPlaneInds):\n        passbyPlaneNormal = planesNormal[passbyPlaneInds[0]]\n    else:\n        passbyPlaneNormal = np.array([0, 1, 0])\n        pass\n\n\n    resultImage = image.copy().reshape((-1, 3))\n    distanceOffset = 0\n\n    for point_1, point_2, planeNormal, planeInds in [(startPoint, boundaryPoint, planesNormal[startPlaneIndex], [startPlaneIndex]), (boundaryPoint, endPoint, passbyPlaneNormal, passbyPlaneInds)]:\n        if point_1[0] == point_2[0] and point_1[1] == point_2[1]:\n            continue\n\n        direction_u = point_2 - point_1\n        direction_u = direction_u / np.maximum(np.linalg.norm(direction_u), 1e-4)\n        direction_v = -np.cross(planeNormal, direction_u)\n        direction_v = direction_v / np.maximum(np.linalg.norm(direction_v), 1e-4)\n        projection_u = np.tensordot(XYZ, direction_u, axes=([2], [0])).reshape(-1)\n        projection_v = np.tensordot(XYZ, direction_v, axes=([2], [0])).reshape(-1)\n\n        offset_u = np.dot(point_1, direction_u)\n        offset_v = np.dot(point_1, direction_v)\n\n        projection_u = (projection_u - offset_u) / textureSizeU\n        projection_v = (projection_v - offset_v) / textureSizeV\n\n        rectangleMask = np.logical_and(np.logical_and(projection_u >= distanceOffset / textureSizeU, projection_u <= (distanceOffset + np.linalg.norm(point_2 - point_1)) / textureSizeU), np.logical_and(projection_v >= 0, projection_v <= 1))\n\n        if len(planeInds) > 0:\n            validMask = np.zeros(segmentation.shape, dtype=np.bool)\n            for planeIndex in planeInds:\n                validMask = np.logical_or(validMask, segmentation == planeIndex)\n                continue\n            rectangleMask = np.logical_and(rectangleMask, validMask.reshape(-1))\n            pass\n\n        rectangleIndices = rectangleMask.nonzero()[0]\n\n        projections = np.stack([projection_u[rectangleIndices], projection_v[rectangleIndices]], axis=1)\n        uv = projections * textureSizes2D\n\n        uv[:, 1] = textureSizes2D[1] - 1 - uv[:, 1]\n        uv = np.maximum(np.minimum(uv, textureSizes2D - 1), 0)\n\n\n        u = uv[:, 0]\n        v = uv[:, 1]\n        u_min = np.floor(u).astype(np.int32)\n        u_max = np.ceil(u).astype(np.int32)\n        v_min = np.floor(v).astype(np.int32)\n        v_max = np.ceil(v).astype(np.int32)\n\n        area_11 = (u_max - u) * (v_max - v)\n        area_12 = (u_max - u) * (v - v_min)\n        area_21 = (u - u_min) * (v_max - v)\n        area_22 = (u - u_min) * (v - v_min)\n\n        area_11 = np.expand_dims(area_11, -1)\n        area_12 = np.expand_dims(area_12, -1)\n        area_21 = np.expand_dims(area_21, -1)\n        area_22 = np.expand_dims(area_22, -1)\n\n\n        colors_11 = textureImage[v_min, u_min]\n        colors_12 = textureImage[v_max, u_min]\n        colors_21 = textureImage[v_min, u_max]\n        colors_22 = textureImage[v_max, u_max]\n\n        alphas_11 = alphaMask[v_min, u_min]\n        alphas_12 = alphaMask[v_max, u_min]\n        alphas_21 = alphaMask[v_min, u_max]\n        alphas_22 = alphaMask[v_max, u_max]\n\n        colors = colors_11 * area_11 + colors_12 * area_12 + colors_21 * area_21 + colors_22 * area_22\n        alphas = alphas_11 * area_11 + alphas_12 * area_12 + alphas_21 * area_21 + alphas_22 * area_22\n\n        resultImage[rectangleIndices] = resultImage[rectangleIndices] * (1 - alphas) + colors * alphas\n\n        distanceOffset += np.linalg.norm(point_2 - point_1)\n        print(point_1, point_2)\n        print(direction_u)\n        print(direction_v)\n        cv2.imwrite(\'test/result.png\', resultImage.reshape(image.shape))\n        exit(1)\n        continue\n    return\n\n\ndef addRuler(folder, indexOffset, image, depth, planes, segmentation, info, startPoint, endPoint, boundaryPoints, startPlaneIndex, fixedEndPoint=False, numFrames=1):\n    width = segmentation.shape[1]\n    height = segmentation.shape[0]\n\n    #info[0] -= 40\n    #info[5] -= 40\n\n    camera = getCameraFromInfo(info)\n\n    planesD = np.linalg.norm(planes, axis=-1, keepdims=True)\n    planesNormal = planes / np.maximum(planesD, 1e-4)\n\n    textureImage = cv2.imread(\'../texture_images/ruler_36.png\')\n    alphaMask = np.ones((textureImage.shape[0], textureImage.shape[1], 1), dtype=np.float32)\n    #alphaMask = (textureImage.mean(2) < 224).astype(np.float32)\n    #alphaMask = np.expand_dims(alphaMask, -1)\n\n    #backgroundMask = cv2.erode(backgroundMask.astype(np.uint8), np.ones((3, 3)))\n    #cv2.imwrite(\'test/mask.png\', drawMaskImage(background))\n    #exit(1)\n\n    textureHeight = float(textureImage.shape[0])\n    textureWidth = float(textureImage.shape[1])\n    textureRatio = textureHeight / textureWidth\n    textureSizes2D = np.array([textureWidth, textureHeight])\n\n    #textureSizeU = 0.96\n    #textureSizeU = 0.3048\n    textureSizeU = 0.9144\n    #textureSizeU = 0.78\n    textureSizeV = textureSizeU * textureRatio\n    textureSizes = np.array([textureSizeU, textureSizeV])\n    #textureImage = cv2.imread(\'../textures/texture_2.jpg\')\n    #textureImage = cv2.resize(textureImage, (width, height), interpolation=cv2.INTER_LINEAR)\n\n\n    distances = np.linalg.norm(boundaryPoints - startPoint, axis=-1) + np.linalg.norm(boundaryPoints - endPoint, axis=-1)\n    boundaryPoint = boundaryPoints[np.argmin(distances)]\n\n    print(startPoint)\n    print(startPoint[0] / startPoint[1] * camera[\'fx\'] + camera[\'cx\'], -startPoint[2] / startPoint[1] * camera[\'fy\'] + camera[\'cy\'])\n    print(boundaryPoint)\n    print(boundaryPoint[0] / boundaryPoint[1] * camera[\'fx\'] + camera[\'cx\'], -boundaryPoint[2] / boundaryPoint[1] * camera[\'fy\'] + camera[\'cy\'])\n\n    boundaryPointNeighbors = boundaryPoints[np.linalg.norm(boundaryPoints - boundaryPoint, axis=-1) < 0.05]\n    boundaryDirections = []\n    for boundaryPointNeighbor in boundaryPointNeighbors:\n        boundaryDirection = boundaryPointNeighbor - boundaryPoint\n        norm = np.linalg.norm(boundaryDirection, axis=-1)\n        if norm < 1e-4:\n            continue\n        boundaryDirection /= norm\n        if np.dot(np.cross(boundaryPoint - startPoint, planesNormal[startPlaneIndex]), boundaryDirection) > 0:\n            boundaryDirections.append(boundaryDirection)\n        else:\n            boundaryDirections.append(-boundaryDirection)\n            pass\n        continue\n\n\n    if len(boundaryDirections) == 0:\n        distances = np.argmin(np.linalg.norm(boundaryPoints - boundaryPoint, axis=-1))\n        neighborIndex = np.argpartition(distances, 2)[1]\n        boundaryNeighbor = boundaryPoints[neighborIndex]\n        boundaryDirection = boundaryPointNeighbor - boundaryPoint\n        norm = np.linalg.norm(boundaryDirection, axis=-1)\n        boundaryDirection /= norm\n        boundaryDirections.append(boundaryDirection)\n        pass\n\n    boundaryDirections = np.array(boundaryDirections)\n\n    boundaryDirection = boundaryDirections.mean(0)\n    boundaryDirection /= np.linalg.norm(boundaryDirection)\n\n\n    boundaryNormal = np.cross(boundaryDirection, endPoint - boundaryPoint)\n    boundaryNormal /= np.linalg.norm(boundaryNormal)\n\n    totalLength = np.linalg.norm(endPoint - boundaryPoint) + np.linalg.norm(boundaryPoint - startPoint)\n    distanceOffset = 0\n\n    resultImage = image.copy().reshape((-1, 3))\n\n    camera = getCameraFromInfo(info)\n    #print(camera)\n    #print(\'total length\', totalLength, np.linalg.norm(endPoint - boundaryPoint), np.linalg.norm(boundaryPoint - startPoint))\n    #exit(1)\n    firstSegment = True\n\n    #IBL = IBL.reshape((width * height, -1))\n\n    for point_1, point_2, planeNormal in [(startPoint, boundaryPoint, planesNormal[startPlaneIndex]), (boundaryPoint, endPoint, boundaryNormal)]:\n        if point_1[0] == point_2[0] and point_1[1] == point_2[1]:\n            continue\n\n        #planeNormal = np.cross(endPoint - startPoint, verticalDirection)\n        #planeNormal = planeNormal / np.linalg.norm(planeNormal)\n        planeD = np.dot(point_1, planeNormal)\n\n        urange = (np.arange(width, dtype=np.float32) / width * camera[\'width\'] - camera[\'cx\']) / camera[\'fx\']\n        urange = urange.reshape(1, -1).repeat(height, 0)\n        vrange = (np.arange(height, dtype=np.float32) / height * camera[\'height\'] - camera[\'cy\']) / camera[\'fy\']\n        vrange = vrange.reshape(-1, 1).repeat(width, 1)\n\n        coef = urange * planeNormal[0] + planeNormal[1] + (-vrange) * planeNormal[2]\n        Y = planeD / coef\n        X = urange * Y\n        Z = -vrange * Y\n        XYZ = np.stack([X, Y, Z], axis=2)\n\n\n        direction_u = point_2 - point_1\n        direction_u = direction_u / np.maximum(np.linalg.norm(direction_u), 1e-4)\n        direction_v = -np.cross(planeNormal, direction_u)\n        direction_v = direction_v / np.maximum(np.linalg.norm(direction_v), 1e-4)\n\n\n        offset_v = np.dot(point_1, direction_v)\n\n        if firstSegment:\n            direction_u *= 0.6\n            #point_2 -= direction_u * 0.001\n            offset_v -= 0.002\n        else:\n            distanceOffset -= 0.02\n            pass\n\n        offset_u = np.dot(point_1, direction_u)\n\n        projection_u = np.tensordot(XYZ, direction_u, axes=([2], [0])).reshape(-1)\n        projection_v = np.tensordot(XYZ, direction_v, axes=([2], [0])).reshape(-1)\n\n\n        projection_u = (projection_u - offset_u + distanceOffset) / textureSizeU\n        projection_v = (projection_v - offset_v) / textureSizeV\n\n        # print(\'u\', projection_u[850 * width + 1050])\n        # print(\'u\', projection_u[958 * width + 1060])\n        # print(\'u\', projection_u[1064 * width + 1074])\n        # print(point_1, point_2, planeNormal)\n        # print(np.dot(planeNormal, point_2 - point_1))\n        # print(np.dot(point_1, planeNormal) - planeD, np.dot(point_2, planeNormal) - planeD)\n\n\n        for frameIndex in xrange(numFrames):\n            maxOffset = min(float(frameIndex + 1) / numFrames * totalLength, distanceOffset + np.linalg.norm(point_2 - point_1))\n            minOffset = max(float(frameIndex) / numFrames * totalLength, distanceOffset)\n            #print(minOffset, maxOffset)\n            if minOffset >= maxOffset:\n                continue\n\n            if firstSegment:\n                maxOffset = min(maxOffset, distanceOffset + np.linalg.norm(point_2 - point_1) - 0.018)\n                pass\n\n            rectangleMask = np.logical_and(np.logical_and(projection_u >= minOffset / textureSizeU, projection_u < maxOffset / textureSizeU), np.logical_and(projection_v >= 0, projection_v <= 1))\n\n            rectangleIndices = rectangleMask.nonzero()[0]\n\n            projections = np.stack([projection_u[rectangleIndices], projection_v[rectangleIndices]], axis=1)\n            uv = projections * textureSizes2D\n\n            uv[:, 1] = textureSizes2D[1] - 1 - uv[:, 1]\n            uv = np.maximum(np.minimum(uv, textureSizes2D - 1), 0)\n\n\n            u = uv[:, 0]\n            v = uv[:, 1]\n            u_min = np.floor(u).astype(np.int32)\n            u_max = np.ceil(u).astype(np.int32)\n            v_min = np.floor(v).astype(np.int32)\n            v_max = np.ceil(v).astype(np.int32)\n\n            area_11 = (u_max - u) * (v_max - v)\n            area_12 = (u_max - u) * (v - v_min)\n            area_21 = (u - u_min) * (v_max - v)\n            area_22 = (u - u_min) * (v - v_min)\n\n            area_11 = np.expand_dims(area_11, -1)\n            area_12 = np.expand_dims(area_12, -1)\n            area_21 = np.expand_dims(area_21, -1)\n            area_22 = np.expand_dims(area_22, -1)\n\n\n            colors_11 = textureImage[v_min, u_min]\n            colors_12 = textureImage[v_max, u_min]\n            colors_21 = textureImage[v_min, u_max]\n            colors_22 = textureImage[v_max, u_max]\n\n            alphas_11 = alphaMask[v_min, u_min]\n            alphas_12 = alphaMask[v_max, u_min]\n            alphas_21 = alphaMask[v_min, u_max]\n            alphas_22 = alphaMask[v_max, u_max]\n\n            colors = colors_11 * area_11 + colors_12 * area_12 + colors_21 * area_21 + colors_22 * area_22\n            alphas = alphas_11 * area_11 + alphas_12 * area_12 + alphas_21 * area_21 + alphas_22 * area_22\n\n\n            #print(np.expand_dims(IBL[rectangleIndices], -1))\n\n            resultImage[rectangleIndices] = np.minimum(resultImage[rectangleIndices] * (1 - alphas) + colors * alphas, 255).astype(np.uint8)\n            cv2.imwrite(folder + (\'/%04d.png\' % (indexOffset + frameIndex)), resultImage.reshape(image.shape))\n            continue\n\n        distanceOffset += np.linalg.norm(point_2 - point_1)\n        #print(point_1, point_2)\n        #print(direction_u)\n        #print(direction_v)\n        firstSegment = False\n\n        continue\n    return\n\ndef addRulerComplete(folder, indexOffset, image, depth, planes, segmentation, info, startPixel, endPixel, fixedEndPoint=False, numFrames=1):\n    width = segmentation.shape[1]\n    height = segmentation.shape[0]\n\n    #IBL = cv2.imread(\'../ibl_output/IMG_0103_IBL.exr\', -1)\n    # print(IBL.shape)\n    # print(IBL.max())\n    # print(IBL.min())\n    # print(IBL.dtype)\n    #IBL = cv2.resize(IBL, (width, height))\n    #exit(1)\n\n    #info[0] += 200\n    #info[5] += 200\n    #info[6] = height - info[6]\n\n    camera = getCameraFromInfo(info)\n\n\n    urange = (np.arange(width, dtype=np.float32) / width * camera[\'width\'] - camera[\'cx\']) / camera[\'fx\']\n    urange = urange.reshape(1, -1).repeat(height, 0)\n    vrange = (np.arange(height, dtype=np.float32) / height * camera[\'height\'] - camera[\'cy\']) / camera[\'fy\']\n    vrange = vrange.reshape(-1, 1).repeat(width, 1)\n    X = depth * urange\n    Y = depth\n    Z = -depth * vrange\n    XYZ = np.stack([X, Y, Z], axis=2)\n    #plane_depths = calcPlaneDepths(planes, width, height, info)\n\n    planesD = np.linalg.norm(planes, axis=-1, keepdims=True)\n    planesNormal = planes / np.maximum(planesD, 1e-4)\n\n    startPlaneIndex = segmentation[startPixel[1]][startPixel[0]]\n    endPlaneIndex = segmentation[endPixel[1]][endPixel[0]]\n    assert(startPlaneIndex < planes.shape[0] and endPlaneIndex < planes.shape[0])\n    startPoint = XYZ[startPixel[1]][startPixel[0]]\n    endPoint = XYZ[endPixel[1]][endPixel[0]]\n\n\n\n    mask = (segmentation == startPlaneIndex).astype(np.uint8)\n\n    boundary = mask - cv2.erode(mask, np.ones((3, 3), dtype=np.uint8))\n    boundaryPoints = XYZ[boundary.nonzero()]\n    boundaryPoints = boundaryPoints[boundaryPoints[:, 1] < startPoint[1]]\n\n    endPlane = planes[endPlaneIndex]\n    endPlaneD = np.linalg.norm(endPlane)\n    endPlaneNormal = endPlane / endPlaneD\n    endDistances = endPlaneD - np.tensordot(boundaryPoints, endPlaneNormal, axes=(1, 0))\n    distances = np.linalg.norm(boundaryPoints - startPoint, axis=-1) + np.abs(endDistances)\n    boundaryPointIndex = np.argmin(distances)\n    boundaryPoint = boundaryPoints[boundaryPointIndex]\n    endDistance = endDistances[boundaryPointIndex]\n    #finalEndPoint = boundaryPoint + endDistance * endPlaneNormal\n    #finalEndPoint = boundaryPoint + 0.30 * planesNormal[startPlaneIndex]\n    finalEndPoint = endPoint\n\n    print(\'points\', startPoint, boundaryPoint, endPoint)\n    print(startPoint[0] / startPoint[1] * camera[\'fx\'] + camera[\'cx\'], -startPoint[2] / startPoint[1] * camera[\'fy\'] + camera[\'cy\'])\n    print(boundaryPoint[0] / boundaryPoint[1] * camera[\'fx\'] + camera[\'cx\'], -boundaryPoint[2] / boundaryPoint[1] * camera[\'fy\'] + camera[\'cy\'])\n    print(finalEndPoint)\n    print(finalEndPoint[0] / finalEndPoint[1] * camera[\'fx\'] + camera[\'cx\'], -finalEndPoint[2] / finalEndPoint[1] * camera[\'fy\'] + camera[\'cy\'])\n\n    print(np.dot(planesNormal[startPlaneIndex], boundaryPoint - startPoint))\n    print(startPlaneIndex, endPlaneIndex)\n    print(planes)\n    print(planesNormal[startPlaneIndex])\n    print(planesD)\n    #exit(1)\n\n    #exit(1)\n    #numExtendingFrames = 1000\n    #numAdjustFrames = 100\n    numExtendingFrames = 200\n    numAdjustFrames = 0\n    addRuler(folder, 0, image, depth, planes, segmentation, info, startPoint, endPoint, boundaryPoints, startPlaneIndex=startPlaneIndex, fixedEndPoint=True, numFrames=numExtendingFrames)\n\n    for frameIndex in xrange(numAdjustFrames):\n        newEndPoint = endPoint + (finalEndPoint - endPoint) * (frameIndex + 1) / numAdjustFrames\n        addRuler(folder, numExtendingFrames + frameIndex, image, depth, planes, segmentation, info, startPoint, newEndPoint, boundaryPoints, startPlaneIndex=startPlaneIndex, fixedEndPoint=True, numFrames=1)\n        continue\n    return\n\n\ndef writeGridImage(image_list, width, height, gridSize):\n    gridImage = np.zeros((height, width, 3))\n    gapX = 0.1\n    gapBetween = 0.08\n    imageWidth = float(width) / (gridSize[0] * 2 + gridSize[0] * gapBetween + (gridSize[0] + 1) * gapX)\n    gapX *= imageWidth\n    gapBetween *= imageWidth\n\n    imageHeight = imageWidth * 3 / 4\n\n    imageWidth = int(round(imageWidth))\n    imageHeight = int(round(imageHeight))\n    gapX = int(round(gapX))\n    gapBetween = int(round(gapBetween))\n    gapY = int(round(float(height - imageHeight * gridSize[1]) / (gridSize[1] + 1)))\n\n    for gridY in xrange(gridSize[1]):\n        for gridX in xrange(gridSize[0]):\n            image_filename = image_list[gridY * gridSize[0] + gridX]\n            image = cv2.imread(image_filename)\n            image = cv2.resize(image, (imageWidth, imageHeight))\n            offsetY = gapY * (gridY + 1) + imageHeight * gridY\n            offsetX = gapX * (gridX + 1) + imageWidth * gridX * 2 + gapBetween * gridX\n            gridImage[offsetY:offsetY + imageHeight, offsetX:offsetX + imageWidth] = image\n\n            segmentation_filename = image_filename.replace(\'image\', \'segmentation_pred_blended_0\')\n            segmentation = cv2.imread(segmentation_filename)\n            segmentation = cv2.resize(segmentation, (imageWidth, imageHeight))\n\n            offsetX = gapX * (gridX + 1) + imageWidth * gridX * 2 + gapBetween * gridX + imageWidth + gapBetween\n            print(offsetX, imageWidth)\n            gridImage[offsetY:offsetY + imageHeight, offsetX:offsetX + imageWidth] = segmentation\n            continue\n        continue\n    return gridImage\n\ndef normal2CameraAngles(normal):\n    normal *= -1\n    towards = np.array([0, 1, 0])\n    up = np.array([0, normal[1], normal[2]])\n    beta = np.rad2deg(np.arccos(np.dot(up, towards) / np.maximum(np.linalg.norm(up), 1e-4))) - 90\n    theta = np.rad2deg(np.arcsin(normal[0]))\n    print([0, beta, theta])\n    return\n\nif __name__ == \'__main__\':\n    normal2CameraAngles(np.array([0.06, 0.35, -0.93]))\n'"
code/utils_backup.py,31,"b'import numpy as np\nimport PIL.Image\nimport copy\nimport sys\nimport os\nimport cv2\nimport scipy.ndimage as ndimage\n#import pydensecrf.densecrf as dcrf\n#from pydensecrf.utils import compute_unary, create_pairwise_bilateral, \\\n\t#create_pairwise_gaussian, unary_from_softmax\nfrom skimage import segmentation\n#from skimage.future import graph\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n#from layers import PlaneDepthLayer\n#from layers import PlaneNormalLayer\n#from html import HTML\n\nclass ColorPalette:\n\tdef __init__(self, numColors):\n\t\tnp.random.seed(1)\n\t\tself.colorMap = np.random.randint(255, size = (numColors, 3))\n\t\tself.colorMap[0] = 0\n\t\treturn\n\n\tdef getColorMap(self):\n\t\treturn self.colorMap\n\t\n\tdef getColor(self, index):\n\t\tif index >= colorMap.shape[0]:\n\t\t\treturn np.random.randint(255, size = (3))\n\t\telse:\n\t\t\treturn self.colorMap[index]\n\t\t\tpass\n\t\t\n\ndef getNYURGBDCamera():\n    camera = {}\n\tcamera[\'fx\'] = 5.1885790117450188e+02\n\tcamera[\'fy\'] = 5.1946961112127485e+02\n\tcamera[\'cx\'] = 3.2558244941119034e+02 - 40\n\tcamera[\'cy\'] = 2.5373616633400465e+02 - 44\n\tcamera[\'width\'] = 560\n\tcamera[\'height\'] = 426\n\treturn camera\n\ndef writePointCloud(filename, pointCloud, color = [255, 255, 255]):\n\twith open(filename, \'w\') as f:\n\t\theader = """"""ply\nformat ascii 1.0\nelement vertex """"""\n\t\theader += str(pointCloud.shape[0])\n\t\theader += """"""\nproperty float x\nproperty float y\nproperty float z\nproperty uchar red\t\t\t\t\t\t\t\t\t { start of vertex color }\nproperty uchar green\nproperty uchar blue\nend_header\n""""""\n\t\tf.write(header)\n\t\tfor point in pointCloud:\n\t\t\tfor value in point:\n\t\t\t\tf.write(str(value) + \' \')\n\t\t\t\tcontinue\n\t\t\tfor value in color:\n\t\t\t\tf.write(str(value) + \' \')\n\t\t\t\tcontinue\n\t\t\tf.write(\'\\n\')\n\t\t\tcontinue\n\t\tf.close()\n\t\tpass\n\treturn\n\n\ndef writeClusteringPointCloud(filename, pointCloud, clusters):\n\twith open(filename, \'w\') as f:\n\t\theader = """"""ply\nformat ascii 1.0\nelement vertex """"""\n\t\theader += str(pointCloud.shape[0])\n\t\theader += """"""\nproperty float x\nproperty float y\nproperty float z\nproperty uchar red\t\t\t\t\t\t\t\t\t { start of vertex color }\nproperty uchar green\nproperty uchar blue\nend_header\n""""""\n\t\tcolorMap = np.random.randint(255, size = clusters.shape)\n\t\tassignment = np.argmin(np.linalg.norm(pointCloud.reshape(-1, 1, 3).repeat(clusters.shape[0], 1)[:] - clusters, 2, 2), 1)\n\t\tf.write(header)\n\t\tfor pointIndex, point in enumerate(pointCloud):\n\t\t\tfor value in point:\n\t\t\t\tf.write(str(value) + \' \')\n\t\t\t\tcontinue\n\t\t\tcolor = colorMap[assignment[pointIndex]]\n\t\t\tfor value in color:\n\t\t\t\tf.write(str(value) + \' \')\n\t\t\t\tcontinue\n\t\t\tf.write(\'\\n\')\n\t\t\tcontinue\n\t\tf.close()\n\t\tpass\n\treturn\n\n\ndef writeNearestNeighbors(filename, pointCloudSource, pointCloudTarget):\n\twith open(filename, \'w\') as f:\n\t\theader = """"""ply\nformat ascii 1.0\nelement vertex """"""\n\t\theader += str((pointCloudSource.shape[0] + pointCloudTarget.shape[0] + pointCloudSource.shape[0]) * 4)\n\t\theader += """"""\nproperty float x\nproperty float y\nproperty float z\nproperty uchar red\nproperty uchar green\nproperty uchar blue\nelement face """"""\n\t\theader += str(pointCloudSource.shape[0] + pointCloudTarget.shape[0] + pointCloudSource.shape[0])\n\t\theader += """"""\nproperty list uchar int vertex_index\nend_header\n""""""\n\t\tf.write(header)\n\t\t\n\t\tsourceColor = [0, 255, 0]\n\t\ttargetColor = [0, 0, 255]\n\t\tcolorMap = np.random.randint(255, size = pointCloudSource.shape)\n\t\t\n\t\t# for pointIndex, point in enumerate(pointCloudSource):\n\t\t#\t for value in point:\n\t\t#\t\t f.write(str(value) + \' \')\n\t\t#\t\t continue\n\t\t#\t color = sourceColor\n\t\t#\t for value in color:\n\t\t#\t\t f.write(str(value) + \' \')\n\t\t#\t\t continue\n\t\t#\t f.write(\'\\n\')\n\t\t#\t continue\n\n\t\t# for pointIndex, point in enumerate(pointCloudTarget):\n\t\t#\t for value in point:\n\t\t#\t\t f.write(str(value) + \' \')\n\t\t#\t\t continue\n\t\t#\t color = targetColor\n\t\t#\t for value in color:\n\t\t#\t\t f.write(str(value) + \' \')\n\t\t#\t\t continue\n\t\t#\t f.write(\'\\n\')\n\t\t#\t continue\t\t\n\n\t\tplaneSize = 0.1\n\t\tfor planeType, planes in enumerate([pointCloudSource, pointCloudTarget]):\n\t\t\tfor planeIndex, plane in enumerate(planes):\n\t\t\t\tplaneD = np.linalg.norm(plane)\n\t\t\t\tplaneNormal = -plane / planeD\n\n\t\t\t\tmaxNormalDim = np.argmax(np.abs(plane))\n\t\t\t\tallDims = [0, 1, 2]\n\t\t\t\tallDims.remove(maxNormalDim)\n\t\t\t\tdim_1, dim_2 = allDims\n\t\t\t\tfor delta_1, delta_2 in [(-planeSize, -planeSize), (planeSize, -planeSize), (planeSize, planeSize), (-planeSize, planeSize)]:\n\t\t\t\t\tpoint = copy.deepcopy(plane)\n\t\t\t\t\tpoint[dim_1] += delta_1\n\t\t\t\t\tpoint[dim_2] += delta_2\n\t\t\t\t\tpoint[maxNormalDim] = (-planeD - planeNormal[dim_1] * point[dim_1] - planeNormal[dim_2] * point[dim_2]) / planeNormal[maxNormalDim]\n\n\t\t\t\t\tfor value in point:\n\t\t\t\t\t\tf.write(str(value) + \' \')\n\t\t\t\t\t\tcontinue\n\t\t\t\t\tif planeType == 0:\n\t\t\t\t\t\tcolor = sourceColor\n\t\t\t\t\telse:\n\t\t\t\t\t\tcolor = targetColor\n\t\t\t\t\t\tpass\n\t\t\t\t\t\n\t\t\t\t\tfor value in color:\n\t\t\t\t\t\tf.write(str(value) + \' \')\n\t\t\t\t\t\tcontinue\n\t\t\t\t\tf.write(\'\\n\')\n\t\t\t\t\tcontinue\n\t\t\t\tcontinue\n\t\t\tcontinue\n\n\t\tassignment = np.argmin(np.linalg.norm(pointCloudSource.reshape(-1, 1, 3).repeat(pointCloudTarget.shape[0], 1)[:] - pointCloudTarget, 2, 2), 1)\n\n\t\tplaneSize = 0.01\n\t\tlineColor = [255, 0, 0]\n\t\tfor planeIndex, planeSource in enumerate(pointCloudSource):\n\t\t\tplaneD = np.linalg.norm(planeSource)\n\t\t\tplaneNormal = -planeSource / planeD\t\t\t\n\n\t\t\tmaxNormalDim = np.argmax(np.abs(planeSource))\n\t\t\tallDims = [0, 1, 2]\n\t\t\tallDims.remove(maxNormalDim)\n\t\t\tdim_1, dim_2 = allDims\n\t\t\tminNormalDim = np.argmin(np.abs(planeSource))\n\n\t\t\tfor delta in [-planeSize, planeSize]:\n\t\t\t\tpoint = copy.deepcopy(planeSource)\n\t\t\t\tpoint[minNormalDim] += delta\n\t\t\t\tpoint[maxNormalDim] = (-planeD - planeNormal[dim_1] * point[dim_1] - planeNormal[dim_2] * point[dim_2]) / planeNormal[maxNormalDim]\n\t\t\t\tfor value in point:\n\t\t\t\t\tf.write(str(value) + \' \')\n\t\t\t\t\tcontinue\n\t\t\t\tcolor = lineColor\n\t\t\t\tfor value in color:\n\t\t\t\t\tf.write(str(value) + \' \')\n\t\t\t\t\tcontinue\n\t\t\t\tf.write(\'\\n\')\n\t\t\t\tcontinue\n\n\t\t\tplaneTarget = pointCloudTarget[assignment[planeIndex]]\n\t\t\tplaneDTarget = np.linalg.norm(plane)\n\t\t\tplaneNormalTarget = -plane / planeD\n\t\t\tplaneD = np.linalg.norm(planeTarget)\n\t\t\tplaneNormal = -planeTarget / planeD\t\t\t\n\n\t\t\tfor delta in [planeSize, -planeSize]:\n\t\t\t\tpoint = copy.deepcopy(planeTarget)\n\t\t\t\tpoint[minNormalDim] += delta\n\t\t\t\tpoint[maxNormalDim] = (-planeD - planeNormal[dim_1] * point[dim_1] - planeNormal[dim_2] * point[dim_2]) / planeNormal[maxNormalDim]\n\t\t\t\tfor value in point:\n\t\t\t\t\tf.write(str(value) + \' \')\n\t\t\t\t\tcontinue\n\t\t\t\tcolor = lineColor\n\t\t\t\tfor value in color:\n\t\t\t\t\tf.write(str(value) + \' \')\n\t\t\t\t\tcontinue\n\t\t\t\tf.write(\'\\n\')\n\t\t\t\tcontinue\n\t\t\tcontinue\n\n\t\tfor index in xrange(pointCloudSource.shape[0] + pointCloudTarget.shape[0] + pointCloudSource.shape[0]):\n\t\t\tplaneIndex = index * 4\n\t\t\tf.write(\'4 \' + str(planeIndex + 0) + \' \' + str(planeIndex + 1) + \' \' + str(planeIndex + 2) + \' \' + str(planeIndex + 3) + \'\\n\')\n\t\t\tcontinue\n\n\t\t# for pointIndexSource, point in enumerate(pointCloudSource):\n\t#\t pointIndexTarget = assignment[pointIndexSource]\n#\t f.write(str(pointIndexSource) + \' \' + str(pointIndexTarget + pointCloudSource.shape[0]) + \' \')\n\t\t#\t color = colorMap[pointIndexSource]\n\t#\t for value in color:\n#\t\t f.write(str(value) + \' \')\n\t\t#\t\t continue\n\t#\t f.write(\'\\n\')\n#\t continue\n\n\n\t\tf.close()\n\t\tpass\n\treturn\n\n\ndef evaluatePlanes(planes, filename = None, depths = None, normals = None, invalidMask = None, outputFolder = None, outputIndex = 0, colorMap = None):\n\tif filename != None:\n\t\tif \'mlt\' not in filename:\n\t\t\tfilename = filename.replace(\'color\', \'mlt\')\n\t\t\tpass\n\t\tnormalFilename = filename.replace(\'mlt\', \'norm_camera\')\n\t\tnormals = np.array(PIL.Image.open(normalFilename)).astype(np.float) / 255 * 2 - 1\n\t\tnorm = np.linalg.norm(normals, 2, 2)\n\t\tfor c in xrange(3):\n\t\t\tnormals[:, :, c] /= norm\n\t\t\tcontinue\n\t\t\n\t\tdepthFilename = filename.replace(\'mlt\', \'depth\')\n\t\tdepths = np.array(PIL.Image.open(depthFilename)).astype(np.float) / 1000\n\t\t# if len(depths.shape) == 3:\n\t\t#\t depths = depths.mean(2)\n\t\t#\t pass\n\t\tmaskFilename = filename.replace(\'mlt\', \'valid\')\t\n\t\tinvalidMask = np.array(PIL.Image.open(maskFilename))\n\t\tinvalidMask = invalidMask < 128\n\t\tinvalidMask += depths > 10\n\t\tpass\n\n\theight = normals.shape[0]\n\twidth = normals.shape[1]\n\tfocalLength = 517.97\n\turange = np.arange(width).reshape(1, -1).repeat(height, 0) - width * 0.5\n\tvrange = np.arange(height).reshape(-1, 1).repeat(width, 1) - height * 0.5\n\tranges = np.array([urange / focalLength, np.ones(urange.shape), -vrange / focalLength]).transpose([1, 2, 0])\n\t\n\tX = depths / focalLength * urange\n\tY = depths\n\tZ = -depths / focalLength * vrange\n\td = -(normals[:, :, 0] * X + normals[:, :, 1] * Y + normals[:, :, 2] * Z)\t\n\n\n\tnormalDotThreshold = np.cos(np.deg2rad(30))\n\tdistanceThreshold = 50000\n\t\n\treconstructedNormals = np.zeros(normals.shape)\n\treconstructedDepths = np.zeros(depths.shape)\n\tsegmentationImage = np.zeros((height, width, 3))\n\tdistanceMap = np.ones((height, width)) * distanceThreshold\n\toccupancyMask = np.zeros((height, width)).astype(np.bool)\n\tsegmentationTest = np.zeros((height, width))\n\ty = 297\n\tx = 540\n\tfor planeIndex, plane in enumerate(planes):\n\t\tplaneD = np.linalg.norm(plane)\n\t\tplaneNormal = -plane / planeD\n\n\t\tnormalXYZ = np.dot(ranges, planeNormal)\n\t\tnormalXYZ = np.reciprocal(normalXYZ)\n\t\tplaneY = -normalXYZ * planeD\n\n\t\tdistance = np.abs(planeNormal[0] * X + planeNormal[1] * Y + planeNormal[2] * Z + planeD) / np.abs(np.dot(normals, planeNormal))\n\t\t#distance = np.abs(planeY - depths)\n\t\t\n\t\tmask = (distance < distanceMap) * (planeY > 0) * (np.abs(np.dot(normals, planeNormal)) > normalDotThreshold) * (np.abs(planeY - depths) < 0.5)\n\t\toccupancyMask += mask\n\t\t\n\t\treconstructedNormals[mask] = planeNormal\n\t\t\n\t\t\n\t\t#if planeNormal[2] > 0.9:\n\t\t#print(planeD)\n\t\t#print(planeNormal)\n\t\t# minDepth = depths.min()\n\t\t# maxDepth = depths.max()\n\t\t# print(depths[300][300])\n\t\t# print(planeY[300][300])\n\t\t# print(depths[350][350])\n\t\t# print(planeY[350][350])\n\t\t# PIL.Image.fromarray((np.maximum(np.minimum((planeY - minDepth) / (maxDepth - minDepth), 1), 0) * 255).astype(np.uint8)).save(outputFolder + \'/plane.png\')\n\t\t# exit(1)\n\t\t#pass\n\t\treconstructedDepths[mask] = planeY[mask]\n\t\tif colorMap != None and planeIndex in colorMap:\n\t\t\tsegmentationImage[mask] = colorMap[planeIndex]\n\t\telse:\n\t\t\tsegmentationImage[mask] = np.random.randint(255, size=(3,))\n\t\t\tpass\n\t\tdistanceMap[mask] = distance[mask]\n\t\tsegmentationTest[mask] = planeIndex + 1\n\t\t#print((planeIndex, planeY[y][x], distance[y][x], np.abs(np.dot(normals, planeNormal))[y][x]))\n\t\tcontinue\n\n\t# print(distanceMap.mean())\n# print(distanceMap.max())\n\t# print(np.abs(reconstructedDepths - depths)[occupancyMask].max())\n# print(pow(reconstructedDepths - depths, 2)[True - invalidMask].mean())\n\t# exit(1)\n\n\t# planeIndex = segmentationTest[y][x]\n# print(normals[y][x])\n\t# plane = planes[int(planeIndex)]\n# planeD = np.linalg.norm(plane)\n\t# planeNormal = -plane / planeD\n# print((planeNormal, planeD))\n\t# print(depths[y][x])\n# print(reconstructedDepths[y][x])\n\t# print(segmentationTest[y][x])\n\n\tif outputFolder != None:\n\t\tdepths[invalidMask] = 0\n\t\tnormals[invalidMask] = 0\n\t\treconstructedDepths[invalidMask] = 0\n\t\treconstructedNormals[invalidMask] = 0\n\t\tminDepth = depths.min()\n\t\tmaxDepth = depths.max()\n\t\t#print(minDepth)\n\t\t#print(maxDepth)\n\t\tPIL.Image.fromarray(((depths - minDepth) / (maxDepth - minDepth) * 255).astype(np.uint8)).save(outputFolder + \'/\' + str(outputIndex) + \'_depth.png\')\n\t\tPIL.Image.fromarray((np.maximum(np.minimum((reconstructedDepths - minDepth) / (maxDepth - minDepth), 1), 0) * 255).astype(np.uint8)).save(outputFolder + \'/\' + str(outputIndex) + \'_depth_reconstructed.png\')\n\t\t#PIL.Image.fromarray((np.maximum(np.minimum((reconstructedDepths - depths) / (distanceThreshold), 1), 0) * 255).astype(np.uint8)).save(outputFolder + \'/depth_\' + str(outputIndex) + \'_diff.png\')\n\t\tPIL.Image.fromarray(((normals + 1) / 2 * 255).astype(np.uint8)).save(outputFolder + \'/\' + str(outputIndex) + \'_normal_.png\')\n\t\tPIL.Image.fromarray(((reconstructedNormals + 1) / 2 * 255).astype(np.uint8)).save(outputFolder + \'/\' + str(outputIndex) + \'_normal_reconstructed.png\')\n\t\tPIL.Image.fromarray(segmentationImage.astype(np.uint8)).save(outputFolder + \'/\' + str(outputIndex) + \'_plane_segmentation.png\')\n\t\t#depthImage = ((depths - minDepth) / (maxDepth - minDepth) * 255).astype(np.uint8)\n\t\t#PIL.Image.fromarray((invalidMask * 255).astype(np.uint8)).save(outputFolder + \'/mask.png\')\n\t\t#exit(1)\n\telse:\n\t\toccupancy = (occupancyMask > 0.5).astype(np.float32).sum() / (1 - invalidMask).sum()\n\t\tinvalidMask += np.invert(occupancyMask)\n\t\t#PIL.Image.fromarray(invalidMask.astype(np.uint8) * 255).save(outputFolder + \'/mask.png\')\n\t\treconstructedDepths = np.maximum(np.minimum(reconstructedDepths, 10), 0)\n\t\tdepthError = pow(reconstructedDepths - depths, 2)[np.invert(invalidMask)].mean()\n\t\t#depthError = distanceMap.mean()\n\t\tnormalError = np.arccos(np.maximum(np.minimum(np.sum(reconstructedNormals * normals, 2), 1), -1))[np.invert(invalidMask)].mean()\n\t\t#normalError = pow(np.linalg.norm(reconstructedNormals - normals, 2, 2), 2)[True - invalidMask].mean()\n\t\t#print((depthError, normalError, occupancy))\n\t\t# print(depths.max())\n\t\t# print(depths.min())\n\t\t# print(reconstructedDepths.max())\n\t\t# print(reconstructedDepths.min())\n\t\t# print(occupancy)\n\t\t# exit(1)\n\t\t\n\t\t#reconstructedDepths[np.invert(occupancyMask)] = depths[np.invert(occupancyMask)]\n\t\treturn depthError, normalError, occupancy, segmentationTest, reconstructedDepths, occupancyMask\n\treturn\n\n\ndef evaluatePlanesSeparately(planes, filename, outputFolder = None, outputIndex = 0):\n\tif \'mlt\' not in filename:\n\t\tfilename = filename.replace(\'color\', \'mlt\')\n\t\tpass\n\tcolorImage = np.array(PIL.Image.open(filename))\n\tnormalFilename = filename.replace(\'mlt\', \'norm_camera\')\n\tnormals = np.array(PIL.Image.open(normalFilename)).astype(np.float) / 255 * 2 - 1\n\theight = normals.shape[0]\n\twidth = normals.shape[1]\n\tnorm = np.linalg.norm(normals, 2, 2)\n\tfor c in xrange(3):\n\t\tnormals[:, :, c] /= norm\n\t\tcontinue\n\n\t\n\tdepthFilename = filename.replace(\'mlt\', \'depth\')\n\tdepths = np.array(PIL.Image.open(depthFilename)).astype(np.float) / 1000\n\t# if len(depths.shape) == 3:\n\t#\t depths = depths.mean(2)\n\t#\t pass\n\t\n\tfocalLength = 517.97\n\turange = np.arange(width).reshape(1, -1).repeat(height, 0) - width * 0.5\n\tvrange = np.arange(height).reshape(-1, 1).repeat(width, 1) - height * 0.5\n\tranges = np.array([urange / focalLength, np.ones(urange.shape), -vrange / focalLength]).transpose([1, 2, 0])\n\tX = depths / focalLength * urange\n\tY = depths\n\tZ = -depths / focalLength * vrange\n\td = -(normals[:, :, 0] * X + normals[:, :, 1] * Y + normals[:, :, 2] * Z)\n\n\t\n\tmaskFilename = filename.replace(\'mlt\', \'valid\')\t\n\tinvalidMask = np.array(PIL.Image.open(maskFilename))\n\t# if len(invalidMask.shape) == 3:\n\t#\t invalidMask = invalidMask.mean(2)\n\t#\t pass\n\tinvalidMask = invalidMask < 128\n\tinvalidMask += depths > 10\n\n\n\tnormalDotThreshold = np.cos(np.deg2rad(15))\n\tdistanceThreshold = 0.15\n\tcolorPalette = ColorPalette(len(planes))\n\tfor planeIndex, plane in enumerate(planes):\n\t\tplaneD = np.linalg.norm(plane)\n\t\tplaneNormal = -plane / planeD\n\n\t\tdistance = np.abs(planeNormal[0] * X + planeNormal[1] * Y + planeNormal[2] * Z + planeD)\n\n\t\tnormalXYZ = np.dot(ranges, planeNormal)\n\t\tnormalXYZ = np.reciprocal(normalXYZ)\n\t\tplaneY = -normalXYZ * planeD\n\t\t\n\t\tmask = (planeY > 0) * (np.abs(np.dot(normals, planeNormal)) > normalDotThreshold) * (distance < distanceThreshold)\n\n\t\tmaxDepth = 10\n\t\tminDepth = 0\n\t\t#PIL.Image.fromarray((np.minimum(np.maximum((planeY - minDepth) / (maxDepth - minDepth), 0), 1) * 255).astype(np.uint8)).save(outputFolder + \'/plane_depth_\' + str(planeIndex) + \'.png\')\n\t\t#PIL.Image.fromarray(((planeNormal.reshape(1, 1, 3).repeat(height, 0).repeat(width, 1) + 1) / 2 * 255).astype(np.uint8)).save(outputFolder + \'/plane_normal_\' + str(planeIndex) + \'.png\')\n\t\tplaneImage = colorImage * 0.3\n\t\tplaneImage[mask] += colorPalette.getColor(planeIndex) * 0.7\n\t\tPIL.Image.fromarray(planeImage.astype(np.uint8)).save(outputFolder + \'/plane_mask_\' + str(planeIndex) + \'_\' + str(outputIndex) + \'.png\')\n\t\t#PIL.Image.fromarray(mask.astype(np.uint8) * 255).save(outputFolder + \'/mask_\' + str(planeIndex) + \'.png\')\n\t\tcontinue\n\treturn\n\ndef residual2Planes(residualPlanes, predefinedPlanes):\n\tnumClusters = predefinedPlanes.shape[0]\n\tplanes = []\n\tfor residualPlane in residualPlanes:\n\t\tgridIndex = int(residualPlane[0]) / numClusters\n\t\tplaneIndex = int(residualPlane[0]) % numClusters\n\t\tplanes.append(predefinedPlanes[planeIndex] + residualPlane[1:])\n\t\tcontinue\n\treturn planes\n\ndef residual2PlanesGlobal(residualPlanes, predefinedPlanes):\n\tnumClusters = predefinedPlanes.shape[0]\n\tplanes = []\n\tfor residualPlane in residualPlanes:\n\t\tplaneIndex = int(residualPlane[0])\n\t\tplanes.append(predefinedPlanes[planeIndex] + residualPlane[1:])\n\t\tcontinue\n\treturn planes\n\n\ndef getPlaneInfo(planes):\n    imageWidth = 640\n\timageHeight = 480\n\tfocalLength = 517.97\n\turange = np.arange(imageWidth).reshape(1, -1).repeat(imageHeight, 0) - imageWidth * 0.5\n\tvrange = np.arange(imageHeight).reshape(-1, 1).repeat(imageWidth, 1) - imageHeight * 0.5\n\tranges = np.array([urange / focalLength, np.ones(urange.shape), -vrange / focalLength]).transpose([1, 2, 0])\n\t\n\tplaneDepths = PlaneDepthLayer(planes, ranges)\n\tplaneNormals = PlaneNormalLayer(planes, ranges)\n\treturn planeDepths, planeNormals\n\ndef getProbability(image, segmentation):\n    width = image.shape[1]\n\theight = image.shape[0]\n\tnumPlanes = segmentation.shape[0]\n\tprobabilities = np.exp(segmentation)\n\tprobabilities = probabilities / probabilities.sum(0)\n\t# The input should be the negative of the logarithm of probability values\n\t# Look up the definition of the softmax_to_unary for more information\n\tunary = unary_from_softmax(probabilities)\n\n\t# The inputs should be C-continious -- we are using Cython wrapper\n\tunary = np.ascontiguousarray(unary)\n\n\td = dcrf.DenseCRF(height * width, numPlanes)\n\t\n\td.setUnaryEnergy(unary)\n\n\t# This potential penalizes small pieces of segmentation that are\n\t# spatially isolated -- enforces more spatially consistent segmentations\n\t# feats = create_pairwise_gaussian(sdims=(10, 10), shape=(height, width))\n\t# d.addPairwiseEnergy(feats, compat=300,\n\t#\t\t\t\t\t\t\t\t\t\t kernel=dcrf.DIAG_KERNEL,\n\t#\t\t\t\t\t\t\t\t\t\t normalization=dcrf.NORMALIZE_SYMMETRIC)\n\n\t\t# This creates the color-dependent features --\n\t\t# because the segmentation that we get from CNN are too coarse\n\t\t# and we can use local color features to refine them\n\t\t\n\t\tfeats = create_pairwise_bilateral(sdims=(50, 50), schan=(20, 20, 20),\n\t\t\t\t\t\t\t\t\t\t  img=image, chdim=2)\n\t\td.addPairwiseEnergy(feats, compat=10,\n\t\t\t\t\t\t\tkernel=dcrf.DIAG_KERNEL,\n\t\t\t\t\t\t\tnormalization=dcrf.NORMALIZE_SYMMETRIC)\n\t\t\n\t\tQ = d.inference(50)\n\n\t\tinds = np.argmax(Q, axis=0).reshape((height, width))\n\t\tprobabilities = np.zeros((height * width, numPlanes))\n\t\tprobabilities[np.arange(height * width), inds.reshape(-1)] = 1\n\t\tprobabilities = probabilities.reshape([height, width, -1])\n\t\t#print(res.shape)\n\t\treturn probabilities\n\ndef getProbabilityMax(segmentation):\n\twidth = segmentation.shape[2]\n\theight = segmentation.shape[1]\n\tnumPlanes = segmentation.shape[0]\n\tinds = np.argmax(segmentation.reshape([-1, height * width]), axis=0)\n\tprobabilities = np.zeros((height * width, numPlanes))\n\tprobabilities[np.arange(height * width), inds] = 1\n\tprobabilities = probabilities.reshape([height, width, -1])\n\t\treturn probabilities\n\t\ndef evaluateSegmentation(testdir, image, depth, normal, segmentation, planes, resultIndex=0):\n\twidth = depth.shape[1]\n\theight = depth.shape[0]\n\tnumPlanes = planes.shape[0]\n\tplaneDepths, planeNormals = getPlaneInfo(planes)\n\tprobabilities_small = getProbabilityMax(segmentation)\n\tprobabilities = np.zeros(planeDepths.shape)\n\n\t\tfor index in xrange(probabilities.shape[2]):\n\t\t\tprobabilities[:, :, index] = cv2.resize(probabilities_small[:, :, index], (width, height), interpolation=cv2.INTER_LINEAR)\n\t\t\t\tcontinue\n\n\t\tdepthPred = (probabilities * planeDepths).sum(2)\n\t\tnormalPred = (probabilities.reshape([height, width, numPlanes, 1]).repeat(3, 3) * planeNormals).sum(2)\n\t\t#depthPred, normalPred = drawDepthNormal(depth.shape[1], depth.shape[0], segmentation, planes)\n\n\t\trandomColor = np.random.randint(255, size=(numPlanes, 3))\n\t\tcv2.imwrite(testdir + \'/\' + str(resultIndex) + \'_image.png\', image)\n\t\tcv2.imwrite(testdir + \'/\' + str(resultIndex) + \'_depth.png\', np.minimum(np.maximum(depth / 10 * 255, 0), 255).astype(np.uint8))\n\t\tcv2.imwrite(testdir + \'/\' + str(resultIndex) + \'_output_depth.png\', np.minimum(np.maximum(depthPred / 10 * 255, 0), 255).astype(np.uint8))\n\t\tcv2.imwrite(testdir + \'/\' + str(resultIndex) + \'_normal.png\', ((normal + 1) / 2 * 255).astype(np.uint8))\n\t\tcv2.imwrite(testdir + \'/\' + str(resultIndex) + \'_output_normal.png\', ((normalPred + 1) / 2 * 255).astype(np.uint8))\n\t\t#cv2.imwrite(testdir + \'/\' + str(resultIndex) + \'_segmentation.png\', np.dot(probabilities, randomColor).astype(np.uint8))\n\t\tcv2.imwrite(testdir + \'/\' + str(resultIndex) + \'_output_segmentation.png\', np.dot(probabilities, randomColor).astype(np.uint8))\n\n\t\treturn\n\tprobabilities_small = getProbability(cv2.resize(depth.reshape(height, width, 1).repeat(3, 2), (segmentation.shape[2], segmentation.shape[1])), segmentation)\n\tprobabilities = np.zeros(planeDepths.shape)\n\t\tfor index in xrange(probabilities.shape[2]):\n\t\t\tprobabilities[:, :, index] = cv2.resize(probabilities_small[:, :, index], (width, height), interpolation=cv2.INTER_LINEAR)\n\t\t\t\tcontinue\n\n\t\tdepthPred = (probabilities * planeDepths).sum(2)\n\t\tnormalPred = (probabilities.reshape([height, width, numPlanes, 1]).repeat(3, 3) * planeNormals).sum(2)\n\t\t#depthPred, normalPred = drawDepthNormal(depth.shape[1], depth.shape[0], segmentation, planes)\n\t\t\n\n\t\tcv2.imwrite(testdir + \'/\' + str(resultIndex) + \'_output_depth_mrf.png\', np.minimum(np.maximum(depthPred / 10 * 255, 0), 255).astype(np.uint8))\n\t\tcv2.imwrite(testdir + \'/\' + str(resultIndex) + \'_output_normal_mrf.png\', ((normalPred + 1) / 2 * 255).astype(np.uint8))\n\t\tcv2.imwrite(testdir + \'/\' + str(resultIndex) + \'_output_segmentation_mrf.png\', np.dot(probabilities, np.random.randint(255, size=(numPlanes, 3))).astype(np.uint8))\n\n\t\treturn\n\n\ndef calcPlaneInfo(im_name):\n\tnormalFilename = im_name[\'normal\']\n\tnormals = np.array(PIL.Image.open(normalFilename)).astype(np.float) / 255 * 2 - 1\n\tnorm = np.linalg.norm(normals, 2, 2)\n\t\tfor c in xrange(3):\n\t\t\tnormals[:, :, c] /= norm\n\t\t\t\tcontinue\n\t\t\twidth = normals.shape[1]\n\t\t\theight = normals.shape[0]\n\t\t\t\n\t\tmaskFilename = im_name[\'valid\']\n\t\tinvalidMask = (np.array(PIL.Image.open(maskFilename)) < 128)\n\n\t\tsampleRatio = 3\n\t\tazimuthAngleImage = (-np.round(np.rad2deg(np.arctan2(normals[:, :, 1], normals[:, :, 0])) / sampleRatio).astype(np.int) * sampleRatio + 360) % 360\n\n\t\taltitudeAngleImage = (np.round(np.rad2deg(np.arctan2(np.sign(-normals[:, :, 1]) * np.linalg.norm(normals[:, :, :2], 2, 2), normals[:, :, 2])) / sampleRatio).astype(np.int) * sampleRatio + 360) % 360\n\n\t\torthogonalThreshold = 5\n\t\torthogonalAzimuthMask_1 = ((azimuthAngleImage - 0) < orthogonalThreshold) + ((360 - azimuthAngleImage) < orthogonalThreshold)\n\t\torthogonalAzimuthMask_2 = np.abs(azimuthAngleImage - 180) < orthogonalThreshold\n\t\tazimuthAngleImage[orthogonalAzimuthMask_1] = 0\n\t\tazimuthAngleImage[orthogonalAzimuthMask_2] = 180\n\t\taltitudeAngleImage[orthogonalAzimuthMask_1 + orthogonalAzimuthMask_2] = 0\n\n\t\torthogonalAltitudeMask_1 = ((altitudeAngleImage - 0) < orthogonalThreshold) + ((360 - altitudeAngleImage) < orthogonalThreshold)\n\t\torthogonalAltitudeMask_2 = np.abs(altitudeAngleImage - 180) < orthogonalThreshold\n\t\taltitudeAngleImage[orthogonalAltitudeMask_1] = 0\n\t\taltitudeAngleImage[orthogonalAltitudeMask_2] = 180\n\t\tazimuthAngleImage[orthogonalAltitudeMask_1 + orthogonalAltitudeMask_2] = 0\n\n\t\tazimuthAngleImage[invalidMask] = 360\n\t\taltitudeAngleImage[invalidMask] = 360\n\t\t\n\t\t\n\t\tsampleRatio = 5\n\t\tdepthFilename = im_name[\'depth\']\n\t\tdepths = np.array(PIL.Image.open(depthFilename)).astype(np.float) / 1000\n\t\tfocalLength = 517.97\n\t\turange = np.arange(width).reshape(1, -1).repeat(height, 0) - width * 0.5\n\t\tvrange = np.arange(height).reshape(-1, 1).repeat(width, 1) - height * 0.5\n\t\tX = depths / focalLength * urange\n\t\tY = depths\n\t\tZ = -depths / focalLength * vrange\n\t\td = -(normals[:, :, 0] * X + normals[:, :, 1] * Y + normals[:, :, 2] * Z)\n\t\tdImage = np.round(d / (10. / 360) / sampleRatio).astype(np.int) * sampleRatio\n\t\tdImage[dImage < 0] = 0\n\t\tdImage[dImage > 360] = 360\n\t\tdImage[invalidMask] = 360\t\t\n\n\t\tvalueMaps = [azimuthAngleImage, altitudeAngleImage, dImage]\n\t\tplanes = []\n\t\tvalues_1, counts_1 = np.unique(valueMaps[0], return_counts=True)\n\n\t\tglobalMask = np.zeros((height, width), np.bool)\n\t\tplaneAreaThreshold = 40 * 30\n\t\tsegmentations = []\n\t\tfor index_1, value_1 in enumerate(values_1):\n\t\t\t\tif counts_1[index_1] < planeAreaThreshold or value_1 == 360:\n\t\t\t\t\t\tcontinue\n\t\t\t\t\tmask_1 = valueMaps[0] == value_1\n\n\t\t\t\tvalues_2, counts_2 = np.unique(valueMaps[1][mask_1], return_counts=True)\n\t\t\t\tfor index_2, value_2 in enumerate(values_2):\n\t\t\t\t\t\tif counts_2[index_2] < planeAreaThreshold or value_2 == 360:\n\t\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\t\tmask_2 = mask_1 * (valueMaps[1] == value_2)\n\t\t\t\t\t\t\tvalues_3, counts_3 = np.unique(valueMaps[2][mask_2], return_counts=True)\n\t\t\t\t\t\tfor index_3, value_3 in enumerate(values_3):\n\t\t\t\t\t\t\t\tif counts_3[index_3] < planeAreaThreshold or value_3 == 360:\n\t\t\t\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\t\t\t\tmask_3 = mask_2 * (valueMaps[2] == value_3)\n\t\t\t\t\t\t\t\t\tmask_3 = ndimage.binary_erosion(mask_3).astype(mask_3.dtype)\n\t\t\t\t\t\t\t\tif mask_3.sum() < planeAreaThreshold:\n\t\t\t\t\t\t\t\t\t\tcontinue\n\n\t\t\t\t\t\t\t\t# regionX = X[mask_3]\n\t\t\t\t\t\t\t# regionY = Y[mask_3]\n\t\t\t\t\t\t# regionZ = Y[mask_3]\n\t\t\t\t\t\n\t\t\t\t\t\t\t\tnormal = np.array([normals[:, :, 0][mask_3].mean(), normals[:, :, 1][mask_3].mean(), normals[:, :, 2][mask_3].mean()])\n\t\t\t\t\t\t\t\tnormal /= np.linalg.norm(normal, 2)\n\t\t\t\t\t\t\t\tdPlane = (-(normal[0] * X + normal[1] * Y + normal[2] * Z))[mask_3].mean()\n\n\t\t\t\t\t\t\t\tglobalMask += mask_3\n\t\t\t\t\t\t\t\tsegmentations.append(mask_3)\n\t\t\t\t\t\t\t\tazimuth = np.arctan2(-normal[1], normal[0])\n\t\t\t\t\t\t\t\taltitude = np.arctan2(np.sign(-normal[1]) * np.linalg.norm(normal[:2]), normal[2])\n\t\t\t\t\t\t\t\t#planes.append(((azimuth, altitude, dPlane), mask_3))\n\t\t\t\t\t\t\t\tplanes.append(((-normal[0] * dPlane, -normal[1] * dPlane, -normal[2] * dPlane), mask_3))\n\n\n\t\t\t\t\t\t\t\tif False:\n\t\t\t\t\t\t\t\t\tplane = np.array([-normal[0] * dPlane, -normal[1] * dPlane, -normal[2] * dPlane])\n\n\t\t\t\t\t\t\t\t\t\t#focalLength = 517.97\n\t\t\t\t\t\t\t\t\t\t#urange = np.arange(width).reshape(1, -1).repeat(height, 0) - width * 0.5\n\t\t\t\t\t\t\t\t\t\t#vrange = np.arange(height).reshape(-1, 1).repeat(width, 1) - height * 0.5\n\t\t\t\t\t\t\t\t\t\tranges = np.array([urange / focalLength / width * 640, np.ones(urange.shape), -vrange / focalLength / height * 480]).transpose([1, 2, 0])\n\n\t\t\t\t\t\t\t\t\t\t#ranges = np.stack([urange, np.ones([height, width]), -vrange], axis=2)\n\t\t\t\t\t\t\t\t\t\tranges = np.reshape(ranges, [-1, 3])\n\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\tplaneD = np.linalg.norm(plane)\n\t\t\t\t\t\t\t\t\t\t#planeD = np.clip(planeD, 1e-5, 10)\n\t\t\t\t\t\t\t\t\t\tplaneNormal = -plane / planeD\n\n\t\t\t\t\t\t\t\t\t\tnormalXYZ = np.matmul(ranges, planeNormal.reshape(3, 1))\n\t\t\t\t\t\t\t\t\t\t#normalXYZ = np.multiply(np.sign(normalXYZ), np.clip(np.abs(normalXYZ), 1e-4, 1000000))\n\t\t\t\t\t\t\t\t\t\tnormalXYZ[normalXYZ == 0] = 1e-5\n\t\t\t\t\t\t\t\t\t\tnormalXYZ = 1 / normalXYZ\n\t\t\t\t\t\t\t\t\t\tplaneDepth = -normalXYZ * planeD\n\t\t\t\t\t\t\t\t\t\tplaneDepth = np.reshape(planeDepth, [height, width])\n\n\t\t\t\t\t\t\t\t\t\tplaneDepth = np.clip(planeDepth, 0, 10)\n\t\t\t\t\t\t\t\t\t\tnormalDotThreshold = np.cos(np.deg2rad(15))\n\t\t\t\t\t\t\t\t\t\tdepthDiffThreshold = 0.1\n\t\t\t\t\t\t\t\t\t\t#print(planeDepth[mask_3])\n\t\t\t\t\t\t\t\t\t\t#print(depths[mask_3])\n\t\t\t\t\t\t\t\t\t\tmask = (np.abs(np.dot(normals, planeNormal)) > normalDotThreshold) * (np.abs(planeDepth - depths) < depthDiffThreshold)\n\t\t\t\t\t\t\t\t\t\t#mask = np.abs(np.dot(normals, planeNormal)) > normalDotThreshold\n\t\t\t\t\t\t\t\t\t\tcv2.imwrite(\'test_evaluate/segmentation_0_\' + str(len(planes) - 1) + \'_mask.png\', mask.astype(np.uint8) * 255)\n\t\t\t\t\t\t\t\t\t\tcv2.imwrite(\'test_evaluate/segmentation_0_\' + str(len(planes) - 1) + \'_mask_gt.png\', mask_3.astype(np.uint8) * 255)\n\t\t\t\t\t\t\t\t\t\t#exit(1)\n\t\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\tcontinue\n\t\t\t\tcontinue\n\t\t\tsegmentations = np.array(segmentations)\n\t\t\t\n\t\tif False:\n\t\t\tplaneParameters = np.array([plane[0] for plane in planes])\n\t\t\tplaneD = np.linalg.norm(planeParameters, 2, 1, keepdims=True)\n\t\t\tplaneNormals = planeParameters / planeD\n\t\t\t\n\t\t\t\tnormalXYZ = np.array([urange / focalLength, np.ones(urange.shape), -vrange / focalLength])\n\n\t\t\t\tnormalXYZ = np.dot(normalXYZ.transpose([1, 2, 0]), planeNormals.transpose())\n\t\t\t\tnormalXYZ = np.reciprocal(normalXYZ)\n\n\t\t\t\tXYZ = np.array([X, Y, Z])\n\t\t\t\tplaneXYZ = np.zeros(XYZ.shape)\n\t\t\t\tfor i in xrange(planeParameters.shape[0]):\n\t\t\t\t\tmask = planes[i][1]\n\t\t\t\t\tplaneY = normalXYZ[:, :, i] * planeD[i]\n\t\t\t\t\tplaneX = planeY * urange / focalLength\n\t\t\t\t\tplaneZ = -planeY * vrange / focalLength\n\n\t\t\t\t\t\tplaneXYZ[0][mask] = planeX[mask]\n\t\t\t\t\t\tplaneXYZ[1][mask] = planeY[mask]\n\t\t\t\t\t\tplaneXYZ[2][mask] = planeZ[mask]\n\t\t\t\t\t\tcontinue\n\n\t\t\t\t# for c in xrange(3):\n\t\t\t#\t\t inputImage = XYZ[c]\n\t\t#\t\t cMin = inputImage.min()\n\t#\t\t cMax = inputImage.max()\n#\t\t #PIL.Image.fromarray(((inputImage - cMin) / (cMax - cMin) * 255).astype(np.uint8)).save(\'test/\' + str(c) + \'.png\')\n\t\t\t\t#\t\t reconstructed = planeXYZ[c]\n\t\t\t#\t\t #PIL.Image.fromarray(((reconstructed - cMin) / (cMax - cMin) * 255).astype(np.uint8)).save(\'test/\' + str(c) + \'_reconstructed.png\')\n\t\t#\t\t continue\n\n\t\t\t\tplaneImage = np.zeros((height, width, 3))\n\t\t\t\tfor plane in planes:\n\t\t\t\t\tmask = plane[1]\n\t\t\t\t\t\tfor c in xrange(3):\n\t\t\t\t\t\t\tplaneImage[:, :, c][mask] = np.random.randint(0, 255)\n\t\t\t\t\t\t\t#planeImage[:, :, c][mask] = max(min(round((plane[0][c] + 1) / 2 * 255), 255), 0)\n\t\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\tcontinue\n\t\t\t\t\tcv2.imwrite(\'test_evaluate/plane_image.png\', cv2.imread(im_name[\'image\']))\n\t\t\t\t\tPIL.Image.fromarray(planeImage.astype(np.uint8)).save(\'test_evaluate/plane.png\')\n\t\t\t\t\tprint(planeParameters)\n\t\t\t\t\t#print(np.load(im_name[\'plane\'])[:, :3])\n\t\t\t\tpass\n\t\treturn globalMask, segmentations\n\t\n\ndef findCornerPoints(im_name, planes, segmentations = None):\n\timageWidth = 640\n\timageHeight = 480\n\tfocalLength = 517.97\n\turange = np.arange(imageWidth).reshape(1, -1).repeat(imageHeight, 0) - imageWidth * 0.5\n\tvrange = np.arange(imageHeight).reshape(-1, 1).repeat(imageWidth, 1) - imageHeight * 0.5\n\tranges = np.array([urange / focalLength, np.ones(urange.shape), -vrange / focalLength]).transpose([1, 2, 0])\n\t\n\n\t\tnormalFilename = im_name[\'normal\']\n\t\tnormal = np.array(PIL.Image.open(normalFilename)).astype(np.float) / 255 * 2 - 1\n\t\tnorm = np.linalg.norm(normal, 2, 2)\n\t\tfor c in xrange(3):\n\t\t\tnormal[:, :, c] /= norm\n\t\t\t\tcontinue\n\t\t\t\n\t\tmaskFilename = im_name[\'valid\']\n\t\tinvalidMask = (np.array(PIL.Image.open(maskFilename)) < 128)\n\n\t\tdepthFilename = im_name[\'depth\']\n\t\tdepth = np.array(PIL.Image.open(depthFilename)).astype(np.float) / 1000\n\t\tdepth = np.clip(depth, 0, 10)\n\t\t\n\t\tplaneDepths = PlaneDepthLayer(planes, ranges)\n\t\t\n\t\tdepthDiffThreshold = 0.15\n\t\toccludedRatioThreshold = 0.1\n\t\toccludedMasks = (planeDepths - np.expand_dims(depth, -1)) < -depthDiffThreshold\n\t\toccludedRatio = occludedMasks.astype(np.float).mean(0).mean(0)\n\t\tplaneCandidates = planes[occludedRatio < occludedRatioThreshold]\n\t\tplaneConfidence = 1 - occludedRatio[occludedRatio < occludedRatioThreshold]\n\t\tplaneCandidates = np.concatenate([planeCandidates, planeConfidence.reshape(-1, 1)], 1)\n\n\t\tangleDotThreshold = np.cos(np.deg2rad(20))\n\t\tceilingPlaneInds = np.dot(planeCandidates[:, :3], np.array([0, 0, -1])) / np.linalg.norm(planeCandidates[:, :3], 2, 1) > angleDotThreshold\n\t\tceilingPlanes = planeCandidates[ceilingPlaneInds]\n\t\tif ceilingPlanes.shape[0] > 1:\n\t\t\tplaneConfidence = ceilingPlanes[:, 3:].sum(1)\n\t\t\tsortInds = np.argsort(planeConfidence)[::-1]\n\t\t\tceilingPlanes = ceilingPlanes[sortInds[:1]]\n\t\t\t\tpass\n\t\t\t#print(np.dot(planeCandidates[:, :3], np.array([0, 0, -1])) / np.linalg.norm(planeCandidates[:, :3], 2, 1))\n\t\t#print(ceilingPlanes)\n\n\t\thorizontalPlanes = {}\n\t\tif ceilingPlanes.shape[0] > 0:\n\t\t\thorizontalPlanes[\'ceiling\'] = ceilingPlanes[0, :3]\n\t\t\t\tpass\n\t\t\t\n\t\tfloorPlaneInds = np.dot(planeCandidates[:, :3], np.array([0, 0, 1])) / np.linalg.norm(planeCandidates[:, :3], 2, 1) > angleDotThreshold\n\t\tfloorPlanes = planeCandidates[floorPlaneInds]\n\t\tfloorPlanes = planeCandidates[floorPlaneInds]\n\t\tif floorPlanes.shape[0] > 1:\n\t\t\tplaneConfidence = floorPlanes[:, 3:].sum(1)\n\t\t\tsortInds = np.argsort(planeConfidence)[::-1]\n\t\t\tfloorPlanes = floorPlanes[sortInds[:1]]\n\t\t\t\tpass\n\n\t\tif floorPlanes.shape[0] > 0:\n\t\t\thorizontalPlanes[\'floor\'] = floorPlanes[0, :3]\n\t\t\t\tpass\n\t\tif len(horizontalPlanes) == 0:\n\t\t\t\treturn []\n\t\t\t\n\t\tangleDotThreshold = np.cos(np.deg2rad(70))\n\t\twallPlaneInds = np.abs(np.dot(planeCandidates[:, :3], np.array([0, 0, 1]))) / np.linalg.norm(planeCandidates[:, :3], 2, 1) < angleDotThreshold\n\t\twallPlanes = planeCandidates[wallPlaneInds]\n\t\twallPlanes = planeCandidates[wallPlaneInds]\n\t\tif wallPlanes.shape[0] > 1:\n\t\t\tplaneConfidence = wallPlanes[:, 3:].sum(1)\n\t\t\tsortInds = np.argsort(planeConfidence)[::-1]\n\t\t\twallPlanes = wallPlanes[sortInds]\n\t\t\t\tpass\n\n\t\tangles = np.arctan2(wallPlanes[:, 1], wallPlanes[:, 0])\n\t\twalls = []\n\t\tangleDiffThreshold = np.deg2rad(60)\n\t\tfor wallIndex in xrange(wallPlanes.shape[0]):\n\t\t\t\tif len(walls) == 0:\n\t\t\t\t\twalls.append((wallPlanes[wallIndex, :3], angles[wallIndex]))\n\t\t\t\telif len(walls) == 1:\n\t\t\t\t\t\tif abs(angles[wallIndex] - walls[0][1]) > angleDiffThreshold:\n\t\t\t\t\t\t\twalls.append((wallPlanes[wallIndex, :3], angles[wallIndex]))\n\t\t\t\t\t\t\t\tpass\n\t\t\t\t\t\tpass\n\t\t\t\telif len(walls) == 2:\n\t\t\t\t\t\tif abs(angles[wallIndex] - walls[0][1]) > angleDiffThreshold and abs(angles[wallIndex] - walls[1][1]) > angleDiffThreshold:\n\t\t\t\t\t\t\twalls.append((wallPlanes[wallIndex, :3], angles[wallIndex]))\n\t\t\t\t\t\t\t\tpass\n\t\t\t\t\t\tpass\n\t\t\t\telse:\n\t\t\t\t\t\tbreak\n\t\t\t\tcontinue\n\n\t\tif len(walls) > 1:\n\t\t\tsortInds = np.argsort([wall[1] for wall in walls])\n\t\t\twalls = [walls[index][0] for index in sortInds]\n\t\telse:\n\t\t\t\treturn []\n\n\t\tcornerPoints = []\n\t\tfor wallIndex in xrange(len(walls) - 1):\n\t\t\tcornerPlanes = []\n\t\t\tcornerPlanes.append(walls[wallIndex])\n\t\t\tcornerPlanes.append(walls[wallIndex + 1])\n\t\t\t\tfor _, plane in horizontalPlanes.items():\n\t\t\t\t\tcornerPlanes.append(plane)\n\t\t\t\t\tA = np.array(cornerPlanes)\n\t\t\t\t\tb = np.linalg.norm(A, 2, 1)\n\t\t\t\t\tA /= b.reshape(-1, 1)\n\t\t\t\t\tcornerPoint = np.linalg.solve(A, b)\n\t\t\t\t\tu = cornerPoint[0] / cornerPoint[1] * focalLength + imageWidth / 2\n\t\t\t\t\tv = -cornerPoint[2] / cornerPoint[1] * focalLength + imageHeight / 2\n\t\t\t\t\tcornerPoints.append([u, v])\n\t\t\t\t\tcornerPlanes.pop()\n\t\t\t\t\t\tpass\n\t\t\t\tcontinue\n\t\treturn cornerPoints\n\t\n\ndef evaluateDepths(predDepths, gtDepths, validMasks, planeMasks=True, printInfo=True):\n\tmasks = np.logical_and(np.logical_and(validMasks, planeMasks), gtDepths > 1e-4)\n\t\n\t\tnumPixels = float(masks.sum())\n\t\trms = np.sqrt((pow(predDepths - gtDepths, 2) * masks).sum() / numPixels)\n\t\t#log10 = (np.abs(np.log10(np.maximum(predDepths, 1e-4)) - np.log10(np.maximum(gtDepths, 1e-4))) * masks).sum() / numPixels\n\t\t#rel = (np.abs(predDepths - gtDepths) / np.maximum(gtDepths, 1e-4) * masks).sum() / numPixels\n\t\tdeltas = np.maximum(predDepths / np.maximum(gtDepths, 1e-4), gtDepths / np.maximum(predDepths, 1e-4)) + (1 - masks.astype(np.float32)) * 10000\n\t\taccuracy_1 = (deltas < 1.25).sum() / numPixels\n\t\taccuracy_2 = (deltas < pow(1.25, 2)).sum() / numPixels\n\t\taccuracy_3 = (deltas < pow(1.25, 3)).sum() / numPixels\n\t\trecall = float(masks.sum()) / validMasks.sum()\n\t\t#print((rms, recall))\n\t\tif printInfo:\n\t\t\tprint((\'evaluate\', rms, accuracy_1, accuracy_2, accuracy_3, recall))\n\t\t\t\tpass\n\t\treturn rms, accuracy_1\n\t#return rel, log10, rms, accuracy_1, accuracy_2, accuracy_3, recall\n\ndef drawDepthImage(depth):\n\t#return cv2.applyColorMap(np.clip(depth / 10 * 255, 0, 255).astype(np.uint8), cv2.COLORMAP_JET)\n\t\treturn 255 - np.clip(depth / 10 * 255, 0, 255).astype(np.uint8)\n\t\ndef drawNormalImage(normal):\n\t\treturn ((normal + 1) / 2 * 255).astype(np.uint8)\n\t\ndef drawSegmentationImage(segmentations, randomColor=None, numColors=22, planeMask=1, offset=1, black=False):\n\trandomColor = ColorPalette(numColors).getColorMap()\n\t\tif black:\n\t\t\trandomColor[0] = 0\n\t\t\t\tpass\n\t\t\twidth = segmentations.shape[1]\n\t\t\theight = segmentations.shape[0]\n\t\tif segmentations.ndim == 2:\n\t\t\tsegmentation = (segmentations + offset) * planeMask\n\t\telse:\n\t\t\t#segmentation = (np.argmax(segmentations, 2) + 1) * (np.max(segmentations, 2) > 0.5)\n\t\t\t\tif black:\n\t\t\t\t\tsegmentation = np.argmax(segmentations, 2)\n\t\t\t\telse:\n\t\t\t\t\tsegmentation = (np.argmax(segmentations, 2) + 1) * planeMask\n\t\t\t\t\t\tpass\n\t\t\t\tpass\n\t\t\tsegmentation = segmentation.astype(np.int)\n\t\treturn randomColor[segmentation.reshape(-1)].reshape((height, width, 3))\n\ndef drawMaskImage(mask):\n\t\treturn (mask * 255).astype(np.uint8)\n\ndef drawDiffImage(values_1, values_2, threshold):\n\t#return cv2.applyColorMap(np.clip(np.abs(values_1 - values_2) / threshold * 255, 0, 255).astype(np.uint8), cv2.COLORMAP_JET)\n\t\treturn np.clip(np.abs(values_1 - values_2) / threshold * 255, 0, 255).astype(np.uint8)\n\n\ndef getSuperpixels(depth, normal, width, height, numPlanes=50, numGlobalPlanes = 10):\n\tdepth = np.expand_dims(depth, -1)\n\n\turange = (np.arange(width, dtype=np.float32) / (width + 1) - 0.5) / focalLength * 641\n\turange = np.tile(np.reshape(urange, [1, -1]), [height, 1])\n\tvrange = (np.arange(height, dtype=np.float32) / (height + 1) - 0.5) / focalLength * 481\n\tvrange = np.tile(np.reshape(vrange, [-1, 1]), [1, width])\n\t\n\t\tranges = np.stack([urange, np.ones([height, width]), -vrange], axis=2)\n\t\t#ranges = np.expand_dims(ranges, 0)\n\n\t\tplaneImage = np.sum(normal * ranges, axis=2, keepdims=True) * depth * normal\n\t\tplaneImage = planeImage / 10 * 1000\n\n\t\tsuperpixels = segmentation.slic(planeImage, compactness=30, n_segments=400)\n\t\tg = graph.rag_mean_color(planeImage, superpixels, mode=\'similarity\')\n\t\tplaneSegmentation = graph.cut_normalized(superpixels, g)\n\t\treturn planeSegmentation, superpixels\n\n\ndef calcPlaneDepths(planes, width, height):\n\tfocalLength = 517.97\n\turange = np.arange(width).reshape(1, -1).repeat(height, 0) - width * 0.5\n\tvrange = np.arange(height).reshape(-1, 1).repeat(width, 1) - height * 0.5\n\tranges = np.array([urange / width * 640 / focalLength, np.ones(urange.shape), -vrange / height * 480 / focalLength]).transpose([1, 2, 0])\n\t\n\t\tplaneDepths = PlaneDepthLayer(planes, ranges)\n\t\treturn planeDepths\n\n\ndef writePLYFileParts(folder, index, image, depth, segmentation):\n\t\n\t\timageFilename = str(index) + \'_image.png\'\n\t\tcv2.imwrite(folder + \'/\' + imageFilename, image)\n\t\tfocalLength = 517.97\n\t\twidth = image.shape[1]\n\t\theight = image.shape[0]\n\t\t\n\t\tfor segmentIndex in xrange(segmentation.max() + 1):\n\t\t\tfaces = []\n\t\t\t\tfor y in xrange(height - 1):\n\t\t\t\t\t\tfor x in xrange(width - 1):\n\t\t\t\t\t\t\t\tif segmentation[y][x] != segmentIndex:\n\t\t\t\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\t\t\tif segmentation[y + 1][x] == segmentIndex and segmentation[y + 1][x + 1] == segmentIndex:\n\t\t\t\t\t\t\t\t\tdepths = [depth[y][x], depth[y + 1][x], depth[y + 1][x + 1]]\n\t\t\t\t\t\t\t\t\t\tif min(depths) > 0 and max(depths) < 10:\n\t\t\t\t\t\t\t\t\t\t\tfaces.append((x, y, x, y + 1, x + 1, y + 1))\n\t\t\t\t\t\t\t\t\t\t\t\tpass\n\t\t\t\t\t\t\t\t\t\tpass\n\t\t\t\t\t\t\t\tif segmentation[y][x + 1] == segmentIndex and segmentation[y + 1][x + 1] == segmentIndex:\n\t\t\t\t\t\t\t\t\tdepths = [depth[y][x], depth[y][x + 1], depth[y + 1][x + 1]]\n\t\t\t\t\t\t\t\t\t\tif min(depths) > 0 and max(depths) < 10:\n\t\t\t\t\t\t\t\t\t\t\tfaces.append((x, y, x + 1, y + 1, x + 1, y))\n\t\t\t\t\t\t\t\t\t\t\t\tpass\n\t\t\t\t\t\t\t\t\t\tpass\n\t\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\tcontinue\n\n\t\t\t\t#print(len(faces))\n\t\t\t\twith open(folder + \'/\' + str(index) + \'_model_\' + str(segmentIndex) + \'.ply\', \'w\') as f:\n\t\t\t\t\theader = """"""ply\nformat ascii 1.0\ncomment VCGLIB generated\ncomment TextureFile """"""\n\t\t\t\t\theader += imageFilename\n\t\t\t\t\theader += """"""\nelement vertex """"""\n\t\t\t\t\theader += str(width * height)\n\t\t\t\t\theader += """"""\nproperty float x\nproperty float y\nproperty float z\nelement face """"""\n\t\t\t\t\theader += str(len(faces))\n\t\t\t\t\theader += """"""\nproperty list uchar int vertex_indices\nproperty list uchar float texcoord\nend_header\n""""""\n\t\t\t\t\tf.write(header)\n\t\t\t\t\t\tfor y in xrange(height):\n\t\t\t\t\t\t\t\tfor x in xrange(width):\n\t\t\t\t\t\t\t\t\t\tif segmentation[y][x] != segmentIndex:\n\t\t\t\t\t\t\t\t\t\t\tf.write(""0.0 0.0 0.0\\n"")\n\t\t\t\t\t\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\t\t\t\t\t\tY = depth[y][x]\n\t\t\t\t\t\t\t\t\t\t\tX = Y / focalLength * (x - width / 2) / width * 640\n\t\t\t\t\t\t\t\t\t\t\tZ = -Y / focalLength * (y - height / 2) / height * 480\n\t\t\t\t\t\t\t\t\t\t\tf.write(str(X) + \' \' +\tstr(Z) + \' \' + str(-Y) + \'\\n\')\n\t\t\t\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\t\t\tcontinue\n\n\n\t\t\t\t\t\tfor face in faces:\n\t\t\t\t\t\t\tf.write(\'3 \')\n\t\t\t\t\t\t\t\tfor c in xrange(3):\n\t\t\t\t\t\t\t\t\tf.write(str(face[c * 2 + 1] * width + face[c * 2]) + \' \')\n\t\t\t\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\t\t\t\tf.write(\'6 \')\t\t\t\t\t\t\n\t\t\t\t\t\t\t\tfor c in xrange(3):\n\t\t\t\t\t\t\t\t\tf.write(str(float(face[c * 2]) / width) + \' \' + str(1 - float(face[c * 2 + 1]) / height) + \' \')\n\t\t\t\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\t\t\t\tf.write(\'\\n\')\n\t\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\t\tf.close()\n\t\t\t\t\t\tpass\n\t\t\t\tcontinue\n\t\treturn\t\n\ndef writeHTML(folder, numImages):\n\treturn\n\th = HTML(\'html\')\n\th.p(\'Results\')\n\th.br()\n\t#suffixes = [\'\', \'_crf_1\']\n\t#folders = [\'test_all_resnet_v2\' + suffix + \'/\' for suffix in suffixes]\n\tfor index in xrange(numImages):\n\t\tt = h.table(border=\'1\')\n\t\tr_inp = t.tr()\n\t\tr_inp.td(\'input\')\n\t\tr_inp.td().img(src=str(index) + \'_image.png\')\n\t\tr_inp.td().img(src=\'one.png\')\n\t\tr_inp.td().img(src=\'one.png\')\n\t\t#r_inp.td().img(src=\'one.png\')\n\t\tr_inp.td().img(src=str(index) + \'_model.png\')\n\n\t\tr_gt = t.tr()\n\t\tr_gt.td(\'gt\')\n\t\tr_gt.td().img(src=str(index) + \'_segmentation_gt.png\')\n\t\tr_gt.td().img(src=str(index) + \'_depth.png\')\n\t\tr_gt.td().img(src=\'one.png\')\n\t\tr_gt.td().img(src=str(index) + \'_normal.png\')\n\t\t\t\t\n\t\t#r_gt.td().img(src=folders[0] + str(index) + \'_depth_gt.png\')\n\t\t#r_gt.td().img(src=folders[0] + \'_depth_gt_diff.png\')\n\t\t#r_gt.td().img(src=folders[0] + str(index) + \'_normal_gt.png\')\n\n\t\tr_pred = t.tr()\n\t\tr_pred.td(\'pred\')\n\t\tr_pred.td().img(src=str(index) + \'_segmentation_pred.png\')\n\t\tr_pred.td().img(src=str(index) + \'_depth_pred.png\')\n\t\tr_pred.td().img(src=str(index) + \'_depth_pred_diff.png\')\n\t\tr_pred.td().img(src=str(index) + \'_normal_pred.png\')\n\n\t\th.br()\n\t\tcontinue\n\n\thtml_file = open(folder + \'/index.html\', \'w\')\n\thtml_file.write(str(h))\n\thtml_file.close()\n\treturn\n\n\ndef fitPlane(points):\n\t\treturn np.linalg.solve(points, np.ones(points.shape[0]))\n\ndef fitPlanes(depth, numPlanes=50, planeAreaThreshold=3*4, numIterations=50, distanceThreshold=0.05):\n\twidth = depth.shape[0]\n\theight = depth.shape[1]\n\n\tcamera = getNYURGBDCamera()\n\turange = (np.arange(width, dtype=np.float32) / width * camera[\'width\'] - camera[\'cx\']) / camera[\'fx\']\n\tvrange = (np.arange(height, dtype=np.float32) / height * camera[\'height\'] - camera[\'cy\']) / camera[\'fy\']\n\n\tX = depth / urange\n\tY = depth\n\tZ = -depth / vrange\n\tXYZ = np.stack([X, Y, Z], axis=2).reshape(-1, 3)\n\n\tplanes = []\n\tplanePointsArray = []\n\tfor planeIndex in xrange(numPlanes):\n\t\tmaxNumInliers = planeAreaThreshold\n\t\tfor iteration in xrange(numIterations):\n\t\t    sampledPoints = XYZ[np.random.choice(np.arange(XYZ.shape[0]), size=(3))]\n\t\t\tplane = fitPlane(sampledPoints)\n\t\t\tnumInliers = np.sum(np.abs(np.matmul(XYZ, plane) - np.ones(XYZ.shape[0])) < distanceThreshold)\n\t\t\tif numInliers > maxNumInliers:\n\t\t\t\tmaxNumInliers = numInliers\n\t\t\t\tbestPlane = plane\n\t\t\t\tpass\n\t\t\tcontinue\n\t\tif maxNumInliers == planeAreaThreshold:\n\t\t\tbreak\n\t\tplanes.append(bestPlane)\n\t\tinlierInds = np.abs(np.matmul(XYZ, bestPlane) - np.ones(XYZ.shape[0])) < distanceThreshold\n\t\tinliersPoints = XYZ[inlierInds]\n\t\tplanePointsArray = inliersPoints\n\t\tXYZ = XYZ[logical_not(inlierInds)]\n\t\tcontinue\n\tplanes = np.array(planes)\n\t\n\tplaneSegmentation = np.zeros(depth.shape).reshape(-1)\n\tfor planeIndex, planePoints in enumerate(planePointsArray):\n\t\tplaneDepth = planePoints[:, 1]\n\t\tu = int((planePoints[:, 0] / planeDepth * camera[\'fx\'] + camera[\'cx\']) / camera[\'width\'] * width)\n\t\tv = int((-planePoints[:, 2] / planeDepth * camera[\'fy\'] + camera[\'cy\']) / camera[\'height\'] * height)\n\t\tplaneSegmentation[v, u] = planeIndex\n\t\tcontinue\n\treturn planes, planeSegmentation\n\n\t\t\n'"
crfasrnn/__init__.py,0,b'import crfasrnn_layer\n'
crfasrnn/crfasrnn_layer.py,18,"b'""""""\nMIT License\nCopyright (c) 2017 Sadeep Jayasumana\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the ""Software""), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n""""""\n\nimport numpy as np\nimport tensorflow as tf\nfrom keras.engine.topology import Layer\nimport os\npath = os.path.dirname(os.path.realpath(__file__))\ncustom_module = tf.load_op_library(path + \'/high_dim_filter.so\')\nimport high_dim_filter_grad  # Register gradients for the custom op\n\n\nclass CrfRnnLayer(Layer):\n    """""" Implements the CRF-RNN layer described in:\n    Conditional Random Fields as Recurrent Neural Networks,\n    S. Zheng, S. Jayasumana, B. Romera-Paredes, V. Vineet, Z. Su, D. Du, C. Huang and P. Torr,\n    ICCV 2015\n    """"""\n\n    def __init__(self, image_dims, num_classes,\n                 theta_alpha, theta_beta, theta_gamma,\n                 num_iterations, **kwargs):\n        self.image_dims = image_dims\n        self.num_classes = num_classes\n        self.theta_alpha = theta_alpha\n        self.theta_beta = theta_beta\n        self.theta_gamma = theta_gamma\n        self.num_iterations = num_iterations\n        self.spatial_ker_weights = None\n        self.bilateral_ker_weights = None\n        self.compatibility_matrix = None\n        super(CrfRnnLayer, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        # # Weights of the spatial kernel\n        # self.spatial_ker_weights = self.add_weight(name=\'spatial_ker_weights\',\n        #                                            shape=(self.num_classes, self.num_classes),\n        #                                            initializer=\'uniform\',\n        #                                            trainable=True)\n\n        # # Weights of the bilateral kernel\n        # self.bilateral_ker_weights = self.add_weight(name=\'bilateral_ker_weights\',\n        #                                              shape=(self.num_classes, self.num_classes),\n        #                                              initializer=\'uniform\',\n        #                                              trainable=True)\n\n        # # Compatibility matrix\n        # self.compatibility_matrix = self.add_weight(name=\'compatibility_matrix\',\n        #                                             shape=(self.num_classes, self.num_classes),\n        #                                             initializer=\'uniform\',\n        #                                             trainable=True)\n\n\n        weights = np.load(\'weights.npy\')\n        weights = [weights[0], weights[1], weights[2]]\n        self.spatial_ker_weights = tf.Variable(weights[0][:self.num_classes, :self.num_classes], name=\'spatial_ker_weights\', trainable=True)\n        self.bilateral_ker_weights = tf.Variable(weights[1][:self.num_classes, :self.num_classes], name=\'bilateral_ker_weights\', trainable=True)\n        self.compatibility_matrix = tf.Variable(weights[2][:self.num_classes, :self.num_classes], name=\'compatibility_matrix\', trainable=True)\n\n        \n        # self.spatial_ker_weights = tf.constant(weights[0].reshape(-1), name=\'spatial_ker_weights\', shape=(self.num_classes, self.num_classes))\n        # self.bilateral_ker_weights = tf.constant(weights[1].reshape(-1), name=\'bilateral_ker_weights\', shape=(self.num_classes, self.num_classes))\n        # self.compatibility_ker_weights = tf.constant(weights[2].reshape(-1), name=\'compatibility_ker_weights\', shape=(self.num_classes, self.num_classes))\n        \n        \n        super(CrfRnnLayer, self).build(input_shape)\n\n\n    def call(self, inputs):\n        batchSize = int(inputs[0].shape[0])\n        c, h, w = self.num_classes, self.image_dims[0], self.image_dims[1]\n        all_ones = np.ones((c, h, w), dtype=np.float32)\n\n        outputs = []\n        for batchIndex in xrange(batchSize):\n            unaries = tf.transpose(inputs[0][batchIndex, :, :, :], perm=(2, 0, 1))\n            rgb = tf.transpose(inputs[1][batchIndex, :, :, :], perm=(2, 0, 1))\n\n\n            # Prepare filter normalization coefficients\n            spatial_norm_vals = custom_module.high_dim_filter(all_ones, rgb, bilateral=False,\n                                                              theta_gamma=self.theta_gamma)\n            bilateral_norm_vals = custom_module.high_dim_filter(all_ones, rgb, bilateral=True,\n                                                                theta_alpha=self.theta_alpha,\n                                                                theta_beta=self.theta_beta)\n            q_values = unaries\n\n            for i in range(self.num_iterations):\n                softmax_out = tf.nn.softmax(q_values, dim=0)\n\n                # Spatial filtering\n                spatial_out = custom_module.high_dim_filter(softmax_out, rgb, bilateral=False,\n                                                            theta_gamma=self.theta_gamma)\n                spatial_out = spatial_out / spatial_norm_vals\n\n                # Bilateral filtering\n                bilateral_out = custom_module.high_dim_filter(softmax_out, rgb, bilateral=True,\n                                                              theta_alpha=self.theta_alpha,\n                                                              theta_beta=self.theta_beta)\n                bilateral_out = bilateral_out / bilateral_norm_vals\n\n                # Weighting filter outputs\n                message_passing = (tf.matmul(self.spatial_ker_weights,\n                                             tf.reshape(spatial_out, (c, -1))) +\n                                   tf.matmul(self.bilateral_ker_weights,\n                                             tf.reshape(bilateral_out, (c, -1))))\n\n                # Compatibility transform\n                pairwise = tf.matmul(self.compatibility_matrix, message_passing)\n\n                # Adding unary potentials\n                pairwise = tf.reshape(pairwise, (c, h, w))\n                q_values = unaries - pairwise\n                continue\n            outputs.append(tf.transpose(tf.reshape(q_values, (1, c, h, w)), perm=(0, 2, 3, 1)))\n            continue\n        outputs = tf.concat(outputs, axis=0)\n        return outputs\n\n    def compute_output_shape(self, input_shape):\n        return input_shape\n'"
crfasrnn/high_dim_filter_grad.py,2,"b'""""""\nMIT License\n\nCopyright (c) 2017 Sadeep Jayasumana\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the ""Software""), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n""""""\n\nimport tensorflow as tf\nfrom tensorflow.python.framework import ops\nimport os\npath = os.path.dirname(os.path.realpath(__file__))\ncustom_module = tf.load_op_library(path + \'/high_dim_filter.so\')\n\n\n@ops.RegisterGradient(""HighDimFilter"")\ndef _high_dim_filter_grad(op, grad):\n    """""" Gradients for the HighDimFilter op. We only need to calculate the gradients\n    w.r.t. the first input (unaries) as we never need to backprop errors to the\n    second input (RGB values of the image).\n\n    Args:\n    op: The `high_dim_filter` operation that we are differentiating.\n    grad: Gradients with respect to the output of the `high_dim_filter` op.\n\n    Returns:\n    Gradients with respect to the input of `high_dim_filter`.\n    """"""\n\n    rgb = op.inputs[1]\n    grad_vals = custom_module.high_dim_filter(grad, rgb,\n                                              bilateral=op.get_attr(""bilateral""),\n                                              theta_alpha=op.get_attr(""theta_alpha""),\n                                              theta_beta=op.get_attr(""theta_beta""),\n                                              theta_gamma=op.get_attr(""theta_gamma""),\n                                              backwards=True)\n\n    return [grad_vals, tf.zeros_like(rgb)]\n'"
data_preparation/parse.py,0,"b'import xml.etree.ElementTree as ET\nimport numpy as np\n#np.set_printoptions(precision=3, threshold=np.nan)\nimport cv2\nimport sys\nimport os\n#sys.path.append(\'/home/chenliu/Projects/PlaneNet/code\')\nfrom plyfile import PlyData, PlyElement\nimport json\nimport zipfile\nimport glob\nfrom download_scannet import *\n\n#ROOT_FOLDER = \'/mnt/vision/ScanNet/data/\'\nROOT_FOLDER = \'/home/chenliu/Projects/server/Data/ScanNet/data/\'\n\n\nclass ColorPalette:\n    def __init__(self, numColors):\n        np.random.seed(2)\n        #self.colorMap = np.random.randint(255, size = (numColors, 3))\n        #self.colorMap[0] = 0\n\n\n        self.colorMap = np.array([[255, 0, 0],\n                                  [0, 255, 0],\n                                  [0, 0, 255],\n                                  [80, 128, 255],\n                                  [255, 230, 180],\n                                  [255, 0, 255],\n                                  [0, 255, 255],\n                                  [100, 0, 0],\n                                  [0, 100, 0],\n                                  [255, 255, 0],\n                                  [50, 150, 0],\n                                  [200, 255, 255],\n                                  [255, 200, 255],\n                                  [128, 128, 80],\n                                  [0, 50, 128],\n                                  [0, 100, 100],\n                                  [0, 255, 128],\n                                  [0, 128, 255],\n                                  [255, 0, 128],\n                                  [128, 0, 255],\n                                  [255, 128, 0],\n                                  [128, 255, 0],\n        ])\n\n        if numColors > self.colorMap.shape[0]:\n            self.colorMap = np.concatenate([self.colorMap, np.random.randint(255, size = (numColors - self.colorMap.shape[0], 3))], axis=0)\n            pass\n\n        return\n\n    def getColorMap(self):\n        return self.colorMap\n\n    def getColor(self, index):\n        if index >= colorMap.shape[0]:\n            return np.random.randint(255, size = (3))\n        else:\n            return self.colorMap[index]\n            pass\n\ndef writePointCloudFace(filename, points, faces):\n    with open(filename, \'w\') as f:\n        header = """"""ply\nformat ascii 1.0\nelement vertex """"""\n        header += str(len(points))\n        header += """"""\nproperty float x\nproperty float y\nproperty float z\nproperty uchar red                                     { start of vertex color }\nproperty uchar green\nproperty uchar blue\nelement face """"""\n        header += str(len(faces))\n        header += """"""\nproperty list uchar int vertex_index\nend_header\n""""""\n        f.write(header)\n        for point in points:\n            for value in point[:3]:\n                f.write(str(value) + \' \')\n                continue\n            for value in point[3:]:\n                f.write(str(int(value)) + \' \')\n                continue\n            f.write(\'\\n\')\n            continue\n        for face in faces:\n            f.write(\'3 \' + str(face[0]) + \' \' + str(face[1]) + \' \' + str(face[2]) + \'\\n\')\n            continue        \n        f.close()\n        pass\n    return\n\ndef loadClassMap():\n    classMap = {}\n    classLabelMap = {}\n    with open(ROOT_FOLDER + \'/tasks/scannet-labels.combined.tsv\') as info_file:\n        line_index = 0\n        for line in info_file:\n            if line_index > 0:\n                line = line.split(\'\\t\')\n                \n                key = line[1].strip()                \n                classMap[key] = line[7].strip()\n                classMap[key + \'s\'] = line[7].strip()\n\n                if line[4].strip() != \'\':\n                    label = int(line[4].strip())\n                else:\n                    label = -1\n                    pass\n                classLabelMap[key] = label\n                classLabelMap[key + \'s\'] = label                    \n                pass\n            line_index += 1\n            continue\n        pass\n    return classMap, classLabelMap\n\ndef fitPlane(points):\n    if points.shape[0] == points.shape[1]:\n        return np.linalg.solve(points, np.ones(points.shape[0]))\n    else:\n        return np.linalg.lstsq(points, np.ones(points.shape[0]), rcond=None)[0]\n    \ndef mergePlanesNew(points, planes, planePointIndices, planeSegments, segmentNeighbors, numPlanes, planeDiffThreshold = 0.05, planeAngleThreshold = 30, inlierThreshold = 0.9, planeAreaThreshold = 10, orthogonalThreshold = np.cos(np.deg2rad(60)), parallelThreshold = np.cos(np.deg2rad(30)), debug=False):\n\n\n    fittingErrorThreshold = planeDiffThreshold\n    \n    planeFittingErrors = []\n    for plane, pointIndices in zip(planes, planePointIndices):\n        XYZ = points[pointIndices]\n        planeNorm = np.linalg.norm(plane)\n        if planeNorm == 0:\n            planeFittingErrors.append(fittingErrorThreshold)\n            continue\n        diff = np.abs(np.matmul(XYZ, plane) - np.ones(XYZ.shape[0])) / planeNorm\n        planeFittingErrors.append(diff.mean())\n        continue\n    \n    planeList = zip(planes, planePointIndices, planeSegments, planeFittingErrors)\n    planeList = sorted(planeList, key=lambda x:x[3])\n\n    ## Merge two planes if they are neighbors and the merged plane has small fitting error\n    while len(planeList) > 0:\n        hasChange = False\n        planeIndex = 0\n\n        if debug:\n            for index, planeInfo in enumerate(sorted(planeList, key=lambda x:-len(x[1]))):\n                print(index, planeInfo[0] / np.linalg.norm(planeInfo[0]), planeInfo[2], planeInfo[3])\n                continue\n            pass\n        \n        while planeIndex < len(planeList):\n            plane, pointIndices, segments, fittingError = planeList[planeIndex]\n            if fittingError > fittingErrorThreshold:\n                break\n            neighborSegments = []\n            for segment in segments:\n                if segment in segmentNeighbors:\n                    neighborSegments += segmentNeighbors[segment]\n                    pass\n                continue\n            neighborSegments += list(segments)\n            neighborSegments = set(neighborSegments)\n            bestNeighborPlane = (fittingErrorThreshold, -1, None)\n            for neighborPlaneIndex, neighborPlane in enumerate(planeList):\n                if neighborPlaneIndex <= planeIndex:\n                    continue\n                if not bool(neighborSegments & neighborPlane[2]):\n                    continue\n                dotProduct = np.abs(np.dot(neighborPlane[0], plane) / np.maximum(np.linalg.norm(neighborPlane[0]) * np.linalg.norm(plane), 1e-4))\n                newPointIndices = np.concatenate([neighborPlane[1], pointIndices], axis=0)\n                XYZ = points[newPointIndices]\n                if dotProduct > parallelThreshold and len(neighborPlane[1]) > len(pointIndices) * 0.5:\n                    newPlane = fitPlane(XYZ)                    \n                else:\n                    newPlane = plane\n                    pass\n                #newPlane = plane\n                diff = np.abs(np.matmul(XYZ, newPlane) - np.ones(XYZ.shape[0])) / np.linalg.norm(newPlane)\n                newFittingError = diff.mean()\n                if debug:\n                    print(len(planeList), planeIndex, neighborPlaneIndex, newFittingError, plane / np.linalg.norm(plane), neighborPlane[0] / np.linalg.norm(neighborPlane[0]), dotProduct, orthogonalThreshold)\n                    pass\n                if dotProduct < orthogonalThreshold:\n                    continue                \n                if newFittingError < bestNeighborPlane[0]:\n                    newPlaneInfo = [newPlane, newPointIndices, segments.union(neighborPlane[2]), newFittingError]\n                    bestNeighborPlane = (newFittingError, neighborPlaneIndex, newPlaneInfo)\n                    pass\n                continue\n            if bestNeighborPlane[1] != -1:\n                newPlaneList = planeList[:planeIndex] + planeList[planeIndex + 1:bestNeighborPlane[1]] + planeList[bestNeighborPlane[1] + 1:]\n                newFittingError, newPlaneIndex, newPlane = bestNeighborPlane\n                for newPlaneIndex in range(len(newPlaneList)):\n                    if (newPlaneIndex == 0 and newPlaneList[newPlaneIndex][3] > newFittingError) \\\n                       or newPlaneIndex == len(newPlaneList) - 1 \\\n                       or (newPlaneList[newPlaneIndex][3] < newFittingError and newPlaneList[newPlaneIndex + 1][3] > newFittingError):\n                        newPlaneList.insert(newPlaneIndex, newPlane)\n                        break                    \n                    continue\n                if len(newPlaneList) == 0:\n                    newPlaneList = [newPlane]\n                    pass\n                planeList = newPlaneList\n                hasChange = True\n            else:\n                planeIndex += 1\n                pass\n            continue\n        if not hasChange:\n            break\n        continue\n\n    planeList = sorted(planeList, key=lambda x:-len(x[1]))\n\n    \n    minNumPlanes, maxNumPlanes = numPlanes\n    if minNumPlanes == 1 and len(planeList) == 0:\n        if debug:\n            print(\'at least one plane\')\n            pass\n    elif len(planeList) > maxNumPlanes:\n        if debug:\n            print(\'too many planes\', len(planeList), maxNumPlanes)\n            pass\n        planeList = planeList[:maxNumPlanes]\n        pass\n    \n    groupedPlanes, groupedPlanePointIndices, groupedPlaneSegments, groupedPlaneFittingErrors = zip(*planeList)\n    groupNeighbors = []\n    for planeIndex, planeSegments in enumerate(groupedPlaneSegments):\n        neighborSegments = []\n        for segment in planeSegments:\n            if segment in segmentNeighbors:            \n                neighborSegments += segmentNeighbors[segment]\n                pass\n            continue\n        neighborSegments += list(planeSegments)        \n        neighborSegments = set(neighborSegments)\n        neighborPlaneIndices = []\n        for neighborPlaneIndex, neighborPlaneSegments in enumerate(groupedPlaneSegments):\n            if neighborPlaneIndex == planeIndex:\n                continue\n            if bool(neighborSegments & neighborPlaneSegments):\n                plane = groupedPlanes[planeIndex]\n                neighborPlane = groupedPlanes[neighborPlaneIndex]\n                if np.linalg.norm(plane) * np.linalg.norm(neighborPlane) < 1e-4:\n                    continue\n                dotProduct = np.abs(np.dot(plane, neighborPlane) / np.maximum(np.linalg.norm(plane) * np.linalg.norm(neighborPlane), 1e-4))\n                if dotProduct < orthogonalThreshold:\n                    neighborPlaneIndices.append(neighborPlaneIndex)\n                    pass\n                pass\n            continue\n        groupNeighbors.append(neighborPlaneIndices)\n        continue\n\n    if debug and len(groupedPlanes) > 1:\n        print(\'merging result\', [len(pointIndices) for pointIndices in groupedPlanePointIndices], groupedPlaneFittingErrors, groupNeighbors)\n        pass\n    \n    planeList = zip(groupedPlanes, groupedPlanePointIndices, groupNeighbors)\n    return planeList\n\n\ndef readMesh(scene_id):\n\n    filename = ROOT_FOLDER + scene_id + \'/\' + scene_id + \'.aggregation.json\'\n    data = json.load(open(filename, \'r\'))\n    aggregation = np.array(data[\'segGroups\'])\n\n    high_res = False\n\n    if high_res:\n        filename = ROOT_FOLDER + scene_id + \'/\' + scene_id + \'_vh_clean.labels.ply\'\n    else:\n        filename = ROOT_FOLDER + scene_id + \'/\' + scene_id + \'_vh_clean_2.labels.ply\'\n        pass\n\n    plydata = PlyData.read(filename)\n    vertices = plydata[\'vertex\']\n    points = np.stack([vertices[\'x\'], vertices[\'y\'], vertices[\'z\']], axis=1)\n    faces = np.array(plydata[\'face\'][\'vertex_indices\'])\n    \n    semanticSegmentation = vertices[\'label\']\n\n\n    if high_res:\n        filename = ROOT_FOLDER + scene_id + \'/\' + scene_id + \'_vh_clean.segs.json\'\n    else:\n        filename = ROOT_FOLDER + scene_id + \'/\' + scene_id + \'_vh_clean_2.0.010000.segs.json\'\n        pass\n\n    data = json.load(open(filename, \'r\'))\n    segmentation = np.array(data[\'segIndices\'])\n\n    groupSegments = []\n    groupLabels = []\n    for segmentIndex in xrange(len(aggregation)):\n        groupSegments.append(aggregation[segmentIndex][\'segments\'])\n        groupLabels.append(aggregation[segmentIndex][\'label\'])\n        continue\n\n    segmentation = segmentation.astype(np.int32)\n\n    uniqueSegments = np.unique(segmentation).tolist()\n    numSegments = 0\n    for segments in groupSegments:\n        for segmentIndex in segments:\n            if segmentIndex in uniqueSegments:\n                uniqueSegments.remove(segmentIndex)\n                pass\n            continue\n        numSegments += len(segments)\n        continue\n\n    for segment in uniqueSegments:\n        groupSegments.append([segment, ])\n        groupLabels.append(\'unannotated\')\n        continue\n\n    numGroups = len(groupSegments)\n    numPoints = segmentation.shape[0]    \n    numPlanes = 1000\n\n    ## Segment connections for plane merging later\n    segmentEdges = []\n    for faceIndex in xrange(faces.shape[0]):\n        face = faces[faceIndex]\n        segment_1 = segmentation[face[0]]\n        segment_2 = segmentation[face[1]]\n        segment_3 = segmentation[face[2]]\n        if segment_1 != segment_2 or segment_1 != segment_3:\n            if segment_1 != segment_2 and segment_1 != -1 and segment_2 != -1:\n                segmentEdges.append((min(segment_1, segment_2), max(segment_1, segment_2)))\n                pass\n            if segment_1 != segment_3 and segment_1 != -1 and segment_3 != -1:\n                segmentEdges.append((min(segment_1, segment_3), max(segment_1, segment_3)))\n                pass\n            if segment_2 != segment_3 and segment_2 != -1 and segment_3 != -1:\n                segmentEdges.append((min(segment_2, segment_3), max(segment_2, segment_3)))                \n                pass\n            pass\n        continue\n    segmentEdges = list(set(segmentEdges))\n\n\n    numPlanes = 200\n    numPlanesPerSegment = 2\n    segmentRatio = 0.1\n    planeAreaThreshold = 10\n    numIterations = 100\n    numIterationsPair = 1000\n    planeDiffThreshold = 0.05\n    fittingErrorThreshold = planeDiffThreshold\n\n    ## Specify the minimum and maximum number of planes for each object\n    labelNumPlanes = {\'wall\': [1, 3], \n                      \'floor\': [1, 1],\n                      \'cabinet\': [1, 5],\n                      \'bed\': [1, 5],\n                      \'chair\': [1, 2],\n                      \'sofa\': [1, 10],\n                      \'table\': [1, 5],\n                      \'door\': [1, 2],\n                      \'window\': [1, 2],\n                      \'bookshelf\': [1, 5],\n                      \'picture\': [1, 1],\n                      \'counter\': [1, 10],\n                      \'blinds\': [0, 0],\n                      \'desk\': [1, 10],\n                      \'shelf\': [1, 5],\n                      \'shelves\': [1, 5],                      \n                      \'curtain\': [0, 0],\n                      \'dresser\': [1, 5],\n                      \'pillow\': [0, 0],\n                      \'mirror\': [0, 0],\n                      \'entrance\': [1, 1],\n                      \'floor mat\': [1, 1],                      \n                      \'clothes\': [0, 0],\n                      \'ceiling\': [1, 5],\n                      \'book\': [0, 1],\n                      \'books\': [0, 1],                      \n                      \'refridgerator\': [1, 5],\n                      \'television\': [1, 1], \n                      \'paper\': [0, 1],\n                      \'towel\': [0, 1],\n                      \'shower curtain\': [0, 1],\n                      \'box\': [1, 5],\n                      \'whiteboard\': [1, 5],\n                      \'person\': [0, 0],\n                      \'night stand\': [1, 5],\n                      \'toilet\': [0, 5],\n                      \'sink\': [0, 5],\n                      \'lamp\': [0, 1],\n                      \'bathtub\': [0, 5],\n                      \'bag\': [0, 1],\n                      \'otherprop\': [0, 5],\n                      \'otherstructure\': [0, 5],\n                      \'otherfurniture\': [0, 5],                      \n                      \'unannotated\': [0, 5],\n                      \'\': [0, 0],\n    }\n    nonPlanarGroupLabels = [\'bicycle\', \'bottle\', \'water bottle\']\n    nonPlanarGroupLabels = {label: True for label in nonPlanarGroupLabels}\n    \n    verticalLabels = [\'wall\', \'door\', \'cabinet\']\n    classMap, classLabelMap = loadClassMap()\n    allXYZ = points.reshape(-1, 3)\n\n    segmentNeighbors = {}\n    for segmentEdge in segmentEdges:\n        if segmentEdge[0] not in segmentNeighbors:\n            segmentNeighbors[segmentEdge[0]] = []\n            pass\n        segmentNeighbors[segmentEdge[0]].append(segmentEdge[1])\n        \n        if segmentEdge[1] not in segmentNeighbors:\n            segmentNeighbors[segmentEdge[1]] = []\n            pass\n        segmentNeighbors[segmentEdge[1]].append(segmentEdge[0])\n        continue\n\n    planeGroups = []\n    print(\'num groups\', len(groupSegments))\n\n    debug = False    \n    debugIndex = -1\n\n    ## A group corresponds to an instance in the ScanNet annotation\n    for groupIndex, group in enumerate(groupSegments):\n        if debugIndex != -1 and groupIndex != debugIndex:\n            continue\n        if groupLabels[groupIndex] in nonPlanarGroupLabels:\n            groupLabel = groupLabels[groupIndex]\n            minNumPlanes, maxNumPlanes = 0, 0\n        elif groupLabels[groupIndex] == \'unannotated\':\n            groupLabel = \'unannotated\'\n            minNumPlanes, maxNumPlanes = labelNumPlanes[groupLabel]\n        elif groupLabels[groupIndex] in classMap:\n            groupLabel = classMap[groupLabels[groupIndex]]\n            minNumPlanes, maxNumPlanes = labelNumPlanes[groupLabel]            \n        else:\n            minNumPlanes, maxNumPlanes = 0, 0\n            groupLabel = \'\'\n            pass\n\n        if maxNumPlanes == 0:\n            pointMasks = []\n            for segmentIndex in group:\n                pointMasks.append(segmentation == segmentIndex)\n                continue\n            pointIndices = np.any(np.stack(pointMasks, 0), 0).nonzero()[0]\n            groupPlanes = [[np.zeros(3), pointIndices, []]]\n            planeGroups.append(groupPlanes)\n            continue\n        groupPlanes = []\n        groupPlanePointIndices = []\n        groupPlaneSegments = []\n\n\n        ## A group contains multiple segments and we run RANSAC for each segment\n        for segmentIndex in group:\n            segmentMask = segmentation == segmentIndex\n            segmentIndices = segmentMask.nonzero()[0]\n\n            XYZ = allXYZ[segmentMask.reshape(-1)]\n            numPoints = XYZ.shape[0]\n\n            segmentPlanes = []\n            segmentPlanePointIndices = []\n\n            for c in range(2):\n                if c == 0:\n                    ## First try to fit one plane to see if the entire segment is one plane\n                    plane = fitPlane(XYZ)\n                    diff = np.abs(np.matmul(XYZ, plane) - np.ones(XYZ.shape[0])) / np.linalg.norm(plane)\n                    if diff.mean() < fittingErrorThreshold:\n                        segmentPlanes.append(plane)\n                        segmentPlanePointIndices.append(segmentIndices)\n                        break\n                else:\n                    ## Run ransac                    \n                    for planeIndex in range(numPlanesPerSegment):\n                        if len(XYZ) < planeAreaThreshold:\n                            continue\n                        bestPlaneInfo = [None, 0, None]\n                        for iteration in range(min(XYZ.shape[0], numIterations)):\n                            sampledPoints = XYZ[np.random.choice(np.arange(XYZ.shape[0]), size=(3), replace=False)]\n                            try:\n                                plane = fitPlane(sampledPoints)\n                                pass\n                            except:\n                                continue\n                            diff = np.abs(np.matmul(XYZ, plane) - np.ones(XYZ.shape[0])) / np.linalg.norm(plane)\n                            inlierMask = diff < planeDiffThreshold\n                            numInliers = inlierMask.sum()\n                            if numInliers > bestPlaneInfo[1]:\n                                bestPlaneInfo = [plane, numInliers, inlierMask]\n                                pass\n                            continue\n\n                        if bestPlaneInfo[1] < planeAreaThreshold:\n                            break\n\n                        \n                        pointIndices = segmentIndices[bestPlaneInfo[2]]\n                        #bestPlane = bestPlaneInfo[0]\n                        bestPlane = fitPlane(XYZ[bestPlaneInfo[2]])\n                        \n                        segmentPlanes.append(bestPlane)                \n                        segmentPlanePointIndices.append(pointIndices)\n\n                        outlierMask = np.logical_not(bestPlaneInfo[2])\n                        segmentIndices = segmentIndices[outlierMask]\n                        XYZ = XYZ[outlierMask]\n                        continue\n                    pass\n                continue\n            \n            if sum([len(indices) for indices in segmentPlanePointIndices]) < numPoints * 0.5:\n                print(\'not enough fitted points\')\n                if len(segmentIndices) >= planeAreaThreshold:\n                    groupPlanes.append(np.zeros(3))\n                    groupPlanePointIndices.append(segmentIndices)\n                    groupPlaneSegments.append(set([segmentIndex]))\n                    pass\n            else:\n                groupPlanes += segmentPlanes\n                groupPlanePointIndices += segmentPlanePointIndices\n                for _ in range(len(segmentPlanes)):\n                    groupPlaneSegments.append(set([segmentIndex]))\n                    continue\n                pass\n            continue\n            \n        if len(groupPlanes) > 0:\n            ## Merge planes of each instance\n            groupPlanes = mergePlanesNew(points, groupPlanes, groupPlanePointIndices, groupPlaneSegments, segmentNeighbors, numPlanes=(minNumPlanes, maxNumPlanes), planeDiffThreshold=planeDiffThreshold, planeAreaThreshold=planeAreaThreshold, debug=debugIndex != -1)\n            pass\n\n        if debug:\n            print(\'group\', groupIndex, groupLabels[groupIndex], groupLabel, len(groupPlanes))\n            pass\n        \n        planeGroups.append(groupPlanes)\n        continue\n    \n    \n    if debug:\n        #colorMap = np.random.randint(255, size=(segmentation.max() + 2, 3))\n        colorMap = ColorPalette(segmentation.max() + 2).getColorMap()\n        colorMap[-1] = 0\n        colorMap[-2] = 255\n        annotationFolder = \'test/\'\n        #colorMap = np.tile(np.expand_dims(np.arange(256), -1), [1, 3])\n    else:\n        #colorMap = ColorPalette(segmentation.max() + 2).getColorMap()\n        numPlanes = sum([len(group) for group in planeGroups])\n        #print(\'num planes\', numPlanes)\n        #exit(1)\n        segmentationColor = (np.arange(numPlanes) + 1) * 100\n        colorMap = np.stack([segmentationColor / (256 * 256), segmentationColor / 256 % 256, segmentationColor % 256], axis=1)\n        colorMap[-1] = 255\n        annotationFolder = ROOT_FOLDER + scene_id + \'/annotation/\'\n        pass\n\n\n    if debug:\n        colors = colorMap[segmentation]\n        writePointCloudFace(annotationFolder + \'/segments.ply\', np.concatenate([points, colors], axis=-1), faces)\n\n        groupedSegmentation = np.full(segmentation.shape, fill_value=-1)\n        for segmentIndex in xrange(len(aggregation)):\n            indices = aggregation[segmentIndex][\'segments\']\n            for index in indices:\n                groupedSegmentation[segmentation == index] = segmentIndex\n                continue\n            continue\n        groupedSegmentation = groupedSegmentation.astype(np.int32)\n        colors = colorMap[groupedSegmentation]\n        writePointCloudFace(annotationFolder + \'/groups.ply\', np.concatenate([points, colors], axis=-1), faces)\n        pass\n\n    \n    planes = []\n    planePointIndices = []\n    for index, group in enumerate(planeGroups):\n        groupPlanes, groupPlanePointIndices, groupNeighbors = zip(*group)\n\n        planes += groupPlanes\n        planePointIndices += groupPlanePointIndices\n        continue\n    \n\n    planeSegmentation = np.full(segmentation.shape, fill_value=-1, dtype=np.int32)\n    for planeIndex, planePoints in enumerate(planePointIndices):\n        if np.linalg.norm(planes[planeIndex]) < 1e-4:\n            planeSegmentation[planePoints] = -2\n        else:\n            planeSegmentation[planePoints] = planeIndex\n            pass\n        continue\n\n\n    if debug:\n        groupSegmentation = np.full(segmentation.shape, fill_value=-1, dtype=np.int32)        \n        structureSegmentation = np.full(segmentation.shape, fill_value=-1, dtype=np.int32)\n        typeSegmentation = np.full(segmentation.shape, fill_value=-1, dtype=np.int32)\n        for planeIndex, planePoints in enumerate(planePointIndices):\n            if len(planeInfo[planeIndex]) > 1:\n                structureSegmentation[planePoints] = planeInfo[planeIndex][1][0]\n                typeSegmentation[planePoints] = np.maximum(typeSegmentation[planePoints], planeInfo[planeIndex][1][1] - 2)\n                pass\n            groupSegmentation[planePoints] = planeInfo[planeIndex][0][0]\n            continue\n\n        colors = colorMap[groupSegmentation]    \n        writePointCloudFace(annotationFolder + \'/group.ply\', np.concatenate([points, colors], axis=-1), faces)\n\n        colors = colorMap[structureSegmentation]    \n        writePointCloudFace(annotationFolder + \'/structure.ply\', np.concatenate([points, colors], axis=-1), faces)\n\n        colors = colorMap[typeSegmentation]    \n        writePointCloudFace(annotationFolder + \'/type.ply\', np.concatenate([points, colors], axis=-1), faces)\n        pass\n\n\n    planes = np.array(planes)\n    print(\'number of planes: \', planes.shape[0])    \n    planesD = 1.0 / np.maximum(np.linalg.norm(planes, axis=-1, keepdims=True), 1e-4)\n    planes *= pow(planesD, 2)\n\n    ## Remove boundary faces for rendering purpose\n    removeIndices = []\n    for faceIndex in xrange(faces.shape[0]):\n        face = faces[faceIndex]\n        segment_1 = planeSegmentation[face[0]]\n        segment_2 = planeSegmentation[face[1]]\n        segment_3 = planeSegmentation[face[2]]\n        if segment_1 != segment_2 or segment_1 != segment_3:\n            removeIndices.append(faceIndex)\n            pass\n        continue\n    faces = np.delete(faces, removeIndices)\n    colors = colorMap[planeSegmentation]    \n    writePointCloudFace(annotationFolder + \'/planes.ply\', np.concatenate([points, colors], axis=-1), faces)\n\n    if debug:\n        exit(1)\n        pass\n    \n    np.save(annotationFolder + \'/planes.npy\', planes)\n        \n    return\n\n\nif __name__==\'__main__\':\n\n    scene_ids = os.listdir(ROOT_FOLDER)\n    scene_ids = scene_ids\n\n    for scene_id in scene_ids:\n        if scene_id[:5] != \'scene\':\n            continue\n        if not os.path.exists(ROOT_FOLDER + \'/\' + scene_id + \'/annotation\'):\n            os.system(\'mkdir -p \' + ROOT_FOLDER + \'/\' + scene_id + \'/annotation\')\n            pass\n        if not os.path.exists(ROOT_FOLDER + \'/\' + scene_id + \'/annotation/segmentation\'):\n            os.system(\'mkdir -p \' + ROOT_FOLDER + \'/\' + scene_id + \'/annotation/segmentation\')\n            pass\n        print(scene_id)\n        ## Download if not exists\n        if not os.path.exists(ROOT_FOLDER + \'/\' + scene_id + \'/\' + scene_id + \'.aggregation.json\'):\n            print(\'download\')\n            download_release([scene_id], ROOT_FOLDER, FILETYPES, use_v1_sens=True)\n            pass\n        print(\'plane fitting\', scene_id)\n        if not os.path.exists(ROOT_FOLDER + \'/\' + scene_id + \'/annotation/planes.ply\'):\n            readMesh(scene_id)\n            pass\n\n        ## Use a C++ program built upon OpenGL to render the 3D plane fitting results to each view\n        if len(glob.glob(ROOT_FOLDER + \'/\' + scene_id + \'/annotation/segmentation/*.png\')) < len(glob.glob(ROOT_FOLDER + \'/\' + scene_id + \'/frames/pose/*.txt\')):\n            cmd = \'../../Renderer/Renderer --scene_id=\' + scene_id + \' --root_folder=\' + ROOT_FOLDER\n            os.system(cmd)\n            pass\n        continue\n\n'"
kaffe/__init__.py,0,"b'from .graph import GraphBuilder, NodeMapper\nfrom .errors import KaffeError, print_stderr\n\nfrom . import tensorflow\n'"
kaffe/errors.py,0,"b""import sys\n\nclass KaffeError(Exception):\n    pass\n\ndef print_stderr(msg):\n    sys.stderr.write('%s\\n' % msg)\n"""
kaffe/graph.py,0,"b'from google.protobuf import text_format\n\nfrom .caffe import get_caffe_resolver\nfrom .errors import KaffeError, print_stderr\nfrom .layers import LayerAdapter, LayerType, NodeKind, NodeDispatch\nfrom .shapes import TensorShape\n\nclass Node(object):\n\n    def __init__(self, name, kind, layer=None):\n        self.name = name\n        self.kind = kind\n        self.layer = LayerAdapter(layer, kind) if layer else None\n        self.parents = []\n        self.children = []\n        self.data = None\n        self.output_shape = None\n        self.metadata = {}\n\n    def add_parent(self, parent_node):\n        assert parent_node not in self.parents\n        self.parents.append(parent_node)\n        if self not in parent_node.children:\n            parent_node.children.append(self)\n\n    def add_child(self, child_node):\n        assert child_node not in self.children\n        self.children.append(child_node)\n        if self not in child_node.parents:\n            child_node.parents.append(self)\n\n    def get_only_parent(self):\n        if len(self.parents) != 1:\n            raise KaffeError(\'Node (%s) expected to have 1 parent. Found %s.\' %\n                             (self, len(self.parents)))\n        return self.parents[0]\n\n    @property\n    def parameters(self):\n        if self.layer is not None:\n            return self.layer.parameters\n        return None\n\n    def __str__(self):\n        return \'[%s] %s\' % (self.kind, self.name)\n\n    def __repr__(self):\n        return \'%s (0x%x)\' % (self.name, id(self))\n\n\nclass Graph(object):\n\n    def __init__(self, nodes=None, name=None):\n        self.nodes = nodes or []\n        self.node_lut = {node.name: node for node in self.nodes}\n        self.name = name\n\n    def add_node(self, node):\n        self.nodes.append(node)\n        self.node_lut[node.name] = node\n\n    def get_node(self, name):\n        try:\n            return self.node_lut[name]\n        except KeyError:\n            raise KaffeError(\'Layer not found: %s\' % name)\n\n    def get_input_nodes(self):\n        return [node for node in self.nodes if len(node.parents) == 0]\n\n    def get_output_nodes(self):\n        return [node for node in self.nodes if len(node.children) == 0]\n\n    def topologically_sorted(self):\n        sorted_nodes = []\n        unsorted_nodes = list(self.nodes)\n        temp_marked = set()\n        perm_marked = set()\n\n        def visit(node):\n            if node in temp_marked:\n                raise KaffeError(\'Graph is not a DAG.\')\n            if node in perm_marked:\n                return\n            temp_marked.add(node)\n            for child in node.children:\n                visit(child)\n            perm_marked.add(node)\n            temp_marked.remove(node)\n            sorted_nodes.insert(0, node)\n\n        while len(unsorted_nodes):\n            visit(unsorted_nodes.pop())\n        return sorted_nodes\n\n    def compute_output_shapes(self):\n        sorted_nodes = self.topologically_sorted()\n        for node in sorted_nodes:\n            node.output_shape = TensorShape(*NodeKind.compute_output_shape(node))\n\n    def replaced(self, new_nodes):\n        return Graph(nodes=new_nodes, name=self.name)\n\n    def transformed(self, transformers):\n        graph = self\n        for transformer in transformers:\n            graph = transformer(graph)\n            if graph is None:\n                raise KaffeError(\'Transformer failed: {}\'.format(transformer))\n            assert isinstance(graph, Graph)\n        return graph\n\n    def __contains__(self, key):\n        return key in self.node_lut\n\n    def __str__(self):\n        hdr = \'{:<20} {:<30} {:>20} {:>20}\'.format(\'Type\', \'Name\', \'Param\', \'Output\')\n        s = [hdr, \'-\' * 94]\n        for node in self.topologically_sorted():\n            # If the node has learned parameters, display the first one\'s shape.\n            # In case of convolutions, this corresponds to the weights.\n            data_shape = node.data[0].shape if node.data else \'--\'\n            out_shape = node.output_shape or \'--\'\n            s.append(\'{:<20} {:<30} {:>20} {:>20}\'.format(node.kind, node.name, data_shape,\n                                                          tuple(out_shape)))\n        return \'\\n\'.join(s)\n\n\nclass GraphBuilder(object):\n    \'\'\'Constructs a model graph from a Caffe protocol buffer definition.\'\'\'\n\n    def __init__(self, def_path, phase=\'test\'):\n        \'\'\'\n        def_path: Path to the model definition (.prototxt)\n        data_path: Path to the model data (.caffemodel)\n        phase: Either \'test\' or \'train\'. Used for filtering phase-specific nodes.\n        \'\'\'\n        self.def_path = def_path\n        self.phase = phase\n        self.load()\n\n    def load(self):\n        \'\'\'Load the layer definitions from the prototxt.\'\'\'\n        self.params = get_caffe_resolver().NetParameter()\n        with open(self.def_path, \'rb\') as def_file:\n            text_format.Merge(def_file.read(), self.params)\n\n    def filter_layers(self, layers):\n        \'\'\'Filter out layers based on the current phase.\'\'\'\n        phase_map = {0: \'train\', 1: \'test\'}\n        filtered_layer_names = set()\n        filtered_layers = []\n        for layer in layers:\n            phase = self.phase\n            if len(layer.include):\n                phase = phase_map[layer.include[0].phase]\n            if len(layer.exclude):\n                phase = phase_map[1 - layer.include[0].phase]\n            exclude = (phase != self.phase)\n            # Dropout layers appear in a fair number of Caffe\n            # test-time networks. These are just ignored. We\'ll\n            # filter them out here.\n            if (not exclude) and (phase == \'test\'):\n                exclude = (layer.type == LayerType.Dropout)\n            if not exclude:\n                filtered_layers.append(layer)\n                # Guard against dupes.\n                assert layer.name not in filtered_layer_names\n                filtered_layer_names.add(layer.name)\n        return filtered_layers\n\n    def make_node(self, layer):\n        \'\'\'Create a graph node for the given layer.\'\'\'\n        kind = NodeKind.map_raw_kind(layer.type)\n        if kind is None:\n            raise KaffeError(\'Unknown layer type encountered: %s\' % layer.type)\n        # We want to use the layer\'s top names (the ""output"" names), rather than the\n        # name attribute, which is more of readability thing than a functional one.\n        # Other layers will refer to a node by its ""top name"".\n        return Node(layer.name, kind, layer=layer)\n\n    def make_input_nodes(self):\n        \'\'\'\n        Create data input nodes.\n\n        This method is for old-style inputs, where the input specification\n        was not treated as a first-class layer in the prototext.\n        Newer models use the ""Input layer"" type.\n        \'\'\'\n        nodes = [Node(name, NodeKind.Data) for name in self.params.input]\n        if len(nodes):\n            input_dim = map(int, self.params.input_dim)\n            if not input_dim:\n                if len(self.params.input_shape) > 0:\n                    input_dim = map(int, self.params.input_shape[0].dim)\n                else:\n                    raise KaffeError(\'Dimensions for input not specified.\')\n            for node in nodes:\n                node.output_shape = tuple(input_dim)\n        return nodes\n\n    def build(self):\n        \'\'\'\n        Builds the graph from the Caffe layer definitions.\n        \'\'\'\n        # Get the layers\n        layers = self.params.layers or self.params.layer\n        # Filter out phase-excluded layers\n        layers = self.filter_layers(layers)\n        # Get any separately-specified input layers\n        nodes = self.make_input_nodes()\n        nodes += [self.make_node(layer) for layer in layers]\n        # Initialize the graph\n        graph = Graph(nodes=nodes, name=self.params.name)\n        # Connect the nodes\n        #\n        # A note on layers and outputs:\n        # In Caffe, each layer can produce multiple outputs (""tops"") from a set of inputs\n        # (""bottoms""). The bottoms refer to other layers\' tops. The top can rewrite a bottom\n        # (in case of in-place operations). Note that the layer\'s name is not used for establishing\n        # any connectivity. It\'s only used for data association. By convention, a layer with a\n        # single top will often use the same name (although this is not required).\n        #\n        # The current implementation only supports single-output nodes (note that a node can still\n        # have multiple children, since multiple child nodes can refer to the single top\'s name).\n        node_outputs = {}\n        for layer in layers:\n            node = graph.get_node(layer.name)\n            for input_name in layer.bottom:\n                assert input_name != layer.name\n                parent_node = node_outputs.get(input_name)\n                if (parent_node is None) or (parent_node == node):\n                    parent_node = graph.get_node(input_name)\n                node.add_parent(parent_node)\n            if len(layer.top)>1:\n                raise KaffeError(\'Multiple top nodes are not supported.\')\n            for output_name in layer.top:\n                if output_name == layer.name:\n                    # Output is named the same as the node. No further action required.\n                    continue\n                # There are two possibilities here:\n                #\n                # Case 1: output_name refers to another node in the graph.\n                # This is an ""in-place operation"" that overwrites an existing node.\n                # This would create a cycle in the graph. We\'ll undo the in-placing\n                # by substituting this node wherever the overwritten node is referenced.\n                #\n                # Case 2: output_name violates the convention layer.name == output_name.\n                # Since we are working in the single-output regime, we will can rename it to\n                # match the layer name.\n                #\n                # For both cases, future references to this top re-routes to this node.\n                node_outputs[output_name] = node\n\n        graph.compute_output_shapes()\n        return graph\n\n\nclass NodeMapper(NodeDispatch):\n\n    def __init__(self, graph):\n        self.graph = graph\n\n    def map(self):\n        nodes = self.graph.topologically_sorted()\n        # Remove input nodes - we\'ll handle them separately.\n        input_nodes = self.graph.get_input_nodes()\n        nodes = [t for t in nodes if t not in input_nodes]\n        # Decompose DAG into chains.\n        chains = []\n        for node in nodes:\n            attach_to_chain = None\n            if len(node.parents) == 1:\n                parent = node.get_only_parent()\n                for chain in chains:\n                    if chain[-1] == parent:\n                        # Node is part of an existing chain.\n                        attach_to_chain = chain\n                        break\n            if attach_to_chain is None:\n                # Start a new chain for this node.\n                attach_to_chain = []\n                chains.append(attach_to_chain)\n            attach_to_chain.append(node)\n        # Map each chain.\n        mapped_chains = []\n        for chain in chains:\n            mapped_chains.append(self.map_chain(chain))\n        return self.commit(mapped_chains)\n\n    def map_chain(self, chain):\n        return [self.map_node(node) for node in chain]\n\n    def map_node(self, node):\n        map_func = self.get_handler(node.kind, \'map\')\n        mapped_node = map_func(node)\n        assert mapped_node is not None\n        mapped_node.node = node\n        return mapped_node\n\n    def commit(self, mapped_chains):\n        raise NotImplementedError(\'Must be implemented by subclass.\')\n'"
kaffe/layers.py,0,"b""import re\nimport numbers\nfrom collections import namedtuple\n\nfrom .shapes import *\n\nLAYER_DESCRIPTORS = {\n\n    # Caffe Types\n    'AbsVal': shape_identity,\n    'Accuracy': shape_scalar,\n    'ArgMax': shape_not_implemented,\n    'BatchNorm': shape_identity,\n    'BNLL': shape_not_implemented,\n    'Concat': shape_concat,\n    'ContrastiveLoss': shape_scalar,\n    'Convolution': shape_convolution,\n    'Deconvolution': shape_not_implemented,\n    'Data': shape_data,\n    'Dropout': shape_identity,\n    'DummyData': shape_data,\n    'EuclideanLoss': shape_scalar,\n    'Eltwise': shape_identity,\n    'Exp': shape_identity,\n    'Flatten': shape_not_implemented,\n    'HDF5Data': shape_data,\n    'HDF5Output': shape_identity,\n    'HingeLoss': shape_scalar,\n    'Im2col': shape_not_implemented,\n    'ImageData': shape_data,\n    'InfogainLoss': shape_scalar,\n    'InnerProduct': shape_inner_product,\n    'Input': shape_data,\n    'LRN': shape_identity,\n    'MemoryData': shape_mem_data,\n    'MultinomialLogisticLoss': shape_scalar,\n    'MVN': shape_not_implemented,\n    'Pooling': shape_pool,\n    'Power': shape_identity,\n    'ReLU': shape_identity,\n    'Scale': shape_identity,\n    'Sigmoid': shape_identity,\n    'SigmoidCrossEntropyLoss': shape_scalar,\n    'Silence': shape_not_implemented,\n    'Softmax': shape_identity,\n    'SoftmaxWithLoss': shape_scalar,\n    'Split': shape_not_implemented,\n    'Slice': shape_not_implemented,\n    'TanH': shape_identity,\n    'WindowData': shape_not_implemented,\n    'Threshold': shape_identity,\n}\n\nLAYER_TYPES = LAYER_DESCRIPTORS.keys()\n\nLayerType = type('LayerType', (), {t: t for t in LAYER_TYPES})\n\nclass NodeKind(LayerType):\n\n    @staticmethod\n    def map_raw_kind(kind):\n        if kind in LAYER_TYPES:\n            return kind\n        return None\n\n    @staticmethod\n    def compute_output_shape(node):\n        try:\n            val = LAYER_DESCRIPTORS[node.kind](node)\n            return val\n        except NotImplementedError:\n            raise KaffeError('Output shape computation not implemented for type: %s' % node.kind)\n\n\nclass NodeDispatchError(KaffeError):\n\n    pass\n\n\nclass NodeDispatch(object):\n\n    @staticmethod\n    def get_handler_name(node_kind):\n        if len(node_kind) <= 4:\n            # A catch-all for things like ReLU and tanh\n            return node_kind.lower()\n        # Convert from CamelCase to under_scored\n        name = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', node_kind)\n        return re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', name).lower()\n\n    def get_handler(self, node_kind, prefix):\n        name = self.get_handler_name(node_kind)\n        name = '_'.join((prefix, name))\n        try:\n            return getattr(self, name)\n        except AttributeError:\n            raise NodeDispatchError('No handler found for node kind: %s (expected: %s)' %\n                                    (node_kind, name))\n\n\nclass LayerAdapter(object):\n\n    def __init__(self, layer, kind):\n        self.layer = layer\n        self.kind = kind\n\n    @property\n    def parameters(self):\n        name = NodeDispatch.get_handler_name(self.kind)\n        name = '_'.join((name, 'param'))\n        try:\n            return getattr(self.layer, name)\n        except AttributeError:\n            raise NodeDispatchError('Caffe parameters not found for layer kind: %s' % (self.kind))\n\n    @staticmethod\n    def get_kernel_value(scalar, repeated, idx, default=None):\n        if scalar:\n            return scalar\n        if repeated:\n            if isinstance(repeated, numbers.Number):\n                return repeated\n            if len(repeated) == 1:\n                # Same value applies to all spatial dimensions\n                return int(repeated[0])\n            assert idx < len(repeated)\n            # Extract the value for the given spatial dimension\n            return repeated[idx]\n        if default is None:\n            raise ValueError('Unable to determine kernel parameter!')\n        return default\n\n    @property\n    def kernel_parameters(self):\n        assert self.kind in (NodeKind.Convolution, NodeKind.Pooling)\n        params = self.parameters\n        k_h = self.get_kernel_value(params.kernel_h, params.kernel_size, 0)\n        k_w = self.get_kernel_value(params.kernel_w, params.kernel_size, 1)\n        s_h = self.get_kernel_value(params.stride_h, params.stride, 0, default=1)\n        s_w = self.get_kernel_value(params.stride_w, params.stride, 1, default=1)\n        p_h = self.get_kernel_value(params.pad_h, params.pad, 0, default=0)\n        p_w = self.get_kernel_value(params.pad_h, params.pad, 1, default=0)\n        return KernelParameters(k_h, k_w, s_h, s_w, p_h, p_w)\n\n\nKernelParameters = namedtuple('KernelParameters', ['kernel_h', 'kernel_w', 'stride_h', 'stride_w',\n                                                   'pad_h', 'pad_w'])\n"""
kaffe/shapes.py,0,"b'import math\nfrom collections import namedtuple\n\nfrom .errors import KaffeError\n\nTensorShape = namedtuple(\'TensorShape\', [\'batch_size\', \'channels\', \'height\', \'width\'])\n\n\ndef get_filter_output_shape(i_h, i_w, params, round_func):\n    o_h = (i_h + 2 * params.pad_h - params.kernel_h) / float(params.stride_h) + 1\n    o_w = (i_w + 2 * params.pad_w - params.kernel_w) / float(params.stride_w) + 1\n    return (int(round_func(o_h)), int(round_func(o_w)))\n\n\ndef get_strided_kernel_output_shape(node, round_func):\n    assert node.layer is not None\n    input_shape = node.get_only_parent().output_shape\n    o_h, o_w = get_filter_output_shape(input_shape.height, input_shape.width,\n                                       node.layer.kernel_parameters, round_func)\n    params = node.layer.parameters\n    has_c_o = hasattr(params, \'num_output\')\n    c = params.num_output if has_c_o else input_shape.channels\n    return TensorShape(input_shape.batch_size, c, o_h, o_w)\n\n\ndef shape_not_implemented(node):\n    raise NotImplementedError\n\n\ndef shape_identity(node):\n    assert len(node.parents) > 0\n    return node.parents[0].output_shape\n\n\ndef shape_scalar(node):\n    return TensorShape(1, 1, 1, 1)\n\n\ndef shape_data(node):\n    if node.output_shape:\n        # Old-style input specification\n        return node.output_shape\n    try:\n        # New-style input specification\n        return map(int, node.parameters.shape[0].dim)\n    except:\n        # We most likely have a data layer on our hands. The problem is,\n        # Caffe infers the dimensions of the data from the source (eg: LMDB).\n        # We want to avoid reading datasets here. Fail for now.\n        # This can be temporarily fixed by transforming the data layer to\n        # Caffe\'s ""input"" layer (as is usually used in the ""deploy"" version).\n        # TODO: Find a better solution for this.\n        raise KaffeError(\'Cannot determine dimensions of data layer.\\n\'\n                         \'See comments in function shape_data for more info.\')\n\n\ndef shape_mem_data(node):\n    params = node.parameters\n    return TensorShape(params.batch_size, params.channels, params.height, params.width)\n\n\ndef shape_concat(node):\n    axis = node.layer.parameters.axis\n    output_shape = None\n    for parent in node.parents:\n        if output_shape is None:\n            output_shape = list(parent.output_shape)\n        else:\n            output_shape[axis] += parent.output_shape[axis]\n    return tuple(output_shape)\n\n\ndef shape_convolution(node):\n    return get_strided_kernel_output_shape(node, math.floor)\n\n\ndef shape_pool(node):\n    return get_strided_kernel_output_shape(node, math.ceil)\n\n\ndef shape_inner_product(node):\n    input_shape = node.get_only_parent().output_shape\n    return TensorShape(input_shape.batch_size, node.layer.parameters.num_output, 1, 1)\n'"
kaffe/transformers.py,0,"b""'''\nA collection of graph transforms.\n\nA transformer is a callable that accepts a graph and returns a transformed version.\n'''\n\nimport numpy as np\n\nfrom .caffe import get_caffe_resolver, has_pycaffe\nfrom .errors import KaffeError, print_stderr\nfrom .layers import NodeKind\n\n\nclass DataInjector(object):\n    '''\n    Associates parameters loaded from a .caffemodel file with their corresponding nodes.\n    '''\n\n    def __init__(self, def_path, data_path):\n        # The .prototxt file defining the graph\n        self.def_path = def_path\n        # The .caffemodel file containing the learned parameters\n        self.data_path = data_path\n        # Set to true if the fallback protocol-buffer based backend was used\n        self.did_use_pb = False\n        # A list containing (layer name, parameters) tuples\n        self.params = None\n        # Load the parameters\n        self.load()\n\n    def load(self):\n        if has_pycaffe():\n            self.load_using_caffe()\n        else:\n            self.load_using_pb()\n\n    def load_using_caffe(self):\n        caffe = get_caffe_resolver().caffe\n        net = caffe.Net(self.def_path, self.data_path, caffe.TEST)\n        data = lambda blob: blob.data\n        self.params = [(k, map(data, v)) for k, v in net.params.items()]\n\n    def load_using_pb(self):\n        data = get_caffe_resolver().NetParameter()\n        data.MergeFromString(open(self.data_path, 'rb').read())\n        pair = lambda layer: (layer.name, self.normalize_pb_data(layer))\n        layers = data.layers or data.layer\n        self.params = [pair(layer) for layer in layers if layer.blobs]\n        self.did_use_pb = True\n\n    def normalize_pb_data(self, layer):\n        transformed = []\n        for blob in layer.blobs:\n            if len(blob.shape.dim):\n                dims = blob.shape.dim\n                c_o, c_i, h, w = map(int, [1] * (4 - len(dims)) + list(dims))\n            else:\n                c_o = blob.num\n                c_i = blob.channels\n                h = blob.height\n                w = blob.width\n            data = np.array(blob.data, dtype=np.float32).reshape(c_o, c_i, h, w)\n            transformed.append(data)\n        return transformed\n\n    def adjust_parameters(self, node, data):\n        if not self.did_use_pb:\n            return data\n        # When using the protobuf-backend, each parameter initially has four dimensions.\n        # In certain cases (like FC layers), we want to eliminate the singleton dimensions.\n        # This implementation takes care of the common cases. However, it does leave the\n        # potential for future issues.\n        # The Caffe-backend does not suffer from this problem.\n        data = list(data)\n        squeeze_indices = [1]  # Squeeze biases.\n        if node.kind == NodeKind.InnerProduct:\n            squeeze_indices.append(0)  # Squeeze FC.\n        for idx in squeeze_indices:\n            data[idx] = np.squeeze(data[idx])\n        return data\n\n    def __call__(self, graph):\n        for layer_name, data in self.params:\n            if layer_name in graph:\n                node = graph.get_node(layer_name)\n                node.data = self.adjust_parameters(node, data)\n            else:\n                print_stderr('Ignoring parameters for non-existent layer: %s' % layer_name)\n        return graph\n\n\nclass DataReshaper(object):\n\n    def __init__(self, mapping, replace=True):\n        # A dictionary mapping NodeKind to the transposed order.\n        self.mapping = mapping\n        # The node kinds eligible for reshaping\n        self.reshaped_node_types = self.mapping.keys()\n        # If true, the reshaped data will replace the old one.\n        # Otherwise, it's set to the reshaped_data attribute.\n        self.replace = replace\n\n    def has_spatial_parent(self, node):\n        try:\n            parent = node.get_only_parent()\n            s = parent.output_shape\n            return s.height > 1 or s.width > 1\n        except KaffeError:\n            return False\n\n    def map(self, node_kind):\n        try:\n            return self.mapping[node_kind]\n        except KeyError:\n            raise KaffeError('Ordering not found for node kind: {}'.format(node_kind))\n\n    def __call__(self, graph):\n        for node in graph.nodes:\n            if node.data is None:\n                continue\n            if node.kind not in self.reshaped_node_types:\n                # Check for 2+ dimensional data\n                if any(len(tensor.shape) > 1 for tensor in node.data):\n                    print_stderr('Warning: parmaters not reshaped for node: {}'.format(node))\n                continue\n            transpose_order = self.map(node.kind)\n            weights = node.data[0]\n            if (node.kind == NodeKind.InnerProduct) and self.has_spatial_parent(node):\n                # The FC layer connected to the spatial layer needs to be\n                # re-wired to match the new spatial ordering.\n                in_shape = node.get_only_parent().output_shape\n                fc_shape = weights.shape\n                output_channels = fc_shape[0]\n                weights = weights.reshape((output_channels, in_shape.channels, in_shape.height,\n                                           in_shape.width))\n                weights = weights.transpose(self.map(NodeKind.Convolution))\n                node.reshaped_data = weights.reshape(fc_shape[transpose_order[0]],\n                                                     fc_shape[transpose_order[1]])\n            else:\n                node.reshaped_data = weights.transpose(transpose_order)\n\n        if self.replace:\n            for node in graph.nodes:\n                if hasattr(node, 'reshaped_data'):\n                    # Set the weights\n                    node.data[0] = node.reshaped_data\n                    del node.reshaped_data\n        return graph\n\n\nclass SubNodeFuser(object):\n    '''\n    An abstract helper for merging a single-child with its single-parent.\n    '''\n\n    def __call__(self, graph):\n        nodes = graph.nodes\n        fused_nodes = []\n        for node in nodes:\n            if len(node.parents) != 1:\n                # We're only fusing nodes with single parents\n                continue\n            parent = node.get_only_parent()\n            if len(parent.children) != 1:\n                # We can only fuse a node if its parent's\n                # value isn't used by any other node.\n                continue\n            if not self.is_eligible_pair(parent, node):\n                continue\n            # Rewrite the fused node's children to its parent.\n            for child in node.children:\n                child.parents.remove(node)\n                parent.add_child(child)\n            # Disconnect the fused node from the graph.\n            parent.children.remove(node)\n            fused_nodes.append(node)\n            # Let the sub-class merge the fused node in any arbitrary way.\n            self.merge(parent, node)\n        transformed_nodes = [node for node in nodes if node not in fused_nodes]\n        return graph.replaced(transformed_nodes)\n\n    def is_eligible_pair(self, parent, child):\n        '''Returns true if this parent/child pair is eligible for fusion.'''\n        raise NotImplementedError('Must be implemented by subclass.')\n\n    def merge(self, parent, child):\n        '''Merge the child node into the parent.'''\n        raise NotImplementedError('Must be implemented by subclass')\n\n\nclass ReLUFuser(SubNodeFuser):\n    '''\n    Fuses rectified linear units with their parent nodes.\n    '''\n\n    def __init__(self, allowed_parent_types=None):\n        # Fuse ReLUs when the parent node is one of the given types.\n        # If None, all node types are eligible.\n        self.allowed_parent_types = allowed_parent_types\n\n    def is_eligible_pair(self, parent, child):\n        return ((self.allowed_parent_types is None or parent.kind in self.allowed_parent_types) and\n                child.kind == NodeKind.ReLU)\n\n    def merge(self, parent, _):\n        parent.metadata['relu'] = True\n\n\nclass BatchNormScaleBiasFuser(SubNodeFuser):\n    '''\n    The original batch normalization paper includes two learned\n    parameters: a scaling factor \\gamma and a bias \\beta.\n    Caffe's implementation does not include these two. However, it is commonly\n    replicated by adding a scaling+bias layer immidiately after the batch norm.\n\n    This fuser merges the scaling+bias layer with the batch norm.\n    '''\n\n    def is_eligible_pair(self, parent, child):\n        return (parent.kind == NodeKind.BatchNorm and child.kind == NodeKind.Scale and\n                child.parameters.axis == 1 and child.parameters.bias_term == True)\n\n    def merge(self, parent, child):\n        parent.scale_bias_node = child\n\n\nclass BatchNormPreprocessor(object):\n    '''\n    Prescale batch normalization parameters.\n    Concatenate gamma (scale) and beta (bias) terms if set.\n    '''\n\n    def __call__(self, graph):\n        for node in graph.nodes:\n            if node.kind != NodeKind.BatchNorm:\n                continue\n            assert node.data is not None\n            assert len(node.data) == 3\n            mean, variance, scale = node.data\n            # Prescale the stats\n            scaling_factor = 1.0 / scale if scale != 0 else 0\n            mean *= scaling_factor\n            variance *= scaling_factor\n            # Replace with the updated values\n            node.data = [mean, variance]\n            if hasattr(node, 'scale_bias_node'):\n                # Include the scale and bias terms\n                gamma, beta = node.scale_bias_node.data\n                node.data += [gamma, beta]\n        return graph\n\n\nclass NodeRenamer(object):\n    '''\n    Renames nodes in the graph using a given unary function that\n    accepts a node and returns its new name.\n    '''\n\n    def __init__(self, renamer):\n        self.renamer = renamer\n\n    def __call__(self, graph):\n        for node in graph.nodes:\n            node.name = self.renamer(node)\n        return graph\n\n\nclass ParameterNamer(object):\n    '''\n    Convert layer data arrays to a dictionary mapping parameter names to their values.\n    '''\n\n    def __call__(self, graph):\n        for node in graph.nodes:\n            if node.data is None:\n                continue\n            if node.kind in (NodeKind.Convolution, NodeKind.InnerProduct):\n                names = ('weights',)\n                if node.parameters.bias_term:\n                    names += ('biases',)\n            elif node.kind == NodeKind.BatchNorm:\n                names = ('moving_mean', 'moving_variance')\n                if len(node.data) == 4:\n                    names += ('gamma', 'beta')\n            else:\n                print_stderr('WARNING: Unhandled parameters: {}'.format(node.kind))\n                continue\n            assert len(names) == len(node.data)\n            node.data = dict(zip(names, node.data))\n        return graph\n"""
nndistance/__init__.py,0,b'import tf_nndistance\n'
nndistance/tf_nndistance.py,11,"b""import tensorflow as tf\nfrom tensorflow.python.framework import ops\nnn_distance_module=tf.load_op_library('./nndistance/tf_nndistance_so.so')\n\ndef nn_distance(xyz1,xyz2):\n\t'''\nComputes the distance of nearest neighbors for a pair of point clouds\ninput: xyz1: (batch_size,#points_1,3)  the first point cloud\ninput: xyz2: (batch_size,#points_2,3)  the second point cloud\noutput: dist1: (batch_size,#point_1)   distance from first to second\noutput: idx1:  (batch_size,#point_1)   nearest neighbor from first to second\noutput: dist2: (batch_size,#point_2)   distance from second to first\noutput: idx2:  (batch_size,#point_2)   nearest neighbor from second to first\n\t'''\n        return nn_distance_module.nn_distance(xyz1,xyz2)\n#@tf.RegisterShape('NnDistance')\n#def _nn_distance_shape(op):\n\t#shape1=op.inputs[0].get_shape().with_rank(3)\n\t#shape2=op.inputs[1].get_shape().with_rank(3)\n\t#return [tf.TensorShape([shape1.dims[0],shape1.dims[1]]),tf.TensorShape([shape1.dims[0],shape1.dims[1]]),\n\t\t#tf.TensorShape([shape2.dims[0],shape2.dims[1]]),tf.TensorShape([shape2.dims[0],shape2.dims[1]])]\n@ops.RegisterGradient('NnDistance')\ndef _nn_distance_grad(op,grad_dist1,grad_idx1,grad_dist2,grad_idx2):\n\txyz1=op.inputs[0]\n\txyz2=op.inputs[1]\n\tidx1=op.outputs[1]\n\tidx2=op.outputs[3]\n\treturn nn_distance_module.nn_distance_grad(xyz1,xyz2,grad_dist1,idx1,grad_dist2,idx2)\n\n\nif __name__=='__main__':\n\timport numpy as np\n\timport random\n\timport time\n\tfrom tensorflow.python.ops.gradient_checker import compute_gradient\n\trandom.seed(100)\n\tnp.random.seed(100)\n\twith tf.Session('') as sess:\n\t\txyz1=np.random.randn(32,16384,3).astype('float32')\n\t\txyz2=np.random.randn(32,1024,3).astype('float32')\n\t\t#with tf.device('/gpu:0'):\n\t\tif True:\n\t\t\tinp1=tf.Variable(xyz1)\n\t\t\tinp2=tf.constant(xyz2)\n\t\t\treta,retb,retc,retd=nn_distance(inp1,inp2)\n\t\t\tloss=tf.reduce_sum(reta)+tf.reduce_sum(retc)\n\t\t\ttrain=tf.train.GradientDescentOptimizer(learning_rate=0.05).minimize(loss)\n\t\tsess.run(tf.global_variables_initializer())\n\t\tt0=time.time()\n\t\tt1=t0\n\t\tbest=1e100\n\t\tfor i in xrange(100):\n\t\t\ttrainloss,_=sess.run([loss,train])\n\t\t\tnewt=time.time()\n\t\t\tbest=min(best,newt-t1)\n\t\t\tprint i,trainloss,(newt-t0)/(i+1),best\n\t\t\tt1=newt\n\t\t#print sess.run([inp1,retb,inp2,retd])\n\t\t#grads=compute_gradient([inp1,inp2],[(16,32,3),(16,32,3)],loss,(1,),[xyz1,xyz2])\n\t\t#for i,j in grads:\n\t\t\t#print i.shape,j.shape,np.mean(np.abs(i-j)),np.mean(np.abs(i)),np.mean(np.abs(j))\n\t\t#for i in xrange(10):\n\t\t\t#t0=time.time()\n\t\t\t#a,b,c,d=sess.run([reta,retb,retc,retd],feed_dict={inp1:xyz1,inp2:xyz2})\n\t\t\t#print 'time',time.time()-t0\n\t\t#print a.shape,b.shape,c.shape,d.shape\n\t\t#print a.dtype,b.dtype,c.dtype,d.dtype\n\t\t#samples=np.array(random.sample(range(xyz2.shape[1]),100),dtype='int32')\n\t\t#dist1=((xyz1[:,samples,None,:]-xyz2[:,None,:,:])**2).sum(axis=-1).min(axis=-1)\n\t\t#idx1=((xyz1[:,samples,None,:]-xyz2[:,None,:,:])**2).sum(axis=-1).argmin(axis=-1)\n\t\t#print np.abs(dist1-a[:,samples]).max()\n\t\t#print np.abs(idx1-b[:,samples]).max()\n\t\t#dist2=((xyz2[:,samples,None,:]-xyz1[:,None,:,:])**2).sum(axis=-1).min(axis=-1)\n\t\t#idx2=((xyz2[:,samples,None,:]-xyz1[:,None,:,:])**2).sum(axis=-1).argmin(axis=-1)\n\t\t#print np.abs(dist2-c[:,samples]).max()\n\t\t#print np.abs(idx2-d[:,samples]).max()\n\n"""
pool/obj2egg.py,0,"b'#!/usr/bin/python\n""""""\n    This Version: $Id: obj2egg.py,v 1.7 2008/05/26 17:42:53 andyp Exp $\n    Info: info >at< pfastergames.com\n\n    Extended from: http://panda3d.org/phpbb2/viewtopic.php?t=3378\n    .___..__ .___.___.___.__..__ .  .\n      |  [__)[__ [__ [__ |  |[__)|\\/|\n      |  |  \\[___[___|   |__||  \\|  |\n    obj2egg.py [n##][b][t][s] filename1.obj ...\n        -n regenerate normals with # degree smoothing\n            exaple -n30  (normals at less 30 degrees will be smoothed)\n        -b make binarmals\n        -t make tangents\n        -s show in pview\n\n    licensed under WTFPL (http://sam.zoy.org/wtfpl/)\n""""""\n\nfrom pandac.PandaModules import *\nimport math\nimport string\nimport getopt\nimport sys, os\n\n\ndef floats(float_list):\n    """"""coerce a list of strings that represent floats into a list of floats""""""\n    return [ float(number) for number in float_list ]\n\ndef ints(int_list):\n    """"""coerce a list of strings that represent integers into a list of integers""""""\n    return [ int(number) for number in int_list ]\n\n\nclass ObjMaterial:\n    """"""a wavefront material""""""\n    def __init__(self):\n        self.filename = None\n        self.name = ""default""\n        self.eggdiffusetexture = None\n        self.eggmaterial = None\n        self.attrib = {}\n        self.attrib[""Ns""] = 100.0\n        self.attrib[""d""] = 1.0\n        self.attrib[""illum""] = 2\n        # ""magenta""\n        self.attrib[""Kd""] = [1.0, 1.0, 1.0]\n        self.attrib[""Ka""] = [0.0, 0.0, 0.0]\n        self.attrib[""Ks""] = [0.0, 0.0, 0.0]\n        self.attrib[""Ke""] = [0.0, 0.0, 0.0]\n\n    def put(self, key, value):\n        self.attrib[key] = value\n        return self\n\n    def get(self, key):\n        if self.attrib.has_key(key):\n            return self.attrib[key]\n        return None\n\n    def has_key(self, key):\n        return self.attrib.has_key(key)\n\n    def isTextured(self):\n        # for k in (""map_Kd"", ""map_Bump"", ""map_Ks""):    <-- NOT YET\n        if self.attrib.has_key(""map_Kd""):\n            return True;\n        return False;\n\n    def getEggTexture(self):\n        if self.eggdiffusetexture:\n            return self.eggdiffusetexture\n        if not self.isTextured():\n            return None\n        m = EggTexture(self.name + ""_diffuse"", self.get(""map_Kd""))\n        m.setFormat(EggTexture.FRgb)\n        m.setMagfilter(EggTexture.FTLinearMipmapLinear)\n        m.setMinfilter(EggTexture.FTLinearMipmapLinear)\n        m.setWrapU(EggTexture.WMRepeat)\n        m.setWrapV(EggTexture.WMRepeat)\n        self.eggdiffusetexture = m\n        return self.eggdiffusetexture\n\n    def getEggMaterial(self):\n        if self.eggmaterial:\n            return self.eggmaterial\n        m = EggMaterial(self.name + ""_mat"")\n        # XXX TODO: add support for specular, and obey illum setting\n        # XXX as best as we can\n        rgb = self.get(""Kd"")\n        if rgb is not None:\n            m.setDiff(Vec4(rgb[0], rgb[1], rgb[2], 1.0))\n        rgb = self.get(""Ka"")\n        if rgb is not None:\n            m.setAmb(Vec4(rgb[0], rgb[1], rgb[2], 1.0))\n        rgb = self.get(""Ks"")\n        if rgb is not None:\n            m.setSpec(Vec4(rgb[0], rgb[1], rgb[2], 1.0))\n        ns = self.get(""Ns"")\n        if ns is not None:\n            m.setShininess(ns)\n        self.eggmaterial = m\n        return self.eggmaterial\n\nclass MtlFile:\n    """"""an object representing all Wavefront materials in a .mtl file""""""\n    def __init__(self, filename=None):\n        self.filename = None\n        self.materials = {}\n        self.comments = {}\n        if filename is not None:\n            self.read(filename)\n\n    def read(self, filename, verbose=False):\n        self.filename = filename\n        self.materials = {}\n        self.comments = {}\n        try:\n            file = open(filename)\n        except:\n            return self\n        linenumber = 0\n        mat = None\n        for line in file.readlines():\n            line = line.strip()\n            linenumber = linenumber + 1\n            if not line:\n                continue\n            if line[0] == \'#\':\n                self.comments[linenumber] = line\n                print line\n                continue\n            tokens = line.split()\n            if not tokens:\n                continue\n            if verbose: print ""tokens[0]:"", tokens\n            if tokens[0] == ""newmtl"":\n                mat = ObjMaterial()\n                mat.filename = filename\n                mat.name = tokens[1]\n                self.materials[mat.name] = mat\n                if verbose: print ""newmtl:"", mat.name\n                continue\n            if tokens[0] in (""Ns"", ""d"", ""Tr""):\n                # ""d factor"" - specifies the dissovle for the current material,\n                #              1.0 is full opaque\n                # ""Ns exponent"" - specifies the specular exponent.  A high exponent\n                #               results in a tight, concentrated highlight.\n                mat.put(tokens[0], float(tokens[1]))\n                continue\n            if tokens[0] in (""illum""):\n                # according to http://www.fileformat.info/format/material/\n                # 0 = Color on and Ambient off\n                # 1 = Color on and Ambient on\n                # 2 = Highlight on\n                # 3 = Reflection on and Ray trace on\n                # 4 = Transparency: Glass on, Reflection: Ray trace on\n                # 5 = Reflection: Fesnel on and Ray trace on\n                # 6 = Transparency: Refraction on, Reflection: Fresnel off and Ray trace on\n                # 7 = Transparency: Refraction on, Refelction: Fresnel on and Ray Trace on\n                # 8 = Reflection on and Ray trace off\n                # 9 = Transparency: Glass on, Reflection: Ray trace off\n                # 10 = Casts shadows onto invisible surfaces\n                mat.put(tokens[0], int(tokens[1]))\n                continue\n            if tokens[0] in (""Kd"", ""Ka"", ""Ks"", ""Ke""):\n                mat.put(tokens[0], floats(tokens[1:]))\n                continue\n            if tokens[0] in (""map_Kd"", ""map_Bump"", ""map_Ks"", ""map_bump"", ""bump""):\n                # Ultimate Unwrap 3D Pro emits these:\n                # map_Kd == diffuse\n                # map_Bump == bump\n                # map_Ks == specular\n                mat.put(tokens[0], pathify(tokens[1]))\n                if verbose: print ""map:"", mat.name, tokens[0], mat.get(tokens[0])\n                continue\n            if tokens[0] in (""Ni""):\n                # blender\'s .obj exporter can emit this ""Ni 1.000000""\n                mat.put(tokens[0], float(tokens[1]))\n                continue\n            print ""file \\""%s\\"": line %d: unrecognized:"" % (filename, linenumber), tokens\n        file.close()\n        if verbose: print ""%d materials"" % len(self.materials), ""loaded from"", filename\n        return self\n\nclass ObjFile:\n    """"""a representation of a wavefront .obj file""""""\n    def __init__(self, filename=None):\n        self.filename = None\n        self.objects = [""defaultobject""]\n        self.groups = [""defaultgroup""]\n        self.points = []\n        self.uvs = []\n        self.normals = []\n        self.faces = []\n        self.polylines = []\n        self.matlibs = []\n        self.materialsbyname = {}\n        self.comments = {}\n        self.currentobject = self.objects[0]\n        self.currentgroup = self.groups[0]\n        self.currentmaterial = None\n        if filename is not None:\n            self.read(filename)\n\n    def read(self, filename, verbose=False):\n        if verbose: print ""ObjFile.read:"", ""filename:"", filename\n        self.filename = filename\n        self.objects = [""defaultobject""]\n        self.groups = [""defaultgroup""]\n        self.points = []\n        self.uvs = []\n        self.normals = []\n        self.faces = []\n        self.polylines = []\n        self.matlibs = []\n        self.materialsbyname = {}\n        self.comments = {}\n        self.currentobject = self.objects[0]\n        self.currentgroup = self.groups[0]\n        self.currentmaterial = None\n        try:\n            file = open(filename)\n        except:\n            return self\n        linenumber = 0\n        for line in file.readlines():\n            line = line.strip()\n            linenumber = linenumber + 1\n            if not line:\n                continue\n            if line[0] == \'#\':\n                self.comments[linenumber] = line\n                print line\n                continue\n            tokens = line.split()\n            if not tokens:\n                continue\n            if tokens[0] == ""mtllib"":\n                if verbose: print ""mtllib:"", tokens[1:]\n                mtllib = MtlFile(tokens[1])\n                # if verbose: print mtllib\n                self.matlibs.append(mtllib)\n                self.indexmaterials(mtllib)\n                continue\n            if tokens[0] == ""g"":\n                if verbose: print ""g:"", tokens[1:]\n                self.__newgroup("""".join(tokens[1:]))\n                continue\n            if tokens[0] == ""o"":\n                if verbose: print ""o:"", tokens[1:]\n                self.__newobject("""".join(tokens[1:]))\n                continue\n            if tokens[0] == ""usemtl"":\n                if verbose: print ""usemtl:"", tokens[1:]\n                self.__usematerial(tokens[1])\n                continue\n            if tokens[0] == ""v"":\n                if verbose: print ""v:"", tokens[1:]\n                self.__newv(tokens[1:])\n                continue\n            if tokens[0] == ""vn"":\n                if verbose: print ""vn:"", tokens[1:]\n                self.__newnormal(tokens[1:])\n                continue\n            if tokens[0] == ""vt"":\n                if verbose: print ""vt:"", tokens[1:]\n                self.__newuv(tokens[1:])\n                continue\n            if tokens[0] == ""f"":\n                if verbose: print ""f:"", tokens[1:]\n                self.__newface(tokens[1:])\n                continue\n            if tokens[0] == ""s"":\n                # apparently, this enables/disables smoothing\n                print ""%s:%d:"" % (filename, linenumber), ""ignoring:"", tokens\n                continue\n            if tokens[0] == ""l"":\n                if verbose: print ""l:"", tokens[1:]\n                self.__newpolyline(tokens[1:])\n                continue\n            print ""%s:%d:"" % (filename, linenumber), ""unknown:"", tokens\n        file.close()\n        return self\n\n    def __vertlist(self, lst):\n        res = []\n        for vert in lst:\n            vinfo = vert.split(""/"")\n            vlen = len(vinfo)\n            vertex = {\'v\':None, \'vt\':None, \'vn\':None}\n            if vlen == 1:\n                vertex[\'v\'] = int(vinfo[0])\n            elif vlen == 2:\n                if vinfo[0] != \'\':\n                    vertex[\'v\'] = int(vinfo[0])\n                if vinfo[1] != \'\':\n                    vertex[\'vt\'] = int(vinfo[1])\n            elif vlen == 3:\n                if vinfo[0] != \'\':\n                    vertex[\'v\'] = int(vinfo[0])\n                if vinfo[1] != \'\':\n                    vertex[\'vt\'] = int(vinfo[1])\n                if vinfo[2] != \'\':\n                    vertex[\'vn\'] = int(vinfo[2])\n            else:\n                print ""aborting...""\n                raise UNKNOWN, res\n            res.append(vertex)\n        if False: print res\n        return res\n\n    def __enclose(self, lst):\n        mdata = (self.currentobject, self.currentgroup, self.currentmaterial)\n        return (lst, mdata)\n\n    def __newpolyline(self, l):\n        polyline = self.__vertlist(l)\n        if False: print ""__newline:"", polyline\n        self.polylines.append(self.__enclose(polyline))\n        return self\n\n    def __newface(self, f):\n        face = self.__vertlist(f)\n        if False: print face\n        self.faces.append(self.__enclose(face))\n        return self\n\n    def __newuv(self, uv):\n        self.uvs.append(floats(uv))\n        return self\n\n    def __newnormal(self, normal):\n        self.normals.append(floats(normal))\n        return self\n\n    def __newv(self, v):\n        # capture the current metadata with vertices\n        vdata = floats(v)\n        mdata = (self.currentobject, self.currentgroup, self.currentmaterial)\n        vinfo = (vdata, mdata)\n        self.points.append(vinfo)\n        return self\n\n    def indexmaterials(self, mtllib, verbose=False):\n        # traverse the materials defined in mtllib, indexing\n        # them by name.\n        for mname in mtllib.materials:\n            mobj = mtllib.materials[mname]\n            self.materialsbyname[mobj.name] = mobj\n        if verbose: \n            print ""indexmaterials:"", mtllib.filename, ""materials:"", self.materialsbyname.keys()\n        return self\n\n    def __closeobject(self):\n        self.currentobject = ""defaultobject""\n        return self\n\n    def __newobject(self, object):\n        self.__closeobject()\n        if False: print ""__newobject:"", ""object:"", object\n        self.currentobject = object\n        self.objects.append(object)\n        return self\n\n    def __closegroup(self):\n        self.currentgroup = ""defaultgroup""\n        return self\n\n    def __newgroup(self, group):\n        self.__closegroup()\n        if False: print ""__newgroup:"", ""group:"", group\n        self.currentgroup = group\n        self.groups.append(group)\n        return self\n\n    def __usematerial(self, material):\n        if False: print ""__usematerial:"", ""material:"", material\n        if self.materialsbyname.has_key(material):\n            self.currentmaterial = material\n        else:\n            print ""warning:"", ""__usematerial:"", ""unknown material:"", material\n        return self\n\n    def __itemsby(self, itemlist, objname, groupname):\n        res = []\n        for item in itemlist:\n            vlist, mdata = item\n            wobj, wgrp, wmat = mdata\n            if (wobj == objname) and (wgrp == groupname):\n                res.append(item)\n        return res\n\n    def __facesby(self, objname, groupname):\n        return self.__itemsby(self.faces, objname, groupname)\n\n    def __linesby(self, objname, groupname):\n        return self.__itemsby(self.polylines, objname, groupname)\n\n    def __eggifyverts(self, eprim, evpool, vlist):\n        for vertex in vlist:\n            ixyz = vertex[\'v\']\n            vinfo = self.points[ixyz-1]\n            vxyz, vmeta = vinfo\n            ev = EggVertex()\n            ev.setPos(Point3D(vxyz[0], vxyz[1], vxyz[2]))\n            iuv = vertex[\'vt\']\n            if iuv is not None:\n                vuv = self.uvs[iuv-1]\n                ev.setUv(Point2D(vuv[0], vuv[1]))\n            inormal = vertex[\'vn\']\n            if inormal is not None:\n                vn = self.normals[inormal-1]\n                ev.setNormal(Vec3D(vn[0], vn[1], vn[2]))\n            evpool.addVertex(ev)\n            eprim.addVertex(ev)\n        return self\n\n    def __eggifymats(self, eprim, wmat):\n        if self.materialsbyname.has_key(wmat):\n            mtl = self.materialsbyname[wmat]\n            if mtl.isTextured():\n                eprim.setTexture(mtl.getEggTexture())\n                # NOTE: it looks like you almost always want to setMaterial()\n                #       for textured polys.... [continued below...]\n                eprim.setMaterial(mtl.getEggMaterial())\n            rgb = mtl.get(""Kd"")\n            if rgb is not None:\n                # ... and some untextured .obj\'s store the color of the\n                # material # in the Kd settings...\n                eprim.setColor(Vec4(rgb[0], rgb[1], rgb[2], 1.0))\n            # [continued...] but you may *not* always want to assign\n            # materials to untextured polys...  hmmmm.\n            if False:\n                eprim.setMaterial(mtl.getEggMaterial())\n        return self\n\n    def __facestoegg(self, egg, objname, groupname):\n        selectedfaces = self.__facesby(objname, groupname)\n        if len(selectedfaces) == 0:\n            return self\n        eobj = EggGroup(objname)\n        egg.addChild(eobj)\n        egrp = EggGroup(groupname)\n        eobj.addChild(egrp)\n        evpool = EggVertexPool(groupname)\n        egrp.addChild(evpool)\n        for face in selectedfaces:\n            vlist, mdata = face\n            wobj, wgrp, wmat = mdata\n            epoly = EggPolygon()\n            egrp.addChild(epoly)\n            self.__eggifymats(epoly, wmat)\n            self.__eggifyverts(epoly, evpool, vlist)\n        #; each matching face\n        return self\n\n    def __polylinestoegg(self, egg, objname, groupname):\n        selectedlines = self.__linesby(objname, groupname)\n        if len(selectedlines) == 0:\n            return self\n        eobj = EggGroup(objname)\n        egg.addChild(eobj)\n        egrp = EggGroup(groupname)\n        eobj.addChild(egrp)\n        evpool = EggVertexPool(groupname)\n        egrp.addChild(evpool)\n        for line in selectedlines:\n            vlist, mdata = line\n            wobj, wgrp, wmat = mdata\n            eline = EggLine()\n            egrp.addChild(eline)\n            self.__eggifymats(eline, wmat)\n            self.__eggifyverts(eline, evpool, vlist)\n        #; each matching line\n        return self\n\n    def toEgg(self, verbose=True):\n        if verbose: print ""converting...""\n        # make a new egg\n        egg = EggData()\n        # convert polygon faces\n        if len(self.faces) > 0:\n            for objname in self.objects:\n                for groupname in self.groups:\n                    self.__facestoegg(egg, objname, groupname)\n        # convert polylines\n        if len(self.polylines) > 0:\n            for objname in self.objects:\n                for groupname in self.groups:\n                    self.__polylinestoegg(egg, objname, groupname)\n        return egg\n\ndef pathify(path):\n    if os.path.isfile(path):\n        return path\n    # if it was written on win32, it may have \\\'s in it, and\n    # also a full rather than relative pathname (Hexagon does this... ick)\n    orig = path\n    path = path.lower()\n    path = path.replace(""\\\\"", ""/"")\n    h, t = os.path.split(path)\n    if os.path.isfile(t):\n        return t\n    print ""warning: can\'t make sense of this map file name:"", orig\n    return t\n    \ndef main(argv=None):\n    if argv is None:\n        argv = sys.argv\n    try:\n        opts, args = getopt.getopt(argv[1:], ""hn:bs"", [""help"", ""normals"", ""binormals"", ""show""])\n    except getopt.error, msg:\n        print msg\n        print __doc__\n        return 2\n    show = False\n    for o, a in opts:\n        if o in (""-h"", ""--help""):\n            print __doc__\n            return 0\n        elif o in (""-s"", ""--show""):\n            show = True\n    for infile in args:\n        try:\n            if "".obj"" not in infile:\n                print ""WARNING"", finfile, ""does not look like a valid obj file""\n                continue\n            obj = ObjFile(infile)\n            egg = obj.toEgg()\n            f, e = os.path.splitext(infile)\n            outfile = f + "".egg""\n            for o, a in opts:\n                if o in (""-n"", ""--normals""):\n                    egg.recomputeVertexNormals(float(a))\n                elif o in (""-b"", ""--binormals""):\n                    egg.recomputeTangentBinormal(GlobPattern(""""))\n            egg.removeUnusedVertices(GlobPattern(""""))\n            if True:\n                egg.triangulatePolygons(EggData.TConvex & EggData.TPolygon)\n            if True:\n                egg.recomputePolygonNormals()\n            egg.writeEgg(Filename(outfile))\n            if show:\n                os.system(""pview "" + outfile)\n        except Exception,e:\n            print e\n    return 0\n\nif __name__ == ""__main__"":\n    sys.exit(main())\n\n\n'"
pool/parts_scene.py,0,"b'from panda3d.egg import *\nfrom panda3d.core import *\nfrom obj2egg import ObjMaterial\nfrom copy import deepcopy\nimport numpy as np\nimport cv2\nimport copy\nfrom direct.gui.OnscreenImage import OnscreenImage\n\nimport sys\nimport os\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom utils import getCameraFromInfo\n\ndef calcDistance(point_1, point_2):\n  return pow(pow(point_1[0] - point_2[0], 2) + pow(point_1[1] - point_2[1], 2), 0.5)\n\ndef calcLineDim(line, lineWidth = -1):\n  if abs(line[0][0] - line[1][0]) > abs(line[0][1] - line[1][1]):\n    if lineWidth < 0 or abs(line[0][1] - line[1][1]) <= lineWidth:\n      return 0\n    pass\n  elif abs(line[0][0] - line[1][0]) < abs(line[0][1] - line[1][1]):\n    if lineWidth < 0 or abs(line[0][0] - line[1][0]) <= lineWidth:\n      return 1\n  else:\n    return -1\n  \nclass PartsScene():\n  def __init__(self, index):\n    #self.depth = cv2.imread(\'dump/\' + str(index) + \'_depth_pred.png\').astype(np.float32) / 255 * 10\n    self.depth = np.load(\'dump/\' + str(index) + \'_depth.npy\')\n    self.segmentation = np.load(\'dump/\' + str(index) + \'_segmentation.npy\')\n\n    width = 640\n    height = 480\n    self.depth = cv2.resize(self.depth, (width, height))\n    self.segmentation = cv2.resize(self.segmentation, (width, height), interpolation=cv2.INTER_NEAREST)\n    \n    self.planes = np.load(\'dump/\' + str(index) + \'_planes.npy\')\n    self.numPlanes = self.planes.shape[0]\n\n    self.imageTexture = ObjMaterial()\n    self.imageTexture.name = \'image\'\n    self.imageTexture.put(\'map_Kd\', \'dump/\' + str(index) + \'_image.png\')\n    self.width = self.depth.shape[1]\n    self.height = self.depth.shape[0]\n    self.info = np.load(\'dump/\' + str(index) + \'_info.npy\')\n    self.camera = getCameraFromInfo(self.info)\n\n    return\n\n  def addRectangle(self, parent):\n    planesGroup = EggGroup(\'planes\')\n    parent.addChild(planesGroup)\n    vp = EggVertexPool(\'plane_vertex\')\n    parent.addChild(vp)\n    \n    p0 = Point3D(-10, 1, 0)\n    p1 = Point3D(-10, 10, 0)\n    p2 = Point3D(10, 1, 0)\n    p3 = Point3D(10, 10, 0)    \n    # p0 = Point3D(-10, , 0)\n    # p1 = Point3D(-10, 100, 0)\n    # p3 = Point3D(10, 100, 0)\n    # p2 = Point3D(10, 90, 0)\n    \n    planeGroup = EggGroup(\'plane\')\n    planesGroup.addChild(planeGroup)\n    poly = EggPolygon()\n    planeGroup.addChild(poly)\n    vertex = EggVertex()\n    vertex.setPos(p0)\n    vertex.setUv(Point2D(0, 0))\n    poly.addVertex(vp.addVertex(vertex))\n    vertex = EggVertex()\n    vertex.setPos(p1)\n    vertex.setUv(Point2D(0, 1))\n    poly.addVertex(vp.addVertex(vertex))\n    vertex = EggVertex()\n    vertex.setPos(p2)\n    vertex.setUv(Point2D(1, 1))\n    poly.addVertex(vp.addVertex(vertex))\n\n    \n    poly = EggPolygon()\n    planeGroup.addChild(poly)\n    \n    vertex = EggVertex()\n    vertex.setPos(p1)\n    vertex.setUv(Point2D(0, 1))\n    poly.addVertex(vp.addVertex(vertex))\n    vertex = EggVertex()\n    vertex.setPos(p2)\n    vertex.setUv(Point2D(1, 1))\n    poly.addVertex(vp.addVertex(vertex))\n    vertex = EggVertex()\n    vertex.setPos(p3)\n    vertex.setUv(Point2D(1, 0))\n    poly.addVertex(vp.addVertex(vertex))\n\n    # vertex = EggVertex()\n    # vertex.setPos(p2)\n    # vertex.setUv(Point2D(1, 1))\n    # poly.addVertex(vp.addVertex(vertex))\n    \n    return\n    \n\n  def generateEggModel(self):\n  \n    self.planeNPs = []\n    self.planeCenters = []\n\n    print(self.numPlanes)\n    for planeIndex in xrange(self.numPlanes):\n      mask = (self.segmentation == planeIndex).astype(np.uint8) * 255\n      #cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', mask)\n      contours, _ = cv2.findContours(mask, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n      plane = self.planes[planeIndex]\n      planeD = np.linalg.norm(plane)\n      planeNormal = plane / planeD\n\n      for contour in contours:\n        data = EggData()\n        model = EggGroup(\'model\')\n        data.addChild(model)\n\n        vp = EggVertexPool(\'plane_vertex\')\n        model.addChild(vp)\n        \n        planeGroup = EggGroup(\'plane\')\n        model.addChild(planeGroup)\n        poly = EggPolygon()\n        planeGroup.addChild(poly)\n\n        poly.setTexture(self.imageTexture.getEggTexture())\n        poly.setMaterial(self.imageTexture.getEggMaterial())\n\n        contour = contour.astype(np.float32)\n        #u = (contour[:, 0, 0] - self.width / 2) / self.width * 640 / self.focalLength\n        #v = -(contour[:, 0, 1] - self.height / 2) / self.height * 480 / self.focalLength\n        u = (contour[:, 0, 0].astype(np.float32) / self.width * self.info[16] - self.camera[\'cx\']) / self.camera[\'fx\']\n        v = -(contour[:, 0, 1].astype(np.float32) / self.height * self.info[17] - self.camera[\'cy\']) / self.camera[\'fy\']\n\n        ranges = np.stack([u, np.ones(u.shape), v], axis=1)\n        depth = planeD / np.dot(ranges, planeNormal)\n        XYZ = ranges * np.expand_dims(depth, -1)\n        center = XYZ.mean(0)\n        #print(contour)\n        #print(XYZ)\n        #exit(1)\n        for vertexIndex, uv in enumerate(contour):\n          vertex = EggVertex()\n          X, Y, Z = XYZ[vertexIndex]\n          vertex.setPos(Point3D(X - center[0], Y - center[1], Z - center[2]))\n          u, v = uv[0]\n          vertex.setUv(Point2D(u / self.width, 1 - v / self.height))\n          poly.addVertex(vp.addVertex(vertex))\n          continue\n        scene = NodePath(loadEggData(data))\n        self.planeNPs.append(scene)\n        self.planeCenters.append(center)\n        continue\n    return self.planeNPs, self.planeCenters\n\n\n  def generateRectangle(self, parent):    \n    planesGroup = EggGroup(\'planes\')\n    parent.addChild(planesGroup)\n    vp = EggVertexPool(\'plane_vertex\')\n    parent.addChild(vp)\n\n    poly = EggPolygon()\n    planesGroup.addChild(poly)\n\n\n    w = 0.5\n    p0 = Point3D(-w / 2, 0, -w / 2)\n    p1 = Point3D(-w / 2, 0, w / 2)\n    p2 = Point3D(w / 2, 0, w / 2)\n    p3 = Point3D(w / 2, 0, -w / 2)    \n  \n    \n    poly.setTexture(self.plateTexture.getEggTexture())\n    poly.setMaterial(self.plateTexture.getEggMaterial())\n    vertex = EggVertex()\n    vertex.setPos(Point3D(0, 1, 0))\n    vertex.setUv(Point2D(0, 0))\n    poly.addVertex(vp.addVertex(vertex))\n    vertex = EggVertex()\n    vertex.setPos(Point3D(0, 1, 1))\n    vertex.setUv(Point2D(0, 1))\n    poly.addVertex(vp.addVertex(vertex))\n    vertex = EggVertex()\n    vertex.setPos(Point3D(1, 1, 1))\n    vertex.setUv(Point2D(1, 1))\n    poly.addVertex(vp.addVertex(vertex))\n    vertex = EggVertex()\n    vertex.setPos(Point3D(1, 1, 0))\n    vertex.setUv(Point2D(1, 0))\n    poly.addVertex(vp.addVertex(vertex))\n    \n    return\n\n  def addCollisionPolygons(self, scene):\n    \n    polygons = scene.findAllMatches(""**/plane"")\n    mesh = BulletTriangleMesh()      \n    for polygon in polygons:\n      #cNode = scene.attachNewNode(CollisionNode(\'plane_solid\'))\n      #cNode.node().addSolid(CollisionPolygon(polygon))\n      #polygon.setCollideMask(BitMask32.bit(1))\n      node = polygon.node()\n      print(node.getNumGeoms())\n      for i in xrange(node.getNumGeoms()):\n        geom = node.getGeom(i)\n        mesh.addGeom(geom)\n        continue\n      continue\n\n  def test(self, scene):\n    groundMask=BitMask32(0b1)\n    parent = NodePath(\'cGeomConversionParent\') \n    for c in incomingNode.findAllMatches(\'**/+GeomNode\'): \n        if relativeTo:\n            xform=c.getMat(relativeTo).xformPoint\n        else:\n            xform=c.getMat().xformPoint\n        gni = 0 \n        geomNode = c.node() \n        for g in range(geomNode.getNumGeoms()): \n            geom = geomNode.getGeom(g).decompose() \n            vdata = geom.getVertexData() \n            vreader = GeomVertexReader(vdata, \'vertex\') \n            cChild = CollisionNode(\'cGeom-%s-gni%i\' % (c.getName(), gni)) \n            \n            gni += 1 \n            for p in range(geom.getNumPrimitives()): \n                prim = geom.getPrimitive(p) \n                for p2 in range(prim.getNumPrimitives()): \n                    s = prim.getPrimitiveStart(p2) \n                    e = prim.getPrimitiveEnd(p2) \n                    v = [] \n                    for vi in range (s, e): \n                        vreader.setRow(prim.getVertex(vi)) \n                        v.append (xform(vreader.getData3f())) \n                    colPoly = CollisionPolygon(*v) \n                    cChild.addSolid(colPoly) \n\n            n=parent.attachNewNode (cChild) \n            #n.show()\n            \n    return parent\n'"
pool/plane_scene.py,0,"b'from panda3d.egg import *\nfrom panda3d.core import *\nfrom obj2egg import ObjMaterial\nfrom copy import deepcopy\nimport numpy as np\nimport cv2\nimport copy\nfrom direct.gui.OnscreenImage import OnscreenImage\n\nimport sys\nimport os\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom utils import getCameraFromInfo\n\ndef calcDistance(point_1, point_2):\n  return pow(pow(point_1[0] - point_2[0], 2) + pow(point_1[1] - point_2[1], 2), 0.5)\n\ndef calcLineDim(line, lineWidth = -1):\n  if abs(line[0][0] - line[1][0]) > abs(line[0][1] - line[1][1]):\n    if lineWidth < 0 or abs(line[0][1] - line[1][1]) <= lineWidth:\n      return 0\n    pass\n  elif abs(line[0][0] - line[1][0]) < abs(line[0][1] - line[1][1]):\n    if lineWidth < 0 or abs(line[0][0] - line[1][0]) <= lineWidth:\n      return 1\n  else:\n    return -1\n  \nclass PlaneScene():\n  def __init__(self, index):\n    #self.depth = cv2.imread(\'dump/\' + str(index) + \'_depth_pred.png\').astype(np.float32) / 255 * 10\n    self.depth = np.load(\'dump/\' + str(index) + \'_depth.npy\')\n    #cv2.imwrite(\'dump/alpha_0.5.png\', np.zeros(self.depth[:, :, 0].shape).astype(np.uint8))\n    self.segmentation = np.load(\'dump/\' + str(index) + \'_segmentation.npy\')\n\n    width = 640\n    height = 480\n    self.depth = cv2.resize(self.depth, (width, height))\n    self.segmentation = cv2.resize(self.segmentation, (width, height), interpolation=cv2.INTER_NEAREST)\n    self.planes = np.load(\'dump/\' + str(index) + \'_planes.npy\')\n    self.numPlanes = self.planes.shape[0]\n\n    self.imageTexture = ObjMaterial()\n    self.imageTexture.name = \'image\'\n    self.imageTexture.put(\'map_Kd\', \'dump/\' + str(index) + \'_image.png\')\n    self.width = self.depth.shape[1]\n    self.height = self.depth.shape[0]\n    self.info = np.load(\'dump/\' + str(index) + \'_info.npy\')\n    self.camera = getCameraFromInfo(self.info)\n    self.scene_index = index\n    self.calcHorizontalPlanes()\n    return\n\n  def addRectangle(self, parent):\n    planesGroup = EggGroup(\'planes\')\n    parent.addChild(planesGroup)\n    vp = EggVertexPool(\'plane_vertex\')\n    parent.addChild(vp)\n    \n    p0 = Point3D(-10, 1, 0)\n    p1 = Point3D(-10, 10, 0)\n    p2 = Point3D(10, 1, 0)\n    p3 = Point3D(10, 10, 0)    \n    # p0 = Point3D(-10, , 0)\n    # p1 = Point3D(-10, 100, 0)\n    # p3 = Point3D(10, 100, 0)\n    # p2 = Point3D(10, 90, 0)\n    \n    planeGroup = EggGroup(\'plane\')\n    planesGroup.addChild(planeGroup)\n    poly = EggPolygon()\n    planeGroup.addChild(poly)\n    vertex = EggVertex()\n    vertex.setPos(p0)\n    vertex.setUv(Point2D(0, 0))\n    poly.addVertex(vp.addVertex(vertex))\n    vertex = EggVertex()\n    vertex.setPos(p1)\n    vertex.setUv(Point2D(0, 1))\n    poly.addVertex(vp.addVertex(vertex))\n    vertex = EggVertex()\n    vertex.setPos(p2)\n    vertex.setUv(Point2D(1, 1))\n    poly.addVertex(vp.addVertex(vertex))\n\n    \n    poly = EggPolygon()\n    planeGroup.addChild(poly)\n    \n    vertex = EggVertex()\n    vertex.setPos(p1)\n    vertex.setUv(Point2D(0, 1))\n    poly.addVertex(vp.addVertex(vertex))\n    vertex = EggVertex()\n    vertex.setPos(p2)\n    vertex.setUv(Point2D(1, 1))\n    poly.addVertex(vp.addVertex(vertex))\n    vertex = EggVertex()\n    vertex.setPos(p3)\n    vertex.setUv(Point2D(1, 0))\n    poly.addVertex(vp.addVertex(vertex))\n\n    # vertex = EggVertex()\n    # vertex.setPos(p2)\n    # vertex.setUv(Point2D(1, 1))\n    # poly.addVertex(vp.addVertex(vertex))\n    \n    return\n    \n\n  def generatePlanes(self, parent):\n    planesGroup = EggGroup(\'planes\')\n    parent.addChild(planesGroup)\n    vp = EggVertexPool(\'plane_vertex\')\n    parent.addChild(vp)\n\n    for planeIndex in xrange(self.numPlanes):\n      mask = (self.segmentation == planeIndex).astype(np.uint8) * 255\n      cv2.imwrite(\'dump/mask_\' + str(planeIndex) + \'.png\', mask)\n      contours, _ = cv2.findContours(mask, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n      plane = self.planes[planeIndex]\n      planeD = np.linalg.norm(plane)\n      planeNormal = plane / planeD\n      for contour in contours:\n        planeGroup = EggGroup(\'plane\')\n        planesGroup.addChild(planeGroup)\n        poly = EggPolygon()\n        planeGroup.addChild(poly)\n\n        poly.setTexture(self.imageTexture.getEggTexture())\n        poly.setMaterial(self.imageTexture.getEggMaterial())\n\n        contour = contour.astype(np.float32)\n        u = (contour[:, 0, 0].astype(np.float32) / self.width * self.info[16] - self.camera[\'cx\']) / self.camera[\'fx\']\n        v = -(contour[:, 0, 1].astype(np.float32) / self.height * self.info[17] - self.camera[\'cy\']) / self.camera[\'fy\']\n        ranges = np.stack([u, np.ones(u.shape), v], axis=1)\n        depth = planeD / np.dot(ranges, planeNormal)\n        XYZ = ranges * np.expand_dims(depth, -1)\n        #print(contour)\n        #print(XYZ)\n        #exit(1)\n        for vertexIndex, uv in enumerate(contour):\n          vertex = EggVertex()\n          X, Y, Z = XYZ[vertexIndex]\n          vertex.setPos(Point3D(X, Y, Z))\n          u, v = uv[0]\n          vertex.setUv(Point2D(u / self.width, 1 - v / self.height))\n          poly.addVertex(vp.addVertex(vertex))\n          continue\n        continue\n      continue\n    return\n\n\n  def generateRectangle(self, parent):    \n    planesGroup = EggGroup(\'planes\')\n    parent.addChild(planesGroup)\n    vp = EggVertexPool(\'plane_vertex\')\n    parent.addChild(vp)\n\n    poly = EggPolygon()\n    planesGroup.addChild(poly)\n\n\n    w = 0.5\n    p0 = Point3D(-w / 2, 0, -w / 2)\n    p1 = Point3D(-w / 2, 0, w / 2)\n    p2 = Point3D(w / 2, 0, w / 2)\n    p3 = Point3D(w / 2, 0, -w / 2)    \n  \n    \n    poly.setTexture(self.plateTexture.getEggTexture())\n    poly.setMaterial(self.plateTexture.getEggMaterial())\n    vertex = EggVertex()\n    vertex.setPos(Point3D(0, 1, 0))\n    vertex.setUv(Point2D(0, 0))\n    poly.addVertex(vp.addVertex(vertex))\n    vertex = EggVertex()\n    vertex.setPos(Point3D(0, 1, 1))\n    vertex.setUv(Point2D(0, 1))\n    poly.addVertex(vp.addVertex(vertex))\n    vertex = EggVertex()\n    vertex.setPos(Point3D(1, 1, 1))\n    vertex.setUv(Point2D(1, 1))\n    poly.addVertex(vp.addVertex(vertex))\n    vertex = EggVertex()\n    vertex.setPos(Point3D(1, 1, 0))\n    vertex.setUv(Point2D(1, 0))\n    poly.addVertex(vp.addVertex(vertex))\n    \n    return\n\n  def addCollisionPolygons(self, scene):\n    \n    polygons = scene.findAllMatches(""**/plane"")\n    mesh = BulletTriangleMesh()      \n    for polygon in polygons:\n      #cNode = scene.attachNewNode(CollisionNode(\'plane_solid\'))\n      #cNode.node().addSolid(CollisionPolygon(polygon))\n      #polygon.setCollideMask(BitMask32.bit(1))\n      node = polygon.node()\n      print(node.getNumGeoms())\n      for i in xrange(node.getNumGeoms()):\n        geom = node.getGeom(i)\n        mesh.addGeom(geom)\n        continue\n      continue\n\n  def test(self, scene):\n    groundMask=BitMask32(0b1)\n    parent = NodePath(\'cGeomConversionParent\') \n    for c in incomingNode.findAllMatches(\'**/+GeomNode\'): \n        if relativeTo:\n            xform=c.getMat(relativeTo).xformPoint\n        else:\n            xform=c.getMat().xformPoint\n        gni = 0 \n        geomNode = c.node() \n        for g in range(geomNode.getNumGeoms()): \n            geom = geomNode.getGeom(g).decompose() \n            vdata = geom.getVertexData() \n            vreader = GeomVertexReader(vdata, \'vertex\') \n            cChild = CollisionNode(\'cGeom-%s-gni%i\' % (c.getName(), gni)) \n            \n            gni += 1 \n            for p in range(geom.getNumPrimitives()): \n                prim = geom.getPrimitive(p) \n                for p2 in range(prim.getNumPrimitives()): \n                    s = prim.getPrimitiveStart(p2) \n                    e = prim.getPrimitiveEnd(p2) \n                    v = [] \n                    for vi in range (s, e): \n                        vreader.setRow(prim.getVertex(vi)) \n                        v.append (xform(vreader.getData3f())) \n                    colPoly = CollisionPolygon(*v) \n                    cChild.addSolid(colPoly) \n\n            n=parent.attachNewNode (cChild) \n            #n.show()\n            \n    return parent\n\n  \n  def generateEggModel(self):\n    data = EggData()\n    model = EggGroup(\'model\')\n    data.addChild(model)\n    self.generatePlanes(model)\n    #self.generateRectangle(model)\n    data.writeEgg(Filename(""dump/plane.egg""))\n    scene = NodePath(loadEggData(data))\n    #self.addCollisionPolygons(scene)\n    \n    return scene  \n\n    \n\n  def getPlaneTriangles(self):\n    from skimage import measure\n    \n    planeTriangles = []\n    planeNormals = []    \n    horizontalPlaneTriangles = []\n    \n    for planeIndex in xrange(self.numPlanes):\n      mask = (self.segmentation == planeIndex).astype(np.uint8) * 255\n      mask_ori = mask.copy()\n      #contours, _ = cv2.findContours(mask, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n      #contours, _ = cv2.findContours(mask, cv2.RETR_LIST, cv2.CHAIN_APPROX_TC89_KCOS)\n      masks = measure.label(mask.astype(np.int32), background=0)\n      contours = []\n      for maskIndex in xrange(masks.min() + 1, masks.max() + 1):\n        mask = masks == maskIndex\n        contour_mask = mask - np.logical_and(np.logical_and(np.roll(mask, shift=1, axis=0), np.roll(mask, shift=-1, axis=0)), np.logical_and(np.roll(mask, shift=1, axis=1), np.roll(mask, shift=-1, axis=1)))\n        contour_v, contour_u = contour_mask.nonzero()\n        contours.append(np.stack([contour_u, contour_v], axis=1))\n        continue\n        \n        \n      plane = self.planes[planeIndex]\n      planeD = np.linalg.norm(plane)\n      planeNormal = plane / np.maximum(planeD, 1e-4)\n\n      # cv2.imwrite(\'test/mask.png\', mask_ori)\n      # #print(len(contours))\n\n      # mask_ori = np.stack([mask_ori, mask_ori, mask_ori], 2)\n      # count = 0\n      # for contour in contours:\n      #   count += contour.shape[0]\n      #   for uv in contour:\n      #     #uv = uv[0]\n      #     mask_ori[uv[1]][uv[0]] = np.array([255, 0, 0])\n      #     continue\n      #   continue\n      # cv2.imwrite(\'test/mask_contour.png\', mask_ori)\n      # if planeIndex == 1:\n      #   exit(1)\n\n      indices = np.arange(self.width * self.height).astype(np.float32)\n      us = indices % self.width\n      us = us / self.width * self.info[16] - self.camera[\'cx\']\n      vs = indices / self.width      \n      vs = -(vs / self.height * self.info[17] - self.camera[\'cy\'])\n      ranges = np.stack([us / self.camera[\'fx\'], np.ones(us.shape), vs / self.camera[\'fy\']], axis=1)\n      #print(ranges)\n      #print(np.dot(ranges, planeNormal).shape)\n      #print(np.dot(ranges, planeNormal))\n      #print(ranges)\n      #exit(1)\n      depth = planeD / np.tensordot(ranges, planeNormal, axes=([1], [0]))\n      XYZ = ranges * np.expand_dims(depth, -1)\n      XYZ = XYZ.reshape((self.height, self.width, 3))\n      for contour in contours:\n        contour = contour.astype(np.float32)[::20]\n        if contour.shape[0] < 3:\n          continue\n        rect = (0, 0, self.width, self.height)\n        subdiv = cv2.Subdiv2D(rect)\n\n        for point in contour:\n          subdiv.insert((point[0], point[1]))\n          continue\n        triangleList = subdiv.getTriangleList()\n\n        #print(contour)                \n        #print(triangleList)\n        #exit(1)\n        for triangle2D in triangleList:\n          triangle = []\n          for vertexIndex in xrange(3):\n            x = int(triangle2D[vertexIndex * 2 + 0])\n            y = int(triangle2D[vertexIndex * 2 + 1])\n            #print(x, y)\n            if x < 0 or x >= self.width or y < 0 or y >= self.height:\n              continue\n            triangle.append(XYZ[y][x])\n            continue\n          if len(triangle) == 3:\n            #print(triangle)\n            if np.dot(np.cross(planeNormal, triangle[1] - triangle[0]), triangle[2] - triangle[0]) > 0:\n              triangle = [triangle[0], triangle[2], triangle[1]]\n              pass\n            if planeIndex in self.horizontalPlanes:\n              horizontalPlaneTriangles.append(triangle)\n            else:\n              planeTriangles.append(triangle)\n              pass\n            #planeNormals.append(planeNormal)\n            pass\n          continue\n      continue\n    planeTriangles = np.array(planeTriangles)\n    #planeNormals = np.array(planeNormals)\n    np.save(\'dump/\' + str(self.scene_index) + \'_plane_triangles.npy\', planeTriangles)\n    #np.save(\'dump/\' + str(self.scene_index) + \'_plane_normals.npy\', planeNormals)\n    return planeTriangles, horizontalPlaneTriangles, self.gravityDirection\n  \n\n  def getPlaneGeometries(self):\n    if os.path.exists(\'dump/\' + str(self.scene_index) + \'_plane_triangles.npy\'):\n      print(\'loading\')\n      planeTriangles = np.load(\'dump/\' + str(self.scene_index) + \'_plane_triangles.npy\')\n      planeNormals =  np.load(\'dump/\' + str(self.scene_index) + \'_plane_normals.npy\')\n      return planeTriangles, planeNormals\n      pass\n    \n    planeNormals = []\n    planeTriangles = []\n    for planeIndex in xrange(self.numPlanes):\n      mask = (self.segmentation == planeIndex).astype(np.uint8) * 255\n      #mask_ori = mask.copy()\n      #contours, _ = cv2.findContours(mask, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n      plane = self.planes[planeIndex]\n      planeD = np.linalg.norm(plane)\n      planeNormal = plane / np.maximum(planeD, 1e-4)\n\n      #cv2.imwrite(\'test/mask.png\', mask)\n      #v, u = mask.nonzero()\n      u = np.arange(self.width * self.height) % self.width\n      v = np.arange(self.width * self.height) / self.width\n      u = u.astype(np.float32) / self.width * self.info[16] - self.camera[\'cx\']\n      v = -(v.astype(np.float32) / self.height * self.info[17] - self.camera[\'cy\'])\n      ranges = np.stack([u / self.camera[\'fx\'], np.ones(u.shape), v / self.camera[\'fy\']], axis=1)\n      depth = planeD / np.dot(ranges, planeNormal)\n      XYZ = ranges * np.expand_dims(depth, -1)\n      XYZ = XYZ.reshape((self.height, self.width, 3))\n\n      triangles = []\n      for pixel in mask.reshape(-1).nonzero()[0]:\n        x = pixel % self.width\n        y = pixel / self.width\n        for neighbors in [((x - 1, y), (x, y - 1)), ((x - 1, y), (x, y + 1)), ((x + 1, y), (x, y - 1)), ((x + 1, y), (x, y + 1))]:\n          valid = True\n          for neighbor in neighbors:\n            if neighbor[0] < 0 or neighbor[0] >= self.width or neighbor[1] < 0 or neighbor[1] >= self.height or mask[neighbor[1]][neighbor[0]] == False:\n              valid = False\n              break\n            continue\n          if valid:\n            triangle = [XYZ[y][x]]\n            for neighbor in neighbors:\n              triangle.append(XYZ[neighbor[1], neighbor[0]])\n              continue\n            triangles.append(triangle)\n            pass\n          continue\n        continue\n      planeTriangles.append(triangles)\n      planeNormals.append(planeNormal)\n      continue\n\n    planeTriangles = np.array(planeTriangles)\n    #planeNormals = np.array(planeNormals)\n    #np.save(\'dump/\' + str(self.scene_index) + \'_plane_triangles.npy\', planeTriangles)\n    #np.save(\'dump/\' + str(self.scene_index) + \'_plane_normals.npy\', planeNormals)\n    return planeTriangles, planeNormals\n  \n\n  def calcHorizontalPlanes(self):\n    from sklearn.cluster import KMeans\n    \n    planesD = np.linalg.norm(self.planes, axis=-1, keepdims=True)\n    normals = self.planes / np.maximum(planesD, 1e-4)\n    \n    normals[normals[:, 1] < 0] *= -1    \n\n    kmeans = KMeans(n_clusters=3).fit(normals)\n    dominantNormals = kmeans.cluster_centers_\n    dominantNormals = dominantNormals / np.maximum(np.linalg.norm(dominantNormals, axis=-1, keepdims=True), 1e-4)\n\n    planeClusters = kmeans.predict(normals)\n    \n    horizontalNormalIndex = np.argmax(np.abs(dominantNormals[:, 2]))\n    self.gravityDirection = dominantNormals[horizontalNormalIndex]\n    self.horizontalPlanes = (planeClusters == horizontalNormalIndex).nonzero()[0]\n    if self.gravityDirection[2] > 0:\n      self.gravityDirection *= -1\n      pass\n\n    print(self.horizontalPlanes)\n    print(self.gravityDirection)\n    return\n    \n  def getHorizontalPlanes(self):\n    return self.gravityDirection, self.horizontalPlanes\n\n  def getHolePos(self):\n    floorPlaneIndex = 2\n    closePoint = np.array([0., 1.22, -0.2])\n    plane = self.planes[floorPlaneIndex]\n    planeD = np.linalg.norm(plane)\n    planeNormal = plane / planeD\n    distance = planeD - np.dot(planeNormal, closePoint)\n    distance *= 0.99\n    holePos = closePoint + planeNormal * distance\n\n    H = P = R = 0\n    H = -90 + np.rad2deg(np.arctan2(planeNormal[1], planeNormal[0]))\n    #P = 90 - np.rad2deg(np.arccos(np.abs(planeNormal[2])))\n    P = -90 + np.rad2deg(np.arccos(np.abs(planeNormal[2])))\n    #print(H, P, R)\n    return holePos, np.array([H, P, R])\n\n\n  def getPortalPos(self):\n    wallPlaneIndex = 1\n    closePoint_1 = np.array([0.5, 1.35, -0.5])\n    closePoint_2 = np.array([-0.4, 1, 0.19])\n    plane = self.planes[wallPlaneIndex]\n    planeD = np.linalg.norm(plane)\n    planeNormal = plane / planeD\n    \n    distance = planeD - np.dot(planeNormal, closePoint_1)\n    distance *= 0.95\n    portalPos_1 = closePoint_1 + planeNormal * distance\n\n    distance = planeD - np.dot(planeNormal, closePoint_2)\n    distance *= 0.95\n    portalPos_2 = closePoint_2 + planeNormal * distance    \n\n    H = P = R = 0\n    H = -90 + np.rad2deg(np.arctan2(planeNormal[1], planeNormal[0]))\n    #P = 90 - np.rad2deg(np.arccos(np.abs(planeNormal[2])))\n    P = -90 + np.rad2deg(np.arccos(-np.abs(planeNormal[2])))\n    #print(H, P, R)\n    return portalPos_1, np.array([H, P, R]), portalPos_2, np.array([H, P, R]), planeNormal\n  \n'"
pool/pool.py,0,"b'#!/usr/bin/env python\n\n# Author: Shao Zhang, Phil Saltzman\n# Last Updated: 2015-03-13\n#\n# This tutorial shows how to detect and respond to collisions. It uses solids\n# create in code and the egg files, how to set up collision masks, a traverser,\n# and a handler, how to detect collisions, and how to dispatch function based\n# on the collisions. All of this is put together to simulate a labyrinth-style\n# game\n\nfrom direct.showbase.ShowBase import ShowBase\nfrom panda3d.core import CollisionTraverser, CollisionNode\nfrom panda3d.core import CollisionHandlerQueue, CollisionRay, CollisionPolygon, CollisionSphere, CollisionTube\nfrom panda3d.core import Material, LRotationf, NodePath\nfrom panda3d.core import AmbientLight, DirectionalLight\nfrom panda3d.core import TextNode\nfrom panda3d.core import LVector3, BitMask32\nfrom panda3d.core import PerspectiveLens, Vec3, Point3\nfrom panda3d.core import CardMaker\nfrom direct.gui.OnscreenText import OnscreenText\nfrom direct.interval.MetaInterval import Sequence, Parallel\nfrom direct.interval.LerpInterval import LerpFunc\nfrom direct.interval.FunctionInterval import Func, Wait\nfrom direct.task.Task import Task\nfrom plane_scene import PlaneScene\nfrom parts_scene import PartsScene\n#from panda3d.bullet import BulletWorld, BulletPlaneShape, BulletRigidBodyNode, BulletBoxShape, BulletTriangleMesh, BulletTriangleMeshShape, BulletSphereShape, BulletGhostNode\nimport sys\nimport numpy as np\n\n# Some constants for the program\nACCEL = 70         # Acceleration in ft/sec/sec\nMAX_SPEED = 5      # Max speed in ft/sec\nMAX_SPEED_SQ = MAX_SPEED ** 2  # Squared to make it easier to use lengthSquared\n# Instead of length\n\n\nclass PoolBallGame(ShowBase):\n\n    def __init__(self):\n        # Initialize the ShowBase class from which we inherit, which will\n        # create a window and set up everything we need for rendering into it.\n        ShowBase.__init__(self)\n        base.setBackgroundColor(0, 0, 0)\n        \n        self.accept(""escape"", sys.exit)  # Escape quits\n        self.disableMouse()\n        camera.setPosHpr(0, 0, 0, 0, 0, 0)\n\n        lens = PerspectiveLens()\n        lens.setFov(90, 60)\n        lens.setNear(0.01)\n        lens.setFar(100000)\n        self.cam.node().setLens(lens)\n\n        self.ballSize = 0.025\n        self.cueLength = 0.2\n        # self.ballRoot = render.attachNewNode(""ballRoot"")\n        # #self.ball = loader.loadModel(""models/ball"")\n        # self.ball = loader.loadModel(""models/ball_0_center.egg"")\n        # #self.ball = loader.loadModel(""models/ball.dae"")\n        # self.ball.setScale(ballSize, ballSize, ballSize)\n        # self.ball.reparentTo(self.ballRoot)\n        # #print(self.ball.getBounds())\n        # #exit(1)\n        # #self.ballSphere = self.ball.find(""**/ball"")\n        # #print(self.ball.getScale()[0])\n        # cs = CollisionSphere(0, 0, 0, 1)\n        # self.ballSphere = self.ball.attachNewNode(CollisionNode(\'ball\'))\n        # self.ballSphere.node().addSolid(cs)\n        \n        # self.ballSphere.node().setFromCollideMask(BitMask32.bit(0))\n        # self.ballSphere.node().setIntoCollideMask(BitMask32.bit(1))\n\n\n        self.sceneIndex = 0\n        self.planeInfo = PlaneScene(self.sceneIndex)\n        \n        self.planeScene = self.planeInfo.generateEggModel()\n        self.planeScene.setTwoSided(True)        \n        self.planeScene.reparentTo(render)\n        self.planeScene.hide()\n\n        #get geometries from plane predictions\n        planeTriangles, horizontalPlaneTriangles, self.gravityDirection = self.planeInfo.getPlaneTriangles()\n\n\n        # add pool balls\n        self.ballRoots = []\n        self.balls = []\n        self.ballSpheres = []\n        self.ballGroundRays = []\n        for ballIndex in xrange(3):\n            ballRoot = render.attachNewNode(""ballRoot_"" + str(ballIndex))\n            ball = loader.loadModel(""models/ball_"" + str(ballIndex) + ""_center.egg"")\n            ball.setScale(self.ballSize, self.ballSize, self.ballSize)\n\n            cs = CollisionSphere(0, 0, 0, 1)\n            ballSphere = ball.attachNewNode(CollisionNode(\'ball_\' + str(ballIndex)))\n            ballSphere.node().addSolid(cs)\n            ballSphere.node().setFromCollideMask(BitMask32.bit(0) | BitMask32.bit(1) | BitMask32.bit(3) | BitMask32.bit(4))\n            ballSphere.node().setIntoCollideMask(BitMask32.bit(1))\n\n            ball.reparentTo(ballRoot)\n            self.ballRoots.append(ballRoot)\n            self.balls.append(ball)            \n            self.ballSpheres.append(ballSphere)\n\n\n            ballGroundRay = CollisionRay()     # Create the ray\n            ballGroundRay.setOrigin(0, 0, 0)    # Set its origin\n            ballGroundRay.setDirection(self.gravityDirection[0], self.gravityDirection[1], self.gravityDirection[2])  # And its direction\n            # Collision solids go in CollisionNode\n            # Create and name the node\n            ballGroundCol = CollisionNode(\'ball_ray_\' + str(ballIndex))\n            ballGroundCol.addSolid(ballGroundRay)  # Add the ray\n            ballGroundCol.setFromCollideMask(BitMask32.bit(2))  # Set its bitmasks\n            ballGroundCol.setIntoCollideMask(BitMask32.allOff())\n            # Attach the node to the ballRoot so that the ray is relative to the ball\n            # (it will always be 10 feet over the ball and point down)\n            ballGroundColNp = ballRoot.attachNewNode(ballGroundCol)\n            self.ballGroundRays.append(ballGroundColNp)\n\n            ballRoot.hide()\n            continue\n\n        \n        # Finally, we create a CollisionTraverser. CollisionTraversers are what\n        # do the job of walking the scene graph and calculating collisions.\n        # For a traverser to actually do collisions, you need to call\n        # traverser.traverse() on a part of the scene. Fortunately, ShowBase\n        # has a task that does this for the entire scene once a frame.  By\n        # assigning it to self.cTrav, we designate that this is the one that\n        # it should call traverse() on each frame.\n        self.cTrav = CollisionTraverser()\n\n        # Collision traversers tell collision handlers about collisions, and then\n        # the handler decides what to do with the information. We are using a\n        # CollisionHandlerQueue, which simply creates a list of all of the\n        # collisions in a given pass. There are more sophisticated handlers like\n        # one that sends events and another that tries to keep collided objects\n        # apart, but the results are often better with a simple queue\n        self.cHandler = CollisionHandlerQueue()\n        # Now we add the collision nodes that can create a collision to the\n        # traverser. The traverser will compare these to all others nodes in the\n        # scene. There is a limit of 32 CollisionNodes per traverser\n        # We add the collider, and the handler to use as a pair\n        \n        #self.cTrav.addCollider(self.ballSphere, self.cHandler)\n        for ballSphere in self.ballSpheres:\n            self.cTrav.addCollider(ballSphere, self.cHandler)\n            continue\n        for ballGroundRay in self.ballGroundRays:\n            self.cTrav.addCollider(ballGroundRay, self.cHandler)\n            continue        \n        #self.cTrav.addCollider(self.ballGroundColNp, self.cHandler)\n\n        # Collision traversers have a built in tool to help visualize collisions.\n        # Uncomment the next line to see it.\n        #self.cTrav.showCollisions(render)\n\n        # This section deals with lighting for the ball. Only the ball was lit\n        # because the maze has static lighting pregenerated by the modeler\n        ambientLight = AmbientLight(""ambientLight"")\n        ambientLight.setColor((.55, .55, .55, 1))\n        directionalLight = DirectionalLight(""directionalLight"")\n        directionalLight.setDirection(LVector3(0, 0, -1))\n        directionalLight.setColor((0.375, 0.375, 0.375, 1))\n        directionalLight.setSpecularColor((1, 1, 1, 1))\n\n        for ballRoot in self.ballRoots:\n            ballRoot.setLight(render.attachNewNode(ambientLight))\n            ballRoot.setLight(render.attachNewNode(directionalLight))\n            continue\n\n        # This section deals with adding a specular highlight to the ball to make\n        # it look shiny.  Normally, this is specified in the .egg file.\n        m = Material()\n        m.setSpecular((1, 1, 1, 1))\n        m.setShininess(96)\n        for ball in self.balls:\n            ball.setMaterial(m, 1)\n            continue\n\n\n        # self.original = False\n        # if self.original:\n        #     camera.setPosHpr(0, 0, 25, 0, -90, 0)        \n        #     self.maze = loader.loadModel(""models/maze"")\n        #     self.maze.reparentTo(render)\n        #     self.walls = self.maze.find(""**/wall_collide"")\n        #     self.walls.node().setIntoCollideMask(BitMask32.bit(0))\n        #     self.walls.show()\n        #     pass\n\n\n\n        # create collision entities from plane predictions\n        self.triNPs = []\n        for triangleIndex, triangle in enumerate(planeTriangles):\n            #print(triangleIndex)\n            #for triangle in triangles:\n            #print(triangle)\n            tri = CollisionPolygon(Point3(triangle[0][0], triangle[0][1], triangle[0][2]), Point3(triangle[1][0], triangle[1][1], triangle[1][2]), Point3(triangle[2][0], triangle[2][1], triangle[2][2]))\n            triNP = render.attachNewNode(CollisionNode(\'tri_\' + str(triangleIndex)))\n            triNP.node().setIntoCollideMask(BitMask32.bit(0))\n            triNP.node().addSolid(tri)\n            self.triNPs.append(triNP)\n            #triNP.show()\n            continue\n\n\n        # create special collision entities for horizontal planes so that balls can fall on one horizontal plane and bounce on it\n        for triangleIndex, triangle in enumerate(horizontalPlaneTriangles):\n            #print(triangleIndex)\n            #for triangle in triangles:\n            #print(triangle)\n            tri = CollisionPolygon(Point3(triangle[0][0], triangle[0][1], triangle[0][2]), Point3(triangle[1][0], triangle[1][1], triangle[1][2]), Point3(triangle[2][0], triangle[2][1], triangle[2][2]))\n            triNP = render.attachNewNode(CollisionNode(\'ground_\' + str(triangleIndex)))\n            triNP.node().setIntoCollideMask(BitMask32.bit(2))\n            triNP.node().addSolid(tri)\n            self.triNPs.append(triNP)\n            #triNP.show()\n            continue\n        \n        \n        # tri = CollisionPolygon(Point3(-1, 4, -1), Point3(2, 4, -1), Point3(2, 4, 2))    \n        # triNP = render.attachNewNode(CollisionNode(\'tri\'))\n        # triNP.node().setIntoCollideMask(BitMask32.bit(0))\n        # triNP.node().addSolid(tri)\n        # triNP.show()\n        \n        \n        #self.planeScene.node().setIntoCollideMask(BitMask32.bit(0))\n        # roomRootNP = self.planeScene\n        # roomRootNP.flattenLight()\n        # mesh = BulletTriangleMesh()\n        # polygons = roomRootNP.findAllMatches(""**/+GeomNode"")\n\n        # # p0 = Point3(-10, 4, -10)\n        # # p1 = Point3(-10, 4, 10)\n        # # p2 = Point3(10, 4, 10)\n        # # p3 = Point3(10, 4, -10)\n        # # mesh.addTriangle(p0, p1, p2)\n        # # mesh.addTriangle(p1, p2, p3)\n\n        # print(polygons)\n        # for polygon in polygons:\n        #     geom_node = polygon.node()\n        #     #geom_node.reparentTo(self.render)\n        #     #print(geom_node.getNumGeoms())\n        #     ts = geom_node.getTransform()\n        #     #print(ts)\n        #     for geom in geom_node.getGeoms():\n        #         mesh.addGeom(geom, ts)\n        #         continue\n        #     continue\n        # #self.scene = roomRootNP\n        # shape = BulletTriangleMeshShape(mesh, dynamic=False)\n        # #shape = BulletPlaneShape(Vec3(0, 0, 1), 1)\n        # room = BulletRigidBodyNode(\'scene\')\n        # room.addShape(shape)\n        # #room.setLinearDamping(0.0)\n        # #room.setFriction(0.0)\n        # print(shape)\n        # room.setDeactivationEnabled(False)\n        # roomNP = render.attachNewNode(room)\n        # roomNP.setPos(0, 0, 0)\n        # roomNP.node().setIntoCollideMask(BitMask32.bit(0))\n        # self.world = BulletWorld()\n        # self.world.setGravity(Vec3(0, 0, 0))\n        # self.world.attachRigidBody(roomNP.node())\n        #room.setRestitution(1)\n\n        #self.roomNP = self.scene\n        \n\n        # create the cue\n        self.cueRoot = render.attachNewNode(""cueRoot"")\n        self.cue = loader.loadModel(""models/cue_center.egg"")\n        self.cue.setScale(self.cueLength * 3, self.cueLength * 3, self.cueLength)\n        self.cue.reparentTo(self.cueRoot)\n\n        self.cuePos = (10, 0, 0)\n        \n        self.pickerNode = CollisionNode(\'mouseRay\')\n        # Attach that node to the camera since the ray will need to be positioned\n        # relative to it\n        self.pickerNP = camera.attachNewNode(self.pickerNode)\n        # Everything to be picked will use bit 1. This way if we were doing other\n        # collision we could separate it\n        self.pickerNode.setFromCollideMask(BitMask32.bit(2))\n        self.pickerNode.setIntoCollideMask(BitMask32.allOff())        \n        self.pickerRay = CollisionRay()  # Make our ray\n        # Add it to the collision node\n        self.pickerNode.addSolid(self.pickerRay)\n        # Register the ray as something that can cause collisions\n        self.cTrav.addCollider(self.pickerNP, self.cHandler)        \n\n        self.accept(""mouse1"", self.hit)  # left-click grabs a piece\n\n\n        # create holes\n        self.holeLength = 0.06\n        holePos, holeHpr = self.planeInfo.getHolePos()\n        self.holeRoot = render.attachNewNode(""holeRoot"")\n        #self.hole = loader.loadModel(""models/hole_horizontal_center.egg"")\n        self.hole = loader.loadModel(""models/hole_color.egg"")\n        #self.hole = loader.loadModel(""models/billiards_hole_center.egg"")\n        self.hole.setScale(self.holeLength, self.holeLength, self.holeLength)\n        self.hole.reparentTo(self.holeRoot)\n        self.hole.setTwoSided(True)\n        self.holeRoot.setPos(holePos[0], holePos[1], holePos[2])\n        self.holeRoot.setHpr(holeHpr[0], holeHpr[1], holeHpr[2])\n        #tex = loader.loadTexture(\'models/Black_Hole.jpg\')\n        #self.hole.setTexture(tex, 1)\n        self.holeRoot.hide()\n        \n        ct = CollisionTube(0, 0, 0, 0, 0.001, 0, 0.5)\n        self.holeTube = self.hole.attachNewNode(CollisionNode(\'hole\'))\n        self.holeTube.node().addSolid(ct)\n        self.holeTube.node().setFromCollideMask(BitMask32.allOff())        \n        self.holeTube.node().setIntoCollideMask(BitMask32.bit(4))\n        #self.holeTube.show()\n\n\n        # create portals\n        inPortalPos, inPortalHpr, outPortalPos, outPortalHpr, self.portalNormal = self.planeInfo.getPortalPos()\n        self.portalLength = 0.06\n        self.inPortalRoot = render.attachNewNode(""inPortalRoot"")\n        self.inPortal = loader.loadModel(""models/portal_2_center.egg"")\n        self.inPortal.setScale(self.portalLength, self.portalLength, self.portalLength)\n        self.inPortal.reparentTo(self.inPortalRoot)\n        self.inPortalRoot.setPos(inPortalPos[0], inPortalPos[1], inPortalPos[2])\n        self.inPortalRoot.setHpr(inPortalHpr[0], inPortalHpr[1], inPortalHpr[2])\n        self.inPortalRoot.hide()\n        \n        ct = CollisionTube(0, 0, 0, 0, 0.001, 0, 1)\n        self.inPortalTube = self.inPortal.attachNewNode(CollisionNode(\'portal_in\'))\n        self.inPortalTube.node().addSolid(ct)\n        self.inPortalTube.node().setFromCollideMask(BitMask32.allOff())        \n        self.inPortalTube.node().setIntoCollideMask(BitMask32.bit(3))\n        #self.inPortalTube.hide()\n\n        self.outPortalRoot = render.attachNewNode(""outPortalRoot"")\n        self.outPortal = loader.loadModel(""models/portal_2_center.egg"")\n        self.outPortal.setScale(self.portalLength, self.portalLength, self.portalLength)\n        self.outPortal.reparentTo(self.outPortalRoot)\n        self.outPortalRoot.setPos(outPortalPos[0], outPortalPos[1], outPortalPos[2])\n        self.outPortalRoot.setHpr(outPortalHpr[0], outPortalHpr[1], outPortalHpr[2])\n        self.outPortalRoot.hide()\n        \n        ct = CollisionTube(0, 0, 0, 0, 0.001, 0, 1)\n        self.outPortalTube = self.outPortal.attachNewNode(CollisionNode(\'portal_out\'))\n        self.outPortalTube.node().addSolid(ct)\n        self.outPortalTube.node().setFromCollideMask(BitMask32.allOff())        \n        self.outPortalTube.node().setIntoCollideMask(BitMask32.bit(3))\n        #self.outPortalTube.hide()        \n        #self.inPortalTube.show()\n        #self.outPortalTube.show()\n        #self.holeTube.show()\n        \n        #self.cTrav.addCollider(self.holeTube, self.cHandler)\n\n        # create background image\n        background_image = loader.loadTexture(\'dump/\' + str(self.sceneIndex) + \'_image.png\')\n        cm = CardMaker(\'background\')\n        cm.setHas3dUvs(True)\n        info = np.load(\'dump/\' + str(self.sceneIndex) + \'_info.npy\')\n        #self.camera = getCameraFromInfo(self.info)\n        depth = 10.0\n        sizeU = info[2] / info[0] * depth\n        sizeV = info[6] / info[5] * depth\n        cm.setFrame(Point3(-sizeU, depth, -sizeV), Point3(sizeU, depth, -sizeV), Point3(sizeU, depth, sizeV), Point3(-sizeU, depth, sizeV))\n        self.card = self.render.attachNewNode(cm.generate())\n        self.card.setTransparency(True)    \n        self.card.setTexture(background_image)\n        self.card.hide()\n        \n        \n        self.ballGroundMap = {}\n        self.ballBouncing = np.full(len(self.balls), 3)\n        \n        self.started = False\n        self.start()\n        \n        #self.hitIndex = -1\n        \n        self.showing = \'parts\'\n        self.showingProgress = 0\n        \n        partsScene = PartsScene(self.sceneIndex)        \n        self.planeNPs, self.planeCenters = partsScene.generateEggModel()\n        return\n\n    def start(self):\n        #startPos = self.maze.find(""**/start"").getPos()\n        #self.ballRoot.setPos(0.5, 0, 0)\n        #self.ballV = LVector3(0, 0.5, 0)         # Initial velocity is 0\n        #self.accelV = LVector3(0, 0, 0)        # Initial acceleration is 0\n\n        self.ballVs = []\n        self.accelVs = []\n        for ballIndex in xrange(len(self.balls)):\n            self.ballVs.append(LVector3(0, 0, 0))\n            self.accelVs.append(LVector3(0, 0, 0))\n            continue\n        self.ballRoots[0].setPos(0.2, 1.05, -0.1)\n        #self.ballVs[0] = LVector3(0, 0.0, 0)                \n        self.ballRoots[1].setPos(0.32, 1.2, -0.1)\n        #self.ballRoots[2].setHpr(0, 0, 90)\n        self.ballRoots[2].setPos(-0.4, 1.1, 0.4)\n        axis = LVector3.up()\n        prevRot = LRotationf(self.balls[2].getQuat())\n        newRot = LRotationf(axis, 90)\n        self.balls[2].setQuat(prevRot * newRot)\n            \n        # Create the movement task, but first make sure it is not already\n        # running\n        taskMgr.remove(""rollTask"")\n        #taskMgr.remove(""mouseTask"")\n        self.mainLoop = taskMgr.add(self.rollTask, ""rollTask"")        \n        #self.mainLoop = taskMgr.add(self.mouseTask, ""mouseTask"")\n        \n        return\n\n    def hit(self):\n        if abs(self.cuePos[0]) < 5:\n            # direction and strength based on mouse position\n            cueDirection = self.ballRoots[0].getPos() - LVector3(self.cuePos[0], self.cuePos[1], self.cuePos[2])\n            power = cueDirection.length()\n            cueDirection = cueDirection / cueDirection.length()\n            self.ballVs[0] = cueDirection * np.sqrt(self.cuePower)\n                \n            # elif self.hitIndex == 0:\n            #     self.ballVs[0] = LVector3(0.5, 0.47, 0)\n            #     self.hitIndex += 1\n            # elif self.hitIndex == 1:\n            #     self.ballVs[0] = LVector3(0.072, 0.62, 0)\n            #     self.hitIndex += 1\n            # elif self.hitIndex == 2:\n            #     self.ballVs[0] = LVector3(0.7, 0.0, 0)\n            #     self.hitIndex += 1                                \n            #     pass\n            \n            self.started = True\n            print(\'hit\', cueDirection)\n            self.ballBouncing = np.full(len(self.balls), 3)\n            pass\n\n\n\n    # This function handles the collision between the ball and a wall\n    def planeCollideHandler(self, colEntry):\n        #return\n        ballName = colEntry.getFromNode().getName()\n        ballIndex = int(ballName[5:])\n        \n        # First we calculate some numbers we need to do a reflection\n        # print(colEntry)\n        # name = colEntry.getIntoNode().getName()\n        # triangleIndex = int(name[4:])\n        # print(triangleIndex)\n        # print(self.planeNormals[triangleIndex])\n        # print(colEntry.getSurfaceNormal(render))\n        # exit(1)\n        norm = colEntry.getSurfaceNormal(render) * -1  # The normal of the wall\n        norm.normalize()\n        curSpeed = self.ballVs[ballIndex].length()                # The current speed\n        inVec = self.ballVs[ballIndex] / curSpeed                 # The direction of travel\n        velAngle = norm.dot(inVec)                    # Angle of incidance\n        hitDir = colEntry.getSurfacePoint(render) - self.ballRoots[ballIndex].getPos()\n        hitDir.normalize()\n        # The angle between the ball and the normal\n        hitAngle = norm.dot(hitDir)\n\n        # Ignore the collision if the ball is either moving away from the wall\n        # already (so that we don\'t accidentally send it back into the wall)\n        # and ignore it if the collision isn\'t dead-on (to avoid getting caught on\n        # corners)\n        #print(velAngle, hitAngle)\n\n        if velAngle > 0 and hitAngle > .995:\n            print(\'plane\', ballName, velAngle)\n            # Standard reflection equation\n            reflectVec = (norm * norm.dot(inVec * -1) * 2) + inVec\n\n            # This makes the velocity half of what it was if the hit was dead-on\n            # and nearly exactly what it was if this is a glancing blow\n            #self.ballVs[ballIndex] = reflectVec * (curSpeed * (((1 - velAngle) * .5) + .5))\n            self.ballVs[ballIndex] = reflectVec * curSpeed\n            # Since we have a collision, the ball is already a little bit buried in\n            # the wall. This calculates a vector needed to move it so that it is\n            # exactly touching the wall\n            disp = (colEntry.getSurfacePoint(render) -\n                    colEntry.getInteriorPoint(render))\n            newPos = self.ballRoots[ballIndex].getPos() + disp\n            self.ballRoots[ballIndex].setPos(newPos)\n            pass\n        return    \n\n    # This function handles the collision between the ball and a wall\n    def portal(self, colEntry):\n        ballName = colEntry.getFromNode().getName()\n        print(\'portal\', ballName)\n        ballIndex = int(ballName[5:])\n        \n        #norm = colEntry.getSurfaceNormal(render) * -1  # The normal of the wall\n        norm = LVector3(self.portalNormal[0], self.portalNormal[1], self.portalNormal[2])\n        norm.normalize()\n        curSpeed = self.ballVs[ballIndex].length()                # The current speed\n        inVec = self.ballVs[ballIndex] / curSpeed                 # The direction of travel\n        velAngle = norm.dot(inVec)                    # Angle of incidance\n        hitDir = colEntry.getSurfacePoint(render) - self.ballRoots[ballIndex].getPos()\n        hitDir.normalize()\n        # The angle between the ball and the normal\n        #print(colEntry.getSurfacePoint(render), self.ballRoots[ballIndex].getPos())\n        #print(norm, hitDir)\n        hitAngle = norm.dot(hitDir)\n        \n        # Ignore the collision if the ball is either moving away from the wall\n        # already (so that we don\'t accidentally send it back into the wall)\n        # and ignore it if the collision isn\'t dead-on (to avoid getting caught on\n        # corners)\n        #print(velAngle, hitAngle)\n        #print(velAngle, hitAngle)\n        if velAngle > 0:\n            print(colEntry.getIntoNode().getName())\n            if \'_in\' in colEntry.getIntoNode().getName():\n                self.ballRoots[ballIndex].setPos(self.outPortalRoot.getPos())\n            else:\n                self.ballRoots[ballIndex].setPos(self.inPortalRoot.getPos())\n                pass\n            print(self.ballVs[ballIndex], ((norm * norm.dot(inVec * -1) * 2) + inVec) * curSpeed, norm)\n            #exit(1)\n            self.ballVs[ballIndex] = ((norm * norm.dot(inVec * -1) * 2) + inVec) * curSpeed\n            #self.ballVs[ballIndex] *= -1\n            pass\n        return    \n    \n\n    # This function handles the collision between the ball and a wall\n    def ballCollideHandler(self, colEntry):\n        # First we calculate some numbers we need to do a reflection\n        fromBallName = colEntry.getFromNode().getName()\n        fromBallIndex = int(fromBallName[5:])\n        #if fromBallIndex != 0:\n        #return\n        intoBallName = colEntry.getIntoNode().getName()\n        intoBallIndex = int(intoBallName[5:])        \n\n        print(\'ball\', fromBallName, intoBallName)\n        \n        norm = colEntry.getSurfaceNormal(render) * -1  # The normal of the wall\n        norm = norm / norm.length()\n        curSpeed = self.ballVs[fromBallIndex].length()                # The current speed\n        inVec = self.ballVs[fromBallIndex] / curSpeed                 # The direction of travel\n        velAngle = norm.dot(inVec)                    # Angle of incidance\n        hitDir = colEntry.getSurfacePoint(render) - self.ballRoots[fromBallIndex].getPos()\n        hitDir.normalize()\n        # The angle between the ball and the normal\n        hitAngle = norm.dot(hitDir)\n\n        # print(norm)\n        # print(self.ballVs[fromBallIndex])\n        # print(velAngle, hitAngle)\n        # print(self.ballRoots[fromBallIndex].getPos())\n        # print(self.ballRoots[intoBallIndex].getPos())        \n        # exit(1)\n        #print(fromBallIndex, intoBallIndex)\n        #exit(1)\n        \n        # Ignore the collision if the ball is either moving away from the wall\n        # already (so that we don\'t accidentally send it back into the wall)\n        # and ignore it if the collision isn\'t dead-on (to avoid getting caught on\n        # corners)\n        #print(velAngle, hitAngle)\n        if velAngle > 0 and hitAngle > .995:\n            # Standard reflection equation\n            self.ballVs[fromBallIndex] = ((norm * norm.dot(inVec * -1)) + inVec) * curSpeed\n\n            disp = (colEntry.getSurfacePoint(render) -\n                    colEntry.getInteriorPoint(render))\n            newPos = self.ballRoots[fromBallIndex].getPos() + disp\n            self.ballRoots[fromBallIndex].setPos(newPos)\n\n            self.ballVs[intoBallIndex] = norm * norm.dot(inVec) * curSpeed\n            pass\n        return    \n\n\n    # the function handles the situation when a ball falls on a lower horizontal plane\n    def groundCollideHandler(self, colEntry):\n        # Set the ball to the appropriate Z value for it to be exactly on the\n        # ground\n        ballName = colEntry.getFromNode().getName()\n\n        if \'mouseRay\' in ballName:\n            for v in self.ballVs:\n                if v.length() > 1e-4:\n                    self.cuePos = (10, 0, 0)\n                    return\n                continue\n            #print(self.mouseWatcherNode.hasMouse())\n            norm = colEntry.getSurfaceNormal(render)\n            norm.normalize()\n            touchPoint = colEntry.getSurfacePoint(render)\n            cuePoint = touchPoint + norm * self.ballSize\n            cueDirection = self.ballRoots[0].getPos() - cuePoint\n            self.cuePower = cueDirection.length()\n            cueDirection = cueDirection / cueDirection.length()\n            cuePoint = self.ballRoots[0].getPos() - cueDirection * self.cueLength\n            self.cuePos = cuePoint\n            #self.cueRoot.setH(np.rad2deg(np.arctan2(cueDirection[1], cueDirection[0])) + 90)\n            self.cueRoot.setH(np.rad2deg(np.arctan2(cueDirection[1], cueDirection[0])) + 90)  \n            self.cueRoot.setP(-np.rad2deg(np.arcsin(cueDirection[2])) + 90)\n            #self.cueRoot.setP(90)\n            #print(np.rad2deg(np.arctan2(cueDirection[1], cueDirection[0])), np.rad2deg(np.arcsin(cueDirection[2])))\n\n            # prevRot = LRotationf(self.cue.getQuat())\n            # axis = LVector3.up().cross(self.ballVs[ballIndex])\n            # newRot = LRotationf(axis, 45.5 * dt * self.ballVs[ballIndex].length())\n            # self.balls[ballIndex].setQuat(prevRot * newRot)\n            return\n            \n        #print(\'ground\', ballName)\n        #print(ballName, colEntry.getIntoNode().getName())\n        #print(colEntry.getFromNode().getBitMask(), colEntry.getIntoNode().getBitMask())\n        ballIndex = int(ballName[9:])\n\n        groundName = colEntry.getIntoNode().getName()\n        groundIndex = int(groundName[7:])\n        #print(groundIndex)\n        #print(self.ballGroundMap)\n        if ballIndex == 0 and False:\n            print(groundIndex, self.ballGroundMap)\n            pass\n        \n        if ballIndex not in self.ballGroundMap or self.ballGroundMap[ballIndex][0] != groundIndex:\n            return\n        \n        norm = -colEntry.getSurfaceNormal(render)\n        norm = norm / norm.length()\n\n        curSpeed = self.ballVs[ballIndex].length()                # The current speed\n        inVec = self.ballVs[ballIndex] / max(curSpeed, 1e-4)                 # The direction of travel\n        velAngle = norm.dot(inVec)                    # Angle of incidance\n        hitDir = colEntry.getSurfacePoint(render) - self.ballRoots[ballIndex].getPos()\n        hitDir.normalize()\n        # The angle between the ball and the normal\n        hitAngle = norm.dot(hitDir)\n        \n        surfacePos = colEntry.getSurfacePoint(render)\n        ballPos = self.ballRoots[ballIndex].getPos()\n        surfacePos = ballPos + norm * norm.dot(surfacePos - ballPos)\n\n        distance = norm.dot(surfacePos - ballPos)\n        if distance < 0:\n            return\n\n        \n        if distance < self.ballSize + 1e-3:\n            self.ballRoots[ballIndex].setPos(surfacePos - norm * self.ballSize)\n            if self.ballVs[ballIndex].length() > 1e-2:\n                self.ballVs[ballIndex] = (-norm * velAngle + inVec) * curSpeed\n                #self.ballVs[ballIndex] = -norm.cross(norm.cross(self.ballVs[ballIndex]))\n                self.accelVs[ballIndex] = -self.ballVs[ballIndex] / self.ballVs[ballIndex].length() * 0.0025\n            else:\n                self.ballVs[ballIndex] = LVector3(0, 0, 0)\n                self.accelVs[ballIndex] = LVector3(0, 0, 0)                \n                pass\n        else:\n            self.accelVs[ballIndex] = self.accelVs[ballIndex] - norm * norm.dot(self.accelVs[ballIndex]) + norm * 0.05\n            pass\n        return\n\n    \n        # if self.started:\n        #     if abs(distance - self.ballSize) > 0.001 and abs(distance - self.ballSize) < self.ballSize:\n        #         self.ballRoots[ballIndex].setPos(surfacePos - norm * self.ballSize)\n        #         pass\n        #     self.ballVs[ballIndex] = -norm.cross(norm.cross(self.ballVs[ballIndex]))\n        #     if self.ballVs[ballIndex].length() > 1e-3:\n        #         self.accelVs[ballIndex] = -self.ballVs[ballIndex] / self.ballVs[ballIndex].length() * 0.015\n        #     else:\n        #         self.ballVs[ballIndex] = LVector3(0, 0, 0)\n        #         self.accelVs[ballIndex] = LVector3(0, 0, 0)\n        #         pass\n        #     #print(self.ballVs[ballIndex], self.accelVs[ballIndex])\n        #     #print(surfacePos - norm * self.ballSize)\n\n        #     return\n\n\n        if ballIndex == 0:\n            print(\'distance_1\', self.started, distance, velAngle, self.ballVs[ballIndex], self.accelVs[ballIndex])\n        \n        if distance < self.ballSize:\n            self.ballRoots[ballIndex].setPos(surfacePos - norm * self.ballSize)\n            if velAngle > 0 and hitAngle > .995:\n                if abs(velAngle * curSpeed) < 0.2:\n                    if ((-norm * velAngle + inVec) * curSpeed).length() < 0.02:\n                        self.ballVs[ballIndex] = LVector3(0, 0, 0)\n                        self.accelVs[ballIndex] = LVector3(0, 0, 0)\n                        pass\n                    pass\n                else:\n                    if self.ballBouncing[ballIndex] > 0:\n                        if ballIndex == 0:\n                            print(\'bouncing\')\n                            pass\n                        self.ballVs[ballIndex] = (-norm * velAngle + inVec) * curSpeed * 0.5 - norm * velAngle * curSpeed * 0.25\n                        self.accelVs[ballIndex] = LVector3(0, 0, 0)\n                        self.ballBouncing[ballIndex] -= 1\n                    else:\n                        self.ballVs[ballIndex] = (-norm * velAngle + inVec) * curSpeed\n                        self.accelVs[ballIndex] = LVector3(0, 0, 0)\n                        pass\n                    pass\n                pass\n            \n            pass\n\n        if (distance - self.ballSize) > 0.001:\n            self.accelVs[ballIndex] = self.accelVs[ballIndex] - norm * norm.dot(self.accelVs[ballIndex]) + norm * 0.1\n            # print(self.accelVs[ballIndex] - norm * norm.dot(self.accelVs[ballIndex]))\n            # print(norm)\n            # print(inVec)\n            # print(velAngle)\n            # print(-norm * velAngle + inVec)\n            # print(norm * 0.01)\n            # exit(1)\n        elif distance - self.ballSize > -0.001:\n            if self.ballVs[ballIndex].length() < 0.001:\n                #print(\'stop\', self.ballVs[ballIndex], self.accelVs[ballIndex])\n\n                self.ballVs[ballIndex] = LVector3(0, 0, 0)\n                self.accelVs[ballIndex] = LVector3(0, 0, 0)\n                self.started = False\n            else:\n                if abs(velAngle) < 1e-3:\n                    self.ballVs[ballIndex] = (-norm * velAngle + inVec) * curSpeed\n                    #self.ballVs[ballIndex] = -norm.cross(norm.cross(self.ballVs[ballIndex]))\n                    self.accelVs[ballIndex] = -self.ballVs[ballIndex] / self.ballVs[ballIndex].length() * 0.01\n                    #print(\'speed\', self.ballVs[ballIndex], self.accelVs[ballIndex])\n                    pass\n                pass\n            pass\n    \n        # #print(distance - self.ballSize)\n        # if (distance - self.ballSize) > 0.01:\n        #     self.accelVs[ballIndex] = self.accelVs[ballIndex] - norm * norm.dot(self.accelVs[ballIndex]) + norm * 0.01\n        #     #if ballIndex == 0:\n        #     #print(velAngle, self.ballVs[ballIndex], self.accelVs[ballIndex], norm)\n        #     #pass\n\n        #     print(\'fall\', self.accelVs[ballIndex], distance)\n        #     # print(self.accelVs[ballIndex] - norm * norm.dot(self.accelVs[ballIndex]))\n        #     # print(norm)\n        #     # print(inVec)\n        #     # print(velAngle)\n        #     # print(-norm * velAngle + inVec)\n        #     # print(norm * 0.01)\n        #     # exit(1)\n        # else:\n        #     #hitAngle > .995\n        #     #print(velAngle)\n        #     #print(norm)\n\n        #     #self.ballRoots[ballIndex].setPos(surfacePos - norm * self.ballSize)\n        #     if curSpeed > 1e-1:\n        #         print(\'angle\', velAngle, norm)\n        #         self.norm = norm\n        #         pass\n        #     if velAngle > 1e-3:\n        #         if curSpeed < 1e-3:\n        #             self.ballVs[ballIndex] = LVector3(0, 0, 0)\n        #             self.accelVs[ballIndex] = LVector3(0, 0, 0)\n        #             self.ballRoots[ballIndex].setPos(surfacePos - norm * self.ballSize)\n        #         else:\n        #             self.ballVs[ballIndex] = (-norm * velAngle + inVec) * curSpeed * 0.9 - norm * velAngle * curSpeed * 0.25\n        #             self.accelVs[ballIndex] = LVector3(0, 0, 0)\n        #             pass\n        #         #print((-norm * velAngle + inVec) * curSpeed * 0.9, norm * velAngle * curSpeed * 0.25)\n        #         #print(curSpeed, norm.dot(self.ballVs[ballIndex]) / self.ballVs[ballIndex].length(), self.ballVs[ballIndex], self.accelVs[ballIndex])\n        #         #print(norm.dot(self.ballVs[ballIndex]) / self.ballVs[ballIndex].length(), norm.dot(self.accelVs[ballIndex]) / self.accelVs[ballIndex].length(), self.ballVs[ballIndex], self.accelVs[ballIndex])\n        #     elif velAngle > -1e-3:\n        #         if self.ballVs[ballIndex].length() < 0.001:\n        #             #self.ballVs[ballIndex] = LVector3(0, 0, 0)\n        #             #self.accelVs[ballIndex] = LVector3(0, 0, 0)\n        #             #print(\'stop\', self.ballVs[ballIndex], self.accelVs[ballIndex])\n        #             pass\n        #         else:\n        #             #self.ballVs[ballIndex] = (-norm * velAngle + inVec) * curSpeed * 0.9\n        #             #print(self.ballVs[ballIndex], self.accelVs[ballIndex])\n        #             self.accelVs[ballIndex] = -(-norm * velAngle + inVec) * 0.1\n        #             print(\'accel\', self.accelVs[ballIndex])\n        #             pass\n        #         pass\n        #     else:\n        #         #print(\'stop\', self.ballVs[ballIndex], self.accelVs[ballIndex])\n        #         #self.ballVs[ballIndex] = LVector3(0, 0, 0)\n        #         #self.accelVs[ballIndex] = LVector3(0, 0, 0)\n        #         pass\n        #     pass\n        return\n    \n    # This is the task that deals with making everything interactive\n    def rollTask(self, task):\n        # Standard technique for finding the amount of time since the last\n        # frame\n        dt = globalClock.getDt()\n\n        # If dt is large, then there has been a # hiccup that could cause the ball\n        # to leave the field if this functions runs, so ignore the frame\n        if dt > .2:\n            return Task.cont\n\n        # if base.mouseWatcherNode.is_button_down(\'a\'):\n        #     self.holeRoot.setH(self.holeRoot.getH() + 1)\n        #     print(self.holeRoot.getHpr())\n        #     pass\n        # if base.mouseWatcherNode.is_button_down(\'s\'):\n        #     self.holeRoot.setP(self.holeRoot.getP() + 1)\n        #     print(self.holeRoot.getHpr())\n        #     pass\n        # if base.mouseWatcherNode.is_button_down(\'d\'):\n        #     self.holeRoot.setR(self.holeRoot.getR() + 1)\n        #     print(self.holeRoot.getHpr())\n        #     pass\n\n\n        # go through different visualizations\n        if base.mouseWatcherNode.is_button_down(\'space\') and self.showing == \'none\':\n            self.showing = \'parts\'\n            self.showingProgress = 0\n            pass\n        #print(self.showing)\n        #print(self.showing)\n        if self.showing == \'none\':\n            return Task.cont\n        if self.showing == \'parts\':\n            self.showingProgress += 0.01\n            #self.showingProgress += 1\n            #print(self.showingProgress)\n            scale = 2 - self.showingProgress\n            scaleY = 1 + (scale - 1) * 0.5\n            for planeIndex, planeNP in enumerate(self.planeNPs):\n                center = self.planeCenters[planeIndex]\n                planeNP.setPos(center[0] * scale, center[1] * scaleY, center[2] * scale)\n                planeNP.reparentTo(self.render)\n                planeNP.setTwoSided(True)\n                continue\n            if self.showingProgress > 1:\n                self.showing = \'moving\'\n                for planeIndex, planeNP in enumerate(self.planeNPs):\n                    planeNP.removeNode()\n                    continue\n                self.planeScene.show()\n                self.showingProgress = 1\n            return Task.cont\n        if self.showing == \'moving\':\n            self.showingProgress += 0.005\n            #self.showingProgress += 1\n            #print(self.showingProgress, np.sign(self.showingProgress - 0.5) * min(self.showingProgress % 0.5, 0.5 - self.showingProgress % 0.5) * 4)\n            self.camera.setPos(np.sign(self.showingProgress - 0.5) * min(self.showingProgress % 0.5, 0.5 - self.showingProgress % 0.5) * 3, 0, 0)\n            #self.camera.setHpr(angleDegrees, 0, 0)\n            #self.camera.lookAt(0, 0, 0)\n            self.camera.lookAt(0, 3, 0)\n            if self.showingProgress > 1:\n                self.showing = \'geometry\'\n                self.camera.setPos(0, 0, 0)\n                #self.planeScene.removeNode()\n                # for triNP in self.triNPs:\n                #     triNP.show()\n                #     continue\n                self.showingProgress = 1\n            return Task.cont\n        if self.showing == \'geometry\':\n            self.showingProgress += 0.02\n            if self.showingProgress > 1:\n                #self.showing = \'image\'\n                self.showing = \'placement\'\n                self.showingProgress = 0\n                self.holeRoot.show()\n                self.inPortalRoot.show()\n                self.outPortalRoot.show()\n                self.inPortalTube.show()\n                self.outPortalTube.show()\n                for ballRoot in self.ballRoots:\n                    ballRoot.show()\n                    continue\n                self.showingProgress = 0                \n                pass\n            return Task.cont\n        # if self.showing == \'placement\':\n        #     self.showingProgress += 0.005\n        #         continue\n\n        # mouse pose\n        if self.mouseWatcherNode.hasMouse():\n            mpos = self.mouseWatcherNode.getMouse()\n            self.mpos = mpos\n            self.pickerRay.setFromLens(self.camNode, mpos.getX(), mpos.getY())\n            pass\n\n        \n        #if base.mouseWatcherNode.is_button_down(\'space\') and self.showing == \'placement\':\n        if self.showing == \'placement\':\n            self.card.show()\n            self.planeScene.removeNode()\n            self.showing = \'image\'\n            pass\n        # if base.mouseWatcherNode.is_button_down(\'space\') and self.showing == \'image\':\n        #     for triNP in self.triNPs:\n        #         triNP.hide()\n        #         continue\n        #     self.showing = \'start\'\n        #     pass\n            \n        \n        # for each plane, check which horizontal plane it is sitting on\n        self.ballGroundMap = {}\n        for i in range(self.cHandler.getNumEntries()):\n            entry = self.cHandler.getEntry(i)\n            ballName = entry.getFromNode().getName()\n            groundName = entry.getIntoNode().getName()            \n            if \'ball_ray_\' not in ballName:\n                continue\n            if \'ground_\' not in groundName:\n                continue\n            ballIndex = int(ballName[9:])\n            groundIndex = int(groundName[7:])\n            norm = -entry.getSurfaceNormal(render)\n            if norm.length() == 0:\n                continue\n            norm = norm / norm.length()            \n            distance = norm.dot(entry.getSurfacePoint(render) - self.ballRoots[ballIndex].getPos())\n            #print(distance)\n            if distance < 0:\n                continue\n            if ballIndex not in self.ballGroundMap or distance < self.ballGroundMap[ballIndex][1]:\n                self.ballGroundMap[ballIndex] = (groundIndex, distance)\n                pass\n            continue\n\n        # The collision handler collects the collisions. We dispatch which function\n        # to handle the collision based on the name of what was collided into        \n        for i in range(self.cHandler.getNumEntries()):\n            entry = self.cHandler.getEntry(i)\n            fromName = entry.getFromNode().getName()\n            #if \'mouseRay\' in fromName:\n            #continue\n            name = entry.getIntoNode().getName()            \n            #if name == ""plane_collide"":\n            if \'tri_\' in name:\n                self.planeCollideHandler(entry)\n            #elif name == ""wall_collide"":\n            #self.wallCollideHandler(entry)\n            #elif name == ""ground_collide"":\n            #self.groundCollideHandler(entry)\n            elif \'ball_\' in name:\n                self.ballCollideHandler(entry)\n            elif \'ground_\' in name:\n                self.groundCollideHandler(entry)\n            elif \'hole\' in name:\n                self.score(entry)\n            elif \'portal_\' in name:\n                self.portal(entry)\n                pass\n            continue\n\n        # Read the mouse position and tilt the maze accordingly\n        if base.mouseWatcherNode.hasMouse():\n            mpos = base.mouseWatcherNode.getMouse()  # get the mouse position\n            #self.maze.setP(mpos.getY() * -10)\n            #self.maze.setR(mpos.getX() * 10)\n            pass\n\n        # if base.mouseWatcherNode.is_button_down(\'mouse1\'):\n        #     print(base.mouseWatcherNode.getMouseX())\n        #     print(base.mouseWatcherNode.getMouseY())            \n        #     exit(1)\n            \n        # Finally, we move the ball\n        # Update the velocity based on acceleration\n        for ballIndex in xrange(len(self.balls)):\n            if self.ballVs[ballIndex].length() < 1e-4 and self.ballVs[ballIndex].dot(self.accelVs[ballIndex]) < -1e-4:\n                self.ballVs[ballIndex] = LVector3(0, 0, 0)\n                self.accelVs[ballIndex] = LVector3(0, 0, 0)\n            else:\n                self.ballVs[ballIndex] += self.accelVs[ballIndex] * dt * ACCEL\n                pass\n            #print(\'current speed\', self.ballVs[ballIndex], self.accelVs[ballIndex])\n            # Clamp the velocity to the maximum speed\n            if self.ballVs[ballIndex].lengthSquared() > MAX_SPEED_SQ:\n                self.ballVs[ballIndex].normalize()\n                self.ballVs[ballIndex] *= MAX_SPEED\n                pass\n            #print(self.ballVs[ballIndex], self.accelVs[ballIndex], self.ballRoots[ballIndex].getPos())\n            \n            # Update the position based on the velocity\n            self.ballRoots[ballIndex].setPos(self.ballRoots[ballIndex].getPos() + (self.ballVs[ballIndex] * dt))\n\n            # This block of code rotates the ball. It uses something called a quaternion\n            # to rotate the ball around an arbitrary axis. That axis perpendicular to\n            # the balls rotation, and the amount has to do with the size of the ball\n            # This is multiplied on the previous rotation to incrimentally turn it.\n            prevRot = LRotationf(self.balls[ballIndex].getQuat())\n            axis = LVector3.up().cross(self.ballVs[ballIndex])\n            newRot = LRotationf(axis, np.rad2deg(dt * self.ballVs[ballIndex].length() / self.ballSize))\n            self.balls[ballIndex].setQuat(prevRot * newRot)\n            continue\n\n        self.cueRoot.setPos(self.cuePos[0], self.cuePos[1], self.cuePos[2])\n        return Task.cont       # Continue the task indefinitely\n\n    # handle scoring (when a ball fall in a hole)\n    def score(self, colEntry):\n        ballName = colEntry.getFromNode().getName()\n        if \'ball_\' not in ballName:\n            return\n        print(\'score\', ballName)\n        ballIndex = int(ballName[5:])\n        self.ballRoots[ballIndex].removeNode()\n\n        del self.ballRoots[ballIndex]\n        del self.balls[ballIndex]\n        del self.ballSpheres[ballIndex]\n        del self.ballGroundRays[ballIndex]        \n        del self.ballVs[ballIndex]\n        del self.accelVs[ballIndex]\n        for otherIndex in xrange(ballIndex, len(self.balls)):\n            self.ballSpheres[otherIndex].setName(\'ball_\' + str(otherIndex))\n            self.ballGroundRays[otherIndex].setName(\'ball_ray_\' + str(otherIndex))\n            continue\n        return\n        \n    # # If the ball hits a hole trigger, then it should fall in the hole.\n    # # This is faked rather than dealing with the actual physics of it.\n    # def loseGame(self, entry):\n    #     # The triggers are set up so that the center of the ball should move to the\n    #     # collision point to be in the hole\n    #     toPos = entry.getInteriorPoint(render)\n    #     taskMgr.remove(\'rollTask\')  # Stop the maze task\n\n    #     # Move the ball into the hole over a short sequence of time. Then wait a\n    #     # second and call start to reset the game\n    #     Sequence(\n    #         Parallel(\n    #             LerpFunc(self.ballRoot.setX, fromData=self.ballRoot.getX(),\n    #                      toData=toPos.getX(), duration=.1),\n    #             LerpFunc(self.ballRoot.setY, fromData=self.ballRoot.getY(),\n    #                      toData=toPos.getY(), duration=.1),\n    #             LerpFunc(self.ballRoot.setZ, fromData=self.ballRoot.getZ(),\n    #                      toData=self.ballRoot.getZ() - .9, duration=.2)),\n    #         Wait(1),\n    #         Func(self.start)).start()\n\n    \n# Finally, create an instance of our class and start 3d rendering\napp = PoolBallGame()\napp.run()            \n'"
pytorch/augmentation.py,0,"b'import numpy as np\nimport cv2\n\ndef horizontalFlip(image, planes, segmentation, depth, metadata):\n    image = image[:, ::-1]\n    depth = depth[:, ::-1]\n    segmentation = segmentation[:, ::-1]\n    metadata[2] = image.shape[1] - metadata[2]\n    if len(planes) > 0:\n        planes[:, 0] *= -1\n        pass\n    return image, planes, segmentation, depth, metadata\n\ndef cropPatch(box, imageSizes, image, planes, segmentation, depth, metadata):\n    mins, ranges = box\n    image = cv2.resize(image[mins[1]:mins[1] + ranges[1], mins[0]:mins[0] + ranges[0]], (imageSizes[0], imageSizes[1]))\n    depth = cv2.resize(depth[mins[1]:mins[1] + ranges[1], mins[0]:mins[0] + ranges[0]], (imageSizes[0], imageSizes[1]))\n    segmentation = cv2.resize(segmentation[mins[1]:mins[1] + ranges[1], mins[0]:mins[0] + ranges[0]], (imageSizes[0], imageSizes[1]), interpolation=cv2.INTER_NEAREST)\n    metadata[0] *= float(imageSizes[0]) / ranges[0]\n    metadata[1] *= float(imageSizes[1]) / ranges[1]\n    metadata[2] = (metadata[2] - mins[0]) * float(imageSizes[0]) / ranges[0]\n    metadata[3] = (metadata[3] - mins[1]) * float(imageSizes[1]) / ranges[1]\n    metadata[4] = imageSizes[0]\n    metadata[5] = imageSizes[1]    \n    return image, planes, segmentation, depth, metadata\n'"
pytorch/options.py,0,"b'import argparse\n\ndef parse_args():\n    """"""\n    Parse input arguments\n    """"""\n    parser = argparse.ArgumentParser(description=\'PlaneFlow\')\n    \n    parser.add_argument(\'--task\', dest=\'task\',\n                        help=\'task type: [train, test, predict]\',\n                        default=\'train\', type=str)\n    parser.add_argument(\'--restore\', dest=\'restore\',\n                        help=\'how to restore the model\',\n                        default=1, type=int)\n    parser.add_argument(\'--batchSize\', dest=\'batchSize\',\n                        help=\'batch size\',\n                        default=16, type=int)\n    parser.add_argument(\'--dataset\', dest=\'dataset\',\n                        help=\'dataset name for training\',\n                        default=\'scannet\', type=str)\n    parser.add_argument(\'--testingDataset\', dest=\'testingDataset\',\n                        help=\'dataset name for test/predict\',\n                        default=\'scannet\', type=str)\n    parser.add_argument(\'--numTrainingImages\', dest=\'numTrainingImages\',\n                        help=\'the number of images to train\',\n                        default=10000, type=int)\n    parser.add_argument(\'--numTestingImages\', dest=\'numTestingImages\',\n                        help=\'the number of images to test/predict\',\n                        default=100, type=int)\n    parser.add_argument(\'--LR\', dest=\'LR\',\n                        help=\'learning rate\',\n                        default=2.5e-4, type=float)\n    parser.add_argument(\'--numEpochs\', dest=\'numEpochs\',\n                        help=\'the number of epochs\',\n                        default=1000, type=int)\n    parser.add_argument(\'--startEpoch\', dest=\'startEpoch\',\n                        help=\'starting epoch index\',\n                        default=0, type=int)\n    parser.add_argument(\'--modelType\', dest=\'modelType\',\n                        help=\'model type\',\n                        default=\'\', type=str)\n    parser.add_argument(\'--heatmapThreshold\', dest=\'heatmapThreshold\',\n                        help=\'heatmap threshold for positive predictions\',\n                        default=0.5, type=float)\n    parser.add_argument(\'--distanceThreshold3D\', dest=\'distanceThreshold3D\',\n                        help=\'distance threshold 3D\',\n                        default=0.2, type=float)\n    parser.add_argument(\'--distanceThreshold2D\', dest=\'distanceThreshold2D\',\n                        help=\'distance threshold 2D\',\n                        default=20, type=float)\n    parser.add_argument(\'--numInputPlanes\', dest=\'numInputPlanes\',\n                        help=\'the number of input planes\',\n                        default=1024, type=int)\n    parser.add_argument(\'--numOutputPlanes\', dest=\'numOutputPlanes\',\n                        help=\'the number of output planes\',\n                        default=10, type=int)\n    parser.add_argument(\'--numInputClasses\', dest=\'numInputClasses\',\n                        help=\'the number of input classes\',\n                        default=0, type=int)\n    parser.add_argument(\'--numOutputClasses\', dest=\'numOutputClasses\',\n                        help=\'the number of output classes\',\n                        default=0, type=int)    \n    parser.add_argument(\'--width\', dest=\'width\',\n                        help=\'input width\',\n                        default=256, type=int)\n    parser.add_argument(\'--height\', dest=\'height\',\n                        help=\'input height\',\n                        default=192, type=int)\n    parser.add_argument(\'--outputWidth\', dest=\'outputWidth\',\n                        help=\'output width\',\n                        default=256, type=int)\n    parser.add_argument(\'--outputHeight\', dest=\'outputHeight\',\n                        help=\'output height\',\n                        default=192, type=int)\n    ## Flags\n    parser.add_argument(\'--visualizeMode\', dest=\'visualizeMode\',\n                        help=\'visualization mode\',\n                        default=\'\', type=str)    \n    parser.add_argument(\'--suffix\', dest=\'suffix\',\n                        help=\'suffix to distinguish experiments\',\n                        default=\'\', type=str)    \n    \n    args = parser.parse_args()\n    return args\n\n'"
pytorch/train_planenet.py,0,"b'import torch\nfrom torch.utils.data import DataLoader\n\nfrom tqdm import tqdm\nimport numpy as np\nimport os\n\nfrom utils import *\nfrom options import parse_args\n\nfrom models.planenet import PlaneNet\nfrom models.modules import *\n\nfrom datasets.plane_dataset import PlaneDataset\n\ndef main(options):\n    if not os.path.exists(options.checkpoint_dir):\n        os.system(""mkdir -p %s""%options.checkpoint_dir)\n        pass\n    if not os.path.exists(options.test_dir):\n        os.system(""mkdir -p %s""%options.test_dir)\n        pass\n\n    dataset = PlaneDataset(options, split=\'train\', random=True)\n    dataset_test = PlaneDataset(options, split=\'test\', random=False)\n\n    print(\'the number of images\', len(dataset), len(dataset_test))    \n\n    dataloader = DataLoader(dataset, batch_size=options.batchSize, shuffle=True, num_workers=16)\n\n    model = PlaneNet(options)\n    model.cuda()\n    model.train()\n\n    if options.restore == 1 and os.path.exists(options.checkpoint_dir + \'/checkpoint.pth\'):\n        print(\'restore\')\n        model.load_state_dict(torch.load(options.checkpoint_dir + \'/checkpoint.pth\'))\n        pass\n\n    plane_criterion = torch.nn.MSELoss(reduce=False)    \n    segmentation_criterion = torch.nn.CrossEntropyLoss()\n    depth_criterion = torch.nn.MSELoss(reduce=False)    \n    \n    if options.task == \'test\':\n        testOneEpoch(options, model, plane_criterion, segmentation_criterion, depth_criterion, dataset_test)\n        exit(1)\n    \n    optimizer = torch.optim.Adam(model.parameters(), lr = options.LR)\n    if options.restore == 1 and os.path.exists(options.checkpoint_dir + \'/optim.pth\'):\n        optimizer.load_state_dict(torch.load(options.checkpoint_dir + \'/optim.pth\'))\n        pass\n\n    for epoch in range(options.numEpochs):\n        epoch_losses = []\n        data_iterator = tqdm(dataloader, total=len(dataset) // options.batchSize + 1)\n        for sampleIndex, sample in enumerate(data_iterator):\n            image_inp, planes_gt, segmentation_gt, depth_gt, metadata, numbers = sample[0].cuda(), sample[1].cuda(), sample[2].cuda(), sample[3].cuda(), sample[4].cuda(), sample[5].cuda()\n\n            optimizer.zero_grad()\n            planes_pred, segmentation_pred, non_plane_depth_pred = model(image_inp)\n\n            distances = torch.norm(planes_gt.unsqueeze(2) - planes_pred.unsqueeze(1), dim=-1)\n            W = distances.max() - distances.transpose(1, 2)\n            mapping = torch.stack([assignmentModule(W[batchIndex]) for batchIndex in xrange(len(distances))], dim=0)\n\n            mapping = oneHotModule(mapping.view(-1), depth=int(planes_pred.shape[1])).view((int(mapping.shape[0]), int(mapping.shape[1]), -1))\n            planes_pred_shuffled = torch.matmul(mapping, planes_pred)\n            segmentation_pred_shuffled = torch.matmul(mapping, segmentation_pred[:, :-1].view((int(segmentation_pred.shape[0]), options.numOutputPlanes, -1))).view(segmentation_pred[:, :-1].shape)\n            segmentation_pred_shuffled = torch.cat([segmentation_pred_shuffled, segmentation_pred[:, -1:]], dim=1)\n\n            validMask = (torch.arange(int(planes_gt.shape[1]), dtype=torch.int64).cuda() < numbers.unsqueeze(-1)).float()\n            \n            plane_loss = torch.sum(plane_criterion(planes_pred_shuffled, planes_gt) * validMask.unsqueeze(-1)) / torch.sum(validMask)\n            segmentation_loss = segmentation_criterion(segmentation_pred_shuffled, segmentation_gt)\n\n                        \n            segmentation_pred_shuffled = torch.nn.Softmax(dim=1)(segmentation_pred_shuffled)\n            plane_depths = calcPlaneDepthsModule(options.outputWidth, options.outputHeight, planes_pred_shuffled, metadata[0])\n            all_depths = torch.cat([plane_depths.transpose(2, 3).transpose(1, 2), non_plane_depth_pred], dim=1)\n            depth_mask = ((depth_gt > 1e-4) & (depth_gt < MAX_DEPTH)).float()\n            depth_loss = torch.mean(torch.pow(all_depths - depth_gt.unsqueeze(1), 2) * depth_mask.unsqueeze(1) * segmentation_pred_shuffled) * 10\n            depth_pred = torch.sum(all_depths * segmentation_pred_shuffled, 1) * depth_mask\n\n            segmentation_pred_shuffled = segmentation_pred_shuffled.max(1)[1]\n            #depth_pred = calcDepthModule(options.outputWidth, options.outputHeight, planes_pred, segmentation_pred, non_plane_depth_pred, metadata[0])\n            #depth_loss = depth_criterion(depth_pred, depth_gt)\n\n            depth_gt = calcDepthModule(options.outputWidth, options.outputHeight, planes_gt, oneHotModule(segmentation_gt, depth=options.numOutputPlanes + 1).transpose(2, 3).transpose(1, 2), depth_gt.unsqueeze(1), metadata[0])\n            \n            \n            #print(torch.round(adjacency_pred_shuffled[0]).long())\n            #print(adjacency_gt[0])\n            \n            losses = [plane_loss, segmentation_loss, depth_loss]\n            loss = sum(losses)\n\n            loss_values = [l.data.item() for l in losses]\n            epoch_losses.append(loss_values)\n            status = str(epoch + 1) + \' loss: \'\n            for l in loss_values:\n                status += \'%0.5f \'%l\n                continue\n            data_iterator.set_description(status)\n            loss.backward()\n            optimizer.step()\n\n            if sampleIndex % 500 == 0:\n                visualizeBatchPlanes(options, image_inp.detach().cpu().numpy(), numbers.long().detach().cpu().numpy(), [(\'gt\', {\'plane\': planes_gt.detach().cpu().numpy(), \'segmentation\': segmentation_gt.detach().cpu().numpy(), \'depth\': depth_gt.detach().cpu().numpy()}), (\'pred\', {\'plane\': planes_pred_shuffled.detach().cpu().numpy(), \'segmentation\': segmentation_pred_shuffled.detach().cpu().numpy(), \'depth\': depth_pred.detach().cpu().numpy()})])\n                if options.visualizeMode == \'debug\':\n                    exit(1)\n                    pass\n            continue\n        print(\'loss\', np.array(epoch_losses).mean(0))\n        if True:\n            torch.save(model.state_dict(), options.checkpoint_dir + \'/checkpoint.pth\')\n            torch.save(optimizer.state_dict(), options.checkpoint_dir + \'/optim.pth\')\n            pass\n\n        testOneEpoch(options, model, plane_criterion, segmentation_criterion, depth_criterion, dataset_test)        \n        continue\n\n    #test(options)\n    return\n\ndef testOneEpoch(options, model, plane_criterion, segmentation_criterion, depth_criterion, dataset):\n    model.eval()\n    \n    dataloader = DataLoader(dataset, batch_size=options.batchSize, shuffle=False, num_workers=4)\n    \n    epoch_losses = []    \n    data_iterator = tqdm(dataloader, total=len(dataset) // options.batchSize + 1)\n    for sampleIndex, sample in enumerate(data_iterator):\n        image_inp, planes_gt, segmentation_gt, depth_gt, metadata, numbers = sample[0].cuda(), sample[1].cuda(), sample[2].cuda(), sample[3].cuda(), sample[4].cuda(), sample[5].cuda()\n\n        planes_pred, segmentation_pred, non_plane_depth_pred = model(image_inp)\n\n        distances = torch.norm(planes_gt.unsqueeze(2) - planes_pred.unsqueeze(1), dim=-1)\n        W = distances.max() - distances.transpose(1, 2)\n        mapping = torch.stack([assignmentModule(W[batchIndex]) for batchIndex in xrange(len(distances))], dim=0)\n\n        mapping = oneHotModule(mapping.view(-1), depth=int(planes_pred.shape[1])).view((int(mapping.shape[0]), int(mapping.shape[1]), -1))\n        planes_pred_shuffled = torch.matmul(mapping, planes_pred)\n        segmentation_pred_shuffled = torch.matmul(mapping, segmentation_pred[:, :-1].view((int(segmentation_pred.shape[0]), options.numOutputPlanes, -1))).view(segmentation_pred[:, :-1].shape)\n        segmentation_pred_shuffled = torch.cat([segmentation_pred_shuffled, segmentation_pred[:, -1:]], dim=1)\n\n        validMask = (torch.arange(int(planes_gt.shape[1]), dtype=torch.int64).cuda() < numbers.unsqueeze(-1)).float()\n\n        plane_loss = torch.sum(plane_criterion(planes_pred_shuffled, planes_gt) * validMask.unsqueeze(-1)) / torch.sum(validMask)\n        segmentation_loss = segmentation_criterion(segmentation_pred_shuffled, segmentation_gt)\n\n\n        segmentation_pred_shuffled = torch.nn.Softmax(dim=1)(segmentation_pred_shuffled)\n        plane_depths = calcPlaneDepthsModule(options.outputWidth, options.outputHeight, planes_pred_shuffled, metadata[0])\n        all_depths = torch.cat([plane_depths.transpose(2, 3).transpose(1, 2), non_plane_depth_pred], dim=1)\n        depth_mask = ((depth_gt > 1e-4) & (depth_gt < MAX_DEPTH)).float()\n        depth_loss = torch.mean(torch.pow(all_depths - depth_gt.unsqueeze(1), 2) * depth_mask.unsqueeze(1) * segmentation_pred_shuffled) * 10\n        depth_pred = torch.sum(all_depths * segmentation_pred_shuffled, 1) * depth_mask\n\n        #depth_pred = calcDepthModule(options.outputWidth, options.outputHeight, planes_pred, segmentation_pred, non_plane_depth_pred, metadata[0])\n        #depth_loss = depth_criterion(depth_pred, depth_gt)\n\n        #depth_gt = calcDepthModule(options.outputWidth, options.outputHeight, planes_gt, oneHotModule(segmentation_gt, depth=options.numOutputPlanes + 1).transpose(2, 3).transpose(1, 2), depth_gt.unsqueeze(1), metadata[0])\n\n\n        segmentation_pred = segmentation_pred.max(1)[1]\n        segmentation_pred_shuffled = segmentation_pred_shuffled.max(1)[1]        \n        #print(torch.round(adjacency_pred_shuffled[0]).long())\n        #print(adjacency_gt[0])\n\n        losses = [plane_loss, segmentation_loss, depth_loss]\n        loss = sum(losses)\n\n        loss_values = [l.data.item() for l in losses]\n        epoch_losses.append(loss_values)\n        status = \'val loss: \'\n        for l in loss_values:\n            status += \'%0.5f \'%l\n            continue\n        data_iterator.set_description(status)\n\n        if sampleIndex % 500 == 0:\n            visualizeBatchPlanes(options, image_inp.detach().cpu().numpy(), numbers.long().detach().cpu().numpy(), [(\'gt\', {\'plane\': planes_gt.detach().cpu().numpy(), \'segmentation\': segmentation_gt.detach().cpu().numpy(), \'depth\': depth_gt.detach().cpu().numpy()}), (\'pred\', {\'plane\': planes_pred_shuffled.detach().cpu().numpy(), \'segmentation\': segmentation_pred_shuffled.detach().cpu().numpy(), \'depth\': depth_pred.detach().cpu().numpy()})], prefix=\'test\')\n            if options.visualizeMode == \'debug\':\n                exit(1)\n                pass\n        continue\n    print(\'validation loss\', np.array(epoch_losses).mean(0))\n\n    model.train()\n    return\n\ndef visualizeBatchPlanes(options, image_inp, numbers, dicts, indexOffset=0, prefix=\'\'):\n    #cornerColorMap = {\'gt\': np.array([255, 0, 0]), \'pred\': np.array([0, 0, 255]), \'inp\': np.array([0, 255, 0])}\n    #pointColorMap = ColorPalette(20).getColorMap()\n    image_inp = image_inp.transpose((0, 2, 3, 1))\n    for batchIndex in range(len(image_inp)):\n        if prefix == \'\':\n            filename = options.test_dir + \'/\' + str(indexOffset + batchIndex) + \'_input.png\'\n        else:\n            filename = options.test_dir + \'/\' + prefix + \'_\' + str(indexOffset + batchIndex) + \'_input.png\'\n            pass\n\n        inputImage = ((image_inp[batchIndex] + MEAN_STD[0]) * 255).astype(np.uint8)        \n        cv2.imwrite(filename, inputImage)\n        for name, result_dict in dicts:\n            #image = inputImage.copy()\n            segmentationImage = drawSegmentationImage(result_dict[\'segmentation\'][batchIndex], blackIndex=options.numOutputPlanes)\n            cv2.imwrite(filename.replace(\'input\', \'segmentation_\' + name), segmentationImage)\n            depthImage = drawDepthImage(result_dict[\'depth\'][batchIndex])\n            cv2.imwrite(filename.replace(\'input\', \'depth_\' + name), depthImage)\n            continue\n        continue\n    return\n\nif __name__ == \'__main__\':\n    args = parse_args()\n    \n    args.keyname = \'planenet\'\n    #args.keyname += \'_\' + args.dataset\n\n    if args.suffix != \'\':\n        args.keyname += \'_\' + suffix\n        pass\n    \n    args.checkpoint_dir = \'checkpoint/\' + args.keyname\n    args.test_dir = \'test/\' + args.keyname\n\n    print(\'keyname=%s task=%s started\'%(args.keyname, args.task))\n\n    main(args)\n'"
pytorch/utils.py,0,"b'import numpy as np\nimport cv2\n\n#MEAN_STD = [[0.29010095242892997, 0.32808144844279574, 0.28696394422942517], [0.1829540508368939, 0.18656561047509476, 0.18447508988480435]]\nMEAN_STD = np.array([[0.5, 0.5, 0.5], [1, 1, 1]], dtype=np.float32)\nMAX_DEPTH = 10\n\n## Global color mapping\nclass ColorPalette:\n    def __init__(self, numColors):\n        np.random.seed(1)\n\n        self.colorMap = np.array([[255, 0, 0],\n                                  [0, 255, 0],\n                                  [0, 0, 255],\n                                  [80, 128, 255],\n                                  [128, 0, 255],\n                                  [255, 0, 255],\n                                  [0, 255, 255],\n                                  [255, 0, 128],\n                                  [255, 255, 0],\n                                  [0, 128, 255],\n                                  [50, 150, 0],\n                                  [200, 255, 255],\n                                  [255, 200, 255],\n                                  [128, 128, 80],\n                                  [0, 50, 128],\n                                  [0, 100, 100],\n                                  [0, 255, 128],\n                                  [100, 0, 0],\n                                  [0, 100, 0],\n                                  [255, 230, 180],\n                                  [255, 128, 0],\n                                  [128, 255, 0],\n        ], dtype=np.uint8)\n        self.colorMap = np.maximum(self.colorMap, 1)\n\n        if numColors > self.colorMap.shape[0]:\n            self.colorMap = np.concatenate([self.colorMap, np.random.randint(255, size = (numColors - self.colorMap.shape[0], 3), dtype=np.uint8)], axis=0)\n            pass\n\n        #self.colorMap = np.random.randint(255, size = (numColors, 3), dtype=np.uint8)\n        #self.colorMap[0] = np.maximum(self.colorMap[0], 1)\n        return\n\n    def getColorMap(self):\n        return self.colorMap\n\n    def getColor(self, index):\n        if index >= colorMap.shape[0]:\n            return np.random.randint(255, size = (3), dtype=np.uint8)\n        else:\n            return self.colorMap[index]\n            pass\n        return\n    \n## Draw segmentation image. The input could be either HxW or HxWxC\ndef drawSegmentationImage(segmentations, numColors=42, blackIndex=-1, blackThreshold=-1):\n    if segmentations.ndim == 2:\n        numColors = max(numColors, segmentations.max() + 2)\n    else:\n        if blackThreshold > 0:\n            segmentations = np.concatenate([segmentations, np.ones((segmentations.shape[0], segmentations.shape[1], 1)) * blackThreshold], axis=2)\n            blackIndex = segmentations.shape[2] - 1\n            pass\n\n        numColors = max(numColors, segmentations.shape[2] + 2)\n        pass\n    randomColor = ColorPalette(numColors).getColorMap()\n    if blackIndex >= 0:\n        randomColor[blackIndex] = 0\n        pass\n    width = segmentations.shape[1]\n    height = segmentations.shape[0]\n    if segmentations.ndim == 3:\n        #segmentation = (np.argmax(segmentations, 2) + 1) * (np.max(segmentations, 2) > 0.5)\n        segmentation = np.argmax(segmentations, 2)\n    else:\n        segmentation = segmentations\n        pass\n\n    segmentation = segmentation.astype(np.int32)\n    return randomColor[segmentation.reshape(-1)].reshape((height, width, 3))\n\n## Draw depth image\ndef drawDepthImage(depth):\n    depthImage = np.clip(depth / 5 * 255, 0, 255).astype(np.uint8)\n    depthImage = cv2.applyColorMap(255 - depthImage, colormap=cv2.COLORMAP_JET)\n    return depthImage\n\n## Math operations\ndef softmax(values):\n    exp = np.exp(values - values.max())\n    return exp / exp.sum(-1, keepdims=True)\n\ndef one_hot(values, depth):\n    maxInds = values.reshape(-1)\n    results = np.zeros([maxInds.shape[0], depth])\n    results[np.arange(maxInds.shape[0]), maxInds] = 1\n    results = results.reshape(list(values.shape) + [depth])\n    return results\n\ndef sigmoid(values):\n    return 1 / (1 + np.exp(-values))\n\n\n## Fit a 3D plane from points\ndef fitPlane(points):\n    if points.shape[0] == points.shape[1]:\n        return np.linalg.solve(points, np.ones(points.shape[0]))\n    else:\n        return np.linalg.lstsq(points, np.ones(points.shape[0]))[0]\n    return\n\n\n## Metadata to intrinsics\ndef metadataToIntrinsics(metadata):\n    intrinsics = np.zeros((3, 3))\n    intrinsics[0][0] = metadata[0]\n    intrinsics[1][1] = metadata[1]\n    intrinsics[0][2] = metadata[2]\n    intrinsics[1][2] = metadata[3]\n    intrinsics[2][2] = 1\n    return intrinsics\n\n## The function to compute plane depths from plane parameters\ndef calcPlaneDepths(planes, width, height, metadata):\n    urange = (np.arange(width, dtype=np.float32).reshape(1, -1).repeat(height, 0) / (width + 1) * (metadata[4] + 1) - metadata[2]) / metadata[0]\n    vrange = (np.arange(height, dtype=np.float32).reshape(-1, 1).repeat(width, 1) / (height + 1) * (metadata[5] + 1) - metadata[3]) / metadata[1]\n    ranges = np.stack([urange, np.ones(urange.shape), -vrange], axis=-1)\n    \n    planeOffsets = np.linalg.norm(planes, axis=-1, keepdims=True)\n    planeNormals = planes / np.maximum(planeOffsets, 1e-4)\n\n    normalXYZ = np.dot(ranges, planeNormal.transpose())\n    normalXYZ[normalXYZ == 0] = 1e-4\n    planeDepths = planeOffsets / normalXYZ\n    planeDepths = np.clip(planeDepths, 0, MAX_DEPTH)\n    return planeDepths\n'"
code/kaffe/__init__.py,0,"b'from .graph import GraphBuilder, NodeMapper\nfrom .errors import KaffeError, print_stderr\n\nfrom . import tensorflow\n'"
code/kaffe/errors.py,0,"b""import sys\n\nclass KaffeError(Exception):\n    pass\n\ndef print_stderr(msg):\n    sys.stderr.write('%s\\n' % msg)\n"""
code/kaffe/graph.py,0,"b'from google.protobuf import text_format\n\nfrom .caffe import get_caffe_resolver\nfrom .errors import KaffeError, print_stderr\nfrom .layers import LayerAdapter, LayerType, NodeKind, NodeDispatch\nfrom .shapes import TensorShape\n\nclass Node(object):\n\n    def __init__(self, name, kind, layer=None):\n        self.name = name\n        self.kind = kind\n        self.layer = LayerAdapter(layer, kind) if layer else None\n        self.parents = []\n        self.children = []\n        self.data = None\n        self.output_shape = None\n        self.metadata = {}\n\n    def add_parent(self, parent_node):\n        assert parent_node not in self.parents\n        self.parents.append(parent_node)\n        if self not in parent_node.children:\n            parent_node.children.append(self)\n\n    def add_child(self, child_node):\n        assert child_node not in self.children\n        self.children.append(child_node)\n        if self not in child_node.parents:\n            child_node.parents.append(self)\n\n    def get_only_parent(self):\n        if len(self.parents) != 1:\n            raise KaffeError(\'Node (%s) expected to have 1 parent. Found %s.\' %\n                             (self, len(self.parents)))\n        return self.parents[0]\n\n    @property\n    def parameters(self):\n        if self.layer is not None:\n            return self.layer.parameters\n        return None\n\n    def __str__(self):\n        return \'[%s] %s\' % (self.kind, self.name)\n\n    def __repr__(self):\n        return \'%s (0x%x)\' % (self.name, id(self))\n\n\nclass Graph(object):\n\n    def __init__(self, nodes=None, name=None):\n        self.nodes = nodes or []\n        self.node_lut = {node.name: node for node in self.nodes}\n        self.name = name\n\n    def add_node(self, node):\n        self.nodes.append(node)\n        self.node_lut[node.name] = node\n\n    def get_node(self, name):\n        try:\n            return self.node_lut[name]\n        except KeyError:\n            raise KaffeError(\'Layer not found: %s\' % name)\n\n    def get_input_nodes(self):\n        return [node for node in self.nodes if len(node.parents) == 0]\n\n    def get_output_nodes(self):\n        return [node for node in self.nodes if len(node.children) == 0]\n\n    def topologically_sorted(self):\n        sorted_nodes = []\n        unsorted_nodes = list(self.nodes)\n        temp_marked = set()\n        perm_marked = set()\n\n        def visit(node):\n            if node in temp_marked:\n                raise KaffeError(\'Graph is not a DAG.\')\n            if node in perm_marked:\n                return\n            temp_marked.add(node)\n            for child in node.children:\n                visit(child)\n            perm_marked.add(node)\n            temp_marked.remove(node)\n            sorted_nodes.insert(0, node)\n\n        while len(unsorted_nodes):\n            visit(unsorted_nodes.pop())\n        return sorted_nodes\n\n    def compute_output_shapes(self):\n        sorted_nodes = self.topologically_sorted()\n        for node in sorted_nodes:\n            node.output_shape = TensorShape(*NodeKind.compute_output_shape(node))\n\n    def replaced(self, new_nodes):\n        return Graph(nodes=new_nodes, name=self.name)\n\n    def transformed(self, transformers):\n        graph = self\n        for transformer in transformers:\n            graph = transformer(graph)\n            if graph is None:\n                raise KaffeError(\'Transformer failed: {}\'.format(transformer))\n            assert isinstance(graph, Graph)\n        return graph\n\n    def __contains__(self, key):\n        return key in self.node_lut\n\n    def __str__(self):\n        hdr = \'{:<20} {:<30} {:>20} {:>20}\'.format(\'Type\', \'Name\', \'Param\', \'Output\')\n        s = [hdr, \'-\' * 94]\n        for node in self.topologically_sorted():\n            # If the node has learned parameters, display the first one\'s shape.\n            # In case of convolutions, this corresponds to the weights.\n            data_shape = node.data[0].shape if node.data else \'--\'\n            out_shape = node.output_shape or \'--\'\n            s.append(\'{:<20} {:<30} {:>20} {:>20}\'.format(node.kind, node.name, data_shape,\n                                                          tuple(out_shape)))\n        return \'\\n\'.join(s)\n\n\nclass GraphBuilder(object):\n    \'\'\'Constructs a model graph from a Caffe protocol buffer definition.\'\'\'\n\n    def __init__(self, def_path, phase=\'test\'):\n        \'\'\'\n        def_path: Path to the model definition (.prototxt)\n        data_path: Path to the model data (.caffemodel)\n        phase: Either \'test\' or \'train\'. Used for filtering phase-specific nodes.\n        \'\'\'\n        self.def_path = def_path\n        self.phase = phase\n        self.load()\n\n    def load(self):\n        \'\'\'Load the layer definitions from the prototxt.\'\'\'\n        self.params = get_caffe_resolver().NetParameter()\n        with open(self.def_path, \'rb\') as def_file:\n            text_format.Merge(def_file.read(), self.params)\n\n    def filter_layers(self, layers):\n        \'\'\'Filter out layers based on the current phase.\'\'\'\n        phase_map = {0: \'train\', 1: \'test\'}\n        filtered_layer_names = set()\n        filtered_layers = []\n        for layer in layers:\n            phase = self.phase\n            if len(layer.include):\n                phase = phase_map[layer.include[0].phase]\n            if len(layer.exclude):\n                phase = phase_map[1 - layer.include[0].phase]\n            exclude = (phase != self.phase)\n            # Dropout layers appear in a fair number of Caffe\n            # test-time networks. These are just ignored. We\'ll\n            # filter them out here.\n            if (not exclude) and (phase == \'test\'):\n                exclude = (layer.type == LayerType.Dropout)\n            if not exclude:\n                filtered_layers.append(layer)\n                # Guard against dupes.\n                assert layer.name not in filtered_layer_names\n                filtered_layer_names.add(layer.name)\n        return filtered_layers\n\n    def make_node(self, layer):\n        \'\'\'Create a graph node for the given layer.\'\'\'\n        kind = NodeKind.map_raw_kind(layer.type)\n        if kind is None:\n            raise KaffeError(\'Unknown layer type encountered: %s\' % layer.type)\n        # We want to use the layer\'s top names (the ""output"" names), rather than the\n        # name attribute, which is more of readability thing than a functional one.\n        # Other layers will refer to a node by its ""top name"".\n        return Node(layer.name, kind, layer=layer)\n\n    def make_input_nodes(self):\n        \'\'\'\n        Create data input nodes.\n\n        This method is for old-style inputs, where the input specification\n        was not treated as a first-class layer in the prototext.\n        Newer models use the ""Input layer"" type.\n        \'\'\'\n        nodes = [Node(name, NodeKind.Data) for name in self.params.input]\n        if len(nodes):\n            input_dim = map(int, self.params.input_dim)\n            if not input_dim:\n                if len(self.params.input_shape) > 0:\n                    input_dim = map(int, self.params.input_shape[0].dim)\n                else:\n                    raise KaffeError(\'Dimensions for input not specified.\')\n            for node in nodes:\n                node.output_shape = tuple(input_dim)\n        return nodes\n\n    def build(self):\n        \'\'\'\n        Builds the graph from the Caffe layer definitions.\n        \'\'\'\n        # Get the layers\n        layers = self.params.layers or self.params.layer\n        # Filter out phase-excluded layers\n        layers = self.filter_layers(layers)\n        # Get any separately-specified input layers\n        nodes = self.make_input_nodes()\n        nodes += [self.make_node(layer) for layer in layers]\n        # Initialize the graph\n        graph = Graph(nodes=nodes, name=self.params.name)\n        # Connect the nodes\n        #\n        # A note on layers and outputs:\n        # In Caffe, each layer can produce multiple outputs (""tops"") from a set of inputs\n        # (""bottoms""). The bottoms refer to other layers\' tops. The top can rewrite a bottom\n        # (in case of in-place operations). Note that the layer\'s name is not used for establishing\n        # any connectivity. It\'s only used for data association. By convention, a layer with a\n        # single top will often use the same name (although this is not required).\n        #\n        # The current implementation only supports single-output nodes (note that a node can still\n        # have multiple children, since multiple child nodes can refer to the single top\'s name).\n        node_outputs = {}\n        for layer in layers:\n            node = graph.get_node(layer.name)\n            for input_name in layer.bottom:\n                assert input_name != layer.name\n                parent_node = node_outputs.get(input_name)\n                if (parent_node is None) or (parent_node == node):\n                    parent_node = graph.get_node(input_name)\n                node.add_parent(parent_node)\n            if len(layer.top)>1:\n                raise KaffeError(\'Multiple top nodes are not supported.\')\n            for output_name in layer.top:\n                if output_name == layer.name:\n                    # Output is named the same as the node. No further action required.\n                    continue\n                # There are two possibilities here:\n                #\n                # Case 1: output_name refers to another node in the graph.\n                # This is an ""in-place operation"" that overwrites an existing node.\n                # This would create a cycle in the graph. We\'ll undo the in-placing\n                # by substituting this node wherever the overwritten node is referenced.\n                #\n                # Case 2: output_name violates the convention layer.name == output_name.\n                # Since we are working in the single-output regime, we will can rename it to\n                # match the layer name.\n                #\n                # For both cases, future references to this top re-routes to this node.\n                node_outputs[output_name] = node\n\n        graph.compute_output_shapes()\n        return graph\n\n\nclass NodeMapper(NodeDispatch):\n\n    def __init__(self, graph):\n        self.graph = graph\n\n    def map(self):\n        nodes = self.graph.topologically_sorted()\n        # Remove input nodes - we\'ll handle them separately.\n        input_nodes = self.graph.get_input_nodes()\n        nodes = [t for t in nodes if t not in input_nodes]\n        # Decompose DAG into chains.\n        chains = []\n        for node in nodes:\n            attach_to_chain = None\n            if len(node.parents) == 1:\n                parent = node.get_only_parent()\n                for chain in chains:\n                    if chain[-1] == parent:\n                        # Node is part of an existing chain.\n                        attach_to_chain = chain\n                        break\n            if attach_to_chain is None:\n                # Start a new chain for this node.\n                attach_to_chain = []\n                chains.append(attach_to_chain)\n            attach_to_chain.append(node)\n        # Map each chain.\n        mapped_chains = []\n        for chain in chains:\n            mapped_chains.append(self.map_chain(chain))\n        return self.commit(mapped_chains)\n\n    def map_chain(self, chain):\n        return [self.map_node(node) for node in chain]\n\n    def map_node(self, node):\n        map_func = self.get_handler(node.kind, \'map\')\n        mapped_node = map_func(node)\n        assert mapped_node is not None\n        mapped_node.node = node\n        return mapped_node\n\n    def commit(self, mapped_chains):\n        raise NotImplementedError(\'Must be implemented by subclass.\')\n'"
code/kaffe/layers.py,0,"b""import re\nimport numbers\nfrom collections import namedtuple\n\nfrom .shapes import *\n\nLAYER_DESCRIPTORS = {\n\n    # Caffe Types\n    'AbsVal': shape_identity,\n    'Accuracy': shape_scalar,\n    'ArgMax': shape_not_implemented,\n    'BatchNorm': shape_identity,\n    'BNLL': shape_not_implemented,\n    'Concat': shape_concat,\n    'ContrastiveLoss': shape_scalar,\n    'Convolution': shape_convolution,\n    'Deconvolution': shape_not_implemented,\n    'Data': shape_data,\n    'Dropout': shape_identity,\n    'DummyData': shape_data,\n    'EuclideanLoss': shape_scalar,\n    'Eltwise': shape_identity,\n    'Exp': shape_identity,\n    'Flatten': shape_not_implemented,\n    'HDF5Data': shape_data,\n    'HDF5Output': shape_identity,\n    'HingeLoss': shape_scalar,\n    'Im2col': shape_not_implemented,\n    'ImageData': shape_data,\n    'InfogainLoss': shape_scalar,\n    'InnerProduct': shape_inner_product,\n    'Input': shape_data,\n    'LRN': shape_identity,\n    'MemoryData': shape_mem_data,\n    'MultinomialLogisticLoss': shape_scalar,\n    'MVN': shape_not_implemented,\n    'Pooling': shape_pool,\n    'Power': shape_identity,\n    'ReLU': shape_identity,\n    'Scale': shape_identity,\n    'Sigmoid': shape_identity,\n    'SigmoidCrossEntropyLoss': shape_scalar,\n    'Silence': shape_not_implemented,\n    'Softmax': shape_identity,\n    'SoftmaxWithLoss': shape_scalar,\n    'Split': shape_not_implemented,\n    'Slice': shape_not_implemented,\n    'TanH': shape_identity,\n    'WindowData': shape_not_implemented,\n    'Threshold': shape_identity,\n}\n\nLAYER_TYPES = LAYER_DESCRIPTORS.keys()\n\nLayerType = type('LayerType', (), {t: t for t in LAYER_TYPES})\n\nclass NodeKind(LayerType):\n\n    @staticmethod\n    def map_raw_kind(kind):\n        if kind in LAYER_TYPES:\n            return kind\n        return None\n\n    @staticmethod\n    def compute_output_shape(node):\n        try:\n            val = LAYER_DESCRIPTORS[node.kind](node)\n            return val\n        except NotImplementedError:\n            raise KaffeError('Output shape computation not implemented for type: %s' % node.kind)\n\n\nclass NodeDispatchError(KaffeError):\n\n    pass\n\n\nclass NodeDispatch(object):\n\n    @staticmethod\n    def get_handler_name(node_kind):\n        if len(node_kind) <= 4:\n            # A catch-all for things like ReLU and tanh\n            return node_kind.lower()\n        # Convert from CamelCase to under_scored\n        name = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', node_kind)\n        return re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', name).lower()\n\n    def get_handler(self, node_kind, prefix):\n        name = self.get_handler_name(node_kind)\n        name = '_'.join((prefix, name))\n        try:\n            return getattr(self, name)\n        except AttributeError:\n            raise NodeDispatchError('No handler found for node kind: %s (expected: %s)' %\n                                    (node_kind, name))\n\n\nclass LayerAdapter(object):\n\n    def __init__(self, layer, kind):\n        self.layer = layer\n        self.kind = kind\n\n    @property\n    def parameters(self):\n        name = NodeDispatch.get_handler_name(self.kind)\n        name = '_'.join((name, 'param'))\n        try:\n            return getattr(self.layer, name)\n        except AttributeError:\n            raise NodeDispatchError('Caffe parameters not found for layer kind: %s' % (self.kind))\n\n    @staticmethod\n    def get_kernel_value(scalar, repeated, idx, default=None):\n        if scalar:\n            return scalar\n        if repeated:\n            if isinstance(repeated, numbers.Number):\n                return repeated\n            if len(repeated) == 1:\n                # Same value applies to all spatial dimensions\n                return int(repeated[0])\n            assert idx < len(repeated)\n            # Extract the value for the given spatial dimension\n            return repeated[idx]\n        if default is None:\n            raise ValueError('Unable to determine kernel parameter!')\n        return default\n\n    @property\n    def kernel_parameters(self):\n        assert self.kind in (NodeKind.Convolution, NodeKind.Pooling)\n        params = self.parameters\n        k_h = self.get_kernel_value(params.kernel_h, params.kernel_size, 0)\n        k_w = self.get_kernel_value(params.kernel_w, params.kernel_size, 1)\n        s_h = self.get_kernel_value(params.stride_h, params.stride, 0, default=1)\n        s_w = self.get_kernel_value(params.stride_w, params.stride, 1, default=1)\n        p_h = self.get_kernel_value(params.pad_h, params.pad, 0, default=0)\n        p_w = self.get_kernel_value(params.pad_h, params.pad, 1, default=0)\n        return KernelParameters(k_h, k_w, s_h, s_w, p_h, p_w)\n\n\nKernelParameters = namedtuple('KernelParameters', ['kernel_h', 'kernel_w', 'stride_h', 'stride_w',\n                                                   'pad_h', 'pad_w'])\n"""
code/kaffe/shapes.py,0,"b'import math\nfrom collections import namedtuple\n\nfrom .errors import KaffeError\n\nTensorShape = namedtuple(\'TensorShape\', [\'batch_size\', \'channels\', \'height\', \'width\'])\n\n\ndef get_filter_output_shape(i_h, i_w, params, round_func):\n    o_h = (i_h + 2 * params.pad_h - params.kernel_h) / float(params.stride_h) + 1\n    o_w = (i_w + 2 * params.pad_w - params.kernel_w) / float(params.stride_w) + 1\n    return (int(round_func(o_h)), int(round_func(o_w)))\n\n\ndef get_strided_kernel_output_shape(node, round_func):\n    assert node.layer is not None\n    input_shape = node.get_only_parent().output_shape\n    o_h, o_w = get_filter_output_shape(input_shape.height, input_shape.width,\n                                       node.layer.kernel_parameters, round_func)\n    params = node.layer.parameters\n    has_c_o = hasattr(params, \'num_output\')\n    c = params.num_output if has_c_o else input_shape.channels\n    return TensorShape(input_shape.batch_size, c, o_h, o_w)\n\n\ndef shape_not_implemented(node):\n    raise NotImplementedError\n\n\ndef shape_identity(node):\n    assert len(node.parents) > 0\n    return node.parents[0].output_shape\n\n\ndef shape_scalar(node):\n    return TensorShape(1, 1, 1, 1)\n\n\ndef shape_data(node):\n    if node.output_shape:\n        # Old-style input specification\n        return node.output_shape\n    try:\n        # New-style input specification\n        return map(int, node.parameters.shape[0].dim)\n    except:\n        # We most likely have a data layer on our hands. The problem is,\n        # Caffe infers the dimensions of the data from the source (eg: LMDB).\n        # We want to avoid reading datasets here. Fail for now.\n        # This can be temporarily fixed by transforming the data layer to\n        # Caffe\'s ""input"" layer (as is usually used in the ""deploy"" version).\n        # TODO: Find a better solution for this.\n        raise KaffeError(\'Cannot determine dimensions of data layer.\\n\'\n                         \'See comments in function shape_data for more info.\')\n\n\ndef shape_mem_data(node):\n    params = node.parameters\n    return TensorShape(params.batch_size, params.channels, params.height, params.width)\n\n\ndef shape_concat(node):\n    axis = node.layer.parameters.axis\n    output_shape = None\n    for parent in node.parents:\n        if output_shape is None:\n            output_shape = list(parent.output_shape)\n        else:\n            output_shape[axis] += parent.output_shape[axis]\n    return tuple(output_shape)\n\n\ndef shape_convolution(node):\n    return get_strided_kernel_output_shape(node, math.floor)\n\n\ndef shape_pool(node):\n    return get_strided_kernel_output_shape(node, math.ceil)\n\n\ndef shape_inner_product(node):\n    input_shape = node.get_only_parent().output_shape\n    return TensorShape(input_shape.batch_size, node.layer.parameters.num_output, 1, 1)\n'"
code/kaffe/transformers.py,0,"b""'''\nA collection of graph transforms.\n\nA transformer is a callable that accepts a graph and returns a transformed version.\n'''\n\nimport numpy as np\n\nfrom .caffe import get_caffe_resolver, has_pycaffe\nfrom .errors import KaffeError, print_stderr\nfrom .layers import NodeKind\n\n\nclass DataInjector(object):\n    '''\n    Associates parameters loaded from a .caffemodel file with their corresponding nodes.\n    '''\n\n    def __init__(self, def_path, data_path):\n        # The .prototxt file defining the graph\n        self.def_path = def_path\n        # The .caffemodel file containing the learned parameters\n        self.data_path = data_path\n        # Set to true if the fallback protocol-buffer based backend was used\n        self.did_use_pb = False\n        # A list containing (layer name, parameters) tuples\n        self.params = None\n        # Load the parameters\n        self.load()\n\n    def load(self):\n        if has_pycaffe():\n            self.load_using_caffe()\n        else:\n            self.load_using_pb()\n\n    def load_using_caffe(self):\n        caffe = get_caffe_resolver().caffe\n        net = caffe.Net(self.def_path, self.data_path, caffe.TEST)\n        data = lambda blob: blob.data\n        self.params = [(k, map(data, v)) for k, v in net.params.items()]\n\n    def load_using_pb(self):\n        data = get_caffe_resolver().NetParameter()\n        data.MergeFromString(open(self.data_path, 'rb').read())\n        pair = lambda layer: (layer.name, self.normalize_pb_data(layer))\n        layers = data.layers or data.layer\n        self.params = [pair(layer) for layer in layers if layer.blobs]\n        self.did_use_pb = True\n\n    def normalize_pb_data(self, layer):\n        transformed = []\n        for blob in layer.blobs:\n            if len(blob.shape.dim):\n                dims = blob.shape.dim\n                c_o, c_i, h, w = map(int, [1] * (4 - len(dims)) + list(dims))\n            else:\n                c_o = blob.num\n                c_i = blob.channels\n                h = blob.height\n                w = blob.width\n            data = np.array(blob.data, dtype=np.float32).reshape(c_o, c_i, h, w)\n            transformed.append(data)\n        return transformed\n\n    def adjust_parameters(self, node, data):\n        if not self.did_use_pb:\n            return data\n        # When using the protobuf-backend, each parameter initially has four dimensions.\n        # In certain cases (like FC layers), we want to eliminate the singleton dimensions.\n        # This implementation takes care of the common cases. However, it does leave the\n        # potential for future issues.\n        # The Caffe-backend does not suffer from this problem.\n        data = list(data)\n        squeeze_indices = [1]  # Squeeze biases.\n        if node.kind == NodeKind.InnerProduct:\n            squeeze_indices.append(0)  # Squeeze FC.\n        for idx in squeeze_indices:\n            data[idx] = np.squeeze(data[idx])\n        return data\n\n    def __call__(self, graph):\n        for layer_name, data in self.params:\n            if layer_name in graph:\n                node = graph.get_node(layer_name)\n                node.data = self.adjust_parameters(node, data)\n            else:\n                print_stderr('Ignoring parameters for non-existent layer: %s' % layer_name)\n        return graph\n\n\nclass DataReshaper(object):\n\n    def __init__(self, mapping, replace=True):\n        # A dictionary mapping NodeKind to the transposed order.\n        self.mapping = mapping\n        # The node kinds eligible for reshaping\n        self.reshaped_node_types = self.mapping.keys()\n        # If true, the reshaped data will replace the old one.\n        # Otherwise, it's set to the reshaped_data attribute.\n        self.replace = replace\n\n    def has_spatial_parent(self, node):\n        try:\n            parent = node.get_only_parent()\n            s = parent.output_shape\n            return s.height > 1 or s.width > 1\n        except KaffeError:\n            return False\n\n    def map(self, node_kind):\n        try:\n            return self.mapping[node_kind]\n        except KeyError:\n            raise KaffeError('Ordering not found for node kind: {}'.format(node_kind))\n\n    def __call__(self, graph):\n        for node in graph.nodes:\n            if node.data is None:\n                continue\n            if node.kind not in self.reshaped_node_types:\n                # Check for 2+ dimensional data\n                if any(len(tensor.shape) > 1 for tensor in node.data):\n                    print_stderr('Warning: parmaters not reshaped for node: {}'.format(node))\n                continue\n            transpose_order = self.map(node.kind)\n            weights = node.data[0]\n            if (node.kind == NodeKind.InnerProduct) and self.has_spatial_parent(node):\n                # The FC layer connected to the spatial layer needs to be\n                # re-wired to match the new spatial ordering.\n                in_shape = node.get_only_parent().output_shape\n                fc_shape = weights.shape\n                output_channels = fc_shape[0]\n                weights = weights.reshape((output_channels, in_shape.channels, in_shape.height,\n                                           in_shape.width))\n                weights = weights.transpose(self.map(NodeKind.Convolution))\n                node.reshaped_data = weights.reshape(fc_shape[transpose_order[0]],\n                                                     fc_shape[transpose_order[1]])\n            else:\n                node.reshaped_data = weights.transpose(transpose_order)\n\n        if self.replace:\n            for node in graph.nodes:\n                if hasattr(node, 'reshaped_data'):\n                    # Set the weights\n                    node.data[0] = node.reshaped_data\n                    del node.reshaped_data\n        return graph\n\n\nclass SubNodeFuser(object):\n    '''\n    An abstract helper for merging a single-child with its single-parent.\n    '''\n\n    def __call__(self, graph):\n        nodes = graph.nodes\n        fused_nodes = []\n        for node in nodes:\n            if len(node.parents) != 1:\n                # We're only fusing nodes with single parents\n                continue\n            parent = node.get_only_parent()\n            if len(parent.children) != 1:\n                # We can only fuse a node if its parent's\n                # value isn't used by any other node.\n                continue\n            if not self.is_eligible_pair(parent, node):\n                continue\n            # Rewrite the fused node's children to its parent.\n            for child in node.children:\n                child.parents.remove(node)\n                parent.add_child(child)\n            # Disconnect the fused node from the graph.\n            parent.children.remove(node)\n            fused_nodes.append(node)\n            # Let the sub-class merge the fused node in any arbitrary way.\n            self.merge(parent, node)\n        transformed_nodes = [node for node in nodes if node not in fused_nodes]\n        return graph.replaced(transformed_nodes)\n\n    def is_eligible_pair(self, parent, child):\n        '''Returns true if this parent/child pair is eligible for fusion.'''\n        raise NotImplementedError('Must be implemented by subclass.')\n\n    def merge(self, parent, child):\n        '''Merge the child node into the parent.'''\n        raise NotImplementedError('Must be implemented by subclass')\n\n\nclass ReLUFuser(SubNodeFuser):\n    '''\n    Fuses rectified linear units with their parent nodes.\n    '''\n\n    def __init__(self, allowed_parent_types=None):\n        # Fuse ReLUs when the parent node is one of the given types.\n        # If None, all node types are eligible.\n        self.allowed_parent_types = allowed_parent_types\n\n    def is_eligible_pair(self, parent, child):\n        return ((self.allowed_parent_types is None or parent.kind in self.allowed_parent_types) and\n                child.kind == NodeKind.ReLU)\n\n    def merge(self, parent, _):\n        parent.metadata['relu'] = True\n\n\nclass BatchNormScaleBiasFuser(SubNodeFuser):\n    '''\n    The original batch normalization paper includes two learned\n    parameters: a scaling factor \\gamma and a bias \\beta.\n    Caffe's implementation does not include these two. However, it is commonly\n    replicated by adding a scaling+bias layer immidiately after the batch norm.\n\n    This fuser merges the scaling+bias layer with the batch norm.\n    '''\n\n    def is_eligible_pair(self, parent, child):\n        return (parent.kind == NodeKind.BatchNorm and child.kind == NodeKind.Scale and\n                child.parameters.axis == 1 and child.parameters.bias_term == True)\n\n    def merge(self, parent, child):\n        parent.scale_bias_node = child\n\n\nclass BatchNormPreprocessor(object):\n    '''\n    Prescale batch normalization parameters.\n    Concatenate gamma (scale) and beta (bias) terms if set.\n    '''\n\n    def __call__(self, graph):\n        for node in graph.nodes:\n            if node.kind != NodeKind.BatchNorm:\n                continue\n            assert node.data is not None\n            assert len(node.data) == 3\n            mean, variance, scale = node.data\n            # Prescale the stats\n            scaling_factor = 1.0 / scale if scale != 0 else 0\n            mean *= scaling_factor\n            variance *= scaling_factor\n            # Replace with the updated values\n            node.data = [mean, variance]\n            if hasattr(node, 'scale_bias_node'):\n                # Include the scale and bias terms\n                gamma, beta = node.scale_bias_node.data\n                node.data += [gamma, beta]\n        return graph\n\n\nclass NodeRenamer(object):\n    '''\n    Renames nodes in the graph using a given unary function that\n    accepts a node and returns its new name.\n    '''\n\n    def __init__(self, renamer):\n        self.renamer = renamer\n\n    def __call__(self, graph):\n        for node in graph.nodes:\n            node.name = self.renamer(node)\n        return graph\n\n\nclass ParameterNamer(object):\n    '''\n    Convert layer data arrays to a dictionary mapping parameter names to their values.\n    '''\n\n    def __call__(self, graph):\n        for node in graph.nodes:\n            if node.data is None:\n                continue\n            if node.kind in (NodeKind.Convolution, NodeKind.InnerProduct):\n                names = ('weights',)\n                if node.parameters.bias_term:\n                    names += ('biases',)\n            elif node.kind == NodeKind.BatchNorm:\n                names = ('moving_mean', 'moving_variance')\n                if len(node.data) == 4:\n                    names += ('gamma', 'beta')\n            else:\n                print_stderr('WARNING: Unhandled parameters: {}'.format(node.kind))\n                continue\n            assert len(names) == len(node.data)\n            node.data = dict(zip(names, node.data))\n        return graph\n"""
code/polls/main.py,0,"b'#!/usr/bin/env python\n\n# Author: Shao Zhang, Phil Saltzman\n# Last Updated: 2015-03-13\n#\n# This tutorial shows how to detect and respond to collisions. It uses solids\n# create in code and the egg files, how to set up collision masks, a traverser,\n# and a handler, how to detect collisions, and how to dispatch function based\n# on the collisions. All of this is put together to simulate a labyrinth-style\n# game\n\nfrom direct.showbase.ShowBase import ShowBase\nfrom panda3d.core import CollisionTraverser, CollisionNode\nfrom panda3d.core import CollisionHandlerQueue, CollisionRay\nfrom panda3d.core import Material, LRotationf, NodePath\nfrom panda3d.core import AmbientLight, DirectionalLight\nfrom panda3d.core import TextNode\nfrom panda3d.core import LVector3, BitMask32\nfrom direct.gui.OnscreenText import OnscreenText\nfrom direct.interval.MetaInterval import Sequence, Parallel\nfrom direct.interval.LerpInterval import LerpFunc\nfrom direct.interval.FunctionInterval import Func, Wait\nfrom direct.task.Task import Task\nimport sys\n\n# Some constants for the program\nACCEL = 70         # Acceleration in ft/sec/sec\nMAX_SPEED = 5      # Max speed in ft/sec\nMAX_SPEED_SQ = MAX_SPEED ** 2  # Squared to make it easier to use lengthSquared\n# Instead of length\n\n\nclass BallInMazeDemo(ShowBase):\n\n    def __init__(self):\n        # Initialize the ShowBase class from which we inherit, which will\n        # create a window and set up everything we need for rendering into it.\n        ShowBase.__init__(self)\n\n        # This code puts the standard title and instruction text on screen\n        self.title = \\\n            OnscreenText(text=""Panda3D: Tutorial - Collision Detection"",\n                         parent=base.a2dBottomRight, align=TextNode.ARight,\n                         fg=(1, 1, 1, 1), pos=(-0.1, 0.1), scale=.08,\n                         shadow=(0, 0, 0, 0.5))\n        self.instructions = \\\n            OnscreenText(text=""Mouse pointer tilts the board"",\n                         parent=base.a2dTopLeft, align=TextNode.ALeft,\n                         pos=(0.05, -0.08), fg=(1, 1, 1, 1), scale=.06,\n                         shadow=(0, 0, 0, 0.5))\n\n        self.accept(""escape"", sys.exit)  # Escape quits\n\n        # Disable default mouse-based camera control.  This is a method on the\n        # ShowBase class from which we inherit.\n        self.disableMouse()\n        camera.setPosHpr(0, 0, 25, 0, -90, 0)  # Place the camera\n\n        # Load the maze and place it in the scene\n        self.maze = loader.loadModel(""models/maze"")\n        self.maze.reparentTo(render)\n\n        # Most times, you want collisions to be tested against invisible geometry\n        # rather than every polygon. This is because testing against every polygon\n        # in the scene is usually too slow. You can have simplified or approximate\n        # geometry for the solids and still get good results.\n        #\n        # Sometimes you\'ll want to create and position your own collision solids in\n        # code, but it\'s often easier to have them built automatically. This can be\n        # done by adding special tags into an egg file. Check maze.egg and ball.egg\n        # and look for lines starting with <Collide>. The part is brackets tells\n        # Panda exactly what to do. Polyset means to use the polygons in that group\n        # as solids, while Sphere tells panda to make a collision sphere around them\n        # Keep means to keep the polygons in the group as visable geometry (good\n        # for the ball, not for the triggers), and descend means to make sure that\n        # the settings are applied to any subgroups.\n        #\n        # Once we have the collision tags in the models, we can get to them using\n        # NodePath\'s find command\n\n        # Find the collision node named wall_collide\n        self.walls = self.maze.find(""**/wall_collide"")\n\n        # Collision objects are sorted using BitMasks. BitMasks are ordinary numbers\n        # with extra methods for working with them as binary bits. Every collision\n        # solid has both a from mask and an into mask. Before Panda tests two\n        # objects, it checks to make sure that the from and into collision masks\n        # have at least one bit in common. That way things that shouldn\'t interact\n        # won\'t. Normal model nodes have collision masks as well. By default they\n        # are set to bit 20. If you want to collide against actual visable polygons,\n        # set a from collide mask to include bit 20\n        #\n        # For this example, we will make everything we want the ball to collide with\n        # include bit 0\n        self.walls.node().setIntoCollideMask(BitMask32.bit(0))\n        # CollisionNodes are usually invisible but can be shown. Uncomment the next\n        # line to see the collision walls\n        #self.walls.show()\n\n        # We will now find the triggers for the holes and set their masks to 0 as\n        # well. We also set their names to make them easier to identify during\n        # collisions\n        self.loseTriggers = []\n        for i in range(6):\n            trigger = self.maze.find(""**/hole_collide"" + str(i))\n            trigger.node().setIntoCollideMask(BitMask32.bit(0))\n            trigger.node().setName(""loseTrigger"")\n            self.loseTriggers.append(trigger)\n            # Uncomment this line to see the triggers\n            # trigger.show()\n\n        # Ground_collide is a single polygon on the same plane as the ground in the\n        # maze. We will use a ray to collide with it so that we will know exactly\n        # what height to put the ball at every frame. Since this is not something\n        # that we want the ball itself to collide with, it has a different\n        # bitmask.\n        self.mazeGround = self.maze.find(""**/ground_collide"")\n        self.mazeGround.node().setIntoCollideMask(BitMask32.bit(1))\n\n        # Load the ball and attach it to the scene\n        # It is on a root dummy node so that we can rotate the ball itself without\n        # rotating the ray that will be attached to it\n        self.ballRoot = render.attachNewNode(""ballRoot"")\n        self.ball = loader.loadModel(""models/ball"")\n        self.ball.reparentTo(self.ballRoot)\n\n        # Find the collison sphere for the ball which was created in the egg file\n        # Notice that it has a from collision mask of bit 0, and an into collison\n        # mask of no bits. This means that the ball can only cause collisions, not\n        # be collided into\n        self.ballSphere = self.ball.find(""**/ball"")\n        self.ballSphere.node().setFromCollideMask(BitMask32.bit(0))\n        self.ballSphere.node().setIntoCollideMask(BitMask32.allOff())\n\n        # No we create a ray to start above the ball and cast down. This is to\n        # Determine the height the ball should be at and the angle the floor is\n        # tilting. We could have used the sphere around the ball itself, but it\n        # would not be as reliable\n        self.ballGroundRay = CollisionRay()     # Create the ray\n        self.ballGroundRay.setOrigin(0, 0, 10)    # Set its origin\n        self.ballGroundRay.setDirection(0, 0, -1)  # And its direction\n        # Collision solids go in CollisionNode\n        # Create and name the node\n        self.ballGroundCol = CollisionNode(\'groundRay\')\n        self.ballGroundCol.addSolid(self.ballGroundRay)  # Add the ray\n        self.ballGroundCol.setFromCollideMask(\n            BitMask32.bit(1))  # Set its bitmasks\n        self.ballGroundCol.setIntoCollideMask(BitMask32.allOff())\n        # Attach the node to the ballRoot so that the ray is relative to the ball\n        # (it will always be 10 feet over the ball and point down)\n        self.ballGroundColNp = self.ballRoot.attachNewNode(self.ballGroundCol)\n        # Uncomment this line to see the ray\n        #self.ballGroundColNp.show()\n\n        # Finally, we create a CollisionTraverser. CollisionTraversers are what\n        # do the job of walking the scene graph and calculating collisions.\n        # For a traverser to actually do collisions, you need to call\n        # traverser.traverse() on a part of the scene. Fortunately, ShowBase\n        # has a task that does this for the entire scene once a frame.  By\n        # assigning it to self.cTrav, we designate that this is the one that\n        # it should call traverse() on each frame.\n        self.cTrav = CollisionTraverser()\n\n        # Collision traversers tell collision handlers about collisions, and then\n        # the handler decides what to do with the information. We are using a\n        # CollisionHandlerQueue, which simply creates a list of all of the\n        # collisions in a given pass. There are more sophisticated handlers like\n        # one that sends events and another that tries to keep collided objects\n        # apart, but the results are often better with a simple queue\n        self.cHandler = CollisionHandlerQueue()\n        # Now we add the collision nodes that can create a collision to the\n        # traverser. The traverser will compare these to all others nodes in the\n        # scene. There is a limit of 32 CollisionNodes per traverser\n        # We add the collider, and the handler to use as a pair\n        self.cTrav.addCollider(self.ballSphere, self.cHandler)\n        self.cTrav.addCollider(self.ballGroundColNp, self.cHandler)\n\n        # Collision traversers have a built in tool to help visualize collisions.\n        # Uncomment the next line to see it.\n        #self.cTrav.showCollisions(render)\n\n        # This section deals with lighting for the ball. Only the ball was lit\n        # because the maze has static lighting pregenerated by the modeler\n        ambientLight = AmbientLight(""ambientLight"")\n        ambientLight.setColor((.55, .55, .55, 1))\n        directionalLight = DirectionalLight(""directionalLight"")\n        directionalLight.setDirection(LVector3(0, 0, -1))\n        directionalLight.setColor((0.375, 0.375, 0.375, 1))\n        directionalLight.setSpecularColor((1, 1, 1, 1))\n        self.ballRoot.setLight(render.attachNewNode(ambientLight))\n        self.ballRoot.setLight(render.attachNewNode(directionalLight))\n\n        # This section deals with adding a specular highlight to the ball to make\n        # it look shiny.  Normally, this is specified in the .egg file.\n        m = Material()\n        m.setSpecular((1, 1, 1, 1))\n        m.setShininess(96)\n        self.ball.setMaterial(m, 1)\n\n        # Finally, we call start for more initialization\n        self.start()\n\n    def start(self):\n        # The maze model also has a locator in it for where to start the ball\n        # To access it we use the find command\n        startPos = self.maze.find(""**/start"").getPos()\n        # Set the ball in the starting position\n        self.ballRoot.setPos(startPos)\n        self.ballV = LVector3(0, 0, 0)         # Initial velocity is 0\n        self.accelV = LVector3(0, 0, 0)        # Initial acceleration is 0\n\n        # Create the movement task, but first make sure it is not already\n        # running\n        taskMgr.remove(""rollTask"")\n        self.mainLoop = taskMgr.add(self.rollTask, ""rollTask"")\n\n    # This function handles the collision between the ray and the ground\n    # Information about the interaction is passed in colEntry\n    def groundCollideHandler(self, colEntry):\n        # Set the ball to the appropriate Z value for it to be exactly on the\n        # ground\n        newZ = colEntry.getSurfacePoint(render).getZ()\n        self.ballRoot.setZ(newZ + .4)\n\n        # Find the acceleration direction. First the surface normal is crossed with\n        # the up vector to get a vector perpendicular to the slope\n        norm = colEntry.getSurfaceNormal(render)\n        accelSide = norm.cross(LVector3.up())\n        # Then that vector is crossed with the surface normal to get a vector that\n        # points down the slope. By getting the acceleration in 3D like this rather\n        # than in 2D, we reduce the amount of error per-frame, reducing jitter\n        self.accelV = norm.cross(accelSide)\n\n    # This function handles the collision between the ball and a wall\n    def wallCollideHandler(self, colEntry):\n        # First we calculate some numbers we need to do a reflection\n        norm = colEntry.getSurfaceNormal(render) * -1  # The normal of the wall\n        curSpeed = self.ballV.length()                # The current speed\n        inVec = self.ballV / curSpeed                 # The direction of travel\n        velAngle = norm.dot(inVec)                    # Angle of incidance\n        hitDir = colEntry.getSurfacePoint(render) - self.ballRoot.getPos()\n        hitDir.normalize()\n        # The angle between the ball and the normal\n        hitAngle = norm.dot(hitDir)\n\n        # Ignore the collision if the ball is either moving away from the wall\n        # already (so that we don\'t accidentally send it back into the wall)\n        # and ignore it if the collision isn\'t dead-on (to avoid getting caught on\n        # corners)\n        if velAngle > 0 and hitAngle > .995:\n            # Standard reflection equation\n            reflectVec = (norm * norm.dot(inVec * -1) * 2) + inVec\n\n            # This makes the velocity half of what it was if the hit was dead-on\n            # and nearly exactly what it was if this is a glancing blow\n            self.ballV = reflectVec * (curSpeed * (((1 - velAngle) * .5) + .5))\n            # Since we have a collision, the ball is already a little bit buried in\n            # the wall. This calculates a vector needed to move it so that it is\n            # exactly touching the wall\n            disp = (colEntry.getSurfacePoint(render) -\n                    colEntry.getInteriorPoint(render))\n            newPos = self.ballRoot.getPos() + disp\n            self.ballRoot.setPos(newPos)\n\n    # This is the task that deals with making everything interactive\n    def rollTask(self, task):\n        # Standard technique for finding the amount of time since the last\n        # frame\n        dt = globalClock.getDt()\n\n        # If dt is large, then there has been a # hiccup that could cause the ball\n        # to leave the field if this functions runs, so ignore the frame\n        if dt > .2:\n            return Task.cont\n\n        # The collision handler collects the collisions. We dispatch which function\n        # to handle the collision based on the name of what was collided into\n        for i in range(self.cHandler.getNumEntries()):\n            entry = self.cHandler.getEntry(i)\n            name = entry.getIntoNode().getName()\n            if name == ""wall_collide"":\n                self.wallCollideHandler(entry)\n            elif name == ""ground_collide"":\n                self.groundCollideHandler(entry)\n            elif name == ""loseTrigger"":\n                self.loseGame(entry)\n\n        # Read the mouse position and tilt the maze accordingly\n        if base.mouseWatcherNode.hasMouse():\n            mpos = base.mouseWatcherNode.getMouse()  # get the mouse position\n            self.maze.setP(mpos.getY() * -10)\n            self.maze.setR(mpos.getX() * 10)\n\n        # Finally, we move the ball\n        # Update the velocity based on acceleration\n        self.ballV += self.accelV * dt * ACCEL\n        # Clamp the velocity to the maximum speed\n        if self.ballV.lengthSquared() > MAX_SPEED_SQ:\n            self.ballV.normalize()\n            self.ballV *= MAX_SPEED\n        # Update the position based on the velocity\n        self.ballRoot.setPos(self.ballRoot.getPos() + (self.ballV * dt))\n\n        # This block of code rotates the ball. It uses something called a quaternion\n        # to rotate the ball around an arbitrary axis. That axis perpendicular to\n        # the balls rotation, and the amount has to do with the size of the ball\n        # This is multiplied on the previous rotation to incrimentally turn it.\n        prevRot = LRotationf(self.ball.getQuat())\n        axis = LVector3.up().cross(self.ballV)\n        newRot = LRotationf(axis, 45.5 * dt * self.ballV.length())\n        self.ball.setQuat(prevRot * newRot)\n\n        return Task.cont       # Continue the task indefinitely\n\n    # If the ball hits a hole trigger, then it should fall in the hole.\n    # This is faked rather than dealing with the actual physics of it.\n    def loseGame(self, entry):\n        # The triggers are set up so that the center of the ball should move to the\n        # collision point to be in the hole\n        toPos = entry.getInteriorPoint(render)\n        taskMgr.remove(\'rollTask\')  # Stop the maze task\n\n        # Move the ball into the hole over a short sequence of time. Then wait a\n        # second and call start to reset the game\n        Sequence(\n            Parallel(\n                LerpFunc(self.ballRoot.setX, fromData=self.ballRoot.getX(),\n                         toData=toPos.getX(), duration=.1),\n                LerpFunc(self.ballRoot.setY, fromData=self.ballRoot.getY(),\n                         toData=toPos.getY(), duration=.1),\n                LerpFunc(self.ballRoot.setZ, fromData=self.ballRoot.getZ(),\n                         toData=self.ballRoot.getZ() - .9, duration=.2)),\n            Wait(1),\n            Func(self.start)).start()\n\n# Finally, create an instance of our class and start 3d rendering\ndemo = BallInMazeDemo()\ndemo.run()\n'"
code/polls/plane_scene.py,0,"b'from panda3d.egg import *\nfrom panda3d.core import *\nfrom obj2egg import ObjMaterial\nfrom copy import deepcopy\nimport numpy as np\nimport cv2\nimport copy\nfrom direct.gui.OnscreenImage import OnscreenImage\n\nimport sys\nimport os\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom utils import getCameraFromInfo, drawSegmentationImage\n\ndef calcDistance(point_1, point_2):\n  return pow(pow(point_1[0] - point_2[0], 2) + pow(point_1[1] - point_2[1], 2), 0.5)\n\ndef calcLineDim(line, lineWidth = -1):\n  if abs(line[0][0] - line[1][0]) > abs(line[0][1] - line[1][1]):\n    if lineWidth < 0 or abs(line[0][1] - line[1][1]) <= lineWidth:\n      return 0\n    pass\n  elif abs(line[0][0] - line[1][0]) < abs(line[0][1] - line[1][1]):\n    if lineWidth < 0 or abs(line[0][0] - line[1][0]) <= lineWidth:\n      return 1\n  else:\n    return -1\n  \nclass PlaneScene():\n  def __init__(self, index):\n    #self.depth = cv2.imread(\'dump/\' + str(index) + \'_depth_pred.png\').astype(np.float32) / 255 * 10\n    self.depth = np.load(\'dump/\' + str(index) + \'_depth.npy\')\n    #cv2.imwrite(\'dump/alpha_0.5.png\', np.zeros(self.depth[:, :, 0].shape).astype(np.uint8))\n    self.segmentation = np.load(\'dump/\' + str(index) + \'_segmentation.npy\')\n\n    #print(self.segmentation.shape)\n    self.segmentation[self.segmentation == -1] = 10\n    cv2.imwrite(\'dump/2_segmentation.png\', drawSegmentationImage(self.segmentation, blackIndex=10))\n    exit(1)\n\n    width = 640\n    height = 480\n    self.depth = cv2.resize(self.depth, (width, height))\n    self.segmentation = cv2.resize(self.segmentation, (width, height), interpolation=cv2.INTER_NEAREST)\n    self.planes = np.load(\'dump/\' + str(index) + \'_planes.npy\')\n    self.numPlanes = self.planes.shape[0]\n\n    self.imageTexture = ObjMaterial()\n    self.imageTexture.name = \'image\'\n    self.imageTexture.put(\'map_Kd\', \'dump/\' + str(index) + \'_image.png\')\n    self.width = self.depth.shape[1]\n    self.height = self.depth.shape[0]\n    self.info = np.load(\'dump/\' + str(index) + \'_info.npy\')\n    self.camera = getCameraFromInfo(self.info)\n    self.scene_index = index\n    self.calcHorizontalPlanes()\n    return\n\n  def addRectangle(self, parent):\n    planesGroup = EggGroup(\'planes\')\n    parent.addChild(planesGroup)\n    vp = EggVertexPool(\'plane_vertex\')\n    parent.addChild(vp)\n    \n    p0 = Point3D(-10, 1, 0)\n    p1 = Point3D(-10, 10, 0)\n    p2 = Point3D(10, 1, 0)\n    p3 = Point3D(10, 10, 0)    \n    # p0 = Point3D(-10, , 0)\n    # p1 = Point3D(-10, 100, 0)\n    # p3 = Point3D(10, 100, 0)\n    # p2 = Point3D(10, 90, 0)\n    \n    planeGroup = EggGroup(\'plane\')\n    planesGroup.addChild(planeGroup)\n    poly = EggPolygon()\n    planeGroup.addChild(poly)\n    vertex = EggVertex()\n    vertex.setPos(p0)\n    vertex.setUv(Point2D(0, 0))\n    poly.addVertex(vp.addVertex(vertex))\n    vertex = EggVertex()\n    vertex.setPos(p1)\n    vertex.setUv(Point2D(0, 1))\n    poly.addVertex(vp.addVertex(vertex))\n    vertex = EggVertex()\n    vertex.setPos(p2)\n    vertex.setUv(Point2D(1, 1))\n    poly.addVertex(vp.addVertex(vertex))\n\n    \n    poly = EggPolygon()\n    planeGroup.addChild(poly)\n    \n    vertex = EggVertex()\n    vertex.setPos(p1)\n    vertex.setUv(Point2D(0, 1))\n    poly.addVertex(vp.addVertex(vertex))\n    vertex = EggVertex()\n    vertex.setPos(p2)\n    vertex.setUv(Point2D(1, 1))\n    poly.addVertex(vp.addVertex(vertex))\n    vertex = EggVertex()\n    vertex.setPos(p3)\n    vertex.setUv(Point2D(1, 0))\n    poly.addVertex(vp.addVertex(vertex))\n\n    # vertex = EggVertex()\n    # vertex.setPos(p2)\n    # vertex.setUv(Point2D(1, 1))\n    # poly.addVertex(vp.addVertex(vertex))\n    \n    return\n    \n\n  def generatePlanes(self, parent):\n    planesGroup = EggGroup(\'planes\')\n    parent.addChild(planesGroup)\n    vp = EggVertexPool(\'plane_vertex\')\n    parent.addChild(vp)\n\n    for planeIndex in xrange(self.numPlanes):\n      mask = (self.segmentation == planeIndex).astype(np.uint8) * 255\n      cv2.imwrite(\'test/mask_\' + str(planeIndex) + \'.png\', mask)\n      contours, _ = cv2.findContours(mask, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n      plane = self.planes[planeIndex]\n      planeD = np.linalg.norm(plane)\n      planeNormal = plane / planeD\n      for contour in contours:\n        planeGroup = EggGroup(\'plane\')\n        planesGroup.addChild(planeGroup)\n        poly = EggPolygon()\n        planeGroup.addChild(poly)\n\n        poly.setTexture(self.imageTexture.getEggTexture())\n        poly.setMaterial(self.imageTexture.getEggMaterial())\n\n        contour = contour.astype(np.float32)\n        u = (contour[:, 0, 0].astype(np.float32) / self.width * self.info[16] - self.camera[\'cx\']) / self.camera[\'fx\']\n        v = -(contour[:, 0, 1].astype(np.float32) / self.height * self.info[17] - self.camera[\'cy\']) / self.camera[\'fy\']\n        ranges = np.stack([u, np.ones(u.shape), v], axis=1)\n        depth = planeD / np.dot(ranges, planeNormal)\n        XYZ = ranges * np.expand_dims(depth, -1)\n        #print(contour)\n        #print(XYZ)\n        #exit(1)\n        for vertexIndex, uv in enumerate(contour):\n          vertex = EggVertex()\n          X, Y, Z = XYZ[vertexIndex]\n          vertex.setPos(Point3D(X, Y, Z))\n          u, v = uv[0]\n          vertex.setUv(Point2D(u / self.width, 1 - v / self.height))\n          poly.addVertex(vp.addVertex(vertex))\n          continue\n        continue\n      continue\n    return\n\n\n  def generateRectangle(self, parent):    \n    planesGroup = EggGroup(\'planes\')\n    parent.addChild(planesGroup)\n    vp = EggVertexPool(\'plane_vertex\')\n    parent.addChild(vp)\n\n    poly = EggPolygon()\n    planesGroup.addChild(poly)\n\n\n    w = 0.5\n    p0 = Point3D(-w / 2, 0, -w / 2)\n    p1 = Point3D(-w / 2, 0, w / 2)\n    p2 = Point3D(w / 2, 0, w / 2)\n    p3 = Point3D(w / 2, 0, -w / 2)    \n  \n    \n    poly.setTexture(self.plateTexture.getEggTexture())\n    poly.setMaterial(self.plateTexture.getEggMaterial())\n    vertex = EggVertex()\n    vertex.setPos(Point3D(0, 1, 0))\n    vertex.setUv(Point2D(0, 0))\n    poly.addVertex(vp.addVertex(vertex))\n    vertex = EggVertex()\n    vertex.setPos(Point3D(0, 1, 1))\n    vertex.setUv(Point2D(0, 1))\n    poly.addVertex(vp.addVertex(vertex))\n    vertex = EggVertex()\n    vertex.setPos(Point3D(1, 1, 1))\n    vertex.setUv(Point2D(1, 1))\n    poly.addVertex(vp.addVertex(vertex))\n    vertex = EggVertex()\n    vertex.setPos(Point3D(1, 1, 0))\n    vertex.setUv(Point2D(1, 0))\n    poly.addVertex(vp.addVertex(vertex))\n    \n    return\n\n  def addCollisionPolygons(self, scene):\n    \n    polygons = scene.findAllMatches(""**/plane"")\n    mesh = BulletTriangleMesh()      \n    for polygon in polygons:\n      #cNode = scene.attachNewNode(CollisionNode(\'plane_solid\'))\n      #cNode.node().addSolid(CollisionPolygon(polygon))\n      #polygon.setCollideMask(BitMask32.bit(1))\n      node = polygon.node()\n      print(node.getNumGeoms())\n      for i in xrange(node.getNumGeoms()):\n        geom = node.getGeom(i)\n        mesh.addGeom(geom)\n        continue\n      continue\n\n  def test(self, scene):\n    groundMask=BitMask32(0b1)\n    parent = NodePath(\'cGeomConversionParent\') \n    for c in incomingNode.findAllMatches(\'**/+GeomNode\'): \n        if relativeTo:\n            xform=c.getMat(relativeTo).xformPoint\n        else:\n            xform=c.getMat().xformPoint\n        gni = 0 \n        geomNode = c.node() \n        for g in range(geomNode.getNumGeoms()): \n            geom = geomNode.getGeom(g).decompose() \n            vdata = geom.getVertexData() \n            vreader = GeomVertexReader(vdata, \'vertex\') \n            cChild = CollisionNode(\'cGeom-%s-gni%i\' % (c.getName(), gni)) \n            \n            gni += 1 \n            for p in range(geom.getNumPrimitives()): \n                prim = geom.getPrimitive(p) \n                for p2 in range(prim.getNumPrimitives()): \n                    s = prim.getPrimitiveStart(p2) \n                    e = prim.getPrimitiveEnd(p2) \n                    v = [] \n                    for vi in range (s, e): \n                        vreader.setRow(prim.getVertex(vi)) \n                        v.append (xform(vreader.getData3f())) \n                    colPoly = CollisionPolygon(*v) \n                    cChild.addSolid(colPoly) \n\n            n=parent.attachNewNode (cChild) \n            #n.show()\n            \n    return parent\n\n  \n  def generateEggModel(self):\n    data = EggData()\n    model = EggGroup(\'model\')\n    data.addChild(model)\n    self.generatePlanes(model)\n    #self.generateRectangle(model)\n    data.writeEgg(Filename(""test/plane.egg""))\n    scene = NodePath(loadEggData(data))\n    #self.addCollisionPolygons(scene)\n    \n    return scene  \n\n    \n\n  def getPlaneTriangles(self):\n    from skimage import measure\n    \n    planeTriangles = []\n    planeNormals = []    \n    horizontalPlaneTriangles = []\n    \n    for planeIndex in xrange(self.numPlanes):\n      mask = (self.segmentation == planeIndex).astype(np.uint8) * 255\n      mask_ori = mask.copy()\n      #contours, _ = cv2.findContours(mask, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n      #contours, _ = cv2.findContours(mask, cv2.RETR_LIST, cv2.CHAIN_APPROX_TC89_KCOS)\n      masks = measure.label(mask.astype(np.int32), background=0)\n      contours = []\n      for maskIndex in xrange(masks.min() + 1, masks.max() + 1):\n        mask = masks == maskIndex\n        contour_mask = mask - np.logical_and(np.logical_and(np.roll(mask, shift=1, axis=0), np.roll(mask, shift=-1, axis=0)), np.logical_and(np.roll(mask, shift=1, axis=1), np.roll(mask, shift=-1, axis=1)))\n        contour_v, contour_u = contour_mask.nonzero()\n        contours.append(np.stack([contour_u, contour_v], axis=1))\n        continue\n        \n        \n      plane = self.planes[planeIndex]\n      planeD = np.linalg.norm(plane)\n      planeNormal = plane / np.maximum(planeD, 1e-4)\n\n      # cv2.imwrite(\'test/mask.png\', mask_ori)\n      # #print(len(contours))\n\n      # mask_ori = np.stack([mask_ori, mask_ori, mask_ori], 2)\n      # count = 0\n      # for contour in contours:\n      #   count += contour.shape[0]\n      #   for uv in contour:\n      #     #uv = uv[0]\n      #     mask_ori[uv[1]][uv[0]] = np.array([255, 0, 0])\n      #     continue\n      #   continue\n      # cv2.imwrite(\'test/mask_contour.png\', mask_ori)\n      # if planeIndex == 1:\n      #   exit(1)\n\n      indices = np.arange(self.width * self.height).astype(np.float32)\n      us = indices % self.width\n      us = us / self.width * self.info[16] - self.camera[\'cx\']\n      vs = indices / self.width      \n      vs = -(vs / self.height * self.info[17] - self.camera[\'cy\'])\n      ranges = np.stack([us / self.camera[\'fx\'], np.ones(us.shape), vs / self.camera[\'fy\']], axis=1)\n      #print(ranges)\n      #print(np.dot(ranges, planeNormal).shape)\n      #print(np.dot(ranges, planeNormal))\n      #print(ranges)\n      #exit(1)\n      depth = planeD / np.tensordot(ranges, planeNormal, axes=([1], [0]))\n      XYZ = ranges * np.expand_dims(depth, -1)\n      XYZ = XYZ.reshape((self.height, self.width, 3))\n      for contour in contours:\n        contour = contour.astype(np.float32)[::20]\n        if contour.shape[0] < 3:\n          continue\n        rect = (0, 0, self.width, self.height)\n        subdiv = cv2.Subdiv2D(rect)\n\n        for point in contour:\n          subdiv.insert((point[0], point[1]))\n          continue\n        triangleList = subdiv.getTriangleList()\n\n        #print(contour)                \n        #print(triangleList)\n        #exit(1)\n        for triangle2D in triangleList:\n          triangle = []\n          for vertexIndex in xrange(3):\n            x = int(triangle2D[vertexIndex * 2 + 0])\n            y = int(triangle2D[vertexIndex * 2 + 1])\n            #print(x, y)\n            if x < 0 or x >= self.width or y < 0 or y >= self.height:\n              continue\n            triangle.append(XYZ[y][x])\n            continue\n          if len(triangle) == 3:\n            #print(triangle)\n            if np.dot(np.cross(planeNormal, triangle[1] - triangle[0]), triangle[2] - triangle[0]) > 0:\n              triangle = [triangle[0], triangle[2], triangle[1]]\n              pass\n            if planeIndex in self.horizontalPlanes:\n              horizontalPlaneTriangles.append(triangle)\n            else:\n              planeTriangles.append(triangle)\n              pass\n            #planeNormals.append(planeNormal)\n            pass\n          continue\n      continue\n    planeTriangles = np.array(planeTriangles)\n    #planeNormals = np.array(planeNormals)\n    np.save(\'dump/\' + str(self.scene_index) + \'_plane_triangles.npy\', planeTriangles)\n    #np.save(\'dump/\' + str(self.scene_index) + \'_plane_normals.npy\', planeNormals)\n    return planeTriangles, horizontalPlaneTriangles, self.gravityDirection\n  \n\n  def getPlaneGeometries(self):\n    if os.path.exists(\'dump/\' + str(self.scene_index) + \'_plane_triangles.npy\'):\n      print(\'loading\')\n      planeTriangles = np.load(\'dump/\' + str(self.scene_index) + \'_plane_triangles.npy\')\n      planeNormals =  np.load(\'dump/\' + str(self.scene_index) + \'_plane_normals.npy\')\n      return planeTriangles, planeNormals\n      pass\n    \n    planeNormals = []\n    planeTriangles = []\n    for planeIndex in xrange(self.numPlanes):\n      mask = (self.segmentation == planeIndex).astype(np.uint8) * 255\n      #mask_ori = mask.copy()\n      #contours, _ = cv2.findContours(mask, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n      plane = self.planes[planeIndex]\n      planeD = np.linalg.norm(plane)\n      planeNormal = plane / np.maximum(planeD, 1e-4)\n\n      #cv2.imwrite(\'test/mask.png\', mask)\n      #v, u = mask.nonzero()\n      u = np.arange(self.width * self.height) % self.width\n      v = np.arange(self.width * self.height) / self.width\n      u = u.astype(np.float32) / self.width * self.info[16] - self.camera[\'cx\']\n      v = -(v.astype(np.float32) / self.height * self.info[17] - self.camera[\'cy\'])\n      ranges = np.stack([u / self.camera[\'fx\'], np.ones(u.shape), v / self.camera[\'fy\']], axis=1)\n      depth = planeD / np.dot(ranges, planeNormal)\n      XYZ = ranges * np.expand_dims(depth, -1)\n      XYZ = XYZ.reshape((self.height, self.width, 3))\n\n      triangles = []\n      for pixel in mask.reshape(-1).nonzero()[0]:\n        x = pixel % self.width\n        y = pixel / self.width\n        for neighbors in [((x - 1, y), (x, y - 1)), ((x - 1, y), (x, y + 1)), ((x + 1, y), (x, y - 1)), ((x + 1, y), (x, y + 1))]:\n          valid = True\n          for neighbor in neighbors:\n            if neighbor[0] < 0 or neighbor[0] >= self.width or neighbor[1] < 0 or neighbor[1] >= self.height or mask[neighbor[1]][neighbor[0]] == False:\n              valid = False\n              break\n            continue\n          if valid:\n            triangle = [XYZ[y][x]]\n            for neighbor in neighbors:\n              triangle.append(XYZ[neighbor[1], neighbor[0]])\n              continue\n            triangles.append(triangle)\n            pass\n          continue\n        continue\n      planeTriangles.append(triangles)\n      planeNormals.append(planeNormal)\n      continue\n\n    planeTriangles = np.array(planeTriangles)\n    #planeNormals = np.array(planeNormals)\n    #np.save(\'dump/\' + str(self.scene_index) + \'_plane_triangles.npy\', planeTriangles)\n    #np.save(\'dump/\' + str(self.scene_index) + \'_plane_normals.npy\', planeNormals)\n    return planeTriangles, planeNormals\n  \n\n  def calcHorizontalPlanes(self):\n    from sklearn.cluster import KMeans\n    \n    planesD = np.linalg.norm(self.planes, axis=-1, keepdims=True)\n    normals = self.planes / np.maximum(planesD, 1e-4)\n    \n    normals[normals[:, 1] < 0] *= -1    \n\n    kmeans = KMeans(n_clusters=3).fit(normals)\n    dominantNormals = kmeans.cluster_centers_\n    dominantNormals = dominantNormals / np.maximum(np.linalg.norm(dominantNormals, axis=-1, keepdims=True), 1e-4)\n\n    planeClusters = kmeans.predict(normals)\n    \n    horizontalNormalIndex = np.argmax(np.abs(dominantNormals[:, 2]))\n    self.gravityDirection = dominantNormals[horizontalNormalIndex]\n    self.horizontalPlanes = (planeClusters == horizontalNormalIndex).nonzero()[0]\n    if self.gravityDirection[2] > 0:\n      self.gravityDirection *= -1\n      pass\n\n    print(self.horizontalPlanes)\n    print(self.gravityDirection)\n    return\n    \n  def getHorizontalPlanes(self):\n    return self.gravityDirection, self.horizontalPlanes\n\n  def getHolePos(self):\n    floorPlaneIndex = 2\n    closePoint = np.array([0., 1.22, -0.2])\n    plane = self.planes[floorPlaneIndex]\n    planeD = np.linalg.norm(plane)\n    planeNormal = plane / planeD\n    distance = planeD - np.dot(planeNormal, closePoint)\n    distance *= 0.99\n    holePos = closePoint + planeNormal * distance\n\n    H = P = R = 0\n    H = -90 + np.rad2deg(np.arctan2(planeNormal[1], planeNormal[0]))\n    #P = 90 - np.rad2deg(np.arccos(np.abs(planeNormal[2])))\n    P = -90 + np.rad2deg(np.arccos(np.abs(planeNormal[2])))\n    #print(H, P, R)\n    return holePos, np.array([H, P, R])\n\n\n  def getPortalPos(self):\n    wallPlaneIndex = 1\n    closePoint_1 = np.array([0.5, 1.35, -0.5])\n    closePoint_2 = np.array([-0.4, 1, 0.19])\n    plane = self.planes[wallPlaneIndex]\n    planeD = np.linalg.norm(plane)\n    planeNormal = plane / planeD\n    \n    distance = planeD - np.dot(planeNormal, closePoint_1)\n    distance *= 0.95\n    portalPos_1 = closePoint_1 + planeNormal * distance\n\n    distance = planeD - np.dot(planeNormal, closePoint_2)\n    distance *= 0.95\n    portalPos_2 = closePoint_2 + planeNormal * distance    \n\n    H = P = R = 0\n    H = -90 + np.rad2deg(np.arctan2(planeNormal[1], planeNormal[0]))\n    #P = 90 - np.rad2deg(np.arccos(np.abs(planeNormal[2])))\n    P = -90 + np.rad2deg(np.arccos(-np.abs(planeNormal[2])))\n    #print(H, P, R)\n    return portalPos_1, np.array([H, P, R]), portalPos_2, np.array([H, P, R]), planeNormal\n  \n'"
code/polls/polls.py,0,"b'#!/usr/bin/env python\n\n# Author: Shao Zhang, Phil Saltzman\n# Last Updated: 2015-03-13\n#\n# This tutorial shows how to detect and respond to collisions. It uses solids\n# create in code and the egg files, how to set up collision masks, a traverser,\n# and a handler, how to detect collisions, and how to dispatch function based\n# on the collisions. All of this is put together to simulate a labyrinth-style\n# game\n\nfrom direct.showbase.ShowBase import ShowBase\nfrom panda3d.core import CollisionTraverser, CollisionNode\nfrom panda3d.core import CollisionHandlerQueue, CollisionRay, CollisionPolygon, CollisionSphere, CollisionTube\nfrom panda3d.core import Material, LRotationf, NodePath\nfrom panda3d.core import AmbientLight, DirectionalLight\nfrom panda3d.core import TextNode\nfrom panda3d.core import LVector3, BitMask32\nfrom panda3d.core import PerspectiveLens, Vec3, Point3\nfrom panda3d.core import CardMaker\nfrom direct.gui.OnscreenText import OnscreenText\nfrom direct.interval.MetaInterval import Sequence, Parallel\nfrom direct.interval.LerpInterval import LerpFunc\nfrom direct.interval.FunctionInterval import Func, Wait\nfrom direct.task.Task import Task\nfrom plane_scene import PlaneScene\nfrom parts_scene import PartsScene\n#from panda3d.bullet import BulletWorld, BulletPlaneShape, BulletRigidBodyNode, BulletBoxShape, BulletTriangleMesh, BulletTriangleMeshShape, BulletSphereShape, BulletGhostNode\nimport sys\nimport numpy as np\n\n# Some constants for the program\nACCEL = 70         # Acceleration in ft/sec/sec\nMAX_SPEED = 5      # Max speed in ft/sec\nMAX_SPEED_SQ = MAX_SPEED ** 2  # Squared to make it easier to use lengthSquared\n# Instead of length\n\n\nclass BallInMazeDemo(ShowBase):\n\n    def __init__(self):\n        # Initialize the ShowBase class from which we inherit, which will\n        # create a window and set up everything we need for rendering into it.\n        ShowBase.__init__(self)\n        base.setBackgroundColor(0, 0, 0)\n        \n        self.accept(""escape"", sys.exit)  # Escape quits\n        self.disableMouse()\n        camera.setPosHpr(0, 0, 0, 0, 0, 0)\n\n        lens = PerspectiveLens()\n        lens.setFov(90, 60)\n        lens.setNear(0.01)\n        lens.setFar(100000)\n        self.cam.node().setLens(lens)\n\n        self.ballSize = 0.025\n        self.cueLength = 0.2\n        # self.ballRoot = render.attachNewNode(""ballRoot"")\n        # #self.ball = loader.loadModel(""models/ball"")\n        # self.ball = loader.loadModel(""models/ball_0_center.egg"")\n        # #self.ball = loader.loadModel(""models/ball.dae"")\n        # self.ball.setScale(ballSize, ballSize, ballSize)\n        # self.ball.reparentTo(self.ballRoot)\n        # #print(self.ball.getBounds())\n        # #exit(1)\n        # #self.ballSphere = self.ball.find(""**/ball"")\n        # #print(self.ball.getScale()[0])\n        # cs = CollisionSphere(0, 0, 0, 1)\n        # self.ballSphere = self.ball.attachNewNode(CollisionNode(\'ball\'))\n        # self.ballSphere.node().addSolid(cs)\n        \n        # self.ballSphere.node().setFromCollideMask(BitMask32.bit(0))\n        # self.ballSphere.node().setIntoCollideMask(BitMask32.bit(1))\n\n\n        self.sceneIndex = 2\n        self.planeInfo = PlaneScene(self.sceneIndex)\n        \n        self.planeScene = self.planeInfo.generateEggModel()\n        self.planeScene.setTwoSided(True)        \n        self.planeScene.reparentTo(render)\n        self.planeScene.hide()\n        \n        planeTriangles, horizontalPlaneTriangles, self.gravityDirection = self.planeInfo.getPlaneTriangles()\n\n        \n        self.ballRoots = []\n        self.balls = []\n        self.ballSpheres = []\n        self.ballGroundRays = []\n        for ballIndex in xrange(3):\n            ballRoot = render.attachNewNode(""ballRoot_"" + str(ballIndex))\n            ball = loader.loadModel(""models/ball_"" + str(ballIndex) + ""_center.egg"")\n            ball.setScale(self.ballSize, self.ballSize, self.ballSize)\n\n            cs = CollisionSphere(0, 0, 0, 1)\n            ballSphere = ball.attachNewNode(CollisionNode(\'ball_\' + str(ballIndex)))\n            ballSphere.node().addSolid(cs)\n            ballSphere.node().setFromCollideMask(BitMask32.bit(0) | BitMask32.bit(1) | BitMask32.bit(3) | BitMask32.bit(4))\n            ballSphere.node().setIntoCollideMask(BitMask32.bit(1))\n\n            ball.reparentTo(ballRoot)\n            self.ballRoots.append(ballRoot)\n            self.balls.append(ball)            \n            self.ballSpheres.append(ballSphere)\n\n\n            ballGroundRay = CollisionRay()     # Create the ray\n            ballGroundRay.setOrigin(0, 0, 0)    # Set its origin\n            ballGroundRay.setDirection(self.gravityDirection[0], self.gravityDirection[1], self.gravityDirection[2])  # And its direction\n            # Collision solids go in CollisionNode\n            # Create and name the node\n            ballGroundCol = CollisionNode(\'ball_ray_\' + str(ballIndex))\n            ballGroundCol.addSolid(ballGroundRay)  # Add the ray\n            ballGroundCol.setFromCollideMask(BitMask32.bit(2))  # Set its bitmasks\n            ballGroundCol.setIntoCollideMask(BitMask32.allOff())\n            # Attach the node to the ballRoot so that the ray is relative to the ball\n            # (it will always be 10 feet over the ball and point down)\n            ballGroundColNp = ballRoot.attachNewNode(ballGroundCol)\n            self.ballGroundRays.append(ballGroundColNp)\n\n            ballRoot.hide()\n            continue\n\n        \n        # Finally, we create a CollisionTraverser. CollisionTraversers are what\n        # do the job of walking the scene graph and calculating collisions.\n        # For a traverser to actually do collisions, you need to call\n        # traverser.traverse() on a part of the scene. Fortunately, ShowBase\n        # has a task that does this for the entire scene once a frame.  By\n        # assigning it to self.cTrav, we designate that this is the one that\n        # it should call traverse() on each frame.\n        self.cTrav = CollisionTraverser()\n\n        # Collision traversers tell collision handlers about collisions, and then\n        # the handler decides what to do with the information. We are using a\n        # CollisionHandlerQueue, which simply creates a list of all of the\n        # collisions in a given pass. There are more sophisticated handlers like\n        # one that sends events and another that tries to keep collided objects\n        # apart, but the results are often better with a simple queue\n        self.cHandler = CollisionHandlerQueue()\n        # Now we add the collision nodes that can create a collision to the\n        # traverser. The traverser will compare these to all others nodes in the\n        # scene. There is a limit of 32 CollisionNodes per traverser\n        # We add the collider, and the handler to use as a pair\n        \n        #self.cTrav.addCollider(self.ballSphere, self.cHandler)\n        for ballSphere in self.ballSpheres:\n            self.cTrav.addCollider(ballSphere, self.cHandler)\n            continue\n        for ballGroundRay in self.ballGroundRays:\n            self.cTrav.addCollider(ballGroundRay, self.cHandler)\n            continue        \n        #self.cTrav.addCollider(self.ballGroundColNp, self.cHandler)\n\n        # Collision traversers have a built in tool to help visualize collisions.\n        # Uncomment the next line to see it.\n        #self.cTrav.showCollisions(render)\n\n        # This section deals with lighting for the ball. Only the ball was lit\n        # because the maze has static lighting pregenerated by the modeler\n        ambientLight = AmbientLight(""ambientLight"")\n        ambientLight.setColor((.55, .55, .55, 1))\n        directionalLight = DirectionalLight(""directionalLight"")\n        directionalLight.setDirection(LVector3(0, 0, -1))\n        directionalLight.setColor((0.375, 0.375, 0.375, 1))\n        directionalLight.setSpecularColor((1, 1, 1, 1))\n\n        for ballRoot in self.ballRoots:\n            ballRoot.setLight(render.attachNewNode(ambientLight))\n            ballRoot.setLight(render.attachNewNode(directionalLight))\n            continue\n\n        # This section deals with adding a specular highlight to the ball to make\n        # it look shiny.  Normally, this is specified in the .egg file.\n        m = Material()\n        m.setSpecular((1, 1, 1, 1))\n        m.setShininess(96)\n        for ball in self.balls:\n            ball.setMaterial(m, 1)\n            continue\n\n\n        self.original = False\n        if self.original:\n            camera.setPosHpr(0, 0, 25, 0, -90, 0)        \n            self.maze = loader.loadModel(""models/maze"")\n            self.maze.reparentTo(render)\n            self.walls = self.maze.find(""**/wall_collide"")\n            self.walls.node().setIntoCollideMask(BitMask32.bit(0))\n            self.walls.show()\n            pass\n\n\n\n        #planeTriangles, planeNormals = self.planeInfo.getPlaneGeometries()\n\n        self.triNPs = []\n        for triangleIndex, triangle in enumerate(planeTriangles):\n            #print(triangleIndex)\n            #for triangle in triangles:\n            #print(triangle)\n            tri = CollisionPolygon(Point3(triangle[0][0], triangle[0][1], triangle[0][2]), Point3(triangle[1][0], triangle[1][1], triangle[1][2]), Point3(triangle[2][0], triangle[2][1], triangle[2][2]))\n            triNP = render.attachNewNode(CollisionNode(\'tri_\' + str(triangleIndex)))\n            triNP.node().setIntoCollideMask(BitMask32.bit(0))\n            triNP.node().addSolid(tri)\n            self.triNPs.append(triNP)\n            #triNP.show()\n            continue\n\n        #print(horizontalPlaneTriangles)\n        \n        for triangleIndex, triangle in enumerate(horizontalPlaneTriangles):\n            #print(triangleIndex)\n            #for triangle in triangles:\n            #print(triangle)\n            tri = CollisionPolygon(Point3(triangle[0][0], triangle[0][1], triangle[0][2]), Point3(triangle[1][0], triangle[1][1], triangle[1][2]), Point3(triangle[2][0], triangle[2][1], triangle[2][2]))\n            triNP = render.attachNewNode(CollisionNode(\'ground_\' + str(triangleIndex)))\n            triNP.node().setIntoCollideMask(BitMask32.bit(2))\n            triNP.node().addSolid(tri)\n            self.triNPs.append(triNP)\n            #triNP.show()\n            continue\n        \n        \n        # tri = CollisionPolygon(Point3(-1, 4, -1), Point3(2, 4, -1), Point3(2, 4, 2))    \n        # triNP = render.attachNewNode(CollisionNode(\'tri\'))\n        # triNP.node().setIntoCollideMask(BitMask32.bit(0))\n        # triNP.node().addSolid(tri)\n        # triNP.show()\n        \n        \n        #self.planeScene.node().setIntoCollideMask(BitMask32.bit(0))\n        # roomRootNP = self.planeScene\n        # roomRootNP.flattenLight()\n        # mesh = BulletTriangleMesh()\n        # polygons = roomRootNP.findAllMatches(""**/+GeomNode"")\n\n        # # p0 = Point3(-10, 4, -10)\n        # # p1 = Point3(-10, 4, 10)\n        # # p2 = Point3(10, 4, 10)\n        # # p3 = Point3(10, 4, -10)\n        # # mesh.addTriangle(p0, p1, p2)\n        # # mesh.addTriangle(p1, p2, p3)\n\n        # print(polygons)\n        # for polygon in polygons:\n        #     geom_node = polygon.node()\n        #     #geom_node.reparentTo(self.render)\n        #     #print(geom_node.getNumGeoms())\n        #     ts = geom_node.getTransform()\n        #     #print(ts)\n        #     for geom in geom_node.getGeoms():\n        #         mesh.addGeom(geom, ts)\n        #         continue\n        #     continue\n        # #self.scene = roomRootNP\n        # shape = BulletTriangleMeshShape(mesh, dynamic=False)\n        # #shape = BulletPlaneShape(Vec3(0, 0, 1), 1)\n        # room = BulletRigidBodyNode(\'scene\')\n        # room.addShape(shape)\n        # #room.setLinearDamping(0.0)\n        # #room.setFriction(0.0)\n        # print(shape)\n        # room.setDeactivationEnabled(False)\n        # roomNP = render.attachNewNode(room)\n        # roomNP.setPos(0, 0, 0)\n        # roomNP.node().setIntoCollideMask(BitMask32.bit(0))\n        # self.world = BulletWorld()\n        # self.world.setGravity(Vec3(0, 0, 0))\n        # self.world.attachRigidBody(roomNP.node())\n        #room.setRestitution(1)\n\n        #self.roomNP = self.scene\n        \n\n        self.cueRoot = render.attachNewNode(""cueRoot"")\n        self.cue = loader.loadModel(""models/cue_center.egg"")\n        self.cue.setScale(self.cueLength * 3, self.cueLength * 3, self.cueLength)\n        self.cue.reparentTo(self.cueRoot)\n\n        self.cuePos = (10, 0, 0)\n        \n        self.pickerNode = CollisionNode(\'mouseRay\')\n        # Attach that node to the camera since the ray will need to be positioned\n        # relative to it\n        self.pickerNP = camera.attachNewNode(self.pickerNode)\n        # Everything to be picked will use bit 1. This way if we were doing other\n        # collision we could separate it\n        self.pickerNode.setFromCollideMask(BitMask32.bit(2))\n        self.pickerNode.setIntoCollideMask(BitMask32.allOff())        \n        self.pickerRay = CollisionRay()  # Make our ray\n        # Add it to the collision node\n        self.pickerNode.addSolid(self.pickerRay)\n        # Register the ray as something that can cause collisions\n        self.cTrav.addCollider(self.pickerNP, self.cHandler)        \n\n        self.accept(""mouse1"", self.hit)  # left-click grabs a piece\n\n\n        self.holeLength = 0.06\n        holePos, holeHpr = self.planeInfo.getHolePos()\n        self.holeRoot = render.attachNewNode(""holeRoot"")\n        #self.hole = loader.loadModel(""models/hole_horizontal_center.egg"")\n        self.hole = loader.loadModel(""models/hole_color.egg"")\n        #self.hole = loader.loadModel(""models/billiards_hole_center.egg"")\n        self.hole.setScale(self.holeLength, self.holeLength, self.holeLength)\n        self.hole.reparentTo(self.holeRoot)\n        self.hole.setTwoSided(True)\n        self.holeRoot.setPos(holePos[0], holePos[1], holePos[2])\n        self.holeRoot.setHpr(holeHpr[0], holeHpr[1], holeHpr[2])\n        #tex = loader.loadTexture(\'models/Black_Hole.jpg\')\n        #self.hole.setTexture(tex, 1)\n        self.holeRoot.hide()\n        \n        ct = CollisionTube(0, 0, 0, 0, 0.001, 0, 0.5)\n        self.holeTube = self.hole.attachNewNode(CollisionNode(\'hole\'))\n        self.holeTube.node().addSolid(ct)\n        self.holeTube.node().setFromCollideMask(BitMask32.allOff())        \n        self.holeTube.node().setIntoCollideMask(BitMask32.bit(4))\n        #self.holeTube.show()\n\n\n        inPortalPos, inPortalHpr, outPortalPos, outPortalHpr, self.portalNormal = self.planeInfo.getPortalPos()\n        self.portalLength = 0.06\n        self.inPortalRoot = render.attachNewNode(""inPortalRoot"")\n        self.inPortal = loader.loadModel(""models/portal_2_center.egg"")\n        self.inPortal.setScale(self.portalLength, self.portalLength, self.portalLength)\n        self.inPortal.reparentTo(self.inPortalRoot)\n        self.inPortalRoot.setPos(inPortalPos[0], inPortalPos[1], inPortalPos[2])\n        self.inPortalRoot.setHpr(inPortalHpr[0], inPortalHpr[1], inPortalHpr[2])\n        self.inPortalRoot.hide()\n        \n        ct = CollisionTube(0, 0, 0, 0, 0.001, 0, 1)\n        self.inPortalTube = self.inPortal.attachNewNode(CollisionNode(\'portal_in\'))\n        self.inPortalTube.node().addSolid(ct)\n        self.inPortalTube.node().setFromCollideMask(BitMask32.allOff())        \n        self.inPortalTube.node().setIntoCollideMask(BitMask32.bit(3))\n        #self.inPortalTube.hide()\n\n        self.outPortalRoot = render.attachNewNode(""outPortalRoot"")\n        self.outPortal = loader.loadModel(""models/portal_2_center.egg"")\n        self.outPortal.setScale(self.portalLength, self.portalLength, self.portalLength)\n        self.outPortal.reparentTo(self.outPortalRoot)\n        self.outPortalRoot.setPos(outPortalPos[0], outPortalPos[1], outPortalPos[2])\n        self.outPortalRoot.setHpr(outPortalHpr[0], outPortalHpr[1], outPortalHpr[2])\n        self.outPortalRoot.hide()\n        \n        ct = CollisionTube(0, 0, 0, 0, 0.001, 0, 1)\n        self.outPortalTube = self.outPortal.attachNewNode(CollisionNode(\'portal_out\'))\n        self.outPortalTube.node().addSolid(ct)\n        self.outPortalTube.node().setFromCollideMask(BitMask32.allOff())        \n        self.outPortalTube.node().setIntoCollideMask(BitMask32.bit(3))\n        #self.outPortalTube.hide()        \n        #self.inPortalTube.show()\n        #self.outPortalTube.show()\n        #self.holeTube.show()\n        \n        #self.cTrav.addCollider(self.holeTube, self.cHandler)\n\n        background_image = loader.loadTexture(\'dump/\' + str(self.sceneIndex) + \'_image.png\')\n        cm = CardMaker(\'background\')\n        cm.setHas3dUvs(True)\n        info = np.load(\'dump/\' + str(self.sceneIndex) + \'_info.npy\')\n        #self.camera = getCameraFromInfo(self.info)\n        depth = 10.0\n        sizeU = info[2] / info[0] * depth\n        sizeV = info[6] / info[5] * depth\n        cm.setFrame(Point3(-sizeU, depth, -sizeV), Point3(sizeU, depth, -sizeV), Point3(sizeU, depth, sizeV), Point3(-sizeU, depth, sizeV))\n        self.card = self.render.attachNewNode(cm.generate())\n        self.card.setTransparency(True)    \n        self.card.setTexture(background_image)\n        self.card.hide()\n        \n        \n        self.ballGroundMap = {}\n        self.ballBouncing = np.full(len(self.balls), 3)\n        \n        self.started = False\n        self.start()\n        \n        self.hitIndex = 0\n        \n        self.showing = \'none\'\n        self.showingProgress = 0\n        \n        partsScene = PartsScene(self.sceneIndex)        \n        self.planeNPs, self.planeCenters = partsScene.generateEggModel()\n        return\n\n    def start(self):\n        #startPos = self.maze.find(""**/start"").getPos()\n        #self.ballRoot.setPos(0.5, 0, 0)\n        #self.ballV = LVector3(0, 0.5, 0)         # Initial velocity is 0\n        #self.accelV = LVector3(0, 0, 0)        # Initial acceleration is 0\n\n        self.ballVs = []\n        self.accelVs = []\n        for ballIndex in xrange(len(self.balls)):\n            self.ballVs.append(LVector3(0, 0, 0))\n            self.accelVs.append(LVector3(0, 0, 0))\n            continue\n        self.ballRoots[0].setPos(0.2, 1.05, -0.1)\n        #self.ballVs[0] = LVector3(0, 0.0, 0)                \n        self.ballRoots[1].setPos(0.32, 1.2, -0.1)\n        #self.ballRoots[2].setHpr(0, 0, 90)\n        self.ballRoots[2].setPos(-0.4, 1.1, 0.4)\n        axis = LVector3.up()\n        prevRot = LRotationf(self.balls[2].getQuat())\n        newRot = LRotationf(axis, 90)\n        self.balls[2].setQuat(prevRot * newRot)\n            \n        # Create the movement task, but first make sure it is not already\n        # running\n        taskMgr.remove(""rollTask"")\n        #taskMgr.remove(""mouseTask"")\n        self.mainLoop = taskMgr.add(self.rollTask, ""rollTask"")        \n        #self.mainLoop = taskMgr.add(self.mouseTask, ""mouseTask"")\n        \n        return\n\n    def hit(self):\n        if self.cuePos[0] < 5:\n            cueDirection = self.ballRoots[0].getPos() - LVector3(self.cuePos[0], self.cuePos[1], self.cuePos[2])\n            #power = cueDirection.length()\n            cueDirection = cueDirection / cueDirection.length()\n            if self.hitIndex < 0:\n                self.ballVs[0] = cueDirection * self.cuePower * 8\n            elif self.hitIndex == 0:\n                self.ballVs[0] = LVector3(0.5, 0.47, 0)\n                self.hitIndex += 1\n            elif self.hitIndex == 1:\n                self.ballVs[0] = LVector3(0.072, 0.62, 0)\n                self.hitIndex += 1\n            elif self.hitIndex == 2:\n                self.ballVs[0] = LVector3(0.7, 0.0, 0)\n                self.hitIndex += 1                                \n                pass\n            self.started = True\n            print(\'hit\', cueDirection)\n            self.ballBouncing = np.full(len(self.balls), 3)\n            pass\n\n\n\n    # This function handles the collision between the ball and a wall\n    def planeCollideHandler(self, colEntry):\n        #return\n        ballName = colEntry.getFromNode().getName()\n        ballIndex = int(ballName[5:])\n        \n        # First we calculate some numbers we need to do a reflection\n        # print(colEntry)\n        # name = colEntry.getIntoNode().getName()\n        # triangleIndex = int(name[4:])\n        # print(triangleIndex)\n        # print(self.planeNormals[triangleIndex])\n        # print(colEntry.getSurfaceNormal(render))\n        # exit(1)\n        norm = colEntry.getSurfaceNormal(render) * -1  # The normal of the wall\n        norm.normalize()\n        curSpeed = self.ballVs[ballIndex].length()                # The current speed\n        inVec = self.ballVs[ballIndex] / curSpeed                 # The direction of travel\n        velAngle = norm.dot(inVec)                    # Angle of incidance\n        hitDir = colEntry.getSurfacePoint(render) - self.ballRoots[ballIndex].getPos()\n        hitDir.normalize()\n        # The angle between the ball and the normal\n        hitAngle = norm.dot(hitDir)\n\n        # Ignore the collision if the ball is either moving away from the wall\n        # already (so that we don\'t accidentally send it back into the wall)\n        # and ignore it if the collision isn\'t dead-on (to avoid getting caught on\n        # corners)\n        #print(velAngle, hitAngle)\n\n        if velAngle > 0 and hitAngle > .995:\n            print(\'plane\', ballName, velAngle)\n            # Standard reflection equation\n            reflectVec = (norm * norm.dot(inVec * -1) * 2) + inVec\n\n            # This makes the velocity half of what it was if the hit was dead-on\n            # and nearly exactly what it was if this is a glancing blow\n            #self.ballVs[ballIndex] = reflectVec * (curSpeed * (((1 - velAngle) * .5) + .5))\n            self.ballVs[ballIndex] = reflectVec * curSpeed\n            # Since we have a collision, the ball is already a little bit buried in\n            # the wall. This calculates a vector needed to move it so that it is\n            # exactly touching the wall\n            disp = (colEntry.getSurfacePoint(render) -\n                    colEntry.getInteriorPoint(render))\n            newPos = self.ballRoots[ballIndex].getPos() + disp\n            self.ballRoots[ballIndex].setPos(newPos)\n            pass\n        return    \n\n    # This function handles the collision between the ball and a wall\n    def portal(self, colEntry):\n        ballName = colEntry.getFromNode().getName()\n        print(\'portal\', ballName)\n        ballIndex = int(ballName[5:])\n        \n        #norm = colEntry.getSurfaceNormal(render) * -1  # The normal of the wall\n        norm = LVector3(self.portalNormal[0], self.portalNormal[1], self.portalNormal[2])\n        norm.normalize()\n        curSpeed = self.ballVs[ballIndex].length()                # The current speed\n        inVec = self.ballVs[ballIndex] / curSpeed                 # The direction of travel\n        velAngle = norm.dot(inVec)                    # Angle of incidance\n        hitDir = colEntry.getSurfacePoint(render) - self.ballRoots[ballIndex].getPos()\n        hitDir.normalize()\n        # The angle between the ball and the normal\n        #print(colEntry.getSurfacePoint(render), self.ballRoots[ballIndex].getPos())\n        #print(norm, hitDir)\n        hitAngle = norm.dot(hitDir)\n        \n        # Ignore the collision if the ball is either moving away from the wall\n        # already (so that we don\'t accidentally send it back into the wall)\n        # and ignore it if the collision isn\'t dead-on (to avoid getting caught on\n        # corners)\n        #print(velAngle, hitAngle)\n        #print(velAngle, hitAngle)\n        if velAngle > 0:\n            print(colEntry.getIntoNode().getName())\n            if \'_in\' in colEntry.getIntoNode().getName():\n                self.ballRoots[ballIndex].setPos(self.outPortalRoot.getPos())\n            else:\n                self.ballRoots[ballIndex].setPos(self.inPortalRoot.getPos())\n                pass\n            print(self.ballVs[ballIndex], ((norm * norm.dot(inVec * -1) * 2) + inVec) * curSpeed, norm)\n            #exit(1)\n            self.ballVs[ballIndex] = ((norm * norm.dot(inVec * -1) * 2) + inVec) * curSpeed\n            #self.ballVs[ballIndex] *= -1\n            pass\n        return    \n    \n\n    # This function handles the collision between the ball and a wall\n    def ballCollideHandler(self, colEntry):\n        # First we calculate some numbers we need to do a reflection\n        fromBallName = colEntry.getFromNode().getName()\n        fromBallIndex = int(fromBallName[5:])\n        #if fromBallIndex != 0:\n        #return\n        intoBallName = colEntry.getIntoNode().getName()\n        intoBallIndex = int(intoBallName[5:])        \n\n        print(\'ball\', fromBallName, intoBallName)\n        \n        norm = colEntry.getSurfaceNormal(render) * -1  # The normal of the wall\n        norm = norm / norm.length()\n        curSpeed = self.ballVs[fromBallIndex].length()                # The current speed\n        inVec = self.ballVs[fromBallIndex] / curSpeed                 # The direction of travel\n        velAngle = norm.dot(inVec)                    # Angle of incidance\n        hitDir = colEntry.getSurfacePoint(render) - self.ballRoots[fromBallIndex].getPos()\n        hitDir.normalize()\n        # The angle between the ball and the normal\n        hitAngle = norm.dot(hitDir)\n\n        # print(norm)\n        # print(self.ballVs[fromBallIndex])\n        # print(velAngle, hitAngle)\n        # print(self.ballRoots[fromBallIndex].getPos())\n        # print(self.ballRoots[intoBallIndex].getPos())        \n        # exit(1)\n        #print(fromBallIndex, intoBallIndex)\n        #exit(1)\n        \n        # Ignore the collision if the ball is either moving away from the wall\n        # already (so that we don\'t accidentally send it back into the wall)\n        # and ignore it if the collision isn\'t dead-on (to avoid getting caught on\n        # corners)\n        #print(velAngle, hitAngle)\n        if velAngle > 0 and hitAngle > .995:\n            # Standard reflection equation\n            self.ballVs[fromBallIndex] = ((norm * norm.dot(inVec * -1)) + inVec) * curSpeed\n\n            disp = (colEntry.getSurfacePoint(render) -\n                    colEntry.getInteriorPoint(render))\n            newPos = self.ballRoots[fromBallIndex].getPos() + disp\n            self.ballRoots[fromBallIndex].setPos(newPos)\n\n            self.ballVs[intoBallIndex] = norm * norm.dot(inVec) * curSpeed\n            pass\n        return    \n\n\n        \n    def groundCollideHandler(self, colEntry):\n        # Set the ball to the appropriate Z value for it to be exactly on the\n        # ground\n        ballName = colEntry.getFromNode().getName()\n\n        if \'mouseRay\' in ballName:\n            for v in self.ballVs:\n                if v.length() > 1e-4:\n                    self.cuePos = (10, 0, 0)\n                    return\n                continue\n            #print(self.mouseWatcherNode.hasMouse())\n            norm = colEntry.getSurfaceNormal(render)\n            norm.normalize()\n            touchPoint = colEntry.getSurfacePoint(render)\n            cuePoint = touchPoint + norm * self.ballSize\n            cueDirection = self.ballRoots[0].getPos() - cuePoint\n            self.cuePower = cueDirection.length()\n            cueDirection = cueDirection / cueDirection.length()\n            cuePoint = self.ballRoots[0].getPos() - cueDirection * self.cueLength\n            self.cuePos = cuePoint\n            #self.cueRoot.setH(np.rad2deg(np.arctan2(cueDirection[1], cueDirection[0])) + 90)\n            self.cueRoot.setH(np.rad2deg(np.arctan2(cueDirection[1], cueDirection[0])) + 90)  \n            self.cueRoot.setP(-np.rad2deg(np.arcsin(cueDirection[2])) + 90)\n            #self.cueRoot.setP(90)\n            #print(np.rad2deg(np.arctan2(cueDirection[1], cueDirection[0])), np.rad2deg(np.arcsin(cueDirection[2])))\n\n            # prevRot = LRotationf(self.cue.getQuat())\n            # axis = LVector3.up().cross(self.ballVs[ballIndex])\n            # newRot = LRotationf(axis, 45.5 * dt * self.ballVs[ballIndex].length())\n            # self.balls[ballIndex].setQuat(prevRot * newRot)\n            return\n            \n        #print(\'ground\', ballName)\n        #print(ballName, colEntry.getIntoNode().getName())\n        #print(colEntry.getFromNode().getBitMask(), colEntry.getIntoNode().getBitMask())\n        ballIndex = int(ballName[9:])\n\n        groundName = colEntry.getIntoNode().getName()\n        groundIndex = int(groundName[7:])\n        #print(groundIndex)\n        #print(self.ballGroundMap)\n        if ballIndex == 0 and False:\n            print(groundIndex, self.ballGroundMap)\n            pass\n        \n        if ballIndex not in self.ballGroundMap or self.ballGroundMap[ballIndex][0] != groundIndex:\n            return\n        \n        norm = -colEntry.getSurfaceNormal(render)\n        norm = norm / norm.length()\n\n        curSpeed = self.ballVs[ballIndex].length()                # The current speed\n        inVec = self.ballVs[ballIndex] / max(curSpeed, 1e-4)                 # The direction of travel\n        velAngle = norm.dot(inVec)                    # Angle of incidance\n        hitDir = colEntry.getSurfacePoint(render) - self.ballRoots[ballIndex].getPos()\n        hitDir.normalize()\n        # The angle between the ball and the normal\n        hitAngle = norm.dot(hitDir)\n        \n        surfacePos = colEntry.getSurfacePoint(render)\n        ballPos = self.ballRoots[ballIndex].getPos()\n        surfacePos = ballPos + norm * norm.dot(surfacePos - ballPos)\n\n        distance = norm.dot(surfacePos - ballPos)\n        if distance < 0:\n            return\n\n        \n        if distance < self.ballSize + 1e-3:\n            self.ballRoots[ballIndex].setPos(surfacePos - norm * self.ballSize)\n            if self.ballVs[ballIndex].length() > 1e-2:\n                self.ballVs[ballIndex] = (-norm * velAngle + inVec) * curSpeed\n                #self.ballVs[ballIndex] = -norm.cross(norm.cross(self.ballVs[ballIndex]))\n                self.accelVs[ballIndex] = -self.ballVs[ballIndex] / self.ballVs[ballIndex].length() * 0.0025\n            else:\n                self.ballVs[ballIndex] = LVector3(0, 0, 0)\n                self.accelVs[ballIndex] = LVector3(0, 0, 0)                \n                pass\n        else:\n            self.accelVs[ballIndex] = self.accelVs[ballIndex] - norm * norm.dot(self.accelVs[ballIndex]) + norm * 0.05\n            pass\n        return\n\n    \n        # if self.started:\n        #     if abs(distance - self.ballSize) > 0.001 and abs(distance - self.ballSize) < self.ballSize:\n        #         self.ballRoots[ballIndex].setPos(surfacePos - norm * self.ballSize)\n        #         pass\n        #     self.ballVs[ballIndex] = -norm.cross(norm.cross(self.ballVs[ballIndex]))\n        #     if self.ballVs[ballIndex].length() > 1e-3:\n        #         self.accelVs[ballIndex] = -self.ballVs[ballIndex] / self.ballVs[ballIndex].length() * 0.015\n        #     else:\n        #         self.ballVs[ballIndex] = LVector3(0, 0, 0)\n        #         self.accelVs[ballIndex] = LVector3(0, 0, 0)\n        #         pass\n        #     #print(self.ballVs[ballIndex], self.accelVs[ballIndex])\n        #     #print(surfacePos - norm * self.ballSize)\n\n        #     return\n\n\n        if ballIndex == 0:\n            print(\'distance_1\', self.started, distance, velAngle, self.ballVs[ballIndex], self.accelVs[ballIndex])\n        \n        if distance < self.ballSize:\n            self.ballRoots[ballIndex].setPos(surfacePos - norm * self.ballSize)\n            if velAngle > 0 and hitAngle > .995:\n                if abs(velAngle * curSpeed) < 0.2:\n                    if ((-norm * velAngle + inVec) * curSpeed).length() < 0.02:\n                        self.ballVs[ballIndex] = LVector3(0, 0, 0)\n                        self.accelVs[ballIndex] = LVector3(0, 0, 0)\n                        pass\n                    pass\n                else:\n                    if self.ballBouncing[ballIndex] > 0:\n                        if ballIndex == 0:\n                            print(\'bouncing\')\n                            pass\n                        self.ballVs[ballIndex] = (-norm * velAngle + inVec) * curSpeed * 0.5 - norm * velAngle * curSpeed * 0.25\n                        self.accelVs[ballIndex] = LVector3(0, 0, 0)\n                        self.ballBouncing[ballIndex] -= 1\n                    else:\n                        self.ballVs[ballIndex] = (-norm * velAngle + inVec) * curSpeed\n                        self.accelVs[ballIndex] = LVector3(0, 0, 0)\n                        pass\n                    pass\n                pass\n            \n            pass\n\n        if (distance - self.ballSize) > 0.001:\n            self.accelVs[ballIndex] = self.accelVs[ballIndex] - norm * norm.dot(self.accelVs[ballIndex]) + norm * 0.1\n            # print(self.accelVs[ballIndex] - norm * norm.dot(self.accelVs[ballIndex]))\n            # print(norm)\n            # print(inVec)\n            # print(velAngle)\n            # print(-norm * velAngle + inVec)\n            # print(norm * 0.01)\n            # exit(1)\n        elif distance - self.ballSize > -0.001:\n            if self.ballVs[ballIndex].length() < 0.001:\n                #print(\'stop\', self.ballVs[ballIndex], self.accelVs[ballIndex])\n\n                self.ballVs[ballIndex] = LVector3(0, 0, 0)\n                self.accelVs[ballIndex] = LVector3(0, 0, 0)\n                self.started = False\n            else:\n                if abs(velAngle) < 1e-3:\n                    self.ballVs[ballIndex] = (-norm * velAngle + inVec) * curSpeed\n                    #self.ballVs[ballIndex] = -norm.cross(norm.cross(self.ballVs[ballIndex]))\n                    self.accelVs[ballIndex] = -self.ballVs[ballIndex] / self.ballVs[ballIndex].length() * 0.01\n                    #print(\'speed\', self.ballVs[ballIndex], self.accelVs[ballIndex])\n                    pass\n                pass\n            pass\n    \n        # #print(distance - self.ballSize)\n        # if (distance - self.ballSize) > 0.01:\n        #     self.accelVs[ballIndex] = self.accelVs[ballIndex] - norm * norm.dot(self.accelVs[ballIndex]) + norm * 0.01\n        #     #if ballIndex == 0:\n        #     #print(velAngle, self.ballVs[ballIndex], self.accelVs[ballIndex], norm)\n        #     #pass\n\n        #     print(\'fall\', self.accelVs[ballIndex], distance)\n        #     # print(self.accelVs[ballIndex] - norm * norm.dot(self.accelVs[ballIndex]))\n        #     # print(norm)\n        #     # print(inVec)\n        #     # print(velAngle)\n        #     # print(-norm * velAngle + inVec)\n        #     # print(norm * 0.01)\n        #     # exit(1)\n        # else:\n        #     #hitAngle > .995\n        #     #print(velAngle)\n        #     #print(norm)\n\n        #     #self.ballRoots[ballIndex].setPos(surfacePos - norm * self.ballSize)\n        #     if curSpeed > 1e-1:\n        #         print(\'angle\', velAngle, norm)\n        #         self.norm = norm\n        #         pass\n        #     if velAngle > 1e-3:\n        #         if curSpeed < 1e-3:\n        #             self.ballVs[ballIndex] = LVector3(0, 0, 0)\n        #             self.accelVs[ballIndex] = LVector3(0, 0, 0)\n        #             self.ballRoots[ballIndex].setPos(surfacePos - norm * self.ballSize)\n        #         else:\n        #             self.ballVs[ballIndex] = (-norm * velAngle + inVec) * curSpeed * 0.9 - norm * velAngle * curSpeed * 0.25\n        #             self.accelVs[ballIndex] = LVector3(0, 0, 0)\n        #             pass\n        #         #print((-norm * velAngle + inVec) * curSpeed * 0.9, norm * velAngle * curSpeed * 0.25)\n        #         #print(curSpeed, norm.dot(self.ballVs[ballIndex]) / self.ballVs[ballIndex].length(), self.ballVs[ballIndex], self.accelVs[ballIndex])\n        #         #print(norm.dot(self.ballVs[ballIndex]) / self.ballVs[ballIndex].length(), norm.dot(self.accelVs[ballIndex]) / self.accelVs[ballIndex].length(), self.ballVs[ballIndex], self.accelVs[ballIndex])\n        #     elif velAngle > -1e-3:\n        #         if self.ballVs[ballIndex].length() < 0.001:\n        #             #self.ballVs[ballIndex] = LVector3(0, 0, 0)\n        #             #self.accelVs[ballIndex] = LVector3(0, 0, 0)\n        #             #print(\'stop\', self.ballVs[ballIndex], self.accelVs[ballIndex])\n        #             pass\n        #         else:\n        #             #self.ballVs[ballIndex] = (-norm * velAngle + inVec) * curSpeed * 0.9\n        #             #print(self.ballVs[ballIndex], self.accelVs[ballIndex])\n        #             self.accelVs[ballIndex] = -(-norm * velAngle + inVec) * 0.1\n        #             print(\'accel\', self.accelVs[ballIndex])\n        #             pass\n        #         pass\n        #     else:\n        #         #print(\'stop\', self.ballVs[ballIndex], self.accelVs[ballIndex])\n        #         #self.ballVs[ballIndex] = LVector3(0, 0, 0)\n        #         #self.accelVs[ballIndex] = LVector3(0, 0, 0)\n        #         pass\n        #     pass\n        return\n    \n    # This is the task that deals with making everything interactive\n    def rollTask(self, task):\n        # Standard technique for finding the amount of time since the last\n        # frame\n        dt = globalClock.getDt()\n\n        # If dt is large, then there has been a # hiccup that could cause the ball\n        # to leave the field if this functions runs, so ignore the frame\n        if dt > .2:\n            return Task.cont\n\n        # if base.mouseWatcherNode.is_button_down(\'a\'):\n        #     self.holeRoot.setH(self.holeRoot.getH() + 1)\n        #     print(self.holeRoot.getHpr())\n        #     pass\n        # if base.mouseWatcherNode.is_button_down(\'s\'):\n        #     self.holeRoot.setP(self.holeRoot.getP() + 1)\n        #     print(self.holeRoot.getHpr())\n        #     pass\n        # if base.mouseWatcherNode.is_button_down(\'d\'):\n        #     self.holeRoot.setR(self.holeRoot.getR() + 1)\n        #     print(self.holeRoot.getHpr())\n        #     pass\n        \n        if base.mouseWatcherNode.is_button_down(\'space\') and self.showing == \'none\':\n            self.showing = \'parts\'\n            #self.showingProgress = 0\n            pass\n        #print(self.showing)\n        #print(self.showing)\n        if self.showing == \'none\':\n            return Task.cont\n        if self.showing == \'parts\':\n            self.showingProgress += 0.01\n            #self.showingProgress += 1\n            print(self.showingProgress)\n            scale = 2 - self.showingProgress\n            scaleY = 1 + (scale - 1) * 0.5\n            for planeIndex, planeNP in enumerate(self.planeNPs):\n                center = self.planeCenters[planeIndex]\n                planeNP.setPos(center[0] * scale, center[1] * scaleY, center[2] * scale)\n                planeNP.reparentTo(self.render)\n                planeNP.setTwoSided(True)\n                continue\n            if self.showingProgress > 1:\n                self.showing = \'moving\'\n                for planeIndex, planeNP in enumerate(self.planeNPs):\n                    planeNP.removeNode()\n                    continue\n                self.planeScene.show()\n                self.showingProgress = 0\n            return Task.cont\n        if self.showing == \'moving\':\n            self.showingProgress += 0.005\n            #self.showingProgress += 1\n            #print(self.showingProgress, np.sign(self.showingProgress - 0.5) * min(self.showingProgress % 0.5, 0.5 - self.showingProgress % 0.5) * 4)\n            self.camera.setPos(np.sign(self.showingProgress - 0.5) * min(self.showingProgress % 0.5, 0.5 - self.showingProgress % 0.5) * 3, 0, 0)\n            #self.camera.setHpr(angleDegrees, 0, 0)\n            #self.camera.lookAt(0, 0, 0)\n            self.camera.lookAt(0, 3, 0)\n            if self.showingProgress > 1:\n                self.showing = \'geometry\'\n                self.camera.setPos(0, 0, 0)\n                #self.planeScene.removeNode()\n                # for triNP in self.triNPs:\n                #     triNP.show()\n                #     continue\n                self.showingProgress = 1\n            return Task.cont\n        if self.showing == \'geometry\':\n            self.showingProgress += 0.02\n            if self.showingProgress > 1:\n                #self.showing = \'image\'\n                self.showing = \'placement\'\n                self.showingProgress = 0\n                self.holeRoot.show()\n                self.inPortalRoot.show()\n                self.outPortalRoot.show()\n                self.inPortalTube.show()\n                self.outPortalTube.show()\n                for ballRoot in self.ballRoots:\n                    ballRoot.show()\n                    continue\n                self.showingProgress = 0                \n                pass\n            return Task.cont\n        # if self.showing == \'placement\':\n        #     self.showingProgress += 0.005\n        #         continue\n\n        if self.mouseWatcherNode.hasMouse():\n            mpos = self.mouseWatcherNode.getMouse()\n            self.mpos = mpos\n            self.pickerRay.setFromLens(self.camNode, mpos.getX(), mpos.getY())\n            pass\n        \n        if base.mouseWatcherNode.is_button_down(\'space\') and self.showing == \'placement\':\n            self.card.show()\n            self.planeScene.removeNode()\n            self.showing = \'image\'\n            pass\n        # if base.mouseWatcherNode.is_button_down(\'space\') and self.showing == \'image\':\n        #     for triNP in self.triNPs:\n        #         triNP.hide()\n        #         continue\n        #     self.showing = \'start\'\n        #     pass\n            \n        \n        # The collision handler collects the collisions. We dispatch which function\n        # to handle the collision based on the name of what was collided into\n\n\n        self.ballGroundMap = {}\n        for i in range(self.cHandler.getNumEntries()):\n            entry = self.cHandler.getEntry(i)\n            ballName = entry.getFromNode().getName()\n            groundName = entry.getIntoNode().getName()            \n            if \'ball_ray_\' not in ballName:\n                continue\n            if \'ground_\' not in groundName:\n                continue\n            ballIndex = int(ballName[9:])\n            groundIndex = int(groundName[7:])\n            norm = -entry.getSurfaceNormal(render)\n            if norm.length() == 0:\n                continue\n            norm = norm / norm.length()            \n            distance = norm.dot(entry.getSurfacePoint(render) - self.ballRoots[ballIndex].getPos())\n            #print(distance)\n            if distance < 0:\n                continue\n            if ballIndex not in self.ballGroundMap or distance < self.ballGroundMap[ballIndex][1]:\n                self.ballGroundMap[ballIndex] = (groundIndex, distance)\n                pass\n            continue\n        \n        for i in range(self.cHandler.getNumEntries()):\n            entry = self.cHandler.getEntry(i)\n            fromName = entry.getFromNode().getName()\n            #if \'mouseRay\' in fromName:\n            #continue\n            name = entry.getIntoNode().getName()            \n            #if name == ""plane_collide"":\n            if \'tri_\' in name:\n                self.planeCollideHandler(entry)\n            #elif name == ""wall_collide"":\n            #self.wallCollideHandler(entry)\n            #elif name == ""ground_collide"":\n            #self.groundCollideHandler(entry)\n            elif \'ball_\' in name:\n                self.ballCollideHandler(entry)\n            elif \'ground_\' in name:\n                self.groundCollideHandler(entry)\n            elif \'hole\' in name:\n                self.score(entry)\n            elif \'portal_\' in name:\n                self.portal(entry)\n                pass\n            continue\n\n        # Read the mouse position and tilt the maze accordingly\n        if base.mouseWatcherNode.hasMouse():\n            mpos = base.mouseWatcherNode.getMouse()  # get the mouse position\n            #self.maze.setP(mpos.getY() * -10)\n            #self.maze.setR(mpos.getX() * 10)\n            pass\n\n        # if base.mouseWatcherNode.is_button_down(\'mouse1\'):\n        #     print(base.mouseWatcherNode.getMouseX())\n        #     print(base.mouseWatcherNode.getMouseY())            \n        #     exit(1)\n            \n        # Finally, we move the ball\n        # Update the velocity based on acceleration\n        for ballIndex in xrange(len(self.balls)):\n            if self.ballVs[ballIndex].length() < 1e-4 and self.ballVs[ballIndex].dot(self.accelVs[ballIndex]) < -1e-4:\n                self.ballVs[ballIndex] = LVector3(0, 0, 0)\n                self.accelVs[ballIndex] = LVector3(0, 0, 0)\n            else:\n                self.ballVs[ballIndex] += self.accelVs[ballIndex] * dt * ACCEL\n                pass\n            #print(\'current speed\', self.ballVs[ballIndex], self.accelVs[ballIndex])\n            # Clamp the velocity to the maximum speed\n            if self.ballVs[ballIndex].lengthSquared() > MAX_SPEED_SQ:\n                self.ballVs[ballIndex].normalize()\n                self.ballVs[ballIndex] *= MAX_SPEED\n                pass\n            #print(self.ballVs[ballIndex], self.accelVs[ballIndex], self.ballRoots[ballIndex].getPos())\n            \n            # Update the position based on the velocity\n            self.ballRoots[ballIndex].setPos(self.ballRoots[ballIndex].getPos() + (self.ballVs[ballIndex] * dt))\n\n            # This block of code rotates the ball. It uses something called a quaternion\n            # to rotate the ball around an arbitrary axis. That axis perpendicular to\n            # the balls rotation, and the amount has to do with the size of the ball\n            # This is multiplied on the previous rotation to incrimentally turn it.\n            prevRot = LRotationf(self.balls[ballIndex].getQuat())\n            axis = LVector3.up().cross(self.ballVs[ballIndex])\n            newRot = LRotationf(axis, np.rad2deg(dt * self.ballVs[ballIndex].length() / self.ballSize))\n            self.balls[ballIndex].setQuat(prevRot * newRot)\n            continue\n\n        self.cueRoot.setPos(self.cuePos[0], self.cuePos[1], self.cuePos[2])\n        return Task.cont       # Continue the task indefinitely\n\n    def score(self, colEntry):\n        ballName = colEntry.getFromNode().getName()\n        if \'ball_\' not in ballName:\n            return\n        print(\'score\', ballName)\n        ballIndex = int(ballName[5:])\n        self.ballRoots[ballIndex].removeNode()\n\n        del self.ballRoots[ballIndex]\n        del self.balls[ballIndex]\n        del self.ballSpheres[ballIndex]\n        del self.ballGroundRays[ballIndex]        \n        del self.ballVs[ballIndex]\n        del self.accelVs[ballIndex]\n        for otherIndex in xrange(ballIndex, len(self.balls)):\n            self.ballSpheres[otherIndex].setName(\'ball_\' + str(otherIndex))\n            self.ballGroundRays[otherIndex].setName(\'ball_ray_\' + str(otherIndex))\n            continue\n        return\n        \n    # If the ball hits a hole trigger, then it should fall in the hole.\n    # This is faked rather than dealing with the actual physics of it.\n    def loseGame(self, entry):\n        # The triggers are set up so that the center of the ball should move to the\n        # collision point to be in the hole\n        toPos = entry.getInteriorPoint(render)\n        taskMgr.remove(\'rollTask\')  # Stop the maze task\n\n        # Move the ball into the hole over a short sequence of time. Then wait a\n        # second and call start to reset the game\n        Sequence(\n            Parallel(\n                LerpFunc(self.ballRoot.setX, fromData=self.ballRoot.getX(),\n                         toData=toPos.getX(), duration=.1),\n                LerpFunc(self.ballRoot.setY, fromData=self.ballRoot.getY(),\n                         toData=toPos.getY(), duration=.1),\n                LerpFunc(self.ballRoot.setZ, fromData=self.ballRoot.getZ(),\n                         toData=self.ballRoot.getZ() - .9, duration=.2)),\n            Wait(1),\n            Func(self.start)).start()\n\n# Finally, create an instance of our class and start 3d rendering\ndemo = BallInMazeDemo()\ndemo.run()\n    \n\n            \n'"
kaffe/caffe/__init__.py,0,"b'from .resolver import get_caffe_resolver, has_pycaffe\n'"
kaffe/caffe/caffepb.py,0,"b'# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: caffe.proto\n\nfrom google.protobuf.internal import enum_type_wrapper\nfrom google.protobuf import descriptor as _descriptor\nfrom google.protobuf import message as _message\nfrom google.protobuf import reflection as _reflection\nfrom google.protobuf import descriptor_pb2\n# @@protoc_insertion_point(imports)\n\n\n\n\nDESCRIPTOR = _descriptor.FileDescriptor(\n  name=\'caffe.proto\',\n  package=\'caffe\',\n  serialized_pb=\'\\n\\x0b\\x63\\x61\\x66\\x66\\x65.proto\\x12\\x05\\x63\\x61\\x66\\x66\\x65\\""\\x1c\\n\\tBlobShape\\x12\\x0f\\n\\x03\\x64im\\x18\\x01 \\x03(\\x03\\x42\\x02\\x10\\x01\\""\\xcc\\x01\\n\\tBlobProto\\x12\\x1f\\n\\x05shape\\x18\\x07 \\x01(\\x0b\\x32\\x10.caffe.BlobShape\\x12\\x10\\n\\x04\\x64\\x61ta\\x18\\x05 \\x03(\\x02\\x42\\x02\\x10\\x01\\x12\\x10\\n\\x04\\x64iff\\x18\\x06 \\x03(\\x02\\x42\\x02\\x10\\x01\\x12\\x17\\n\\x0b\\x64ouble_data\\x18\\x08 \\x03(\\x01\\x42\\x02\\x10\\x01\\x12\\x17\\n\\x0b\\x64ouble_diff\\x18\\t \\x03(\\x01\\x42\\x02\\x10\\x01\\x12\\x0e\\n\\x03num\\x18\\x01 \\x01(\\x05:\\x01\\x30\\x12\\x13\\n\\x08\\x63hannels\\x18\\x02 \\x01(\\x05:\\x01\\x30\\x12\\x11\\n\\x06height\\x18\\x03 \\x01(\\x05:\\x01\\x30\\x12\\x10\\n\\x05width\\x18\\x04 \\x01(\\x05:\\x01\\x30\\""2\\n\\x0f\\x42lobProtoVector\\x12\\x1f\\n\\x05\\x62lobs\\x18\\x01 \\x03(\\x0b\\x32\\x10.caffe.BlobProto\\""\\x81\\x01\\n\\x05\\x44\\x61tum\\x12\\x10\\n\\x08\\x63hannels\\x18\\x01 \\x01(\\x05\\x12\\x0e\\n\\x06height\\x18\\x02 \\x01(\\x05\\x12\\r\\n\\x05width\\x18\\x03 \\x01(\\x05\\x12\\x0c\\n\\x04\\x64\\x61ta\\x18\\x04 \\x01(\\x0c\\x12\\r\\n\\x05label\\x18\\x05 \\x01(\\x05\\x12\\x12\\n\\nfloat_data\\x18\\x06 \\x03(\\x02\\x12\\x16\\n\\x07\\x65ncoded\\x18\\x07 \\x01(\\x08:\\x05\\x66\\x61lse\\""\\x8a\\x02\\n\\x0f\\x46illerParameter\\x12\\x16\\n\\x04type\\x18\\x01 \\x01(\\t:\\x08\\x63onstant\\x12\\x10\\n\\x05value\\x18\\x02 \\x01(\\x02:\\x01\\x30\\x12\\x0e\\n\\x03min\\x18\\x03 \\x01(\\x02:\\x01\\x30\\x12\\x0e\\n\\x03max\\x18\\x04 \\x01(\\x02:\\x01\\x31\\x12\\x0f\\n\\x04mean\\x18\\x05 \\x01(\\x02:\\x01\\x30\\x12\\x0e\\n\\x03std\\x18\\x06 \\x01(\\x02:\\x01\\x31\\x12\\x12\\n\\x06sparse\\x18\\x07 \\x01(\\x05:\\x02-1\\x12\\x42\\n\\rvariance_norm\\x18\\x08 \\x01(\\x0e\\x32#.caffe.FillerParameter.VarianceNorm:\\x06\\x46\\x41N_IN\\""4\\n\\x0cVarianceNorm\\x12\\n\\n\\x06\\x46\\x41N_IN\\x10\\x00\\x12\\x0b\\n\\x07\\x46\\x41N_OUT\\x10\\x01\\x12\\x0b\\n\\x07\\x41VERAGE\\x10\\x02\\""\\x8e\\x02\\n\\x0cNetParameter\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12\\r\\n\\x05input\\x18\\x03 \\x03(\\t\\x12%\\n\\x0binput_shape\\x18\\x08 \\x03(\\x0b\\x32\\x10.caffe.BlobShape\\x12\\x11\\n\\tinput_dim\\x18\\x04 \\x03(\\x05\\x12\\x1d\\n\\x0e\\x66orce_backward\\x18\\x05 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x1e\\n\\x05state\\x18\\x06 \\x01(\\x0b\\x32\\x0f.caffe.NetState\\x12\\x19\\n\\ndebug_info\\x18\\x07 \\x01(\\x08:\\x05\\x66\\x61lse\\x12$\\n\\x05layer\\x18\\x64 \\x03(\\x0b\\x32\\x15.caffe.LayerParameter\\x12\\\'\\n\\x06layers\\x18\\x02 \\x03(\\x0b\\x32\\x17.caffe.V1LayerParameter\\""\\x9c\\n\\n\\x0fSolverParameter\\x12\\x0b\\n\\x03net\\x18\\x18 \\x01(\\t\\x12&\\n\\tnet_param\\x18\\x19 \\x01(\\x0b\\x32\\x13.caffe.NetParameter\\x12\\x11\\n\\ttrain_net\\x18\\x01 \\x01(\\t\\x12\\x10\\n\\x08test_net\\x18\\x02 \\x03(\\t\\x12,\\n\\x0ftrain_net_param\\x18\\x15 \\x01(\\x0b\\x32\\x13.caffe.NetParameter\\x12+\\n\\x0etest_net_param\\x18\\x16 \\x03(\\x0b\\x32\\x13.caffe.NetParameter\\x12$\\n\\x0btrain_state\\x18\\x1a \\x01(\\x0b\\x32\\x0f.caffe.NetState\\x12#\\n\\ntest_state\\x18\\x1b \\x03(\\x0b\\x32\\x0f.caffe.NetState\\x12\\x11\\n\\ttest_iter\\x18\\x03 \\x03(\\x05\\x12\\x18\\n\\rtest_interval\\x18\\x04 \\x01(\\x05:\\x01\\x30\\x12 \\n\\x11test_compute_loss\\x18\\x13 \\x01(\\x08:\\x05\\x66\\x61lse\\x12!\\n\\x13test_initialization\\x18  \\x01(\\x08:\\x04true\\x12\\x0f\\n\\x07\\x62\\x61se_lr\\x18\\x05 \\x01(\\x02\\x12\\x0f\\n\\x07\\x64isplay\\x18\\x06 \\x01(\\x05\\x12\\x17\\n\\x0c\\x61verage_loss\\x18! \\x01(\\x05:\\x01\\x31\\x12\\x10\\n\\x08max_iter\\x18\\x07 \\x01(\\x05\\x12\\x14\\n\\titer_size\\x18$ \\x01(\\x05:\\x01\\x31\\x12\\x11\\n\\tlr_policy\\x18\\x08 \\x01(\\t\\x12\\r\\n\\x05gamma\\x18\\t \\x01(\\x02\\x12\\r\\n\\x05power\\x18\\n \\x01(\\x02\\x12\\x10\\n\\x08momentum\\x18\\x0b \\x01(\\x02\\x12\\x14\\n\\x0cweight_decay\\x18\\x0c \\x01(\\x02\\x12\\x1f\\n\\x13regularization_type\\x18\\x1d \\x01(\\t:\\x02L2\\x12\\x10\\n\\x08stepsize\\x18\\r \\x01(\\x05\\x12\\x11\\n\\tstepvalue\\x18\\"" \\x03(\\x05\\x12\\x1a\\n\\x0e\\x63lip_gradients\\x18# \\x01(\\x02:\\x02-1\\x12\\x13\\n\\x08snapshot\\x18\\x0e \\x01(\\x05:\\x01\\x30\\x12\\x17\\n\\x0fsnapshot_prefix\\x18\\x0f \\x01(\\t\\x12\\x1c\\n\\rsnapshot_diff\\x18\\x10 \\x01(\\x08:\\x05\\x66\\x61lse\\x12K\\n\\x0fsnapshot_format\\x18% \\x01(\\x0e\\x32%.caffe.SolverParameter.SnapshotFormat:\\x0b\\x42INARYPROTO\\x12;\\n\\x0bsolver_mode\\x18\\x11 \\x01(\\x0e\\x32!.caffe.SolverParameter.SolverMode:\\x03GPU\\x12\\x14\\n\\tdevice_id\\x18\\x12 \\x01(\\x05:\\x01\\x30\\x12\\x17\\n\\x0brandom_seed\\x18\\x14 \\x01(\\x03:\\x02-1\\x12\\x11\\n\\x04type\\x18( \\x01(\\t:\\x03SGD\\x12\\x14\\n\\x05\\x64\\x65lta\\x18\\x1f \\x01(\\x02:\\x05\\x31\\x65-08\\x12\\x18\\n\\tmomentum2\\x18\\\' \\x01(\\x02:\\x05\\x30.999\\x12\\x11\\n\\trms_decay\\x18& \\x01(\\x02\\x12\\x19\\n\\ndebug_info\\x18\\x17 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\""\\n\\x14snapshot_after_train\\x18\\x1c \\x01(\\x08:\\x04true\\x12;\\n\\x0bsolver_type\\x18\\x1e \\x01(\\x0e\\x32!.caffe.SolverParameter.SolverType:\\x03SGD\\""+\\n\\x0eSnapshotFormat\\x12\\x08\\n\\x04HDF5\\x10\\x00\\x12\\x0f\\n\\x0b\\x42INARYPROTO\\x10\\x01\\""\\x1e\\n\\nSolverMode\\x12\\x07\\n\\x03\\x43PU\\x10\\x00\\x12\\x07\\n\\x03GPU\\x10\\x01\\""U\\n\\nSolverType\\x12\\x07\\n\\x03SGD\\x10\\x00\\x12\\x0c\\n\\x08NESTEROV\\x10\\x01\\x12\\x0b\\n\\x07\\x41\\x44\\x41GRAD\\x10\\x02\\x12\\x0b\\n\\x07RMSPROP\\x10\\x03\\x12\\x0c\\n\\x08\\x41\\x44\\x41\\x44\\x45LTA\\x10\\x04\\x12\\x08\\n\\x04\\x41\\x44\\x41M\\x10\\x05\\""l\\n\\x0bSolverState\\x12\\x0c\\n\\x04iter\\x18\\x01 \\x01(\\x05\\x12\\x13\\n\\x0blearned_net\\x18\\x02 \\x01(\\t\\x12!\\n\\x07history\\x18\\x03 \\x03(\\x0b\\x32\\x10.caffe.BlobProto\\x12\\x17\\n\\x0c\\x63urrent_step\\x18\\x04 \\x01(\\x05:\\x01\\x30\\""N\\n\\x08NetState\\x12!\\n\\x05phase\\x18\\x01 \\x01(\\x0e\\x32\\x0c.caffe.Phase:\\x04TEST\\x12\\x10\\n\\x05level\\x18\\x02 \\x01(\\x05:\\x01\\x30\\x12\\r\\n\\x05stage\\x18\\x03 \\x03(\\t\\""s\\n\\x0cNetStateRule\\x12\\x1b\\n\\x05phase\\x18\\x01 \\x01(\\x0e\\x32\\x0c.caffe.Phase\\x12\\x11\\n\\tmin_level\\x18\\x02 \\x01(\\x05\\x12\\x11\\n\\tmax_level\\x18\\x03 \\x01(\\x05\\x12\\r\\n\\x05stage\\x18\\x04 \\x03(\\t\\x12\\x11\\n\\tnot_stage\\x18\\x05 \\x03(\\t\\""\\xa3\\x01\\n\\tParamSpec\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12\\x31\\n\\nshare_mode\\x18\\x02 \\x01(\\x0e\\x32\\x1d.caffe.ParamSpec.DimCheckMode\\x12\\x12\\n\\x07lr_mult\\x18\\x03 \\x01(\\x02:\\x01\\x31\\x12\\x15\\n\\ndecay_mult\\x18\\x04 \\x01(\\x02:\\x01\\x31\\""*\\n\\x0c\\x44imCheckMode\\x12\\n\\n\\x06STRICT\\x10\\x00\\x12\\x0e\\n\\nPERMISSIVE\\x10\\x01\\""\\x98\\x13\\n\\x0eLayerParameter\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12\\x0c\\n\\x04type\\x18\\x02 \\x01(\\t\\x12\\x0e\\n\\x06\\x62ottom\\x18\\x03 \\x03(\\t\\x12\\x0b\\n\\x03top\\x18\\x04 \\x03(\\t\\x12\\x1b\\n\\x05phase\\x18\\n \\x01(\\x0e\\x32\\x0c.caffe.Phase\\x12\\x13\\n\\x0bloss_weight\\x18\\x05 \\x03(\\x02\\x12\\x1f\\n\\x05param\\x18\\x06 \\x03(\\x0b\\x32\\x10.caffe.ParamSpec\\x12\\x1f\\n\\x05\\x62lobs\\x18\\x07 \\x03(\\x0b\\x32\\x10.caffe.BlobProto\\x12\\x16\\n\\x0epropagate_down\\x18\\x0b \\x03(\\x08\\x12$\\n\\x07include\\x18\\x08 \\x03(\\x0b\\x32\\x13.caffe.NetStateRule\\x12$\\n\\x07\\x65xclude\\x18\\t \\x03(\\x0b\\x32\\x13.caffe.NetStateRule\\x12\\x37\\n\\x0ftransform_param\\x18\\x64 \\x01(\\x0b\\x32\\x1e.caffe.TransformationParameter\\x12(\\n\\nloss_param\\x18\\x65 \\x01(\\x0b\\x32\\x14.caffe.LossParameter\\x12\\x30\\n\\x0e\\x61\\x63\\x63uracy_param\\x18\\x66 \\x01(\\x0b\\x32\\x18.caffe.AccuracyParameter\\x12,\\n\\x0c\\x61rgmax_param\\x18g \\x01(\\x0b\\x32\\x16.caffe.ArgMaxParameter\\x12\\x34\\n\\x10\\x62\\x61tch_norm_param\\x18\\x8b\\x01 \\x01(\\x0b\\x32\\x19.caffe.BatchNormParameter\\x12)\\n\\nbias_param\\x18\\x8d\\x01 \\x01(\\x0b\\x32\\x14.caffe.BiasParameter\\x12,\\n\\x0c\\x63oncat_param\\x18h \\x01(\\x0b\\x32\\x16.caffe.ConcatParameter\\x12?\\n\\x16\\x63ontrastive_loss_param\\x18i \\x01(\\x0b\\x32\\x1f.caffe.ContrastiveLossParameter\\x12\\x36\\n\\x11\\x63onvolution_param\\x18j \\x01(\\x0b\\x32\\x1b.caffe.ConvolutionParameter\\x12)\\n\\ncrop_param\\x18\\x90\\x01 \\x01(\\x0b\\x32\\x14.caffe.CropParameter\\x12(\\n\\ndata_param\\x18k \\x01(\\x0b\\x32\\x14.caffe.DataParameter\\x12.\\n\\rdropout_param\\x18l \\x01(\\x0b\\x32\\x17.caffe.DropoutParameter\\x12\\x33\\n\\x10\\x64ummy_data_param\\x18m \\x01(\\x0b\\x32\\x19.caffe.DummyDataParameter\\x12.\\n\\reltwise_param\\x18n \\x01(\\x0b\\x32\\x17.caffe.EltwiseParameter\\x12\\\'\\n\\telu_param\\x18\\x8c\\x01 \\x01(\\x0b\\x32\\x13.caffe.ELUParameter\\x12+\\n\\x0b\\x65mbed_param\\x18\\x89\\x01 \\x01(\\x0b\\x32\\x15.caffe.EmbedParameter\\x12&\\n\\texp_param\\x18o \\x01(\\x0b\\x32\\x13.caffe.ExpParameter\\x12/\\n\\rflatten_param\\x18\\x87\\x01 \\x01(\\x0b\\x32\\x17.caffe.FlattenParameter\\x12\\x31\\n\\x0fhdf5_data_param\\x18p \\x01(\\x0b\\x32\\x18.caffe.HDF5DataParameter\\x12\\x35\\n\\x11hdf5_output_param\\x18q \\x01(\\x0b\\x32\\x1a.caffe.HDF5OutputParameter\\x12\\x33\\n\\x10hinge_loss_param\\x18r \\x01(\\x0b\\x32\\x19.caffe.HingeLossParameter\\x12\\x33\\n\\x10image_data_param\\x18s \\x01(\\x0b\\x32\\x19.caffe.ImageDataParameter\\x12\\x39\\n\\x13infogain_loss_param\\x18t \\x01(\\x0b\\x32\\x1c.caffe.InfogainLossParameter\\x12\\x39\\n\\x13inner_product_param\\x18u \\x01(\\x0b\\x32\\x1c.caffe.InnerProductParameter\\x12+\\n\\x0binput_param\\x18\\x8f\\x01 \\x01(\\x0b\\x32\\x15.caffe.InputParameter\\x12\\\'\\n\\tlog_param\\x18\\x86\\x01 \\x01(\\x0b\\x32\\x13.caffe.LogParameter\\x12&\\n\\tlrn_param\\x18v \\x01(\\x0b\\x32\\x13.caffe.LRNParameter\\x12\\x35\\n\\x11memory_data_param\\x18w \\x01(\\x0b\\x32\\x1a.caffe.MemoryDataParameter\\x12&\\n\\tmvn_param\\x18x \\x01(\\x0b\\x32\\x13.caffe.MVNParameter\\x12.\\n\\rpooling_param\\x18y \\x01(\\x0b\\x32\\x17.caffe.PoolingParameter\\x12*\\n\\x0bpower_param\\x18z \\x01(\\x0b\\x32\\x15.caffe.PowerParameter\\x12+\\n\\x0bprelu_param\\x18\\x83\\x01 \\x01(\\x0b\\x32\\x15.caffe.PReLUParameter\\x12-\\n\\x0cpython_param\\x18\\x82\\x01 \\x01(\\x0b\\x32\\x16.caffe.PythonParameter\\x12\\x33\\n\\x0freduction_param\\x18\\x88\\x01 \\x01(\\x0b\\x32\\x19.caffe.ReductionParameter\\x12(\\n\\nrelu_param\\x18{ \\x01(\\x0b\\x32\\x14.caffe.ReLUParameter\\x12/\\n\\rreshape_param\\x18\\x85\\x01 \\x01(\\x0b\\x32\\x17.caffe.ReshapeParameter\\x12+\\n\\x0bscale_param\\x18\\x8e\\x01 \\x01(\\x0b\\x32\\x15.caffe.ScaleParameter\\x12.\\n\\rsigmoid_param\\x18| \\x01(\\x0b\\x32\\x17.caffe.SigmoidParameter\\x12.\\n\\rsoftmax_param\\x18} \\x01(\\x0b\\x32\\x17.caffe.SoftmaxParameter\\x12\\\'\\n\\tspp_param\\x18\\x84\\x01 \\x01(\\x0b\\x32\\x13.caffe.SPPParameter\\x12*\\n\\x0bslice_param\\x18~ \\x01(\\x0b\\x32\\x15.caffe.SliceParameter\\x12(\\n\\ntanh_param\\x18\\x7f \\x01(\\x0b\\x32\\x14.caffe.TanHParameter\\x12\\x33\\n\\x0fthreshold_param\\x18\\x80\\x01 \\x01(\\x0b\\x32\\x19.caffe.ThresholdParameter\\x12)\\n\\ntile_param\\x18\\x8a\\x01 \\x01(\\x0b\\x32\\x14.caffe.TileParameter\\x12\\x36\\n\\x11window_data_param\\x18\\x81\\x01 \\x01(\\x0b\\x32\\x1a.caffe.WindowDataParameter\\""\\xb6\\x01\\n\\x17TransformationParameter\\x12\\x10\\n\\x05scale\\x18\\x01 \\x01(\\x02:\\x01\\x31\\x12\\x15\\n\\x06mirror\\x18\\x02 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x14\\n\\tcrop_size\\x18\\x03 \\x01(\\r:\\x01\\x30\\x12\\x11\\n\\tmean_file\\x18\\x04 \\x01(\\t\\x12\\x12\\n\\nmean_value\\x18\\x05 \\x03(\\x02\\x12\\x1a\\n\\x0b\\x66orce_color\\x18\\x06 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x19\\n\\nforce_gray\\x18\\x07 \\x01(\\x08:\\x05\\x66\\x61lse\\""\\xc2\\x01\\n\\rLossParameter\\x12\\x14\\n\\x0cignore_label\\x18\\x01 \\x01(\\x05\\x12\\x44\\n\\rnormalization\\x18\\x03 \\x01(\\x0e\\x32&.caffe.LossParameter.NormalizationMode:\\x05VALID\\x12\\x11\\n\\tnormalize\\x18\\x02 \\x01(\\x08\\""B\\n\\x11NormalizationMode\\x12\\x08\\n\\x04\\x46ULL\\x10\\x00\\x12\\t\\n\\x05VALID\\x10\\x01\\x12\\x0e\\n\\nBATCH_SIZE\\x10\\x02\\x12\\x08\\n\\x04NONE\\x10\\x03\\""L\\n\\x11\\x41\\x63\\x63uracyParameter\\x12\\x10\\n\\x05top_k\\x18\\x01 \\x01(\\r:\\x01\\x31\\x12\\x0f\\n\\x04\\x61xis\\x18\\x02 \\x01(\\x05:\\x01\\x31\\x12\\x14\\n\\x0cignore_label\\x18\\x03 \\x01(\\x05\\""M\\n\\x0f\\x41rgMaxParameter\\x12\\x1a\\n\\x0bout_max_val\\x18\\x01 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x10\\n\\x05top_k\\x18\\x02 \\x01(\\r:\\x01\\x31\\x12\\x0c\\n\\x04\\x61xis\\x18\\x03 \\x01(\\x05\\""9\\n\\x0f\\x43oncatParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x02 \\x01(\\x05:\\x01\\x31\\x12\\x15\\n\\nconcat_dim\\x18\\x01 \\x01(\\r:\\x01\\x31\\""j\\n\\x12\\x42\\x61tchNormParameter\\x12\\x18\\n\\x10use_global_stats\\x18\\x01 \\x01(\\x08\\x12&\\n\\x17moving_average_fraction\\x18\\x02 \\x01(\\x02:\\x05\\x30.999\\x12\\x12\\n\\x03\\x65ps\\x18\\x03 \\x01(\\x02:\\x05\\x31\\x65-05\\""]\\n\\rBiasParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x01 \\x01(\\x05:\\x01\\x31\\x12\\x13\\n\\x08num_axes\\x18\\x02 \\x01(\\x05:\\x01\\x31\\x12&\\n\\x06\\x66iller\\x18\\x03 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\""L\\n\\x18\\x43ontrastiveLossParameter\\x12\\x11\\n\\x06margin\\x18\\x01 \\x01(\\x02:\\x01\\x31\\x12\\x1d\\n\\x0elegacy_version\\x18\\x02 \\x01(\\x08:\\x05\\x66\\x61lse\\""\\xfc\\x03\\n\\x14\\x43onvolutionParameter\\x12\\x12\\n\\nnum_output\\x18\\x01 \\x01(\\r\\x12\\x17\\n\\tbias_term\\x18\\x02 \\x01(\\x08:\\x04true\\x12\\x0b\\n\\x03pad\\x18\\x03 \\x03(\\r\\x12\\x13\\n\\x0bkernel_size\\x18\\x04 \\x03(\\r\\x12\\x0e\\n\\x06stride\\x18\\x06 \\x03(\\r\\x12\\x10\\n\\x08\\x64ilation\\x18\\x12 \\x03(\\r\\x12\\x10\\n\\x05pad_h\\x18\\t \\x01(\\r:\\x01\\x30\\x12\\x10\\n\\x05pad_w\\x18\\n \\x01(\\r:\\x01\\x30\\x12\\x10\\n\\x08kernel_h\\x18\\x0b \\x01(\\r\\x12\\x10\\n\\x08kernel_w\\x18\\x0c \\x01(\\r\\x12\\x10\\n\\x08stride_h\\x18\\r \\x01(\\r\\x12\\x10\\n\\x08stride_w\\x18\\x0e \\x01(\\r\\x12\\x10\\n\\x05group\\x18\\x05 \\x01(\\r:\\x01\\x31\\x12-\\n\\rweight_filler\\x18\\x07 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12+\\n\\x0b\\x62ias_filler\\x18\\x08 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12;\\n\\x06\\x65ngine\\x18\\x0f \\x01(\\x0e\\x32\\"".caffe.ConvolutionParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\x12\\x0f\\n\\x04\\x61xis\\x18\\x10 \\x01(\\x05:\\x01\\x31\\x12\\x1e\\n\\x0f\\x66orce_nd_im2col\\x18\\x11 \\x01(\\x08:\\x05\\x66\\x61lse\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""0\\n\\rCropParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x01 \\x01(\\x05:\\x01\\x32\\x12\\x0e\\n\\x06offset\\x18\\x02 \\x03(\\r\\""\\xa4\\x02\\n\\rDataParameter\\x12\\x0e\\n\\x06source\\x18\\x01 \\x01(\\t\\x12\\x12\\n\\nbatch_size\\x18\\x04 \\x01(\\r\\x12\\x14\\n\\trand_skip\\x18\\x07 \\x01(\\r:\\x01\\x30\\x12\\x31\\n\\x07\\x62\\x61\\x63kend\\x18\\x08 \\x01(\\x0e\\x32\\x17.caffe.DataParameter.DB:\\x07LEVELDB\\x12\\x10\\n\\x05scale\\x18\\x02 \\x01(\\x02:\\x01\\x31\\x12\\x11\\n\\tmean_file\\x18\\x03 \\x01(\\t\\x12\\x14\\n\\tcrop_size\\x18\\x05 \\x01(\\r:\\x01\\x30\\x12\\x15\\n\\x06mirror\\x18\\x06 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\""\\n\\x13\\x66orce_encoded_color\\x18\\t \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x13\\n\\x08prefetch\\x18\\n \\x01(\\r:\\x01\\x34\\""\\x1b\\n\\x02\\x44\\x42\\x12\\x0b\\n\\x07LEVELDB\\x10\\x00\\x12\\x08\\n\\x04LMDB\\x10\\x01\\"".\\n\\x10\\x44ropoutParameter\\x12\\x1a\\n\\rdropout_ratio\\x18\\x01 \\x01(\\x02:\\x03\\x30.5\\""\\xa0\\x01\\n\\x12\\x44ummyDataParameter\\x12+\\n\\x0b\\x64\\x61ta_filler\\x18\\x01 \\x03(\\x0b\\x32\\x16.caffe.FillerParameter\\x12\\x1f\\n\\x05shape\\x18\\x06 \\x03(\\x0b\\x32\\x10.caffe.BlobShape\\x12\\x0b\\n\\x03num\\x18\\x02 \\x03(\\r\\x12\\x10\\n\\x08\\x63hannels\\x18\\x03 \\x03(\\r\\x12\\x0e\\n\\x06height\\x18\\x04 \\x03(\\r\\x12\\r\\n\\x05width\\x18\\x05 \\x03(\\r\\""\\xa5\\x01\\n\\x10\\x45ltwiseParameter\\x12\\x39\\n\\toperation\\x18\\x01 \\x01(\\x0e\\x32!.caffe.EltwiseParameter.EltwiseOp:\\x03SUM\\x12\\r\\n\\x05\\x63oeff\\x18\\x02 \\x03(\\x02\\x12\\x1e\\n\\x10stable_prod_grad\\x18\\x03 \\x01(\\x08:\\x04true\\""\\\'\\n\\tEltwiseOp\\x12\\x08\\n\\x04PROD\\x10\\x00\\x12\\x07\\n\\x03SUM\\x10\\x01\\x12\\x07\\n\\x03MAX\\x10\\x02\\"" \\n\\x0c\\x45LUParameter\\x12\\x10\\n\\x05\\x61lpha\\x18\\x01 \\x01(\\x02:\\x01\\x31\\""\\xac\\x01\\n\\x0e\\x45mbedParameter\\x12\\x12\\n\\nnum_output\\x18\\x01 \\x01(\\r\\x12\\x11\\n\\tinput_dim\\x18\\x02 \\x01(\\r\\x12\\x17\\n\\tbias_term\\x18\\x03 \\x01(\\x08:\\x04true\\x12-\\n\\rweight_filler\\x18\\x04 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12+\\n\\x0b\\x62ias_filler\\x18\\x05 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\""D\\n\\x0c\\x45xpParameter\\x12\\x10\\n\\x04\\x62\\x61se\\x18\\x01 \\x01(\\x02:\\x02-1\\x12\\x10\\n\\x05scale\\x18\\x02 \\x01(\\x02:\\x01\\x31\\x12\\x10\\n\\x05shift\\x18\\x03 \\x01(\\x02:\\x01\\x30\\""9\\n\\x10\\x46lattenParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x01 \\x01(\\x05:\\x01\\x31\\x12\\x14\\n\\x08\\x65nd_axis\\x18\\x02 \\x01(\\x05:\\x02-1\\""O\\n\\x11HDF5DataParameter\\x12\\x0e\\n\\x06source\\x18\\x01 \\x01(\\t\\x12\\x12\\n\\nbatch_size\\x18\\x02 \\x01(\\r\\x12\\x16\\n\\x07shuffle\\x18\\x03 \\x01(\\x08:\\x05\\x66\\x61lse\\""(\\n\\x13HDF5OutputParameter\\x12\\x11\\n\\tfile_name\\x18\\x01 \\x01(\\t\\""^\\n\\x12HingeLossParameter\\x12\\x30\\n\\x04norm\\x18\\x01 \\x01(\\x0e\\x32\\x1e.caffe.HingeLossParameter.Norm:\\x02L1\\""\\x16\\n\\x04Norm\\x12\\x06\\n\\x02L1\\x10\\x01\\x12\\x06\\n\\x02L2\\x10\\x02\\""\\x97\\x02\\n\\x12ImageDataParameter\\x12\\x0e\\n\\x06source\\x18\\x01 \\x01(\\t\\x12\\x15\\n\\nbatch_size\\x18\\x04 \\x01(\\r:\\x01\\x31\\x12\\x14\\n\\trand_skip\\x18\\x07 \\x01(\\r:\\x01\\x30\\x12\\x16\\n\\x07shuffle\\x18\\x08 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x15\\n\\nnew_height\\x18\\t \\x01(\\r:\\x01\\x30\\x12\\x14\\n\\tnew_width\\x18\\n \\x01(\\r:\\x01\\x30\\x12\\x16\\n\\x08is_color\\x18\\x0b \\x01(\\x08:\\x04true\\x12\\x10\\n\\x05scale\\x18\\x02 \\x01(\\x02:\\x01\\x31\\x12\\x11\\n\\tmean_file\\x18\\x03 \\x01(\\t\\x12\\x14\\n\\tcrop_size\\x18\\x05 \\x01(\\r:\\x01\\x30\\x12\\x15\\n\\x06mirror\\x18\\x06 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x15\\n\\x0broot_folder\\x18\\x0c \\x01(\\t:\\x00\\""\\\'\\n\\x15InfogainLossParameter\\x12\\x0e\\n\\x06source\\x18\\x01 \\x01(\\t\\""\\xcb\\x01\\n\\x15InnerProductParameter\\x12\\x12\\n\\nnum_output\\x18\\x01 \\x01(\\r\\x12\\x17\\n\\tbias_term\\x18\\x02 \\x01(\\x08:\\x04true\\x12-\\n\\rweight_filler\\x18\\x03 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12+\\n\\x0b\\x62ias_filler\\x18\\x04 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x05 \\x01(\\x05:\\x01\\x31\\x12\\x18\\n\\ttranspose\\x18\\x06 \\x01(\\x08:\\x05\\x66\\x61lse\\""1\\n\\x0eInputParameter\\x12\\x1f\\n\\x05shape\\x18\\x01 \\x03(\\x0b\\x32\\x10.caffe.BlobShape\\""D\\n\\x0cLogParameter\\x12\\x10\\n\\x04\\x62\\x61se\\x18\\x01 \\x01(\\x02:\\x02-1\\x12\\x10\\n\\x05scale\\x18\\x02 \\x01(\\x02:\\x01\\x31\\x12\\x10\\n\\x05shift\\x18\\x03 \\x01(\\x02:\\x01\\x30\\""\\xb8\\x02\\n\\x0cLRNParameter\\x12\\x15\\n\\nlocal_size\\x18\\x01 \\x01(\\r:\\x01\\x35\\x12\\x10\\n\\x05\\x61lpha\\x18\\x02 \\x01(\\x02:\\x01\\x31\\x12\\x12\\n\\x04\\x62\\x65ta\\x18\\x03 \\x01(\\x02:\\x04\\x30.75\\x12\\x44\\n\\x0bnorm_region\\x18\\x04 \\x01(\\x0e\\x32\\x1e.caffe.LRNParameter.NormRegion:\\x0f\\x41\\x43ROSS_CHANNELS\\x12\\x0c\\n\\x01k\\x18\\x05 \\x01(\\x02:\\x01\\x31\\x12\\x33\\n\\x06\\x65ngine\\x18\\x06 \\x01(\\x0e\\x32\\x1a.caffe.LRNParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\""5\\n\\nNormRegion\\x12\\x13\\n\\x0f\\x41\\x43ROSS_CHANNELS\\x10\\x00\\x12\\x12\\n\\x0eWITHIN_CHANNEL\\x10\\x01\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""Z\\n\\x13MemoryDataParameter\\x12\\x12\\n\\nbatch_size\\x18\\x01 \\x01(\\r\\x12\\x10\\n\\x08\\x63hannels\\x18\\x02 \\x01(\\r\\x12\\x0e\\n\\x06height\\x18\\x03 \\x01(\\r\\x12\\r\\n\\x05width\\x18\\x04 \\x01(\\r\\""d\\n\\x0cMVNParameter\\x12 \\n\\x12normalize_variance\\x18\\x01 \\x01(\\x08:\\x04true\\x12\\x1e\\n\\x0f\\x61\\x63ross_channels\\x18\\x02 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x12\\n\\x03\\x65ps\\x18\\x03 \\x01(\\x02:\\x05\\x31\\x65-09\\""\\xa2\\x03\\n\\x10PoolingParameter\\x12\\x35\\n\\x04pool\\x18\\x01 \\x01(\\x0e\\x32\\"".caffe.PoolingParameter.PoolMethod:\\x03MAX\\x12\\x0e\\n\\x03pad\\x18\\x04 \\x01(\\r:\\x01\\x30\\x12\\x10\\n\\x05pad_h\\x18\\t \\x01(\\r:\\x01\\x30\\x12\\x10\\n\\x05pad_w\\x18\\n \\x01(\\r:\\x01\\x30\\x12\\x13\\n\\x0bkernel_size\\x18\\x02 \\x01(\\r\\x12\\x10\\n\\x08kernel_h\\x18\\x05 \\x01(\\r\\x12\\x10\\n\\x08kernel_w\\x18\\x06 \\x01(\\r\\x12\\x11\\n\\x06stride\\x18\\x03 \\x01(\\r:\\x01\\x31\\x12\\x10\\n\\x08stride_h\\x18\\x07 \\x01(\\r\\x12\\x10\\n\\x08stride_w\\x18\\x08 \\x01(\\r\\x12\\x37\\n\\x06\\x65ngine\\x18\\x0b \\x01(\\x0e\\x32\\x1e.caffe.PoolingParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\x12\\x1d\\n\\x0eglobal_pooling\\x18\\x0c \\x01(\\x08:\\x05\\x66\\x61lse\\"".\\n\\nPoolMethod\\x12\\x07\\n\\x03MAX\\x10\\x00\\x12\\x07\\n\\x03\\x41VE\\x10\\x01\\x12\\x0e\\n\\nSTOCHASTIC\\x10\\x02\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""F\\n\\x0ePowerParameter\\x12\\x10\\n\\x05power\\x18\\x01 \\x01(\\x02:\\x01\\x31\\x12\\x10\\n\\x05scale\\x18\\x02 \\x01(\\x02:\\x01\\x31\\x12\\x10\\n\\x05shift\\x18\\x03 \\x01(\\x02:\\x01\\x30\\""g\\n\\x0fPythonParameter\\x12\\x0e\\n\\x06module\\x18\\x01 \\x01(\\t\\x12\\r\\n\\x05layer\\x18\\x02 \\x01(\\t\\x12\\x13\\n\\tparam_str\\x18\\x03 \\x01(\\t:\\x00\\x12 \\n\\x11share_in_parallel\\x18\\x04 \\x01(\\x08:\\x05\\x66\\x61lse\\""\\xad\\x01\\n\\x12ReductionParameter\\x12=\\n\\toperation\\x18\\x01 \\x01(\\x0e\\x32%.caffe.ReductionParameter.ReductionOp:\\x03SUM\\x12\\x0f\\n\\x04\\x61xis\\x18\\x02 \\x01(\\x05:\\x01\\x30\\x12\\x10\\n\\x05\\x63oeff\\x18\\x03 \\x01(\\x02:\\x01\\x31\\""5\\n\\x0bReductionOp\\x12\\x07\\n\\x03SUM\\x10\\x01\\x12\\x08\\n\\x04\\x41SUM\\x10\\x02\\x12\\t\\n\\x05SUMSQ\\x10\\x03\\x12\\x08\\n\\x04MEAN\\x10\\x04\\""\\x8d\\x01\\n\\rReLUParameter\\x12\\x19\\n\\x0enegative_slope\\x18\\x01 \\x01(\\x02:\\x01\\x30\\x12\\x34\\n\\x06\\x65ngine\\x18\\x02 \\x01(\\x0e\\x32\\x1b.caffe.ReLUParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""Z\\n\\x10ReshapeParameter\\x12\\x1f\\n\\x05shape\\x18\\x01 \\x01(\\x0b\\x32\\x10.caffe.BlobShape\\x12\\x0f\\n\\x04\\x61xis\\x18\\x02 \\x01(\\x05:\\x01\\x30\\x12\\x14\\n\\x08num_axes\\x18\\x03 \\x01(\\x05:\\x02-1\\""\\xa5\\x01\\n\\x0eScaleParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x01 \\x01(\\x05:\\x01\\x31\\x12\\x13\\n\\x08num_axes\\x18\\x02 \\x01(\\x05:\\x01\\x31\\x12&\\n\\x06\\x66iller\\x18\\x03 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12\\x18\\n\\tbias_term\\x18\\x04 \\x01(\\x08:\\x05\\x66\\x61lse\\x12+\\n\\x0b\\x62ias_filler\\x18\\x05 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\""x\\n\\x10SigmoidParameter\\x12\\x37\\n\\x06\\x65ngine\\x18\\x01 \\x01(\\x0e\\x32\\x1e.caffe.SigmoidParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""L\\n\\x0eSliceParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x03 \\x01(\\x05:\\x01\\x31\\x12\\x13\\n\\x0bslice_point\\x18\\x02 \\x03(\\r\\x12\\x14\\n\\tslice_dim\\x18\\x01 \\x01(\\r:\\x01\\x31\\""\\x89\\x01\\n\\x10SoftmaxParameter\\x12\\x37\\n\\x06\\x65ngine\\x18\\x01 \\x01(\\x0e\\x32\\x1e.caffe.SoftmaxParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\x12\\x0f\\n\\x04\\x61xis\\x18\\x02 \\x01(\\x05:\\x01\\x31\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""r\\n\\rTanHParameter\\x12\\x34\\n\\x06\\x65ngine\\x18\\x01 \\x01(\\x0e\\x32\\x1b.caffe.TanHParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""/\\n\\rTileParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x01 \\x01(\\x05:\\x01\\x31\\x12\\r\\n\\x05tiles\\x18\\x02 \\x01(\\x05\\""*\\n\\x12ThresholdParameter\\x12\\x14\\n\\tthreshold\\x18\\x01 \\x01(\\x02:\\x01\\x30\\""\\xc1\\x02\\n\\x13WindowDataParameter\\x12\\x0e\\n\\x06source\\x18\\x01 \\x01(\\t\\x12\\x10\\n\\x05scale\\x18\\x02 \\x01(\\x02:\\x01\\x31\\x12\\x11\\n\\tmean_file\\x18\\x03 \\x01(\\t\\x12\\x12\\n\\nbatch_size\\x18\\x04 \\x01(\\r\\x12\\x14\\n\\tcrop_size\\x18\\x05 \\x01(\\r:\\x01\\x30\\x12\\x15\\n\\x06mirror\\x18\\x06 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x19\\n\\x0c\\x66g_threshold\\x18\\x07 \\x01(\\x02:\\x03\\x30.5\\x12\\x19\\n\\x0c\\x62g_threshold\\x18\\x08 \\x01(\\x02:\\x03\\x30.5\\x12\\x19\\n\\x0b\\x66g_fraction\\x18\\t \\x01(\\x02:\\x04\\x30.25\\x12\\x16\\n\\x0b\\x63ontext_pad\\x18\\n \\x01(\\r:\\x01\\x30\\x12\\x17\\n\\tcrop_mode\\x18\\x0b \\x01(\\t:\\x04warp\\x12\\x1b\\n\\x0c\\x63\\x61\\x63he_images\\x18\\x0c \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x15\\n\\x0broot_folder\\x18\\r \\x01(\\t:\\x00\\""\\xeb\\x01\\n\\x0cSPPParameter\\x12\\x16\\n\\x0epyramid_height\\x18\\x01 \\x01(\\r\\x12\\x31\\n\\x04pool\\x18\\x02 \\x01(\\x0e\\x32\\x1e.caffe.SPPParameter.PoolMethod:\\x03MAX\\x12\\x33\\n\\x06\\x65ngine\\x18\\x06 \\x01(\\x0e\\x32\\x1a.caffe.SPPParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\"".\\n\\nPoolMethod\\x12\\x07\\n\\x03MAX\\x10\\x00\\x12\\x07\\n\\x03\\x41VE\\x10\\x01\\x12\\x0e\\n\\nSTOCHASTIC\\x10\\x02\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""\\xe0\\x13\\n\\x10V1LayerParameter\\x12\\x0e\\n\\x06\\x62ottom\\x18\\x02 \\x03(\\t\\x12\\x0b\\n\\x03top\\x18\\x03 \\x03(\\t\\x12\\x0c\\n\\x04name\\x18\\x04 \\x01(\\t\\x12$\\n\\x07include\\x18  \\x03(\\x0b\\x32\\x13.caffe.NetStateRule\\x12$\\n\\x07\\x65xclude\\x18! \\x03(\\x0b\\x32\\x13.caffe.NetStateRule\\x12/\\n\\x04type\\x18\\x05 \\x01(\\x0e\\x32!.caffe.V1LayerParameter.LayerType\\x12\\x1f\\n\\x05\\x62lobs\\x18\\x06 \\x03(\\x0b\\x32\\x10.caffe.BlobProto\\x12\\x0e\\n\\x05param\\x18\\xe9\\x07 \\x03(\\t\\x12>\\n\\x0f\\x62lob_share_mode\\x18\\xea\\x07 \\x03(\\x0e\\x32$.caffe.V1LayerParameter.DimCheckMode\\x12\\x10\\n\\x08\\x62lobs_lr\\x18\\x07 \\x03(\\x02\\x12\\x14\\n\\x0cweight_decay\\x18\\x08 \\x03(\\x02\\x12\\x13\\n\\x0bloss_weight\\x18# \\x03(\\x02\\x12\\x30\\n\\x0e\\x61\\x63\\x63uracy_param\\x18\\x1b \\x01(\\x0b\\x32\\x18.caffe.AccuracyParameter\\x12,\\n\\x0c\\x61rgmax_param\\x18\\x17 \\x01(\\x0b\\x32\\x16.caffe.ArgMaxParameter\\x12,\\n\\x0c\\x63oncat_param\\x18\\t \\x01(\\x0b\\x32\\x16.caffe.ConcatParameter\\x12?\\n\\x16\\x63ontrastive_loss_param\\x18( \\x01(\\x0b\\x32\\x1f.caffe.ContrastiveLossParameter\\x12\\x36\\n\\x11\\x63onvolution_param\\x18\\n \\x01(\\x0b\\x32\\x1b.caffe.ConvolutionParameter\\x12(\\n\\ndata_param\\x18\\x0b \\x01(\\x0b\\x32\\x14.caffe.DataParameter\\x12.\\n\\rdropout_param\\x18\\x0c \\x01(\\x0b\\x32\\x17.caffe.DropoutParameter\\x12\\x33\\n\\x10\\x64ummy_data_param\\x18\\x1a \\x01(\\x0b\\x32\\x19.caffe.DummyDataParameter\\x12.\\n\\reltwise_param\\x18\\x18 \\x01(\\x0b\\x32\\x17.caffe.EltwiseParameter\\x12&\\n\\texp_param\\x18) \\x01(\\x0b\\x32\\x13.caffe.ExpParameter\\x12\\x31\\n\\x0fhdf5_data_param\\x18\\r \\x01(\\x0b\\x32\\x18.caffe.HDF5DataParameter\\x12\\x35\\n\\x11hdf5_output_param\\x18\\x0e \\x01(\\x0b\\x32\\x1a.caffe.HDF5OutputParameter\\x12\\x33\\n\\x10hinge_loss_param\\x18\\x1d \\x01(\\x0b\\x32\\x19.caffe.HingeLossParameter\\x12\\x33\\n\\x10image_data_param\\x18\\x0f \\x01(\\x0b\\x32\\x19.caffe.ImageDataParameter\\x12\\x39\\n\\x13infogain_loss_param\\x18\\x10 \\x01(\\x0b\\x32\\x1c.caffe.InfogainLossParameter\\x12\\x39\\n\\x13inner_product_param\\x18\\x11 \\x01(\\x0b\\x32\\x1c.caffe.InnerProductParameter\\x12&\\n\\tlrn_param\\x18\\x12 \\x01(\\x0b\\x32\\x13.caffe.LRNParameter\\x12\\x35\\n\\x11memory_data_param\\x18\\x16 \\x01(\\x0b\\x32\\x1a.caffe.MemoryDataParameter\\x12&\\n\\tmvn_param\\x18\\"" \\x01(\\x0b\\x32\\x13.caffe.MVNParameter\\x12.\\n\\rpooling_param\\x18\\x13 \\x01(\\x0b\\x32\\x17.caffe.PoolingParameter\\x12*\\n\\x0bpower_param\\x18\\x15 \\x01(\\x0b\\x32\\x15.caffe.PowerParameter\\x12(\\n\\nrelu_param\\x18\\x1e \\x01(\\x0b\\x32\\x14.caffe.ReLUParameter\\x12.\\n\\rsigmoid_param\\x18& \\x01(\\x0b\\x32\\x17.caffe.SigmoidParameter\\x12.\\n\\rsoftmax_param\\x18\\\' \\x01(\\x0b\\x32\\x17.caffe.SoftmaxParameter\\x12*\\n\\x0bslice_param\\x18\\x1f \\x01(\\x0b\\x32\\x15.caffe.SliceParameter\\x12(\\n\\ntanh_param\\x18% \\x01(\\x0b\\x32\\x14.caffe.TanHParameter\\x12\\x32\\n\\x0fthreshold_param\\x18\\x19 \\x01(\\x0b\\x32\\x19.caffe.ThresholdParameter\\x12\\x35\\n\\x11window_data_param\\x18\\x14 \\x01(\\x0b\\x32\\x1a.caffe.WindowDataParameter\\x12\\x37\\n\\x0ftransform_param\\x18$ \\x01(\\x0b\\x32\\x1e.caffe.TransformationParameter\\x12(\\n\\nloss_param\\x18* \\x01(\\x0b\\x32\\x14.caffe.LossParameter\\x12&\\n\\x05layer\\x18\\x01 \\x01(\\x0b\\x32\\x17.caffe.V0LayerParameter\\""\\xd8\\x04\\n\\tLayerType\\x12\\x08\\n\\x04NONE\\x10\\x00\\x12\\n\\n\\x06\\x41\\x42SVAL\\x10#\\x12\\x0c\\n\\x08\\x41\\x43\\x43URACY\\x10\\x01\\x12\\n\\n\\x06\\x41RGMAX\\x10\\x1e\\x12\\x08\\n\\x04\\x42NLL\\x10\\x02\\x12\\n\\n\\x06\\x43ONCAT\\x10\\x03\\x12\\x14\\n\\x10\\x43ONTRASTIVE_LOSS\\x10%\\x12\\x0f\\n\\x0b\\x43ONVOLUTION\\x10\\x04\\x12\\x08\\n\\x04\\x44\\x41TA\\x10\\x05\\x12\\x11\\n\\rDECONVOLUTION\\x10\\\'\\x12\\x0b\\n\\x07\\x44ROPOUT\\x10\\x06\\x12\\x0e\\n\\nDUMMY_DATA\\x10 \\x12\\x12\\n\\x0e\\x45UCLIDEAN_LOSS\\x10\\x07\\x12\\x0b\\n\\x07\\x45LTWISE\\x10\\x19\\x12\\x07\\n\\x03\\x45XP\\x10&\\x12\\x0b\\n\\x07\\x46LATTEN\\x10\\x08\\x12\\r\\n\\tHDF5_DATA\\x10\\t\\x12\\x0f\\n\\x0bHDF5_OUTPUT\\x10\\n\\x12\\x0e\\n\\nHINGE_LOSS\\x10\\x1c\\x12\\n\\n\\x06IM2COL\\x10\\x0b\\x12\\x0e\\n\\nIMAGE_DATA\\x10\\x0c\\x12\\x11\\n\\rINFOGAIN_LOSS\\x10\\r\\x12\\x11\\n\\rINNER_PRODUCT\\x10\\x0e\\x12\\x07\\n\\x03LRN\\x10\\x0f\\x12\\x0f\\n\\x0bMEMORY_DATA\\x10\\x1d\\x12\\x1d\\n\\x19MULTINOMIAL_LOGISTIC_LOSS\\x10\\x10\\x12\\x07\\n\\x03MVN\\x10\\""\\x12\\x0b\\n\\x07POOLING\\x10\\x11\\x12\\t\\n\\x05POWER\\x10\\x1a\\x12\\x08\\n\\x04RELU\\x10\\x12\\x12\\x0b\\n\\x07SIGMOID\\x10\\x13\\x12\\x1e\\n\\x1aSIGMOID_CROSS_ENTROPY_LOSS\\x10\\x1b\\x12\\x0b\\n\\x07SILENCE\\x10$\\x12\\x0b\\n\\x07SOFTMAX\\x10\\x14\\x12\\x10\\n\\x0cSOFTMAX_LOSS\\x10\\x15\\x12\\t\\n\\x05SPLIT\\x10\\x16\\x12\\t\\n\\x05SLICE\\x10!\\x12\\x08\\n\\x04TANH\\x10\\x17\\x12\\x0f\\n\\x0bWINDOW_DATA\\x10\\x18\\x12\\r\\n\\tTHRESHOLD\\x10\\x1f\\""*\\n\\x0c\\x44imCheckMode\\x12\\n\\n\\x06STRICT\\x10\\x00\\x12\\x0e\\n\\nPERMISSIVE\\x10\\x01\\""\\xfd\\x07\\n\\x10V0LayerParameter\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12\\x0c\\n\\x04type\\x18\\x02 \\x01(\\t\\x12\\x12\\n\\nnum_output\\x18\\x03 \\x01(\\r\\x12\\x16\\n\\x08\\x62iasterm\\x18\\x04 \\x01(\\x08:\\x04true\\x12-\\n\\rweight_filler\\x18\\x05 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12+\\n\\x0b\\x62ias_filler\\x18\\x06 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12\\x0e\\n\\x03pad\\x18\\x07 \\x01(\\r:\\x01\\x30\\x12\\x12\\n\\nkernelsize\\x18\\x08 \\x01(\\r\\x12\\x10\\n\\x05group\\x18\\t \\x01(\\r:\\x01\\x31\\x12\\x11\\n\\x06stride\\x18\\n \\x01(\\r:\\x01\\x31\\x12\\x35\\n\\x04pool\\x18\\x0b \\x01(\\x0e\\x32\\"".caffe.V0LayerParameter.PoolMethod:\\x03MAX\\x12\\x1a\\n\\rdropout_ratio\\x18\\x0c \\x01(\\x02:\\x03\\x30.5\\x12\\x15\\n\\nlocal_size\\x18\\r \\x01(\\r:\\x01\\x35\\x12\\x10\\n\\x05\\x61lpha\\x18\\x0e \\x01(\\x02:\\x01\\x31\\x12\\x12\\n\\x04\\x62\\x65ta\\x18\\x0f \\x01(\\x02:\\x04\\x30.75\\x12\\x0c\\n\\x01k\\x18\\x16 \\x01(\\x02:\\x01\\x31\\x12\\x0e\\n\\x06source\\x18\\x10 \\x01(\\t\\x12\\x10\\n\\x05scale\\x18\\x11 \\x01(\\x02:\\x01\\x31\\x12\\x10\\n\\x08meanfile\\x18\\x12 \\x01(\\t\\x12\\x11\\n\\tbatchsize\\x18\\x13 \\x01(\\r\\x12\\x13\\n\\x08\\x63ropsize\\x18\\x14 \\x01(\\r:\\x01\\x30\\x12\\x15\\n\\x06mirror\\x18\\x15 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x1f\\n\\x05\\x62lobs\\x18\\x32 \\x03(\\x0b\\x32\\x10.caffe.BlobProto\\x12\\x10\\n\\x08\\x62lobs_lr\\x18\\x33 \\x03(\\x02\\x12\\x14\\n\\x0cweight_decay\\x18\\x34 \\x03(\\x02\\x12\\x14\\n\\trand_skip\\x18\\x35 \\x01(\\r:\\x01\\x30\\x12\\x1d\\n\\x10\\x64\\x65t_fg_threshold\\x18\\x36 \\x01(\\x02:\\x03\\x30.5\\x12\\x1d\\n\\x10\\x64\\x65t_bg_threshold\\x18\\x37 \\x01(\\x02:\\x03\\x30.5\\x12\\x1d\\n\\x0f\\x64\\x65t_fg_fraction\\x18\\x38 \\x01(\\x02:\\x04\\x30.25\\x12\\x1a\\n\\x0f\\x64\\x65t_context_pad\\x18: \\x01(\\r:\\x01\\x30\\x12\\x1b\\n\\rdet_crop_mode\\x18; \\x01(\\t:\\x04warp\\x12\\x12\\n\\x07new_num\\x18< \\x01(\\x05:\\x01\\x30\\x12\\x17\\n\\x0cnew_channels\\x18= \\x01(\\x05:\\x01\\x30\\x12\\x15\\n\\nnew_height\\x18> \\x01(\\x05:\\x01\\x30\\x12\\x14\\n\\tnew_width\\x18? \\x01(\\x05:\\x01\\x30\\x12\\x1d\\n\\x0eshuffle_images\\x18@ \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x15\\n\\nconcat_dim\\x18\\x41 \\x01(\\r:\\x01\\x31\\x12\\x36\\n\\x11hdf5_output_param\\x18\\xe9\\x07 \\x01(\\x0b\\x32\\x1a.caffe.HDF5OutputParameter\\"".\\n\\nPoolMethod\\x12\\x07\\n\\x03MAX\\x10\\x00\\x12\\x07\\n\\x03\\x41VE\\x10\\x01\\x12\\x0e\\n\\nSTOCHASTIC\\x10\\x02\\""W\\n\\x0ePReLUParameter\\x12&\\n\\x06\\x66iller\\x18\\x01 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12\\x1d\\n\\x0e\\x63hannel_shared\\x18\\x02 \\x01(\\x08:\\x05\\x66\\x61lse*\\x1c\\n\\x05Phase\\x12\\t\\n\\x05TRAIN\\x10\\x00\\x12\\x08\\n\\x04TEST\\x10\\x01\')\n\n_PHASE = _descriptor.EnumDescriptor(\n  name=\'Phase\',\n  full_name=\'caffe.Phase\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'TRAIN\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'TEST\', index=1, number=1,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=14991,\n  serialized_end=15019,\n)\n\nPhase = enum_type_wrapper.EnumTypeWrapper(_PHASE)\nTRAIN = 0\nTEST = 1\n\n\n_FILLERPARAMETER_VARIANCENORM = _descriptor.EnumDescriptor(\n  name=\'VarianceNorm\',\n  full_name=\'caffe.FillerParameter.VarianceNorm\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'FAN_IN\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'FAN_OUT\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'AVERAGE\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=658,\n  serialized_end=710,\n)\n\n_SOLVERPARAMETER_SNAPSHOTFORMAT = _descriptor.EnumDescriptor(\n  name=\'SnapshotFormat\',\n  full_name=\'caffe.SolverParameter.SnapshotFormat\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'HDF5\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'BINARYPROTO\', index=1, number=1,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=2132,\n  serialized_end=2175,\n)\n\n_SOLVERPARAMETER_SOLVERMODE = _descriptor.EnumDescriptor(\n  name=\'SolverMode\',\n  full_name=\'caffe.SolverParameter.SolverMode\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'CPU\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'GPU\', index=1, number=1,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=2177,\n  serialized_end=2207,\n)\n\n_SOLVERPARAMETER_SOLVERTYPE = _descriptor.EnumDescriptor(\n  name=\'SolverType\',\n  full_name=\'caffe.SolverParameter.SolverType\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'SGD\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'NESTEROV\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ADAGRAD\', index=2, number=2,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'RMSPROP\', index=3, number=3,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ADADELTA\', index=4, number=4,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ADAM\', index=5, number=5,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=2209,\n  serialized_end=2294,\n)\n\n_PARAMSPEC_DIMCHECKMODE = _descriptor.EnumDescriptor(\n  name=\'DimCheckMode\',\n  full_name=\'caffe.ParamSpec.DimCheckMode\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'STRICT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'PERMISSIVE\', index=1, number=1,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=2725,\n  serialized_end=2767,\n)\n\n_LOSSPARAMETER_NORMALIZATIONMODE = _descriptor.EnumDescriptor(\n  name=\'NormalizationMode\',\n  full_name=\'caffe.LossParameter.NormalizationMode\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'FULL\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'VALID\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'BATCH_SIZE\', index=2, number=2,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'NONE\', index=3, number=3,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=5542,\n  serialized_end=5608,\n)\n\n_CONVOLUTIONPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.ConvolutionParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=6573,\n  serialized_end=6616,\n)\n\n_DATAPARAMETER_DB = _descriptor.EnumDescriptor(\n  name=\'DB\',\n  full_name=\'caffe.DataParameter.DB\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'LEVELDB\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'LMDB\', index=1, number=1,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=6934,\n  serialized_end=6961,\n)\n\n_ELTWISEPARAMETER_ELTWISEOP = _descriptor.EnumDescriptor(\n  name=\'EltwiseOp\',\n  full_name=\'caffe.EltwiseParameter.EltwiseOp\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'PROD\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SUM\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'MAX\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=7301,\n  serialized_end=7340,\n)\n\n_HINGELOSSPARAMETER_NORM = _descriptor.EnumDescriptor(\n  name=\'Norm\',\n  full_name=\'caffe.HingeLossParameter.Norm\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'L1\', index=0, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'L2\', index=1, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=7875,\n  serialized_end=7897,\n)\n\n_LRNPARAMETER_NORMREGION = _descriptor.EnumDescriptor(\n  name=\'NormRegion\',\n  full_name=\'caffe.LRNParameter.NormRegion\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'ACROSS_CHANNELS\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'WITHIN_CHANNEL\', index=1, number=1,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=8764,\n  serialized_end=8817,\n)\n\n_LRNPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.LRNParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=6573,\n  serialized_end=6616,\n)\n\n_POOLINGPARAMETER_POOLMETHOD = _descriptor.EnumDescriptor(\n  name=\'PoolMethod\',\n  full_name=\'caffe.PoolingParameter.PoolMethod\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'MAX\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'AVE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'STOCHASTIC\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=9386,\n  serialized_end=9432,\n)\n\n_POOLINGPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.PoolingParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=6573,\n  serialized_end=6616,\n)\n\n_REDUCTIONPARAMETER_REDUCTIONOP = _descriptor.EnumDescriptor(\n  name=\'ReductionOp\',\n  full_name=\'caffe.ReductionParameter.ReductionOp\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'SUM\', index=0, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ASUM\', index=1, number=2,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SUMSQ\', index=2, number=3,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'MEAN\', index=3, number=4,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=9777,\n  serialized_end=9830,\n)\n\n_RELUPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.ReLUParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=6573,\n  serialized_end=6616,\n)\n\n_SIGMOIDPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.SigmoidParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=6573,\n  serialized_end=6616,\n)\n\n_SOFTMAXPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.SoftmaxParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=6573,\n  serialized_end=6616,\n)\n\n_TANHPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.TanHParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=6573,\n  serialized_end=6616,\n)\n\n_SPPPARAMETER_POOLMETHOD = _descriptor.EnumDescriptor(\n  name=\'PoolMethod\',\n  full_name=\'caffe.SPPParameter.PoolMethod\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'MAX\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'AVE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'STOCHASTIC\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=9386,\n  serialized_end=9432,\n)\n\n_SPPPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.SPPParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=6573,\n  serialized_end=6616,\n)\n\n_V1LAYERPARAMETER_LAYERTYPE = _descriptor.EnumDescriptor(\n  name=\'LayerType\',\n  full_name=\'caffe.V1LayerParameter.LayerType\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'NONE\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ABSVAL\', index=1, number=35,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ACCURACY\', index=2, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ARGMAX\', index=3, number=30,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'BNLL\', index=4, number=2,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CONCAT\', index=5, number=3,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CONTRASTIVE_LOSS\', index=6, number=37,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CONVOLUTION\', index=7, number=4,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'DATA\', index=8, number=5,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'DECONVOLUTION\', index=9, number=39,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'DROPOUT\', index=10, number=6,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'DUMMY_DATA\', index=11, number=32,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'EUCLIDEAN_LOSS\', index=12, number=7,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ELTWISE\', index=13, number=25,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'EXP\', index=14, number=38,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'FLATTEN\', index=15, number=8,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'HDF5_DATA\', index=16, number=9,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'HDF5_OUTPUT\', index=17, number=10,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'HINGE_LOSS\', index=18, number=28,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'IM2COL\', index=19, number=11,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'IMAGE_DATA\', index=20, number=12,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'INFOGAIN_LOSS\', index=21, number=13,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'INNER_PRODUCT\', index=22, number=14,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'LRN\', index=23, number=15,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'MEMORY_DATA\', index=24, number=29,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'MULTINOMIAL_LOGISTIC_LOSS\', index=25, number=16,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'MVN\', index=26, number=34,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'POOLING\', index=27, number=17,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'POWER\', index=28, number=26,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'RELU\', index=29, number=18,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SIGMOID\', index=30, number=19,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SIGMOID_CROSS_ENTROPY_LOSS\', index=31, number=27,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SILENCE\', index=32, number=36,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SOFTMAX\', index=33, number=20,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SOFTMAX_LOSS\', index=34, number=21,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SPLIT\', index=35, number=22,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SLICE\', index=36, number=33,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'TANH\', index=37, number=23,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'WINDOW_DATA\', index=38, number=24,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'THRESHOLD\', index=39, number=31,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=13232,\n  serialized_end=13832,\n)\n\n_V1LAYERPARAMETER_DIMCHECKMODE = _descriptor.EnumDescriptor(\n  name=\'DimCheckMode\',\n  full_name=\'caffe.V1LayerParameter.DimCheckMode\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'STRICT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'PERMISSIVE\', index=1, number=1,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=2725,\n  serialized_end=2767,\n)\n\n_V0LAYERPARAMETER_POOLMETHOD = _descriptor.EnumDescriptor(\n  name=\'PoolMethod\',\n  full_name=\'caffe.V0LayerParameter.PoolMethod\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'MAX\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'AVE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'STOCHASTIC\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=9386,\n  serialized_end=9432,\n)\n\n\n_BLOBSHAPE = _descriptor.Descriptor(\n  name=\'BlobShape\',\n  full_name=\'caffe.BlobShape\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'dim\', full_name=\'caffe.BlobShape.dim\', index=0,\n      number=1, type=3, cpp_type=2, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), \'\\020\\001\')),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=22,\n  serialized_end=50,\n)\n\n\n_BLOBPROTO = _descriptor.Descriptor(\n  name=\'BlobProto\',\n  full_name=\'caffe.BlobProto\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'shape\', full_name=\'caffe.BlobProto.shape\', index=0,\n      number=7, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'data\', full_name=\'caffe.BlobProto.data\', index=1,\n      number=5, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), \'\\020\\001\')),\n    _descriptor.FieldDescriptor(\n      name=\'diff\', full_name=\'caffe.BlobProto.diff\', index=2,\n      number=6, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), \'\\020\\001\')),\n    _descriptor.FieldDescriptor(\n      name=\'double_data\', full_name=\'caffe.BlobProto.double_data\', index=3,\n      number=8, type=1, cpp_type=5, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), \'\\020\\001\')),\n    _descriptor.FieldDescriptor(\n      name=\'double_diff\', full_name=\'caffe.BlobProto.double_diff\', index=4,\n      number=9, type=1, cpp_type=5, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), \'\\020\\001\')),\n    _descriptor.FieldDescriptor(\n      name=\'num\', full_name=\'caffe.BlobProto.num\', index=5,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'channels\', full_name=\'caffe.BlobProto.channels\', index=6,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'height\', full_name=\'caffe.BlobProto.height\', index=7,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'width\', full_name=\'caffe.BlobProto.width\', index=8,\n      number=4, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=53,\n  serialized_end=257,\n)\n\n\n_BLOBPROTOVECTOR = _descriptor.Descriptor(\n  name=\'BlobProtoVector\',\n  full_name=\'caffe.BlobProtoVector\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'blobs\', full_name=\'caffe.BlobProtoVector.blobs\', index=0,\n      number=1, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=259,\n  serialized_end=309,\n)\n\n\n_DATUM = _descriptor.Descriptor(\n  name=\'Datum\',\n  full_name=\'caffe.Datum\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'channels\', full_name=\'caffe.Datum.channels\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'height\', full_name=\'caffe.Datum.height\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'width\', full_name=\'caffe.Datum.width\', index=2,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'data\', full_name=\'caffe.Datum.data\', index=3,\n      number=4, type=12, cpp_type=9, label=1,\n      has_default_value=False, default_value="""",\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'label\', full_name=\'caffe.Datum.label\', index=4,\n      number=5, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'float_data\', full_name=\'caffe.Datum.float_data\', index=5,\n      number=6, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'encoded\', full_name=\'caffe.Datum.encoded\', index=6,\n      number=7, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=312,\n  serialized_end=441,\n)\n\n\n_FILLERPARAMETER = _descriptor.Descriptor(\n  name=\'FillerParameter\',\n  full_name=\'caffe.FillerParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'type\', full_name=\'caffe.FillerParameter.type\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=unicode(""constant"", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'value\', full_name=\'caffe.FillerParameter.value\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'min\', full_name=\'caffe.FillerParameter.min\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'max\', full_name=\'caffe.FillerParameter.max\', index=3,\n      number=4, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mean\', full_name=\'caffe.FillerParameter.mean\', index=4,\n      number=5, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'std\', full_name=\'caffe.FillerParameter.std\', index=5,\n      number=6, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'sparse\', full_name=\'caffe.FillerParameter.sparse\', index=6,\n      number=7, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=-1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'variance_norm\', full_name=\'caffe.FillerParameter.variance_norm\', index=7,\n      number=8, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _FILLERPARAMETER_VARIANCENORM,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=444,\n  serialized_end=710,\n)\n\n\n_NETPARAMETER = _descriptor.Descriptor(\n  name=\'NetParameter\',\n  full_name=\'caffe.NetParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'caffe.NetParameter.name\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'input\', full_name=\'caffe.NetParameter.input\', index=1,\n      number=3, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'input_shape\', full_name=\'caffe.NetParameter.input_shape\', index=2,\n      number=8, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'input_dim\', full_name=\'caffe.NetParameter.input_dim\', index=3,\n      number=4, type=5, cpp_type=1, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'force_backward\', full_name=\'caffe.NetParameter.force_backward\', index=4,\n      number=5, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'state\', full_name=\'caffe.NetParameter.state\', index=5,\n      number=6, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'debug_info\', full_name=\'caffe.NetParameter.debug_info\', index=6,\n      number=7, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'layer\', full_name=\'caffe.NetParameter.layer\', index=7,\n      number=100, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'layers\', full_name=\'caffe.NetParameter.layers\', index=8,\n      number=2, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=713,\n  serialized_end=983,\n)\n\n\n_SOLVERPARAMETER = _descriptor.Descriptor(\n  name=\'SolverParameter\',\n  full_name=\'caffe.SolverParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'net\', full_name=\'caffe.SolverParameter.net\', index=0,\n      number=24, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'net_param\', full_name=\'caffe.SolverParameter.net_param\', index=1,\n      number=25, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'train_net\', full_name=\'caffe.SolverParameter.train_net\', index=2,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'test_net\', full_name=\'caffe.SolverParameter.test_net\', index=3,\n      number=2, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'train_net_param\', full_name=\'caffe.SolverParameter.train_net_param\', index=4,\n      number=21, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'test_net_param\', full_name=\'caffe.SolverParameter.test_net_param\', index=5,\n      number=22, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'train_state\', full_name=\'caffe.SolverParameter.train_state\', index=6,\n      number=26, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'test_state\', full_name=\'caffe.SolverParameter.test_state\', index=7,\n      number=27, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'test_iter\', full_name=\'caffe.SolverParameter.test_iter\', index=8,\n      number=3, type=5, cpp_type=1, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'test_interval\', full_name=\'caffe.SolverParameter.test_interval\', index=9,\n      number=4, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'test_compute_loss\', full_name=\'caffe.SolverParameter.test_compute_loss\', index=10,\n      number=19, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'test_initialization\', full_name=\'caffe.SolverParameter.test_initialization\', index=11,\n      number=32, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'base_lr\', full_name=\'caffe.SolverParameter.base_lr\', index=12,\n      number=5, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'display\', full_name=\'caffe.SolverParameter.display\', index=13,\n      number=6, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'average_loss\', full_name=\'caffe.SolverParameter.average_loss\', index=14,\n      number=33, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'max_iter\', full_name=\'caffe.SolverParameter.max_iter\', index=15,\n      number=7, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'iter_size\', full_name=\'caffe.SolverParameter.iter_size\', index=16,\n      number=36, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'lr_policy\', full_name=\'caffe.SolverParameter.lr_policy\', index=17,\n      number=8, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'gamma\', full_name=\'caffe.SolverParameter.gamma\', index=18,\n      number=9, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'power\', full_name=\'caffe.SolverParameter.power\', index=19,\n      number=10, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'momentum\', full_name=\'caffe.SolverParameter.momentum\', index=20,\n      number=11, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'weight_decay\', full_name=\'caffe.SolverParameter.weight_decay\', index=21,\n      number=12, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'regularization_type\', full_name=\'caffe.SolverParameter.regularization_type\', index=22,\n      number=29, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=unicode(""L2"", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stepsize\', full_name=\'caffe.SolverParameter.stepsize\', index=23,\n      number=13, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stepvalue\', full_name=\'caffe.SolverParameter.stepvalue\', index=24,\n      number=34, type=5, cpp_type=1, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'clip_gradients\', full_name=\'caffe.SolverParameter.clip_gradients\', index=25,\n      number=35, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=-1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'snapshot\', full_name=\'caffe.SolverParameter.snapshot\', index=26,\n      number=14, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'snapshot_prefix\', full_name=\'caffe.SolverParameter.snapshot_prefix\', index=27,\n      number=15, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'snapshot_diff\', full_name=\'caffe.SolverParameter.snapshot_diff\', index=28,\n      number=16, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'snapshot_format\', full_name=\'caffe.SolverParameter.snapshot_format\', index=29,\n      number=37, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'solver_mode\', full_name=\'caffe.SolverParameter.solver_mode\', index=30,\n      number=17, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'device_id\', full_name=\'caffe.SolverParameter.device_id\', index=31,\n      number=18, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'random_seed\', full_name=\'caffe.SolverParameter.random_seed\', index=32,\n      number=20, type=3, cpp_type=2, label=1,\n      has_default_value=True, default_value=-1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'type\', full_name=\'caffe.SolverParameter.type\', index=33,\n      number=40, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=unicode(""SGD"", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'delta\', full_name=\'caffe.SolverParameter.delta\', index=34,\n      number=31, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1e-08,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'momentum2\', full_name=\'caffe.SolverParameter.momentum2\', index=35,\n      number=39, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0.999,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'rms_decay\', full_name=\'caffe.SolverParameter.rms_decay\', index=36,\n      number=38, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'debug_info\', full_name=\'caffe.SolverParameter.debug_info\', index=37,\n      number=23, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'snapshot_after_train\', full_name=\'caffe.SolverParameter.snapshot_after_train\', index=38,\n      number=28, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'solver_type\', full_name=\'caffe.SolverParameter.solver_type\', index=39,\n      number=30, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _SOLVERPARAMETER_SNAPSHOTFORMAT,\n    _SOLVERPARAMETER_SOLVERMODE,\n    _SOLVERPARAMETER_SOLVERTYPE,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=986,\n  serialized_end=2294,\n)\n\n\n_SOLVERSTATE = _descriptor.Descriptor(\n  name=\'SolverState\',\n  full_name=\'caffe.SolverState\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'iter\', full_name=\'caffe.SolverState.iter\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'learned_net\', full_name=\'caffe.SolverState.learned_net\', index=1,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'history\', full_name=\'caffe.SolverState.history\', index=2,\n      number=3, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'current_step\', full_name=\'caffe.SolverState.current_step\', index=3,\n      number=4, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=2296,\n  serialized_end=2404,\n)\n\n\n_NETSTATE = _descriptor.Descriptor(\n  name=\'NetState\',\n  full_name=\'caffe.NetState\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'phase\', full_name=\'caffe.NetState.phase\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'level\', full_name=\'caffe.NetState.level\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stage\', full_name=\'caffe.NetState.stage\', index=2,\n      number=3, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=2406,\n  serialized_end=2484,\n)\n\n\n_NETSTATERULE = _descriptor.Descriptor(\n  name=\'NetStateRule\',\n  full_name=\'caffe.NetStateRule\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'phase\', full_name=\'caffe.NetStateRule.phase\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'min_level\', full_name=\'caffe.NetStateRule.min_level\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'max_level\', full_name=\'caffe.NetStateRule.max_level\', index=2,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stage\', full_name=\'caffe.NetStateRule.stage\', index=3,\n      number=4, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'not_stage\', full_name=\'caffe.NetStateRule.not_stage\', index=4,\n      number=5, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=2486,\n  serialized_end=2601,\n)\n\n\n_PARAMSPEC = _descriptor.Descriptor(\n  name=\'ParamSpec\',\n  full_name=\'caffe.ParamSpec\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'caffe.ParamSpec.name\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'share_mode\', full_name=\'caffe.ParamSpec.share_mode\', index=1,\n      number=2, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'lr_mult\', full_name=\'caffe.ParamSpec.lr_mult\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'decay_mult\', full_name=\'caffe.ParamSpec.decay_mult\', index=3,\n      number=4, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _PARAMSPEC_DIMCHECKMODE,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=2604,\n  serialized_end=2767,\n)\n\n\n_LAYERPARAMETER = _descriptor.Descriptor(\n  name=\'LayerParameter\',\n  full_name=\'caffe.LayerParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'caffe.LayerParameter.name\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'type\', full_name=\'caffe.LayerParameter.type\', index=1,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bottom\', full_name=\'caffe.LayerParameter.bottom\', index=2,\n      number=3, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'top\', full_name=\'caffe.LayerParameter.top\', index=3,\n      number=4, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'phase\', full_name=\'caffe.LayerParameter.phase\', index=4,\n      number=10, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'loss_weight\', full_name=\'caffe.LayerParameter.loss_weight\', index=5,\n      number=5, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'param\', full_name=\'caffe.LayerParameter.param\', index=6,\n      number=6, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'blobs\', full_name=\'caffe.LayerParameter.blobs\', index=7,\n      number=7, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'propagate_down\', full_name=\'caffe.LayerParameter.propagate_down\', index=8,\n      number=11, type=8, cpp_type=7, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'include\', full_name=\'caffe.LayerParameter.include\', index=9,\n      number=8, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'exclude\', full_name=\'caffe.LayerParameter.exclude\', index=10,\n      number=9, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'transform_param\', full_name=\'caffe.LayerParameter.transform_param\', index=11,\n      number=100, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'loss_param\', full_name=\'caffe.LayerParameter.loss_param\', index=12,\n      number=101, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'accuracy_param\', full_name=\'caffe.LayerParameter.accuracy_param\', index=13,\n      number=102, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'argmax_param\', full_name=\'caffe.LayerParameter.argmax_param\', index=14,\n      number=103, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'batch_norm_param\', full_name=\'caffe.LayerParameter.batch_norm_param\', index=15,\n      number=139, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_param\', full_name=\'caffe.LayerParameter.bias_param\', index=16,\n      number=141, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'concat_param\', full_name=\'caffe.LayerParameter.concat_param\', index=17,\n      number=104, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'contrastive_loss_param\', full_name=\'caffe.LayerParameter.contrastive_loss_param\', index=18,\n      number=105, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'convolution_param\', full_name=\'caffe.LayerParameter.convolution_param\', index=19,\n      number=106, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'crop_param\', full_name=\'caffe.LayerParameter.crop_param\', index=20,\n      number=144, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'data_param\', full_name=\'caffe.LayerParameter.data_param\', index=21,\n      number=107, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'dropout_param\', full_name=\'caffe.LayerParameter.dropout_param\', index=22,\n      number=108, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'dummy_data_param\', full_name=\'caffe.LayerParameter.dummy_data_param\', index=23,\n      number=109, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'eltwise_param\', full_name=\'caffe.LayerParameter.eltwise_param\', index=24,\n      number=110, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'elu_param\', full_name=\'caffe.LayerParameter.elu_param\', index=25,\n      number=140, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'embed_param\', full_name=\'caffe.LayerParameter.embed_param\', index=26,\n      number=137, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'exp_param\', full_name=\'caffe.LayerParameter.exp_param\', index=27,\n      number=111, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'flatten_param\', full_name=\'caffe.LayerParameter.flatten_param\', index=28,\n      number=135, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'hdf5_data_param\', full_name=\'caffe.LayerParameter.hdf5_data_param\', index=29,\n      number=112, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'hdf5_output_param\', full_name=\'caffe.LayerParameter.hdf5_output_param\', index=30,\n      number=113, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'hinge_loss_param\', full_name=\'caffe.LayerParameter.hinge_loss_param\', index=31,\n      number=114, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'image_data_param\', full_name=\'caffe.LayerParameter.image_data_param\', index=32,\n      number=115, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'infogain_loss_param\', full_name=\'caffe.LayerParameter.infogain_loss_param\', index=33,\n      number=116, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'inner_product_param\', full_name=\'caffe.LayerParameter.inner_product_param\', index=34,\n      number=117, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'input_param\', full_name=\'caffe.LayerParameter.input_param\', index=35,\n      number=143, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'log_param\', full_name=\'caffe.LayerParameter.log_param\', index=36,\n      number=134, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'lrn_param\', full_name=\'caffe.LayerParameter.lrn_param\', index=37,\n      number=118, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'memory_data_param\', full_name=\'caffe.LayerParameter.memory_data_param\', index=38,\n      number=119, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mvn_param\', full_name=\'caffe.LayerParameter.mvn_param\', index=39,\n      number=120, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pooling_param\', full_name=\'caffe.LayerParameter.pooling_param\', index=40,\n      number=121, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'power_param\', full_name=\'caffe.LayerParameter.power_param\', index=41,\n      number=122, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'prelu_param\', full_name=\'caffe.LayerParameter.prelu_param\', index=42,\n      number=131, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'python_param\', full_name=\'caffe.LayerParameter.python_param\', index=43,\n      number=130, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'reduction_param\', full_name=\'caffe.LayerParameter.reduction_param\', index=44,\n      number=136, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'relu_param\', full_name=\'caffe.LayerParameter.relu_param\', index=45,\n      number=123, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'reshape_param\', full_name=\'caffe.LayerParameter.reshape_param\', index=46,\n      number=133, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'scale_param\', full_name=\'caffe.LayerParameter.scale_param\', index=47,\n      number=142, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'sigmoid_param\', full_name=\'caffe.LayerParameter.sigmoid_param\', index=48,\n      number=124, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'softmax_param\', full_name=\'caffe.LayerParameter.softmax_param\', index=49,\n      number=125, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'spp_param\', full_name=\'caffe.LayerParameter.spp_param\', index=50,\n      number=132, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'slice_param\', full_name=\'caffe.LayerParameter.slice_param\', index=51,\n      number=126, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'tanh_param\', full_name=\'caffe.LayerParameter.tanh_param\', index=52,\n      number=127, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'threshold_param\', full_name=\'caffe.LayerParameter.threshold_param\', index=53,\n      number=128, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'tile_param\', full_name=\'caffe.LayerParameter.tile_param\', index=54,\n      number=138, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'window_data_param\', full_name=\'caffe.LayerParameter.window_data_param\', index=55,\n      number=129, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=2770,\n  serialized_end=5226,\n)\n\n\n_TRANSFORMATIONPARAMETER = _descriptor.Descriptor(\n  name=\'TransformationParameter\',\n  full_name=\'caffe.TransformationParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.TransformationParameter.scale\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mirror\', full_name=\'caffe.TransformationParameter.mirror\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'crop_size\', full_name=\'caffe.TransformationParameter.crop_size\', index=2,\n      number=3, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mean_file\', full_name=\'caffe.TransformationParameter.mean_file\', index=3,\n      number=4, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mean_value\', full_name=\'caffe.TransformationParameter.mean_value\', index=4,\n      number=5, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'force_color\', full_name=\'caffe.TransformationParameter.force_color\', index=5,\n      number=6, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'force_gray\', full_name=\'caffe.TransformationParameter.force_gray\', index=6,\n      number=7, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=5229,\n  serialized_end=5411,\n)\n\n\n_LOSSPARAMETER = _descriptor.Descriptor(\n  name=\'LossParameter\',\n  full_name=\'caffe.LossParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'ignore_label\', full_name=\'caffe.LossParameter.ignore_label\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'normalization\', full_name=\'caffe.LossParameter.normalization\', index=1,\n      number=3, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'normalize\', full_name=\'caffe.LossParameter.normalize\', index=2,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=False, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _LOSSPARAMETER_NORMALIZATIONMODE,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=5414,\n  serialized_end=5608,\n)\n\n\n_ACCURACYPARAMETER = _descriptor.Descriptor(\n  name=\'AccuracyParameter\',\n  full_name=\'caffe.AccuracyParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'top_k\', full_name=\'caffe.AccuracyParameter.top_k\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.AccuracyParameter.axis\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'ignore_label\', full_name=\'caffe.AccuracyParameter.ignore_label\', index=2,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=5610,\n  serialized_end=5686,\n)\n\n\n_ARGMAXPARAMETER = _descriptor.Descriptor(\n  name=\'ArgMaxParameter\',\n  full_name=\'caffe.ArgMaxParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'out_max_val\', full_name=\'caffe.ArgMaxParameter.out_max_val\', index=0,\n      number=1, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'top_k\', full_name=\'caffe.ArgMaxParameter.top_k\', index=1,\n      number=2, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.ArgMaxParameter.axis\', index=2,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=5688,\n  serialized_end=5765,\n)\n\n\n_CONCATPARAMETER = _descriptor.Descriptor(\n  name=\'ConcatParameter\',\n  full_name=\'caffe.ConcatParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.ConcatParameter.axis\', index=0,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'concat_dim\', full_name=\'caffe.ConcatParameter.concat_dim\', index=1,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=5767,\n  serialized_end=5824,\n)\n\n\n_BATCHNORMPARAMETER = _descriptor.Descriptor(\n  name=\'BatchNormParameter\',\n  full_name=\'caffe.BatchNormParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'use_global_stats\', full_name=\'caffe.BatchNormParameter.use_global_stats\', index=0,\n      number=1, type=8, cpp_type=7, label=1,\n      has_default_value=False, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'moving_average_fraction\', full_name=\'caffe.BatchNormParameter.moving_average_fraction\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0.999,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'eps\', full_name=\'caffe.BatchNormParameter.eps\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1e-05,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=5826,\n  serialized_end=5932,\n)\n\n\n_BIASPARAMETER = _descriptor.Descriptor(\n  name=\'BiasParameter\',\n  full_name=\'caffe.BiasParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.BiasParameter.axis\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'num_axes\', full_name=\'caffe.BiasParameter.num_axes\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'filler\', full_name=\'caffe.BiasParameter.filler\', index=2,\n      number=3, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=5934,\n  serialized_end=6027,\n)\n\n\n_CONTRASTIVELOSSPARAMETER = _descriptor.Descriptor(\n  name=\'ContrastiveLossParameter\',\n  full_name=\'caffe.ContrastiveLossParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'margin\', full_name=\'caffe.ContrastiveLossParameter.margin\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'legacy_version\', full_name=\'caffe.ContrastiveLossParameter.legacy_version\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=6029,\n  serialized_end=6105,\n)\n\n\n_CONVOLUTIONPARAMETER = _descriptor.Descriptor(\n  name=\'ConvolutionParameter\',\n  full_name=\'caffe.ConvolutionParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'num_output\', full_name=\'caffe.ConvolutionParameter.num_output\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_term\', full_name=\'caffe.ConvolutionParameter.bias_term\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pad\', full_name=\'caffe.ConvolutionParameter.pad\', index=2,\n      number=3, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'kernel_size\', full_name=\'caffe.ConvolutionParameter.kernel_size\', index=3,\n      number=4, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stride\', full_name=\'caffe.ConvolutionParameter.stride\', index=4,\n      number=6, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'dilation\', full_name=\'caffe.ConvolutionParameter.dilation\', index=5,\n      number=18, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pad_h\', full_name=\'caffe.ConvolutionParameter.pad_h\', index=6,\n      number=9, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pad_w\', full_name=\'caffe.ConvolutionParameter.pad_w\', index=7,\n      number=10, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'kernel_h\', full_name=\'caffe.ConvolutionParameter.kernel_h\', index=8,\n      number=11, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'kernel_w\', full_name=\'caffe.ConvolutionParameter.kernel_w\', index=9,\n      number=12, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stride_h\', full_name=\'caffe.ConvolutionParameter.stride_h\', index=10,\n      number=13, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stride_w\', full_name=\'caffe.ConvolutionParameter.stride_w\', index=11,\n      number=14, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'group\', full_name=\'caffe.ConvolutionParameter.group\', index=12,\n      number=5, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'weight_filler\', full_name=\'caffe.ConvolutionParameter.weight_filler\', index=13,\n      number=7, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_filler\', full_name=\'caffe.ConvolutionParameter.bias_filler\', index=14,\n      number=8, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.ConvolutionParameter.engine\', index=15,\n      number=15, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.ConvolutionParameter.axis\', index=16,\n      number=16, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'force_nd_im2col\', full_name=\'caffe.ConvolutionParameter.force_nd_im2col\', index=17,\n      number=17, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _CONVOLUTIONPARAMETER_ENGINE,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=6108,\n  serialized_end=6616,\n)\n\n\n_CROPPARAMETER = _descriptor.Descriptor(\n  name=\'CropParameter\',\n  full_name=\'caffe.CropParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.CropParameter.axis\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=2,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'offset\', full_name=\'caffe.CropParameter.offset\', index=1,\n      number=2, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=6618,\n  serialized_end=6666,\n)\n\n\n_DATAPARAMETER = _descriptor.Descriptor(\n  name=\'DataParameter\',\n  full_name=\'caffe.DataParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'source\', full_name=\'caffe.DataParameter.source\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'batch_size\', full_name=\'caffe.DataParameter.batch_size\', index=1,\n      number=4, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'rand_skip\', full_name=\'caffe.DataParameter.rand_skip\', index=2,\n      number=7, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'backend\', full_name=\'caffe.DataParameter.backend\', index=3,\n      number=8, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.DataParameter.scale\', index=4,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mean_file\', full_name=\'caffe.DataParameter.mean_file\', index=5,\n      number=3, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'crop_size\', full_name=\'caffe.DataParameter.crop_size\', index=6,\n      number=5, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mirror\', full_name=\'caffe.DataParameter.mirror\', index=7,\n      number=6, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'force_encoded_color\', full_name=\'caffe.DataParameter.force_encoded_color\', index=8,\n      number=9, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'prefetch\', full_name=\'caffe.DataParameter.prefetch\', index=9,\n      number=10, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=4,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _DATAPARAMETER_DB,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=6669,\n  serialized_end=6961,\n)\n\n\n_DROPOUTPARAMETER = _descriptor.Descriptor(\n  name=\'DropoutParameter\',\n  full_name=\'caffe.DropoutParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'dropout_ratio\', full_name=\'caffe.DropoutParameter.dropout_ratio\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0.5,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=6963,\n  serialized_end=7009,\n)\n\n\n_DUMMYDATAPARAMETER = _descriptor.Descriptor(\n  name=\'DummyDataParameter\',\n  full_name=\'caffe.DummyDataParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'data_filler\', full_name=\'caffe.DummyDataParameter.data_filler\', index=0,\n      number=1, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'shape\', full_name=\'caffe.DummyDataParameter.shape\', index=1,\n      number=6, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'num\', full_name=\'caffe.DummyDataParameter.num\', index=2,\n      number=2, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'channels\', full_name=\'caffe.DummyDataParameter.channels\', index=3,\n      number=3, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'height\', full_name=\'caffe.DummyDataParameter.height\', index=4,\n      number=4, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'width\', full_name=\'caffe.DummyDataParameter.width\', index=5,\n      number=5, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=7012,\n  serialized_end=7172,\n)\n\n\n_ELTWISEPARAMETER = _descriptor.Descriptor(\n  name=\'EltwiseParameter\',\n  full_name=\'caffe.EltwiseParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'operation\', full_name=\'caffe.EltwiseParameter.operation\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'coeff\', full_name=\'caffe.EltwiseParameter.coeff\', index=1,\n      number=2, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stable_prod_grad\', full_name=\'caffe.EltwiseParameter.stable_prod_grad\', index=2,\n      number=3, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _ELTWISEPARAMETER_ELTWISEOP,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=7175,\n  serialized_end=7340,\n)\n\n\n_ELUPARAMETER = _descriptor.Descriptor(\n  name=\'ELUParameter\',\n  full_name=\'caffe.ELUParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'alpha\', full_name=\'caffe.ELUParameter.alpha\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=7342,\n  serialized_end=7374,\n)\n\n\n_EMBEDPARAMETER = _descriptor.Descriptor(\n  name=\'EmbedParameter\',\n  full_name=\'caffe.EmbedParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'num_output\', full_name=\'caffe.EmbedParameter.num_output\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'input_dim\', full_name=\'caffe.EmbedParameter.input_dim\', index=1,\n      number=2, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_term\', full_name=\'caffe.EmbedParameter.bias_term\', index=2,\n      number=3, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'weight_filler\', full_name=\'caffe.EmbedParameter.weight_filler\', index=3,\n      number=4, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_filler\', full_name=\'caffe.EmbedParameter.bias_filler\', index=4,\n      number=5, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=7377,\n  serialized_end=7549,\n)\n\n\n_EXPPARAMETER = _descriptor.Descriptor(\n  name=\'ExpParameter\',\n  full_name=\'caffe.ExpParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'base\', full_name=\'caffe.ExpParameter.base\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=-1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.ExpParameter.scale\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'shift\', full_name=\'caffe.ExpParameter.shift\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=7551,\n  serialized_end=7619,\n)\n\n\n_FLATTENPARAMETER = _descriptor.Descriptor(\n  name=\'FlattenParameter\',\n  full_name=\'caffe.FlattenParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.FlattenParameter.axis\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'end_axis\', full_name=\'caffe.FlattenParameter.end_axis\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=-1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=7621,\n  serialized_end=7678,\n)\n\n\n_HDF5DATAPARAMETER = _descriptor.Descriptor(\n  name=\'HDF5DataParameter\',\n  full_name=\'caffe.HDF5DataParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'source\', full_name=\'caffe.HDF5DataParameter.source\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'batch_size\', full_name=\'caffe.HDF5DataParameter.batch_size\', index=1,\n      number=2, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'shuffle\', full_name=\'caffe.HDF5DataParameter.shuffle\', index=2,\n      number=3, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=7680,\n  serialized_end=7759,\n)\n\n\n_HDF5OUTPUTPARAMETER = _descriptor.Descriptor(\n  name=\'HDF5OutputParameter\',\n  full_name=\'caffe.HDF5OutputParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'file_name\', full_name=\'caffe.HDF5OutputParameter.file_name\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=7761,\n  serialized_end=7801,\n)\n\n\n_HINGELOSSPARAMETER = _descriptor.Descriptor(\n  name=\'HingeLossParameter\',\n  full_name=\'caffe.HingeLossParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'norm\', full_name=\'caffe.HingeLossParameter.norm\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _HINGELOSSPARAMETER_NORM,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=7803,\n  serialized_end=7897,\n)\n\n\n_IMAGEDATAPARAMETER = _descriptor.Descriptor(\n  name=\'ImageDataParameter\',\n  full_name=\'caffe.ImageDataParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'source\', full_name=\'caffe.ImageDataParameter.source\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'batch_size\', full_name=\'caffe.ImageDataParameter.batch_size\', index=1,\n      number=4, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'rand_skip\', full_name=\'caffe.ImageDataParameter.rand_skip\', index=2,\n      number=7, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'shuffle\', full_name=\'caffe.ImageDataParameter.shuffle\', index=3,\n      number=8, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'new_height\', full_name=\'caffe.ImageDataParameter.new_height\', index=4,\n      number=9, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'new_width\', full_name=\'caffe.ImageDataParameter.new_width\', index=5,\n      number=10, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'is_color\', full_name=\'caffe.ImageDataParameter.is_color\', index=6,\n      number=11, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.ImageDataParameter.scale\', index=7,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mean_file\', full_name=\'caffe.ImageDataParameter.mean_file\', index=8,\n      number=3, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'crop_size\', full_name=\'caffe.ImageDataParameter.crop_size\', index=9,\n      number=5, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mirror\', full_name=\'caffe.ImageDataParameter.mirror\', index=10,\n      number=6, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'root_folder\', full_name=\'caffe.ImageDataParameter.root_folder\', index=11,\n      number=12, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=7900,\n  serialized_end=8179,\n)\n\n\n_INFOGAINLOSSPARAMETER = _descriptor.Descriptor(\n  name=\'InfogainLossParameter\',\n  full_name=\'caffe.InfogainLossParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'source\', full_name=\'caffe.InfogainLossParameter.source\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=8181,\n  serialized_end=8220,\n)\n\n\n_INNERPRODUCTPARAMETER = _descriptor.Descriptor(\n  name=\'InnerProductParameter\',\n  full_name=\'caffe.InnerProductParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'num_output\', full_name=\'caffe.InnerProductParameter.num_output\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_term\', full_name=\'caffe.InnerProductParameter.bias_term\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'weight_filler\', full_name=\'caffe.InnerProductParameter.weight_filler\', index=2,\n      number=3, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_filler\', full_name=\'caffe.InnerProductParameter.bias_filler\', index=3,\n      number=4, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.InnerProductParameter.axis\', index=4,\n      number=5, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'transpose\', full_name=\'caffe.InnerProductParameter.transpose\', index=5,\n      number=6, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=8223,\n  serialized_end=8426,\n)\n\n\n_INPUTPARAMETER = _descriptor.Descriptor(\n  name=\'InputParameter\',\n  full_name=\'caffe.InputParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'shape\', full_name=\'caffe.InputParameter.shape\', index=0,\n      number=1, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=8428,\n  serialized_end=8477,\n)\n\n\n_LOGPARAMETER = _descriptor.Descriptor(\n  name=\'LogParameter\',\n  full_name=\'caffe.LogParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'base\', full_name=\'caffe.LogParameter.base\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=-1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.LogParameter.scale\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'shift\', full_name=\'caffe.LogParameter.shift\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=8479,\n  serialized_end=8547,\n)\n\n\n_LRNPARAMETER = _descriptor.Descriptor(\n  name=\'LRNParameter\',\n  full_name=\'caffe.LRNParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'local_size\', full_name=\'caffe.LRNParameter.local_size\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=5,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'alpha\', full_name=\'caffe.LRNParameter.alpha\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'beta\', full_name=\'caffe.LRNParameter.beta\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0.75,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'norm_region\', full_name=\'caffe.LRNParameter.norm_region\', index=3,\n      number=4, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'k\', full_name=\'caffe.LRNParameter.k\', index=4,\n      number=5, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.LRNParameter.engine\', index=5,\n      number=6, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _LRNPARAMETER_NORMREGION,\n    _LRNPARAMETER_ENGINE,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=8550,\n  serialized_end=8862,\n)\n\n\n_MEMORYDATAPARAMETER = _descriptor.Descriptor(\n  name=\'MemoryDataParameter\',\n  full_name=\'caffe.MemoryDataParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'batch_size\', full_name=\'caffe.MemoryDataParameter.batch_size\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'channels\', full_name=\'caffe.MemoryDataParameter.channels\', index=1,\n      number=2, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'height\', full_name=\'caffe.MemoryDataParameter.height\', index=2,\n      number=3, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'width\', full_name=\'caffe.MemoryDataParameter.width\', index=3,\n      number=4, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=8864,\n  serialized_end=8954,\n)\n\n\n_MVNPARAMETER = _descriptor.Descriptor(\n  name=\'MVNParameter\',\n  full_name=\'caffe.MVNParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'normalize_variance\', full_name=\'caffe.MVNParameter.normalize_variance\', index=0,\n      number=1, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'across_channels\', full_name=\'caffe.MVNParameter.across_channels\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'eps\', full_name=\'caffe.MVNParameter.eps\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1e-09,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=8956,\n  serialized_end=9056,\n)\n\n\n_POOLINGPARAMETER = _descriptor.Descriptor(\n  name=\'PoolingParameter\',\n  full_name=\'caffe.PoolingParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'pool\', full_name=\'caffe.PoolingParameter.pool\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pad\', full_name=\'caffe.PoolingParameter.pad\', index=1,\n      number=4, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pad_h\', full_name=\'caffe.PoolingParameter.pad_h\', index=2,\n      number=9, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pad_w\', full_name=\'caffe.PoolingParameter.pad_w\', index=3,\n      number=10, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'kernel_size\', full_name=\'caffe.PoolingParameter.kernel_size\', index=4,\n      number=2, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'kernel_h\', full_name=\'caffe.PoolingParameter.kernel_h\', index=5,\n      number=5, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'kernel_w\', full_name=\'caffe.PoolingParameter.kernel_w\', index=6,\n      number=6, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stride\', full_name=\'caffe.PoolingParameter.stride\', index=7,\n      number=3, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stride_h\', full_name=\'caffe.PoolingParameter.stride_h\', index=8,\n      number=7, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stride_w\', full_name=\'caffe.PoolingParameter.stride_w\', index=9,\n      number=8, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.PoolingParameter.engine\', index=10,\n      number=11, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'global_pooling\', full_name=\'caffe.PoolingParameter.global_pooling\', index=11,\n      number=12, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _POOLINGPARAMETER_POOLMETHOD,\n    _POOLINGPARAMETER_ENGINE,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=9059,\n  serialized_end=9477,\n)\n\n\n_POWERPARAMETER = _descriptor.Descriptor(\n  name=\'PowerParameter\',\n  full_name=\'caffe.PowerParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'power\', full_name=\'caffe.PowerParameter.power\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.PowerParameter.scale\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'shift\', full_name=\'caffe.PowerParameter.shift\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=9479,\n  serialized_end=9549,\n)\n\n\n_PYTHONPARAMETER = _descriptor.Descriptor(\n  name=\'PythonParameter\',\n  full_name=\'caffe.PythonParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'module\', full_name=\'caffe.PythonParameter.module\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'layer\', full_name=\'caffe.PythonParameter.layer\', index=1,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'param_str\', full_name=\'caffe.PythonParameter.param_str\', index=2,\n      number=3, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'share_in_parallel\', full_name=\'caffe.PythonParameter.share_in_parallel\', index=3,\n      number=4, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=9551,\n  serialized_end=9654,\n)\n\n\n_REDUCTIONPARAMETER = _descriptor.Descriptor(\n  name=\'ReductionParameter\',\n  full_name=\'caffe.ReductionParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'operation\', full_name=\'caffe.ReductionParameter.operation\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.ReductionParameter.axis\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'coeff\', full_name=\'caffe.ReductionParameter.coeff\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _REDUCTIONPARAMETER_REDUCTIONOP,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=9657,\n  serialized_end=9830,\n)\n\n\n_RELUPARAMETER = _descriptor.Descriptor(\n  name=\'ReLUParameter\',\n  full_name=\'caffe.ReLUParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'negative_slope\', full_name=\'caffe.ReLUParameter.negative_slope\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.ReLUParameter.engine\', index=1,\n      number=2, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _RELUPARAMETER_ENGINE,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=9833,\n  serialized_end=9974,\n)\n\n\n_RESHAPEPARAMETER = _descriptor.Descriptor(\n  name=\'ReshapeParameter\',\n  full_name=\'caffe.ReshapeParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'shape\', full_name=\'caffe.ReshapeParameter.shape\', index=0,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.ReshapeParameter.axis\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'num_axes\', full_name=\'caffe.ReshapeParameter.num_axes\', index=2,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=-1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=9976,\n  serialized_end=10066,\n)\n\n\n_SCALEPARAMETER = _descriptor.Descriptor(\n  name=\'ScaleParameter\',\n  full_name=\'caffe.ScaleParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.ScaleParameter.axis\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'num_axes\', full_name=\'caffe.ScaleParameter.num_axes\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'filler\', full_name=\'caffe.ScaleParameter.filler\', index=2,\n      number=3, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_term\', full_name=\'caffe.ScaleParameter.bias_term\', index=3,\n      number=4, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_filler\', full_name=\'caffe.ScaleParameter.bias_filler\', index=4,\n      number=5, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=10069,\n  serialized_end=10234,\n)\n\n\n_SIGMOIDPARAMETER = _descriptor.Descriptor(\n  name=\'SigmoidParameter\',\n  full_name=\'caffe.SigmoidParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.SigmoidParameter.engine\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _SIGMOIDPARAMETER_ENGINE,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=10236,\n  serialized_end=10356,\n)\n\n\n_SLICEPARAMETER = _descriptor.Descriptor(\n  name=\'SliceParameter\',\n  full_name=\'caffe.SliceParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.SliceParameter.axis\', index=0,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'slice_point\', full_name=\'caffe.SliceParameter.slice_point\', index=1,\n      number=2, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'slice_dim\', full_name=\'caffe.SliceParameter.slice_dim\', index=2,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=10358,\n  serialized_end=10434,\n)\n\n\n_SOFTMAXPARAMETER = _descriptor.Descriptor(\n  name=\'SoftmaxParameter\',\n  full_name=\'caffe.SoftmaxParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.SoftmaxParameter.engine\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.SoftmaxParameter.axis\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _SOFTMAXPARAMETER_ENGINE,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=10437,\n  serialized_end=10574,\n)\n\n\n_TANHPARAMETER = _descriptor.Descriptor(\n  name=\'TanHParameter\',\n  full_name=\'caffe.TanHParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.TanHParameter.engine\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _TANHPARAMETER_ENGINE,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=10576,\n  serialized_end=10690,\n)\n\n\n_TILEPARAMETER = _descriptor.Descriptor(\n  name=\'TileParameter\',\n  full_name=\'caffe.TileParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.TileParameter.axis\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'tiles\', full_name=\'caffe.TileParameter.tiles\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=10692,\n  serialized_end=10739,\n)\n\n\n_THRESHOLDPARAMETER = _descriptor.Descriptor(\n  name=\'ThresholdParameter\',\n  full_name=\'caffe.ThresholdParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'threshold\', full_name=\'caffe.ThresholdParameter.threshold\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=10741,\n  serialized_end=10783,\n)\n\n\n_WINDOWDATAPARAMETER = _descriptor.Descriptor(\n  name=\'WindowDataParameter\',\n  full_name=\'caffe.WindowDataParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'source\', full_name=\'caffe.WindowDataParameter.source\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.WindowDataParameter.scale\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mean_file\', full_name=\'caffe.WindowDataParameter.mean_file\', index=2,\n      number=3, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'batch_size\', full_name=\'caffe.WindowDataParameter.batch_size\', index=3,\n      number=4, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'crop_size\', full_name=\'caffe.WindowDataParameter.crop_size\', index=4,\n      number=5, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mirror\', full_name=\'caffe.WindowDataParameter.mirror\', index=5,\n      number=6, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'fg_threshold\', full_name=\'caffe.WindowDataParameter.fg_threshold\', index=6,\n      number=7, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0.5,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bg_threshold\', full_name=\'caffe.WindowDataParameter.bg_threshold\', index=7,\n      number=8, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0.5,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'fg_fraction\', full_name=\'caffe.WindowDataParameter.fg_fraction\', index=8,\n      number=9, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0.25,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'context_pad\', full_name=\'caffe.WindowDataParameter.context_pad\', index=9,\n      number=10, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'crop_mode\', full_name=\'caffe.WindowDataParameter.crop_mode\', index=10,\n      number=11, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=unicode(""warp"", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'cache_images\', full_name=\'caffe.WindowDataParameter.cache_images\', index=11,\n      number=12, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'root_folder\', full_name=\'caffe.WindowDataParameter.root_folder\', index=12,\n      number=13, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=10786,\n  serialized_end=11107,\n)\n\n\n_SPPPARAMETER = _descriptor.Descriptor(\n  name=\'SPPParameter\',\n  full_name=\'caffe.SPPParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'pyramid_height\', full_name=\'caffe.SPPParameter.pyramid_height\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pool\', full_name=\'caffe.SPPParameter.pool\', index=1,\n      number=2, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.SPPParameter.engine\', index=2,\n      number=6, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _SPPPARAMETER_POOLMETHOD,\n    _SPPPARAMETER_ENGINE,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=11110,\n  serialized_end=11345,\n)\n\n\n_V1LAYERPARAMETER = _descriptor.Descriptor(\n  name=\'V1LayerParameter\',\n  full_name=\'caffe.V1LayerParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'bottom\', full_name=\'caffe.V1LayerParameter.bottom\', index=0,\n      number=2, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'top\', full_name=\'caffe.V1LayerParameter.top\', index=1,\n      number=3, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'caffe.V1LayerParameter.name\', index=2,\n      number=4, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'include\', full_name=\'caffe.V1LayerParameter.include\', index=3,\n      number=32, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'exclude\', full_name=\'caffe.V1LayerParameter.exclude\', index=4,\n      number=33, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'type\', full_name=\'caffe.V1LayerParameter.type\', index=5,\n      number=5, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'blobs\', full_name=\'caffe.V1LayerParameter.blobs\', index=6,\n      number=6, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'param\', full_name=\'caffe.V1LayerParameter.param\', index=7,\n      number=1001, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'blob_share_mode\', full_name=\'caffe.V1LayerParameter.blob_share_mode\', index=8,\n      number=1002, type=14, cpp_type=8, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'blobs_lr\', full_name=\'caffe.V1LayerParameter.blobs_lr\', index=9,\n      number=7, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'weight_decay\', full_name=\'caffe.V1LayerParameter.weight_decay\', index=10,\n      number=8, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'loss_weight\', full_name=\'caffe.V1LayerParameter.loss_weight\', index=11,\n      number=35, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'accuracy_param\', full_name=\'caffe.V1LayerParameter.accuracy_param\', index=12,\n      number=27, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'argmax_param\', full_name=\'caffe.V1LayerParameter.argmax_param\', index=13,\n      number=23, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'concat_param\', full_name=\'caffe.V1LayerParameter.concat_param\', index=14,\n      number=9, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'contrastive_loss_param\', full_name=\'caffe.V1LayerParameter.contrastive_loss_param\', index=15,\n      number=40, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'convolution_param\', full_name=\'caffe.V1LayerParameter.convolution_param\', index=16,\n      number=10, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'data_param\', full_name=\'caffe.V1LayerParameter.data_param\', index=17,\n      number=11, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'dropout_param\', full_name=\'caffe.V1LayerParameter.dropout_param\', index=18,\n      number=12, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'dummy_data_param\', full_name=\'caffe.V1LayerParameter.dummy_data_param\', index=19,\n      number=26, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'eltwise_param\', full_name=\'caffe.V1LayerParameter.eltwise_param\', index=20,\n      number=24, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'exp_param\', full_name=\'caffe.V1LayerParameter.exp_param\', index=21,\n      number=41, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'hdf5_data_param\', full_name=\'caffe.V1LayerParameter.hdf5_data_param\', index=22,\n      number=13, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'hdf5_output_param\', full_name=\'caffe.V1LayerParameter.hdf5_output_param\', index=23,\n      number=14, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'hinge_loss_param\', full_name=\'caffe.V1LayerParameter.hinge_loss_param\', index=24,\n      number=29, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'image_data_param\', full_name=\'caffe.V1LayerParameter.image_data_param\', index=25,\n      number=15, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'infogain_loss_param\', full_name=\'caffe.V1LayerParameter.infogain_loss_param\', index=26,\n      number=16, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'inner_product_param\', full_name=\'caffe.V1LayerParameter.inner_product_param\', index=27,\n      number=17, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'lrn_param\', full_name=\'caffe.V1LayerParameter.lrn_param\', index=28,\n      number=18, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'memory_data_param\', full_name=\'caffe.V1LayerParameter.memory_data_param\', index=29,\n      number=22, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mvn_param\', full_name=\'caffe.V1LayerParameter.mvn_param\', index=30,\n      number=34, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pooling_param\', full_name=\'caffe.V1LayerParameter.pooling_param\', index=31,\n      number=19, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'power_param\', full_name=\'caffe.V1LayerParameter.power_param\', index=32,\n      number=21, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'relu_param\', full_name=\'caffe.V1LayerParameter.relu_param\', index=33,\n      number=30, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'sigmoid_param\', full_name=\'caffe.V1LayerParameter.sigmoid_param\', index=34,\n      number=38, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'softmax_param\', full_name=\'caffe.V1LayerParameter.softmax_param\', index=35,\n      number=39, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'slice_param\', full_name=\'caffe.V1LayerParameter.slice_param\', index=36,\n      number=31, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'tanh_param\', full_name=\'caffe.V1LayerParameter.tanh_param\', index=37,\n      number=37, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'threshold_param\', full_name=\'caffe.V1LayerParameter.threshold_param\', index=38,\n      number=25, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'window_data_param\', full_name=\'caffe.V1LayerParameter.window_data_param\', index=39,\n      number=20, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'transform_param\', full_name=\'caffe.V1LayerParameter.transform_param\', index=40,\n      number=36, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'loss_param\', full_name=\'caffe.V1LayerParameter.loss_param\', index=41,\n      number=42, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'layer\', full_name=\'caffe.V1LayerParameter.layer\', index=42,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _V1LAYERPARAMETER_LAYERTYPE,\n    _V1LAYERPARAMETER_DIMCHECKMODE,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=11348,\n  serialized_end=13876,\n)\n\n\n_V0LAYERPARAMETER = _descriptor.Descriptor(\n  name=\'V0LayerParameter\',\n  full_name=\'caffe.V0LayerParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'caffe.V0LayerParameter.name\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'type\', full_name=\'caffe.V0LayerParameter.type\', index=1,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'num_output\', full_name=\'caffe.V0LayerParameter.num_output\', index=2,\n      number=3, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'biasterm\', full_name=\'caffe.V0LayerParameter.biasterm\', index=3,\n      number=4, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'weight_filler\', full_name=\'caffe.V0LayerParameter.weight_filler\', index=4,\n      number=5, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_filler\', full_name=\'caffe.V0LayerParameter.bias_filler\', index=5,\n      number=6, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pad\', full_name=\'caffe.V0LayerParameter.pad\', index=6,\n      number=7, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'kernelsize\', full_name=\'caffe.V0LayerParameter.kernelsize\', index=7,\n      number=8, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'group\', full_name=\'caffe.V0LayerParameter.group\', index=8,\n      number=9, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stride\', full_name=\'caffe.V0LayerParameter.stride\', index=9,\n      number=10, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pool\', full_name=\'caffe.V0LayerParameter.pool\', index=10,\n      number=11, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'dropout_ratio\', full_name=\'caffe.V0LayerParameter.dropout_ratio\', index=11,\n      number=12, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0.5,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'local_size\', full_name=\'caffe.V0LayerParameter.local_size\', index=12,\n      number=13, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=5,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'alpha\', full_name=\'caffe.V0LayerParameter.alpha\', index=13,\n      number=14, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'beta\', full_name=\'caffe.V0LayerParameter.beta\', index=14,\n      number=15, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0.75,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'k\', full_name=\'caffe.V0LayerParameter.k\', index=15,\n      number=22, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'source\', full_name=\'caffe.V0LayerParameter.source\', index=16,\n      number=16, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.V0LayerParameter.scale\', index=17,\n      number=17, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'meanfile\', full_name=\'caffe.V0LayerParameter.meanfile\', index=18,\n      number=18, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'batchsize\', full_name=\'caffe.V0LayerParameter.batchsize\', index=19,\n      number=19, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'cropsize\', full_name=\'caffe.V0LayerParameter.cropsize\', index=20,\n      number=20, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mirror\', full_name=\'caffe.V0LayerParameter.mirror\', index=21,\n      number=21, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'blobs\', full_name=\'caffe.V0LayerParameter.blobs\', index=22,\n      number=50, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'blobs_lr\', full_name=\'caffe.V0LayerParameter.blobs_lr\', index=23,\n      number=51, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'weight_decay\', full_name=\'caffe.V0LayerParameter.weight_decay\', index=24,\n      number=52, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'rand_skip\', full_name=\'caffe.V0LayerParameter.rand_skip\', index=25,\n      number=53, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'det_fg_threshold\', full_name=\'caffe.V0LayerParameter.det_fg_threshold\', index=26,\n      number=54, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0.5,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'det_bg_threshold\', full_name=\'caffe.V0LayerParameter.det_bg_threshold\', index=27,\n      number=55, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0.5,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'det_fg_fraction\', full_name=\'caffe.V0LayerParameter.det_fg_fraction\', index=28,\n      number=56, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0.25,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'det_context_pad\', full_name=\'caffe.V0LayerParameter.det_context_pad\', index=29,\n      number=58, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'det_crop_mode\', full_name=\'caffe.V0LayerParameter.det_crop_mode\', index=30,\n      number=59, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=unicode(""warp"", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'new_num\', full_name=\'caffe.V0LayerParameter.new_num\', index=31,\n      number=60, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'new_channels\', full_name=\'caffe.V0LayerParameter.new_channels\', index=32,\n      number=61, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'new_height\', full_name=\'caffe.V0LayerParameter.new_height\', index=33,\n      number=62, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'new_width\', full_name=\'caffe.V0LayerParameter.new_width\', index=34,\n      number=63, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'shuffle_images\', full_name=\'caffe.V0LayerParameter.shuffle_images\', index=35,\n      number=64, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'concat_dim\', full_name=\'caffe.V0LayerParameter.concat_dim\', index=36,\n      number=65, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'hdf5_output_param\', full_name=\'caffe.V0LayerParameter.hdf5_output_param\', index=37,\n      number=1001, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _V0LAYERPARAMETER_POOLMETHOD,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=13879,\n  serialized_end=14900,\n)\n\n\n_PRELUPARAMETER = _descriptor.Descriptor(\n  name=\'PReLUParameter\',\n  full_name=\'caffe.PReLUParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'filler\', full_name=\'caffe.PReLUParameter.filler\', index=0,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'channel_shared\', full_name=\'caffe.PReLUParameter.channel_shared\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=14902,\n  serialized_end=14989,\n)\n\n_BLOBPROTO.fields_by_name[\'shape\'].message_type = _BLOBSHAPE\n_BLOBPROTOVECTOR.fields_by_name[\'blobs\'].message_type = _BLOBPROTO\n_FILLERPARAMETER.fields_by_name[\'variance_norm\'].enum_type = _FILLERPARAMETER_VARIANCENORM\n_FILLERPARAMETER_VARIANCENORM.containing_type = _FILLERPARAMETER;\n_NETPARAMETER.fields_by_name[\'input_shape\'].message_type = _BLOBSHAPE\n_NETPARAMETER.fields_by_name[\'state\'].message_type = _NETSTATE\n_NETPARAMETER.fields_by_name[\'layer\'].message_type = _LAYERPARAMETER\n_NETPARAMETER.fields_by_name[\'layers\'].message_type = _V1LAYERPARAMETER\n_SOLVERPARAMETER.fields_by_name[\'net_param\'].message_type = _NETPARAMETER\n_SOLVERPARAMETER.fields_by_name[\'train_net_param\'].message_type = _NETPARAMETER\n_SOLVERPARAMETER.fields_by_name[\'test_net_param\'].message_type = _NETPARAMETER\n_SOLVERPARAMETER.fields_by_name[\'train_state\'].message_type = _NETSTATE\n_SOLVERPARAMETER.fields_by_name[\'test_state\'].message_type = _NETSTATE\n_SOLVERPARAMETER.fields_by_name[\'snapshot_format\'].enum_type = _SOLVERPARAMETER_SNAPSHOTFORMAT\n_SOLVERPARAMETER.fields_by_name[\'solver_mode\'].enum_type = _SOLVERPARAMETER_SOLVERMODE\n_SOLVERPARAMETER.fields_by_name[\'solver_type\'].enum_type = _SOLVERPARAMETER_SOLVERTYPE\n_SOLVERPARAMETER_SNAPSHOTFORMAT.containing_type = _SOLVERPARAMETER;\n_SOLVERPARAMETER_SOLVERMODE.containing_type = _SOLVERPARAMETER;\n_SOLVERPARAMETER_SOLVERTYPE.containing_type = _SOLVERPARAMETER;\n_SOLVERSTATE.fields_by_name[\'history\'].message_type = _BLOBPROTO\n_NETSTATE.fields_by_name[\'phase\'].enum_type = _PHASE\n_NETSTATERULE.fields_by_name[\'phase\'].enum_type = _PHASE\n_PARAMSPEC.fields_by_name[\'share_mode\'].enum_type = _PARAMSPEC_DIMCHECKMODE\n_PARAMSPEC_DIMCHECKMODE.containing_type = _PARAMSPEC;\n_LAYERPARAMETER.fields_by_name[\'phase\'].enum_type = _PHASE\n_LAYERPARAMETER.fields_by_name[\'param\'].message_type = _PARAMSPEC\n_LAYERPARAMETER.fields_by_name[\'blobs\'].message_type = _BLOBPROTO\n_LAYERPARAMETER.fields_by_name[\'include\'].message_type = _NETSTATERULE\n_LAYERPARAMETER.fields_by_name[\'exclude\'].message_type = _NETSTATERULE\n_LAYERPARAMETER.fields_by_name[\'transform_param\'].message_type = _TRANSFORMATIONPARAMETER\n_LAYERPARAMETER.fields_by_name[\'loss_param\'].message_type = _LOSSPARAMETER\n_LAYERPARAMETER.fields_by_name[\'accuracy_param\'].message_type = _ACCURACYPARAMETER\n_LAYERPARAMETER.fields_by_name[\'argmax_param\'].message_type = _ARGMAXPARAMETER\n_LAYERPARAMETER.fields_by_name[\'batch_norm_param\'].message_type = _BATCHNORMPARAMETER\n_LAYERPARAMETER.fields_by_name[\'bias_param\'].message_type = _BIASPARAMETER\n_LAYERPARAMETER.fields_by_name[\'concat_param\'].message_type = _CONCATPARAMETER\n_LAYERPARAMETER.fields_by_name[\'contrastive_loss_param\'].message_type = _CONTRASTIVELOSSPARAMETER\n_LAYERPARAMETER.fields_by_name[\'convolution_param\'].message_type = _CONVOLUTIONPARAMETER\n_LAYERPARAMETER.fields_by_name[\'crop_param\'].message_type = _CROPPARAMETER\n_LAYERPARAMETER.fields_by_name[\'data_param\'].message_type = _DATAPARAMETER\n_LAYERPARAMETER.fields_by_name[\'dropout_param\'].message_type = _DROPOUTPARAMETER\n_LAYERPARAMETER.fields_by_name[\'dummy_data_param\'].message_type = _DUMMYDATAPARAMETER\n_LAYERPARAMETER.fields_by_name[\'eltwise_param\'].message_type = _ELTWISEPARAMETER\n_LAYERPARAMETER.fields_by_name[\'elu_param\'].message_type = _ELUPARAMETER\n_LAYERPARAMETER.fields_by_name[\'embed_param\'].message_type = _EMBEDPARAMETER\n_LAYERPARAMETER.fields_by_name[\'exp_param\'].message_type = _EXPPARAMETER\n_LAYERPARAMETER.fields_by_name[\'flatten_param\'].message_type = _FLATTENPARAMETER\n_LAYERPARAMETER.fields_by_name[\'hdf5_data_param\'].message_type = _HDF5DATAPARAMETER\n_LAYERPARAMETER.fields_by_name[\'hdf5_output_param\'].message_type = _HDF5OUTPUTPARAMETER\n_LAYERPARAMETER.fields_by_name[\'hinge_loss_param\'].message_type = _HINGELOSSPARAMETER\n_LAYERPARAMETER.fields_by_name[\'image_data_param\'].message_type = _IMAGEDATAPARAMETER\n_LAYERPARAMETER.fields_by_name[\'infogain_loss_param\'].message_type = _INFOGAINLOSSPARAMETER\n_LAYERPARAMETER.fields_by_name[\'inner_product_param\'].message_type = _INNERPRODUCTPARAMETER\n_LAYERPARAMETER.fields_by_name[\'input_param\'].message_type = _INPUTPARAMETER\n_LAYERPARAMETER.fields_by_name[\'log_param\'].message_type = _LOGPARAMETER\n_LAYERPARAMETER.fields_by_name[\'lrn_param\'].message_type = _LRNPARAMETER\n_LAYERPARAMETER.fields_by_name[\'memory_data_param\'].message_type = _MEMORYDATAPARAMETER\n_LAYERPARAMETER.fields_by_name[\'mvn_param\'].message_type = _MVNPARAMETER\n_LAYERPARAMETER.fields_by_name[\'pooling_param\'].message_type = _POOLINGPARAMETER\n_LAYERPARAMETER.fields_by_name[\'power_param\'].message_type = _POWERPARAMETER\n_LAYERPARAMETER.fields_by_name[\'prelu_param\'].message_type = _PRELUPARAMETER\n_LAYERPARAMETER.fields_by_name[\'python_param\'].message_type = _PYTHONPARAMETER\n_LAYERPARAMETER.fields_by_name[\'reduction_param\'].message_type = _REDUCTIONPARAMETER\n_LAYERPARAMETER.fields_by_name[\'relu_param\'].message_type = _RELUPARAMETER\n_LAYERPARAMETER.fields_by_name[\'reshape_param\'].message_type = _RESHAPEPARAMETER\n_LAYERPARAMETER.fields_by_name[\'scale_param\'].message_type = _SCALEPARAMETER\n_LAYERPARAMETER.fields_by_name[\'sigmoid_param\'].message_type = _SIGMOIDPARAMETER\n_LAYERPARAMETER.fields_by_name[\'softmax_param\'].message_type = _SOFTMAXPARAMETER\n_LAYERPARAMETER.fields_by_name[\'spp_param\'].message_type = _SPPPARAMETER\n_LAYERPARAMETER.fields_by_name[\'slice_param\'].message_type = _SLICEPARAMETER\n_LAYERPARAMETER.fields_by_name[\'tanh_param\'].message_type = _TANHPARAMETER\n_LAYERPARAMETER.fields_by_name[\'threshold_param\'].message_type = _THRESHOLDPARAMETER\n_LAYERPARAMETER.fields_by_name[\'tile_param\'].message_type = _TILEPARAMETER\n_LAYERPARAMETER.fields_by_name[\'window_data_param\'].message_type = _WINDOWDATAPARAMETER\n_LOSSPARAMETER.fields_by_name[\'normalization\'].enum_type = _LOSSPARAMETER_NORMALIZATIONMODE\n_LOSSPARAMETER_NORMALIZATIONMODE.containing_type = _LOSSPARAMETER;\n_BIASPARAMETER.fields_by_name[\'filler\'].message_type = _FILLERPARAMETER\n_CONVOLUTIONPARAMETER.fields_by_name[\'weight_filler\'].message_type = _FILLERPARAMETER\n_CONVOLUTIONPARAMETER.fields_by_name[\'bias_filler\'].message_type = _FILLERPARAMETER\n_CONVOLUTIONPARAMETER.fields_by_name[\'engine\'].enum_type = _CONVOLUTIONPARAMETER_ENGINE\n_CONVOLUTIONPARAMETER_ENGINE.containing_type = _CONVOLUTIONPARAMETER;\n_DATAPARAMETER.fields_by_name[\'backend\'].enum_type = _DATAPARAMETER_DB\n_DATAPARAMETER_DB.containing_type = _DATAPARAMETER;\n_DUMMYDATAPARAMETER.fields_by_name[\'data_filler\'].message_type = _FILLERPARAMETER\n_DUMMYDATAPARAMETER.fields_by_name[\'shape\'].message_type = _BLOBSHAPE\n_ELTWISEPARAMETER.fields_by_name[\'operation\'].enum_type = _ELTWISEPARAMETER_ELTWISEOP\n_ELTWISEPARAMETER_ELTWISEOP.containing_type = _ELTWISEPARAMETER;\n_EMBEDPARAMETER.fields_by_name[\'weight_filler\'].message_type = _FILLERPARAMETER\n_EMBEDPARAMETER.fields_by_name[\'bias_filler\'].message_type = _FILLERPARAMETER\n_HINGELOSSPARAMETER.fields_by_name[\'norm\'].enum_type = _HINGELOSSPARAMETER_NORM\n_HINGELOSSPARAMETER_NORM.containing_type = _HINGELOSSPARAMETER;\n_INNERPRODUCTPARAMETER.fields_by_name[\'weight_filler\'].message_type = _FILLERPARAMETER\n_INNERPRODUCTPARAMETER.fields_by_name[\'bias_filler\'].message_type = _FILLERPARAMETER\n_INPUTPARAMETER.fields_by_name[\'shape\'].message_type = _BLOBSHAPE\n_LRNPARAMETER.fields_by_name[\'norm_region\'].enum_type = _LRNPARAMETER_NORMREGION\n_LRNPARAMETER.fields_by_name[\'engine\'].enum_type = _LRNPARAMETER_ENGINE\n_LRNPARAMETER_NORMREGION.containing_type = _LRNPARAMETER;\n_LRNPARAMETER_ENGINE.containing_type = _LRNPARAMETER;\n_POOLINGPARAMETER.fields_by_name[\'pool\'].enum_type = _POOLINGPARAMETER_POOLMETHOD\n_POOLINGPARAMETER.fields_by_name[\'engine\'].enum_type = _POOLINGPARAMETER_ENGINE\n_POOLINGPARAMETER_POOLMETHOD.containing_type = _POOLINGPARAMETER;\n_POOLINGPARAMETER_ENGINE.containing_type = _POOLINGPARAMETER;\n_REDUCTIONPARAMETER.fields_by_name[\'operation\'].enum_type = _REDUCTIONPARAMETER_REDUCTIONOP\n_REDUCTIONPARAMETER_REDUCTIONOP.containing_type = _REDUCTIONPARAMETER;\n_RELUPARAMETER.fields_by_name[\'engine\'].enum_type = _RELUPARAMETER_ENGINE\n_RELUPARAMETER_ENGINE.containing_type = _RELUPARAMETER;\n_RESHAPEPARAMETER.fields_by_name[\'shape\'].message_type = _BLOBSHAPE\n_SCALEPARAMETER.fields_by_name[\'filler\'].message_type = _FILLERPARAMETER\n_SCALEPARAMETER.fields_by_name[\'bias_filler\'].message_type = _FILLERPARAMETER\n_SIGMOIDPARAMETER.fields_by_name[\'engine\'].enum_type = _SIGMOIDPARAMETER_ENGINE\n_SIGMOIDPARAMETER_ENGINE.containing_type = _SIGMOIDPARAMETER;\n_SOFTMAXPARAMETER.fields_by_name[\'engine\'].enum_type = _SOFTMAXPARAMETER_ENGINE\n_SOFTMAXPARAMETER_ENGINE.containing_type = _SOFTMAXPARAMETER;\n_TANHPARAMETER.fields_by_name[\'engine\'].enum_type = _TANHPARAMETER_ENGINE\n_TANHPARAMETER_ENGINE.containing_type = _TANHPARAMETER;\n_SPPPARAMETER.fields_by_name[\'pool\'].enum_type = _SPPPARAMETER_POOLMETHOD\n_SPPPARAMETER.fields_by_name[\'engine\'].enum_type = _SPPPARAMETER_ENGINE\n_SPPPARAMETER_POOLMETHOD.containing_type = _SPPPARAMETER;\n_SPPPARAMETER_ENGINE.containing_type = _SPPPARAMETER;\n_V1LAYERPARAMETER.fields_by_name[\'include\'].message_type = _NETSTATERULE\n_V1LAYERPARAMETER.fields_by_name[\'exclude\'].message_type = _NETSTATERULE\n_V1LAYERPARAMETER.fields_by_name[\'type\'].enum_type = _V1LAYERPARAMETER_LAYERTYPE\n_V1LAYERPARAMETER.fields_by_name[\'blobs\'].message_type = _BLOBPROTO\n_V1LAYERPARAMETER.fields_by_name[\'blob_share_mode\'].enum_type = _V1LAYERPARAMETER_DIMCHECKMODE\n_V1LAYERPARAMETER.fields_by_name[\'accuracy_param\'].message_type = _ACCURACYPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'argmax_param\'].message_type = _ARGMAXPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'concat_param\'].message_type = _CONCATPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'contrastive_loss_param\'].message_type = _CONTRASTIVELOSSPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'convolution_param\'].message_type = _CONVOLUTIONPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'data_param\'].message_type = _DATAPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'dropout_param\'].message_type = _DROPOUTPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'dummy_data_param\'].message_type = _DUMMYDATAPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'eltwise_param\'].message_type = _ELTWISEPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'exp_param\'].message_type = _EXPPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'hdf5_data_param\'].message_type = _HDF5DATAPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'hdf5_output_param\'].message_type = _HDF5OUTPUTPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'hinge_loss_param\'].message_type = _HINGELOSSPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'image_data_param\'].message_type = _IMAGEDATAPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'infogain_loss_param\'].message_type = _INFOGAINLOSSPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'inner_product_param\'].message_type = _INNERPRODUCTPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'lrn_param\'].message_type = _LRNPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'memory_data_param\'].message_type = _MEMORYDATAPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'mvn_param\'].message_type = _MVNPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'pooling_param\'].message_type = _POOLINGPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'power_param\'].message_type = _POWERPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'relu_param\'].message_type = _RELUPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'sigmoid_param\'].message_type = _SIGMOIDPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'softmax_param\'].message_type = _SOFTMAXPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'slice_param\'].message_type = _SLICEPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'tanh_param\'].message_type = _TANHPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'threshold_param\'].message_type = _THRESHOLDPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'window_data_param\'].message_type = _WINDOWDATAPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'transform_param\'].message_type = _TRANSFORMATIONPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'loss_param\'].message_type = _LOSSPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'layer\'].message_type = _V0LAYERPARAMETER\n_V1LAYERPARAMETER_LAYERTYPE.containing_type = _V1LAYERPARAMETER;\n_V1LAYERPARAMETER_DIMCHECKMODE.containing_type = _V1LAYERPARAMETER;\n_V0LAYERPARAMETER.fields_by_name[\'weight_filler\'].message_type = _FILLERPARAMETER\n_V0LAYERPARAMETER.fields_by_name[\'bias_filler\'].message_type = _FILLERPARAMETER\n_V0LAYERPARAMETER.fields_by_name[\'pool\'].enum_type = _V0LAYERPARAMETER_POOLMETHOD\n_V0LAYERPARAMETER.fields_by_name[\'blobs\'].message_type = _BLOBPROTO\n_V0LAYERPARAMETER.fields_by_name[\'hdf5_output_param\'].message_type = _HDF5OUTPUTPARAMETER\n_V0LAYERPARAMETER_POOLMETHOD.containing_type = _V0LAYERPARAMETER;\n_PRELUPARAMETER.fields_by_name[\'filler\'].message_type = _FILLERPARAMETER\nDESCRIPTOR.message_types_by_name[\'BlobShape\'] = _BLOBSHAPE\nDESCRIPTOR.message_types_by_name[\'BlobProto\'] = _BLOBPROTO\nDESCRIPTOR.message_types_by_name[\'BlobProtoVector\'] = _BLOBPROTOVECTOR\nDESCRIPTOR.message_types_by_name[\'Datum\'] = _DATUM\nDESCRIPTOR.message_types_by_name[\'FillerParameter\'] = _FILLERPARAMETER\nDESCRIPTOR.message_types_by_name[\'NetParameter\'] = _NETPARAMETER\nDESCRIPTOR.message_types_by_name[\'SolverParameter\'] = _SOLVERPARAMETER\nDESCRIPTOR.message_types_by_name[\'SolverState\'] = _SOLVERSTATE\nDESCRIPTOR.message_types_by_name[\'NetState\'] = _NETSTATE\nDESCRIPTOR.message_types_by_name[\'NetStateRule\'] = _NETSTATERULE\nDESCRIPTOR.message_types_by_name[\'ParamSpec\'] = _PARAMSPEC\nDESCRIPTOR.message_types_by_name[\'LayerParameter\'] = _LAYERPARAMETER\nDESCRIPTOR.message_types_by_name[\'TransformationParameter\'] = _TRANSFORMATIONPARAMETER\nDESCRIPTOR.message_types_by_name[\'LossParameter\'] = _LOSSPARAMETER\nDESCRIPTOR.message_types_by_name[\'AccuracyParameter\'] = _ACCURACYPARAMETER\nDESCRIPTOR.message_types_by_name[\'ArgMaxParameter\'] = _ARGMAXPARAMETER\nDESCRIPTOR.message_types_by_name[\'ConcatParameter\'] = _CONCATPARAMETER\nDESCRIPTOR.message_types_by_name[\'BatchNormParameter\'] = _BATCHNORMPARAMETER\nDESCRIPTOR.message_types_by_name[\'BiasParameter\'] = _BIASPARAMETER\nDESCRIPTOR.message_types_by_name[\'ContrastiveLossParameter\'] = _CONTRASTIVELOSSPARAMETER\nDESCRIPTOR.message_types_by_name[\'ConvolutionParameter\'] = _CONVOLUTIONPARAMETER\nDESCRIPTOR.message_types_by_name[\'CropParameter\'] = _CROPPARAMETER\nDESCRIPTOR.message_types_by_name[\'DataParameter\'] = _DATAPARAMETER\nDESCRIPTOR.message_types_by_name[\'DropoutParameter\'] = _DROPOUTPARAMETER\nDESCRIPTOR.message_types_by_name[\'DummyDataParameter\'] = _DUMMYDATAPARAMETER\nDESCRIPTOR.message_types_by_name[\'EltwiseParameter\'] = _ELTWISEPARAMETER\nDESCRIPTOR.message_types_by_name[\'ELUParameter\'] = _ELUPARAMETER\nDESCRIPTOR.message_types_by_name[\'EmbedParameter\'] = _EMBEDPARAMETER\nDESCRIPTOR.message_types_by_name[\'ExpParameter\'] = _EXPPARAMETER\nDESCRIPTOR.message_types_by_name[\'FlattenParameter\'] = _FLATTENPARAMETER\nDESCRIPTOR.message_types_by_name[\'HDF5DataParameter\'] = _HDF5DATAPARAMETER\nDESCRIPTOR.message_types_by_name[\'HDF5OutputParameter\'] = _HDF5OUTPUTPARAMETER\nDESCRIPTOR.message_types_by_name[\'HingeLossParameter\'] = _HINGELOSSPARAMETER\nDESCRIPTOR.message_types_by_name[\'ImageDataParameter\'] = _IMAGEDATAPARAMETER\nDESCRIPTOR.message_types_by_name[\'InfogainLossParameter\'] = _INFOGAINLOSSPARAMETER\nDESCRIPTOR.message_types_by_name[\'InnerProductParameter\'] = _INNERPRODUCTPARAMETER\nDESCRIPTOR.message_types_by_name[\'InputParameter\'] = _INPUTPARAMETER\nDESCRIPTOR.message_types_by_name[\'LogParameter\'] = _LOGPARAMETER\nDESCRIPTOR.message_types_by_name[\'LRNParameter\'] = _LRNPARAMETER\nDESCRIPTOR.message_types_by_name[\'MemoryDataParameter\'] = _MEMORYDATAPARAMETER\nDESCRIPTOR.message_types_by_name[\'MVNParameter\'] = _MVNPARAMETER\nDESCRIPTOR.message_types_by_name[\'PoolingParameter\'] = _POOLINGPARAMETER\nDESCRIPTOR.message_types_by_name[\'PowerParameter\'] = _POWERPARAMETER\nDESCRIPTOR.message_types_by_name[\'PythonParameter\'] = _PYTHONPARAMETER\nDESCRIPTOR.message_types_by_name[\'ReductionParameter\'] = _REDUCTIONPARAMETER\nDESCRIPTOR.message_types_by_name[\'ReLUParameter\'] = _RELUPARAMETER\nDESCRIPTOR.message_types_by_name[\'ReshapeParameter\'] = _RESHAPEPARAMETER\nDESCRIPTOR.message_types_by_name[\'ScaleParameter\'] = _SCALEPARAMETER\nDESCRIPTOR.message_types_by_name[\'SigmoidParameter\'] = _SIGMOIDPARAMETER\nDESCRIPTOR.message_types_by_name[\'SliceParameter\'] = _SLICEPARAMETER\nDESCRIPTOR.message_types_by_name[\'SoftmaxParameter\'] = _SOFTMAXPARAMETER\nDESCRIPTOR.message_types_by_name[\'TanHParameter\'] = _TANHPARAMETER\nDESCRIPTOR.message_types_by_name[\'TileParameter\'] = _TILEPARAMETER\nDESCRIPTOR.message_types_by_name[\'ThresholdParameter\'] = _THRESHOLDPARAMETER\nDESCRIPTOR.message_types_by_name[\'WindowDataParameter\'] = _WINDOWDATAPARAMETER\nDESCRIPTOR.message_types_by_name[\'SPPParameter\'] = _SPPPARAMETER\nDESCRIPTOR.message_types_by_name[\'V1LayerParameter\'] = _V1LAYERPARAMETER\nDESCRIPTOR.message_types_by_name[\'V0LayerParameter\'] = _V0LAYERPARAMETER\nDESCRIPTOR.message_types_by_name[\'PReLUParameter\'] = _PRELUPARAMETER\n\nclass BlobShape(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _BLOBSHAPE\n\n  # @@protoc_insertion_point(class_scope:caffe.BlobShape)\n\nclass BlobProto(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _BLOBPROTO\n\n  # @@protoc_insertion_point(class_scope:caffe.BlobProto)\n\nclass BlobProtoVector(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _BLOBPROTOVECTOR\n\n  # @@protoc_insertion_point(class_scope:caffe.BlobProtoVector)\n\nclass Datum(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _DATUM\n\n  # @@protoc_insertion_point(class_scope:caffe.Datum)\n\nclass FillerParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _FILLERPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.FillerParameter)\n\nclass NetParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _NETPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.NetParameter)\n\nclass SolverParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _SOLVERPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.SolverParameter)\n\nclass SolverState(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _SOLVERSTATE\n\n  # @@protoc_insertion_point(class_scope:caffe.SolverState)\n\nclass NetState(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _NETSTATE\n\n  # @@protoc_insertion_point(class_scope:caffe.NetState)\n\nclass NetStateRule(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _NETSTATERULE\n\n  # @@protoc_insertion_point(class_scope:caffe.NetStateRule)\n\nclass ParamSpec(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _PARAMSPEC\n\n  # @@protoc_insertion_point(class_scope:caffe.ParamSpec)\n\nclass LayerParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _LAYERPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.LayerParameter)\n\nclass TransformationParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _TRANSFORMATIONPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.TransformationParameter)\n\nclass LossParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _LOSSPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.LossParameter)\n\nclass AccuracyParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _ACCURACYPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.AccuracyParameter)\n\nclass ArgMaxParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _ARGMAXPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.ArgMaxParameter)\n\nclass ConcatParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _CONCATPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.ConcatParameter)\n\nclass BatchNormParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _BATCHNORMPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.BatchNormParameter)\n\nclass BiasParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _BIASPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.BiasParameter)\n\nclass ContrastiveLossParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _CONTRASTIVELOSSPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.ContrastiveLossParameter)\n\nclass ConvolutionParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _CONVOLUTIONPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.ConvolutionParameter)\n\nclass CropParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _CROPPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.CropParameter)\n\nclass DataParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _DATAPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.DataParameter)\n\nclass DropoutParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _DROPOUTPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.DropoutParameter)\n\nclass DummyDataParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _DUMMYDATAPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.DummyDataParameter)\n\nclass EltwiseParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _ELTWISEPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.EltwiseParameter)\n\nclass ELUParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _ELUPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.ELUParameter)\n\nclass EmbedParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _EMBEDPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.EmbedParameter)\n\nclass ExpParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _EXPPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.ExpParameter)\n\nclass FlattenParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _FLATTENPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.FlattenParameter)\n\nclass HDF5DataParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _HDF5DATAPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.HDF5DataParameter)\n\nclass HDF5OutputParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _HDF5OUTPUTPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.HDF5OutputParameter)\n\nclass HingeLossParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _HINGELOSSPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.HingeLossParameter)\n\nclass ImageDataParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _IMAGEDATAPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.ImageDataParameter)\n\nclass InfogainLossParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _INFOGAINLOSSPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.InfogainLossParameter)\n\nclass InnerProductParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _INNERPRODUCTPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.InnerProductParameter)\n\nclass InputParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _INPUTPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.InputParameter)\n\nclass LogParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _LOGPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.LogParameter)\n\nclass LRNParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _LRNPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.LRNParameter)\n\nclass MemoryDataParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _MEMORYDATAPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.MemoryDataParameter)\n\nclass MVNParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _MVNPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.MVNParameter)\n\nclass PoolingParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _POOLINGPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.PoolingParameter)\n\nclass PowerParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _POWERPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.PowerParameter)\n\nclass PythonParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _PYTHONPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.PythonParameter)\n\nclass ReductionParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _REDUCTIONPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.ReductionParameter)\n\nclass ReLUParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _RELUPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.ReLUParameter)\n\nclass ReshapeParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _RESHAPEPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.ReshapeParameter)\n\nclass ScaleParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _SCALEPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.ScaleParameter)\n\nclass SigmoidParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _SIGMOIDPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.SigmoidParameter)\n\nclass SliceParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _SLICEPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.SliceParameter)\n\nclass SoftmaxParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _SOFTMAXPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.SoftmaxParameter)\n\nclass TanHParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _TANHPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.TanHParameter)\n\nclass TileParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _TILEPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.TileParameter)\n\nclass ThresholdParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _THRESHOLDPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.ThresholdParameter)\n\nclass WindowDataParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _WINDOWDATAPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.WindowDataParameter)\n\nclass SPPParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _SPPPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.SPPParameter)\n\nclass V1LayerParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _V1LAYERPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.V1LayerParameter)\n\nclass V0LayerParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _V0LAYERPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.V0LayerParameter)\n\nclass PReLUParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _PRELUPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.PReLUParameter)\n\n\n_BLOBSHAPE.fields_by_name[\'dim\'].has_options = True\n_BLOBSHAPE.fields_by_name[\'dim\']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), \'\\020\\001\')\n_BLOBPROTO.fields_by_name[\'data\'].has_options = True\n_BLOBPROTO.fields_by_name[\'data\']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), \'\\020\\001\')\n_BLOBPROTO.fields_by_name[\'diff\'].has_options = True\n_BLOBPROTO.fields_by_name[\'diff\']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), \'\\020\\001\')\n_BLOBPROTO.fields_by_name[\'double_data\'].has_options = True\n_BLOBPROTO.fields_by_name[\'double_data\']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), \'\\020\\001\')\n_BLOBPROTO.fields_by_name[\'double_diff\'].has_options = True\n_BLOBPROTO.fields_by_name[\'double_diff\']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), \'\\020\\001\')\n# @@protoc_insertion_point(module_scope)\n'"
kaffe/caffe/resolver.py,0,"b""import sys\n\nSHARED_CAFFE_RESOLVER = None\n\nclass CaffeResolver(object):\n    def __init__(self):\n        self.import_caffe()\n\n    def import_caffe(self):\n        self.caffe = None\n        try:\n            # Try to import PyCaffe first\n            import caffe\n            self.caffe = caffe\n        except ImportError:\n            # Fall back to the protobuf implementation\n            from . import caffepb\n            self.caffepb = caffepb\n            show_fallback_warning()\n        if self.caffe:\n            # Use the protobuf code from the imported distribution.\n            # This way, Caffe variants with custom layers will work.\n            self.caffepb = self.caffe.proto.caffe_pb2\n        self.NetParameter = self.caffepb.NetParameter\n\n    def has_pycaffe(self):\n        return self.caffe is not None\n\ndef get_caffe_resolver():\n    global SHARED_CAFFE_RESOLVER\n    if SHARED_CAFFE_RESOLVER is None:\n        SHARED_CAFFE_RESOLVER = CaffeResolver()\n    return SHARED_CAFFE_RESOLVER\n\ndef has_pycaffe():\n    return get_caffe_resolver().has_pycaffe()\n\ndef show_fallback_warning():\n    msg = '''\n------------------------------------------------------------\n    WARNING: PyCaffe not found!\n    Falling back to a pure protocol buffer implementation.\n    * Conversions will be drastically slower.\n    * This backend is UNTESTED!\n------------------------------------------------------------\n\n'''\n    sys.stderr.write(msg)\n"""
kaffe/tensorflow/__init__.py,0,b'from .transformer import TensorFlowTransformer\nfrom .network import Network\n'
kaffe/tensorflow/network.py,36,"b""import numpy as np\nimport tensorflow as tf\nslim = tf.contrib.slim\n\nDEFAULT_PADDING = 'SAME'\n\n\ndef layer(op):\n    '''Decorator for composable network layers.'''\n\n    def layer_decorated(self, *args, **kwargs):\n        # Automatically set a name if not provided.\n        name = kwargs.setdefault('name', self.get_unique_name(op.__name__))\n        # Figure out the layer inputs.\n        if len(self.terminals) == 0:\n            raise RuntimeError('No input variables found for layer %s.' % name)\n        elif len(self.terminals) == 1:\n            layer_input = self.terminals[0]\n        else:\n            layer_input = list(self.terminals)\n        # Perform the operation and get the output.\n        layer_output = op(self, layer_input, *args, **kwargs)\n        # Add to layer LUT.\n        self.layers[name] = layer_output\n        # This output is now the input for the next layer.\n        self.feed(layer_output)\n        # Return self for chained calls.\n        return self\n\n    return layer_decorated\n\n\nclass Network(object):\n\n    def __init__(self, inputs, options, trainable=True, is_training=False):\n        # The input nodes for this network\n        self.inputs = inputs\n        # The current list of terminal nodes\n        self.terminals = []\n        # Mapping from layer names to layers\n        self.layers = dict(inputs)\n        # If true, the resulting variables are set as trainable\n        self.trainable = trainable\n        # Switch variable for dropout\n        \n        # self.use_dropout = tf.placeholder_with_default(tf.constant(1.0),\n        #                                                shape=[],\n        #                                                name='use_dropout')\n\n        self.use_dropout = tf.placeholder_with_default(tf.cast(is_training, tf.float32),\n                                                       shape=[],\n                                                       name='use_dropout')\n        \n        self.setup(is_training, options=options)\n\n    def setup(self, is_training):\n        '''Construct the network. '''\n        raise NotImplementedError('Must be implemented by the subclass.')\n\n    def load(self, data_path, session, ignore_missing=False):\n        '''Load network weights.\n        data_path: The path to the numpy-serialized network weights\n        session: The current TensorFlow session\n        ignore_missing: If true, serialized weights for missing layers are ignored.\n        '''\n        data_dict = np.load(data_path).item()\n        for op_name in data_dict:\n            with tf.variable_scope(op_name, reuse=True):\n                for param_name, data in data_dict[op_name].iteritems():\n                    try:\n                        var = tf.get_variable(param_name)\n                        session.run(var.assign(data))\n                    except ValueError:\n                        if not ignore_missing:\n                            raise\n\n    def feed(self, *args):\n        '''Set the input(s) for the next operation by replacing the terminal nodes.\n        The arguments can be either layer names or the actual layers.\n        '''\n        assert len(args) != 0\n        self.terminals = []\n        for fed_layer in args:\n            if isinstance(fed_layer, basestring):\n                try:\n                    fed_layer = self.layers[fed_layer]\n                except KeyError:\n                    raise KeyError('Unknown layer name fed: %s' % fed_layer)\n            self.terminals.append(fed_layer)\n        return self\n\n    def get_output(self):\n        '''Returns the current network output.'''\n        return self.terminals[-1]\n\n    def get_unique_name(self, prefix):\n        '''Returns an index-suffixed unique name for the given prefix.\n        This is used for auto-generating layer names based on the type-prefix.\n        '''\n        ident = sum(t.startswith(prefix) for t, _ in self.layers.items()) + 1\n        return '%s_%d' % (prefix, ident)\n\n    def make_var(self, name, shape):\n        '''Creates a new TensorFlow variable.'''\n        return tf.get_variable(name, shape, trainable=self.trainable)\n\n    def validate_padding(self, padding):\n        '''Verifies that the padding is one of the supported ones.'''\n        assert padding in ('SAME', 'VALID')\n\n    @layer\n    def conv(self,\n             input,\n             k_h,\n             k_w,\n             c_o,\n             s_h,\n             s_w,\n             name,\n             relu=True,\n             padding=DEFAULT_PADDING,\n             group=1,\n             biased=True):\n        # Verify that the padding is acceptable\n        self.validate_padding(padding)\n        # Get the number of channels in the input\n        c_i = input.get_shape()[-1]\n        # Verify that the grouping parameter is valid\n        assert c_i % group == 0\n        assert c_o % group == 0\n        # Convolution for a given input and kernel\n        convolve = lambda i, k: tf.nn.conv2d(i, k, [1, s_h, s_w, 1], padding=padding)\n        with tf.variable_scope(name) as scope:\n            kernel = self.make_var('weights', shape=[k_h, k_w, c_i / group, c_o])\n            if group == 1:\n                # This is the common-case. Convolve the input without any further complications.\n                output = convolve(input, kernel)\n            else:\n                # Split the input into groups and then convolve each of them independently\n                input_groups = tf.split(3, group, input)\n                kernel_groups = tf.split(3, group, kernel)\n                output_groups = [convolve(i, k) for i, k in zip(input_groups, kernel_groups)]\n                # Concatenate the groups\n                output = tf.concat(3, output_groups)\n            # Add the biases\n            if biased:\n                biases = self.make_var('biases', [c_o])\n                output = tf.nn.bias_add(output, biases)\n            if relu:\n                # ReLU non-linearity\n                output = tf.nn.relu(output, name=scope.name)\n            return output\n\n    @layer\n    def atrous_conv(self,\n                    input,\n                    k_h,\n                    k_w,\n                    c_o,\n                    dilation,\n                    name,\n                    relu=True,\n                    padding=DEFAULT_PADDING,\n                    group=1,\n                    biased=True):\n        # Verify that the padding is acceptable\n        self.validate_padding(padding)\n        # Get the number of channels in the input\n        c_i = input.get_shape()[-1]\n        # Verify that the grouping parameter is valid\n        assert c_i % group == 0\n        assert c_o % group == 0\n        # Convolution for a given input and kernel\n        convolve = lambda i, k: tf.nn.atrous_conv2d(i, k, dilation, padding=padding)\n        with tf.variable_scope(name) as scope:\n            kernel = self.make_var('weights', shape=[k_h, k_w, c_i / group, c_o])\n            if group == 1:\n                # This is the common-case. Convolve the input without any further complications.\n                output = convolve(input, kernel)\n            else:\n                # Split the input into groups and then convolve each of them independently\n                input_groups = tf.split(3, group, input)\n                kernel_groups = tf.split(3, group, kernel)\n                output_groups = [convolve(i, k) for i, k in zip(input_groups, kernel_groups)]\n                # Concatenate the groups\n                output = tf.concat(3, output_groups)\n            # Add the biases\n            if biased:\n                biases = self.make_var('biases', [c_o])\n                output = tf.nn.bias_add(output, biases)\n            if relu:\n                # ReLU non-linearity\n                output = tf.nn.relu(output, name=scope.name)\n            return output\n        \n    @layer\n    def relu(self, input, name):\n        return tf.nn.relu(input, name=name)\n\n    @layer\n    def max_pool(self, input, k_h, k_w, s_h, s_w, name, padding=DEFAULT_PADDING):\n        self.validate_padding(padding)\n        return tf.nn.max_pool(input,\n                              ksize=[1, k_h, k_w, 1],\n                              strides=[1, s_h, s_w, 1],\n                              padding=padding,\n                              name=name)\n\n    @layer\n    def avg_pool(self, input, k_h, k_w, s_h, s_w, name, padding=DEFAULT_PADDING):\n        self.validate_padding(padding)\n        return tf.nn.avg_pool(input,\n                              ksize=[1, k_h, k_w, 1],\n                              strides=[1, s_h, s_w, 1],\n                              padding=padding,\n                              name=name)\n\n    @layer\n    def lrn(self, input, radius, alpha, beta, name, bias=1.0):\n        return tf.nn.local_response_normalization(input,\n                                                  depth_radius=radius,\n                                                  alpha=alpha,\n                                                  beta=beta,\n                                                  bias=bias,\n                                                  name=name)\n\n    @layer\n    def concat(self, inputs, axis, name):\n        return tf.concat(values=inputs, axis=axis, name=name)\n\n    @layer\n    def add(self, inputs, name):\n        return tf.add_n(inputs, name=name)\n\n    @layer\n    def fc(self, input, num_out, name, relu=True):\n        with tf.variable_scope(name) as scope:\n            input_shape = input.get_shape()\n            if input_shape.ndims == 4:\n                # The input is spatial. Vectorize it first.\n                dim = 1\n                for d in input_shape[1:].as_list():\n                    dim *= d\n                feed_in = tf.reshape(input, [-1, dim])\n            else:\n                feed_in, dim = (input, input_shape[-1].value)\n            weights = self.make_var('weights', shape=[dim, num_out])\n            biases = self.make_var('biases', [num_out])\n            op = tf.nn.relu_layer if relu else tf.nn.xw_plus_b\n            fc = op(feed_in, weights, biases, name=scope.name)\n            return fc\n\n    @layer\n    def softmax(self, input, name):\n        input_shape = map(lambda v: v.value, input.get_shape())\n        if len(input_shape) > 2:\n            # For certain models (like NiN), the singleton spatial dimensions\n            # need to be explicitly squeezed, since they're not broadcast-able\n            # in TensorFlow's NHWC ordering (unlike Caffe's NCHW).\n            if input_shape[1] == 1 and input_shape[2] == 1:\n                input = tf.squeeze(input, squeeze_dims=[1, 2])\n            else:\n                raise ValueError('Rank 2 tensor input expected for softmax!')\n        return tf.nn.softmax(input, name)\n        \n    @layer\n    def batch_normalization(self, input, name, is_training, activation_fn=None, scale=True):\n        with tf.variable_scope(name) as scope:\n            output = slim.batch_norm(\n                input,\n                activation_fn=activation_fn,\n                is_training=is_training,\n                updates_collections=None,\n                scale=scale,\n                scope=scope)\n            return output\n\n    @layer\n    def dropout(self, input, keep_prob, name):\n        keep = 1 - self.use_dropout + (self.use_dropout * keep_prob)\n        return tf.nn.dropout(input, keep, name=name)\n\n    @layer\n    def reshape(self, input, shape, name):\n        return tf.reshape(input, shape=shape, name=name)\n    \n\n    @layer\n    def tile(self, input, multiples, name):\n        return tf.tile(input, multiples=multiples, name=name)\n\n    @layer\n    def resize_bilinear(self, input, size, name):\n        return tf.image.resize_bilinear(input, size=size, name=name)\n    \n"""
kaffe/tensorflow/transformer.py,0,"b'import numpy as np\n\nfrom ..errors import KaffeError, print_stderr\nfrom ..graph import GraphBuilder, NodeMapper\nfrom ..layers import NodeKind\nfrom ..transformers import (DataInjector, DataReshaper, NodeRenamer, ReLUFuser,\n                            BatchNormScaleBiasFuser, BatchNormPreprocessor, ParameterNamer)\n\nfrom . import network\n\n\ndef get_padding_type(kernel_params, input_shape, output_shape):\n    \'\'\'Translates Caffe\'s numeric padding to one of (\'SAME\', \'VALID\').\n    Caffe supports arbitrary padding values, while TensorFlow only\n    supports \'SAME\' and \'VALID\' modes. So, not all Caffe paddings\n    can be translated to TensorFlow. There are some subtleties to\n    how the padding edge-cases are handled. These are described here:\n    https://github.com/Yangqing/caffe2/blob/master/caffe2/proto/caffe2_legacy.proto\n    \'\'\'\n    k_h, k_w, s_h, s_w, p_h, p_w = kernel_params\n    s_o_h = np.ceil(input_shape.height / float(s_h))\n    s_o_w = np.ceil(input_shape.width / float(s_w))\n    if (output_shape.height == s_o_h) and (output_shape.width == s_o_w):\n        return \'SAME\'\n    v_o_h = np.ceil((input_shape.height - k_h + 1.0) / float(s_h))\n    v_o_w = np.ceil((input_shape.width - k_w + 1.0) / float(s_w))\n    if (output_shape.height == v_o_h) and (output_shape.width == v_o_w):\n        return \'VALID\'\n    return None\n\n\nclass TensorFlowNode(object):\n    \'\'\'An intermediate representation for TensorFlow operations.\'\'\'\n\n    def __init__(self, op, *args, **kwargs):\n        # A string corresponding to the TensorFlow operation\n        self.op = op\n        # Positional arguments for the operation\n        self.args = args\n        # Keyword arguments for the operation\n        self.kwargs = list(kwargs.items())\n        # The source Caffe node\n        self.node = None\n\n    def format(self, arg):\n        \'\'\'Returns a string representation for the given value.\'\'\'\n        return ""\'%s\'"" % arg if isinstance(arg, basestring) else str(arg)\n\n    def pair(self, key, value):\n        \'\'\'Returns key=formatted(value).\'\'\'\n        return \'%s=%s\' % (key, self.format(value))\n\n    def emit(self):\n        \'\'\'Emits the Python source for this node.\'\'\'\n        # Format positional arguments\n        args = map(self.format, self.args)\n        # Format any keyword arguments\n        if self.kwargs:\n            args += [self.pair(k, v) for k, v in self.kwargs]\n        # Set the node name\n        args.append(self.pair(\'name\', self.node.name))\n        args = \', \'.join(args)\n        return \'%s(%s)\' % (self.op, args)\n\n\nclass MaybeActivated(object):\n\n    def __init__(self, node, default=True):\n        self.inject_kwargs = {}\n        if node.metadata.get(\'relu\', False) != default:\n            self.inject_kwargs[\'relu\'] = not default\n\n    def __call__(self, *args, **kwargs):\n        kwargs.update(self.inject_kwargs)\n        return TensorFlowNode(*args, **kwargs)\n\n\nclass TensorFlowMapper(NodeMapper):\n\n    def get_kernel_params(self, node):\n        kernel_params = node.layer.kernel_parameters\n        input_shape = node.get_only_parent().output_shape\n        padding = get_padding_type(kernel_params, input_shape, node.output_shape)\n        # Only emit the padding if it\'s not the default value.\n        padding = {\'padding\': padding} if padding != network.DEFAULT_PADDING else {}\n        return (kernel_params, padding)\n\n    def map_convolution(self, node):\n        (kernel_params, kwargs) = self.get_kernel_params(node)\n        h = kernel_params.kernel_h\n        w = kernel_params.kernel_w\n        c_o = node.output_shape[1]\n        c_i = node.parents[0].output_shape[1]\n        group = node.parameters.group\n        if group != 1:\n            kwargs[\'group\'] = group\n        if not node.parameters.bias_term:\n            kwargs[\'biased\'] = False\n        assert kernel_params.kernel_h == h\n        assert kernel_params.kernel_w == w\n        return MaybeActivated(node)(\'conv\', kernel_params.kernel_h, kernel_params.kernel_w, c_o,\n                                    kernel_params.stride_h, kernel_params.stride_w, **kwargs)\n\n    def map_relu(self, node):\n        return TensorFlowNode(\'relu\')\n\n    def map_pooling(self, node):\n        pool_type = node.parameters.pool\n        if pool_type == 0:\n            pool_op = \'max_pool\'\n        elif pool_type == 1:\n            pool_op = \'avg_pool\'\n        else:\n            # Stochastic pooling, for instance.\n            raise KaffeError(\'Unsupported pooling type.\')\n        (kernel_params, padding) = self.get_kernel_params(node)\n        return TensorFlowNode(pool_op, kernel_params.kernel_h, kernel_params.kernel_w,\n                              kernel_params.stride_h, kernel_params.stride_w, **padding)\n\n    def map_inner_product(self, node):\n        #TODO: Axis\n        assert node.parameters.axis == 1\n        #TODO: Unbiased\n        assert node.parameters.bias_term == True\n        return MaybeActivated(node)(\'fc\', node.parameters.num_output)\n\n    def map_softmax(self, node):\n        return TensorFlowNode(\'softmax\')\n\n    def map_lrn(self, node):\n        params = node.parameters\n        # The window size must be an odd value. For a window\n        # size of (2*n+1), TensorFlow defines depth_radius = n.\n        assert params.local_size % 2 == 1\n        # Caffe scales by (alpha/(2*n+1)), whereas TensorFlow\n        # just scales by alpha (as does Krizhevsky\'s paper).\n        # We\'ll account for that here.\n        alpha = params.alpha / float(params.local_size)\n        return TensorFlowNode(\'lrn\', int(params.local_size / 2), alpha, params.beta)\n\n    def map_concat(self, node):\n        axis = (2, 3, 1, 0)[node.parameters.axis]\n        return TensorFlowNode(\'concat\', axis)\n\n    def map_dropout(self, node):\n        return TensorFlowNode(\'dropout\', node.parameters.dropout_ratio)\n\n    def map_batch_norm(self, node):\n        scale_offset = len(node.data) == 4\n        kwargs = {\'is_training\': True} if scale_offset else {\'is_training\': True, \'scale\': False}\n        return MaybeActivated(node, default=False)(\'batch_normalization\', **kwargs)\n\n    def map_eltwise(self, node):\n        operations = {0: \'multiply\', 1: \'add\', 2: \'max\'}\n        op_code = node.parameters.operation\n        try:\n            return TensorFlowNode(operations[op_code])\n        except KeyError:\n            raise KaffeError(\'Unknown elementwise operation: {}\'.format(op_code))\n\n    def commit(self, chains):\n        return chains\n\n\nclass TensorFlowEmitter(object):\n\n    def __init__(self, tab=None):\n        self.tab = tab or \' \' * 4\n        self.prefix = \'\'\n\n    def indent(self):\n        self.prefix += self.tab\n\n    def outdent(self):\n        self.prefix = self.prefix[:-len(self.tab)]\n\n    def statement(self, s):\n        return self.prefix + s + \'\\n\'\n\n    def emit_imports(self):\n        return self.statement(\'from kaffe.tensorflow import Network\\n\')\n\n    def emit_class_def(self, name):\n        return self.statement(\'class %s(Network):\' % (name))\n\n    def emit_setup_def(self):\n        return self.statement(\'def setup(self):\')\n\n    def emit_parents(self, chain):\n        assert len(chain)\n        s = \'(self.feed(\'\n        sep = \', \\n\' + self.prefix + (\' \' * len(s))\n        s += sep.join([""\'%s\'"" % parent.name for parent in chain[0].node.parents])\n        return self.statement(s + \')\')\n\n    def emit_node(self, node):\n        return self.statement(\' \' * 5 + \'.\' + node.emit())\n\n    def emit(self, name, chains):\n        s = self.emit_imports()\n        s += self.emit_class_def(name)\n        self.indent()\n        s += self.emit_setup_def()\n        self.indent()\n        blocks = []\n        for chain in chains:\n            b = \'\'\n            b += self.emit_parents(chain)\n            for node in chain:\n                b += self.emit_node(node)\n            blocks.append(b[:-1] + \')\')\n        s = s + \'\\n\\n\'.join(blocks)\n        return s\n\n\nclass TensorFlowTransformer(object):\n\n    def __init__(self, def_path, data_path, verbose=True, phase=\'test\'):\n        self.verbose = verbose\n        self.phase = phase\n        self.load(def_path, data_path, phase)\n        self.params = None\n        self.source = None\n\n    def load(self, def_path, data_path, phase):\n        # Build the graph\n        graph = GraphBuilder(def_path, phase).build()\n\n        if data_path is not None:\n            # Load and associate learned parameters\n            graph = DataInjector(def_path, data_path)(graph)\n\n        # Transform the graph\n        transformers = [\n            # Fuse split batch normalization layers\n            BatchNormScaleBiasFuser(),\n\n            # Fuse ReLUs\n            # TODO: Move non-linearity application to layer wrapper, allowing\n            # any arbitrary operation to be optionally activated.\n            ReLUFuser(allowed_parent_types=[NodeKind.Convolution, NodeKind.InnerProduct,\n                                            NodeKind.BatchNorm]),\n\n            # Rename nodes\n            # Slashes are used for scoping in TensorFlow. Replace slashes\n            # in node names with underscores.\n            # (Caffe\'s GoogLeNet implementation uses slashes)\n            NodeRenamer(lambda node: node.name.replace(\'/\', \'_\'))\n        ]\n        self.graph = graph.transformed(transformers)\n\n        # Display the graph\n        if self.verbose:\n            print_stderr(self.graph)\n\n    def transform_data(self):\n        if self.params is None:\n            transformers = [\n\n                # Reshape the parameters to TensorFlow\'s ordering\n                DataReshaper({\n                    # (c_o, c_i, h, w) -> (h, w, c_i, c_o)\n                    NodeKind.Convolution: (2, 3, 1, 0),\n\n                    # (c_o, c_i) -> (c_i, c_o)\n                    NodeKind.InnerProduct: (1, 0)\n                }),\n\n                # Pre-process batch normalization data\n                BatchNormPreprocessor(),\n\n                # Convert parameters to dictionaries\n                ParameterNamer(),\n            ]\n            self.graph = self.graph.transformed(transformers)\n            self.params = {node.name: node.data for node in self.graph.nodes if node.data}\n        return self.params\n\n    def transform_source(self):\n        if self.source is None:\n            mapper = TensorFlowMapper(self.graph)\n            chains = mapper.map()\n            emitter = TensorFlowEmitter()\n            self.source = emitter.emit(self.graph.name, chains)\n        return self.source\n'"
pool/models/add_texture.py,0,"b""import csv\nimport sys\nimport numpy as np\nimport cv2\n\ntexture = cv2.imread(sys.argv[3])\n\nwith open(sys.argv[1]) as modelFile, open(sys.argv[2], 'w') as outputFile:\n    modelLoader = csv.reader(modelFile, delimiter=' ')\n    xs = []\n    ys = []\n    zs = []        \n    for lineIndex, line in enumerate(modelLoader):\n        if len(line) == 0:\n            outputFile.write('\\n')\n            continue\n        if line[0] == 'vt':\n            continue\n        if line[0] == 'v':\n            line = line[:4]\n            u = max(min(int(round((1 + float(line[1])) * 0.5 * texture.shape[1])), texture.shape[1] - 1), 0)\n            v = max(min(int(round((1 + float(line[2])) * 0.5 * texture.shape[0])), texture.shape[0] - 1), 0)\n            print(u, v)\n            color = texture[v][u].astype(np.float32) / 255\n            line.append(str(color[2]))\n            line.append(str(color[1]))\n            line.append(str(color[0]))\n            pass\n        outputFile.write(' '.join(line) + '\\n')\n        continue\n    modelFile.close()\n    outputFile.close()\n    pass\n"""
pool/models/move_to_origin.py,0,"b""import csv\nimport sys\nimport numpy as np\n\nwith open(sys.argv[1]) as modelFile:\n    modelLoader = csv.reader(modelFile, delimiter=' ')\n    xs = []\n    ys = []\n    zs = []        \n    for lineIndex, line in enumerate(modelLoader):\n        if len(line) == 0:\n            continue\n        if line[0] == 'v':\n            xs.append(float(line[1]))\n            ys.append(float(line[2]))\n            zs.append(float(line[3]))\n            pass\n        continue\n    modelFile.close()\n    pass\n\nxs = np.array(xs)\nys = np.array(ys)\nzs = np.array(zs)\nprint(xs.shape)\nminX = xs.min()\nmaxX = xs.max()\nminY = ys.min()\nmaxY = ys.max()\nminZ = zs.min()\nmaxZ = zs.max()\ncenterX = (minX + maxX) / 2\ncenterY = (minY + maxY) / 2\ncenterZ = (minZ + maxZ) / 2\nsizeX = (maxX - minX)\nsizeY = (maxY - minY)\nsizeZ = (maxZ - minZ)\nscale = 2 / max(sizeX, sizeY, sizeZ)\n\nwith open(sys.argv[1]) as modelFile, open(sys.argv[2], 'w') as outputFile:\n    modelLoader = csv.reader(modelFile, delimiter=' ')\n    xs = []\n    ys = []\n    zs = []        \n    for lineIndex, line in enumerate(modelLoader):\n        if len(line) == 0:\n            outputFile.write('\\n')\n            continue\n        if line[0] == 'v':\n            line[1] = str((float(line[1]) - centerX) * scale)\n            line[2] = str((float(line[2]) - centerY) * scale)\n            line[3] = str((float(line[3]) - centerZ) * scale)\n            pass\n        outputFile.write(' '.join(line) + '\\n')\n        continue\n    modelFile.close()\n    outputFile.close()\n    pass\n"""
pool/models/obj2egg.py,0,"b'#!/usr/bin/python\n""""""\n    This Version: $Id: obj2egg.py,v 1.7 2008/05/26 17:42:53 andyp Exp $\n    Info: info >at< pfastergames.com\n\n    Extended from: http://panda3d.org/phpbb2/viewtopic.php?t=3378\n    .___..__ .___.___.___.__..__ .  .\n      |  [__)[__ [__ [__ |  |[__)|\\/|\n      |  |  \\[___[___|   |__||  \\|  |\n    obj2egg.py [n##][b][t][s] filename1.obj ...\n        -n regenerate normals with # degree smoothing\n            exaple -n30  (normals at less 30 degrees will be smoothed)\n        -b make binarmals\n        -t make tangents\n        -s show in pview\n\n    licensed under WTFPL (http://sam.zoy.org/wtfpl/)\n""""""\n\nfrom pandac.PandaModules import *\nimport math\nimport string\nimport getopt\nimport sys, os\n\n\ndef floats(float_list):\n    """"""coerce a list of strings that represent floats into a list of floats""""""\n    return [ float(number) for number in float_list ]\n\ndef ints(int_list):\n    """"""coerce a list of strings that represent integers into a list of integers""""""\n    return [ int(number) for number in int_list ]\n\n\nclass ObjMaterial:\n    """"""a wavefront material""""""\n    def __init__(self):\n        self.filename = None\n        self.name = ""default""\n        self.eggdiffusetexture = None\n        self.eggmaterial = None\n        self.attrib = {}\n        self.attrib[""Ns""] = 100.0\n        self.attrib[""d""] = 1.0\n        self.attrib[""illum""] = 2\n        # ""magenta""\n        self.attrib[""Kd""] = [1.0, 1.0, 1.0]\n        self.attrib[""Ka""] = [0.0, 0.0, 0.0]\n        self.attrib[""Ks""] = [0.0, 0.0, 0.0]\n        self.attrib[""Ke""] = [0.0, 0.0, 0.0]\n\n    def put(self, key, value):\n        self.attrib[key] = value\n        return self\n\n    def get(self, key):\n        if self.attrib.has_key(key):\n            return self.attrib[key]\n        return None\n\n    def has_key(self, key):\n        return self.attrib.has_key(key)\n\n    def isTextured(self):\n        # for k in (""map_Kd"", ""map_Bump"", ""map_Ks""):    <-- NOT YET\n        if self.attrib.has_key(""map_Kd""):\n            return True;\n        return False;\n\n    def getEggTexture(self):\n        if self.eggdiffusetexture:\n            return self.eggdiffusetexture\n        if not self.isTextured():\n            return None\n        m = EggTexture(self.name + ""_diffuse"", self.get(""map_Kd""))\n        m.setFormat(EggTexture.FRgb)\n        m.setMagfilter(EggTexture.FTLinearMipmapLinear)\n        m.setMinfilter(EggTexture.FTLinearMipmapLinear)\n        m.setWrapU(EggTexture.WMRepeat)\n        m.setWrapV(EggTexture.WMRepeat)\n        self.eggdiffusetexture = m\n        return self.eggdiffusetexture\n\n    def getEggMaterial(self):\n        if self.eggmaterial:\n            return self.eggmaterial\n        m = EggMaterial(self.name + ""_mat"")\n        # XXX TODO: add support for specular, and obey illum setting\n        # XXX as best as we can\n        rgb = self.get(""Kd"")\n        if rgb is not None:\n            m.setDiff(Vec4(rgb[0], rgb[1], rgb[2], 1.0))\n        rgb = self.get(""Ka"")\n        if rgb is not None:\n            m.setAmb(Vec4(rgb[0], rgb[1], rgb[2], 1.0))\n        rgb = self.get(""Ks"")\n        if rgb is not None:\n            m.setSpec(Vec4(rgb[0], rgb[1], rgb[2], 1.0))\n        ns = self.get(""Ns"")\n        if ns is not None:\n            m.setShininess(ns)\n        self.eggmaterial = m\n        return self.eggmaterial\n\nclass MtlFile:\n    """"""an object representing all Wavefront materials in a .mtl file""""""\n    def __init__(self, filename=None):\n        self.filename = None\n        self.materials = {}\n        self.comments = {}\n        if filename is not None:\n            self.read(filename)\n\n    def read(self, filename, verbose=False):\n        self.filename = filename\n        self.materials = {}\n        self.comments = {}\n        try:\n            file = open(filename)\n        except:\n            return self\n        linenumber = 0\n        mat = None\n        for line in file.readlines():\n            line = line.strip()\n            linenumber = linenumber + 1\n            if not line:\n                continue\n            if line[0] == \'#\':\n                self.comments[linenumber] = line\n                print line\n                continue\n            tokens = line.split()\n            if not tokens:\n                continue\n            if verbose: print ""tokens[0]:"", tokens\n            if tokens[0] == ""newmtl"":\n                mat = ObjMaterial()\n                mat.filename = filename\n                mat.name = tokens[1]\n                self.materials[mat.name] = mat\n                if verbose: print ""newmtl:"", mat.name\n                continue\n            if tokens[0] in (""Ns"", ""d"", ""Tr""):\n                # ""d factor"" - specifies the dissovle for the current material,\n                #              1.0 is full opaque\n                # ""Ns exponent"" - specifies the specular exponent.  A high exponent\n                #               results in a tight, concentrated highlight.\n                mat.put(tokens[0], float(tokens[1]))\n                continue\n            if tokens[0] in (""illum""):\n                # according to http://www.fileformat.info/format/material/\n                # 0 = Color on and Ambient off\n                # 1 = Color on and Ambient on\n                # 2 = Highlight on\n                # 3 = Reflection on and Ray trace on\n                # 4 = Transparency: Glass on, Reflection: Ray trace on\n                # 5 = Reflection: Fesnel on and Ray trace on\n                # 6 = Transparency: Refraction on, Reflection: Fresnel off and Ray trace on\n                # 7 = Transparency: Refraction on, Refelction: Fresnel on and Ray Trace on\n                # 8 = Reflection on and Ray trace off\n                # 9 = Transparency: Glass on, Reflection: Ray trace off\n                # 10 = Casts shadows onto invisible surfaces\n                mat.put(tokens[0], int(tokens[1]))\n                continue\n            if tokens[0] in (""Kd"", ""Ka"", ""Ks"", ""Ke""):\n                mat.put(tokens[0], floats(tokens[1:]))\n                continue\n            if tokens[0] in (""map_Kd"", ""map_Bump"", ""map_Ks"", ""map_bump"", ""bump""):\n                # Ultimate Unwrap 3D Pro emits these:\n                # map_Kd == diffuse\n                # map_Bump == bump\n                # map_Ks == specular\n                mat.put(tokens[0], pathify(tokens[1]))\n                if verbose: print ""map:"", mat.name, tokens[0], mat.get(tokens[0])\n                continue\n            if tokens[0] in (""Ni""):\n                # blender\'s .obj exporter can emit this ""Ni 1.000000""\n                mat.put(tokens[0], float(tokens[1]))\n                continue\n            print ""file \\""%s\\"": line %d: unrecognized:"" % (filename, linenumber), tokens\n        file.close()\n        if verbose: print ""%d materials"" % len(self.materials), ""loaded from"", filename\n        return self\n\nclass ObjFile:\n    """"""a representation of a wavefront .obj file""""""\n    def __init__(self, filename=None):\n        self.filename = None\n        self.objects = [""defaultobject""]\n        self.groups = [""defaultgroup""]\n        self.points = []\n        self.uvs = []\n        self.normals = []\n        self.faces = []\n        self.polylines = []\n        self.matlibs = []\n        self.materialsbyname = {}\n        self.comments = {}\n        self.currentobject = self.objects[0]\n        self.currentgroup = self.groups[0]\n        self.currentmaterial = None\n        if filename is not None:\n            self.read(filename)\n\n    def read(self, filename, verbose=False):\n        if verbose: print ""ObjFile.read:"", ""filename:"", filename\n        self.filename = filename\n        self.objects = [""defaultobject""]\n        self.groups = [""defaultgroup""]\n        self.points = []\n        self.uvs = []\n        self.normals = []\n        self.faces = []\n        self.polylines = []\n        self.matlibs = []\n        self.materialsbyname = {}\n        self.comments = {}\n        self.currentobject = self.objects[0]\n        self.currentgroup = self.groups[0]\n        self.currentmaterial = None\n        try:\n            file = open(filename)\n        except:\n            return self\n        linenumber = 0\n        for line in file.readlines():\n            line = line.strip()\n            linenumber = linenumber + 1\n            if not line:\n                continue\n            if line[0] == \'#\':\n                self.comments[linenumber] = line\n                print line\n                continue\n            tokens = line.split()\n            if not tokens:\n                continue\n            if tokens[0] == ""mtllib"":\n                if verbose: print ""mtllib:"", tokens[1:]\n                mtllib = MtlFile(tokens[1])\n                # if verbose: print mtllib\n                self.matlibs.append(mtllib)\n                self.indexmaterials(mtllib)\n                continue\n            if tokens[0] == ""g"":\n                if verbose: print ""g:"", tokens[1:]\n                self.__newgroup("""".join(tokens[1:]))\n                continue\n            if tokens[0] == ""o"":\n                if verbose: print ""o:"", tokens[1:]\n                self.__newobject("""".join(tokens[1:]))\n                continue\n            if tokens[0] == ""usemtl"":\n                if verbose: print ""usemtl:"", tokens[1:]\n                self.__usematerial(tokens[1])\n                continue\n            if tokens[0] == ""v"":\n                if verbose: print ""v:"", tokens[1:]\n                self.__newv(tokens[1:])\n                continue\n            if tokens[0] == ""vn"":\n                if verbose: print ""vn:"", tokens[1:]\n                self.__newnormal(tokens[1:])\n                continue\n            if tokens[0] == ""vt"":\n                if verbose: print ""vt:"", tokens[1:]\n                self.__newuv(tokens[1:])\n                continue\n            if tokens[0] == ""f"":\n                if verbose: print ""f:"", tokens[1:]\n                self.__newface(tokens[1:])\n                continue\n            if tokens[0] == ""s"":\n                # apparently, this enables/disables smoothing\n                print ""%s:%d:"" % (filename, linenumber), ""ignoring:"", tokens\n                continue\n            if tokens[0] == ""l"":\n                if verbose: print ""l:"", tokens[1:]\n                self.__newpolyline(tokens[1:])\n                continue\n            print ""%s:%d:"" % (filename, linenumber), ""unknown:"", tokens\n        file.close()\n        return self\n\n    def __vertlist(self, lst):\n        res = []\n        for vert in lst:\n            vinfo = vert.split(""/"")\n            vlen = len(vinfo)\n            vertex = {\'v\':None, \'vt\':None, \'vn\':None}\n            if vlen == 1:\n                vertex[\'v\'] = int(vinfo[0])\n            elif vlen == 2:\n                if vinfo[0] != \'\':\n                    vertex[\'v\'] = int(vinfo[0])\n                if vinfo[1] != \'\':\n                    vertex[\'vt\'] = int(vinfo[1])\n            elif vlen == 3:\n                if vinfo[0] != \'\':\n                    vertex[\'v\'] = int(vinfo[0])\n                if vinfo[1] != \'\':\n                    vertex[\'vt\'] = int(vinfo[1])\n                if vinfo[2] != \'\':\n                    vertex[\'vn\'] = int(vinfo[2])\n            else:\n                print ""aborting...""\n                raise UNKNOWN, res\n            res.append(vertex)\n        if False: print res\n        return res\n\n    def __enclose(self, lst):\n        mdata = (self.currentobject, self.currentgroup, self.currentmaterial)\n        return (lst, mdata)\n\n    def __newpolyline(self, l):\n        polyline = self.__vertlist(l)\n        if False: print ""__newline:"", polyline\n        self.polylines.append(self.__enclose(polyline))\n        return self\n\n    def __newface(self, f):\n        face = self.__vertlist(f)\n        if False: print face\n        self.faces.append(self.__enclose(face))\n        return self\n\n    def __newuv(self, uv):\n        self.uvs.append(floats(uv))\n        return self\n\n    def __newnormal(self, normal):\n        self.normals.append(floats(normal))\n        return self\n\n    def __newv(self, v):\n        # capture the current metadata with vertices\n        vdata = floats(v)\n        mdata = (self.currentobject, self.currentgroup, self.currentmaterial)\n        vinfo = (vdata, mdata)\n        self.points.append(vinfo)\n        return self\n\n    def indexmaterials(self, mtllib, verbose=False):\n        # traverse the materials defined in mtllib, indexing\n        # them by name.\n        for mname in mtllib.materials:\n            mobj = mtllib.materials[mname]\n            self.materialsbyname[mobj.name] = mobj\n        if verbose: \n            print ""indexmaterials:"", mtllib.filename, ""materials:"", self.materialsbyname.keys()\n        return self\n\n    def __closeobject(self):\n        self.currentobject = ""defaultobject""\n        return self\n\n    def __newobject(self, object):\n        self.__closeobject()\n        if False: print ""__newobject:"", ""object:"", object\n        self.currentobject = object\n        self.objects.append(object)\n        return self\n\n    def __closegroup(self):\n        self.currentgroup = ""defaultgroup""\n        return self\n\n    def __newgroup(self, group):\n        self.__closegroup()\n        if False: print ""__newgroup:"", ""group:"", group\n        self.currentgroup = group\n        self.groups.append(group)\n        return self\n\n    def __usematerial(self, material):\n        if False: print ""__usematerial:"", ""material:"", material\n        if self.materialsbyname.has_key(material):\n            self.currentmaterial = material\n        else:\n            print ""warning:"", ""__usematerial:"", ""unknown material:"", material\n        return self\n\n    def __itemsby(self, itemlist, objname, groupname):\n        res = []\n        for item in itemlist:\n            vlist, mdata = item\n            wobj, wgrp, wmat = mdata\n            if (wobj == objname) and (wgrp == groupname):\n                res.append(item)\n        return res\n\n    def __facesby(self, objname, groupname):\n        return self.__itemsby(self.faces, objname, groupname)\n\n    def __linesby(self, objname, groupname):\n        return self.__itemsby(self.polylines, objname, groupname)\n\n    def __eggifyverts(self, eprim, evpool, vlist):\n        for vertex in vlist:\n            ixyz = vertex[\'v\']\n            vinfo = self.points[ixyz-1]\n            vxyz, vmeta = vinfo\n            ev = EggVertex()\n            ev.setPos(Point3D(vxyz[0], vxyz[1], vxyz[2]))\n            iuv = vertex[\'vt\']\n            if iuv is not None:\n                vuv = self.uvs[iuv-1]\n                ev.setUv(Point2D(vuv[0], vuv[1]))\n            inormal = vertex[\'vn\']\n            if inormal is not None:\n                vn = self.normals[inormal-1]\n                ev.setNormal(Vec3D(vn[0], vn[1], vn[2]))\n            evpool.addVertex(ev)\n            eprim.addVertex(ev)\n        return self\n\n    def __eggifymats(self, eprim, wmat):\n        if self.materialsbyname.has_key(wmat):\n            mtl = self.materialsbyname[wmat]\n            if mtl.isTextured():\n                eprim.setTexture(mtl.getEggTexture())\n                # NOTE: it looks like you almost always want to setMaterial()\n                #       for textured polys.... [continued below...]\n                eprim.setMaterial(mtl.getEggMaterial())\n            rgb = mtl.get(""Kd"")\n            if rgb is not None:\n                # ... and some untextured .obj\'s store the color of the\n                # material # in the Kd settings...\n                eprim.setColor(Vec4(rgb[0], rgb[1], rgb[2], 1.0))\n            # [continued...] but you may *not* always want to assign\n            # materials to untextured polys...  hmmmm.\n            if False:\n                eprim.setMaterial(mtl.getEggMaterial())\n        return self\n\n    def __facestoegg(self, egg, objname, groupname):\n        selectedfaces = self.__facesby(objname, groupname)\n        if len(selectedfaces) == 0:\n            return self\n        eobj = EggGroup(objname)\n        egg.addChild(eobj)\n        egrp = EggGroup(groupname)\n        eobj.addChild(egrp)\n        evpool = EggVertexPool(groupname)\n        egrp.addChild(evpool)\n        for face in selectedfaces:\n            vlist, mdata = face\n            wobj, wgrp, wmat = mdata\n            epoly = EggPolygon()\n            egrp.addChild(epoly)\n            self.__eggifymats(epoly, wmat)\n            self.__eggifyverts(epoly, evpool, vlist)\n        #; each matching face\n        return self\n\n    def __polylinestoegg(self, egg, objname, groupname):\n        selectedlines = self.__linesby(objname, groupname)\n        if len(selectedlines) == 0:\n            return self\n        eobj = EggGroup(objname)\n        egg.addChild(eobj)\n        egrp = EggGroup(groupname)\n        eobj.addChild(egrp)\n        evpool = EggVertexPool(groupname)\n        egrp.addChild(evpool)\n        for line in selectedlines:\n            vlist, mdata = line\n            wobj, wgrp, wmat = mdata\n            eline = EggLine()\n            egrp.addChild(eline)\n            self.__eggifymats(eline, wmat)\n            self.__eggifyverts(eline, evpool, vlist)\n        #; each matching line\n        return self\n\n    def toEgg(self, verbose=True):\n        if verbose: print ""converting...""\n        # make a new egg\n        egg = EggData()\n        # convert polygon faces\n        if len(self.faces) > 0:\n            for objname in self.objects:\n                for groupname in self.groups:\n                    self.__facestoegg(egg, objname, groupname)\n        # convert polylines\n        if len(self.polylines) > 0:\n            for objname in self.objects:\n                for groupname in self.groups:\n                    self.__polylinestoegg(egg, objname, groupname)\n        return egg\n\ndef pathify(path):\n    if os.path.isfile(path):\n        return path\n    # if it was written on win32, it may have \\\'s in it, and\n    # also a full rather than relative pathname (Hexagon does this... ick)\n    orig = path\n    path = path.lower()\n    path = path.replace(""\\\\"", ""/"")\n    h, t = os.path.split(path)\n    if os.path.isfile(t):\n        return t\n    print ""warning: can\'t make sense of this map file name:"", orig\n    return t\n    \ndef main(argv=None):\n    if argv is None:\n        argv = sys.argv\n    try:\n        opts, args = getopt.getopt(argv[1:], ""hn:bs"", [""help"", ""normals"", ""binormals"", ""show""])\n    except getopt.error, msg:\n        print msg\n        print __doc__\n        return 2\n    show = False\n    for o, a in opts:\n        if o in (""-h"", ""--help""):\n            print __doc__\n            return 0\n        elif o in (""-s"", ""--show""):\n            show = True\n    for infile in args:\n        try:\n            if "".obj"" not in infile:\n                print ""WARNING"", finfile, ""does not look like a valid obj file""\n                continue\n            obj = ObjFile(infile)\n            egg = obj.toEgg()\n            f, e = os.path.splitext(infile)\n            outfile = f + "".egg""\n            for o, a in opts:\n                if o in (""-n"", ""--normals""):\n                    egg.recomputeVertexNormals(float(a))\n                elif o in (""-b"", ""--binormals""):\n                    egg.recomputeTangentBinormal(GlobPattern(""""))\n            egg.removeUnusedVertices(GlobPattern(""""))\n            if True:\n                egg.triangulatePolygons(EggData.TConvex & EggData.TPolygon)\n            if True:\n                egg.recomputePolygonNormals()\n            egg.writeEgg(Filename(outfile))\n            if show:\n                os.system(""pview "" + outfile)\n        except Exception,e:\n            print e\n    return 0\n\nif __name__ == ""__main__"":\n    sys.exit(main())\n\n\n'"
pool/models/writeDisk.py,0,"b'import csv\nimport sys\nimport numpy as np\nimport cv2\n\ntexture = cv2.imread(sys.argv[1])\ntexture = cv2.resize(texture, (256, 256))\ntextureWidth = texture.shape[1]\ntextureHeight = texture.shape[0]\n\nnumPoints = 0\nfaces = []\nindicesMap = {}\nfor y in xrange(textureHeight):\n    for x in xrange(textureWidth):\n        if np.sqrt(pow(x - textureWidth / 2, 2) + pow(y - textureHeight / 2, 2)) < min(textureHeight, textureWidth) / 2:\n            indicesMap[y * textureWidth + x] = numPoints\n            numPoints += 1\n            pass        \n        continue\n    continue\n\nfor y in xrange(textureHeight):\n    for x in xrange(textureWidth):\n        neighbors = []\n        for (u, v) in [(x, y), (x + 1, y), (x + 1, y + 1), (x, y + 1)]:\n            if np.sqrt(pow(u - textureWidth / 2, 2) + pow(v - textureHeight / 2, 2)) < min(textureHeight, textureWidth) / 2:\n                neighbors.append((u, v))\n                pass\n            continue\n        if len(neighbors) == 4:\n            face = []\n            face.append(indicesMap[neighbors[0][1] * textureWidth + neighbors[0][0]])\n            face.append(indicesMap[neighbors[1][1] * textureWidth + neighbors[1][0]])\n            face.append(indicesMap[neighbors[2][1] * textureWidth + neighbors[2][0]])                \n            faces.append(face)\n            face = []\n            face.append(indicesMap[neighbors[0][1] * textureWidth + neighbors[0][0]])\n            face.append(indicesMap[neighbors[2][1] * textureWidth + neighbors[2][0]])\n            face.append(indicesMap[neighbors[3][1] * textureWidth + neighbors[3][0]])\n            faces.append(face)\n        elif len(neighbors) == 3:\n            face = []\n            face.append(indicesMap[neighbors[0][1] * textureWidth + neighbors[0][0]])\n            face.append(indicesMap[neighbors[1][1] * textureWidth + neighbors[1][0]])\n            face.append(indicesMap[neighbors[2][1] * textureWidth + neighbors[2][0]])                \n            faces.append(face)\n            pass\n        continue\n    continue\n\nwith open(sys.argv[2], \'w\') as outputFile:\n    header = """"""ply\nformat ascii 1.0\nelement vertex """"""\n    header += str(numPoints)\n    header += """"""\nproperty float x\nproperty float y\nproperty float z\nproperty uchar red                                     { start of vertex color }\nproperty uchar green\nproperty uchar blue\nelement face """"""\n    header += str(len(faces))\n    header += """"""\nproperty list uchar int vertex_indices\nend_header\n""""""\n    outputFile.write(header)\n    for y in xrange(textureHeight):\n        for x in xrange(textureWidth):\n            if np.sqrt(pow(x - textureWidth / 2, 2) + pow(y - textureHeight / 2, 2)) < min(textureHeight, textureWidth) / 2:\n                color = texture[y][x]\n                outputFile.write(str(float(x) / textureWidth * 2 - 1) + \' \' + str(float(y) / textureHeight * 2 - 1) + \' 0.0 \' + str(color[2]) + \' \' + str(color[1]) + \' \' + str(color[0]) + \'\\n\')\n                pass\n            continue\n        continue\n    for face in faces:\n        outputFile.write(\'3 \' + str(face[0]) + \' \' + str(face[1]) + \' \' + str(face[2]) + \'\\n\')\n        continue\n    outputFile.close()\n    pass\n'"
pytorch/datasets/__init__.py,0,b''
pytorch/datasets/plane_dataset.py,0,"b""from torch.utils.data import Dataset\n\nimport numpy as np\nimport time\n\nfrom plane_dataset_scannet import PlaneDatasetScanNet\nfrom augmentation import *\nfrom utils import *\n\n## Plane dataset class\nclass PlaneDataset(Dataset):\n    def __init__(self, options, split, random=True):\n        self.options = options\n        self.split = split\n        \n        dataset = options.dataset if split == 'train' else options.testingDataset\n        self.datasets = []\n        if 'scannet' in dataset:\n            self.datasets.append(PlaneDatasetScanNet(options, split, random))\n            pass\n\n        self.numImages = sum([len(dataset) for dataset in self.datasets])\n        numImages = options.numTrainingImages if split == 'train' else options.numTestingImages\n        if numImages > 0:\n            self.numImages = numImages\n            pass\n        return\n    \n    def __len__(self):\n        return self.numImages\n\n    def __getitem__(self, index):\n        t = int(time.time() * 1000000)\n        np.random.seed(((t & 0xff000000) >> 24) +\n                       ((t & 0x00ff0000) >> 8) +\n                       ((t & 0x0000ff00) << 8) +\n                       ((t & 0x000000ff) << 24))\n        \n        dataset = self.datasets[np.random.randint(len(self.datasets))]\n        info = dataset[index]\n        \n        image = info[0]\n        planes = info[1]\n        segmentation = info[2]\n        depth = info[3]\n        metadata = info[4]\n\n        if self.split == 'train':\n            if np.random.random() > 0.5:\n                image, planes, segmentation, depth, metadata = horizontalFlip(image, planes, segmentation, depth, metadata)\n                pass\n            pass\n        image, planes, segmentation, depth, metadata = cropPatch((np.zeros(2, dtype=np.int32), np.array([image.shape[1], image.shape[0]])), (self.options.outputWidth, self.options.outputHeight), image, planes, segmentation, depth, metadata)\n        if len(planes) == 0:\n            planes = np.zeros((self.options.numOutputPlanes, 3))\n        elif len(planes) < self.options.numOutputPlanes:\n            planes = np.concatenate([planes, np.zeros((self.options.numOutputPlanes - len(planes), 3))], axis=0)\n        elif len(planes) > self.options.numOutputPlanes:\n            planes = planes[:self.options.numOutputPlanes]\n            pass\n        segmentation[segmentation >= self.options.numOutputPlanes] = self.options.numOutputPlanes\n        segmentation[segmentation < 0] = self.options.numOutputPlanes\n\n        numbers = np.array([len(planes)])\n        sample = [(image.astype(np.float32) / 255 - MEAN_STD[0]).transpose((2, 0, 1)), planes.astype(np.float32), segmentation.astype(np.int64), depth, metadata.astype(np.float32), numbers]\n        #print([[item.shape, item.dtype] for item in sample])\n        return sample\n"""
pytorch/datasets/plane_dataset_scannet.py,0,"b""import numpy as np\nfrom datasets.scannet_scene import ScanNetScene\nimport os\nimport glob\n\n## This class maintains a pool of ScanNet scenes to load plane information\nclass PlaneDatasetScanNet():\n    def __init__(self, options, split, random=True):\n        self.options = options\n        self.random = random\n        \n        dataFolder = '../../Data/ScanNet/'\n        \n        self.scenes = []\n        self.sceneImageIndices = []\n        with open(dataFolder + '/ScanNet/Tasks/Benchmark/scannetv1_' + split + '.txt') as f:\n            for line in f:\n                scene_id = line.strip()\n                scenePath = dataFolder + '/scans/' + scene_id\n                if not os.path.exists(scenePath + '/' + scene_id + '.txt') or len(glob.glob(scenePath + '/annotation/segmentation/*')) == 0:\n                    continue\n                scene = ScanNetScene(options, scenePath, scene_id)\n                self.scenes.append(scene)\n                self.sceneImageIndices += [[len(self.scenes) - 1, imageIndex] for imageIndex in range(len(scene.imagePaths))]\n                continue\n            pass\n        #np.savetxt(dataFolder + '/image_list_' + split + '.txt', imagePaths, fmt='%s')\n        #imagePaths = np.loadtxt(dataFolder + '/image_list_' + split + '.txt', fmt='%s')\n\n        print('num images', len(self.sceneImageIndices))\n\n        np.random.shuffle(self.sceneImageIndices)\n        \n        numImages = options.numTrainingImages if split == 'train' else options.numTestingImages\n        if numImages > 0:\n            self.sceneImageIndices = self.sceneImageIndices[:numImages]\n            pass\n        return\n\n    def __len__(self):\n        return len(self.sceneImageIndices)\n    \n    def __getitem__(self, index):\n        if self.random:\n            index = np.random.randint(len(self.sceneImageIndices))\n        else:\n            index = index % len(self.sceneImageIndices)\n            pass\n        sceneIndex, imageIndex = self.sceneImageIndices[index]\n        plane_info = self.scenes[sceneIndex][imageIndex]\n        return plane_info\n"""
pytorch/datasets/scannet_scene.py,0,"b'import numpy as np\nimport glob\nimport cv2\nimport os\n\nfrom utils import *\n\n## This class handle one scene of the scannet dataset and provide interface for dataloaders\nclass ScanNetScene():\n    def __init__(self, options, scenePath, scene_id):\n        self.options = options\n\n        self.loadCached = False\n        self.scannetVersion = 2\n        \n        if not self.loadCached:\n            self.metadata = np.zeros(10)\n\n            if self.scannetVersion == 1:\n                with open(scenePath + \'/frames/_info.txt\') as f:\n                    for line in f:\n                        line = line.strip()\n                        tokens = [token for token in line.split(\' \') if token.strip() != \'\']\n                        if tokens[0] == ""m_calibrationColorIntrinsic"":\n                            intrinsics = np.array([float(e) for e in tokens[2:]])\n                            intrinsics = intrinsics.reshape((4, 4))\n                            self.metadata[0] = intrinsics[0][0]\n                            self.metadata[1] = intrinsics[1][1]\n                            self.metadata[2] = intrinsics[0][2]\n                            self.metadata[3] = intrinsics[1][2]                    \n                        elif tokens[0] == ""m_colorWidth"":\n                            self.colorWidth = int(tokens[2])\n                        elif tokens[0] == ""m_colorHeight"":\n                            self.colorHeight = int(tokens[2])\n                        elif tokens[0] == ""m_depthWidth"":\n                            self.depthWidth = int(tokens[2])\n                        elif tokens[0] == ""m_depthHeight"":\n                            self.depthHeight = int(tokens[2])\n                        elif tokens[0] == ""m_depthShift"":\n                            self.depthShift = int(tokens[2])\n                        elif tokens[0] == ""m_frames.size"":\n                            self.numImages = int(tokens[2])\n                            pass\n                        continue\n                    pass\n                self.imagePaths = glob.glob(scenePath + \'/frames/frame-*color.jpg\')\n            else:\n                with open(scenePath + \'/\' + scene_id + \'.txt\') as f:\n                    for line in f:\n                        line = line.strip()\n                        tokens = [token for token in line.split(\' \') if token.strip() != \'\']\n                        if tokens[0] == ""fx_color"":\n                            self.metadata[0] = float(tokens[2])\n                        if tokens[0] == ""fy_color"":\n                            self.metadata[1] = float(tokens[2])\n                        if tokens[0] == ""mx_color"":\n                            self.metadata[2] = float(tokens[2])                            \n                        if tokens[0] == ""my_color"":\n                            self.metadata[3] = float(tokens[2])                            \n                        elif tokens[0] == ""colorWidth"":\n                            self.colorWidth = int(tokens[2])\n                        elif tokens[0] == ""colorHeight"":\n                            self.colorHeight = int(tokens[2])\n                        elif tokens[0] == ""depthWidth"":\n                            self.depthWidth = int(tokens[2])\n                        elif tokens[0] == ""depthHeight"":\n                            self.depthHeight = int(tokens[2])\n                        elif tokens[0] == ""numDepthFrames"":\n                            self.numImages = int(tokens[2])\n                            pass\n                        continue\n                    pass\n                self.depthShift = 1000.0\n                self.imagePaths = glob.glob(scenePath + \'/frames/color/*.jpg\')                \n                pass\n                    \n            self.metadata[4] = self.colorWidth\n            self.metadata[5] = self.colorHeight\n            self.planes = np.load(scenePath + \'/annotation/planes.npy\')\n\n            #self.imagePaths = [imagePath for imagePath in self.imagePaths if os.path.exists(imagePath.replace(\'frames/\', \'annotation/segmentation/\').replace(\'color.jpg\', \'segmentation.png\')) and os.path.exists(imagePath.replace(\'color.jpg\', \'depth.pgm\')) and os.path.exists(imagePath.replace(\'color.jpg\', \'pose.txt\'))]\n            \n        else:\n            self.metadata = np.load(scenePath + \'/annotation_new/info.npy\')\n            self.imagePaths = glob.glob(scenePath + \'/annotation_new/frame-*.segmentation.png\')\n            pass\n        \n        # self.imagePaths = []\n        # for imageIndex in xrange(self.numImages):\n        #     self.imagePaths.append(\'%s/frames/frame-%06d.color.jpg\'%(scenePath, imageIndex))\n        #     continue\n        return\n\n    def getItemCached(self, imageIndex):\n        segmentationPath = self.imagePaths[imageIndex]\n        imagePath = segmentationPath.replace(\'annotation_new/\', \'frames/\').replace(\'segmentation.png\', \'color.jpg\')\n        image = cv2.imread(imagePath)\n        depth = cv2.imread(imagePath.replace(\'color.jpg\', \'depth.pgm\'), -1).astype(np.float32) / self.metadata[6]\n        extrinsics_inv = []\n        with open(imagePath.replace(\'color.jpg\', \'pose.txt\'), \'r\') as f:\n            for line in f:\n                extrinsics_inv += [float(value) for value in line.strip().split(\' \') if value.strip() != \'\']\n                continue\n            pass\n        extrinsics_inv = np.array(extrinsics_inv).reshape((4, 4))\n        extrinsics = np.linalg.inv(extrinsics_inv)\n        temp = extrinsics[1].copy()\n        extrinsics[1] = extrinsics[2]\n        extrinsics[2] = -temp\n\n        segmentation = cv2.imread(segmentationPath, -1).astype(np.int32)\n        #segmentation = segmentation[:, :, 2] * 256 * 256 + segmentation[:, :, 1] * 256 + segmentation[:, :, 0]\n\n        planes = np.load(segmentationPath.replace(\'segmentation.png\', \'planes.npy\'))\n\n        info = [image, planes, segmentation, depth, self.metadata]\n\n        if False:\n            print(planes)\n            print(depth.min(), depth.max())\n            cv2.imwrite(\'test/image.png\', image)\n            cv2.imwrite(\'test/depth_ori.png\', drawDepthImage(depth))\n            cv2.imwrite(\'test/segmentation.png\', drawSegmentationImage(segmentation))\n            # for index in range(segmentation.max() + 1):\n            #     print(index, newPlanes[index])\n            #     cv2.imwrite(\'test/mask_\' + str(index) + \'.png\', (segmentation == index).astype(np.uint8) * 255)\n            #     continue\n\n            #planeDepths = calcPlaneDepths(planes, segmentation, 192, self.metadata)\n            exit(1)\n\n        return info\n\n    def transformPlanes(self, transformation, planes):\n        planeOffsets = np.linalg.norm(planes, axis=-1, keepdims=True)\n        \n        centers = planes\n        centers = np.concatenate([centers, np.ones((planes.shape[0], 1))], axis=-1)\n        newCenters = np.transpose(np.matmul(transformation, np.transpose(centers)))\n        newCenters = newCenters[:, :3] / newCenters[:, 3:4]\n\n        refPoints = planes - planes / np.maximum(planeOffsets, 1e-4)\n        refPoints = np.concatenate([refPoints, np.ones((planes.shape[0], 1))], axis=-1)\n        newRefPoints = np.transpose(np.matmul(transformation, np.transpose(refPoints)))\n        newRefPoints = newRefPoints[:, :3] / newRefPoints[:, 3:4]\n\n        planeNormals = newRefPoints - newCenters\n        planeNormals /= np.linalg.norm(planeNormals, axis=-1, keepdims=True)\n        planeOffsets = np.sum(newCenters * planeNormals, axis=-1, keepdims=True)\n        newPlanes = planeNormals * planeOffsets\n        return newPlanes\n        \n    def __getitem__(self, imageIndex):\n        if self.loadCached:\n            return self.getItemCached(imageIndex)\n        \n        imagePath = self.imagePaths[imageIndex]\n\n        if self.scannetVersion == 1:\n            segmentationPath = imagePath.replace(\'frames/\', \'annotation/segmentation/\').replace(\'color.jpg\', \'segmentation.png\')\n            depthPath = imagePath.replace(\'color.jpg\', \'depth.pgm\')\n            posePath = imagePath.replace(\'color.jpg\', \'pose.txt\')\n        else:\n            segmentationPath = imagePath.replace(\'frames/color/\', \'annotation/segmentation/\').replace(\'.jpg\', \'.png\')\n            depthPath = imagePath.replace(\'color\', \'depth\').replace(\'.jpg\', \'.png\')\n            posePath = imagePath.replace(\'color\', \'pose\').replace(\'.jpg\', \'.txt\')\n            pass\n        \n        image = cv2.imread(imagePath)\n        depth = cv2.imread(depthPath, -1).astype(np.float32) / self.depthShift\n\n        extrinsics_inv = []\n        with open(posePath, \'r\') as f:\n            for line in f:\n                extrinsics_inv += [float(value) for value in line.strip().split(\' \') if value.strip() != \'\']\n                continue\n            pass\n        extrinsics_inv = np.array(extrinsics_inv).reshape((4, 4))\n        extrinsics = np.linalg.inv(extrinsics_inv)\n        \n        segmentation = cv2.imread(segmentationPath, -1).astype(np.int32)\n        segmentation = segmentation[:, :, 2] * 256 * 256 + segmentation[:, :, 1] * 256 + segmentation[:, :, 0]\n        \n        segmentation = segmentation / 100 - 1\n        segments, counts = np.unique(segmentation, return_counts=True)\n        segmentList = zip(segments.tolist(), counts.tolist())\n        segmentList = [segment for segment in segmentList if segment[0] not in [-1, 167771]]\n        segmentList = sorted(segmentList, key=lambda x:-x[1])\n        \n        newPlanes = []\n        newSegmentation = np.full(segmentation.shape, fill_value=-1, dtype=np.int32)\n        for newIndex, (oriIndex, count) in enumerate(segmentList):\n            if count < (segmentation.shape[0] * segmentation.shape[1]) * 0.02:\n                continue\n            newPlanes.append(self.planes[oriIndex])\n            newSegmentation[segmentation == oriIndex] = newIndex\n            continue\n\n        newPlanes = np.array(newPlanes)\n\n        temp = extrinsics[1].copy()\n        extrinsics[1] = extrinsics[2]\n        extrinsics[2] = -temp\n\n        if len(newPlanes) > 0:\n            newPlanes = self.transformPlanes(extrinsics, newPlanes)\n            pass\n\n        info = [image, newPlanes, newSegmentation, depth, self.metadata]\n\n        if False:\n            print(newPlanes)\n            print(depth.min(), depth.max())\n            cv2.imwrite(\'test/image.png\', image)\n            cv2.imwrite(\'test/depth_ori.png\', drawDepthImage(depth))\n            cv2.imwrite(\'test/segmentation.png\', drawSegmentationImage(newSegmentation))\n            for index in range(newSegmentation.max() + 1):\n                print(index, newPlanes[index])\n                cv2.imwrite(\'test/mask_\' + str(index) + \'.png\', (newSegmentation == index).astype(np.uint8) * 255)\n                continue\n            #planeDepths = calcPlaneDepths(planes, segmentation, 192, self.metadata)\n            exit(1)\n        \n        return info\n'"
pytorch/models/__init__.py,0,b''
pytorch/models/drn.py,0,"b""import pdb\n\nimport torch.nn as nn\nimport math\nimport torch.utils.model_zoo as model_zoo\nfrom torch.nn import functional as F\n\n__all__ = ['DRN', 'drn26', 'drn42', 'drn58']\n\n\nwebroot = 'https://tigress-web.princeton.edu/~fy/drn/models/'\n\nmodel_urls = {\n    'drn-c-26': webroot + 'drn_c_26-ddedf421.pth',\n    'drn-c-42': webroot + 'drn_c_42-9d336e8c.pth',\n    'drn-c-58': webroot + 'drn_c_58-0a53a92c.pth',\n    'drn-d-22': webroot + 'drn_d_22-4bd2f8ea.pth',\n    'drn-d-38': webroot + 'drn_d_38-eebb45f0.pth',\n    'drn-d-54': webroot + 'drn_d_54-0e0534ff.pth',\n    'drn-d-105': webroot + 'drn_d_105-12b40979.pth'\n}\n\n\ndef conv3x3(in_planes, out_planes, stride=1, padding=1, dilation=1):\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=padding, bias=False, dilation=dilation)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None,\n                 dilation=(1, 1), residual=True):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride,\n                             padding=dilation[0], dilation=dilation[0])\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes,\n                             padding=dilation[1], dilation=dilation[1])\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n        self.residual = residual\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n        if self.residual:\n            out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None,\n                 dilation=(1, 1), residual=True):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=dilation[1], bias=False,\n                               dilation=dilation[1])\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass DRN(nn.Module):\n\n    def __init__(self, block, layers, num_classes=1000,\n                 channels=(16, 32, 64, 128, 256, 512, 512, 512),\n                 out_map=-1, out_middle=False, pool_size=28, arch='D'):\n        super(DRN, self).__init__()\n        self.inplanes = channels[0]\n        self.out_map = out_map\n        self.out_dim = channels[-1]\n        self.out_middle = out_middle\n        self.arch = arch\n\n        if arch == 'C':\n            self.conv1 = nn.Conv2d(3, channels[0], kernel_size=7, stride=1,\n                                   padding=3, bias=False)\n            self.bn1 = nn.BatchNorm2d(channels[0])\n            self.relu = nn.ReLU(inplace=True)\n\n            self.layer1 = self._make_layer(\n                BasicBlock, channels[0], layers[0], stride=1)\n            self.layer2 = self._make_layer(\n                BasicBlock, channels[1], layers[1], stride=2)\n        elif arch == 'D':\n            self.layer0 = nn.Sequential(\n                nn.Conv2d(3, channels[0], kernel_size=7, stride=1, padding=3,\n                          bias=False),\n                nn.BatchNorm2d(channels[0]),\n                nn.ReLU(inplace=True)\n            )\n\n            self.layer1 = self._make_conv_layers(\n                channels[0], layers[0], stride=1)\n            self.layer2 = self._make_conv_layers(\n                channels[1], layers[1], stride=2)\n\n        self.layer3 = self._make_layer(block, channels[2], layers[2], stride=2)\n        self.layer4 = self._make_layer(block, channels[3], layers[3], stride=2)\n        self.layer5 = self._make_layer(block, channels[4], layers[4], dilation=2,\n                                       new_level=False)\n        self.layer6 = None if layers[5] == 0 else \\\n            self._make_layer(block, channels[5], layers[5], dilation=4,\n                             new_level=False)\n\n        if arch == 'C':\n            self.layer7 = None if layers[6] == 0 else \\\n                self._make_layer(BasicBlock, channels[6], layers[6], dilation=2,\n                                 new_level=False, residual=False)\n            self.layer8 = None if layers[7] == 0 else \\\n                self._make_layer(BasicBlock, channels[7], layers[7], dilation=1,\n                                 new_level=False, residual=False)\n        elif arch == 'D':\n            self.layer7 = None if layers[6] == 0 else \\\n                self._make_conv_layers(channels[6], layers[6], dilation=2)\n            self.layer8 = None if layers[7] == 0 else \\\n                self._make_conv_layers(channels[7], layers[7], dilation=1)\n\n        self.num_classes = num_classes\n        if self.num_classes > 0:\n            self.avgpool = nn.AvgPool2d(pool_size)\n            self.pred = nn.Conv2d(self.out_dim, num_classes, kernel_size=1,\n                                  stride=1, padding=0, bias=True)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n        if self.out_map < 32:\n            self.out_pool = nn.MaxPool2d(32 // self.out_map)\n            pass\n\n    def _make_layer(self, block, planes, blocks, stride=1, dilation=1,\n                    new_level=True, residual=True):\n        assert dilation == 1 or dilation % 2 == 0\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = list()\n        layers.append(block(\n            self.inplanes, planes, stride, downsample,\n            dilation=(1, 1) if dilation == 1 else (\n                dilation // 2 if new_level else dilation, dilation),\n            residual=residual))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes, residual=residual,\n                                dilation=(dilation, dilation)))\n\n        return nn.Sequential(*layers)\n\n    def _make_conv_layers(self, channels, convs, stride=1, dilation=1):\n        modules = []\n        for i in range(convs):\n            modules.extend([\n                nn.Conv2d(self.inplanes, channels, kernel_size=3,\n                          stride=stride if i == 0 else 1,\n                          padding=dilation, bias=False, dilation=dilation),\n                nn.BatchNorm2d(channels),\n                nn.ReLU(inplace=True)])\n            self.inplanes = channels\n        return nn.Sequential(*modules)\n\n    def forward(self, x):\n        y = list()\n\n        if self.arch == 'C':\n            x = self.conv1(x)\n            x = self.bn1(x)\n            x = self.relu(x)\n        elif self.arch == 'D':\n            x = self.layer0(x)\n\n        x = self.layer1(x)\n        y.append(x)\n        x = self.layer2(x)\n        y.append(x)\n\n        x = self.layer3(x)\n        y.append(x)\n\n        x = self.layer4(x)\n        y.append(x)\n\n        x = self.layer5(x)\n        y.append(x)\n\n        if self.layer6 is not None:\n            x = self.layer6(x)\n            y.append(x)\n\n        if self.layer7 is not None:\n            x = self.layer7(x)\n            y.append(x)\n\n        if self.layer8 is not None:\n            x = self.layer8(x)\n            y.append(x)\n\n        if self.out_map > 0:\n            if self.num_classes > 0:\n                if self.out_map == x.shape[2]:\n                    x = self.pred(x)\n                elif self.out_map > x.shape[2]:\n                    x = self.pred(x)\n                    x = F.upsample(input=x, size=(self.out_map, self.out_map), mode='bilinear')\n                else:\n                    x = self.out_pool(x)\n                    y.append(x)\n                    x = self.pred(x)\n                    pass\n            else:\n                if self.out_map > x.shape[3]:\n                    x = F.upsample(input=x, size=(self.out_map, self.out_map), mode='bilinear')\n                    pass\n                pass\n        else:\n            x = self.avgpool(x)\n            x = self.pred(x)\n            x = x.view(x.size(0), -1)\n\n        if self.out_middle:\n            return x, y\n        else:\n            return x\n\n\ndef drn_c_26(pretrained=False, **kwargs):\n    model = DRN(BasicBlock, [1, 1, 2, 2, 2, 2, 1, 1], arch='C', **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls['drn-c-26']))\n    return model\n\n\ndef drn_c_42(pretrained=False, **kwargs):\n    model = DRN(BasicBlock, [1, 1, 3, 4, 6, 3, 1, 1], arch='C', **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls['drn-c-42']))\n    return model\n\n\ndef drn_c_58(pretrained=False, **kwargs):\n    model = DRN(Bottleneck, [1, 1, 3, 4, 6, 3, 1, 1], arch='C', **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls['drn-c-58']))\n    return model\n\n\ndef drn_d_22(pretrained=False, **kwargs):\n    model = DRN(BasicBlock, [1, 1, 2, 2, 2, 2, 1, 1], arch='D', **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls['drn-d-22']))\n    return model\n\n\ndef drn_d_38(pretrained=False, **kwargs):\n    model = DRN(BasicBlock, [1, 1, 3, 4, 6, 3, 1, 1], arch='D', **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls['drn-d-38']))\n    return model\n\n\ndef drn_d_54(pretrained=False, out_map=256, num_classes=20, **kwargs):\n    model = DRN(Bottleneck, [1, 1, 3, 4, 6, 3, 1, 1], arch='D', out_map=out_map, num_classes=num_classes, **kwargs)\n    if pretrained:\n        pretrained_dict = model_zoo.load_url(model_urls['drn-d-54'])\n        pretrained_dict = {k: v for k, v in pretrained_dict.items() if 'fc' not in k}\n        state = model.state_dict()\n        state.update(pretrained_dict)\n        model.load_state_dict(state)\n    return model\n\n\ndef drn_d_105(pretrained=False, **kwargs):\n    model = DRN(Bottleneck, [1, 1, 3, 4, 23, 3, 1, 1], arch='D', **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls['drn-d-105']))\n    return model\n"""
pytorch/models/modules.py,0,"b""import torch\nfrom torch import nn\nimport numpy as np\nfrom utils import *\n\n## Conv + bn + relu\nclass ConvBlock(nn.Module):\n    def __init__(self, in_planes, out_planes, kernel_size=3, stride=1, padding=None, mode='conv'):\n        super(ConvBlock, self).__init__()\n       \n        if padding == None:\n            padding = (kernel_size - 1) // 2\n            pass\n        if mode == 'conv':\n            self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, bias=False)\n        elif mode == 'deconv':\n            self.conv = nn.ConvTranspose2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, bias=False)\n        elif mode == 'conv_3d':\n            self.conv = nn.Conv3d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, bias=False)\n        elif mode == 'deconv_3d':\n            self.conv = nn.ConvTranspose3d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, bias=False)\n        else:\n            print('conv mode not supported', mode)\n            exit(1)\n            pass\n        if '3d' not in mode:\n            self.bn = nn.BatchNorm2d(out_planes)\n        else:\n            self.bn = nn.BatchNorm3d(out_planes)\n            pass\n        self.relu = nn.ReLU(inplace=True)\n        return\n   \n    def forward(self, inp):\n        #return self.relu(self.conv(inp))       \n        return self.relu(self.bn(self.conv(inp)))\n\n## The pyramid module from pyramid scene parsing\nclass PyramidModule(nn.Module):\n    def __init__(self, options, in_planes, middle_planes, scales=[32, 16, 8, 4]):\n        super(PyramidModule, self).__init__()\n        \n        self.pool_1 = torch.nn.AvgPool2d((scales[0] * options.height / options.width, scales[0]))\n        self.pool_2 = torch.nn.AvgPool2d((scales[1] * options.height / options.width, scales[1]))        \n        self.pool_3 = torch.nn.AvgPool2d((scales[2] * options.height / options.width, scales[2]))\n        self.pool_4 = torch.nn.AvgPool2d((scales[3] * options.height / options.width, scales[3]))        \n        self.conv_1 = ConvBlock(in_planes, middle_planes, kernel_size=1)\n        self.conv_2 = ConvBlock(in_planes, middle_planes, kernel_size=1)\n        self.conv_3 = ConvBlock(in_planes, middle_planes, kernel_size=1)\n        self.conv_4 = ConvBlock(in_planes, middle_planes, kernel_size=1)\n        self.upsample = torch.nn.Upsample(size=(scales[0] * options.height / options.width, scales[0]), mode='bilinear')\n        return\n    \n    def forward(self, inp):\n        x_1 = self.upsample(self.conv_1(self.pool_1(inp)))\n        x_2 = self.upsample(self.conv_2(self.pool_2(inp)))\n        x_3 = self.upsample(self.conv_3(self.pool_3(inp)))\n        x_4 = self.upsample(self.conv_4(self.pool_4(inp)))\n        out = torch.cat([inp, x_1, x_2, x_3, x_4], dim=1)\n        return out\n\n\n## The module to compute plane depths from plane parameters\ndef calcPlaneDepthsModule(width, height, planes, metadata, return_ranges=False):\n    urange = (torch.arange(width, dtype=torch.float32).cuda().view((1, -1)).repeat(height, 1) / (float(width) + 1) * (metadata[4] + 1) - metadata[2]) / metadata[0]\n    vrange = (torch.arange(height, dtype=torch.float32).cuda().view((-1, 1)).repeat(1, width) / (float(height) + 1) * (metadata[5] + 1) - metadata[3]) / metadata[1]\n    ranges = torch.stack([urange, torch.ones(urange.shape).cuda(), -vrange], dim=-1)\n    \n    planeOffsets = torch.norm(planes, dim=-1, keepdim=True)\n    planeNormals = planes / torch.clamp(planeOffsets, min=1e-4)\n\n    normalXYZ = torch.sum(ranges.unsqueeze(-2) * planeNormals.unsqueeze(-3).unsqueeze(-3), dim=-1)\n    normalXYZ[normalXYZ == 0] = 1e-4\n    planeDepths = planeOffsets.squeeze(-1).unsqueeze(-2).unsqueeze(-2) / normalXYZ\n    planeDepths = torch.clamp(planeDepths, min=0, max=MAX_DEPTH)\n    if return_ranges:\n        return planeDepths, ranges\n    return planeDepths\n\n\n## The module to compute depth from plane information\ndef calcDepthModule(width, height, planes, segmentation, non_plane_depth, metadata):\n    planeDepths = calcPlaneDepthsModule(width, height, planes, metadata)\n    allDepths = torch.cat([planeDepths.transpose(-1, -2).transpose(-2, -3), non_plane_depth], dim=1)\n    return torch.sum(allDepths * segmentation, dim=1)\n\n\n## Compute matching with the auction-based approximation algorithm\ndef assignmentModule(W):\n    O = calcAssignment(W.detach().cpu().numpy())\n    return torch.from_numpy(O).cuda()\n\ndef calcAssignment(W):\n    numOwners = int(W.shape[0])\n    numGoods = int(W.shape[1])    \n    P = np.zeros(numGoods)\n    O = np.full(shape=(numGoods, ), fill_value=-1)\n    delta = 1.0 / (numGoods + 1)\n    queue = list(range(numOwners))\n    while len(queue) > 0:\n        ownerIndex = queue[0]\n        queue = queue[1:]\n        weights = W[ownerIndex]\n        goodIndex = (weights - P).argmax()\n        if weights[goodIndex] >= P[goodIndex]:\n            if O[goodIndex] >= 0:\n                queue.append(O[goodIndex])\n                pass\n            O[goodIndex] = ownerIndex\n            P[goodIndex] += delta\n            pass\n        continue\n    return O\n\n## Get one-hot tensor\ndef oneHotModule(inp, depth):\n    inpShape = [int(size) for size in inp.shape]\n    inp = inp.view(-1)\n    out = torch.zeros(int(inp.shape[0]), depth).cuda()\n    out.scatter_(1, inp.unsqueeze(-1), 1)\n    out = out.view(inpShape + [depth])\n    return out\n\n## Warp image\ndef warpImages(options, planes, images, transformations, metadata):\n    planeDepths, ranges = calcPlaneDepthsModule(options.width, options.height, planes, metadata, return_ranges=True)\n    print(planeDepths.shape, ranges.shape, transformations.shape)\n    exit(1)\n    XYZ = planeDepths.unsqueeze(-1) * ranges.unsqueeze(-2)\n    XYZ = torch.cat([XYZ, torch.ones([int(size) for size in XYZ.shape[:-1]] + [1]).cuda()], dim=-1)\n    XYZ = torch.matmul(XYZ.unsqueeze(-3), transformations.unsqueeze(-4).unsqueeze(-4))\n    UVs = XYZ[:, :, :, :, :, :2] / XYZ[:, :, :, :, :, 2:3]\n    UVs = (UVs * metadata[:2] + metadata[2:4]) / metadata[4:6] * 2 - 1\n    warpedImages = []\n    for imageIndex in range(options.numNeighborImages):\n        warpedImage = []\n        image = images[:, imageIndex]\n        for planeIndex in range(options.numOutputPlanes):\n            warpedImage.append(F.grid_sample(image, UVs[:, :, :, imageIndex, planeIndex]))\n            continue\n        warpedImages.append(torch.stack(warpedImage, 1))\n        continue\n    warpedImages = torch.stack(warpedImages, 2)\n    return warpedImages\n"""
pytorch/models/planenet.py,0,"b""from models.drn import drn_d_54\nfrom models.modules import *\n\nclass PlaneNet(nn.Module):\n    def __init__(self, options):\n        super(PlaneNet, self).__init__()\n        \n        self.options = options        \n        self.drn = drn_d_54(pretrained=True, out_map=32, num_classes=-1, out_middle=False)\n        self.pool = torch.nn.AvgPool2d((32 * options.height / options.width, 32))\n        self.plane_pred = nn.Linear(512, options.numOutputPlanes * 3)\n        self.pyramid = PyramidModule(options, 512, 128)\n        self.feature_conv = ConvBlock(1024, 512)\n        self.segmentation_pred = nn.Conv2d(512, options.numOutputPlanes + 1, kernel_size=1)\n        self.depth_pred = nn.Conv2d(512, 1, kernel_size=1)\n        self.upsample = torch.nn.Upsample(size=(options.outputHeight, options.outputWidth), mode='bilinear')\n        return\n\n    def forward(self, inp):\n        features = self.drn(inp)\n        planes = self.plane_pred(self.pool(features).view((-1, 512))).view((-1, self.options.numOutputPlanes, 3))\n        features = self.pyramid(features)\n        features = self.feature_conv(features)\n        segmentation = self.upsample(self.segmentation_pred(features))\n        depth = self.upsample(self.depth_pred(features))\n        return planes, segmentation, depth\n"""
pytorch/tf/RecordReaderAll.py,51,"b""import tensorflow as tf\nimport numpy as np\nimport threading\nimport PIL.Image as Image\nfrom functools import partial\nfrom multiprocessing import Pool\nimport cv2\n\nimport sys\nimport os\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n#from modules import *\n\n\nHEIGHT=192\nWIDTH=256\nNUM_PLANES = 20\nNUM_THREADS = 4\n\n\n\nclass RecordReaderAll():\n    def __init__(self):\n        return\n\n    def getBatch(self, filename_queue, numOutputPlanes = 20, batchSize = 16, min_after_dequeue = 1000, random=True, getLocal=False, getSegmentation=False, test=True):\n        reader = tf.TFRecordReader()\n        _, serialized_example = reader.read(filename_queue)\n\n        features = tf.parse_single_example(\n            serialized_example,\n            # Defaults are not specified since both keys are required.\n            features={\n                #'height': tf.FixedLenFeature([], tf.int64),\n                #'width': tf.FixedLenFeature([], tf.int64),\n                'image_raw': tf.FixedLenFeature([], tf.string),\n                'image_path': tf.FixedLenFeature([], tf.string),\n                'num_planes': tf.FixedLenFeature([], tf.int64),\n                'plane': tf.FixedLenFeature([NUM_PLANES * 3], tf.float32),\n                #'plane_relation': tf.FixedLenFeature([NUM_PLANES * NUM_PLANES], tf.float32),\n                'segmentation_raw': tf.FixedLenFeature([], tf.string),\n                'depth': tf.FixedLenFeature([HEIGHT * WIDTH], tf.float32),\n                'normal': tf.FixedLenFeature([HEIGHT * WIDTH * 3], tf.float32),\n                'semantics_raw': tf.FixedLenFeature([], tf.string),                \n                'boundary_raw': tf.FixedLenFeature([], tf.string),\n                'info': tf.FixedLenFeature([4 * 4 + 4], tf.float32),                \n            })\n\n        # Convert from a scalar string tensor (whose single string has\n        # length mnist.IMAGE_PIXELS) to a uint8 tensor with shape\n        # [mnist.IMAGE_PIXELS].\n        image = tf.decode_raw(features['image_raw'], tf.uint8)\n        image = tf.cast(image, tf.float32) * (1. / 255) - 0.5\n        image = tf.reshape(image, [HEIGHT, WIDTH, 3])\n\n        \n        depth = features['depth']\n        depth = tf.reshape(depth, [HEIGHT, WIDTH, 1])\n\n        normal = features['normal']\n        normal = tf.reshape(normal, [HEIGHT, WIDTH, 3])\n        \n        normal = tf.nn.l2_normalize(normal, dim=2)\n        \n        #normal = tf.stack([normal[:, :, 1], normal[:, :, 0], normal[:, :, 2]], axis=2)\n\n\n        semantics = tf.decode_raw(features['semantics_raw'], tf.uint8)\n        semantics = tf.cast(tf.reshape(semantics, [HEIGHT, WIDTH]), tf.int32)\n\n        numPlanes = tf.minimum(tf.cast(features['num_planes'], tf.int32), numOutputPlanes)\n\n        numPlanesOri = numPlanes\n        numPlanes = tf.maximum(numPlanes, 1)\n        \n        planes = features['plane']\n        planes = tf.reshape(planes, [NUM_PLANES, 3])\n        planes = tf.slice(planes, [0, 0], [numPlanes, 3])\n\n        #shuffle_inds = tf.one_hot(tf.random_shuffle(tf.range(numPlanes)), depth = numPlanes)\n        shuffle_inds = tf.one_hot(tf.range(numPlanes), numPlanes)\n        \n        planes = tf.transpose(tf.matmul(tf.transpose(planes), shuffle_inds))\n        planes = tf.reshape(planes, [numPlanes, 3])\n        planes = tf.concat([planes, tf.zeros([numOutputPlanes - numPlanes, 3])], axis=0)\n        planes = tf.reshape(planes, [numOutputPlanes, 3])\n\n        \n        boundary = tf.decode_raw(features['boundary_raw'], tf.uint8)\n        boundary = tf.cast(tf.reshape(boundary, (HEIGHT, WIDTH, 2)), tf.float32)\n\n        #boundary = tf.decode_raw(features['boundary_raw'], tf.float64)\n        #boundary = tf.cast(tf.reshape(boundary, (HEIGHT, WIDTH, 3)), tf.float32)        \n        #boundary = tf.slice(boundary, [0, 0, 0], [HEIGHT, WIDTH, 2])\n\n        segmentation = tf.decode_raw(features['segmentation_raw'], tf.uint8)\n        segmentation = tf.reshape(segmentation, [HEIGHT, WIDTH, 1])\n\n\n        \n        coef = tf.range(numPlanes)\n        coef = tf.reshape(tf.matmul(tf.reshape(coef, [-1, numPlanes]), tf.cast(shuffle_inds, tf.int32)), [1, 1, numPlanes])\n        \n        plane_masks = tf.cast(tf.equal(segmentation, tf.cast(coef, tf.uint8)), tf.float32)\n        plane_masks = tf.concat([plane_masks, tf.zeros([HEIGHT, WIDTH, numOutputPlanes - numPlanes])], axis=2)\n        plane_masks = tf.reshape(plane_masks, [HEIGHT, WIDTH, numOutputPlanes])\n\n        #non_plane_mask = tf.cast(tf.equal(segmentation, tf.cast(numOutputPlanes, tf.uint8)), tf.float32)\n        non_plane_mask = 1 - tf.reduce_max(plane_masks, axis=2, keep_dims=True)\n        #tf.cast(tf.equal(segmentation, tf.cast(numOutputPlanes, tf.uint8)), tf.float32)\n\n        \n        if random:\n            image_inp, plane_inp, depth_gt, normal_gt, semantics_gt, plane_masks_gt, boundary_gt, num_planes_gt, non_plane_mask_gt, image_path, info = tf.train.shuffle_batch([image, planes, depth, normal, semantics, plane_masks, boundary, numPlanesOri, non_plane_mask, features['image_path'], features['info']], batch_size=batchSize, capacity=min_after_dequeue + (NUM_THREADS + 2) * batchSize, num_threads=NUM_THREADS, min_after_dequeue=min_after_dequeue)\n        else:\n            image_inp, plane_inp, depth_gt, normal_gt, semantics_gt, plane_masks_gt, boundary_gt, num_planes_gt, non_plane_mask_gt, image_path, info = tf.train.batch([image, planes, depth, normal, semantics, plane_masks, boundary, numPlanesOri, non_plane_mask, features['image_path'], features['info']], batch_size=batchSize, capacity=(NUM_THREADS + 2) * batchSize, num_threads=1)\n            pass\n        global_gt_dict = {'plane': plane_inp, 'depth': depth_gt, 'normal': normal_gt, 'semantics': semantics_gt, 'segmentation': plane_masks_gt, 'boundary': boundary_gt, 'num_planes': num_planes_gt, 'non_plane_mask': non_plane_mask_gt, 'image_path': image_path, 'info': info}\n        return image_inp, global_gt_dict, {}\n"""
pytorch/tf/data_converter.py,11,"b""\nimport tensorflow as tf\nimport numpy as np\nimport cv2\nimport random\nimport PIL.Image\nimport sys\nimport os\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n#from modules import *\nfrom RecordReaderAll import *\nfrom utils import *\n\nHEIGHT=192\nWIDTH=256\nNUM_PLANES = 20\n\ndef _bytes_feature(value):\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _int64_feature(value):\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n\ndef _float_feature(value):\n    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n\n\ndef writeRecordFile(split, dataset):\n    \n    batchSize = 8\n    numOutputPlanes = 20\n    if split == 'train':\n        reader = RecordReaderAll()\n        filename_queue = tf.train.string_input_producer(['../../Data/PlaneNet/planes_' + dataset + '_train.tfrecords'], num_epochs=1)\n        img_inp, global_gt_dict, _ = reader.getBatch(filename_queue, numOutputPlanes=numOutputPlanes, batchSize=batchSize, random=False, getLocal=True)\n        numImages = 50000\n    else:\n        reader = RecordReaderAll()\n        filename_queue = tf.train.string_input_producer(['../../Data/PlaneNet/planes_' + dataset + '_val.tfrecords'], num_epochs=1)\n        img_inp, global_gt_dict, _ = reader.getBatch(filename_queue, numOutputPlanes=numOutputPlanes, batchSize=batchSize, random=False, getLocal=True)\n        numImages = 1000\n        pass\n    \n        \n    init_op = tf.group(tf.global_variables_initializer(),\n                       tf.local_variables_initializer())\n\n    \n    with tf.Session() as sess:\n        sess.run(init_op)\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n        try:\n            for _ in xrange(numImages / batchSize):\n                img, global_gt = sess.run([img_inp, global_gt_dict])\n                if _ % 500 == 0:\n                    print(_)\n                    pass\n                for batchIndex in xrange(batchSize):\n                    imagePath = global_gt['image_path'][batchIndex]\n                    if '/mnt/vision/' in imagePath:\n                        imagePath = imagePath.replace('/mnt/vision/', '../../Data/')\n                    elif '/home/chenliu/Projects/Data/' in imagePath:\n                        imagePath = imagePath.replace('/home/chenliu/Projects/Data/', '../../Data/')\n                        pass\n                    \n                    tokens = imagePath.split('/')\n                    if not os.path.exists('/'.join(tokens[:-2])):\n                        os.system('mkdir ' + '/'.join(tokens[:-2]))\n                        pass\n                    annotationPath = '/'.join(tokens[:-2]) + '/annotation_new/'\n\n#                     info = global_gt['info'][batchIndex]\n#                     info[1] = info[5]\n#                     info[3] = info[6]\n#                     info[4] = info[16]\n#                     info[5] = info[17]\n#                     info[6] = info[18]\n#                     info[7] = info[8] = info[9] = 0\n#                     info = info[:10]\n#                     if not os.path.exists(annotationPath + '/info.npy'):\n#                         np.save(annotationPath + '/info.npy', info)\n#                         pass\n#                     continue\n                    \n                    if os.path.exists(annotationPath + tokens[-1].replace('color.jpg', 'planes.npy')):\n                        continue\n\n                    image = ((img[batchIndex] + 0.5) * 255).astype(np.uint8)                    \n                    numPlanes = global_gt['num_planes'][batchIndex]\n                    if numPlanes == 0:\n                        continue\n                    segmentation = np.argmax(np.concatenate([global_gt['segmentation'][batchIndex], global_gt['non_plane_mask'][batchIndex]], axis=-1), axis=-1).astype(np.uint8).squeeze()\n                    #boundary = global_gt['boundary'][batchIndex].astype(np.uint8)\n                    #semantics = global_gt['semantics'][batchIndex].astype(np.uint8)\n                    planes = global_gt['plane'][batchIndex]\n                    \n                    if not os.path.exists(annotationPath):\n                        os.system('mkdir ' + annotationPath)\n                        pass\n                    cv2.imwrite(annotationPath + tokens[-1].replace('color.jpg', 'segmentation.png'), segmentation)\n                    np.save(annotationPath + tokens[-1].replace('color.jpg', 'planes.npy'), planes[:numPlanes])\n                    cv2.imwrite(annotationPath + tokens[-1], image)\n                    depth = np.round(global_gt['depth'][batchIndex] * 1000).astype(np.uint16)\n                    cv2.imwrite(annotationPath + tokens[-1].replace('color.jpg', 'depth.png'), depth)\n                    continue\n                continue\n            pass\n        except tf.errors.OutOfRangeError:\n            print('Done training -- epoch limit reached')\n        finally:\n            # When done, ask the threads to stop.\n            coord.request_stop()\n            pass\n        \n        # Wait for threads to finish.\n        coord.join(threads)\n        sess.close()    \n    return\n\n    \nif __name__=='__main__':\n    #writeRecordFile('val', 'matterport')\n    #writeRecordFile('val', 'scannet')\n    # writeRecordFile('train', 'matterport')    \n    #writeRecordFile('train', 'scannet')\n    #writeRecordFile('train', 'nyu_rgbd')\n    writeRecordFile('val', 'scannet')    \n"""
pytorch/tf/modules.py,564,"b'import tensorflow as tf\nimport numpy as np\n\n# def segmentationRefinementModule(segmentation, planeDepths, numOutputPlanes = 20, gpu_id = 0, coef = [1, 1, 1], beta = 10):\n#     with tf.device(\'/gpu:%d\'%gpu_id):\n#         S = segmentation\n#         #S = tf.one_hot(tf.argmax(S, 3), numOutputPlanes)\n#         D = tf.tile(tf.expand_dims(planeDepths, -1), [1, 1, 1, 1, numOutputPlanes])\n#         D_transpose = tf.tile(tf.expand_dims(planeDepths, 3), [1, 1, 1, numOutputPlanes, 1])\n#         D_diff = tf.abs(D - D_transpose)\n#         batchSize = int(segmentation.shape[0])\n#         height = int(segmentation.shape[1])\n#         width = int(segmentation.shape[2])\n#         S_neighbor_up = tf.concat([tf.zeros([batchSize, 1, width, numOutputPlanes]), tf.slice(S, [0, 0, 0, 0], [batchSize, height - 1, width, numOutputPlanes])], axis = 1)\n#         S_neighbor_down = tf.concat([tf.slice(S, [0, 1, 0, 0], [batchSize, height - 1, width, numOutputPlanes]), tf.zeros([batchSize, 1, width, numOutputPlanes]), ], axis = 1)\n#         S_neighbor_left = tf.concat([tf.zeros([batchSize, height, 1, numOutputPlanes]), tf.slice(S, [0, 0, 0, 0], [batchSize, height, width - 1, numOutputPlanes])], axis = 2)\n#         S_neighbor_right = tf.concat([tf.slice(S, [0, 0, 1, 0], [batchSize, height, width - 1, numOutputPlanes]), tf.zeros([batchSize, height, 1, numOutputPlanes]), ], axis = 2)\n#         #S_neighbors = tf.stack([S_neighbor_up, S_neighbor_down, S_neighbor_left, S_neighbor_right], axis = 4)\n#         S_neighbors = (S_neighbor_up + S_neighbor_down + S_neighbor_left + S_neighbor_right) / 4\n#         DS = tf.reduce_sum(tf.multiply(D_diff, tf.expand_dims(S_neighbors, 3)), axis=4)\n#         #test = tf.multiply(D_diff, tf.expand_dims(S_neighbors, 3))\n#         #S_diff = tf.tile(tf.reduce_sum(S_neighbors, axis=3, keep_dims=True), [1, 1, 1, numOutputPlanes]) - S_neighbors\n#         S_diff = tf.ones(S_neighbors.shape) - S_neighbors\n#         pass\n#     P = tf.clip_by_value(S, 1e-4, 1)\n#     DS = tf.clip_by_value(DS / 0.5, 1e-4, 1)\n#     S_diff = tf.clip_by_value(S_diff, 1e-4, 1)\n#     #return tf.nn.softmax(-beta * (-coef[0] * tf.log(P) + coef[1] * tf.log(DS) + coef[2] * tf.log(S_diff))), tf.nn.softmax(tf.log(P)), 1 - tf.clip_by_value(DS / 2, 0, 1), 1 - S_diff, 1 - tf.clip_by_value(tf.multiply(D_diff, tf.expand_dims(S_neighbors, 3)) / 2, 0, 1), S_neighbors, D_diff\n#     return tf.nn.softmax(-beta * (-coef[0] * tf.log(P) + coef[1] * tf.log(DS) + coef[2] * tf.log(S_diff)))\n\ndef planeDepthsModule(plane_parameters, width, height, info):\n    urange = (tf.range(width, dtype=tf.float32) / (width + 1) * (info[16] + 1) - info[2]) / info[0]\n    urange = tf.tile(tf.reshape(urange, [1, -1]), [height, 1])\n    vrange = (tf.range(height, dtype=tf.float32) / (height + 1) * (info[17] + 1) - info[6]) / info[5]\n    vrange = tf.tile(tf.reshape(vrange, [-1, 1]), [1, width])\n            \n    ranges = tf.stack([urange, np.ones([height, width]), -vrange], axis=2)\n    ranges = tf.reshape(ranges, [-1, 3])\n            \n    planesD = tf.norm(plane_parameters, axis=1, keep_dims=True)\n    planesD = tf.clip_by_value(planesD, 1e-5, 10)\n    planesNormal = tf.div(tf.negative(plane_parameters), tf.tile(planesD, [1, 3]))\n\n    normalXYZ = tf.matmul(ranges, planesNormal, transpose_b=True)\n    normalXYZ = tf.multiply(tf.sign(normalXYZ), tf.clip_by_value(tf.abs(normalXYZ), 1e-4, 1000000))\n    normalXYZ = tf.reciprocal(normalXYZ)\n    plane_depths = tf.negative(normalXYZ) * tf.reshape(planesD, [-1])\n    plane_depths = tf.reshape(plane_depths, [height, width, -1])\n\n    plane_depths = tf.clip_by_value(plane_depths, 0, 10)\n    \n    return plane_depths\n\ndef planeNormalsModule(plane_parameters, width, height):\n    planesD = tf.norm(plane_parameters, axis=-1, keep_dims=True)\n    planesD = tf.clip_by_value(planesD, 1e-4, 10)\n    planesNormal = tf.div(tf.negative(plane_parameters), planesD)\n\n    #plane_normals = tf.tile(tf.reshape(planesNormal, [1, 1, -1, 3]), [height, width, 1, 1])\n    #plane_normals = tf.reshape(planesNormal, [1, 1, -1, 3])\n    return planesNormal\n\ndef gaussian(k=5, sig=0):\n    """"""\n    creates gaussian kernel with side length l and a sigma of sig\n    """"""\n    if sig == 0:\n        sig = 0.3 * ((k - 1) * 0.5 - 1) + 0.8\n        pass\n    ax = np.arange(-k // 2 + 1., k // 2 + 1.)\n    xx, yy = np.meshgrid(ax, ax)\n\n    kernel = np.exp(-(xx**2 + yy**2) / (2. * sig**2))\n\n    return kernel / np.sum(kernel)\n\ndef meanfieldModuleLayer(layerSegmentations, planeDepths, numOutputPlanes = 20, numLayers=2, coef = [1, 1, 1], beta = 1, iteration = 0, sigmaDepthDiff = 0.5):\n    batchSize = int(planeSegmentations.shape[0])\n    height = int(planeSegmentations.shape[1])\n    width = int(planeSegmentations.shape[2])\n\n    minDepthDiff = 0.1\n    #P = planeSegmentations\n    #S = tf.one_hot(tf.argmax(planeSegmentations, 3), depth=numOutputPlanes)\n    kernel_size = 9\n    neighbor_kernel_array = gaussian(kernel_size)\n    neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n    neighbor_kernel_array /= neighbor_kernel_array.sum()\n    neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n    neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n\n\n    layerDepths = []\n    layerSs = []\n    for layer in xrange(numLayers):\n        S = tf.one_hot(tf.argmax(planeSegmentations, 3), depth=numOutputPlanes)\n        layerDepth = tf.reduce_sum(planeDepths * S, 3, keep_dims=True)\n        layerSs.append(S)\n        layerDepths.append(layerDepth)\n\n    DSs = []\n    conflictDs = []\n    conflictDepthThreshold = 0.1\n    \n    for layer in xrange(numLayers):        \n        DS_diff = tf.exp(-tf.pow(1 - tf.clip_by_value(tf.abs(planeDepths - layerDepths[layer]), 0, 1), 2) / sigmaDepthDiff) - tf.exp(-1 / sigmaDepthDiff) * layerSs[layer]\n        DS = tf.nn.depthwise_conv2d(DS_diff, tf.tile(neighbor_kernel, [1, 1, numOutputPlanes, 1]), strides=[1, 1, 1, 1], padding=\'SAME\')\n        DSs.append(DS)\n        \n        conflictD = tf.zeros((batchSize, height, width, 1))\n        if layer > 0:\n            minDepth = tf.min(tf.concat(layerDepths[:layer - 1], axis=3), axis=3, keep_dims=True)\n            conflictD = tf.maximum(conflictD, layerDepths[layer] - minDepth)\n            pass\n        if layer < numLayers - 1:\n            maxDepth = tf.max(tf.concat(layerDepths[layer + 1:], axis=3), axis=3, keep_dims=True)\n            conflictD = tf.maximum(conflictD, maxDepth -  layerDepths[layer])\n            pass\n        conflictDs.append(tf.cast(conflictD > conflictDepthThreshold, tf.float32))\n\n        \n    P = tf.clip_by_value(P, 1e-4, 1)\n    confidence = P * tf.exp(-coef[1] * DS)\n    refined_segmentation = tf.nn.softmax(tf.log(confidence))\n    return refined_segmentation\n\ndef calcImageDiff(images, kernel_size = 9):\n    neighbor_kernel_array = gaussian(kernel_size)\n    neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n    neighbor_kernel_array /= neighbor_kernel_array.sum()\n    neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = -1\n    neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n    neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n\n    image_diff = tf.nn.depthwise_conv2d(images, tf.tile(neighbor_kernel, [1, 1, 3, 1]), strides=[1, 1, 1, 1], padding=\'SAME\')\n    image_diff = tf.pow(image_diff, 2)\n    image_diff = tf.reduce_sum(image_diff, axis=3, keep_dims=True)\n    var_image_diff =  tf.reduce_mean(image_diff, axis=[1, 2, 3], keep_dims=True)\n    #image_diff = image_diff\n    #image_diff = tf.exp(-image_diff)\n    #image_diff = tf.nn.max_pool(image_diff, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\')\n    return image_diff, var_image_diff\n    \ndef meanfieldModule(planeSegmentations, planeDepths, planesY, imageDiff, numOutputPlanes = 20, coef = [1, 1, 1], beta = 1, iteration = 0, maxDepthDiff = 0.2, varDepthDiff = 0.5, kernel_size = 9):\n    batchSize = int(planeSegmentations.shape[0])\n    height = int(planeSegmentations.shape[1])\n    width = int(planeSegmentations.shape[2])\n\n    P = planeSegmentations\n\n\n    #minDepthDiff = 0.1\n    #normalDotThreshold = np.cos(np.deg2rad(30))\n    #N_diff = tf.matmul(planeNormals, planeNormals, transpose_b=True)\n    #N_diff_mask = tf.cast((N_diff < normalDotThreshold), tf.float) + tf.diag(tf.ones(numOutputPlanes))\n    #N_diff = tf.clip(N_diff, minDepthDiff, 1)\n    #N_diff_mask = tf.expand_dims(tf.expand_dims(N_diff_mask, 1), 1)\n\n    #D_diff = (D_diff - minDepthDiff) * N_diff_mask + minDepthDiff\n\n\n    #confidenceThreshold = 0.00\n    #P_truncated = P * (P >= confidenceThreshold).astype(tf.float)\n    S = tf.one_hot(tf.argmax(planeSegmentations, 3), depth=numOutputPlanes)\n\n    # D = tf.tile(tf.expand_dims(planeDepths, -1), [1, 1, 1, 1, numOutputPlanes])\n    # D_transpose = tf.tile(tf.expand_dims(planeDepths, 3), [1, 1, 1, numOutputPlanes, 1])\n    # D_diff = tf.abs(D - D_transpose)\n    # DS_weight = tf.exp(-tf.pow(tf.clip_by_value(1 - D_diff / maxDepthDiff, 0, 1), 2) / sigmaDepthDiff)\n    # DS_diff = tf.reduce_sum(DS_weight * tf.expand_dims(S, 3), axis=4) - tf.exp(-1 / sigmaDepthDiff) * S\n\n    \n    \n    \n    depthWeight = 50.0\n    colorWeight = 50.0\n    normalY = tf.reduce_sum(S * tf.reshape(planesY, [-1, 1, 1, numOutputPlanes]), axis=3, keep_dims=True)\n    depth_diff = (planeDepths - tf.reduce_sum(planeDepths * S, 3, keep_dims=True)) * normalY\n    depth_diff = tf.concat([depth_diff[:, :, :, :numOutputPlanes - 1], (1 - S[:, :, :, numOutputPlanes - 1:numOutputPlanes])], axis=3)\n    DS_diff = (1 - tf.exp(-tf.pow(tf.minimum(depth_diff, maxDepthDiff), 2) / varDepthDiff)) + (1 - S) * (1 / depthWeight + (colorWeight / depthWeight) * imageDiff)\n\n\n    #DS_diff = tf.exp(-tf.pow(1 - tf.clip_by_value(tf.abs(planeDepths - tf.reduce_sum(planeDepths * S, 3, keep_dims=True)), 0, 1), 2) / 0.5) - tf.exp(-1 / 0.5) * S\n\n    neighbor_kernel_array = gaussian(kernel_size)\n    neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n    neighbor_kernel_array /= neighbor_kernel_array.sum()\n    neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n    neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n    \n    DS = tf.nn.depthwise_conv2d(DS_diff, tf.tile(neighbor_kernel, [1, 1, numOutputPlanes, 1]), strides=[1, 1, 1, 1], padding=\'SAME\')\n    \n\n    P = tf.clip_by_value(P, 1e-4, 1)\n    confidence = P * tf.exp(-coef[1] * DS)\n    #confidence = coef[0] * P + tf.exp(-coef[1] * DS) + tf.exp(-coef[2] * S_diff)\n    #confidence[:, :, :, numOutputPlanes] = 1e-4\n    #confidence = tf.clip(confidence, 1e-4, 1)\n    refined_segmentation = tf.nn.softmax(tf.log(confidence))\n    return refined_segmentation, {\'diff\': DS}\n\n\ndef segmentationRefinementModule(planeSegmentations, planeDepths, planesY, imageDiff, numOutputPlanes = 20, numIterations=20, kernel_size = 9):\n\n    # kernel_size = 9\n    # neighbor_kernel_array = gaussian(kernel_size)\n    # neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n    # neighbor_kernel_array /= neighbor_kernel_array.sum()\n    # neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = -1\n    # neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n    # neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n\n    #maxDepthDiff = tf.Variable(0.3)\n    #sigmaDepthDiff = tf.Variable(0.5)\n    maxDepthDiff = 0.2\n    varDepthDiff = pow(0.2, 2)\n    \n    \n    refined_segmentation = planeSegmentations\n    for _ in xrange(numIterations):\n        refined_segmentation, _ = meanfieldModule(refined_segmentation, planeDepths, planesY, imageDiff, numOutputPlanes=numOutputPlanes, maxDepthDiff=maxDepthDiff, varDepthDiff=varDepthDiff, kernel_size = kernel_size)\n        continue\n    return refined_segmentation, {}\n\n\ndef meanfieldModuleBoundary(planeSegmentations, originalSegmentations, planeDepths, occlusionBoundary = 0, smoothBoundary = 0, numOutputPlanes = 20, coef = [1, 10, 1], beta = 1, iteration = 0, sigmaDepthDiff = 0.5):\n    batchSize = int(planeSegmentations.shape[0])\n    height = int(planeSegmentations.shape[1])\n    width = int(planeSegmentations.shape[2])\n\n    #S = tf.one_hot(tf.argmax(planeSegmentations, 3), depth=numOutputPlanes)\n    #D_diff = tf.clip_by_value(tf.abs(planeDepths - tf.reduce_sum(planeDepths * S, 3, keep_dims=True)), 0, 1) * smoothBoundary + tf.clip_by_value(1 - smoothBoundary - occlusionBoundary, 0, 1)\n    #DS_diff = tf.exp(-tf.pow(1 - D_diff, 2) / sigmaDepthDiff) - tf.exp(-1 / sigmaDepthDiff) * S\n    #DS_diff = DS_diff * smoothBoundary + (tf.exp(-1 / sigmaDepthDiff) * occlusionBoundary + tf.clip_by_value(1 - smoothBoundary - occlusionBoundary, 0, 1)) * (1 - S)\n\n    maxDepthDiff = 0.5\n    S = planeSegmentations\n    D_diff = tf.abs(planeDepths - tf.reduce_sum(planeDepths * S, 3, keep_dims=True))\n    DS_diff = tf.clip_by_value(D_diff / maxDepthDiff, 0, 1)\n    DS_diff = DS_diff * (1 - occlusionBoundary)\n    #+ (1 - S) * occlusionBoundary * 0.1\n    \n    kernel_size = 5\n    neighbor_kernel_array = gaussian(kernel_size)\n    neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n    neighbor_kernel_array /= neighbor_kernel_array.sum()\n    neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n    neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n\n    DS = tf.nn.depthwise_conv2d(DS_diff, tf.tile(neighbor_kernel, [1, 1, numOutputPlanes, 1]), strides=[1, 1, 1, 1], padding=\'VALID\')\n    padding = (kernel_size - 1) / 2\n    DS = tf.pad(DS, paddings = [[0, 0], [padding, padding], [padding, padding], [0, 0]])\n    \n    P = originalSegmentations\n    P = tf.clip_by_value(P, 1e-4, 1)\n    confidence = P * tf.exp(-coef[1] * DS)\n    #confidence = coef[0] * P + tf.exp(-coef[1] * DS) + tf.exp(-coef[2] * S_diff)\n    #confidence[:, :, :, numOutputPlanes] = 1e-4\n    #confidence = tf.clip(confidence, 1e-4, 1)\n    refined_segmentation = tf.nn.softmax(tf.log(confidence))\n    return refined_segmentation\n\n\ndef segmentationRefinementModuleBoundary(planeSegmentations, planeDepths, occlusionBoundary = 0, smoothBoundary = 0, numOutputPlanes = 20, numIterations=20):\n    #maxDepthDiff = tf.Variable(0.3)\n    #sigmaDepthDiff = tf.Variable(0.5)\n    maxDepthDiff = 0.3\n    sigmaDepthDiff = 0.5\n\n    refined_segmentation = planeSegmentations\n\n    #occlusionBoundary = tf.slice(boundaries, [0, 0, 0, 1], [boundaries.shape[0], boundaries.shape[1], boundaries.shape[2], 1])\n    #smoothBoundary = tf.slice(boundaries, [0, 0, 0, 2], [boundaries.shape[0], boundaries.shape[1], boundaries.shape[2], 1])\n    for _ in xrange(numIterations):\n        refined_segmentation = meanfieldModuleBoundary(refined_segmentation, planeSegmentations, planeDepths, occlusionBoundary=occlusionBoundary, smoothBoundary=smoothBoundary, numOutputPlanes=numOutputPlanes, sigmaDepthDiff=sigmaDepthDiff)\n        continue\n    return refined_segmentation\n\n\ndef planeMapModule(depth, normal, ranges):\n    #ranges = tf.reshape(ranges, [-1, 3])\n\n    planes = tf.reduce_sum(normal * ranges, 3, keep_dims=True) * depth * normal\n    return planes\n    \n# def planeFittingModule(depth, normal, numPlanes=50, numGlobalPlanes=20, planeAreaThreshold=3*4):\n#     width = int(depth.shape[2])\n#     height = int(depth.shape[1])\n\n#     focalLength = 517.97\n#     urange = (tf.range(width, dtype=tf.float32) / (width + 1) - 0.5) / focalLength * 641\n#     urange = tf.tile(tf.reshape(urange, [1, -1]), [height, 1])\n#     vrange = (tf.range(height, dtype=tf.float32) / (height + 1) - 0.5) / focalLength * 481\n#     vrange = tf.tile(tf.reshape(vrange, [-1, 1]), [1, width])\n            \n#     ranges = tf.stack([urange, tf.ones([height, width]), -vrange], axis=2)\n#     ranges = tf.expand_dims(ranges, 0)\n\n#     batchSize = int(depth.shape[0])\n#     planeDiffThreshold = 0.1\n#     #plane parameter for each pixel\n#     planeMap = planeMapModule(depth, normal, ranges)\n    \n#     kernel_size = 3\n#     neighbor_kernel_array = gaussian(kernel_size)\n#     neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n#     neighbor_kernel_array /= neighbor_kernel_array.sum()\n#     neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n#     neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n#     #smoothedPlaneMap = tf.nn.depthwise_conv2d(planeMap, tf.tile(neighbor_kernel, [1, 1, 3, 1]), strides=[1, 1, 1, 1], padding=\'SAME\')\n#     median_kernel_array = np.zeros((3, 3, 1, 9))\n#     for index in xrange(9):\n#         median_kernel_array[index / 3, index % 3, 0, index] = 1\n#         continue\n#     median_kernel = tf.constant(median_kernel_array.reshape(-1), shape=median_kernel_array.shape, dtype=tf.float32)\n#     smoothedPlaneMap = tf.nn.depthwise_conv2d(planeMap, tf.tile(median_kernel, [1, 1, 3, 1]), strides=[1, 1, 1, 1], padding=\'SAME\')\n#     smoothedPlaneMap, _ = tf.nn.top_k(tf.reshape(smoothedPlaneMap, [batchSize, height, width, 3, 9]), k=5)\n#     planeMap = tf.squeeze(tf.slice(smoothedPlaneMap, [0, 0, 0, 0, 4], [batchSize, height, width, 3, 1]), axis=4)\n\n#     #planeDiff = tf.norm(planeMap - tf.nn.depthwise_conv2d(planeMap, tf.tile(neighbor_kernel, [1, 1, 3, 1]), strides=[1, 1, 1, 1], padding=\'SAME\'), axis=3, keep_dims=True)\n#     smoothedPlaneMap = tf.nn.depthwise_conv2d(planeMap, tf.tile(median_kernel, [1, 1, 3, 1]), strides=[1, 1, 1, 1], padding=\'SAME\')\n#     planeDiff = tf.reduce_max(tf.norm(tf.expand_dims(planeMap, -1) - tf.reshape(smoothedPlaneMap, [batchSize, height, width, 3, 9]), axis=3, keep_dims=True), axis=4)\n#     boundaryMask = tf.cast(tf.less(planeDiff, planeDiffThreshold), tf.float32)\n    \n#     #opening\n#     erosionKernel = np.array([[-1, 0, -1], [0, 0, 0], [-1, 0, -1]], dtype=np.float32).reshape([3, 3, 1])\n#     dilationKernel = np.array([[-1, 0, -1], [0, 0, 0], [-1, 0, -1]], dtype=np.float32).reshape([3, 3, 1])\n#     boundaryMask = tf.nn.erosion2d(boundaryMask, kernel=erosionKernel, strides=[1, 1, 1, 1], rates=[1, 1, 1, 1], padding=\'SAME\')\n    \n#     #region indices\n#     assignment = tf.reshape(tf.range(batchSize * height * width, dtype=tf.float32) + 1, [batchSize, height, width, 1]) * boundaryMask\n#     with tf.variable_scope(""flooding"") as scope:\n#         scope.reuse_variables()\n#         for _ in xrange(width / 2):\n#             assignment = tf.nn.max_pool(assignment, ksize=[1, 5, 5, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\') * boundaryMask\n#             continue\n#         pass\n#     #inds, mask, count = tf.unique_with_counts(tf.concat([tf.constant(0, shape=[1], dtype=tf.float32), tf.reshape(assignment, [-1])], axis=0))\n#     #ignoredInds = tf.range(count.shape, dtype=tf.float32) * tf.less(count, planeAreaThreshold)\n#     assignment = tf.reshape(assignment, [-1])\n    \n#     #find unique regions\n#     inds, mask, count = tf.unique_with_counts(assignment)\n#     ignoredInds = tf.boolean_mask(inds, tf.less(count, planeAreaThreshold))\n#     assignment = assignment * (1 - tf.reduce_max(tf.cast(tf.equal(tf.expand_dims(assignment, -1), tf.expand_dims(ignoredInds, 0)), tf.float32), axis=1))\n#     inds, mask, count = tf.unique_with_counts(tf.concat([tf.constant(0, shape=[1], dtype=tf.float32), assignment], axis=0))\n        \n#     mask = tf.slice(mask, [1], [batchSize * height * width])\n#     mask = tf.reshape(mask, [batchSize, height, width, 1])\n#     #inds = tf.boolean_mask(inds, tf.greater(count, width * height / (16 * 16)))\n#     batchInds = tf.equal(tf.cast(tf.tile(tf.reshape(inds - 1, [1, -1]), [batchSize, 1]), tf.int32) / (width * height), tf.expand_dims(tf.range(batchSize), -1))\n#     counts = tf.count_nonzero(batchInds, axis=1)\n#     counts = tf.concat([tf.constant([1], dtype=tf.int64), counts], axis=0)\n#     counts = tf.slice(tf.cumsum(counts), [0], [batchSize])\n#     batchPlaneInds = tf.reshape(tf.range(numPlanes), [1, -1]) + tf.cast(tf.reshape(counts, [-1, 1]), tf.int32)\n#     #batchPlaneInds = tf.tile(tf.reshape(tf.range(numPlanes, dtype=tf.int32) + 1, [1, 1, 1, -1]), [batchSize, 1, 1, 1])\n#     planeMasks = tf.cast(tf.equal(mask, tf.reshape(batchPlaneInds, [batchSize, 1, 1, numPlanes])), tf.float32)\n\n#     planeMasks_test = planeMasks\n\n\n#     planeAreas = tf.clip_by_value(tf.reduce_sum(planeMasks, axis=[1, 2]), 1e-4, width * height)\n#     #planeAreas, sortInds = tf.nn.top_k(planeAreas, k=numPlanes)\n#     #sortMap = tf.one_hot(sortInds, depth=numPlanes, axis=1)\n#     #planeMasks = tf.reshape(tf.matmul(tf.reshape(planeMasks, [-1, height * width, numPlanes]), sortMap), [-1, height, width, numPlanes])\n\n#     #fit plane based on mask\n#     planesNormal = tf.reduce_sum(tf.expand_dims(normal, 3) * tf.expand_dims(planeMasks, -1), axis=[1, 2]) / tf.expand_dims(planeAreas, -1)\n#     planesNormal = tf.nn.l2_normalize(planesNormal, 2)\n\n#     weightedABC = tf.transpose(tf.reshape(tf.matmul(tf.reshape(ranges, [-1, 3]), tf.reshape(planesNormal, [-1, 3]), transpose_b=True), [height, width, batchSize, numPlanes]), [2, 0, 1, 3])\n#     planesD = tf.reduce_sum(weightedABC * depth * planeMasks, axis=[1, 2]) / planeAreas\n#     planesD = tf.expand_dims(planesD, -1)\n#     planes = planesNormal * planesD\n    \n#     #globalPlanes = tf.slice(planes, [0, 0, 0], [batchSize, numGlobalPlanes, 3])\n#     #planes = tf.transpose(tf.matmul(planes, sortMap, transpose_a=True), [0, 2, 1])\n#     #planesNormal = tf.slice(planesNormal, [0, 0, 0], [batchSize, numGlobalPlanes, 3])\n#     #planesD = tf.slice(planesD, [0, 0, 0], [batchSize, numGlobalPlanes, 1])\n\n#     normalDotThreshold = np.cos(np.deg2rad(5))\n#     distanceThreshold = 0.05\n#     X = depth * tf.expand_dims(urange, -1)\n#     Y = depth\n#     Z = -depth * tf.expand_dims(vrange, -1)\n#     XYZ = tf.concat([X, Y, Z], axis=3)\n#     XYZ = tf.reshape(XYZ, [-1, height * width, 3])\n    \n#     planesNormal = -planesNormal\n#     distance = tf.reshape(tf.abs(tf.matmul(XYZ, planesNormal, transpose_b=True) + tf.reshape(planesD, [-1, 1, numPlanes])), [-1, height, width, numPlanes])\n#     angle = tf.reshape(tf.abs(tf.matmul(tf.reshape(normal, [-1, height * width, 3]), planesNormal, transpose_b=True)), [-1, height, width, numPlanes])\n\n#     explainedPlaneMasks = tf.cast(tf.logical_and(tf.greater(angle, normalDotThreshold), tf.less(distance, distanceThreshold)), tf.float32)\n#     explainedPlaneMasks = tf.nn.dilation2d(explainedPlaneMasks, filter=np.tile(dilationKernel, [1, 1, numPlanes]), strides=[1, 1, 1, 1], rates=[1, 1, 1, 1], padding=\'SAME\')\n#     explainedPlaneMasks = tf.nn.erosion2d(explainedPlaneMasks, kernel=np.tile(erosionKernel, [1, 1, numPlanes]), strides=[1, 1, 1, 1], rates=[1, 1, 1, 1], padding=\'SAME\')    \n\n#     with tf.variable_scope(""expansion"") as scope:\n#         scope.reuse_variables()\n#         for _ in xrange(width / 6):\n#             planeMasks = tf.nn.max_pool(planeMasks, ksize=[1, 13, 13, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\') * explainedPlaneMasks\n#             continue\n#         pass\n        \n#     planeAreas = tf.reduce_sum(planeMasks, axis=[1, 2])\n#     planeAreas, sortInds = tf.nn.top_k(planeAreas, k=numPlanes)\n#     sortMap = tf.one_hot(sortInds, depth=numPlanes, axis=1)\n#     planeMasks = tf.reshape(tf.matmul(tf.reshape(planeMasks, [-1, height * width, numPlanes]), sortMap), [-1, height, width, numPlanes])\n#     planes = tf.transpose(tf.matmul(planes, sortMap, transpose_a=True), [0, 2, 1])\n\n#     #remove duplicate planes by expanding each plane mask, if two masks coincide, remove one of them\n#     substractionMatrix = -tf.cast(tf.less(tf.reshape(tf.range(numPlanes), [-1, 1]), tf.reshape(tf.range(numPlanes), [1, -1])), tf.float32) + tf.eye(numPlanes)\n#     substractionMatrix = tf.tile(tf.expand_dims(substractionMatrix, 0), [batchSize, 1, 1])\n#     planeMasks = tf.clip_by_value(tf.reshape(tf.matmul(tf.reshape(planeMasks, [-1, height * width, numPlanes]), substractionMatrix), [-1, height, width, numPlanes]), 0, 1)\n\n\n#     planeMasksWithoutBoundary = planeMasks * boundaryMask\n#     planeAreas = tf.reduce_sum(planeMasksWithoutBoundary, axis=[1, 2])\n#     maxMeanDepthThreshold = 10\n#     planeAreas = tf.clip_by_value(planeAreas, 1e-4, width * height)\n#     #validPlaneMask = tf.cast(tf.logical_and(tf.logical_or(tf.greater(planeAreas, planeAreaThreshold), tf.equal(tf.argmax(np.abs(planes), 2), 2)), tf.less(tf.reduce_sum(planeMasksWithoutBoundary * depth, axis=[1, 2]) / planeAreas, maxMeanDepthThreshold)), tf.float32)\n#     #validPlaneMask = tf.cast(tf.equal(tf.argmax(np.abs(planes), 2), 2), tf.float32)\n#     #planeAreas, sortInds = tf.nn.top_k(planeAreas, k=numPlanes)\n#     #sortMap = tf.one_hot(sortInds, depth=numPlanes, axis=1)\n#     #planeMasks = tf.reshape(tf.matmul(tf.reshape(planeMasks, [-1, height * width, numPlanes]), sortMap), [-1, height, width, numPlanes])\n\n#     if False:\n#         planes = tf.transpose(tf.matmul(planes, sortMap, transpose_a=True), [0, 2, 1])\n#     else:\n#         #fit planes based on merged masks\n#         planesNormal = tf.reduce_sum(tf.expand_dims(normal, 3) * tf.expand_dims(planeMasksWithoutBoundary, -1), axis=[1, 2]) / tf.expand_dims(planeAreas, -1)\n#         planesNormal = tf.nn.l2_normalize(planesNormal, 2)\n\n#         weightedABC = tf.transpose(tf.reshape(tf.matmul(tf.reshape(ranges, [-1, 3]), tf.reshape(planesNormal, [-1, 3]), transpose_b=True), [height, width, batchSize, numPlanes]), [2, 0, 1, 3])\n#         planesD = tf.reduce_sum(weightedABC * depth * planeMasksWithoutBoundary, axis=[1, 2]) / planeAreas\n#         planesD = tf.expand_dims(planesD, -1)\n#         planes = planesNormal * planesD\n#         pass\n\n#     validPlaneMask = tf.cast(tf.less(tf.reduce_sum(planeMasksWithoutBoundary * depth, axis=[1, 2]) / planeAreas, maxMeanDepthThreshold), tf.float32)\n#     planeMasks = planeMasks * tf.expand_dims(tf.expand_dims(validPlaneMask, 1), 1)\n#     planes = planes * tf.expand_dims(validPlaneMask, -1)\n#     planeAreas = planeAreas * validPlaneMask\n            \n\n#     # planeAreas = tf.reduce_sum(localPlaneMasks, axis=[1, 2])\n#     # planeAreas, sortInds = tf.nn.top_k(planeAreas, k=numPlanes)\n#     # sortMap = tf.one_hot(sortInds, depth=numPlanes, axis=1)\n#     # localPlaneMasks = tf.reshape(tf.matmul(tf.reshape(localPlaneMasks, [-1, height * width, numPlanes]), sortMap), [-1, height, width, numPlanes])\n#     # localPlanes = tf.transpose(tf.matmul(localPlanes, sortMap, transpose_a=True), [0, 2, 1])\n\n#     # substractionMatrix = -tf.cast(tf.less(tf.reshape(tf.range(numPlanes), [-1, 1]), tf.reshape(tf.range(numPlanes), [1, -1])), tf.float32) + tf.eye(numPlanes)\n#     # substractionMatrix = tf.tile(tf.expand_dims(substractionMatrix, 0), [batchSize, 1, 1])\n#     # localPlaneMasks = tf.clip_by_value(tf.reshape(tf.matmul(tf.reshape(localPlaneMasks, [-1, height * width, numPlanes]), substractionMatrix), [-1, height, width, numPlanes]), 0, 1)\n\n\n#     # planeMasksWithoutBoundary = localPlaneMasks * boundaryMask\n#     # planeAreas = tf.reduce_sum(planeMasksWithoutBoundary, axis=[1, 2])\n#     # maxMeanDepthThreshold = 10\n#     # #validPlaneMask = tf.cast(tf.logical_and(tf.logical_or(tf.greater(planeAreas, planeAreaThreshold), tf.equal(tf.argmax(np.abs(planes), 2), 2)), tf.less(tf.reduce_sum(planeMasksWithoutBoundary * depth, axis=[1, 2]) / planeAreas, maxMeanDepthThreshold)), tf.float32)\n#     # #validPlaneMask = tf.cast(tf.equal(tf.argmax(np.abs(planes), 2), 2), tf.float32)\n#     # validPlaneMask = tf.cast(tf.less(tf.reduce_sum(planeMasksWithoutBoundary * depth, axis=[1, 2]) / planeAreas, maxMeanDepthThreshold), tf.float32)\n#     # localPlanes = localPlanes * tf.expand_dims(validPlaneMask, -1)\n#     # localPlaneMasks = localPlaneMasks * tf.expand_dims(tf.expand_dims(validPlaneMask, 1), 1)\n#     # planeAreas = planeAreas * validPlaneMask\n#     # planeAreas, sortInds = tf.nn.top_k(planeAreas, k=numPlanes)\n#     # sortMap = tf.one_hot(sortInds, depth=numPlanes, axis=1)\n#     # localPlaneMasks = tf.reshape(tf.matmul(tf.reshape(localPlaneMasks, [-1, height * width, numPlanes]), sortMap), [-1, height, width, numPlanes])\n\n#     # planeMasksWithoutBoundary = localPlaneMasks * boundaryMask\n#     # planeAreas = tf.clip_by_value(planeAreas, 1e-4, width * height)\n#     # planesNormal = tf.reduce_sum(tf.expand_dims(normal, 3) * tf.expand_dims(planeMasksWithoutBoundary, -1), axis=[1, 2]) / tf.expand_dims(planeAreas, -1)\n#     # planesNormal = tf.nn.l2_normalize(planesNormal, 2)\n\n#     # weightedABC = tf.transpose(tf.reshape(tf.matmul(tf.reshape(ranges, [-1, 3]), tf.reshape(planesNormal, [-1, 3]), transpose_b=True), [height, width, batchSize, numPlanes]), [2, 0, 1, 3])\n#     # planesD = tf.reduce_sum(weightedABC * depth * planeMasksWithoutBoundary, axis=[1, 2]) / planeAreas\n#     # planesD = tf.expand_dims(planesD, -1)\n#     # localPlanes = planesNormal * planesD\n    \n\n#     #find local ground truth\n#     urange = tf.reshape(tf.range(width, dtype=tf.float32), [1, -1, 1])\n#     planeXs = tf.reduce_max(planeMasks, axis=1)\n#     planeMinX = width - tf.reduce_max(planeXs * (float(width) - urange), axis=1)\n#     planeMaxX = tf.reduce_max(planeXs * urange, axis=1)\n\n#     vrange = tf.reshape(tf.range(height, dtype=tf.float32), [1, -1, 1])\n#     planeYs = tf.reduce_max(planeMasks, axis=2)\n#     planeMinY = height - tf.reduce_max(planeYs * (float(height) - vrange), axis=1)\n#     planeMaxY = tf.reduce_max(planeYs * vrange, axis=1)\n\n#     planeBoxes = tf.stack([planeMinX, planeMaxX, planeMinY, planeMaxY], axis=2)\n\n#     localPlaneWidthThreshold = 64\n#     localPlaneHeightThreshold = 64\n#     globalPlaneAreaThreshold = 16 * 16\n#     globalPlaneWidthThreshold = 8\n    \n#     globalPlaneMask = tf.logical_or(tf.greater(planeMaxX - planeMinX, localPlaneWidthThreshold), tf.greater(planeMaxY - planeMinY, localPlaneHeightThreshold))\n#     globalPlaneMask = tf.logical_and(globalPlaneMask, tf.greater((planeMaxX - planeMinX) * (planeMaxY - planeMinY), globalPlaneAreaThreshold))\n#     globalPlaneMask = tf.logical_and(globalPlaneMask, tf.greater(planeAreas / (planeMaxY + 1 - planeMinY), globalPlaneWidthThreshold))\n#     #globalPlaneMask = tf.cast(tf.squeeze(globalPlaneMask, axis=[2]), tf.float32)\n#     globalPlaneMask = tf.cast(globalPlaneMask, tf.float32)\n#     weightedPlaneAreas = globalPlaneMask * (planeAreas + height * width) + (1 - globalPlaneMask) * planeAreas\n#     planeAreas, sortInds = tf.nn.top_k(weightedPlaneAreas, k=numPlanes)\n#     sortMap = tf.one_hot(sortInds, depth=numPlanes, axis=1)\n#     planeMasks = tf.reshape(tf.matmul(tf.reshape(planeMasks, [-1, height * width, numPlanes]), sortMap), [-1, height, width, numPlanes])\n#     planes = tf.transpose(tf.matmul(planes, sortMap, transpose_a=True), [0, 2, 1])\n#     planeBoxes = tf.transpose(tf.matmul(planeBoxes, sortMap, transpose_a=True), [0, 2, 1])\n#     globalPlaneMask = tf.squeeze(tf.matmul(tf.expand_dims(globalPlaneMask, 1), sortMap), axis=1)\n    \n\n\n#     #boundary ground truth\n#     boundary = tf.nn.max_pool(planeMasks, ksize=[1, 5, 5, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n    \n#     boundaryType = tf.cast(tf.round(tf.reduce_sum(boundary, axis=3, keep_dims=True)), tf.int32)\n#     singleBoundary = tf.cast(tf.equal(tf.reduce_sum(boundary - planeMasks, axis=3, keep_dims=True), 1), tf.float32)\n\n#     commonBoundary = tf.cast(tf.equal(boundaryType, 2), tf.float32)\n#     #boundary = boundary * commonBoundary\n#     boundaryCoef = tf.cast(tf.round(tf.cumsum(boundary, axis=3)), tf.float32)\n\n#     #boundary_1 = tf.cast(tf.equal(boundaryCoef, 1), tf.float32) * boundary\n#     #boundary_1 = tf.cast(tf.equal(boundaryCoef, 1), tf.float32) * boundary\n    \n#     boundaryPlane_1 = tf.reshape(tf.matmul(tf.reshape(tf.cast(tf.equal(boundaryCoef, 1), tf.float32) * boundary, [batchSize, height * width, numPlanes]), planes), [batchSize, height, width, 3])\n#     boundaryD_1 = tf.maximum(tf.norm(boundaryPlane_1, axis=3, keep_dims=True), 1e-4)\n#     boundaryNormal_1 = boundaryPlane_1 / boundaryD_1\n#     boundaryDepth_1 = boundaryD_1 / tf.maximum(tf.reduce_sum(boundaryNormal_1 * ranges, axis=3, keep_dims=True), 1e-4)\n\n#     boundaryPlane_2 = tf.reshape(tf.matmul(tf.reshape(tf.cast(tf.equal(boundaryCoef, 2), tf.float32) * boundary, [batchSize, height * width, numPlanes]), planes), [batchSize, height, width, 3])\n#     boundaryD_2 = tf.maximum(tf.norm(boundaryPlane_2, axis=3, keep_dims=True), 1e-4)\n#     boundaryNormal_2 = boundaryPlane_2 / boundaryD_2\n#     boundaryDepth_2 = boundaryD_2 / tf.maximum(tf.reduce_sum(boundaryNormal_2 * ranges, axis=3, keep_dims=True), 1e-4)\n\n#     depthDiffThreshold = 0.05\n#     #occlusionBoundary = tf.cast(tf.greater(tf.abs(boundaryDepth_1 - boundaryDepth_2), depthDiffThreshold), tf.float32) * commonBoundary\n#     largerMask = tf.nn.max_pool(tf.cast(tf.greater_equal(boundaryDepth_1, boundaryDepth_2), tf.float32) * commonBoundary, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\')\n#     smallerMask = tf.nn.max_pool(tf.cast(tf.less_equal(boundaryDepth_1, boundaryDepth_2), tf.float32) * commonBoundary, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\')\n#     smoothBoundary = tf.nn.max_pool(largerMask * smallerMask, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\')\n#     #depthDiff = tf.abs(depth - tf.nn.depthwise_conv2d(depth, neighbor_kernel, strides=[1, 1, 1, 1], padding=\'SAME\'))\n#     #occlusionBoundary = tf.cast(tf.greater(depthDiff, depthDiffThreshold), tf.float32) * commonBoundary\n    \n#     #boundaryConvexity = tf.cast(tf.less(tf.reduce_sum(boundaryNormal_1 * boundaryNormal_2, axis=3, keep_dims=True), 0), tf.float32)\n#     #convexBoundary = smoothBoundary * boundaryConvexity\n#     #concaveBoundary = smoothBoundary * (1 - boundaryConvexity)\n\n    \n#     occlusionBoundary = commonBoundary - smoothBoundary\n\n#     singleBoundary = tf.maximum(singleBoundary - tf.nn.max_pool(commonBoundary, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\'), 0)\n#     boundaries = tf.concat([singleBoundary, occlusionBoundary, smoothBoundary], axis=3)\n#     #boundaries = tf.concat([tf.maximum(tf.minimum((boundaryDepth_1 - boundaryDepth_2) + 0.5, 1), 0)], axis=3)\n#     #boundaries = tf.concat([tf.maximum(tf.minimum(boundaryDepth_1 / 10, 1), 0), tf.maximum(tf.minimum(boundaryDepth_2 / 10, 1), 0), tf.maximum(tf.minimum((boundaryDepth_1 - boundaryDepth_2) + 0.5, 1), 0)], axis=3)\n#     boundaries = 1 - tf.nn.max_pool(1 - boundaries, ksize=[1, 2, 2, 1], strides=[1, 1, 1, 1], padding=\'SAME\')\n    \n#     if True:\n#         coef = tf.pow(tf.constant(2, dtype=tf.float64), tf.range(numPlanes, dtype=tf.float64))\n#         planeMask = tf.cast(tf.round(tf.tensordot(tf.cast(planeMasks, tf.float64), coef, axes=[[3], [0]])), tf.int64)\n#         #localPlaneMask = tf.cast(tf.round(tf.tensordot(tf.cast(localPlaneMasks, tf.float64), coef, axes=[[3], [0]])), tf.int64)\n#         #coef = tf.pow(tf.constant(2, dtype=tf.float64), tf.range(numPlanes, dtype=tf.float64))\n#         #planeCroppedMask = tf.cast(tf.round(tf.tensordot(tf.cast(tf.greater(planeCroppedMasks, 0.5), tf.float64), coef, axes=[[3], [0]])), tf.int64)\n#         numGlobalPlanes = tf.reduce_sum(globalPlaneMask, axis=1)\n\n#         gridScores, gridPlanes, gridMasks = findLocalPlanes(planes, planeMasks)\n#         return planes, planeMask, numGlobalPlanes, boundaries, gridScores, gridPlanes, gridMasks\n\n    \n#     maskWidth = 32\n#     maskHeight = 32\n#     planeCroppedMasks = []\n#     for batchIndex in xrange(batchSize):\n#         boxes = planeBoxes[batchIndex]\n#         masks = tf.transpose(planeMasks[batchIndex], [2, 0, 1])\n#         croppedMasks = []\n#         for planeIndex in xrange(numPlanes):\n#         #for planeIndex in xrange(1):\n#             box = boxes[planeIndex]\n#             mask = masks[planeIndex]\n#             #minX = tf.cond(tf.less(planeIndex, tf.numValidPlanes[batchIndex]), lambda: tf.cast(box[0], tf.int32)\n#             minX = tf.cast(box[0], tf.int32)\n#             maxX = tf.cast(box[1], tf.int32)\n#             minY = tf.cast(box[2], tf.int32)\n#             maxY = tf.cast(box[3], tf.int32)\n#             minX = tf.minimum(minX, maxX)\n#             minY = tf.minimum(minY, maxY)\n#             croppedMask = tf.slice(mask, [minY, minX], [maxY - minY + 1, maxX - minX + 1])\n#             #croppedMask = tf.slice(mask, [0, 0], [height - 10, width - 10])\n#             croppedMask = tf.image.resize_bilinear(tf.expand_dims(tf.expand_dims(croppedMask, -1), 0), [maskHeight, maskWidth])\n#             croppedMasks.append(croppedMask)\n#             continue\n#         planeCroppedMasks.append(tf.squeeze(tf.concat(croppedMasks, axis=3)))\n#         continue\n#     planeCroppedMasks = tf.stack(planeCroppedMasks, axis=0)   \n\n#     gridMinX = []\n#     gridMaxX = []\n#     gridMinY = []\n#     gridMaxY = []\n#     for stride in [8, 16, 32]:\n#         boxSize = stride * 2\n#         xs = tf.tile(tf.expand_dims(tf.range(width / stride, dtype=tf.float32) * stride + stride / 2, 0), [height / stride, 1])\n#         ys = tf.tile(tf.expand_dims(tf.range(height / stride, dtype=tf.float32) * stride + stride / 2, 1), [1, width / stride])\n#         gridMinX.append(tf.reshape(xs - boxSize / 2, [1, -1, 1]))\n#         gridMaxX.append(tf.reshape(xs + boxSize / 2, [1, -1, 1]))\n#         gridMinY.append(tf.reshape(ys - boxSize / 2, [1, -1, 1]))\n#         gridMaxY.append(tf.reshape(ys + boxSize / 2, [1, -1, 1]))\n#         continue\n    \n#     gridMinX = tf.tile(tf.concat(gridMinX, axis=1), [batchSize, 1, 1])\n#     gridMaxX = tf.tile(tf.concat(gridMaxX, axis=1), [batchSize, 1, 1])\n#     gridMinY = tf.tile(tf.concat(gridMinY, axis=1), [batchSize, 1, 1])\n#     gridMaxY = tf.tile(tf.concat(gridMaxY, axis=1), [batchSize, 1, 1])\n\n#     planeMinX = tf.matmul(tf.reshape(planeMinX, [batchSize, 1, numPlanes]), sortMap)\n#     planeMaxX = tf.matmul(tf.reshape(planeMaxX, [batchSize, 1, numPlanes]), sortMap)\n#     planeMinY = tf.matmul(tf.reshape(planeMinY, [batchSize, 1, numPlanes]), sortMap)\n#     planeMaxY = tf.matmul(tf.reshape(planeMaxY, [batchSize, 1, numPlanes]), sortMap)\n\n#     intersection = tf.maximum(tf.minimum(gridMaxX, planeMaxX) - tf.maximum(gridMinX, planeMinX) + 1, 0.) * tf.maximum(tf.minimum(gridMaxY, planeMaxY) - tf.maximum(gridMinY, planeMinY) + 1, 0.)\n#     union = (gridMaxX - gridMinX + 1) * (gridMaxY - gridMinY + 1) + (planeMaxX - planeMinX + 1) * (planeMaxY - planeMinY + 1) - intersection\n#     IOU = intersection / union\n#     maxIOUInds = tf.argmax(IOU, axis=1)\n#     maxIOU = tf.reduce_max(IOU, axis=1)\n#     IOU = IOU * tf.one_hot(tf.argmax(IOU, 1), depth=IOU.shape[1], axis=1)\n#     #IOUThreshold = tf.concat([tf.ones((1, (width / 8) * (height / 8), 1)) * 0.2, tf.ones((1, (width / 16) * (height / 16), 1)) * 0.3, tf.ones((1, (width / 32) * (height / 32), 1)) * 0.7], axis=1)\n#     #activeGridMask = tf.one_hot(tf.argmax(IOU, 2), depth=IOU.shape[2], axis=2) * tf.cast(tf.greater(IOU, IOUThreshold), tf.float32)\n#     activeGridMask = tf.one_hot(tf.argmax(IOU, 2), depth=IOU.shape[2], axis=2) * (1 - tf.expand_dims(globalPlaneMask, 1))\n#     gridScores = tf.reduce_sum(activeGridMask, axis=2, keep_dims=True)\n#     activeGridMask = tf.expand_dims(activeGridMask, -1)\n#     gridPlanes = tf.reduce_sum(activeGridMask * tf.expand_dims(planes, 1), axis=2)\n#     gridMasks = tf.reduce_sum(activeGridMask * tf.expand_dims(tf.transpose(tf.reshape(planeCroppedMasks, [batchSize, -1, numPlanes]), [0, 2, 1]), 1), axis=2)\n\n#     activeGridMask = tf.squeeze(activeGridMask, axis=3)\n#     #gridBoxes = tf.reduce_sum(activeGridMask * tf.expand_dims(planeBoxes, 1), axis=2)\n#     gridPlaneMinX = tf.reduce_sum(activeGridMask * planeMinX, axis=2, keep_dims=True)\n#     gridPlaneMaxX = tf.reduce_sum(activeGridMask * planeMaxX, axis=2, keep_dims=True)\n#     gridPlaneMinY = tf.reduce_sum(activeGridMask * planeMinY, axis=2, keep_dims=True)\n#     gridPlaneMaxY = tf.reduce_sum(activeGridMask * planeMaxY, axis=2, keep_dims=True)\n#     gridWidths = gridMaxX - gridMinX\n#     gridHeights = gridMaxY - gridMinY\n\n#     gridOffsetX = ((gridPlaneMinX + gridPlaneMaxX) - (gridMinX + gridMaxX)) / 2 / gridWidths\n#     gridOffsetY = ((gridPlaneMinY + gridPlaneMaxY) - (gridMinY + gridMaxY)) / 2 / gridHeights\n#     gridW = (gridPlaneMaxX - gridPlaneMinX) / gridWidths\n#     gridH = (gridPlaneMaxY - gridPlaneMinY) / gridHeights\n#     gridBoxes = tf.concat([gridOffsetX, gridOffsetY, gridW, gridH], axis=2)\n    \n    \n#     offset = 0\n#     gridScoresArray = []\n#     gridPlanesArray = []\n#     gridBoxesArray = []\n#     gridMasksArray = []\n#     for stride in [8, 16, 32]:\n#         numGrids = (width / stride) * (height / stride)\n#         gridScoresArray.append(tf.reshape(tf.slice(gridScores, [0, offset, 0], [batchSize, numGrids, 1]), [batchSize, height / stride, width / stride, -1]))\n#         gridPlanesArray.append(tf.reshape(tf.slice(gridPlanes, [0, offset, 0], [batchSize, numGrids, 3]), [batchSize, height / stride, width / stride, -1]))\n#         gridBoxesArray.append(tf.reshape(tf.slice(gridBoxes, [0, offset, 0], [batchSize, numGrids, 4]), [batchSize, height / stride, width / stride, -1]))\n#         gridMasksArray.append(tf.reshape(tf.slice(gridMasks, [0, offset, 0], [batchSize, numGrids, maskWidth * maskHeight]), [batchSize, height / stride, width / stride, -1]))\n#         offset += numGrids\n#         continue\n\n    \n#     if True:\n#         coef = tf.pow(tf.constant(2, dtype=tf.float64), tf.range(numPlanes, dtype=tf.float64))\n#         planeMask = tf.cast(tf.round(tf.tensordot(tf.cast(planeMasks, tf.float64), coef, axes=[[3], [0]])), tf.int64)\n#         #localPlaneMask = tf.cast(tf.round(tf.tensordot(tf.cast(localPlaneMasks, tf.float64), coef, axes=[[3], [0]])), tf.int64)\n#         #coef = tf.pow(tf.constant(2, dtype=tf.float64), tf.range(numPlanes, dtype=tf.float64))\n#         planeCroppedMask = tf.cast(tf.round(tf.tensordot(tf.cast(tf.greater(planeCroppedMasks, 0.5), tf.float64), coef, axes=[[3], [0]])), tf.int64)\n#         numGlobalPlanes = tf.reduce_sum(globalPlaneMask, axis=1)\n\n#         return planes, planeMask, numGlobalPlanes, boundaries, planeBoxes, planeCroppedMask, gridScoresArray, gridPlanesArray, gridBoxesArray, gridMasksArray, maxIOU, maxIOUInds\n    \n#     # coef = tf.pow(tf.constant(0.9, dtype=tf.float64), tf.range(numPlanes, dtype=tf.float64))\n#     # coef = tf.tile(tf.reshape(coef, [1, 1, -1]), [batchSize, 1, 1])\n#     # coef = tf.matmul(coef, tf.cast(sortMap, tf.float64), transpose_b=True)\n#     # #planeMasks = tf.reshape(tf.matmul(tf.reshape(planeMasks, [-1, height * width, numPlanes]), sortMap), [-1, height, width, numPlanes])\n\n#     # assignment = tf.reduce_max(tf.cast(planeMasks, tf.float64) * tf.expand_dims(coef, axis=2), axis=3, keep_dims=True)\n#     # inds, mask, count = tf.unique_with_counts(tf.concat([tf.constant(0), tf.reshape(assignment, [-1])]))\n#     # mask = tf.reshape(tf.slice(mask, [1], [batchSize * height * width * 1], [batchSize, height, width, 1])\n\n#     # coef = tf.tile(tf.reshape(coef, [1, 1, -1]), [batchSize, 1, 1])\n#     # coef = tf.matmul(coef, tf.cast(sortMap, tf.float64), transpose_b=True)\n#     # coef = tf.reshape(tf.range(numPlanes)\n#     # planeMasks = tf.cast(tf.equal(mask, tf.tile(, [1, 1, 1, numPlanes]), [batchSize, 1, 1, 1])), tf.float32)\n    \n#     # planeAreas = tf.clip_by_value(tf.reduce_sum(planeMasks, axis=[1, 2]), 1e-4, width * height)\n#     # planeAreas, sortInds = tf.nn.top_k(planeAreas, k=numPlanes)\n#     # sortMap = tf.one_hot(sortInds, depth=numPlanes, axis=1)\n#     # planeMasks = tf.reshape(tf.matmul(tf.reshape(planeMasks, [-1, height * width, numPlanes]), sortMap), [-1, height, width, numPlanes])\n\n#     #planeAreas = tf.clip_by_value(tf.reduce_sum(planeMasks, axis=[1, 2]), 1e-4, width * height)\n    \n#     # planesNormal = tf.reduce_sum(tf.expand_dims(normal, 3) * tf.expand_dims(planeMasks, -1), axis=[1, 2]) / tf.expand_dims(planeAreas, -1)\n#     # planesNormal = tf.nn.l2_normalize(planesNormal, 2)\n#     # weightedABC = tf.reshape(tf.matmul(tf.reshape(ranges, [-1, 3]), tf.reshape(planesNormal, [-1, 3]), transpose_b=True), [batchSize, height, width, numPlanes])\n#     # planesD = tf.reduce_sum(weightedABC * depth * planeMasks, axis=[1, 2]) / planeAreas\n#     # planesD = tf.expand_dims(planesD, -1)\n#     # planes = planesNormal * planesD\n\n\n#     if True:\n#         planeMask = tf.cast(tf.round(tf.tensordot(tf.cast(planeMasks, tf.float64), coef, axes=[[3], [0]])), tf.int64)\n#         return planes, planeMask, tf.reduce_sum(validPlaneMask, axis=1)\n\n    \n#     globalPlanes = tf.slice(planes, [0, 0, 0], [batchSize, numGlobalPlanes, 3])\n#     globalPlaneMasks = tf.slice(planeMasks, [0, 0, 0, 0], [batchSize, height, width, numGlobalPlanes])\n\n#     if True:\n#         return planes, planeMasks, tf.reduce_sum(validPlaneMask, axis=1), planeMasks_test, boundaryMask\n#     #return globalPlanes, globalPlaneMasks, tf.reduce_sum(validPlaneMask, axis=1)\n    \n#     globalPlaneMask = tf.reduce_max(globalPlaneMasks, axis=3, keep_dims=True)\n#     smallPlaneMasks = tf.clip_by_value(tf.slice(planeMasks, [0, 0, 0, numGlobalPlanes], [batchSize, height, width, numPlanes - numGlobalPlanes]) - globalPlaneMask, 0, 1)\n#     smallPlaneMasks = tf.nn.dilation2d(smallPlaneMasks, filter=np.tile(dilationKernel, [1, 1, numPlanes - numGlobalPlanes]), strides=[1, 1, 1, 1], rates=[1, 1, 1, 1], padding=\'SAME\')\n#     smallPlaneMasks = tf.concat([globalPlaneMasks, smallPlaneMasks], axis=3)\n\n\n#     IOUThreshold = 0.9\n#     areaThreshold = 0.25\n\n#     blockSize = 16\n#     smallPlaneInds = tf.nn.avg_pool(smallPlaneMasks, ksize=[1, blockSize, blockSize, 1], strides=[1, blockSize, blockSize, 1], padding=\'VALID\')\n#     smallPlaneAreas = tf.clip_by_value(tf.reduce_sum(smallPlaneInds, axis=[1, 2], keep_dims=True), 1e-4, width * height)    \n#     IOU = smallPlaneInds / smallPlaneAreas\n#     inds = smallPlaneInds\n#     smallPlaneInds = tf.one_hot(tf.argmax(smallPlaneInds, 3), depth=numPlanes) * tf.cast(tf.greater_equal(IOU, IOUThreshold), tf.float32) * tf.cast(tf.greater(smallPlaneInds, areaThreshold), tf.float32)\n\n#     blockSmallPlaneMasks_16 = tf.reshape(tf.space_to_depth(smallPlaneMasks, block_size=blockSize), [batchSize, height / blockSize, width / blockSize, blockSize * blockSize, numPlanes])\n#     blockSmallPlanes_16 = tf.reduce_sum(tf.expand_dims(smallPlaneInds, -1) * tf.expand_dims(tf.expand_dims(planes, 1), 1), axis=3)\n#     blockSmallPlaneMasks_16 = tf.reduce_sum(tf.expand_dims(smallPlaneInds, 3) * blockSmallPlaneMasks_16, axis=4)\n#     blockPlaneIndicators_16 = tf.reduce_max(smallPlaneInds, axis=3, keep_dims=True)\n\n    \n#     blockSize = 32\n#     smallPlaneInds = tf.nn.avg_pool(smallPlaneMasks, ksize=[1, blockSize, blockSize, 1], strides=[1, blockSize, blockSize, 1], padding=\'VALID\')\n#     smallPlaneAreas = tf.clip_by_value(tf.reduce_sum(smallPlaneInds, axis=[1, 2], keep_dims=True), 1e-4, width * height)    \n#     IOU = smallPlaneInds / smallPlaneAreas\n#     inds = smallPlaneInds\n#     smallPlaneInds = tf.one_hot(tf.argmax(smallPlaneInds, 3), depth=numPlanes) * tf.cast(tf.greater_equal(IOU, IOUThreshold), tf.float32) * tf.cast(tf.greater(smallPlaneInds, areaThreshold), tf.float32)\n    \n#     blockSmallPlaneMasks_32 = tf.reshape(tf.space_to_depth(smallPlaneMasks, block_size=blockSize), [batchSize, height / blockSize, width / blockSize, blockSize * blockSize, numPlanes])\n#     blockSmallPlanes_32 = tf.reduce_sum(tf.expand_dims(smallPlaneInds, -1) * tf.expand_dims(tf.expand_dims(planes, 1), 1), axis=3)\n#     blockSmallPlaneMasks_32 = tf.reduce_sum(tf.expand_dims(smallPlaneInds, 3) * blockSmallPlaneMasks_32, axis=4)\n#     blockPlaneIndicators_32 = tf.reduce_max(smallPlaneInds, axis=3, keep_dims=True)\n\n#     return globalPlanes, globalPlaneMasks, blockSmallPlanes_16, blockSmallPlaneMasks_16, blockPlaneIndicators_16, blockSmallPlanes_32, blockSmallPlaneMasks_32, blockPlaneIndicators_32, tf.depth_to_space(blockSmallPlaneMasks_16 * blockPlaneIndicators_16, 16), tf.depth_to_space(blockSmallPlaneMasks_32 * blockPlaneIndicators_32, 32), planeMasks_test, planeDiff, boundaryMask\n\n\n# def planeFittingDepthModule(depth)\n#     width = int(depth.shape[2])\n#     height = int(depth.shape[1])\n\n#     focalLength = 517.97\n#     urange = (tf.range(width, dtype=tf.float32) / (width + 1) - 0.5) / focalLength * 641\n#     urange = tf.tile(tf.reshape(urange, [1, -1]), [height, 1])\n#     vrange = (tf.range(height, dtype=tf.float32) / (height + 1) - 0.5) / focalLength * 481\n#     vrange = tf.tile(tf.reshape(vrange, [-1, 1]), [1, width])\n            \n#     ranges = tf.stack([urange, tf.ones([height, width]), -vrange], axis=2)\n#     ranges = tf.expand_dims(ranges, 0)\n\n#     batchSize = int(depth.shape[0])\n\n#     X = depth * tf.expand_dims(urange, -1)\n#     Y = depth\n#     Z = -depth * tf.expand_dims(vrange, -1)\n#     XYZ = tf.concat([X, Y, Z], axis=3)\n#     XYZ = tf.reshape(XYZ, [-1, height * width, 3])\n\n\t\n\t\ndef findLocalPlanes(planes, planeMasks):\n    batchSize = int(planeMasks.shape[0])\n    height = int(planeMasks.shape[1])\n    width = int(planeMasks.shape[2])\n    numPlanes = int(planeMasks.shape[3])\n    \n    maskWidth = 16\n    maskHeight = 16\n\n    urange = tf.reshape(tf.range(width, dtype=tf.float32), [1, -1, 1])\n    planeXs = tf.reduce_max(planeMasks, axis=1)\n    planeMinX = float(width) - tf.reduce_max(planeXs * (float(width) - urange), axis=1)\n    planeMaxX = tf.reduce_max(planeXs * urange, axis=1)\n\n    vrange = tf.reshape(tf.range(height, dtype=tf.float32), [1, -1, 1])\n    planeYs = tf.reduce_max(planeMasks, axis=2)\n    planeMinY = float(height) - tf.reduce_max(planeYs * (float(height) - vrange), axis=1)\n    planeMaxY = tf.reduce_max(planeYs * vrange, axis=1)\n\n\n    localPlaneWidthThreshold = 64\n    localPlaneHeightThreshold = 64\n    localPlaneMask = tf.logical_and(tf.less(planeMaxX - planeMinX, localPlaneWidthThreshold), tf.less(planeMaxY - planeMinY, localPlaneHeightThreshold))\n\n    \n    stride = 8\n    boxSize = 64\n    xs = tf.tile(tf.expand_dims(tf.range(width / stride, dtype=tf.float32) * stride + stride / 2, 0), [height / stride, 1])\n    ys = tf.tile(tf.expand_dims(tf.range(height / stride, dtype=tf.float32) * stride + stride / 2, 1), [1, width / stride])\n    gridMinX = tf.reshape(xs - boxSize / 2, [1, -1, 1])\n    gridMaxX = tf.reshape(xs + boxSize / 2, [1, -1, 1])\n    gridMinY = tf.reshape(ys - boxSize / 2, [1, -1, 1])\n    gridMaxY = tf.reshape(ys + boxSize / 2, [1, -1, 1])\n    \n    gridMinX = tf.tile(gridMinX, [batchSize, 1, 1])\n    gridMaxX = tf.tile(gridMaxX, [batchSize, 1, 1])\n    gridMinY = tf.tile(gridMinY, [batchSize, 1, 1])\n    gridMaxY = tf.tile(gridMaxY, [batchSize, 1, 1])\n\n    padding = boxSize / 2 + 1\n    padding = boxSize / 2 + 1\n    paddedPlaneMasks = tf.concat([tf.zeros([batchSize, height, padding, numPlanes]), planeMasks, tf.zeros([batchSize, height, padding, numPlanes])], axis=2)\n    paddedPlaneMasks = tf.concat([tf.zeros([batchSize, padding, width + padding * 2, numPlanes]), paddedPlaneMasks, tf.zeros([batchSize, padding, width + padding * 2, numPlanes])], axis=1)\n\n    gridPlaneMasks = []\n    for gridY in xrange(height / stride):\n        for gridX in xrange(width / stride):\n            localPlaneMasks = tf.slice(paddedPlaneMasks, [0, gridY * stride + stride / 2 - boxSize / 2 + padding, gridX * stride + stride / 2 - boxSize / 2 + padding, 0], [batchSize, boxSize, boxSize, numPlanes])\n            gridPlaneMasks.append(tf.image.resize_bilinear(localPlaneMasks, [maskHeight, maskWidth]))\n            continue\n        continue\n    gridPlaneMasks = tf.stack(gridPlaneMasks, axis=1)\n    gridPlaneMasks = tf.reshape(gridPlaneMasks, [batchSize, -1, maskHeight * maskWidth, numPlanes])\n\n    planeMinX = tf.expand_dims(planeMinX, 1)\n    planeMaxX = tf.expand_dims(planeMaxX, 1)\n    planeMinY = tf.expand_dims(planeMinY, 1)\n    planeMaxY = tf.expand_dims(planeMaxY, 1)    \n    intersection = tf.maximum(tf.minimum(gridMaxX, planeMaxX) - tf.maximum(gridMinX, planeMinX) + 1, 0.) * tf.maximum(tf.minimum(gridMaxY, planeMaxY) - tf.maximum(gridMinY, planeMinY) + 1, 0.)\n    union = (gridMaxX - gridMinX + 1) * (gridMaxY - gridMinY + 1) + (planeMaxX - planeMinX + 1) * (planeMaxY - planeMinY + 1) - intersection\n    IOU = intersection / union\n    #maxIOUInds = tf.argmax(IOU, axis=1)\n    #maxIOU = tf.reduce_max(IOU, axis=1)\n    IOU = IOU * tf.expand_dims(tf.cast(localPlaneMask, tf.float32), 1)\n    IOU = IOU * tf.one_hot(tf.argmax(IOU, 1), depth=IOU.shape[1], axis=1)\n    IOUThreshold = 1.0 / pow(boxSize / stride, 2)\n    activeGridMask = tf.one_hot(tf.argmax(IOU, 2), depth=IOU.shape[2], axis=2) * tf.cast(tf.greater(IOU, IOUThreshold), tf.float32)\n    \n    #activeGridMask = tf.one_hot(tf.ones((batchSize, IOU.shape[1]), dtype=tf.int32), depth=IOU.shape[2], axis=2)\n    \n    gridScores = tf.reduce_sum(activeGridMask, axis=2, keep_dims=True)\n    activeGridMask = tf.expand_dims(activeGridMask, -1)\n    gridPlanes = tf.reduce_sum(activeGridMask * tf.expand_dims(planes, 1), axis=2)\n    gridMasks = tf.reduce_sum(activeGridMask * tf.transpose(gridPlaneMasks, [0, 1, 3, 2]), axis=2)\n\n    gridScores = tf.reshape(gridScores, [batchSize, height / stride, width / stride, -1])\n    gridPlanes = tf.reshape(gridPlanes, [batchSize, height / stride, width / stride, -1])\n    gridMasks = tf.reshape(gridMasks, [batchSize, height / stride, width / stride, -1])\n    \n    return gridScores, gridPlanes, gridMasks\n\n\ndef findBoundaries(planes, planeMasks):\n    height = int(planeMasks.shape[0])\n    width = int(planeMasks.shape[1])\n    \n    planesD = tf.norm(planes, axis=1, keep_dims=True)\n    planesD = tf.clip_by_value(planesD, 1e-5, 10)\n    planesNormal = planes / planesD\n\n    ND = tf.expand_dims(planesNormal, 0) * tf.expand_dims(planesD, 1)\n    ND_diff = tf.reshape(ND - tf.transpose(ND, [1, 0, 2]), [-1, 3])\n    coefX, coefY, coefZ = tf.unstack(ND_diff, axis=1)\n\n    pixels = []\n    focalLength = 517.97\n    urange = tf.range(width, dtype=tf.float32) / focalLength\n    ones = tf.ones(urange.shape)\n    vs = (coefX * urange + coefY * ones) / coefZ\n    pixels.append(tf.stack([tf.floor(vs), urange], axis=1))\n    pixels.append(tf.stack([tf.ceil(vs), urange], axis=1))\n    \n    vrange = tf.range(height, dtype=tf.float32) / focalLength\n    ones = tf.ones(vrange.shape)\n    us = -(coefY * ones - coefZ * vrange) / coefX\n    pixels.append(tf.stack([vrange, tf.floor(us)], axis=1))\n    pixels.append(tf.stack([vrange, tf.ceil(us)], axis=1))\n\n    v, u = tf.unstack(pixels, axis=1)\n    validMask = tf.logical_and(tf.less(u, width), tf.less(v, height))\n    validMask = tf.logical_and(validMask, tf.greater_equal(u, 0))\n    validMask = tf.logical_and(validMask, tf.greater_equal(v, 0))\n    \n    pixels *= tf.expand_dims(invalidMask, -1)\n    \n    boundary = tf.sparse_to_dense(pixels, output_shape=[height, width], sparse_values=1)\n    return boundary\n\n\ndef fitPlaneMasksModule(planes, depth, normal, width = 640, height = 480, numPlanes = 20, normalDotThreshold = np.cos(np.deg2rad(5)), distanceThreshold = 0.05, closing=True, one_hot=True):\n    focalLength = 517.97\n    urange = (tf.range(width, dtype=tf.float32) / (width + 1) - 0.5) / focalLength * 641\n    urange = tf.tile(tf.reshape(urange, [1, -1]), [height, 1])\n    vrange = (tf.range(height, dtype=tf.float32) / (height + 1) - 0.5) / focalLength * 481\n    vrange = tf.tile(tf.reshape(vrange, [-1, 1]), [1, width])\n        \n    X = depth * tf.expand_dims(urange, -1)\n    Y = depth\n    Z = -depth * tf.expand_dims(vrange, -1)\n    XYZ = tf.concat([X, Y, Z], axis=3)\n    XYZ = tf.reshape(XYZ, [-1, height * width, 3])\n    plane_parameters = planes\n    planesD = tf.norm(plane_parameters, axis=2, keep_dims=True)\n    planesNormal = tf.div(tf.negative(plane_parameters), tf.clip_by_value(planesD, 1e-4, 10))\n\n    distance = tf.reshape(tf.abs(tf.matmul(XYZ, planesNormal, transpose_b=True) + tf.reshape(planesD, [-1, 1, numPlanes])), [-1, height, width, numPlanes])\n    angle = tf.reshape(np.abs(tf.matmul(tf.reshape(normal, [-1, height * width, 3]), planesNormal, transpose_b=True)), [-1, height, width, numPlanes])\n\n    planeMasks = tf.cast(tf.logical_and(tf.greater(angle, normalDotThreshold), tf.less(distance, distanceThreshold)), tf.float32)\n\n    if closing:\n        #morphological closing\n        planeMasks = tf.nn.max_pool(planeMasks, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n        pass\n    plane_mask = tf.reduce_max(planeMasks, axis=3, keep_dims=True)\n    if one_hot:\n        if closing:\n            plane_mask = 1 - tf.nn.max_pool(1 - plane_mask, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n            pass\n        #one-hot encoding\n        planeMasks = tf.one_hot(tf.argmax(planeMasks * (distanceThreshold - distance), axis=3), depth=numPlanes) * plane_mask\n        pass\n    \n    return planeMasks, plane_mask\n    \n\ndef depthToNormalModule(depth):\n    batchSize = int(depth.shape[0])\n    height = int(depth.shape[1])\n    width = int(depth.shape[2])\n    \n    focalLength = 517.97\n    urange = (tf.range(width, dtype=tf.float32) / width - 0.5) / focalLength * 640\n    urange = tf.tile(tf.reshape(urange, [1, -1]), [height, 1])\n    vrange = (tf.range(height, dtype=tf.float32) / height - 0.5) / focalLength * 480\n    vrange = tf.tile(tf.reshape(vrange, [-1, 1]), [1, width])\n        \n    X = depth * tf.expand_dims(urange, -1)\n    Y = depth\n    Z = -depth * tf.expand_dims(vrange, -1)\n    XYZ = tf.concat([X, Y, Z], axis=3)\n    #XYZ = tf.reshape(XYZ, [-1, height * width, 3])\n\n    \n    kernel_array = np.zeros((3, 3, 1, 4))\n    kernel_array[0, 1, 0, 0] = 1\n    kernel_array[1, 0, 0, 1] = 1\n    kernel_array[2, 1, 0, 2] = 1\n    kernel_array[1, 2, 0, 3] = 1\n    kernel_array[1, 1, 0, 0] = -1\n    kernel_array[1, 1, 0, 1] = -1\n    kernel_array[1, 1, 0, 2] = -1\n    kernel_array[1, 1, 0, 3] = -1\n    kernel = tf.constant(kernel_array.reshape(-1), shape=kernel_array.shape, dtype=tf.float32)\n    XYZ_diff = tf.nn.depthwise_conv2d(tf.pad(XYZ, [[0, 0], [1, 1], [1, 1], [0, 0]], mode=\'REFLECT\'), tf.tile(kernel, [1, 1, 3, 1]), strides=[1, 1, 1, 1], padding=\'VALID\')\n    XYZ_diff = tf.reshape(XYZ_diff, [-1, height, width, 3, 4])\n    XYZ_diff_2 = tf.concat([tf.slice(XYZ_diff, [0, 0, 0, 0, 1], [batchSize, height, width, 3, 3]), tf.slice(XYZ_diff, [0, 0, 0, 0, 0], [batchSize, height, width, 3, 1])], axis=4)\n    XYZ_diff_1 = tf.unstack(XYZ_diff, axis=3)\n    XYZ_diff_2 = tf.unstack(XYZ_diff_2, axis=3)\n\n    normal_X = XYZ_diff_1[1] * XYZ_diff_2[2] - XYZ_diff_1[2] * XYZ_diff_2[1]\n    normal_Y = XYZ_diff_1[2] * XYZ_diff_2[0] - XYZ_diff_1[0] * XYZ_diff_2[2]\n    normal_Z = XYZ_diff_1[0] * XYZ_diff_2[1] - XYZ_diff_1[1] * XYZ_diff_2[0]\n\n    normal_X = tf.reduce_sum(normal_X, axis=[3])\n    normal_Y = tf.reduce_sum(normal_Y, axis=[3])\n    normal_Z = tf.reduce_sum(normal_Z, axis=[3])\n    normal = tf.stack([normal_X, normal_Y, normal_Z], axis=3)\n\n    kernel_size = 5\n    padding = (kernel_size - 1) / 2\n    neighbor_kernel_array = gaussian(kernel_size)\n    #neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n    neighbor_kernel_array /= neighbor_kernel_array.sum()\n    neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n    neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n    normal = tf.nn.depthwise_conv2d(tf.pad(normal, [[0, 0], [padding, padding], [padding, padding], [0, 0]], mode=\'REFLECT\'), tf.tile(neighbor_kernel, [1, 1, 3, 1]), strides=[1, 1, 1, 1], padding=\'VALID\')\n    \n    normal = normal / tf.norm(normal, axis=3, keep_dims=True)\n    return normal\n\ndef findBoundaryModule(depth, normal, segmentation, plane_mask, max_depth_diff = 0.1, max_normal_diff = np.sqrt(2 * (1 - np.cos(np.deg2rad(20))))):\n    kernel_size = 3\n    padding = (kernel_size - 1) / 2\n    neighbor_kernel_array = gaussian(kernel_size)\n    neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n    neighbor_kernel_array /= neighbor_kernel_array.sum()\n    neighbor_kernel_array *= -1\n    neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 1\n    neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n    neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n        \n    depth_diff = tf.abs(tf.nn.depthwise_conv2d(depth, neighbor_kernel, strides=[1, 1, 1, 1], padding=\'VALID\'))\n    depth_diff = tf.pad(depth_diff, paddings = [[0, 0], [padding, padding], [padding, padding], [0, 0]])\n    max_depth_diff = 0.1\n    depth_boundary = tf.greater(depth_diff, max_depth_diff)\n\n    normal_diff = tf.norm(tf.nn.depthwise_conv2d(normal, tf.tile(neighbor_kernel, [1, 1, 3, 1]), strides=[1, 1, 1, 1], padding=\'VALID\'), axis=3, keep_dims=True)\n    normal_diff = tf.pad(normal_diff, paddings = [[0, 0], [padding, padding], [padding, padding], [0, 0]])\n    max_normal_diff = np.sqrt(2 * (1 - np.cos(np.deg2rad(20))))\n    normal_boundary = tf.greater(normal_diff, max_normal_diff)\n\n    plane_region = tf.nn.max_pool(plane_mask, ksize=[1, kernel_size, kernel_size, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n    segmentation_eroded = 1 - tf.nn.max_pool(1 - segmentation, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n    plane_region -= tf.reduce_max(segmentation_eroded, axis=3, keep_dims=True)\n    boundary = tf.cast(tf.logical_or(depth_boundary, normal_boundary), tf.float32) * plane_region\n    #boundary = plane_region\n    #smooth_boundary = tf.cast(tf.less_equal(depth_diff, max_depth_diff), tf.float32) * boundary\n    smooth_boundary = tf.cast(tf.logical_and(normal_boundary, tf.less_equal(depth_diff, max_depth_diff)), tf.float32)\n    smooth_boundary = tf.nn.max_pool(smooth_boundary, ksize=[1, kernel_size, kernel_size, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\') * boundary\n    #smooth_boundary = smooth_boundary * boundary\n    boundary_gt = tf.concat([smooth_boundary, boundary - smooth_boundary], axis=3)\n    return boundary_gt\n\n\ndef findBoundaryModuleSmooth(depth, segmentation, plane_mask, smooth_boundary, max_depth_diff = 0.1, max_normal_diff = np.sqrt(2 * (1 - np.cos(np.deg2rad(20))))):\n    kernel_size = 3\n    padding = (kernel_size - 1) / 2\n    neighbor_kernel_array = gaussian(kernel_size)\n    neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n    neighbor_kernel_array /= neighbor_kernel_array.sum()\n    neighbor_kernel_array *= -1\n    neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 1\n    neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n    neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n        \n    depth_diff = tf.abs(tf.nn.depthwise_conv2d(depth, neighbor_kernel, strides=[1, 1, 1, 1], padding=\'VALID\'))\n    depth_diff = tf.pad(depth_diff, paddings = [[0, 0], [padding, padding], [padding, padding], [0, 0]])\n    max_depth_diff = 0.1\n    depth_boundary = tf.greater(depth_diff, max_depth_diff)\n\n\n    plane_region = tf.nn.max_pool(plane_mask, ksize=[1, kernel_size, kernel_size, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n    segmentation_eroded = 1 - tf.nn.max_pool(1 - segmentation, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\')\n    plane_region -= tf.reduce_max(segmentation_eroded, axis=3, keep_dims=True)\n    occlusion_boundary = tf.cast(depth_boundary, tf.float32) * plane_region\n    #boundary = plane_region\n    #smooth_boundary = tf.cast(tf.less_equal(depth_diff, max_depth_diff), tf.float32) * boundary\n    smooth_boundary = smooth_boundary * plane_region\n    smooth_boundary_dilated = tf.nn.max_pool(smooth_boundary, ksize=[1, kernel_size, kernel_size, 1], strides=[1, 1, 1, 1], padding=\'SAME\', name=\'max_pool\') * plane_region\n    #smooth_boundary = smooth_boundary * boundary\n    boundary_gt = tf.concat([smooth_boundary, tf.maximum(occlusion_boundary - smooth_boundary_dilated, 0)], axis=3)\n    return boundary_gt\n\n\ndef crfModule(segmentations, planes, non_plane_depth, info, numOutputPlanes=20, numIterations=20, kernel_size = 9):\n    width = int(segmentations.shape[2])\n    height = int(segmentations.shape[1])\n    \n    #maxDepthDiff = tf.Variable(0.3)\n    #sigmaDepthDiff = tf.Variable(0.5)\n    maxDepthDiff = 0.3\n    sigmaDepthDiff = 0.5\n\n    plane_parameters = tf.reshape(planes, (-1, 3))\n    plane_depths = planeDepthsModule(plane_parameters, width, height, info)\n    plane_depths = tf.transpose(tf.reshape(plane_depths, [height, width, -1, numOutputPlanes]), [2, 0, 1, 3])\n    all_depths = tf.concat([plane_depths, non_plane_depth], axis=3)\n    \n    refined_segmentation = segmentations\n    for _ in xrange(numIterations):\n        refined_segmentation = meanfieldModule(refined_segmentation, all_depths, numOutputPlanes=numOutputPlanes + 1, sigmaDepthDiff=sigmaDepthDiff, kernel_size = kernel_size)\n        continue\n    return refined_segmentation\n\ndef divideLayers(segmentations, planes, non_plane_mask, info, num_planes, numOutputPlanes_0=5, validAreaRatio=0.95, distanceThreshold=0.05):\n    batchSize = int(planes.shape[0])    \n    numOutputPlanes = int(planes.shape[1])\n    width = int(segmentations.shape[2])\n    height = int(segmentations.shape[1])\n    \n    plane_parameters = tf.reshape(planes, (-1, 3))\n    plane_depths = planeDepthsModule(plane_parameters, width, height, info)\n    plane_depths = tf.transpose(tf.reshape(plane_depths, [height, width, -1, numOutputPlanes]), [2, 0, 1, 3])\n    depth = tf.reduce_sum(plane_depths * segmentations[:, :, :, :numOutputPlanes], axis=3, keep_dims=True)\n    #non_plane_mask = segmentations[:, :, :, numOutputPlanes:numOutputPlanes+1]\n    \n    background_mask = tf.logical_or(tf.logical_or(tf.less(plane_depths, 1e-4), tf.greater(plane_depths, depth - distanceThreshold)), tf.cast(non_plane_mask, tf.bool))\n    background_planes = tf.greater(tf.reduce_mean(tf.cast(background_mask, tf.float32), axis=[1, 2]), validAreaRatio)\n    validPlaneMask = tf.less(tf.tile(tf.expand_dims(tf.range(numOutputPlanes), 0), [batchSize, 1]), tf.expand_dims(num_planes, -1))\n    background_planes = tf.logical_and(background_planes, validPlaneMask)\n    background_planes = tf.cast(background_planes, tf.float32)\n    plane_areas = tf.reduce_sum(segmentations[:, :, :, :numOutputPlanes], axis=[1, 2])\n    \n    layer_plane_areas_0 = plane_areas * background_planes    \n    areas, sortInds = tf.nn.top_k(layer_plane_areas_0, k=numOutputPlanes_0)\n    sortMap = tf.one_hot(sortInds, depth=numOutputPlanes, axis=1)\n    validMask = tf.cast(tf.greater(areas, 1e-4), tf.float32)\n    sortMap *= tf.expand_dims(validMask, 1)\n    layer_segmentations_0 = tf.reshape(tf.matmul(tf.reshape(segmentations, [batchSize, height * width, -1]), sortMap), [batchSize, height, width, -1])\n    layer_planes_0 = tf.transpose(tf.matmul(planes, sortMap, transpose_a=True), [0, 2, 1])\n\n\n    layer_plane_areas_1 = plane_areas * (1 - background_planes)\n    areas, sortInds = tf.nn.top_k(layer_plane_areas_1, k=numOutputPlanes - numOutputPlanes_0)\n    sortMap = tf.one_hot(sortInds, depth=numOutputPlanes, axis=1)\n    validMask = tf.cast(tf.greater(areas, 1e-4), tf.float32)\n    sortMap *= tf.expand_dims(validMask, 1)\n    layer_segmentations_1 = tf.reshape(tf.matmul(tf.reshape(segmentations, [batchSize, height * width, -1]), sortMap), [batchSize, height, width, -1])\n    layer_planes_1 = tf.transpose(tf.matmul(planes, sortMap, transpose_a=True), [0, 2, 1])\n    \n    \n    return tf.concat([layer_segmentations_0, layer_segmentations_1], axis=3), tf.concat([layer_planes_0, layer_planes_1], axis=1)\n\n\n\ndef calcMessages(planeSegmentations, planeDepths, planesY, numOutputPlanes = 21, coef = [1, 1, 1], beta = 1, iteration = 0, maxDepthDiff = 0.2, varDepthDiff = 0.5, kernel_size = 9):\n    #images, varImageDiff\n    batchSize = int(planeSegmentations.shape[0])\n    height = int(planeSegmentations.shape[1])\n    width = int(planeSegmentations.shape[2])\n\n\n    n2 = tf.pow(tf.reshape(planesY, [batchSize, 1, 1, -1]), 2)\n    d2n2s = tf.reduce_sum(tf.pow(planeDepths, 2) * n2 * planeSegmentations, axis=-1, keep_dims=True)\n    dnsd = tf.reduce_sum(planeDepths * n2 * planeSegmentations, axis=-1, keep_dims=True) * planeDepths\n    n2sd2 = tf.reduce_sum(n2 * planeSegmentations, axis=-1, keep_dims=True) * tf.pow(planeDepths, 2)\n\n    messages = d2n2s - 2 * dnsd + n2sd2\n\n    maxDepthDiff = 0.2\n    messages = tf.minimum(messages / pow(maxDepthDiff, 2), 1)\n    \n    # vertical_padding = tf.zeros((batchSize, height, 1, numOutputPlanes))\n    # horizontal_padding = tf.zeros((batchSize, height, 1, numOutputPlanes))    \n\n\n    # neighbor_kernel_array = gaussian(kernel_size)\n    # neighbor_kernel_array[(kernel_size - 1) / 2][(kernel_size - 1) / 2] = 0\n    # neighbor_kernel_array /= neighbor_kernel_array.sum()\n    # neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n    # neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n    \n    # messages = tf.nn.depthwise_conv2d(messages, tf.tile(neighbor_kernel, [1, 1, numOutputPlanes, 1]), strides=[1, 1, 1, 1], padding=\'SAME\')\n\n    return messages\n\n\ndef crfrnnModule(inputs, image_dims, num_classes, theta_alpha, theta_beta, theta_gamma, num_iterations):\n    custom_module = tf.load_op_library(\'./cpp/high_dim_filter.so\')\n    import high_dim_filter_grad  # Register gradients for the custom op\n\n    weights = np.load(\'weights.npy\')\n    weights = [weights[0], weights[1], weights[2]]\n    spatial_ker_weights = tf.Variable(weights[0][:num_classes, :num_classes], name=\'spatial_ker_weights\', trainable=True)\n    bilateral_ker_weights = tf.Variable(weights[1][:num_classes, :num_classes], name=\'bilateral_ker_weights\', trainable=True)\n    compatibility_matrix = tf.Variable(weights[2][:num_classes, :num_classes], name=\'compatibility_matrix\', trainable=True)\n    \n\n    batchSize = int(inputs[0].shape[0])\n    c, h, w = num_classes, image_dims[0], image_dims[1]\n    all_ones = np.ones((c, h, w), dtype=np.float32)\n\n    outputs = []\n    for batchIndex in xrange(batchSize):\n        unaries = tf.transpose(inputs[0][batchIndex, :, :, :], perm=(2, 0, 1))\n        rgb = tf.transpose(inputs[1][batchIndex, :, :, :], perm=(2, 0, 1))\n\n\n        # Prepare filter normalization coefficients\n        spatial_norm_vals = custom_module.high_dim_filter(all_ones, rgb, bilateral=False,\n                                                          theta_gamma=theta_gamma)\n        bilateral_norm_vals = custom_module.high_dim_filter(all_ones, rgb, bilateral=True,\n                                                            theta_alpha=theta_alpha,\n                                                            theta_beta=theta_beta)\n        q_values = unaries\n\n        for i in range(num_iterations):\n            softmax_out = tf.nn.softmax(q_values, dim=0)\n\n            # Spatial filtering\n            spatial_out = custom_module.high_dim_filter(softmax_out, rgb, bilateral=False,\n                                                        theta_gamma=theta_gamma)\n            spatial_out = spatial_out / spatial_norm_vals\n\n            # Bilateral filtering\n            bilateral_out = custom_module.high_dim_filter(softmax_out, rgb, bilateral=True,\n                                                          theta_alpha=theta_alpha,\n                                                          theta_beta=theta_beta)\n            bilateral_out = bilateral_out / bilateral_norm_vals\n\n            # Weighting filter outputs\n            message_passing = (tf.matmul(spatial_ker_weights,\n                                         tf.reshape(spatial_out, (c, -1))) +\n                               tf.matmul(bilateral_ker_weights,\n                                         tf.reshape(bilateral_out, (c, -1))))\n\n            # Compatibility transform\n            pairwise = tf.matmul(compatibility_matrix, message_passing)\n\n            # Adding unary potentials\n            pairwise = tf.reshape(pairwise, (c, h, w))\n            q_values = unaries - pairwise\n            continue\n        outputs.append(tf.transpose(tf.reshape(q_values, (1, c, h, w)), perm=(0, 2, 3, 1)))\n        continue\n    outputs = tf.concat(outputs, axis=0)\n    return outputs\n'"
code/kaffe/caffe/__init__.py,0,"b'from .resolver import get_caffe_resolver, has_pycaffe\n'"
code/kaffe/caffe/caffepb.py,0,"b'# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: caffe.proto\n\nfrom google.protobuf.internal import enum_type_wrapper\nfrom google.protobuf import descriptor as _descriptor\nfrom google.protobuf import message as _message\nfrom google.protobuf import reflection as _reflection\nfrom google.protobuf import descriptor_pb2\n# @@protoc_insertion_point(imports)\n\n\n\n\nDESCRIPTOR = _descriptor.FileDescriptor(\n  name=\'caffe.proto\',\n  package=\'caffe\',\n  serialized_pb=\'\\n\\x0b\\x63\\x61\\x66\\x66\\x65.proto\\x12\\x05\\x63\\x61\\x66\\x66\\x65\\""\\x1c\\n\\tBlobShape\\x12\\x0f\\n\\x03\\x64im\\x18\\x01 \\x03(\\x03\\x42\\x02\\x10\\x01\\""\\xcc\\x01\\n\\tBlobProto\\x12\\x1f\\n\\x05shape\\x18\\x07 \\x01(\\x0b\\x32\\x10.caffe.BlobShape\\x12\\x10\\n\\x04\\x64\\x61ta\\x18\\x05 \\x03(\\x02\\x42\\x02\\x10\\x01\\x12\\x10\\n\\x04\\x64iff\\x18\\x06 \\x03(\\x02\\x42\\x02\\x10\\x01\\x12\\x17\\n\\x0b\\x64ouble_data\\x18\\x08 \\x03(\\x01\\x42\\x02\\x10\\x01\\x12\\x17\\n\\x0b\\x64ouble_diff\\x18\\t \\x03(\\x01\\x42\\x02\\x10\\x01\\x12\\x0e\\n\\x03num\\x18\\x01 \\x01(\\x05:\\x01\\x30\\x12\\x13\\n\\x08\\x63hannels\\x18\\x02 \\x01(\\x05:\\x01\\x30\\x12\\x11\\n\\x06height\\x18\\x03 \\x01(\\x05:\\x01\\x30\\x12\\x10\\n\\x05width\\x18\\x04 \\x01(\\x05:\\x01\\x30\\""2\\n\\x0f\\x42lobProtoVector\\x12\\x1f\\n\\x05\\x62lobs\\x18\\x01 \\x03(\\x0b\\x32\\x10.caffe.BlobProto\\""\\x81\\x01\\n\\x05\\x44\\x61tum\\x12\\x10\\n\\x08\\x63hannels\\x18\\x01 \\x01(\\x05\\x12\\x0e\\n\\x06height\\x18\\x02 \\x01(\\x05\\x12\\r\\n\\x05width\\x18\\x03 \\x01(\\x05\\x12\\x0c\\n\\x04\\x64\\x61ta\\x18\\x04 \\x01(\\x0c\\x12\\r\\n\\x05label\\x18\\x05 \\x01(\\x05\\x12\\x12\\n\\nfloat_data\\x18\\x06 \\x03(\\x02\\x12\\x16\\n\\x07\\x65ncoded\\x18\\x07 \\x01(\\x08:\\x05\\x66\\x61lse\\""\\x8a\\x02\\n\\x0f\\x46illerParameter\\x12\\x16\\n\\x04type\\x18\\x01 \\x01(\\t:\\x08\\x63onstant\\x12\\x10\\n\\x05value\\x18\\x02 \\x01(\\x02:\\x01\\x30\\x12\\x0e\\n\\x03min\\x18\\x03 \\x01(\\x02:\\x01\\x30\\x12\\x0e\\n\\x03max\\x18\\x04 \\x01(\\x02:\\x01\\x31\\x12\\x0f\\n\\x04mean\\x18\\x05 \\x01(\\x02:\\x01\\x30\\x12\\x0e\\n\\x03std\\x18\\x06 \\x01(\\x02:\\x01\\x31\\x12\\x12\\n\\x06sparse\\x18\\x07 \\x01(\\x05:\\x02-1\\x12\\x42\\n\\rvariance_norm\\x18\\x08 \\x01(\\x0e\\x32#.caffe.FillerParameter.VarianceNorm:\\x06\\x46\\x41N_IN\\""4\\n\\x0cVarianceNorm\\x12\\n\\n\\x06\\x46\\x41N_IN\\x10\\x00\\x12\\x0b\\n\\x07\\x46\\x41N_OUT\\x10\\x01\\x12\\x0b\\n\\x07\\x41VERAGE\\x10\\x02\\""\\x8e\\x02\\n\\x0cNetParameter\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12\\r\\n\\x05input\\x18\\x03 \\x03(\\t\\x12%\\n\\x0binput_shape\\x18\\x08 \\x03(\\x0b\\x32\\x10.caffe.BlobShape\\x12\\x11\\n\\tinput_dim\\x18\\x04 \\x03(\\x05\\x12\\x1d\\n\\x0e\\x66orce_backward\\x18\\x05 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x1e\\n\\x05state\\x18\\x06 \\x01(\\x0b\\x32\\x0f.caffe.NetState\\x12\\x19\\n\\ndebug_info\\x18\\x07 \\x01(\\x08:\\x05\\x66\\x61lse\\x12$\\n\\x05layer\\x18\\x64 \\x03(\\x0b\\x32\\x15.caffe.LayerParameter\\x12\\\'\\n\\x06layers\\x18\\x02 \\x03(\\x0b\\x32\\x17.caffe.V1LayerParameter\\""\\x9c\\n\\n\\x0fSolverParameter\\x12\\x0b\\n\\x03net\\x18\\x18 \\x01(\\t\\x12&\\n\\tnet_param\\x18\\x19 \\x01(\\x0b\\x32\\x13.caffe.NetParameter\\x12\\x11\\n\\ttrain_net\\x18\\x01 \\x01(\\t\\x12\\x10\\n\\x08test_net\\x18\\x02 \\x03(\\t\\x12,\\n\\x0ftrain_net_param\\x18\\x15 \\x01(\\x0b\\x32\\x13.caffe.NetParameter\\x12+\\n\\x0etest_net_param\\x18\\x16 \\x03(\\x0b\\x32\\x13.caffe.NetParameter\\x12$\\n\\x0btrain_state\\x18\\x1a \\x01(\\x0b\\x32\\x0f.caffe.NetState\\x12#\\n\\ntest_state\\x18\\x1b \\x03(\\x0b\\x32\\x0f.caffe.NetState\\x12\\x11\\n\\ttest_iter\\x18\\x03 \\x03(\\x05\\x12\\x18\\n\\rtest_interval\\x18\\x04 \\x01(\\x05:\\x01\\x30\\x12 \\n\\x11test_compute_loss\\x18\\x13 \\x01(\\x08:\\x05\\x66\\x61lse\\x12!\\n\\x13test_initialization\\x18  \\x01(\\x08:\\x04true\\x12\\x0f\\n\\x07\\x62\\x61se_lr\\x18\\x05 \\x01(\\x02\\x12\\x0f\\n\\x07\\x64isplay\\x18\\x06 \\x01(\\x05\\x12\\x17\\n\\x0c\\x61verage_loss\\x18! \\x01(\\x05:\\x01\\x31\\x12\\x10\\n\\x08max_iter\\x18\\x07 \\x01(\\x05\\x12\\x14\\n\\titer_size\\x18$ \\x01(\\x05:\\x01\\x31\\x12\\x11\\n\\tlr_policy\\x18\\x08 \\x01(\\t\\x12\\r\\n\\x05gamma\\x18\\t \\x01(\\x02\\x12\\r\\n\\x05power\\x18\\n \\x01(\\x02\\x12\\x10\\n\\x08momentum\\x18\\x0b \\x01(\\x02\\x12\\x14\\n\\x0cweight_decay\\x18\\x0c \\x01(\\x02\\x12\\x1f\\n\\x13regularization_type\\x18\\x1d \\x01(\\t:\\x02L2\\x12\\x10\\n\\x08stepsize\\x18\\r \\x01(\\x05\\x12\\x11\\n\\tstepvalue\\x18\\"" \\x03(\\x05\\x12\\x1a\\n\\x0e\\x63lip_gradients\\x18# \\x01(\\x02:\\x02-1\\x12\\x13\\n\\x08snapshot\\x18\\x0e \\x01(\\x05:\\x01\\x30\\x12\\x17\\n\\x0fsnapshot_prefix\\x18\\x0f \\x01(\\t\\x12\\x1c\\n\\rsnapshot_diff\\x18\\x10 \\x01(\\x08:\\x05\\x66\\x61lse\\x12K\\n\\x0fsnapshot_format\\x18% \\x01(\\x0e\\x32%.caffe.SolverParameter.SnapshotFormat:\\x0b\\x42INARYPROTO\\x12;\\n\\x0bsolver_mode\\x18\\x11 \\x01(\\x0e\\x32!.caffe.SolverParameter.SolverMode:\\x03GPU\\x12\\x14\\n\\tdevice_id\\x18\\x12 \\x01(\\x05:\\x01\\x30\\x12\\x17\\n\\x0brandom_seed\\x18\\x14 \\x01(\\x03:\\x02-1\\x12\\x11\\n\\x04type\\x18( \\x01(\\t:\\x03SGD\\x12\\x14\\n\\x05\\x64\\x65lta\\x18\\x1f \\x01(\\x02:\\x05\\x31\\x65-08\\x12\\x18\\n\\tmomentum2\\x18\\\' \\x01(\\x02:\\x05\\x30.999\\x12\\x11\\n\\trms_decay\\x18& \\x01(\\x02\\x12\\x19\\n\\ndebug_info\\x18\\x17 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\""\\n\\x14snapshot_after_train\\x18\\x1c \\x01(\\x08:\\x04true\\x12;\\n\\x0bsolver_type\\x18\\x1e \\x01(\\x0e\\x32!.caffe.SolverParameter.SolverType:\\x03SGD\\""+\\n\\x0eSnapshotFormat\\x12\\x08\\n\\x04HDF5\\x10\\x00\\x12\\x0f\\n\\x0b\\x42INARYPROTO\\x10\\x01\\""\\x1e\\n\\nSolverMode\\x12\\x07\\n\\x03\\x43PU\\x10\\x00\\x12\\x07\\n\\x03GPU\\x10\\x01\\""U\\n\\nSolverType\\x12\\x07\\n\\x03SGD\\x10\\x00\\x12\\x0c\\n\\x08NESTEROV\\x10\\x01\\x12\\x0b\\n\\x07\\x41\\x44\\x41GRAD\\x10\\x02\\x12\\x0b\\n\\x07RMSPROP\\x10\\x03\\x12\\x0c\\n\\x08\\x41\\x44\\x41\\x44\\x45LTA\\x10\\x04\\x12\\x08\\n\\x04\\x41\\x44\\x41M\\x10\\x05\\""l\\n\\x0bSolverState\\x12\\x0c\\n\\x04iter\\x18\\x01 \\x01(\\x05\\x12\\x13\\n\\x0blearned_net\\x18\\x02 \\x01(\\t\\x12!\\n\\x07history\\x18\\x03 \\x03(\\x0b\\x32\\x10.caffe.BlobProto\\x12\\x17\\n\\x0c\\x63urrent_step\\x18\\x04 \\x01(\\x05:\\x01\\x30\\""N\\n\\x08NetState\\x12!\\n\\x05phase\\x18\\x01 \\x01(\\x0e\\x32\\x0c.caffe.Phase:\\x04TEST\\x12\\x10\\n\\x05level\\x18\\x02 \\x01(\\x05:\\x01\\x30\\x12\\r\\n\\x05stage\\x18\\x03 \\x03(\\t\\""s\\n\\x0cNetStateRule\\x12\\x1b\\n\\x05phase\\x18\\x01 \\x01(\\x0e\\x32\\x0c.caffe.Phase\\x12\\x11\\n\\tmin_level\\x18\\x02 \\x01(\\x05\\x12\\x11\\n\\tmax_level\\x18\\x03 \\x01(\\x05\\x12\\r\\n\\x05stage\\x18\\x04 \\x03(\\t\\x12\\x11\\n\\tnot_stage\\x18\\x05 \\x03(\\t\\""\\xa3\\x01\\n\\tParamSpec\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12\\x31\\n\\nshare_mode\\x18\\x02 \\x01(\\x0e\\x32\\x1d.caffe.ParamSpec.DimCheckMode\\x12\\x12\\n\\x07lr_mult\\x18\\x03 \\x01(\\x02:\\x01\\x31\\x12\\x15\\n\\ndecay_mult\\x18\\x04 \\x01(\\x02:\\x01\\x31\\""*\\n\\x0c\\x44imCheckMode\\x12\\n\\n\\x06STRICT\\x10\\x00\\x12\\x0e\\n\\nPERMISSIVE\\x10\\x01\\""\\x98\\x13\\n\\x0eLayerParameter\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12\\x0c\\n\\x04type\\x18\\x02 \\x01(\\t\\x12\\x0e\\n\\x06\\x62ottom\\x18\\x03 \\x03(\\t\\x12\\x0b\\n\\x03top\\x18\\x04 \\x03(\\t\\x12\\x1b\\n\\x05phase\\x18\\n \\x01(\\x0e\\x32\\x0c.caffe.Phase\\x12\\x13\\n\\x0bloss_weight\\x18\\x05 \\x03(\\x02\\x12\\x1f\\n\\x05param\\x18\\x06 \\x03(\\x0b\\x32\\x10.caffe.ParamSpec\\x12\\x1f\\n\\x05\\x62lobs\\x18\\x07 \\x03(\\x0b\\x32\\x10.caffe.BlobProto\\x12\\x16\\n\\x0epropagate_down\\x18\\x0b \\x03(\\x08\\x12$\\n\\x07include\\x18\\x08 \\x03(\\x0b\\x32\\x13.caffe.NetStateRule\\x12$\\n\\x07\\x65xclude\\x18\\t \\x03(\\x0b\\x32\\x13.caffe.NetStateRule\\x12\\x37\\n\\x0ftransform_param\\x18\\x64 \\x01(\\x0b\\x32\\x1e.caffe.TransformationParameter\\x12(\\n\\nloss_param\\x18\\x65 \\x01(\\x0b\\x32\\x14.caffe.LossParameter\\x12\\x30\\n\\x0e\\x61\\x63\\x63uracy_param\\x18\\x66 \\x01(\\x0b\\x32\\x18.caffe.AccuracyParameter\\x12,\\n\\x0c\\x61rgmax_param\\x18g \\x01(\\x0b\\x32\\x16.caffe.ArgMaxParameter\\x12\\x34\\n\\x10\\x62\\x61tch_norm_param\\x18\\x8b\\x01 \\x01(\\x0b\\x32\\x19.caffe.BatchNormParameter\\x12)\\n\\nbias_param\\x18\\x8d\\x01 \\x01(\\x0b\\x32\\x14.caffe.BiasParameter\\x12,\\n\\x0c\\x63oncat_param\\x18h \\x01(\\x0b\\x32\\x16.caffe.ConcatParameter\\x12?\\n\\x16\\x63ontrastive_loss_param\\x18i \\x01(\\x0b\\x32\\x1f.caffe.ContrastiveLossParameter\\x12\\x36\\n\\x11\\x63onvolution_param\\x18j \\x01(\\x0b\\x32\\x1b.caffe.ConvolutionParameter\\x12)\\n\\ncrop_param\\x18\\x90\\x01 \\x01(\\x0b\\x32\\x14.caffe.CropParameter\\x12(\\n\\ndata_param\\x18k \\x01(\\x0b\\x32\\x14.caffe.DataParameter\\x12.\\n\\rdropout_param\\x18l \\x01(\\x0b\\x32\\x17.caffe.DropoutParameter\\x12\\x33\\n\\x10\\x64ummy_data_param\\x18m \\x01(\\x0b\\x32\\x19.caffe.DummyDataParameter\\x12.\\n\\reltwise_param\\x18n \\x01(\\x0b\\x32\\x17.caffe.EltwiseParameter\\x12\\\'\\n\\telu_param\\x18\\x8c\\x01 \\x01(\\x0b\\x32\\x13.caffe.ELUParameter\\x12+\\n\\x0b\\x65mbed_param\\x18\\x89\\x01 \\x01(\\x0b\\x32\\x15.caffe.EmbedParameter\\x12&\\n\\texp_param\\x18o \\x01(\\x0b\\x32\\x13.caffe.ExpParameter\\x12/\\n\\rflatten_param\\x18\\x87\\x01 \\x01(\\x0b\\x32\\x17.caffe.FlattenParameter\\x12\\x31\\n\\x0fhdf5_data_param\\x18p \\x01(\\x0b\\x32\\x18.caffe.HDF5DataParameter\\x12\\x35\\n\\x11hdf5_output_param\\x18q \\x01(\\x0b\\x32\\x1a.caffe.HDF5OutputParameter\\x12\\x33\\n\\x10hinge_loss_param\\x18r \\x01(\\x0b\\x32\\x19.caffe.HingeLossParameter\\x12\\x33\\n\\x10image_data_param\\x18s \\x01(\\x0b\\x32\\x19.caffe.ImageDataParameter\\x12\\x39\\n\\x13infogain_loss_param\\x18t \\x01(\\x0b\\x32\\x1c.caffe.InfogainLossParameter\\x12\\x39\\n\\x13inner_product_param\\x18u \\x01(\\x0b\\x32\\x1c.caffe.InnerProductParameter\\x12+\\n\\x0binput_param\\x18\\x8f\\x01 \\x01(\\x0b\\x32\\x15.caffe.InputParameter\\x12\\\'\\n\\tlog_param\\x18\\x86\\x01 \\x01(\\x0b\\x32\\x13.caffe.LogParameter\\x12&\\n\\tlrn_param\\x18v \\x01(\\x0b\\x32\\x13.caffe.LRNParameter\\x12\\x35\\n\\x11memory_data_param\\x18w \\x01(\\x0b\\x32\\x1a.caffe.MemoryDataParameter\\x12&\\n\\tmvn_param\\x18x \\x01(\\x0b\\x32\\x13.caffe.MVNParameter\\x12.\\n\\rpooling_param\\x18y \\x01(\\x0b\\x32\\x17.caffe.PoolingParameter\\x12*\\n\\x0bpower_param\\x18z \\x01(\\x0b\\x32\\x15.caffe.PowerParameter\\x12+\\n\\x0bprelu_param\\x18\\x83\\x01 \\x01(\\x0b\\x32\\x15.caffe.PReLUParameter\\x12-\\n\\x0cpython_param\\x18\\x82\\x01 \\x01(\\x0b\\x32\\x16.caffe.PythonParameter\\x12\\x33\\n\\x0freduction_param\\x18\\x88\\x01 \\x01(\\x0b\\x32\\x19.caffe.ReductionParameter\\x12(\\n\\nrelu_param\\x18{ \\x01(\\x0b\\x32\\x14.caffe.ReLUParameter\\x12/\\n\\rreshape_param\\x18\\x85\\x01 \\x01(\\x0b\\x32\\x17.caffe.ReshapeParameter\\x12+\\n\\x0bscale_param\\x18\\x8e\\x01 \\x01(\\x0b\\x32\\x15.caffe.ScaleParameter\\x12.\\n\\rsigmoid_param\\x18| \\x01(\\x0b\\x32\\x17.caffe.SigmoidParameter\\x12.\\n\\rsoftmax_param\\x18} \\x01(\\x0b\\x32\\x17.caffe.SoftmaxParameter\\x12\\\'\\n\\tspp_param\\x18\\x84\\x01 \\x01(\\x0b\\x32\\x13.caffe.SPPParameter\\x12*\\n\\x0bslice_param\\x18~ \\x01(\\x0b\\x32\\x15.caffe.SliceParameter\\x12(\\n\\ntanh_param\\x18\\x7f \\x01(\\x0b\\x32\\x14.caffe.TanHParameter\\x12\\x33\\n\\x0fthreshold_param\\x18\\x80\\x01 \\x01(\\x0b\\x32\\x19.caffe.ThresholdParameter\\x12)\\n\\ntile_param\\x18\\x8a\\x01 \\x01(\\x0b\\x32\\x14.caffe.TileParameter\\x12\\x36\\n\\x11window_data_param\\x18\\x81\\x01 \\x01(\\x0b\\x32\\x1a.caffe.WindowDataParameter\\""\\xb6\\x01\\n\\x17TransformationParameter\\x12\\x10\\n\\x05scale\\x18\\x01 \\x01(\\x02:\\x01\\x31\\x12\\x15\\n\\x06mirror\\x18\\x02 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x14\\n\\tcrop_size\\x18\\x03 \\x01(\\r:\\x01\\x30\\x12\\x11\\n\\tmean_file\\x18\\x04 \\x01(\\t\\x12\\x12\\n\\nmean_value\\x18\\x05 \\x03(\\x02\\x12\\x1a\\n\\x0b\\x66orce_color\\x18\\x06 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x19\\n\\nforce_gray\\x18\\x07 \\x01(\\x08:\\x05\\x66\\x61lse\\""\\xc2\\x01\\n\\rLossParameter\\x12\\x14\\n\\x0cignore_label\\x18\\x01 \\x01(\\x05\\x12\\x44\\n\\rnormalization\\x18\\x03 \\x01(\\x0e\\x32&.caffe.LossParameter.NormalizationMode:\\x05VALID\\x12\\x11\\n\\tnormalize\\x18\\x02 \\x01(\\x08\\""B\\n\\x11NormalizationMode\\x12\\x08\\n\\x04\\x46ULL\\x10\\x00\\x12\\t\\n\\x05VALID\\x10\\x01\\x12\\x0e\\n\\nBATCH_SIZE\\x10\\x02\\x12\\x08\\n\\x04NONE\\x10\\x03\\""L\\n\\x11\\x41\\x63\\x63uracyParameter\\x12\\x10\\n\\x05top_k\\x18\\x01 \\x01(\\r:\\x01\\x31\\x12\\x0f\\n\\x04\\x61xis\\x18\\x02 \\x01(\\x05:\\x01\\x31\\x12\\x14\\n\\x0cignore_label\\x18\\x03 \\x01(\\x05\\""M\\n\\x0f\\x41rgMaxParameter\\x12\\x1a\\n\\x0bout_max_val\\x18\\x01 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x10\\n\\x05top_k\\x18\\x02 \\x01(\\r:\\x01\\x31\\x12\\x0c\\n\\x04\\x61xis\\x18\\x03 \\x01(\\x05\\""9\\n\\x0f\\x43oncatParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x02 \\x01(\\x05:\\x01\\x31\\x12\\x15\\n\\nconcat_dim\\x18\\x01 \\x01(\\r:\\x01\\x31\\""j\\n\\x12\\x42\\x61tchNormParameter\\x12\\x18\\n\\x10use_global_stats\\x18\\x01 \\x01(\\x08\\x12&\\n\\x17moving_average_fraction\\x18\\x02 \\x01(\\x02:\\x05\\x30.999\\x12\\x12\\n\\x03\\x65ps\\x18\\x03 \\x01(\\x02:\\x05\\x31\\x65-05\\""]\\n\\rBiasParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x01 \\x01(\\x05:\\x01\\x31\\x12\\x13\\n\\x08num_axes\\x18\\x02 \\x01(\\x05:\\x01\\x31\\x12&\\n\\x06\\x66iller\\x18\\x03 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\""L\\n\\x18\\x43ontrastiveLossParameter\\x12\\x11\\n\\x06margin\\x18\\x01 \\x01(\\x02:\\x01\\x31\\x12\\x1d\\n\\x0elegacy_version\\x18\\x02 \\x01(\\x08:\\x05\\x66\\x61lse\\""\\xfc\\x03\\n\\x14\\x43onvolutionParameter\\x12\\x12\\n\\nnum_output\\x18\\x01 \\x01(\\r\\x12\\x17\\n\\tbias_term\\x18\\x02 \\x01(\\x08:\\x04true\\x12\\x0b\\n\\x03pad\\x18\\x03 \\x03(\\r\\x12\\x13\\n\\x0bkernel_size\\x18\\x04 \\x03(\\r\\x12\\x0e\\n\\x06stride\\x18\\x06 \\x03(\\r\\x12\\x10\\n\\x08\\x64ilation\\x18\\x12 \\x03(\\r\\x12\\x10\\n\\x05pad_h\\x18\\t \\x01(\\r:\\x01\\x30\\x12\\x10\\n\\x05pad_w\\x18\\n \\x01(\\r:\\x01\\x30\\x12\\x10\\n\\x08kernel_h\\x18\\x0b \\x01(\\r\\x12\\x10\\n\\x08kernel_w\\x18\\x0c \\x01(\\r\\x12\\x10\\n\\x08stride_h\\x18\\r \\x01(\\r\\x12\\x10\\n\\x08stride_w\\x18\\x0e \\x01(\\r\\x12\\x10\\n\\x05group\\x18\\x05 \\x01(\\r:\\x01\\x31\\x12-\\n\\rweight_filler\\x18\\x07 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12+\\n\\x0b\\x62ias_filler\\x18\\x08 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12;\\n\\x06\\x65ngine\\x18\\x0f \\x01(\\x0e\\x32\\"".caffe.ConvolutionParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\x12\\x0f\\n\\x04\\x61xis\\x18\\x10 \\x01(\\x05:\\x01\\x31\\x12\\x1e\\n\\x0f\\x66orce_nd_im2col\\x18\\x11 \\x01(\\x08:\\x05\\x66\\x61lse\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""0\\n\\rCropParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x01 \\x01(\\x05:\\x01\\x32\\x12\\x0e\\n\\x06offset\\x18\\x02 \\x03(\\r\\""\\xa4\\x02\\n\\rDataParameter\\x12\\x0e\\n\\x06source\\x18\\x01 \\x01(\\t\\x12\\x12\\n\\nbatch_size\\x18\\x04 \\x01(\\r\\x12\\x14\\n\\trand_skip\\x18\\x07 \\x01(\\r:\\x01\\x30\\x12\\x31\\n\\x07\\x62\\x61\\x63kend\\x18\\x08 \\x01(\\x0e\\x32\\x17.caffe.DataParameter.DB:\\x07LEVELDB\\x12\\x10\\n\\x05scale\\x18\\x02 \\x01(\\x02:\\x01\\x31\\x12\\x11\\n\\tmean_file\\x18\\x03 \\x01(\\t\\x12\\x14\\n\\tcrop_size\\x18\\x05 \\x01(\\r:\\x01\\x30\\x12\\x15\\n\\x06mirror\\x18\\x06 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\""\\n\\x13\\x66orce_encoded_color\\x18\\t \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x13\\n\\x08prefetch\\x18\\n \\x01(\\r:\\x01\\x34\\""\\x1b\\n\\x02\\x44\\x42\\x12\\x0b\\n\\x07LEVELDB\\x10\\x00\\x12\\x08\\n\\x04LMDB\\x10\\x01\\"".\\n\\x10\\x44ropoutParameter\\x12\\x1a\\n\\rdropout_ratio\\x18\\x01 \\x01(\\x02:\\x03\\x30.5\\""\\xa0\\x01\\n\\x12\\x44ummyDataParameter\\x12+\\n\\x0b\\x64\\x61ta_filler\\x18\\x01 \\x03(\\x0b\\x32\\x16.caffe.FillerParameter\\x12\\x1f\\n\\x05shape\\x18\\x06 \\x03(\\x0b\\x32\\x10.caffe.BlobShape\\x12\\x0b\\n\\x03num\\x18\\x02 \\x03(\\r\\x12\\x10\\n\\x08\\x63hannels\\x18\\x03 \\x03(\\r\\x12\\x0e\\n\\x06height\\x18\\x04 \\x03(\\r\\x12\\r\\n\\x05width\\x18\\x05 \\x03(\\r\\""\\xa5\\x01\\n\\x10\\x45ltwiseParameter\\x12\\x39\\n\\toperation\\x18\\x01 \\x01(\\x0e\\x32!.caffe.EltwiseParameter.EltwiseOp:\\x03SUM\\x12\\r\\n\\x05\\x63oeff\\x18\\x02 \\x03(\\x02\\x12\\x1e\\n\\x10stable_prod_grad\\x18\\x03 \\x01(\\x08:\\x04true\\""\\\'\\n\\tEltwiseOp\\x12\\x08\\n\\x04PROD\\x10\\x00\\x12\\x07\\n\\x03SUM\\x10\\x01\\x12\\x07\\n\\x03MAX\\x10\\x02\\"" \\n\\x0c\\x45LUParameter\\x12\\x10\\n\\x05\\x61lpha\\x18\\x01 \\x01(\\x02:\\x01\\x31\\""\\xac\\x01\\n\\x0e\\x45mbedParameter\\x12\\x12\\n\\nnum_output\\x18\\x01 \\x01(\\r\\x12\\x11\\n\\tinput_dim\\x18\\x02 \\x01(\\r\\x12\\x17\\n\\tbias_term\\x18\\x03 \\x01(\\x08:\\x04true\\x12-\\n\\rweight_filler\\x18\\x04 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12+\\n\\x0b\\x62ias_filler\\x18\\x05 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\""D\\n\\x0c\\x45xpParameter\\x12\\x10\\n\\x04\\x62\\x61se\\x18\\x01 \\x01(\\x02:\\x02-1\\x12\\x10\\n\\x05scale\\x18\\x02 \\x01(\\x02:\\x01\\x31\\x12\\x10\\n\\x05shift\\x18\\x03 \\x01(\\x02:\\x01\\x30\\""9\\n\\x10\\x46lattenParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x01 \\x01(\\x05:\\x01\\x31\\x12\\x14\\n\\x08\\x65nd_axis\\x18\\x02 \\x01(\\x05:\\x02-1\\""O\\n\\x11HDF5DataParameter\\x12\\x0e\\n\\x06source\\x18\\x01 \\x01(\\t\\x12\\x12\\n\\nbatch_size\\x18\\x02 \\x01(\\r\\x12\\x16\\n\\x07shuffle\\x18\\x03 \\x01(\\x08:\\x05\\x66\\x61lse\\""(\\n\\x13HDF5OutputParameter\\x12\\x11\\n\\tfile_name\\x18\\x01 \\x01(\\t\\""^\\n\\x12HingeLossParameter\\x12\\x30\\n\\x04norm\\x18\\x01 \\x01(\\x0e\\x32\\x1e.caffe.HingeLossParameter.Norm:\\x02L1\\""\\x16\\n\\x04Norm\\x12\\x06\\n\\x02L1\\x10\\x01\\x12\\x06\\n\\x02L2\\x10\\x02\\""\\x97\\x02\\n\\x12ImageDataParameter\\x12\\x0e\\n\\x06source\\x18\\x01 \\x01(\\t\\x12\\x15\\n\\nbatch_size\\x18\\x04 \\x01(\\r:\\x01\\x31\\x12\\x14\\n\\trand_skip\\x18\\x07 \\x01(\\r:\\x01\\x30\\x12\\x16\\n\\x07shuffle\\x18\\x08 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x15\\n\\nnew_height\\x18\\t \\x01(\\r:\\x01\\x30\\x12\\x14\\n\\tnew_width\\x18\\n \\x01(\\r:\\x01\\x30\\x12\\x16\\n\\x08is_color\\x18\\x0b \\x01(\\x08:\\x04true\\x12\\x10\\n\\x05scale\\x18\\x02 \\x01(\\x02:\\x01\\x31\\x12\\x11\\n\\tmean_file\\x18\\x03 \\x01(\\t\\x12\\x14\\n\\tcrop_size\\x18\\x05 \\x01(\\r:\\x01\\x30\\x12\\x15\\n\\x06mirror\\x18\\x06 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x15\\n\\x0broot_folder\\x18\\x0c \\x01(\\t:\\x00\\""\\\'\\n\\x15InfogainLossParameter\\x12\\x0e\\n\\x06source\\x18\\x01 \\x01(\\t\\""\\xcb\\x01\\n\\x15InnerProductParameter\\x12\\x12\\n\\nnum_output\\x18\\x01 \\x01(\\r\\x12\\x17\\n\\tbias_term\\x18\\x02 \\x01(\\x08:\\x04true\\x12-\\n\\rweight_filler\\x18\\x03 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12+\\n\\x0b\\x62ias_filler\\x18\\x04 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x05 \\x01(\\x05:\\x01\\x31\\x12\\x18\\n\\ttranspose\\x18\\x06 \\x01(\\x08:\\x05\\x66\\x61lse\\""1\\n\\x0eInputParameter\\x12\\x1f\\n\\x05shape\\x18\\x01 \\x03(\\x0b\\x32\\x10.caffe.BlobShape\\""D\\n\\x0cLogParameter\\x12\\x10\\n\\x04\\x62\\x61se\\x18\\x01 \\x01(\\x02:\\x02-1\\x12\\x10\\n\\x05scale\\x18\\x02 \\x01(\\x02:\\x01\\x31\\x12\\x10\\n\\x05shift\\x18\\x03 \\x01(\\x02:\\x01\\x30\\""\\xb8\\x02\\n\\x0cLRNParameter\\x12\\x15\\n\\nlocal_size\\x18\\x01 \\x01(\\r:\\x01\\x35\\x12\\x10\\n\\x05\\x61lpha\\x18\\x02 \\x01(\\x02:\\x01\\x31\\x12\\x12\\n\\x04\\x62\\x65ta\\x18\\x03 \\x01(\\x02:\\x04\\x30.75\\x12\\x44\\n\\x0bnorm_region\\x18\\x04 \\x01(\\x0e\\x32\\x1e.caffe.LRNParameter.NormRegion:\\x0f\\x41\\x43ROSS_CHANNELS\\x12\\x0c\\n\\x01k\\x18\\x05 \\x01(\\x02:\\x01\\x31\\x12\\x33\\n\\x06\\x65ngine\\x18\\x06 \\x01(\\x0e\\x32\\x1a.caffe.LRNParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\""5\\n\\nNormRegion\\x12\\x13\\n\\x0f\\x41\\x43ROSS_CHANNELS\\x10\\x00\\x12\\x12\\n\\x0eWITHIN_CHANNEL\\x10\\x01\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""Z\\n\\x13MemoryDataParameter\\x12\\x12\\n\\nbatch_size\\x18\\x01 \\x01(\\r\\x12\\x10\\n\\x08\\x63hannels\\x18\\x02 \\x01(\\r\\x12\\x0e\\n\\x06height\\x18\\x03 \\x01(\\r\\x12\\r\\n\\x05width\\x18\\x04 \\x01(\\r\\""d\\n\\x0cMVNParameter\\x12 \\n\\x12normalize_variance\\x18\\x01 \\x01(\\x08:\\x04true\\x12\\x1e\\n\\x0f\\x61\\x63ross_channels\\x18\\x02 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x12\\n\\x03\\x65ps\\x18\\x03 \\x01(\\x02:\\x05\\x31\\x65-09\\""\\xa2\\x03\\n\\x10PoolingParameter\\x12\\x35\\n\\x04pool\\x18\\x01 \\x01(\\x0e\\x32\\"".caffe.PoolingParameter.PoolMethod:\\x03MAX\\x12\\x0e\\n\\x03pad\\x18\\x04 \\x01(\\r:\\x01\\x30\\x12\\x10\\n\\x05pad_h\\x18\\t \\x01(\\r:\\x01\\x30\\x12\\x10\\n\\x05pad_w\\x18\\n \\x01(\\r:\\x01\\x30\\x12\\x13\\n\\x0bkernel_size\\x18\\x02 \\x01(\\r\\x12\\x10\\n\\x08kernel_h\\x18\\x05 \\x01(\\r\\x12\\x10\\n\\x08kernel_w\\x18\\x06 \\x01(\\r\\x12\\x11\\n\\x06stride\\x18\\x03 \\x01(\\r:\\x01\\x31\\x12\\x10\\n\\x08stride_h\\x18\\x07 \\x01(\\r\\x12\\x10\\n\\x08stride_w\\x18\\x08 \\x01(\\r\\x12\\x37\\n\\x06\\x65ngine\\x18\\x0b \\x01(\\x0e\\x32\\x1e.caffe.PoolingParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\x12\\x1d\\n\\x0eglobal_pooling\\x18\\x0c \\x01(\\x08:\\x05\\x66\\x61lse\\"".\\n\\nPoolMethod\\x12\\x07\\n\\x03MAX\\x10\\x00\\x12\\x07\\n\\x03\\x41VE\\x10\\x01\\x12\\x0e\\n\\nSTOCHASTIC\\x10\\x02\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""F\\n\\x0ePowerParameter\\x12\\x10\\n\\x05power\\x18\\x01 \\x01(\\x02:\\x01\\x31\\x12\\x10\\n\\x05scale\\x18\\x02 \\x01(\\x02:\\x01\\x31\\x12\\x10\\n\\x05shift\\x18\\x03 \\x01(\\x02:\\x01\\x30\\""g\\n\\x0fPythonParameter\\x12\\x0e\\n\\x06module\\x18\\x01 \\x01(\\t\\x12\\r\\n\\x05layer\\x18\\x02 \\x01(\\t\\x12\\x13\\n\\tparam_str\\x18\\x03 \\x01(\\t:\\x00\\x12 \\n\\x11share_in_parallel\\x18\\x04 \\x01(\\x08:\\x05\\x66\\x61lse\\""\\xad\\x01\\n\\x12ReductionParameter\\x12=\\n\\toperation\\x18\\x01 \\x01(\\x0e\\x32%.caffe.ReductionParameter.ReductionOp:\\x03SUM\\x12\\x0f\\n\\x04\\x61xis\\x18\\x02 \\x01(\\x05:\\x01\\x30\\x12\\x10\\n\\x05\\x63oeff\\x18\\x03 \\x01(\\x02:\\x01\\x31\\""5\\n\\x0bReductionOp\\x12\\x07\\n\\x03SUM\\x10\\x01\\x12\\x08\\n\\x04\\x41SUM\\x10\\x02\\x12\\t\\n\\x05SUMSQ\\x10\\x03\\x12\\x08\\n\\x04MEAN\\x10\\x04\\""\\x8d\\x01\\n\\rReLUParameter\\x12\\x19\\n\\x0enegative_slope\\x18\\x01 \\x01(\\x02:\\x01\\x30\\x12\\x34\\n\\x06\\x65ngine\\x18\\x02 \\x01(\\x0e\\x32\\x1b.caffe.ReLUParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""Z\\n\\x10ReshapeParameter\\x12\\x1f\\n\\x05shape\\x18\\x01 \\x01(\\x0b\\x32\\x10.caffe.BlobShape\\x12\\x0f\\n\\x04\\x61xis\\x18\\x02 \\x01(\\x05:\\x01\\x30\\x12\\x14\\n\\x08num_axes\\x18\\x03 \\x01(\\x05:\\x02-1\\""\\xa5\\x01\\n\\x0eScaleParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x01 \\x01(\\x05:\\x01\\x31\\x12\\x13\\n\\x08num_axes\\x18\\x02 \\x01(\\x05:\\x01\\x31\\x12&\\n\\x06\\x66iller\\x18\\x03 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12\\x18\\n\\tbias_term\\x18\\x04 \\x01(\\x08:\\x05\\x66\\x61lse\\x12+\\n\\x0b\\x62ias_filler\\x18\\x05 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\""x\\n\\x10SigmoidParameter\\x12\\x37\\n\\x06\\x65ngine\\x18\\x01 \\x01(\\x0e\\x32\\x1e.caffe.SigmoidParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""L\\n\\x0eSliceParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x03 \\x01(\\x05:\\x01\\x31\\x12\\x13\\n\\x0bslice_point\\x18\\x02 \\x03(\\r\\x12\\x14\\n\\tslice_dim\\x18\\x01 \\x01(\\r:\\x01\\x31\\""\\x89\\x01\\n\\x10SoftmaxParameter\\x12\\x37\\n\\x06\\x65ngine\\x18\\x01 \\x01(\\x0e\\x32\\x1e.caffe.SoftmaxParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\x12\\x0f\\n\\x04\\x61xis\\x18\\x02 \\x01(\\x05:\\x01\\x31\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""r\\n\\rTanHParameter\\x12\\x34\\n\\x06\\x65ngine\\x18\\x01 \\x01(\\x0e\\x32\\x1b.caffe.TanHParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""/\\n\\rTileParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x01 \\x01(\\x05:\\x01\\x31\\x12\\r\\n\\x05tiles\\x18\\x02 \\x01(\\x05\\""*\\n\\x12ThresholdParameter\\x12\\x14\\n\\tthreshold\\x18\\x01 \\x01(\\x02:\\x01\\x30\\""\\xc1\\x02\\n\\x13WindowDataParameter\\x12\\x0e\\n\\x06source\\x18\\x01 \\x01(\\t\\x12\\x10\\n\\x05scale\\x18\\x02 \\x01(\\x02:\\x01\\x31\\x12\\x11\\n\\tmean_file\\x18\\x03 \\x01(\\t\\x12\\x12\\n\\nbatch_size\\x18\\x04 \\x01(\\r\\x12\\x14\\n\\tcrop_size\\x18\\x05 \\x01(\\r:\\x01\\x30\\x12\\x15\\n\\x06mirror\\x18\\x06 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x19\\n\\x0c\\x66g_threshold\\x18\\x07 \\x01(\\x02:\\x03\\x30.5\\x12\\x19\\n\\x0c\\x62g_threshold\\x18\\x08 \\x01(\\x02:\\x03\\x30.5\\x12\\x19\\n\\x0b\\x66g_fraction\\x18\\t \\x01(\\x02:\\x04\\x30.25\\x12\\x16\\n\\x0b\\x63ontext_pad\\x18\\n \\x01(\\r:\\x01\\x30\\x12\\x17\\n\\tcrop_mode\\x18\\x0b \\x01(\\t:\\x04warp\\x12\\x1b\\n\\x0c\\x63\\x61\\x63he_images\\x18\\x0c \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x15\\n\\x0broot_folder\\x18\\r \\x01(\\t:\\x00\\""\\xeb\\x01\\n\\x0cSPPParameter\\x12\\x16\\n\\x0epyramid_height\\x18\\x01 \\x01(\\r\\x12\\x31\\n\\x04pool\\x18\\x02 \\x01(\\x0e\\x32\\x1e.caffe.SPPParameter.PoolMethod:\\x03MAX\\x12\\x33\\n\\x06\\x65ngine\\x18\\x06 \\x01(\\x0e\\x32\\x1a.caffe.SPPParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\"".\\n\\nPoolMethod\\x12\\x07\\n\\x03MAX\\x10\\x00\\x12\\x07\\n\\x03\\x41VE\\x10\\x01\\x12\\x0e\\n\\nSTOCHASTIC\\x10\\x02\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""\\xe0\\x13\\n\\x10V1LayerParameter\\x12\\x0e\\n\\x06\\x62ottom\\x18\\x02 \\x03(\\t\\x12\\x0b\\n\\x03top\\x18\\x03 \\x03(\\t\\x12\\x0c\\n\\x04name\\x18\\x04 \\x01(\\t\\x12$\\n\\x07include\\x18  \\x03(\\x0b\\x32\\x13.caffe.NetStateRule\\x12$\\n\\x07\\x65xclude\\x18! \\x03(\\x0b\\x32\\x13.caffe.NetStateRule\\x12/\\n\\x04type\\x18\\x05 \\x01(\\x0e\\x32!.caffe.V1LayerParameter.LayerType\\x12\\x1f\\n\\x05\\x62lobs\\x18\\x06 \\x03(\\x0b\\x32\\x10.caffe.BlobProto\\x12\\x0e\\n\\x05param\\x18\\xe9\\x07 \\x03(\\t\\x12>\\n\\x0f\\x62lob_share_mode\\x18\\xea\\x07 \\x03(\\x0e\\x32$.caffe.V1LayerParameter.DimCheckMode\\x12\\x10\\n\\x08\\x62lobs_lr\\x18\\x07 \\x03(\\x02\\x12\\x14\\n\\x0cweight_decay\\x18\\x08 \\x03(\\x02\\x12\\x13\\n\\x0bloss_weight\\x18# \\x03(\\x02\\x12\\x30\\n\\x0e\\x61\\x63\\x63uracy_param\\x18\\x1b \\x01(\\x0b\\x32\\x18.caffe.AccuracyParameter\\x12,\\n\\x0c\\x61rgmax_param\\x18\\x17 \\x01(\\x0b\\x32\\x16.caffe.ArgMaxParameter\\x12,\\n\\x0c\\x63oncat_param\\x18\\t \\x01(\\x0b\\x32\\x16.caffe.ConcatParameter\\x12?\\n\\x16\\x63ontrastive_loss_param\\x18( \\x01(\\x0b\\x32\\x1f.caffe.ContrastiveLossParameter\\x12\\x36\\n\\x11\\x63onvolution_param\\x18\\n \\x01(\\x0b\\x32\\x1b.caffe.ConvolutionParameter\\x12(\\n\\ndata_param\\x18\\x0b \\x01(\\x0b\\x32\\x14.caffe.DataParameter\\x12.\\n\\rdropout_param\\x18\\x0c \\x01(\\x0b\\x32\\x17.caffe.DropoutParameter\\x12\\x33\\n\\x10\\x64ummy_data_param\\x18\\x1a \\x01(\\x0b\\x32\\x19.caffe.DummyDataParameter\\x12.\\n\\reltwise_param\\x18\\x18 \\x01(\\x0b\\x32\\x17.caffe.EltwiseParameter\\x12&\\n\\texp_param\\x18) \\x01(\\x0b\\x32\\x13.caffe.ExpParameter\\x12\\x31\\n\\x0fhdf5_data_param\\x18\\r \\x01(\\x0b\\x32\\x18.caffe.HDF5DataParameter\\x12\\x35\\n\\x11hdf5_output_param\\x18\\x0e \\x01(\\x0b\\x32\\x1a.caffe.HDF5OutputParameter\\x12\\x33\\n\\x10hinge_loss_param\\x18\\x1d \\x01(\\x0b\\x32\\x19.caffe.HingeLossParameter\\x12\\x33\\n\\x10image_data_param\\x18\\x0f \\x01(\\x0b\\x32\\x19.caffe.ImageDataParameter\\x12\\x39\\n\\x13infogain_loss_param\\x18\\x10 \\x01(\\x0b\\x32\\x1c.caffe.InfogainLossParameter\\x12\\x39\\n\\x13inner_product_param\\x18\\x11 \\x01(\\x0b\\x32\\x1c.caffe.InnerProductParameter\\x12&\\n\\tlrn_param\\x18\\x12 \\x01(\\x0b\\x32\\x13.caffe.LRNParameter\\x12\\x35\\n\\x11memory_data_param\\x18\\x16 \\x01(\\x0b\\x32\\x1a.caffe.MemoryDataParameter\\x12&\\n\\tmvn_param\\x18\\"" \\x01(\\x0b\\x32\\x13.caffe.MVNParameter\\x12.\\n\\rpooling_param\\x18\\x13 \\x01(\\x0b\\x32\\x17.caffe.PoolingParameter\\x12*\\n\\x0bpower_param\\x18\\x15 \\x01(\\x0b\\x32\\x15.caffe.PowerParameter\\x12(\\n\\nrelu_param\\x18\\x1e \\x01(\\x0b\\x32\\x14.caffe.ReLUParameter\\x12.\\n\\rsigmoid_param\\x18& \\x01(\\x0b\\x32\\x17.caffe.SigmoidParameter\\x12.\\n\\rsoftmax_param\\x18\\\' \\x01(\\x0b\\x32\\x17.caffe.SoftmaxParameter\\x12*\\n\\x0bslice_param\\x18\\x1f \\x01(\\x0b\\x32\\x15.caffe.SliceParameter\\x12(\\n\\ntanh_param\\x18% \\x01(\\x0b\\x32\\x14.caffe.TanHParameter\\x12\\x32\\n\\x0fthreshold_param\\x18\\x19 \\x01(\\x0b\\x32\\x19.caffe.ThresholdParameter\\x12\\x35\\n\\x11window_data_param\\x18\\x14 \\x01(\\x0b\\x32\\x1a.caffe.WindowDataParameter\\x12\\x37\\n\\x0ftransform_param\\x18$ \\x01(\\x0b\\x32\\x1e.caffe.TransformationParameter\\x12(\\n\\nloss_param\\x18* \\x01(\\x0b\\x32\\x14.caffe.LossParameter\\x12&\\n\\x05layer\\x18\\x01 \\x01(\\x0b\\x32\\x17.caffe.V0LayerParameter\\""\\xd8\\x04\\n\\tLayerType\\x12\\x08\\n\\x04NONE\\x10\\x00\\x12\\n\\n\\x06\\x41\\x42SVAL\\x10#\\x12\\x0c\\n\\x08\\x41\\x43\\x43URACY\\x10\\x01\\x12\\n\\n\\x06\\x41RGMAX\\x10\\x1e\\x12\\x08\\n\\x04\\x42NLL\\x10\\x02\\x12\\n\\n\\x06\\x43ONCAT\\x10\\x03\\x12\\x14\\n\\x10\\x43ONTRASTIVE_LOSS\\x10%\\x12\\x0f\\n\\x0b\\x43ONVOLUTION\\x10\\x04\\x12\\x08\\n\\x04\\x44\\x41TA\\x10\\x05\\x12\\x11\\n\\rDECONVOLUTION\\x10\\\'\\x12\\x0b\\n\\x07\\x44ROPOUT\\x10\\x06\\x12\\x0e\\n\\nDUMMY_DATA\\x10 \\x12\\x12\\n\\x0e\\x45UCLIDEAN_LOSS\\x10\\x07\\x12\\x0b\\n\\x07\\x45LTWISE\\x10\\x19\\x12\\x07\\n\\x03\\x45XP\\x10&\\x12\\x0b\\n\\x07\\x46LATTEN\\x10\\x08\\x12\\r\\n\\tHDF5_DATA\\x10\\t\\x12\\x0f\\n\\x0bHDF5_OUTPUT\\x10\\n\\x12\\x0e\\n\\nHINGE_LOSS\\x10\\x1c\\x12\\n\\n\\x06IM2COL\\x10\\x0b\\x12\\x0e\\n\\nIMAGE_DATA\\x10\\x0c\\x12\\x11\\n\\rINFOGAIN_LOSS\\x10\\r\\x12\\x11\\n\\rINNER_PRODUCT\\x10\\x0e\\x12\\x07\\n\\x03LRN\\x10\\x0f\\x12\\x0f\\n\\x0bMEMORY_DATA\\x10\\x1d\\x12\\x1d\\n\\x19MULTINOMIAL_LOGISTIC_LOSS\\x10\\x10\\x12\\x07\\n\\x03MVN\\x10\\""\\x12\\x0b\\n\\x07POOLING\\x10\\x11\\x12\\t\\n\\x05POWER\\x10\\x1a\\x12\\x08\\n\\x04RELU\\x10\\x12\\x12\\x0b\\n\\x07SIGMOID\\x10\\x13\\x12\\x1e\\n\\x1aSIGMOID_CROSS_ENTROPY_LOSS\\x10\\x1b\\x12\\x0b\\n\\x07SILENCE\\x10$\\x12\\x0b\\n\\x07SOFTMAX\\x10\\x14\\x12\\x10\\n\\x0cSOFTMAX_LOSS\\x10\\x15\\x12\\t\\n\\x05SPLIT\\x10\\x16\\x12\\t\\n\\x05SLICE\\x10!\\x12\\x08\\n\\x04TANH\\x10\\x17\\x12\\x0f\\n\\x0bWINDOW_DATA\\x10\\x18\\x12\\r\\n\\tTHRESHOLD\\x10\\x1f\\""*\\n\\x0c\\x44imCheckMode\\x12\\n\\n\\x06STRICT\\x10\\x00\\x12\\x0e\\n\\nPERMISSIVE\\x10\\x01\\""\\xfd\\x07\\n\\x10V0LayerParameter\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12\\x0c\\n\\x04type\\x18\\x02 \\x01(\\t\\x12\\x12\\n\\nnum_output\\x18\\x03 \\x01(\\r\\x12\\x16\\n\\x08\\x62iasterm\\x18\\x04 \\x01(\\x08:\\x04true\\x12-\\n\\rweight_filler\\x18\\x05 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12+\\n\\x0b\\x62ias_filler\\x18\\x06 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12\\x0e\\n\\x03pad\\x18\\x07 \\x01(\\r:\\x01\\x30\\x12\\x12\\n\\nkernelsize\\x18\\x08 \\x01(\\r\\x12\\x10\\n\\x05group\\x18\\t \\x01(\\r:\\x01\\x31\\x12\\x11\\n\\x06stride\\x18\\n \\x01(\\r:\\x01\\x31\\x12\\x35\\n\\x04pool\\x18\\x0b \\x01(\\x0e\\x32\\"".caffe.V0LayerParameter.PoolMethod:\\x03MAX\\x12\\x1a\\n\\rdropout_ratio\\x18\\x0c \\x01(\\x02:\\x03\\x30.5\\x12\\x15\\n\\nlocal_size\\x18\\r \\x01(\\r:\\x01\\x35\\x12\\x10\\n\\x05\\x61lpha\\x18\\x0e \\x01(\\x02:\\x01\\x31\\x12\\x12\\n\\x04\\x62\\x65ta\\x18\\x0f \\x01(\\x02:\\x04\\x30.75\\x12\\x0c\\n\\x01k\\x18\\x16 \\x01(\\x02:\\x01\\x31\\x12\\x0e\\n\\x06source\\x18\\x10 \\x01(\\t\\x12\\x10\\n\\x05scale\\x18\\x11 \\x01(\\x02:\\x01\\x31\\x12\\x10\\n\\x08meanfile\\x18\\x12 \\x01(\\t\\x12\\x11\\n\\tbatchsize\\x18\\x13 \\x01(\\r\\x12\\x13\\n\\x08\\x63ropsize\\x18\\x14 \\x01(\\r:\\x01\\x30\\x12\\x15\\n\\x06mirror\\x18\\x15 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x1f\\n\\x05\\x62lobs\\x18\\x32 \\x03(\\x0b\\x32\\x10.caffe.BlobProto\\x12\\x10\\n\\x08\\x62lobs_lr\\x18\\x33 \\x03(\\x02\\x12\\x14\\n\\x0cweight_decay\\x18\\x34 \\x03(\\x02\\x12\\x14\\n\\trand_skip\\x18\\x35 \\x01(\\r:\\x01\\x30\\x12\\x1d\\n\\x10\\x64\\x65t_fg_threshold\\x18\\x36 \\x01(\\x02:\\x03\\x30.5\\x12\\x1d\\n\\x10\\x64\\x65t_bg_threshold\\x18\\x37 \\x01(\\x02:\\x03\\x30.5\\x12\\x1d\\n\\x0f\\x64\\x65t_fg_fraction\\x18\\x38 \\x01(\\x02:\\x04\\x30.25\\x12\\x1a\\n\\x0f\\x64\\x65t_context_pad\\x18: \\x01(\\r:\\x01\\x30\\x12\\x1b\\n\\rdet_crop_mode\\x18; \\x01(\\t:\\x04warp\\x12\\x12\\n\\x07new_num\\x18< \\x01(\\x05:\\x01\\x30\\x12\\x17\\n\\x0cnew_channels\\x18= \\x01(\\x05:\\x01\\x30\\x12\\x15\\n\\nnew_height\\x18> \\x01(\\x05:\\x01\\x30\\x12\\x14\\n\\tnew_width\\x18? \\x01(\\x05:\\x01\\x30\\x12\\x1d\\n\\x0eshuffle_images\\x18@ \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x15\\n\\nconcat_dim\\x18\\x41 \\x01(\\r:\\x01\\x31\\x12\\x36\\n\\x11hdf5_output_param\\x18\\xe9\\x07 \\x01(\\x0b\\x32\\x1a.caffe.HDF5OutputParameter\\"".\\n\\nPoolMethod\\x12\\x07\\n\\x03MAX\\x10\\x00\\x12\\x07\\n\\x03\\x41VE\\x10\\x01\\x12\\x0e\\n\\nSTOCHASTIC\\x10\\x02\\""W\\n\\x0ePReLUParameter\\x12&\\n\\x06\\x66iller\\x18\\x01 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12\\x1d\\n\\x0e\\x63hannel_shared\\x18\\x02 \\x01(\\x08:\\x05\\x66\\x61lse*\\x1c\\n\\x05Phase\\x12\\t\\n\\x05TRAIN\\x10\\x00\\x12\\x08\\n\\x04TEST\\x10\\x01\')\n\n_PHASE = _descriptor.EnumDescriptor(\n  name=\'Phase\',\n  full_name=\'caffe.Phase\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'TRAIN\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'TEST\', index=1, number=1,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=14991,\n  serialized_end=15019,\n)\n\nPhase = enum_type_wrapper.EnumTypeWrapper(_PHASE)\nTRAIN = 0\nTEST = 1\n\n\n_FILLERPARAMETER_VARIANCENORM = _descriptor.EnumDescriptor(\n  name=\'VarianceNorm\',\n  full_name=\'caffe.FillerParameter.VarianceNorm\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'FAN_IN\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'FAN_OUT\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'AVERAGE\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=658,\n  serialized_end=710,\n)\n\n_SOLVERPARAMETER_SNAPSHOTFORMAT = _descriptor.EnumDescriptor(\n  name=\'SnapshotFormat\',\n  full_name=\'caffe.SolverParameter.SnapshotFormat\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'HDF5\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'BINARYPROTO\', index=1, number=1,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=2132,\n  serialized_end=2175,\n)\n\n_SOLVERPARAMETER_SOLVERMODE = _descriptor.EnumDescriptor(\n  name=\'SolverMode\',\n  full_name=\'caffe.SolverParameter.SolverMode\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'CPU\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'GPU\', index=1, number=1,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=2177,\n  serialized_end=2207,\n)\n\n_SOLVERPARAMETER_SOLVERTYPE = _descriptor.EnumDescriptor(\n  name=\'SolverType\',\n  full_name=\'caffe.SolverParameter.SolverType\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'SGD\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'NESTEROV\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ADAGRAD\', index=2, number=2,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'RMSPROP\', index=3, number=3,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ADADELTA\', index=4, number=4,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ADAM\', index=5, number=5,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=2209,\n  serialized_end=2294,\n)\n\n_PARAMSPEC_DIMCHECKMODE = _descriptor.EnumDescriptor(\n  name=\'DimCheckMode\',\n  full_name=\'caffe.ParamSpec.DimCheckMode\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'STRICT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'PERMISSIVE\', index=1, number=1,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=2725,\n  serialized_end=2767,\n)\n\n_LOSSPARAMETER_NORMALIZATIONMODE = _descriptor.EnumDescriptor(\n  name=\'NormalizationMode\',\n  full_name=\'caffe.LossParameter.NormalizationMode\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'FULL\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'VALID\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'BATCH_SIZE\', index=2, number=2,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'NONE\', index=3, number=3,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=5542,\n  serialized_end=5608,\n)\n\n_CONVOLUTIONPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.ConvolutionParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=6573,\n  serialized_end=6616,\n)\n\n_DATAPARAMETER_DB = _descriptor.EnumDescriptor(\n  name=\'DB\',\n  full_name=\'caffe.DataParameter.DB\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'LEVELDB\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'LMDB\', index=1, number=1,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=6934,\n  serialized_end=6961,\n)\n\n_ELTWISEPARAMETER_ELTWISEOP = _descriptor.EnumDescriptor(\n  name=\'EltwiseOp\',\n  full_name=\'caffe.EltwiseParameter.EltwiseOp\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'PROD\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SUM\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'MAX\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=7301,\n  serialized_end=7340,\n)\n\n_HINGELOSSPARAMETER_NORM = _descriptor.EnumDescriptor(\n  name=\'Norm\',\n  full_name=\'caffe.HingeLossParameter.Norm\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'L1\', index=0, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'L2\', index=1, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=7875,\n  serialized_end=7897,\n)\n\n_LRNPARAMETER_NORMREGION = _descriptor.EnumDescriptor(\n  name=\'NormRegion\',\n  full_name=\'caffe.LRNParameter.NormRegion\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'ACROSS_CHANNELS\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'WITHIN_CHANNEL\', index=1, number=1,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=8764,\n  serialized_end=8817,\n)\n\n_LRNPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.LRNParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=6573,\n  serialized_end=6616,\n)\n\n_POOLINGPARAMETER_POOLMETHOD = _descriptor.EnumDescriptor(\n  name=\'PoolMethod\',\n  full_name=\'caffe.PoolingParameter.PoolMethod\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'MAX\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'AVE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'STOCHASTIC\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=9386,\n  serialized_end=9432,\n)\n\n_POOLINGPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.PoolingParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=6573,\n  serialized_end=6616,\n)\n\n_REDUCTIONPARAMETER_REDUCTIONOP = _descriptor.EnumDescriptor(\n  name=\'ReductionOp\',\n  full_name=\'caffe.ReductionParameter.ReductionOp\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'SUM\', index=0, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ASUM\', index=1, number=2,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SUMSQ\', index=2, number=3,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'MEAN\', index=3, number=4,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=9777,\n  serialized_end=9830,\n)\n\n_RELUPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.ReLUParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=6573,\n  serialized_end=6616,\n)\n\n_SIGMOIDPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.SigmoidParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=6573,\n  serialized_end=6616,\n)\n\n_SOFTMAXPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.SoftmaxParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=6573,\n  serialized_end=6616,\n)\n\n_TANHPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.TanHParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=6573,\n  serialized_end=6616,\n)\n\n_SPPPARAMETER_POOLMETHOD = _descriptor.EnumDescriptor(\n  name=\'PoolMethod\',\n  full_name=\'caffe.SPPParameter.PoolMethod\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'MAX\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'AVE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'STOCHASTIC\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=9386,\n  serialized_end=9432,\n)\n\n_SPPPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.SPPParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=6573,\n  serialized_end=6616,\n)\n\n_V1LAYERPARAMETER_LAYERTYPE = _descriptor.EnumDescriptor(\n  name=\'LayerType\',\n  full_name=\'caffe.V1LayerParameter.LayerType\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'NONE\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ABSVAL\', index=1, number=35,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ACCURACY\', index=2, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ARGMAX\', index=3, number=30,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'BNLL\', index=4, number=2,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CONCAT\', index=5, number=3,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CONTRASTIVE_LOSS\', index=6, number=37,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CONVOLUTION\', index=7, number=4,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'DATA\', index=8, number=5,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'DECONVOLUTION\', index=9, number=39,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'DROPOUT\', index=10, number=6,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'DUMMY_DATA\', index=11, number=32,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'EUCLIDEAN_LOSS\', index=12, number=7,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ELTWISE\', index=13, number=25,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'EXP\', index=14, number=38,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'FLATTEN\', index=15, number=8,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'HDF5_DATA\', index=16, number=9,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'HDF5_OUTPUT\', index=17, number=10,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'HINGE_LOSS\', index=18, number=28,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'IM2COL\', index=19, number=11,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'IMAGE_DATA\', index=20, number=12,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'INFOGAIN_LOSS\', index=21, number=13,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'INNER_PRODUCT\', index=22, number=14,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'LRN\', index=23, number=15,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'MEMORY_DATA\', index=24, number=29,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'MULTINOMIAL_LOGISTIC_LOSS\', index=25, number=16,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'MVN\', index=26, number=34,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'POOLING\', index=27, number=17,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'POWER\', index=28, number=26,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'RELU\', index=29, number=18,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SIGMOID\', index=30, number=19,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SIGMOID_CROSS_ENTROPY_LOSS\', index=31, number=27,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SILENCE\', index=32, number=36,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SOFTMAX\', index=33, number=20,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SOFTMAX_LOSS\', index=34, number=21,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SPLIT\', index=35, number=22,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SLICE\', index=36, number=33,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'TANH\', index=37, number=23,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'WINDOW_DATA\', index=38, number=24,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'THRESHOLD\', index=39, number=31,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=13232,\n  serialized_end=13832,\n)\n\n_V1LAYERPARAMETER_DIMCHECKMODE = _descriptor.EnumDescriptor(\n  name=\'DimCheckMode\',\n  full_name=\'caffe.V1LayerParameter.DimCheckMode\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'STRICT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'PERMISSIVE\', index=1, number=1,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=2725,\n  serialized_end=2767,\n)\n\n_V0LAYERPARAMETER_POOLMETHOD = _descriptor.EnumDescriptor(\n  name=\'PoolMethod\',\n  full_name=\'caffe.V0LayerParameter.PoolMethod\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'MAX\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'AVE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'STOCHASTIC\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=9386,\n  serialized_end=9432,\n)\n\n\n_BLOBSHAPE = _descriptor.Descriptor(\n  name=\'BlobShape\',\n  full_name=\'caffe.BlobShape\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'dim\', full_name=\'caffe.BlobShape.dim\', index=0,\n      number=1, type=3, cpp_type=2, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), \'\\020\\001\')),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=22,\n  serialized_end=50,\n)\n\n\n_BLOBPROTO = _descriptor.Descriptor(\n  name=\'BlobProto\',\n  full_name=\'caffe.BlobProto\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'shape\', full_name=\'caffe.BlobProto.shape\', index=0,\n      number=7, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'data\', full_name=\'caffe.BlobProto.data\', index=1,\n      number=5, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), \'\\020\\001\')),\n    _descriptor.FieldDescriptor(\n      name=\'diff\', full_name=\'caffe.BlobProto.diff\', index=2,\n      number=6, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), \'\\020\\001\')),\n    _descriptor.FieldDescriptor(\n      name=\'double_data\', full_name=\'caffe.BlobProto.double_data\', index=3,\n      number=8, type=1, cpp_type=5, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), \'\\020\\001\')),\n    _descriptor.FieldDescriptor(\n      name=\'double_diff\', full_name=\'caffe.BlobProto.double_diff\', index=4,\n      number=9, type=1, cpp_type=5, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), \'\\020\\001\')),\n    _descriptor.FieldDescriptor(\n      name=\'num\', full_name=\'caffe.BlobProto.num\', index=5,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'channels\', full_name=\'caffe.BlobProto.channels\', index=6,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'height\', full_name=\'caffe.BlobProto.height\', index=7,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'width\', full_name=\'caffe.BlobProto.width\', index=8,\n      number=4, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=53,\n  serialized_end=257,\n)\n\n\n_BLOBPROTOVECTOR = _descriptor.Descriptor(\n  name=\'BlobProtoVector\',\n  full_name=\'caffe.BlobProtoVector\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'blobs\', full_name=\'caffe.BlobProtoVector.blobs\', index=0,\n      number=1, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=259,\n  serialized_end=309,\n)\n\n\n_DATUM = _descriptor.Descriptor(\n  name=\'Datum\',\n  full_name=\'caffe.Datum\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'channels\', full_name=\'caffe.Datum.channels\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'height\', full_name=\'caffe.Datum.height\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'width\', full_name=\'caffe.Datum.width\', index=2,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'data\', full_name=\'caffe.Datum.data\', index=3,\n      number=4, type=12, cpp_type=9, label=1,\n      has_default_value=False, default_value="""",\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'label\', full_name=\'caffe.Datum.label\', index=4,\n      number=5, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'float_data\', full_name=\'caffe.Datum.float_data\', index=5,\n      number=6, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'encoded\', full_name=\'caffe.Datum.encoded\', index=6,\n      number=7, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=312,\n  serialized_end=441,\n)\n\n\n_FILLERPARAMETER = _descriptor.Descriptor(\n  name=\'FillerParameter\',\n  full_name=\'caffe.FillerParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'type\', full_name=\'caffe.FillerParameter.type\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=unicode(""constant"", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'value\', full_name=\'caffe.FillerParameter.value\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'min\', full_name=\'caffe.FillerParameter.min\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'max\', full_name=\'caffe.FillerParameter.max\', index=3,\n      number=4, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mean\', full_name=\'caffe.FillerParameter.mean\', index=4,\n      number=5, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'std\', full_name=\'caffe.FillerParameter.std\', index=5,\n      number=6, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'sparse\', full_name=\'caffe.FillerParameter.sparse\', index=6,\n      number=7, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=-1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'variance_norm\', full_name=\'caffe.FillerParameter.variance_norm\', index=7,\n      number=8, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _FILLERPARAMETER_VARIANCENORM,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=444,\n  serialized_end=710,\n)\n\n\n_NETPARAMETER = _descriptor.Descriptor(\n  name=\'NetParameter\',\n  full_name=\'caffe.NetParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'caffe.NetParameter.name\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'input\', full_name=\'caffe.NetParameter.input\', index=1,\n      number=3, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'input_shape\', full_name=\'caffe.NetParameter.input_shape\', index=2,\n      number=8, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'input_dim\', full_name=\'caffe.NetParameter.input_dim\', index=3,\n      number=4, type=5, cpp_type=1, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'force_backward\', full_name=\'caffe.NetParameter.force_backward\', index=4,\n      number=5, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'state\', full_name=\'caffe.NetParameter.state\', index=5,\n      number=6, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'debug_info\', full_name=\'caffe.NetParameter.debug_info\', index=6,\n      number=7, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'layer\', full_name=\'caffe.NetParameter.layer\', index=7,\n      number=100, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'layers\', full_name=\'caffe.NetParameter.layers\', index=8,\n      number=2, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=713,\n  serialized_end=983,\n)\n\n\n_SOLVERPARAMETER = _descriptor.Descriptor(\n  name=\'SolverParameter\',\n  full_name=\'caffe.SolverParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'net\', full_name=\'caffe.SolverParameter.net\', index=0,\n      number=24, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'net_param\', full_name=\'caffe.SolverParameter.net_param\', index=1,\n      number=25, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'train_net\', full_name=\'caffe.SolverParameter.train_net\', index=2,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'test_net\', full_name=\'caffe.SolverParameter.test_net\', index=3,\n      number=2, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'train_net_param\', full_name=\'caffe.SolverParameter.train_net_param\', index=4,\n      number=21, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'test_net_param\', full_name=\'caffe.SolverParameter.test_net_param\', index=5,\n      number=22, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'train_state\', full_name=\'caffe.SolverParameter.train_state\', index=6,\n      number=26, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'test_state\', full_name=\'caffe.SolverParameter.test_state\', index=7,\n      number=27, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'test_iter\', full_name=\'caffe.SolverParameter.test_iter\', index=8,\n      number=3, type=5, cpp_type=1, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'test_interval\', full_name=\'caffe.SolverParameter.test_interval\', index=9,\n      number=4, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'test_compute_loss\', full_name=\'caffe.SolverParameter.test_compute_loss\', index=10,\n      number=19, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'test_initialization\', full_name=\'caffe.SolverParameter.test_initialization\', index=11,\n      number=32, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'base_lr\', full_name=\'caffe.SolverParameter.base_lr\', index=12,\n      number=5, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'display\', full_name=\'caffe.SolverParameter.display\', index=13,\n      number=6, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'average_loss\', full_name=\'caffe.SolverParameter.average_loss\', index=14,\n      number=33, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'max_iter\', full_name=\'caffe.SolverParameter.max_iter\', index=15,\n      number=7, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'iter_size\', full_name=\'caffe.SolverParameter.iter_size\', index=16,\n      number=36, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'lr_policy\', full_name=\'caffe.SolverParameter.lr_policy\', index=17,\n      number=8, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'gamma\', full_name=\'caffe.SolverParameter.gamma\', index=18,\n      number=9, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'power\', full_name=\'caffe.SolverParameter.power\', index=19,\n      number=10, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'momentum\', full_name=\'caffe.SolverParameter.momentum\', index=20,\n      number=11, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'weight_decay\', full_name=\'caffe.SolverParameter.weight_decay\', index=21,\n      number=12, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'regularization_type\', full_name=\'caffe.SolverParameter.regularization_type\', index=22,\n      number=29, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=unicode(""L2"", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stepsize\', full_name=\'caffe.SolverParameter.stepsize\', index=23,\n      number=13, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stepvalue\', full_name=\'caffe.SolverParameter.stepvalue\', index=24,\n      number=34, type=5, cpp_type=1, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'clip_gradients\', full_name=\'caffe.SolverParameter.clip_gradients\', index=25,\n      number=35, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=-1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'snapshot\', full_name=\'caffe.SolverParameter.snapshot\', index=26,\n      number=14, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'snapshot_prefix\', full_name=\'caffe.SolverParameter.snapshot_prefix\', index=27,\n      number=15, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'snapshot_diff\', full_name=\'caffe.SolverParameter.snapshot_diff\', index=28,\n      number=16, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'snapshot_format\', full_name=\'caffe.SolverParameter.snapshot_format\', index=29,\n      number=37, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'solver_mode\', full_name=\'caffe.SolverParameter.solver_mode\', index=30,\n      number=17, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'device_id\', full_name=\'caffe.SolverParameter.device_id\', index=31,\n      number=18, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'random_seed\', full_name=\'caffe.SolverParameter.random_seed\', index=32,\n      number=20, type=3, cpp_type=2, label=1,\n      has_default_value=True, default_value=-1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'type\', full_name=\'caffe.SolverParameter.type\', index=33,\n      number=40, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=unicode(""SGD"", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'delta\', full_name=\'caffe.SolverParameter.delta\', index=34,\n      number=31, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1e-08,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'momentum2\', full_name=\'caffe.SolverParameter.momentum2\', index=35,\n      number=39, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0.999,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'rms_decay\', full_name=\'caffe.SolverParameter.rms_decay\', index=36,\n      number=38, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'debug_info\', full_name=\'caffe.SolverParameter.debug_info\', index=37,\n      number=23, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'snapshot_after_train\', full_name=\'caffe.SolverParameter.snapshot_after_train\', index=38,\n      number=28, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'solver_type\', full_name=\'caffe.SolverParameter.solver_type\', index=39,\n      number=30, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _SOLVERPARAMETER_SNAPSHOTFORMAT,\n    _SOLVERPARAMETER_SOLVERMODE,\n    _SOLVERPARAMETER_SOLVERTYPE,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=986,\n  serialized_end=2294,\n)\n\n\n_SOLVERSTATE = _descriptor.Descriptor(\n  name=\'SolverState\',\n  full_name=\'caffe.SolverState\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'iter\', full_name=\'caffe.SolverState.iter\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'learned_net\', full_name=\'caffe.SolverState.learned_net\', index=1,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'history\', full_name=\'caffe.SolverState.history\', index=2,\n      number=3, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'current_step\', full_name=\'caffe.SolverState.current_step\', index=3,\n      number=4, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=2296,\n  serialized_end=2404,\n)\n\n\n_NETSTATE = _descriptor.Descriptor(\n  name=\'NetState\',\n  full_name=\'caffe.NetState\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'phase\', full_name=\'caffe.NetState.phase\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'level\', full_name=\'caffe.NetState.level\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stage\', full_name=\'caffe.NetState.stage\', index=2,\n      number=3, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=2406,\n  serialized_end=2484,\n)\n\n\n_NETSTATERULE = _descriptor.Descriptor(\n  name=\'NetStateRule\',\n  full_name=\'caffe.NetStateRule\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'phase\', full_name=\'caffe.NetStateRule.phase\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'min_level\', full_name=\'caffe.NetStateRule.min_level\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'max_level\', full_name=\'caffe.NetStateRule.max_level\', index=2,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stage\', full_name=\'caffe.NetStateRule.stage\', index=3,\n      number=4, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'not_stage\', full_name=\'caffe.NetStateRule.not_stage\', index=4,\n      number=5, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=2486,\n  serialized_end=2601,\n)\n\n\n_PARAMSPEC = _descriptor.Descriptor(\n  name=\'ParamSpec\',\n  full_name=\'caffe.ParamSpec\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'caffe.ParamSpec.name\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'share_mode\', full_name=\'caffe.ParamSpec.share_mode\', index=1,\n      number=2, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'lr_mult\', full_name=\'caffe.ParamSpec.lr_mult\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'decay_mult\', full_name=\'caffe.ParamSpec.decay_mult\', index=3,\n      number=4, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _PARAMSPEC_DIMCHECKMODE,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=2604,\n  serialized_end=2767,\n)\n\n\n_LAYERPARAMETER = _descriptor.Descriptor(\n  name=\'LayerParameter\',\n  full_name=\'caffe.LayerParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'caffe.LayerParameter.name\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'type\', full_name=\'caffe.LayerParameter.type\', index=1,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bottom\', full_name=\'caffe.LayerParameter.bottom\', index=2,\n      number=3, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'top\', full_name=\'caffe.LayerParameter.top\', index=3,\n      number=4, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'phase\', full_name=\'caffe.LayerParameter.phase\', index=4,\n      number=10, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'loss_weight\', full_name=\'caffe.LayerParameter.loss_weight\', index=5,\n      number=5, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'param\', full_name=\'caffe.LayerParameter.param\', index=6,\n      number=6, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'blobs\', full_name=\'caffe.LayerParameter.blobs\', index=7,\n      number=7, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'propagate_down\', full_name=\'caffe.LayerParameter.propagate_down\', index=8,\n      number=11, type=8, cpp_type=7, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'include\', full_name=\'caffe.LayerParameter.include\', index=9,\n      number=8, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'exclude\', full_name=\'caffe.LayerParameter.exclude\', index=10,\n      number=9, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'transform_param\', full_name=\'caffe.LayerParameter.transform_param\', index=11,\n      number=100, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'loss_param\', full_name=\'caffe.LayerParameter.loss_param\', index=12,\n      number=101, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'accuracy_param\', full_name=\'caffe.LayerParameter.accuracy_param\', index=13,\n      number=102, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'argmax_param\', full_name=\'caffe.LayerParameter.argmax_param\', index=14,\n      number=103, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'batch_norm_param\', full_name=\'caffe.LayerParameter.batch_norm_param\', index=15,\n      number=139, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_param\', full_name=\'caffe.LayerParameter.bias_param\', index=16,\n      number=141, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'concat_param\', full_name=\'caffe.LayerParameter.concat_param\', index=17,\n      number=104, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'contrastive_loss_param\', full_name=\'caffe.LayerParameter.contrastive_loss_param\', index=18,\n      number=105, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'convolution_param\', full_name=\'caffe.LayerParameter.convolution_param\', index=19,\n      number=106, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'crop_param\', full_name=\'caffe.LayerParameter.crop_param\', index=20,\n      number=144, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'data_param\', full_name=\'caffe.LayerParameter.data_param\', index=21,\n      number=107, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'dropout_param\', full_name=\'caffe.LayerParameter.dropout_param\', index=22,\n      number=108, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'dummy_data_param\', full_name=\'caffe.LayerParameter.dummy_data_param\', index=23,\n      number=109, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'eltwise_param\', full_name=\'caffe.LayerParameter.eltwise_param\', index=24,\n      number=110, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'elu_param\', full_name=\'caffe.LayerParameter.elu_param\', index=25,\n      number=140, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'embed_param\', full_name=\'caffe.LayerParameter.embed_param\', index=26,\n      number=137, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'exp_param\', full_name=\'caffe.LayerParameter.exp_param\', index=27,\n      number=111, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'flatten_param\', full_name=\'caffe.LayerParameter.flatten_param\', index=28,\n      number=135, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'hdf5_data_param\', full_name=\'caffe.LayerParameter.hdf5_data_param\', index=29,\n      number=112, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'hdf5_output_param\', full_name=\'caffe.LayerParameter.hdf5_output_param\', index=30,\n      number=113, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'hinge_loss_param\', full_name=\'caffe.LayerParameter.hinge_loss_param\', index=31,\n      number=114, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'image_data_param\', full_name=\'caffe.LayerParameter.image_data_param\', index=32,\n      number=115, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'infogain_loss_param\', full_name=\'caffe.LayerParameter.infogain_loss_param\', index=33,\n      number=116, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'inner_product_param\', full_name=\'caffe.LayerParameter.inner_product_param\', index=34,\n      number=117, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'input_param\', full_name=\'caffe.LayerParameter.input_param\', index=35,\n      number=143, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'log_param\', full_name=\'caffe.LayerParameter.log_param\', index=36,\n      number=134, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'lrn_param\', full_name=\'caffe.LayerParameter.lrn_param\', index=37,\n      number=118, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'memory_data_param\', full_name=\'caffe.LayerParameter.memory_data_param\', index=38,\n      number=119, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mvn_param\', full_name=\'caffe.LayerParameter.mvn_param\', index=39,\n      number=120, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pooling_param\', full_name=\'caffe.LayerParameter.pooling_param\', index=40,\n      number=121, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'power_param\', full_name=\'caffe.LayerParameter.power_param\', index=41,\n      number=122, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'prelu_param\', full_name=\'caffe.LayerParameter.prelu_param\', index=42,\n      number=131, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'python_param\', full_name=\'caffe.LayerParameter.python_param\', index=43,\n      number=130, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'reduction_param\', full_name=\'caffe.LayerParameter.reduction_param\', index=44,\n      number=136, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'relu_param\', full_name=\'caffe.LayerParameter.relu_param\', index=45,\n      number=123, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'reshape_param\', full_name=\'caffe.LayerParameter.reshape_param\', index=46,\n      number=133, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'scale_param\', full_name=\'caffe.LayerParameter.scale_param\', index=47,\n      number=142, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'sigmoid_param\', full_name=\'caffe.LayerParameter.sigmoid_param\', index=48,\n      number=124, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'softmax_param\', full_name=\'caffe.LayerParameter.softmax_param\', index=49,\n      number=125, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'spp_param\', full_name=\'caffe.LayerParameter.spp_param\', index=50,\n      number=132, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'slice_param\', full_name=\'caffe.LayerParameter.slice_param\', index=51,\n      number=126, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'tanh_param\', full_name=\'caffe.LayerParameter.tanh_param\', index=52,\n      number=127, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'threshold_param\', full_name=\'caffe.LayerParameter.threshold_param\', index=53,\n      number=128, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'tile_param\', full_name=\'caffe.LayerParameter.tile_param\', index=54,\n      number=138, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'window_data_param\', full_name=\'caffe.LayerParameter.window_data_param\', index=55,\n      number=129, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=2770,\n  serialized_end=5226,\n)\n\n\n_TRANSFORMATIONPARAMETER = _descriptor.Descriptor(\n  name=\'TransformationParameter\',\n  full_name=\'caffe.TransformationParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.TransformationParameter.scale\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mirror\', full_name=\'caffe.TransformationParameter.mirror\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'crop_size\', full_name=\'caffe.TransformationParameter.crop_size\', index=2,\n      number=3, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mean_file\', full_name=\'caffe.TransformationParameter.mean_file\', index=3,\n      number=4, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mean_value\', full_name=\'caffe.TransformationParameter.mean_value\', index=4,\n      number=5, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'force_color\', full_name=\'caffe.TransformationParameter.force_color\', index=5,\n      number=6, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'force_gray\', full_name=\'caffe.TransformationParameter.force_gray\', index=6,\n      number=7, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=5229,\n  serialized_end=5411,\n)\n\n\n_LOSSPARAMETER = _descriptor.Descriptor(\n  name=\'LossParameter\',\n  full_name=\'caffe.LossParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'ignore_label\', full_name=\'caffe.LossParameter.ignore_label\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'normalization\', full_name=\'caffe.LossParameter.normalization\', index=1,\n      number=3, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'normalize\', full_name=\'caffe.LossParameter.normalize\', index=2,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=False, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _LOSSPARAMETER_NORMALIZATIONMODE,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=5414,\n  serialized_end=5608,\n)\n\n\n_ACCURACYPARAMETER = _descriptor.Descriptor(\n  name=\'AccuracyParameter\',\n  full_name=\'caffe.AccuracyParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'top_k\', full_name=\'caffe.AccuracyParameter.top_k\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.AccuracyParameter.axis\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'ignore_label\', full_name=\'caffe.AccuracyParameter.ignore_label\', index=2,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=5610,\n  serialized_end=5686,\n)\n\n\n_ARGMAXPARAMETER = _descriptor.Descriptor(\n  name=\'ArgMaxParameter\',\n  full_name=\'caffe.ArgMaxParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'out_max_val\', full_name=\'caffe.ArgMaxParameter.out_max_val\', index=0,\n      number=1, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'top_k\', full_name=\'caffe.ArgMaxParameter.top_k\', index=1,\n      number=2, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.ArgMaxParameter.axis\', index=2,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=5688,\n  serialized_end=5765,\n)\n\n\n_CONCATPARAMETER = _descriptor.Descriptor(\n  name=\'ConcatParameter\',\n  full_name=\'caffe.ConcatParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.ConcatParameter.axis\', index=0,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'concat_dim\', full_name=\'caffe.ConcatParameter.concat_dim\', index=1,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=5767,\n  serialized_end=5824,\n)\n\n\n_BATCHNORMPARAMETER = _descriptor.Descriptor(\n  name=\'BatchNormParameter\',\n  full_name=\'caffe.BatchNormParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'use_global_stats\', full_name=\'caffe.BatchNormParameter.use_global_stats\', index=0,\n      number=1, type=8, cpp_type=7, label=1,\n      has_default_value=False, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'moving_average_fraction\', full_name=\'caffe.BatchNormParameter.moving_average_fraction\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0.999,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'eps\', full_name=\'caffe.BatchNormParameter.eps\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1e-05,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=5826,\n  serialized_end=5932,\n)\n\n\n_BIASPARAMETER = _descriptor.Descriptor(\n  name=\'BiasParameter\',\n  full_name=\'caffe.BiasParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.BiasParameter.axis\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'num_axes\', full_name=\'caffe.BiasParameter.num_axes\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'filler\', full_name=\'caffe.BiasParameter.filler\', index=2,\n      number=3, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=5934,\n  serialized_end=6027,\n)\n\n\n_CONTRASTIVELOSSPARAMETER = _descriptor.Descriptor(\n  name=\'ContrastiveLossParameter\',\n  full_name=\'caffe.ContrastiveLossParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'margin\', full_name=\'caffe.ContrastiveLossParameter.margin\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'legacy_version\', full_name=\'caffe.ContrastiveLossParameter.legacy_version\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=6029,\n  serialized_end=6105,\n)\n\n\n_CONVOLUTIONPARAMETER = _descriptor.Descriptor(\n  name=\'ConvolutionParameter\',\n  full_name=\'caffe.ConvolutionParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'num_output\', full_name=\'caffe.ConvolutionParameter.num_output\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_term\', full_name=\'caffe.ConvolutionParameter.bias_term\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pad\', full_name=\'caffe.ConvolutionParameter.pad\', index=2,\n      number=3, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'kernel_size\', full_name=\'caffe.ConvolutionParameter.kernel_size\', index=3,\n      number=4, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stride\', full_name=\'caffe.ConvolutionParameter.stride\', index=4,\n      number=6, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'dilation\', full_name=\'caffe.ConvolutionParameter.dilation\', index=5,\n      number=18, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pad_h\', full_name=\'caffe.ConvolutionParameter.pad_h\', index=6,\n      number=9, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pad_w\', full_name=\'caffe.ConvolutionParameter.pad_w\', index=7,\n      number=10, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'kernel_h\', full_name=\'caffe.ConvolutionParameter.kernel_h\', index=8,\n      number=11, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'kernel_w\', full_name=\'caffe.ConvolutionParameter.kernel_w\', index=9,\n      number=12, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stride_h\', full_name=\'caffe.ConvolutionParameter.stride_h\', index=10,\n      number=13, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stride_w\', full_name=\'caffe.ConvolutionParameter.stride_w\', index=11,\n      number=14, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'group\', full_name=\'caffe.ConvolutionParameter.group\', index=12,\n      number=5, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'weight_filler\', full_name=\'caffe.ConvolutionParameter.weight_filler\', index=13,\n      number=7, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_filler\', full_name=\'caffe.ConvolutionParameter.bias_filler\', index=14,\n      number=8, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.ConvolutionParameter.engine\', index=15,\n      number=15, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.ConvolutionParameter.axis\', index=16,\n      number=16, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'force_nd_im2col\', full_name=\'caffe.ConvolutionParameter.force_nd_im2col\', index=17,\n      number=17, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _CONVOLUTIONPARAMETER_ENGINE,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=6108,\n  serialized_end=6616,\n)\n\n\n_CROPPARAMETER = _descriptor.Descriptor(\n  name=\'CropParameter\',\n  full_name=\'caffe.CropParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.CropParameter.axis\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=2,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'offset\', full_name=\'caffe.CropParameter.offset\', index=1,\n      number=2, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=6618,\n  serialized_end=6666,\n)\n\n\n_DATAPARAMETER = _descriptor.Descriptor(\n  name=\'DataParameter\',\n  full_name=\'caffe.DataParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'source\', full_name=\'caffe.DataParameter.source\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'batch_size\', full_name=\'caffe.DataParameter.batch_size\', index=1,\n      number=4, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'rand_skip\', full_name=\'caffe.DataParameter.rand_skip\', index=2,\n      number=7, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'backend\', full_name=\'caffe.DataParameter.backend\', index=3,\n      number=8, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.DataParameter.scale\', index=4,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mean_file\', full_name=\'caffe.DataParameter.mean_file\', index=5,\n      number=3, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'crop_size\', full_name=\'caffe.DataParameter.crop_size\', index=6,\n      number=5, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mirror\', full_name=\'caffe.DataParameter.mirror\', index=7,\n      number=6, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'force_encoded_color\', full_name=\'caffe.DataParameter.force_encoded_color\', index=8,\n      number=9, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'prefetch\', full_name=\'caffe.DataParameter.prefetch\', index=9,\n      number=10, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=4,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _DATAPARAMETER_DB,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=6669,\n  serialized_end=6961,\n)\n\n\n_DROPOUTPARAMETER = _descriptor.Descriptor(\n  name=\'DropoutParameter\',\n  full_name=\'caffe.DropoutParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'dropout_ratio\', full_name=\'caffe.DropoutParameter.dropout_ratio\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0.5,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=6963,\n  serialized_end=7009,\n)\n\n\n_DUMMYDATAPARAMETER = _descriptor.Descriptor(\n  name=\'DummyDataParameter\',\n  full_name=\'caffe.DummyDataParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'data_filler\', full_name=\'caffe.DummyDataParameter.data_filler\', index=0,\n      number=1, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'shape\', full_name=\'caffe.DummyDataParameter.shape\', index=1,\n      number=6, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'num\', full_name=\'caffe.DummyDataParameter.num\', index=2,\n      number=2, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'channels\', full_name=\'caffe.DummyDataParameter.channels\', index=3,\n      number=3, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'height\', full_name=\'caffe.DummyDataParameter.height\', index=4,\n      number=4, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'width\', full_name=\'caffe.DummyDataParameter.width\', index=5,\n      number=5, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=7012,\n  serialized_end=7172,\n)\n\n\n_ELTWISEPARAMETER = _descriptor.Descriptor(\n  name=\'EltwiseParameter\',\n  full_name=\'caffe.EltwiseParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'operation\', full_name=\'caffe.EltwiseParameter.operation\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'coeff\', full_name=\'caffe.EltwiseParameter.coeff\', index=1,\n      number=2, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stable_prod_grad\', full_name=\'caffe.EltwiseParameter.stable_prod_grad\', index=2,\n      number=3, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _ELTWISEPARAMETER_ELTWISEOP,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=7175,\n  serialized_end=7340,\n)\n\n\n_ELUPARAMETER = _descriptor.Descriptor(\n  name=\'ELUParameter\',\n  full_name=\'caffe.ELUParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'alpha\', full_name=\'caffe.ELUParameter.alpha\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=7342,\n  serialized_end=7374,\n)\n\n\n_EMBEDPARAMETER = _descriptor.Descriptor(\n  name=\'EmbedParameter\',\n  full_name=\'caffe.EmbedParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'num_output\', full_name=\'caffe.EmbedParameter.num_output\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'input_dim\', full_name=\'caffe.EmbedParameter.input_dim\', index=1,\n      number=2, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_term\', full_name=\'caffe.EmbedParameter.bias_term\', index=2,\n      number=3, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'weight_filler\', full_name=\'caffe.EmbedParameter.weight_filler\', index=3,\n      number=4, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_filler\', full_name=\'caffe.EmbedParameter.bias_filler\', index=4,\n      number=5, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=7377,\n  serialized_end=7549,\n)\n\n\n_EXPPARAMETER = _descriptor.Descriptor(\n  name=\'ExpParameter\',\n  full_name=\'caffe.ExpParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'base\', full_name=\'caffe.ExpParameter.base\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=-1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.ExpParameter.scale\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'shift\', full_name=\'caffe.ExpParameter.shift\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=7551,\n  serialized_end=7619,\n)\n\n\n_FLATTENPARAMETER = _descriptor.Descriptor(\n  name=\'FlattenParameter\',\n  full_name=\'caffe.FlattenParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.FlattenParameter.axis\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'end_axis\', full_name=\'caffe.FlattenParameter.end_axis\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=-1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=7621,\n  serialized_end=7678,\n)\n\n\n_HDF5DATAPARAMETER = _descriptor.Descriptor(\n  name=\'HDF5DataParameter\',\n  full_name=\'caffe.HDF5DataParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'source\', full_name=\'caffe.HDF5DataParameter.source\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'batch_size\', full_name=\'caffe.HDF5DataParameter.batch_size\', index=1,\n      number=2, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'shuffle\', full_name=\'caffe.HDF5DataParameter.shuffle\', index=2,\n      number=3, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=7680,\n  serialized_end=7759,\n)\n\n\n_HDF5OUTPUTPARAMETER = _descriptor.Descriptor(\n  name=\'HDF5OutputParameter\',\n  full_name=\'caffe.HDF5OutputParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'file_name\', full_name=\'caffe.HDF5OutputParameter.file_name\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=7761,\n  serialized_end=7801,\n)\n\n\n_HINGELOSSPARAMETER = _descriptor.Descriptor(\n  name=\'HingeLossParameter\',\n  full_name=\'caffe.HingeLossParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'norm\', full_name=\'caffe.HingeLossParameter.norm\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _HINGELOSSPARAMETER_NORM,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=7803,\n  serialized_end=7897,\n)\n\n\n_IMAGEDATAPARAMETER = _descriptor.Descriptor(\n  name=\'ImageDataParameter\',\n  full_name=\'caffe.ImageDataParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'source\', full_name=\'caffe.ImageDataParameter.source\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'batch_size\', full_name=\'caffe.ImageDataParameter.batch_size\', index=1,\n      number=4, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'rand_skip\', full_name=\'caffe.ImageDataParameter.rand_skip\', index=2,\n      number=7, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'shuffle\', full_name=\'caffe.ImageDataParameter.shuffle\', index=3,\n      number=8, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'new_height\', full_name=\'caffe.ImageDataParameter.new_height\', index=4,\n      number=9, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'new_width\', full_name=\'caffe.ImageDataParameter.new_width\', index=5,\n      number=10, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'is_color\', full_name=\'caffe.ImageDataParameter.is_color\', index=6,\n      number=11, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.ImageDataParameter.scale\', index=7,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mean_file\', full_name=\'caffe.ImageDataParameter.mean_file\', index=8,\n      number=3, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'crop_size\', full_name=\'caffe.ImageDataParameter.crop_size\', index=9,\n      number=5, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mirror\', full_name=\'caffe.ImageDataParameter.mirror\', index=10,\n      number=6, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'root_folder\', full_name=\'caffe.ImageDataParameter.root_folder\', index=11,\n      number=12, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=7900,\n  serialized_end=8179,\n)\n\n\n_INFOGAINLOSSPARAMETER = _descriptor.Descriptor(\n  name=\'InfogainLossParameter\',\n  full_name=\'caffe.InfogainLossParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'source\', full_name=\'caffe.InfogainLossParameter.source\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=8181,\n  serialized_end=8220,\n)\n\n\n_INNERPRODUCTPARAMETER = _descriptor.Descriptor(\n  name=\'InnerProductParameter\',\n  full_name=\'caffe.InnerProductParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'num_output\', full_name=\'caffe.InnerProductParameter.num_output\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_term\', full_name=\'caffe.InnerProductParameter.bias_term\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'weight_filler\', full_name=\'caffe.InnerProductParameter.weight_filler\', index=2,\n      number=3, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_filler\', full_name=\'caffe.InnerProductParameter.bias_filler\', index=3,\n      number=4, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.InnerProductParameter.axis\', index=4,\n      number=5, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'transpose\', full_name=\'caffe.InnerProductParameter.transpose\', index=5,\n      number=6, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=8223,\n  serialized_end=8426,\n)\n\n\n_INPUTPARAMETER = _descriptor.Descriptor(\n  name=\'InputParameter\',\n  full_name=\'caffe.InputParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'shape\', full_name=\'caffe.InputParameter.shape\', index=0,\n      number=1, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=8428,\n  serialized_end=8477,\n)\n\n\n_LOGPARAMETER = _descriptor.Descriptor(\n  name=\'LogParameter\',\n  full_name=\'caffe.LogParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'base\', full_name=\'caffe.LogParameter.base\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=-1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.LogParameter.scale\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'shift\', full_name=\'caffe.LogParameter.shift\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=8479,\n  serialized_end=8547,\n)\n\n\n_LRNPARAMETER = _descriptor.Descriptor(\n  name=\'LRNParameter\',\n  full_name=\'caffe.LRNParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'local_size\', full_name=\'caffe.LRNParameter.local_size\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=5,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'alpha\', full_name=\'caffe.LRNParameter.alpha\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'beta\', full_name=\'caffe.LRNParameter.beta\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0.75,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'norm_region\', full_name=\'caffe.LRNParameter.norm_region\', index=3,\n      number=4, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'k\', full_name=\'caffe.LRNParameter.k\', index=4,\n      number=5, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.LRNParameter.engine\', index=5,\n      number=6, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _LRNPARAMETER_NORMREGION,\n    _LRNPARAMETER_ENGINE,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=8550,\n  serialized_end=8862,\n)\n\n\n_MEMORYDATAPARAMETER = _descriptor.Descriptor(\n  name=\'MemoryDataParameter\',\n  full_name=\'caffe.MemoryDataParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'batch_size\', full_name=\'caffe.MemoryDataParameter.batch_size\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'channels\', full_name=\'caffe.MemoryDataParameter.channels\', index=1,\n      number=2, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'height\', full_name=\'caffe.MemoryDataParameter.height\', index=2,\n      number=3, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'width\', full_name=\'caffe.MemoryDataParameter.width\', index=3,\n      number=4, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=8864,\n  serialized_end=8954,\n)\n\n\n_MVNPARAMETER = _descriptor.Descriptor(\n  name=\'MVNParameter\',\n  full_name=\'caffe.MVNParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'normalize_variance\', full_name=\'caffe.MVNParameter.normalize_variance\', index=0,\n      number=1, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'across_channels\', full_name=\'caffe.MVNParameter.across_channels\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'eps\', full_name=\'caffe.MVNParameter.eps\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1e-09,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=8956,\n  serialized_end=9056,\n)\n\n\n_POOLINGPARAMETER = _descriptor.Descriptor(\n  name=\'PoolingParameter\',\n  full_name=\'caffe.PoolingParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'pool\', full_name=\'caffe.PoolingParameter.pool\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pad\', full_name=\'caffe.PoolingParameter.pad\', index=1,\n      number=4, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pad_h\', full_name=\'caffe.PoolingParameter.pad_h\', index=2,\n      number=9, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pad_w\', full_name=\'caffe.PoolingParameter.pad_w\', index=3,\n      number=10, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'kernel_size\', full_name=\'caffe.PoolingParameter.kernel_size\', index=4,\n      number=2, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'kernel_h\', full_name=\'caffe.PoolingParameter.kernel_h\', index=5,\n      number=5, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'kernel_w\', full_name=\'caffe.PoolingParameter.kernel_w\', index=6,\n      number=6, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stride\', full_name=\'caffe.PoolingParameter.stride\', index=7,\n      number=3, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stride_h\', full_name=\'caffe.PoolingParameter.stride_h\', index=8,\n      number=7, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stride_w\', full_name=\'caffe.PoolingParameter.stride_w\', index=9,\n      number=8, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.PoolingParameter.engine\', index=10,\n      number=11, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'global_pooling\', full_name=\'caffe.PoolingParameter.global_pooling\', index=11,\n      number=12, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _POOLINGPARAMETER_POOLMETHOD,\n    _POOLINGPARAMETER_ENGINE,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=9059,\n  serialized_end=9477,\n)\n\n\n_POWERPARAMETER = _descriptor.Descriptor(\n  name=\'PowerParameter\',\n  full_name=\'caffe.PowerParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'power\', full_name=\'caffe.PowerParameter.power\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.PowerParameter.scale\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'shift\', full_name=\'caffe.PowerParameter.shift\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=9479,\n  serialized_end=9549,\n)\n\n\n_PYTHONPARAMETER = _descriptor.Descriptor(\n  name=\'PythonParameter\',\n  full_name=\'caffe.PythonParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'module\', full_name=\'caffe.PythonParameter.module\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'layer\', full_name=\'caffe.PythonParameter.layer\', index=1,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'param_str\', full_name=\'caffe.PythonParameter.param_str\', index=2,\n      number=3, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'share_in_parallel\', full_name=\'caffe.PythonParameter.share_in_parallel\', index=3,\n      number=4, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=9551,\n  serialized_end=9654,\n)\n\n\n_REDUCTIONPARAMETER = _descriptor.Descriptor(\n  name=\'ReductionParameter\',\n  full_name=\'caffe.ReductionParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'operation\', full_name=\'caffe.ReductionParameter.operation\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.ReductionParameter.axis\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'coeff\', full_name=\'caffe.ReductionParameter.coeff\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _REDUCTIONPARAMETER_REDUCTIONOP,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=9657,\n  serialized_end=9830,\n)\n\n\n_RELUPARAMETER = _descriptor.Descriptor(\n  name=\'ReLUParameter\',\n  full_name=\'caffe.ReLUParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'negative_slope\', full_name=\'caffe.ReLUParameter.negative_slope\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.ReLUParameter.engine\', index=1,\n      number=2, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _RELUPARAMETER_ENGINE,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=9833,\n  serialized_end=9974,\n)\n\n\n_RESHAPEPARAMETER = _descriptor.Descriptor(\n  name=\'ReshapeParameter\',\n  full_name=\'caffe.ReshapeParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'shape\', full_name=\'caffe.ReshapeParameter.shape\', index=0,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.ReshapeParameter.axis\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'num_axes\', full_name=\'caffe.ReshapeParameter.num_axes\', index=2,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=-1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=9976,\n  serialized_end=10066,\n)\n\n\n_SCALEPARAMETER = _descriptor.Descriptor(\n  name=\'ScaleParameter\',\n  full_name=\'caffe.ScaleParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.ScaleParameter.axis\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'num_axes\', full_name=\'caffe.ScaleParameter.num_axes\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'filler\', full_name=\'caffe.ScaleParameter.filler\', index=2,\n      number=3, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_term\', full_name=\'caffe.ScaleParameter.bias_term\', index=3,\n      number=4, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_filler\', full_name=\'caffe.ScaleParameter.bias_filler\', index=4,\n      number=5, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=10069,\n  serialized_end=10234,\n)\n\n\n_SIGMOIDPARAMETER = _descriptor.Descriptor(\n  name=\'SigmoidParameter\',\n  full_name=\'caffe.SigmoidParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.SigmoidParameter.engine\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _SIGMOIDPARAMETER_ENGINE,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=10236,\n  serialized_end=10356,\n)\n\n\n_SLICEPARAMETER = _descriptor.Descriptor(\n  name=\'SliceParameter\',\n  full_name=\'caffe.SliceParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.SliceParameter.axis\', index=0,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'slice_point\', full_name=\'caffe.SliceParameter.slice_point\', index=1,\n      number=2, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'slice_dim\', full_name=\'caffe.SliceParameter.slice_dim\', index=2,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=10358,\n  serialized_end=10434,\n)\n\n\n_SOFTMAXPARAMETER = _descriptor.Descriptor(\n  name=\'SoftmaxParameter\',\n  full_name=\'caffe.SoftmaxParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.SoftmaxParameter.engine\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.SoftmaxParameter.axis\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _SOFTMAXPARAMETER_ENGINE,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=10437,\n  serialized_end=10574,\n)\n\n\n_TANHPARAMETER = _descriptor.Descriptor(\n  name=\'TanHParameter\',\n  full_name=\'caffe.TanHParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.TanHParameter.engine\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _TANHPARAMETER_ENGINE,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=10576,\n  serialized_end=10690,\n)\n\n\n_TILEPARAMETER = _descriptor.Descriptor(\n  name=\'TileParameter\',\n  full_name=\'caffe.TileParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.TileParameter.axis\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'tiles\', full_name=\'caffe.TileParameter.tiles\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=10692,\n  serialized_end=10739,\n)\n\n\n_THRESHOLDPARAMETER = _descriptor.Descriptor(\n  name=\'ThresholdParameter\',\n  full_name=\'caffe.ThresholdParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'threshold\', full_name=\'caffe.ThresholdParameter.threshold\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=10741,\n  serialized_end=10783,\n)\n\n\n_WINDOWDATAPARAMETER = _descriptor.Descriptor(\n  name=\'WindowDataParameter\',\n  full_name=\'caffe.WindowDataParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'source\', full_name=\'caffe.WindowDataParameter.source\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.WindowDataParameter.scale\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mean_file\', full_name=\'caffe.WindowDataParameter.mean_file\', index=2,\n      number=3, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'batch_size\', full_name=\'caffe.WindowDataParameter.batch_size\', index=3,\n      number=4, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'crop_size\', full_name=\'caffe.WindowDataParameter.crop_size\', index=4,\n      number=5, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mirror\', full_name=\'caffe.WindowDataParameter.mirror\', index=5,\n      number=6, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'fg_threshold\', full_name=\'caffe.WindowDataParameter.fg_threshold\', index=6,\n      number=7, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0.5,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bg_threshold\', full_name=\'caffe.WindowDataParameter.bg_threshold\', index=7,\n      number=8, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0.5,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'fg_fraction\', full_name=\'caffe.WindowDataParameter.fg_fraction\', index=8,\n      number=9, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0.25,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'context_pad\', full_name=\'caffe.WindowDataParameter.context_pad\', index=9,\n      number=10, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'crop_mode\', full_name=\'caffe.WindowDataParameter.crop_mode\', index=10,\n      number=11, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=unicode(""warp"", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'cache_images\', full_name=\'caffe.WindowDataParameter.cache_images\', index=11,\n      number=12, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'root_folder\', full_name=\'caffe.WindowDataParameter.root_folder\', index=12,\n      number=13, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=10786,\n  serialized_end=11107,\n)\n\n\n_SPPPARAMETER = _descriptor.Descriptor(\n  name=\'SPPParameter\',\n  full_name=\'caffe.SPPParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'pyramid_height\', full_name=\'caffe.SPPParameter.pyramid_height\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pool\', full_name=\'caffe.SPPParameter.pool\', index=1,\n      number=2, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.SPPParameter.engine\', index=2,\n      number=6, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _SPPPARAMETER_POOLMETHOD,\n    _SPPPARAMETER_ENGINE,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=11110,\n  serialized_end=11345,\n)\n\n\n_V1LAYERPARAMETER = _descriptor.Descriptor(\n  name=\'V1LayerParameter\',\n  full_name=\'caffe.V1LayerParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'bottom\', full_name=\'caffe.V1LayerParameter.bottom\', index=0,\n      number=2, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'top\', full_name=\'caffe.V1LayerParameter.top\', index=1,\n      number=3, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'caffe.V1LayerParameter.name\', index=2,\n      number=4, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'include\', full_name=\'caffe.V1LayerParameter.include\', index=3,\n      number=32, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'exclude\', full_name=\'caffe.V1LayerParameter.exclude\', index=4,\n      number=33, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'type\', full_name=\'caffe.V1LayerParameter.type\', index=5,\n      number=5, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'blobs\', full_name=\'caffe.V1LayerParameter.blobs\', index=6,\n      number=6, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'param\', full_name=\'caffe.V1LayerParameter.param\', index=7,\n      number=1001, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'blob_share_mode\', full_name=\'caffe.V1LayerParameter.blob_share_mode\', index=8,\n      number=1002, type=14, cpp_type=8, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'blobs_lr\', full_name=\'caffe.V1LayerParameter.blobs_lr\', index=9,\n      number=7, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'weight_decay\', full_name=\'caffe.V1LayerParameter.weight_decay\', index=10,\n      number=8, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'loss_weight\', full_name=\'caffe.V1LayerParameter.loss_weight\', index=11,\n      number=35, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'accuracy_param\', full_name=\'caffe.V1LayerParameter.accuracy_param\', index=12,\n      number=27, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'argmax_param\', full_name=\'caffe.V1LayerParameter.argmax_param\', index=13,\n      number=23, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'concat_param\', full_name=\'caffe.V1LayerParameter.concat_param\', index=14,\n      number=9, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'contrastive_loss_param\', full_name=\'caffe.V1LayerParameter.contrastive_loss_param\', index=15,\n      number=40, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'convolution_param\', full_name=\'caffe.V1LayerParameter.convolution_param\', index=16,\n      number=10, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'data_param\', full_name=\'caffe.V1LayerParameter.data_param\', index=17,\n      number=11, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'dropout_param\', full_name=\'caffe.V1LayerParameter.dropout_param\', index=18,\n      number=12, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'dummy_data_param\', full_name=\'caffe.V1LayerParameter.dummy_data_param\', index=19,\n      number=26, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'eltwise_param\', full_name=\'caffe.V1LayerParameter.eltwise_param\', index=20,\n      number=24, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'exp_param\', full_name=\'caffe.V1LayerParameter.exp_param\', index=21,\n      number=41, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'hdf5_data_param\', full_name=\'caffe.V1LayerParameter.hdf5_data_param\', index=22,\n      number=13, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'hdf5_output_param\', full_name=\'caffe.V1LayerParameter.hdf5_output_param\', index=23,\n      number=14, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'hinge_loss_param\', full_name=\'caffe.V1LayerParameter.hinge_loss_param\', index=24,\n      number=29, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'image_data_param\', full_name=\'caffe.V1LayerParameter.image_data_param\', index=25,\n      number=15, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'infogain_loss_param\', full_name=\'caffe.V1LayerParameter.infogain_loss_param\', index=26,\n      number=16, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'inner_product_param\', full_name=\'caffe.V1LayerParameter.inner_product_param\', index=27,\n      number=17, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'lrn_param\', full_name=\'caffe.V1LayerParameter.lrn_param\', index=28,\n      number=18, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'memory_data_param\', full_name=\'caffe.V1LayerParameter.memory_data_param\', index=29,\n      number=22, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mvn_param\', full_name=\'caffe.V1LayerParameter.mvn_param\', index=30,\n      number=34, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pooling_param\', full_name=\'caffe.V1LayerParameter.pooling_param\', index=31,\n      number=19, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'power_param\', full_name=\'caffe.V1LayerParameter.power_param\', index=32,\n      number=21, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'relu_param\', full_name=\'caffe.V1LayerParameter.relu_param\', index=33,\n      number=30, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'sigmoid_param\', full_name=\'caffe.V1LayerParameter.sigmoid_param\', index=34,\n      number=38, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'softmax_param\', full_name=\'caffe.V1LayerParameter.softmax_param\', index=35,\n      number=39, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'slice_param\', full_name=\'caffe.V1LayerParameter.slice_param\', index=36,\n      number=31, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'tanh_param\', full_name=\'caffe.V1LayerParameter.tanh_param\', index=37,\n      number=37, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'threshold_param\', full_name=\'caffe.V1LayerParameter.threshold_param\', index=38,\n      number=25, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'window_data_param\', full_name=\'caffe.V1LayerParameter.window_data_param\', index=39,\n      number=20, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'transform_param\', full_name=\'caffe.V1LayerParameter.transform_param\', index=40,\n      number=36, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'loss_param\', full_name=\'caffe.V1LayerParameter.loss_param\', index=41,\n      number=42, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'layer\', full_name=\'caffe.V1LayerParameter.layer\', index=42,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _V1LAYERPARAMETER_LAYERTYPE,\n    _V1LAYERPARAMETER_DIMCHECKMODE,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=11348,\n  serialized_end=13876,\n)\n\n\n_V0LAYERPARAMETER = _descriptor.Descriptor(\n  name=\'V0LayerParameter\',\n  full_name=\'caffe.V0LayerParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'caffe.V0LayerParameter.name\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'type\', full_name=\'caffe.V0LayerParameter.type\', index=1,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'num_output\', full_name=\'caffe.V0LayerParameter.num_output\', index=2,\n      number=3, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'biasterm\', full_name=\'caffe.V0LayerParameter.biasterm\', index=3,\n      number=4, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'weight_filler\', full_name=\'caffe.V0LayerParameter.weight_filler\', index=4,\n      number=5, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_filler\', full_name=\'caffe.V0LayerParameter.bias_filler\', index=5,\n      number=6, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pad\', full_name=\'caffe.V0LayerParameter.pad\', index=6,\n      number=7, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'kernelsize\', full_name=\'caffe.V0LayerParameter.kernelsize\', index=7,\n      number=8, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'group\', full_name=\'caffe.V0LayerParameter.group\', index=8,\n      number=9, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stride\', full_name=\'caffe.V0LayerParameter.stride\', index=9,\n      number=10, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pool\', full_name=\'caffe.V0LayerParameter.pool\', index=10,\n      number=11, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'dropout_ratio\', full_name=\'caffe.V0LayerParameter.dropout_ratio\', index=11,\n      number=12, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0.5,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'local_size\', full_name=\'caffe.V0LayerParameter.local_size\', index=12,\n      number=13, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=5,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'alpha\', full_name=\'caffe.V0LayerParameter.alpha\', index=13,\n      number=14, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'beta\', full_name=\'caffe.V0LayerParameter.beta\', index=14,\n      number=15, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0.75,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'k\', full_name=\'caffe.V0LayerParameter.k\', index=15,\n      number=22, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'source\', full_name=\'caffe.V0LayerParameter.source\', index=16,\n      number=16, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.V0LayerParameter.scale\', index=17,\n      number=17, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'meanfile\', full_name=\'caffe.V0LayerParameter.meanfile\', index=18,\n      number=18, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=unicode("""", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'batchsize\', full_name=\'caffe.V0LayerParameter.batchsize\', index=19,\n      number=19, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'cropsize\', full_name=\'caffe.V0LayerParameter.cropsize\', index=20,\n      number=20, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mirror\', full_name=\'caffe.V0LayerParameter.mirror\', index=21,\n      number=21, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'blobs\', full_name=\'caffe.V0LayerParameter.blobs\', index=22,\n      number=50, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'blobs_lr\', full_name=\'caffe.V0LayerParameter.blobs_lr\', index=23,\n      number=51, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'weight_decay\', full_name=\'caffe.V0LayerParameter.weight_decay\', index=24,\n      number=52, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'rand_skip\', full_name=\'caffe.V0LayerParameter.rand_skip\', index=25,\n      number=53, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'det_fg_threshold\', full_name=\'caffe.V0LayerParameter.det_fg_threshold\', index=26,\n      number=54, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0.5,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'det_bg_threshold\', full_name=\'caffe.V0LayerParameter.det_bg_threshold\', index=27,\n      number=55, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0.5,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'det_fg_fraction\', full_name=\'caffe.V0LayerParameter.det_fg_fraction\', index=28,\n      number=56, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=0.25,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'det_context_pad\', full_name=\'caffe.V0LayerParameter.det_context_pad\', index=29,\n      number=58, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'det_crop_mode\', full_name=\'caffe.V0LayerParameter.det_crop_mode\', index=30,\n      number=59, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=unicode(""warp"", ""utf-8""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'new_num\', full_name=\'caffe.V0LayerParameter.new_num\', index=31,\n      number=60, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'new_channels\', full_name=\'caffe.V0LayerParameter.new_channels\', index=32,\n      number=61, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'new_height\', full_name=\'caffe.V0LayerParameter.new_height\', index=33,\n      number=62, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'new_width\', full_name=\'caffe.V0LayerParameter.new_width\', index=34,\n      number=63, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'shuffle_images\', full_name=\'caffe.V0LayerParameter.shuffle_images\', index=35,\n      number=64, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'concat_dim\', full_name=\'caffe.V0LayerParameter.concat_dim\', index=36,\n      number=65, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'hdf5_output_param\', full_name=\'caffe.V0LayerParameter.hdf5_output_param\', index=37,\n      number=1001, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _V0LAYERPARAMETER_POOLMETHOD,\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=13879,\n  serialized_end=14900,\n)\n\n\n_PRELUPARAMETER = _descriptor.Descriptor(\n  name=\'PReLUParameter\',\n  full_name=\'caffe.PReLUParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'filler\', full_name=\'caffe.PReLUParameter.filler\', index=0,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'channel_shared\', full_name=\'caffe.PReLUParameter.channel_shared\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  extension_ranges=[],\n  serialized_start=14902,\n  serialized_end=14989,\n)\n\n_BLOBPROTO.fields_by_name[\'shape\'].message_type = _BLOBSHAPE\n_BLOBPROTOVECTOR.fields_by_name[\'blobs\'].message_type = _BLOBPROTO\n_FILLERPARAMETER.fields_by_name[\'variance_norm\'].enum_type = _FILLERPARAMETER_VARIANCENORM\n_FILLERPARAMETER_VARIANCENORM.containing_type = _FILLERPARAMETER;\n_NETPARAMETER.fields_by_name[\'input_shape\'].message_type = _BLOBSHAPE\n_NETPARAMETER.fields_by_name[\'state\'].message_type = _NETSTATE\n_NETPARAMETER.fields_by_name[\'layer\'].message_type = _LAYERPARAMETER\n_NETPARAMETER.fields_by_name[\'layers\'].message_type = _V1LAYERPARAMETER\n_SOLVERPARAMETER.fields_by_name[\'net_param\'].message_type = _NETPARAMETER\n_SOLVERPARAMETER.fields_by_name[\'train_net_param\'].message_type = _NETPARAMETER\n_SOLVERPARAMETER.fields_by_name[\'test_net_param\'].message_type = _NETPARAMETER\n_SOLVERPARAMETER.fields_by_name[\'train_state\'].message_type = _NETSTATE\n_SOLVERPARAMETER.fields_by_name[\'test_state\'].message_type = _NETSTATE\n_SOLVERPARAMETER.fields_by_name[\'snapshot_format\'].enum_type = _SOLVERPARAMETER_SNAPSHOTFORMAT\n_SOLVERPARAMETER.fields_by_name[\'solver_mode\'].enum_type = _SOLVERPARAMETER_SOLVERMODE\n_SOLVERPARAMETER.fields_by_name[\'solver_type\'].enum_type = _SOLVERPARAMETER_SOLVERTYPE\n_SOLVERPARAMETER_SNAPSHOTFORMAT.containing_type = _SOLVERPARAMETER;\n_SOLVERPARAMETER_SOLVERMODE.containing_type = _SOLVERPARAMETER;\n_SOLVERPARAMETER_SOLVERTYPE.containing_type = _SOLVERPARAMETER;\n_SOLVERSTATE.fields_by_name[\'history\'].message_type = _BLOBPROTO\n_NETSTATE.fields_by_name[\'phase\'].enum_type = _PHASE\n_NETSTATERULE.fields_by_name[\'phase\'].enum_type = _PHASE\n_PARAMSPEC.fields_by_name[\'share_mode\'].enum_type = _PARAMSPEC_DIMCHECKMODE\n_PARAMSPEC_DIMCHECKMODE.containing_type = _PARAMSPEC;\n_LAYERPARAMETER.fields_by_name[\'phase\'].enum_type = _PHASE\n_LAYERPARAMETER.fields_by_name[\'param\'].message_type = _PARAMSPEC\n_LAYERPARAMETER.fields_by_name[\'blobs\'].message_type = _BLOBPROTO\n_LAYERPARAMETER.fields_by_name[\'include\'].message_type = _NETSTATERULE\n_LAYERPARAMETER.fields_by_name[\'exclude\'].message_type = _NETSTATERULE\n_LAYERPARAMETER.fields_by_name[\'transform_param\'].message_type = _TRANSFORMATIONPARAMETER\n_LAYERPARAMETER.fields_by_name[\'loss_param\'].message_type = _LOSSPARAMETER\n_LAYERPARAMETER.fields_by_name[\'accuracy_param\'].message_type = _ACCURACYPARAMETER\n_LAYERPARAMETER.fields_by_name[\'argmax_param\'].message_type = _ARGMAXPARAMETER\n_LAYERPARAMETER.fields_by_name[\'batch_norm_param\'].message_type = _BATCHNORMPARAMETER\n_LAYERPARAMETER.fields_by_name[\'bias_param\'].message_type = _BIASPARAMETER\n_LAYERPARAMETER.fields_by_name[\'concat_param\'].message_type = _CONCATPARAMETER\n_LAYERPARAMETER.fields_by_name[\'contrastive_loss_param\'].message_type = _CONTRASTIVELOSSPARAMETER\n_LAYERPARAMETER.fields_by_name[\'convolution_param\'].message_type = _CONVOLUTIONPARAMETER\n_LAYERPARAMETER.fields_by_name[\'crop_param\'].message_type = _CROPPARAMETER\n_LAYERPARAMETER.fields_by_name[\'data_param\'].message_type = _DATAPARAMETER\n_LAYERPARAMETER.fields_by_name[\'dropout_param\'].message_type = _DROPOUTPARAMETER\n_LAYERPARAMETER.fields_by_name[\'dummy_data_param\'].message_type = _DUMMYDATAPARAMETER\n_LAYERPARAMETER.fields_by_name[\'eltwise_param\'].message_type = _ELTWISEPARAMETER\n_LAYERPARAMETER.fields_by_name[\'elu_param\'].message_type = _ELUPARAMETER\n_LAYERPARAMETER.fields_by_name[\'embed_param\'].message_type = _EMBEDPARAMETER\n_LAYERPARAMETER.fields_by_name[\'exp_param\'].message_type = _EXPPARAMETER\n_LAYERPARAMETER.fields_by_name[\'flatten_param\'].message_type = _FLATTENPARAMETER\n_LAYERPARAMETER.fields_by_name[\'hdf5_data_param\'].message_type = _HDF5DATAPARAMETER\n_LAYERPARAMETER.fields_by_name[\'hdf5_output_param\'].message_type = _HDF5OUTPUTPARAMETER\n_LAYERPARAMETER.fields_by_name[\'hinge_loss_param\'].message_type = _HINGELOSSPARAMETER\n_LAYERPARAMETER.fields_by_name[\'image_data_param\'].message_type = _IMAGEDATAPARAMETER\n_LAYERPARAMETER.fields_by_name[\'infogain_loss_param\'].message_type = _INFOGAINLOSSPARAMETER\n_LAYERPARAMETER.fields_by_name[\'inner_product_param\'].message_type = _INNERPRODUCTPARAMETER\n_LAYERPARAMETER.fields_by_name[\'input_param\'].message_type = _INPUTPARAMETER\n_LAYERPARAMETER.fields_by_name[\'log_param\'].message_type = _LOGPARAMETER\n_LAYERPARAMETER.fields_by_name[\'lrn_param\'].message_type = _LRNPARAMETER\n_LAYERPARAMETER.fields_by_name[\'memory_data_param\'].message_type = _MEMORYDATAPARAMETER\n_LAYERPARAMETER.fields_by_name[\'mvn_param\'].message_type = _MVNPARAMETER\n_LAYERPARAMETER.fields_by_name[\'pooling_param\'].message_type = _POOLINGPARAMETER\n_LAYERPARAMETER.fields_by_name[\'power_param\'].message_type = _POWERPARAMETER\n_LAYERPARAMETER.fields_by_name[\'prelu_param\'].message_type = _PRELUPARAMETER\n_LAYERPARAMETER.fields_by_name[\'python_param\'].message_type = _PYTHONPARAMETER\n_LAYERPARAMETER.fields_by_name[\'reduction_param\'].message_type = _REDUCTIONPARAMETER\n_LAYERPARAMETER.fields_by_name[\'relu_param\'].message_type = _RELUPARAMETER\n_LAYERPARAMETER.fields_by_name[\'reshape_param\'].message_type = _RESHAPEPARAMETER\n_LAYERPARAMETER.fields_by_name[\'scale_param\'].message_type = _SCALEPARAMETER\n_LAYERPARAMETER.fields_by_name[\'sigmoid_param\'].message_type = _SIGMOIDPARAMETER\n_LAYERPARAMETER.fields_by_name[\'softmax_param\'].message_type = _SOFTMAXPARAMETER\n_LAYERPARAMETER.fields_by_name[\'spp_param\'].message_type = _SPPPARAMETER\n_LAYERPARAMETER.fields_by_name[\'slice_param\'].message_type = _SLICEPARAMETER\n_LAYERPARAMETER.fields_by_name[\'tanh_param\'].message_type = _TANHPARAMETER\n_LAYERPARAMETER.fields_by_name[\'threshold_param\'].message_type = _THRESHOLDPARAMETER\n_LAYERPARAMETER.fields_by_name[\'tile_param\'].message_type = _TILEPARAMETER\n_LAYERPARAMETER.fields_by_name[\'window_data_param\'].message_type = _WINDOWDATAPARAMETER\n_LOSSPARAMETER.fields_by_name[\'normalization\'].enum_type = _LOSSPARAMETER_NORMALIZATIONMODE\n_LOSSPARAMETER_NORMALIZATIONMODE.containing_type = _LOSSPARAMETER;\n_BIASPARAMETER.fields_by_name[\'filler\'].message_type = _FILLERPARAMETER\n_CONVOLUTIONPARAMETER.fields_by_name[\'weight_filler\'].message_type = _FILLERPARAMETER\n_CONVOLUTIONPARAMETER.fields_by_name[\'bias_filler\'].message_type = _FILLERPARAMETER\n_CONVOLUTIONPARAMETER.fields_by_name[\'engine\'].enum_type = _CONVOLUTIONPARAMETER_ENGINE\n_CONVOLUTIONPARAMETER_ENGINE.containing_type = _CONVOLUTIONPARAMETER;\n_DATAPARAMETER.fields_by_name[\'backend\'].enum_type = _DATAPARAMETER_DB\n_DATAPARAMETER_DB.containing_type = _DATAPARAMETER;\n_DUMMYDATAPARAMETER.fields_by_name[\'data_filler\'].message_type = _FILLERPARAMETER\n_DUMMYDATAPARAMETER.fields_by_name[\'shape\'].message_type = _BLOBSHAPE\n_ELTWISEPARAMETER.fields_by_name[\'operation\'].enum_type = _ELTWISEPARAMETER_ELTWISEOP\n_ELTWISEPARAMETER_ELTWISEOP.containing_type = _ELTWISEPARAMETER;\n_EMBEDPARAMETER.fields_by_name[\'weight_filler\'].message_type = _FILLERPARAMETER\n_EMBEDPARAMETER.fields_by_name[\'bias_filler\'].message_type = _FILLERPARAMETER\n_HINGELOSSPARAMETER.fields_by_name[\'norm\'].enum_type = _HINGELOSSPARAMETER_NORM\n_HINGELOSSPARAMETER_NORM.containing_type = _HINGELOSSPARAMETER;\n_INNERPRODUCTPARAMETER.fields_by_name[\'weight_filler\'].message_type = _FILLERPARAMETER\n_INNERPRODUCTPARAMETER.fields_by_name[\'bias_filler\'].message_type = _FILLERPARAMETER\n_INPUTPARAMETER.fields_by_name[\'shape\'].message_type = _BLOBSHAPE\n_LRNPARAMETER.fields_by_name[\'norm_region\'].enum_type = _LRNPARAMETER_NORMREGION\n_LRNPARAMETER.fields_by_name[\'engine\'].enum_type = _LRNPARAMETER_ENGINE\n_LRNPARAMETER_NORMREGION.containing_type = _LRNPARAMETER;\n_LRNPARAMETER_ENGINE.containing_type = _LRNPARAMETER;\n_POOLINGPARAMETER.fields_by_name[\'pool\'].enum_type = _POOLINGPARAMETER_POOLMETHOD\n_POOLINGPARAMETER.fields_by_name[\'engine\'].enum_type = _POOLINGPARAMETER_ENGINE\n_POOLINGPARAMETER_POOLMETHOD.containing_type = _POOLINGPARAMETER;\n_POOLINGPARAMETER_ENGINE.containing_type = _POOLINGPARAMETER;\n_REDUCTIONPARAMETER.fields_by_name[\'operation\'].enum_type = _REDUCTIONPARAMETER_REDUCTIONOP\n_REDUCTIONPARAMETER_REDUCTIONOP.containing_type = _REDUCTIONPARAMETER;\n_RELUPARAMETER.fields_by_name[\'engine\'].enum_type = _RELUPARAMETER_ENGINE\n_RELUPARAMETER_ENGINE.containing_type = _RELUPARAMETER;\n_RESHAPEPARAMETER.fields_by_name[\'shape\'].message_type = _BLOBSHAPE\n_SCALEPARAMETER.fields_by_name[\'filler\'].message_type = _FILLERPARAMETER\n_SCALEPARAMETER.fields_by_name[\'bias_filler\'].message_type = _FILLERPARAMETER\n_SIGMOIDPARAMETER.fields_by_name[\'engine\'].enum_type = _SIGMOIDPARAMETER_ENGINE\n_SIGMOIDPARAMETER_ENGINE.containing_type = _SIGMOIDPARAMETER;\n_SOFTMAXPARAMETER.fields_by_name[\'engine\'].enum_type = _SOFTMAXPARAMETER_ENGINE\n_SOFTMAXPARAMETER_ENGINE.containing_type = _SOFTMAXPARAMETER;\n_TANHPARAMETER.fields_by_name[\'engine\'].enum_type = _TANHPARAMETER_ENGINE\n_TANHPARAMETER_ENGINE.containing_type = _TANHPARAMETER;\n_SPPPARAMETER.fields_by_name[\'pool\'].enum_type = _SPPPARAMETER_POOLMETHOD\n_SPPPARAMETER.fields_by_name[\'engine\'].enum_type = _SPPPARAMETER_ENGINE\n_SPPPARAMETER_POOLMETHOD.containing_type = _SPPPARAMETER;\n_SPPPARAMETER_ENGINE.containing_type = _SPPPARAMETER;\n_V1LAYERPARAMETER.fields_by_name[\'include\'].message_type = _NETSTATERULE\n_V1LAYERPARAMETER.fields_by_name[\'exclude\'].message_type = _NETSTATERULE\n_V1LAYERPARAMETER.fields_by_name[\'type\'].enum_type = _V1LAYERPARAMETER_LAYERTYPE\n_V1LAYERPARAMETER.fields_by_name[\'blobs\'].message_type = _BLOBPROTO\n_V1LAYERPARAMETER.fields_by_name[\'blob_share_mode\'].enum_type = _V1LAYERPARAMETER_DIMCHECKMODE\n_V1LAYERPARAMETER.fields_by_name[\'accuracy_param\'].message_type = _ACCURACYPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'argmax_param\'].message_type = _ARGMAXPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'concat_param\'].message_type = _CONCATPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'contrastive_loss_param\'].message_type = _CONTRASTIVELOSSPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'convolution_param\'].message_type = _CONVOLUTIONPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'data_param\'].message_type = _DATAPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'dropout_param\'].message_type = _DROPOUTPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'dummy_data_param\'].message_type = _DUMMYDATAPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'eltwise_param\'].message_type = _ELTWISEPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'exp_param\'].message_type = _EXPPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'hdf5_data_param\'].message_type = _HDF5DATAPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'hdf5_output_param\'].message_type = _HDF5OUTPUTPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'hinge_loss_param\'].message_type = _HINGELOSSPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'image_data_param\'].message_type = _IMAGEDATAPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'infogain_loss_param\'].message_type = _INFOGAINLOSSPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'inner_product_param\'].message_type = _INNERPRODUCTPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'lrn_param\'].message_type = _LRNPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'memory_data_param\'].message_type = _MEMORYDATAPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'mvn_param\'].message_type = _MVNPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'pooling_param\'].message_type = _POOLINGPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'power_param\'].message_type = _POWERPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'relu_param\'].message_type = _RELUPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'sigmoid_param\'].message_type = _SIGMOIDPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'softmax_param\'].message_type = _SOFTMAXPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'slice_param\'].message_type = _SLICEPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'tanh_param\'].message_type = _TANHPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'threshold_param\'].message_type = _THRESHOLDPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'window_data_param\'].message_type = _WINDOWDATAPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'transform_param\'].message_type = _TRANSFORMATIONPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'loss_param\'].message_type = _LOSSPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'layer\'].message_type = _V0LAYERPARAMETER\n_V1LAYERPARAMETER_LAYERTYPE.containing_type = _V1LAYERPARAMETER;\n_V1LAYERPARAMETER_DIMCHECKMODE.containing_type = _V1LAYERPARAMETER;\n_V0LAYERPARAMETER.fields_by_name[\'weight_filler\'].message_type = _FILLERPARAMETER\n_V0LAYERPARAMETER.fields_by_name[\'bias_filler\'].message_type = _FILLERPARAMETER\n_V0LAYERPARAMETER.fields_by_name[\'pool\'].enum_type = _V0LAYERPARAMETER_POOLMETHOD\n_V0LAYERPARAMETER.fields_by_name[\'blobs\'].message_type = _BLOBPROTO\n_V0LAYERPARAMETER.fields_by_name[\'hdf5_output_param\'].message_type = _HDF5OUTPUTPARAMETER\n_V0LAYERPARAMETER_POOLMETHOD.containing_type = _V0LAYERPARAMETER;\n_PRELUPARAMETER.fields_by_name[\'filler\'].message_type = _FILLERPARAMETER\nDESCRIPTOR.message_types_by_name[\'BlobShape\'] = _BLOBSHAPE\nDESCRIPTOR.message_types_by_name[\'BlobProto\'] = _BLOBPROTO\nDESCRIPTOR.message_types_by_name[\'BlobProtoVector\'] = _BLOBPROTOVECTOR\nDESCRIPTOR.message_types_by_name[\'Datum\'] = _DATUM\nDESCRIPTOR.message_types_by_name[\'FillerParameter\'] = _FILLERPARAMETER\nDESCRIPTOR.message_types_by_name[\'NetParameter\'] = _NETPARAMETER\nDESCRIPTOR.message_types_by_name[\'SolverParameter\'] = _SOLVERPARAMETER\nDESCRIPTOR.message_types_by_name[\'SolverState\'] = _SOLVERSTATE\nDESCRIPTOR.message_types_by_name[\'NetState\'] = _NETSTATE\nDESCRIPTOR.message_types_by_name[\'NetStateRule\'] = _NETSTATERULE\nDESCRIPTOR.message_types_by_name[\'ParamSpec\'] = _PARAMSPEC\nDESCRIPTOR.message_types_by_name[\'LayerParameter\'] = _LAYERPARAMETER\nDESCRIPTOR.message_types_by_name[\'TransformationParameter\'] = _TRANSFORMATIONPARAMETER\nDESCRIPTOR.message_types_by_name[\'LossParameter\'] = _LOSSPARAMETER\nDESCRIPTOR.message_types_by_name[\'AccuracyParameter\'] = _ACCURACYPARAMETER\nDESCRIPTOR.message_types_by_name[\'ArgMaxParameter\'] = _ARGMAXPARAMETER\nDESCRIPTOR.message_types_by_name[\'ConcatParameter\'] = _CONCATPARAMETER\nDESCRIPTOR.message_types_by_name[\'BatchNormParameter\'] = _BATCHNORMPARAMETER\nDESCRIPTOR.message_types_by_name[\'BiasParameter\'] = _BIASPARAMETER\nDESCRIPTOR.message_types_by_name[\'ContrastiveLossParameter\'] = _CONTRASTIVELOSSPARAMETER\nDESCRIPTOR.message_types_by_name[\'ConvolutionParameter\'] = _CONVOLUTIONPARAMETER\nDESCRIPTOR.message_types_by_name[\'CropParameter\'] = _CROPPARAMETER\nDESCRIPTOR.message_types_by_name[\'DataParameter\'] = _DATAPARAMETER\nDESCRIPTOR.message_types_by_name[\'DropoutParameter\'] = _DROPOUTPARAMETER\nDESCRIPTOR.message_types_by_name[\'DummyDataParameter\'] = _DUMMYDATAPARAMETER\nDESCRIPTOR.message_types_by_name[\'EltwiseParameter\'] = _ELTWISEPARAMETER\nDESCRIPTOR.message_types_by_name[\'ELUParameter\'] = _ELUPARAMETER\nDESCRIPTOR.message_types_by_name[\'EmbedParameter\'] = _EMBEDPARAMETER\nDESCRIPTOR.message_types_by_name[\'ExpParameter\'] = _EXPPARAMETER\nDESCRIPTOR.message_types_by_name[\'FlattenParameter\'] = _FLATTENPARAMETER\nDESCRIPTOR.message_types_by_name[\'HDF5DataParameter\'] = _HDF5DATAPARAMETER\nDESCRIPTOR.message_types_by_name[\'HDF5OutputParameter\'] = _HDF5OUTPUTPARAMETER\nDESCRIPTOR.message_types_by_name[\'HingeLossParameter\'] = _HINGELOSSPARAMETER\nDESCRIPTOR.message_types_by_name[\'ImageDataParameter\'] = _IMAGEDATAPARAMETER\nDESCRIPTOR.message_types_by_name[\'InfogainLossParameter\'] = _INFOGAINLOSSPARAMETER\nDESCRIPTOR.message_types_by_name[\'InnerProductParameter\'] = _INNERPRODUCTPARAMETER\nDESCRIPTOR.message_types_by_name[\'InputParameter\'] = _INPUTPARAMETER\nDESCRIPTOR.message_types_by_name[\'LogParameter\'] = _LOGPARAMETER\nDESCRIPTOR.message_types_by_name[\'LRNParameter\'] = _LRNPARAMETER\nDESCRIPTOR.message_types_by_name[\'MemoryDataParameter\'] = _MEMORYDATAPARAMETER\nDESCRIPTOR.message_types_by_name[\'MVNParameter\'] = _MVNPARAMETER\nDESCRIPTOR.message_types_by_name[\'PoolingParameter\'] = _POOLINGPARAMETER\nDESCRIPTOR.message_types_by_name[\'PowerParameter\'] = _POWERPARAMETER\nDESCRIPTOR.message_types_by_name[\'PythonParameter\'] = _PYTHONPARAMETER\nDESCRIPTOR.message_types_by_name[\'ReductionParameter\'] = _REDUCTIONPARAMETER\nDESCRIPTOR.message_types_by_name[\'ReLUParameter\'] = _RELUPARAMETER\nDESCRIPTOR.message_types_by_name[\'ReshapeParameter\'] = _RESHAPEPARAMETER\nDESCRIPTOR.message_types_by_name[\'ScaleParameter\'] = _SCALEPARAMETER\nDESCRIPTOR.message_types_by_name[\'SigmoidParameter\'] = _SIGMOIDPARAMETER\nDESCRIPTOR.message_types_by_name[\'SliceParameter\'] = _SLICEPARAMETER\nDESCRIPTOR.message_types_by_name[\'SoftmaxParameter\'] = _SOFTMAXPARAMETER\nDESCRIPTOR.message_types_by_name[\'TanHParameter\'] = _TANHPARAMETER\nDESCRIPTOR.message_types_by_name[\'TileParameter\'] = _TILEPARAMETER\nDESCRIPTOR.message_types_by_name[\'ThresholdParameter\'] = _THRESHOLDPARAMETER\nDESCRIPTOR.message_types_by_name[\'WindowDataParameter\'] = _WINDOWDATAPARAMETER\nDESCRIPTOR.message_types_by_name[\'SPPParameter\'] = _SPPPARAMETER\nDESCRIPTOR.message_types_by_name[\'V1LayerParameter\'] = _V1LAYERPARAMETER\nDESCRIPTOR.message_types_by_name[\'V0LayerParameter\'] = _V0LAYERPARAMETER\nDESCRIPTOR.message_types_by_name[\'PReLUParameter\'] = _PRELUPARAMETER\n\nclass BlobShape(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _BLOBSHAPE\n\n  # @@protoc_insertion_point(class_scope:caffe.BlobShape)\n\nclass BlobProto(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _BLOBPROTO\n\n  # @@protoc_insertion_point(class_scope:caffe.BlobProto)\n\nclass BlobProtoVector(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _BLOBPROTOVECTOR\n\n  # @@protoc_insertion_point(class_scope:caffe.BlobProtoVector)\n\nclass Datum(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _DATUM\n\n  # @@protoc_insertion_point(class_scope:caffe.Datum)\n\nclass FillerParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _FILLERPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.FillerParameter)\n\nclass NetParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _NETPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.NetParameter)\n\nclass SolverParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _SOLVERPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.SolverParameter)\n\nclass SolverState(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _SOLVERSTATE\n\n  # @@protoc_insertion_point(class_scope:caffe.SolverState)\n\nclass NetState(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _NETSTATE\n\n  # @@protoc_insertion_point(class_scope:caffe.NetState)\n\nclass NetStateRule(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _NETSTATERULE\n\n  # @@protoc_insertion_point(class_scope:caffe.NetStateRule)\n\nclass ParamSpec(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _PARAMSPEC\n\n  # @@protoc_insertion_point(class_scope:caffe.ParamSpec)\n\nclass LayerParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _LAYERPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.LayerParameter)\n\nclass TransformationParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _TRANSFORMATIONPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.TransformationParameter)\n\nclass LossParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _LOSSPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.LossParameter)\n\nclass AccuracyParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _ACCURACYPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.AccuracyParameter)\n\nclass ArgMaxParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _ARGMAXPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.ArgMaxParameter)\n\nclass ConcatParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _CONCATPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.ConcatParameter)\n\nclass BatchNormParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _BATCHNORMPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.BatchNormParameter)\n\nclass BiasParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _BIASPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.BiasParameter)\n\nclass ContrastiveLossParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _CONTRASTIVELOSSPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.ContrastiveLossParameter)\n\nclass ConvolutionParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _CONVOLUTIONPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.ConvolutionParameter)\n\nclass CropParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _CROPPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.CropParameter)\n\nclass DataParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _DATAPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.DataParameter)\n\nclass DropoutParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _DROPOUTPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.DropoutParameter)\n\nclass DummyDataParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _DUMMYDATAPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.DummyDataParameter)\n\nclass EltwiseParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _ELTWISEPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.EltwiseParameter)\n\nclass ELUParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _ELUPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.ELUParameter)\n\nclass EmbedParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _EMBEDPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.EmbedParameter)\n\nclass ExpParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _EXPPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.ExpParameter)\n\nclass FlattenParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _FLATTENPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.FlattenParameter)\n\nclass HDF5DataParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _HDF5DATAPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.HDF5DataParameter)\n\nclass HDF5OutputParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _HDF5OUTPUTPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.HDF5OutputParameter)\n\nclass HingeLossParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _HINGELOSSPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.HingeLossParameter)\n\nclass ImageDataParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _IMAGEDATAPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.ImageDataParameter)\n\nclass InfogainLossParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _INFOGAINLOSSPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.InfogainLossParameter)\n\nclass InnerProductParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _INNERPRODUCTPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.InnerProductParameter)\n\nclass InputParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _INPUTPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.InputParameter)\n\nclass LogParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _LOGPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.LogParameter)\n\nclass LRNParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _LRNPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.LRNParameter)\n\nclass MemoryDataParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _MEMORYDATAPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.MemoryDataParameter)\n\nclass MVNParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _MVNPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.MVNParameter)\n\nclass PoolingParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _POOLINGPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.PoolingParameter)\n\nclass PowerParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _POWERPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.PowerParameter)\n\nclass PythonParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _PYTHONPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.PythonParameter)\n\nclass ReductionParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _REDUCTIONPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.ReductionParameter)\n\nclass ReLUParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _RELUPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.ReLUParameter)\n\nclass ReshapeParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _RESHAPEPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.ReshapeParameter)\n\nclass ScaleParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _SCALEPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.ScaleParameter)\n\nclass SigmoidParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _SIGMOIDPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.SigmoidParameter)\n\nclass SliceParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _SLICEPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.SliceParameter)\n\nclass SoftmaxParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _SOFTMAXPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.SoftmaxParameter)\n\nclass TanHParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _TANHPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.TanHParameter)\n\nclass TileParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _TILEPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.TileParameter)\n\nclass ThresholdParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _THRESHOLDPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.ThresholdParameter)\n\nclass WindowDataParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _WINDOWDATAPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.WindowDataParameter)\n\nclass SPPParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _SPPPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.SPPParameter)\n\nclass V1LayerParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _V1LAYERPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.V1LayerParameter)\n\nclass V0LayerParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _V0LAYERPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.V0LayerParameter)\n\nclass PReLUParameter(_message.Message):\n  __metaclass__ = _reflection.GeneratedProtocolMessageType\n  DESCRIPTOR = _PRELUPARAMETER\n\n  # @@protoc_insertion_point(class_scope:caffe.PReLUParameter)\n\n\n_BLOBSHAPE.fields_by_name[\'dim\'].has_options = True\n_BLOBSHAPE.fields_by_name[\'dim\']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), \'\\020\\001\')\n_BLOBPROTO.fields_by_name[\'data\'].has_options = True\n_BLOBPROTO.fields_by_name[\'data\']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), \'\\020\\001\')\n_BLOBPROTO.fields_by_name[\'diff\'].has_options = True\n_BLOBPROTO.fields_by_name[\'diff\']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), \'\\020\\001\')\n_BLOBPROTO.fields_by_name[\'double_data\'].has_options = True\n_BLOBPROTO.fields_by_name[\'double_data\']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), \'\\020\\001\')\n_BLOBPROTO.fields_by_name[\'double_diff\'].has_options = True\n_BLOBPROTO.fields_by_name[\'double_diff\']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), \'\\020\\001\')\n# @@protoc_insertion_point(module_scope)\n'"
code/kaffe/caffe/resolver.py,0,"b""import sys\n\nSHARED_CAFFE_RESOLVER = None\n\nclass CaffeResolver(object):\n    def __init__(self):\n        self.import_caffe()\n\n    def import_caffe(self):\n        self.caffe = None\n        try:\n            # Try to import PyCaffe first\n            import caffe\n            self.caffe = caffe\n        except ImportError:\n            # Fall back to the protobuf implementation\n            from . import caffepb\n            self.caffepb = caffepb\n            show_fallback_warning()\n        if self.caffe:\n            # Use the protobuf code from the imported distribution.\n            # This way, Caffe variants with custom layers will work.\n            self.caffepb = self.caffe.proto.caffe_pb2\n        self.NetParameter = self.caffepb.NetParameter\n\n    def has_pycaffe(self):\n        return self.caffe is not None\n\ndef get_caffe_resolver():\n    global SHARED_CAFFE_RESOLVER\n    if SHARED_CAFFE_RESOLVER is None:\n        SHARED_CAFFE_RESOLVER = CaffeResolver()\n    return SHARED_CAFFE_RESOLVER\n\ndef has_pycaffe():\n    return get_caffe_resolver().has_pycaffe()\n\ndef show_fallback_warning():\n    msg = '''\n------------------------------------------------------------\n    WARNING: PyCaffe not found!\n    Falling back to a pure protocol buffer implementation.\n    * Conversions will be drastically slower.\n    * This backend is UNTESTED!\n------------------------------------------------------------\n\n'''\n    sys.stderr.write(msg)\n"""
code/kaffe/tensorflow/__init__.py,0,b'from .transformer import TensorFlowTransformer\nfrom .network import Network\n'
code/kaffe/tensorflow/network.py,36,"b""import numpy as np\nimport tensorflow as tf\nslim = tf.contrib.slim\n\nDEFAULT_PADDING = 'SAME'\n\n\ndef layer(op):\n    '''Decorator for composable network layers.'''\n\n    def layer_decorated(self, *args, **kwargs):\n        # Automatically set a name if not provided.\n        name = kwargs.setdefault('name', self.get_unique_name(op.__name__))\n        # Figure out the layer inputs.\n        if len(self.terminals) == 0:\n            raise RuntimeError('No input variables found for layer %s.' % name)\n        elif len(self.terminals) == 1:\n            layer_input = self.terminals[0]\n        else:\n            layer_input = list(self.terminals)\n        # Perform the operation and get the output.\n        layer_output = op(self, layer_input, *args, **kwargs)\n        # Add to layer LUT.\n        self.layers[name] = layer_output\n        # This output is now the input for the next layer.\n        self.feed(layer_output)\n        # Return self for chained calls.\n        return self\n\n    return layer_decorated\n\n\nclass Network(object):\n\n    def __init__(self, inputs, options, trainable=True, is_training=False):\n        # The input nodes for this network\n        self.inputs = inputs\n        # The current list of terminal nodes\n        self.terminals = []\n        # Mapping from layer names to layers\n        self.layers = dict(inputs)\n        # If true, the resulting variables are set as trainable\n        self.trainable = trainable\n        # Switch variable for dropout\n        \n        # self.use_dropout = tf.placeholder_with_default(tf.constant(1.0),\n        #                                                shape=[],\n        #                                                name='use_dropout')\n\n        self.use_dropout = tf.placeholder_with_default(tf.cast(is_training, tf.float32),\n                                                       shape=[],\n                                                       name='use_dropout')\n        \n        self.setup(is_training, options=options)\n\n    def setup(self, is_training):\n        '''Construct the network. '''\n        raise NotImplementedError('Must be implemented by the subclass.')\n\n    def load(self, data_path, session, ignore_missing=False):\n        '''Load network weights.\n        data_path: The path to the numpy-serialized network weights\n        session: The current TensorFlow session\n        ignore_missing: If true, serialized weights for missing layers are ignored.\n        '''\n        data_dict = np.load(data_path).item()\n        for op_name in data_dict:\n            with tf.variable_scope(op_name, reuse=True):\n                for param_name, data in data_dict[op_name].iteritems():\n                    try:\n                        var = tf.get_variable(param_name)\n                        session.run(var.assign(data))\n                    except ValueError:\n                        if not ignore_missing:\n                            raise\n\n    def feed(self, *args):\n        '''Set the input(s) for the next operation by replacing the terminal nodes.\n        The arguments can be either layer names or the actual layers.\n        '''\n        assert len(args) != 0\n        self.terminals = []\n        for fed_layer in args:\n            if isinstance(fed_layer, basestring):\n                try:\n                    fed_layer = self.layers[fed_layer]\n                except KeyError:\n                    raise KeyError('Unknown layer name fed: %s' % fed_layer)\n            self.terminals.append(fed_layer)\n        return self\n\n    def get_output(self):\n        '''Returns the current network output.'''\n        return self.terminals[-1]\n\n    def get_unique_name(self, prefix):\n        '''Returns an index-suffixed unique name for the given prefix.\n        This is used for auto-generating layer names based on the type-prefix.\n        '''\n        ident = sum(t.startswith(prefix) for t, _ in self.layers.items()) + 1\n        return '%s_%d' % (prefix, ident)\n\n    def make_var(self, name, shape):\n        '''Creates a new TensorFlow variable.'''\n        return tf.get_variable(name, shape, trainable=self.trainable)\n\n    def validate_padding(self, padding):\n        '''Verifies that the padding is one of the supported ones.'''\n        assert padding in ('SAME', 'VALID')\n\n    @layer\n    def conv(self,\n             input,\n             k_h,\n             k_w,\n             c_o,\n             s_h,\n             s_w,\n             name,\n             relu=True,\n             padding=DEFAULT_PADDING,\n             group=1,\n             biased=True):\n        # Verify that the padding is acceptable\n        self.validate_padding(padding)\n        # Get the number of channels in the input\n        c_i = input.get_shape()[-1]\n        # Verify that the grouping parameter is valid\n        assert c_i % group == 0\n        assert c_o % group == 0\n        # Convolution for a given input and kernel\n        convolve = lambda i, k: tf.nn.conv2d(i, k, [1, s_h, s_w, 1], padding=padding)\n        with tf.variable_scope(name) as scope:\n            kernel = self.make_var('weights', shape=[k_h, k_w, c_i / group, c_o])\n            if group == 1:\n                # This is the common-case. Convolve the input without any further complications.\n                output = convolve(input, kernel)\n            else:\n                # Split the input into groups and then convolve each of them independently\n                input_groups = tf.split(3, group, input)\n                kernel_groups = tf.split(3, group, kernel)\n                output_groups = [convolve(i, k) for i, k in zip(input_groups, kernel_groups)]\n                # Concatenate the groups\n                output = tf.concat(3, output_groups)\n            # Add the biases\n            if biased:\n                biases = self.make_var('biases', [c_o])\n                output = tf.nn.bias_add(output, biases)\n            if relu:\n                # ReLU non-linearity\n                output = tf.nn.relu(output, name=scope.name)\n            return output\n\n    @layer\n    def atrous_conv(self,\n                    input,\n                    k_h,\n                    k_w,\n                    c_o,\n                    dilation,\n                    name,\n                    relu=True,\n                    padding=DEFAULT_PADDING,\n                    group=1,\n                    biased=True):\n        # Verify that the padding is acceptable\n        self.validate_padding(padding)\n        # Get the number of channels in the input\n        c_i = input.get_shape()[-1]\n        # Verify that the grouping parameter is valid\n        assert c_i % group == 0\n        assert c_o % group == 0\n        # Convolution for a given input and kernel\n        convolve = lambda i, k: tf.nn.atrous_conv2d(i, k, dilation, padding=padding)\n        with tf.variable_scope(name) as scope:\n            kernel = self.make_var('weights', shape=[k_h, k_w, c_i / group, c_o])\n            if group == 1:\n                # This is the common-case. Convolve the input without any further complications.\n                output = convolve(input, kernel)\n            else:\n                # Split the input into groups and then convolve each of them independently\n                input_groups = tf.split(3, group, input)\n                kernel_groups = tf.split(3, group, kernel)\n                output_groups = [convolve(i, k) for i, k in zip(input_groups, kernel_groups)]\n                # Concatenate the groups\n                output = tf.concat(3, output_groups)\n            # Add the biases\n            if biased:\n                biases = self.make_var('biases', [c_o])\n                output = tf.nn.bias_add(output, biases)\n            if relu:\n                # ReLU non-linearity\n                output = tf.nn.relu(output, name=scope.name)\n            return output\n        \n    @layer\n    def relu(self, input, name):\n        return tf.nn.relu(input, name=name)\n\n    @layer\n    def max_pool(self, input, k_h, k_w, s_h, s_w, name, padding=DEFAULT_PADDING):\n        self.validate_padding(padding)\n        return tf.nn.max_pool(input,\n                              ksize=[1, k_h, k_w, 1],\n                              strides=[1, s_h, s_w, 1],\n                              padding=padding,\n                              name=name)\n\n    @layer\n    def avg_pool(self, input, k_h, k_w, s_h, s_w, name, padding=DEFAULT_PADDING):\n        self.validate_padding(padding)\n        return tf.nn.avg_pool(input,\n                              ksize=[1, k_h, k_w, 1],\n                              strides=[1, s_h, s_w, 1],\n                              padding=padding,\n                              name=name)\n\n    @layer\n    def lrn(self, input, radius, alpha, beta, name, bias=1.0):\n        return tf.nn.local_response_normalization(input,\n                                                  depth_radius=radius,\n                                                  alpha=alpha,\n                                                  beta=beta,\n                                                  bias=bias,\n                                                  name=name)\n\n    @layer\n    def concat(self, inputs, axis, name):\n        return tf.concat(values=inputs, axis=axis, name=name)\n\n    @layer\n    def add(self, inputs, name):\n        return tf.add_n(inputs, name=name)\n\n    @layer\n    def fc(self, input, num_out, name, relu=True):\n        with tf.variable_scope(name) as scope:\n            input_shape = input.get_shape()\n            if input_shape.ndims == 4:\n                # The input is spatial. Vectorize it first.\n                dim = 1\n                for d in input_shape[1:].as_list():\n                    dim *= d\n                feed_in = tf.reshape(input, [-1, dim])\n            else:\n                feed_in, dim = (input, input_shape[-1].value)\n            weights = self.make_var('weights', shape=[dim, num_out])\n            biases = self.make_var('biases', [num_out])\n            op = tf.nn.relu_layer if relu else tf.nn.xw_plus_b\n            fc = op(feed_in, weights, biases, name=scope.name)\n            return fc\n\n    @layer\n    def softmax(self, input, name):\n        input_shape = map(lambda v: v.value, input.get_shape())\n        if len(input_shape) > 2:\n            # For certain models (like NiN), the singleton spatial dimensions\n            # need to be explicitly squeezed, since they're not broadcast-able\n            # in TensorFlow's NHWC ordering (unlike Caffe's NCHW).\n            if input_shape[1] == 1 and input_shape[2] == 1:\n                input = tf.squeeze(input, squeeze_dims=[1, 2])\n            else:\n                raise ValueError('Rank 2 tensor input expected for softmax!')\n        return tf.nn.softmax(input, name)\n        \n    @layer\n    def batch_normalization(self, input, name, is_training, activation_fn=None, scale=True):\n        with tf.variable_scope(name) as scope:\n            output = slim.batch_norm(\n                input,\n                activation_fn=activation_fn,\n                is_training=is_training,\n                updates_collections=None,\n                scale=scale,\n                scope=scope)\n            return output\n\n    @layer\n    def dropout(self, input, keep_prob, name):\n        keep = 1 - self.use_dropout + (self.use_dropout * keep_prob)\n        return tf.nn.dropout(input, keep, name=name)\n\n    @layer\n    def reshape(self, input, shape, name):\n        return tf.reshape(input, shape=shape, name=name)\n    \n\n    @layer\n    def tile(self, input, multiples, name):\n        return tf.tile(input, multiples=multiples, name=name)\n\n    @layer\n    def resize_bilinear(self, input, size, name):\n        return tf.image.resize_bilinear(input, size=size, name=name)\n    \n"""
code/kaffe/tensorflow/transformer.py,0,"b'import numpy as np\n\nfrom ..errors import KaffeError, print_stderr\nfrom ..graph import GraphBuilder, NodeMapper\nfrom ..layers import NodeKind\nfrom ..transformers import (DataInjector, DataReshaper, NodeRenamer, ReLUFuser,\n                            BatchNormScaleBiasFuser, BatchNormPreprocessor, ParameterNamer)\n\nfrom . import network\n\n\ndef get_padding_type(kernel_params, input_shape, output_shape):\n    \'\'\'Translates Caffe\'s numeric padding to one of (\'SAME\', \'VALID\').\n    Caffe supports arbitrary padding values, while TensorFlow only\n    supports \'SAME\' and \'VALID\' modes. So, not all Caffe paddings\n    can be translated to TensorFlow. There are some subtleties to\n    how the padding edge-cases are handled. These are described here:\n    https://github.com/Yangqing/caffe2/blob/master/caffe2/proto/caffe2_legacy.proto\n    \'\'\'\n    k_h, k_w, s_h, s_w, p_h, p_w = kernel_params\n    s_o_h = np.ceil(input_shape.height / float(s_h))\n    s_o_w = np.ceil(input_shape.width / float(s_w))\n    if (output_shape.height == s_o_h) and (output_shape.width == s_o_w):\n        return \'SAME\'\n    v_o_h = np.ceil((input_shape.height - k_h + 1.0) / float(s_h))\n    v_o_w = np.ceil((input_shape.width - k_w + 1.0) / float(s_w))\n    if (output_shape.height == v_o_h) and (output_shape.width == v_o_w):\n        return \'VALID\'\n    return None\n\n\nclass TensorFlowNode(object):\n    \'\'\'An intermediate representation for TensorFlow operations.\'\'\'\n\n    def __init__(self, op, *args, **kwargs):\n        # A string corresponding to the TensorFlow operation\n        self.op = op\n        # Positional arguments for the operation\n        self.args = args\n        # Keyword arguments for the operation\n        self.kwargs = list(kwargs.items())\n        # The source Caffe node\n        self.node = None\n\n    def format(self, arg):\n        \'\'\'Returns a string representation for the given value.\'\'\'\n        return ""\'%s\'"" % arg if isinstance(arg, basestring) else str(arg)\n\n    def pair(self, key, value):\n        \'\'\'Returns key=formatted(value).\'\'\'\n        return \'%s=%s\' % (key, self.format(value))\n\n    def emit(self):\n        \'\'\'Emits the Python source for this node.\'\'\'\n        # Format positional arguments\n        args = map(self.format, self.args)\n        # Format any keyword arguments\n        if self.kwargs:\n            args += [self.pair(k, v) for k, v in self.kwargs]\n        # Set the node name\n        args.append(self.pair(\'name\', self.node.name))\n        args = \', \'.join(args)\n        return \'%s(%s)\' % (self.op, args)\n\n\nclass MaybeActivated(object):\n\n    def __init__(self, node, default=True):\n        self.inject_kwargs = {}\n        if node.metadata.get(\'relu\', False) != default:\n            self.inject_kwargs[\'relu\'] = not default\n\n    def __call__(self, *args, **kwargs):\n        kwargs.update(self.inject_kwargs)\n        return TensorFlowNode(*args, **kwargs)\n\n\nclass TensorFlowMapper(NodeMapper):\n\n    def get_kernel_params(self, node):\n        kernel_params = node.layer.kernel_parameters\n        input_shape = node.get_only_parent().output_shape\n        padding = get_padding_type(kernel_params, input_shape, node.output_shape)\n        # Only emit the padding if it\'s not the default value.\n        padding = {\'padding\': padding} if padding != network.DEFAULT_PADDING else {}\n        return (kernel_params, padding)\n\n    def map_convolution(self, node):\n        (kernel_params, kwargs) = self.get_kernel_params(node)\n        h = kernel_params.kernel_h\n        w = kernel_params.kernel_w\n        c_o = node.output_shape[1]\n        c_i = node.parents[0].output_shape[1]\n        group = node.parameters.group\n        if group != 1:\n            kwargs[\'group\'] = group\n        if not node.parameters.bias_term:\n            kwargs[\'biased\'] = False\n        assert kernel_params.kernel_h == h\n        assert kernel_params.kernel_w == w\n        return MaybeActivated(node)(\'conv\', kernel_params.kernel_h, kernel_params.kernel_w, c_o,\n                                    kernel_params.stride_h, kernel_params.stride_w, **kwargs)\n\n    def map_relu(self, node):\n        return TensorFlowNode(\'relu\')\n\n    def map_pooling(self, node):\n        pool_type = node.parameters.pool\n        if pool_type == 0:\n            pool_op = \'max_pool\'\n        elif pool_type == 1:\n            pool_op = \'avg_pool\'\n        else:\n            # Stochastic pooling, for instance.\n            raise KaffeError(\'Unsupported pooling type.\')\n        (kernel_params, padding) = self.get_kernel_params(node)\n        return TensorFlowNode(pool_op, kernel_params.kernel_h, kernel_params.kernel_w,\n                              kernel_params.stride_h, kernel_params.stride_w, **padding)\n\n    def map_inner_product(self, node):\n        #TODO: Axis\n        assert node.parameters.axis == 1\n        #TODO: Unbiased\n        assert node.parameters.bias_term == True\n        return MaybeActivated(node)(\'fc\', node.parameters.num_output)\n\n    def map_softmax(self, node):\n        return TensorFlowNode(\'softmax\')\n\n    def map_lrn(self, node):\n        params = node.parameters\n        # The window size must be an odd value. For a window\n        # size of (2*n+1), TensorFlow defines depth_radius = n.\n        assert params.local_size % 2 == 1\n        # Caffe scales by (alpha/(2*n+1)), whereas TensorFlow\n        # just scales by alpha (as does Krizhevsky\'s paper).\n        # We\'ll account for that here.\n        alpha = params.alpha / float(params.local_size)\n        return TensorFlowNode(\'lrn\', int(params.local_size / 2), alpha, params.beta)\n\n    def map_concat(self, node):\n        axis = (2, 3, 1, 0)[node.parameters.axis]\n        return TensorFlowNode(\'concat\', axis)\n\n    def map_dropout(self, node):\n        return TensorFlowNode(\'dropout\', node.parameters.dropout_ratio)\n\n    def map_batch_norm(self, node):\n        scale_offset = len(node.data) == 4\n        kwargs = {\'is_training\': True} if scale_offset else {\'is_training\': True, \'scale\': False}\n        return MaybeActivated(node, default=False)(\'batch_normalization\', **kwargs)\n\n    def map_eltwise(self, node):\n        operations = {0: \'multiply\', 1: \'add\', 2: \'max\'}\n        op_code = node.parameters.operation\n        try:\n            return TensorFlowNode(operations[op_code])\n        except KeyError:\n            raise KaffeError(\'Unknown elementwise operation: {}\'.format(op_code))\n\n    def commit(self, chains):\n        return chains\n\n\nclass TensorFlowEmitter(object):\n\n    def __init__(self, tab=None):\n        self.tab = tab or \' \' * 4\n        self.prefix = \'\'\n\n    def indent(self):\n        self.prefix += self.tab\n\n    def outdent(self):\n        self.prefix = self.prefix[:-len(self.tab)]\n\n    def statement(self, s):\n        return self.prefix + s + \'\\n\'\n\n    def emit_imports(self):\n        return self.statement(\'from kaffe.tensorflow import Network\\n\')\n\n    def emit_class_def(self, name):\n        return self.statement(\'class %s(Network):\' % (name))\n\n    def emit_setup_def(self):\n        return self.statement(\'def setup(self):\')\n\n    def emit_parents(self, chain):\n        assert len(chain)\n        s = \'(self.feed(\'\n        sep = \', \\n\' + self.prefix + (\' \' * len(s))\n        s += sep.join([""\'%s\'"" % parent.name for parent in chain[0].node.parents])\n        return self.statement(s + \')\')\n\n    def emit_node(self, node):\n        return self.statement(\' \' * 5 + \'.\' + node.emit())\n\n    def emit(self, name, chains):\n        s = self.emit_imports()\n        s += self.emit_class_def(name)\n        self.indent()\n        s += self.emit_setup_def()\n        self.indent()\n        blocks = []\n        for chain in chains:\n            b = \'\'\n            b += self.emit_parents(chain)\n            for node in chain:\n                b += self.emit_node(node)\n            blocks.append(b[:-1] + \')\')\n        s = s + \'\\n\\n\'.join(blocks)\n        return s\n\n\nclass TensorFlowTransformer(object):\n\n    def __init__(self, def_path, data_path, verbose=True, phase=\'test\'):\n        self.verbose = verbose\n        self.phase = phase\n        self.load(def_path, data_path, phase)\n        self.params = None\n        self.source = None\n\n    def load(self, def_path, data_path, phase):\n        # Build the graph\n        graph = GraphBuilder(def_path, phase).build()\n\n        if data_path is not None:\n            # Load and associate learned parameters\n            graph = DataInjector(def_path, data_path)(graph)\n\n        # Transform the graph\n        transformers = [\n            # Fuse split batch normalization layers\n            BatchNormScaleBiasFuser(),\n\n            # Fuse ReLUs\n            # TODO: Move non-linearity application to layer wrapper, allowing\n            # any arbitrary operation to be optionally activated.\n            ReLUFuser(allowed_parent_types=[NodeKind.Convolution, NodeKind.InnerProduct,\n                                            NodeKind.BatchNorm]),\n\n            # Rename nodes\n            # Slashes are used for scoping in TensorFlow. Replace slashes\n            # in node names with underscores.\n            # (Caffe\'s GoogLeNet implementation uses slashes)\n            NodeRenamer(lambda node: node.name.replace(\'/\', \'_\'))\n        ]\n        self.graph = graph.transformed(transformers)\n\n        # Display the graph\n        if self.verbose:\n            print_stderr(self.graph)\n\n    def transform_data(self):\n        if self.params is None:\n            transformers = [\n\n                # Reshape the parameters to TensorFlow\'s ordering\n                DataReshaper({\n                    # (c_o, c_i, h, w) -> (h, w, c_i, c_o)\n                    NodeKind.Convolution: (2, 3, 1, 0),\n\n                    # (c_o, c_i) -> (c_i, c_o)\n                    NodeKind.InnerProduct: (1, 0)\n                }),\n\n                # Pre-process batch normalization data\n                BatchNormPreprocessor(),\n\n                # Convert parameters to dictionaries\n                ParameterNamer(),\n            ]\n            self.graph = self.graph.transformed(transformers)\n            self.params = {node.name: node.data for node in self.graph.nodes if node.data}\n        return self.params\n\n    def transform_source(self):\n        if self.source is None:\n            mapper = TensorFlowMapper(self.graph)\n            chains = mapper.map()\n            emitter = TensorFlowEmitter()\n            self.source = emitter.emit(self.graph.name, chains)\n        return self.source\n'"
code/polls/models/move_to_origin.py,0,"b""import csv\nimport sys\nimport numpy as np\n\nwith open(sys.argv[1]) as modelFile:\n    modelLoader = csv.reader(modelFile, delimiter=' ')\n    xs = []\n    ys = []\n    zs = []        \n    for lineIndex, line in enumerate(modelLoader):\n        if len(line) == 0:\n            continue\n        if line[0] == 'v':\n            xs.append(float(line[1]))\n            ys.append(float(line[2]))\n            zs.append(float(line[3]))\n            pass\n        continue\n    modelFile.close()\n    pass\n\nxs = np.array(xs)\nys = np.array(ys)\nzs = np.array(zs)\nprint(xs.shape)\nminX = xs.min()\nmaxX = xs.max()\nminY = ys.min()\nmaxY = ys.max()\nminZ = zs.min()\nmaxZ = zs.max()\ncenterX = (minX + maxX) / 2\ncenterY = (minY + maxY) / 2\ncenterZ = (minZ + maxZ) / 2\nsizeX = (maxX - minX)\nsizeY = (maxY - minY)\nsizeZ = (maxZ - minZ)\nscale = 2 / max(sizeX, sizeY, sizeZ)\n\nwith open(sys.argv[1]) as modelFile, open(sys.argv[2], 'w') as outputFile:\n    modelLoader = csv.reader(modelFile, delimiter=' ')\n    xs = []\n    ys = []\n    zs = []        \n    for lineIndex, line in enumerate(modelLoader):\n        if len(line) == 0:\n            outputFile.write('\\n')\n            continue\n        if line[0] == 'v':\n            line[1] = str((float(line[1]) - centerX) * scale)\n            line[2] = str((float(line[2]) - centerY) * scale)\n            line[3] = str((float(line[3]) - centerZ) * scale)\n            pass\n        outputFile.write(' '.join(line) + '\\n')\n        continue\n    modelFile.close()\n    outputFile.close()\n    pass\n"""
code/polls/models/obj2egg.py,0,"b'#!/usr/bin/python\n""""""\n    This Version: $Id: obj2egg.py,v 1.7 2008/05/26 17:42:53 andyp Exp $\n    Info: info >at< pfastergames.com\n\n    Extended from: http://panda3d.org/phpbb2/viewtopic.php?t=3378\n    .___..__ .___.___.___.__..__ .  .\n      |  [__)[__ [__ [__ |  |[__)|\\/|\n      |  |  \\[___[___|   |__||  \\|  |\n    obj2egg.py [n##][b][t][s] filename1.obj ...\n        -n regenerate normals with # degree smoothing\n            exaple -n30  (normals at less 30 degrees will be smoothed)\n        -b make binarmals\n        -t make tangents\n        -s show in pview\n\n    licensed under WTFPL (http://sam.zoy.org/wtfpl/)\n""""""\n\nfrom pandac.PandaModules import *\nimport math\nimport string\nimport getopt\nimport sys, os\n\n\ndef floats(float_list):\n    """"""coerce a list of strings that represent floats into a list of floats""""""\n    return [ float(number) for number in float_list ]\n\ndef ints(int_list):\n    """"""coerce a list of strings that represent integers into a list of integers""""""\n    return [ int(number) for number in int_list ]\n\n\nclass ObjMaterial:\n    """"""a wavefront material""""""\n    def __init__(self):\n        self.filename = None\n        self.name = ""default""\n        self.eggdiffusetexture = None\n        self.eggmaterial = None\n        self.attrib = {}\n        self.attrib[""Ns""] = 100.0\n        self.attrib[""d""] = 1.0\n        self.attrib[""illum""] = 2\n        # ""magenta""\n        self.attrib[""Kd""] = [1.0, 1.0, 1.0]\n        self.attrib[""Ka""] = [0.0, 0.0, 0.0]\n        self.attrib[""Ks""] = [0.0, 0.0, 0.0]\n        self.attrib[""Ke""] = [0.0, 0.0, 0.0]\n\n    def put(self, key, value):\n        self.attrib[key] = value\n        return self\n\n    def get(self, key):\n        if self.attrib.has_key(key):\n            return self.attrib[key]\n        return None\n\n    def has_key(self, key):\n        return self.attrib.has_key(key)\n\n    def isTextured(self):\n        # for k in (""map_Kd"", ""map_Bump"", ""map_Ks""):    <-- NOT YET\n        if self.attrib.has_key(""map_Kd""):\n            return True;\n        return False;\n\n    def getEggTexture(self):\n        if self.eggdiffusetexture:\n            return self.eggdiffusetexture\n        if not self.isTextured():\n            return None\n        m = EggTexture(self.name + ""_diffuse"", self.get(""map_Kd""))\n        m.setFormat(EggTexture.FRgb)\n        m.setMagfilter(EggTexture.FTLinearMipmapLinear)\n        m.setMinfilter(EggTexture.FTLinearMipmapLinear)\n        m.setWrapU(EggTexture.WMRepeat)\n        m.setWrapV(EggTexture.WMRepeat)\n        self.eggdiffusetexture = m\n        return self.eggdiffusetexture\n\n    def getEggMaterial(self):\n        if self.eggmaterial:\n            return self.eggmaterial\n        m = EggMaterial(self.name + ""_mat"")\n        # XXX TODO: add support for specular, and obey illum setting\n        # XXX as best as we can\n        rgb = self.get(""Kd"")\n        if rgb is not None:\n            m.setDiff(Vec4(rgb[0], rgb[1], rgb[2], 1.0))\n        rgb = self.get(""Ka"")\n        if rgb is not None:\n            m.setAmb(Vec4(rgb[0], rgb[1], rgb[2], 1.0))\n        rgb = self.get(""Ks"")\n        if rgb is not None:\n            m.setSpec(Vec4(rgb[0], rgb[1], rgb[2], 1.0))\n        ns = self.get(""Ns"")\n        if ns is not None:\n            m.setShininess(ns)\n        self.eggmaterial = m\n        return self.eggmaterial\n\nclass MtlFile:\n    """"""an object representing all Wavefront materials in a .mtl file""""""\n    def __init__(self, filename=None):\n        self.filename = None\n        self.materials = {}\n        self.comments = {}\n        if filename is not None:\n            self.read(filename)\n\n    def read(self, filename, verbose=False):\n        self.filename = filename\n        self.materials = {}\n        self.comments = {}\n        try:\n            file = open(filename)\n        except:\n            return self\n        linenumber = 0\n        mat = None\n        for line in file.readlines():\n            line = line.strip()\n            linenumber = linenumber + 1\n            if not line:\n                continue\n            if line[0] == \'#\':\n                self.comments[linenumber] = line\n                print line\n                continue\n            tokens = line.split()\n            if not tokens:\n                continue\n            if verbose: print ""tokens[0]:"", tokens\n            if tokens[0] == ""newmtl"":\n                mat = ObjMaterial()\n                mat.filename = filename\n                mat.name = tokens[1]\n                self.materials[mat.name] = mat\n                if verbose: print ""newmtl:"", mat.name\n                continue\n            if tokens[0] in (""Ns"", ""d"", ""Tr""):\n                # ""d factor"" - specifies the dissovle for the current material,\n                #              1.0 is full opaque\n                # ""Ns exponent"" - specifies the specular exponent.  A high exponent\n                #               results in a tight, concentrated highlight.\n                mat.put(tokens[0], float(tokens[1]))\n                continue\n            if tokens[0] in (""illum""):\n                # according to http://www.fileformat.info/format/material/\n                # 0 = Color on and Ambient off\n                # 1 = Color on and Ambient on\n                # 2 = Highlight on\n                # 3 = Reflection on and Ray trace on\n                # 4 = Transparency: Glass on, Reflection: Ray trace on\n                # 5 = Reflection: Fesnel on and Ray trace on\n                # 6 = Transparency: Refraction on, Reflection: Fresnel off and Ray trace on\n                # 7 = Transparency: Refraction on, Refelction: Fresnel on and Ray Trace on\n                # 8 = Reflection on and Ray trace off\n                # 9 = Transparency: Glass on, Reflection: Ray trace off\n                # 10 = Casts shadows onto invisible surfaces\n                mat.put(tokens[0], int(tokens[1]))\n                continue\n            if tokens[0] in (""Kd"", ""Ka"", ""Ks"", ""Ke""):\n                mat.put(tokens[0], floats(tokens[1:]))\n                continue\n            if tokens[0] in (""map_Kd"", ""map_Bump"", ""map_Ks"", ""map_bump"", ""bump""):\n                # Ultimate Unwrap 3D Pro emits these:\n                # map_Kd == diffuse\n                # map_Bump == bump\n                # map_Ks == specular\n                mat.put(tokens[0], pathify(tokens[1]))\n                if verbose: print ""map:"", mat.name, tokens[0], mat.get(tokens[0])\n                continue\n            if tokens[0] in (""Ni""):\n                # blender\'s .obj exporter can emit this ""Ni 1.000000""\n                mat.put(tokens[0], float(tokens[1]))\n                continue\n            print ""file \\""%s\\"": line %d: unrecognized:"" % (filename, linenumber), tokens\n        file.close()\n        if verbose: print ""%d materials"" % len(self.materials), ""loaded from"", filename\n        return self\n\nclass ObjFile:\n    """"""a representation of a wavefront .obj file""""""\n    def __init__(self, filename=None):\n        self.filename = None\n        self.objects = [""defaultobject""]\n        self.groups = [""defaultgroup""]\n        self.points = []\n        self.uvs = []\n        self.normals = []\n        self.faces = []\n        self.polylines = []\n        self.matlibs = []\n        self.materialsbyname = {}\n        self.comments = {}\n        self.currentobject = self.objects[0]\n        self.currentgroup = self.groups[0]\n        self.currentmaterial = None\n        if filename is not None:\n            self.read(filename)\n\n    def read(self, filename, verbose=False):\n        if verbose: print ""ObjFile.read:"", ""filename:"", filename\n        self.filename = filename\n        self.objects = [""defaultobject""]\n        self.groups = [""defaultgroup""]\n        self.points = []\n        self.uvs = []\n        self.normals = []\n        self.faces = []\n        self.polylines = []\n        self.matlibs = []\n        self.materialsbyname = {}\n        self.comments = {}\n        self.currentobject = self.objects[0]\n        self.currentgroup = self.groups[0]\n        self.currentmaterial = None\n        try:\n            file = open(filename)\n        except:\n            return self\n        linenumber = 0\n        for line in file.readlines():\n            line = line.strip()\n            linenumber = linenumber + 1\n            if not line:\n                continue\n            if line[0] == \'#\':\n                self.comments[linenumber] = line\n                print line\n                continue\n            tokens = line.split()\n            if not tokens:\n                continue\n            if tokens[0] == ""mtllib"":\n                if verbose: print ""mtllib:"", tokens[1:]\n                mtllib = MtlFile(tokens[1])\n                # if verbose: print mtllib\n                self.matlibs.append(mtllib)\n                self.indexmaterials(mtllib)\n                continue\n            if tokens[0] == ""g"":\n                if verbose: print ""g:"", tokens[1:]\n                self.__newgroup("""".join(tokens[1:]))\n                continue\n            if tokens[0] == ""o"":\n                if verbose: print ""o:"", tokens[1:]\n                self.__newobject("""".join(tokens[1:]))\n                continue\n            if tokens[0] == ""usemtl"":\n                if verbose: print ""usemtl:"", tokens[1:]\n                self.__usematerial(tokens[1])\n                continue\n            if tokens[0] == ""v"":\n                if verbose: print ""v:"", tokens[1:]\n                self.__newv(tokens[1:])\n                continue\n            if tokens[0] == ""vn"":\n                if verbose: print ""vn:"", tokens[1:]\n                self.__newnormal(tokens[1:])\n                continue\n            if tokens[0] == ""vt"":\n                if verbose: print ""vt:"", tokens[1:]\n                self.__newuv(tokens[1:])\n                continue\n            if tokens[0] == ""f"":\n                if verbose: print ""f:"", tokens[1:]\n                self.__newface(tokens[1:])\n                continue\n            if tokens[0] == ""s"":\n                # apparently, this enables/disables smoothing\n                print ""%s:%d:"" % (filename, linenumber), ""ignoring:"", tokens\n                continue\n            if tokens[0] == ""l"":\n                if verbose: print ""l:"", tokens[1:]\n                self.__newpolyline(tokens[1:])\n                continue\n            print ""%s:%d:"" % (filename, linenumber), ""unknown:"", tokens\n        file.close()\n        return self\n\n    def __vertlist(self, lst):\n        res = []\n        for vert in lst:\n            vinfo = vert.split(""/"")\n            vlen = len(vinfo)\n            vertex = {\'v\':None, \'vt\':None, \'vn\':None}\n            if vlen == 1:\n                vertex[\'v\'] = int(vinfo[0])\n            elif vlen == 2:\n                if vinfo[0] != \'\':\n                    vertex[\'v\'] = int(vinfo[0])\n                if vinfo[1] != \'\':\n                    vertex[\'vt\'] = int(vinfo[1])\n            elif vlen == 3:\n                if vinfo[0] != \'\':\n                    vertex[\'v\'] = int(vinfo[0])\n                if vinfo[1] != \'\':\n                    vertex[\'vt\'] = int(vinfo[1])\n                if vinfo[2] != \'\':\n                    vertex[\'vn\'] = int(vinfo[2])\n            else:\n                print ""aborting...""\n                raise UNKNOWN, res\n            res.append(vertex)\n        if False: print res\n        return res\n\n    def __enclose(self, lst):\n        mdata = (self.currentobject, self.currentgroup, self.currentmaterial)\n        return (lst, mdata)\n\n    def __newpolyline(self, l):\n        polyline = self.__vertlist(l)\n        if False: print ""__newline:"", polyline\n        self.polylines.append(self.__enclose(polyline))\n        return self\n\n    def __newface(self, f):\n        face = self.__vertlist(f)\n        if False: print face\n        self.faces.append(self.__enclose(face))\n        return self\n\n    def __newuv(self, uv):\n        self.uvs.append(floats(uv))\n        return self\n\n    def __newnormal(self, normal):\n        self.normals.append(floats(normal))\n        return self\n\n    def __newv(self, v):\n        # capture the current metadata with vertices\n        vdata = floats(v)\n        mdata = (self.currentobject, self.currentgroup, self.currentmaterial)\n        vinfo = (vdata, mdata)\n        self.points.append(vinfo)\n        return self\n\n    def indexmaterials(self, mtllib, verbose=False):\n        # traverse the materials defined in mtllib, indexing\n        # them by name.\n        for mname in mtllib.materials:\n            mobj = mtllib.materials[mname]\n            self.materialsbyname[mobj.name] = mobj\n        if verbose: \n            print ""indexmaterials:"", mtllib.filename, ""materials:"", self.materialsbyname.keys()\n        return self\n\n    def __closeobject(self):\n        self.currentobject = ""defaultobject""\n        return self\n\n    def __newobject(self, object):\n        self.__closeobject()\n        if False: print ""__newobject:"", ""object:"", object\n        self.currentobject = object\n        self.objects.append(object)\n        return self\n\n    def __closegroup(self):\n        self.currentgroup = ""defaultgroup""\n        return self\n\n    def __newgroup(self, group):\n        self.__closegroup()\n        if False: print ""__newgroup:"", ""group:"", group\n        self.currentgroup = group\n        self.groups.append(group)\n        return self\n\n    def __usematerial(self, material):\n        if False: print ""__usematerial:"", ""material:"", material\n        if self.materialsbyname.has_key(material):\n            self.currentmaterial = material\n        else:\n            print ""warning:"", ""__usematerial:"", ""unknown material:"", material\n        return self\n\n    def __itemsby(self, itemlist, objname, groupname):\n        res = []\n        for item in itemlist:\n            vlist, mdata = item\n            wobj, wgrp, wmat = mdata\n            if (wobj == objname) and (wgrp == groupname):\n                res.append(item)\n        return res\n\n    def __facesby(self, objname, groupname):\n        return self.__itemsby(self.faces, objname, groupname)\n\n    def __linesby(self, objname, groupname):\n        return self.__itemsby(self.polylines, objname, groupname)\n\n    def __eggifyverts(self, eprim, evpool, vlist):\n        for vertex in vlist:\n            ixyz = vertex[\'v\']\n            vinfo = self.points[ixyz-1]\n            vxyz, vmeta = vinfo\n            ev = EggVertex()\n            ev.setPos(Point3D(vxyz[0], vxyz[1], vxyz[2]))\n            iuv = vertex[\'vt\']\n            if iuv is not None:\n                vuv = self.uvs[iuv-1]\n                ev.setUv(Point2D(vuv[0], vuv[1]))\n            inormal = vertex[\'vn\']\n            if inormal is not None:\n                vn = self.normals[inormal-1]\n                ev.setNormal(Vec3D(vn[0], vn[1], vn[2]))\n            evpool.addVertex(ev)\n            eprim.addVertex(ev)\n        return self\n\n    def __eggifymats(self, eprim, wmat):\n        if self.materialsbyname.has_key(wmat):\n            mtl = self.materialsbyname[wmat]\n            if mtl.isTextured():\n                eprim.setTexture(mtl.getEggTexture())\n                # NOTE: it looks like you almost always want to setMaterial()\n                #       for textured polys.... [continued below...]\n                eprim.setMaterial(mtl.getEggMaterial())\n            rgb = mtl.get(""Kd"")\n            if rgb is not None:\n                # ... and some untextured .obj\'s store the color of the\n                # material # in the Kd settings...\n                eprim.setColor(Vec4(rgb[0], rgb[1], rgb[2], 1.0))\n            # [continued...] but you may *not* always want to assign\n            # materials to untextured polys...  hmmmm.\n            if False:\n                eprim.setMaterial(mtl.getEggMaterial())\n        return self\n\n    def __facestoegg(self, egg, objname, groupname):\n        selectedfaces = self.__facesby(objname, groupname)\n        if len(selectedfaces) == 0:\n            return self\n        eobj = EggGroup(objname)\n        egg.addChild(eobj)\n        egrp = EggGroup(groupname)\n        eobj.addChild(egrp)\n        evpool = EggVertexPool(groupname)\n        egrp.addChild(evpool)\n        for face in selectedfaces:\n            vlist, mdata = face\n            wobj, wgrp, wmat = mdata\n            epoly = EggPolygon()\n            egrp.addChild(epoly)\n            self.__eggifymats(epoly, wmat)\n            self.__eggifyverts(epoly, evpool, vlist)\n        #; each matching face\n        return self\n\n    def __polylinestoegg(self, egg, objname, groupname):\n        selectedlines = self.__linesby(objname, groupname)\n        if len(selectedlines) == 0:\n            return self\n        eobj = EggGroup(objname)\n        egg.addChild(eobj)\n        egrp = EggGroup(groupname)\n        eobj.addChild(egrp)\n        evpool = EggVertexPool(groupname)\n        egrp.addChild(evpool)\n        for line in selectedlines:\n            vlist, mdata = line\n            wobj, wgrp, wmat = mdata\n            eline = EggLine()\n            egrp.addChild(eline)\n            self.__eggifymats(eline, wmat)\n            self.__eggifyverts(eline, evpool, vlist)\n        #; each matching line\n        return self\n\n    def toEgg(self, verbose=True):\n        if verbose: print ""converting...""\n        # make a new egg\n        egg = EggData()\n        # convert polygon faces\n        if len(self.faces) > 0:\n            for objname in self.objects:\n                for groupname in self.groups:\n                    self.__facestoegg(egg, objname, groupname)\n        # convert polylines\n        if len(self.polylines) > 0:\n            for objname in self.objects:\n                for groupname in self.groups:\n                    self.__polylinestoegg(egg, objname, groupname)\n        return egg\n\ndef pathify(path):\n    if os.path.isfile(path):\n        return path\n    # if it was written on win32, it may have \\\'s in it, and\n    # also a full rather than relative pathname (Hexagon does this... ick)\n    orig = path\n    path = path.lower()\n    path = path.replace(""\\\\"", ""/"")\n    h, t = os.path.split(path)\n    if os.path.isfile(t):\n        return t\n    print ""warning: can\'t make sense of this map file name:"", orig\n    return t\n    \ndef main(argv=None):\n    if argv is None:\n        argv = sys.argv\n    try:\n        opts, args = getopt.getopt(argv[1:], ""hn:bs"", [""help"", ""normals"", ""binormals"", ""show""])\n    except getopt.error, msg:\n        print msg\n        print __doc__\n        return 2\n    show = False\n    for o, a in opts:\n        if o in (""-h"", ""--help""):\n            print __doc__\n            return 0\n        elif o in (""-s"", ""--show""):\n            show = True\n    for infile in args:\n        try:\n            if "".obj"" not in infile:\n                print ""WARNING"", finfile, ""does not look like a valid obj file""\n                continue\n            obj = ObjFile(infile)\n            egg = obj.toEgg()\n            f, e = os.path.splitext(infile)\n            outfile = f + "".egg""\n            for o, a in opts:\n                if o in (""-n"", ""--normals""):\n                    egg.recomputeVertexNormals(float(a))\n                elif o in (""-b"", ""--binormals""):\n                    egg.recomputeTangentBinormal(GlobPattern(""""))\n            egg.removeUnusedVertices(GlobPattern(""""))\n            if True:\n                egg.triangulatePolygons(EggData.TConvex & EggData.TPolygon)\n            if True:\n                egg.recomputePolygonNormals()\n            egg.writeEgg(Filename(outfile))\n            if show:\n                os.system(""pview "" + outfile)\n        except Exception,e:\n            print e\n    return 0\n\nif __name__ == ""__main__"":\n    sys.exit(main())\n\n\n'"
