file_path,api_count,code
src/__init__.py,0,b''
src/convert_batch_of_images.py,0,"b'#!/usr/bin/env python\nimport sys\nimport os\nfrom argparse import ArgumentParser\nfrom os.path import basename\n\nfrom classes.inference.Sampler import *\n\ndef build_parser():\n  parser = ArgumentParser()\n  parser.add_argument(\'--pngs_path\', type=str,\n                      dest=\'pngs_path\', help=\'png folder to convert into HTML\',\n                      required=True)\n  parser.add_argument(\'--output_folder\', type=str,\n                      dest=\'output_folder\', help=\'dir to save generated gui and html\',\n                      required=True)\n  parser.add_argument(\'--model_json_file\', type=str,\n                      dest=\'model_json_file\', help=\'trained model json file\',\n                      required=True)\n  parser.add_argument(\'--model_weights_file\', type=str,\n                      dest=\'model_weights_file\', help=\'trained model weights file\', required=True)\n  parser.add_argument(\'--print_bleu_score\', type=int,\n                      dest=\'print_bleu_score\', help=\'see BLEU score for single example\', default=0)\n  parser.add_argument(\'--original_guis_filepath\', type=str,\n                      dest=\'original_guis_filepath\', help=\'if getting BLEU score, provide original guis folder filepath\', default=None)\n  parser.add_argument(\'--style\', type=str,\n                      dest=\'style\', help=\'style to use for generation\', default=\'default\')\n  return parser\n\ndef main():\n    parser = build_parser()\n    options = parser.parse_args()\n    pngs_path = options.pngs_path\n    output_folder = options.output_folder\n    model_json_file = options.model_json_file\n    model_weights_file = options.model_weights_file\n    print_bleu_score = options.print_bleu_score\n    original_guis_filepath = options.original_guis_filepath\n    style = options.style\n\n\n    if not os.path.exists(output_folder):\n        os.makedirs(output_folder)\n\n    # Create sampler\n    sampler = Sampler(model_json_path=model_json_file,\n                      model_weights_path = model_weights_file)\n\n    # Sample and retrieve BLEU\n    sampler.convert_batch_of_images(output_folder, pngs_path=pngs_path, get_corpus_bleu=print_bleu_score, original_guis_filepath=original_guis_filepath, style=style)\n\nif __name__ == ""__main__"":\n  main()'"
src/convert_single_image.py,0,"b'#!/usr/bin/env python\nimport sys\nimport os\nfrom argparse import ArgumentParser\nfrom os.path import basename\n\nfrom classes.inference.Sampler import *\n\ndef build_parser():\n  parser = ArgumentParser()\n  parser.add_argument(\'--png_path\', type=str,\n                      dest=\'png_path\', help=\'png filepath to convert into HTML\',\n                      required=True)\n  parser.add_argument(\'--output_folder\', type=str,\n                      dest=\'output_folder\', help=\'dir to save generated gui and html\',\n                      required=True)\n  parser.add_argument(\'--model_json_file\', type=str,\n                      dest=\'model_json_file\', help=\'trained model json file\',\n                      required=True)\n  parser.add_argument(\'--model_weights_file\', type=str,\n                      dest=\'model_weights_file\', help=\'trained model weights file\', required=True)\n  parser.add_argument(\'--style\', type=str,\n                      dest=\'style\', help=\'style to use for generation\', default=\'default\')\n  parser.add_argument(\'--print_generated_output\', type=int,\n                      dest=\'print_generated_output\', help=\'see generated GUI output in terminal\', default=1)\n  parser.add_argument(\'--print_bleu_score\', type=int,\n                      dest=\'print_bleu_score\', help=\'see BLEU score for single example\', default=0)\n  parser.add_argument(\'--original_gui_filepath\', type=str,\n                      dest=\'original_gui_filepath\', help=\'if getting BLEU score, provide original gui filepath\', default=None)\n\n  return parser\n\ndef main():\n    parser = build_parser()\n    options = parser.parse_args()\n    png_path = options.png_path\n    output_folder = options.output_folder\n    model_json_file = options.model_json_file\n    model_weights_file = options.model_weights_file\n    style = options.style\n    print_generated_output = options.print_generated_output\n    print_bleu_score = options.print_bleu_score\n    original_gui_filepath = options.original_gui_filepath\n\n    if not os.path.exists(output_folder):\n        os.makedirs(output_folder)\n\n    sampler = Sampler(model_json_path=model_json_file,\n                      model_weights_path = model_weights_file)\n    sampler.convert_single_image(output_folder, png_path=png_path, print_generated_output=print_generated_output, get_sentence_bleu=print_bleu_score, original_gui_filepath=original_gui_filepath, style=style)\n\nif __name__ == ""__main__"":\n  main()'"
src/evaluate_batch_guis.py,0,"b'#!/usr/bin/env python\nfrom __future__ import print_function\n\nfrom argparse import ArgumentParser\n\nfrom classes.inference.Evaluator import *\n\ndef build_parser():\n    parser = ArgumentParser()\n    parser.add_argument(\'--original_guis_filepath\', type=str,\n                        dest=\'original_guis_filepath\', help=\'dir with all original guis\',\n                        required=True)\n    parser.add_argument(\'--predicted_guis_filepath\', type=str,\n                        dest=\'predicted_guis_filepath\', help=\'dir with all predicted guis\',\n                        required=True)\n    return parser\n\ndef main():\n\n    parser = build_parser()\n    options = parser.parse_args()\n    original_guis_filepath = options.original_guis_filepath\n    predicted_guis_filepath = options.predicted_guis_filepath\n\n    bleu_score = Evaluator.get_corpus_bleu(original_guis_filepath, predicted_guis_filepath)\n    print(""BLEU score for batch of GUIs: {}"".format(bleu_score))\n\nif __name__ == ""__main__"":\n    main()'"
src/evaluate_single_gui.py,0,"b'from __future__ import print_function\nfrom __future__ import absolute_import\n\nfrom argparse import ArgumentParser\nfrom nltk.translate.bleu_score import sentence_bleu, corpus_bleu\n\nfrom classes.inference.Evaluator import *\n\ndef build_parser():\n    parser = ArgumentParser()\n    parser.add_argument(\'--original_gui_filepath\', type=str,\n                        dest=\'original_gui_filepath\', help=\'filepath of original gui file\',\n                        required=True)\n    parser.add_argument(\'--predicted_gui_filepath\', type=str,\n                        dest=\'predicted_gui_filepath\', help=\'filepath of original gui file\',\n                        required=True)\n    return parser\n\ndef main():\n\n    parser = build_parser()\n    options = parser.parse_args()\n    original_gui_filepath = options.original_gui_filepath\n    predicted_gui_filepath = options.predicted_gui_filepath\n\n    bleu_score = Evaluator.get_sentence_bleu(original_gui_filepath, predicted_gui_filepath)\n    print(""BLEU score for single GUI: {}"".format(bleu_score))\n\nif __name__ == ""__main__"":\n    main()'"
src/train.py,0,"b'#!/usr/bin/env python\nfrom __future__ import print_function\nfrom __future__ import absolute_import\n\nfrom argparse import ArgumentParser\n\nfrom classes.model.SketchCodeModel import *\n\nVAL_SPLIT = 0.2\n\ndef build_parser():\n    parser = ArgumentParser()\n    parser.add_argument(\'--data_input_path\', type=str,\n                        dest=\'data_input_path\', help=\'directory containing images and guis\',\n                        required=True)\n    parser.add_argument(\'--validation_split\', type=float,\n                        dest=\'validation_split\', help=\'portion of training data for validation set\',\n                        default=VAL_SPLIT)\n    parser.add_argument(\'--epochs\', type=int,\n                        dest=\'epochs\', help=\'number of epochs to train on\',\n                        required=True)\n    parser.add_argument(\'--model_output_path\', type=str,\n                        dest=\'model_output_path\', help=\'directory for saving model data\',\n                        required=True)\n    parser.add_argument(\'--model_json_file\', type=str,\n                        dest=\'model_json_file\', help=\'pretrained model json file\',\n                        required=False)\n    parser.add_argument(\'--model_weights_file\', type=str,\n                        dest=\'model_weights_file\', help=\'pretrained model weights file\',\n                        required=False)\n    parser.add_argument(\'--augment_training_data\', type=int,\n                        dest=\'augment_training_data\', help=\'use Keras image augmentation on training data\',\n                        default=1)\n    return parser\n\ndef main():\n\n    parser = build_parser()\n    options = parser.parse_args()\n    data_input_path = options.data_input_path\n    validation_split = options.validation_split\n    epochs = options.epochs\n    model_output_path = options.model_output_path\n    model_json_file = options.model_json_file\n    model_weights_file = options.model_weights_file\n    augment_training_data = options.augment_training_data\n\n    # Load model\n    model = SketchCodeModel(model_output_path, model_json_file, model_weights_file)\n\n    # Create the model output path if it doesn\'t exist\n    if not os.path.exists(model_output_path):\n        os.makedirs(model_output_path)\n\n    # Split the datasets and save down image arrays\n    training_path, validation_path = ModelUtils.prepare_data_for_training(data_input_path, validation_split, augment_training_data)\n\n    # Begin model training\n    model.train(training_path=training_path,\n                validation_path=validation_path,\n                epochs=epochs)\n\nif __name__ == ""__main__"":\n    main()'"
src/classes/__init__.py,0,b''
src/classes/dataset/Dataset.py,0,"b'from __future__ import absolute_import\n\nimport os\nimport shutil\nimport pdb\nimport hashlib\nimport numpy as np\n\nfrom keras.preprocessing.text import Tokenizer, one_hot\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.utils import to_categorical\n\nfrom .ImagePreprocessor import *\n\nVOCAB_FILE              = \'../vocabulary.vocab\'\nTRAINING_SET_NAME       = ""training_set""\nVALIDATION_SET_NAME     = ""validation_set""\nBATCH_SIZE              = 64\n\nclass Dataset:\n\n    def __init__(self, data_input_folder, test_set_folder=None):\n        self.data_input_folder = data_input_folder\n        self.test_set_folder   = test_set_folder\n\n    def split_datasets(self, validation_split):\n        sample_ids = self.populate_sample_ids()\n        print(""Total number of samples: "", len(sample_ids))\n\n        train_set_ids, val_set_ids, shuffled_sampled_ids = self.get_all_id_sets(validation_split, sample_ids)\n        training_path, validation_path = self.split_samples(train_set_ids, val_set_ids)\n\n        return training_path, validation_path\n\n    def split_samples(self, train_set_ids, val_set_ids):\n        training_path, validation_path = self.create_data_folders()\n        self.copy_files_to_folders(train_set_ids, training_path)\n        self.copy_files_to_folders(val_set_ids, validation_path)\n        return training_path, validation_path\n\n    def preprocess_data(self, training_path, validation_path, augment_training_data):\n        train_img_preprocessor = ImagePreprocessor()\n        train_img_preprocessor.build_image_dataset(training_path, augment_data=augment_training_data)\n        val_img_preprocessor = ImagePreprocessor()\n        val_img_preprocessor.build_image_dataset(validation_path, augment_data=0)\n\n\n\n\n    ##########################################\n    ####### PRIVATE METHODS ##################\n    ##########################################\n\n    @classmethod\n    def load_vocab(cls):\n        file = open(VOCAB_FILE, \'r\')\n        text = file.read().splitlines()[0]\n        file.close()\n        tokenizer = Tokenizer(filters=\'\', split="" "", lower=False)\n        tokenizer.fit_on_texts([text])\n        vocab_size = len(tokenizer.word_index) + 1\n        return tokenizer, vocab_size\n\n    @classmethod\n    def create_generator(cls, data_input_path, max_sequences):\n        img_features, text_features = Dataset.load_data(data_input_path)\n        total_sequences = 0\n        for text_set in text_features: total_sequences += len(text_set.split())\n        steps_per_epoch = total_sequences // BATCH_SIZE\n        tokenizer, vocab_size = Dataset.load_vocab()\n        data_gen = Dataset.data_generator(text_features, img_features, max_sequences, tokenizer, vocab_size)\n        return data_gen, steps_per_epoch\n\n    @classmethod\n    def data_generator(cls, text_features, img_features, max_sequences, tokenizer, vocab_size):\n        while 1:\n            for i in range(0, len(text_features), 1):\n                Ximages, XSeq, y = list(), list(),list()\n                for j in range(i, min(len(text_features), i+1)):\n                    image = img_features[j]\n                    desc = text_features[j]\n                    in_img, in_seq, out_word = Dataset.process_data_for_generator([desc], [image], max_sequences, tokenizer, vocab_size)\n                    for k in range(len(in_img)):\n                        Ximages.append(in_img[k])\n                        XSeq.append(in_seq[k])\n                        y.append(out_word[k])\n                yield [[np.array(Ximages), np.array(XSeq)], np.array(y)]\n\n    @classmethod\n    def process_data_for_generator(cls, texts, features, max_sequences, tokenizer, vocab_size):\n        X, y, image_data = list(), list(), list()\n        sequences = tokenizer.texts_to_sequences(texts)\n        for img_no, seq in enumerate(sequences):\n            for i in range(1, len(seq)):\n                in_seq, out_seq = seq[:i], seq[i]\n                in_seq = pad_sequences([in_seq], maxlen=max_sequences)[0]\n                out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n                image_data.append(features[img_no])\n                X.append(in_seq[-48:])\n                y.append(out_seq)\n        return np.array(image_data), np.array(X), np.array(y)\n\n    @classmethod\n    def load_data(cls, data_input_path):\n        text = []\n        images = []\n        all_filenames = os.listdir(data_input_path)\n        all_filenames.sort()\n        for filename in all_filenames:\n            if filename[-3:] == ""npz"":\n                image = np.load(data_input_path+\'/\'+filename)\n                images.append(image[\'features\'])\n            elif filename[-3:] == \'gui\':\n                file = open(data_input_path+\'/\'+filename, \'r\')\n                texts = file.read()\n                file.close()\n                syntax = \'<START> \' + texts + \' <END>\'\n                syntax = \' \'.join(syntax.split())\n                syntax = syntax.replace(\',\', \' ,\')\n                text.append(syntax)\n        images = np.array(images, dtype=float)\n        return images, text\n\n    def create_data_folders(self):\n        training_path = ""{}/{}"".format(os.path.dirname(self.data_input_folder), TRAINING_SET_NAME)\n        validation_path = ""{}/{}"".format(os.path.dirname(self.data_input_folder), VALIDATION_SET_NAME)\n\n        self.delete_existing_folders(training_path)\n        self.delete_existing_folders(validation_path)\n\n        if not os.path.exists(training_path): os.makedirs(training_path)\n        if not os.path.exists(validation_path): os.makedirs(validation_path)\n        return training_path, validation_path\n\n    def copy_files_to_folders(self, sample_ids, output_folder):\n        copied_count = 0\n        for sample_id in sample_ids:\n            sample_id_png_path = ""{}/{}.png"".format(self.data_input_folder, sample_id)\n            sample_id_gui_path = ""{}/{}.gui"".format(self.data_input_folder, sample_id)\n            if os.path.exists(sample_id_png_path) and os.path.exists(sample_id_gui_path):\n                output_png_path = ""{}/{}.png"".format(output_folder, sample_id)\n                output_gui_path = ""{}/{}.gui"".format(output_folder, sample_id)\n                shutil.copyfile(sample_id_png_path, output_png_path)\n                shutil.copyfile(sample_id_gui_path, output_gui_path)\n                copied_count += 1\n        print(""Moved {} files from {} to {}"".format(copied_count, self.data_input_folder, output_folder))\n\n    def delete_existing_folders(self, folder_to_delete):\n        if os.path.exists(folder_to_delete):\n            shutil.rmtree(folder_to_delete)\n            print(""Deleted existing folder: {}"".format(folder_to_delete))\n\n    def populate_sample_ids(self):\n        all_sample_ids = []\n        full_path = os.path.realpath(self.data_input_folder)\n        for f in os.listdir(full_path):\n            if f.find("".gui"") != -1:\n                file_name = f[:f.find("".gui"")]\n                if os.path.isfile(""{}/{}.png"".format(self.data_input_folder, file_name)):\n                    all_sample_ids.append(file_name)\n        return all_sample_ids\n\n    def get_all_id_sets(self, validation_split, sample_ids):\n        np.random.shuffle(sample_ids)\n        val_count = int(validation_split * len(sample_ids))\n        train_count = len(sample_ids) - val_count\n        print(""Splitting datasets, training samples: {}, validation samples: {}"".format(train_count, val_count))\n        train_set, val_set = self.split_paths(sample_ids, train_count, val_count)\n\n        return train_set, val_set, sample_ids\n\n    def split_paths(self, sample_ids, train_count, val_count):\n        train_set = []\n        val_set = []\n        hashes = []\n        for sample_id in sample_ids:\n            f = open(""{}/{}.gui"".format(self.data_input_folder, sample_id), \'r\', encoding=\'utf-8\')\n\n            with f:\n                chars = """"\n                for line in f:\n                    chars += line\n                content_hash = chars.replace("" "", """").replace(""\\n"", """")\n                content_hash = hashlib.sha256(content_hash.encode(\'utf-8\')).hexdigest()\n\n                if len(val_set) == val_count:\n                    train_set.append(sample_id)\n                else:\n                    is_unique = True\n                    for h in hashes:\n                        if h is content_hash:\n                            is_unique = False\n                            break\n\n                    if is_unique:\n                        val_set.append(sample_id)\n                    else:\n                        train_set.append(sample_id)\n\n                hashes.append(content_hash)\n\n        assert len(val_set) == val_count\n\n        return train_set, val_set\n'"
src/classes/dataset/ImagePreprocessor.py,0,"b'from __future__ import absolute_import\n\nimport os\nimport sys\nimport shutil\n\nimport numpy as np\nfrom PIL import Image\nimport cv2\nfrom keras.preprocessing.image import ImageDataGenerator\n\nclass ImagePreprocessor:\n\n    def __init__(self):\n        pass\n\n    def build_image_dataset(self, data_input_folder, augment_data=True):\n\n        print(""Converting images from {} into arrays, augmentation: {}"".format(data_input_folder, augment_data))\n        resized_img_arrays, sample_ids = self.get_resized_images(data_input_folder)\n\n        if augment_data == 1:\n            self.augment_and_save_images(resized_img_arrays, sample_ids, data_input_folder)\n        else:\n            self.save_resized_img_arrays(resized_img_arrays, sample_ids, data_input_folder)\n\n    def get_img_features(self, png_path):\n        img_features = self.resize_img(png_path)\n        assert(img_features.shape == (256,256,3))\n        return img_features\n\n\n   ##########################################\n   ####### PRIVATE METHODS ##################\n   ##########################################\n\n\n\n    def save_resized_img_arrays(self, resized_img_arrays, sample_ids, output_folder):\n        count = 0\n        for img_arr, sample_id in zip(resized_img_arrays, sample_ids):\n            npz_filename = ""{}/{}.npz"".format(output_folder, sample_id)\n            np.savez_compressed(npz_filename, features=img_arr)\n            retrieve = np.load(npz_filename)[""features""]\n            assert np.array_equal(img_arr, retrieve)\n            count += 1\n        print(""Saved down {} resized images to folder {}"".format(count, output_folder))\n        del resized_img_arrays\n\n    def augment_and_save_images(self, resized_img_arrays, sample_ids, data_input_folder):\n        datagen = ImageDataGenerator(\n                                 rotation_range=2,\n                                 width_shift_range=0.05,\n                                 height_shift_range=0.05,\n                                 zoom_range=0.05\n                                )\n        keras_generator = datagen.flow(resized_img_arrays,sample_ids,batch_size=1)\n        count = 0\n        for i in range(len(resized_img_arrays)):\n            img_arr, sample_id = next(keras_generator)\n            img_arr = np.squeeze(img_arr)\n            npz_filename = ""{}/{}.npz"".format(data_input_folder, sample_id[0])\n            im = Image.fromarray(img_arr.astype(\'uint8\'))\n            np.savez_compressed(npz_filename, features=img_arr)\n            retrieve = np.load(npz_filename)[""features""]\n            assert np.array_equal(img_arr, retrieve)\n            count += 1\n        print(""Saved down {} augmented images to folder {}"".format(count, data_input_folder))\n        del resized_img_arrays\n\n    def get_resized_images(self, pngs_input_folder):\n        all_files = os.listdir(pngs_input_folder)\n        png_files = [f for f in all_files if f.find("".png"") != -1]\n        images = []\n        labels = []\n        for png_file_path in png_files:\n            png_path = ""{}/{}"".format(pngs_input_folder, png_file_path)\n            sample_id = png_file_path[:png_file_path.find(\'.png\')]\n            resized_img_arr = self.resize_img(png_path)\n            images.append(resized_img_arr)\n            labels.append(sample_id)\n        return np.array(images), np.array(labels)\n\n    def resize_img(self, png_file_path):\n        img_rgb = cv2.imread(png_file_path)\n        img_grey = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)\n        img_adapted = cv2.adaptiveThreshold(img_grey, 255, cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY, 101, 9)\n        img_stacked = np.repeat(img_adapted[...,None],3,axis=2)\n        resized = cv2.resize(img_stacked, (200,200), interpolation=cv2.INTER_AREA)\n        bg_img = 255 * np.ones(shape=(256,256,3))\n        bg_img[27:227, 27:227,:] = resized\n        bg_img /= 255\n        return bg_img\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n'"
src/classes/dataset/__init__.py,0,b''
src/classes/inference/Compiler.py,0,"b'from __future__ import print_function\nfrom __future__ import absolute_import\n\nimport os\nimport json\n\nfrom .Node import *\n\nBASE_DIR_NAME = os.path.dirname(__file__)\nDEFAULT_DSL_MAPPING_FILEPATH = ""{}/styles/default-dsl-mapping.json"".format(BASE_DIR_NAME)\nFACEBOOK_DSL_MAPPING_FILEPATH = ""{}/styles/facebook_dsl_mapping.json"".format(BASE_DIR_NAME)\nAIRBNB_DSL_MAPPING_FILEPATH = ""{}/styles/airbnb_dsl_mapping.json"".format(BASE_DIR_NAME)\n\n\nclass Compiler:\n    def __init__(self, style):\n        style_json = self.get_stylesheet(style)\n        with open(style_json) as data_file:\n            self.dsl_mapping = json.load(data_file)\n\n        self.opening_tag = self.dsl_mapping[""opening-tag""]\n        self.closing_tag = self.dsl_mapping[""closing-tag""]\n        self.content_holder = self.opening_tag + self.closing_tag\n\n        self.root = Node(""body"", None, self.content_holder)\n\n    def get_stylesheet(self, style):\n        if style == \'default\':\n            return DEFAULT_DSL_MAPPING_FILEPATH\n        elif style == \'facebook\':\n            return FACEBOOK_DSL_MAPPING_FILEPATH\n        elif style == \'airbnb\':\n            return AIRBNB_DSL_MAPPING_FILEPATH\n\n    def compile(self, generated_gui):\n        dsl_file = generated_gui\n\n        #Parse fix\n        dsl_file = dsl_file[1:-1]\n        dsl_file = \' \'.join(dsl_file)\n        dsl_file = dsl_file.replace(\'{\', \'{8\').replace(\'}\', \'8}8\')\n        dsl_file = dsl_file.replace(\' \', \'\')\n        dsl_file = dsl_file.split(\'8\')\n        dsl_file = list(filter(None, dsl_file))\n\n        current_parent = self.root\n        for token in dsl_file:\n            token = token.replace("" "", """").replace(""\\n"", """")\n\n            if token.find(self.opening_tag) != -1:\n                token = token.replace(self.opening_tag, """")\n                element = Node(token, current_parent, self.content_holder)\n                current_parent.add_child(element)\n                current_parent = element\n            elif token.find(self.closing_tag) != -1:\n                current_parent = current_parent.parent\n            else:\n                tokens = token.split("","")\n                for t in tokens:\n                    element = Node(t, current_parent, self.content_holder)\n                    current_parent.add_child(element)\n\n        output_html = self.root.render(self.dsl_mapping)\n        if output_html is None: return ""HTML Parsing Error""\n\n        return output_html'"
src/classes/inference/Evaluator.py,0,"b'from __future__ import print_function\nfrom __future__ import absolute_import\n\nimport pdb\nimport os\nimport operator\nfrom nltk.translate.bleu_score import sentence_bleu, corpus_bleu\n\nclass Evaluator:\n    def __init__(self):\n        pass\n\n    @classmethod\n    def get_sentence_bleu(cls, original_gui_filepath, generated_gui_filepath):\n        original_gui = Evaluator.load_gui_doc(original_gui_filepath)\n        generated_gui = Evaluator.load_gui_doc(generated_gui_filepath)\n        hypothesis = generated_gui[1:-1]\n        reference = original_gui\n        references = [reference]\n        return sentence_bleu(references, hypothesis)\n\n    @classmethod\n    def get_corpus_bleu(cls, original_guis_filepath, predicted_guis_filepath):\n        actuals, predicted = Evaluator.load_guis_from_folder(original_guis_filepath, predicted_guis_filepath)\n        regular_bleu = corpus_bleu(actuals, predicted)\n        return regular_bleu\n\n    @classmethod\n    def load_gui_doc(cls, gui_filepath):\n        file = open(gui_filepath, \'r\')\n        gui = file.read()\n        file.close()\n        gui = \' \'.join(gui.split())\n        gui = gui.replace(\',\', \' ,\')\n        gui = gui.split()\n\n        # Predicted images don\'t have color so we normalize all buttons to btn-orange or btn-active\n        btns_to_replace = [\'btn-green\', \'btn-red\']\n        normalized_gui = [\'btn-orange\' if token in btns_to_replace else token for token in gui]\n        normalized_gui = [\'btn-active\' if token == \'btn-inactive\' else token for token in normalized_gui]\n        return normalized_gui\n\n    @classmethod\n    def load_guis_from_folder(cls, original_guis_filepath, predicted_guis_filepath):\n        actuals, predicted = list(), list()\n        all_files = os.listdir(predicted_guis_filepath)\n        all_predicted_files = os.listdir(predicted_guis_filepath)\n        all_predicted_guis = [f for f in all_predicted_files if f.find(\'.gui\') != -1]\n        all_predicted_guis.sort()\n        guis = []\n        for f in all_predicted_guis:\n            generated_gui_filepath = ""{}/{}"".format(predicted_guis_filepath, f)\n            actual_gui_filepath = ""{}/{}"".format(original_guis_filepath, f)\n            if os.path.isfile(actual_gui_filepath):\n                predicted_gui = Evaluator.load_gui_doc(generated_gui_filepath)\n                actual_gui = Evaluator.load_gui_doc(actual_gui_filepath)\n\n                predicted.append(predicted_gui[1:-1])\n                actuals.append([actual_gui])\n        return actuals, predicted'"
src/classes/inference/Node.py,0,"b'from __future__ import print_function\nfrom __future__ import absolute_import\n\nfrom .SamplerUtils import *\n\nTEXT_PLACE_HOLDER = ""[]""\n\nclass Node:\n\n    def __init__(self, key, parent_node, content_holder):\n        self.key = key\n        self.parent = parent_node\n        self.children = []\n        self.content_holder = content_holder\n\n    def add_child(self, child):\n        self.children.append(child)\n\n    def show(self):\n        for child in self.children:\n            child.show()\n\n    def rendering_function(self, key, value):\n        if key.find(""btn"") != -1:\n            value = value.replace(TEXT_PLACE_HOLDER, SamplerUtils.get_random_text())\n        elif key.find(""title"") != -1:\n            value = value.replace(TEXT_PLACE_HOLDER, SamplerUtils.get_random_text(length_text=5, space_number=0))\n        elif key.find(""text"") != -1:\n            value = value.replace(TEXT_PLACE_HOLDER,\n                                  SamplerUtils.get_random_text(length_text=56, space_number=7, with_upper_case=False))\n        return value\n\n    def render(self, mapping, rendering_function=None):\n        content = """"\n        for child in self.children:\n            placeholder = child.render(mapping, self.rendering_function)\n            if placeholder is None:\n                self = None\n                return\n            else:\n                content += placeholder\n\n        value = mapping.get(self.key, None)\n\n        if value is None:\n            self = None\n            return None\n\n        if rendering_function is not None:\n            value = self.rendering_function(self.key, value)\n\n        if len(self.children) != 0:\n            value = value.replace(self.content_holder, content)\n\n        return value'"
src/classes/inference/Sampler.py,0,"b'from __future__ import absolute_import\n\nimport sys\nimport os\nimport shutil\nimport json\nimport numpy as np\n\nfrom keras.models import model_from_json\nfrom keras.preprocessing.sequence import pad_sequences\n\nfrom classes.dataset.Dataset import *\nfrom classes.dataset.ImagePreprocessor import *\nfrom .Evaluator import *\nfrom .Compiler import *\n\nMAX_LENGTH = 48\n\nclass Sampler:\n\n    def __init__(self, model_json_path=None, model_weights_path=None):\n        self.tokenizer, self.vocab_size = Dataset.load_vocab()\n        self.model = self.load_model(model_json_path, model_weights_path)\n\n    def convert_batch_of_images(self, output_folder, pngs_path, get_corpus_bleu, original_guis_filepath, style):\n\n        all_filenames = os.listdir(pngs_path)\n        all_filenames.sort()\n        generated_count = 0\n        for filename in all_filenames:\n            if filename.find(\'.png\') != -1:\n                png_path = ""{}/{}"".format(pngs_path, filename)\n                try:\n                    self.convert_single_image(output_folder, png_path, print_generated_output=0, get_sentence_bleu=0, original_gui_filepath=png_path, style=style)\n                    generated_count += 1\n                except:\n                    print(""Error with GUI / HTML generation:"", sys.exc_info()[0])\n                    print(sys.exc_info())\n                    continue\n        print(""Generated code for {} images"".format(generated_count))\n\n        if (get_corpus_bleu == 1) and (original_guis_filepath is not None):\n            print(""BLEU score: {}"".format(Evaluator.get_corpus_bleu(original_guis_filepath, output_folder)))\n\n    def convert_single_image(self, output_folder, png_path, print_generated_output, get_sentence_bleu, original_gui_filepath, style):\n\n        # Retrieve sample ID\n        png_filename = os.path.basename(png_path)\n        if png_filename.find(\'.png\') == -1:\n            raise ValueError(""Image is not a png!"")\n        sample_id = png_filename[:png_filename.find(\'.png\')]\n\n        # Generate GUI\n        print(""Generating code for sample ID {}"".format(sample_id))\n        generated_gui, gui_output_filepath= self.generate_gui(png_path, print_generated_output=print_generated_output, output_folder=output_folder, sample_id=sample_id)\n\n        # Generate HTML\n        generated_html = self.generate_html(generated_gui, sample_id, print_generated_output=print_generated_output, output_folder=output_folder, style=style)\n\n        # Get BLEU\n        if get_sentence_bleu == 1 and (original_gui_filepath is not None):\n            print(""BLEU score: {}"".format(Evaluator.get_sentence_bleu(original_gui_filepath, gui_output_filepath)))\n\n\n    ##########################################\n    ####### PRIVATE METHODS ##################\n    ##########################################\n\n    def load_model(self, model_json_path, model_weights_path):\n        json_file = open(model_json_path, \'r\')\n        loaded_model_json = json_file.read()\n        json_file.close()\n        loaded_model = model_from_json(loaded_model_json)\n        loaded_model.load_weights(model_weights_path)\n        print(""\\nLoaded model from disk"")\n        return loaded_model\n\n    def generate_gui(self, png_path, print_generated_output, sample_id, output_folder):\n        test_img_preprocessor = ImagePreprocessor()\n        img_features = test_img_preprocessor.get_img_features(png_path)\n\n        in_text = \'<START> \'\n        photo = np.array([img_features])\n        for i in range(150):\n            sequence = self.tokenizer.texts_to_sequences([in_text])[0]\n            sequence = pad_sequences([sequence], maxlen=MAX_LENGTH)\n            yhat = self.model.predict([photo, sequence], verbose=0)\n            yhat = np.argmax(yhat)\n            word = self.word_for_id(yhat)\n            if word is None:\n                break\n            in_text += word + \' \'\n            if word == \'<END>\':\n                break\n\n        generated_gui = in_text.split()\n\n        if print_generated_output is 1:\n            print(""\\n=========\\nGenerated GUI code:"")\n            print(generated_gui)\n\n        gui_output_filepath = self.write_gui_to_disk(generated_gui, sample_id, output_folder)\n\n        return generated_gui, gui_output_filepath\n\n    def generate_html(self, gui_array, sample_id, print_generated_output, output_folder, style=\'default\'):\n\n        compiler = Compiler(style)\n        compiled_website = compiler.compile(gui_array)\n\n        if print_generated_output is 1:\n            print(""\\nCompiled HTML:"")\n            print(compiled_website)\n\n        if compiled_website != \'HTML Parsing Error\':\n            output_filepath = ""{}/{}.html"".format(output_folder, sample_id)\n            with open(output_filepath, \'w\') as output_file:\n                output_file.write(compiled_website)\n                print(""Saved generated HTML to {}"".format(output_filepath))\n\n    def word_for_id(self, integer):\n        for word, index in self.tokenizer.word_index.items():\n            if index == integer:\n                return word\n        return None\n\n    def write_gui_to_disk(self, gui_array, sample_id, output_folder):\n        gui_output_filepath = ""{}/{}.gui"".format(output_folder, sample_id)\n        with open(gui_output_filepath, \'w\') as out_f:\n            out_f.write(\' \'.join(gui_array))\n        return gui_output_filepath\n\n\n\n\n\n\n'"
src/classes/inference/SamplerUtils.py,0,"b'from __future__ import print_function\nfrom __future__ import absolute_import\n\nimport string\nimport random\n\nclass SamplerUtils:\n\n    @staticmethod\n    def get_random_text(length_text=10, space_number=1, with_upper_case=True):\n        results = []\n        while len(results) < length_text:\n            char = random.choice(string.ascii_letters[:26])\n            results.append(char)\n        if with_upper_case:\n            results[0] = results[0].upper()\n\n        current_spaces = []\n        while len(current_spaces) < space_number:\n            space_pos = random.randint(2, length_text - 3)\n            if space_pos in current_spaces:\n                break\n            results[space_pos] = "" ""\n            if with_upper_case:\n                results[space_pos + 1] = results[space_pos - 1].upper()\n\n            current_spaces.append(space_pos)\n\n        return \'\'.join(results)'"
src/classes/model/ModelUtils.py,0,"b'from __future__ import absolute_import\n\nfrom classes.dataset.Dataset import *\n\nclass ModelUtils:\n\n    @staticmethod\n    def prepare_data_for_training(data_input_folder, validation_split, augment_training_data):\n\n        dataset = Dataset(data_input_folder)\n        training_path, validation_path = dataset.split_datasets(validation_split)\n        dataset.preprocess_data(training_path, validation_path, augment_training_data)\n\n        return training_path, validation_path'"
src/classes/model/SketchCodeModel.py,0,"b'from __future__ import absolute_import\n\nfrom keras.models import Model, Sequential, model_from_json\nfrom keras.callbacks import ModelCheckpoint, CSVLogger, Callback\nfrom keras.layers.core import Dense, Dropout, Flatten\nfrom keras.layers import Embedding, GRU, TimeDistributed, RepeatVector, LSTM, concatenate , Input, Reshape, Dense\nfrom keras.layers.convolutional import Conv2D\nfrom keras.optimizers import RMSprop\n\nfrom .ModelUtils import *\nfrom classes.dataset.Dataset import *\n\nMAX_LENGTH = 48\nMAX_SEQ    = 150\n\nclass SketchCodeModel():\n\n    def __init__(self, model_output_path, model_json_file=None, model_weights_file=None):\n\n        # Create model output path\n        self.model_output_path = model_output_path\n\n        # If we have an existing model json / weights, load in that model\n        if model_json_file is not None and model_weights_file is not None:\n            self.model = self.load_model(model_json_file, model_weights_file)\n            optimizer = RMSprop(lr=0.0001, clipvalue=1.0)\n            self.model.compile(loss=\'categorical_crossentropy\', optimizer=optimizer)\n            print(""Loaded pretrained model from disk"")\n\n        # Create a new model if we don\'t have one\n        else:\n            self.create_model()\n            print(""Created new model, vocab size: {}"".format(self.vocab_size))\n\n        print(self.model.summary())\n\n    def load_model(self, model_json_file, model_weights_file):\n        json_file = open(model_json_file, \'r\')\n        loaded_model_json = json_file.read()\n        json_file.close()\n        loaded_model = model_from_json(loaded_model_json)\n        loaded_model.load_weights(model_weights_file)\n        return loaded_model\n\n    def save_model(self):\n        model_json = self.model.to_json()\n        with open(""{}/model_json.json"".format(self.model_output_path), ""w"") as json_file:\n            json_file.write(model_json)\n        self.model.save_weights(""{}/weights.h5"".format(self.model_output_path))\n\n    def create_model(self):\n        tokenizer, vocab_size = Dataset.load_vocab()\n        self.vocab_size = vocab_size\n\n        # Image encoder\n        image_model = Sequential()\n        image_model.add(Conv2D(16, (3, 3), padding=\'valid\', activation=\'relu\', input_shape=(256, 256, 3,)))\n        image_model.add(Conv2D(16, (3,3), activation=\'relu\', padding=\'same\', strides=2))\n        image_model.add(Conv2D(32, (3,3), activation=\'relu\', padding=\'same\'))\n        image_model.add(Conv2D(32, (3,3), activation=\'relu\', padding=\'same\', strides=2))\n        image_model.add(Conv2D(64, (3,3), activation=\'relu\', padding=\'same\'))\n        image_model.add(Conv2D(64, (3,3), activation=\'relu\', padding=\'same\', strides=2))\n        image_model.add(Conv2D(128, (3,3), activation=\'relu\', padding=\'same\'))\n        image_model.add(Flatten())\n        image_model.add(Dense(1024, activation=\'relu\'))\n        image_model.add(Dropout(0.3))\n        image_model.add(Dense(1024, activation=\'relu\'))\n        image_model.add(Dropout(0.3))\n        image_model.add(RepeatVector(MAX_LENGTH))\n        visual_input = Input(shape=(256, 256, 3,))\n        encoded_image = image_model(visual_input)\n\n        # Language encoder\n        language_input = Input(shape=(MAX_LENGTH,))\n        language_model = Embedding(vocab_size, 50, input_length=MAX_LENGTH, mask_zero=True)(language_input)\n        language_model = GRU(128, return_sequences=True)(language_model)\n        language_model = GRU(128, return_sequences=True)(language_model)\n\n        # Decoder\n        decoder = concatenate([encoded_image, language_model])\n        decoder = GRU(512, return_sequences=True)(decoder)\n        decoder = GRU(512, return_sequences=False)(decoder)\n        decoder = Dense(vocab_size, activation=\'softmax\')(decoder)\n\n        # Compile the model\n        self.model = Model(inputs=[visual_input, language_input], outputs=decoder)\n        optimizer = RMSprop(lr=0.0001, clipvalue=1.0)\n        self.model.compile(loss=\'categorical_crossentropy\', optimizer=optimizer)\n\n    def train(self, training_path, validation_path, epochs):\n\n        # Setup data generators\n        training_generator, train_steps_per_epoch = Dataset.create_generator(training_path, max_sequences=MAX_SEQ)\n        validation_generator, val_steps_per_epoch = Dataset.create_generator(validation_path, max_sequences=MAX_SEQ)\n\n        # Setup model callbacks\n        callbacks_list = self.construct_callbacks(validation_path)\n\n        # Begin training\n        print(""\\n### Starting model training ###\\n"")\n        self.model.fit_generator(generator=training_generator, validation_data=validation_generator, epochs=epochs, shuffle=False, validation_steps=val_steps_per_epoch, steps_per_epoch=train_steps_per_epoch, callbacks=callbacks_list, verbose=1)\n        print(""\\n### Finished model training ###\\n"")\n        self.save_model()\n\n    def construct_callbacks(self, validation_path):\n        checkpoint_filepath=""{}/"".format(self.model_output_path) + ""weights-epoch-{epoch:04d}--val_loss-{val_loss:.4f}--loss-{loss:.4f}.h5""\n        csv_logger = CSVLogger(""{}/training_val_losses.csv"".format(self.model_output_path))\n        checkpoint = ModelCheckpoint(checkpoint_filepath,\n                                    verbose=0,\n                                    save_weights_only=True,\n                                    save_best_only=True,\n                                    mode= \'min\',\n                                    period=2)\n        callbacks_list = [checkpoint, csv_logger]\n        return callbacks_list\n\n\n\n\n\n\n'"
src/classes/model/__init__.py,0,b''
