file_path,api_count,code
docs/conf.py,0,"b'# -*- coding: utf-8 -*-\n#\n# TensorFlow-World documentation build configuration file, created by\n# sphinx-quickstart on Wed Jun 28 22:26:19 2017.\n#\n# This file is execfile()d with the current directory set to its\n# containing dir.\n#\n# Note that not all possible configuration values are present in this\n# autogenerated file.\n#\n# All configuration values have a default; values that are commented out\n# serve to show the default.\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n#\n# import os\n# import sys\n# sys.path.insert(0, os.path.abspath(\'.\'))\n\n\n# -- General configuration ------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\n#\n# needs_sphinx = \'1.0\'\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named \'sphinx.ext.*\') or your custom\n# ones.\nextensions = [\'sphinx.ext.autodoc\',\n    \'sphinx.ext.mathjax\',\n    \'sphinx.ext.viewcode\',\n    \'sphinx.ext.githubpages\']\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\'_templates\']\n\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n#\n# source_suffix = [\'.rst\', \'.md\']\nsource_suffix = \'.rst\'\n\n# The master toctree document.\nmaster_doc = \'index\'\n\n# General information about the project.\n# project = u\'TensorFlow-World\'\ncopyright = u\'2017, Amirsina Torfi\'\nauthor = u\'Amirsina Torfi\'\n\n# The version info for the project you\'re documenting, acts as replacement for\n# |version| and |release|, also used in various other places throughout the\n# built documents.\n#\n# The short X.Y version.\nversion = u\'1.0\'\n# The full version, including alpha/beta/rc tags.\nrelease = u\'1.0\'\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#\n# This is also used if you do content translation via gettext catalogs.\n# Usually you set ""language"" from the command line for these cases.\nlanguage = None\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This patterns also effect to html_static_path and html_extra_path\nexclude_patterns = [\'_build\', \'Thumbs.db\', \'.DS_Store\']\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = \'sphinx\'\n\n# If true, `todo` and `todoList` produce output, else they produce nothing.\ntodo_include_todos = False\n\n\n# -- Options for HTML output ----------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n#\nhtml_theme = \'alabaster\'\n\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n#\n# html_theme_options = {}\n\nhtml_theme_options = {\n    \'show_powered_by\': False,\n    \'github_user\': \'astorfi\',\n    \'github_repo\': \'TensorFlow-World\',\n    \'github_banner\': True,\n    \'show_related\': False\n}\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named ""default.css"" will overwrite the builtin ""default.css"".\nhtml_static_path = [\'_static\']\n\n# Title\nhtml_title = \'TensorFlow World\'\n\n\n# -- Options for HTMLHelp output ------------------------------------------\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = \'TensorFlow-Worlddoc\'\n\n\n# If true, links to the reST sources are added to the pages.\nhtml_show_sourcelink = False\n\n# If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.\nhtml_show_sphinx = False\n\n\n# -- Options for LaTeX output ---------------------------------------------\n\nlatex_elements = {\n    # The paper size (\'letterpaper\' or \'a4paper\').\n    #\n    # \'papersize\': \'letterpaper\',\n\n    # The font size (\'10pt\', \'11pt\' or \'12pt\').\n    #\n    # \'pointsize\': \'10pt\',\n\n    # Additional stuff for the LaTeX preamble.\n    #\n    # \'preamble\': \'\',\n\n    # Latex figure (float) alignment\n    #\n    # \'figure_align\': \'htbp\',\n}\n\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title,\n#  author, documentclass [howto, manual, or own class]).\nlatex_documents = [\n    (master_doc, \'TensorFlow-World.tex\', u\'TensorFlow-World Documentation\',\n     u\'Amirsina Torfi\', \'manual\'),\n]\n\n\n# -- Options for manual page output ---------------------------------------\n\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [\n    (master_doc, \'tensorflow-world\', u\'TensorFlow-World Documentation\',\n     [author], 1)\n]\n\n\n# -- Options for Texinfo output -------------------------------------------\n\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n    (master_doc, \'TensorFlow-World\', u\'TensorFlow-World Documentation\',\n     author, \'TensorFlow-World\', \'One line description of project.\',\n     \'Miscellaneous\'),\n]\n\n\n\n'"
codes/0-welcome/code/0-welcome.py,3,"b'#####################################################\n########## Welcome to TensorFlow World ##############\n#####################################################\n\n# The tutorials in this section is just a start for going into TensorFlow world.\n# The TensorFlow flags are used for having a more user friendly environment.\n\nfrom __future__ import print_function\nimport tensorflow as tf\nimport os\n\n\n######################################\n######### Necessary Flags ############\n# ####################################\n\nlog_dir = os.path.dirname(os.path.abspath(__file__)) + \'/logs\'\n\n################################################\n################# handling errors!##############\n################################################\n\n# Defining some sentence!\nwelcome = tf.constant(\'Welcome to TensorFlow world!\')\n\n# Run the session\nwith tf.Session() as sess:\n    writer = tf.summary.FileWriter(os.path.expanduser(log_dir), sess.graph)\n    print(""output: "", sess.run(welcome))\n\n# Closing the writer.\nwriter.close()\nsess.close()\n\n\n'"
codes/0-welcome/code/TensorFlow_Test.py,3,"b""# This code has been provided by TensorFlow.\n# Please refer to: https://www.tensorflow.org/api_guides/python/test\n\nimport tensorflow as tf\n\nclass SquareTest(tf.test.TestCase):\n\n  def testSquare(self):\n    with self.test_session():\n      x = tf.square([2, 3])\n      self.assertAllEqual(x.eval(), [4, 9])\n\nif __name__ == '__main__':\n    tf.test.main()\n"""
codes/1-basics/basic_math_operations/code/basic_math_operation.py,8,"b'#####################################################\n########## Welcome to TensorFlow World ##############\n#####################################################\n\n# The tutorials in this section is just a start for math operations.\n# The TensorFlow flags are used for having a more user friendly environment.\n\nfrom __future__ import print_function\nimport tensorflow as tf\nimport os\n\n\n######################################\n######### Necessary Flags ############\n# ####################################\n\n# The default path for saving event files is the same folder of this python file.\ntf.app.flags.DEFINE_string(\n    \'log_dir\', os.path.dirname(os.path.abspath(__file__)) + \'/logs\',\n    \'Directory where event logs are written to.\')\n\n# Store all elemnts in FLAG structure!\nFLAGS = tf.app.flags.FLAGS\n\n################################################\n################# handling errors!##############\n################################################\n\n# The user is prompted to input an absolute path.\n# os.path.expanduser is leveraged to transform \'~\' sign to the corresponding path indicator.\n#       Example: \'~/logs\' equals to \'/home/username/logs\'\nif not os.path.isabs(os.path.expanduser(FLAGS.log_dir)):\n    raise ValueError(\'You must assign absolute path for --log_dir\')\n\n\n# Defining some constant values\na = tf.constant(5.0, name=""a"")\nb = tf.constant(10.0, name=""b"")\n\n# Some basic operations\nx = tf.add(a, b, name=""add"")\ny = tf.div(a, b, name=""divide"")\n\n# Run the session\nwith tf.Session() as sess:\n    writer = tf.summary.FileWriter(os.path.expanduser(FLAGS.log_dir), sess.graph)\n    print(""a ="", sess.run(a))\n    print(""b ="", sess.run(b))\n    print(""a + b ="", sess.run(x))\n    print(""a/b ="", sess.run(y))\n\n# Closing the writer.\nwriter.close()\nsess.close()\n\n'"
codes/1-basics/variables/code/variables.py,9,"b'## This code create some arbitrary variables and initialize them ###\n# The goal is to show how to define and initialize variables from scratch.\n\nimport tensorflow as tf\nfrom tensorflow.python.framework import ops\n\n#######################################\n######## Defining Variables ###########\n#######################################\n\n# Create three variables with some default values.\nweights = tf.Variable(tf.random_normal([2, 3], stddev=0.1),\n                      name=""weights"")\nbiases = tf.Variable(tf.zeros([3]), name=""biases"")\ncustom_variable = tf.Variable(tf.zeros([3]), name=""custom"")\n\n# Get all the variables\' tensors and store them in a list.\nall_variables_list = ops.get_collection(ops.GraphKeys.GLOBAL_VARIABLES)\n\n\n############################################\n######## Customized initializer ############\n############################################\n\n## Initialation of some custom variables.\n## In this part we choose some variables and only initialize them rather than initializing all variables.\n\n# ""variable_list_custom"" is the list of variables that we want to initialize.\nvariable_list_custom = [weights, custom_variable]\n\n# The initializer\ninit_custom_op = tf.variables_initializer(var_list=variable_list_custom )\n\n\n########################################\n######## Global initializer ############\n########################################\n\n# Method-1\n# Add an op to initialize the variables.\ninit_all_op = tf.global_variables_initializer()\n\n# Method-2\ninit_all_op = tf.variables_initializer(var_list=all_variables_list)\n\n\n\n##########################################################\n######## Initialization using other variables ############\n##########################################################\n\n# Create another variable with the same value as \'weights\'.\nWeightsNew = tf.Variable(weights.initialized_value(), name=""WeightsNew"")\n\n# Now, the variable must be initialized.\ninit_WeightsNew_op = tf.variables_initializer(var_list=[WeightsNew])\n\n######################################\n####### Running the session ##########\n######################################\nwith tf.Session() as sess:\n    # Run the initializer operation.\n    sess.run(init_all_op)\n    sess.run(init_custom_op)\n    sess.run(init_WeightsNew_op)\n'"
codes/2-basics_in_machine_learning/linear_regression/code/linear_regression.py,10,"b'import numpy as np\nimport tensorflow as tf\nimport xlrd\nimport matplotlib.pyplot as plt\nimport os\nfrom sklearn.utils import check_random_state\n\n# Generating artificial data.\nn = 50\nXX = np.arange(n)\nrs = check_random_state(0)\nYY = rs.randint(-20, 20, size=(n,)) + 2.0 * XX\ndata = np.stack([XX,YY], axis=1)\n\n#######################\n## Defining flags #####\n#######################\ntf.app.flags.DEFINE_integer(\'num_epochs\', 50, \'The number of epochs for training the model. Default=50\')\n# Store all elemnts in FLAG structure!\nFLAGS = tf.app.flags.FLAGS\n\n\n# creating the weight and bias.\n# The defined variables will be initialized to zero.\nW = tf.Variable(0.0, name=""weights"")\nb = tf.Variable(0.0, name=""bias"")\n\n\n#  Creating placeholders for input X and label Y.\ndef inputs():\n    """"""\n    Defining the place_holders.\n    :return:\n            Returning the data and label place holders.\n    """"""\n    X = tf.placeholder(tf.float32, name=""X"")\n    Y = tf.placeholder(tf.float32, name=""Y"")\n    return X,Y\n\n# Create the prediction.\ndef inference(X):\n    """"""\n    Forward passing the X.\n    :param X: Input.\n    :return: X*W + b.\n    """"""\n    return X * W + b\n\ndef loss(X, Y):\n    \'\'\'\n    compute the loss by comparing the predicted value to the actual label.\n    :param X: The input.\n    :param Y: The label.\n    :return: The loss over the samples.\n    \'\'\'\n\n    # Making the prediction.\n    Y_predicted = inference(X)\n    return tf.reduce_sum(tf.squared_difference(Y, Y_predicted))/(2*data.shape[0])\n\n\n# The training function.\ndef train(loss):\n    learning_rate = 0.0001\n    return tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n\n\nwith tf.Session() as sess:\n\n    # Initialize the variables[w and b].\n    sess.run(tf.global_variables_initializer())\n\n    # Get the input tensors\n    X, Y = inputs()\n\n    # Return the train loss and create the train_op.\n    train_loss = loss(X, Y)\n    train_op = train(train_loss)\n\n    # Step 8: train the model\n    for epoch_num in range(FLAGS.num_epochs): # run 100 epochs\n        loss_value, _ = sess.run([train_loss,train_op],\n                                 feed_dict={X: data[:,0], Y: data[:,1]})\n\n        # Displaying the loss per epoch.\n        print(\'epoch %d, loss=%f\' %(epoch_num+1, loss_value))\n\n        # save the values of weight and bias\n        wcoeff, bias = sess.run([W, b])\n\n\n###############################\n#### Evaluate and plot ########\n###############################\nInput_values = data[:,0]\nLabels = data[:,1]\nPrediction_values = data[:,0] * wcoeff + bias\n\n# # uncomment if plotting is desired!\n# plt.plot(Input_values, Labels, \'ro\', label=\'main\')\n# plt.plot(Input_values, Prediction_values, label=\'Predicted\')\n\n# # Saving the result.\n# plt.legend()\n# plt.savefig(\'plot.png\')\n# plt.close()\n'"
codes/2-basics_in_machine_learning/linear_svm/code/linear_svm.py,21,"b'import matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn import datasets\nimport random\nimport sys\n\n\n#######################\n### Necessary Flags ###\n#######################\n\ntf.app.flags.DEFINE_integer(\'batch_size\', 32,\n                            \'Number of samples per batch.\')\n\ntf.app.flags.DEFINE_integer(\'num_steps\', 500,\n                            \'Number of steps for training.\')\n\ntf.app.flags.DEFINE_boolean(\'is_evaluation\', True,\n                            \'Whether or not the model should be evaluated.\')\n\ntf.app.flags.DEFINE_float(\n    \'C_param\', 0.1,\n    \'penalty parameter of the error term.\')\n\ntf.app.flags.DEFINE_float(\n    \'Reg_param\', 1.0,\n    \'penalty parameter of the error term.\')\n\ntf.app.flags.DEFINE_float(\n    \'delta\', 1.0,\n    \'The parameter set for margin.\')\n\ntf.app.flags.DEFINE_float(\n    \'initial_learning_rate\', 0.1,\n    \'The initial learning rate for optimization.\')\n\nFLAGS = tf.app.flags.FLAGS\n\n\n##########################\n### Required Functions ###\n##########################\n\ndef loss_fn(W,b,x_data,y_target):\n    logits = tf.subtract(tf.matmul(x_data, W),b)\n    norm_term = tf.divide(tf.reduce_sum(tf.multiply(tf.transpose(W),W)),2)\n    classification_loss = tf.reduce_mean(tf.maximum(0., tf.subtract(FLAGS.delta, tf.multiply(logits, y_target))))\n    total_loss = tf.add(tf.multiply(FLAGS.C_param,classification_loss), tf.multiply(FLAGS.Reg_param,norm_term))\n    return total_loss\n\ndef inference_fn(W,b,x_data,y_target):\n    prediction = tf.sign(tf.subtract(tf.matmul(x_data, W), b))\n    accuracy = tf.reduce_mean(tf.cast(tf.equal(prediction, y_target), tf.float32))\n    return accuracy\n\ndef next_batch_fn(x_train,y_train,num_samples=FLAGS.batch_size):\n    index = np.random.choice(len(x_train), size=num_samples)\n    X_batch = x_train[index]\n    y_batch = np.transpose([y_train[index]])\n    return X_batch, y_batch\n\n##########################\n### Dataset peparation ###\n##########################\n\n# Dataset loading and organizing.\niris = datasets.load_iris()\n\n# Only the first two features are extracted and used.\nX = iris.data[:, :2]\n\n# The labels are transformed to -1 and 1.\ny = np.array([1 if label==0 else -1 for label in iris.target])\n\n# Get the indices for train and test sets.\nmy_randoms = np.random.choice(X.shape[0], X.shape[0], replace=False)\ntrain_indices = my_randoms[0:int(0.5 * X.shape[0])]\ntest_indices = my_randoms[int(0.5 * X.shape[0]):]\n\n# Splitting train and test sets.\nx_train = X[train_indices]\ny_train = y[train_indices]\nx_test = X[test_indices]\ny_test = y[test_indices]\n\n#############################\n### Defining Placeholders ###\n#############################\n\nx_data = tf.placeholder(shape=[None, X.shape[1]], dtype=tf.float32)\ny_target = tf.placeholder(shape=[None, 1], dtype=tf.float32)\nW = tf.Variable(tf.random_normal(shape=[X.shape[1],1]))\nb = tf.Variable(tf.random_normal(shape=[1,1]))\n\n# Calculation of loss and accuracy.\ntotal_loss = loss_fn(W, b, x_data, y_target)\naccuracy = inference_fn(W, b, x_data, y_target)\n\n# Defining train_op\ntrain_op = tf.train.GradientDescentOptimizer(FLAGS.initial_learning_rate).minimize(total_loss)\n\n###############\n### Session ###\n###############\nsess = tf.Session()\n\n# Initialization of the variables.\ninit = tf.initialize_all_variables()\nsess.run(init)\n\n###############################\n### Training the Linear SVM ###\n###############################\nfor step_idx in range(FLAGS.num_steps):\n\n    # Get the batch of data.\n    X_batch, y_batch = next_batch_fn(x_train, y_train, num_samples=FLAGS.batch_size)\n\n    # Run the optimizer.\n    sess.run(train_op, feed_dict={x_data: X_batch, y_target: y_batch})\n\n    # Calculation of loss and accuracy.\n    loss_step = sess.run(total_loss, feed_dict={x_data: X_batch, y_target: y_batch})\n    train_acc_step = sess.run(accuracy, feed_dict={x_data: x_train, y_target: np.transpose([y_train])})\n    test_acc_step = sess.run(accuracy, feed_dict={x_data: x_test, y_target: np.transpose([y_test])})\n\n    # Displaying the desired values.\n    if step_idx % 100 == 0:\n        print(\'Step #%d, training accuracy= %% %.2f, testing accuracy= %% %.2f \' % (step_idx, float(100 * train_acc_step), float(100 * test_acc_step)))\n\nif FLAGS.is_evaluation:\n    [[w1], [w2]] = sess.run(W)\n    [[bias]] = sess.run(b)\n    x_line = [data[1] for data in X]\n\n    # Find the separator line.\n    line = []\n    line = [-w2/w1*i+bias/w1 for i in x_line]\n\n    # coor_pos_list = [positive_X, positive_y]\n    # coor_neg_list = [negative_X, negative_y]\n\n    for index, data in enumerate(X):\n        if y[index] == 1:\n            positive_X = data[1]\n            positive_y = data[0]\n        elif y[index] == -1:\n            negative_X = data[1]\n            negative_y = data[0]\n        else:\n            sys.exit(""Invalid label!"")\n    \n    # # uncomment if plotting is desired!\n    # # Plotting the SVM decision boundary.\n    # plt.plot(positive_X, positive_y, \'+\', label=\'Positive\')\n    # plt.plot(negative_X, negative_y, \'o\', label=\'Negative\')\n    # plt.plot(x_line, line, \'r-\', label=\'Separator\', linewidth=3)\n    # plt.legend(loc=\'best\')\n    # plt.title(\'Linear SVM\')\n    # plt.show()\n\n\n\n\n\n\n'"
codes/2-basics_in_machine_learning/logistic_regression/code/logistic_regression.py,33,"b'import numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport tempfile\nimport urllib\nimport pandas as pd\nimport os\nfrom tensorflow.examples.tutorials.mnist import input_data\n\n######################################\n######### Necessary Flags ############\n######################################\n\ntf.app.flags.DEFINE_string(\n    \'train_path\', os.path.dirname(os.path.abspath(__file__)) + \'/train_logs\',\n    \'Directory where event logs are written to.\')\n\ntf.app.flags.DEFINE_string(\n    \'checkpoint_path\',\n    os.path.dirname(os.path.abspath(__file__)) + \'/checkpoints\',\n    \'Directory where checkpoints are written to.\')\n\ntf.app.flags.DEFINE_integer(\'max_num_checkpoint\', 10,\n                            \'Maximum number of checkpoints that TensorFlow will keep.\')\n\ntf.app.flags.DEFINE_integer(\'num_classes\', 2,\n                            \'Number of model clones to deploy.\')\n\ntf.app.flags.DEFINE_integer(\'batch_size\', np.power(2, 9),\n                            \'Number of model clones to deploy.\')\n\ntf.app.flags.DEFINE_integer(\'num_epochs\', 10,\n                            \'Number of epochs for training.\')\n\n##########################################\n######## Learning rate flags #############\n##########################################\ntf.app.flags.DEFINE_float(\'initial_learning_rate\', 0.001, \'Initial learning rate.\')\n\ntf.app.flags.DEFINE_float(\n    \'learning_rate_decay_factor\', 0.95, \'Learning rate decay factor.\')\n\ntf.app.flags.DEFINE_float(\n    \'num_epochs_per_decay\', 1, \'Number of epoch pass to decay learning rate.\')\n\n#########################################\n########## status flags #################\n#########################################\ntf.app.flags.DEFINE_boolean(\'is_training\', False,\n                            \'Training/Testing.\')\n\ntf.app.flags.DEFINE_boolean(\'fine_tuning\', False,\n                            \'Fine tuning is desired or not?.\')\n\ntf.app.flags.DEFINE_boolean(\'online_test\', True,\n                            \'Fine tuning is desired or not?.\')\n\ntf.app.flags.DEFINE_boolean(\'allow_soft_placement\', True,\n                            \'Automatically put the variables on CPU if there is no GPU support.\')\n\ntf.app.flags.DEFINE_boolean(\'log_device_placement\', False,\n                            \'Demonstrate which variables are on what device.\')\n\n# Store all elemnts in FLAG structure!\nFLAGS = tf.app.flags.FLAGS\n\n\n################################################\n################# handling errors!##############\n################################################\nif not os.path.isabs(FLAGS.train_path):\n    raise ValueError(\'You must assign absolute path for --train_path\')\n\nif not os.path.isabs(FLAGS.checkpoint_path):\n    raise ValueError(\'You must assign absolute path for --checkpoint_path\')\n\n# Download and get MNIST dataset(available in tensorflow.contrib.learn.python.learn.datasets.mnist)\n# It checks and download MNIST if it\'s not already downloaded then extract it.\n# The \'reshape\' is True by default to extract feature vectors but we set it to false to we get the original images.\nmnist = input_data.read_data_sets(""MNIST_data/"", reshape=True, one_hot=False)\n\n########################\n### Data Processing ####\n########################\n# Organize the data and feed it to associated dictionaries.\ndata={}\n\ndata[\'train/image\'] = mnist.train.images\ndata[\'train/label\'] = mnist.train.labels\ndata[\'test/image\'] = mnist.test.images\ndata[\'test/label\'] = mnist.test.labels\n\ndef extract_samples_Fn(data):\n    index_list = []\n    for sample_index in range(data.shape[0]):\n        label = data[sample_index]\n        if label == 1 or label == 0:\n            index_list.append(sample_index)\n    return index_list\n\n\n# Get only the samples with zero and one label for training.\nindex_list_train = extract_samples_Fn(data[\'train/label\'])\n\n\n# Get only the samples with zero and one label for test set.\nindex_list_test = extract_samples_Fn(data[\'test/label\'])\n\n# Reform the train data structure.\ndata[\'train/image\'] = mnist.train.images[index_list_train]\ndata[\'train/label\'] = mnist.train.labels[index_list_train]\n\n# Reform the test data structure.\ndata[\'test/image\'] = mnist.test.images[index_list_test]\ndata[\'test/label\'] = mnist.test.labels[index_list_test]\n\n# Dimentionality of train\ndimensionality_train = data[\'train/image\'].shape\n\n# Dimensions\nnum_train_samples = dimensionality_train[0]\nnum_features = dimensionality_train[1]\n\n#######################################\n########## Defining Graph ############\n#######################################\n\ngraph = tf.Graph()\nwith graph.as_default():\n    ###################################\n    ########### Parameters ############\n    ###################################\n\n    # global step\n    global_step = tf.Variable(0, name=""global_step"", trainable=False)\n\n    # learning rate policy\n    decay_steps = int(num_train_samples / FLAGS.batch_size *\n                      FLAGS.num_epochs_per_decay)\n    learning_rate = tf.train.exponential_decay(FLAGS.initial_learning_rate,\n                                               global_step,\n                                               decay_steps,\n                                               FLAGS.learning_rate_decay_factor,\n                                               staircase=True,\n                                               name=\'exponential_decay_learning_rate\')\n\n    ###############################################\n    ########### Defining place holders ############\n    ###############################################\n    image_place = tf.placeholder(tf.float32, shape=([None, num_features]), name=\'image\')\n    label_place = tf.placeholder(tf.int32, shape=([None,]), name=\'gt\')\n    label_one_hot = tf.one_hot(label_place, depth=FLAGS.num_classes, axis=-1)\n    dropout_param = tf.placeholder(tf.float32)\n\n    ##################################################\n    ########### Model + Loss + Accuracy ##############\n    ##################################################\n    # A simple fully connected with two class and a softmax is equivalent to Logistic Regression.\n    logits = tf.contrib.layers.fully_connected(inputs=image_place, num_outputs = FLAGS.num_classes, scope=\'fc\')\n\n    # Define loss\n    with tf.name_scope(\'loss\'):\n        loss_tensor = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=label_one_hot))\n\n    # Accuracy\n    # Evaluate the model\n    prediction_correct = tf.equal(tf.argmax(logits, 1), tf.argmax(label_one_hot, 1))\n\n    # Accuracy calculation\n    accuracy = tf.reduce_mean(tf.cast(prediction_correct, tf.float32))\n\n    #############################################\n    ########### training operation ##############\n    #############################################\n\n    # Define optimizer by its default values\n    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n\n    # \'train_op\' is a operation that is run for gradient update on parameters.\n    # Each execution of \'train_op\' is a training step.\n    # By passing \'global_step\' to the optimizer, each time that the \'train_op\' is run, Tensorflow\n    # update the \'global_step\' and increment it by one!\n\n    # gradient update.\n    with tf.name_scope(\'train_op\'):\n        gradients_and_variables = optimizer.compute_gradients(loss_tensor)\n        train_op = optimizer.apply_gradients(gradients_and_variables, global_step=global_step)\n\n\n    ############################################\n    ############ Run the Session ###############\n    ############################################\n    session_conf = tf.ConfigProto(\n        allow_soft_placement=FLAGS.allow_soft_placement,\n        log_device_placement=FLAGS.log_device_placement)\n    sess = tf.Session(graph=graph, config=session_conf)\n\n    with sess.as_default():\n\n        # The saver op.\n        saver = tf.train.Saver()\n\n        # Initialize all variables\n        sess.run(tf.global_variables_initializer())\n\n        # The prefix for checkpoint files\n        checkpoint_prefix = \'model\'\n\n        # If fie-tuning flag in \'True\' the model will be restored.\n        if FLAGS.fine_tuning:\n            saver.restore(sess, os.path.join(FLAGS.checkpoint_path, checkpoint_prefix))\n            print(""Model restored for fine-tuning..."")\n\n        ###################################################################\n        ########## Run the training and loop over the batches #############\n        ###################################################################\n\n        # go through the batches\n        test_accuracy = 0\n        for epoch in range(FLAGS.num_epochs):\n            total_batch_training = int(data[\'train/image\'].shape[0] / FLAGS.batch_size)\n\n            # go through the batches\n            for batch_num in range(total_batch_training):\n                #################################################\n                ########## Get the training batches #############\n                #################################################\n\n                start_idx = batch_num * FLAGS.batch_size\n                end_idx = (batch_num + 1) * FLAGS.batch_size\n\n                # Fit training using batch data\n                train_batch_data, train_batch_label = data[\'train/image\'][start_idx:end_idx], data[\'train/label\'][\n                                                                                             start_idx:end_idx]\n\n                ########################################\n                ########## Run the session #############\n                ########################################\n\n                # Run optimization op (backprop) and Calculate batch loss and accuracy\n                # When the tensor tensors[\'global_step\'] is evaluated, it will be incremented by one.\n                batch_loss, _, training_step = sess.run(\n                    [loss_tensor, train_op,\n                     global_step],\n                    feed_dict={image_place: train_batch_data,\n                               label_place: train_batch_label,\n                               dropout_param: 0.5})\n\n                ########################################\n                ########## Write summaries #############\n                ########################################\n\n\n                #################################################\n                ########## Plot the progressive bar #############\n                #################################################\n\n            print(""Epoch "" + str(epoch + 1) + "", Training Loss= "" + \\\n                  ""{:.5f}"".format(batch_loss))\n\n        ###########################################################\n        ############ Saving the model checkpoint ##################\n        ###########################################################\n\n        # # The model will be saved when the training is done.\n\n        # Create the path for saving the checkpoints.\n        if not os.path.exists(FLAGS.checkpoint_path):\n            os.makedirs(FLAGS.checkpoint_path)\n\n        # save the model\n        save_path = saver.save(sess, os.path.join(FLAGS.checkpoint_path, checkpoint_prefix))\n        print(""Model saved in file: %s"" % save_path)\n\n        ############################################################################\n        ########## Run the session for pur evaluation on the test data #############\n        ############################################################################\n\n        # The prefix for checkpoint files\n        checkpoint_prefix = \'model\'\n\n        # Restoring the saved weights.\n        saver.restore(sess, os.path.join(FLAGS.checkpoint_path, checkpoint_prefix))\n        print(""Model restored..."")\n\n        # Evaluation of the model\n        test_accuracy = 100 * sess.run(accuracy, feed_dict={\n            image_place: data[\'test/image\'],\n            label_place: data[\'test/label\'],\n            dropout_param: 1.})\n\n        print(""Final Test Accuracy is %% %.2f"" % test_accuracy)\n'"
codes/2-basics_in_machine_learning/multiclass_svm/code/multiclass_svm.py,32,"b'import matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn import datasets\nfrom tensorflow.python.framework import ops\nfrom tensorflow.examples.tutorials.mnist import input_data\nfrom sklearn.decomposition import PCA\n\n#######################\n### Necessary Flags ###\n#######################\n\ntf.app.flags.DEFINE_integer(\'batch_size\', 50,\n                            \'Number of samples per batch.\')\n\ntf.app.flags.DEFINE_integer(\'num_steps\', 1000,\n                            \'Number of steps for training.\')\n\ntf.app.flags.DEFINE_integer(\'log_steps\', 50,\n                            \'Number of steps per each display.\')\n\ntf.app.flags.DEFINE_boolean(\'is_evaluation\', True,\n                            \'Whether or not the model should be evaluated.\')\n\ntf.app.flags.DEFINE_float(\n    \'gamma\', -15.0,\n    \'penalty parameter of the error term.\')\n\ntf.app.flags.DEFINE_float(\n    \'initial_learning_rate\', 0.01,\n    \'The initial learning rate for optimization.\')\n\nFLAGS = tf.app.flags.FLAGS\n\n\n###########################\n### Necessary Functions ###\n###########################\ndef cross_class_label_fn(A):\n    """"""\n    This function take the matrix of size (num_classes, batch_size) and return the cross-class label matrix\n    in which Yij are the elements where i,j are class indices.\n    :param A: The input matrix of size (num_classes, batch_size).\n    :return: The output matrix of size (num_classes, batch_size, batch_size).\n    """"""\n    label_class_i = tf.reshape(A, [num_classes, 1, FLAGS.batch_size])\n    label_class_j = tf.reshape(label_class_i, [num_classes, FLAGS.batch_size, 1])\n    returned_mat = tf.matmul(label_class_j, label_class_i)\n    return returned_mat\n\n\n# Compute SVM loss.\ndef loss_fn(alpha, label_placeholder):\n    term_1 = tf.reduce_sum(alpha)\n    alpha_cross = tf.matmul(tf.transpose(alpha), alpha)\n    cross_class_label = cross_class_label_fn(label_placeholder)\n    term_2 = tf.reduce_sum(tf.multiply(my_kernel, tf.multiply(alpha_cross, cross_class_label)), [1, 2])\n    return tf.reduce_sum(tf.subtract(term_2, term_1))\n\n\n# Gaussian (RBF) prediction kernel\ndef kernel_pred(x_data, prediction_grid):\n    A = tf.reshape(tf.reduce_sum(tf.square(x_data), 1), [-1, 1])\n    B = tf.reshape(tf.reduce_sum(tf.square(prediction_grid), 1), [-1, 1])\n    square_distance = tf.add(tf.subtract(A, tf.multiply(2., tf.matmul(x_data, tf.transpose(prediction_grid)))),\n                             tf.transpose(B))\n    return tf.exp(tf.multiply(gamma, tf.abs(square_distance)))\n\n\ndef kernel_fn(x_data, gamma):\n    """"""\n    This function generates the RBF kernel.\n    :param x_data: Input data\n    :param gamma: Hyperparamet.\n    :return: The RBF kernel.\n    """"""\n    square_distance = tf.multiply(2., tf.matmul(x_data, tf.transpose(x_data)))\n    kernel = tf.exp(tf.multiply(gamma, tf.abs(square_distance)))\n    return kernel\n\n\ndef prepare_label_fn(label_onehot):\n    """"""\n    Label preparation. Since we are dealing with one vs all scenario, for each sample\n    all the labels other than the current class must be set to -1. It can be done by simply\n    Setting all the zero values to -1 in the return one_hot array for classes.\n\n    :param label_onehot: The input as one_hot label which shape (num_samples,num_classes)\n    :return: The output with the same shape and all zeros tured to -1.\n    """"""\n    labels = label_onehot\n    labels[labels == 0] = -1\n    labels = np.transpose(labels)\n    return labels\n\n\ndef next_batch(X, y, batch_size):\n    """"""\n    Generating a batch of random data.\n    :param x_train:\n    :param batch_size:\n    :return:\n    """"""\n    idx = np.random.choice(len(X), size=batch_size)\n    X_batch = X[idx]\n    y_batch = y[:, idx]\n    return X_batch, y_batch\n\n\n########################\n### Data Preparation ###\n########################\n\n# Read MNIST data. It has a data structure.\n# mnist.train.images, mnist.train.labels: The training set images and their associated labels.\n# mnist.validation.images, mnist.validation.labels: The validation set images and their associated labels.\n# mnist.test.images, mnist.test.labels: The test set images and their associated labels.\n\n# Flags:\n#      ""reshape=True"", by this flag, the data will be reshaped to (num_samples,num_features)\n#      and since each image is 28x28, the num_features = 784\n#      ""one_hot=True"", this flag return one_hot labeling format\n#      ex: sample_label [1 0 0 0 0 0 0 0 0 0] says the sample belongs to the first class.\nmnist = input_data.read_data_sets(""MNIST_data/"", reshape=True, one_hot=True)\n\n# Label preparation.\ny_train = prepare_label_fn(mnist.train.labels)\ny_test = prepare_label_fn(mnist.test.labels)\n\n# Get the number of classes.\nnum_classes = y_train.shape[0]\n\n##########################################\n### Dimensionality Reduction Using PCA ###\n##########################################\npca = PCA(n_components=100)\npca.fit(mnist.train.images)\n\n# print the accumulative variance for the returned principle components.\nprint(""The variance of the chosen components = %{0:.2f}"".format(100 * np.sum(pca.explained_variance_ratio_)))\nx_train = pca.transform(mnist.train.images)\nx_test = pca.transform(mnist.test.images)\nnum_fetures = x_train.shape[1]\n\n############################\n### Graph & Optimization ###\n############################\n# Create graph\nsess = tf.Session()\n\n# Initialize placeholders\ndata_placeholder = tf.placeholder(shape=[None, num_fetures], dtype=tf.float32)\nlabel_placeholder = tf.placeholder(shape=[num_classes, None], dtype=tf.float32)\npred_placeholder = tf.placeholder(shape=[None, num_fetures], dtype=tf.float32)\n\n# The alpha variable for solving the dual optimization problem.\nalpha = tf.Variable(tf.random_normal(shape=[num_classes, FLAGS.batch_size]))\n\n# Gaussian (RBF) kernel\ngamma = tf.constant(FLAGS.gamma)\n\n# RBF kernel\nmy_kernel = kernel_fn(data_placeholder, gamma)\n\n# Loss calculation.\nloss = loss_fn(alpha, label_placeholder)\n\n# Generating the prediction kernel.\npred_kernel = kernel_pred(data_placeholder, pred_placeholder)\n\n#############################\n### Prediction & Accuracy ###\n#############################\nprediction_output = tf.matmul(tf.multiply(label_placeholder, alpha), pred_kernel)\nprediction = tf.arg_max(prediction_output - tf.expand_dims(tf.reduce_mean(prediction_output, 1), 1), 0)\naccuracy = tf.reduce_mean(tf.cast(tf.equal(prediction, tf.argmax(label_placeholder, 0)), tf.float32))\n\n# Optimizer\ntrain_op = tf.train.AdamOptimizer(FLAGS.initial_learning_rate).minimize(loss)\n\n# Variables Initialization.\ninit = tf.global_variables_initializer()\nsess.run(init)\n\n# Training loop\nfor i in range(FLAGS.num_steps):\n\n    batch_X, batch_y = next_batch(x_train, y_train, FLAGS.batch_size)\n    sess.run(train_op, feed_dict={data_placeholder: batch_X, label_placeholder: batch_y})\n\n    temp_loss = sess.run(loss, feed_dict={data_placeholder: batch_X, label_placeholder: batch_y})\n\n    acc_train_batch = sess.run(accuracy, feed_dict={data_placeholder: batch_X,\n                                                   label_placeholder: batch_y,\n                                                   pred_placeholder: batch_X})\n\n    batch_X_test, batch_y_test = next_batch(x_test, y_test, FLAGS.batch_size)\n    acc_test_batch = sess.run(accuracy, feed_dict={data_placeholder: batch_X_test,\n                                                  label_placeholder: batch_y_test,\n                                                  pred_placeholder: batch_X_test})\n\n    if (i + 1) % FLAGS.log_steps == 0:\n        print(\'Step #%d, Loss= %f, training accuracy= %f, testing accuracy= %f \' % (\n            (i+1), temp_loss, acc_train_batch, acc_test_batch))\n'"
codes/3-neural_networks/convolutional-neural-network/code/__init__.py,0,b''
codes/3-neural_networks/convolutional-neural-network/code/test_classifier.py,32,"b'from __future__ import print_function\nfrom tensorflow.examples.tutorials.mnist import input_data\nimport tensorflow as tf\nimport numpy as np\nfrom net_structure import net\nfrom input_function import input\nfrom auxiliary import progress_bar\nimport os\nimport sys\n\n######################################\n######### Necessary Flags ############\n######################################\ntf.app.flags.DEFINE_string(\n    \'evaluation_path\', os.path.dirname(os.path.abspath(__file__)) + \'/test_log\',\n    \'Directory where event logs are written to.\')\n\ntf.app.flags.DEFINE_string(\n    \'checkpoints_directory\',\n    os.path.dirname(os.path.abspath(__file__)) + \'/checkpoints\',\n    \'Directory where checkpoints are written to.\')\n\ntf.app.flags.DEFINE_integer(\'num_classes\', 10,\n                            \'Number of model clones to deploy.\')\n\ntf.app.flags.DEFINE_integer(\'batch_size\', np.power(2, 9),\n                            \'Number of model clones to deploy.\')\n\n#########################################\n########## status flags #################\n#########################################\ntf.app.flags.DEFINE_boolean(\'is_training\', False,\n                            \'Training/Testing.\')\n\ntf.app.flags.DEFINE_boolean(\'allow_soft_placement\', True,\n                            \'Automatically put the variables on CPU if there is no GPU support.\')\n\ntf.app.flags.DEFINE_boolean(\'log_device_placement\', False,\n                            \'Demonstrate which variables are on what device.\')\n\n# Store all elemnts in FLAG structure!\nFLAGS = tf.app.flags.FLAGS\n\n################################################\n################# handling errors!##############\n################################################\nif not os.path.isabs(FLAGS.checkpoints_directory):\n    raise ValueError(\'You must assign absolute path for --checkpoints_directory\')\n\n##########################################\n####### Load and Organize Data ###########\n##########################################\n\'\'\'\nIn this part the input must be prepared.\n\n   1 - The MNIST data will be downloaded.\n   2 - The images and labels for both training and testing will be extracted.\n   3 - The prepared data format(?,784) is different by the appropriate image shape(?,28,28,1) which needs\n        to be fed to the CNN architecture. So it needs to be reshaped.\n\n\'\'\'\n\n# Download and get MNIST dataset(available in tensorflow.contrib.learn.python.learn.datasets.mnist)\n# It checks and download MNIST if it\'s not already downloaded then extract it.\n# The \'reshape\' is True by default to extract feature vectors but we set it to false to we get the original images.\nmnist = input_data.read_data_sets(""MNIST_data/"", reshape=False, one_hot=False)\n\n# The \'input.provide_data\' is provided to organize any custom dataset which has specific characteristics.\ndata = input.provide_data(mnist)\n\n# Dimentionality of train\ndimensionality_train = data.train.images.shape\n\n# Dimensions\nnum_train_samples = dimensionality_train[0]\nheight = dimensionality_train[1]\nwidth = dimensionality_train[2]\nnum_channels = dimensionality_train[3]\n\n#######################################\n########## Defining Graph ############\n#######################################\n\ngraph = tf.Graph()\nwith graph.as_default():\n    ###################################\n    ########### Parameters ############\n    ###################################\n\n    # global step\n    global_step = tf.Variable(0, name=""global_step"", trainable=False)\n\n    ###############################################\n    ########### Defining place holders ############\n    ###############################################\n    image_place = tf.placeholder(tf.float32, shape=([None, height, width, num_channels]), name=\'image\')\n    label_place = tf.placeholder(tf.float32, shape=([None, FLAGS.num_classes]), name=\'gt\')\n    dropout_parameter = tf.placeholder(tf.float32)\n\n    ##################################################\n    ########### Model + loss + accuracy ##############\n    ##################################################\n\n    # MODEL\n    joint_arg_scope = net.net_arg_scope(weight_decay=0.0005, is_training=FLAGS.is_training)\n    with tf.contrib.framework.arg_scope(joint_arg_scope):\n        logits_features, end_points = net.net_architecture(image_place, num_classes=FLAGS.num_classes,\n                                                  dropout_keep_prob=dropout_parameter,\n                                                  is_training=FLAGS.is_training)\n\n    # Define loss\n    with tf.name_scope(\'loss\'):\n        loss_test = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits_features, labels=label_place))\n\n    # Accuracy\n    with tf.name_scope(\'accuracy_test\'):\n        # Evaluate the model\n        correct_test_prediction = tf.equal(tf.argmax(logits_features, 1), tf.argmax(label_place, 1))\n\n        # Accuracy calculation\n        accuracy_test = tf.reduce_mean(tf.cast(correct_test_prediction, tf.float32))\n\n    ###############################################\n    ############ Define Sammaries #################\n    ###############################################\n\n    # Image summaries(draw three random images from data in both training and testing phases)\n    # The image summaries is only cerated for train summaries and it get three random images from the training set.\n    arr = np.random.randint(data.test.images.shape[0], size=(3,))\n    tf.summary.image(\'images\', data.test.images[arr], max_outputs=3,\n                     collections=[\'per_epoch_train\'])\n\n    # Histogram and scalar summaries sammaries\n    # sparsity: This summary is the fraction of zero activation for the output of each layer!\n    # activations: This summary is the histogram of activation for the output of each layer!\n    # WARNING: tf.summary.histogram can be very time consuming so it will be calculated per epoch!\n    for end_point in end_points:\n        x = end_points[end_point]\n        tf.summary.scalar(\'sparsity/\' + end_point,\n                          tf.nn.zero_fraction(x), collections=[\'test\'])\n\n    # Summaries for loss and accuracy\n    tf.summary.scalar(""loss"", loss_test, collections=[\'test\'])\n    tf.summary.scalar(""accuracy_test"", accuracy_test, collections=[\'test\'])\n    tf.summary.scalar(""global_step"", global_step, collections=[\'test\'])\n\n    # Merge all summaries together.\n    summary_test_op = tf.summary.merge_all(\'test\')\n\n    ########################################################\n    ############ # Defining the tensors list ###############\n    ########################################################\n\n    tensors_key = [\'loss_test\', \'accuracy_test\', \'global_step\', \'image_place\', \'label_place\',\n                   \'summary_test_op\']\n    tensors_values = [loss_test, accuracy_test, global_step, image_place, label_place, summary_test_op]\n    tensors = dict(zip(tensors_key, tensors_values))\n\n    ############################################\n    ############ Run the Session ###############\n    ############################################\n    session_conf = tf.ConfigProto(\n        allow_soft_placement=FLAGS.allow_soft_placement,\n        log_device_placement=FLAGS.log_device_placement)\n    sess = tf.Session(graph=graph, config=session_conf)\n\n    with sess.as_default():\n\n        # The saver op.\n        saver = tf.train.Saver()\n\n        # Initialize all variables\n        sess.run(tf.global_variables_initializer())\n\n        ###################################################################\n        ########## Defining the summary writers for test ###########\n        ###################################################################\n\n        test_summary_dir = os.path.join(FLAGS.evaluation_path, ""summaries"", ""test"")\n        test_summary_writer = tf.summary.FileWriter(test_summary_dir)\n        test_summary_writer.add_graph(sess.graph)\n\n        # The prefix for checkpoint files\n        checkpoint_prefix = \'model\'\n\n        # Restoring the saved weights.\n        saver.restore(sess, os.path.join(FLAGS.checkpoints_directory, checkpoint_prefix))\n        print(""Model restored..."")\n\n        ###################################################################\n        ########## Run the training and loop over the batches #############\n        ###################################################################\n        num_test_samples = data.test.images.shape[0]\n        total_batch_test = int(num_test_samples / FLAGS.batch_size)\n\n        # go through the batches\n        test_accuracy = 0\n        for batch_num in range(total_batch_test):\n            #################################################\n            ########## Get the training batches #############\n            #################################################\n\n            start_idx = batch_num * FLAGS.batch_size\n            end_idx = (batch_num + 1) * FLAGS.batch_size\n\n            # Fit training using batch data\n            test_batch_data, test_batch_label = data.test.images[start_idx:end_idx], data.test.labels[\n                                                                                     start_idx:end_idx]\n\n            ########################################\n            ########## Run the session #############\n            ########################################\n\n            # Run session and Calculate batch loss and accuracy\n            # When the tensor tensors[\'global_step\'] is evaluated, it will be incremented by one.\n\n            test_batch_accuracy, batch_loss, test_summaries, test_step = sess.run(\n                [tensors[\'accuracy_test\'], tensors[\'loss_test\'], tensors[\'summary_test_op\'],\n                 tensors[\'global_step\']],\n                feed_dict={tensors[\'image_place\']: test_batch_data,\n                           tensors[\'label_place\']: test_batch_label})\n            test_accuracy += test_batch_accuracy\n\n            ########################################\n            ########## Write summaries #############\n            ########################################\n\n            # Write the summaries\n            test_summary_writer.add_summary(test_summaries, global_step=test_step)\n\n            # # Write the specific summaries for training phase.\n            # train_summary_writer.add_summary(train_image_summary, global_step=training_step)\n\n            #################################################\n            ########## Plot the progressive bar #############\n            #################################################\n\n            progress = float(batch_num + 1) / total_batch_test\n            progress_bar.print_progress(progress, epoch_num=1, loss=batch_loss)\n\n\n        ######################################################################\n        ########## Calculate the accuracy for the whole test set #############\n        ######################################################################\n        test_accuracy_total = test_accuracy / float(total_batch_test)\n        print(""Testing Accuracy= "" + \\\n              ""{:.5f}"".format(test_accuracy_total))\n'"
codes/3-neural_networks/convolutional-neural-network/code/train_classifier.py,45,"b'from __future__ import print_function\nfrom tensorflow.examples.tutorials.mnist import input_data\nimport tensorflow as tf\nimport numpy as np\nfrom net_structure import net\nfrom input_function import input\nimport os\nimport train_evaluation\n\n######################################\n######### Necessary Flags ############\n######################################\n\ntf.app.flags.DEFINE_string(\n    \'train_dir\', os.path.dirname(os.path.abspath(__file__)) + \'/train_logs\',\n    \'Directory where event logs are written to.\')\n\ntf.app.flags.DEFINE_string(\n    \'checkpoint_dir\',\n    os.path.dirname(os.path.abspath(__file__)) + \'/checkpoints\',\n    \'Directory where checkpoints are written to.\')\n\ntf.app.flags.DEFINE_integer(\'max_num_checkpoint\', 10,\n                            \'Maximum number of checkpoints that TensorFlow will keep.\')\n\ntf.app.flags.DEFINE_integer(\'num_classes\', 10,\n                            \'Number of model clones to deploy.\')\n\ntf.app.flags.DEFINE_integer(\'batch_size\', np.power(2, 9),\n                            \'Number of model clones to deploy.\')\n\ntf.app.flags.DEFINE_integer(\'num_epochs\', 1,\n                            \'Number of epochs for training.\')\n\n##########################################\n######## Learning rate flags #############\n##########################################\ntf.app.flags.DEFINE_float(\'initial_learning_rate\', 0.001, \'Initial learning rate.\')\n\ntf.app.flags.DEFINE_float(\n    \'learning_rate_decay_factor\', 0.95, \'Learning rate decay factor.\')\n\ntf.app.flags.DEFINE_float(\n    \'num_epochs_per_decay\', 1, \'Number of epoch pass to decay learning rate.\')\n\n#########################################\n########## status flags #################\n#########################################\ntf.app.flags.DEFINE_boolean(\'is_training\', False,\n                            \'Training/Testing.\')\n\ntf.app.flags.DEFINE_boolean(\'fine_tuning\', False,\n                            \'Fine tuning is desired or not?.\')\n\ntf.app.flags.DEFINE_boolean(\'online_test\', True,\n                            \'Fine tuning is desired or not?.\')\n\ntf.app.flags.DEFINE_boolean(\'allow_soft_placement\', True,\n                            \'Automatically put the variables on CPU if there is no GPU support.\')\n\ntf.app.flags.DEFINE_boolean(\'log_device_placement\', False,\n                            \'Demonstrate which variables are on what device.\')\n\n# Store all elemnts in FLAG structure!\nFLAGS = tf.app.flags.FLAGS\n\n\n################################################\n################# handling errors!##############\n################################################\nif not os.path.isabs(FLAGS.train_dir):\n    raise ValueError(\'You must assign absolute path for --train_dir\')\n\nif not os.path.isabs(FLAGS.checkpoint_dir):\n    raise ValueError(\'You must assign absolute path for --checkpoint_dir\')\n\n##########################################\n####### Load and Organize Data ###########\n##########################################\n\'\'\'\nIn this part the input must be prepared.\n\n   1 - The MNIST data will be downloaded.\n   2 - The images and labels for both training and testing will be extracted.\n   3 - The prepared data format(?,784) is different by the appropriate image shape(?,28,28,1) which needs\n        to be fed to the CNN architecture. So it needs to be reshaped.\n\n\'\'\'\n\n# Download and get MNIST dataset(available in tensorflow.contrib.learn.python.learn.datasets.mnist)\n# It checks and download MNIST if it\'s not already downloaded then extract it.\n# The \'reshape\' is True by default to extract feature vectors but we set it to false to we get the original images.\nmnist = input_data.read_data_sets(""MNIST_data/"", reshape=False, one_hot=False)\n\n# The \'input.provide_data\' is provided to organize any custom dataset which has specific characteristics.\ndata = input.provide_data(mnist)\n\n# Dimentionality of train\ndimensionality_train = data.train.images.shape\n\n# Dimensions\nnum_train_samples = dimensionality_train[0]\nheight = dimensionality_train[1]\nwidth = dimensionality_train[2]\nnum_channels = dimensionality_train[3]\n\n#######################################\n########## Defining Graph ############\n#######################################\n\ngraph = tf.Graph()\nwith graph.as_default():\n    ###################################\n    ########### Parameters ############\n    ###################################\n\n    # global step\n    global_step = tf.Variable(0, name=""global_step"", trainable=False)\n\n    # learning rate policy\n    decay_steps = int(num_train_samples / FLAGS.batch_size *\n                      FLAGS.num_epochs_per_decay)\n    learning_rate = tf.train.exponential_decay(FLAGS.initial_learning_rate,\n                                               global_step,\n                                               decay_steps,\n                                               FLAGS.learning_rate_decay_factor,\n                                               staircase=True,\n                                               name=\'exponential_decay_learning_rate\')\n\n    ###############################################\n    ########### Defining place holders ############\n    ###############################################\n    image_place = tf.placeholder(tf.float32, shape=([None, height, width, num_channels]), name=\'image\')\n    label_place = tf.placeholder(tf.float32, shape=([None, FLAGS.num_classes]), name=\'gt\')\n    dropout_param = tf.placeholder(tf.float32)\n\n    ##################################################\n    ########### Model + Loss + Accuracy ##############\n    ##################################################\n\n    # MODEL\n    arg_scope = net.net_arg_scope(weight_decay=0.0005, is_training=FLAGS.is_training)\n    with tf.contrib.framework.arg_scope(arg_scope):\n        logits, end_points = net.net_architecture(image_place, num_classes=FLAGS.num_classes,\n                                                  dropout_keep_prob=dropout_param,\n                                                  is_training=FLAGS.is_training)\n\n    # Define loss\n    with tf.name_scope(\'loss\'):\n        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=label_place))\n\n    # Accuracy\n    with tf.name_scope(\'accuracy\'):\n        # Evaluate the model\n        correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(label_place, 1))\n\n        # Accuracy calculation\n        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\n    #############################################\n    ########### training operation ##############\n    #############################################\n\n    # Define optimizer by its default values\n    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n\n    # \'train_op\' is a operation that is run for gradient update on parameters.\n    # Each execution of \'train_op\' is a training step.\n    # By passing \'global_step\' to the optimizer, each time that the \'train_op\' is run, Tensorflow\n    # update the \'global_step\' and increment it by one!\n\n    # gradient update.\n    with tf.name_scope(\'train\'):\n        grads_and_vars = optimizer.compute_gradients(loss)\n        train_op = optimizer.apply_gradients(grads_and_vars, global_step=global_step)\n\n    ###############################################\n    ############ Define Sammaries #################\n    ###############################################\n\n    # Image summaries(draw three random images from data in both training and testing phases)\n    # The image summaries is only cerated for train summaries and it get three random images from the training set.\n    arr = np.random.randint(data.train.images.shape[0], size=(3,))\n    tf.summary.image(\'images\', data.train.images[arr], max_outputs=3,\n                     collections=[\'per_epoch_train\'])\n\n    # Histogram and scalar summaries sammaries\n    # sparsity: This summary is the fraction of zero activation for the output of each layer!\n    # activations: This summary is the histogram of activation for the output of each layer!\n    # WARNING: tf.summary.histogram can be very time consuming so it will be calculated per epoch!\n    for end_point in end_points:\n        x = end_points[end_point]\n        tf.summary.scalar(\'sparsity/\' + end_point,\n                          tf.nn.zero_fraction(x), collections=[\'train\', \'test\'])\n        tf.summary.histogram(\'activations/\' + end_point, x, collections=[\'per_epoch_train\'])\n\n    # Summaries for loss and accuracy\n    tf.summary.scalar(""loss"", loss, collections=[\'train\', \'test\'])\n    tf.summary.scalar(""accuracy"", accuracy, collections=[\'train\', \'test\'])\n    tf.summary.scalar(""global_step"", global_step, collections=[\'train\'])\n    tf.summary.scalar(""learning_rate"", learning_rate, collections=[\'train\'])\n\n    # Merge all summaries together.\n    summary_train_op = tf.summary.merge_all(\'train\')\n    summary_test_op = tf.summary.merge_all(\'test\')\n    summary_epoch_train_op = tf.summary.merge_all(\'per_epoch_train\')\n\n    ########################################################\n    ############ # Defining the tensors list ###############\n    ########################################################\n\n    tensors_key = [\'cost\', \'accuracy\', \'train_op\', \'global_step\', \'image_place\', \'label_place\', \'dropout_param\',\n                   \'summary_train_op\', \'summary_test_op\', \'summary_epoch_train_op\']\n    tensors = [loss, accuracy, train_op, global_step, image_place, label_place, dropout_param, summary_train_op,\n               summary_test_op, summary_epoch_train_op]\n    tensors_dictionary = dict(zip(tensors_key, tensors))\n\n    ############################################\n    ############ Run the Session ###############\n    ############################################\n    session_conf = tf.ConfigProto(\n        allow_soft_placement=FLAGS.allow_soft_placement,\n        log_device_placement=FLAGS.log_device_placement)\n    sess = tf.Session(graph=graph, config=session_conf)\n\n    with sess.as_default():\n        # Run the saver.\n        # \'max_to_keep\' flag determines the maximum number of models that the tensorflow save and keep. default by TensorFlow = 5.\n        saver = tf.train.Saver(max_to_keep=FLAGS.max_num_checkpoint)\n\n        # Initialize all variables\n        sess.run(tf.global_variables_initializer())\n\n        ###################################################\n        ############ Training / Evaluation ###############\n        ###################################################\n        train_evaluation.train(sess=sess, saver=saver, tensors=tensors_dictionary, data=data,\n                               train_dir=FLAGS.train_dir,\n                               finetuning=FLAGS.fine_tuning, online_test=FLAGS.online_test,\n                               num_epochs=FLAGS.num_epochs, checkpoint_dir=FLAGS.checkpoint_dir,\n                               batch_size=FLAGS.batch_size)\n\n        # Test in the end of experiment.\n        train_evaluation.evaluation(sess=sess, saver=saver, tensors=tensors_dictionary, data=data,\n                                    checkpoint_dir=FLAGS.checkpoint_dir)\n'"
codes/3-neural_networks/convolutional-neural-network/code/train_evaluation.py,3,"b'from __future__ import print_function\nimport tensorflow as tf\nimport numpy as np\nfrom auxiliary import progress_bar\nimport os\nimport sys\n\n\ndef train(**keywords):\n    """"""\n    This function run the session whether in training or evaluation mode.\n    NOTE: **keywords is defined in order to make the code easily changable.\n    WARNING: All the arguments for the **keywords must be defined when calling this function.\n    **keywords:\n    :param sess: The default session.\n    :param saver: The saver operator to save and load the model weights.\n    :param tensors: The tensors dictionary defined by the graph.\n    :param data: The data structure.\n    :param train_dir: The training dir which is a reference for saving the logs and model checkpoints.\n    :param finetuning: If fine tuning should be done or random initialization is needed.\n    :param num_epochs: Number of epochs for training.\n    :param online_test: If the testing is done while training.\n    :param checkpoint_dir: The directory of the checkpoints.\n    :param batch_size: The training batch size.\n\n    :return:\n             Run the session.\n    """"""\n\n    # The prefix for checkpoint files\n    checkpoint_prefix = \'model\'\n\n    ###################################################################\n    ########## Defining the summary writers for train/test ###########\n    ###################################################################\n\n    train_summary_dir = os.path.join(keywords[\'train_dir\'], ""summaries"", ""train"")\n    train_summary_writer = tf.summary.FileWriter(train_summary_dir)\n    train_summary_writer.add_graph(keywords[\'sess\'].graph)\n\n    test_summary_dir = os.path.join(keywords[\'train_dir\'], ""summaries"", ""test"")\n    test_summary_writer = tf.summary.FileWriter(test_summary_dir)\n    test_summary_writer.add_graph(keywords[\'sess\'].graph)\n\n    # If fie-tuning flag in \'True\' the model will be restored.\n    if keywords[\'finetuning\']:\n        keywords[\'saver\'].restore(keywords[\'sess\'], os.path.join(keywords[\'checkpoint_dir\'], checkpoint_prefix))\n        print(""Model restored for fine-tuning..."")\n\n    ###################################################################\n    ########## Run the training and loop over the batches #############\n    ###################################################################\n    for epoch in range(keywords[\'num_epochs\']):\n        total_batch_training = int(keywords[\'data\'].train.images.shape[0] / keywords[\'batch_size\'])\n\n        # go through the batches\n        for batch_num in range(total_batch_training):\n            #################################################\n            ########## Get the training batches #############\n            #################################################\n\n            start_idx = batch_num * keywords[\'batch_size\']\n            end_idx = (batch_num + 1) * keywords[\'batch_size\']\n\n            # Fit training using batch data\n            train_batch_data, train_batch_label = keywords[\'data\'].train.images[start_idx:end_idx], keywords[\n                                                                                                        \'data\'].train.labels[\n                                                                                                    start_idx:end_idx]\n\n            ########################################\n            ########## Run the session #############\n            ########################################\n\n            # Run optimization op (backprop) and Calculate batch loss and accuracy\n            # When the tensor tensors[\'global_step\'] is evaluated, it will be incremented by one.\n            batch_loss, _, train_summaries, training_step = keywords[\'sess\'].run(\n                [keywords[\'tensors\'][\'cost\'], keywords[\'tensors\'][\'train_op\'], keywords[\'tensors\'][\'summary_train_op\'],\n                 keywords[\'tensors\'][\'global_step\']],\n                feed_dict={keywords[\'tensors\'][\'image_place\']: train_batch_data,\n                           keywords[\'tensors\'][\'label_place\']: train_batch_label,\n                           keywords[\'tensors\'][\'dropout_param\']: 0.5})\n\n            ########################################\n            ########## Write summaries #############\n            ########################################\n\n            # Write the summaries\n            train_summary_writer.add_summary(train_summaries, global_step=training_step)\n\n            # # Write the specific summaries for training phase.\n            # train_summary_writer.add_summary(train_image_summary, global_step=training_step)\n\n            #################################################\n            ########## Plot the progressive bar #############\n            #################################################\n\n            progress = float(batch_num + 1) / total_batch_training\n            progress_bar.print_progress(progress, epoch_num=epoch + 1, loss=batch_loss)\n\n        # ################################################################\n        # ############ Summaries per epoch of training ###################\n        # ################################################################\n        summary_epoch_train_op = keywords[\'tensors\'][\'summary_epoch_train_op\']\n        train_epoch_summaries = keywords[\'sess\'].run(summary_epoch_train_op,\n                                                     feed_dict={keywords[\'tensors\'][\'image_place\']: train_batch_data,\n                                                                keywords[\'tensors\'][\'label_place\']: train_batch_label,\n                                                                keywords[\'tensors\'][\'dropout_param\']: 1.0})\n\n        # Put the summaries to the train summary writer.\n        train_summary_writer.add_summary(train_epoch_summaries, global_step=training_step)\n\n        #####################################################\n        ########## Evaluation on the test data #############\n        #####################################################\n\n        if keywords[\'online_test\']:\n            # WARNING: In this evaluation the whole test data is fed. In case the test data is huge this implementation\n            #          may lead to memory error. In presense of large testing samples, batch evaluation on testing is\n            #          recommended as in the training phase.\n            test_accuracy_epoch, test_summaries = keywords[\'sess\'].run(\n                [keywords[\'tensors\'][\'accuracy\'], keywords[\'tensors\'][\'summary_test_op\']],\n                feed_dict={keywords[\'tensors\'][\'image_place\']: keywords[\'data\'].test.images,\n                           keywords[\'tensors\'][\n                               \'label_place\']: keywords[\'data\'].test.labels,\n                           keywords[\'tensors\'][\n                               \'dropout_param\']: 1.})\n            print(""Epoch "" + str(epoch + 1) + "", Testing Accuracy= "" + \\\n                  ""{:.5f}"".format(test_accuracy_epoch))\n\n            ###########################################################\n            ########## Write the summaries for test phase #############\n            ###########################################################\n\n            # Returning the value of global_step if necessary\n            current_step = tf.train.global_step(keywords[\'sess\'], keywords[\'tensors\'][\'global_step\'])\n\n            # Add the couter of global step for proper scaling between train and test summuries.\n            test_summary_writer.add_summary(test_summaries, global_step=current_step)\n\n    ###########################################################\n    ############ Saving the model checkpoint ##################\n    ###########################################################\n\n    # # The model will be saved when the training is done.\n\n    # Create the path for saving the checkpoints.\n    if not os.path.exists(keywords[\'checkpoint_dir\']):\n        os.makedirs(keywords[\'checkpoint_dir\'])\n\n    # save the model\n    save_path = keywords[\'saver\'].save(keywords[\'sess\'], os.path.join(keywords[\'checkpoint_dir\'], checkpoint_prefix))\n    print(""Model saved in file: %s"" % save_path)\n\n\n    ############################################################################\n    ########## Run the session for pur evaluation on the test data #############\n    ############################################################################\n\n\ndef evaluation(**keywords):\n    # The prefix for checkpoint files\n    checkpoint_prefix = \'model\'\n\n    # Get the input arguments\n    saver = keywords[\'saver\']\n    sess = keywords[\'sess\']\n    checkpoint_dir = keywords[\'checkpoint_dir\']\n    data = keywords[\'data\']\n    accuracy_tensor = keywords[\'tensors\'][\'accuracy\']\n    image_place = keywords[\'tensors\'][\'image_place\']\n    label_place = keywords[\'tensors\'][\'label_place\']\n    dropout_param = keywords[\'tensors\'][\'dropout_param\']\n\n\n    # Restoring the saved weights.\n    saver.restore(sess, os.path.join(checkpoint_dir, checkpoint_prefix))\n    print(""Model restored..."")\n\n    test_set = data.test.images\n    test_label = data.test.labels\n    # Evaluation of the model\n    test_accuracy = 100 * keywords[\'sess\'].run(accuracy_tensor, feed_dict={\n        image_place: test_set,\n        label_place: test_label,\n        dropout_param: 1.})\n\n    print(""Final Test Accuracy is %% %.2f"" % test_accuracy)\n'"
codes/3-neural_networks/multi-layer-perceptron/code/test_classifier.py,29,"b'from __future__ import print_function\nfrom tensorflow.examples.tutorials.mnist import input_data\nimport tensorflow as tf\nimport numpy as np\nimport os\nimport sys\n\n######################################\n######### Necessary Flags ############\n######################################\ntf.app.flags.DEFINE_string(\n    \'test_dir\', os.path.dirname(os.path.abspath(__file__)) + \'/test_logs\',\n    \'Directory where event logs are written to.\')\n\ntf.app.flags.DEFINE_string(\n    \'checkpoint_dir\',\n    os.path.dirname(os.path.abspath(__file__)) + \'/checkpoints\',\n    \'Directory where checkpoints are written to.\')\n\ntf.app.flags.DEFINE_integer(\'num_classes\', 10,\n                            \'Number of model clones to deploy.\')\n\ntf.app.flags.DEFINE_integer(\'batch_size\', np.power(2, 9),\n                            \'Number of model clones to deploy.\')\n\n#########################################\n########## status flags #################\n#########################################\ntf.app.flags.DEFINE_boolean(\'is_training\', False,\n                            \'Training/Testing.\')\n\ntf.app.flags.DEFINE_boolean(\'allow_soft_placement\', True,\n                            \'Automatically put the variables on CPU if there is no GPU support.\')\n\ntf.app.flags.DEFINE_boolean(\'log_device_placement\', False,\n                            \'Demonstrate which variables are on what device.\')\n\n# Store all elemnts in FLAG structure!\nFLAGS = tf.app.flags.FLAGS\n\n################################################\n################# handling errors!##############\n################################################\nif not os.path.isabs(FLAGS.checkpoint_dir):\n    raise ValueError(\'You must assign absolute path for --checkpoint_dir\')\n\n##########################################\n####### Load and Organize Data ###########\n##########################################\n\'\'\'\nIn this part the input must be prepared.\n\n   1 - The MNIST data will be downloaded.\n   2 - The images and labels for both training and testing will be extracted.\n   3 - The prepared data format(?,784) is different by the appropriate image shape(?,28,28,1) which needs\n        to be fed to the CNN architecture. So it needs to be reshaped.\n\n\'\'\'\n\n# Download and get MNIST dataset(available in tensorflow.contrib.learn.python.learn.datasets.mnist)\n# It checks and download MNIST if it\'s not already downloaded then extract it.\n# The \'reshape\' is True by default to extract feature vectors but we set it to false to we get the original images.\nmnist = input_data.read_data_sets(""MNIST_data/"", reshape=True, one_hot=True)\n\n\n# Dimentionality of train\ndimensionality = mnist.train.images.shape\n\n# Dimensions\nnum_train_samples = dimensionality[0]\nnum_features = dimensionality[1]\n\n#######################################\n########## Defining Graph ############\n#######################################\n\ngraph = tf.Graph()\nwith graph.as_default():\n    ###################################\n    ########### Parameters ############\n    ###################################\n\n    # global step\n    global_step = tf.Variable(0, name=""global_step"", trainable=False)\n\n    ###############################################\n    ########### Defining place holders ############\n    ###############################################\n    image_place = tf.placeholder(tf.float32, shape=([None, num_features]), name=\'image\')\n    label_place = tf.placeholder(tf.float32, shape=([None, FLAGS.num_classes]), name=\'gt\')\n    dropout_param = tf.placeholder(tf.float32)\n\n    ##################################################\n    ########### Model + loss + accuracy ##############\n    ##################################################\n\n    # MODEL(MPL with two hidden layer)\n\n    # LAYER-1\n    net = tf.contrib.layers.fully_connected(inputs=image_place, num_outputs=250, scope=\'fc-1\')\n\n    # LAYER-2\n    net = tf.contrib.layers.fully_connected(inputs=net, num_outputs=250, scope=\'fc-2\')\n\n    # SOFTMAX\n    logits_last = tf.contrib.layers.fully_connected(inputs=net, num_outputs=FLAGS.num_classes, scope=\'fc-3\')\n\n    # Define loss\n    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits_last, labels=label_place))\n\n    # Accuracy\n    # Evaluate the model\n    pred_classifier = tf.equal(tf.argmax(logits_last, 1), tf.argmax(label_place, 1))\n\n    # Accuracy calculation\n    accuracy = tf.reduce_mean(tf.cast(pred_classifier, tf.float32))\n\n    ###############################################\n    ############ Define Sammaries #################\n    ###############################################\n\n    # Image summaries(draw three random images from data in both training and testing phases)\n    # The image summaries is only cerated for train summaries and it get three random images from the training set.\n    arr = np.random.randint(mnist.test.images.shape[0], size=(3,))\n    tf.summary.image(\'images\', mnist.test.images[arr], max_outputs=3,\n                     collections=[\'per_epoch_train\'])\n\n\n    # Summaries for loss and accuracy\n    tf.summary.scalar(""loss"", loss, collections=[\'test\'])\n    tf.summary.scalar(""accuracy"", accuracy, collections=[\'test\'])\n    tf.summary.scalar(""global_step"", global_step, collections=[\'test\'])\n\n    # Merge all summaries together.\n    summary_test_op = tf.summary.merge_all(\'test\')\n\n    ########################################################\n    ############ # Defining the tensors list ###############\n    ########################################################\n\n    # tensors_key = [\'loss\', \'accuracy\', \'global_step\', \'image_place\', \'label_place\',\n    #                \'summary_test_op\']\n    # tensors_values = [loss, accuracy, global_step, image_place, label_place, summary_test_op]\n    # tensors = dict(zip(tensors_key, tensors_values))\n\n    ############################################\n    ############ Run the Session ###############\n    ############################################\n    session_conf = tf.ConfigProto(\n        allow_soft_placement=FLAGS.allow_soft_placement,\n        log_device_placement=FLAGS.log_device_placement)\n    sess = tf.Session(graph=graph, config=session_conf)\n\n    with sess.as_default():\n\n        # The saver op.\n        saver = tf.train.Saver()\n\n        # Initialize all variables\n        sess.run(tf.global_variables_initializer())\n\n        ###################################################################\n        ########## Defining the summary writers for test ###########\n        ###################################################################\n\n        test_summary_dir = os.path.join(FLAGS.test_dir, ""summaries"", ""test"")\n        test_summary_writer = tf.summary.FileWriter(test_summary_dir)\n        test_summary_writer.add_graph(sess.graph)\n\n        # The prefix for checkpoint files\n        checkpoint_prefix = \'model\'\n\n        # Restoring the saved weights.\n        saver.restore(sess, os.path.join(FLAGS.checkpoint_dir, checkpoint_prefix))\n        print(""Model restored..."")\n\n        ###################################################################\n        ########## Run the training and loop over the batches #############\n        ###################################################################\n        total_batch_test = int(mnist.test.images.shape[0] / FLAGS.batch_size)\n\n        # go through the batches\n        test_accuracy = 0\n        for batch_num in range(total_batch_test):\n            #################################################\n            ########## Get the training batches #############\n            #################################################\n\n            start_idx = batch_num * FLAGS.batch_size\n            end_idx = (batch_num + 1) * FLAGS.batch_size\n\n            # Fit training using batch data\n            test_batch_data, test_batch_label = mnist.test.images[start_idx:end_idx], mnist.test.labels[\n                                                                                     start_idx:end_idx]\n\n            ########################################\n            ########## Run the session #############\n            ########################################\n\n            # Run session and Calculate batch loss and accuracy\n            # When the tensor tensors[\'global_step\'] is evaluated, it will be incremented by one.\n\n            test_batch_accuracy, batch_loss, test_summaries, test_step = sess.run(\n                [accuracy, loss, summary_test_op,\n                 global_step],\n                feed_dict={image_place: test_batch_data,\n                           label_place: test_batch_label})\n            test_accuracy += test_batch_accuracy\n\n            ########################################\n            ########## Write summaries #############\n            ########################################\n\n            # Write the summaries\n            test_summary_writer.add_summary(test_summaries, global_step=test_step)\n\n            # # Write the specific summaries for training phase.\n            # train_summary_writer.add_summary(train_image_summary, global_step=training_step)\n\n            #################################################\n            ########## Plot the progressive bar #############\n            #################################################\n\n            print(""Batch "" + str(batch_num + 1) + "", Testing Loss= "" + \\\n                  ""{:.5f}"".format(test_batch_accuracy))\n\n\n        ######################################################################\n        ########## Calculate the accuracy for the whole test set #############\n        ######################################################################\n        test_accuracy_total = test_accuracy / float(total_batch_test)\n        print(""Total Test Accuracy= "" + \\\n              ""{:.5f}"".format(test_accuracy_total))\n'"
codes/3-neural_networks/multi-layer-perceptron/code/train_mlp.py,43,"b'from __future__ import print_function\nfrom tensorflow.examples.tutorials.mnist import input_data\nimport tensorflow as tf\nimport numpy as np\nimport os\n\n######################################\n######### Necessary Flags ############\n######################################\n\ntf.app.flags.DEFINE_string(\n    \'train_root\', os.path.dirname(os.path.abspath(__file__)) + \'/train_logs\',\n    \'Directory where event logs are written to.\')\n\ntf.app.flags.DEFINE_string(\n    \'checkpoint_root\',\n    os.path.dirname(os.path.abspath(__file__)) + \'/checkpoints\',\n    \'Directory where checkpoints are written to.\')\n\ntf.app.flags.DEFINE_integer(\'max_num_checkpoint\', 10,\n                            \'Maximum number of checkpoints that TensorFlow will keep.\')\n\ntf.app.flags.DEFINE_integer(\'num_classes\', 10,\n                            \'Number of model clones to deploy.\')\n\ntf.app.flags.DEFINE_integer(\'batch_size\', np.power(2, 7),\n                            \'Number of model clones to deploy.\')\n\ntf.app.flags.DEFINE_integer(\'num_epochs\', 5,\n                            \'Number of epochs for training.\')\n\n##########################################\n######## Learning rate flags #############\n##########################################\ntf.app.flags.DEFINE_float(\'initial_learning_rate\', 0.001, \'Initial learning rate.\')\n\ntf.app.flags.DEFINE_float(\n    \'learning_rate_decay_factor\', 0.95, \'Learning rate decay factor.\')\n\ntf.app.flags.DEFINE_float(\n    \'num_epochs_per_decay\', 1, \'Number of epoch pass to decay learning rate.\')\n\n#########################################\n########## status flags #################\n#########################################\ntf.app.flags.DEFINE_boolean(\'is_training\', False,\n                            \'Training/Testing.\')\n\ntf.app.flags.DEFINE_boolean(\'fine_tuning\', False,\n                            \'Fine tuning is desired or not?.\')\n\ntf.app.flags.DEFINE_boolean(\'online_test\', True,\n                            \'Fine tuning is desired or not?.\')\n\ntf.app.flags.DEFINE_boolean(\'allow_soft_placement\', True,\n                            \'Automatically put the variables on CPU if there is no GPU support.\')\n\ntf.app.flags.DEFINE_boolean(\'log_device_placement\', False,\n                            \'Demonstrate which variables are on what device.\')\n\n# Store all elemnts in FLAG structure!\nFLAGS = tf.app.flags.FLAGS\n\n################################################\n################# handling errors!##############\n################################################\nif not os.path.isabs(FLAGS.train_root):\n    raise ValueError(\'You must assign absolute path for --train_root\')\n\nif not os.path.isabs(FLAGS.checkpoint_root):\n    raise ValueError(\'You must assign absolute path for --checkpoint_root\')\n\n##########################################\n####### Load and Organize Data ###########\n##########################################\n\'\'\'\nIn this part the input must be prepared.\n\n   1 - The MNIST data will be downloaded.\n   2 - The images and labels for both training and testing will be extracted.\n   3 - The prepared data format(?,784) is different by the appropriate image shape(?,28,28,1) which needs\n        to be fed to the CNN architecture. So it needs to be reshaped.\n\n\'\'\'\n\n# Download and get MNIST dataset(available in tensorflow.contrib.learn.python.learn.datasets.mnist)\n# It checks and download MNIST if it\'s not already downloaded then extract it.\n# The \'reshape\' is True by default to extract feature vectors but we set it to false to we get the original images.\nmnist = input_data.read_data_sets(""MNIST_data/"", reshape=True, one_hot=True)\ntrain_data = mnist.train.images\ntrain_label = mnist.train.labels\ntest_data = mnist.test.images\ntest_label = mnist.test.labels\n\n# # The \'input.provide_data\' is provided to organize any custom dataset which has specific characteristics.\n# data = input.provide_data(mnist)\n\n# Dimentionality of train\ndimensionality_train = train_data.shape\n\n# Dimensions\nnum_train_samples = dimensionality_train[0]\nnum_features = dimensionality_train[1]\n\n#######################################\n########## Defining Graph ############\n#######################################\n\ngraph = tf.Graph()\nwith graph.as_default():\n    ###################################\n    ########### Parameters ############\n    ###################################\n\n    # global step\n    global_step = tf.Variable(0, name=""global_step"", trainable=False)\n\n    # learning rate policy\n    decay_steps = int(num_train_samples / FLAGS.batch_size *\n                      FLAGS.num_epochs_per_decay)\n    learning_rate = tf.train.exponential_decay(FLAGS.initial_learning_rate,\n                                               global_step,\n                                               decay_steps,\n                                               FLAGS.learning_rate_decay_factor,\n                                               staircase=True,\n                                               name=\'exponential_decay_learning_rate\')\n\n    ###############################################\n    ########### Defining place holders ############\n    ###############################################\n    image_place = tf.placeholder(tf.float32, shape=([None, num_features]), name=\'image\')\n    label_place = tf.placeholder(tf.float32, shape=([None, FLAGS.num_classes]), name=\'gt\')\n    dropout_param = tf.placeholder(tf.float32)\n\n    ##################################################\n    ########### Model + Loss + Accuracy ##############\n    ##################################################\n\n    # MODEL(MPL with two hidden layer)\n\n    # LAYER-1\n    net = tf.contrib.layers.fully_connected(inputs=image_place, num_outputs=250, scope=\'fc-1\')\n\n    # LAYER-2\n    net = tf.contrib.layers.fully_connected(inputs=net, num_outputs=250, scope=\'fc-2\')\n\n    # SOFTMAX\n    logits_pre_softmax = tf.contrib.layers.fully_connected(inputs=net, num_outputs=FLAGS.num_classes, scope=\'fc-3\')\n\n    # Define loss\n    softmax_loss = tf.reduce_mean(\n        tf.nn.softmax_cross_entropy_with_logits(logits=logits_pre_softmax, labels=label_place))\n\n    # Accuracy\n    accuracy = tf.reduce_mean(\n        tf.cast(tf.equal(tf.argmax(logits_pre_softmax, 1), tf.argmax(label_place, 1)), tf.float32))\n\n    #############################################\n    ########### training operation ##############\n    #############################################\n\n    # Define optimizer by its default values\n    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n\n    # \'train_op\' is a operation that is run for gradient update on parameters.\n    # Each execution of \'train_op\' is a training step.\n    # By passing \'global_step\' to the optimizer, each time that the \'train_op\' is run, Tensorflow\n    # update the \'global_step\' and increment it by one!\n\n    # gradient update.\n    with tf.name_scope(\'train_scope\'):\n        grads = optimizer.compute_gradients(softmax_loss)\n        train_op = optimizer.apply_gradients(grads, global_step=global_step)\n\n    ###############################################\n    ############ Define Sammaries #################\n    ###############################################\n\n    # Summaries for loss and accuracy\n    tf.summary.scalar(""loss"", softmax_loss, collections=[\'train\', \'test\'])\n    tf.summary.scalar(""accuracy"", accuracy, collections=[\'train\', \'test\'])\n    tf.summary.scalar(""global_step"", global_step, collections=[\'train\'])\n    tf.summary.scalar(""learning_rate"", learning_rate, collections=[\'train\'])\n\n    # Merge all summaries together.\n    summary_train_op = tf.summary.merge_all(\'train\')\n    summary_test_op = tf.summary.merge_all(\'test\')\n\n    ############################################\n    ############ Run the Session ###############\n    ############################################\n    session_conf = tf.ConfigProto(\n        allow_soft_placement=FLAGS.allow_soft_placement,\n        log_device_placement=FLAGS.log_device_placement)\n    sess = tf.Session(graph=graph, config=session_conf)\n\n    with sess.as_default():\n        # Run the saver.\n        # \'max_to_keep\' flag determines the maximum number of models that the tensorflow save and keep. default by TensorFlow = 5.\n        saver = tf.train.Saver(max_to_keep=FLAGS.max_num_checkpoint)\n\n        # Initialize all variables\n        sess.run(tf.global_variables_initializer())\n\n        ###################################################\n        ############ Training / Evaluation ###############\n        ###################################################\n\n        # The prefix for checkpoint files\n        checkpoint_prefix = \'model\'\n\n        ###################################################################\n        ########## Defining the summary writers for train/test ###########\n        ###################################################################\n\n        train_summary_dir = os.path.join(FLAGS.train_root, ""summaries"", ""train"")\n        train_summary_writer = tf.summary.FileWriter(train_summary_dir)\n        train_summary_writer.add_graph(sess.graph)\n\n        test_summary_dir = os.path.join(FLAGS.train_root, ""summaries"", ""test"")\n        test_summary_writer = tf.summary.FileWriter(test_summary_dir)\n        test_summary_writer.add_graph(sess.graph)\n\n        # If fine-tuning flag in \'True\' the model will be restored.\n        if FLAGS.fine_tuning:\n            saver.restore(sess, os.path.join(FLAGS.checkpoint_root, checkpoint_prefix))\n            print(""Model restored for fine-tuning..."")\n\n        ###################################################################\n        ########## Run the training and loop over the batches #############\n        ###################################################################\n        for epoch in range(FLAGS.num_epochs):\n            total_batch_training = int(train_data.shape[0] / FLAGS.batch_size)\n\n            # go through the batches\n            for batch_num in range(total_batch_training):\n                #################################################\n                ########## Get the training batches #############\n                #################################################\n\n                start_idx = batch_num * FLAGS.batch_size\n                end_idx = (batch_num + 1) * FLAGS.batch_size\n\n                # Fit training using batch data\n                train_batch_data, train_batch_label = train_data[start_idx:end_idx], train_label[\n                                                                                     start_idx:end_idx]\n\n                ########################################\n                ########## Run the session #############\n                ########################################\n\n                # Run optimization op (backprop) and Calculate batch loss and accuracy\n                # When the tensor tensors[\'global_step\'] is evaluated, it will be incremented by one.\n                batch_loss, _, train_summaries, training_step = sess.run(\n                    [softmax_loss, train_op,\n                     summary_train_op,\n                     global_step],\n                    feed_dict={image_place: train_batch_data,\n                               label_place: train_batch_label,\n                               dropout_param: 0.5})\n\n                ########################################\n                ########## Write summaries #############\n                ########################################\n\n                # Write the summaries\n                train_summary_writer.add_summary(train_summaries, global_step=training_step)\n\n                # # Write the specific summaries for training phase.\n                # train_summary_writer.add_summary(train_image_summary, global_step=training_step)\n\n                #################################################\n                ########## Plot the progressive bar #############\n                #################################################\n\n            print(""Epoch #"" + str(epoch + 1) + "", Train Loss="" + \\\n                  ""{:.3f}"".format(batch_loss))\n\n            #####################################################\n            ########## Evaluation on the test data #############\n            #####################################################\n\n            if FLAGS.online_test:\n                # WARNING: In this evaluation the whole test data is fed. In case the test data is huge this implementation\n                #          may lead to memory error. In presense of large testing samples, batch evaluation on testing is\n                #          recommended as in the training phase.\n                test_accuracy_epoch, test_summaries = sess.run(\n                    [accuracy, summary_test_op],\n                    feed_dict={image_place: test_data,\n                               label_place: test_label,\n                               dropout_param: 1.})\n                print(""Test Accuracy= "" + \\\n                      ""{:.4f}"".format(test_accuracy_epoch))\n\n                ###########################################################\n                ########## Write the summaries for test phase #############\n                ###########################################################\n\n                # Returning the value of global_step if necessary\n                current_step = tf.train.global_step(sess, global_step)\n\n                # Add the couter of global step for proper scaling between train and test summuries.\n                test_summary_writer.add_summary(test_summaries, global_step=current_step)\n\n        ###########################################################\n        ############ Saving the model checkpoint ##################\n        ###########################################################\n\n        # # The model will be saved when the training is done.\n\n        # Create the path for saving the checkpoints.\n        if not os.path.exists(FLAGS.checkpoint_root):\n            os.makedirs(FLAGS.checkpoint_root)\n\n        # save the model\n        save_path = saver.save(sess, os.path.join(FLAGS.checkpoint_root, checkpoint_prefix))\n        print(""Model saved in file: %s"" % save_path)\n\n        ############################################################################\n        ########## Run the session for pur evaluation on the test data #############\n        ############################################################################\n\n        # The prefix for checkpoint files\n        checkpoint_prefix = \'model\'\n\n        # Restoring the saved weights.\n        saver.restore(sess, os.path.join(FLAGS.checkpoint_root, checkpoint_prefix))\n        print(""Model restored..."")\n\n        # Evaluation of the model\n        total_test_accuracy = sess.run(accuracy, feed_dict={\n            image_place: test_data,\n            label_place: test_label,\n            dropout_param: 1.})\n\n        print(""Final Test Accuracy is %.2f"" % total_test_accuracy)\n'"
codes/3-neural_networks/recurrent-neural-networks/code/rnn.py,21,"b'import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport argparse\n\n# Useful function for arguments.\ndef str2bool(v):\n    return v.lower() in (""yes"", ""true"")\n\n# Parser\nparser = argparse.ArgumentParser(description=\'Creating Classifier\')\n\n######################\n# Optimization Flags #\n######################\n\ntf.app.flags.DEFINE_float(\'learning_rate\', default=0.001, help=\'initial learning rate\')\ntf.app.flags.DEFINE_integer(\'seed\', default=111, help=\'seed\')\n\n##################\n# Training Flags #\n##################\ntf.app.flags.DEFINE_integer(\'batch_size\', default=128, help=\'Batch size for training\')\ntf.app.flags.DEFINE_integer(\'num_epoch\', default=10, help=\'Number of training iterations\')\ntf.app.flags.DEFINE_integer(\'batch_per_log\', default=10, help=\'Print the log at what number of batches?\')\n\n###############\n# Model Flags #\n###############\ntf.app.flags.DEFINE_integer(\'hidden_size\', default=128, help=\'Number of neurons for RNN hodden layer\')\n\n# Store all elemnts in FLAG structure!\nargs = tf.app.flags.FLAGS\n\n\n# Reset the graph set the random numbers to be the same using ""seed""\ntf.reset_default_graph()\ntf.set_random_seed(args.seed)\nnp.random.seed(args.seed)\n\n# Divide 28x28 images to rows of data to feed to RNN as sequantial information\nstep_size = 28\ninput_size = 28\noutput_size = 10\n\n# Input tensors\nX = tf.placeholder(tf.float32, [None, step_size, input_size])\ny = tf.placeholder(tf.int32, [None])\n\n# Rnn\ncell = tf.nn.rnn_cell.BasicRNNCell(num_units=args.hidden_size)\noutput, state = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n\n# Forward pass and loss calcualtion\nlogits = tf.layers.dense(state, output_size)\ncross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\nloss = tf.reduce_mean(cross_entropy)\n\n# optimizer\noptimizer = tf.train.AdamOptimizer(learning_rate=args.learning_rate).minimize(loss)\n\n# Prediction\nprediction = tf.nn.in_top_k(logits, y, 1)\naccuracy = tf.reduce_mean(tf.cast(prediction, tf.float32))\n\n# input data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""MNIST_data/"")\n\n# Process MNIST\nX_test = mnist.test.images # X_test shape: [num_test, 28*28]\nX_test = X_test.reshape([-1, step_size, input_size])\ny_test = mnist.test.labels\n\n# initialize the variables\ninit = tf.global_variables_initializer()\n\n# Empty list for tracking\nloss_train_list = []\nacc_train_list = []\n\n# train the model\nwith tf.Session() as sess:\n    sess.run(init)\n    n_batches = mnist.train.num_examples // args.batch_size\n    for epoch in range(args.num_epoch):\n        for batch in range(n_batches):\n            X_train, y_train = mnist.train.next_batch(args.batch_size)\n            X_train = X_train.reshape([-1, step_size, input_size])\n            sess.run(optimizer, feed_dict={X: X_train, y: y_train})\n        loss_train, acc_train = sess.run(\n            [loss, accuracy], feed_dict={X: X_train, y: y_train})\n        loss_train_list.append(loss_train)\n        acc_train_list.append(acc_train)\n        print(\'Epoch: {}, Train Loss: {:.3f}, Train Acc: {:.3f}\'.format(\n            epoch + 1, loss_train, acc_train))\n    loss_test, acc_test = sess.run(\n        [loss, accuracy], feed_dict={X: X_test, y: y_test})\n    print(\'Test Loss: {:.3f}, Test Acc: {:.3f}\'.format(loss_test, acc_test))\n'"
codes/3-neural_networks/undercomplete-autoencoder/code/autoencoder.py,6,"b'# An undercomplete autoencoder on MNIST dataset\nfrom __future__ import division, print_function, absolute_import\nimport tensorflow.contrib.layers as lays\n\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom skimage import transform\nfrom tensorflow.examples.tutorials.mnist import input_data\n\nbatch_size = 500  # Number of samples in each batch\nepoch_num = 5     # Number of epochs to train the network\nlr = 0.001        # Learning rate\n\n\ndef resize_batch(imgs):\n    # A function to resize a batch of MNIST images to (32, 32)\n    # Args:\n    #   imgs: a numpy array of size [batch_size, 28 X 28].\n    # Returns:\n    #   a numpy array of size [batch_size, 32, 32].\n    imgs = imgs.reshape((-1, 28, 28, 1))\n    resized_imgs = np.zeros((imgs.shape[0], 32, 32, 1))\n    for i in range(imgs.shape[0]):\n        resized_imgs[i, ..., 0] = transform.resize(imgs[i, ..., 0], (32, 32))\n    return resized_imgs\n\n\ndef autoencoder(inputs):\n    # encoder\n    # 32 x 32 x 1   ->  16 x 16 x 32\n    # 16 x 16 x 32  ->  8 x 8 x 16\n    # 8 x 8 x 16    ->  2 x 2 x 8\n    net = lays.conv2d(inputs, 32, [5, 5], stride=2, padding=\'SAME\')\n    net = lays.conv2d(net, 16, [5, 5], stride=2, padding=\'SAME\')\n    net = lays.conv2d(net, 8, [5, 5], stride=4, padding=\'SAME\')\n    # decoder\n    # 2 x 2 x 8    ->  8 x 8 x 16\n    # 8 x 8 x 16   ->  16 x 16 x 32\n    # 16 x 16 x 32  ->  32 x 32 x 1\n    net = lays.conv2d_transpose(net, 16, [5, 5], stride=4, padding=\'SAME\')\n    net = lays.conv2d_transpose(net, 32, [5, 5], stride=2, padding=\'SAME\')\n    net = lays.conv2d_transpose(net, 1, [5, 5], stride=2, padding=\'SAME\', activation_fn=tf.nn.tanh)\n    return net\n\n# read MNIST dataset\nmnist = input_data.read_data_sets(""MNIST_data"", one_hot=True)\n\n# calculate the number of batches per epoch\nbatch_per_ep = mnist.train.num_examples // batch_size\n\nae_inputs = tf.placeholder(tf.float32, (None, 32, 32, 1))  # input to the network (MNIST images)\nae_outputs = autoencoder(ae_inputs)  # create the Autoencoder network\n\n# calculate the loss and optimize the network\nloss = tf.reduce_mean(tf.square(ae_outputs - ae_inputs))  # claculate the mean square error loss\ntrain_op = tf.train.AdamOptimizer(learning_rate=lr).minimize(loss)\n\n# initialize the network\ninit = tf.global_variables_initializer()\n\nwith tf.Session() as sess:\n    sess.run(init)\n    for ep in range(epoch_num):  # epochs loop\n        for batch_n in range(batch_per_ep):  # batches loop\n            batch_img, batch_label = mnist.train.next_batch(batch_size)  # read a batch\n            batch_img = batch_img.reshape((-1, 28, 28, 1))               # reshape each sample to an (28, 28) image\n            batch_img = resize_batch(batch_img)                          # reshape the images to (32, 32)\n            _, c = sess.run([train_op, loss], feed_dict={ae_inputs: batch_img})\n            print(\'Epoch: {} - cost= {:.5f}\'.format((ep + 1), c))\n\n    # test the trained network\n    batch_img, batch_label = mnist.test.next_batch(50)\n    batch_img = resize_batch(batch_img)\n    recon_img = sess.run([ae_outputs], feed_dict={ae_inputs: batch_img})[0]\n\n    # plot the reconstructed images and their ground truths (inputs)\n    plt.figure(1)\n    plt.title(\'Reconstructed Images\')\n    for i in range(50):\n        plt.subplot(5, 10, i+1)\n        plt.imshow(recon_img[i, ..., 0], cmap=\'gray\')\n\n    plt.figure(2)\n    plt.title(\'Input Images\')\n    for i in range(50):\n        plt.subplot(5, 10, i+1)\n        plt.imshow(batch_img[i, ..., 0], cmap=\'gray\')\n    plt.show()\n\n'"
codes/3-neural_networks/convolutional-neural-network/code/auxiliary/__init__.py,0,b''
codes/3-neural_networks/convolutional-neural-network/code/auxiliary/progress_bar.py,0,"b'import sys\n\n\ndef print_progress(progress, epoch_num, loss):\n    """"""\n    This function draw an active progress bar.\n    :param progress: Where we are:\n                       type: float\n                       value: [0,1]\n    :param epoch_num: number of epochs for training\n    :param loss: The loss for the specific batch in training phase.\n\n    :return: Progressing bar\n    """"""\n\n    # Define the length of bar\n    barLength = 30\n\n    # Ceck the input!\n    assert type(progress) is float, ""id is not a float: %r"" % id\n    assert 0 <= progress <= 1, ""variable should be between zero and one!""\n\n    # Empty status while processing.\n    status = """"\n\n    # This part is to make a new line when the process is finished.\n    if progress >= 1:\n        progress = 1\n        status = ""\\r\\n""\n\n    # Where we are in the progress!\n    indicator = int(round(barLength*progress))\n\n    # Print the appropriate progress phase!\n    list = [str(epoch_num), ""#""*indicator , ""-""*(barLength-indicator), progress*100, loss, status]\n    text = ""\\rEpoch {0[0]} {0[1]} {0[2]} %{0[3]:.2f} loss={0[4]:.3f} {0[5]}"".format(list)\n    sys.stdout.write(text)\n    sys.stdout.flush()\n'"
codes/3-neural_networks/convolutional-neural-network/code/input_function/__init__.py,0,b''
codes/3-neural_networks/convolutional-neural-network/code/input_function/input.py,0,"b'import numpy as np\nimport collections\n\n\nclass DATA_OBJECT(object):\n    def __init__(self,\n                 images,\n                 labels,\n                 num_classes=0,\n                 one_hot=False,\n                 dtype=np.float32,\n                 reshape=False):\n        """"""Data object construction.\n         images: The images of size [num_samples, rows, columns, depth].\n         labels: The labels of size [num_samples,]\n         num_classes: The number of classes in case one_hot labeling is desired.\n         one_hot=False: Turn the labels into one_hot format.\n         dtype=np.float32: The data type.\n         reshape=False: Reshape in case the feature vector extraction is desired.\n\n        """"""\n        # Define the date type.\n        if dtype not in (np.uint8, np.float32):\n            raise TypeError(\'Invalid image dtype %r, expected uint8 or float32\' %\n                            dtype)\n        assert images.shape[0] == labels.shape[0], (\n            \'images.shape: %s labels.shape: %s\' % (images.shape, labels.shape))\n        self._num_samples = images.shape[0]\n\n        # [num_examples, rows, columns, depth] -> [num_examples, rows*columns]\n        if reshape:\n            assert images.shape[3] == 1\n            images = images.reshape(images.shape[0],\n                                    images.shape[1] * images.shape[2])\n\n        # Conver to float if necessary\n        if dtype == np.float32:\n            # Convert from [0, 255] -> [0.0, 1.0].\n            images = images.astype(dtype)\n            images = np.multiply(images, 1.0 / 255.0)\n        self._images = images\n        self._labels = labels\n\n        # If the one_hot flag is true, then the one_hot labeling supersedes the normal labeling.\n        if one_hot:\n            # If the one_hot labeling is desired, number of classes must be defined as one of the arguments of DATA_OBJECT class!\n            assert num_classes != 0, (\n                \'You must specify the num_classes in the DATA_OBJECT for one_hot label construction!\')\n\n            # Define the indexes.\n            index = np.arange(self._num_samples) * num_classes\n            one_hot_labels = np.zeros((self._num_samples, num_classes))\n            one_hot_labels.flat[index + labels.ravel()] = 1\n            self._labels = one_hot_labels\n\n    @property\n    def images(self):\n        return self._images\n\n    @property\n    def labels(self):\n        return self._labels\n\n    @property\n    def num_samples(self):\n        return self._num_samples\n\n\ndef provide_data(mnist):\n    """"""\n    This function provide data object with desired shape.\n    The attribute of data object:\n        - train\n        - validation\n        - test\n    The sub attributs of the data object attributes:\n        -images\n        -labels\n\n    :param mnist: The downloaded MNIST dataset\n    :return: data: The data object.\n                   ex: data.train.images return the images of the dataset object in the training set!\n\n\n    """"""\n    ################################################\n    ########## Get the images and labels############\n    ################################################\n\n    # Note: This setup is specific to mnist data but can be generalized for any data.\n    # The ?_images(? can be train, validation or test) must have the format of [num_samples, rows, columns, depth] after extraction from data.\n    # The ?_labels(? can be train, validation or test) must have the format of [num_samples,] after extraction from data.\n    train_images = mnist.train.images\n    train_labels = mnist.train.labels\n    validation_images = mnist.validation.images\n    validation_labels = mnist.validation.labels\n    test_images = mnist.test.images\n    test_labels = mnist.test.labels\n\n    # Create separate objects for train, validation & test.\n    train = DATA_OBJECT(train_images, train_labels, num_classes=10, one_hot=True, dtype=np.float32, reshape=False)\n    validation = DATA_OBJECT(validation_images, validation_labels, num_classes=10, one_hot=True, dtype=np.float32,\n                             reshape=False)\n    test = DATA_OBJECT(test_images, test_labels, num_classes=10, one_hot=True, dtype=np.float32, reshape=False)\n\n    # Create the whole data object\n    DataSetObject = collections.namedtuple(\'DataSetObject\', [\'train\', \'validation\', \'test\'])\n    data = DataSetObject(train=train, validation=validation, test=test)\n\n    return data\n'"
codes/3-neural_networks/convolutional-neural-network/code/net_structure/__init__.py,0,b''
codes/3-neural_networks/convolutional-neural-network/code/net_structure/net.py,19,"b'#####################################\n# With some tiny modification, this code is the one used by Tensorflow slim at:\n# https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim\n# Please refer to the link for further explanations.\n\n### The difference is this architecture is written in fully-convolutional fashion.\n### The advantage is that, this model can be used for larger image sizes with some average pooling in the last layer.\n\nimport tensorflow as tf\n\nslim = tf.contrib.slim\n\n\ndef net_architecture(images, num_classes=10, is_training=False,\n                     dropout_keep_prob=0.5,\n                     spatial_squeeze=True,\n                     scope=\'Net\'):\n    """"""Creates a variant of the Net model.\n\n    Args:\n      images: The batch of `Tensors`: size [batch_size, height, width, channels].\n      num_classes: Total number of classes.\n      is_training: Training/Validation.\n      dropout_keep_prob: The percentage of activation values: Only active in training mode!\n      scope: Variable_scope.\n\n    Returns:\n      logits: the pre-softmax activations of size [batch_size, `num_classes`]\n      end_points: The dictionary for the layers outputs.\n    """"""\n\n    # Create empty dictionary\n    end_points = {}\n\n    with tf.variable_scope(scope, \'Net\', [images, num_classes]) as sc:\n        end_points_collection = sc.name + \'_end_points\'\n\n        # Collect outputs for conv2d and max_pool2d.\n        with tf.contrib.framework.arg_scope([tf.contrib.layers.conv2d, tf.contrib.layers.max_pool2d],\n                                            outputs_collections=end_points_collection):\n            # Layer-1\n            net = tf.contrib.layers.conv2d(images, 32, [5, 5], scope=\'conv1\')\n            net = tf.contrib.layers.max_pool2d(net, [2, 2], 2, scope=\'pool1\')\n\n            # Layer-2\n            net = tf.contrib.layers.conv2d(net, 64, [5, 5], scope=\'conv2\')\n            net = tf.contrib.layers.max_pool2d(net, [2, 2], 2, scope=\'pool2\')\n\n            # Layer-3\n            net = tf.contrib.layers.conv2d(net, 1024, [7, 7], padding=\'VALID\', scope=\'fc3\')\n            net = tf.contrib.layers.dropout(net, dropout_keep_prob, is_training=is_training,\n                                            scope=\'dropout3\')\n\n            # Last layer which is the logits for classes\n            logits = tf.contrib.layers.conv2d(net, num_classes, [1, 1], activation_fn=None, scope=\'fc4\')\n\n            # Return the collections as a dictionary\n            end_points = slim.utils.convert_collection_to_dict(end_points_collection)\n\n            # Squeeze spatially to eliminate extra dimensions.(embedding layer)\n            if spatial_squeeze:\n                logits = tf.squeeze(logits, [1, 2], name=\'fc4/squeezed\')\n                end_points[sc.name + \'/fc4\'] = logits\n            return logits, end_points\n\n\ndef net_arg_scope(weight_decay=0.0005, is_training=False):\n    """"""Defines the default network argument scope.\n\n    Args:\n      weight_decay: The weight decay to use for regularizing the model.\n\n    Returns:\n      An `arg_scope` to use for the model.\n    """"""\n    if is_training:\n        with tf.contrib.framework.arg_scope(\n                [tf.contrib.layers.conv2d],\n                padding=\'SAME\',\n                weights_regularizer=slim.l2_regularizer(weight_decay),\n                weights_initializer=tf.contrib.layers.variance_scaling_initializer(factor=1.0, mode=\'FAN_AVG\',\n                                                                                   uniform=False, seed=None,\n                                                                                   dtype=tf.float32),\n                activation_fn=tf.nn.relu) as sc:\n            return sc\n\n    else:\n        with tf.contrib.framework.arg_scope(\n                [tf.contrib.layers.conv2d],\n                padding=\'SAME\',\n                activation_fn=tf.nn.relu) as sc:\n            return sc\n\n'"
