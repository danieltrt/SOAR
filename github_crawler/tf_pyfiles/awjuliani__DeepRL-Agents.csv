file_path,api_count,code
gridworld.py,0,"b'import numpy as np\nimport random\nimport itertools\nimport scipy.misc\nimport matplotlib.pyplot as plt\n\n\nclass gameOb():\n    def __init__(self,coordinates,size,intensity,channel,reward,name):\n        self.x = coordinates[0]\n        self.y = coordinates[1]\n        self.size = size\n        self.intensity = intensity\n        self.channel = channel\n        self.reward = reward\n        self.name = name\n        \nclass gameEnv():\n    def __init__(self,partial,size):\n        self.sizeX = size\n        self.sizeY = size\n        self.actions = 4\n        self.objects = []\n        self.partial = partial\n        a = self.reset()\n        plt.imshow(a,interpolation=""nearest"")\n        \n        \n    def reset(self):\n        self.objects = []\n        hero = gameOb(self.newPosition(),1,1,2,None,\'hero\')\n        self.objects.append(hero)\n        bug = gameOb(self.newPosition(),1,1,1,1,\'goal\')\n        self.objects.append(bug)\n        hole = gameOb(self.newPosition(),1,1,0,-1,\'fire\')\n        self.objects.append(hole)\n        bug2 = gameOb(self.newPosition(),1,1,1,1,\'goal\')\n        self.objects.append(bug2)\n        hole2 = gameOb(self.newPosition(),1,1,0,-1,\'fire\')\n        self.objects.append(hole2)\n        bug3 = gameOb(self.newPosition(),1,1,1,1,\'goal\')\n        self.objects.append(bug3)\n        bug4 = gameOb(self.newPosition(),1,1,1,1,\'goal\')\n        self.objects.append(bug4)\n        state = self.renderEnv()\n        self.state = state\n        return state\n\n    def moveChar(self,direction):\n        # 0 - up, 1 - down, 2 - left, 3 - right\n        hero = self.objects[0]\n        heroX = hero.x\n        heroY = hero.y\n        penalize = 0.\n        if direction == 0 and hero.y >= 1:\n            hero.y -= 1\n        if direction == 1 and hero.y <= self.sizeY-2:\n            hero.y += 1\n        if direction == 2 and hero.x >= 1:\n            hero.x -= 1\n        if direction == 3 and hero.x <= self.sizeX-2:\n            hero.x += 1     \n        if hero.x == heroX and hero.y == heroY:\n            penalize = 0.0\n        self.objects[0] = hero\n        return penalize\n    \n    def newPosition(self):\n        iterables = [ range(self.sizeX), range(self.sizeY)]\n        points = []\n        for t in itertools.product(*iterables):\n            points.append(t)\n        currentPositions = []\n        for objectA in self.objects:\n            if (objectA.x,objectA.y) not in currentPositions:\n                currentPositions.append((objectA.x,objectA.y))\n        for pos in currentPositions:\n            points.remove(pos)\n        location = np.random.choice(range(len(points)),replace=False)\n        return points[location]\n\n    def checkGoal(self):\n        others = []\n        for obj in self.objects:\n            if obj.name == \'hero\':\n                hero = obj\n            else:\n                others.append(obj)\n        ended = False\n        for other in others:\n            if hero.x == other.x and hero.y == other.y:\n                self.objects.remove(other)\n                if other.reward == 1:\n                    self.objects.append(gameOb(self.newPosition(),1,1,1,1,\'goal\'))\n                else: \n                    self.objects.append(gameOb(self.newPosition(),1,1,0,-1,\'fire\'))\n                return other.reward,False\n        if ended == False:\n            return 0.0,False\n\n    def renderEnv(self):\n        #a = np.zeros([self.sizeY,self.sizeX,3])\n        a = np.ones([self.sizeY+2,self.sizeX+2,3])\n        a[1:-1,1:-1,:] = 0\n        hero = None\n        for item in self.objects:\n            a[item.y+1:item.y+item.size+1,item.x+1:item.x+item.size+1,item.channel] = item.intensity\n            if item.name == \'hero\':\n                hero = item\n        if self.partial == True:\n            a = a[hero.y:hero.y+3,hero.x:hero.x+3,:]\n        b = scipy.misc.imresize(a[:,:,0],[84,84,1],interp=\'nearest\')\n        c = scipy.misc.imresize(a[:,:,1],[84,84,1],interp=\'nearest\')\n        d = scipy.misc.imresize(a[:,:,2],[84,84,1],interp=\'nearest\')\n        a = np.stack([b,c,d],axis=2)\n        return a\n\n    def step(self,action):\n        penalty = self.moveChar(action)\n        reward,done = self.checkGoal()\n        state = self.renderEnv()\n        if reward == None:\n            print(done)\n            print(reward)\n            print(penalty)\n            return state,(reward+penalty),done\n        else:\n            return state,(reward+penalty),done'"
helper.py,3,"b'import numpy as np\nimport random\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport scipy.misc\nimport os\nimport csv\nimport itertools\nimport tensorflow.contrib.slim as slim\n\n#This is a simple function to reshape our game frames.\ndef processState(state1):\n    return np.reshape(state1,[21168])\n    \n#These functions allows us to update the parameters of our target network with those of the primary network.\ndef updateTargetGraph(tfVars,tau):\n    total_vars = len(tfVars)\n    op_holder = []\n    for idx,var in enumerate(tfVars[0:total_vars//2]):\n        op_holder.append(tfVars[idx+total_vars//2].assign((var.value()*tau) + ((1-tau)*tfVars[idx+total_vars//2].value())))\n    return op_holder\n\ndef updateTarget(op_holder,sess):\n    for op in op_holder:\n        sess.run(op)\n    total_vars = len(tf.trainable_variables())\n    a = tf.trainable_variables()[0].eval(session=sess)\n    b = tf.trainable_variables()[total_vars//2].eval(session=sess)\n    if a.all() == b.all():\n        print(""Target Set Success"")\n    else:\n        print(""Target Set Failed"")\n        \n#Record performance metrics and episode logs for the Control Center.\ndef saveToCenter(i,rList,jList,bufferArray,summaryLength,h_size,sess,mainQN,time_per_step):\n    with open(\'./Center/log.csv\', \'a\') as myfile:\n        state_display = (np.zeros([1,h_size]),np.zeros([1,h_size]))\n        imagesS = []\n        for idx,z in enumerate(np.vstack(bufferArray[:,0])):\n            img,state_display = sess.run([mainQN.salience,mainQN.rnn_state],\\\n                feed_dict={mainQN.scalarInput:np.reshape(bufferArray[idx,0],[1,21168])/255.0,\\\n                mainQN.trainLength:1,mainQN.state_in:state_display,mainQN.batch_size:1})\n            imagesS.append(img)\n        imagesS = (imagesS - np.min(imagesS))/(np.max(imagesS) - np.min(imagesS))\n        imagesS = np.vstack(imagesS)\n        imagesS = np.resize(imagesS,[len(imagesS),84,84,3])\n        luminance = np.max(imagesS,3)\n        imagesS = np.multiply(np.ones([len(imagesS),84,84,3]),np.reshape(luminance,[len(imagesS),84,84,1]))\n        make_gif(np.ones([len(imagesS),84,84,3]),\'./Center/frames/sal\'+str(i)+\'.gif\',duration=len(imagesS)*time_per_step,true_image=False,salience=True,salIMGS=luminance)\n\n        images = zip(bufferArray[:,0])\n        images.append(bufferArray[-1,3])\n        images = np.vstack(images)\n        images = np.resize(images,[len(images),84,84,3])\n        make_gif(images,\'./Center/frames/image\'+str(i)+\'.gif\',duration=len(images)*time_per_step,true_image=True,salience=False)\n\n        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n        wr.writerow([i,np.mean(jList[-100:]),np.mean(rList[-summaryLength:]),\'./frames/image\'+str(i)+\'.gif\',\'./frames/log\'+str(i)+\'.csv\',\'./frames/sal\'+str(i)+\'.gif\'])\n        myfile.close()\n    with open(\'./Center/frames/log\'+str(i)+\'.csv\',\'w\') as myfile:\n        state_train = (np.zeros([1,h_size]),np.zeros([1,h_size]))\n        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n        wr.writerow([""ACTION"",""REWARD"",""A0"",""A1"",\'A2\',\'A3\',\'V\'])\n        a, v = sess.run([mainQN.Advantage,mainQN.Value],\\\n            feed_dict={mainQN.scalarInput:np.vstack(bufferArray[:,0])/255.0,mainQN.trainLength:len(bufferArray),mainQN.state_in:state_train,mainQN.batch_size:1})\n        wr.writerows(zip(bufferArray[:,1],bufferArray[:,2],a[:,0],a[:,1],a[:,2],a[:,3],v[:,0]))\n    \n#This code allows gifs to be saved of the training episode for use in the Control Center.\ndef make_gif(images, fname, duration=2, true_image=False,salience=False,salIMGS=None):\n  import moviepy.editor as mpy\n  \n  def make_frame(t):\n    try:\n      x = images[int(len(images)/duration*t)]\n    except:\n      x = images[-1]\n\n    if true_image:\n      return x.astype(np.uint8)\n    else:\n      return ((x+1)/2*255).astype(np.uint8)\n  \n  def make_mask(t):\n    try:\n      x = salIMGS[int(len(salIMGS)/duration*t)]\n    except:\n      x = salIMGS[-1]\n    return x\n\n  clip = mpy.VideoClip(make_frame, duration=duration)\n  if salience == True:\n    mask = mpy.VideoClip(make_mask, ismask=True,duration= duration)\n    clipB = clip.set_mask(mask)\n    clipB = clip.set_opacity(0)\n    mask = mask.set_opacity(0.1)\n    mask.write_gif(fname, fps = len(images) / duration,verbose=False)\n    #clipB.write_gif(fname, fps = len(images) / duration,verbose=False)\n  else:\n    clip.write_gif(fname, fps = len(images) / duration,verbose=False)\n'"
