file_path,api_count,code
setup.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nimport os\nfrom glob import glob\nimport sys\n\nfrom setuptools import setup, find_packages\n\n\ndef read(fname):\n    """"""\n    Args:\n        fname:\n    """"""\n    return open(os.path.join(os.path.dirname(__file__), fname)).read()\n\n\ndef read_version():\n    return read(""VERSION"").strip()\n\n\n# Declare minimal set for installation\nrequired_packages = [\n    ""boto3>=1.13.6"",\n    ""numpy>=1.9.0"",\n    ""protobuf>=3.1"",\n    ""scipy>=0.19.0"",\n    ""protobuf3-to-dict>=0.1.5"",\n    ""smdebug-rulesconfig==0.1.4"",\n    ""importlib-metadata>=1.4.0"",\n    ""packaging>=20.0"",\n]\n\n# Specific use case dependencies\nextras = {\n    ""analytics"": [""pandas""],\n    ""local"": [\n        ""urllib3>=1.21.1,<1.26,!=1.25.0,!=1.25.1"",\n        ""docker-compose>=1.25.2"",\n        ""PyYAML>=5.3, <6"",  # PyYAML version has to match docker-compose requirements\n    ],\n    ""tensorflow"": [""tensorflow>=1.3.0""],\n}\n# Meta dependency groups\nextras[""all""] = [item for group in extras.values() for item in group]\n# Tests specific dependencies (do not need to be included in \'all\')\nextras[""test""] = (\n    [\n        extras[""all""],\n        ""tox==3.13.1"",\n        ""flake8"",\n        ""pytest==4.4.1"",\n        ""pytest-cov"",\n        ""pytest-rerunfailures"",\n        ""pytest-xdist"",\n        ""mock"",\n        ""contextlib2"",\n        ""awslogs"",\n        ""black==19.3b0 ; python_version >= \'3.6\'"",\n        ""stopit==1.1.2"",\n        ""apache-airflow==1.10.5"",\n        ""fabric>=2.0"",\n        ""requests>=2.20.0, <3"",\n    ],\n)\n\n# enum is introduced in Python 3.4. Installing enum back port\nif sys.version_info < (3, 4):\n    required_packages.append(""enum34>=1.1.6"")\n\nsetup(\n    name=""sagemaker"",\n    version=read_version(),\n    description=""Open source library for training and deploying models on Amazon SageMaker."",\n    packages=find_packages(""src""),\n    package_dir={"""": ""src""},\n    py_modules=[os.path.splitext(os.path.basename(path))[0] for path in glob(""src/*.py"")],\n    long_description=read(""README.rst""),\n    author=""Amazon Web Services"",\n    url=""https://github.com/aws/sagemaker-python-sdk/"",\n    license=""Apache License 2.0"",\n    keywords=""ML Amazon AWS AI Tensorflow MXNet"",\n    classifiers=[\n        ""Development Status :: 5 - Production/Stable"",\n        ""Intended Audience :: Developers"",\n        ""Natural Language :: English"",\n        ""License :: OSI Approved :: Apache Software License"",\n        ""Programming Language :: Python"",\n        ""Programming Language :: Python :: 2.7"",\n        ""Programming Language :: Python :: 3.6"",\n        ""Programming Language :: Python :: 3.7"",\n    ],\n    install_requires=required_packages,\n    extras_require=extras,\n    entry_points={""console_scripts"": [""sagemaker=sagemaker.cli.main:main""]},\n    include_package_data=True,  # TODO-reinvent-2019 [knakad]: Remove after rule_configs is in PyPI\n)\n'"
ci-scripts/queue_build.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport os\nimport time\nimport boto3\n\naccount = boto3.client(\n    ""sts"", region_name=""us-west-2"", endpoint_url=""https://sts.us-west-2.amazonaws.com""\n).get_caller_identity()[""Account""]\nbucket_name = ""sagemaker-us-west-2-%s"" % account\n\n\ndef queue_build():\n    build_id = os.environ.get(""CODEBUILD_BUILD_ID"", ""CODEBUILD-BUILD-ID"")\n    source_version = os.environ.get(""CODEBUILD_SOURCE_VERSION"", ""CODEBUILD-SOURCE-VERSION"").replace(\n        ""/"", ""-""\n    )\n    ticket_number = int(1000 * time.time())\n    filename = ""%s_%s_%s"" % (ticket_number, build_id, source_version)\n\n    print(""Created queue ticket %s"" % ticket_number)\n\n    _write_ticket(filename)\n    files = _list_tickets()\n    _cleanup_tickets_older_than_8_hours(files)\n    _wait_for_other_builds(files, ticket_number)\n\n\ndef _build_info_from_file(file):\n    filename = file.key.split(""/"")[1]\n    ticket_number, build_id, source_version = filename.split(""_"")\n    return int(ticket_number), build_id, source_version\n\n\ndef _wait_for_other_builds(files, ticket_number):\n    newfiles = list(filter(lambda file: not _file_older_than(file), files))\n    sorted_files = list(sorted(newfiles, key=lambda y: y.key))\n\n    print(""build queue status:"")\n    print()\n\n    for order, file in enumerate(sorted_files):\n        file_ticket_number, build_id, source_version = _build_info_from_file(file)\n        print(\n            ""%s -> %s %s, ticket number: %s"" % (order, build_id, source_version, file_ticket_number)\n        )\n\n    for file in sorted_files:\n        file_ticket_number, build_id, source_version = _build_info_from_file(file)\n\n        if file_ticket_number == ticket_number:\n\n            break\n        else:\n            while True:\n                client = boto3.client(""codebuild"")\n                response = client.batch_get_builds(ids=[build_id])\n                build_status = response[""builds""][0][""buildStatus""]\n\n                if build_status == ""IN_PROGRESS"":\n                    print(\n                        ""waiting on build %s %s %s"" % (build_id, source_version, file_ticket_number)\n                    )\n                    time.sleep(30)\n                else:\n                    print(""build %s finished, deleting lock"" % build_id)\n                    file.delete()\n                    break\n\n\ndef _cleanup_tickets_older_than_8_hours(files):\n    oldfiles = list(filter(_file_older_than, files))\n    for file in oldfiles:\n        print(""object %s older than 8 hours. Deleting"" % file.key)\n        file.delete()\n    return files\n\n\ndef _list_tickets():\n    s3 = boto3.resource(""s3"")\n    bucket = s3.Bucket(bucket_name)\n    objects = [file for file in bucket.objects.filter(Prefix=""ci-lock/"")]\n    files = list(filter(lambda x: x != ""ci-lock/"", objects))\n    return files\n\n\ndef _file_older_than(file):\n    timelimit = 1000 * 60 * 60 * 8\n\n    file_ticket_number, build_id, source_version = _build_info_from_file(file)\n\n    return int(time.time()) - file_ticket_number > timelimit\n\n\ndef _write_ticket(ticket_number):\n\n    if not os.path.exists(""ci-lock""):\n        os.mkdir(""ci-lock"")\n\n    filename = ""ci-lock/"" + ticket_number\n    with open(filename, ""w"") as file:\n        file.write(ticket_number)\n    boto3.Session().resource(""s3"").Object(bucket_name, filename).upload_file(filename)\n\n\nif __name__ == ""__main__"":\n    queue_build()\n'"
doc/conf.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nimport pkg_resources\nimport sys\nfrom datetime import datetime\nfrom unittest.mock import MagicMock\n\n\nclass Mock(MagicMock):\n    @classmethod\n    def __getattr__(cls, name):\n        """"""\n        Args:\n            name:\n        """"""\n        if name == ""__version__"":\n            return ""1.4.0""\n        else:\n            return MagicMock()\n\n\nMOCK_MODULES = [\n    ""tensorflow"",\n    ""tensorflow.core"",\n    ""tensorflow.core.framework"",\n    ""tensorflow.python"",\n    ""tensorflow.python.framework"",\n    ""tensorflow_serving"",\n    ""tensorflow_serving.apis"",\n    ""scipy"",\n    ""scipy.sparse"",\n]\nsys.modules.update((mod_name, Mock()) for mod_name in MOCK_MODULES)\n\nproject = u""sagemaker""\nversion = pkg_resources.require(project)[0].version\n\n# Add any Sphinx extension module names here, as strings. They can be extensions\n# coming with Sphinx (named \'sphinx.ext.*\') or your custom ones.\nextensions = [\n    ""sphinx.ext.autodoc"",\n    ""sphinx.ext.doctest"",\n    ""sphinx.ext.intersphinx"",\n    ""sphinx.ext.todo"",\n    ""sphinx.ext.coverage"",\n    ""sphinx.ext.autosummary"",\n    ""sphinx.ext.napoleon"",\n    ""sphinx.ext.autosectionlabel"",\n]\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [""_templates""]\n\nsource_suffix = "".rst""  # The suffix of source filenames.\nmaster_doc = ""index""  # The master toctree document.\n\ncopyright = u""%s, Amazon"" % datetime.now().year\n\n# The full version, including alpha/beta/rc tags.\nrelease = version\n\n# List of directories, relative to source directory, that shouldn\'t be searched\n# for source files.\nexclude_trees = [""_build""]\n\npygments_style = ""default""\n\nautoclass_content = ""both""\nautodoc_default_flags = [""show-inheritance"", ""members"", ""undoc-members""]\nautodoc_member_order = ""bysource""\n\nhtml_theme = ""sphinx_rtd_theme""\n\nhtml_static_path = [""_static""]\n\nhtmlhelp_basename = ""%sdoc"" % project\n\nhtml_js_files = [""https://a0.awsstatic.com/s_code/js/1.0/awshome_s_code.js"", ""js/analytics.js""]\n\n# Example configuration for intersphinx: refer to the Python standard library.\nintersphinx_mapping = {""http://docs.python.org/"": None}\n\n# autosummary\nautosummary_generate = True\n\n# autosectionlabel\nautosectionlabel_prefix_document = True\n'"
tests/__init__.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n'"
tests/conftest.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport json\nimport os\n\nimport boto3\nimport pytest\nimport tests.integ\nfrom botocore.config import Config\n\nfrom sagemaker import Session, utils\nfrom sagemaker.chainer import Chainer\nfrom sagemaker.local import LocalSession\nfrom sagemaker.mxnet import MXNet\nfrom sagemaker.pytorch import PyTorch\nfrom sagemaker.rl import RLEstimator\nfrom sagemaker.sklearn.defaults import SKLEARN_VERSION\nfrom sagemaker.tensorflow import TensorFlow\nfrom sagemaker.tensorflow.defaults import LATEST_VERSION, LATEST_SERVING_VERSION\n\nDEFAULT_REGION = ""us-west-2""\nCUSTOM_BUCKET_NAME_PREFIX = ""sagemaker-custom-bucket""\n\nNO_M4_REGIONS = [\n    ""eu-west-3"",\n    ""eu-north-1"",\n    ""ap-east-1"",\n    ""ap-northeast-1"",  # it has m4.xl, but not enough in all AZs\n    ""sa-east-1"",\n    ""me-south-1"",\n]\n\nNO_T2_REGIONS = [""eu-north-1"", ""ap-east-1"", ""me-south-1""]\n\n\ndef pytest_addoption(parser):\n    parser.addoption(""--sagemaker-client-config"", action=""store"", default=None)\n    parser.addoption(""--sagemaker-runtime-config"", action=""store"", default=None)\n    parser.addoption(""--boto-config"", action=""store"", default=None)\n    parser.addoption(""--chainer-full-version"", action=""store"", default=Chainer.LATEST_VERSION)\n    parser.addoption(""--mxnet-full-version"", action=""store"", default=MXNet.LATEST_VERSION)\n    parser.addoption(""--ei-mxnet-full-version"", action=""store"", default=""1.5.1"")\n    parser.addoption(""--pytorch-full-version"", action=""store"", default=PyTorch.LATEST_VERSION)\n    parser.addoption(\n        ""--rl-coach-mxnet-full-version"",\n        action=""store"",\n        default=RLEstimator.COACH_LATEST_VERSION_MXNET,\n    )\n    parser.addoption(\n        ""--rl-coach-tf-full-version"", action=""store"", default=RLEstimator.COACH_LATEST_VERSION_TF\n    )\n    parser.addoption(\n        ""--rl-ray-full-version"", action=""store"", default=RLEstimator.RAY_LATEST_VERSION\n    )\n    parser.addoption(""--sklearn-full-version"", action=""store"", default=SKLEARN_VERSION)\n    parser.addoption(""--tf-full-version"", action=""store"")\n    parser.addoption(""--ei-tf-full-version"", action=""store"")\n    parser.addoption(""--xgboost-full-version"", action=""store"", default=SKLEARN_VERSION)\n\n\ndef pytest_configure(config):\n    bc = config.getoption(""--boto-config"")\n    parsed = json.loads(bc) if bc else {}\n    region = parsed.get(""region_name"", boto3.session.Session().region_name)\n    if region:\n        os.environ[""TEST_AWS_REGION_NAME""] = region\n\n\n@pytest.fixture(scope=""session"")\ndef sagemaker_client_config(request):\n    config = request.config.getoption(""--sagemaker-client-config"")\n    return json.loads(config) if config else dict()\n\n\n@pytest.fixture(scope=""session"")\ndef sagemaker_runtime_config(request):\n    config = request.config.getoption(""--sagemaker-runtime-config"")\n    return json.loads(config) if config else None\n\n\n@pytest.fixture(scope=""session"")\ndef boto_session(request):\n    config = request.config.getoption(""--boto-config"")\n    if config:\n        return boto3.Session(**json.loads(config))\n    else:\n        return boto3.Session(region_name=DEFAULT_REGION)\n\n\n@pytest.fixture(scope=""session"")\ndef sagemaker_session(sagemaker_client_config, sagemaker_runtime_config, boto_session):\n    sagemaker_client_config.setdefault(""config"", Config(retries=dict(max_attempts=10)))\n    sagemaker_client = (\n        boto_session.client(""sagemaker"", **sagemaker_client_config)\n        if sagemaker_client_config\n        else None\n    )\n    runtime_client = (\n        boto_session.client(""sagemaker-runtime"", **sagemaker_runtime_config)\n        if sagemaker_runtime_config\n        else None\n    )\n\n    return Session(\n        boto_session=boto_session,\n        sagemaker_client=sagemaker_client,\n        sagemaker_runtime_client=runtime_client,\n    )\n\n\n@pytest.fixture(scope=""session"")\ndef sagemaker_local_session(boto_session):\n    return LocalSession(boto_session=boto_session)\n\n\n@pytest.fixture(scope=""module"")\ndef custom_bucket_name(boto_session):\n    region = boto_session.region_name\n    account = boto_session.client(\n        ""sts"", region_name=region, endpoint_url=utils.sts_regional_endpoint(region)\n    ).get_caller_identity()[""Account""]\n    return ""{}-{}-{}"".format(CUSTOM_BUCKET_NAME_PREFIX, region, account)\n\n\n@pytest.fixture(scope=""module"", params=[""4.0"", ""4.0.0"", ""4.1"", ""4.1.0"", ""5.0"", ""5.0.0""])\ndef chainer_version(request):\n    return request.param\n\n\n# TODO: current version fixtures are legacy fixtures that aren\'t useful\n# and no longer verify whether images are valid\n@pytest.fixture(\n    scope=""module"",\n    params=[\n        ""0.12"",\n        ""0.12.1"",\n        ""1.0"",\n        ""1.0.0"",\n        ""1.1"",\n        ""1.1.0"",\n        ""1.2"",\n        ""1.2.1"",\n        ""1.3"",\n        ""1.3.0"",\n        ""1.4"",\n        ""1.4.0"",\n        ""1.4.1"",\n    ],\n)\ndef mxnet_version(request):\n    return request.param\n\n\n@pytest.fixture(scope=""module"", params=[""0.4"", ""0.4.0"", ""1.0"", ""1.0.0""])\ndef pytorch_version(request):\n    return request.param\n\n\n@pytest.fixture(scope=""module"", params=[""0.20.0""])\ndef sklearn_version(request):\n    return request.param\n\n\n@pytest.fixture(scope=""module"", params=[""0.90-1""])\ndef xgboost_version(request):\n    return request.param\n\n\n@pytest.fixture(\n    scope=""module"",\n    params=[\n        ""1.4"",\n        ""1.4.1"",\n        ""1.5"",\n        ""1.5.0"",\n        ""1.6"",\n        ""1.6.0"",\n        ""1.7"",\n        ""1.7.0"",\n        ""1.8"",\n        ""1.8.0"",\n        ""1.9"",\n        ""1.9.0"",\n        ""1.10"",\n        ""1.10.0"",\n        ""1.11"",\n        ""1.11.0"",\n        ""1.12"",\n        ""1.12.0"",\n    ],\n)\ndef tf_version(request):\n    return request.param\n\n\n@pytest.fixture(scope=""module"", params=[""0.10.1"", ""0.10.1"", ""0.11"", ""0.11.0"", ""0.11.1""])\ndef rl_coach_tf_version(request):\n    return request.param\n\n\n@pytest.fixture(scope=""module"", params=[""0.11"", ""0.11.0""])\ndef rl_coach_mxnet_version(request):\n    return request.param\n\n\n@pytest.fixture(scope=""module"", params=[""0.5"", ""0.5.3"", ""0.6"", ""0.6.5""])\ndef rl_ray_version(request):\n    return request.param\n\n\n@pytest.fixture(scope=""module"")\ndef chainer_full_version(request):\n    return request.config.getoption(""--chainer-full-version"")\n\n\n@pytest.fixture(scope=""module"")\ndef mxnet_full_version(request):\n    return request.config.getoption(""--mxnet-full-version"")\n\n\n@pytest.fixture(scope=""module"")\ndef ei_mxnet_full_version(request):\n    return request.config.getoption(""--ei-mxnet-full-version"")\n\n\n@pytest.fixture(scope=""module"")\ndef pytorch_full_version(request):\n    return request.config.getoption(""--pytorch-full-version"")\n\n\n@pytest.fixture(scope=""module"")\ndef rl_coach_mxnet_full_version(request):\n    return request.config.getoption(""--rl-coach-mxnet-full-version"")\n\n\n@pytest.fixture(scope=""module"")\ndef rl_coach_tf_full_version(request):\n    return request.config.getoption(""--rl-coach-tf-full-version"")\n\n\n@pytest.fixture(scope=""module"")\ndef rl_ray_full_version(request):\n    return request.config.getoption(""--rl-ray-full-version"")\n\n\n@pytest.fixture(scope=""module"")\ndef sklearn_full_version(request):\n    return request.config.getoption(""--sklearn-full-version"")\n\n\n@pytest.fixture(scope=""module"", params=[TensorFlow._LATEST_1X_VERSION, LATEST_VERSION])\ndef tf_full_version(request):\n    tf_version = request.config.getoption(""--tf-full-version"")\n    if tf_version is None:\n        return request.param\n    else:\n        return tf_version\n\n\n@pytest.fixture(scope=""module"", params=[""1.15.0"", ""2.0.0""])\ndef ei_tf_full_version(request):\n    tf_ei_version = request.config.getoption(""--ei-tf-full-version"")\n    if tf_ei_version is None:\n        return request.param\n    else:\n        tf_ei_version\n\n\n@pytest.fixture(scope=""session"")\ndef cpu_instance_type(sagemaker_session, request):\n    region = sagemaker_session.boto_session.region_name\n    if region in NO_M4_REGIONS:\n        return ""ml.m5.xlarge""\n    else:\n        return ""ml.m4.xlarge""\n\n\n@pytest.fixture(scope=""session"")\ndef inf_instance_type(sagemaker_session, request):\n    return ""ml.inf1.xlarge""\n\n\n@pytest.fixture(scope=""session"")\ndef ec2_instance_type(cpu_instance_type):\n    return cpu_instance_type[3:]\n\n\n@pytest.fixture(scope=""session"")\ndef alternative_cpu_instance_type(sagemaker_session, request):\n    region = sagemaker_session.boto_session.region_name\n    if region in NO_T2_REGIONS:\n        # T3 is not supported by hosting yet\n        return ""ml.c5.xlarge""\n    else:\n        return ""ml.t2.medium""\n\n\n@pytest.fixture(scope=""session"")\ndef cpu_instance_family(cpu_instance_type):\n    return ""_"".join(cpu_instance_type.split(""."")[0:2])\n\n\n@pytest.fixture(scope=""session"")\ndef inf_instance_family(inf_instance_type):\n    return ""_"".join(inf_instance_type.split(""."")[0:2])\n\n\ndef pytest_generate_tests(metafunc):\n    if ""instance_type"" in metafunc.fixturenames:\n        boto_config = metafunc.config.getoption(""--boto-config"")\n        parsed_config = json.loads(boto_config) if boto_config else {}\n        region = parsed_config.get(""region_name"", DEFAULT_REGION)\n        cpu_instance_type = ""ml.m5.xlarge"" if region in NO_M4_REGIONS else ""ml.m4.xlarge""\n\n        params = [cpu_instance_type]\n        if not (\n            region in tests.integ.HOSTING_NO_P2_REGIONS\n            or region in tests.integ.TRAINING_NO_P2_REGIONS\n        ):\n            params.append(""ml.p2.xlarge"")\n        metafunc.parametrize(""instance_type"", params, scope=""session"")\n\n\n@pytest.fixture(scope=""module"")\ndef xgboost_full_version(request):\n    return request.config.getoption(""--xgboost-full-version"")\n\n\n@pytest.fixture(scope=""module"")\ndef tf_serving_version(tf_full_version):\n    if tf_full_version == LATEST_VERSION:\n        return LATEST_SERVING_VERSION\n    return tf_full_version\n'"
src/sagemaker/__init__.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nimport logging\nimport sys\nimport importlib_metadata\n\nfrom sagemaker import estimator, parameter, tuner  # noqa: F401\nfrom sagemaker.amazon.kmeans import KMeans, KMeansModel, KMeansPredictor  # noqa: F401\nfrom sagemaker.amazon.pca import PCA, PCAModel, PCAPredictor  # noqa: F401\nfrom sagemaker.amazon.lda import LDA, LDAModel, LDAPredictor  # noqa: F401\nfrom sagemaker.amazon.linear_learner import (  # noqa: F401\n    LinearLearner,\n    LinearLearnerModel,\n    LinearLearnerPredictor,\n)\nfrom sagemaker.amazon.factorization_machines import (  # noqa: F401\n    FactorizationMachines,\n    FactorizationMachinesModel,\n)\nfrom sagemaker.amazon.factorization_machines import FactorizationMachinesPredictor  # noqa: F401\nfrom sagemaker.amazon.ntm import NTM, NTMModel, NTMPredictor  # noqa: F401\nfrom sagemaker.amazon.randomcutforest import (  # noqa: F401\n    RandomCutForest,\n    RandomCutForestModel,\n    RandomCutForestPredictor,\n)\nfrom sagemaker.amazon.knn import KNN, KNNModel, KNNPredictor  # noqa: F401\nfrom sagemaker.amazon.object2vec import Object2Vec, Object2VecModel  # noqa: F401\nfrom sagemaker.amazon.ipinsights import (  # noqa: F401\n    IPInsights,\n    IPInsightsModel,\n    IPInsightsPredictor,\n)\n\nfrom sagemaker.algorithm import AlgorithmEstimator  # noqa: F401\nfrom sagemaker.analytics import TrainingJobAnalytics, HyperparameterTuningJobAnalytics  # noqa: F401\nfrom sagemaker.local.local_session import LocalSession  # noqa: F401\n\nfrom sagemaker.model import Model, ModelPackage  # noqa: F401\nfrom sagemaker.pipeline import PipelineModel  # noqa: F401\nfrom sagemaker.predictor import RealTimePredictor  # noqa: F401\nfrom sagemaker.processing import Processor, ScriptProcessor  # noqa: F401\nfrom sagemaker.session import Session  # noqa: F401\nfrom sagemaker.session import container_def, pipeline_container_def  # noqa: F401\nfrom sagemaker.session import production_variant  # noqa: F401\nfrom sagemaker.session import s3_input  # noqa: F401\nfrom sagemaker.session import get_execution_role  # noqa: F401\n\nfrom sagemaker.automl.automl import AutoML, AutoMLJob, AutoMLInput  # noqa: F401\nfrom sagemaker.automl.candidate_estimator import CandidateEstimator, CandidateStep  # noqa: F401\n\n__version__ = importlib_metadata.version(""sagemaker"")\n\nif sys.version[0] == ""2"":\n    logging.getLogger(""sagemaker"").warning(\n        ""SageMaker Python SDK v2 will no longer support Python 2. ""\n        ""Please see https://github.com/aws/sagemaker-python-sdk/issues/1459 ""\n        ""for more information""\n    )\n'"
src/sagemaker/algorithm.py,0,"b'# Copyright 2018-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Test docstring""""""\nfrom __future__ import absolute_import\n\nimport sagemaker\nimport sagemaker.parameter\nfrom sagemaker import vpc_utils\nfrom sagemaker.estimator import EstimatorBase\nfrom sagemaker.transformer import Transformer\nfrom sagemaker.predictor import RealTimePredictor\n\n\nclass AlgorithmEstimator(EstimatorBase):\n    """"""A generic Estimator to train using any algorithm object (with an\n    ``algorithm_arn``). The Algorithm can be your own, or any Algorithm from AWS\n    Marketplace that you have a valid subscription for. This class will perform\n    client-side validation on all the inputs.\n    """"""\n\n    # These Hyperparameter Types have a range definition.\n    _hyperpameters_with_range = (""Integer"", ""Continuous"", ""Categorical"")\n\n    def __init__(\n        self,\n        algorithm_arn,\n        role,\n        train_instance_count,\n        train_instance_type,\n        train_volume_size=30,\n        train_volume_kms_key=None,\n        train_max_run=24 * 60 * 60,\n        input_mode=""File"",\n        output_path=None,\n        output_kms_key=None,\n        base_job_name=None,\n        sagemaker_session=None,\n        hyperparameters=None,\n        tags=None,\n        subnets=None,\n        security_group_ids=None,\n        model_uri=None,\n        model_channel_name=""model"",\n        metric_definitions=None,\n        encrypt_inter_container_traffic=False,\n        **kwargs  # pylint: disable=W0613\n    ):\n        """"""Initialize an ``AlgorithmEstimator`` instance.\n\n        Args:\n            algorithm_arn (str): algorithm arn used for training. Can be just the name if your\n                account owns the algorithm.\n            role (str): An AWS IAM role (either name or full ARN). The Amazon SageMaker\n                training jobs and APIsthat create Amazon SageMaker endpoints use this role to\n                access training data and model artifacts. After the endpoint\n                is created, the inference code might use the IAM role, if it\n                needs to access an AWS resource.\n            train_instance_count (int): Number of Amazon EC2 instances to\n                use for training. train_instance_type (str): Type of EC2\n                instance to use for training, for example, \'ml.c4.xlarge\'.\n            train_volume_size (int): Size in GB of the EBS volume to use for\n                storing input data during training (default: 30). Must be large enough to store\n                training data if File Mode is used (which is the default).\n            train_volume_kms_key (str): Optional. KMS key ID for encrypting EBS volume attached\n                to the training instance (default: None).\n            train_max_run (int): Timeout in seconds for training (default: 24 * 60 * 60).\n                After this amount of time Amazon SageMaker terminates the\n                job regardless of its current status.\n            input_mode (str): The input mode that the algorithm supports\n            (default: \'File\'). Valid modes:\n\n                * \'File\' - Amazon SageMaker copies the training dataset from\n                  the S3 location to a local directory.\n                * \'Pipe\' - Amazon SageMaker streams data directly from S3 to\n                  the container via a Unix-named pipe.\n\n                This argument can be overriden on a per-channel basis using\n                ``sagemaker.session.s3_input.input_mode``.\n\n            output_path (str): S3 location for saving the training result (model artifacts and\n                output files). If not specified, results are stored to a default bucket. If\n                the bucket with the specific name does not exist, the\n                estimator creates the bucket during the\n                :meth:`~sagemaker.estimator.EstimatorBase.fit` method\n                execution.\n            output_kms_key (str): Optional. KMS key ID for encrypting the\n                training output (default: None). base_job_name (str): Prefix for\n                training job name when the\n                :meth:`~sagemaker.estimator.EstimatorBase.fit`\n                method launches. If not specified, the estimator generates a\n                default job name, based on the training image name and\n                current timestamp.\n            sagemaker_session (sagemaker.session.Session): Session object which manages\n                interactions with Amazon SageMaker APIs and any other AWS services needed. If\n                not specified, the estimator creates one using the default\n                AWS configuration chain.\n            tags (list[dict]): List of tags for labeling a training job. For more, see\n                https://docs.aws.amazon.com/sagemaker/latest/dg/API_Tag.html.\n            subnets (list[str]): List of subnet ids. If not specified\n                training job will be created without VPC config.\n                security_group_ids (list[str]): List of security group ids. If\n                not specified training job will be created without VPC config.\n            model_uri (str): URI where a pre-trained model is stored, either locally or in S3\n                (default: None). If specified, the estimator will create a channel pointing to\n                the model so the training job can download it. This model\n                can be a \'model.tar.gz\' from a previous training job, or\n                other artifacts coming from a different source.\n                More information:\n                https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-training.html#td-deserialization\n            model_channel_name (str): Name of the channel where \'model_uri\'\n                will be downloaded (default: \'model\'). metric_definitions\n                (list[dict]): A list of dictionaries that defines the metric(s)\n                used to evaluate the training jobs. Each dictionary contains two keys: \'Name\' for\n                the name of the metric, and \'Regex\' for the regular\n                expression used to extract the metric from the logs.\n            encrypt_inter_container_traffic (bool): Specifies whether traffic between training\n                containers is encrypted for the training job (default: ``False``).\n            **kwargs: Additional kwargs. This is unused. It\'s only added for AlgorithmEstimator\n                to ignore the irrelevant arguments.\n        """"""\n        self.algorithm_arn = algorithm_arn\n        super(AlgorithmEstimator, self).__init__(\n            role,\n            train_instance_count,\n            train_instance_type,\n            train_volume_size,\n            train_volume_kms_key,\n            train_max_run,\n            input_mode,\n            output_path,\n            output_kms_key,\n            base_job_name,\n            sagemaker_session,\n            tags,\n            subnets,\n            security_group_ids,\n            model_uri=model_uri,\n            model_channel_name=model_channel_name,\n            metric_definitions=metric_definitions,\n            encrypt_inter_container_traffic=encrypt_inter_container_traffic,\n        )\n\n        self.algorithm_spec = self.sagemaker_session.sagemaker_client.describe_algorithm(\n            AlgorithmName=algorithm_arn\n        )\n        self.validate_train_spec()\n        self.hyperparameter_definitions = self._parse_hyperparameters()\n\n        self.hyperparam_dict = {}\n        if hyperparameters:\n            self.set_hyperparameters(**hyperparameters)\n\n    def validate_train_spec(self):\n        """"""Placeholder docstring""""""\n        train_spec = self.algorithm_spec[""TrainingSpecification""]\n        algorithm_name = self.algorithm_spec[""AlgorithmName""]\n\n        # Check that the input mode provided is compatible with the training input modes for the\n        # algorithm.\n        train_input_modes = self._algorithm_training_input_modes(train_spec[""TrainingChannels""])\n        if self.input_mode not in train_input_modes:\n            raise ValueError(\n                ""Invalid input mode: %s. %s only supports: %s""\n                % (self.input_mode, algorithm_name, train_input_modes)\n            )\n\n        # Check that the training instance type is compatible with the algorithm.\n        supported_instances = train_spec[""SupportedTrainingInstanceTypes""]\n        if self.train_instance_type not in supported_instances:\n            raise ValueError(\n                ""Invalid train_instance_type: %s. %s supports the following instance types: %s""\n                % (self.train_instance_type, algorithm_name, supported_instances)\n            )\n\n        # Verify if distributed training is supported by the algorithm\n        if (\n            self.train_instance_count > 1\n            and ""SupportsDistributedTraining"" in train_spec\n            and not train_spec[""SupportsDistributedTraining""]\n        ):\n            raise ValueError(\n                ""Distributed training is not supported by %s. ""\n                ""Please set train_instance_count=1"" % algorithm_name\n            )\n\n    def set_hyperparameters(self, **kwargs):\n        """"""\n        Args:\n            **kwargs:\n        """"""\n        for k, v in kwargs.items():\n            value = self._validate_and_cast_hyperparameter(k, v)\n            self.hyperparam_dict[k] = value\n\n        self._validate_and_set_default_hyperparameters()\n\n    def hyperparameters(self):\n        """"""Returns the hyperparameters as a dictionary to use for training.\n\n        The fit() method, that does the model training, calls this method to\n        find the hyperparameters you specified.\n        """"""\n        return self.hyperparam_dict\n\n    def train_image(self):\n        """"""Returns the docker image to use for training.\n\n        The fit() method, that does the model training, calls this method to\n        find the image to use for model training.\n        """"""\n        raise RuntimeError(""train_image is never meant to be called on Algorithm Estimators"")\n\n    def enable_network_isolation(self):\n        """"""Return True if this Estimator will need network isolation to run.\n\n        On Algorithm Estimators this depends on the algorithm being used. If\n        this is algorithm owned by your account it will be False. If this is an\n        an algorithm consumed from Marketplace it will be True.\n\n        Returns:\n            bool: Whether this Estimator needs network isolation or not.\n        """"""\n        return self._is_marketplace()\n\n    def create_model(\n        self,\n        role=None,\n        predictor_cls=None,\n        serializer=None,\n        deserializer=None,\n        content_type=None,\n        accept=None,\n        vpc_config_override=vpc_utils.VPC_CONFIG_DEFAULT,\n        **kwargs\n    ):\n        """"""Create a model to deploy.\n\n        The serializer, deserializer, content_type, and accept arguments are\n        only used to define a default RealTimePredictor. They are ignored if an\n        explicit predictor class is passed in. Other arguments are passed\n        through to the Model class.\n\n        Args:\n            role (str): The ``ExecutionRoleArn`` IAM Role ARN for the ``Model``,\n                which is also used during transform jobs. If not specified, the\n                role from the Estimator will be used.\n            predictor_cls (RealTimePredictor): The predictor class to use when\n                deploying the model.\n            serializer (callable): Should accept a single argument, the input\n                data, and return a sequence of bytes. May provide a content_type\n                attribute that defines the endpoint request content type\n            deserializer (callable): Should accept two arguments, the result\n                data and the response content type, and return a sequence of\n                bytes. May provide a content_type attribute that defines the\n                endpoint response Accept content type.\n            content_type (str): The invocation ContentType, overriding any\n                content_type from the serializer\n            accept (str): The invocation Accept, overriding any accept from the\n                deserializer.\n            vpc_config_override (dict[str, list[str]]): Optional override for VpcConfig set on\n                the model. Default: use subnets and security groups from this Estimator.\n                * \'Subnets\' (list[str]): List of subnet ids.\n                * \'SecurityGroupIds\' (list[str]): List of security group ids.\n            **kwargs: Additional arguments for creating a :class:`~sagemaker.model.ModelPackage`.\n\n        .. tip::\n\n            You can find additional parameters for using this method at\n            :class:`~sagemaker.model.ModelPackage` and\n            :class:`~sagemaker.model.Model`.\n\n        Returns:\n            a Model ready for deployment.\n        """"""\n        if predictor_cls is None:\n\n            def predict_wrapper(endpoint, session):\n                return RealTimePredictor(\n                    endpoint, session, serializer, deserializer, content_type, accept\n                )\n\n            predictor_cls = predict_wrapper\n\n        role = role or self.role\n\n        return sagemaker.ModelPackage(\n            role,\n            algorithm_arn=self.algorithm_arn,\n            model_data=self.model_data,\n            vpc_config=self.get_vpc_config(vpc_config_override),\n            sagemaker_session=self.sagemaker_session,\n            predictor_cls=predictor_cls,\n            **kwargs\n        )\n\n    def transformer(\n        self,\n        instance_count,\n        instance_type,\n        strategy=None,\n        assemble_with=None,\n        output_path=None,\n        output_kms_key=None,\n        accept=None,\n        env=None,\n        max_concurrent_transforms=None,\n        max_payload=None,\n        tags=None,\n        role=None,\n        volume_kms_key=None,\n    ):\n        """"""Return a ``Transformer`` that uses a SageMaker Model based on the\n        training job. It reuses the SageMaker Session and base job name used by\n        the Estimator.\n\n        Args:\n            instance_count (int): Number of EC2 instances to use.\n            instance_type (str): Type of EC2 instance to use, for example,\n                \'ml.c4.xlarge\'.\n            strategy (str): The strategy used to decide how to batch records in\n                a single request (default: None). Valid values: \'MultiRecord\'\n                and \'SingleRecord\'.\n            assemble_with (str): How the output is assembled (default: None).\n                Valid values: \'Line\' or \'None\'.\n            output_path (str): S3 location for saving the transform result. If\n                not specified, results are stored to a default bucket.\n            output_kms_key (str): Optional. KMS key ID for encrypting the\n                transform output (default: None).\n            accept (str): The accept header passed by the client to\n                the inference endpoint. If it is supported by the endpoint,\n                it will be the format of the batch transform output.\n            env (dict): Environment variables to be set for use during the\n                transform job (default: None).\n            max_concurrent_transforms (int): The maximum number of HTTP requests\n                to be made to each individual transform container at one time.\n            max_payload (int): Maximum size of the payload in a single HTTP\n                request to the container in MB.\n            tags (list[dict]): List of tags for labeling a transform job. If\n                none specified, then the tags used for the training job are used\n                for the transform job.\n            role (str): The ``ExecutionRoleArn`` IAM Role ARN for the ``Model``,\n                which is also used during transform jobs. If not specified, the\n                role from the Estimator will be used.\n            volume_kms_key (str): Optional. KMS key ID for encrypting the volume\n                attached to the ML compute instance (default: None).\n        """"""\n        role = role or self.role\n\n        if self.latest_training_job is not None:\n            model = self.create_model(role=role)\n            model._create_sagemaker_model()\n            model_name = model.name\n            transform_env = {}\n            if env is not None:\n                transform_env = model.env.copy()\n                transform_env.update(env)\n            if self._is_marketplace():\n                transform_env = None\n\n            tags = tags or self.tags\n        else:\n            raise RuntimeError(""No finished training job found associated with this estimator"")\n\n        return Transformer(\n            model_name,\n            instance_count,\n            instance_type,\n            strategy=strategy,\n            assemble_with=assemble_with,\n            output_path=output_path,\n            output_kms_key=output_kms_key,\n            accept=accept,\n            max_concurrent_transforms=max_concurrent_transforms,\n            max_payload=max_payload,\n            env=transform_env,\n            tags=tags,\n            base_transform_job_name=self.base_job_name,\n            volume_kms_key=volume_kms_key,\n            sagemaker_session=self.sagemaker_session,\n        )\n\n    def _is_marketplace(self):\n        """"""Placeholder docstring""""""\n        return ""ProductId"" in self.algorithm_spec\n\n    def _prepare_for_training(self, job_name=None):\n        # Validate hyperparameters\n        # an explicit call to set_hyperparameters() will also validate the hyperparameters\n        # but it is possible that the user never called it.\n        """"""\n        Args:\n            job_name:\n        """"""\n        self._validate_and_set_default_hyperparameters()\n\n        super(AlgorithmEstimator, self)._prepare_for_training(job_name)\n\n    def fit(self, inputs=None, wait=True, logs=True, job_name=None):\n        """"""\n        Args:\n            inputs:\n            wait:\n            logs:\n            job_name:\n        """"""\n        if inputs:\n            self._validate_input_channels(inputs)\n\n        super(AlgorithmEstimator, self).fit(inputs, wait, logs, job_name)\n\n    def _validate_input_channels(self, channels):\n        """"""\n        Args:\n            channels:\n        """"""\n        train_spec = self.algorithm_spec[""TrainingSpecification""]\n        algorithm_name = self.algorithm_spec[""AlgorithmName""]\n        training_channels = {c[""Name""]: c for c in train_spec[""TrainingChannels""]}\n\n        # check for unknown channels that the algorithm does not support\n        for c in channels:\n            if c not in training_channels:\n                raise ValueError(\n                    ""Unknown input channel: %s is not supported by: %s"" % (c, algorithm_name)\n                )\n\n        # check for required channels that were not provided\n        for name, channel in training_channels.items():\n            if name not in channels and ""IsRequired"" in channel and channel[""IsRequired""]:\n                raise ValueError(""Required input channel: %s Was not provided."" % (name))\n\n    def _validate_and_cast_hyperparameter(self, name, v):\n        """"""\n        Args:\n            name:\n            v:\n        """"""\n        algorithm_name = self.algorithm_spec[""AlgorithmName""]\n\n        if name not in self.hyperparameter_definitions:\n            raise ValueError(\n                ""Invalid hyperparameter: %s is not supported by %s"" % (name, algorithm_name)\n            )\n\n        definition = self.hyperparameter_definitions[name]\n        if ""class"" in definition:\n            value = definition[""class""].cast_to_type(v)\n        else:\n            value = v\n\n        if ""range"" in definition and not definition[""range""].is_valid(value):\n            valid_range = definition[""range""].as_tuning_range(name)\n            raise ValueError(""Invalid value: %s Supported range: %s"" % (value, valid_range))\n        return value\n\n    def _validate_and_set_default_hyperparameters(self):\n        """"""Placeholder docstring""""""\n        # Check if all the required hyperparameters are set. If there is a default value\n        # for one, set it.\n        for name, definition in self.hyperparameter_definitions.items():\n            if name not in self.hyperparam_dict:\n                spec = definition[""spec""]\n                if ""DefaultValue"" in spec:\n                    self.hyperparam_dict[name] = spec[""DefaultValue""]\n                elif ""IsRequired"" in spec and spec[""IsRequired""]:\n                    raise ValueError(""Required hyperparameter: %s is not set"" % name)\n\n    def _parse_hyperparameters(self):\n        """"""Placeholder docstring""""""\n        definitions = {}\n\n        training_spec = self.algorithm_spec[""TrainingSpecification""]\n        if ""SupportedHyperParameters"" in training_spec:\n            hyperparameters = training_spec[""SupportedHyperParameters""]\n            for h in hyperparameters:\n                parameter_type = h[""Type""]\n                name = h[""Name""]\n                parameter_class, parameter_range = self._hyperparameter_range_and_class(\n                    parameter_type, h\n                )\n\n                definitions[name] = {""spec"": h}\n                if parameter_range:\n                    definitions[name][""range""] = parameter_range\n                if parameter_class:\n                    definitions[name][""class""] = parameter_class\n\n        return definitions\n\n    def _hyperparameter_range_and_class(self, parameter_type, hyperparameter):\n        """"""\n        Args:\n            parameter_type:\n            hyperparameter:\n        """"""\n        if parameter_type in self._hyperpameters_with_range:\n            range_name = parameter_type + ""ParameterRangeSpecification""\n\n        parameter_class = None\n        parameter_range = None\n\n        if parameter_type in (""Integer"", ""Continuous""):\n            # Integer and Continuous are handled the same way. We get the min and max values\n            # and just create an Instance of Parameter. Note that the range is optional for all\n            # the Parameter Types.\n            if parameter_type == ""Integer"":\n                parameter_class = sagemaker.parameter.IntegerParameter\n            else:\n                parameter_class = sagemaker.parameter.ContinuousParameter\n\n            if ""Range"" in hyperparameter:\n                min_value = parameter_class.cast_to_type(\n                    hyperparameter[""Range""][range_name][""MinValue""]\n                )\n                max_value = parameter_class.cast_to_type(\n                    hyperparameter[""Range""][range_name][""MaxValue""]\n                )\n                parameter_range = parameter_class(min_value, max_value)\n\n        elif parameter_type == ""Categorical"":\n            parameter_class = sagemaker.parameter.CategoricalParameter\n            if ""Range"" in hyperparameter:\n                values = hyperparameter[""Range""][range_name][""Values""]\n                parameter_range = sagemaker.parameter.CategoricalParameter(values)\n        elif parameter_type == ""FreeText"":\n            pass\n        else:\n            raise ValueError(\n                ""Invalid Hyperparameter type: %s. Valid ones are:""\n                ""(Integer, Continuous, Categorical, FreeText)"" % parameter_type\n            )\n\n        return parameter_class, parameter_range\n\n    def _algorithm_training_input_modes(self, training_channels):\n        """"""\n        Args:\n            training_channels:\n        """"""\n        current_input_modes = {""File"", ""Pipe""}\n        for channel in training_channels:\n            supported_input_modes = set(channel[""SupportedInputModes""])\n            current_input_modes = current_input_modes & supported_input_modes\n\n        return current_input_modes\n\n    @classmethod\n    def _prepare_init_params_from_job_description(cls, job_details, model_channel_name=None):\n        """"""Convert the job description to init params that can be handled by the\n        class constructor\n\n        Args:\n            job_details (dict): the returned job details from a DescribeTrainingJob\n                API call.\n            model_channel_name (str): Name of the channel where pre-trained\n                model data will be downloaded.\n\n        Returns:\n            dict: The transformed init_params\n        """"""\n        init_params = super(AlgorithmEstimator, cls)._prepare_init_params_from_job_description(\n            job_details, model_channel_name\n        )\n\n        # This hyperparameter is added by Amazon SageMaker Automatic Model Tuning.\n        # It cannot be set through instantiating an estimator.\n        if ""_tuning_objective_metric"" in init_params[""hyperparameters""]:\n            del init_params[""hyperparameters""][""_tuning_objective_metric""]\n\n        return init_params\n'"
src/sagemaker/analytics.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import print_function, absolute_import\n\nfrom abc import ABCMeta, abstractmethod\nfrom collections import defaultdict, OrderedDict\nimport datetime\nimport logging\n\nfrom six import with_metaclass\n\nfrom sagemaker.session import Session\nfrom sagemaker.utils import DeferredError\n\n\ntry:\n    import pandas as pd\nexcept ImportError as e:\n    logging.warning(""pandas failed to import. Analytics features will be impaired or broken."")\n    # Any subsequent attempt to use pandas will raise the ImportError\n    pd = DeferredError(e)\n\nMETRICS_PERIOD_DEFAULT = 60  # seconds\n\n\nclass AnalyticsMetricsBase(with_metaclass(ABCMeta, object)):\n    """"""Base class for tuning job or training job analytics classes. Understands\n    common functionality like persistence and caching.\n    """"""\n\n    def __init__(self):\n        self._dataframe = None\n\n    def export_csv(self, filename):\n        """"""Persists the analytics dataframe to a file.\n\n        Args:\n            filename (str): The name of the file to save to.\n        """"""\n        self.dataframe().to_csv(filename)\n\n    def dataframe(self, force_refresh=False):\n        """"""A pandas dataframe with lots of interesting results about this\n        object. Created by calling SageMaker List and Describe APIs and\n        converting them into a convenient tabular summary.\n\n        Args:\n            force_refresh (bool): Set to True to fetch the latest data from\n                SageMaker API.\n        """"""\n        if force_refresh:\n            self.clear_cache()\n        if self._dataframe is None:\n            self._dataframe = self._fetch_dataframe()\n        return self._dataframe\n\n    @abstractmethod\n    def _fetch_dataframe(self):\n        """"""Sub-class must calculate the dataframe and return it.""""""\n\n    def clear_cache(self):\n        """"""Clear the object of all local caches of API methods, so that the next\n        time any properties are accessed they will be refreshed from the\n        service.\n        """"""\n        self._dataframe = None\n\n\nclass HyperparameterTuningJobAnalytics(AnalyticsMetricsBase):\n    """"""Fetch results about a hyperparameter tuning job and make them accessible\n    for analytics.\n    """"""\n\n    def __init__(self, hyperparameter_tuning_job_name, sagemaker_session=None):\n        """"""Initialize a ``HyperparameterTuningJobAnalytics`` instance.\n\n        Args:\n            hyperparameter_tuning_job_name (str): name of the\n                HyperparameterTuningJob to analyze.\n            sagemaker_session (sagemaker.session.Session): Session object which\n                manages interactions with Amazon SageMaker APIs and any other\n                AWS services needed. If not specified, one is created using the\n                default AWS configuration chain.\n        """"""\n        sagemaker_session = sagemaker_session or Session()\n        self._sage_client = sagemaker_session.sagemaker_client\n        self._tuning_job_name = hyperparameter_tuning_job_name\n        self._tuning_job_describe_result = None\n        self._training_job_summaries = None\n        super(HyperparameterTuningJobAnalytics, self).__init__()\n        self.clear_cache()\n\n    @property\n    def name(self):\n        """"""Name of the HyperparameterTuningJob being analyzed""""""\n        return self._tuning_job_name\n\n    def __repr__(self):\n        return ""<sagemaker.HyperparameterTuningJobAnalytics for %s>"" % self.name\n\n    def clear_cache(self):\n        """"""Clear the object of all local caches of API methods.""""""\n        super(HyperparameterTuningJobAnalytics, self).clear_cache()\n        self._tuning_job_describe_result = None\n        self._training_job_summaries = None\n\n    def _fetch_dataframe(self):\n        """"""Return a pandas dataframe with all the training jobs, along with\n        their hyperparameters, results, and metadata. This also includes a\n        column to indicate if a training job was the best seen so far.\n        """"""\n\n        def reshape(training_summary):\n            # Helper method to reshape a single training job summary into a dataframe record\n            out = {}\n            for k, v in training_summary[""TunedHyperParameters""].items():\n                # Something (bokeh?) gets confused with ints so convert to float\n                try:\n                    v = float(v)\n                except (TypeError, ValueError):\n                    pass\n                out[k] = v\n            out[""TrainingJobName""] = training_summary[""TrainingJobName""]\n            out[""TrainingJobStatus""] = training_summary[""TrainingJobStatus""]\n            out[""FinalObjectiveValue""] = training_summary.get(\n                ""FinalHyperParameterTuningJobObjectiveMetric"", {}\n            ).get(""Value"")\n\n            start_time = training_summary.get(""TrainingStartTime"", None)\n            end_time = training_summary.get(""TrainingEndTime"", None)\n            out[""TrainingStartTime""] = start_time\n            out[""TrainingEndTime""] = end_time\n            if start_time and end_time:\n                out[""TrainingElapsedTimeSeconds""] = (end_time - start_time).total_seconds()\n            if ""TrainingJobDefinitionName"" in training_summary:\n                out[""TrainingJobDefinitionName""] = training_summary[""TrainingJobDefinitionName""]\n            return out\n\n        # Run that helper over all the summaries.\n        df = pd.DataFrame([reshape(tjs) for tjs in self.training_job_summaries()])\n        return df\n\n    @property\n    def tuning_ranges(self):\n        """"""A dictionary describing the ranges of all tuned hyperparameters. The\n        keys are the names of the hyperparameter, and the values are the ranges.\n\n        The output can take one of two forms:\n\n            * If the \'TrainingJobDefinition\' field is present in the job description, the output\n                is a dictionary constructed from \'ParameterRanges\' in\n                \'HyperParameterTuningJobConfig\' of the job description. The keys are the\n                parameter names, while the values are the parameter ranges.\n                Example:\n                >>> {\n                >>>     ""eta"": {""MaxValue"": ""1"", ""MinValue"": ""0"", ""Name"": ""eta""},\n                >>>     ""gamma"": {""MaxValue"": ""10"", ""MinValue"": ""0"", ""Name"": ""gamma""},\n                >>>     ""iterations"": {""MaxValue"": ""100"", ""MinValue"": ""50"", ""Name"": ""iterations""},\n                >>>     ""num_layers"": {""MaxValue"": ""30"", ""MinValue"": ""5"", ""Name"": ""num_layers""},\n                >>> }\n            * If the \'TrainingJobDefinitions\' field (list) is present in the job description,\n                the output is a dictionary with keys as the \'DefinitionName\' values from\n                all items in \'TrainingJobDefinitions\', and each value would be a dictionary\n                constructed from \'HyperParameterRanges\' in each item in \'TrainingJobDefinitions\'\n                in the same format as above\n                Example:\n                >>> {\n                >>>     ""estimator_1"": {\n                >>>         ""eta"": {""MaxValue"": ""1"", ""MinValue"": ""0"", ""Name"": ""eta""},\n                >>>         ""gamma"": {""MaxValue"": ""10"", ""MinValue"": ""0"", ""Name"": ""gamma""},\n                >>>     },\n                >>>     ""estimator_2"": {\n                >>>         ""framework"": {""Values"": [""TF"", ""MXNet""], ""Name"": ""framework""},\n                >>>         ""gamma"": {""MaxValue"": ""1.0"", ""MinValue"": ""0.2"", ""Name"": ""gamma""}\n                >>>     }\n                >>> }\n\n        For more details about the \'TrainingJobDefinition\' and \'TrainingJobDefinitions\' fields\n        in job description, see\n        https://botocore.readthedocs.io/en/latest/reference/services/sagemaker.html#SageMaker.Client.create_hyper_parameter_tuning_job\n        """"""\n        description = self.description()\n\n        if ""TrainingJobDefinition"" in description:\n            return self._prepare_parameter_ranges(\n                description[""HyperParameterTuningJobConfig""][""ParameterRanges""]\n            )\n\n        return {\n            training_job_definition[""DefinitionName""]: self._prepare_parameter_ranges(\n                training_job_definition[""HyperParameterRanges""]\n            )\n            for training_job_definition in description[""TrainingJobDefinitions""]\n        }\n\n    def _prepare_parameter_ranges(self, parameter_ranges):\n        """"""Convert parameter ranges a dictionary using the parameter range names as the keys""""""\n        out = {}\n        for _, ranges in parameter_ranges.items():\n            for param in ranges:\n                out[param[""Name""]] = param\n        return out\n\n    def description(self, force_refresh=False):\n        """"""Call ``DescribeHyperParameterTuningJob`` for the hyperparameter\n        tuning job.\n\n        Args:\n            force_refresh (bool): Set to True to fetch the latest data from\n                SageMaker API.\n\n        Returns:\n            dict: The Amazon SageMaker response for\n            ``DescribeHyperParameterTuningJob``.\n        """"""\n        if force_refresh:\n            self.clear_cache()\n        if not self._tuning_job_describe_result:\n            self._tuning_job_describe_result = self._sage_client.describe_hyper_parameter_tuning_job(  # noqa: E501 # pylint: disable=line-too-long\n                HyperParameterTuningJobName=self.name\n            )\n        return self._tuning_job_describe_result\n\n    def training_job_summaries(self, force_refresh=False):\n        """"""A (paginated) list of everything from\n        ``ListTrainingJobsForTuningJob``.\n\n        Args:\n            force_refresh (bool): Set to True to fetch the latest data from\n                SageMaker API.\n\n        Returns:\n            dict: The Amazon SageMaker response for\n            ``ListTrainingJobsForTuningJob``.\n        """"""\n        if force_refresh:\n            self.clear_cache()\n        if self._training_job_summaries is not None:\n            return self._training_job_summaries\n        output = []\n        next_args = {}\n        for count in range(100):\n            logging.debug(""Calling list_training_jobs_for_hyper_parameter_tuning_job %d"", count)\n            raw_result = self._sage_client.list_training_jobs_for_hyper_parameter_tuning_job(\n                HyperParameterTuningJobName=self.name, MaxResults=100, **next_args\n            )\n            new_output = raw_result[""TrainingJobSummaries""]\n            output.extend(new_output)\n            logging.debug(\n                ""Got %d more TrainingJobs. Total so far: %d"", len(new_output), len(output)\n            )\n            if (""NextToken"" in raw_result) and (len(new_output) > 0):\n                next_args[""NextToken""] = raw_result[""NextToken""]\n            else:\n                break\n        self._training_job_summaries = output\n        return output\n\n\nclass TrainingJobAnalytics(AnalyticsMetricsBase):\n    """"""Fetch training curve data from CloudWatch Metrics for a specific training\n    job.\n    """"""\n\n    CLOUDWATCH_NAMESPACE = ""/aws/sagemaker/TrainingJobs""\n\n    def __init__(\n        self,\n        training_job_name,\n        metric_names=None,\n        sagemaker_session=None,\n        start_time=None,\n        end_time=None,\n        period=None,\n    ):\n        """"""Initialize a ``TrainingJobAnalytics`` instance.\n\n        Args:\n            training_job_name (str): name of the TrainingJob to analyze.\n            metric_names (list, optional): string names of all the metrics to\n                collect for this training job. If not specified, then it will\n                use all metric names configured for this job.\n            sagemaker_session (sagemaker.session.Session): Session object which\n                manages interactions with Amazon SageMaker APIs and any other\n                AWS services needed. If not specified, one is specified using\n                the default AWS configuration chain.\n            start_time:\n            end_time:\n            period:\n        """"""\n        sagemaker_session = sagemaker_session or Session()\n        self._sage_client = sagemaker_session.sagemaker_client\n        self._cloudwatch = sagemaker_session.boto_session.client(""cloudwatch"")\n        self._training_job_name = training_job_name\n        self._start_time = start_time\n        self._end_time = end_time\n        self._period = period or METRICS_PERIOD_DEFAULT\n\n        if metric_names:\n            self._metric_names = metric_names\n        else:\n            self._metric_names = self._metric_names_for_training_job()\n\n        super(TrainingJobAnalytics, self).__init__()\n        self.clear_cache()\n\n    @property\n    def name(self):\n        """"""Name of the TrainingJob being analyzed""""""\n        return self._training_job_name\n\n    def __repr__(self):\n        return ""<sagemaker.TrainingJobAnalytics for %s>"" % self.name\n\n    def clear_cache(self):\n        """"""Clear the object of all local caches of API methods, so that the next\n        time any properties are accessed they will be refreshed from the\n        service.\n        """"""\n        super(TrainingJobAnalytics, self).clear_cache()\n        self._data = defaultdict(list)\n        self._time_interval = self._determine_timeinterval()\n\n    def _determine_timeinterval(self):\n        """"""Return a dictionary with two datetime objects, start_time and\n        end_time, covering the interval of the training job\n        """"""\n        description = self._sage_client.describe_training_job(TrainingJobName=self.name)\n        start_time = self._start_time or description[u""TrainingStartTime""]  # datetime object\n        # Incrementing end time by 1 min since CloudWatch drops seconds before finding the logs.\n        # This results in logs being searched in the time range in which the correct log line was\n        # not present.\n        # Example - Log time - 2018-10-22 08:25:55\n        #       Here calculated end time would also be 2018-10-22 08:25:55 (without 1 min addition)\n        #       CW will consider end time as 2018-10-22 08:25 and will not be able to search the\n        #           correct log.\n        end_time = self._end_time or description.get(\n            u""TrainingEndTime"", datetime.datetime.utcnow()\n        ) + datetime.timedelta(minutes=1)\n\n        return {""start_time"": start_time, ""end_time"": end_time}\n\n    def _fetch_dataframe(self):\n        for metric_name in self._metric_names:\n            self._fetch_metric(metric_name)\n        return pd.DataFrame(self._data)\n\n    def _fetch_metric(self, metric_name):\n        """"""Fetch all the values of a named metric, and add them to _data\n\n        Args:\n            metric_name:\n        """"""\n        request = {\n            ""Namespace"": self.CLOUDWATCH_NAMESPACE,\n            ""MetricName"": metric_name,\n            ""Dimensions"": [{""Name"": ""TrainingJobName"", ""Value"": self.name}],\n            ""StartTime"": self._time_interval[""start_time""],\n            ""EndTime"": self._time_interval[""end_time""],\n            ""Period"": self._period,\n            ""Statistics"": [""Average""],\n        }\n        raw_cwm_data = self._cloudwatch.get_metric_statistics(**request)[""Datapoints""]\n        if len(raw_cwm_data) == 0:\n            logging.warning(""Warning: No metrics called %s found"", metric_name)\n            return\n\n        # Process data: normalize to starting time, and sort.\n        base_time = min(raw_cwm_data, key=lambda pt: pt[""Timestamp""])[""Timestamp""]\n        all_xy = []\n        for pt in raw_cwm_data:\n            y = pt[""Average""]\n            x = (pt[""Timestamp""] - base_time).total_seconds()\n            all_xy.append([x, y])\n        all_xy = sorted(all_xy, key=lambda x: x[0])\n\n        # Store everything in _data to make a dataframe from\n        for elapsed_seconds, value in all_xy:\n            self._add_single_metric(elapsed_seconds, metric_name, value)\n\n    def _add_single_metric(self, timestamp, metric_name, value):\n        """"""Store a single metric in the _data dict which can be converted to a\n        dataframe.\n\n        Args:\n            timestamp:\n            metric_name:\n            value:\n        """"""\n        # note that this method is built this way to make it possible to\n        # support live-refreshing charts in Bokeh at some point in the future.\n        self._data[""timestamp""].append(timestamp)\n        self._data[""metric_name""].append(metric_name)\n        self._data[""value""].append(value)\n\n    def _metric_names_for_training_job(self):\n        """"""Helper method to discover the metrics defined for a training job.""""""\n        training_description = self._sage_client.describe_training_job(\n            TrainingJobName=self._training_job_name\n        )\n\n        metric_definitions = training_description[""AlgorithmSpecification""][""MetricDefinitions""]\n        metric_names = [md[""Name""] for md in metric_definitions]\n\n        return metric_names\n\n\nclass ExperimentAnalytics(AnalyticsMetricsBase):\n    """"""Fetch trial component data and make them accessible for analytics.\n    """"""\n\n    MAX_TRIAL_COMPONENTS = 10000\n\n    def __init__(\n        self,\n        experiment_name=None,\n        search_expression=None,\n        sort_by=None,\n        sort_order=None,\n        metric_names=None,\n        parameter_names=None,\n        sagemaker_session=None,\n    ):\n        """"""Initialize a ``ExperimentAnalytics`` instance.\n\n        Args:\n            experiment_name (str, optional): Name of the experiment if you want to constrain the\n                search to only trial components belonging to an experiment.\n            search_expression (dict, optional): The search query to find the set of trial components\n                to use to populate the data frame.\n            sort_by (str, optional): The name of the resource property used to sort\n                the set of trial components.\n            sort_order(str optional): How trial components are ordered, valid values are Ascending\n                and Descending. The default is Descending.\n            metric_names (list, optional): string names of all the metrics to be shown in the\n                data frame. If not specified, all metrics will be shown of all trials.\n            parameter_names (list, optional): string names of the parameters to be shown in the\n                data frame. If not specified, all parameters will be shown of all trials.\n            sagemaker_session (sagemaker.session.Session): Session object which manages interactions\n                with Amazon SageMaker APIs and any other AWS services needed. If not specified,\n                one is created using the default AWS configuration chain.\n        """"""\n        sagemaker_session = sagemaker_session or Session()\n        self._sage_client = sagemaker_session.sagemaker_client\n\n        if not experiment_name and not search_expression:\n            raise ValueError(""Either experiment_name or search_expression must be supplied."")\n\n        self._experiment_name = experiment_name\n        self._search_expression = search_expression\n        self._sort_by = sort_by\n        self._sort_order = sort_order\n        self._metric_names = metric_names\n        self._parameter_names = parameter_names\n        self._trial_components = None\n        super(ExperimentAnalytics, self).__init__()\n        self.clear_cache()\n\n    @property\n    def name(self):\n        """"""Name of the Experiment being analyzed\n        """"""\n        return self._experiment_name\n\n    def __repr__(self):\n        return ""<sagemaker.ExperimentAnalytics for %s>"" % self.name\n\n    def clear_cache(self):\n        """"""Clear the object of all local caches of API methods.\n        """"""\n        super(ExperimentAnalytics, self).clear_cache()\n        self._trial_components = None\n\n    def _reshape_parameters(self, parameters):\n        """"""Reshape trial component parameters to a pandas column\n        Args:\n            parameters: trial component parameters\n        Returns:\n            dict: Key: Parameter name, Value: Parameter value\n        """"""\n        out = OrderedDict()\n        for name, value in sorted(parameters.items()):\n            if self._parameter_names and name not in self._parameter_names:\n                continue\n            out[name] = value.get(""NumberValue"", value.get(""StringValue""))\n        return out\n\n    def _reshape_metrics(self, metrics):\n        """"""Reshape trial component metrics to a pandas column\n        Args:\n            metrics: trial component metrics\n        Returns:\n            dict: Key: Metric name, Value: Metric value\n        """"""\n        statistic_types = [""Min"", ""Max"", ""Avg"", ""StdDev"", ""Last"", ""Count""]\n        out = OrderedDict()\n        for metric_summary in metrics:\n            metric_name = metric_summary[""MetricName""]\n            if self._metric_names and metric_name not in self._metric_names:\n                continue\n\n            for stat_type in statistic_types:\n                stat_value = metric_summary.get(stat_type)\n                if stat_value is not None:\n                    out[""{} - {}"".format(metric_name, stat_type)] = stat_value\n        return out\n\n    def _reshape(self, trial_component):\n        """"""Reshape trial component data to pandas columns\n        Args:\n            trial_component: dict representing a trial component\n        Returns:\n            dict: Key-Value pair representing the data in the pandas dataframe\n        """"""\n        out = OrderedDict()\n        for attribute in [""TrialComponentName"", ""DisplayName""]:\n            out[attribute] = trial_component.get(attribute, """")\n\n        source = trial_component.get(""Source"", """")\n        if source:\n            out[""SourceArn""] = source[""SourceArn""]\n\n        out.update(self._reshape_parameters(trial_component.get(""Parameters"", [])))\n        out.update(self._reshape_metrics(trial_component.get(""Metrics"", [])))\n        return out\n\n    def _fetch_dataframe(self):\n        """"""Return a pandas dataframe with all the trial_components,\n            along with their parameters and metrics.\n        """"""\n        df = pd.DataFrame([self._reshape(component) for component in self._get_trial_components()])\n        return df\n\n    def _get_trial_components(self, force_refresh=False):\n        """""" Get all trial components matching the given search query expression.\n\n        Args:\n            force_refresh (bool): Set to True to fetch the latest data from SageMaker API.\n\n        Returns:\n            list: List of dicts representing the trial components\n        """"""\n        if force_refresh:\n            self.clear_cache()\n        if self._trial_components is not None:\n            return self._trial_components\n\n        if not self._search_expression:\n            self._search_expression = {}\n\n        if self._experiment_name:\n            if not self._search_expression.get(""Filters""):\n                self._search_expression[""Filters""] = []\n\n            self._search_expression[""Filters""].append(\n                {\n                    ""Name"": ""Parents.ExperimentName"",\n                    ""Operator"": ""Equals"",\n                    ""Value"": self._experiment_name,\n                }\n            )\n\n        return self._search(self._search_expression, self._sort_by, self._sort_order)\n\n    def _search(self, search_expression, sort_by, sort_order):\n        """"""\n        Perform a search query using SageMaker Search and return the matching trial components\n\n        Args:\n            search_expression: Search expression to filter trial components.\n            sort_by: The name of the resource property used to sort the trial components.\n            sort_order: How trial components are ordered, valid values are Ascending\n                and Descending. The default is Descending.\n        Returns:\n            list: List of dict representing trial components.\n        """"""\n        trial_components = []\n\n        search_args = {\n            ""Resource"": ""ExperimentTrialComponent"",\n            ""SearchExpression"": search_expression,\n        }\n\n        if sort_by:\n            search_args[""SortBy""] = sort_by\n\n        if sort_order:\n            search_args[""SortOrder""] = sort_order\n\n        while len(trial_components) < self.MAX_TRIAL_COMPONENTS:\n            search_response = self._sage_client.search(**search_args)\n            components = [result[""TrialComponent""] for result in search_response[""Results""]]\n            trial_components.extend(components)\n            if ""NextToken"" in search_response and len(components) > 0:\n                search_args[""NextToken""] = search_response[""NextToken""]\n            else:\n                break\n\n        return trial_components\n'"
src/sagemaker/content_types.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Contains content types strings""""""\nfrom __future__ import absolute_import\n\nCONTENT_TYPE_JSON = ""application/json""\nCONTENT_TYPE_CSV = ""text/csv""\nCONTENT_TYPE_OCTET_STREAM = ""application/octet-stream""\nCONTENT_TYPE_NPY = ""application/x-npy""\n'"
src/sagemaker/debugger.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Amazon SageMaker Debugger is a service that provides full visibility\ninto the training of machine learning (ML) models, enabling customers\nto automatically detect several classes of errors. Customers can configure\nDebugger when starting their training jobs by specifying debug level, models,\nand location where debug output will be stored. Optionally, customers can\nalso specify custom error conditions that they want to be alerted on.\nDebugger automatically collects model specific data, monitors for errors,\nand alerts when it detects errors during training.\n""""""\nfrom __future__ import absolute_import\n\nimport smdebug_rulesconfig as rule_configs  # noqa: F401 # pylint: disable=unused-import\n\nfrom sagemaker.utils import get_ecr_image_uri_prefix\n\nRULES_ECR_REPO_NAME = ""sagemaker-debugger-rules""\n\nSAGEMAKER_RULE_CONTAINERS_ACCOUNTS_MAP = {\n    ""eu-north-1"": {RULES_ECR_REPO_NAME: ""314864569078""},\n    ""me-south-1"": {RULES_ECR_REPO_NAME: ""986000313247""},\n    ""ap-south-1"": {RULES_ECR_REPO_NAME: ""904829902805""},\n    ""eu-west-3"": {RULES_ECR_REPO_NAME: ""447278800020""},\n    ""us-east-2"": {RULES_ECR_REPO_NAME: ""915447279597""},\n    ""eu-west-1"": {RULES_ECR_REPO_NAME: ""929884845733""},\n    ""eu-central-1"": {RULES_ECR_REPO_NAME: ""482524230118""},\n    ""sa-east-1"": {RULES_ECR_REPO_NAME: ""818342061345""},\n    ""ap-east-1"": {RULES_ECR_REPO_NAME: ""199566480951""},\n    ""us-east-1"": {RULES_ECR_REPO_NAME: ""503895931360""},\n    ""ap-northeast-2"": {RULES_ECR_REPO_NAME: ""578805364391""},\n    ""eu-west-2"": {RULES_ECR_REPO_NAME: ""250201462417""},\n    ""ap-northeast-1"": {RULES_ECR_REPO_NAME: ""430734990657""},\n    ""us-west-2"": {RULES_ECR_REPO_NAME: ""895741380848""},\n    ""us-west-1"": {RULES_ECR_REPO_NAME: ""685455198987""},\n    ""ap-southeast-1"": {RULES_ECR_REPO_NAME: ""972752614525""},\n    ""ap-southeast-2"": {RULES_ECR_REPO_NAME: ""184798709955""},\n    ""ca-central-1"": {RULES_ECR_REPO_NAME: ""519511493484""},\n    ""cn-north-1"": {RULES_ECR_REPO_NAME: ""618459771430""},\n    ""cn-northwest-1"": {RULES_ECR_REPO_NAME: ""658757709296""},\n}\n\n\ndef get_rule_container_image_uri(region):\n    """"""\n    Returns the rule image uri for the given AWS region and rule type\n\n    Args:\n        region: AWS Region\n\n    Returns:\n        str: Formatted image uri for the given region and the rule container type\n    """"""\n    registry_id = SAGEMAKER_RULE_CONTAINERS_ACCOUNTS_MAP.get(region).get(RULES_ECR_REPO_NAME)\n    image_uri_prefix = get_ecr_image_uri_prefix(registry_id, region)\n    return ""{}/{}:latest"".format(image_uri_prefix, RULES_ECR_REPO_NAME)\n\n\nclass Rule(object):\n    """"""Rules analyze tensors emitted during the training of a model. They\n    monitor conditions that are critical for the success of a training job.\n\n    For example, they can detect whether gradients are getting too large or\n    too small or if a model is being overfit. Debugger comes pre-packaged with\n    certain built-in rules (created using the Rule.sagemaker classmethod).\n    You can use these rules or write your own rules using the Amazon SageMaker\n    Debugger APIs. You can also analyze raw tensor data without using rules in,\n    for example, an Amazon SageMaker notebook, using Debugger\'s full set of APIs.\n    """"""\n\n    def __init__(\n        self,\n        name,\n        image_uri,\n        instance_type,\n        container_local_output_path,\n        s3_output_path,\n        volume_size_in_gb,\n        rule_parameters,\n        collections_to_save,\n    ):\n        """"""Do not use this initialization method. Instead, use either the\n        ``Rule.sagemaker`` or ``Rule.custom`` class method.\n\n        Initialize a ``Rule`` instance. The Rule analyzes tensors emitted\n        during the training of a model and monitors conditions that are critical\n        for the success of a training job.\n\n        Args:\n            name (str): The name of the debugger rule.\n            image_uri (str): The URI of the image to be used by the debugger rule.\n            instance_type (str): Type of EC2 instance to use, for example,\n                \'ml.c4.xlarge\'.\n            container_local_output_path (str): The local path to store the Rule output.\n            s3_output_path (str): The location in S3 to store the output.\n            volume_size_in_gb (int): Size in GB of the EBS volume\n                to use for storing data.\n            rule_parameters (dict): A dictionary of parameters for the rule.\n            collections_to_save ([sagemaker.debugger.CollectionConfig]): A list\n                of CollectionConfig objects to be saved.\n        """"""\n        self.name = name\n        self.instance_type = instance_type\n        self.container_local_output_path = container_local_output_path\n        self.s3_output_path = s3_output_path\n        self.volume_size_in_gb = volume_size_in_gb\n        self.rule_parameters = rule_parameters\n        self.collection_configs = collections_to_save\n        self.image_uri = image_uri\n\n    @classmethod\n    def sagemaker(\n        cls,\n        base_config,\n        name=None,\n        container_local_output_path=None,\n        s3_output_path=None,\n        other_trials_s3_input_paths=None,\n        rule_parameters=None,\n        collections_to_save=None,\n    ):\n        """"""Initialize a ``Rule`` instance for a built-in SageMaker Debugging\n        Rule. The Rule analyzes tensors emitted during the training of a model\n        and monitors conditions that are critical for the success of a training\n        job.\n\n        Args:\n            base_config (dict): This is the base rule config returned from the\n                built-in list of rules. For example, \'rule_configs.dead_relu()\'.\n            name (str): The name of the debugger rule. If one is not provided,\n                the name of the base_config will be used.\n            container_local_output_path (str): The path in the container.\n            s3_output_path (str): The location in S3 to store the output.\n            other_trials_s3_input_paths ([str]): S3 input paths for other trials.\n            rule_parameters (dict): A dictionary of parameters for the rule.\n            collections_to_save ([sagemaker.debugger.CollectionConfig]): A list\n                of CollectionConfig objects to be saved.\n\n        Returns:\n            sagemaker.debugger.Rule: The instance of the built-in Rule.\n        """"""\n        merged_rule_params = {}\n\n        if rule_parameters is not None and rule_parameters.get(""rule_to_invoke"") is not None:\n            raise RuntimeError(\n                """"""You cannot provide a \'rule_to_invoke\' for SageMaker rules.\n                Please either remove the rule_to_invoke or use a custom rule.\n                """"""\n            )\n\n        if other_trials_s3_input_paths is not None:\n            for index, s3_input_path in enumerate(other_trials_s3_input_paths):\n                merged_rule_params[""other_trial_{}"".format(str(index))] = s3_input_path\n\n        default_rule_params = base_config[""DebugRuleConfiguration""].get(""RuleParameters"", {})\n        merged_rule_params.update(default_rule_params)\n        merged_rule_params.update(rule_parameters or {})\n\n        base_config_collections = []\n        for config in base_config.get(""CollectionConfigurations"", []):\n            collection_name = None\n            collection_parameters = {}\n            for key, value in config.items():\n                if key == ""CollectionName"":\n                    collection_name = value\n                if key == ""CollectionParameters"":\n                    collection_parameters = value\n            base_config_collections.append(\n                CollectionConfig(name=collection_name, parameters=collection_parameters)\n            )\n\n        return cls(\n            name=name or base_config[""DebugRuleConfiguration""].get(""RuleConfigurationName""),\n            image_uri=""DEFAULT_RULE_EVALUATOR_IMAGE"",\n            instance_type=None,\n            container_local_output_path=container_local_output_path,\n            s3_output_path=s3_output_path,\n            volume_size_in_gb=None,\n            rule_parameters=merged_rule_params,\n            collections_to_save=collections_to_save or base_config_collections,\n        )\n\n    @classmethod\n    def custom(\n        cls,\n        name,\n        image_uri,\n        instance_type,\n        volume_size_in_gb,\n        source=None,\n        rule_to_invoke=None,\n        container_local_output_path=None,\n        s3_output_path=None,\n        other_trials_s3_input_paths=None,\n        rule_parameters=None,\n        collections_to_save=None,\n    ):\n        """"""Initialize a ``Rule`` instance for a custom rule. The Rule\n        analyzes tensors emitted during the training of a model and\n        monitors conditions that are critical for the success of a\n        training job.\n\n        Args:\n            name (str): The name of the debugger rule.\n            image_uri (str): The URI of the image to be used by the debugger rule.\n            instance_type (str): Type of EC2 instance to use, for example,\n                \'ml.c4.xlarge\'.\n            volume_size_in_gb (int): Size in GB of the EBS volume\n                to use for storing data.\n            source (str): A source file containing a rule to invoke. If provided,\n                you must also provide rule_to_invoke. This can either be an S3 uri or\n                a local path.\n            rule_to_invoke (str): The name of the rule to invoke within the source.\n                If provided, you must also provide source.\n            container_local_output_path (str): The path in the container.\n            s3_output_path (str): The location in S3 to store the output.\n            other_trials_s3_input_paths ([str]): S3 input paths for other trials.\n            rule_parameters (dict): A dictionary of parameters for the rule.\n            collections_to_save ([sagemaker.debugger.CollectionConfig]): A list\n                of CollectionConfig objects to be saved.\n\n        Returns:\n            sagemaker.debugger.Rule: The instance of the custom Rule.\n        """"""\n        if bool(source) ^ bool(rule_to_invoke):\n            raise ValueError(\n                ""If you provide a source, you must also provide a rule to invoke (and vice versa).""\n            )\n\n        merged_rule_params = {}\n\n        if source is not None and rule_to_invoke is not None:\n            merged_rule_params[""source_s3_uri""] = source\n            merged_rule_params[""rule_to_invoke""] = rule_to_invoke\n\n        other_trials_params = {}\n        if other_trials_s3_input_paths is not None:\n            for index, s3_input_path in enumerate(other_trials_s3_input_paths):\n                other_trials_params[""other_trial_{}"".format(str(index))] = s3_input_path\n\n        merged_rule_params.update(other_trials_params)\n        merged_rule_params.update(rule_parameters or {})\n\n        return cls(\n            name=name,\n            image_uri=image_uri,\n            instance_type=instance_type,\n            container_local_output_path=container_local_output_path,\n            s3_output_path=s3_output_path,\n            volume_size_in_gb=volume_size_in_gb,\n            rule_parameters=merged_rule_params,\n            collections_to_save=collections_to_save or [],\n        )\n\n    def to_debugger_rule_config_dict(self):\n        """"""Generates a request dictionary using the parameters provided\n        when initializing the object.\n\n        Returns:\n            dict: An portion of an API request as a dictionary.\n        """"""\n        debugger_rule_config_request = {\n            ""RuleConfigurationName"": self.name,\n            ""RuleEvaluatorImage"": self.image_uri,\n        }\n\n        if self.instance_type is not None:\n            debugger_rule_config_request[""InstanceType""] = self.instance_type\n\n        if self.volume_size_in_gb is not None:\n            debugger_rule_config_request[""VolumeSizeInGB""] = self.volume_size_in_gb\n\n        if self.container_local_output_path is not None:\n            debugger_rule_config_request[""LocalPath""] = self.container_local_output_path\n\n        if self.s3_output_path is not None:\n            debugger_rule_config_request[""S3OutputPath""] = self.s3_output_path\n\n        if self.rule_parameters:\n            debugger_rule_config_request[""RuleParameters""] = self.rule_parameters\n\n        return debugger_rule_config_request\n\n\nclass DebuggerHookConfig(object):\n    """"""DebuggerHookConfig provides options to customize how debugging\n    information is emitted.\n    """"""\n\n    def __init__(\n        self,\n        s3_output_path=None,\n        container_local_output_path=None,\n        hook_parameters=None,\n        collection_configs=None,\n    ):\n        """"""Initialize an instance of ``DebuggerHookConfig``.\n        DebuggerHookConfig provides options to customize how debugging\n        information is emitted.\n\n        Args:\n            s3_output_path (str): The location in S3 to store the output.\n            container_local_output_path (str): The path in the container.\n            hook_parameters (dict): A dictionary of parameters.\n            collection_configs ([sagemaker.debugger.CollectionConfig]): A list\n                of CollectionConfig objects to be provided to the API.\n        """"""\n        self.s3_output_path = s3_output_path\n        self.container_local_output_path = container_local_output_path\n        self.hook_parameters = hook_parameters\n        self.collection_configs = collection_configs\n\n    def _to_request_dict(self):\n        """"""Generates a request dictionary using the parameters provided\n        when initializing the object.\n\n        Returns:\n            dict: An portion of an API request as a dictionary.\n        """"""\n        debugger_hook_config_request = {""S3OutputPath"": self.s3_output_path}\n\n        if self.container_local_output_path is not None:\n            debugger_hook_config_request[""LocalPath""] = self.container_local_output_path\n\n        if self.hook_parameters is not None:\n            debugger_hook_config_request[""HookParameters""] = self.hook_parameters\n\n        if self.collection_configs is not None:\n            debugger_hook_config_request[""CollectionConfigurations""] = [\n                collection_config._to_request_dict()\n                for collection_config in self.collection_configs\n            ]\n\n        return debugger_hook_config_request\n\n\nclass TensorBoardOutputConfig(object):\n    """"""TensorBoardOutputConfig provides options to customize\n    debugging visualization using TensorBoard.""""""\n\n    def __init__(self, s3_output_path, container_local_output_path=None):\n        """"""Initialize an instance of TensorBoardOutputConfig.\n        TensorBoardOutputConfig provides options to customize\n        debugging visualization using TensorBoard.\n\n        Args:\n            s3_output_path (str): The location in S3 to store the output.\n            container_local_output_path (str): The path in the container.\n        """"""\n        self.s3_output_path = s3_output_path\n        self.container_local_output_path = container_local_output_path\n\n    def _to_request_dict(self):\n        """"""Generates a request dictionary using the parameters provided\n        when initializing the object.\n\n        Returns:\n            dict: An portion of an API request as a dictionary.\n        """"""\n        tensorboard_output_config_request = {""S3OutputPath"": self.s3_output_path}\n\n        if self.container_local_output_path is not None:\n            tensorboard_output_config_request[""LocalPath""] = self.container_local_output_path\n\n        return tensorboard_output_config_request\n\n\nclass CollectionConfig(object):\n    """"""CollectionConfig object for SageMaker Debugger.""""""\n\n    def __init__(self, name, parameters=None):\n        """"""Initialize a ``CollectionConfig`` object.\n\n        Args:\n            name (str): The name of the collection configuration.\n            parameters (dict): The parameters for the collection\n                configuration.\n        """"""\n        self.name = name\n        self.parameters = parameters\n\n    def __eq__(self, other):\n        if not isinstance(other, CollectionConfig):\n            raise TypeError(\n                ""CollectionConfig is only comparable with other CollectionConfig objects.""\n            )\n\n        return self.name == other.name and self.parameters == other.parameters\n\n    def __ne__(self, other):\n        if not isinstance(other, CollectionConfig):\n            raise TypeError(\n                ""CollectionConfig is only comparable with other CollectionConfig objects.""\n            )\n\n        return self.name != other.name or self.parameters != other.parameters\n\n    def __hash__(self):\n        return hash((self.name, tuple(sorted((self.parameters or {}).items()))))\n\n    def _to_request_dict(self):\n        """"""Generates a request dictionary using the parameters provided\n        when initializing the object.\n\n        Returns:\n            dict: An portion of an API request as a dictionary.\n        """"""\n        collection_config_request = {""CollectionName"": self.name}\n\n        if self.parameters is not None:\n            collection_config_request[""CollectionParameters""] = self.parameters\n\n        return collection_config_request\n'"
src/sagemaker/estimator.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import print_function, absolute_import\n\nimport json\nimport logging\nimport os\nimport uuid\nimport warnings\nfrom abc import ABCMeta\nfrom abc import abstractmethod\n\nfrom six import with_metaclass\nfrom six import string_types\nfrom six.moves.urllib.parse import urlparse\nimport sagemaker\nfrom sagemaker import git_utils\nfrom sagemaker.analytics import TrainingJobAnalytics\nfrom sagemaker.debugger import DebuggerHookConfig\nfrom sagemaker.debugger import TensorBoardOutputConfig  # noqa: F401 # pylint: disable=unused-import\nfrom sagemaker.debugger import get_rule_container_image_uri\nfrom sagemaker.s3 import S3Uploader\n\nfrom sagemaker.fw_utils import (\n    create_image_uri,\n    tar_and_upload_dir,\n    parse_s3_url,\n    UploadedCode,\n    validate_source_dir,\n    _region_supports_debugger,\n    parameter_v2_rename_warning,\n)\nfrom sagemaker.job import _Job\nfrom sagemaker.local import LocalSession\nfrom sagemaker.model import Model, NEO_ALLOWED_FRAMEWORKS\nfrom sagemaker.model import (\n    SCRIPT_PARAM_NAME,\n    DIR_PARAM_NAME,\n    CLOUDWATCH_METRICS_PARAM_NAME,\n    CONTAINER_LOG_LEVEL_PARAM_NAME,\n    JOB_NAME_PARAM_NAME,\n    SAGEMAKER_REGION_PARAM_NAME,\n)\nfrom sagemaker.predictor import RealTimePredictor\nfrom sagemaker.session import Session\nfrom sagemaker.session import s3_input\nfrom sagemaker.transformer import Transformer\nfrom sagemaker.utils import base_name_from_image, name_from_base, get_config_value\nfrom sagemaker import vpc_utils\n\n\nclass EstimatorBase(with_metaclass(ABCMeta, object)):\n    """"""Handle end-to-end Amazon SageMaker training and deployment tasks.\n\n    For introduction to model training and deployment, see\n    http://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-training.html\n\n    Subclasses must define a way to determine what image to use for training,\n    what hyperparameters to use, and how to create an appropriate predictor\n    instance.\n    """"""\n\n    def __init__(\n        self,\n        role,\n        train_instance_count,\n        train_instance_type,\n        train_volume_size=30,\n        train_volume_kms_key=None,\n        train_max_run=24 * 60 * 60,\n        input_mode=""File"",\n        output_path=None,\n        output_kms_key=None,\n        base_job_name=None,\n        sagemaker_session=None,\n        tags=None,\n        subnets=None,\n        security_group_ids=None,\n        model_uri=None,\n        model_channel_name=""model"",\n        metric_definitions=None,\n        encrypt_inter_container_traffic=False,\n        train_use_spot_instances=False,\n        train_max_wait=None,\n        checkpoint_s3_uri=None,\n        checkpoint_local_path=None,\n        rules=None,\n        debugger_hook_config=None,\n        tensorboard_output_config=None,\n        enable_sagemaker_metrics=None,\n        enable_network_isolation=False,\n    ):\n        """"""Initialize an ``EstimatorBase`` instance.\n\n        Args:\n            role (str): An AWS IAM role (either name or full ARN). The Amazon\n                SageMaker training jobs and APIs that create Amazon SageMaker\n                endpoints use this role to access training data and model\n                artifacts. After the endpoint is created, the inference code\n                might use the IAM role, if it needs to access an AWS resource.\n            train_instance_count (int): Number of Amazon EC2 instances to use\n                for training.\n            train_instance_type (str): Type of EC2 instance to use for training,\n                for example, \'ml.c4.xlarge\'.\n            train_volume_size (int): Size in GB of the EBS volume to use for\n                storing input data during training (default: 30). Must be large\n                enough to store training data if File Mode is used (which is the\n                default).\n            train_volume_kms_key (str): Optional. KMS key ID for encrypting EBS\n                volume attached to the training instance (default: None).\n            train_max_run (int): Timeout in seconds for training (default: 24 *\n                60 * 60). After this amount of time Amazon SageMaker terminates\n                the job regardless of its current status.\n            input_mode (str): The input mode that the algorithm supports\n                (default: \'File\'). Valid modes: \'File\' - Amazon SageMaker copies\n                the training dataset from the S3 location to a local directory.\n                \'Pipe\' - Amazon SageMaker streams data directly from S3 to the\n                container via a Unix-named pipe. This argument can be overriden\n                on a per-channel basis using\n                ``sagemaker.session.s3_input.input_mode``.\n            output_path (str): S3 location for saving the training result (model\n                artifacts and output files). If not specified, results are\n                stored to a default bucket. If the bucket with the specific name\n                does not exist, the estimator creates the bucket during the\n                :meth:`~sagemaker.estimator.EstimatorBase.fit` method execution.\n                file:// urls are used for local mode. For example: \'file://model/\'\n                will save to the model folder in the current directory.\n            output_kms_key (str): Optional. KMS key ID for encrypting the\n                training output (default: None).\n            base_job_name (str): Prefix for training job name when the\n                :meth:`~sagemaker.estimator.EstimatorBase.fit` method launches.\n                If not specified, the estimator generates a default job name,\n                based on the training image name and current timestamp.\n            sagemaker_session (sagemaker.session.Session): Session object which\n                manages interactions with Amazon SageMaker APIs and any other\n                AWS services needed. If not specified, the estimator creates one\n                using the default AWS configuration chain.\n            tags (list[dict]): List of tags for labeling a training job. For\n                more, see\n                https://docs.aws.amazon.com/sagemaker/latest/dg/API_Tag.html.\n            subnets (list[str]): List of subnet ids. If not specified training\n                job will be created without VPC config.\n            security_group_ids (list[str]): List of security group ids. If not\n                specified training job will be created without VPC config.\n            model_uri (str): URI where a pre-trained model is stored, either\n                locally or in S3 (default: None). If specified, the estimator\n                will create a channel pointing to the model so the training job\n                can download it. This model can be a \'model.tar.gz\' from a\n                previous training job, or other artifacts coming from a\n                different source.\n\n                In local mode, this should point to the path in which the model\n                is located and not the file itself, as local Docker containers\n                will try to mount the URI as a volume.\n\n                More information:\n                https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-training.html#td-deserialization\n            model_channel_name (str): Name of the channel where \'model_uri\' will\n                be downloaded (default: \'model\').\n            metric_definitions (list[dict]): A list of dictionaries that defines\n                the metric(s) used to evaluate the training jobs. Each\n                dictionary contains two keys: \'Name\' for the name of the metric,\n                and \'Regex\' for the regular expression used to extract the\n                metric from the logs. This should be defined only for jobs that\n                don\'t use an Amazon algorithm.\n            encrypt_inter_container_traffic (bool): Specifies whether traffic\n                between training containers is encrypted for the training job\n                (default: ``False``).\n            train_use_spot_instances (bool): Specifies whether to use SageMaker\n                Managed Spot instances for training. If enabled then the\n                `train_max_wait` arg should also be set.\n\n                More information:\n                https://docs.aws.amazon.com/sagemaker/latest/dg/model-managed-spot-training.html\n                (default: ``False``).\n            train_max_wait (int): Timeout in seconds waiting for spot training\n                instances (default: None). After this amount of time Amazon\n                SageMaker will stop waiting for Spot instances to become\n                available (default: ``None``).\n            checkpoint_s3_uri (str): The S3 URI in which to persist checkpoints\n                that the algorithm persists (if any) during training. (default:\n                ``None``).\n            checkpoint_local_path (str): The local path that the algorithm\n                writes its checkpoints to. SageMaker will persist all files\n                under this path to `checkpoint_s3_uri` continually during\n                training. On job startup the reverse happens - data from the\n                s3 location is downloaded to this path before the algorithm is\n                started. If the path is unset then SageMaker assumes the\n                checkpoints will be provided under `/opt/ml/checkpoints/`.\n                (default: ``None``).\n            rules (list[:class:`~sagemaker.debugger.Rule`]): A list of\n                :class:`~sagemaker.debugger.Rule` objects used to define\n                rules for continuous analysis with SageMaker Debugger\n                (default: ``None``). For more, see\n                https://sagemaker.readthedocs.io/en/stable/amazon_sagemaker_debugger.html#continuous-analyses-through-rules\n            debugger_hook_config (:class:`~sagemaker.debugger.DebuggerHookConfig` or bool):\n                Configuration for how debugging information is emitted with\n                SageMaker Debugger. If not specified, a default one is created using\n                the estimator\'s ``output_path``, unless the region does not\n                support SageMaker Debugger. To disable SageMaker Debugger,\n                set this parameter to ``False``. For more, see\n                https://sagemaker.readthedocs.io/en/stable/amazon_sagemaker_debugger.html\n            tensorboard_output_config (:class:`~sagemaker.debugger.TensorBoardOutputConfig`):\n                Configuration for customizing debugging visualization using TensorBoard\n                (default: ``None``). For more, see\n                https://sagemaker.readthedocs.io/en/stable/amazon_sagemaker_debugger.html#capture-real-time-tensorboard-data-from-the-debugging-hook\n            enable_sagemaker_metrics (bool): Enables SageMaker Metrics Time\n                Series. For more information see:\n                https://docs.aws.amazon.com/sagemaker/latest/dg/API_AlgorithmSpecification.html#SageMaker-Type-AlgorithmSpecification-EnableSageMakerMetricsTimeSeries\n                (default: ``None``).\n            enable_network_isolation (bool): Specifies whether container will\n                run in network isolation mode (default: ``False``). Network\n                isolation mode restricts the container access to outside networks\n                (such as the Internet). The container does not make any inbound or\n                outbound network calls. Also known as Internet-free mode.\n        """"""\n        self.role = role\n        self.train_instance_count = train_instance_count\n        self.train_instance_type = train_instance_type\n        self.train_volume_size = train_volume_size\n        self.train_volume_kms_key = train_volume_kms_key\n        self.train_max_run = train_max_run\n        self.input_mode = input_mode\n        self.tags = tags\n        self.metric_definitions = metric_definitions\n        self.model_uri = model_uri\n        self.model_channel_name = model_channel_name\n        self.code_uri = None\n        self.code_channel_name = ""code""\n\n        if self.train_instance_type in (""local"", ""local_gpu""):\n            if self.train_instance_type == ""local_gpu"" and self.train_instance_count > 1:\n                raise RuntimeError(""Distributed Training in Local GPU is not supported"")\n            self.sagemaker_session = sagemaker_session or LocalSession()\n            if not isinstance(self.sagemaker_session, sagemaker.local.LocalSession):\n                raise RuntimeError(\n                    ""instance_type local or local_gpu is only supported with an""\n                    ""instance of LocalSession""\n                )\n        else:\n            self.sagemaker_session = sagemaker_session or Session()\n\n        self.base_job_name = base_job_name\n        self._current_job_name = None\n        if (\n            not self.sagemaker_session.local_mode\n            and output_path\n            and output_path.startswith(""file://"")\n        ):\n            raise RuntimeError(""file:// output paths are only supported in Local Mode"")\n        self.output_path = output_path\n        self.output_kms_key = output_kms_key\n        self.latest_training_job = None\n        self.jobs = []\n        self.deploy_instance_type = None\n\n        self._compiled_models = {}\n\n        # VPC configurations\n        self.subnets = subnets\n        self.security_group_ids = security_group_ids\n\n        self.encrypt_inter_container_traffic = encrypt_inter_container_traffic\n        self.train_use_spot_instances = train_use_spot_instances\n        self.train_max_wait = train_max_wait\n        self.checkpoint_s3_uri = checkpoint_s3_uri\n        self.checkpoint_local_path = checkpoint_local_path\n\n        self.rules = rules\n        self.debugger_hook_config = debugger_hook_config\n        self.tensorboard_output_config = tensorboard_output_config\n\n        self.debugger_rule_configs = None\n        self.collection_configs = None\n\n        self.enable_sagemaker_metrics = enable_sagemaker_metrics\n        self._enable_network_isolation = enable_network_isolation\n\n    @abstractmethod\n    def train_image(self):\n        """"""Return the Docker image to use for training.\n\n        The :meth:`~sagemaker.estimator.EstimatorBase.fit` method, which does\n        the model training, calls this method to find the image to use for model\n        training.\n\n        Returns:\n            str: The URI of the Docker image.\n        """"""\n\n    @abstractmethod\n    def hyperparameters(self):\n        """"""Return the hyperparameters as a dictionary to use for training.\n\n        The :meth:`~sagemaker.estimator.EstimatorBase.fit` method, which\n        trains the model, calls this method to find the hyperparameters.\n\n        Returns:\n            dict[str, str]: The hyperparameters.\n        """"""\n\n    def enable_network_isolation(self):\n        """"""Return True if this Estimator will need network isolation to run.\n\n        Returns:\n            bool: Whether this Estimator needs network isolation or not.\n        """"""\n        return self._enable_network_isolation\n\n    def prepare_workflow_for_training(self, job_name=None):\n        """"""Calls _prepare_for_training. Used when setting up a workflow.\n\n        Args:\n            job_name (str): Name of the training job to be created. If not\n                specified, one is generated, using the base name given to the\n                constructor if applicable.\n        """"""\n        self._prepare_for_training(job_name=job_name)\n\n    def _prepare_for_training(self, job_name=None):\n        """"""Set any values in the estimator that need to be set before training.\n\n        Args:\n            job_name (str): Name of the training job to be created. If not\n                specified, one is generated, using the base name given to the\n                constructor if applicable.\n        """"""\n        if job_name is not None:\n            self._current_job_name = job_name\n        else:\n            # honor supplied base_job_name or generate it\n            if self.base_job_name:\n                base_name = self.base_job_name\n            elif isinstance(self, sagemaker.algorithm.AlgorithmEstimator):\n                base_name = self.algorithm_arn.split(""/"")[-1]  # pylint: disable=no-member\n            else:\n                base_name = base_name_from_image(self.train_image())\n\n            self._current_job_name = name_from_base(base_name)\n\n        # if output_path was specified we use it otherwise initialize here.\n        # For Local Mode with local_code=True we don\'t need an explicit output_path\n        if self.output_path is None:\n            local_code = get_config_value(""local.local_code"", self.sagemaker_session.config)\n            if self.sagemaker_session.local_mode and local_code:\n                self.output_path = """"\n            else:\n                self.output_path = ""s3://{}/"".format(self.sagemaker_session.default_bucket())\n\n        # Prepare rules and debugger configs for training.\n        if self.rules and self.debugger_hook_config is None:\n            self.debugger_hook_config = DebuggerHookConfig(s3_output_path=self.output_path)\n        # If an object was provided without an S3 URI is not provided, default it for the customer.\n        if self.debugger_hook_config and not self.debugger_hook_config.s3_output_path:\n            self.debugger_hook_config.s3_output_path = self.output_path\n        self._prepare_rules()\n        self._prepare_collection_configs()\n\n    def _prepare_rules(self):\n        """"""Set any necessary values in debugger rules, if they are provided.""""""\n        self.debugger_rule_configs = []\n        if self.rules is not None:\n            # Iterate through each of the provided rules.\n            for rule in self.rules:\n                # Set the image URI using the default rule evaluator image and the region.\n                if rule.image_uri == ""DEFAULT_RULE_EVALUATOR_IMAGE"":\n                    rule.image_uri = get_rule_container_image_uri(\n                        self.sagemaker_session.boto_region_name\n                    )\n                    rule.instance_type = None\n                    rule.volume_size_in_gb = None\n                # If source was provided as a rule parameter, upload to S3 and save the S3 uri.\n                if ""source_s3_uri"" in (rule.rule_parameters or {}):\n                    parse_result = urlparse(rule.rule_parameters[""source_s3_uri""])\n                    if parse_result.scheme != ""s3"":\n                        desired_s3_uri = os.path.join(\n                            ""s3://"",\n                            self.sagemaker_session.default_bucket(),\n                            rule.name,\n                            str(uuid.uuid4()),\n                        )\n                        s3_uri = S3Uploader.upload(\n                            local_path=rule.rule_parameters[""source_s3_uri""],\n                            desired_s3_uri=desired_s3_uri,\n                            session=self.sagemaker_session,\n                        )\n                        rule.rule_parameters[""source_s3_uri""] = s3_uri\n                # Save the request dictionary for the rule.\n                self.debugger_rule_configs.append(rule.to_debugger_rule_config_dict())\n\n    def _prepare_collection_configs(self):\n        """"""De-duplicate any collection configurations and save them\n        in the debugger hook configuration.\n        """"""\n        # Create a set to de-duplicate CollectionConfigs.\n        self.collection_configs = set()\n        # Iterate through the rules and add their respective CollectionConfigs to the set.\n        if self.rules is not None:\n            for rule in self.rules:\n                self.collection_configs.update(rule.collection_configs)\n        # Add the CollectionConfigs from DebuggerHookConfig to the set.\n        if self.debugger_hook_config:\n            self.collection_configs.update(self.debugger_hook_config.collection_configs or [])\n\n    def latest_job_debugger_artifacts_path(self):\n        """"""Gets the path to the DebuggerHookConfig output artifacts.\n\n        Returns:\n            str: An S3 path to the output artifacts.\n        """"""\n        self._ensure_latest_training_job(\n            error_message=""""""Cannot get the Debugger artifacts path.\n        The Estimator is not associated with a training job.""""""\n        )\n        if self.debugger_hook_config is not None:\n            return os.path.join(\n                self.debugger_hook_config.s3_output_path,\n                self.latest_training_job.name,\n                ""debug-output"",\n            )\n        return None\n\n    def latest_job_tensorboard_artifacts_path(self):\n        """"""Gets the path to the TensorBoardOutputConfig output artifacts.\n\n        Returns:\n            str: An S3 path to the output artifacts.\n        """"""\n        self._ensure_latest_training_job(\n            error_message=""""""Cannot get the TensorBoard artifacts path.\n        The Estimator is not associated with a training job.""""""\n        )\n        if self.debugger_hook_config is not None:\n            return os.path.join(\n                self.tensorboard_output_config.s3_output_path,\n                self.latest_training_job.name,\n                ""tensorboard-output"",\n            )\n        return None\n\n    def fit(self, inputs=None, wait=True, logs=""All"", job_name=None, experiment_config=None):\n        """"""Train a model using the input training dataset.\n\n        The API calls the Amazon SageMaker CreateTrainingJob API to start\n        model training. The API uses configuration you provided to create the\n        estimator and the specified input training data to send the\n        CreatingTrainingJob request to Amazon SageMaker.\n\n        This is a synchronous operation. After the model training\n        successfully completes, you can call the ``deploy()`` method to host the\n        model using the Amazon SageMaker hosting services.\n\n        Args:\n            inputs (str or dict or sagemaker.session.s3_input): Information\n                about the training data. This can be one of three types:\n\n                * (str) the S3 location where training data is saved, or a file:// path in\n                    local mode.\n                * (dict[str, str] or dict[str, sagemaker.session.s3_input]) If using multiple\n                    channels for training data, you can specify a dict mapping channel names to\n                    strings or :func:`~sagemaker.session.s3_input` objects.\n                * (sagemaker.session.s3_input) - channel configuration for S3 data sources that can\n                    provide additional information as well as the path to the training dataset.\n                    See :func:`sagemaker.session.s3_input` for full details.\n                * (sagemaker.session.FileSystemInput) - channel configuration for\n                    a file system data source that can provide additional information as well as\n                    the path to the training dataset.\n\n            wait (bool): Whether the call should wait until the job completes (default: True).\n            logs ([str]): A list of strings specifying which logs to print. Acceptable\n                strings are ""All"", ""None"", ""Training"", or ""Rules"". To maintain backwards\n                compatibility, boolean values are also accepted and converted to strings.\n                Only meaningful when wait is True.\n            job_name (str): Training job name. If not specified, the estimator generates\n                a default job name, based on the training image name and current timestamp.\n            experiment_config (dict[str, str]): Experiment management configuration.\n                Dictionary contains three optional keys,\n                \'ExperimentName\', \'TrialName\', and \'TrialComponentDisplayName\'.\n\n        """"""\n        self._prepare_for_training(job_name=job_name)\n\n        self.latest_training_job = _TrainingJob.start_new(self, inputs, experiment_config)\n        self.jobs.append(self.latest_training_job)\n        if wait:\n            self.latest_training_job.wait(logs=logs)\n\n    def _compilation_job_name(self):\n        """"""Placeholder docstring""""""\n        base_name = self.base_job_name or base_name_from_image(self.train_image())\n        return name_from_base(""compilation-"" + base_name)\n\n    def compile_model(\n        self,\n        target_instance_family,\n        input_shape,\n        output_path,\n        framework=None,\n        framework_version=None,\n        compile_max_run=15 * 60,\n        tags=None,\n        **kwargs\n    ):\n        """"""Compile a Neo model using the input model.\n\n        Args:\n            target_instance_family (str): Identifies the device that you want to\n                run your model after compilation, for example: ml_c5. For allowed\n                strings see\n                https://docs.aws.amazon.com/sagemaker/latest/dg/API_OutputConfig.html.\n            input_shape (dict): Specifies the name and shape of the expected\n                inputs for your trained model in json dictionary form, for\n                example: {\'data\':[1,3,1024,1024]}, or {\'var1\': [1,1,28,28],\n                \'var2\':[1,1,28,28]}\n            output_path (str): Specifies where to store the compiled model\n            framework (str): The framework that is used to train the original\n                model. Allowed values: \'mxnet\', \'tensorflow\', \'keras\', \'pytorch\',\n                \'onnx\', \'xgboost\'\n            framework_version (str): The version of the framework\n            compile_max_run (int): Timeout in seconds for compilation (default:\n                3 * 60). After this amount of time Amazon SageMaker Neo\n                terminates the compilation job regardless of its current status.\n            tags (list[dict]): List of tags for labeling a compilation job. For\n                more, see\n                https://docs.aws.amazon.com/sagemaker/latest/dg/API_Tag.html.\n            **kwargs: Passed to invocation of ``create_model()``.\n                Implementations may customize ``create_model()`` to accept\n                ``**kwargs`` to customize model creation during deploy. For\n                more, see the implementation docs.\n\n        Returns:\n            sagemaker.model.Model: A SageMaker ``Model`` object. See\n            :func:`~sagemaker.model.Model` for full details.\n        """"""\n        if framework and framework not in NEO_ALLOWED_FRAMEWORKS:\n            raise ValueError(\n                ""Please use valid framework, allowed values: {}"".format(NEO_ALLOWED_FRAMEWORKS)\n            )\n\n        if (framework is None) != (framework_version is None):\n            raise ValueError(""You should provide framework and framework_version at the same time."")\n\n        model = self.create_model(**kwargs)\n\n        self._compiled_models[target_instance_family] = model.compile(\n            target_instance_family,\n            input_shape,\n            output_path,\n            self.role,\n            tags,\n            self._compilation_job_name(),\n            compile_max_run,\n            framework=framework,\n            framework_version=framework_version,\n        )\n        return self._compiled_models[target_instance_family]\n\n    @classmethod\n    def attach(cls, training_job_name, sagemaker_session=None, model_channel_name=""model""):\n        """"""Attach to an existing training job.\n\n        Create an Estimator bound to an existing training job, each subclass\n        is responsible to implement\n        ``_prepare_init_params_from_job_description()`` as this method delegates\n        the actual conversion of a training job description to the arguments\n        that the class constructor expects. After attaching, if the training job\n        has a Complete status, it can be ``deploy()`` ed to create a SageMaker\n        Endpoint and return a ``Predictor``.\n\n        If the training job is in progress, attach will block and display log\n        messages from the training job, until the training job completes.\n\n        Examples:\n            >>> my_estimator.fit(wait=False)\n            >>> training_job_name = my_estimator.latest_training_job.name\n            Later on:\n            >>> attached_estimator = Estimator.attach(training_job_name)\n            >>> attached_estimator.deploy()\n\n        Args:\n            training_job_name (str): The name of the training job to attach to.\n            sagemaker_session (sagemaker.session.Session): Session object which\n                manages interactions with Amazon SageMaker APIs and any other\n                AWS services needed. If not specified, the estimator creates one\n                using the default AWS configuration chain.\n            model_channel_name (str): Name of the channel where pre-trained\n                model data will be downloaded (default: \'model\'). If no channel\n                with the same name exists in the training job, this option will\n                be ignored.\n\n        Returns:\n            Instance of the calling ``Estimator`` Class with the attached\n            training job.\n        """"""\n        sagemaker_session = sagemaker_session or Session()\n\n        job_details = sagemaker_session.sagemaker_client.describe_training_job(\n            TrainingJobName=training_job_name\n        )\n        init_params = cls._prepare_init_params_from_job_description(job_details, model_channel_name)\n        tags = sagemaker_session.sagemaker_client.list_tags(\n            ResourceArn=job_details[""TrainingJobArn""]\n        )[""Tags""]\n        init_params.update(tags=tags)\n\n        estimator = cls(sagemaker_session=sagemaker_session, **init_params)\n        estimator.latest_training_job = _TrainingJob(\n            sagemaker_session=sagemaker_session, job_name=init_params[""base_job_name""]\n        )\n        estimator._current_job_name = estimator.latest_training_job.name\n        estimator.latest_training_job.wait()\n        return estimator\n\n    def deploy(\n        self,\n        initial_instance_count,\n        instance_type,\n        accelerator_type=None,\n        endpoint_name=None,\n        use_compiled_model=False,\n        update_endpoint=False,\n        wait=True,\n        model_name=None,\n        kms_key=None,\n        data_capture_config=None,\n        tags=None,\n        **kwargs\n    ):\n        """"""Deploy the trained model to an Amazon SageMaker endpoint and return a\n        ``sagemaker.RealTimePredictor`` object.\n\n        More information:\n        http://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-training.html\n\n        Args:\n            initial_instance_count (int): Minimum number of EC2 instances to\n                deploy to an endpoint for prediction.\n            instance_type (str): Type of EC2 instance to deploy to an endpoint\n                for prediction, for example, \'ml.c4.xlarge\'.\n            accelerator_type (str): Type of Elastic Inference accelerator to\n                attach to an endpoint for model loading and inference, for\n                example, \'ml.eia1.medium\'. If not specified, no Elastic\n                Inference accelerator will be attached to the endpoint. For more\n                information:\n                https://docs.aws.amazon.com/sagemaker/latest/dg/ei.html\n            endpoint_name (str): Name to use for creating an Amazon SageMaker\n                endpoint. If not specified, the name of the training job is\n                used.\n            use_compiled_model (bool): Flag to select whether to use compiled\n                (optimized) model. Default: False.\n            update_endpoint (bool): Flag to update the model in an existing\n                Amazon SageMaker endpoint. If True, this will deploy a new\n                EndpointConfig to an already existing endpoint and delete\n                resources corresponding to the previous EndpointConfig. Default:\n                False\n            wait (bool): Whether the call should wait until the deployment of\n                model completes (default: True).\n            model_name (str): Name to use for creating an Amazon SageMaker\n                model. If not specified, the name of the training job is used.\n            kms_key (str): The ARN of the KMS key that is used to encrypt the\n                data on the storage volume attached to the instance hosting the\n                endpoint.\n            data_capture_config (sagemaker.model_monitor.DataCaptureConfig): Specifies\n                configuration related to Endpoint data capture for use with\n                Amazon SageMaker Model Monitoring. Default: None.\n            tags(List[dict[str, str]]): Optional. The list of tags to attach to this specific\n                endpoint. Example:\n                >>> tags = [{\'Key\': \'tagname\', \'Value\': \'tagvalue\'}]\n                For more information about tags, see\n                https://boto3.amazonaws.com/v1/documentation\\\n                /api/latest/reference/services/sagemaker.html#SageMaker.Client.add_tags\n            **kwargs: Passed to invocation of ``create_model()``.\n                Implementations may customize ``create_model()`` to accept\n                ``**kwargs`` to customize model creation during deploy.\n                For more, see the implementation docs.\n\n        Returns:\n            sagemaker.predictor.RealTimePredictor: A predictor that provides a ``predict()`` method,\n                which can be used to send requests to the Amazon SageMaker\n                endpoint and obtain inferences.\n        """"""\n        self._ensure_latest_training_job()\n        endpoint_name = endpoint_name or self.latest_training_job.name\n        model_name = model_name or self.latest_training_job.name\n        self.deploy_instance_type = instance_type\n        if use_compiled_model:\n            family = ""_"".join(instance_type.split(""."")[:-1])\n            if family not in self._compiled_models:\n                raise ValueError(\n                    ""No compiled model for {}. ""\n                    ""Please compile one with compile_model before deploying."".format(family)\n                )\n            model = self._compiled_models[family]\n        else:\n            kwargs[""model_kms_key""] = self.output_kms_key\n            model = self.create_model(**kwargs)\n\n        model.name = model_name\n\n        return model.deploy(\n            instance_type=instance_type,\n            initial_instance_count=initial_instance_count,\n            accelerator_type=accelerator_type,\n            endpoint_name=endpoint_name,\n            update_endpoint=update_endpoint,\n            tags=tags or self.tags,\n            wait=wait,\n            kms_key=kms_key,\n            data_capture_config=data_capture_config,\n        )\n\n    @property\n    def model_data(self):\n        """"""str: The model location in S3. Only set if Estimator has been\n        ``fit()``.\n        """"""\n        if self.latest_training_job is not None:\n            model_uri = self.sagemaker_session.sagemaker_client.describe_training_job(\n                TrainingJobName=self.latest_training_job.name\n            )[""ModelArtifacts""][""S3ModelArtifacts""]\n        else:\n            logging.warning(\n                ""No finished training job found associated with this estimator. Please make sure ""\n                ""this estimator is only used for building workflow config""\n            )\n            model_uri = os.path.join(\n                self.output_path, self._current_job_name, ""output"", ""model.tar.gz""\n            )\n\n        return model_uri\n\n    @abstractmethod\n    def create_model(self, **kwargs):\n        """"""Create a SageMaker ``Model`` object that can be deployed to an\n        ``Endpoint``.\n\n        Args:\n            **kwargs: Keyword arguments used by the implemented method for\n                creating the ``Model``.\n\n        Returns:\n            sagemaker.model.Model: A SageMaker ``Model`` object. See\n            :func:`~sagemaker.model.Model` for full details.\n        """"""\n\n    @classmethod\n    def _prepare_init_params_from_job_description(cls, job_details, model_channel_name=None):\n        """"""Convert the job description to init params that can be handled by the\n        class constructor\n\n        Args:\n            job_details: the returned job details from a describe_training_job\n                API call.\n            model_channel_name (str): Name of the channel where pre-trained\n                model data will be downloaded.\n\n        Returns:\n            dictionary: The transformed init_params\n        """"""\n        init_params = dict()\n\n        init_params[""role""] = job_details[""RoleArn""]\n        init_params[""train_instance_count""] = job_details[""ResourceConfig""][""InstanceCount""]\n        init_params[""train_instance_type""] = job_details[""ResourceConfig""][""InstanceType""]\n        init_params[""train_volume_size""] = job_details[""ResourceConfig""][""VolumeSizeInGB""]\n        init_params[""train_max_run""] = job_details[""StoppingCondition""][""MaxRuntimeInSeconds""]\n        init_params[""input_mode""] = job_details[""AlgorithmSpecification""][""TrainingInputMode""]\n        init_params[""base_job_name""] = job_details[""TrainingJobName""]\n        init_params[""output_path""] = job_details[""OutputDataConfig""][""S3OutputPath""]\n        init_params[""output_kms_key""] = job_details[""OutputDataConfig""][""KmsKeyId""]\n        if ""EnableNetworkIsolation"" in job_details:\n            init_params[""enable_network_isolation""] = job_details[""EnableNetworkIsolation""]\n\n        has_hps = ""HyperParameters"" in job_details\n        init_params[""hyperparameters""] = job_details[""HyperParameters""] if has_hps else {}\n\n        if ""AlgorithmName"" in job_details[""AlgorithmSpecification""]:\n            init_params[""algorithm_arn""] = job_details[""AlgorithmSpecification""][""AlgorithmName""]\n        elif ""TrainingImage"" in job_details[""AlgorithmSpecification""]:\n            init_params[""image""] = job_details[""AlgorithmSpecification""][""TrainingImage""]\n        else:\n            raise RuntimeError(\n                ""Invalid AlgorithmSpecification. Either TrainingImage or ""\n                ""AlgorithmName is expected. None was found.""\n            )\n\n        if ""MetricDefinitons"" in job_details[""AlgorithmSpecification""]:\n            init_params[""metric_definitions""] = job_details[""AlgorithmSpecification""][\n                ""MetricsDefinition""\n            ]\n\n        if ""EnableInterContainerTrafficEncryption"" in job_details:\n            init_params[""encrypt_inter_container_traffic""] = job_details[\n                ""EnableInterContainerTrafficEncryption""\n            ]\n\n        subnets, security_group_ids = vpc_utils.from_dict(job_details.get(vpc_utils.VPC_CONFIG_KEY))\n        if subnets:\n            init_params[""subnets""] = subnets\n        if security_group_ids:\n            init_params[""security_group_ids""] = security_group_ids\n\n        if ""InputDataConfig"" in job_details and model_channel_name:\n            for channel in job_details[""InputDataConfig""]:\n                if channel[""ChannelName""] == model_channel_name:\n                    init_params[""model_channel_name""] = model_channel_name\n                    init_params[""model_uri""] = channel[""DataSource""][""S3DataSource""][""S3Uri""]\n                    break\n\n        return init_params\n\n    def delete_endpoint(self):\n        """"""Delete an Amazon SageMaker ``Endpoint``.\n\n        Raises:\n            botocore.exceptions.ClientError: If the endpoint does not exist.\n        """"""\n        self._ensure_latest_training_job(error_message=""Endpoint was not created yet"")\n        self.sagemaker_session.delete_endpoint(self.latest_training_job.name)\n\n    def transformer(\n        self,\n        instance_count,\n        instance_type,\n        strategy=None,\n        assemble_with=None,\n        output_path=None,\n        output_kms_key=None,\n        accept=None,\n        env=None,\n        max_concurrent_transforms=None,\n        max_payload=None,\n        tags=None,\n        role=None,\n        volume_kms_key=None,\n        vpc_config_override=vpc_utils.VPC_CONFIG_DEFAULT,\n        enable_network_isolation=None,\n        model_name=None,\n    ):\n        """"""Return a ``Transformer`` that uses a SageMaker Model based on the\n        training job. It reuses the SageMaker Session and base job name used by\n        the Estimator.\n\n        Args:\n            instance_count (int): Number of EC2 instances to use.\n            instance_type (str): Type of EC2 instance to use, for example,\n                \'ml.c4.xlarge\'.\n            strategy (str): The strategy used to decide how to batch records in\n                a single request (default: None). Valid values: \'MultiRecord\'\n                and \'SingleRecord\'.\n            assemble_with (str): How the output is assembled (default: None).\n                Valid values: \'Line\' or \'None\'.\n            output_path (str): S3 location for saving the transform result. If\n                not specified, results are stored to a default bucket.\n            output_kms_key (str): Optional. KMS key ID for encrypting the\n                transform output (default: None).\n            accept (str): The accept header passed by the client to\n                the inference endpoint. If it is supported by the endpoint,\n                it will be the format of the batch transform output.\n            env (dict): Environment variables to be set for use during the\n                transform job (default: None).\n            max_concurrent_transforms (int): The maximum number of HTTP requests\n                to be made to each individual transform container at one time.\n            max_payload (int): Maximum size of the payload in a single HTTP\n                request to the container in MB.\n            tags (list[dict]): List of tags for labeling a transform job. If\n                none specified, then the tags used for the training job are used\n                for the transform job.\n            role (str): The ``ExecutionRoleArn`` IAM Role ARN for the ``Model``,\n                which is also used during transform jobs. If not specified, the\n                role from the Estimator will be used.\n            volume_kms_key (str): Optional. KMS key ID for encrypting the volume\n                attached to the ML compute instance (default: None).\n            vpc_config_override (dict[str, list[str]]): Optional override for the\n                VpcConfig set on the model.\n                Default: use subnets and security groups from this Estimator.\n\n                * \'Subnets\' (list[str]): List of subnet ids.\n                * \'SecurityGroupIds\' (list[str]): List of security group ids.\n\n            enable_network_isolation (bool): Specifies whether container will\n                run in network isolation mode. Network isolation mode restricts\n                the container access to outside networks (such as the internet).\n                The container does not make any inbound or outbound network\n                calls. If True, a channel named ""code"" will be created for any\n                user entry script for inference. Also known as Internet-free mode.\n                If not specified, this setting is taken from the estimator\'s\n                current configuration.\n            model_name (str): Name to use for creating an Amazon SageMaker\n                model. If not specified, the name of the training job is used.\n        """"""\n        tags = tags or self.tags\n\n        if self.latest_training_job is None:\n            logging.warning(\n                ""No finished training job found associated with this estimator. Please make sure ""\n                ""this estimator is only used for building workflow config""\n            )\n            model_name = model_name or self._current_job_name\n        else:\n            model_name = model_name or self.latest_training_job.name\n            if enable_network_isolation is None:\n                enable_network_isolation = self.enable_network_isolation()\n\n            model = self.create_model(\n                vpc_config_override=vpc_config_override,\n                model_kms_key=self.output_kms_key,\n                enable_network_isolation=enable_network_isolation,\n            )\n\n            # not all create_model() implementations have the same kwargs\n            model.name = model_name\n            if role is not None:\n                model.role = role\n\n            model._create_sagemaker_model(instance_type, tags=tags)\n\n        return Transformer(\n            model_name,\n            instance_count,\n            instance_type,\n            strategy=strategy,\n            assemble_with=assemble_with,\n            output_path=output_path,\n            output_kms_key=output_kms_key,\n            accept=accept,\n            max_concurrent_transforms=max_concurrent_transforms,\n            max_payload=max_payload,\n            env=env,\n            tags=tags,\n            base_transform_job_name=self.base_job_name,\n            volume_kms_key=volume_kms_key,\n            sagemaker_session=self.sagemaker_session,\n        )\n\n    @property\n    def training_job_analytics(self):\n        """"""Return a ``TrainingJobAnalytics`` object for the current training\n        job.\n        """"""\n        if self._current_job_name is None:\n            raise ValueError(""Estimator is not associated with a TrainingJob"")\n        return TrainingJobAnalytics(\n            self._current_job_name, sagemaker_session=self.sagemaker_session\n        )\n\n    def get_vpc_config(self, vpc_config_override=vpc_utils.VPC_CONFIG_DEFAULT):\n        """"""Returns VpcConfig dict either from this Estimator\'s subnets and\n        security groups, or else validate and return an optional override value.\n\n        Args:\n            vpc_config_override:\n        """"""\n        if vpc_config_override is vpc_utils.VPC_CONFIG_DEFAULT:\n            return vpc_utils.to_dict(self.subnets, self.security_group_ids)\n        return vpc_utils.sanitize(vpc_config_override)\n\n    def _ensure_latest_training_job(\n        self, error_message=""Estimator is not associated with a training job""\n    ):\n        """"""\n        Args:\n            error_message:\n        """"""\n        if self.latest_training_job is None:\n            raise ValueError(error_message)\n\n\nclass _TrainingJob(_Job):\n    """"""Placeholder docstring""""""\n\n    @classmethod\n    def start_new(cls, estimator, inputs, experiment_config):\n        """"""Create a new Amazon SageMaker training job from the estimator.\n\n        Args:\n            estimator (sagemaker.estimator.EstimatorBase): Estimator object\n                created by the user.\n            inputs (str): Parameters used when called\n                :meth:`~sagemaker.estimator.EstimatorBase.fit`.\n            experiment_config (dict[str, str]): Experiment management configuration used when called\n                :meth:`~sagemaker.estimator.EstimatorBase.fit`.  Dictionary contains\n                three optional keys, \'ExperimentName\', \'TrialName\', and \'TrialComponentDisplayName\'.\n\n\n        Returns:\n            sagemaker.estimator._TrainingJob: Constructed object that captures\n            all information about the started training job.\n        """"""\n\n        local_mode = estimator.sagemaker_session.local_mode\n        model_uri = estimator.model_uri\n\n        # Allow file:// input only in local mode\n        if cls._is_local_channel(inputs) or cls._is_local_channel(model_uri):\n            if not local_mode:\n                raise ValueError(\n                    ""File URIs are supported in local mode only. Please use a S3 URI instead.""\n                )\n\n        config = _Job._load_config(inputs, estimator)\n\n        if estimator.hyperparameters() is not None:\n            hyperparameters = {str(k): str(v) for (k, v) in estimator.hyperparameters().items()}\n\n        train_args = config.copy()\n        train_args[""input_mode""] = estimator.input_mode\n        train_args[""job_name""] = estimator._current_job_name\n        train_args[""hyperparameters""] = hyperparameters\n        train_args[""tags""] = estimator.tags\n        train_args[""metric_definitions""] = estimator.metric_definitions\n        train_args[""experiment_config""] = experiment_config\n\n        if isinstance(inputs, s3_input):\n            if ""InputMode"" in inputs.config:\n                logging.debug(\n                    ""Selecting s3_input\'s input_mode (%s) for TrainingInputMode."",\n                    inputs.config[""InputMode""],\n                )\n                train_args[""input_mode""] = inputs.config[""InputMode""]\n\n        if estimator.enable_network_isolation():\n            train_args[""enable_network_isolation""] = True\n\n        if estimator.encrypt_inter_container_traffic:\n            train_args[""encrypt_inter_container_traffic""] = True\n\n        if isinstance(estimator, sagemaker.algorithm.AlgorithmEstimator):\n            train_args[""algorithm_arn""] = estimator.algorithm_arn\n        else:\n            train_args[""image""] = estimator.train_image()\n\n        if estimator.debugger_rule_configs:\n            train_args[""debugger_rule_configs""] = estimator.debugger_rule_configs\n\n        if estimator.debugger_hook_config:\n            estimator.debugger_hook_config.collection_configs = estimator.collection_configs\n            train_args[""debugger_hook_config""] = estimator.debugger_hook_config._to_request_dict()\n\n        if estimator.tensorboard_output_config:\n            train_args[\n                ""tensorboard_output_config""\n            ] = estimator.tensorboard_output_config._to_request_dict()\n\n        cls._add_spot_checkpoint_args(local_mode, estimator, train_args)\n\n        if estimator.enable_sagemaker_metrics is not None:\n            train_args[""enable_sagemaker_metrics""] = estimator.enable_sagemaker_metrics\n\n        estimator.sagemaker_session.train(**train_args)\n\n        return cls(estimator.sagemaker_session, estimator._current_job_name)\n\n    @classmethod\n    def _add_spot_checkpoint_args(cls, local_mode, estimator, train_args):\n        """"""\n        Args:\n            local_mode:\n            estimator:\n            train_args:\n        """"""\n        if estimator.train_use_spot_instances:\n            if local_mode:\n                raise ValueError(""Spot training is not supported in local mode."")\n            train_args[""train_use_spot_instances""] = True\n\n        if estimator.checkpoint_s3_uri:\n            if local_mode:\n                raise ValueError(""Setting checkpoint_s3_uri is not supported in local mode."")\n            train_args[""checkpoint_s3_uri""] = estimator.checkpoint_s3_uri\n\n        if estimator.checkpoint_local_path:\n            if local_mode:\n                raise ValueError(""Setting checkpoint_local_path is not supported in local mode."")\n            train_args[""checkpoint_local_path""] = estimator.checkpoint_local_path\n\n    @classmethod\n    def _is_local_channel(cls, input_uri):\n        """"""\n        Args:\n            input_uri:\n        """"""\n        return isinstance(input_uri, string_types) and input_uri.startswith(""file://"")\n\n    def wait(self, logs=""All""):\n        """"""\n        Args:\n            logs ([str]): A list of strings specifying which logs to print. Acceptable\n                strings are ""All"", ""None"", ""Training"", or ""Rules"". To maintain backwards\n                compatibility, boolean values are also accepted and converted to strings.\n        """"""\n        # Convert boolean values of logs to strings.\n        log_string_map = {True: ""All"", False: ""None""}\n        if isinstance(logs, bool):\n            logs = log_string_map[logs]\n        # If logs are requested, call logs_for_jobs.\n        if logs != ""None"":\n            self.sagemaker_session.logs_for_job(self.job_name, wait=True, log_type=logs)\n        else:\n            self.sagemaker_session.wait_for_job(self.job_name)\n\n    def describe(self):\n        """"""Returns a response from the DescribeTrainingJob API call.""""""\n        return self.sagemaker_session.describe_training_job(self.job_name)\n\n    def rule_job_summary(self):\n        """"""Calls describe_training_job and returns the\n        DebugRuleEvaluationStatuses dictionary.\n        """"""\n        return self.describe()[""DebugRuleEvaluationStatuses""]\n\n    def stop(self):\n        """"""Stops the training job.""""""\n        self.sagemaker_session.stop_training_job(self.name)\n\n\nclass Estimator(EstimatorBase):\n    """"""A generic Estimator to train using any supplied algorithm. This class is\n    designed for use with algorithms that don\'t have their own, custom class.\n    """"""\n\n    def __init__(\n        self,\n        image_name,\n        role,\n        train_instance_count,\n        train_instance_type,\n        train_volume_size=30,\n        train_volume_kms_key=None,\n        train_max_run=24 * 60 * 60,\n        input_mode=""File"",\n        output_path=None,\n        output_kms_key=None,\n        base_job_name=None,\n        sagemaker_session=None,\n        hyperparameters=None,\n        tags=None,\n        subnets=None,\n        security_group_ids=None,\n        model_uri=None,\n        model_channel_name=""model"",\n        metric_definitions=None,\n        encrypt_inter_container_traffic=False,\n        train_use_spot_instances=False,\n        train_max_wait=None,\n        checkpoint_s3_uri=None,\n        checkpoint_local_path=None,\n        enable_network_isolation=False,\n        rules=None,\n        debugger_hook_config=None,\n        tensorboard_output_config=None,\n        enable_sagemaker_metrics=None,\n    ):\n        """"""Initialize an ``Estimator`` instance.\n\n        Args:\n            image_name (str): The container image to use for training.\n            role (str): An AWS IAM role (either name or full ARN). The Amazon\n                SageMaker training jobs and APIs that create Amazon SageMaker\n                endpoints use this role to access training data and model\n                artifacts. After the endpoint is created, the inference code\n                might use the IAM role, if it needs to access an AWS resource.\n            train_instance_count (int): Number of Amazon EC2 instances to use\n                for training.\n            train_instance_type (str): Type of EC2 instance to use for training,\n                for example, \'ml.c4.xlarge\'.\n            train_volume_size (int): Size in GB of the EBS volume to use for\n                storing input data during training (default: 30). Must be large\n                enough to store training data if File Mode is used (which is the\n                default).\n            train_volume_kms_key (str): Optional. KMS key ID for encrypting EBS\n                volume attached to the training instance (default: None).\n            train_max_run (int): Timeout in seconds for training (default: 24 *\n                60 * 60). After this amount of time Amazon SageMaker terminates\n                the job regardless of its current status.\n            input_mode (str): The input mode that the algorithm supports\n                (default: \'File\'). Valid modes:\n\n                * \'File\' - Amazon SageMaker copies the training dataset from the\n                  S3 location to a local directory.\n                * \'Pipe\' - Amazon SageMaker streams data directly from S3 to the\n                  container via a Unix-named pipe.\n\n                This argument can be overriden on a per-channel basis using\n                ``sagemaker.session.s3_input.input_mode``.\n            output_path (str): S3 location for saving the training result (model\n                artifacts and output files). If not specified, results are\n                stored to a default bucket. If the bucket with the specific name\n                does not exist, the estimator creates the bucket during the\n                :meth:`~sagemaker.estimator.EstimatorBase.fit` method execution.\n            output_kms_key (str): Optional. KMS key ID for encrypting the\n                training output (default: None).\n            base_job_name (str): Prefix for training job name when the\n                :meth:`~sagemaker.estimator.EstimatorBase.fit` method launches.\n                If not specified, the estimator generates a default job name,\n                based on the training image name and current timestamp.\n            sagemaker_session (sagemaker.session.Session): Session object which\n                manages interactions with Amazon SageMaker APIs and any other\n                AWS services needed. If not specified, the estimator creates one\n                using the default AWS configuration chain.\n            hyperparameters (dict): Dictionary containing the hyperparameters to\n                initialize this estimator with.\n            tags (list[dict]): List of tags for labeling a training job. For\n                more, see\n                https://docs.aws.amazon.com/sagemaker/latest/dg/API_Tag.html.\n            subnets (list[str]): List of subnet ids. If not specified training\n                job will be created without VPC config.\n            security_group_ids (list[str]): List of security group ids. If not\n                specified training job will be created without VPC config.\n            model_uri (str): URI where a pre-trained model is stored, either\n                locally or in S3 (default: None). If specified, the estimator\n                will create a channel pointing to the model so the training job\n                can download it. This model can be a \'model.tar.gz\' from a\n                previous training job, or other artifacts coming from a\n                different source.\n\n                In local mode, this should point to the path in which the model\n                is located and not the file itself, as local Docker containers\n                will try to mount the URI as a volume.\n\n                More information:\n                https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-training.html#td-deserialization\n            model_channel_name (str): Name of the channel where \'model_uri\' will\n                be downloaded (default: \'model\').\n            metric_definitions (list[dict]): A list of dictionaries that defines\n                the metric(s) used to evaluate the training jobs. Each\n                dictionary contains two keys: \'Name\' for the name of the metric,\n                and \'Regex\' for the regular expression used to extract the\n                metric from the logs. This should be defined only for jobs that\n                don\'t use an Amazon algorithm.\n            encrypt_inter_container_traffic (bool): Specifies whether traffic\n                between training containers is encrypted for the training job\n                (default: ``False``).\n            train_use_spot_instances (bool): Specifies whether to use SageMaker\n                Managed Spot instances for training. If enabled then the\n                `train_max_wait` arg should also be set.\n\n                More information:\n                https://docs.aws.amazon.com/sagemaker/latest/dg/model-managed-spot-training.html\n                (default: ``False``).\n            train_max_wait (int): Timeout in seconds waiting for spot training\n                instances (default: None). After this amount of time Amazon\n                SageMaker will stop waiting for Spot instances to become\n                available (default: ``None``).\n            checkpoint_s3_uri (str): The S3 URI in which to persist checkpoints\n                that the algorithm persists (if any) during training. (default:\n                ``None``).\n            checkpoint_local_path (str): The local path that the algorithm\n                writes its checkpoints to. SageMaker will persist all files\n                under this path to `checkpoint_s3_uri` continually during\n                training. On job startup the reverse happens - data from the\n                s3 location is downloaded to this path before the algorithm is\n                started. If the path is unset then SageMaker assumes the\n                checkpoints will be provided under `/opt/ml/checkpoints/`.\n                (default: ``None``).\n            enable_network_isolation (bool): Specifies whether container will\n                run in network isolation mode (default: ``False``). Network\n                isolation mode restricts the container access to outside networks\n                (such as the Internet). The container does not make any inbound or\n                outbound network calls. Also known as Internet-free mode.\n            enable_sagemaker_metrics (bool): enable SageMaker Metrics Time\n                Series. For more information see:\n                https://docs.aws.amazon.com/sagemaker/latest/dg/API_AlgorithmSpecification.html#SageMaker-Type-AlgorithmSpecification-EnableSageMakerMetricsTimeSeries\n                (default: ``None``).\n        """"""\n        logging.warning(parameter_v2_rename_warning(""image_name"", ""image_uri""))\n        self.image_name = image_name\n        self.hyperparam_dict = hyperparameters.copy() if hyperparameters else {}\n        super(Estimator, self).__init__(\n            role,\n            train_instance_count,\n            train_instance_type,\n            train_volume_size,\n            train_volume_kms_key,\n            train_max_run,\n            input_mode,\n            output_path,\n            output_kms_key,\n            base_job_name,\n            sagemaker_session,\n            tags,\n            subnets,\n            security_group_ids,\n            model_uri=model_uri,\n            model_channel_name=model_channel_name,\n            metric_definitions=metric_definitions,\n            encrypt_inter_container_traffic=encrypt_inter_container_traffic,\n            train_use_spot_instances=train_use_spot_instances,\n            train_max_wait=train_max_wait,\n            checkpoint_s3_uri=checkpoint_s3_uri,\n            checkpoint_local_path=checkpoint_local_path,\n            rules=rules,\n            debugger_hook_config=debugger_hook_config,\n            tensorboard_output_config=tensorboard_output_config,\n            enable_sagemaker_metrics=enable_sagemaker_metrics,\n            enable_network_isolation=enable_network_isolation,\n        )\n\n    def train_image(self):\n        """"""Returns the docker image to use for training.\n\n        The fit() method, that does the model training, calls this method to\n        find the image to use for model training.\n        """"""\n        return self.image_name\n\n    def set_hyperparameters(self, **kwargs):\n        """"""\n        Args:\n            **kwargs:\n        """"""\n        for k, v in kwargs.items():\n            self.hyperparam_dict[k] = v\n\n    def hyperparameters(self):\n        """"""Returns the hyperparameters as a dictionary to use for training.\n\n        The fit() method, that does the model training, calls this method to\n        find the hyperparameters you specified.\n        """"""\n        return self.hyperparam_dict\n\n    def create_model(\n        self,\n        role=None,\n        image=None,\n        predictor_cls=None,\n        serializer=None,\n        deserializer=None,\n        content_type=None,\n        accept=None,\n        vpc_config_override=vpc_utils.VPC_CONFIG_DEFAULT,\n        **kwargs\n    ):\n        """"""Create a model to deploy.\n\n        The serializer, deserializer, content_type, and accept arguments are only used to define a\n        default RealTimePredictor. They are ignored if an explicit predictor class is passed in.\n        Other arguments are passed through to the Model class.\n\n        Args:\n            role (str): The ``ExecutionRoleArn`` IAM Role ARN for the ``Model``,\n                which is also used during transform jobs. If not specified, the\n                role from the Estimator will be used.\n            image (str): An container image to use for deploying the model.\n                Defaults to the image used for training.\n            predictor_cls (RealTimePredictor): The predictor class to use when\n                deploying the model.\n            serializer (callable): Should accept a single argument, the input\n                data, and return a sequence of bytes. May provide a content_type\n                attribute that defines the endpoint request content type\n            deserializer (callable): Should accept two arguments, the result\n                data and the response content type, and return a sequence of\n                bytes. May provide a content_type attribute that defines th\n                endpoint response Accept content type.\n            content_type (str): The invocation ContentType, overriding any\n                content_type from the serializer\n            accept (str): The invocation Accept, overriding any accept from the\n                deserializer.\n            vpc_config_override (dict[str, list[str]]): Optional override for VpcConfig set on\n                the model.\n                Default: use subnets and security groups from this Estimator.\n                * \'Subnets\' (list[str]): List of subnet ids.\n                * \'SecurityGroupIds\' (list[str]): List of security group ids.\n            **kwargs: Additional parameters passed to :class:`~sagemaker.model.Model`\n\n        .. tip::\n\n            You can find additional parameters for using this method at\n            :class:`~sagemaker.model.Model`.\n\n        Returns:\n            (sagemaker.model.Model) a Model ready for deployment.\n        """"""\n        if predictor_cls is None:\n\n            def predict_wrapper(endpoint, session):\n                return RealTimePredictor(\n                    endpoint, session, serializer, deserializer, content_type, accept\n                )\n\n            predictor_cls = predict_wrapper\n\n        role = role or self.role\n\n        if ""enable_network_isolation"" not in kwargs:\n            kwargs[""enable_network_isolation""] = self.enable_network_isolation()\n\n        return Model(\n            self.model_data,\n            image or self.train_image(),\n            role,\n            vpc_config=self.get_vpc_config(vpc_config_override),\n            sagemaker_session=self.sagemaker_session,\n            predictor_cls=predictor_cls,\n            **kwargs\n        )\n\n    @classmethod\n    def _prepare_init_params_from_job_description(cls, job_details, model_channel_name=None):\n        """"""Convert the job description to init params that can be handled by the\n        class constructor\n\n        Args:\n            job_details: the returned job details from a describe_training_job\n                API call.\n            model_channel_name (str): Name of the channel where pre-trained\n                model data will be downloaded\n\n        Returns:\n            dictionary: The transformed init_params\n        """"""\n        init_params = super(Estimator, cls)._prepare_init_params_from_job_description(\n            job_details, model_channel_name\n        )\n\n        init_params[""image_name""] = init_params.pop(""image"")\n        return init_params\n\n\nclass Framework(EstimatorBase):\n    """"""Base class that cannot be instantiated directly.\n\n    Subclasses define functionality pertaining to specific ML frameworks,\n    such as training/deployment images and predictor instances.\n    """"""\n\n    __framework_name__ = None\n\n    LAUNCH_PS_ENV_NAME = ""sagemaker_parameter_server_enabled""\n    LAUNCH_MPI_ENV_NAME = ""sagemaker_mpi_enabled""\n    MPI_NUM_PROCESSES_PER_HOST = ""sagemaker_mpi_num_of_processes_per_host""\n    MPI_CUSTOM_MPI_OPTIONS = ""sagemaker_mpi_custom_mpi_options""\n    CONTAINER_CODE_CHANNEL_SOURCEDIR_PATH = ""/opt/ml/input/data/code/sourcedir.tar.gz""\n\n    def __init__(\n        self,\n        entry_point,\n        source_dir=None,\n        hyperparameters=None,\n        enable_cloudwatch_metrics=False,\n        container_log_level=logging.INFO,\n        code_location=None,\n        image_name=None,\n        dependencies=None,\n        enable_network_isolation=False,\n        git_config=None,\n        checkpoint_s3_uri=None,\n        checkpoint_local_path=None,\n        enable_sagemaker_metrics=None,\n        **kwargs\n    ):\n        """"""Base class initializer. Subclasses which override ``__init__`` should\n        invoke ``super()``\n\n        Args:\n            entry_point (str): Path (absolute or relative) to the local Python\n                source file which should be executed as the entry point to\n                training. If ``source_dir`` is specified, then ``entry_point``\n                must point to a file located at the root of ``source_dir``.\n                If \'git_config\' is provided, \'entry_point\' should be\n                a relative location to the Python source file in the Git repo.\n                Example:\n\n                    With the following GitHub repo directory structure:\n\n                    >>> |----- README.md\n                    >>> |----- src\n                    >>>         |----- train.py\n                    >>>         |----- test.py\n\n                    You can assign entry_point=\'src/train.py\'.\n            source_dir (str): Path (absolute, relative or an S3 URI) to a directory\n                with any other training source code dependencies aside from the entry\n                point file (default: None). If ``source_dir`` is an S3 URI, it must\n                point to a tar.gz file. Structure within this directory are preserved\n                when training on Amazon SageMaker. If \'git_config\' is provided,\n                \'source_dir\' should be a relative location to a directory in the Git\n                repo.\n\n                .. admonition:: Example\n\n                    With the following GitHub repo directory structure:\n\n                    >>> |----- README.md\n                    >>> |----- src\n                    >>>         |----- train.py\n                    >>>         |----- test.py\n\n                    and you need \'train.py\' as entry point and \'test.py\' as\n                    training source code as well, you can assign\n                    entry_point=\'train.py\', source_dir=\'src\'.\n            hyperparameters (dict): Hyperparameters that will be used for\n                training (default: None). The hyperparameters are made\n                accessible as a dict[str, str] to the training code on\n                SageMaker. For convenience, this accepts other types for keys\n                and values, but ``str()`` will be called to convert them before\n                training.\n            enable_cloudwatch_metrics (bool): [DEPRECATED] Now there are\n                cloudwatch metrics emitted by all SageMaker training jobs. This\n                will be ignored for now and removed in a further release.\n            container_log_level (int): Log level to use within the container\n                (default: logging.INFO). Valid values are defined in the Python\n                logging module.\n            code_location (str): The S3 prefix URI where custom code will be\n                uploaded (default: None) - don\'t include a trailing slash since\n                a string prepended with a ""/"" is appended to ``code_location``. The code\n                file uploaded to S3 is \'code_location/job-name/source/sourcedir.tar.gz\'.\n                If not specified, the default ``code location`` is s3://output_bucket/job-name/.\n            image_name (str): An alternate image name to use instead of the\n                official Sagemaker image for the framework. This is useful to\n                run one of the Sagemaker supported frameworks with an image\n                containing custom dependencies.\n            dependencies (list[str]): A list of paths to directories (absolute\n                or relative) with any additional libraries that will be exported\n                to the container (default: []). The library folders will be\n                copied to SageMaker in the same folder where the entrypoint is\n                copied. If \'git_config\' is provided, \'dependencies\' should be a\n                list of relative locations to directories with any additional\n                libraries needed in the Git repo. .. admonition:: Example\n\n                    The following call >>> Estimator(entry_point=\'train.py\',\n                    dependencies=[\'my/libs/common\', \'virtual-env\']) results in\n                    the following inside the container:\n\n                    >>> $ ls\n\n                    >>> opt/ml/code\n                    >>>     |------ train.py\n                    >>>     |------ common\n                    >>>     |------ virtual-env\n\n            enable_network_isolation (bool): Specifies whether container will\n                run in network isolation mode. Network isolation mode restricts\n                the container access to outside networks (such as the internet).\n                The container does not make any inbound or outbound network\n                calls. If True, a channel named ""code"" will be created for any\n                user entry script for training. The user entry script, files in\n                source_dir (if specified), and dependencies will be uploaded in\n                a tar to S3. Also known as internet-free mode (default: `False`).\n            git_config (dict[str, str]): Git configurations used for cloning\n                files, including ``repo``, ``branch``, ``commit``,\n                ``2FA_enabled``, ``username``, ``password`` and ``token``. The\n                ``repo`` field is required. All other fields are optional.\n                ``repo`` specifies the Git repository where your training script\n                is stored. If you don\'t provide ``branch``, the default value\n                \'master\' is used. If you don\'t provide ``commit``, the latest\n                commit in the specified branch is used. .. admonition:: Example\n\n                    The following config:\n\n                    >>> git_config = {\'repo\': \'https://github.com/aws/sagemaker-python-sdk.git\',\n                    >>>               \'branch\': \'test-branch-git-config\',\n                    >>>               \'commit\': \'329bfcf884482002c05ff7f44f62599ebc9f445a\'}\n\n                    results in cloning the repo specified in \'repo\', then\n                    checkout the \'master\' branch, and checkout the specified\n                    commit.\n\n                ``2FA_enabled``, ``username``, ``password`` and ``token`` are\n                used for authentication. For GitHub (or other Git) accounts, set\n                ``2FA_enabled`` to \'True\' if two-factor authentication is\n                enabled for the account, otherwise set it to \'False\'. If you do\n                not provide a value for ``2FA_enabled``, a default value of\n                \'False\' is used. CodeCommit does not support two-factor\n                authentication, so do not provide ""2FA_enabled"" with CodeCommit\n                repositories.\n\n                For GitHub and other Git repos, when SSH URLs are provided, it\n                doesn\'t matter whether 2FA is enabled or disabled; you should\n                either have no passphrase for the SSH key pairs, or have the\n                ssh-agent configured so that you will not be prompted for SSH\n                passphrase when you do \'git clone\' command with SSH URLs. When\n                HTTPS URLs are provided: if 2FA is disabled, then either token\n                or username+password will be used for authentication if provided\n                (token prioritized); if 2FA is enabled, only token will be used\n                for authentication if provided. If required authentication info\n                is not provided, python SDK will try to use local credentials\n                storage to authenticate. If that fails either, an error message\n                will be thrown.\n\n                For CodeCommit repos, 2FA is not supported, so \'2FA_enabled\'\n                should not be provided. There is no token in CodeCommit, so\n                \'token\' should not be provided too. When \'repo\' is an SSH URL,\n                the requirements are the same as GitHub-like repos. When \'repo\'\n                is an HTTPS URL, username+password will be used for\n                authentication if they are provided; otherwise, python SDK will\n                try to use either CodeCommit credential helper or local\n                credential storage for authentication.\n            checkpoint_s3_uri (str): The S3 URI in which to persist checkpoints\n                that the algorithm persists (if any) during training. (default:\n                ``None``).\n            checkpoint_local_path (str): The local path that the algorithm\n                writes its checkpoints to. SageMaker will persist all files\n                under this path to `checkpoint_s3_uri` continually during\n                training. On job startup the reverse happens - data from the\n                s3 location is downloaded to this path before the algorithm is\n                started. If the path is unset then SageMaker assumes the\n                checkpoints will be provided under `/opt/ml/checkpoints/`.\n                (default: ``None``).\n            enable_sagemaker_metrics (bool): enable SageMaker Metrics Time\n                Series. For more information see:\n                https://docs.aws.amazon.com/sagemaker/latest/dg/API_AlgorithmSpecification.html#SageMaker-Type-AlgorithmSpecification-EnableSageMakerMetricsTimeSeries\n                (default: ``None``).\n            **kwargs: Additional kwargs passed to the ``EstimatorBase``\n                constructor.\n\n        .. tip::\n\n            You can find additional parameters for initializing this class at\n            :class:`~sagemaker.estimator.EstimatorBase`.\n        """"""\n        super(Framework, self).__init__(enable_network_isolation=enable_network_isolation, **kwargs)\n        if entry_point.startswith(""s3://""):\n            raise ValueError(\n                ""Invalid entry point script: {}. Must be a path to a local file."".format(\n                    entry_point\n                )\n            )\n        self.entry_point = entry_point\n        self.git_config = git_config\n        self.source_dir = source_dir\n        self.dependencies = dependencies or []\n        if enable_cloudwatch_metrics:\n            warnings.warn(\n                ""enable_cloudwatch_metrics is now deprecated and will be removed in the future."",\n                DeprecationWarning,\n            )\n        self.enable_cloudwatch_metrics = False\n        self.container_log_level = container_log_level\n        self.code_location = code_location\n        self.image_name = image_name\n        if image_name is not None:\n            logging.warning(parameter_v2_rename_warning(""image_name"", ""image_uri""))\n\n        self.uploaded_code = None\n\n        self._hyperparameters = hyperparameters or {}\n        self.checkpoint_s3_uri = checkpoint_s3_uri\n        self.checkpoint_local_path = checkpoint_local_path\n        self.enable_sagemaker_metrics = enable_sagemaker_metrics\n\n    def _prepare_for_training(self, job_name=None):\n        """"""Set hyperparameters needed for training. This method will also\n        validate ``source_dir``.\n\n        Args:\n           * job_name (str): Name of the training job to be created. If not\n                specified, one is generated, using the base name given to the\n                constructor if applicable.\n        """"""\n        super(Framework, self)._prepare_for_training(job_name=job_name)\n\n        if self.git_config:\n            updated_paths = git_utils.git_clone_repo(\n                self.git_config, self.entry_point, self.source_dir, self.dependencies\n            )\n            self.entry_point = updated_paths[""entry_point""]\n            self.source_dir = updated_paths[""source_dir""]\n            self.dependencies = updated_paths[""dependencies""]\n\n        # validate source dir will raise a ValueError if there is something wrong with the\n        # source directory. We are intentionally not handling it because this is a critical error.\n        if self.source_dir and not self.source_dir.lower().startswith(""s3://""):\n            validate_source_dir(self.entry_point, self.source_dir)\n\n        # if we are in local mode with local_code=True. We want the container to just\n        # mount the source dir instead of uploading to S3.\n        local_code = get_config_value(""local.local_code"", self.sagemaker_session.config)\n        if self.sagemaker_session.local_mode and local_code:\n            # if there is no source dir, use the directory containing the entry point.\n            if self.source_dir is None:\n                self.source_dir = os.path.dirname(self.entry_point)\n            self.entry_point = os.path.basename(self.entry_point)\n\n            code_dir = ""file://"" + self.source_dir\n            script = self.entry_point\n        elif self.enable_network_isolation() and self.entry_point:\n            self.uploaded_code = self._stage_user_code_in_s3()\n            code_dir = self.CONTAINER_CODE_CHANNEL_SOURCEDIR_PATH\n            script = self.uploaded_code.script_name\n            self.code_uri = self.uploaded_code.s3_prefix\n        else:\n            self.uploaded_code = self._stage_user_code_in_s3()\n            code_dir = self.uploaded_code.s3_prefix\n            script = self.uploaded_code.script_name\n\n        # Modify hyperparameters in-place to point to the right code directory and script URIs\n        self._hyperparameters[DIR_PARAM_NAME] = code_dir\n        self._hyperparameters[SCRIPT_PARAM_NAME] = script\n        self._hyperparameters[CLOUDWATCH_METRICS_PARAM_NAME] = self.enable_cloudwatch_metrics\n        self._hyperparameters[CONTAINER_LOG_LEVEL_PARAM_NAME] = self.container_log_level\n        self._hyperparameters[JOB_NAME_PARAM_NAME] = self._current_job_name\n        self._hyperparameters[SAGEMAKER_REGION_PARAM_NAME] = self.sagemaker_session.boto_region_name\n\n        self._validate_and_set_debugger_configs()\n\n    def _validate_and_set_debugger_configs(self):\n        """"""\n        Set defaults for debugging\n        """"""\n        if self.debugger_hook_config is None and _region_supports_debugger(\n            self.sagemaker_session.boto_region_name\n        ):\n            self.debugger_hook_config = DebuggerHookConfig(s3_output_path=self.output_path)\n        elif not self.debugger_hook_config:\n            self.debugger_hook_config = None\n\n    def _stage_user_code_in_s3(self):\n        """"""Upload the user training script to s3 and return the location.\n\n        Returns: s3 uri\n        """"""\n        local_mode = self.output_path.startswith(""file://"")\n\n        if self.code_location is None and local_mode:\n            code_bucket = self.sagemaker_session.default_bucket()\n            code_s3_prefix = ""{}/{}"".format(self._current_job_name, ""source"")\n            kms_key = None\n        elif self.code_location is None:\n            code_bucket, _ = parse_s3_url(self.output_path)\n            code_s3_prefix = ""{}/{}"".format(self._current_job_name, ""source"")\n            kms_key = self.output_kms_key\n        elif local_mode:\n            code_bucket, key_prefix = parse_s3_url(self.code_location)\n            code_s3_prefix = ""/"".join(filter(None, [key_prefix, self._current_job_name, ""source""]))\n            kms_key = None\n        else:\n            code_bucket, key_prefix = parse_s3_url(self.code_location)\n            code_s3_prefix = ""/"".join(filter(None, [key_prefix, self._current_job_name, ""source""]))\n\n            output_bucket, _ = parse_s3_url(self.output_path)\n            kms_key = self.output_kms_key if code_bucket == output_bucket else None\n\n        return tar_and_upload_dir(\n            session=self.sagemaker_session.boto_session,\n            bucket=code_bucket,\n            s3_key_prefix=code_s3_prefix,\n            script=self.entry_point,\n            directory=self.source_dir,\n            dependencies=self.dependencies,\n            kms_key=kms_key,\n            s3_resource=self.sagemaker_session.s3_resource,\n        )\n\n    def _model_source_dir(self):\n        """"""Get the appropriate value to pass as source_dir to model constructor\n        on deploying\n\n        Returns:\n            str: Either a local or an S3 path pointing to the source_dir to be\n            used for code by the model to be deployed\n        """"""\n        return (\n            self.source_dir if self.sagemaker_session.local_mode else self.uploaded_code.s3_prefix\n        )\n\n    def hyperparameters(self):\n        """"""Return the hyperparameters as a dictionary to use for training.\n\n        The :meth:`~sagemaker.estimator.EstimatorBase.fit` method, which\n        trains the model, calls this method to find the hyperparameters.\n\n        Returns:\n            dict[str, str]: The hyperparameters.\n        """"""\n        return self._json_encode_hyperparameters(self._hyperparameters)\n\n    @classmethod\n    def _prepare_init_params_from_job_description(cls, job_details, model_channel_name=None):\n        """"""Convert the job description to init params that can be handled by the\n        class constructor\n\n        Args:\n            job_details: the returned job details from a describe_training_job\n                API call.\n            model_channel_name (str): Name of the channel where pre-trained\n                model data will be downloaded\n\n        Returns:\n            dictionary: The transformed init_params\n        """"""\n        init_params = super(Framework, cls)._prepare_init_params_from_job_description(\n            job_details, model_channel_name\n        )\n\n        init_params[""entry_point""] = json.loads(\n            init_params[""hyperparameters""].get(SCRIPT_PARAM_NAME)\n        )\n        init_params[""source_dir""] = json.loads(init_params[""hyperparameters""].get(DIR_PARAM_NAME))\n        init_params[""enable_cloudwatch_metrics""] = json.loads(\n            init_params[""hyperparameters""].get(CLOUDWATCH_METRICS_PARAM_NAME)\n        )\n        init_params[""container_log_level""] = json.loads(\n            init_params[""hyperparameters""].get(CONTAINER_LOG_LEVEL_PARAM_NAME)\n        )\n\n        hyperparameters = {}\n        for k, v in init_params[""hyperparameters""].items():\n            # Tuning jobs add this special hyperparameter which is not JSON serialized\n            if k == ""_tuning_objective_metric"":\n                if v.startswith(\'""\') and v.endswith(\'""\'):\n                    v = v.strip(\'""\')\n                hyperparameters[k] = v\n            else:\n                hyperparameters[k] = json.loads(v)\n\n        init_params[""hyperparameters""] = hyperparameters\n\n        return init_params\n\n    def train_image(self):\n        """"""Return the Docker image to use for training.\n\n        The :meth:`~sagemaker.estimator.EstimatorBase.fit` method, which does\n        the model training, calls this method to find the image to use for model\n        training.\n\n        Returns:\n            str: The URI of the Docker image.\n        """"""\n        if self.image_name:\n            return self.image_name\n        return create_image_uri(\n            self.sagemaker_session.boto_region_name,\n            self.__framework_name__,\n            self.train_instance_type,\n            self.framework_version,  # pylint: disable=no-member\n            py_version=self.py_version,  # pylint: disable=no-member\n        )\n\n    @classmethod\n    def attach(cls, training_job_name, sagemaker_session=None, model_channel_name=""model""):\n        """"""Attach to an existing training job.\n\n        Create an Estimator bound to an existing training job, each subclass\n        is responsible to implement\n        ``_prepare_init_params_from_job_description()`` as this method delegates\n        the actual conversion of a training job description to the arguments\n        that the class constructor expects. After attaching, if the training job\n        has a Complete status, it can be ``deploy()`` ed to create a SageMaker\n        Endpoint and return a ``Predictor``.\n\n        If the training job is in progress, attach will block and display log\n        messages from the training job, until the training job completes.\n\n        Examples:\n            >>> my_estimator.fit(wait=False)\n            >>> training_job_name = my_estimator.latest_training_job.name\n            Later on:\n            >>> attached_estimator = Estimator.attach(training_job_name)\n            >>> attached_estimator.deploy()\n\n        Args:\n            training_job_name (str): The name of the training job to attach to.\n            sagemaker_session (sagemaker.session.Session): Session object which\n                manages interactions with Amazon SageMaker APIs and any other\n                AWS services needed. If not specified, the estimator creates one\n                using the default AWS configuration chain.\n            model_channel_name (str): Name of the channel where pre-trained\n                model data will be downloaded (default: \'model\'). If no channel\n                with the same name exists in the training job, this option will\n                be ignored.\n\n        Returns:\n            Instance of the calling ``Estimator`` Class with the attached\n            training job.\n        """"""\n        estimator = super(Framework, cls).attach(\n            training_job_name, sagemaker_session, model_channel_name\n        )\n\n        # pylint gets confused thinking that estimator is an EstimatorBase instance, but it actually\n        # is a Framework or any of its derived classes. We can safely ignore the no-member errors.\n        estimator.uploaded_code = UploadedCode(\n            estimator.source_dir, estimator.entry_point  # pylint: disable=no-member\n        )\n        return estimator\n\n    @staticmethod\n    def _json_encode_hyperparameters(hyperparameters):\n        """"""\n        Args:\n            hyperparameters:\n        """"""\n        return {str(k): json.dumps(v) for (k, v) in hyperparameters.items()}\n\n    @classmethod\n    def _update_init_params(cls, hp, tf_arguments):\n        """"""\n        Args:\n            hp:\n            tf_arguments:\n        """"""\n        updated_params = {}\n        for argument in tf_arguments:\n            value = hp.pop(argument, None)\n            if value is not None:\n                value = json.loads(value)\n                updated_params[argument] = value\n        return updated_params\n\n    def transformer(\n        self,\n        instance_count,\n        instance_type,\n        strategy=None,\n        assemble_with=None,\n        output_path=None,\n        output_kms_key=None,\n        accept=None,\n        env=None,\n        max_concurrent_transforms=None,\n        max_payload=None,\n        tags=None,\n        role=None,\n        model_server_workers=None,\n        volume_kms_key=None,\n        entry_point=None,\n        vpc_config_override=vpc_utils.VPC_CONFIG_DEFAULT,\n        enable_network_isolation=None,\n        model_name=None,\n    ):\n        """"""Return a ``Transformer`` that uses a SageMaker Model based on the\n        training job. It reuses the SageMaker Session and base job name used by\n        the Estimator.\n\n        Args:\n            instance_count (int): Number of EC2 instances to use.\n            instance_type (str): Type of EC2 instance to use, for example,\n                \'ml.c4.xlarge\'.\n            strategy (str): The strategy used to decide how to batch records in\n                a single request (default: None). Valid values: \'MultiRecord\'\n                and \'SingleRecord\'.\n            assemble_with (str): How the output is assembled (default: None).\n                Valid values: \'Line\' or \'None\'.\n            output_path (str): S3 location for saving the transform result. If\n                not specified, results are stored to a default bucket.\n            output_kms_key (str): Optional. KMS key ID for encrypting the\n                transform output (default: None).\n            accept (str): The accept header passed by the client to\n                the inference endpoint. If it is supported by the endpoint,\n                it will be the format of the batch transform output.\n            env (dict): Environment variables to be set for use during the\n                transform job (default: None).\n            max_concurrent_transforms (int): The maximum number of HTTP requests\n                to be made to each individual transform container at one time.\n            max_payload (int): Maximum size of the payload in a single HTTP\n                request to the container in MB.\n            tags (list[dict]): List of tags for labeling a transform job. If\n                none specified, then the tags used for the training job are used\n                for the transform job.\n            role (str): The ``ExecutionRoleArn`` IAM Role ARN for the ``Model``,\n                which is also used during transform jobs. If not specified, the\n                role from the Estimator will be used.\n            model_server_workers (int): Optional. The number of worker processes\n                used by the inference server. If None, server will use one\n                worker per vCPU.\n            volume_kms_key (str): Optional. KMS key ID for encrypting the volume\n                attached to the ML compute instance (default: None).\n            entry_point (str): Path (absolute or relative) to the local Python source file which\n                should be executed as the entry point to training. If ``source_dir`` is specified,\n                then ``entry_point`` must point to a file located at the root of ``source_dir``.\n                If not specified, the training entry point is used.\n            vpc_config_override (dict[str, list[str]]): Optional override for\n                the VpcConfig set on the model.\n                Default: use subnets and security groups from this Estimator.\n\n                * \'Subnets\' (list[str]): List of subnet ids.\n                * \'SecurityGroupIds\' (list[str]): List of security group ids.\n\n            enable_network_isolation (bool): Specifies whether container will\n                run in network isolation mode. Network isolation mode restricts\n                the container access to outside networks (such as the internet).\n                The container does not make any inbound or outbound network\n                calls. If True, a channel named ""code"" will be created for any\n                user entry script for inference. Also known as Internet-free mode.\n                If not specified, this setting is taken from the estimator\'s\n                current configuration.\n            model_name (str): Name to use for creating an Amazon SageMaker\n                model. If not specified, the name of the training job is used.\n\n        Returns:\n            sagemaker.transformer.Transformer: a ``Transformer`` object that can be used to start a\n                SageMaker Batch Transform job.\n        """"""\n        role = role or self.role\n        tags = tags or self.tags\n\n        if self.latest_training_job is not None:\n            if enable_network_isolation is None:\n                enable_network_isolation = self.enable_network_isolation()\n\n            model = self.create_model(\n                role=role,\n                model_server_workers=model_server_workers,\n                entry_point=entry_point,\n                vpc_config_override=vpc_config_override,\n                model_kms_key=self.output_kms_key,\n                enable_network_isolation=enable_network_isolation,\n                name=model_name,\n            )\n            model._create_sagemaker_model(instance_type, tags=tags)\n\n            model_name = model.name\n            transform_env = model.env.copy()\n            if env is not None:\n                transform_env.update(env)\n        else:\n            logging.warning(\n                ""No finished training job found associated with this estimator. Please make sure ""\n                ""this estimator is only used for building workflow config""\n            )\n            model_name = model_name or self._current_job_name\n            transform_env = env or {}\n\n        return Transformer(\n            model_name,\n            instance_count,\n            instance_type,\n            strategy=strategy,\n            assemble_with=assemble_with,\n            output_path=output_path,\n            output_kms_key=output_kms_key,\n            accept=accept,\n            max_concurrent_transforms=max_concurrent_transforms,\n            max_payload=max_payload,\n            env=transform_env,\n            tags=tags,\n            base_transform_job_name=self.base_job_name,\n            volume_kms_key=volume_kms_key,\n            sagemaker_session=self.sagemaker_session,\n        )\n\n\ndef _s3_uri_prefix(channel_name, s3_data):\n    """"""\n    Args:\n        channel_name:\n        s3_data:\n    """"""\n    if isinstance(s3_data, s3_input):\n        s3_uri = s3_data.config[""DataSource""][""S3DataSource""][""S3Uri""]\n    else:\n        s3_uri = s3_data\n    if not s3_uri.startswith(""s3://""):\n        raise ValueError(""Expecting an s3 uri. Got {}"".format(s3_uri))\n    return {channel_name: s3_uri[5:]}\n\n\n# E.g. \'s3://bucket/data\' would return \'bucket/data\'.\n# Also accepts other valid input types, e.g. dict and s3_input.\ndef _s3_uri_without_prefix_from_input(input_data):\n    # Unpack an input_config object from a dict if a dict was passed in.\n    """"""\n    Args:\n        input_data:\n    """"""\n    if isinstance(input_data, dict):\n        response = {}\n        for channel_name, channel_s3_uri in input_data.items():\n            response.update(_s3_uri_prefix(channel_name, channel_s3_uri))\n        return response\n    if isinstance(input_data, str):\n        return _s3_uri_prefix(""training"", input_data)\n    if isinstance(input_data, s3_input):\n        return _s3_uri_prefix(""training"", input_data)\n    raise ValueError(\n        ""Unrecognized type for S3 input data config - not str or s3_input: {}"".format(input_data)\n    )\n'"
src/sagemaker/exceptions.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Custom exception classes for Sagemaker SDK""""""\nfrom __future__ import absolute_import\n\n\nclass UnexpectedStatusException(ValueError):\n    """"""Raised when resource status is not expected and thus not allowed for further execution""""""\n\n    def __init__(self, message, allowed_statuses, actual_status):\n        self.allowed_statuses = allowed_statuses\n        self.actual_status = actual_status\n        super(UnexpectedStatusException, self).__init__(message)\n'"
src/sagemaker/fw_registry.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\nimport logging\n\nfrom sagemaker.utils import get_ecr_image_uri_prefix\n\nimage_registry_map = {\n    ""us-west-1"": {\n        ""sparkml-serving"": ""746614075791"",\n        ""scikit-learn"": ""746614075791"",\n        ""xgboost"": ""746614075791"",\n    },\n    ""us-west-2"": {\n        ""sparkml-serving"": ""246618743249"",\n        ""scikit-learn"": ""246618743249"",\n        ""xgboost"": ""246618743249"",\n    },\n    ""us-east-1"": {\n        ""sparkml-serving"": ""683313688378"",\n        ""scikit-learn"": ""683313688378"",\n        ""xgboost"": ""683313688378"",\n    },\n    ""us-east-2"": {\n        ""sparkml-serving"": ""257758044811"",\n        ""scikit-learn"": ""257758044811"",\n        ""xgboost"": ""257758044811"",\n    },\n    ""ap-northeast-1"": {\n        ""sparkml-serving"": ""354813040037"",\n        ""scikit-learn"": ""354813040037"",\n        ""xgboost"": ""354813040037"",\n    },\n    ""ap-northeast-2"": {\n        ""sparkml-serving"": ""366743142698"",\n        ""scikit-learn"": ""366743142698"",\n        ""xgboost"": ""366743142698"",\n    },\n    ""ap-southeast-1"": {\n        ""sparkml-serving"": ""121021644041"",\n        ""scikit-learn"": ""121021644041"",\n        ""xgboost"": ""121021644041"",\n    },\n    ""ap-southeast-2"": {\n        ""sparkml-serving"": ""783357654285"",\n        ""scikit-learn"": ""783357654285"",\n        ""xgboost"": ""783357654285"",\n    },\n    ""ap-south-1"": {\n        ""sparkml-serving"": ""720646828776"",\n        ""scikit-learn"": ""720646828776"",\n        ""xgboost"": ""720646828776"",\n    },\n    ""eu-west-1"": {\n        ""sparkml-serving"": ""141502667606"",\n        ""scikit-learn"": ""141502667606"",\n        ""xgboost"": ""141502667606"",\n    },\n    ""eu-west-2"": {\n        ""sparkml-serving"": ""764974769150"",\n        ""scikit-learn"": ""764974769150"",\n        ""xgboost"": ""764974769150"",\n    },\n    ""eu-central-1"": {\n        ""sparkml-serving"": ""492215442770"",\n        ""scikit-learn"": ""492215442770"",\n        ""xgboost"": ""492215442770"",\n    },\n    ""ca-central-1"": {\n        ""sparkml-serving"": ""341280168497"",\n        ""scikit-learn"": ""341280168497"",\n        ""xgboost"": ""341280168497"",\n    },\n    ""us-gov-west-1"": {\n        ""sparkml-serving"": ""414596584902"",\n        ""scikit-learn"": ""414596584902"",\n        ""xgboost"": ""414596584902"",\n    },\n    ""us-iso-east-1"": {\n        ""sparkml-serving"": ""833128469047"",\n        ""scikit-learn"": ""833128469047"",\n        ""xgboost"": ""833128469047"",\n    },\n    ""ap-east-1"": {\n        ""sparkml-serving"": ""651117190479"",\n        ""scikit-learn"": ""651117190479"",\n        ""xgboost"": ""651117190479"",\n    },\n    ""sa-east-1"": {\n        ""sparkml-serving"": ""737474898029"",\n        ""scikit-learn"": ""737474898029"",\n        ""xgboost"": ""737474898029"",\n    },\n    ""eu-north-1"": {\n        ""sparkml-serving"": ""662702820516"",\n        ""scikit-learn"": ""662702820516"",\n        ""xgboost"": ""662702820516"",\n    },\n    ""eu-west-3"": {\n        ""sparkml-serving"": ""659782779980"",\n        ""scikit-learn"": ""659782779980"",\n        ""xgboost"": ""659782779980"",\n    },\n    ""me-south-1"": {\n        ""sparkml-serving"": ""801668240914"",\n        ""scikit-learn"": ""801668240914"",\n        ""xgboost"": ""801668240914"",\n    },\n    ""cn-north-1"": {\n        ""sparkml-serving"": ""450853457545"",\n        ""scikit-learn"": ""450853457545"",\n        ""xgboost"": ""450853457545"",\n    },\n    ""cn-northwest-1"": {\n        ""sparkml-serving"": ""451049120500"",\n        ""scikit-learn"": ""451049120500"",\n        ""xgboost"": ""451049120500"",\n    },\n}\n\n\ndef registry(region_name, framework=None):\n    """"""Return docker registry for the given AWS region for the given framework.\n    This is only used for SparkML and Scikit-learn for now.\n\n    Args:\n        region_name:\n        framework:\n    """"""\n    try:\n        account_id = image_registry_map[region_name][framework]\n        return get_ecr_image_uri_prefix(account_id, region_name)\n    except KeyError:\n        logging.error(""The specific image or region does not exist"")\n        raise\n\n\ndef default_framework_uri(framework, region_name, image_tag):\n    """"""\n    Args:\n        framework:\n        region_name:\n        image_tag:\n    """"""\n    repository_name = ""sagemaker-{}"".format(framework)\n    account_name = registry(region_name, framework)\n    return ""{}/{}:{}"".format(account_name, repository_name, image_tag)\n'"
src/sagemaker/fw_utils.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Utility methods used by framework classes""""""\nfrom __future__ import absolute_import\n\nimport logging\nimport os\nimport re\nimport shutil\nimport tempfile\nfrom collections import namedtuple\n\nimport sagemaker.utils\nfrom sagemaker import s3\nfrom sagemaker.utils import get_ecr_image_uri_prefix, ECR_URI_PATTERN\n\nlogger = logging.getLogger(""sagemaker"")\n\n_TAR_SOURCE_FILENAME = ""source.tar.gz""\n\nUploadedCode = namedtuple(""UserCode"", [""s3_prefix"", ""script_name""])\n""""""sagemaker.fw_utils.UserCode: An object containing the S3 prefix and script name.\nThis is for the source code used for the entry point with an ``Estimator``. It can be\ninstantiated with positional or keyword arguments.\n""""""\n\nEMPTY_FRAMEWORK_VERSION_WARNING = (\n    ""No framework_version specified, defaulting to version {}. ""\n    ""framework_version will be required in SageMaker Python SDK v2.""\n)\nLATER_FRAMEWORK_VERSION_WARNING = (\n    ""This is not the latest supported version. ""\n    ""If you would like to use version {latest}, ""\n    ""please add framework_version={latest} to your constructor.""\n)\nPYTHON_2_DEPRECATION_WARNING = (\n    ""{latest_supported_version} is the latest version of {framework} that supports ""\n    ""Python 2. Newer versions of {framework} will only be available for Python 3.""\n    ""Please set the argument \\""py_version=\'py3\'\\"" to use the Python 3 {framework} image.""\n)\nPARAMETER_SERVER_MULTI_GPU_WARNING = (\n    ""You have selected a multi-GPU training instance type. ""\n    ""You have also enabled parameter server for distributed training. ""\n    ""Distributed training with the default parameter server configuration will not ""\n    ""fully leverage all GPU cores; the parameter server will be configured to run ""\n    ""only one worker per host regardless of the number of GPUs.""\n)\nPARAMETER_V2_RENAME_WARNING = (\n    ""Parameter {v1_parameter_name} will be renamed to {v2_parameter_name} ""\n    ""in SageMaker Python SDK v2.""\n)\n\n\nEMPTY_FRAMEWORK_VERSION_ERROR = (\n    ""framework_version is required for script mode estimator. ""\n    ""Please add framework_version={} to your constructor to avoid this error.""\n)\nUNSUPPORTED_FRAMEWORK_VERSION_ERROR = (\n    ""{} framework does not support version {}. Please use one of the following: {}.""\n)\n\nVALID_PY_VERSIONS = [""py2"", ""py3"", ""py37""]\nVALID_EIA_FRAMEWORKS = [\n    ""tensorflow"",\n    ""tensorflow-serving"",\n    ""mxnet"",\n    ""mxnet-serving"",\n    ""pytorch-serving"",\n]\nPY2_RESTRICTED_EIA_FRAMEWORKS = [""pytorch-serving""]\nPY37_SUPPORTED_FRAMEWORKS = [""tensorflow-scriptmode""]\nVALID_ACCOUNTS_BY_REGION = {\n    ""us-gov-west-1"": ""246785580436"",\n    ""us-iso-east-1"": ""744548109606"",\n    ""cn-north-1"": ""422961961927"",\n    ""cn-northwest-1"": ""423003514399"",\n}\nASIMOV_VALID_ACCOUNTS_BY_REGION = {\n    ""us-gov-west-1"": ""442386744353"",\n    ""us-iso-east-1"": ""886529160074"",\n    ""cn-north-1"": ""727897471807"",\n    ""cn-northwest-1"": ""727897471807"",\n}\nOPT_IN_ACCOUNTS_BY_REGION = {""ap-east-1"": ""057415533634"", ""me-south-1"": ""724002660598""}\nASIMOV_OPT_IN_ACCOUNTS_BY_REGION = {""ap-east-1"": ""871362719292"", ""me-south-1"": ""217643126080""}\nDEFAULT_ACCOUNT = ""520713654638""\nASIMOV_PROD_ACCOUNT = ""763104351884""\nASIMOV_DEFAULT_ACCOUNT = ASIMOV_PROD_ACCOUNT\nSINGLE_GPU_INSTANCE_TYPES = (""ml.p2.xlarge"", ""ml.p3.2xlarge"")\n\nMERGED_FRAMEWORKS_REPO_MAP = {\n    ""tensorflow-scriptmode"": ""tensorflow-training"",\n    ""tensorflow-serving"": ""tensorflow-inference"",\n    ""tensorflow-serving-eia"": ""tensorflow-inference-eia"",\n    ""mxnet"": ""mxnet-training"",\n    ""mxnet-serving"": ""mxnet-inference"",\n    ""mxnet-serving-eia"": ""mxnet-inference-eia"",\n    ""pytorch"": ""pytorch-training"",\n    ""pytorch-serving"": ""pytorch-inference"",\n    ""pytorch-serving-eia"": ""pytorch-inference-eia"",\n}\n\nMERGED_FRAMEWORKS_LOWEST_VERSIONS = {\n    ""tensorflow-scriptmode"": {""py3"": [1, 13, 1], ""py2"": [1, 14, 0], ""py37"": [1, 15, 2]},\n    ""tensorflow-serving"": [1, 13, 0],\n    ""tensorflow-serving-eia"": [1, 14, 0],\n    ""mxnet"": {""py3"": [1, 4, 1], ""py2"": [1, 6, 0]},\n    ""mxnet-serving"": {""py3"": [1, 4, 1], ""py2"": [1, 6, 0]},\n    ""mxnet-serving-eia"": [1, 4, 1],\n    ""pytorch"": [1, 2, 0],\n    ""pytorch-serving"": [1, 2, 0],\n    ""pytorch-serving-eia"": [1, 3, 1],\n}\n\nINFERENTIA_VERSION_RANGES = {\n    ""neo-mxnet"": [[1, 5, 1], [1, 5, 1]],\n    ""neo-tensorflow"": [[1, 15, 0], [1, 15, 0]],\n}\n\nINFERENTIA_SUPPORTED_REGIONS = [""us-east-1"", ""us-west-2""]\n\nDEBUGGER_UNSUPPORTED_REGIONS = [""us-gov-west-1"", ""us-iso-east-1""]\n\n\ndef is_version_equal_or_higher(lowest_version, framework_version):\n    """"""Determine whether the ``framework_version`` is equal to or higher than\n    ``lowest_version``\n\n    Args:\n        lowest_version (List[int]): lowest version represented in an integer\n            list\n        framework_version (str): framework version string\n\n    Returns:\n        bool: Whether or not ``framework_version`` is equal to or higher than\n            ``lowest_version``\n    """"""\n    version_list = [int(s) for s in framework_version.split(""."")]\n    return version_list >= lowest_version[0 : len(version_list)]\n\n\ndef is_version_equal_or_lower(highest_version, framework_version):\n    """"""Determine whether the ``framework_version`` is equal to or lower than\n    ``highest_version``\n\n    Args:\n        highest_version (List[int]): highest version represented in an integer\n            list\n        framework_version (str): framework version string\n\n    Returns:\n        bool: Whether or not ``framework_version`` is equal to or lower than\n            ``highest_version``\n    """"""\n    version_list = [int(s) for s in framework_version.split(""."")]\n    return version_list <= highest_version[0 : len(version_list)]\n\n\ndef _is_dlc_version(framework, framework_version, py_version):\n    """"""Return if the framework\'s version uses the corresponding DLC image.\n\n    Args:\n        framework (str): The framework name, e.g. ""tensorflow-scriptmode""\n        framework_version (str): The framework version\n        py_version (str): The Python version, e.g. ""py3""\n\n    Returns:\n        bool: Whether or not the framework\'s version uses the DLC image.\n    """"""\n    lowest_version_list = MERGED_FRAMEWORKS_LOWEST_VERSIONS.get(framework)\n    if isinstance(lowest_version_list, dict):\n        lowest_version_list = lowest_version_list[py_version]\n\n    if lowest_version_list:\n        return is_version_equal_or_higher(lowest_version_list, framework_version)\n    return False\n\n\ndef _is_inferentia_supported(framework, framework_version):\n    """"""Return if Inferentia supports the framework and its version.\n\n    Args:\n        framework (str): The framework name, e.g. ""tensorflow""\n        framework_version (str): The framework version\n\n    Returns:\n        bool: Whether or not Inferentia supports the framework and its version.\n    """"""\n    lowest_version_list = INFERENTIA_VERSION_RANGES.get(framework)[0]\n    highest_version_list = INFERENTIA_VERSION_RANGES.get(framework)[1]\n    return is_version_equal_or_higher(\n        lowest_version_list, framework_version\n    ) and is_version_equal_or_lower(highest_version_list, framework_version)\n\n\ndef _registry_id(region, framework, py_version, account, framework_version):\n    """"""Return the Amazon ECR registry number (or AWS account ID) for\n    the given framework, framework version, Python version, and region.\n\n    Args:\n        region (str): The AWS region.\n        framework (str): The framework name, e.g. ""tensorflow-scriptmode"".\n        py_version (str): The Python version, e.g. ""py3"".\n        account (str): The AWS account ID to use as a default.\n        framework_version (str): The framework version.\n\n    Returns:\n        str: The appropriate Amazon ECR registry number. If there is no\n            specific one for the framework, framework version, Python version,\n            and region, then ``account`` is returned.\n    """"""\n    if _is_dlc_version(framework, framework_version, py_version):\n        if region in ASIMOV_OPT_IN_ACCOUNTS_BY_REGION:\n            return ASIMOV_OPT_IN_ACCOUNTS_BY_REGION.get(region)\n        if region in ASIMOV_VALID_ACCOUNTS_BY_REGION:\n            return ASIMOV_VALID_ACCOUNTS_BY_REGION.get(region)\n        return ASIMOV_DEFAULT_ACCOUNT\n    if region in OPT_IN_ACCOUNTS_BY_REGION:\n        return OPT_IN_ACCOUNTS_BY_REGION.get(region)\n    return VALID_ACCOUNTS_BY_REGION.get(region, account)\n\n\ndef create_image_uri(\n    region,\n    framework,\n    instance_type,\n    framework_version,\n    py_version=None,\n    account=None,\n    accelerator_type=None,\n    optimized_families=None,\n):\n    """"""Return the ECR URI of an image.\n\n    Args:\n        region (str): AWS region where the image is uploaded.\n        framework (str): framework used by the image.\n        instance_type (str): SageMaker instance type. Used to determine device\n            type (cpu/gpu/family-specific optimized).\n        framework_version (str): The version of the framework.\n        py_version (str): Optional. Python version. If specified, should be one\n            of \'py2\' or \'py3\'. If not specified, image uri will not include a\n            python component.\n        account (str): AWS account that contains the image. (default:\n            \'520713654638\')\n        accelerator_type (str): SageMaker Elastic Inference accelerator type.\n        optimized_families (str): Instance families for which there exist\n            specific optimized images.\n\n    Returns:\n        str: The appropriate image URI based on the given parameters.\n    """"""\n    logger.warning(\n        ""\'create_image_uri\' will be deprecated in favor of \'ImageURIProvider\' class ""\n        ""in SageMaker Python SDK v2.""\n    )\n\n    optimized_families = optimized_families or []\n\n    if py_version and py_version not in VALID_PY_VERSIONS:\n        raise ValueError(""invalid py_version argument: {}"".format(py_version))\n\n    if py_version == ""py37"" and framework not in PY37_SUPPORTED_FRAMEWORKS:\n        raise ValueError(""{} does not support Python 3.7 at this time."".format(framework))\n\n    if _accelerator_type_valid_for_framework(\n        framework=framework,\n        py_version=py_version,\n        accelerator_type=accelerator_type,\n        optimized_families=optimized_families,\n    ):\n        framework += ""-eia""\n\n    # Handle account number for specific cases (e.g. GovCloud, opt-in regions, DLC images etc.)\n    if account is None:\n        account = _registry_id(\n            region=region,\n            framework=framework,\n            py_version=py_version,\n            account=DEFAULT_ACCOUNT,\n            framework_version=framework_version,\n        )\n\n    # Handle Local Mode\n    if instance_type.startswith(""local""):\n        device_type = ""cpu"" if instance_type == ""local"" else ""gpu""\n    elif not instance_type.startswith(""ml.""):\n        raise ValueError(\n            ""{} is not a valid SageMaker instance type. See: ""\n            ""https://aws.amazon.com/sagemaker/pricing/instance-types/"".format(instance_type)\n        )\n    else:\n        family = instance_type.split(""."")[1]\n\n        # For some frameworks, we have optimized images for specific families, e.g c5 or p3.\n        # In those cases, we use the family name in the image tag. In other cases, we use\n        # \'cpu\' or \'gpu\'.\n        if family in optimized_families:\n            device_type = family\n        elif family.startswith(""inf""):\n            device_type = ""inf""\n        elif family[0] in [""g"", ""p""]:\n            device_type = ""gpu""\n        else:\n            device_type = ""cpu""\n\n    if device_type == ""inf"":\n        if region not in INFERENTIA_SUPPORTED_REGIONS:\n            raise ValueError(\n                ""Inferentia is not supported in region {}. Supported regions are {}"".format(\n                    region, "", "".join(INFERENTIA_SUPPORTED_REGIONS)\n                )\n            )\n        if framework not in INFERENTIA_VERSION_RANGES:\n            raise ValueError(\n                ""Inferentia does not support {}. Currently it supports ""\n                ""MXNet and TensorFlow with more frameworks coming soon."".format(\n                    framework.split(""-"")[-1]\n                )\n            )\n        if not _is_inferentia_supported(framework, framework_version):\n            raise ValueError(\n                ""Inferentia is not supported with {} version {}."".format(\n                    framework.split(""-"")[-1], framework_version\n                )\n            )\n\n    use_dlc_image = _is_dlc_version(framework, framework_version, py_version)\n\n    if not py_version or (use_dlc_image and framework == ""tensorflow-serving-eia""):\n        tag = ""{}-{}"".format(framework_version, device_type)\n    else:\n        tag = ""{}-{}-{}"".format(framework_version, device_type, py_version)\n\n    if use_dlc_image:\n        ecr_repo = MERGED_FRAMEWORKS_REPO_MAP[framework]\n    else:\n        ecr_repo = ""sagemaker-{}"".format(framework)\n\n    return ""{}/{}:{}"".format(get_ecr_image_uri_prefix(account, region), ecr_repo, tag)\n\n\ndef _accelerator_type_valid_for_framework(\n    framework, py_version, accelerator_type=None, optimized_families=None\n):\n    """"""\n    Args:\n        framework:\n        py_version:\n        accelerator_type:\n        optimized_families:\n    """"""\n    if accelerator_type is None:\n        return False\n\n    if py_version == ""py2"" and framework in PY2_RESTRICTED_EIA_FRAMEWORKS:\n        raise ValueError(\n            ""{} is not supported with Amazon Elastic Inference in Python 2."".format(framework)\n        )\n\n    if framework not in VALID_EIA_FRAMEWORKS:\n        raise ValueError(\n            ""{} is not supported with Amazon Elastic Inference. Currently only ""\n            ""Python-based TensorFlow, MXNet, PyTorch are supported."".format(framework)\n        )\n\n    if optimized_families:\n        raise ValueError(""Neo does not support Amazon Elastic Inference."")\n\n    if (\n        not accelerator_type.startswith(""ml.eia"")\n        and not accelerator_type == ""local_sagemaker_notebook""\n    ):\n        raise ValueError(\n            ""{} is not a valid SageMaker Elastic Inference accelerator type. ""\n            ""See: https://docs.aws.amazon.com/sagemaker/latest/dg/ei.html"".format(accelerator_type)\n        )\n\n    return True\n\n\ndef validate_source_dir(script, directory):\n    """"""Validate that the source directory exists and it contains the user script\n    Args:\n        script (str): Script filename.\n        directory (str): Directory containing the source file.\n    Raises:\n        ValueError: If ``directory`` does not exist, is not a directory, or does\n            not contain ``script``.\n    """"""\n    if directory:\n        if not os.path.isfile(os.path.join(directory, script)):\n            raise ValueError(\n                \'No file named ""{}"" was found in directory ""{}"".\'.format(script, directory)\n            )\n\n    return True\n\n\ndef tar_and_upload_dir(\n    session,\n    bucket,\n    s3_key_prefix,\n    script,\n    directory=None,\n    dependencies=None,\n    kms_key=None,\n    s3_resource=None,\n):\n    """"""Package source files and upload a compress tar file to S3. The S3\n    location will be ``s3://<bucket>/s3_key_prefix/sourcedir.tar.gz``.\n    If directory is an S3 URI, an UploadedCode object will be returned, but\n    nothing will be uploaded to S3 (this allow reuse of code already in S3).\n    If directory is None, the script will be added to the archive at\n    ``./<basename of script>``.\n    If directory is not None, the (recursive) contents of the directory will\n    be added to the archive. directory is treated as the base path of the\n    archive, and the script name is assumed to be a filename or relative path\n    inside the directory.\n    Args:\n        session (boto3.Session): Boto session used to access S3.\n        bucket (str): S3 bucket to which the compressed file is uploaded.\n        s3_key_prefix (str): Prefix for the S3 key.\n        script (str): Script filename or path.\n        directory (str): Optional. Directory containing the source file. If it\n            starts with ""s3://"", no action is taken.\n        dependencies (List[str]): Optional. A list of paths to directories\n            (absolute or relative) containing additional libraries that will be\n            copied into /opt/ml/lib\n        kms_key (str): Optional. KMS key ID used to upload objects to the bucket\n            (default: None).\n        s3_resource (boto3.resource(""s3"")): Optional. Pre-instantiated Boto3 Resource\n            for S3 connections, can be used to customize the configuration,\n            e.g. set the endpoint URL (default: None).\n    Returns:\n        sagemaker.fw_utils.UserCode: An object with the S3 bucket and key (S3 prefix) and\n            script name.\n    """"""\n    if directory and directory.lower().startswith(""s3://""):\n        return UploadedCode(s3_prefix=directory, script_name=os.path.basename(script))\n\n    script_name = script if directory else os.path.basename(script)\n    dependencies = dependencies or []\n    key = ""%s/sourcedir.tar.gz"" % s3_key_prefix\n    tmp = tempfile.mkdtemp()\n\n    try:\n        source_files = _list_files_to_compress(script, directory) + dependencies\n        tar_file = sagemaker.utils.create_tar_file(\n            source_files, os.path.join(tmp, _TAR_SOURCE_FILENAME)\n        )\n\n        if kms_key:\n            extra_args = {""ServerSideEncryption"": ""aws:kms"", ""SSEKMSKeyId"": kms_key}\n        else:\n            extra_args = None\n\n        if s3_resource is None:\n            s3_resource = session.resource(""s3"", region_name=session.region_name)\n        else:\n            print(""Using provided s3_resource"")\n\n        s3_resource.Object(bucket, key).upload_file(tar_file, ExtraArgs=extra_args)\n    finally:\n        shutil.rmtree(tmp)\n\n    return UploadedCode(s3_prefix=""s3://%s/%s"" % (bucket, key), script_name=script_name)\n\n\ndef _list_files_to_compress(script, directory):\n    """"""\n    Args:\n        script:\n        directory:\n    """"""\n    if directory is None:\n        return [script]\n\n    basedir = directory if directory else os.path.dirname(script)\n    return [os.path.join(basedir, name) for name in os.listdir(basedir)]\n\n\ndef framework_name_from_image(image_name):\n    # noinspection LongLine\n    """"""Extract the framework and Python version from the image name.\n    Args:\n        image_name (str): Image URI, which should be one of the following forms:\n            legacy:\n            \'<account>.dkr.ecr.<region>.amazonaws.com/sagemaker-<fw>-<py_ver>-<device>:<container_version>\'\n            legacy:\n            \'<account>.dkr.ecr.<region>.amazonaws.com/sagemaker-<fw>-<py_ver>-<device>:<fw_version>-<device>-<py_ver>\'\n            current:\n            \'<account>.dkr.ecr.<region>.amazonaws.com/sagemaker-<fw>:<fw_version>-<device>-<py_ver>\'\n            current:\n            \'<account>.dkr.ecr.<region>.amazonaws.com/sagemaker-rl-<fw>:<rl_toolkit><rl_version>-<device>-<py_ver>\'\n    Returns:\n        tuple: A tuple containing:\n            str: The framework name str: The Python version str: The image tag\n            str: If the image is script mode\n        """"""\n    sagemaker_pattern = re.compile(ECR_URI_PATTERN)\n    sagemaker_match = sagemaker_pattern.match(image_name)\n    if sagemaker_match is None:\n        return None, None, None, None\n    # extract framework, python version and image tag\n    # We must support both the legacy and current image name format.\n    name_pattern = re.compile(\n        r""^(?:sagemaker(?:-rl)?-)?(tensorflow|mxnet|chainer|pytorch|scikit-learn|xgboost)(?:-)?(scriptmode|training)?:(.*)-(.*?)-(py2|py3)$""  # noqa: E501 # pylint: disable=line-too-long\n    )\n    legacy_name_pattern = re.compile(r""^sagemaker-(tensorflow|mxnet)-(py2|py3)-(cpu|gpu):(.*)$"")\n\n    name_match = name_pattern.match(sagemaker_match.group(9))\n    legacy_match = legacy_name_pattern.match(sagemaker_match.group(9))\n\n    if name_match is not None:\n        fw, scriptmode, ver, device, py = (\n            name_match.group(1),\n            name_match.group(2),\n            name_match.group(3),\n            name_match.group(4),\n            name_match.group(5),\n        )\n        return fw, py, ""{}-{}-{}"".format(ver, device, py), scriptmode\n    if legacy_match is not None:\n        return (legacy_match.group(1), legacy_match.group(2), legacy_match.group(4), None)\n    return None, None, None, None\n\n\ndef framework_version_from_tag(image_tag):\n    """"""Extract the framework version from the image tag.\n    Args:\n        image_tag (str): Image tag, which should take the form\n            \'<framework_version>-<device>-<py_version>\'\n    Returns:\n        str: The framework version.\n    """"""\n    tag_pattern = re.compile(""^(.*)-(cpu|gpu)-(py2|py3)$"")\n    tag_match = tag_pattern.match(image_tag)\n    return None if tag_match is None else tag_match.group(1)\n\n\ndef parse_s3_url(url):\n    """"""Calls the method with the same name in the s3 module.\n\n    :func:~sagemaker.s3.parse_s3_url\n\n    Args:\n        url: A URL, expected with an s3 scheme.\n\n    Returns: The return value of s3.parse_s3_url, which is a tuple containing:\n        str: S3 bucket name str: S3 key\n    """"""\n    return s3.parse_s3_url(url)\n\n\ndef model_code_key_prefix(code_location_key_prefix, model_name, image):\n    """"""Returns the s3 key prefix for uploading code during model deployment\n    The location returned is a potential concatenation of 2 parts\n        1. code_location_key_prefix if it exists\n        2. model_name or a name derived from the image\n    Args:\n        code_location_key_prefix (str): the s3 key prefix from code_location\n        model_name (str): the name of the model\n        image (str): the image from which a default name can be extracted\n    Returns:\n        str: the key prefix to be used in uploading code\n    """"""\n    training_job_name = sagemaker.utils.name_from_image(image)\n    return ""/"".join(filter(None, [code_location_key_prefix, model_name or training_job_name]))\n\n\ndef empty_framework_version_warning(default_version, latest_version):\n    """"""\n    Args:\n        default_version:\n        latest_version:\n    """"""\n    msgs = [EMPTY_FRAMEWORK_VERSION_WARNING.format(default_version)]\n    if default_version != latest_version:\n        msgs.append(LATER_FRAMEWORK_VERSION_WARNING.format(latest=latest_version))\n    return "" "".join(msgs)\n\n\ndef warn_if_parameter_server_with_multi_gpu(training_instance_type, distributions):\n    """"""Warn the user that training will not fully leverage all the GPU\n    cores if parameter server is enabled and a multi-GPU instance is selected.\n    Distributed training with the default parameter server setup doesn\'t\n    support multi-GPU instances.\n\n    Args:\n        training_instance_type (str): A string representing the type of training instance selected.\n        distributions (dict): A dictionary with information to enable distributed training.\n            (Defaults to None if distributed training is not enabled.) For example:\n\n            .. code:: python\n\n                {\n                    \'parameter_server\':\n                    {\n                        \'enabled\': True\n                    }\n                }\n\n\n    """"""\n    if training_instance_type == ""local"" or distributions is None:\n        return\n\n    is_multi_gpu_instance = (\n        training_instance_type.split(""."")[1].startswith(""p"")\n        and training_instance_type not in SINGLE_GPU_INSTANCE_TYPES\n    )\n\n    ps_enabled = ""parameter_server"" in distributions and distributions[""parameter_server""].get(\n        ""enabled"", False\n    )\n\n    if is_multi_gpu_instance and ps_enabled:\n        logger.warning(PARAMETER_SERVER_MULTI_GPU_WARNING)\n\n\ndef get_unsupported_framework_version_error(\n    framework_name, unsupported_version, supported_versions\n):\n    """"""Return error message for unsupported framework version.\n\n    This should also return the supported versions for customers.\n\n    :param framework_name:\n    :param unsupported_version:\n    :param supported_versions:\n    :return:\n    """"""\n    return UNSUPPORTED_FRAMEWORK_VERSION_ERROR.format(\n        framework_name,\n        unsupported_version,\n        "", "".join(\'""{}""\'.format(version) for version in supported_versions),\n    )\n\n\ndef python_deprecation_warning(framework, latest_supported_version):\n    """"""\n    Args:\n        framework:\n        latest_supported_version:\n    """"""\n    return PYTHON_2_DEPRECATION_WARNING.format(\n        framework=framework, latest_supported_version=latest_supported_version\n    )\n\n\ndef parameter_v2_rename_warning(v1_parameter_name, v2_parameter_name):\n    """"""\n    Args:\n        v1_parameter_name: parameter name used in SageMaker Python SDK v1\n        v2_parameter_name: parameter name used in SageMaker Python SDK v2\n    """"""\n    return PARAMETER_V2_RENAME_WARNING.format(\n        v1_parameter_name=v1_parameter_name, v2_parameter_name=v2_parameter_name\n    )\n\n\ndef _region_supports_debugger(region_name):\n    """"""Returns boolean indicating whether the region supports Amazon SageMaker Debugger.\n\n    Args:\n        region_name (str): Name of the region to check against.\n\n    Returns:\n        bool: Whether or not the region supports Amazon SageMaker Debugger.\n\n    """"""\n    return region_name.lower() not in DEBUGGER_UNSUPPORTED_REGIONS\n'"
src/sagemaker/git_utils.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nimport os\nimport subprocess\nimport tempfile\nimport warnings\nimport six\nfrom six.moves import urllib\n\n\ndef git_clone_repo(git_config, entry_point, source_dir=None, dependencies=None):\n    """"""Git clone repo containing the training code and serving code. This method\n    also validate ``git_config``, and set ``entry_point``, ``source_dir`` and\n    ``dependencies`` to the right file or directory in the repo cloned.\n\n    Args:\n        git_config (dict[str, str]): Git configurations used for cloning files,\n            including ``repo``, ``branch``, ``commit``, ``2FA_enabled``,\n            ``username``, ``password`` and ``token``. The ``repo`` field is\n            required. All other fields are optional. ``repo`` specifies the Git\n            repository where your training script is stored. If you don\'t\n            provide ``branch``, the default value \'master\' is used. If you don\'t\n            provide ``commit``, the latest commit in the specified branch is\n            used. ``2FA_enabled``, ``username``, ``password`` and ``token`` are\n            for authentication purpose. If ``2FA_enabled`` is not provided, we\n            consider 2FA as disabled.\n\n            For GitHub and GitHub-like repos, when SSH URLs are provided, it\n            doesn\'t matter whether 2FA is enabled or disabled; you should either\n            have no passphrase for the SSH key pairs, or have the ssh-agent\n            configured so that you will not be prompted for SSH passphrase when\n            you do \'git clone\' command with SSH URLs. When https URLs are\n            provided: if 2FA is disabled, then either token or username+password\n            will be used for authentication if provided (token prioritized); if\n            2FA is enabled, only token will be used for authentication if\n            provided. If required authentication info is not provided, python\n            SDK will try to use local credentials storage to authenticate. If\n            that fails either, an error message will be thrown.\n\n            For CodeCommit repos, 2FA is not supported, so \'2FA_enabled\' should\n            not be provided. There is no token in CodeCommit, so \'token\' should\n            not be provided too. When \'repo\' is an SSH URL, the requirements are\n            the same as GitHub-like repos. When \'repo\' is an https URL,\n            username+password will be used for authentication if they are\n            provided; otherwise, python SDK will try to use either CodeCommit\n            credential helper or local credential storage for authentication.\n        entry_point (str): A relative location to the Python source file which\n            should be executed as the entry point to training or model hosting\n            in the Git repo.\n        source_dir (str): A relative location to a directory with other training\n            or model hosting source code dependencies aside from the entry point\n            file in the Git repo (default: None). Structure within this\n            directory are preserved when training on Amazon SageMaker.\n        dependencies (list[str]): A list of relative locations to directories\n            with any additional libraries that will be exported to the container\n            in the Git repo (default: []).\n\n    Returns:\n        dict: A dict that contains the updated values of entry_point, source_dir\n        and dependencies.\n\n    Raises:\n        CalledProcessError: If 1. failed to clone git repo\n                               2. failed to checkout the required branch\n                               3. failed to checkout the required commit\n        ValueError: If 1. entry point specified does not exist in the repo\n                       2. source dir specified does not exist in the repo\n                       3. dependencies specified do not exist in the repo\n                       4. wrong format is provided for git_config\n    """"""\n    if entry_point is None:\n        raise ValueError(""Please provide an entry point."")\n    _validate_git_config(git_config)\n    dest_dir = tempfile.mkdtemp()\n    _generate_and_run_clone_command(git_config, dest_dir)\n\n    _checkout_branch_and_commit(git_config, dest_dir)\n\n    updated_paths = {\n        ""entry_point"": entry_point,\n        ""source_dir"": source_dir,\n        ""dependencies"": dependencies,\n    }\n\n    # check if the cloned repo contains entry point, source directory and dependencies\n    if source_dir:\n        if not os.path.isdir(os.path.join(dest_dir, source_dir)):\n            raise ValueError(""Source directory does not exist in the repo."")\n        if not os.path.isfile(os.path.join(dest_dir, source_dir, entry_point)):\n            raise ValueError(""Entry point does not exist in the repo."")\n        updated_paths[""source_dir""] = os.path.join(dest_dir, source_dir)\n    else:\n        if os.path.isfile(os.path.join(dest_dir, entry_point)):\n            updated_paths[""entry_point""] = os.path.join(dest_dir, entry_point)\n        else:\n            raise ValueError(""Entry point does not exist in the repo."")\n    if dependencies is not None:\n        updated_paths[""dependencies""] = []\n        for path in dependencies:\n            if os.path.exists(os.path.join(dest_dir, path)):\n                updated_paths[""dependencies""].append(os.path.join(dest_dir, path))\n            else:\n                raise ValueError(""Dependency {} does not exist in the repo."".format(path))\n    return updated_paths\n\n\ndef _validate_git_config(git_config):\n    """"""\n    Args:\n        git_config:\n    """"""\n    if ""repo"" not in git_config:\n        raise ValueError(""Please provide a repo for git_config."")\n    for key in git_config:\n        if key == ""2FA_enabled"":\n            if not isinstance(git_config[""2FA_enabled""], bool):\n                raise ValueError(""Please enter a bool type for 2FA_enabled\'."")\n        elif not isinstance(git_config[key], six.string_types):\n            raise ValueError(""\'{}\' must be a string."".format(key))\n\n\ndef _generate_and_run_clone_command(git_config, dest_dir):\n    """"""check if a git_config param is valid, if it is, create the command to git\n    clone the repo, and run it.\n\n    Args:\n        git_config ((dict[str, str]): Git configurations used for cloning files,\n            including ``repo``, ``branch`` and ``commit``.\n        dest_dir (str): The local directory to clone the Git repo into.\n\n    Raises:\n        CalledProcessError: If failed to clone git repo.\n    """"""\n    if git_config[""repo""].startswith(""https://git-codecommit"") or git_config[""repo""].startswith(\n        ""ssh://git-codecommit""\n    ):\n        _clone_command_for_codecommit(git_config, dest_dir)\n    else:\n        _clone_command_for_github_like(git_config, dest_dir)\n\n\ndef _clone_command_for_github_like(git_config, dest_dir):\n    """"""check if a git_config param representing a GitHub (or like) repo is\n    valid, if it is, create the command to git clone the repo, and run it.\n\n    Args:\n        git_config ((dict[str, str]): Git configurations used for cloning files,\n            including ``repo``, ``branch`` and ``commit``.\n        dest_dir (str): The local directory to clone the Git repo into.\n\n    Raises:\n        ValueError: If git_config[\'repo\'] is in the wrong format.\n        CalledProcessError: If failed to clone git repo.\n    """"""\n    is_https = git_config[""repo""].startswith(""https://"")\n    is_ssh = git_config[""repo""].startswith(""git@"")\n    if not is_https and not is_ssh:\n        raise ValueError(""Invalid Git url provided."")\n    if is_ssh:\n        _clone_command_for_ssh(git_config, dest_dir)\n    elif ""2FA_enabled"" in git_config and git_config[""2FA_enabled""] is True:\n        _clone_command_for_github_like_https_2fa_enabled(git_config, dest_dir)\n    else:\n        _clone_command_for_github_like_https_2fa_disabled(git_config, dest_dir)\n\n\ndef _clone_command_for_ssh(git_config, dest_dir):\n    """"""\n    Args:\n        git_config:\n        dest_dir:\n    """"""\n    if ""username"" in git_config or ""password"" in git_config or ""token"" in git_config:\n        warnings.warn(""SSH cloning, authentication information in git config will be ignored."")\n    _run_clone_command(git_config[""repo""], dest_dir)\n\n\ndef _clone_command_for_github_like_https_2fa_disabled(git_config, dest_dir):\n    """"""\n    Args:\n        git_config:\n        dest_dir:\n    """"""\n    updated_url = git_config[""repo""]\n    if ""token"" in git_config:\n        if ""username"" in git_config or ""password"" in git_config:\n            warnings.warn(""Using token for authentication, "" ""other credentials will be ignored."")\n        updated_url = _insert_token_to_repo_url(url=git_config[""repo""], token=git_config[""token""])\n    elif ""username"" in git_config and ""password"" in git_config:\n        updated_url = _insert_username_and_password_to_repo_url(\n            url=git_config[""repo""], username=git_config[""username""], password=git_config[""password""]\n        )\n    elif ""username"" in git_config or ""password"" in git_config:\n        warnings.warn(""Credentials provided in git config will be ignored."")\n    _run_clone_command(updated_url, dest_dir)\n\n\ndef _clone_command_for_github_like_https_2fa_enabled(git_config, dest_dir):\n    """"""\n    Args:\n        git_config:\n        dest_dir:\n    """"""\n    updated_url = git_config[""repo""]\n    if ""token"" in git_config:\n        if ""username"" in git_config or ""password"" in git_config:\n            warnings.warn(""Using token for authentication, "" ""other credentials will be ignored."")\n        updated_url = _insert_token_to_repo_url(url=git_config[""repo""], token=git_config[""token""])\n    _run_clone_command(updated_url, dest_dir)\n\n\ndef _clone_command_for_codecommit(git_config, dest_dir):\n    """"""check if a git_config param representing a CodeCommit repo is valid, if\n    it is, create the command to git clone the repo, and run it.\n\n    Args:\n        git_config ((dict[str, str]): Git configurations used for cloning files,\n            including ``repo``, ``branch`` and ``commit``.\n        dest_dir (str): The local directory to clone the Git repo into.\n\n    Raises:\n        ValueError: If git_config[\'repo\'] is in the wrong format.\n        CalledProcessError: If failed to clone git repo.\n    """"""\n    is_https = git_config[""repo""].startswith(""https://git-codecommit"")\n    is_ssh = git_config[""repo""].startswith(""ssh://git-codecommit"")\n    if not is_https and not is_ssh:\n        raise ValueError(""Invalid Git url provided."")\n    if ""2FA_enabled"" in git_config:\n        warnings.warn(""CodeCommit does not support 2FA, \'2FA_enabled\' will be ignored."")\n    if ""token"" in git_config:\n        warnings.warn(""There are no tokens in CodeCommit, the token provided will be ignored."")\n    if is_ssh:\n        _clone_command_for_ssh(git_config, dest_dir)\n    else:\n        _clone_command_for_codecommit_https(git_config, dest_dir)\n\n\ndef _clone_command_for_codecommit_https(git_config, dest_dir):\n    """"""\n    Args:\n        git_config:\n        dest_dir:\n    """"""\n    updated_url = git_config[""repo""]\n    if ""username"" in git_config and ""password"" in git_config:\n        updated_url = _insert_username_and_password_to_repo_url(\n            url=git_config[""repo""], username=git_config[""username""], password=git_config[""password""]\n        )\n    elif ""username"" in git_config or ""password"" in git_config:\n        warnings.warn(""Credentials provided in git config will be ignored."")\n    _run_clone_command(updated_url, dest_dir)\n\n\ndef _run_clone_command(repo_url, dest_dir):\n    """"""Run the \'git clone\' command with the repo url and the directory to clone\n    the repo into.\n\n    Args:\n        repo_url (str): Git repo url to be cloned.\n        dest_dir: (str): Local path where the repo should be cloned into.\n\n    Raises:\n        CalledProcessError: If failed to clone git repo.\n    """"""\n    my_env = os.environ.copy()\n    if repo_url.startswith(""https://""):\n        my_env[""GIT_TERMINAL_PROMPT""] = ""0""\n        subprocess.check_call([""git"", ""clone"", repo_url, dest_dir], env=my_env)\n    elif repo_url.startswith(""git@""):\n        with tempfile.NamedTemporaryFile() as sshnoprompt:\n            write_pipe = open(sshnoprompt.name, ""w"")\n            write_pipe.write(""ssh -oBatchMode=yes $@"")\n            write_pipe.close()\n            # 511 in decimal is same as 777 in octal\n            os.chmod(sshnoprompt.name, 511)\n            my_env[""GIT_SSH""] = sshnoprompt.name\n            subprocess.check_call([""git"", ""clone"", repo_url, dest_dir], env=my_env)\n\n\ndef _insert_token_to_repo_url(url, token):\n    """"""Insert the token to the Git repo url, to make a component of the git\n    clone command. This method can only be called when repo_url is an https url.\n\n    Args:\n        url (str): Git repo url where the token should be inserted into.\n        token (str): Token to be inserted.\n\n    Returns:\n        str: the component needed fot the git clone command.\n    """"""\n    index = len(""https://"")\n    if url.find(token) == index:\n        return url\n    return url.replace(""https://"", ""https://"" + token + ""@"")\n\n\ndef _insert_username_and_password_to_repo_url(url, username, password):\n    """"""Insert the username and the password to the Git repo url, to make a\n    component of the git clone command. This method can only be called when\n    repo_url is an https url.\n\n    Args:\n        url (str): Git repo url where the token should be inserted into.\n        username (str): Username to be inserted.\n        password (str): Password to be inserted.\n\n    Returns:\n        str: the component needed for the git clone command.\n    """"""\n    password = urllib.parse.quote_plus(password)\n    # urllib parses \' \' as \'+\', but what we need is \'%20\' here\n    password = password.replace(""+"", ""%20"")\n    index = len(""https://"")\n    return url[:index] + username + "":"" + password + ""@"" + url[index:]\n\n\ndef _checkout_branch_and_commit(git_config, dest_dir):\n    """"""Checkout the required branch and commit.\n\n    Args:\n        git_config (dict[str, str]): Git configurations used for cloning files,\n            including ``repo``, ``branch`` and ``commit``.\n        dest_dir (str): the directory where the repo is cloned\n\n    Raises:\n        CalledProcessError: If 1. failed to checkout the required branch 2.\n            failed to checkout the required commit\n    """"""\n    if ""branch"" in git_config:\n        subprocess.check_call(args=[""git"", ""checkout"", git_config[""branch""]], cwd=str(dest_dir))\n    if ""commit"" in git_config:\n        subprocess.check_call(args=[""git"", ""checkout"", git_config[""commit""]], cwd=str(dest_dir))\n'"
src/sagemaker/inputs.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Amazon SageMaker channel configurations for S3 data sources and file system data sources""""""\nfrom __future__ import absolute_import, print_function\n\nimport logging\n\nFILE_SYSTEM_TYPES = [""FSxLustre"", ""EFS""]\nFILE_SYSTEM_ACCESS_MODES = [""ro"", ""rw""]\n\nlogger = logging.getLogger(""sagemaker"")\n\n\nclass s3_input(object):\n    """"""Amazon SageMaker channel configurations for S3 data sources.\n\n    Attributes:\n        config (dict[str, dict]): A SageMaker ``DataSource`` referencing\n            a SageMaker ``S3DataSource``.\n    """"""\n\n    def __init__(\n        self,\n        s3_data,\n        distribution=None,\n        compression=None,\n        content_type=None,\n        record_wrapping=None,\n        s3_data_type=""S3Prefix"",\n        input_mode=None,\n        attribute_names=None,\n        target_attribute_name=None,\n        shuffle_config=None,\n    ):\n        """"""Create a definition for input data used by an SageMaker training job.\n        See AWS documentation on the ``CreateTrainingJob`` API for more details on the parameters.\n\n        Args:\n            s3_data (str): Defines the location of s3 data to train on.\n            distribution (str): Valid values: \'FullyReplicated\', \'ShardedByS3Key\'\n                (default: \'FullyReplicated\').\n            compression (str): Valid values: \'Gzip\', None (default: None). This is used only in\n                Pipe input mode.\n            content_type (str): MIME type of the input data (default: None).\n            record_wrapping (str): Valid values: \'RecordIO\' (default: None).\n            s3_data_type (str): Valid values: \'S3Prefix\', \'ManifestFile\', \'AugmentedManifestFile\'.\n                If \'S3Prefix\', ``s3_data`` defines a prefix of s3 objects to train on.\n                All objects with s3 keys beginning with ``s3_data`` will be used to train.\n                If \'ManifestFile\' or \'AugmentedManifestFile\', then ``s3_data`` defines a\n                single S3 manifest file or augmented manifest file (respectively),\n                listing the S3 data to train on. Both the ManifestFile and\n                AugmentedManifestFile formats are described in the SageMaker API documentation:\n                https://docs.aws.amazon.com/sagemaker/latest/dg/API_S3DataSource.html\n            input_mode (str): Optional override for this channel\'s input mode (default: None).\n                By default, channels will use the input mode defined on\n                ``sagemaker.estimator.EstimatorBase.input_mode``, but they will ignore\n                that setting if this parameter is set.\n\n                    * None - Amazon SageMaker will use the input mode specified in the ``Estimator``\n                    * \'File\' - Amazon SageMaker copies the training dataset from the S3 location to\n                        a local directory.\n                    * \'Pipe\' - Amazon SageMaker streams data directly from S3 to the container via\n                        a Unix-named pipe.\n\n            attribute_names (list[str]): A list of one or more attribute names to use that are\n                found in a specified AugmentedManifestFile.\n            target_attribute_name (str): The name of the attribute will be predicted (classified)\n                in a SageMaker AutoML job. It is required if the input is for SageMaker AutoML job.\n            shuffle_config (ShuffleConfig): If specified this configuration enables shuffling on\n                this channel. See the SageMaker API documentation for more info:\n                https://docs.aws.amazon.com/sagemaker/latest/dg/API_ShuffleConfig.html\n        """"""\n        logger.warning(\n            ""\'s3_input\' class will be renamed to \'TrainingInput\' in SageMaker Python SDK v2.""\n        )\n\n        self.config = {\n            ""DataSource"": {""S3DataSource"": {""S3DataType"": s3_data_type, ""S3Uri"": s3_data}}\n        }\n\n        if not (target_attribute_name or distribution):\n            distribution = ""FullyReplicated""\n\n        if distribution is not None:\n            self.config[""DataSource""][""S3DataSource""][""S3DataDistributionType""] = distribution\n\n        if compression is not None:\n            self.config[""CompressionType""] = compression\n        if content_type is not None:\n            self.config[""ContentType""] = content_type\n        if record_wrapping is not None:\n            self.config[""RecordWrapperType""] = record_wrapping\n        if input_mode is not None:\n            self.config[""InputMode""] = input_mode\n        if attribute_names is not None:\n            self.config[""DataSource""][""S3DataSource""][""AttributeNames""] = attribute_names\n        if target_attribute_name is not None:\n            self.config[""TargetAttributeName""] = target_attribute_name\n        if shuffle_config is not None:\n            self.config[""ShuffleConfig""] = {""Seed"": shuffle_config.seed}\n\n\nclass FileSystemInput(object):\n    """"""Amazon SageMaker channel configurations for file system data sources.\n\n    Attributes:\n        config (dict[str, dict]): A Sagemaker File System ``DataSource``.\n    """"""\n\n    def __init__(\n        self,\n        file_system_id,\n        file_system_type,\n        directory_path,\n        file_system_access_mode=""ro"",\n        content_type=None,\n    ):\n        """"""Create a new file system input used by an SageMaker training job.\n\n        Args:\n            file_system_id (str): An Amazon file system ID starting with \'fs-\'.\n            file_system_type (str): The type of file system used for the input.\n                Valid values: \'EFS\', \'FSxLustre\'.\n            directory_path (str): Absolute or normalized path to the root directory (mount point) in\n                the file system.\n                Reference: https://docs.aws.amazon.com/efs/latest/ug/mounting-fs.html and\n                https://docs.aws.amazon.com/fsx/latest/LustreGuide/mount-fs-auto-mount-onreboot.html\n            file_system_access_mode (str): Permissions for read and write.\n                Valid values: \'ro\' or \'rw\'. Defaults to \'ro\'.\n        """"""\n\n        if file_system_type not in FILE_SYSTEM_TYPES:\n            raise ValueError(\n                ""Unrecognized file system type: %s. Valid values: %s.""\n                % (file_system_type, "", "".join(FILE_SYSTEM_TYPES))\n            )\n\n        if file_system_access_mode not in FILE_SYSTEM_ACCESS_MODES:\n            raise ValueError(\n                ""Unrecognized file system access mode: %s. Valid values: %s.""\n                % (file_system_access_mode, "", "".join(FILE_SYSTEM_ACCESS_MODES))\n            )\n\n        self.config = {\n            ""DataSource"": {\n                ""FileSystemDataSource"": {\n                    ""FileSystemId"": file_system_id,\n                    ""FileSystemType"": file_system_type,\n                    ""DirectoryPath"": directory_path,\n                    ""FileSystemAccessMode"": file_system_access_mode,\n                }\n            }\n        }\n\n        if content_type:\n            self.config[""ContentType""] = content_type\n'"
src/sagemaker/job.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nfrom abc import abstractmethod\nfrom six import string_types\n\nfrom sagemaker.inputs import FileSystemInput\nfrom sagemaker.local import file_input\nfrom sagemaker.session import s3_input\n\n\nclass _Job(object):\n    """"""Handle creating, starting and waiting for Amazon SageMaker jobs to\n    finish.\n\n    This class shouldn\'t be directly instantiated.\n\n    Subclasses must define a way to create, start and wait for an Amazon\n    SageMaker job.\n    """"""\n\n    def __init__(self, sagemaker_session, job_name):\n        """"""\n        Args:\n            sagemaker_session:\n            job_name:\n        """"""\n        self.sagemaker_session = sagemaker_session\n        self.job_name = job_name\n\n    @abstractmethod\n    def start_new(self, estimator, inputs):\n        """"""Create a new Amazon SageMaker job from the estimator.\n\n        Args:\n            estimator (sagemaker.estimator.EstimatorBase): Estimator object\n                created by the user.\n            inputs (str): Parameters used when called\n                :meth:`~sagemaker.estimator.EstimatorBase.fit`.\n\n        Returns:\n            sagemaker.job: Constructed object that captures all information\n            about the started job.\n        """"""\n\n    @abstractmethod\n    def wait(self):\n        """"""Wait for the Amazon SageMaker job to finish.""""""\n\n    @abstractmethod\n    def describe(self):\n        """"""Describe the job.""""""\n\n    @abstractmethod\n    def stop(self):\n        """"""Stop the job.""""""\n\n    @staticmethod\n    def _load_config(inputs, estimator, expand_role=True, validate_uri=True):\n        """"""\n        Args:\n            inputs:\n            estimator:\n            expand_role:\n            validate_uri:\n        """"""\n        input_config = _Job._format_inputs_to_input_config(inputs, validate_uri)\n        role = (\n            estimator.sagemaker_session.expand_role(estimator.role)\n            if expand_role\n            else estimator.role\n        )\n        output_config = _Job._prepare_output_config(estimator.output_path, estimator.output_kms_key)\n        resource_config = _Job._prepare_resource_config(\n            estimator.train_instance_count,\n            estimator.train_instance_type,\n            estimator.train_volume_size,\n            estimator.train_volume_kms_key,\n        )\n        stop_condition = _Job._prepare_stop_condition(\n            estimator.train_max_run, estimator.train_max_wait\n        )\n        vpc_config = estimator.get_vpc_config()\n\n        model_channel = _Job._prepare_channel(\n            input_config,\n            estimator.model_uri,\n            estimator.model_channel_name,\n            validate_uri,\n            content_type=""application/x-sagemaker-model"",\n            input_mode=""File"",\n        )\n        if model_channel:\n            input_config = [] if input_config is None else input_config\n            input_config.append(model_channel)\n\n        if estimator.enable_network_isolation():\n            code_channel = _Job._prepare_channel(\n                input_config, estimator.code_uri, estimator.code_channel_name, validate_uri\n            )\n\n            if code_channel:\n                input_config = [] if input_config is None else input_config\n                input_config.append(code_channel)\n\n        return {\n            ""input_config"": input_config,\n            ""role"": role,\n            ""output_config"": output_config,\n            ""resource_config"": resource_config,\n            ""stop_condition"": stop_condition,\n            ""vpc_config"": vpc_config,\n        }\n\n    @staticmethod\n    def _format_inputs_to_input_config(inputs, validate_uri=True):\n        """"""\n        Args:\n            inputs:\n            validate_uri:\n        """"""\n        if inputs is None:\n            return None\n\n        # Deferred import due to circular dependency\n        from sagemaker.amazon.amazon_estimator import RecordSet\n        from sagemaker.amazon.amazon_estimator import FileSystemRecordSet\n\n        if isinstance(inputs, (RecordSet, FileSystemRecordSet)):\n            inputs = inputs.data_channel()\n\n        input_dict = {}\n        if isinstance(inputs, string_types):\n            input_dict[""training""] = _Job._format_string_uri_input(inputs, validate_uri)\n        elif isinstance(inputs, s3_input):\n            input_dict[""training""] = inputs\n        elif isinstance(inputs, file_input):\n            input_dict[""training""] = inputs\n        elif isinstance(inputs, dict):\n            for k, v in inputs.items():\n                input_dict[k] = _Job._format_string_uri_input(v, validate_uri)\n        elif isinstance(inputs, list):\n            input_dict = _Job._format_record_set_list_input(inputs)\n        elif isinstance(inputs, FileSystemInput):\n            input_dict[""training""] = inputs\n        else:\n            msg = ""Cannot format input {}. Expecting one of str, dict, s3_input or FileSystemInput""\n            raise ValueError(msg.format(inputs))\n\n        channels = [\n            _Job._convert_input_to_channel(name, input) for name, input in input_dict.items()\n        ]\n\n        return channels\n\n    @staticmethod\n    def _convert_input_to_channel(channel_name, channel_s3_input):\n        """"""\n        Args:\n            channel_name:\n            channel_s3_input:\n        """"""\n        channel_config = channel_s3_input.config.copy()\n        channel_config[""ChannelName""] = channel_name\n        return channel_config\n\n    @staticmethod\n    def _format_string_uri_input(\n        uri_input,\n        validate_uri=True,\n        content_type=None,\n        input_mode=None,\n        compression=None,\n        target_attribute_name=None,\n    ):\n        """"""\n        Args:\n            uri_input:\n            validate_uri:\n            content_type:\n            input_mode:\n            compression:\n            target_attribute_name:\n        """"""\n        if isinstance(uri_input, str) and validate_uri and uri_input.startswith(""s3://""):\n            s3_input_result = s3_input(\n                uri_input,\n                content_type=content_type,\n                input_mode=input_mode,\n                compression=compression,\n                target_attribute_name=target_attribute_name,\n            )\n            return s3_input_result\n        if isinstance(uri_input, str) and validate_uri and uri_input.startswith(""file://""):\n            return file_input(uri_input)\n        if isinstance(uri_input, str) and validate_uri:\n            raise ValueError(\n                \'URI input {} must be a valid S3 or FILE URI: must start with ""s3://"" or \'\n                \'""file://""\'.format(uri_input)\n            )\n        if isinstance(uri_input, str):\n            s3_input_result = s3_input(\n                uri_input,\n                content_type=content_type,\n                input_mode=input_mode,\n                compression=compression,\n                target_attribute_name=target_attribute_name,\n            )\n            return s3_input_result\n        if isinstance(uri_input, (s3_input, file_input, FileSystemInput)):\n            return uri_input\n\n        raise ValueError(\n            ""Cannot format input {}. Expecting one of str, s3_input, file_input or ""\n            ""FileSystemInput"".format(uri_input)\n        )\n\n    @staticmethod\n    def _prepare_channel(\n        input_config,\n        channel_uri=None,\n        channel_name=None,\n        validate_uri=True,\n        content_type=None,\n        input_mode=None,\n    ):\n        """"""\n        Args:\n            input_config:\n            channel_uri:\n            channel_name:\n            validate_uri:\n            content_type:\n            input_mode:\n        """"""\n        if not channel_uri:\n            return None\n        if not channel_name:\n            raise ValueError(\n                ""Expected a channel name if a channel URI {} is specified"".format(channel_uri)\n            )\n\n        if input_config:\n            for existing_channel in input_config:\n                if existing_channel[""ChannelName""] == channel_name:\n                    raise ValueError(""Duplicate channel {} not allowed."".format(channel_name))\n\n        channel_input = _Job._format_string_uri_input(\n            channel_uri, validate_uri, content_type, input_mode\n        )\n        channel = _Job._convert_input_to_channel(channel_name, channel_input)\n\n        return channel\n\n    @staticmethod\n    def _format_model_uri_input(model_uri, validate_uri=True):\n        """"""\n        Args:\n            model_uri:\n            validate_uri:\n        """"""\n        if isinstance(model_uri, string_types) and validate_uri and model_uri.startswith(""s3://""):\n            return s3_input(\n                model_uri,\n                input_mode=""File"",\n                distribution=""FullyReplicated"",\n                content_type=""application/x-sagemaker-model"",\n            )\n        if isinstance(model_uri, string_types) and validate_uri and model_uri.startswith(""file://""):\n            return file_input(model_uri)\n        if isinstance(model_uri, string_types) and validate_uri:\n            raise ValueError(\n                \'Model URI must be a valid S3 or FILE URI: must start with ""s3://"" or \' \'""file://\'\n            )\n        if isinstance(model_uri, string_types):\n            return s3_input(\n                model_uri,\n                input_mode=""File"",\n                distribution=""FullyReplicated"",\n                content_type=""application/x-sagemaker-model"",\n            )\n        raise ValueError(""Cannot format model URI {}. Expecting str"".format(model_uri))\n\n    @staticmethod\n    def _format_record_set_list_input(inputs):\n        """"""\n        Args:\n            inputs:\n        """"""\n        # Deferred import due to circular dependency\n        from sagemaker.amazon.amazon_estimator import FileSystemRecordSet, RecordSet\n\n        input_dict = {}\n        for record in inputs:\n            if not isinstance(record, (RecordSet, FileSystemRecordSet)):\n                raise ValueError(""List compatible only with RecordSets or FileSystemRecordSets."")\n\n            if record.channel in input_dict:\n                raise ValueError(""Duplicate channels not allowed."")\n            if isinstance(record, RecordSet):\n                input_dict[record.channel] = record.records_s3_input()\n            if isinstance(record, FileSystemRecordSet):\n                input_dict[record.channel] = record.file_system_input\n\n        return input_dict\n\n    @staticmethod\n    def _prepare_output_config(s3_path, kms_key_id):\n        """"""\n        Args:\n            s3_path:\n            kms_key_id:\n        """"""\n        config = {""S3OutputPath"": s3_path}\n        if kms_key_id is not None:\n            config[""KmsKeyId""] = kms_key_id\n        return config\n\n    @staticmethod\n    def _prepare_resource_config(instance_count, instance_type, volume_size, train_volume_kms_key):\n        """"""\n        Args:\n            instance_count:\n            instance_type:\n            volume_size:\n            train_volume_kms_key:\n        """"""\n        resource_config = {\n            ""InstanceCount"": instance_count,\n            ""InstanceType"": instance_type,\n            ""VolumeSizeInGB"": volume_size,\n        }\n        if train_volume_kms_key is not None:\n            resource_config[""VolumeKmsKeyId""] = train_volume_kms_key\n\n        return resource_config\n\n    @staticmethod\n    def _prepare_stop_condition(max_run, max_wait):\n        """"""\n        Args:\n            max_run:\n            max_wait:\n        """"""\n        if max_wait:\n            return {""MaxRuntimeInSeconds"": max_run, ""MaxWaitTimeInSeconds"": max_wait}\n        return {""MaxRuntimeInSeconds"": max_run}\n\n    @property\n    def name(self):\n        """"""Placeholder docstring""""""\n        return self.job_name\n'"
src/sagemaker/logs.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nimport collections\nimport functools\nimport os\nimport sys\n\n##############################################################################\n#\n# Support for reading logs\n#\n##############################################################################\n\n\nclass ColorWrap(object):\n    """"""A callable that will print text in a different color depending on the\n    instance (up to 6 if standard output is a terminal or a Jupyter notebook\n    cell).\n    """"""\n\n    # For what color each number represents, see\n    # https://misc.flogisoft.com/bash/tip_colors_and_formatting#colors\n    _stream_colors = [34, 35, 32, 36, 33]\n\n    def __init__(self, force=False):\n        """"""Initialize the class.\n\n        Args:\n            force (bool): If True, render colorizes output no matter where the\n                output is (default: False).\n        """"""\n        self.colorize = force or sys.stdout.isatty() or os.environ.get(""JPY_PARENT_PID"", None)\n\n    def __call__(self, index, s):\n        """"""Print the output, colorized or not, depending on the environment.\n\n        Args:\n            index (int): The instance number.\n            s (str): The string to print.\n        """"""\n        if self.colorize:\n            self._color_wrap(index, s)\n        else:\n            print(s)\n\n    def _color_wrap(self, index, s):\n        """"""\n        Args:\n            index:\n            s:\n        """"""\n        print(""\\x1b[{}m{}\\x1b[0m"".format(self._stream_colors[index % len(self._stream_colors)], s))\n\n\ndef argmin(arr, f):\n    """"""Return the index, i, in arr that minimizes f(arr[i])\n\n    Args:\n        arr:\n        f:\n    """"""\n    m = None\n    i = None\n    for idx, item in enumerate(arr):\n        if item is not None:\n            if m is None or f(item) < m:\n                m = f(item)\n                i = idx\n    return i\n\n\ndef some(arr):\n    """"""Return True iff there is an element, a, of arr such that a is not None\n\n    Args:\n        arr:\n    """"""\n    return functools.reduce(lambda x, y: x or (y is not None), arr, False)\n\n\n# Position is a tuple that includes the last read timestamp and the number of items that were read\n# at that time. This is used to figure out which event to start with on the next read.\nPosition = collections.namedtuple(""Position"", [""timestamp"", ""skip""])\n\n\ndef multi_stream_iter(client, log_group, streams, positions=None):\n    """"""Iterate over the available events coming from a set of log streams in a single log group\n    interleaving the events from each stream so they\'re yielded in timestamp order.\n\n    Args:\n        client (boto3 client): The boto client for logs.\n        log_group (str): The name of the log group.\n        streams (list of str): A list of the log stream names. The position of the stream in\n        this list is the stream number.\n        positions: (list of Positions): A list of pairs of (timestamp, skip) which represents\n        the last record read from each stream.\n\n    Yields:\n        A tuple of (stream number, cloudwatch log event).\n    """"""\n    positions = positions or {s: Position(timestamp=0, skip=0) for s in streams}\n    event_iters = [\n        log_stream(client, log_group, s, positions[s].timestamp, positions[s].skip) for s in streams\n    ]\n    events = []\n    for s in event_iters:\n        if not s:\n            events.append(None)\n            continue\n        try:\n            events.append(next(s))\n        except StopIteration:\n            events.append(None)\n\n    while some(events):\n        i = argmin(events, lambda x: x[""timestamp""] if x else 9999999999)\n        yield (i, events[i])\n        try:\n            events[i] = next(event_iters[i])\n        except StopIteration:\n            events[i] = None\n\n\ndef log_stream(client, log_group, stream_name, start_time=0, skip=0):\n    """"""A generator for log items in a single stream. This will yield all the\n    items that are available at the current moment.\n\n    Args:\n        client (boto3.CloudWatchLogs.Client): The Boto client for CloudWatch logs.\n        log_group (str): The name of the log group.\n        stream_name (str): The name of the specific stream.\n        start_time (int): The time stamp value to start reading the logs from (default: 0).\n        skip (int): The number of log entries to skip at the start (default: 0). This is for\n        when there are multiple entries at the same timestamp.\n\n    Yields:\n       dict: A CloudWatch log event with the following key-value pairs:\n           \'timestamp\' (int): The time of the event.\n           \'message\' (str): The log event data.\n           \'ingestionTime\' (int): The time the event was ingested.\n    """"""\n\n    next_token = None\n\n    event_count = 1\n    while event_count > 0:\n        if next_token is not None:\n            token_arg = {""nextToken"": next_token}\n        else:\n            token_arg = {}\n\n        response = client.get_log_events(\n            logGroupName=log_group,\n            logStreamName=stream_name,\n            startTime=start_time,\n            startFromHead=True,\n            **token_arg\n        )\n        next_token = response[""nextForwardToken""]\n        events = response[""events""]\n        event_count = len(events)\n        if event_count > skip:\n            events = events[skip:]\n            skip = 0\n        else:\n            skip = skip - event_count\n            events = []\n        for ev in events:\n            yield ev\n'"
src/sagemaker/model.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nimport json\nimport logging\nimport os\n\nimport sagemaker\nfrom sagemaker import fw_utils, local, session, utils, git_utils\nfrom sagemaker.fw_utils import UploadedCode\nfrom sagemaker.transformer import Transformer\n\nLOGGER = logging.getLogger(""sagemaker"")\n\nNEO_ALLOWED_FRAMEWORKS = set(\n    [""mxnet"", ""tensorflow"", ""keras"", ""pytorch"", ""onnx"", ""xgboost"", ""tflite""]\n)\n\nNEO_IMAGE_ACCOUNT = {\n    ""us-west-1"": ""710691900526"",\n    ""us-west-2"": ""301217895009"",\n    ""us-east-1"": ""785573368785"",\n    ""us-east-2"": ""007439368137"",\n    ""eu-west-1"": ""802834080501"",\n    ""eu-west-2"": ""205493899709"",\n    ""eu-west-3"": ""254080097072"",\n    ""eu-central-1"": ""746233611703"",\n    ""eu-north-1"": ""601324751636"",\n    ""ap-northeast-1"": ""941853720454"",\n    ""ap-northeast-2"": ""151534178276"",\n    ""ap-east-1"": ""110948597952"",\n    ""ap-southeast-1"": ""324986816169"",\n    ""ap-southeast-2"": ""355873309152"",\n    ""ap-south-1"": ""763008648453"",\n    ""sa-east-1"": ""756306329178"",\n    ""ca-central-1"": ""464438896020"",\n    ""me-south-1"": ""836785723513"",\n    ""cn-north-1"": ""472730292857"",\n    ""cn-northwest-1"": ""474822919863"",\n    ""us-gov-west-1"": ""263933020539"",\n}\n\nINFERENTIA_INSTANCE_PREFIX = ""ml_inf""\n\n\nclass Model(object):\n    """"""A SageMaker ``Model`` that can be deployed to an ``Endpoint``.""""""\n\n    def __init__(\n        self,\n        model_data,\n        image,\n        role=None,\n        predictor_cls=None,\n        env=None,\n        name=None,\n        vpc_config=None,\n        sagemaker_session=None,\n        enable_network_isolation=False,\n        model_kms_key=None,\n    ):\n        """"""Initialize an SageMaker ``Model``.\n\n        Args:\n            model_data (str): The S3 location of a SageMaker model data\n                ``.tar.gz`` file.\n            image (str): A Docker image URI.\n            role (str): An AWS IAM role (either name or full ARN). The Amazon\n                SageMaker training jobs and APIs that create Amazon SageMaker\n                endpoints use this role to access training data and model\n                artifacts. After the endpoint is created, the inference code\n                might use the IAM role if it needs to access some AWS resources.\n                It can be null if this is being used to create a Model to pass\n                to a ``PipelineModel`` which has its own Role field. (default:\n                None)\n            predictor_cls (callable[string, sagemaker.session.Session]): A\n                function to call to create a predictor (default: None). If not\n                None, ``deploy`` will return the result of invoking this\n                function on the created endpoint name.\n            env (dict[str, str]): Environment variables to run with ``image``\n                when hosted in SageMaker (default: None).\n            name (str): The model name. If None, a default model name will be\n                selected on each ``deploy``.\n            vpc_config (dict[str, list[str]]): The VpcConfig set on the model\n                (default: None)\n                * \'Subnets\' (list[str]): List of subnet ids.\n                * \'SecurityGroupIds\' (list[str]): List of security group ids.\n            sagemaker_session (sagemaker.session.Session): A SageMaker Session\n                object, used for SageMaker interactions (default: None). If not\n                specified, one is created using the default AWS configuration\n                chain.\n            enable_network_isolation (Boolean): Default False. if True, enables\n                network isolation in the endpoint, isolating the model\n                container. No inbound or outbound network calls can be made to\n                or from the model container.\n            model_kms_key (str): KMS key ARN used to encrypt the repacked\n                model archive file if the model is repacked\n        """"""\n        LOGGER.warning(fw_utils.parameter_v2_rename_warning(""image"", ""image_uri""))\n\n        self.model_data = model_data\n        self.image = image\n        self.role = role\n        self.predictor_cls = predictor_cls\n        self.env = env or {}\n        self.name = name\n        self.vpc_config = vpc_config\n        self.sagemaker_session = sagemaker_session\n        self._model_name = None\n        self.endpoint_name = None\n        self._is_compiled_model = False\n        self._enable_network_isolation = enable_network_isolation\n        self.model_kms_key = model_kms_key\n\n    def _init_sagemaker_session_if_does_not_exist(self, instance_type):\n        """"""Set ``self.sagemaker_session`` to be a ``LocalSession`` or\n        ``Session`` if it is not already. The type of session object is\n        determined by the instance type.\n        """"""\n        if self.sagemaker_session:\n            return\n\n        if instance_type in (""local"", ""local_gpu""):\n            self.sagemaker_session = local.LocalSession()\n        else:\n            self.sagemaker_session = session.Session()\n\n    def prepare_container_def(\n        self, instance_type, accelerator_type=None\n    ):  # pylint: disable=unused-argument\n        """"""Return a dict created by ``sagemaker.container_def()`` for deploying\n        this model to a specified instance type.\n\n        Subclasses can override this to provide custom container definitions\n        for deployment to a specific instance type. Called by ``deploy()``.\n\n        Args:\n            instance_type (str): The EC2 instance type to deploy this Model to.\n                For example, \'ml.p2.xlarge\'.\n            accelerator_type (str): The Elastic Inference accelerator type to\n                deploy to the instance for loading and making inferences to the\n                model. For example, \'ml.eia1.medium\'.\n\n        Returns:\n            dict: A container definition object usable with the CreateModel API.\n        """"""\n        return sagemaker.container_def(self.image, self.model_data, self.env)\n\n    def enable_network_isolation(self):\n        """"""Whether to enable network isolation when creating this Model\n\n        Returns:\n            bool: If network isolation should be enabled or not.\n        """"""\n        return self._enable_network_isolation\n\n    def _create_sagemaker_model(self, instance_type, accelerator_type=None, tags=None):\n        """"""Create a SageMaker Model Entity\n\n        Args:\n            instance_type (str): The EC2 instance type that this Model will be\n                used for, this is only used to determine if the image needs GPU\n                support or not.\n            accelerator_type (str): Type of Elastic Inference accelerator to\n                attach to an endpoint for model loading and inference, for\n                example, \'ml.eia1.medium\'. If not specified, no Elastic\n                Inference accelerator will be attached to the endpoint.\n            tags (List[dict[str, str]]): Optional. The list of tags to add to\n                the model. Example: >>> tags = [{\'Key\': \'tagname\', \'Value\':\n                \'tagvalue\'}] For more information about tags, see\n                https://boto3.amazonaws.com/v1/documentation\n                /api/latest/reference/services/sagemaker.html#SageMaker.Client.add_tags\n        """"""\n        container_def = self.prepare_container_def(instance_type, accelerator_type=accelerator_type)\n        self.name = self.name or utils.name_from_image(container_def[""Image""])\n        enable_network_isolation = self.enable_network_isolation()\n\n        self._init_sagemaker_session_if_does_not_exist(instance_type)\n        self.sagemaker_session.create_model(\n            self.name,\n            self.role,\n            container_def,\n            vpc_config=self.vpc_config,\n            enable_network_isolation=enable_network_isolation,\n            tags=tags,\n        )\n\n    def _framework(self):\n        """"""Placeholder docstring""""""\n        return getattr(self, ""__framework_name__"", None)\n\n    def _get_framework_version(self):\n        """"""Placeholder docstring""""""\n        return getattr(self, ""framework_version"", None)\n\n    def _compilation_job_config(\n        self,\n        target_instance_type,\n        input_shape,\n        output_path,\n        role,\n        compile_max_run,\n        job_name,\n        framework,\n        tags,\n    ):\n        """"""\n        Args:\n            target_instance_type:\n            input_shape:\n            output_path:\n            role:\n            compile_max_run:\n            job_name:\n            framework:\n            tags:\n        """"""\n        input_model_config = {\n            ""S3Uri"": self.model_data,\n            ""DataInputConfig"": input_shape\n            if not isinstance(input_shape, dict)\n            else json.dumps(input_shape),\n            ""Framework"": framework,\n        }\n        role = self.sagemaker_session.expand_role(role)\n        output_model_config = {\n            ""TargetDevice"": target_instance_type,\n            ""S3OutputLocation"": output_path,\n        }\n\n        return {\n            ""input_model_config"": input_model_config,\n            ""output_model_config"": output_model_config,\n            ""role"": role,\n            ""stop_condition"": {""MaxRuntimeInSeconds"": compile_max_run},\n            ""tags"": tags,\n            ""job_name"": job_name,\n        }\n\n    def check_neo_region(self, region):\n        """"""Check if this ``Model`` in the available region where neo support.\n\n        Args:\n            region (str): Specifies the region where want to execute compilation\n\n        Returns:\n            bool: boolean value whether if neo is available in the specified\n            region\n        """"""\n        if region in NEO_IMAGE_ACCOUNT:\n            return True\n        return False\n\n    def _neo_image_account(self, region):\n        """"""\n        Args:\n            region:\n        """"""\n        if region not in NEO_IMAGE_ACCOUNT:\n            raise ValueError(\n                ""Neo is not currently supported in {}, ""\n                ""valid regions: {}"".format(region, NEO_IMAGE_ACCOUNT.keys())\n            )\n        return NEO_IMAGE_ACCOUNT[region]\n\n    def _neo_image(self, region, target_instance_type, framework, framework_version):\n        """"""\n        Args:\n            region:\n            target_instance_type:\n            framework:\n            framework_version:\n        """"""\n        return fw_utils.create_image_uri(\n            region,\n            ""neo-"" + framework.lower(),\n            target_instance_type.replace(""_"", "".""),\n            framework_version,\n            py_version=""py3"",\n            account=self._neo_image_account(region),\n        )\n\n    def _inferentia_image(self, region, target_instance_type, framework, framework_version):\n        """"""\n                Args:\n                    region:\n                    target_instance_type:\n                    framework:\n                    framework_version:\n                """"""\n        return fw_utils.create_image_uri(\n            region,\n            ""neo-"" + framework.lower(),\n            target_instance_type.replace(""_"", "".""),\n            framework_version,\n            py_version=""py3"",\n            account=self._neo_image_account(region),\n        )\n\n    def compile(\n        self,\n        target_instance_family,\n        input_shape,\n        output_path,\n        role,\n        tags=None,\n        job_name=None,\n        compile_max_run=5 * 60,\n        framework=None,\n        framework_version=None,\n    ):\n        """"""Compile this ``Model`` with SageMaker Neo.\n\n        Args:\n            target_instance_family (str): Identifies the device that you want to\n                run your model after compilation, for example: ml_c5. For allowed\n                strings see\n                https://docs.aws.amazon.com/sagemaker/latest/dg/API_OutputConfig.html.\n            input_shape (dict): Specifies the name and shape of the expected\n                inputs for your trained model in json dictionary form, for\n                example: {\'data\': [1,3,1024,1024]}, or {\'var1\': [1,1,28,28],\n                \'var2\': [1,1,28,28]}\n            output_path (str): Specifies where to store the compiled model\n            role (str): Execution role\n            tags (list[dict]): List of tags for labeling a compilation job. For\n                more, see\n                https://docs.aws.amazon.com/sagemaker/latest/dg/API_Tag.html.\n            job_name (str): The name of the compilation job\n            compile_max_run (int): Timeout in seconds for compilation (default:\n                3 * 60). After this amount of time Amazon SageMaker Neo\n                terminates the compilation job regardless of its current status.\n            framework (str): The framework that is used to train the original\n                model. Allowed values: \'mxnet\', \'tensorflow\', \'keras\', \'pytorch\',\n                \'onnx\', \'xgboost\'\n            framework_version (str):\n\n        Returns:\n            sagemaker.model.Model: A SageMaker ``Model`` object. See\n            :func:`~sagemaker.model.Model` for full details.\n        """"""\n        framework = self._framework() or framework\n        if framework is None:\n            raise ValueError(\n                ""You must specify framework, allowed values {}"".format(NEO_ALLOWED_FRAMEWORKS)\n            )\n        if framework not in NEO_ALLOWED_FRAMEWORKS:\n            raise ValueError(\n                ""You must provide valid framework, allowed values {}"".format(NEO_ALLOWED_FRAMEWORKS)\n            )\n        if job_name is None:\n            raise ValueError(""You must provide a compilation job name"")\n\n        framework = framework.upper()\n        framework_version = self._get_framework_version() or framework_version\n\n        self._init_sagemaker_session_if_does_not_exist(target_instance_family)\n        config = self._compilation_job_config(\n            target_instance_family,\n            input_shape,\n            output_path,\n            role,\n            compile_max_run,\n            job_name,\n            framework,\n            tags,\n        )\n        self.sagemaker_session.compile_model(**config)\n        job_status = self.sagemaker_session.wait_for_compilation_job(job_name)\n        self.model_data = job_status[""ModelArtifacts""][""S3ModelArtifacts""]\n        if target_instance_family.startswith(""ml_""):\n            self.image = self._neo_image(\n                self.sagemaker_session.boto_region_name,\n                target_instance_family,\n                framework,\n                framework_version,\n            )\n            self._is_compiled_model = True\n        elif target_instance_family.startswith(INFERENTIA_INSTANCE_PREFIX):\n            self.image = self._inferentia_image(\n                self.sagemaker_session.boto_region_name,\n                target_instance_family,\n                framework,\n                framework_version,\n            )\n            self._is_compiled_model = True\n        else:\n            LOGGER.warning(\n                ""The instance type %s is not supported to deploy via SageMaker,""\n                ""please deploy the model manually."",\n                target_instance_family,\n            )\n        return self\n\n    def deploy(\n        self,\n        initial_instance_count,\n        instance_type,\n        accelerator_type=None,\n        endpoint_name=None,\n        update_endpoint=False,\n        tags=None,\n        kms_key=None,\n        wait=True,\n        data_capture_config=None,\n    ):\n        """"""Deploy this ``Model`` to an ``Endpoint`` and optionally return a\n        ``Predictor``.\n\n        Create a SageMaker ``Model`` and ``EndpointConfig``, and deploy an\n        ``Endpoint`` from this ``Model``. If ``self.predictor_cls`` is not None,\n        this method returns a the result of invoking ``self.predictor_cls`` on\n        the created endpoint name.\n\n        The name of the created model is accessible in the ``name`` field of\n        this ``Model`` after deploy returns\n\n        The name of the created endpoint is accessible in the\n        ``endpoint_name`` field of this ``Model`` after deploy returns.\n\n        Args:\n            initial_instance_count (int): The initial number of instances to run\n                in the ``Endpoint`` created from this ``Model``.\n            instance_type (str): The EC2 instance type to deploy this Model to.\n                For example, \'ml.p2.xlarge\', or \'local\' for local mode.\n            accelerator_type (str): Type of Elastic Inference accelerator to\n                deploy this model for model loading and inference, for example,\n                \'ml.eia1.medium\'. If not specified, no Elastic Inference\n                accelerator will be attached to the endpoint. For more\n                information:\n                https://docs.aws.amazon.com/sagemaker/latest/dg/ei.html\n            endpoint_name (str): The name of the endpoint to create (default:\n                None). If not specified, a unique endpoint name will be created.\n            update_endpoint (bool): Flag to update the model in an existing\n                Amazon SageMaker endpoint. If True, this will deploy a new\n                EndpointConfig to an already existing endpoint and delete\n                resources corresponding to the previous EndpointConfig. If\n                False, a new endpoint will be created. Default: False\n            tags (List[dict[str, str]]): The list of tags to attach to this\n                specific endpoint.\n            kms_key (str): The ARN of the KMS key that is used to encrypt the\n                data on the storage volume attached to the instance hosting the\n                endpoint.\n            wait (bool): Whether the call should wait until the deployment of\n                this model completes (default: True).\n            data_capture_config (sagemaker.model_monitor.DataCaptureConfig): Specifies\n                configuration related to Endpoint data capture for use with\n                Amazon SageMaker Model Monitoring. Default: None.\n\n        Returns:\n            callable[string, sagemaker.session.Session] or None: Invocation of\n                ``self.predictor_cls`` on the created endpoint name, if ``self.predictor_cls``\n                is not None. Otherwise, return None.\n        """"""\n        self._init_sagemaker_session_if_does_not_exist(instance_type)\n\n        if self.role is None:\n            raise ValueError(""Role can not be null for deploying a model"")\n\n        if instance_type.startswith(""ml.inf"") and not self._is_compiled_model:\n            LOGGER.warning(\n                ""Your model is not compiled. Please compile your model before using Inferentia.""\n            )\n\n        compiled_model_suffix = ""-"".join(instance_type.split(""."")[:-1])\n        if self._is_compiled_model:\n            name_prefix = self.name or utils.name_from_image(self.image)\n            self.name = ""{}{}"".format(name_prefix, compiled_model_suffix)\n\n        self._create_sagemaker_model(instance_type, accelerator_type, tags)\n        production_variant = sagemaker.production_variant(\n            self.name, instance_type, initial_instance_count, accelerator_type=accelerator_type\n        )\n        if endpoint_name:\n            self.endpoint_name = endpoint_name\n        else:\n            self.endpoint_name = self.name\n            if self._is_compiled_model and not self.endpoint_name.endswith(compiled_model_suffix):\n                self.endpoint_name += compiled_model_suffix\n\n        data_capture_config_dict = None\n        if data_capture_config is not None:\n            data_capture_config_dict = data_capture_config._to_request_dict()\n\n        if update_endpoint:\n            endpoint_config_name = self.sagemaker_session.create_endpoint_config(\n                name=self.name,\n                model_name=self.name,\n                initial_instance_count=initial_instance_count,\n                instance_type=instance_type,\n                accelerator_type=accelerator_type,\n                tags=tags,\n                kms_key=kms_key,\n                data_capture_config_dict=data_capture_config_dict,\n            )\n            self.sagemaker_session.update_endpoint(\n                self.endpoint_name, endpoint_config_name, wait=wait\n            )\n        else:\n            self.sagemaker_session.endpoint_from_production_variants(\n                name=self.endpoint_name,\n                production_variants=[production_variant],\n                tags=tags,\n                kms_key=kms_key,\n                wait=wait,\n                data_capture_config_dict=data_capture_config_dict,\n            )\n\n        if self.predictor_cls:\n            return self.predictor_cls(self.endpoint_name, self.sagemaker_session)\n        return None\n\n    def transformer(\n        self,\n        instance_count,\n        instance_type,\n        strategy=None,\n        assemble_with=None,\n        output_path=None,\n        output_kms_key=None,\n        accept=None,\n        env=None,\n        max_concurrent_transforms=None,\n        max_payload=None,\n        tags=None,\n        volume_kms_key=None,\n    ):\n        """"""Return a ``Transformer`` that uses this Model.\n\n        Args:\n            instance_count (int): Number of EC2 instances to use.\n            instance_type (str): Type of EC2 instance to use, for example,\n                \'ml.c4.xlarge\'.\n            strategy (str): The strategy used to decide how to batch records in\n                a single request (default: None). Valid values: \'MultiRecord\'\n                and \'SingleRecord\'.\n            assemble_with (str): How the output is assembled (default: None).\n                Valid values: \'Line\' or \'None\'.\n            output_path (str): S3 location for saving the transform result. If\n                not specified, results are stored to a default bucket.\n            output_kms_key (str): Optional. KMS key ID for encrypting the\n                transform output (default: None).\n            accept (str): The accept header passed by the client to\n                the inference endpoint. If it is supported by the endpoint,\n                it will be the format of the batch transform output.\n            env (dict): Environment variables to be set for use during the\n                transform job (default: None).\n            max_concurrent_transforms (int): The maximum number of HTTP requests\n                to be made to each individual transform container at one time.\n            max_payload (int): Maximum size of the payload in a single HTTP\n                request to the container in MB.\n            tags (list[dict]): List of tags for labeling a transform job. If\n                none specified, then the tags used for the training job are used\n                for the transform job.\n            volume_kms_key (str): Optional. KMS key ID for encrypting the volume\n                attached to the ML compute instance (default: None).\n        """"""\n        self._init_sagemaker_session_if_does_not_exist(instance_type)\n\n        self._create_sagemaker_model(instance_type, tags=tags)\n        if self.enable_network_isolation():\n            env = None\n\n        return Transformer(\n            self.name,\n            instance_count,\n            instance_type,\n            strategy=strategy,\n            assemble_with=assemble_with,\n            output_path=output_path,\n            output_kms_key=output_kms_key,\n            accept=accept,\n            max_concurrent_transforms=max_concurrent_transforms,\n            max_payload=max_payload,\n            env=env,\n            tags=tags,\n            base_transform_job_name=self.name,\n            volume_kms_key=volume_kms_key,\n            sagemaker_session=self.sagemaker_session,\n        )\n\n    def delete_model(self):\n        """"""Delete an Amazon SageMaker Model.\n\n        Raises:\n            ValueError: if the model is not created yet.\n        """"""\n        if self.name is None:\n            raise ValueError(\n                ""The SageMaker model must be created first before attempting to delete.""\n            )\n        self.sagemaker_session.delete_model(self.name)\n\n\nSCRIPT_PARAM_NAME = ""sagemaker_program""\nDIR_PARAM_NAME = ""sagemaker_submit_directory""\nCLOUDWATCH_METRICS_PARAM_NAME = ""sagemaker_enable_cloudwatch_metrics""\nCONTAINER_LOG_LEVEL_PARAM_NAME = ""sagemaker_container_log_level""\nJOB_NAME_PARAM_NAME = ""sagemaker_job_name""\nMODEL_SERVER_WORKERS_PARAM_NAME = ""sagemaker_model_server_workers""\nSAGEMAKER_REGION_PARAM_NAME = ""sagemaker_region""\nSAGEMAKER_OUTPUT_LOCATION = ""sagemaker_s3_output""\n\n\nclass FrameworkModel(Model):\n    """"""A Model for working with an SageMaker ``Framework``.\n\n    This class hosts user-defined code in S3 and sets code location and\n    configuration in model environment variables.\n    """"""\n\n    def __init__(\n        self,\n        model_data,\n        image,\n        role,\n        entry_point,\n        source_dir=None,\n        predictor_cls=None,\n        env=None,\n        name=None,\n        enable_cloudwatch_metrics=False,\n        container_log_level=logging.INFO,\n        code_location=None,\n        sagemaker_session=None,\n        dependencies=None,\n        git_config=None,\n        **kwargs\n    ):\n        """"""Initialize a ``FrameworkModel``.\n\n        Args:\n            model_data (str): The S3 location of a SageMaker model data\n                ``.tar.gz`` file.\n            image (str): A Docker image URI.\n            role (str): An IAM role name or ARN for SageMaker to access AWS\n                resources on your behalf.\n            entry_point (str): Path (absolute or relative) to the Python source\n                file which should be executed as the entry point to model\n                hosting. If ``source_dir`` is specified, then ``entry_point``\n                must point to a file located at the root of ``source_dir``.\n                If \'git_config\' is provided, \'entry_point\' should be\n                a relative location to the Python source file in the Git repo.\n                Example:\n\n                    With the following GitHub repo directory structure:\n\n                    >>> |----- README.md\n                    >>> |----- src\n                    >>>         |----- inference.py\n                    >>>         |----- test.py\n\n                    You can assign entry_point=\'src/inference.py\'.\n            source_dir (str): Path (absolute, relative or an S3 URI) to a directory\n                with any other training source code dependencies aside from the entry\n                point file (default: None). If ``source_dir`` is an S3 URI, it must\n                point to a tar.gz file. Structure within this directory are preserved\n                when training on Amazon SageMaker. If \'git_config\' is provided,\n                \'source_dir\' should be a relative location to a directory in the Git repo.\n                If the directory points to S3, no code will be uploaded and the S3 location\n                will be used instead.\n                .. admonition:: Example\n\n                    With the following GitHub repo directory structure:\n\n                    >>> |----- README.md\n                    >>> |----- src\n                    >>>         |----- inference.py\n                    >>>         |----- test.py\n\n                    You can assign entry_point=\'inference.py\', source_dir=\'src\'.\n            predictor_cls (callable[string, sagemaker.session.Session]): A\n                function to call to create a predictor (default: None). If not\n                None, ``deploy`` will return the result of invoking this\n                function on the created endpoint name.\n            env (dict[str, str]): Environment variables to run with ``image``\n                when hosted in SageMaker (default: None).\n            name (str): The model name. If None, a default model name will be\n                selected on each ``deploy``.\n            enable_cloudwatch_metrics (bool): Whether training and hosting\n                containers will generate CloudWatch metrics under the\n                AWS/SageMakerContainer namespace (default: False).\n            container_log_level (int): Log level to use within the container\n                (default: logging.INFO). Valid values are defined in the Python\n                logging module.\n            code_location (str): Name of the S3 bucket where custom code is\n                uploaded (default: None). If not specified, default bucket\n                created by ``sagemaker.session.Session`` is used.\n            sagemaker_session (sagemaker.session.Session): A SageMaker Session\n                object, used for SageMaker interactions (default: None). If not\n                specified, one is created using the default AWS configuration\n                chain.\n            dependencies (list[str]): A list of paths to directories (absolute\n                or relative) with any additional libraries that will be exported\n                to the container (default: []). The library folders will be\n                copied to SageMaker in the same folder where the entrypoint is\n                copied. If \'git_config\' is provided, \'dependencies\' should be a\n                list of relative locations to directories with any additional\n                libraries needed in the Git repo. If the ```source_dir``` points\n                to S3, code will be uploaded and the S3 location will be used\n                instead. .. admonition:: Example\n\n                    The following call >>> Estimator(entry_point=\'inference.py\',\n                    dependencies=[\'my/libs/common\', \'virtual-env\']) results in\n                    the following inside the container:\n\n                    >>> $ ls\n\n                    >>> opt/ml/code\n                    >>>     |------ inference.py\n                    >>>     |------ common\n                    >>>     |------ virtual-env\n            git_config (dict[str, str]): Git configurations used for cloning\n                files, including ``repo``, ``branch``, ``commit``,\n                ``2FA_enabled``, ``username``, ``password`` and ``token``. The\n                ``repo`` field is required. All other fields are optional.\n                ``repo`` specifies the Git repository where your training script\n                is stored. If you don\'t provide ``branch``, the default value\n                \'master\' is used. If you don\'t provide ``commit``, the latest\n                commit in the specified branch is used. .. admonition:: Example\n\n                    The following config:\n\n                    >>> git_config = {\'repo\': \'https://github.com/aws/sagemaker-python-sdk.git\',\n                    >>>               \'branch\': \'test-branch-git-config\',\n                    >>>               \'commit\': \'329bfcf884482002c05ff7f44f62599ebc9f445a\'}\n\n                    results in cloning the repo specified in \'repo\', then\n                    checkout the \'master\' branch, and checkout the specified\n                    commit.\n\n                ``2FA_enabled``, ``username``, ``password`` and ``token`` are\n                used for authentication. For GitHub (or other Git) accounts, set\n                ``2FA_enabled`` to \'True\' if two-factor authentication is\n                enabled for the account, otherwise set it to \'False\'. If you do\n                not provide a value for ``2FA_enabled``, a default value of\n                \'False\' is used. CodeCommit does not support two-factor\n                authentication, so do not provide ""2FA_enabled"" with CodeCommit\n                repositories.\n\n                For GitHub and other Git repos, when SSH URLs are provided, it\n                doesn\'t matter whether 2FA is enabled or disabled; you should\n                either have no passphrase for the SSH key pairs, or have the\n                ssh-agent configured so that you will not be prompted for SSH\n                passphrase when you do \'git clone\' command with SSH URLs. When\n                HTTPS URLs are provided: if 2FA is disabled, then either token\n                or username+password will be used for authentication if provided\n                (token prioritized); if 2FA is enabled, only token will be used\n                for authentication if provided. If required authentication info\n                is not provided, python SDK will try to use local credentials\n                storage to authenticate. If that fails either, an error message\n                will be thrown.\n\n                For CodeCommit repos, 2FA is not supported, so \'2FA_enabled\'\n                should not be provided. There is no token in CodeCommit, so\n                \'token\' should not be provided too. When \'repo\' is an SSH URL,\n                the requirements are the same as GitHub-like repos. When \'repo\'\n                is an HTTPS URL, username+password will be used for\n                authentication if they are provided; otherwise, python SDK will\n                try to use either CodeCommit credential helper or local\n                credential storage for authentication.\n            **kwargs: Keyword arguments passed to the ``Model`` initializer.\n\n        .. tip::\n\n            You can find additional parameters for initializing this class at\n            :class:`~sagemaker.model.Model`.\n        """"""\n        super(FrameworkModel, self).__init__(\n            model_data,\n            image,\n            role,\n            predictor_cls=predictor_cls,\n            env=env,\n            name=name,\n            sagemaker_session=sagemaker_session,\n            **kwargs\n        )\n        self.entry_point = entry_point\n        self.source_dir = source_dir\n        self.dependencies = dependencies or []\n        self.git_config = git_config\n        self.enable_cloudwatch_metrics = enable_cloudwatch_metrics\n        self.container_log_level = container_log_level\n        if code_location:\n            self.bucket, self.key_prefix = fw_utils.parse_s3_url(code_location)\n        else:\n            self.bucket, self.key_prefix = None, None\n        if self.git_config:\n            updates = git_utils.git_clone_repo(\n                self.git_config, self.entry_point, self.source_dir, self.dependencies\n            )\n            self.entry_point = updates[""entry_point""]\n            self.source_dir = updates[""source_dir""]\n            self.dependencies = updates[""dependencies""]\n        self.uploaded_code = None\n        self.repacked_model_data = None\n\n    def prepare_container_def(\n        self, instance_type, accelerator_type=None\n    ):  # pylint disable=unused-argument\n        """"""Return a container definition with framework configuration set in\n        model environment variables.\n\n        This also uploads user-supplied code to S3.\n\n        Args:\n            instance_type (str): The EC2 instance type to deploy this Model to.\n                For example, \'ml.p2.xlarge\'.\n            accelerator_type (str): The Elastic Inference accelerator type to\n                deploy to the instance for loading and making inferences to the\n                model. For example, \'ml.eia1.medium\'.\n\n        Returns:\n            dict[str, str]: A container definition object usable with the\n            CreateModel API.\n        """"""\n        deploy_key_prefix = fw_utils.model_code_key_prefix(self.key_prefix, self.name, self.image)\n        self._upload_code(deploy_key_prefix)\n        deploy_env = dict(self.env)\n        deploy_env.update(self._framework_env_vars())\n        return sagemaker.container_def(self.image, self.model_data, deploy_env)\n\n    def _upload_code(self, key_prefix, repack=False):\n        """"""\n        Args:\n            key_prefix:\n            repack:\n        """"""\n        local_code = utils.get_config_value(""local.local_code"", self.sagemaker_session.config)\n        if self.sagemaker_session.local_mode and local_code:\n            self.uploaded_code = None\n        elif not repack:\n            bucket = self.bucket or self.sagemaker_session.default_bucket()\n            self.uploaded_code = fw_utils.tar_and_upload_dir(\n                session=self.sagemaker_session.boto_session,\n                bucket=bucket,\n                s3_key_prefix=key_prefix,\n                script=self.entry_point,\n                directory=self.source_dir,\n                dependencies=self.dependencies,\n            )\n\n        if repack:\n            bucket = self.bucket or self.sagemaker_session.default_bucket()\n            repacked_model_data = ""s3://"" + ""/"".join([bucket, key_prefix, ""model.tar.gz""])\n\n            utils.repack_model(\n                inference_script=self.entry_point,\n                source_directory=self.source_dir,\n                dependencies=self.dependencies,\n                model_uri=self.model_data,\n                repacked_model_uri=repacked_model_data,\n                sagemaker_session=self.sagemaker_session,\n                kms_key=self.model_kms_key,\n            )\n\n            self.repacked_model_data = repacked_model_data\n            self.uploaded_code = UploadedCode(\n                s3_prefix=self.repacked_model_data, script_name=os.path.basename(self.entry_point)\n            )\n\n    def _framework_env_vars(self):\n        """"""Placeholder docstring""""""\n        if self.uploaded_code:\n            script_name = self.uploaded_code.script_name\n            if self.enable_network_isolation():\n                dir_name = ""/opt/ml/model/code""\n            else:\n                dir_name = self.uploaded_code.s3_prefix\n        elif self.entry_point is not None:\n            script_name = self.entry_point\n            dir_name = ""file://"" + self.source_dir\n        else:\n            script_name = None\n            dir_name = None\n\n        return {\n            SCRIPT_PARAM_NAME.upper(): script_name,\n            DIR_PARAM_NAME.upper(): dir_name,\n            CLOUDWATCH_METRICS_PARAM_NAME.upper(): str(self.enable_cloudwatch_metrics).lower(),\n            CONTAINER_LOG_LEVEL_PARAM_NAME.upper(): str(self.container_log_level),\n            SAGEMAKER_REGION_PARAM_NAME.upper(): self.sagemaker_session.boto_region_name,\n        }\n\n\nclass ModelPackage(Model):\n    """"""A SageMaker ``Model`` that can be deployed to an ``Endpoint``.""""""\n\n    def __init__(self, role, model_data=None, algorithm_arn=None, model_package_arn=None, **kwargs):\n        """"""Initialize a SageMaker ModelPackage.\n\n        Args:\n            role (str): An AWS IAM role (either name or full ARN). The Amazon\n                SageMaker training jobs and APIs that create Amazon SageMaker\n                endpoints use this role to access training data and model\n                artifacts. After the endpoint is created, the inference code\n                might use the IAM role, if it needs to access an AWS resource.\n            model_data (str): The S3 location of a SageMaker model data\n                ``.tar.gz`` file. Must be provided if algorithm_arn is provided.\n            algorithm_arn (str): algorithm arn used to train the model, can be\n                just the name if your account owns the algorithm. Must also\n                provide ``model_data``.\n            model_package_arn (str): An existing SageMaker Model Package arn,\n                can be just the name if your account owns the Model Package.\n                ``model_data`` is not required.\n            **kwargs: Additional kwargs passed to the Model constructor.\n        """"""\n        super(ModelPackage, self).__init__(role=role, model_data=model_data, image=None, **kwargs)\n\n        if model_package_arn and algorithm_arn:\n            raise ValueError(\n                ""model_package_arn and algorithm_arn are mutually exclusive.""\n                ""Both were provided: model_package_arn: %s algorithm_arn: %s""\n                % (model_package_arn, algorithm_arn)\n            )\n\n        if model_package_arn is None and algorithm_arn is None:\n            raise ValueError(\n                ""either model_package_arn or algorithm_arn is required."" "" None was provided.""\n            )\n\n        self.algorithm_arn = algorithm_arn\n        if self.algorithm_arn is not None:\n            if model_data is None:\n                raise ValueError(""model_data must be provided with algorithm_arn"")\n            self.model_data = model_data\n\n        self.model_package_arn = model_package_arn\n        self._created_model_package_name = None\n\n    def _create_sagemaker_model_package(self):\n        """"""Placeholder docstring""""""\n        if self.algorithm_arn is None:\n            raise ValueError(""No algorithm_arn was provided to create a SageMaker Model Pacakge"")\n\n        name = self.name or utils.name_from_base(self.algorithm_arn.split(""/"")[-1])\n        description = ""Model Package created from training with %s"" % self.algorithm_arn\n        self.sagemaker_session.create_model_package_from_algorithm(\n            name, description, self.algorithm_arn, self.model_data\n        )\n        return name\n\n    def enable_network_isolation(self):\n        """"""Whether to enable network isolation when creating a model out of this\n        ModelPackage\n\n        Returns:\n            bool: If network isolation should be enabled or not.\n        """"""\n        return self._is_marketplace()\n\n    def _is_marketplace(self):\n        """"""Placeholder docstring""""""\n        model_package_name = self.model_package_arn or self._created_model_package_name\n        if model_package_name is None:\n            return True\n\n        # Models can lazy-init sagemaker_session until deploy() is called to support\n        # LocalMode so we must make sure we have an actual session to describe the model package.\n        sagemaker_session = self.sagemaker_session or sagemaker.Session()\n\n        model_package_desc = sagemaker_session.sagemaker_client.describe_model_package(\n            ModelPackageName=model_package_name\n        )\n        for container in model_package_desc[""InferenceSpecification""][""Containers""]:\n            if ""ProductId"" in container:\n                return True\n        return False\n\n    def _create_sagemaker_model(self, *args, **kwargs):  # pylint: disable=unused-argument\n        """"""Create a SageMaker Model Entity\n\n        Args:\n            args: Positional arguments coming from the caller. This class does not require\n                any so they are ignored.\n\n            kwargs: Keyword arguments coming from the caller. This class does not require\n                any so they are ignored.\n        """"""\n        if self.algorithm_arn:\n            # When ModelPackage is created using an algorithm_arn we need to first\n            # create a ModelPackage. If we had already created one then its fine to re-use it.\n            if self._created_model_package_name is None:\n                model_package_name = self._create_sagemaker_model_package()\n                self.sagemaker_session.wait_for_model_package(model_package_name)\n                self._created_model_package_name = model_package_name\n            model_package_name = self._created_model_package_name\n        else:\n            # When a ModelPackageArn is provided we just create the Model\n            model_package_name = self.model_package_arn\n\n        container_def = {""ModelPackageName"": model_package_name}\n\n        if self.env != {}:\n            container_def[""Environment""] = self.env\n\n        model_package_short_name = model_package_name.split(""/"")[-1]\n        enable_network_isolation = self.enable_network_isolation()\n        self.name = self.name or utils.name_from_base(model_package_short_name)\n        self.sagemaker_session.create_model(\n            self.name,\n            self.role,\n            container_def,\n            vpc_config=self.vpc_config,\n            enable_network_isolation=enable_network_isolation,\n        )\n'"
src/sagemaker/multidatamodel.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""This module contains code to create and manage SageMaker ``MultiDataModel``""""""\nfrom __future__ import absolute_import\n\nimport os\nfrom six.moves.urllib.parse import urlparse\n\nimport sagemaker\nfrom sagemaker import local, s3\nfrom sagemaker.model import Model\nfrom sagemaker.session import Session\n\nMULTI_MODEL_CONTAINER_MODE = ""MultiModel""\n\n\nclass MultiDataModel(Model):\n    """"""A SageMaker ``MultiDataModel`` that can be used to deploy multiple models to the same\n    SageMaker ``Endpoint``, and also deploy additional models to an existing SageMaker\n    multi-model ``Endpoint``\n    """"""\n\n    def __init__(\n        self,\n        name,\n        model_data_prefix,\n        model=None,\n        image=None,\n        role=None,\n        sagemaker_session=None,\n        **kwargs\n    ):\n        """"""Initialize a ``MultiDataModel``. In addition to these arguments, it supports all\n           arguments supported by ``Model`` constructor\n\n        Args:\n            name (str): The model name.\n            model_data_prefix (str): The S3 prefix where all the models artifacts (.tar.gz)\n                in a Multi-Model endpoint are located\n            model (sagemaker.Model): The Model object that would define the\n                SageMaker model attributes like vpc_config, predictors, etc.\n                If this is present, the attributes from this model are used when\n                deploying the ``MultiDataModel``.  Parameters \'image\', \'role\' and \'kwargs\'\n                are not permitted when model parameter is set.\n            image (str): A Docker image URI. It can be null if the \'model\' parameter\n                is passed to during ``MultiDataModel`` initialization (default: None)\n            role (str): An AWS IAM role (either name or full ARN). The Amazon\n                SageMaker training jobs and APIs that create Amazon SageMaker\n                endpoints use this role to access training data and model\n                artifacts. After the endpoint is created, the inference code\n                might use the IAM role if it needs to access some AWS resources.\n                It can be null if this is being used to create a Model to pass\n                to a ``PipelineModel`` which has its own Role field or if the \'model\' parameter\n                is passed to during ``MultiDataModel`` initialization (default: None)\n            sagemaker_session (sagemaker.session.Session): A SageMaker Session\n                object, used for SageMaker interactions (default: None). If not\n                specified, one is created using the default AWS configuration\n                chain.\n            **kwargs: Keyword arguments passed to the\n                :class:`~sagemaker.model.Model` initializer.\n\n        .. tip::\n\n            You can find additional parameters for initializing this class at\n            :class:`~sagemaker.model.Model`.\n        """"""\n        # Validate path\n        if not model_data_prefix.startswith(""s3://""):\n            raise ValueError(\n                \'Expecting S3 model prefix beginning with ""s3://"". Received: ""{}""\'.format(\n                    model_data_prefix\n                )\n            )\n\n        if model and (image or role or kwargs):\n            raise ValueError(\n                ""Parameters image, role or kwargs are not permitted when model parameter is passed.""\n            )\n\n        self.name = name\n        self.model_data_prefix = model_data_prefix\n        self.model = model\n        self.container_mode = MULTI_MODEL_CONTAINER_MODE\n        self.sagemaker_session = sagemaker_session or Session()\n\n        if self.sagemaker_session.s3_client is None:\n            self.s3_client = self.sagemaker_session.boto_session.client(\n                ""s3"", region_name=self.sagemaker_session.boto_session.region_name\n            )\n        else:\n            self.s3_client = self.sagemaker_session.s3_client\n\n        # Set the ``Model`` parameters if the model parameter is not specified\n        if not self.model:\n            super(MultiDataModel, self).__init__(\n                self.model_data_prefix,\n                image,\n                role,\n                name=self.name,\n                sagemaker_session=self.sagemaker_session,\n                **kwargs\n            )\n\n    def prepare_container_def(self, instance_type, accelerator_type=None):\n        """"""Return a container definition set with MultiModel mode,\n        model data and other parameters from the model (if available).\n\n        Subclasses can override this to provide custom container definitions\n        for deployment to a specific instance type. Called by ``deploy()``.\n\n        Returns:\n            dict[str, str]: A complete container definition object usable with the CreateModel API\n        """"""\n        # Copy the trained model\'s image and environment variables if they exist. Models trained\n        # with FrameworkEstimator set framework specific environment variables which need to be\n        # copied over\n        if self.model:\n            container_definition = self.model.prepare_container_def(instance_type, accelerator_type)\n            image = container_definition[""Image""]\n            environment = container_definition[""Environment""]\n        else:\n            image = self.image\n            environment = self.env\n        return sagemaker.container_def(\n            image,\n            env=environment,\n            model_data_url=self.model_data_prefix,\n            container_mode=self.container_mode,\n        )\n\n    def deploy(\n        self,\n        initial_instance_count,\n        instance_type,\n        accelerator_type=None,\n        endpoint_name=None,\n        update_endpoint=False,\n        tags=None,\n        kms_key=None,\n        wait=True,\n        data_capture_config=None,\n    ):\n        """"""Deploy this ``Model`` to an ``Endpoint`` and optionally return a ``Predictor``.\n\n        Create a SageMaker ``Model`` and ``EndpointConfig``, and deploy an\n        ``Endpoint`` from this ``Model``. If self.model is not None, then the ``Endpoint``\n        will be deployed with parameters in self.model (like vpc_config,\n        enable_network_isolation, etc).  If self.model is None, then use the parameters\n        in ``MultiDataModel`` constructor will be used. If ``self.predictor_cls`` is not\n        None, this method returns a the result of invoking ``self.predictor_cls`` on\n        the created endpoint name.\n\n        The name of the created model is accessible in the ``name`` field of\n        this ``Model`` after deploy returns\n\n        The name of the created endpoint is accessible in the\n        ``endpoint_name`` field of this ``Model`` after deploy returns.\n\n        Args:\n            initial_instance_count (int): The initial number of instances to run\n                in the ``Endpoint`` created from this ``Model``.\n            instance_type (str): The EC2 instance type to deploy this Model to.\n                For example, \'ml.p2.xlarge\', or \'local\' for local mode.\n            accelerator_type (str): Type of Elastic Inference accelerator to\n                deploy this model for model loading and inference, for example,\n                \'ml.eia1.medium\'. If not specified, no Elastic Inference\n                accelerator will be attached to the endpoint. For more\n                information:\n                https://docs.aws.amazon.com/sagemaker/latest/dg/ei.html\n            endpoint_name (str): The name of the endpoint to create (default:\n                None). If not specified, a unique endpoint name will be created.\n            update_endpoint (bool): Flag to update the model in an existing\n                Amazon SageMaker endpoint. If True, this will deploy a new\n                EndpointConfig to an already existing endpoint and delete\n                resources corresponding to the previous EndpointConfig. If\n                False, a new endpoint will be created. Default: False\n            tags (List[dict[str, str]]): The list of tags to attach to this\n                specific endpoint.\n            kms_key (str): The ARN of the KMS key that is used to encrypt the\n                data on the storage volume attached to the instance hosting the\n                endpoint.\n            wait (bool): Whether the call should wait until the deployment of\n                this model completes (default: True).\n            data_capture_config (sagemaker.model_monitor.DataCaptureConfig): Specifies\n                configuration related to Endpoint data capture for use with\n                Amazon SageMaker Model Monitoring. Default: None.\n\n        Returns:\n            callable[string, sagemaker.session.Session] or None: Invocation of\n                ``self.predictor_cls`` on the created endpoint name,\n                if ``self.predictor_cls``\n                is not None. Otherwise, return None.\n        """"""\n        # Set model specific parameters\n        if self.model:\n            enable_network_isolation = self.model.enable_network_isolation()\n            role = self.model.role\n            vpc_config = self.model.vpc_config\n            predictor = self.model.predictor_cls\n        else:\n            enable_network_isolation = self.enable_network_isolation()\n            role = self.role\n            vpc_config = self.vpc_config\n            predictor = self.predictor_cls\n\n        if role is None:\n            raise ValueError(""Role can not be null for deploying a model"")\n\n        if instance_type == ""local"" and not isinstance(self.sagemaker_session, local.LocalSession):\n            self.sagemaker_session = local.LocalSession()\n\n        container_def = self.prepare_container_def(instance_type, accelerator_type=accelerator_type)\n        self.sagemaker_session.create_model(\n            self.name,\n            role,\n            container_def,\n            vpc_config=vpc_config,\n            enable_network_isolation=enable_network_isolation,\n            tags=tags,\n        )\n\n        production_variant = sagemaker.production_variant(\n            self.name, instance_type, initial_instance_count, accelerator_type=accelerator_type\n        )\n        if endpoint_name:\n            self.endpoint_name = endpoint_name\n        else:\n            self.endpoint_name = self.name\n\n        data_capture_config_dict = None\n        if data_capture_config is not None:\n            data_capture_config_dict = data_capture_config._to_request_dict()\n\n        if update_endpoint:\n            endpoint_config_name = self.sagemaker_session.create_endpoint_config(\n                name=self.name,\n                model_name=self.name,\n                initial_instance_count=initial_instance_count,\n                instance_type=instance_type,\n                accelerator_type=accelerator_type,\n                tags=tags,\n                kms_key=kms_key,\n                data_capture_config_dict=data_capture_config_dict,\n            )\n            self.sagemaker_session.update_endpoint(\n                self.endpoint_name, endpoint_config_name, wait=wait\n            )\n        else:\n            self.sagemaker_session.endpoint_from_production_variants(\n                name=self.endpoint_name,\n                production_variants=[production_variant],\n                tags=tags,\n                kms_key=kms_key,\n                wait=wait,\n                data_capture_config_dict=data_capture_config_dict,\n            )\n\n        if predictor:\n            return predictor(self.endpoint_name, self.sagemaker_session)\n        return None\n\n    def add_model(self, model_data_source, model_data_path=None):\n        """"""Adds a model to the ``MultiDataModel`` by uploading or copying the model_data_source\n         artifact to the given S3 path model_data_path relative to model_data_prefix\n\n        Args:\n            model_source: Valid local file path or S3 path of the trained model artifact\n            model_data_path: S3 path where the trained model artifact\n                should be uploaded relative to ``self.model_data_prefix`` path. (default: None).\n                If None, then the model artifact is uploaded to a path relative to model_data_prefix\n\n        Returns:\n            str: S3 uri to uploaded model artifact\n        """"""\n        parse_result = urlparse(model_data_source)\n\n        # If the model source is an S3 path, copy the model artifact to the destination S3 path\n        if parse_result.scheme == ""s3"":\n            source_bucket, source_model_data_path = s3.parse_s3_url(model_data_source)\n            copy_source = {""Bucket"": source_bucket, ""Key"": source_model_data_path}\n\n            if not model_data_path:\n                model_data_path = source_model_data_path\n\n            # Construct the destination path\n            dst_url = os.path.join(self.model_data_prefix, model_data_path)\n            destination_bucket, destination_model_data_path = s3.parse_s3_url(dst_url)\n\n            # Copy the model artifact\n            self.s3_client.copy(copy_source, destination_bucket, destination_model_data_path)\n            return os.path.join(""s3://"", destination_bucket, destination_model_data_path)\n\n        # If the model source is a local path, upload the local model artifact to the destination\n        #  s3 path\n        if os.path.exists(model_data_source):\n            destination_bucket, dst_prefix = s3.parse_s3_url(self.model_data_prefix)\n            if model_data_path:\n                dst_s3_uri = os.path.join(dst_prefix, model_data_path)\n            else:\n                dst_s3_uri = os.path.join(dst_prefix, os.path.basename(model_data_source))\n            self.s3_client.upload_file(model_data_source, destination_bucket, dst_s3_uri)\n            # return upload_path\n            return os.path.join(""s3://"", destination_bucket, dst_s3_uri)\n\n        # Raise error if the model source is of an unexpected type\n        raise ValueError(\n            ""model_source must either be a valid local file path or s3 uri. Received: ""\n            \'""{}""\'.format(model_data_source)\n        )\n\n    def list_models(self):\n        """"""Generates and returns relative paths to model archives stored at model_data_prefix\n        S3 location.\n\n        Yields: Paths to model archives relative to model_data_prefix path.\n        """"""\n        bucket, url_prefix = s3.parse_s3_url(self.model_data_prefix)\n        file_keys = self.sagemaker_session.list_s3_files(bucket=bucket, key_prefix=url_prefix)\n        for file_key in file_keys:\n            # Return the model paths relative to the model_data_prefix\n            # Ex: ""a/b/c.tar.gz"" -> ""b/c.tar.gz"" where url_prefix = ""a/""\n            yield file_key.replace(url_prefix, """")\n'"
src/sagemaker/network.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""This file contains code related to network configuration, including\nencryption, network isolation, and VPC configurations.\n""""""\nfrom __future__ import absolute_import\n\n\nclass NetworkConfig(object):\n    """"""Accepts network configuration parameters and provides a method to turn these parameters\n    into a dictionary.""""""\n\n    def __init__(\n        self,\n        enable_network_isolation=False,\n        security_group_ids=None,\n        subnets=None,\n        encrypt_inter_container_traffic=None,\n    ):\n        """"""Initialize a ``NetworkConfig`` instance. NetworkConfig accepts network configuration\n        parameters and provides a method to turn these parameters into a dictionary.\n\n        Args:\n            enable_network_isolation (bool): Boolean that determines whether to enable\n                network isolation.\n            security_group_ids ([str]): A list of strings representing security group IDs.\n            subnets ([str]): A list of strings representing subnets.\n            encrypt_inter_container_traffic (bool): Boolean that determines whether to\n                encrypt inter-container traffic. Default value is None.\n        """"""\n        self.enable_network_isolation = enable_network_isolation\n        self.security_group_ids = security_group_ids\n        self.subnets = subnets\n        self.encrypt_inter_container_traffic = encrypt_inter_container_traffic\n\n    def _to_request_dict(self):\n        """"""Generates a request dictionary using the parameters provided to the class.""""""\n        network_config_request = {""EnableNetworkIsolation"": self.enable_network_isolation}\n\n        if self.encrypt_inter_container_traffic is not None:\n            network_config_request[\n                ""EnableInterContainerTrafficEncryption""\n            ] = self.encrypt_inter_container_traffic\n\n        if self.security_group_ids is not None or self.subnets is not None:\n            network_config_request[""VpcConfig""] = {}\n\n        if self.security_group_ids is not None:\n            network_config_request[""VpcConfig""][""SecurityGroupIds""] = self.security_group_ids\n\n        if self.subnets is not None:\n            network_config_request[""VpcConfig""][""Subnets""] = self.subnets\n\n        return network_config_request\n'"
src/sagemaker/parameter.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\nimport json\n\nfrom sagemaker.utils import to_str\n\n\nclass ParameterRange(object):\n    """"""Base class for representing parameter ranges. This is used to define what\n    hyperparameters to tune for an Amazon SageMaker hyperparameter tuning job\n    and to verify hyperparameters for Marketplace Algorithms.\n    """"""\n\n    __all_types__ = (""Continuous"", ""Categorical"", ""Integer"")\n\n    def __init__(self, min_value, max_value, scaling_type=""Auto""):\n        """"""Initialize a parameter range.\n\n        Args:\n            min_value (float or int): The minimum value for the range.\n            max_value (float or int): The maximum value for the range.\n            scaling_type (str): The scale used for searching the range during\n                tuning (default: \'Auto\'). Valid values: \'Auto\', \'Linear\',\n                \'Logarithmic\' and \'ReverseLogarithmic\'.\n        """"""\n        self.min_value = min_value\n        self.max_value = max_value\n        self.scaling_type = scaling_type\n\n    def is_valid(self, value):\n        """"""Determine if a value is valid within this ParameterRange.\n\n        Args:\n            value (float or int): The value to be verified.\n\n        Returns:\n            bool: True if valid, False otherwise.\n        """"""\n        return self.min_value <= value <= self.max_value\n\n    @classmethod\n    def cast_to_type(cls, value):\n        """"""\n        Args:\n            value:\n        """"""\n        return float(value)\n\n    def as_tuning_range(self, name):\n        """"""Represent the parameter range as a dicionary suitable for a request\n        to create an Amazon SageMaker hyperparameter tuning job.\n\n        Args:\n            name (str): The name of the hyperparameter.\n\n        Returns:\n            dict[str, str]: A dictionary that contains the name and values of\n            the hyperparameter.\n        """"""\n        return {\n            ""Name"": name,\n            ""MinValue"": to_str(self.min_value),\n            ""MaxValue"": to_str(self.max_value),\n            ""ScalingType"": self.scaling_type,\n        }\n\n\nclass ContinuousParameter(ParameterRange):\n    """"""A class for representing hyperparameters that have a continuous range of possible values.\n\n    Args:\n            min_value (float): The minimum value for the range.\n            max_value (float): The maximum value for the range.\n    """"""\n\n    __name__ = ""Continuous""\n\n    @classmethod\n    def cast_to_type(cls, value):\n        """"""\n        Args:\n            value:\n        """"""\n        return float(value)\n\n\nclass CategoricalParameter(ParameterRange):\n    """"""A class for representing hyperparameters that have a discrete list of\n    possible values.\n    """"""\n\n    __name__ = ""Categorical""\n\n    def __init__(self, values):  # pylint: disable=super-init-not-called\n        """"""Initialize a ``CategoricalParameter``.\n\n        Args:\n            values (list or object): The possible values for the hyperparameter.\n                This input will be converted into a list of strings.\n        """"""\n        if isinstance(values, list):\n            self.values = [to_str(v) for v in values]\n        else:\n            self.values = [to_str(values)]\n\n    def as_tuning_range(self, name):\n        """"""Represent the parameter range as a dicionary suitable for a request\n        to create an Amazon SageMaker hyperparameter tuning job.\n\n        Args:\n            name (str): The name of the hyperparameter.\n\n        Returns:\n            dict[str, list[str]]: A dictionary that contains the name and values\n            of the hyperparameter.\n        """"""\n        return {""Name"": name, ""Values"": self.values}\n\n    def as_json_range(self, name):\n        """"""Represent the parameter range as a dictionary suitable for a request\n        to create an Amazon SageMaker hyperparameter tuning job using one of the\n        deep learning frameworks.\n\n        The deep learning framework images require that hyperparameters be\n        serialized as JSON.\n\n        Args:\n            name (str): The name of the hyperparameter.\n\n        Returns:\n            dict[str, list[str]]: A dictionary that contains the name and values of the\n            hyperparameter, where the values are serialized as JSON.\n        """"""\n        return {""Name"": name, ""Values"": [json.dumps(v) for v in self.values]}\n\n    def is_valid(self, value):\n        """"""\n        Args:\n            value:\n        """"""\n        return value in self.values\n\n    @classmethod\n    def cast_to_type(cls, value):\n        """"""\n        Args:\n            value:\n        """"""\n        return to_str(value)\n\n\nclass IntegerParameter(ParameterRange):\n    """"""A class for representing hyperparameters that have an integer range of possible values.\n        Args:\n            min_value (int): The minimum value for the range.\n            max_value (int): The maximum value for the range.\n    """"""\n\n    __name__ = ""Integer""\n\n    @classmethod\n    def cast_to_type(cls, value):\n        """"""\n        Args:\n            value:\n        """"""\n        return int(value)\n'"
src/sagemaker/pipeline.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nimport sagemaker\nfrom sagemaker.session import Session\nfrom sagemaker.utils import name_from_image\nfrom sagemaker.transformer import Transformer\n\n\nclass PipelineModel(object):\n    """"""A pipeline of SageMaker\n    ``Model``s that can be deployed to an ``Endpoint``.\n    """"""\n\n    def __init__(\n        self, models, role, predictor_cls=None, name=None, vpc_config=None, sagemaker_session=None\n    ):\n        """"""Initialize an SageMaker ``Model`` which can be used to build an\n        Inference Pipeline comprising of multiple model containers.\n\n        Args:\n            models (list[sagemaker.Model]): For using multiple containers to\n                build an inference pipeline, you can pass a list of ``sagemaker.Model`` objects\n                in the order you want the inference to happen.\n            role (str): An AWS IAM role (either name or full ARN). The Amazon\n                SageMaker training jobs and APIs that create Amazon SageMaker\n                endpoints use this role to access training data and model\n                artifacts. After the endpoint is created, the inference code\n                might use the IAM role, if it needs to access an AWS resource.\n            predictor_cls (callable[string, sagemaker.session.Session]): A\n                function to call to create a predictor (default: None). If not\n                None, ``deploy`` will return the result of invoking this\n                function on the created endpoint name.\n            name (str): The model name. If None, a default model name will be\n                selected on each ``deploy``.\n            vpc_config (dict[str, list[str]]): The VpcConfig set on the model\n                (default: None)\n                * \'Subnets\' (list[str]): List of subnet ids.\n                * \'SecurityGroupIds\' (list[str]): List of security group ids.\n            sagemaker_session (sagemaker.session.Session): A SageMaker Session\n                object, used for SageMaker interactions (default: None). If not\n                specified, one is created using the default AWS configuration\n                chain.\n        """"""\n        self.models = models\n        self.role = role\n        self.predictor_cls = predictor_cls\n        self.name = name\n        self.vpc_config = vpc_config\n        self.sagemaker_session = sagemaker_session\n        self._model_name = None\n        self.endpoint_name = None\n\n    def pipeline_container_def(self, instance_type):\n        """"""Return a dict created by ``sagemaker.pipeline_container_def()`` for\n        deploying this model to a specified instance type.\n\n        Subclasses can override this to provide custom container definitions\n        for deployment to a specific instance type. Called by ``deploy()``.\n\n        Args:\n            instance_type (str): The EC2 instance type to deploy this Model to.\n                For example, \'ml.p2.xlarge\'.\n\n        Returns:\n            list[dict[str, str]]: A list of container definition objects usable\n            with the CreateModel API in the scenario of multiple containers\n            (Inference Pipeline).\n        """"""\n\n        return sagemaker.pipeline_container_def(self.models, instance_type)\n\n    def deploy(\n        self,\n        initial_instance_count,\n        instance_type,\n        endpoint_name=None,\n        tags=None,\n        wait=True,\n        update_endpoint=False,\n        data_capture_config=None,\n    ):\n        """"""Deploy this ``Model`` to an ``Endpoint`` and optionally return a\n        ``Predictor``.\n\n        Create a SageMaker ``Model`` and ``EndpointConfig``, and deploy an\n        ``Endpoint`` from this ``Model``. If ``self.predictor_cls`` is not None,\n        this method returns a the result of invoking ``self.predictor_cls`` on\n        the created endpoint name.\n\n        The name of the created model is accessible in the ``name`` field of\n        this ``Model`` after deploy returns\n\n        The name of the created endpoint is accessible in the\n        ``endpoint_name`` field of this ``Model`` after deploy returns.\n\n        Args:\n            initial_instance_count (int): The initial number of instances to run\n                in the ``Endpoint`` created from this ``Model``.\n            instance_type (str): The EC2 instance type to deploy this Model to.\n                For example, \'ml.p2.xlarge\'.\n            endpoint_name (str): The name of the endpoint to create (default:\n                None). If not specified, a unique endpoint name will be created.\n            tags (List[dict[str, str]]): The list of tags to attach to this\n                specific endpoint.\n            wait (bool): Whether the call should wait until the deployment of\n                model completes (default: True).\n            update_endpoint (bool): Flag to update the model in an existing\n                Amazon SageMaker endpoint. If True, this will deploy a new\n                EndpointConfig to an already existing endpoint and delete\n                resources corresponding to the previous EndpointConfig. If\n                False, a new endpoint will be created. Default: False\n            data_capture_config (sagemaker.model_monitor.DataCaptureConfig): Specifies\n                configuration related to Endpoint data capture for use with\n                Amazon SageMaker Model Monitoring. Default: None.\n\n        Returns:\n            callable[string, sagemaker.session.Session] or None: Invocation of\n            ``self.predictor_cls`` on the created endpoint name, if ``self.predictor_cls``\n            is not None. Otherwise, return None.\n        """"""\n        if not self.sagemaker_session:\n            self.sagemaker_session = Session()\n\n        containers = self.pipeline_container_def(instance_type)\n\n        self.name = self.name or name_from_image(containers[0][""Image""])\n        self.sagemaker_session.create_model(\n            self.name, self.role, containers, vpc_config=self.vpc_config\n        )\n\n        production_variant = sagemaker.production_variant(\n            self.name, instance_type, initial_instance_count\n        )\n        self.endpoint_name = endpoint_name or self.name\n\n        data_capture_config_dict = None\n        if data_capture_config is not None:\n            data_capture_config_dict = data_capture_config._to_request_dict()\n\n        if update_endpoint:\n            endpoint_config_name = self.sagemaker_session.create_endpoint_config(\n                name=self.name,\n                model_name=self.name,\n                initial_instance_count=initial_instance_count,\n                instance_type=instance_type,\n                tags=tags,\n                data_capture_config_dict=data_capture_config_dict,\n            )\n            self.sagemaker_session.update_endpoint(\n                self.endpoint_name, endpoint_config_name, wait=wait\n            )\n        else:\n            self.sagemaker_session.endpoint_from_production_variants(\n                name=self.endpoint_name,\n                production_variants=[production_variant],\n                tags=tags,\n                wait=wait,\n                data_capture_config_dict=data_capture_config_dict,\n            )\n\n        if self.predictor_cls:\n            return self.predictor_cls(self.endpoint_name, self.sagemaker_session)\n        return None\n\n    def _create_sagemaker_pipeline_model(self, instance_type):\n        """"""Create a SageMaker Model Entity\n\n        Args:\n            instance_type (str): The EC2 instance type that this Model will be\n                used for, this is only used to determine if the image needs GPU\n                support or not.\n        """"""\n        if not self.sagemaker_session:\n            self.sagemaker_session = Session()\n\n        containers = self.pipeline_container_def(instance_type)\n\n        self.name = self.name or name_from_image(containers[0][""Image""])\n        self.sagemaker_session.create_model(\n            self.name, self.role, containers, vpc_config=self.vpc_config\n        )\n\n    def transformer(\n        self,\n        instance_count,\n        instance_type,\n        strategy=None,\n        assemble_with=None,\n        output_path=None,\n        output_kms_key=None,\n        accept=None,\n        env=None,\n        max_concurrent_transforms=None,\n        max_payload=None,\n        tags=None,\n        volume_kms_key=None,\n    ):\n        """"""Return a ``Transformer`` that uses this Model.\n\n        Args:\n            instance_count (int): Number of EC2 instances to use.\n            instance_type (str): Type of EC2 instance to use, for example,\n                \'ml.c4.xlarge\'.\n            strategy (str): The strategy used to decide how to batch records in\n                a single request (default: None). Valid values: \'MultiRecord\'\n                and \'SingleRecord\'.\n            assemble_with (str): How the output is assembled (default: None).\n                Valid values: \'Line\' or \'None\'.\n            output_path (str): S3 location for saving the transform result. If\n                not specified, results are stored to a default bucket.\n            output_kms_key (str): Optional. KMS key ID for encrypting the\n                transform output (default: None).\n            accept (str): The accept header passed by the client to\n                the inference endpoint. If it is supported by the endpoint,\n                it will be the format of the batch transform output.\n            env (dict): Environment variables to be set for use during the\n                transform job (default: None).\n            max_concurrent_transforms (int): The maximum number of HTTP requests\n                to be made to each individual transform container at one time.\n            max_payload (int): Maximum size of the payload in a single HTTP\n                request to the container in MB.\n            tags (list[dict]): List of tags for labeling a transform job. If\n                none specified, then the tags used for the training job are used\n                for the transform job.\n            volume_kms_key (str): Optional. KMS key ID for encrypting the volume\n                attached to the ML compute instance (default: None).\n        """"""\n        self._create_sagemaker_pipeline_model(instance_type)\n\n        return Transformer(\n            self.name,\n            instance_count,\n            instance_type,\n            strategy=strategy,\n            assemble_with=assemble_with,\n            output_path=output_path,\n            output_kms_key=output_kms_key,\n            accept=accept,\n            max_concurrent_transforms=max_concurrent_transforms,\n            max_payload=max_payload,\n            env=env,\n            tags=tags,\n            base_transform_job_name=self.name,\n            volume_kms_key=volume_kms_key,\n            sagemaker_session=self.sagemaker_session,\n        )\n\n    def delete_model(self):\n        """"""Delete the SageMaker model backing this pipeline model. This does not\n        delete the list of SageMaker models used in multiple containers to build\n        the inference pipeline.\n        """"""\n\n        if self.name is None:\n            raise ValueError(""The SageMaker model must be created before attempting to delete."")\n\n        self.sagemaker_session.delete_model(self.name)\n'"
src/sagemaker/predictor.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import print_function, absolute_import\n\nimport codecs\nimport csv\nimport json\nimport six\nfrom six import StringIO, BytesIO\nimport numpy as np\n\nfrom sagemaker.content_types import CONTENT_TYPE_JSON, CONTENT_TYPE_CSV, CONTENT_TYPE_NPY\nfrom sagemaker.model_monitor import DataCaptureConfig\nfrom sagemaker.session import Session\nfrom sagemaker.utils import name_from_base\n\nfrom sagemaker.model_monitor.model_monitoring import (\n    _DEFAULT_MONITOR_IMAGE_URI_WITH_PLACEHOLDERS,\n    ModelMonitor,\n    DefaultModelMonitor,\n)\n\n\nclass RealTimePredictor(object):\n    """"""Make prediction requests to an Amazon SageMaker endpoint.""""""\n\n    def __init__(\n        self,\n        endpoint,\n        sagemaker_session=None,\n        serializer=None,\n        deserializer=None,\n        content_type=None,\n        accept=None,\n    ):\n        """"""Initialize a ``RealTimePredictor``.\n\n        Behavior for serialization of input data and deserialization of\n        result data can be configured through initializer arguments. If not\n        specified, a sequence of bytes is expected and the API sends it in the\n        request body without modifications. In response, the API returns the\n        sequence of bytes from the prediction result without any modifications.\n\n        Args:\n            endpoint (str): Name of the Amazon SageMaker endpoint to which\n                requests are sent.\n            sagemaker_session (sagemaker.session.Session): A SageMaker Session\n                object, used for SageMaker interactions (default: None). If not\n                specified, one is created using the default AWS configuration\n                chain.\n            serializer (callable): Accepts a single argument, the input data,\n                and returns a sequence of bytes. It may provide a\n                ``content_type`` attribute that defines the endpoint request\n                content type. If not specified, a sequence of bytes is expected\n                for the data.\n            deserializer (callable): Accepts two arguments, the result data and\n                the response content type, and returns a sequence of bytes. It\n                may provide a ``content_type`` attribute that defines the\n                endpoint response\'s ""Accept"" content type. If not specified, a\n                sequence of bytes is expected for the data.\n            content_type (str): The invocation\'s ""ContentType"", overriding any\n                ``content_type`` from the serializer (default: None).\n            accept (str): The invocation\'s ""Accept"", overriding any accept from\n                the deserializer (default: None).\n        """"""\n        self.endpoint = endpoint\n        self.sagemaker_session = sagemaker_session or Session()\n        self.serializer = serializer\n        self.deserializer = deserializer\n        self.content_type = content_type or getattr(serializer, ""content_type"", None)\n        self.accept = accept or getattr(deserializer, ""accept"", None)\n        self._endpoint_config_name = self._get_endpoint_config_name()\n        self._model_names = self._get_model_names()\n\n    def predict(self, data, initial_args=None, target_model=None):\n        """"""Return the inference from the specified endpoint.\n\n        Args:\n            data (object): Input data for which you want the model to provide\n                inference. If a serializer was specified when creating the\n                RealTimePredictor, the result of the serializer is sent as input\n                data. Otherwise the data must be sequence of bytes, and the\n                predict method then sends the bytes in the request body as is.\n            initial_args (dict[str,str]): Optional. Default arguments for boto3\n                ``invoke_endpoint`` call. Default is None (no default\n                arguments).\n            target_model (str): S3 model artifact path to run an inference request on,\n                in case of a multi model endpoint. Does not apply to endpoints hosting\n                single model (Default: None)\n\n        Returns:\n            object: Inference for the given input. If a deserializer was specified when creating\n                the RealTimePredictor, the result of the deserializer is\n                returned. Otherwise the response returns the sequence of bytes\n                as is.\n        """"""\n\n        request_args = self._create_request_args(data, initial_args, target_model)\n        response = self.sagemaker_session.sagemaker_runtime_client.invoke_endpoint(**request_args)\n        return self._handle_response(response)\n\n    def _handle_response(self, response):\n        """"""\n        Args:\n            response:\n        """"""\n        response_body = response[""Body""]\n        if self.deserializer is not None:\n            # It\'s the deserializer\'s responsibility to close the stream\n            return self.deserializer(response_body, response[""ContentType""])\n        data = response_body.read()\n        response_body.close()\n        return data\n\n    def _create_request_args(self, data, initial_args=None, target_model=None):\n        """"""\n        Args:\n            data:\n            initial_args:\n            target_model:\n        """"""\n        args = dict(initial_args) if initial_args else {}\n\n        if ""EndpointName"" not in args:\n            args[""EndpointName""] = self.endpoint\n\n        if self.content_type and ""ContentType"" not in args:\n            args[""ContentType""] = self.content_type\n\n        if self.accept and ""Accept"" not in args:\n            args[""Accept""] = self.accept\n\n        if target_model:\n            args[""TargetModel""] = target_model\n\n        if self.serializer is not None:\n            data = self.serializer(data)\n\n        args[""Body""] = data\n        return args\n\n    def _delete_endpoint_config(self):\n        """"""Delete the Amazon SageMaker endpoint configuration""""""\n        self.sagemaker_session.delete_endpoint_config(self._endpoint_config_name)\n\n    def delete_endpoint(self, delete_endpoint_config=True):\n        """"""Delete the Amazon SageMaker endpoint backing this predictor. Also\n        delete the endpoint configuration attached to it if\n        delete_endpoint_config is True.\n\n        Args:\n            delete_endpoint_config (bool, optional): Flag to indicate whether to\n                delete endpoint configuration together with endpoint. Defaults\n                to True. If True, both endpoint and endpoint configuration will\n                be deleted. If False, only endpoint will be deleted.\n        """"""\n        if delete_endpoint_config:\n            self._delete_endpoint_config()\n\n        self.sagemaker_session.delete_endpoint(self.endpoint)\n\n    def delete_model(self):\n        """"""Deletes the Amazon SageMaker models backing this predictor.""""""\n        request_failed = False\n        failed_models = []\n        for model_name in self._model_names:\n            try:\n                self.sagemaker_session.delete_model(model_name)\n            except Exception:  # pylint: disable=broad-except\n                request_failed = True\n                failed_models.append(model_name)\n\n        if request_failed:\n            raise Exception(\n                ""One or more models cannot be deleted, please retry. \\n""\n                ""Failed models: {}"".format("", "".join(failed_models))\n            )\n\n    def enable_data_capture(self):\n        """"""Updates the DataCaptureConfig for the Predictor\'s associated Amazon SageMaker Endpoint\n        to enable data capture. For a more customized experience, refer to\n        update_data_capture_config, instead.\n        """"""\n        self.update_data_capture_config(\n            data_capture_config=DataCaptureConfig(\n                enable_capture=True, sagemaker_session=self.sagemaker_session\n            )\n        )\n\n    def disable_data_capture(self):\n        """"""Updates the DataCaptureConfig for the Predictor\'s associated Amazon SageMaker Endpoint\n        to disable data capture. For a more customized experience, refer to\n        update_data_capture_config, instead.\n        """"""\n        self.update_data_capture_config(\n            data_capture_config=DataCaptureConfig(\n                enable_capture=False, sagemaker_session=self.sagemaker_session\n            )\n        )\n\n    def update_data_capture_config(self, data_capture_config):\n        """"""Updates the DataCaptureConfig for the Predictor\'s associated Amazon SageMaker Endpoint\n        with the provided DataCaptureConfig.\n\n        Args:\n            data_capture_config (sagemaker.model_monitor.DataCaptureConfig): The\n                DataCaptureConfig to update the predictor\'s endpoint to use.\n        """"""\n        endpoint_desc = self.sagemaker_session.sagemaker_client.describe_endpoint(\n            EndpointName=self.endpoint\n        )\n\n        new_config_name = name_from_base(base=self.endpoint)\n\n        data_capture_config_dict = None\n        if data_capture_config is not None:\n            data_capture_config_dict = data_capture_config._to_request_dict()\n\n        self.sagemaker_session.create_endpoint_config_from_existing(\n            existing_config_name=endpoint_desc[""EndpointConfigName""],\n            new_config_name=new_config_name,\n            new_data_capture_config_dict=data_capture_config_dict,\n        )\n\n        self.sagemaker_session.update_endpoint(\n            endpoint_name=self.endpoint, endpoint_config_name=new_config_name\n        )\n\n    def list_monitors(self):\n        """"""Generates ModelMonitor objects (or DefaultModelMonitors) based on the schedule(s)\n        associated with the endpoint that this predictor refers to.\n\n        Returns:\n            [sagemaker.model_monitor.model_monitoring.ModelMonitor]: A list of\n                ModelMonitor (or DefaultModelMonitor) objects.\n\n        """"""\n        monitoring_schedules_dict = self.sagemaker_session.list_monitoring_schedules(\n            endpoint_name=self.endpoint\n        )\n        if len(monitoring_schedules_dict[""MonitoringScheduleSummaries""]) == 0:\n            print(""No monitors found for endpoint. endpoint: {}"".format(self.endpoint))\n            return []\n\n        monitors = []\n        for schedule_dict in monitoring_schedules_dict[""MonitoringScheduleSummaries""]:\n            schedule_name = schedule_dict[""MonitoringScheduleName""]\n            schedule = self.sagemaker_session.describe_monitoring_schedule(\n                monitoring_schedule_name=schedule_name\n            )\n            image_uri = schedule[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n                ""MonitoringAppSpecification""\n            ][""ImageUri""]\n            index_after_placeholders = _DEFAULT_MONITOR_IMAGE_URI_WITH_PLACEHOLDERS.rfind(""{}"")\n            if image_uri.endswith(\n                _DEFAULT_MONITOR_IMAGE_URI_WITH_PLACEHOLDERS[index_after_placeholders + len(""{}"") :]\n            ):\n                monitors.append(\n                    DefaultModelMonitor.attach(\n                        monitor_schedule_name=schedule_name,\n                        sagemaker_session=self.sagemaker_session,\n                    )\n                )\n            else:\n                monitors.append(\n                    ModelMonitor.attach(\n                        monitor_schedule_name=schedule_name,\n                        sagemaker_session=self.sagemaker_session,\n                    )\n                )\n\n        return monitors\n\n    def _get_endpoint_config_name(self):\n        """"""Placeholder docstring""""""\n        endpoint_desc = self.sagemaker_session.sagemaker_client.describe_endpoint(\n            EndpointName=self.endpoint\n        )\n        endpoint_config_name = endpoint_desc[""EndpointConfigName""]\n        return endpoint_config_name\n\n    def _get_model_names(self):\n        """"""Placeholder docstring""""""\n        endpoint_config = self.sagemaker_session.sagemaker_client.describe_endpoint_config(\n            EndpointConfigName=self._endpoint_config_name\n        )\n        production_variants = endpoint_config[""ProductionVariants""]\n        return map(lambda d: d[""ModelName""], production_variants)\n\n\nclass _CsvSerializer(object):\n    """"""Placeholder docstring""""""\n\n    def __init__(self):\n        """"""Placeholder docstring""""""\n        self.content_type = CONTENT_TYPE_CSV\n\n    def __call__(self, data):\n        """"""Take data of various data formats and serialize them into CSV.\n\n        Args:\n            data (object): Data to be serialized.\n\n        Returns:\n            object: Sequence of bytes to be used for the request body.\n        """"""\n        # For inputs which represent multiple ""rows"", the result should be newline-separated CSV\n        # rows\n        if _is_mutable_sequence_like(data) and len(data) > 0 and _is_sequence_like(data[0]):\n            return ""\\n"".join([_CsvSerializer._serialize_row(row) for row in data])\n        return _CsvSerializer._serialize_row(data)\n\n    @staticmethod\n    def _serialize_row(data):\n        # Don\'t attempt to re-serialize a string\n        """"""\n        Args:\n            data:\n        """"""\n        if isinstance(data, str):\n            return data\n        if isinstance(data, np.ndarray):\n            data = np.ndarray.flatten(data)\n        if hasattr(data, ""__len__""):\n            if len(data) == 0:\n                raise ValueError(""Cannot serialize empty array"")\n            return _csv_serialize_python_array(data)\n\n        # files and buffers\n        if hasattr(data, ""read""):\n            return _csv_serialize_from_buffer(data)\n\n        raise ValueError(""Unable to handle input format: "", type(data))\n\n\ndef _csv_serialize_python_array(data):\n    """"""\n    Args:\n        data:\n    """"""\n    return _csv_serialize_object(data)\n\n\ndef _csv_serialize_from_buffer(buff):\n    """"""\n    Args:\n        buff:\n    """"""\n    return buff.read()\n\n\ndef _csv_serialize_object(data):\n    """"""\n    Args:\n        data:\n    """"""\n    csv_buffer = StringIO()\n\n    csv_writer = csv.writer(csv_buffer, delimiter="","")\n    csv_writer.writerow(data)\n    return csv_buffer.getvalue().rstrip(""\\r\\n"")\n\n\ncsv_serializer = _CsvSerializer()\n\n\ndef _is_mutable_sequence_like(obj):\n    """"""\n    Args:\n        obj:\n    """"""\n    return _is_sequence_like(obj) and hasattr(obj, ""__setitem__"")\n\n\ndef _is_sequence_like(obj):\n    """"""\n    Args:\n        obj:\n    """"""\n    # Need to explicitly check on str since str lacks the iterable magic methods in Python 2\n    return (  # pylint: disable=consider-using-ternary\n        hasattr(obj, ""__iter__"") and hasattr(obj, ""__getitem__"")\n    ) or isinstance(obj, str)\n\n\ndef _row_to_csv(obj):\n    """"""\n    Args:\n        obj:\n    """"""\n    if isinstance(obj, str):\n        return obj\n    return "","".join(obj)\n\n\nclass _CsvDeserializer(object):\n    """"""Placeholder docstring""""""\n\n    def __init__(self, encoding=""utf-8""):\n        """"""\n        Args:\n            encoding:\n        """"""\n        self.accept = CONTENT_TYPE_CSV\n        self.encoding = encoding\n\n    def __call__(self, stream, content_type):\n        """"""\n        Args:\n            stream:\n            content_type:\n        """"""\n        try:\n            return list(csv.reader(stream.read().decode(self.encoding).splitlines()))\n        finally:\n            stream.close()\n\n\ncsv_deserializer = _CsvDeserializer()\n\n\nclass BytesDeserializer(object):\n    """"""Return the response as an undecoded array of bytes.\n\n    Args:\n        accept (str): The Accept header to send to the server (optional).\n    """"""\n\n    def __init__(self, accept=None):\n        """"""\n        Args:\n            accept:\n        """"""\n        self.accept = accept\n\n    def __call__(self, stream, content_type):\n        """"""\n        Args:\n            stream:\n            content_type:\n        """"""\n        try:\n            return stream.read()\n        finally:\n            stream.close()\n\n\nclass StringDeserializer(object):\n    """"""Return the response as a decoded string.\n\n    Args:\n        encoding (str): The string encoding to use (default=utf-8).\n        accept (str): The Accept header to send to the server (optional).\n    """"""\n\n    def __init__(self, encoding=""utf-8"", accept=None):\n        """"""\n        Args:\n            encoding:\n            accept:\n        """"""\n        self.encoding = encoding\n        self.accept = accept\n\n    def __call__(self, stream, content_type):\n        """"""\n        Args:\n            stream:\n            content_type:\n        """"""\n        try:\n            return stream.read().decode(self.encoding)\n        finally:\n            stream.close()\n\n\nclass StreamDeserializer(object):\n    """"""Returns the tuple of the response stream and the content-type of the response.\n       It is the receivers responsibility to close the stream when they\'re done\n       reading the stream.\n\n    Args:\n        accept (str): The Accept header to send to the server (optional).\n    """"""\n\n    def __init__(self, accept=None):\n        """"""\n        Args:\n            accept:\n        """"""\n        self.accept = accept\n\n    def __call__(self, stream, content_type):\n        """"""\n        Args:\n            stream:\n            content_type:\n        """"""\n        return (stream, content_type)\n\n\nclass _JsonSerializer(object):\n    """"""Placeholder docstring""""""\n\n    def __init__(self):\n        """"""Placeholder docstring""""""\n        self.content_type = CONTENT_TYPE_JSON\n\n    def __call__(self, data):\n        """"""Take data of various formats and serialize them into the expected\n        request body. This uses information about supported input formats for\n        the deployed model.\n\n        Args:\n            data (object): Data to be serialized.\n\n        Returns:\n            object: Serialized data used for the request.\n        """"""\n        if isinstance(data, dict):\n            # convert each value in dict from a numpy array to a list if necessary, so they can be\n            # json serialized\n            return json.dumps({k: _ndarray_to_list(v) for k, v in six.iteritems(data)})\n\n        # files and buffers\n        if hasattr(data, ""read""):\n            return _json_serialize_from_buffer(data)\n\n        return json.dumps(_ndarray_to_list(data))\n\n\njson_serializer = _JsonSerializer()\n\n\ndef _ndarray_to_list(data):\n    """"""\n    Args:\n        data:\n    """"""\n    return data.tolist() if isinstance(data, np.ndarray) else data\n\n\ndef _json_serialize_from_buffer(buff):\n    """"""\n    Args:\n        buff:\n    """"""\n    return buff.read()\n\n\nclass _JsonDeserializer(object):\n    """"""Placeholder docstring""""""\n\n    def __init__(self):\n        """"""Placeholder docstring""""""\n        self.accept = CONTENT_TYPE_JSON\n\n    def __call__(self, stream, content_type):\n        """"""Decode a JSON object into the corresponding Python object.\n\n        Args:\n            stream (stream): The response stream to be deserialized.\n            content_type (str): The content type of the response.\n\n        Returns:\n            object: Body of the response deserialized into a JSON object.\n        """"""\n        try:\n            return json.load(codecs.getreader(""utf-8"")(stream))\n        finally:\n            stream.close()\n\n\njson_deserializer = _JsonDeserializer()\n\n\nclass _NumpyDeserializer(object):\n    """"""Placeholder docstring""""""\n\n    def __init__(self, accept=CONTENT_TYPE_NPY, dtype=None):\n        """"""\n        Args:\n            accept:\n            dtype:\n        """"""\n        self.accept = accept\n        self.dtype = dtype\n\n    def __call__(self, stream, content_type=CONTENT_TYPE_NPY):\n        """"""Decode from serialized data into a Numpy array.\n\n        Args:\n            stream (stream): The response stream to be deserialized.\n            content_type (str): The content type of the response. Can accept\n                CSV, JSON, or NPY data.\n\n        Returns:\n            object: Body of the response deserialized into a Numpy array.\n        """"""\n        try:\n            if content_type == CONTENT_TYPE_CSV:\n                return np.genfromtxt(\n                    codecs.getreader(""utf-8"")(stream), delimiter="","", dtype=self.dtype\n                )\n            if content_type == CONTENT_TYPE_JSON:\n                return np.array(json.load(codecs.getreader(""utf-8"")(stream)), dtype=self.dtype)\n            if content_type == CONTENT_TYPE_NPY:\n                return np.load(BytesIO(stream.read()))\n        finally:\n            stream.close()\n        raise ValueError(\n            ""content_type must be one of the following: CSV, JSON, NPY. content_type: {}"".format(\n                content_type\n            )\n        )\n\n\nnumpy_deserializer = _NumpyDeserializer()\n\n\nclass _NPYSerializer(object):\n    """"""Placeholder docstring""""""\n\n    def __init__(self):\n        """"""Placeholder docstring""""""\n        self.content_type = CONTENT_TYPE_NPY\n\n    def __call__(self, data, dtype=None):\n        """"""Serialize data into the request body in NPY format.\n\n        Args:\n            data (object): Data to be serialized. Can be a numpy array, list,\n                file, or buffer.\n            dtype:\n\n        Returns:\n            object: NPY serialized data used for the request.\n        """"""\n        if isinstance(data, np.ndarray):\n            if not data.size > 0:\n                raise ValueError(""empty array can\'t be serialized"")\n            return _npy_serialize(data)\n\n        if isinstance(data, list):\n            if not len(data) > 0:\n                raise ValueError(""empty array can\'t be serialized"")\n            return _npy_serialize(np.array(data, dtype))\n\n        # files and buffers. Assumed to hold npy-formatted data.\n        if hasattr(data, ""read""):\n            return data.read()\n\n        return _npy_serialize(np.array(data))\n\n\ndef _npy_serialize(data):\n    """"""\n    Args:\n        data:\n    """"""\n    buffer = BytesIO()\n    np.save(buffer, data)\n    return buffer.getvalue()\n\n\nnpy_serializer = _NPYSerializer()\n'"
src/sagemaker/processing.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""This module contains code related to the ``Processor`` class, which is used\nfor Amazon SageMaker Processing Jobs. These jobs let users perform data pre-processing,\npost-processing, feature engineering, data validation, and model evaluation,\nand interpretation on Amazon SageMaker.\n""""""\nfrom __future__ import print_function, absolute_import\n\nimport os\n\nfrom six.moves.urllib.parse import urlparse\n\nfrom sagemaker.job import _Job\nfrom sagemaker.utils import base_name_from_image, name_from_base\nfrom sagemaker.session import Session\nfrom sagemaker.s3 import S3Uploader\nfrom sagemaker.network import NetworkConfig  # noqa: F401 # pylint: disable=unused-import\n\n\nclass Processor(object):\n    """"""Handles Amazon SageMaker Processing tasks.""""""\n\n    def __init__(\n        self,\n        role,\n        image_uri,\n        instance_count,\n        instance_type,\n        entrypoint=None,\n        volume_size_in_gb=30,\n        volume_kms_key=None,\n        output_kms_key=None,\n        max_runtime_in_seconds=None,\n        base_job_name=None,\n        sagemaker_session=None,\n        env=None,\n        tags=None,\n        network_config=None,\n    ):\n        """"""Initializes a ``Processor`` instance. The ``Processor`` handles Amazon\n        SageMaker Processing tasks.\n\n        Args:\n            role (str): An AWS IAM role name or ARN. Amazon SageMaker Processing\n                uses this role to access AWS resources, such as\n                data stored in Amazon S3.\n            image_uri (str): The URI of the Docker image to use for the\n                processing jobs.\n            instance_count (int): The number of instances to run\n                a processing job with.\n            instance_type (str): The type of EC2 instance to use for\n                processing, for example, \'ml.c4.xlarge\'.\n            entrypoint (list[str]): The entrypoint for the processing job (default: None).\n                This is in the form of a list of strings that make a command.\n            volume_size_in_gb (int): Size in GB of the EBS volume\n                to use for storing data during processing (default: 30).\n            volume_kms_key (str): A KMS key for the processing\n                volume (default: None).\n            output_kms_key (str): The KMS key ID for processing job outputs (default: None).\n            max_runtime_in_seconds (int): Timeout in seconds (default: None).\n                After this amount of time, Amazon SageMaker terminates the job,\n                regardless of its current status. If `max_runtime_in_seconds` is not\n                specified, the default value is 24 hours.\n            base_job_name (str): Prefix for processing job name. If not specified,\n                the processor generates a default job name, based on the\n                processing image name and current timestamp.\n            sagemaker_session (:class:`~sagemaker.session.Session`):\n                Session object which manages interactions with Amazon SageMaker and\n                any other AWS services needed. If not specified, the processor creates\n                one using the default AWS configuration chain.\n            env (dict[str, str]): Environment variables to be passed to\n                the processing jobs (default: None).\n            tags (list[dict]): List of tags to be passed to the processing job\n                (default: None). For more, see\n                https://docs.aws.amazon.com/sagemaker/latest/dg/API_Tag.html.\n            network_config (:class:`~sagemaker.network.NetworkConfig`):\n                A :class:`~sagemaker.network.NetworkConfig`\n                object that configures network isolation, encryption of\n                inter-container traffic, security group IDs, and subnets.\n        """"""\n        self.role = role\n        self.image_uri = image_uri\n        self.instance_count = instance_count\n        self.instance_type = instance_type\n        self.entrypoint = entrypoint\n        self.volume_size_in_gb = volume_size_in_gb\n        self.volume_kms_key = volume_kms_key\n        self.output_kms_key = output_kms_key\n        self.max_runtime_in_seconds = max_runtime_in_seconds\n        self.base_job_name = base_job_name\n        self.sagemaker_session = sagemaker_session or Session()\n        self.env = env\n        self.tags = tags\n        self.network_config = network_config\n\n        self.jobs = []\n        self.latest_job = None\n        self._current_job_name = None\n        self.arguments = None\n\n    def run(\n        self,\n        inputs=None,\n        outputs=None,\n        arguments=None,\n        wait=True,\n        logs=True,\n        job_name=None,\n        experiment_config=None,\n    ):\n        """"""Runs a processing job.\n\n        Args:\n            inputs (list[:class:`~sagemaker.processing.ProcessingInput`]): Input files for\n                the processing job. These must be provided as\n                :class:`~sagemaker.processing.ProcessingInput` objects (default: None).\n            outputs (list[:class:`~sagemaker.processing.ProcessingOutput`]): Outputs for\n                the processing job. These can be specified as either path strings or\n                :class:`~sagemaker.processing.ProcessingOutput` objects (default: None).\n            arguments (list[str]): A list of string arguments to be passed to a\n                processing job (default: None).\n            wait (bool): Whether the call should wait until the job completes (default: True).\n            logs (bool): Whether to show the logs produced by the job.\n                Only meaningful when ``wait`` is True (default: True).\n            job_name (str): Processing job name. If not specified, the processor generates\n                a default job name, based on the base job name and current timestamp.\n            experiment_config (dict[str, str]): Experiment management configuration.\n                Dictionary contains three optional keys:\n                \'ExperimentName\', \'TrialName\', and \'TrialComponentDisplayName\'.\n\n        Raises:\n            ValueError: if ``logs`` is True but ``wait`` is False.\n        """"""\n        if logs and not wait:\n            raise ValueError(\n                """"""Logs can only be shown if wait is set to True.\n                Please either set wait to True or set logs to False.""""""\n            )\n\n        self._current_job_name = self._generate_current_job_name(job_name=job_name)\n\n        normalized_inputs = self._normalize_inputs(inputs)\n        normalized_outputs = self._normalize_outputs(outputs)\n        self.arguments = arguments\n\n        self.latest_job = ProcessingJob.start_new(\n            processor=self,\n            inputs=normalized_inputs,\n            outputs=normalized_outputs,\n            experiment_config=experiment_config,\n        )\n        self.jobs.append(self.latest_job)\n        if wait:\n            self.latest_job.wait(logs=logs)\n\n    def _generate_current_job_name(self, job_name=None):\n        """"""Generates the job name before running a processing job.\n\n        Args:\n            job_name (str): Name of the processing job to be created. If not\n                specified, one is generated, using the base name given to the\n                constructor if applicable.\n\n        Returns:\n            str: The supplied or generated job name.\n        """"""\n        if job_name is not None:\n            return job_name\n        # Honor supplied base_job_name or generate it.\n        if self.base_job_name:\n            base_name = self.base_job_name\n        else:\n            base_name = base_name_from_image(self.image_uri)\n\n        return name_from_base(base_name)\n\n    def _normalize_inputs(self, inputs=None):\n        """"""Ensures that all the ``ProcessingInput`` objects have names and S3 URIs.\n\n        Args:\n            inputs (list[sagemaker.processing.ProcessingInput]): A list of ``ProcessingInput``\n                objects to be normalized (default: None). If not specified,\n                an empty list is returned.\n\n        Returns:\n            list[sagemaker.processing.ProcessingInput]: The list of normalized\n                ``ProcessingInput`` objects.\n\n        Raises:\n            TypeError: if the inputs are not ``ProcessingInput`` objects.\n        """"""\n        # Initialize a list of normalized ProcessingInput objects.\n        normalized_inputs = []\n        if inputs is not None:\n            # Iterate through the provided list of inputs.\n            for count, file_input in enumerate(inputs, 1):\n                if not isinstance(file_input, ProcessingInput):\n                    raise TypeError(""Your inputs must be provided as ProcessingInput objects."")\n                # Generate a name for the ProcessingInput if it doesn\'t have one.\n                if file_input.input_name is None:\n                    file_input.input_name = ""input-{}"".format(count)\n                # If the source is a local path, upload it to S3\n                # and save the S3 uri in the ProcessingInput source.\n                parse_result = urlparse(file_input.source)\n                if parse_result.scheme != ""s3"":\n                    desired_s3_uri = ""s3://{}/{}/input/{}"".format(\n                        self.sagemaker_session.default_bucket(),\n                        self._current_job_name,\n                        file_input.input_name,\n                    )\n                    s3_uri = S3Uploader.upload(\n                        local_path=file_input.source,\n                        desired_s3_uri=desired_s3_uri,\n                        session=self.sagemaker_session,\n                    )\n                    file_input.source = s3_uri\n                normalized_inputs.append(file_input)\n        return normalized_inputs\n\n    def _normalize_outputs(self, outputs=None):\n        """"""Ensures that all the outputs are ``ProcessingOutput`` objects with\n        names and S3 URIs.\n\n        Args:\n            outputs (list[sagemaker.processing.ProcessingOutput]): A list\n                of outputs to be normalized (default: None). Can be either strings or\n                ``ProcessingOutput`` objects. If not specified,\n                an empty list is returned.\n\n        Returns:\n            list[sagemaker.processing.ProcessingOutput]: The list of normalized\n                ``ProcessingOutput`` objects.\n\n        Raises:\n            TypeError: if the outputs are not ``ProcessingOutput`` objects.\n        """"""\n        # Initialize a list of normalized ProcessingOutput objects.\n        normalized_outputs = []\n        if outputs is not None:\n            # Iterate through the provided list of outputs.\n            for count, output in enumerate(outputs, 1):\n                if not isinstance(output, ProcessingOutput):\n                    raise TypeError(""Your outputs must be provided as ProcessingOutput objects."")\n                # Generate a name for the ProcessingOutput if it doesn\'t have one.\n                if output.output_name is None:\n                    output.output_name = ""output-{}"".format(count)\n                # If the output\'s destination is not an s3_uri, create one.\n                parse_result = urlparse(output.destination)\n                if parse_result.scheme != ""s3"":\n                    s3_uri = ""s3://{}/{}/output/{}"".format(\n                        self.sagemaker_session.default_bucket(),\n                        self._current_job_name,\n                        output.output_name,\n                    )\n                    output.destination = s3_uri\n                normalized_outputs.append(output)\n        return normalized_outputs\n\n\nclass ScriptProcessor(Processor):\n    """"""Handles Amazon SageMaker processing tasks for jobs using a machine learning framework.""""""\n\n    def __init__(\n        self,\n        role,\n        image_uri,\n        command,\n        instance_count,\n        instance_type,\n        volume_size_in_gb=30,\n        volume_kms_key=None,\n        output_kms_key=None,\n        max_runtime_in_seconds=None,\n        base_job_name=None,\n        sagemaker_session=None,\n        env=None,\n        tags=None,\n        network_config=None,\n    ):\n        """"""Initializes a ``ScriptProcessor`` instance. The ``ScriptProcessor``\n        handles Amazon SageMaker Processing tasks for jobs using a machine learning framework.\n\n        Args:\n            role (str): An AWS IAM role name or ARN. Amazon SageMaker Processing\n                uses this role to access AWS resources, such as\n                data stored in Amazon S3.\n            image_uri (str): The URI of the Docker image to use for the\n                processing jobs.\n            command ([str]): The command to run, along with any command-line flags.\n                Example: [""python3"", ""-v""].\n            instance_count (int): The number of instances to run\n                a processing job with.\n            instance_type (str): The type of EC2 instance to use for\n                processing, for example, \'ml.c4.xlarge\'.\n            volume_size_in_gb (int): Size in GB of the EBS volume\n                to use for storing data during processing (default: 30).\n            volume_kms_key (str): A KMS key for the processing\n                volume (default: None).\n            output_kms_key (str): The KMS key ID for processing job outputs (default: None).\n            max_runtime_in_seconds (int): Timeout in seconds (default: None).\n                After this amount of time, Amazon SageMaker terminates the job,\n                regardless of its current status. If `max_runtime_in_seconds` is not\n                specified, the default value is 24 hours.\n            base_job_name (str): Prefix for processing name. If not specified,\n                the processor generates a default job name, based on the\n                processing image name and current timestamp.\n            sagemaker_session (:class:`~sagemaker.session.Session`):\n                Session object which manages interactions with Amazon SageMaker and\n                any other AWS services needed. If not specified, the processor creates\n                one using the default AWS configuration chain.\n            env (dict[str, str]): Environment variables to be passed to\n                the processing jobs (default: None).\n            tags (list[dict]): List of tags to be passed to the processing job\n                (default: None). For more, see\n                https://docs.aws.amazon.com/sagemaker/latest/dg/API_Tag.html.\n            network_config (:class:`~sagemaker.network.NetworkConfig`):\n                A :class:`~sagemaker.network.NetworkConfig`\n                object that configures network isolation, encryption of\n                inter-container traffic, security group IDs, and subnets.\n        """"""\n        self._CODE_CONTAINER_BASE_PATH = ""/opt/ml/processing/input/""\n        self._CODE_CONTAINER_INPUT_NAME = ""code""\n        self.command = command\n\n        super(ScriptProcessor, self).__init__(\n            role=role,\n            image_uri=image_uri,\n            instance_count=instance_count,\n            instance_type=instance_type,\n            volume_size_in_gb=volume_size_in_gb,\n            volume_kms_key=volume_kms_key,\n            output_kms_key=output_kms_key,\n            max_runtime_in_seconds=max_runtime_in_seconds,\n            base_job_name=base_job_name,\n            sagemaker_session=sagemaker_session,\n            env=env,\n            tags=tags,\n            network_config=network_config,\n        )\n\n    def run(\n        self,\n        code,\n        inputs=None,\n        outputs=None,\n        arguments=None,\n        wait=True,\n        logs=True,\n        job_name=None,\n        experiment_config=None,\n    ):\n        """"""Runs a processing job.\n\n        Args:\n            code (str): This can be an S3 URI or a local path to\n                a file with the framework script to run.\n            inputs (list[:class:`~sagemaker.processing.ProcessingInput`]): Input files for\n                the processing job. These must be provided as\n                :class:`~sagemaker.processing.ProcessingInput` objects (default: None).\n            outputs (list[:class:`~sagemaker.processing.ProcessingOutput`]): Outputs for\n                the processing job. These can be specified as either path strings or\n                :class:`~sagemaker.processing.ProcessingOutput` objects (default: None).\n            arguments (list[str]): A list of string arguments to be passed to a\n                processing job (default: None).\n            wait (bool): Whether the call should wait until the job completes (default: True).\n            logs (bool): Whether to show the logs produced by the job.\n                Only meaningful when wait is True (default: True).\n            job_name (str): Processing job name. If not specified, the processor generates\n                a default job name, based on the base job name and current timestamp.\n            experiment_config (dict[str, str]): Experiment management configuration.\n                Dictionary contains three optional keys:\n                \'ExperimentName\', \'TrialName\', and \'TrialComponentDisplayName\'.\n        """"""\n        self._current_job_name = self._generate_current_job_name(job_name=job_name)\n\n        user_code_s3_uri = self._handle_user_code_url(code)\n        user_script_name = self._get_user_code_name(code)\n\n        inputs_with_code = self._convert_code_and_add_to_inputs(inputs, user_code_s3_uri)\n\n        self._set_entrypoint(self.command, user_script_name)\n\n        normalized_inputs = self._normalize_inputs(inputs_with_code)\n        normalized_outputs = self._normalize_outputs(outputs)\n        self.arguments = arguments\n\n        self.latest_job = ProcessingJob.start_new(\n            processor=self,\n            inputs=normalized_inputs,\n            outputs=normalized_outputs,\n            experiment_config=experiment_config,\n        )\n        self.jobs.append(self.latest_job)\n        if wait:\n            self.latest_job.wait(logs=logs)\n\n    def _get_user_code_name(self, code):\n        """"""Gets the basename of the user\'s code from the URL the customer provided.\n\n        Args:\n            code (str): A URL to the user\'s code.\n\n        Returns:\n            str: The basename of the user\'s code.\n\n        """"""\n        code_url = urlparse(code)\n        return os.path.basename(code_url.path)\n\n    def _handle_user_code_url(self, code):\n        """"""Gets the S3 URL containing the user\'s code.\n\n           Inspects the scheme the customer passed in (""s3://"" for code in S3, ""file://"" or nothing\n           for absolute or local file paths. Uploads the code to S3 if the code is a local file.\n\n        Args:\n            code (str): A URL to the customer\'s code.\n\n        Returns:\n            str: The S3 URL to the customer\'s code.\n\n        Raises:\n            ValueError: if the code isn\'t found, is a directory, or\n                does not have a valid URL scheme.\n        """"""\n        code_url = urlparse(code)\n        if code_url.scheme == ""s3"":\n            user_code_s3_uri = code\n        elif code_url.scheme == """" or code_url.scheme == ""file"":\n            # Validate that the file exists locally and is not a directory.\n            if not os.path.exists(code):\n                raise ValueError(\n                    """"""code {} wasn\'t found. Please make sure that the file exists.\n                    """""".format(\n                        code\n                    )\n                )\n            if not os.path.isfile(code):\n                raise ValueError(\n                    """"""code {} must be a file, not a directory. Please pass a path to a file.\n                    """""".format(\n                        code\n                    )\n                )\n            user_code_s3_uri = self._upload_code(code)\n        else:\n            raise ValueError(\n                ""code {} url scheme {} is not recognized. Please pass a file path or S3 url"".format(\n                    code, code_url.scheme\n                )\n            )\n        return user_code_s3_uri\n\n    def _upload_code(self, code):\n        """"""Uploads a code file or directory specified as a string\n        and returns the S3 URI.\n\n        Args:\n            code (str): A file or directory to be uploaded to S3.\n\n        Returns:\n            str: The S3 URI of the uploaded file or directory.\n\n        """"""\n        desired_s3_uri = ""s3://{}/{}/input/{}"".format(\n            self.sagemaker_session.default_bucket(),\n            self._current_job_name,\n            self._CODE_CONTAINER_INPUT_NAME,\n        )\n        return S3Uploader.upload(\n            local_path=code, desired_s3_uri=desired_s3_uri, session=self.sagemaker_session\n        )\n\n    def _convert_code_and_add_to_inputs(self, inputs, s3_uri):\n        """"""Creates a ``ProcessingInput`` object from an S3 URI and adds it to the list of inputs.\n\n        Args:\n            inputs (list[sagemaker.processing.ProcessingInput]):\n                List of ``ProcessingInput`` objects.\n            s3_uri (str): S3 URI of the input to be added to inputs.\n\n        Returns:\n            list[sagemaker.processing.ProcessingInput]: A new list of ``ProcessingInput`` objects,\n                with the ``ProcessingInput`` object created from ``s3_uri`` appended to the list.\n\n        """"""\n        code_file_input = ProcessingInput(\n            source=s3_uri,\n            destination=""{}{}"".format(\n                self._CODE_CONTAINER_BASE_PATH, self._CODE_CONTAINER_INPUT_NAME\n            ),\n            input_name=self._CODE_CONTAINER_INPUT_NAME,\n        )\n        return (inputs or []) + [code_file_input]\n\n    def _set_entrypoint(self, command, user_script_name):\n        """"""Sets the entrypoint based on the user\'s script and corresponding executable.\n\n        Args:\n            user_script_name (str): A filename with an extension.\n        """"""\n        user_script_location = ""{}{}/{}"".format(\n            self._CODE_CONTAINER_BASE_PATH, self._CODE_CONTAINER_INPUT_NAME, user_script_name\n        )\n        self.entrypoint = command + [user_script_location]\n\n\nclass ProcessingJob(_Job):\n    """"""Provides functionality to start, describe, and stop processing jobs.""""""\n\n    def __init__(self, sagemaker_session, job_name, inputs, outputs, output_kms_key=None):\n        """"""Initializes a Processing job.\n\n        Args:\n            sagemaker_session (:class:`~sagemaker.session.Session`):\n                Session object which manages interactions with Amazon SageMaker and\n                any other AWS services needed. If not specified, the processor creates\n                one using the default AWS configuration chain.\n            job_name (str): Name of the Processing job.\n            inputs (list[:class:`~sagemaker.processing.ProcessingInput`]): A list of\n                :class:`~sagemaker.processing.ProcessingInput` objects.\n            outputs (list[:class:`~sagemaker.processing.ProcessingOutput`]): A list of\n                :class:`~sagemaker.processing.ProcessingOutput` objects.\n            output_kms_key (str): The output KMS key associated with the job (default: None).\n        """"""\n        self.inputs = inputs\n        self.outputs = outputs\n        self.output_kms_key = output_kms_key\n        super(ProcessingJob, self).__init__(sagemaker_session=sagemaker_session, job_name=job_name)\n\n    @classmethod\n    def start_new(cls, processor, inputs, outputs, experiment_config):\n        """"""Starts a new processing job using the provided inputs and outputs.\n\n        Args:\n            processor (:class:`~sagemaker.processing.Processor`): The ``Processor`` instance\n                that started the job.\n            inputs (list[:class:`~sagemaker.processing.ProcessingInput`]): A list of\n                :class:`~sagemaker.processing.ProcessingInput` objects.\n            outputs (list[:class:`~sagemaker.processing.ProcessingOutput`]): A list of\n                :class:`~sagemaker.processing.ProcessingOutput` objects.\n            experiment_config (dict[str, str]): Experiment management configuration.\n                Dictionary contains three optional keys:\n                \'ExperimentName\', \'TrialName\', and \'TrialComponentDisplayName\'.\n\n        Returns:\n            :class:`~sagemaker.processing.ProcessingJob`: The instance of ``ProcessingJob`` created\n                using the ``Processor``.\n        """"""\n        # Initialize an empty dictionary for arguments to be passed to sagemaker_session.process.\n        process_request_args = {}\n\n        # Add arguments to the dictionary.\n        process_request_args[""inputs""] = [input._to_request_dict() for input in inputs]\n\n        process_request_args[""output_config""] = {\n            ""Outputs"": [output._to_request_dict() for output in outputs]\n        }\n        if processor.output_kms_key is not None:\n            process_request_args[""output_config""][""KmsKeyId""] = processor.output_kms_key\n\n        process_request_args[""experiment_config""] = experiment_config\n        process_request_args[""job_name""] = processor._current_job_name\n\n        process_request_args[""resources""] = {\n            ""ClusterConfig"": {\n                ""InstanceType"": processor.instance_type,\n                ""InstanceCount"": processor.instance_count,\n                ""VolumeSizeInGB"": processor.volume_size_in_gb,\n            }\n        }\n\n        if processor.volume_kms_key is not None:\n            process_request_args[""resources""][""ClusterConfig""][\n                ""VolumeKmsKeyId""\n            ] = processor.volume_kms_key\n\n        if processor.max_runtime_in_seconds is not None:\n            process_request_args[""stopping_condition""] = {\n                ""MaxRuntimeInSeconds"": processor.max_runtime_in_seconds\n            }\n        else:\n            process_request_args[""stopping_condition""] = None\n\n        process_request_args[""app_specification""] = {""ImageUri"": processor.image_uri}\n        if processor.arguments is not None:\n            process_request_args[""app_specification""][""ContainerArguments""] = processor.arguments\n        if processor.entrypoint is not None:\n            process_request_args[""app_specification""][""ContainerEntrypoint""] = processor.entrypoint\n\n        process_request_args[""environment""] = processor.env\n\n        if processor.network_config is not None:\n            process_request_args[""network_config""] = processor.network_config._to_request_dict()\n        else:\n            process_request_args[""network_config""] = None\n\n        process_request_args[""role_arn""] = processor.sagemaker_session.expand_role(processor.role)\n\n        process_request_args[""tags""] = processor.tags\n\n        # Print the job name and the user\'s inputs and outputs as lists of dictionaries.\n        print()\n        print(""Job Name: "", process_request_args[""job_name""])\n        print(""Inputs: "", process_request_args[""inputs""])\n        print(""Outputs: "", process_request_args[""output_config""][""Outputs""])\n\n        # Call sagemaker_session.process using the arguments dictionary.\n        processor.sagemaker_session.process(**process_request_args)\n\n        return cls(\n            processor.sagemaker_session,\n            processor._current_job_name,\n            inputs,\n            outputs,\n            processor.output_kms_key,\n        )\n\n    @classmethod\n    def from_processing_name(cls, sagemaker_session, processing_job_name):\n        """"""Initializes a ``ProcessingJob`` from a processing job name.\n\n        Args:\n            processing_job_name (str): Name of the processing job.\n            sagemaker_session (:class:`~sagemaker.session.Session`):\n                Session object which manages interactions with Amazon SageMaker and\n                any other AWS services needed. If not specified, the processor creates\n                one using the default AWS configuration chain.\n\n        Returns:\n            :class:`~sagemaker.processing.ProcessingJob`: The instance of ``ProcessingJob`` created\n                from the job name.\n        """"""\n        job_desc = sagemaker_session.describe_processing_job(job_name=processing_job_name)\n\n        inputs = None\n        if job_desc.get(""ProcessingInputs""):\n            inputs = [\n                ProcessingInput(\n                    source=processing_input[""S3Input""][""S3Uri""],\n                    destination=processing_input[""S3Input""][""LocalPath""],\n                    input_name=processing_input[""InputName""],\n                    s3_data_type=processing_input[""S3Input""].get(""S3DataType""),\n                    s3_input_mode=processing_input[""S3Input""].get(""S3InputMode""),\n                    s3_data_distribution_type=processing_input[""S3Input""].get(\n                        ""S3DataDistributionType""\n                    ),\n                    s3_compression_type=processing_input[""S3Input""].get(""S3CompressionType""),\n                )\n                for processing_input in job_desc[""ProcessingInputs""]\n            ]\n\n        outputs = None\n        if job_desc.get(""ProcessingOutputConfig"") and job_desc[""ProcessingOutputConfig""].get(\n            ""Outputs""\n        ):\n            outputs = [\n                ProcessingOutput(\n                    source=processing_output[""S3Output""][""LocalPath""],\n                    destination=processing_output[""S3Output""][""S3Uri""],\n                    output_name=processing_output[""OutputName""],\n                )\n                for processing_output in job_desc[""ProcessingOutputConfig""][""Outputs""]\n            ]\n\n        output_kms_key = None\n        if job_desc.get(""ProcessingOutputConfig""):\n            output_kms_key = job_desc[""ProcessingOutputConfig""].get(""KmsKeyId"")\n\n        return cls(\n            sagemaker_session=sagemaker_session,\n            job_name=processing_job_name,\n            inputs=inputs,\n            outputs=outputs,\n            output_kms_key=output_kms_key,\n        )\n\n    @classmethod\n    def from_processing_arn(cls, sagemaker_session, processing_job_arn):\n        """"""Initializes a ``ProcessingJob`` from a Processing ARN.\n\n        Args:\n            processing_job_arn (str): ARN of the processing job.\n            sagemaker_session (:class:`~sagemaker.session.Session`):\n                Session object which manages interactions with Amazon SageMaker and\n                any other AWS services needed. If not specified, the processor creates\n                one using the default AWS configuration chain.\n\n        Returns:\n            :class:`~sagemaker.processing.ProcessingJob`: The instance of ``ProcessingJob`` created\n                from the processing job\'s ARN.\n        """"""\n        processing_job_name = processing_job_arn.split("":"")[5][\n            len(""processing-job/"") :\n        ]  # This is necessary while the API only vends an arn.\n        return cls.from_processing_name(\n            sagemaker_session=sagemaker_session, processing_job_name=processing_job_name\n        )\n\n    def _is_local_channel(self, input_url):\n        """"""Used for Local Mode. Not yet implemented.\n\n        Args:\n            input_url (str): input URL\n\n        Raises:\n            NotImplementedError: this method is not yet implemented.\n        """"""\n        raise NotImplementedError\n\n    def wait(self, logs=True):\n        """"""Waits for the processing job to complete.\n\n        Args:\n            logs (bool): Whether to show the logs produced by the job (default: True).\n\n        """"""\n        if logs:\n            self.sagemaker_session.logs_for_processing_job(self.job_name, wait=True)\n        else:\n            self.sagemaker_session.wait_for_processing_job(self.job_name)\n\n    def describe(self):\n        """"""Prints out a response from the DescribeProcessingJob API call.""""""\n        return self.sagemaker_session.describe_processing_job(self.job_name)\n\n    def stop(self):\n        """"""Stops the processing job.""""""\n        self.sagemaker_session.stop_processing_job(self.name)\n\n\nclass ProcessingInput(object):\n    """"""Accepts parameters that specify an Amazon S3 input for a processing job and\n    provides a method to turn those parameters into a dictionary.""""""\n\n    def __init__(\n        self,\n        source,\n        destination,\n        input_name=None,\n        s3_data_type=""S3Prefix"",\n        s3_input_mode=""File"",\n        s3_data_distribution_type=""FullyReplicated"",\n        s3_compression_type=""None"",\n    ):\n        """"""Initializes a ``ProcessingInput`` instance. ``ProcessingInput`` accepts parameters\n        that specify an Amazon S3 input for a processing job and provides a method\n        to turn those parameters into a dictionary.\n\n        Args:\n            source (str): The source for the input. If a local path is provided, it will\n                automatically be uploaded to S3 under:\n                ""s3://<default-bucket-name>/<job-name>/input/<input-name>"".\n            destination (str): The destination of the input.\n            input_name (str): The name for the input. If a name\n                is not provided, one will be generated (eg. ""input-1"").\n            s3_data_type (str): Valid options are ""ManifestFile"" or ""S3Prefix"".\n            s3_input_mode (str): Valid options are ""Pipe"" or ""File"".\n            s3_data_distribution_type (str): Valid options are ""FullyReplicated""\n                or ""ShardedByS3Key"".\n            s3_compression_type (str): Valid options are ""None"" or ""Gzip"".\n        """"""\n        self.source = source\n        self.destination = destination\n        self.input_name = input_name\n        self.s3_data_type = s3_data_type\n        self.s3_input_mode = s3_input_mode\n        self.s3_data_distribution_type = s3_data_distribution_type\n        self.s3_compression_type = s3_compression_type\n\n    def _to_request_dict(self):\n        """"""Generates a request dictionary using the parameters provided to the class.""""""\n        # Create the request dictionary.\n        s3_input_request = {\n            ""InputName"": self.input_name,\n            ""S3Input"": {\n                ""S3Uri"": self.source,\n                ""LocalPath"": self.destination,\n                ""S3DataType"": self.s3_data_type,\n                ""S3InputMode"": self.s3_input_mode,\n                ""S3DataDistributionType"": self.s3_data_distribution_type,\n            },\n        }\n\n        # Check the compression type, then add it to the dictionary.\n        if self.s3_compression_type == ""Gzip"" and self.s3_input_mode != ""Pipe"":\n            raise ValueError(""Data can only be gzipped when the input mode is Pipe."")\n        if self.s3_compression_type is not None:\n            s3_input_request[""S3Input""][""S3CompressionType""] = self.s3_compression_type\n\n        # Return the request dictionary.\n        return s3_input_request\n\n\nclass ProcessingOutput(object):\n    """"""Accepts parameters that specify an Amazon S3 output for a processing job and provides\n    a method to turn those parameters into a dictionary.""""""\n\n    def __init__(self, source, destination=None, output_name=None, s3_upload_mode=""EndOfJob""):\n        """"""Initializes a ``ProcessingOutput`` instance. ``ProcessingOutput`` accepts parameters that\n        specify an Amazon S3 output for a processing job and provides a method to turn\n        those parameters into a dictionary.\n\n        Args:\n            source (str): The source for the output.\n            destination (str): The destination of the output. If a destination\n                is not provided, one will be generated:\n                ""s3://<default-bucket-name>/<job-name>/output/<output-name>"".\n            output_name (str): The name of the output. If a name\n                is not provided, one will be generated (eg. ""output-1"").\n            s3_upload_mode (str): Valid options are ""EndOfJob"" or ""Continuous"".\n        """"""\n        self.source = source\n        self.destination = destination\n        self.output_name = output_name\n        self.s3_upload_mode = s3_upload_mode\n\n    def _to_request_dict(self):\n        """"""Generates a request dictionary using the parameters provided to the class.""""""\n        # Create the request dictionary.\n        s3_output_request = {\n            ""OutputName"": self.output_name,\n            ""S3Output"": {\n                ""S3Uri"": self.destination,\n                ""LocalPath"": self.source,\n                ""S3UploadMode"": self.s3_upload_mode,\n            },\n        }\n\n        # Return the request dictionary.\n        return s3_output_request\n'"
src/sagemaker/s3.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""This module contains Enums and helper methods related to S3.""""""\nfrom __future__ import print_function, absolute_import\n\nimport logging\n\nfrom six.moves.urllib.parse import urlparse\nfrom sagemaker.session import Session\n\nlogger = logging.getLogger(""sagemaker"")\n\nSESSION_V2_RENAME_MESSAGE = (\n    ""Parameter \'session\' will be renamed to \'sagemaker_session\' in SageMaker Python SDK v2.""\n)\n\n\ndef _session_v2_rename_warning(session):\n    """"""\n    Args:\n        session (sagemaker.session.Session):\n    """"""\n    if session is not None:\n        logger.warning(SESSION_V2_RENAME_MESSAGE)\n\n\ndef parse_s3_url(url):\n    """"""Returns an (s3 bucket, key name/prefix) tuple from a url with an s3\n    scheme.\n    Args:\n        url (str):\n    Returns:\n        tuple: A tuple containing:\n            str: S3 bucket name str: S3 key\n    """"""\n    parsed_url = urlparse(url)\n    if parsed_url.scheme != ""s3"":\n        raise ValueError(""Expecting \'s3\' scheme, got: {} in {}."".format(parsed_url.scheme, url))\n    return parsed_url.netloc, parsed_url.path.lstrip(""/"")\n\n\nclass S3Uploader(object):\n    """"""Contains static methods for uploading directories or files to S3.""""""\n\n    @staticmethod\n    def upload(local_path, desired_s3_uri, kms_key=None, session=None):\n        """"""Static method that uploads a given file or directory to S3.\n\n        Args:\n            local_path (str): A local path to a file or directory.\n            desired_s3_uri (str): The desired S3 uri to upload to.\n            kms_key (str): The KMS key to use to encrypt the files.\n            session (sagemaker.session.Session): Session object which\n                manages interactions with Amazon SageMaker APIs and any other\n                AWS services needed. If not specified, the estimator creates one\n                using the default AWS configuration chain.\n\n        Returns:\n            The S3 uri of the uploaded file(s).\n\n        """"""\n        if session is not None:\n            _session_v2_rename_warning(session)\n\n        sagemaker_session = session or Session()\n        bucket, key_prefix = parse_s3_url(url=desired_s3_uri)\n        if kms_key is not None:\n            extra_args = {""SSEKMSKeyId"": kms_key}\n        else:\n            extra_args = None\n\n        return sagemaker_session.upload_data(\n            path=local_path, bucket=bucket, key_prefix=key_prefix, extra_args=extra_args\n        )\n\n    @staticmethod\n    def upload_string_as_file_body(body, desired_s3_uri=None, kms_key=None, session=None):\n        """"""Static method that uploads a given file or directory to S3.\n\n        Args:\n            body (str): String representing the body of the file.\n            desired_s3_uri (str): The desired S3 uri to upload to.\n            kms_key (str): The KMS key to use to encrypt the files.\n            session (sagemaker.session.Session): AWS session to use. Automatically\n                generates one if not provided.\n\n        Returns:\n            str: The S3 uri of the uploaded file(s).\n\n        """"""\n        if session is not None:\n            _session_v2_rename_warning(session)\n\n        sagemaker_session = session or Session()\n        bucket, key = parse_s3_url(desired_s3_uri)\n\n        sagemaker_session.upload_string_as_file_body(\n            body=body, bucket=bucket, key=key, kms_key=kms_key\n        )\n\n        return desired_s3_uri\n\n\nclass S3Downloader(object):\n    """"""Contains static methods for downloading directories or files from S3.""""""\n\n    @staticmethod\n    def download(s3_uri, local_path, kms_key=None, session=None):\n        """"""Static method that downloads a given S3 uri to the local machine.\n\n        Args:\n            s3_uri (str): An S3 uri to download from.\n            local_path (str): A local path to download the file(s) to.\n            kms_key (str): The KMS key to use to decrypt the files.\n            session (sagemaker.session.Session): Session object which\n                manages interactions with Amazon SageMaker APIs and any other\n                AWS services needed. If not specified, the estimator creates one\n                using the default AWS configuration chain.\n\n        """"""\n        if session is not None:\n            _session_v2_rename_warning(session)\n\n        sagemaker_session = session or Session()\n        bucket, key_prefix = parse_s3_url(url=s3_uri)\n        if kms_key is not None:\n            extra_args = {""SSECustomerKey"": kms_key}\n        else:\n            extra_args = None\n\n        sagemaker_session.download_data(\n            path=local_path, bucket=bucket, key_prefix=key_prefix, extra_args=extra_args\n        )\n\n    @staticmethod\n    def read_file(s3_uri, session=None):\n        """"""Static method that returns the contents of an s3 uri file body as a string.\n\n        Args:\n            s3_uri (str): An S3 uri that refers to a single file.\n            session (sagemaker.session.Session): AWS session to use. Automatically\n                generates one if not provided.\n\n        Returns:\n            str: The body of the file.\n\n        """"""\n        if session is not None:\n            _session_v2_rename_warning(session)\n\n        sagemaker_session = session or Session()\n        bucket, key_prefix = parse_s3_url(url=s3_uri)\n\n        return sagemaker_session.read_s3_file(bucket=bucket, key_prefix=key_prefix)\n\n    @staticmethod\n    def list(s3_uri, session=None):\n        """"""Static method that lists the contents of an S3 uri.\n\n        Args:\n            s3_uri (str): The S3 base uri to list objects in.\n            session (sagemaker.session.Session): AWS session to use. Automatically\n                generates one if not provided.\n\n        Returns:\n            [str]: The list of S3 URIs in the given S3 base uri.\n\n        """"""\n        if session is not None:\n            _session_v2_rename_warning(session)\n\n        sagemaker_session = session or Session()\n        bucket, key_prefix = parse_s3_url(url=s3_uri)\n\n        file_keys = sagemaker_session.list_s3_files(bucket=bucket, key_prefix=key_prefix)\n        return [""s3://{}/{}"".format(bucket, file_key) for file_key in file_keys]\n'"
src/sagemaker/session.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import, print_function\n\nimport json\nimport logging\nimport os\nimport re\nimport sys\nimport time\nimport warnings\n\nimport boto3\nimport botocore.config\nfrom botocore.exceptions import ClientError\nimport six\n\nimport sagemaker.logs\nfrom sagemaker import vpc_utils\n\n# import s3_input for backward compatibility\nfrom sagemaker.inputs import s3_input  # noqa # pylint: disable=unused-import\nfrom sagemaker.user_agent import prepend_user_agent\nfrom sagemaker.utils import (\n    name_from_image,\n    secondary_training_status_changed,\n    secondary_training_status_message,\n    sts_regional_endpoint,\n)\nfrom sagemaker import exceptions\n\nLOGGER = logging.getLogger(""sagemaker"")\n\nNOTEBOOK_METADATA_FILE = ""/opt/ml/metadata/resource-metadata.json""\n\n_STATUS_CODE_TABLE = {\n    ""COMPLETED"": ""Completed"",\n    ""INPROGRESS"": ""InProgress"",\n    ""FAILED"": ""Failed"",\n    ""STOPPED"": ""Stopped"",\n    ""STOPPING"": ""Stopping"",\n    ""STARTING"": ""Starting"",\n}\n\n\nclass LogState(object):\n    """"""Placeholder docstring""""""\n\n    STARTING = 1\n    WAIT_IN_PROGRESS = 2\n    TAILING = 3\n    JOB_COMPLETE = 4\n    COMPLETE = 5\n\n\nclass Session(object):  # pylint: disable=too-many-public-methods\n    """"""Manage interactions with the Amazon SageMaker APIs and any other AWS services needed.\n\n    This class provides convenient methods for manipulating entities and resources that Amazon\n    SageMaker uses, such as training jobs, endpoints, and input datasets in S3.\n\n    AWS service calls are delegated to an underlying Boto3 session, which by default\n    is initialized using the AWS configuration chain. When you make an Amazon SageMaker API call\n    that accesses an S3 bucket location and one is not specified, the ``Session`` creates a default\n    bucket based on a naming convention which includes the current AWS account ID.\n    """"""\n\n    def __init__(\n        self,\n        boto_session=None,\n        sagemaker_client=None,\n        sagemaker_runtime_client=None,\n        default_bucket=None,\n    ):\n        """"""Initialize a SageMaker ``Session``.\n\n        Args:\n            boto_session (boto3.session.Session): The underlying Boto3 session which AWS service\n                calls are delegated to (default: None). If not provided, one is created with\n                default AWS configuration chain.\n            sagemaker_client (boto3.SageMaker.Client): Client which makes Amazon SageMaker service\n                calls other than ``InvokeEndpoint`` (default: None). Estimators created using this\n                ``Session`` use this client. If not provided, one will be created using this\n                instance\'s ``boto_session``.\n            sagemaker_runtime_client (boto3.SageMakerRuntime.Client): Client which makes\n                ``InvokeEndpoint`` calls to Amazon SageMaker (default: None). Predictors created\n                using this ``Session`` use this client. If not provided, one will be created using\n                this instance\'s ``boto_session``.\n            default_bucket (str): The default Amazon S3 bucket to be used by this session.\n                This will be created the next time an Amazon S3 bucket is needed (by calling\n                :func:`default_bucket`).\n                If not provided, a default bucket will be created based on the following format:\n                ""sagemaker-{region}-{aws-account-id}"".\n                Example: ""sagemaker-my-custom-bucket"".\n\n        """"""\n        self._default_bucket = None\n        self._default_bucket_name_override = default_bucket\n        self.s3_resource = None\n        self.s3_client = None\n        self.config = None\n\n        self._initialize(\n            boto_session=boto_session,\n            sagemaker_client=sagemaker_client,\n            sagemaker_runtime_client=sagemaker_runtime_client,\n        )\n\n    def _initialize(self, boto_session, sagemaker_client, sagemaker_runtime_client):\n        """"""Initialize this SageMaker Session.\n\n        Creates or uses a boto_session, sagemaker_client and sagemaker_runtime_client.\n        Sets the region_name.\n        """"""\n        self.boto_session = boto_session or boto3.DEFAULT_SESSION or boto3.Session()\n\n        self._region_name = self.boto_session.region_name\n        if self._region_name is None:\n            raise ValueError(\n                ""Must setup local AWS configuration with a region supported by SageMaker.""\n            )\n\n        self.sagemaker_client = sagemaker_client or self.boto_session.client(""sagemaker"")\n        prepend_user_agent(self.sagemaker_client)\n\n        if sagemaker_runtime_client is not None:\n            self.sagemaker_runtime_client = sagemaker_runtime_client\n        else:\n            config = botocore.config.Config(read_timeout=80)\n            self.sagemaker_runtime_client = self.boto_session.client(\n                ""runtime.sagemaker"", config=config\n            )\n\n        prepend_user_agent(self.sagemaker_runtime_client)\n\n        self.local_mode = False\n\n    @property\n    def boto_region_name(self):\n        """"""Placeholder docstring""""""\n        return self._region_name\n\n    def upload_data(self, path, bucket=None, key_prefix=""data"", extra_args=None):\n        """"""Upload local file or directory to S3.\n\n        If a single file is specified for upload, the resulting S3 object key is\n        ``{key_prefix}/{filename}`` (filename does not include the local path, if any specified).\n\n        If a directory is specified for upload, the API uploads all content, recursively,\n        preserving relative structure of subdirectories. The resulting object key names are:\n        ``{key_prefix}/{relative_subdirectory_path}/filename``.\n\n        Args:\n            path (str): Path (absolute or relative) of local file or directory to upload.\n            bucket (str): Name of the S3 Bucket to upload to (default: None). If not specified, the\n                default bucket of the ``Session`` is used (if default bucket does not exist, the\n                ``Session`` creates it).\n            key_prefix (str): Optional S3 object key name prefix (default: \'data\'). S3 uses the\n                prefix to create a directory structure for the bucket content that it display in\n                the S3 console.\n            extra_args (dict): Optional extra arguments that may be passed to the upload operation.\n                Similar to ExtraArgs parameter in S3 upload_file function. Please refer to the\n                ExtraArgs parameter documentation here:\n                https://boto3.amazonaws.com/v1/documentation/api/latest/guide/s3-uploading-files.html#the-extraargs-parameter\n\n        Returns:\n            str: The S3 URI of the uploaded file(s). If a file is specified in the path argument,\n                the URI format is: ``s3://{bucket name}/{key_prefix}/{original_file_name}``.\n                If a directory is specified in the path argument, the URI format is\n                ``s3://{bucket name}/{key_prefix}``.\n        """"""\n        # Generate a tuple for each file that we want to upload of the form (local_path, s3_key).\n        files = []\n        key_suffix = None\n        if os.path.isdir(path):\n            for dirpath, _, filenames in os.walk(path):\n                for name in filenames:\n                    local_path = os.path.join(dirpath, name)\n                    s3_relative_prefix = (\n                        """" if path == dirpath else os.path.relpath(dirpath, start=path) + ""/""\n                    )\n                    s3_key = ""{}/{}{}"".format(key_prefix, s3_relative_prefix, name)\n                    files.append((local_path, s3_key))\n        else:\n            _, name = os.path.split(path)\n            s3_key = ""{}/{}"".format(key_prefix, name)\n            files.append((path, s3_key))\n            key_suffix = name\n\n        bucket = bucket or self.default_bucket()\n        if self.s3_resource is None:\n            s3 = self.boto_session.resource(""s3"", region_name=self.boto_region_name)\n        else:\n            s3 = self.s3_resource\n\n        for local_path, s3_key in files:\n            s3.Object(bucket, s3_key).upload_file(local_path, ExtraArgs=extra_args)\n\n        s3_uri = ""s3://{}/{}"".format(bucket, key_prefix)\n        # If a specific file was used as input (instead of a directory), we return the full S3 key\n        # of the uploaded object. This prevents unintentionally using other files under the same\n        # prefix during training.\n        if key_suffix:\n            s3_uri = ""{}/{}"".format(s3_uri, key_suffix)\n        return s3_uri\n\n    def upload_string_as_file_body(self, body, bucket, key, kms_key=None):\n        """"""Upload a string as a file body.\n\n        Args:\n            body (str): String representing the body of the file.\n            bucket (str): Name of the S3 Bucket to upload to (default: None). If not specified, the\n                default bucket of the ``Session`` is used (if default bucket does not exist, the\n                ``Session`` creates it).\n            key (str): S3 object key. This is the s3 path to the file.\n            kms_key (str): The KMS key to use for encrypting the file.\n\n        Returns:\n            str: The S3 URI of the uploaded file.\n                The URI format is: ``s3://{bucket name}/{key}``.\n        """"""\n        if self.s3_resource is None:\n            s3 = self.boto_session.resource(""s3"", region_name=self.boto_region_name)\n        else:\n            s3 = self.s3_resource\n\n        s3_object = s3.Object(bucket_name=bucket, key=key)\n\n        if kms_key is not None:\n            s3_object.put(Body=body, SSEKMSKeyId=kms_key, ServerSideEncryption=""aws:kms"")\n        else:\n            s3_object.put(Body=body)\n\n        s3_uri = ""s3://{}/{}"".format(bucket, key)\n        return s3_uri\n\n    def download_data(self, path, bucket, key_prefix="""", extra_args=None):\n        """"""Download file or directory from S3.\n\n        Args:\n            path (str): Local path where the file or directory should be downloaded to.\n            bucket (str): Name of the S3 Bucket to download from.\n            key_prefix (str): Optional S3 object key name prefix.\n            extra_args (dict): Optional extra arguments that may be passed to the\n                download operation. Please refer to the ExtraArgs parameter in the boto3\n                documentation here:\n                https://boto3.amazonaws.com/v1/documentation/api/latest/guide/s3-example-download-file.html\n\n        Returns:\n\n        """"""\n        # Initialize the S3 client.\n        if self.s3_client is None:\n            s3 = self.boto_session.client(""s3"", region_name=self.boto_region_name)\n        else:\n            s3 = self.s3_client\n\n        # Initialize the variables used to loop through the contents of the S3 bucket.\n        keys = []\n        next_token = """"\n        base_parameters = {""Bucket"": bucket, ""Prefix"": key_prefix}\n\n        # Loop through the contents of the bucket, 1,000 objects at a time. Gathering all keys into\n        # a ""keys"" list.\n        while next_token is not None:\n            request_parameters = base_parameters.copy()\n            if next_token != """":\n                request_parameters.update({""ContinuationToken"": next_token})\n            response = s3.list_objects_v2(**request_parameters)\n            contents = response.get(""Contents"")\n            # For each object, save its key or directory.\n            for s3_object in contents:\n                key = s3_object.get(""Key"")\n                keys.append(key)\n            next_token = response.get(""NextContinuationToken"")\n\n        # For each object key, create the directory on the local machine if needed, and then\n        # download the file.\n        for key in keys:\n            tail_s3_uri_path = os.path.basename(key_prefix)\n            if not os.path.splitext(key_prefix)[1]:\n                tail_s3_uri_path = os.path.relpath(key, key_prefix)\n            destination_path = os.path.join(path, tail_s3_uri_path)\n            if not os.path.exists(os.path.dirname(destination_path)):\n                os.makedirs(os.path.dirname(destination_path))\n            s3.download_file(\n                Bucket=bucket, Key=key, Filename=destination_path, ExtraArgs=extra_args\n            )\n\n    def read_s3_file(self, bucket, key_prefix):\n        """"""Read a single file from S3.\n\n        Args:\n            bucket (str): Name of the S3 Bucket to download from.\n            key_prefix (str): S3 object key name prefix.\n\n        Returns:\n            str: The body of the s3 file as a string.\n\n        """"""\n        if self.s3_client is None:\n            s3 = self.boto_session.client(""s3"", region_name=self.boto_region_name)\n        else:\n            s3 = self.s3_client\n\n        # Explicitly passing a None kms_key to boto3 throws a validation error.\n        s3_object = s3.get_object(Bucket=bucket, Key=key_prefix)\n\n        return s3_object[""Body""].read().decode(""utf-8"")\n\n    def list_s3_files(self, bucket, key_prefix):\n        """"""Lists the S3 files given an S3 bucket and key.\n\n        Args:\n            bucket (str): Name of the S3 Bucket to download from.\n            key_prefix (str): S3 object key name prefix.\n\n        Returns:\n            [str]: The list of files at the S3 path.\n\n        """"""\n        if self.s3_resource is None:\n            s3 = self.boto_session.resource(""s3"", region_name=self.boto_region_name)\n        else:\n            s3 = self.s3_resource\n\n        s3_bucket = s3.Bucket(name=bucket)\n        s3_objects = s3_bucket.objects.filter(Prefix=key_prefix).all()\n        return [s3_object.key for s3_object in s3_objects]\n\n    def default_bucket(self):\n        """"""Return the name of the default bucket to use in relevant Amazon SageMaker interactions.\n\n        Returns:\n            str: The name of the default bucket, which is of the form:\n                ``sagemaker-{region}-{AWS account ID}``.\n        """"""\n\n        if self._default_bucket:\n            return self._default_bucket\n\n        region = self.boto_session.region_name\n\n        default_bucket = self._default_bucket_name_override\n        if not default_bucket:\n            account = self.boto_session.client(\n                ""sts"", region_name=region, endpoint_url=sts_regional_endpoint(region)\n            ).get_caller_identity()[""Account""]\n            default_bucket = ""sagemaker-{}-{}"".format(region, account)\n\n        self._create_s3_bucket_if_it_does_not_exist(bucket_name=default_bucket, region=region)\n\n        self._default_bucket = default_bucket\n\n        return self._default_bucket\n\n    def _create_s3_bucket_if_it_does_not_exist(self, bucket_name, region):\n        """"""Creates an S3 Bucket if it does not exist.\n        Also swallows a few common exceptions that indicate that the bucket already exists or\n        that it is being created.\n\n        Args:\n            bucket_name (str): Name of the S3 bucket to be created.\n            region (str): The region in which to create the bucket.\n\n        Raises:\n            botocore.exceptions.ClientError: If S3 throws an unexpected exception during bucket\n                creation.\n                If the exception is due to the bucket already existing or\n                already being created, no exception is raised.\n\n        """"""\n        if self.s3_resource is None:\n            s3 = self.boto_session.resource(""s3"", region_name=region)\n        else:\n            s3 = self.s3_resource\n\n        bucket = s3.Bucket(name=bucket_name)\n        if bucket.creation_date is None:\n            try:\n                if region == ""us-east-1"":\n                    # \'us-east-1\' cannot be specified because it is the default region:\n                    # https://github.com/boto/boto3/issues/125\n                    s3.create_bucket(Bucket=bucket_name)\n                else:\n                    s3.create_bucket(\n                        Bucket=bucket_name, CreateBucketConfiguration={""LocationConstraint"": region}\n                    )\n\n                LOGGER.info(""Created S3 bucket: %s"", bucket_name)\n            except ClientError as e:\n                error_code = e.response[""Error""][""Code""]\n                message = e.response[""Error""][""Message""]\n\n                if error_code == ""BucketAlreadyOwnedByYou"":\n                    pass\n                elif (\n                    error_code == ""OperationAborted""\n                    and ""conflicting conditional operation"" in message\n                ):\n                    # If this bucket is already being concurrently created, we don\'t need to create\n                    # it again.\n                    pass\n                else:\n                    raise\n\n    def train(  # noqa: C901\n        self,\n        input_mode,\n        input_config,\n        role,\n        job_name,\n        output_config,\n        resource_config,\n        vpc_config,\n        hyperparameters,\n        stop_condition,\n        tags,\n        metric_definitions,\n        enable_network_isolation=False,\n        image=None,\n        algorithm_arn=None,\n        encrypt_inter_container_traffic=False,\n        train_use_spot_instances=False,\n        checkpoint_s3_uri=None,\n        checkpoint_local_path=None,\n        experiment_config=None,\n        debugger_rule_configs=None,\n        debugger_hook_config=None,\n        tensorboard_output_config=None,\n        enable_sagemaker_metrics=None,\n    ):\n        """"""Create an Amazon SageMaker training job.\n\n        Args:\n            input_mode (str): The input mode that the algorithm supports. Valid modes:\n                * \'File\' - Amazon SageMaker copies the training dataset from the S3 location to\n                a directory in the Docker container.\n                * \'Pipe\' - Amazon SageMaker streams data directly from S3 to the container via a\n                Unix-named pipe.\n\n            input_config (list): A list of Channel objects. Each channel is a named input source.\n                Please refer to the format details described:\n                https://botocore.readthedocs.io/en/latest/reference/services/sagemaker.html#SageMaker.Client.create_training_job\n            role (str): An AWS IAM role (either name or full ARN). The Amazon SageMaker training\n                jobs and APIs that create Amazon SageMaker endpoints use this role to access\n                training data and model artifacts. You must grant sufficient permissions to this\n                role.\n            job_name (str): Name of the training job being created.\n            output_config (dict): The S3 URI where you want to store the training results and\n                optional KMS key ID.\n            resource_config (dict): Contains values for ResourceConfig:\n                * instance_count (int): Number of EC2 instances to use for training.\n                The key in resource_config is \'InstanceCount\'.\n                * instance_type (str): Type of EC2 instance to use for training, for example,\n                \'ml.c4.xlarge\'. The key in resource_config is \'InstanceType\'.\n\n            vpc_config (dict): Contains values for VpcConfig:\n                * subnets (list[str]): List of subnet ids.\n                The key in vpc_config is \'Subnets\'.\n                * security_group_ids (list[str]): List of security group ids.\n                The key in vpc_config is \'SecurityGroupIds\'.\n\n            hyperparameters (dict): Hyperparameters for model training. The hyperparameters are\n                made accessible as a dict[str, str] to the training code on SageMaker. For\n                convenience, this accepts other types for keys and values, but ``str()`` will be\n                called to convert them before training.\n            stop_condition (dict): Defines when training shall finish. Contains entries that can\n                be understood by the service like ``MaxRuntimeInSeconds``.\n            tags (list[dict]): List of tags for labeling a training job. For more, see\n                https://docs.aws.amazon.com/sagemaker/latest/dg/API_Tag.html.\n            metric_definitions (list[dict]): A list of dictionaries that defines the metric(s)\n                used to evaluate the training jobs. Each dictionary contains two keys: \'Name\' for\n                the name of the metric, and \'Regex\' for the regular expression used to extract the\n                metric from the logs.\n            enable_network_isolation (bool): Whether to request for the training job to run with\n                network isolation or not.\n            image (str): Docker image containing training code.\n            algorithm_arn (str): Algorithm Arn from Marketplace.\n            encrypt_inter_container_traffic (bool): Specifies whether traffic between training\n                containers is encrypted for the training job (default: ``False``).\n            train_use_spot_instances (bool): whether to use spot instances for training.\n            checkpoint_s3_uri (str): The S3 URI in which to persist checkpoints\n                that the algorithm persists (if any) during training. (default:\n                ``None``).\n            checkpoint_local_path (str): The local path that the algorithm\n                writes its checkpoints to. SageMaker will persist all files\n                under this path to `checkpoint_s3_uri` continually during\n                training. On job startup the reverse happens - data from the\n                s3 location is downloaded to this path before the algorithm is\n                started. If the path is unset then SageMaker assumes the\n                checkpoints will be provided under `/opt/ml/checkpoints/`.\n                (default: ``None``).\n            experiment_config (dict): Experiment management configuration. Dictionary contains\n                three optional keys, \'ExperimentName\', \'TrialName\', and \'TrialComponentDisplayName\'.\n                (default: ``None``)\n            enable_sagemaker_metrics (bool): enable SageMaker Metrics Time\n                Series. For more information see:\n                https://docs.aws.amazon.com/sagemaker/latest/dg/API_AlgorithmSpecification.html#SageMaker-Type-AlgorithmSpecification-EnableSageMakerMetricsTimeSeries\n                (default: ``None``).\n\n        Returns:\n            str: ARN of the training job, if it is created.\n        """"""\n\n        train_request = {\n            ""AlgorithmSpecification"": {""TrainingInputMode"": input_mode},\n            ""OutputDataConfig"": output_config,\n            ""TrainingJobName"": job_name,\n            ""StoppingCondition"": stop_condition,\n            ""ResourceConfig"": resource_config,\n            ""RoleArn"": role,\n        }\n\n        if image and algorithm_arn:\n            raise ValueError(\n                ""image and algorithm_arn are mutually exclusive.""\n                ""Both were provided: image: %s algorithm_arn: %s"" % (image, algorithm_arn)\n            )\n\n        if image is None and algorithm_arn is None:\n            raise ValueError(""either image or algorithm_arn is required. None was provided."")\n\n        if image is not None:\n            train_request[""AlgorithmSpecification""][""TrainingImage""] = image\n\n        if algorithm_arn is not None:\n            train_request[""AlgorithmSpecification""][""AlgorithmName""] = algorithm_arn\n\n        if input_config is not None:\n            train_request[""InputDataConfig""] = input_config\n\n        if metric_definitions is not None:\n            train_request[""AlgorithmSpecification""][""MetricDefinitions""] = metric_definitions\n\n        if enable_sagemaker_metrics is not None:\n            train_request[""AlgorithmSpecification""][\n                ""EnableSageMakerMetricsTimeSeries""\n            ] = enable_sagemaker_metrics\n\n        if hyperparameters and len(hyperparameters) > 0:\n            train_request[""HyperParameters""] = hyperparameters\n\n        if tags is not None:\n            train_request[""Tags""] = tags\n\n        if vpc_config is not None:\n            train_request[""VpcConfig""] = vpc_config\n\n        if experiment_config and len(experiment_config) > 0:\n            train_request[""ExperimentConfig""] = experiment_config\n\n        if enable_network_isolation:\n            train_request[""EnableNetworkIsolation""] = enable_network_isolation\n\n        if encrypt_inter_container_traffic:\n            train_request[""EnableInterContainerTrafficEncryption""] = encrypt_inter_container_traffic\n\n        if train_use_spot_instances:\n            train_request[""EnableManagedSpotTraining""] = train_use_spot_instances\n\n        if checkpoint_s3_uri:\n            checkpoint_config = {""S3Uri"": checkpoint_s3_uri}\n            if checkpoint_local_path:\n                checkpoint_config[""LocalPath""] = checkpoint_local_path\n            train_request[""CheckpointConfig""] = checkpoint_config\n\n        if debugger_rule_configs is not None:\n            train_request[""DebugRuleConfigurations""] = debugger_rule_configs\n\n        if debugger_hook_config is not None:\n            train_request[""DebugHookConfig""] = debugger_hook_config\n\n        if tensorboard_output_config is not None:\n            train_request[""TensorBoardOutputConfig""] = tensorboard_output_config\n\n        LOGGER.info(""Creating training-job with name: %s"", job_name)\n        LOGGER.debug(""train request: %s"", json.dumps(train_request, indent=4))\n        self.sagemaker_client.create_training_job(**train_request)\n\n    def process(\n        self,\n        inputs,\n        output_config,\n        job_name,\n        resources,\n        stopping_condition,\n        app_specification,\n        environment,\n        network_config,\n        role_arn,\n        tags,\n        experiment_config=None,\n    ):\n        """"""Create an Amazon SageMaker processing job.\n\n        Args:\n            inputs ([dict]): List of up to 10 ProcessingInput dictionaries.\n            output_config (dict): A config dictionary, which contains a list of up\n                to 10 ProcessingOutput dictionaries, as well as an optional KMS key ID.\n            job_name (str): The name of the processing job. The name must be unique\n                within an AWS Region in an AWS account. Names should have minimum\n                length of 1 and maximum length of 63 characters.\n            resources (dict): Encapsulates the resources, including ML instances\n                and storage, to use for the processing job.\n            stopping_condition (dict[str,int]): Specifies a limit to how long\n                the processing job can run, in seconds.\n            app_specification (dict[str,str]): Configures the processing job to\n                run the given image. Details are in the processing container\n                specification.\n            environment (dict): Environment variables to start the processing\n                container with.\n            network_config (dict): Specifies networking options, such as network\n                traffic encryption between processing containers, whether to allow\n                inbound and outbound network calls to and from processing containers,\n                and VPC subnets and security groups to use for VPC-enabled processing\n                jobs.\n            role_arn (str): The Amazon Resource Name (ARN) of an IAM role that\n                Amazon SageMaker can assume to perform tasks on your behalf.\n            tags ([dict[str,str]]): A list of dictionaries containing key-value\n                pairs.\n            experiment_config (dict): Experiment management configuration. Dictionary contains\n                three optional keys, \'ExperimentName\', \'TrialName\', and \'TrialComponentDisplayName\'.\n                (default: ``None``)\n        """"""\n        process_request = {\n            ""ProcessingJobName"": job_name,\n            ""ProcessingResources"": resources,\n            ""AppSpecification"": app_specification,\n            ""RoleArn"": role_arn,\n        }\n\n        if inputs:\n            process_request[""ProcessingInputs""] = inputs\n\n        if output_config[""Outputs""]:\n            process_request[""ProcessingOutputConfig""] = output_config\n\n        if environment is not None:\n            process_request[""Environment""] = environment\n\n        if network_config is not None:\n            process_request[""NetworkConfig""] = network_config\n\n        if stopping_condition is not None:\n            process_request[""StoppingCondition""] = stopping_condition\n\n        if tags is not None:\n            process_request[""Tags""] = tags\n\n        if experiment_config:\n            process_request[""ExperimentConfig""] = experiment_config\n\n        LOGGER.info(""Creating processing-job with name %s"", job_name)\n        LOGGER.debug(""process request: %s"", json.dumps(process_request, indent=4))\n        self.sagemaker_client.create_processing_job(**process_request)\n\n    def create_monitoring_schedule(\n        self,\n        monitoring_schedule_name,\n        schedule_expression,\n        statistics_s3_uri,\n        constraints_s3_uri,\n        monitoring_inputs,\n        monitoring_output_config,\n        instance_count,\n        instance_type,\n        volume_size_in_gb,\n        volume_kms_key,\n        image_uri,\n        entrypoint,\n        arguments,\n        record_preprocessor_source_uri,\n        post_analytics_processor_source_uri,\n        max_runtime_in_seconds,\n        environment,\n        network_config,\n        role_arn,\n        tags,\n    ):\n        """"""Create an Amazon SageMaker monitoring schedule.\n\n        Args:\n            monitoring_schedule_name (str): The name of the monitoring schedule. The name must be\n                unique within an AWS Region in an AWS account. Names should have a minimum length\n                of 1 and a maximum length of 63 characters.\n            schedule_expression (str): The cron expression that dictates the monitoring execution\n                schedule.\n            statistics_s3_uri (str): The S3 uri of the statistics file to use.\n            constraints_s3_uri (str): The S3 uri of the constraints file to use.\n            monitoring_inputs ([dict]): List of MonitoringInput dictionaries.\n            monitoring_output_config (dict): A config dictionary, which contains a list of\n                MonitoringOutput dictionaries, as well as an optional KMS key ID.\n            instance_count (int): The number of instances to run.\n            instance_type (str): The type of instance to run.\n            volume_size_in_gb (int): Size of the volume in GB.\n            volume_kms_key (str): KMS key to use when encrypting the volume.\n            image_uri (str): The image uri to use for monitoring executions.\n            entrypoint (str): The entrypoint to the monitoring execution image.\n            arguments (str): The arguments to pass to the monitoring execution image.\n            record_preprocessor_source_uri (str or None): The S3 uri that points to the script that\n                pre-processes the dataset (only applicable to first-party images).\n            post_analytics_processor_source_uri (str or None): The S3 uri that points to the script\n                that post-processes the dataset (only applicable to first-party images).\n            max_runtime_in_seconds (int): Specifies a limit to how long\n                the processing job can run, in seconds.\n            environment (dict): Environment variables to start the monitoring execution\n                container with.\n            network_config (dict): Specifies networking options, such as network\n                traffic encryption between processing containers, whether to allow\n                inbound and outbound network calls to and from processing containers,\n                and VPC subnets and security groups to use for VPC-enabled processing\n                jobs.\n            role_arn (str): The Amazon Resource Name (ARN) of an IAM role that\n                Amazon SageMaker can assume to perform tasks on your behalf.\n            tags ([dict[str,str]]): A list of dictionaries containing key-value\n                pairs.\n\n        """"""\n        monitoring_schedule_request = {\n            ""MonitoringScheduleName"": monitoring_schedule_name,\n            ""MonitoringScheduleConfig"": {\n                ""MonitoringJobDefinition"": {\n                    ""MonitoringInputs"": monitoring_inputs,\n                    ""MonitoringResources"": {\n                        ""ClusterConfig"": {\n                            ""InstanceCount"": instance_count,\n                            ""InstanceType"": instance_type,\n                            ""VolumeSizeInGB"": volume_size_in_gb,\n                        }\n                    },\n                    ""MonitoringAppSpecification"": {""ImageUri"": image_uri},\n                    ""RoleArn"": role_arn,\n                }\n            },\n        }\n\n        if schedule_expression is not None:\n            monitoring_schedule_request[""MonitoringScheduleConfig""][""ScheduleConfig""] = {\n                ""ScheduleExpression"": schedule_expression\n            }\n\n        if monitoring_output_config is not None:\n            monitoring_schedule_request[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n                ""MonitoringOutputConfig""\n            ] = monitoring_output_config\n\n        if statistics_s3_uri is not None or constraints_s3_uri is not None:\n            monitoring_schedule_request[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n                ""BaselineConfig""\n            ] = {}\n\n        if statistics_s3_uri is not None:\n            monitoring_schedule_request[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n                ""BaselineConfig""\n            ][""StatisticsResource""] = {""S3Uri"": statistics_s3_uri}\n\n        if constraints_s3_uri is not None:\n            monitoring_schedule_request[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n                ""BaselineConfig""\n            ][""ConstraintsResource""] = {""S3Uri"": constraints_s3_uri}\n\n        if record_preprocessor_source_uri is not None:\n            monitoring_schedule_request[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n                ""MonitoringAppSpecification""\n            ][""RecordPreprocessorSourceUri""] = record_preprocessor_source_uri\n\n        if post_analytics_processor_source_uri is not None:\n            monitoring_schedule_request[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n                ""MonitoringAppSpecification""\n            ][""PostAnalyticsProcessorSourceUri""] = post_analytics_processor_source_uri\n\n        if entrypoint is not None:\n            monitoring_schedule_request[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n                ""MonitoringAppSpecification""\n            ][""ContainerEntrypoint""] = entrypoint\n\n        if arguments is not None:\n            monitoring_schedule_request[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n                ""MonitoringAppSpecification""\n            ][""ContainerArguments""] = arguments\n\n        if volume_kms_key is not None:\n            monitoring_schedule_request[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n                ""MonitoringResources""\n            ][""ClusterConfig""][""VolumeKmsKeyId""] = volume_kms_key\n\n        if max_runtime_in_seconds is not None:\n            monitoring_schedule_request[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n                ""StoppingCondition""\n            ] = {""MaxRuntimeInSeconds"": max_runtime_in_seconds}\n\n        if environment is not None:\n            monitoring_schedule_request[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n                ""Environment""\n            ] = environment\n\n        if network_config is not None:\n            monitoring_schedule_request[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n                ""NetworkConfig""\n            ] = network_config\n\n        if tags is not None:\n            monitoring_schedule_request[""Tags""] = tags\n\n        LOGGER.info(""Creating monitoring schedule name %s."", monitoring_schedule_name)\n        LOGGER.debug(\n            ""monitoring_schedule_request= %s"", json.dumps(monitoring_schedule_request, indent=4)\n        )\n        self.sagemaker_client.create_monitoring_schedule(**monitoring_schedule_request)\n\n    def update_monitoring_schedule(\n        self,\n        monitoring_schedule_name,\n        schedule_expression=None,\n        statistics_s3_uri=None,\n        constraints_s3_uri=None,\n        monitoring_inputs=None,\n        monitoring_output_config=None,\n        instance_count=None,\n        instance_type=None,\n        volume_size_in_gb=None,\n        volume_kms_key=None,\n        image_uri=None,\n        entrypoint=None,\n        arguments=None,\n        record_preprocessor_source_uri=None,\n        post_analytics_processor_source_uri=None,\n        max_runtime_in_seconds=None,\n        environment=None,\n        network_config=None,\n        role_arn=None,\n    ):\n        """"""Update an Amazon SageMaker monitoring schedule.\n\n        Args:\n            monitoring_schedule_name (str): The name of the monitoring schedule. The name must be\n                unique within an AWS Region in an AWS account. Names should have a minimum length\n                of 1 and a maximum length of 63 characters.\n            schedule_expression (str): The cron expression that dictates the monitoring execution\n                schedule.\n            statistics_s3_uri (str): The S3 uri of the statistics file to use.\n            constraints_s3_uri (str): The S3 uri of the constraints file to use.\n            monitoring_inputs ([dict]): List of MonitoringInput dictionaries.\n            monitoring_output_config (dict): A config dictionary, which contains a list of\n                MonitoringOutput dictionaries, as well as an optional KMS key ID.\n            instance_count (int): The number of instances to run.\n            instance_type (str): The type of instance to run.\n            volume_size_in_gb (int): Size of the volume in GB.\n            volume_kms_key (str): KMS key to use when encrypting the volume.\n            image_uri (str): The image uri to use for monitoring executions.\n            entrypoint (str): The entrypoint to the monitoring execution image.\n            arguments (str): The arguments to pass to the monitoring execution image.\n            record_preprocessor_source_uri (str or None): The S3 uri that points to the script that\n                pre-processes the dataset (only applicable to first-party images).\n            post_analytics_processor_source_uri (str or None): The S3 uri that points to the script\n                that post-processes the dataset (only applicable to first-party images).\n            max_runtime_in_seconds (int): Specifies a limit to how long\n                the processing job can run, in seconds.\n            environment (dict): Environment variables to start the monitoring execution\n                container with.\n            network_config (dict): Specifies networking options, such as network\n                traffic encryption between processing containers, whether to allow\n                inbound and outbound network calls to and from processing containers,\n                and VPC subnets and security groups to use for VPC-enabled processing\n                jobs.\n            role_arn (str): The Amazon Resource Name (ARN) of an IAM role that\n                Amazon SageMaker can assume to perform tasks on your behalf.\n            tags ([dict[str,str]]): A list of dictionaries containing key-value\n                pairs.\n\n        """"""\n        existing_desc = self.sagemaker_client.describe_monitoring_schedule(\n            MonitoringScheduleName=monitoring_schedule_name\n        )\n\n        existing_schedule_config = None\n        if (\n            existing_desc.get(""MonitoringScheduleConfig"") is not None\n            and existing_desc[""MonitoringScheduleConfig""].get(""ScheduleConfig"") is not None\n            and existing_desc[""MonitoringScheduleConfig""][""ScheduleConfig""][""ScheduleExpression""]\n            is not None\n        ):\n            existing_schedule_config = existing_desc[""MonitoringScheduleConfig""][""ScheduleConfig""][\n                ""ScheduleExpression""\n            ]\n\n        request_schedule_expression = schedule_expression or existing_schedule_config\n        request_monitoring_inputs = (\n            monitoring_inputs\n            or existing_desc[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n                ""MonitoringInputs""\n            ]\n        )\n        request_instance_count = (\n            instance_count\n            or existing_desc[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n                ""MonitoringResources""\n            ][""ClusterConfig""][""InstanceCount""]\n        )\n        request_instance_type = (\n            instance_type\n            or existing_desc[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n                ""MonitoringResources""\n            ][""ClusterConfig""][""InstanceType""]\n        )\n        request_volume_size_in_gb = (\n            volume_size_in_gb\n            or existing_desc[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n                ""MonitoringResources""\n            ][""ClusterConfig""][""VolumeSizeInGB""]\n        )\n        request_image_uri = (\n            image_uri\n            or existing_desc[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n                ""MonitoringAppSpecification""\n            ][""ImageUri""]\n        )\n        request_role_arn = (\n            role_arn\n            or existing_desc[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][""RoleArn""]\n        )\n\n        monitoring_schedule_request = {\n            ""MonitoringScheduleName"": monitoring_schedule_name,\n            ""MonitoringScheduleConfig"": {\n                ""MonitoringJobDefinition"": {\n                    ""MonitoringInputs"": request_monitoring_inputs,\n                    ""MonitoringResources"": {\n                        ""ClusterConfig"": {\n                            ""InstanceCount"": request_instance_count,\n                            ""InstanceType"": request_instance_type,\n                            ""VolumeSizeInGB"": request_volume_size_in_gb,\n                        }\n                    },\n                    ""MonitoringAppSpecification"": {""ImageUri"": request_image_uri},\n                    ""RoleArn"": request_role_arn,\n                }\n            },\n        }\n\n        if existing_schedule_config is not None:\n            monitoring_schedule_request[""MonitoringScheduleConfig""][""ScheduleConfig""] = {\n                ""ScheduleExpression"": request_schedule_expression\n            }\n\n        existing_monitoring_output_config = existing_desc[""MonitoringScheduleConfig""][\n            ""MonitoringJobDefinition""\n        ].get(""MonitoringOutputConfig"")\n        if monitoring_output_config is not None or existing_monitoring_output_config is not None:\n            monitoring_schedule_request[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n                ""MonitoringOutputConfig""\n            ] = (monitoring_output_config or existing_monitoring_output_config)\n\n        existing_statistics_s3_uri = None\n        existing_constraints_s3_uri = None\n        if (\n            existing_desc[""MonitoringScheduleConfig""][""MonitoringJobDefinition""].get(\n                ""BaselineConfig""\n            )\n            is not None\n        ):\n            if (\n                existing_desc[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n                    ""BaselineConfig""\n                ].get(""StatisticsResource"")\n                is not None\n            ):\n                existing_statistics_s3_uri = existing_desc[""MonitoringScheduleConfig""][\n                    ""MonitoringJobDefinition""\n                ][""BaselineConfig""][""StatisticsResource""][""S3Uri""]\n\n            if (\n                existing_desc[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n                    ""BaselineConfig""\n                ].get(""ConstraintsResource"")\n                is not None\n            ):\n                existing_statistics_s3_uri = existing_desc[""MonitoringScheduleConfig""][\n                    ""MonitoringJobDefinition""\n                ][""BaselineConfig""][""ConstraintsResource""][""S3Uri""]\n\n        if (\n            statistics_s3_uri is not None\n            or constraints_s3_uri is not None\n            or existing_statistics_s3_uri is not None\n            or existing_constraints_s3_uri is not None\n        ):\n            monitoring_schedule_request[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n                ""BaselineConfig""\n            ] = {}\n\n        if statistics_s3_uri is not None or existing_statistics_s3_uri is not None:\n            monitoring_schedule_request[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n                ""BaselineConfig""\n            ][""StatisticsResource""] = {""S3Uri"": statistics_s3_uri or existing_statistics_s3_uri}\n\n        if constraints_s3_uri is not None or existing_constraints_s3_uri is not None:\n            monitoring_schedule_request[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n                ""BaselineConfig""\n            ][""ConstraintsResource""] = {""S3Uri"": constraints_s3_uri or existing_constraints_s3_uri}\n\n        existing_record_preprocessor_source_uri = existing_desc[""MonitoringScheduleConfig""][\n            ""MonitoringJobDefinition""\n        ][""MonitoringAppSpecification""].get(""RecordPreprocessorSourceUri"")\n        if (\n            record_preprocessor_source_uri is not None\n            or existing_record_preprocessor_source_uri is not None\n        ):\n            monitoring_schedule_request[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n                ""MonitoringAppSpecification""\n            ][""RecordPreprocessorSourceUri""] = (\n                record_preprocessor_source_uri or existing_record_preprocessor_source_uri\n            )\n\n        existing_post_analytics_processor_source_uri = existing_desc[""MonitoringScheduleConfig""][\n            ""MonitoringJobDefinition""\n        ][""MonitoringAppSpecification""].get(""PostAnalyticsProcessorSourceUri"")\n        if (\n            post_analytics_processor_source_uri is not None\n            or existing_post_analytics_processor_source_uri is not None\n        ):\n            monitoring_schedule_request[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n                ""MonitoringAppSpecification""\n            ][""PostAnalyticsProcessorSourceUri""] = (\n                post_analytics_processor_source_uri or existing_post_analytics_processor_source_uri\n            )\n\n        existing_entrypoint = existing_desc[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringAppSpecification""\n        ].get(""ContainerEntrypoint"")\n        if entrypoint is not None or existing_entrypoint is not None:\n            monitoring_schedule_request[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n                ""MonitoringAppSpecification""\n            ][""ContainerEntrypoint""] = (entrypoint or existing_entrypoint)\n\n        existing_arguments = existing_desc[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringAppSpecification""\n        ].get(""ContainerArguments"")\n        if arguments is not None or existing_arguments is not None:\n            monitoring_schedule_request[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n                ""MonitoringAppSpecification""\n            ][""ContainerArguments""] = (arguments or existing_arguments)\n\n        existing_volume_kms_key = existing_desc[""MonitoringScheduleConfig""][\n            ""MonitoringJobDefinition""\n        ][""MonitoringResources""][""ClusterConfig""].get(""VolumeKmsKeyId"")\n\n        if volume_kms_key is not None or existing_volume_kms_key is not None:\n            monitoring_schedule_request[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n                ""MonitoringResources""\n            ][""ClusterConfig""][""VolumeKmsKeyId""] = (volume_kms_key or existing_volume_kms_key)\n\n        existing_max_runtime_in_seconds = None\n        if existing_desc[""MonitoringScheduleConfig""][""MonitoringJobDefinition""].get(\n            ""StoppingCondition""\n        ):\n            existing_max_runtime_in_seconds = existing_desc[""MonitoringScheduleConfig""][\n                ""MonitoringJobDefinition""\n            ][""StoppingCondition""].get(""MaxRuntimeInSeconds"")\n\n        if max_runtime_in_seconds is not None or existing_max_runtime_in_seconds is not None:\n            monitoring_schedule_request[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n                ""StoppingCondition""\n            ] = {""MaxRuntimeInSeconds"": max_runtime_in_seconds or existing_max_runtime_in_seconds}\n\n        existing_environment = existing_desc[""MonitoringScheduleConfig""][\n            ""MonitoringJobDefinition""\n        ].get(""Environment"")\n        if environment is not None or existing_environment is not None:\n            monitoring_schedule_request[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n                ""Environment""\n            ] = (environment or existing_environment)\n\n        existing_network_config = existing_desc[""MonitoringScheduleConfig""][\n            ""MonitoringJobDefinition""\n        ].get(""NetworkConfig"")\n        if network_config is not None or existing_network_config is not None:\n            monitoring_schedule_request[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n                ""NetworkConfig""\n            ] = (network_config or existing_network_config)\n\n        LOGGER.info(""Updating monitoring schedule with name: %s ."", monitoring_schedule_name)\n        LOGGER.debug(\n            ""monitoring_schedule_request= %s"", json.dumps(monitoring_schedule_request, indent=4)\n        )\n        self.sagemaker_client.update_monitoring_schedule(**monitoring_schedule_request)\n\n    def start_monitoring_schedule(self, monitoring_schedule_name):\n        """"""Starts a monitoring schedule.\n\n        Args:\n            monitoring_schedule_name (str): The name of the Amazon SageMaker Monitoring\n                Schedule to start.\n\n        """"""\n        print()\n        print(""Starting Monitoring Schedule with name: {}"".format(monitoring_schedule_name))\n        self.sagemaker_client.start_monitoring_schedule(\n            MonitoringScheduleName=monitoring_schedule_name\n        )\n\n    def stop_monitoring_schedule(self, monitoring_schedule_name):\n        """"""Stops a monitoring schedule.\n\n        Args:\n            monitoring_schedule_name (str): The name of the Amazon SageMaker Monitoring\n                Schedule to stop.\n\n        """"""\n        print()\n        print(""Stopping Monitoring Schedule with name: {}"".format(monitoring_schedule_name))\n        self.sagemaker_client.stop_monitoring_schedule(\n            MonitoringScheduleName=monitoring_schedule_name\n        )\n\n    def delete_monitoring_schedule(self, monitoring_schedule_name):\n        """"""Deletes a monitoring schedule.\n\n        Args:\n            monitoring_schedule_name (str): The name of the Amazon SageMaker Monitoring\n                Schedule to delete.\n\n        """"""\n        print()\n        print(""Deleting Monitoring Schedule with name: {}"".format(monitoring_schedule_name))\n        self.sagemaker_client.delete_monitoring_schedule(\n            MonitoringScheduleName=monitoring_schedule_name\n        )\n\n    def describe_monitoring_schedule(self, monitoring_schedule_name):\n        """"""Calls the DescribeMonitoringSchedule API for the given monitoring schedule name\n        and returns the response.\n\n        Args:\n            monitoring_schedule_name (str): The name of the processing job to describe.\n\n        Returns:\n            dict: A dictionary response with the processing job description.\n\n        """"""\n        return self.sagemaker_client.describe_monitoring_schedule(\n            MonitoringScheduleName=monitoring_schedule_name\n        )\n\n    def list_monitoring_executions(\n        self,\n        monitoring_schedule_name,\n        sort_by=""ScheduledTime"",\n        sort_order=""Descending"",\n        max_results=100,\n    ):\n        """"""Lists the monitoring executions associated with the given monitoring_schedule_name.\n\n        Args:\n            monitoring_schedule_name (str): The monitoring_schedule_name for which to retrieve the\n                monitoring executions.\n            sort_by (str): The field to sort by. Can be one of: ""CreationTime"", ""ScheduledTime"",\n                ""Status"". Default: ""ScheduledTime"".\n            sort_order (str): The sort order. Can be one of: ""Ascending"", ""Descending"".\n                Default: ""Descending"".\n            max_results (int): The maximum number of results to return. Must be between 1 and 100.\n\n        Returns:\n            dict: Dictionary of monitoring schedule executions.\n        """"""\n        response = self.sagemaker_client.list_monitoring_executions(\n            MonitoringScheduleName=monitoring_schedule_name,\n            SortBy=sort_by,\n            SortOrder=sort_order,\n            MaxResults=max_results,\n        )\n        return response\n\n    def list_monitoring_schedules(\n        self, endpoint_name=None, sort_by=""CreationTime"", sort_order=""Descending"", max_results=100\n    ):\n        """"""Lists the monitoring executions associated with the given monitoring_schedule_name.\n\n        Args:\n            endpoint_name (str): The name of the endpoint to filter on. If not provided, does not\n                filter on it. Default: None.\n            sort_by (str): The field to sort by. Can be one of: ""Name"", ""CreationTime"", ""Status"".\n                Default: ""CreationTime"".\n            sort_order (str): The sort order. Can be one of: ""Ascending"", ""Descending"".\n                Default: ""Descending"".\n            max_results (int): The maximum number of results to return. Must be between 1 and 100.\n\n        Returns:\n            dict: Dictionary of monitoring schedule executions.\n        """"""\n        if endpoint_name is not None:\n            response = self.sagemaker_client.list_monitoring_schedules(\n                EndpointName=endpoint_name,\n                SortBy=sort_by,\n                SortOrder=sort_order,\n                MaxResults=max_results,\n            )\n        else:\n            response = self.sagemaker_client.list_monitoring_schedules(\n                SortBy=sort_by, SortOrder=sort_order, MaxResults=max_results\n            )\n\n        return response\n\n    def was_processing_job_successful(self, job_name):\n        """"""Calls the DescribeProcessingJob API for the given job name\n        and returns the True if the job was successful. False otherwise.\n\n        Args:\n            job_name (str): The name of the processing job to describe.\n\n        Returns:\n            bool: Whether the processing job was successful.\n        """"""\n        job_desc = self.sagemaker_client.describe_processing_job(ProcessingJobName=job_name)\n        return job_desc[""ProcessingJobStatus""] == ""Completed""\n\n    def describe_processing_job(self, job_name):\n        """"""Calls the DescribeProcessingJob API for the given job name\n        and returns the response.\n\n        Args:\n            job_name (str): The name of the processing job to describe.\n\n        Returns:\n            dict: A dictionary response with the processing job description.\n        """"""\n        return self.sagemaker_client.describe_processing_job(ProcessingJobName=job_name)\n\n    def stop_processing_job(self, job_name):\n        """"""Calls the StopProcessingJob API for the given job name.\n\n        Args:\n            job_name (str): The name of the processing job to stop.\n\n        """"""\n        self.sagemaker_client.stop_processing_job(ProcessingJobName=job_name)\n\n    def stop_training_job(self, job_name):\n        """"""Calls the StopTrainingJob API for the given job name.\n\n        Args:\n            job_name (str): The name of the training job to stop.\n        """"""\n        self.sagemaker_client.stop_training_job(TrainingJobName=job_name)\n\n    def describe_training_job(self, job_name):\n        """"""Calls the DescribeTrainingJob API for the given job name\n        and returns the response.\n\n        Args:\n            job_name (str): The name of the training job to describe.\n\n        Returns:\n            dict: A dictionary response with the training job description.\n        """"""\n        return self.sagemaker_client.describe_training_job(TrainingJobName=job_name)\n\n    def auto_ml(\n        self,\n        input_config,\n        output_config,\n        auto_ml_job_config,\n        role,\n        job_name,\n        problem_type=None,\n        job_objective=None,\n        generate_candidate_definitions_only=False,\n        tags=None,\n    ):\n        """"""Create an Amazon SageMaker AutoML job.\n\n        Args:\n            input_config (list[dict]): A list of Channel objects. Each channel contains ""DataSource""\n                and ""TargetAttributeName"", ""CompressionType"" is an optional field.\n            output_config (dict): The S3 URI where you want to store the training results and\n                optional KMS key ID.\n            auto_ml_job_config (dict): A dict of AutoMLJob config, containing ""StoppingCondition"",\n                ""SecurityConfig"", optionally contains ""VolumeKmsKeyId"".\n            role (str): The Amazon Resource Name (ARN) of an IAM role that\n                Amazon SageMaker can assume to perform tasks on your behalf.\n            job_name (str): A string that can be used to identify an AutoMLJob. Each AutoMLJob\n                should have a unique job name.\n            problem_type (str): The type of problem of this AutoMLJob. Valid values are\n                ""Regression"", ""BinaryClassification"", ""MultiClassClassification"". If None,\n                SageMaker AutoMLJob will infer the problem type automatically.\n            job_objective (dict): AutoMLJob objective, contains ""AutoMLJobObjectiveType"" (optional),\n                ""MetricName"" and ""Value"".\n            generate_candidate_definitions_only (bool): Indicates whether to only generate candidate\n                definitions. If True, AutoML.list_candidates() cannot be called. Default: False.\n            tags ([dict[str,str]]): A list of dictionaries containing key-value\n                pairs.\n\n        Returns:\n\n        """"""\n        auto_ml_job_request = {\n            ""AutoMLJobName"": job_name,\n            ""InputDataConfig"": input_config,\n            ""OutputDataConfig"": output_config,\n            ""AutoMLJobConfig"": auto_ml_job_config,\n            ""RoleArn"": role,\n            ""GenerateCandidateDefinitionsOnly"": generate_candidate_definitions_only,\n        }\n\n        if job_objective is not None:\n            auto_ml_job_request[""AutoMLJobObjective""] = job_objective\n        if problem_type is not None:\n            auto_ml_job_request[""ProblemType""] = problem_type\n        if tags is not None:\n            auto_ml_job_request[""Tags""] = tags\n\n        LOGGER.info(""Creating auto-ml-job with name: %s"", job_name)\n        LOGGER.debug(""auto ml request: %s"", json.dumps(auto_ml_job_request, indent=4))\n        self.sagemaker_client.create_auto_ml_job(**auto_ml_job_request)\n\n    def describe_auto_ml_job(self, job_name):\n        """"""Calls the DescribeAutoMLJob API for the given job name\n        and returns the response.\n        Args:\n            job_name (str): The name of the AutoML job to describe.\n        Returns:\n            dict: A dictionary response with the AutoML Job description.\n        """"""\n        return self.sagemaker_client.describe_auto_ml_job(AutoMLJobName=job_name)\n\n    def list_candidates(\n        self,\n        job_name,\n        status_equals=None,\n        candidate_name=None,\n        candidate_arn=None,\n        sort_order=None,\n        sort_by=None,\n        max_results=None,\n    ):\n        """"""Returns the list of candidates of an AutoML job for a given name.\n\n        Args:\n            job_name (str): The name of the AutoML job. If None, will use object\'s\n                latest_auto_ml_job name.\n            status_equals (str): Filter the result with candidate status, values could be\n                ""Completed"", ""InProgress"", ""Failed"", ""Stopped"", ""Stopping""\n            candidate_name (str): The name of a specified candidate to list.\n                Default to None.\n            candidate_arn (str): The Arn of a specified candidate to list.\n                Default to None.\n            sort_order (str): The order that the candidates will be listed in result.\n                Default to None.\n            sort_by (str): The value that the candidates will be sorted by.\n                Default to None.\n            max_results (int): The number of candidates will be listed in results,\n                between 1 to 100. Default to None. If None, will return all the candidates.\n        Returns:\n            list: A list of dictionaries with candidates information\n        """"""\n        list_candidates_args = {""AutoMLJobName"": job_name}\n\n        if status_equals:\n            list_candidates_args[""StatusEquals""] = status_equals\n        if candidate_name:\n            list_candidates_args[""CandidateNameEquals""] = candidate_name\n        if candidate_arn:\n            list_candidates_args[""CandidateArnEquals""] = candidate_arn\n        if sort_order:\n            list_candidates_args[""SortOrder""] = sort_order\n        if sort_by:\n            list_candidates_args[""SortBy""] = sort_by\n        if max_results:\n            list_candidates_args[""MaxResults""] = max_results\n\n        return self.sagemaker_client.list_candidates_for_auto_ml_job(**list_candidates_args)\n\n    def wait_for_auto_ml_job(self, job, poll=5):\n        """"""Wait for an Amazon SageMaker AutoML job to complete.\n\n        Args:\n            job (str): Name of the auto ml job to wait for.\n            poll (int): Polling interval in seconds (default: 5).\n        Returns:\n            (dict): Return value from the ``DescribeAutoMLJob`` API.\n        Raises:\n            exceptions.UnexpectedStatusException: If the auto ml job fails.\n        """"""\n        desc = _wait_until(lambda: _auto_ml_job_status(self.sagemaker_client, job), poll)\n        self._check_job_status(job, desc, ""AutoMLJobStatus"")\n        return desc\n\n    def logs_for_auto_ml_job(  # noqa: C901 - suppress complexity warning for this method\n        self, job_name, wait=False, poll=10\n    ):\n        """"""Display the logs for a given AutoML job, optionally tailing them until the\n        job is complete. If the output is a tty or a Jupyter cell, it will be color-coded\n        based on which instance the log entry is from.\n\n        Args:\n            job_name (str): Name of the Auto ML job to display the logs for.\n            wait (bool): Whether to keep looking for new log entries until the job completes\n                (default: False).\n            poll (int): The interval in seconds between polling for new log entries and job\n                completion (default: 5).\n\n        Raises:\n            exceptions.UnexpectedStatusException: If waiting and the training job fails.\n        """"""\n\n        description = self.sagemaker_client.describe_auto_ml_job(AutoMLJobName=job_name)\n\n        instance_count, stream_names, positions, client, log_group, dot, color_wrap = _logs_init(\n            self, description, job=""AutoML""\n        )\n\n        state = _get_initial_job_state(description, ""AutoMLJobStatus"", wait)\n\n        # The loop below implements a state machine that alternates between checking the job status\n        # and reading whatever is available in the logs at this point. Note, that if we were\n        # called with wait == False, we never check the job status.\n        #\n        # If wait == TRUE and job is not completed, the initial state is TAILING\n        # If wait == FALSE, the initial state is COMPLETE (doesn\'t matter if the job really is\n        # complete).\n        #\n        # The state table:\n        #\n        # STATE               ACTIONS                        CONDITION             NEW STATE\n        # ----------------    ----------------               -----------------     ----------------\n        # TAILING             Read logs, Pause, Get status   Job complete          JOB_COMPLETE\n        #                                                    Else                  TAILING\n        # JOB_COMPLETE        Read logs, Pause               Any                   COMPLETE\n        # COMPLETE            Read logs, Exit                                      N/A\n        #\n        # Notes:\n        # - The JOB_COMPLETE state forces us to do an extra pause and read any items that got to\n        #   Cloudwatch after the job was marked complete.\n        last_describe_job_call = time.time()\n        while True:\n            _flush_log_streams(\n                stream_names,\n                instance_count,\n                client,\n                log_group,\n                job_name,\n                positions,\n                dot,\n                color_wrap,\n            )\n            if state == LogState.COMPLETE:\n                break\n\n            time.sleep(poll)\n\n            if state == LogState.JOB_COMPLETE:\n                state = LogState.COMPLETE\n            elif time.time() - last_describe_job_call >= 30:\n                description = self.sagemaker_client.describe_auto_ml_job(AutoMLJobName=job_name)\n                last_describe_job_call = time.time()\n\n                status = description[""AutoMLJobStatus""]\n\n                if status in (""Completed"", ""Failed"", ""Stopped""):\n                    print()\n                    state = LogState.JOB_COMPLETE\n\n        if wait:\n            self._check_job_status(job_name, description, ""AutoMLJobStatus"")\n            if dot:\n                print()\n\n    def compile_model(\n        self, input_model_config, output_model_config, role, job_name, stop_condition, tags\n    ):\n        """"""Create an Amazon SageMaker Neo compilation job.\n\n        Args:\n            input_model_config (dict): the trained model and the Amazon S3 location where it is\n                stored.\n            output_model_config (dict): Identifies the Amazon S3 location where you want Amazon\n                SageMaker Neo to save the results of compilation job\n            role (str): An AWS IAM role (either name or full ARN). The Amazon SageMaker Neo\n                compilation jobs use this role to access model artifacts. You must grant\n                sufficient permissions to this role.\n            job_name (str): Name of the compilation job being created.\n            stop_condition (dict): Defines when compilation job shall finish. Contains entries\n                that can be understood by the service like ``MaxRuntimeInSeconds``.\n            tags (list[dict]): List of tags for labeling a compile model job. For more, see\n                https://docs.aws.amazon.com/sagemaker/latest/dg/API_Tag.html.\n\n        Returns:\n            str: ARN of the compile model job, if it is created.\n\n        """"""\n        compilation_job_request = {\n            ""InputConfig"": input_model_config,\n            ""OutputConfig"": output_model_config,\n            ""RoleArn"": role,\n            ""StoppingCondition"": stop_condition,\n            ""CompilationJobName"": job_name,\n        }\n\n        if tags is not None:\n            compilation_job_request[""Tags""] = tags\n\n        LOGGER.info(""Creating compilation-job with name: %s"", job_name)\n        self.sagemaker_client.create_compilation_job(**compilation_job_request)\n\n    def tune(  # noqa: C901\n        self,\n        job_name,\n        strategy,\n        objective_type,\n        objective_metric_name,\n        max_jobs,\n        max_parallel_jobs,\n        parameter_ranges,\n        static_hyperparameters,\n        input_mode,\n        metric_definitions,\n        role,\n        input_config,\n        output_config,\n        resource_config,\n        stop_condition,\n        tags,\n        warm_start_config,\n        enable_network_isolation=False,\n        image=None,\n        algorithm_arn=None,\n        early_stopping_type=""Off"",\n        encrypt_inter_container_traffic=False,\n        vpc_config=None,\n        train_use_spot_instances=False,\n        checkpoint_s3_uri=None,\n        checkpoint_local_path=None,\n    ):\n        """"""Create an Amazon SageMaker hyperparameter tuning job\n\n        Args:\n            job_name (str): Name of the tuning job being created.\n            strategy (str): Strategy to be used for hyperparameter estimations.\n            objective_type (str): The type of the objective metric for evaluating training jobs.\n                This value can be either \'Minimize\' or \'Maximize\'.\n            objective_metric_name (str): Name of the metric for evaluating training jobs.\n            max_jobs (int): Maximum total number of training jobs to start for the hyperparameter\n                tuning job.\n            max_parallel_jobs (int): Maximum number of parallel training jobs to start.\n            parameter_ranges (dict): Dictionary of parameter ranges. These parameter ranges can be\n                one of three types: Continuous, Integer, or Categorical.\n            static_hyperparameters (dict): Hyperparameters for model training. These\n                hyperparameters remain unchanged across all of the training jobs for the\n                hyperparameter tuning job. The hyperparameters are made accessible as a dictionary\n                for the training code on SageMaker.\n            image (str): Docker image containing training code.\n            algorithm_arn (str): Resource ARN for training algorithm created on or subscribed from\n                AWS Marketplace (default: None).\n            input_mode (str): The input mode that the algorithm supports. Valid modes:\n                * \'File\' - Amazon SageMaker copies the training dataset from the S3 location to\n                a directory in the Docker container.\n                * \'Pipe\' - Amazon SageMaker streams data directly from S3 to the container via a\n                Unix-named pipe.\n\n            metric_definitions (list[dict]): A list of dictionaries that defines the metric(s)\n                used to evaluate the training jobs. Each dictionary contains two keys: \'Name\' for\n                the name of the metric, and \'Regex\' for the regular expression used to extract the\n                metric from the logs. This should be defined only for jobs that don\'t use an\n                Amazon algorithm.\n            role (str): An AWS IAM role (either name or full ARN). The Amazon SageMaker\n                training jobs and APIs that create Amazon SageMaker endpoints use this role to\n                access training data and model artifacts. You must grant sufficient permissions\n                to this role.\n            input_config (list): A list of Channel objects. Each channel is a named input source.\n                Please refer to the format details described:\n                https://botocore.readthedocs.io/en/latest/reference/services/sagemaker.html#SageMaker.Client.create_training_job\n            output_config (dict): The S3 URI where you want to store the training results and\n                optional KMS key ID.\n            resource_config (dict): Contains values for ResourceConfig:\n                * instance_count (int): Number of EC2 instances to use for training.\n                The key in resource_config is \'InstanceCount\'.\n                * instance_type (str): Type of EC2 instance to use for training, for example,\n                \'ml.c4.xlarge\'. The key in resource_config is \'InstanceType\'.\n\n            stop_condition (dict): When training should finish, e.g. ``MaxRuntimeInSeconds``.\n            tags (list[dict]): List of tags for labeling the tuning job. For more, see\n                https://docs.aws.amazon.com/sagemaker/latest/dg/API_Tag.html.\n            warm_start_config (dict): Configuration defining the type of warm start and\n                other required configurations.\n            early_stopping_type (str): Specifies whether early stopping is enabled for the job.\n                Can be either \'Auto\' or \'Off\'. If set to \'Off\', early stopping will not be\n                attempted. If set to \'Auto\', early stopping of some training jobs may happen, but\n                is not guaranteed to.\n            enable_network_isolation (bool): Specifies whether to isolate the training container\n                (default: ``False``).\n            encrypt_inter_container_traffic (bool): Specifies whether traffic between training\n                containers is encrypted for the training jobs started for this hyperparameter\n                tuning job (default: ``False``).\n            vpc_config (dict): Contains values for VpcConfig (default: None):\n                * subnets (list[str]): List of subnet ids.\n                The key in vpc_config is \'Subnets\'.\n                * security_group_ids (list[str]): List of security group ids.\n                The key in vpc_config is \'SecurityGroupIds\'.\n            train_use_spot_instances (bool): whether to use spot instances for training.\n            checkpoint_s3_uri (str): The S3 URI in which to persist checkpoints\n                that the algorithm persists (if any) during training. (default:\n                ``None``).\n            checkpoint_local_path (str): The local path that the algorithm\n                writes its checkpoints to. SageMaker will persist all files\n                under this path to `checkpoint_s3_uri` continually during\n                training. On job startup the reverse happens - data from the\n                s3 location is downloaded to this path before the algorithm is\n                started. If the path is unset then SageMaker assumes the\n                checkpoints will be provided under `/opt/ml/checkpoints/`.\n                (default: ``None``).\n\n        """"""\n\n        tune_request = {\n            ""HyperParameterTuningJobName"": job_name,\n            ""HyperParameterTuningJobConfig"": self._map_tuning_config(\n                strategy=strategy,\n                max_jobs=max_jobs,\n                max_parallel_jobs=max_parallel_jobs,\n                objective_type=objective_type,\n                objective_metric_name=objective_metric_name,\n                parameter_ranges=parameter_ranges,\n                early_stopping_type=early_stopping_type,\n            ),\n            ""TrainingJobDefinition"": self._map_training_config(\n                static_hyperparameters=static_hyperparameters,\n                role=role,\n                input_mode=input_mode,\n                image=image,\n                algorithm_arn=algorithm_arn,\n                metric_definitions=metric_definitions,\n                input_config=input_config,\n                output_config=output_config,\n                resource_config=resource_config,\n                vpc_config=vpc_config,\n                stop_condition=stop_condition,\n                enable_network_isolation=enable_network_isolation,\n                encrypt_inter_container_traffic=encrypt_inter_container_traffic,\n                train_use_spot_instances=train_use_spot_instances,\n                checkpoint_s3_uri=checkpoint_s3_uri,\n                checkpoint_local_path=checkpoint_local_path,\n            ),\n        }\n\n        if warm_start_config is not None:\n            tune_request[""WarmStartConfig""] = warm_start_config\n\n        if tags is not None:\n            tune_request[""Tags""] = tags\n\n        LOGGER.info(""Creating hyperparameter tuning job with name: %s"", job_name)\n        LOGGER.debug(""tune request: %s"", json.dumps(tune_request, indent=4))\n        self.sagemaker_client.create_hyper_parameter_tuning_job(**tune_request)\n\n    def create_tuning_job(\n        self,\n        job_name,\n        tuning_config,\n        training_config=None,\n        training_config_list=None,\n        warm_start_config=None,\n        tags=None,\n    ):\n        """"""Create an Amazon SageMaker hyperparameter tuning job. This method supports creating\n        tuning jobs with single or multiple training algorithms (estimators), while the ``tune()``\n        method above only supports creating tuning jobs with single training algorithm.\n\n        Args:\n            job_name (str): Name of the tuning job being created.\n            tuning_config (dict): Configuration to launch the tuning job.\n            training_config (dict): Configuration to launch training jobs under the tuning job\n                using a single algorithm.\n            training_config_list (list[dict]): A list of configurations to launch training jobs\n                under the tuning job using one or multiple algorithms. Either training_config\n                or training_config_list should be provided, but not both.\n            warm_start_config (dict): Configuration defining the type of warm start and\n                other required configurations.\n            tags (list[dict]): List of tags for labeling the tuning job. For more, see\n                https://docs.aws.amazon.com/sagemaker/latest/dg/API_Tag.html.\n        """"""\n\n        if training_config is None and training_config_list is None:\n            raise ValueError(""Either training_config or training_config_list should be provided."")\n        if training_config is not None and training_config_list is not None:\n            raise ValueError(\n                ""Only one of training_config and training_config_list should be provided.""\n            )\n\n        tune_request = {\n            ""HyperParameterTuningJobName"": job_name,\n            ""HyperParameterTuningJobConfig"": self._map_tuning_config(**tuning_config),\n        }\n\n        if training_config is not None:\n            tune_request[""TrainingJobDefinition""] = self._map_training_config(**training_config)\n\n        if training_config_list is not None:\n            tune_request[""TrainingJobDefinitions""] = [\n                self._map_training_config(**training_cfg) for training_cfg in training_config_list\n            ]\n\n        if warm_start_config is not None:\n            tune_request[""WarmStartConfig""] = warm_start_config\n\n        if tags is not None:\n            tune_request[""Tags""] = tags\n\n        LOGGER.info(""Creating hyperparameter tuning job with name: %s"", job_name)\n        LOGGER.debug(""tune request: %s"", json.dumps(tune_request, indent=4))\n        self.sagemaker_client.create_hyper_parameter_tuning_job(**tune_request)\n\n    @classmethod\n    def _map_tuning_config(\n        cls,\n        strategy,\n        max_jobs,\n        max_parallel_jobs,\n        early_stopping_type=""Off"",\n        objective_type=None,\n        objective_metric_name=None,\n        parameter_ranges=None,\n    ):\n        """"""\n        Construct tuning job configuration dictionary.\n\n        Args:\n            strategy (str): Strategy to be used for hyperparameter estimations.\n            max_jobs (int): Maximum total number of training jobs to start for the hyperparameter\n                tuning job.\n            max_parallel_jobs (int): Maximum number of parallel training jobs to start.\n            early_stopping_type (str): Specifies whether early stopping is enabled for the job.\n                Can be either \'Auto\' or \'Off\'. If set to \'Off\', early stopping will not be\n                attempted. If set to \'Auto\', early stopping of some training jobs may happen,\n                but is not guaranteed to.\n            objective_type (str): The type of the objective metric for evaluating training jobs.\n                This value can be either \'Minimize\' or \'Maximize\'.\n            objective_metric_name (str): Name of the metric for evaluating training jobs.\n            parameter_ranges (dict): Dictionary of parameter ranges. These parameter ranges can\n                be one of three types: Continuous, Integer, or Categorical.\n\n        Returns:\n            A dictionary of tuning job configuration. For format details, please refer to\n            HyperParameterTuningJobConfig as described in\n            https://botocore.readthedocs.io/en/latest/reference/services/sagemaker.html#SageMaker.Client.create_hyper_parameter_tuning_job\n        """"""\n\n        tuning_config = {\n            ""Strategy"": strategy,\n            ""ResourceLimits"": {\n                ""MaxNumberOfTrainingJobs"": max_jobs,\n                ""MaxParallelTrainingJobs"": max_parallel_jobs,\n            },\n            ""TrainingJobEarlyStoppingType"": early_stopping_type,\n        }\n\n        tuning_objective = cls._map_tuning_objective(objective_type, objective_metric_name)\n        if tuning_objective is not None:\n            tuning_config[""HyperParameterTuningJobObjective""] = tuning_objective\n\n        if parameter_ranges is not None:\n            tuning_config[""ParameterRanges""] = parameter_ranges\n\n        return tuning_config\n\n    @classmethod\n    def _map_tuning_objective(cls, objective_type, objective_metric_name):\n        """"""\n        Construct a dictionary of tuning objective from the arguments\n\n        Args:\n            objective_type (str): The type of the objective metric for evaluating training jobs.\n                This value can be either \'Minimize\' or \'Maximize\'.\n            objective_metric_name (str): Name of the metric for evaluating training jobs.\n\n        Returns:\n            A dictionary of tuning objective. For format details, please refer to\n            HyperParameterTuningJobObjective as described in\n            https://botocore.readthedocs.io/en/latest/reference/services/sagemaker.html#SageMaker.Client.create_hyper_parameter_tuning_job\n        """"""\n\n        tuning_objective = None\n\n        if objective_type is not None or objective_metric_name is not None:\n            tuning_objective = {}\n\n        if objective_type is not None:\n            tuning_objective[""Type""] = objective_type\n\n        if objective_metric_name is not None:\n            tuning_objective[""MetricName""] = objective_metric_name\n\n        return tuning_objective\n\n    @classmethod\n    def _map_training_config(\n        cls,\n        static_hyperparameters,\n        input_mode,\n        role,\n        output_config,\n        resource_config,\n        stop_condition,\n        input_config=None,\n        metric_definitions=None,\n        image=None,\n        algorithm_arn=None,\n        vpc_config=None,\n        enable_network_isolation=False,\n        encrypt_inter_container_traffic=False,\n        estimator_name=None,\n        objective_type=None,\n        objective_metric_name=None,\n        parameter_ranges=None,\n        train_use_spot_instances=False,\n        checkpoint_s3_uri=None,\n        checkpoint_local_path=None,\n    ):\n        """"""\n        Construct a dictionary of training job configuration from the arguments\n\n        Args:\n            static_hyperparameters (dict): Hyperparameters for model training. These\n                hyperparameters remain unchanged across all of the training jobs for the\n                hyperparameter tuning job. The hyperparameters are made accessible as a dictionary\n                for the training code on SageMaker.\n            input_mode (str): The input mode that the algorithm supports. Valid modes:\n\n                * \'File\' - Amazon SageMaker copies the training dataset from the S3 location to\n                    a directory in the Docker container.\n                * \'Pipe\' - Amazon SageMaker streams data directly from S3 to the container via a\n                    Unix-named pipe.\n\n            role (str): An AWS IAM role (either name or full ARN). The Amazon SageMaker training\n                jobs and APIs that create Amazon SageMaker endpoints use this role to access\n                training data and model artifacts. You must grant sufficient permissions to\n                this role.\n            output_config (dict): The S3 URI where you want to store the training results and\n                optional KMS key ID.\n            resource_config (dict): Contains values for ResourceConfig:\n\n                * instance_count (int): Number of EC2 instances to use for training.\n                    The key in resource_config is \'InstanceCount\'.\n                * instance_type (str): Type of EC2 instance to use for training, for example,\n                    \'ml.c4.xlarge\'. The key in resource_config is \'InstanceType\'.\n\n            stop_condition (dict): When training should finish, e.g. ``MaxRuntimeInSeconds``.\n            input_config (list): A list of Channel objects. Each channel is a named input source.\n                Please refer to the format details described:\n                https://botocore.readthedocs.io/en/latest/reference/services/sagemaker.html#SageMaker.Client.create_training_job\n            metric_definitions (list[dict]): A list of dictionaries that defines the metric(s)\n                used to evaluate the training jobs. Each dictionary contains two keys: \'Name\' for\n                the name of the metric, and \'Regex\' for the regular expression used to extract the\n                metric from the logs. This should be defined only for jobs that don\'t use an\n                Amazon algorithm.\n            image (str): Docker image containing training code.\n            algorithm_arn (str): Resource ARN for training algorithm created or subscribed on\n                AWS Marketplace\n            vpc_config (dict): Contains values for VpcConfig (default: None):\n\n                * subnets (list[str]): List of subnet ids.\n                    The key in vpc_config is \'Subnets\'.\n                * security_group_ids (list[str]): List of security group ids.\n                    The key in vpc_config is \'SecurityGroupIds\'.\n\n            enable_network_isolation (bool): Specifies whether to isolate the training container\n            encrypt_inter_container_traffic (bool): Specifies whether traffic between training\n                containers is encrypted for the training jobs started for this hyperparameter\n                tuning job (default: ``False``).\n            estimator_name (str): Unique name for the estimator.\n            objective_type (str): The type of the objective metric for evaluating training jobs.\n                This value can be either \'Minimize\' or \'Maximize\'.\n            objective_metric_name (str): Name of the metric for evaluating training jobs.\n            parameter_ranges (dict): Dictionary of parameter ranges. These parameter ranges can\n                be one of three types: Continuous, Integer, or Categorical.\n\n        Returns:\n            A dictionary of training job configuration. For format details, please refer to\n            TrainingJobDefinition as described in\n            https://botocore.readthedocs.io/en/latest/reference/services/sagemaker.html#SageMaker.Client.create_hyper_parameter_tuning_job\n\n        """"""\n\n        training_job_definition = {\n            ""StaticHyperParameters"": static_hyperparameters,\n            ""RoleArn"": role,\n            ""OutputDataConfig"": output_config,\n            ""ResourceConfig"": resource_config,\n            ""StoppingCondition"": stop_condition,\n        }\n\n        algorithm_spec = {""TrainingInputMode"": input_mode}\n        if metric_definitions is not None:\n            algorithm_spec[""MetricDefinitions""] = metric_definitions\n\n        if algorithm_arn:\n            algorithm_spec[""AlgorithmName""] = algorithm_arn\n        else:\n            algorithm_spec[""TrainingImage""] = image\n\n        training_job_definition[""AlgorithmSpecification""] = algorithm_spec\n\n        if input_config is not None:\n            training_job_definition[""InputDataConfig""] = input_config\n\n        if vpc_config is not None:\n            training_job_definition[""VpcConfig""] = vpc_config\n\n        if enable_network_isolation:\n            training_job_definition[""EnableNetworkIsolation""] = True\n\n        if encrypt_inter_container_traffic:\n            training_job_definition[""EnableInterContainerTrafficEncryption""] = True\n\n        if train_use_spot_instances:\n            training_job_definition[""EnableManagedSpotTraining""] = True\n\n        if checkpoint_s3_uri:\n            checkpoint_config = {""S3Uri"": checkpoint_s3_uri}\n            if checkpoint_local_path:\n                checkpoint_config[""LocalPath""] = checkpoint_local_path\n            training_job_definition[""CheckpointConfig""] = checkpoint_config\n        if estimator_name is not None:\n            training_job_definition[""DefinitionName""] = estimator_name\n\n        tuning_objective = cls._map_tuning_objective(objective_type, objective_metric_name)\n        if tuning_objective is not None:\n            training_job_definition[""TuningObjective""] = tuning_objective\n\n        if parameter_ranges is not None:\n            training_job_definition[""HyperParameterRanges""] = parameter_ranges\n\n        return training_job_definition\n\n    def stop_tuning_job(self, name):\n        """"""Stop the Amazon SageMaker hyperparameter tuning job with the specified name.\n\n        Args:\n            name (str): Name of the Amazon SageMaker hyperparameter tuning job.\n\n        Raises:\n            ClientError: If an error occurs while trying to stop the hyperparameter tuning job.\n        """"""\n        try:\n            LOGGER.info(""Stopping tuning job: %s"", name)\n            self.sagemaker_client.stop_hyper_parameter_tuning_job(HyperParameterTuningJobName=name)\n        except ClientError as e:\n            error_code = e.response[""Error""][""Code""]\n            # allow to pass if the job already stopped\n            if error_code == ""ValidationException"":\n                LOGGER.info(""Tuning job: %s is already stopped or not running."", name)\n            else:\n                LOGGER.error(\n                    ""Error occurred while attempting to stop tuning job: %s. Please try again."",\n                    name,\n                )\n                raise\n\n    def transform(\n        self,\n        job_name,\n        model_name,\n        strategy,\n        max_concurrent_transforms,\n        max_payload,\n        env,\n        input_config,\n        output_config,\n        resource_config,\n        experiment_config,\n        tags,\n        data_processing,\n    ):\n        """"""Create an Amazon SageMaker transform job.\n\n        Args:\n            job_name (str): Name of the transform job being created.\n            model_name (str): Name of the SageMaker model being used for the transform job.\n            strategy (str): The strategy used to decide how to batch records in a single request.\n                Possible values are \'MultiRecord\' and \'SingleRecord\'.\n            max_concurrent_transforms (int): The maximum number of HTTP requests to be made to\n                each individual transform container at one time.\n            max_payload (int): Maximum size of the payload in a single HTTP request to the\n                container in MB.\n            env (dict): Environment variables to be set for use during the transform job.\n            input_config (dict): A dictionary describing the input data (and its location) for the\n                job.\n            output_config (dict): A dictionary describing the output location for the job.\n            resource_config (dict): A dictionary describing the resources to complete the job.\n            experiment_config (dict): A dictionary describing the experiment configuration for the\n                job. Dictionary contains three optional keys,\n                \'ExperimentName\', \'TrialName\', and \'TrialComponentDisplayName\'.\n            tags (list[dict]): List of tags for labeling a transform job.\n            data_processing(dict): A dictionary describing config for combining the input data and\n                transformed data. For more, see\n                https://docs.aws.amazon.com/sagemaker/latest/dg/API_Tag.html.\n        """"""\n        transform_request = {\n            ""TransformJobName"": job_name,\n            ""ModelName"": model_name,\n            ""TransformInput"": input_config,\n            ""TransformOutput"": output_config,\n            ""TransformResources"": resource_config,\n        }\n\n        if strategy is not None:\n            transform_request[""BatchStrategy""] = strategy\n\n        if max_concurrent_transforms is not None:\n            transform_request[""MaxConcurrentTransforms""] = max_concurrent_transforms\n\n        if max_payload is not None:\n            transform_request[""MaxPayloadInMB""] = max_payload\n\n        if env is not None:\n            transform_request[""Environment""] = env\n\n        if tags is not None:\n            transform_request[""Tags""] = tags\n\n        if data_processing is not None:\n            transform_request[""DataProcessing""] = data_processing\n\n        if experiment_config and len(experiment_config) > 0:\n            transform_request[""ExperimentConfig""] = experiment_config\n\n        LOGGER.info(""Creating transform job with name: %s"", job_name)\n        LOGGER.debug(""Transform request: %s"", json.dumps(transform_request, indent=4))\n        self.sagemaker_client.create_transform_job(**transform_request)\n\n    def create_model(\n        self,\n        name,\n        role,\n        container_defs,\n        vpc_config=None,\n        enable_network_isolation=False,\n        primary_container=None,\n        tags=None,\n    ):\n        """"""Create an Amazon SageMaker ``Model``.\n        Specify the S3 location of the model artifacts and Docker image containing\n        the inference code. Amazon SageMaker uses this information to deploy the\n        model in Amazon SageMaker. This method can also be used to create a Model for an Inference\n        Pipeline if you pass the list of container definitions through the containers parameter.\n\n        Args:\n            name (str): Name of the Amazon SageMaker ``Model`` to create.\n            role (str): An AWS IAM role (either name or full ARN). The Amazon SageMaker training\n                jobs and APIs that create Amazon SageMaker endpoints use this role to access\n                training data and model artifacts. You must grant sufficient permissions to this\n                role.\n            container_defs (list[dict[str, str]] or [dict[str, str]]): A single container\n                definition or a list of container definitions which will be invoked sequentially\n                while performing the prediction. If the list contains only one container, then\n                it\'ll be passed to SageMaker Hosting as the ``PrimaryContainer`` and otherwise,\n                it\'ll be passed as ``Containers``.You can also specify the  return value of\n                ``sagemaker.get_container_def()`` or ``sagemaker.pipeline_container_def()``,\n                which will used to create more advanced container configurations, including model\n                containers which need artifacts from S3.\n            vpc_config (dict[str, list[str]]): The VpcConfig set on the model (default: None)\n                * \'Subnets\' (list[str]): List of subnet ids.\n                * \'SecurityGroupIds\' (list[str]): List of security group ids.\n            enable_network_isolation (bool): Wether the model requires network isolation or not.\n            primary_container (str or dict[str, str]): Docker image which defines the inference\n                code. You can also specify the return value of ``sagemaker.container_def()``,\n                which is used to create more advanced container configurations, including model\n                containers which need artifacts from S3. This field is deprecated, please use\n                container_defs instead.\n            tags(List[dict[str, str]]): Optional. The list of tags to add to the model.\n\n        Example:\n            >>> tags = [{\'Key\': \'tagname\', \'Value\': \'tagvalue\'}]\n            For more information about tags, see https://boto3.amazonaws.com/v1/documentation\\\n            /api/latest/reference/services/sagemaker.html#SageMaker.Client.add_tags\n\n\n        Returns:\n            str: Name of the Amazon SageMaker ``Model`` created.\n        """"""\n        if container_defs and primary_container:\n            raise ValueError(""Both container_defs and primary_container can not be passed as input"")\n\n        if primary_container:\n            msg = (\n                ""primary_container is going to be deprecated in a future release. Please use ""\n                ""container_defs instead.""\n            )\n            warnings.warn(msg, DeprecationWarning)\n            container_defs = primary_container\n\n        role = self.expand_role(role)\n\n        if isinstance(container_defs, list):\n            container_definition = container_defs\n        else:\n            container_definition = _expand_container_def(container_defs)\n\n        create_model_request = _create_model_request(\n            name=name, role=role, container_def=container_definition, tags=tags\n        )\n\n        if vpc_config:\n            create_model_request[""VpcConfig""] = vpc_config\n\n        if enable_network_isolation:\n            create_model_request[""EnableNetworkIsolation""] = True\n\n        LOGGER.info(""Creating model with name: %s"", name)\n        LOGGER.debug(""CreateModel request: %s"", json.dumps(create_model_request, indent=4))\n\n        try:\n            self.sagemaker_client.create_model(**create_model_request)\n        except ClientError as e:\n            error_code = e.response[""Error""][""Code""]\n            message = e.response[""Error""][""Message""]\n\n            if (\n                error_code == ""ValidationException""\n                and ""Cannot create already existing model"" in message\n            ):\n                LOGGER.warning(""Using already existing model: %s"", name)\n            else:\n                raise\n\n        return name\n\n    def create_model_from_job(\n        self,\n        training_job_name,\n        name=None,\n        role=None,\n        primary_container_image=None,\n        model_data_url=None,\n        env=None,\n        vpc_config_override=vpc_utils.VPC_CONFIG_DEFAULT,\n        tags=None,\n    ):\n        """"""Create an Amazon SageMaker ``Model`` from a SageMaker Training Job.\n\n        Args:\n            training_job_name (str): The Amazon SageMaker Training Job name.\n            name (str): The name of the SageMaker ``Model`` to create (default: None).\n                If not specified, the training job name is used.\n            role (str): The ``ExecutionRoleArn`` IAM Role ARN for the ``Model``, specified either\n                by an IAM role name or role ARN. If None, the ``RoleArn`` from the SageMaker\n                Training Job will be used.\n            primary_container_image (str): The Docker image reference (default: None). If None, it\n                defaults to the Training Image in ``training_job_name``.\n            model_data_url (str): S3 location of the model data (default: None). If None, defaults\n                to the ``ModelS3Artifacts`` of ``training_job_name``.\n            env (dict[string,string]): Model environment variables (default: {}).\n            vpc_config_override (dict[str, list[str]]): Optional override for VpcConfig set on the\n                model.\n                Default: use VpcConfig from training job.\n                * \'Subnets\' (list[str]): List of subnet ids.\n                * \'SecurityGroupIds\' (list[str]): List of security group ids.\n            tags(List[dict[str, str]]): Optional. The list of tags to add to the model.\n                For more, see https://docs.aws.amazon.com/sagemaker/latest/dg/API_Tag.html.\n\n        Returns:\n            str: The name of the created ``Model``.\n        """"""\n        training_job = self.sagemaker_client.describe_training_job(\n            TrainingJobName=training_job_name\n        )\n        name = name or training_job_name\n        role = role or training_job[""RoleArn""]\n        env = env or {}\n        primary_container = container_def(\n            primary_container_image or training_job[""AlgorithmSpecification""][""TrainingImage""],\n            model_data_url=model_data_url or training_job[""ModelArtifacts""][""S3ModelArtifacts""],\n            env=env,\n        )\n        vpc_config = _vpc_config_from_training_job(training_job, vpc_config_override)\n        return self.create_model(name, role, primary_container, vpc_config=vpc_config, tags=tags)\n\n    def create_model_package_from_algorithm(self, name, description, algorithm_arn, model_data):\n        """"""Create a SageMaker Model Package from the results of training with an Algorithm Package\n\n        Args:\n            name (str): ModelPackage name\n            description (str): Model Package description\n            algorithm_arn (str): arn or name of the algorithm used for training.\n            model_data (str): s3 URI to the model artifacts produced by training\n        """"""\n        request = {\n            ""ModelPackageName"": name,\n            ""ModelPackageDescription"": description,\n            ""SourceAlgorithmSpecification"": {\n                ""SourceAlgorithms"": [{""AlgorithmName"": algorithm_arn, ""ModelDataUrl"": model_data}]\n            },\n        }\n        try:\n            LOGGER.info(""Creating model package with name: %s"", name)\n            self.sagemaker_client.create_model_package(**request)\n        except ClientError as e:\n            error_code = e.response[""Error""][""Code""]\n            message = e.response[""Error""][""Message""]\n\n            if error_code == ""ValidationException"" and ""ModelPackage already exists"" in message:\n                LOGGER.warning(""Using already existing model package: %s"", name)\n            else:\n                raise\n\n    def wait_for_model_package(self, model_package_name, poll=5):\n        """"""Wait for an Amazon SageMaker endpoint deployment to complete.\n\n        Args:\n            endpoint (str): Name of the ``Endpoint`` to wait for.\n            poll (int): Polling interval in seconds (default: 5).\n\n        Returns:\n            dict: Return value from the ``DescribeEndpoint`` API.\n        """"""\n        desc = _wait_until(\n            lambda: _create_model_package_status(self.sagemaker_client, model_package_name), poll\n        )\n        status = desc[""ModelPackageStatus""]\n\n        if status != ""Completed"":\n            reason = desc.get(""FailureReason"", None)\n            raise exceptions.UnexpectedStatusException(\n                message=""Error creating model package {package}: {status} Reason: {reason}"".format(\n                    package=model_package_name, status=status, reason=reason\n                ),\n                allowed_statuses=[""Completed""],\n                actual_status=status,\n            )\n        return desc\n\n    def create_endpoint_config(\n        self,\n        name,\n        model_name,\n        initial_instance_count,\n        instance_type,\n        accelerator_type=None,\n        tags=None,\n        kms_key=None,\n        data_capture_config_dict=None,\n    ):\n        """"""Create an Amazon SageMaker endpoint configuration.\n\n        The endpoint configuration identifies the Amazon SageMaker model (created using the\n        ``CreateModel`` API) and the hardware configuration on which to deploy the model. Provide\n        this endpoint configuration to the ``CreateEndpoint`` API, which then launches the\n        hardware and deploys the model.\n\n        Args:\n            name (str): Name of the Amazon SageMaker endpoint configuration to create.\n            model_name (str): Name of the Amazon SageMaker ``Model``.\n            initial_instance_count (int): Minimum number of EC2 instances to launch. The actual\n                number of active instances for an endpoint at any given time varies due to\n                autoscaling.\n            instance_type (str): Type of EC2 instance to launch, for example, \'ml.c4.xlarge\'.\n            accelerator_type (str): Type of Elastic Inference accelerator to attach to the\n                instance. For example, \'ml.eia1.medium\'.\n                For more information: https://docs.aws.amazon.com/sagemaker/latest/dg/ei.html\n            tags(List[dict[str, str]]): Optional. The list of tags to add to the endpoint config.\n            kms_key (str): The KMS key that is used to encrypt the data on the storage volume\n                attached to the instance hosting the endpoint.\n            data_capture_config_dict (dict): Specifies configuration related to Endpoint data\n                capture for use with Amazon SageMaker Model Monitoring. Default: None.\n\n        Example:\n            >>> tags = [{\'Key\': \'tagname\', \'Value\': \'tagvalue\'}]\n            For more information about tags, see\n            https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html#SageMaker.Client.add_tags\n\n        Returns:\n            str: Name of the endpoint point configuration created.\n\n        """"""\n        LOGGER.info(""Creating endpoint-config with name %s"", name)\n\n        tags = tags or []\n\n        request = {\n            ""EndpointConfigName"": name,\n            ""ProductionVariants"": [\n                production_variant(\n                    model_name,\n                    instance_type,\n                    initial_instance_count,\n                    accelerator_type=accelerator_type,\n                )\n            ],\n        }\n\n        if tags is not None:\n            request[""Tags""] = tags\n\n        if kms_key is not None:\n            request[""KmsKeyId""] = kms_key\n\n        if data_capture_config_dict is not None:\n            request[""DataCaptureConfig""] = data_capture_config_dict\n\n        self.sagemaker_client.create_endpoint_config(**request)\n        return name\n\n    def create_endpoint_config_from_existing(\n        self,\n        existing_config_name,\n        new_config_name,\n        new_tags=None,\n        new_kms_key=None,\n        new_data_capture_config_dict=None,\n    ):\n        """"""Create an Amazon SageMaker endpoint configuration from an existing one. Updating any\n        values that were passed in.\n\n        The endpoint configuration identifies the Amazon SageMaker model (created using the\n        ``CreateModel`` API) and the hardware configuration on which to deploy the model. Provide\n        this endpoint configuration to the ``CreateEndpoint`` API, which then launches the\n        hardware and deploys the model.\n\n        Args:\n            new_config_name (str): Name of the Amazon SageMaker endpoint configuration to create.\n            existing_config_name (str): Name of the existing Amazon SageMaker endpoint\n                configuration.\n            new_tags(List[dict[str, str]]): Optional. The list of tags to add to the endpoint\n                config. If not specified, the tags of the existing endpoint configuration are used.\n                If any of the existing tags are reserved AWS ones (i.e. begin with ""aws""),\n                they are not carried over to the new endpoint configuration.\n            new_kms_key (str): The KMS key that is used to encrypt the data on the storage volume\n                attached to the instance hosting the endpoint (default: None). If not specified,\n                the KMS key of the existing endpoint configuration is used.\n            new_data_capture_config_dict (dict): Specifies configuration related to Endpoint data\n                capture for use with Amazon SageMaker Model Monitoring (default: None).\n                If not specified, the data capture configuration of the existing\n                endpoint configuration is used.\n\n        Returns:\n            str: Name of the endpoint point configuration created.\n\n        """"""\n        LOGGER.info(""Creating endpoint-config with name %s"", new_config_name)\n\n        existing_endpoint_config_desc = self.sagemaker_client.describe_endpoint_config(\n            EndpointConfigName=existing_config_name\n        )\n\n        request = {\n            ""EndpointConfigName"": new_config_name,\n            ""ProductionVariants"": existing_endpoint_config_desc[""ProductionVariants""],\n        }\n\n        request_tags = new_tags or self.list_tags(\n            existing_endpoint_config_desc[""EndpointConfigArn""]\n        )\n        if request_tags:\n            request[""Tags""] = request_tags\n\n        if new_kms_key is not None or existing_endpoint_config_desc.get(""KmsKeyId"") is not None:\n            request[""KmsKeyId""] = new_kms_key or existing_endpoint_config_desc.get(""KmsKeyId"")\n\n        request_data_capture_config_dict = (\n            new_data_capture_config_dict or existing_endpoint_config_desc.get(""DataCaptureConfig"")\n        )\n\n        if request_data_capture_config_dict is not None:\n            request[""DataCaptureConfig""] = request_data_capture_config_dict\n\n        self.sagemaker_client.create_endpoint_config(**request)\n\n    def create_endpoint(self, endpoint_name, config_name, tags=None, wait=True):\n        """"""Create an Amazon SageMaker ``Endpoint`` according to the endpoint configuration\n        specified in the request.\n\n        Once the ``Endpoint`` is created, client applications can send requests to obtain\n        inferences. The endpoint configuration is created using the ``CreateEndpointConfig`` API.\n\n        Args:\n            endpoint_name (str): Name of the Amazon SageMaker ``Endpoint`` being created.\n            config_name (str): Name of the Amazon SageMaker endpoint configuration to deploy.\n            wait (bool): Whether to wait for the endpoint deployment to complete before returning\n                (default: True).\n\n        Returns:\n            str: Name of the Amazon SageMaker ``Endpoint`` created.\n        """"""\n        LOGGER.info(""Creating endpoint with name %s"", endpoint_name)\n\n        tags = tags or []\n\n        self.sagemaker_client.create_endpoint(\n            EndpointName=endpoint_name, EndpointConfigName=config_name, Tags=tags\n        )\n        if wait:\n            self.wait_for_endpoint(endpoint_name)\n        return endpoint_name\n\n    def update_endpoint(self, endpoint_name, endpoint_config_name, wait=True):\n        """"""Update an Amazon SageMaker ``Endpoint`` according to the endpoint configuration\n        specified in the request\n\n        Raise an error if endpoint with endpoint_name does not exist.\n\n        Args:\n            endpoint_name (str): Name of the Amazon SageMaker ``Endpoint`` to update.\n            endpoint_config_name (str): Name of the Amazon SageMaker endpoint configuration to\n                deploy.\n            wait (bool): Whether to wait for the endpoint deployment to complete before returning\n                (default: True).\n\n        Returns:\n            str: Name of the Amazon SageMaker ``Endpoint`` being updated.\n\n        Raises:\n            ValueError: if the endpoint does not already exist\n        """"""\n        if not _deployment_entity_exists(\n            lambda: self.sagemaker_client.describe_endpoint(EndpointName=endpoint_name)\n        ):\n            raise ValueError(\n                ""Endpoint with name \'{}\' does not exist; please use an ""\n                ""existing endpoint name"".format(endpoint_name)\n            )\n\n        self.sagemaker_client.update_endpoint(\n            EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n        )\n\n        if wait:\n            self.wait_for_endpoint(endpoint_name)\n        return endpoint_name\n\n    def delete_endpoint(self, endpoint_name):\n        """"""Delete an Amazon SageMaker ``Endpoint``.\n\n        Args:\n            endpoint_name (str): Name of the Amazon SageMaker ``Endpoint`` to delete.\n        """"""\n        LOGGER.info(""Deleting endpoint with name: %s"", endpoint_name)\n        self.sagemaker_client.delete_endpoint(EndpointName=endpoint_name)\n\n    def delete_endpoint_config(self, endpoint_config_name):\n        """"""Delete an Amazon SageMaker endpoint configuration.\n\n        Args:\n            endpoint_config_name (str): Name of the Amazon SageMaker endpoint configuration to\n                delete.\n        """"""\n        LOGGER.info(""Deleting endpoint configuration with name: %s"", endpoint_config_name)\n        self.sagemaker_client.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\n\n    def delete_model(self, model_name):\n        """"""Delete an Amazon SageMaker Model.\n\n        Args:\n            model_name (str): Name of the Amazon SageMaker model to delete.\n\n        """"""\n        LOGGER.info(""Deleting model with name: %s"", model_name)\n        self.sagemaker_client.delete_model(ModelName=model_name)\n\n    def list_tags(self, resource_arn, max_results=50):\n        """"""List the tags given an Amazon Resource Name\n\n        Args:\n            resource_arn (str): The Amazon Resource Name (ARN) for which to get the tags list.\n            max_results (int): The maximum number of results to include in a single page.\n                This method takes care of that abstraction and returns a full list.\n\n        """"""\n        tags_list = []\n\n        try:\n            list_tags_response = self.sagemaker_client.list_tags(\n                ResourceArn=resource_arn, MaxResults=max_results\n            )\n            tags_list = tags_list + list_tags_response[""Tags""]\n\n            next_token = list_tags_response.get(""nextToken"")\n            while next_token is not None:\n                list_tags_response = self.sagemaker_client.list_tags(\n                    ResourceArn=resource_arn, MaxResults=max_results, NextToken=next_token\n                )\n                tags_list = tags_list + list_tags_response[""Tags""]\n                next_token = list_tags_response.get(""nextToken"")\n\n            non_aws_tags = []\n            for tag in tags_list:\n                if ""aws:"" not in tag[""Key""]:\n                    non_aws_tags.append(tag)\n            return non_aws_tags\n        except ClientError as error:\n            print(""Error retrieving tags. resource_arn: {}"".format(resource_arn))\n            raise error\n\n    def wait_for_job(self, job, poll=5):\n        """"""Wait for an Amazon SageMaker training job to complete.\n\n        Args:\n            job (str): Name of the training job to wait for.\n            poll (int): Polling interval in seconds (default: 5).\n\n        Returns:\n            (dict): Return value from the ``DescribeTrainingJob`` API.\n\n        Raises:\n            exceptions.UnexpectedStatusException: If the training job fails.\n\n        """"""\n        desc = _wait_until_training_done(\n            lambda last_desc: _train_done(self.sagemaker_client, job, last_desc), None, poll\n        )\n        self._check_job_status(job, desc, ""TrainingJobStatus"")\n        return desc\n\n    def wait_for_processing_job(self, job, poll=5):\n        """"""Wait for an Amazon SageMaker Processing job to complete.\n\n        Args:\n            job (str): Name of the processing job to wait for.\n            poll (int): Polling interval in seconds (default: 5).\n\n        Returns:\n            (dict): Return value from the ``DescribeProcessingJob`` API.\n\n        Raises:\n            exceptions.UnexpectedStatusException: If the compilation job fails.\n        """"""\n        desc = _wait_until(lambda: _processing_job_status(self.sagemaker_client, job), poll)\n        self._check_job_status(job, desc, ""ProcessingJobStatus"")\n        return desc\n\n    def wait_for_compilation_job(self, job, poll=5):\n        """"""Wait for an Amazon SageMaker Neo compilation job to complete.\n\n        Args:\n            job (str): Name of the compilation job to wait for.\n            poll (int): Polling interval in seconds (default: 5).\n\n        Returns:\n            (dict): Return value from the ``DescribeCompilationJob`` API.\n\n        Raises:\n            exceptions.UnexpectedStatusException: If the compilation job fails.\n        """"""\n        desc = _wait_until(lambda: _compilation_job_status(self.sagemaker_client, job), poll)\n        self._check_job_status(job, desc, ""CompilationJobStatus"")\n        return desc\n\n    def wait_for_tuning_job(self, job, poll=5):\n        """"""Wait for an Amazon SageMaker hyperparameter tuning job to complete.\n\n        Args:\n            job (str): Name of the tuning job to wait for.\n            poll (int): Polling interval in seconds (default: 5).\n\n        Returns:\n            (dict): Return value from the ``DescribeHyperParameterTuningJob`` API.\n\n        Raises:\n            exceptions.UnexpectedStatusException: If the hyperparameter tuning job fails.\n        """"""\n        desc = _wait_until(lambda: _tuning_job_status(self.sagemaker_client, job), poll)\n        self._check_job_status(job, desc, ""HyperParameterTuningJobStatus"")\n        return desc\n\n    def describe_transform_job(self, job_name):\n        """"""Calls the DescribeTransformJob API for the given job name\n        and returns the response.\n\n        Args:\n            job_name (str): The name of the transform job to describe.\n\n        Returns:\n            dict: A dictionary response with the transform job description.\n        """"""\n        return self.sagemaker_client.describe_transform_job(TransformJobName=job_name)\n\n    def wait_for_transform_job(self, job, poll=5):\n        """"""Wait for an Amazon SageMaker transform job to complete.\n\n        Args:\n            job (str): Name of the transform job to wait for.\n            poll (int): Polling interval in seconds (default: 5).\n\n        Returns:\n            (dict): Return value from the ``DescribeTransformJob`` API.\n\n        Raises:\n            exceptions.UnexpectedStatusException: If the transform job fails.\n        """"""\n        desc = _wait_until(lambda: _transform_job_status(self.sagemaker_client, job), poll)\n        self._check_job_status(job, desc, ""TransformJobStatus"")\n        return desc\n\n    def stop_transform_job(self, name):\n        """"""Stop the Amazon SageMaker hyperparameter tuning job with the specified name.\n\n        Args:\n            name (str): Name of the Amazon SageMaker batch transform job.\n\n        Raises:\n            ClientError: If an error occurs while trying to stop the batch transform job.\n        """"""\n        try:\n            LOGGER.info(""Stopping transform job: %s"", name)\n            self.sagemaker_client.stop_transform_job(TransformJobName=name)\n        except ClientError as e:\n            error_code = e.response[""Error""][""Code""]\n            # allow to pass if the job already stopped\n            if error_code == ""ValidationException"":\n                LOGGER.info(""Transform job: %s is already stopped or not running."", name)\n            else:\n                LOGGER.error(""Error occurred while attempting to stop transform job: %s."", name)\n                raise\n\n    def _check_job_status(self, job, desc, status_key_name):\n        """"""Check to see if the job completed successfully and, if not, construct and\n        raise a exceptions.UnexpectedStatusException.\n\n        Args:\n            job (str): The name of the job to check.\n            desc (dict[str, str]): The result of ``describe_training_job()``.\n            status_key_name (str): Status key name to check for.\n\n        Raises:\n            exceptions.UnexpectedStatusException: If the training job fails.\n        """"""\n        status = desc[status_key_name]\n        # If the status is capital case, then convert it to Camel case\n        status = _STATUS_CODE_TABLE.get(status, status)\n\n        if status not in (""Completed"", ""Stopped""):\n            reason = desc.get(""FailureReason"", ""(No reason provided)"")\n            job_type = status_key_name.replace(""JobStatus"", "" job"")\n            raise exceptions.UnexpectedStatusException(\n                message=""Error for {job_type} {job_name}: {status}. Reason: {reason}"".format(\n                    job_type=job_type, job_name=job, status=status, reason=reason\n                ),\n                allowed_statuses=[""Completed"", ""Stopped""],\n                actual_status=status,\n            )\n\n    def wait_for_endpoint(self, endpoint, poll=30):\n        """"""Wait for an Amazon SageMaker endpoint deployment to complete.\n\n        Args:\n            endpoint (str): Name of the ``Endpoint`` to wait for.\n            poll (int): Polling interval in seconds (default: 5).\n\n        Returns:\n            dict: Return value from the ``DescribeEndpoint`` API.\n        """"""\n        desc = _wait_until(lambda: _deploy_done(self.sagemaker_client, endpoint), poll)\n        status = desc[""EndpointStatus""]\n\n        if status != ""InService"":\n            reason = desc.get(""FailureReason"", None)\n            raise exceptions.UnexpectedStatusException(\n                message=""Error hosting endpoint {endpoint}: {status}. Reason: {reason}."".format(\n                    endpoint=endpoint, status=status, reason=reason\n                ),\n                allowed_statuses=[""InService""],\n                actual_status=status,\n            )\n        return desc\n\n    def endpoint_from_job(\n        self,\n        job_name,\n        initial_instance_count,\n        instance_type,\n        deployment_image=None,\n        name=None,\n        role=None,\n        wait=True,\n        model_environment_vars=None,\n        vpc_config_override=vpc_utils.VPC_CONFIG_DEFAULT,\n        accelerator_type=None,\n        data_capture_config=None,\n    ):\n        """"""Create an ``Endpoint`` using the results of a successful training job.\n\n        Specify the job name, Docker image containing the inference code, and hardware\n        configuration to deploy the model. Internally the API, creates an Amazon SageMaker model\n        (that describes the model artifacts and the Docker image containing inference code),\n        endpoint configuration (describing the hardware to deploy for hosting the model), and\n        creates an ``Endpoint`` (launches the EC2 instances and deploys the model on them). In\n        response, the API returns the endpoint name to which you can send requests for inferences.\n\n        Args:\n            job_name (str): Name of the training job to deploy the results of.\n            initial_instance_count (int): Minimum number of EC2 instances to launch. The actual\n                number of active instances for an endpoint at any given time varies due to\n                autoscaling.\n            instance_type (str): Type of EC2 instance to deploy to an endpoint for prediction,\n                for example, \'ml.c4.xlarge\'.\n            deployment_image (str): The Docker image which defines the inference code to be used\n                as the entry point for accepting prediction requests. If not specified, uses the\n                image used for the training job.\n            name (str): Name of the ``Endpoint`` to create. If not specified, uses the training job\n                name.\n            role (str): An AWS IAM role (either name or full ARN). The Amazon SageMaker training\n                jobs and APIs that create Amazon SageMaker endpoints use this role to access\n                training data and model artifacts. You must grant sufficient permissions to this\n                role.\n            wait (bool): Whether to wait for the endpoint deployment to complete before returning\n                (default: True).\n            model_environment_vars (dict[str, str]): Environment variables to set on the model\n                container (default: None).\n            vpc_config_override (dict[str, list[str]]): Overrides VpcConfig set on the model.\n                Default: use VpcConfig from training job.\n                * \'Subnets\' (list[str]): List of subnet ids.\n                * \'SecurityGroupIds\' (list[str]): List of security group ids.\n            accelerator_type (str): Type of Elastic Inference accelerator to attach to the\n                instance. For example, \'ml.eia1.medium\'.\n                For more information: https://docs.aws.amazon.com/sagemaker/latest/dg/ei.html\n            data_capture_config (sagemaker.model_monitor.DataCaptureConfig): Specifies\n                configuration related to Endpoint data capture for use with\n                Amazon SageMaker Model Monitoring. Default: None.\n\n        Returns:\n            str: Name of the ``Endpoint`` that is created.\n\n        """"""\n        job_desc = self.sagemaker_client.describe_training_job(TrainingJobName=job_name)\n        output_url = job_desc[""ModelArtifacts""][""S3ModelArtifacts""]\n        deployment_image = deployment_image or job_desc[""AlgorithmSpecification""][""TrainingImage""]\n        role = role or job_desc[""RoleArn""]\n        name = name or job_name\n        vpc_config_override = _vpc_config_from_training_job(job_desc, vpc_config_override)\n\n        return self.endpoint_from_model_data(\n            model_s3_location=output_url,\n            deployment_image=deployment_image,\n            initial_instance_count=initial_instance_count,\n            instance_type=instance_type,\n            name=name,\n            role=role,\n            wait=wait,\n            model_environment_vars=model_environment_vars,\n            model_vpc_config=vpc_config_override,\n            accelerator_type=accelerator_type,\n            data_capture_config=data_capture_config,\n        )\n\n    def endpoint_from_model_data(\n        self,\n        model_s3_location,\n        deployment_image,\n        initial_instance_count,\n        instance_type,\n        name=None,\n        role=None,\n        wait=True,\n        model_environment_vars=None,\n        model_vpc_config=None,\n        accelerator_type=None,\n        data_capture_config=None,\n    ):\n        """"""Create and deploy to an ``Endpoint`` using existing model data stored in S3.\n\n        Args:\n            model_s3_location (str): S3 URI of the model artifacts to use for the endpoint.\n            deployment_image (str): The Docker image which defines the runtime code to be used as\n                the entry point for accepting prediction requests.\n            initial_instance_count (int): Minimum number of EC2 instances to launch. The actual\n                number of active instances for an endpoint at any given time varies due to\n                autoscaling.\n            instance_type (str): Type of EC2 instance to deploy to an endpoint for prediction,\n                e.g. \'ml.c4.xlarge\'.\n            name (str): Name of the ``Endpoint`` to create. If not specified, uses a name\n                generated by combining the image name with a timestamp.\n            role (str): An AWS IAM role (either name or full ARN). The Amazon SageMaker training\n                jobs and APIs that create Amazon SageMaker endpoints use this role to access\n                training data and model artifacts.\n                You must grant sufficient permissions to this role.\n            wait (bool): Whether to wait for the endpoint deployment to complete before returning\n                (default: True).\n            model_environment_vars (dict[str, str]): Environment variables to set on the model\n                container (default: None).\n            model_vpc_config (dict[str, list[str]]): The VpcConfig set on the model (default: None)\n                * \'Subnets\' (list[str]): List of subnet ids.\n                * \'SecurityGroupIds\' (list[str]): List of security group ids.\n            accelerator_type (str): Type of Elastic Inference accelerator to attach to the instance.\n                For example, \'ml.eia1.medium\'.\n                For more information: https://docs.aws.amazon.com/sagemaker/latest/dg/ei.html\n            data_capture_config (sagemaker.model_monitor.DataCaptureConfig): Specifies\n                configuration related to Endpoint data capture for use with\n                Amazon SageMaker Model Monitoring. Default: None.\n\n        Returns:\n            str: Name of the ``Endpoint`` that is created.\n\n        """"""\n        model_environment_vars = model_environment_vars or {}\n        name = name or name_from_image(deployment_image)\n        model_vpc_config = vpc_utils.sanitize(model_vpc_config)\n\n        if _deployment_entity_exists(\n            lambda: self.sagemaker_client.describe_endpoint(EndpointName=name)\n        ):\n            raise ValueError(\n                \'Endpoint with name ""{}"" already exists; please pick a different name.\'.format(name)\n            )\n\n        if not _deployment_entity_exists(\n            lambda: self.sagemaker_client.describe_model(ModelName=name)\n        ):\n            primary_container = container_def(\n                image=deployment_image, model_data_url=model_s3_location, env=model_environment_vars\n            )\n            self.create_model(\n                name=name, role=role, container_defs=primary_container, vpc_config=model_vpc_config\n            )\n\n        data_capture_config_dict = None\n        if data_capture_config is not None:\n            data_capture_config_dict = data_capture_config._to_request_dict()\n\n        if not _deployment_entity_exists(\n            lambda: self.sagemaker_client.describe_endpoint_config(EndpointConfigName=name)\n        ):\n            self.create_endpoint_config(\n                name=name,\n                model_name=name,\n                initial_instance_count=initial_instance_count,\n                instance_type=instance_type,\n                accelerator_type=accelerator_type,\n                data_capture_config_dict=data_capture_config_dict,\n            )\n\n        self.create_endpoint(endpoint_name=name, config_name=name, wait=wait)\n        return name\n\n    def endpoint_from_production_variants(\n        self,\n        name,\n        production_variants,\n        tags=None,\n        kms_key=None,\n        wait=True,\n        data_capture_config_dict=None,\n    ):\n        """"""Create an SageMaker ``Endpoint`` from a list of production variants.\n\n        Args:\n            name (str): The name of the ``Endpoint`` to create.\n            production_variants (list[dict[str, str]]): The list of production variants to deploy.\n            tags (list[dict[str, str]]): A list of key-value pairs for tagging the endpoint\n                (default: None).\n            kms_key (str): The KMS key that is used to encrypt the data on the storage volume\n                attached to the instance hosting the endpoint.\n            wait (bool): Whether to wait for the endpoint deployment to complete before returning\n                (default: True).\n            data_capture_config_dict (dict): Specifies configuration related to Endpoint data\n                capture for use with Amazon SageMaker Model Monitoring. Default: None.\n\n        Returns:\n            str: The name of the created ``Endpoint``.\n\n        """"""\n        if not _deployment_entity_exists(\n            lambda: self.sagemaker_client.describe_endpoint_config(EndpointConfigName=name)\n        ):\n            config_options = {""EndpointConfigName"": name, ""ProductionVariants"": production_variants}\n            if tags:\n                config_options[""Tags""] = tags\n            if kms_key:\n                config_options[""KmsKeyId""] = kms_key\n            if data_capture_config_dict is not None:\n                config_options[""DataCaptureConfig""] = data_capture_config_dict\n\n            self.sagemaker_client.create_endpoint_config(**config_options)\n        return self.create_endpoint(endpoint_name=name, config_name=name, tags=tags, wait=wait)\n\n    def expand_role(self, role):\n        """"""Expand an IAM role name into an ARN.\n\n        If the role is already in the form of an ARN, then the role is simply returned. Otherwise\n        we retrieve the full ARN and return it.\n\n        Args:\n            role (str): An AWS IAM role (either name or full ARN).\n\n        Returns:\n            str: The corresponding AWS IAM role ARN.\n        """"""\n        if ""/"" in role:\n            return role\n        return self.boto_session.resource(""iam"").Role(role).arn\n\n    def get_caller_identity_arn(self):\n        """"""Returns the ARN user or role whose credentials are used to call the API.\n\n        Returns:\n            str: The ARN user or role\n        """"""\n        if os.path.exists(NOTEBOOK_METADATA_FILE):\n            with open(NOTEBOOK_METADATA_FILE, ""rb"") as f:\n                instance_name = json.loads(f.read())[""ResourceName""]\n            try:\n                instance_desc = self.sagemaker_client.describe_notebook_instance(\n                    NotebookInstanceName=instance_name\n                )\n                return instance_desc[""RoleArn""]\n            except ClientError:\n                LOGGER.debug(\n                    ""Couldn\'t call \'describe_notebook_instance\' to get the Role ""\n                    ""ARN of the instance %s."",\n                    instance_name,\n                )\n\n        assumed_role = self.boto_session.client(\n            ""sts"",\n            region_name=self.boto_region_name,\n            endpoint_url=sts_regional_endpoint(self.boto_region_name),\n        ).get_caller_identity()[""Arn""]\n\n        if ""AmazonSageMaker-ExecutionRole"" in assumed_role:\n            role = re.sub(\n                r""^(.+)sts::(\\d+):assumed-role/(.+?)/.*$"",\n                r""\\1iam::\\2:role/service-role/\\3"",\n                assumed_role,\n            )\n            return role\n\n        role = re.sub(r""^(.+)sts::(\\d+):assumed-role/(.+?)/.*$"", r""\\1iam::\\2:role/\\3"", assumed_role)\n\n        # Call IAM to get the role\'s path\n        role_name = role[role.rfind(""/"") + 1 :]\n        try:\n            role = self.boto_session.client(""iam"").get_role(RoleName=role_name)[""Role""][""Arn""]\n        except ClientError:\n            LOGGER.warning(\n                ""Couldn\'t call \'get_role\' to get Role ARN from role name %s to get Role path."",\n                role_name,\n            )\n\n        return role\n\n    def logs_for_job(  # noqa: C901 - suppress complexity warning for this method\n        self, job_name, wait=False, poll=10, log_type=""All""\n    ):\n        """"""Display the logs for a given training job, optionally tailing them until the\n        job is complete. If the output is a tty or a Jupyter cell, it will be color-coded\n        based on which instance the log entry is from.\n\n        Args:\n            job_name (str): Name of the training job to display the logs for.\n            wait (bool): Whether to keep looking for new log entries until the job completes\n                (default: False).\n            poll (int): The interval in seconds between polling for new log entries and job\n                completion (default: 5).\n\n        Raises:\n            exceptions.UnexpectedStatusException: If waiting and the training job fails.\n        """"""\n\n        description = self.sagemaker_client.describe_training_job(TrainingJobName=job_name)\n        print(secondary_training_status_message(description, None), end="""")\n\n        instance_count, stream_names, positions, client, log_group, dot, color_wrap = _logs_init(\n            self, description, job=""Training""\n        )\n\n        state = _get_initial_job_state(description, ""TrainingJobStatus"", wait)\n\n        # The loop below implements a state machine that alternates between checking the job status\n        # and reading whatever is available in the logs at this point. Note, that if we were\n        # called with wait == False, we never check the job status.\n        #\n        # If wait == TRUE and job is not completed, the initial state is TAILING\n        # If wait == FALSE, the initial state is COMPLETE (doesn\'t matter if the job really is\n        # complete).\n        #\n        # The state table:\n        #\n        # STATE               ACTIONS                        CONDITION             NEW STATE\n        # ----------------    ----------------               -----------------     ----------------\n        # TAILING             Read logs, Pause, Get status   Job complete          JOB_COMPLETE\n        #                                                    Else                  TAILING\n        # JOB_COMPLETE        Read logs, Pause               Any                   COMPLETE\n        # COMPLETE            Read logs, Exit                                      N/A\n        #\n        # Notes:\n        # - The JOB_COMPLETE state forces us to do an extra pause and read any items that got to\n        #   Cloudwatch after the job was marked complete.\n        last_describe_job_call = time.time()\n        last_description = description\n        last_debug_rule_statuses = None\n\n        while True:\n            _flush_log_streams(\n                stream_names,\n                instance_count,\n                client,\n                log_group,\n                job_name,\n                positions,\n                dot,\n                color_wrap,\n            )\n            if state == LogState.COMPLETE:\n                break\n\n            time.sleep(poll)\n\n            if state == LogState.JOB_COMPLETE:\n                state = LogState.COMPLETE\n            elif time.time() - last_describe_job_call >= 30:\n                description = self.sagemaker_client.describe_training_job(TrainingJobName=job_name)\n                last_describe_job_call = time.time()\n\n                if secondary_training_status_changed(description, last_description):\n                    print()\n                    print(secondary_training_status_message(description, last_description), end="""")\n                    last_description = description\n\n                status = description[""TrainingJobStatus""]\n\n                if status in (""Completed"", ""Failed"", ""Stopped""):\n                    print()\n                    state = LogState.JOB_COMPLETE\n\n                # Print prettified logs related to the status of SageMaker Debugger rules.\n                debug_rule_statuses = description.get(""DebugRuleEvaluationStatuses"", {})\n                if (\n                    debug_rule_statuses\n                    and _debug_rule_statuses_changed(debug_rule_statuses, last_debug_rule_statuses)\n                    and (log_type in {""All"", ""Rules""})\n                ):\n                    print()\n                    print(""********* Debugger Rule Status *********"")\n                    print(""*"")\n                    for status in debug_rule_statuses:\n                        rule_log = ""* {:>18}: {:<18}"".format(\n                            status[""RuleConfigurationName""], status[""RuleEvaluationStatus""]\n                        )\n                        print(rule_log)\n                    print(""*"")\n                    print(""*"" * 40)\n\n                    last_debug_rule_statuses = debug_rule_statuses\n\n        if wait:\n            self._check_job_status(job_name, description, ""TrainingJobStatus"")\n            if dot:\n                print()\n            # Customers are not billed for hardware provisioning, so billable time is less than\n            # total time\n            training_time = description.get(""TrainingTimeInSeconds"")\n            billable_time = description.get(""BillableTimeInSeconds"")\n            if training_time is not None:\n                print(""Training seconds:"", training_time * instance_count)\n            if billable_time is not None:\n                print(""Billable seconds:"", billable_time * instance_count)\n                if description.get(""EnableManagedSpotTraining""):\n                    saving = (1 - float(billable_time) / training_time) * 100\n                    print(""Managed Spot Training savings: {:.1f}%"".format(saving))\n\n    def logs_for_processing_job(self, job_name, wait=False, poll=10):\n        """"""Display the logs for a given processing job, optionally tailing them until the\n        job is complete.\n\n        Args:\n            job_name (str): Name of the processing job to display the logs for.\n            wait (bool): Whether to keep looking for new log entries until the job completes\n                (default: False).\n            poll (int): The interval in seconds between polling for new log entries and job\n                completion (default: 5).\n\n        Raises:\n            ValueError: If the processing job fails.\n        """"""\n\n        description = self.sagemaker_client.describe_processing_job(ProcessingJobName=job_name)\n\n        instance_count, stream_names, positions, client, log_group, dot, color_wrap = _logs_init(\n            self, description, job=""Processing""\n        )\n\n        state = _get_initial_job_state(description, ""ProcessingJobStatus"", wait)\n\n        # The loop below implements a state machine that alternates between checking the job status\n        # and reading whatever is available in the logs at this point. Note, that if we were\n        # called with wait == False, we never check the job status.\n        #\n        # If wait == TRUE and job is not completed, the initial state is TAILING\n        # If wait == FALSE, the initial state is COMPLETE (doesn\'t matter if the job really is\n        # complete).\n        #\n        # The state table:\n        #\n        # STATE               ACTIONS                        CONDITION             NEW STATE\n        # ----------------    ----------------               -----------------     ----------------\n        # TAILING             Read logs, Pause, Get status   Job complete          JOB_COMPLETE\n        #                                                    Else                  TAILING\n        # JOB_COMPLETE        Read logs, Pause               Any                   COMPLETE\n        # COMPLETE            Read logs, Exit                                      N/A\n        #\n        # Notes:\n        # - The JOB_COMPLETE state forces us to do an extra pause and read any items that got to\n        #   Cloudwatch after the job was marked complete.\n        last_describe_job_call = time.time()\n        while True:\n            _flush_log_streams(\n                stream_names,\n                instance_count,\n                client,\n                log_group,\n                job_name,\n                positions,\n                dot,\n                color_wrap,\n            )\n            if state == LogState.COMPLETE:\n                break\n\n            time.sleep(poll)\n\n            if state == LogState.JOB_COMPLETE:\n                state = LogState.COMPLETE\n            elif time.time() - last_describe_job_call >= 30:\n                description = self.sagemaker_client.describe_processing_job(\n                    ProcessingJobName=job_name\n                )\n                last_describe_job_call = time.time()\n\n                status = description[""ProcessingJobStatus""]\n\n                if status in (""Completed"", ""Failed"", ""Stopped""):\n                    print()\n                    state = LogState.JOB_COMPLETE\n\n        if wait:\n            self._check_job_status(job_name, description, ""ProcessingJobStatus"")\n            if dot:\n                print()\n\n    def logs_for_transform_job(self, job_name, wait=False, poll=10):\n        """"""Display the logs for a given transform job, optionally tailing them until the\n        job is complete. If the output is a tty or a Jupyter cell, it will be color-coded\n        based on which instance the log entry is from.\n\n        Args:\n            job_name (str): Name of the transform job to display the logs for.\n            wait (bool): Whether to keep looking for new log entries until the job completes\n                (default: False).\n            poll (int): The interval in seconds between polling for new log entries and job\n                completion (default: 5).\n\n        Raises:\n            ValueError: If the transform job fails.\n        """"""\n\n        description = self.sagemaker_client.describe_transform_job(TransformJobName=job_name)\n\n        instance_count, stream_names, positions, client, log_group, dot, color_wrap = _logs_init(\n            self, description, job=""Transform""\n        )\n\n        state = _get_initial_job_state(description, ""TransformJobStatus"", wait)\n\n        # The loop below implements a state machine that alternates between checking the job status\n        # and reading whatever is available in the logs at this point. Note, that if we were\n        # called with wait == False, we never check the job status.\n        #\n        # If wait == TRUE and job is not completed, the initial state is TAILING\n        # If wait == FALSE, the initial state is COMPLETE (doesn\'t matter if the job really is\n        # complete).\n        #\n        # The state table:\n        #\n        # STATE               ACTIONS                        CONDITION             NEW STATE\n        # ----------------    ----------------               -----------------     ----------------\n        # TAILING             Read logs, Pause, Get status   Job complete          JOB_COMPLETE\n        #                                                    Else                  TAILING\n        # JOB_COMPLETE        Read logs, Pause               Any                   COMPLETE\n        # COMPLETE            Read logs, Exit                                      N/A\n        #\n        # Notes:\n        # - The JOB_COMPLETE state forces us to do an extra pause and read any items that got to\n        #   Cloudwatch after the job was marked complete.\n        last_describe_job_call = time.time()\n        while True:\n            _flush_log_streams(\n                stream_names,\n                instance_count,\n                client,\n                log_group,\n                job_name,\n                positions,\n                dot,\n                color_wrap,\n            )\n            if state == LogState.COMPLETE:\n                break\n\n            time.sleep(poll)\n\n            if state == LogState.JOB_COMPLETE:\n                state = LogState.COMPLETE\n            elif time.time() - last_describe_job_call >= 30:\n                description = self.sagemaker_client.describe_transform_job(\n                    TransformJobName=job_name\n                )\n                last_describe_job_call = time.time()\n\n                status = description[""TransformJobStatus""]\n\n                if status in (""Completed"", ""Failed"", ""Stopped""):\n                    print()\n                    state = LogState.JOB_COMPLETE\n\n        if wait:\n            self._check_job_status(job_name, description, ""TransformJobStatus"")\n            if dot:\n                print()\n\n\ndef container_def(image, model_data_url=None, env=None, container_mode=None):\n    """"""Create a definition for executing a container as part of a SageMaker model.\n\n    Args:\n        image (str): Docker image to run for this container.\n        model_data_url (str): S3 URI of data required by this container,\n            e.g. SageMaker training job model artifacts (default: None).\n        env (dict[str, str]): Environment variables to set inside the container (default: None).\n        container_mode (str): The model container mode. Valid modes:\n                * MultiModel: Indicates that model container can support hosting multiple models\n                * SingleModel: Indicates that model container can support hosting a single model\n                This is the default model container mode when container_mode = None\n    Returns:\n        dict[str, str]: A complete container definition object usable with the CreateModel API if\n        passed via `PrimaryContainers` field.\n    """"""\n    if env is None:\n        env = {}\n    c_def = {""Image"": image, ""Environment"": env}\n    if model_data_url:\n        c_def[""ModelDataUrl""] = model_data_url\n    if container_mode:\n        c_def[""Mode""] = container_mode\n    return c_def\n\n\ndef pipeline_container_def(models, instance_type=None):\n    """"""Create a definition for executing a pipeline of containers as part of a SageMaker model.\n\n    Args:\n        models (list[sagemaker.Model]): this will be a list of ``sagemaker.Model`` objects in the\n            order the inference should be invoked.\n        instance_type (str): The EC2 instance type to deploy this Model to. For example,\n            \'ml.p2.xlarge\' (default: None).\n\n    Returns:\n        list[dict[str, str]]: list of container definition objects usable with with the\n            CreateModel API for inference pipelines if passed via `Containers` field.\n    """"""\n    c_defs = []  # should contain list of container definitions in the same order customer passed\n    for model in models:\n        c_defs.append(model.prepare_container_def(instance_type))\n    return c_defs\n\n\ndef production_variant(\n    model_name,\n    instance_type,\n    initial_instance_count=1,\n    variant_name=""AllTraffic"",\n    initial_weight=1,\n    accelerator_type=None,\n):\n    """"""Create a production variant description suitable for use in a ``ProductionVariant`` list as\n    part of a ``CreateEndpointConfig`` request.\n\n    Args:\n        model_name (str): The name of the SageMaker model this production variant references.\n        instance_type (str): The EC2 instance type for this production variant. For example,\n            \'ml.c4.8xlarge\'.\n        initial_instance_count (int): The initial instance count for this production variant\n            (default: 1).\n        variant_name (string): The ``VariantName`` of this production variant\n            (default: \'AllTraffic\').\n        initial_weight (int): The relative ``InitialVariantWeight`` of this production variant\n            (default: 1).\n        accelerator_type (str): Type of Elastic Inference accelerator for this production variant.\n            For example, \'ml.eia1.medium\'.\n            For more information: https://docs.aws.amazon.com/sagemaker/latest/dg/ei.html\n\n    Returns:\n        dict[str, str]: An SageMaker ``ProductionVariant`` description\n    """"""\n    production_variant_configuration = {\n        ""ModelName"": model_name,\n        ""InstanceType"": instance_type,\n        ""InitialInstanceCount"": initial_instance_count,\n        ""VariantName"": variant_name,\n        ""InitialVariantWeight"": initial_weight,\n    }\n\n    if accelerator_type:\n        production_variant_configuration[""AcceleratorType""] = accelerator_type\n\n    return production_variant_configuration\n\n\ndef get_execution_role(sagemaker_session=None):\n    """"""Return the role ARN whose credentials are used to call the API.\n    Throws an exception if\n    Args:\n        sagemaker_session(Session): Current sagemaker session\n    Returns:\n        (str): The role ARN\n    """"""\n    if not sagemaker_session:\n        sagemaker_session = Session()\n    arn = sagemaker_session.get_caller_identity_arn()\n\n    if "":role/"" in arn:\n        return arn\n    message = (\n        ""The current AWS identity is not a role: {}, therefore it cannot be used as a ""\n        ""SageMaker execution role""\n    )\n    raise ValueError(message.format(arn))\n\n\nclass ShuffleConfig(object):\n    """"""\n    Used to configure channel shuffling using a seed. See SageMaker documentation for\n    more detail: https://docs.aws.amazon.com/sagemaker/latest/dg/API_ShuffleConfig.html\n    """"""\n\n    def __init__(self, seed):\n        """"""\n        Create a ShuffleConfig.\n        Args:\n            seed (long): the long value used to seed the shuffled sequence.\n        """"""\n        self.seed = seed\n\n\nclass ModelContainer(object):\n    """"""Amazon SageMaker Model configurations for inference pipelines.\n\n    Attributes:\n        model_data (str): S3 Model artifact location\n        image (str): Docker image URL in ECR\n        env (dict[str,str]): Environment variable mapping\n    """"""\n\n    def __init__(self, model_data, image, env=None):\n        """"""Create a definition of a model which can be part of an Inference Pipeline\n\n        Args:\n            model_data (str): The S3 location of a SageMaker model data ``.tar.gz`` file.\n            image (str): A Docker image URI.\n            env (dict[str, str]): Environment variables to run with ``image`` when hosted in\n                SageMaker (default: None).\n        """"""\n        self.model_data = model_data\n        self.image = image\n        self.env = env\n\n\ndef _create_model_request(\n    name, role, container_def=None, tags=None\n):  # pylint: disable=redefined-outer-name\n    """"""Placeholder docstring""""""\n    request = {""ModelName"": name, ""ExecutionRoleArn"": role}\n\n    if isinstance(container_def, list):\n        request[""Containers""] = container_def\n    else:\n        request[""PrimaryContainer""] = container_def\n\n    if tags:\n        request[""Tags""] = tags\n\n    return request\n\n\ndef _deployment_entity_exists(describe_fn):\n    """"""Placeholder docstring""""""\n    try:\n        describe_fn()\n        return True\n    except ClientError as ce:\n        error_code = ce.response[""Error""][""Code""]\n        if not (\n            error_code == ""ValidationException""\n            and ""Could not find"" in ce.response[""Error""][""Message""]\n        ):\n            raise ce\n        return False\n\n\ndef _train_done(sagemaker_client, job_name, last_desc):\n    """"""Placeholder docstring""""""\n    in_progress_statuses = [""InProgress"", ""Created""]\n\n    desc = sagemaker_client.describe_training_job(TrainingJobName=job_name)\n    status = desc[""TrainingJobStatus""]\n\n    if secondary_training_status_changed(desc, last_desc):\n        print()\n        print(secondary_training_status_message(desc, last_desc), end="""")\n    else:\n        print(""."", end="""")\n    sys.stdout.flush()\n\n    if status in in_progress_statuses:\n        return desc, False\n\n    print()\n    return desc, True\n\n\ndef _processing_job_status(sagemaker_client, job_name):\n    """"""Prints the job status for the given processing job name.\n    Returns the job description.\n\n    Args:\n        sagemaker_client: The boto3 SageMaker client.\n        job_name (str): The name of the job for which the status\n            is requested.\n\n    Returns:\n        dict: The processing job description.\n\n    """"""\n    compile_status_codes = {\n        ""Completed"": ""!"",\n        ""InProgress"": ""."",\n        ""Failed"": ""*"",\n        ""Stopped"": ""s"",\n        ""Stopping"": ""_"",\n    }\n    in_progress_statuses = [""InProgress"", ""Stopping"", ""Starting""]\n\n    desc = sagemaker_client.describe_processing_job(ProcessingJobName=job_name)\n    status = desc[""ProcessingJobStatus""]\n\n    status = _STATUS_CODE_TABLE.get(status, status)\n    print(compile_status_codes.get(status, ""?""), end="""")\n    sys.stdout.flush()\n\n    if status in in_progress_statuses:\n        return None\n\n    return desc\n\n\ndef _compilation_job_status(sagemaker_client, job_name):\n    """"""Placeholder docstring""""""\n    compile_status_codes = {\n        ""Completed"": ""!"",\n        ""InProgress"": ""."",\n        ""Failed"": ""*"",\n        ""Stopped"": ""s"",\n        ""Stopping"": ""_"",\n    }\n    in_progress_statuses = [""InProgress"", ""Stopping"", ""Starting""]\n\n    desc = sagemaker_client.describe_compilation_job(CompilationJobName=job_name)\n    status = desc[""CompilationJobStatus""]\n\n    status = _STATUS_CODE_TABLE.get(status, status)\n    print(compile_status_codes.get(status, ""?""), end="""")\n    sys.stdout.flush()\n\n    if status in in_progress_statuses:\n        return None\n\n    return desc\n\n\ndef _tuning_job_status(sagemaker_client, job_name):\n    """"""Placeholder docstring""""""\n    tuning_status_codes = {\n        ""Completed"": ""!"",\n        ""InProgress"": ""."",\n        ""Failed"": ""*"",\n        ""Stopped"": ""s"",\n        ""Stopping"": ""_"",\n    }\n    in_progress_statuses = [""InProgress"", ""Stopping""]\n\n    desc = sagemaker_client.describe_hyper_parameter_tuning_job(\n        HyperParameterTuningJobName=job_name\n    )\n    status = desc[""HyperParameterTuningJobStatus""]\n\n    print(tuning_status_codes.get(status, ""?""), end="""")\n    sys.stdout.flush()\n\n    if status in in_progress_statuses:\n        return None\n\n    print("""")\n    return desc\n\n\ndef _transform_job_status(sagemaker_client, job_name):\n    """"""Placeholder docstring""""""\n    transform_job_status_codes = {\n        ""Completed"": ""!"",\n        ""InProgress"": ""."",\n        ""Failed"": ""*"",\n        ""Stopped"": ""s"",\n        ""Stopping"": ""_"",\n    }\n    in_progress_statuses = [""InProgress"", ""Stopping""]\n\n    desc = sagemaker_client.describe_transform_job(TransformJobName=job_name)\n    status = desc[""TransformJobStatus""]\n\n    print(transform_job_status_codes.get(status, ""?""), end="""")\n    sys.stdout.flush()\n\n    if status in in_progress_statuses:\n        return None\n\n    print("""")\n    return desc\n\n\ndef _auto_ml_job_status(sagemaker_client, job_name):\n    """"""Placeholder docstring""""""\n    auto_ml_job_status_codes = {\n        ""Completed"": ""!"",\n        ""InProgress"": ""."",\n        ""Failed"": ""*"",\n        ""Stopped"": ""s"",\n        ""Stopping"": ""_"",\n    }\n    in_progress_statuses = [""InProgress"", ""Stopping""]\n\n    desc = sagemaker_client.describe_auto_ml_job(AutoMLJobName=job_name)\n    status = desc[""AutoMLJobStatus""]\n\n    print(auto_ml_job_status_codes.get(status, ""?""), end="""")\n    sys.stdout.flush()\n\n    if status in in_progress_statuses:\n        return None\n\n    print("""")\n    return desc\n\n\ndef _create_model_package_status(sagemaker_client, model_package_name):\n    """"""Placeholder docstring""""""\n    in_progress_statuses = [""InProgress"", ""Pending""]\n\n    desc = sagemaker_client.describe_model_package(ModelPackageName=model_package_name)\n    status = desc[""ModelPackageStatus""]\n    print(""."", end="""")\n    sys.stdout.flush()\n\n    if status in in_progress_statuses:\n        return None\n\n    print("""")\n    return desc\n\n\ndef _deploy_done(sagemaker_client, endpoint_name):\n    """"""Placeholder docstring""""""\n    hosting_status_codes = {\n        ""OutOfService"": ""x"",\n        ""Creating"": ""-"",\n        ""Updating"": ""-"",\n        ""InService"": ""!"",\n        ""RollingBack"": ""<"",\n        ""Deleting"": ""o"",\n        ""Failed"": ""*"",\n    }\n    in_progress_statuses = [""Creating"", ""Updating""]\n\n    desc = sagemaker_client.describe_endpoint(EndpointName=endpoint_name)\n    status = desc[""EndpointStatus""]\n\n    print(hosting_status_codes.get(status, ""?""), end="""")\n    sys.stdout.flush()\n\n    return None if status in in_progress_statuses else desc\n\n\ndef _wait_until_training_done(callable_fn, desc, poll=5):\n    """"""Placeholder docstring""""""\n    job_desc, finished = callable_fn(desc)\n    while not finished:\n        time.sleep(poll)\n        job_desc, finished = callable_fn(job_desc)\n    return job_desc\n\n\ndef _wait_until(callable_fn, poll=5):\n    """"""Placeholder docstring""""""\n    result = callable_fn()\n    while result is None:\n        time.sleep(poll)\n        result = callable_fn()\n    return result\n\n\ndef _expand_container_def(c_def):\n    """"""Placeholder docstring""""""\n    if isinstance(c_def, six.string_types):\n        return container_def(c_def)\n    return c_def\n\n\ndef _vpc_config_from_training_job(\n    training_job_desc, vpc_config_override=vpc_utils.VPC_CONFIG_DEFAULT\n):\n    """"""Placeholder docstring""""""\n    if vpc_config_override is vpc_utils.VPC_CONFIG_DEFAULT:\n        return training_job_desc.get(vpc_utils.VPC_CONFIG_KEY)\n    return vpc_utils.sanitize(vpc_config_override)\n\n\ndef _get_initial_job_state(description, status_key, wait):\n    """"""Placeholder docstring""""""\n    status = description[status_key]\n    job_already_completed = status in (""Completed"", ""Failed"", ""Stopped"")\n    return LogState.TAILING if wait and not job_already_completed else LogState.COMPLETE\n\n\ndef _debug_rule_statuses_changed(current_statuses, last_statuses):\n    """"""Checks the rule evaluation statuses for SageMaker Debugger rules.""""""\n    if not last_statuses:\n        return True\n\n    for current, last in zip(current_statuses, last_statuses):\n        if (current[""RuleConfigurationName""] == last[""RuleConfigurationName""]) and (\n            current[""RuleEvaluationStatus""] != last[""RuleEvaluationStatus""]\n        ):\n            return True\n\n    return False\n\n\ndef _logs_init(sagemaker_session, description, job):\n    """"""Placeholder docstring""""""\n    if job == ""Training"":\n        instance_count = description[""ResourceConfig""][""InstanceCount""]\n    elif job == ""Transform"":\n        instance_count = description[""TransformResources""][""InstanceCount""]\n    elif job == ""Processing"":\n        instance_count = description[""ProcessingResources""][""ClusterConfig""][""InstanceCount""]\n    elif job == ""AutoML"":\n        instance_count = 0\n\n    stream_names = []  # The list of log streams\n    positions = {}  # The current position in each stream, map of stream name -> position\n\n    # Increase retries allowed (from default of 4), as we don\'t want waiting for a training job\n    # to be interrupted by a transient exception.\n    config = botocore.config.Config(retries={""max_attempts"": 15})\n    client = sagemaker_session.boto_session.client(""logs"", config=config)\n    log_group = ""/aws/sagemaker/"" + job + ""Jobs""\n\n    dot = False\n\n    color_wrap = sagemaker.logs.ColorWrap()\n\n    return instance_count, stream_names, positions, client, log_group, dot, color_wrap\n\n\ndef _flush_log_streams(\n    stream_names, instance_count, client, log_group, job_name, positions, dot, color_wrap\n):\n    """"""Placeholder docstring""""""\n    if len(stream_names) < instance_count:\n        # Log streams are created whenever a container starts writing to stdout/err, so this list\n        # may be dynamic until we have a stream for every instance.\n        try:\n            streams = client.describe_log_streams(\n                logGroupName=log_group,\n                logStreamNamePrefix=job_name + ""/"",\n                orderBy=""LogStreamName"",\n                limit=min(instance_count, 50),\n            )\n            stream_names = [s[""logStreamName""] for s in streams[""logStreams""]]\n\n            while ""nextToken"" in streams:\n                streams = client.describe_log_streams(\n                    logGroupName=log_group,\n                    logStreamNamePrefix=job_name + ""/"",\n                    orderBy=""LogStreamName"",\n                    limit=50,\n                )\n\n                stream_names.extend([s[""logStreamName""] for s in streams[""logStreams""]])\n\n            positions.update(\n                [\n                    (s, sagemaker.logs.Position(timestamp=0, skip=0))\n                    for s in stream_names\n                    if s not in positions\n                ]\n            )\n        except ClientError as e:\n            # On the very first training job run on an account, there\'s no log group until\n            # the container starts logging, so ignore any errors thrown about that\n            err = e.response.get(""Error"", {})\n            if err.get(""Code"", None) != ""ResourceNotFoundException"":\n                raise\n\n    if len(stream_names) > 0:\n        if dot:\n            print("""")\n            dot = False\n        for idx, event in sagemaker.logs.multi_stream_iter(\n            client, log_group, stream_names, positions\n        ):\n            color_wrap(idx, event[""message""])\n            ts, count = positions[stream_names[idx]]\n            if event[""timestamp""] == ts:\n                positions[stream_names[idx]] = sagemaker.logs.Position(timestamp=ts, skip=count + 1)\n            else:\n                positions[stream_names[idx]] = sagemaker.logs.Position(\n                    timestamp=event[""timestamp""], skip=1\n                )\n    else:\n        dot = True\n        print(""."", end="""")\n        sys.stdout.flush()\n'"
src/sagemaker/transformer.py,1,"b'# Copyright 2018-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nfrom botocore import exceptions\n\nfrom sagemaker.job import _Job\nfrom sagemaker.session import Session\nfrom sagemaker.utils import base_name_from_image, name_from_base\n\n\nclass Transformer(object):\n    """"""A class for handling creating and interacting with Amazon SageMaker\n    transform jobs.\n    """"""\n\n    def __init__(\n        self,\n        model_name,\n        instance_count,\n        instance_type,\n        strategy=None,\n        assemble_with=None,\n        output_path=None,\n        output_kms_key=None,\n        accept=None,\n        max_concurrent_transforms=None,\n        max_payload=None,\n        tags=None,\n        env=None,\n        base_transform_job_name=None,\n        sagemaker_session=None,\n        volume_kms_key=None,\n    ):\n        """"""Initialize a ``Transformer``.\n\n        Args:\n            model_name (str): Name of the SageMaker model being used for the\n                transform job.\n            instance_count (int): Number of EC2 instances to use.\n            instance_type (str): Type of EC2 instance to use, for example,\n                \'ml.c4.xlarge\'.\n            strategy (str): The strategy used to decide how to batch records in\n                a single request (default: None). Valid values: \'MultiRecord\'\n                and \'SingleRecord\'.\n            assemble_with (str): How the output is assembled (default: None).\n                Valid values: \'Line\' or \'None\'.\n            output_path (str): S3 location for saving the transform result. If\n                not specified, results are stored to a default bucket.\n            output_kms_key (str): Optional. KMS key ID for encrypting the\n                transform output (default: None).\n            accept (str): The accept header passed by the client to\n                the inference endpoint. If it is supported by the endpoint,\n                it will be the format of the batch transform output.\n            max_concurrent_transforms (int): The maximum number of HTTP requests\n                to be made to each individual transform container at one time.\n            max_payload (int): Maximum size of the payload in a single HTTP\n                request to the container in MB.\n            tags (list[dict]): List of tags for labeling a transform job\n                (default: None). For more, see the SageMaker API documentation for\n                `Tag <https://docs.aws.amazon.com/sagemaker/latest/dg/API_Tag.html>`_.\n            env (dict): Environment variables to be set for use during the\n                transform job (default: None).\n            base_transform_job_name (str): Prefix for the transform job when the\n                :meth:`~sagemaker.transformer.Transformer.transform` method\n                launches. If not specified, a default prefix will be generated\n                based on the training image name that was used to train the\n                model associated with the transform job.\n            sagemaker_session (sagemaker.session.Session): Session object which\n                manages interactions with Amazon SageMaker APIs and any other\n                AWS services needed. If not specified, the estimator creates one\n                using the default AWS configuration chain.\n            volume_kms_key (str): Optional. KMS key ID for encrypting the volume\n                attached to the ML compute instance (default: None).\n        """"""\n        self.model_name = model_name\n        self.strategy = strategy\n        self.env = env\n\n        self.output_path = output_path\n        self.output_kms_key = output_kms_key\n        self.accept = accept\n        self.assemble_with = assemble_with\n\n        self.instance_count = instance_count\n        self.instance_type = instance_type\n        self.volume_kms_key = volume_kms_key\n\n        self.max_concurrent_transforms = max_concurrent_transforms\n        self.max_payload = max_payload\n        self.tags = tags\n\n        self.base_transform_job_name = base_transform_job_name\n        self._current_job_name = None\n        self.latest_transform_job = None\n        self._reset_output_path = False\n\n        self.sagemaker_session = sagemaker_session or Session()\n\n    def transform(\n        self,\n        data,\n        data_type=""S3Prefix"",\n        content_type=None,\n        compression_type=None,\n        split_type=None,\n        job_name=None,\n        input_filter=None,\n        output_filter=None,\n        join_source=None,\n        experiment_config=None,\n        wait=False,\n        logs=False,\n    ):\n        """"""Start a new transform job.\n\n        Args:\n            data (str): Input data location in S3.\n            data_type (str): What the S3 location defines (default: \'S3Prefix\').\n                Valid values:\n\n                * \'S3Prefix\' - the S3 URI defines a key name prefix. All objects with this prefix\n                    will be used as inputs for the transform job.\n\n                * \'ManifestFile\' - the S3 URI points to a single manifest file listing each S3\n                    object to use as an input for the transform job.\n\n            content_type (str): MIME type of the input data (default: None).\n            compression_type (str): Compression type of the input data, if\n                compressed (default: None). Valid values: \'Gzip\', None.\n            split_type (str): The record delimiter for the input object\n                (default: \'None\'). Valid values: \'None\', \'Line\', \'RecordIO\', and\n                \'TFRecord\'.\n            job_name (str): job name (default: None). If not specified, one will\n                be generated.\n            input_filter (str): A JSONPath to select a portion of the input to\n                pass to the algorithm container for inference. If you omit the\n                field, it gets the value \'$\', representing the entire input.\n                For CSV data, each row is taken as a JSON array,\n                so only index-based JSONPaths can be applied, e.g. $[0], $[1:].\n                CSV data should follow the `RFC format <https://tools.ietf.org/html/rfc4180>`_.\n                See `Supported JSONPath Operators\n                <https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform-data-processing.html#data-processing-operators>`_\n                for a table of supported JSONPath operators.\n                For more information, see the SageMaker API documentation for\n                `CreateTransformJob\n                <https://docs.aws.amazon.com/sagemaker/latest/dg/API_CreateTransformJob.html>`_.\n                Some examples: ""$[1:]"", ""$.features"" (default: None).\n            output_filter (str): A JSONPath to select a portion of the\n                joined/original output to return as the output.\n                For more information, see the SageMaker API documentation for\n                `CreateTransformJob\n                <https://docs.aws.amazon.com/sagemaker/latest/dg/API_CreateTransformJob.html>`_.\n                Some examples: ""$[1:]"", ""$.prediction"" (default: None).\n            join_source (str): The source of data to be joined to the transform\n                output. It can be set to \'Input\' meaning the entire input record\n                will be joined to the inference result. You can use OutputFilter\n                to select the useful portion before uploading to S3. (default:\n                None). Valid values: Input, None.\n            experiment_config (dict[str, str]): Experiment management configuration.\n                Dictionary contains three optional keys,\n                \'ExperimentName\', \'TrialName\', and \'TrialComponentDisplayName\'.\n                (default: ``None``).\n            wait (bool): Whether the call should wait until the job completes\n                (default: False).\n            logs (bool): Whether to show the logs produced by the job.\n                Only meaningful when wait is True (default: False).\n        """"""\n        local_mode = self.sagemaker_session.local_mode\n        if not local_mode and not data.startswith(""s3://""):\n            raise ValueError(""Invalid S3 URI: {}"".format(data))\n\n        if job_name is not None:\n            self._current_job_name = job_name\n        else:\n            base_name = self.base_transform_job_name\n\n            if base_name is None:\n                base_name = self._retrieve_base_name()\n\n            self._current_job_name = name_from_base(base_name)\n\n        if self.output_path is None or self._reset_output_path is True:\n            self.output_path = ""s3://{}/{}"".format(\n                self.sagemaker_session.default_bucket(), self._current_job_name\n            )\n            self._reset_output_path = True\n\n        self.latest_transform_job = _TransformJob.start_new(\n            self,\n            data,\n            data_type,\n            content_type,\n            compression_type,\n            split_type,\n            input_filter,\n            output_filter,\n            join_source,\n            experiment_config,\n        )\n\n        if wait:\n            self.latest_transform_job.wait(logs=logs)\n\n    def delete_model(self):\n        """"""Delete the corresponding SageMaker model for this Transformer.""""""\n        self.sagemaker_session.delete_model(self.model_name)\n\n    def _retrieve_base_name(self):\n        """"""Placeholder docstring""""""\n        image_name = self._retrieve_image_name()\n\n        if image_name:\n            return base_name_from_image(image_name)\n\n        return self.model_name\n\n    def _retrieve_image_name(self):\n        """"""Placeholder docstring""""""\n        try:\n            model_desc = self.sagemaker_session.sagemaker_client.describe_model(\n                ModelName=self.model_name\n            )\n\n            primary_container = model_desc.get(""PrimaryContainer"")\n            if primary_container:\n                return primary_container.get(""Image"")\n\n            containers = model_desc.get(""Containers"")\n            if containers:\n                return containers[0].get(""Image"")\n\n            return None\n\n        except exceptions.ClientError:\n            raise ValueError(\n                ""Failed to fetch model information for %s. ""\n                ""Please ensure that the model exists. ""\n                ""Local instance types require locally created models."" % self.model_name\n            )\n\n    def wait(self, logs=True):\n        """"""Placeholder docstring""""""\n        self._ensure_last_transform_job()\n        self.latest_transform_job.wait(logs=logs)\n\n    def stop_transform_job(self, wait=True):\n        """"""Stop latest running batch transform job.\n        """"""\n        self._ensure_last_transform_job()\n        self.latest_transform_job.stop()\n        if wait:\n            self.latest_transform_job.wait()\n\n    def _ensure_last_transform_job(self):\n        """"""Placeholder docstring""""""\n        if self.latest_transform_job is None:\n            raise ValueError(""No transform job available"")\n\n    @classmethod\n    def attach(cls, transform_job_name, sagemaker_session=None):\n        """"""Attach an existing transform job to a new Transformer instance\n\n        Args:\n            transform_job_name (str): Name for the transform job to be attached.\n            sagemaker_session (sagemaker.session.Session): Session object which\n                manages interactions with Amazon SageMaker APIs and any other\n                AWS services needed. If not specified, one will be created using\n                the default AWS configuration chain.\n\n        Returns:\n            sagemaker.transformer.Transformer: The Transformer instance with the\n            specified transform job attached.\n        """"""\n        sagemaker_session = sagemaker_session or Session()\n\n        job_details = sagemaker_session.sagemaker_client.describe_transform_job(\n            TransformJobName=transform_job_name\n        )\n        init_params = cls._prepare_init_params_from_job_description(job_details)\n        transformer = cls(sagemaker_session=sagemaker_session, **init_params)\n        transformer.latest_transform_job = _TransformJob(\n            sagemaker_session=sagemaker_session, job_name=init_params[""base_transform_job_name""]\n        )\n\n        return transformer\n\n    @classmethod\n    def _prepare_init_params_from_job_description(cls, job_details):\n        """"""Convert the transform job description to init params that can be\n        handled by the class constructor\n\n        Args:\n            job_details (dict): the returned job details from a\n                describe_transform_job API call.\n\n        Returns:\n            dict: The transformed init_params\n        """"""\n        init_params = dict()\n\n        init_params[""model_name""] = job_details[""ModelName""]\n        init_params[""instance_count""] = job_details[""TransformResources""][""InstanceCount""]\n        init_params[""instance_type""] = job_details[""TransformResources""][""InstanceType""]\n        init_params[""volume_kms_key""] = job_details[""TransformResources""].get(""VolumeKmsKeyId"")\n        init_params[""strategy""] = job_details.get(""BatchStrategy"")\n        init_params[""assemble_with""] = job_details[""TransformOutput""].get(""AssembleWith"")\n        init_params[""output_path""] = job_details[""TransformOutput""][""S3OutputPath""]\n        init_params[""output_kms_key""] = job_details[""TransformOutput""].get(""KmsKeyId"")\n        init_params[""accept""] = job_details[""TransformOutput""].get(""Accept"")\n        init_params[""max_concurrent_transforms""] = job_details.get(""MaxConcurrentTransforms"")\n        init_params[""max_payload""] = job_details.get(""MaxPayloadInMB"")\n        init_params[""base_transform_job_name""] = job_details[""TransformJobName""]\n\n        return init_params\n\n\nclass _TransformJob(_Job):\n    """"""Placeholder docstring""""""\n\n    @classmethod\n    def start_new(\n        cls,\n        transformer,\n        data,\n        data_type,\n        content_type,\n        compression_type,\n        split_type,\n        input_filter,\n        output_filter,\n        join_source,\n        experiment_config,\n    ):\n        """"""\n        Args:\n            transformer:\n            data:\n            data_type:\n            content_type:\n            compression_type:\n            split_type:\n            input_filter:\n            output_filter:\n            join_source:\n            experiment_config:\n        """"""\n        config = _TransformJob._load_config(\n            data, data_type, content_type, compression_type, split_type, transformer\n        )\n        data_processing = _TransformJob._prepare_data_processing(\n            input_filter, output_filter, join_source\n        )\n\n        transformer.sagemaker_session.transform(\n            job_name=transformer._current_job_name,\n            model_name=transformer.model_name,\n            strategy=transformer.strategy,\n            max_concurrent_transforms=transformer.max_concurrent_transforms,\n            max_payload=transformer.max_payload,\n            env=transformer.env,\n            input_config=config[""input_config""],\n            output_config=config[""output_config""],\n            resource_config=config[""resource_config""],\n            experiment_config=experiment_config,\n            tags=transformer.tags,\n            data_processing=data_processing,\n        )\n\n        return cls(transformer.sagemaker_session, transformer._current_job_name)\n\n    def wait(self, logs=True):\n        if logs:\n            self.sagemaker_session.logs_for_transform_job(self.job_name, wait=True)\n        else:\n            self.sagemaker_session.wait_for_transform_job(self.job_name)\n\n    def stop(self):\n        """"""Placeholder docstring""""""\n        self.sagemaker_session.stop_transform_job(name=self.job_name)\n\n    @staticmethod\n    def _load_config(data, data_type, content_type, compression_type, split_type, transformer):\n        """"""\n        Args:\n            data:\n            data_type:\n            content_type:\n            compression_type:\n            split_type:\n            transformer:\n        """"""\n        input_config = _TransformJob._format_inputs_to_input_config(\n            data, data_type, content_type, compression_type, split_type\n        )\n\n        output_config = _TransformJob._prepare_output_config(\n            transformer.output_path,\n            transformer.output_kms_key,\n            transformer.assemble_with,\n            transformer.accept,\n        )\n\n        resource_config = _TransformJob._prepare_resource_config(\n            transformer.instance_count, transformer.instance_type, transformer.volume_kms_key\n        )\n\n        return {\n            ""input_config"": input_config,\n            ""output_config"": output_config,\n            ""resource_config"": resource_config,\n        }\n\n    @staticmethod\n    def _format_inputs_to_input_config(data, data_type, content_type, compression_type, split_type):\n        """"""\n        Args:\n            data:\n            data_type:\n            content_type:\n            compression_type:\n            split_type:\n        """"""\n        config = {""DataSource"": {""S3DataSource"": {""S3DataType"": data_type, ""S3Uri"": data}}}\n\n        if content_type is not None:\n            config[""ContentType""] = content_type\n\n        if compression_type is not None:\n            config[""CompressionType""] = compression_type\n\n        if split_type is not None:\n            config[""SplitType""] = split_type\n\n        return config\n\n    @staticmethod\n    def _prepare_output_config(s3_path, kms_key_id, assemble_with, accept):\n        """"""\n        Args:\n            s3_path:\n            kms_key_id:\n            assemble_with:\n            accept:\n        """"""\n        config = super(_TransformJob, _TransformJob)._prepare_output_config(s3_path, kms_key_id)\n\n        if assemble_with is not None:\n            config[""AssembleWith""] = assemble_with\n\n        if accept is not None:\n            config[""Accept""] = accept\n\n        return config\n\n    @staticmethod\n    def _prepare_resource_config(instance_count, instance_type, volume_kms_key):\n        """"""\n        Args:\n            instance_count:\n            instance_type:\n            volume_kms_key:\n        """"""\n        config = {""InstanceCount"": instance_count, ""InstanceType"": instance_type}\n\n        if volume_kms_key is not None:\n            config[""VolumeKmsKeyId""] = volume_kms_key\n\n        return config\n\n    @staticmethod\n    def _prepare_data_processing(input_filter, output_filter, join_source):\n        """"""\n        Args:\n            input_filter:\n            output_filter:\n            join_source:\n        """"""\n        config = {}\n\n        if input_filter is not None:\n            config[""InputFilter""] = input_filter\n\n        if output_filter is not None:\n            config[""OutputFilter""] = output_filter\n\n        if join_source is not None:\n            config[""JoinSource""] = join_source\n\n        if len(config) == 0:\n            return None\n\n        return config\n'"
src/sagemaker/tuner.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nimport importlib\nimport inspect\nimport json\nimport logging\nfrom enum import Enum\n\nimport sagemaker\nfrom sagemaker.amazon.amazon_estimator import (\n    RecordSet,\n    AmazonAlgorithmEstimatorBase,\n    FileSystemRecordSet,\n)\nfrom sagemaker.amazon.hyperparameter import Hyperparameter as hp  # noqa\nfrom sagemaker.analytics import HyperparameterTuningJobAnalytics\nfrom sagemaker.estimator import Framework\nfrom sagemaker.job import _Job\nfrom sagemaker.parameter import (\n    CategoricalParameter,\n    ContinuousParameter,\n    IntegerParameter,\n    ParameterRange,\n)\nfrom sagemaker.session import Session\nfrom sagemaker.session import s3_input\nfrom sagemaker.utils import base_name_from_image, name_from_base, to_str\n\nAMAZON_ESTIMATOR_MODULE = ""sagemaker""\nAMAZON_ESTIMATOR_CLS_NAMES = {\n    ""factorization-machines"": ""FactorizationMachines"",\n    ""kmeans"": ""KMeans"",\n    ""lda"": ""LDA"",\n    ""linear-learner"": ""LinearLearner"",\n    ""ntm"": ""NTM"",\n    ""randomcutforest"": ""RandomCutForest"",\n    ""knn"": ""KNN"",\n    ""object2vec"": ""Object2Vec"",\n}\nHYPERPARAMETER_TUNING_JOB_NAME = ""HyperParameterTuningJobName""\nPARENT_HYPERPARAMETER_TUNING_JOBS = ""ParentHyperParameterTuningJobs""\nWARM_START_TYPE = ""WarmStartType""\n\n\nclass WarmStartTypes(Enum):\n    """"""Warm Start Configuration type. There can be two types of warm start jobs:\n    * IdenticalDataAndAlgorithm: Type of warm start that allows users to reuse\n    training results from existing tuning jobs that have the same algorithm code\n    and datasets. * TransferLearning: Type of warm start that allows users to\n    reuse training results from existing tuning jobs that have similar algorithm\n    code and datasets.\n    """"""\n\n    IDENTICAL_DATA_AND_ALGORITHM = ""IdenticalDataAndAlgorithm""\n    TRANSFER_LEARNING = ""TransferLearning""\n\n\nclass WarmStartConfig(object):\n    """"""Warm Start Configuration which defines the nature of the warm start\n    ``HyperparameterTuner``, with type and parents for warm start.\n\n    Examples:\n        >>> warm_start_config = WarmStartConfig(\n        >>>                         type=WarmStartTypes.TransferLearning, parents={""p1"",""p2""})\n        >>> warm_start_config.type\n        ""TransferLearning""\n        >>> warm_start_config.parents\n        {""p1"",""p2""}\n    """"""\n\n    def __init__(self, warm_start_type, parents):\n        """"""Initializes the ``WarmStartConfig`` with the provided\n        ``WarmStartTypes`` and parents.\n\n        Args:\n            warm_start_type (sagemaker.tuner.WarmStartTypes): This should be one\n                of the supported warm start types in WarmStartType\n            parents (set{str}): Set of parent tuning jobs which will be used to\n                warm start the new tuning job.\n        """"""\n\n        if warm_start_type not in WarmStartTypes:\n            raise ValueError(\n                ""Invalid type: {}, valid warm start types are: [{}]"".format(\n                    warm_start_type, [t for t in WarmStartTypes]\n                )\n            )\n\n        if not parents:\n            raise ValueError(\n                ""Invalid parents: {}, parents should not be None/empty"".format(parents)\n            )\n\n        self.type = warm_start_type\n        self.parents = set(parents)\n\n    @classmethod\n    def from_job_desc(cls, warm_start_config):\n        """"""Creates an instance of ``WarmStartConfig`` class, from warm start\n        configuration response from DescribeTrainingJob.\n\n        Examples:\n            >>> warm_start_config = WarmStartConfig.from_job_desc(warm_start_config={\n            >>>    ""WarmStartType"":""TransferLearning"",\n            >>>    ""ParentHyperParameterTuningJobs"": [\n            >>>        {\'HyperParameterTuningJobName\': ""p1""},\n            >>>        {\'HyperParameterTuningJobName\': ""p2""},\n            >>>    ]\n            >>>})\n            >>> warm_start_config.type\n            ""TransferLearning""\n            >>> warm_start_config.parents\n            [""p1"",""p2""]\n\n        Args:\n            warm_start_config (dict): The expected format of the\n                ``warm_start_config`` contains two first-class\n\n        Returns:\n            sagemaker.tuner.WarmStartConfig: De-serialized instance of\n            WarmStartConfig containing the type and parents provided as part of\n            ``warm_start_config``.\n        """"""\n        if (\n            not warm_start_config\n            or WARM_START_TYPE not in warm_start_config\n            or PARENT_HYPERPARAMETER_TUNING_JOBS not in warm_start_config\n        ):\n            return None\n\n        parents = []\n        for parent in warm_start_config[PARENT_HYPERPARAMETER_TUNING_JOBS]:\n            parents.append(parent[HYPERPARAMETER_TUNING_JOB_NAME])\n\n        return cls(\n            warm_start_type=WarmStartTypes(warm_start_config[WARM_START_TYPE]), parents=parents\n        )\n\n    def to_input_req(self):\n        """"""Converts the ``self`` instance to the desired input request format.\n\n        Examples:\n            >>> warm_start_config = WarmStartConfig\n            (\n                warm_start_type=WarmStartTypes.TransferLearning,parents=[""p1,p2""]\n            )\n            >>> warm_start_config.to_input_req()\n            {\n                ""WarmStartType"":""TransferLearning"",\n                ""ParentHyperParameterTuningJobs"": [\n                    {\'HyperParameterTuningJobName\': ""p1""},\n                    {\'HyperParameterTuningJobName\': ""p2""},\n                ]\n            }\n\n        Returns:\n            dict: Containing the ""WarmStartType"" and\n            ""ParentHyperParameterTuningJobs"" as the first class fields.\n        """"""\n        return {\n            WARM_START_TYPE: self.type.value,\n            PARENT_HYPERPARAMETER_TUNING_JOBS: [\n                {HYPERPARAMETER_TUNING_JOB_NAME: parent} for parent in self.parents\n            ],\n        }\n\n\nclass HyperparameterTuner(object):\n    """"""A class for creating and interacting with Amazon SageMaker hyperparameter\n    tuning jobs, as well as deploying the resulting model(s).\n    """"""\n\n    TUNING_JOB_NAME_MAX_LENGTH = 32\n\n    SAGEMAKER_ESTIMATOR_MODULE = ""sagemaker_estimator_module""\n    SAGEMAKER_ESTIMATOR_CLASS_NAME = ""sagemaker_estimator_class_name""\n\n    DEFAULT_ESTIMATOR_MODULE = ""sagemaker.estimator""\n    DEFAULT_ESTIMATOR_CLS_NAME = ""Estimator""\n\n    def __init__(\n        self,\n        estimator,\n        objective_metric_name,\n        hyperparameter_ranges,\n        metric_definitions=None,\n        strategy=""Bayesian"",\n        objective_type=""Maximize"",\n        max_jobs=1,\n        max_parallel_jobs=1,\n        tags=None,\n        base_tuning_job_name=None,\n        warm_start_config=None,\n        early_stopping_type=""Off"",\n        estimator_name=None,\n    ):\n        """"""Initialize a ``HyperparameterTuner``. It takes an estimator to obtain\n        configuration information for training jobs that are created as the\n        result of a hyperparameter tuning job.\n\n        Args:\n            estimator (sagemaker.estimator.EstimatorBase): An estimator object\n                that has been initialized with the desired configuration. There\n                does not need to be a training job associated with this\n                instance.\n            objective_metric_name (str): Name of the metric for evaluating\n                training jobs.\n            hyperparameter_ranges (dict[str, sagemaker.parameter.ParameterRange]): Dictionary of\n                parameter ranges. These parameter ranges can be one\n                of three types: Continuous, Integer, or Categorical. The keys of\n                the dictionary are the names of the hyperparameter, and the\n                values are the appropriate parameter range class to represent\n                the range.\n            metric_definitions (list[dict]): A list of dictionaries that defines\n                the metric(s) used to evaluate the training jobs (default:\n                None). Each dictionary contains two keys: \'Name\' for the name of\n                the metric, and \'Regex\' for the regular expression used to\n                extract the metric from the logs. This should be defined only\n                for hyperparameter tuning jobs that don\'t use an Amazon\n                algorithm.\n            strategy (str): Strategy to be used for hyperparameter estimations\n                (default: \'Bayesian\').\n            objective_type (str): The type of the objective metric for\n                evaluating training jobs. This value can be either \'Minimize\' or\n                \'Maximize\' (default: \'Maximize\').\n            max_jobs (int): Maximum total number of training jobs to start for\n                the hyperparameter tuning job (default: 1).\n            max_parallel_jobs (int): Maximum number of parallel training jobs to\n                start (default: 1).\n            tags (list[dict]): List of tags for labeling the tuning job\n                (default: None). For more, see\n                https://docs.aws.amazon.com/sagemaker/latest/dg/API_Tag.html.\n            base_tuning_job_name (str): Prefix for the hyperparameter tuning job\n                name when the :meth:`~sagemaker.tuner.HyperparameterTuner.fit`\n                method launches. If not specified, a default job name is\n                generated, based on the training image name and current\n                timestamp.\n            warm_start_config (sagemaker.tuner.WarmStartConfig): A\n                ``WarmStartConfig`` object that has been initialized with the\n                configuration defining the nature of warm start tuning job.\n            early_stopping_type (str): Specifies whether early stopping is\n                enabled for the job. Can be either \'Auto\' or \'Off\' (default:\n                \'Off\'). If set to \'Off\', early stopping will not be attempted.\n                If set to \'Auto\', early stopping of some training jobs may\n                happen, but is not guaranteed to.\n            estimator_name (str): A unique name to identify an estimator within the\n                hyperparameter tuning job, when more than one estimator is used with\n                the same tuning job (default: None).\n        """"""\n        if hyperparameter_ranges is None or len(hyperparameter_ranges) == 0:\n            raise ValueError(""Need to specify hyperparameter ranges"")\n\n        if estimator_name is not None:\n            self.estimator = None\n            self.objective_metric_name = None\n            self._hyperparameter_ranges = None\n            self.metric_definitions = None\n            self.estimator_dict = {estimator_name: estimator}\n            self.objective_metric_name_dict = {estimator_name: objective_metric_name}\n            self._hyperparameter_ranges_dict = {estimator_name: hyperparameter_ranges}\n            self.metric_definitions_dict = (\n                {estimator_name: metric_definitions} if metric_definitions is not None else {}\n            )\n            self.static_hyperparameters = None\n        else:\n            self.estimator = estimator\n            self.objective_metric_name = objective_metric_name\n            self._hyperparameter_ranges = hyperparameter_ranges\n            self.metric_definitions = metric_definitions\n            self.estimator_dict = None\n            self.objective_metric_name_dict = None\n            self._hyperparameter_ranges_dict = None\n            self.metric_definitions_dict = None\n            self.static_hyperparameters_dict = None\n\n        self._validate_parameter_ranges(estimator, hyperparameter_ranges)\n\n        self.strategy = strategy\n        self.objective_type = objective_type\n        self.max_jobs = max_jobs\n        self.max_parallel_jobs = max_parallel_jobs\n\n        self.tags = tags\n        self.base_tuning_job_name = base_tuning_job_name\n        self._current_job_name = None\n        self.latest_tuning_job = None\n        self.warm_start_config = warm_start_config\n        self.early_stopping_type = early_stopping_type\n\n    def _prepare_for_tuning(self, job_name=None, include_cls_metadata=False):\n        """"""Prepare the tuner instance for tuning (fit)""""""\n        self._prepare_job_name_for_tuning(job_name=job_name)\n        self._prepare_static_hyperparameters_for_tuning(include_cls_metadata=include_cls_metadata)\n\n    def _prepare_job_name_for_tuning(self, job_name=None):\n        """"""Set current job name before starting tuning""""""\n        if job_name is not None:\n            self._current_job_name = job_name\n        else:\n            base_name = self.base_tuning_job_name\n            if base_name is None:\n                estimator = (\n                    self.estimator or self.estimator_dict[sorted(self.estimator_dict.keys())[0]]\n                )\n                base_name = base_name_from_image(estimator.train_image())\n            self._current_job_name = name_from_base(\n                base_name, max_length=self.TUNING_JOB_NAME_MAX_LENGTH, short=True\n            )\n\n    def _prepare_static_hyperparameters_for_tuning(self, include_cls_metadata=False):\n        """"""Prepare static hyperparameters for all estimators before tuning""""""\n        self.static_hyperparameters = None\n        if self.estimator is not None:\n            self.static_hyperparameters = self._prepare_static_hyperparameters(\n                self.estimator, self._hyperparameter_ranges, include_cls_metadata\n            )\n\n        self.static_hyperparameters_dict = None\n        if self.estimator_dict is not None:\n            self.static_hyperparameters_dict = {\n                estimator_name: self._prepare_static_hyperparameters(\n                    estimator,\n                    self._hyperparameter_ranges_dict[estimator_name],\n                    include_cls_metadata.get(estimator_name, False),\n                )\n                for (estimator_name, estimator) in self.estimator_dict.items()\n            }\n\n    @classmethod\n    def _prepare_static_hyperparameters(\n        cls, estimator, hyperparameter_ranges, include_cls_metadata\n    ):\n        """"""Prepare static hyperparameters for one estimator before tuning""""""\n        # Remove any hyperparameter that will be tuned\n        static_hyperparameters = {\n            to_str(k): to_str(v) for (k, v) in estimator.hyperparameters().items()\n        }\n        for hyperparameter_name in hyperparameter_ranges.keys():\n            static_hyperparameters.pop(hyperparameter_name, None)\n\n        # For attach() to know what estimator to use for frameworks\n        # (other algorithms may not accept extra hyperparameters)\n        if include_cls_metadata or isinstance(estimator, Framework):\n            static_hyperparameters[cls.SAGEMAKER_ESTIMATOR_CLASS_NAME] = json.dumps(\n                estimator.__class__.__name__\n            )\n            static_hyperparameters[cls.SAGEMAKER_ESTIMATOR_MODULE] = json.dumps(\n                estimator.__module__\n            )\n\n        return static_hyperparameters\n\n    def fit(\n        self,\n        inputs=None,\n        job_name=None,\n        include_cls_metadata=False,\n        estimator_kwargs=None,\n        **kwargs\n    ):\n        """"""Start a hyperparameter tuning job.\n\n        Args:\n            inputs: Information about the training data. Please refer to the\n                ``fit()`` method of the associated estimator, as this can take\n                any of the following forms:\n\n                * (str) - The S3 location where training data is saved.\n                * (dict[str, str] or dict[str, sagemaker.session.s3_input]) -\n                    If using multiple channels for training data, you can specify\n                    a dict mapping channel names to strings or\n                    :func:`~sagemaker.session.s3_input` objects.\n                * (sagemaker.session.s3_input) - Channel configuration for S3 data sources that can\n                    provide additional information about the training dataset.\n                    See :func:`sagemaker.session.s3_input` for full details.\n                * (sagemaker.session.FileSystemInput) - channel configuration for\n                    a file system data source that can provide additional information as well as\n                    the path to the training dataset.\n                * (sagemaker.amazon.amazon_estimator.RecordSet) - A collection of\n                    Amazon :class:~`Record` objects serialized and stored in S3.\n                    For use with an estimator for an Amazon algorithm.\n                * (sagemaker.amazon.amazon_estimator.FileSystemRecordSet) -\n                    Amazon SageMaker channel configuration for a file system data source for\n                    Amazon algorithms.\n                * (list[sagemaker.amazon.amazon_estimator.RecordSet]) - A list of\n                    :class:~`sagemaker.amazon.amazon_estimator.RecordSet` objects,\n                    where each instance is a different channel of training data.\n                * (list[sagemaker.amazon.amazon_estimator.FileSystemRecordSet]) - A list of\n                    :class:~`sagemaker.amazon.amazon_estimator.FileSystemRecordSet` objects,\n                    where each instance is a different channel of training data.\n\n            job_name (str): Tuning job name. If not specified, the tuner\n                generates a default job name, based on the training image name\n                and current timestamp.\n            include_cls_metadata: It can take one of the following two forms.\n\n                * (bool) - Whether or not the hyperparameter tuning job should include information\n                    about the estimator class (default: False). This information is passed as a\n                    hyperparameter, so if the algorithm you are using cannot handle unknown\n                    hyperparameters (e.g. an Amazon SageMaker built-in algorithm that does not\n                    have a custom estimator in the Python SDK), then set ``include_cls_metadata``\n                    to ``False``.\n                * (dict[str, bool]) - This version should be used for tuners created via the\n                    factory method create(), to specify the flag for each estimator provided in\n                    the estimator_dict argument of the method. The keys would be the same\n                    estimator names as in estimator_dict. If one estimator doesn\'t need the flag\n                    set, then no need to include it in the dictionary.\n\n            estimator_kwargs (dict[str, dict]): Dictionary for other arguments needed for\n                training. Should be used only for tuners created via the factory method create().\n                The keys are the estimator names for the estimator_dict argument of create()\n                method. Each value is a dictionary for the other arguments needed for training\n                of the corresponding estimator.\n            **kwargs: Other arguments needed for training. Please refer to the\n                ``fit()`` method of the associated estimator to see what other\n                arguments are needed.\n        """"""\n        if self.estimator is not None:\n            self._fit_with_estimator(inputs, job_name, include_cls_metadata, **kwargs)\n        else:\n            self._fit_with_estimator_dict(inputs, job_name, include_cls_metadata, estimator_kwargs)\n\n    def _fit_with_estimator(self, inputs, job_name, include_cls_metadata, **kwargs):\n        """"""Start tuning for tuner instances that have the ``estimator`` field set""""""\n        self._prepare_estimator_for_tuning(self.estimator, inputs, job_name, **kwargs)\n        self._prepare_for_tuning(job_name=job_name, include_cls_metadata=include_cls_metadata)\n        self.latest_tuning_job = _TuningJob.start_new(self, inputs)\n\n    def _fit_with_estimator_dict(self, inputs, job_name, include_cls_metadata, estimator_kwargs):\n        """"""Start tuning for tuner instances that have the ``estimator_dict`` field set""""""\n        estimator_names = sorted(self.estimator_dict.keys())\n        self._validate_dict_argument(name=""inputs"", value=inputs, allowed_keys=estimator_names)\n        self._validate_dict_argument(\n            name=""include_cls_metadata"", value=include_cls_metadata, allowed_keys=estimator_names\n        )\n        self._validate_dict_argument(\n            name=""estimator_kwargs"", value=estimator_kwargs, allowed_keys=estimator_names\n        )\n\n        for (estimator_name, estimator) in self.estimator_dict.items():\n            ins = inputs.get(estimator_name, None) if inputs is not None else None\n            args = estimator_kwargs.get(estimator_name, {}) if estimator_kwargs is not None else {}\n            self._prepare_estimator_for_tuning(estimator, ins, job_name, **args)\n\n        inc_cls_metadata = include_cls_metadata if include_cls_metadata is not None else {}\n        self._prepare_for_tuning(job_name=job_name, include_cls_metadata=inc_cls_metadata)\n\n        self.latest_tuning_job = _TuningJob.start_new(self, inputs)\n\n    @classmethod\n    def _prepare_estimator_for_tuning(cls, estimator, inputs, job_name, **kwargs):\n        """"""Prepare one estimator before starting tuning""""""\n        if isinstance(inputs, (list, RecordSet, FileSystemRecordSet)):\n            estimator._prepare_for_training(inputs, **kwargs)\n        else:\n            estimator._prepare_for_training(job_name)\n\n    @classmethod\n    def attach(cls, tuning_job_name, sagemaker_session=None, job_details=None, estimator_cls=None):\n        """"""Attach to an existing hyperparameter tuning job.\n\n        Create a HyperparameterTuner bound to an existing hyperparameter\n        tuning job. After attaching, if there exists a best training job (or any\n        other completed training job), that can be deployed to create an Amazon\n        SageMaker Endpoint and return a ``Predictor``.\n\n        The ``HyperparameterTuner`` instance could be created in one of the following two forms.\n\n            * If the \'TrainingJobDefinition\' field is present in tuning job description, the tuner\n                will be created using the default constructor with a single estimator.\n            * If the \'TrainingJobDefinitions\' field (list) is present in tuning job description,\n                the tuner will be created using the factory method ``create()`` with one or\n                several estimators. Each estimator corresponds to one item in the\n                \'TrainingJobDefinitions\' field, while the estimator names would come from the\n                \'DefinitionName\' field of items in the \'TrainingJobDefinitions\' field. For more\n                details on how tuners are created from multiple estimators, see ``create()``\n                documentation.\n\n        For more details on \'TrainingJobDefinition\' and \'TrainingJobDefinitions\' fields in tuning\n        job description, see\n        https://botocore.readthedocs.io/en/latest/reference/services/sagemaker.html#SageMaker.Client.create_hyper_parameter_tuning_job\n\n        Args:\n            tuning_job_name (str): The name of the hyperparameter tuning job to attach to.\n            sagemaker_session (sagemaker.session.Session): Session object which manages\n                interactions with Amazon SageMaker APIs and any other AWS services needed.\n                If not specified, one is created using the default AWS configuration chain.\n            job_details (dict): The response to a ``DescribeHyperParameterTuningJob`` call.\n                If not specified, the ``HyperparameterTuner`` will perform one such call with\n                the provided hyperparameter tuning job name.\n            estimator_cls: It can take one of the following two forms.\n\n                (str): The estimator class name associated with the training jobs, e.g.\n                    \'sagemaker.estimator.Estimator\'. If not specified, the ``HyperparameterTuner``\n                    will try to derive the correct estimator class from training job metadata,\n                    defaulting to :class:~`sagemaker.estimator.Estimator` if it is unable to\n                    determine a more specific class.\n                (dict[str, str]): This form should be used only when the \'TrainingJobDefinitions\'\n                    field (list) is present in tuning job description. In this scenario training\n                    jobs could be created from different training job definitions in the\n                    \'TrainingJobDefinitions\' field, each of which would be mapped to a different\n                    estimator after the ``attach()`` call. The ``estimator_cls`` should then be a\n                    dictionary to specify estimator class names for individual estimators as\n                    needed. The keys should be the \'DefinitionName\' value of items in\n                    \'TrainingJobDefinitions\', which would be used as estimator names in the\n                    resulting tuner instance.\n\n        Examples:\n            Example #1 - assuming we have the following tuning job description, which has the\n            \'TrainingJobDefinition\' field present using a SageMaker built-in algorithm (i.e. PCA),\n            and ``attach()`` can derive the estimator class from the training image.\n            So ``estimator_cls`` would not be needed.\n\n            .. code:: python\n\n                {\n                    \'BestTrainingJob\': \'best_training_job_name\',\n                    \'TrainingJobDefinition\': {\n                        \'AlgorithmSpecification\': {\n                            \'TrainingImage\': \'174872318107.dkr.ecr.us-west-2.amazonaws.com/pca:1,\n                        },\n                    },\n                }\n\n            >>> my_tuner.fit()\n            >>> job_name = my_tuner.latest_tuning_job.name\n            Later on:\n            >>> attached_tuner = HyperparameterTuner.attach(job_name)\n            >>> attached_tuner.deploy()\n\n            Example #2 - assuming we have the following tuning job description, which has a 2-item\n            list for the \'TrainingJobDefinitions\' field. In this case \'estimator_cls\' is only\n            needed for the 2nd item since the 1st item uses a SageMaker built-in algorithm\n            (i.e. PCA).\n\n            .. code:: python\n\n                {\n                    \'BestTrainingJob\': \'best_training_job_name\',\n                    \'TrainingJobDefinitions\': [\n                        {\n                            \'DefinitionName\': \'estimator_pca\',\n                            \'AlgorithmSpecification\': {\n                                \'TrainingImage\': \'174872318107.dkr.ecr.us-west-2.amazonaws.com/pca:1,\n                            },\n                        },\n                        {\n                            \'DefinitionName\': \'estimator_byoa\',\n                            \'AlgorithmSpecification\': {\n                                \'TrainingImage\': \'123456789012.dkr.ecr.us-west-2.amazonaws.com/byoa:latest,\n                            },\n                        }\n                    ]\n                }\n\n            >>> my_tuner.fit()\n            >>> job_name = my_tuner.latest_tuning_job.name\n            Later on:\n            >>> attached_tuner = HyperparameterTuner.attach(\n            >>>     job_name,\n            >>>     estimator_cls={\n            >>>         \'estimator_byoa\': \'org.byoa.Estimator\'\n            >>>     })\n            >>> attached_tuner.deploy()\n\n\n        Returns:\n            sagemaker.tuner.HyperparameterTuner: A ``HyperparameterTuner``\n            instance with the attached hyperparameter tuning job.\n        """"""\n        sagemaker_session = sagemaker_session or Session()\n\n        if job_details is None:\n            job_details = sagemaker_session.sagemaker_client.describe_hyper_parameter_tuning_job(\n                HyperParameterTuningJobName=tuning_job_name\n            )\n\n        if ""TrainingJobDefinition"" in job_details:\n            return cls._attach_with_training_details(\n                tuning_job_name, sagemaker_session, estimator_cls, job_details\n            )\n\n        return cls._attach_with_training_details_list(\n            tuning_job_name, sagemaker_session, estimator_cls, job_details\n        )\n\n    @classmethod\n    def _attach_with_training_details(\n        cls, tuning_job_name, sagemaker_session, estimator_cls, job_details\n    ):\n        """"""Create a HyperparameterTuner bound to an existing hyperparameter\n        tuning job that has the ``TrainingJobDefinition`` field set.""""""\n        estimator = cls._prepare_estimator(\n            estimator_cls=estimator_cls,\n            training_details=job_details[""TrainingJobDefinition""],\n            parameter_ranges=job_details[""HyperParameterTuningJobConfig""][""ParameterRanges""],\n            sagemaker_session=sagemaker_session,\n        )\n        init_params = cls._prepare_init_params_from_job_description(job_details)\n\n        tuner = cls(estimator=estimator, **init_params)\n        tuner.latest_tuning_job = _TuningJob(\n            sagemaker_session=sagemaker_session, job_name=tuning_job_name\n        )\n\n        return tuner\n\n    @classmethod\n    def _attach_with_training_details_list(\n        cls, tuning_job_name, sagemaker_session, estimator_cls, job_details\n    ):\n        """"""Create a HyperparameterTuner bound to an existing hyperparameter\n        tuning job that has the ``TrainingJobDefinitions`` field set.""""""\n        estimator_names = sorted(\n            [\n                training_details[""DefinitionName""]\n                for training_details in job_details[""TrainingJobDefinitions""]\n            ]\n        )\n        cls._validate_dict_argument(\n            name=""estimator_cls"", value=estimator_cls, allowed_keys=estimator_names\n        )\n\n        estimator_dict = {}\n        objective_metric_name_dict = {}\n        hyperparameter_ranges_dict = {}\n        metric_definitions_dict = {}\n\n        for training_details in job_details[""TrainingJobDefinitions""]:\n            estimator_name = training_details[""DefinitionName""]\n\n            estimator_dict[estimator_name] = cls._prepare_estimator(\n                estimator_cls=estimator_cls.get(estimator_name) if estimator_cls else None,\n                training_details=training_details,\n                parameter_ranges=training_details[""HyperParameterRanges""],\n                sagemaker_session=sagemaker_session,\n            )\n\n            objective_metric_name_dict[estimator_name] = training_details[""TuningObjective""][\n                ""MetricName""\n            ]\n            hyperparameter_ranges_dict[\n                estimator_name\n            ] = cls._prepare_parameter_ranges_from_job_description(  # noqa: E501 # pylint: disable=line-too-long\n                training_details[""HyperParameterRanges""]\n            )\n\n            metric_definitions = training_details[""AlgorithmSpecification""].get(\n                ""MetricDefinitions"", None\n            )\n            if metric_definitions is not None:\n                metric_definitions_dict[estimator_name] = metric_definitions\n\n        init_params = cls._prepare_init_params_from_job_description(job_details)\n\n        tuner = HyperparameterTuner.create(\n            estimator_dict=estimator_dict,\n            objective_metric_name_dict=objective_metric_name_dict,\n            hyperparameter_ranges_dict=hyperparameter_ranges_dict,\n            metric_definitions_dict=metric_definitions_dict,\n            **init_params\n        )\n        tuner.latest_tuning_job = _TuningJob(\n            sagemaker_session=sagemaker_session, job_name=tuning_job_name\n        )\n\n        return tuner\n\n    def deploy(\n        self,\n        initial_instance_count,\n        instance_type,\n        accelerator_type=None,\n        endpoint_name=None,\n        wait=True,\n        model_name=None,\n        kms_key=None,\n        data_capture_config=None,\n        **kwargs\n    ):\n        """"""Deploy the best trained or user specified model to an Amazon\n        SageMaker endpoint and return a ``sagemaker.RealTimePredictor`` object.\n\n        For more information:\n        http://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-training.html\n\n        Args:\n            initial_instance_count (int): Minimum number of EC2 instances to\n                deploy to an endpoint for prediction.\n            instance_type (str): Type of EC2 instance to deploy to an endpoint\n                for prediction, for example, \'ml.c4.xlarge\'.\n            accelerator_type (str): Type of Elastic Inference accelerator to\n                attach to an endpoint for model loading and inference, for\n                example, \'ml.eia1.medium\'. If not specified, no Elastic\n                Inference accelerator will be attached to the endpoint. For more\n                information:\n                https://docs.aws.amazon.com/sagemaker/latest/dg/ei.html\n            endpoint_name (str): Name to use for creating an Amazon SageMaker\n                endpoint. If not specified, the name of the training job is\n                used.\n            wait (bool): Whether the call should wait until the deployment of\n                model completes (default: True).\n            model_name (str): Name to use for creating an Amazon SageMaker\n                model. If not specified, the name of the training job is used.\n            kms_key (str): The ARN of the KMS key that is used to encrypt the\n                data on the storage volume attached to the instance hosting the\n                endpoint.\n            data_capture_config (sagemaker.model_monitor.DataCaptureConfig): Specifies\n                configuration related to Endpoint data capture for use with\n                Amazon SageMaker Model Monitoring. Default: None.\n            **kwargs: Other arguments needed for deployment. Please refer to the\n                ``create_model()`` method of the associated estimator to see\n                what other arguments are needed.\n\n        Returns:\n            sagemaker.predictor.RealTimePredictor: A predictor that provides a ``predict()``\n                method, which can be used to send requests to the Amazon SageMaker endpoint\n                and obtain inferences.\n        """"""\n        best_training_job = self._get_best_training_job()\n        best_estimator = self.best_estimator(best_training_job)\n\n        return best_estimator.deploy(\n            initial_instance_count=initial_instance_count,\n            instance_type=instance_type,\n            accelerator_type=accelerator_type,\n            endpoint_name=endpoint_name or best_training_job[""TrainingJobName""],\n            wait=wait,\n            model_name=model_name,\n            kms_key=kms_key,\n            data_capture_config=data_capture_config,\n            **kwargs\n        )\n\n    def stop_tuning_job(self):\n        """"""Stop latest running hyperparameter tuning job.""""""\n        self._ensure_last_tuning_job()\n        self.latest_tuning_job.stop()\n\n    def wait(self):\n        """"""Wait for latest hyperparameter tuning job to finish.""""""\n        self._ensure_last_tuning_job()\n        self.latest_tuning_job.wait()\n\n    def best_estimator(self, best_training_job=None):\n        """"""Return the estimator that has best training job attached. The trained model can then\n        be deployed to an Amazon SageMaker endpoint and return a ``sagemaker.RealTimePredictor``\n        object.\n\n        Args:\n            best_training_job (dict): Dictionary containing ""TrainingJobName"" and\n                ""TrainingJobDefinitionName"".\n\n                Example:\n\n                .. code:: python\n\n                    {\n                        ""TrainingJobName"": ""my_training_job_name"",\n                        ""TrainingJobDefinitionName"": ""my_training_job_definition_name""\n                    }\n\n        Returns:\n            sagemaker.estimator.EstimatorBase: The estimator that has the best training job\n                attached.\n\n        Raises:\n            Exception: If there is no best training job available for the hyperparameter tuning job.\n        """"""\n        if best_training_job is None:\n            best_training_job = self._get_best_training_job()\n\n        if self.estimator is not None:\n            best_estimator = self.estimator\n        else:\n            best_estimator_name = best_training_job[""TrainingJobDefinitionName""]\n            best_estimator = self.estimator_dict[best_estimator_name]\n\n        return best_estimator.attach(\n            training_job_name=best_training_job[""TrainingJobName""],\n            sagemaker_session=self.sagemaker_session,\n        )\n\n    def best_training_job(self):\n        """"""Return name of the best training job for the latest hyperparameter\n        tuning job.\n\n        Raises:\n            Exception: If there is no best training job available for the\n                hyperparameter tuning job.\n        """"""\n        return self._get_best_training_job()[""TrainingJobName""]\n\n    def _get_best_training_job(self):\n        """"""Return the best training job for the latest hyperparameter\n        tuning job.\n\n        Raises:\n            Exception: If there is no best training job available for the\n                hyperparameter tuning job.\n        """"""\n        self._ensure_last_tuning_job()\n\n        tuning_job_describe_result = self.sagemaker_session.sagemaker_client.describe_hyper_parameter_tuning_job(  # noqa: E501 # pylint: disable=line-too-long\n            HyperParameterTuningJobName=self.latest_tuning_job.name\n        )\n\n        try:\n            return tuning_job_describe_result[""BestTrainingJob""]\n        except KeyError:\n            raise Exception(\n                ""Best training job not available for tuning job: {}"".format(\n                    self.latest_tuning_job.name\n                )\n            )\n\n    def delete_endpoint(self, endpoint_name=None):\n        """"""Delete an Amazon SageMaker endpoint.\n\n        If an endpoint name is not specified, this defaults to looking for an\n        endpoint that shares a name with the best training job for deletion.\n\n        Args:\n            endpoint_name (str): Name of the endpoint to delete\n        """"""\n        endpoint_name = endpoint_name or self.best_training_job()\n        self.sagemaker_session.delete_endpoint(endpoint_name)\n\n    def _ensure_last_tuning_job(self):\n        """"""Placeholder docstring""""""\n        if self.latest_tuning_job is None:\n            raise ValueError(""No tuning job available"")\n\n    @classmethod\n    def _prepare_estimator(\n        cls, estimator_cls, training_details, parameter_ranges, sagemaker_session\n    ):\n        """"""Attach an estimator from training job details""""""\n        estimator_cls = cls._prepare_estimator_cls(estimator_cls, training_details)\n        return cls._prepare_estimator_from_job_description(\n            estimator_cls, training_details, parameter_ranges, sagemaker_session\n        )\n\n    @classmethod\n    def _prepare_estimator_cls(cls, estimator_cls, training_details):\n        # Check for customer-specified estimator first\n        """"""\n        Args:\n            estimator_cls:\n            training_details:\n        """"""\n        if estimator_cls is not None:\n            module, cls_name = estimator_cls.rsplit(""."", 1)\n            return getattr(importlib.import_module(module), cls_name)\n\n        # Then check for estimator class in hyperparameters\n        hyperparameters = training_details[""StaticHyperParameters""]\n        if (\n            cls.SAGEMAKER_ESTIMATOR_CLASS_NAME in hyperparameters\n            and cls.SAGEMAKER_ESTIMATOR_MODULE in hyperparameters\n        ):\n            module = hyperparameters.get(cls.SAGEMAKER_ESTIMATOR_MODULE)\n            cls_name = hyperparameters.get(cls.SAGEMAKER_ESTIMATOR_CLASS_NAME)\n            return getattr(importlib.import_module(json.loads(module)), json.loads(cls_name))\n\n        # Then try to derive the estimator from the image name for 1P algorithms\n        image_name = training_details[""AlgorithmSpecification""][""TrainingImage""]\n        algorithm = image_name[image_name.find(""/"") + 1 : image_name.find("":"")]\n        if algorithm in AMAZON_ESTIMATOR_CLS_NAMES:\n            cls_name = AMAZON_ESTIMATOR_CLS_NAMES[algorithm]\n            return getattr(importlib.import_module(AMAZON_ESTIMATOR_MODULE), cls_name)\n\n        # Default to the BYO estimator\n        return getattr(\n            importlib.import_module(cls.DEFAULT_ESTIMATOR_MODULE), cls.DEFAULT_ESTIMATOR_CLS_NAME\n        )\n\n    @classmethod\n    def _prepare_estimator_from_job_description(\n        cls, estimator_cls, training_details, parameter_ranges, sagemaker_session\n    ):\n        """"""\n        Args:\n            estimator_cls:\n            job_details:\n            sagemaker_session:\n        """"""\n        # Swap name for static hyperparameters to what an estimator would expect\n        training_details[""HyperParameters""] = training_details[""StaticHyperParameters""]\n        del training_details[""StaticHyperParameters""]\n\n        # Remove hyperparameter reserved by SageMaker for tuning jobs\n        del training_details[""HyperParameters""][""_tuning_objective_metric""]\n\n        # Add missing hyperparameters defined in the hyperparameter ranges,\n        # as potentially required in the Amazon algorithm estimator\'s constructor\n        if issubclass(estimator_cls, AmazonAlgorithmEstimatorBase):\n            additional_hyperparameters = cls._extract_hyperparameters_from_parameter_ranges(\n                parameter_ranges\n            )\n            training_details[""HyperParameters""].update(additional_hyperparameters)\n\n        # Add items expected by the estimator (but aren\'t needed otherwise)\n        training_details[""TrainingJobName""] = """"\n        if ""KmsKeyId"" not in training_details[""OutputDataConfig""]:\n            training_details[""OutputDataConfig""][""KmsKeyId""] = """"\n\n        estimator_init_params = estimator_cls._prepare_init_params_from_job_description(\n            training_details\n        )\n        return estimator_cls(sagemaker_session=sagemaker_session, **estimator_init_params)\n\n    @classmethod\n    def _prepare_init_params_from_job_description(cls, job_details):\n        """"""\n        Args:\n            job_details:\n        """"""\n        tuning_config = job_details[""HyperParameterTuningJobConfig""]\n\n        params = {\n            ""strategy"": tuning_config[""Strategy""],\n            ""max_jobs"": tuning_config[""ResourceLimits""][""MaxNumberOfTrainingJobs""],\n            ""max_parallel_jobs"": tuning_config[""ResourceLimits""][""MaxParallelTrainingJobs""],\n            ""warm_start_config"": WarmStartConfig.from_job_desc(\n                job_details.get(""WarmStartConfig"", None)\n            ),\n            ""early_stopping_type"": tuning_config[""TrainingJobEarlyStoppingType""],\n        }\n\n        if ""HyperParameterTuningJobObjective"" in tuning_config:\n            params[""objective_metric_name""] = tuning_config[""HyperParameterTuningJobObjective""][\n                ""MetricName""\n            ]\n            params[""objective_type""] = tuning_config[""HyperParameterTuningJobObjective""][""Type""]\n\n        if ""ParameterRanges"" in tuning_config:\n            params[""hyperparameter_ranges""] = cls._prepare_parameter_ranges_from_job_description(\n                tuning_config[""ParameterRanges""]\n            )\n\n        if ""TrainingJobDefinition"" in job_details:\n            params[""metric_definitions""] = job_details[""TrainingJobDefinition""][\n                ""AlgorithmSpecification""\n            ][""MetricDefinitions""]\n\n        if ""TrainingJobDefinitions"" in job_details:\n            params[""objective_type""] = job_details[""TrainingJobDefinitions""][0][""TuningObjective""][\n                ""Type""\n            ]\n\n        return params\n\n    @classmethod\n    def _prepare_parameter_ranges_from_job_description(cls, parameter_ranges):\n        """"""\n        Args:\n            parameter_ranges:\n        """"""\n        ranges = {}\n\n        for parameter in parameter_ranges[""CategoricalParameterRanges""]:\n            ranges[parameter[""Name""]] = CategoricalParameter(parameter[""Values""])\n\n        for parameter in parameter_ranges[""ContinuousParameterRanges""]:\n            ranges[parameter[""Name""]] = ContinuousParameter(\n                float(parameter[""MinValue""]), float(parameter[""MaxValue""])\n            )\n\n        for parameter in parameter_ranges[""IntegerParameterRanges""]:\n            ranges[parameter[""Name""]] = IntegerParameter(\n                int(parameter[""MinValue""]), int(parameter[""MaxValue""])\n            )\n\n        return ranges\n\n    @classmethod\n    def _extract_hyperparameters_from_parameter_ranges(cls, parameter_ranges):\n        """"""\n        Args:\n            parameter_ranges:\n        """"""\n        hyperparameters = {}\n\n        for parameter in parameter_ranges[""CategoricalParameterRanges""]:\n            hyperparameters[parameter[""Name""]] = parameter[""Values""][0]\n\n        for parameter in parameter_ranges[""ContinuousParameterRanges""]:\n            hyperparameters[parameter[""Name""]] = float(parameter[""MinValue""])\n\n        for parameter in parameter_ranges[""IntegerParameterRanges""]:\n            hyperparameters[parameter[""Name""]] = int(parameter[""MinValue""])\n\n        return hyperparameters\n\n    def hyperparameter_ranges(self):\n        """"""Return the hyperparameter ranges in a dictionary to be used as part\n        of a request for creating a hyperparameter tuning job.\n        """"""\n        if self._hyperparameter_ranges is None:\n            return None\n\n        return self._prepare_parameter_ranges_for_tuning(\n            self._hyperparameter_ranges, self.estimator\n        )\n\n    def hyperparameter_ranges_dict(self):\n        """"""Return a dictionary of hyperparameter ranges for all estimators in ``estimator_dict``\n        """"""\n        if self._hyperparameter_ranges_dict is None:\n            return None\n\n        return {\n            estimator_name: self._prepare_parameter_ranges_for_tuning(\n                self._hyperparameter_ranges_dict[estimator_name],\n                self.estimator_dict[estimator_name],\n            )\n            for estimator_name in sorted(self.estimator_dict.keys())\n        }\n\n    @classmethod\n    def _prepare_parameter_ranges_for_tuning(cls, parameter_ranges, estimator):\n        """"""Prepare hyperparameter ranges for tuning""""""\n        processed_parameter_ranges = dict()\n        for range_type in ParameterRange.__all_types__:\n            hp_ranges = []\n            for parameter_name, parameter in parameter_ranges.items():\n                if parameter is not None and parameter.__name__ == range_type:\n                    # Categorical parameters needed to be serialized as JSON for our framework\n                    # containers\n                    if isinstance(parameter, CategoricalParameter) and isinstance(\n                        estimator, Framework\n                    ):\n                        tuning_range = parameter.as_json_range(parameter_name)\n                    else:\n                        tuning_range = parameter.as_tuning_range(parameter_name)\n                    hp_ranges.append(tuning_range)\n            processed_parameter_ranges[range_type + ""ParameterRanges""] = hp_ranges\n        return processed_parameter_ranges\n\n    @property\n    def sagemaker_session(self):\n        """"""Convenience method for accessing the\n        :class:`~sagemaker.session.Session` object associated with the estimator\n        for the ``HyperparameterTuner``.\n        """"""\n        estimator = self.estimator\n        if estimator is None:\n            first_estimator_name = sorted(self.estimator_dict.keys())[0]\n            estimator = self.estimator_dict[first_estimator_name]\n        return estimator.sagemaker_session\n\n    def analytics(self):\n        """"""An instance of HyperparameterTuningJobAnalytics for this latest\n        tuning job of this tuner. Analytics olbject gives you access to tuning\n        results summarized into a pandas dataframe.\n        """"""\n        return HyperparameterTuningJobAnalytics(self.latest_tuning_job.name, self.sagemaker_session)\n\n    def _validate_parameter_ranges(self, estimator, hyperparameter_ranges):\n        """"""Validate hyperparameter ranges for an estimator""""""\n        for kls in inspect.getmro(estimator.__class__)[::-1]:\n            for _, value in kls.__dict__.items():\n                if isinstance(value, hp):\n                    try:\n                        # The hyperparam names may not be the same as the class attribute that\n                        # holds them, for instance: local_lloyd_init_method is called\n                        # local_init_method. We need to map these and pass the correct name to\n                        # the constructor.\n                        parameter_range = hyperparameter_ranges[value.name]\n\n                        if isinstance(parameter_range, ParameterRange):\n                            self._validate_parameter_range(value, parameter_range)\n                    except KeyError:\n                        pass\n\n    def _validate_parameter_range(self, value_hp, parameter_range):\n        """"""\n        Args:\n            value_hp:\n            parameter_range:\n        """"""\n        for (parameter_range_key, parameter_range_value) in parameter_range.__dict__.items():\n            if parameter_range_key == ""scaling_type"":\n                continue\n\n            # Categorical ranges\n            if isinstance(parameter_range_value, list):\n                for categorical_value in parameter_range_value:\n                    value_hp.validate(categorical_value)\n            # Continuous, Integer ranges\n            else:\n                value_hp.validate(parameter_range_value)\n\n    def transfer_learning_tuner(self, additional_parents=None, estimator=None):\n        """"""Creates a new ``HyperparameterTuner`` by copying the request fields\n        from the provided parent to the new instance of ``HyperparameterTuner``.\n        Followed by addition of warm start configuration with the type as\n        ""TransferLearning"" and parents as the union of provided list of\n        ``additional_parents`` and the ``self``. Also, training image in the new\n        tuner\'s estimator is updated with the provided ``training_image``.\n\n        Examples:\n            >>> parent_tuner = HyperparameterTuner.attach(tuning_job_name=""parent-job-1"")\n            >>> transfer_learning_tuner = parent_tuner.transfer_learning_tuner(\n            >>>                                             additional_parents={""parent-job-2""})\n            Later On:\n            >>> transfer_learning_tuner.fit(inputs={})\n\n        Args:\n            additional_parents (set{str}): Set of additional parents along with\n                the self to be used in warm starting\n            estimator (sagemaker.estimator.EstimatorBase): An estimator object\n                that has been initialized with the desired configuration. There\n                does not need to be a training job associated with this\n                instance.\n\n        Returns:\n            sagemaker.tuner.HyperparameterTuner: ``HyperparameterTuner``\n            instance which can be used to launch transfer learning tuning job.\n        """"""\n\n        return self._create_warm_start_tuner(\n            additional_parents=additional_parents,\n            warm_start_type=WarmStartTypes.TRANSFER_LEARNING,\n            estimator=estimator,\n        )\n\n    def identical_dataset_and_algorithm_tuner(self, additional_parents=None):\n        """"""Creates a new ``HyperparameterTuner`` by copying the request fields\n        from the provided parent to the new instance of ``HyperparameterTuner``.\n        Followed by addition of warm start configuration with the type as\n        ""IdenticalDataAndAlgorithm"" and parents as the union of provided list of\n        ``additional_parents`` and the ``self``\n\n        Examples:\n            >>> parent_tuner = HyperparameterTuner.attach(tuning_job_name=""parent-job-1"")\n            >>> identical_dataset_algo_tuner = parent_tuner.identical_dataset_and_algorithm_tuner(\n            >>>                                                additional_parents={""parent-job-2""})\n            Later On:\n            >>> identical_dataset_algo_tuner.fit(inputs={})\n\n        Args:\n            additional_parents (set{str}): Set of additional parents along with\n                the self to be used in warm starting\n\n        Returns:\n            sagemaker.tuner.HyperparameterTuner: HyperparameterTuner instance\n            which can be used to launch identical dataset and algorithm tuning\n            job.\n        """"""\n\n        return self._create_warm_start_tuner(\n            additional_parents=additional_parents,\n            warm_start_type=WarmStartTypes.IDENTICAL_DATA_AND_ALGORITHM,\n        )\n\n    def _create_warm_start_tuner(self, additional_parents, warm_start_type, estimator=None):\n        """"""Creates a new ``HyperparameterTuner`` with ``WarmStartConfig``, where\n        type will be equal to ``warm_start_type`` and``parents`` would be equal\n        to union of ``additional_parents`` and self.\n\n        Args:\n            additional_parents (set{str}): Additional parents along with self,\n                to be used for warm starting.\n            warm_start_type (sagemaker.tuner.WarmStartTypes): Type of warm start\n                job.\n            estimator:\n\n        Returns:\n            sagemaker.tuner.HyperparameterTuner: Instance with the request\n            fields copied from self along with the warm start configuration\n        """"""\n        all_parents = {self.latest_tuning_job.name}\n        if additional_parents:\n            all_parents = all_parents.union(additional_parents)\n\n        if self.estimator is not None:\n            return HyperparameterTuner(\n                estimator=estimator if estimator else self.estimator,\n                objective_metric_name=self.objective_metric_name,\n                hyperparameter_ranges=self._hyperparameter_ranges,\n                strategy=self.strategy,\n                objective_type=self.objective_type,\n                max_jobs=self.max_jobs,\n                max_parallel_jobs=self.max_parallel_jobs,\n                warm_start_config=WarmStartConfig(\n                    warm_start_type=warm_start_type, parents=all_parents\n                ),\n                early_stopping_type=self.early_stopping_type,\n            )\n\n        if len(self.estimator_dict) > 1:\n            raise ValueError(\n                ""Warm start is not supported currently for tuners with multiple estimators""\n            )\n\n        if estimator is not None:\n            estimator_name = list(self.estimator_dict.keys())[0]\n            estimator_dict = {estimator_name: estimator}\n        else:\n            estimator_dict = self.estimator_dict\n\n        return HyperparameterTuner.create(\n            estimator_dict=estimator_dict,\n            objective_metric_name_dict=self.objective_metric_name_dict,\n            hyperparameter_ranges_dict=self._hyperparameter_ranges_dict,\n            metric_definitions_dict=self.metric_definitions_dict,\n            strategy=self.strategy,\n            objective_type=self.objective_type,\n            max_jobs=self.max_jobs,\n            max_parallel_jobs=self.max_parallel_jobs,\n            warm_start_config=WarmStartConfig(warm_start_type=warm_start_type, parents=all_parents),\n            early_stopping_type=self.early_stopping_type,\n        )\n\n    @classmethod\n    def create(\n        cls,\n        estimator_dict,\n        objective_metric_name_dict,\n        hyperparameter_ranges_dict,\n        metric_definitions_dict=None,\n        base_tuning_job_name=None,\n        strategy=""Bayesian"",\n        objective_type=""Maximize"",\n        max_jobs=1,\n        max_parallel_jobs=1,\n        tags=None,\n        warm_start_config=None,\n        early_stopping_type=""Off"",\n    ):\n        """"""Factory method to create a ``HyperparameterTuner`` instance. It takes one or more\n        estimators to obtain configuration information for training jobs that are created as the\n        result of a hyperparameter tuning job. The estimators are provided through a dictionary\n        (i.e. ``estimator_dict``) with unique estimator names as the keys. For individual\n        estimators separate objective metric names and hyperparameter ranges should be provided in\n        two dictionaries, i.e. ``objective_metric_name_dict`` and ``hyperparameter_ranges_dict``,\n        with the same estimator names as the keys. Optional metrics definitions could also be\n        provided for individual estimators via another dictionary ``metric_definitions_dict``.\n\n        Args:\n            estimator_dict (dict[str, sagemaker.estimator.EstimatorBase]): Dictionary of estimator\n                instances that have been initialized with the desired configuration. There does not\n                need to be a training job associated with the estimator instances. The keys of the\n                dictionary would be referred to as ""estimator names"".\n            objective_metric_name_dict (dict[str, str]): Dictionary of names of the objective\n                metric for evaluating training jobs. The keys are the same set of estimator names\n                as in ``estimator_dict``, and there must be one entry for each estimator in\n                ``estimator_dict``.\n            hyperparameter_ranges_dict (dict[str, dict[str, sagemaker.parameter.ParameterRange]]):\n                Dictionary of tunable hyperparameter ranges. The keys are the same set of estimator\n                names as in estimator_dict, and there must be one entry for each estimator in\n                estimator_dict. Each value is a dictionary of sagemaker.parameter.ParameterRange\n                instance, which can be one of three types: Continuous, Integer, or Categorical.\n                The keys of each ParameterRange dictionaries are the names of the hyperparameter,\n                and the values are the appropriate parameter range class to represent the range.\n            metric_definitions_dict (dict(str, list[dict]]): Dictionary of metric definitions.\n                The keys are the same set or a subset of estimator names as in estimator_dict,\n                and there must be one entry for each estimator in estimator_dict. Each value is\n                a list of dictionaries that defines the metric(s) used to evaluate the training\n                jobs (default: None). Each of these dictionaries contains two keys: \'Name\' for the\n                name of the metric, and \'Regex\' for the regular expression used to extract the\n                metric from the logs. This should be defined only for hyperparameter tuning jobs\n                that don\'t use an Amazon algorithm.\n            base_tuning_job_name (str): Prefix for the hyperparameter tuning job name when the\n                :meth:`~sagemaker.tuner.HyperparameterTuner.fit` method launches. If not specified,\n                a default job name is generated, based on the training image name and current\n                timestamp.\n            strategy (str): Strategy to be used for hyperparameter estimations\n                (default: \'Bayesian\').\n            objective_type (str): The type of the objective metric for evaluating training jobs.\n                This value can be either \'Minimize\' or \'Maximize\' (default: \'Maximize\').\n            max_jobs (int): Maximum total number of training jobs to start for the hyperparameter\n                tuning job (default: 1).\n            max_parallel_jobs (int): Maximum number of parallel training jobs to start\n                (default: 1).\n            tags (list[dict]): List of tags for labeling the tuning job (default: None). For more,\n                see https://docs.aws.amazon.com/sagemaker/latest/dg/API_Tag.html.\n            warm_start_config (sagemaker.tuner.WarmStartConfig): A ``WarmStartConfig`` object that\n                has been initialized with the configuration defining the nature of warm start\n                tuning job.\n            early_stopping_type (str): Specifies whether early stopping is enabled for the job.\n                Can be either \'Auto\' or \'Off\' (default: \'Off\'). If set to \'Off\', early stopping\n                will not be attempted. If set to \'Auto\', early stopping of some training jobs may\n                happen, but is not guaranteed to.\n\n        Returns:\n            sagemaker.tuner.HyperparameterTuner: a new ``HyperparameterTuner`` object that can\n            start a hyperparameter tuning job with one or more estimators.\n\n        """"""\n\n        cls._validate_create_tuner_inputs(\n            estimator_dict,\n            objective_metric_name_dict,\n            hyperparameter_ranges_dict,\n            metric_definitions_dict,\n        )\n\n        estimator_names = sorted(estimator_dict.keys())\n        first_estimator_name = estimator_names[0]\n\n        metric_definitions = (\n            metric_definitions_dict.get(first_estimator_name, None)\n            if metric_definitions_dict is not None\n            else None\n        )\n\n        tuner = HyperparameterTuner(\n            base_tuning_job_name=base_tuning_job_name,\n            estimator_name=first_estimator_name,\n            estimator=estimator_dict[first_estimator_name],\n            objective_metric_name=objective_metric_name_dict[first_estimator_name],\n            hyperparameter_ranges=hyperparameter_ranges_dict[first_estimator_name],\n            metric_definitions=metric_definitions,\n            strategy=strategy,\n            objective_type=objective_type,\n            max_jobs=max_jobs,\n            max_parallel_jobs=max_parallel_jobs,\n            tags=tags,\n            warm_start_config=warm_start_config,\n            early_stopping_type=early_stopping_type,\n        )\n\n        for estimator_name in estimator_names[1:]:\n            metric_definitions = (\n                metric_definitions_dict.get(estimator_name, None)\n                if metric_definitions_dict is not None\n                else None\n            )\n            tuner._add_estimator(\n                estimator_name=estimator_name,\n                estimator=estimator_dict[estimator_name],\n                objective_metric_name=objective_metric_name_dict[estimator_name],\n                hyperparameter_ranges=hyperparameter_ranges_dict[estimator_name],\n                metric_definitions=metric_definitions,\n            )\n        return tuner\n\n    @classmethod\n    def _validate_create_tuner_inputs(\n        cls,\n        estimator_dict,\n        objective_metric_name_dict,\n        hyperparameter_ranges_dict,\n        metric_definitions_dict=None,\n    ):\n        """"""Validate inputs for ``HyperparameterTuner.create()``""""""\n        cls._validate_estimator_dict(estimator_dict)\n\n        estimator_names = sorted(estimator_dict.keys())\n\n        cls._validate_dict_argument(\n            name=""objective_metric_name_dict"",\n            value=objective_metric_name_dict,\n            allowed_keys=estimator_names,\n            require_same_keys=True,\n        )\n        cls._validate_dict_argument(\n            name=""hyperparameter_ranges_dict"",\n            value=hyperparameter_ranges_dict,\n            allowed_keys=estimator_names,\n            require_same_keys=True,\n        )\n        cls._validate_dict_argument(\n            name=""metric_definitions_dict"",\n            value=metric_definitions_dict,\n            allowed_keys=estimator_names,\n        )\n\n    @classmethod\n    def _validate_estimator_dict(cls, estimator_dict):\n        """"""Validate ``estimator_dict`` in inputs for ``HyperparameterTuner.create()``""""""\n        if estimator_dict is None or len(estimator_dict) == 0:\n            raise ValueError(""At least one estimator should be provided"")\n        if None in estimator_dict.keys():\n            raise ValueError(""Estimator names cannot be None"")\n\n    @classmethod\n    def _validate_dict_argument(cls, name, value, allowed_keys, require_same_keys=False):\n        """"""Check if an argument is an dictionary with correct key set""""""\n        if value is None:\n            return\n\n        if not isinstance(value, dict):\n            raise ValueError(\n                ""Argument \'{}\' must be a dictionary using {} as keys"".format(name, allowed_keys)\n            )\n\n        value_keys = sorted(value.keys())\n\n        if require_same_keys:\n            if value_keys != allowed_keys:\n                raise ValueError(\n                    ""The keys of argument \'{}\' must be the same as {}"".format(name, allowed_keys)\n                )\n        else:\n            if not set(value_keys).issubset(set(allowed_keys)):\n                raise ValueError(\n                    ""The keys of argument \'{}\' must be a subset of {}"".format(name, allowed_keys)\n                )\n\n    def _add_estimator(\n        self,\n        estimator_name,\n        estimator,\n        objective_metric_name,\n        hyperparameter_ranges,\n        metric_definitions=None,\n    ):\n        """"""Add an estimator with corresponding objective metric name, parameter ranges and metric\n        definitions (if applicable)""""""\n        self.estimator_dict[estimator_name] = estimator\n        self.objective_metric_name_dict[estimator_name] = objective_metric_name\n        self._hyperparameter_ranges_dict[estimator_name] = hyperparameter_ranges\n        if metric_definitions is not None:\n            self.metric_definitions_dict[estimator_name] = metric_definitions\n\n\nclass _TuningJob(_Job):\n    """"""Placeholder docstring""""""\n\n    @classmethod\n    def start_new(cls, tuner, inputs):\n        """"""Create a new Amazon SageMaker hyperparameter tuning job from the\n        HyperparameterTuner.\n\n        Args:\n            tuner (sagemaker.tuner.HyperparameterTuner): HyperparameterTuner\n                object created by the user.\n            inputs (str): Parameters used when called\n                :meth:`~sagemaker.estimator.EstimatorBase.fit`.\n\n        Returns:\n            sagemaker.tuner._TuningJob: Constructed object that captures all\n            information about the started job.\n        """"""\n\n        logging.info(""_TuningJob.start_new!!!"")\n\n        warm_start_config_req = None\n        if tuner.warm_start_config:\n            warm_start_config_req = tuner.warm_start_config.to_input_req()\n\n        tuning_config = {\n            ""strategy"": tuner.strategy,\n            ""max_jobs"": tuner.max_jobs,\n            ""max_parallel_jobs"": tuner.max_parallel_jobs,\n            ""early_stopping_type"": tuner.early_stopping_type,\n        }\n\n        if tuner.objective_metric_name is not None:\n            tuning_config[""objective_type""] = tuner.objective_type\n            tuning_config[""objective_metric_name""] = tuner.objective_metric_name\n\n        parameter_ranges = tuner.hyperparameter_ranges()\n        if parameter_ranges is not None:\n            tuning_config[""parameter_ranges""] = parameter_ranges\n\n        tuner_args = {\n            ""job_name"": tuner._current_job_name,\n            ""tuning_config"": tuning_config,\n            ""tags"": tuner.tags,\n            ""warm_start_config"": warm_start_config_req,\n        }\n\n        if tuner.estimator is not None:\n            tuner_args[""training_config""] = cls._prepare_training_config(\n                inputs, tuner.estimator, tuner.static_hyperparameters, tuner.metric_definitions\n            )\n\n        if tuner.estimator_dict is not None:\n            tuner_args[""training_config_list""] = [\n                cls._prepare_training_config(\n                    inputs.get(estimator_name, None) if inputs is not None else None,\n                    tuner.estimator_dict[estimator_name],\n                    tuner.static_hyperparameters_dict[estimator_name],\n                    tuner.metric_definitions_dict.get(estimator_name, None),\n                    estimator_name,\n                    tuner.objective_type,\n                    tuner.objective_metric_name_dict[estimator_name],\n                    tuner.hyperparameter_ranges_dict()[estimator_name],\n                )\n                for estimator_name in sorted(tuner.estimator_dict.keys())\n            ]\n\n        tuner.sagemaker_session.create_tuning_job(**tuner_args)\n        return cls(tuner.sagemaker_session, tuner._current_job_name)\n\n    @staticmethod\n    def _prepare_training_config(\n        inputs,\n        estimator,\n        static_hyperparameters,\n        metric_definitions,\n        estimator_name=None,\n        objective_type=None,\n        objective_metric_name=None,\n        parameter_ranges=None,\n    ):\n        """"""Prepare training config for one estimator""""""\n        training_config = _Job._load_config(inputs, estimator)\n\n        training_config[""input_mode""] = estimator.input_mode\n        training_config[""metric_definitions""] = metric_definitions\n\n        if isinstance(inputs, s3_input):\n            if ""InputMode"" in inputs.config:\n                logging.debug(\n                    ""Selecting s3_input\'s input_mode (%s) for TrainingInputMode."",\n                    inputs.config[""InputMode""],\n                )\n                training_config[""input_mode""] = inputs.config[""InputMode""]\n\n        if isinstance(estimator, sagemaker.algorithm.AlgorithmEstimator):\n            training_config[""algorithm_arn""] = estimator.algorithm_arn\n        else:\n            training_config[""image""] = estimator.train_image()\n\n        training_config[""enable_network_isolation""] = estimator.enable_network_isolation()\n        training_config[\n            ""encrypt_inter_container_traffic""\n        ] = estimator.encrypt_inter_container_traffic\n\n        training_config[""train_use_spot_instances""] = estimator.train_use_spot_instances\n        training_config[""checkpoint_s3_uri""] = estimator.checkpoint_s3_uri\n        training_config[""checkpoint_local_path""] = estimator.checkpoint_local_path\n\n        training_config[""static_hyperparameters""] = static_hyperparameters\n\n        if estimator_name is not None:\n            training_config[""estimator_name""] = estimator_name\n\n        if objective_type is not None:\n            training_config[""objective_type""] = objective_type\n\n        if objective_metric_name is not None:\n            training_config[""objective_metric_name""] = objective_metric_name\n\n        if parameter_ranges is not None:\n            training_config[""parameter_ranges""] = parameter_ranges\n\n        return training_config\n\n    def stop(self):\n        """"""Placeholder docstring""""""\n        self.sagemaker_session.stop_tuning_job(name=self.name)\n\n    def wait(self):\n        """"""Placeholder docstring""""""\n        self.sagemaker_session.wait_for_tuning_job(self.name)\n\n\ndef create_identical_dataset_and_algorithm_tuner(\n    parent, additional_parents=None, sagemaker_session=None\n):\n    """"""Creates a new tuner by copying the request fields from the provided parent to the new\n        instance of ``HyperparameterTuner`` followed by addition of warm start configuration\n        with the type as ""IdenticalDataAndAlgorithm"" and ``parents`` as the\n        union of provided list of ``additional_parents`` and the ``parent``.\n\n    Args:\n        parent (str): Primary parent tuning job\'s name from which the Tuner and\n            Estimator configuration has to be copied\n        additional_parents (set{str}): Set of additional parent tuning job\'s\n            names along with the primary parent tuning job name to be used in\n            warm starting the transfer learning tuner.\n        sagemaker_session (sagemaker.session.Session): Session object which\n            manages interactions with Amazon SageMaker APIs and any other AWS\n            services needed. If not specified, one is created using the default\n            AWS configuration chain.\n\n    Returns:\n        sagemaker.tuner.HyperparameterTuner: a new ``HyperparameterTuner``\n        object for the warm-started hyperparameter tuning job\n    """"""\n\n    parent_tuner = HyperparameterTuner.attach(\n        tuning_job_name=parent, sagemaker_session=sagemaker_session\n    )\n    return parent_tuner.identical_dataset_and_algorithm_tuner(additional_parents=additional_parents)\n\n\ndef create_transfer_learning_tuner(\n    parent, additional_parents=None, estimator=None, sagemaker_session=None\n):\n    """"""Creates a new ``HyperParameterTuner`` by copying the request fields from the\n    provided parent to the new instance\n        of ``HyperparameterTuner`` followed by addition of warm start\n        configuration with the type as ""TransferLearning"" and ``parents`` as the\n        union of provided list of ``additional_parents`` and the ``parent``.\n\n    Args:\n        parent (str): Primary parent tuning job\'s name from which the Tuner and\n            Estimator configuration has to be copied\n        additional_parents (set{str}): Set of additional parent tuning job\'s\n            names along with the primary parent tuning job name to be used in\n            warm starting the identical dataset and algorithm tuner.\n        estimator (sagemaker.estimator.EstimatorBase): An estimator object that\n            has been initialized with the desired configuration. There does not\n            need to be a training job associated with this instance.\n        sagemaker_session (sagemaker.session.Session): Session object which\n            manages interactions with Amazon SageMaker APIs and any other AWS\n            services needed. If not specified, one is created using the default\n            AWS configuration chain.\n\n    Returns:\n        sagemaker.tuner.HyperparameterTuner: New instance of warm started\n        HyperparameterTuner\n    """"""\n\n    parent_tuner = HyperparameterTuner.attach(\n        tuning_job_name=parent, sagemaker_session=sagemaker_session\n    )\n    return parent_tuner.transfer_learning_tuner(\n        additional_parents=additional_parents, estimator=estimator\n    )\n'"
src/sagemaker/user_agent.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nimport platform\nimport sys\n\nimport boto3\nimport botocore\nimport importlib_metadata\n\nSDK_VERSION = importlib_metadata.version(""sagemaker"")\nOS_NAME = platform.system() or ""UnresolvedOS""\nOS_VERSION = platform.release() or ""UnresolvedOSVersion""\nPYTHON_VERSION = ""{}.{}.{}"".format(\n    sys.version_info.major, sys.version_info.minor, sys.version_info.micro\n)\n\n\ndef determine_prefix():\n    """"""Placeholder docstring""""""\n    prefix = ""AWS-SageMaker-Python-SDK/{} Python/{} {}/{} Boto3/{} Botocore/{}"".format(\n        SDK_VERSION, PYTHON_VERSION, OS_NAME, OS_VERSION, boto3.__version__, botocore.__version__\n    )\n\n    try:\n        with open(""/etc/opt/ml/sagemaker-notebook-instance-version.txt"") as sagemaker_nbi_file:\n            prefix = ""AWS-SageMaker-Notebook-Instance/{} {}"".format(\n                sagemaker_nbi_file.read().strip(), prefix\n            )\n    except IOError:\n        # This file isn\'t expected to always exist, and we DO want to silently ignore failures.\n        pass\n\n    return prefix\n\n\ndef prepend_user_agent(client):\n    """"""\n    Args:\n        client:\n    """"""\n    prefix = determine_prefix()\n\n    if client._client_config.user_agent is None:\n        client._client_config.user_agent = prefix\n    else:\n        client._client_config.user_agent = ""{} {}"".format(prefix, client._client_config.user_agent)\n'"
src/sagemaker/utils.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nimport contextlib\nimport errno\nimport logging\nimport os\nimport random\nimport re\nimport shutil\nimport sys\nimport tarfile\nimport tempfile\nimport time\nfrom datetime import datetime\nfrom functools import wraps\n\nimport botocore\nimport six\nfrom six.moves.urllib import parse\n\n\nECR_URI_PATTERN = r""^(\\d+)(\\.)dkr(\\.)ecr(\\.)(.+)(\\.)(.*)(/)(.*:.*)$""\nMAX_BUCKET_PATHS_COUNT = 5\nS3_PREFIX = ""s3://""\nHTTP_PREFIX = ""http://""\nHTTPS_PREFIX = ""https://""\nDEFAULT_SLEEP_TIME_SECONDS = 10\n\nlogger = logging.getLogger(__name__)\n\n\n# Use the base name of the image as the job name if the user doesn\'t give us one\ndef name_from_image(image):\n    """"""Create a training job name based on the image name and a timestamp.\n\n    Args:\n        image (str): Image name.\n\n    Returns:\n        str: Training job name using the algorithm from the image name and a\n        timestamp.\n    """"""\n    return name_from_base(base_name_from_image(image))\n\n\ndef name_from_base(base, max_length=63, short=False):\n    """"""Append a timestamp to the provided string.\n\n    This function assures that the total length of the resulting string is\n    not longer than the specified max length, trimming the input parameter if\n    necessary.\n\n    Args:\n        base (str): String used as prefix to generate the unique name.\n        max_length (int): Maximum length for the resulting string.\n        short (bool): Whether or not to use a truncated timestamp.\n\n    Returns:\n        str: Input parameter with appended timestamp.\n    """"""\n    timestamp = sagemaker_short_timestamp() if short else sagemaker_timestamp()\n    trimmed_base = base[: max_length - len(timestamp) - 1]\n    return ""{}-{}"".format(trimmed_base, timestamp)\n\n\ndef unique_name_from_base(base, max_length=63):\n    """"""\n    Args:\n        base:\n        max_length:\n    """"""\n    unique = ""%04x"" % random.randrange(16 ** 4)  # 4-digit hex\n    ts = str(int(time.time()))\n    available_length = max_length - 2 - len(ts) - len(unique)\n    trimmed = base[:available_length]\n    return ""{}-{}-{}"".format(trimmed, ts, unique)\n\n\ndef base_name_from_image(image):\n    """"""Extract the base name of the image to use as the \'algorithm name\' for the\n    job.\n\n    Args:\n        image (str): Image name.\n\n    Returns:\n        str: Algorithm name, as extracted from the image name.\n    """"""\n    m = re.match(""^(.+/)?([^:/]+)(:[^:]+)?$"", image)\n    algo_name = m.group(2) if m else image\n    return algo_name\n\n\ndef sagemaker_timestamp():\n    """"""Return a timestamp with millisecond precision.""""""\n    moment = time.time()\n    moment_ms = repr(moment).split(""."")[1][:3]\n    return time.strftime(""%Y-%m-%d-%H-%M-%S-{}"".format(moment_ms), time.gmtime(moment))\n\n\ndef sagemaker_short_timestamp():\n    """"""Return a timestamp that is relatively short in length""""""\n    return time.strftime(""%y%m%d-%H%M"")\n\n\ndef debug(func):\n    """"""Print the function name and arguments for debugging.\n\n    Args:\n        func:\n    """"""\n\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        print(""{} args: {} kwargs: {}"".format(func.__name__, args, kwargs))\n        return func(*args, **kwargs)\n\n    return wrapper\n\n\ndef get_config_value(key_path, config):\n    """"""\n    Args:\n        key_path:\n        config:\n    """"""\n    if config is None:\n        return None\n\n    current_section = config\n    for key in key_path.split("".""):\n        if key in current_section:\n            current_section = current_section[key]\n        else:\n            return None\n\n    return current_section\n\n\ndef get_short_version(framework_version):\n    """"""Return short version in the format of x.x\n\n    Args:\n        framework_version: The version string to be shortened.\n\n    Returns:\n        str: The short version string\n    """"""\n    return ""."".join(framework_version.split(""."")[:2])\n\n\ndef to_str(value):\n    """"""Convert the input to a string, unless it is a unicode string in Python 2.\n\n    Unicode strings are supported as native strings in Python 3, but\n    ``str()`` cannot be invoked on unicode strings in Python 2, so we need to\n    check for that case when converting user-specified values to strings.\n\n    Args:\n        value: The value to convert to a string.\n\n    Returns:\n        str or unicode: The string representation of the value or the unicode\n        string itself.\n    """"""\n    if sys.version_info.major < 3 and isinstance(value, six.string_types):\n        return value\n    return str(value)\n\n\ndef extract_name_from_job_arn(arn):\n    """"""Returns the name used in the API given a full ARN for a training job or\n    hyperparameter tuning job.\n\n    Args:\n        arn:\n    """"""\n    slash_pos = arn.find(""/"")\n    if slash_pos == -1:\n        raise ValueError(""Cannot parse invalid ARN: %s"" % arn)\n    return arn[(slash_pos + 1) :]\n\n\ndef secondary_training_status_changed(current_job_description, prev_job_description):\n    """"""Returns true if training job\'s secondary status message has changed.\n\n    Args:\n        current_job_description: Current job description, returned from DescribeTrainingJob call.\n        prev_job_description: Previous job description, returned from DescribeTrainingJob call.\n\n    Returns:\n        boolean: Whether the secondary status message of a training job changed\n        or not.\n    """"""\n    current_secondary_status_transitions = current_job_description.get(""SecondaryStatusTransitions"")\n    if (\n        current_secondary_status_transitions is None\n        or len(current_secondary_status_transitions) == 0\n    ):\n        return False\n\n    prev_job_secondary_status_transitions = (\n        prev_job_description.get(""SecondaryStatusTransitions"")\n        if prev_job_description is not None\n        else None\n    )\n\n    last_message = (\n        prev_job_secondary_status_transitions[-1][""StatusMessage""]\n        if prev_job_secondary_status_transitions is not None\n        and len(prev_job_secondary_status_transitions) > 0\n        else """"\n    )\n\n    message = current_job_description[""SecondaryStatusTransitions""][-1][""StatusMessage""]\n\n    return message != last_message\n\n\ndef secondary_training_status_message(job_description, prev_description):\n    """"""Returns a string contains last modified time and the secondary training\n    job status message.\n\n    Args:\n        job_description: Returned response from DescribeTrainingJob call\n        prev_description: Previous job description from DescribeTrainingJob call\n\n    Returns:\n        str: Job status string to be printed.\n    """"""\n\n    if (\n        job_description is None\n        or job_description.get(""SecondaryStatusTransitions"") is None\n        or len(job_description.get(""SecondaryStatusTransitions"")) == 0\n    ):\n        return """"\n\n    prev_description_secondary_transitions = (\n        prev_description.get(""SecondaryStatusTransitions"") if prev_description is not None else None\n    )\n    prev_transitions_num = (\n        len(prev_description[""SecondaryStatusTransitions""])\n        if prev_description_secondary_transitions is not None\n        else 0\n    )\n    current_transitions = job_description[""SecondaryStatusTransitions""]\n\n    if len(current_transitions) == prev_transitions_num:\n        # Secondary status is not changed but the message changed.\n        transitions_to_print = current_transitions[-1:]\n    else:\n        # Secondary status is changed we need to print all the entries.\n        transitions_to_print = current_transitions[\n            prev_transitions_num - len(current_transitions) :\n        ]\n\n    status_strs = []\n    for transition in transitions_to_print:\n        message = transition[""StatusMessage""]\n        time_str = datetime.utcfromtimestamp(\n            time.mktime(job_description[""LastModifiedTime""].timetuple())\n        ).strftime(""%Y-%m-%d %H:%M:%S"")\n        status_strs.append(""{} {} - {}"".format(time_str, transition[""Status""], message))\n\n    return ""\\n"".join(status_strs)\n\n\ndef generate_tensorboard_url(domain, bucket_paths):\n    """"""Generate Tensorboard URL for given list of s3 buckets\n\n    Args:\n        domain: JupyterLab app domain\n        bucket_paths: List of S3 bucket paths in format `bucket/path`\n                      or a single string in the same format\n\n    Returns:\n        str: Tensorboard URL\n\n    Raises:\n        AttributeError if invalid inputs are passed\n    """"""\n\n    def trim_prefix(s, prefix):\n        if s.startswith(prefix):\n            return s[len(prefix) :]\n        return s\n\n    def encode_s3_url(s3_url):\n        if not s3_url:\n            raise AttributeError(""bucket_paths element should not be empty"")\n        s3_url = trim_prefix(s3_url, S3_PREFIX)\n        return parse.quote_plus(""{}{}"".format(S3_PREFIX, s3_url))\n\n    if not isinstance(domain, six.string_types):\n        raise AttributeError(""domain parameter should be string"")\n\n    if len(domain) == 0:\n        raise AttributeError(""domain parameter should not be empty"")\n\n    if isinstance(bucket_paths, six.string_types):\n        bucket_paths = [bucket_paths]\n    elif not isinstance(bucket_paths, list):\n        raise AttributeError(""bucket paths should be a list or a string"")\n\n    if len(bucket_paths) == 0:\n        raise AttributeError(""bucket_paths parameter should not be empty list"")\n\n    domain = trim_prefix(domain, HTTPS_PREFIX)\n    domain = trim_prefix(domain, HTTP_PREFIX)\n\n    s3_urls = map(encode_s3_url, bucket_paths)\n    query = "","".join(s3_urls)\n\n    return ""https://{}/tensorboard/default?s3urls={}"".format(domain, query)\n\n\ndef download_folder(bucket_name, prefix, target, sagemaker_session):\n    """"""Download a folder from S3 to a local path\n\n    Args:\n        bucket_name (str): S3 bucket name\n        prefix (str): S3 prefix within the bucket that will be downloaded. Can\n            be a single file.\n        target (str): destination path where the downloaded items will be placed\n        sagemaker_session (sagemaker.session.Session): a sagemaker session to\n            interact with S3.\n    """"""\n    boto_session = sagemaker_session.boto_session\n    s3 = boto_session.resource(""s3"", region_name=boto_session.region_name)\n\n    prefix = prefix.lstrip(""/"")\n\n    # Try to download the prefix as an object first, in case it is a file and not a \'directory\'.\n    # Do this first, in case the object has broader permissions than the bucket.\n    if not prefix.endswith(""/""):\n        try:\n            file_destination = os.path.join(target, os.path.basename(prefix))\n            s3.Object(bucket_name, prefix).download_file(file_destination)\n            return\n        except botocore.exceptions.ClientError as e:\n            err_info = e.response[""Error""]\n            if err_info[""Code""] == ""404"" and err_info[""Message""] == ""Not Found"":\n                # S3 also throws this error if the object is a folder,\n                # so assume that is the case here, and then raise for an actual 404 later.\n                pass\n            else:\n                raise\n\n    _download_files_under_prefix(bucket_name, prefix, target, s3)\n\n\ndef _download_files_under_prefix(bucket_name, prefix, target, s3):\n    """"""Download all S3 files which match the given prefix\n\n    Args:\n        bucket_name (str): S3 bucket name\n        prefix (str): S3 prefix within the bucket that will be downloaded\n        target (str): destination path where the downloaded items will be placed\n        s3 (boto3.resources.base.ServiceResource): S3 resource\n    """"""\n    bucket = s3.Bucket(bucket_name)\n    for obj_sum in bucket.objects.filter(Prefix=prefix):\n        # if obj_sum is a folder object skip it.\n        if obj_sum.key.endswith(""/""):\n            continue\n        obj = s3.Object(obj_sum.bucket_name, obj_sum.key)\n        s3_relative_path = obj_sum.key[len(prefix) :].lstrip(""/"")\n        file_path = os.path.join(target, s3_relative_path)\n\n        try:\n            os.makedirs(os.path.dirname(file_path))\n        except OSError as exc:\n            # EEXIST means the folder already exists, this is safe to skip\n            # anything else will be raised.\n            if exc.errno != errno.EEXIST:\n                raise\n        obj.download_file(file_path)\n\n\ndef create_tar_file(source_files, target=None):\n    """"""Create a tar file containing all the source_files\n\n    Args:\n        source_files: (List[str]): List of file paths that will be contained in the tar file\n        target:\n\n    Returns:\n        (str): path to created tar file\n    """"""\n    if target:\n        filename = target\n    else:\n        _, filename = tempfile.mkstemp()\n\n    with tarfile.open(filename, mode=""w:gz"") as t:\n        for sf in source_files:\n            # Add all files from the directory into the root of the directory structure of the tar\n            t.add(sf, arcname=os.path.basename(sf))\n    return filename\n\n\n@contextlib.contextmanager\ndef _tmpdir(suffix="""", prefix=""tmp""):\n    """"""Create a temporary directory with a context manager. The file is deleted\n    when the context exits.\n\n    The prefix, suffix, and dir arguments are the same as for mkstemp().\n\n    Args:\n        suffix (str): If suffix is specified, the file name will end with that\n            suffix, otherwise there will be no suffix.\n        prefix (str): If prefix is specified, the file name will begin with that\n            prefix; otherwise, a default prefix is used.\n\n    Returns:\n        str: path to the directory\n    """"""\n    tmp = tempfile.mkdtemp(suffix=suffix, prefix=prefix, dir=None)\n    yield tmp\n    shutil.rmtree(tmp)\n\n\ndef repack_model(\n    inference_script,\n    source_directory,\n    dependencies,\n    model_uri,\n    repacked_model_uri,\n    sagemaker_session,\n    kms_key=None,\n):\n    """"""Unpack model tarball and creates a new model tarball with the provided\n    code script.\n\n    This function does the following: - uncompresses model tarball from S3 or\n    local system into a temp folder - replaces the inference code from the model\n    with the new code provided - compresses the new model tarball and saves it\n    in S3 or local file system\n\n    Args:\n        inference_script (str): path or basename of the inference script that\n            will be packed into the model\n        source_directory (str): path including all the files that will be packed\n            into the model\n        dependencies (list[str]): A list of paths to directories (absolute or\n            relative) with any additional libraries that will be exported to the\n            container (default: []). The library folders will be copied to\n            SageMaker in the same folder where the entrypoint is copied.\n            Example\n\n                The following call >>> Estimator(entry_point=\'train.py\',\n                dependencies=[\'my/libs/common\', \'virtual-env\']) results in the\n                following inside the container:\n\n                >>> $ ls\n\n                >>> opt/ml/code\n                >>>     |------ train.py\n                >>>     |------ common\n                >>>     |------ virtual-env\n        model_uri (str): S3 or file system location of the original model tar\n        repacked_model_uri (str): path or file system location where the new\n            model will be saved\n        sagemaker_session (sagemaker.session.Session): a sagemaker session to\n            interact with S3.\n        kms_key (str): KMS key ARN for encrypting the repacked model file\n\n    Returns:\n        str: path to the new packed model\n    """"""\n    dependencies = dependencies or []\n\n    with _tmpdir() as tmp:\n        model_dir = _extract_model(model_uri, sagemaker_session, tmp)\n\n        _create_or_update_code_dir(\n            model_dir, inference_script, source_directory, dependencies, sagemaker_session, tmp\n        )\n\n        tmp_model_path = os.path.join(tmp, ""temp-model.tar.gz"")\n        with tarfile.open(tmp_model_path, mode=""w:gz"") as t:\n            t.add(model_dir, arcname=os.path.sep)\n\n        _save_model(repacked_model_uri, tmp_model_path, sagemaker_session, kms_key=kms_key)\n\n\ndef _save_model(repacked_model_uri, tmp_model_path, sagemaker_session, kms_key):\n    """"""\n    Args:\n        repacked_model_uri:\n        tmp_model_path:\n        sagemaker_session:\n    """"""\n    if repacked_model_uri.lower().startswith(""s3://""):\n        url = parse.urlparse(repacked_model_uri)\n        bucket, key = url.netloc, url.path.lstrip(""/"")\n        new_key = key.replace(os.path.basename(key), os.path.basename(repacked_model_uri))\n\n        if kms_key:\n            extra_args = {""ServerSideEncryption"": ""aws:kms"", ""SSEKMSKeyId"": kms_key}\n        else:\n            extra_args = None\n        sagemaker_session.boto_session.resource(\n            ""s3"", region_name=sagemaker_session.boto_region_name\n        ).Object(bucket, new_key).upload_file(tmp_model_path, ExtraArgs=extra_args)\n    else:\n        shutil.move(tmp_model_path, repacked_model_uri.replace(""file://"", """"))\n\n\ndef _create_or_update_code_dir(\n    model_dir, inference_script, source_directory, dependencies, sagemaker_session, tmp\n):\n    """"""\n    Args:\n        model_dir:\n        inference_script:\n        source_directory:\n        dependencies:\n        sagemaker_session:\n        tmp:\n    """"""\n    code_dir = os.path.join(model_dir, ""code"")\n    if source_directory and source_directory.lower().startswith(""s3://""):\n        local_code_path = os.path.join(tmp, ""local_code.tar.gz"")\n        download_file_from_url(source_directory, local_code_path, sagemaker_session)\n\n        with tarfile.open(name=local_code_path, mode=""r:gz"") as t:\n            t.extractall(path=code_dir)\n\n    elif source_directory:\n        if os.path.exists(code_dir):\n            shutil.rmtree(code_dir)\n        shutil.copytree(source_directory, code_dir)\n    else:\n        if not os.path.exists(code_dir):\n            os.mkdir(code_dir)\n        try:\n            shutil.copy2(inference_script, code_dir)\n        except FileNotFoundError:\n            if os.path.exists(os.path.join(code_dir, inference_script)):\n                pass\n            else:\n                raise\n\n    for dependency in dependencies:\n        lib_dir = os.path.join(code_dir, ""lib"")\n        if os.path.isdir(dependency):\n            shutil.copytree(dependency, os.path.join(lib_dir, os.path.basename(dependency)))\n        else:\n            if not os.path.exists(lib_dir):\n                os.mkdir(lib_dir)\n            shutil.copy2(dependency, lib_dir)\n\n\ndef _extract_model(model_uri, sagemaker_session, tmp):\n    """"""\n    Args:\n        model_uri:\n        sagemaker_session:\n        tmp:\n    """"""\n    tmp_model_dir = os.path.join(tmp, ""model"")\n    os.mkdir(tmp_model_dir)\n    if model_uri.lower().startswith(""s3://""):\n        local_model_path = os.path.join(tmp, ""tar_file"")\n        download_file_from_url(model_uri, local_model_path, sagemaker_session)\n    else:\n        local_model_path = model_uri.replace(""file://"", """")\n    with tarfile.open(name=local_model_path, mode=""r:gz"") as t:\n        t.extractall(path=tmp_model_dir)\n    return tmp_model_dir\n\n\ndef download_file_from_url(url, dst, sagemaker_session):\n    """"""\n    Args:\n        url:\n        dst:\n        sagemaker_session:\n    """"""\n    url = parse.urlparse(url)\n    bucket, key = url.netloc, url.path.lstrip(""/"")\n\n    download_file(bucket, key, dst, sagemaker_session)\n\n\ndef download_file(bucket_name, path, target, sagemaker_session):\n    """"""Download a Single File from S3 into a local path\n\n    Args:\n        bucket_name (str): S3 bucket name\n        path (str): file path within the bucket\n        target (str): destination directory for the downloaded file.\n        sagemaker_session (sagemaker.session.Session): a sagemaker session to\n            interact with S3.\n    """"""\n    path = path.lstrip(""/"")\n    boto_session = sagemaker_session.boto_session\n\n    s3 = boto_session.resource(""s3"", region_name=sagemaker_session.boto_region_name)\n    bucket = s3.Bucket(bucket_name)\n    bucket.download_file(path, target)\n\n\ndef get_ecr_image_uri_prefix(account, region):\n    """"""get prefix of ECR image URI\n\n    Args:\n        account (str): AWS account number\n        region (str): AWS region name\n\n    Returns:\n        (str): URI prefix of ECR image\n    """"""\n    endpoint_data = _botocore_resolver().construct_endpoint(""ecr"", region)\n    return ""{}.dkr.{}"".format(account, endpoint_data[""hostname""])\n\n\ndef sts_regional_endpoint(region):\n    """"""Get the AWS STS endpoint specific for the given region.\n\n    We need this function because the AWS SDK does not yet honor\n    the ``region_name`` parameter when creating an AWS STS client.\n\n    For the list of regional endpoints, see\n    https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_temp_enable-regions.html#id_credentials_region-endpoints.\n\n    Args:\n        region (str): AWS region name\n\n    Returns:\n        str: AWS STS regional endpoint\n    """"""\n    endpoint_data = _botocore_resolver().construct_endpoint(""sts"", region)\n    return ""https://{}"".format(endpoint_data[""hostname""])\n\n\ndef retries(max_retry_count, exception_message_prefix, seconds_to_sleep=DEFAULT_SLEEP_TIME_SECONDS):\n    """"""Retries until max retry count is reached.\n\n    Args:\n        max_retry_count (int): The retry count.\n        exception_message_prefix (str): The message to include in the exception on failure.\n        seconds_to_sleep (int): The number of seconds to sleep between executions.\n\n    """"""\n    for i in range(max_retry_count):\n        yield i\n        time.sleep(seconds_to_sleep)\n\n    raise Exception(\n        ""\'{}\' has reached the maximum retry count of {}"".format(\n            exception_message_prefix, max_retry_count\n        )\n    )\n\n\ndef _botocore_resolver():\n    """"""Get the DNS suffix for the given region.\n\n    Args:\n        region (str): AWS region name\n\n    Returns:\n        str: the DNS suffix\n    """"""\n    loader = botocore.loaders.create_loader()\n    return botocore.regions.EndpointResolver(loader.load_data(""endpoints""))\n\n\ndef _aws_partition(region):\n    """"""\n    Given a region name (ex: ""cn-north-1""), return the corresponding aws partition (""aws-cn"").\n\n    Args:\n        region (str): The region name for which to return the corresponding partition.\n        Ex: ""cn-north-1""\n\n    Returns:\n        str: partition corresponding to the region name passed in. Ex: ""aws-cn""\n    """"""\n    endpoint_data = _botocore_resolver().construct_endpoint(""sts"", region)\n    return endpoint_data[""partition""]\n\n\nclass DeferredError(object):\n    """"""Stores an exception and raises it at a later time if this object is\n    accessed in any way. Useful to allow soft-dependencies on imports, so that\n    the ImportError can be raised again later if code actually relies on the\n    missing library.\n\n    Example::\n\n        try:\n            import obscurelib\n        except ImportError as e:\n            logging.warning(""Failed to import obscurelib. Obscure features will not work."")\n            obscurelib = DeferredError(e)\n    """"""\n\n    def __init__(self, exception):\n        """"""\n        Args:\n            exception:\n        """"""\n        self.exc = exception\n\n    def __getattr__(self, name):\n        """"""Called by Python interpreter before using any method or property on\n        the object. So this will short-circuit essentially any access to this\n        object.\n\n        Args:\n            name:\n        """"""\n        raise self.exc\n\n\ndef _module_import_error(py_module, feature, extras):\n    """"""Return error message for module import errors, provide\n    installation details.\n\n    Args:\n        py_module (str): Module that failed to be imported\n        feature (str): Affected SageMaker feature\n        extras (str): Name of the `extras_require` to install the relevant dependencies\n\n    Returns:\n        str: Error message with installation instructions.\n    """"""\n    error_msg = (\n        ""Failed to import {}. {} features will be impaired or broken. ""\n        ""Please run \\""pip install \'sagemaker[{}]\'\\"" ""\n        ""to install all required dependencies.""\n    )\n    return error_msg.format(py_module, feature, extras)\n'"
src/sagemaker/vpc_utils.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nSUBNETS_KEY = ""Subnets""\nSECURITY_GROUP_IDS_KEY = ""SecurityGroupIds""\nVPC_CONFIG_KEY = ""VpcConfig""\n\n# A global constant value for methods which can optionally override VpcConfig\n# Using the default implies that VpcConfig should be reused from an existing Estimator or\n# Training Job\nVPC_CONFIG_DEFAULT = ""VPC_CONFIG_DEFAULT""\n\n\ndef to_dict(subnets, security_group_ids):\n    """"""Prepares a VpcConfig dict containing keys \'Subnets\' and\n    \'SecurityGroupIds\' This is the dict format expected by SageMaker\n    CreateTrainingJob and CreateModel APIs See\n    https://docs.aws.amazon.com/sagemaker/latest/dg/API_VpcConfig.html\n\n    Args:\n        subnets (list): list of subnet IDs to use in VpcConfig\n        security_group_ids (list): list of security group IDs to use in\n            VpcConfig\n\n    Returns:\n        A VpcConfig dict containing keys \'Subnets\' and \'SecurityGroupIds\' If\n        either or both parameters are None, returns None\n    """"""\n    if subnets is None or security_group_ids is None:\n        return None\n    return {SUBNETS_KEY: subnets, SECURITY_GROUP_IDS_KEY: security_group_ids}\n\n\ndef from_dict(vpc_config, do_sanitize=False):\n    """"""Extracts subnets and security group ids as lists from a VpcConfig dict\n\n    Args:\n        vpc_config (dict): a VpcConfig dict containing \'Subnets\' and\n            \'SecurityGroupIds\'\n        do_sanitize (bool): whether to sanitize the VpcConfig dict before\n            extracting values\n\n    Returns:\n        Tuple of lists as (subnets, security_group_ids) If vpc_config parameter\n        is None, returns (None, None)\n\n    Raises:\n        * ValueError if sanitize enabled and vpc_config is invalid\n\n        * KeyError if sanitize disabled and vpc_config is missing key(s)\n    """"""\n    if do_sanitize:\n        vpc_config = sanitize(vpc_config)\n    if vpc_config is None:\n        return None, None\n    return vpc_config[SUBNETS_KEY], vpc_config[SECURITY_GROUP_IDS_KEY]\n\n\ndef sanitize(vpc_config):\n    """"""Checks that an instance of VpcConfig has the expected keys and values,\n    removes unexpected keys, and raises ValueErrors if any expectations are\n    violated\n\n    Args:\n        vpc_config (dict): a VpcConfig dict containing \'Subnets\' and\n            \'SecurityGroupIds\'\n\n    Returns:\n        A valid VpcConfig dict containing only \'Subnets\' and \'SecurityGroupIds\'\n        from the vpc_config parameter If vpc_config parameter is None, returns\n        None\n\n    Raises:\n        ValueError if any expectations are violated:\n            * vpc_config must be a non-empty dict\n            * vpc_config must have key `Subnets` and the value must be a non-empty list\n            * vpc_config must have key `SecurityGroupIds` and the value must be a non-empty list\n    """"""\n    if vpc_config is None:\n        return vpc_config\n    if not isinstance(vpc_config, dict):\n        raise ValueError(""vpc_config is not a dict: {}"".format(vpc_config))\n    if not vpc_config:\n        raise ValueError(""vpc_config is empty"")\n\n    subnets = vpc_config.get(SUBNETS_KEY)\n    if subnets is None:\n        raise ValueError(""vpc_config is missing key: {}"".format(SUBNETS_KEY))\n    if not isinstance(subnets, list):\n        raise ValueError(""vpc_config value for {} is not a list: {}"".format(SUBNETS_KEY, subnets))\n    if not subnets:\n        raise ValueError(""vpc_config value for {} is empty"".format(SUBNETS_KEY))\n\n    security_group_ids = vpc_config.get(SECURITY_GROUP_IDS_KEY)\n    if security_group_ids is None:\n        raise ValueError(""vpc_config is missing key: {}"".format(SECURITY_GROUP_IDS_KEY))\n    if not isinstance(security_group_ids, list):\n        raise ValueError(\n            ""vpc_config value for {} is not a list: {}"".format(\n                SECURITY_GROUP_IDS_KEY, security_group_ids\n            )\n        )\n    if not security_group_ids:\n        raise ValueError(""vpc_config value for {} is empty"".format(SECURITY_GROUP_IDS_KEY))\n\n    return to_dict(subnets, security_group_ids)\n'"
tests/component/__init__.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n'"
tests/component/test_mxnet_estimator.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport pytest\nfrom mock import Mock\nfrom sagemaker.mxnet import MXNet\n\n\nSCRIPT = ""resnet_cifar_10.py""\nTIMESTAMP = ""2017-11-06-14:14:15.673""\nTIME = 1510006209.073025\nBUCKET_NAME = ""mybucket""\nINSTANCE_COUNT = 1\nINSTANCE_TYPE_GPU = ""ml.p2.xlarge""\nINSTANCE_TYPE_CPU = ""ml.m4.xlarge""\nCPU_IMAGE_NAME = ""sagemaker-mxnet-py2-cpu""\nGPU_IMAGE_NAME = ""sagemaker-mxnet-py2-gpu""\nREGION = ""us-west-2""\nIMAGE_URI_FORMAT_STRING = ""520713654638.dkr.ecr.{}.amazonaws.com/{}:{}-{}-{}""\nREGION = ""us-west-2""\nROLE = ""SagemakerRole""\nSOURCE_DIR = ""s3://fefergerger""\n\n\n@pytest.fixture()\ndef sagemaker_session():\n    boto_mock = Mock(name=""boto_session"", region_name=REGION)\n    ims = Mock(\n        name=""sagemaker_session"",\n        boto_session=boto_mock,\n        config=None,\n        local_mode=False,\n        region_name=REGION,\n    )\n\n    ims.default_bucket = Mock(name=""default_bucket"", return_value=BUCKET_NAME)\n    ims.expand_role = Mock(name=""expand_role"", return_value=ROLE)\n    ims.sagemaker_client.describe_training_job = Mock(\n        return_value={""ModelArtifacts"": {""S3ModelArtifacts"": ""s3://m/m.tar.gz""}}\n    )\n    return ims\n\n\n# Test that we pass all necessary fields from estimator to the session when we call deploy\ndef test_deploy(sagemaker_session, tf_version):\n    estimator = MXNet(\n        entry_point=SCRIPT,\n        source_dir=SOURCE_DIR,\n        role=ROLE,\n        framework_version=tf_version,\n        train_instance_count=2,\n        train_instance_type=INSTANCE_TYPE_GPU,\n        sagemaker_session=sagemaker_session,\n        base_job_name=""test-cifar"",\n    )\n\n    estimator.fit(""s3://mybucket/train"")\n    print(""job succeeded: {}"".format(estimator.latest_training_job.name))\n\n    estimator.deploy(initial_instance_count=1, instance_type=INSTANCE_TYPE_CPU)\n    image = IMAGE_URI_FORMAT_STRING.format(REGION, CPU_IMAGE_NAME, tf_version, ""cpu"", ""py2"")\n    sagemaker_session.create_model.assert_called_with(\n        estimator._current_job_name,\n        ROLE,\n        {\n            ""Environment"": {\n                ""SAGEMAKER_ENABLE_CLOUDWATCH_METRICS"": ""false"",\n                ""SAGEMAKER_CONTAINER_LOG_LEVEL"": ""20"",\n                ""SAGEMAKER_SUBMIT_DIRECTORY"": SOURCE_DIR,\n                ""SAGEMAKER_REGION"": REGION,\n                ""SAGEMAKER_PROGRAM"": SCRIPT,\n            },\n            ""Image"": image,\n            ""ModelDataUrl"": ""s3://m/m.tar.gz"",\n        },\n    )\n'"
tests/component/test_tf_estimator.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport pytest\nfrom mock import Mock\nfrom sagemaker.tensorflow import TensorFlow\n\n\nSCRIPT = ""resnet_cifar_10.py""\nTIMESTAMP = ""2017-11-06-14:14:15.673""\nTIME = 1510006209.073025\nBUCKET_NAME = ""mybucket""\nINSTANCE_COUNT = 1\nINSTANCE_TYPE_GPU = ""ml.p2.xlarge""\nINSTANCE_TYPE_CPU = ""ml.m4.xlarge""\nCPU_IMAGE_NAME = ""sagemaker-tensorflow-py2-cpu""\nGPU_IMAGE_NAME = ""sagemaker-tensorflow-py2-gpu""\nREGION = ""us-west-2""\nIMAGE_URI_FORMAT_STRING = ""520713654638.dkr.ecr.{}.amazonaws.com/{}:{}-{}-{}""\nREGION = ""us-west-2""\nROLE = ""SagemakerRole""\nSOURCE_DIR = ""s3://fefergerger""\n\n\n@pytest.fixture()\ndef sagemaker_session():\n    boto_mock = Mock(name=""boto_session"", region_name=REGION)\n    ims = Mock(\n        name=""sagemaker_session"",\n        boto_session=boto_mock,\n        config=None,\n        local_mode=False,\n        region_name=REGION,\n    )\n    ims.default_bucket = Mock(name=""default_bucket"", return_value=BUCKET_NAME)\n    ims.expand_role = Mock(name=""expand_role"", return_value=ROLE)\n    ims.sagemaker_client.describe_training_job = Mock(\n        return_value={""ModelArtifacts"": {""S3ModelArtifacts"": ""s3://m/m.tar.gz""}}\n    )\n    return ims\n\n\n# Test that we pass all necessary fields from estimator to the session when we call deploy\ndef test_deploy(sagemaker_session, tf_version):\n    estimator = TensorFlow(\n        entry_point=SCRIPT,\n        source_dir=SOURCE_DIR,\n        role=ROLE,\n        framework_version=tf_version,\n        train_instance_count=2,\n        train_instance_type=INSTANCE_TYPE_CPU,\n        sagemaker_session=sagemaker_session,\n        base_job_name=""test-cifar"",\n    )\n\n    estimator.fit(""s3://mybucket/train"")\n    print(""job succeeded: {}"".format(estimator.latest_training_job.name))\n\n    estimator.deploy(initial_instance_count=1, instance_type=INSTANCE_TYPE_CPU)\n    image = IMAGE_URI_FORMAT_STRING.format(REGION, CPU_IMAGE_NAME, tf_version, ""cpu"", ""py2"")\n    sagemaker_session.create_model.assert_called_with(\n        estimator._current_job_name,\n        ROLE,\n        {\n            ""Environment"": {\n                ""SAGEMAKER_ENABLE_CLOUDWATCH_METRICS"": ""false"",\n                ""SAGEMAKER_CONTAINER_LOG_LEVEL"": ""20"",\n                ""SAGEMAKER_SUBMIT_DIRECTORY"": SOURCE_DIR,\n                ""SAGEMAKER_REQUIREMENTS"": """",\n                ""SAGEMAKER_REGION"": REGION,\n                ""SAGEMAKER_PROGRAM"": SCRIPT,\n            },\n            ""Image"": image,\n            ""ModelDataUrl"": ""s3://m/m.tar.gz"",\n        },\n    )\n'"
tests/data/dummy_script.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nprint(""This is the print output from dummy_script.py."")\n'"
tests/integ/__init__.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport logging\nimport os\nimport sys\n\nimport boto3\n\nDATA_DIR = os.path.join(os.path.dirname(__file__), "".."", ""data"")\nTRAINING_DEFAULT_TIMEOUT_MINUTES = 20\nTUNING_DEFAULT_TIMEOUT_MINUTES = 20\nTRANSFORM_DEFAULT_TIMEOUT_MINUTES = 20\nAUTO_ML_DEFAULT_TIMEMOUT_MINUTES = 60\nPYTHON_VERSION = ""py"" + str(sys.version_info.major)\n\n# these regions have some p2 and p3 instances, but not enough for continuous testing\nHOSTING_NO_P2_REGIONS = [\n    ""ap-east-1"",\n    ""ca-central-1"",\n    ""eu-central-1"",\n    ""eu-north-1"",\n    ""eu-west-2"",\n    ""eu-west-3"",\n    ""sa-east-1"",\n    ""us-west-1"",\n]\nHOSTING_NO_P3_REGIONS = [\n    ""ap-east-1"",\n    ""ap-south-1"",\n    ""ap-southeast-1"",\n    ""ap-southeast-2"",\n    ""ca-central-1"",\n    ""eu-central-1"",\n    ""eu-north-1"",\n    ""eu-west-2"",\n    ""eu-west-3"",\n    ""sa-east-1"",\n    ""us-west-1"",\n]\nTRAINING_NO_P2_REGIONS = [\n    ""ap-east-1"",\n    ""ap-southeast-1"",\n    ""ap-southeast-2"",\n    ""ca-central-1"",\n    ""eu-central-1"",\n    ""eu-north-1"",\n    ""eu-west-2"",\n    ""eu-west-3"",\n    ""me-south-1"",\n    ""sa-east-1"",\n    ""us-west-1"",\n]\n\n# EI is currently only supported in the following regions\n# regions were derived from https://aws.amazon.com/machine-learning/elastic-inference/pricing/\nEI_SUPPORTED_REGIONS = [\n    ""ap-northeast-1"",\n    ""ap-northeast-2"",\n    ""eu-west-1"",\n    ""us-east-1"",\n    ""us-east-2"",\n    ""us-west-2"",\n]\n\nNO_LDA_REGIONS = [""eu-west-3"", ""eu-north-1"", ""sa-east-1"", ""ap-east-1"", ""me-south-1""]\nNO_MARKET_PLACE_REGIONS = [""eu-west-3"", ""eu-north-1"", ""sa-east-1"", ""ap-east-1"", ""me-south-1""]\nNO_AUTO_ML_REGIONS = [""sa-east-1"", ""me-south-1"", ""ap-east-1"", ""eu-west-3""]\nNO_MODEL_MONITORING_REGIONS = [""me-south-1""]\n\nEFS_TEST_ENABLED_REGION = []\n\nlogging.getLogger(""boto3"").setLevel(logging.INFO)\nlogging.getLogger(""botocore"").setLevel(logging.INFO)\n\n\ndef test_region():\n    return os.environ.get(""TEST_AWS_REGION_NAME"", boto3.session.Session().region_name)\n'"
tests/integ/auto_ml_utils.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport os\n\nfrom sagemaker import AutoML\nfrom tests.integ import DATA_DIR, AUTO_ML_DEFAULT_TIMEMOUT_MINUTES\nfrom tests.integ.timeout import timeout\n\nROLE = ""SageMakerRole""\nDATA_DIR = os.path.join(DATA_DIR, ""automl"", ""data"")\nPREFIX = ""sagemaker/beta-automl-xgboost""\nTRAINING_DATA = os.path.join(DATA_DIR, ""iris_training.csv"")\nTARGET_ATTRIBUTE_NAME = ""virginica""\n\n\ndef create_auto_ml_job_if_not_exist(sagemaker_session):\n    auto_ml_job_name = ""python-sdk-integ-test-base-job""\n\n    try:\n        sagemaker_session.describe_auto_ml_job(job_name=auto_ml_job_name)\n    except Exception as e:  # noqa: F841\n        auto_ml = AutoML(\n            role=ROLE,\n            target_attribute_name=TARGET_ATTRIBUTE_NAME,\n            sagemaker_session=sagemaker_session,\n            max_candidates=3,\n        )\n        inputs = sagemaker_session.upload_data(path=TRAINING_DATA, key_prefix=PREFIX + ""/input"")\n        with timeout(minutes=AUTO_ML_DEFAULT_TIMEMOUT_MINUTES):\n            auto_ml.fit(inputs, job_name=auto_ml_job_name, wait=True)\n'"
tests/integ/file_system_input_utils.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nfrom operator import itemgetter\nimport os\nfrom os import path\nimport stat\nimport tempfile\nimport uuid\n\nfrom botocore.exceptions import ClientError\nfrom fabric import Connection\n\nfrom tests.integ.retry import retries\nfrom tests.integ.vpc_test_utils import check_or_create_vpc_resources_efs_fsx\n\nVPC_NAME = ""sagemaker-efs-fsx-vpc""\nALINUX_AMI_NAME_FILTER = ""amzn-ami-hvm-????.??.?.????????-x86_64-gp2""\nEFS_CREATION_TOKEN = str(uuid.uuid4())\nPREFIX = ""ec2_fs_key_""\nKEY_NAME = PREFIX + str(uuid.uuid4().hex.upper()[0:8])\nROLE_NAME = ""SageMakerRole""\nMIN_COUNT = 1\nMAX_COUNT = 1\n\nEFS_MOUNT_DIRECTORY = ""efs""\nFSX_MOUNT_DIRECTORY = ""/mnt/fsx""\n\nRESOURCE_PATH = os.path.join(os.path.dirname(__file__), "".."", ""data"")\nMNIST_RESOURCE_PATH = os.path.join(RESOURCE_PATH, ""tensorflow_mnist"")\nMNIST_LOCAL_DATA = os.path.join(MNIST_RESOURCE_PATH, ""data"")\nONE_P_RESOURCE_PATH = os.path.join(RESOURCE_PATH, ""protobuf_data"")\nONE_P_LOCAL_DATA = os.path.join(ONE_P_RESOURCE_PATH, ""matrix_0.pbr"")\n\nSCRIPTS_FOLDER = os.path.join(os.path.dirname(__file__), "".."", ""scripts"")\nFS_MOUNT_SCRIPT = os.path.join(SCRIPTS_FOLDER, ""fs_mount_setup.sh"")\nFILE_NAME = KEY_NAME + "".pem""\nKEY_PATH = os.path.join(tempfile.gettempdir(), FILE_NAME)\nSTORAGE_CAPACITY_IN_BYTES = 3600\n\nfs_resources = {""key_name"": KEY_NAME, ""key_path"": KEY_PATH, ""role_name"": ROLE_NAME}\n\n\ndef set_up_efs_fsx(sagemaker_session, ec2_instance_type):\n    try:\n        _check_or_create_key_pair(sagemaker_session)\n        _check_or_create_iam_profile_and_attach_role(sagemaker_session)\n\n        subnet_ids, security_group_ids = check_or_create_vpc_resources_efs_fsx(\n            sagemaker_session, VPC_NAME\n        )\n        fs_resources[""subnet_id""] = subnet_ids[0]\n        fs_resources[""security_group_ids""] = security_group_ids\n\n        ami_id = _ami_id_for_region(sagemaker_session)\n        ec2_instance = _create_ec2_instance(\n            sagemaker_session,\n            ami_id,\n            ec2_instance_type,\n            KEY_NAME,\n            MIN_COUNT,\n            MAX_COUNT,\n            security_group_ids,\n            subnet_ids[0],\n        )\n\n        file_system_efs_id, mount_efs_target_id = _create_efs(sagemaker_session)\n        file_system_fsx_id = _create_fsx(sagemaker_session)\n\n        connected_instance = _connect_ec2_instance(ec2_instance)\n        region = sagemaker_session.boto_region_name\n        _upload_data_and_mount_fs(\n            connected_instance, file_system_efs_id, file_system_fsx_id, region\n        )\n        return fs_resources\n    except Exception:\n        tear_down(sagemaker_session, fs_resources)\n        raise\n\n\ndef _ami_id_for_region(sagemaker_session):\n    ec2_client = sagemaker_session.boto_session.client(""ec2"")\n    filters = [\n        {""Name"": ""name"", ""Values"": [ALINUX_AMI_NAME_FILTER]},\n        {""Name"": ""state"", ""Values"": [""available""]},\n    ]\n    response = ec2_client.describe_images(Filters=filters)\n    image_details = sorted(response[""Images""], key=itemgetter(""CreationDate""), reverse=True)\n\n    if len(image_details) == 0:\n        raise Exception(""AMI was not found based on current search criteria: {}"".format(filters))\n\n    return image_details[0][""ImageId""]\n\n\ndef _connect_ec2_instance(ec2_instance):\n    public_ip_address = ec2_instance.public_ip_address\n    connected_instance = Connection(\n        host=public_ip_address,\n        port=22,\n        user=""ec2-user"",\n        connect_kwargs={""key_filename"": [KEY_PATH]},\n    )\n    return connected_instance\n\n\ndef _upload_data_and_mount_fs(connected_instance, file_system_efs_id, file_system_fsx_id, region):\n    connected_instance.put(FS_MOUNT_SCRIPT, ""."")\n    connected_instance.run(""mkdir temp_tf; mkdir temp_one_p"", in_stream=False)\n    for dir_name, subdir_list, file_list in os.walk(MNIST_LOCAL_DATA):\n        for fname in file_list:\n            local_file = os.path.join(MNIST_LOCAL_DATA, fname)\n            connected_instance.put(local_file, ""temp_tf/"")\n    connected_instance.put(ONE_P_LOCAL_DATA, ""temp_one_p/"")\n    connected_instance.run(\n        ""sudo sh fs_mount_setup.sh {} {} {} {} {}"".format(\n            file_system_efs_id, file_system_fsx_id, region, EFS_MOUNT_DIRECTORY, FSX_MOUNT_DIRECTORY\n        ),\n        in_stream=False,\n    )\n\n\ndef _create_efs(sagemaker_session):\n    efs_client = sagemaker_session.boto_session.client(""efs"")\n    create_response = efs_client.create_file_system(CreationToken=EFS_CREATION_TOKEN)\n    efs_id = create_response[""FileSystemId""]\n    fs_resources[""file_system_efs_id""] = efs_id\n    for _ in retries(50, ""Checking EFS creating status""):\n        desc = efs_client.describe_file_systems(CreationToken=EFS_CREATION_TOKEN)\n        status = desc[""FileSystems""][0][""LifeCycleState""]\n        if status == ""available"":\n            break\n    mount_target_id = _create_efs_mount(sagemaker_session, efs_id)\n\n    return efs_id, mount_target_id\n\n\ndef _create_efs_mount(sagemaker_session, file_system_id):\n    subnet_ids, security_group_ids = check_or_create_vpc_resources_efs_fsx(\n        sagemaker_session, VPC_NAME\n    )\n    efs_client = sagemaker_session.boto_session.client(""efs"")\n    mount_response = efs_client.create_mount_target(\n        FileSystemId=file_system_id, SubnetId=subnet_ids[0], SecurityGroups=security_group_ids\n    )\n    mount_target_id = mount_response[""MountTargetId""]\n    fs_resources[""mount_efs_target_id""] = mount_target_id\n\n    for _ in retries(50, ""Checking EFS mounting target status""):\n        desc = efs_client.describe_mount_targets(MountTargetId=mount_target_id)\n        status = desc[""MountTargets""][0][""LifeCycleState""]\n        if status == ""available"":\n            break\n\n    return mount_target_id\n\n\ndef _create_fsx(sagemaker_session):\n    fsx_client = sagemaker_session.boto_session.client(""fsx"")\n    subnet_ids, security_group_ids = check_or_create_vpc_resources_efs_fsx(\n        sagemaker_session, VPC_NAME\n    )\n    create_response = fsx_client.create_file_system(\n        FileSystemType=""LUSTRE"",\n        StorageCapacity=STORAGE_CAPACITY_IN_BYTES,\n        SubnetIds=[subnet_ids[0]],\n        SecurityGroupIds=security_group_ids,\n    )\n    fsx_id = create_response[""FileSystem""][""FileSystemId""]\n    fs_resources[""file_system_fsx_id""] = fsx_id\n\n    for _ in retries(50, ""Checking FSX creating status""):\n        desc = fsx_client.describe_file_systems(FileSystemIds=[fsx_id])\n        status = desc[""FileSystems""][0][""Lifecycle""]\n        if status == ""AVAILABLE"":\n            break\n\n    return fsx_id\n\n\ndef _create_ec2_instance(\n    sagemaker_session,\n    image_id,\n    instance_type,\n    key_name,\n    min_count,\n    max_count,\n    security_group_ids,\n    subnet_id,\n):\n    ec2_resource = sagemaker_session.boto_session.resource(""ec2"")\n    ec2_instances = ec2_resource.create_instances(\n        ImageId=image_id,\n        InstanceType=instance_type,\n        KeyName=key_name,\n        MinCount=min_count,\n        MaxCount=max_count,\n        IamInstanceProfile={""Name"": ROLE_NAME},\n        DryRun=False,\n        NetworkInterfaces=[\n            {\n                ""SubnetId"": subnet_id,\n                ""DeviceIndex"": 0,\n                ""AssociatePublicIpAddress"": True,\n                ""Groups"": security_group_ids,\n            }\n        ],\n    )\n\n    ec2_instances[0].wait_until_running()\n    ec2_instances[0].reload()\n    fs_resources[""ec2_instance_id""] = ec2_instances[0].id\n    ec2_client = sagemaker_session.boto_session.client(""ec2"")\n    for _ in retries(30, ""Checking EC2 creation status""):\n        statuses = ec2_client.describe_instance_status(InstanceIds=[ec2_instances[0].id])\n        status = statuses[""InstanceStatuses""][0]\n        if status[""InstanceStatus""][""Status""] == ""ok"" and status[""SystemStatus""][""Status""] == ""ok"":\n            break\n    return ec2_instances[0]\n\n\ndef _check_key_pair_and_cleanup_old_artifacts(sagemaker_session):\n    ec2_client = sagemaker_session.boto_session.client(""ec2"")\n    response = ec2_client.describe_key_pairs(Filters=[{""Name"": ""key-name"", ""Values"": [KEY_NAME]}])\n    if len(response[""KeyPairs""]) > 0 and not path.exists(KEY_PATH):\n        ec2_client.delete_key_pair(KeyName=KEY_NAME)\n    if len(response[""KeyPairs""]) == 0 and path.exists(KEY_PATH):\n        os.remove(KEY_PATH)\n    return len(response[""KeyPairs""]) > 0 and path.exists(KEY_PATH)\n\n\ndef _check_or_create_key_pair(sagemaker_session):\n    if _check_key_pair_and_cleanup_old_artifacts(sagemaker_session):\n        return\n    ec2_client = sagemaker_session.boto_session.client(""ec2"")\n    key_pair = ec2_client.create_key_pair(KeyName=KEY_NAME)\n    with open(KEY_PATH, ""w"") as file:\n        file.write(key_pair[""KeyMaterial""])\n    fd = os.open(KEY_PATH, os.O_RDONLY)\n    os.fchmod(fd, stat.S_IREAD)\n\n\ndef _delete_key_pair(sagemaker_session):\n    ec2_client = sagemaker_session.boto_session.client(""ec2"")\n    ec2_client.delete_key_pair(KeyName=KEY_NAME)\n    os.remove(KEY_PATH)\n\n\ndef _terminate_instance(ec2_resource, instance_ids):\n    ec2_resource.instances.filter(InstanceIds=instance_ids).terminate()\n\n\ndef _check_or_create_iam_profile_and_attach_role(sagemaker_session):\n    if _instance_profile_exists(sagemaker_session):\n        return\n    iam_client = sagemaker_session.boto_session.client(""iam"")\n    iam_client.create_instance_profile(InstanceProfileName=ROLE_NAME)\n    iam_client.add_role_to_instance_profile(InstanceProfileName=ROLE_NAME, RoleName=ROLE_NAME)\n\n    for _ in retries(30, ""Checking EC2 instance profile creating status""):\n        profile_info = iam_client.get_instance_profile(InstanceProfileName=ROLE_NAME)\n        if profile_info[""InstanceProfile""][""Roles""][0][""RoleName""] == ROLE_NAME:\n            break\n\n\ndef _instance_profile_exists(sagemaker_session):\n    iam = sagemaker_session.boto_session.client(""iam"")\n    try:\n        iam.get_instance_profile(InstanceProfileName=ROLE_NAME)\n    except ClientError as e:\n        error_code = e.response[""Error""][""Code""]\n        message = e.response[""Error""][""Message""]\n        if error_code == ""NoSuchEntity"" and ROLE_NAME in message:\n            return False\n        else:\n            raise\n    return True\n\n\ndef tear_down(sagemaker_session, fs_resources={}):\n    try:\n        if ""file_system_fsx_id"" in fs_resources:\n            fsx_client = sagemaker_session.boto_session.client(""fsx"")\n            fsx_client.delete_file_system(FileSystemId=fs_resources[""file_system_fsx_id""])\n\n        efs_client = sagemaker_session.boto_session.client(""efs"")\n        if ""mount_efs_target_id"" in fs_resources:\n            efs_client.delete_mount_target(MountTargetId=fs_resources[""mount_efs_target_id""])\n\n        if ""file_system_efs_id"" in fs_resources:\n            for _ in retries(30, ""Checking mount target deleting status""):\n                desc = efs_client.describe_mount_targets(\n                    FileSystemId=fs_resources[""file_system_efs_id""]\n                )\n                if len(desc[""MountTargets""]) > 0:\n                    status = desc[""MountTargets""][0][""LifeCycleState""]\n                    if status == ""deleted"":\n                        break\n                else:\n                    break\n\n            efs_client.delete_file_system(FileSystemId=fs_resources[""file_system_efs_id""])\n\n        if ""ec2_instance_id"" in fs_resources:\n            ec2_resource = sagemaker_session.boto_session.resource(""ec2"")\n            _terminate_instance(ec2_resource, [fs_resources[""ec2_instance_id""]])\n\n        _delete_key_pair(sagemaker_session)\n\n    except Exception:\n        pass\n'"
tests/integ/kms_utils.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport contextlib\nimport json\n\nfrom sagemaker import utils\n\nPRINCIPAL_TEMPLATE = (\n    \'[""{account_id}"", ""{role_arn}"", \' \'""arn:{partition}:iam::{account_id}:role/{sagemaker_role}""] \'\n)\n\nKEY_ALIAS = ""SageMakerTestKMSKey""\nKMS_S3_ALIAS = ""SageMakerTestS3KMSKey""\nPOLICY_NAME = ""default""\nKEY_POLICY = """"""\n{{\n  ""Version"": ""2012-10-17"",\n  ""Id"": ""{id}"",\n  ""Statement"": [\n    {{\n      ""Sid"": ""Enable IAM User Permissions"",\n      ""Effect"": ""Allow"",\n      ""Principal"": {{\n        ""AWS"": {principal}\n      }},\n      ""Action"": ""kms:*"",\n      ""Resource"": ""*""\n    }}\n  ]\n}}\n""""""\n\n\ndef _get_kms_key_arn(kms_client, alias):\n    try:\n        response = kms_client.describe_key(KeyId=""alias/"" + alias)\n        return response[""KeyMetadata""][""Arn""]\n    except kms_client.exceptions.NotFoundException:\n        return None\n\n\ndef _get_kms_key_id(kms_client, alias):\n    try:\n        response = kms_client.describe_key(KeyId=""alias/"" + alias)\n        return response[""KeyMetadata""][""KeyId""]\n    except kms_client.exceptions.NotFoundException:\n        return None\n\n\ndef _create_kms_key(\n    kms_client, account_id, region, role_arn=None, sagemaker_role=""SageMakerRole"", alias=KEY_ALIAS\n):\n    if role_arn:\n        principal = PRINCIPAL_TEMPLATE.format(\n            partition=utils._aws_partition(region),\n            account_id=account_id,\n            role_arn=role_arn,\n            sagemaker_role=sagemaker_role,\n        )\n    else:\n        principal = \'""{account_id}""\'.format(account_id=account_id)\n\n    response = kms_client.create_key(\n        Policy=KEY_POLICY.format(\n            id=POLICY_NAME, principal=principal, sagemaker_role=sagemaker_role\n        ),\n        Description=""KMS key for SageMaker Python SDK integ tests"",\n    )\n    key_arn = response[""KeyMetadata""][""Arn""]\n\n    if alias:\n        kms_client.create_alias(AliasName=""alias/"" + alias, TargetKeyId=key_arn)\n    return key_arn\n\n\ndef _add_role_to_policy(\n    kms_client, account_id, role_arn, region, alias=KEY_ALIAS, sagemaker_role=""SageMakerRole""\n):\n    key_id = _get_kms_key_id(kms_client, alias)\n    policy = kms_client.get_key_policy(KeyId=key_id, PolicyName=POLICY_NAME)\n    policy = json.loads(policy[""Policy""])\n    principal = policy[""Statement""][0][""Principal""][""AWS""]\n\n    if role_arn not in principal or sagemaker_role not in principal:\n        principal = PRINCIPAL_TEMPLATE.format(\n            partition=utils._aws_partition(region),\n            account_id=account_id,\n            role_arn=role_arn,\n            sagemaker_role=sagemaker_role,\n        )\n\n        kms_client.put_key_policy(\n            KeyId=key_id,\n            PolicyName=POLICY_NAME,\n            Policy=KEY_POLICY.format(id=POLICY_NAME, principal=principal),\n        )\n\n\ndef get_or_create_kms_key(\n    sagemaker_session, role_arn=None, alias=KEY_ALIAS, sagemaker_role=""SageMakerRole""\n):\n    kms_client = sagemaker_session.boto_session.client(""kms"")\n    kms_key_arn = _get_kms_key_arn(kms_client, alias)\n\n    region = sagemaker_session.boto_region_name\n    sts_client = sagemaker_session.boto_session.client(\n        ""sts"", region_name=region, endpoint_url=utils.sts_regional_endpoint(region)\n    )\n    account_id = sts_client.get_caller_identity()[""Account""]\n\n    if kms_key_arn is None:\n        return _create_kms_key(kms_client, account_id, region, role_arn, sagemaker_role, alias)\n\n    if role_arn:\n        _add_role_to_policy(kms_client, account_id, role_arn, region, alias, sagemaker_role)\n\n    return kms_key_arn\n\n\nKMS_BUCKET_POLICY = """"""{{\n  ""Version"": ""2012-10-17"",\n  ""Id"": ""PutObjPolicy"",\n  ""Statement"": [\n    {{\n      ""Sid"": ""DenyIncorrectEncryptionHeader"",\n      ""Effect"": ""Deny"",\n      ""Principal"": ""*"",\n      ""Action"": ""s3:PutObject"",\n      ""Resource"": ""arn:{partition}:s3:::{bucket_name}/*"",\n      ""Condition"": {{\n        ""StringNotEquals"": {{\n          ""s3:x-amz-server-side-encryption"": ""aws:kms""\n        }}\n      }}\n    }},\n    {{\n      ""Sid"": ""DenyUnEncryptedObjectUploads"",\n      ""Effect"": ""Deny"",\n      ""Principal"": ""*"",\n      ""Action"": ""s3:PutObject"",\n      ""Resource"": ""arn:{partition}:s3:::{bucket_name}/*"",\n      ""Condition"": {{\n        ""Null"": {{\n          ""s3:x-amz-server-side-encryption"": ""true""\n        }}\n      }}\n    }}\n  ]\n}}""""""\n\n\n@contextlib.contextmanager\ndef bucket_with_encryption(sagemaker_session, sagemaker_role):\n    boto_session = sagemaker_session.boto_session\n    region = boto_session.region_name\n    sts_client = boto_session.client(\n        ""sts"", region_name=region, endpoint_url=utils.sts_regional_endpoint(region)\n    )\n\n    account = sts_client.get_caller_identity()[""Account""]\n    role_arn = sts_client.get_caller_identity()[""Arn""]\n\n    kms_client = boto_session.client(""kms"", region_name=region)\n    kms_key_arn = _create_kms_key(kms_client, account, region, role_arn, sagemaker_role, None)\n\n    region = boto_session.region_name\n    bucket_name = ""sagemaker-{}-{}-with-kms"".format(region, account)\n\n    sagemaker_session._create_s3_bucket_if_it_does_not_exist(bucket_name=bucket_name, region=region)\n\n    s3_client = boto_session.client(""s3"", region_name=region)\n    s3_client.put_bucket_encryption(\n        Bucket=bucket_name,\n        ServerSideEncryptionConfiguration={\n            ""Rules"": [\n                {\n                    ""ApplyServerSideEncryptionByDefault"": {\n                        ""SSEAlgorithm"": ""aws:kms"",\n                        ""KMSMasterKeyID"": kms_key_arn,\n                    }\n                }\n            ]\n        },\n    )\n\n    s3_client.put_bucket_policy(\n        Bucket=bucket_name,\n        Policy=KMS_BUCKET_POLICY.format(\n            partition=utils._aws_partition(region), bucket_name=bucket_name\n        ),\n    )\n\n    yield ""s3://"" + bucket_name, kms_key_arn\n\n    kms_client.schedule_key_deletion(KeyId=kms_key_arn, PendingWindowInDays=7)\n'"
tests/integ/lock.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport fcntl\nimport os\nimport time\nimport tempfile\nfrom contextlib import contextmanager\n\nDEFAULT_LOCK_PATH = os.path.join(tempfile.gettempdir(), ""sagemaker_test_lock"")\n\n\n@contextmanager\ndef lock(path=DEFAULT_LOCK_PATH):\n    """"""Create a file lock to control concurrent test execution. Certain tests or\n    test operations need to limit concurrency to work reliably. Examples include\n    local mode endpoint tests and vpc creation tests.\n    """"""\n    f = open(path, ""w"")\n    fd = f.fileno()\n\n    fcntl.lockf(fd, fcntl.LOCK_EX)\n\n    try:\n        yield\n    finally:\n        time.sleep(5)\n        fcntl.lockf(fd, fcntl.LOCK_UN)\n'"
tests/integ/marketplace_utils.py,0,"b'# Copyright 2018-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nREGION_ACCOUNT_MAP = {\n    ""us-east-1"": ""865070037744"",\n    ""us-east-2"": ""057799348421"",\n    ""us-west-2"": ""594846645681"",\n    ""eu-west-1"": ""985815980388"",\n    ""eu-central-1"": ""446921602837"",\n    ""ap-northeast-1"": ""977537786026"",\n    ""ap-northeast-2"": ""745090734665"",\n    ""ap-southeast-2"": ""666831318237"",\n    ""ap-southeast-1"": ""192199979996"",\n    ""ap-south-1"": ""077584701553"",\n    ""ca-central-1"": ""470592106596"",\n    ""eu-west-2"": ""856760150666"",\n    ""us-west-1"": ""382657785993"",\n    ""eu-west-3"": ""843114510376"",\n    ""eu-north-1"": ""136758871317"",\n    ""sa-east-1"": ""270155090741"",\n    ""ap-east-1"": ""822005858737"",\n    ""me-south-1"": ""335155493544"",\n    ""cn-north-1"": ""295401494951"",\n    ""cn-northwest-1"": ""304690803264"",\n}\n'"
tests/integ/record_set.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nfrom six.moves.urllib.parse import urlparse\n\nfrom sagemaker.amazon.amazon_estimator import RecordSet\nfrom sagemaker.utils import sagemaker_timestamp\n\n\ndef prepare_record_set_from_local_files(\n    dir_path, destination, num_records, feature_dim, sagemaker_session\n):\n    """"""Build a :class:`~RecordSet` by pointing to local files.\n\n    Args:\n        dir_path (string): Path to local directory from where the files shall be uploaded.\n        destination (string): S3 path to upload the file to.\n        num_records (int): Number of records in all the files\n        feature_dim (int): Number of features in the data set\n        sagemaker_session (sagemaker.session.Session): Session object to manage interactions with Amazon SageMaker APIs.\n    Returns:\n        RecordSet: A RecordSet specified by S3Prefix to to be used in training.\n    """"""\n    key_prefix = urlparse(destination).path\n    key_prefix = key_prefix + ""{}-{}"".format(""testfiles"", sagemaker_timestamp())\n    key_prefix = key_prefix.lstrip(""/"")\n    uploaded_location = sagemaker_session.upload_data(path=dir_path, key_prefix=key_prefix)\n    return RecordSet(uploaded_location, num_records, feature_dim, s3_data_type=""S3Prefix"")\n'"
tests/integ/retry.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport time\n\nDEFAULT_SLEEP_TIME_SECONDS = 10\n\n\ndef retries(max_retry_count, exception_message_prefix, seconds_to_sleep=DEFAULT_SLEEP_TIME_SECONDS):\n    for i in range(max_retry_count):\n        yield i\n        time.sleep(seconds_to_sleep)\n\n    raise Exception(\n        ""{} has reached the maximum retry count {}"".format(\n            exception_message_prefix, max_retry_count\n        )\n    )\n'"
tests/integ/s3_utils.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport boto3\nfrom six.moves.urllib.parse import urlparse\n\n\ndef assert_s3_files_exist(sagemaker_session, s3_url, files):\n    parsed_url = urlparse(s3_url)\n    region = sagemaker_session.boto_region_name\n    s3 = boto3.client(""s3"", region_name=region)\n    contents = s3.list_objects_v2(Bucket=parsed_url.netloc, Prefix=parsed_url.path.lstrip(""/""))[\n        ""Contents""\n    ]\n    for f in files:\n        found = [x[""Key""] for x in contents if x[""Key""].endswith(f)]\n        if not found:\n            raise ValueError(""File {} is not found under {}"".format(f, s3_url))\n'"
tests/integ/test_airflow_config.py,1,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport gzip\nimport os\nimport pickle\nimport sys\nimport pytest\nimport tests.integ\n\nimport numpy as np\n\nfrom sagemaker import (\n    KMeans,\n    FactorizationMachines,\n    IPInsights,\n    KNN,\n    LDA,\n    LinearLearner,\n    NTM,\n    PCA,\n    RandomCutForest,\n)\nfrom sagemaker.amazon.amazon_estimator import get_image_uri\nfrom sagemaker.amazon.common import read_records\nfrom sagemaker.chainer import Chainer\nfrom sagemaker.estimator import Estimator\nfrom sagemaker.mxnet import MXNet\nfrom sagemaker.pytorch.estimator import PyTorch\nfrom sagemaker.sklearn import SKLearn\nfrom sagemaker.tensorflow import TensorFlow\nfrom sagemaker.xgboost.defaults import XGBOOST_LATEST_VERSION\nfrom sagemaker.workflow import airflow as sm_airflow\nfrom sagemaker.utils import sagemaker_timestamp\n\nimport airflow\nfrom airflow import DAG\nfrom airflow.contrib.operators.sagemaker_training_operator import SageMakerTrainingOperator\nfrom airflow.contrib.operators.sagemaker_transform_operator import SageMakerTransformOperator\n\nfrom sagemaker.xgboost import XGBoost\nfrom tests.integ import DATA_DIR, PYTHON_VERSION\nfrom tests.integ.record_set import prepare_record_set_from_local_files\nfrom tests.integ.timeout import timeout\n\nfrom six.moves.urllib.parse import urlparse\n\nPYTORCH_MNIST_DIR = os.path.join(DATA_DIR, ""pytorch_mnist"")\nPYTORCH_MNIST_SCRIPT = os.path.join(PYTORCH_MNIST_DIR, ""mnist.py"")\nAIRFLOW_CONFIG_TIMEOUT_IN_SECONDS = 10\n\nRESOURCE_PATH = os.path.join(os.path.dirname(__file__), "".."", ""data"")\nTF_MNIST_RESOURCE_PATH = os.path.join(RESOURCE_PATH, ""tensorflow_mnist"")\nSCRIPT = os.path.join(TF_MNIST_RESOURCE_PATH, ""mnist.py"")\nROLE = ""SageMakerRole""\nSINGLE_INSTANCE_COUNT = 1\n\n\n@pytest.mark.canary_quick\ndef test_byo_airflow_config_uploads_data_source_to_s3_when_inputs_provided(\n    sagemaker_session, cpu_instance_type\n):\n    with timeout(seconds=AIRFLOW_CONFIG_TIMEOUT_IN_SECONDS):\n        training_data_path = os.path.join(DATA_DIR, ""dummy_tensor"")\n\n        data_source_location = ""test-airflow-config-{}"".format(sagemaker_timestamp())\n        inputs = sagemaker_session.upload_data(\n            path=training_data_path, key_prefix=os.path.join(data_source_location, ""train"")\n        )\n\n        estimator = Estimator(\n            image_name=get_image_uri(\n                sagemaker_session.boto_session.region_name, ""factorization-machines""\n            ),\n            role=ROLE,\n            train_instance_count=SINGLE_INSTANCE_COUNT,\n            train_instance_type=cpu_instance_type,\n            sagemaker_session=sagemaker_session,\n        )\n\n        training_config = _build_airflow_workflow(\n            estimator=estimator, instance_type=cpu_instance_type, inputs=inputs\n        )\n\n        _assert_that_s3_url_contains_data(\n            sagemaker_session,\n            training_config[""InputDataConfig""][0][""DataSource""][""S3DataSource""][""S3Uri""],\n        )\n\n\n@pytest.mark.canary_quick\ndef test_kmeans_airflow_config_uploads_data_source_to_s3(sagemaker_session, cpu_instance_type):\n    with timeout(seconds=AIRFLOW_CONFIG_TIMEOUT_IN_SECONDS):\n        data_path = os.path.join(DATA_DIR, ""one_p_mnist"", ""mnist.pkl.gz"")\n        pickle_args = {} if sys.version_info.major == 2 else {""encoding"": ""latin1""}\n\n        # Load the data into memory as numpy arrays\n        with gzip.open(data_path, ""rb"") as f:\n            train_set, _, _ = pickle.load(f, **pickle_args)\n\n        kmeans = KMeans(\n            role=ROLE,\n            train_instance_count=SINGLE_INSTANCE_COUNT,\n            train_instance_type=cpu_instance_type,\n            k=10,\n            sagemaker_session=sagemaker_session,\n        )\n\n        kmeans.init_method = ""random""\n        kmeans.max_iterations = 1\n        kmeans.tol = 1\n        kmeans.num_trials = 1\n        kmeans.local_init_method = ""kmeans++""\n        kmeans.half_life_time_size = 1\n        kmeans.epochs = 1\n        kmeans.center_factor = 1\n        kmeans.eval_metrics = [""ssd"", ""msd""]\n\n        records = kmeans.record_set(train_set[0][:100])\n\n        training_config = _build_airflow_workflow(\n            estimator=kmeans, instance_type=cpu_instance_type, inputs=records\n        )\n\n        _assert_that_s3_url_contains_data(\n            sagemaker_session,\n            training_config[""InputDataConfig""][0][""DataSource""][""S3DataSource""][""S3Uri""],\n        )\n\n\ndef test_fm_airflow_config_uploads_data_source_to_s3(sagemaker_session, cpu_instance_type):\n    with timeout(seconds=AIRFLOW_CONFIG_TIMEOUT_IN_SECONDS):\n        data_path = os.path.join(DATA_DIR, ""one_p_mnist"", ""mnist.pkl.gz"")\n        pickle_args = {} if sys.version_info.major == 2 else {""encoding"": ""latin1""}\n\n        # Load the data into memory as numpy arrays\n        with gzip.open(data_path, ""rb"") as f:\n            train_set, _, _ = pickle.load(f, **pickle_args)\n\n        fm = FactorizationMachines(\n            role=ROLE,\n            train_instance_count=SINGLE_INSTANCE_COUNT,\n            train_instance_type=cpu_instance_type,\n            num_factors=10,\n            predictor_type=""regressor"",\n            epochs=2,\n            clip_gradient=1e2,\n            eps=0.001,\n            rescale_grad=1.0 / 100,\n            sagemaker_session=sagemaker_session,\n        )\n\n        records = fm.record_set(train_set[0][:200], train_set[1][:200].astype(""float32""))\n\n        training_config = _build_airflow_workflow(\n            estimator=fm, instance_type=cpu_instance_type, inputs=records\n        )\n\n        _assert_that_s3_url_contains_data(\n            sagemaker_session,\n            training_config[""InputDataConfig""][0][""DataSource""][""S3DataSource""][""S3Uri""],\n        )\n\n\n@pytest.mark.canary_quick\ndef test_ipinsights_airflow_config_uploads_data_source_to_s3(sagemaker_session, cpu_instance_type):\n    with timeout(seconds=AIRFLOW_CONFIG_TIMEOUT_IN_SECONDS):\n        data_path = os.path.join(DATA_DIR, ""ipinsights"")\n        data_filename = ""train.csv""\n\n        with open(os.path.join(data_path, data_filename), ""rb"") as f:\n            num_records = len(f.readlines())\n\n        ipinsights = IPInsights(\n            role=ROLE,\n            train_instance_count=SINGLE_INSTANCE_COUNT,\n            train_instance_type=cpu_instance_type,\n            num_entity_vectors=10,\n            vector_dim=100,\n            sagemaker_session=sagemaker_session,\n        )\n\n        records = prepare_record_set_from_local_files(\n            data_path, ipinsights.data_location, num_records, None, sagemaker_session\n        )\n\n        training_config = _build_airflow_workflow(\n            estimator=ipinsights, instance_type=cpu_instance_type, inputs=records\n        )\n\n        _assert_that_s3_url_contains_data(\n            sagemaker_session,\n            training_config[""InputDataConfig""][0][""DataSource""][""S3DataSource""][""S3Uri""],\n        )\n\n\ndef test_knn_airflow_config_uploads_data_source_to_s3(sagemaker_session, cpu_instance_type):\n    with timeout(seconds=AIRFLOW_CONFIG_TIMEOUT_IN_SECONDS):\n        data_path = os.path.join(DATA_DIR, ""one_p_mnist"", ""mnist.pkl.gz"")\n        pickle_args = {} if sys.version_info.major == 2 else {""encoding"": ""latin1""}\n\n        # Load the data into memory as numpy arrays\n        with gzip.open(data_path, ""rb"") as f:\n            train_set, _, _ = pickle.load(f, **pickle_args)\n\n        knn = KNN(\n            role=ROLE,\n            train_instance_count=SINGLE_INSTANCE_COUNT,\n            train_instance_type=cpu_instance_type,\n            k=10,\n            predictor_type=""regressor"",\n            sample_size=500,\n            sagemaker_session=sagemaker_session,\n        )\n\n        records = knn.record_set(train_set[0][:200], train_set[1][:200].astype(""float32""))\n\n        training_config = _build_airflow_workflow(\n            estimator=knn, instance_type=cpu_instance_type, inputs=records\n        )\n\n        _assert_that_s3_url_contains_data(\n            sagemaker_session,\n            training_config[""InputDataConfig""][0][""DataSource""][""S3DataSource""][""S3Uri""],\n        )\n\n\n@pytest.mark.skipif(\n    tests.integ.test_region() in tests.integ.NO_LDA_REGIONS,\n    reason=""LDA image is not supported in certain regions"",\n)\n@pytest.mark.canary_quick\ndef test_lda_airflow_config_uploads_data_source_to_s3(sagemaker_session, cpu_instance_type):\n    with timeout(seconds=AIRFLOW_CONFIG_TIMEOUT_IN_SECONDS):\n        data_path = os.path.join(DATA_DIR, ""lda"")\n        data_filename = ""nips-train_1.pbr""\n\n        with open(os.path.join(data_path, data_filename), ""rb"") as f:\n            all_records = read_records(f)\n\n        # all records must be same\n        feature_num = int(all_records[0].features[""values""].float32_tensor.shape[0])\n\n        lda = LDA(\n            role=ROLE,\n            train_instance_type=cpu_instance_type,\n            num_topics=10,\n            sagemaker_session=sagemaker_session,\n        )\n\n        records = prepare_record_set_from_local_files(\n            data_path, lda.data_location, len(all_records), feature_num, sagemaker_session\n        )\n\n        training_config = _build_airflow_workflow(\n            estimator=lda, instance_type=cpu_instance_type, inputs=records, mini_batch_size=100\n        )\n\n        _assert_that_s3_url_contains_data(\n            sagemaker_session,\n            training_config[""InputDataConfig""][0][""DataSource""][""S3DataSource""][""S3Uri""],\n        )\n\n\n@pytest.mark.canary_quick\ndef test_linearlearner_airflow_config_uploads_data_source_to_s3(\n    sagemaker_session, cpu_instance_type\n):\n    with timeout(seconds=AIRFLOW_CONFIG_TIMEOUT_IN_SECONDS):\n        data_path = os.path.join(DATA_DIR, ""one_p_mnist"", ""mnist.pkl.gz"")\n        pickle_args = {} if sys.version_info.major == 2 else {""encoding"": ""latin1""}\n\n        # Load the data into memory as numpy arrays\n        with gzip.open(data_path, ""rb"") as f:\n            train_set, _, _ = pickle.load(f, **pickle_args)\n\n        train_set[1][:100] = 1\n        train_set[1][100:200] = 0\n        train_set = train_set[0], train_set[1].astype(np.dtype(""float32""))\n\n        ll = LinearLearner(\n            ROLE,\n            1,\n            cpu_instance_type,\n            predictor_type=""binary_classifier"",\n            sagemaker_session=sagemaker_session,\n        )\n        ll.binary_classifier_model_selection_criteria = ""accuracy""\n        ll.target_recall = 0.5\n        ll.target_precision = 0.5\n        ll.positive_example_weight_mult = 0.1\n        ll.epochs = 1\n        ll.use_bias = True\n        ll.num_models = 1\n        ll.num_calibration_samples = 1\n        ll.init_method = ""uniform""\n        ll.init_scale = 0.5\n        ll.init_sigma = 0.2\n        ll.init_bias = 5\n        ll.optimizer = ""adam""\n        ll.loss = ""logistic""\n        ll.wd = 0.5\n        ll.l1 = 0.5\n        ll.momentum = 0.5\n        ll.learning_rate = 0.1\n        ll.beta_1 = 0.1\n        ll.beta_2 = 0.1\n        ll.use_lr_scheduler = True\n        ll.lr_scheduler_step = 2\n        ll.lr_scheduler_factor = 0.5\n        ll.lr_scheduler_minimum_lr = 0.1\n        ll.normalize_data = False\n        ll.normalize_label = False\n        ll.unbias_data = True\n        ll.unbias_label = False\n        ll.num_point_for_scaler = 10000\n        ll.margin = 1.0\n        ll.quantile = 0.5\n        ll.loss_insensitivity = 0.1\n        ll.huber_delta = 0.1\n        ll.early_stopping_tolerance = 0.0001\n        ll.early_stopping_patience = 3\n\n        records = ll.record_set(train_set[0][:200], train_set[1][:200])\n\n        training_config = _build_airflow_workflow(\n            estimator=ll, instance_type=cpu_instance_type, inputs=records\n        )\n\n        _assert_that_s3_url_contains_data(\n            sagemaker_session,\n            training_config[""InputDataConfig""][0][""DataSource""][""S3DataSource""][""S3Uri""],\n        )\n\n\n@pytest.mark.canary_quick\ndef test_ntm_airflow_config_uploads_data_source_to_s3(sagemaker_session, cpu_instance_type):\n    with timeout(seconds=AIRFLOW_CONFIG_TIMEOUT_IN_SECONDS):\n        data_path = os.path.join(DATA_DIR, ""ntm"")\n        data_filename = ""nips-train_1.pbr""\n\n        with open(os.path.join(data_path, data_filename), ""rb"") as f:\n            all_records = read_records(f)\n\n        # all records must be same\n        feature_num = int(all_records[0].features[""values""].float32_tensor.shape[0])\n\n        ntm = NTM(\n            role=ROLE,\n            train_instance_count=SINGLE_INSTANCE_COUNT,\n            train_instance_type=cpu_instance_type,\n            num_topics=10,\n            sagemaker_session=sagemaker_session,\n        )\n\n        records = prepare_record_set_from_local_files(\n            data_path, ntm.data_location, len(all_records), feature_num, sagemaker_session\n        )\n\n        training_config = _build_airflow_workflow(\n            estimator=ntm, instance_type=cpu_instance_type, inputs=records\n        )\n\n        _assert_that_s3_url_contains_data(\n            sagemaker_session,\n            training_config[""InputDataConfig""][0][""DataSource""][""S3DataSource""][""S3Uri""],\n        )\n\n\n@pytest.mark.canary_quick\ndef test_pca_airflow_config_uploads_data_source_to_s3(sagemaker_session, cpu_instance_type):\n    with timeout(seconds=AIRFLOW_CONFIG_TIMEOUT_IN_SECONDS):\n        data_path = os.path.join(DATA_DIR, ""one_p_mnist"", ""mnist.pkl.gz"")\n        pickle_args = {} if sys.version_info.major == 2 else {""encoding"": ""latin1""}\n\n        # Load the data into memory as numpy arrays\n        with gzip.open(data_path, ""rb"") as f:\n            train_set, _, _ = pickle.load(f, **pickle_args)\n\n        pca = PCA(\n            role=ROLE,\n            train_instance_count=SINGLE_INSTANCE_COUNT,\n            train_instance_type=cpu_instance_type,\n            num_components=48,\n            sagemaker_session=sagemaker_session,\n        )\n\n        pca.algorithm_mode = ""randomized""\n        pca.subtract_mean = True\n        pca.extra_components = 5\n\n        records = pca.record_set(train_set[0][:100])\n\n        training_config = _build_airflow_workflow(\n            estimator=pca, instance_type=cpu_instance_type, inputs=records\n        )\n\n        _assert_that_s3_url_contains_data(\n            sagemaker_session,\n            training_config[""InputDataConfig""][0][""DataSource""][""S3DataSource""][""S3Uri""],\n        )\n\n\n@pytest.mark.canary_quick\ndef test_rcf_airflow_config_uploads_data_source_to_s3(sagemaker_session, cpu_instance_type):\n    with timeout(seconds=AIRFLOW_CONFIG_TIMEOUT_IN_SECONDS):\n        # Generate a thousand 14-dimensional datapoints.\n        feature_num = 14\n        train_input = np.random.rand(1000, feature_num)\n\n        rcf = RandomCutForest(\n            role=ROLE,\n            train_instance_count=SINGLE_INSTANCE_COUNT,\n            train_instance_type=cpu_instance_type,\n            num_trees=50,\n            num_samples_per_tree=20,\n            eval_metrics=[""accuracy"", ""precision_recall_fscore""],\n            sagemaker_session=sagemaker_session,\n        )\n\n        records = rcf.record_set(train_input)\n\n        training_config = _build_airflow_workflow(\n            estimator=rcf, instance_type=cpu_instance_type, inputs=records\n        )\n\n        _assert_that_s3_url_contains_data(\n            sagemaker_session,\n            training_config[""InputDataConfig""][0][""DataSource""][""S3DataSource""][""S3Uri""],\n        )\n\n\n@pytest.mark.canary_quick\ndef test_chainer_airflow_config_uploads_data_source_to_s3(\n    sagemaker_local_session, cpu_instance_type, chainer_full_version\n):\n    with timeout(seconds=AIRFLOW_CONFIG_TIMEOUT_IN_SECONDS):\n        script_path = os.path.join(DATA_DIR, ""chainer_mnist"", ""mnist.py"")\n        data_path = os.path.join(DATA_DIR, ""chainer_mnist"")\n\n        chainer = Chainer(\n            entry_point=script_path,\n            role=ROLE,\n            train_instance_count=SINGLE_INSTANCE_COUNT,\n            train_instance_type=""local"",\n            framework_version=chainer_full_version,\n            py_version=PYTHON_VERSION,\n            sagemaker_session=sagemaker_local_session,\n            hyperparameters={""epochs"": 1},\n            use_mpi=True,\n            num_processes=2,\n            process_slots_per_host=2,\n            additional_mpi_options=""-x NCCL_DEBUG=INFO"",\n        )\n\n        train_input = ""file://"" + os.path.join(data_path, ""train"")\n        test_input = ""file://"" + os.path.join(data_path, ""test"")\n\n        training_config = _build_airflow_workflow(\n            estimator=chainer,\n            instance_type=cpu_instance_type,\n            inputs={""train"": train_input, ""test"": test_input},\n        )\n\n        _assert_that_s3_url_contains_data(\n            sagemaker_local_session,\n            training_config[""HyperParameters""][""sagemaker_submit_directory""].strip(\'""\'),\n        )\n\n\n@pytest.mark.canary_quick\ndef test_mxnet_airflow_config_uploads_data_source_to_s3(\n    sagemaker_session, cpu_instance_type, mxnet_full_version\n):\n    with timeout(seconds=AIRFLOW_CONFIG_TIMEOUT_IN_SECONDS):\n        script_path = os.path.join(DATA_DIR, ""chainer_mnist"", ""mnist.py"")\n        data_path = os.path.join(DATA_DIR, ""chainer_mnist"")\n\n        mx = MXNet(\n            entry_point=script_path,\n            role=ROLE,\n            framework_version=mxnet_full_version,\n            py_version=PYTHON_VERSION,\n            train_instance_count=SINGLE_INSTANCE_COUNT,\n            train_instance_type=cpu_instance_type,\n            sagemaker_session=sagemaker_session,\n        )\n\n        train_input = ""file://"" + os.path.join(data_path, ""train"")\n        test_input = ""file://"" + os.path.join(data_path, ""test"")\n\n        training_config = _build_airflow_workflow(\n            estimator=mx,\n            instance_type=cpu_instance_type,\n            inputs={""train"": train_input, ""test"": test_input},\n        )\n\n        _assert_that_s3_url_contains_data(\n            sagemaker_session,\n            training_config[""HyperParameters""][""sagemaker_submit_directory""].strip(\'""\'),\n        )\n\n\n@pytest.mark.canary_quick\ndef test_sklearn_airflow_config_uploads_data_source_to_s3(\n    sagemaker_session, cpu_instance_type, sklearn_full_version\n):\n    with timeout(seconds=AIRFLOW_CONFIG_TIMEOUT_IN_SECONDS):\n        script_path = os.path.join(DATA_DIR, ""sklearn_mnist"", ""mnist.py"")\n        data_path = os.path.join(DATA_DIR, ""sklearn_mnist"")\n\n        sklearn = SKLearn(\n            entry_point=script_path,\n            role=ROLE,\n            train_instance_type=cpu_instance_type,\n            framework_version=sklearn_full_version,\n            py_version=PYTHON_VERSION,\n            sagemaker_session=sagemaker_session,\n            hyperparameters={""epochs"": 1},\n        )\n\n        train_input = sklearn.sagemaker_session.upload_data(\n            path=os.path.join(data_path, ""train""), key_prefix=""integ-test-data/sklearn_mnist/train""\n        )\n        test_input = sklearn.sagemaker_session.upload_data(\n            path=os.path.join(data_path, ""test""), key_prefix=""integ-test-data/sklearn_mnist/test""\n        )\n\n        training_config = _build_airflow_workflow(\n            estimator=sklearn,\n            instance_type=cpu_instance_type,\n            inputs={""train"": train_input, ""test"": test_input},\n        )\n\n        _assert_that_s3_url_contains_data(\n            sagemaker_session,\n            training_config[""HyperParameters""][""sagemaker_submit_directory""].strip(\'""\'),\n        )\n\n\n@pytest.mark.canary_quick\ndef test_tf_airflow_config_uploads_data_source_to_s3(sagemaker_session, cpu_instance_type):\n    with timeout(seconds=AIRFLOW_CONFIG_TIMEOUT_IN_SECONDS):\n        tf = TensorFlow(\n            image_name=get_image_uri(\n                sagemaker_session.boto_session.region_name, ""factorization-machines""\n            ),\n            entry_point=SCRIPT,\n            role=ROLE,\n            train_instance_count=SINGLE_INSTANCE_COUNT,\n            train_instance_type=cpu_instance_type,\n            sagemaker_session=sagemaker_session,\n            script_mode=True,\n            framework_version=TensorFlow.LATEST_VERSION,\n            py_version=PYTHON_VERSION,\n            metric_definitions=[\n                {""Name"": ""train:global_steps"", ""Regex"": r""global_step\\/sec:\\s(.*)""}\n            ],\n        )\n        inputs = tf.sagemaker_session.upload_data(\n            path=os.path.join(TF_MNIST_RESOURCE_PATH, ""data""), key_prefix=""scriptmode/mnist""\n        )\n\n        training_config = _build_airflow_workflow(\n            estimator=tf, instance_type=cpu_instance_type, inputs=inputs\n        )\n\n        _assert_that_s3_url_contains_data(\n            sagemaker_session,\n            training_config[""HyperParameters""][""sagemaker_submit_directory""].strip(\'""\'),\n        )\n\n\n@pytest.mark.canary_quick\ndef test_xgboost_airflow_config_uploads_data_source_to_s3(sagemaker_session, cpu_instance_type):\n    with timeout(seconds=AIRFLOW_CONFIG_TIMEOUT_IN_SECONDS):\n        xgboost = XGBoost(\n            entry_point=os.path.join(DATA_DIR, ""dummy_script.py""),\n            framework_version=XGBOOST_LATEST_VERSION,\n            role=ROLE,\n            sagemaker_session=sagemaker_session,\n            train_instance_type=cpu_instance_type,\n            train_instance_count=SINGLE_INSTANCE_COUNT,\n            base_job_name=""XGBoost job"",\n            py_version=PYTHON_VERSION,\n        )\n\n        training_config = _build_airflow_workflow(\n            estimator=xgboost, instance_type=cpu_instance_type\n        )\n\n        _assert_that_s3_url_contains_data(\n            sagemaker_session,\n            training_config[""HyperParameters""][""sagemaker_submit_directory""].strip(\'""\'),\n        )\n\n\n@pytest.mark.canary_quick\ndef test_pytorch_airflow_config_uploads_data_source_to_s3_when_inputs_not_provided(\n    sagemaker_session, cpu_instance_type\n):\n    with timeout(seconds=AIRFLOW_CONFIG_TIMEOUT_IN_SECONDS):\n        estimator = PyTorch(\n            entry_point=PYTORCH_MNIST_SCRIPT,\n            role=ROLE,\n            framework_version=""1.1.0"",\n            train_instance_count=2,\n            train_instance_type=cpu_instance_type,\n            hyperparameters={""epochs"": 6, ""backend"": ""gloo""},\n            sagemaker_session=sagemaker_session,\n        )\n\n        training_config = _build_airflow_workflow(\n            estimator=estimator, instance_type=cpu_instance_type\n        )\n\n        _assert_that_s3_url_contains_data(\n            sagemaker_session,\n            training_config[""HyperParameters""][""sagemaker_submit_directory""].strip(\'""\'),\n        )\n\n\ndef test_pytorch_12_airflow_config_uploads_data_source_to_s3_when_inputs_not_provided(\n    sagemaker_session, cpu_instance_type\n):\n    with timeout(seconds=AIRFLOW_CONFIG_TIMEOUT_IN_SECONDS):\n        estimator = PyTorch(\n            entry_point=PYTORCH_MNIST_SCRIPT,\n            role=ROLE,\n            framework_version=""1.2.0"",\n            train_instance_count=2,\n            train_instance_type=cpu_instance_type,\n            hyperparameters={""epochs"": 6, ""backend"": ""gloo""},\n            sagemaker_session=sagemaker_session,\n        )\n\n        training_config = _build_airflow_workflow(\n            estimator=estimator, instance_type=cpu_instance_type\n        )\n\n        _assert_that_s3_url_contains_data(\n            sagemaker_session,\n            training_config[""HyperParameters""][""sagemaker_submit_directory""].strip(\'""\'),\n        )\n\n\ndef _assert_that_s3_url_contains_data(sagemaker_session, s3_url):\n    parsed_s3_url = urlparse(s3_url)\n    s3_request = sagemaker_session.boto_session.client(""s3"").list_objects_v2(\n        Bucket=parsed_s3_url.netloc, Prefix=parsed_s3_url.path.lstrip(""/"")\n    )\n    assert s3_request[""KeyCount""] > 0\n\n\ndef _build_airflow_workflow(estimator, instance_type, inputs=None, mini_batch_size=None):\n    training_config = sm_airflow.training_config(\n        estimator=estimator, inputs=inputs, mini_batch_size=mini_batch_size\n    )\n\n    model = estimator.create_model()\n    assert model is not None\n\n    model_config = sm_airflow.model_config(instance_type, model)\n    assert model_config is not None\n\n    transform_config = sm_airflow.transform_config_from_estimator(\n        estimator=estimator,\n        task_id=""transform_config"",\n        task_type=""training"",\n        instance_count=SINGLE_INSTANCE_COUNT,\n        instance_type=estimator.train_instance_type,\n        data=inputs,\n        content_type=""text/csv"",\n        input_filter=""$"",\n        output_filter=""$"",\n    )\n\n    default_args = {\n        ""owner"": ""airflow"",\n        ""start_date"": airflow.utils.dates.days_ago(2),\n        ""provide_context"": True,\n    }\n\n    dag = DAG(""tensorflow_example"", default_args=default_args, schedule_interval=""@once"")\n\n    train_op = SageMakerTrainingOperator(\n        task_id=""tf_training"", config=training_config, wait_for_completion=True, dag=dag\n    )\n\n    transform_op = SageMakerTransformOperator(\n        task_id=""transform_operator"", config=transform_config, wait_for_completion=True, dag=dag\n    )\n\n    transform_op.set_upstream(train_op)\n\n    return training_config\n'"
tests/integ/test_auto_ml.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport os\n\nimport pytest\nimport tests.integ\nfrom sagemaker import AutoML, CandidateEstimator, AutoMLInput\n\nfrom sagemaker.exceptions import UnexpectedStatusException\nfrom sagemaker.utils import unique_name_from_base\nfrom tests.integ import DATA_DIR, AUTO_ML_DEFAULT_TIMEMOUT_MINUTES, auto_ml_utils\nfrom tests.integ.timeout import timeout\n\nROLE = ""SageMakerRole""\nPREFIX = ""sagemaker/beta-automl-xgboost""\nAUTO_ML_INSTANCE_TYPE = ""ml.m5.2xlarge""\nINSTANCE_COUNT = 1\nRESOURCE_POOLS = [{""InstanceType"": AUTO_ML_INSTANCE_TYPE, ""PoolSize"": INSTANCE_COUNT}]\nTARGET_ATTRIBUTE_NAME = ""virginica""\nDATA_DIR = os.path.join(DATA_DIR, ""automl"", ""data"")\nTRAINING_DATA = os.path.join(DATA_DIR, ""iris_training.csv"")\nTEST_DATA = os.path.join(DATA_DIR, ""iris_test.csv"")\nPROBLEM_TYPE = ""MultiClassClassification""\nBASE_JOB_NAME = ""auto-ml""\n\n# use a succeeded AutoML job to test describe and list candidates method, otherwise tests will run too long\nAUTO_ML_JOB_NAME = ""python-sdk-integ-test-base-job""\n\nEXPECTED_DEFAULT_JOB_CONFIG = {\n    ""CompletionCriteria"": {""MaxCandidates"": 3},\n    ""SecurityConfig"": {""EnableInterContainerTrafficEncryption"": False},\n}\n\n\n@pytest.mark.skipif(\n    tests.integ.test_region() in tests.integ.NO_AUTO_ML_REGIONS,\n    reason=""AutoML is not supported in the region yet."",\n)\n@pytest.mark.canary_quick\ndef test_auto_ml_fit(sagemaker_session):\n    auto_ml = AutoML(\n        role=ROLE,\n        target_attribute_name=TARGET_ATTRIBUTE_NAME,\n        sagemaker_session=sagemaker_session,\n        max_candidates=3,\n    )\n\n    job_name = unique_name_from_base(""auto-ml"", max_length=32)\n    inputs = sagemaker_session.upload_data(path=TRAINING_DATA, key_prefix=PREFIX + ""/input"")\n    with timeout(minutes=AUTO_ML_DEFAULT_TIMEMOUT_MINUTES):\n        auto_ml.fit(inputs, job_name=job_name)\n\n\n@pytest.mark.skipif(\n    tests.integ.test_region() in tests.integ.NO_AUTO_ML_REGIONS,\n    reason=""AutoML is not supported in the region yet."",\n)\ndef test_auto_ml_fit_local_input(sagemaker_session):\n    auto_ml = AutoML(\n        role=ROLE,\n        target_attribute_name=TARGET_ATTRIBUTE_NAME,\n        sagemaker_session=sagemaker_session,\n        max_candidates=1,\n    )\n\n    inputs = TRAINING_DATA\n    job_name = unique_name_from_base(""auto-ml"", max_length=32)\n    with timeout(minutes=AUTO_ML_DEFAULT_TIMEMOUT_MINUTES):\n        auto_ml.fit(inputs, job_name=job_name)\n\n\n@pytest.mark.skipif(\n    tests.integ.test_region() in tests.integ.NO_AUTO_ML_REGIONS,\n    reason=""AutoML is not supported in the region yet."",\n)\ndef test_auto_ml_input_object_fit(sagemaker_session):\n    auto_ml = AutoML(\n        role=ROLE,\n        target_attribute_name=TARGET_ATTRIBUTE_NAME,\n        sagemaker_session=sagemaker_session,\n        max_candidates=1,\n    )\n    job_name = unique_name_from_base(""auto-ml"", max_length=32)\n    s3_input = sagemaker_session.upload_data(path=TRAINING_DATA, key_prefix=PREFIX + ""/input"")\n    inputs = AutoMLInput(inputs=s3_input, target_attribute_name=TARGET_ATTRIBUTE_NAME)\n    with timeout(minutes=AUTO_ML_DEFAULT_TIMEMOUT_MINUTES):\n        auto_ml.fit(inputs, job_name=job_name)\n\n\n@pytest.mark.skipif(\n    tests.integ.test_region() in tests.integ.NO_AUTO_ML_REGIONS,\n    reason=""AutoML is not supported in the region yet."",\n)\ndef test_auto_ml_fit_optional_args(sagemaker_session):\n    output_path = ""s3://{}/{}"".format(sagemaker_session.default_bucket(), ""specified_ouput_path"")\n    problem_type = ""MulticlassClassification""\n    job_objective = {""MetricName"": ""Accuracy""}\n    auto_ml = AutoML(\n        role=ROLE,\n        target_attribute_name=TARGET_ATTRIBUTE_NAME,\n        sagemaker_session=sagemaker_session,\n        max_candidates=1,\n        output_path=output_path,\n        problem_type=problem_type,\n        job_objective=job_objective,\n    )\n    inputs = TRAINING_DATA\n    with timeout(minutes=AUTO_ML_DEFAULT_TIMEMOUT_MINUTES):\n        auto_ml.fit(inputs, job_name=unique_name_from_base(BASE_JOB_NAME))\n\n    auto_ml_desc = auto_ml.describe_auto_ml_job(job_name=auto_ml.latest_auto_ml_job.job_name)\n    assert auto_ml_desc[""AutoMLJobStatus""] == ""Completed""\n    assert auto_ml_desc[""AutoMLJobName""] == auto_ml.latest_auto_ml_job.job_name\n    assert auto_ml_desc[""AutoMLJobObjective""] == job_objective\n    assert auto_ml_desc[""ProblemType""] == problem_type\n    assert auto_ml_desc[""OutputDataConfig""][""S3OutputPath""] == output_path\n\n\n@pytest.mark.skipif(\n    tests.integ.test_region() in tests.integ.NO_AUTO_ML_REGIONS,\n    reason=""AutoML is not supported in the region yet."",\n)\ndef test_auto_ml_invalid_target_attribute(sagemaker_session):\n    auto_ml = AutoML(\n        role=ROLE, target_attribute_name=""y"", sagemaker_session=sagemaker_session, max_candidates=1\n    )\n    job_name = unique_name_from_base(""auto-ml"", max_length=32)\n    inputs = sagemaker_session.upload_data(path=TRAINING_DATA, key_prefix=PREFIX + ""/input"")\n    with pytest.raises(\n        UnexpectedStatusException, match=""Could not complete the data builder processing job.""\n    ):\n        auto_ml.fit(inputs, job_name=job_name)\n\n\n@pytest.mark.skipif(\n    tests.integ.test_region() in tests.integ.NO_AUTO_ML_REGIONS,\n    reason=""AutoML is not supported in the region yet."",\n)\ndef test_auto_ml_describe_auto_ml_job(sagemaker_session):\n    expected_default_input_config = [\n        {\n            ""DataSource"": {\n                ""S3DataSource"": {\n                    ""S3DataType"": ""S3Prefix"",\n                    ""S3Uri"": ""s3://{}/{}/input/iris_training.csv"".format(\n                        sagemaker_session.default_bucket(), PREFIX\n                    ),\n                }\n            },\n            ""TargetAttributeName"": TARGET_ATTRIBUTE_NAME,\n        }\n    ]\n    expected_default_output_config = {\n        ""S3OutputPath"": ""s3://{}/"".format(sagemaker_session.default_bucket())\n    }\n\n    auto_ml_utils.create_auto_ml_job_if_not_exist(sagemaker_session)\n    auto_ml = AutoML(\n        role=ROLE, target_attribute_name=TARGET_ATTRIBUTE_NAME, sagemaker_session=sagemaker_session\n    )\n\n    desc = auto_ml.describe_auto_ml_job(job_name=AUTO_ML_JOB_NAME)\n    assert desc[""AutoMLJobName""] == AUTO_ML_JOB_NAME\n    assert desc[""AutoMLJobStatus""] == ""Completed""\n    assert isinstance(desc[""BestCandidate""], dict)\n    assert desc[""InputDataConfig""] == expected_default_input_config\n    assert desc[""AutoMLJobConfig""] == EXPECTED_DEFAULT_JOB_CONFIG\n    assert desc[""OutputDataConfig""] == expected_default_output_config\n\n\n@pytest.mark.skipif(\n    tests.integ.test_region() in tests.integ.NO_AUTO_ML_REGIONS,\n    reason=""AutoML is not supported in the region yet."",\n)\ndef test_list_candidates(sagemaker_session):\n    auto_ml_utils.create_auto_ml_job_if_not_exist(sagemaker_session)\n\n    auto_ml = AutoML(\n        role=ROLE, target_attribute_name=TARGET_ATTRIBUTE_NAME, sagemaker_session=sagemaker_session\n    )\n\n    candidates = auto_ml.list_candidates(job_name=AUTO_ML_JOB_NAME)\n    assert len(candidates) == 3\n\n\n@pytest.mark.skipif(\n    tests.integ.test_region() in tests.integ.NO_AUTO_ML_REGIONS,\n    reason=""AutoML is not supported in the region yet."",\n)\ndef test_best_candidate(sagemaker_session):\n    auto_ml_utils.create_auto_ml_job_if_not_exist(sagemaker_session)\n\n    auto_ml = AutoML(\n        role=ROLE, target_attribute_name=TARGET_ATTRIBUTE_NAME, sagemaker_session=sagemaker_session\n    )\n    best_candidate = auto_ml.best_candidate(job_name=AUTO_ML_JOB_NAME)\n    assert len(best_candidate[""InferenceContainers""]) == 3\n    assert len(best_candidate[""CandidateSteps""]) == 4\n    assert best_candidate[""CandidateStatus""] == ""Completed""\n\n\n@pytest.mark.skipif(\n    tests.integ.test_region() in tests.integ.NO_AUTO_ML_REGIONS,\n    reason=""AutoML is not supported in the region yet."",\n)\n@pytest.mark.canary_quick\ndef test_deploy_best_candidate(sagemaker_session, cpu_instance_type):\n    auto_ml_utils.create_auto_ml_job_if_not_exist(sagemaker_session)\n\n    auto_ml = AutoML(\n        role=ROLE, target_attribute_name=TARGET_ATTRIBUTE_NAME, sagemaker_session=sagemaker_session\n    )\n    best_candidate = auto_ml.best_candidate(job_name=AUTO_ML_JOB_NAME)\n    endpoint_name = unique_name_from_base(""sagemaker-auto-ml-best-candidate-test"")\n\n    with timeout(minutes=AUTO_ML_DEFAULT_TIMEMOUT_MINUTES):\n        auto_ml.deploy(\n            candidate=best_candidate,\n            initial_instance_count=INSTANCE_COUNT,\n            instance_type=cpu_instance_type,\n            endpoint_name=endpoint_name,\n        )\n\n    endpoint_status = sagemaker_session.sagemaker_client.describe_endpoint(\n        EndpointName=endpoint_name\n    )[""EndpointStatus""]\n    assert endpoint_status == ""InService""\n    sagemaker_session.sagemaker_client.delete_endpoint(EndpointName=endpoint_name)\n\n\n@pytest.mark.skipif(\n    tests.integ.test_region() in tests.integ.NO_AUTO_ML_REGIONS,\n    reason=""AutoML is not supported in the region yet."",\n)\ndef test_candidate_estimator_default_rerun_and_deploy(sagemaker_session, cpu_instance_type):\n    auto_ml_utils.create_auto_ml_job_if_not_exist(sagemaker_session)\n\n    auto_ml = AutoML(\n        role=ROLE, target_attribute_name=TARGET_ATTRIBUTE_NAME, sagemaker_session=sagemaker_session\n    )\n\n    candidates = auto_ml.list_candidates(job_name=AUTO_ML_JOB_NAME)\n    candidate = candidates[1]\n\n    candidate_estimator = CandidateEstimator(candidate, sagemaker_session)\n    inputs = sagemaker_session.upload_data(path=TEST_DATA, key_prefix=PREFIX + ""/input"")\n    endpoint_name = unique_name_from_base(""sagemaker-auto-ml-rerun-candidate-test"")\n    with timeout(minutes=AUTO_ML_DEFAULT_TIMEMOUT_MINUTES):\n        candidate_estimator.fit(inputs)\n        auto_ml.deploy(\n            initial_instance_count=INSTANCE_COUNT,\n            instance_type=cpu_instance_type,\n            candidate=candidate,\n            endpoint_name=endpoint_name,\n        )\n\n    endpoint_status = sagemaker_session.sagemaker_client.describe_endpoint(\n        EndpointName=endpoint_name\n    )[""EndpointStatus""]\n    assert endpoint_status == ""InService""\n    sagemaker_session.sagemaker_client.delete_endpoint(EndpointName=endpoint_name)\n\n\n@pytest.mark.skipif(\n    tests.integ.test_region() in tests.integ.NO_AUTO_ML_REGIONS,\n    reason=""AutoML is not supported in the region yet."",\n)\ndef test_candidate_estimator_rerun_with_optional_args(sagemaker_session, cpu_instance_type):\n    auto_ml_utils.create_auto_ml_job_if_not_exist(sagemaker_session)\n\n    auto_ml = AutoML(\n        role=ROLE, target_attribute_name=TARGET_ATTRIBUTE_NAME, sagemaker_session=sagemaker_session\n    )\n\n    candidates = auto_ml.list_candidates(job_name=AUTO_ML_JOB_NAME)\n    candidate = candidates[1]\n\n    candidate_estimator = CandidateEstimator(candidate, sagemaker_session)\n    inputs = sagemaker_session.upload_data(path=TEST_DATA, key_prefix=PREFIX + ""/input"")\n    endpoint_name = unique_name_from_base(""sagemaker-auto-ml-rerun-candidate-test"")\n    with timeout(minutes=AUTO_ML_DEFAULT_TIMEMOUT_MINUTES):\n        candidate_estimator.fit(inputs, encrypt_inter_container_traffic=True)\n        auto_ml.deploy(\n            initial_instance_count=INSTANCE_COUNT,\n            instance_type=cpu_instance_type,\n            candidate=candidate,\n            endpoint_name=endpoint_name,\n        )\n\n    endpoint_status = sagemaker_session.sagemaker_client.describe_endpoint(\n        EndpointName=endpoint_name\n    )[""EndpointStatus""]\n    assert endpoint_status == ""InService""\n    sagemaker_session.sagemaker_client.delete_endpoint(EndpointName=endpoint_name)\n\n\n@pytest.mark.skipif(\n    tests.integ.test_region() in tests.integ.NO_AUTO_ML_REGIONS,\n    reason=""AutoML is not supported in the region yet."",\n)\ndef test_candidate_estimator_get_steps(sagemaker_session):\n    auto_ml_utils.create_auto_ml_job_if_not_exist(sagemaker_session)\n\n    auto_ml = AutoML(\n        role=ROLE, target_attribute_name=TARGET_ATTRIBUTE_NAME, sagemaker_session=sagemaker_session\n    )\n    candidates = auto_ml.list_candidates(job_name=AUTO_ML_JOB_NAME)\n    candidate = candidates[1]\n\n    candidate_estimator = CandidateEstimator(candidate, sagemaker_session)\n    steps = candidate_estimator.get_steps()\n    assert len(steps) == 3\n'"
tests/integ/test_byo_estimator.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport gzip\nimport json\nimport os\nimport pickle\nimport sys\n\nimport pytest\n\nimport sagemaker\nfrom sagemaker.amazon.amazon_estimator import get_image_uri\nfrom sagemaker.estimator import Estimator\nfrom sagemaker.utils import unique_name_from_base\nfrom tests.integ import DATA_DIR, TRAINING_DEFAULT_TIMEOUT_MINUTES\nfrom tests.integ.timeout import timeout, timeout_and_delete_endpoint_by_name\n\n\n@pytest.fixture(scope=""module"")\ndef region(sagemaker_session):\n    return sagemaker_session.boto_session.region_name\n\n\ndef fm_serializer(data):\n    js = {""instances"": []}\n    for row in data:\n        js[""instances""].append({""features"": row.tolist()})\n    return json.dumps(js)\n\n\n@pytest.mark.canary_quick\ndef test_byo_estimator(sagemaker_session, region, cpu_instance_type):\n    """"""Use Factorization Machines algorithm as an example here.\n\n    First we need to prepare data for training. We take standard data set, convert it to the\n    format that the algorithm can process and upload it to S3.\n    Then we create the Estimator and set hyperparamets as required by the algorithm.\n    Next, we can call fit() with path to the S3.\n    Later the trained model is deployed and prediction is called against the endpoint.\n    Default predictor is updated with json serializer and deserializer.\n\n    """"""\n    image_name = get_image_uri(region, ""factorization-machines"")\n    training_data_path = os.path.join(DATA_DIR, ""dummy_tensor"")\n    job_name = unique_name_from_base(""byo"")\n\n    with timeout(minutes=TRAINING_DEFAULT_TIMEOUT_MINUTES):\n        data_path = os.path.join(DATA_DIR, ""one_p_mnist"", ""mnist.pkl.gz"")\n        pickle_args = {} if sys.version_info.major == 2 else {""encoding"": ""latin1""}\n\n        with gzip.open(data_path, ""rb"") as f:\n            train_set, _, _ = pickle.load(f, **pickle_args)\n\n        prefix = ""test_byo_estimator""\n        key = ""recordio-pb-data""\n\n        s3_train_data = sagemaker_session.upload_data(\n            path=training_data_path, key_prefix=os.path.join(prefix, ""train"", key)\n        )\n\n        estimator = Estimator(\n            image_name=image_name,\n            role=""SageMakerRole"",\n            train_instance_count=1,\n            train_instance_type=cpu_instance_type,\n            sagemaker_session=sagemaker_session,\n        )\n\n        estimator.set_hyperparameters(\n            num_factors=10, feature_dim=784, mini_batch_size=100, predictor_type=""binary_classifier""\n        )\n\n        # training labels must be \'float32\'\n        estimator.fit({""train"": s3_train_data}, job_name=job_name)\n\n    with timeout_and_delete_endpoint_by_name(job_name, sagemaker_session):\n        model = estimator.create_model()\n        predictor = model.deploy(1, cpu_instance_type, endpoint_name=job_name)\n        predictor.serializer = fm_serializer\n        predictor.content_type = ""application/json""\n        predictor.deserializer = sagemaker.predictor.json_deserializer\n\n        result = predictor.predict(train_set[0][:10])\n\n        assert len(result[""predictions""]) == 10\n        for prediction in result[""predictions""]:\n            assert prediction[""score""] is not None\n\n\ndef test_async_byo_estimator(sagemaker_session, region, cpu_instance_type):\n    image_name = get_image_uri(region, ""factorization-machines"")\n    endpoint_name = unique_name_from_base(""byo"")\n    training_data_path = os.path.join(DATA_DIR, ""dummy_tensor"")\n    job_name = unique_name_from_base(""byo"")\n\n    with timeout(minutes=5):\n        data_path = os.path.join(DATA_DIR, ""one_p_mnist"", ""mnist.pkl.gz"")\n        pickle_args = {} if sys.version_info.major == 2 else {""encoding"": ""latin1""}\n\n        with gzip.open(data_path, ""rb"") as f:\n            train_set, _, _ = pickle.load(f, **pickle_args)\n\n        prefix = ""test_byo_estimator""\n        key = ""recordio-pb-data""\n\n        s3_train_data = sagemaker_session.upload_data(\n            path=training_data_path, key_prefix=os.path.join(prefix, ""train"", key)\n        )\n\n        estimator = Estimator(\n            image_name=image_name,\n            role=""SageMakerRole"",\n            train_instance_count=1,\n            train_instance_type=cpu_instance_type,\n            sagemaker_session=sagemaker_session,\n        )\n\n        estimator.set_hyperparameters(\n            num_factors=10, feature_dim=784, mini_batch_size=100, predictor_type=""binary_classifier""\n        )\n\n        # training labels must be \'float32\'\n        estimator.fit({""train"": s3_train_data}, wait=False, job_name=job_name)\n\n    with timeout_and_delete_endpoint_by_name(endpoint_name, sagemaker_session):\n        estimator = Estimator.attach(\n            training_job_name=job_name, sagemaker_session=sagemaker_session\n        )\n        model = estimator.create_model()\n        predictor = model.deploy(1, cpu_instance_type, endpoint_name=endpoint_name)\n        predictor.serializer = fm_serializer\n        predictor.content_type = ""application/json""\n        predictor.deserializer = sagemaker.predictor.json_deserializer\n\n        result = predictor.predict(train_set[0][:10])\n\n        assert len(result[""predictions""]) == 10\n        for prediction in result[""predictions""]:\n            assert prediction[""score""] is not None\n\n        assert estimator.train_image() == image_name\n'"
tests/integ/test_chainer_train.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport os\n\nimport numpy\nimport pytest\n\nfrom sagemaker.chainer.estimator import Chainer\nfrom sagemaker.chainer.model import ChainerModel\nfrom sagemaker.utils import unique_name_from_base\nfrom tests.integ import DATA_DIR, PYTHON_VERSION, TRAINING_DEFAULT_TIMEOUT_MINUTES\nfrom tests.integ.timeout import timeout, timeout_and_delete_endpoint_by_name\n\n\n@pytest.fixture(scope=""module"")\ndef chainer_local_training_job(sagemaker_local_session, chainer_full_version):\n    return _run_mnist_training_job(sagemaker_local_session, ""local"", 1, chainer_full_version)\n\n\n@pytest.mark.local_mode\ndef test_distributed_cpu_training(sagemaker_local_session, chainer_full_version):\n    _run_mnist_training_job(sagemaker_local_session, ""local"", 2, chainer_full_version)\n\n\n@pytest.mark.local_mode\ndef test_training_with_additional_hyperparameters(sagemaker_local_session, chainer_full_version):\n    script_path = os.path.join(DATA_DIR, ""chainer_mnist"", ""mnist.py"")\n    data_path = os.path.join(DATA_DIR, ""chainer_mnist"")\n\n    chainer = Chainer(\n        entry_point=script_path,\n        role=""SageMakerRole"",\n        train_instance_count=1,\n        train_instance_type=""local"",\n        framework_version=chainer_full_version,\n        py_version=PYTHON_VERSION,\n        sagemaker_session=sagemaker_local_session,\n        hyperparameters={""epochs"": 1},\n        use_mpi=True,\n        num_processes=2,\n        process_slots_per_host=2,\n        additional_mpi_options=""-x NCCL_DEBUG=INFO"",\n    )\n\n    train_input = ""file://"" + os.path.join(data_path, ""train"")\n    test_input = ""file://"" + os.path.join(data_path, ""test"")\n\n    chainer.fit({""train"": train_input, ""test"": test_input})\n\n\n@pytest.mark.canary_quick\n@pytest.mark.regional_testing\ndef test_attach_deploy(sagemaker_session, chainer_full_version, cpu_instance_type):\n    with timeout(minutes=TRAINING_DEFAULT_TIMEOUT_MINUTES):\n        script_path = os.path.join(DATA_DIR, ""chainer_mnist"", ""mnist.py"")\n        data_path = os.path.join(DATA_DIR, ""chainer_mnist"")\n\n        chainer = Chainer(\n            entry_point=script_path,\n            role=""SageMakerRole"",\n            framework_version=chainer_full_version,\n            py_version=PYTHON_VERSION,\n            train_instance_count=1,\n            train_instance_type=cpu_instance_type,\n            sagemaker_session=sagemaker_session,\n            hyperparameters={""epochs"": 1},\n        )\n\n        train_input = sagemaker_session.upload_data(\n            path=os.path.join(data_path, ""train""), key_prefix=""integ-test-data/chainer_mnist/train""\n        )\n\n        test_input = sagemaker_session.upload_data(\n            path=os.path.join(data_path, ""test""), key_prefix=""integ-test-data/chainer_mnist/test""\n        )\n\n        job_name = unique_name_from_base(""test-chainer-training"")\n        chainer.fit({""train"": train_input, ""test"": test_input}, wait=False, job_name=job_name)\n\n    endpoint_name = unique_name_from_base(""test-chainer-attach-deploy"")\n\n    with timeout_and_delete_endpoint_by_name(endpoint_name, sagemaker_session):\n        estimator = Chainer.attach(\n            chainer.latest_training_job.name, sagemaker_session=sagemaker_session\n        )\n        predictor = estimator.deploy(1, cpu_instance_type, endpoint_name=endpoint_name)\n        _predict_and_assert(predictor)\n\n\n@pytest.mark.local_mode\ndef test_deploy_model(chainer_local_training_job, sagemaker_local_session):\n    script_path = os.path.join(DATA_DIR, ""chainer_mnist"", ""mnist.py"")\n\n    model = ChainerModel(\n        chainer_local_training_job.model_data,\n        ""SageMakerRole"",\n        entry_point=script_path,\n        sagemaker_session=sagemaker_local_session,\n    )\n\n    predictor = model.deploy(1, ""local"")\n    try:\n        _predict_and_assert(predictor)\n    finally:\n        predictor.delete_endpoint()\n\n\ndef _run_mnist_training_job(\n    sagemaker_session, instance_type, instance_count, chainer_full_version, wait=True\n):\n    script_path = (\n        os.path.join(DATA_DIR, ""chainer_mnist"", ""mnist.py"")\n        if instance_type == 1\n        else os.path.join(DATA_DIR, ""chainer_mnist"", ""distributed_mnist.py"")\n    )\n\n    data_path = os.path.join(DATA_DIR, ""chainer_mnist"")\n\n    chainer = Chainer(\n        entry_point=script_path,\n        role=""SageMakerRole"",\n        framework_version=chainer_full_version,\n        py_version=PYTHON_VERSION,\n        train_instance_count=instance_count,\n        train_instance_type=instance_type,\n        sagemaker_session=sagemaker_session,\n        hyperparameters={""epochs"": 1},\n        # test output_path without trailing slash\n        output_path=""s3://{}"".format(sagemaker_session.default_bucket()),\n    )\n\n    train_input = ""file://"" + os.path.join(data_path, ""train"")\n    test_input = ""file://"" + os.path.join(data_path, ""test"")\n\n    job_name = unique_name_from_base(""test-chainer-training"")\n    chainer.fit({""train"": train_input, ""test"": test_input}, wait=wait, job_name=job_name)\n    return chainer\n\n\ndef _predict_and_assert(predictor):\n    batch_size = 100\n    data = numpy.zeros((batch_size, 784), dtype=""float32"")\n    output = predictor.predict(data)\n    assert len(output) == batch_size\n\n    data = numpy.zeros((batch_size, 1, 28, 28), dtype=""float32"")\n    output = predictor.predict(data)\n    assert len(output) == batch_size\n\n    data = numpy.zeros((batch_size, 28, 28), dtype=""float32"")\n    output = predictor.predict(data)\n    assert len(output) == batch_size\n'"
tests/integ/test_data_capture_config.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport os\n\nimport sagemaker\nimport tests.integ\nimport tests.integ.timeout\nfrom sagemaker.model_monitor import DataCaptureConfig, NetworkConfig\nfrom sagemaker.tensorflow.serving import Model\nfrom sagemaker.utils import unique_name_from_base\nfrom tests.integ.retry import retries\n\nROLE = ""SageMakerRole""\nSKLEARN_FRAMEWORK = ""scikit-learn""\n\nINSTANCE_COUNT = 1\nINSTANCE_TYPE = ""ml.m5.xlarge""\nVOLUME_SIZE_IN_GB = 20\nMAX_RUNTIME_IN_SECONDS = 2 * 60 * 60\nENVIRONMENT = {""env_key_1"": ""env_value_1""}\nTAGS = [{""Key"": ""tag_key_1"", ""Value"": ""tag_value_1""}]\nNETWORK_CONFIG = NetworkConfig(enable_network_isolation=True)\nENABLE_CLOUDWATCH_METRICS = True\n\nCUSTOM_SAMPLING_PERCENTAGE = 10\nCUSTOM_CAPTURE_OPTIONS = [""REQUEST""]\nCUSTOM_CSV_CONTENT_TYPES = [""text/csvtype1"", ""text/csvtype2""]\nCUSTOM_JSON_CONTENT_TYPES = [""application/jsontype1"", ""application/jsontype2""]\n\n\ndef test_enabling_data_capture_on_endpoint_shows_correct_data_capture_status(\n    sagemaker_session, tf_serving_version\n):\n    endpoint_name = unique_name_from_base(""sagemaker-tensorflow-serving"")\n    model_data = sagemaker_session.upload_data(\n        path=os.path.join(tests.integ.DATA_DIR, ""tensorflow-serving-test-model.tar.gz""),\n        key_prefix=""tensorflow-serving/models"",\n    )\n    with tests.integ.timeout.timeout_and_delete_endpoint_by_name(endpoint_name, sagemaker_session):\n        model = Model(\n            model_data=model_data,\n            role=ROLE,\n            framework_version=tf_serving_version,\n            sagemaker_session=sagemaker_session,\n        )\n        predictor = model.deploy(\n            initial_instance_count=INSTANCE_COUNT,\n            instance_type=INSTANCE_TYPE,\n            endpoint_name=endpoint_name,\n        )\n\n        endpoint_desc = sagemaker_session.sagemaker_client.describe_endpoint(\n            EndpointName=predictor.endpoint\n        )\n\n        endpoint_config_desc = sagemaker_session.sagemaker_client.describe_endpoint_config(\n            EndpointConfigName=endpoint_desc[""EndpointConfigName""]\n        )\n\n        assert endpoint_config_desc.get(""DataCaptureConfig"") is None\n\n        predictor.enable_data_capture()\n\n        # Wait for endpoint to finish updating\n        # Endpoint update takes ~7min. 25 retries * 60s sleeps = 25min timeout\n        for _ in retries(\n            max_retry_count=25,\n            exception_message_prefix=""Waiting for \'InService\' endpoint status"",\n            seconds_to_sleep=60,\n        ):\n            new_endpoint = sagemaker_session.sagemaker_client.describe_endpoint(\n                EndpointName=predictor.endpoint\n            )\n            if new_endpoint[""EndpointStatus""] == ""InService"":\n                break\n\n        endpoint_desc = sagemaker_session.sagemaker_client.describe_endpoint(\n            EndpointName=predictor.endpoint\n        )\n\n        endpoint_config_desc = sagemaker_session.sagemaker_client.describe_endpoint_config(\n            EndpointConfigName=endpoint_desc[""EndpointConfigName""]\n        )\n\n        assert endpoint_config_desc[""DataCaptureConfig""][""EnableCapture""]\n\n\ndef test_disabling_data_capture_on_endpoint_shows_correct_data_capture_status(\n    sagemaker_session, tf_serving_version\n):\n    endpoint_name = unique_name_from_base(""sagemaker-tensorflow-serving"")\n    model_data = sagemaker_session.upload_data(\n        path=os.path.join(tests.integ.DATA_DIR, ""tensorflow-serving-test-model.tar.gz""),\n        key_prefix=""tensorflow-serving/models"",\n    )\n    with tests.integ.timeout.timeout_and_delete_endpoint_by_name(endpoint_name, sagemaker_session):\n        model = Model(\n            model_data=model_data,\n            role=ROLE,\n            framework_version=tf_serving_version,\n            sagemaker_session=sagemaker_session,\n        )\n        destination_s3_uri = os.path.join(\n            ""s3://"", sagemaker_session.default_bucket(), endpoint_name, ""custom""\n        )\n        predictor = model.deploy(\n            initial_instance_count=INSTANCE_COUNT,\n            instance_type=INSTANCE_TYPE,\n            endpoint_name=endpoint_name,\n            data_capture_config=DataCaptureConfig(\n                enable_capture=True,\n                sampling_percentage=CUSTOM_SAMPLING_PERCENTAGE,\n                destination_s3_uri=destination_s3_uri,\n                capture_options=CUSTOM_CAPTURE_OPTIONS,\n                csv_content_types=CUSTOM_CSV_CONTENT_TYPES,\n                json_content_types=CUSTOM_JSON_CONTENT_TYPES,\n                sagemaker_session=sagemaker_session,\n            ),\n        )\n\n        endpoint_desc = sagemaker_session.sagemaker_client.describe_endpoint(\n            EndpointName=predictor.endpoint\n        )\n\n        endpoint_config_desc = sagemaker_session.sagemaker_client.describe_endpoint_config(\n            EndpointConfigName=endpoint_desc[""EndpointConfigName""]\n        )\n\n        assert endpoint_config_desc[""DataCaptureConfig""][""EnableCapture""]\n        assert (\n            endpoint_config_desc[""DataCaptureConfig""][""InitialSamplingPercentage""]\n            == CUSTOM_SAMPLING_PERCENTAGE\n        )\n        assert endpoint_config_desc[""DataCaptureConfig""][""CaptureOptions""] == [\n            {""CaptureMode"": ""Input""}\n        ]\n        assert (\n            endpoint_config_desc[""DataCaptureConfig""][""CaptureContentTypeHeader""][""CsvContentTypes""]\n            == CUSTOM_CSV_CONTENT_TYPES\n        )\n        assert (\n            endpoint_config_desc[""DataCaptureConfig""][""CaptureContentTypeHeader""][\n                ""JsonContentTypes""\n            ]\n            == CUSTOM_JSON_CONTENT_TYPES\n        )\n\n        predictor.disable_data_capture()\n\n        # Wait for endpoint to finish updating\n        # Endpoint update takes ~7min. 25 retries * 60s sleeps = 25min timeout\n        for _ in retries(\n            max_retry_count=25,\n            exception_message_prefix=""Waiting for \'InService\' endpoint status"",\n            seconds_to_sleep=60,\n        ):\n            new_endpoint = sagemaker_session.sagemaker_client.describe_endpoint(\n                EndpointName=predictor.endpoint\n            )\n            if new_endpoint[""EndpointStatus""] == ""InService"":\n                break\n\n        endpoint_desc = sagemaker_session.sagemaker_client.describe_endpoint(\n            EndpointName=predictor.endpoint\n        )\n\n        endpoint_config_desc = sagemaker_session.sagemaker_client.describe_endpoint_config(\n            EndpointConfigName=endpoint_desc[""EndpointConfigName""]\n        )\n\n        assert not endpoint_config_desc[""DataCaptureConfig""][""EnableCapture""]\n\n\ndef test_updating_data_capture_on_endpoint_shows_correct_data_capture_status(\n    sagemaker_session, tf_serving_version\n):\n    endpoint_name = sagemaker.utils.unique_name_from_base(""sagemaker-tensorflow-serving"")\n    model_data = sagemaker_session.upload_data(\n        path=os.path.join(tests.integ.DATA_DIR, ""tensorflow-serving-test-model.tar.gz""),\n        key_prefix=""tensorflow-serving/models"",\n    )\n    with tests.integ.timeout.timeout_and_delete_endpoint_by_name(endpoint_name, sagemaker_session):\n        model = Model(\n            model_data=model_data,\n            role=ROLE,\n            framework_version=tf_serving_version,\n            sagemaker_session=sagemaker_session,\n        )\n        destination_s3_uri = os.path.join(\n            ""s3://"", sagemaker_session.default_bucket(), endpoint_name, ""custom""\n        )\n        predictor = model.deploy(\n            initial_instance_count=INSTANCE_COUNT,\n            instance_type=INSTANCE_TYPE,\n            endpoint_name=endpoint_name,\n        )\n\n        endpoint_desc = sagemaker_session.sagemaker_client.describe_endpoint(\n            EndpointName=predictor.endpoint\n        )\n\n        endpoint_config_desc = sagemaker_session.sagemaker_client.describe_endpoint_config(\n            EndpointConfigName=endpoint_desc[""EndpointConfigName""]\n        )\n\n        assert endpoint_config_desc.get(""DataCaptureConfig"") is None\n\n        predictor.update_data_capture_config(\n            data_capture_config=DataCaptureConfig(\n                enable_capture=True,\n                sampling_percentage=CUSTOM_SAMPLING_PERCENTAGE,\n                destination_s3_uri=destination_s3_uri,\n                capture_options=CUSTOM_CAPTURE_OPTIONS,\n                csv_content_types=CUSTOM_CSV_CONTENT_TYPES,\n                json_content_types=CUSTOM_JSON_CONTENT_TYPES,\n                sagemaker_session=sagemaker_session,\n            )\n        )\n\n        # Wait for endpoint to finish updating\n        # Endpoint update takes ~7min. 25 retries * 60s sleeps = 25min timeout\n        for _ in retries(\n            max_retry_count=25,\n            exception_message_prefix=""Waiting for \'InService\' endpoint status"",\n            seconds_to_sleep=60,\n        ):\n            new_endpoint = sagemaker_session.sagemaker_client.describe_endpoint(\n                EndpointName=predictor.endpoint\n            )\n            if new_endpoint[""EndpointStatus""] == ""InService"":\n                break\n\n        endpoint_desc = sagemaker_session.sagemaker_client.describe_endpoint(\n            EndpointName=predictor.endpoint\n        )\n\n        endpoint_config_desc = sagemaker_session.sagemaker_client.describe_endpoint_config(\n            EndpointConfigName=endpoint_desc[""EndpointConfigName""]\n        )\n\n        assert endpoint_config_desc[""DataCaptureConfig""][""EnableCapture""]\n        assert (\n            endpoint_config_desc[""DataCaptureConfig""][""InitialSamplingPercentage""]\n            == CUSTOM_SAMPLING_PERCENTAGE\n        )\n        assert endpoint_config_desc[""DataCaptureConfig""][""CaptureOptions""] == [\n            {""CaptureMode"": ""Input""}\n        ]\n        assert (\n            endpoint_config_desc[""DataCaptureConfig""][""CaptureContentTypeHeader""][""CsvContentTypes""]\n            == CUSTOM_CSV_CONTENT_TYPES\n        )\n        assert (\n            endpoint_config_desc[""DataCaptureConfig""][""CaptureContentTypeHeader""][\n                ""JsonContentTypes""\n            ]\n            == CUSTOM_JSON_CONTENT_TYPES\n        )\n'"
tests/integ/test_data_upload.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport os\n\nfrom six.moves.urllib.parse import urlparse\n\nfrom tests.integ import DATA_DIR\n\nAES_ENCRYPTION_ENABLED = {""ServerSideEncryption"": ""AES256""}\n\n\ndef test_upload_data_absolute_file(sagemaker_session):\n    """"""Test the method ``Session.upload_data`` can upload one encrypted file to S3 bucket""""""\n    data_path = os.path.join(DATA_DIR, ""upload_data_tests"", ""file1.py"")\n    uploaded_file = sagemaker_session.upload_data(data_path, extra_args=AES_ENCRYPTION_ENABLED)\n    parsed_url = urlparse(uploaded_file)\n    s3_client = sagemaker_session.boto_session.client(""s3"")\n    head = s3_client.head_object(Bucket=parsed_url.netloc, Key=parsed_url.path.lstrip(""/""))\n    assert head[""ServerSideEncryption""] == ""AES256""\n\n\ndef test_upload_data_absolute_dir(sagemaker_session):\n    """"""Test the method ``Session.upload_data`` can upload encrypted objects to S3 bucket""""""\n    data_path = os.path.join(DATA_DIR, ""upload_data_tests"", ""nested_dir"")\n    uploaded_dir = sagemaker_session.upload_data(data_path, extra_args=AES_ENCRYPTION_ENABLED)\n    parsed_url = urlparse(uploaded_dir)\n    s3_bucket = parsed_url.netloc\n    s3_prefix = parsed_url.path.lstrip(""/"")\n    s3_client = sagemaker_session.boto_session.client(""s3"")\n    for file in os.listdir(data_path):\n        s3_key = ""{}/{}"".format(s3_prefix, file)\n        head = s3_client.head_object(Bucket=s3_bucket, Key=s3_key)\n        assert head[""ServerSideEncryption""] == ""AES256""\n'"
tests/integ/test_debugger.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport os\nimport uuid\n\nimport pytest\n\nfrom sagemaker.debugger import Rule\nfrom sagemaker.debugger import DebuggerHookConfig\nfrom sagemaker.debugger import TensorBoardOutputConfig\n\nfrom sagemaker.debugger import rule_configs\nfrom sagemaker.mxnet.estimator import MXNet\nfrom tests.integ import DATA_DIR, PYTHON_VERSION, TRAINING_DEFAULT_TIMEOUT_MINUTES\nfrom tests.integ.retry import retries\nfrom tests.integ.timeout import timeout\n\n\n_NON_ERROR_TERMINAL_RULE_JOB_STATUSES = [""NoIssuesFound"", ""IssuesFound"", ""Stopped""]\n\nCUSTOM_RULE_REPO_WITH_PLACEHOLDERS = (\n    ""{}.dkr.ecr.{}.amazonaws.com/sagemaker-debugger-rule-evaluator:latest""\n)\n\nCUSTOM_RULE_CONTAINERS_ACCOUNTS_MAP = {\n    ""ap-east-1"": ""645844755771"",\n    ""ap-northeast-1"": ""670969264625"",\n    ""ap-northeast-2"": ""326368420253"",\n    ""ap-south-1"": ""552407032007"",\n    ""ap-southeast-1"": ""631532610101"",\n    ""ap-southeast-2"": ""445670767460"",\n    ""ca-central-1"": ""105842248657"",\n    ""eu-central-1"": ""691764027602"",\n    ""eu-north-1"": ""091235270104"",\n    ""eu-west-1"": ""606966180310"",\n    ""eu-west-2"": ""074613877050"",\n    ""eu-west-3"": ""224335253976"",\n    ""me-south-1"": ""050406412588"",\n    ""sa-east-1"": ""466516958431"",\n    ""us-east-1"": ""864354269164"",\n    ""us-east-2"": ""840043622174"",\n    ""us-west-1"": ""952348334681"",\n    ""us-west-2"": ""759209512951"",\n    ""cn-north-1"": ""617202126805"",\n    ""cn-northwest-1"": ""658559488188"",\n}\n\n# TODO-reinvent-2019: test get_debugger_artifacts_path and get_tensorboard_artifacts_path\n\n\ndef test_mxnet_with_rules(sagemaker_session, mxnet_full_version, cpu_instance_type):\n    with timeout(minutes=TRAINING_DEFAULT_TIMEOUT_MINUTES):\n        rules = [\n            Rule.sagemaker(rule_configs.vanishing_gradient()),\n            Rule.sagemaker(\n                base_config=rule_configs.all_zero(), rule_parameters={""tensor_regex"": "".*""}\n            ),\n            Rule.sagemaker(rule_configs.loss_not_decreasing()),\n        ]\n\n        script_path = os.path.join(DATA_DIR, ""mxnet_mnist"", ""mnist_gluon.py"")\n        data_path = os.path.join(DATA_DIR, ""mxnet_mnist"")\n\n        mx = MXNet(\n            entry_point=script_path,\n            role=""SageMakerRole"",\n            framework_version=mxnet_full_version,\n            py_version=PYTHON_VERSION,\n            train_instance_count=1,\n            train_instance_type=cpu_instance_type,\n            sagemaker_session=sagemaker_session,\n            rules=rules,\n        )\n\n        train_input = mx.sagemaker_session.upload_data(\n            path=os.path.join(data_path, ""train""), key_prefix=""integ-test-data/mxnet_mnist/train""\n        )\n        test_input = mx.sagemaker_session.upload_data(\n            path=os.path.join(data_path, ""test""), key_prefix=""integ-test-data/mxnet_mnist/test""\n        )\n\n        mx.fit({""train"": train_input, ""test"": test_input})\n\n        job_description = mx.latest_training_job.describe()\n\n        for index, rule in enumerate(rules):\n            assert (\n                job_description[""DebugRuleConfigurations""][index][""RuleConfigurationName""]\n                == rule.name\n            )\n            assert (\n                job_description[""DebugRuleConfigurations""][index][""RuleEvaluatorImage""]\n                == rule.image_uri\n            )\n            assert job_description[""DebugRuleConfigurations""][index][""VolumeSizeInGB""] == 0\n            assert (\n                job_description[""DebugRuleConfigurations""][index][""RuleParameters""][\n                    ""rule_to_invoke""\n                ]\n                == rule.rule_parameters[""rule_to_invoke""]\n            )\n        assert (\n            job_description[""DebugRuleEvaluationStatuses""]\n            == mx.latest_training_job.rule_job_summary()\n        )\n\n        _wait_and_assert_that_no_rule_jobs_errored(training_job=mx.latest_training_job)\n\n\ndef test_mxnet_with_custom_rule(sagemaker_session, mxnet_full_version, cpu_instance_type):\n    with timeout(minutes=TRAINING_DEFAULT_TIMEOUT_MINUTES):\n        rules = [_get_custom_rule(sagemaker_session)]\n\n        script_path = os.path.join(DATA_DIR, ""mxnet_mnist"", ""mnist_gluon.py"")\n        data_path = os.path.join(DATA_DIR, ""mxnet_mnist"")\n\n        mx = MXNet(\n            entry_point=script_path,\n            role=""SageMakerRole"",\n            framework_version=mxnet_full_version,\n            py_version=PYTHON_VERSION,\n            train_instance_count=1,\n            train_instance_type=cpu_instance_type,\n            sagemaker_session=sagemaker_session,\n            rules=rules,\n        )\n\n        train_input = mx.sagemaker_session.upload_data(\n            path=os.path.join(data_path, ""train""), key_prefix=""integ-test-data/mxnet_mnist/train""\n        )\n        test_input = mx.sagemaker_session.upload_data(\n            path=os.path.join(data_path, ""test""), key_prefix=""integ-test-data/mxnet_mnist/test""\n        )\n\n        mx.fit({""train"": train_input, ""test"": test_input})\n\n        job_description = mx.latest_training_job.describe()\n\n        for index, rule in enumerate(rules):\n            assert (\n                job_description[""DebugRuleConfigurations""][index][""RuleConfigurationName""]\n                == rule.name\n            )\n            assert (\n                job_description[""DebugRuleConfigurations""][index][""RuleEvaluatorImage""]\n                == rule.image_uri\n            )\n            assert job_description[""DebugRuleConfigurations""][index][""VolumeSizeInGB""] == 30\n        assert (\n            job_description[""DebugRuleEvaluationStatuses""]\n            == mx.latest_training_job.rule_job_summary()\n        )\n\n        _wait_and_assert_that_no_rule_jobs_errored(training_job=mx.latest_training_job)\n\n\ndef test_mxnet_with_debugger_hook_config(sagemaker_session, mxnet_full_version, cpu_instance_type):\n    with timeout(minutes=TRAINING_DEFAULT_TIMEOUT_MINUTES):\n        debugger_hook_config = DebuggerHookConfig(\n            s3_output_path=os.path.join(\n                ""s3://"", sagemaker_session.default_bucket(), str(uuid.uuid4()), ""tensors""\n            )\n        )\n\n        script_path = os.path.join(DATA_DIR, ""mxnet_mnist"", ""mnist_gluon.py"")\n        data_path = os.path.join(DATA_DIR, ""mxnet_mnist"")\n\n        mx = MXNet(\n            entry_point=script_path,\n            role=""SageMakerRole"",\n            framework_version=mxnet_full_version,\n            py_version=PYTHON_VERSION,\n            train_instance_count=1,\n            train_instance_type=cpu_instance_type,\n            sagemaker_session=sagemaker_session,\n            debugger_hook_config=debugger_hook_config,\n        )\n\n        train_input = mx.sagemaker_session.upload_data(\n            path=os.path.join(data_path, ""train""), key_prefix=""integ-test-data/mxnet_mnist/train""\n        )\n        test_input = mx.sagemaker_session.upload_data(\n            path=os.path.join(data_path, ""test""), key_prefix=""integ-test-data/mxnet_mnist/test""\n        )\n\n        mx.fit({""train"": train_input, ""test"": test_input})\n\n        job_description = mx.latest_training_job.describe()\n        assert job_description[""DebugHookConfig""] == debugger_hook_config._to_request_dict()\n\n        _wait_and_assert_that_no_rule_jobs_errored(training_job=mx.latest_training_job)\n\n\ndef test_mxnet_with_rules_and_debugger_hook_config(\n    sagemaker_session, mxnet_full_version, cpu_instance_type\n):\n    with timeout(minutes=TRAINING_DEFAULT_TIMEOUT_MINUTES):\n        rules = [\n            Rule.sagemaker(rule_configs.vanishing_gradient()),\n            Rule.sagemaker(\n                base_config=rule_configs.all_zero(), rule_parameters={""tensor_regex"": "".*""}\n            ),\n            Rule.sagemaker(rule_configs.loss_not_decreasing()),\n        ]\n        debugger_hook_config = DebuggerHookConfig(\n            s3_output_path=os.path.join(\n                ""s3://"", sagemaker_session.default_bucket(), str(uuid.uuid4()), ""tensors""\n            )\n        )\n\n        script_path = os.path.join(DATA_DIR, ""mxnet_mnist"", ""mnist_gluon.py"")\n        data_path = os.path.join(DATA_DIR, ""mxnet_mnist"")\n\n        mx = MXNet(\n            entry_point=script_path,\n            role=""SageMakerRole"",\n            framework_version=mxnet_full_version,\n            py_version=PYTHON_VERSION,\n            train_instance_count=1,\n            train_instance_type=cpu_instance_type,\n            sagemaker_session=sagemaker_session,\n            rules=rules,\n            debugger_hook_config=debugger_hook_config,\n        )\n\n        train_input = mx.sagemaker_session.upload_data(\n            path=os.path.join(data_path, ""train""), key_prefix=""integ-test-data/mxnet_mnist/train""\n        )\n        test_input = mx.sagemaker_session.upload_data(\n            path=os.path.join(data_path, ""test""), key_prefix=""integ-test-data/mxnet_mnist/test""\n        )\n\n        mx.fit({""train"": train_input, ""test"": test_input})\n\n        job_description = mx.latest_training_job.describe()\n\n        for index, rule in enumerate(rules):\n            assert (\n                job_description[""DebugRuleConfigurations""][index][""RuleConfigurationName""]\n                == rule.name\n            )\n            assert (\n                job_description[""DebugRuleConfigurations""][index][""RuleEvaluatorImage""]\n                == rule.image_uri\n            )\n            assert job_description[""DebugRuleConfigurations""][index][""VolumeSizeInGB""] == 0\n            assert (\n                job_description[""DebugRuleConfigurations""][index][""RuleParameters""][\n                    ""rule_to_invoke""\n                ]\n                == rule.rule_parameters[""rule_to_invoke""]\n            )\n        assert job_description[""DebugHookConfig""] == debugger_hook_config._to_request_dict()\n        assert (\n            job_description[""DebugRuleEvaluationStatuses""]\n            == mx.latest_training_job.rule_job_summary()\n        )\n\n        _wait_and_assert_that_no_rule_jobs_errored(training_job=mx.latest_training_job)\n\n\ndef test_mxnet_with_custom_rule_and_debugger_hook_config(\n    sagemaker_session, mxnet_full_version, cpu_instance_type\n):\n    with timeout(minutes=TRAINING_DEFAULT_TIMEOUT_MINUTES):\n        rules = [_get_custom_rule(sagemaker_session)]\n        debugger_hook_config = DebuggerHookConfig(\n            s3_output_path=os.path.join(\n                ""s3://"", sagemaker_session.default_bucket(), str(uuid.uuid4()), ""tensors""\n            )\n        )\n\n        script_path = os.path.join(DATA_DIR, ""mxnet_mnist"", ""mnist_gluon.py"")\n        data_path = os.path.join(DATA_DIR, ""mxnet_mnist"")\n\n        mx = MXNet(\n            entry_point=script_path,\n            role=""SageMakerRole"",\n            framework_version=mxnet_full_version,\n            py_version=PYTHON_VERSION,\n            train_instance_count=1,\n            train_instance_type=cpu_instance_type,\n            sagemaker_session=sagemaker_session,\n            rules=rules,\n            debugger_hook_config=debugger_hook_config,\n        )\n\n        train_input = mx.sagemaker_session.upload_data(\n            path=os.path.join(data_path, ""train""), key_prefix=""integ-test-data/mxnet_mnist/train""\n        )\n        test_input = mx.sagemaker_session.upload_data(\n            path=os.path.join(data_path, ""test""), key_prefix=""integ-test-data/mxnet_mnist/test""\n        )\n\n        mx.fit({""train"": train_input, ""test"": test_input})\n\n        job_description = mx.latest_training_job.describe()\n\n        for index, rule in enumerate(rules):\n            assert (\n                job_description[""DebugRuleConfigurations""][index][""RuleConfigurationName""]\n                == rule.name\n            )\n            assert (\n                job_description[""DebugRuleConfigurations""][index][""RuleEvaluatorImage""]\n                == rule.image_uri\n            )\n            assert job_description[""DebugRuleConfigurations""][index][""VolumeSizeInGB""] == 30\n        assert job_description[""DebugHookConfig""] == debugger_hook_config._to_request_dict()\n        assert (\n            job_description[""DebugRuleEvaluationStatuses""]\n            == mx.latest_training_job.rule_job_summary()\n        )\n\n        _wait_and_assert_that_no_rule_jobs_errored(training_job=mx.latest_training_job)\n\n\ndef test_mxnet_with_tensorboard_output_config(\n    sagemaker_session, mxnet_full_version, cpu_instance_type\n):\n    with timeout(minutes=TRAINING_DEFAULT_TIMEOUT_MINUTES):\n        tensorboard_output_config = TensorBoardOutputConfig(\n            s3_output_path=os.path.join(\n                ""s3://"", sagemaker_session.default_bucket(), str(uuid.uuid4()), ""tensorboard""\n            )\n        )\n\n        script_path = os.path.join(DATA_DIR, ""mxnet_mnist"", ""mnist_gluon.py"")\n        data_path = os.path.join(DATA_DIR, ""mxnet_mnist"")\n\n        mx = MXNet(\n            entry_point=script_path,\n            role=""SageMakerRole"",\n            framework_version=mxnet_full_version,\n            py_version=PYTHON_VERSION,\n            train_instance_count=1,\n            train_instance_type=cpu_instance_type,\n            sagemaker_session=sagemaker_session,\n            tensorboard_output_config=tensorboard_output_config,\n        )\n\n        train_input = mx.sagemaker_session.upload_data(\n            path=os.path.join(data_path, ""train""), key_prefix=""integ-test-data/mxnet_mnist/train""\n        )\n        test_input = mx.sagemaker_session.upload_data(\n            path=os.path.join(data_path, ""test""), key_prefix=""integ-test-data/mxnet_mnist/test""\n        )\n\n        mx.fit({""train"": train_input, ""test"": test_input})\n\n        job_description = mx.latest_training_job.describe()\n        assert (\n            job_description[""TensorBoardOutputConfig""]\n            == tensorboard_output_config._to_request_dict()\n        )\n\n        _wait_and_assert_that_no_rule_jobs_errored(training_job=mx.latest_training_job)\n\n\n@pytest.mark.canary_quick\ndef test_mxnet_with_all_rules_and_configs(sagemaker_session, mxnet_full_version, cpu_instance_type):\n    with timeout(minutes=TRAINING_DEFAULT_TIMEOUT_MINUTES):\n        rules = [\n            Rule.sagemaker(rule_configs.vanishing_gradient()),\n            Rule.sagemaker(\n                base_config=rule_configs.all_zero(), rule_parameters={""tensor_regex"": "".*""}\n            ),\n            Rule.sagemaker(rule_configs.loss_not_decreasing()),\n            _get_custom_rule(sagemaker_session),\n        ]\n        debugger_hook_config = DebuggerHookConfig(\n            s3_output_path=os.path.join(\n                ""s3://"", sagemaker_session.default_bucket(), str(uuid.uuid4()), ""tensors""\n            )\n        )\n        tensorboard_output_config = TensorBoardOutputConfig(\n            s3_output_path=os.path.join(\n                ""s3://"", sagemaker_session.default_bucket(), str(uuid.uuid4()), ""tensorboard""\n            )\n        )\n\n        script_path = os.path.join(DATA_DIR, ""mxnet_mnist"", ""mnist_gluon.py"")\n        data_path = os.path.join(DATA_DIR, ""mxnet_mnist"")\n\n        mx = MXNet(\n            entry_point=script_path,\n            role=""SageMakerRole"",\n            framework_version=mxnet_full_version,\n            py_version=PYTHON_VERSION,\n            train_instance_count=1,\n            train_instance_type=cpu_instance_type,\n            sagemaker_session=sagemaker_session,\n            rules=rules,\n            debugger_hook_config=debugger_hook_config,\n            tensorboard_output_config=tensorboard_output_config,\n        )\n\n        train_input = mx.sagemaker_session.upload_data(\n            path=os.path.join(data_path, ""train""), key_prefix=""integ-test-data/mxnet_mnist/train""\n        )\n        test_input = mx.sagemaker_session.upload_data(\n            path=os.path.join(data_path, ""test""), key_prefix=""integ-test-data/mxnet_mnist/test""\n        )\n\n        mx.fit({""train"": train_input, ""test"": test_input})\n\n        job_description = mx.latest_training_job.describe()\n\n        for index, rule in enumerate(rules):\n            assert (\n                job_description[""DebugRuleConfigurations""][index][""RuleConfigurationName""]\n                == rule.name\n            )\n            assert (\n                job_description[""DebugRuleConfigurations""][index][""RuleEvaluatorImage""]\n                == rule.image_uri\n            )\n        assert job_description[""DebugHookConfig""] == debugger_hook_config._to_request_dict()\n        assert (\n            job_description[""TensorBoardOutputConfig""]\n            == tensorboard_output_config._to_request_dict()\n        )\n        assert (\n            job_description[""DebugRuleEvaluationStatuses""]\n            == mx.latest_training_job.rule_job_summary()\n        )\n\n        _wait_and_assert_that_no_rule_jobs_errored(training_job=mx.latest_training_job)\n\n\ndef test_mxnet_with_debugger_hook_config_disabled(\n    sagemaker_session, mxnet_full_version, cpu_instance_type\n):\n    with timeout(minutes=TRAINING_DEFAULT_TIMEOUT_MINUTES):\n        script_path = os.path.join(DATA_DIR, ""mxnet_mnist"", ""mnist_gluon.py"")\n        data_path = os.path.join(DATA_DIR, ""mxnet_mnist"")\n\n        mx = MXNet(\n            entry_point=script_path,\n            role=""SageMakerRole"",\n            framework_version=mxnet_full_version,\n            py_version=PYTHON_VERSION,\n            train_instance_count=1,\n            train_instance_type=cpu_instance_type,\n            sagemaker_session=sagemaker_session,\n            debugger_hook_config=False,\n        )\n\n        train_input = mx.sagemaker_session.upload_data(\n            path=os.path.join(data_path, ""train""), key_prefix=""integ-test-data/mxnet_mnist/train""\n        )\n        test_input = mx.sagemaker_session.upload_data(\n            path=os.path.join(data_path, ""test""), key_prefix=""integ-test-data/mxnet_mnist/test""\n        )\n\n        mx.fit({""train"": train_input, ""test"": test_input})\n\n        job_description = mx.latest_training_job.describe()\n\n        assert job_description.get(""DebugHookConfig"") is None\n\n\ndef _get_custom_rule(session):\n    script_path = os.path.join(DATA_DIR, ""mxnet_mnist"", ""my_custom_rule.py"")\n\n    return Rule.custom(\n        name=""test-custom-rule"",\n        source=script_path,\n        rule_to_invoke=""CustomGradientRule"",\n        instance_type=""ml.m5.xlarge"",\n        volume_size_in_gb=30,\n        image_uri=CUSTOM_RULE_REPO_WITH_PLACEHOLDERS.format(\n            CUSTOM_RULE_CONTAINERS_ACCOUNTS_MAP[session.boto_region_name], session.boto_region_name\n        ),\n    )\n\n\ndef _wait_and_assert_that_no_rule_jobs_errored(training_job):\n    # Wait for all rule jobs to complete.\n    # Training job completion takes takes ~5min after training job ends\n    # 120 retries * 10s sleeps = 20min timeout\n    for _ in retries(\n        max_retry_count=120,\n        exception_message_prefix=""Waiting for all jobs to be in success status or any to be in error"",\n        seconds_to_sleep=10,\n    ):\n        job_description = training_job.describe()\n        debug_rule_evaluation_statuses = job_description.get(""DebugRuleEvaluationStatuses"")\n        if not debug_rule_evaluation_statuses:\n            break\n        incomplete_rule_job_found = False\n        for debug_rule_evaluation_status in debug_rule_evaluation_statuses:\n            assert debug_rule_evaluation_status[""RuleEvaluationStatus""] != ""Error""\n            if (\n                debug_rule_evaluation_status[""RuleEvaluationStatus""]\n                not in _NON_ERROR_TERMINAL_RULE_JOB_STATUSES\n            ):\n                incomplete_rule_job_found = True\n        if not incomplete_rule_job_found:\n            break\n'"
tests/integ/test_experiments_analytics.py,0,"b'from __future__ import absolute_import\n\nimport time\nimport uuid\nfrom contextlib import contextmanager\n\nimport pytest\n\nfrom sagemaker.analytics import ExperimentAnalytics\n\n\n@contextmanager\ndef experiment(sagemaker_session):\n    sm = sagemaker_session.sagemaker_client\n    trials = {}  # for resource cleanup\n\n    experiment_name = ""experiment-"" + str(uuid.uuid4())\n    try:\n        sm.create_experiment(ExperimentName=experiment_name)\n\n        # Search returns 10 results by default. Add 20 trials to verify pagination.\n        for i in range(20):\n            trial_name = ""trial-"" + str(uuid.uuid4())\n            sm.create_trial(TrialName=trial_name, ExperimentName=experiment_name)\n\n            trial_component_name = ""tc-"" + str(uuid.uuid4())\n            trials[trial_name] = trial_component_name\n\n            sm.create_trial_component(\n                TrialComponentName=trial_component_name, DisplayName=""Training""\n            )\n            sm.update_trial_component(\n                TrialComponentName=trial_component_name, Parameters={""hp1"": {""NumberValue"": i}}\n            )\n            sm.associate_trial_component(\n                TrialComponentName=trial_component_name, TrialName=trial_name\n            )\n\n        time.sleep(15)  # wait for search to get updated\n\n        yield experiment_name\n    finally:\n        _delete_resources(sm, experiment_name, trials)\n\n\n@pytest.mark.canary_quick\ndef test_experiment_analytics(sagemaker_session):\n    with experiment(sagemaker_session) as experiment_name:\n        analytics = ExperimentAnalytics(\n            experiment_name=experiment_name, sagemaker_session=sagemaker_session\n        )\n\n        assert list(analytics.dataframe().columns) == [""TrialComponentName"", ""DisplayName"", ""hp1""]\n\n\ndef test_experiment_analytics_pagination(sagemaker_session):\n    with experiment(sagemaker_session) as experiment_name:\n        analytics = ExperimentAnalytics(\n            experiment_name=experiment_name, sagemaker_session=sagemaker_session\n        )\n\n        assert list(analytics.dataframe().columns) == [""TrialComponentName"", ""DisplayName"", ""hp1""]\n        assert (\n            len(analytics.dataframe()) > 10\n        )  # TODO [owen-t] Replace with == 20 and put test in retry block\n\n\ndef test_experiment_analytics_search_by_nested_filter(sagemaker_session):\n    with experiment(sagemaker_session) as experiment_name:\n        search_exp = {\n            ""Filters"": [\n                {""Name"": ""Parents.ExperimentName"", ""Operator"": ""Equals"", ""Value"": experiment_name},\n                {""Name"": ""Parameters.hp1"", ""Operator"": ""GreaterThanOrEqualTo"", ""Value"": ""10""},\n            ]\n        }\n\n        analytics = ExperimentAnalytics(\n            sagemaker_session=sagemaker_session, search_expression=search_exp\n        )\n\n        assert list(analytics.dataframe().columns) == [""TrialComponentName"", ""DisplayName"", ""hp1""]\n        assert (\n            len(analytics.dataframe()) > 5\n        )  # TODO [owen-t] Replace with == 10 and put test in retry block\n\n\ndef test_experiment_analytics_search_by_nested_filter_sort_ascending(sagemaker_session):\n    with experiment(sagemaker_session) as experiment_name:\n        search_exp = {\n            ""Filters"": [\n                {""Name"": ""Parents.ExperimentName"", ""Operator"": ""Equals"", ""Value"": experiment_name},\n                {""Name"": ""Parameters.hp1"", ""Operator"": ""GreaterThanOrEqualTo"", ""Value"": ""10""},\n            ]\n        }\n\n        analytics = ExperimentAnalytics(\n            sagemaker_session=sagemaker_session,\n            search_expression=search_exp,\n            sort_by=""Parameters.hp1"",\n            sort_order=""Ascending"",\n        )\n\n        assert list(analytics.dataframe().columns) == [""TrialComponentName"", ""DisplayName"", ""hp1""]\n        assert (\n            len(analytics.dataframe()) > 5\n        )  # TODO [owen-t] Replace with == 10 and put test in retry block\n        assert list(analytics.dataframe()[""hp1""].values) == sorted(\n            analytics.dataframe()[""hp1""].values\n        )\n\n\ndef test_experiment_analytics_search_by_nested_filter_sort_descending(sagemaker_session):\n    with experiment(sagemaker_session) as experiment_name:\n        search_exp = {\n            ""Filters"": [\n                {""Name"": ""Parents.ExperimentName"", ""Operator"": ""Equals"", ""Value"": experiment_name},\n                {""Name"": ""Parameters.hp1"", ""Operator"": ""GreaterThanOrEqualTo"", ""Value"": ""10""},\n            ]\n        }\n\n        analytics = ExperimentAnalytics(\n            sagemaker_session=sagemaker_session,\n            search_expression=search_exp,\n            sort_by=""Parameters.hp1"",\n        )\n\n        assert list(analytics.dataframe().columns) == [""TrialComponentName"", ""DisplayName"", ""hp1""]\n        assert (\n            len(analytics.dataframe()) > 5\n        )  # TODO [owen-t] Replace with == 10 and put test in retry block\n        assert (\n            list(analytics.dataframe()[""hp1""].values)\n            == sorted(analytics.dataframe()[""hp1""].values)[::-1]\n        )\n\n\ndef _delete_resources(sagemaker_client, experiment_name, trials):\n    for trial, tc in trials.items():\n        with _ignore_resource_not_found(sagemaker_client):\n            sagemaker_client.disassociate_trial_component(TrialName=trial, TrialComponentName=tc)\n            _wait_for_trial_component_disassociation(sagemaker_client, tc)\n\n        with _ignore_resource_not_found(sagemaker_client):\n            sagemaker_client.delete_trial_component(TrialComponentName=tc)\n\n        with _ignore_resource_not_found(sagemaker_client):\n            sagemaker_client.delete_trial(TrialName=trial)\n\n    with _ignore_resource_not_found(sagemaker_client):\n        sagemaker_client.delete_experiment(ExperimentName=experiment_name)\n\n\n@contextmanager\ndef _ignore_resource_not_found(sagemaker_client):\n    try:\n        yield\n    except sagemaker_client.exceptions.ResourceNotFound:\n        pass\n\n\ndef _wait_for_trial_component_disassociation(sagemaker_client, tc):\n    # Sometimes it can take a bit of waiting for the trial component to be disassociated\n    for _ in range(5):\n        # Check that the trial component has been disassociated from the trial\n        trials = sagemaker_client.list_trials(TrialComponentName=tc)[""TrialSummaries""]\n        if len(trials) == 0:\n            break\n\n        time.sleep(1)\n'"
tests/integ/test_factorization_machines.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport gzip\nimport os\nimport pickle\nimport sys\nimport time\n\nfrom sagemaker import FactorizationMachines, FactorizationMachinesModel\nfrom sagemaker.utils import unique_name_from_base\nfrom tests.integ import DATA_DIR, TRAINING_DEFAULT_TIMEOUT_MINUTES\nfrom tests.integ.timeout import timeout, timeout_and_delete_endpoint_by_name\n\n\ndef test_factorization_machines(sagemaker_session, cpu_instance_type):\n    job_name = unique_name_from_base(""fm"")\n\n    with timeout(minutes=TRAINING_DEFAULT_TIMEOUT_MINUTES):\n        data_path = os.path.join(DATA_DIR, ""one_p_mnist"", ""mnist.pkl.gz"")\n        pickle_args = {} if sys.version_info.major == 2 else {""encoding"": ""latin1""}\n\n        # Load the data into memory as numpy arrays\n        with gzip.open(data_path, ""rb"") as f:\n            train_set, _, _ = pickle.load(f, **pickle_args)\n\n        fm = FactorizationMachines(\n            role=""SageMakerRole"",\n            train_instance_count=1,\n            train_instance_type=cpu_instance_type,\n            num_factors=10,\n            predictor_type=""regressor"",\n            epochs=2,\n            clip_gradient=1e2,\n            eps=0.001,\n            rescale_grad=1.0 / 100,\n            sagemaker_session=sagemaker_session,\n        )\n\n        # training labels must be \'float32\'\n        fm.fit(\n            fm.record_set(train_set[0][:200], train_set[1][:200].astype(""float32"")),\n            job_name=job_name,\n        )\n\n    with timeout_and_delete_endpoint_by_name(job_name, sagemaker_session):\n        model = FactorizationMachinesModel(\n            fm.model_data, role=""SageMakerRole"", sagemaker_session=sagemaker_session\n        )\n        predictor = model.deploy(1, cpu_instance_type, endpoint_name=job_name)\n        result = predictor.predict(train_set[0][:10])\n\n        assert len(result) == 10\n        for record in result:\n            assert record.label[""score""] is not None\n\n\ndef test_async_factorization_machines(sagemaker_session, cpu_instance_type):\n    job_name = unique_name_from_base(""fm"")\n\n    with timeout(minutes=5):\n        data_path = os.path.join(DATA_DIR, ""one_p_mnist"", ""mnist.pkl.gz"")\n        pickle_args = {} if sys.version_info.major == 2 else {""encoding"": ""latin1""}\n\n        # Load the data into memory as numpy arrays\n        with gzip.open(data_path, ""rb"") as f:\n            train_set, _, _ = pickle.load(f, **pickle_args)\n\n        fm = FactorizationMachines(\n            role=""SageMakerRole"",\n            train_instance_count=1,\n            train_instance_type=cpu_instance_type,\n            num_factors=10,\n            predictor_type=""regressor"",\n            epochs=2,\n            clip_gradient=1e2,\n            eps=0.001,\n            rescale_grad=1.0 / 100,\n            sagemaker_session=sagemaker_session,\n        )\n\n        # training labels must be \'float32\'\n        fm.fit(\n            fm.record_set(train_set[0][:200], train_set[1][:200].astype(""float32"")),\n            job_name=job_name,\n            wait=False,\n        )\n\n        print(""Detached from training job. Will re-attach in 20 seconds"")\n        time.sleep(20)\n        print(""attaching now..."")\n\n    with timeout_and_delete_endpoint_by_name(job_name, sagemaker_session):\n        estimator = FactorizationMachines.attach(\n            training_job_name=job_name, sagemaker_session=sagemaker_session\n        )\n        model = FactorizationMachinesModel(\n            estimator.model_data, role=""SageMakerRole"", sagemaker_session=sagemaker_session\n        )\n        predictor = model.deploy(1, cpu_instance_type, endpoint_name=job_name)\n        result = predictor.predict(train_set[0][:10])\n\n        assert len(result) == 10\n        for record in result:\n            assert record.label[""score""] is not None\n'"
tests/integ/test_git.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport os\n\nimport numpy\nimport pytest\nimport subprocess\nimport tempfile\n\nfrom tests.integ import lock as lock\nfrom sagemaker.mxnet.estimator import MXNet\nfrom sagemaker.pytorch.defaults import PYTORCH_VERSION\nfrom sagemaker.pytorch.estimator import PyTorch\nfrom sagemaker.sklearn.estimator import SKLearn\nfrom sagemaker.sklearn.model import SKLearnModel\nfrom tests.integ import DATA_DIR, PYTHON_VERSION\n\nMNIST_FOLDER_NAME = ""MNIST""\n\nGIT_REPO = ""https://github.com/aws/sagemaker-python-sdk.git""\nBRANCH = ""test-branch-git-config""\nCOMMIT = ""ae15c9d7d5b97ea95ea451e4662ee43da3401d73""\n\nPRIVATE_GIT_REPO = ""https://github.com/git-support-test/test-git.git""\nPRIVATE_BRANCH = ""master""\nPRIVATE_COMMIT = ""a46d6f9add3532ca3e4e231e4108b6bad15b7373""\n\nPRIVATE_GIT_REPO_2FA = ""https://github.com/git-support-test-2fa/test-git.git""\nPRIVATE_GIT_REPO_2FA_SSH = ""git@github.com:git-support-test-2fa/test-git.git""\nPRIVATE_BRANCH_2FA = ""master""\nPRIVATE_COMMIT_2FA = ""52381dee030eb332a7e42d9992878d7261eb21d4""\n\nCODECOMMIT_REPO = (\n    ""https://git-codecommit.us-west-2.amazonaws.com/v1/repos/sagemaker-python-sdk-git-testing-repo/""\n)\nCODECOMMIT_BRANCH = ""master""\n\n# endpoint tests all use the same port, so we use this lock to prevent concurrent execution\nLOCK_PATH = os.path.join(tempfile.gettempdir(), ""sagemaker_test_git_lock"")\n\n\n@pytest.mark.local_mode\ndef test_github(sagemaker_local_session):\n    script_path = ""mnist.py""\n    data_path = os.path.join(DATA_DIR, ""pytorch_mnist"")\n    git_config = {""repo"": GIT_REPO, ""branch"": BRANCH, ""commit"": COMMIT}\n    pytorch = PyTorch(\n        entry_point=script_path,\n        role=""SageMakerRole"",\n        source_dir=""pytorch"",\n        framework_version=PYTORCH_VERSION,\n        py_version=PYTHON_VERSION,\n        train_instance_count=1,\n        train_instance_type=""local"",\n        sagemaker_session=sagemaker_local_session,\n        git_config=git_config,\n    )\n\n    pytorch.fit({""training"": ""file://"" + os.path.join(data_path, ""training"", MNIST_FOLDER_NAME)})\n\n    with lock.lock(LOCK_PATH):\n        try:\n            predictor = pytorch.deploy(initial_instance_count=1, instance_type=""local"")\n            data = numpy.zeros(shape=(1, 1, 28, 28)).astype(numpy.float32)\n            result = predictor.predict(data)\n            assert result is not None\n        finally:\n            predictor.delete_endpoint()\n\n\n@pytest.mark.local_mode\n@pytest.mark.skip(""needs a secure authentication approach"")\ndef test_private_github(sagemaker_local_session):\n    script_path = ""mnist.py""\n    data_path = os.path.join(DATA_DIR, ""mxnet_mnist"")\n    git_config = {\n        ""repo"": PRIVATE_GIT_REPO,\n        ""branch"": PRIVATE_BRANCH,\n        ""commit"": PRIVATE_COMMIT,\n        ""2FA_enabled"": False,\n        ""username"": ""git-support-test"",\n        ""password"": """",  # TODO: find a secure approach\n    }\n    source_dir = ""mxnet""\n    dependencies = [""foo/bar.py""]\n    mx = MXNet(\n        entry_point=script_path,\n        role=""SageMakerRole"",\n        source_dir=source_dir,\n        dependencies=dependencies,\n        framework_version=MXNet.LATEST_VERSION,\n        py_version=PYTHON_VERSION,\n        train_instance_count=1,\n        train_instance_type=""local"",\n        sagemaker_session=sagemaker_local_session,\n        git_config=git_config,\n    )\n\n    mx.fit(\n        {\n            ""train"": ""file://"" + os.path.join(data_path, ""train""),\n            ""test"": ""file://"" + os.path.join(data_path, ""test""),\n        }\n    )\n\n    files = [file for file in os.listdir(mx.source_dir)]\n    assert ""some_file"" in files\n    assert ""mnist.py"" in files\n    assert os.path.exists(mx.dependencies[0])\n\n    with lock.lock(LOCK_PATH):\n        try:\n            serving_script_path = ""mnist_hosting_with_custom_handlers.py""\n            predictor = mx.deploy(1, ""local"", entry_point=serving_script_path)\n\n            data = numpy.zeros(shape=(1, 1, 28, 28))\n            result = predictor.predict(data)\n            assert result is not None\n        finally:\n            predictor.delete_endpoint()\n\n\n@pytest.mark.local_mode\n@pytest.mark.skip(""needs a secure authentication approach"")\ndef test_private_github_with_2fa(sagemaker_local_session, sklearn_full_version):\n    script_path = ""mnist.py""\n    data_path = os.path.join(DATA_DIR, ""sklearn_mnist"")\n    git_config = {\n        ""repo"": PRIVATE_GIT_REPO_2FA,\n        ""branch"": PRIVATE_BRANCH_2FA,\n        ""commit"": PRIVATE_COMMIT_2FA,\n        ""2FA_enabled"": True,\n        ""token"": """",  # TODO: find a secure approach\n    }\n    source_dir = ""sklearn""\n\n    sklearn = SKLearn(\n        entry_point=script_path,\n        role=""SageMakerRole"",\n        source_dir=source_dir,\n        py_version=""py3"",  # Scikit-learn supports only Python 3\n        train_instance_count=1,\n        train_instance_type=""local"",\n        sagemaker_session=sagemaker_local_session,\n        framework_version=sklearn_full_version,\n        hyperparameters={""epochs"": 1},\n        git_config=git_config,\n    )\n    train_input = ""file://"" + os.path.join(data_path, ""train"")\n    test_input = ""file://"" + os.path.join(data_path, ""test"")\n    sklearn.fit({""train"": train_input, ""test"": test_input})\n\n    assert os.path.isdir(sklearn.source_dir)\n\n    with lock.lock(LOCK_PATH):\n        try:\n            client = sagemaker_local_session.sagemaker_client\n            desc = client.describe_training_job(TrainingJobName=sklearn.latest_training_job.name)\n            model_data = desc[""ModelArtifacts""][""S3ModelArtifacts""]\n            model = SKLearnModel(\n                model_data,\n                ""SageMakerRole"",\n                entry_point=script_path,\n                source_dir=source_dir,\n                sagemaker_session=sagemaker_local_session,\n                git_config=git_config,\n            )\n            predictor = model.deploy(1, ""local"")\n\n            data = numpy.zeros((100, 784), dtype=""float32"")\n            result = predictor.predict(data)\n            assert result is not None\n        finally:\n            predictor.delete_endpoint()\n\n\n@pytest.mark.local_mode\ndef test_github_with_ssh_passphrase_not_configured(sagemaker_local_session, sklearn_full_version):\n    script_path = ""mnist.py""\n    data_path = os.path.join(DATA_DIR, ""sklearn_mnist"")\n    git_config = {\n        ""repo"": PRIVATE_GIT_REPO_2FA_SSH,\n        ""branch"": PRIVATE_BRANCH_2FA,\n        ""commit"": PRIVATE_COMMIT_2FA,\n    }\n    source_dir = ""sklearn""\n\n    sklearn = SKLearn(\n        entry_point=script_path,\n        role=""SageMakerRole"",\n        source_dir=source_dir,\n        py_version=""py3"",  # Scikit-learn supports only Python 3\n        train_instance_count=1,\n        train_instance_type=""local"",\n        sagemaker_session=sagemaker_local_session,\n        framework_version=sklearn_full_version,\n        hyperparameters={""epochs"": 1},\n        git_config=git_config,\n    )\n    train_input = ""file://"" + os.path.join(data_path, ""train"")\n    test_input = ""file://"" + os.path.join(data_path, ""test"")\n\n    with pytest.raises(subprocess.CalledProcessError) as error:\n        sklearn.fit({""train"": train_input, ""test"": test_input})\n    assert ""returned non-zero exit status"" in str(error)\n\n\n@pytest.mark.local_mode\n@pytest.mark.skip(""needs a secure authentication approach"")\ndef test_codecommit(sagemaker_local_session):\n    script_path = ""mnist.py""\n    data_path = os.path.join(DATA_DIR, ""mxnet_mnist"")\n    git_config = {\n        ""repo"": CODECOMMIT_REPO,\n        ""branch"": CODECOMMIT_BRANCH,\n        ""username"": ""GitTest-at-142577830533"",\n        ""password"": """",  # TODO: assume a role to get temporary credentials\n    }\n    source_dir = ""mxnet""\n    dependencies = [""foo/bar.py""]\n    mx = MXNet(\n        entry_point=script_path,\n        role=""SageMakerRole"",\n        source_dir=source_dir,\n        dependencies=dependencies,\n        framework_version=MXNet.LATEST_VERSION,\n        py_version=PYTHON_VERSION,\n        train_instance_count=1,\n        train_instance_type=""local"",\n        sagemaker_session=sagemaker_local_session,\n        git_config=git_config,\n    )\n\n    mx.fit(\n        {\n            ""train"": ""file://"" + os.path.join(data_path, ""train""),\n            ""test"": ""file://"" + os.path.join(data_path, ""test""),\n        }\n    )\n\n    files = [file for file in os.listdir(mx.source_dir)]\n    assert ""some_file"" in files\n    assert ""mnist.py"" in files\n    assert os.path.exists(mx.dependencies[0])\n\n    with lock.lock(LOCK_PATH):\n        try:\n            predictor = mx.deploy(1, ""local"")\n\n            data = numpy.zeros(shape=(1, 1, 28, 28))\n            result = predictor.predict(data)\n            assert result is not None\n        finally:\n            predictor.delete_endpoint()\n'"
tests/integ/test_horovod.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport json\nimport os\nimport tarfile\nfrom six.moves.urllib.parse import urlparse\n\nimport boto3\nimport pytest\n\nimport sagemaker.utils\nimport tests.integ as integ\nfrom sagemaker.tensorflow import TensorFlow\nfrom tests.integ import timeout\n\nhorovod_dir = os.path.join(os.path.dirname(__file__), "".."", ""data"", ""horovod"")\n\n\n@pytest.fixture(scope=""module"")\ndef gpu_instance_type(request):\n    return ""ml.p2.xlarge""\n\n\n@pytest.mark.canary_quick\ndef test_hvd_cpu(sagemaker_session, cpu_instance_type, tmpdir):\n    _create_and_fit_estimator(sagemaker_session, cpu_instance_type, tmpdir)\n\n\n@pytest.mark.canary_quick\n@pytest.mark.skipif(\n    integ.test_region() in integ.TRAINING_NO_P2_REGIONS, reason=""no ml.p2 instances in this region""\n)\ndef test_hvd_gpu(sagemaker_session, gpu_instance_type, tmpdir):\n    _create_and_fit_estimator(sagemaker_session, gpu_instance_type, tmpdir)\n\n\n@pytest.mark.local_mode\n@pytest.mark.parametrize(""instances, processes"", [[1, 2], (2, 1), (2, 2)])\ndef test_horovod_local_mode(sagemaker_local_session, instances, processes, tmpdir):\n    output_path = ""file://%s"" % tmpdir\n    job_name = sagemaker.utils.unique_name_from_base(""tf-horovod"")\n    estimator = TensorFlow(\n        entry_point=os.path.join(horovod_dir, ""hvd_basic.py""),\n        role=""SageMakerRole"",\n        train_instance_count=2,\n        train_instance_type=""local"",\n        sagemaker_session=sagemaker_local_session,\n        py_version=integ.PYTHON_VERSION,\n        script_mode=True,\n        output_path=output_path,\n        framework_version=""1.12"",\n        distributions={""mpi"": {""enabled"": True, ""processes_per_host"": processes}},\n    )\n\n    with timeout.timeout(minutes=integ.TRAINING_DEFAULT_TIMEOUT_MINUTES):\n        estimator.fit(job_name=job_name)\n\n        tmp = str(tmpdir)\n        extract_files(output_path.replace(""file://"", """"), tmp)\n\n        size = instances * processes\n\n        for rank in range(size):\n            assert read_json(""rank-%s"" % rank, tmp)[""rank""] == rank\n\n\ndef extract_files(output_path, tmpdir):\n    with tarfile.open(os.path.join(output_path, ""model.tar.gz"")) as tar:\n        tar.extractall(tmpdir)\n\n\ndef read_json(file, tmp):\n    with open(os.path.join(tmp, file)) as f:\n        return json.load(f)\n\n\ndef extract_files_from_s3(s3_url, tmpdir, sagemaker_session):\n    parsed_url = urlparse(s3_url)\n    s3 = boto3.resource(""s3"", region_name=sagemaker_session.boto_region_name)\n\n    model = os.path.join(tmpdir, ""model"")\n    s3.Bucket(parsed_url.netloc).download_file(parsed_url.path.lstrip(""/""), model)\n\n    with tarfile.open(model, ""r"") as tar_file:\n        tar_file.extractall(tmpdir)\n\n\ndef _create_and_fit_estimator(sagemaker_session, instance_type, tmpdir):\n    job_name = sagemaker.utils.unique_name_from_base(""tf-horovod"")\n    estimator = TensorFlow(\n        entry_point=os.path.join(horovod_dir, ""hvd_basic.py""),\n        role=""SageMakerRole"",\n        train_instance_count=2,\n        train_instance_type=instance_type,\n        sagemaker_session=sagemaker_session,\n        py_version=integ.PYTHON_VERSION,\n        script_mode=True,\n        framework_version=""1.12"",\n        distributions={""mpi"": {""enabled"": True}},\n    )\n\n    with timeout.timeout(minutes=integ.TRAINING_DEFAULT_TIMEOUT_MINUTES):\n        estimator.fit(job_name=job_name)\n\n        tmp = str(tmpdir)\n        extract_files_from_s3(estimator.model_data, tmp, sagemaker_session)\n\n        for rank in range(2):\n            assert read_json(""rank-%s"" % rank, tmp)[""rank""] == rank\n'"
tests/integ/test_inference_pipeline.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport json\nimport os\n\nimport pytest\nfrom tests.integ import DATA_DIR, TRANSFORM_DEFAULT_TIMEOUT_MINUTES\nfrom tests.integ.timeout import (\n    timeout_and_delete_endpoint_by_name,\n    timeout_and_delete_model_with_transformer,\n)\n\nfrom sagemaker.amazon.amazon_estimator import get_image_uri\nfrom sagemaker.content_types import CONTENT_TYPE_CSV\nfrom sagemaker.model import Model\nfrom sagemaker.pipeline import PipelineModel\nfrom sagemaker.predictor import RealTimePredictor, json_serializer\nfrom sagemaker.sparkml.model import SparkMLModel\nfrom sagemaker.utils import sagemaker_timestamp\nfrom tests.integ.retry import retries\n\nSPARKML_DATA_PATH = os.path.join(DATA_DIR, ""sparkml_model"")\nXGBOOST_DATA_PATH = os.path.join(DATA_DIR, ""xgboost_model"")\nSPARKML_XGBOOST_DATA_DIR = ""sparkml_xgboost_pipeline""\nVALID_DATA_PATH = os.path.join(DATA_DIR, SPARKML_XGBOOST_DATA_DIR, ""valid_input.csv"")\nINVALID_DATA_PATH = os.path.join(DATA_DIR, SPARKML_XGBOOST_DATA_DIR, ""invalid_input.csv"")\nSCHEMA = json.dumps(\n    {\n        ""input"": [\n            {""name"": ""Pclass"", ""type"": ""float""},\n            {""name"": ""Embarked"", ""type"": ""string""},\n            {""name"": ""Age"", ""type"": ""float""},\n            {""name"": ""Fare"", ""type"": ""float""},\n            {""name"": ""SibSp"", ""type"": ""float""},\n            {""name"": ""Sex"", ""type"": ""string""},\n        ],\n        ""output"": {""name"": ""features"", ""struct"": ""vector"", ""type"": ""double""},\n    }\n)\n\n\n@pytest.mark.continuous_testing\n@pytest.mark.regional_testing\ndef test_inference_pipeline_batch_transform(sagemaker_session, cpu_instance_type):\n    sparkml_model_data = sagemaker_session.upload_data(\n        path=os.path.join(SPARKML_DATA_PATH, ""mleap_model.tar.gz""),\n        key_prefix=""integ-test-data/sparkml/model"",\n    )\n    xgb_model_data = sagemaker_session.upload_data(\n        path=os.path.join(XGBOOST_DATA_PATH, ""xgb_model.tar.gz""),\n        key_prefix=""integ-test-data/xgboost/model"",\n    )\n    batch_job_name = ""test-inference-pipeline-batch-{}"".format(sagemaker_timestamp())\n    sparkml_model = SparkMLModel(\n        model_data=sparkml_model_data,\n        env={""SAGEMAKER_SPARKML_SCHEMA"": SCHEMA},\n        sagemaker_session=sagemaker_session,\n    )\n    xgb_image = get_image_uri(sagemaker_session.boto_region_name, ""xgboost"")\n    xgb_model = Model(\n        model_data=xgb_model_data, image=xgb_image, sagemaker_session=sagemaker_session\n    )\n    model = PipelineModel(\n        models=[sparkml_model, xgb_model],\n        role=""SageMakerRole"",\n        sagemaker_session=sagemaker_session,\n        name=batch_job_name,\n    )\n    transformer = model.transformer(1, cpu_instance_type)\n    transform_input_key_prefix = ""integ-test-data/sparkml_xgboost/transform""\n    transform_input = transformer.sagemaker_session.upload_data(\n        path=VALID_DATA_PATH, key_prefix=transform_input_key_prefix\n    )\n\n    with timeout_and_delete_model_with_transformer(\n        transformer, sagemaker_session, minutes=TRANSFORM_DEFAULT_TIMEOUT_MINUTES\n    ):\n        transformer.transform(\n            transform_input, content_type=CONTENT_TYPE_CSV, job_name=batch_job_name\n        )\n        transformer.wait()\n\n\n@pytest.mark.canary_quick\n@pytest.mark.regional_testing\n@pytest.mark.skip(\n    reason=""This test has always failed, but the failure was masked by a bug. ""\n    ""This test should be fixed. Details in https://github.com/aws/sagemaker-python-sdk/pull/968""\n)\ndef test_inference_pipeline_model_deploy(sagemaker_session, cpu_instance_type):\n    sparkml_data_path = os.path.join(DATA_DIR, ""sparkml_model"")\n    xgboost_data_path = os.path.join(DATA_DIR, ""xgboost_model"")\n    endpoint_name = ""test-inference-pipeline-deploy-{}"".format(sagemaker_timestamp())\n    sparkml_model_data = sagemaker_session.upload_data(\n        path=os.path.join(sparkml_data_path, ""mleap_model.tar.gz""),\n        key_prefix=""integ-test-data/sparkml/model"",\n    )\n    xgb_model_data = sagemaker_session.upload_data(\n        path=os.path.join(xgboost_data_path, ""xgb_model.tar.gz""),\n        key_prefix=""integ-test-data/xgboost/model"",\n    )\n\n    with timeout_and_delete_endpoint_by_name(endpoint_name, sagemaker_session):\n        sparkml_model = SparkMLModel(\n            model_data=sparkml_model_data,\n            env={""SAGEMAKER_SPARKML_SCHEMA"": SCHEMA},\n            sagemaker_session=sagemaker_session,\n        )\n        xgb_image = get_image_uri(sagemaker_session.boto_region_name, ""xgboost"")\n        xgb_model = Model(\n            model_data=xgb_model_data, image=xgb_image, sagemaker_session=sagemaker_session\n        )\n        model = PipelineModel(\n            models=[sparkml_model, xgb_model],\n            role=""SageMakerRole"",\n            sagemaker_session=sagemaker_session,\n            name=endpoint_name,\n        )\n        model.deploy(1, cpu_instance_type, endpoint_name=endpoint_name)\n        predictor = RealTimePredictor(\n            endpoint=endpoint_name,\n            sagemaker_session=sagemaker_session,\n            serializer=json_serializer,\n            content_type=CONTENT_TYPE_CSV,\n            accept=CONTENT_TYPE_CSV,\n        )\n\n        with open(VALID_DATA_PATH, ""r"") as f:\n            valid_data = f.read()\n            assert predictor.predict(valid_data) == ""0.714013934135""\n\n        with open(INVALID_DATA_PATH, ""r"") as f:\n            invalid_data = f.read()\n            assert predictor.predict(invalid_data) is None\n\n    model.delete_model()\n    with pytest.raises(Exception) as exception:\n        sagemaker_session.sagemaker_client.describe_model(ModelName=model.name)\n        assert ""Could not find model"" in str(exception.value)\n\n\ndef test_inference_pipeline_model_deploy_with_update_endpoint(\n    sagemaker_session, cpu_instance_type, alternative_cpu_instance_type\n):\n    sparkml_data_path = os.path.join(DATA_DIR, ""sparkml_model"")\n    xgboost_data_path = os.path.join(DATA_DIR, ""xgboost_model"")\n    endpoint_name = ""test-inference-pipeline-deploy-{}"".format(sagemaker_timestamp())\n    sparkml_model_data = sagemaker_session.upload_data(\n        path=os.path.join(sparkml_data_path, ""mleap_model.tar.gz""),\n        key_prefix=""integ-test-data/sparkml/model"",\n    )\n    xgb_model_data = sagemaker_session.upload_data(\n        path=os.path.join(xgboost_data_path, ""xgb_model.tar.gz""),\n        key_prefix=""integ-test-data/xgboost/model"",\n    )\n\n    with timeout_and_delete_endpoint_by_name(endpoint_name, sagemaker_session):\n        sparkml_model = SparkMLModel(\n            model_data=sparkml_model_data,\n            env={""SAGEMAKER_SPARKML_SCHEMA"": SCHEMA},\n            sagemaker_session=sagemaker_session,\n        )\n        xgb_image = get_image_uri(sagemaker_session.boto_region_name, ""xgboost"")\n        xgb_model = Model(\n            model_data=xgb_model_data, image=xgb_image, sagemaker_session=sagemaker_session\n        )\n        model = PipelineModel(\n            models=[sparkml_model, xgb_model],\n            role=""SageMakerRole"",\n            sagemaker_session=sagemaker_session,\n        )\n        model.deploy(1, alternative_cpu_instance_type, endpoint_name=endpoint_name)\n        old_endpoint = sagemaker_session.sagemaker_client.describe_endpoint(\n            EndpointName=endpoint_name\n        )\n        old_config_name = old_endpoint[""EndpointConfigName""]\n\n        model.deploy(1, cpu_instance_type, update_endpoint=True, endpoint_name=endpoint_name)\n\n        # Wait for endpoint to finish updating\n        # Endpoint update takes ~7min. 40 retries * 30s sleeps = 20min timeout\n        for _ in retries(40, ""Waiting for \'InService\' endpoint status"", seconds_to_sleep=30):\n            new_endpoint = sagemaker_session.sagemaker_client.describe_endpoint(\n                EndpointName=endpoint_name\n            )\n            if new_endpoint[""EndpointStatus""] == ""InService"":\n                break\n\n        new_config_name = new_endpoint[""EndpointConfigName""]\n        new_config = sagemaker_session.sagemaker_client.describe_endpoint_config(\n            EndpointConfigName=new_config_name\n        )\n\n        assert old_config_name != new_config_name\n        assert new_config[""ProductionVariants""][0][""InstanceType""] == cpu_instance_type\n        assert new_config[""ProductionVariants""][0][""InitialInstanceCount""] == 1\n\n    model.delete_model()\n    with pytest.raises(Exception) as exception:\n        sagemaker_session.sagemaker_client.describe_model(ModelName=model.name)\n        assert ""Could not find model"" in str(exception.value)\n'"
tests/integ/test_ipinsights.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport os\n\nfrom sagemaker import IPInsights, IPInsightsModel\nfrom sagemaker.predictor import RealTimePredictor\nfrom sagemaker.utils import unique_name_from_base\nfrom tests.integ import DATA_DIR, TRAINING_DEFAULT_TIMEOUT_MINUTES\nfrom tests.integ.record_set import prepare_record_set_from_local_files\nfrom tests.integ.timeout import timeout, timeout_and_delete_endpoint_by_name\n\nFEATURE_DIM = None\n\n\ndef test_ipinsights(sagemaker_session, cpu_instance_type):\n    job_name = unique_name_from_base(""ipinsights"")\n\n    with timeout(minutes=TRAINING_DEFAULT_TIMEOUT_MINUTES):\n        data_path = os.path.join(DATA_DIR, ""ipinsights"")\n        data_filename = ""train.csv""\n\n        with open(os.path.join(data_path, data_filename), ""rb"") as f:\n            num_records = len(f.readlines())\n\n            ipinsights = IPInsights(\n                role=""SageMakerRole"",\n                train_instance_count=1,\n                train_instance_type=cpu_instance_type,\n                num_entity_vectors=10,\n                vector_dim=100,\n                sagemaker_session=sagemaker_session,\n            )\n\n        record_set = prepare_record_set_from_local_files(\n            data_path, ipinsights.data_location, num_records, FEATURE_DIM, sagemaker_session\n        )\n        ipinsights.fit(records=record_set, job_name=job_name)\n\n    with timeout_and_delete_endpoint_by_name(job_name, sagemaker_session):\n        model = IPInsightsModel(\n            ipinsights.model_data, role=""SageMakerRole"", sagemaker_session=sagemaker_session\n        )\n        predictor = model.deploy(1, cpu_instance_type, endpoint_name=job_name)\n        assert isinstance(predictor, RealTimePredictor)\n\n        predict_input = [[""user_1"", ""1.1.1.1""]]\n        result = predictor.predict(predict_input)\n\n        assert len(result[""predictions""]) == 1\n        assert 0 > result[""predictions""][0][""dot_product""] > -1  # We expect ~ -0.22\n'"
tests/integ/test_kmeans.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport gzip\nimport json\nimport os\nimport pickle\nimport sys\nimport time\n\nimport pytest\n\nfrom sagemaker import KMeans, KMeansModel\nfrom sagemaker.utils import unique_name_from_base\nfrom tests.integ import DATA_DIR, TRAINING_DEFAULT_TIMEOUT_MINUTES\nfrom tests.integ.timeout import timeout, timeout_and_delete_endpoint_by_name\n\n\ndef test_kmeans(sagemaker_session, cpu_instance_type):\n    job_name = unique_name_from_base(""kmeans"")\n    with timeout(minutes=TRAINING_DEFAULT_TIMEOUT_MINUTES):\n        data_path = os.path.join(DATA_DIR, ""one_p_mnist"", ""mnist.pkl.gz"")\n        pickle_args = {} if sys.version_info.major == 2 else {""encoding"": ""latin1""}\n\n        # Load the data into memory as numpy arrays\n        with gzip.open(data_path, ""rb"") as f:\n            train_set, _, _ = pickle.load(f, **pickle_args)\n\n        kmeans = KMeans(\n            role=""SageMakerRole"",\n            train_instance_count=1,\n            train_instance_type=cpu_instance_type,\n            k=10,\n            sagemaker_session=sagemaker_session,\n        )\n\n        kmeans.init_method = ""random""\n        kmeans.max_iterations = 1\n        kmeans.tol = 1\n        kmeans.num_trials = 1\n        kmeans.local_init_method = ""kmeans++""\n        kmeans.half_life_time_size = 1\n        kmeans.epochs = 1\n        kmeans.center_factor = 1\n        kmeans.eval_metrics = [""ssd"", ""msd""]\n\n        assert kmeans.hyperparameters() == dict(\n            init_method=kmeans.init_method,\n            local_lloyd_max_iter=str(kmeans.max_iterations),\n            local_lloyd_tol=str(kmeans.tol),\n            local_lloyd_num_trials=str(kmeans.num_trials),\n            local_lloyd_init_method=kmeans.local_init_method,\n            half_life_time_size=str(kmeans.half_life_time_size),\n            epochs=str(kmeans.epochs),\n            extra_center_factor=str(kmeans.center_factor),\n            k=str(kmeans.k),\n            eval_metrics=json.dumps(kmeans.eval_metrics),\n            force_dense=""True"",\n        )\n\n        kmeans.fit(kmeans.record_set(train_set[0][:100]), job_name=job_name)\n\n    with timeout_and_delete_endpoint_by_name(job_name, sagemaker_session):\n        model = KMeansModel(\n            kmeans.model_data, role=""SageMakerRole"", sagemaker_session=sagemaker_session\n        )\n        predictor = model.deploy(1, cpu_instance_type, endpoint_name=job_name)\n        result = predictor.predict(train_set[0][:10])\n\n        assert len(result) == 10\n        for record in result:\n            assert record.label[""closest_cluster""] is not None\n            assert record.label[""distance_to_cluster""] is not None\n\n    predictor.delete_model()\n    with pytest.raises(Exception) as exception:\n        sagemaker_session.sagemaker_client.describe_model(ModelName=model.name)\n        assert ""Could not find model"" in str(exception.value)\n\n\ndef test_async_kmeans(sagemaker_session, cpu_instance_type):\n    job_name = unique_name_from_base(""kmeans"")\n\n    with timeout(minutes=5):\n        data_path = os.path.join(DATA_DIR, ""one_p_mnist"", ""mnist.pkl.gz"")\n        pickle_args = {} if sys.version_info.major == 2 else {""encoding"": ""latin1""}\n\n        # Load the data into memory as numpy arrays\n        with gzip.open(data_path, ""rb"") as f:\n            train_set, _, _ = pickle.load(f, **pickle_args)\n\n        kmeans = KMeans(\n            role=""SageMakerRole"",\n            train_instance_count=1,\n            train_instance_type=cpu_instance_type,\n            k=10,\n            sagemaker_session=sagemaker_session,\n        )\n\n        kmeans.init_method = ""random""\n        kmeans.max_iterations = 1\n        kmeans.tol = 1\n        kmeans.num_trials = 1\n        kmeans.local_init_method = ""kmeans++""\n        kmeans.half_life_time_size = 1\n        kmeans.epochs = 1\n        kmeans.center_factor = 1\n\n        assert kmeans.hyperparameters() == dict(\n            init_method=kmeans.init_method,\n            local_lloyd_max_iter=str(kmeans.max_iterations),\n            local_lloyd_tol=str(kmeans.tol),\n            local_lloyd_num_trials=str(kmeans.num_trials),\n            local_lloyd_init_method=kmeans.local_init_method,\n            half_life_time_size=str(kmeans.half_life_time_size),\n            epochs=str(kmeans.epochs),\n            extra_center_factor=str(kmeans.center_factor),\n            k=str(kmeans.k),\n            force_dense=""True"",\n        )\n\n        kmeans.fit(kmeans.record_set(train_set[0][:100]), wait=False, job_name=job_name)\n\n        print(""Detached from training job. Will re-attach in 20 seconds"")\n        time.sleep(20)\n        print(""attaching now..."")\n\n    with timeout_and_delete_endpoint_by_name(job_name, sagemaker_session):\n        estimator = KMeans.attach(training_job_name=job_name, sagemaker_session=sagemaker_session)\n        model = KMeansModel(\n            estimator.model_data, role=""SageMakerRole"", sagemaker_session=sagemaker_session\n        )\n        predictor = model.deploy(1, cpu_instance_type, endpoint_name=job_name)\n        result = predictor.predict(train_set[0][:10])\n\n        assert len(result) == 10\n        for record in result:\n            assert record.label[""closest_cluster""] is not None\n            assert record.label[""distance_to_cluster""] is not None\n'"
tests/integ/test_kmeans_efs_fsx.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport pytest\n\nfrom sagemaker import KMeans\nfrom sagemaker.amazon.amazon_estimator import FileSystemRecordSet\nfrom sagemaker.parameter import IntegerParameter, CategoricalParameter\nfrom sagemaker.tuner import HyperparameterTuner\nfrom sagemaker.utils import unique_name_from_base\nimport tests\nfrom tests.integ import TRAINING_DEFAULT_TIMEOUT_MINUTES, TUNING_DEFAULT_TIMEOUT_MINUTES\nfrom tests.integ.file_system_input_utils import set_up_efs_fsx, tear_down\nfrom tests.integ.s3_utils import assert_s3_files_exist\nfrom tests.integ.timeout import timeout\n\nTRAIN_INSTANCE_COUNT = 1\nOBJECTIVE_METRIC_NAME = ""test:msd""\nEFS_DIR_PATH = ""/one_p_mnist""\nFSX_DIR_PATH = ""/fsx/one_p_mnist""\nMAX_JOBS = 2\nMAX_PARALLEL_JOBS = 2\nK = 10\nNUM_RECORDS = 784\nFEATURE_DIM = 784\n\n\n@pytest.fixture(scope=""module"")\ndef efs_fsx_setup(sagemaker_session, ec2_instance_type):\n    fs_resources = None\n    try:\n        fs_resources = set_up_efs_fsx(sagemaker_session, ec2_instance_type)\n        yield fs_resources\n    finally:\n        if fs_resources:\n            tear_down(sagemaker_session, fs_resources)\n\n\n@pytest.mark.skipif(\n    tests.integ.test_region() not in tests.integ.EFS_TEST_ENABLED_REGION,\n    reason=""EFS integration tests need to be fixed before running in all regions."",\n)\ndef test_kmeans_efs(efs_fsx_setup, sagemaker_session, cpu_instance_type):\n    with timeout(minutes=TRAINING_DEFAULT_TIMEOUT_MINUTES):\n        role = efs_fsx_setup[""role_name""]\n        subnets = [efs_fsx_setup[""subnet_id""]]\n        security_group_ids = efs_fsx_setup[""security_group_ids""]\n\n        kmeans = KMeans(\n            role=role,\n            train_instance_count=TRAIN_INSTANCE_COUNT,\n            train_instance_type=cpu_instance_type,\n            k=K,\n            sagemaker_session=sagemaker_session,\n            subnets=subnets,\n            security_group_ids=security_group_ids,\n        )\n\n        file_system_efs_id = efs_fsx_setup[""file_system_efs_id""]\n        records = FileSystemRecordSet(\n            file_system_id=file_system_efs_id,\n            file_system_type=""EFS"",\n            directory_path=EFS_DIR_PATH,\n            num_records=NUM_RECORDS,\n            feature_dim=FEATURE_DIM,\n        )\n\n        job_name = unique_name_from_base(""kmeans-efs"")\n        kmeans.fit(records, job_name=job_name)\n        model_path, _ = kmeans.model_data.rsplit(""/"", 1)\n        assert_s3_files_exist(sagemaker_session, model_path, [""model.tar.gz""])\n\n\n@pytest.mark.skipif(\n    tests.integ.test_region() not in tests.integ.EFS_TEST_ENABLED_REGION,\n    reason=""EFS integration tests need to be fixed before running in all regions."",\n)\ndef test_kmeans_fsx(efs_fsx_setup, sagemaker_session, cpu_instance_type):\n    with timeout(minutes=TRAINING_DEFAULT_TIMEOUT_MINUTES):\n        role = efs_fsx_setup[""role_name""]\n        subnets = [efs_fsx_setup[""subnet_id""]]\n        security_group_ids = efs_fsx_setup[""security_group_ids""]\n        kmeans = KMeans(\n            role=role,\n            train_instance_count=TRAIN_INSTANCE_COUNT,\n            train_instance_type=cpu_instance_type,\n            k=K,\n            sagemaker_session=sagemaker_session,\n            subnets=subnets,\n            security_group_ids=security_group_ids,\n        )\n\n        file_system_fsx_id = efs_fsx_setup[""file_system_fsx_id""]\n        records = FileSystemRecordSet(\n            file_system_id=file_system_fsx_id,\n            file_system_type=""FSxLustre"",\n            directory_path=FSX_DIR_PATH,\n            num_records=NUM_RECORDS,\n            feature_dim=FEATURE_DIM,\n        )\n\n        job_name = unique_name_from_base(""kmeans-fsx"")\n        kmeans.fit(records, job_name=job_name)\n        model_path, _ = kmeans.model_data.rsplit(""/"", 1)\n        assert_s3_files_exist(sagemaker_session, model_path, [""model.tar.gz""])\n\n\n@pytest.mark.skipif(\n    tests.integ.test_region() not in tests.integ.EFS_TEST_ENABLED_REGION,\n    reason=""EFS integration tests need to be fixed before running in all regions."",\n)\ndef test_tuning_kmeans_efs(efs_fsx_setup, sagemaker_session, cpu_instance_type):\n    role = efs_fsx_setup[""role_name""]\n    subnets = [efs_fsx_setup[""subnet_id""]]\n    security_group_ids = efs_fsx_setup[""security_group_ids""]\n    kmeans = KMeans(\n        role=role,\n        train_instance_count=TRAIN_INSTANCE_COUNT,\n        train_instance_type=cpu_instance_type,\n        k=K,\n        sagemaker_session=sagemaker_session,\n        subnets=subnets,\n        security_group_ids=security_group_ids,\n    )\n\n    hyperparameter_ranges = {\n        ""extra_center_factor"": IntegerParameter(4, 10),\n        ""mini_batch_size"": IntegerParameter(10, 100),\n        ""epochs"": IntegerParameter(1, 2),\n        ""init_method"": CategoricalParameter([""kmeans++"", ""random""]),\n    }\n\n    with timeout(minutes=TUNING_DEFAULT_TIMEOUT_MINUTES):\n        tuner = HyperparameterTuner(\n            estimator=kmeans,\n            objective_metric_name=OBJECTIVE_METRIC_NAME,\n            hyperparameter_ranges=hyperparameter_ranges,\n            objective_type=""Minimize"",\n            max_jobs=MAX_JOBS,\n            max_parallel_jobs=MAX_PARALLEL_JOBS,\n        )\n\n        file_system_efs_id = efs_fsx_setup[""file_system_efs_id""]\n        train_records = FileSystemRecordSet(\n            file_system_id=file_system_efs_id,\n            file_system_type=""EFS"",\n            directory_path=EFS_DIR_PATH,\n            num_records=NUM_RECORDS,\n            feature_dim=FEATURE_DIM,\n        )\n\n        test_records = FileSystemRecordSet(\n            file_system_id=file_system_efs_id,\n            file_system_type=""EFS"",\n            directory_path=EFS_DIR_PATH,\n            num_records=NUM_RECORDS,\n            feature_dim=FEATURE_DIM,\n            channel=""test"",\n        )\n\n        job_name = unique_name_from_base(""tune-kmeans-efs"")\n        tuner.fit([train_records, test_records], job_name=job_name)\n        tuner.wait()\n        best_training_job = tuner.best_training_job()\n        assert best_training_job\n\n\n@pytest.mark.skipif(\n    tests.integ.test_region() not in tests.integ.EFS_TEST_ENABLED_REGION,\n    reason=""EFS integration tests need to be fixed before running in all regions."",\n)\ndef test_tuning_kmeans_fsx(efs_fsx_setup, sagemaker_session, cpu_instance_type):\n    role = efs_fsx_setup[""role_name""]\n    subnets = [efs_fsx_setup[""subnet_id""]]\n    security_group_ids = efs_fsx_setup[""security_group_ids""]\n    kmeans = KMeans(\n        role=role,\n        train_instance_count=TRAIN_INSTANCE_COUNT,\n        train_instance_type=cpu_instance_type,\n        k=K,\n        sagemaker_session=sagemaker_session,\n        subnets=subnets,\n        security_group_ids=security_group_ids,\n    )\n\n    hyperparameter_ranges = {\n        ""extra_center_factor"": IntegerParameter(4, 10),\n        ""mini_batch_size"": IntegerParameter(10, 100),\n        ""epochs"": IntegerParameter(1, 2),\n        ""init_method"": CategoricalParameter([""kmeans++"", ""random""]),\n    }\n\n    with timeout(minutes=TUNING_DEFAULT_TIMEOUT_MINUTES):\n        tuner = HyperparameterTuner(\n            estimator=kmeans,\n            objective_metric_name=OBJECTIVE_METRIC_NAME,\n            hyperparameter_ranges=hyperparameter_ranges,\n            objective_type=""Minimize"",\n            max_jobs=MAX_JOBS,\n            max_parallel_jobs=MAX_PARALLEL_JOBS,\n        )\n\n        file_system_fsx_id = efs_fsx_setup[""file_system_fsx_id""]\n        train_records = FileSystemRecordSet(\n            file_system_id=file_system_fsx_id,\n            file_system_type=""FSxLustre"",\n            directory_path=FSX_DIR_PATH,\n            num_records=NUM_RECORDS,\n            feature_dim=FEATURE_DIM,\n        )\n\n        test_records = FileSystemRecordSet(\n            file_system_id=file_system_fsx_id,\n            file_system_type=""FSxLustre"",\n            directory_path=FSX_DIR_PATH,\n            num_records=NUM_RECORDS,\n            feature_dim=FEATURE_DIM,\n            channel=""test"",\n        )\n\n        job_name = unique_name_from_base(""tune-kmeans-fsx"")\n        tuner.fit([train_records, test_records], job_name=job_name)\n        tuner.wait()\n        best_training_job = tuner.best_training_job()\n        assert best_training_job\n'"
tests/integ/test_knn.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport gzip\nimport os\nimport pickle\nimport sys\nimport time\n\nfrom sagemaker import KNN, KNNModel\nfrom sagemaker.utils import unique_name_from_base\nfrom tests.integ import DATA_DIR, TRAINING_DEFAULT_TIMEOUT_MINUTES\nfrom tests.integ.timeout import timeout, timeout_and_delete_endpoint_by_name\n\n\ndef test_knn_regressor(sagemaker_session, cpu_instance_type):\n    job_name = unique_name_from_base(""knn"")\n\n    with timeout(minutes=TRAINING_DEFAULT_TIMEOUT_MINUTES):\n        data_path = os.path.join(DATA_DIR, ""one_p_mnist"", ""mnist.pkl.gz"")\n        pickle_args = {} if sys.version_info.major == 2 else {""encoding"": ""latin1""}\n\n        # Load the data into memory as numpy arrays\n        with gzip.open(data_path, ""rb"") as f:\n            train_set, _, _ = pickle.load(f, **pickle_args)\n\n        knn = KNN(\n            role=""SageMakerRole"",\n            train_instance_count=1,\n            train_instance_type=cpu_instance_type,\n            k=10,\n            predictor_type=""regressor"",\n            sample_size=500,\n            sagemaker_session=sagemaker_session,\n        )\n\n        # training labels must be \'float32\'\n        knn.fit(\n            knn.record_set(train_set[0][:200], train_set[1][:200].astype(""float32"")),\n            job_name=job_name,\n        )\n\n    with timeout_and_delete_endpoint_by_name(job_name, sagemaker_session):\n        model = KNNModel(knn.model_data, role=""SageMakerRole"", sagemaker_session=sagemaker_session)\n        predictor = model.deploy(1, cpu_instance_type, endpoint_name=job_name)\n        result = predictor.predict(train_set[0][:10])\n\n        assert len(result) == 10\n        for record in result:\n            assert record.label[""score""] is not None\n\n\ndef test_async_knn_classifier(sagemaker_session, cpu_instance_type):\n    job_name = unique_name_from_base(""knn"")\n\n    with timeout(minutes=5):\n        data_path = os.path.join(DATA_DIR, ""one_p_mnist"", ""mnist.pkl.gz"")\n        pickle_args = {} if sys.version_info.major == 2 else {""encoding"": ""latin1""}\n\n        # Load the data into memory as numpy arrays\n        with gzip.open(data_path, ""rb"") as f:\n            train_set, _, _ = pickle.load(f, **pickle_args)\n\n        knn = KNN(\n            role=""SageMakerRole"",\n            train_instance_count=1,\n            train_instance_type=cpu_instance_type,\n            k=10,\n            predictor_type=""classifier"",\n            sample_size=500,\n            index_type=""faiss.IVFFlat"",\n            index_metric=""L2"",\n            sagemaker_session=sagemaker_session,\n        )\n\n        # training labels must be \'float32\'\n        knn.fit(\n            knn.record_set(train_set[0][:200], train_set[1][:200].astype(""float32"")),\n            wait=False,\n            job_name=job_name,\n        )\n\n        print(""Detached from training job. Will re-attach in 20 seconds"")\n        time.sleep(20)\n        print(""attaching now..."")\n\n    with timeout_and_delete_endpoint_by_name(job_name, sagemaker_session):\n        estimator = KNN.attach(training_job_name=job_name, sagemaker_session=sagemaker_session)\n        model = KNNModel(\n            estimator.model_data, role=""SageMakerRole"", sagemaker_session=sagemaker_session\n        )\n        predictor = model.deploy(1, cpu_instance_type, endpoint_name=job_name)\n        result = predictor.predict(train_set[0][:10])\n\n        assert len(result) == 10\n        for record in result:\n            assert record.label[""score""] is not None\n'"
tests/integ/test_lda.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport os\n\nimport numpy as np\n\nimport pytest\nimport tests.integ\nfrom sagemaker import LDA, LDAModel\nfrom sagemaker.amazon.common import read_records\nfrom sagemaker.utils import unique_name_from_base\nfrom tests.integ import DATA_DIR, TRAINING_DEFAULT_TIMEOUT_MINUTES\nfrom tests.integ.timeout import timeout, timeout_and_delete_endpoint_by_name\nfrom tests.integ.record_set import prepare_record_set_from_local_files\n\n\n@pytest.mark.skipif(\n    tests.integ.test_region() in tests.integ.NO_LDA_REGIONS,\n    reason=""LDA image is not supported in certain regions"",\n)\ndef test_lda(sagemaker_session, cpu_instance_type):\n    job_name = unique_name_from_base(""lda"")\n\n    with timeout(minutes=TRAINING_DEFAULT_TIMEOUT_MINUTES):\n        data_path = os.path.join(DATA_DIR, ""lda"")\n        data_filename = ""nips-train_1.pbr""\n\n        with open(os.path.join(data_path, data_filename), ""rb"") as f:\n            all_records = read_records(f)\n\n        # all records must be same\n        feature_num = int(all_records[0].features[""values""].float32_tensor.shape[0])\n\n        lda = LDA(\n            role=""SageMakerRole"",\n            train_instance_type=cpu_instance_type,\n            num_topics=10,\n            sagemaker_session=sagemaker_session,\n        )\n\n        record_set = prepare_record_set_from_local_files(\n            data_path, lda.data_location, len(all_records), feature_num, sagemaker_session\n        )\n        lda.fit(records=record_set, mini_batch_size=100, job_name=job_name)\n\n    with timeout_and_delete_endpoint_by_name(job_name, sagemaker_session):\n        model = LDAModel(lda.model_data, role=""SageMakerRole"", sagemaker_session=sagemaker_session)\n        predictor = model.deploy(1, cpu_instance_type, endpoint_name=job_name)\n\n        predict_input = np.random.rand(1, feature_num)\n        result = predictor.predict(predict_input)\n\n        assert len(result) == 1\n        for record in result:\n            assert record.label[""topic_mixture""] is not None\n'"
tests/integ/test_linear_learner.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport gzip\nimport os\nimport pickle\nimport sys\nimport time\n\nimport numpy as np\nimport pytest\n\nfrom sagemaker.amazon.linear_learner import LinearLearner, LinearLearnerModel\nfrom sagemaker.utils import unique_name_from_base\nfrom tests.integ import DATA_DIR, TRAINING_DEFAULT_TIMEOUT_MINUTES\nfrom tests.integ.timeout import timeout, timeout_and_delete_endpoint_by_name\n\n\n@pytest.mark.canary_quick\ndef test_linear_learner(sagemaker_session, cpu_instance_type):\n    job_name = unique_name_from_base(""linear-learner"")\n\n    with timeout(minutes=TRAINING_DEFAULT_TIMEOUT_MINUTES):\n        data_path = os.path.join(DATA_DIR, ""one_p_mnist"", ""mnist.pkl.gz"")\n        pickle_args = {} if sys.version_info.major == 2 else {""encoding"": ""latin1""}\n\n        # Load the data into memory as numpy arrays\n        with gzip.open(data_path, ""rb"") as f:\n            train_set, _, _ = pickle.load(f, **pickle_args)\n\n        train_set[1][:100] = 1\n        train_set[1][100:200] = 0\n        train_set = train_set[0], train_set[1].astype(np.dtype(""float32""))\n\n        ll = LinearLearner(\n            ""SageMakerRole"",\n            1,\n            cpu_instance_type,\n            predictor_type=""binary_classifier"",\n            sagemaker_session=sagemaker_session,\n        )\n        ll.binary_classifier_model_selection_criteria = ""accuracy""\n        ll.target_recall = 0.5\n        ll.target_precision = 0.5\n        ll.positive_example_weight_mult = 0.1\n        ll.epochs = 1\n        ll.use_bias = True\n        ll.num_models = 1\n        ll.num_calibration_samples = 1\n        ll.init_method = ""uniform""\n        ll.init_scale = 0.5\n        ll.init_sigma = 0.2\n        ll.init_bias = 5\n        ll.optimizer = ""adam""\n        ll.loss = ""logistic""\n        ll.wd = 0.5\n        ll.l1 = 0.5\n        ll.momentum = 0.5\n        ll.learning_rate = 0.1\n        ll.beta_1 = 0.1\n        ll.beta_2 = 0.1\n        ll.use_lr_scheduler = True\n        ll.lr_scheduler_step = 2\n        ll.lr_scheduler_factor = 0.5\n        ll.lr_scheduler_minimum_lr = 0.1\n        ll.normalize_data = False\n        ll.normalize_label = False\n        ll.unbias_data = True\n        ll.unbias_label = False\n        ll.num_point_for_scaler = 10000\n        ll.margin = 1.0\n        ll.quantile = 0.5\n        ll.loss_insensitivity = 0.1\n        ll.huber_delta = 0.1\n        ll.early_stopping_tolerance = 0.0001\n        ll.early_stopping_patience = 3\n        ll.fit(ll.record_set(train_set[0][:200], train_set[1][:200]), job_name=job_name)\n\n    with timeout_and_delete_endpoint_by_name(job_name, sagemaker_session):\n        predictor = ll.deploy(1, cpu_instance_type, endpoint_name=job_name)\n\n        result = predictor.predict(train_set[0][0:100])\n        assert len(result) == 100\n        for record in result:\n            assert record.label[""predicted_label""] is not None\n            assert record.label[""score""] is not None\n\n\ndef test_linear_learner_multiclass(sagemaker_session, cpu_instance_type):\n    job_name = unique_name_from_base(""linear-learner"")\n\n    with timeout(minutes=TRAINING_DEFAULT_TIMEOUT_MINUTES):\n        data_path = os.path.join(DATA_DIR, ""one_p_mnist"", ""mnist.pkl.gz"")\n        pickle_args = {} if sys.version_info.major == 2 else {""encoding"": ""latin1""}\n\n        # Load the data into memory as numpy arrays\n        with gzip.open(data_path, ""rb"") as f:\n            train_set, _, _ = pickle.load(f, **pickle_args)\n\n        train_set = train_set[0], train_set[1].astype(np.dtype(""float32""))\n\n        ll = LinearLearner(\n            ""SageMakerRole"",\n            1,\n            cpu_instance_type,\n            predictor_type=""multiclass_classifier"",\n            num_classes=10,\n            sagemaker_session=sagemaker_session,\n        )\n\n        ll.epochs = 1\n        ll.fit(ll.record_set(train_set[0][:200], train_set[1][:200]), job_name=job_name)\n\n    with timeout_and_delete_endpoint_by_name(job_name, sagemaker_session):\n        predictor = ll.deploy(1, cpu_instance_type, endpoint_name=job_name)\n\n        result = predictor.predict(train_set[0][0:100])\n        assert len(result) == 100\n        for record in result:\n            assert record.label[""predicted_label""] is not None\n            assert record.label[""score""] is not None\n\n\ndef test_async_linear_learner(sagemaker_session, cpu_instance_type):\n    job_name = unique_name_from_base(""linear-learner"")\n\n    with timeout(minutes=TRAINING_DEFAULT_TIMEOUT_MINUTES):\n        data_path = os.path.join(DATA_DIR, ""one_p_mnist"", ""mnist.pkl.gz"")\n        pickle_args = {} if sys.version_info.major == 2 else {""encoding"": ""latin1""}\n\n        # Load the data into memory as numpy arrays\n        with gzip.open(data_path, ""rb"") as f:\n            train_set, _, _ = pickle.load(f, **pickle_args)\n\n        train_set[1][:100] = 1\n        train_set[1][100:200] = 0\n        train_set = train_set[0], train_set[1].astype(np.dtype(""float32""))\n\n        ll = LinearLearner(\n            ""SageMakerRole"",\n            1,\n            cpu_instance_type,\n            predictor_type=""binary_classifier"",\n            sagemaker_session=sagemaker_session,\n        )\n        ll.binary_classifier_model_selection_criteria = ""accuracy""\n        ll.target_recall = 0.5\n        ll.target_precision = 0.5\n        ll.positive_example_weight_mult = 0.1\n        ll.epochs = 1\n        ll.use_bias = True\n        ll.num_models = 1\n        ll.num_calibration_samples = 1\n        ll.init_method = ""uniform""\n        ll.init_scale = 0.5\n        ll.init_sigma = 0.2\n        ll.init_bias = 5\n        ll.optimizer = ""adam""\n        ll.loss = ""logistic""\n        ll.wd = 0.5\n        ll.l1 = 0.5\n        ll.momentum = 0.5\n        ll.learning_rate = 0.1\n        ll.beta_1 = 0.1\n        ll.beta_2 = 0.1\n        ll.use_lr_scheduler = True\n        ll.lr_scheduler_step = 2\n        ll.lr_scheduler_factor = 0.5\n        ll.lr_scheduler_minimum_lr = 0.1\n        ll.normalize_data = False\n        ll.normalize_label = False\n        ll.unbias_data = True\n        ll.unbias_label = False\n        ll.num_point_for_scaler = 10000\n        ll.margin = 1.0\n        ll.quantile = 0.5\n        ll.loss_insensitivity = 0.1\n        ll.huber_delta = 0.1\n        ll.early_stopping_tolerance = 0.0001\n        ll.early_stopping_patience = 3\n        ll.fit(ll.record_set(train_set[0][:200], train_set[1][:200]), wait=False, job_name=job_name)\n\n        print(""Waiting to re-attach to the training job: %s"" % job_name)\n        time.sleep(20)\n\n    with timeout_and_delete_endpoint_by_name(job_name, sagemaker_session):\n        estimator = LinearLearner.attach(\n            training_job_name=job_name, sagemaker_session=sagemaker_session\n        )\n        model = LinearLearnerModel(\n            estimator.model_data, role=""SageMakerRole"", sagemaker_session=sagemaker_session\n        )\n        predictor = model.deploy(1, cpu_instance_type, endpoint_name=job_name)\n\n        result = predictor.predict(train_set[0][0:100])\n        assert len(result) == 100\n        for record in result:\n            assert record.label[""predicted_label""] is not None\n            assert record.label[""score""] is not None\n'"
tests/integ/test_local_mode.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport os\nimport tarfile\n\nimport boto3\nimport numpy\nimport pytest\nimport tempfile\n\nimport stopit\n\nimport tests.integ.lock as lock\nfrom tests.integ import DATA_DIR, PYTHON_VERSION\n\nfrom sagemaker.local import LocalSession, LocalSagemakerRuntimeClient, LocalSagemakerClient\nfrom sagemaker.mxnet import MXNet\nfrom sagemaker.tensorflow import TensorFlow\n\n# endpoint tests all use the same port, so we use this lock to prevent concurrent execution\nLOCK_PATH = os.path.join(tempfile.gettempdir(), ""sagemaker_test_local_mode_lock"")\nDATA_PATH = os.path.join(DATA_DIR, ""iris"", ""data"")\nDEFAULT_REGION = ""us-west-2""\n\n\nclass LocalNoS3Session(LocalSession):\n    """"""\n    This Session sets  local_code: True regardless of any config file settings\n    """"""\n\n    def __init__(self):\n        super(LocalSession, self).__init__()\n\n    def _initialize(self, boto_session, sagemaker_client, sagemaker_runtime_client):\n        self.boto_session = boto3.Session(region_name=DEFAULT_REGION)\n        if self.config is None:\n            self.config = {""local"": {""local_code"": True, ""region_name"": DEFAULT_REGION}}\n\n        self._region_name = DEFAULT_REGION\n        self.sagemaker_client = LocalSagemakerClient(self)\n        self.sagemaker_runtime_client = LocalSagemakerRuntimeClient(self.config)\n        self.local_mode = True\n\n\n@pytest.fixture(scope=""module"")\ndef mxnet_model(sagemaker_local_session, mxnet_full_version):\n    def _create_model(output_path):\n        script_path = os.path.join(DATA_DIR, ""mxnet_mnist"", ""mnist.py"")\n        data_path = os.path.join(DATA_DIR, ""mxnet_mnist"")\n\n        mx = MXNet(\n            entry_point=script_path,\n            role=""SageMakerRole"",\n            train_instance_count=1,\n            train_instance_type=""local"",\n            output_path=output_path,\n            framework_version=mxnet_full_version,\n            sagemaker_session=sagemaker_local_session,\n        )\n\n        train_input = mx.sagemaker_session.upload_data(\n            path=os.path.join(data_path, ""train""), key_prefix=""integ-test-data/mxnet_mnist/train""\n        )\n        test_input = mx.sagemaker_session.upload_data(\n            path=os.path.join(data_path, ""test""), key_prefix=""integ-test-data/mxnet_mnist/test""\n        )\n\n        mx.fit({""train"": train_input, ""test"": test_input})\n        model = mx.create_model(1)\n        return model\n\n    return _create_model\n\n\n@pytest.mark.local_mode\n@pytest.mark.skipif(PYTHON_VERSION != ""py2"", reason=""TensorFlow image supports only python 2."")\ndef test_tf_local_mode(sagemaker_local_session):\n    with stopit.ThreadingTimeout(5 * 60, swallow_exc=False):\n        script_path = os.path.join(DATA_DIR, ""iris"", ""iris-dnn-classifier.py"")\n\n        estimator = TensorFlow(\n            entry_point=script_path,\n            role=""SageMakerRole"",\n            framework_version=""1.12"",\n            training_steps=1,\n            evaluation_steps=1,\n            hyperparameters={""input_tensor_name"": ""inputs""},\n            train_instance_count=1,\n            train_instance_type=""local"",\n            base_job_name=""test-tf"",\n            sagemaker_session=sagemaker_local_session,\n        )\n\n        inputs = estimator.sagemaker_session.upload_data(\n            path=DATA_PATH, key_prefix=""integ-test-data/tf_iris""\n        )\n        estimator.fit(inputs)\n        print(""job succeeded: {}"".format(estimator.latest_training_job.name))\n\n    endpoint_name = estimator.latest_training_job.name\n    with lock.lock(LOCK_PATH):\n        try:\n            json_predictor = estimator.deploy(\n                initial_instance_count=1, instance_type=""local"", endpoint_name=endpoint_name\n            )\n\n            features = [6.4, 3.2, 4.5, 1.5]\n            dict_result = json_predictor.predict({""inputs"": features})\n            print(""predict result: {}"".format(dict_result))\n            list_result = json_predictor.predict(features)\n            print(""predict result: {}"".format(list_result))\n\n            assert dict_result == list_result\n        finally:\n            estimator.delete_endpoint()\n\n\n@pytest.mark.local_mode\n@pytest.mark.skipif(PYTHON_VERSION != ""py2"", reason=""TensorFlow image supports only python 2."")\ndef test_tf_distributed_local_mode(sagemaker_local_session):\n    with stopit.ThreadingTimeout(5 * 60, swallow_exc=False):\n        script_path = os.path.join(DATA_DIR, ""iris"", ""iris-dnn-classifier.py"")\n\n        estimator = TensorFlow(\n            entry_point=script_path,\n            role=""SageMakerRole"",\n            framework_version=""1.12"",\n            training_steps=1,\n            evaluation_steps=1,\n            hyperparameters={""input_tensor_name"": ""inputs""},\n            train_instance_count=3,\n            train_instance_type=""local"",\n            base_job_name=""test-tf"",\n            sagemaker_session=sagemaker_local_session,\n        )\n\n        inputs = ""file://"" + DATA_PATH\n        estimator.fit(inputs)\n        print(""job succeeded: {}"".format(estimator.latest_training_job.name))\n\n    endpoint_name = estimator.latest_training_job.name\n\n    with lock.lock(LOCK_PATH):\n        try:\n            json_predictor = estimator.deploy(\n                initial_instance_count=1, instance_type=""local"", endpoint_name=endpoint_name\n            )\n\n            features = [6.4, 3.2, 4.5, 1.5]\n            dict_result = json_predictor.predict({""inputs"": features})\n            print(""predict result: {}"".format(dict_result))\n            list_result = json_predictor.predict(features)\n            print(""predict result: {}"".format(list_result))\n\n            assert dict_result == list_result\n        finally:\n            estimator.delete_endpoint()\n\n\n@pytest.mark.local_mode\n@pytest.mark.skipif(PYTHON_VERSION != ""py2"", reason=""TensorFlow image supports only python 2."")\ndef test_tf_local_data(sagemaker_local_session):\n    with stopit.ThreadingTimeout(5 * 60, swallow_exc=False):\n        script_path = os.path.join(DATA_DIR, ""iris"", ""iris-dnn-classifier.py"")\n\n        estimator = TensorFlow(\n            entry_point=script_path,\n            role=""SageMakerRole"",\n            framework_version=""1.12"",\n            training_steps=1,\n            evaluation_steps=1,\n            hyperparameters={""input_tensor_name"": ""inputs""},\n            train_instance_count=1,\n            train_instance_type=""local"",\n            base_job_name=""test-tf"",\n            sagemaker_session=sagemaker_local_session,\n        )\n\n        inputs = ""file://"" + DATA_PATH\n        estimator.fit(inputs)\n        print(""job succeeded: {}"".format(estimator.latest_training_job.name))\n\n    endpoint_name = estimator.latest_training_job.name\n    with lock.lock(LOCK_PATH):\n        try:\n            json_predictor = estimator.deploy(\n                initial_instance_count=1, instance_type=""local"", endpoint_name=endpoint_name\n            )\n\n            features = [6.4, 3.2, 4.5, 1.5]\n            dict_result = json_predictor.predict({""inputs"": features})\n            print(""predict result: {}"".format(dict_result))\n            list_result = json_predictor.predict(features)\n            print(""predict result: {}"".format(list_result))\n\n            assert dict_result == list_result\n        finally:\n            estimator.delete_endpoint()\n\n\n@pytest.mark.local_mode\n@pytest.mark.skipif(PYTHON_VERSION != ""py2"", reason=""TensorFlow image supports only python 2."")\ndef test_tf_local_data_local_script():\n    with stopit.ThreadingTimeout(5 * 60, swallow_exc=False):\n        script_path = os.path.join(DATA_DIR, ""iris"", ""iris-dnn-classifier.py"")\n\n        estimator = TensorFlow(\n            entry_point=script_path,\n            role=""SageMakerRole"",\n            framework_version=""1.12"",\n            training_steps=1,\n            evaluation_steps=1,\n            hyperparameters={""input_tensor_name"": ""inputs""},\n            train_instance_count=1,\n            train_instance_type=""local"",\n            base_job_name=""test-tf"",\n            sagemaker_session=LocalNoS3Session(),\n        )\n\n        inputs = ""file://"" + DATA_PATH\n\n        estimator.fit(inputs)\n        print(""job succeeded: {}"".format(estimator.latest_training_job.name))\n\n    endpoint_name = estimator.latest_training_job.name\n    with lock.lock(LOCK_PATH):\n        try:\n            json_predictor = estimator.deploy(\n                initial_instance_count=1, instance_type=""local"", endpoint_name=endpoint_name\n            )\n\n            features = [6.4, 3.2, 4.5, 1.5]\n            dict_result = json_predictor.predict({""inputs"": features})\n            print(""predict result: {}"".format(dict_result))\n            list_result = json_predictor.predict(features)\n            print(""predict result: {}"".format(list_result))\n\n            assert dict_result == list_result\n        finally:\n            estimator.delete_endpoint()\n\n\n@pytest.mark.local_mode\ndef test_local_mode_serving_from_s3_model(sagemaker_local_session, mxnet_model, mxnet_full_version):\n    path = ""s3://%s"" % sagemaker_local_session.default_bucket()\n    s3_model = mxnet_model(path)\n    s3_model.sagemaker_session = sagemaker_local_session\n\n    predictor = None\n    with lock.lock(LOCK_PATH):\n        try:\n            predictor = s3_model.deploy(initial_instance_count=1, instance_type=""local"")\n            data = numpy.zeros(shape=(1, 1, 28, 28))\n            predictor.predict(data)\n        finally:\n            if predictor:\n                predictor.delete_endpoint()\n\n\n@pytest.mark.local_mode\ndef test_local_mode_serving_from_local_model(tmpdir, sagemaker_local_session, mxnet_model):\n    predictor = None\n\n    with lock.lock(LOCK_PATH):\n        try:\n            path = ""file://%s"" % (str(tmpdir))\n            model = mxnet_model(path)\n            model.sagemaker_session = sagemaker_local_session\n            predictor = model.deploy(initial_instance_count=1, instance_type=""local"")\n            data = numpy.zeros(shape=(1, 1, 28, 28))\n            predictor.predict(data)\n        finally:\n            if predictor:\n                predictor.delete_endpoint()\n\n\n@pytest.mark.local_mode\ndef test_mxnet_local_mode(sagemaker_local_session, mxnet_full_version):\n    script_path = os.path.join(DATA_DIR, ""mxnet_mnist"", ""mnist.py"")\n    data_path = os.path.join(DATA_DIR, ""mxnet_mnist"")\n\n    mx = MXNet(\n        entry_point=script_path,\n        role=""SageMakerRole"",\n        py_version=PYTHON_VERSION,\n        train_instance_count=1,\n        train_instance_type=""local"",\n        sagemaker_session=sagemaker_local_session,\n        framework_version=mxnet_full_version,\n    )\n\n    train_input = mx.sagemaker_session.upload_data(\n        path=os.path.join(data_path, ""train""), key_prefix=""integ-test-data/mxnet_mnist/train""\n    )\n    test_input = mx.sagemaker_session.upload_data(\n        path=os.path.join(data_path, ""test""), key_prefix=""integ-test-data/mxnet_mnist/test""\n    )\n\n    mx.fit({""train"": train_input, ""test"": test_input})\n    endpoint_name = mx.latest_training_job.name\n\n    with lock.lock(LOCK_PATH):\n        try:\n            predictor = mx.deploy(1, ""local"", endpoint_name=endpoint_name)\n            data = numpy.zeros(shape=(1, 1, 28, 28))\n            predictor.predict(data)\n        finally:\n            mx.delete_endpoint()\n\n\n@pytest.mark.local_mode\ndef test_mxnet_local_data_local_script(mxnet_full_version):\n    data_path = os.path.join(DATA_DIR, ""mxnet_mnist"")\n    script_path = os.path.join(data_path, ""mnist.py"")\n\n    mx = MXNet(\n        entry_point=script_path,\n        role=""SageMakerRole"",\n        train_instance_count=1,\n        train_instance_type=""local"",\n        framework_version=mxnet_full_version,\n        sagemaker_session=LocalNoS3Session(),\n    )\n\n    train_input = ""file://"" + os.path.join(data_path, ""train"")\n    test_input = ""file://"" + os.path.join(data_path, ""test"")\n\n    mx.fit({""train"": train_input, ""test"": test_input})\n    endpoint_name = mx.latest_training_job.name\n\n    with lock.lock(LOCK_PATH):\n        try:\n            predictor = mx.deploy(1, ""local"", endpoint_name=endpoint_name)\n            data = numpy.zeros(shape=(1, 1, 28, 28))\n            predictor.predict(data)\n        finally:\n            mx.delete_endpoint()\n\n\n@pytest.mark.local_mode\ndef test_mxnet_training_failure(sagemaker_local_session, mxnet_full_version, tmpdir):\n    script_path = os.path.join(DATA_DIR, ""mxnet_mnist"", ""failure_script.py"")\n\n    mx = MXNet(\n        entry_point=script_path,\n        role=""SageMakerRole"",\n        framework_version=mxnet_full_version,\n        py_version=PYTHON_VERSION,\n        train_instance_count=1,\n        train_instance_type=""local"",\n        sagemaker_session=sagemaker_local_session,\n        code_location=""s3://{}"".format(sagemaker_local_session.default_bucket()),\n        output_path=""file://{}"".format(tmpdir),\n    )\n\n    with pytest.raises(RuntimeError):\n        mx.fit()\n\n    with tarfile.open(os.path.join(str(tmpdir), ""output.tar.gz"")) as tar:\n        tar.getmember(""failure"")\n\n\n@pytest.mark.local_mode\ndef test_local_transform_mxnet(\n    sagemaker_local_session, tmpdir, mxnet_full_version, cpu_instance_type\n):\n    data_path = os.path.join(DATA_DIR, ""mxnet_mnist"")\n    script_path = os.path.join(data_path, ""mnist.py"")\n\n    mx = MXNet(\n        entry_point=script_path,\n        role=""SageMakerRole"",\n        train_instance_count=1,\n        train_instance_type=""local"",\n        framework_version=mxnet_full_version,\n        sagemaker_session=sagemaker_local_session,\n    )\n\n    train_input = mx.sagemaker_session.upload_data(\n        path=os.path.join(data_path, ""train""), key_prefix=""integ-test-data/mxnet_mnist/train""\n    )\n    test_input = mx.sagemaker_session.upload_data(\n        path=os.path.join(data_path, ""test""), key_prefix=""integ-test-data/mxnet_mnist/test""\n    )\n\n    with stopit.ThreadingTimeout(5 * 60, swallow_exc=False):\n        mx.fit({""train"": train_input, ""test"": test_input})\n\n    transform_input_path = os.path.join(data_path, ""transform"")\n    transform_input_key_prefix = ""integ-test-data/mxnet_mnist/transform""\n    transform_input = mx.sagemaker_session.upload_data(\n        path=transform_input_path, key_prefix=transform_input_key_prefix\n    )\n\n    output_path = ""file://%s"" % (str(tmpdir))\n    transformer = mx.transformer(\n        1,\n        ""local"",\n        assemble_with=""Line"",\n        max_payload=1,\n        strategy=""SingleRecord"",\n        output_path=output_path,\n    )\n\n    with lock.lock(LOCK_PATH):\n        transformer.transform(transform_input, content_type=""text/csv"", split_type=""Line"")\n        transformer.wait()\n\n    assert os.path.exists(os.path.join(str(tmpdir), ""data.csv.out""))\n'"
tests/integ/test_marketplace.py,0,"b'# Copyright 2018-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport itertools\nimport os\nimport time\n\nimport pandas\nimport pytest\n\nimport sagemaker\nimport tests.integ\nfrom sagemaker import AlgorithmEstimator, ModelPackage\nfrom sagemaker.tuner import IntegerParameter, HyperparameterTuner\nfrom sagemaker.utils import sagemaker_timestamp\nfrom sagemaker.utils import _aws_partition\nfrom tests.integ import DATA_DIR\nfrom tests.integ.timeout import timeout, timeout_and_delete_endpoint_by_name\nfrom tests.integ.marketplace_utils import REGION_ACCOUNT_MAP\n\n\n# All these tests require a manual 1 time subscription to the following Marketplace items:\n# Algorithm: Scikit Decision Trees\n# https://aws.amazon.com/marketplace/pp/prodview-ha4f3kqugba3u\n#\n# Pre-Trained Model: Scikit Decision Trees - Pretrained Model\n# https://aws.amazon.com/marketplace/pp/prodview-7qop4x5ahrdhe\n#\n# Both are written by Amazon and are free to subscribe.\n\nALGORITHM_ARN = (\n    ""arn:{partition}:sagemaker:{region}:{account}:algorithm/scikit-decision-trees-""\n    ""15423055-57b73412d2e93e9239e4e16f83298b8f""\n)\n\nMODEL_PACKAGE_ARN = (\n    ""arn:{partition}:sagemaker:{region}:{account}:model-package/scikit-iris-detector-""\n    ""154230595-8f00905c1f927a512b73ea29dd09ae30""\n)\n\n\n@pytest.mark.canary_quick\n@pytest.mark.skipif(\n    tests.integ.test_region() in tests.integ.NO_MARKET_PLACE_REGIONS,\n    reason=""Marketplace is not available in {}"".format(tests.integ.test_region()),\n)\n@pytest.mark.skip(\n    reason=""This test has always failed, but the failure was masked by a bug. ""\n    ""This test should be fixed. Details in https://github.com/aws/sagemaker-python-sdk/pull/968""\n)\ndef test_marketplace_estimator(sagemaker_session, cpu_instance_type):\n    with timeout(minutes=15):\n        data_path = os.path.join(DATA_DIR, ""marketplace"", ""training"")\n        region = sagemaker_session.boto_region_name\n        account = REGION_ACCOUNT_MAP[region]\n        algorithm_arn = ALGORITHM_ARN.format(\n            partition=_aws_partition(region), region=region, account=account\n        )\n\n        algo = AlgorithmEstimator(\n            algorithm_arn=algorithm_arn,\n            role=""SageMakerRole"",\n            train_instance_count=1,\n            train_instance_type=cpu_instance_type,\n            sagemaker_session=sagemaker_session,\n        )\n\n        train_input = algo.sagemaker_session.upload_data(\n            path=data_path, key_prefix=""integ-test-data/marketplace/train""\n        )\n\n        algo.fit({""training"": train_input})\n\n    endpoint_name = ""test-marketplace-estimator{}"".format(sagemaker_timestamp())\n    with timeout_and_delete_endpoint_by_name(endpoint_name, sagemaker_session, minutes=20):\n        predictor = algo.deploy(1, cpu_instance_type, endpoint_name=endpoint_name)\n        shape = pandas.read_csv(os.path.join(data_path, ""iris.csv""), header=None)\n\n        a = [50 * i for i in range(3)]\n        b = [40 + i for i in range(10)]\n        indices = [i + j for i, j in itertools.product(a, b)]\n\n        test_data = shape.iloc[indices[:-1]]\n        test_x = test_data.iloc[:, 1:]\n\n        print(predictor.predict(test_x.values).decode(""utf-8""))\n\n\n@pytest.mark.skipif(\n    tests.integ.test_region() in tests.integ.NO_MARKET_PLACE_REGIONS,\n    reason=""Marketplace is not available in {}"".format(tests.integ.test_region()),\n)\ndef test_marketplace_attach(sagemaker_session, cpu_instance_type):\n    with timeout(minutes=15):\n        data_path = os.path.join(DATA_DIR, ""marketplace"", ""training"")\n        region = sagemaker_session.boto_region_name\n        account = REGION_ACCOUNT_MAP[region]\n        algorithm_arn = ALGORITHM_ARN.format(\n            partition=_aws_partition(region), region=region, account=account\n        )\n\n        mktplace = AlgorithmEstimator(\n            algorithm_arn=algorithm_arn,\n            role=""SageMakerRole"",\n            train_instance_count=1,\n            train_instance_type=cpu_instance_type,\n            sagemaker_session=sagemaker_session,\n            base_job_name=""test-marketplace"",\n        )\n\n        train_input = mktplace.sagemaker_session.upload_data(\n            path=data_path, key_prefix=""integ-test-data/marketplace/train""\n        )\n\n        mktplace.fit({""training"": train_input}, wait=False)\n        training_job_name = mktplace.latest_training_job.name\n\n        print(""Waiting to re-attach to the training job: %s"" % training_job_name)\n        time.sleep(20)\n        endpoint_name = ""test-marketplace-estimator{}"".format(sagemaker_timestamp())\n\n    with timeout_and_delete_endpoint_by_name(endpoint_name, sagemaker_session, minutes=20):\n        print(""Re-attaching now to: %s"" % training_job_name)\n        estimator = AlgorithmEstimator.attach(\n            training_job_name=training_job_name, sagemaker_session=sagemaker_session\n        )\n        predictor = estimator.deploy(\n            1,\n            cpu_instance_type,\n            endpoint_name=endpoint_name,\n            serializer=sagemaker.predictor.csv_serializer,\n        )\n        shape = pandas.read_csv(os.path.join(data_path, ""iris.csv""), header=None)\n        a = [50 * i for i in range(3)]\n        b = [40 + i for i in range(10)]\n        indices = [i + j for i, j in itertools.product(a, b)]\n\n        test_data = shape.iloc[indices[:-1]]\n        test_x = test_data.iloc[:, 1:]\n\n        print(predictor.predict(test_x.values).decode(""utf-8""))\n\n\n@pytest.mark.canary_quick\n@pytest.mark.skipif(\n    tests.integ.test_region() in tests.integ.NO_MARKET_PLACE_REGIONS,\n    reason=""Marketplace is not available in {}"".format(tests.integ.test_region()),\n)\ndef test_marketplace_model(sagemaker_session, cpu_instance_type):\n    region = sagemaker_session.boto_region_name\n    account = REGION_ACCOUNT_MAP[region]\n    model_package_arn = MODEL_PACKAGE_ARN.format(\n        partition=_aws_partition(region), region=region, account=account\n    )\n\n    def predict_wrapper(endpoint, session):\n        return sagemaker.RealTimePredictor(\n            endpoint, session, serializer=sagemaker.predictor.csv_serializer\n        )\n\n    model = ModelPackage(\n        role=""SageMakerRole"",\n        model_package_arn=model_package_arn,\n        sagemaker_session=sagemaker_session,\n        predictor_cls=predict_wrapper,\n    )\n\n    endpoint_name = ""test-marketplace-model-endpoint{}"".format(sagemaker_timestamp())\n    with timeout_and_delete_endpoint_by_name(endpoint_name, sagemaker_session, minutes=20):\n        predictor = model.deploy(1, cpu_instance_type, endpoint_name=endpoint_name)\n        data_path = os.path.join(DATA_DIR, ""marketplace"", ""training"")\n        shape = pandas.read_csv(os.path.join(data_path, ""iris.csv""), header=None)\n        a = [50 * i for i in range(3)]\n        b = [40 + i for i in range(10)]\n        indices = [i + j for i, j in itertools.product(a, b)]\n\n        test_data = shape.iloc[indices[:-1]]\n        test_x = test_data.iloc[:, 1:]\n\n        print(predictor.predict(test_x.values).decode(""utf-8""))\n\n\n@pytest.mark.skipif(\n    tests.integ.test_region() in tests.integ.NO_MARKET_PLACE_REGIONS,\n    reason=""Marketplace is not available in {}"".format(tests.integ.test_region()),\n)\ndef test_marketplace_tuning_job(sagemaker_session, cpu_instance_type):\n    data_path = os.path.join(DATA_DIR, ""marketplace"", ""training"")\n    region = sagemaker_session.boto_region_name\n    account = REGION_ACCOUNT_MAP[region]\n    algorithm_arn = ALGORITHM_ARN.format(\n        partition=_aws_partition(region), region=region, account=account\n    )\n\n    mktplace = AlgorithmEstimator(\n        algorithm_arn=algorithm_arn,\n        role=""SageMakerRole"",\n        train_instance_count=1,\n        train_instance_type=cpu_instance_type,\n        sagemaker_session=sagemaker_session,\n        base_job_name=""test-marketplace"",\n    )\n\n    train_input = mktplace.sagemaker_session.upload_data(\n        path=data_path, key_prefix=""integ-test-data/marketplace/train""\n    )\n\n    mktplace.set_hyperparameters(max_leaf_nodes=10)\n\n    hyperparameter_ranges = {""max_leaf_nodes"": IntegerParameter(1, 100000)}\n\n    tuner = HyperparameterTuner(\n        estimator=mktplace,\n        base_tuning_job_name=""byo"",\n        objective_metric_name=""validation:accuracy"",\n        hyperparameter_ranges=hyperparameter_ranges,\n        max_jobs=2,\n        max_parallel_jobs=2,\n    )\n\n    tuner.fit({""training"": train_input}, include_cls_metadata=False)\n    time.sleep(15)\n    tuner.wait()\n\n\n@pytest.mark.skipif(\n    tests.integ.test_region() in tests.integ.NO_MARKET_PLACE_REGIONS,\n    reason=""Marketplace is not available in {}"".format(tests.integ.test_region()),\n)\ndef test_marketplace_transform_job(sagemaker_session, cpu_instance_type):\n    data_path = os.path.join(DATA_DIR, ""marketplace"", ""training"")\n    region = sagemaker_session.boto_region_name\n    account = REGION_ACCOUNT_MAP[region]\n    algorithm_arn = ALGORITHM_ARN.format(\n        partition=_aws_partition(region), region=region, account=account\n    )\n\n    algo = AlgorithmEstimator(\n        algorithm_arn=algorithm_arn,\n        role=""SageMakerRole"",\n        train_instance_count=1,\n        train_instance_type=cpu_instance_type,\n        sagemaker_session=sagemaker_session,\n        base_job_name=""test-marketplace"",\n    )\n\n    train_input = algo.sagemaker_session.upload_data(\n        path=data_path, key_prefix=""integ-test-data/marketplace/train""\n    )\n\n    shape = pandas.read_csv(data_path + ""/iris.csv"", header=None).drop([0], axis=1)\n\n    transform_workdir = DATA_DIR + ""/marketplace/transform""\n    shape.to_csv(transform_workdir + ""/batchtransform_test.csv"", index=False, header=False)\n    transform_input = algo.sagemaker_session.upload_data(\n        transform_workdir, key_prefix=""integ-test-data/marketplace/transform""\n    )\n\n    algo.fit({""training"": train_input})\n\n    transformer = algo.transformer(1, cpu_instance_type)\n    transformer.transform(transform_input, content_type=""text/csv"")\n    transformer.wait()\n\n\n@pytest.mark.skipif(\n    tests.integ.test_region() in tests.integ.NO_MARKET_PLACE_REGIONS,\n    reason=""Marketplace is not available in {}"".format(tests.integ.test_region()),\n)\ndef test_marketplace_transform_job_from_model_package(sagemaker_session, cpu_instance_type):\n    data_path = os.path.join(DATA_DIR, ""marketplace"", ""training"")\n    shape = pandas.read_csv(data_path + ""/iris.csv"", header=None).drop([0], axis=1)\n\n    TRANSFORM_WORKDIR = DATA_DIR + ""/marketplace/transform""\n    shape.to_csv(TRANSFORM_WORKDIR + ""/batchtransform_test.csv"", index=False, header=False)\n    transform_input = sagemaker_session.upload_data(\n        TRANSFORM_WORKDIR, key_prefix=""integ-test-data/marketplace/transform""\n    )\n\n    region = sagemaker_session.boto_region_name\n    account = REGION_ACCOUNT_MAP[region]\n    model_package_arn = MODEL_PACKAGE_ARN.format(\n        partition=_aws_partition(region), region=region, account=account\n    )\n\n    model = ModelPackage(\n        role=""SageMakerRole"",\n        model_package_arn=model_package_arn,\n        sagemaker_session=sagemaker_session,\n    )\n\n    transformer = model.transformer(1, cpu_instance_type)\n    transformer.transform(transform_input, content_type=""text/csv"")\n    transformer.wait()\n'"
tests/integ/test_model_monitor.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport json\nimport os\nimport uuid\n\nimport pytest\n\nimport tests.integ\nimport tests.integ.timeout\n\nfrom sagemaker.s3 import S3Uploader\nfrom datetime import datetime, timedelta\n\nfrom tests.integ import DATA_DIR\nfrom sagemaker.model_monitor import DatasetFormat\nfrom sagemaker.model_monitor import NetworkConfig, Statistics, Constraints\nfrom sagemaker.model_monitor import ModelMonitor\nfrom sagemaker.model_monitor import DefaultModelMonitor\nfrom sagemaker.model_monitor import MonitoringOutput\nfrom sagemaker.model_monitor import DataCaptureConfig\nfrom sagemaker.model_monitor.data_capture_config import _MODEL_MONITOR_S3_PATH\nfrom sagemaker.model_monitor.data_capture_config import _DATA_CAPTURE_S3_PATH\nfrom sagemaker.model_monitor import CronExpressionGenerator\nfrom sagemaker.processing import ProcessingInput\nfrom sagemaker.processing import ProcessingOutput\nfrom sagemaker.tensorflow.serving import Model\nfrom sagemaker.utils import unique_name_from_base\n\nfrom tests.integ.kms_utils import get_or_create_kms_key\nfrom tests.integ.retry import retries\n\nROLE = ""SageMakerRole""\nINSTANCE_COUNT = 1\nINSTANCE_TYPE = ""ml.m5.xlarge""\nVOLUME_SIZE_IN_GB = 40\nMAX_RUNTIME_IN_SECONDS = 45 * 60\nENV_KEY_1 = ""env_key_1""\nENV_VALUE_1 = ""env_key_1""\nENVIRONMENT = {ENV_KEY_1: ENV_VALUE_1}\nTAG_KEY_1 = ""tag_key_1""\nTAG_VALUE_1 = ""tag_value_1""\nTAGS = [{""Key"": TAG_KEY_1, ""Value"": TAG_VALUE_1}]\nNETWORK_CONFIG = NetworkConfig(enable_network_isolation=True)\nENABLE_CLOUDWATCH_METRICS = True\n\nDEFAULT_INSTANCE_TYPE = ""ml.m5.xlarge""\nDEFAULT_INSTANCE_COUNT = 1\nDEFAULT_VOLUME_SIZE_IN_GB = 30\nDEFAULT_BASELINING_MAX_RUNTIME_IN_SECONDS = 86400\nDEFAULT_EXECUTION_MAX_RUNTIME_IN_SECONDS = 3600\nDEFAULT_IMAGE_SUFFIX = ""/sagemaker-model-monitor-analyzer""\n\nUPDATED_ROLE = ""SageMakerRole""\nUPDATED_INSTANCE_COUNT = 2\nUPDATED_INSTANCE_TYPE = ""ml.m5.2xlarge""\nUPDATED_VOLUME_SIZE_IN_GB = 50\nUPDATED_MAX_RUNTIME_IN_SECONDS = 46 * 2\nUPDATED_ENV_KEY_1 = ""env_key_2""\nUPDATED_ENV_VALUE_1 = ""env_key_2""\nUPDATED_ENVIRONMENT = {UPDATED_ENV_KEY_1: UPDATED_ENV_VALUE_1}\nUPDATED_TAG_KEY_1 = ""tag_key_2""\nUPDATED_TAG_VALUE_1 = ""tag_value_2""\nUPDATED_TAGS = [{""Key"": TAG_KEY_1, ""Value"": TAG_VALUE_1}]\nUPDATED_NETWORK_CONFIG = NetworkConfig(enable_network_isolation=False)\nDISABLE_CLOUDWATCH_METRICS = False\n\nCUSTOM_SAMPLING_PERCENTAGE = 10\nCUSTOM_CAPTURE_OPTIONS = [""REQUEST""]\nCUSTOM_CSV_CONTENT_TYPES = [""text/csvtype1"", ""text/csvtype2""]\nCUSTOM_JSON_CONTENT_TYPES = [""application/jsontype1"", ""application/jsontype2""]\n\nINTEG_TEST_MONITORING_OUTPUT_BUCKET = ""integ-test-monitoring-output-bucket""\n\nFIVE_MINUTE_CRON_EXPRESSION = ""cron(0/5 * ? * * *)""\n\n\n@pytest.fixture(scope=""module"")\ndef predictor(sagemaker_session, tf_serving_version):\n    endpoint_name = unique_name_from_base(""sagemaker-tensorflow-serving"")\n    model_data = sagemaker_session.upload_data(\n        path=os.path.join(tests.integ.DATA_DIR, ""tensorflow-serving-test-model.tar.gz""),\n        key_prefix=""tensorflow-serving/models"",\n    )\n    with tests.integ.timeout.timeout_and_delete_endpoint_by_name(\n        endpoint_name=endpoint_name, sagemaker_session=sagemaker_session, hours=2\n    ):\n        model = Model(\n            model_data=model_data,\n            role=ROLE,\n            framework_version=tf_serving_version,\n            sagemaker_session=sagemaker_session,\n        )\n        predictor = model.deploy(\n            INSTANCE_COUNT,\n            INSTANCE_TYPE,\n            endpoint_name=endpoint_name,\n            data_capture_config=DataCaptureConfig(True, sagemaker_session=sagemaker_session),\n        )\n        yield predictor\n\n\n@pytest.fixture(scope=""module"")\ndef default_monitoring_schedule_name(sagemaker_session, output_kms_key, volume_kms_key, predictor):\n    my_default_monitor = DefaultModelMonitor(\n        role=ROLE,\n        instance_count=INSTANCE_COUNT,\n        instance_type=INSTANCE_TYPE,\n        volume_size_in_gb=VOLUME_SIZE_IN_GB,\n        volume_kms_key=volume_kms_key,\n        output_kms_key=output_kms_key,\n        max_runtime_in_seconds=MAX_RUNTIME_IN_SECONDS,\n        sagemaker_session=sagemaker_session,\n        env=ENVIRONMENT,\n        tags=TAGS,\n        network_config=NETWORK_CONFIG,\n    )\n\n    output_s3_uri = os.path.join(\n        ""s3://"",\n        sagemaker_session.default_bucket(),\n        ""integ-test-monitoring-output-bucket"",\n        str(uuid.uuid4()),\n    )\n\n    statistics = Statistics.from_file_path(\n        statistics_file_path=os.path.join(tests.integ.DATA_DIR, ""monitor/statistics.json""),\n        sagemaker_session=sagemaker_session,\n    )\n\n    constraints = Constraints.from_file_path(\n        constraints_file_path=os.path.join(tests.integ.DATA_DIR, ""monitor/constraints.json""),\n        sagemaker_session=sagemaker_session,\n    )\n\n    my_default_monitor.create_monitoring_schedule(\n        endpoint_input=predictor.endpoint,\n        output_s3_uri=output_s3_uri,\n        statistics=statistics,\n        constraints=constraints,\n        schedule_cron_expression=FIVE_MINUTE_CRON_EXPRESSION,\n        enable_cloudwatch_metrics=ENABLE_CLOUDWATCH_METRICS,\n    )\n\n    _wait_for_schedule_changes_to_apply(monitor=my_default_monitor)\n\n    _upload_captured_data_to_endpoint(predictor=predictor, sagemaker_session=sagemaker_session)\n\n    _predict_while_waiting_for_first_monitoring_job_to_complete(predictor, my_default_monitor)\n\n    return my_default_monitor.monitoring_schedule_name\n\n\n@pytest.fixture(scope=""module"")\ndef byoc_monitoring_schedule_name(sagemaker_session, output_kms_key, volume_kms_key, predictor):\n    byoc_env = ENVIRONMENT.copy()\n    byoc_env[""dataset_format""] = json.dumps(DatasetFormat.csv(header=False))\n    byoc_env[""dataset_source""] = ""/opt/ml/processing/input/baseline_dataset_input""\n    byoc_env[""output_path""] = os.path.join(""/opt/ml/processing/output"")\n    byoc_env[""publish_cloudwatch_metrics""] = ""Disabled""\n\n    my_byoc_monitor = ModelMonitor(\n        role=ROLE,\n        image_uri=DefaultModelMonitor._get_default_image_uri(\n            sagemaker_session.boto_session.region_name\n        ),\n        instance_count=INSTANCE_COUNT,\n        instance_type=INSTANCE_TYPE,\n        volume_size_in_gb=VOLUME_SIZE_IN_GB,\n        volume_kms_key=volume_kms_key,\n        output_kms_key=output_kms_key,\n        max_runtime_in_seconds=MAX_RUNTIME_IN_SECONDS,\n        sagemaker_session=sagemaker_session,\n        env=byoc_env,\n        tags=TAGS,\n        network_config=NETWORK_CONFIG,\n    )\n\n    output_s3_uri = os.path.join(\n        ""s3://"",\n        sagemaker_session.default_bucket(),\n        ""integ-test-monitoring-output-bucket"",\n        str(uuid.uuid4()),\n    )\n\n    statistics = Statistics.from_file_path(\n        statistics_file_path=os.path.join(tests.integ.DATA_DIR, ""monitor/statistics.json""),\n        sagemaker_session=sagemaker_session,\n    )\n\n    constraints = Constraints.from_file_path(\n        constraints_file_path=os.path.join(tests.integ.DATA_DIR, ""monitor/constraints.json""),\n        sagemaker_session=sagemaker_session,\n    )\n\n    my_byoc_monitor.create_monitoring_schedule(\n        endpoint_input=predictor.endpoint,\n        output=MonitoringOutput(source=""/opt/ml/processing/output"", destination=output_s3_uri),\n        statistics=statistics,\n        constraints=constraints,\n        schedule_cron_expression=FIVE_MINUTE_CRON_EXPRESSION,\n    )\n\n    _wait_for_schedule_changes_to_apply(monitor=my_byoc_monitor)\n\n    _upload_captured_data_to_endpoint(predictor=predictor, sagemaker_session=sagemaker_session)\n\n    _predict_while_waiting_for_first_monitoring_job_to_complete(predictor, my_byoc_monitor)\n\n    return my_byoc_monitor.monitoring_schedule_name\n\n\n@pytest.fixture(scope=""module"")\ndef volume_kms_key(sagemaker_session):\n    role_arn = sagemaker_session.expand_role(ROLE)\n    return get_or_create_kms_key(\n        sagemaker_session=sagemaker_session,\n        role_arn=role_arn,\n        alias=""integ-test-processing-volume-kms-key-{}"".format(\n            sagemaker_session.boto_session.region_name\n        ),\n    )\n\n\n@pytest.fixture(scope=""module"")\ndef output_kms_key(sagemaker_session):\n    role_arn = sagemaker_session.expand_role(ROLE)\n    return get_or_create_kms_key(\n        sagemaker_session=sagemaker_session,\n        role_arn=role_arn,\n        alias=""integ-test-processing-output-kms-key-{}"".format(\n            sagemaker_session.boto_session.region_name\n        ),\n    )\n\n\n@pytest.fixture(scope=""module"")\ndef updated_volume_kms_key(sagemaker_session):\n    role_arn = sagemaker_session.expand_role(ROLE)\n    return get_or_create_kms_key(\n        sagemaker_session=sagemaker_session,\n        role_arn=role_arn,\n        alias=""integ-test-processing-volume-kms-key-updated-{}"".format(\n            sagemaker_session.boto_session.region_name\n        ),\n    )\n\n\n@pytest.fixture(scope=""module"")\ndef updated_output_kms_key(sagemaker_session):\n    role_arn = sagemaker_session.expand_role(ROLE)\n    return get_or_create_kms_key(\n        sagemaker_session=sagemaker_session,\n        role_arn=role_arn,\n        alias=""integ-test-processing-output-kms-key-updated-{}"".format(\n            sagemaker_session.boto_session.region_name\n        ),\n    )\n\n\n@pytest.mark.skipif(\n    tests.integ.test_region() in tests.integ.NO_MODEL_MONITORING_REGIONS,\n    reason=""ModelMonitoring is not yet supported in this region."",\n)\n@pytest.mark.canary_quick\ndef test_default_monitor_suggest_baseline_and_create_monitoring_schedule_with_customizations(\n    sagemaker_session, output_kms_key, volume_kms_key, predictor\n):\n    baseline_dataset = os.path.join(DATA_DIR, ""monitor/baseline_dataset.csv"")\n\n    my_default_monitor = DefaultModelMonitor(\n        role=ROLE,\n        instance_count=INSTANCE_COUNT,\n        instance_type=INSTANCE_TYPE,\n        volume_size_in_gb=VOLUME_SIZE_IN_GB,\n        volume_kms_key=volume_kms_key,\n        output_kms_key=output_kms_key,\n        max_runtime_in_seconds=MAX_RUNTIME_IN_SECONDS,\n        sagemaker_session=sagemaker_session,\n        env=ENVIRONMENT,\n        tags=TAGS,\n        network_config=NETWORK_CONFIG,\n    )\n\n    output_s3_uri = os.path.join(\n        ""s3://"",\n        sagemaker_session.default_bucket(),\n        INTEG_TEST_MONITORING_OUTPUT_BUCKET,\n        str(uuid.uuid4()),\n    )\n\n    my_default_monitor.suggest_baseline(\n        baseline_dataset=baseline_dataset,\n        dataset_format=DatasetFormat.csv(header=False),\n        output_s3_uri=output_s3_uri,\n        wait=True,\n        logs=False,\n    )\n\n    baselining_job_description = my_default_monitor.latest_baselining_job.describe()\n\n    assert (\n        baselining_job_description[""ProcessingResources""][""ClusterConfig""][""InstanceType""]\n        == INSTANCE_TYPE\n    )\n    assert (\n        baselining_job_description[""ProcessingResources""][""ClusterConfig""][""InstanceCount""]\n        == INSTANCE_COUNT\n    )\n    assert (\n        baselining_job_description[""ProcessingResources""][""ClusterConfig""][""VolumeSizeInGB""]\n        == VOLUME_SIZE_IN_GB\n    )\n    assert (\n        baselining_job_description[""ProcessingResources""][""ClusterConfig""][""VolumeKmsKeyId""]\n        == volume_kms_key\n    )\n    assert DEFAULT_IMAGE_SUFFIX in baselining_job_description[""AppSpecification""][""ImageUri""]\n    assert ROLE in baselining_job_description[""RoleArn""]\n    assert (\n        baselining_job_description[""ProcessingInputs""][0][""InputName""] == ""baseline_dataset_input""\n    )\n    assert (\n        baselining_job_description[""ProcessingOutputConfig""][""Outputs""][0][""OutputName""]\n        == ""monitoring_output""\n    )\n    assert baselining_job_description[""ProcessingOutputConfig""][""KmsKeyId""] == output_kms_key\n    assert baselining_job_description[""Environment""][ENV_KEY_1] == ENV_VALUE_1\n    assert baselining_job_description[""Environment""][""output_path""] == ""/opt/ml/processing/output""\n    assert (\n        baselining_job_description[""Environment""][""dataset_source""]\n        == ""/opt/ml/processing/input/baseline_dataset_input""\n    )\n    assert (\n        baselining_job_description[""StoppingCondition""][""MaxRuntimeInSeconds""]\n        == MAX_RUNTIME_IN_SECONDS\n    )\n    assert (\n        baselining_job_description[""NetworkConfig""][""EnableNetworkIsolation""]\n        == NETWORK_CONFIG.enable_network_isolation\n    )\n\n    statistics = my_default_monitor.baseline_statistics()\n    assert statistics.body_dict[""dataset""][""item_count""] == 418\n\n    constraints = my_default_monitor.suggested_constraints()\n    assert constraints.body_dict[""monitoring_config""][""evaluate_constraints""] == ""Enabled""\n\n    constraints.set_monitoring(enable_monitoring=False)\n\n    assert constraints.body_dict[""monitoring_config""][""evaluate_constraints""] == ""Disabled""\n\n    constraints.save()\n\n    my_default_monitor.create_monitoring_schedule(\n        endpoint_input=predictor.endpoint,\n        output_s3_uri=output_s3_uri,\n        statistics=my_default_monitor.baseline_statistics(),\n        constraints=my_default_monitor.suggested_constraints(),\n        schedule_cron_expression=CronExpressionGenerator.daily(),\n        enable_cloudwatch_metrics=ENABLE_CLOUDWATCH_METRICS,\n    )\n\n    schedule_description = my_default_monitor.describe_schedule()\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""ScheduleConfig""][""ScheduleExpression""]\n        == CronExpressionGenerator.daily()\n    )\n    assert (\n        ""sagemaker-tensorflow-serving""\n        in schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringInputs""\n        ][0][""EndpointInput""][""EndpointName""]\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""InstanceCount""]\n        == INSTANCE_COUNT\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""InstanceType""]\n        == INSTANCE_TYPE\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""VolumeSizeInGB""]\n        == VOLUME_SIZE_IN_GB\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""VolumeKmsKeyId""]\n        == volume_kms_key\n    )\n    assert (\n        DEFAULT_IMAGE_SUFFIX\n        in schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringAppSpecification""\n        ][""ImageUri""]\n    )\n    assert (\n        ROLE\n        in schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][""RoleArn""]\n    )\n    assert (\n        len(\n            schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n                ""MonitoringOutputConfig""\n            ][""MonitoringOutputs""]\n        )\n        == 1\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringOutputConfig""\n        ][""KmsKeyId""]\n        == output_kms_key\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""BaselineConfig""\n        ][""StatisticsResource""][""S3Uri""]\n        is not None\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""BaselineConfig""\n        ][""ConstraintsResource""][""S3Uri""]\n        is not None\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""StoppingCondition""\n        ][""MaxRuntimeInSeconds""]\n        == MAX_RUNTIME_IN_SECONDS\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][""Environment""][\n            ENV_KEY_1\n        ]\n        == ENV_VALUE_1\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][""Environment""][\n            ""publish_cloudwatch_metrics""\n        ]\n        == ""Enabled""\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""NetworkConfig""\n        ][""EnableNetworkIsolation""]\n        == NETWORK_CONFIG.enable_network_isolation\n    )\n\n    summary = sagemaker_session.list_monitoring_schedules()\n    assert len(summary[""MonitoringScheduleSummaries""]) > 0\n\n\n@pytest.mark.skipif(\n    tests.integ.test_region() in tests.integ.NO_MODEL_MONITORING_REGIONS,\n    reason=""ModelMonitoring is not yet supported in this region."",\n)\ndef test_default_monitor_suggest_baseline_and_create_monitoring_schedule_without_customizations(\n    sagemaker_session, predictor\n):\n    baseline_dataset = os.path.join(DATA_DIR, ""monitor/baseline_dataset.csv"")\n\n    my_default_monitor = DefaultModelMonitor(role=ROLE, sagemaker_session=sagemaker_session)\n\n    my_default_monitor.suggest_baseline(\n        baseline_dataset=baseline_dataset,\n        dataset_format=DatasetFormat.csv(header=False),\n        logs=False,\n    )\n\n    baselining_job_description = my_default_monitor.latest_baselining_job.describe()\n\n    assert (\n        baselining_job_description[""ProcessingResources""][""ClusterConfig""][""InstanceType""]\n        == DEFAULT_INSTANCE_TYPE\n    )\n    assert (\n        baselining_job_description[""ProcessingResources""][""ClusterConfig""][""InstanceCount""]\n        == DEFAULT_INSTANCE_COUNT\n    )\n    assert (\n        baselining_job_description[""ProcessingResources""][""ClusterConfig""][""VolumeSizeInGB""]\n        == DEFAULT_VOLUME_SIZE_IN_GB\n    )\n    assert (\n        baselining_job_description[""ProcessingResources""][""ClusterConfig""].get(""VolumeKmsKeyId"")\n        is None\n    )\n    assert DEFAULT_IMAGE_SUFFIX in baselining_job_description[""AppSpecification""][""ImageUri""]\n    assert ROLE in baselining_job_description[""RoleArn""]\n    assert (\n        baselining_job_description[""ProcessingInputs""][0][""InputName""] == ""baseline_dataset_input""\n    )\n    assert len(baselining_job_description[""ProcessingInputs""]) == 1\n    assert (\n        baselining_job_description[""ProcessingOutputConfig""][""Outputs""][0][""OutputName""]\n        == ""monitoring_output""\n    )\n    assert baselining_job_description[""ProcessingOutputConfig""].get(""KmsKeyId"") is None\n    assert baselining_job_description[""Environment""].get(ENV_KEY_1) is None\n    assert baselining_job_description[""Environment""][""output_path""] == ""/opt/ml/processing/output""\n    assert baselining_job_description[""Environment""].get(""record_preprocessor_script"") is None\n    assert baselining_job_description[""Environment""].get(""post_analytics_processor_script"") is None\n    assert (\n        baselining_job_description[""Environment""][""dataset_source""]\n        == ""/opt/ml/processing/input/baseline_dataset_input""\n    )\n    assert (\n        baselining_job_description[""StoppingCondition""][""MaxRuntimeInSeconds""]\n        == DEFAULT_BASELINING_MAX_RUNTIME_IN_SECONDS\n    )\n    assert baselining_job_description.get(""NetworkConfig"") is None\n\n    statistics = my_default_monitor.baseline_statistics()\n    assert statistics.body_dict[""dataset""][""item_count""] == 418\n\n    constraints = my_default_monitor.suggested_constraints()\n    assert constraints.body_dict[""monitoring_config""][""evaluate_constraints""] == ""Enabled""\n\n    constraints.set_monitoring(enable_monitoring=False)\n\n    assert constraints.body_dict[""monitoring_config""][""evaluate_constraints""] == ""Disabled""\n\n    constraints.save()\n\n    my_default_monitor.create_monitoring_schedule(\n        endpoint_input=predictor.endpoint, schedule_cron_expression=CronExpressionGenerator.daily()\n    )\n    schedule_description = my_default_monitor.describe_schedule()\n    assert (\n        ""sagemaker-tensorflow-serving""\n        in schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringInputs""\n        ][0][""EndpointInput""][""EndpointName""]\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""InstanceCount""]\n        == DEFAULT_INSTANCE_COUNT\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""InstanceType""]\n        == DEFAULT_INSTANCE_TYPE\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""VolumeSizeInGB""]\n        == DEFAULT_VOLUME_SIZE_IN_GB\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""].get(""VolumeKmsKeyId"")\n        is None\n    )\n    assert (\n        DEFAULT_IMAGE_SUFFIX\n        in schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringAppSpecification""\n        ][""ImageUri""]\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringAppSpecification""\n        ].get(""RecordPreprocessorSourceUri"")\n        is None\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringAppSpecification""\n        ].get(""PostAnalyticsProcessorSourceUri"")\n        is None\n    )\n    assert (\n        ROLE\n        in schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][""RoleArn""]\n    )\n    assert (\n        len(\n            schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n                ""MonitoringOutputConfig""\n            ][""MonitoringOutputs""]\n        )\n        == 1\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringOutputConfig""\n        ].get(""KmsKeyId"")\n        is None\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""].get(\n            ""BaselineConfig""\n        )\n        is None\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""].get(\n            ""BaselineConfig""\n        )\n        is None\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""Environment""\n        ].get(ENV_KEY_1)\n        is None\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][""Environment""][\n            ""publish_cloudwatch_metrics""\n        ]\n        == ""Enabled""\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""].get(\n            ""NetworkConfig""\n        )\n        is None\n    )\n\n    summary = sagemaker_session.list_monitoring_schedules()\n    assert len(summary[""MonitoringScheduleSummaries""]) > 0\n\n\n@pytest.mark.skipif(\n    tests.integ.test_region() in tests.integ.NO_MODEL_MONITORING_REGIONS,\n    reason=""ModelMonitoring is not yet supported in this region."",\n)\ndef test_default_monitor_create_stop_and_start_monitoring_schedule_with_customizations(\n    sagemaker_session, output_kms_key, volume_kms_key, predictor\n):\n\n    my_default_monitor = DefaultModelMonitor(\n        role=ROLE,\n        instance_count=INSTANCE_COUNT,\n        instance_type=INSTANCE_TYPE,\n        volume_size_in_gb=VOLUME_SIZE_IN_GB,\n        volume_kms_key=volume_kms_key,\n        output_kms_key=output_kms_key,\n        max_runtime_in_seconds=MAX_RUNTIME_IN_SECONDS,\n        sagemaker_session=sagemaker_session,\n        env=ENVIRONMENT,\n        tags=TAGS,\n        network_config=NETWORK_CONFIG,\n    )\n\n    output_s3_uri = os.path.join(\n        ""s3://"",\n        sagemaker_session.default_bucket(),\n        INTEG_TEST_MONITORING_OUTPUT_BUCKET,\n        str(uuid.uuid4()),\n    )\n\n    statistics = Statistics.from_file_path(\n        statistics_file_path=os.path.join(tests.integ.DATA_DIR, ""monitor/statistics.json""),\n        sagemaker_session=sagemaker_session,\n    )\n\n    constraints = Constraints.from_file_path(\n        constraints_file_path=os.path.join(tests.integ.DATA_DIR, ""monitor/constraints.json""),\n        sagemaker_session=sagemaker_session,\n    )\n\n    my_default_monitor.create_monitoring_schedule(\n        endpoint_input=predictor.endpoint,\n        output_s3_uri=output_s3_uri,\n        statistics=statistics,\n        constraints=constraints,\n        schedule_cron_expression=CronExpressionGenerator.daily(),\n        enable_cloudwatch_metrics=ENABLE_CLOUDWATCH_METRICS,\n    )\n\n    schedule_description = my_default_monitor.describe_schedule()\n\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""ScheduleConfig""][""ScheduleExpression""]\n        == CronExpressionGenerator.daily()\n    )\n    assert (\n        ""sagemaker-tensorflow-serving""\n        in schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringInputs""\n        ][0][""EndpointInput""][""EndpointName""]\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""InstanceCount""]\n        == INSTANCE_COUNT\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""InstanceType""]\n        == INSTANCE_TYPE\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""VolumeSizeInGB""]\n        == VOLUME_SIZE_IN_GB\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""VolumeKmsKeyId""]\n        == volume_kms_key\n    )\n    assert (\n        DEFAULT_IMAGE_SUFFIX\n        in schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringAppSpecification""\n        ][""ImageUri""]\n    )\n    assert (\n        ROLE\n        in schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][""RoleArn""]\n    )\n    assert (\n        len(\n            schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n                ""MonitoringOutputConfig""\n            ][""MonitoringOutputs""]\n        )\n        == 1\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringOutputConfig""\n        ][""KmsKeyId""]\n        == output_kms_key\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""BaselineConfig""\n        ][""StatisticsResource""][""S3Uri""]\n        is not None\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""BaselineConfig""\n        ][""ConstraintsResource""][""S3Uri""]\n        is not None\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""StoppingCondition""\n        ][""MaxRuntimeInSeconds""]\n        == MAX_RUNTIME_IN_SECONDS\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][""Environment""][\n            ENV_KEY_1\n        ]\n        == ENV_VALUE_1\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][""Environment""][\n            ""publish_cloudwatch_metrics""\n        ]\n        == ""Enabled""\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""NetworkConfig""\n        ][""EnableNetworkIsolation""]\n        == NETWORK_CONFIG.enable_network_isolation\n    )\n\n    _wait_for_schedule_changes_to_apply(monitor=my_default_monitor)\n\n    my_default_monitor.stop_monitoring_schedule()\n\n    _wait_for_schedule_changes_to_apply(monitor=my_default_monitor)\n\n    stopped_schedule_description = my_default_monitor.describe_schedule()\n    assert stopped_schedule_description[""MonitoringScheduleStatus""] == ""Stopped""\n\n    my_default_monitor.start_monitoring_schedule()\n\n    _wait_for_schedule_changes_to_apply(monitor=my_default_monitor)\n\n    started_schedule_description = my_default_monitor.describe_schedule()\n    assert started_schedule_description[""MonitoringScheduleStatus""] == ""Scheduled""\n\n    my_default_monitor.stop_monitoring_schedule()\n\n    _wait_for_schedule_changes_to_apply(monitor=my_default_monitor)\n\n\n@pytest.mark.skipif(\n    tests.integ.test_region() in tests.integ.NO_MODEL_MONITORING_REGIONS,\n    reason=""ModelMonitoring is not yet supported in this region."",\n)\ndef test_default_monitor_create_and_update_schedule_config_with_customizations(\n    sagemaker_session,\n    predictor,\n    volume_kms_key,\n    output_kms_key,\n    updated_volume_kms_key,\n    updated_output_kms_key,\n):\n    my_default_monitor = DefaultModelMonitor(\n        role=ROLE,\n        instance_count=INSTANCE_COUNT,\n        instance_type=INSTANCE_TYPE,\n        volume_size_in_gb=VOLUME_SIZE_IN_GB,\n        volume_kms_key=volume_kms_key,\n        output_kms_key=output_kms_key,\n        max_runtime_in_seconds=MAX_RUNTIME_IN_SECONDS,\n        sagemaker_session=sagemaker_session,\n        env=ENVIRONMENT,\n        tags=TAGS,\n        network_config=NETWORK_CONFIG,\n    )\n\n    output_s3_uri = os.path.join(\n        ""s3://"",\n        sagemaker_session.default_bucket(),\n        ""integ-test-monitoring-output-bucket"",\n        str(uuid.uuid4()),\n    )\n\n    statistics = Statistics.from_file_path(\n        statistics_file_path=os.path.join(tests.integ.DATA_DIR, ""monitor/statistics.json""),\n        sagemaker_session=sagemaker_session,\n    )\n\n    constraints = Constraints.from_file_path(\n        constraints_file_path=os.path.join(tests.integ.DATA_DIR, ""monitor/constraints.json""),\n        sagemaker_session=sagemaker_session,\n    )\n\n    my_default_monitor.create_monitoring_schedule(\n        endpoint_input=predictor.endpoint,\n        output_s3_uri=output_s3_uri,\n        statistics=statistics,\n        constraints=constraints,\n        schedule_cron_expression=CronExpressionGenerator.daily(),\n        enable_cloudwatch_metrics=ENABLE_CLOUDWATCH_METRICS,\n    )\n\n    schedule_description = my_default_monitor.describe_schedule()\n\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""ScheduleConfig""][""ScheduleExpression""]\n        == CronExpressionGenerator.daily()\n    )\n    assert (\n        ""sagemaker-tensorflow-serving""\n        in schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringInputs""\n        ][0][""EndpointInput""][""EndpointName""]\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""InstanceCount""]\n        == INSTANCE_COUNT\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""InstanceType""]\n        == INSTANCE_TYPE\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""VolumeSizeInGB""]\n        == VOLUME_SIZE_IN_GB\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""VolumeKmsKeyId""]\n        == volume_kms_key\n    )\n    assert (\n        DEFAULT_IMAGE_SUFFIX\n        in schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringAppSpecification""\n        ][""ImageUri""]\n    )\n    assert (\n        ROLE\n        in schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][""RoleArn""]\n    )\n    assert (\n        len(\n            schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n                ""MonitoringOutputConfig""\n            ][""MonitoringOutputs""]\n        )\n        == 1\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringOutputConfig""\n        ][""KmsKeyId""]\n        == output_kms_key\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""BaselineConfig""\n        ][""StatisticsResource""][""S3Uri""]\n        is not None\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""BaselineConfig""\n        ][""ConstraintsResource""][""S3Uri""]\n        is not None\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""StoppingCondition""\n        ][""MaxRuntimeInSeconds""]\n        == MAX_RUNTIME_IN_SECONDS\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][""Environment""][\n            ENV_KEY_1\n        ]\n        == ENV_VALUE_1\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][""Environment""][\n            ""publish_cloudwatch_metrics""\n        ]\n        == ""Enabled""\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""NetworkConfig""\n        ][""EnableNetworkIsolation""]\n        == NETWORK_CONFIG.enable_network_isolation\n    )\n\n    statistics = Statistics.from_file_path(\n        statistics_file_path=os.path.join(tests.integ.DATA_DIR, ""monitor/statistics.json""),\n        sagemaker_session=sagemaker_session,\n    )\n\n    constraints = Constraints.from_file_path(\n        constraints_file_path=os.path.join(tests.integ.DATA_DIR, ""monitor/constraints.json""),\n        sagemaker_session=sagemaker_session,\n    )\n\n    _wait_for_schedule_changes_to_apply(monitor=my_default_monitor)\n\n    my_default_monitor.update_monitoring_schedule(\n        output_s3_uri=output_s3_uri,\n        statistics=statistics,\n        constraints=constraints,\n        schedule_cron_expression=CronExpressionGenerator.hourly(),\n        instance_count=UPDATED_INSTANCE_COUNT,\n        instance_type=UPDATED_INSTANCE_TYPE,\n        volume_size_in_gb=UPDATED_VOLUME_SIZE_IN_GB,\n        volume_kms_key=updated_volume_kms_key,\n        output_kms_key=updated_output_kms_key,\n        max_runtime_in_seconds=UPDATED_MAX_RUNTIME_IN_SECONDS,\n        env=UPDATED_ENVIRONMENT,\n        network_config=UPDATED_NETWORK_CONFIG,\n        enable_cloudwatch_metrics=DISABLE_CLOUDWATCH_METRICS,\n        role=UPDATED_ROLE,\n    )\n\n    _wait_for_schedule_changes_to_apply(my_default_monitor)\n\n    schedule_description = my_default_monitor.describe_schedule()\n\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""ScheduleConfig""][""ScheduleExpression""]\n        == CronExpressionGenerator.hourly()\n    )\n    assert (\n        ""sagemaker-tensorflow-serving""\n        in schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringInputs""\n        ][0][""EndpointInput""][""EndpointName""]\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""InstanceCount""]\n        == UPDATED_INSTANCE_COUNT\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""InstanceType""]\n        == UPDATED_INSTANCE_TYPE\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""VolumeSizeInGB""]\n        == UPDATED_VOLUME_SIZE_IN_GB\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""VolumeKmsKeyId""]\n        == updated_volume_kms_key\n    )\n    assert (\n        DEFAULT_IMAGE_SUFFIX\n        in schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringAppSpecification""\n        ][""ImageUri""]\n    )\n    assert (\n        UPDATED_ROLE\n        in schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][""RoleArn""]\n    )\n    assert (\n        len(\n            schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n                ""MonitoringOutputConfig""\n            ][""MonitoringOutputs""]\n        )\n        == 1\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringOutputConfig""\n        ][""KmsKeyId""]\n        == updated_output_kms_key\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""BaselineConfig""\n        ][""StatisticsResource""][""S3Uri""]\n        == statistics.file_s3_uri\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""BaselineConfig""\n        ][""ConstraintsResource""][""S3Uri""]\n        == constraints.file_s3_uri\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""StoppingCondition""\n        ][""MaxRuntimeInSeconds""]\n        == UPDATED_MAX_RUNTIME_IN_SECONDS\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][""Environment""][\n            UPDATED_ENV_KEY_1\n        ]\n        == UPDATED_ENV_VALUE_1\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][""Environment""][\n            ""publish_cloudwatch_metrics""\n        ]\n        == ""Disabled""\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""NetworkConfig""\n        ][""EnableNetworkIsolation""]\n        == UPDATED_NETWORK_CONFIG.enable_network_isolation\n    )\n\n    _wait_for_schedule_changes_to_apply(monitor=my_default_monitor)\n\n    my_default_monitor.stop_monitoring_schedule()\n\n    _wait_for_schedule_changes_to_apply(monitor=my_default_monitor)\n\n    assert len(predictor.list_monitors()) > 0\n\n\n@pytest.mark.skipif(\n    tests.integ.test_region() in tests.integ.NO_MODEL_MONITORING_REGIONS,\n    reason=""ModelMonitoring is not yet supported in this region."",\n)\ndef test_default_monitor_create_and_update_schedule_config_without_customizations(\n    sagemaker_session, predictor\n):\n    my_default_monitor = DefaultModelMonitor(role=ROLE, sagemaker_session=sagemaker_session)\n\n    my_default_monitor.create_monitoring_schedule(\n        endpoint_input=predictor.endpoint, schedule_cron_expression=CronExpressionGenerator.daily()\n    )\n\n    schedule_description = my_default_monitor.describe_schedule()\n\n    assert (\n        ""sagemaker-tensorflow-serving""\n        in schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringInputs""\n        ][0][""EndpointInput""][""EndpointName""]\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""InstanceCount""]\n        == DEFAULT_INSTANCE_COUNT\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""InstanceType""]\n        == DEFAULT_INSTANCE_TYPE\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""VolumeSizeInGB""]\n        == DEFAULT_VOLUME_SIZE_IN_GB\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""].get(""VolumeKmsKeyId"")\n        is None\n    )\n    assert (\n        DEFAULT_IMAGE_SUFFIX\n        in schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringAppSpecification""\n        ][""ImageUri""]\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringAppSpecification""\n        ].get(""RecordPreprocessorSourceUri"")\n        is None\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringAppSpecification""\n        ].get(""PostAnalyticsProcessorSourceUri"")\n        is None\n    )\n    assert (\n        ROLE\n        in schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][""RoleArn""]\n    )\n    assert (\n        len(\n            schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n                ""MonitoringOutputConfig""\n            ][""MonitoringOutputs""]\n        )\n        == 1\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringOutputConfig""\n        ].get(""KmsKeyId"")\n        is None\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""].get(\n            ""BaselineConfig""\n        )\n        is None\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""].get(\n            ""BaselineConfig""\n        )\n        is None\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""Environment""\n        ].get(ENV_KEY_1)\n        is None\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][""Environment""][\n            ""publish_cloudwatch_metrics""\n        ]\n        == ""Enabled""\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""].get(\n            ""NetworkConfig""\n        )\n        is None\n    )\n\n    _wait_for_schedule_changes_to_apply(my_default_monitor)\n\n    my_default_monitor.update_monitoring_schedule()\n\n    _wait_for_schedule_changes_to_apply(my_default_monitor)\n\n    schedule_description = my_default_monitor.describe_schedule()\n\n    assert (\n        ""sagemaker-tensorflow-serving""\n        in schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringInputs""\n        ][0][""EndpointInput""][""EndpointName""]\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""InstanceCount""]\n        == DEFAULT_INSTANCE_COUNT\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""InstanceType""]\n        == DEFAULT_INSTANCE_TYPE\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""VolumeSizeInGB""]\n        == DEFAULT_VOLUME_SIZE_IN_GB\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""].get(""VolumeKmsKeyId"")\n        is None\n    )\n    assert (\n        DEFAULT_IMAGE_SUFFIX\n        in schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringAppSpecification""\n        ][""ImageUri""]\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringAppSpecification""\n        ].get(""RecordPreprocessorSourceUri"")\n        is None\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringAppSpecification""\n        ].get(""PostAnalyticsProcessorSourceUri"")\n        is None\n    )\n    assert (\n        ROLE\n        in schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][""RoleArn""]\n    )\n    assert (\n        len(\n            schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n                ""MonitoringOutputConfig""\n            ][""MonitoringOutputs""]\n        )\n        == 1\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringOutputConfig""\n        ].get(""KmsKeyId"")\n        is None\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""].get(\n            ""BaselineConfig""\n        )\n        is None\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""].get(\n            ""BaselineConfig""\n        )\n        is None\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""Environment""\n        ].get(ENV_KEY_1)\n        is None\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][""Environment""][\n            ""publish_cloudwatch_metrics""\n        ]\n        == ""Enabled""\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""].get(\n            ""NetworkConfig""\n        )\n        is None\n    )\n\n    _wait_for_schedule_changes_to_apply(monitor=my_default_monitor)\n\n    my_default_monitor.stop_monitoring_schedule()\n\n    _wait_for_schedule_changes_to_apply(monitor=my_default_monitor)\n\n\n@pytest.mark.skipif(\n    tests.integ.test_region() in tests.integ.NO_MODEL_MONITORING_REGIONS,\n    reason=""ModelMonitoring is not yet supported in this region."",\n)\ndef test_default_monitor_attach_followed_by_baseline_and_update_monitoring_schedule(\n    sagemaker_session,\n    default_monitoring_schedule_name,\n    updated_volume_kms_key,\n    updated_output_kms_key,\n):\n    my_attached_monitor = DefaultModelMonitor.attach(\n        monitor_schedule_name=default_monitoring_schedule_name, sagemaker_session=sagemaker_session\n    )\n\n    output_s3_uri = os.path.join(\n        ""s3://"",\n        sagemaker_session.default_bucket(),\n        ""integ-test-monitoring-output-bucket"",\n        str(uuid.uuid4()),\n    )\n\n    statistics = Statistics.from_file_path(\n        statistics_file_path=os.path.join(tests.integ.DATA_DIR, ""monitor/statistics.json""),\n        sagemaker_session=sagemaker_session,\n    )\n\n    constraints = Constraints.from_file_path(\n        constraints_file_path=os.path.join(tests.integ.DATA_DIR, ""monitor/constraints.json""),\n        sagemaker_session=sagemaker_session,\n    )\n\n    _wait_for_schedule_changes_to_apply(my_attached_monitor)\n\n    my_attached_monitor.update_monitoring_schedule(\n        output_s3_uri=output_s3_uri,\n        statistics=statistics,\n        constraints=constraints,\n        schedule_cron_expression=CronExpressionGenerator.hourly(),\n        instance_count=UPDATED_INSTANCE_COUNT,\n        instance_type=UPDATED_INSTANCE_TYPE,\n        volume_size_in_gb=UPDATED_VOLUME_SIZE_IN_GB,\n        volume_kms_key=updated_volume_kms_key,\n        output_kms_key=updated_output_kms_key,\n        max_runtime_in_seconds=UPDATED_MAX_RUNTIME_IN_SECONDS,\n        env=UPDATED_ENVIRONMENT,\n        network_config=UPDATED_NETWORK_CONFIG,\n        enable_cloudwatch_metrics=DISABLE_CLOUDWATCH_METRICS,\n        role=UPDATED_ROLE,\n    )\n\n    _wait_for_schedule_changes_to_apply(my_attached_monitor)\n\n    schedule_description = my_attached_monitor.describe_schedule()\n\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""ScheduleConfig""][""ScheduleExpression""]\n        == CronExpressionGenerator.hourly()\n    )\n    assert (\n        ""sagemaker-tensorflow-serving""\n        in schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringInputs""\n        ][0][""EndpointInput""][""EndpointName""]\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""InstanceCount""]\n        == UPDATED_INSTANCE_COUNT\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""InstanceType""]\n        == UPDATED_INSTANCE_TYPE\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""VolumeSizeInGB""]\n        == UPDATED_VOLUME_SIZE_IN_GB\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""VolumeKmsKeyId""]\n        == updated_volume_kms_key\n    )\n    assert (\n        DEFAULT_IMAGE_SUFFIX\n        in schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringAppSpecification""\n        ][""ImageUri""]\n    )\n    assert (\n        UPDATED_ROLE\n        in schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][""RoleArn""]\n    )\n    assert (\n        len(\n            schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n                ""MonitoringOutputConfig""\n            ][""MonitoringOutputs""]\n        )\n        == 1\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringOutputConfig""\n        ][""KmsKeyId""]\n        == updated_output_kms_key\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""BaselineConfig""\n        ][""StatisticsResource""][""S3Uri""]\n        == statistics.file_s3_uri\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""BaselineConfig""\n        ][""ConstraintsResource""][""S3Uri""]\n        == constraints.file_s3_uri\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""StoppingCondition""\n        ][""MaxRuntimeInSeconds""]\n        == UPDATED_MAX_RUNTIME_IN_SECONDS\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][""Environment""][\n            UPDATED_ENV_KEY_1\n        ]\n        == UPDATED_ENV_VALUE_1\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][""Environment""][\n            ""publish_cloudwatch_metrics""\n        ]\n        == ""Disabled""\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""NetworkConfig""\n        ][""EnableNetworkIsolation""]\n        == UPDATED_NETWORK_CONFIG.enable_network_isolation\n    )\n\n    _wait_for_schedule_changes_to_apply(monitor=my_attached_monitor)\n\n    my_attached_monitor.stop_monitoring_schedule()\n\n    _wait_for_schedule_changes_to_apply(monitor=my_attached_monitor)\n\n\n@pytest.mark.skipif(\n    tests.integ.test_region() in tests.integ.NO_MODEL_MONITORING_REGIONS,\n    reason=""ModelMonitoring is not yet supported in this region."",\n)\ndef test_default_monitor_monitoring_execution_interactions(\n    sagemaker_session, default_monitoring_schedule_name\n):\n    my_attached_monitor = DefaultModelMonitor.attach(\n        monitor_schedule_name=default_monitoring_schedule_name, sagemaker_session=sagemaker_session\n    )\n    description = my_attached_monitor.describe_schedule()\n    assert description[""MonitoringScheduleName""] == default_monitoring_schedule_name\n\n    executions = my_attached_monitor.list_executions()\n    assert len(executions) > 0\n\n    with open(os.path.join(tests.integ.DATA_DIR, ""monitor/statistics.json""), ""r"") as f:\n        file_body = f.read()\n\n    file_name = ""statistics.json""\n    desired_s3_uri = os.path.join(executions[-1].output.destination, file_name)\n\n    S3Uploader.upload_string_as_file_body(\n        body=file_body, desired_s3_uri=desired_s3_uri, session=sagemaker_session\n    )\n\n    statistics = my_attached_monitor.latest_monitoring_statistics()\n    assert statistics.body_dict[""dataset""][""item_count""] == 418\n\n    with open(os.path.join(tests.integ.DATA_DIR, ""monitor/constraint_violations.json""), ""r"") as f:\n        file_body = f.read()\n\n    file_name = ""constraint_violations.json""\n    desired_s3_uri = os.path.join(executions[-1].output.destination, file_name)\n\n    S3Uploader.upload_string_as_file_body(\n        body=file_body, desired_s3_uri=desired_s3_uri, session=sagemaker_session\n    )\n\n    constraint_violations = my_attached_monitor.latest_monitoring_constraint_violations()\n    assert constraint_violations.body_dict[""violations""][0][""feature_name""] == ""store_and_fwd_flag""\n\n\n@pytest.mark.skipif(\n    tests.integ.test_region() in tests.integ.NO_MODEL_MONITORING_REGIONS,\n    reason=""ModelMonitoring is not yet supported in this region."",\n)\ndef test_byoc_monitor_suggest_baseline_and_create_monitoring_schedule_with_customizations(\n    sagemaker_session, output_kms_key, volume_kms_key, predictor\n):\n    baseline_dataset = os.path.join(DATA_DIR, ""monitor/baseline_dataset.csv"")\n\n    byoc_env = ENVIRONMENT.copy()\n    byoc_env[""dataset_format""] = json.dumps(DatasetFormat.csv(header=False))\n    byoc_env[""dataset_source""] = ""/opt/ml/processing/input/baseline_dataset_input""\n    byoc_env[""output_path""] = os.path.join(""/opt/ml/processing/output"")\n    byoc_env[""publish_cloudwatch_metrics""] = ""Disabled""\n\n    my_byoc_monitor = ModelMonitor(\n        role=ROLE,\n        image_uri=DefaultModelMonitor._get_default_image_uri(\n            sagemaker_session.boto_session.region_name\n        ),\n        instance_count=INSTANCE_COUNT,\n        instance_type=INSTANCE_TYPE,\n        volume_size_in_gb=VOLUME_SIZE_IN_GB,\n        volume_kms_key=volume_kms_key,\n        output_kms_key=output_kms_key,\n        max_runtime_in_seconds=MAX_RUNTIME_IN_SECONDS,\n        sagemaker_session=sagemaker_session,\n        env=byoc_env,\n        tags=TAGS,\n        network_config=NETWORK_CONFIG,\n    )\n\n    output_s3_uri = os.path.join(\n        ""s3://"",\n        sagemaker_session.default_bucket(),\n        INTEG_TEST_MONITORING_OUTPUT_BUCKET,\n        str(uuid.uuid4()),\n    )\n\n    my_byoc_monitor.run_baseline(\n        baseline_inputs=[\n            ProcessingInput(\n                source=baseline_dataset,\n                destination=""/opt/ml/processing/input/baseline_dataset_input"",\n            )\n        ],\n        output=ProcessingOutput(source=""/opt/ml/processing/output"", destination=output_s3_uri),\n        wait=True,\n        logs=False,\n    )\n\n    baselining_job_description = my_byoc_monitor.latest_baselining_job.describe()\n\n    assert (\n        baselining_job_description[""ProcessingResources""][""ClusterConfig""][""InstanceType""]\n        == INSTANCE_TYPE\n    )\n    assert (\n        baselining_job_description[""ProcessingResources""][""ClusterConfig""][""InstanceCount""]\n        == INSTANCE_COUNT\n    )\n    assert (\n        baselining_job_description[""ProcessingResources""][""ClusterConfig""][""VolumeSizeInGB""]\n        == VOLUME_SIZE_IN_GB\n    )\n    assert (\n        baselining_job_description[""ProcessingResources""][""ClusterConfig""][""VolumeKmsKeyId""]\n        == volume_kms_key\n    )\n    assert DEFAULT_IMAGE_SUFFIX in baselining_job_description[""AppSpecification""][""ImageUri""]\n    assert ROLE in baselining_job_description[""RoleArn""]\n    assert baselining_job_description[""ProcessingInputs""][0][""InputName""] == ""input-1""\n    assert (\n        baselining_job_description[""ProcessingOutputConfig""][""Outputs""][0][""OutputName""]\n        == ""output-1""\n    )\n    assert baselining_job_description[""ProcessingOutputConfig""][""KmsKeyId""] == output_kms_key\n    assert baselining_job_description[""Environment""][ENV_KEY_1] == ENV_VALUE_1\n    assert baselining_job_description[""Environment""][""output_path""] == ""/opt/ml/processing/output""\n    assert (\n        baselining_job_description[""Environment""][""dataset_source""]\n        == ""/opt/ml/processing/input/baseline_dataset_input""\n    )\n    assert (\n        baselining_job_description[""StoppingCondition""][""MaxRuntimeInSeconds""]\n        == MAX_RUNTIME_IN_SECONDS\n    )\n    assert (\n        baselining_job_description[""NetworkConfig""][""EnableNetworkIsolation""]\n        == NETWORK_CONFIG.enable_network_isolation\n    )\n\n    statistics = my_byoc_monitor.baseline_statistics()\n    assert statistics.body_dict[""dataset""][""item_count""] == 418\n\n    constraints = my_byoc_monitor.suggested_constraints()\n    assert constraints.body_dict[""monitoring_config""][""evaluate_constraints""] == ""Enabled""\n\n    constraints.set_monitoring(enable_monitoring=False)\n\n    assert constraints.body_dict[""monitoring_config""][""evaluate_constraints""] == ""Disabled""\n\n    constraints.save()\n\n    my_byoc_monitor.create_monitoring_schedule(\n        endpoint_input=predictor.endpoint,\n        output=MonitoringOutput(source=""/opt/ml/processing/output"", destination=output_s3_uri),\n        statistics=my_byoc_monitor.baseline_statistics(),\n        constraints=my_byoc_monitor.suggested_constraints(),\n        schedule_cron_expression=CronExpressionGenerator.daily(),\n    )\n\n    schedule_description = my_byoc_monitor.describe_schedule()\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""ScheduleConfig""][""ScheduleExpression""]\n        == CronExpressionGenerator.daily()\n    )\n    assert (\n        ""sagemaker-tensorflow-serving""\n        in schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringInputs""\n        ][0][""EndpointInput""][""EndpointName""]\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""InstanceCount""]\n        == INSTANCE_COUNT\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""InstanceType""]\n        == INSTANCE_TYPE\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""VolumeSizeInGB""]\n        == VOLUME_SIZE_IN_GB\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""VolumeKmsKeyId""]\n        == volume_kms_key\n    )\n    assert (\n        DEFAULT_IMAGE_SUFFIX\n        in schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringAppSpecification""\n        ][""ImageUri""]\n    )\n    assert (\n        ROLE\n        in schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][""RoleArn""]\n    )\n    assert (\n        len(\n            schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n                ""MonitoringOutputConfig""\n            ][""MonitoringOutputs""]\n        )\n        == 1\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringOutputConfig""\n        ][""KmsKeyId""]\n        == output_kms_key\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""BaselineConfig""\n        ][""StatisticsResource""][""S3Uri""]\n        is not None\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""BaselineConfig""\n        ][""ConstraintsResource""][""S3Uri""]\n        is not None\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""StoppingCondition""\n        ][""MaxRuntimeInSeconds""]\n        == MAX_RUNTIME_IN_SECONDS\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][""Environment""][\n            ENV_KEY_1\n        ]\n        == ENV_VALUE_1\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][""Environment""][\n            ""publish_cloudwatch_metrics""\n        ]\n        == ""Disabled""\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""NetworkConfig""\n        ][""EnableNetworkIsolation""]\n        == NETWORK_CONFIG.enable_network_isolation\n    )\n\n    _wait_for_schedule_changes_to_apply(monitor=my_byoc_monitor)\n\n    my_byoc_monitor.stop_monitoring_schedule()\n\n    _wait_for_schedule_changes_to_apply(monitor=my_byoc_monitor)\n\n    summary = sagemaker_session.list_monitoring_schedules()\n    assert len(summary[""MonitoringScheduleSummaries""]) > 0\n\n\n@pytest.mark.skipif(\n    tests.integ.test_region() in tests.integ.NO_MODEL_MONITORING_REGIONS,\n    reason=""ModelMonitoring is not yet supported in this region."",\n)\ndef test_byoc_monitor_suggest_baseline_and_create_monitoring_schedule_without_customizations(\n    sagemaker_session, predictor\n):\n    baseline_dataset = os.path.join(DATA_DIR, ""monitor/baseline_dataset.csv"")\n\n    byoc_env = ENVIRONMENT.copy()\n    byoc_env[""dataset_format""] = json.dumps(DatasetFormat.csv(header=False))\n    byoc_env[""dataset_source""] = ""/opt/ml/processing/input/baseline_dataset_input""\n    byoc_env[""output_path""] = os.path.join(""/opt/ml/processing/output"")\n    byoc_env[""publish_cloudwatch_metrics""] = ""Disabled""\n\n    my_byoc_monitor = ModelMonitor(\n        role=ROLE,\n        image_uri=DefaultModelMonitor._get_default_image_uri(\n            sagemaker_session.boto_session.region_name\n        ),\n        sagemaker_session=sagemaker_session,\n        env=byoc_env,\n    )\n\n    output_s3_uri = os.path.join(\n        ""s3://"",\n        sagemaker_session.default_bucket(),\n        INTEG_TEST_MONITORING_OUTPUT_BUCKET,\n        str(uuid.uuid4()),\n    )\n\n    my_byoc_monitor.run_baseline(\n        baseline_inputs=[\n            ProcessingInput(\n                source=baseline_dataset,\n                destination=""/opt/ml/processing/input/baseline_dataset_input"",\n            )\n        ],\n        output=ProcessingOutput(source=""/opt/ml/processing/output"", destination=output_s3_uri),\n        logs=False,\n    )\n\n    baselining_job_description = my_byoc_monitor.latest_baselining_job.describe()\n\n    assert (\n        baselining_job_description[""ProcessingResources""][""ClusterConfig""][""InstanceCount""]\n        == DEFAULT_INSTANCE_COUNT\n    )\n    assert (\n        baselining_job_description[""ProcessingResources""][""ClusterConfig""][""InstanceType""]\n        == DEFAULT_INSTANCE_TYPE\n    )\n    assert (\n        baselining_job_description[""ProcessingResources""][""ClusterConfig""][""VolumeSizeInGB""]\n        == DEFAULT_VOLUME_SIZE_IN_GB\n    )\n    assert (\n        baselining_job_description[""ProcessingResources""][""ClusterConfig""].get(""VolumeKmsKeyId"")\n        is None\n    )\n    assert DEFAULT_IMAGE_SUFFIX in baselining_job_description[""AppSpecification""][""ImageUri""]\n    assert ROLE in baselining_job_description[""RoleArn""]\n    assert baselining_job_description[""ProcessingInputs""][0][""InputName""] == ""input-1""\n    assert (\n        baselining_job_description[""ProcessingOutputConfig""][""Outputs""][0][""OutputName""]\n        == ""output-1""\n    )\n    assert baselining_job_description[""ProcessingOutputConfig""].get(""KmsKeyId"") is None\n    assert baselining_job_description[""Environment""][ENV_KEY_1] == ENV_VALUE_1\n    assert baselining_job_description[""Environment""][""output_path""] == ""/opt/ml/processing/output""\n    assert (\n        baselining_job_description[""Environment""][""dataset_source""]\n        == ""/opt/ml/processing/input/baseline_dataset_input""\n    )\n    assert (\n        baselining_job_description[""StoppingCondition""][""MaxRuntimeInSeconds""]\n        == DEFAULT_BASELINING_MAX_RUNTIME_IN_SECONDS\n    )\n    assert baselining_job_description.get(""NetworkConfig"") is None\n\n    statistics = my_byoc_monitor.baseline_statistics()\n    assert statistics.body_dict[""dataset""][""item_count""] == 418\n\n    constraints = my_byoc_monitor.suggested_constraints()\n    assert constraints.body_dict[""monitoring_config""][""evaluate_constraints""] == ""Enabled""\n\n    constraints.set_monitoring(enable_monitoring=False)\n\n    assert constraints.body_dict[""monitoring_config""][""evaluate_constraints""] == ""Disabled""\n\n    constraints.save()\n\n    my_byoc_monitor.create_monitoring_schedule(\n        endpoint_input=predictor.endpoint,\n        output=MonitoringOutput(source=""/opt/ml/processing/output"", destination=output_s3_uri),\n        schedule_cron_expression=CronExpressionGenerator.daily(),\n    )\n\n    schedule_description = my_byoc_monitor.describe_schedule()\n    assert (\n        ""sagemaker-tensorflow-serving""\n        in schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringInputs""\n        ][0][""EndpointInput""][""EndpointName""]\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""InstanceCount""]\n        == DEFAULT_INSTANCE_COUNT\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""InstanceType""]\n        == DEFAULT_INSTANCE_TYPE\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""VolumeSizeInGB""]\n        == DEFAULT_VOLUME_SIZE_IN_GB\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""].get(""VolumeKmsKeyId"")\n        is None\n    )\n    assert (\n        DEFAULT_IMAGE_SUFFIX\n        in schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringAppSpecification""\n        ][""ImageUri""]\n    )\n    assert (\n        ROLE\n        in schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][""RoleArn""]\n    )\n    assert (\n        len(\n            schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n                ""MonitoringOutputConfig""\n            ][""MonitoringOutputs""]\n        )\n        == 1\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringOutputConfig""\n        ].get(""KmsKeyId"")\n        is None\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""].get(\n            ""BaselineConfig""\n        )\n        is None\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""StoppingCondition""\n        ][""MaxRuntimeInSeconds""]\n        == DEFAULT_EXECUTION_MAX_RUNTIME_IN_SECONDS\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][""Environment""][\n            ENV_KEY_1\n        ]\n        == ENV_VALUE_1\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][""Environment""][\n            ""publish_cloudwatch_metrics""\n        ]\n        == ""Disabled""\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""].get(\n            ""NetworkConfig""\n        )\n        is None\n    )\n\n    _wait_for_schedule_changes_to_apply(monitor=my_byoc_monitor)\n\n    my_byoc_monitor.stop_monitoring_schedule()\n\n    _wait_for_schedule_changes_to_apply(monitor=my_byoc_monitor)\n\n    summary = sagemaker_session.list_monitoring_schedules()\n    assert len(summary[""MonitoringScheduleSummaries""]) > 0\n\n\n@pytest.mark.skipif(\n    tests.integ.test_region() in tests.integ.NO_MODEL_MONITORING_REGIONS,\n    reason=""ModelMonitoring is not yet supported in this region."",\n)\ndef test_byoc_monitor_create_and_update_schedule_config_with_customizations(\n    sagemaker_session,\n    predictor,\n    volume_kms_key,\n    output_kms_key,\n    updated_volume_kms_key,\n    updated_output_kms_key,\n):\n    byoc_env = ENVIRONMENT.copy()\n    byoc_env[""dataset_format""] = json.dumps(DatasetFormat.csv(header=False))\n    byoc_env[""dataset_source""] = ""/opt/ml/processing/input/baseline_dataset_input""\n    byoc_env[""output_path""] = os.path.join(""/opt/ml/processing/output"")\n    byoc_env[""publish_cloudwatch_metrics""] = ""Disabled""\n\n    my_byoc_monitor = ModelMonitor(\n        role=ROLE,\n        image_uri=DefaultModelMonitor._get_default_image_uri(\n            sagemaker_session.boto_session.region_name\n        ),\n        instance_count=INSTANCE_COUNT,\n        instance_type=INSTANCE_TYPE,\n        volume_size_in_gb=VOLUME_SIZE_IN_GB,\n        volume_kms_key=volume_kms_key,\n        output_kms_key=output_kms_key,\n        max_runtime_in_seconds=MAX_RUNTIME_IN_SECONDS,\n        sagemaker_session=sagemaker_session,\n        env=byoc_env,\n        tags=TAGS,\n        network_config=NETWORK_CONFIG,\n    )\n\n    output_s3_uri = os.path.join(\n        ""s3://"",\n        sagemaker_session.default_bucket(),\n        ""integ-test-monitoring-output-bucket"",\n        str(uuid.uuid4()),\n    )\n\n    statistics = Statistics.from_file_path(\n        statistics_file_path=os.path.join(tests.integ.DATA_DIR, ""monitor/statistics.json""),\n        sagemaker_session=sagemaker_session,\n    )\n\n    constraints = Constraints.from_file_path(\n        constraints_file_path=os.path.join(tests.integ.DATA_DIR, ""monitor/constraints.json""),\n        sagemaker_session=sagemaker_session,\n    )\n\n    my_byoc_monitor.create_monitoring_schedule(\n        endpoint_input=predictor.endpoint,\n        output=MonitoringOutput(source=""/opt/ml/processing/output"", destination=output_s3_uri),\n        statistics=statistics,\n        constraints=constraints,\n        schedule_cron_expression=CronExpressionGenerator.daily(),\n    )\n\n    schedule_description = my_byoc_monitor.describe_schedule()\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""ScheduleConfig""][""ScheduleExpression""]\n        == CronExpressionGenerator.daily()\n    )\n    assert (\n        ""sagemaker-tensorflow-serving""\n        in schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringInputs""\n        ][0][""EndpointInput""][""EndpointName""]\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""InstanceCount""]\n        == INSTANCE_COUNT\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""InstanceType""]\n        == INSTANCE_TYPE\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""VolumeSizeInGB""]\n        == VOLUME_SIZE_IN_GB\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""VolumeKmsKeyId""]\n        == volume_kms_key\n    )\n    assert (\n        DEFAULT_IMAGE_SUFFIX\n        in schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringAppSpecification""\n        ][""ImageUri""]\n    )\n    assert (\n        ROLE\n        in schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][""RoleArn""]\n    )\n    assert (\n        len(\n            schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n                ""MonitoringOutputConfig""\n            ][""MonitoringOutputs""]\n        )\n        == 1\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringOutputConfig""\n        ][""KmsKeyId""]\n        == output_kms_key\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""BaselineConfig""\n        ][""StatisticsResource""][""S3Uri""]\n        is not None\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""BaselineConfig""\n        ][""ConstraintsResource""][""S3Uri""]\n        is not None\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""StoppingCondition""\n        ][""MaxRuntimeInSeconds""]\n        == MAX_RUNTIME_IN_SECONDS\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][""Environment""][\n            ENV_KEY_1\n        ]\n        == ENV_VALUE_1\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][""Environment""][\n            ""publish_cloudwatch_metrics""\n        ]\n        == ""Disabled""\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""NetworkConfig""\n        ][""EnableNetworkIsolation""]\n        == NETWORK_CONFIG.enable_network_isolation\n    )\n\n    _wait_for_schedule_changes_to_apply(my_byoc_monitor)\n\n    byoc_env.update(UPDATED_ENVIRONMENT)\n\n    my_byoc_monitor.update_monitoring_schedule(\n        endpoint_input=predictor.endpoint,\n        output=MonitoringOutput(source=""/opt/ml/processing/output"", destination=output_s3_uri),\n        statistics=statistics,\n        constraints=constraints,\n        schedule_cron_expression=CronExpressionGenerator.hourly(),\n        instance_count=UPDATED_INSTANCE_COUNT,\n        instance_type=UPDATED_INSTANCE_TYPE,\n        volume_size_in_gb=UPDATED_VOLUME_SIZE_IN_GB,\n        volume_kms_key=updated_volume_kms_key,\n        output_kms_key=updated_output_kms_key,\n        max_runtime_in_seconds=UPDATED_MAX_RUNTIME_IN_SECONDS,\n        env=byoc_env,\n        network_config=UPDATED_NETWORK_CONFIG,\n        role=UPDATED_ROLE,\n    )\n\n    _wait_for_schedule_changes_to_apply(my_byoc_monitor)\n\n    schedule_description = my_byoc_monitor.describe_schedule()\n\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""ScheduleConfig""][""ScheduleExpression""]\n        == CronExpressionGenerator.hourly()\n    )\n    assert (\n        ""sagemaker-tensorflow-serving""\n        in schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringInputs""\n        ][0][""EndpointInput""][""EndpointName""]\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""InstanceCount""]\n        == UPDATED_INSTANCE_COUNT\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""InstanceType""]\n        == UPDATED_INSTANCE_TYPE\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""VolumeSizeInGB""]\n        == UPDATED_VOLUME_SIZE_IN_GB\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""VolumeKmsKeyId""]\n        == updated_volume_kms_key\n    )\n    assert (\n        DEFAULT_IMAGE_SUFFIX\n        in schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringAppSpecification""\n        ][""ImageUri""]\n    )\n    assert (\n        UPDATED_ROLE\n        in schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][""RoleArn""]\n    )\n    assert (\n        len(\n            schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n                ""MonitoringOutputConfig""\n            ][""MonitoringOutputs""]\n        )\n        == 1\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringOutputConfig""\n        ][""KmsKeyId""]\n        == updated_output_kms_key\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""BaselineConfig""\n        ][""StatisticsResource""][""S3Uri""]\n        == statistics.file_s3_uri\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""BaselineConfig""\n        ][""ConstraintsResource""][""S3Uri""]\n        == constraints.file_s3_uri\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""StoppingCondition""\n        ][""MaxRuntimeInSeconds""]\n        == UPDATED_MAX_RUNTIME_IN_SECONDS\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][""Environment""][\n            UPDATED_ENV_KEY_1\n        ]\n        == UPDATED_ENV_VALUE_1\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][""Environment""][\n            ""publish_cloudwatch_metrics""\n        ]\n        == ""Disabled""\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""NetworkConfig""\n        ][""EnableNetworkIsolation""]\n        == UPDATED_NETWORK_CONFIG.enable_network_isolation\n    )\n\n    _wait_for_schedule_changes_to_apply(monitor=my_byoc_monitor)\n\n    my_byoc_monitor.stop_monitoring_schedule()\n\n    _wait_for_schedule_changes_to_apply(monitor=my_byoc_monitor)\n\n    assert len(predictor.list_monitors()) > 0\n\n\n@pytest.mark.skipif(\n    tests.integ.test_region() in tests.integ.NO_MODEL_MONITORING_REGIONS,\n    reason=""ModelMonitoring is not yet supported in this region."",\n)\ndef test_byoc_monitor_attach_followed_by_baseline_and_update_monitoring_schedule(\n    sagemaker_session,\n    predictor,\n    byoc_monitoring_schedule_name,\n    volume_kms_key,\n    output_kms_key,\n    updated_volume_kms_key,\n    updated_output_kms_key,\n):\n    baseline_dataset = os.path.join(DATA_DIR, ""monitor/baseline_dataset.csv"")\n\n    byoc_env = ENVIRONMENT.copy()\n    byoc_env[""dataset_format""] = json.dumps(DatasetFormat.csv(header=False))\n    byoc_env[""dataset_source""] = ""/opt/ml/processing/input/baseline_dataset_input""\n    byoc_env[""output_path""] = os.path.join(""/opt/ml/processing/output"")\n    byoc_env[""publish_cloudwatch_metrics""] = ""Disabled""\n\n    my_attached_monitor = ModelMonitor.attach(\n        monitor_schedule_name=byoc_monitoring_schedule_name, sagemaker_session=sagemaker_session\n    )\n\n    output_s3_uri = os.path.join(\n        ""s3://"",\n        sagemaker_session.default_bucket(),\n        INTEG_TEST_MONITORING_OUTPUT_BUCKET,\n        str(uuid.uuid4()),\n    )\n\n    my_attached_monitor.run_baseline(\n        baseline_inputs=[\n            ProcessingInput(\n                source=baseline_dataset,\n                destination=""/opt/ml/processing/input/baseline_dataset_input"",\n            )\n        ],\n        output=ProcessingOutput(source=""/opt/ml/processing/output"", destination=output_s3_uri),\n        wait=True,\n        logs=False,\n    )\n\n    baselining_job_description = my_attached_monitor.latest_baselining_job.describe()\n\n    assert (\n        baselining_job_description[""ProcessingResources""][""ClusterConfig""][""InstanceType""]\n        == INSTANCE_TYPE\n    )\n    assert (\n        baselining_job_description[""ProcessingResources""][""ClusterConfig""][""InstanceCount""]\n        == INSTANCE_COUNT\n    )\n    assert (\n        baselining_job_description[""ProcessingResources""][""ClusterConfig""][""VolumeSizeInGB""]\n        == VOLUME_SIZE_IN_GB\n    )\n    assert (\n        baselining_job_description[""ProcessingResources""][""ClusterConfig""][""VolumeKmsKeyId""]\n        == volume_kms_key\n    )\n    assert DEFAULT_IMAGE_SUFFIX in baselining_job_description[""AppSpecification""][""ImageUri""]\n    assert ROLE in baselining_job_description[""RoleArn""]\n    assert baselining_job_description[""ProcessingInputs""][0][""InputName""] == ""input-1""\n    assert (\n        baselining_job_description[""ProcessingOutputConfig""][""Outputs""][0][""OutputName""]\n        == ""output-1""\n    )\n    assert baselining_job_description[""ProcessingOutputConfig""][""KmsKeyId""] == output_kms_key\n    assert baselining_job_description[""Environment""][ENV_KEY_1] == ENV_VALUE_1\n    assert baselining_job_description[""Environment""][""output_path""] == ""/opt/ml/processing/output""\n    assert (\n        baselining_job_description[""Environment""][""dataset_source""]\n        == ""/opt/ml/processing/input/baseline_dataset_input""\n    )\n    assert (\n        baselining_job_description[""StoppingCondition""][""MaxRuntimeInSeconds""]\n        == MAX_RUNTIME_IN_SECONDS\n    )\n    assert (\n        baselining_job_description[""NetworkConfig""][""EnableNetworkIsolation""]\n        == NETWORK_CONFIG.enable_network_isolation\n    )\n\n    statistics = my_attached_monitor.baseline_statistics()\n    assert statistics.body_dict[""dataset""][""item_count""] == 418\n\n    constraints = my_attached_monitor.suggested_constraints()\n    assert constraints.body_dict[""monitoring_config""][""evaluate_constraints""] == ""Enabled""\n\n    constraints.set_monitoring(enable_monitoring=False)\n\n    assert constraints.body_dict[""monitoring_config""][""evaluate_constraints""] == ""Disabled""\n\n    constraints.save()\n\n    byoc_env.update(UPDATED_ENVIRONMENT)\n\n    my_attached_monitor.update_monitoring_schedule(\n        endpoint_input=predictor.endpoint,\n        output=MonitoringOutput(source=""/opt/ml/processing/output"", destination=output_s3_uri),\n        statistics=statistics,\n        constraints=constraints,\n        schedule_cron_expression=CronExpressionGenerator.hourly(),\n        instance_count=UPDATED_INSTANCE_COUNT,\n        instance_type=UPDATED_INSTANCE_TYPE,\n        volume_size_in_gb=UPDATED_VOLUME_SIZE_IN_GB,\n        volume_kms_key=updated_volume_kms_key,\n        output_kms_key=updated_output_kms_key,\n        max_runtime_in_seconds=UPDATED_MAX_RUNTIME_IN_SECONDS,\n        env=byoc_env,\n        network_config=UPDATED_NETWORK_CONFIG,\n        role=UPDATED_ROLE,\n    )\n\n    _wait_for_schedule_changes_to_apply(my_attached_monitor)\n\n    schedule_description = my_attached_monitor.describe_schedule()\n\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""ScheduleConfig""][""ScheduleExpression""]\n        == CronExpressionGenerator.hourly()\n    )\n    assert (\n        ""sagemaker-tensorflow-serving""\n        in schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringInputs""\n        ][0][""EndpointInput""][""EndpointName""]\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""InstanceCount""]\n        == UPDATED_INSTANCE_COUNT\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""InstanceType""]\n        == UPDATED_INSTANCE_TYPE\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""VolumeSizeInGB""]\n        == UPDATED_VOLUME_SIZE_IN_GB\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""VolumeKmsKeyId""]\n        == updated_volume_kms_key\n    )\n    assert (\n        DEFAULT_IMAGE_SUFFIX\n        in schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringAppSpecification""\n        ][""ImageUri""]\n    )\n    assert (\n        UPDATED_ROLE\n        in schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][""RoleArn""]\n    )\n    assert (\n        len(\n            schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n                ""MonitoringOutputConfig""\n            ][""MonitoringOutputs""]\n        )\n        == 1\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringOutputConfig""\n        ][""KmsKeyId""]\n        == updated_output_kms_key\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""BaselineConfig""\n        ][""StatisticsResource""][""S3Uri""]\n        == statistics.file_s3_uri\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""BaselineConfig""\n        ][""ConstraintsResource""][""S3Uri""]\n        == constraints.file_s3_uri\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""StoppingCondition""\n        ][""MaxRuntimeInSeconds""]\n        == UPDATED_MAX_RUNTIME_IN_SECONDS\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][""Environment""][\n            UPDATED_ENV_KEY_1\n        ]\n        == UPDATED_ENV_VALUE_1\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][""Environment""][\n            ""publish_cloudwatch_metrics""\n        ]\n        == ""Disabled""\n    )\n    assert (\n        schedule_description[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""NetworkConfig""\n        ][""EnableNetworkIsolation""]\n        == UPDATED_NETWORK_CONFIG.enable_network_isolation\n    )\n\n    _wait_for_schedule_changes_to_apply(monitor=my_attached_monitor)\n\n    my_attached_monitor.stop_monitoring_schedule()\n\n    _wait_for_schedule_changes_to_apply(monitor=my_attached_monitor)\n\n\n@pytest.mark.skipif(\n    tests.integ.test_region() in tests.integ.NO_MODEL_MONITORING_REGIONS,\n    reason=""ModelMonitoring is not yet supported in this region."",\n)\ndef test_byoc_monitor_monitoring_execution_interactions(\n    sagemaker_session, byoc_monitoring_schedule_name\n):\n    my_attached_monitor = ModelMonitor.attach(\n        monitor_schedule_name=byoc_monitoring_schedule_name, sagemaker_session=sagemaker_session\n    )\n    description = my_attached_monitor.describe_schedule()\n    assert description[""MonitoringScheduleName""] == byoc_monitoring_schedule_name\n\n    executions = my_attached_monitor.list_executions()\n    assert len(executions) > 0\n\n    with open(os.path.join(tests.integ.DATA_DIR, ""monitor/statistics.json""), ""r"") as f:\n        file_body = f.read()\n\n    file_name = ""statistics.json""\n    desired_s3_uri = os.path.join(executions[-1].output.destination, file_name)\n\n    S3Uploader.upload_string_as_file_body(\n        body=file_body, desired_s3_uri=desired_s3_uri, session=sagemaker_session\n    )\n\n    statistics = my_attached_monitor.latest_monitoring_statistics()\n    assert statistics.body_dict[""dataset""][""item_count""] == 418\n\n    with open(os.path.join(tests.integ.DATA_DIR, ""monitor/constraint_violations.json""), ""r"") as f:\n        file_body = f.read()\n\n    file_name = ""constraint_violations.json""\n    desired_s3_uri = os.path.join(executions[-1].output.destination, file_name)\n\n    S3Uploader.upload_string_as_file_body(\n        body=file_body, desired_s3_uri=desired_s3_uri, session=sagemaker_session\n    )\n\n    constraint_violations = my_attached_monitor.latest_monitoring_constraint_violations()\n    assert constraint_violations.body_dict[""violations""][0][""feature_name""] == ""store_and_fwd_flag""\n\n\ndef _wait_for_schedule_changes_to_apply(monitor):\n    """"""Waits for the monitor to no longer be in the \'Pending\' state. Updates take under a minute\n    to apply.\n\n    Args:\n        monitor (sagemaker.model_monitor.ModelMonitor): The monitor to watch.\n\n    """"""\n    for _ in retries(\n        max_retry_count=100,\n        exception_message_prefix=""Waiting for schedule to leave \'Pending\' status"",\n        seconds_to_sleep=5,\n    ):\n        schedule_desc = monitor.describe_schedule()\n        if schedule_desc[""MonitoringScheduleStatus""] != ""Pending"":\n            break\n\n\ndef _predict_while_waiting_for_first_monitoring_job_to_complete(predictor, monitor):\n    """"""Waits for the schedule to have an execution in a terminal status.\n\n    Args:\n        monitor (sagemaker.model_monitor.ModelMonitor): The monitor to watch.\n\n    """"""\n    for _ in retries(\n        max_retry_count=200,\n        exception_message_prefix=""Waiting for the latest execution to be in a terminal status."",\n        seconds_to_sleep=50,\n    ):\n        predictor.predict({""instances"": [1.0, 2.0, 5.0]})\n        schedule_desc = monitor.describe_schedule()\n        execution_summary = schedule_desc.get(""LastMonitoringExecutionSummary"")\n        last_execution_status = None\n\n        # Once there is an execution, get its status\n        if execution_summary is not None:\n            last_execution_status = execution_summary[""MonitoringExecutionStatus""]\n            # Stop the schedule as soon as it\'s kicked off the execution that we need from it.\n            if schedule_desc[""MonitoringScheduleStatus""] not in [""Pending"", ""Stopped""]:\n                monitor.stop_monitoring_schedule()\n        # End this loop once the execution has reached a terminal state.\n        if last_execution_status in [""Completed"", ""CompletedWithViolations"", ""Failed"", ""Stopped""]:\n            break\n\n\ndef _upload_captured_data_to_endpoint(sagemaker_session, predictor):\n    current_hour_date_time = datetime.now()\n    previous_hour_date_time = datetime.now() - timedelta(hours=1)\n    current_hour_folder_structure = current_hour_date_time.strftime(""%Y/%m/%d/%H"")\n    previous_hour_folder_structure = previous_hour_date_time.strftime(""%Y/%m/%d/%H"")\n    s3_uri_base = os.path.join(\n        ""s3://"",\n        sagemaker_session.default_bucket(),\n        _MODEL_MONITOR_S3_PATH,\n        _DATA_CAPTURE_S3_PATH,\n        predictor.endpoint,\n        ""AllTraffic"",\n    )\n    s3_uri_previous_hour = os.path.join(s3_uri_base, previous_hour_folder_structure)\n    s3_uri_current_hour = os.path.join(s3_uri_base, current_hour_folder_structure)\n    S3Uploader.upload(\n        local_path=os.path.join(DATA_DIR, ""monitor/captured-data.jsonl""),\n        desired_s3_uri=s3_uri_previous_hour,\n        session=sagemaker_session,\n    )\n    S3Uploader.upload(\n        local_path=os.path.join(DATA_DIR, ""monitor/captured-data.jsonl""),\n        desired_s3_uri=s3_uri_current_hour,\n        session=sagemaker_session,\n    )\n'"
tests/integ/test_monitoring_files.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport os\nimport uuid\n\nimport pytest\n\nimport tests.integ\nimport tests.integ.timeout\nfrom sagemaker.model_monitor import Statistics, Constraints, ConstraintViolations\nfrom sagemaker.s3 import S3Uploader\nfrom tests.integ.kms_utils import get_or_create_kms_key\n\n\n@pytest.fixture(scope=""module"")\ndef monitoring_files_kms_key(sagemaker_session):\n    return get_or_create_kms_key(sagemaker_session=sagemaker_session)\n\n\ndef test_statistics_object_creation_from_file_path_with_customizations(\n    sagemaker_session, monitoring_files_kms_key\n):\n    statistics = Statistics.from_file_path(\n        statistics_file_path=os.path.join(tests.integ.DATA_DIR, ""monitor/statistics.json""),\n        kms_key=monitoring_files_kms_key,\n        sagemaker_session=sagemaker_session,\n    )\n\n    assert statistics.file_s3_uri.startswith(""s3://"")\n    assert statistics.file_s3_uri.endswith(""statistics.json"")\n\n    assert statistics.body_dict[""dataset""][""item_count""] == 418\n\n\ndef test_statistics_object_creation_from_file_path_without_customizations(sagemaker_session):\n    statistics = Statistics.from_file_path(\n        statistics_file_path=os.path.join(tests.integ.DATA_DIR, ""monitor/statistics.json""),\n        sagemaker_session=sagemaker_session,\n    )\n\n    assert statistics.file_s3_uri.startswith(""s3://"")\n    assert statistics.file_s3_uri.endswith(""statistics.json"")\n\n    assert statistics.body_dict[""dataset""][""item_count""] == 418\n\n\ndef test_statistics_object_creation_from_string_with_customizations(\n    sagemaker_session, monitoring_files_kms_key\n):\n    with open(os.path.join(tests.integ.DATA_DIR, ""monitor/statistics.json""), ""r"") as f:\n        file_body = f.read()\n\n    statistics = Statistics.from_string(\n        statistics_file_string=file_body,\n        kms_key=monitoring_files_kms_key,\n        file_name=""statistics.json"",\n        sagemaker_session=sagemaker_session,\n    )\n\n    assert statistics.file_s3_uri.startswith(""s3://"")\n    assert statistics.file_s3_uri.endswith(""statistics.json"")\n\n    assert statistics.body_dict[""dataset""][""item_count""] == 418\n\n\ndef test_statistics_object_creation_from_string_without_customizations(sagemaker_session):\n    with open(os.path.join(tests.integ.DATA_DIR, ""monitor/statistics.json""), ""r"") as f:\n        file_body = f.read()\n\n    statistics = Statistics.from_string(\n        statistics_file_string=file_body, sagemaker_session=sagemaker_session\n    )\n\n    assert statistics.file_s3_uri.startswith(""s3://"")\n    assert statistics.file_s3_uri.endswith(""statistics.json"")\n\n    assert statistics.body_dict[""dataset""][""item_count""] == 418\n\n\ndef test_statistics_object_creation_from_s3_uri_with_customizations(\n    sagemaker_session, monitoring_files_kms_key\n):\n    with open(os.path.join(tests.integ.DATA_DIR, ""monitor/statistics.json""), ""r"") as f:\n        file_body = f.read()\n\n    file_name = ""statistics.json""\n    desired_s3_uri = os.path.join(\n        ""s3://"",\n        sagemaker_session.default_bucket(),\n        ""integ-test-test-monitoring-files"",\n        str(uuid.uuid4()),\n        file_name,\n    )\n\n    s3_uri = S3Uploader.upload_string_as_file_body(\n        body=file_body,\n        desired_s3_uri=desired_s3_uri,\n        kms_key=monitoring_files_kms_key,\n        session=sagemaker_session,\n    )\n\n    statistics = Statistics.from_s3_uri(\n        statistics_file_s3_uri=s3_uri,\n        kms_key=monitoring_files_kms_key,\n        sagemaker_session=sagemaker_session,\n    )\n\n    assert statistics.file_s3_uri.startswith(""s3://"")\n    assert statistics.file_s3_uri.endswith(""statistics.json"")\n\n    assert statistics.body_dict[""dataset""][""item_count""] == 418\n\n\ndef test_statistics_object_creation_from_s3_uri_without_customizations(sagemaker_session):\n    with open(os.path.join(tests.integ.DATA_DIR, ""monitor/statistics.json""), ""r"") as f:\n        file_body = f.read()\n\n    file_name = ""statistics.json""\n    desired_s3_uri = os.path.join(\n        ""s3://"",\n        sagemaker_session.default_bucket(),\n        ""integ-test-test-monitoring-files"",\n        str(uuid.uuid4()),\n        file_name,\n    )\n\n    s3_uri = S3Uploader.upload_string_as_file_body(\n        body=file_body, desired_s3_uri=desired_s3_uri, session=sagemaker_session\n    )\n\n    statistics = Statistics.from_s3_uri(\n        statistics_file_s3_uri=s3_uri, sagemaker_session=sagemaker_session\n    )\n\n    assert statistics.file_s3_uri.startswith(""s3://"")\n    assert statistics.file_s3_uri.endswith(""statistics.json"")\n\n    assert statistics.body_dict[""dataset""][""item_count""] == 418\n\n\ndef test_constraints_object_creation_from_file_path_with_customizations(\n    sagemaker_session, monitoring_files_kms_key\n):\n    constraints = Constraints.from_file_path(\n        constraints_file_path=os.path.join(tests.integ.DATA_DIR, ""monitor/constraints.json""),\n        kms_key=monitoring_files_kms_key,\n        sagemaker_session=sagemaker_session,\n    )\n\n    assert constraints.file_s3_uri.startswith(""s3://"")\n    assert constraints.file_s3_uri.endswith(""constraints.json"")\n\n    assert constraints.body_dict[""monitoring_config""][""evaluate_constraints""] == ""Enabled""\n\n    constraints.set_monitoring(False)\n\n    assert constraints.body_dict[""monitoring_config""][""evaluate_constraints""] == ""Disabled""\n\n    constraints.set_monitoring(True, ""message"")\n\n    assert (\n        constraints.body_dict[""features""][0][""string_constraints""][""monitoring_config_overrides""][\n            ""evaluate_constraints""\n        ]\n        == ""Enabled""\n    )\n\n    constraints.set_monitoring(True, ""second_message"")\n\n    assert (\n        constraints.body_dict[""features""][0][""string_constraints""][""monitoring_config_overrides""][\n            ""evaluate_constraints""\n        ]\n        == ""Enabled""\n    )\n\n    constraints.save()\n\n    new_constraints = Constraints.from_s3_uri(\n        constraints.file_s3_uri, sagemaker_session=sagemaker_session\n    )\n\n    assert new_constraints.body_dict[""monitoring_config""][""evaluate_constraints""] == ""Disabled""\n\n\ndef test_constraints_object_creation_from_file_path_without_customizations(sagemaker_session):\n    constraints = Constraints.from_file_path(\n        constraints_file_path=os.path.join(tests.integ.DATA_DIR, ""monitor/constraints.json""),\n        sagemaker_session=sagemaker_session,\n    )\n\n    assert constraints.file_s3_uri.startswith(""s3://"")\n    assert constraints.file_s3_uri.endswith(""constraints.json"")\n\n    assert constraints.body_dict[""monitoring_config""][""evaluate_constraints""] == ""Enabled""\n\n\ndef test_constraints_object_creation_from_string_with_customizations(\n    sagemaker_session, monitoring_files_kms_key\n):\n    with open(os.path.join(tests.integ.DATA_DIR, ""monitor/constraints.json""), ""r"") as f:\n        file_body = f.read()\n\n    constraints = Constraints.from_string(\n        constraints_file_string=file_body,\n        kms_key=monitoring_files_kms_key,\n        file_name=""constraints.json"",\n        sagemaker_session=sagemaker_session,\n    )\n\n    assert constraints.file_s3_uri.startswith(""s3://"")\n    assert constraints.file_s3_uri.endswith(""constraints.json"")\n\n    assert constraints.body_dict[""monitoring_config""][""evaluate_constraints""] == ""Enabled""\n\n\ndef test_constraints_object_creation_from_string_without_customizations(sagemaker_session):\n    with open(os.path.join(tests.integ.DATA_DIR, ""monitor/constraints.json""), ""r"") as f:\n        file_body = f.read()\n\n    constraints = Constraints.from_string(\n        constraints_file_string=file_body, sagemaker_session=sagemaker_session\n    )\n\n    assert constraints.file_s3_uri.startswith(""s3://"")\n    assert constraints.file_s3_uri.endswith(""constraints.json"")\n\n    assert constraints.body_dict[""monitoring_config""][""evaluate_constraints""] == ""Enabled""\n\n\ndef test_constraints_object_creation_from_s3_uri_with_customizations(\n    sagemaker_session, monitoring_files_kms_key\n):\n    with open(os.path.join(tests.integ.DATA_DIR, ""monitor/constraints.json""), ""r"") as f:\n        file_body = f.read()\n\n    file_name = ""constraints.json""\n    desired_s3_uri = os.path.join(\n        ""s3://"",\n        sagemaker_session.default_bucket(),\n        ""integ-test-test-monitoring-files"",\n        str(uuid.uuid4()),\n        file_name,\n    )\n\n    s3_uri = S3Uploader.upload_string_as_file_body(\n        body=file_body,\n        desired_s3_uri=desired_s3_uri,\n        kms_key=monitoring_files_kms_key,\n        session=sagemaker_session,\n    )\n\n    constraints = Constraints.from_s3_uri(\n        constraints_file_s3_uri=s3_uri,\n        kms_key=monitoring_files_kms_key,\n        sagemaker_session=sagemaker_session,\n    )\n\n    assert constraints.file_s3_uri.startswith(""s3://"")\n    assert constraints.file_s3_uri.endswith(""constraints.json"")\n\n    assert constraints.body_dict[""monitoring_config""][""evaluate_constraints""] == ""Enabled""\n\n\ndef test_constraints_object_creation_from_s3_uri_without_customizations(sagemaker_session):\n    with open(os.path.join(tests.integ.DATA_DIR, ""monitor/constraints.json""), ""r"") as f:\n        file_body = f.read()\n\n    file_name = ""constraints.json""\n    desired_s3_uri = os.path.join(\n        ""s3://"",\n        sagemaker_session.default_bucket(),\n        ""integ-test-test-monitoring-files"",\n        str(uuid.uuid4()),\n        file_name,\n    )\n\n    s3_uri = S3Uploader.upload_string_as_file_body(\n        body=file_body, desired_s3_uri=desired_s3_uri, session=sagemaker_session\n    )\n\n    constraints = Constraints.from_s3_uri(\n        constraints_file_s3_uri=s3_uri, sagemaker_session=sagemaker_session\n    )\n\n    assert constraints.file_s3_uri.startswith(""s3://"")\n    assert constraints.file_s3_uri.endswith(""constraints.json"")\n\n    assert constraints.body_dict[""monitoring_config""][""evaluate_constraints""] == ""Enabled""\n\n\ndef test_constraint_violations_object_creation_from_file_path_with_customizations(\n    sagemaker_session, monitoring_files_kms_key\n):\n    constraint_violations = ConstraintViolations.from_file_path(\n        constraint_violations_file_path=os.path.join(\n            tests.integ.DATA_DIR, ""monitor/constraint_violations.json""\n        ),\n        kms_key=monitoring_files_kms_key,\n        sagemaker_session=sagemaker_session,\n    )\n\n    assert constraint_violations.file_s3_uri.startswith(""s3://"")\n    assert constraint_violations.file_s3_uri.endswith(""constraint_violations.json"")\n\n    assert constraint_violations.body_dict[""violations""][0][""feature_name""] == ""store_and_fwd_flag""\n\n\ndef test_constraint_violations_object_creation_from_file_path_without_customizations(\n    sagemaker_session\n):\n    constraint_violations = ConstraintViolations.from_file_path(\n        constraint_violations_file_path=os.path.join(\n            tests.integ.DATA_DIR, ""monitor/constraint_violations.json""\n        ),\n        sagemaker_session=sagemaker_session,\n    )\n\n    assert constraint_violations.file_s3_uri.startswith(""s3://"")\n    assert constraint_violations.file_s3_uri.endswith(""constraint_violations.json"")\n\n    assert constraint_violations.body_dict[""violations""][0][""feature_name""] == ""store_and_fwd_flag""\n\n\ndef test_constraint_violations_object_creation_from_string_with_customizations(\n    sagemaker_session, monitoring_files_kms_key\n):\n    with open(os.path.join(tests.integ.DATA_DIR, ""monitor/constraint_violations.json""), ""r"") as f:\n        file_body = f.read()\n\n    constraint_violations = ConstraintViolations.from_string(\n        constraint_violations_file_string=file_body,\n        kms_key=monitoring_files_kms_key,\n        file_name=""constraint_violations.json"",\n        sagemaker_session=sagemaker_session,\n    )\n\n    assert constraint_violations.file_s3_uri.startswith(""s3://"")\n    assert constraint_violations.file_s3_uri.endswith(""constraint_violations.json"")\n\n    assert constraint_violations.body_dict[""violations""][0][""feature_name""] == ""store_and_fwd_flag""\n\n\ndef test_constraint_violations_object_creation_from_string_without_customizations(\n    sagemaker_session\n):\n    with open(os.path.join(tests.integ.DATA_DIR, ""monitor/constraint_violations.json""), ""r"") as f:\n        file_body = f.read()\n\n    constraint_violations = ConstraintViolations.from_string(\n        constraint_violations_file_string=file_body, sagemaker_session=sagemaker_session\n    )\n\n    assert constraint_violations.file_s3_uri.startswith(""s3://"")\n    assert constraint_violations.file_s3_uri.endswith(""constraint_violations.json"")\n\n    assert constraint_violations.body_dict[""violations""][0][""feature_name""] == ""store_and_fwd_flag""\n\n\ndef test_constraint_violations_object_creation_from_s3_uri_with_customizations(\n    sagemaker_session, monitoring_files_kms_key\n):\n    with open(os.path.join(tests.integ.DATA_DIR, ""monitor/constraint_violations.json""), ""r"") as f:\n        file_body = f.read()\n\n    file_name = ""constraint_violations.json""\n    desired_s3_uri = os.path.join(\n        ""s3://"",\n        sagemaker_session.default_bucket(),\n        ""integ-test-test-monitoring-files"",\n        str(uuid.uuid4()),\n        file_name,\n    )\n\n    s3_uri = S3Uploader.upload_string_as_file_body(\n        body=file_body,\n        desired_s3_uri=desired_s3_uri,\n        kms_key=monitoring_files_kms_key,\n        session=sagemaker_session,\n    )\n\n    constraint_violations = ConstraintViolations.from_s3_uri(\n        constraint_violations_file_s3_uri=s3_uri,\n        kms_key=monitoring_files_kms_key,\n        sagemaker_session=sagemaker_session,\n    )\n\n    assert constraint_violations.file_s3_uri.startswith(""s3://"")\n    assert constraint_violations.file_s3_uri.endswith(""constraint_violations.json"")\n\n    assert constraint_violations.body_dict[""violations""][0][""feature_name""] == ""store_and_fwd_flag""\n\n\ndef test_constraint_violations_object_creation_from_s3_uri_without_customizations(\n    sagemaker_session\n):\n    with open(os.path.join(tests.integ.DATA_DIR, ""monitor/constraint_violations.json""), ""r"") as f:\n        file_body = f.read()\n\n    file_name = ""constraint_violations.json""\n    desired_s3_uri = os.path.join(\n        ""s3://"",\n        sagemaker_session.default_bucket(),\n        ""integ-test-test-monitoring-files"",\n        str(uuid.uuid4()),\n        file_name,\n    )\n\n    s3_uri = S3Uploader.upload_string_as_file_body(\n        body=file_body, desired_s3_uri=desired_s3_uri, session=sagemaker_session\n    )\n\n    constraint_violations = ConstraintViolations.from_s3_uri(\n        constraint_violations_file_s3_uri=s3_uri, sagemaker_session=sagemaker_session\n    )\n\n    assert constraint_violations.file_s3_uri.startswith(""s3://"")\n    assert constraint_violations.file_s3_uri.endswith(""constraint_violations.json"")\n\n    assert constraint_violations.body_dict[""violations""][0][""feature_name""] == ""store_and_fwd_flag""\n'"
tests/integ/test_multidatamodel.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport base64\nimport os\nimport requests\n\nimport botocore\nimport docker\nimport numpy\nimport pytest\nfrom botocore.exceptions import ClientError\n\nfrom sagemaker import utils\nfrom sagemaker.amazon.randomcutforest import RandomCutForest\nfrom sagemaker.multidatamodel import MultiDataModel\nfrom sagemaker.mxnet import MXNet\nfrom sagemaker.predictor import RealTimePredictor, StringDeserializer, npy_serializer\nfrom sagemaker.utils import sagemaker_timestamp, unique_name_from_base, get_ecr_image_uri_prefix\nfrom tests.integ import DATA_DIR, PYTHON_VERSION, TRAINING_DEFAULT_TIMEOUT_MINUTES\nfrom tests.integ.retry import retries\nfrom tests.integ.timeout import timeout, timeout_and_delete_endpoint_by_name\n\nROLE = ""SageMakerRole""\nPRETRAINED_MODEL_PATH_1 = ""customer_a/dummy_model.tar.gz""\nPRETRAINED_MODEL_PATH_2 = ""customer_b/dummy_model.tar.gz""\nstring_deserializer = StringDeserializer()\n\n\n@pytest.fixture(scope=""module"")\ndef container_image(sagemaker_session):\n    """""" Create a Multi-Model container image for use with integration testcases\n    since 1P containers supporting multiple models are not available yet""""""\n    region = sagemaker_session.boto_region_name\n    ecr_client = sagemaker_session.boto_session.client(""ecr"", region_name=region)\n    sts_client = sagemaker_session.boto_session.client(\n        ""sts"", region_name=region, endpoint_url=utils.sts_regional_endpoint(region)\n    )\n    account_id = sts_client.get_caller_identity()[""Account""]\n    algorithm_name = ""sagemaker-multimodel-integ-test-{}"".format(sagemaker_timestamp())\n    ecr_image_uri_prefix = get_ecr_image_uri_prefix(account=account_id, region=region)\n    ecr_image = ""{prefix}/{algorithm_name}:latest"".format(\n        prefix=ecr_image_uri_prefix, algorithm_name=algorithm_name\n    )\n\n    # Build and tag docker image locally\n    docker_client = docker.from_env()\n    image, build_log = docker_client.images.build(\n        path=os.path.join(DATA_DIR, ""multimodel"", ""container""), tag=algorithm_name, rm=True\n    )\n    image.tag(ecr_image, tag=""latest"")\n\n    # Create AWS ECR and push the local docker image to it\n    _create_repository(ecr_client, algorithm_name)\n    username, password = _ecr_login(ecr_client)\n    # Retry docker image push\n    for _ in retries(3, ""Upload docker image to ECR repo"", seconds_to_sleep=10):\n        try:\n            docker_client.images.push(\n                ecr_image, auth_config={""username"": username, ""password"": password}\n            )\n            break\n        except requests.exceptions.ConnectionError:\n            # This can happen when we try to create multiple repositories in parallel, so we retry\n            pass\n\n    yield ecr_image\n\n    # Delete repository after the multi model integration tests complete\n    _delete_repository(ecr_client, algorithm_name)\n\n\ndef _create_repository(ecr_client, repository_name):\n    """"""\n    Creates an ECS Repository (ECR). When a new transform is being registered,\n    we\'ll need a repository to push the image (and composed model images) to\n    """"""\n    try:\n        response = ecr_client.create_repository(repositoryName=repository_name)\n        return response[""repository""][""repositoryUri""]\n    except ClientError as e:\n        # Handle when the repository already exists\n        if ""RepositoryAlreadyExistsException"" == e.response.get(""Error"", {}).get(""Code""):\n            response = ecr_client.describe_repositories(repositoryNames=[repository_name])\n            return response[""repositories""][0][""repositoryUri""]\n        else:\n            raise\n\n\ndef _delete_repository(ecr_client, repository_name):\n    """"""\n    Deletes an ECS Repository (ECR). After the integration test completes\n    we will remove the repository created during setup\n    """"""\n    try:\n        ecr_client.describe_repositories(repositoryNames=[repository_name])\n        ecr_client.delete_repository(repositoryName=repository_name, force=True)\n    except botocore.errorfactory.ResourceNotFoundException:\n        pass\n\n\ndef _ecr_login(ecr_client):\n    """""" Get a login credentials for an ecr client.\n    """"""\n    login = ecr_client.get_authorization_token()\n    b64token = login[""authorizationData""][0][""authorizationToken""].encode(""utf-8"")\n    username, password = base64.b64decode(b64token).decode(""utf-8"").split("":"")\n    return username, password\n\n\ndef test_multi_data_model_deploy_pretrained_models(\n    container_image, sagemaker_session, cpu_instance_type\n):\n    timestamp = sagemaker_timestamp()\n    endpoint_name = ""test-multimodel-endpoint-{}"".format(timestamp)\n    model_name = ""test-multimodel-{}"".format(timestamp)\n\n    # Define pretrained model local path\n    pretrained_model_data_local_path = os.path.join(DATA_DIR, ""sparkml_model"", ""mleap_model.tar.gz"")\n\n    with timeout_and_delete_endpoint_by_name(endpoint_name, sagemaker_session):\n        model_data_prefix = os.path.join(\n            ""s3://"", sagemaker_session.default_bucket(), ""multimodel-{}/"".format(timestamp)\n        )\n        multi_data_model = MultiDataModel(\n            name=model_name,\n            model_data_prefix=model_data_prefix,\n            image=container_image,\n            role=ROLE,\n            sagemaker_session=sagemaker_session,\n        )\n\n        # Add model before deploy\n        multi_data_model.add_model(pretrained_model_data_local_path, PRETRAINED_MODEL_PATH_1)\n        # Deploy model to an endpoint\n        multi_data_model.deploy(1, cpu_instance_type, endpoint_name=endpoint_name)\n        # Add models after deploy\n        multi_data_model.add_model(pretrained_model_data_local_path, PRETRAINED_MODEL_PATH_2)\n\n        endpoint_models = []\n        for model_path in multi_data_model.list_models():\n            endpoint_models.append(model_path)\n        assert PRETRAINED_MODEL_PATH_1 in endpoint_models\n        assert PRETRAINED_MODEL_PATH_2 in endpoint_models\n\n        predictor = RealTimePredictor(\n            endpoint=endpoint_name,\n            sagemaker_session=sagemaker_session,\n            serializer=npy_serializer,\n            deserializer=string_deserializer,\n        )\n\n        data = numpy.zeros(shape=(1, 1, 28, 28))\n        result = predictor.predict(data, target_model=PRETRAINED_MODEL_PATH_1)\n        assert result == ""Invoked model: {}"".format(PRETRAINED_MODEL_PATH_1)\n\n        result = predictor.predict(data, target_model=PRETRAINED_MODEL_PATH_2)\n        assert result == ""Invoked model: {}"".format(PRETRAINED_MODEL_PATH_2)\n\n        # Cleanup\n        sagemaker_session.sagemaker_client.delete_endpoint_config(EndpointConfigName=endpoint_name)\n        multi_data_model.delete_model()\n    with pytest.raises(Exception) as exception:\n        sagemaker_session.sagemaker_client.describe_model(ModelName=multi_data_model.name)\n        assert ""Could not find model"" in str(exception.value)\n        sagemaker_session.sagemaker_client.describe_endpoint_config(name=endpoint_name)\n        assert ""Could not find endpoint"" in str(exception.value)\n\n\n@pytest.mark.local_mode\ndef test_multi_data_model_deploy_pretrained_models_local_mode(container_image, sagemaker_session):\n    timestamp = sagemaker_timestamp()\n    endpoint_name = ""test-multimodel-endpoint-{}"".format(timestamp)\n    model_name = ""test-multimodel-{}"".format(timestamp)\n\n    # Define pretrained model local path\n    pretrained_model_data_local_path = os.path.join(DATA_DIR, ""sparkml_model"", ""mleap_model.tar.gz"")\n\n    with timeout(minutes=30):\n        model_data_prefix = os.path.join(\n            ""s3://"", sagemaker_session.default_bucket(), ""multimodel-{}/"".format(timestamp)\n        )\n        multi_data_model = MultiDataModel(\n            name=model_name,\n            model_data_prefix=model_data_prefix,\n            image=container_image,\n            role=ROLE,\n            sagemaker_session=sagemaker_session,\n        )\n\n        # Add model before deploy\n        multi_data_model.add_model(pretrained_model_data_local_path, PRETRAINED_MODEL_PATH_1)\n        # Deploy model to an endpoint\n        multi_data_model.deploy(1, ""local"", endpoint_name=endpoint_name)\n        # Add models after deploy\n        multi_data_model.add_model(pretrained_model_data_local_path, PRETRAINED_MODEL_PATH_2)\n\n        endpoint_models = []\n        for model_path in multi_data_model.list_models():\n            endpoint_models.append(model_path)\n        assert PRETRAINED_MODEL_PATH_1 in endpoint_models\n        assert PRETRAINED_MODEL_PATH_2 in endpoint_models\n\n        predictor = RealTimePredictor(\n            endpoint=endpoint_name,\n            sagemaker_session=multi_data_model.sagemaker_session,\n            serializer=npy_serializer,\n            deserializer=string_deserializer,\n        )\n\n        data = numpy.zeros(shape=(1, 1, 28, 28))\n        result = predictor.predict(data, target_model=PRETRAINED_MODEL_PATH_1)\n        assert result == ""Invoked model: {}"".format(PRETRAINED_MODEL_PATH_1)\n\n        result = predictor.predict(data, target_model=PRETRAINED_MODEL_PATH_2)\n        assert result == ""Invoked model: {}"".format(PRETRAINED_MODEL_PATH_2)\n\n        # Cleanup\n        multi_data_model.sagemaker_session.sagemaker_client.delete_endpoint_config(\n            EndpointConfigName=endpoint_name\n        )\n        multi_data_model.sagemaker_session.delete_endpoint(endpoint_name)\n        multi_data_model.delete_model()\n    with pytest.raises(Exception) as exception:\n        sagemaker_session.sagemaker_client.describe_model(ModelName=multi_data_model.name)\n        assert ""Could not find model"" in str(exception.value)\n        sagemaker_session.sagemaker_client.describe_endpoint_config(name=endpoint_name)\n        assert ""Could not find endpoint"" in str(exception.value)\n\n\ndef test_multi_data_model_deploy_trained_model_from_framework_estimator(\n    container_image, sagemaker_session, cpu_instance_type\n):\n    timestamp = sagemaker_timestamp()\n    endpoint_name = ""test-multimodel-endpoint-{}"".format(timestamp)\n    model_name = ""test-multimodel-{}"".format(timestamp)\n    mxnet_version = ""1.4.1""\n\n    with timeout_and_delete_endpoint_by_name(endpoint_name, sagemaker_session):\n        mxnet_model_1 = __mxnet_training_job(\n            sagemaker_session, container_image, mxnet_version, cpu_instance_type, 0.1\n        )\n        model_data_prefix = os.path.join(\n            ""s3://"", sagemaker_session.default_bucket(), ""multimodel-{}/"".format(timestamp)\n        )\n        multi_data_model = MultiDataModel(\n            name=model_name,\n            model_data_prefix=model_data_prefix,\n            model=mxnet_model_1,\n            sagemaker_session=sagemaker_session,\n        )\n\n        # Add model before deploy\n        multi_data_model.add_model(mxnet_model_1.model_data, PRETRAINED_MODEL_PATH_1)\n        # Deploy model to an endpoint\n        multi_data_model.deploy(1, cpu_instance_type, endpoint_name=endpoint_name)\n\n        # Train another model\n        mxnet_model_2 = __mxnet_training_job(\n            sagemaker_session, container_image, mxnet_version, cpu_instance_type, 0.01\n        )\n        # Deploy newly trained model\n        multi_data_model.add_model(mxnet_model_2.model_data, PRETRAINED_MODEL_PATH_2)\n\n        endpoint_models = []\n        for model_path in multi_data_model.list_models():\n            endpoint_models.append(model_path)\n        assert PRETRAINED_MODEL_PATH_1 in endpoint_models\n        assert PRETRAINED_MODEL_PATH_2 in endpoint_models\n\n        # Define a predictor to set `serializer` parameter with npy_serializer\n        # instead of `json_serializer` in the default predictor returned by `MXNetPredictor`\n        # Since we are using a placeholder container image the prediction results are not accurate.\n        predictor = RealTimePredictor(\n            endpoint=endpoint_name,\n            sagemaker_session=sagemaker_session,\n            serializer=npy_serializer,\n            deserializer=string_deserializer,\n        )\n\n        data = numpy.zeros(shape=(1, 1, 28, 28))\n        # Prediction result for the first model\n        result = predictor.predict(data, target_model=PRETRAINED_MODEL_PATH_1)\n        assert result == ""Invoked model: {}"".format(PRETRAINED_MODEL_PATH_1)\n\n        # Prediction result for the second model\n        result = predictor.predict(data, target_model=PRETRAINED_MODEL_PATH_2)\n        assert result == ""Invoked model: {}"".format(PRETRAINED_MODEL_PATH_2)\n\n        # Cleanup\n        sagemaker_session.sagemaker_client.delete_endpoint_config(EndpointConfigName=endpoint_name)\n        multi_data_model.delete_model()\n    with pytest.raises(Exception) as exception:\n        sagemaker_session.sagemaker_client.describe_model(ModelName=model_name)\n        assert ""Could not find model"" in str(exception.value)\n        sagemaker_session.sagemaker_client.describe_endpoint_config(name=endpoint_name)\n        assert ""Could not find endpoint"" in str(exception.value)\n\n\ndef __mxnet_training_job(\n    sagemaker_session, container_image, mxnet_full_version, cpu_instance_type, learning_rate\n):\n    with timeout(minutes=TRAINING_DEFAULT_TIMEOUT_MINUTES):\n        script_path = os.path.join(DATA_DIR, ""mxnet_mnist"", ""mnist.py"")\n        data_path = os.path.join(DATA_DIR, ""mxnet_mnist"")\n\n        mx = MXNet(\n            entry_point=script_path,\n            role=ROLE,\n            framework_version=mxnet_full_version,\n            py_version=PYTHON_VERSION,\n            train_instance_count=1,\n            train_instance_type=cpu_instance_type,\n            sagemaker_session=sagemaker_session,\n            hyperparameters={""learning-rate"": learning_rate},\n        )\n\n        train_input = mx.sagemaker_session.upload_data(\n            path=os.path.join(data_path, ""train""), key_prefix=""integ-test-data/mxnet_mnist/train""\n        )\n        test_input = mx.sagemaker_session.upload_data(\n            path=os.path.join(data_path, ""test""), key_prefix=""integ-test-data/mxnet_mnist/test""\n        )\n\n        mx.fit({""train"": train_input, ""test"": test_input})\n\n        # Replace the container image value for now since the frameworks do not support\n        # multi-model container image yet.\n        return mx.create_model(image_name=container_image)\n\n\ndef test_multi_data_model_deploy_train_model_from_amazon_first_party_estimator(\n    container_image, sagemaker_session, cpu_instance_type\n):\n    timestamp = sagemaker_timestamp()\n    endpoint_name = ""test-multimodel-endpoint-{}"".format(timestamp)\n    model_name = ""test-multimodel-{}"".format(timestamp)\n\n    with timeout_and_delete_endpoint_by_name(endpoint_name, sagemaker_session):\n        rcf_model_v1 = __rcf_training_job(\n            sagemaker_session, container_image, cpu_instance_type, 50, 20\n        )\n\n        model_data_prefix = os.path.join(\n            ""s3://"", sagemaker_session.default_bucket(), ""multimodel-{}/"".format(timestamp)\n        )\n        multi_data_model = MultiDataModel(\n            name=model_name,\n            model_data_prefix=model_data_prefix,\n            model=rcf_model_v1,\n            sagemaker_session=sagemaker_session,\n        )\n\n        # Add model before deploy\n        multi_data_model.add_model(rcf_model_v1.model_data, PRETRAINED_MODEL_PATH_1)\n        # Deploy model to an endpoint\n        multi_data_model.deploy(1, cpu_instance_type, endpoint_name=endpoint_name)\n        # Train another model\n        rcf_model_v2 = __rcf_training_job(\n            sagemaker_session, container_image, cpu_instance_type, 70, 20\n        )\n        # Deploy newly trained model\n        multi_data_model.add_model(rcf_model_v2.model_data, PRETRAINED_MODEL_PATH_2)\n\n        # List model assertions\n        endpoint_models = []\n        for model_path in multi_data_model.list_models():\n            endpoint_models.append(model_path)\n        assert PRETRAINED_MODEL_PATH_1 in endpoint_models\n        assert PRETRAINED_MODEL_PATH_2 in endpoint_models\n\n        # Define a predictor to set `serializer` parameter with npy_serializer\n        # instead of `json_serializer` in the default predictor returned by `MXNetPredictor`\n        # Since we are using a placeholder container image the prediction results are not accurate.\n        predictor = RealTimePredictor(\n            endpoint=endpoint_name,\n            sagemaker_session=sagemaker_session,\n            serializer=npy_serializer,\n            deserializer=string_deserializer,\n        )\n\n        data = numpy.random.rand(1, 14)\n        # Prediction result for the first model\n        result = predictor.predict(data, target_model=PRETRAINED_MODEL_PATH_1)\n        assert result == ""Invoked model: {}"".format(PRETRAINED_MODEL_PATH_1)\n\n        # Prediction result for the second model\n        result = predictor.predict(data, target_model=PRETRAINED_MODEL_PATH_2)\n        assert result == ""Invoked model: {}"".format(PRETRAINED_MODEL_PATH_2)\n\n        # Cleanup\n        sagemaker_session.sagemaker_client.delete_endpoint_config(EndpointConfigName=endpoint_name)\n        multi_data_model.delete_model()\n    with pytest.raises(Exception) as exception:\n        sagemaker_session.sagemaker_client.describe_model(ModelName=model_name)\n        assert ""Could not find model"" in str(exception.value)\n        sagemaker_session.sagemaker_client.describe_endpoint_config(name=endpoint_name)\n        assert ""Could not find endpoint"" in str(exception.value)\n\n\ndef __rcf_training_job(\n    sagemaker_session, container_image, cpu_instance_type, num_trees, num_samples_per_tree\n):\n    job_name = unique_name_from_base(""randomcutforest"")\n    with timeout(minutes=TRAINING_DEFAULT_TIMEOUT_MINUTES):\n        # Generate a thousand 14-dimensional datapoints.\n        feature_num = 14\n        train_input = numpy.random.rand(1000, feature_num)\n\n        rcf = RandomCutForest(\n            role=ROLE,\n            train_instance_count=1,\n            train_instance_type=cpu_instance_type,\n            num_trees=num_trees,\n            num_samples_per_tree=num_samples_per_tree,\n            eval_metrics=[""accuracy"", ""precision_recall_fscore""],\n            sagemaker_session=sagemaker_session,\n        )\n\n        rcf.fit(records=rcf.record_set(train_input), job_name=job_name)\n\n        # Replace the container image value with a multi-model container image for now since the\n        # frameworks do not support multi-model container image yet.\n        rcf_model = rcf.create_model()\n        rcf_model.image = container_image\n        return rcf_model\n\n\ndef test_multi_data_model_deploy_pretrained_models_update_endpoint(\n    container_image, sagemaker_session, cpu_instance_type, alternative_cpu_instance_type\n):\n    timestamp = sagemaker_timestamp()\n    endpoint_name = ""test-multimodel-endpoint-{}"".format(timestamp)\n    model_name = ""test-multimodel-{}"".format(timestamp)\n\n    # Define pretrained model local path\n    pretrained_model_data_local_path = os.path.join(DATA_DIR, ""sparkml_model"", ""mleap_model.tar.gz"")\n\n    with timeout_and_delete_endpoint_by_name(endpoint_name, sagemaker_session):\n        model_data_prefix = os.path.join(\n            ""s3://"", sagemaker_session.default_bucket(), ""multimodel-{}/"".format(timestamp)\n        )\n        multi_data_model = MultiDataModel(\n            name=model_name,\n            model_data_prefix=model_data_prefix,\n            image=container_image,\n            role=ROLE,\n            sagemaker_session=sagemaker_session,\n        )\n\n        # Add model before deploy\n        multi_data_model.add_model(pretrained_model_data_local_path, PRETRAINED_MODEL_PATH_1)\n        # Deploy model to an endpoint\n        multi_data_model.deploy(1, cpu_instance_type, endpoint_name=endpoint_name)\n        # Add model after deploy\n        multi_data_model.add_model(pretrained_model_data_local_path, PRETRAINED_MODEL_PATH_2)\n\n        # List model assertions\n        endpoint_models = []\n        for model_path in multi_data_model.list_models():\n            endpoint_models.append(model_path)\n        assert PRETRAINED_MODEL_PATH_1 in endpoint_models\n        assert PRETRAINED_MODEL_PATH_2 in endpoint_models\n\n        predictor = RealTimePredictor(\n            endpoint=endpoint_name,\n            sagemaker_session=sagemaker_session,\n            serializer=npy_serializer,\n            deserializer=string_deserializer,\n        )\n\n        data = numpy.zeros(shape=(1, 1, 28, 28))\n        result = predictor.predict(data, target_model=PRETRAINED_MODEL_PATH_1)\n        assert result == ""Invoked model: {}"".format(PRETRAINED_MODEL_PATH_1)\n\n        result = predictor.predict(data, target_model=PRETRAINED_MODEL_PATH_2)\n        assert result == ""Invoked model: {}"".format(PRETRAINED_MODEL_PATH_2)\n\n        old_endpoint = sagemaker_session.sagemaker_client.describe_endpoint(\n            EndpointName=endpoint_name\n        )\n        old_config_name = old_endpoint[""EndpointConfigName""]\n\n        # Update endpoint\n        multi_data_model.deploy(\n            1, alternative_cpu_instance_type, endpoint_name=endpoint_name, update_endpoint=True\n        )\n\n        # Wait for endpoint to finish updating\n        for _ in retries(40, ""Waiting for \'InService\' endpoint status"", seconds_to_sleep=30):\n            new_endpoint = sagemaker_session.sagemaker_client.describe_endpoint(\n                EndpointName=endpoint_name\n            )\n            if new_endpoint[""EndpointStatus""] == ""InService"":\n                break\n\n        new_config_name = new_endpoint[""EndpointConfigName""]\n\n        new_config = sagemaker_session.sagemaker_client.describe_endpoint_config(\n            EndpointConfigName=new_config_name\n        )\n        assert old_config_name != new_config_name\n        assert new_config[""ProductionVariants""][0][""InstanceType""] == alternative_cpu_instance_type\n        assert new_config[""ProductionVariants""][0][""InitialInstanceCount""] == 1\n\n        # Cleanup\n        sagemaker_session.sagemaker_client.delete_endpoint_config(\n            EndpointConfigName=old_config_name\n        )\n        sagemaker_session.sagemaker_client.delete_endpoint_config(\n            EndpointConfigName=new_config_name\n        )\n        multi_data_model.delete_model()\n    with pytest.raises(Exception) as exception:\n        sagemaker_session.sagemaker_client.describe_model(ModelName=model_name)\n        assert ""Could not find model"" in str(exception.value)\n        sagemaker_session.sagemaker_client.describe_endpoint_config(name=old_config_name)\n        assert ""Could not find endpoint"" in str(exception.value)\n        sagemaker_session.sagemaker_client.describe_endpoint_config(name=new_config_name)\n        assert ""Could not find endpoint"" in str(exception.value)\n'"
tests/integ/test_mxnet_train.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport os\nimport time\n\nimport numpy\nimport pytest\n\nimport tests.integ\nfrom sagemaker.mxnet.estimator import MXNet\nfrom sagemaker.mxnet.model import MXNetModel\nfrom sagemaker.utils import sagemaker_timestamp\nfrom tests.integ import DATA_DIR, PYTHON_VERSION, TRAINING_DEFAULT_TIMEOUT_MINUTES\nfrom tests.integ.kms_utils import get_or_create_kms_key\nfrom tests.integ.retry import retries\nfrom tests.integ.timeout import timeout, timeout_and_delete_endpoint_by_name\n\n\n@pytest.fixture(scope=""module"")\ndef mxnet_training_job(sagemaker_session, mxnet_full_version, cpu_instance_type):\n    with timeout(minutes=TRAINING_DEFAULT_TIMEOUT_MINUTES):\n        script_path = os.path.join(DATA_DIR, ""mxnet_mnist"", ""mnist.py"")\n        data_path = os.path.join(DATA_DIR, ""mxnet_mnist"")\n\n        mx = MXNet(\n            entry_point=script_path,\n            role=""SageMakerRole"",\n            framework_version=mxnet_full_version,\n            py_version=PYTHON_VERSION,\n            train_instance_count=1,\n            train_instance_type=cpu_instance_type,\n            sagemaker_session=sagemaker_session,\n        )\n\n        train_input = mx.sagemaker_session.upload_data(\n            path=os.path.join(data_path, ""train""), key_prefix=""integ-test-data/mxnet_mnist/train""\n        )\n        test_input = mx.sagemaker_session.upload_data(\n            path=os.path.join(data_path, ""test""), key_prefix=""integ-test-data/mxnet_mnist/test""\n        )\n\n        mx.fit({""train"": train_input, ""test"": test_input})\n        return mx.latest_training_job.name\n\n\n@pytest.mark.canary_quick\n@pytest.mark.regional_testing\ndef test_attach_deploy(mxnet_training_job, sagemaker_session, cpu_instance_type):\n    endpoint_name = ""test-mxnet-attach-deploy-{}"".format(sagemaker_timestamp())\n\n    with timeout_and_delete_endpoint_by_name(endpoint_name, sagemaker_session):\n        estimator = MXNet.attach(mxnet_training_job, sagemaker_session=sagemaker_session)\n        predictor = estimator.deploy(1, cpu_instance_type, endpoint_name=endpoint_name)\n        data = numpy.zeros(shape=(1, 1, 28, 28))\n        result = predictor.predict(data)\n        assert result is not None\n\n\ndef test_deploy_model(mxnet_training_job, sagemaker_session, mxnet_full_version, cpu_instance_type):\n    endpoint_name = ""test-mxnet-deploy-model-{}"".format(sagemaker_timestamp())\n\n    with timeout_and_delete_endpoint_by_name(endpoint_name, sagemaker_session):\n        desc = sagemaker_session.sagemaker_client.describe_training_job(\n            TrainingJobName=mxnet_training_job\n        )\n        model_data = desc[""ModelArtifacts""][""S3ModelArtifacts""]\n        script_path = os.path.join(DATA_DIR, ""mxnet_mnist"", ""mnist.py"")\n        model = MXNetModel(\n            model_data,\n            ""SageMakerRole"",\n            entry_point=script_path,\n            py_version=PYTHON_VERSION,\n            sagemaker_session=sagemaker_session,\n            framework_version=mxnet_full_version,\n        )\n        predictor = model.deploy(1, cpu_instance_type, endpoint_name=endpoint_name)\n\n        data = numpy.zeros(shape=(1, 1, 28, 28))\n        result = predictor.predict(data)\n        assert result is not None\n\n    predictor.delete_model()\n    with pytest.raises(Exception) as exception:\n        sagemaker_session.sagemaker_client.describe_model(ModelName=model.name)\n        assert ""Could not find model"" in str(exception.value)\n\n\ndef test_deploy_model_with_tags_and_kms(\n    mxnet_training_job, sagemaker_session, mxnet_full_version, cpu_instance_type\n):\n    endpoint_name = ""test-mxnet-deploy-model-{}"".format(sagemaker_timestamp())\n\n    with timeout_and_delete_endpoint_by_name(endpoint_name, sagemaker_session):\n        desc = sagemaker_session.sagemaker_client.describe_training_job(\n            TrainingJobName=mxnet_training_job\n        )\n        model_data = desc[""ModelArtifacts""][""S3ModelArtifacts""]\n        script_path = os.path.join(DATA_DIR, ""mxnet_mnist"", ""mnist.py"")\n        model = MXNetModel(\n            model_data,\n            ""SageMakerRole"",\n            entry_point=script_path,\n            py_version=PYTHON_VERSION,\n            sagemaker_session=sagemaker_session,\n            framework_version=mxnet_full_version,\n        )\n\n        tags = [{""Key"": ""TagtestKey"", ""Value"": ""TagtestValue""}]\n        kms_key_arn = get_or_create_kms_key(sagemaker_session)\n\n        model.deploy(\n            1, cpu_instance_type, endpoint_name=endpoint_name, tags=tags, kms_key=kms_key_arn\n        )\n\n        returned_model = sagemaker_session.sagemaker_client.describe_model(ModelName=model.name)\n        returned_model_tags = sagemaker_session.sagemaker_client.list_tags(\n            ResourceArn=returned_model[""ModelArn""]\n        )[""Tags""]\n\n        endpoint = sagemaker_session.sagemaker_client.describe_endpoint(EndpointName=endpoint_name)\n        endpoint_tags = sagemaker_session.sagemaker_client.list_tags(\n            ResourceArn=endpoint[""EndpointArn""]\n        )[""Tags""]\n\n        endpoint_config = sagemaker_session.sagemaker_client.describe_endpoint_config(\n            EndpointConfigName=endpoint[""EndpointConfigName""]\n        )\n        endpoint_config_tags = sagemaker_session.sagemaker_client.list_tags(\n            ResourceArn=endpoint_config[""EndpointConfigArn""]\n        )[""Tags""]\n\n        production_variants = endpoint_config[""ProductionVariants""]\n\n        assert returned_model_tags == tags\n        assert endpoint_config_tags == tags\n        assert endpoint_tags == tags\n        assert production_variants[0][""InstanceType""] == cpu_instance_type\n        assert production_variants[0][""InitialInstanceCount""] == 1\n        assert endpoint_config[""KmsKeyId""] == kms_key_arn\n\n\ndef test_deploy_model_with_update_endpoint(\n    mxnet_training_job,\n    sagemaker_session,\n    mxnet_full_version,\n    cpu_instance_type,\n    alternative_cpu_instance_type,\n):\n    endpoint_name = ""test-mxnet-deploy-model-{}"".format(sagemaker_timestamp())\n\n    with timeout_and_delete_endpoint_by_name(endpoint_name, sagemaker_session):\n        desc = sagemaker_session.sagemaker_client.describe_training_job(\n            TrainingJobName=mxnet_training_job\n        )\n        model_data = desc[""ModelArtifacts""][""S3ModelArtifacts""]\n        script_path = os.path.join(DATA_DIR, ""mxnet_mnist"", ""mnist.py"")\n        model = MXNetModel(\n            model_data,\n            ""SageMakerRole"",\n            entry_point=script_path,\n            py_version=PYTHON_VERSION,\n            sagemaker_session=sagemaker_session,\n            framework_version=mxnet_full_version,\n        )\n        model.deploy(1, alternative_cpu_instance_type, endpoint_name=endpoint_name)\n        old_endpoint = sagemaker_session.sagemaker_client.describe_endpoint(\n            EndpointName=endpoint_name\n        )\n        old_config_name = old_endpoint[""EndpointConfigName""]\n\n        model.deploy(1, cpu_instance_type, update_endpoint=True, endpoint_name=endpoint_name)\n\n        # Wait for endpoint to finish updating\n        # Endpoint update takes ~7min. 40 retries * 30s sleeps = 20min timeout\n        for _ in retries(40, ""Waiting for \'InService\' endpoint status"", seconds_to_sleep=30):\n            new_endpoint = sagemaker_session.sagemaker_client.describe_endpoint(\n                EndpointName=endpoint_name\n            )\n            if new_endpoint[""EndpointStatus""] == ""InService"":\n                break\n\n        new_config_name = new_endpoint[""EndpointConfigName""]\n        new_config = sagemaker_session.sagemaker_client.describe_endpoint_config(\n            EndpointConfigName=new_config_name\n        )\n\n        assert old_config_name != new_config_name\n        assert new_config[""ProductionVariants""][0][""InstanceType""] == cpu_instance_type\n        assert new_config[""ProductionVariants""][0][""InitialInstanceCount""] == 1\n\n\ndef test_deploy_model_with_update_non_existing_endpoint(\n    mxnet_training_job,\n    sagemaker_session,\n    mxnet_full_version,\n    cpu_instance_type,\n    alternative_cpu_instance_type,\n):\n    endpoint_name = ""test-mxnet-deploy-model-{}"".format(sagemaker_timestamp())\n    expected_error_message = (\n        \'Endpoint with name ""{}"" does not exist; \'\n        ""please use an existing endpoint name"".format(endpoint_name)\n    )\n\n    with timeout_and_delete_endpoint_by_name(endpoint_name, sagemaker_session):\n        desc = sagemaker_session.sagemaker_client.describe_training_job(\n            TrainingJobName=mxnet_training_job\n        )\n        model_data = desc[""ModelArtifacts""][""S3ModelArtifacts""]\n        script_path = os.path.join(DATA_DIR, ""mxnet_mnist"", ""mnist.py"")\n        model = MXNetModel(\n            model_data,\n            ""SageMakerRole"",\n            entry_point=script_path,\n            py_version=PYTHON_VERSION,\n            sagemaker_session=sagemaker_session,\n            framework_version=mxnet_full_version,\n        )\n        model.deploy(1, alternative_cpu_instance_type, endpoint_name=endpoint_name)\n        sagemaker_session.sagemaker_client.describe_endpoint(EndpointName=endpoint_name)\n\n        with pytest.raises(ValueError, message=expected_error_message):\n            model.deploy(\n                1, cpu_instance_type, update_endpoint=True, endpoint_name=""non-existing-endpoint""\n            )\n\n\n@pytest.mark.canary_quick\n@pytest.mark.regional_testing\n@pytest.mark.skipif(\n    tests.integ.test_region() not in tests.integ.EI_SUPPORTED_REGIONS,\n    reason=""EI isn\'t supported in that specific region."",\n)\ndef test_deploy_model_with_accelerator(\n    mxnet_training_job, sagemaker_session, ei_mxnet_full_version, cpu_instance_type\n):\n    endpoint_name = ""test-mxnet-deploy-model-ei-{}"".format(sagemaker_timestamp())\n\n    with timeout_and_delete_endpoint_by_name(endpoint_name, sagemaker_session):\n        desc = sagemaker_session.sagemaker_client.describe_training_job(\n            TrainingJobName=mxnet_training_job\n        )\n        model_data = desc[""ModelArtifacts""][""S3ModelArtifacts""]\n        script_path = os.path.join(DATA_DIR, ""mxnet_mnist"", ""mnist.py"")\n        model = MXNetModel(\n            model_data,\n            ""SageMakerRole"",\n            entry_point=script_path,\n            framework_version=ei_mxnet_full_version,\n            py_version=PYTHON_VERSION,\n            sagemaker_session=sagemaker_session,\n        )\n        predictor = model.deploy(\n            1, cpu_instance_type, endpoint_name=endpoint_name, accelerator_type=""ml.eia1.medium""\n        )\n\n        data = numpy.zeros(shape=(1, 1, 28, 28))\n        result = predictor.predict(data)\n        assert result is not None\n\n\ndef test_async_fit(sagemaker_session, mxnet_full_version, cpu_instance_type):\n    endpoint_name = ""test-mxnet-attach-deploy-{}"".format(sagemaker_timestamp())\n\n    with timeout(minutes=5):\n        script_path = os.path.join(DATA_DIR, ""mxnet_mnist"", ""mnist.py"")\n        data_path = os.path.join(DATA_DIR, ""mxnet_mnist"")\n\n        mx = MXNet(\n            entry_point=script_path,\n            role=""SageMakerRole"",\n            py_version=PYTHON_VERSION,\n            train_instance_count=1,\n            train_instance_type=cpu_instance_type,\n            sagemaker_session=sagemaker_session,\n            framework_version=mxnet_full_version,\n            distributions={""parameter_server"": {""enabled"": True}},\n        )\n\n        train_input = mx.sagemaker_session.upload_data(\n            path=os.path.join(data_path, ""train""), key_prefix=""integ-test-data/mxnet_mnist/train""\n        )\n        test_input = mx.sagemaker_session.upload_data(\n            path=os.path.join(data_path, ""test""), key_prefix=""integ-test-data/mxnet_mnist/test""\n        )\n\n        mx.fit({""train"": train_input, ""test"": test_input}, wait=False)\n        training_job_name = mx.latest_training_job.name\n\n        print(""Waiting to re-attach to the training job: %s"" % training_job_name)\n        time.sleep(20)\n\n    with timeout_and_delete_endpoint_by_name(endpoint_name, sagemaker_session):\n        print(""Re-attaching now to: %s"" % training_job_name)\n        estimator = MXNet.attach(\n            training_job_name=training_job_name, sagemaker_session=sagemaker_session\n        )\n        predictor = estimator.deploy(1, cpu_instance_type, endpoint_name=endpoint_name)\n        data = numpy.zeros(shape=(1, 1, 28, 28))\n        result = predictor.predict(data)\n        assert result is not None\n'"
tests/integ/test_neo_mxnet.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport os\n\nimport numpy\nimport pytest\n\nfrom sagemaker.mxnet.estimator import MXNet\nfrom sagemaker.mxnet.model import MXNetModel\nfrom sagemaker.utils import unique_name_from_base\nfrom tests.integ import DATA_DIR, PYTHON_VERSION, TRAINING_DEFAULT_TIMEOUT_MINUTES\nfrom tests.integ.timeout import timeout, timeout_and_delete_endpoint_by_name\n\nNEO_MXNET_VERSION = ""1.4.1""  # Neo doesn\'t support MXNet 1.6 yet.\nINF_MXNET_VERSION = ""1.5.1""\n\n\n@pytest.fixture(scope=""module"")\ndef mxnet_training_job(sagemaker_session, cpu_instance_type):\n    with timeout(minutes=TRAINING_DEFAULT_TIMEOUT_MINUTES):\n        script_path = os.path.join(DATA_DIR, ""mxnet_mnist"", ""mnist_neo.py"")\n        data_path = os.path.join(DATA_DIR, ""mxnet_mnist"")\n\n        mx = MXNet(\n            entry_point=script_path,\n            role=""SageMakerRole"",\n            framework_version=NEO_MXNET_VERSION,\n            py_version=PYTHON_VERSION,\n            train_instance_count=1,\n            train_instance_type=cpu_instance_type,\n            sagemaker_session=sagemaker_session,\n        )\n\n        train_input = mx.sagemaker_session.upload_data(\n            path=os.path.join(data_path, ""train""), key_prefix=""integ-test-data/mxnet_mnist/train""\n        )\n        test_input = mx.sagemaker_session.upload_data(\n            path=os.path.join(data_path, ""test""), key_prefix=""integ-test-data/mxnet_mnist/test""\n        )\n\n        mx.fit({""train"": train_input, ""test"": test_input})\n        return mx.latest_training_job.name\n\n\n@pytest.mark.canary_quick\n@pytest.mark.regional_testing\ndef test_attach_deploy(\n    mxnet_training_job, sagemaker_session, cpu_instance_type, cpu_instance_family\n):\n    endpoint_name = unique_name_from_base(""test-neo-attach-deploy"")\n\n    with timeout_and_delete_endpoint_by_name(endpoint_name, sagemaker_session):\n        estimator = MXNet.attach(mxnet_training_job, sagemaker_session=sagemaker_session)\n\n        estimator.compile_model(\n            target_instance_family=cpu_instance_family,\n            input_shape={""data"": [1, 1, 28, 28]},\n            output_path=estimator.output_path,\n        )\n\n        predictor = estimator.deploy(\n            1, cpu_instance_type, use_compiled_model=True, endpoint_name=endpoint_name\n        )\n        predictor.content_type = ""application/vnd+python.numpy+binary""\n        data = numpy.zeros(shape=(1, 1, 28, 28))\n        predictor.predict(data)\n\n\ndef test_deploy_model(\n    mxnet_training_job, sagemaker_session, cpu_instance_type, cpu_instance_family\n):\n    endpoint_name = unique_name_from_base(""test-neo-deploy-model"")\n\n    with timeout_and_delete_endpoint_by_name(endpoint_name, sagemaker_session):\n        desc = sagemaker_session.sagemaker_client.describe_training_job(\n            TrainingJobName=mxnet_training_job\n        )\n        model_data = desc[""ModelArtifacts""][""S3ModelArtifacts""]\n        script_path = os.path.join(DATA_DIR, ""mxnet_mnist"", ""mnist_neo.py"")\n        role = ""SageMakerRole""\n        model = MXNetModel(\n            model_data,\n            role,\n            entry_point=script_path,\n            py_version=PYTHON_VERSION,\n            framework_version=NEO_MXNET_VERSION,\n            sagemaker_session=sagemaker_session,\n        )\n\n        model.compile(\n            target_instance_family=cpu_instance_family,\n            input_shape={""data"": [1, 1, 28, 28]},\n            role=role,\n            job_name=unique_name_from_base(""test-deploy-model-compilation-job""),\n            output_path=""/"".join(model_data.split(""/"")[:-1]),\n        )\n        predictor = model.deploy(1, cpu_instance_type, endpoint_name=endpoint_name)\n\n        predictor.content_type = ""application/vnd+python.numpy+binary""\n        data = numpy.zeros(shape=(1, 1, 28, 28))\n        predictor.predict(data)\n\n\n@pytest.mark.skip(reason=""Inferentia is not supported yet."")\ndef test_inferentia_deploy_model(\n    mxnet_training_job, sagemaker_session, inf_instance_type, inf_instance_family\n):\n    endpoint_name = unique_name_from_base(""test-neo-deploy-model"")\n\n    with timeout_and_delete_endpoint_by_name(endpoint_name, sagemaker_session):\n        desc = sagemaker_session.sagemaker_client.describe_training_job(\n            TrainingJobName=mxnet_training_job\n        )\n        model_data = desc[""ModelArtifacts""][""S3ModelArtifacts""]\n        script_path = os.path.join(DATA_DIR, ""mxnet_mnist"", ""mnist_neo.py"")\n        role = ""SageMakerRole""\n        model = MXNetModel(\n            model_data,\n            role,\n            entry_point=script_path,\n            framework_version=INF_MXNET_VERSION,\n            sagemaker_session=sagemaker_session,\n        )\n\n        model.compile(\n            target_instance_family=inf_instance_family,\n            input_shape={""data"": [1, 1, 28, 28]},\n            role=role,\n            job_name=unique_name_from_base(""test-deploy-model-compilation-job""),\n            output_path=""/"".join(model_data.split(""/"")[:-1]),\n        )\n        predictor = model.deploy(1, inf_instance_type, endpoint_name=endpoint_name)\n\n        predictor.content_type = ""application/vnd+python.numpy+binary""\n        data = numpy.zeros(shape=(1, 1, 28, 28))\n        predictor.predict(data)\n'"
tests/integ/test_ntm.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport os\n\nimport numpy as np\nimport pytest\n\nfrom sagemaker import NTM, NTMModel\nfrom sagemaker.amazon.common import read_records\nfrom sagemaker.utils import unique_name_from_base\nfrom tests.integ import DATA_DIR, TRAINING_DEFAULT_TIMEOUT_MINUTES\nfrom tests.integ.timeout import timeout, timeout_and_delete_endpoint_by_name\nfrom tests.integ.record_set import prepare_record_set_from_local_files\n\n\n@pytest.mark.canary_quick\n@pytest.mark.skip(\n    reason=""This test has always failed, but the failure was masked by a bug. ""\n    ""This test should be fixed. Details in https://github.com/aws/sagemaker-python-sdk/pull/968""\n)\ndef test_ntm(sagemaker_session, cpu_instance_type):\n    job_name = unique_name_from_base(""ntm"")\n\n    with timeout(minutes=TRAINING_DEFAULT_TIMEOUT_MINUTES):\n        data_path = os.path.join(DATA_DIR, ""ntm"")\n        data_filename = ""nips-train_1.pbr""\n\n        with open(os.path.join(data_path, data_filename), ""rb"") as f:\n            all_records = read_records(f)\n\n        # all records must be same\n        feature_num = int(all_records[0].features[""values""].float32_tensor.shape[0])\n\n        ntm = NTM(\n            role=""SageMakerRole"",\n            train_instance_count=1,\n            train_instance_type=cpu_instance_type,\n            num_topics=10,\n            sagemaker_session=sagemaker_session,\n        )\n\n        record_set = prepare_record_set_from_local_files(\n            data_path, ntm.data_location, len(all_records), feature_num, sagemaker_session\n        )\n        ntm.fit(records=record_set, job_name=job_name)\n\n    with timeout_and_delete_endpoint_by_name(job_name, sagemaker_session):\n        model = NTMModel(ntm.model_data, role=""SageMakerRole"", sagemaker_session=sagemaker_session)\n        predictor = model.deploy(1, cpu_instance_type, endpoint_name=job_name)\n\n        predict_input = np.random.rand(1, feature_num)\n        result = predictor.predict(predict_input)\n\n        assert len(result) == 1\n        for record in result:\n            assert record.label[""topic_weights""] is not None\n'"
tests/integ/test_object2vec.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport os\n\nimport pytest\n\nfrom sagemaker.predictor import RealTimePredictor\nfrom sagemaker import Object2Vec, Object2VecModel\nfrom sagemaker.utils import unique_name_from_base\nfrom tests.integ import DATA_DIR, TRAINING_DEFAULT_TIMEOUT_MINUTES\nfrom tests.integ.timeout import timeout, timeout_and_delete_endpoint_by_name\nfrom tests.integ.record_set import prepare_record_set_from_local_files\n\nFEATURE_NUM = None\n\n\n@pytest.mark.skip(\n    reason=""This test has always failed, but the failure was masked by a bug. ""\n    ""This test should be fixed. Details in https://github.com/aws/sagemaker-python-sdk/pull/968""\n)\ndef test_object2vec(sagemaker_session, cpu_instance_type):\n    job_name = unique_name_from_base(""object2vec"")\n\n    with timeout(minutes=TRAINING_DEFAULT_TIMEOUT_MINUTES):\n        data_path = os.path.join(DATA_DIR, ""object2vec"")\n        data_filename = ""train.jsonl""\n\n        with open(os.path.join(data_path, data_filename), ""r"") as f:\n            num_records = len(f.readlines())\n\n        object2vec = Object2Vec(\n            role=""SageMakerRole"",\n            train_instance_count=1,\n            train_instance_type=cpu_instance_type,\n            epochs=3,\n            enc0_max_seq_len=20,\n            enc0_vocab_size=45000,\n            enc_dim=16,\n            num_classes=3,\n            negative_sampling_rate=0,\n            comparator_list=""hadamard,concat,abs_diff"",\n            tied_token_embedding_weight=False,\n            token_embedding_storage_type=""dense"",\n            sagemaker_session=sagemaker_session,\n        )\n\n        record_set = prepare_record_set_from_local_files(\n            data_path, object2vec.data_location, num_records, FEATURE_NUM, sagemaker_session\n        )\n\n        object2vec.fit(records=record_set, job_name=job_name)\n\n    with timeout_and_delete_endpoint_by_name(job_name, sagemaker_session):\n        model = Object2VecModel(\n            object2vec.model_data, role=""SageMakerRole"", sagemaker_session=sagemaker_session\n        )\n        predictor = model.deploy(1, cpu_instance_type, endpoint_name=job_name)\n        assert isinstance(predictor, RealTimePredictor)\n\n        predict_input = {""instances"": [{""in0"": [354, 623], ""in1"": [16]}]}\n\n        result = predictor.predict(predict_input)\n\n        assert len(result) == 1\n        for record in result:\n            assert record.label[""scores""] is not None\n'"
tests/integ/test_pca.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport gzip\nimport os\nimport pickle\nimport sys\nimport time\n\nimport sagemaker.amazon.pca\nfrom sagemaker.utils import unique_name_from_base\nfrom tests.integ import DATA_DIR, TRAINING_DEFAULT_TIMEOUT_MINUTES\nfrom tests.integ.timeout import timeout, timeout_and_delete_endpoint_by_name\n\n\ndef test_pca(sagemaker_session, cpu_instance_type):\n    job_name = unique_name_from_base(""pca"")\n\n    with timeout(minutes=TRAINING_DEFAULT_TIMEOUT_MINUTES):\n        data_path = os.path.join(DATA_DIR, ""one_p_mnist"", ""mnist.pkl.gz"")\n        pickle_args = {} if sys.version_info.major == 2 else {""encoding"": ""latin1""}\n\n        # Load the data into memory as numpy arrays\n        with gzip.open(data_path, ""rb"") as f:\n            train_set, _, _ = pickle.load(f, **pickle_args)\n\n        pca = sagemaker.amazon.pca.PCA(\n            role=""SageMakerRole"",\n            train_instance_count=1,\n            train_instance_type=cpu_instance_type,\n            num_components=48,\n            sagemaker_session=sagemaker_session,\n            enable_network_isolation=True,\n        )\n\n        pca.algorithm_mode = ""randomized""\n        pca.subtract_mean = True\n        pca.extra_components = 5\n        pca.fit(pca.record_set(train_set[0][:100]), job_name=job_name)\n\n    with timeout_and_delete_endpoint_by_name(job_name, sagemaker_session):\n        pca_model = sagemaker.amazon.pca.PCAModel(\n            model_data=pca.model_data,\n            role=""SageMakerRole"",\n            sagemaker_session=sagemaker_session,\n            enable_network_isolation=True,\n        )\n        predictor = pca_model.deploy(\n            initial_instance_count=1, instance_type=cpu_instance_type, endpoint_name=job_name\n        )\n\n        result = predictor.predict(train_set[0][:5])\n\n        assert len(result) == 5\n        for record in result:\n            assert record.label[""projection""] is not None\n\n\ndef test_async_pca(sagemaker_session, cpu_instance_type):\n    job_name = unique_name_from_base(""pca"")\n\n    with timeout(minutes=5):\n        data_path = os.path.join(DATA_DIR, ""one_p_mnist"", ""mnist.pkl.gz"")\n        pickle_args = {} if sys.version_info.major == 2 else {""encoding"": ""latin1""}\n\n        # Load the data into memory as numpy arrays\n        with gzip.open(data_path, ""rb"") as f:\n            train_set, _, _ = pickle.load(f, **pickle_args)\n\n        pca = sagemaker.amazon.pca.PCA(\n            role=""SageMakerRole"",\n            train_instance_count=1,\n            train_instance_type=cpu_instance_type,\n            num_components=48,\n            sagemaker_session=sagemaker_session,\n            base_job_name=""test-pca"",\n        )\n\n        pca.algorithm_mode = ""randomized""\n        pca.subtract_mean = True\n        pca.extra_components = 5\n        pca.fit(pca.record_set(train_set[0][:100]), wait=False, job_name=job_name)\n\n        print(""Detached from training job. Will re-attach in 20 seconds"")\n        time.sleep(20)\n\n    with timeout_and_delete_endpoint_by_name(job_name, sagemaker_session):\n        estimator = sagemaker.amazon.pca.PCA.attach(\n            training_job_name=job_name, sagemaker_session=sagemaker_session\n        )\n\n        model = sagemaker.amazon.pca.PCAModel(\n            estimator.model_data, role=""SageMakerRole"", sagemaker_session=sagemaker_session\n        )\n        predictor = model.deploy(\n            initial_instance_count=1, instance_type=cpu_instance_type, endpoint_name=job_name\n        )\n\n        result = predictor.predict(train_set[0][:5])\n\n        assert len(result) == 5\n        for record in result:\n            assert record.label[""projection""] is not None\n'"
tests/integ/test_processing.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport os\n\nimport pytest\nfrom botocore.config import Config\nfrom sagemaker import Session\nfrom sagemaker.fw_registry import default_framework_uri\n\nfrom sagemaker.processing import (\n    ProcessingInput,\n    ProcessingOutput,\n    ScriptProcessor,\n    Processor,\n    ProcessingJob,\n)\nfrom sagemaker.sklearn.processing import SKLearnProcessor\nfrom sagemaker.network import NetworkConfig\nfrom tests.integ import DATA_DIR\nfrom tests.integ.kms_utils import get_or_create_kms_key\n\nROLE = ""SageMakerRole""\n\n\n@pytest.fixture(scope=""module"")\ndef sagemaker_session_with_custom_bucket(\n    boto_session, sagemaker_client_config, sagemaker_runtime_config, custom_bucket_name\n):\n    sagemaker_client_config.setdefault(""config"", Config(retries=dict(max_attempts=10)))\n    sagemaker_client = (\n        boto_session.client(""sagemaker"", **sagemaker_client_config)\n        if sagemaker_client_config\n        else None\n    )\n    runtime_client = (\n        boto_session.client(""sagemaker-runtime"", **sagemaker_runtime_config)\n        if sagemaker_runtime_config\n        else None\n    )\n\n    return Session(\n        boto_session=boto_session,\n        sagemaker_client=sagemaker_client,\n        sagemaker_runtime_client=runtime_client,\n        default_bucket=custom_bucket_name,\n    )\n\n\n@pytest.fixture(scope=""module"")\ndef image_uri(sagemaker_session):\n    image_tag = ""{}-{}-{}"".format(""0.20.0"", ""cpu"", ""py3"")\n    return default_framework_uri(\n        ""scikit-learn"", sagemaker_session.boto_session.region_name, image_tag\n    )\n\n\n@pytest.fixture(scope=""module"")\ndef volume_kms_key(sagemaker_session):\n    role_arn = sagemaker_session.expand_role(ROLE)\n    return get_or_create_kms_key(\n        sagemaker_session=sagemaker_session,\n        role_arn=role_arn,\n        alias=""integ-test-processing-volume-kms-key-{}"".format(\n            sagemaker_session.boto_session.region_name\n        ),\n    )\n\n\n@pytest.fixture(scope=""module"")\ndef output_kms_key(sagemaker_session):\n    role_arn = sagemaker_session.expand_role(ROLE)\n    return get_or_create_kms_key(\n        sagemaker_session=sagemaker_session,\n        role_arn=role_arn,\n        alias=""integ-test-processing-output-kms-key-{}"".format(\n            sagemaker_session.boto_session.region_name\n        ),\n    )\n\n\ndef test_sklearn(sagemaker_session, sklearn_full_version, cpu_instance_type):\n    script_path = os.path.join(DATA_DIR, ""dummy_script.py"")\n    input_file_path = os.path.join(DATA_DIR, ""dummy_input.txt"")\n\n    sklearn_processor = SKLearnProcessor(\n        framework_version=sklearn_full_version,\n        role=ROLE,\n        instance_type=cpu_instance_type,\n        instance_count=1,\n        command=[""python3""],\n        sagemaker_session=sagemaker_session,\n        base_job_name=""test-sklearn"",\n    )\n\n    sklearn_processor.run(\n        code=script_path,\n        inputs=[ProcessingInput(source=input_file_path, destination=""/opt/ml/processing/inputs/"")],\n        wait=False,\n        logs=False,\n    )\n\n    job_description = sklearn_processor.latest_job.describe()\n\n    assert len(job_description[""ProcessingInputs""]) == 2\n    assert job_description[""ProcessingResources""][""ClusterConfig""][""InstanceCount""] == 1\n    assert (\n        job_description[""ProcessingResources""][""ClusterConfig""][""InstanceType""] == cpu_instance_type\n    )\n    assert job_description[""ProcessingResources""][""ClusterConfig""][""VolumeSizeInGB""] == 30\n    assert job_description[""StoppingCondition""] == {""MaxRuntimeInSeconds"": 86400}\n    assert job_description[""AppSpecification""][""ContainerEntrypoint""] == [\n        ""python3"",\n        ""/opt/ml/processing/input/code/dummy_script.py"",\n    ]\n    assert ROLE in job_description[""RoleArn""]\n\n\n@pytest.mark.canary_quick\ndef test_sklearn_with_customizations(\n    sagemaker_session, image_uri, sklearn_full_version, cpu_instance_type, output_kms_key\n):\n    input_file_path = os.path.join(DATA_DIR, ""dummy_input.txt"")\n\n    sklearn_processor = SKLearnProcessor(\n        framework_version=sklearn_full_version,\n        role=ROLE,\n        command=[""python3""],\n        instance_type=cpu_instance_type,\n        instance_count=1,\n        volume_size_in_gb=100,\n        volume_kms_key=None,\n        output_kms_key=output_kms_key,\n        max_runtime_in_seconds=3600,\n        base_job_name=""test-sklearn-with-customizations"",\n        env={""DUMMY_ENVIRONMENT_VARIABLE"": ""dummy-value""},\n        tags=[{""Key"": ""dummy-tag"", ""Value"": ""dummy-tag-value""}],\n        sagemaker_session=sagemaker_session,\n    )\n\n    sklearn_processor.run(\n        code=os.path.join(DATA_DIR, ""dummy_script.py""),\n        inputs=[\n            ProcessingInput(\n                source=input_file_path,\n                destination=""/opt/ml/processing/input/container/path/"",\n                input_name=""dummy_input"",\n                s3_data_type=""S3Prefix"",\n                s3_input_mode=""File"",\n                s3_data_distribution_type=""FullyReplicated"",\n                s3_compression_type=""None"",\n            )\n        ],\n        outputs=[\n            ProcessingOutput(\n                source=""/opt/ml/processing/output/container/path/"",\n                output_name=""dummy_output"",\n                s3_upload_mode=""EndOfJob"",\n            )\n        ],\n        arguments=[""-v""],\n        wait=True,\n        logs=True,\n    )\n\n    job_description = sklearn_processor.latest_job.describe()\n\n    assert job_description[""ProcessingInputs""][0][""InputName""] == ""dummy_input""\n\n    assert job_description[""ProcessingInputs""][1][""InputName""] == ""code""\n\n    assert job_description[""ProcessingJobName""].startswith(""test-sklearn-with-customizations"")\n\n    assert job_description[""ProcessingJobStatus""] == ""Completed""\n\n    assert job_description[""ProcessingOutputConfig""][""KmsKeyId""] == output_kms_key\n    assert job_description[""ProcessingOutputConfig""][""Outputs""][0][""OutputName""] == ""dummy_output""\n\n    assert job_description[""ProcessingResources""][""ClusterConfig""][""InstanceCount""] == 1\n    assert (\n        job_description[""ProcessingResources""][""ClusterConfig""][""InstanceType""] == cpu_instance_type\n    )\n    assert job_description[""ProcessingResources""][""ClusterConfig""][""VolumeSizeInGB""] == 100\n\n    assert job_description[""AppSpecification""][""ContainerArguments""] == [""-v""]\n    assert job_description[""AppSpecification""][""ContainerEntrypoint""] == [\n        ""python3"",\n        ""/opt/ml/processing/input/code/dummy_script.py"",\n    ]\n    assert job_description[""AppSpecification""][""ImageUri""] == image_uri\n\n    assert job_description[""Environment""] == {""DUMMY_ENVIRONMENT_VARIABLE"": ""dummy-value""}\n\n    assert ROLE in job_description[""RoleArn""]\n\n    assert job_description[""StoppingCondition""] == {""MaxRuntimeInSeconds"": 3600}\n\n\ndef test_sklearn_with_custom_default_bucket(\n    sagemaker_session_with_custom_bucket,\n    custom_bucket_name,\n    image_uri,\n    sklearn_full_version,\n    cpu_instance_type,\n    output_kms_key,\n):\n    input_file_path = os.path.join(DATA_DIR, ""dummy_input.txt"")\n\n    sklearn_processor = SKLearnProcessor(\n        framework_version=sklearn_full_version,\n        role=ROLE,\n        command=[""python3""],\n        instance_type=cpu_instance_type,\n        instance_count=1,\n        volume_size_in_gb=100,\n        volume_kms_key=None,\n        output_kms_key=output_kms_key,\n        max_runtime_in_seconds=3600,\n        base_job_name=""test-sklearn-with-customizations"",\n        env={""DUMMY_ENVIRONMENT_VARIABLE"": ""dummy-value""},\n        tags=[{""Key"": ""dummy-tag"", ""Value"": ""dummy-tag-value""}],\n        sagemaker_session=sagemaker_session_with_custom_bucket,\n    )\n\n    sklearn_processor.run(\n        code=os.path.join(DATA_DIR, ""dummy_script.py""),\n        inputs=[\n            ProcessingInput(\n                source=input_file_path,\n                destination=""/opt/ml/processing/input/container/path/"",\n                input_name=""dummy_input"",\n                s3_data_type=""S3Prefix"",\n                s3_input_mode=""File"",\n                s3_data_distribution_type=""FullyReplicated"",\n                s3_compression_type=""None"",\n            )\n        ],\n        outputs=[\n            ProcessingOutput(\n                source=""/opt/ml/processing/output/container/path/"",\n                output_name=""dummy_output"",\n                s3_upload_mode=""EndOfJob"",\n            )\n        ],\n        arguments=[""-v""],\n        wait=True,\n        logs=True,\n    )\n\n    job_description = sklearn_processor.latest_job.describe()\n\n    assert job_description[""ProcessingInputs""][0][""InputName""] == ""dummy_input""\n    assert custom_bucket_name in job_description[""ProcessingInputs""][0][""S3Input""][""S3Uri""]\n\n    assert job_description[""ProcessingInputs""][1][""InputName""] == ""code""\n    assert custom_bucket_name in job_description[""ProcessingInputs""][1][""S3Input""][""S3Uri""]\n\n    assert job_description[""ProcessingJobName""].startswith(""test-sklearn-with-customizations"")\n\n    assert job_description[""ProcessingJobStatus""] == ""Completed""\n\n    assert job_description[""ProcessingOutputConfig""][""KmsKeyId""] == output_kms_key\n    assert job_description[""ProcessingOutputConfig""][""Outputs""][0][""OutputName""] == ""dummy_output""\n\n    assert job_description[""ProcessingResources""][""ClusterConfig""][""InstanceCount""] == 1\n    assert (\n        job_description[""ProcessingResources""][""ClusterConfig""][""InstanceType""] == cpu_instance_type\n    )\n    assert job_description[""ProcessingResources""][""ClusterConfig""][""VolumeSizeInGB""] == 100\n\n    assert job_description[""AppSpecification""][""ContainerArguments""] == [""-v""]\n    assert job_description[""AppSpecification""][""ContainerEntrypoint""] == [\n        ""python3"",\n        ""/opt/ml/processing/input/code/dummy_script.py"",\n    ]\n    assert job_description[""AppSpecification""][""ImageUri""] == image_uri\n\n    assert job_description[""Environment""] == {""DUMMY_ENVIRONMENT_VARIABLE"": ""dummy-value""}\n\n    assert ROLE in job_description[""RoleArn""]\n\n    assert job_description[""StoppingCondition""] == {""MaxRuntimeInSeconds"": 3600}\n\n\ndef test_sklearn_with_no_inputs_or_outputs(\n    sagemaker_session, image_uri, sklearn_full_version, cpu_instance_type\n):\n    sklearn_processor = SKLearnProcessor(\n        framework_version=sklearn_full_version,\n        role=ROLE,\n        command=[""python3""],\n        instance_type=cpu_instance_type,\n        instance_count=1,\n        volume_size_in_gb=100,\n        volume_kms_key=None,\n        max_runtime_in_seconds=3600,\n        base_job_name=""test-sklearn-with-no-inputs-or-outputs"",\n        env={""DUMMY_ENVIRONMENT_VARIABLE"": ""dummy-value""},\n        tags=[{""Key"": ""dummy-tag"", ""Value"": ""dummy-tag-value""}],\n        sagemaker_session=sagemaker_session,\n    )\n\n    sklearn_processor.run(\n        code=os.path.join(DATA_DIR, ""dummy_script.py""), arguments=[""-v""], wait=True, logs=True\n    )\n\n    job_description = sklearn_processor.latest_job.describe()\n\n    assert job_description[""ProcessingInputs""][0][""InputName""] == ""code""\n\n    assert job_description[""ProcessingJobName""].startswith(""test-sklearn-with-no-inputs"")\n\n    assert job_description[""ProcessingJobStatus""] == ""Completed""\n\n    assert job_description[""ProcessingResources""][""ClusterConfig""][""InstanceCount""] == 1\n    assert (\n        job_description[""ProcessingResources""][""ClusterConfig""][""InstanceType""] == cpu_instance_type\n    )\n    assert job_description[""ProcessingResources""][""ClusterConfig""][""VolumeSizeInGB""] == 100\n\n    assert job_description[""AppSpecification""][""ContainerArguments""] == [""-v""]\n    assert job_description[""AppSpecification""][""ContainerEntrypoint""] == [\n        ""python3"",\n        ""/opt/ml/processing/input/code/dummy_script.py"",\n    ]\n    assert job_description[""AppSpecification""][""ImageUri""] == image_uri\n\n    assert job_description[""Environment""] == {""DUMMY_ENVIRONMENT_VARIABLE"": ""dummy-value""}\n\n    assert ROLE in job_description[""RoleArn""]\n\n    assert job_description[""StoppingCondition""] == {""MaxRuntimeInSeconds"": 3600}\n\n\n@pytest.mark.canary_quick\ndef test_script_processor(sagemaker_session, image_uri, cpu_instance_type, output_kms_key):\n    input_file_path = os.path.join(DATA_DIR, ""dummy_input.txt"")\n\n    script_processor = ScriptProcessor(\n        role=ROLE,\n        image_uri=image_uri,\n        command=[""python3""],\n        instance_count=1,\n        instance_type=cpu_instance_type,\n        volume_size_in_gb=100,\n        volume_kms_key=None,\n        output_kms_key=output_kms_key,\n        max_runtime_in_seconds=3600,\n        base_job_name=""test-script-processor"",\n        env={""DUMMY_ENVIRONMENT_VARIABLE"": ""dummy-value""},\n        tags=[{""Key"": ""dummy-tag"", ""Value"": ""dummy-tag-value""}],\n        sagemaker_session=sagemaker_session,\n    )\n\n    script_processor.run(\n        code=os.path.join(DATA_DIR, ""dummy_script.py""),\n        inputs=[\n            ProcessingInput(\n                source=input_file_path,\n                destination=""/opt/ml/processing/input/container/path/"",\n                input_name=""dummy_input"",\n                s3_data_type=""S3Prefix"",\n                s3_input_mode=""File"",\n                s3_data_distribution_type=""FullyReplicated"",\n                s3_compression_type=""None"",\n            )\n        ],\n        outputs=[\n            ProcessingOutput(\n                source=""/opt/ml/processing/output/container/path/"",\n                output_name=""dummy_output"",\n                s3_upload_mode=""EndOfJob"",\n            )\n        ],\n        arguments=[""-v""],\n        wait=True,\n        logs=True,\n    )\n\n    job_description = script_processor.latest_job.describe()\n\n    assert job_description[""ProcessingInputs""][0][""InputName""] == ""dummy_input""\n\n    assert job_description[""ProcessingInputs""][1][""InputName""] == ""code""\n\n    assert job_description[""ProcessingJobName""].startswith(""test-script-processor"")\n\n    assert job_description[""ProcessingJobStatus""] == ""Completed""\n\n    assert job_description[""ProcessingOutputConfig""][""KmsKeyId""] == output_kms_key\n    assert job_description[""ProcessingOutputConfig""][""Outputs""][0][""OutputName""] == ""dummy_output""\n\n    assert job_description[""ProcessingResources""][""ClusterConfig""][""InstanceCount""] == 1\n    assert (\n        job_description[""ProcessingResources""][""ClusterConfig""][""InstanceType""] == cpu_instance_type\n    )\n    assert job_description[""ProcessingResources""][""ClusterConfig""][""VolumeSizeInGB""] == 100\n\n    assert job_description[""AppSpecification""][""ContainerArguments""] == [""-v""]\n    assert job_description[""AppSpecification""][""ContainerEntrypoint""] == [\n        ""python3"",\n        ""/opt/ml/processing/input/code/dummy_script.py"",\n    ]\n    assert job_description[""AppSpecification""][""ImageUri""] == image_uri\n\n    assert job_description[""Environment""] == {""DUMMY_ENVIRONMENT_VARIABLE"": ""dummy-value""}\n\n    assert ROLE in job_description[""RoleArn""]\n\n    assert job_description[""StoppingCondition""] == {""MaxRuntimeInSeconds"": 3600}\n\n\ndef test_script_processor_with_no_inputs_or_outputs(\n    sagemaker_session, image_uri, cpu_instance_type\n):\n    script_processor = ScriptProcessor(\n        role=ROLE,\n        image_uri=image_uri,\n        command=[""python3""],\n        instance_count=1,\n        instance_type=cpu_instance_type,\n        volume_size_in_gb=100,\n        volume_kms_key=None,\n        max_runtime_in_seconds=3600,\n        base_job_name=""test-script-processor-with-no-inputs-or-outputs"",\n        env={""DUMMY_ENVIRONMENT_VARIABLE"": ""dummy-value""},\n        tags=[{""Key"": ""dummy-tag"", ""Value"": ""dummy-tag-value""}],\n        sagemaker_session=sagemaker_session,\n    )\n\n    script_processor.run(\n        code=os.path.join(DATA_DIR, ""dummy_script.py""), arguments=[""-v""], wait=True, logs=True\n    )\n\n    job_description = script_processor.latest_job.describe()\n\n    assert job_description[""ProcessingInputs""][0][""InputName""] == ""code""\n\n    assert job_description[""ProcessingJobName""].startswith(""test-script-processor-with-no-inputs"")\n\n    assert job_description[""ProcessingJobStatus""] == ""Completed""\n\n    assert job_description[""ProcessingResources""][""ClusterConfig""][""InstanceCount""] == 1\n    assert (\n        job_description[""ProcessingResources""][""ClusterConfig""][""InstanceType""] == cpu_instance_type\n    )\n    assert job_description[""ProcessingResources""][""ClusterConfig""][""VolumeSizeInGB""] == 100\n\n    assert job_description[""AppSpecification""][""ContainerArguments""] == [""-v""]\n    assert job_description[""AppSpecification""][""ContainerEntrypoint""] == [\n        ""python3"",\n        ""/opt/ml/processing/input/code/dummy_script.py"",\n    ]\n    assert job_description[""AppSpecification""][""ImageUri""] == image_uri\n\n    assert job_description[""Environment""] == {""DUMMY_ENVIRONMENT_VARIABLE"": ""dummy-value""}\n\n    assert ROLE in job_description[""RoleArn""]\n\n    assert job_description[""StoppingCondition""] == {""MaxRuntimeInSeconds"": 3600}\n\n    job_from_name = ProcessingJob.from_processing_name(\n        sagemaker_session=sagemaker_session,\n        processing_job_name=job_description[""ProcessingJobName""],\n    )\n    job_description = job_from_name.describe()\n\n    assert job_description[""ProcessingInputs""][0][""InputName""] == ""code""\n\n    assert job_description[""ProcessingJobName""].startswith(""test-script-processor-with-no-inputs"")\n\n    assert job_description[""ProcessingJobStatus""] == ""Completed""\n\n    assert job_description[""ProcessingResources""][""ClusterConfig""][""InstanceCount""] == 1\n    assert (\n        job_description[""ProcessingResources""][""ClusterConfig""][""InstanceType""] == cpu_instance_type\n    )\n    assert job_description[""ProcessingResources""][""ClusterConfig""][""VolumeSizeInGB""] == 100\n\n    assert job_description[""AppSpecification""][""ContainerArguments""] == [""-v""]\n    assert job_description[""AppSpecification""][""ContainerEntrypoint""] == [\n        ""python3"",\n        ""/opt/ml/processing/input/code/dummy_script.py"",\n    ]\n    assert job_description[""AppSpecification""][""ImageUri""] == image_uri\n\n    assert job_description[""Environment""] == {""DUMMY_ENVIRONMENT_VARIABLE"": ""dummy-value""}\n\n    assert ROLE in job_description[""RoleArn""]\n\n    assert job_description[""StoppingCondition""] == {""MaxRuntimeInSeconds"": 3600}\n\n\n@pytest.mark.canary_quick\ndef test_processor(sagemaker_session, image_uri, cpu_instance_type, output_kms_key):\n    script_path = os.path.join(DATA_DIR, ""dummy_script.py"")\n\n    processor = Processor(\n        role=ROLE,\n        image_uri=image_uri,\n        instance_count=1,\n        instance_type=cpu_instance_type,\n        entrypoint=[""python3"", ""/opt/ml/processing/input/code/dummy_script.py""],\n        volume_size_in_gb=100,\n        volume_kms_key=None,\n        output_kms_key=output_kms_key,\n        max_runtime_in_seconds=3600,\n        base_job_name=""test-processor"",\n        env={""DUMMY_ENVIRONMENT_VARIABLE"": ""dummy-value""},\n        tags=[{""Key"": ""dummy-tag"", ""Value"": ""dummy-tag-value""}],\n        sagemaker_session=sagemaker_session,\n    )\n\n    processor.run(\n        inputs=[\n            ProcessingInput(\n                source=script_path, destination=""/opt/ml/processing/input/code/"", input_name=""code""\n            )\n        ],\n        outputs=[\n            ProcessingOutput(\n                source=""/opt/ml/processing/output/container/path/"",\n                output_name=""dummy_output"",\n                s3_upload_mode=""EndOfJob"",\n            )\n        ],\n        arguments=[""-v""],\n        wait=True,\n        logs=True,\n    )\n\n    job_description = processor.latest_job.describe()\n\n    assert job_description[""ProcessingInputs""][0][""InputName""] == ""code""\n\n    assert job_description[""ProcessingJobName""].startswith(""test-processor"")\n\n    assert job_description[""ProcessingJobStatus""] == ""Completed""\n\n    assert job_description[""ProcessingOutputConfig""][""KmsKeyId""] == output_kms_key\n    assert job_description[""ProcessingOutputConfig""][""Outputs""][0][""OutputName""] == ""dummy_output""\n\n    assert job_description[""ProcessingResources""][""ClusterConfig""][""InstanceCount""] == 1\n    assert (\n        job_description[""ProcessingResources""][""ClusterConfig""][""InstanceType""] == cpu_instance_type\n    )\n    assert job_description[""ProcessingResources""][""ClusterConfig""][""VolumeSizeInGB""] == 100\n\n    assert job_description[""AppSpecification""][""ContainerArguments""] == [""-v""]\n    assert job_description[""AppSpecification""][""ContainerEntrypoint""] == [\n        ""python3"",\n        ""/opt/ml/processing/input/code/dummy_script.py"",\n    ]\n    assert job_description[""AppSpecification""][""ImageUri""] == image_uri\n\n    assert job_description[""Environment""] == {""DUMMY_ENVIRONMENT_VARIABLE"": ""dummy-value""}\n\n    assert ROLE in job_description[""RoleArn""]\n\n    assert job_description[""StoppingCondition""] == {""MaxRuntimeInSeconds"": 3600}\n\n\ndef test_processor_with_custom_bucket(\n    sagemaker_session_with_custom_bucket,\n    custom_bucket_name,\n    image_uri,\n    cpu_instance_type,\n    output_kms_key,\n):\n    script_path = os.path.join(DATA_DIR, ""dummy_script.py"")\n\n    processor = Processor(\n        role=ROLE,\n        image_uri=image_uri,\n        instance_count=1,\n        instance_type=cpu_instance_type,\n        entrypoint=[""python3"", ""/opt/ml/processing/input/code/dummy_script.py""],\n        volume_size_in_gb=100,\n        volume_kms_key=None,\n        output_kms_key=output_kms_key,\n        max_runtime_in_seconds=3600,\n        base_job_name=""test-processor"",\n        env={""DUMMY_ENVIRONMENT_VARIABLE"": ""dummy-value""},\n        tags=[{""Key"": ""dummy-tag"", ""Value"": ""dummy-tag-value""}],\n        sagemaker_session=sagemaker_session_with_custom_bucket,\n    )\n\n    processor.run(\n        inputs=[\n            ProcessingInput(\n                source=script_path, destination=""/opt/ml/processing/input/code/"", input_name=""code""\n            )\n        ],\n        outputs=[\n            ProcessingOutput(\n                source=""/opt/ml/processing/output/container/path/"",\n                output_name=""dummy_output"",\n                s3_upload_mode=""EndOfJob"",\n            )\n        ],\n        arguments=[""-v""],\n        wait=True,\n        logs=True,\n    )\n\n    job_description = processor.latest_job.describe()\n\n    assert job_description[""ProcessingInputs""][0][""InputName""] == ""code""\n    assert custom_bucket_name in job_description[""ProcessingInputs""][0][""S3Input""][""S3Uri""]\n\n    assert job_description[""ProcessingJobName""].startswith(""test-processor"")\n\n    assert job_description[""ProcessingJobStatus""] == ""Completed""\n\n    assert job_description[""ProcessingOutputConfig""][""KmsKeyId""] == output_kms_key\n    assert job_description[""ProcessingOutputConfig""][""Outputs""][0][""OutputName""] == ""dummy_output""\n\n    assert job_description[""ProcessingResources""][""ClusterConfig""][""InstanceCount""] == 1\n    assert (\n        job_description[""ProcessingResources""][""ClusterConfig""][""InstanceType""] == cpu_instance_type\n    )\n    assert job_description[""ProcessingResources""][""ClusterConfig""][""VolumeSizeInGB""] == 100\n\n    assert job_description[""AppSpecification""][""ContainerArguments""] == [""-v""]\n    assert job_description[""AppSpecification""][""ContainerEntrypoint""] == [\n        ""python3"",\n        ""/opt/ml/processing/input/code/dummy_script.py"",\n    ]\n    assert job_description[""AppSpecification""][""ImageUri""] == image_uri\n\n    assert job_description[""Environment""] == {""DUMMY_ENVIRONMENT_VARIABLE"": ""dummy-value""}\n\n    assert ROLE in job_description[""RoleArn""]\n\n    assert job_description[""StoppingCondition""] == {""MaxRuntimeInSeconds"": 3600}\n\n\ndef test_sklearn_with_network_config(sagemaker_session, sklearn_full_version, cpu_instance_type):\n    script_path = os.path.join(DATA_DIR, ""dummy_script.py"")\n    input_file_path = os.path.join(DATA_DIR, ""dummy_input.txt"")\n\n    sklearn_processor = SKLearnProcessor(\n        framework_version=sklearn_full_version,\n        role=ROLE,\n        instance_type=cpu_instance_type,\n        instance_count=1,\n        command=[""python3""],\n        sagemaker_session=sagemaker_session,\n        base_job_name=""test-sklearn-with-network-config"",\n        network_config=NetworkConfig(\n            enable_network_isolation=True, encrypt_inter_container_traffic=True\n        ),\n    )\n\n    sklearn_processor.run(\n        code=script_path,\n        inputs=[ProcessingInput(source=input_file_path, destination=""/opt/ml/processing/inputs/"")],\n        wait=False,\n        logs=False,\n    )\n\n    job_description = sklearn_processor.latest_job.describe()\n    network_config = job_description[""NetworkConfig""]\n    assert network_config[""EnableInterContainerTrafficEncryption""]\n    assert network_config[""EnableNetworkIsolation""]\n'"
tests/integ/test_pytorch_train.py,0,"b'# Copyright 2018-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport numpy\nimport os\nimport pytest\nfrom sagemaker.pytorch.defaults import LATEST_PY2_VERSION\nfrom sagemaker.pytorch.estimator import PyTorch\nfrom sagemaker.pytorch.model import PyTorchModel\nfrom sagemaker.utils import sagemaker_timestamp\n\nfrom tests.integ import (\n    test_region,\n    DATA_DIR,\n    PYTHON_VERSION,\n    TRAINING_DEFAULT_TIMEOUT_MINUTES,\n    EI_SUPPORTED_REGIONS,\n)\nfrom tests.integ.timeout import timeout, timeout_and_delete_endpoint_by_name\n\nMNIST_DIR = os.path.join(DATA_DIR, ""pytorch_mnist"")\nMNIST_SCRIPT = os.path.join(MNIST_DIR, ""mnist.py"")\nPACKED_MODEL = os.path.join(MNIST_DIR, ""packed_model.tar.gz"")\n\nEIA_DIR = os.path.join(DATA_DIR, ""pytorch_eia"")\nEIA_MODEL = os.path.join(EIA_DIR, ""model_mnist.tar.gz"")\nEIA_SCRIPT = os.path.join(EIA_DIR, ""empty_inference_script.py"")\n\n\n@pytest.fixture(scope=""module"", name=""pytorch_training_job"")\ndef fixture_training_job(sagemaker_session, pytorch_full_version, cpu_instance_type):\n    with timeout(minutes=TRAINING_DEFAULT_TIMEOUT_MINUTES):\n        pytorch = _get_pytorch_estimator(sagemaker_session, pytorch_full_version, cpu_instance_type)\n\n        pytorch.fit({""training"": _upload_training_data(pytorch)})\n        return pytorch.latest_training_job.name\n\n\n@pytest.mark.canary_quick\n@pytest.mark.regional_testing\n@pytest.mark.skipif(\n    PYTHON_VERSION == ""py2"",\n    reason=""Python 2 is supported by PyTorch {} and lower versions."".format(LATEST_PY2_VERSION),\n)\ndef test_sync_fit_deploy(pytorch_training_job, sagemaker_session, cpu_instance_type):\n    # TODO: add tests against local mode when it\'s ready to be used\n    endpoint_name = ""test-pytorch-sync-fit-attach-deploy{}"".format(sagemaker_timestamp())\n    with timeout_and_delete_endpoint_by_name(endpoint_name, sagemaker_session):\n        estimator = PyTorch.attach(pytorch_training_job, sagemaker_session=sagemaker_session)\n        predictor = estimator.deploy(1, cpu_instance_type, endpoint_name=endpoint_name)\n        data = numpy.zeros(shape=(1, 1, 28, 28), dtype=numpy.float32)\n        predictor.predict(data)\n\n        batch_size = 100\n        data = numpy.random.rand(batch_size, 1, 28, 28).astype(numpy.float32)\n        output = predictor.predict(data)\n\n        assert output.shape == (batch_size, 10)\n\n\n@pytest.mark.local_mode\n@pytest.mark.skipif(\n    PYTHON_VERSION == ""py2"",\n    reason=""Python 2 is supported by PyTorch {} and lower versions."".format(LATEST_PY2_VERSION),\n)\ndef test_fit_deploy(sagemaker_local_session, pytorch_full_version):\n    pytorch = PyTorch(\n        entry_point=MNIST_SCRIPT,\n        role=""SageMakerRole"",\n        framework_version=pytorch_full_version,\n        py_version=""py3"",\n        train_instance_count=1,\n        train_instance_type=""local"",\n        sagemaker_session=sagemaker_local_session,\n    )\n\n    pytorch.fit({""training"": ""file://"" + os.path.join(MNIST_DIR, ""training"")})\n\n    predictor = pytorch.deploy(1, ""local"")\n    try:\n        batch_size = 100\n        data = numpy.random.rand(batch_size, 1, 28, 28).astype(numpy.float32)\n        output = predictor.predict(data)\n\n        assert output.shape == (batch_size, 10)\n    finally:\n        predictor.delete_endpoint()\n\n\n@pytest.mark.skipif(\n    PYTHON_VERSION == ""py2"",\n    reason=""Python 2 is supported by PyTorch {} and lower versions."".format(LATEST_PY2_VERSION),\n)\ndef test_deploy_model(pytorch_training_job, sagemaker_session, cpu_instance_type):\n    endpoint_name = ""test-pytorch-deploy-model-{}"".format(sagemaker_timestamp())\n\n    with timeout_and_delete_endpoint_by_name(endpoint_name, sagemaker_session):\n        desc = sagemaker_session.sagemaker_client.describe_training_job(\n            TrainingJobName=pytorch_training_job\n        )\n        model_data = desc[""ModelArtifacts""][""S3ModelArtifacts""]\n        model = PyTorchModel(\n            model_data,\n            ""SageMakerRole"",\n            entry_point=MNIST_SCRIPT,\n            sagemaker_session=sagemaker_session,\n        )\n        predictor = model.deploy(1, cpu_instance_type, endpoint_name=endpoint_name)\n\n        batch_size = 100\n        data = numpy.random.rand(batch_size, 1, 28, 28).astype(numpy.float32)\n        output = predictor.predict(data)\n\n        assert output.shape == (batch_size, 10)\n\n\n@pytest.mark.skipif(\n    PYTHON_VERSION == ""py2"",\n    reason=""Python 2 is supported by PyTorch {} and lower versions."".format(LATEST_PY2_VERSION),\n)\ndef test_deploy_packed_model_with_entry_point_name(sagemaker_session, cpu_instance_type):\n    endpoint_name = ""test-pytorch-deploy-model-{}"".format(sagemaker_timestamp())\n\n    with timeout_and_delete_endpoint_by_name(endpoint_name, sagemaker_session):\n        model_data = sagemaker_session.upload_data(path=PACKED_MODEL)\n        model = PyTorchModel(\n            model_data,\n            ""SageMakerRole"",\n            entry_point=""mnist.py"",\n            framework_version=""1.4.0"",\n            sagemaker_session=sagemaker_session,\n        )\n        predictor = model.deploy(1, cpu_instance_type, endpoint_name=endpoint_name)\n\n        batch_size = 100\n        data = numpy.random.rand(batch_size, 1, 28, 28).astype(numpy.float32)\n        output = predictor.predict(data)\n\n        assert output.shape == (batch_size, 10)\n\n\n@pytest.mark.skipif(PYTHON_VERSION == ""py2"", reason=""PyTorch EIA does not support Python 2."")\n@pytest.mark.skipif(\n    test_region() not in EI_SUPPORTED_REGIONS, reason=""EI isn\'t supported in that specific region.""\n)\ndef test_deploy_model_with_accelerator(sagemaker_session, cpu_instance_type):\n    endpoint_name = ""test-pytorch-deploy-eia-{}"".format(sagemaker_timestamp())\n    model_data = sagemaker_session.upload_data(path=EIA_MODEL)\n    pytorch = PyTorchModel(\n        model_data,\n        ""SageMakerRole"",\n        framework_version=""1.3.1"",\n        entry_point=EIA_SCRIPT,\n        sagemaker_session=sagemaker_session,\n    )\n    with timeout_and_delete_endpoint_by_name(endpoint_name, sagemaker_session):\n        predictor = pytorch.deploy(\n            initial_instance_count=1,\n            instance_type=cpu_instance_type,\n            accelerator_type=""ml.eia1.medium"",\n            endpoint_name=endpoint_name,\n        )\n\n        batch_size = 100\n        data = numpy.random.rand(batch_size, 1, 28, 28).astype(numpy.float32)\n        output = predictor.predict(data)\n\n        assert output.shape == (batch_size, 10)\n\n\ndef _upload_training_data(pytorch):\n    return pytorch.sagemaker_session.upload_data(\n        path=os.path.join(MNIST_DIR, ""training""),\n        key_prefix=""integ-test-data/pytorch_mnist/training"",\n    )\n\n\ndef _get_pytorch_estimator(\n    sagemaker_session, pytorch_full_version, instance_type, entry_point=MNIST_SCRIPT\n):\n    return PyTorch(\n        entry_point=entry_point,\n        role=""SageMakerRole"",\n        framework_version=pytorch_full_version,\n        py_version=PYTHON_VERSION,\n        train_instance_count=1,\n        train_instance_type=instance_type,\n        sagemaker_session=sagemaker_session,\n    )\n\n\ndef _is_local_mode(instance_type):\n    return instance_type == ""local""\n'"
tests/integ/test_randomcutforest.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport numpy as np\n\nfrom sagemaker import RandomCutForest, RandomCutForestModel\nfrom sagemaker.utils import unique_name_from_base\nfrom tests.integ import TRAINING_DEFAULT_TIMEOUT_MINUTES\nfrom tests.integ.timeout import timeout, timeout_and_delete_endpoint_by_name\n\n\ndef test_randomcutforest(sagemaker_session, cpu_instance_type):\n    job_name = unique_name_from_base(""randomcutforest"")\n\n    with timeout(minutes=TRAINING_DEFAULT_TIMEOUT_MINUTES):\n        # Generate a thousand 14-dimensional datapoints.\n        feature_num = 14\n        train_input = np.random.rand(1000, feature_num)\n\n        rcf = RandomCutForest(\n            role=""SageMakerRole"",\n            train_instance_count=1,\n            train_instance_type=cpu_instance_type,\n            num_trees=50,\n            num_samples_per_tree=20,\n            eval_metrics=[""accuracy"", ""precision_recall_fscore""],\n            sagemaker_session=sagemaker_session,\n        )\n\n        rcf.fit(records=rcf.record_set(train_input), job_name=job_name)\n\n    with timeout_and_delete_endpoint_by_name(job_name, sagemaker_session):\n        model = RandomCutForestModel(\n            rcf.model_data, role=""SageMakerRole"", sagemaker_session=sagemaker_session\n        )\n        predictor = model.deploy(1, cpu_instance_type, endpoint_name=job_name)\n\n        predict_input = np.random.rand(1, feature_num)\n        result = predictor.predict(predict_input)\n\n        assert len(result) == 1\n        for record in result:\n            assert record.label[""score""] is not None\n            assert len(record.label[""score""].float32_tensor.values) == 1\n'"
tests/integ/test_record_set.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport gzip\nimport os\nimport pickle\nimport sys\n\nfrom six.moves.urllib.parse import urlparse\n\nfrom sagemaker import KMeans\nfrom tests.integ import DATA_DIR\n\n\ndef test_record_set(sagemaker_session, cpu_instance_type):\n    """"""Test the method ``AmazonAlgorithmEstimatorBase.record_set``.\n\n    In particular, test that the objects uploaded to the S3 bucket are encrypted.\n    """"""\n    data_path = os.path.join(DATA_DIR, ""one_p_mnist"", ""mnist.pkl.gz"")\n    pickle_args = {} if sys.version_info.major == 2 else {""encoding"": ""latin1""}\n    with gzip.open(data_path, ""rb"") as file_object:\n        train_set, _, _ = pickle.load(file_object, **pickle_args)\n    kmeans = KMeans(\n        role=""SageMakerRole"",\n        train_instance_count=1,\n        train_instance_type=cpu_instance_type,\n        k=10,\n        sagemaker_session=sagemaker_session,\n    )\n    record_set = kmeans.record_set(train_set[0][:100], encrypt=True)\n    parsed_url = urlparse(record_set.s3_data)\n    s3_client = sagemaker_session.boto_session.client(""s3"")\n    head = s3_client.head_object(Bucket=parsed_url.netloc, Key=parsed_url.path.lstrip(""/""))\n    assert head[""ServerSideEncryption""] == ""AES256""\n'"
tests/integ/test_rl.py,0,"b'# Copyright 2018-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport os\n\nimport numpy\nimport pytest\n\nfrom sagemaker.rl import RLEstimator, RLFramework, RLToolkit\nfrom sagemaker.utils import sagemaker_timestamp, unique_name_from_base\nfrom tests.integ import DATA_DIR, PYTHON_VERSION\nfrom tests.integ.timeout import timeout, timeout_and_delete_endpoint_by_name\n\n\n@pytest.mark.canary_quick\n@pytest.mark.skipif(PYTHON_VERSION != ""py3"", reason=""RL images supports only Python 3."")\ndef test_coach_mxnet(sagemaker_session, rl_coach_mxnet_full_version, cpu_instance_type):\n    estimator = _test_coach(\n        sagemaker_session, RLFramework.MXNET, rl_coach_mxnet_full_version, cpu_instance_type\n    )\n    job_name = unique_name_from_base(""test-coach-mxnet"")\n\n    with timeout(minutes=15):\n        estimator.fit(wait=""False"", job_name=job_name)\n\n        estimator = RLEstimator.attach(\n            estimator.latest_training_job.name, sagemaker_session=sagemaker_session\n        )\n\n    endpoint_name = ""test-mxnet-coach-deploy-{}"".format(sagemaker_timestamp())\n\n    with timeout_and_delete_endpoint_by_name(endpoint_name, sagemaker_session):\n        predictor = estimator.deploy(\n            1, cpu_instance_type, entry_point=""mxnet_deploy.py"", endpoint_name=endpoint_name\n        )\n\n        observation = numpy.asarray([0, 0, 0, 0])\n        action = predictor.predict(observation)\n\n    assert 0 < action[0][0] < 1\n    assert 0 < action[0][1] < 1\n\n\n@pytest.mark.skipif(PYTHON_VERSION != ""py3"", reason=""RL images supports only Python 3."")\ndef test_coach_tf(sagemaker_session, rl_coach_tf_full_version, cpu_instance_type):\n    estimator = _test_coach(\n        sagemaker_session, RLFramework.TENSORFLOW, rl_coach_tf_full_version, cpu_instance_type\n    )\n    job_name = unique_name_from_base(""test-coach-tf"")\n\n    with timeout(minutes=15):\n        estimator.fit(job_name=job_name)\n\n    endpoint_name = ""test-tf-coach-deploy-{}"".format(sagemaker_timestamp())\n\n    with timeout_and_delete_endpoint_by_name(endpoint_name, sagemaker_session):\n        predictor = estimator.deploy(1, cpu_instance_type)\n        observation = numpy.asarray([0, 0, 0, 0])\n        action = predictor.predict(observation)\n\n    assert action == {""predictions"": [[0.5, 0.5]]}\n\n\ndef _test_coach(sagemaker_session, rl_framework, rl_coach_version, cpu_instance_type):\n    source_dir = os.path.join(DATA_DIR, ""coach_cartpole"")\n    dependencies = [os.path.join(DATA_DIR, ""sagemaker_rl"")]\n    cartpole = ""train_coach.py""\n\n    return RLEstimator(\n        toolkit=RLToolkit.COACH,\n        toolkit_version=rl_coach_version,\n        framework=rl_framework,\n        entry_point=cartpole,\n        source_dir=source_dir,\n        role=""SageMakerRole"",\n        train_instance_count=1,\n        train_instance_type=cpu_instance_type,\n        sagemaker_session=sagemaker_session,\n        dependencies=dependencies,\n        hyperparameters={\n            ""save_model"": 1,\n            ""RLCOACH_PRESET"": ""preset_cartpole_clippedppo"",\n            ""rl.agent_params.algorithm.discount"": 0.9,\n            ""rl.evaluation_steps:EnvironmentEpisodes"": 1,\n        },\n    )\n\n\n@pytest.mark.canary_quick\n@pytest.mark.skipif(PYTHON_VERSION != ""py3"", reason=""RL images supports only Python 3."")\ndef test_ray_tf(sagemaker_session, rl_ray_full_version, cpu_instance_type):\n    source_dir = os.path.join(DATA_DIR, ""ray_cartpole"")\n    cartpole = ""train_ray.py""\n\n    estimator = RLEstimator(\n        entry_point=cartpole,\n        source_dir=source_dir,\n        toolkit=RLToolkit.RAY,\n        framework=RLFramework.TENSORFLOW,\n        toolkit_version=rl_ray_full_version,\n        sagemaker_session=sagemaker_session,\n        role=""SageMakerRole"",\n        train_instance_type=cpu_instance_type,\n        train_instance_count=1,\n    )\n    job_name = unique_name_from_base(""test-ray-tf"")\n\n    with timeout(minutes=15):\n        estimator.fit(job_name=job_name)\n\n    with pytest.raises(NotImplementedError) as e:\n        estimator.deploy(1, cpu_instance_type)\n    assert ""Automatic deployment of Ray models is not currently available"" in str(e.value)\n'"
tests/integ/test_s3.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport os\nimport uuid\n\nimport pytest\n\nfrom sagemaker.s3 import S3Uploader\nfrom sagemaker.s3 import S3Downloader\n\nfrom tests.integ.kms_utils import get_or_create_kms_key\n\n\nTMP_BASE_PATH = ""/tmp""\n\n\n@pytest.fixture(scope=""module"")\ndef s3_files_kms_key(sagemaker_session):\n    return get_or_create_kms_key(sagemaker_session=sagemaker_session)\n\n\ndef test_s3_uploader_and_downloader_reads_files_when_given_file_name_uris(\n    sagemaker_session, s3_files_kms_key\n):\n    my_uuid = str(uuid.uuid4())\n\n    file_1_body = ""First File Body {}."".format(my_uuid)\n    file_1_name = ""first_file_{}.txt"".format(my_uuid)\n    file_2_body = ""Second File Body {}."".format(my_uuid)\n    file_2_name = ""second_file_{}.txt"".format(my_uuid)\n\n    base_s3_uri = os.path.join(\n        ""s3://"", sagemaker_session.default_bucket(), ""integ-test-test-s3-list"", my_uuid\n    )\n    file_1_s3_uri = os.path.join(base_s3_uri, file_1_name)\n    file_2_s3_uri = os.path.join(base_s3_uri, file_2_name)\n\n    S3Uploader.upload_string_as_file_body(\n        body=file_1_body,\n        desired_s3_uri=file_1_s3_uri,\n        kms_key=s3_files_kms_key,\n        session=sagemaker_session,\n    )\n\n    S3Uploader.upload_string_as_file_body(\n        body=file_2_body,\n        desired_s3_uri=file_2_s3_uri,\n        kms_key=s3_files_kms_key,\n        session=sagemaker_session,\n    )\n\n    s3_uris = S3Downloader.list(s3_uri=base_s3_uri, session=sagemaker_session)\n\n    assert file_1_name in s3_uris[0]\n    assert file_2_name in s3_uris[1]\n\n    assert file_1_body == S3Downloader.read_file(s3_uri=s3_uris[0], session=sagemaker_session)\n    assert file_2_body == S3Downloader.read_file(s3_uri=s3_uris[1], session=sagemaker_session)\n\n\ndef test_s3_uploader_and_downloader_downloads_files_when_given_file_name_uris(\n    sagemaker_session, s3_files_kms_key\n):\n    my_uuid = str(uuid.uuid4())\n\n    file_1_body = ""First File Body {}."".format(my_uuid)\n    file_1_name = ""first_file_{}.txt"".format(my_uuid)\n    file_2_body = ""Second File Body {}."".format(my_uuid)\n    file_2_name = ""second_file_{}.txt"".format(my_uuid)\n\n    base_s3_uri = os.path.join(\n        ""s3://"", sagemaker_session.default_bucket(), ""integ-test-test-s3-list"", my_uuid\n    )\n    file_1_s3_uri = os.path.join(base_s3_uri, file_1_name)\n    file_2_s3_uri = os.path.join(base_s3_uri, file_2_name)\n\n    S3Uploader.upload_string_as_file_body(\n        body=file_1_body,\n        desired_s3_uri=file_1_s3_uri,\n        kms_key=s3_files_kms_key,\n        session=sagemaker_session,\n    )\n\n    S3Uploader.upload_string_as_file_body(\n        body=file_2_body,\n        desired_s3_uri=file_2_s3_uri,\n        kms_key=s3_files_kms_key,\n        session=sagemaker_session,\n    )\n\n    s3_uris = S3Downloader.list(s3_uri=base_s3_uri, session=sagemaker_session)\n\n    assert file_1_name in s3_uris[0]\n    assert file_2_name in s3_uris[1]\n\n    S3Downloader.download(s3_uri=s3_uris[0], local_path=TMP_BASE_PATH, session=sagemaker_session)\n    S3Downloader.download(s3_uri=s3_uris[1], local_path=TMP_BASE_PATH, session=sagemaker_session)\n\n    with open(os.path.join(TMP_BASE_PATH, file_1_name), ""r"") as f:\n        assert file_1_body == f.read()\n\n    with open(os.path.join(TMP_BASE_PATH, file_2_name), ""r"") as f:\n        assert file_2_body == f.read()\n\n\ndef test_s3_uploader_and_downloader_downloads_files_when_given_directory_uris_with_files(\n    sagemaker_session, s3_files_kms_key\n):\n    my_uuid = str(uuid.uuid4())\n\n    file_1_body = ""First File Body {}."".format(my_uuid)\n    file_1_name = ""first_file_{}.txt"".format(my_uuid)\n    file_2_body = ""Second File Body {}."".format(my_uuid)\n    file_2_name = ""second_file_{}.txt"".format(my_uuid)\n\n    base_s3_uri = os.path.join(\n        ""s3://"", sagemaker_session.default_bucket(), ""integ-test-test-s3-list"", my_uuid\n    )\n    file_1_s3_uri = os.path.join(base_s3_uri, file_1_name)\n    file_2_s3_uri = os.path.join(base_s3_uri, file_2_name)\n\n    S3Uploader.upload_string_as_file_body(\n        body=file_1_body,\n        desired_s3_uri=file_1_s3_uri,\n        kms_key=s3_files_kms_key,\n        session=sagemaker_session,\n    )\n\n    S3Uploader.upload_string_as_file_body(\n        body=file_2_body,\n        desired_s3_uri=file_2_s3_uri,\n        kms_key=s3_files_kms_key,\n        session=sagemaker_session,\n    )\n\n    s3_uris = S3Downloader.list(s3_uri=base_s3_uri, session=sagemaker_session)\n\n    assert file_1_name in s3_uris[0]\n    assert file_2_name in s3_uris[1]\n\n    assert file_1_body == S3Downloader.read_file(s3_uri=s3_uris[0], session=sagemaker_session)\n    assert file_2_body == S3Downloader.read_file(s3_uri=s3_uris[1], session=sagemaker_session)\n\n    S3Downloader.download(s3_uri=base_s3_uri, local_path=TMP_BASE_PATH, session=sagemaker_session)\n\n    with open(os.path.join(TMP_BASE_PATH, file_1_name), ""r"") as f:\n        assert file_1_body == f.read()\n\n    with open(os.path.join(TMP_BASE_PATH, file_2_name), ""r"") as f:\n        assert file_2_body == f.read()\n\n\ndef test_s3_uploader_and_downloader_downloads_files_when_given_directory_uris_with_directory(\n    sagemaker_session, s3_files_kms_key\n):\n    my_uuid = str(uuid.uuid4())\n    my_inner_directory_uuid = str(uuid.uuid4())\n\n    file_1_body = ""First File Body {}."".format(my_uuid)\n    file_1_name = ""first_file_{}.txt"".format(my_uuid)\n    file_2_body = ""Second File Body {}."".format(my_uuid)\n    file_2_name = ""second_file_{}.txt"".format(my_uuid)\n\n    base_s3_uri = os.path.join(\n        ""s3://"",\n        sagemaker_session.default_bucket(),\n        ""integ-test-test-s3-list"",\n        my_uuid,\n        my_inner_directory_uuid,\n    )\n    file_1_s3_uri = os.path.join(base_s3_uri, file_1_name)\n    file_2_s3_uri = os.path.join(base_s3_uri, file_2_name)\n\n    S3Uploader.upload_string_as_file_body(\n        body=file_1_body,\n        desired_s3_uri=file_1_s3_uri,\n        kms_key=s3_files_kms_key,\n        session=sagemaker_session,\n    )\n\n    S3Uploader.upload_string_as_file_body(\n        body=file_2_body,\n        desired_s3_uri=file_2_s3_uri,\n        kms_key=s3_files_kms_key,\n        session=sagemaker_session,\n    )\n\n    s3_uris = S3Downloader.list(s3_uri=base_s3_uri, session=sagemaker_session)\n\n    assert file_1_name in s3_uris[0]\n    assert file_2_name in s3_uris[1]\n\n    assert file_1_body == S3Downloader.read_file(s3_uri=s3_uris[0], session=sagemaker_session)\n    assert file_2_body == S3Downloader.read_file(s3_uri=s3_uris[1], session=sagemaker_session)\n\n    s3_directory_with_directory_underneath = os.path.join(\n        ""s3://"", sagemaker_session.default_bucket(), ""integ-test-test-s3-list"", my_uuid\n    )\n\n    S3Downloader.download(\n        s3_uri=s3_directory_with_directory_underneath,\n        local_path=TMP_BASE_PATH,\n        session=sagemaker_session,\n    )\n\n    with open(os.path.join(TMP_BASE_PATH, my_inner_directory_uuid, file_1_name), ""r"") as f:\n        assert file_1_body == f.read()\n\n    with open(os.path.join(TMP_BASE_PATH, my_inner_directory_uuid, file_2_name), ""r"") as f:\n        assert file_2_body == f.read()\n'"
tests/integ/test_session.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport boto3\nfrom botocore.config import Config\n\nfrom sagemaker import Session\n\nCUSTOM_BUCKET_NAME = ""this-bucket-should-not-exist""\n\n\ndef test_sagemaker_session_does_not_create_bucket_on_init(\n    sagemaker_client_config, sagemaker_runtime_config, boto_session\n):\n    sagemaker_client_config.setdefault(""config"", Config(retries=dict(max_attempts=10)))\n    sagemaker_client = (\n        boto_session.client(""sagemaker"", **sagemaker_client_config)\n        if sagemaker_client_config\n        else None\n    )\n    runtime_client = (\n        boto_session.client(""sagemaker-runtime"", **sagemaker_runtime_config)\n        if sagemaker_runtime_config\n        else None\n    )\n\n    Session(\n        boto_session=boto_session,\n        sagemaker_client=sagemaker_client,\n        sagemaker_runtime_client=runtime_client,\n        default_bucket=CUSTOM_BUCKET_NAME,\n    )\n\n    s3 = boto3.resource(""s3"", region_name=boto_session.region_name)\n    assert s3.Bucket(CUSTOM_BUCKET_NAME).creation_date is None\n'"
tests/integ/test_sklearn_train.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport os\nimport time\n\nimport pytest\nimport numpy\n\nfrom sagemaker.sklearn.defaults import SKLEARN_VERSION\nfrom sagemaker.sklearn import SKLearn\nfrom sagemaker.sklearn import SKLearnModel\nfrom sagemaker.utils import sagemaker_timestamp, unique_name_from_base\nfrom tests.integ import DATA_DIR, PYTHON_VERSION, TRAINING_DEFAULT_TIMEOUT_MINUTES\nfrom tests.integ.timeout import timeout, timeout_and_delete_endpoint_by_name\n\n\n@pytest.fixture(scope=""module"")\n@pytest.mark.skip(\n    reason=""This test has always failed, but the failure was masked by a bug. ""\n    ""This test should be fixed. Details in https://github.com/aws/sagemaker-python-sdk/pull/968""\n)\ndef sklearn_training_job(sagemaker_session, sklearn_full_version, cpu_instance_type):\n    return _run_mnist_training_job(sagemaker_session, cpu_instance_type, sklearn_full_version)\n    sagemaker_session.boto_region_name\n\n\n@pytest.mark.skipif(PYTHON_VERSION != ""py3"", reason=""Scikit-learn image supports only python 3."")\ndef test_training_with_additional_hyperparameters(\n    sagemaker_session, sklearn_full_version, cpu_instance_type\n):\n    with timeout(minutes=TRAINING_DEFAULT_TIMEOUT_MINUTES):\n        script_path = os.path.join(DATA_DIR, ""sklearn_mnist"", ""mnist.py"")\n        data_path = os.path.join(DATA_DIR, ""sklearn_mnist"")\n\n        sklearn = SKLearn(\n            entry_point=script_path,\n            role=""SageMakerRole"",\n            train_instance_type=cpu_instance_type,\n            framework_version=sklearn_full_version,\n            py_version=PYTHON_VERSION,\n            sagemaker_session=sagemaker_session,\n            hyperparameters={""epochs"": 1},\n        )\n\n        train_input = sklearn.sagemaker_session.upload_data(\n            path=os.path.join(data_path, ""train""), key_prefix=""integ-test-data/sklearn_mnist/train""\n        )\n        test_input = sklearn.sagemaker_session.upload_data(\n            path=os.path.join(data_path, ""test""), key_prefix=""integ-test-data/sklearn_mnist/test""\n        )\n        job_name = unique_name_from_base(""test-sklearn-hp"")\n\n        sklearn.fit({""train"": train_input, ""test"": test_input}, job_name=job_name)\n        return sklearn.latest_training_job.name\n\n\n@pytest.mark.skipif(PYTHON_VERSION != ""py3"", reason=""Scikit-learn image supports only python 3."")\ndef test_training_with_network_isolation(\n    sagemaker_session, sklearn_full_version, cpu_instance_type\n):\n    with timeout(minutes=TRAINING_DEFAULT_TIMEOUT_MINUTES):\n        script_path = os.path.join(DATA_DIR, ""sklearn_mnist"", ""mnist.py"")\n        data_path = os.path.join(DATA_DIR, ""sklearn_mnist"")\n\n        sklearn = SKLearn(\n            entry_point=script_path,\n            role=""SageMakerRole"",\n            train_instance_type=cpu_instance_type,\n            framework_version=sklearn_full_version,\n            py_version=PYTHON_VERSION,\n            sagemaker_session=sagemaker_session,\n            hyperparameters={""epochs"": 1},\n            enable_network_isolation=True,\n        )\n\n        train_input = sklearn.sagemaker_session.upload_data(\n            path=os.path.join(data_path, ""train""), key_prefix=""integ-test-data/sklearn_mnist/train""\n        )\n        test_input = sklearn.sagemaker_session.upload_data(\n            path=os.path.join(data_path, ""test""), key_prefix=""integ-test-data/sklearn_mnist/test""\n        )\n        job_name = unique_name_from_base(""test-sklearn-hp"")\n\n        sklearn.fit({""train"": train_input, ""test"": test_input}, job_name=job_name)\n        assert sagemaker_session.sagemaker_client.describe_training_job(TrainingJobName=job_name)[\n            ""EnableNetworkIsolation""\n        ]\n        return sklearn.latest_training_job.name\n\n\n@pytest.mark.canary_quick\n@pytest.mark.regional_testing\n@pytest.mark.skipif(PYTHON_VERSION != ""py3"", reason=""Scikit-learn image supports only python 3."")\n@pytest.mark.skip(\n    reason=""This test has always failed, but the failure was masked by a bug. ""\n    ""This test should be fixed. Details in https://github.com/aws/sagemaker-python-sdk/pull/968""\n)\ndef test_attach_deploy(sklearn_training_job, sagemaker_session, cpu_instance_type):\n    endpoint_name = ""test-sklearn-attach-deploy-{}"".format(sagemaker_timestamp())\n\n    with timeout_and_delete_endpoint_by_name(endpoint_name, sagemaker_session):\n        estimator = SKLearn.attach(sklearn_training_job, sagemaker_session=sagemaker_session)\n        predictor = estimator.deploy(1, cpu_instance_type, endpoint_name=endpoint_name)\n        _predict_and_assert(predictor)\n\n\n@pytest.mark.skipif(PYTHON_VERSION != ""py3"", reason=""Scikit-learn image supports only python 3."")\n@pytest.mark.skip(\n    reason=""This test has always failed, but the failure was masked by a bug. ""\n    ""This test should be fixed. Details in https://github.com/aws/sagemaker-python-sdk/pull/968""\n)\ndef test_deploy_model(sklearn_training_job, sagemaker_session, cpu_instance_type):\n    endpoint_name = ""test-sklearn-deploy-model-{}"".format(sagemaker_timestamp())\n    with timeout_and_delete_endpoint_by_name(endpoint_name, sagemaker_session):\n        desc = sagemaker_session.sagemaker_client.describe_training_job(\n            TrainingJobName=sklearn_training_job\n        )\n        model_data = desc[""ModelArtifacts""][""S3ModelArtifacts""]\n        script_path = os.path.join(DATA_DIR, ""sklearn_mnist"", ""mnist.py"")\n        model = SKLearnModel(\n            model_data,\n            ""SageMakerRole"",\n            entry_point=script_path,\n            sagemaker_session=sagemaker_session,\n        )\n        predictor = model.deploy(1, cpu_instance_type, endpoint_name=endpoint_name)\n        _predict_and_assert(predictor)\n\n\n@pytest.mark.skipif(PYTHON_VERSION != ""py3"", reason=""Scikit-learn image supports only python 3."")\n@pytest.mark.skip(\n    reason=""This test has always failed, but the failure was masked by a bug. ""\n    ""This test should be fixed. Details in https://github.com/aws/sagemaker-python-sdk/pull/968""\n)\ndef test_async_fit(sagemaker_session, cpu_instance_type):\n    endpoint_name = ""test-sklearn-attach-deploy-{}"".format(sagemaker_timestamp())\n\n    with timeout(minutes=5):\n        training_job_name = _run_mnist_training_job(\n            sagemaker_session, cpu_instance_type, sklearn_full_version=SKLEARN_VERSION, wait=False\n        )\n\n        print(""Waiting to re-attach to the training job: %s"" % training_job_name)\n        time.sleep(20)\n\n    with timeout_and_delete_endpoint_by_name(endpoint_name, sagemaker_session):\n        print(""Re-attaching now to: %s"" % training_job_name)\n        estimator = SKLearn.attach(\n            training_job_name=training_job_name, sagemaker_session=sagemaker_session\n        )\n        predictor = estimator.deploy(1, cpu_instance_type, endpoint_name=endpoint_name)\n        _predict_and_assert(predictor)\n\n\n@pytest.mark.skipif(PYTHON_VERSION != ""py3"", reason=""Scikit-learn image supports only python 3."")\ndef test_failed_training_job(sagemaker_session, sklearn_full_version, cpu_instance_type):\n    with timeout(minutes=TRAINING_DEFAULT_TIMEOUT_MINUTES):\n        script_path = os.path.join(DATA_DIR, ""sklearn_mnist"", ""failure_script.py"")\n        data_path = os.path.join(DATA_DIR, ""sklearn_mnist"")\n\n        sklearn = SKLearn(\n            entry_point=script_path,\n            role=""SageMakerRole"",\n            framework_version=sklearn_full_version,\n            py_version=PYTHON_VERSION,\n            train_instance_count=1,\n            train_instance_type=cpu_instance_type,\n            sagemaker_session=sagemaker_session,\n        )\n\n        train_input = sklearn.sagemaker_session.upload_data(\n            path=os.path.join(data_path, ""train""), key_prefix=""integ-test-data/sklearn_mnist/train""\n        )\n        job_name = unique_name_from_base(""test-sklearn-failed"")\n\n        with pytest.raises(ValueError):\n            sklearn.fit(train_input, job_name=job_name)\n\n\ndef _run_mnist_training_job(sagemaker_session, instance_type, sklearn_full_version, wait=True):\n    with timeout(minutes=TRAINING_DEFAULT_TIMEOUT_MINUTES):\n\n        script_path = os.path.join(DATA_DIR, ""sklearn_mnist"", ""mnist.py"")\n\n        data_path = os.path.join(DATA_DIR, ""sklearn_mnist"")\n\n        sklearn = SKLearn(\n            entry_point=script_path,\n            role=""SageMakerRole"",\n            framework_version=sklearn_full_version,\n            py_version=PYTHON_VERSION,\n            train_instance_type=instance_type,\n            sagemaker_session=sagemaker_session,\n            hyperparameters={""epochs"": 1},\n        )\n\n        train_input = sklearn.sagemaker_session.upload_data(\n            path=os.path.join(data_path, ""train""), key_prefix=""integ-test-data/sklearn_mnist/train""\n        )\n        test_input = sklearn.sagemaker_session.upload_data(\n            path=os.path.join(data_path, ""test""), key_prefix=""integ-test-data/sklearn_mnist/test""\n        )\n        job_name = unique_name_from_base(""test-sklearn-mnist"")\n\n        sklearn.fit({""train"": train_input, ""test"": test_input}, wait=wait, job_name=job_name)\n        return sklearn.latest_training_job.name\n\n\ndef _predict_and_assert(predictor):\n    batch_size = 100\n    data = numpy.zeros((batch_size, 784), dtype=""float32"")\n    output = predictor.predict(data)\n    assert len(output) == batch_size\n\n    data = numpy.zeros((batch_size, 1, 28, 28), dtype=""float32"")\n    output = predictor.predict(data)\n    assert len(output) == batch_size\n\n    data = numpy.zeros((batch_size, 28, 28), dtype=""float32"")\n    output = predictor.predict(data)\n    assert len(output) == batch_size\n'"
tests/integ/test_source_dirs.py,0,"b'# Copyright 2018-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport os\n\nimport pytest\n\nimport tests.integ.lock as lock\nfrom tests.integ import DATA_DIR, PYTHON_VERSION\n\nfrom sagemaker.pytorch.estimator import PyTorch\n\n\n@pytest.mark.local_mode\ndef test_source_dirs(tmpdir, sagemaker_local_session):\n    source_dir = os.path.join(DATA_DIR, ""pytorch_source_dirs"")\n    lib = os.path.join(str(tmpdir), ""alexa.py"")\n\n    with open(lib, ""w"") as f:\n        f.write(""def question(to_anything): return 42"")\n\n    estimator = PyTorch(\n        entry_point=""train.py"",\n        role=""SageMakerRole"",\n        source_dir=source_dir,\n        dependencies=[lib],\n        py_version=PYTHON_VERSION,\n        train_instance_count=1,\n        train_instance_type=""local"",\n        sagemaker_session=sagemaker_local_session,\n    )\n    estimator.fit()\n\n    # endpoint tests all use the same port, so we use this lock to prevent concurrent execution\n    with lock.lock():\n        try:\n            predictor = estimator.deploy(initial_instance_count=1, instance_type=""local"")\n            predict_response = predictor.predict([7])\n            assert predict_response == [49]\n        finally:\n            estimator.delete_endpoint()\n'"
tests/integ/test_sparkml_serving.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport json\nimport os\n\nimport pytest\n\nfrom sagemaker.sparkml.model import SparkMLModel\nfrom sagemaker.utils import sagemaker_timestamp\nfrom tests.integ import DATA_DIR\nfrom tests.integ.timeout import timeout_and_delete_endpoint_by_name\n\n\n@pytest.mark.canary_quick\n@pytest.mark.regional_testing\n@pytest.mark.skip(\n    reason=""This test has always failed, but the failure was masked by a bug. ""\n    ""This test should be fixed. Details in https://github.com/aws/sagemaker-python-sdk/pull/968""\n)\ndef test_sparkml_model_deploy(sagemaker_session, cpu_instance_type):\n    # Uploads an MLeap serialized MLeap model to S3 and use that to deploy a SparkML model to perform inference\n    data_path = os.path.join(DATA_DIR, ""sparkml_model"")\n    endpoint_name = ""test-sparkml-deploy-{}"".format(sagemaker_timestamp())\n    model_data = sagemaker_session.upload_data(\n        path=os.path.join(data_path, ""mleap_model.tar.gz""),\n        key_prefix=""integ-test-data/sparkml/model"",\n    )\n    schema = json.dumps(\n        {\n            ""input"": [\n                {""name"": ""Pclass"", ""type"": ""float""},\n                {""name"": ""Embarked"", ""type"": ""string""},\n                {""name"": ""Age"", ""type"": ""float""},\n                {""name"": ""Fare"", ""type"": ""float""},\n                {""name"": ""SibSp"", ""type"": ""float""},\n                {""name"": ""Sex"", ""type"": ""string""},\n            ],\n            ""output"": {""name"": ""features"", ""struct"": ""vector"", ""type"": ""double""},\n        }\n    )\n    with timeout_and_delete_endpoint_by_name(endpoint_name, sagemaker_session):\n        model = SparkMLModel(\n            model_data=model_data,\n            role=""SageMakerRole"",\n            sagemaker_session=sagemaker_session,\n            env={""SAGEMAKER_SPARKML_SCHEMA"": schema},\n        )\n        predictor = model.deploy(1, cpu_instance_type, endpoint_name=endpoint_name)\n\n        valid_data = ""1.0,C,38.0,71.5,1.0,female""\n        assert predictor.predict(valid_data) == ""1.0,0.0,38.0,1.0,71.5,0.0,1.0""\n\n        invalid_data = ""1.0,28.0,C,38.0,71.5,1.0""\n        assert predictor.predict(invalid_data) is None\n'"
tests/integ/test_tf_efs_fsx.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport os\nimport time\n\nimport pytest\n\nfrom sagemaker.inputs import FileSystemInput\nfrom sagemaker.parameter import IntegerParameter\nfrom sagemaker.tensorflow import TensorFlow\nfrom sagemaker.tuner import HyperparameterTuner\nfrom sagemaker.utils import unique_name_from_base\nimport tests\nfrom tests.integ import TRAINING_DEFAULT_TIMEOUT_MINUTES, TUNING_DEFAULT_TIMEOUT_MINUTES\nfrom tests.integ.file_system_input_utils import tear_down, set_up_efs_fsx\nfrom tests.integ.s3_utils import assert_s3_files_exist\nfrom tests.integ.timeout import timeout\n\nRESOURCE_PATH = os.path.join(os.path.dirname(__file__), "".."", ""data"")\nMNIST_RESOURCE_PATH = os.path.join(RESOURCE_PATH, ""tensorflow_mnist"")\nSCRIPT = os.path.join(MNIST_RESOURCE_PATH, ""mnist.py"")\nTFS_RESOURCE_PATH = os.path.join(RESOURCE_PATH, ""tfs"", ""tfs-test-entrypoint-with-handler"")\nEFS_DIR_PATH = ""/tensorflow""\nFSX_DIR_PATH = ""/fsx/tensorflow""\nMAX_JOBS = 2\nMAX_PARALLEL_JOBS = 2\nPY_VERSION = ""py3""\n\n\n@pytest.fixture(scope=""module"")\ndef efs_fsx_setup(sagemaker_session, ec2_instance_type):\n    fs_resources = None\n    try:\n        fs_resources = set_up_efs_fsx(sagemaker_session, ec2_instance_type)\n        yield fs_resources\n    finally:\n        if fs_resources:\n            tear_down(sagemaker_session, fs_resources)\n\n\n@pytest.mark.skipif(\n    tests.integ.test_region() not in tests.integ.EFS_TEST_ENABLED_REGION,\n    reason=""EFS integration tests need to be fixed before running in all regions."",\n)\ndef test_mnist_efs(efs_fsx_setup, sagemaker_session, cpu_instance_type):\n    role = efs_fsx_setup[""role_name""]\n    subnets = [efs_fsx_setup[""subnet_id""]]\n    security_group_ids = efs_fsx_setup[""security_group_ids""]\n\n    estimator = TensorFlow(\n        entry_point=SCRIPT,\n        role=role,\n        train_instance_count=1,\n        train_instance_type=cpu_instance_type,\n        sagemaker_session=sagemaker_session,\n        script_mode=True,\n        framework_version=TensorFlow.LATEST_VERSION,\n        py_version=PY_VERSION,\n        subnets=subnets,\n        security_group_ids=security_group_ids,\n    )\n\n    file_system_efs_id = efs_fsx_setup[""file_system_efs_id""]\n    content_type = ""application/json""\n    file_system_input = FileSystemInput(\n        file_system_id=file_system_efs_id,\n        file_system_type=""EFS"",\n        directory_path=EFS_DIR_PATH,\n        content_type=content_type,\n    )\n    with timeout(minutes=TRAINING_DEFAULT_TIMEOUT_MINUTES):\n        estimator.fit(inputs=file_system_input, job_name=unique_name_from_base(""test-mnist-efs""))\n\n    assert_s3_files_exist(\n        sagemaker_session,\n        estimator.model_dir,\n        [""graph.pbtxt"", ""model.ckpt-0.index"", ""model.ckpt-0.meta""],\n    )\n\n\n@pytest.mark.skipif(\n    tests.integ.test_region() not in tests.integ.EFS_TEST_ENABLED_REGION,\n    reason=""EFS integration tests need to be fixed before running in all regions."",\n)\ndef test_mnist_lustre(efs_fsx_setup, sagemaker_session, cpu_instance_type):\n    role = efs_fsx_setup[""role_name""]\n    subnets = [efs_fsx_setup[""subnet_id""]]\n    security_group_ids = efs_fsx_setup[""security_group_ids""]\n\n    estimator = TensorFlow(\n        entry_point=SCRIPT,\n        role=role,\n        train_instance_count=1,\n        train_instance_type=cpu_instance_type,\n        sagemaker_session=sagemaker_session,\n        script_mode=True,\n        framework_version=TensorFlow.LATEST_VERSION,\n        py_version=PY_VERSION,\n        subnets=subnets,\n        security_group_ids=security_group_ids,\n    )\n\n    file_system_fsx_id = efs_fsx_setup[""file_system_fsx_id""]\n    file_system_input = FileSystemInput(\n        file_system_id=file_system_fsx_id, file_system_type=""FSxLustre"", directory_path=FSX_DIR_PATH\n    )\n\n    with timeout(minutes=TRAINING_DEFAULT_TIMEOUT_MINUTES):\n        estimator.fit(inputs=file_system_input, job_name=unique_name_from_base(""test-mnist-lustre""))\n    assert_s3_files_exist(\n        sagemaker_session,\n        estimator.model_dir,\n        [""graph.pbtxt"", ""model.ckpt-0.index"", ""model.ckpt-0.meta""],\n    )\n\n\n@pytest.mark.skipif(\n    tests.integ.test_region() not in tests.integ.EFS_TEST_ENABLED_REGION,\n    reason=""EFS integration tests need to be fixed before running in all regions."",\n)\ndef test_tuning_tf_script_mode_efs(efs_fsx_setup, sagemaker_session, cpu_instance_type):\n    role = efs_fsx_setup[""role_name""]\n    subnets = [efs_fsx_setup[""subnet_id""]]\n    security_group_ids = efs_fsx_setup[""security_group_ids""]\n\n    estimator = TensorFlow(\n        entry_point=SCRIPT,\n        role=role,\n        train_instance_count=1,\n        train_instance_type=cpu_instance_type,\n        script_mode=True,\n        sagemaker_session=sagemaker_session,\n        py_version=PY_VERSION,\n        framework_version=TensorFlow.LATEST_VERSION,\n        subnets=subnets,\n        security_group_ids=security_group_ids,\n    )\n\n    hyperparameter_ranges = {""epochs"": IntegerParameter(1, 2)}\n    objective_metric_name = ""accuracy""\n    metric_definitions = [{""Name"": objective_metric_name, ""Regex"": ""accuracy = ([0-9\\\\.]+)""}]\n    tuner = HyperparameterTuner(\n        estimator,\n        objective_metric_name,\n        hyperparameter_ranges,\n        metric_definitions,\n        max_jobs=MAX_JOBS,\n        max_parallel_jobs=MAX_PARALLEL_JOBS,\n    )\n\n    file_system_efs_id = efs_fsx_setup[""file_system_efs_id""]\n    file_system_input = FileSystemInput(\n        file_system_id=file_system_efs_id, file_system_type=""EFS"", directory_path=EFS_DIR_PATH\n    )\n\n    with timeout(minutes=TUNING_DEFAULT_TIMEOUT_MINUTES):\n        tuning_job_name = unique_name_from_base(""test-tuning-tf-script-mode-efs"", max_length=32)\n        tuner.fit(file_system_input, job_name=tuning_job_name)\n        time.sleep(15)\n        tuner.wait()\n    best_training_job = tuner.best_training_job()\n    assert best_training_job\n\n\n@pytest.mark.skipif(\n    tests.integ.test_region() not in tests.integ.EFS_TEST_ENABLED_REGION,\n    reason=""EFS integration tests need to be fixed before running in all regions."",\n)\ndef test_tuning_tf_script_mode_lustre(efs_fsx_setup, sagemaker_session, cpu_instance_type):\n    role = efs_fsx_setup[""role_name""]\n    subnets = [efs_fsx_setup[""subnet_id""]]\n    security_group_ids = efs_fsx_setup[""security_group_ids""]\n\n    estimator = TensorFlow(\n        entry_point=SCRIPT,\n        role=role,\n        train_instance_count=1,\n        train_instance_type=cpu_instance_type,\n        script_mode=True,\n        sagemaker_session=sagemaker_session,\n        py_version=PY_VERSION,\n        framework_version=TensorFlow.LATEST_VERSION,\n        subnets=subnets,\n        security_group_ids=security_group_ids,\n    )\n\n    hyperparameter_ranges = {""epochs"": IntegerParameter(1, 2)}\n    objective_metric_name = ""accuracy""\n    metric_definitions = [{""Name"": objective_metric_name, ""Regex"": ""accuracy = ([0-9\\\\.]+)""}]\n    tuner = HyperparameterTuner(\n        estimator,\n        objective_metric_name,\n        hyperparameter_ranges,\n        metric_definitions,\n        max_jobs=MAX_JOBS,\n        max_parallel_jobs=MAX_PARALLEL_JOBS,\n    )\n\n    file_system_fsx_id = efs_fsx_setup[""file_system_fsx_id""]\n    file_system_input = FileSystemInput(\n        file_system_id=file_system_fsx_id, file_system_type=""FSxLustre"", directory_path=FSX_DIR_PATH\n    )\n\n    with timeout(minutes=TUNING_DEFAULT_TIMEOUT_MINUTES):\n        tuning_job_name = unique_name_from_base(""test-tuning-tf-script-mode-lustre"", max_length=32)\n        tuner.fit(file_system_input, job_name=tuning_job_name)\n        time.sleep(15)\n        tuner.wait()\n    best_training_job = tuner.best_training_job()\n    assert best_training_job\n'"
tests/integ/test_tf_script_mode.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport numpy as np\nimport os\nimport time\n\nimport pytest\n\nfrom sagemaker.tensorflow import TensorFlow\nfrom sagemaker.tensorflow.defaults import LATEST_SERVING_VERSION\nfrom sagemaker.utils import unique_name_from_base, sagemaker_timestamp\n\nimport tests.integ\nfrom tests.integ import timeout\nfrom tests.integ import kms_utils\nfrom tests.integ.retry import retries\nfrom tests.integ.s3_utils import assert_s3_files_exist\n\nROLE = ""SageMakerRole""\n\nRESOURCE_PATH = os.path.join(os.path.dirname(__file__), "".."", ""data"")\nMNIST_RESOURCE_PATH = os.path.join(RESOURCE_PATH, ""tensorflow_mnist"")\nTFS_RESOURCE_PATH = os.path.join(RESOURCE_PATH, ""tfs"", ""tfs-test-entrypoint-with-handler"")\n\nSCRIPT = os.path.join(MNIST_RESOURCE_PATH, ""mnist.py"")\nPARAMETER_SERVER_DISTRIBUTION = {""parameter_server"": {""enabled"": True}}\nMPI_DISTRIBUTION = {""mpi"": {""enabled"": True}}\nTAGS = [{""Key"": ""some-key"", ""Value"": ""some-value""}]\n\n\n@pytest.fixture(scope=""module"")\ndef py_version(tf_full_version, tf_serving_version):\n    return ""py37"" if tf_full_version == tf_serving_version else tests.integ.PYTHON_VERSION\n\n\ndef test_mnist_with_checkpoint_config(\n    sagemaker_session, instance_type, tf_full_version, py_version\n):\n    checkpoint_s3_uri = ""s3://{}/checkpoints/tf-{}"".format(\n        sagemaker_session.default_bucket(), sagemaker_timestamp()\n    )\n    checkpoint_local_path = ""/test/checkpoint/path""\n    estimator = TensorFlow(\n        entry_point=SCRIPT,\n        role=""SageMakerRole"",\n        train_instance_count=1,\n        train_instance_type=instance_type,\n        sagemaker_session=sagemaker_session,\n        script_mode=True,\n        framework_version=tf_full_version,\n        py_version=""py37"",\n        metric_definitions=[{""Name"": ""train:global_steps"", ""Regex"": r""global_step\\/sec:\\s(.*)""}],\n        checkpoint_s3_uri=checkpoint_s3_uri,\n        checkpoint_local_path=checkpoint_local_path,\n    )\n    inputs = estimator.sagemaker_session.upload_data(\n        path=os.path.join(MNIST_RESOURCE_PATH, ""data""), key_prefix=""scriptmode/mnist""\n    )\n\n    training_job_name = unique_name_from_base(""test-tf-sm-mnist"")\n    with tests.integ.timeout.timeout(minutes=tests.integ.TRAINING_DEFAULT_TIMEOUT_MINUTES):\n        estimator.fit(inputs=inputs, job_name=training_job_name)\n    assert_s3_files_exist(\n        sagemaker_session,\n        estimator.model_dir,\n        [""graph.pbtxt"", ""model.ckpt-0.index"", ""model.ckpt-0.meta""],\n    )\n    df = estimator.training_job_analytics.dataframe()\n    assert df.size > 0\n\n    expected_training_checkpoint_config = {\n        ""S3Uri"": checkpoint_s3_uri,\n        ""LocalPath"": checkpoint_local_path,\n    }\n    actual_training_checkpoint_config = sagemaker_session.sagemaker_client.describe_training_job(\n        TrainingJobName=training_job_name\n    )[""CheckpointConfig""]\n    assert actual_training_checkpoint_config == expected_training_checkpoint_config\n\n\ndef test_server_side_encryption(sagemaker_session, tf_serving_version, py_version):\n    with kms_utils.bucket_with_encryption(sagemaker_session, ROLE) as (bucket_with_kms, kms_key):\n        output_path = os.path.join(\n            bucket_with_kms, ""test-server-side-encryption"", time.strftime(""%y%m%d-%H%M"")\n        )\n\n        estimator = TensorFlow(\n            entry_point=""training.py"",\n            source_dir=TFS_RESOURCE_PATH,\n            role=ROLE,\n            train_instance_count=1,\n            train_instance_type=""ml.c5.xlarge"",\n            sagemaker_session=sagemaker_session,\n            script_mode=True,\n            framework_version=tf_serving_version,\n            py_version=py_version,\n            code_location=output_path,\n            output_path=output_path,\n            model_dir=""/opt/ml/model"",\n            output_kms_key=kms_key,\n        )\n\n        inputs = estimator.sagemaker_session.upload_data(\n            path=os.path.join(MNIST_RESOURCE_PATH, ""data""), key_prefix=""scriptmode/mnist""\n        )\n\n        with tests.integ.timeout.timeout(minutes=tests.integ.TRAINING_DEFAULT_TIMEOUT_MINUTES):\n            estimator.fit(\n                inputs=inputs, job_name=unique_name_from_base(""test-server-side-encryption"")\n            )\n\n        endpoint_name = unique_name_from_base(""test-server-side-encryption"")\n        with timeout.timeout_and_delete_endpoint_by_name(endpoint_name, sagemaker_session):\n            estimator.deploy(\n                initial_instance_count=1,\n                instance_type=""ml.c5.xlarge"",\n                endpoint_name=endpoint_name,\n                entry_point=os.path.join(TFS_RESOURCE_PATH, ""inference.py""),\n            )\n\n\n@pytest.mark.canary_quick\ndef test_mnist_distributed(sagemaker_session, instance_type, tf_full_version, py_version):\n    estimator = TensorFlow(\n        entry_point=SCRIPT,\n        role=ROLE,\n        train_instance_count=2,\n        train_instance_type=instance_type,\n        sagemaker_session=sagemaker_session,\n        py_version=""py37"",\n        script_mode=True,\n        framework_version=tf_full_version,\n        distributions=PARAMETER_SERVER_DISTRIBUTION,\n    )\n    inputs = estimator.sagemaker_session.upload_data(\n        path=os.path.join(MNIST_RESOURCE_PATH, ""data""), key_prefix=""scriptmode/distributed_mnist""\n    )\n\n    with tests.integ.timeout.timeout(minutes=tests.integ.TRAINING_DEFAULT_TIMEOUT_MINUTES):\n        estimator.fit(inputs=inputs, job_name=unique_name_from_base(""test-tf-sm-distributed""))\n    assert_s3_files_exist(\n        sagemaker_session,\n        estimator.model_dir,\n        [""graph.pbtxt"", ""model.ckpt-0.index"", ""model.ckpt-0.meta""],\n    )\n\n\ndef test_mnist_async(sagemaker_session, cpu_instance_type, tf_full_version, py_version):\n    estimator = TensorFlow(\n        entry_point=SCRIPT,\n        role=ROLE,\n        train_instance_count=1,\n        train_instance_type=""ml.c5.4xlarge"",\n        py_version=tests.integ.PYTHON_VERSION,\n        sagemaker_session=sagemaker_session,\n        script_mode=True,\n        # testing py-sdk functionality, no need to run against all TF versions\n        framework_version=LATEST_SERVING_VERSION,\n        tags=TAGS,\n    )\n    inputs = estimator.sagemaker_session.upload_data(\n        path=os.path.join(MNIST_RESOURCE_PATH, ""data""), key_prefix=""scriptmode/mnist""\n    )\n    estimator.fit(inputs=inputs, wait=False, job_name=unique_name_from_base(""test-tf-sm-async""))\n    training_job_name = estimator.latest_training_job.name\n    time.sleep(20)\n    endpoint_name = training_job_name\n    _assert_training_job_tags_match(\n        sagemaker_session.sagemaker_client, estimator.latest_training_job.name, TAGS\n    )\n    with tests.integ.timeout.timeout_and_delete_endpoint_by_name(endpoint_name, sagemaker_session):\n        estimator = TensorFlow.attach(\n            training_job_name=training_job_name, sagemaker_session=sagemaker_session\n        )\n        model_name = ""model-mnist-async""\n        predictor = estimator.deploy(\n            initial_instance_count=1,\n            instance_type=cpu_instance_type,\n            endpoint_name=endpoint_name,\n            model_name=model_name,\n        )\n\n        result = predictor.predict(np.zeros(784))\n        print(""predict result: {}"".format(result))\n        _assert_endpoint_tags_match(sagemaker_session.sagemaker_client, predictor.endpoint, TAGS)\n        _assert_model_tags_match(sagemaker_session.sagemaker_client, model_name, TAGS)\n        _assert_model_name_match(sagemaker_session.sagemaker_client, endpoint_name, model_name)\n\n\ndef test_deploy_with_input_handlers(\n    sagemaker_session, instance_type, tf_serving_version, py_version\n):\n    estimator = TensorFlow(\n        entry_point=""training.py"",\n        source_dir=TFS_RESOURCE_PATH,\n        role=ROLE,\n        train_instance_count=1,\n        train_instance_type=instance_type,\n        py_version=py_version,\n        sagemaker_session=sagemaker_session,\n        script_mode=True,\n        framework_version=tf_serving_version,\n        tags=TAGS,\n    )\n\n    estimator.fit(job_name=unique_name_from_base(""test-tf-tfs-deploy""))\n\n    endpoint_name = estimator.latest_training_job.name\n\n    with timeout.timeout_and_delete_endpoint_by_name(endpoint_name, sagemaker_session):\n        predictor = estimator.deploy(\n            initial_instance_count=1,\n            instance_type=instance_type,\n            endpoint_name=endpoint_name,\n            entry_point=os.path.join(TFS_RESOURCE_PATH, ""inference.py""),\n        )\n\n        input_data = {""instances"": [1.0, 2.0, 5.0]}\n        expected_result = {""predictions"": [4.0, 4.5, 6.0]}\n\n        result = predictor.predict(input_data)\n        assert expected_result == result\n\n\ndef _assert_tags_match(sagemaker_client, resource_arn, tags, retry_count=15):\n    # endpoint and training tags might take minutes to propagate.\n    for _ in retries(retry_count, ""Getting endpoint tags"", seconds_to_sleep=30):\n        actual_tags = sagemaker_client.list_tags(ResourceArn=resource_arn)[""Tags""]\n        if actual_tags:\n            break\n\n    assert actual_tags == tags\n\n\ndef _assert_model_tags_match(sagemaker_client, model_name, tags):\n    model_description = sagemaker_client.describe_model(ModelName=model_name)\n    _assert_tags_match(sagemaker_client, model_description[""ModelArn""], tags)\n\n\ndef _assert_endpoint_tags_match(sagemaker_client, endpoint_name, tags):\n    endpoint_description = sagemaker_client.describe_endpoint(EndpointName=endpoint_name)\n\n    _assert_tags_match(sagemaker_client, endpoint_description[""EndpointArn""], tags)\n\n\ndef _assert_training_job_tags_match(sagemaker_client, training_job_name, tags):\n    training_job_description = sagemaker_client.describe_training_job(\n        TrainingJobName=training_job_name\n    )\n    _assert_tags_match(sagemaker_client, training_job_description[""TrainingJobArn""], tags)\n\n\ndef _assert_model_name_match(sagemaker_client, endpoint_config_name, model_name):\n    endpoint_config_description = sagemaker_client.describe_endpoint_config(\n        EndpointConfigName=endpoint_config_name\n    )\n    assert model_name == endpoint_config_description[""ProductionVariants""][0][""ModelName""]\n'"
tests/integ/test_tfs.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport tarfile\n\nimport botocore.exceptions\nimport os\n\nimport pytest\nimport sagemaker\nimport sagemaker.predictor\nimport sagemaker.utils\nimport tests.integ\nimport tests.integ.timeout\nfrom sagemaker.tensorflow.serving import Model, Predictor\n\n\n@pytest.fixture(scope=""module"")\ndef tfs_predictor(sagemaker_session, tf_serving_version):\n    endpoint_name = sagemaker.utils.unique_name_from_base(""sagemaker-tensorflow-serving"")\n    model_data = sagemaker_session.upload_data(\n        path=os.path.join(tests.integ.DATA_DIR, ""tensorflow-serving-test-model.tar.gz""),\n        key_prefix=""tensorflow-serving/models"",\n    )\n    with tests.integ.timeout.timeout_and_delete_endpoint_by_name(endpoint_name, sagemaker_session):\n        model = Model(\n            model_data=model_data,\n            role=""SageMakerRole"",\n            framework_version=tf_serving_version,\n            sagemaker_session=sagemaker_session,\n        )\n        predictor = model.deploy(1, ""ml.c5.xlarge"", endpoint_name=endpoint_name)\n        yield predictor\n\n\ndef tar_dir(directory, tmpdir):\n    target = os.path.join(str(tmpdir), ""model.tar.gz"")\n\n    with tarfile.open(target, mode=""w:gz"") as t:\n        t.add(directory, arcname=os.path.sep)\n    return target\n\n\n@pytest.fixture\ndef tfs_predictor_with_model_and_entry_point_same_tar(\n    sagemaker_local_session, tf_serving_version, tmpdir\n):\n    endpoint_name = sagemaker.utils.unique_name_from_base(""sagemaker-tensorflow-serving"")\n\n    model_tar = tar_dir(\n        os.path.join(tests.integ.DATA_DIR, ""tfs/tfs-test-model-with-inference""), tmpdir\n    )\n\n    model = Model(\n        model_data=""file://"" + model_tar,\n        role=""SageMakerRole"",\n        framework_version=tf_serving_version,\n        sagemaker_session=sagemaker_local_session,\n    )\n    predictor = model.deploy(1, ""local"", endpoint_name=endpoint_name)\n\n    try:\n        yield predictor\n    finally:\n        predictor.delete_endpoint()\n\n\n@pytest.fixture(scope=""module"")\ndef tfs_predictor_with_model_and_entry_point_and_dependencies(\n    sagemaker_local_session, tf_serving_version\n):\n    endpoint_name = sagemaker.utils.unique_name_from_base(""sagemaker-tensorflow-serving"")\n\n    entry_point = os.path.join(\n        tests.integ.DATA_DIR, ""tfs/tfs-test-entrypoint-and-dependencies/inference.py""\n    )\n    dependencies = [\n        os.path.join(tests.integ.DATA_DIR, ""tfs/tfs-test-entrypoint-and-dependencies/dependency.py"")\n    ]\n\n    model_data = ""file://"" + os.path.join(\n        tests.integ.DATA_DIR, ""tensorflow-serving-test-model.tar.gz""\n    )\n\n    model = Model(\n        entry_point=entry_point,\n        model_data=model_data,\n        role=""SageMakerRole"",\n        dependencies=dependencies,\n        framework_version=tf_serving_version,\n        sagemaker_session=sagemaker_local_session,\n    )\n\n    predictor = model.deploy(1, ""local"", endpoint_name=endpoint_name)\n    try:\n\n        yield predictor\n    finally:\n        predictor.delete_endpoint()\n\n\n@pytest.fixture(scope=""module"")\ndef tfs_predictor_with_accelerator(sagemaker_session, ei_tf_full_version, cpu_instance_type):\n    endpoint_name = sagemaker.utils.unique_name_from_base(""sagemaker-tensorflow-serving"")\n    model_data = sagemaker_session.upload_data(\n        path=os.path.join(tests.integ.DATA_DIR, ""tensorflow-serving-test-model.tar.gz""),\n        key_prefix=""tensorflow-serving/models"",\n    )\n    with tests.integ.timeout.timeout_and_delete_endpoint_by_name(endpoint_name, sagemaker_session):\n        model = Model(\n            model_data=model_data,\n            role=""SageMakerRole"",\n            framework_version=ei_tf_full_version,\n            sagemaker_session=sagemaker_session,\n        )\n        predictor = model.deploy(\n            1, cpu_instance_type, endpoint_name=endpoint_name, accelerator_type=""ml.eia1.medium""\n        )\n        yield predictor\n\n\n@pytest.mark.canary_quick\ndef test_predict(tfs_predictor):  # pylint: disable=W0613\n    input_data = {""instances"": [1.0, 2.0, 5.0]}\n    expected_result = {""predictions"": [3.5, 4.0, 5.5]}\n\n    result = tfs_predictor.predict(input_data)\n    assert expected_result == result\n\n\n@pytest.mark.skipif(\n    tests.integ.test_region() not in tests.integ.EI_SUPPORTED_REGIONS,\n    reason=""EI is not supported in region {}"".format(tests.integ.test_region()),\n)\n@pytest.mark.canary_quick\ndef test_predict_with_accelerator(tfs_predictor_with_accelerator):\n    input_data = {""instances"": [1.0, 2.0, 5.0]}\n    expected_result = {""predictions"": [3.5, 4.0, 5.5]}\n\n    result = tfs_predictor_with_accelerator.predict(input_data)\n    assert expected_result == result\n\n\n@pytest.mark.local_mode\ndef test_predict_with_entry_point(tfs_predictor_with_model_and_entry_point_same_tar):\n    input_data = {""instances"": [1.0, 2.0, 5.0]}\n    expected_result = {""predictions"": [4.0, 4.5, 6.0]}\n\n    result = tfs_predictor_with_model_and_entry_point_same_tar.predict(input_data)\n    assert expected_result == result\n\n\n@pytest.mark.local_mode\ndef test_predict_with_model_and_entry_point_and_dependencies_separated(\n    tfs_predictor_with_model_and_entry_point_and_dependencies\n):\n    input_data = {""instances"": [1.0, 2.0, 5.0]}\n    expected_result = {""predictions"": [4.0, 4.5, 6.0]}\n\n    result = tfs_predictor_with_model_and_entry_point_and_dependencies.predict(input_data)\n    assert expected_result == result\n\n\ndef test_predict_generic_json(tfs_predictor):\n    input_data = [[1.0, 2.0, 5.0], [1.0, 2.0, 5.0]]\n    expected_result = {""predictions"": [[3.5, 4.0, 5.5], [3.5, 4.0, 5.5]]}\n\n    result = tfs_predictor.predict(input_data)\n    assert expected_result == result\n\n\ndef test_predict_jsons_json_content_type(tfs_predictor):\n    input_data = ""[1.0, 2.0, 5.0]\\n[1.0, 2.0, 5.0]""\n    expected_result = {""predictions"": [[3.5, 4.0, 5.5], [3.5, 4.0, 5.5]]}\n\n    predictor = sagemaker.RealTimePredictor(\n        tfs_predictor.endpoint,\n        tfs_predictor.sagemaker_session,\n        serializer=None,\n        deserializer=sagemaker.predictor.json_deserializer,\n        content_type=""application/json"",\n        accept=""application/json"",\n    )\n\n    result = predictor.predict(input_data)\n    assert expected_result == result\n\n\ndef test_predict_jsons(tfs_predictor):\n    input_data = ""[1.0, 2.0, 5.0]\\n[1.0, 2.0, 5.0]""\n    expected_result = {""predictions"": [[3.5, 4.0, 5.5], [3.5, 4.0, 5.5]]}\n\n    predictor = sagemaker.RealTimePredictor(\n        tfs_predictor.endpoint,\n        tfs_predictor.sagemaker_session,\n        serializer=None,\n        deserializer=sagemaker.predictor.json_deserializer,\n        content_type=""application/jsons"",\n        accept=""application/jsons"",\n    )\n\n    result = predictor.predict(input_data)\n    assert expected_result == result\n\n\ndef test_predict_jsonlines(tfs_predictor):\n    input_data = ""[1.0, 2.0, 5.0]\\n[1.0, 2.0, 5.0]""\n    expected_result = {""predictions"": [[3.5, 4.0, 5.5], [3.5, 4.0, 5.5]]}\n\n    predictor = sagemaker.RealTimePredictor(\n        tfs_predictor.endpoint,\n        tfs_predictor.sagemaker_session,\n        serializer=None,\n        deserializer=sagemaker.predictor.json_deserializer,\n        content_type=""application/jsonlines"",\n        accept=""application/jsonlines"",\n    )\n\n    result = predictor.predict(input_data)\n    assert expected_result == result\n\n\ndef test_predict_csv(tfs_predictor):\n    input_data = ""1.0,2.0,5.0\\n1.0,2.0,5.0""\n    expected_result = {""predictions"": [[3.5, 4.0, 5.5], [3.5, 4.0, 5.5]]}\n\n    predictor = Predictor(\n        tfs_predictor.endpoint,\n        tfs_predictor.sagemaker_session,\n        serializer=sagemaker.predictor.csv_serializer,\n    )\n\n    result = predictor.predict(input_data)\n    assert expected_result == result\n\n\ndef test_predict_bad_input(tfs_predictor):\n    input_data = {""junk"": ""data""}\n    with pytest.raises(botocore.exceptions.ClientError):\n        tfs_predictor.predict(input_data)\n'"
tests/integ/test_transformer.py,2,"b'# Copyright 2018-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport gzip\nimport json\nimport os\nimport pickle\nimport sys\nimport time\n\nimport pytest\n\nfrom sagemaker import KMeans, s3\nfrom sagemaker.mxnet import MXNet\nfrom sagemaker.pytorch import PyTorchModel\nfrom sagemaker.tensorflow import TensorFlow\nfrom sagemaker.tensorflow.defaults import LATEST_SERVING_VERSION\nfrom sagemaker.transformer import Transformer\nfrom sagemaker.estimator import Estimator\nfrom sagemaker.utils import unique_name_from_base\nfrom tests.integ import (\n    DATA_DIR,\n    PYTHON_VERSION,\n    TRAINING_DEFAULT_TIMEOUT_MINUTES,\n    TRANSFORM_DEFAULT_TIMEOUT_MINUTES,\n)\nfrom tests.integ.kms_utils import bucket_with_encryption, get_or_create_kms_key\nfrom tests.integ.timeout import timeout, timeout_and_delete_model_with_transformer\nfrom tests.integ.vpc_test_utils import get_or_create_vpc_resources\n\nMXNET_MNIST_PATH = os.path.join(DATA_DIR, ""mxnet_mnist"")\n\n\n@pytest.fixture(scope=""module"")\ndef mxnet_estimator(sagemaker_session, mxnet_full_version, cpu_instance_type):\n    mx = MXNet(\n        entry_point=os.path.join(MXNET_MNIST_PATH, ""mnist.py""),\n        role=""SageMakerRole"",\n        train_instance_count=1,\n        train_instance_type=cpu_instance_type,\n        sagemaker_session=sagemaker_session,\n        framework_version=mxnet_full_version,\n    )\n\n    train_input = mx.sagemaker_session.upload_data(\n        path=os.path.join(MXNET_MNIST_PATH, ""train""), key_prefix=""integ-test-data/mxnet_mnist/train""\n    )\n    test_input = mx.sagemaker_session.upload_data(\n        path=os.path.join(MXNET_MNIST_PATH, ""test""), key_prefix=""integ-test-data/mxnet_mnist/test""\n    )\n\n    job_name = unique_name_from_base(""test-mxnet-transform"")\n    with timeout(minutes=TRAINING_DEFAULT_TIMEOUT_MINUTES):\n        mx.fit({""train"": train_input, ""test"": test_input}, job_name=job_name)\n\n    return mx\n\n\n@pytest.fixture(scope=""module"")\ndef mxnet_transform_input(sagemaker_session):\n    transform_input_path = os.path.join(MXNET_MNIST_PATH, ""transform"", ""data.csv"")\n    transform_input_key_prefix = ""integ-test-data/mxnet_mnist/transform""\n    return sagemaker_session.upload_data(\n        path=transform_input_path, key_prefix=transform_input_key_prefix\n    )\n\n\n@pytest.mark.canary_quick\ndef test_transform_mxnet(\n    mxnet_estimator, mxnet_transform_input, sagemaker_session, cpu_instance_type\n):\n    kms_key_arn = get_or_create_kms_key(sagemaker_session)\n    output_filter = ""$""\n    input_filter = ""$""\n\n    transformer = _create_transformer_and_transform_job(\n        mxnet_estimator,\n        mxnet_transform_input,\n        cpu_instance_type,\n        kms_key_arn,\n        input_filter=input_filter,\n        output_filter=output_filter,\n        join_source=None,\n    )\n    with timeout_and_delete_model_with_transformer(\n        transformer, sagemaker_session, minutes=TRANSFORM_DEFAULT_TIMEOUT_MINUTES\n    ):\n        transformer.wait()\n\n    job_desc = transformer.sagemaker_session.describe_transform_job(\n        job_name=transformer.latest_transform_job.name\n    )\n    assert kms_key_arn == job_desc[""TransformResources""][""VolumeKmsKeyId""]\n    assert output_filter == job_desc[""DataProcessing""][""OutputFilter""]\n    assert input_filter == job_desc[""DataProcessing""][""InputFilter""]\n\n\n@pytest.mark.canary_quick\ndef test_attach_transform_kmeans(sagemaker_session, cpu_instance_type):\n    data_path = os.path.join(DATA_DIR, ""one_p_mnist"")\n    pickle_args = {} if sys.version_info.major == 2 else {""encoding"": ""latin1""}\n\n    # Load the data into memory as numpy arrays\n    train_set_path = os.path.join(data_path, ""mnist.pkl.gz"")\n    with gzip.open(train_set_path, ""rb"") as f:\n        train_set, _, _ = pickle.load(f, **pickle_args)\n\n    kmeans = KMeans(\n        role=""SageMakerRole"",\n        train_instance_count=1,\n        train_instance_type=cpu_instance_type,\n        k=10,\n        sagemaker_session=sagemaker_session,\n        output_path=""s3://{}/"".format(sagemaker_session.default_bucket()),\n    )\n\n    # set kmeans specific hp\n    kmeans.init_method = ""random""\n    kmeans.max_iterators = 1\n    kmeans.tol = 1\n    kmeans.num_trials = 1\n    kmeans.local_init_method = ""kmeans++""\n    kmeans.half_life_time_size = 1\n    kmeans.epochs = 1\n\n    records = kmeans.record_set(train_set[0][:100])\n\n    job_name = unique_name_from_base(""test-kmeans-attach"")\n\n    with timeout(minutes=TRAINING_DEFAULT_TIMEOUT_MINUTES):\n        kmeans.fit(records, job_name=job_name)\n\n    transform_input_path = os.path.join(data_path, ""transform_input.csv"")\n    transform_input_key_prefix = ""integ-test-data/one_p_mnist/transform""\n    transform_input = kmeans.sagemaker_session.upload_data(\n        path=transform_input_path, key_prefix=transform_input_key_prefix\n    )\n\n    transformer = _create_transformer_and_transform_job(kmeans, transform_input, cpu_instance_type)\n\n    attached_transformer = Transformer.attach(\n        transformer.latest_transform_job.name, sagemaker_session=sagemaker_session\n    )\n    with timeout_and_delete_model_with_transformer(\n        transformer, sagemaker_session, minutes=TRANSFORM_DEFAULT_TIMEOUT_MINUTES\n    ):\n        attached_transformer.wait()\n\n\ndef test_transform_pytorch_vpc_custom_model_bucket(\n    sagemaker_session, pytorch_full_version, cpu_instance_type, custom_bucket_name\n):\n    data_dir = os.path.join(DATA_DIR, ""pytorch_mnist"")\n\n    ec2_client = sagemaker_session.boto_session.client(""ec2"")\n    subnet_ids, security_group_id = get_or_create_vpc_resources(ec2_client)\n\n    model_data = sagemaker_session.upload_data(\n        path=os.path.join(data_dir, ""model.tar.gz""),\n        bucket=custom_bucket_name,\n        key_prefix=""integ-test-data/pytorch_mnist/model"",\n    )\n\n    model = PyTorchModel(\n        model_data=model_data,\n        entry_point=os.path.join(data_dir, ""mnist.py""),\n        role=""SageMakerRole"",\n        framework_version=pytorch_full_version,\n        py_version=PYTHON_VERSION,\n        sagemaker_session=sagemaker_session,\n        vpc_config={""Subnets"": subnet_ids, ""SecurityGroupIds"": [security_group_id]},\n        code_location=""s3://{}"".format(custom_bucket_name),\n    )\n\n    transform_input = sagemaker_session.upload_data(\n        path=os.path.join(data_dir, ""transform"", ""data.npy""),\n        key_prefix=""integ-test-data/pytorch_mnist/transform"",\n    )\n\n    transformer = model.transformer(1, cpu_instance_type)\n    transformer.transform(\n        transform_input,\n        content_type=""application/x-npy"",\n        job_name=unique_name_from_base(""test-transform-vpc""),\n    )\n\n    with timeout_and_delete_model_with_transformer(\n        transformer, sagemaker_session, minutes=TRANSFORM_DEFAULT_TIMEOUT_MINUTES\n    ):\n        transformer.wait()\n        model_desc = sagemaker_session.sagemaker_client.describe_model(\n            ModelName=transformer.model_name\n        )\n        assert set(subnet_ids) == set(model_desc[""VpcConfig""][""Subnets""])\n        assert [security_group_id] == model_desc[""VpcConfig""][""SecurityGroupIds""]\n\n        model_bucket, _ = s3.parse_s3_url(model_desc[""PrimaryContainer""][""ModelDataUrl""])\n        assert custom_bucket_name == model_bucket\n\n\ndef test_transform_mxnet_tags(\n    mxnet_estimator, mxnet_transform_input, sagemaker_session, cpu_instance_type\n):\n    tags = [{""Key"": ""some-tag"", ""Value"": ""value-for-tag""}]\n\n    transformer = mxnet_estimator.transformer(1, cpu_instance_type, tags=tags)\n    transformer.transform(mxnet_transform_input, content_type=""text/csv"")\n\n    with timeout_and_delete_model_with_transformer(\n        transformer, sagemaker_session, minutes=TRANSFORM_DEFAULT_TIMEOUT_MINUTES\n    ):\n        transformer.wait()\n        model_desc = sagemaker_session.sagemaker_client.describe_model(\n            ModelName=transformer.model_name\n        )\n        model_tags = sagemaker_session.sagemaker_client.list_tags(\n            ResourceArn=model_desc[""ModelArn""]\n        )[""Tags""]\n        assert tags == model_tags\n\n\ndef test_transform_byo_estimator(sagemaker_session, cpu_instance_type):\n    data_path = os.path.join(DATA_DIR, ""one_p_mnist"")\n    pickle_args = {} if sys.version_info.major == 2 else {""encoding"": ""latin1""}\n    tags = [{""Key"": ""some-tag"", ""Value"": ""value-for-tag""}]\n\n    # Load the data into memory as numpy arrays\n    train_set_path = os.path.join(data_path, ""mnist.pkl.gz"")\n    with gzip.open(train_set_path, ""rb"") as f:\n        train_set, _, _ = pickle.load(f, **pickle_args)\n\n    kmeans = KMeans(\n        role=""SageMakerRole"",\n        train_instance_count=1,\n        train_instance_type=cpu_instance_type,\n        k=10,\n        sagemaker_session=sagemaker_session,\n        output_path=""s3://{}/"".format(sagemaker_session.default_bucket()),\n    )\n\n    # set kmeans specific hp\n    kmeans.init_method = ""random""\n    kmeans.max_iterators = 1\n    kmeans.tol = 1\n    kmeans.num_trials = 1\n    kmeans.local_init_method = ""kmeans++""\n    kmeans.half_life_time_size = 1\n    kmeans.epochs = 1\n\n    records = kmeans.record_set(train_set[0][:100])\n\n    job_name = unique_name_from_base(""test-kmeans-attach"")\n\n    with timeout(minutes=TRAINING_DEFAULT_TIMEOUT_MINUTES):\n        kmeans.fit(records, job_name=job_name)\n\n    estimator = Estimator.attach(training_job_name=job_name, sagemaker_session=sagemaker_session)\n    estimator._enable_network_isolation = True\n\n    transform_input_path = os.path.join(data_path, ""transform_input.csv"")\n    transform_input_key_prefix = ""integ-test-data/one_p_mnist/transform""\n    transform_input = kmeans.sagemaker_session.upload_data(\n        path=transform_input_path, key_prefix=transform_input_key_prefix\n    )\n\n    transformer = estimator.transformer(1, cpu_instance_type, tags=tags)\n    transformer.transform(transform_input, content_type=""text/csv"")\n\n    with timeout_and_delete_model_with_transformer(\n        transformer, sagemaker_session, minutes=TRANSFORM_DEFAULT_TIMEOUT_MINUTES\n    ):\n        transformer.wait()\n        model_desc = sagemaker_session.sagemaker_client.describe_model(\n            ModelName=transformer.model_name\n        )\n        assert model_desc[""EnableNetworkIsolation""]\n\n        model_tags = sagemaker_session.sagemaker_client.list_tags(\n            ResourceArn=model_desc[""ModelArn""]\n        )[""Tags""]\n        assert tags == model_tags\n\n\ndef test_single_transformer_multiple_jobs(\n    mxnet_estimator, mxnet_transform_input, sagemaker_session, cpu_instance_type\n):\n    transformer = mxnet_estimator.transformer(1, cpu_instance_type)\n\n    job_name = unique_name_from_base(""test-mxnet-transform"")\n    transformer.transform(mxnet_transform_input, content_type=""text/csv"", job_name=job_name)\n    with timeout_and_delete_model_with_transformer(\n        transformer, sagemaker_session, minutes=TRANSFORM_DEFAULT_TIMEOUT_MINUTES\n    ):\n        assert transformer.output_path == ""s3://{}/{}"".format(\n            sagemaker_session.default_bucket(), job_name\n        )\n        job_name = unique_name_from_base(""test-mxnet-transform"")\n        transformer.transform(mxnet_transform_input, content_type=""text/csv"", job_name=job_name)\n        assert transformer.output_path == ""s3://{}/{}"".format(\n            sagemaker_session.default_bucket(), job_name\n        )\n\n\ndef test_stop_transform_job(mxnet_estimator, mxnet_transform_input, cpu_instance_type):\n    transformer = mxnet_estimator.transformer(1, cpu_instance_type)\n    transformer.transform(mxnet_transform_input, content_type=""text/csv"")\n\n    time.sleep(15)\n\n    latest_transform_job_name = transformer.latest_transform_job.name\n\n    print(""Attempting to stop {}"".format(latest_transform_job_name))\n\n    transformer.stop_transform_job()\n\n    desc = transformer.latest_transform_job.sagemaker_session.describe_transform_job(\n        job_name=latest_transform_job_name\n    )\n    assert desc[""TransformJobStatus""] == ""Stopped""\n\n\ndef test_transform_mxnet_logs(\n    mxnet_estimator, mxnet_transform_input, sagemaker_session, cpu_instance_type\n):\n    with timeout(minutes=45):\n        transformer = _create_transformer_and_transform_job(\n            mxnet_estimator, mxnet_transform_input, cpu_instance_type, wait=True, logs=True\n        )\n\n    with timeout_and_delete_model_with_transformer(\n        transformer, sagemaker_session, minutes=TRANSFORM_DEFAULT_TIMEOUT_MINUTES\n    ):\n        transformer.wait()\n\n\ndef test_transform_tf_kms_network_isolation(sagemaker_session, cpu_instance_type, tmpdir):\n    data_path = os.path.join(DATA_DIR, ""tensorflow_mnist"")\n\n    tf = TensorFlow(\n        entry_point=os.path.join(data_path, ""mnist.py""),\n        role=""SageMakerRole"",\n        train_instance_count=1,\n        train_instance_type=cpu_instance_type,\n        framework_version=LATEST_SERVING_VERSION,\n        script_mode=True,\n        py_version=PYTHON_VERSION,\n        sagemaker_session=sagemaker_session,\n    )\n\n    s3_prefix = ""integ-test-data/tf-scriptmode/mnist""\n    training_input = sagemaker_session.upload_data(\n        path=os.path.join(data_path, ""data""), key_prefix=""{}/training"".format(s3_prefix)\n    )\n\n    job_name = unique_name_from_base(""test-tf-transform"")\n    tf.fit(inputs=training_input, job_name=job_name)\n\n    transform_input = sagemaker_session.upload_data(\n        path=os.path.join(data_path, ""transform""), key_prefix=""{}/transform"".format(s3_prefix)\n    )\n\n    with bucket_with_encryption(sagemaker_session, ""SageMakerRole"") as (bucket_with_kms, kms_key):\n        output_path = ""{}/{}/output"".format(bucket_with_kms, job_name)\n\n        transformer = tf.transformer(\n            instance_count=1,\n            instance_type=cpu_instance_type,\n            output_path=output_path,\n            output_kms_key=kms_key,\n            volume_kms_key=kms_key,\n            enable_network_isolation=True,\n        )\n\n        with timeout_and_delete_model_with_transformer(\n            transformer, sagemaker_session, minutes=TRANSFORM_DEFAULT_TIMEOUT_MINUTES\n        ):\n            transformer.transform(\n                transform_input, job_name=job_name, content_type=""text/csv"", wait=True\n            )\n\n            model_desc = sagemaker_session.sagemaker_client.describe_model(\n                ModelName=transformer.model_name\n            )\n            assert model_desc[""EnableNetworkIsolation""]\n\n        job_desc = sagemaker_session.describe_transform_job(job_name=job_name)\n        assert job_desc[""TransformOutput""][""S3OutputPath""] == output_path\n        assert job_desc[""TransformOutput""][""KmsKeyId""] == kms_key\n        assert job_desc[""TransformResources""][""VolumeKmsKeyId""] == kms_key\n\n        s3.S3Downloader.download(\n            s3_uri=output_path,\n            local_path=os.path.join(tmpdir, ""tf-batch-output""),\n            session=sagemaker_session,\n        )\n\n        with open(os.path.join(tmpdir, ""tf-batch-output"", ""data.csv.out"")) as f:\n            result = json.load(f)\n            assert len(result[""predictions""][0][""probabilities""]) == 10\n            assert result[""predictions""][0][""classes""] == 1\n\n\ndef _create_transformer_and_transform_job(\n    estimator,\n    transform_input,\n    instance_type,\n    volume_kms_key=None,\n    input_filter=None,\n    output_filter=None,\n    join_source=None,\n    wait=False,\n    logs=False,\n):\n    transformer = estimator.transformer(1, instance_type, volume_kms_key=volume_kms_key)\n    transformer.transform(\n        transform_input,\n        content_type=""text/csv"",\n        input_filter=input_filter,\n        output_filter=output_filter,\n        join_source=join_source,\n        wait=wait,\n        logs=logs,\n        job_name=unique_name_from_base(""test-transform""),\n    )\n    return transformer\n'"
tests/integ/test_tuner.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport gzip\nimport json\nimport os\nimport pickle\nimport sys\nimport time\n\nimport numpy as np\nimport pytest\nimport tests.integ\nfrom botocore.exceptions import ClientError\nfrom tests.integ import DATA_DIR, PYTHON_VERSION, TUNING_DEFAULT_TIMEOUT_MINUTES\nfrom tests.integ.record_set import prepare_record_set_from_local_files\nfrom tests.integ.timeout import timeout, timeout_and_delete_endpoint_by_name\nfrom tests.integ import vpc_test_utils\n\nfrom sagemaker import KMeans, LDA, RandomCutForest\nfrom sagemaker.amazon.amazon_estimator import get_image_uri\nfrom sagemaker.amazon.common import read_records\nfrom sagemaker.chainer import Chainer\nfrom sagemaker.estimator import Estimator\nfrom sagemaker.mxnet.estimator import MXNet\nfrom sagemaker.predictor import json_deserializer\nfrom sagemaker.pytorch import PyTorch\nfrom sagemaker.tensorflow import TensorFlow\nfrom sagemaker.tensorflow.defaults import LATEST_VERSION\nfrom sagemaker.tuner import (\n    IntegerParameter,\n    ContinuousParameter,\n    CategoricalParameter,\n    HyperparameterTuner,\n    WarmStartConfig,\n    WarmStartTypes,\n    create_transfer_learning_tuner,\n    create_identical_dataset_and_algorithm_tuner,\n)\nfrom sagemaker.utils import unique_name_from_base\n\nDATA_PATH = os.path.join(DATA_DIR, ""iris"", ""data"")\n\nPY37_SUPPORTED_FRAMEWORK_VERSION = [TensorFlow._LATEST_1X_VERSION, LATEST_VERSION]\n\n\n@pytest.fixture(scope=""module"")\ndef py_version(tf_full_version):\n    return ""py37"" if tf_full_version in PY37_SUPPORTED_FRAMEWORK_VERSION else PYTHON_VERSION\n\n\n@pytest.fixture(scope=""module"")\ndef kmeans_train_set(sagemaker_session):\n    data_path = os.path.join(DATA_DIR, ""one_p_mnist"", ""mnist.pkl.gz"")\n    pickle_args = {} if sys.version_info.major == 2 else {""encoding"": ""latin1""}\n    # Load the data into memory as numpy arrays\n    with gzip.open(data_path, ""rb"") as f:\n        train_set, _, _ = pickle.load(f, **pickle_args)\n\n    return train_set\n\n\n@pytest.fixture(scope=""module"")\ndef kmeans_estimator(sagemaker_session, cpu_instance_type):\n    kmeans = KMeans(\n        role=""SageMakerRole"",\n        train_instance_count=1,\n        train_instance_type=cpu_instance_type,\n        k=10,\n        sagemaker_session=sagemaker_session,\n        output_path=""s3://{}/"".format(sagemaker_session.default_bucket()),\n    )\n    # set kmeans specific hp\n    kmeans.init_method = ""random""\n    kmeans.max_iterators = 1\n    kmeans.tol = 1\n    kmeans.num_trials = 1\n    kmeans.local_init_method = ""kmeans++""\n    kmeans.half_life_time_size = 1\n    kmeans.epochs = 1\n\n    return kmeans\n\n\n@pytest.fixture(scope=""module"")\ndef hyperparameter_ranges():\n    return {\n        ""extra_center_factor"": IntegerParameter(1, 10),\n        ""mini_batch_size"": IntegerParameter(10, 100),\n        ""epochs"": IntegerParameter(1, 2),\n        ""init_method"": CategoricalParameter([""kmeans++"", ""random""]),\n    }\n\n\ndef _tune_and_deploy(\n    kmeans_estimator,\n    kmeans_train_set,\n    sagemaker_session,\n    cpu_instance_type,\n    hyperparameter_ranges=None,\n    job_name=None,\n    warm_start_config=None,\n    early_stopping_type=""Off"",\n):\n    tuner = _tune(\n        kmeans_estimator,\n        kmeans_train_set,\n        hyperparameter_ranges=hyperparameter_ranges,\n        warm_start_config=warm_start_config,\n        job_name=job_name,\n        early_stopping_type=early_stopping_type,\n    )\n    _deploy(kmeans_train_set, sagemaker_session, tuner, early_stopping_type, cpu_instance_type)\n\n\ndef _deploy(kmeans_train_set, sagemaker_session, tuner, early_stopping_type, cpu_instance_type):\n    best_training_job = tuner.best_training_job()\n    assert tuner.early_stopping_type == early_stopping_type\n    with timeout_and_delete_endpoint_by_name(best_training_job, sagemaker_session):\n        predictor = tuner.deploy(1, cpu_instance_type)\n\n        result = predictor.predict(kmeans_train_set[0][:10])\n\n        assert len(result) == 10\n        for record in result:\n            assert record.label[""closest_cluster""] is not None\n            assert record.label[""distance_to_cluster""] is not None\n\n\ndef _tune(\n    kmeans_estimator,\n    kmeans_train_set,\n    tuner=None,\n    hyperparameter_ranges=None,\n    job_name=None,\n    warm_start_config=None,\n    wait_till_terminal=True,\n    max_jobs=2,\n    max_parallel_jobs=2,\n    early_stopping_type=""Off"",\n):\n    with timeout(minutes=TUNING_DEFAULT_TIMEOUT_MINUTES):\n\n        if not tuner:\n            tuner = HyperparameterTuner(\n                estimator=kmeans_estimator,\n                objective_metric_name=""test:msd"",\n                hyperparameter_ranges=hyperparameter_ranges,\n                objective_type=""Minimize"",\n                max_jobs=max_jobs,\n                max_parallel_jobs=max_parallel_jobs,\n                warm_start_config=warm_start_config,\n                early_stopping_type=early_stopping_type,\n            )\n\n        records = kmeans_estimator.record_set(kmeans_train_set[0][:100])\n        test_record_set = kmeans_estimator.record_set(kmeans_train_set[0][:100], channel=""test"")\n\n        tuner.fit([records, test_record_set], job_name=job_name)\n        print(""Started hyperparameter tuning job with name:"" + tuner.latest_tuning_job.name)\n\n        if wait_till_terminal:\n            tuner.wait()\n\n    return tuner\n\n\n@pytest.mark.canary_quick\ndef test_tuning_kmeans(\n    sagemaker_session, kmeans_train_set, kmeans_estimator, hyperparameter_ranges, cpu_instance_type\n):\n    job_name = unique_name_from_base(""test-tune-kmeans"")\n    _tune_and_deploy(\n        kmeans_estimator,\n        kmeans_train_set,\n        sagemaker_session,\n        cpu_instance_type,\n        hyperparameter_ranges=hyperparameter_ranges,\n        job_name=job_name,\n    )\n\n\ndef test_tuning_kmeans_identical_dataset_algorithm_tuner_raw(\n    sagemaker_session, kmeans_train_set, kmeans_estimator, hyperparameter_ranges\n):\n    parent_tuning_job_name = unique_name_from_base(""kmeans-identical"", max_length=32)\n    child_tuning_job_name = unique_name_from_base(""c-kmeans-identical"", max_length=32)\n    _tune(\n        kmeans_estimator,\n        kmeans_train_set,\n        job_name=parent_tuning_job_name,\n        hyperparameter_ranges=hyperparameter_ranges,\n        max_parallel_jobs=1,\n        max_jobs=1,\n    )\n    child_tuner = _tune(\n        kmeans_estimator,\n        kmeans_train_set,\n        job_name=child_tuning_job_name,\n        hyperparameter_ranges=hyperparameter_ranges,\n        warm_start_config=WarmStartConfig(\n            warm_start_type=WarmStartTypes.IDENTICAL_DATA_AND_ALGORITHM,\n            parents=[parent_tuning_job_name],\n        ),\n        max_parallel_jobs=1,\n        max_jobs=1,\n    )\n\n    child_warm_start_config_response = WarmStartConfig.from_job_desc(\n        sagemaker_session.sagemaker_client.describe_hyper_parameter_tuning_job(\n            HyperParameterTuningJobName=child_tuning_job_name\n        )[""WarmStartConfig""]\n    )\n\n    assert child_warm_start_config_response.type == child_tuner.warm_start_config.type\n    assert child_warm_start_config_response.parents == child_tuner.warm_start_config.parents\n\n\ndef test_tuning_kmeans_identical_dataset_algorithm_tuner(\n    sagemaker_session, kmeans_train_set, kmeans_estimator, hyperparameter_ranges\n):\n    """"""Tests Identical dataset and algorithm use case with one parent and child job launched with\n        .identical_dataset_and_algorithm_tuner() """"""\n\n    parent_tuning_job_name = unique_name_from_base(""km-iden1-parent"", max_length=32)\n    child_tuning_job_name = unique_name_from_base(""km-iden1-child"", max_length=32)\n\n    parent_tuner = _tune(\n        kmeans_estimator,\n        kmeans_train_set,\n        job_name=parent_tuning_job_name,\n        hyperparameter_ranges=hyperparameter_ranges,\n    )\n\n    child_tuner = parent_tuner.identical_dataset_and_algorithm_tuner()\n    _tune(\n        kmeans_estimator,\n        kmeans_train_set,\n        job_name=child_tuning_job_name,\n        tuner=child_tuner,\n        max_parallel_jobs=1,\n        max_jobs=1,\n    )\n\n    child_warm_start_config_response = WarmStartConfig.from_job_desc(\n        sagemaker_session.sagemaker_client.describe_hyper_parameter_tuning_job(\n            HyperParameterTuningJobName=child_tuning_job_name\n        )[""WarmStartConfig""]\n    )\n\n    assert child_warm_start_config_response.type == child_tuner.warm_start_config.type\n    assert child_warm_start_config_response.parents == child_tuner.warm_start_config.parents\n\n\ndef test_create_tuning_kmeans_identical_dataset_algorithm_tuner(\n    sagemaker_session, kmeans_train_set, kmeans_estimator, hyperparameter_ranges\n):\n    """"""Tests Identical dataset and algorithm use case with one parent and child job launched with\n        .create_identical_dataset_and_algorithm_tuner() """"""\n\n    parent_tuning_job_name = unique_name_from_base(""km-iden2-parent"", max_length=32)\n    child_tuning_job_name = unique_name_from_base(""km-iden2-child"", max_length=32)\n\n    parent_tuner = _tune(\n        kmeans_estimator,\n        kmeans_train_set,\n        job_name=parent_tuning_job_name,\n        hyperparameter_ranges=hyperparameter_ranges,\n        max_parallel_jobs=1,\n        max_jobs=1,\n    )\n\n    child_tuner = create_identical_dataset_and_algorithm_tuner(\n        parent=parent_tuner.latest_tuning_job.name, sagemaker_session=sagemaker_session\n    )\n\n    _tune(\n        kmeans_estimator,\n        kmeans_train_set,\n        job_name=child_tuning_job_name,\n        tuner=child_tuner,\n        max_parallel_jobs=1,\n        max_jobs=1,\n    )\n\n    child_warm_start_config_response = WarmStartConfig.from_job_desc(\n        sagemaker_session.sagemaker_client.describe_hyper_parameter_tuning_job(\n            HyperParameterTuningJobName=child_tuning_job_name\n        )[""WarmStartConfig""]\n    )\n\n    assert child_warm_start_config_response.type == child_tuner.warm_start_config.type\n    assert child_warm_start_config_response.parents == child_tuner.warm_start_config.parents\n\n\ndef test_transfer_learning_tuner(\n    sagemaker_session, kmeans_train_set, kmeans_estimator, hyperparameter_ranges\n):\n    """"""Tests Transfer learning use case with one parent and child job launched with\n        .transfer_learning_tuner() """"""\n\n    parent_tuning_job_name = unique_name_from_base(""km-tran1-parent"", max_length=32)\n    child_tuning_job_name = unique_name_from_base(""km-tran1-child"", max_length=32)\n\n    parent_tuner = _tune(\n        kmeans_estimator,\n        kmeans_train_set,\n        job_name=parent_tuning_job_name,\n        hyperparameter_ranges=hyperparameter_ranges,\n        max_jobs=1,\n        max_parallel_jobs=1,\n    )\n\n    child_tuner = parent_tuner.transfer_learning_tuner()\n    _tune(\n        kmeans_estimator,\n        kmeans_train_set,\n        job_name=child_tuning_job_name,\n        tuner=child_tuner,\n        max_parallel_jobs=1,\n        max_jobs=1,\n    )\n\n    child_warm_start_config_response = WarmStartConfig.from_job_desc(\n        sagemaker_session.sagemaker_client.describe_hyper_parameter_tuning_job(\n            HyperParameterTuningJobName=child_tuning_job_name\n        )[""WarmStartConfig""]\n    )\n\n    assert child_warm_start_config_response.type == child_tuner.warm_start_config.type\n    assert child_warm_start_config_response.parents == child_tuner.warm_start_config.parents\n\n\ndef test_create_transfer_learning_tuner(\n    sagemaker_session, kmeans_train_set, kmeans_estimator, hyperparameter_ranges\n):\n    """"""Tests Transfer learning use case with two parents and child job launched with\n        create_transfer_learning_tuner() """"""\n    parent_tuning_job_name_1 = unique_name_from_base(""km-tran2-parent1"", max_length=32)\n    parent_tuning_job_name_2 = unique_name_from_base(""km-tran2-parent2"", max_length=32)\n    child_tuning_job_name = unique_name_from_base(""km-tran2-child"", max_length=32)\n\n    parent_tuner_1 = _tune(\n        kmeans_estimator,\n        kmeans_train_set,\n        job_name=parent_tuning_job_name_1,\n        hyperparameter_ranges=hyperparameter_ranges,\n        max_parallel_jobs=1,\n        max_jobs=1,\n    )\n\n    parent_tuner_2 = _tune(\n        kmeans_estimator,\n        kmeans_train_set,\n        job_name=parent_tuning_job_name_2,\n        hyperparameter_ranges=hyperparameter_ranges,\n        max_parallel_jobs=1,\n        max_jobs=1,\n    )\n\n    child_tuner = create_transfer_learning_tuner(\n        parent=parent_tuner_1.latest_tuning_job.name,\n        sagemaker_session=sagemaker_session,\n        estimator=kmeans_estimator,\n        additional_parents={parent_tuner_2.latest_tuning_job.name},\n    )\n\n    _tune(kmeans_estimator, kmeans_train_set, job_name=child_tuning_job_name, tuner=child_tuner)\n\n    child_warm_start_config_response = WarmStartConfig.from_job_desc(\n        sagemaker_session.sagemaker_client.describe_hyper_parameter_tuning_job(\n            HyperParameterTuningJobName=child_tuning_job_name\n        )[""WarmStartConfig""]\n    )\n\n    assert child_warm_start_config_response.type == child_tuner.warm_start_config.type\n    assert child_warm_start_config_response.parents == child_tuner.warm_start_config.parents\n\n\ndef test_tuning_kmeans_identical_dataset_algorithm_tuner_from_non_terminal_parent(\n    sagemaker_session, kmeans_train_set, kmeans_estimator, hyperparameter_ranges\n):\n    """"""Tests Identical dataset and algorithm use case with one non terminal parent and child job launched with\n    .identical_dataset_and_algorithm_tuner() """"""\n    parent_tuning_job_name = unique_name_from_base(""km-non-term"", max_length=32)\n    child_tuning_job_name = unique_name_from_base(""km-non-term-child"", max_length=32)\n\n    parent_tuner = _tune(\n        kmeans_estimator,\n        kmeans_train_set,\n        job_name=parent_tuning_job_name,\n        hyperparameter_ranges=hyperparameter_ranges,\n        wait_till_terminal=False,\n        max_parallel_jobs=1,\n        max_jobs=1,\n    )\n\n    child_tuner = parent_tuner.identical_dataset_and_algorithm_tuner()\n    with pytest.raises(ClientError):\n        _tune(\n            kmeans_estimator,\n            kmeans_train_set,\n            job_name=child_tuning_job_name,\n            tuner=child_tuner,\n            max_parallel_jobs=1,\n            max_jobs=1,\n        )\n\n\n@pytest.mark.skipif(\n    tests.integ.test_region() in tests.integ.NO_LDA_REGIONS,\n    reason=""LDA image is not supported in certain regions"",\n)\ndef test_tuning_lda(sagemaker_session, cpu_instance_type):\n    with timeout(minutes=TUNING_DEFAULT_TIMEOUT_MINUTES):\n        data_path = os.path.join(DATA_DIR, ""lda"")\n        data_filename = ""nips-train_1.pbr""\n\n        with open(os.path.join(data_path, data_filename), ""rb"") as f:\n            all_records = read_records(f)\n\n        # all records must be same\n        feature_num = int(all_records[0].features[""values""].float32_tensor.shape[0])\n\n        lda = LDA(\n            role=""SageMakerRole"",\n            train_instance_type=cpu_instance_type,\n            num_topics=10,\n            sagemaker_session=sagemaker_session,\n        )\n\n        record_set = prepare_record_set_from_local_files(\n            data_path, lda.data_location, len(all_records), feature_num, sagemaker_session\n        )\n        test_record_set = prepare_record_set_from_local_files(\n            data_path, lda.data_location, len(all_records), feature_num, sagemaker_session\n        )\n        test_record_set.channel = ""test""\n\n        # specify which hp you want to optimize over\n        hyperparameter_ranges = {\n            ""alpha0"": ContinuousParameter(1, 10),\n            ""num_topics"": IntegerParameter(1, 2),\n        }\n        objective_metric_name = ""test:pwll""\n\n        tuner = HyperparameterTuner(\n            estimator=lda,\n            objective_metric_name=objective_metric_name,\n            hyperparameter_ranges=hyperparameter_ranges,\n            objective_type=""Maximize"",\n            max_jobs=2,\n            max_parallel_jobs=2,\n            early_stopping_type=""Auto"",\n        )\n\n        tuning_job_name = unique_name_from_base(""test-lda"", max_length=32)\n        tuner.fit([record_set, test_record_set], mini_batch_size=1, job_name=tuning_job_name)\n\n        latest_tuning_job_name = tuner.latest_tuning_job.name\n\n        print(""Started hyperparameter tuning job with name:"" + latest_tuning_job_name)\n\n        time.sleep(15)\n        tuner.wait()\n\n    attached_tuner = HyperparameterTuner.attach(\n        tuning_job_name, sagemaker_session=sagemaker_session\n    )\n    assert attached_tuner.early_stopping_type == ""Auto""\n    assert attached_tuner.estimator.alpha0 == 1.0\n    assert attached_tuner.estimator.num_topics == 1\n\n    best_training_job = attached_tuner.best_training_job()\n\n    with timeout_and_delete_endpoint_by_name(best_training_job, sagemaker_session):\n        predictor = tuner.deploy(1, cpu_instance_type)\n        predict_input = np.random.rand(1, feature_num)\n        result = predictor.predict(predict_input)\n\n        assert len(result) == 1\n        for record in result:\n            assert record.label[""topic_mixture""] is not None\n\n\ndef test_stop_tuning_job(sagemaker_session, cpu_instance_type):\n    feature_num = 14\n    train_input = np.random.rand(1000, feature_num)\n\n    rcf = RandomCutForest(\n        role=""SageMakerRole"",\n        train_instance_count=1,\n        train_instance_type=cpu_instance_type,\n        num_trees=50,\n        num_samples_per_tree=20,\n        sagemaker_session=sagemaker_session,\n    )\n\n    records = rcf.record_set(train_input)\n    records.distribution = ""FullyReplicated""\n\n    test_records = rcf.record_set(train_input, channel=""test"")\n    test_records.distribution = ""FullyReplicated""\n\n    hyperparameter_ranges = {\n        ""num_trees"": IntegerParameter(50, 100),\n        ""num_samples_per_tree"": IntegerParameter(1, 2),\n    }\n\n    objective_metric_name = ""test:f1""\n    tuner = HyperparameterTuner(\n        estimator=rcf,\n        objective_metric_name=objective_metric_name,\n        hyperparameter_ranges=hyperparameter_ranges,\n        objective_type=""Maximize"",\n        max_jobs=2,\n        max_parallel_jobs=2,\n    )\n\n    tuning_job_name = unique_name_from_base(""test-randomcutforest"", max_length=32)\n    tuner.fit([records, test_records], tuning_job_name)\n\n    time.sleep(15)\n\n    latest_tuning_job_name = tuner.latest_tuning_job.name\n\n    print(""Attempting to stop {}"".format(latest_tuning_job_name))\n\n    tuner.stop_tuning_job()\n\n    desc = tuner.latest_tuning_job.sagemaker_session.sagemaker_client.describe_hyper_parameter_tuning_job(\n        HyperParameterTuningJobName=latest_tuning_job_name\n    )\n    assert desc[""HyperParameterTuningJobStatus""] == ""Stopping""\n\n\n@pytest.mark.canary_quick\ndef test_tuning_mxnet(sagemaker_session, mxnet_full_version, cpu_instance_type):\n    with timeout(minutes=TUNING_DEFAULT_TIMEOUT_MINUTES):\n        script_path = os.path.join(DATA_DIR, ""mxnet_mnist"", ""mnist.py"")\n        data_path = os.path.join(DATA_DIR, ""mxnet_mnist"")\n\n        estimator = MXNet(\n            entry_point=script_path,\n            role=""SageMakerRole"",\n            py_version=PYTHON_VERSION,\n            train_instance_count=1,\n            train_instance_type=cpu_instance_type,\n            framework_version=mxnet_full_version,\n            sagemaker_session=sagemaker_session,\n        )\n\n        hyperparameter_ranges = {""learning-rate"": ContinuousParameter(0.01, 0.2)}\n        objective_metric_name = ""Validation-accuracy""\n        metric_definitions = [\n            {""Name"": ""Validation-accuracy"", ""Regex"": ""Validation-accuracy=([0-9\\\\.]+)""}\n        ]\n        tuner = HyperparameterTuner(\n            estimator,\n            objective_metric_name,\n            hyperparameter_ranges,\n            metric_definitions,\n            max_jobs=4,\n            max_parallel_jobs=2,\n        )\n\n        train_input = estimator.sagemaker_session.upload_data(\n            path=os.path.join(data_path, ""train""), key_prefix=""integ-test-data/mxnet_mnist/train""\n        )\n        test_input = estimator.sagemaker_session.upload_data(\n            path=os.path.join(data_path, ""test""), key_prefix=""integ-test-data/mxnet_mnist/test""\n        )\n\n        tuning_job_name = unique_name_from_base(""tune-mxnet"", max_length=32)\n        tuner.fit({""train"": train_input, ""test"": test_input}, job_name=tuning_job_name)\n\n        print(""Started hyperparameter tuning job with name:"" + tuning_job_name)\n\n        time.sleep(15)\n        tuner.wait()\n\n    best_training_job = tuner.best_training_job()\n    with timeout_and_delete_endpoint_by_name(best_training_job, sagemaker_session):\n        predictor = tuner.deploy(1, cpu_instance_type)\n        data = np.zeros(shape=(1, 1, 28, 28))\n        predictor.predict(data)\n\n\n@pytest.mark.canary_quick\ndef test_tuning_tf_script_mode(sagemaker_session, cpu_instance_type, tf_full_version, py_version):\n    resource_path = os.path.join(DATA_DIR, ""tensorflow_mnist"")\n    script_path = os.path.join(resource_path, ""mnist.py"")\n\n    estimator = TensorFlow(\n        entry_point=script_path,\n        role=""SageMakerRole"",\n        train_instance_count=1,\n        train_instance_type=cpu_instance_type,\n        script_mode=True,\n        sagemaker_session=sagemaker_session,\n        py_version=py_version,\n        framework_version=tf_full_version,\n    )\n\n    hyperparameter_ranges = {""epochs"": IntegerParameter(1, 2)}\n    objective_metric_name = ""accuracy""\n    metric_definitions = [{""Name"": objective_metric_name, ""Regex"": ""accuracy = ([0-9\\\\.]+)""}]\n\n    tuner = HyperparameterTuner(\n        estimator,\n        objective_metric_name,\n        hyperparameter_ranges,\n        metric_definitions,\n        max_jobs=2,\n        max_parallel_jobs=2,\n    )\n\n    with timeout(minutes=TUNING_DEFAULT_TIMEOUT_MINUTES):\n        inputs = estimator.sagemaker_session.upload_data(\n            path=os.path.join(resource_path, ""data""), key_prefix=""scriptmode/mnist""\n        )\n\n        tuning_job_name = unique_name_from_base(""tune-tf-script-mode"", max_length=32)\n        tuner.fit(inputs, job_name=tuning_job_name)\n\n        print(""Started hyperparameter tuning job with name: "" + tuning_job_name)\n\n        time.sleep(15)\n        tuner.wait()\n\n\n@pytest.mark.canary_quick\n@pytest.mark.skipif(PYTHON_VERSION != ""py2"", reason=""TensorFlow image supports only python 2."")\ndef test_tuning_tf(sagemaker_session, cpu_instance_type):\n    with timeout(minutes=TUNING_DEFAULT_TIMEOUT_MINUTES):\n        script_path = os.path.join(DATA_DIR, ""iris"", ""iris-dnn-classifier.py"")\n\n        estimator = TensorFlow(\n            entry_point=script_path,\n            role=""SageMakerRole"",\n            training_steps=1,\n            evaluation_steps=1,\n            hyperparameters={""input_tensor_name"": ""inputs""},\n            train_instance_count=1,\n            train_instance_type=cpu_instance_type,\n            sagemaker_session=sagemaker_session,\n        )\n\n        inputs = sagemaker_session.upload_data(path=DATA_PATH, key_prefix=""integ-test-data/tf_iris"")\n        hyperparameter_ranges = {""learning_rate"": ContinuousParameter(0.05, 0.2)}\n\n        objective_metric_name = ""loss""\n        metric_definitions = [{""Name"": ""loss"", ""Regex"": ""loss = ([0-9\\\\.]+)""}]\n\n        tuner = HyperparameterTuner(\n            estimator,\n            objective_metric_name,\n            hyperparameter_ranges,\n            metric_definitions,\n            objective_type=""Minimize"",\n            max_jobs=2,\n            max_parallel_jobs=2,\n        )\n\n        tuning_job_name = unique_name_from_base(""tune-tf"", max_length=32)\n        tuner.fit(inputs, job_name=tuning_job_name)\n\n        print(""Started hyperparameter tuning job with name:"" + tuning_job_name)\n\n        time.sleep(15)\n        tuner.wait()\n\n    best_training_job = tuner.best_training_job()\n    with timeout_and_delete_endpoint_by_name(best_training_job, sagemaker_session):\n        predictor = tuner.deploy(1, cpu_instance_type)\n\n        features = [6.4, 3.2, 4.5, 1.5]\n        dict_result = predictor.predict({""inputs"": features})\n        print(""predict result: {}"".format(dict_result))\n        list_result = predictor.predict(features)\n        print(""predict result: {}"".format(list_result))\n\n        assert dict_result == list_result\n\n\n@pytest.mark.skipif(PYTHON_VERSION != ""py2"", reason=""TensorFlow image supports only python 2."")\ndef test_tuning_tf_vpc_multi(sagemaker_session, cpu_instance_type):\n    """"""Test Tensorflow multi-instance using the same VpcConfig for training and inference""""""\n    instance_type = cpu_instance_type\n    instance_count = 2\n\n    script_path = os.path.join(DATA_DIR, ""iris"", ""iris-dnn-classifier.py"")\n\n    ec2_client = sagemaker_session.boto_session.client(""ec2"")\n    subnet_ids, security_group_id = vpc_test_utils.get_or_create_vpc_resources(ec2_client)\n    vpc_test_utils.setup_security_group_for_encryption(ec2_client, security_group_id)\n\n    estimator = TensorFlow(\n        entry_point=script_path,\n        role=""SageMakerRole"",\n        training_steps=1,\n        evaluation_steps=1,\n        hyperparameters={""input_tensor_name"": ""inputs""},\n        train_instance_count=instance_count,\n        train_instance_type=instance_type,\n        sagemaker_session=sagemaker_session,\n        base_job_name=""test-vpc-tf"",\n        subnets=subnet_ids,\n        security_group_ids=[security_group_id],\n        encrypt_inter_container_traffic=True,\n    )\n\n    inputs = sagemaker_session.upload_data(path=DATA_PATH, key_prefix=""integ-test-data/tf_iris"")\n    hyperparameter_ranges = {""learning_rate"": ContinuousParameter(0.05, 0.2)}\n\n    objective_metric_name = ""loss""\n    metric_definitions = [{""Name"": ""loss"", ""Regex"": ""loss = ([0-9\\\\.]+)""}]\n\n    tuner = HyperparameterTuner(\n        estimator,\n        objective_metric_name,\n        hyperparameter_ranges,\n        metric_definitions,\n        objective_type=""Minimize"",\n        max_jobs=2,\n        max_parallel_jobs=2,\n    )\n\n    tuning_job_name = unique_name_from_base(""tune-tf"", max_length=32)\n    with timeout(minutes=TUNING_DEFAULT_TIMEOUT_MINUTES):\n        tuner.fit(inputs, job_name=tuning_job_name)\n\n        print(""Started hyperparameter tuning job with name:"" + tuning_job_name)\n\n        time.sleep(15)\n        tuner.wait()\n\n\n@pytest.mark.canary_quick\ndef test_tuning_chainer(sagemaker_session, cpu_instance_type):\n    with timeout(minutes=TUNING_DEFAULT_TIMEOUT_MINUTES):\n        script_path = os.path.join(DATA_DIR, ""chainer_mnist"", ""mnist.py"")\n        data_path = os.path.join(DATA_DIR, ""chainer_mnist"")\n\n        estimator = Chainer(\n            entry_point=script_path,\n            role=""SageMakerRole"",\n            py_version=PYTHON_VERSION,\n            train_instance_count=1,\n            train_instance_type=cpu_instance_type,\n            sagemaker_session=sagemaker_session,\n            hyperparameters={""epochs"": 1},\n        )\n\n        train_input = estimator.sagemaker_session.upload_data(\n            path=os.path.join(data_path, ""train""), key_prefix=""integ-test-data/chainer_mnist/train""\n        )\n        test_input = estimator.sagemaker_session.upload_data(\n            path=os.path.join(data_path, ""test""), key_prefix=""integ-test-data/chainer_mnist/test""\n        )\n\n        hyperparameter_ranges = {""alpha"": ContinuousParameter(0.001, 0.005)}\n\n        objective_metric_name = ""Validation-accuracy""\n        metric_definitions = [\n            {\n                ""Name"": ""Validation-accuracy"",\n                ""Regex"": r""\\[J1\\s+\\d\\.\\d+\\s+\\d\\.\\d+\\s+\\d\\.\\d+\\s+(\\d\\.\\d+)"",\n            }\n        ]\n\n        tuner = HyperparameterTuner(\n            estimator,\n            objective_metric_name,\n            hyperparameter_ranges,\n            metric_definitions,\n            max_jobs=2,\n            max_parallel_jobs=2,\n        )\n\n        tuning_job_name = unique_name_from_base(""chainer"", max_length=32)\n        tuner.fit({""train"": train_input, ""test"": test_input}, job_name=tuning_job_name)\n\n        print(""Started hyperparameter tuning job with name:"" + tuning_job_name)\n\n        time.sleep(15)\n        tuner.wait()\n\n    best_training_job = tuner.best_training_job()\n    with timeout_and_delete_endpoint_by_name(best_training_job, sagemaker_session):\n        predictor = tuner.deploy(1, cpu_instance_type)\n\n        batch_size = 100\n        data = np.zeros((batch_size, 784), dtype=""float32"")\n        output = predictor.predict(data)\n        assert len(output) == batch_size\n\n        data = np.zeros((batch_size, 1, 28, 28), dtype=""float32"")\n        output = predictor.predict(data)\n        assert len(output) == batch_size\n\n        data = np.zeros((batch_size, 28, 28), dtype=""float32"")\n        output = predictor.predict(data)\n        assert len(output) == batch_size\n\n\n@pytest.mark.canary_quick\n@pytest.mark.skip(\n    reason=""This test has always failed, but the failure was masked by a bug. ""\n    ""This test should be fixed. Details in https://github.com/aws/sagemaker-python-sdk/pull/968""\n)\ndef test_attach_tuning_pytorch(sagemaker_session, cpu_instance_type):\n    mnist_dir = os.path.join(DATA_DIR, ""pytorch_mnist"")\n    mnist_script = os.path.join(mnist_dir, ""mnist.py"")\n\n    estimator = PyTorch(\n        entry_point=mnist_script,\n        role=""SageMakerRole"",\n        train_instance_count=1,\n        py_version=PYTHON_VERSION,\n        train_instance_type=cpu_instance_type,\n        sagemaker_session=sagemaker_session,\n    )\n\n    with timeout(minutes=TUNING_DEFAULT_TIMEOUT_MINUTES):\n        objective_metric_name = ""evaluation-accuracy""\n        metric_definitions = [\n            {""Name"": ""evaluation-accuracy"", ""Regex"": r""Overall test accuracy: (\\d+)""}\n        ]\n        hyperparameter_ranges = {""batch-size"": IntegerParameter(50, 100)}\n\n        tuner = HyperparameterTuner(\n            estimator,\n            objective_metric_name,\n            hyperparameter_ranges,\n            metric_definitions,\n            max_jobs=2,\n            max_parallel_jobs=2,\n            early_stopping_type=""Auto"",\n        )\n\n        training_data = estimator.sagemaker_session.upload_data(\n            path=os.path.join(mnist_dir, ""training""),\n            key_prefix=""integ-test-data/pytorch_mnist/training"",\n        )\n\n        tuning_job_name = unique_name_from_base(""pytorch"", max_length=32)\n        tuner.fit({""training"": training_data}, job_name=tuning_job_name)\n\n        print(""Started hyperparameter tuning job with name:"" + tuning_job_name)\n\n        time.sleep(15)\n        tuner.wait()\n\n    endpoint_name = tuning_job_name\n    model_name = ""model-name-1""\n    attached_tuner = HyperparameterTuner.attach(\n        tuning_job_name, sagemaker_session=sagemaker_session\n    )\n    assert attached_tuner.early_stopping_type == ""Auto""\n\n    with timeout_and_delete_endpoint_by_name(endpoint_name, sagemaker_session):\n        predictor = attached_tuner.deploy(\n            1, cpu_instance_type, endpoint_name=endpoint_name, model_name=model_name\n        )\n    best_training_job = tuner.best_training_job()\n    with timeout_and_delete_endpoint_by_name(best_training_job, sagemaker_session):\n        predictor = attached_tuner.deploy(1, cpu_instance_type)\n        data = np.zeros(shape=(1, 1, 28, 28), dtype=np.float32)\n        predictor.predict(data)\n\n        batch_size = 100\n        data = np.random.rand(batch_size, 1, 28, 28).astype(np.float32)\n        output = predictor.predict(data)\n\n        assert output.shape == (batch_size, 10)\n        _assert_model_name_match(sagemaker_session.sagemaker_client, endpoint_name, model_name)\n\n\n@pytest.mark.canary_quick\ndef test_tuning_byo_estimator(sagemaker_session, cpu_instance_type):\n    """"""Use Factorization Machines algorithm as an example here.\n\n    First we need to prepare data for training. We take standard data set, convert it to the\n    format that the algorithm can process and upload it to S3.\n    Then we create the Estimator and set hyperparamets as required by the algorithm.\n    Next, we can call fit() with path to the S3.\n    Later the trained model is deployed and prediction is called against the endpoint.\n    Default predictor is updated with json serializer and deserializer.\n    """"""\n    image_name = get_image_uri(sagemaker_session.boto_session.region_name, ""factorization-machines"")\n    training_data_path = os.path.join(DATA_DIR, ""dummy_tensor"")\n\n    with timeout(minutes=TUNING_DEFAULT_TIMEOUT_MINUTES):\n        data_path = os.path.join(DATA_DIR, ""one_p_mnist"", ""mnist.pkl.gz"")\n        pickle_args = {} if sys.version_info.major == 2 else {""encoding"": ""latin1""}\n\n        with gzip.open(data_path, ""rb"") as f:\n            train_set, _, _ = pickle.load(f, **pickle_args)\n\n        prefix = ""test_byo_estimator""\n        key = ""recordio-pb-data""\n        s3_train_data = sagemaker_session.upload_data(\n            path=training_data_path, key_prefix=os.path.join(prefix, ""train"", key)\n        )\n\n        estimator = Estimator(\n            image_name=image_name,\n            role=""SageMakerRole"",\n            train_instance_count=1,\n            train_instance_type=cpu_instance_type,\n            sagemaker_session=sagemaker_session,\n        )\n\n        estimator.set_hyperparameters(\n            num_factors=10, feature_dim=784, mini_batch_size=100, predictor_type=""binary_classifier""\n        )\n\n        hyperparameter_ranges = {""mini_batch_size"": IntegerParameter(100, 200)}\n\n        tuner = HyperparameterTuner(\n            estimator=estimator,\n            objective_metric_name=""test:binary_classification_accuracy"",\n            hyperparameter_ranges=hyperparameter_ranges,\n            max_jobs=2,\n            max_parallel_jobs=2,\n        )\n\n        tuner.fit(\n            {""train"": s3_train_data, ""test"": s3_train_data},\n            include_cls_metadata=False,\n            job_name=unique_name_from_base(""byo"", 32),\n        )\n\n        print(""Started hyperparameter tuning job with name:"" + tuner.latest_tuning_job.name)\n\n        time.sleep(15)\n        tuner.wait()\n\n    best_training_job = tuner.best_training_job()\n    with timeout_and_delete_endpoint_by_name(best_training_job, sagemaker_session):\n        predictor = tuner.deploy(1, cpu_instance_type, endpoint_name=best_training_job)\n        predictor.serializer = _fm_serializer\n        predictor.content_type = ""application/json""\n        predictor.deserializer = json_deserializer\n\n        result = predictor.predict(train_set[0][:10])\n\n        assert len(result[""predictions""]) == 10\n        for prediction in result[""predictions""]:\n            assert prediction[""score""] is not None\n\n\n# Serializer for the Factorization Machines predictor (for BYO example)\ndef _fm_serializer(data):\n    js = {""instances"": []}\n    for row in data:\n        js[""instances""].append({""features"": row.tolist()})\n    return json.dumps(js)\n\n\ndef _assert_model_name_match(sagemaker_client, endpoint_config_name, model_name):\n    endpoint_config_description = sagemaker_client.describe_endpoint_config(\n        EndpointConfigName=endpoint_config_name\n    )\n    assert model_name == endpoint_config_description[""ProductionVariants""][0][""ModelName""]\n'"
tests/integ/test_tuner_multi_algo.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport gzip\nimport json\nimport os\nimport pickle\nimport sys\n\nimport pytest\nfrom sagemaker import utils\nfrom sagemaker.amazon.amazon_estimator import get_image_uri\nfrom sagemaker.analytics import HyperparameterTuningJobAnalytics\nfrom sagemaker.content_types import CONTENT_TYPE_JSON\nfrom sagemaker.estimator import Estimator\nfrom sagemaker.predictor import json_deserializer\nfrom sagemaker.tuner import ContinuousParameter, IntegerParameter, HyperparameterTuner\n\nfrom tests.integ import DATA_DIR, TUNING_DEFAULT_TIMEOUT_MINUTES\nfrom tests.integ.timeout import timeout, timeout_and_delete_endpoint_by_name\n\nBASE_TUNING_JOB_NAME = ""multi-algo-pysdk""\n\nDATA_PATH = os.path.join(DATA_DIR, ""one_p_mnist"", ""mnist.pkl.gz"")\n\nEXECUTION_ROLE = ""SageMakerRole""\n\nSTRATEGY = ""Bayesian""\nOBJECTIVE_TYPE = ""Minimize""\n\nTAGS = [{""Key"": ""pysdk-test"", ""Value"": ""multi-algo-tuner""}]\n\nESTIMATOR_FM = ""fm-one""\nESTIMATOR_KNN = ""knn-two""\n\n# TODO: change to use one of the new standard metrics for 1P algorithm\nOBJECTIVE_METRIC_NAME_FM = ""test:rmse""\nOBJECTIVE_METRIC_NAME_KNN = ""test:mse""\n\nHYPER_PARAMETER_RANGES_FM = {\n    ""factors_wd"": ContinuousParameter(1, 30),\n    ""factors_lr"": ContinuousParameter(40, 50),\n}\nHYPER_PARAMETER_RANGES_KNN = {\n    ""k"": IntegerParameter(3, 400),\n    ""sample_size"": IntegerParameter(40, 550),\n}\n\nMAX_JOBS = 2\nMAX_PARALLEL_JOBS = 2\n\n\n@pytest.fixture(scope=""module"")\ndef data_set():\n    pickle_args = {} if sys.version_info.major == 2 else {""encoding"": ""latin1""}\n    with gzip.open(DATA_PATH, ""rb"") as f:\n        data_set, _, _ = pickle.load(f, **pickle_args)\n    return data_set\n\n\n@pytest.fixture(scope=""function"")\ndef estimator_fm(sagemaker_session, cpu_instance_type):\n    fm_image = get_image_uri(\n        sagemaker_session.boto_session.region_name, ""factorization-machines"", repo_version=""1""\n    )\n\n    estimator = Estimator(\n        image_name=fm_image,\n        role=EXECUTION_ROLE,\n        train_instance_count=1,\n        train_instance_type=cpu_instance_type,\n        sagemaker_session=sagemaker_session,\n    )\n\n    estimator.set_hyperparameters(\n        num_factors=10, feature_dim=784, mini_batch_size=100, predictor_type=""regressor""\n    )\n\n    return estimator\n\n\n@pytest.fixture(scope=""function"")\ndef estimator_knn(sagemaker_session, cpu_instance_type):\n    knn_image = get_image_uri(sagemaker_session.boto_session.region_name, ""knn"", repo_version=""1"")\n\n    estimator = Estimator(\n        image_name=knn_image,\n        role=EXECUTION_ROLE,\n        train_instance_count=1,\n        train_instance_type=cpu_instance_type,\n        sagemaker_session=sagemaker_session,\n    )\n\n    estimator.set_hyperparameters(\n        k=10, sample_size=500, feature_dim=784, mini_batch_size=100, predictor_type=""regressor""\n    )\n    return estimator\n\n\n@pytest.mark.canary_quick\ndef test_multi_estimator_tuning(\n    sagemaker_session, estimator_fm, estimator_knn, data_set, cpu_instance_type\n):\n    tuner = HyperparameterTuner.create(\n        base_tuning_job_name=BASE_TUNING_JOB_NAME,\n        estimator_dict={ESTIMATOR_FM: estimator_fm, ESTIMATOR_KNN: estimator_knn},\n        objective_metric_name_dict={\n            ESTIMATOR_FM: OBJECTIVE_METRIC_NAME_FM,\n            ESTIMATOR_KNN: OBJECTIVE_METRIC_NAME_KNN,\n        },\n        hyperparameter_ranges_dict={\n            ESTIMATOR_FM: HYPER_PARAMETER_RANGES_FM,\n            ESTIMATOR_KNN: HYPER_PARAMETER_RANGES_KNN,\n        },\n        strategy=STRATEGY,\n        objective_type=OBJECTIVE_TYPE,\n        max_jobs=MAX_JOBS,\n        max_parallel_jobs=MAX_PARALLEL_JOBS,\n        tags=TAGS,\n    )\n\n    _fit_tuner(sagemaker_session, tuner)\n\n    _retrieve_analytics(sagemaker_session, tuner.latest_tuning_job.name)\n\n    tuner_attached = _attach_tuner(sagemaker_session, tuner.latest_tuning_job.name)\n\n    _deploy_and_predict(sagemaker_session, tuner_attached, data_set, cpu_instance_type)\n\n\ndef _fit_tuner(sagemaker_session, tuner):\n    training_inputs = _create_training_inputs(sagemaker_session)\n    job_name = utils.unique_name_from_base(""test-multi-algo-tuning"", max_length=32)\n\n    with timeout(minutes=TUNING_DEFAULT_TIMEOUT_MINUTES):\n        tuner.fit(\n            inputs={ESTIMATOR_FM: training_inputs, ESTIMATOR_KNN: training_inputs},\n            include_cls_metadata={},\n            job_name=job_name,\n        )\n        tuner.wait()\n\n\ndef _retrieve_analytics(sagemaker_session, tuning_job_name):\n    tuner_analytics = HyperparameterTuningJobAnalytics(\n        hyperparameter_tuning_job_name=tuning_job_name, sagemaker_session=sagemaker_session\n    )\n    _verify_analytics_dataframe(tuner_analytics)\n    _verify_analytics_tuning_ranges(tuner_analytics)\n\n\ndef _verify_analytics_dataframe(tuner_analytics):\n    df = tuner_analytics.dataframe()\n    assert len(df) == MAX_JOBS\n\n\ndef _verify_analytics_tuning_ranges(tuner_analytics):\n    analytics_tuning_ranges = tuner_analytics.tuning_ranges\n    assert len(analytics_tuning_ranges) == 2\n\n    expected_tuning_ranges_fm = {\n        key: value.as_tuning_range(key) for key, value in HYPER_PARAMETER_RANGES_FM.items()\n    }\n    assert expected_tuning_ranges_fm == analytics_tuning_ranges[ESTIMATOR_FM]\n\n    expected_tuning_ranges_knn = {\n        key: value.as_tuning_range(key) for key, value in HYPER_PARAMETER_RANGES_KNN.items()\n    }\n    assert expected_tuning_ranges_knn == analytics_tuning_ranges[ESTIMATOR_KNN]\n\n\ndef _attach_tuner(sagemaker_session, tuning_job_name):\n    print(""Attaching hyperparameter tuning job {} to a new tuner instance"".format(tuning_job_name))\n    return HyperparameterTuner.attach(\n        tuning_job_name,\n        sagemaker_session=sagemaker_session,\n        estimator_cls={\n            ESTIMATOR_FM: ""sagemaker.estimator.Estimator"",\n            ESTIMATOR_KNN: ""sagemaker.estimator.Estimator"",\n        },\n    )\n\n\ndef _deploy_and_predict(sagemaker_session, tuner, data_set, cpu_instance_type):\n    best_training_job = tuner.best_training_job()\n    with timeout_and_delete_endpoint_by_name(best_training_job, sagemaker_session):\n        print(\n            ""Deploying best model of hyperparameter tuning job {}: {}"".format(\n                tuner.latest_tuning_job.name, best_training_job\n            )\n        )\n        predictor = tuner.deploy(1, cpu_instance_type, endpoint_name=best_training_job)\n\n        print(""Making prediction using the deployed model"")\n        data = data_set[0][:10]\n        result = _make_prediction(predictor, data)\n\n        assert len(result[""predictions""]) == len(data)\n        for prediction in result[""predictions""]:\n            assert prediction is not None\n\n\ndef _create_training_inputs(sagemaker_session):\n    training_data_path = os.path.join(DATA_DIR, ""dummy_tensor"")\n\n    prefix = ""multi-algo""\n    key = ""recordio-pb-data""\n\n    s3_train_data = sagemaker_session.upload_data(\n        path=training_data_path, key_prefix=os.path.join(prefix, ""train"", key)\n    )\n\n    return {""train"": s3_train_data, ""test"": s3_train_data}\n\n\ndef _make_prediction(predictor, data):\n    predictor.serializer = _prediction_data_serializer\n    predictor.content_type = CONTENT_TYPE_JSON\n    predictor.deserializer = json_deserializer\n    return predictor.predict(data)\n\n\ndef _prediction_data_serializer(data):\n    js = {""instances"": []}\n    for row in data:\n        js[""instances""].append({""features"": row.tolist()})\n    return json.dumps(js)\n'"
tests/integ/timeout.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nfrom contextlib import contextmanager\nimport logging\nfrom time import sleep\n\nfrom awslogs.core import AWSLogs\nfrom botocore.exceptions import ClientError\nimport stopit\n\nfrom sagemaker import RealTimePredictor\nfrom tests.integ.retry import retries\n\nLOGGER = logging.getLogger(""timeout"")\n\n\n@contextmanager\ndef timeout(seconds=0, minutes=0, hours=0):\n    """"""\n    Add a signal-based timeout to any block of code.\n    If multiple time units are specified, they will be added together to determine time limit.\n    Usage:\n    with timeout(seconds=5):\n        my_slow_function(...)\n    Args:\n        - seconds: The time limit, in seconds.\n        - minutes: The time limit, in minutes.\n        - hours: The time limit, in hours.\n    """"""\n\n    limit = seconds + 60 * minutes + 3600 * hours\n\n    with stopit.ThreadingTimeout(limit, swallow_exc=False) as t:\n        yield [t]\n\n\n@contextmanager\ndef timeout_and_delete_endpoint_by_name(\n    endpoint_name,\n    sagemaker_session,\n    seconds=0,\n    minutes=45,\n    hours=0,\n    sleep_between_cleanup_attempts=10,\n):\n    limit = seconds + 60 * minutes + 3600 * hours\n\n    with stopit.ThreadingTimeout(limit, swallow_exc=False) as t:\n        no_errors = False\n        try:\n            yield [t]\n            no_errors = True\n        finally:\n            attempts = 3\n\n            while attempts > 0:\n                attempts -= 1\n                try:\n                    _delete_schedules_associated_with_endpoint(\n                        sagemaker_session=sagemaker_session, endpoint_name=endpoint_name\n                    )\n                    sagemaker_session.delete_endpoint(endpoint_name)\n                    LOGGER.info(""deleted endpoint {}"".format(endpoint_name))\n\n                    _show_logs(endpoint_name, ""Endpoints"", sagemaker_session)\n                    if no_errors:\n                        _cleanup_logs(endpoint_name, ""Endpoints"", sagemaker_session)\n                    break\n                except ClientError as ce:\n                    if ce.response[""Error""][""Code""] == ""ValidationException"":\n                        # avoids the inner exception to be overwritten\n                        pass\n                # trying to delete the resource again in 10 seconds\n                sleep(sleep_between_cleanup_attempts)\n\n\n@contextmanager\ndef timeout_and_delete_model_with_transformer(\n    transformer, sagemaker_session, seconds=0, minutes=0, hours=0, sleep_between_cleanup_attempts=10\n):\n    limit = seconds + 60 * minutes + 3600 * hours\n\n    with stopit.ThreadingTimeout(limit, swallow_exc=False) as t:\n        no_errors = False\n        try:\n            yield [t]\n            no_errors = True\n        finally:\n            attempts = 3\n\n            while attempts > 0:\n                attempts -= 1\n                try:\n                    transformer.delete_model()\n                    LOGGER.info(""deleted SageMaker model {}"".format(transformer.model_name))\n\n                    _show_logs(transformer.model_name, ""Models"", sagemaker_session)\n                    if no_errors:\n                        _cleanup_logs(transformer.model_name, ""Models"", sagemaker_session)\n                    break\n                except ClientError as ce:\n                    if ce.response[""Error""][""Code""] == ""ValidationException"":\n                        pass\n                sleep(sleep_between_cleanup_attempts)\n\n\ndef _delete_schedules_associated_with_endpoint(sagemaker_session, endpoint_name):\n    """"""Deletes schedules associated with a given endpoint. Per latest validation, ensures the\n    schedule is stopped and no executions are running, before deleting (otherwise latest\n    server-side validations will prevent deletes).\n\n    Args:\n        sagemaker_session (sagemaker.session.Session): A SageMaker Session\n            object, used for SageMaker interactions (default: None). If not\n            specified, one is created using the default AWS configuration\n            chain.\n        endpoint_name (str): The name of the endpoint to delete schedules from.\n\n    """"""\n    predictor = RealTimePredictor(endpoint=endpoint_name, sagemaker_session=sagemaker_session)\n    monitors = predictor.list_monitors()\n    for monitor in monitors:\n        try:\n            monitor._wait_for_schedule_changes_to_apply()\n            # Stop the schedules to prevent new executions from triggering.\n            monitor.stop_monitoring_schedule()\n            executions = monitor.list_executions()\n            for execution in executions:\n                execution.stop()\n            # Wait for all executions to completely stop.\n            # Schedules can\'t be deleted with running executions.\n            for execution in executions:\n                for _ in retries(60, ""Waiting for executions to stop"", seconds_to_sleep=5):\n                    status = execution.describe()[""ProcessingJobStatus""]\n                    if status == ""Stopped"":\n                        break\n            # Delete schedules.\n            monitor.delete_monitoring_schedule()\n        except Exception as e:\n            LOGGER.warning(\n                ""Failed to delete monitor {}"".format(monitor.monitoring_schedule_name), e\n            )\n\n\ndef _show_logs(resource_name, resource_type, sagemaker_session):\n    log_group = ""/aws/sagemaker/{}/{}"".format(resource_type, resource_name)\n    try:\n        # print out logs before deletion for debuggability\n        LOGGER.info(""cloudwatch logs for log group {}:"".format(log_group))\n        logs = AWSLogs(\n            log_group_name=log_group,\n            log_stream_name=""ALL"",\n            start=""1d"",\n            aws_region=sagemaker_session.boto_session.region_name,\n        )\n        logs.list_logs()\n    except Exception:\n        LOGGER.exception(\n            ""Failure occurred while listing cloudwatch log group %s. Swallowing exception but printing ""\n            ""stacktrace for debugging."",\n            log_group,\n        )\n\n\ndef _cleanup_logs(resource_name, resource_type, sagemaker_session):\n    log_group = ""/aws/sagemaker/{}/{}"".format(resource_type, resource_name)\n    try:\n        # print out logs before deletion for debuggability\n        LOGGER.info(""deleting cloudwatch log group {}:"".format(log_group))\n        cwl_client = sagemaker_session.boto_session.client(""logs"")\n        cwl_client.delete_log_group(logGroupName=log_group)\n        LOGGER.info(""deleted cloudwatch log group: {}"".format(log_group))\n    except Exception:\n        LOGGER.exception(\n            ""Failure occurred while cleaning up cloudwatch log group %s. ""\n            ""Swallowing exception but printing stacktrace for debugging."",\n            log_group,\n        )\n'"
tests/integ/vpc_test_utils.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport os\nimport tempfile\n\nimport tests.integ.lock as lock\n\nVPC_NAME = ""sagemaker-python-sdk-test-vpc""\nLOCK_PATH = os.path.join(tempfile.gettempdir(), ""sagemaker_test_vpc_lock"")\nLOCK_PATH_EFS = os.path.join(tempfile.gettempdir(), ""sagemaker_efs_fsx_vpc_lock"")\n\n\ndef _get_subnet_ids_by_name(ec2_client, name):\n    desc = ec2_client.describe_subnets(Filters=[{""Name"": ""tag-value"", ""Values"": [name]}])\n    if len(desc[""Subnets""]) == 0:\n        return None\n    else:\n        return [subnet[""SubnetId""] for subnet in desc[""Subnets""]]\n\n\ndef _get_security_id_by_name(ec2_client, name):\n    desc = ec2_client.describe_security_groups(Filters=[{""Name"": ""tag-value"", ""Values"": [name]}])\n    if len(desc[""SecurityGroups""]) == 0:\n        return None\n    else:\n        return desc[""SecurityGroups""][0][""GroupId""]\n\n\ndef _security_group_ids_by_vpc_id(sagemaker_session, vpc_id):\n    ec2_resource = sagemaker_session.boto_session.resource(""ec2"")\n    security_group_ids = []\n    vpc = ec2_resource.Vpc(vpc_id)\n    for sg in vpc.security_groups.all():\n        security_group_ids.append(sg.id)\n    return security_group_ids\n\n\ndef _vpc_exists(ec2_client, name):\n    desc = ec2_client.describe_vpcs(Filters=[{""Name"": ""tag-value"", ""Values"": [name]}])\n    return len(desc[""Vpcs""]) > 0\n\n\ndef _vpc_id_by_name(ec2_client, name):\n    desc = ec2_client.describe_vpcs(Filters=[{""Name"": ""tag-value"", ""Values"": [name]}])\n    vpc_id = desc[""Vpcs""][0][""VpcId""]\n    return vpc_id\n\n\ndef _route_table_id(ec2_client, vpc_id):\n    desc = ec2_client.describe_route_tables(Filters=[{""Name"": ""vpc-id"", ""Values"": [vpc_id]}])\n    return desc[""RouteTables""][0][""RouteTableId""]\n\n\ndef check_or_create_vpc_resources_efs_fsx(sagemaker_session, name=VPC_NAME):\n    # use lock to prevent race condition when tests are running concurrently\n    with lock.lock(LOCK_PATH_EFS):\n        ec2_client = sagemaker_session.boto_session.client(""ec2"")\n\n        if _vpc_exists(ec2_client, name):\n            vpc_id = _vpc_id_by_name(ec2_client, name)\n            return (\n                _get_subnet_ids_by_name(ec2_client, name),\n                _security_group_ids_by_vpc_id(sagemaker_session, vpc_id),\n            )\n        else:\n            return _create_vpc_with_name_efs_fsx(ec2_client, name)\n\n\ndef _create_vpc_with_name_efs_fsx(ec2_client, name):\n    vpc_id, [subnet_id_a, subnet_id_b], security_group_id = _create_vpc_resources(ec2_client, name)\n    ec2_client.modify_vpc_attribute(EnableDnsHostnames={""Value"": True}, VpcId=vpc_id)\n\n    ig = ec2_client.create_internet_gateway()\n    internet_gateway_id = ig[""InternetGateway""][""InternetGatewayId""]\n    ec2_client.attach_internet_gateway(InternetGatewayId=internet_gateway_id, VpcId=vpc_id)\n\n    route_table_id = _route_table_id(ec2_client, vpc_id)\n    ec2_client.create_route(\n        DestinationCidrBlock=""0.0.0.0/0"", GatewayId=internet_gateway_id, RouteTableId=route_table_id\n    )\n    ec2_client.associate_route_table(RouteTableId=route_table_id, SubnetId=subnet_id_a)\n    ec2_client.associate_route_table(RouteTableId=route_table_id, SubnetId=subnet_id_b)\n\n    ec2_client.authorize_security_group_ingress(\n        GroupId=security_group_id,\n        IpPermissions=[\n            {\n                ""IpProtocol"": ""tcp"",\n                ""FromPort"": 988,\n                ""ToPort"": 988,\n                ""UserIdGroupPairs"": [{""GroupId"": security_group_id}],\n            },\n            {\n                ""IpProtocol"": ""tcp"",\n                ""FromPort"": 2049,\n                ""ToPort"": 2049,\n                ""UserIdGroupPairs"": [{""GroupId"": security_group_id}],\n            },\n            {\n                ""IpProtocol"": ""tcp"",\n                ""FromPort"": 22,\n                ""ToPort"": 22,\n                ""IpRanges"": [{""CidrIp"": ""0.0.0.0/0"", ""Description"": ""For SSH to EC2""}],\n            },\n        ],\n    )\n\n    return [subnet_id_a], [security_group_id]\n\n\ndef _create_vpc_resources(ec2_client, name):\n    vpc_id = ec2_client.create_vpc(CidrBlock=""10.0.0.0/16"")[""Vpc""][""VpcId""]\n    ec2_client.create_tags(Resources=[vpc_id], Tags=[{""Key"": ""Name"", ""Value"": name}])\n\n    availability_zone_name = ec2_client.describe_availability_zones()[""AvailabilityZones""][0][\n        ""ZoneName""\n    ]\n\n    subnet_id_a = ec2_client.create_subnet(\n        CidrBlock=""10.0.0.0/24"", VpcId=vpc_id, AvailabilityZone=availability_zone_name\n    )[""Subnet""][""SubnetId""]\n    print(""created subnet: {}"".format(subnet_id_a))\n    subnet_id_b = ec2_client.create_subnet(\n        CidrBlock=""10.0.1.0/24"", VpcId=vpc_id, AvailabilityZone=availability_zone_name\n    )[""Subnet""][""SubnetId""]\n    print(""created subnet: {}"".format(subnet_id_b))\n\n    s3_service = [\n        s for s in ec2_client.describe_vpc_endpoint_services()[""ServiceNames""] if s.endswith(""s3"")\n    ][0]\n    ec2_client.create_vpc_endpoint(\n        VpcId=vpc_id, ServiceName=s3_service, RouteTableIds=[_route_table_id(ec2_client, vpc_id)]\n    )\n    print(""created s3 vpc endpoint"")\n\n    security_group_id = ec2_client.create_security_group(\n        VpcId=vpc_id, GroupName=name, Description=name\n    )[""GroupId""]\n    print(""created security group: {}"".format(security_group_id))\n\n    # multi-host vpc jobs require communication among hosts\n    ec2_client.authorize_security_group_ingress(\n        GroupId=security_group_id,\n        IpPermissions=[\n            {\n                ""IpProtocol"": ""tcp"",\n                ""FromPort"": 0,\n                ""ToPort"": 65535,\n                ""UserIdGroupPairs"": [{""GroupId"": security_group_id}],\n            }\n        ],\n    )\n\n    ec2_client.create_tags(\n        Resources=[subnet_id_a, subnet_id_b, security_group_id],\n        Tags=[{""Key"": ""Name"", ""Value"": name}],\n    )\n    return vpc_id, [subnet_id_a, subnet_id_b], security_group_id\n\n\ndef _create_vpc_with_name(ec2_client, name):\n    vpc_id, [subnet_id_a, subnet_id_b], security_group_id = _create_vpc_resources(ec2_client, name)\n    return [subnet_id_a, subnet_id_b], security_group_id\n\n\ndef get_or_create_vpc_resources(ec2_client):\n    # use lock to prevent race condition when tests are running concurrently\n    with lock.lock(LOCK_PATH):\n        if _vpc_exists(ec2_client, VPC_NAME):\n            print(""using existing vpc: {}"".format(VPC_NAME))\n            return (\n                _get_subnet_ids_by_name(ec2_client, VPC_NAME),\n                _get_security_id_by_name(ec2_client, VPC_NAME),\n            )\n        else:\n            print(""creating new vpc: {}"".format(VPC_NAME))\n            return _create_vpc_with_name(ec2_client, VPC_NAME)\n\n\ndef setup_security_group_for_encryption(ec2_client, security_group_id):\n    sg_desc = ec2_client.describe_security_groups(GroupIds=[security_group_id])\n    ingress_perms = sg_desc[""SecurityGroups""][0][""IpPermissions""]\n    if len(ingress_perms) == 1:\n        ec2_client.authorize_security_group_ingress(\n            GroupId=security_group_id,\n            IpPermissions=[\n                {""IpProtocol"": ""50"", ""UserIdGroupPairs"": [{""GroupId"": security_group_id}]},\n                {\n                    ""IpProtocol"": ""udp"",\n                    ""FromPort"": 500,\n                    ""ToPort"": 500,\n                    ""UserIdGroupPairs"": [{""GroupId"": security_group_id}],\n                },\n            ],\n        )\n'"
tests/unit/__init__.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport os\n\nDATA_DIR = os.path.join(os.path.dirname(__file__), "".."", ""data"")\n\nNEO_REGION_LIST = [\n    ""us-west-1"",\n    ""us-west-2"",\n    ""us-east-1"",\n    ""us-east-2"",\n    ""eu-west-1"",\n    ""eu-west-2"",\n    ""eu-west-3"",\n    ""eu-central-1"",\n    ""eu-north-1"",\n    ""ap-northeast-1"",\n    ""ap-northeast-2"",\n    ""ap-east-1"",\n    ""ap-south-1"",\n    ""ap-southeast-1"",\n    ""ap-southeast-2"",\n    ""sa-east-1"",\n    ""ca-central-1"",\n    ""me-south-1"",\n    ""cn-north-1"",\n    ""cn-northwest-1"",\n    ""us-gov-west-1"",\n]\n'"
tests/unit/output_capturer.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Module containing classes necessary for capturing output. For use with tests.""""""\nfrom __future__ import absolute_import\n\nimport sys\nfrom contextlib import contextmanager\nfrom six import StringIO\n\n\n@contextmanager\ndef captured_output():\n    """"""Use this when capturing print output for tests.\n\n    Example:\n        >>>>    with captured_output() as (out, err):\n        >>>>        method_that_prints_hello_sagemaker()\n        >>>>    output = out.getvalue().strip()\n        >>>>    assert output == ""Hello SageMaker!""\n    """"""\n    new_out, new_err = StringIO(), StringIO()\n    old_out, old_err = sys.stdout, sys.stderr\n    try:\n        sys.stdout, sys.stderr = new_out, new_err\n        yield sys.stdout, sys.stderr\n    finally:\n        sys.stdout, sys.stderr = old_out, old_err\n'"
tests/unit/test_airflow.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport pytest\nfrom mock import Mock, MagicMock, patch\n\nfrom sagemaker import chainer, estimator, model, mxnet, tensorflow, transformer, tuner\nfrom sagemaker.workflow import airflow\nfrom sagemaker.amazon import amazon_estimator\nfrom sagemaker.amazon import knn, linear_learner, ntm, pca\n\nREGION = ""us-west-2""\nBUCKET_NAME = ""output""\nTIME_STAMP = ""1111""\n\n\n@pytest.fixture()\ndef sagemaker_session():\n    boto_mock = Mock(name=""boto_session"", region_name=REGION)\n    session = Mock(\n        name=""sagemaker_session"",\n        boto_session=boto_mock,\n        boto_region_name=REGION,\n        config=None,\n        local_mode=False,\n        s3_resource=None,\n        s3_client=None,\n    )\n    session.default_bucket = Mock(name=""default_bucket"", return_value=BUCKET_NAME)\n    session._default_bucket = BUCKET_NAME\n    return session\n\n\n@patch(""sagemaker.utils.sagemaker_timestamp"", MagicMock(return_value=TIME_STAMP))\ndef test_byo_training_config_required_args(sagemaker_session):\n    byo = estimator.Estimator(\n        image_name=""byo"",\n        role=""{{ role }}"",\n        train_instance_count=""{{ instance_count }}"",\n        train_instance_type=""ml.c4.2xlarge"",\n        sagemaker_session=sagemaker_session,\n    )\n\n    byo.set_hyperparameters(epochs=32, feature_dim=1024, mini_batch_size=256)\n\n    data = {""train"": ""{{ training_data }}""}\n\n    config = airflow.training_config(byo, data)\n    expected_config = {\n        ""AlgorithmSpecification"": {""TrainingImage"": ""byo"", ""TrainingInputMode"": ""File""},\n        ""OutputDataConfig"": {""S3OutputPath"": ""s3://output/""},\n        ""TrainingJobName"": ""byo-%s"" % TIME_STAMP,\n        ""StoppingCondition"": {""MaxRuntimeInSeconds"": 86400},\n        ""ResourceConfig"": {\n            ""InstanceCount"": ""{{ instance_count }}"",\n            ""InstanceType"": ""ml.c4.2xlarge"",\n            ""VolumeSizeInGB"": 30,\n        },\n        ""RoleArn"": ""{{ role }}"",\n        ""InputDataConfig"": [\n            {\n                ""DataSource"": {\n                    ""S3DataSource"": {\n                        ""S3DataDistributionType"": ""FullyReplicated"",\n                        ""S3DataType"": ""S3Prefix"",\n                        ""S3Uri"": ""{{ training_data }}"",\n                    }\n                },\n                ""ChannelName"": ""train"",\n            }\n        ],\n        ""HyperParameters"": {""epochs"": ""32"", ""feature_dim"": ""1024"", ""mini_batch_size"": ""256""},\n    }\n    assert config == expected_config\n\n\n@patch(""sagemaker.utils.sagemaker_timestamp"", MagicMock(return_value=TIME_STAMP))\ndef test_byo_training_config_all_args(sagemaker_session):\n    byo = estimator.Estimator(\n        image_name=""byo"",\n        role=""{{ role }}"",\n        train_instance_count=""{{ instance_count }}"",\n        train_instance_type=""ml.c4.2xlarge"",\n        train_volume_size=""{{ train_volume_size }}"",\n        train_volume_kms_key=""{{ train_volume_kms_key }}"",\n        train_max_run=""{{ train_max_run }}"",\n        input_mode=""Pipe"",\n        output_path=""{{ output_path }}"",\n        output_kms_key=""{{ output_volume_kms_key }}"",\n        base_job_name=""{{ base_job_name }}"",\n        tags=[{""{{ key }}"": ""{{ value }}""}],\n        subnets=[""{{ subnet }}""],\n        security_group_ids=[""{{ security_group_ids }}""],\n        model_uri=""{{ model_uri }}"",\n        model_channel_name=""{{ model_chanel }}"",\n        sagemaker_session=sagemaker_session,\n    )\n\n    byo.set_hyperparameters(epochs=32, feature_dim=1024, mini_batch_size=256)\n\n    data = {""train"": ""{{ training_data }}""}\n\n    config = airflow.training_config(byo, data)\n    expected_config = {\n        ""AlgorithmSpecification"": {""TrainingImage"": ""byo"", ""TrainingInputMode"": ""Pipe""},\n        ""OutputDataConfig"": {\n            ""S3OutputPath"": ""{{ output_path }}"",\n            ""KmsKeyId"": ""{{ output_volume_kms_key }}"",\n        },\n        ""TrainingJobName"": ""{{ base_job_name }}-%s"" % TIME_STAMP,\n        ""StoppingCondition"": {""MaxRuntimeInSeconds"": ""{{ train_max_run }}""},\n        ""ResourceConfig"": {\n            ""InstanceCount"": ""{{ instance_count }}"",\n            ""InstanceType"": ""ml.c4.2xlarge"",\n            ""VolumeSizeInGB"": ""{{ train_volume_size }}"",\n            ""VolumeKmsKeyId"": ""{{ train_volume_kms_key }}"",\n        },\n        ""RoleArn"": ""{{ role }}"",\n        ""InputDataConfig"": [\n            {\n                ""DataSource"": {\n                    ""S3DataSource"": {\n                        ""S3DataDistributionType"": ""FullyReplicated"",\n                        ""S3DataType"": ""S3Prefix"",\n                        ""S3Uri"": ""{{ training_data }}"",\n                    }\n                },\n                ""ChannelName"": ""train"",\n            },\n            {\n                ""DataSource"": {\n                    ""S3DataSource"": {\n                        ""S3DataDistributionType"": ""FullyReplicated"",\n                        ""S3DataType"": ""S3Prefix"",\n                        ""S3Uri"": ""{{ model_uri }}"",\n                    }\n                },\n                ""ContentType"": ""application/x-sagemaker-model"",\n                ""InputMode"": ""File"",\n                ""ChannelName"": ""{{ model_chanel }}"",\n            },\n        ],\n        ""VpcConfig"": {\n            ""Subnets"": [""{{ subnet }}""],\n            ""SecurityGroupIds"": [""{{ security_group_ids }}""],\n        },\n        ""HyperParameters"": {""epochs"": ""32"", ""feature_dim"": ""1024"", ""mini_batch_size"": ""256""},\n        ""Tags"": [{""{{ key }}"": ""{{ value }}""}],\n    }\n    assert config == expected_config\n\n\n@patch(""sagemaker.utils.sagemaker_timestamp"", MagicMock(return_value=TIME_STAMP))\n@patch(""os.path.isfile"", MagicMock(return_value=True))\n@patch(""sagemaker.estimator.tar_and_upload_dir"", MagicMock())\n@patch(\n    ""sagemaker.fw_utils.parse_s3_url"",\n    MagicMock(\n        return_value=[\n            ""output"",\n            ""sagemaker-tensorflow-{}/source/sourcedir.tar.gz"".format(TIME_STAMP),\n        ]\n    ),\n)\n@patch(\n    ""sagemaker.fw_utils.get_ecr_image_uri_prefix"",\n    return_value=""520713654638.dkr.ecr.us-west-2.amazonaws.com"",\n)\ndef test_framework_training_config_required_args(ecr_prefix, sagemaker_session):\n    tf = tensorflow.TensorFlow(\n        entry_point=""/some/script.py"",\n        framework_version=""1.10.0"",\n        training_steps=1000,\n        evaluation_steps=100,\n        role=""{{ role }}"",\n        train_instance_count=""{{ instance_count }}"",\n        train_instance_type=""ml.c4.2xlarge"",\n        sagemaker_session=sagemaker_session,\n    )\n\n    data = ""{{ training_data }}""\n\n    config = airflow.training_config(tf, data)\n    expected_config = {\n        ""AlgorithmSpecification"": {\n            ""TrainingImage"": ""520713654638.dkr.ecr.us-west-2.amazonaws.com/sagemaker-tensorflow:1.10.0-cpu-py2"",\n            ""TrainingInputMode"": ""File"",\n        },\n        ""OutputDataConfig"": {""S3OutputPath"": ""s3://output/""},\n        ""TrainingJobName"": ""sagemaker-tensorflow-%s"" % TIME_STAMP,\n        ""StoppingCondition"": {""MaxRuntimeInSeconds"": 86400},\n        ""ResourceConfig"": {\n            ""InstanceCount"": ""{{ instance_count }}"",\n            ""InstanceType"": ""ml.c4.2xlarge"",\n            ""VolumeSizeInGB"": 30,\n        },\n        ""RoleArn"": ""{{ role }}"",\n        ""InputDataConfig"": [\n            {\n                ""DataSource"": {\n                    ""S3DataSource"": {\n                        ""S3DataDistributionType"": ""FullyReplicated"",\n                        ""S3DataType"": ""S3Prefix"",\n                        ""S3Uri"": ""{{ training_data }}"",\n                    }\n                },\n                ""ChannelName"": ""training"",\n            }\n        ],\n        ""HyperParameters"": {\n            ""sagemaker_submit_directory"": \'""s3://output/sagemaker-tensorflow-%s/source/sourcedir.tar.gz""\'\n            % TIME_STAMP,\n            ""sagemaker_program"": \'""script.py""\',\n            ""sagemaker_enable_cloudwatch_metrics"": ""false"",\n            ""sagemaker_container_log_level"": ""20"",\n            ""sagemaker_job_name"": \'""sagemaker-tensorflow-%s""\' % TIME_STAMP,\n            ""sagemaker_region"": \'""us-west-2""\',\n            ""checkpoint_path"": \'""s3://output/sagemaker-tensorflow-%s/checkpoints""\' % TIME_STAMP,\n            ""training_steps"": ""1000"",\n            ""evaluation_steps"": ""100"",\n            ""sagemaker_requirements"": \'""""\',\n        },\n        ""S3Operations"": {\n            ""S3Upload"": [\n                {\n                    ""Path"": ""/some/script.py"",\n                    ""Bucket"": ""output"",\n                    ""Key"": ""sagemaker-tensorflow-%s/source/sourcedir.tar.gz"" % TIME_STAMP,\n                    ""Tar"": True,\n                }\n            ]\n        },\n    }\n    assert config == expected_config\n\n\n@patch(""sagemaker.utils.sagemaker_timestamp"", MagicMock(return_value=TIME_STAMP))\n@patch(""os.path.isfile"", MagicMock(return_value=True))\n@patch(""sagemaker.estimator.tar_and_upload_dir"", MagicMock())\n@patch(\n    ""sagemaker.estimator.parse_s3_url"",\n    MagicMock(return_value=[""{{ output_path }}"", ""{{ output_path }}""]),\n)\n@patch(\n    ""sagemaker.fw_utils.get_ecr_image_uri_prefix"",\n    return_value=""520713654638.dkr.ecr.us-west-2.amazonaws.com"",\n)\ndef test_framework_training_config_all_args(ecr_prefix, sagemaker_session):\n    tf = tensorflow.TensorFlow(\n        entry_point=""{{ entry_point }}"",\n        source_dir=""{{ source_dir }}"",\n        enable_cloudwatch_metrics=False,\n        container_log_level=""{{ log_level }}"",\n        code_location=""s3://{{ bucket_name }}/{{ prefix }}"",\n        training_steps=1000,\n        evaluation_steps=100,\n        checkpoint_path=""{{ checkpoint_path }}"",\n        py_version=""py2"",\n        framework_version=""1.10.0"",\n        requirements_file="""",\n        role=""{{ role }}"",\n        train_instance_count=""{{ instance_count }}"",\n        train_instance_type=""ml.c4.2xlarge"",\n        train_volume_size=""{{ train_volume_size }}"",\n        train_volume_kms_key=""{{ train_volume_kms_key }}"",\n        train_max_run=""{{ train_max_run }}"",\n        input_mode=""Pipe"",\n        output_path=""{{ output_path }}"",\n        output_kms_key=""{{ output_volume_kms_key }}"",\n        base_job_name=""{{ base_job_name }}"",\n        tags=[{""{{ key }}"": ""{{ value }}""}],\n        subnets=[""{{ subnet }}""],\n        security_group_ids=[""{{ security_group_ids }}""],\n        metric_definitions=[{""Name"": ""{{ name }}"", ""Regex"": ""{{ regex }}""}],\n        sagemaker_session=sagemaker_session,\n    )\n\n    data = ""{{ training_data }}""\n\n    config = airflow.training_config(tf, data)\n    expected_config = {\n        ""AlgorithmSpecification"": {\n            ""TrainingImage"": ""520713654638.dkr.ecr.us-west-2.amazonaws.com/sagemaker-tensorflow:1.10.0-cpu-py2"",\n            ""TrainingInputMode"": ""Pipe"",\n            ""MetricDefinitions"": [{""Name"": ""{{ name }}"", ""Regex"": ""{{ regex }}""}],\n        },\n        ""OutputDataConfig"": {\n            ""S3OutputPath"": ""{{ output_path }}"",\n            ""KmsKeyId"": ""{{ output_volume_kms_key }}"",\n        },\n        ""TrainingJobName"": ""{{ base_job_name }}-%s"" % TIME_STAMP,\n        ""StoppingCondition"": {""MaxRuntimeInSeconds"": ""{{ train_max_run }}""},\n        ""ResourceConfig"": {\n            ""InstanceCount"": ""{{ instance_count }}"",\n            ""InstanceType"": ""ml.c4.2xlarge"",\n            ""VolumeSizeInGB"": ""{{ train_volume_size }}"",\n            ""VolumeKmsKeyId"": ""{{ train_volume_kms_key }}"",\n        },\n        ""RoleArn"": ""{{ role }}"",\n        ""InputDataConfig"": [\n            {\n                ""DataSource"": {\n                    ""S3DataSource"": {\n                        ""S3DataDistributionType"": ""FullyReplicated"",\n                        ""S3DataType"": ""S3Prefix"",\n                        ""S3Uri"": ""{{ training_data }}"",\n                    }\n                },\n                ""ChannelName"": ""training"",\n            }\n        ],\n        ""VpcConfig"": {\n            ""Subnets"": [""{{ subnet }}""],\n            ""SecurityGroupIds"": [""{{ security_group_ids }}""],\n        },\n        ""HyperParameters"": {\n            ""sagemaker_submit_directory"": \'""s3://{{ bucket_name }}/{{ prefix }}/{{ base_job_name }}-%s/\'\n            \'source/sourcedir.tar.gz""\' % TIME_STAMP,\n            ""sagemaker_program"": \'""{{ entry_point }}""\',\n            ""sagemaker_enable_cloudwatch_metrics"": ""false"",\n            ""sagemaker_container_log_level"": \'""{{ log_level }}""\',\n            ""sagemaker_job_name"": \'""{{ base_job_name }}-%s""\' % TIME_STAMP,\n            ""sagemaker_region"": \'""us-west-2""\',\n            ""checkpoint_path"": \'""{{ checkpoint_path }}""\',\n            ""training_steps"": ""1000"",\n            ""evaluation_steps"": ""100"",\n            ""sagemaker_requirements"": \'""""\',\n        },\n        ""Tags"": [{""{{ key }}"": ""{{ value }}""}],\n        ""S3Operations"": {\n            ""S3Upload"": [\n                {\n                    ""Path"": ""{{ source_dir }}"",\n                    ""Bucket"": ""{{ bucket_name }}"",\n                    ""Key"": ""{{ prefix }}/{{ base_job_name }}-%s/source/sourcedir.tar.gz""\n                    % TIME_STAMP,\n                    ""Tar"": True,\n                }\n            ]\n        },\n    }\n    assert config == expected_config\n\n\n@patch(""sagemaker.utils.sagemaker_timestamp"", MagicMock(return_value=TIME_STAMP))\ndef test_amazon_alg_training_config_required_args(sagemaker_session):\n    ntm_estimator = ntm.NTM(\n        role=""{{ role }}"",\n        num_topics=10,\n        train_instance_count=""{{ instance_count }}"",\n        train_instance_type=""ml.c4.2xlarge"",\n        sagemaker_session=sagemaker_session,\n    )\n\n    ntm_estimator.epochs = 32\n\n    record = amazon_estimator.RecordSet(""{{ record }}"", 10000, 100, ""S3Prefix"")\n\n    config = airflow.training_config(ntm_estimator, record, mini_batch_size=256)\n    expected_config = {\n        ""AlgorithmSpecification"": {\n            ""TrainingImage"": ""174872318107.dkr.ecr.us-west-2.amazonaws.com/ntm:1"",\n            ""TrainingInputMode"": ""File"",\n        },\n        ""OutputDataConfig"": {""S3OutputPath"": ""s3://output/""},\n        ""TrainingJobName"": ""ntm-%s"" % TIME_STAMP,\n        ""StoppingCondition"": {""MaxRuntimeInSeconds"": 86400},\n        ""ResourceConfig"": {\n            ""InstanceCount"": ""{{ instance_count }}"",\n            ""InstanceType"": ""ml.c4.2xlarge"",\n            ""VolumeSizeInGB"": 30,\n        },\n        ""RoleArn"": ""{{ role }}"",\n        ""InputDataConfig"": [\n            {\n                ""DataSource"": {\n                    ""S3DataSource"": {\n                        ""S3DataDistributionType"": ""ShardedByS3Key"",\n                        ""S3DataType"": ""S3Prefix"",\n                        ""S3Uri"": ""{{ record }}"",\n                    }\n                },\n                ""ChannelName"": ""train"",\n            }\n        ],\n        ""HyperParameters"": {\n            ""num_topics"": ""10"",\n            ""epochs"": ""32"",\n            ""mini_batch_size"": ""256"",\n            ""feature_dim"": ""100"",\n        },\n    }\n    assert config == expected_config\n\n\n@patch(""sagemaker.utils.sagemaker_timestamp"", MagicMock(return_value=TIME_STAMP))\ndef test_amazon_alg_training_config_all_args(sagemaker_session):\n    ntm_estimator = ntm.NTM(\n        role=""{{ role }}"",\n        num_topics=10,\n        train_instance_count=""{{ instance_count }}"",\n        train_instance_type=""ml.c4.2xlarge"",\n        train_volume_size=""{{ train_volume_size }}"",\n        train_volume_kms_key=""{{ train_volume_kms_key }}"",\n        train_max_run=""{{ train_max_run }}"",\n        input_mode=""Pipe"",\n        output_path=""{{ output_path }}"",\n        output_kms_key=""{{ output_volume_kms_key }}"",\n        base_job_name=""{{ base_job_name }}"",\n        tags=[{""{{ key }}"": ""{{ value }}""}],\n        subnets=[""{{ subnet }}""],\n        security_group_ids=[""{{ security_group_ids }}""],\n        sagemaker_session=sagemaker_session,\n    )\n\n    ntm_estimator.epochs = 32\n\n    record = amazon_estimator.RecordSet(""{{ record }}"", 10000, 100, ""S3Prefix"")\n\n    config = airflow.training_config(ntm_estimator, record, mini_batch_size=256)\n    expected_config = {\n        ""AlgorithmSpecification"": {\n            ""TrainingImage"": ""174872318107.dkr.ecr.us-west-2.amazonaws.com/ntm:1"",\n            ""TrainingInputMode"": ""Pipe"",\n        },\n        ""OutputDataConfig"": {\n            ""S3OutputPath"": ""{{ output_path }}"",\n            ""KmsKeyId"": ""{{ output_volume_kms_key }}"",\n        },\n        ""TrainingJobName"": ""{{ base_job_name }}-%s"" % TIME_STAMP,\n        ""StoppingCondition"": {""MaxRuntimeInSeconds"": ""{{ train_max_run }}""},\n        ""ResourceConfig"": {\n            ""InstanceCount"": ""{{ instance_count }}"",\n            ""InstanceType"": ""ml.c4.2xlarge"",\n            ""VolumeSizeInGB"": ""{{ train_volume_size }}"",\n            ""VolumeKmsKeyId"": ""{{ train_volume_kms_key }}"",\n        },\n        ""RoleArn"": ""{{ role }}"",\n        ""InputDataConfig"": [\n            {\n                ""DataSource"": {\n                    ""S3DataSource"": {\n                        ""S3DataDistributionType"": ""ShardedByS3Key"",\n                        ""S3DataType"": ""S3Prefix"",\n                        ""S3Uri"": ""{{ record }}"",\n                    }\n                },\n                ""ChannelName"": ""train"",\n            }\n        ],\n        ""VpcConfig"": {\n            ""Subnets"": [""{{ subnet }}""],\n            ""SecurityGroupIds"": [""{{ security_group_ids }}""],\n        },\n        ""HyperParameters"": {\n            ""num_topics"": ""10"",\n            ""epochs"": ""32"",\n            ""mini_batch_size"": ""256"",\n            ""feature_dim"": ""100"",\n        },\n        ""Tags"": [{""{{ key }}"": ""{{ value }}""}],\n    }\n\n    assert config == expected_config\n\n\n@patch(""sagemaker.utils.sagemaker_timestamp"", MagicMock(return_value=TIME_STAMP))\n@patch(""sagemaker.utils.sagemaker_short_timestamp"", MagicMock(return_value=TIME_STAMP))\n@patch(""os.path.isfile"", MagicMock(return_value=True))\n@patch(""sagemaker.estimator.tar_and_upload_dir"", MagicMock())\n@patch(\n    ""sagemaker.fw_utils.parse_s3_url"",\n    MagicMock(\n        return_value=[\n            ""output"",\n            ""{{{{ base_job_name }}}}-{0}/source/sourcedir.tar.gz"".format(TIME_STAMP),\n        ]\n    ),\n)\n@patch(\n    ""sagemaker.fw_utils.get_ecr_image_uri_prefix"",\n    return_value=""520713654638.dkr.ecr.us-west-2.amazonaws.com"",\n)\ndef test_framework_tuning_config(ecr_prefix, sagemaker_session):\n    mxnet_estimator = mxnet.MXNet(\n        entry_point=""{{ entry_point }}"",\n        source_dir=""{{ source_dir }}"",\n        py_version=""py3"",\n        framework_version=""1.3.0"",\n        role=""{{ role }}"",\n        train_instance_count=1,\n        train_instance_type=""ml.m4.xlarge"",\n        sagemaker_session=sagemaker_session,\n        base_job_name=""{{ base_job_name }}"",\n        hyperparameters={""batch_size"": 100},\n    )\n\n    hyperparameter_ranges = {\n        ""optimizer"": tuner.CategoricalParameter([""sgd"", ""Adam""]),\n        ""learning_rate"": tuner.ContinuousParameter(0.01, 0.2),\n        ""num_epoch"": tuner.IntegerParameter(10, 50),\n    }\n    objective_metric_name = ""Validation-accuracy""\n    metric_definitions = [\n        {""Name"": ""Validation-accuracy"", ""Regex"": ""Validation-accuracy=([0-9\\\\.]+)""}\n    ]\n\n    mxnet_tuner = tuner.HyperparameterTuner(\n        estimator=mxnet_estimator,\n        objective_metric_name=objective_metric_name,\n        hyperparameter_ranges=hyperparameter_ranges,\n        metric_definitions=metric_definitions,\n        strategy=""Bayesian"",\n        objective_type=""Maximize"",\n        max_jobs=""{{ max_job }}"",\n        max_parallel_jobs=""{{ max_parallel_job }}"",\n        tags=[{""{{ key }}"": ""{{ value }}""}],\n        base_tuning_job_name=""{{ base_job_name }}"",\n    )\n\n    data = ""{{ training_data }}""\n\n    config = airflow.tuning_config(mxnet_tuner, data)\n    expected_config = {\n        ""HyperParameterTuningJobName"": ""{{ base_job_name }}-%s"" % TIME_STAMP,\n        ""HyperParameterTuningJobConfig"": {\n            ""Strategy"": ""Bayesian"",\n            ""HyperParameterTuningJobObjective"": {\n                ""Type"": ""Maximize"",\n                ""MetricName"": ""Validation-accuracy"",\n            },\n            ""ResourceLimits"": {\n                ""MaxNumberOfTrainingJobs"": ""{{ max_job }}"",\n                ""MaxParallelTrainingJobs"": ""{{ max_parallel_job }}"",\n            },\n            ""ParameterRanges"": {\n                ""ContinuousParameterRanges"": [\n                    {\n                        ""Name"": ""learning_rate"",\n                        ""MinValue"": ""0.01"",\n                        ""MaxValue"": ""0.2"",\n                        ""ScalingType"": ""Auto"",\n                    }\n                ],\n                ""CategoricalParameterRanges"": [\n                    {""Name"": ""optimizer"", ""Values"": [\'""sgd""\', \'""Adam""\']}\n                ],\n                ""IntegerParameterRanges"": [\n                    {""Name"": ""num_epoch"", ""MinValue"": ""10"", ""MaxValue"": ""50"", ""ScalingType"": ""Auto""}\n                ],\n            },\n            ""TrainingJobEarlyStoppingType"": ""Off"",\n        },\n        ""TrainingJobDefinition"": {\n            ""AlgorithmSpecification"": {\n                ""TrainingImage"": ""520713654638.dkr.ecr.us-west-2.amazonaws.com/sagemaker-mxnet:1.3.0-cpu-py3"",\n                ""TrainingInputMode"": ""File"",\n                ""MetricDefinitions"": [\n                    {""Name"": ""Validation-accuracy"", ""Regex"": ""Validation-accuracy=([0-9\\\\.]+)""}\n                ],\n            },\n            ""OutputDataConfig"": {""S3OutputPath"": ""s3://output/""},\n            ""StoppingCondition"": {""MaxRuntimeInSeconds"": 86400},\n            ""ResourceConfig"": {\n                ""InstanceCount"": 1,\n                ""InstanceType"": ""ml.m4.xlarge"",\n                ""VolumeSizeInGB"": 30,\n            },\n            ""RoleArn"": ""{{ role }}"",\n            ""InputDataConfig"": [\n                {\n                    ""DataSource"": {\n                        ""S3DataSource"": {\n                            ""S3DataDistributionType"": ""FullyReplicated"",\n                            ""S3DataType"": ""S3Prefix"",\n                            ""S3Uri"": ""{{ training_data }}"",\n                        }\n                    },\n                    ""ChannelName"": ""training"",\n                }\n            ],\n            ""StaticHyperParameters"": {\n                ""batch_size"": ""100"",\n                ""sagemaker_submit_directory"": \'""s3://output/{{ base_job_name }}-%s/source/sourcedir.tar.gz""\'\n                % TIME_STAMP,\n                ""sagemaker_program"": \'""{{ entry_point }}""\',\n                ""sagemaker_enable_cloudwatch_metrics"": ""false"",\n                ""sagemaker_container_log_level"": ""20"",\n                ""sagemaker_job_name"": \'""{{ base_job_name }}-%s""\' % TIME_STAMP,\n                ""sagemaker_region"": \'""us-west-2""\',\n                ""sagemaker_estimator_module"": \'""sagemaker.mxnet.estimator""\',\n                ""sagemaker_estimator_class_name"": \'""MXNet""\',\n            },\n        },\n        ""Tags"": [{""{{ key }}"": ""{{ value }}""}],\n        ""S3Operations"": {\n            ""S3Upload"": [\n                {\n                    ""Path"": ""{{ source_dir }}"",\n                    ""Bucket"": ""output"",\n                    ""Key"": ""{{ base_job_name }}-%s/source/sourcedir.tar.gz"" % TIME_STAMP,\n                    ""Tar"": True,\n                }\n            ]\n        },\n    }\n    assert config == expected_config\n\n\n@patch(""sagemaker.utils.sagemaker_timestamp"", MagicMock(return_value=TIME_STAMP))\n@patch(""sagemaker.utils.sagemaker_short_timestamp"", MagicMock(return_value=TIME_STAMP))\n@patch(""os.path.isfile"", MagicMock(return_value=True))\n@patch(""sagemaker.estimator.tar_and_upload_dir"", MagicMock())\n@patch(\n    ""sagemaker.fw_utils.parse_s3_url"",\n    MagicMock(\n        return_value=[\n            ""output"",\n            ""{{{{ base_job_name }}}}-{0}/source/sourcedir.tar.gz"".format(TIME_STAMP),\n        ]\n    ),\n)\n@patch(\n    ""sagemaker.fw_utils.get_ecr_image_uri_prefix"",\n    return_value=""520713654638.dkr.ecr.us-west-2.amazonaws.com"",\n)\n@patch(\n    ""sagemaker.amazon.amazon_estimator.get_ecr_image_uri_prefix"",\n    return_value=""174872318107.dkr.ecr.us-west-2.amazonaws.com"",\n)\ndef test_multi_estimator_tuning_config(algo_ecr_prefix, fw_ecr_prefix, sagemaker_session):\n    estimator_dict = {}\n    hyperparameter_ranges_dict = {}\n    objective_metric_name_dict = {}\n    metric_definitions_dict = {}\n\n    mxnet_estimator_name = ""mxnet""\n    estimator_dict[mxnet_estimator_name] = mxnet.MXNet(\n        entry_point=""{{ entry_point }}"",\n        source_dir=""{{ source_dir }}"",\n        py_version=""py3"",\n        framework_version=""1.3.0"",\n        role=""{{ role }}"",\n        train_instance_count=1,\n        train_instance_type=""ml.m4.xlarge"",\n        sagemaker_session=sagemaker_session,\n        base_job_name=""{{ base_job_name }}"",\n        hyperparameters={""batch_size"": 100},\n    )\n    hyperparameter_ranges_dict[mxnet_estimator_name] = {\n        ""optimizer"": tuner.CategoricalParameter([""sgd"", ""Adam""]),\n        ""learning_rate"": tuner.ContinuousParameter(0.01, 0.2),\n        ""num_epoch"": tuner.IntegerParameter(10, 50),\n    }\n    objective_metric_name_dict[mxnet_estimator_name] = ""Validation-accuracy""\n    metric_definitions_dict[mxnet_estimator_name] = [\n        {""Name"": ""Validation-accuracy"", ""Regex"": ""Validation-accuracy=([0-9\\\\.]+)""}\n    ]\n\n    ll_estimator_name = ""linear_learner""\n    estimator_dict[ll_estimator_name] = linear_learner.LinearLearner(\n        predictor_type=""binary_classifier"",\n        role=""{{ role }}"",\n        train_instance_count=1,\n        train_instance_type=""ml.c4.2xlarge"",\n        sagemaker_session=sagemaker_session,\n    )\n    hyperparameter_ranges_dict[ll_estimator_name] = {\n        ""learning_rate"": tuner.ContinuousParameter(0.2, 0.5),\n        ""use_bias"": tuner.CategoricalParameter([True, False]),\n    }\n    objective_metric_name_dict[ll_estimator_name] = ""validation:binary_classification_accuracy""\n\n    multi_estimator_tuner = tuner.HyperparameterTuner.create(\n        estimator_dict=estimator_dict,\n        objective_metric_name_dict=objective_metric_name_dict,\n        hyperparameter_ranges_dict=hyperparameter_ranges_dict,\n        metric_definitions_dict=metric_definitions_dict,\n        strategy=""Bayesian"",\n        objective_type=""Maximize"",\n        max_jobs=""{{ max_job }}"",\n        max_parallel_jobs=""{{ max_parallel_job }}"",\n        tags=[{""{{ key }}"": ""{{ value }}""}],\n        base_tuning_job_name=""{{ base_job_name }}"",\n    )\n\n    data = {\n        mxnet_estimator_name: ""{{ training_data_mxnet }}"",\n        ll_estimator_name: amazon_estimator.RecordSet(""{{ record }}"", 10000, 100, ""S3Prefix""),\n    }\n\n    config = airflow.tuning_config(multi_estimator_tuner, inputs=data, include_cls_metadata={})\n\n    expected_config = {\n        ""HyperParameterTuningJobName"": ""{{ base_job_name }}-%s"" % TIME_STAMP,\n        ""HyperParameterTuningJobConfig"": {\n            ""Strategy"": ""Bayesian"",\n            ""ResourceLimits"": {\n                ""MaxNumberOfTrainingJobs"": ""{{ max_job }}"",\n                ""MaxParallelTrainingJobs"": ""{{ max_parallel_job }}"",\n            },\n            ""TrainingJobEarlyStoppingType"": ""Off"",\n        },\n        ""TrainingJobDefinitions"": [\n            {\n                ""DefinitionName"": ""linear_learner"",\n                ""TuningObjective"": {\n                    ""MetricName"": ""validation:binary_classification_accuracy"",\n                    ""Type"": ""Maximize"",\n                },\n                ""HyperParameterRanges"": {\n                    ""CategoricalParameterRanges"": [\n                        {""Name"": ""use_bias"", ""Values"": [""True"", ""False""]}\n                    ],\n                    ""ContinuousParameterRanges"": [\n                        {\n                            ""MaxValue"": ""0.5"",\n                            ""MinValue"": ""0.2"",\n                            ""Name"": ""learning_rate"",\n                            ""ScalingType"": ""Auto"",\n                        }\n                    ],\n                    ""IntegerParameterRanges"": [],\n                },\n                ""StaticHyperParameters"": {\n                    ""feature_dim"": ""100"",\n                    ""predictor_type"": ""binary_classifier"",\n                },\n                ""AlgorithmSpecification"": {\n                    ""MetricDefinitions"": None,\n                    ""TrainingImage"": ""174872318107.dkr.ecr.us-west-2.amazonaws.com/linear-learner:1"",\n                    ""TrainingInputMode"": ""File"",\n                },\n                ""InputDataConfig"": [\n                    {\n                        ""ChannelName"": ""train"",\n                        ""DataSource"": {\n                            ""S3DataSource"": {\n                                ""S3DataDistributionType"": ""ShardedByS3Key"",\n                                ""S3DataType"": ""S3Prefix"",\n                                ""S3Uri"": ""{{ record }}"",\n                            }\n                        },\n                    }\n                ],\n                ""OutputDataConfig"": {""S3OutputPath"": ""s3://output/""},\n                ""ResourceConfig"": {\n                    ""InstanceCount"": 1,\n                    ""InstanceType"": ""ml.c4.2xlarge"",\n                    ""VolumeSizeInGB"": 30,\n                },\n                ""RoleArn"": ""{{ role }}"",\n                ""StoppingCondition"": {""MaxRuntimeInSeconds"": 86400},\n            },\n            {\n                ""DefinitionName"": ""mxnet"",\n                ""TuningObjective"": {""MetricName"": ""Validation-accuracy"", ""Type"": ""Maximize""},\n                ""HyperParameterRanges"": {\n                    ""CategoricalParameterRanges"": [\n                        {""Name"": ""optimizer"", ""Values"": [\'""sgd""\', \'""Adam""\']}\n                    ],\n                    ""ContinuousParameterRanges"": [\n                        {\n                            ""MaxValue"": ""0.2"",\n                            ""MinValue"": ""0.01"",\n                            ""Name"": ""learning_rate"",\n                            ""ScalingType"": ""Auto"",\n                        }\n                    ],\n                    ""IntegerParameterRanges"": [\n                        {\n                            ""MaxValue"": ""50"",\n                            ""MinValue"": ""10"",\n                            ""Name"": ""num_epoch"",\n                            ""ScalingType"": ""Auto"",\n                        }\n                    ],\n                },\n                ""StaticHyperParameters"": {\n                    ""batch_size"": ""100"",\n                    ""sagemaker_container_log_level"": ""20"",\n                    ""sagemaker_enable_cloudwatch_metrics"": ""false"",\n                    ""sagemaker_estimator_class_name"": \'""MXNet""\',\n                    ""sagemaker_estimator_module"": \'""sagemaker.mxnet.estimator""\',\n                    ""sagemaker_job_name"": \'""{{ base_job_name }}-%s""\' % TIME_STAMP,\n                    ""sagemaker_program"": \'""{{ entry_point }}""\',\n                    ""sagemaker_region"": \'""us-west-2""\',\n                    ""sagemaker_submit_directory"": \'""s3://output/{{ base_job_name }}-%s/source/sourcedir.tar.gz""\'\n                    % TIME_STAMP,\n                },\n                ""AlgorithmSpecification"": {\n                    ""MetricDefinitions"": [\n                        {""Name"": ""Validation-accuracy"", ""Regex"": ""Validation-accuracy=([0-9\\\\.]+)""}\n                    ],\n                    ""TrainingImage"": ""520713654638.dkr.ecr.us-west-2.amazonaws.com/sagemaker-mxnet:1.3.0-cpu-py3"",\n                    ""TrainingInputMode"": ""File"",\n                },\n                ""InputDataConfig"": [\n                    {\n                        ""ChannelName"": ""training"",\n                        ""DataSource"": {\n                            ""S3DataSource"": {\n                                ""S3DataDistributionType"": ""FullyReplicated"",\n                                ""S3DataType"": ""S3Prefix"",\n                                ""S3Uri"": ""{{ training_data_mxnet }}"",\n                            }\n                        },\n                    }\n                ],\n                ""OutputDataConfig"": {""S3OutputPath"": ""s3://output/""},\n                ""ResourceConfig"": {\n                    ""InstanceCount"": 1,\n                    ""InstanceType"": ""ml.m4.xlarge"",\n                    ""VolumeSizeInGB"": 30,\n                },\n                ""RoleArn"": ""{{ role }}"",\n                ""StoppingCondition"": {""MaxRuntimeInSeconds"": 86400},\n            },\n        ],\n        ""S3Operations"": {\n            ""S3Upload"": [\n                {\n                    ""Bucket"": ""output"",\n                    ""Key"": ""{{ base_job_name }}-%s/source/sourcedir.tar.gz"" % TIME_STAMP,\n                    ""Path"": ""{{ source_dir }}"",\n                    ""Tar"": True,\n                }\n            ]\n        },\n        ""Tags"": [{""{{ key }}"": ""{{ value }}""}],\n    }\n\n    assert config == expected_config\n\n\ndef test_merge_s3_operations():\n    s3_operations_list = [\n        {\n            ""S3Upload"": [\n                {\n                    ""Bucket"": ""output"",\n                    ""Key"": ""base_job_name-111/source/sourcedir.tar.gz"",\n                    ""Path"": ""source_dir"",\n                    ""Tar"": True,\n                }\n            ]\n        },\n        {\n            ""S3Upload"": [\n                {\n                    ""Bucket"": ""output"",\n                    ""Key"": ""base_job_name-111/source/sourcedir.tar.gz"",\n                    ""Path"": ""source_dir"",\n                    ""Tar"": True,\n                }\n            ],\n            ""S3CreateBucket"": [{""Bucket"": ""output""}],\n        },\n        {\n            ""S3Upload"": [\n                {\n                    ""Bucket"": ""output_2"",\n                    ""Key"": ""base_job_name-111/source/sourcedir_2.tar.gz"",\n                    ""Path"": ""source_dir_2"",\n                    ""Tar"": True,\n                }\n            ]\n        },\n        {""S3CreateBucket"": [{""Bucket"": ""output_2""}]},\n        {},\n    ]\n\n    expected_result = {\n        ""S3Upload"": [\n            {\n                ""Bucket"": ""output"",\n                ""Key"": ""base_job_name-111/source/sourcedir.tar.gz"",\n                ""Path"": ""source_dir"",\n                ""Tar"": True,\n            },\n            {\n                ""Bucket"": ""output_2"",\n                ""Key"": ""base_job_name-111/source/sourcedir_2.tar.gz"",\n                ""Path"": ""source_dir_2"",\n                ""Tar"": True,\n            },\n        ],\n        ""S3CreateBucket"": [{""Bucket"": ""output""}, {""Bucket"": ""output_2""}],\n    }\n\n    assert airflow._merge_s3_operations(s3_operations_list) == expected_result\n\n\ndef test_byo_model_config(sagemaker_session):\n    byo_model = model.Model(\n        model_data=""{{ model_data }}"",\n        image=""{{ image }}"",\n        role=""{{ role }}"",\n        env={""{{ key }}"": ""{{ value }}""},\n        name=""model"",\n        sagemaker_session=sagemaker_session,\n    )\n\n    config = airflow.model_config(instance_type=""ml.c4.xlarge"", model=byo_model)\n    expected_config = {\n        ""ModelName"": ""model"",\n        ""PrimaryContainer"": {\n            ""Image"": ""{{ image }}"",\n            ""Environment"": {""{{ key }}"": ""{{ value }}""},\n            ""ModelDataUrl"": ""{{ model_data }}"",\n        },\n        ""ExecutionRoleArn"": ""{{ role }}"",\n    }\n\n    assert config == expected_config\n\n\ndef test_byo_framework_model_config(sagemaker_session):\n    byo_model = model.FrameworkModel(\n        model_data=""{{ model_data }}"",\n        image=""{{ image }}"",\n        role=""{{ role }}"",\n        entry_point=""{{ entry_point }}"",\n        source_dir=""{{ source_dir }}"",\n        env={""{{ key }}"": ""{{ value }}""},\n        name=""model"",\n        sagemaker_session=sagemaker_session,\n    )\n\n    config = airflow.model_config(instance_type=""ml.c4.xlarge"", model=byo_model)\n    expected_config = {\n        ""ModelName"": ""model"",\n        ""PrimaryContainer"": {\n            ""Image"": ""{{ image }}"",\n            ""Environment"": {\n                ""{{ key }}"": ""{{ value }}"",\n                ""SAGEMAKER_PROGRAM"": ""{{ entry_point }}"",\n                ""SAGEMAKER_SUBMIT_DIRECTORY"": ""s3://output/model/source/sourcedir.tar.gz"",\n                ""SAGEMAKER_ENABLE_CLOUDWATCH_METRICS"": ""false"",\n                ""SAGEMAKER_CONTAINER_LOG_LEVEL"": ""20"",\n                ""SAGEMAKER_REGION"": ""us-west-2"",\n            },\n            ""ModelDataUrl"": ""{{ model_data }}"",\n        },\n        ""ExecutionRoleArn"": ""{{ role }}"",\n        ""S3Operations"": {\n            ""S3Upload"": [\n                {\n                    ""Path"": ""{{ source_dir }}"",\n                    ""Bucket"": ""output"",\n                    ""Key"": ""model/source/sourcedir.tar.gz"",\n                    ""Tar"": True,\n                }\n            ]\n        },\n    }\n\n    assert config == expected_config\n\n\n@patch(""sagemaker.utils.sagemaker_timestamp"", MagicMock(return_value=TIME_STAMP))\ndef test_framework_model_config(sagemaker_session):\n    chainer_model = chainer.ChainerModel(\n        model_data=""{{ model_data }}"",\n        role=""{{ role }}"",\n        entry_point=""{{ entry_point }}"",\n        source_dir=""{{ source_dir }}"",\n        image=None,\n        py_version=""py3"",\n        framework_version=""5.0.0"",\n        model_server_workers=""{{ model_server_worker }}"",\n        sagemaker_session=sagemaker_session,\n    )\n\n    config = airflow.model_config(instance_type=""ml.c4.xlarge"", model=chainer_model)\n    expected_config = {\n        ""ModelName"": ""sagemaker-chainer-%s"" % TIME_STAMP,\n        ""PrimaryContainer"": {\n            ""Image"": ""520713654638.dkr.ecr.us-west-2.amazonaws.com/sagemaker-chainer:5.0.0-cpu-py3"",\n            ""Environment"": {\n                ""SAGEMAKER_PROGRAM"": ""{{ entry_point }}"",\n                ""SAGEMAKER_SUBMIT_DIRECTORY"": ""s3://output/sagemaker-chainer-%s/source/sourcedir.tar.gz""\n                % TIME_STAMP,\n                ""SAGEMAKER_ENABLE_CLOUDWATCH_METRICS"": ""false"",\n                ""SAGEMAKER_CONTAINER_LOG_LEVEL"": ""20"",\n                ""SAGEMAKER_REGION"": ""us-west-2"",\n                ""SAGEMAKER_MODEL_SERVER_WORKERS"": ""{{ model_server_worker }}"",\n            },\n            ""ModelDataUrl"": ""{{ model_data }}"",\n        },\n        ""ExecutionRoleArn"": ""{{ role }}"",\n        ""S3Operations"": {\n            ""S3Upload"": [\n                {\n                    ""Path"": ""{{ source_dir }}"",\n                    ""Bucket"": ""output"",\n                    ""Key"": ""sagemaker-chainer-%s/source/sourcedir.tar.gz"" % TIME_STAMP,\n                    ""Tar"": True,\n                }\n            ]\n        },\n    }\n\n    assert config == expected_config\n\n\n@patch(""sagemaker.utils.sagemaker_timestamp"", MagicMock(return_value=TIME_STAMP))\ndef test_amazon_alg_model_config(sagemaker_session):\n    pca_model = pca.PCAModel(\n        model_data=""{{ model_data }}"", role=""{{ role }}"", sagemaker_session=sagemaker_session\n    )\n\n    config = airflow.model_config(instance_type=""ml.c4.xlarge"", model=pca_model)\n    expected_config = {\n        ""ModelName"": ""pca-%s"" % TIME_STAMP,\n        ""PrimaryContainer"": {\n            ""Image"": ""174872318107.dkr.ecr.us-west-2.amazonaws.com/pca:1"",\n            ""Environment"": {},\n            ""ModelDataUrl"": ""{{ model_data }}"",\n        },\n        ""ExecutionRoleArn"": ""{{ role }}"",\n    }\n\n    assert config == expected_config\n\n\n@patch(""sagemaker.utils.sagemaker_timestamp"", MagicMock(return_value=TIME_STAMP))\n@patch(""os.path.isfile"", MagicMock(return_value=True))\n@patch(""sagemaker.estimator.tar_and_upload_dir"", MagicMock())\n@patch(\n    ""sagemaker.fw_utils.parse_s3_url"",\n    MagicMock(\n        return_value=[\n            ""output"",\n            ""{{{{ base_job_name }}}}-{0}/source/sourcedir.tar.gz"".format(TIME_STAMP),\n        ]\n    ),\n)\n@patch(\n    ""sagemaker.fw_utils.get_ecr_image_uri_prefix"",\n    return_value=""763104351884.dkr.ecr.us-west-2.amazonaws.com"",\n)\ndef test_model_config_from_framework_estimator(ecr_prefix, sagemaker_session):\n    mxnet_estimator = mxnet.MXNet(\n        entry_point=""{{ entry_point }}"",\n        source_dir=""{{ source_dir }}"",\n        py_version=""py3"",\n        framework_version=""1.6.0"",\n        role=""{{ role }}"",\n        train_instance_count=1,\n        train_instance_type=""ml.m4.xlarge"",\n        sagemaker_session=sagemaker_session,\n        base_job_name=""{{ base_job_name }}"",\n        hyperparameters={""batch_size"": 100},\n    )\n\n    data = ""{{ training_data }}""\n\n    # simulate training\n    airflow.training_config(mxnet_estimator, data)\n\n    config = airflow.model_config_from_estimator(\n        instance_type=""ml.c4.xlarge"",\n        estimator=mxnet_estimator,\n        task_id=""task_id"",\n        task_type=""training"",\n    )\n    expected_config = {\n        ""ModelName"": ""mxnet-inference-%s"" % TIME_STAMP,\n        ""PrimaryContainer"": {\n            ""Image"": ""763104351884.dkr.ecr.us-west-2.amazonaws.com/mxnet-inference:1.6.0-cpu-py3"",\n            ""Environment"": {\n                ""SAGEMAKER_PROGRAM"": ""{{ entry_point }}"",\n                ""SAGEMAKER_SUBMIT_DIRECTORY"": ""s3://output/{{ ti.xcom_pull(task_ids=\'task_id\')[\'Training\']""\n                ""[\'TrainingJobName\'] }}/source/sourcedir.tar.gz"",\n                ""SAGEMAKER_ENABLE_CLOUDWATCH_METRICS"": ""false"",\n                ""SAGEMAKER_CONTAINER_LOG_LEVEL"": ""20"",\n                ""SAGEMAKER_REGION"": ""us-west-2"",\n            },\n            ""ModelDataUrl"": ""s3://output/{{ ti.xcom_pull(task_ids=\'task_id\')[\'Training\'][\'TrainingJobName\'] }}""\n            ""/output/model.tar.gz"",\n        },\n        ""ExecutionRoleArn"": ""{{ role }}"",\n    }\n\n    assert config == expected_config\n\n\n@patch(""sagemaker.utils.sagemaker_timestamp"", MagicMock(return_value=TIME_STAMP))\ndef test_model_config_from_amazon_alg_estimator(sagemaker_session):\n    knn_estimator = knn.KNN(\n        role=""{{ role }}"",\n        train_instance_count=""{{ instance_count }}"",\n        train_instance_type=""ml.m4.xlarge"",\n        k=16,\n        sample_size=128,\n        predictor_type=""regressor"",\n        sagemaker_session=sagemaker_session,\n    )\n\n    record = amazon_estimator.RecordSet(""{{ record }}"", 10000, 100, ""S3Prefix"")\n\n    # simulate training\n    airflow.training_config(knn_estimator, record, mini_batch_size=256)\n\n    config = airflow.model_config_from_estimator(\n        instance_type=""ml.c4.xlarge"", estimator=knn_estimator, task_id=""task_id"", task_type=""tuning""\n    )\n    expected_config = {\n        ""ModelName"": ""knn-%s"" % TIME_STAMP,\n        ""PrimaryContainer"": {\n            ""Image"": ""174872318107.dkr.ecr.us-west-2.amazonaws.com/knn:1"",\n            ""Environment"": {},\n            ""ModelDataUrl"": ""s3://output/{{ ti.xcom_pull(task_ids=\'task_id\')[\'Tuning\'][\'BestTrainingJob\']""\n            ""[\'TrainingJobName\'] }}/output/model.tar.gz"",\n        },\n        ""ExecutionRoleArn"": ""{{ role }}"",\n    }\n\n    assert config == expected_config\n\n\n@patch(""sagemaker.utils.sagemaker_timestamp"", MagicMock(return_value=TIME_STAMP))\ndef test_transform_config(sagemaker_session):\n    tf_transformer = transformer.Transformer(\n        model_name=""tensorflow-model"",\n        instance_count=""{{ instance_count }}"",\n        instance_type=""ml.p2.xlarge"",\n        strategy=""SingleRecord"",\n        assemble_with=""Line"",\n        output_path=""{{ output_path }}"",\n        output_kms_key=""{{ kms_key }}"",\n        accept=""{{ accept }}"",\n        max_concurrent_transforms=""{{ max_parallel_job }}"",\n        max_payload=""{{ max_payload }}"",\n        tags=[{""{{ key }}"": ""{{ value }}""}],\n        env={""{{ key }}"": ""{{ value }}""},\n        base_transform_job_name=""tensorflow-transform"",\n        sagemaker_session=sagemaker_session,\n        volume_kms_key=""{{ kms_key }}"",\n    )\n\n    data = ""{{ transform_data }}""\n\n    config = airflow.transform_config(\n        tf_transformer,\n        data,\n        data_type=""S3Prefix"",\n        content_type=""{{ content_type }}"",\n        compression_type=""{{ compression_type }}"",\n        split_type=""{{ split_type }}"",\n        input_filter=""{{ input_filter }}"",\n        output_filter=""{{ output_filter }}"",\n        join_source=""{{ join_source }}"",\n    )\n    expected_config = {\n        ""TransformJobName"": ""tensorflow-transform-%s"" % TIME_STAMP,\n        ""ModelName"": ""tensorflow-model"",\n        ""TransformInput"": {\n            ""DataSource"": {\n                ""S3DataSource"": {""S3DataType"": ""S3Prefix"", ""S3Uri"": ""{{ transform_data }}""}\n            },\n            ""ContentType"": ""{{ content_type }}"",\n            ""CompressionType"": ""{{ compression_type }}"",\n            ""SplitType"": ""{{ split_type }}"",\n        },\n        ""TransformOutput"": {\n            ""S3OutputPath"": ""{{ output_path }}"",\n            ""KmsKeyId"": ""{{ kms_key }}"",\n            ""AssembleWith"": ""Line"",\n            ""Accept"": ""{{ accept }}"",\n        },\n        ""TransformResources"": {\n            ""InstanceCount"": ""{{ instance_count }}"",\n            ""InstanceType"": ""ml.p2.xlarge"",\n            ""VolumeKmsKeyId"": ""{{ kms_key }}"",\n        },\n        ""BatchStrategy"": ""SingleRecord"",\n        ""MaxConcurrentTransforms"": ""{{ max_parallel_job }}"",\n        ""MaxPayloadInMB"": ""{{ max_payload }}"",\n        ""Environment"": {""{{ key }}"": ""{{ value }}""},\n        ""Tags"": [{""{{ key }}"": ""{{ value }}""}],\n        ""DataProcessing"": {\n            ""InputFilter"": ""{{ input_filter }}"",\n            ""JoinSource"": ""{{ join_source }}"",\n            ""OutputFilter"": ""{{ output_filter }}"",\n        },\n    }\n\n    assert config == expected_config\n\n\n@patch(""sagemaker.utils.sagemaker_timestamp"", MagicMock(return_value=TIME_STAMP))\n@patch(""os.path.isfile"", MagicMock(return_value=True))\n@patch(""sagemaker.estimator.tar_and_upload_dir"", MagicMock())\n@patch(\n    ""sagemaker.fw_utils.parse_s3_url"",\n    MagicMock(\n        return_value=[\n            ""output"",\n            ""{{{{ base_job_name }}}}-{0}/source/sourcedir.tar.gz"".format(TIME_STAMP),\n        ]\n    ),\n)\n@patch(\n    ""sagemaker.fw_utils.get_ecr_image_uri_prefix"",\n    return_value=""763104351884.dkr.ecr.us-west-2.amazonaws.com"",\n)\ndef test_transform_config_from_framework_estimator(ecr_prefix, sagemaker_session):\n    mxnet_estimator = mxnet.MXNet(\n        entry_point=""{{ entry_point }}"",\n        source_dir=""{{ source_dir }}"",\n        py_version=""py3"",\n        framework_version=""1.6.0"",\n        role=""{{ role }}"",\n        train_instance_count=1,\n        train_instance_type=""ml.m4.xlarge"",\n        sagemaker_session=sagemaker_session,\n        base_job_name=""{{ base_job_name }}"",\n        hyperparameters={""batch_size"": 100},\n    )\n\n    train_data = ""{{ train_data }}""\n    transform_data = ""{{ transform_data }}""\n\n    # simulate training\n    airflow.training_config(mxnet_estimator, train_data)\n\n    config = airflow.transform_config_from_estimator(\n        estimator=mxnet_estimator,\n        task_id=""task_id"",\n        task_type=""training"",\n        instance_count=""{{ instance_count }}"",\n        instance_type=""ml.p2.xlarge"",\n        data=transform_data,\n        input_filter=""{{ input_filter }}"",\n        output_filter=""{{ output_filter }}"",\n        join_source=""{{ join_source }}"",\n    )\n    expected_config = {\n        ""Model"": {\n            ""ModelName"": ""mxnet-inference-%s"" % TIME_STAMP,\n            ""PrimaryContainer"": {\n                ""Image"": ""763104351884.dkr.ecr.us-west-2.amazonaws.com/mxnet-inference:1.6.0-gpu-py3"",\n                ""Environment"": {\n                    ""SAGEMAKER_PROGRAM"": ""{{ entry_point }}"",\n                    ""SAGEMAKER_SUBMIT_DIRECTORY"": ""s3://output/{{ ti.xcom_pull(task_ids=\'task_id\')""\n                    ""[\'Training\'][\'TrainingJobName\'] }}""\n                    ""/source/sourcedir.tar.gz"",\n                    ""SAGEMAKER_ENABLE_CLOUDWATCH_METRICS"": ""false"",\n                    ""SAGEMAKER_CONTAINER_LOG_LEVEL"": ""20"",\n                    ""SAGEMAKER_REGION"": ""us-west-2"",\n                },\n                ""ModelDataUrl"": ""s3://output/{{ ti.xcom_pull(task_ids=\'task_id\')[\'Training\'][\'TrainingJobName\'] }}""\n                ""/output/model.tar.gz"",\n            },\n            ""ExecutionRoleArn"": ""{{ role }}"",\n        },\n        ""Transform"": {\n            ""TransformJobName"": ""{{ base_job_name }}-%s"" % TIME_STAMP,\n            ""ModelName"": ""mxnet-inference-%s"" % TIME_STAMP,\n            ""TransformInput"": {\n                ""DataSource"": {\n                    ""S3DataSource"": {""S3DataType"": ""S3Prefix"", ""S3Uri"": ""{{ transform_data }}""}\n                }\n            },\n            ""TransformOutput"": {""S3OutputPath"": ""s3://output/{{ base_job_name }}-%s"" % TIME_STAMP},\n            ""TransformResources"": {\n                ""InstanceCount"": ""{{ instance_count }}"",\n                ""InstanceType"": ""ml.p2.xlarge"",\n            },\n            ""Environment"": {},\n            ""DataProcessing"": {\n                ""InputFilter"": ""{{ input_filter }}"",\n                ""JoinSource"": ""{{ join_source }}"",\n                ""OutputFilter"": ""{{ output_filter }}"",\n            },\n        },\n    }\n\n    assert config == expected_config\n\n\n@patch(""sagemaker.utils.sagemaker_timestamp"", MagicMock(return_value=TIME_STAMP))\ndef test_transform_config_from_amazon_alg_estimator(sagemaker_session):\n    knn_estimator = knn.KNN(\n        role=""{{ role }}"",\n        train_instance_count=""{{ instance_count }}"",\n        train_instance_type=""ml.m4.xlarge"",\n        k=16,\n        sample_size=128,\n        predictor_type=""regressor"",\n        sagemaker_session=sagemaker_session,\n    )\n\n    record = amazon_estimator.RecordSet(""{{ record }}"", 10000, 100, ""S3Prefix"")\n    transform_data = ""{{ transform_data }}""\n\n    # simulate training\n    airflow.training_config(knn_estimator, record, mini_batch_size=256)\n\n    config = airflow.transform_config_from_estimator(\n        estimator=knn_estimator,\n        task_id=""task_id"",\n        task_type=""training"",\n        instance_count=""{{ instance_count }}"",\n        instance_type=""ml.p2.xlarge"",\n        data=transform_data,\n    )\n    expected_config = {\n        ""Model"": {\n            ""ModelName"": ""knn-%s"" % TIME_STAMP,\n            ""PrimaryContainer"": {\n                ""Image"": ""174872318107.dkr.ecr.us-west-2.amazonaws.com/knn:1"",\n                ""Environment"": {},\n                ""ModelDataUrl"": ""s3://output/{{ ti.xcom_pull(task_ids=\'task_id\')[\'Training\'][\'TrainingJobName\'] }}""\n                ""/output/model.tar.gz"",\n            },\n            ""ExecutionRoleArn"": ""{{ role }}"",\n        },\n        ""Transform"": {\n            ""TransformJobName"": ""knn-%s"" % TIME_STAMP,\n            ""ModelName"": ""knn-%s"" % TIME_STAMP,\n            ""TransformInput"": {\n                ""DataSource"": {\n                    ""S3DataSource"": {""S3DataType"": ""S3Prefix"", ""S3Uri"": ""{{ transform_data }}""}\n                }\n            },\n            ""TransformOutput"": {""S3OutputPath"": ""s3://output/knn-%s"" % TIME_STAMP},\n            ""TransformResources"": {\n                ""InstanceCount"": ""{{ instance_count }}"",\n                ""InstanceType"": ""ml.p2.xlarge"",\n            },\n        },\n    }\n\n    assert config == expected_config\n\n\n@patch(""sagemaker.utils.sagemaker_timestamp"", MagicMock(return_value=TIME_STAMP))\ndef test_deploy_framework_model_config(sagemaker_session):\n    chainer_model = chainer.ChainerModel(\n        model_data=""{{ model_data }}"",\n        role=""{{ role }}"",\n        entry_point=""{{ entry_point }}"",\n        source_dir=""{{ source_dir }}"",\n        image=None,\n        py_version=""py3"",\n        framework_version=""5.0.0"",\n        model_server_workers=""{{ model_server_worker }}"",\n        sagemaker_session=sagemaker_session,\n    )\n\n    config = airflow.deploy_config(\n        chainer_model, initial_instance_count=""{{ instance_count }}"", instance_type=""ml.m4.xlarge""\n    )\n    expected_config = {\n        ""Model"": {\n            ""ModelName"": ""sagemaker-chainer-%s"" % TIME_STAMP,\n            ""PrimaryContainer"": {\n                ""Image"": ""520713654638.dkr.ecr.us-west-2.amazonaws.com/sagemaker-chainer:5.0.0-cpu-py3"",\n                ""Environment"": {\n                    ""SAGEMAKER_PROGRAM"": ""{{ entry_point }}"",\n                    ""SAGEMAKER_SUBMIT_DIRECTORY"": ""s3://output/sagemaker-chainer-%s/source/sourcedir.tar.gz""\n                    % TIME_STAMP,\n                    ""SAGEMAKER_ENABLE_CLOUDWATCH_METRICS"": ""false"",\n                    ""SAGEMAKER_CONTAINER_LOG_LEVEL"": ""20"",\n                    ""SAGEMAKER_REGION"": ""us-west-2"",\n                    ""SAGEMAKER_MODEL_SERVER_WORKERS"": ""{{ model_server_worker }}"",\n                },\n                ""ModelDataUrl"": ""{{ model_data }}"",\n            },\n            ""ExecutionRoleArn"": ""{{ role }}"",\n        },\n        ""EndpointConfig"": {\n            ""EndpointConfigName"": ""sagemaker-chainer-%s"" % TIME_STAMP,\n            ""ProductionVariants"": [\n                {\n                    ""InstanceType"": ""ml.m4.xlarge"",\n                    ""InitialInstanceCount"": ""{{ instance_count }}"",\n                    ""ModelName"": ""sagemaker-chainer-%s"" % TIME_STAMP,\n                    ""VariantName"": ""AllTraffic"",\n                    ""InitialVariantWeight"": 1,\n                }\n            ],\n        },\n        ""Endpoint"": {\n            ""EndpointName"": ""sagemaker-chainer-%s"" % TIME_STAMP,\n            ""EndpointConfigName"": ""sagemaker-chainer-%s"" % TIME_STAMP,\n        },\n        ""S3Operations"": {\n            ""S3Upload"": [\n                {\n                    ""Path"": ""{{ source_dir }}"",\n                    ""Bucket"": ""output"",\n                    ""Key"": ""sagemaker-chainer-%s/source/sourcedir.tar.gz"" % TIME_STAMP,\n                    ""Tar"": True,\n                }\n            ]\n        },\n    }\n\n    assert config == expected_config\n\n\n@patch(""sagemaker.utils.sagemaker_timestamp"", MagicMock(return_value=TIME_STAMP))\ndef test_deploy_amazon_alg_model_config(sagemaker_session):\n    pca_model = pca.PCAModel(\n        model_data=""{{ model_data }}"", role=""{{ role }}"", sagemaker_session=sagemaker_session\n    )\n\n    config = airflow.deploy_config(\n        pca_model, initial_instance_count=""{{ instance_count }}"", instance_type=""ml.c4.xlarge""\n    )\n    expected_config = {\n        ""Model"": {\n            ""ModelName"": ""pca-%s"" % TIME_STAMP,\n            ""PrimaryContainer"": {\n                ""Image"": ""174872318107.dkr.ecr.us-west-2.amazonaws.com/pca:1"",\n                ""Environment"": {},\n                ""ModelDataUrl"": ""{{ model_data }}"",\n            },\n            ""ExecutionRoleArn"": ""{{ role }}"",\n        },\n        ""EndpointConfig"": {\n            ""EndpointConfigName"": ""pca-%s"" % TIME_STAMP,\n            ""ProductionVariants"": [\n                {\n                    ""InstanceType"": ""ml.c4.xlarge"",\n                    ""InitialInstanceCount"": ""{{ instance_count }}"",\n                    ""ModelName"": ""pca-%s"" % TIME_STAMP,\n                    ""VariantName"": ""AllTraffic"",\n                    ""InitialVariantWeight"": 1,\n                }\n            ],\n        },\n        ""Endpoint"": {\n            ""EndpointName"": ""pca-%s"" % TIME_STAMP,\n            ""EndpointConfigName"": ""pca-%s"" % TIME_STAMP,\n        },\n    }\n\n    assert config == expected_config\n\n\n@patch(""sagemaker.utils.sagemaker_timestamp"", MagicMock(return_value=TIME_STAMP))\n@patch(""os.path.isfile"", MagicMock(return_value=True))\n@patch(""sagemaker.estimator.tar_and_upload_dir"", MagicMock())\n@patch(\n    ""sagemaker.fw_utils.parse_s3_url"",\n    MagicMock(\n        return_value=[\n            ""output"",\n            ""{{{{ base_job_name }}}}-{0}/source/sourcedir.tar.gz"".format(TIME_STAMP),\n        ]\n    ),\n)\n@patch(\n    ""sagemaker.fw_utils.get_ecr_image_uri_prefix"",\n    return_value=""763104351884.dkr.ecr.us-west-2.amazonaws.com"",\n)\ndef test_deploy_config_from_framework_estimator(ecr_prefix, sagemaker_session):\n    mxnet_estimator = mxnet.MXNet(\n        entry_point=""{{ entry_point }}"",\n        source_dir=""{{ source_dir }}"",\n        py_version=""py3"",\n        framework_version=""1.6.0"",\n        role=""{{ role }}"",\n        train_instance_count=1,\n        train_instance_type=""ml.m4.xlarge"",\n        sagemaker_session=sagemaker_session,\n        base_job_name=""{{ base_job_name }}"",\n        hyperparameters={""batch_size"": 100},\n    )\n\n    train_data = ""{{ train_data }}""\n\n    # simulate training\n    airflow.training_config(mxnet_estimator, train_data)\n\n    config = airflow.deploy_config_from_estimator(\n        estimator=mxnet_estimator,\n        task_id=""task_id"",\n        task_type=""training"",\n        initial_instance_count=""{{ instance_count}}"",\n        instance_type=""ml.c4.large"",\n        endpoint_name=""mxnet-endpoint"",\n    )\n    expected_config = {\n        ""Model"": {\n            ""ModelName"": ""mxnet-inference-%s"" % TIME_STAMP,\n            ""PrimaryContainer"": {\n                ""Image"": ""763104351884.dkr.ecr.us-west-2.amazonaws.com/mxnet-inference:1.6.0-cpu-py3"",\n                ""Environment"": {\n                    ""SAGEMAKER_PROGRAM"": ""{{ entry_point }}"",\n                    ""SAGEMAKER_SUBMIT_DIRECTORY"": ""s3://output/{{ ti.xcom_pull(task_ids=\'task_id\')[\'Training\']""\n                    ""[\'TrainingJobName\'] }}/source/sourcedir.tar.gz"",\n                    ""SAGEMAKER_ENABLE_CLOUDWATCH_METRICS"": ""false"",\n                    ""SAGEMAKER_CONTAINER_LOG_LEVEL"": ""20"",\n                    ""SAGEMAKER_REGION"": ""us-west-2"",\n                },\n                ""ModelDataUrl"": ""s3://output/{{ ti.xcom_pull(task_ids=\'task_id\')[\'Training\'][\'TrainingJobName\'] }}""\n                ""/output/model.tar.gz"",\n            },\n            ""ExecutionRoleArn"": ""{{ role }}"",\n        },\n        ""EndpointConfig"": {\n            ""EndpointConfigName"": ""mxnet-inference-%s"" % TIME_STAMP,\n            ""ProductionVariants"": [\n                {\n                    ""InstanceType"": ""ml.c4.large"",\n                    ""InitialInstanceCount"": ""{{ instance_count}}"",\n                    ""ModelName"": ""mxnet-inference-%s"" % TIME_STAMP,\n                    ""VariantName"": ""AllTraffic"",\n                    ""InitialVariantWeight"": 1,\n                }\n            ],\n        },\n        ""Endpoint"": {\n            ""EndpointName"": ""mxnet-endpoint"",\n            ""EndpointConfigName"": ""mxnet-inference-%s"" % TIME_STAMP,\n        },\n    }\n\n    assert config == expected_config\n\n\n@patch(""sagemaker.utils.sagemaker_timestamp"", MagicMock(return_value=TIME_STAMP))\ndef test_deploy_config_from_amazon_alg_estimator(sagemaker_session):\n    knn_estimator = knn.KNN(\n        role=""{{ role }}"",\n        train_instance_count=""{{ instance_count }}"",\n        train_instance_type=""ml.m4.xlarge"",\n        k=16,\n        sample_size=128,\n        predictor_type=""regressor"",\n        sagemaker_session=sagemaker_session,\n    )\n\n    record = amazon_estimator.RecordSet(""{{ record }}"", 10000, 100, ""S3Prefix"")\n\n    # simulate training\n    airflow.training_config(knn_estimator, record, mini_batch_size=256)\n\n    config = airflow.deploy_config_from_estimator(\n        estimator=knn_estimator,\n        task_id=""task_id"",\n        task_type=""tuning"",\n        initial_instance_count=""{{ instance_count }}"",\n        instance_type=""ml.p2.xlarge"",\n    )\n    expected_config = {\n        ""Model"": {\n            ""ModelName"": ""knn-%s"" % TIME_STAMP,\n            ""PrimaryContainer"": {\n                ""Image"": ""174872318107.dkr.ecr.us-west-2.amazonaws.com/knn:1"",\n                ""Environment"": {},\n                ""ModelDataUrl"": ""s3://output/{{ ti.xcom_pull(task_ids=\'task_id\')[\'Tuning\'][\'BestTrainingJob\']""\n                ""[\'TrainingJobName\'] }}/output/model.tar.gz"",\n            },\n            ""ExecutionRoleArn"": ""{{ role }}"",\n        },\n        ""EndpointConfig"": {\n            ""EndpointConfigName"": ""knn-%s"" % TIME_STAMP,\n            ""ProductionVariants"": [\n                {\n                    ""InstanceType"": ""ml.p2.xlarge"",\n                    ""InitialInstanceCount"": ""{{ instance_count }}"",\n                    ""ModelName"": ""knn-%s"" % TIME_STAMP,\n                    ""VariantName"": ""AllTraffic"",\n                    ""InitialVariantWeight"": 1,\n                }\n            ],\n        },\n        ""Endpoint"": {\n            ""EndpointName"": ""knn-%s"" % TIME_STAMP,\n            ""EndpointConfigName"": ""knn-%s"" % TIME_STAMP,\n        },\n    }\n\n    assert config == expected_config\n'"
tests/unit/test_algorithm.py,0,"b'# Copyright 2018-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport copy\nimport datetime\n\nimport pytest\nfrom mock import Mock, patch\n\nfrom sagemaker.algorithm import AlgorithmEstimator\nfrom sagemaker.estimator import _TrainingJob\nfrom sagemaker.transformer import Transformer\n\nDESCRIBE_ALGORITHM_RESPONSE = {\n    ""AlgorithmName"": ""scikit-decision-trees"",\n    ""AlgorithmArn"": ""arn:aws:sagemaker:us-east-2:1234:algorithm/scikit-decision-trees"",\n    ""AlgorithmDescription"": ""Decision trees using Scikit"",\n    ""CreationTime"": datetime.datetime(2018, 8, 3, 22, 44, 54, 437000),\n    ""TrainingSpecification"": {\n        ""TrainingImage"": ""123.dkr.ecr.us-east-2.amazonaws.com/decision-trees-sample@sha256:12345"",\n        ""TrainingImageDigest"": ""sha256:206854b6ea2f0020d216311da732010515169820b898ec29720bcf1d2b46806a"",\n        ""SupportedHyperParameters"": [\n            {\n                ""Name"": ""max_leaf_nodes"",\n                ""Description"": ""Grow a tree with max_leaf_nodes in best-first fashion."",\n                ""Type"": ""Integer"",\n                ""Range"": {\n                    ""IntegerParameterRangeSpecification"": {""MinValue"": ""1"", ""MaxValue"": ""100000""}\n                },\n                ""IsTunable"": True,\n                ""IsRequired"": False,\n                ""DefaultValue"": ""100"",\n            },\n            {\n                ""Name"": ""free_text_hp1"",\n                ""Description"": ""You can write anything here"",\n                ""Type"": ""FreeText"",\n                ""IsTunable"": False,\n                ""IsRequired"": True,\n            },\n        ],\n        ""SupportedTrainingInstanceTypes"": [""ml.m4.xlarge"", ""ml.m4.2xlarge"", ""ml.m4.4xlarge""],\n        ""SupportsDistributedTraining"": False,\n        ""MetricDefinitions"": [\n            {""Name"": ""validation:accuracy"", ""Regex"": ""validation-accuracy: (\\\\S+)""}\n        ],\n        ""TrainingChannels"": [\n            {\n                ""Name"": ""training"",\n                ""Description"": ""Input channel that provides training data"",\n                ""IsRequired"": True,\n                ""SupportedContentTypes"": [""text/csv""],\n                ""SupportedCompressionTypes"": [""None""],\n                ""SupportedInputModes"": [""File""],\n            }\n        ],\n        ""SupportedTuningJobObjectiveMetrics"": [\n            {""Type"": ""Maximize"", ""MetricName"": ""validation:accuracy""}\n        ],\n    },\n    ""InferenceSpecification"": {\n        ""InferenceImage"": ""123.dkr.ecr.us-east-2.amazonaws.com/decision-trees-sample@sha256:123"",\n        ""SupportedTransformInstanceTypes"": [""ml.m4.xlarge"", ""ml.m4.2xlarge""],\n        ""SupportedContentTypes"": [""text/csv""],\n        ""SupportedResponseMIMETypes"": [""text""],\n    },\n    ""ValidationSpecification"": {\n        ""ValidationRole"": ""arn:aws:iam::764419575721:role/SageMakerRole"",\n        ""ValidationProfiles"": [\n            {\n                ""ProfileName"": ""ValidationProfile1"",\n                ""TrainingJobDefinition"": {\n                    ""TrainingInputMode"": ""File"",\n                    ""HyperParameters"": {},\n                    ""InputDataConfig"": [\n                        {\n                            ""ChannelName"": ""training"",\n                            ""DataSource"": {\n                                ""S3DataSource"": {\n                                    ""S3DataType"": ""S3Prefix"",\n                                    ""S3Uri"": ""s3://sagemaker-us-east-2-7123/-scikit-byo-iris/training-input-data"",\n                                    ""S3DataDistributionType"": ""FullyReplicated"",\n                                }\n                            },\n                            ""ContentType"": ""text/csv"",\n                            ""CompressionType"": ""None"",\n                            ""RecordWrapperType"": ""None"",\n                        }\n                    ],\n                    ""OutputDataConfig"": {\n                        ""KmsKeyId"": """",\n                        ""S3OutputPath"": ""s3://sagemaker-us-east-2-764419575721/DEMO-scikit-byo-iris/training-output"",\n                    },\n                    ""ResourceConfig"": {\n                        ""InstanceType"": ""ml.c4.xlarge"",\n                        ""InstanceCount"": 1,\n                        ""VolumeSizeInGB"": 10,\n                    },\n                    ""StoppingCondition"": {""MaxRuntimeInSeconds"": 3600},\n                },\n                ""TransformJobDefinition"": {\n                    ""MaxConcurrentTransforms"": 0,\n                    ""MaxPayloadInMB"": 0,\n                    ""TransformInput"": {\n                        ""DataSource"": {\n                            ""S3DataSource"": {\n                                ""S3DataType"": ""S3Prefix"",\n                                ""S3Uri"": ""s3://sagemaker-us-east-2/scikit-byo-iris/batch-inference/transform_test.csv"",\n                            }\n                        },\n                        ""ContentType"": ""text/csv"",\n                        ""CompressionType"": ""None"",\n                        ""SplitType"": ""Line"",\n                    },\n                    ""TransformOutput"": {\n                        ""S3OutputPath"": ""s3://sagemaker-us-east-2-764419575721/scikit-byo-iris/batch-transform-output"",\n                        ""Accept"": ""text/csv"",\n                        ""AssembleWith"": ""Line"",\n                        ""KmsKeyId"": """",\n                    },\n                    ""TransformResources"": {""InstanceType"": ""ml.c4.xlarge"", ""InstanceCount"": 1},\n                },\n            }\n        ],\n        ""ValidationOutputS3Prefix"": ""s3://sagemaker-us-east-2-764419575721/DEMO-scikit-byo-iris/validation-output"",\n        ""ValidateForMarketplace"": True,\n    },\n    ""AlgorithmStatus"": ""Completed"",\n    ""AlgorithmStatusDetails"": {\n        ""ValidationStatuses"": [{""ProfileName"": ""ValidationProfile1"", ""Status"": ""Completed""}]\n    },\n    ""ResponseMetadata"": {\n        ""RequestId"": ""e04bc28b-61b6-4486-9106-0edf07f5649c"",\n        ""HTTPStatusCode"": 200,\n        ""HTTPHeaders"": {\n            ""x-amzn-requestid"": ""e04bc28b-61b6-4486-9106-0edf07f5649c"",\n            ""content-type"": ""application/x-amz-json-1.1"",\n            ""content-length"": ""3949"",\n            ""date"": ""Fri, 03 Aug 2018 23:08:43 GMT"",\n        },\n        ""RetryAttempts"": 0,\n    },\n}\n\n\n@patch(""sagemaker.Session"")\ndef test_algorithm_supported_input_mode_with_valid_input_types(session):\n    # verify that the Estimator verifies the\n    # input mode that an Algorithm supports.\n\n    file_mode_algo = copy.deepcopy(DESCRIBE_ALGORITHM_RESPONSE)\n    file_mode_algo[""TrainingSpecification""][""TrainingChannels""] = [\n        {\n            ""Name"": ""training"",\n            ""Description"": ""Input channel that provides training data"",\n            ""IsRequired"": True,\n            ""SupportedContentTypes"": [""text/csv""],\n            ""SupportedCompressionTypes"": [""None""],\n            ""SupportedInputModes"": [""File""],\n        },\n        {\n            ""Name"": ""validation"",\n            ""Description"": ""Input channel that provides validation data"",\n            ""IsRequired"": False,\n            ""SupportedContentTypes"": [""text/csv""],\n            ""SupportedCompressionTypes"": [""None""],\n            ""SupportedInputModes"": [""File"", ""Pipe""],\n        },\n    ]\n\n    session.sagemaker_client.describe_algorithm = Mock(return_value=file_mode_algo)\n\n    # Creating a File mode Estimator with a File mode algorithm should work\n    AlgorithmEstimator(\n        algorithm_arn=""arn:aws:sagemaker:us-east-2:1234:algorithm/scikit-decision-trees"",\n        role=""SageMakerRole"",\n        train_instance_type=""ml.m4.xlarge"",\n        train_instance_count=1,\n        sagemaker_session=session,\n    )\n\n    pipe_mode_algo = copy.deepcopy(DESCRIBE_ALGORITHM_RESPONSE)\n    pipe_mode_algo[""TrainingSpecification""][""TrainingChannels""] = [\n        {\n            ""Name"": ""training"",\n            ""Description"": ""Input channel that provides training data"",\n            ""IsRequired"": True,\n            ""SupportedContentTypes"": [""text/csv""],\n            ""SupportedCompressionTypes"": [""None""],\n            ""SupportedInputModes"": [""Pipe""],\n        },\n        {\n            ""Name"": ""validation"",\n            ""Description"": ""Input channel that provides validation data"",\n            ""IsRequired"": False,\n            ""SupportedContentTypes"": [""text/csv""],\n            ""SupportedCompressionTypes"": [""None""],\n            ""SupportedInputModes"": [""File"", ""Pipe""],\n        },\n    ]\n\n    session.sagemaker_client.describe_algorithm = Mock(return_value=pipe_mode_algo)\n\n    # Creating a Pipe mode Estimator with a Pipe mode algorithm should work.\n    AlgorithmEstimator(\n        algorithm_arn=""arn:aws:sagemaker:us-east-2:1234:algorithm/scikit-decision-trees"",\n        role=""SageMakerRole"",\n        train_instance_type=""ml.m4.xlarge"",\n        train_instance_count=1,\n        input_mode=""Pipe"",\n        sagemaker_session=session,\n    )\n\n    any_input_algo = copy.deepcopy(DESCRIBE_ALGORITHM_RESPONSE)\n    any_input_algo[""TrainingSpecification""][""TrainingChannels""] = [\n        {\n            ""Name"": ""training"",\n            ""Description"": ""Input channel that provides training data"",\n            ""IsRequired"": True,\n            ""SupportedContentTypes"": [""text/csv""],\n            ""SupportedCompressionTypes"": [""None""],\n            ""SupportedInputModes"": [""File"", ""Pipe""],\n        },\n        {\n            ""Name"": ""validation"",\n            ""Description"": ""Input channel that provides validation data"",\n            ""IsRequired"": False,\n            ""SupportedContentTypes"": [""text/csv""],\n            ""SupportedCompressionTypes"": [""None""],\n            ""SupportedInputModes"": [""File"", ""Pipe""],\n        },\n    ]\n\n    session.sagemaker_client.describe_algorithm = Mock(return_value=any_input_algo)\n\n    # Creating a File mode Estimator with an algorithm that supports both input modes\n    # should work.\n    AlgorithmEstimator(\n        algorithm_arn=""arn:aws:sagemaker:us-east-2:1234:algorithm/scikit-decision-trees"",\n        role=""SageMakerRole"",\n        train_instance_type=""ml.m4.xlarge"",\n        train_instance_count=1,\n        sagemaker_session=session,\n    )\n\n\n@patch(""sagemaker.Session"")\ndef test_algorithm_supported_input_mode_with_bad_input_types(session):\n    # verify that the Estimator verifies raises exceptions when\n    # attempting to train with an incorrect input type\n\n    file_mode_algo = copy.deepcopy(DESCRIBE_ALGORITHM_RESPONSE)\n    file_mode_algo[""TrainingSpecification""][""TrainingChannels""] = [\n        {\n            ""Name"": ""training"",\n            ""Description"": ""Input channel that provides training data"",\n            ""IsRequired"": True,\n            ""SupportedContentTypes"": [""text/csv""],\n            ""SupportedCompressionTypes"": [""None""],\n            ""SupportedInputModes"": [""File""],\n        },\n        {\n            ""Name"": ""validation"",\n            ""Description"": ""Input channel that provides validation data"",\n            ""IsRequired"": False,\n            ""SupportedContentTypes"": [""text/csv""],\n            ""SupportedCompressionTypes"": [""None""],\n            ""SupportedInputModes"": [""File"", ""Pipe""],\n        },\n    ]\n\n    session.sagemaker_client.describe_algorithm = Mock(return_value=file_mode_algo)\n\n    # Creating a Pipe mode Estimator with a File mode algorithm should fail.\n    with pytest.raises(ValueError):\n        AlgorithmEstimator(\n            algorithm_arn=""arn:aws:sagemaker:us-east-2:1234:algorithm/scikit-decision-trees"",\n            role=""SageMakerRole"",\n            train_instance_type=""ml.m4.xlarge"",\n            train_instance_count=1,\n            input_mode=""Pipe"",\n            sagemaker_session=session,\n        )\n\n    pipe_mode_algo = copy.deepcopy(DESCRIBE_ALGORITHM_RESPONSE)\n    pipe_mode_algo[""TrainingSpecification""][""TrainingChannels""] = [\n        {\n            ""Name"": ""training"",\n            ""Description"": ""Input channel that provides training data"",\n            ""IsRequired"": True,\n            ""SupportedContentTypes"": [""text/csv""],\n            ""SupportedCompressionTypes"": [""None""],\n            ""SupportedInputModes"": [""Pipe""],\n        },\n        {\n            ""Name"": ""validation"",\n            ""Description"": ""Input channel that provides validation data"",\n            ""IsRequired"": False,\n            ""SupportedContentTypes"": [""text/csv""],\n            ""SupportedCompressionTypes"": [""None""],\n            ""SupportedInputModes"": [""File"", ""Pipe""],\n        },\n    ]\n\n    session.sagemaker_client.describe_algorithm = Mock(return_value=pipe_mode_algo)\n\n    # Creating a File mode Estimator with a Pipe mode algorithm should fail.\n    with pytest.raises(ValueError):\n        AlgorithmEstimator(\n            algorithm_arn=""arn:aws:sagemaker:us-east-2:1234:algorithm/scikit-decision-trees"",\n            role=""SageMakerRole"",\n            train_instance_type=""ml.m4.xlarge"",\n            train_instance_count=1,\n            sagemaker_session=session,\n        )\n\n\n@patch(""sagemaker.estimator.EstimatorBase.fit"", Mock())\n@patch(""sagemaker.Session"")\ndef test_algorithm_trainining_channels_with_expected_channels(session):\n    training_channels = copy.deepcopy(DESCRIBE_ALGORITHM_RESPONSE)\n\n    training_channels[""TrainingSpecification""][""TrainingChannels""] = [\n        {\n            ""Name"": ""training"",\n            ""Description"": ""Input channel that provides training data"",\n            ""IsRequired"": True,\n            ""SupportedContentTypes"": [""text/csv""],\n            ""SupportedCompressionTypes"": [""None""],\n            ""SupportedInputModes"": [""File""],\n        },\n        {\n            ""Name"": ""validation"",\n            ""Description"": ""Input channel that provides validation data"",\n            ""IsRequired"": False,\n            ""SupportedContentTypes"": [""text/csv""],\n            ""SupportedCompressionTypes"": [""None""],\n            ""SupportedInputModes"": [""File""],\n        },\n    ]\n\n    session.sagemaker_client.describe_algorithm = Mock(return_value=training_channels)\n\n    estimator = AlgorithmEstimator(\n        algorithm_arn=""arn:aws:sagemaker:us-east-2:1234:algorithm/scikit-decision-trees"",\n        role=""SageMakerRole"",\n        train_instance_type=""ml.m4.xlarge"",\n        train_instance_count=1,\n        sagemaker_session=session,\n    )\n\n    # Pass training and validation channels. This should work\n    estimator.fit({""training"": ""s3://some/place"", ""validation"": ""s3://some/other""})\n\n    # Passing only the training channel. Validation is optional so this should also work.\n    estimator.fit({""training"": ""s3://some/place""})\n\n\n@patch(""sagemaker.estimator.EstimatorBase.fit"", Mock())\n@patch(""sagemaker.Session"")\ndef test_algorithm_trainining_channels_with_invalid_channels(session):\n    training_channels = copy.deepcopy(DESCRIBE_ALGORITHM_RESPONSE)\n\n    training_channels[""TrainingSpecification""][""TrainingChannels""] = [\n        {\n            ""Name"": ""training"",\n            ""Description"": ""Input channel that provides training data"",\n            ""IsRequired"": True,\n            ""SupportedContentTypes"": [""text/csv""],\n            ""SupportedCompressionTypes"": [""None""],\n            ""SupportedInputModes"": [""File""],\n        },\n        {\n            ""Name"": ""validation"",\n            ""Description"": ""Input channel that provides validation data"",\n            ""IsRequired"": False,\n            ""SupportedContentTypes"": [""text/csv""],\n            ""SupportedCompressionTypes"": [""None""],\n            ""SupportedInputModes"": [""File""],\n        },\n    ]\n\n    session.sagemaker_client.describe_algorithm = Mock(return_value=training_channels)\n\n    estimator = AlgorithmEstimator(\n        algorithm_arn=""arn:aws:sagemaker:us-east-2:1234:algorithm/scikit-decision-trees"",\n        role=""SageMakerRole"",\n        train_instance_type=""ml.m4.xlarge"",\n        train_instance_count=1,\n        sagemaker_session=session,\n    )\n\n    # Passing only validation should fail as training is required.\n    with pytest.raises(ValueError):\n        estimator.fit({""validation"": ""s3://some/thing""})\n\n    # Passing an unknown channel should fail???\n    with pytest.raises(ValueError):\n        estimator.fit({""training"": ""s3://some/data"", ""training2"": ""s3://some/other/data""})\n\n\n@patch(""sagemaker.Session"")\ndef test_algorithm_train_instance_types_valid_instance_types(session):\n    describe_algo_response = copy.deepcopy(DESCRIBE_ALGORITHM_RESPONSE)\n    train_instance_types = [""ml.m4.xlarge"", ""ml.m5.2xlarge""]\n\n    describe_algo_response[""TrainingSpecification""][\n        ""SupportedTrainingInstanceTypes""\n    ] = train_instance_types\n\n    session.sagemaker_client.describe_algorithm = Mock(return_value=describe_algo_response)\n\n    AlgorithmEstimator(\n        algorithm_arn=""arn:aws:sagemaker:us-east-2:1234:algorithm/scikit-decision-trees"",\n        role=""SageMakerRole"",\n        train_instance_type=""ml.m4.xlarge"",\n        train_instance_count=1,\n        sagemaker_session=session,\n    )\n\n    AlgorithmEstimator(\n        algorithm_arn=""arn:aws:sagemaker:us-east-2:1234:algorithm/scikit-decision-trees"",\n        role=""SageMakerRole"",\n        train_instance_type=""ml.m5.2xlarge"",\n        train_instance_count=1,\n        sagemaker_session=session,\n    )\n\n\n@patch(""sagemaker.Session"")\ndef test_algorithm_train_instance_types_invalid_instance_types(session):\n    describe_algo_response = copy.deepcopy(DESCRIBE_ALGORITHM_RESPONSE)\n    train_instance_types = [""ml.m4.xlarge"", ""ml.m5.2xlarge""]\n\n    describe_algo_response[""TrainingSpecification""][\n        ""SupportedTrainingInstanceTypes""\n    ] = train_instance_types\n\n    session.sagemaker_client.describe_algorithm = Mock(return_value=describe_algo_response)\n\n    # invalid instance type, should fail\n    with pytest.raises(ValueError):\n        AlgorithmEstimator(\n            algorithm_arn=""arn:aws:sagemaker:us-east-2:1234:algorithm/scikit-decision-trees"",\n            role=""SageMakerRole"",\n            train_instance_type=""ml.m4.8xlarge"",\n            train_instance_count=1,\n            sagemaker_session=session,\n        )\n\n\n@patch(""sagemaker.Session"")\ndef test_algorithm_distributed_training_validation(session):\n    distributed_algo = copy.deepcopy(DESCRIBE_ALGORITHM_RESPONSE)\n    distributed_algo[""TrainingSpecification""][""SupportsDistributedTraining""] = True\n\n    single_instance_algo = copy.deepcopy(DESCRIBE_ALGORITHM_RESPONSE)\n    single_instance_algo[""TrainingSpecification""][""SupportsDistributedTraining""] = False\n\n    session.sagemaker_client.describe_algorithm = Mock(return_value=distributed_algo)\n\n    # Distributed training should work for Distributed and Single instance.\n    AlgorithmEstimator(\n        algorithm_arn=""arn:aws:sagemaker:us-east-2:1234:algorithm/scikit-decision-trees"",\n        role=""SageMakerRole"",\n        train_instance_type=""ml.m4.xlarge"",\n        train_instance_count=1,\n        sagemaker_session=session,\n    )\n\n    AlgorithmEstimator(\n        algorithm_arn=""arn:aws:sagemaker:us-east-2:1234:algorithm/scikit-decision-trees"",\n        role=""SageMakerRole"",\n        train_instance_type=""ml.m4.xlarge"",\n        train_instance_count=2,\n        sagemaker_session=session,\n    )\n\n    session.sagemaker_client.describe_algorithm = Mock(return_value=single_instance_algo)\n\n    # distributed training on a single instance algorithm should fail.\n    with pytest.raises(ValueError):\n        AlgorithmEstimator(\n            algorithm_arn=""arn:aws:sagemaker:us-east-2:1234:algorithm/scikit-decision-trees"",\n            role=""SageMakerRole"",\n            train_instance_type=""ml.m5.2xlarge"",\n            train_instance_count=2,\n            sagemaker_session=session,\n        )\n\n\n@patch(""sagemaker.Session"")\ndef test_algorithm_hyperparameter_integer_range_valid_range(session):\n    hyperparameters = [\n        {\n            ""Description"": ""Grow a tree with max_leaf_nodes in best-first fashion."",\n            ""Type"": ""Integer"",\n            ""Name"": ""max_leaf_nodes"",\n            ""Range"": {\n                ""IntegerParameterRangeSpecification"": {""MinValue"": ""1"", ""MaxValue"": ""100000""}\n            },\n            ""IsTunable"": True,\n            ""IsRequired"": False,\n            ""DefaultValue"": ""100"",\n        }\n    ]\n\n    some_algo = copy.deepcopy(DESCRIBE_ALGORITHM_RESPONSE)\n    some_algo[""TrainingSpecification""][""SupportedHyperParameters""] = hyperparameters\n\n    session.sagemaker_client.describe_algorithm = Mock(return_value=some_algo)\n\n    estimator = AlgorithmEstimator(\n        algorithm_arn=""arn:aws:sagemaker:us-east-2:1234:algorithm/scikit-decision-trees"",\n        role=""SageMakerRole"",\n        train_instance_type=""ml.m4.2xlarge"",\n        train_instance_count=1,\n        sagemaker_session=session,\n    )\n\n    estimator.set_hyperparameters(max_leaf_nodes=1)\n    estimator.set_hyperparameters(max_leaf_nodes=100000)\n\n\n@patch(""sagemaker.Session"")\ndef test_algorithm_hyperparameter_integer_range_invalid_range(session):\n    hyperparameters = [\n        {\n            ""Description"": ""Grow a tree with max_leaf_nodes in best-first fashion."",\n            ""Type"": ""Integer"",\n            ""Name"": ""max_leaf_nodes"",\n            ""Range"": {\n                ""IntegerParameterRangeSpecification"": {""MinValue"": ""1"", ""MaxValue"": ""100000""}\n            },\n            ""IsTunable"": True,\n            ""IsRequired"": False,\n            ""DefaultValue"": ""100"",\n        }\n    ]\n\n    some_algo = copy.deepcopy(DESCRIBE_ALGORITHM_RESPONSE)\n    some_algo[""TrainingSpecification""][""SupportedHyperParameters""] = hyperparameters\n\n    session.sagemaker_client.describe_algorithm = Mock(return_value=some_algo)\n\n    estimator = AlgorithmEstimator(\n        algorithm_arn=""arn:aws:sagemaker:us-east-2:1234:algorithm/scikit-decision-trees"",\n        role=""SageMakerRole"",\n        train_instance_type=""ml.m4.2xlarge"",\n        train_instance_count=1,\n        sagemaker_session=session,\n    )\n\n    with pytest.raises(ValueError):\n        estimator.set_hyperparameters(max_leaf_nodes=0)\n\n    with pytest.raises(ValueError):\n        estimator.set_hyperparameters(max_leaf_nodes=100001)\n\n\n@patch(""sagemaker.Session"")\ndef test_algorithm_hyperparameter_continuous_range_valid_range(session):\n    hyperparameters = [\n        {\n            ""Description"": ""A continuous hyperparameter"",\n            ""Type"": ""Continuous"",\n            ""Name"": ""max_leaf_nodes"",\n            ""Range"": {\n                ""ContinuousParameterRangeSpecification"": {""MinValue"": ""0.0"", ""MaxValue"": ""1.0""}\n            },\n            ""IsTunable"": True,\n            ""IsRequired"": False,\n            ""DefaultValue"": ""100"",\n        }\n    ]\n\n    some_algo = copy.deepcopy(DESCRIBE_ALGORITHM_RESPONSE)\n    some_algo[""TrainingSpecification""][""SupportedHyperParameters""] = hyperparameters\n\n    session.sagemaker_client.describe_algorithm = Mock(return_value=some_algo)\n\n    estimator = AlgorithmEstimator(\n        algorithm_arn=""arn:aws:sagemaker:us-east-2:1234:algorithm/scikit-decision-trees"",\n        role=""SageMakerRole"",\n        train_instance_type=""ml.m4.2xlarge"",\n        train_instance_count=1,\n        sagemaker_session=session,\n    )\n\n    estimator.set_hyperparameters(max_leaf_nodes=0)\n    estimator.set_hyperparameters(max_leaf_nodes=1.0)\n    estimator.set_hyperparameters(max_leaf_nodes=0.5)\n    estimator.set_hyperparameters(max_leaf_nodes=1)\n\n\n@patch(""sagemaker.Session"")\ndef test_algorithm_hyperparameter_continuous_range_invalid_range(session):\n    hyperparameters = [\n        {\n            ""Description"": ""A continuous hyperparameter"",\n            ""Type"": ""Continuous"",\n            ""Name"": ""max_leaf_nodes"",\n            ""Range"": {\n                ""ContinuousParameterRangeSpecification"": {""MinValue"": ""0.0"", ""MaxValue"": ""1.0""}\n            },\n            ""IsTunable"": True,\n            ""IsRequired"": False,\n            ""DefaultValue"": ""100"",\n        }\n    ]\n\n    some_algo = copy.deepcopy(DESCRIBE_ALGORITHM_RESPONSE)\n    some_algo[""TrainingSpecification""][""SupportedHyperParameters""] = hyperparameters\n\n    session.sagemaker_client.describe_algorithm = Mock(return_value=some_algo)\n\n    estimator = AlgorithmEstimator(\n        algorithm_arn=""arn:aws:sagemaker:us-east-2:1234:algorithm/scikit-decision-trees"",\n        role=""SageMakerRole"",\n        train_instance_type=""ml.m4.2xlarge"",\n        train_instance_count=1,\n        sagemaker_session=session,\n    )\n\n    with pytest.raises(ValueError):\n        estimator.set_hyperparameters(max_leaf_nodes=1.1)\n\n    with pytest.raises(ValueError):\n        estimator.set_hyperparameters(max_leaf_nodes=-0.1)\n\n\n@patch(""sagemaker.Session"")\ndef test_algorithm_hyperparameter_categorical_range(session):\n    hyperparameters = [\n        {\n            ""Description"": ""A continuous hyperparameter"",\n            ""Type"": ""Categorical"",\n            ""Name"": ""hp1"",\n            ""Range"": {""CategoricalParameterRangeSpecification"": {""Values"": [""TF"", ""MXNet""]}},\n            ""IsTunable"": True,\n            ""IsRequired"": False,\n            ""DefaultValue"": ""100"",\n        }\n    ]\n\n    some_algo = copy.deepcopy(DESCRIBE_ALGORITHM_RESPONSE)\n    some_algo[""TrainingSpecification""][""SupportedHyperParameters""] = hyperparameters\n\n    session.sagemaker_client.describe_algorithm = Mock(return_value=some_algo)\n\n    estimator = AlgorithmEstimator(\n        algorithm_arn=""arn:aws:sagemaker:us-east-2:1234:algorithm/scikit-decision-trees"",\n        role=""SageMakerRole"",\n        train_instance_type=""ml.m4.2xlarge"",\n        train_instance_count=1,\n        sagemaker_session=session,\n    )\n\n    estimator.set_hyperparameters(hp1=""MXNet"")\n    estimator.set_hyperparameters(hp1=""TF"")\n\n    with pytest.raises(ValueError):\n        estimator.set_hyperparameters(hp1=""Chainer"")\n\n    with pytest.raises(ValueError):\n        estimator.set_hyperparameters(hp1=""MxNET"")\n\n\n@patch(""sagemaker.Session"")\ndef test_algorithm_required_hyperparameters_not_provided(session):\n    hyperparameters = [\n        {\n            ""Description"": ""A continuous hyperparameter"",\n            ""Type"": ""Categorical"",\n            ""Name"": ""hp1"",\n            ""Range"": {""CategoricalParameterRangeSpecification"": {""Values"": [""TF"", ""MXNet""]}},\n            ""IsTunable"": True,\n            ""IsRequired"": True,\n        },\n        {\n            ""Name"": ""hp2"",\n            ""Description"": ""A continuous hyperparameter"",\n            ""Type"": ""Categorical"",\n            ""IsTunable"": False,\n            ""IsRequired"": True,\n        },\n    ]\n\n    some_algo = copy.deepcopy(DESCRIBE_ALGORITHM_RESPONSE)\n    some_algo[""TrainingSpecification""][""SupportedHyperParameters""] = hyperparameters\n\n    session.sagemaker_client.describe_algorithm = Mock(return_value=some_algo)\n\n    estimator = AlgorithmEstimator(\n        algorithm_arn=""arn:aws:sagemaker:us-east-2:1234:algorithm/scikit-decision-trees"",\n        role=""SageMakerRole"",\n        train_instance_type=""ml.m4.2xlarge"",\n        train_instance_count=1,\n        sagemaker_session=session,\n    )\n\n    # hp1 is required and was not provided\n    with pytest.raises(ValueError):\n        estimator.set_hyperparameters(hp2=""TF2"")\n\n    # Calling fit with unset required hyperparameters should fail\n    # this covers the use case of not calling set_hyperparameters() explicitly\n    with pytest.raises(ValueError):\n        estimator.fit({""training"": ""s3://some/place""})\n\n\n@patch(""sagemaker.Session"")\n@patch(""sagemaker.estimator.EstimatorBase.fit"", Mock())\ndef test_algorithm_required_hyperparameters_are_provided(session):\n    hyperparameters = [\n        {\n            ""Description"": ""A categorical hyperparameter"",\n            ""Type"": ""Categorical"",\n            ""Name"": ""hp1"",\n            ""Range"": {""CategoricalParameterRangeSpecification"": {""Values"": [""TF"", ""MXNet""]}},\n            ""IsTunable"": True,\n            ""IsRequired"": True,\n        },\n        {\n            ""Name"": ""hp2"",\n            ""Description"": ""A categorical hyperparameter"",\n            ""Type"": ""Categorical"",\n            ""IsTunable"": False,\n            ""IsRequired"": True,\n        },\n        {\n            ""Name"": ""free_text_hp1"",\n            ""Description"": ""You can write anything here"",\n            ""Type"": ""FreeText"",\n            ""IsTunable"": False,\n            ""IsRequired"": True,\n        },\n    ]\n\n    some_algo = copy.deepcopy(DESCRIBE_ALGORITHM_RESPONSE)\n    some_algo[""TrainingSpecification""][""SupportedHyperParameters""] = hyperparameters\n\n    session.sagemaker_client.describe_algorithm = Mock(return_value=some_algo)\n\n    estimator = AlgorithmEstimator(\n        algorithm_arn=""arn:aws:sagemaker:us-east-2:1234:algorithm/scikit-decision-trees"",\n        role=""SageMakerRole"",\n        train_instance_type=""ml.m4.2xlarge"",\n        train_instance_count=1,\n        sagemaker_session=session,\n    )\n\n    # All 3 Hyperparameters are provided\n    estimator.set_hyperparameters(hp1=""TF"", hp2=""TF2"", free_text_hp1=""Hello!"")\n\n\n@patch(""sagemaker.Session"")\ndef test_algorithm_required_free_text_hyperparameter_not_provided(session):\n    hyperparameters = [\n        {\n            ""Name"": ""free_text_hp1"",\n            ""Description"": ""You can write anything here"",\n            ""Type"": ""FreeText"",\n            ""IsTunable"": False,\n            ""IsRequired"": True,\n        },\n        {\n            ""Name"": ""free_text_hp2"",\n            ""Description"": ""You can write anything here"",\n            ""Type"": ""FreeText"",\n            ""IsTunable"": False,\n            ""IsRequired"": False,\n        },\n    ]\n\n    some_algo = copy.deepcopy(DESCRIBE_ALGORITHM_RESPONSE)\n    some_algo[""TrainingSpecification""][""SupportedHyperParameters""] = hyperparameters\n\n    session.sagemaker_client.describe_algorithm = Mock(return_value=some_algo)\n\n    estimator = AlgorithmEstimator(\n        algorithm_arn=""arn:aws:sagemaker:us-east-2:1234:algorithm/scikit-decision-trees"",\n        role=""SageMakerRole"",\n        train_instance_type=""ml.m4.2xlarge"",\n        train_instance_count=1,\n        sagemaker_session=session,\n    )\n\n    # Calling fit with unset required hyperparameters should fail\n    # this covers the use case of not calling set_hyperparameters() explicitly\n    with pytest.raises(ValueError):\n        estimator.fit({""training"": ""s3://some/place""})\n\n    # hp1 is required and was not provided\n    with pytest.raises(ValueError):\n        estimator.set_hyperparameters(free_text_hp2=""some text"")\n\n\n@patch(""sagemaker.Session"")\n@patch(""sagemaker.algorithm.AlgorithmEstimator.create_model"")\ndef test_algorithm_create_transformer(create_model, session):\n    session.sagemaker_client.describe_algorithm = Mock(return_value=DESCRIBE_ALGORITHM_RESPONSE)\n\n    estimator = AlgorithmEstimator(\n        algorithm_arn=""arn:aws:sagemaker:us-east-2:1234:algorithm/scikit-decision-trees"",\n        role=""SageMakerRole"",\n        train_instance_type=""ml.m4.xlarge"",\n        train_instance_count=1,\n        sagemaker_session=session,\n    )\n\n    estimator.latest_training_job = _TrainingJob(session, ""some-job-name"")\n    model = Mock()\n    model.name = ""my-model""\n    create_model.return_value = model\n\n    transformer = estimator.transformer(instance_count=1, instance_type=""ml.m4.xlarge"")\n\n    assert isinstance(transformer, Transformer)\n    create_model.assert_called()\n    assert transformer.model_name == ""my-model""\n\n\n@patch(""sagemaker.Session"")\ndef test_algorithm_create_transformer_without_completed_training_job(session):\n    session.sagemaker_client.describe_algorithm = Mock(return_value=DESCRIBE_ALGORITHM_RESPONSE)\n\n    estimator = AlgorithmEstimator(\n        algorithm_arn=""arn:aws:sagemaker:us-east-2:1234:algorithm/scikit-decision-trees"",\n        role=""SageMakerRole"",\n        train_instance_type=""ml.m4.xlarge"",\n        train_instance_count=1,\n        sagemaker_session=session,\n    )\n\n    with pytest.raises(RuntimeError) as error:\n        estimator.transformer(instance_count=1, instance_type=""ml.m4.xlarge"")\n        assert ""No finished training job found associated with this estimator"" in str(error)\n\n\n@patch(""sagemaker.algorithm.AlgorithmEstimator.create_model"")\n@patch(""sagemaker.Session"")\ndef test_algorithm_create_transformer_with_product_id(create_model, session):\n    response = copy.deepcopy(DESCRIBE_ALGORITHM_RESPONSE)\n    response[""ProductId""] = ""some-product-id""\n    session.sagemaker_client.describe_algorithm = Mock(return_value=response)\n\n    estimator = AlgorithmEstimator(\n        algorithm_arn=""arn:aws:sagemaker:us-east-2:1234:algorithm/scikit-decision-trees"",\n        role=""SageMakerRole"",\n        train_instance_type=""ml.m4.xlarge"",\n        train_instance_count=1,\n        sagemaker_session=session,\n    )\n\n    estimator.latest_training_job = _TrainingJob(session, ""some-job-name"")\n    model = Mock()\n    model.name = ""my-model""\n    create_model.return_value = model\n\n    transformer = estimator.transformer(instance_count=1, instance_type=""ml.m4.xlarge"")\n    assert transformer.env is None\n\n\n@patch(""sagemaker.Session"")\ndef test_algorithm_enable_network_isolation_no_product_id(session):\n    session.sagemaker_client.describe_algorithm = Mock(return_value=DESCRIBE_ALGORITHM_RESPONSE)\n\n    estimator = AlgorithmEstimator(\n        algorithm_arn=""arn:aws:sagemaker:us-east-2:1234:algorithm/scikit-decision-trees"",\n        role=""SageMakerRole"",\n        train_instance_type=""ml.m4.xlarge"",\n        train_instance_count=1,\n        sagemaker_session=session,\n    )\n\n    network_isolation = estimator.enable_network_isolation()\n    assert network_isolation is False\n\n\n@patch(""sagemaker.Session"")\ndef test_algorithm_enable_network_isolation_with_product_id(session):\n    response = copy.deepcopy(DESCRIBE_ALGORITHM_RESPONSE)\n    response[""ProductId""] = ""some-product-id""\n    session.sagemaker_client.describe_algorithm = Mock(return_value=response)\n\n    estimator = AlgorithmEstimator(\n        algorithm_arn=""arn:aws:sagemaker:us-east-2:1234:algorithm/scikit-decision-trees"",\n        role=""SageMakerRole"",\n        train_instance_type=""ml.m4.xlarge"",\n        train_instance_count=1,\n        sagemaker_session=session,\n    )\n\n    network_isolation = estimator.enable_network_isolation()\n    assert network_isolation is True\n\n\n@patch(""sagemaker.Session"")\ndef test_algorithm_encrypt_inter_container_traffic(session):\n    response = copy.deepcopy(DESCRIBE_ALGORITHM_RESPONSE)\n    response[""encrypt_inter_container_traffic""] = True\n    session.sagemaker_client.describe_algorithm = Mock(return_value=response)\n\n    estimator = AlgorithmEstimator(\n        algorithm_arn=""arn:aws:sagemaker:us-east-2:1234:algorithm/scikit-decision-trees"",\n        role=""SageMakerRole"",\n        train_instance_type=""ml.m4.xlarge"",\n        train_instance_count=1,\n        sagemaker_session=session,\n        encrypt_inter_container_traffic=True,\n    )\n\n    encrypt_inter_container_traffic = estimator.encrypt_inter_container_traffic\n    assert encrypt_inter_container_traffic is True\n\n\n@patch(""sagemaker.Session"")\ndef test_algorithm_no_required_hyperparameters(session):\n    some_algo = copy.deepcopy(DESCRIBE_ALGORITHM_RESPONSE)\n    del some_algo[""TrainingSpecification""][""SupportedHyperParameters""]\n\n    session.sagemaker_client.describe_algorithm = Mock(return_value=some_algo)\n\n    # Calling AlgorithmEstimator() with unset required hyperparameters\n    # should fail if they are required.\n    # Pass training and hyperparameters channels. This should work\n    assert AlgorithmEstimator(\n        algorithm_arn=""arn:aws:sagemaker:us-east-2:1234:algorithm/scikit-decision-trees"",\n        role=""SageMakerRole"",\n        train_instance_type=""ml.m4.2xlarge"",\n        train_instance_count=1,\n        sagemaker_session=session,\n    )\n\n\ndef test_algorithm_attach_from_hyperparameter_tuning():\n    session = Mock()\n    job_name = ""training-job-that-is-part-of-a-tuning-job""\n    algo_arn = ""arn:aws:sagemaker:us-east-2:000000000000:algorithm/scikit-decision-trees""\n    role_arn = ""arn:aws:iam::123412341234:role/SageMakerRole""\n    instance_count = 1\n    instance_type = ""ml.m4.xlarge""\n    train_volume_size = 30\n    input_mode = ""File""\n\n    session.sagemaker_client.list_tags.return_value = {""Tags"": []}\n    session.sagemaker_client.describe_algorithm.return_value = DESCRIBE_ALGORITHM_RESPONSE\n    session.sagemaker_client.describe_training_job.return_value = {\n        ""TrainingJobName"": job_name,\n        ""TrainingJobArn"": ""arn:aws:sagemaker:us-east-2:123412341234:training-job/%s"" % job_name,\n        ""TuningJobArn"": ""arn:aws:sagemaker:us-east-2:123412341234:hyper-parameter-tuning-job/%s""\n        % job_name,\n        ""ModelArtifacts"": {\n            ""S3ModelArtifacts"": ""s3://sagemaker-us-east-2-123412341234/output/model.tar.gz""\n        },\n        ""TrainingJobOutput"": {\n            ""S3TrainingJobOutput"": ""s3://sagemaker-us-east-2-123412341234/output/output.tar.gz""\n        },\n        ""TrainingJobStatus"": ""Succeeded"",\n        ""HyperParameters"": {\n            ""_tuning_objective_metric"": ""validation:accuracy"",\n            ""max_leaf_nodes"": 1,\n            ""free_text_hp1"": ""foo"",\n        },\n        ""AlgorithmSpecification"": {""AlgorithmName"": algo_arn, ""TrainingInputMode"": input_mode},\n        ""MetricDefinitions"": [\n            {""Name"": ""validation:accuracy"", ""Regex"": ""validation-accuracy: (\\\\S+)""}\n        ],\n        ""RoleArn"": role_arn,\n        ""InputDataConfig"": [\n            {\n                ""ChannelName"": ""training"",\n                ""DataSource"": {\n                    ""S3DataSource"": {\n                        ""S3DataType"": ""S3Prefix"",\n                        ""S3Uri"": ""s3://sagemaker-us-east-2-123412341234/input/training.csv"",\n                        ""S3DataDistributionType"": ""FullyReplicated"",\n                    }\n                },\n                ""CompressionType"": ""None"",\n                ""RecordWrapperType"": ""None"",\n            }\n        ],\n        ""OutputDataConfig"": {\n            ""KmsKeyId"": """",\n            ""S3OutputPath"": ""s3://sagemaker-us-east-2-123412341234/output"",\n            ""RemoveJobNameFromS3OutputPath"": False,\n        },\n        ""ResourceConfig"": {\n            ""InstanceType"": instance_type,\n            ""InstanceCount"": instance_count,\n            ""VolumeSizeInGB"": train_volume_size,\n        },\n        ""StoppingCondition"": {""MaxRuntimeInSeconds"": 86400},\n    }\n\n    estimator = AlgorithmEstimator.attach(job_name, sagemaker_session=session)\n    assert estimator.hyperparameters() == {""max_leaf_nodes"": 1, ""free_text_hp1"": ""foo""}\n    assert estimator.algorithm_arn == algo_arn\n    assert estimator.role == role_arn\n    assert estimator.train_instance_count == instance_count\n    assert estimator.train_instance_type == instance_type\n    assert estimator.train_volume_size == train_volume_size\n    assert estimator.input_mode == input_mode\n    assert estimator.sagemaker_session == session\n'"
tests/unit/test_amazon_estimator.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport numpy as np\nimport pytest\nfrom mock import ANY, Mock, patch, call\n\n# Use PCA as a test implementation of AmazonAlgorithmEstimator\nfrom sagemaker.amazon.pca import PCA\nfrom sagemaker.amazon.amazon_estimator import (\n    upload_numpy_to_s3_shards,\n    _build_shards,\n    registry,\n    get_image_uri,\n    FileSystemRecordSet,\n    _is_latest_xgboost_version,\n)\nfrom sagemaker.xgboost.defaults import XGBOOST_LATEST_VERSION, XGBOOST_SUPPORTED_VERSIONS\n\nCOMMON_ARGS = {""role"": ""myrole"", ""train_instance_count"": 1, ""train_instance_type"": ""ml.c4.xlarge""}\n\nREGION = ""us-west-2""\nBUCKET_NAME = ""Some-Bucket""\nTIMESTAMP = ""2017-11-06-14:14:15.671""\n\n\n@pytest.fixture()\ndef sagemaker_session():\n    boto_mock = Mock(name=""boto_session"", region_name=REGION)\n    sms = Mock(\n        name=""sagemaker_session"",\n        boto_session=boto_mock,\n        region_name=REGION,\n        config=None,\n        local_mode=False,\n    )\n    sms.boto_region_name = REGION\n    sms.default_bucket = Mock(name=""default_bucket"", return_value=BUCKET_NAME)\n    returned_job_description = {\n        ""AlgorithmSpecification"": {\n            ""TrainingInputMode"": ""File"",\n            ""TrainingImage"": registry(""us-west-2"") + ""/pca:1"",\n        },\n        ""ModelArtifacts"": {""S3ModelArtifacts"": ""s3://some-bucket/model.tar.gz""},\n        ""HyperParameters"": {\n            ""sagemaker_submit_directory"": \'""s3://some/sourcedir.tar.gz""\',\n            ""checkpoint_path"": \'""s3://other/1508872349""\',\n            ""sagemaker_program"": \'""iris-dnn-classifier.py""\',\n            ""sagemaker_enable_cloudwatch_metrics"": ""false"",\n            ""sagemaker_container_log_level"": \'""logging.INFO""\',\n            ""sagemaker_job_name"": \'""neo""\',\n            ""training_steps"": ""100"",\n        },\n        ""RoleArn"": ""arn:aws:iam::366:role/IMRole"",\n        ""ResourceConfig"": {\n            ""VolumeSizeInGB"": 30,\n            ""InstanceCount"": 1,\n            ""InstanceType"": ""ml.c4.xlarge"",\n        },\n        ""StoppingCondition"": {""MaxRuntimeInSeconds"": 24 * 60 * 60},\n        ""TrainingJobName"": ""neo"",\n        ""TrainingJobStatus"": ""Completed"",\n        ""OutputDataConfig"": {""KmsKeyId"": """", ""S3OutputPath"": ""s3://place/output/neo""},\n        ""TrainingJobOutput"": {""S3TrainingJobOutput"": ""s3://here/output.tar.gz""},\n    }\n    sms.sagemaker_client.describe_training_job = Mock(\n        name=""describe_training_job"", return_value=returned_job_description\n    )\n    return sms\n\n\ndef test_gov_ecr_uri():\n    assert (\n        get_image_uri(""us-gov-west-1"", ""kmeans"", ""latest"")\n        == ""226302683700.dkr.ecr.us-gov-west-1.amazonaws.com/kmeans:latest""\n    )\n\n    assert (\n        get_image_uri(""us-iso-east-1"", ""kmeans"", ""latest"")\n        == ""490574956308.dkr.ecr.us-iso-east-1.c2s.ic.gov/kmeans:latest""\n    )\n\n\ndef test_init(sagemaker_session):\n    pca = PCA(num_components=55, sagemaker_session=sagemaker_session, **COMMON_ARGS)\n    assert pca.num_components == 55\n    assert pca.enable_network_isolation() is False\n\n\ndef test_init_enable_network_isolation(sagemaker_session):\n    pca = PCA(\n        num_components=55,\n        sagemaker_session=sagemaker_session,\n        enable_network_isolation=True,\n        **COMMON_ARGS\n    )\n    assert pca.num_components == 55\n    assert pca.enable_network_isolation() is True\n\n\ndef test_init_all_pca_hyperparameters(sagemaker_session):\n    pca = PCA(\n        num_components=55,\n        algorithm_mode=""randomized"",\n        subtract_mean=True,\n        extra_components=33,\n        sagemaker_session=sagemaker_session,\n        **COMMON_ARGS\n    )\n    assert pca.num_components == 55\n    assert pca.algorithm_mode == ""randomized""\n    assert pca.extra_components == 33\n\n\ndef test_init_estimator_args(sagemaker_session):\n    pca = PCA(\n        num_components=1,\n        train_max_run=1234,\n        sagemaker_session=sagemaker_session,\n        data_location=""s3://some-bucket/some-key/"",\n        **COMMON_ARGS\n    )\n    assert pca.train_instance_type == COMMON_ARGS[""train_instance_type""]\n    assert pca.train_instance_count == COMMON_ARGS[""train_instance_count""]\n    assert pca.role == COMMON_ARGS[""role""]\n    assert pca.train_max_run == 1234\n    assert pca.data_location == ""s3://some-bucket/some-key/""\n\n\ndef test_data_location_validation(sagemaker_session):\n    pca = PCA(num_components=2, sagemaker_session=sagemaker_session, **COMMON_ARGS)\n    with pytest.raises(ValueError):\n        pca.data_location = ""nots3://abcd/efgh""\n\n\ndef test_data_location_does_not_call_default_bucket(sagemaker_session):\n    data_location = ""s3://my-bucket/path/""\n    pca = PCA(\n        num_components=2,\n        sagemaker_session=sagemaker_session,\n        data_location=data_location,\n        **COMMON_ARGS\n    )\n    assert pca.data_location == data_location\n    assert not sagemaker_session.default_bucket.called\n\n\ndef test_prepare_for_training(sagemaker_session):\n    pca = PCA(num_components=55, sagemaker_session=sagemaker_session, **COMMON_ARGS)\n\n    train = [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 8.0], [44.0, 55.0, 66.0]]\n    labels = [99, 85, 87, 2]\n    records = pca.record_set(np.array(train), np.array(labels))\n\n    pca._prepare_for_training(records, mini_batch_size=1)\n    assert pca.feature_dim == 3\n    assert pca.mini_batch_size == 1\n\n\ndef test_prepare_for_training_list(sagemaker_session):\n    pca = PCA(num_components=55, sagemaker_session=sagemaker_session, **COMMON_ARGS)\n\n    train = [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 8.0], [44.0, 55.0, 66.0]]\n    labels = [99, 85, 87, 2]\n    records = [pca.record_set(np.array(train), np.array(labels))]\n\n    pca._prepare_for_training(records, mini_batch_size=1)\n    assert pca.feature_dim == 3\n    assert pca.mini_batch_size == 1\n\n\ndef test_prepare_for_training_list_no_train_channel(sagemaker_session):\n    pca = PCA(num_components=55, sagemaker_session=sagemaker_session, **COMMON_ARGS)\n\n    train = [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 8.0], [44.0, 55.0, 66.0]]\n    labels = [99, 85, 87, 2]\n    records = [pca.record_set(np.array(train), np.array(labels), ""test"")]\n\n    with pytest.raises(ValueError) as ex:\n        pca._prepare_for_training(records, mini_batch_size=1)\n\n    assert ""Must provide train channel."" in str(ex)\n\n\ndef test_prepare_for_training_encrypt(sagemaker_session):\n    pca = PCA(num_components=55, sagemaker_session=sagemaker_session, **COMMON_ARGS)\n\n    train = [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 8.0], [44.0, 55.0, 66.0]]\n    labels = [99, 85, 87, 2]\n    with patch(\n        ""sagemaker.amazon.amazon_estimator.upload_numpy_to_s3_shards"", return_value=""manfiest_file""\n    ) as mock_upload:\n        pca.record_set(np.array(train), np.array(labels))\n        pca.record_set(np.array(train), np.array(labels), encrypt=True)\n\n    def make_upload_call(encrypt):\n        return call(ANY, ANY, ANY, ANY, ANY, ANY, encrypt)\n\n    mock_upload.assert_has_calls([make_upload_call(False), make_upload_call(True)])\n\n\n@patch(""time.strftime"", return_value=TIMESTAMP)\ndef test_fit_ndarray(time, sagemaker_session):\n    mock_s3 = Mock()\n    mock_object = Mock()\n    mock_s3.Object = Mock(return_value=mock_object)\n    sagemaker_session.boto_session.resource = Mock(return_value=mock_s3)\n    kwargs = dict(COMMON_ARGS)\n    kwargs[""train_instance_count""] = 3\n    pca = PCA(\n        num_components=55,\n        sagemaker_session=sagemaker_session,\n        data_location=""s3://{}/key-prefix/"".format(BUCKET_NAME),\n        **kwargs\n    )\n    train = [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 8.0], [44.0, 55.0, 66.0]]\n    labels = [99, 85, 87, 2]\n    pca.fit(pca.record_set(np.array(train), np.array(labels)))\n    mock_s3.Object.assert_any_call(\n        BUCKET_NAME, ""key-prefix/PCA-2017-11-06-14:14:15.671/matrix_0.pbr""\n    )\n    mock_s3.Object.assert_any_call(\n        BUCKET_NAME, ""key-prefix/PCA-2017-11-06-14:14:15.671/matrix_1.pbr""\n    )\n    mock_s3.Object.assert_any_call(\n        BUCKET_NAME, ""key-prefix/PCA-2017-11-06-14:14:15.671/matrix_2.pbr""\n    )\n    mock_s3.Object.assert_any_call(\n        BUCKET_NAME, ""key-prefix/PCA-2017-11-06-14:14:15.671/.amazon.manifest""\n    )\n\n    assert mock_object.put.call_count == 4\n\n\ndef test_fit_pass_experiment_config(sagemaker_session):\n    kwargs = dict(COMMON_ARGS)\n    kwargs[""train_instance_count""] = 3\n    pca = PCA(\n        num_components=55,\n        sagemaker_session=sagemaker_session,\n        data_location=""s3://{}/key-prefix/"".format(BUCKET_NAME),\n        **kwargs\n    )\n    train = [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 8.0], [44.0, 55.0, 66.0]]\n    labels = [99, 85, 87, 2]\n    pca.fit(\n        pca.record_set(np.array(train), np.array(labels)),\n        experiment_config={""ExperimentName"": ""exp""},\n    )\n\n    called_args = sagemaker_session.train.call_args\n\n    assert called_args[1][""experiment_config""] == {""ExperimentName"": ""exp""}\n\n\ndef test_build_shards():\n    array = np.array([1, 2, 3, 4])\n    shards = _build_shards(4, array)\n    assert shards == [np.array([1]), np.array([2]), np.array([3]), np.array([4])]\n\n    shards = _build_shards(3, array)\n    for out, expected in zip(shards, map(np.array, [[1], [2], [3, 4]])):\n        assert np.array_equal(out, expected)\n\n    with pytest.raises(ValueError):\n        shards = _build_shards(5, array)\n\n\ndef test_upload_numpy_to_s3_shards():\n    mock_s3 = Mock()\n    mock_object = Mock()\n    mock_s3.Object = Mock(return_value=mock_object)\n    mock_put = mock_s3.Object.return_value.put\n    array = np.array([[j for j in range(10)] for i in range(10)])\n    labels = np.array([i for i in range(10)])\n    num_shards = 3\n    num_objects = num_shards + 1  # Account for the manifest file.\n\n    def make_all_put_calls(**kwargs):\n        return [call(Body=ANY, **kwargs) for i in range(num_objects)]\n\n    upload_numpy_to_s3_shards(num_shards, mock_s3, BUCKET_NAME, ""key-prefix"", array, labels)\n    mock_s3.Object.assert_has_calls([call(BUCKET_NAME, ""key-prefix/matrix_0.pbr"")])\n    mock_s3.Object.assert_has_calls([call(BUCKET_NAME, ""key-prefix/matrix_1.pbr"")])\n    mock_s3.Object.assert_has_calls([call(BUCKET_NAME, ""key-prefix/matrix_2.pbr"")])\n    mock_put.assert_has_calls(make_all_put_calls())\n\n    mock_put.reset()\n    upload_numpy_to_s3_shards(3, mock_s3, BUCKET_NAME, ""key-prefix"", array, labels, encrypt=True)\n    mock_put.assert_has_calls(make_all_put_calls(ServerSideEncryption=""AES256""))\n\n\ndef test_file_system_record_set_efs_default_parameters():\n    file_system_id = ""fs-0a48d2a1""\n    file_system_type = ""EFS""\n    directory_path = ""ipinsights""\n    num_records = 1\n    feature_dim = 1\n\n    actual = FileSystemRecordSet(\n        file_system_id=file_system_id,\n        file_system_type=file_system_type,\n        directory_path=directory_path,\n        num_records=num_records,\n        feature_dim=feature_dim,\n    )\n\n    expected_input_config = {\n        ""DataSource"": {\n            ""FileSystemDataSource"": {\n                ""DirectoryPath"": ""ipinsights"",\n                ""FileSystemId"": ""fs-0a48d2a1"",\n                ""FileSystemType"": ""EFS"",\n                ""FileSystemAccessMode"": ""ro"",\n            }\n        }\n    }\n    assert actual.file_system_input.config == expected_input_config\n    assert actual.num_records == num_records\n    assert actual.feature_dim == feature_dim\n    assert actual.channel == ""train""\n\n\ndef test_file_system_record_set_efs_customized_parameters():\n    file_system_id = ""fs-0a48d2a1""\n    file_system_type = ""EFS""\n    directory_path = ""ipinsights""\n    num_records = 1\n    feature_dim = 1\n\n    actual = FileSystemRecordSet(\n        file_system_id=file_system_id,\n        file_system_type=file_system_type,\n        directory_path=directory_path,\n        num_records=num_records,\n        feature_dim=feature_dim,\n        file_system_access_mode=""rw"",\n        channel=""test"",\n    )\n\n    expected_input_config = {\n        ""DataSource"": {\n            ""FileSystemDataSource"": {\n                ""DirectoryPath"": ""ipinsights"",\n                ""FileSystemId"": ""fs-0a48d2a1"",\n                ""FileSystemType"": ""EFS"",\n                ""FileSystemAccessMode"": ""rw"",\n            }\n        }\n    }\n    assert actual.file_system_input.config == expected_input_config\n    assert actual.num_records == num_records\n    assert actual.feature_dim == feature_dim\n    assert actual.channel == ""test""\n\n\ndef test_file_system_record_set_fsx_default_parameters():\n    file_system_id = ""fs-0a48d2a1""\n    file_system_type = ""FSxLustre""\n    directory_path = ""ipinsights""\n    num_records = 1\n    feature_dim = 1\n\n    actual = FileSystemRecordSet(\n        file_system_id=file_system_id,\n        file_system_type=file_system_type,\n        directory_path=directory_path,\n        num_records=num_records,\n        feature_dim=feature_dim,\n    )\n    expected_input_config = {\n        ""DataSource"": {\n            ""FileSystemDataSource"": {\n                ""DirectoryPath"": ""ipinsights"",\n                ""FileSystemId"": ""fs-0a48d2a1"",\n                ""FileSystemType"": ""FSxLustre"",\n                ""FileSystemAccessMode"": ""ro"",\n            }\n        }\n    }\n    assert actual.file_system_input.config == expected_input_config\n    assert actual.num_records == num_records\n    assert actual.feature_dim == feature_dim\n    assert actual.channel == ""train""\n\n\ndef test_file_system_record_set_fsx_customized_parameters():\n    file_system_id = ""fs-0a48d2a1""\n    file_system_type = ""FSxLustre""\n    directory_path = ""ipinsights""\n    num_records = 1\n    feature_dim = 1\n\n    actual = FileSystemRecordSet(\n        file_system_id=file_system_id,\n        file_system_type=file_system_type,\n        directory_path=directory_path,\n        num_records=num_records,\n        feature_dim=feature_dim,\n        file_system_access_mode=""rw"",\n        channel=""test"",\n    )\n\n    expected_input_config = {\n        ""DataSource"": {\n            ""FileSystemDataSource"": {\n                ""DirectoryPath"": ""ipinsights"",\n                ""FileSystemId"": ""fs-0a48d2a1"",\n                ""FileSystemType"": ""FSxLustre"",\n                ""FileSystemAccessMode"": ""rw"",\n            }\n        }\n    }\n    assert actual.file_system_input.config == expected_input_config\n    assert actual.num_records == num_records\n    assert actual.feature_dim == feature_dim\n    assert actual.channel == ""test""\n\n\ndef test_file_system_record_set_data_channel():\n    file_system_id = ""fs-0a48d2a1""\n    file_system_type = ""EFS""\n    directory_path = ""ipinsights""\n    num_records = 1\n    feature_dim = 1\n    record_set = FileSystemRecordSet(\n        file_system_id=file_system_id,\n        file_system_type=file_system_type,\n        directory_path=directory_path,\n        num_records=num_records,\n        feature_dim=feature_dim,\n    )\n\n    file_system_input = Mock()\n    record_set.file_system_input = file_system_input\n    actual = record_set.data_channel()\n    expected = {""train"": file_system_input}\n    assert actual == expected\n\n\ndef test_get_xgboost_image_uri():\n    legacy_xgb_image_uri = get_image_uri(REGION, ""xgboost"")\n    assert legacy_xgb_image_uri == ""433757028032.dkr.ecr.us-west-2.amazonaws.com/xgboost:1""\n    legacy_xgb_image_uri = get_image_uri(REGION, ""xgboost"", 1)\n    assert legacy_xgb_image_uri == ""433757028032.dkr.ecr.us-west-2.amazonaws.com/xgboost:1""\n    legacy_xgb_image_uri = get_image_uri(REGION, ""xgboost"", ""latest"")\n    assert legacy_xgb_image_uri == ""433757028032.dkr.ecr.us-west-2.amazonaws.com/xgboost:latest""\n\n    updated_xgb_image_uri = get_image_uri(REGION, ""xgboost"", ""0.90-1"")\n    assert (\n        updated_xgb_image_uri\n        == ""246618743249.dkr.ecr.us-west-2.amazonaws.com/sagemaker-xgboost:0.90-1-cpu-py3""\n    )\n\n    updated_xgb_image_uri_v2 = get_image_uri(REGION, ""xgboost"", ""0.90-2"")\n    assert (\n        updated_xgb_image_uri_v2\n        == ""246618743249.dkr.ecr.us-west-2.amazonaws.com/sagemaker-xgboost:0.90-2-cpu-py3""\n    )\n\n    assert (\n        get_image_uri(REGION, ""xgboost"", ""0.90-2-cpu-py3"")\n        == ""246618743249.dkr.ecr.us-west-2.amazonaws.com/sagemaker-xgboost:0.90-2-cpu-py3""\n    )\n    assert (\n        get_image_uri(REGION, ""xgboost"", ""0.90"")\n        == ""246618743249.dkr.ecr.us-west-2.amazonaws.com/sagemaker-xgboost:0.90-1-cpu-py3""\n    )\n    assert (\n        get_image_uri(REGION, ""xgboost"", ""1.0-1"")\n        == ""246618743249.dkr.ecr.us-west-2.amazonaws.com/sagemaker-xgboost:1.0-1-cpu-py3""\n    )\n    assert (\n        get_image_uri(REGION, ""xgboost"", ""1.0-1-cpu-py3"")\n        == ""246618743249.dkr.ecr.us-west-2.amazonaws.com/sagemaker-xgboost:1.0-1-cpu-py3""\n    )\n    assert (\n        get_image_uri(REGION, ""xgboost"", ""1.0"")\n        == ""246618743249.dkr.ecr.us-west-2.amazonaws.com/sagemaker-xgboost:1.0-1-cpu-py3""\n    )\n\n\ndef test_get_xgboost_image_uri_warning_with_legacy(caplog):\n    get_image_uri(REGION, ""xgboost"", 1)\n    assert ""There is a more up to date SageMaker XGBoost image."" in caplog.text\n\n\ndef test_get_xgboost_image_uri_warning_with_no_sagemaker_version(caplog):\n    get_image_uri(REGION, ""xgboost"", ""0.90"")\n    assert ""There is a more up to date SageMaker XGBoost image."" in caplog.text\n\n\ndef test_get_xgboost_image_uri_no_warning_with_latest(caplog):\n    get_image_uri(REGION, ""xgboost"", XGBOOST_LATEST_VERSION.split(""-"")[0])\n    assert ""There is a more up to date SageMaker XGBoost image."" not in caplog.text\n\n\ndef test_get_xgboost_image_uri_throws_error_for_unsupported_version():\n    with pytest.raises(ValueError) as error:\n        get_image_uri(REGION, ""xgboost"", ""99.99-9"")\n    assert ""SageMaker XGBoost version 99.99-9 is not supported"" in str(error)\n\n    with pytest.raises(ValueError) as error:\n        get_image_uri(REGION, ""xgboost"", ""0.90-1-gpu-py3"")\n    assert ""SageMaker XGBoost version 0.90-1-gpu-py3 is not supported"" in str(error)\n\n\ndef test_regitry_throws_error_if_mapping_does_not_exist_for_lda():\n    with pytest.raises(ValueError) as error:\n        registry(""cn-north-1"", ""lda"")\n    assert ""Algorithm (lda) is unsupported for region (cn-north-1)."" in str(error)\n\n\ndef test_regitry_throws_error_if_mapping_does_not_exist_for_default_algorithm():\n    with pytest.raises(ValueError) as error:\n        registry(""broken_region_name"")\n    assert ""Algorithm (None) is unsupported for region (broken_region_name)."" in str(error)\n\n\ndef test_is_latest_xgboost_version():\n    for version in XGBOOST_SUPPORTED_VERSIONS:\n        if version != XGBOOST_LATEST_VERSION:\n            assert _is_latest_xgboost_version(version) is False\n        else:\n            assert _is_latest_xgboost_version(version) is True\n\n\ndef test_get_image_uri_warn(caplog):\n    warning_message = (\n        ""\'get_image_uri\' method will be deprecated in favor of \'ImageURIProvider\' class ""\n        ""in SageMaker Python SDK v2.""\n    )\n    get_image_uri(""us-west-2"", ""kmeans"", ""latest"")\n    assert warning_message in caplog.text\n'"
tests/unit/test_analytics.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport datetime\nimport os\nimport uuid\n\nimport pytest\nfrom mock import Mock\n\nfrom sagemaker.analytics import (\n    AnalyticsMetricsBase,\n    HyperparameterTuningJobAnalytics,\n    TrainingJobAnalytics,\n)\n\nBUCKET_NAME = ""mybucket""\nREGION = ""us-west-2""\n\n\n@pytest.fixture()\ndef sagemaker_session():\n    return create_sagemaker_session()\n\n\ndef create_sagemaker_session(\n    describe_training_result=None,\n    list_training_results=None,\n    metric_stats_results=None,\n    describe_tuning_result=None,\n):\n    boto_mock = Mock(name=""boto_session"", region_name=REGION)\n    sms = Mock(\n        name=""sagemaker_session"",\n        boto_session=boto_mock,\n        boto_region_name=REGION,\n        config=None,\n        local_mode=False,\n    )\n    sms.default_bucket = Mock(name=""default_bucket"", return_value=BUCKET_NAME)\n    sms.sagemaker_client.describe_hyper_parameter_tuning_job = Mock(\n        name=""describe_hyper_parameter_tuning_job"", return_value=describe_tuning_result\n    )\n    sms.sagemaker_client.describe_training_job = Mock(\n        name=""describe_training_job"", return_value=describe_training_result\n    )\n    sms.sagemaker_client.list_training_jobs_for_hyper_parameter_tuning_job = Mock(\n        name=""list_training_jobs_for_hyper_parameter_tuning_job"", return_value=list_training_results\n    )\n    cwm_mock = Mock(name=""cloudwatch_client"")\n    boto_mock.client = Mock(return_value=cwm_mock)\n    cwm_mock.get_metric_statistics = Mock(name=""get_metric_statistics"")\n    cwm_mock.get_metric_statistics.side_effect = cw_request_side_effect\n    return sms\n\n\ndef cw_request_side_effect(\n    Namespace, MetricName, Dimensions, StartTime, EndTime, Period, Statistics\n):\n    if _is_valid_request(Namespace, MetricName, Dimensions, StartTime, EndTime, Period, Statistics):\n        return _metric_stats_results()\n\n\ndef _is_valid_request(Namespace, MetricName, Dimensions, StartTime, EndTime, Period, Statistics):\n    could_watch_request = {\n        ""Namespace"": Namespace,\n        ""MetricName"": MetricName,\n        ""Dimensions"": Dimensions,\n        ""StartTime"": StartTime,\n        ""EndTime"": EndTime,\n        ""Period"": Period,\n        ""Statistics"": Statistics,\n    }\n    print(could_watch_request)\n    return could_watch_request == cw_request()\n\n\ndef cw_request():\n    describe_training_result = _describe_training_result()\n    return {\n        ""Namespace"": ""/aws/sagemaker/TrainingJobs"",\n        ""MetricName"": ""train:acc"",\n        ""Dimensions"": [{""Name"": ""TrainingJobName"", ""Value"": ""my-training-job""}],\n        ""StartTime"": describe_training_result[""TrainingStartTime""],\n        ""EndTime"": describe_training_result[""TrainingEndTime""] + datetime.timedelta(minutes=1),\n        ""Period"": 60,\n        ""Statistics"": [""Average""],\n    }\n\n\ndef test_abstract_base_class():\n    # confirm that the abstract base class can\'t be instantiated directly\n    with pytest.raises(TypeError) as _:  # noqa: F841\n        AnalyticsMetricsBase()\n\n\ndef test_tuner_name(sagemaker_session):\n    tuner = HyperparameterTuningJobAnalytics(""my-tuning-job"", sagemaker_session=sagemaker_session)\n    assert tuner.name == ""my-tuning-job""\n    assert str(tuner).find(""my-tuning-job"") != -1\n\n\n@pytest.mark.parametrize(""has_training_job_definition_name"", [True, False])\ndef test_tuner_dataframe(has_training_job_definition_name):\n    training_job_definition_name = ""training_def_1""\n\n    def mock_summary(name=""job-name"", value=0.9):\n        summary = {\n            ""TrainingJobName"": name,\n            ""TrainingJobStatus"": ""Completed"",\n            ""FinalHyperParameterTuningJobObjectiveMetric"": {""Name"": ""awesomeness"", ""Value"": value},\n            ""TrainingStartTime"": datetime.datetime(2018, 5, 16, 1, 2, 3),\n            ""TrainingEndTime"": datetime.datetime(2018, 5, 16, 5, 6, 7),\n            ""TunedHyperParameters"": {""learning_rate"": 0.1, ""layers"": 137},\n        }\n\n        if has_training_job_definition_name:\n            summary[""TrainingJobDefinitionName""] = training_job_definition_name\n        return summary\n\n    session = create_sagemaker_session(\n        list_training_results={\n            ""TrainingJobSummaries"": [\n                mock_summary(),\n                mock_summary(),\n                mock_summary(),\n                mock_summary(),\n                mock_summary(),\n            ]\n        }\n    )\n\n    tuner = HyperparameterTuningJobAnalytics(""my-tuning-job"", sagemaker_session=session)\n    df = tuner.dataframe()\n    assert df is not None\n    assert len(df) == 5\n    assert (\n        len(session.sagemaker_client.list_training_jobs_for_hyper_parameter_tuning_job.mock_calls)\n        == 1\n    )\n\n    # Clear the cache, check that it calls the service again.\n    tuner.clear_cache()\n    df = tuner.dataframe()\n    assert (\n        len(session.sagemaker_client.list_training_jobs_for_hyper_parameter_tuning_job.mock_calls)\n        == 2\n    )\n    df = tuner.dataframe(force_refresh=True)\n    assert (\n        len(session.sagemaker_client.list_training_jobs_for_hyper_parameter_tuning_job.mock_calls)\n        == 3\n    )\n\n    # check that the hyperparameter is in the dataframe\n    assert len(df[""layers""]) == 5\n    assert min(df[""layers""]) == 137\n\n    # Check that the training time calculation is returning something sane.\n    assert min(df[""TrainingElapsedTimeSeconds""]) > 5\n    assert max(df[""TrainingElapsedTimeSeconds""]) < 86400\n\n    if has_training_job_definition_name:\n        for index in range(0, 5):\n            assert df[""TrainingJobDefinitionName""][index] == training_job_definition_name\n    else:\n        assert ""TrainingJobDefinitionName"" not in df\n\n    # Export to CSV and check that file exists\n    tmp_name = ""/tmp/unit-test-%s.csv"" % uuid.uuid4()\n    assert not os.path.isfile(tmp_name)\n    tuner.export_csv(tmp_name)\n    assert os.path.isfile(tmp_name)\n    os.unlink(tmp_name)\n\n\ndef test_description():\n    session = create_sagemaker_session(\n        describe_tuning_result={\n            ""HyperParameterTuningJobConfig"": {\n                ""ParameterRanges"": {\n                    ""CategoricalParameterRanges"": [],\n                    ""ContinuousParameterRanges"": [\n                        {""MaxValue"": ""1"", ""MinValue"": ""0"", ""Name"": ""eta""},\n                        {""MaxValue"": ""10"", ""MinValue"": ""0"", ""Name"": ""gamma""},\n                    ],\n                    ""IntegerParameterRanges"": [\n                        {""MaxValue"": ""30"", ""MinValue"": ""5"", ""Name"": ""num_layers""},\n                        {""MaxValue"": ""100"", ""MinValue"": ""50"", ""Name"": ""iterations""},\n                    ],\n                }\n            },\n            ""TrainingJobDefinition"": {\n                ""AlgorithmSpecification"": {\n                    ""TrainingImage"": ""training_image"",\n                    ""TrainingInputMode"": ""File"",\n                }\n            },\n        }\n    )\n\n    tuner = HyperparameterTuningJobAnalytics(""my-tuning-job"", sagemaker_session=session)\n\n    d = tuner.description()\n    assert len(session.sagemaker_client.describe_hyper_parameter_tuning_job.mock_calls) == 1\n    assert d is not None\n    assert d[""HyperParameterTuningJobConfig""] is not None\n    tuner.clear_cache()\n    d = tuner.description()\n    assert len(session.sagemaker_client.describe_hyper_parameter_tuning_job.mock_calls) == 2\n    d = tuner.description()\n    assert len(session.sagemaker_client.describe_hyper_parameter_tuning_job.mock_calls) == 2\n    d = tuner.description(force_refresh=True)\n    assert len(session.sagemaker_client.describe_hyper_parameter_tuning_job.mock_calls) == 3\n\n    # Check that the ranges work.\n    r = tuner.tuning_ranges\n    assert len(r) == 4\n\n\ndef test_tuning_ranges_multi_training_job_definitions():\n    session = create_sagemaker_session(\n        describe_tuning_result={\n            ""HyperParameterTuningJobConfig"": {},\n            ""TrainingJobDefinitions"": [\n                {\n                    ""DefinitionName"": ""estimator_1"",\n                    ""HyperParameterRanges"": {\n                        ""CategoricalParameterRanges"": [],\n                        ""ContinuousParameterRanges"": [\n                            {""MaxValue"": ""1"", ""MinValue"": ""0"", ""Name"": ""eta""},\n                            {""MaxValue"": ""10"", ""MinValue"": ""0"", ""Name"": ""gamma""},\n                        ],\n                        ""IntegerParameterRanges"": [\n                            {""MaxValue"": ""30"", ""MinValue"": ""5"", ""Name"": ""num_layers""},\n                            {""MaxValue"": ""100"", ""MinValue"": ""50"", ""Name"": ""iterations""},\n                        ],\n                    },\n                    ""AlgorithmSpecification"": {\n                        ""TrainingImage"": ""training_image_1"",\n                        ""TrainingInputMode"": ""File"",\n                    },\n                },\n                {\n                    ""DefinitionName"": ""estimator_2"",\n                    ""HyperParameterRanges"": {\n                        ""CategoricalParameterRanges"": [\n                            {""Values"": [""TF"", ""MXNet""], ""Name"": ""framework""}\n                        ],\n                        ""ContinuousParameterRanges"": [\n                            {""MaxValue"": ""1.0"", ""MinValue"": ""0.2"", ""Name"": ""gamma""}\n                        ],\n                        ""IntegerParameterRanges"": [],\n                    },\n                    ""AlgorithmSpecification"": {\n                        ""TrainingImage"": ""training_image_2"",\n                        ""TrainingInputMode"": ""File"",\n                    },\n                },\n            ],\n        }\n    )\n\n    expected_result = {\n        ""estimator_1"": {\n            ""eta"": {""MaxValue"": ""1"", ""MinValue"": ""0"", ""Name"": ""eta""},\n            ""gamma"": {""MaxValue"": ""10"", ""MinValue"": ""0"", ""Name"": ""gamma""},\n            ""iterations"": {""MaxValue"": ""100"", ""MinValue"": ""50"", ""Name"": ""iterations""},\n            ""num_layers"": {""MaxValue"": ""30"", ""MinValue"": ""5"", ""Name"": ""num_layers""},\n        },\n        ""estimator_2"": {\n            ""framework"": {""Values"": [""TF"", ""MXNet""], ""Name"": ""framework""},\n            ""gamma"": {""MaxValue"": ""1.0"", ""MinValue"": ""0.2"", ""Name"": ""gamma""},\n        },\n    }\n\n    tuner = HyperparameterTuningJobAnalytics(""my-tuning-job"", sagemaker_session=session)\n\n    assert expected_result == tuner.tuning_ranges\n\n\ndef test_trainer_name():\n    describe_training_result = {\n        ""TrainingStartTime"": datetime.datetime(2018, 5, 16, 1, 2, 3),\n        ""TrainingEndTime"": datetime.datetime(2018, 5, 16, 5, 6, 7),\n    }\n    session = create_sagemaker_session(describe_training_result)\n    trainer = TrainingJobAnalytics(""my-training-job"", [""metric""], sagemaker_session=session)\n    assert trainer.name == ""my-training-job""\n    assert str(trainer).find(""my-training-job"") != -1\n\n\ndef _describe_training_result():\n    return {\n        ""TrainingStartTime"": datetime.datetime(2018, 5, 16, 1, 2, 3),\n        ""TrainingEndTime"": datetime.datetime(2018, 5, 16, 5, 6, 7),\n    }\n\n\ndef _metric_stats_results():\n    return {\n        ""Datapoints"": [\n            {""Average"": 77.1, ""Timestamp"": datetime.datetime(2018, 5, 16, 1, 3, 3)},\n            {""Average"": 87.1, ""Timestamp"": datetime.datetime(2018, 5, 16, 1, 8, 3)},\n            {""Average"": 97.1, ""Timestamp"": datetime.datetime(2018, 5, 16, 2, 3, 3)},\n        ]\n    }\n\n\ndef test_trainer_dataframe():\n    session = create_sagemaker_session(\n        describe_training_result=_describe_training_result(),\n        metric_stats_results=_metric_stats_results(),\n    )\n    trainer = TrainingJobAnalytics(""my-training-job"", [""train:acc""], sagemaker_session=session)\n\n    df = trainer.dataframe()\n    assert df is not None\n    assert len(df) == 3\n    assert min(df[""value""]) == 77.1\n    assert max(df[""value""]) == 97.1\n\n    # Export to CSV and check that file exists\n    tmp_name = ""/tmp/unit-test-%s.csv"" % uuid.uuid4()\n    assert not os.path.isfile(tmp_name)\n    trainer.export_csv(tmp_name)\n    assert os.path.isfile(tmp_name)\n    os.unlink(tmp_name)\n\n\ndef test_start_time_end_time_and_period_specified():\n    describe_training_result = {\n        ""TrainingStartTime"": datetime.datetime(2018, 5, 16, 1, 2, 3),\n        ""TrainingEndTime"": datetime.datetime(2018, 5, 16, 5, 6, 7),\n    }\n    session = create_sagemaker_session(describe_training_result)\n    start_time = datetime.datetime(2018, 5, 16, 1, 3, 4)\n    end_time = datetime.datetime(2018, 5, 16, 5, 1, 1)\n    period = 300\n    trainer = TrainingJobAnalytics(\n        ""my-training-job"",\n        [""metric""],\n        sagemaker_session=session,\n        start_time=start_time,\n        end_time=end_time,\n        period=period,\n    )\n\n    assert trainer._time_interval[""start_time""] == start_time\n    assert trainer._time_interval[""end_time""] == end_time\n    assert trainer._period == period\n'"
tests/unit/test_chainer.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport logging\nimport json\nimport os\nimport pytest\nimport sys\nfrom distutils.util import strtobool\nfrom mock import MagicMock, Mock\nfrom mock import patch\n\n\nfrom sagemaker.chainer import defaults\nfrom sagemaker.chainer import Chainer\nfrom sagemaker.chainer import ChainerPredictor, ChainerModel\n\n\nDATA_DIR = os.path.join(os.path.dirname(__file__), "".."", ""data"")\nSCRIPT_PATH = os.path.join(DATA_DIR, ""dummy_script.py"")\nSERVING_SCRIPT_FILE = ""another_dummy_script.py""\nMODEL_DATA = ""s3://some/data.tar.gz""\nENV = {""DUMMY_ENV_VAR"": ""dummy_value""}\nTIMESTAMP = ""2017-11-06-14:14:15.672""\nTIME = 1507167947\nBUCKET_NAME = ""mybucket""\nINSTANCE_COUNT = 1\nINSTANCE_TYPE = ""ml.c4.4xlarge""\nACCELERATOR_TYPE = ""ml.eia.medium""\nPYTHON_VERSION = ""py"" + str(sys.version_info.major)\nIMAGE_NAME = ""sagemaker-chainer""\nJOB_NAME = ""{}-{}"".format(IMAGE_NAME, TIMESTAMP)\nIMAGE_URI_FORMAT_STRING = ""520713654638.dkr.ecr.{}.amazonaws.com/{}:{}-{}-{}""\nROLE = ""Dummy""\nREGION = ""us-west-2""\nGPU = ""ml.p2.xlarge""\nCPU = ""ml.c4.xlarge""\n\nENDPOINT_DESC = {""EndpointConfigName"": ""test-endpoint""}\n\nENDPOINT_CONFIG_DESC = {""ProductionVariants"": [{""ModelName"": ""model-1""}, {""ModelName"": ""model-2""}]}\n\nLIST_TAGS_RESULT = {""Tags"": [{""Key"": ""TagtestKey"", ""Value"": ""TagtestValue""}]}\n\n\n@pytest.fixture()\ndef sagemaker_session():\n    boto_mock = Mock(name=""boto_session"", region_name=REGION)\n    session = Mock(\n        name=""sagemaker_session"",\n        boto_session=boto_mock,\n        boto_region_name=REGION,\n        config=None,\n        local_mode=False,\n        s3_resource=None,\n        s3_client=None,\n    )\n\n    describe = {""ModelArtifacts"": {""S3ModelArtifacts"": ""s3://m/m.tar.gz""}}\n    session.sagemaker_client.describe_training_job = Mock(return_value=describe)\n    session.sagemaker_client.describe_endpoint = Mock(return_value=ENDPOINT_DESC)\n    session.sagemaker_client.describe_endpoint_config = Mock(return_value=ENDPOINT_CONFIG_DESC)\n    session.sagemaker_client.list_tags = Mock(return_value=LIST_TAGS_RESULT)\n    session.default_bucket = Mock(name=""default_bucket"", return_value=BUCKET_NAME)\n    session.expand_role = Mock(name=""expand_role"", return_value=ROLE)\n    return session\n\n\ndef _get_full_cpu_image_uri(version, py_version=PYTHON_VERSION):\n    return IMAGE_URI_FORMAT_STRING.format(REGION, IMAGE_NAME, version, ""cpu"", py_version)\n\n\ndef _get_full_gpu_image_uri(version, py_version=PYTHON_VERSION):\n    return IMAGE_URI_FORMAT_STRING.format(REGION, IMAGE_NAME, version, ""gpu"", py_version)\n\n\ndef _get_full_cpu_image_uri_with_ei(version, py_version=PYTHON_VERSION):\n    return _get_full_cpu_image_uri(version, py_version=py_version) + ""-eia""\n\n\ndef _chainer_estimator(\n    sagemaker_session,\n    framework_version=defaults.CHAINER_VERSION,\n    train_instance_type=None,\n    base_job_name=None,\n    use_mpi=None,\n    num_processes=None,\n    process_slots_per_host=None,\n    additional_mpi_options=None,\n    **kwargs\n):\n    return Chainer(\n        entry_point=SCRIPT_PATH,\n        framework_version=framework_version,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=train_instance_type if train_instance_type else INSTANCE_TYPE,\n        base_job_name=base_job_name,\n        use_mpi=use_mpi,\n        num_processes=num_processes,\n        process_slots_per_host=process_slots_per_host,\n        additional_mpi_options=additional_mpi_options,\n        py_version=PYTHON_VERSION,\n        **kwargs\n    )\n\n\ndef _create_train_job(version):\n    return {\n        ""image"": _get_full_cpu_image_uri(version),\n        ""input_mode"": ""File"",\n        ""input_config"": [\n            {\n                ""ChannelName"": ""training"",\n                ""DataSource"": {\n                    ""S3DataSource"": {\n                        ""S3DataDistributionType"": ""FullyReplicated"",\n                        ""S3DataType"": ""S3Prefix"",\n                    }\n                },\n            }\n        ],\n        ""role"": ROLE,\n        ""job_name"": JOB_NAME,\n        ""output_config"": {""S3OutputPath"": ""s3://{}/"".format(BUCKET_NAME)},\n        ""resource_config"": {\n            ""InstanceType"": ""ml.c4.4xlarge"",\n            ""InstanceCount"": 1,\n            ""VolumeSizeInGB"": 30,\n        },\n        ""hyperparameters"": {\n            ""sagemaker_program"": json.dumps(""dummy_script.py""),\n            ""sagemaker_enable_cloudwatch_metrics"": ""false"",\n            ""sagemaker_container_log_level"": str(logging.INFO),\n            ""sagemaker_job_name"": json.dumps(JOB_NAME),\n            ""sagemaker_submit_directory"": json.dumps(\n                ""s3://{}/{}/source/sourcedir.tar.gz"".format(BUCKET_NAME, JOB_NAME)\n            ),\n            ""sagemaker_region"": \'""us-west-2""\',\n        },\n        ""stop_condition"": {""MaxRuntimeInSeconds"": 24 * 60 * 60},\n        ""tags"": None,\n        ""vpc_config"": None,\n        ""metric_definitions"": None,\n        ""experiment_config"": None,\n        ""debugger_hook_config"": {\n            ""CollectionConfigurations"": [],\n            ""S3OutputPath"": ""s3://{}/"".format(BUCKET_NAME),\n        },\n    }\n\n\ndef _create_train_job_with_additional_hyperparameters(version):\n    return {\n        ""image"": _get_full_cpu_image_uri(version),\n        ""input_mode"": ""File"",\n        ""input_config"": [\n            {\n                ""ChannelName"": ""training"",\n                ""DataSource"": {\n                    ""S3DataSource"": {\n                        ""S3DataDistributionType"": ""FullyReplicated"",\n                        ""S3DataType"": ""S3Prefix"",\n                    }\n                },\n            }\n        ],\n        ""role"": ROLE,\n        ""job_name"": JOB_NAME,\n        ""output_config"": {""S3OutputPath"": ""s3://{}/"".format(BUCKET_NAME)},\n        ""resource_config"": {\n            ""InstanceType"": ""ml.c4.4xlarge"",\n            ""InstanceCount"": 1,\n            ""VolumeSizeInGB"": 30,\n        },\n        ""hyperparameters"": {\n            ""sagemaker_program"": json.dumps(""dummy_script.py""),\n            ""sagemaker_container_log_level"": str(logging.INFO),\n            ""sagemaker_job_name"": json.dumps(JOB_NAME),\n            ""sagemaker_submit_directory"": json.dumps(\n                ""s3://{}/{}/source/sourcedir.tar.gz"".format(BUCKET_NAME, JOB_NAME)\n            ),\n            ""sagemaker_region"": \'""us-west-2""\',\n            ""sagemaker_num_processes"": ""4"",\n            ""sagemaker_additional_mpi_options"": \'""-x MY_ENVIRONMENT_VARIABLE""\',\n            ""sagemaker_process_slots_per_host"": ""10"",\n            ""sagemaker_use_mpi"": ""true"",\n        },\n        ""stop_condition"": {""MaxRuntimeInSeconds"": 24 * 60 * 60},\n    }\n\n\ndef test_additional_hyperparameters(sagemaker_session):\n    chainer = _chainer_estimator(\n        sagemaker_session,\n        use_mpi=True,\n        num_processes=4,\n        process_slots_per_host=10,\n        additional_mpi_options=""-x MY_ENVIRONMENT_VARIABLE"",\n    )\n    assert bool(strtobool(chainer.hyperparameters()[""sagemaker_use_mpi""]))\n    assert int(chainer.hyperparameters()[""sagemaker_num_processes""]) == 4\n    assert int(chainer.hyperparameters()[""sagemaker_process_slots_per_host""]) == 10\n    assert (\n        str(chainer.hyperparameters()[""sagemaker_additional_mpi_options""])\n        == \'""-x MY_ENVIRONMENT_VARIABLE""\'\n    )\n\n\ndef test_attach_with_additional_hyperparameters(sagemaker_session, chainer_version):\n    training_image = ""1.dkr.ecr.us-west-2.amazonaws.com/sagemaker-chainer:{}-cpu-{}"".format(\n        chainer_version, PYTHON_VERSION\n    )\n    returned_job_description = {\n        ""AlgorithmSpecification"": {""TrainingInputMode"": ""File"", ""TrainingImage"": training_image},\n        ""HyperParameters"": {\n            ""sagemaker_submit_directory"": \'""s3://some/sourcedir.tar.gz""\',\n            ""sagemaker_program"": \'""iris-dnn-classifier.py""\',\n            ""sagemaker_s3_uri_training"": \'""sagemaker-3/integ-test-data/tf_iris""\',\n            ""sagemaker_enable_cloudwatch_metrics"": ""false"",\n            ""sagemaker_container_log_level"": \'""logging.INFO""\',\n            ""sagemaker_job_name"": \'""neo""\',\n            ""sagemaker_region"": \'""us-west-2""\',\n            ""sagemaker_num_processes"": ""4"",\n            ""sagemaker_additional_mpi_options"": \'""-x MY_ENVIRONMENT_VARIABLE""\',\n            ""sagemaker_process_slots_per_host"": ""10"",\n            ""sagemaker_use_mpi"": ""true"",\n        },\n        ""RoleArn"": ""arn:aws:iam::366:role/SageMakerRole"",\n        ""ResourceConfig"": {\n            ""VolumeSizeInGB"": 30,\n            ""InstanceCount"": 1,\n            ""InstanceType"": ""ml.c4.xlarge"",\n        },\n        ""StoppingCondition"": {""MaxRuntimeInSeconds"": 24 * 60 * 60},\n        ""TrainingJobName"": ""neo"",\n        ""TrainingJobStatus"": ""Completed"",\n        ""TrainingJobArn"": ""arn:aws:sagemaker:us-west-2:336:training-job/neo"",\n        ""OutputDataConfig"": {""KmsKeyId"": """", ""S3OutputPath"": ""s3://place/output/neo""},\n        ""TrainingJobOutput"": {""S3TrainingJobOutput"": ""s3://here/output.tar.gz""},\n    }\n    sagemaker_session.sagemaker_client.describe_training_job = Mock(\n        name=""describe_training_job"", return_value=returned_job_description\n    )\n\n    estimator = Chainer.attach(training_job_name=""neo"", sagemaker_session=sagemaker_session)\n    assert bool(estimator.hyperparameters()[""sagemaker_use_mpi""])\n    assert int(estimator.hyperparameters()[""sagemaker_num_processes""]) == 4\n    assert int(estimator.hyperparameters()[""sagemaker_process_slots_per_host""]) == 10\n    assert (\n        str(estimator.hyperparameters()[""sagemaker_additional_mpi_options""])\n        == \'""-x MY_ENVIRONMENT_VARIABLE""\'\n    )\n    assert estimator.use_mpi\n    assert estimator.num_processes == 4\n    assert estimator.process_slots_per_host == 10\n    assert estimator.additional_mpi_options == ""-x MY_ENVIRONMENT_VARIABLE""\n\n\ndef test_create_model(sagemaker_session, chainer_version):\n    container_log_level = \'""logging.INFO""\'\n    source_dir = ""s3://mybucket/source""\n    chainer = Chainer(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        framework_version=chainer_version,\n        container_log_level=container_log_level,\n        py_version=PYTHON_VERSION,\n        base_job_name=""job"",\n        source_dir=source_dir,\n    )\n\n    job_name = ""new_name""\n    chainer.fit(inputs=""s3://mybucket/train"", job_name=job_name)\n    model = chainer.create_model()\n\n    assert model.sagemaker_session == sagemaker_session\n    assert model.framework_version == chainer_version\n    assert model.py_version == chainer.py_version\n    assert model.entry_point == SCRIPT_PATH\n    assert model.role == ROLE\n    assert model.name == job_name\n    assert model.container_log_level == container_log_level\n    assert model.source_dir == source_dir\n    assert model.vpc_config is None\n\n\ndef test_create_model_with_optional_params(sagemaker_session):\n    container_log_level = \'""logging.INFO""\'\n    source_dir = ""s3://mybucket/source""\n    enable_cloudwatch_metrics = ""true""\n    chainer = Chainer(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        container_log_level=container_log_level,\n        py_version=PYTHON_VERSION,\n        base_job_name=""job"",\n        source_dir=source_dir,\n        enable_cloudwatch_metrics=enable_cloudwatch_metrics,\n    )\n\n    chainer.fit(inputs=""s3://mybucket/train"", job_name=""new_name"")\n\n    new_role = ""role""\n    model_server_workers = 2\n    vpc_config = {""Subnets"": [""foo""], ""SecurityGroupIds"": [""bar""]}\n    model_name = ""model-name""\n    model = chainer.create_model(\n        role=new_role,\n        model_server_workers=model_server_workers,\n        vpc_config_override=vpc_config,\n        entry_point=SERVING_SCRIPT_FILE,\n        env=ENV,\n        name=model_name,\n    )\n\n    assert model.role == new_role\n    assert model.model_server_workers == model_server_workers\n    assert model.vpc_config == vpc_config\n    assert model.entry_point == SERVING_SCRIPT_FILE\n    assert model.env == ENV\n    assert model.name == model_name\n\n\ndef test_create_model_with_custom_image(sagemaker_session):\n    container_log_level = \'""logging.INFO""\'\n    source_dir = ""s3://mybucket/source""\n    custom_image = ""ubuntu:latest""\n    chainer = Chainer(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        image_name=custom_image,\n        container_log_level=container_log_level,\n        py_version=PYTHON_VERSION,\n        base_job_name=""job"",\n        source_dir=source_dir,\n    )\n\n    chainer.fit(inputs=""s3://mybucket/train"", job_name=""new_name"")\n    model = chainer.create_model()\n\n    assert model.image == custom_image\n\n\n@patch(""sagemaker.utils.create_tar_file"", MagicMock())\n@patch(""time.strftime"", return_value=TIMESTAMP)\ndef test_chainer(strftime, sagemaker_session, chainer_version):\n    chainer = Chainer(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        py_version=PYTHON_VERSION,\n        framework_version=chainer_version,\n    )\n\n    inputs = ""s3://mybucket/train""\n\n    chainer.fit(inputs=inputs)\n\n    sagemaker_call_names = [c[0] for c in sagemaker_session.method_calls]\n    assert sagemaker_call_names == [""train"", ""logs_for_job""]\n    boto_call_names = [c[0] for c in sagemaker_session.boto_session.method_calls]\n    assert boto_call_names == [""resource""]\n\n    expected_train_args = _create_train_job(chainer_version)\n    expected_train_args[""input_config""][0][""DataSource""][""S3DataSource""][""S3Uri""] = inputs\n\n    actual_train_args = sagemaker_session.method_calls[0][2]\n    assert actual_train_args == expected_train_args\n\n    model = chainer.create_model()\n\n    expected_image_base = ""520713654638.dkr.ecr.us-west-2.amazonaws.com/sagemaker-chainer:{}-gpu-{}""\n    assert {\n        ""Environment"": {\n            ""SAGEMAKER_SUBMIT_DIRECTORY"": ""s3://mybucket/sagemaker-chainer-{}/source/sourcedir.tar.gz"".format(\n                TIMESTAMP\n            ),\n            ""SAGEMAKER_PROGRAM"": ""dummy_script.py"",\n            ""SAGEMAKER_ENABLE_CLOUDWATCH_METRICS"": ""false"",\n            ""SAGEMAKER_REGION"": ""us-west-2"",\n            ""SAGEMAKER_CONTAINER_LOG_LEVEL"": ""20"",\n        },\n        ""Image"": expected_image_base.format(chainer_version, PYTHON_VERSION),\n        ""ModelDataUrl"": ""s3://m/m.tar.gz"",\n    } == model.prepare_container_def(GPU)\n\n    assert ""cpu"" in model.prepare_container_def(CPU)[""Image""]\n    predictor = chainer.deploy(1, GPU)\n    assert isinstance(predictor, ChainerPredictor)\n\n\n@patch(""sagemaker.utils.create_tar_file"", MagicMock())\ndef test_model(sagemaker_session):\n    model = ChainerModel(\n        ""s3://some/data.tar.gz"",\n        role=ROLE,\n        entry_point=SCRIPT_PATH,\n        sagemaker_session=sagemaker_session,\n    )\n    predictor = model.deploy(1, GPU)\n    assert isinstance(predictor, ChainerPredictor)\n\n\n@patch(""sagemaker.fw_utils.tar_and_upload_dir"", MagicMock())\ndef test_model_prepare_container_def_accelerator_error(sagemaker_session):\n    model = ChainerModel(\n        MODEL_DATA, role=ROLE, entry_point=SCRIPT_PATH, sagemaker_session=sagemaker_session\n    )\n    with pytest.raises(ValueError):\n        model.prepare_container_def(INSTANCE_TYPE, accelerator_type=ACCELERATOR_TYPE)\n\n\ndef test_train_image_default(sagemaker_session):\n    chainer = Chainer(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        py_version=PYTHON_VERSION,\n    )\n\n    assert _get_full_cpu_image_uri(defaults.CHAINER_VERSION) in chainer.train_image()\n\n\ndef test_train_image_cpu_instances(sagemaker_session, chainer_version):\n    chainer = _chainer_estimator(\n        sagemaker_session, chainer_version, train_instance_type=""ml.c2.2xlarge""\n    )\n    assert chainer.train_image() == _get_full_cpu_image_uri(chainer_version)\n\n    chainer = _chainer_estimator(\n        sagemaker_session, chainer_version, train_instance_type=""ml.c4.2xlarge""\n    )\n    assert chainer.train_image() == _get_full_cpu_image_uri(chainer_version)\n\n    chainer = _chainer_estimator(sagemaker_session, chainer_version, train_instance_type=""ml.m16"")\n    assert chainer.train_image() == _get_full_cpu_image_uri(chainer_version)\n\n\ndef test_train_image_gpu_instances(sagemaker_session, chainer_version):\n    chainer = _chainer_estimator(\n        sagemaker_session, chainer_version, train_instance_type=""ml.g2.2xlarge""\n    )\n    assert chainer.train_image() == _get_full_gpu_image_uri(chainer_version)\n\n    chainer = _chainer_estimator(\n        sagemaker_session, chainer_version, train_instance_type=""ml.p2.2xlarge""\n    )\n    assert chainer.train_image() == _get_full_gpu_image_uri(chainer_version)\n\n\ndef test_attach(sagemaker_session, chainer_version):\n    training_image = ""1.dkr.ecr.us-west-2.amazonaws.com/sagemaker-chainer:{}-cpu-{}"".format(\n        chainer_version, PYTHON_VERSION\n    )\n    returned_job_description = {\n        ""AlgorithmSpecification"": {""TrainingInputMode"": ""File"", ""TrainingImage"": training_image},\n        ""HyperParameters"": {\n            ""sagemaker_submit_directory"": \'""s3://some/sourcedir.tar.gz""\',\n            ""sagemaker_program"": \'""iris-dnn-classifier.py""\',\n            ""sagemaker_s3_uri_training"": \'""sagemaker-3/integ-test-data/tf_iris""\',\n            ""sagemaker_enable_cloudwatch_metrics"": ""false"",\n            ""sagemaker_container_log_level"": \'""logging.INFO""\',\n            ""sagemaker_job_name"": \'""neo""\',\n            ""training_steps"": ""100"",\n            ""sagemaker_region"": \'""us-west-2""\',\n        },\n        ""RoleArn"": ""arn:aws:iam::366:role/SageMakerRole"",\n        ""ResourceConfig"": {\n            ""VolumeSizeInGB"": 30,\n            ""InstanceCount"": 1,\n            ""InstanceType"": ""ml.c4.xlarge"",\n        },\n        ""StoppingCondition"": {""MaxRuntimeInSeconds"": 24 * 60 * 60},\n        ""TrainingJobName"": ""neo"",\n        ""TrainingJobStatus"": ""Completed"",\n        ""TrainingJobArn"": ""arn:aws:sagemaker:us-west-2:336:training-job/neo"",\n        ""OutputDataConfig"": {""KmsKeyId"": """", ""S3OutputPath"": ""s3://place/output/neo""},\n        ""TrainingJobOutput"": {""S3TrainingJobOutput"": ""s3://here/output.tar.gz""},\n    }\n    sagemaker_session.sagemaker_client.describe_training_job = Mock(\n        name=""describe_training_job"", return_value=returned_job_description\n    )\n\n    estimator = Chainer.attach(training_job_name=""neo"", sagemaker_session=sagemaker_session)\n    assert estimator.latest_training_job.job_name == ""neo""\n    assert estimator.py_version == PYTHON_VERSION\n    assert estimator.framework_version == chainer_version\n    assert estimator.role == ""arn:aws:iam::366:role/SageMakerRole""\n    assert estimator.train_instance_count == 1\n    assert estimator.train_max_run == 24 * 60 * 60\n    assert estimator.input_mode == ""File""\n    assert estimator.base_job_name == ""neo""\n    assert estimator.output_path == ""s3://place/output/neo""\n    assert estimator.output_kms_key == """"\n    assert estimator.hyperparameters()[""training_steps""] == ""100""\n    assert estimator.source_dir == ""s3://some/sourcedir.tar.gz""\n    assert estimator.entry_point == ""iris-dnn-classifier.py""\n\n\ndef test_attach_wrong_framework(sagemaker_session):\n    rjd = {\n        ""AlgorithmSpecification"": {\n            ""TrainingInputMode"": ""File"",\n            ""TrainingImage"": ""1.dkr.ecr.us-west-2.amazonaws.com/sagemaker-mxnet-py2-cpu:1.0.4"",\n        },\n        ""HyperParameters"": {\n            ""sagemaker_submit_directory"": \'""s3://some/sourcedir.tar.gz""\',\n            ""checkpoint_path"": \'""s3://other/1508872349""\',\n            ""sagemaker_program"": \'""iris-dnn-classifier.py""\',\n            ""sagemaker_enable_cloudwatch_metrics"": ""false"",\n            ""sagemaker_container_log_level"": \'""logging.INFO""\',\n            ""training_steps"": ""100"",\n            ""sagemaker_region"": \'""us-west-2""\',\n        },\n        ""RoleArn"": ""arn:aws:iam::366:role/SageMakerRole"",\n        ""ResourceConfig"": {\n            ""VolumeSizeInGB"": 30,\n            ""InstanceCount"": 1,\n            ""InstanceType"": ""ml.c4.xlarge"",\n        },\n        ""StoppingCondition"": {""MaxRuntimeInSeconds"": 24 * 60 * 60},\n        ""TrainingJobName"": ""neo"",\n        ""TrainingJobStatus"": ""Completed"",\n        ""TrainingJobArn"": ""arn:aws:sagemaker:us-west-2:336:training-job/neo"",\n        ""OutputDataConfig"": {""KmsKeyId"": """", ""S3OutputPath"": ""s3://place/output/neo""},\n        ""TrainingJobOutput"": {""S3TrainingJobOutput"": ""s3://here/output.tar.gz""},\n    }\n    sagemaker_session.sagemaker_client.describe_training_job = Mock(\n        name=""describe_training_job"", return_value=rjd\n    )\n\n    with pytest.raises(ValueError) as error:\n        Chainer.attach(training_job_name=""neo"", sagemaker_session=sagemaker_session)\n    assert ""didn\'t use image for requested framework"" in str(error)\n\n\ndef test_attach_custom_image(sagemaker_session):\n    training_image = ""1.dkr.ecr.us-west-2.amazonaws.com/my_custom_chainer_image:latest""\n    returned_job_description = {\n        ""AlgorithmSpecification"": {""TrainingInputMode"": ""File"", ""TrainingImage"": training_image},\n        ""HyperParameters"": {\n            ""sagemaker_submit_directory"": \'""s3://some/sourcedir.tar.gz""\',\n            ""sagemaker_program"": \'""iris-dnn-classifier.py""\',\n            ""sagemaker_s3_uri_training"": \'""sagemaker-3/integ-test-data/tf_iris""\',\n            ""sagemaker_enable_cloudwatch_metrics"": ""false"",\n            ""sagemaker_container_log_level"": \'""logging.INFO""\',\n            ""sagemaker_job_name"": \'""neo""\',\n            ""training_steps"": ""100"",\n            ""sagemaker_region"": \'""us-west-2""\',\n        },\n        ""RoleArn"": ""arn:aws:iam::366:role/SageMakerRole"",\n        ""ResourceConfig"": {\n            ""VolumeSizeInGB"": 30,\n            ""InstanceCount"": 1,\n            ""InstanceType"": ""ml.c4.xlarge"",\n        },\n        ""StoppingCondition"": {""MaxRuntimeInSeconds"": 24 * 60 * 60},\n        ""TrainingJobName"": ""neo"",\n        ""TrainingJobStatus"": ""Completed"",\n        ""TrainingJobArn"": ""arn:aws:sagemaker:us-west-2:336:training-job/neo"",\n        ""OutputDataConfig"": {""KmsKeyId"": """", ""S3OutputPath"": ""s3://place/output/neo""},\n        ""TrainingJobOutput"": {""S3TrainingJobOutput"": ""s3://here/output.tar.gz""},\n    }\n    sagemaker_session.sagemaker_client.describe_training_job = Mock(\n        name=""describe_training_job"", return_value=returned_job_description\n    )\n\n    estimator = Chainer.attach(training_job_name=""neo"", sagemaker_session=sagemaker_session)\n    assert estimator.image_name == training_image\n    assert estimator.train_image() == training_image\n\n\n@patch(""sagemaker.chainer.estimator.python_deprecation_warning"")\ndef test_estimator_py2_warning(warning, sagemaker_session):\n    estimator = Chainer(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        py_version=""py2"",\n    )\n\n    assert estimator.py_version == ""py2""\n    warning.assert_called_with(estimator.__framework_name__, defaults.LATEST_PY2_VERSION)\n\n\n@patch(""sagemaker.chainer.model.python_deprecation_warning"")\ndef test_model_py2_warning(warning, sagemaker_session):\n    model = ChainerModel(\n        MODEL_DATA,\n        role=ROLE,\n        entry_point=SCRIPT_PATH,\n        sagemaker_session=sagemaker_session,\n        py_version=""py2"",\n    )\n    assert model.py_version == ""py2""\n    warning.assert_called_with(model.__framework_name__, defaults.LATEST_PY2_VERSION)\n\n\n@patch(""sagemaker.chainer.estimator.empty_framework_version_warning"")\ndef test_empty_framework_version(warning, sagemaker_session):\n    estimator = Chainer(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        framework_version=None,\n    )\n\n    assert estimator.framework_version == defaults.CHAINER_VERSION\n    warning.assert_called_with(defaults.CHAINER_VERSION, Chainer.LATEST_VERSION)\n\n\n@patch(""sagemaker.chainer.model.empty_framework_version_warning"")\ndef test_model_empty_framework_version(warning, sagemaker_session):\n    model = ChainerModel(\n        MODEL_DATA,\n        role=ROLE,\n        entry_point=SCRIPT_PATH,\n        sagemaker_session=sagemaker_session,\n        framework_version=None,\n    )\n    assert model.framework_version == defaults.CHAINER_VERSION\n    warning.assert_called_with(defaults.CHAINER_VERSION, defaults.LATEST_VERSION)\n\n\ndef test_custom_image_estimator_deploy(sagemaker_session):\n    custom_image = ""mycustomimage:latest""\n    chainer = _chainer_estimator(sagemaker_session)\n    chainer.fit(inputs=""s3://mybucket/train"", job_name=""new_name"")\n    model = chainer.create_model(image=custom_image)\n    assert model.image == custom_image\n'"
tests/unit/test_cli.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport pytest\nimport sagemaker.cli.main as cli\nfrom mock import patch\n\nCOMMON_ARGS = (\n    ""--role-name myrole --data mydata --script myscript --job-name myjob --bucket-name mybucket ""\n    + ""--python py3 --instance-type myinstance --instance-count 2""\n)\n\nTRAIN_ARGS = ""--hyperparameters myhyperparameters.json""\n\nLOG_ARGS = ""--log-level debug --botocore-log-level debug""\n\nHOST_ARGS = ""--env ENV1=env1 ENV2=env2""\n\n\ndef assert_common_defaults(args):\n    assert args.data == ""./data""\n    assert args.script == ""./script.py""\n    assert args.job_name is None\n    assert args.bucket_name is None\n    assert args.python == ""py2""\n    assert args.instance_type == ""ml.m4.xlarge""\n    assert args.instance_count == 1\n    assert args.log_level == ""info""\n    assert args.botocore_log_level == ""warning""\n\n\ndef assert_common_non_defaults(args):\n    assert args.data == ""mydata""\n    assert args.script == ""myscript""\n    assert args.job_name == ""myjob""\n    assert args.bucket_name == ""mybucket""\n    assert args.role_name == ""myrole""\n    assert args.python == ""py3""\n    assert args.instance_type == ""myinstance""\n    assert args.instance_count == 2\n    assert args.log_level == ""debug""\n    assert args.botocore_log_level == ""debug""\n\n\ndef assert_train_defaults(args):\n    assert args.hyperparameters == ""./hyperparameters.json""\n\n\ndef assert_train_non_defaults(args):\n    assert args.hyperparameters == ""myhyperparameters.json""\n\n\ndef assert_host_defaults(args):\n    assert args.env == []\n\n\ndef assert_host_non_defaults(args):\n    assert args.env == [""ENV1=env1"", ""ENV2=env2""]\n\n\ndef test_args_mxnet_train_defaults():\n    args = cli.parse_arguments(""mxnet train --role-name role"".split())\n    assert_common_defaults(args)\n    assert_train_defaults(args)\n    assert args.func.__module__ == ""sagemaker.cli.mxnet""\n    assert args.func.__name__ == ""train""\n\n\ndef test_args_mxnet_train_non_defaults():\n    args = cli.parse_arguments(\n        ""{} mxnet train --role-name role {} {}"".format(LOG_ARGS, COMMON_ARGS, TRAIN_ARGS).split()\n    )\n    assert_common_non_defaults(args)\n    assert_train_non_defaults(args)\n    assert args.func.__module__ == ""sagemaker.cli.mxnet""\n    assert args.func.__name__ == ""train""\n\n\ndef test_args_mxnet_host_defaults():\n    args = cli.parse_arguments(""mxnet host --role-name role"".split())\n    assert_common_defaults(args)\n    assert_host_defaults(args)\n    assert args.func.__module__ == ""sagemaker.cli.mxnet""\n    assert args.func.__name__ == ""host""\n\n\ndef test_args_mxnet_host_non_defaults():\n    args = cli.parse_arguments(\n        ""{} mxnet host --role-name role {} {}"".format(LOG_ARGS, COMMON_ARGS, HOST_ARGS).split()\n    )\n    assert_common_non_defaults(args)\n    assert_host_non_defaults(args)\n    assert args.func.__module__ == ""sagemaker.cli.mxnet""\n    assert args.func.__name__ == ""host""\n\n\ndef test_args_tensorflow_train_defaults():\n    args = cli.parse_arguments(""tensorflow train --role-name role"".split())\n    assert_common_defaults(args)\n    assert_train_defaults(args)\n    assert args.training_steps is None\n    assert args.evaluation_steps is None\n    assert args.func.__module__ == ""sagemaker.cli.tensorflow""\n    assert args.func.__name__ == ""train""\n\n\ndef test_args_tensorflow_train_non_defaults():\n    args = cli.parse_arguments(\n        ""{} tensorflow train --role-name role --training-steps 10 --evaluation-steps 5 {} {}"".format(\n            LOG_ARGS, COMMON_ARGS, TRAIN_ARGS\n        ).split()\n    )\n    assert_common_non_defaults(args)\n    assert_train_non_defaults(args)\n    assert args.training_steps == 10\n    assert args.evaluation_steps == 5\n    assert args.func.__module__ == ""sagemaker.cli.tensorflow""\n    assert args.func.__name__ == ""train""\n\n\ndef test_args_tensorflow_host_defaults():\n    args = cli.parse_arguments(""tensorflow host --role-name role"".split())\n    assert_common_defaults(args)\n    assert_host_defaults(args)\n    assert args.func.__module__ == ""sagemaker.cli.tensorflow""\n    assert args.func.__name__ == ""host""\n\n\ndef test_args_tensorflow_host_non_defaults():\n    args = cli.parse_arguments(\n        ""{} tensorflow host --role-name role {} {}"".format(LOG_ARGS, COMMON_ARGS, HOST_ARGS).split()\n    )\n    assert_common_non_defaults(args)\n    assert_host_non_defaults(args)\n    assert args.func.__module__ == ""sagemaker.cli.tensorflow""\n    assert args.func.__name__ == ""host""\n\n\ndef test_args_invalid_framework():\n    with pytest.raises(SystemExit):\n        cli.parse_arguments(""fakeframework train --role-name role"".split())\n\n\ndef test_args_invalid_subcommand():\n    with pytest.raises(SystemExit):\n        cli.parse_arguments(""mxnet drain"".split())\n\n\ndef test_args_invalid_args():\n    with pytest.raises(SystemExit):\n        cli.parse_arguments(""tensorflow train --role-name role --notdata foo"".split())\n\n\ndef test_args_invalid_mxnet_python():\n    with pytest.raises(SystemExit):\n        cli.parse_arguments(""mxnet train --role-name role nython py2"".split())\n\n\ndef test_args_invalid_host_args_in_train():\n    with pytest.raises(SystemExit):\n        cli.parse_arguments(""mxnet train --role-name role --env FOO=bar"".split())\n\n\ndef test_args_invalid_train_args_in_host():\n    with pytest.raises(SystemExit):\n        cli.parse_arguments(""tensorflow host --role-name role --hyperparameters foo.json"".split())\n\n\n@patch(""sagemaker.mxnet.estimator.MXNet"")\n@patch(""sagemaker.Session"")\ndef test_mxnet_train(session, estimator):\n    args = cli.parse_arguments(""mxnet train --role-name role"".split())\n    args.func(args)\n    session.return_value.upload_data.assert_called()\n    estimator.assert_called()\n    estimator.return_value.fit.assert_called()\n\n\n@patch(""sagemaker.mxnet.model.MXNetModel"")\n@patch(""sagemaker.cli.common.HostCommand.upload_model"")\n@patch(""sagemaker.Session"")\ndef test_mxnet_host(session, upload_model, model):\n    args = cli.parse_arguments(""mxnet host --role-name role"".split())\n    args.func(args)\n    session.assert_called()\n    upload_model.assert_called()\n    model.assert_called()\n    model.return_value.deploy.assert_called()\n'"
tests/unit/test_common.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport numpy as np\nimport tempfile\nimport pytest\nimport itertools\nfrom scipy.sparse import coo_matrix\nfrom sagemaker.amazon.common import (\n    record_deserializer,\n    write_numpy_to_dense_tensor,\n    read_recordio,\n    numpy_to_record_serializer,\n    write_spmatrix_to_sparse_tensor,\n)\nfrom sagemaker.amazon.record_pb2 import Record\n\n\ndef test_serializer():\n    s = numpy_to_record_serializer()\n    array_data = [[1.0, 2.0, 3.0], [10.0, 20.0, 30.0]]\n    buf = s(np.array(array_data))\n    for record_data, expected in zip(read_recordio(buf), array_data):\n        record = Record()\n        record.ParseFromString(record_data)\n        assert record.features[""values""].float64_tensor.values == expected\n\n\ndef test_serializer_accepts_one_dimensional_array():\n    s = numpy_to_record_serializer()\n    array_data = [1.0, 2.0, 3.0]\n    buf = s(np.array(array_data))\n    record_data = next(read_recordio(buf))\n    record = Record()\n    record.ParseFromString(record_data)\n    assert record.features[""values""].float64_tensor.values == array_data\n\n\ndef test_deserializer():\n    array_data = [[1.0, 2.0, 3.0], [10.0, 20.0, 30.0]]\n    s = numpy_to_record_serializer()\n    buf = s(np.array(array_data))\n    d = record_deserializer()\n    for record, expected in zip(d(buf, ""who cares""), array_data):\n        assert record.features[""values""].float64_tensor.values == expected\n\n\ndef test_float_write_numpy_to_dense_tensor():\n    array_data = [[1.0, 2.0, 3.0], [10.0, 20.0, 30.0]]\n    array = np.array(array_data)\n    with tempfile.TemporaryFile() as f:\n        write_numpy_to_dense_tensor(f, array)\n        f.seek(0)\n        for record_data, expected in zip(read_recordio(f), array_data):\n            record = Record()\n            record.ParseFromString(record_data)\n            assert record.features[""values""].float64_tensor.values == expected\n\n\ndef test_float32_write_numpy_to_dense_tensor():\n    array_data = [[1.0, 2.0, 3.0], [10.0, 20.0, 30.0]]\n    array = np.array(array_data).astype(np.dtype(""float32""))\n    with tempfile.TemporaryFile() as f:\n        write_numpy_to_dense_tensor(f, array)\n        f.seek(0)\n        for record_data, expected in zip(read_recordio(f), array_data):\n            record = Record()\n            record.ParseFromString(record_data)\n            assert record.features[""values""].float32_tensor.values == expected\n\n\ndef test_int_write_numpy_to_dense_tensor():\n    array_data = [[1, 2, 3], [10, 20, 3]]\n    array = np.array(array_data)\n    with tempfile.TemporaryFile() as f:\n        write_numpy_to_dense_tensor(f, array)\n        f.seek(0)\n        for record_data, expected in zip(read_recordio(f), array_data):\n            record = Record()\n            record.ParseFromString(record_data)\n            assert record.features[""values""].int32_tensor.values == expected\n\n\ndef test_int_label():\n    array_data = [[1, 2, 3], [10, 20, 3]]\n    array = np.array(array_data)\n    label_data = np.array([99, 98, 97])\n    with tempfile.TemporaryFile() as f:\n        write_numpy_to_dense_tensor(f, array, label_data)\n        f.seek(0)\n        for record_data, expected, label in zip(read_recordio(f), array_data, label_data):\n            record = Record()\n            record.ParseFromString(record_data)\n            assert record.features[""values""].int32_tensor.values == expected\n            assert record.label[""values""].int32_tensor.values == [label]\n\n\ndef test_float32_label():\n    array_data = [[1, 2, 3], [10, 20, 3]]\n    array = np.array(array_data)\n    label_data = np.array([99, 98, 97]).astype(np.dtype(""float32""))\n    with tempfile.TemporaryFile() as f:\n        write_numpy_to_dense_tensor(f, array, label_data)\n        f.seek(0)\n        for record_data, expected, label in zip(read_recordio(f), array_data, label_data):\n            record = Record()\n            record.ParseFromString(record_data)\n            assert record.features[""values""].int32_tensor.values == expected\n            assert record.label[""values""].float32_tensor.values == [label]\n\n\ndef test_float_label():\n    array_data = [[1, 2, 3], [10, 20, 3]]\n    array = np.array(array_data)\n    label_data = np.array([99, 98, 97]).astype(np.dtype(""float64""))\n    with tempfile.TemporaryFile() as f:\n        write_numpy_to_dense_tensor(f, array, label_data)\n        f.seek(0)\n        for record_data, expected, label in zip(read_recordio(f), array_data, label_data):\n            record = Record()\n            record.ParseFromString(record_data)\n            assert record.features[""values""].int32_tensor.values == expected\n            assert record.label[""values""].float64_tensor.values == [label]\n\n\ndef test_invalid_array():\n    array_data = [[[1, 2, 3], [10, 20, 3]], [[1, 2, 3], [10, 20, 3]]]\n    array = np.array(array_data)\n    label_data = np.array([99, 98, 97]).astype(np.dtype(""float64""))\n    with tempfile.TemporaryFile() as f:\n        with pytest.raises(ValueError):\n            write_numpy_to_dense_tensor(f, array, label_data)\n\n\ndef test_invalid_label():\n    array_data = [[1, 2, 3], [10, 20, 3]]\n    array = np.array(array_data)\n    label_data = np.array([99, 98, 97, 1000]).astype(np.dtype(""float64""))\n    with tempfile.TemporaryFile() as f:\n        with pytest.raises(ValueError):\n            write_numpy_to_dense_tensor(f, array, label_data)\n\n\ndef test_dense_float_write_spmatrix_to_sparse_tensor():\n    array_data = [[1.0, 2.0, 3.0], [10.0, 20.0, 30.0]]\n    keys_data = [[0, 1, 2], [0, 1, 2]]\n    array = coo_matrix(np.array(array_data))\n    with tempfile.TemporaryFile() as f:\n        write_spmatrix_to_sparse_tensor(f, array)\n        f.seek(0)\n        for record_data, expected_data, expected_keys in zip(\n            read_recordio(f), array_data, keys_data\n        ):\n            record = Record()\n            record.ParseFromString(record_data)\n            assert record.features[""values""].float64_tensor.values == expected_data\n            assert record.features[""values""].float64_tensor.keys == expected_keys\n            assert record.features[""values""].float64_tensor.shape == [len(expected_data)]\n\n\ndef test_dense_float32_write_spmatrix_to_sparse_tensor():\n    array_data = [[1.0, 2.0, 3.0], [10.0, 20.0, 30.0]]\n    keys_data = [[0, 1, 2], [0, 1, 2]]\n    array = coo_matrix(np.array(array_data).astype(np.dtype(""float32"")))\n    with tempfile.TemporaryFile() as f:\n        write_spmatrix_to_sparse_tensor(f, array)\n        f.seek(0)\n        for record_data, expected_data, expected_keys in zip(\n            read_recordio(f), array_data, keys_data\n        ):\n            record = Record()\n            record.ParseFromString(record_data)\n            assert record.features[""values""].float32_tensor.values == expected_data\n            assert record.features[""values""].float32_tensor.keys == expected_keys\n            assert record.features[""values""].float32_tensor.shape == [len(expected_data)]\n\n\ndef test_dense_int_write_spmatrix_to_sparse_tensor():\n    array_data = [[1.0, 2.0, 3.0], [10.0, 20.0, 30.0]]\n    keys_data = [[0, 1, 2], [0, 1, 2]]\n    array = coo_matrix(np.array(array_data).astype(np.dtype(""int"")))\n    with tempfile.TemporaryFile() as f:\n        write_spmatrix_to_sparse_tensor(f, array)\n        f.seek(0)\n        for record_data, expected_data, expected_keys in zip(\n            read_recordio(f), array_data, keys_data\n        ):\n            record = Record()\n            record.ParseFromString(record_data)\n            assert record.features[""values""].int32_tensor.values == expected_data\n            assert record.features[""values""].int32_tensor.keys == expected_keys\n            assert record.features[""values""].int32_tensor.shape == [len(expected_data)]\n\n\ndef test_dense_int_spmatrix_to_sparse_label():\n    array_data = [[1, 2, 3], [10, 20, 3]]\n    keys_data = [[0, 1, 2], [0, 1, 2]]\n    array = coo_matrix(np.array(array_data))\n    label_data = np.array([99, 98, 97])\n    with tempfile.TemporaryFile() as f:\n        write_spmatrix_to_sparse_tensor(f, array, label_data)\n        f.seek(0)\n        for record_data, expected_data, expected_keys, label in zip(\n            read_recordio(f), array_data, keys_data, label_data\n        ):\n            record = Record()\n            record.ParseFromString(record_data)\n            assert record.features[""values""].int32_tensor.values == expected_data\n            assert record.features[""values""].int32_tensor.keys == expected_keys\n            assert record.label[""values""].int32_tensor.values == [label]\n            assert record.features[""values""].int32_tensor.shape == [len(expected_data)]\n\n\ndef test_dense_float32_spmatrix_to_sparse_label():\n    array_data = [[1, 2, 3], [10, 20, 3]]\n    keys_data = [[0, 1, 2], [0, 1, 2]]\n    array = coo_matrix(np.array(array_data).astype(""float32""))\n    label_data = np.array([99, 98, 97])\n    with tempfile.TemporaryFile() as f:\n        write_spmatrix_to_sparse_tensor(f, array, label_data)\n        f.seek(0)\n        for record_data, expected_data, expected_keys, label in zip(\n            read_recordio(f), array_data, keys_data, label_data\n        ):\n            record = Record()\n            record.ParseFromString(record_data)\n            assert record.features[""values""].float32_tensor.values == expected_data\n            assert record.features[""values""].float32_tensor.keys == expected_keys\n            assert record.label[""values""].int32_tensor.values == [label]\n            assert record.features[""values""].float32_tensor.shape == [len(expected_data)]\n\n\ndef test_dense_float64_spmatrix_to_sparse_label():\n    array_data = [[1, 2, 3], [10, 20, 3]]\n    keys_data = [[0, 1, 2], [0, 1, 2]]\n    array = coo_matrix(np.array(array_data).astype(""float64""))\n    label_data = np.array([99, 98, 97])\n    with tempfile.TemporaryFile() as f:\n        write_spmatrix_to_sparse_tensor(f, array, label_data)\n        f.seek(0)\n        for record_data, expected_data, expected_keys, label in zip(\n            read_recordio(f), array_data, keys_data, label_data\n        ):\n            record = Record()\n            record.ParseFromString(record_data)\n            assert record.features[""values""].float64_tensor.values == expected_data\n            assert record.features[""values""].float64_tensor.keys == expected_keys\n            assert record.label[""values""].int32_tensor.values == [label]\n            assert record.features[""values""].float64_tensor.shape == [len(expected_data)]\n\n\ndef test_invalid_sparse_label():\n    array_data = [[1, 2, 3], [10, 20, 3]]\n    array = coo_matrix(np.array(array_data))\n    label_data = np.array([99, 98, 97, 1000]).astype(np.dtype(""float64""))\n    with tempfile.TemporaryFile() as f:\n        with pytest.raises(ValueError):\n            write_spmatrix_to_sparse_tensor(f, array, label_data)\n\n\ndef test_sparse_float_write_spmatrix_to_sparse_tensor():\n    n = 4\n    array_data = [[1.0, 2.0], [10.0, 30.0], [100.0, 200.0, 300.0, 400.0], [1000.0, 2000.0, 3000.0]]\n    keys_data = [[0, 1], [1, 2], [0, 1, 2, 3], [0, 2, 3]]\n\n    flatten_data = list(itertools.chain.from_iterable(array_data))\n    y_indices = list(itertools.chain.from_iterable(keys_data))\n    x_indices = [[i] * len(keys_data[i]) for i in range(len(keys_data))]\n    x_indices = list(itertools.chain.from_iterable(x_indices))\n\n    array = coo_matrix((flatten_data, (x_indices, y_indices)), dtype=""float64"")\n    with tempfile.TemporaryFile() as f:\n        write_spmatrix_to_sparse_tensor(f, array)\n        f.seek(0)\n        for record_data, expected_data, expected_keys in zip(\n            read_recordio(f), array_data, keys_data\n        ):\n            record = Record()\n            record.ParseFromString(record_data)\n            assert record.features[""values""].float64_tensor.values == expected_data\n            assert record.features[""values""].float64_tensor.keys == expected_keys\n            assert record.features[""values""].float64_tensor.shape == [n]\n\n\ndef test_sparse_float32_write_spmatrix_to_sparse_tensor():\n    n = 4\n    array_data = [[1.0, 2.0], [10.0, 30.0], [100.0, 200.0, 300.0, 400.0], [1000.0, 2000.0, 3000.0]]\n    keys_data = [[0, 1], [1, 2], [0, 1, 2, 3], [0, 2, 3]]\n\n    flatten_data = list(itertools.chain.from_iterable(array_data))\n    y_indices = list(itertools.chain.from_iterable(keys_data))\n    x_indices = [[i] * len(keys_data[i]) for i in range(len(keys_data))]\n    x_indices = list(itertools.chain.from_iterable(x_indices))\n\n    array = coo_matrix((flatten_data, (x_indices, y_indices)), dtype=""float32"")\n    with tempfile.TemporaryFile() as f:\n        write_spmatrix_to_sparse_tensor(f, array)\n        f.seek(0)\n        for record_data, expected_data, expected_keys in zip(\n            read_recordio(f), array_data, keys_data\n        ):\n            record = Record()\n            record.ParseFromString(record_data)\n            assert record.features[""values""].float32_tensor.values == expected_data\n            assert record.features[""values""].float32_tensor.keys == expected_keys\n            assert record.features[""values""].float32_tensor.shape == [n]\n\n\ndef test_sparse_int_write_spmatrix_to_sparse_tensor():\n    n = 4\n    array_data = [[1.0, 2.0], [10.0, 30.0], [100.0, 200.0, 300.0, 400.0], [1000.0, 2000.0, 3000.0]]\n    keys_data = [[0, 1], [1, 2], [0, 1, 2, 3], [0, 2, 3]]\n\n    flatten_data = list(itertools.chain.from_iterable(array_data))\n    y_indices = list(itertools.chain.from_iterable(keys_data))\n    x_indices = [[i] * len(keys_data[i]) for i in range(len(keys_data))]\n    x_indices = list(itertools.chain.from_iterable(x_indices))\n\n    array = coo_matrix((flatten_data, (x_indices, y_indices)), dtype=""int"")\n    with tempfile.TemporaryFile() as f:\n        write_spmatrix_to_sparse_tensor(f, array)\n        f.seek(0)\n        for record_data, expected_data, expected_keys in zip(\n            read_recordio(f), array_data, keys_data\n        ):\n            record = Record()\n            record.ParseFromString(record_data)\n            assert record.features[""values""].int32_tensor.values == expected_data\n            assert record.features[""values""].int32_tensor.keys == expected_keys\n            assert record.features[""values""].int32_tensor.shape == [n]\n\n\ndef test_dense_to_sparse():\n    array_data = [[1, 2, 3], [10, 20, 3]]\n    array = np.array(array_data)\n    label_data = np.array([99, 98, 97]).astype(np.dtype(""float64""))\n    with tempfile.TemporaryFile() as f:\n        with pytest.raises(TypeError):\n            write_spmatrix_to_sparse_tensor(f, array, label_data)\n'"
tests/unit/test_create_deploy_entities.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport pytest\nfrom mock import Mock\n\nimport sagemaker\n\nMODEL_NAME = ""mymodelname""\nENDPOINT_CONFIG_NAME = ""myendpointconfigname""\nENDPOINT_NAME = ""myendpointname""\nROLE = ""myimrole""\nEXPANDED_ROLE = ""arn:aws:iam::111111111111:role/ExpandedRole""\nIMAGE = ""myimage""\nFULL_CONTAINER_DEF = {""Environment"": {}, ""Image"": IMAGE, ""ModelDataUrl"": ""s3://mybucket/mymodel""}\nVPC_CONFIG = {""Subnets"": [""subnet-foo""], ""SecurityGroups"": [""sg-foo""]}\nINITIAL_INSTANCE_COUNT = 1\nINSTANCE_TYPE = ""ml.c4.xlarge""\nACCELERATOR_TYPE = ""ml.eia.medium""\nREGION = ""us-west-2""\n\n\n@pytest.fixture()\ndef sagemaker_session():\n    boto_mock = Mock(name=""boto_session"", region_name=REGION)\n    ims = sagemaker.Session(boto_session=boto_mock)\n    ims.expand_role = Mock(return_value=EXPANDED_ROLE)\n    return ims\n\n\ndef test_create_model(sagemaker_session):\n    returned_name = sagemaker_session.create_model(\n        name=MODEL_NAME, role=ROLE, container_defs=FULL_CONTAINER_DEF, vpc_config=VPC_CONFIG\n    )\n\n    assert returned_name == MODEL_NAME\n    sagemaker_session.sagemaker_client.create_model.assert_called_once_with(\n        ModelName=MODEL_NAME,\n        PrimaryContainer=FULL_CONTAINER_DEF,\n        ExecutionRoleArn=EXPANDED_ROLE,\n        VpcConfig=VPC_CONFIG,\n    )\n\n\ndef test_create_model_expand_primary_container(sagemaker_session):\n    sagemaker_session.create_model(name=MODEL_NAME, role=ROLE, container_defs=IMAGE)\n\n    _1, _2, create_model_kwargs = sagemaker_session.sagemaker_client.create_model.mock_calls[0]\n    assert create_model_kwargs[""PrimaryContainer""] == {""Environment"": {}, ""Image"": IMAGE}\n\n\ndef test_create_endpoint_config(sagemaker_session):\n    returned_name = sagemaker_session.create_endpoint_config(\n        name=ENDPOINT_CONFIG_NAME,\n        model_name=MODEL_NAME,\n        initial_instance_count=INITIAL_INSTANCE_COUNT,\n        instance_type=INSTANCE_TYPE,\n    )\n\n    assert returned_name == ENDPOINT_CONFIG_NAME\n    expected_pvs = [\n        {\n            ""ModelName"": MODEL_NAME,\n            ""InitialInstanceCount"": INITIAL_INSTANCE_COUNT,\n            ""InstanceType"": INSTANCE_TYPE,\n            ""InitialVariantWeight"": 1,\n            ""VariantName"": ""AllTraffic"",\n        }\n    ]\n    sagemaker_session.sagemaker_client.create_endpoint_config.assert_called_once_with(\n        EndpointConfigName=ENDPOINT_CONFIG_NAME, ProductionVariants=expected_pvs, Tags=[]\n    )\n\n\ndef test_create_endpoint_config_with_accelerator(sagemaker_session):\n    returned_name = sagemaker_session.create_endpoint_config(\n        name=ENDPOINT_CONFIG_NAME,\n        model_name=MODEL_NAME,\n        initial_instance_count=INITIAL_INSTANCE_COUNT,\n        instance_type=INSTANCE_TYPE,\n        accelerator_type=ACCELERATOR_TYPE,\n    )\n\n    assert returned_name == ENDPOINT_CONFIG_NAME\n    expected_pvs = [\n        {\n            ""ModelName"": MODEL_NAME,\n            ""InitialInstanceCount"": INITIAL_INSTANCE_COUNT,\n            ""InstanceType"": INSTANCE_TYPE,\n            ""InitialVariantWeight"": 1,\n            ""VariantName"": ""AllTraffic"",\n            ""AcceleratorType"": ACCELERATOR_TYPE,\n        }\n    ]\n    sagemaker_session.sagemaker_client.create_endpoint_config.assert_called_once_with(\n        EndpointConfigName=ENDPOINT_CONFIG_NAME, ProductionVariants=expected_pvs, Tags=[]\n    )\n\n\ndef test_create_endpoint_no_wait(sagemaker_session):\n    returned_name = sagemaker_session.create_endpoint(\n        endpoint_name=ENDPOINT_NAME, config_name=ENDPOINT_CONFIG_NAME, wait=False\n    )\n\n    assert returned_name == ENDPOINT_NAME\n    sagemaker_session.sagemaker_client.create_endpoint.assert_called_once_with(\n        EndpointName=ENDPOINT_NAME, EndpointConfigName=ENDPOINT_CONFIG_NAME, Tags=[]\n    )\n\n\ndef test_create_endpoint_wait(sagemaker_session):\n    sagemaker_session.wait_for_endpoint = Mock()\n    returned_name = sagemaker_session.create_endpoint(\n        endpoint_name=ENDPOINT_NAME, config_name=ENDPOINT_CONFIG_NAME\n    )\n\n    assert returned_name == ENDPOINT_NAME\n    sagemaker_session.sagemaker_client.create_endpoint.assert_called_once_with(\n        EndpointName=ENDPOINT_NAME, EndpointConfigName=ENDPOINT_CONFIG_NAME, Tags=[]\n    )\n    sagemaker_session.wait_for_endpoint.assert_called_once_with(ENDPOINT_NAME)\n'"
tests/unit/test_default_bucket.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport pytest\nfrom botocore.exceptions import ClientError\nfrom mock import Mock\nimport sagemaker\n\nACCOUNT_ID = ""123""\nREGION = ""us-west-2""\nDEFAULT_BUCKET_NAME = ""sagemaker-{}-{}"".format(REGION, ACCOUNT_ID)\n\n\n@pytest.fixture()\ndef sagemaker_session():\n    boto_mock = Mock(name=""boto_session"", region_name=REGION)\n    boto_mock.client(""sts"").get_caller_identity.return_value = {""Account"": ACCOUNT_ID}\n    sagemaker_session = sagemaker.Session(boto_session=boto_mock)\n    sagemaker_session.boto_session.resource(""s3"").Bucket().creation_date = None\n    return sagemaker_session\n\n\ndef test_default_bucket_s3_create_call(sagemaker_session):\n    bucket_name = sagemaker_session.default_bucket()\n\n    create_calls = sagemaker_session.boto_session.resource().create_bucket.mock_calls\n    _1, _2, create_kwargs = create_calls[0]\n    assert bucket_name == DEFAULT_BUCKET_NAME\n    assert len(create_calls) == 1\n    assert create_kwargs == {\n        ""CreateBucketConfiguration"": {""LocationConstraint"": ""us-west-2""},\n        ""Bucket"": bucket_name,\n    }\n    assert sagemaker_session._default_bucket == bucket_name\n\n\ndef test_default_already_cached(sagemaker_session):\n    existing_default = ""mydefaultbucket""\n    sagemaker_session._default_bucket = existing_default\n\n    bucket_name = sagemaker_session.default_bucket()\n\n    create_calls = sagemaker_session.boto_session.resource().create_bucket.mock_calls\n    assert bucket_name == existing_default\n    assert create_calls == []\n\n\ndef test_default_bucket_exists(sagemaker_session):\n    error = ClientError(\n        error_response={""Error"": {""Code"": ""BucketAlreadyOwnedByYou"", ""Message"": ""message""}},\n        operation_name=""foo"",\n    )\n    sagemaker_session.boto_session.resource().create_bucket.side_effect = error\n\n    bucket_name = sagemaker_session.default_bucket()\n    assert bucket_name == DEFAULT_BUCKET_NAME\n\n\ndef test_concurrent_bucket_modification(sagemaker_session):\n    message = ""A conflicting conditional operation is currently in progress against this resource. Please try again""\n    error = ClientError(\n        error_response={""Error"": {""Code"": ""BucketAlreadyOwnedByYou"", ""Message"": message}},\n        operation_name=""foo"",\n    )\n    sagemaker_session.boto_session.resource().create_bucket.side_effect = error\n\n    bucket_name = sagemaker_session.default_bucket()\n    assert bucket_name == DEFAULT_BUCKET_NAME\n\n\ndef test_bucket_creation_client_error(sagemaker_session):\n    with pytest.raises(ClientError):\n        error = ClientError(\n            error_response={""Error"": {""Code"": ""SomethingWrong"", ""Message"": ""message""}},\n            operation_name=""foo"",\n        )\n        sagemaker_session.boto_session.resource().create_bucket.side_effect = error\n\n        sagemaker_session.default_bucket()\n    assert sagemaker_session._default_bucket is None\n\n\ndef test_bucket_creation_other_error(sagemaker_session):\n    with pytest.raises(RuntimeError):\n        error = RuntimeError()\n        sagemaker_session.boto_session.resource().create_bucket.side_effect = error\n\n        sagemaker_session.default_bucket()\n    assert sagemaker_session._default_bucket is None\n'"
tests/unit/test_endpoint_from_job.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport pytest\nfrom mock import Mock\n\nimport sagemaker\n\nJOB_NAME = ""myjob""\nINITIAL_INSTANCE_COUNT = 1\nINSTANCE_TYPE = ""ml.c4.xlarge""\nACCELERATOR_TYPE = ""ml.eia.medium""\nIMAGE = ""myimage""\nS3_MODEL_ARTIFACTS = ""s3://mybucket/mymodel""\nTRAIN_ROLE = ""mytrainrole""\nVPC_CONFIG = {""Subnets"": [""subnet-foo""], ""SecurityGroupIds"": [""sg-foo""]}\nTRAINING_JOB_RESPONSE = {\n    ""AlgorithmSpecification"": {""TrainingImage"": IMAGE},\n    ""ModelArtifacts"": {""S3ModelArtifacts"": S3_MODEL_ARTIFACTS},\n    ""RoleArn"": TRAIN_ROLE,\n    ""VpcConfig"": VPC_CONFIG,\n}\nFULL_CONTAINER_DEF = {""Environment"": {}, ""Image"": IMAGE, ""ModelDataUrl"": S3_MODEL_ARTIFACTS}\nDEPLOY_IMAGE = ""mydeployimage""\nDEPLOY_ROLE = ""mydeployrole""\nNEW_ENTITY_NAME = ""mynewendpoint""\nENV_VARS = {""PYTHONUNBUFFERED"": ""TRUE"", ""some"": ""nonsense""}\nENDPOINT_FROM_MODEL_RETURNED_NAME = ""endpointfrommodelname""\nREGION = ""us-west-2""\n\n\n@pytest.fixture()\ndef sagemaker_session():\n    boto_mock = Mock(name=""boto_session"", region_name=REGION)\n    ims = sagemaker.Session(sagemaker_client=Mock(name=""sagemaker_client""), boto_session=boto_mock)\n    ims.sagemaker_client.describe_training_job = Mock(\n        name=""describe_training_job"", return_value=TRAINING_JOB_RESPONSE\n    )\n\n    ims.endpoint_from_model_data = Mock(\n        ""endpoint_from_model_data"", return_value=ENDPOINT_FROM_MODEL_RETURNED_NAME\n    )\n    return ims\n\n\ndef test_all_defaults_no_existing_entities(sagemaker_session):\n    original_args = {\n        ""job_name"": JOB_NAME,\n        ""initial_instance_count"": INITIAL_INSTANCE_COUNT,\n        ""instance_type"": INSTANCE_TYPE,\n        ""wait"": False,\n    }\n\n    returned_name = sagemaker_session.endpoint_from_job(**original_args)\n\n    expected_args = original_args.copy()\n    expected_args.pop(""job_name"")\n    expected_args[""model_s3_location""] = S3_MODEL_ARTIFACTS\n    expected_args[""deployment_image""] = IMAGE\n    expected_args[""role""] = TRAIN_ROLE\n    expected_args[""name""] = JOB_NAME\n    expected_args[""model_environment_vars""] = None\n    expected_args[""model_vpc_config""] = VPC_CONFIG\n    expected_args[""accelerator_type""] = None\n    expected_args[""data_capture_config""] = None\n    sagemaker_session.endpoint_from_model_data.assert_called_once_with(**expected_args)\n    assert returned_name == ENDPOINT_FROM_MODEL_RETURNED_NAME\n\n\ndef test_no_defaults_no_existing_entities(sagemaker_session):\n    vpc_config_override = {""Subnets"": [""foo"", ""bar""], ""SecurityGroupIds"": [""baz""]}\n\n    original_args = {\n        ""job_name"": JOB_NAME,\n        ""initial_instance_count"": INITIAL_INSTANCE_COUNT,\n        ""instance_type"": INSTANCE_TYPE,\n        ""deployment_image"": DEPLOY_IMAGE,\n        ""role"": DEPLOY_ROLE,\n        ""name"": NEW_ENTITY_NAME,\n        ""model_environment_vars"": ENV_VARS,\n        ""vpc_config_override"": vpc_config_override,\n        ""accelerator_type"": ACCELERATOR_TYPE,\n        ""wait"": False,\n    }\n\n    returned_name = sagemaker_session.endpoint_from_job(**original_args)\n\n    expected_args = original_args.copy()\n    expected_args.pop(""job_name"")\n    expected_args[""model_s3_location""] = S3_MODEL_ARTIFACTS\n    expected_args[""model_vpc_config""] = expected_args.pop(""vpc_config_override"")\n    expected_args[""data_capture_config""] = None\n    sagemaker_session.endpoint_from_model_data.assert_called_once_with(**expected_args)\n    assert returned_name == ENDPOINT_FROM_MODEL_RETURNED_NAME\n'"
tests/unit/test_endpoint_from_model_data.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport pytest\nfrom botocore.exceptions import ClientError\nfrom mock import Mock\nfrom mock import patch\n\nimport sagemaker\n\nENDPOINT_NAME = ""myendpoint""\nINITIAL_INSTANCE_COUNT = 1\nINSTANCE_TYPE = ""ml.c4.xlarge""\nACCELERATOR_TYPE = ""ml.eia.medium""\nS3_MODEL_ARTIFACTS = ""s3://mybucket/mymodel""\nDEPLOY_IMAGE = ""mydeployimage""\nCONTAINER_DEF = {""Environment"": {}, ""Image"": DEPLOY_IMAGE, ""ModelDataUrl"": S3_MODEL_ARTIFACTS}\nVPC_CONFIG = {""Subnets"": [""foo""], ""SecurityGroupIds"": [""bar""]}\nDEPLOY_ROLE = ""mydeployrole""\nENV_VARS = {""PYTHONUNBUFFERED"": ""TRUE"", ""some"": ""nonsense""}\nNAME_FROM_IMAGE = ""namefromimage""\nREGION = ""us-west-2""\n\n\n@pytest.fixture()\ndef sagemaker_session():\n    boto_mock = Mock(name=""boto_session"", region_name=REGION)\n    ims = sagemaker.Session(sagemaker_client=Mock(name=""sagemaker_client""), boto_session=boto_mock)\n    ims.sagemaker_client.describe_model = Mock(\n        name=""describe_model"", side_effect=_raise_does_not_exist_client_error\n    )\n    ims.sagemaker_client.describe_endpoint_config = Mock(\n        name=""describe_endpoint_config"", side_effect=_raise_does_not_exist_client_error\n    )\n    ims.sagemaker_client.describe_endpoint = Mock(\n        name=""describe_endpoint"", side_effect=_raise_does_not_exist_client_error\n    )\n    ims.create_model = Mock(name=""create_model"")\n    ims.create_endpoint_config = Mock(name=""create_endpoint_config"")\n    ims.create_endpoint = Mock(name=""create_endpoint"")\n    return ims\n\n\n@patch(""sagemaker.session.name_from_image"", return_value=NAME_FROM_IMAGE)\ndef test_all_defaults_no_existing_entities(name_from_image_mock, sagemaker_session):\n    returned_name = sagemaker_session.endpoint_from_model_data(\n        model_s3_location=S3_MODEL_ARTIFACTS,\n        deployment_image=DEPLOY_IMAGE,\n        initial_instance_count=INITIAL_INSTANCE_COUNT,\n        instance_type=INSTANCE_TYPE,\n        role=DEPLOY_ROLE,\n        wait=False,\n    )\n\n    sagemaker_session.sagemaker_client.describe_endpoint.assert_called_once_with(\n        EndpointName=NAME_FROM_IMAGE\n    )\n    sagemaker_session.sagemaker_client.describe_model.assert_called_once_with(\n        ModelName=NAME_FROM_IMAGE\n    )\n    sagemaker_session.sagemaker_client.describe_endpoint_config.assert_called_once_with(\n        EndpointConfigName=NAME_FROM_IMAGE\n    )\n    sagemaker_session.create_model.assert_called_once_with(\n        name=NAME_FROM_IMAGE, role=DEPLOY_ROLE, container_defs=CONTAINER_DEF, vpc_config=None\n    )\n    sagemaker_session.create_endpoint_config.assert_called_once_with(\n        name=NAME_FROM_IMAGE,\n        model_name=NAME_FROM_IMAGE,\n        initial_instance_count=INITIAL_INSTANCE_COUNT,\n        instance_type=INSTANCE_TYPE,\n        accelerator_type=None,\n        data_capture_config_dict=None,\n    )\n    sagemaker_session.create_endpoint.assert_called_once_with(\n        endpoint_name=NAME_FROM_IMAGE, config_name=NAME_FROM_IMAGE, wait=False\n    )\n    assert returned_name == NAME_FROM_IMAGE\n\n\n@patch(""sagemaker.session.name_from_image"", return_value=NAME_FROM_IMAGE)\ndef test_no_defaults_no_existing_entities(name_from_image_mock, sagemaker_session):\n    container_def_with_env = CONTAINER_DEF.copy()\n    container_def_with_env.update({""Environment"": ENV_VARS})\n\n    returned_name = sagemaker_session.endpoint_from_model_data(\n        model_s3_location=S3_MODEL_ARTIFACTS,\n        deployment_image=DEPLOY_IMAGE,\n        initial_instance_count=INITIAL_INSTANCE_COUNT,\n        instance_type=INSTANCE_TYPE,\n        role=DEPLOY_ROLE,\n        wait=False,\n        name=ENDPOINT_NAME,\n        model_environment_vars=ENV_VARS,\n        model_vpc_config=VPC_CONFIG,\n        accelerator_type=ACCELERATOR_TYPE,\n    )\n\n    sagemaker_session.sagemaker_client.describe_endpoint.assert_called_once_with(\n        EndpointName=ENDPOINT_NAME\n    )\n    sagemaker_session.sagemaker_client.describe_model.assert_called_once_with(\n        ModelName=ENDPOINT_NAME\n    )\n    sagemaker_session.sagemaker_client.describe_endpoint_config.assert_called_once_with(\n        EndpointConfigName=ENDPOINT_NAME\n    )\n    sagemaker_session.create_model.assert_called_once_with(\n        name=ENDPOINT_NAME,\n        role=DEPLOY_ROLE,\n        container_defs=container_def_with_env,\n        vpc_config=VPC_CONFIG,\n    )\n    sagemaker_session.create_endpoint_config.assert_called_once_with(\n        name=ENDPOINT_NAME,\n        model_name=ENDPOINT_NAME,\n        initial_instance_count=INITIAL_INSTANCE_COUNT,\n        instance_type=INSTANCE_TYPE,\n        accelerator_type=ACCELERATOR_TYPE,\n        data_capture_config_dict=None,\n    )\n    sagemaker_session.create_endpoint.assert_called_once_with(\n        endpoint_name=ENDPOINT_NAME, config_name=ENDPOINT_NAME, wait=False\n    )\n    assert returned_name == ENDPOINT_NAME\n\n\n@patch(""sagemaker.session.name_from_image"", return_value=NAME_FROM_IMAGE)\ndef test_model_and_endpoint_config_exist(name_from_image_mock, sagemaker_session):\n    sagemaker_session.sagemaker_client.describe_model = Mock(name=""describe_model"")\n    sagemaker_session.sagemaker_client.describe_endpoint_config = Mock(\n        name=""describe_endpoint_config""\n    )\n\n    sagemaker_session.endpoint_from_model_data(\n        model_s3_location=S3_MODEL_ARTIFACTS,\n        deployment_image=DEPLOY_IMAGE,\n        initial_instance_count=INITIAL_INSTANCE_COUNT,\n        instance_type=INSTANCE_TYPE,\n        wait=False,\n    )\n\n    sagemaker_session.create_model.assert_not_called()\n    sagemaker_session.create_endpoint_config.assert_not_called()\n    sagemaker_session.create_endpoint.assert_called_once_with(\n        endpoint_name=NAME_FROM_IMAGE, config_name=NAME_FROM_IMAGE, wait=False\n    )\n\n\ndef test_entity_exists():\n    assert sagemaker.session._deployment_entity_exists(lambda: None)\n\n\ndef test_entity_doesnt_exist():\n    assert not sagemaker.session._deployment_entity_exists(_raise_does_not_exist_client_error)\n\n\ndef test_describe_failure():\n    def _raise_unexpected_client_error():\n        response = {\n            ""Error"": {""Code"": ""ValidationException"", ""Message"": ""Name does not satisfy expression.""}\n        }\n        raise ClientError(error_response=response, operation_name=""foo"")\n\n    with pytest.raises(ClientError):\n        sagemaker.session._deployment_entity_exists(_raise_unexpected_client_error)\n\n\ndef _raise_does_not_exist_client_error(**kwargs):\n    response = {""Error"": {""Code"": ""ValidationException"", ""Message"": ""Could not find entity.""}}\n    raise ClientError(error_response=response, operation_name=""foo"")\n'"
tests/unit/test_estimator.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport logging\nimport json\nimport os\nimport subprocess\nfrom time import sleep\n\nimport pytest\nfrom mock import ANY, MagicMock, Mock, patch\n\nfrom sagemaker import vpc_utils\nfrom sagemaker.amazon.amazon_estimator import registry\nfrom sagemaker.algorithm import AlgorithmEstimator\nfrom sagemaker.estimator import Estimator, EstimatorBase, Framework, _TrainingJob\nfrom sagemaker.model import FrameworkModel\nfrom sagemaker.predictor import RealTimePredictor\nfrom sagemaker.session import s3_input, ShuffleConfig\nfrom sagemaker.transformer import Transformer\nfrom botocore.exceptions import ClientError\nimport sagemaker.local\n\nMODEL_DATA = ""s3://bucket/model.tar.gz""\nMODEL_IMAGE = ""mi""\nENTRY_POINT = ""blah.py""\n\nDATA_DIR = os.path.join(os.path.dirname(__file__), "".."", ""data"")\nSCRIPT_NAME = ""dummy_script.py""\nSCRIPT_PATH = os.path.join(DATA_DIR, SCRIPT_NAME)\nTIMESTAMP = ""2017-11-06-14:14:15.671""\nBUCKET_NAME = ""mybucket""\nINSTANCE_COUNT = 1\nINSTANCE_TYPE = ""c4.4xlarge""\nACCELERATOR_TYPE = ""ml.eia.medium""\nROLE = ""DummyRole""\nIMAGE_NAME = ""fakeimage""\nREGION = ""us-west-2""\nJOB_NAME = ""{}-{}"".format(IMAGE_NAME, TIMESTAMP)\nTAGS = [{""Name"": ""some-tag"", ""Value"": ""value-for-tag""}]\nOUTPUT_PATH = ""s3://bucket/prefix""\nGIT_REPO = ""https://github.com/aws/sagemaker-python-sdk.git""\nBRANCH = ""test-branch-git-config""\nCOMMIT = ""ae15c9d7d5b97ea95ea451e4662ee43da3401d73""\nPRIVATE_GIT_REPO_SSH = ""git@github.com:testAccount/private-repo.git""\nPRIVATE_GIT_REPO = ""https://github.com/testAccount/private-repo.git""\nPRIVATE_BRANCH = ""test-branch""\nPRIVATE_COMMIT = ""329bfcf884482002c05ff7f44f62599ebc9f445a""\nCODECOMMIT_REPO = ""https://git-codecommit.us-west-2.amazonaws.com/v1/repos/test-repo/""\nCODECOMMIT_REPO_SSH = ""ssh://git-codecommit.us-west-2.amazonaws.com/v1/repos/test-repo/""\nCODECOMMIT_BRANCH = ""master""\nREPO_DIR = ""/tmp/repo_dir""\n\nDESCRIBE_TRAINING_JOB_RESULT = {""ModelArtifacts"": {""S3ModelArtifacts"": MODEL_DATA}}\n\nRETURNED_JOB_DESCRIPTION = {\n    ""AlgorithmSpecification"": {\n        ""TrainingInputMode"": ""File"",\n        ""TrainingImage"": ""1.dkr.ecr.us-west-2.amazonaws.com/sagemaker-other-py2-cpu:1.0.4"",\n    },\n    ""HyperParameters"": {\n        ""sagemaker_submit_directory"": \'""s3://some/sourcedir.tar.gz""\',\n        ""checkpoint_path"": \'""s3://other/1508872349""\',\n        ""sagemaker_program"": \'""iris-dnn-classifier.py""\',\n        ""sagemaker_enable_cloudwatch_metrics"": ""false"",\n        ""sagemaker_container_log_level"": \'""logging.INFO""\',\n        ""sagemaker_job_name"": \'""neo""\',\n        ""training_steps"": ""100"",\n    },\n    ""RoleArn"": ""arn:aws:iam::366:role/SageMakerRole"",\n    ""ResourceConfig"": {""VolumeSizeInGB"": 30, ""InstanceCount"": 1, ""InstanceType"": ""ml.c4.xlarge""},\n    ""EnableNetworkIsolation"": False,\n    ""StoppingCondition"": {""MaxRuntimeInSeconds"": 24 * 60 * 60},\n    ""TrainingJobName"": ""neo"",\n    ""TrainingJobStatus"": ""Completed"",\n    ""TrainingJobArn"": ""arn:aws:sagemaker:us-west-2:336:training-job/neo"",\n    ""OutputDataConfig"": {""KmsKeyId"": """", ""S3OutputPath"": ""s3://place/output/neo""},\n    ""TrainingJobOutput"": {""S3TrainingJobOutput"": ""s3://here/output.tar.gz""},\n    ""EnableInterContainerTrafficEncryption"": False,\n}\n\nMODEL_CONTAINER_DEF = {\n    ""Environment"": {\n        ""SAGEMAKER_PROGRAM"": ENTRY_POINT,\n        ""SAGEMAKER_SUBMIT_DIRECTORY"": ""s3://mybucket/mi-2017-10-10-14-14-15/sourcedir.tar.gz"",\n        ""SAGEMAKER_CONTAINER_LOG_LEVEL"": ""20"",\n        ""SAGEMAKER_REGION"": REGION,\n        ""SAGEMAKER_ENABLE_CLOUDWATCH_METRICS"": ""false"",\n    },\n    ""Image"": MODEL_IMAGE,\n    ""ModelDataUrl"": MODEL_DATA,\n}\n\nENDPOINT_DESC = {""EndpointConfigName"": ""test-endpoint""}\n\nENDPOINT_CONFIG_DESC = {""ProductionVariants"": [{""ModelName"": ""model-1""}, {""ModelName"": ""model-2""}]}\n\nLIST_TAGS_RESULT = {""Tags"": [{""Key"": ""TagtestKey"", ""Value"": ""TagtestValue""}]}\n\n\nclass DummyFramework(Framework):\n    __framework_name__ = ""dummy""\n\n    def train_image(self):\n        return IMAGE_NAME\n\n    def create_model(\n        self,\n        role=None,\n        model_server_workers=None,\n        entry_point=None,\n        vpc_config_override=vpc_utils.VPC_CONFIG_DEFAULT,\n        enable_network_isolation=None,\n        **kwargs\n    ):\n        if enable_network_isolation is None:\n            enable_network_isolation = self.enable_network_isolation()\n\n        return DummyFrameworkModel(\n            self.sagemaker_session,\n            vpc_config=self.get_vpc_config(vpc_config_override),\n            entry_point=entry_point,\n            enable_network_isolation=enable_network_isolation,\n            role=role,\n            **kwargs\n        )\n\n    @classmethod\n    def _prepare_init_params_from_job_description(cls, job_details, model_channel_name=None):\n        init_params = super(DummyFramework, cls)._prepare_init_params_from_job_description(\n            job_details, model_channel_name\n        )\n        init_params.pop(""image"", None)\n        return init_params\n\n\nclass DummyFrameworkModel(FrameworkModel):\n    def __init__(self, sagemaker_session, entry_point=None, role=ROLE, **kwargs):\n        super(DummyFrameworkModel, self).__init__(\n            MODEL_DATA,\n            MODEL_IMAGE,\n            role,\n            entry_point or ENTRY_POINT,\n            sagemaker_session=sagemaker_session,\n            **kwargs\n        )\n\n    def create_predictor(self, endpoint_name):\n        return None\n\n    def prepare_container_def(self, instance_type, accelerator_type=None):\n        return MODEL_CONTAINER_DEF\n\n\n@pytest.fixture(autouse=True)\ndef mock_create_tar_file():\n    with patch(""sagemaker.utils.create_tar_file"", MagicMock()) as create_tar_file:\n        yield create_tar_file\n\n\n@pytest.fixture()\ndef sagemaker_session():\n    boto_mock = Mock(name=""boto_session"", region_name=REGION)\n    sms = Mock(\n        name=""sagemaker_session"",\n        boto_session=boto_mock,\n        boto_region_name=REGION,\n        config=None,\n        local_mode=False,\n        s3_client=None,\n        s3_resource=None,\n    )\n    sms.default_bucket = Mock(name=""default_bucket"", return_value=BUCKET_NAME)\n    sms.sagemaker_client.describe_training_job = Mock(\n        name=""describe_training_job"", return_value=DESCRIBE_TRAINING_JOB_RESULT\n    )\n    sms.sagemaker_client.describe_endpoint = Mock(return_value=ENDPOINT_DESC)\n    sms.sagemaker_client.describe_endpoint_config = Mock(return_value=ENDPOINT_CONFIG_DESC)\n    sms.sagemaker_client.list_tags = Mock(return_value=LIST_TAGS_RESULT)\n    return sms\n\n\ndef test_framework_all_init_args(sagemaker_session):\n    f = DummyFramework(\n        ""my_script.py"",\n        role=""DummyRole"",\n        train_instance_count=3,\n        train_instance_type=""ml.m4.xlarge"",\n        sagemaker_session=sagemaker_session,\n        train_volume_size=123,\n        train_volume_kms_key=""volumekms"",\n        train_max_run=456,\n        input_mode=""inputmode"",\n        output_path=""outputpath"",\n        output_kms_key=""outputkms"",\n        base_job_name=""basejobname"",\n        tags=[{""foo"": ""bar""}],\n        subnets=[""123"", ""456""],\n        security_group_ids=[""789"", ""012""],\n        metric_definitions=[{""Name"": ""validation-rmse"", ""Regex"": ""validation-rmse=(\\\\d+)""}],\n        encrypt_inter_container_traffic=True,\n        checkpoint_s3_uri=""s3://bucket/checkpoint"",\n        checkpoint_local_path=""file://local/checkpoint"",\n        enable_sagemaker_metrics=True,\n        enable_network_isolation=True,\n    )\n    _TrainingJob.start_new(f, ""s3://mydata"", None)\n    sagemaker_session.train.assert_called_once()\n    _, args = sagemaker_session.train.call_args\n    assert args == {\n        ""input_mode"": ""inputmode"",\n        ""tags"": [{""foo"": ""bar""}],\n        ""hyperparameters"": {},\n        ""image"": ""fakeimage"",\n        ""input_config"": [\n            {\n                ""ChannelName"": ""training"",\n                ""DataSource"": {\n                    ""S3DataSource"": {\n                        ""S3DataType"": ""S3Prefix"",\n                        ""S3DataDistributionType"": ""FullyReplicated"",\n                        ""S3Uri"": ""s3://mydata"",\n                    }\n                },\n            }\n        ],\n        ""output_config"": {""KmsKeyId"": ""outputkms"", ""S3OutputPath"": ""outputpath""},\n        ""vpc_config"": {""Subnets"": [""123"", ""456""], ""SecurityGroupIds"": [""789"", ""012""]},\n        ""stop_condition"": {""MaxRuntimeInSeconds"": 456},\n        ""role"": sagemaker_session.expand_role(),\n        ""job_name"": None,\n        ""resource_config"": {\n            ""VolumeSizeInGB"": 123,\n            ""InstanceCount"": 3,\n            ""VolumeKmsKeyId"": ""volumekms"",\n            ""InstanceType"": ""ml.m4.xlarge"",\n        },\n        ""metric_definitions"": [{""Name"": ""validation-rmse"", ""Regex"": ""validation-rmse=(\\\\d+)""}],\n        ""encrypt_inter_container_traffic"": True,\n        ""experiment_config"": None,\n        ""checkpoint_s3_uri"": ""s3://bucket/checkpoint"",\n        ""checkpoint_local_path"": ""file://local/checkpoint"",\n        ""enable_sagemaker_metrics"": True,\n        ""enable_network_isolation"": True,\n    }\n\n\ndef test_framework_with_spot_and_checkpoints(sagemaker_session):\n    f = DummyFramework(\n        ""my_script.py"",\n        role=""DummyRole"",\n        train_instance_count=3,\n        train_instance_type=""ml.m4.xlarge"",\n        sagemaker_session=sagemaker_session,\n        train_volume_size=123,\n        train_volume_kms_key=""volumekms"",\n        train_max_run=456,\n        input_mode=""inputmode"",\n        output_path=""outputpath"",\n        output_kms_key=""outputkms"",\n        base_job_name=""basejobname"",\n        tags=[{""foo"": ""bar""}],\n        subnets=[""123"", ""456""],\n        security_group_ids=[""789"", ""012""],\n        metric_definitions=[{""Name"": ""validation-rmse"", ""Regex"": ""validation-rmse=(\\\\d+)""}],\n        encrypt_inter_container_traffic=True,\n        train_use_spot_instances=True,\n        train_max_wait=500,\n        checkpoint_s3_uri=""s3://mybucket/checkpoints/"",\n        checkpoint_local_path=""/tmp/checkpoints"",\n    )\n    _TrainingJob.start_new(f, ""s3://mydata"", None)\n    sagemaker_session.train.assert_called_once()\n    _, args = sagemaker_session.train.call_args\n    assert args == {\n        ""input_mode"": ""inputmode"",\n        ""tags"": [{""foo"": ""bar""}],\n        ""hyperparameters"": {},\n        ""image"": ""fakeimage"",\n        ""input_config"": [\n            {\n                ""ChannelName"": ""training"",\n                ""DataSource"": {\n                    ""S3DataSource"": {\n                        ""S3DataType"": ""S3Prefix"",\n                        ""S3DataDistributionType"": ""FullyReplicated"",\n                        ""S3Uri"": ""s3://mydata"",\n                    }\n                },\n            }\n        ],\n        ""output_config"": {""KmsKeyId"": ""outputkms"", ""S3OutputPath"": ""outputpath""},\n        ""vpc_config"": {""Subnets"": [""123"", ""456""], ""SecurityGroupIds"": [""789"", ""012""]},\n        ""stop_condition"": {""MaxRuntimeInSeconds"": 456, ""MaxWaitTimeInSeconds"": 500},\n        ""role"": sagemaker_session.expand_role(),\n        ""job_name"": None,\n        ""resource_config"": {\n            ""VolumeSizeInGB"": 123,\n            ""InstanceCount"": 3,\n            ""VolumeKmsKeyId"": ""volumekms"",\n            ""InstanceType"": ""ml.m4.xlarge"",\n        },\n        ""metric_definitions"": [{""Name"": ""validation-rmse"", ""Regex"": ""validation-rmse=(\\\\d+)""}],\n        ""encrypt_inter_container_traffic"": True,\n        ""train_use_spot_instances"": True,\n        ""checkpoint_s3_uri"": ""s3://mybucket/checkpoints/"",\n        ""checkpoint_local_path"": ""/tmp/checkpoints"",\n        ""experiment_config"": None,\n    }\n\n\ndef test_framework_init_s3_entry_point_invalid(sagemaker_session):\n    with pytest.raises(ValueError) as error:\n        DummyFramework(\n            ""s3://remote-script-because-im-mistaken"",\n            role=ROLE,\n            sagemaker_session=sagemaker_session,\n            train_instance_count=INSTANCE_COUNT,\n            train_instance_type=INSTANCE_TYPE,\n        )\n    assert ""Must be a path to a local file"" in str(error)\n\n\ndef test_sagemaker_s3_uri_invalid(sagemaker_session):\n    with pytest.raises(ValueError) as error:\n        t = DummyFramework(\n            entry_point=SCRIPT_PATH,\n            role=ROLE,\n            sagemaker_session=sagemaker_session,\n            train_instance_count=INSTANCE_COUNT,\n            train_instance_type=INSTANCE_TYPE,\n        )\n        t.fit(""thisdoesntstartwiths3"")\n    assert ""must be a valid S3 or FILE URI"" in str(error)\n\n\ndef test_sagemaker_model_s3_uri_invalid(sagemaker_session):\n    with pytest.raises(ValueError) as error:\n        t = DummyFramework(\n            entry_point=SCRIPT_PATH,\n            role=ROLE,\n            sagemaker_session=sagemaker_session,\n            train_instance_count=INSTANCE_COUNT,\n            train_instance_type=INSTANCE_TYPE,\n            model_uri=""thisdoesntstartwiths3either.tar.gz"",\n        )\n        t.fit(""s3://mydata"")\n    assert ""must be a valid S3 or FILE URI"" in str(error)\n\n\ndef test_sagemaker_model_file_uri_invalid(sagemaker_session):\n    with pytest.raises(ValueError) as error:\n        t = DummyFramework(\n            entry_point=SCRIPT_PATH,\n            role=ROLE,\n            sagemaker_session=sagemaker_session,\n            train_instance_count=INSTANCE_COUNT,\n            train_instance_type=INSTANCE_TYPE,\n            model_uri=""file://notins3.tar.gz"",\n        )\n        t.fit(""s3://mydata"")\n    assert ""File URIs are supported in local mode only"" in str(error)\n\n\ndef test_sagemaker_model_default_channel_name(sagemaker_session):\n    f = DummyFramework(\n        entry_point=""my_script.py"",\n        role=""DummyRole"",\n        train_instance_count=3,\n        train_instance_type=""ml.m4.xlarge"",\n        sagemaker_session=sagemaker_session,\n        model_uri=""s3://model-bucket/prefix/model.tar.gz"",\n    )\n    _TrainingJob.start_new(f, {}, None)\n    sagemaker_session.train.assert_called_once()\n    _, args = sagemaker_session.train.call_args\n    assert args[""input_config""] == [\n        {\n            ""ChannelName"": ""model"",\n            ""InputMode"": ""File"",\n            ""ContentType"": ""application/x-sagemaker-model"",\n            ""DataSource"": {\n                ""S3DataSource"": {\n                    ""S3DataType"": ""S3Prefix"",\n                    ""S3DataDistributionType"": ""FullyReplicated"",\n                    ""S3Uri"": ""s3://model-bucket/prefix/model.tar.gz"",\n                }\n            },\n        }\n    ]\n\n\ndef test_sagemaker_model_custom_channel_name(sagemaker_session):\n    f = DummyFramework(\n        entry_point=""my_script.py"",\n        role=""DummyRole"",\n        train_instance_count=3,\n        train_instance_type=""ml.m4.xlarge"",\n        sagemaker_session=sagemaker_session,\n        model_uri=""s3://model-bucket/prefix/model.tar.gz"",\n        model_channel_name=""testModelChannel"",\n    )\n    _TrainingJob.start_new(f, {}, None)\n    sagemaker_session.train.assert_called_once()\n    _, args = sagemaker_session.train.call_args\n    assert args[""input_config""] == [\n        {\n            ""ChannelName"": ""testModelChannel"",\n            ""InputMode"": ""File"",\n            ""ContentType"": ""application/x-sagemaker-model"",\n            ""DataSource"": {\n                ""S3DataSource"": {\n                    ""S3DataType"": ""S3Prefix"",\n                    ""S3DataDistributionType"": ""FullyReplicated"",\n                    ""S3Uri"": ""s3://model-bucket/prefix/model.tar.gz"",\n                }\n            },\n        }\n    ]\n\n\n@patch(""time.strftime"", return_value=TIMESTAMP)\ndef test_custom_code_bucket(time, sagemaker_session):\n    code_bucket = ""codebucket""\n    prefix = ""someprefix""\n    code_location = ""s3://{}/{}"".format(code_bucket, prefix)\n    t = DummyFramework(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        code_location=code_location,\n    )\n    t.fit(""s3://bucket/mydata"")\n\n    expected_key = ""{}/{}/source/sourcedir.tar.gz"".format(prefix, JOB_NAME)\n    _, s3_args, _ = sagemaker_session.boto_session.resource(""s3"").Object.mock_calls[0]\n    assert s3_args == (code_bucket, expected_key)\n\n    expected_submit_dir = ""s3://{}/{}"".format(code_bucket, expected_key)\n    _, _, train_kwargs = sagemaker_session.train.mock_calls[0]\n    assert train_kwargs[""hyperparameters""][""sagemaker_submit_directory""] == json.dumps(\n        expected_submit_dir\n    )\n\n\n@patch(""time.strftime"", return_value=TIMESTAMP)\ndef test_custom_code_bucket_without_prefix(time, sagemaker_session):\n    code_bucket = ""codebucket""\n    code_location = ""s3://{}"".format(code_bucket)\n    t = DummyFramework(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        code_location=code_location,\n    )\n    t.fit(""s3://bucket/mydata"")\n\n    expected_key = ""{}/source/sourcedir.tar.gz"".format(JOB_NAME)\n    _, s3_args, _ = sagemaker_session.boto_session.resource(""s3"").Object.mock_calls[0]\n    assert s3_args == (code_bucket, expected_key)\n\n    expected_submit_dir = ""s3://{}/{}"".format(code_bucket, expected_key)\n    _, _, train_kwargs = sagemaker_session.train.mock_calls[0]\n    assert train_kwargs[""hyperparameters""][""sagemaker_submit_directory""] == json.dumps(\n        expected_submit_dir\n    )\n\n\ndef test_invalid_custom_code_bucket(sagemaker_session):\n    code_location = ""thisllworkright?""\n    t = DummyFramework(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        code_location=code_location,\n    )\n\n    with pytest.raises(ValueError) as error:\n        t.fit(""s3://bucket/mydata"")\n    assert ""Expecting \'s3\' scheme"" in str(error)\n\n\ndef test_augmented_manifest(sagemaker_session):\n    fw = DummyFramework(\n        entry_point=SCRIPT_PATH,\n        role=""DummyRole"",\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        enable_cloudwatch_metrics=True,\n    )\n    fw.fit(\n        inputs=s3_input(\n            ""s3://mybucket/train_manifest"",\n            s3_data_type=""AugmentedManifestFile"",\n            attribute_names=[""foo"", ""bar""],\n        )\n    )\n\n    _, _, train_kwargs = sagemaker_session.train.mock_calls[0]\n    s3_data_source = train_kwargs[""input_config""][0][""DataSource""][""S3DataSource""]\n    assert s3_data_source[""S3Uri""] == ""s3://mybucket/train_manifest""\n    assert s3_data_source[""S3DataType""] == ""AugmentedManifestFile""\n    assert s3_data_source[""AttributeNames""] == [""foo"", ""bar""]\n\n\ndef test_s3_input_mode(sagemaker_session):\n    expected_input_mode = ""Pipe""\n    fw = DummyFramework(\n        entry_point=SCRIPT_PATH,\n        role=""DummyRole"",\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        enable_cloudwatch_metrics=True,\n    )\n    fw.fit(inputs=s3_input(""s3://mybucket/train_manifest"", input_mode=expected_input_mode))\n\n    actual_input_mode = sagemaker_session.method_calls[1][2][""input_mode""]\n    assert actual_input_mode == expected_input_mode\n\n\ndef test_shuffle_config(sagemaker_session):\n    fw = DummyFramework(\n        entry_point=SCRIPT_PATH,\n        role=""DummyRole"",\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        enable_cloudwatch_metrics=True,\n    )\n    fw.fit(inputs=s3_input(""s3://mybucket/train_manifest"", shuffle_config=ShuffleConfig(100)))\n    _, _, train_kwargs = sagemaker_session.train.mock_calls[0]\n    channel = train_kwargs[""input_config""][0]\n    assert channel[""ShuffleConfig""][""Seed""] == 100\n\n\nBASE_HP = {\n    ""sagemaker_program"": json.dumps(SCRIPT_NAME),\n    ""sagemaker_submit_directory"": json.dumps(\n        ""s3://mybucket/{}/source/sourcedir.tar.gz"".format(JOB_NAME)\n    ),\n    ""sagemaker_job_name"": json.dumps(JOB_NAME),\n}\n\n\ndef test_local_code_location():\n    config = {""local"": {""local_code"": True, ""region"": ""us-west-2""}}\n    sms = Mock(\n        name=""sagemaker_session"",\n        boto_session=None,\n        boto_region_name=REGION,\n        config=config,\n        local_mode=True,\n        spec=sagemaker.local.LocalSession,\n    )\n    t = DummyFramework(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sms,\n        train_instance_count=1,\n        train_instance_type=""local"",\n        base_job_name=IMAGE_NAME,\n        hyperparameters={123: [456], ""learning_rate"": 0.1},\n    )\n\n    t.fit(""file:///data/file"")\n    assert t.source_dir == DATA_DIR\n    assert t.entry_point == ""dummy_script.py""\n\n\n@patch(""time.strftime"", return_value=TIMESTAMP)\ndef test_start_new_convert_hyperparameters_to_str(strftime, sagemaker_session):\n    uri = ""bucket/mydata""\n\n    t = DummyFramework(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        base_job_name=IMAGE_NAME,\n        hyperparameters={123: [456], ""learning_rate"": 0.1},\n    )\n    t.fit(""s3://{}"".format(uri))\n\n    expected_hyperparameters = BASE_HP.copy()\n    expected_hyperparameters[""sagemaker_enable_cloudwatch_metrics""] = ""false""\n    expected_hyperparameters[""sagemaker_container_log_level""] = str(logging.INFO)\n    expected_hyperparameters[""learning_rate""] = json.dumps(0.1)\n    expected_hyperparameters[""123""] = json.dumps([456])\n    expected_hyperparameters[""sagemaker_region""] = \'""us-west-2""\'\n\n    actual_hyperparameter = sagemaker_session.method_calls[1][2][""hyperparameters""]\n    assert actual_hyperparameter == expected_hyperparameters\n\n\n@patch(""time.strftime"", return_value=TIMESTAMP)\ndef test_start_new_wait_called(strftime, sagemaker_session):\n    uri = ""bucket/mydata""\n\n    t = DummyFramework(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n    )\n\n    t.fit(""s3://{}"".format(uri))\n\n    expected_hyperparameters = BASE_HP.copy()\n    expected_hyperparameters[""sagemaker_enable_cloudwatch_metrics""] = ""false""\n    expected_hyperparameters[""sagemaker_container_log_level""] = str(logging.INFO)\n    expected_hyperparameters[""sagemaker_region""] = \'""us-west-2""\'\n\n    actual_hyperparameter = sagemaker_session.method_calls[1][2][""hyperparameters""]\n    assert actual_hyperparameter == expected_hyperparameters\n    assert sagemaker_session.wait_for_job.assert_called_once\n\n\ndef test_delete_endpoint(sagemaker_session):\n    t = DummyFramework(\n        entry_point=SCRIPT_PATH,\n        role=""DummyRole"",\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        container_log_level=logging.INFO,\n    )\n\n    class tj(object):\n        @property\n        def name(self):\n            return ""myjob""\n\n    t.latest_training_job = tj()\n\n    t.delete_endpoint()\n\n    sagemaker_session.delete_endpoint.assert_called_with(""myjob"")\n\n\ndef test_delete_endpoint_without_endpoint(sagemaker_session):\n    t = DummyFramework(\n        entry_point=SCRIPT_PATH,\n        role=""DummyRole"",\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n    )\n\n    with pytest.raises(ValueError) as error:\n        t.delete_endpoint()\n    assert ""Endpoint was not created yet"" in str(error)\n\n\ndef test_enable_cloudwatch_metrics(sagemaker_session):\n    fw = DummyFramework(\n        entry_point=SCRIPT_PATH,\n        role=""DummyRole"",\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        enable_cloudwatch_metrics=True,\n    )\n    fw.fit(inputs=s3_input(""s3://mybucket/train""))\n\n    _, _, train_kwargs = sagemaker_session.train.mock_calls[0]\n    assert train_kwargs[""hyperparameters""][""sagemaker_enable_cloudwatch_metrics""]\n\n\ndef test_attach_framework(sagemaker_session):\n    returned_job_description = RETURNED_JOB_DESCRIPTION.copy()\n    returned_job_description[""VpcConfig""] = {""Subnets"": [""foo""], ""SecurityGroupIds"": [""bar""]}\n    returned_job_description[""EnableNetworkIsolation""] = True\n    sagemaker_session.sagemaker_client.describe_training_job = Mock(\n        name=""describe_training_job"", return_value=returned_job_description\n    )\n\n    framework_estimator = DummyFramework.attach(\n        training_job_name=""neo"", sagemaker_session=sagemaker_session\n    )\n    assert framework_estimator._current_job_name == ""neo""\n    assert framework_estimator.latest_training_job.job_name == ""neo""\n    assert framework_estimator.role == ""arn:aws:iam::366:role/SageMakerRole""\n    assert framework_estimator.train_instance_count == 1\n    assert framework_estimator.train_max_run == 24 * 60 * 60\n    assert framework_estimator.input_mode == ""File""\n    assert framework_estimator.base_job_name == ""neo""\n    assert framework_estimator.output_path == ""s3://place/output/neo""\n    assert framework_estimator.output_kms_key == """"\n    assert framework_estimator.hyperparameters()[""training_steps""] == ""100""\n    assert framework_estimator.source_dir == ""s3://some/sourcedir.tar.gz""\n    assert framework_estimator.entry_point == ""iris-dnn-classifier.py""\n    assert framework_estimator.subnets == [""foo""]\n    assert framework_estimator.security_group_ids == [""bar""]\n    assert framework_estimator.encrypt_inter_container_traffic is False\n    assert framework_estimator.tags == LIST_TAGS_RESULT[""Tags""]\n    assert framework_estimator.enable_network_isolation() is True\n\n\ndef test_attach_without_hyperparameters(sagemaker_session):\n    returned_job_description = RETURNED_JOB_DESCRIPTION.copy()\n    del returned_job_description[""HyperParameters""]\n\n    mock_describe_training_job = Mock(\n        name=""describe_training_job"", return_value=returned_job_description\n    )\n    sagemaker_session.sagemaker_client.describe_training_job = mock_describe_training_job\n\n    estimator = Estimator.attach(training_job_name=""job"", sagemaker_session=sagemaker_session)\n\n    assert estimator.hyperparameters() == {}\n\n\ndef test_attach_framework_with_tuning(sagemaker_session):\n    returned_job_description = RETURNED_JOB_DESCRIPTION.copy()\n    returned_job_description[""HyperParameters""][""_tuning_objective_metric""] = ""Validation-accuracy""\n\n    mock_describe_training_job = Mock(\n        name=""describe_training_job"", return_value=returned_job_description\n    )\n    sagemaker_session.sagemaker_client.describe_training_job = mock_describe_training_job\n\n    framework_estimator = DummyFramework.attach(\n        training_job_name=""neo"", sagemaker_session=sagemaker_session\n    )\n    assert framework_estimator.latest_training_job.job_name == ""neo""\n    assert framework_estimator.role == ""arn:aws:iam::366:role/SageMakerRole""\n    assert framework_estimator.train_instance_count == 1\n    assert framework_estimator.train_max_run == 24 * 60 * 60\n    assert framework_estimator.input_mode == ""File""\n    assert framework_estimator.base_job_name == ""neo""\n    assert framework_estimator.output_path == ""s3://place/output/neo""\n    assert framework_estimator.output_kms_key == """"\n    hyper_params = framework_estimator.hyperparameters()\n    assert hyper_params[""training_steps""] == ""100""\n    assert hyper_params[""_tuning_objective_metric""] == \'""Validation-accuracy""\'\n    assert framework_estimator.source_dir == ""s3://some/sourcedir.tar.gz""\n    assert framework_estimator.entry_point == ""iris-dnn-classifier.py""\n    assert framework_estimator.encrypt_inter_container_traffic is False\n\n\ndef test_attach_framework_with_model_channel(sagemaker_session):\n    s3_uri = ""s3://some/s3/path/model.tar.gz""\n    returned_job_description = RETURNED_JOB_DESCRIPTION.copy()\n    returned_job_description[""InputDataConfig""] = [\n        {\n            ""ChannelName"": ""model"",\n            ""InputMode"": ""File"",\n            ""DataSource"": {""S3DataSource"": {""S3Uri"": s3_uri}},\n        }\n    ]\n\n    sagemaker_session.sagemaker_client.describe_training_job = Mock(\n        name=""describe_training_job"", return_value=returned_job_description\n    )\n\n    framework_estimator = DummyFramework.attach(\n        training_job_name=""neo"", sagemaker_session=sagemaker_session\n    )\n    assert framework_estimator.model_uri is s3_uri\n    assert framework_estimator.encrypt_inter_container_traffic is False\n\n\ndef test_attach_framework_with_inter_container_traffic_encryption_flag(sagemaker_session):\n    returned_job_description = RETURNED_JOB_DESCRIPTION.copy()\n    returned_job_description[""EnableInterContainerTrafficEncryption""] = True\n\n    sagemaker_session.sagemaker_client.describe_training_job = Mock(\n        name=""describe_training_job"", return_value=returned_job_description\n    )\n\n    framework_estimator = DummyFramework.attach(\n        training_job_name=""neo"", sagemaker_session=sagemaker_session\n    )\n\n    assert framework_estimator.encrypt_inter_container_traffic is True\n\n\n@patch(""time.strftime"", return_value=TIMESTAMP)\ndef test_fit_verify_job_name(strftime, sagemaker_session):\n    fw = DummyFramework(\n        entry_point=SCRIPT_PATH,\n        role=""DummyRole"",\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        enable_cloudwatch_metrics=True,\n        tags=TAGS,\n        encrypt_inter_container_traffic=True,\n    )\n    fw.fit(inputs=s3_input(""s3://mybucket/train""))\n\n    _, _, train_kwargs = sagemaker_session.train.mock_calls[0]\n\n    assert train_kwargs[""hyperparameters""][""sagemaker_enable_cloudwatch_metrics""]\n    assert train_kwargs[""image""] == IMAGE_NAME\n    assert train_kwargs[""input_mode""] == ""File""\n    assert train_kwargs[""tags""] == TAGS\n    assert train_kwargs[""job_name""] == JOB_NAME\n    assert train_kwargs[""encrypt_inter_container_traffic""] is True\n    assert fw.latest_training_job.name == JOB_NAME\n\n\ndef test_prepare_for_training_unique_job_name_generation(sagemaker_session):\n    fw = DummyFramework(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        enable_cloudwatch_metrics=True,\n    )\n    fw._prepare_for_training()\n    first_job_name = fw._current_job_name\n\n    sleep(0.1)\n    fw._prepare_for_training()\n    second_job_name = fw._current_job_name\n\n    assert first_job_name != second_job_name\n\n\ndef test_prepare_for_training_force_name(sagemaker_session):\n    fw = DummyFramework(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        base_job_name=""some"",\n        enable_cloudwatch_metrics=True,\n    )\n    fw._prepare_for_training(job_name=""use_it"")\n    assert ""use_it"" == fw._current_job_name\n\n\n@patch(""time.strftime"", return_value=TIMESTAMP)\ndef test_prepare_for_training_force_name_generation(strftime, sagemaker_session):\n    fw = DummyFramework(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        base_job_name=""some"",\n        enable_cloudwatch_metrics=True,\n    )\n    fw.base_job_name = None\n    fw._prepare_for_training()\n    assert JOB_NAME == fw._current_job_name\n\n\n@patch(""sagemaker.git_utils.git_clone_repo"")\ndef test_git_support_with_branch_and_commit_succeed(git_clone_repo, sagemaker_session):\n    git_clone_repo.side_effect = lambda gitconfig, entrypoint, source_dir=None, dependencies=None: {\n        ""entry_point"": ""/tmp/repo_dir/entry_point"",\n        ""source_dir"": None,\n        ""dependencies"": None,\n    }\n    git_config = {""repo"": GIT_REPO, ""branch"": BRANCH, ""commit"": COMMIT}\n    entry_point = ""entry_point""\n    fw = DummyFramework(\n        entry_point=entry_point,\n        git_config=git_config,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        enable_cloudwatch_metrics=True,\n    )\n    fw.fit()\n    git_clone_repo.assert_called_once_with(git_config, entry_point, None, [])\n\n\n@patch(""sagemaker.git_utils.git_clone_repo"")\ndef test_git_support_with_branch_succeed(git_clone_repo, sagemaker_session):\n    git_clone_repo.side_effect = lambda gitconfig, entrypoint, source_dir, dependencies=None: {\n        ""entry_point"": ""/tmp/repo_dir/source_dir/entry_point"",\n        ""source_dir"": None,\n        ""dependencies"": None,\n    }\n    git_config = {""repo"": GIT_REPO, ""branch"": BRANCH}\n    entry_point = ""entry_point""\n    fw = DummyFramework(\n        entry_point=entry_point,\n        git_config=git_config,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        enable_cloudwatch_metrics=True,\n    )\n    fw.fit()\n    git_clone_repo.assert_called_once_with(git_config, entry_point, None, [])\n\n\n@patch(""sagemaker.git_utils.git_clone_repo"")\ndef test_git_support_with_dependencies_succeed(git_clone_repo, sagemaker_session):\n    git_clone_repo.side_effect = lambda gitconfig, entrypoint, source_dir, dependencies: {\n        ""entry_point"": ""/tmp/repo_dir/source_dir/entry_point"",\n        ""source_dir"": None,\n        ""dependencies"": [""/tmp/repo_dir/foo"", ""/tmp/repo_dir/foo/bar""],\n    }\n    git_config = {""repo"": GIT_REPO, ""branch"": BRANCH, ""commit"": COMMIT}\n    entry_point = ""source_dir/entry_point""\n    fw = DummyFramework(\n        entry_point=entry_point,\n        git_config=git_config,\n        dependencies=[""foo"", ""foo/bar""],\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        enable_cloudwatch_metrics=True,\n    )\n    fw.fit()\n    git_clone_repo.assert_called_once_with(git_config, entry_point, None, [""foo"", ""foo/bar""])\n\n\n@patch(""sagemaker.git_utils.git_clone_repo"")\ndef test_git_support_without_branch_and_commit_succeed(git_clone_repo, sagemaker_session):\n    git_clone_repo.side_effect = lambda gitconfig, entrypoint, source_dir, dependencies=None: {\n        ""entry_point"": ""/tmp/repo_dir/source_dir/entry_point"",\n        ""source_dir"": None,\n        ""dependencies"": None,\n    }\n    git_config = {""repo"": GIT_REPO}\n    entry_point = ""source_dir/entry_point""\n    fw = DummyFramework(\n        entry_point=entry_point,\n        git_config=git_config,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        enable_cloudwatch_metrics=True,\n    )\n    fw.fit()\n    git_clone_repo.assert_called_once_with(git_config, entry_point, None, [])\n\n\ndef test_git_support_repo_not_provided(sagemaker_session):\n    git_config = {""branch"": BRANCH, ""commit"": COMMIT}\n    fw = DummyFramework(\n        entry_point=""entry_point"",\n        git_config=git_config,\n        source_dir=""source_dir"",\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        enable_cloudwatch_metrics=True,\n    )\n    with pytest.raises(ValueError) as error:\n        fw.fit()\n    assert ""Please provide a repo for git_config."" in str(error)\n\n\ndef test_git_support_bad_repo_url_format(sagemaker_session):\n    git_config = {""repo"": ""hhttps://github.com/user/repo.git"", ""branch"": BRANCH}\n    fw = DummyFramework(\n        entry_point=""entry_point"",\n        git_config=git_config,\n        source_dir=""source_dir"",\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        enable_cloudwatch_metrics=True,\n    )\n    with pytest.raises(ValueError) as error:\n        fw.fit()\n    assert ""Invalid Git url provided."" in str(error)\n\n\n@patch(\n    ""sagemaker.git_utils.git_clone_repo"",\n    side_effect=subprocess.CalledProcessError(\n        returncode=1, cmd=""git clone https://github.com/aws/no-such-repo.git /tmp/repo_dir""\n    ),\n)\ndef test_git_support_git_clone_fail(sagemaker_session):\n    git_config = {""repo"": ""https://github.com/aws/no-such-repo.git"", ""branch"": BRANCH}\n    fw = DummyFramework(\n        entry_point=""entry_point"",\n        git_config=git_config,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        enable_cloudwatch_metrics=True,\n    )\n    with pytest.raises(subprocess.CalledProcessError) as error:\n        fw.fit()\n    assert ""returned non-zero exit status"" in str(error)\n\n\n@patch(\n    ""sagemaker.git_utils.git_clone_repo"",\n    side_effect=subprocess.CalledProcessError(\n        returncode=1, cmd=""git checkout branch-that-does-not-exist""\n    ),\n)\ndef test_git_support_branch_not_exist(sagemaker_session):\n    git_config = {""repo"": GIT_REPO, ""branch"": ""branch-that-does-not-exist"", ""commit"": COMMIT}\n    fw = DummyFramework(\n        entry_point=""entry_point"",\n        git_config=git_config,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        enable_cloudwatch_metrics=True,\n    )\n    with pytest.raises(subprocess.CalledProcessError) as error:\n        fw.fit()\n    assert ""returned non-zero exit status"" in str(error)\n\n\n@patch(\n    ""sagemaker.git_utils.git_clone_repo"",\n    side_effect=subprocess.CalledProcessError(\n        returncode=1, cmd=""git checkout commit-sha-that-does-not-exist""\n    ),\n)\ndef test_git_support_commit_not_exist(sagemaker_session):\n    git_config = {""repo"": GIT_REPO, ""branch"": BRANCH, ""commit"": ""commit-sha-that-does-not-exist""}\n    fw = DummyFramework(\n        entry_point=""entry_point"",\n        git_config=git_config,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        enable_cloudwatch_metrics=True,\n    )\n    with pytest.raises(subprocess.CalledProcessError) as error:\n        fw.fit()\n    assert ""returned non-zero exit status"" in str(error)\n\n\n@patch(\n    ""sagemaker.git_utils.git_clone_repo"",\n    side_effect=ValueError(""Entry point does not exist in the repo.""),\n)\ndef test_git_support_entry_point_not_exist(sagemaker_session):\n    git_config = {""repo"": GIT_REPO, ""branch"": BRANCH, ""commit"": COMMIT}\n    fw = DummyFramework(\n        entry_point=""entry_point_that_does_not_exist"",\n        git_config=git_config,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        enable_cloudwatch_metrics=True,\n    )\n    with pytest.raises(ValueError) as error:\n        fw.fit()\n    assert ""Entry point does not exist in the repo."" in str(error)\n\n\n@patch(\n    ""sagemaker.git_utils.git_clone_repo"",\n    side_effect=ValueError(""Source directory does not exist in the repo.""),\n)\ndef test_git_support_source_dir_not_exist(sagemaker_session):\n    git_config = {""repo"": GIT_REPO, ""branch"": BRANCH, ""commit"": COMMIT}\n    fw = DummyFramework(\n        entry_point=""entry_point"",\n        git_config=git_config,\n        source_dir=""source_dir_that_does_not_exist"",\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        enable_cloudwatch_metrics=True,\n    )\n    with pytest.raises(ValueError) as error:\n        fw.fit()\n    assert ""Source directory does not exist in the repo."" in str(error)\n\n\n@patch(\n    ""sagemaker.git_utils.git_clone_repo"",\n    side_effect=ValueError(""Dependency no-such-dir does not exist in the repo.""),\n)\ndef test_git_support_dependencies_not_exist(sagemaker_session):\n    git_config = {""repo"": GIT_REPO, ""branch"": BRANCH, ""commit"": COMMIT}\n    fw = DummyFramework(\n        entry_point=""entry_point"",\n        git_config=git_config,\n        source_dir=""source_dir"",\n        dependencies=[""foo"", ""no-such-dir""],\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        enable_cloudwatch_metrics=True,\n    )\n    with pytest.raises(ValueError) as error:\n        fw.fit()\n    assert ""Dependency"", ""does not exist in the repo."" in str(error)\n\n\n@patch(\n    ""sagemaker.git_utils.git_clone_repo"",\n    side_effect=lambda gitconfig, entrypoint, source_dir=None, dependencies=None: {\n        ""entry_point"": ""/tmp/repo_dir/entry_point"",\n        ""source_dir"": None,\n        ""dependencies"": None,\n    },\n)\ndef test_git_support_with_username_password_no_2fa(git_clone_repo, sagemaker_session):\n    git_config = {\n        ""repo"": PRIVATE_GIT_REPO,\n        ""branch"": PRIVATE_BRANCH,\n        ""commit"": PRIVATE_COMMIT,\n        ""username"": ""username"",\n        ""password"": ""passw0rd!"",\n    }\n    entry_point = ""entry_point""\n    fw = DummyFramework(\n        entry_point=entry_point,\n        git_config=git_config,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        enable_cloudwatch_metrics=True,\n    )\n    fw.fit()\n    git_clone_repo.assert_called_once_with(git_config, entry_point, None, [])\n    assert fw.entry_point == ""/tmp/repo_dir/entry_point""\n\n\n@patch(\n    ""sagemaker.git_utils.git_clone_repo"",\n    side_effect=lambda gitconfig, entrypoint, source_dir=None, dependencies=None: {\n        ""entry_point"": ""/tmp/repo_dir/entry_point"",\n        ""source_dir"": None,\n        ""dependencies"": None,\n    },\n)\ndef test_git_support_with_token_2fa(git_clone_repo, sagemaker_session):\n    git_config = {\n        ""repo"": PRIVATE_GIT_REPO,\n        ""branch"": PRIVATE_BRANCH,\n        ""commit"": PRIVATE_COMMIT,\n        ""token"": ""my-token"",\n        ""2FA_enabled"": True,\n    }\n    entry_point = ""entry_point""\n    fw = DummyFramework(\n        entry_point=entry_point,\n        git_config=git_config,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        enable_cloudwatch_metrics=True,\n    )\n    fw.fit()\n    git_clone_repo.assert_called_once_with(git_config, entry_point, None, [])\n    assert fw.entry_point == ""/tmp/repo_dir/entry_point""\n\n\n@patch(\n    ""sagemaker.git_utils.git_clone_repo"",\n    side_effect=lambda gitconfig, entrypoint, source_dir=None, dependencies=None: {\n        ""entry_point"": ""/tmp/repo_dir/entry_point"",\n        ""source_dir"": None,\n        ""dependencies"": None,\n    },\n)\ndef test_git_support_ssh_no_passphrase_needed(git_clone_repo, sagemaker_session):\n    git_config = {""repo"": PRIVATE_GIT_REPO_SSH, ""branch"": PRIVATE_BRANCH, ""commit"": PRIVATE_COMMIT}\n    entry_point = ""entry_point""\n    fw = DummyFramework(\n        entry_point=entry_point,\n        git_config=git_config,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        enable_cloudwatch_metrics=True,\n    )\n    fw.fit()\n    git_clone_repo.assert_called_once_with(git_config, entry_point, None, [])\n    assert fw.entry_point == ""/tmp/repo_dir/entry_point""\n\n\n@patch(\n    ""sagemaker.git_utils.git_clone_repo"",\n    side_effect=subprocess.CalledProcessError(\n        returncode=1, cmd=""git clone {} {}"".format(PRIVATE_GIT_REPO_SSH, REPO_DIR)\n    ),\n)\ndef test_git_support_ssh_passphrase_required(git_clone_repo, sagemaker_session):\n    git_config = {""repo"": PRIVATE_GIT_REPO_SSH, ""branch"": PRIVATE_BRANCH, ""commit"": PRIVATE_COMMIT}\n    entry_point = ""entry_point""\n    fw = DummyFramework(\n        entry_point=entry_point,\n        git_config=git_config,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        enable_cloudwatch_metrics=True,\n    )\n    with pytest.raises(subprocess.CalledProcessError) as error:\n        fw.fit()\n    assert ""returned non-zero exit status"" in str(error)\n\n\n@patch(\n    ""sagemaker.git_utils.git_clone_repo"",\n    side_effect=lambda gitconfig, entrypoint, source_dir=None, dependencies=None: {\n        ""entry_point"": ""/tmp/repo_dir/entry_point"",\n        ""source_dir"": None,\n        ""dependencies"": None,\n    },\n)\ndef test_git_support_codecommit_with_username_and_password_succeed(\n    git_clone_repo, sagemaker_session\n):\n    git_config = {\n        ""repo"": CODECOMMIT_REPO,\n        ""branch"": CODECOMMIT_BRANCH,\n        ""username"": ""username"",\n        ""password"": ""passw0rd!"",\n    }\n    entry_point = ""entry_point""\n    fw = DummyFramework(\n        entry_point=entry_point,\n        git_config=git_config,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        enable_cloudwatch_metrics=True,\n    )\n    fw.fit()\n    git_clone_repo.assert_called_once_with(git_config, entry_point, None, [])\n    assert fw.entry_point == ""/tmp/repo_dir/entry_point""\n\n\n@patch(\n    ""sagemaker.git_utils.git_clone_repo"",\n    side_effect=lambda gitconfig, entrypoint, source_dir=None, dependencies=None: {\n        ""entry_point"": ""/tmp/repo_dir/entry_point"",\n        ""source_dir"": None,\n        ""dependencies"": None,\n    },\n)\ndef test_git_support_codecommit_with_ssh_no_passphrase_needed(git_clone_repo, sagemaker_session):\n    git_config = {""repo"": CODECOMMIT_REPO_SSH, ""branch"": CODECOMMIT_BRANCH}\n    entry_point = ""entry_point""\n    fw = DummyFramework(\n        entry_point=entry_point,\n        git_config=git_config,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        # enable_cloudwatch_metrics=True,\n    )\n    fw.fit()\n    git_clone_repo.assert_called_once_with(git_config, entry_point, None, [])\n    assert fw.entry_point == ""/tmp/repo_dir/entry_point""\n\n\n@patch(""time.strftime"", return_value=TIMESTAMP)\ndef test_init_with_source_dir_s3(strftime, sagemaker_session):\n    fw = DummyFramework(\n        entry_point=SCRIPT_PATH,\n        source_dir=""s3://location"",\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        enable_cloudwatch_metrics=False,\n    )\n    fw._prepare_for_training()\n\n    expected_hyperparameters = {\n        ""sagemaker_program"": SCRIPT_NAME,\n        ""sagemaker_job_name"": JOB_NAME,\n        ""sagemaker_enable_cloudwatch_metrics"": False,\n        ""sagemaker_container_log_level"": logging.INFO,\n        ""sagemaker_submit_directory"": ""s3://location"",\n        ""sagemaker_region"": ""us-west-2"",\n    }\n    assert fw._hyperparameters == expected_hyperparameters\n\n\n@patch(""sagemaker.model.utils.name_from_image"", return_value=MODEL_IMAGE)\ndef test_framework_transformer_creation(name_from_image, sagemaker_session):\n    vpc_config = {""Subnets"": [""foo""], ""SecurityGroupIds"": [""bar""]}\n    fw = DummyFramework(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        sagemaker_session=sagemaker_session,\n        subnets=vpc_config[""Subnets""],\n        security_group_ids=vpc_config[""SecurityGroupIds""],\n    )\n    fw.latest_training_job = _TrainingJob(sagemaker_session, JOB_NAME)\n\n    transformer = fw.transformer(INSTANCE_COUNT, INSTANCE_TYPE)\n\n    name_from_image.assert_called_with(MODEL_IMAGE)\n    sagemaker_session.create_model.assert_called_with(\n        MODEL_IMAGE,\n        ROLE,\n        MODEL_CONTAINER_DEF,\n        tags=None,\n        vpc_config=vpc_config,\n        enable_network_isolation=False,\n    )\n\n    assert isinstance(transformer, Transformer)\n    assert transformer.sagemaker_session == sagemaker_session\n    assert transformer.instance_count == INSTANCE_COUNT\n    assert transformer.instance_type == INSTANCE_TYPE\n    assert transformer.model_name == MODEL_IMAGE\n    assert transformer.tags is None\n    assert transformer.env == {}\n\n\n@patch(""sagemaker.model.utils.name_from_image"", return_value=MODEL_IMAGE)\ndef test_framework_transformer_creation_with_optional_params(name_from_image, sagemaker_session):\n    base_name = ""foo""\n    vpc_config = {""Subnets"": [""foo""], ""SecurityGroupIds"": [""bar""]}\n    fw = DummyFramework(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        sagemaker_session=sagemaker_session,\n        base_job_name=base_name,\n        subnets=vpc_config[""Subnets""],\n        security_group_ids=vpc_config[""SecurityGroupIds""],\n        enable_network_isolation=False,\n    )\n    fw.latest_training_job = _TrainingJob(sagemaker_session, JOB_NAME)\n\n    strategy = ""MultiRecord""\n    assemble_with = ""Line""\n    kms_key = ""key""\n    accept = ""text/csv""\n    max_concurrent_transforms = 1\n    max_payload = 6\n    env = {""FOO"": ""BAR""}\n    new_role = ""dummy-model-role""\n    new_vpc_config = {""Subnets"": [""x""], ""SecurityGroupIds"": [""y""]}\n    model_name = ""model-name""\n\n    transformer = fw.transformer(\n        INSTANCE_COUNT,\n        INSTANCE_TYPE,\n        strategy=strategy,\n        assemble_with=assemble_with,\n        output_path=OUTPUT_PATH,\n        output_kms_key=kms_key,\n        accept=accept,\n        tags=TAGS,\n        max_concurrent_transforms=max_concurrent_transforms,\n        max_payload=max_payload,\n        volume_kms_key=kms_key,\n        env=env,\n        role=new_role,\n        model_server_workers=1,\n        vpc_config_override=new_vpc_config,\n        enable_network_isolation=True,\n        model_name=model_name,\n    )\n\n    sagemaker_session.create_model.assert_called_with(\n        model_name,\n        new_role,\n        MODEL_CONTAINER_DEF,\n        vpc_config=new_vpc_config,\n        tags=TAGS,\n        enable_network_isolation=True,\n    )\n    assert transformer.strategy == strategy\n    assert transformer.assemble_with == assemble_with\n    assert transformer.output_path == OUTPUT_PATH\n    assert transformer.output_kms_key == kms_key\n    assert transformer.accept == accept\n    assert transformer.max_concurrent_transforms == max_concurrent_transforms\n    assert transformer.max_payload == max_payload\n    assert transformer.env == env\n    assert transformer.base_transform_job_name == base_name\n    assert transformer.tags == TAGS\n    assert transformer.volume_kms_key == kms_key\n    assert transformer.model_name == model_name\n\n\ndef test_ensure_latest_training_job(sagemaker_session):\n    fw = DummyFramework(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        sagemaker_session=sagemaker_session,\n    )\n    fw.latest_training_job = Mock(name=""training_job"")\n\n    fw._ensure_latest_training_job()\n\n\ndef test_ensure_latest_training_job_failure(sagemaker_session):\n    fw = DummyFramework(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        sagemaker_session=sagemaker_session,\n    )\n\n    with pytest.raises(ValueError) as e:\n        fw._ensure_latest_training_job()\n    assert ""Estimator is not associated with a training job"" in str(e)\n\n\n@patch(""sagemaker.estimator.Estimator.create_model"")\ndef test_estimator_transformer_creation(create_model, sagemaker_session):\n    estimator = Estimator(\n        image_name=IMAGE_NAME,\n        role=ROLE,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        sagemaker_session=sagemaker_session,\n    )\n    estimator.latest_training_job = _TrainingJob(sagemaker_session, JOB_NAME)\n\n    transformer = estimator.transformer(INSTANCE_COUNT, INSTANCE_TYPE)\n\n    create_model.assert_called_with(\n        vpc_config_override=vpc_utils.VPC_CONFIG_DEFAULT,\n        model_kms_key=estimator.output_kms_key,\n        enable_network_isolation=False,\n    )\n\n    assert isinstance(transformer, Transformer)\n    assert transformer.sagemaker_session == sagemaker_session\n    assert transformer.instance_count == INSTANCE_COUNT\n    assert transformer.instance_type == INSTANCE_TYPE\n    assert transformer.model_name == JOB_NAME\n    assert transformer.tags is None\n\n\n@patch(""sagemaker.estimator.Estimator.create_model"")\ndef test_estimator_transformer_creation_with_optional_params(create_model, sagemaker_session):\n    base_name = ""foo""\n    kms_key = ""key""\n\n    estimator = Estimator(\n        image_name=IMAGE_NAME,\n        role=ROLE,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        sagemaker_session=sagemaker_session,\n        base_job_name=base_name,\n        output_kms_key=kms_key,\n    )\n    estimator.latest_training_job = _TrainingJob(sagemaker_session, JOB_NAME)\n\n    strategy = ""MultiRecord""\n    assemble_with = ""Line""\n    accept = ""text/csv""\n    max_concurrent_transforms = 1\n    max_payload = 6\n    env = {""FOO"": ""BAR""}\n    new_vpc_config = {""Subnets"": [""x""], ""SecurityGroupIds"": [""y""]}\n    model_name = ""model-name""\n\n    transformer = estimator.transformer(\n        INSTANCE_COUNT,\n        INSTANCE_TYPE,\n        strategy=strategy,\n        assemble_with=assemble_with,\n        output_path=OUTPUT_PATH,\n        output_kms_key=kms_key,\n        accept=accept,\n        tags=TAGS,\n        max_concurrent_transforms=max_concurrent_transforms,\n        max_payload=max_payload,\n        env=env,\n        role=ROLE,\n        vpc_config_override=new_vpc_config,\n        enable_network_isolation=True,\n        model_name=model_name,\n    )\n\n    create_model.assert_called_with(\n        vpc_config_override=new_vpc_config, model_kms_key=kms_key, enable_network_isolation=True\n    )\n\n    assert transformer.strategy == strategy\n    assert transformer.assemble_with == assemble_with\n    assert transformer.output_path == OUTPUT_PATH\n    assert transformer.output_kms_key == kms_key\n    assert transformer.accept == accept\n    assert transformer.max_concurrent_transforms == max_concurrent_transforms\n    assert transformer.max_payload == max_payload\n    assert transformer.env == env\n    assert transformer.base_transform_job_name == base_name\n    assert transformer.tags == TAGS\n    assert transformer.model_name == model_name\n\n\n# _TrainingJob \'utils\'\ndef test_start_new(sagemaker_session):\n    training_job = _TrainingJob(sagemaker_session, JOB_NAME)\n    hyperparameters = {""mock"": ""hyperparameters""}\n    inputs = ""s3://mybucket/train""\n\n    estimator = Estimator(\n        IMAGE_NAME,\n        ROLE,\n        INSTANCE_COUNT,\n        INSTANCE_TYPE,\n        output_path=OUTPUT_PATH,\n        sagemaker_session=sagemaker_session,\n        hyperparameters=hyperparameters,\n    )\n\n    exp_config = {""ExperimentName"": ""exp"", ""TrialName"": ""t"", ""TrialComponentDisplayName"": ""tc""}\n\n    started_training_job = training_job.start_new(estimator, inputs, experiment_config=exp_config)\n    called_args = sagemaker_session.train.call_args\n\n    assert started_training_job.sagemaker_session == sagemaker_session\n    assert called_args[1][""hyperparameters""] == hyperparameters\n    assert called_args[1][""experiment_config""] == exp_config\n    sagemaker_session.train.assert_called_once()\n\n\ndef test_start_new_not_local_mode_error(sagemaker_session):\n    training_job = _TrainingJob(sagemaker_session, JOB_NAME)\n    inputs = ""file://mybucket/train""\n\n    estimator = Estimator(\n        IMAGE_NAME,\n        ROLE,\n        INSTANCE_COUNT,\n        INSTANCE_TYPE,\n        output_path=OUTPUT_PATH,\n        sagemaker_session=sagemaker_session,\n    )\n    with pytest.raises(ValueError) as error:\n        training_job.start_new(estimator, inputs, None)\n        assert ""File URIs are supported in local mode only. Please use a S3 URI instead."" == str(\n            error\n        )\n\n\ndef test_container_log_level(sagemaker_session):\n    fw = DummyFramework(\n        entry_point=SCRIPT_PATH,\n        role=""DummyRole"",\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        container_log_level=logging.DEBUG,\n    )\n    fw.fit(inputs=s3_input(""s3://mybucket/train""))\n\n    _, _, train_kwargs = sagemaker_session.train.mock_calls[0]\n    assert train_kwargs[""hyperparameters""][""sagemaker_container_log_level""] == ""10""\n\n\n@patch(""sagemaker.utils"")\ndef test_same_code_location_keeps_kms_key(utils, sagemaker_session):\n    fw = DummyFramework(\n        entry_point=SCRIPT_PATH,\n        role=""DummyRole"",\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        output_kms_key=""kms-key"",\n    )\n\n    fw.fit(wait=False)\n\n    extra_args = {""ServerSideEncryption"": ""aws:kms"", ""SSEKMSKeyId"": ""kms-key""}\n    obj = sagemaker_session.boto_session.resource(""s3"").Object\n\n    obj.assert_called_with(""mybucket"", ""%s/source/sourcedir.tar.gz"" % fw._current_job_name)\n\n    obj().upload_file.assert_called_with(utils.create_tar_file(), ExtraArgs=extra_args)\n\n\n@patch(""sagemaker.utils"")\ndef test_different_code_location_kms_key(utils, sagemaker_session):\n    fw = DummyFramework(\n        entry_point=SCRIPT_PATH,\n        role=""DummyRole"",\n        sagemaker_session=sagemaker_session,\n        code_location=""s3://another-location"",\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        output_kms_key=""kms-key"",\n    )\n\n    fw.fit(wait=False)\n\n    obj = sagemaker_session.boto_session.resource(""s3"").Object\n\n    obj.assert_called_with(""another-location"", ""%s/source/sourcedir.tar.gz"" % fw._current_job_name)\n\n    obj().upload_file.assert_called_with(utils.create_tar_file(), ExtraArgs=None)\n\n\n@patch(""sagemaker.utils"")\ndef test_default_code_location_uses_output_path(utils, sagemaker_session):\n    fw = DummyFramework(\n        entry_point=SCRIPT_PATH,\n        role=""DummyRole"",\n        sagemaker_session=sagemaker_session,\n        output_path=""s3://output_path"",\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        output_kms_key=""kms-key"",\n    )\n\n    fw.fit(wait=False)\n\n    obj = sagemaker_session.boto_session.resource(""s3"").Object\n\n    obj.assert_called_with(""output_path"", ""%s/source/sourcedir.tar.gz"" % fw._current_job_name)\n\n    extra_args = {""ServerSideEncryption"": ""aws:kms"", ""SSEKMSKeyId"": ""kms-key""}\n    obj().upload_file.assert_called_with(utils.create_tar_file(), ExtraArgs=extra_args)\n\n\ndef test_wait_without_logs(sagemaker_session):\n    training_job = _TrainingJob(sagemaker_session, JOB_NAME)\n\n    training_job.wait(False)\n\n    sagemaker_session.wait_for_job.assert_called_once()\n    assert not sagemaker_session.logs_for_job.called\n\n\ndef test_wait_with_logs(sagemaker_session):\n    training_job = _TrainingJob(sagemaker_session, JOB_NAME)\n\n    training_job.wait()\n\n    sagemaker_session.logs_for_job.assert_called_once()\n    assert not sagemaker_session.wait_for_job.called\n\n\ndef test_unsupported_type_in_dict():\n    with pytest.raises(ValueError):\n        _TrainingJob._format_inputs_to_input_config({""a"": 66})\n\n\n#################################################################################\n# Tests for the generic Estimator class\n\nNO_INPUT_TRAIN_CALL = {\n    ""hyperparameters"": {},\n    ""image"": IMAGE_NAME,\n    ""input_config"": None,\n    ""input_mode"": ""File"",\n    ""output_config"": {""S3OutputPath"": OUTPUT_PATH},\n    ""resource_config"": {\n        ""InstanceCount"": INSTANCE_COUNT,\n        ""InstanceType"": INSTANCE_TYPE,\n        ""VolumeSizeInGB"": 30,\n    },\n    ""stop_condition"": {""MaxRuntimeInSeconds"": 86400},\n    ""tags"": None,\n    ""vpc_config"": None,\n    ""metric_definitions"": None,\n    ""experiment_config"": None,\n}\n\nINPUT_CONFIG = [\n    {\n        ""DataSource"": {\n            ""S3DataSource"": {\n                ""S3DataDistributionType"": ""FullyReplicated"",\n                ""S3DataType"": ""S3Prefix"",\n                ""S3Uri"": ""s3://bucket/training-prefix"",\n            }\n        },\n        ""ChannelName"": ""train"",\n    }\n]\n\nBASE_TRAIN_CALL = dict(NO_INPUT_TRAIN_CALL)\nBASE_TRAIN_CALL.update({""input_config"": INPUT_CONFIG})\n\nHYPERPARAMS = {""x"": 1, ""y"": ""hello""}\nSTRINGIFIED_HYPERPARAMS = dict([(x, str(y)) for x, y in HYPERPARAMS.items()])\nHP_TRAIN_CALL = dict(BASE_TRAIN_CALL)\nHP_TRAIN_CALL.update({""hyperparameters"": STRINGIFIED_HYPERPARAMS})\n\nEXP_TRAIN_CALL = dict(BASE_TRAIN_CALL)\nEXP_TRAIN_CALL.update(\n    {\n        ""experiment_config"": {\n            ""ExperimentName"": ""exp"",\n            ""TrialName"": ""trial"",\n            ""TrialComponentDisplayName"": ""tc"",\n        }\n    }\n)\n\n\ndef test_fit_deploy_tags_in_estimator(sagemaker_session):\n    tags = [{""Key"": ""TagtestKey"", ""Value"": ""TagtestValue""}]\n    estimator = Estimator(\n        IMAGE_NAME,\n        ROLE,\n        INSTANCE_COUNT,\n        INSTANCE_TYPE,\n        tags=tags,\n        sagemaker_session=sagemaker_session,\n    )\n\n    estimator.fit()\n\n    estimator.deploy(INSTANCE_COUNT, INSTANCE_TYPE)\n\n    variant = [\n        {\n            ""InstanceType"": ""c4.4xlarge"",\n            ""VariantName"": ""AllTraffic"",\n            ""ModelName"": ANY,\n            ""InitialVariantWeight"": 1,\n            ""InitialInstanceCount"": 1,\n        }\n    ]\n\n    job_name = estimator._current_job_name\n    sagemaker_session.endpoint_from_production_variants.assert_called_with(\n        name=job_name,\n        production_variants=variant,\n        tags=tags,\n        kms_key=None,\n        wait=True,\n        data_capture_config_dict=None,\n    )\n\n    sagemaker_session.create_model.assert_called_with(\n        ANY,\n        ""DummyRole"",\n        {""ModelDataUrl"": ""s3://bucket/model.tar.gz"", ""Environment"": {}, ""Image"": ""fakeimage""},\n        enable_network_isolation=False,\n        vpc_config=None,\n        tags=tags,\n    )\n\n\ndef test_fit_deploy_tags(sagemaker_session):\n    estimator = Estimator(\n        IMAGE_NAME, ROLE, INSTANCE_COUNT, INSTANCE_TYPE, sagemaker_session=sagemaker_session\n    )\n\n    estimator.fit()\n\n    tags = [{""Key"": ""TagtestKey"", ""Value"": ""TagtestValue""}]\n    estimator.deploy(INSTANCE_COUNT, INSTANCE_TYPE, tags=tags)\n\n    variant = [\n        {\n            ""InstanceType"": ""c4.4xlarge"",\n            ""VariantName"": ""AllTraffic"",\n            ""ModelName"": ANY,\n            ""InitialVariantWeight"": 1,\n            ""InitialInstanceCount"": 1,\n        }\n    ]\n\n    job_name = estimator._current_job_name\n    sagemaker_session.endpoint_from_production_variants.assert_called_with(\n        name=job_name,\n        production_variants=variant,\n        tags=tags,\n        kms_key=None,\n        wait=True,\n        data_capture_config_dict=None,\n    )\n\n    sagemaker_session.create_model.assert_called_with(\n        ANY,\n        ""DummyRole"",\n        {""ModelDataUrl"": ""s3://bucket/model.tar.gz"", ""Environment"": {}, ""Image"": ""fakeimage""},\n        enable_network_isolation=False,\n        vpc_config=None,\n        tags=tags,\n    )\n\n\ndef test_generic_to_fit_no_input(sagemaker_session):\n    e = Estimator(\n        IMAGE_NAME,\n        ROLE,\n        INSTANCE_COUNT,\n        INSTANCE_TYPE,\n        output_path=OUTPUT_PATH,\n        sagemaker_session=sagemaker_session,\n    )\n\n    e.fit()\n\n    sagemaker_session.train.assert_called_once()\n    assert len(sagemaker_session.train.call_args[0]) == 0\n    args = sagemaker_session.train.call_args[1]\n    assert args[""job_name""].startswith(IMAGE_NAME)\n\n    args.pop(""job_name"")\n    args.pop(""role"")\n\n    assert args == NO_INPUT_TRAIN_CALL\n\n\ndef test_generic_to_fit_no_hps(sagemaker_session):\n    e = Estimator(\n        IMAGE_NAME,\n        ROLE,\n        INSTANCE_COUNT,\n        INSTANCE_TYPE,\n        output_path=OUTPUT_PATH,\n        sagemaker_session=sagemaker_session,\n    )\n\n    e.fit({""train"": ""s3://bucket/training-prefix""})\n\n    sagemaker_session.train.assert_called_once()\n    assert len(sagemaker_session.train.call_args[0]) == 0\n    args = sagemaker_session.train.call_args[1]\n    assert args[""job_name""].startswith(IMAGE_NAME)\n\n    args.pop(""job_name"")\n    args.pop(""role"")\n\n    assert args == BASE_TRAIN_CALL\n\n\ndef test_generic_to_fit_with_hps(sagemaker_session):\n    e = Estimator(\n        IMAGE_NAME,\n        ROLE,\n        INSTANCE_COUNT,\n        INSTANCE_TYPE,\n        output_path=OUTPUT_PATH,\n        sagemaker_session=sagemaker_session,\n    )\n\n    e.set_hyperparameters(**HYPERPARAMS)\n\n    e.fit({""train"": ""s3://bucket/training-prefix""})\n\n    sagemaker_session.train.assert_called_once()\n    assert len(sagemaker_session.train.call_args[0]) == 0\n    args = sagemaker_session.train.call_args[1]\n    assert args[""job_name""].startswith(IMAGE_NAME)\n\n    args.pop(""job_name"")\n    args.pop(""role"")\n\n    assert args == HP_TRAIN_CALL\n\n\ndef test_generic_to_fit_with_experiment_config(sagemaker_session):\n    e = Estimator(\n        IMAGE_NAME,\n        ROLE,\n        INSTANCE_COUNT,\n        INSTANCE_TYPE,\n        output_path=OUTPUT_PATH,\n        sagemaker_session=sagemaker_session,\n    )\n\n    e.fit(\n        inputs={""train"": ""s3://bucket/training-prefix""},\n        experiment_config={\n            ""ExperimentName"": ""exp"",\n            ""TrialName"": ""trial"",\n            ""TrialComponentDisplayName"": ""tc"",\n        },\n    )\n\n    sagemaker_session.train.assert_called_once()\n    assert len(sagemaker_session.train.call_args[0]) == 0\n    args = sagemaker_session.train.call_args[1]\n    assert args[""job_name""].startswith(IMAGE_NAME)\n\n    args.pop(""job_name"")\n    args.pop(""role"")\n\n    assert args == EXP_TRAIN_CALL\n\n\ndef test_generic_to_fit_with_encrypt_inter_container_traffic_flag(sagemaker_session):\n    e = Estimator(\n        IMAGE_NAME,\n        ROLE,\n        INSTANCE_COUNT,\n        INSTANCE_TYPE,\n        output_path=OUTPUT_PATH,\n        sagemaker_session=sagemaker_session,\n        encrypt_inter_container_traffic=True,\n    )\n\n    e.fit()\n\n    sagemaker_session.train.assert_called_once()\n    args = sagemaker_session.train.call_args[1]\n    assert args[""encrypt_inter_container_traffic""] is True\n\n\ndef test_generic_to_fit_with_network_isolation(sagemaker_session):\n    e = Estimator(\n        IMAGE_NAME,\n        ROLE,\n        INSTANCE_COUNT,\n        INSTANCE_TYPE,\n        output_path=OUTPUT_PATH,\n        sagemaker_session=sagemaker_session,\n        enable_network_isolation=True,\n    )\n\n    e.fit()\n\n    sagemaker_session.train.assert_called_once()\n    args = sagemaker_session.train.call_args[1]\n    assert args[""enable_network_isolation""]\n\n\ndef test_generic_to_fit_with_sagemaker_metrics_missing(sagemaker_session):\n    e = Estimator(\n        IMAGE_NAME,\n        ROLE,\n        INSTANCE_COUNT,\n        INSTANCE_TYPE,\n        output_path=OUTPUT_PATH,\n        sagemaker_session=sagemaker_session,\n    )\n\n    e.fit()\n\n    sagemaker_session.train.assert_called_once()\n    args = sagemaker_session.train.call_args[1]\n    assert ""enable_sagemaker_metrics"" not in args\n\n\ndef test_generic_to_fit_with_sagemaker_metrics_enabled(sagemaker_session):\n    e = Estimator(\n        IMAGE_NAME,\n        ROLE,\n        INSTANCE_COUNT,\n        INSTANCE_TYPE,\n        output_path=OUTPUT_PATH,\n        sagemaker_session=sagemaker_session,\n        enable_sagemaker_metrics=True,\n    )\n\n    e.fit()\n\n    sagemaker_session.train.assert_called_once()\n    args = sagemaker_session.train.call_args[1]\n    assert args[""enable_sagemaker_metrics""]\n\n\ndef test_generic_to_fit_with_sagemaker_metrics_disabled(sagemaker_session):\n    e = Estimator(\n        IMAGE_NAME,\n        ROLE,\n        INSTANCE_COUNT,\n        INSTANCE_TYPE,\n        output_path=OUTPUT_PATH,\n        sagemaker_session=sagemaker_session,\n        enable_sagemaker_metrics=False,\n    )\n\n    e.fit()\n\n    sagemaker_session.train.assert_called_once()\n    args = sagemaker_session.train.call_args[1]\n    assert not args[""enable_sagemaker_metrics""]\n\n\ndef test_generic_to_deploy(sagemaker_session):\n    e = Estimator(\n        IMAGE_NAME,\n        ROLE,\n        INSTANCE_COUNT,\n        INSTANCE_TYPE,\n        output_path=OUTPUT_PATH,\n        sagemaker_session=sagemaker_session,\n    )\n\n    e.set_hyperparameters(**HYPERPARAMS)\n\n    e.fit({""train"": ""s3://bucket/training-prefix""})\n\n    predictor = e.deploy(INSTANCE_COUNT, INSTANCE_TYPE)\n\n    sagemaker_session.train.assert_called_once()\n    assert len(sagemaker_session.train.call_args[0]) == 0\n    args = sagemaker_session.train.call_args[1]\n    assert args[""job_name""].startswith(IMAGE_NAME)\n\n    args.pop(""job_name"")\n    args.pop(""role"")\n\n    assert args == HP_TRAIN_CALL\n\n    sagemaker_session.create_model.assert_called_once()\n    args, kwargs = sagemaker_session.create_model.call_args\n    assert args[0].startswith(IMAGE_NAME)\n    assert args[1] == ROLE\n    assert args[2][""Image""] == IMAGE_NAME\n    assert args[2][""ModelDataUrl""] == MODEL_DATA\n    assert kwargs[""vpc_config""] is None\n\n    assert isinstance(predictor, RealTimePredictor)\n    assert predictor.endpoint.startswith(IMAGE_NAME)\n    assert predictor.sagemaker_session == sagemaker_session\n\n\ndef test_generic_to_deploy_network_isolation(sagemaker_session):\n    e = Estimator(\n        IMAGE_NAME,\n        ROLE,\n        INSTANCE_COUNT,\n        INSTANCE_TYPE,\n        output_path=OUTPUT_PATH,\n        enable_network_isolation=True,\n        sagemaker_session=sagemaker_session,\n    )\n\n    e.fit()\n    e.deploy(INSTANCE_COUNT, INSTANCE_TYPE)\n\n    sagemaker_session.create_model.assert_called_once()\n    _, kwargs = sagemaker_session.create_model.call_args\n    assert kwargs[""enable_network_isolation""]\n\n\n@patch(""sagemaker.estimator.Estimator.create_model"")\ndef test_generic_to_deploy_kms(create_model, sagemaker_session):\n    e = Estimator(\n        IMAGE_NAME,\n        ROLE,\n        INSTANCE_COUNT,\n        INSTANCE_TYPE,\n        output_path=OUTPUT_PATH,\n        sagemaker_session=sagemaker_session,\n    )\n    e.fit()\n\n    model = MagicMock()\n    create_model.return_value = model\n\n    endpoint_name = ""foo""\n    kms_key = ""key""\n    e.deploy(INSTANCE_COUNT, INSTANCE_TYPE, endpoint_name=endpoint_name, kms_key=kms_key)\n\n    model.deploy.assert_called_with(\n        instance_type=INSTANCE_TYPE,\n        initial_instance_count=INSTANCE_COUNT,\n        accelerator_type=None,\n        endpoint_name=endpoint_name,\n        update_endpoint=False,\n        tags=None,\n        wait=True,\n        kms_key=kms_key,\n        data_capture_config=None,\n    )\n\n\ndef test_generic_training_job_analytics(sagemaker_session):\n    sagemaker_session.sagemaker_client.describe_training_job = Mock(\n        name=""describe_training_job"",\n        return_value={\n            ""TuningJobArn"": ""arn:aws:sagemaker:us-west-2:968277160000:hyper-parameter-tuning-job/mock-tuner"",\n            ""TrainingStartTime"": 1530562991.299,\n            ""AlgorithmSpecification"": {\n                ""TrainingImage"": ""some-image-url"",\n                ""TrainingInputMode"": ""File"",\n                ""MetricDefinitions"": [\n                    {""Name"": ""train:loss"", ""Regex"": ""train_loss=([0-9]+\\\\.[0-9]+)""},\n                    {""Name"": ""validation:loss"", ""Regex"": ""valid_loss=([0-9]+\\\\.[0-9]+)""},\n                ],\n            },\n        },\n    )\n\n    e = Estimator(\n        IMAGE_NAME,\n        ROLE,\n        INSTANCE_COUNT,\n        INSTANCE_TYPE,\n        output_path=OUTPUT_PATH,\n        sagemaker_session=sagemaker_session,\n    )\n\n    with pytest.raises(ValueError) as err:  # noqa: F841\n        # No training job yet\n        a = e.training_job_analytics\n        assert a is not None  # This line is never reached\n\n    e.set_hyperparameters(**HYPERPARAMS)\n    e.fit({""train"": ""s3://bucket/training-prefix""})\n    a = e.training_job_analytics\n    assert a is not None\n\n\ndef test_generic_create_model_vpc_config_override(sagemaker_session):\n    vpc_config_a = {""Subnets"": [""foo""], ""SecurityGroupIds"": [""bar""]}\n    vpc_config_b = {""Subnets"": [""foo"", ""bar""], ""SecurityGroupIds"": [""baz""]}\n\n    e = Estimator(\n        IMAGE_NAME, ROLE, INSTANCE_COUNT, INSTANCE_TYPE, sagemaker_session=sagemaker_session\n    )\n    e.fit({""train"": ""s3://bucket/training-prefix""})\n    assert e.get_vpc_config() is None\n    assert e.create_model().vpc_config is None\n    assert e.create_model(vpc_config_override=vpc_config_a).vpc_config == vpc_config_a\n    assert e.create_model(vpc_config_override=None).vpc_config is None\n\n    e.subnets = vpc_config_a[""Subnets""]\n    e.security_group_ids = vpc_config_a[""SecurityGroupIds""]\n    assert e.get_vpc_config() == vpc_config_a\n    assert e.create_model().vpc_config == vpc_config_a\n    assert e.create_model(vpc_config_override=vpc_config_b).vpc_config == vpc_config_b\n    assert e.create_model(vpc_config_override=None).vpc_config is None\n\n    with pytest.raises(ValueError):\n        e.get_vpc_config(vpc_config_override={""invalid""})\n    with pytest.raises(ValueError):\n        e.create_model(vpc_config_override={""invalid""})\n\n\ndef test_generic_deploy_vpc_config_override(sagemaker_session):\n    vpc_config_a = {""Subnets"": [""foo""], ""SecurityGroupIds"": [""bar""]}\n    vpc_config_b = {""Subnets"": [""foo"", ""bar""], ""SecurityGroupIds"": [""baz""]}\n\n    e = Estimator(\n        IMAGE_NAME, ROLE, INSTANCE_COUNT, INSTANCE_TYPE, sagemaker_session=sagemaker_session\n    )\n    e.fit({""train"": ""s3://bucket/training-prefix""})\n    e.deploy(INSTANCE_COUNT, INSTANCE_TYPE)\n    assert sagemaker_session.create_model.call_args_list[0][1][""vpc_config""] is None\n\n    e.subnets = vpc_config_a[""Subnets""]\n    e.security_group_ids = vpc_config_a[""SecurityGroupIds""]\n    e.deploy(INSTANCE_COUNT, INSTANCE_TYPE)\n    assert sagemaker_session.create_model.call_args_list[1][1][""vpc_config""] == vpc_config_a\n\n    e.deploy(INSTANCE_COUNT, INSTANCE_TYPE, vpc_config_override=vpc_config_b)\n    assert sagemaker_session.create_model.call_args_list[2][1][""vpc_config""] == vpc_config_b\n\n    e.deploy(INSTANCE_COUNT, INSTANCE_TYPE, vpc_config_override=None)\n    assert sagemaker_session.create_model.call_args_list[3][1][""vpc_config""] is None\n\n\ndef test_generic_deploy_accelerator_type(sagemaker_session):\n    e = Estimator(\n        IMAGE_NAME, ROLE, INSTANCE_COUNT, INSTANCE_TYPE, sagemaker_session=sagemaker_session\n    )\n    e.fit({""train"": ""s3://bucket/training-prefix""})\n    e.deploy(INSTANCE_COUNT, INSTANCE_TYPE, ACCELERATOR_TYPE)\n\n    args = e.sagemaker_session.endpoint_from_production_variants.call_args[1]\n    print(args)\n    assert args[""name""].startswith(IMAGE_NAME)\n    assert args[""production_variants""][0][""AcceleratorType""] == ACCELERATOR_TYPE\n    assert args[""production_variants""][0][""InitialInstanceCount""] == INSTANCE_COUNT\n    assert args[""production_variants""][0][""InstanceType""] == INSTANCE_TYPE\n\n\ndef test_deploy_with_update_endpoint(sagemaker_session):\n    estimator = Estimator(\n        IMAGE_NAME,\n        ROLE,\n        INSTANCE_COUNT,\n        INSTANCE_TYPE,\n        output_path=OUTPUT_PATH,\n        sagemaker_session=sagemaker_session,\n    )\n    estimator.set_hyperparameters(**HYPERPARAMS)\n    estimator.fit({""train"": ""s3://bucket/training-prefix""})\n    endpoint_name = ""endpoint-name""\n    estimator.deploy(\n        INSTANCE_COUNT, INSTANCE_TYPE, endpoint_name=endpoint_name, update_endpoint=True\n    )\n\n    update_endpoint_args = sagemaker_session.update_endpoint.call_args[0]\n    assert update_endpoint_args[0] == endpoint_name\n    assert update_endpoint_args[1].startWith(IMAGE_NAME)\n\n    sagemaker_session.create_endpoint.assert_not_called()\n\n\ndef test_deploy_with_model_name(sagemaker_session):\n    estimator = Estimator(\n        IMAGE_NAME,\n        ROLE,\n        INSTANCE_COUNT,\n        INSTANCE_TYPE,\n        output_path=OUTPUT_PATH,\n        sagemaker_session=sagemaker_session,\n    )\n    estimator.set_hyperparameters(**HYPERPARAMS)\n    estimator.fit({""train"": ""s3://bucket/training-prefix""})\n    model_name = ""model-name""\n    estimator.deploy(INSTANCE_COUNT, INSTANCE_TYPE, model_name=model_name)\n\n    sagemaker_session.create_model.assert_called_once()\n    args, kwargs = sagemaker_session.create_model.call_args\n    assert args[0] == model_name\n\n\ndef test_deploy_with_no_model_name(sagemaker_session):\n    estimator = Estimator(\n        IMAGE_NAME,\n        ROLE,\n        INSTANCE_COUNT,\n        INSTANCE_TYPE,\n        output_path=OUTPUT_PATH,\n        sagemaker_session=sagemaker_session,\n    )\n    estimator.set_hyperparameters(**HYPERPARAMS)\n    estimator.fit({""train"": ""s3://bucket/training-prefix""})\n    estimator.deploy(INSTANCE_COUNT, INSTANCE_TYPE)\n\n    sagemaker_session.create_model.assert_called_once()\n    args, kwargs = sagemaker_session.create_model.call_args\n    assert args[0].startswith(IMAGE_NAME)\n\n\n@patch(""sagemaker.estimator.LocalSession"")\n@patch(""sagemaker.estimator.Session"")\ndef test_local_mode(session_class, local_session_class):\n    local_session = Mock(spec=sagemaker.local.LocalSession)\n    local_session.local_mode = True\n\n    session = Mock()\n    session.local_mode = False\n\n    local_session_class.return_value = local_session\n    session_class.return_value = session\n\n    e = Estimator(IMAGE_NAME, ROLE, INSTANCE_COUNT, ""local"")\n    print(e.sagemaker_session.local_mode)\n    assert e.sagemaker_session.local_mode is True\n\n    e2 = Estimator(IMAGE_NAME, ROLE, INSTANCE_COUNT, ""local_gpu"")\n    assert e2.sagemaker_session.local_mode is True\n\n    e3 = Estimator(IMAGE_NAME, ROLE, INSTANCE_COUNT, INSTANCE_TYPE)\n    assert e3.sagemaker_session.local_mode is False\n\n\n@patch(""sagemaker.estimator.LocalSession"")\ndef test_distributed_gpu_local_mode(LocalSession):\n    with pytest.raises(RuntimeError):\n        Estimator(IMAGE_NAME, ROLE, 3, ""local_gpu"", output_path=OUTPUT_PATH)\n\n\n@patch(""sagemaker.estimator.LocalSession"")\ndef test_local_mode_file_output_path(local_session_class):\n    local_session = Mock(spec=sagemaker.local.LocalSession)\n    local_session.local_mode = True\n    local_session_class.return_value = local_session\n\n    e = Estimator(IMAGE_NAME, ROLE, INSTANCE_COUNT, ""local"", output_path=""file:///tmp/model/"")\n    assert e.output_path == ""file:///tmp/model/""\n\n\n@patch(""sagemaker.estimator.Session"")\ndef test_file_output_path_not_supported_outside_local_mode(session_class):\n    session = Mock()\n    session.local_mode = False\n    session_class.return_value = session\n\n    with pytest.raises(RuntimeError):\n        Estimator(IMAGE_NAME, ROLE, INSTANCE_COUNT, INSTANCE_TYPE, output_path=""file:///tmp/model"")\n\n\ndef test_prepare_init_params_from_job_description_with_image_training_job():\n\n    init_params = EstimatorBase._prepare_init_params_from_job_description(\n        job_details=RETURNED_JOB_DESCRIPTION\n    )\n\n    assert init_params[""role""] == ""arn:aws:iam::366:role/SageMakerRole""\n    assert init_params[""train_instance_count""] == 1\n    assert init_params[""image""] == ""1.dkr.ecr.us-west-2.amazonaws.com/sagemaker-other-py2-cpu:1.0.4""\n\n\ndef test_prepare_init_params_from_job_description_with_algorithm_training_job():\n    algorithm_job_description = RETURNED_JOB_DESCRIPTION.copy()\n    algorithm_job_description[""AlgorithmSpecification""] = {\n        ""TrainingInputMode"": ""File"",\n        ""AlgorithmName"": ""arn:aws:sagemaker:us-east-2:1234:algorithm/scikit-decision-trees"",\n        ""TrainingImage"": """",\n    }\n\n    init_params = EstimatorBase._prepare_init_params_from_job_description(\n        job_details=algorithm_job_description\n    )\n\n    assert init_params[""role""] == ""arn:aws:iam::366:role/SageMakerRole""\n    assert init_params[""train_instance_count""] == 1\n    assert (\n        init_params[""algorithm_arn""]\n        == ""arn:aws:sagemaker:us-east-2:1234:algorithm/scikit-decision-trees""\n    )\n\n\ndef test_prepare_init_params_from_job_description_with_invalid_training_job():\n\n    invalid_job_description = RETURNED_JOB_DESCRIPTION.copy()\n    invalid_job_description[""AlgorithmSpecification""] = {""TrainingInputMode"": ""File""}\n\n    with pytest.raises(RuntimeError) as error:\n        EstimatorBase._prepare_init_params_from_job_description(job_details=invalid_job_description)\n        assert ""Invalid AlgorithmSpecification"" in str(error)\n\n\ndef test_prepare_for_training_with_base_name(sagemaker_session):\n    estimator = Estimator(\n        image_name=""some-image"",\n        role=""some_image"",\n        train_instance_count=1,\n        train_instance_type=""ml.m4.xlarge"",\n        sagemaker_session=sagemaker_session,\n        base_job_name=""base_job_name"",\n    )\n\n    estimator._prepare_for_training()\n    assert ""base_job_name"" in estimator._current_job_name\n\n\ndef test_prepare_for_training_with_name_based_on_image(sagemaker_session):\n    estimator = Estimator(\n        image_name=""some-image"",\n        role=""some_image"",\n        train_instance_count=1,\n        train_instance_type=""ml.m4.xlarge"",\n        sagemaker_session=sagemaker_session,\n    )\n\n    estimator._prepare_for_training()\n    assert ""some-image"" in estimator._current_job_name\n\n\n@patch(""sagemaker.algorithm.AlgorithmEstimator.validate_train_spec"", Mock())\n@patch(""sagemaker.algorithm.AlgorithmEstimator._parse_hyperparameters"", Mock(return_value={}))\ndef test_prepare_for_training_with_name_based_on_algorithm(sagemaker_session):\n    estimator = AlgorithmEstimator(\n        algorithm_arn=""arn:aws:sagemaker:us-west-2:1234:algorithm/scikit-decision-trees-1542410022"",\n        role=""some_image"",\n        train_instance_count=1,\n        train_instance_type=""ml.m4.xlarge"",\n        sagemaker_session=sagemaker_session,\n    )\n\n    estimator._prepare_for_training()\n    assert ""scikit-decision-trees-1542410022"" in estimator._current_job_name\n\n\n@patch(\n    ""sagemaker.estimator.Estimator.fit"",\n    Mock(\n        side_effect=ClientError(\n            error_response={\n                ""Error"": {\n                    ""Code"": 403,\n                    ""Message"": \'""EnableInterContainerTrafficEncryption"" and \'\n                    \'""VpcConfig"" must be provided together\',\n                }\n            },\n            operation_name=""Unit Test"",\n        )\n    ),\n)\ndef test_encryption_flag_in_non_vpc_mode_invalid(sagemaker_session):\n    image_name = registry(""us-west-2"") + ""/factorization-machines:1""\n    with pytest.raises(ClientError) as error:\n        estimator = Estimator(\n            image_name=image_name,\n            role=""SageMakerRole"",\n            train_instance_count=1,\n            train_instance_type=""ml.c4.xlarge"",\n            sagemaker_session=sagemaker_session,\n            base_job_name=""test-non-vpc-encryption"",\n            encrypt_inter_container_traffic=True,\n        )\n        estimator.fit()\n    assert (\n        \'""EnableInterContainerTrafficEncryption"" and ""VpcConfig"" must be provided together\'\n        in str(error)\n    )\n\n\ndef test_estimator_local_mode_error(sagemaker_session):\n    # When using instance local with a session which is not LocalSession we should error out\n    with pytest.raises(RuntimeError):\n        Estimator(\n            image_name=""some-image"",\n            role=""some_image"",\n            train_instance_count=1,\n            train_instance_type=""local"",\n            sagemaker_session=sagemaker_session,\n            base_job_name=""base_job_name"",\n        )\n\n\ndef test_estimator_local_mode_ok(sagemaker_local_session):\n    # When using instance local with a session which is not LocalSession we should error out\n    Estimator(\n        image_name=""some-image"",\n        role=""some_image"",\n        train_instance_count=1,\n        train_instance_type=""local"",\n        sagemaker_session=sagemaker_local_session,\n        base_job_name=""base_job_name"",\n    )\n'"
tests/unit/test_exception_on_bad_status.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport pytest\nfrom mock import Mock, MagicMock\nimport sagemaker\n\nEXPANDED_ROLE = ""arn:aws:iam::111111111111:role/ExpandedRole""\nREGION = ""us-west-2""\nMODEL_PACKAGE_NAME = ""my_model_package""\nJOB_NAME = ""my_job_name""\nENDPOINT_NAME = ""the_point_of_end""\n\n\ndef get_sagemaker_session(returns_status):\n    boto_mock = Mock(name=""boto_session"", region_name=REGION)\n    client_mock = Mock()\n    client_mock.describe_model_package = MagicMock(\n        return_value={""ModelPackageStatus"": returns_status}\n    )\n    client_mock.describe_endpoint = MagicMock(return_value={""EndpointStatus"": returns_status})\n    ims = sagemaker.Session(boto_session=boto_mock, sagemaker_client=client_mock)\n    ims.expand_role = Mock(return_value=EXPANDED_ROLE)\n    return ims\n\n\ndef test_does_not_raise_when_successfully_created_package():\n    try:\n        sagemaker_session = get_sagemaker_session(returns_status=""Completed"")\n        sagemaker_session.wait_for_model_package(MODEL_PACKAGE_NAME)\n    except sagemaker.exceptions.UnexpectedStatusException:\n        pytest.fail(""UnexpectedStatusException was thrown while it should not"")\n\n\ndef test_raise_when_failed_created_package():\n    try:\n        sagemaker_session = get_sagemaker_session(returns_status=""EnRoute"")\n        sagemaker_session.wait_for_model_package(MODEL_PACKAGE_NAME)\n        assert (\n            False\n        ), ""sagemaker.exceptions.UnexpectedStatusException should have been raised but was not""\n    except Exception as e:\n        assert type(e) == sagemaker.exceptions.UnexpectedStatusException\n        assert e.actual_status == ""EnRoute""\n        assert ""Completed"" in e.allowed_statuses\n\n\ndef test_does_not_raise_when_correct_job_status():\n    try:\n        job = Mock()\n        sagemaker_session = get_sagemaker_session(returns_status=""Stopped"")\n        sagemaker_session._check_job_status(\n            job, {""TransformationJobStatus"": ""Stopped""}, ""TransformationJobStatus""\n        )\n    except sagemaker.exceptions.UnexpectedStatusException:\n        pytest.fail(""UnexpectedStatusException was thrown while it should not"")\n\n\ndef test_does_raise_when_incorrect_job_status():\n    try:\n        job = Mock()\n        sagemaker_session = get_sagemaker_session(returns_status=""Failed"")\n        sagemaker_session._check_job_status(\n            job, {""TransformationJobStatus"": ""Failed""}, ""TransformationJobStatus""\n        )\n        assert (\n            False\n        ), ""sagemaker.exceptions.UnexpectedStatusException should have been raised but was not""\n    except Exception as e:\n        assert type(e) == sagemaker.exceptions.UnexpectedStatusException\n        assert e.actual_status == ""Failed""\n        assert ""Completed"" in e.allowed_statuses\n        assert ""Stopped"" in e.allowed_statuses\n\n\ndef test_does_not_raise_when_successfully_deployed_endpoint():\n    try:\n        sagemaker_session = get_sagemaker_session(returns_status=""InService"")\n        sagemaker_session.wait_for_endpoint(ENDPOINT_NAME)\n    except sagemaker.exceptions.UnexpectedStatusException:\n        pytest.fail(""UnexpectedStatusException was thrown while it should not"")\n\n\ndef test_raise_when_failed_to_deploy_endpoint():\n    try:\n        sagemaker_session = get_sagemaker_session(returns_status=""Failed"")\n        assert sagemaker_session.wait_for_endpoint(ENDPOINT_NAME)\n        assert (\n            False\n        ), ""sagemaker.exceptions.UnexpectedStatusException should have been raised but was not""\n    except Exception as e:\n        assert type(e) == sagemaker.exceptions.UnexpectedStatusException\n        assert e.actual_status == ""Failed""\n        assert ""InService"" in e.allowed_statuses\n'"
tests/unit/test_experiments_analytics.py,0,"b'from __future__ import absolute_import\n\nimport mock\nimport pytest\nimport pandas as pd\n\nfrom collections import OrderedDict\n\nfrom sagemaker.analytics import ExperimentAnalytics\n\n\n@pytest.fixture\ndef mock_session():\n    return mock.Mock()\n\n\ndef trial_component(trial_component_name):\n    return {\n        ""TrialComponentName"": trial_component_name,\n        ""DisplayName"": ""Training"",\n        ""Source"": {""SourceArn"": ""some-source-arn""},\n        ""Parameters"": {""hp1"": {""NumberValue"": 1.0}, ""hp2"": {""StringValue"": ""abc""}},\n        ""Metrics"": [\n            {\n                ""MetricName"": ""metric1"",\n                ""Max"": 5.0,\n                ""Min"": 3.0,\n                ""Avg"": 4.0,\n                ""StdDev"": 1.0,\n                ""Last"": 2.0,\n                ""Count"": 2.0,\n            },\n            {\n                ""MetricName"": ""metric2"",\n                ""Max"": 10.0,\n                ""Min"": 8.0,\n                ""Avg"": 9.0,\n                ""StdDev"": 0.05,\n                ""Last"": 7.0,\n                ""Count"": 2.0,\n            },\n        ],\n    }\n\n\ndef test_trial_analytics_dataframe_all_metrics_hyperparams(mock_session):\n    mock_session.sagemaker_client.search.return_value = {\n        ""Results"": [\n            {""TrialComponent"": trial_component(""trial-1"")},\n            {""TrialComponent"": trial_component(""trial-2"")},\n        ]\n    }\n    analytics = ExperimentAnalytics(experiment_name=""experiment1"", sagemaker_session=mock_session)\n\n    expected_dataframe = pd.DataFrame.from_dict(\n        OrderedDict(\n            [\n                (""TrialComponentName"", [""trial-1"", ""trial-2""]),\n                (""DisplayName"", [""Training"", ""Training""]),\n                (""SourceArn"", [""some-source-arn"", ""some-source-arn""]),\n                (""hp1"", [1.0, 1.0]),\n                (""hp2"", [""abc"", ""abc""]),\n                (""metric1 - Min"", [3.0, 3.0]),\n                (""metric1 - Max"", [5.0, 5.0]),\n                (""metric1 - Avg"", [4.0, 4.0]),\n                (""metric1 - StdDev"", [1.0, 1.0]),\n                (""metric1 - Last"", [2.0, 2.0]),\n                (""metric1 - Count"", [2.0, 2.0]),\n                (""metric2 - Min"", [8.0, 8.0]),\n                (""metric2 - Max"", [10.0, 10.0]),\n                (""metric2 - Avg"", [9.0, 9.0]),\n                (""metric2 - StdDev"", [0.05, 0.05]),\n                (""metric2 - Last"", [7.0, 7.0]),\n                (""metric2 - Count"", [2.0, 2.0]),\n            ]\n        )\n    )\n\n    pd.testing.assert_frame_equal(expected_dataframe, analytics.dataframe())\n    expected_search_exp = {\n        ""Filters"": [\n            {""Name"": ""Parents.ExperimentName"", ""Operator"": ""Equals"", ""Value"": ""experiment1""}\n        ]\n    }\n    mock_session.sagemaker_client.search.assert_called_with(\n        Resource=""ExperimentTrialComponent"", SearchExpression=expected_search_exp\n    )\n\n\ndef test_trial_analytics_dataframe_selected_hyperparams(mock_session):\n    mock_session.sagemaker_client.search.return_value = {\n        ""Results"": [\n            {""TrialComponent"": trial_component(""trial-1"")},\n            {""TrialComponent"": trial_component(""trial-2"")},\n        ]\n    }\n    analytics = ExperimentAnalytics(\n        experiment_name=""experiment1"", parameter_names=[""hp2""], sagemaker_session=mock_session\n    )\n\n    expected_dataframe = pd.DataFrame.from_dict(\n        OrderedDict(\n            [\n                (""TrialComponentName"", [""trial-1"", ""trial-2""]),\n                (""DisplayName"", [""Training"", ""Training""]),\n                (""SourceArn"", [""some-source-arn"", ""some-source-arn""]),\n                (""hp2"", [""abc"", ""abc""]),\n                (""metric1 - Min"", [3.0, 3.0]),\n                (""metric1 - Max"", [5.0, 5.0]),\n                (""metric1 - Avg"", [4.0, 4.0]),\n                (""metric1 - StdDev"", [1.0, 1.0]),\n                (""metric1 - Last"", [2.0, 2.0]),\n                (""metric1 - Count"", [2.0, 2.0]),\n                (""metric2 - Min"", [8.0, 8.0]),\n                (""metric2 - Max"", [10.0, 10.0]),\n                (""metric2 - Avg"", [9.0, 9.0]),\n                (""metric2 - StdDev"", [0.05, 0.05]),\n                (""metric2 - Last"", [7.0, 7.0]),\n                (""metric2 - Count"", [2.0, 2.0]),\n            ]\n        )\n    )\n\n    pd.testing.assert_frame_equal(expected_dataframe, analytics.dataframe())\n    expected_search_exp = {\n        ""Filters"": [\n            {""Name"": ""Parents.ExperimentName"", ""Operator"": ""Equals"", ""Value"": ""experiment1""}\n        ]\n    }\n    mock_session.sagemaker_client.search.assert_called_with(\n        Resource=""ExperimentTrialComponent"", SearchExpression=expected_search_exp\n    )\n\n\ndef test_trial_analytics_dataframe_selected_metrics(mock_session):\n    mock_session.sagemaker_client.search.return_value = {\n        ""Results"": [\n            {""TrialComponent"": trial_component(""trial-1"")},\n            {""TrialComponent"": trial_component(""trial-2"")},\n        ]\n    }\n    analytics = ExperimentAnalytics(\n        experiment_name=""experiment1"", metric_names=[""metric1""], sagemaker_session=mock_session\n    )\n\n    expected_dataframe = pd.DataFrame.from_dict(\n        OrderedDict(\n            [\n                (""TrialComponentName"", [""trial-1"", ""trial-2""]),\n                (""DisplayName"", [""Training"", ""Training""]),\n                (""SourceArn"", [""some-source-arn"", ""some-source-arn""]),\n                (""hp1"", [1.0, 1.0]),\n                (""hp2"", [""abc"", ""abc""]),\n                (""metric1 - Min"", [3.0, 3.0]),\n                (""metric1 - Max"", [5.0, 5.0]),\n                (""metric1 - Avg"", [4.0, 4.0]),\n                (""metric1 - StdDev"", [1.0, 1.0]),\n                (""metric1 - Last"", [2.0, 2.0]),\n                (""metric1 - Count"", [2.0, 2.0]),\n            ]\n        )\n    )\n\n    pd.testing.assert_frame_equal(expected_dataframe, analytics.dataframe())\n    expected_search_exp = {\n        ""Filters"": [\n            {""Name"": ""Parents.ExperimentName"", ""Operator"": ""Equals"", ""Value"": ""experiment1""}\n        ]\n    }\n    mock_session.sagemaker_client.search.assert_called_with(\n        Resource=""ExperimentTrialComponent"", SearchExpression=expected_search_exp\n    )\n\n\ndef test_trial_analytics_dataframe_search_pagination(mock_session):\n    result_page_1 = {\n        ""Results"": [{""TrialComponent"": trial_component(""trial-1"")}],\n        ""NextToken"": ""nextToken"",\n    }\n\n    result_page_2 = {""Results"": [{""TrialComponent"": trial_component(""trial-2"")}]}\n\n    mock_session.sagemaker_client.search.side_effect = [result_page_1, result_page_2]\n    analytics = ExperimentAnalytics(experiment_name=""experiment1"", sagemaker_session=mock_session)\n\n    expected_dataframe = pd.DataFrame.from_dict(\n        OrderedDict(\n            [\n                (""TrialComponentName"", [""trial-1"", ""trial-2""]),\n                (""DisplayName"", [""Training"", ""Training""]),\n                (""SourceArn"", [""some-source-arn"", ""some-source-arn""]),\n                (""hp1"", [1.0, 1.0]),\n                (""hp2"", [""abc"", ""abc""]),\n                (""metric1 - Min"", [3.0, 3.0]),\n                (""metric1 - Max"", [5.0, 5.0]),\n                (""metric1 - Avg"", [4.0, 4.0]),\n                (""metric1 - StdDev"", [1.0, 1.0]),\n                (""metric1 - Last"", [2.0, 2.0]),\n                (""metric1 - Count"", [2.0, 2.0]),\n                (""metric2 - Min"", [8.0, 8.0]),\n                (""metric2 - Max"", [10.0, 10.0]),\n                (""metric2 - Avg"", [9.0, 9.0]),\n                (""metric2 - StdDev"", [0.05, 0.05]),\n                (""metric2 - Last"", [7.0, 7.0]),\n                (""metric2 - Count"", [2.0, 2.0]),\n            ]\n        )\n    )\n\n    pd.testing.assert_frame_equal(expected_dataframe, analytics.dataframe())\n    expected_search_exp = {\n        ""Filters"": [\n            {""Name"": ""Parents.ExperimentName"", ""Operator"": ""Equals"", ""Value"": ""experiment1""}\n        ]\n    }\n    mock_session.sagemaker_client.search.assert_has_calls(\n        [\n            mock.call(Resource=""ExperimentTrialComponent"", SearchExpression=expected_search_exp),\n            mock.call(\n                Resource=""ExperimentTrialComponent"",\n                SearchExpression=expected_search_exp,\n                NextToken=""nextToken"",\n            ),\n        ]\n    )\n\n\ndef test_trial_analytics_dataframe_filter_trials_search_exp_only(mock_session):\n    mock_session.sagemaker_client.search.return_value = {""Results"": []}\n\n    search_exp = {""Filters"": [{""Name"": ""Tags.someTag"", ""Operator"": ""Equals"", ""Value"": ""someValue""}]}\n    analytics = ExperimentAnalytics(search_expression=search_exp, sagemaker_session=mock_session)\n\n    analytics.dataframe()\n\n    mock_session.sagemaker_client.search.assert_called_with(\n        Resource=""ExperimentTrialComponent"", SearchExpression=search_exp\n    )\n\n\ndef test_trial_analytics_dataframe_filter_trials_search_exp_with_experiment(mock_session):\n    mock_session.sagemaker_client.search.return_value = {""Results"": []}\n\n    search_exp = {""Filters"": [{""Name"": ""Tags.someTag"", ""Operator"": ""Equals"", ""Value"": ""someValue""}]}\n    analytics = ExperimentAnalytics(\n        experiment_name=""someExperiment"",\n        search_expression=search_exp,\n        sagemaker_session=mock_session,\n    )\n\n    analytics.dataframe()\n\n    expected_search_exp = {\n        ""Filters"": [\n            {""Name"": ""Tags.someTag"", ""Operator"": ""Equals"", ""Value"": ""someValue""},\n            {""Name"": ""Parents.ExperimentName"", ""Operator"": ""Equals"", ""Value"": ""someExperiment""},\n        ]\n    }\n\n    mock_session.sagemaker_client.search.assert_called_with(\n        Resource=""ExperimentTrialComponent"", SearchExpression=expected_search_exp\n    )\n\n\ndef test_trial_analytics_dataframe_throws_error_if_no_filter_specified(mock_session):\n    with pytest.raises(ValueError):\n        ExperimentAnalytics(sagemaker_session=mock_session)\n\n\ndef test_trial_analytics_dataframe_filter_trials_search_exp_with_sort(mock_session):\n    mock_session.sagemaker_client.search.return_value = {""Results"": []}\n\n    search_exp = {""Filters"": [{""Name"": ""Tags.someTag"", ""Operator"": ""Equals"", ""Value"": ""someValue""}]}\n    analytics = ExperimentAnalytics(\n        experiment_name=""someExperiment"",\n        search_expression=search_exp,\n        sort_by=""Tags.someTag"",\n        sort_order=""Ascending"",\n        sagemaker_session=mock_session,\n    )\n\n    analytics.dataframe()\n\n    expected_search_exp = {\n        ""Filters"": [\n            {""Name"": ""Tags.someTag"", ""Operator"": ""Equals"", ""Value"": ""someValue""},\n            {""Name"": ""Parents.ExperimentName"", ""Operator"": ""Equals"", ""Value"": ""someExperiment""},\n        ]\n    }\n\n    mock_session.sagemaker_client.search.assert_called_with(\n        Resource=""ExperimentTrialComponent"",\n        SearchExpression=expected_search_exp,\n        SortBy=""Tags.someTag"",\n        SortOrder=""Ascending"",\n    )\n'"
tests/unit/test_fm.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport pytest\nfrom mock import Mock, patch\n\nfrom sagemaker.amazon.factorization_machines import (\n    FactorizationMachines,\n    FactorizationMachinesPredictor,\n)\nfrom sagemaker.amazon.amazon_estimator import registry, RecordSet\n\nROLE = ""myrole""\nTRAIN_INSTANCE_COUNT = 1\nTRAIN_INSTANCE_TYPE = ""ml.c4.xlarge""\nNUM_FACTORS = 3\nPREDICTOR_TYPE = ""regressor""\n\nCOMMON_TRAIN_ARGS = {\n    ""role"": ROLE,\n    ""train_instance_count"": TRAIN_INSTANCE_COUNT,\n    ""train_instance_type"": TRAIN_INSTANCE_TYPE,\n}\nALL_REQ_ARGS = dict(\n    {""num_factors"": NUM_FACTORS, ""predictor_type"": PREDICTOR_TYPE}, **COMMON_TRAIN_ARGS\n)\n\nREGION = ""us-west-2""\nBUCKET_NAME = ""Some-Bucket""\n\nDESCRIBE_TRAINING_JOB_RESULT = {""ModelArtifacts"": {""S3ModelArtifacts"": ""s3://bucket/model.tar.gz""}}\n\nENDPOINT_DESC = {""EndpointConfigName"": ""test-endpoint""}\n\nENDPOINT_CONFIG_DESC = {""ProductionVariants"": [{""ModelName"": ""model-1""}, {""ModelName"": ""model-2""}]}\n\n\n@pytest.fixture()\ndef sagemaker_session():\n    boto_mock = Mock(name=""boto_session"", region_name=REGION)\n    sms = Mock(\n        name=""sagemaker_session"",\n        boto_session=boto_mock,\n        region_name=REGION,\n        config=None,\n        local_mode=False,\n        s3_client=False,\n        s3_resource=False,\n    )\n    sms.boto_region_name = REGION\n    sms.default_bucket = Mock(name=""default_bucket"", return_value=BUCKET_NAME)\n    sms.sagemaker_client.describe_training_job = Mock(\n        name=""describe_training_job"", return_value=DESCRIBE_TRAINING_JOB_RESULT\n    )\n    sms.sagemaker_client.describe_endpoint = Mock(return_value=ENDPOINT_DESC)\n    sms.sagemaker_client.describe_endpoint_config = Mock(return_value=ENDPOINT_CONFIG_DESC)\n    return sms\n\n\ndef test_init_required_positional(sagemaker_session):\n    fm = FactorizationMachines(\n        ""myrole"", 1, ""ml.c4.xlarge"", 3, ""regressor"", sagemaker_session=sagemaker_session\n    )\n    assert fm.role == ""myrole""\n    assert fm.train_instance_count == 1\n    assert fm.train_instance_type == ""ml.c4.xlarge""\n    assert fm.num_factors == 3\n    assert fm.predictor_type == ""regressor""\n\n\ndef test_init_required_named(sagemaker_session):\n    fm = FactorizationMachines(sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n\n    assert fm.role == COMMON_TRAIN_ARGS[""role""]\n    assert fm.train_instance_count == COMMON_TRAIN_ARGS[""train_instance_count""]\n    assert fm.train_instance_type == COMMON_TRAIN_ARGS[""train_instance_type""]\n    assert fm.num_factors == ALL_REQ_ARGS[""num_factors""]\n    assert fm.predictor_type == ALL_REQ_ARGS[""predictor_type""]\n\n\ndef test_all_hyperparameters(sagemaker_session):\n    fm = FactorizationMachines(\n        sagemaker_session=sagemaker_session,\n        epochs=2,\n        clip_gradient=1e2,\n        eps=0.001,\n        rescale_grad=2.2,\n        bias_lr=0.01,\n        linear_lr=0.002,\n        factors_lr=0.0003,\n        bias_wd=0.0004,\n        linear_wd=1.01,\n        factors_wd=1.002,\n        bias_init_method=""uniform"",\n        bias_init_scale=0.1,\n        bias_init_sigma=0.05,\n        bias_init_value=2.002,\n        linear_init_method=""constant"",\n        linear_init_scale=0.02,\n        linear_init_sigma=0.003,\n        linear_init_value=1.0,\n        factors_init_method=""normal"",\n        factors_init_scale=1.101,\n        factors_init_sigma=1.202,\n        factors_init_value=1.303,\n        **ALL_REQ_ARGS\n    )\n    assert fm.hyperparameters() == dict(\n        num_factors=str(ALL_REQ_ARGS[""num_factors""]),\n        predictor_type=ALL_REQ_ARGS[""predictor_type""],\n        epochs=""2"",\n        clip_gradient=""100.0"",\n        eps=""0.001"",\n        rescale_grad=""2.2"",\n        bias_lr=""0.01"",\n        linear_lr=""0.002"",\n        factors_lr=""0.0003"",\n        bias_wd=""0.0004"",\n        linear_wd=""1.01"",\n        factors_wd=""1.002"",\n        bias_init_method=""uniform"",\n        bias_init_scale=""0.1"",\n        bias_init_sigma=""0.05"",\n        bias_init_value=""2.002"",\n        linear_init_method=""constant"",\n        linear_init_scale=""0.02"",\n        linear_init_sigma=""0.003"",\n        linear_init_value=""1.0"",\n        factors_init_method=""normal"",\n        factors_init_scale=""1.101"",\n        factors_init_sigma=""1.202"",\n        factors_init_value=""1.303"",\n    )\n\n\ndef test_image(sagemaker_session):\n    fm = FactorizationMachines(sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n    assert fm.train_image() == registry(REGION) + ""/factorization-machines:1""\n\n\n@pytest.mark.parametrize(\n    ""required_hyper_parameters, value"", [(""num_factors"", ""string""), (""predictor_type"", 0)]\n)\ndef test_required_hyper_parameters_type(sagemaker_session, required_hyper_parameters, value):\n    with pytest.raises(ValueError):\n        test_params = ALL_REQ_ARGS.copy()\n        test_params[required_hyper_parameters] = value\n        FactorizationMachines(sagemaker_session=sagemaker_session, **test_params)\n\n\n@pytest.mark.parametrize(\n    ""required_hyper_parameters, value"", [(""num_factors"", 0), (""predictor_type"", ""string"")]\n)\ndef test_required_hyper_parameters_value(sagemaker_session, required_hyper_parameters, value):\n    with pytest.raises(ValueError):\n        test_params = ALL_REQ_ARGS.copy()\n        test_params[required_hyper_parameters] = value\n        FactorizationMachines(sagemaker_session=sagemaker_session, **test_params)\n\n\n@pytest.mark.parametrize(\n    ""optional_hyper_parameters, value"",\n    [\n        (""epochs"", ""string""),\n        (""clip_gradient"", ""string""),\n        (""eps"", ""string""),\n        (""rescale_grad"", ""string""),\n        (""bias_lr"", ""string""),\n        (""linear_lr"", ""string""),\n        (""factors_lr"", ""string""),\n        (""bias_wd"", ""string""),\n        (""linear_wd"", ""string""),\n        (""factors_wd"", ""string""),\n        (""bias_init_method"", 0),\n        (""bias_init_scale"", ""string""),\n        (""bias_init_sigma"", ""string""),\n        (""bias_init_value"", ""string""),\n        (""linear_init_method"", 0),\n        (""linear_init_scale"", ""string""),\n        (""linear_init_sigma"", ""string""),\n        (""linear_init_value"", ""string""),\n        (""factors_init_method"", 0),\n        (""factors_init_scale"", ""string""),\n        (""factors_init_sigma"", ""string""),\n        (""factors_init_value"", ""string""),\n    ],\n)\ndef test_optional_hyper_parameters_type(sagemaker_session, optional_hyper_parameters, value):\n    with pytest.raises(ValueError):\n        test_params = ALL_REQ_ARGS.copy()\n        test_params.update({optional_hyper_parameters: value})\n        FactorizationMachines(sagemaker_session=sagemaker_session, **test_params)\n\n\n@pytest.mark.parametrize(\n    ""optional_hyper_parameters, value"",\n    [\n        (""epochs"", 0),\n        (""bias_lr"", -1),\n        (""linear_lr"", -1),\n        (""factors_lr"", -1),\n        (""bias_wd"", -1),\n        (""linear_wd"", -1),\n        (""factors_wd"", -1),\n        (""bias_init_method"", ""string""),\n        (""bias_init_scale"", -1),\n        (""bias_init_sigma"", -1),\n        (""linear_init_method"", ""string""),\n        (""linear_init_scale"", -1),\n        (""linear_init_sigma"", -1),\n        (""factors_init_method"", ""string""),\n        (""factors_init_scale"", -1),\n        (""factors_init_sigma"", -1),\n    ],\n)\ndef test_optional_hyper_parameters_value(sagemaker_session, optional_hyper_parameters, value):\n    with pytest.raises(ValueError):\n        test_params = ALL_REQ_ARGS.copy()\n        test_params.update({optional_hyper_parameters: value})\n        FactorizationMachines(sagemaker_session=sagemaker_session, **test_params)\n\n\nPREFIX = ""prefix""\nFEATURE_DIM = 10\nMINI_BATCH_SIZE = 200\n\n\n@patch(""sagemaker.amazon.amazon_estimator.AmazonAlgorithmEstimatorBase.fit"")\ndef test_call_fit(base_fit, sagemaker_session):\n    fm = FactorizationMachines(\n        base_job_name=""fm"", sagemaker_session=sagemaker_session, **ALL_REQ_ARGS\n    )\n\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n\n    fm.fit(data, MINI_BATCH_SIZE)\n\n    base_fit.assert_called_once()\n    assert len(base_fit.call_args[0]) == 2\n    assert base_fit.call_args[0][0] == data\n    assert base_fit.call_args[0][1] == MINI_BATCH_SIZE\n\n\ndef test_prepare_for_training_no_mini_batch_size(sagemaker_session):\n    fm = FactorizationMachines(\n        base_job_name=""fm"", sagemaker_session=sagemaker_session, **ALL_REQ_ARGS\n    )\n\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n    fm._prepare_for_training(data)\n\n\ndef test_prepare_for_training_wrong_type_mini_batch_size(sagemaker_session):\n    fm = FactorizationMachines(\n        base_job_name=""fm"", sagemaker_session=sagemaker_session, **ALL_REQ_ARGS\n    )\n\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n\n    with pytest.raises((TypeError, ValueError)):\n        fm._prepare_for_training(data, ""some"")\n\n\ndef test_prepare_for_training_wrong_value_mini_batch_size(sagemaker_session):\n    fm = FactorizationMachines(\n        base_job_name=""fm"", sagemaker_session=sagemaker_session, **ALL_REQ_ARGS\n    )\n\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n    with pytest.raises(ValueError):\n        fm._prepare_for_training(data, 0)\n\n\ndef test_model_image(sagemaker_session):\n    fm = FactorizationMachines(sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n    fm.fit(data, MINI_BATCH_SIZE)\n\n    model = fm.create_model()\n    assert model.image == registry(REGION, ""factorization-machines"") + ""/factorization-machines:1""\n\n\ndef test_predictor_type(sagemaker_session):\n    fm = FactorizationMachines(sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n    fm.fit(data, MINI_BATCH_SIZE)\n    model = fm.create_model()\n    predictor = model.deploy(1, TRAIN_INSTANCE_TYPE)\n\n    assert isinstance(predictor, FactorizationMachinesPredictor)\n'"
tests/unit/test_fw_registry.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport pytest\n\nfrom sagemaker.fw_registry import registry, default_framework_uri\nfrom sagemaker.sklearn import SKLearn\n\n\nscikit_learn_framework_name = SKLearn.__framework_name__\n\n\ndef test_registry_sparkml_serving():\n    assert (\n        registry(""us-west-1"", ""sparkml-serving"") == ""746614075791.dkr.ecr.us-west-1.amazonaws.com""\n    )\n    assert (\n        registry(""us-west-2"", ""sparkml-serving"") == ""246618743249.dkr.ecr.us-west-2.amazonaws.com""\n    )\n    assert (\n        registry(""us-east-1"", ""sparkml-serving"") == ""683313688378.dkr.ecr.us-east-1.amazonaws.com""\n    )\n    assert (\n        registry(""us-east-2"", ""sparkml-serving"") == ""257758044811.dkr.ecr.us-east-2.amazonaws.com""\n    )\n    assert (\n        registry(""ap-northeast-1"", ""sparkml-serving"")\n        == ""354813040037.dkr.ecr.ap-northeast-1.amazonaws.com""\n    )\n    assert (\n        registry(""ap-northeast-2"", ""sparkml-serving"")\n        == ""366743142698.dkr.ecr.ap-northeast-2.amazonaws.com""\n    )\n    assert (\n        registry(""ap-southeast-1"", ""sparkml-serving"")\n        == ""121021644041.dkr.ecr.ap-southeast-1.amazonaws.com""\n    )\n    assert (\n        registry(""ap-southeast-2"", ""sparkml-serving"")\n        == ""783357654285.dkr.ecr.ap-southeast-2.amazonaws.com""\n    )\n    assert (\n        registry(""ap-south-1"", ""sparkml-serving"") == ""720646828776.dkr.ecr.ap-south-1.amazonaws.com""\n    )\n    assert (\n        registry(""eu-west-1"", ""sparkml-serving"") == ""141502667606.dkr.ecr.eu-west-1.amazonaws.com""\n    )\n    assert (\n        registry(""eu-west-2"", ""sparkml-serving"") == ""764974769150.dkr.ecr.eu-west-2.amazonaws.com""\n    )\n    assert (\n        registry(""eu-central-1"", ""sparkml-serving"")\n        == ""492215442770.dkr.ecr.eu-central-1.amazonaws.com""\n    )\n    assert (\n        registry(""ca-central-1"", ""sparkml-serving"")\n        == ""341280168497.dkr.ecr.ca-central-1.amazonaws.com""\n    )\n    assert (\n        registry(""us-gov-west-1"", ""sparkml-serving"")\n        == ""414596584902.dkr.ecr.us-gov-west-1.amazonaws.com""\n    )\n    assert (\n        registry(""us-iso-east-1"", ""sparkml-serving"")\n        == ""833128469047.dkr.ecr.us-iso-east-1.c2s.ic.gov""\n    )\n\n\ndef test_registry_sklearn():\n    assert (\n        registry(""us-west-1"", scikit_learn_framework_name)\n        == ""746614075791.dkr.ecr.us-west-1.amazonaws.com""\n    )\n    assert (\n        registry(""us-west-2"", scikit_learn_framework_name)\n        == ""246618743249.dkr.ecr.us-west-2.amazonaws.com""\n    )\n    assert (\n        registry(""us-east-1"", scikit_learn_framework_name)\n        == ""683313688378.dkr.ecr.us-east-1.amazonaws.com""\n    )\n    assert (\n        registry(""us-east-2"", scikit_learn_framework_name)\n        == ""257758044811.dkr.ecr.us-east-2.amazonaws.com""\n    )\n    assert (\n        registry(""ap-northeast-1"", scikit_learn_framework_name)\n        == ""354813040037.dkr.ecr.ap-northeast-1.amazonaws.com""\n    )\n    assert (\n        registry(""ap-northeast-2"", scikit_learn_framework_name)\n        == ""366743142698.dkr.ecr.ap-northeast-2.amazonaws.com""\n    )\n    assert (\n        registry(""ap-southeast-1"", scikit_learn_framework_name)\n        == ""121021644041.dkr.ecr.ap-southeast-1.amazonaws.com""\n    )\n    assert (\n        registry(""ap-southeast-2"", scikit_learn_framework_name)\n        == ""783357654285.dkr.ecr.ap-southeast-2.amazonaws.com""\n    )\n    assert (\n        registry(""ap-south-1"", scikit_learn_framework_name)\n        == ""720646828776.dkr.ecr.ap-south-1.amazonaws.com""\n    )\n    assert (\n        registry(""eu-west-1"", scikit_learn_framework_name)\n        == ""141502667606.dkr.ecr.eu-west-1.amazonaws.com""\n    )\n    assert (\n        registry(""eu-west-2"", scikit_learn_framework_name)\n        == ""764974769150.dkr.ecr.eu-west-2.amazonaws.com""\n    )\n    assert (\n        registry(""eu-central-1"", scikit_learn_framework_name)\n        == ""492215442770.dkr.ecr.eu-central-1.amazonaws.com""\n    )\n    assert (\n        registry(""ca-central-1"", scikit_learn_framework_name)\n        == ""341280168497.dkr.ecr.ca-central-1.amazonaws.com""\n    )\n    assert (\n        registry(""us-gov-west-1"", scikit_learn_framework_name)\n        == ""414596584902.dkr.ecr.us-gov-west-1.amazonaws.com""\n    )\n    assert (\n        registry(""us-iso-east-1"", scikit_learn_framework_name)\n        == ""833128469047.dkr.ecr.us-iso-east-1.c2s.ic.gov""\n    )\n\n\ndef test_default_sklearn_image_uri():\n    image_tag = ""0.20.0-cpu-py3""\n    sklearn_image_uri = default_framework_uri(scikit_learn_framework_name, ""us-west-1"", image_tag)\n    assert (\n        sklearn_image_uri\n        == ""746614075791.dkr.ecr.us-west-1.amazonaws.com/sagemaker-scikit-learn:0.20.0-cpu-py3""\n    )\n\n\ndef test_framework_invalid():\n    with pytest.raises(KeyError):\n        registry(""us-west-2"", ""dummy-value"")\n\n\ndef test_framework_none():\n    with pytest.raises(KeyError):\n        registry(""us-west-2"", None)\n\n\ndef test_region_invalid():\n    with pytest.raises(KeyError):\n        registry(""us-west-5"", ""scikit-learn"")\n\n\ndef test_region_none():\n    with pytest.raises(KeyError):\n        registry(None, ""scikit-learn"")\n'"
tests/unit/test_fw_utils.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport inspect\nimport os\nimport tarfile\n\nimport pytest\nfrom mock import Mock, patch\n\nfrom contextlib import contextmanager\nfrom sagemaker import fw_utils\nfrom sagemaker.utils import name_from_image\n\nDATA_DIR = ""data_dir""\nBUCKET_NAME = ""mybucket""\nROLE = ""Sagemaker""\nREGION = ""us-west-2""\nSCRIPT_PATH = ""script.py""\nTIMESTAMP = ""2017-10-10-14-14-15""\nECR_PREFIX_FORMAT = ""{}.dkr.ecr.mars-south-3.amazonaws.com""\n\nMOCK_ACCOUNT = ""520713654638""\nMOCK_FRAMEWORK = ""mlfw""\nMOCK_REGION = ""mars-south-3""\nMOCK_ACCELERATOR = ""eia1.medium""\nMOCK_HKG_REGION = ""ap-east-1""\nMOCK_BAH_REGION = ""me-south-1""\n\n\nORIGINAL_FW_VERSIONS = {\n    ""pytorch"": [""0.4"", ""0.4.0"", ""1.0"", ""1.0.0""],\n    ""mxnet"": [""0.12"", ""0.12.1"", ""1.0"", ""1.0.0"", ""1.1"", ""1.1.0"", ""1.2"", ""1.2.1""],\n    ""tensorflow"": [\n        ""1.4"",\n        ""1.4.1"",\n        ""1.5"",\n        ""1.5.0"",\n        ""1.6"",\n        ""1.6.0"",\n        ""1.7"",\n        ""1.7.0"",\n        ""1.8"",\n        ""1.8.0"",\n        ""1.9"",\n        ""1.9.0"",\n        ""1.10"",\n        ""1.10.0"",\n        ""1.11"",\n        ""1.11.0"",\n        ""1.12"",\n        ""1.12.0"",\n    ],\n}\n\n\nSERVING_FW_VERSIONS = {\n    ""pytorch"": [""1.1"", ""1.1.0""],\n    ""mxnet"": [""1.3"", ""1.3.0"", ""1.4.0""],\n    ""tensorflow"": [""1.11"", ""1.11.0"", ""1.12"", ""1.12.0""],\n}\n\n\ndef get_account(framework, framework_version, py_version=""py3""):\n    if (\n        framework_version in ORIGINAL_FW_VERSIONS[framework]\n        or framework_version in SERVING_FW_VERSIONS[framework]\n        or is_mxnet_1_4_py2(\n            framework, framework_version, py_version\n        )  # except for MXNet 1.4.1 (1.4) py2 Asimov teams owns both py2 and py3\n    ):\n        return fw_utils.DEFAULT_ACCOUNT\n    return fw_utils.ASIMOV_DEFAULT_ACCOUNT\n\n\ndef get_repo_name(framework, framework_version, is_serving=False, py_version=""py3""):\n    if (\n        framework_version in ORIGINAL_FW_VERSIONS[framework]\n        or framework_version in SERVING_FW_VERSIONS[framework]\n        or is_mxnet_1_4_py2(framework, framework_version, py_version)\n    ):  # except for MXNet 1.4.1 (1.4) py2 Asimov teams owns both py2 and py3\n        # TODO: check whether sagemaker-{}-serving images actually exist for ORIGINAL_FW_VERSIONS\n        if is_serving:\n            ecr_repo = ""sagemaker-{}-serving""\n        else:\n            ecr_repo = ""sagemaker-{}""\n            if framework == ""tensorflow"" and framework_version in SERVING_FW_VERSIONS[framework]:\n                framework = framework + ""-scriptmode""\n    elif is_serving:\n        ecr_repo = ""{}-inference""\n    else:\n        ecr_repo = ""{}-training""\n    return ecr_repo.format(framework)\n\n\ndef is_mxnet_1_4_py2(framework, framework_version, py_version):\n    return framework == ""mxnet"" and py_version == ""py2"" and framework_version in [""1.4"", ""1.4.1""]\n\n\n@pytest.fixture(\n    scope=""module"", params=[""1.11"", ""1.11.0"", ""1.12"", ""1.12.0"", ""1.14"", ""1.14.0"", ""1.15"", ""1.15.0""]\n)\ndef tf_version(request):\n    return request.param\n\n\n@pytest.fixture(\n    scope=""module"",\n    params=[""0.4"", ""0.4.0"", ""1.0"", ""1.0.0"", ""1.1"", ""1.1.0"", ""1.2"", ""1.2.0"", ""1.3"", ""1.3.1""],\n)\ndef pytorch_version(request):\n    return request.param\n\n\n@pytest.fixture(\n    scope=""module"",\n    params=[\n        ""0.12"",\n        ""0.12.1"",\n        ""1.0"",\n        ""1.0.0"",\n        ""1.1"",\n        ""1.1.0"",\n        ""1.2"",\n        ""1.2.1"",\n        ""1.3"",\n        ""1.3.0"",\n        ""1.4"",\n        ""1.4.0"",\n        ""1.4.1"",\n        ""1.6"",\n        ""1.6.0"",\n    ],\n)\ndef mxnet_version(request):\n    return request.param\n\n\n@contextmanager\ndef cd(path):\n    old_dir = os.getcwd()\n    os.chdir(path)\n    yield\n    os.chdir(old_dir)\n\n\n@pytest.fixture()\ndef sagemaker_session():\n    boto_mock = Mock(name=""boto_session"", region_name=REGION)\n    session_mock = Mock(\n        name=""sagemaker_session"", boto_session=boto_mock, s3_client=None, s3_resource=None\n    )\n    session_mock.default_bucket = Mock(name=""default_bucket"", return_value=BUCKET_NAME)\n    session_mock.expand_role = Mock(name=""expand_role"", return_value=ROLE)\n    session_mock.sagemaker_client.describe_training_job = Mock(\n        return_value={""ModelArtifacts"": {""S3ModelArtifacts"": ""s3://m/m.tar.gz""}}\n    )\n    return session_mock\n\n\n@patch(""sagemaker.fw_utils.get_ecr_image_uri_prefix"")\ndef test_create_image_uri_cpu(ecr_prefix):\n    ecr_prefix.return_value = ECR_PREFIX_FORMAT.format(""23"")\n    image_uri = fw_utils.create_image_uri(\n        MOCK_REGION, MOCK_FRAMEWORK, ""ml.c4.large"", ""1.0rc"", ""py2"", ""23""\n    )\n    assert image_uri == ""23.dkr.ecr.mars-south-3.amazonaws.com/sagemaker-mlfw:1.0rc-cpu-py2""\n\n    image_uri = fw_utils.create_image_uri(\n        MOCK_REGION, MOCK_FRAMEWORK, ""local"", ""1.0rc"", ""py2"", ""23""\n    )\n    assert image_uri == ""23.dkr.ecr.mars-south-3.amazonaws.com/sagemaker-mlfw:1.0rc-cpu-py2""\n\n    ecr_prefix.return_value = ""246785580436.dkr.ecr.us-gov-west-1.amazonaws.com""\n    image_uri = fw_utils.create_image_uri(\n        ""us-gov-west-1"", MOCK_FRAMEWORK, ""ml.c4.large"", ""1.0rc"", ""py2""\n    )\n    assert (\n        image_uri == ""246785580436.dkr.ecr.us-gov-west-1.amazonaws.com/sagemaker-mlfw:1.0rc-cpu-py2""\n    )\n\n    ecr_prefix.return_value = ""744548109606.dkr.ecr.us-iso-east-1.c2s.ic.gov""\n    image_uri = fw_utils.create_image_uri(\n        ""us-iso-east-1"", MOCK_FRAMEWORK, ""ml.c4.large"", ""1.0rc"", ""py2""\n    )\n    assert image_uri == ""744548109606.dkr.ecr.us-iso-east-1.c2s.ic.gov/sagemaker-mlfw:1.0rc-cpu-py2""\n\n\n@patch(""sagemaker.fw_utils.get_ecr_image_uri_prefix"", return_value=ECR_PREFIX_FORMAT.format(""23""))\ndef test_create_image_uri_no_python(ecr_prefix):\n    image_uri = fw_utils.create_image_uri(\n        MOCK_REGION, MOCK_FRAMEWORK, ""ml.c4.large"", ""1.0rc"", account=""23""\n    )\n    assert image_uri == ""23.dkr.ecr.mars-south-3.amazonaws.com/sagemaker-mlfw:1.0rc-cpu""\n\n\ndef test_create_image_uri_bad_python():\n    with pytest.raises(ValueError):\n        fw_utils.create_image_uri(MOCK_REGION, MOCK_FRAMEWORK, ""ml.c4.large"", ""1.0rc"", ""py0"")\n\n\n@patch(""sagemaker.fw_utils.get_ecr_image_uri_prefix"", return_value=ECR_PREFIX_FORMAT.format(""23""))\ndef test_create_image_uri_gpu(ecr_prefix):\n    image_uri = fw_utils.create_image_uri(\n        MOCK_REGION, MOCK_FRAMEWORK, ""ml.p3.2xlarge"", ""1.0rc"", ""py3"", ""23""\n    )\n    assert image_uri == ""23.dkr.ecr.mars-south-3.amazonaws.com/sagemaker-mlfw:1.0rc-gpu-py3""\n\n    image_uri = fw_utils.create_image_uri(\n        MOCK_REGION, MOCK_FRAMEWORK, ""local_gpu"", ""1.0rc"", ""py3"", ""23""\n    )\n    assert image_uri == ""23.dkr.ecr.mars-south-3.amazonaws.com/sagemaker-mlfw:1.0rc-gpu-py3""\n\n\n@patch(""sagemaker.fw_utils.get_ecr_image_uri_prefix"", return_value=ECR_PREFIX_FORMAT.format(""23""))\ndef test_create_image_uri_accelerator_tfs(ecr_prefix):\n    image_uri = fw_utils.create_image_uri(\n        MOCK_REGION,\n        ""tensorflow-serving"",\n        ""ml.c4.large"",\n        ""1.1.0"",\n        accelerator_type=""ml.eia1.large"",\n        account=""23"",\n    )\n    assert (\n        image_uri\n        == ""23.dkr.ecr.mars-south-3.amazonaws.com/sagemaker-tensorflow-serving-eia:1.1.0-cpu""\n    )\n\n\n@patch(\n    ""sagemaker.fw_utils.get_ecr_image_uri_prefix"",\n    return_value=ECR_PREFIX_FORMAT.format(MOCK_ACCOUNT),\n)\ndef test_create_image_uri_default_account(ecr_prefix):\n    image_uri = fw_utils.create_image_uri(\n        MOCK_REGION, MOCK_FRAMEWORK, ""ml.p3.2xlarge"", ""1.0rc"", ""py3""\n    )\n    assert (\n        image_uri == ""520713654638.dkr.ecr.mars-south-3.amazonaws.com/sagemaker-mlfw:1.0rc-gpu-py3""\n    )\n\n\ndef test_create_image_uri_gov_cloud():\n    image_uri = fw_utils.create_image_uri(\n        ""us-gov-west-1"", MOCK_FRAMEWORK, ""ml.p3.2xlarge"", ""1.0rc"", ""py3""\n    )\n    assert (\n        image_uri == ""246785580436.dkr.ecr.us-gov-west-1.amazonaws.com/sagemaker-mlfw:1.0rc-gpu-py3""\n    )\n\n\ndef test_create_image_uri_hkg():\n    image_uri = fw_utils.create_image_uri(\n        MOCK_HKG_REGION, MOCK_FRAMEWORK, ""ml.p3.2xlarge"", ""1.0rc"", ""py3""\n    )\n    assert {\n        image_uri == ""871362719292.dkr.ecr.ap-east-1.amazonaws.com/sagemaker-mlfw:1.0rc-gpu-py3""\n    }\n\n\ndef test_create_image_uri_bah():\n    image_uri = fw_utils.create_image_uri(\n        MOCK_BAH_REGION, MOCK_FRAMEWORK, ""ml.p3.2xlarge"", ""1.0rc"", ""py3""\n    )\n    assert {\n        image_uri == ""217643126080.dkr.ecr.me-south-1.amazonaws.com/sagemaker-mlfw:1.0rc-gpu-py3""\n    }\n\n\ndef test_create_image_uri_cn_north_1():\n    image_uri = fw_utils.create_image_uri(\n        ""cn-north-1"", MOCK_FRAMEWORK, ""ml.p3.2xlarge"", ""1.0rc"", ""py3""\n    )\n    assert {\n        image_uri == ""727897471807.dkr.ecr.me-south-1.amazonaws.com/sagemaker-mlfw:1.0rc-gpu-py3""\n    }\n\n\ndef test_create_image_uri_cn_northwest_1():\n    image_uri = fw_utils.create_image_uri(\n        ""cn-northwest-1"", MOCK_FRAMEWORK, ""ml.p3.2xlarge"", ""1.0rc"", ""py3""\n    )\n    assert {\n        image_uri == ""727897471807.dkr.ecr.me-south-1.amazonaws.com/sagemaker-mlfw:1.0rc-gpu-py3""\n    }\n\n\ndef test_create_image_uri_py37_invalid_framework():\n    error_message = ""{} does not support Python 3.7 at this time."".format(MOCK_FRAMEWORK)\n\n    with pytest.raises(ValueError) as error:\n        fw_utils.create_image_uri(REGION, MOCK_FRAMEWORK, ""ml.m4.xlarge"", ""1.4.0"", ""py37"")\n    assert error_message in str(error)\n\n\ndef test_create_image_uri_py37():\n    image_uri = fw_utils.create_image_uri(\n        REGION, ""tensorflow-scriptmode"", ""ml.m4.xlarge"", ""1.15.2"", ""py37""\n    )\n    assert (\n        image_uri\n        == ""763104351884.dkr.ecr.us-west-2.amazonaws.com/tensorflow-training:1.15.2-cpu-py37""\n    )\n\n\ndef test_tf_eia_images():\n    image_uri = fw_utils.create_image_uri(\n        ""us-west-2"",\n        ""tensorflow-serving"",\n        ""ml.m4.xlarge"",\n        ""2.0.0"",\n        ""py3"",\n        accelerator_type=""ml.eia1.medium"",\n    )\n    assert (\n        image_uri\n        == ""{}.dkr.ecr.us-west-2.amazonaws.com/tensorflow-inference-eia:2.0.0-cpu"".format(\n            fw_utils.ASIMOV_PROD_ACCOUNT\n        )\n    )\n\n\ndef test_mxnet_eia_images():\n    image_uri = fw_utils.create_image_uri(\n        ""us-east-1"",\n        ""mxnet-serving"",\n        ""ml.c4.2xlarge"",\n        ""1.5.1"",\n        ""py3"",\n        accelerator_type=""ml.eia1.large"",\n    )\n    assert (\n        image_uri\n        == ""{}.dkr.ecr.us-east-1.amazonaws.com/mxnet-inference-eia:1.5.1-cpu-py3"".format(\n            fw_utils.ASIMOV_PROD_ACCOUNT\n        )\n    )\n\n\ndef test_pytorch_eia_images():\n    image_uri = fw_utils.create_image_uri(\n        ""us-east-1"",\n        ""pytorch-serving"",\n        ""ml.c4.2xlarge"",\n        ""1.3.1"",\n        ""py3"",\n        accelerator_type=""ml.eia1.large"",\n    )\n    assert (\n        image_uri\n        == ""{}.dkr.ecr.us-east-1.amazonaws.com/pytorch-inference-eia:1.3.1-cpu-py3"".format(\n            fw_utils.ASIMOV_PROD_ACCOUNT\n        )\n    )\n\n\ndef test_pytorch_eia_py2_error():\n    error_message = ""pytorch-serving is not supported with Amazon Elastic Inference in Python 2.""\n    with pytest.raises(ValueError) as error:\n        fw_utils.create_image_uri(\n            ""us-east-1"",\n            ""pytorch-serving"",\n            ""ml.c4.2xlarge"",\n            ""1.3.1"",\n            ""py2"",\n            accelerator_type=""ml.eia1.large"",\n        )\n    assert error_message in str(error)\n\n\ndef test_create_image_uri_override_account():\n    image_uri = fw_utils.create_image_uri(\n        ""us-west-1"", MOCK_FRAMEWORK, ""ml.p3.2xlarge"", ""1.0rc"", ""py3"", account=""fake""\n    )\n    assert image_uri == ""fake.dkr.ecr.us-west-1.amazonaws.com/sagemaker-mlfw:1.0rc-gpu-py3""\n\n\ndef test_create_image_uri_gov_cloud_override_account():\n    image_uri = fw_utils.create_image_uri(\n        ""us-gov-west-1"", MOCK_FRAMEWORK, ""ml.p3.2xlarge"", ""1.0rc"", ""py3"", account=""fake""\n    )\n    assert image_uri == ""fake.dkr.ecr.us-gov-west-1.amazonaws.com/sagemaker-mlfw:1.0rc-gpu-py3""\n\n\ndef test_create_image_uri_hkg_override_account():\n    image_uri = fw_utils.create_image_uri(\n        MOCK_HKG_REGION, MOCK_FRAMEWORK, ""ml.p3.2xlarge"", ""1.0rc"", ""py3"", account=""fake""\n    )\n    assert {image_uri == ""fake.dkr.ecr.ap-east-1.amazonaws.com/sagemaker-mlfw:1.0rc-gpu-py3""}\n\n\ndef test_create_dlc_image_uri():\n    image_uri = fw_utils.create_image_uri(\n        ""us-west-2"", ""tensorflow-scriptmode"", ""ml.p3.2xlarge"", ""1.14"", ""py3""\n    )\n    assert (\n        image_uri\n        == ""{}.dkr.ecr.us-west-2.amazonaws.com/tensorflow-training:1.14-gpu-py3"".format(\n            fw_utils.ASIMOV_DEFAULT_ACCOUNT\n        )\n    )\n\n    image_uri = fw_utils.create_image_uri(\n        ""us-west-2"", ""tensorflow-scriptmode"", ""ml.p3.2xlarge"", ""1.13.1"", ""py3""\n    )\n    assert (\n        image_uri\n        == ""{}.dkr.ecr.us-west-2.amazonaws.com/tensorflow-training:1.13.1-gpu-py3"".format(\n            fw_utils.ASIMOV_DEFAULT_ACCOUNT\n        )\n    )\n\n    image_uri = fw_utils.create_image_uri(\n        ""us-west-2"", ""tensorflow-serving"", ""ml.c4.2xlarge"", ""1.13.1""\n    )\n    assert image_uri == ""{}.dkr.ecr.us-west-2.amazonaws.com/tensorflow-inference:1.13.1-cpu"".format(\n        fw_utils.ASIMOV_DEFAULT_ACCOUNT\n    )\n\n    image_uri = fw_utils.create_image_uri(""us-west-2"", ""mxnet"", ""ml.p3.2xlarge"", ""1.4.1"", ""py3"")\n    assert image_uri == ""{}.dkr.ecr.us-west-2.amazonaws.com/mxnet-training:1.4.1-gpu-py3"".format(\n        fw_utils.ASIMOV_DEFAULT_ACCOUNT\n    )\n\n    image_uri = fw_utils.create_image_uri(\n        ""us-west-2"", ""mxnet-serving"", ""ml.c4.2xlarge"", ""1.4.1"", ""py3""\n    )\n    assert image_uri == ""{}.dkr.ecr.us-west-2.amazonaws.com/mxnet-inference:1.4.1-cpu-py3"".format(\n        fw_utils.ASIMOV_DEFAULT_ACCOUNT\n    )\n\n    image_uri = fw_utils.create_image_uri(\n        ""us-west-2"",\n        ""mxnet-serving"",\n        ""ml.c4.2xlarge"",\n        ""1.4.1"",\n        ""py3"",\n        accelerator_type=""ml.eia1.medium"",\n    )\n    assert (\n        image_uri\n        == ""{}.dkr.ecr.us-west-2.amazonaws.com/mxnet-inference-eia:1.4.1-cpu-py3"".format(\n            fw_utils.ASIMOV_PROD_ACCOUNT\n        )\n    )\n\n\ndef test_create_dlc_image_uri_py2():\n    image_uri = fw_utils.create_image_uri(\n        ""us-west-2"", ""tensorflow-scriptmode"", ""ml.p3.2xlarge"", ""1.13.1"", ""py2""\n    )\n    assert (\n        image_uri\n        == ""520713654638.dkr.ecr.us-west-2.amazonaws.com/sagemaker-tensorflow-scriptmode:1.13.1-gpu-py2""\n    )\n\n    image_uri = fw_utils.create_image_uri(\n        ""us-west-2"", ""tensorflow-scriptmode"", ""ml.p3.2xlarge"", ""1.14"", ""py2""\n    )\n    assert (\n        image_uri\n        == ""{}.dkr.ecr.us-west-2.amazonaws.com/tensorflow-training:1.14-gpu-py2"".format(\n            fw_utils.ASIMOV_DEFAULT_ACCOUNT\n        )\n    )\n\n    image_uri = fw_utils.create_image_uri(""us-west-2"", ""mxnet"", ""ml.p3.2xlarge"", ""1.4.1"", ""py2"")\n    assert image_uri == ""520713654638.dkr.ecr.us-west-2.amazonaws.com/sagemaker-mxnet:1.4.1-gpu-py2""\n\n    image_uri = fw_utils.create_image_uri(\n        ""us-west-2"", ""mxnet-serving"", ""ml.c4.2xlarge"", ""1.3.1"", ""py2""\n    )\n    assert (\n        image_uri\n        == ""520713654638.dkr.ecr.us-west-2.amazonaws.com/sagemaker-mxnet-serving:1.3.1-cpu-py2""\n    )\n\n\ndef test_create_dlc_image_uri_iso_east_1():\n    image_uri = fw_utils.create_image_uri(\n        ""us-iso-east-1"", ""tensorflow-scriptmode"", ""ml.m4.xlarge"", ""1.13.1"", ""py3""\n    )\n    assert (\n        image_uri\n        == ""886529160074.dkr.ecr.us-iso-east-1.c2s.ic.gov/tensorflow-training:1.13.1-cpu-py3""\n    )\n\n    image_uri = fw_utils.create_image_uri(\n        ""us-iso-east-1"", ""tensorflow-scriptmode"", ""ml.p3.2xlarge"", ""1.14"", ""py2""\n    )\n    assert (\n        image_uri\n        == ""886529160074.dkr.ecr.us-iso-east-1.c2s.ic.gov/tensorflow-training:1.14-gpu-py2""\n    )\n\n    image_uri = fw_utils.create_image_uri(\n        ""us-iso-east-1"", ""tensorflow-serving"", ""ml.m4.xlarge"", ""1.13.0""\n    )\n    assert (\n        image_uri == ""886529160074.dkr.ecr.us-iso-east-1.c2s.ic.gov/tensorflow-inference:1.13.0-cpu""\n    )\n\n    image_uri = fw_utils.create_image_uri(""us-iso-east-1"", ""mxnet"", ""ml.p3.2xlarge"", ""1.4.1"", ""py3"")\n    assert image_uri == ""886529160074.dkr.ecr.us-iso-east-1.c2s.ic.gov/mxnet-training:1.4.1-gpu-py3""\n\n    image_uri = fw_utils.create_image_uri(\n        ""us-iso-east-1"", ""mxnet-serving"", ""ml.c4.2xlarge"", ""1.4.1"", ""py3""\n    )\n    assert (\n        image_uri == ""886529160074.dkr.ecr.us-iso-east-1.c2s.ic.gov/mxnet-inference:1.4.1-cpu-py3""\n    )\n\n    image_uri = fw_utils.create_image_uri(\n        ""us-iso-east-1"", ""mxnet-serving"", ""ml.c4.2xlarge"", ""1.3.1"", ""py3""\n    )\n    assert (\n        image_uri\n        == ""744548109606.dkr.ecr.us-iso-east-1.c2s.ic.gov/sagemaker-mxnet-serving:1.3.1-cpu-py3""\n    )\n\n\ndef test_create_dlc_image_uri_gov_west_1():\n    image_uri = fw_utils.create_image_uri(\n        ""us-gov-west-1"", ""tensorflow-scriptmode"", ""ml.m4.xlarge"", ""1.13.1"", ""py3""\n    )\n    assert (\n        image_uri\n        == ""442386744353.dkr.ecr.us-gov-west-1.amazonaws.com/tensorflow-training:1.13.1-cpu-py3""\n    )\n\n    image_uri = fw_utils.create_image_uri(\n        ""us-gov-west-1"", ""tensorflow-scriptmode"", ""ml.p3.2xlarge"", ""1.14"", ""py2""\n    )\n    assert (\n        image_uri\n        == ""442386744353.dkr.ecr.us-gov-west-1.amazonaws.com/tensorflow-training:1.14-gpu-py2""\n    )\n\n    image_uri = fw_utils.create_image_uri(\n        ""us-gov-west-1"", ""tensorflow-serving"", ""ml.m4.xlarge"", ""1.13.0""\n    )\n    assert (\n        image_uri\n        == ""442386744353.dkr.ecr.us-gov-west-1.amazonaws.com/tensorflow-inference:1.13.0-cpu""\n    )\n\n    image_uri = fw_utils.create_image_uri(""us-gov-west-1"", ""mxnet"", ""ml.p3.2xlarge"", ""1.4.1"", ""py3"")\n    assert (\n        image_uri == ""442386744353.dkr.ecr.us-gov-west-1.amazonaws.com/mxnet-training:1.4.1-gpu-py3""\n    )\n\n    image_uri = fw_utils.create_image_uri(\n        ""us-gov-west-1"", ""mxnet-serving"", ""ml.c4.2xlarge"", ""1.4.1"", ""py3""\n    )\n    assert (\n        image_uri\n        == ""442386744353.dkr.ecr.us-gov-west-1.amazonaws.com/mxnet-inference:1.4.1-cpu-py3""\n    )\n\n    image_uri = fw_utils.create_image_uri(\n        ""us-gov-west-1"", ""pytorch"", ""ml.p3.2xlarge"", ""1.2.0"", ""py3""\n    )\n    assert (\n        image_uri\n        == ""442386744353.dkr.ecr.us-gov-west-1.amazonaws.com/pytorch-training:1.2.0-gpu-py3""\n    )\n\n    image_uri = fw_utils.create_image_uri(\n        ""us-gov-west-1"", ""pytorch-serving"", ""ml.c4.2xlarge"", ""1.2.0"", ""py3""\n    )\n    assert (\n        image_uri\n        == ""442386744353.dkr.ecr.us-gov-west-1.amazonaws.com/pytorch-inference:1.2.0-cpu-py3""\n    )\n\n\ndef test_create_image_uri_pytorch(pytorch_version):\n    image_uri = fw_utils.create_image_uri(\n        ""us-west-2"", ""pytorch"", ""ml.p3.2xlarge"", pytorch_version, ""py3""\n    )\n    assert image_uri == ""{}.dkr.ecr.us-west-2.amazonaws.com/{}:{}-gpu-py3"".format(\n        get_account(""pytorch"", pytorch_version),\n        get_repo_name(""pytorch"", pytorch_version),\n        pytorch_version,\n    )\n\n    if pytorch_version not in ORIGINAL_FW_VERSIONS:\n        image_uri = fw_utils.create_image_uri(\n            ""us-west-2"", ""pytorch-serving"", ""ml.c4.2xlarge"", pytorch_version, ""py2""\n        )\n        assert image_uri == ""{}.dkr.ecr.us-west-2.amazonaws.com/{}:{}-cpu-py2"".format(\n            get_account(""pytorch"", pytorch_version),\n            get_repo_name(""pytorch"", pytorch_version, True),\n            pytorch_version,\n        )\n\n\ndef test_create_image_uri_mxnet(mxnet_version):\n\n    image_uri = fw_utils.create_image_uri(\n        ""us-west-2"", ""mxnet"", ""ml.p3.2xlarge"", mxnet_version, ""py3""\n    )\n    assert image_uri == ""{}.dkr.ecr.us-west-2.amazonaws.com/{}:{}-gpu-py3"".format(\n        get_account(""mxnet"", mxnet_version), get_repo_name(""mxnet"", mxnet_version), mxnet_version\n    )\n\n    if mxnet_version not in ORIGINAL_FW_VERSIONS:\n        py_version = ""py2""\n        image_uri = fw_utils.create_image_uri(\n            ""us-west-2"", ""mxnet-serving"", ""ml.c4.2xlarge"", mxnet_version, py_version\n        )\n        assert image_uri == ""{}.dkr.ecr.us-west-2.amazonaws.com/{}:{}-cpu-{}"".format(\n            get_account(""mxnet"", mxnet_version, py_version),\n            get_repo_name(""mxnet"", mxnet_version, True, py_version),\n            mxnet_version,\n            py_version,\n        )\n\n\ndef test_create_image_uri_tensorflow(tf_version):\n    image_uri = fw_utils.create_image_uri(\n        ""us-west-2"", ""tensorflow-scriptmode"", ""ml.p3.2xlarge"", tf_version, ""py3""\n    )\n    assert image_uri == ""{}.dkr.ecr.us-west-2.amazonaws.com/{}:{}-gpu-py3"".format(\n        get_account(""tensorflow"", tf_version), get_repo_name(""tensorflow"", tf_version), tf_version\n    )\n\n    if tf_version not in ORIGINAL_FW_VERSIONS:\n        image_uri = fw_utils.create_image_uri(\n            ""us-west-2"", ""tensorflow-serving"", ""ml.c4.2xlarge"", tf_version\n        )\n        assert image_uri == ""{}.dkr.ecr.us-west-2.amazonaws.com/{}:{}-cpu"".format(\n            get_account(""tensorflow"", tf_version),\n            get_repo_name(""tensorflow"", tf_version, True),\n            tf_version,\n        )\n\n\n@patch(\n    ""sagemaker.fw_utils.get_ecr_image_uri_prefix"",\n    return_value=ECR_PREFIX_FORMAT.format(MOCK_ACCOUNT),\n)\ndef test_create_image_uri_accelerator_tf(ecr_prefix):\n    image_uri = fw_utils.create_image_uri(\n        MOCK_REGION, ""tensorflow"", ""ml.p3.2xlarge"", ""1.0"", ""py3"", accelerator_type=""ml.eia1.medium""\n    )\n    assert (\n        image_uri\n        == ""520713654638.dkr.ecr.mars-south-3.amazonaws.com/sagemaker-tensorflow-eia:1.0-gpu-py3""\n    )\n\n\n@patch(\n    ""sagemaker.fw_utils.get_ecr_image_uri_prefix"",\n    return_value=ECR_PREFIX_FORMAT.format(MOCK_ACCOUNT),\n)\ndef test_create_image_uri_accelerator_mxnet_serving(ecr_prefix):\n    image_uri = fw_utils.create_image_uri(\n        MOCK_REGION,\n        ""mxnet-serving"",\n        ""ml.p3.2xlarge"",\n        ""1.0"",\n        ""py3"",\n        accelerator_type=""ml.eia1.medium"",\n    )\n    assert (\n        image_uri\n        == ""520713654638.dkr.ecr.mars-south-3.amazonaws.com/sagemaker-mxnet-serving-eia:1.0-gpu-py3""\n    )\n\n\n@patch(\n    ""sagemaker.fw_utils.get_ecr_image_uri_prefix"",\n    return_value=ECR_PREFIX_FORMAT.format(MOCK_ACCOUNT),\n)\ndef test_create_image_uri_local_sagemaker_notebook_accelerator(ecr_prefix):\n    image_uri = fw_utils.create_image_uri(\n        MOCK_REGION,\n        ""mxnet"",\n        ""ml.p3.2xlarge"",\n        ""1.0"",\n        ""py3"",\n        accelerator_type=""local_sagemaker_notebook"",\n    )\n    assert (\n        image_uri\n        == ""520713654638.dkr.ecr.mars-south-3.amazonaws.com/sagemaker-mxnet-eia:1.0-gpu-py3""\n    )\n\n\ndef test_invalid_accelerator():\n    error_message = ""{} is not a valid SageMaker Elastic Inference accelerator type."".format(\n        MOCK_ACCELERATOR\n    )\n    # accelerator type is missing \'ml.\' prefix\n    with pytest.raises(ValueError) as error:\n        fw_utils.create_image_uri(\n            MOCK_REGION,\n            ""tensorflow"",\n            ""ml.p3.2xlarge"",\n            ""1.0.0"",\n            ""py3"",\n            accelerator_type=MOCK_ACCELERATOR,\n        )\n\n    assert error_message in str(error)\n\n\ndef test_invalid_framework_accelerator():\n    error_message = ""{} is not supported with Amazon Elastic Inference."".format(MOCK_FRAMEWORK)\n    # accelerator was chosen for unsupported framework\n    with pytest.raises(ValueError) as error:\n        fw_utils.create_image_uri(\n            MOCK_REGION,\n            MOCK_FRAMEWORK,\n            ""ml.p3.2xlarge"",\n            ""1.0.0"",\n            ""py3"",\n            accelerator_type=""ml.eia1.medium"",\n        )\n\n    assert error_message in str(error)\n\n\ndef test_invalid_framework_accelerator_with_neo():\n    error_message = ""Neo does not support Amazon Elastic Inference.""\n    # accelerator was chosen for unsupported framework\n    with pytest.raises(ValueError) as error:\n        fw_utils.create_image_uri(\n            MOCK_REGION,\n            ""tensorflow"",\n            ""ml.p3.2xlarge"",\n            ""1.0.0"",\n            ""py3"",\n            accelerator_type=""ml.eia1.medium"",\n            optimized_families=[""c5"", ""p3""],\n        )\n\n    assert error_message in str(error)\n\n\ndef test_invalid_instance_type():\n    # instance type is missing \'ml.\' prefix\n    with pytest.raises(ValueError):\n        fw_utils.create_image_uri(MOCK_REGION, MOCK_FRAMEWORK, ""p3.2xlarge"", ""1.0.0"", ""py3"")\n\n\ndef test_valid_inferentia_image():\n    image_uri = fw_utils.create_image_uri(\n        REGION,\n        ""neo-tensorflow"",\n        ""ml.inf1.2xlarge"",\n        ""1.15.0"",\n        py_version=""py3"",\n        account=MOCK_ACCOUNT,\n    )\n    assert (\n        image_uri\n        == ""{}.dkr.ecr.{}.amazonaws.com/sagemaker-neo-tensorflow:1.15.0-inf-py3"".format(\n            MOCK_ACCOUNT, REGION\n        )\n    )\n\n\ndef test_invalid_inferentia_region():\n    with pytest.raises(ValueError) as e:\n        fw_utils.create_image_uri(\n            ""ap-south-1"",\n            ""neo-tensorflow"",\n            ""ml.inf1.2xlarge"",\n            ""1.15.0"",\n            py_version=""py3"",\n            account=MOCK_ACCOUNT,\n        )\n    assert ""Inferentia is not supported in region ap-south-1."" in str(e)\n\n\ndef test_inferentia_invalid_framework():\n    with pytest.raises(ValueError) as e:\n        fw_utils.create_image_uri(\n            REGION,\n            ""neo-pytorch"",\n            ""ml.inf1.2xlarge"",\n            ""1.4.0"",\n            py_version=""py3"",\n            account=MOCK_ACCOUNT,\n        )\n    assert ""Inferentia does not support pytorch."" in str(e)\n\n\ndef test_invalid_inferentia_framework_version():\n    with pytest.raises(ValueError) as e:\n        fw_utils.create_image_uri(\n            REGION,\n            ""neo-tensorflow"",\n            ""ml.inf1.2xlarge"",\n            ""1.15.2"",\n            py_version=""py3"",\n            account=MOCK_ACCOUNT,\n        )\n    assert ""Inferentia is not supported with tensorflow version 1.15.2."" in str(e)\n\n\n@patch(\n    ""sagemaker.fw_utils.get_ecr_image_uri_prefix"",\n    return_value=ECR_PREFIX_FORMAT.format(MOCK_ACCOUNT),\n)\ndef test_optimized_family(ecr_prefix):\n    image_uri = fw_utils.create_image_uri(\n        MOCK_REGION,\n        MOCK_FRAMEWORK,\n        ""ml.p3.2xlarge"",\n        ""1.0.0"",\n        ""py3"",\n        optimized_families=[""c5"", ""p3""],\n    )\n    assert (\n        image_uri == ""520713654638.dkr.ecr.mars-south-3.amazonaws.com/sagemaker-mlfw:1.0.0-p3-py3""\n    )\n\n\n@patch(\n    ""sagemaker.fw_utils.get_ecr_image_uri_prefix"",\n    return_value=ECR_PREFIX_FORMAT.format(MOCK_ACCOUNT),\n)\ndef test_unoptimized_cpu_family(ecr_prefix):\n    image_uri = fw_utils.create_image_uri(\n        MOCK_REGION, MOCK_FRAMEWORK, ""ml.m4.xlarge"", ""1.0.0"", ""py3"", optimized_families=[""c5"", ""p3""]\n    )\n    assert (\n        image_uri == ""520713654638.dkr.ecr.mars-south-3.amazonaws.com/sagemaker-mlfw:1.0.0-cpu-py3""\n    )\n\n\n@patch(\n    ""sagemaker.fw_utils.get_ecr_image_uri_prefix"",\n    return_value=ECR_PREFIX_FORMAT.format(MOCK_ACCOUNT),\n)\ndef test_unoptimized_gpu_family(ecr_prefix):\n    image_uri = fw_utils.create_image_uri(\n        MOCK_REGION, MOCK_FRAMEWORK, ""ml.p2.xlarge"", ""1.0.0"", ""py3"", optimized_families=[""c5"", ""p3""]\n    )\n    assert (\n        image_uri == ""520713654638.dkr.ecr.mars-south-3.amazonaws.com/sagemaker-mlfw:1.0.0-gpu-py3""\n    )\n\n\ndef test_tar_and_upload_dir_s3(sagemaker_session):\n    bucket = ""mybucket""\n    s3_key_prefix = ""something/source""\n    script = ""mnist.py""\n    directory = ""s3://m""\n    result = fw_utils.tar_and_upload_dir(\n        sagemaker_session, bucket, s3_key_prefix, script, directory\n    )\n\n    assert result == fw_utils.UploadedCode(""s3://m"", ""mnist.py"")\n\n\n@patch(""sagemaker.utils"")\ndef test_tar_and_upload_dir_s3_with_kms(utils, sagemaker_session):\n    bucket = ""mybucket""\n    s3_key_prefix = ""something/source""\n    script = ""mnist.py""\n    kms_key = ""kms-key""\n    result = fw_utils.tar_and_upload_dir(\n        sagemaker_session, bucket, s3_key_prefix, script, kms_key=kms_key\n    )\n\n    assert result == fw_utils.UploadedCode(\n        ""s3://{}/{}/sourcedir.tar.gz"".format(bucket, s3_key_prefix), script\n    )\n\n    extra_args = {""ServerSideEncryption"": ""aws:kms"", ""SSEKMSKeyId"": kms_key}\n    obj = sagemaker_session.resource(""s3"").Object("""", """")\n    obj.upload_file.assert_called_with(utils.create_tar_file(), ExtraArgs=extra_args)\n\n\ndef test_validate_source_dir_does_not_exits(sagemaker_session):\n    script = ""mnist.py""\n    directory = "" !@#$%^&*()path probably in not there.!@#$%^&*()""\n    with pytest.raises(ValueError):\n        fw_utils.validate_source_dir(script, directory)\n\n\ndef test_validate_source_dir_is_not_directory(sagemaker_session):\n    script = ""mnist.py""\n    directory = inspect.getfile(inspect.currentframe())\n    with pytest.raises(ValueError):\n        fw_utils.validate_source_dir(script, directory)\n\n\ndef test_validate_source_dir_file_not_in_dir():\n    script = "" !@#$%^&*() .myscript. !@#$%^&*() ""\n    directory = "".""\n    with pytest.raises(ValueError):\n        fw_utils.validate_source_dir(script, directory)\n\n\ndef test_tar_and_upload_dir_not_s3(sagemaker_session):\n    bucket = ""mybucket""\n    s3_key_prefix = ""something/source""\n    script = os.path.basename(__file__)\n    directory = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n    result = fw_utils.tar_and_upload_dir(\n        sagemaker_session, bucket, s3_key_prefix, script, directory\n    )\n    assert result == fw_utils.UploadedCode(\n        ""s3://{}/{}/sourcedir.tar.gz"".format(bucket, s3_key_prefix), script\n    )\n\n\ndef file_tree(tmpdir, files=None, folders=None):\n    files = files or []\n    folders = folders or []\n    for file in files:\n        tmpdir.join(file).ensure(file=True)\n\n    for folder in folders:\n        tmpdir.join(folder).ensure(dir=True)\n\n    return str(tmpdir)\n\n\ndef test_tar_and_upload_dir_no_directory(sagemaker_session, tmpdir):\n    source_dir = file_tree(tmpdir, [""train.py""])\n    entrypoint = os.path.join(source_dir, ""train.py"")\n\n    with patch(""shutil.rmtree""):\n        result = fw_utils.tar_and_upload_dir(\n            sagemaker_session, ""bucket"", ""prefix"", entrypoint, None\n        )\n\n    assert result == fw_utils.UploadedCode(\n        s3_prefix=""s3://bucket/prefix/sourcedir.tar.gz"", script_name=""train.py""\n    )\n\n    assert {""/train.py""} == list_source_dir_files(sagemaker_session, tmpdir)\n\n\ndef test_tar_and_upload_dir_no_directory_only_entrypoint(sagemaker_session, tmpdir):\n    source_dir = file_tree(tmpdir, [""train.py"", ""not_me.py""])\n    entrypoint = os.path.join(source_dir, ""train.py"")\n\n    with patch(""shutil.rmtree""):\n        result = fw_utils.tar_and_upload_dir(\n            sagemaker_session, ""bucket"", ""prefix"", entrypoint, None\n        )\n\n    assert result == fw_utils.UploadedCode(\n        s3_prefix=""s3://bucket/prefix/sourcedir.tar.gz"", script_name=""train.py""\n    )\n\n    assert {""/train.py""} == list_source_dir_files(sagemaker_session, tmpdir)\n\n\ndef test_tar_and_upload_dir_no_directory_bare_filename(sagemaker_session, tmpdir):\n    source_dir = file_tree(tmpdir, [""train.py""])\n    entrypoint = ""train.py""\n\n    with patch(""shutil.rmtree""):\n        with cd(source_dir):\n            result = fw_utils.tar_and_upload_dir(\n                sagemaker_session, ""bucket"", ""prefix"", entrypoint, None\n            )\n\n    assert result == fw_utils.UploadedCode(\n        s3_prefix=""s3://bucket/prefix/sourcedir.tar.gz"", script_name=""train.py""\n    )\n\n    assert {""/train.py""} == list_source_dir_files(sagemaker_session, tmpdir)\n\n\ndef test_tar_and_upload_dir_with_directory(sagemaker_session, tmpdir):\n    file_tree(tmpdir, [""src-dir/train.py""])\n    source_dir = os.path.join(str(tmpdir), ""src-dir"")\n\n    with patch(""shutil.rmtree""):\n        result = fw_utils.tar_and_upload_dir(\n            sagemaker_session, ""bucket"", ""prefix"", ""train.py"", source_dir\n        )\n\n    assert result == fw_utils.UploadedCode(\n        s3_prefix=""s3://bucket/prefix/sourcedir.tar.gz"", script_name=""train.py""\n    )\n\n    assert {""/train.py""} == list_source_dir_files(sagemaker_session, tmpdir)\n\n\ndef test_tar_and_upload_dir_with_subdirectory(sagemaker_session, tmpdir):\n    file_tree(tmpdir, [""src-dir/sub/train.py""])\n    source_dir = os.path.join(str(tmpdir), ""src-dir"")\n\n    with patch(""shutil.rmtree""):\n        result = fw_utils.tar_and_upload_dir(\n            sagemaker_session, ""bucket"", ""prefix"", ""train.py"", source_dir\n        )\n\n    assert result == fw_utils.UploadedCode(\n        s3_prefix=""s3://bucket/prefix/sourcedir.tar.gz"", script_name=""train.py""\n    )\n\n    assert {""/sub/train.py""} == list_source_dir_files(sagemaker_session, tmpdir)\n\n\ndef test_tar_and_upload_dir_with_directory_and_files(sagemaker_session, tmpdir):\n    file_tree(tmpdir, [""src-dir/train.py"", ""src-dir/laucher"", ""src-dir/module/__init__.py""])\n    source_dir = os.path.join(str(tmpdir), ""src-dir"")\n\n    with patch(""shutil.rmtree""):\n        result = fw_utils.tar_and_upload_dir(\n            sagemaker_session, ""bucket"", ""prefix"", ""train.py"", source_dir\n        )\n\n    assert result == fw_utils.UploadedCode(\n        s3_prefix=""s3://bucket/prefix/sourcedir.tar.gz"", script_name=""train.py""\n    )\n\n    assert {""/laucher"", ""/module/__init__.py"", ""/train.py""} == list_source_dir_files(\n        sagemaker_session, tmpdir\n    )\n\n\ndef test_tar_and_upload_dir_with_directories_and_files(sagemaker_session, tmpdir):\n    file_tree(tmpdir, [""src-dir/a/b"", ""src-dir/a/b2"", ""src-dir/x/y"", ""src-dir/x/y2"", ""src-dir/z""])\n    source_dir = os.path.join(str(tmpdir), ""src-dir"")\n\n    with patch(""shutil.rmtree""):\n        result = fw_utils.tar_and_upload_dir(\n            sagemaker_session, ""bucket"", ""prefix"", ""a/b"", source_dir\n        )\n\n    assert result == fw_utils.UploadedCode(\n        s3_prefix=""s3://bucket/prefix/sourcedir.tar.gz"", script_name=""a/b""\n    )\n\n    assert {""/a/b"", ""/a/b2"", ""/x/y"", ""/x/y2"", ""/z""} == list_source_dir_files(\n        sagemaker_session, tmpdir\n    )\n\n\ndef test_tar_and_upload_dir_with_many_folders(sagemaker_session, tmpdir):\n    file_tree(tmpdir, [""src-dir/a/b"", ""src-dir/a/b2"", ""common/x/y"", ""common/x/y2"", ""t/y/z""])\n    source_dir = os.path.join(str(tmpdir), ""src-dir"")\n    dependencies = [os.path.join(str(tmpdir), ""common""), os.path.join(str(tmpdir), ""t"", ""y"", ""z"")]\n\n    with patch(""shutil.rmtree""):\n        result = fw_utils.tar_and_upload_dir(\n            sagemaker_session, ""bucket"", ""prefix"", ""pipeline.py"", source_dir, dependencies\n        )\n\n    assert result == fw_utils.UploadedCode(\n        s3_prefix=""s3://bucket/prefix/sourcedir.tar.gz"", script_name=""pipeline.py""\n    )\n\n    assert {""/a/b"", ""/a/b2"", ""/common/x/y"", ""/common/x/y2"", ""/z""} == list_source_dir_files(\n        sagemaker_session, tmpdir\n    )\n\n\ndef test_test_tar_and_upload_dir_with_subfolders(sagemaker_session, tmpdir):\n    file_tree(tmpdir, [""a/b/c"", ""a/b/c2""])\n    root = file_tree(tmpdir, [""x/y/z"", ""x/y/z2""])\n\n    with patch(""shutil.rmtree""):\n        result = fw_utils.tar_and_upload_dir(\n            sagemaker_session,\n            ""bucket"",\n            ""prefix"",\n            ""b/c"",\n            os.path.join(root, ""a""),\n            [os.path.join(root, ""x"")],\n        )\n\n    assert result == fw_utils.UploadedCode(\n        s3_prefix=""s3://bucket/prefix/sourcedir.tar.gz"", script_name=""b/c""\n    )\n\n    assert {""/b/c"", ""/b/c2"", ""/x/y/z"", ""/x/y/z2""} == list_source_dir_files(\n        sagemaker_session, tmpdir\n    )\n\n\ndef list_source_dir_files(sagemaker_session, tmpdir):\n    source_dir_tar = sagemaker_session.resource(""s3"").Object().upload_file.call_args[0][0]\n\n    source_dir_files = list_tar_files(""/opt/ml/code/"", source_dir_tar, tmpdir)\n    return source_dir_files\n\n\ndef list_tar_files(folder, tar_ball, tmpdir):\n    startpath = str(tmpdir.ensure(folder, dir=True))\n\n    with tarfile.open(name=tar_ball, mode=""r:gz"") as t:\n        t.extractall(path=startpath)\n\n    def walk():\n        for root, dirs, files in os.walk(startpath):\n            path = root.replace(startpath, """")\n            for f in files:\n                yield ""%s/%s"" % (path, f)\n\n    result = set(walk())\n    return result if result else {}\n\n\ndef test_framework_name_from_image_mxnet():\n    image_name = ""123.dkr.ecr.us-west-2.amazonaws.com/sagemaker-mxnet:1.1-gpu-py3""\n    assert (""mxnet"", ""py3"", ""1.1-gpu-py3"", None) == fw_utils.framework_name_from_image(image_name)\n\n\ndef test_framework_name_from_image_mxnet_in_gov():\n    image_name = ""123.dkr.ecr.region-name.c2s.ic.gov/sagemaker-mxnet:1.1-gpu-py3""\n    assert (""mxnet"", ""py3"", ""1.1-gpu-py3"", None) == fw_utils.framework_name_from_image(image_name)\n\n\ndef test_framework_name_from_image_tf():\n    image_name = ""123.dkr.ecr.us-west-2.amazonaws.com/sagemaker-tensorflow:1.6-cpu-py2""\n    assert (""tensorflow"", ""py2"", ""1.6-cpu-py2"", None) == fw_utils.framework_name_from_image(\n        image_name\n    )\n\n\ndef test_framework_name_from_image_tf_scriptmode():\n    image_name = ""123.dkr.ecr.us-west-2.amazonaws.com/sagemaker-tensorflow-scriptmode:1.12-cpu-py3""\n    assert (\n        ""tensorflow"",\n        ""py3"",\n        ""1.12-cpu-py3"",\n        ""scriptmode"",\n    ) == fw_utils.framework_name_from_image(image_name)\n\n    image_name = ""123.dkr.ecr.us-west-2.amazonaws.com/tensorflow-training:1.13-cpu-py3""\n    assert (""tensorflow"", ""py3"", ""1.13-cpu-py3"", ""training"") == fw_utils.framework_name_from_image(\n        image_name\n    )\n\n\ndef test_framework_name_from_image_rl():\n    image_name = ""123.dkr.ecr.us-west-2.amazonaws.com/sagemaker-rl-mxnet:toolkit1.1-gpu-py3""\n    assert (""mxnet"", ""py3"", ""toolkit1.1-gpu-py3"", None) == fw_utils.framework_name_from_image(\n        image_name\n    )\n\n\ndef test_legacy_name_from_framework_image():\n    image_name = ""123.dkr.ecr.us-west-2.amazonaws.com/sagemaker-mxnet-py3-gpu:2.5.6-gpu-py2""\n    framework, py_ver, tag, _ = fw_utils.framework_name_from_image(image_name)\n    assert framework == ""mxnet""\n    assert py_ver == ""py3""\n    assert tag == ""2.5.6-gpu-py2""\n\n\ndef test_legacy_name_from_wrong_framework():\n    framework, py_ver, tag, _ = fw_utils.framework_name_from_image(\n        ""123.dkr.ecr.us-west-2.amazonaws.com/sagemaker-myown-py2-gpu:1""\n    )\n    assert framework is None\n    assert py_ver is None\n    assert tag is None\n\n\ndef test_legacy_name_from_wrong_python():\n    framework, py_ver, tag, _ = fw_utils.framework_name_from_image(\n        ""123.dkr.ecr.us-west-2.amazonaws.com/sagemaker-myown-py4-gpu:1""\n    )\n    assert framework is None\n    assert py_ver is None\n    assert tag is None\n\n\ndef test_legacy_name_from_wrong_device():\n    framework, py_ver, tag, _ = fw_utils.framework_name_from_image(\n        ""123.dkr.ecr.us-west-2.amazonaws.com/sagemaker-myown-py4-gpu:1""\n    )\n    assert framework is None\n    assert py_ver is None\n    assert tag is None\n\n\ndef test_legacy_name_from_image_any_tag():\n    image_name = ""123.dkr.ecr.us-west-2.amazonaws.com/sagemaker-tensorflow-py2-cpu:any-tag""\n    framework, py_ver, tag, _ = fw_utils.framework_name_from_image(image_name)\n    assert framework == ""tensorflow""\n    assert py_ver == ""py2""\n    assert tag == ""any-tag""\n\n\ndef test_framework_version_from_tag():\n    version = fw_utils.framework_version_from_tag(""1.5rc-keras-gpu-py2"")\n    assert version == ""1.5rc-keras""\n\n\ndef test_framework_version_from_tag_other():\n    version = fw_utils.framework_version_from_tag(""weird-tag-py2"")\n    assert version is None\n\n\ndef test_parse_s3_url():\n    bucket, key_prefix = fw_utils.parse_s3_url(""s3://bucket/code_location"")\n    assert ""bucket"" == bucket\n    assert ""code_location"" == key_prefix\n\n\ndef test_parse_s3_url_fail():\n    with pytest.raises(ValueError) as error:\n        fw_utils.parse_s3_url(""t3://code_location"")\n    assert ""Expecting \'s3\' scheme"" in str(error)\n\n\ndef test_model_code_key_prefix_with_all_values_present():\n    key_prefix = fw_utils.model_code_key_prefix(""prefix"", ""model_name"", ""image_name"")\n    assert key_prefix == ""prefix/model_name""\n\n\ndef test_model_code_key_prefix_with_no_prefix_and_all_other_values_present():\n    key_prefix = fw_utils.model_code_key_prefix(None, ""model_name"", ""image_name"")\n    assert key_prefix == ""model_name""\n\n\n@patch(""time.strftime"", return_value=TIMESTAMP)\ndef test_model_code_key_prefix_with_only_image_present(time):\n    key_prefix = fw_utils.model_code_key_prefix(None, None, ""image_name"")\n    assert key_prefix == name_from_image(""image_name"")\n\n\n@patch(""time.strftime"", return_value=TIMESTAMP)\ndef test_model_code_key_prefix_and_image_present(time):\n    key_prefix = fw_utils.model_code_key_prefix(""prefix"", None, ""image_name"")\n    assert key_prefix == ""prefix/"" + name_from_image(""image_name"")\n\n\ndef test_model_code_key_prefix_with_prefix_present_and_others_none_fail():\n    with pytest.raises(TypeError) as error:\n        fw_utils.model_code_key_prefix(""prefix"", None, None)\n    assert ""expected string"" in str(error)\n\n\ndef test_model_code_key_prefix_with_all_none_fail():\n    with pytest.raises(TypeError) as error:\n        fw_utils.model_code_key_prefix(None, None, None)\n    assert ""expected string"" in str(error)\n\n\ndef test_region_supports_debugger_feature_returns_true_for_supported_regions():\n    assert fw_utils._region_supports_debugger(""us-west-2"") is True\n    assert fw_utils._region_supports_debugger(""us-east-2"") is True\n\n\ndef test_region_supports_debugger_feature_returns_false_for_unsupported_regions():\n    assert fw_utils._region_supports_debugger(""us-gov-west-1"") is False\n    assert fw_utils._region_supports_debugger(""us-iso-east-1"") is False\n\n\ndef test_warn_if_parameter_server_with_multi_gpu(caplog):\n    train_instance_type = ""ml.p2.8xlarge""\n    distributions = {""parameter_server"": {""enabled"": True}}\n\n    fw_utils.warn_if_parameter_server_with_multi_gpu(\n        training_instance_type=train_instance_type, distributions=distributions\n    )\n    assert fw_utils.PARAMETER_SERVER_MULTI_GPU_WARNING in caplog.text\n'"
tests/unit/test_git_utils.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport pytest\nimport os\nimport subprocess\nfrom mock import patch\n\nfrom sagemaker import git_utils\n\nREPO_DIR = ""/tmp/repo_dir""\nPUBLIC_GIT_REPO = ""https://github.com/aws/sagemaker-python-sdk.git""\nPUBLIC_BRANCH = ""test-branch-git-config""\nPUBLIC_COMMIT = ""ae15c9d7d5b97ea95ea451e4662ee43da3401d73""\nPRIVATE_GIT_REPO_SSH = ""git@github.com:testAccount/private-repo.git""\nPRIVATE_GIT_REPO = ""https://github.com/testAccount/private-repo.git""\nPRIVATE_BRANCH = ""test-branch""\nPRIVATE_COMMIT = ""329bfcf884482002c05ff7f44f62599ebc9f445a""\nCODECOMMIT_REPO = ""https://git-codecommit.us-west-2.amazonaws.com/v1/repos/test-repo/""\nCODECOMMIT_REPO_SSH = ""ssh://git-codecommit.us-west-2.amazonaws.com/v1/repos/test-repo/""\nCODECOMMIT_BRANCH = ""master""\n\n\n@patch(""subprocess.check_call"")\n@patch(""tempfile.mkdtemp"", return_value=REPO_DIR)\n@patch(""os.path.isfile"", return_value=True)\n@patch(""os.path.isdir"", return_value=True)\n@patch(""os.path.exists"", return_value=True)\ndef test_git_clone_repo_succeed(exists, isdir, isfile, mkdtemp, check_call):\n    git_config = {""repo"": PUBLIC_GIT_REPO, ""branch"": PUBLIC_BRANCH, ""commit"": PUBLIC_COMMIT}\n    entry_point = ""entry_point""\n    source_dir = ""source_dir""\n    dependencies = [""foo"", ""bar""]\n    env = os.environ.copy()\n    env[""GIT_TERMINAL_PROMPT""] = ""0""\n    ret = git_utils.git_clone_repo(git_config, entry_point, source_dir, dependencies)\n    check_call.assert_any_call([""git"", ""clone"", git_config[""repo""], REPO_DIR], env=env)\n    check_call.assert_any_call(args=[""git"", ""checkout"", PUBLIC_BRANCH], cwd=REPO_DIR)\n    check_call.assert_any_call(args=[""git"", ""checkout"", PUBLIC_COMMIT], cwd=REPO_DIR)\n    mkdtemp.assert_called_once()\n    assert ret[""entry_point""] == ""entry_point""\n    assert ret[""source_dir""] == ""/tmp/repo_dir/source_dir""\n    assert ret[""dependencies""] == [""/tmp/repo_dir/foo"", ""/tmp/repo_dir/bar""]\n\n\ndef test_git_clone_repo_repo_not_provided():\n    git_config = {""branch"": PUBLIC_BRANCH, ""commit"": PUBLIC_COMMIT}\n    entry_point = ""entry_point_that_does_not_exist""\n    source_dir = ""source_dir""\n    dependencies = [""foo"", ""bar""]\n    with pytest.raises(ValueError) as error:\n        git_utils.git_clone_repo(git_config, entry_point, source_dir, dependencies)\n    assert ""Please provide a repo for git_config."" in str(error)\n\n\ndef test_git_clone_repo_git_argument_wrong_format():\n    git_config = {\n        ""repo"": PUBLIC_GIT_REPO,\n        ""branch"": PUBLIC_BRANCH,\n        ""commit"": PUBLIC_COMMIT,\n        ""token"": 42,\n    }\n    entry_point = ""entry_point""\n    source_dir = ""source_dir""\n    dependencies = [""foo"", ""bar""]\n    env = os.environ.copy()\n    env[""GIT_TERMINAL_PROMPT""] = ""0""\n    with pytest.raises(ValueError) as error:\n        git_utils.git_clone_repo(git_config, entry_point, source_dir, dependencies)\n    assert ""\'token\' must be a string."" in str(error)\n\n\n@patch(\n    ""subprocess.check_call"",\n    side_effect=subprocess.CalledProcessError(\n        returncode=1, cmd=""git clone {} {}"".format(PUBLIC_GIT_REPO, REPO_DIR)\n    ),\n)\n@patch(""tempfile.mkdtemp"", return_value=REPO_DIR)\ndef test_git_clone_repo_clone_fail(mkdtemp, check_call):\n    git_config = {""repo"": PUBLIC_GIT_REPO, ""branch"": PUBLIC_BRANCH, ""commit"": PUBLIC_COMMIT}\n    entry_point = ""entry_point""\n    source_dir = ""source_dir""\n    dependencies = [""foo"", ""bar""]\n    with pytest.raises(subprocess.CalledProcessError) as error:\n        git_utils.git_clone_repo(git_config, entry_point, source_dir, dependencies)\n    assert ""returned non-zero exit status"" in str(error)\n\n\n@patch(\n    ""subprocess.check_call"",\n    side_effect=[True, subprocess.CalledProcessError(returncode=1, cmd=""git checkout banana"")],\n)\n@patch(""tempfile.mkdtemp"", return_value=REPO_DIR)\ndef test_git_clone_repo_branch_not_exist(mkdtemp, check_call):\n    git_config = {""repo"": PUBLIC_GIT_REPO, ""branch"": PUBLIC_BRANCH, ""commit"": PUBLIC_COMMIT}\n    entry_point = ""entry_point""\n    source_dir = ""source_dir""\n    dependencies = [""foo"", ""bar""]\n    with pytest.raises(subprocess.CalledProcessError) as error:\n        git_utils.git_clone_repo(git_config, entry_point, source_dir, dependencies)\n    assert ""returned non-zero exit status"" in str(error)\n\n\n@patch(\n    ""subprocess.check_call"",\n    side_effect=[\n        True,\n        True,\n        subprocess.CalledProcessError(returncode=1, cmd=""git checkout {}"".format(PUBLIC_COMMIT)),\n    ],\n)\n@patch(""tempfile.mkdtemp"", return_value=REPO_DIR)\ndef test_git_clone_repo_commit_not_exist(mkdtemp, check_call):\n    git_config = {""repo"": PUBLIC_GIT_REPO, ""branch"": PUBLIC_BRANCH, ""commit"": PUBLIC_COMMIT}\n    entry_point = ""entry_point""\n    source_dir = ""source_dir""\n    dependencies = [""foo"", ""bar""]\n    with pytest.raises(subprocess.CalledProcessError) as error:\n        git_utils.git_clone_repo(git_config, entry_point, source_dir, dependencies)\n    assert ""returned non-zero exit status"" in str(error)\n\n\n@patch(""subprocess.check_call"")\n@patch(""tempfile.mkdtemp"", return_value=REPO_DIR)\n@patch(""os.path.isfile"", return_value=False)\n@patch(""os.path.isdir"", return_value=True)\n@patch(""os.path.exists"", return_value=True)\ndef test_git_clone_repo_entry_point_not_exist(exists, isdir, isfile, mkdtemp, heck_call):\n    git_config = {""repo"": PUBLIC_GIT_REPO, ""branch"": PUBLIC_BRANCH, ""commit"": PUBLIC_COMMIT}\n    entry_point = ""entry_point_that_does_not_exist""\n    source_dir = ""source_dir""\n    dependencies = [""foo"", ""bar""]\n    with pytest.raises(ValueError) as error:\n        git_utils.git_clone_repo(git_config, entry_point, source_dir, dependencies)\n    assert ""Entry point does not exist in the repo."" in str(error)\n\n\n@patch(""subprocess.check_call"")\n@patch(""tempfile.mkdtemp"", return_value=REPO_DIR)\n@patch(""os.path.isfile"", return_value=True)\n@patch(""os.path.isdir"", return_value=False)\n@patch(""os.path.exists"", return_value=True)\ndef test_git_clone_repo_source_dir_not_exist(exists, isdir, isfile, mkdtemp, check_call):\n    git_config = {""repo"": PUBLIC_GIT_REPO, ""branch"": PUBLIC_BRANCH, ""commit"": PUBLIC_COMMIT}\n    entry_point = ""entry_point""\n    source_dir = ""source_dir_that_does_not_exist""\n    dependencies = [""foo"", ""bar""]\n    with pytest.raises(ValueError) as error:\n        git_utils.git_clone_repo(git_config, entry_point, source_dir, dependencies)\n    assert ""Source directory does not exist in the repo."" in str(error)\n\n\n@patch(""subprocess.check_call"")\n@patch(""tempfile.mkdtemp"", return_value=REPO_DIR)\n@patch(""os.path.isfile"", return_value=True)\n@patch(""os.path.isdir"", return_value=True)\n@patch(""os.path.exists"", side_effect=[True, False])\ndef test_git_clone_repo_dependencies_not_exist(exists, isdir, isfile, mkdtemp, check_call):\n    git_config = {""repo"": PUBLIC_GIT_REPO, ""branch"": PUBLIC_BRANCH, ""commit"": PUBLIC_COMMIT}\n    entry_point = ""entry_point""\n    source_dir = ""source_dir""\n    dependencies = [""foo"", ""dep_that_does_not_exist""]\n    with pytest.raises(ValueError) as error:\n        git_utils.git_clone_repo(git_config, entry_point, source_dir, dependencies)\n    assert ""does not exist in the repo."" in str(error)\n\n\n@patch(""subprocess.check_call"")\n@patch(""tempfile.mkdtemp"", return_value=REPO_DIR)\n@patch(""os.path.isfile"", return_value=True)\ndef test_git_clone_repo_with_username_password_no_2fa(sfile, mkdtemp, check_call):\n    git_config = {\n        ""repo"": PRIVATE_GIT_REPO,\n        ""branch"": PRIVATE_BRANCH,\n        ""commit"": PRIVATE_COMMIT,\n        ""username"": ""username"",\n        ""password"": ""passw0rd!"",\n    }\n    entry_point = ""entry_point""\n    env = os.environ.copy()\n    env[""GIT_TERMINAL_PROMPT""] = ""0""\n    ret = git_utils.git_clone_repo(git_config=git_config, entry_point=entry_point)\n    check_call.assert_any_call(\n        [\n            ""git"",\n            ""clone"",\n            ""https://username:passw0rd%21@github.com/testAccount/private-repo.git"",\n            REPO_DIR,\n        ],\n        env=env,\n    )\n    check_call.assert_any_call(args=[""git"", ""checkout"", PRIVATE_BRANCH], cwd=REPO_DIR)\n    check_call.assert_any_call(args=[""git"", ""checkout"", PRIVATE_COMMIT], cwd=REPO_DIR)\n    assert ret[""entry_point""] == ""/tmp/repo_dir/entry_point""\n    assert ret[""source_dir""] is None\n    assert ret[""dependencies""] is None\n\n\n@patch(""subprocess.check_call"")\n@patch(""tempfile.mkdtemp"", return_value=REPO_DIR)\n@patch(""os.path.isfile"", return_value=True)\ndef test_git_clone_repo_with_token_no_2fa(isfile, mkdtemp, check_call):\n    git_config = {\n        ""repo"": PRIVATE_GIT_REPO,\n        ""branch"": PRIVATE_BRANCH,\n        ""commit"": PRIVATE_COMMIT,\n        ""token"": ""my-token"",\n        ""2FA_enabled"": False,\n    }\n    entry_point = ""entry_point""\n    env = os.environ.copy()\n    env[""GIT_TERMINAL_PROMPT""] = ""0""\n    ret = git_utils.git_clone_repo(git_config=git_config, entry_point=entry_point)\n    check_call.assert_any_call(\n        [""git"", ""clone"", ""https://my-token@github.com/testAccount/private-repo.git"", REPO_DIR],\n        env=env,\n    )\n    check_call.assert_any_call(args=[""git"", ""checkout"", PRIVATE_BRANCH], cwd=REPO_DIR)\n    check_call.assert_any_call(args=[""git"", ""checkout"", PRIVATE_COMMIT], cwd=REPO_DIR)\n    assert ret[""entry_point""] == ""/tmp/repo_dir/entry_point""\n    assert ret[""source_dir""] is None\n    assert ret[""dependencies""] is None\n\n\n@patch(""subprocess.check_call"")\n@patch(""tempfile.mkdtemp"", return_value=REPO_DIR)\n@patch(""os.path.isfile"", return_value=True)\ndef test_git_clone_repo_with_token_2fa(isfile, mkdtemp, check_call):\n    git_config = {\n        ""repo"": PRIVATE_GIT_REPO,\n        ""branch"": PRIVATE_BRANCH,\n        ""commit"": PRIVATE_COMMIT,\n        ""2FA_enabled"": True,\n        ""username"": ""username"",\n        ""token"": ""my-token"",\n    }\n    entry_point = ""entry_point""\n    env = os.environ.copy()\n    env[""GIT_TERMINAL_PROMPT""] = ""0""\n    ret = git_utils.git_clone_repo(git_config=git_config, entry_point=entry_point)\n    check_call.assert_any_call(\n        [""git"", ""clone"", ""https://my-token@github.com/testAccount/private-repo.git"", REPO_DIR],\n        env=env,\n    )\n    check_call.assert_any_call(args=[""git"", ""checkout"", PRIVATE_BRANCH], cwd=REPO_DIR)\n    check_call.assert_any_call(args=[""git"", ""checkout"", PRIVATE_COMMIT], cwd=REPO_DIR)\n    assert ret[""entry_point""] == ""/tmp/repo_dir/entry_point""\n    assert ret[""source_dir""] is None\n    assert ret[""dependencies""] is None\n\n\n@patch(""subprocess.check_call"")\n@patch(""tempfile.mkdtemp"", return_value=REPO_DIR)\n@patch(""os.path.isfile"", return_value=True)\ndef test_git_clone_repo_ssh(isfile, mkdtemp, check_call):\n    git_config = {""repo"": PRIVATE_GIT_REPO_SSH, ""branch"": PRIVATE_BRANCH, ""commit"": PRIVATE_COMMIT}\n    entry_point = ""entry_point""\n    ret = git_utils.git_clone_repo(git_config, entry_point)\n    assert ret[""entry_point""] == ""/tmp/repo_dir/entry_point""\n    assert ret[""source_dir""] is None\n    assert ret[""dependencies""] is None\n\n\n@patch(""subprocess.check_call"")\n@patch(""tempfile.mkdtemp"", return_value=REPO_DIR)\n@patch(""os.path.isfile"", return_value=True)\ndef test_git_clone_repo_with_token_no_2fa_unnecessary_creds_provided(isfile, mkdtemp, check_call):\n    git_config = {\n        ""repo"": PRIVATE_GIT_REPO,\n        ""branch"": PRIVATE_BRANCH,\n        ""commit"": PRIVATE_COMMIT,\n        ""username"": ""username"",\n        ""password"": ""passw0rd!"",\n        ""token"": ""my-token"",\n    }\n    entry_point = ""entry_point""\n    env = os.environ.copy()\n    env[""GIT_TERMINAL_PROMPT""] = ""0""\n    with pytest.warns(UserWarning) as warn:\n        ret = git_utils.git_clone_repo(git_config=git_config, entry_point=entry_point)\n    assert (\n        ""Using token for authentication, other credentials will be ignored.""\n        in warn[0].message.args[0]\n    )\n    check_call.assert_any_call(\n        [""git"", ""clone"", ""https://my-token@github.com/testAccount/private-repo.git"", REPO_DIR],\n        env=env,\n    )\n    check_call.assert_any_call(args=[""git"", ""checkout"", PRIVATE_BRANCH], cwd=REPO_DIR)\n    check_call.assert_any_call(args=[""git"", ""checkout"", PRIVATE_COMMIT], cwd=REPO_DIR)\n    assert ret[""entry_point""] == ""/tmp/repo_dir/entry_point""\n    assert ret[""source_dir""] is None\n    assert ret[""dependencies""] is None\n\n\n@patch(""subprocess.check_call"")\n@patch(""tempfile.mkdtemp"", return_value=REPO_DIR)\n@patch(""os.path.isfile"", return_value=True)\ndef test_git_clone_repo_with_token_2fa_unnecessary_creds_provided(isfile, mkdtemp, check_call):\n    git_config = {\n        ""repo"": PRIVATE_GIT_REPO,\n        ""branch"": PRIVATE_BRANCH,\n        ""commit"": PRIVATE_COMMIT,\n        ""2FA_enabled"": True,\n        ""username"": ""username"",\n        ""token"": ""my-token"",\n    }\n    entry_point = ""entry_point""\n    env = os.environ.copy()\n    env[""GIT_TERMINAL_PROMPT""] = ""0""\n    with pytest.warns(UserWarning) as warn:\n        ret = git_utils.git_clone_repo(git_config=git_config, entry_point=entry_point)\n    assert (\n        ""Using token for authentication, other credentials will be ignored.""\n        in warn[0].message.args[0]\n    )\n    check_call.assert_any_call(\n        [""git"", ""clone"", ""https://my-token@github.com/testAccount/private-repo.git"", REPO_DIR],\n        env=env,\n    )\n    check_call.assert_any_call(args=[""git"", ""checkout"", PRIVATE_BRANCH], cwd=REPO_DIR)\n    check_call.assert_any_call(args=[""git"", ""checkout"", PRIVATE_COMMIT], cwd=REPO_DIR)\n    assert ret[""entry_point""] == ""/tmp/repo_dir/entry_point""\n    assert ret[""source_dir""] is None\n    assert ret[""dependencies""] is None\n\n\n@patch(\n    ""subprocess.check_call"",\n    side_effect=subprocess.CalledProcessError(\n        returncode=1, cmd=""git clone {} {}"".format(PRIVATE_GIT_REPO, REPO_DIR)\n    ),\n)\n@patch(""tempfile.mkdtemp"", return_value=REPO_DIR)\ndef test_git_clone_repo_with_username_and_password_wrong_creds(mkdtemp, check_call):\n    git_config = {\n        ""repo"": PRIVATE_GIT_REPO,\n        ""branch"": PRIVATE_BRANCH,\n        ""commit"": PRIVATE_COMMIT,\n        ""2FA_enabled"": False,\n        ""username"": ""username"",\n        ""password"": ""wrong-password"",\n    }\n    entry_point = ""entry_point""\n    env = os.environ.copy()\n    env[""GIT_TERMINAL_PROMPT""] = ""0""\n    with pytest.raises(subprocess.CalledProcessError) as error:\n        git_utils.git_clone_repo(git_config=git_config, entry_point=entry_point)\n    assert ""returned non-zero exit status"" in str(error)\n\n\n@patch(\n    ""subprocess.check_call"",\n    side_effect=subprocess.CalledProcessError(\n        returncode=1, cmd=""git clone {} {}"".format(PRIVATE_GIT_REPO, REPO_DIR)\n    ),\n)\n@patch(""tempfile.mkdtemp"", return_value=REPO_DIR)\ndef test_git_clone_repo_with_token_wrong_creds(mkdtemp, check_call):\n    git_config = {\n        ""repo"": PRIVATE_GIT_REPO,\n        ""branch"": PRIVATE_BRANCH,\n        ""commit"": PRIVATE_COMMIT,\n        ""2FA_enabled"": False,\n        ""token"": ""wrong-token"",\n    }\n    entry_point = ""entry_point""\n    env = os.environ.copy()\n    env[""GIT_TERMINAL_PROMPT""] = ""0""\n    with pytest.raises(subprocess.CalledProcessError) as error:\n        git_utils.git_clone_repo(git_config=git_config, entry_point=entry_point)\n    assert ""returned non-zero exit status"" in str(error)\n\n\n@patch(\n    ""subprocess.check_call"",\n    side_effect=subprocess.CalledProcessError(\n        returncode=1, cmd=""git clone {} {}"".format(PRIVATE_GIT_REPO, REPO_DIR)\n    ),\n)\n@patch(""tempfile.mkdtemp"", return_value=REPO_DIR)\ndef test_git_clone_repo_with_and_token_2fa_wrong_creds(mkdtemp, check_call):\n    git_config = {\n        ""repo"": PRIVATE_GIT_REPO,\n        ""branch"": PRIVATE_BRANCH,\n        ""commit"": PRIVATE_COMMIT,\n        ""2FA_enabled"": False,\n        ""token"": ""wrong-token"",\n    }\n    entry_point = ""entry_point""\n    env = os.environ.copy()\n    env[""GIT_TERMINAL_PROMPT""] = ""0""\n    with pytest.raises(subprocess.CalledProcessError) as error:\n        git_utils.git_clone_repo(git_config=git_config, entry_point=entry_point)\n    assert ""returned non-zero exit status"" in str(error)\n\n\n@patch(""subprocess.check_call"")\n@patch(""tempfile.mkdtemp"", return_value=REPO_DIR)\n@patch(""os.path.isfile"", return_value=True)\ndef test_git_clone_repo_codecommit_https_with_username_and_password(isfile, mkdtemp, check_call):\n    git_config = {\n        ""repo"": CODECOMMIT_REPO,\n        ""branch"": CODECOMMIT_BRANCH,\n        ""username"": ""username"",\n        ""password"": ""my-codecommit-password"",\n    }\n    entry_point = ""entry_point""\n    env = os.environ.copy()\n    env[""GIT_TERMINAL_PROMPT""] = ""0""\n    ret = git_utils.git_clone_repo(git_config=git_config, entry_point=entry_point)\n    check_call.assert_any_call(\n        [\n            ""git"",\n            ""clone"",\n            ""https://username:my-codecommit-password@git-codecommit.us-west-2.amazonaws.com/v1/repos/test-repo/"",\n            REPO_DIR,\n        ],\n        env=env,\n    )\n    check_call.assert_any_call(args=[""git"", ""checkout"", CODECOMMIT_BRANCH], cwd=REPO_DIR)\n    assert ret[""entry_point""] == ""/tmp/repo_dir/entry_point""\n    assert ret[""source_dir""] is None\n    assert ret[""dependencies""] is None\n\n\n@patch(\n    ""subprocess.check_call"",\n    side_effect=subprocess.CalledProcessError(\n        returncode=128, cmd=""git clone {} {}"".format(CODECOMMIT_REPO_SSH, REPO_DIR)\n    ),\n)\n@patch(""tempfile.mkdtemp"", return_value=REPO_DIR)\ndef test_git_clone_repo_codecommit_ssh_passphrase_required(mkdtemp, check_call):\n    git_config = {""repo"": CODECOMMIT_REPO_SSH, ""branch"": CODECOMMIT_BRANCH}\n    entry_point = ""entry_point""\n    with pytest.raises(subprocess.CalledProcessError) as error:\n        git_utils.git_clone_repo(git_config, entry_point)\n    assert ""returned non-zero exit status"" in str(error)\n\n\n@patch(\n    ""subprocess.check_call"",\n    side_effect=subprocess.CalledProcessError(\n        returncode=128, cmd=""git clone {} {}"".format(CODECOMMIT_REPO, REPO_DIR)\n    ),\n)\n@patch(""tempfile.mkdtemp"", return_value=REPO_DIR)\ndef test_git_clone_repo_codecommit_https_creds_not_stored_locally(mkdtemp, check_call):\n    git_config = {""repo"": CODECOMMIT_REPO, ""branch"": CODECOMMIT_BRANCH}\n    entry_point = ""entry_point""\n    with pytest.raises(subprocess.CalledProcessError) as error:\n        git_utils.git_clone_repo(git_config, entry_point)\n    assert ""returned non-zero exit status"" in str(error)\n'"
tests/unit/test_hyperparameter.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport pytest\nfrom sagemaker.amazon.hyperparameter import Hyperparameter\n\n\nclass Test(object):\n\n    blank = Hyperparameter(name=""some-name"", data_type=int)\n    elizabeth = Hyperparameter(name=""elizabeth"")\n    validated = Hyperparameter(name=""validated"", validate=lambda value: value > 55, data_type=int)\n\n\ndef test_blank_access():\n    x = Test()\n    # blank isn\'t set yet, so accessing it is an error\n    with pytest.raises(AttributeError):\n        x.blank\n\n\ndef test_blank():\n    x = Test()\n    x.blank = 82\n    assert x.blank == 82\n\n\ndef test_delete():\n    x = Test()\n    x.blank = 97\n    assert x.blank == 97\n    del x.blank\n    with pytest.raises(AttributeError):\n        x.blank\n\n\ndef test_name():\n    x = Test()\n    with pytest.raises(AttributeError) as excinfo:\n        x.elizabeth\n        assert ""elizabeth"" in excinfo\n\n\ndef test_validated():\n    x = Test()\n    x.validated = 66\n    with pytest.raises(ValueError):\n        x.validated = 23\n\n\ndef test_data_type():\n    x = Test()\n    x.validated = 66\n    assert type(x.validated) == Test.__dict__[""validated""].data_type\n\n\ndef test_from_string():\n    x = Test()\n    value = 65\n\n    x.validated = value\n    from_api = str(value)\n\n    x.validated = from_api\n    assert x.validated == value\n'"
tests/unit/test_image.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport random\nimport string\n\nfrom botocore.credentials import Credentials\n\nimport base64\nimport json\nimport os\nimport subprocess\nimport tarfile\n\nimport pytest\nimport yaml\nfrom mock import patch, Mock, MagicMock\n\nimport sagemaker\nfrom sagemaker.local.image import _SageMakerContainer, _aws_credentials\n\nREGION = ""us-west-2""\nBUCKET_NAME = ""mybucket""\nEXPANDED_ROLE = ""arn:aws:iam::111111111111:role/ExpandedRole""\nTRAINING_JOB_NAME = ""my-job""\nINPUT_DATA_CONFIG = [\n    {\n        ""ChannelName"": ""a"",\n        ""DataUri"": ""file:///tmp/source1"",\n        ""DataSource"": {\n            ""FileDataSource"": {\n                ""FileDataDistributionType"": ""FullyReplicated"",\n                ""FileUri"": ""file:///tmp/source1"",\n            }\n        },\n    },\n    {\n        ""ChannelName"": ""b"",\n        ""DataUri"": ""s3://my-own-bucket/prefix"",\n        ""DataSource"": {\n            ""S3DataSource"": {\n                ""S3DataDistributionType"": ""FullyReplicated"",\n                ""S3DataType"": ""S3Prefix"",\n                ""S3Uri"": ""s3://my-own-bucket/prefix"",\n            }\n        },\n    },\n]\n\nOUTPUT_DATA_CONFIG = {""S3OutputPath"": """"}\n\nHYPERPARAMETERS = {\n    ""a"": 1,\n    ""b"": json.dumps(""bee""),\n    ""sagemaker_submit_directory"": json.dumps(""s3://my_bucket/code""),\n}\n\nLOCAL_CODE_HYPERPARAMETERS = {\n    ""a"": 1,\n    ""b"": 2,\n    ""sagemaker_submit_directory"": json.dumps(""file:///tmp/code""),\n}\n\n\n@pytest.fixture()\ndef sagemaker_session():\n    boto_mock = Mock(name=""boto_session"", region_name=REGION)\n    boto_mock.client(""sts"").get_caller_identity.return_value = {""Account"": ""123""}\n    boto_mock.resource(""s3"").Bucket(BUCKET_NAME).objects.filter.return_value = []\n\n    sms = sagemaker.Session(boto_session=boto_mock, sagemaker_client=Mock())\n\n    sms.default_bucket = Mock(name=""default_bucket"", return_value=BUCKET_NAME)\n    sms.expand_role = Mock(return_value=EXPANDED_ROLE)\n\n    return sms\n\n\ndef test_sagemaker_container_hosts_should_have_lowercase_names():\n    random.seed(a=42)\n\n    def assert_all_lowercase(hosts):\n        for host in hosts:\n            assert host.lower() == host\n\n    sagemaker_container = _SageMakerContainer(""local"", 2, ""my-image"", sagemaker_session=Mock())\n    assert_all_lowercase(sagemaker_container.hosts)\n\n    sagemaker_container = _SageMakerContainer(""local"", 10, ""my-image"", sagemaker_session=Mock())\n    assert_all_lowercase(sagemaker_container.hosts)\n\n    sagemaker_container = _SageMakerContainer(""local"", 1, ""my-image"", sagemaker_session=Mock())\n    assert_all_lowercase(sagemaker_container.hosts)\n\n\n@patch(""sagemaker.local.local_session.LocalSession"")\ndef test_write_config_file(LocalSession, tmpdir):\n    sagemaker_container = _SageMakerContainer(""local"", 2, ""my-image"")\n    sagemaker_container.container_root = str(tmpdir.mkdir(""container-root""))\n    host = ""algo-1""\n\n    sagemaker.local.image._create_config_file_directories(sagemaker_container.container_root, host)\n\n    container_root = sagemaker_container.container_root\n    config_file_root = os.path.join(container_root, host, ""input"", ""config"")\n\n    hyperparameters_file = os.path.join(config_file_root, ""hyperparameters.json"")\n    resource_config_file = os.path.join(config_file_root, ""resourceconfig.json"")\n    input_data_config_file = os.path.join(config_file_root, ""inputdataconfig.json"")\n\n    # write the config files, and then lets check they exist and have the right content.\n    sagemaker_container.write_config_files(host, HYPERPARAMETERS, INPUT_DATA_CONFIG)\n\n    assert os.path.exists(hyperparameters_file)\n    assert os.path.exists(resource_config_file)\n    assert os.path.exists(input_data_config_file)\n\n    hyperparameters_data = json.load(open(hyperparameters_file))\n    resource_config_data = json.load(open(resource_config_file))\n    input_data_config_data = json.load(open(input_data_config_file))\n\n    # Validate HyperParameters\n    for k, v in HYPERPARAMETERS.items():\n        assert k in hyperparameters_data\n        assert hyperparameters_data[k] == v\n\n    # Validate Resource Config\n    assert resource_config_data[""current_host""] == host\n    assert resource_config_data[""hosts""] == sagemaker_container.hosts\n\n    # Validate Input Data Config\n    for channel in INPUT_DATA_CONFIG:\n        assert channel[""ChannelName""] in input_data_config_data\n\n\n@patch(""sagemaker.local.local_session.LocalSession"")\ndef test_write_config_files_input_content_type(LocalSession, tmpdir):\n    sagemaker_container = _SageMakerContainer(""local"", 1, ""my-image"")\n    sagemaker_container.container_root = str(tmpdir.mkdir(""container-root""))\n    host = ""algo-1""\n\n    sagemaker.local.image._create_config_file_directories(sagemaker_container.container_root, host)\n\n    container_root = sagemaker_container.container_root\n    config_file_root = os.path.join(container_root, host, ""input"", ""config"")\n\n    input_data_config_file = os.path.join(config_file_root, ""inputdataconfig.json"")\n\n    # write the config files, and then lets check they exist and have the right content.\n    input_data_config = [\n        {\n            ""ChannelName"": ""channel_a"",\n            ""DataUri"": ""file:///tmp/source1"",\n            ""ContentType"": ""text/csv"",\n            ""DataSource"": {\n                ""FileDataSource"": {\n                    ""FileDataDistributionType"": ""FullyReplicated"",\n                    ""FileUri"": ""file:///tmp/source1"",\n                }\n            },\n        },\n        {\n            ""ChannelName"": ""channel_b"",\n            ""DataUri"": ""s3://my-own-bucket/prefix"",\n            ""DataSource"": {\n                ""S3DataSource"": {\n                    ""S3DataDistributionType"": ""FullyReplicated"",\n                    ""S3DataType"": ""S3Prefix"",\n                    ""S3Uri"": ""s3://my-own-bucket/prefix"",\n                }\n            },\n        },\n    ]\n    sagemaker_container.write_config_files(host, HYPERPARAMETERS, input_data_config)\n\n    assert os.path.exists(input_data_config_file)\n    parsed_input_config = json.load(open(input_data_config_file))\n    # Validate Input Data Config\n    for channel in input_data_config:\n        assert channel[""ChannelName""] in parsed_input_config\n\n    # Channel A has a content type\n    assert ""ContentType"" in parsed_input_config[""channel_a""]\n    assert parsed_input_config[""channel_a""][""ContentType""] == ""text/csv""\n\n    # Channel B does not have content type\n    assert ""ContentType"" not in parsed_input_config[""channel_b""]\n\n\n@patch(""sagemaker.local.local_session.LocalSession"")\ndef test_retrieve_artifacts(LocalSession, tmpdir):\n    sagemaker_container = _SageMakerContainer(""local"", 2, ""my-image"")\n    sagemaker_container.hosts = [""algo-1"", ""algo-2""]  # avoid any randomness\n    sagemaker_container.container_root = str(tmpdir.mkdir(""container-root""))\n\n    volume1 = os.path.join(sagemaker_container.container_root, ""algo-1"")\n    volume2 = os.path.join(sagemaker_container.container_root, ""algo-2"")\n    os.mkdir(volume1)\n    os.mkdir(volume2)\n\n    compose_data = {\n        ""services"": {\n            ""algo-1"": {\n                ""volumes"": [\n                    ""%s:/opt/ml/model"" % os.path.join(volume1, ""model""),\n                    ""%s:/opt/ml/output"" % os.path.join(volume1, ""output""),\n                ]\n            },\n            ""algo-2"": {\n                ""volumes"": [\n                    ""%s:/opt/ml/model"" % os.path.join(volume2, ""model""),\n                    ""%s:/opt/ml/output"" % os.path.join(volume2, ""output""),\n                ]\n            },\n        }\n    }\n\n    dirs = [\n        (""model"", volume1),\n        (""model/data"", volume1),\n        (""model"", volume2),\n        (""model/data"", volume2),\n        (""model/tmp"", volume2),\n        (""output"", volume1),\n        (""output/data"", volume1),\n        (""output"", volume2),\n        (""output/data"", volume2),\n        (""output/log"", volume2),\n    ]\n\n    files = [\n        (""model/data/model.json"", volume1),\n        (""model/data/variables.csv"", volume1),\n        (""model/data/model.json"", volume2),\n        (""model/data/variables2.csv"", volume2),\n        (""model/tmp/something-else.json"", volume2),\n        (""output/data/loss.json"", volume1),\n        (""output/data/accuracy.json"", volume1),\n        (""output/data/loss.json"", volume2),\n        (""output/data/accuracy2.json"", volume2),\n        (""output/log/warnings.txt"", volume2),\n    ]\n\n    expected_model = [\n        ""data"",\n        ""data/model.json"",\n        ""data/variables.csv"",\n        ""data/variables2.csv"",\n        ""tmp/something-else.json"",\n    ]\n    expected_output = [\n        ""data"",\n        ""log"",\n        ""data/loss.json"",\n        ""data/accuracy.json"",\n        ""data/accuracy2.json"",\n        ""log/warnings.txt"",\n    ]\n\n    for d, volume in dirs:\n        os.mkdir(os.path.join(volume, d))\n\n    # create all the files\n    for f, volume in files:\n        open(os.path.join(volume, f), ""a"").close()\n\n    output_path = str(tmpdir.mkdir(""exported_files""))\n    output_data_config = {""S3OutputPath"": ""file://%s"" % output_path}\n\n    model_artifacts = sagemaker_container.retrieve_artifacts(\n        compose_data, output_data_config, sagemaker_session\n    ).replace(""file://"", """")\n    artifacts = os.path.dirname(model_artifacts)\n\n    # we have both the tar files\n    assert set(os.listdir(artifacts)) == {""model.tar.gz"", ""output.tar.gz""}\n\n    # check that the tar files contain what we expect\n    tar = tarfile.open(os.path.join(output_path, ""model.tar.gz""))\n    model_tar_files = [m.name for m in tar.getmembers()]\n    for f in expected_model:\n        assert f in model_tar_files\n\n    tar = tarfile.open(os.path.join(output_path, ""output.tar.gz""))\n    output_tar_files = [m.name for m in tar.getmembers()]\n    for f in expected_output:\n        assert f in output_tar_files\n\n\ndef test_stream_output():\n    # it should raise an exception if the command fails\n    with pytest.raises(RuntimeError):\n        p = subprocess.Popen(\n            [""ls"", ""/some/unknown/path""], stdout=subprocess.PIPE, stderr=subprocess.PIPE\n        )\n        sagemaker.local.image._stream_output(p)\n\n    p = subprocess.Popen([""echo"", ""hello""], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    exit_code = sagemaker.local.image._stream_output(p)\n    assert exit_code == 0\n\n\ndef test_check_output():\n    with pytest.raises(Exception):\n        sagemaker.local.image._check_output([""ls"", ""/some/unknown/path""])\n\n    msg = ""hello!""\n\n    output = sagemaker.local.image._check_output([""echo"", msg]).strip()\n    assert output == msg\n\n    output = sagemaker.local.image._check_output(""echo %s"" % msg).strip()\n    assert output == msg\n\n\n@patch(""sagemaker.local.local_session.LocalSession"", Mock())\n@patch(""sagemaker.local.image._stream_output"", Mock())\n@patch(""sagemaker.local.image._SageMakerContainer._cleanup"")\n@patch(""sagemaker.local.image._SageMakerContainer.retrieve_artifacts"")\n@patch(""sagemaker.local.data.get_data_source_instance"")\n@patch(""subprocess.Popen"")\ndef test_train(\n    popen, get_data_source_instance, retrieve_artifacts, cleanup, tmpdir, sagemaker_session\n):\n    data_source = Mock()\n    data_source.get_root_dir.return_value = ""foo""\n    get_data_source_instance.return_value = data_source\n\n    directories = [str(tmpdir.mkdir(""container-root"")), str(tmpdir.mkdir(""data""))]\n    with patch(\n        ""sagemaker.local.image._SageMakerContainer._create_tmp_folder"", side_effect=directories\n    ):\n\n        instance_count = 2\n        image = ""my-image""\n        sagemaker_container = _SageMakerContainer(\n            ""local"", instance_count, image, sagemaker_session=sagemaker_session\n        )\n        sagemaker_container.train(\n            INPUT_DATA_CONFIG, OUTPUT_DATA_CONFIG, HYPERPARAMETERS, TRAINING_JOB_NAME\n        )\n\n        docker_compose_file = os.path.join(\n            sagemaker_container.container_root, ""docker-compose.yaml""\n        )\n        call_args = popen.call_args[0][0]\n        assert call_args is not None\n\n        expected = [\n            ""docker-compose"",\n            ""-f"",\n            docker_compose_file,\n            ""up"",\n            ""--build"",\n            ""--abort-on-container-exit"",\n        ]\n        for i, v in enumerate(expected):\n            assert call_args[i] == v\n\n        with open(docker_compose_file, ""r"") as f:\n            config = yaml.load(f)\n            assert len(config[""services""]) == instance_count\n            for h in sagemaker_container.hosts:\n                assert config[""services""][h][""image""] == image\n                assert config[""services""][h][""command""] == ""train""\n                # TODO-reinvent-2019 [akarpur]: uncomment the below assert statement\n                # assert ""AWS_REGION={}"".format(REGION) in config[""services""][h][""environment""]\n                assert (\n                    ""TRAINING_JOB_NAME={}"".format(TRAINING_JOB_NAME)\n                    in config[""services""][h][""environment""]\n                )\n\n        # assert that expected by sagemaker container output directories exist\n        assert os.path.exists(os.path.join(sagemaker_container.container_root, ""output""))\n        assert os.path.exists(os.path.join(sagemaker_container.container_root, ""output/data""))\n\n    retrieve_artifacts.assert_called_once()\n    cleanup.assert_called_once()\n\n\n@patch(""sagemaker.local.local_session.LocalSession"", Mock())\n@patch(""sagemaker.local.image._stream_output"", Mock())\n@patch(""sagemaker.local.image._SageMakerContainer._cleanup"", Mock())\n@patch(""sagemaker.local.data.get_data_source_instance"")\ndef test_train_with_hyperparameters_without_job_name(\n    get_data_source_instance, tmpdir, sagemaker_session\n):\n    data_source = Mock()\n    data_source.get_root_dir.return_value = ""foo""\n    get_data_source_instance.return_value = data_source\n\n    directories = [str(tmpdir.mkdir(""container-root"")), str(tmpdir.mkdir(""data""))]\n    with patch(\n        ""sagemaker.local.image._SageMakerContainer._create_tmp_folder"", side_effect=directories\n    ):\n        instance_count = 2\n        image = ""my-image""\n        sagemaker_container = _SageMakerContainer(\n            ""local"", instance_count, image, sagemaker_session=sagemaker_session\n        )\n        sagemaker_container.train(\n            INPUT_DATA_CONFIG, OUTPUT_DATA_CONFIG, HYPERPARAMETERS, TRAINING_JOB_NAME\n        )\n\n        docker_compose_file = os.path.join(\n            sagemaker_container.container_root, ""docker-compose.yaml""\n        )\n\n        with open(docker_compose_file, ""r"") as f:\n            config = yaml.load(f)\n            for h in sagemaker_container.hosts:\n                assert (\n                    ""TRAINING_JOB_NAME={}"".format(TRAINING_JOB_NAME)\n                    in config[""services""][h][""environment""]\n                )\n\n\n@patch(""sagemaker.local.local_session.LocalSession"", Mock())\n@patch(""sagemaker.local.image._stream_output"", side_effect=RuntimeError(""this is expected""))\n@patch(""sagemaker.local.image._SageMakerContainer._cleanup"")\n@patch(""sagemaker.local.image._SageMakerContainer.retrieve_artifacts"")\n@patch(""sagemaker.local.data.get_data_source_instance"")\n@patch(""subprocess.Popen"", Mock())\ndef test_train_error(\n    get_data_source_instance, retrieve_artifacts, cleanup, _stream_output, tmpdir, sagemaker_session\n):\n    data_source = Mock()\n    data_source.get_root_dir.return_value = ""foo""\n    get_data_source_instance.return_value = data_source\n\n    directories = [str(tmpdir.mkdir(""container-root"")), str(tmpdir.mkdir(""data""))]\n    with patch(\n        ""sagemaker.local.image._SageMakerContainer._create_tmp_folder"", side_effect=directories\n    ):\n        instance_count = 2\n        image = ""my-image""\n        sagemaker_container = _SageMakerContainer(\n            ""local"", instance_count, image, sagemaker_session=sagemaker_session\n        )\n\n        with pytest.raises(RuntimeError) as e:\n            sagemaker_container.train(\n                INPUT_DATA_CONFIG, OUTPUT_DATA_CONFIG, HYPERPARAMETERS, TRAINING_JOB_NAME\n            )\n\n        assert ""this is expected"" in str(e)\n\n    retrieve_artifacts.assert_called_once()\n    cleanup.assert_called_once()\n\n\n@patch(""sagemaker.local.local_session.LocalSession"", Mock())\n@patch(""sagemaker.local.image._stream_output"", Mock())\n@patch(""sagemaker.local.image._SageMakerContainer._cleanup"", Mock())\n@patch(""sagemaker.local.data.get_data_source_instance"")\n@patch(""subprocess.Popen"", Mock())\ndef test_train_local_code(get_data_source_instance, tmpdir, sagemaker_session):\n    data_source = Mock()\n    data_source.get_root_dir.return_value = ""foo""\n    get_data_source_instance.return_value = data_source\n\n    directories = [str(tmpdir.mkdir(""container-root"")), str(tmpdir.mkdir(""data""))]\n    with patch(\n        ""sagemaker.local.image._SageMakerContainer._create_tmp_folder"", side_effect=directories\n    ):\n        instance_count = 2\n        image = ""my-image""\n        sagemaker_container = _SageMakerContainer(\n            ""local"", instance_count, image, sagemaker_session=sagemaker_session\n        )\n\n        sagemaker_container.train(\n            INPUT_DATA_CONFIG, OUTPUT_DATA_CONFIG, LOCAL_CODE_HYPERPARAMETERS, TRAINING_JOB_NAME\n        )\n\n        docker_compose_file = os.path.join(\n            sagemaker_container.container_root, ""docker-compose.yaml""\n        )\n        shared_folder_path = os.path.join(sagemaker_container.container_root, ""shared"")\n\n        with open(docker_compose_file, ""r"") as f:\n            config = yaml.load(f)\n            assert len(config[""services""]) == instance_count\n\n        for h in sagemaker_container.hosts:\n            assert config[""services""][h][""image""] == image\n            assert config[""services""][h][""command""] == ""train""\n            volumes = config[""services""][h][""volumes""]\n            assert ""%s:/opt/ml/code"" % ""/tmp/code"" in volumes\n            assert ""%s:/opt/ml/shared"" % shared_folder_path in volumes\n\n            config_file_root = os.path.join(\n                sagemaker_container.container_root, h, ""input"", ""config""\n            )\n            hyperparameters_file = os.path.join(config_file_root, ""hyperparameters.json"")\n            hyperparameters_data = json.load(open(hyperparameters_file))\n            assert hyperparameters_data[""sagemaker_submit_directory""] == json.dumps(""/opt/ml/code"")\n\n\n@patch(""sagemaker.local.local_session.LocalSession"", Mock())\n@patch(""sagemaker.local.image._stream_output"", Mock())\n@patch(""sagemaker.local.image._SageMakerContainer._cleanup"", Mock())\n@patch(""sagemaker.local.data.get_data_source_instance"")\n@patch(""subprocess.Popen"", Mock())\ndef test_train_local_intermediate_output(get_data_source_instance, tmpdir, sagemaker_session):\n    data_source = Mock()\n    data_source.get_root_dir.return_value = ""foo""\n    get_data_source_instance.return_value = data_source\n\n    directories = [str(tmpdir.mkdir(""container-root"")), str(tmpdir.mkdir(""data""))]\n    with patch(\n        ""sagemaker.local.image._SageMakerContainer._create_tmp_folder"", side_effect=directories\n    ):\n        instance_count = 2\n        image = ""my-image""\n        sagemaker_container = _SageMakerContainer(\n            ""local"", instance_count, image, sagemaker_session=sagemaker_session\n        )\n\n        output_path = str(tmpdir.mkdir(""customer_intermediate_output""))\n        output_data_config = {""S3OutputPath"": ""file://%s"" % output_path}\n        hyperparameters = {""sagemaker_s3_output"": output_path}\n\n        sagemaker_container.train(\n            INPUT_DATA_CONFIG, output_data_config, hyperparameters, TRAINING_JOB_NAME\n        )\n\n        docker_compose_file = os.path.join(\n            sagemaker_container.container_root, ""docker-compose.yaml""\n        )\n        intermediate_folder_path = os.path.join(output_path, ""output/intermediate"")\n\n        with open(docker_compose_file, ""r"") as f:\n            config = yaml.load(f)\n            assert len(config[""services""]) == instance_count\n            for h in sagemaker_container.hosts:\n                assert config[""services""][h][""image""] == image\n                assert config[""services""][h][""command""] == ""train""\n                volumes = config[""services""][h][""volumes""]\n                assert ""%s:/opt/ml/output/intermediate"" % intermediate_folder_path in volumes\n\n\ndef test_container_has_gpu_support(tmpdir, sagemaker_session):\n    instance_count = 1\n    image = ""my-image""\n    sagemaker_container = _SageMakerContainer(\n        ""local_gpu"", instance_count, image, sagemaker_session=sagemaker_session\n    )\n\n    docker_host = sagemaker_container._create_docker_host(""host-1"", {}, set(), ""train"", [])\n    assert ""runtime"" in docker_host\n    assert docker_host[""runtime""] == ""nvidia""\n\n\ndef test_container_does_not_enable_nvidia_docker_for_cpu_containers(sagemaker_session):\n    instance_count = 1\n    image = ""my-image""\n    sagemaker_container = _SageMakerContainer(\n        ""local"", instance_count, image, sagemaker_session=sagemaker_session\n    )\n\n    docker_host = sagemaker_container._create_docker_host(""host-1"", {}, set(), ""train"", [])\n    assert ""runtime"" not in docker_host\n\n\n@patch(""sagemaker.local.image._HostingContainer.run"", Mock())\n@patch(""sagemaker.local.image._SageMakerContainer._prepare_serving_volumes"", Mock(return_value=[]))\n@patch(""shutil.copy"", Mock())\n@patch(""shutil.copytree"", Mock())\ndef test_serve(tmpdir, sagemaker_session):\n    with patch(\n        ""sagemaker.local.image._SageMakerContainer._create_tmp_folder"",\n        return_value=str(tmpdir.mkdir(""container-root"")),\n    ):\n        image = ""my-image""\n        sagemaker_container = _SageMakerContainer(\n            ""local"", 1, image, sagemaker_session=sagemaker_session\n        )\n        environment = {""env1"": 1, ""env2"": ""b"", ""SAGEMAKER_SUBMIT_DIRECTORY"": ""s3://some/path""}\n\n        sagemaker_container.serve(""/some/model/path"", environment)\n        docker_compose_file = os.path.join(\n            sagemaker_container.container_root, ""docker-compose.yaml""\n        )\n\n        with open(docker_compose_file, ""r"") as f:\n            config = yaml.load(f)\n\n            for h in sagemaker_container.hosts:\n                assert config[""services""][h][""image""] == image\n                assert config[""services""][h][""command""] == ""serve""\n\n\n@patch(""sagemaker.local.image._HostingContainer.run"", Mock())\n@patch(""sagemaker.local.image._SageMakerContainer._prepare_serving_volumes"", Mock(return_value=[]))\n@patch(""shutil.copy"", Mock())\n@patch(""shutil.copytree"", Mock())\ndef test_serve_local_code(tmpdir, sagemaker_session):\n    with patch(\n        ""sagemaker.local.image._SageMakerContainer._create_tmp_folder"",\n        return_value=str(tmpdir.mkdir(""container-root"")),\n    ):\n        image = ""my-image""\n        sagemaker_container = _SageMakerContainer(\n            ""local"", 1, image, sagemaker_session=sagemaker_session\n        )\n        environment = {""env1"": 1, ""env2"": ""b"", ""SAGEMAKER_SUBMIT_DIRECTORY"": ""file:///tmp/code""}\n\n        sagemaker_container.serve(""/some/model/path"", environment)\n        docker_compose_file = os.path.join(\n            sagemaker_container.container_root, ""docker-compose.yaml""\n        )\n\n        with open(docker_compose_file, ""r"") as f:\n            config = yaml.load(f)\n\n            for h in sagemaker_container.hosts:\n                assert config[""services""][h][""image""] == image\n                assert config[""services""][h][""command""] == ""serve""\n\n                volumes = config[""services""][h][""volumes""]\n                assert ""%s:/opt/ml/code"" % ""/tmp/code"" in volumes\n                assert (\n                    ""SAGEMAKER_SUBMIT_DIRECTORY=/opt/ml/code""\n                    in config[""services""][h][""environment""]\n                )\n\n\n@patch(""sagemaker.local.image._HostingContainer.run"", Mock())\n@patch(""sagemaker.local.image._SageMakerContainer._prepare_serving_volumes"", Mock(return_value=[]))\n@patch(""shutil.copy"", Mock())\n@patch(""shutil.copytree"", Mock())\ndef test_serve_local_code_no_env(tmpdir, sagemaker_session):\n    with patch(\n        ""sagemaker.local.image._SageMakerContainer._create_tmp_folder"",\n        return_value=str(tmpdir.mkdir(""container-root"")),\n    ):\n        image = ""my-image""\n        sagemaker_container = _SageMakerContainer(\n            ""local"", 1, image, sagemaker_session=sagemaker_session\n        )\n        sagemaker_container.serve(""/some/model/path"", {})\n        docker_compose_file = os.path.join(\n            sagemaker_container.container_root, ""docker-compose.yaml""\n        )\n\n        with open(docker_compose_file, ""r"") as f:\n            config = yaml.load(f)\n\n            for h in sagemaker_container.hosts:\n                assert config[""services""][h][""image""] == image\n                assert config[""services""][h][""command""] == ""serve""\n\n\n@patch(""sagemaker.local.data.get_data_source_instance"")\n@patch(""tarfile.is_tarfile"")\n@patch(""tarfile.open"", MagicMock())\n@patch(""os.makedirs"", Mock())\ndef test_prepare_serving_volumes_with_s3_model(\n    is_tarfile, get_data_source_instance, sagemaker_session\n):\n    sagemaker_container = _SageMakerContainer(\n        ""local"", 1, ""some-image"", sagemaker_session=sagemaker_session\n    )\n    sagemaker_container.container_root = ""/tmp/container_root""\n\n    s3_data_source = Mock()\n    s3_data_source.get_root_dir.return_value = ""/tmp/downloaded/data/""\n    s3_data_source.get_file_list.return_value = [""/tmp/downloaded/data/my_model.tar.gz""]\n    get_data_source_instance.return_value = s3_data_source\n    is_tarfile.return_value = True\n\n    volumes = sagemaker_container._prepare_serving_volumes(""s3://bucket/my_model.tar.gz"")\n    is_tarfile.assert_called_with(""/tmp/downloaded/data/my_model.tar.gz"")\n\n    assert len(volumes) == 1\n    assert volumes[0].container_dir == ""/opt/ml/model""\n    assert volumes[0].host_dir == ""/tmp/downloaded/data/""\n\n\n@patch(""sagemaker.local.data.get_data_source_instance"")\n@patch(""tarfile.is_tarfile"", Mock(return_value=False))\n@patch(""os.makedirs"", Mock())\ndef test_prepare_serving_volumes_with_local_model(get_data_source_instance, sagemaker_session):\n    sagemaker_container = _SageMakerContainer(\n        ""local"", 1, ""some-image"", sagemaker_session=sagemaker_session\n    )\n    sagemaker_container.container_root = ""/tmp/container_root""\n\n    local_file_data_source = Mock()\n    local_file_data_source.get_root_dir.return_value = ""/path/to/my_model""\n    local_file_data_source.get_file_list.return_value = [""/path/to/my_model/model""]\n    get_data_source_instance.return_value = local_file_data_source\n\n    volumes = sagemaker_container._prepare_serving_volumes(""file:///path/to/my_model"")\n\n    assert len(volumes) == 1\n    assert volumes[0].container_dir == ""/opt/ml/model""\n    assert volumes[0].host_dir == ""/path/to/my_model""\n\n\ndef test_ecr_login_non_ecr():\n    session_mock = Mock()\n    result = sagemaker.local.image._ecr_login_if_needed(session_mock, ""ubuntu"")\n\n    session_mock.assert_not_called()\n    assert result is False\n\n\n@patch(""sagemaker.local.image._check_output"", return_value=""123451324"")\n@pytest.mark.parametrize(\n    ""image"",\n    [\n        ""520713654638.dkr.ecr.us-east-1.amazonaws.com/image-i-have:1.0"",\n        ""520713654638.dkr.ecr.us-iso-east-1.c2s.ic.gov/image-i-have:1.0"",\n    ],\n)\ndef test_ecr_login_image_exists(_check_output, image):\n    session_mock = Mock()\n\n    result = sagemaker.local.image._ecr_login_if_needed(session_mock, image)\n\n    session_mock.assert_not_called()\n    _check_output.assert_called()\n    assert result is False\n\n\n@patch(""subprocess.check_output"", return_value="""".encode(""utf-8""))\ndef test_ecr_login_needed(check_output):\n    session_mock = Mock()\n\n    token = ""very-secure-token""\n    token_response = ""AWS:%s"" % token\n    b64_token = base64.b64encode(token_response.encode(""utf-8""))\n    response = {\n        u""authorizationData"": [\n            {\n                u""authorizationToken"": b64_token,\n                u""proxyEndpoint"": u""https://520713654638.dkr.ecr.us-east-1.amazonaws.com"",\n            }\n        ],\n        ""ResponseMetadata"": {\n            ""RetryAttempts"": 0,\n            ""HTTPStatusCode"": 200,\n            ""RequestId"": ""25b2ac63-36bf-11e8-ab6a-e5dc597d2ad9"",\n        },\n    }\n    session_mock.client(""ecr"").get_authorization_token.return_value = response\n    image = ""520713654638.dkr.ecr.us-east-1.amazonaws.com/image-i-need:1.1""\n    result = sagemaker.local.image._ecr_login_if_needed(session_mock, image)\n\n    expected_command = (\n        ""docker login -u AWS -p %s https://520713654638.dkr.ecr.us-east-1.amazonaws.com"" % token\n    )\n\n    check_output.assert_called_with(expected_command, shell=True)\n    session_mock.client(""ecr"").get_authorization_token.assert_called_with(\n        registryIds=[""520713654638""]\n    )\n\n    assert result is True\n\n\n@patch(""subprocess.check_output"", return_value="""".encode(""utf-8""))\ndef test_pull_image(check_output):\n    image = ""520713654638.dkr.ecr.us-east-1.amazonaws.com/image-i-need:1.1""\n\n    sagemaker.local.image._pull_image(image)\n\n    expected_command = ""docker pull %s"" % image\n\n    check_output.assert_called_once_with(expected_command, shell=True)\n\n\ndef test__aws_credentials_with_long_lived_credentials():\n    credentials = Credentials(access_key=_random_string(), secret_key=_random_string(), token=None)\n    session = Mock()\n    session.get_credentials.return_value = credentials\n\n    aws_credentials = _aws_credentials(session)\n\n    assert aws_credentials == [\n        ""AWS_ACCESS_KEY_ID=%s"" % credentials.access_key,\n        ""AWS_SECRET_ACCESS_KEY=%s"" % credentials.secret_key,\n    ]\n\n\n@patch(""sagemaker.local.image._aws_credentials_available_in_metadata_service"")\ndef test__aws_credentials_with_short_lived_credentials_and_ec2_metadata_service_having_credentials(\n    mock\n):\n    credentials = Credentials(\n        access_key=_random_string(), secret_key=_random_string(), token=_random_string()\n    )\n    session = Mock()\n    session.get_credentials.return_value = credentials\n    mock.return_value = True\n    aws_credentials = _aws_credentials(session)\n\n    assert aws_credentials is None\n\n\n@patch(""sagemaker.local.image._aws_credentials_available_in_metadata_service"")\ndef test__aws_credentials_with_short_lived_credentials_and_ec2_metadata_service_having_no_credentials(\n    mock\n):\n    credentials = Credentials(\n        access_key=_random_string(), secret_key=_random_string(), token=_random_string()\n    )\n    session = Mock()\n    session.get_credentials.return_value = credentials\n    mock.return_value = False\n    aws_credentials = _aws_credentials(session)\n\n    assert aws_credentials == [\n        ""AWS_ACCESS_KEY_ID=%s"" % credentials.access_key,\n        ""AWS_SECRET_ACCESS_KEY=%s"" % credentials.secret_key,\n        ""AWS_SESSION_TOKEN=%s"" % credentials.token,\n    ]\n\n\ndef _random_string(size=6, chars=string.ascii_uppercase):\n    return """".join(random.choice(chars) for x in range(size))\n'"
tests/unit/test_init.py,0,"b'# Copyright 2018-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport sagemaker\n\n\ndef test_version():\n    assert sagemaker.__version__\n'"
tests/unit/test_inputs.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport pytest\n\nfrom sagemaker import s3_input\nfrom sagemaker.inputs import FileSystemInput\n\n\ndef test_s3_input_all_defaults(caplog):\n    prefix = ""pre""\n    actual = s3_input(s3_data=prefix)\n    expected = {\n        ""DataSource"": {\n            ""S3DataSource"": {\n                ""S3DataDistributionType"": ""FullyReplicated"",\n                ""S3DataType"": ""S3Prefix"",\n                ""S3Uri"": prefix,\n            }\n        }\n    }\n    assert actual.config == expected\n\n    warning_message = (\n        ""\'s3_input\' class will be renamed to \'TrainingInput\' in SageMaker Python SDK v2.""\n    )\n    assert warning_message in caplog.text\n\n\ndef test_s3_input_all_arguments():\n    prefix = ""pre""\n    distribution = ""FullyReplicated""\n    compression = ""Gzip""\n    content_type = ""text/csv""\n    record_wrapping = ""RecordIO""\n    s3_data_type = ""Manifestfile""\n    input_mode = ""Pipe""\n    result = s3_input(\n        s3_data=prefix,\n        distribution=distribution,\n        compression=compression,\n        input_mode=input_mode,\n        content_type=content_type,\n        record_wrapping=record_wrapping,\n        s3_data_type=s3_data_type,\n    )\n    expected = {\n        ""DataSource"": {\n            ""S3DataSource"": {\n                ""S3DataDistributionType"": distribution,\n                ""S3DataType"": s3_data_type,\n                ""S3Uri"": prefix,\n            }\n        },\n        ""CompressionType"": compression,\n        ""ContentType"": content_type,\n        ""RecordWrapperType"": record_wrapping,\n        ""InputMode"": input_mode,\n    }\n\n    assert result.config == expected\n\n\ndef test_file_system_input_default_access_mode():\n    file_system_id = ""fs-0a48d2a1""\n    file_system_type = ""EFS""\n    directory_path = ""tensorflow""\n    actual = FileSystemInput(\n        file_system_id=file_system_id,\n        file_system_type=file_system_type,\n        directory_path=directory_path,\n    )\n    expected = {\n        ""DataSource"": {\n            ""FileSystemDataSource"": {\n                ""FileSystemId"": file_system_id,\n                ""FileSystemType"": file_system_type,\n                ""DirectoryPath"": directory_path,\n                ""FileSystemAccessMode"": ""ro"",\n            }\n        }\n    }\n    assert actual.config == expected\n\n\ndef test_file_system_input_all_arguments():\n    file_system_id = ""fs-0a48d2a1""\n    file_system_type = ""FSxLustre""\n    directory_path = ""tensorflow""\n    file_system_access_mode = ""rw""\n    actual = FileSystemInput(\n        file_system_id=file_system_id,\n        file_system_type=file_system_type,\n        directory_path=directory_path,\n        file_system_access_mode=file_system_access_mode,\n    )\n    expected = {\n        ""DataSource"": {\n            ""FileSystemDataSource"": {\n                ""FileSystemId"": file_system_id,\n                ""FileSystemType"": file_system_type,\n                ""DirectoryPath"": directory_path,\n                ""FileSystemAccessMode"": ""rw"",\n            }\n        }\n    }\n    assert actual.config == expected\n\n\ndef test_file_system_input_content_type():\n    file_system_id = ""fs-0a48d2a1""\n    file_system_type = ""FSxLustre""\n    directory_path = ""tensorflow""\n    file_system_access_mode = ""rw""\n    content_type = ""application/json""\n    actual = FileSystemInput(\n        file_system_id=file_system_id,\n        file_system_type=file_system_type,\n        directory_path=directory_path,\n        file_system_access_mode=file_system_access_mode,\n        content_type=content_type,\n    )\n    expected = {\n        ""DataSource"": {\n            ""FileSystemDataSource"": {\n                ""FileSystemId"": file_system_id,\n                ""FileSystemType"": file_system_type,\n                ""DirectoryPath"": directory_path,\n                ""FileSystemAccessMode"": ""rw"",\n            }\n        },\n        ""ContentType"": content_type,\n    }\n    assert actual.config == expected\n\n\ndef test_file_system_input_type_invalid():\n    with pytest.raises(ValueError) as excinfo:\n        file_system_id = ""fs-0a48d2a1""\n        file_system_type = ""ABC""\n        directory_path = ""tensorflow""\n        FileSystemInput(\n            file_system_id=file_system_id,\n            file_system_type=file_system_type,\n            directory_path=directory_path,\n        )\n    assert str(excinfo.value) == ""Unrecognized file system type: ABC. Valid values: FSxLustre, EFS.""\n\n\ndef test_file_system_input_mode_invalid():\n    with pytest.raises(ValueError) as excinfo:\n        file_system_id = ""fs-0a48d2a1""\n        file_system_type = ""EFS""\n        directory_path = ""tensorflow""\n        file_system_access_mode = ""p""\n        FileSystemInput(\n            file_system_id=file_system_id,\n            file_system_type=file_system_type,\n            directory_path=directory_path,\n            file_system_access_mode=file_system_access_mode,\n        )\n    assert str(excinfo.value) == ""Unrecognized file system access mode: p. Valid values: ro, rw.""\n'"
tests/unit/test_ipinsights.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport pytest\nfrom mock import Mock, patch\n\nfrom sagemaker.amazon.ipinsights import IPInsights, IPInsightsPredictor\nfrom sagemaker.amazon.amazon_estimator import registry, RecordSet\n\n# Mocked training config\nROLE = ""myrole""\nTRAIN_INSTANCE_COUNT = 1\nTRAIN_INSTANCE_TYPE = ""ml.c4.xlarge""\n\n# Required algorithm hyperparameters\nNUM_ENTITY_VECTORS = 10000\nVECTOR_DIM = 128\n\nCOMMON_TRAIN_ARGS = {\n    ""role"": ROLE,\n    ""train_instance_count"": TRAIN_INSTANCE_COUNT,\n    ""train_instance_type"": TRAIN_INSTANCE_TYPE,\n}\nALL_REQ_ARGS = dict(\n    {""num_entity_vectors"": NUM_ENTITY_VECTORS, ""vector_dim"": VECTOR_DIM}, **COMMON_TRAIN_ARGS\n)\nREGION = ""us-west-2""\nBUCKET_NAME = ""Some-Bucket""\n\nDESCRIBE_TRAINING_JOB_RESULT = {""ModelArtifacts"": {""S3ModelArtifacts"": ""s3://bucket/model.tar.gz""}}\n\nENDPOINT_DESC = {""EndpointConfigName"": ""test-endpoint""}\n\nENDPOINT_CONFIG_DESC = {""ProductionVariants"": [{""ModelName"": ""model-1""}, {""ModelName"": ""model-2""}]}\n\n\n@pytest.fixture()\ndef sagemaker_session():\n    boto_mock = Mock(name=""boto_session"", region_name=REGION)\n    sms = Mock(\n        name=""sagemaker_session"",\n        boto_session=boto_mock,\n        region_name=REGION,\n        config=None,\n        local_mode=False,\n    )\n    sms.boto_region_name = REGION\n    sms.default_bucket = Mock(name=""default_bucket"", return_value=BUCKET_NAME)\n    sms.sagemaker_client.describe_training_job = Mock(\n        name=""describe_training_job"", return_value=DESCRIBE_TRAINING_JOB_RESULT\n    )\n    sms.sagemaker_client.describe_endpoint = Mock(return_value=ENDPOINT_DESC)\n    sms.sagemaker_client.describe_endpoint_config = Mock(return_value=ENDPOINT_CONFIG_DESC)\n\n    return sms\n\n\ndef test_init_required_positional(sagemaker_session):\n    ipinsights = IPInsights(\n        ROLE,\n        TRAIN_INSTANCE_COUNT,\n        TRAIN_INSTANCE_TYPE,\n        NUM_ENTITY_VECTORS,\n        VECTOR_DIM,\n        sagemaker_session=sagemaker_session,\n    )\n    assert ipinsights.role == ROLE\n    assert ipinsights.train_instance_count == TRAIN_INSTANCE_COUNT\n    assert ipinsights.train_instance_type == TRAIN_INSTANCE_TYPE\n    assert ipinsights.num_entity_vectors == NUM_ENTITY_VECTORS\n    assert ipinsights.vector_dim == VECTOR_DIM\n\n\ndef test_init_required_named(sagemaker_session):\n    ipinsights = IPInsights(sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n\n    assert ipinsights.role == COMMON_TRAIN_ARGS[""role""]\n    assert ipinsights.train_instance_count == TRAIN_INSTANCE_COUNT\n    assert ipinsights.train_instance_type == COMMON_TRAIN_ARGS[""train_instance_type""]\n    assert ipinsights.num_entity_vectors == NUM_ENTITY_VECTORS\n    assert ipinsights.vector_dim == VECTOR_DIM\n\n\ndef test_all_hyperparameters(sagemaker_session):\n    ipinsights = IPInsights(\n        sagemaker_session=sagemaker_session,\n        batch_metrics_publish_interval=100,\n        epochs=10,\n        learning_rate=0.001,\n        num_ip_encoder_layers=3,\n        random_negative_sampling_rate=5,\n        shuffled_negative_sampling_rate=5,\n        weight_decay=5.0,\n        **ALL_REQ_ARGS\n    )\n    assert ipinsights.hyperparameters() == dict(\n        num_entity_vectors=str(ALL_REQ_ARGS[""num_entity_vectors""]),\n        vector_dim=str(ALL_REQ_ARGS[""vector_dim""]),\n        batch_metrics_publish_interval=""100"",\n        epochs=""10"",\n        learning_rate=""0.001"",\n        num_ip_encoder_layers=""3"",\n        random_negative_sampling_rate=""5"",\n        shuffled_negative_sampling_rate=""5"",\n        weight_decay=""5.0"",\n    )\n\n\ndef test_image(sagemaker_session):\n    ipinsights = IPInsights(sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n    assert ipinsights.train_image() == registry(REGION, ""ipinsights"") + ""/ipinsights:1""\n\n\n@pytest.mark.parametrize(\n    ""required_hyper_parameters, value"", [(""num_entity_vectors"", ""string""), (""vector_dim"", ""string"")]\n)\ndef test_required_hyper_parameters_type(sagemaker_session, required_hyper_parameters, value):\n    with pytest.raises(ValueError):\n        test_params = ALL_REQ_ARGS.copy()\n        test_params[required_hyper_parameters] = value\n        IPInsights(sagemaker_session=sagemaker_session, **test_params)\n\n\n@pytest.mark.parametrize(\n    ""required_hyper_parameters, value"",\n    [\n        (""num_entity_vectors"", 0),\n        (""num_entity_vectors"", 500000001),\n        (""vector_dim"", 3),\n        (""vector_dim"", 4097),\n    ],\n)\ndef test_required_hyper_parameters_value(sagemaker_session, required_hyper_parameters, value):\n    with pytest.raises(ValueError):\n        test_params = ALL_REQ_ARGS.copy()\n        test_params[required_hyper_parameters] = value\n        IPInsights(sagemaker_session=sagemaker_session, **test_params)\n\n\n@pytest.mark.parametrize(\n    ""optional_hyper_parameters, value"",\n    [\n        (""batch_metrics_publish_interval"", ""string""),\n        (""epochs"", ""string""),\n        (""learning_rate"", ""string""),\n        (""num_ip_encoder_layers"", ""string""),\n        (""random_negative_sampling_rate"", ""string""),\n        (""shuffled_negative_sampling_rate"", ""string""),\n        (""weight_decay"", ""string""),\n    ],\n)\ndef test_optional_hyper_parameters_type(sagemaker_session, optional_hyper_parameters, value):\n    with pytest.raises(ValueError):\n        test_params = ALL_REQ_ARGS.copy()\n        test_params.update({optional_hyper_parameters: value})\n        IPInsights(sagemaker_session=sagemaker_session, **test_params)\n\n\n@pytest.mark.parametrize(\n    ""optional_hyper_parameters, value"",\n    [\n        (""batch_metrics_publish_interval"", 0),\n        (""epochs"", 0),\n        (""learning_rate"", 0),\n        (""learning_rate"", 11),\n        (""num_ip_encoder_layers"", -1),\n        (""num_ip_encoder_layers"", 101),\n        (""random_negative_sampling_rate"", -1),\n        (""random_negative_sampling_rate"", 501),\n        (""shuffled_negative_sampling_rate"", -1),\n        (""shuffled_negative_sampling_rate"", 501),\n        (""weight_decay"", -1),\n        (""weight_decay"", 11),\n    ],\n)\ndef test_optional_hyper_parameters_value(sagemaker_session, optional_hyper_parameters, value):\n    with pytest.raises(ValueError):\n        test_params = ALL_REQ_ARGS.copy()\n        test_params.update({optional_hyper_parameters: value})\n        IPInsights(sagemaker_session=sagemaker_session, **test_params)\n\n\nPREFIX = ""prefix""\nFEATURE_DIM = None\nMINI_BATCH_SIZE = 200\n\n\n@patch(""sagemaker.amazon.amazon_estimator.AmazonAlgorithmEstimatorBase.fit"")\ndef test_call_fit(base_fit, sagemaker_session):\n    ipinsights = IPInsights(\n        base_job_name=""ipinsights"", sagemaker_session=sagemaker_session, **ALL_REQ_ARGS\n    )\n\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n\n    ipinsights.fit(data, MINI_BATCH_SIZE)\n\n    base_fit.assert_called_once()\n    assert len(base_fit.call_args[0]) == 2\n    assert base_fit.call_args[0][0] == data\n    assert base_fit.call_args[0][1] == MINI_BATCH_SIZE\n\n\ndef test_call_fit_none_mini_batch_size(sagemaker_session):\n    ipinsights = IPInsights(\n        base_job_name=""ipinsights"", sagemaker_session=sagemaker_session, **ALL_REQ_ARGS\n    )\n\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n    ipinsights.fit(data)\n\n\ndef test_prepare_for_training_wrong_type_mini_batch_size(sagemaker_session):\n    ipinsights = IPInsights(\n        base_job_name=""ipinsights"", sagemaker_session=sagemaker_session, **ALL_REQ_ARGS\n    )\n\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n\n    with pytest.raises((TypeError, ValueError)):\n        ipinsights._prepare_for_training(data, ""some"")\n\n\ndef test_prepare_for_training_wrong_value_lower_mini_batch_size(sagemaker_session):\n    ipinsights = IPInsights(\n        base_job_name=""ipinsights"", sagemaker_session=sagemaker_session, **ALL_REQ_ARGS\n    )\n\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n    with pytest.raises(ValueError):\n        ipinsights._prepare_for_training(data, 0)\n\n\ndef test_prepare_for_training_wrong_value_upper_mini_batch_size(sagemaker_session):\n    ipinsights = IPInsights(\n        base_job_name=""ipinsights"", sagemaker_session=sagemaker_session, **ALL_REQ_ARGS\n    )\n\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n    with pytest.raises(ValueError):\n        ipinsights._prepare_for_training(data, 500001)\n\n\ndef test_model_image(sagemaker_session):\n    ipinsights = IPInsights(sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n    ipinsights.fit(data, MINI_BATCH_SIZE)\n\n    model = ipinsights.create_model()\n    assert model.image == registry(REGION, ""ipinsights"") + ""/ipinsights:1""\n\n\ndef test_predictor_type(sagemaker_session):\n    ipinsights = IPInsights(sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n    ipinsights.fit(data, MINI_BATCH_SIZE)\n    model = ipinsights.create_model()\n    predictor = model.deploy(1, TRAIN_INSTANCE_TYPE)\n\n    assert isinstance(predictor, IPInsightsPredictor)\n'"
tests/unit/test_job.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport pytest\nimport os\nfrom mock import Mock\n\nfrom sagemaker.amazon.amazon_estimator import RecordSet, FileSystemRecordSet\nfrom sagemaker.estimator import Estimator, Framework\nfrom sagemaker.inputs import FileSystemInput\nfrom sagemaker.job import _Job\nfrom sagemaker.model import FrameworkModel\nfrom sagemaker.session import s3_input\n\nBUCKET_NAME = ""s3://mybucket/train""\nS3_OUTPUT_PATH = ""s3://bucket/prefix""\nLOCAL_FILE_NAME = ""file://local/file""\nINSTANCE_COUNT = 1\nINSTANCE_TYPE = ""c4.4xlarge""\nVOLUME_SIZE = 1\nMAX_RUNTIME = 1\nROLE = ""DummyRole""\nREGION = ""us-west-2""\nIMAGE_NAME = ""fakeimage""\nSCRIPT_NAME = ""script.py""\nJOB_NAME = ""fakejob""\nVOLUME_KMS_KEY = ""volkmskey""\nMODEL_CHANNEL_NAME = ""testModelChannel""\nMODEL_URI = ""s3://bucket/prefix/model.tar.gz""\nLOCAL_MODEL_NAME = ""file://local/file.tar.gz""\nCODE_CHANNEL_NAME = ""testCodeChannel""\nCODE_URI = ""s3://bucket/prefix/code.py""\nDATA_DIR = os.path.join(os.path.dirname(__file__), "".."", ""data"")\nSCRIPT_PATH = os.path.join(DATA_DIR, SCRIPT_NAME)\nMODEL_CONTAINER_DEF = {\n    ""Environment"": {\n        ""SAGEMAKER_PROGRAM"": SCRIPT_NAME,\n        ""SAGEMAKER_SUBMIT_DIRECTORY"": ""s3://mybucket/mi-2017-10-10-14-14-15/sourcedir.tar.gz"",\n        ""SAGEMAKER_CONTAINER_LOG_LEVEL"": ""20"",\n        ""SAGEMAKER_REGION"": REGION,\n        ""SAGEMAKER_ENABLE_CLOUDWATCH_METRICS"": ""false"",\n    },\n    ""Image"": IMAGE_NAME,\n    ""ModelDataUrl"": MODEL_URI,\n}\n\n\n@pytest.fixture()\ndef estimator(sagemaker_session):\n    return Estimator(\n        IMAGE_NAME,\n        ROLE,\n        INSTANCE_COUNT,\n        INSTANCE_TYPE,\n        train_volume_size=VOLUME_SIZE,\n        train_max_run=MAX_RUNTIME,\n        output_path=S3_OUTPUT_PATH,\n        sagemaker_session=sagemaker_session,\n    )\n\n\n@pytest.fixture()\ndef sagemaker_session():\n    boto_mock = Mock(name=""boto_session"")\n    mock_session = Mock(\n        name=""sagemaker_session"", boto_session=boto_mock, s3_client=None, s3_resource=None\n    )\n    mock_session.expand_role = Mock(name=""expand_role"", return_value=ROLE)\n\n    return mock_session\n\n\nclass DummyFramework(Framework):\n    __framework_name__ = ""dummy""\n\n    def train_image(self):\n        return IMAGE_NAME\n\n    def create_model(self, role=None, model_server_workers=None):\n        return DummyFrameworkModel(self.sagemaker_session, vpc_config=self.get_vpc_config())\n\n    @classmethod\n    def _prepare_init_params_from_job_description(cls, job_details, model_channel_name=None):\n        init_params = super(DummyFramework, cls)._prepare_init_params_from_job_description(\n            job_details, model_channel_name\n        )\n        init_params.pop(""image"", None)\n        return init_params\n\n\nclass DummyFrameworkModel(FrameworkModel):\n    def __init__(self, sagemaker_session, **kwargs):\n        super(DummyFrameworkModel, self).__init__(\n            MODEL_URI,\n            IMAGE_NAME,\n            INSTANCE_TYPE,\n            ROLE,\n            SCRIPT_NAME,\n            sagemaker_session=sagemaker_session,\n            **kwargs\n        )\n\n    def prepare_container_def(self, instance_type, accelerator_type=None):\n        return MODEL_CONTAINER_DEF\n\n\n@pytest.fixture()\ndef framework(sagemaker_session):\n    return DummyFramework(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        output_path=S3_OUTPUT_PATH,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n    )\n\n\ndef test_load_config(estimator):\n    inputs = s3_input(BUCKET_NAME)\n\n    config = _Job._load_config(inputs, estimator)\n\n    assert config[""input_config""][0][""DataSource""][""S3DataSource""][""S3Uri""] == BUCKET_NAME\n    assert config[""role""] == ROLE\n    assert config[""output_config""][""S3OutputPath""] == S3_OUTPUT_PATH\n    assert ""KmsKeyId"" not in config[""output_config""]\n    assert config[""resource_config""][""InstanceCount""] == INSTANCE_COUNT\n    assert config[""resource_config""][""InstanceType""] == INSTANCE_TYPE\n    assert config[""resource_config""][""VolumeSizeInGB""] == VOLUME_SIZE\n    assert config[""stop_condition""][""MaxRuntimeInSeconds""] == MAX_RUNTIME\n\n\ndef test_load_config_with_model_channel(estimator):\n    inputs = s3_input(BUCKET_NAME)\n\n    estimator.model_uri = MODEL_URI\n    estimator.model_channel_name = MODEL_CHANNEL_NAME\n\n    config = _Job._load_config(inputs, estimator)\n\n    assert config[""input_config""][0][""DataSource""][""S3DataSource""][""S3Uri""] == BUCKET_NAME\n    assert config[""input_config""][1][""DataSource""][""S3DataSource""][""S3Uri""] == MODEL_URI\n    assert config[""input_config""][1][""ChannelName""] == MODEL_CHANNEL_NAME\n    assert config[""role""] == ROLE\n    assert config[""output_config""][""S3OutputPath""] == S3_OUTPUT_PATH\n    assert ""KmsKeyId"" not in config[""output_config""]\n    assert config[""resource_config""][""InstanceCount""] == INSTANCE_COUNT\n    assert config[""resource_config""][""InstanceType""] == INSTANCE_TYPE\n    assert config[""resource_config""][""VolumeSizeInGB""] == VOLUME_SIZE\n    assert config[""stop_condition""][""MaxRuntimeInSeconds""] == MAX_RUNTIME\n\n\ndef test_load_config_with_model_channel_no_inputs(estimator):\n    estimator.model_uri = MODEL_URI\n    estimator.model_channel_name = MODEL_CHANNEL_NAME\n\n    config = _Job._load_config(inputs=None, estimator=estimator)\n\n    assert config[""input_config""][0][""DataSource""][""S3DataSource""][""S3Uri""] == MODEL_URI\n    assert config[""input_config""][0][""ChannelName""] == MODEL_CHANNEL_NAME\n    assert config[""role""] == ROLE\n    assert config[""output_config""][""S3OutputPath""] == S3_OUTPUT_PATH\n    assert ""KmsKeyId"" not in config[""output_config""]\n    assert config[""resource_config""][""InstanceCount""] == INSTANCE_COUNT\n    assert config[""resource_config""][""InstanceType""] == INSTANCE_TYPE\n    assert config[""resource_config""][""VolumeSizeInGB""] == VOLUME_SIZE\n    assert config[""stop_condition""][""MaxRuntimeInSeconds""] == MAX_RUNTIME\n\n\ndef test_load_config_with_code_channel(framework):\n    inputs = s3_input(BUCKET_NAME)\n\n    framework.model_uri = MODEL_URI\n    framework.model_channel_name = MODEL_CHANNEL_NAME\n    framework.code_uri = CODE_URI\n    framework._enable_network_isolation = True\n    config = _Job._load_config(inputs, framework)\n\n    assert len(config[""input_config""]) == 3\n    assert config[""input_config""][0][""DataSource""][""S3DataSource""][""S3Uri""] == BUCKET_NAME\n    assert config[""input_config""][2][""DataSource""][""S3DataSource""][""S3Uri""] == CODE_URI\n    assert config[""input_config""][2][""ChannelName""] == framework.code_channel_name\n    assert config[""role""] == ROLE\n    assert config[""output_config""][""S3OutputPath""] == S3_OUTPUT_PATH\n    assert ""KmsKeyId"" not in config[""output_config""]\n    assert config[""resource_config""][""InstanceCount""] == INSTANCE_COUNT\n    assert config[""resource_config""][""InstanceType""] == INSTANCE_TYPE\n\n\ndef test_load_config_with_code_channel_no_code_uri(framework):\n    inputs = s3_input(BUCKET_NAME)\n\n    framework.model_uri = MODEL_URI\n    framework.model_channel_name = MODEL_CHANNEL_NAME\n    framework._enable_network_isolation = True\n    config = _Job._load_config(inputs, framework)\n\n    assert len(config[""input_config""]) == 2\n    assert config[""input_config""][0][""DataSource""][""S3DataSource""][""S3Uri""] == BUCKET_NAME\n    assert config[""role""] == ROLE\n    assert config[""output_config""][""S3OutputPath""] == S3_OUTPUT_PATH\n    assert ""KmsKeyId"" not in config[""output_config""]\n    assert config[""resource_config""][""InstanceCount""] == INSTANCE_COUNT\n    assert config[""resource_config""][""InstanceType""] == INSTANCE_TYPE\n\n\ndef test_format_inputs_none():\n    channels = _Job._format_inputs_to_input_config(inputs=None)\n\n    assert channels is None\n\n\ndef test_format_inputs_to_input_config_string():\n    inputs = BUCKET_NAME\n\n    channels = _Job._format_inputs_to_input_config(inputs)\n\n    assert channels[0][""DataSource""][""S3DataSource""][""S3Uri""] == inputs\n\n\ndef test_format_inputs_to_input_config_s3_input():\n    inputs = s3_input(BUCKET_NAME)\n\n    channels = _Job._format_inputs_to_input_config(inputs)\n\n    assert (\n        channels[0][""DataSource""][""S3DataSource""][""S3Uri""]\n        == inputs.config[""DataSource""][""S3DataSource""][""S3Uri""]\n    )\n\n\ndef test_format_inputs_to_input_config_dict():\n    inputs = {""train"": BUCKET_NAME}\n\n    channels = _Job._format_inputs_to_input_config(inputs)\n\n    assert channels[0][""DataSource""][""S3DataSource""][""S3Uri""] == inputs[""train""]\n\n\ndef test_format_inputs_to_input_config_record_set():\n    inputs = RecordSet(s3_data=BUCKET_NAME, num_records=1, feature_dim=1)\n\n    channels = _Job._format_inputs_to_input_config(inputs)\n\n    assert channels[0][""DataSource""][""S3DataSource""][""S3Uri""] == inputs.s3_data\n    assert channels[0][""DataSource""][""S3DataSource""][""S3DataType""] == inputs.s3_data_type\n\n\ndef test_format_inputs_to_input_config_file_system_record_set():\n    file_system_id = ""fs-0a48d2a1""\n    file_system_type = ""EFS""\n    directory_path = ""ipinsights""\n    num_records = 1\n    feature_dim = 1\n    records = FileSystemRecordSet(\n        file_system_id=file_system_id,\n        file_system_type=file_system_type,\n        directory_path=directory_path,\n        num_records=num_records,\n        feature_dim=feature_dim,\n    )\n    channels = _Job._format_inputs_to_input_config(records)\n    assert channels[0][""DataSource""][""FileSystemDataSource""][""DirectoryPath""] == directory_path\n    assert channels[0][""DataSource""][""FileSystemDataSource""][""FileSystemId""] == file_system_id\n    assert channels[0][""DataSource""][""FileSystemDataSource""][""FileSystemType""] == file_system_type\n    assert channels[0][""DataSource""][""FileSystemDataSource""][""FileSystemAccessMode""] == ""ro""\n\n\ndef test_format_inputs_to_input_config_list():\n    records = RecordSet(s3_data=BUCKET_NAME, num_records=1, feature_dim=1)\n    inputs = [records]\n\n    channels = _Job._format_inputs_to_input_config(inputs)\n\n    assert channels[0][""DataSource""][""S3DataSource""][""S3Uri""] == records.s3_data\n    assert channels[0][""DataSource""][""S3DataSource""][""S3DataType""] == records.s3_data_type\n\n\ndef test_format_record_set_list_input():\n    records = FileSystemRecordSet(\n        file_system_id=""fs-fd85e556"",\n        file_system_type=""EFS"",\n        directory_path=""ipinsights"",\n        num_records=100,\n        feature_dim=1,\n    )\n    test_records = FileSystemRecordSet(\n        file_system_id=""fs-fd85e556"",\n        file_system_type=""EFS"",\n        directory_path=""ipinsights"",\n        num_records=20,\n        feature_dim=1,\n        channel=""validation"",\n    )\n    inputs = [records, test_records]\n    input_dict = _Job._format_record_set_list_input(inputs)\n    assert isinstance(input_dict[""train""], FileSystemInput)\n    assert isinstance(input_dict[""validation""], FileSystemInput)\n\n\n@pytest.mark.parametrize(\n    ""channel_uri, channel_name, content_type, input_mode"",\n    [\n        [MODEL_URI, MODEL_CHANNEL_NAME, ""application/x-sagemaker-model"", ""File""],\n        [CODE_URI, CODE_CHANNEL_NAME, None, None],\n    ],\n)\ndef test_prepare_channel(channel_uri, channel_name, content_type, input_mode):\n    channel = _Job._prepare_channel(\n        [], channel_uri, channel_name, content_type=content_type, input_mode=input_mode\n    )\n\n    assert channel[""DataSource""][""S3DataSource""][""S3Uri""] == channel_uri\n    assert channel[""DataSource""][""S3DataSource""][""S3DataDistributionType""] == ""FullyReplicated""\n    assert channel[""DataSource""][""S3DataSource""][""S3DataType""] == ""S3Prefix""\n    assert channel[""ChannelName""] == channel_name\n    assert ""CompressionType"" not in channel\n    assert ""RecordWrapperType"" not in channel\n\n    # The model channel should use all the defaults except InputMode and ContentType\n    if channel_name == MODEL_CHANNEL_NAME:\n        assert channel[""ContentType""] == ""application/x-sagemaker-model""\n        assert channel[""InputMode""] == ""File""\n\n\ndef test_prepare_channel_duplicate():\n    channels = [\n        {\n            ""ChannelName"": MODEL_CHANNEL_NAME,\n            ""DataSource"": {\n                ""S3DataSource"": {\n                    ""S3DataDistributionType"": ""FullyReplicated"",\n                    ""S3DataType"": ""S3Prefix"",\n                    ""S3Uri"": ""s3://blah/blah"",\n                }\n            },\n        }\n    ]\n\n    with pytest.raises(ValueError) as error:\n        _Job._prepare_channel(channels, MODEL_URI, MODEL_CHANNEL_NAME)\n\n    assert ""Duplicate channel {} not allowed."".format(MODEL_CHANNEL_NAME) in str(error)\n\n\ndef test_prepare_channel_with_missing_name():\n    with pytest.raises(ValueError) as ex:\n        _Job._prepare_channel([], channel_uri=MODEL_URI, channel_name=None)\n\n    assert ""Expected a channel name if a channel URI {} is specified"".format(MODEL_URI) in str(ex)\n\n\ndef test_prepare_channel_with_missing_uri():\n    assert _Job._prepare_channel([], channel_uri=None, channel_name=None) is None\n\n\ndef test_format_inputs_to_input_config_list_not_all_records():\n    records = RecordSet(s3_data=BUCKET_NAME, num_records=1, feature_dim=1)\n    inputs = [records, ""mock""]\n\n    with pytest.raises(ValueError) as ex:\n        _Job._format_inputs_to_input_config(inputs)\n\n    assert ""List compatible only with RecordSets or FileSystemRecordSets."" in str(ex)\n\n\ndef test_format_inputs_to_input_config_list_duplicate_channel():\n    record = RecordSet(s3_data=BUCKET_NAME, num_records=1, feature_dim=1)\n    inputs = [record, record]\n\n    with pytest.raises(ValueError) as ex:\n        _Job._format_inputs_to_input_config(inputs)\n\n    assert ""Duplicate channels not allowed."" in str(ex)\n\n\ndef test_format_input_single_unamed_channel():\n    input_dict = _Job._format_inputs_to_input_config(""s3://blah/blah"")\n    assert input_dict == [\n        {\n            ""ChannelName"": ""training"",\n            ""DataSource"": {\n                ""S3DataSource"": {\n                    ""S3DataDistributionType"": ""FullyReplicated"",\n                    ""S3DataType"": ""S3Prefix"",\n                    ""S3Uri"": ""s3://blah/blah"",\n                }\n            },\n        }\n    ]\n\n\ndef test_format_input_multiple_channels():\n    input_list = _Job._format_inputs_to_input_config({""a"": ""s3://blah/blah"", ""b"": ""s3://foo/bar""})\n    expected = [\n        {\n            ""ChannelName"": ""a"",\n            ""DataSource"": {\n                ""S3DataSource"": {\n                    ""S3DataDistributionType"": ""FullyReplicated"",\n                    ""S3DataType"": ""S3Prefix"",\n                    ""S3Uri"": ""s3://blah/blah"",\n                }\n            },\n        },\n        {\n            ""ChannelName"": ""b"",\n            ""DataSource"": {\n                ""S3DataSource"": {\n                    ""S3DataDistributionType"": ""FullyReplicated"",\n                    ""S3DataType"": ""S3Prefix"",\n                    ""S3Uri"": ""s3://foo/bar"",\n                }\n            },\n        },\n    ]\n\n    # convert back into map for comparison so list order (which is arbitrary) is ignored\n    assert {c[""ChannelName""]: c for c in input_list} == {c[""ChannelName""]: c for c in expected}\n\n\ndef test_format_input_s3_input():\n    input_dict = _Job._format_inputs_to_input_config(\n        s3_input(\n            ""s3://foo/bar"",\n            distribution=""ShardedByS3Key"",\n            compression=""gzip"",\n            content_type=""whizz"",\n            record_wrapping=""bang"",\n        )\n    )\n    assert input_dict == [\n        {\n            ""CompressionType"": ""gzip"",\n            ""ChannelName"": ""training"",\n            ""ContentType"": ""whizz"",\n            ""DataSource"": {\n                ""S3DataSource"": {\n                    ""S3DataType"": ""S3Prefix"",\n                    ""S3DataDistributionType"": ""ShardedByS3Key"",\n                    ""S3Uri"": ""s3://foo/bar"",\n                }\n            },\n            ""RecordWrapperType"": ""bang"",\n        }\n    ]\n\n\ndef test_dict_of_mixed_input_types():\n    input_list = _Job._format_inputs_to_input_config(\n        {""a"": ""s3://foo/bar"", ""b"": s3_input(""s3://whizz/bang"")}\n    )\n\n    expected = [\n        {\n            ""ChannelName"": ""a"",\n            ""DataSource"": {\n                ""S3DataSource"": {\n                    ""S3DataDistributionType"": ""FullyReplicated"",\n                    ""S3DataType"": ""S3Prefix"",\n                    ""S3Uri"": ""s3://foo/bar"",\n                }\n            },\n        },\n        {\n            ""ChannelName"": ""b"",\n            ""DataSource"": {\n                ""S3DataSource"": {\n                    ""S3DataDistributionType"": ""FullyReplicated"",\n                    ""S3DataType"": ""S3Prefix"",\n                    ""S3Uri"": ""s3://whizz/bang"",\n                }\n            },\n        },\n    ]\n\n    # convert back into map for comparison so list order (which is arbitrary) is ignored\n    assert {c[""ChannelName""]: c for c in input_list} == {c[""ChannelName""]: c for c in expected}\n\n\ndef test_format_inputs_to_input_config_exception():\n    inputs = 1\n\n    with pytest.raises(ValueError):\n        _Job._format_inputs_to_input_config(inputs)\n\n\ndef test_unsupported_type_in_dict():\n    with pytest.raises(ValueError):\n        _Job._format_inputs_to_input_config({""a"": 66})\n\n\ndef test_format_string_uri_input_string():\n    inputs = BUCKET_NAME\n\n    s3_uri_input = _Job._format_string_uri_input(inputs)\n\n    assert s3_uri_input.config[""DataSource""][""S3DataSource""][""S3Uri""] == inputs\n\n\ndef test_format_string_uri_file_system_input():\n    file_system_id = ""fs-fd85e556""\n    file_system_type = ""EFS""\n    directory_path = ""ipinsights""\n\n    file_system_input = FileSystemInput(\n        file_system_id=file_system_id,\n        file_system_type=file_system_type,\n        directory_path=directory_path,\n    )\n\n    uri_input = _Job._format_string_uri_input(file_system_input)\n    assert uri_input == file_system_input\n\n\ndef test_format_string_uri_input_string_exception():\n    inputs = ""mybucket/train""\n\n    with pytest.raises(ValueError):\n        _Job._format_string_uri_input(inputs)\n\n\ndef test_format_string_uri_input_local_file():\n    file_uri_input = _Job._format_string_uri_input(LOCAL_FILE_NAME)\n\n    assert file_uri_input.config[""DataSource""][""FileDataSource""][""FileUri""] == LOCAL_FILE_NAME\n\n\ndef test_format_string_uri_input():\n    inputs = s3_input(BUCKET_NAME)\n\n    s3_uri_input = _Job._format_string_uri_input(inputs)\n\n    assert (\n        s3_uri_input.config[""DataSource""][""S3DataSource""][""S3Uri""]\n        == inputs.config[""DataSource""][""S3DataSource""][""S3Uri""]\n    )\n\n\ndef test_format_string_uri_input_exception():\n    inputs = 1\n\n    with pytest.raises(ValueError):\n        _Job._format_string_uri_input(inputs)\n\n\ndef test_format_model_uri_input_string():\n    model_uri = MODEL_URI\n\n    model_uri_input = _Job._format_model_uri_input(model_uri)\n\n    assert model_uri_input.config[""DataSource""][""S3DataSource""][""S3Uri""] == model_uri\n\n\ndef test_format_model_uri_input_local_file():\n    model_uri_input = _Job._format_model_uri_input(LOCAL_MODEL_NAME)\n\n    assert model_uri_input.config[""DataSource""][""FileDataSource""][""FileUri""] == LOCAL_MODEL_NAME\n\n\ndef test_format_model_uri_input_exception():\n    model_uri = 1\n\n    with pytest.raises(ValueError):\n        _Job._format_model_uri_input(model_uri)\n\n\ndef test_prepare_output_config():\n    kms_key_id = ""kms_key""\n\n    config = _Job._prepare_output_config(BUCKET_NAME, kms_key_id)\n\n    assert config[""S3OutputPath""] == BUCKET_NAME\n    assert config[""KmsKeyId""] == kms_key_id\n\n\ndef test_prepare_output_config_kms_key_none():\n    s3_path = BUCKET_NAME\n    kms_key_id = None\n\n    config = _Job._prepare_output_config(s3_path, kms_key_id)\n\n    assert config[""S3OutputPath""] == s3_path\n    assert ""KmsKeyId"" not in config\n\n\ndef test_prepare_resource_config():\n    resource_config = _Job._prepare_resource_config(\n        INSTANCE_COUNT, INSTANCE_TYPE, VOLUME_SIZE, None\n    )\n\n    assert resource_config == {\n        ""InstanceCount"": INSTANCE_COUNT,\n        ""InstanceType"": INSTANCE_TYPE,\n        ""VolumeSizeInGB"": VOLUME_SIZE,\n    }\n\n\ndef test_prepare_resource_config_with_volume_kms():\n    resource_config = _Job._prepare_resource_config(\n        INSTANCE_COUNT, INSTANCE_TYPE, VOLUME_SIZE, VOLUME_KMS_KEY\n    )\n\n    assert resource_config == {\n        ""InstanceCount"": INSTANCE_COUNT,\n        ""InstanceType"": INSTANCE_TYPE,\n        ""VolumeSizeInGB"": VOLUME_SIZE,\n        ""VolumeKmsKeyId"": VOLUME_KMS_KEY,\n    }\n\n\ndef test_prepare_stop_condition():\n    max_run = 1\n    max_wait = 2\n\n    stop_condition = _Job._prepare_stop_condition(max_run, max_wait)\n\n    assert stop_condition[""MaxRuntimeInSeconds""] == max_run\n    assert stop_condition[""MaxWaitTimeInSeconds""] == max_wait\n\n\ndef test_prepare_stop_condition_no_wait():\n    max_run = 1\n    max_wait = None\n\n    stop_condition = _Job._prepare_stop_condition(max_run, max_wait)\n\n    assert stop_condition[""MaxRuntimeInSeconds""] == max_run\n    assert ""MaxWaitTimeInSeconds"" not in stop_condition\n\n\ndef test_name(sagemaker_session):\n    job = _Job(sagemaker_session, JOB_NAME)\n    assert job.name == JOB_NAME\n'"
tests/unit/test_kmeans.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport pytest\nfrom mock import Mock, patch\n\nfrom sagemaker.amazon.kmeans import KMeans, KMeansPredictor\nfrom sagemaker.amazon.amazon_estimator import registry, RecordSet\n\nROLE = ""myrole""\nTRAIN_INSTANCE_COUNT = 1\nTRAIN_INSTANCE_TYPE = ""ml.c4.xlarge""\nK = 2\n\nCOMMON_TRAIN_ARGS = {\n    ""role"": ROLE,\n    ""train_instance_count"": TRAIN_INSTANCE_COUNT,\n    ""train_instance_type"": TRAIN_INSTANCE_TYPE,\n}\nALL_REQ_ARGS = dict({""k"": K}, **COMMON_TRAIN_ARGS)\n\nREGION = ""us-west-2""\nBUCKET_NAME = ""Some-Bucket""\n\nDESCRIBE_TRAINING_JOB_RESULT = {""ModelArtifacts"": {""S3ModelArtifacts"": ""s3://bucket/model.tar.gz""}}\n\nENDPOINT_DESC = {""EndpointConfigName"": ""test-endpoint""}\n\nENDPOINT_CONFIG_DESC = {""ProductionVariants"": [{""ModelName"": ""model-1""}, {""ModelName"": ""model-2""}]}\n\n\n@pytest.fixture()\ndef sagemaker_session():\n    boto_mock = Mock(name=""boto_session"", region_name=REGION)\n    sms = Mock(\n        name=""sagemaker_session"",\n        boto_session=boto_mock,\n        region_name=REGION,\n        config=None,\n        local_mode=False,\n        s3_client=None,\n        s3_resource=None,\n    )\n    sms.boto_region_name = REGION\n    sms.default_bucket = Mock(name=""default_bucket"", return_value=BUCKET_NAME)\n    sms.sagemaker_client.describe_training_job = Mock(\n        name=""describe_training_job"", return_value=DESCRIBE_TRAINING_JOB_RESULT\n    )\n    sms.sagemaker_client.describe_endpoint = Mock(return_value=ENDPOINT_DESC)\n    sms.sagemaker_client.describe_endpoint_config = Mock(return_value=ENDPOINT_CONFIG_DESC)\n\n    return sms\n\n\ndef test_init_required_positional(sagemaker_session):\n    kmeans = KMeans(\n        ROLE, TRAIN_INSTANCE_COUNT, TRAIN_INSTANCE_TYPE, K, sagemaker_session=sagemaker_session\n    )\n    assert kmeans.role == ROLE\n    assert kmeans.train_instance_count == TRAIN_INSTANCE_COUNT\n    assert kmeans.train_instance_type == TRAIN_INSTANCE_TYPE\n    assert kmeans.k == K\n\n\ndef test_init_required_named(sagemaker_session):\n    kmeans = KMeans(sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n\n    assert kmeans.role == COMMON_TRAIN_ARGS[""role""]\n    assert kmeans.train_instance_count == TRAIN_INSTANCE_COUNT\n    assert kmeans.train_instance_type == COMMON_TRAIN_ARGS[""train_instance_type""]\n    assert kmeans.k == ALL_REQ_ARGS[""k""]\n\n\ndef test_all_hyperparameters(sagemaker_session):\n    kmeans = KMeans(\n        sagemaker_session=sagemaker_session,\n        init_method=""random"",\n        max_iterations=3,\n        tol=0.5,\n        num_trials=5,\n        local_init_method=""kmeans++"",\n        half_life_time_size=0,\n        epochs=10,\n        center_factor=2,\n        eval_metrics=[""msd"", ""ssd""],\n        **ALL_REQ_ARGS\n    )\n    assert kmeans.hyperparameters() == dict(\n        k=str(ALL_REQ_ARGS[""k""]),\n        init_method=""random"",\n        local_lloyd_max_iter=""3"",\n        local_lloyd_tol=""0.5"",\n        local_lloyd_num_trials=""5"",\n        local_lloyd_init_method=""kmeans++"",\n        half_life_time_size=""0"",\n        epochs=""10"",\n        extra_center_factor=""2"",\n        eval_metrics=\'[""msd"", ""ssd""]\',\n        force_dense=""True"",\n    )\n\n\ndef test_image(sagemaker_session):\n    kmeans = KMeans(sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n    assert kmeans.train_image() == registry(REGION, ""kmeans"") + ""/kmeans:1""\n\n\n@pytest.mark.parametrize(""required_hyper_parameters, value"", [(""k"", ""string"")])\ndef test_required_hyper_parameters_type(sagemaker_session, required_hyper_parameters, value):\n    with pytest.raises(ValueError):\n        test_params = ALL_REQ_ARGS.copy()\n        test_params[required_hyper_parameters] = value\n        KMeans(sagemaker_session=sagemaker_session, **test_params)\n\n\n@pytest.mark.parametrize(""required_hyper_parameters, value"", [(""k"", 0)])\ndef test_required_hyper_parameters_value(sagemaker_session, required_hyper_parameters, value):\n    with pytest.raises(ValueError):\n        test_params = ALL_REQ_ARGS.copy()\n        test_params[required_hyper_parameters] = value\n        KMeans(sagemaker_session=sagemaker_session, **test_params)\n\n\n@pytest.mark.parametrize(""iterable_hyper_parameters, value"", [(""eval_metrics"", 0)])\ndef test_iterable_hyper_parameters_type(sagemaker_session, iterable_hyper_parameters, value):\n    with pytest.raises(TypeError):\n        test_params = ALL_REQ_ARGS.copy()\n        test_params.update({iterable_hyper_parameters: value})\n        KMeans(sagemaker_session=sagemaker_session, **test_params)\n\n\n@pytest.mark.parametrize(\n    ""optional_hyper_parameters, value"",\n    [\n        (""init_method"", 0),\n        (""max_iterations"", ""string""),\n        (""tol"", ""string""),\n        (""num_trials"", ""string""),\n        (""local_init_method"", 0),\n        (""half_life_time_size"", ""string""),\n        (""epochs"", ""string""),\n        (""center_factor"", ""string""),\n    ],\n)\ndef test_optional_hyper_parameters_type(sagemaker_session, optional_hyper_parameters, value):\n    with pytest.raises(ValueError):\n        test_params = ALL_REQ_ARGS.copy()\n        test_params.update({optional_hyper_parameters: value})\n        KMeans(sagemaker_session=sagemaker_session, **test_params)\n\n\n@pytest.mark.parametrize(\n    ""optional_hyper_parameters, value"",\n    [\n        (""init_method"", ""string""),\n        (""max_iterations"", 0),\n        (""tol"", -0.1),\n        (""tol"", 1.1),\n        (""num_trials"", 0),\n        (""local_init_method"", ""string""),\n        (""half_life_time_size"", -1),\n        (""epochs"", 0),\n        (""center_factor"", 0),\n    ],\n)\ndef test_optional_hyper_parameters_value(sagemaker_session, optional_hyper_parameters, value):\n    with pytest.raises(ValueError):\n        test_params = ALL_REQ_ARGS.copy()\n        test_params.update({optional_hyper_parameters: value})\n        KMeans(sagemaker_session=sagemaker_session, **test_params)\n\n\nPREFIX = ""prefix""\nFEATURE_DIM = 10\nMINI_BATCH_SIZE = 200\n\n\n@patch(""sagemaker.amazon.amazon_estimator.AmazonAlgorithmEstimatorBase.fit"")\ndef test_call_fit(base_fit, sagemaker_session):\n    kmeans = KMeans(base_job_name=""kmeans"", sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n\n    kmeans.fit(data, MINI_BATCH_SIZE)\n\n    base_fit.assert_called_once()\n    assert len(base_fit.call_args[0]) == 2\n    assert base_fit.call_args[0][0] == data\n    assert base_fit.call_args[0][1] == MINI_BATCH_SIZE\n\n\ndef test_prepare_for_training_no_mini_batch_size(sagemaker_session):\n    kmeans = KMeans(base_job_name=""kmeans"", sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n    kmeans._prepare_for_training(data)\n\n    assert kmeans.mini_batch_size == 5000\n\n\ndef test_prepare_for_training_wrong_type_mini_batch_size(sagemaker_session):\n    kmeans = KMeans(base_job_name=""kmeans"", sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n\n    with pytest.raises((TypeError, ValueError)):\n        kmeans._prepare_for_training(data, ""some"")\n\n\ndef test_prepare_for_training_wrong_value_mini_batch_size(sagemaker_session):\n    kmeans = KMeans(base_job_name=""kmeans"", sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n    with pytest.raises(ValueError):\n        kmeans._prepare_for_training(data, 0)\n\n\ndef test_model_image(sagemaker_session):\n    kmeans = KMeans(sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n    kmeans.fit(data, MINI_BATCH_SIZE)\n\n    model = kmeans.create_model()\n    assert model.image == registry(REGION, ""kmeans"") + ""/kmeans:1""\n\n\ndef test_predictor_type(sagemaker_session):\n    kmeans = KMeans(sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n    kmeans.fit(data, MINI_BATCH_SIZE)\n    model = kmeans.create_model()\n    predictor = model.deploy(1, TRAIN_INSTANCE_TYPE)\n\n    assert isinstance(predictor, KMeansPredictor)\n'"
tests/unit/test_knn.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport pytest\nfrom mock import Mock, patch\n\nfrom sagemaker.amazon.knn import KNN, KNNPredictor\nfrom sagemaker.amazon.amazon_estimator import registry, RecordSet\n\nROLE = ""myrole""\nTRAIN_INSTANCE_COUNT = 1\nTRAIN_INSTANCE_TYPE = ""ml.c4.xlarge""\nK = 5\nSAMPLE_SIZE = 1000\nPREDICTOR_TYPE_REGRESSOR = ""regressor""\nPREDICTOR_TYPE_CLASSIFIER = ""classifier""\n\nCOMMON_TRAIN_ARGS = {\n    ""role"": ROLE,\n    ""train_instance_count"": TRAIN_INSTANCE_COUNT,\n    ""train_instance_type"": TRAIN_INSTANCE_TYPE,\n}\nALL_REQ_ARGS = dict(\n    {""k"": K, ""sample_size"": SAMPLE_SIZE, ""predictor_type"": PREDICTOR_TYPE_REGRESSOR},\n    **COMMON_TRAIN_ARGS\n)\n\nREGION = ""us-west-2""\nBUCKET_NAME = ""Some-Bucket""\n\nDESCRIBE_TRAINING_JOB_RESULT = {""ModelArtifacts"": {""S3ModelArtifacts"": ""s3://bucket/model.tar.gz""}}\n\nENDPOINT_DESC = {""EndpointConfigName"": ""test-endpoint""}\n\nENDPOINT_CONFIG_DESC = {""ProductionVariants"": [{""ModelName"": ""model-1""}, {""ModelName"": ""model-2""}]}\n\n\n@pytest.fixture()\ndef sagemaker_session():\n    boto_mock = Mock(name=""boto_session"", region_name=REGION)\n    sms = Mock(\n        name=""sagemaker_session"",\n        boto_session=boto_mock,\n        region_name=REGION,\n        config=None,\n        local_mode=False,\n        s3_client=None,\n        s3_resource=None,\n    )\n    sms.boto_region_name = REGION\n    sms.default_bucket = Mock(name=""default_bucket"", return_value=BUCKET_NAME)\n    sms.sagemaker_client.describe_training_job = Mock(\n        name=""describe_training_job"", return_value=DESCRIBE_TRAINING_JOB_RESULT\n    )\n    sms.sagemaker_client.describe_endpoint = Mock(return_value=ENDPOINT_DESC)\n    sms.sagemaker_client.describe_endpoint_config = Mock(return_value=ENDPOINT_CONFIG_DESC)\n\n    return sms\n\n\ndef test_init_required_positional(sagemaker_session):\n    knn = KNN(\n        ROLE,\n        TRAIN_INSTANCE_COUNT,\n        TRAIN_INSTANCE_TYPE,\n        K,\n        SAMPLE_SIZE,\n        PREDICTOR_TYPE_REGRESSOR,\n        sagemaker_session=sagemaker_session,\n    )\n    assert knn.role == ROLE\n    assert knn.train_instance_count == TRAIN_INSTANCE_COUNT\n    assert knn.train_instance_type == TRAIN_INSTANCE_TYPE\n    assert knn.k == K\n\n\ndef test_init_required_named(sagemaker_session):\n    knn = KNN(sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n\n    assert knn.role == COMMON_TRAIN_ARGS[""role""]\n    assert knn.train_instance_count == TRAIN_INSTANCE_COUNT\n    assert knn.train_instance_type == COMMON_TRAIN_ARGS[""train_instance_type""]\n    assert knn.k == ALL_REQ_ARGS[""k""]\n\n\ndef test_all_hyperparameters_regressor(sagemaker_session):\n    knn = KNN(\n        sagemaker_session=sagemaker_session,\n        dimension_reduction_type=""sign"",\n        dimension_reduction_target=""2"",\n        index_type=""faiss.Flat"",\n        index_metric=""COSINE"",\n        faiss_index_ivf_nlists=""auto"",\n        faiss_index_pq_m=1,\n        **ALL_REQ_ARGS\n    )\n    assert knn.hyperparameters() == dict(\n        k=str(ALL_REQ_ARGS[""k""]),\n        sample_size=str(ALL_REQ_ARGS[""sample_size""]),\n        predictor_type=str(ALL_REQ_ARGS[""predictor_type""]),\n        dimension_reduction_type=""sign"",\n        dimension_reduction_target=""2"",\n        index_type=""faiss.Flat"",\n        index_metric=""COSINE"",\n        faiss_index_ivf_nlists=""auto"",\n        faiss_index_pq_m=""1"",\n    )\n\n\ndef test_all_hyperparameters_classifier(sagemaker_session):\n    test_params = ALL_REQ_ARGS.copy()\n    test_params[""predictor_type""] = PREDICTOR_TYPE_CLASSIFIER\n\n    knn = KNN(\n        sagemaker_session=sagemaker_session,\n        dimension_reduction_type=""fjlt"",\n        dimension_reduction_target=""2"",\n        index_type=""faiss.IVFFlat"",\n        index_metric=""L2"",\n        faiss_index_ivf_nlists=""20"",\n        **test_params\n    )\n    assert knn.hyperparameters() == dict(\n        k=str(ALL_REQ_ARGS[""k""]),\n        sample_size=str(ALL_REQ_ARGS[""sample_size""]),\n        predictor_type=str(PREDICTOR_TYPE_CLASSIFIER),\n        dimension_reduction_type=""fjlt"",\n        dimension_reduction_target=""2"",\n        index_type=""faiss.IVFFlat"",\n        index_metric=""L2"",\n        faiss_index_ivf_nlists=""20"",\n    )\n\n\ndef test_image(sagemaker_session):\n    knn = KNN(sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n    assert knn.train_image() == registry(REGION, ""knn"") + ""/knn:1""\n\n\n@pytest.mark.parametrize(\n    ""required_hyper_parameters, value"",\n    [(""k"", ""string""), (""sample_size"", ""string""), (""predictor_type"", 1)],\n)\ndef test_required_hyper_parameters_type(sagemaker_session, required_hyper_parameters, value):\n    with pytest.raises(ValueError):\n        test_params = ALL_REQ_ARGS.copy()\n        test_params[required_hyper_parameters] = value\n        KNN(sagemaker_session=sagemaker_session, **test_params)\n\n\n@pytest.mark.parametrize(""required_hyper_parameters, value"", [(""predictor_type"", ""random_string"")])\ndef test_required_hyper_parameters_value(sagemaker_session, required_hyper_parameters, value):\n    with pytest.raises(ValueError):\n        test_params = ALL_REQ_ARGS.copy()\n        test_params[required_hyper_parameters] = value\n        KNN(sagemaker_session=sagemaker_session, **test_params)\n\n\n@pytest.mark.parametrize(\n    ""iterable_hyper_parameters, value"", [(""index_type"", 1), (""index_metric"", ""string"")]\n)\ndef test_error_optional_hyper_parameters_type(sagemaker_session, iterable_hyper_parameters, value):\n    with pytest.raises(ValueError):\n        test_params = ALL_REQ_ARGS.copy()\n        test_params.update({iterable_hyper_parameters: value})\n        KNN(sagemaker_session=sagemaker_session, **test_params)\n\n\n@pytest.mark.parametrize(\n    ""optional_hyper_parameters, value"",\n    [(""index_type"", ""faiss.random""), (""index_metric"", ""randomstring""), (""faiss_index_pq_m"", -1)],\n)\ndef test_error_optional_hyper_parameters_value(sagemaker_session, optional_hyper_parameters, value):\n    with pytest.raises(ValueError):\n        test_params = ALL_REQ_ARGS.copy()\n        test_params.update({optional_hyper_parameters: value})\n        KNN(sagemaker_session=sagemaker_session, **test_params)\n\n\n@pytest.mark.parametrize(\n    ""conditional_hyper_parameters"",\n    [\n        {""dimension_reduction_type"": ""sign""},  # errors due to missing dimension_reduction_target\n        {""dimension_reduction_type"": ""sign"", ""dimension_reduction_target"": -2},\n        {""dimension_reduction_type"": ""sign"", ""dimension_reduction_target"": ""string""},\n        {""dimension_reduction_type"": 2, ""dimension_reduction_target"": 20},\n        {""dimension_reduction_type"": ""randomstring"", ""dimension_reduction_target"": 20},\n    ],\n)\ndef test_error_conditional_hyper_parameters_value(sagemaker_session, conditional_hyper_parameters):\n    with pytest.raises(ValueError):\n        test_params = ALL_REQ_ARGS.copy()\n        test_params.update(conditional_hyper_parameters)\n        KNN(sagemaker_session=sagemaker_session, **test_params)\n\n\nPREFIX = ""prefix""\nFEATURE_DIM = 10\nMINI_BATCH_SIZE = 200\n\n\n@patch(""sagemaker.amazon.amazon_estimator.AmazonAlgorithmEstimatorBase.fit"")\ndef test_call_fit(base_fit, sagemaker_session):\n    knn = KNN(base_job_name=""knn"", sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n\n    knn.fit(data, MINI_BATCH_SIZE)\n\n    base_fit.assert_called_once()\n    assert len(base_fit.call_args[0]) == 2\n    assert base_fit.call_args[0][0] == data\n    assert base_fit.call_args[0][1] == MINI_BATCH_SIZE\n\n\ndef test_call_fit_none_mini_batch_size(sagemaker_session):\n    knn = KNN(base_job_name=""knn"", sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n    knn.fit(data)\n\n\ndef test_prepare_for_training_wrong_type_mini_batch_size(sagemaker_session):\n    knn = KNN(base_job_name=""knn"", sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n\n    with pytest.raises((TypeError, ValueError)):\n        knn._prepare_for_training(data, ""some"")\n\n\ndef test_prepare_for_training_wrong_value_lower_mini_batch_size(sagemaker_session):\n    knn = KNN(base_job_name=""knn"", sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n    with pytest.raises(ValueError):\n        knn._prepare_for_training(data, 0)\n\n\ndef test_model_image(sagemaker_session):\n    knn = KNN(sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n    knn.fit(data, MINI_BATCH_SIZE)\n\n    model = knn.create_model()\n    assert model.image == registry(REGION, ""knn"") + ""/knn:1""\n\n\ndef test_predictor_type(sagemaker_session):\n    knn = KNN(sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n    knn.fit(data, MINI_BATCH_SIZE)\n    model = knn.create_model()\n    predictor = model.deploy(1, TRAIN_INSTANCE_TYPE)\n\n    assert isinstance(predictor, KNNPredictor)\n'"
tests/unit/test_lda.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport pytest\nfrom mock import Mock, patch\n\nfrom sagemaker.amazon.lda import LDA, LDAPredictor\nfrom sagemaker.amazon.amazon_estimator import registry, RecordSet\n\nROLE = ""myrole""\nTRAIN_INSTANCE_COUNT = 1\nTRAIN_INSTANCE_TYPE = ""ml.c4.xlarge""\nNUM_TOPICS = 3\n\nCOMMON_TRAIN_ARGS = {""role"": ROLE, ""train_instance_type"": TRAIN_INSTANCE_TYPE}\nALL_REQ_ARGS = dict({""num_topics"": NUM_TOPICS}, **COMMON_TRAIN_ARGS)\n\nREGION = ""us-west-2""\nBUCKET_NAME = ""Some-Bucket""\n\nDESCRIBE_TRAINING_JOB_RESULT = {""ModelArtifacts"": {""S3ModelArtifacts"": ""s3://bucket/model.tar.gz""}}\n\nENDPOINT_DESC = {""EndpointConfigName"": ""test-endpoint""}\n\nENDPOINT_CONFIG_DESC = {""ProductionVariants"": [{""ModelName"": ""model-1""}, {""ModelName"": ""model-2""}]}\n\n\n@pytest.fixture()\ndef sagemaker_session():\n    boto_mock = Mock(name=""boto_session"", region_name=REGION)\n    sms = Mock(\n        name=""sagemaker_session"",\n        boto_session=boto_mock,\n        config=None,\n        local_mode=False,\n        s3_client=None,\n        s3_resource=None,\n    )\n    sms.boto_region_name = REGION\n    sms.default_bucket = Mock(name=""default_bucket"", return_value=BUCKET_NAME)\n    sms.sagemaker_client.describe_training_job = Mock(\n        name=""describe_training_job"", return_value=DESCRIBE_TRAINING_JOB_RESULT\n    )\n    sms.sagemaker_client.describe_endpoint = Mock(return_value=ENDPOINT_DESC)\n    sms.sagemaker_client.describe_endpoint_config = Mock(return_value=ENDPOINT_CONFIG_DESC)\n\n    return sms\n\n\ndef test_init_required_positional(sagemaker_session):\n    lda = LDA(ROLE, TRAIN_INSTANCE_TYPE, NUM_TOPICS, sagemaker_session=sagemaker_session)\n    assert lda.role == ROLE\n    assert lda.train_instance_count == TRAIN_INSTANCE_COUNT\n    assert lda.train_instance_type == TRAIN_INSTANCE_TYPE\n    assert lda.num_topics == NUM_TOPICS\n\n\ndef test_init_required_named(sagemaker_session):\n    lda = LDA(sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n\n    assert lda.role == COMMON_TRAIN_ARGS[""role""]\n    assert lda.train_instance_count == TRAIN_INSTANCE_COUNT\n    assert lda.train_instance_type == COMMON_TRAIN_ARGS[""train_instance_type""]\n    assert lda.num_topics == ALL_REQ_ARGS[""num_topics""]\n\n\ndef test_all_hyperparameters(sagemaker_session):\n    lda = LDA(\n        sagemaker_session=sagemaker_session,\n        alpha0=2.2,\n        max_restarts=3,\n        max_iterations=10,\n        tol=3.3,\n        **ALL_REQ_ARGS\n    )\n    assert lda.hyperparameters() == dict(\n        num_topics=str(ALL_REQ_ARGS[""num_topics""]),\n        alpha0=""2.2"",\n        max_restarts=""3"",\n        max_iterations=""10"",\n        tol=""3.3"",\n    )\n\n\ndef test_image(sagemaker_session):\n    lda = LDA(sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n    assert lda.train_image() == registry(REGION, ""lda"") + ""/lda:1""\n\n\n@pytest.mark.parametrize(""required_hyper_parameters, value"", [(""num_topics"", ""string"")])\ndef test_required_hyper_parameters_type(sagemaker_session, required_hyper_parameters, value):\n    with pytest.raises(ValueError):\n        test_params = ALL_REQ_ARGS.copy()\n        test_params[required_hyper_parameters] = value\n        LDA(sagemaker_session=sagemaker_session, **test_params)\n\n\n@pytest.mark.parametrize(""required_hyper_parameters, value"", [(""num_topics"", 0)])\ndef test_required_hyper_parameters_value(sagemaker_session, required_hyper_parameters, value):\n    with pytest.raises(ValueError):\n        test_params = ALL_REQ_ARGS.copy()\n        test_params[required_hyper_parameters] = value\n        LDA(sagemaker_session=sagemaker_session, **test_params)\n\n\n@pytest.mark.parametrize(\n    ""optional_hyper_parameters, value"",\n    [\n        (""alpha0"", ""string""),\n        (""max_restarts"", ""string""),\n        (""max_iterations"", ""string""),\n        (""tol"", ""string""),\n    ],\n)\ndef test_optional_hyper_parameters_type(sagemaker_session, optional_hyper_parameters, value):\n    with pytest.raises(ValueError):\n        test_params = ALL_REQ_ARGS.copy()\n        test_params.update({optional_hyper_parameters: value})\n        LDA(sagemaker_session=sagemaker_session, **test_params)\n\n\n@pytest.mark.parametrize(\n    ""optional_hyper_parameters, value"", [(""max_restarts"", 0), (""max_iterations"", 0), (""tol"", 0)]\n)\ndef test_optional_hyper_parameters_value(sagemaker_session, optional_hyper_parameters, value):\n    with pytest.raises(ValueError):\n        test_params = ALL_REQ_ARGS.copy()\n        test_params.update({optional_hyper_parameters: value})\n        LDA(sagemaker_session=sagemaker_session, **test_params)\n\n\nPREFIX = ""prefix""\nFEATURE_DIM = 10\nMINI_BATCH_SZIE = 200\n\n\n@patch(""sagemaker.amazon.amazon_estimator.AmazonAlgorithmEstimatorBase.fit"")\ndef test_call_fit(base_fit, sagemaker_session):\n    lda = LDA(base_job_name=""lda"", sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n\n    lda.fit(data, MINI_BATCH_SZIE)\n\n    base_fit.assert_called_once()\n    assert len(base_fit.call_args[0]) == 2\n    assert base_fit.call_args[0][0] == data\n    assert base_fit.call_args[0][1] == MINI_BATCH_SZIE\n\n\ndef test_prepare_for_training_no_mini_batch_size(sagemaker_session):\n    lda = LDA(base_job_name=""lda"", sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n    with pytest.raises(ValueError):\n        lda._prepare_for_training(data, None)\n\n\ndef test_prepare_for_training_wrong_type_mini_batch_size(sagemaker_session):\n    lda = LDA(base_job_name=""lda"", sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n\n    with pytest.raises(ValueError):\n        lda._prepare_for_training(data, ""some"")\n\n\ndef test_prepare_for_training_wrong_value_mini_batch_size(sagemaker_session):\n    lda = LDA(base_job_name=""lda"", sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n    with pytest.raises(ValueError):\n        lda._prepare_for_training(data, 0)\n\n\ndef test_model_image(sagemaker_session):\n    lda = LDA(sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n    lda.fit(data, MINI_BATCH_SZIE)\n\n    model = lda.create_model()\n    assert model.image == registry(REGION, ""lda"") + ""/lda:1""\n\n\ndef test_predictor_type(sagemaker_session):\n    lda = LDA(sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n    lda.fit(data, MINI_BATCH_SZIE)\n    model = lda.create_model()\n    predictor = model.deploy(1, TRAIN_INSTANCE_TYPE)\n\n    assert isinstance(predictor, LDAPredictor)\n'"
tests/unit/test_linear_learner.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport pytest\nfrom mock import Mock, patch\n\nfrom sagemaker.amazon.linear_learner import LinearLearner, LinearLearnerPredictor\nfrom sagemaker.amazon.amazon_estimator import registry, RecordSet\n\nROLE = ""myrole""\nTRAIN_INSTANCE_COUNT = 1\nTRAIN_INSTANCE_TYPE = ""ml.c4.xlarge""\n\nPREDICTOR_TYPE = ""binary_classifier""\n\nCOMMON_TRAIN_ARGS = {\n    ""role"": ROLE,\n    ""train_instance_count"": TRAIN_INSTANCE_COUNT,\n    ""train_instance_type"": TRAIN_INSTANCE_TYPE,\n}\nALL_REQ_ARGS = dict({""predictor_type"": PREDICTOR_TYPE}, **COMMON_TRAIN_ARGS)\n\nREGION = ""us-west-2""\nBUCKET_NAME = ""Some-Bucket""\n\nDESCRIBE_TRAINING_JOB_RESULT = {""ModelArtifacts"": {""S3ModelArtifacts"": ""s3://bucket/model.tar.gz""}}\n\nENDPOINT_DESC = {""EndpointConfigName"": ""test-endpoint""}\n\nENDPOINT_CONFIG_DESC = {""ProductionVariants"": [{""ModelName"": ""model-1""}, {""ModelName"": ""model-2""}]}\n\n\n@pytest.fixture()\ndef sagemaker_session():\n    boto_mock = Mock(name=""boto_session"", region_name=REGION)\n    sms = Mock(\n        name=""sagemaker_session"",\n        boto_session=boto_mock,\n        region_name=REGION,\n        config=None,\n        local_mode=False,\n        s3_client=None,\n        s3_resource=None,\n    )\n    sms.boto_region_name = REGION\n    sms.default_bucket = Mock(name=""default_bucket"", return_value=BUCKET_NAME)\n    sms.sagemaker_client.describe_training_job = Mock(\n        name=""describe_training_job"", return_value=DESCRIBE_TRAINING_JOB_RESULT\n    )\n    sms.sagemaker_client.describe_endpoint = Mock(return_value=ENDPOINT_DESC)\n    sms.sagemaker_client.describe_endpoint_config = Mock(return_value=ENDPOINT_CONFIG_DESC)\n\n    return sms\n\n\ndef test_init_required_positional(sagemaker_session):\n    lr = LinearLearner(\n        ROLE,\n        TRAIN_INSTANCE_COUNT,\n        TRAIN_INSTANCE_TYPE,\n        PREDICTOR_TYPE,\n        sagemaker_session=sagemaker_session,\n    )\n    assert lr.role == ROLE\n    assert lr.train_instance_count == TRAIN_INSTANCE_COUNT\n    assert lr.train_instance_type == TRAIN_INSTANCE_TYPE\n    assert lr.predictor_type == PREDICTOR_TYPE\n\n\ndef test_init_required_named(sagemaker_session):\n    lr = LinearLearner(sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n\n    assert lr.role == ALL_REQ_ARGS[""role""]\n    assert lr.train_instance_count == ALL_REQ_ARGS[""train_instance_count""]\n    assert lr.train_instance_type == ALL_REQ_ARGS[""train_instance_type""]\n    assert lr.predictor_type == ALL_REQ_ARGS[""predictor_type""]\n\n\ndef test_all_hyperparameters(sagemaker_session):\n    lr = LinearLearner(\n        sagemaker_session=sagemaker_session,\n        binary_classifier_model_selection_criteria=""accuracy"",\n        target_recall=0.5,\n        target_precision=0.6,\n        positive_example_weight_mult=0.1,\n        epochs=1,\n        use_bias=True,\n        num_models=5,\n        num_calibration_samples=6,\n        init_method=""uniform"",\n        init_scale=0.1,\n        init_sigma=0.001,\n        init_bias=0,\n        optimizer=""sgd"",\n        loss=""logistic"",\n        wd=0.4,\n        l1=0.04,\n        momentum=0.1,\n        learning_rate=0.001,\n        beta_1=0.2,\n        beta_2=0.03,\n        bias_lr_mult=5.5,\n        bias_wd_mult=6.6,\n        use_lr_scheduler=False,\n        lr_scheduler_step=2,\n        lr_scheduler_factor=0.03,\n        lr_scheduler_minimum_lr=0.001,\n        normalize_data=False,\n        normalize_label=True,\n        unbias_data=True,\n        unbias_label=False,\n        num_point_for_scaler=3,\n        margin=1.0,\n        quantile=0.5,\n        loss_insensitivity=0.1,\n        huber_delta=0.1,\n        early_stopping_patience=3,\n        early_stopping_tolerance=0.001,\n        num_classes=1,\n        accuracy_top_k=3,\n        f_beta=1.0,\n        balance_multiclass_weights=False,\n        **ALL_REQ_ARGS\n    )\n\n    assert lr.hyperparameters() == dict(\n        predictor_type=""binary_classifier"",\n        binary_classifier_model_selection_criteria=""accuracy"",\n        target_recall=""0.5"",\n        target_precision=""0.6"",\n        positive_example_weight_mult=""0.1"",\n        epochs=""1"",\n        use_bias=""True"",\n        num_models=""5"",\n        num_calibration_samples=""6"",\n        init_method=""uniform"",\n        init_scale=""0.1"",\n        init_sigma=""0.001"",\n        init_bias=""0.0"",\n        optimizer=""sgd"",\n        loss=""logistic"",\n        wd=""0.4"",\n        l1=""0.04"",\n        momentum=""0.1"",\n        learning_rate=""0.001"",\n        beta_1=""0.2"",\n        beta_2=""0.03"",\n        bias_lr_mult=""5.5"",\n        bias_wd_mult=""6.6"",\n        use_lr_scheduler=""False"",\n        lr_scheduler_step=""2"",\n        lr_scheduler_factor=""0.03"",\n        lr_scheduler_minimum_lr=""0.001"",\n        normalize_data=""False"",\n        normalize_label=""True"",\n        unbias_data=""True"",\n        unbias_label=""False"",\n        num_point_for_scaler=""3"",\n        margin=""1.0"",\n        quantile=""0.5"",\n        loss_insensitivity=""0.1"",\n        huber_delta=""0.1"",\n        early_stopping_patience=""3"",\n        early_stopping_tolerance=""0.001"",\n        num_classes=""1"",\n        accuracy_top_k=""3"",\n        f_beta=""1.0"",\n        balance_multiclass_weights=""False"",\n    )\n\n\ndef test_image(sagemaker_session):\n    lr = LinearLearner(sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n    assert lr.train_image() == registry(REGION, ""linear-learner"") + ""/linear-learner:1""\n\n\n@pytest.mark.parametrize(""required_hyper_parameters, value"", [(""predictor_type"", 0)])\ndef test_required_hyper_parameters_type(sagemaker_session, required_hyper_parameters, value):\n    with pytest.raises(ValueError):\n        test_params = ALL_REQ_ARGS.copy()\n        test_params[required_hyper_parameters] = value\n        LinearLearner(sagemaker_session=sagemaker_session, **test_params)\n\n\n@pytest.mark.parametrize(""required_hyper_parameters, value"", [(""predictor_type"", ""string"")])\ndef test_required_hyper_parameters_value(sagemaker_session, required_hyper_parameters, value):\n    with pytest.raises(ValueError):\n        test_params = ALL_REQ_ARGS.copy()\n        test_params[required_hyper_parameters] = value\n        LinearLearner(sagemaker_session=sagemaker_session, **test_params)\n\n\ndef test_num_classes_is_required_for_multiclass_classifier(sagemaker_session):\n    with pytest.raises(ValueError) as excinfo:\n        test_params = ALL_REQ_ARGS.copy()\n        test_params[""predictor_type""] = ""multiclass_classifier""\n        LinearLearner(sagemaker_session=sagemaker_session, **test_params)\n    assert (\n        ""For predictor_type \'multiclass_classifier\', \'num_classes\' should be set to a value greater than 2.""\n        in str(excinfo.value)\n    )\n\n\ndef test_num_classes_can_be_string_for_multiclass_classifier(sagemaker_session):\n    test_params = ALL_REQ_ARGS.copy()\n    test_params[""predictor_type""] = ""multiclass_classifier""\n    test_params[""num_classes""] = ""3""\n    LinearLearner(sagemaker_session=sagemaker_session, **test_params)\n\n\n@pytest.mark.parametrize(""iterable_hyper_parameters, value"", [(""eval_metrics"", 0)])\ndef test_iterable_hyper_parameters_type(sagemaker_session, iterable_hyper_parameters, value):\n    with pytest.raises(TypeError):\n        test_params = ALL_REQ_ARGS.copy()\n        test_params.update({iterable_hyper_parameters: value})\n        LinearLearner(sagemaker_session=sagemaker_session, **test_params)\n\n\n@pytest.mark.parametrize(\n    ""optional_hyper_parameters, value"",\n    [\n        (""binary_classifier_model_selection_criteria"", 0),\n        (""target_recall"", ""string""),\n        (""target_precision"", ""string""),\n        (""epochs"", ""string""),\n        (""num_models"", ""string""),\n        (""num_calibration_samples"", ""string""),\n        (""init_method"", 0),\n        (""init_scale"", ""string""),\n        (""init_sigma"", ""string""),\n        (""init_bias"", ""string""),\n        (""optimizer"", 0),\n        (""loss"", 0),\n        (""wd"", ""string""),\n        (""l1"", ""string""),\n        (""momentum"", ""string""),\n        (""learning_rate"", ""string""),\n        (""beta_1"", ""string""),\n        (""beta_2"", ""string""),\n        (""bias_lr_mult"", ""string""),\n        (""bias_wd_mult"", ""string""),\n        (""lr_scheduler_step"", ""string""),\n        (""lr_scheduler_factor"", ""string""),\n        (""lr_scheduler_minimum_lr"", ""string""),\n        (""num_point_for_scaler"", ""string""),\n        (""margin"", ""string""),\n        (""quantile"", ""string""),\n        (""loss_insensitivity"", ""string""),\n        (""huber_delta"", ""string""),\n        (""early_stopping_patience"", ""string""),\n        (""early_stopping_tolerance"", ""string""),\n        (""num_classes"", ""string""),\n        (""accuracy_top_k"", ""string""),\n        (""f_beta"", ""string""),\n    ],\n)\ndef test_optional_hyper_parameters_type(sagemaker_session, optional_hyper_parameters, value):\n    with pytest.raises(ValueError):\n        test_params = ALL_REQ_ARGS.copy()\n        test_params.update({optional_hyper_parameters: value})\n        LinearLearner(sagemaker_session=sagemaker_session, **test_params)\n\n\n@pytest.mark.parametrize(\n    ""optional_hyper_parameters, value"",\n    [\n        (""binary_classifier_model_selection_criteria"", ""string""),\n        (""target_recall"", 0),\n        (""target_recall"", 1),\n        (""target_precision"", 0),\n        (""target_precision"", 1),\n        (""epochs"", 0),\n        (""num_models"", 0),\n        (""num_calibration_samples"", 0),\n        (""init_method"", ""string""),\n        (""init_scale"", 0),\n        (""init_sigma"", 0),\n        (""optimizer"", ""string""),\n        (""loss"", ""string""),\n        (""wd"", -1),\n        (""l1"", -1),\n        (""momentum"", 1),\n        (""learning_rate"", 0),\n        (""beta_1"", 1),\n        (""beta_2"", 1),\n        (""bias_lr_mult"", 0),\n        (""bias_wd_mult"", -1),\n        (""lr_scheduler_step"", 0),\n        (""lr_scheduler_factor"", 0),\n        (""lr_scheduler_factor"", 1),\n        (""lr_scheduler_minimum_lr"", 0),\n        (""num_point_for_scaler"", 0),\n        (""margin"", -1),\n        (""quantile"", 0),\n        (""quantile"", 1),\n        (""loss_insensitivity"", 0),\n        (""huber_delta"", -1),\n        (""early_stopping_patience"", 0),\n        (""early_stopping_tolerance"", 0),\n        (""num_classes"", 0),\n        (""accuracy_top_k"", 0),\n        (""f_beta"", -1.0),\n    ],\n)\ndef test_optional_hyper_parameters_value(sagemaker_session, optional_hyper_parameters, value):\n    with pytest.raises(ValueError):\n        test_params = ALL_REQ_ARGS.copy()\n        test_params.update({optional_hyper_parameters: value})\n        LinearLearner(sagemaker_session=sagemaker_session, **test_params)\n\n\nPREFIX = ""prefix""\nFEATURE_DIM = 10\nDEFAULT_MINI_BATCH_SIZE = 1000\n\n\ndef test_prepare_for_training_calculate_batch_size_1(sagemaker_session):\n    lr = LinearLearner(base_job_name=""lr"", sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n\n    lr._prepare_for_training(data)\n\n    assert lr.mini_batch_size == 1\n\n\ndef test_prepare_for_training_calculate_batch_size_2(sagemaker_session):\n    lr = LinearLearner(base_job_name=""lr"", sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=10000,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n\n    lr._prepare_for_training(data)\n\n    assert lr.mini_batch_size == DEFAULT_MINI_BATCH_SIZE\n\n\ndef test_prepare_for_training_multiple_channel(sagemaker_session):\n    lr = LinearLearner(base_job_name=""lr"", sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=10000,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n\n    lr._prepare_for_training([data, data])\n\n    assert lr.mini_batch_size == DEFAULT_MINI_BATCH_SIZE\n\n\ndef test_prepare_for_training_multiple_channel_no_train(sagemaker_session):\n    lr = LinearLearner(base_job_name=""lr"", sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=10000,\n        feature_dim=FEATURE_DIM,\n        channel=""mock"",\n    )\n\n    with pytest.raises(ValueError) as ex:\n        lr._prepare_for_training([data, data])\n\n        assert ""Must provide train channel."" in str(ex)\n\n\n@patch(""sagemaker.amazon.amazon_estimator.AmazonAlgorithmEstimatorBase.fit"")\ndef test_call_fit_pass_batch_size(base_fit, sagemaker_session):\n    lr = LinearLearner(base_job_name=""lr"", sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=10000,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n\n    lr.fit(data, 10)\n\n    base_fit.assert_called_once()\n    assert len(base_fit.call_args[0]) == 2\n    assert base_fit.call_args[0][0] == data\n    assert base_fit.call_args[0][1] == 10\n\n\ndef test_model_image(sagemaker_session):\n    lr = LinearLearner(sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n    lr.fit(data)\n\n    model = lr.create_model()\n    assert model.image == registry(REGION, ""linear-learner"") + ""/linear-learner:1""\n\n\ndef test_predictor_type(sagemaker_session):\n    lr = LinearLearner(sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n    lr.fit(data)\n    model = lr.create_model()\n    predictor = model.deploy(1, TRAIN_INSTANCE_TYPE)\n\n    assert isinstance(predictor, LinearLearnerPredictor)\n'"
tests/unit/test_local_data.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport sys\n\nimport pytest\nfrom mock import patch, Mock\n\nimport sagemaker.amazon\nimport sagemaker.local.data\n\n\n@patch(""sagemaker.local.data.LocalFileDataSource"")\ndef test_get_data_source_instance_with_file(LocalFileDataSource, sagemaker_local_session):\n    # file\n    data_source = sagemaker.local.data.get_data_source_instance(\n        ""file:///my/file"", sagemaker_local_session\n    )\n    LocalFileDataSource.assert_called_with(""/my/file"")\n    assert data_source is not None\n\n    data_source = sagemaker.local.data.get_data_source_instance(\n        ""file://relative/path"", sagemaker_local_session\n    )\n    LocalFileDataSource.assert_called_with(""relative/path"")\n    assert data_source is not None\n\n\n@patch(""sagemaker.local.data.S3DataSource"")\ndef test_get_data_source_instance_with_s3(S3DataSource, sagemaker_local_session):\n    data_source = sagemaker.local.data.get_data_source_instance(\n        ""s3://bucket/path"", sagemaker_local_session\n    )\n    S3DataSource.assert_called_with(""bucket"", ""/path"", sagemaker_local_session)\n    assert data_source is not None\n\n\n@patch(""os.path.exists"", Mock(return_value=True))\n@patch(""os.path.abspath"", lambda x: x)\n@patch(""os.path.isdir"", lambda x: x[-1] == ""/"")\n@patch(""os.path.isfile"", lambda x: x[-1] != ""/"")\n@patch(""os.listdir"")\ndef test_file_data_source_get_file_list_with_folder(listdir):\n    data_source = sagemaker.local.data.LocalFileDataSource(""/some/path/"")\n    listdir.return_value = [""/some/path/a"", ""/some/path/b"", ""/some/path/c/"", ""/some/path/c/a""]\n    expected = [""/some/path/a"", ""/some/path/b"", ""/some/path/c/a""]\n    result = data_source.get_file_list()\n    assert result == expected\n\n\n@patch(""os.path.exists"", Mock(return_value=True))\n@patch(""os.path.abspath"", lambda x: x)\n@patch(""os.path.isdir"", lambda x: x[-1] == ""/"")\n@patch(""os.path.isfile"", lambda x: x[-1] != ""/"")\ndef test_file_data_source_get_file_list_with_single_file():\n    data_source = sagemaker.local.data.LocalFileDataSource(""/some/batch/file.csv"")\n    assert data_source.get_file_list() == [""/some/batch/file.csv""]\n\n\n@patch(""os.path.exists"", Mock(return_value=True))\n@patch(""os.path.abspath"", lambda x: x)\n@patch(""os.path.isdir"", lambda x: x[-1] == ""/"")\ndef test_file_data_source_get_root():\n    data_source = sagemaker.local.data.LocalFileDataSource(""/some/path/"")\n    assert data_source.get_root_dir() == ""/some/path/""\n\n    data_source = sagemaker.local.data.LocalFileDataSource(""/some/path/my_file.csv"")\n    assert data_source.get_root_dir() == ""/some/path""\n\n\n@patch(""sagemaker.local.data.LocalFileDataSource"")\n@patch(""sagemaker.utils.download_folder"")\n@patch(""tempfile.mkdtemp"", lambda dir: ""/tmp/working_dir"")\ndef test_s3_data_source(download_folder, LocalFileDataSource, sagemaker_local_session):\n    data_source = sagemaker.local.data.S3DataSource(\n        ""my_bucket"", ""/transform/data"", sagemaker_local_session\n    )\n    download_folder.assert_called()\n    data_source.get_file_list()\n    LocalFileDataSource().get_file_list.assert_called()\n    data_source.get_root_dir()\n    LocalFileDataSource().get_root_dir.assert_called()\n\n\ndef test_get_splitter_instance_with_valid_types():\n    splitter = sagemaker.local.data.get_splitter_instance(None)\n    assert isinstance(splitter, sagemaker.local.data.NoneSplitter)\n\n    splitter = sagemaker.local.data.get_splitter_instance(""Line"")\n    assert isinstance(splitter, sagemaker.local.data.LineSplitter)\n\n    splitter = sagemaker.local.data.get_splitter_instance(""RecordIO"")\n    assert isinstance(splitter, sagemaker.local.data.RecordIOSplitter)\n\n\ndef test_get_splitter_instance_with_invalid_types():\n    with pytest.raises(ValueError):\n        sagemaker.local.data.get_splitter_instance(""SomethingInvalid"")\n\n\ndef test_none_splitter(tmpdir):\n    splitter = sagemaker.local.data.NoneSplitter()\n\n    test_file_path = tmpdir.join(""none_test.txt"")\n\n    with test_file_path.open(""w"") as f:\n        f.write(""this\\nis\\na\\ntest"")\n\n    data = [x for x in splitter.split(str(test_file_path))]\n    assert data == [""this\\nis\\na\\ntest""]\n\n    test_bin_file_path = tmpdir.join(""none_test.bin"")\n\n    with test_bin_file_path.open(""wb"") as f:\n        f.write(b""\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00C"")\n\n    data = [x for x in splitter.split(str(test_bin_file_path))]\n    assert data == [b""\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00C""]\n\n\ndef test_line_splitter(tmpdir):\n    test_file_path = tmpdir.join(""line_test.txt"")\n\n    with test_file_path.open(""w"") as f:\n        for i in range(10):\n            f.write(""%s\\n"" % i)\n\n    splitter = sagemaker.local.data.LineSplitter()\n    data = [x for x in splitter.split(str(test_file_path))]\n    assert len(data) == 10\n    for i in range(10):\n        assert data[i] == ""%s\\n"" % str(i)\n\n\ndef test_recordio_splitter(tmpdir):\n    test_file_path = tmpdir.join(""recordio_test.txt"")\n    with test_file_path.open(""wb"") as f:\n        for i in range(10):\n            data = str(i).encode(""utf-8"")\n            sagemaker.amazon.common._write_recordio(f, data)\n\n    splitter = sagemaker.local.data.RecordIOSplitter()\n    data = [x for x in splitter.split(str(test_file_path))]\n\n    assert len(data) == 10\n\n\ndef test_get_batch_strategy_instance_with_valid_type():\n    # Single Record\n    strategy = sagemaker.local.data.get_batch_strategy_instance(""SingleRecord"", None)\n    assert isinstance(strategy, sagemaker.local.data.SingleRecordStrategy)\n\n    # Multi Record\n    strategy = sagemaker.local.data.get_batch_strategy_instance(""MultiRecord"", None)\n    assert isinstance(strategy, sagemaker.local.data.MultiRecordStrategy)\n\n\ndef test_get_batch_strategy_instance_with_invalid_type():\n    with pytest.raises(ValueError):\n        # something invalid\n        sagemaker.local.data.get_batch_strategy_instance(""NiceRecord"", None)\n\n\ndef test_single_record_strategy_with_small_records():\n    splitter = Mock()\n\n    single_record = sagemaker.local.data.SingleRecordStrategy(splitter)\n    data = [""123"", ""456"", ""789""]\n    splitter.split.return_value = data\n\n    # given 3 small records the output should be the same 3 records\n    batch_records = [r for r in single_record.pad(""some_file"", 6)]\n    assert data == batch_records\n\n\ndef test_single_record_strategy_with_large_records():\n    splitter = Mock()\n    mb = 1024 * 1024\n\n    single_record = sagemaker.local.data.SingleRecordStrategy(splitter)\n    # We will construct a huge record greater than 1MB and we expect an exception\n    # since there is no way to fit this with the payload size.\n    buffer = """"\n    while sys.getsizeof(buffer) < 2 * mb:\n        buffer += ""1"" * 100\n\n    data = [buffer]\n    with pytest.raises(RuntimeError):\n        splitter.split.return_value = data\n        batch_records = [r for r in single_record.pad(""some_file"", 1)]\n        print(batch_records)\n\n\ndef test_single_record_strategy_with_no_payload_limit():\n    # passing 0 as the max_payload_size should work and a 1MB record should be returned\n    # correctly.\n    splitter = Mock()\n    mb = 1024 * 1024\n\n    buffer = """"\n    while sys.getsizeof(buffer) < 2 * mb:\n        buffer += ""1"" * 100\n    splitter.split.return_value = [buffer]\n\n    single_record = sagemaker.local.data.SingleRecordStrategy(splitter)\n    batch_records = [r for r in single_record.pad(""some_file"", 0)]\n    assert len(batch_records) == 1\n\n\ndef test_multi_record_strategy_with_small_records():\n    splitter = Mock()\n\n    multi_record = sagemaker.local.data.MultiRecordStrategy(splitter)\n    data = [""123"", ""456"", ""789""]\n    splitter.split.return_value = data\n\n    # given 3 small records, the output should be 1 single record with the data from all 3 combined\n    batch_records = [r for r in multi_record.pad(""some_file"", 6)]\n    assert len(batch_records) == 1\n    assert batch_records[0] == ""123456789""\n\n\ndef test_multi_record_strategy_with_large_records():\n    splitter = Mock()\n    mb = 1024 * 1024\n\n    multi_record = sagemaker.local.data.MultiRecordStrategy(splitter)\n    # we will construct several large records and we expect them to be merged into <1MB ones\n    buffer = """"\n    while sys.getsizeof(buffer) < 0.5 * mb:\n        buffer += ""1"" * 100\n\n    # buffer should be aprox 0.5 MB. We will make the data total 10 MB made out of 0.5mb records\n    # with a max_payload size of 1MB the expectation is to have ~10 output records.\n\n    data = [buffer for _ in range(10)]\n    splitter.split.return_value = data\n\n    batch_records = [r for r in multi_record.pad(""some_file"", 1)]\n    # check with 11 because there may be a bit of leftover.\n    assert len(batch_records) <= 11\n'"
tests/unit/test_local_entities.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport os\nimport pytest\n\nfrom mock import patch, Mock\n\nimport sagemaker.local\n\n\n@pytest.fixture(scope=""session"")\ndef local_transform_job(sagemaker_local_session):\n    with patch(\n        ""sagemaker.local.local_session.LocalSagemakerClient.describe_model""\n    ) as describe_model:\n        describe_model.return_value = {\n            ""PrimaryContainer"": {""Environment"": {}, ""Image"": ""some-image:1.0""}\n        }\n        job = sagemaker.local.entities._LocalTransformJob(\n            ""my-transform-job"", ""some-model"", sagemaker_local_session\n        )\n        return job\n\n\n@patch(\n    ""sagemaker.local.local_session.LocalSagemakerClient.describe_model"",\n    Mock(return_value={""PrimaryContainer"": {}}),\n)\ndef test_local_transform_job_init(sagemaker_local_session):\n    job = sagemaker.local.entities._LocalTransformJob(\n        ""my-transform-job"", ""some-model"", sagemaker_local_session\n    )\n    assert job.name == ""my-transform-job""\n    assert job.state == sagemaker.local.entities._LocalTransformJob._CREATING\n\n\ndef test_local_transform_job_container_environment(local_transform_job):\n    transform_kwargs = {""MaxPayloadInMB"": 3, ""BatchStrategy"": ""MultiRecord""}\n    container_env = local_transform_job._get_container_environment(**transform_kwargs)\n\n    assert ""SAGEMAKER_BATCH"" in container_env\n    assert ""SAGEMAKER_MAX_PAYLOAD_IN_MB"" in container_env\n    assert ""SAGEMAKER_BATCH_STRATEGY"" in container_env\n    assert ""SAGEMAKER_MAX_CONCURRENT_TRANSFORMS"" in container_env\n\n    transform_kwargs = {""BatchStrategy"": ""SingleRecord""}\n\n    container_env = local_transform_job._get_container_environment(**transform_kwargs)\n\n    assert ""SAGEMAKER_BATCH"" in container_env\n    assert ""SAGEMAKER_BATCH_STRATEGY"" in container_env\n    assert ""SAGEMAKER_MAX_CONCURRENT_TRANSFORMS"" in container_env\n\n    transform_kwargs = {""Environment"": {""MY_ENV"": 3}}\n\n    container_env = local_transform_job._get_container_environment(**transform_kwargs)\n\n    assert ""SAGEMAKER_BATCH"" in container_env\n    assert ""SAGEMAKER_MAX_PAYLOAD_IN_MB"" not in container_env\n    assert ""SAGEMAKER_BATCH_STRATEGY"" not in container_env\n    assert ""SAGEMAKER_MAX_CONCURRENT_TRANSFORMS"" in container_env\n    assert ""MY_ENV"" in container_env\n\n\ndef test_local_transform_job_defaults_with_empty_args(local_transform_job):\n    transform_kwargs = {}\n    defaults = local_transform_job._get_required_defaults(**transform_kwargs)\n    assert ""BatchStrategy"" in defaults\n    assert ""MaxPayloadInMB"" in defaults\n\n\ndef test_local_transform_job_defaults_with_batch_strategy(local_transform_job):\n    transform_kwargs = {""BatchStrategy"": ""my-own""}\n    defaults = local_transform_job._get_required_defaults(**transform_kwargs)\n    assert ""BatchStrategy"" not in defaults\n    assert ""MaxPayloadInMB"" in defaults\n\n\ndef test_local_transform_job_defaults_with_max_payload(local_transform_job):\n    transform_kwargs = {""MaxPayloadInMB"": 322}\n    defaults = local_transform_job._get_required_defaults(**transform_kwargs)\n    assert ""BatchStrategy"" in defaults\n    assert ""MaxPayloadInMB"" not in defaults\n\n\n@patch(""sagemaker.local.entities._SageMakerContainer"", Mock())\n@patch(""sagemaker.local.entities._wait_for_serving_container"", Mock())\n@patch(""sagemaker.local.entities._perform_request"")\n@patch(""sagemaker.local.entities._LocalTransformJob._perform_batch_inference"")\ndef test_start_local_transform_job(_perform_batch_inference, _perform_request, local_transform_job):\n    input_data = {}\n    output_data = {}\n    transform_resources = {""InstanceType"": ""local""}\n\n    response = Mock()\n    _perform_request.return_value = (response, 200)\n    response.read.return_value = \'{""BatchStrategy"": ""SingleRecord""}\'\n    local_transform_job.primary_container[""ModelDataUrl""] = ""file:///some/model""\n    local_transform_job.start(input_data, output_data, transform_resources, Environment={})\n\n    _perform_batch_inference.assert_called()\n    response = local_transform_job.describe()\n    assert response[""TransformJobStatus""] == ""Completed""\n\n\n@patch(""sagemaker.local.data.get_batch_strategy_instance"")\n@patch(""sagemaker.local.data.get_data_source_instance"")\n@patch(""sagemaker.local.entities.move_to_destination"")\n@patch(""sagemaker.local.entities.get_config_value"")\ndef test_local_transform_job_perform_batch_inference(\n    get_config_value,\n    move_to_destination,\n    get_data_source_instance,\n    get_batch_strategy_instance,\n    local_transform_job,\n    tmpdir,\n):\n    input_data = {\n        ""DataSource"": {""S3DataSource"": {""S3Uri"": ""s3://some_bucket/nice/data""}},\n        ""ContentType"": ""text/csv"",\n    }\n\n    output_data = {""S3OutputPath"": ""s3://bucket/output"", ""AssembleWith"": ""Line""}\n\n    transform_kwargs = {""MaxPayloadInMB"": 3, ""BatchStrategy"": ""MultiRecord""}\n\n    data_source = Mock()\n    data_source.get_file_list.return_value = [""/tmp/file1"", ""/tmp/file2""]\n    data_source.get_root_dir.return_value = ""/tmp""\n    get_data_source_instance.return_value = data_source\n\n    batch_strategy = Mock()\n    batch_strategy.pad.return_value = ""some data""\n    get_batch_strategy_instance.return_value = batch_strategy\n\n    get_config_value.return_value = str(tmpdir)\n\n    runtime_client = Mock()\n    response_object = Mock()\n    response_object.read.return_value = b""data""\n    runtime_client.invoke_endpoint.return_value = {""Body"": response_object}\n    local_transform_job.local_session.sagemaker_runtime_client = runtime_client\n\n    local_transform_job.container = Mock()\n\n    local_transform_job._perform_batch_inference(input_data, output_data, **transform_kwargs)\n\n    dir, output, job_name, session = move_to_destination.call_args[0]\n    assert output == ""s3://bucket/output""\n    output_files = os.listdir(dir)\n    assert len(output_files) == 2\n    assert ""file1.out"" in output_files\n    assert ""file2.out"" in output_files\n'"
tests/unit/test_local_session.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport pytest\nimport urllib3\nimport os\nfrom botocore.exceptions import ClientError\nfrom mock import Mock, patch\nfrom tests.unit import DATA_DIR\n\nimport sagemaker\n\n\nOK_RESPONSE = urllib3.HTTPResponse()\nOK_RESPONSE.status = 200\n\nBAD_RESPONSE = urllib3.HTTPResponse()\nBAD_RESPONSE.status = 502\n\nENDPOINT_CONFIG_NAME = ""test-endpoint-config""\nPRODUCTION_VARIANTS = [{""InstanceType"": ""ml.c4.99xlarge"", ""InitialInstanceCount"": 10}]\n\nMODEL_NAME = ""test-model""\nPRIMARY_CONTAINER = {""ModelDataUrl"": ""/some/model/path"", ""Environment"": {""env1"": 1, ""env2"": ""b""}}\n\nENDPOINT_URL = ""http://127.0.0.1:9000""\nBUCKET_NAME = ""mybucket""\nLS_FILES = {""Contents"": [{""Key"": ""/data/test.csv""}]}\n\n\n@patch(""sagemaker.local.image._SageMakerContainer.train"", return_value=""/some/path/to/model"")\n@patch(""sagemaker.local.local_session.LocalSession"")\ndef test_create_training_job(train, LocalSession):\n    local_sagemaker_client = sagemaker.local.local_session.LocalSagemakerClient()\n\n    instance_count = 2\n    image = ""my-docker-image:1.0""\n\n    algo_spec = {""TrainingImage"": image}\n    input_data_config = [\n        {\n            ""ChannelName"": ""a"",\n            ""DataSource"": {\n                ""S3DataSource"": {\n                    ""S3DataDistributionType"": ""FullyReplicated"",\n                    ""S3Uri"": ""s3://my_bucket/tmp/source1"",\n                }\n            },\n        },\n        {\n            ""ChannelName"": ""b"",\n            ""DataSource"": {\n                ""FileDataSource"": {\n                    ""FileDataDistributionType"": ""FullyReplicated"",\n                    ""FileUri"": ""file:///tmp/source1"",\n                }\n            },\n        },\n    ]\n    output_data_config = {}\n    resource_config = {""InstanceType"": ""local"", ""InstanceCount"": instance_count}\n    hyperparameters = {""a"": 1, ""b"": ""bee""}\n\n    local_sagemaker_client.create_training_job(\n        ""my-training-job"",\n        algo_spec,\n        output_data_config,\n        resource_config,\n        InputDataConfig=input_data_config,\n        HyperParameters=hyperparameters,\n    )\n\n    expected = {\n        ""ResourceConfig"": {""InstanceCount"": instance_count},\n        ""TrainingJobStatus"": ""Completed"",\n        ""ModelArtifacts"": {""S3ModelArtifacts"": ""/some/path/to/model""},\n    }\n\n    response = local_sagemaker_client.describe_training_job(""my-training-job"")\n\n    assert response[""TrainingJobStatus""] == expected[""TrainingJobStatus""]\n    assert (\n        response[""ResourceConfig""][""InstanceCount""] == expected[""ResourceConfig""][""InstanceCount""]\n    )\n    assert (\n        response[""ModelArtifacts""][""S3ModelArtifacts""]\n        == expected[""ModelArtifacts""][""S3ModelArtifacts""]\n    )\n\n\n@patch(""sagemaker.local.local_session.LocalSession"")\ndef test_describe_invalid_training_job(*args):\n    local_sagemaker_client = sagemaker.local.local_session.LocalSagemakerClient()\n    with pytest.raises(ClientError):\n        local_sagemaker_client.describe_training_job(""i-havent-created-this-job"")\n\n\n@patch(""sagemaker.local.image._SageMakerContainer.train"", return_value=""/some/path/to/model"")\n@patch(""sagemaker.local.local_session.LocalSession"")\ndef test_create_training_job_invalid_data_source(train, LocalSession):\n    local_sagemaker_client = sagemaker.local.local_session.LocalSagemakerClient()\n\n    instance_count = 2\n    image = ""my-docker-image:1.0""\n\n    algo_spec = {""TrainingImage"": image}\n\n    # InvalidDataSource is not supported. S3DataSource and FileDataSource are currently the only\n    # valid Data Sources. We expect a ValueError if we pass this input data config.\n    input_data_config = [\n        {\n            ""ChannelName"": ""a"",\n            ""DataSource"": {\n                ""InvalidDataSource"": {\n                    ""FileDataDistributionType"": ""FullyReplicated"",\n                    ""FileUri"": ""ftp://myserver.com/tmp/source1"",\n                }\n            },\n        }\n    ]\n\n    output_data_config = {}\n    resource_config = {""InstanceType"": ""local"", ""InstanceCount"": instance_count}\n    hyperparameters = {""a"": 1, ""b"": ""bee""}\n\n    with pytest.raises(ValueError):\n        local_sagemaker_client.create_training_job(\n            ""my-training-job"",\n            algo_spec,\n            output_data_config,\n            resource_config,\n            InputDataConfig=input_data_config,\n            HyperParameters=hyperparameters,\n        )\n\n\n@patch(""sagemaker.local.image._SageMakerContainer.train"", return_value=""/some/path/to/model"")\n@patch(""sagemaker.local.local_session.LocalSession"")\ndef test_create_training_job_not_fully_replicated(train, LocalSession):\n    local_sagemaker_client = sagemaker.local.local_session.LocalSagemakerClient()\n\n    instance_count = 2\n    image = ""my-docker-image:1.0""\n\n    algo_spec = {""TrainingImage"": image}\n\n    # Local Mode only supports FullyReplicated as Data Distribution type.\n    input_data_config = [\n        {\n            ""ChannelName"": ""a"",\n            ""DataSource"": {\n                ""S3DataSource"": {\n                    ""S3DataDistributionType"": ""ShardedByS3Key"",\n                    ""S3Uri"": ""s3://my_bucket/tmp/source1"",\n                }\n            },\n        }\n    ]\n\n    output_data_config = {}\n    resource_config = {""InstanceType"": ""local"", ""InstanceCount"": instance_count}\n    hyperparameters = {""a"": 1, ""b"": ""bee""}\n\n    with pytest.raises(RuntimeError):\n        local_sagemaker_client.create_training_job(\n            ""my-training-job"",\n            algo_spec,\n            output_data_config,\n            resource_config,\n            InputDataConfig=input_data_config,\n            HyperParameters=hyperparameters,\n        )\n\n\n@patch(""sagemaker.local.local_session.LocalSession"")\ndef test_create_model(LocalSession):\n    local_sagemaker_client = sagemaker.local.local_session.LocalSagemakerClient()\n\n    local_sagemaker_client.create_model(MODEL_NAME, PRIMARY_CONTAINER)\n\n    assert MODEL_NAME in sagemaker.local.local_session.LocalSagemakerClient._models\n\n\n@patch(""sagemaker.local.local_session.LocalSession"")\ndef test_delete_model(LocalSession):\n    local_sagemaker_client = sagemaker.local.local_session.LocalSagemakerClient()\n\n    local_sagemaker_client.create_model(MODEL_NAME, PRIMARY_CONTAINER)\n    assert MODEL_NAME in sagemaker.local.local_session.LocalSagemakerClient._models\n\n    local_sagemaker_client.delete_model(MODEL_NAME)\n    assert MODEL_NAME not in sagemaker.local.local_session.LocalSagemakerClient._models\n\n\n@patch(""sagemaker.local.local_session.LocalSession"")\ndef test_describe_model(LocalSession):\n    local_sagemaker_client = sagemaker.local.local_session.LocalSagemakerClient()\n\n    with pytest.raises(ClientError):\n        local_sagemaker_client.describe_model(""model-does-not-exist"")\n\n    local_sagemaker_client.create_model(MODEL_NAME, PRIMARY_CONTAINER)\n    response = local_sagemaker_client.describe_model(MODEL_NAME)\n\n    assert response[""ModelName""] == ""test-model""\n    assert response[""PrimaryContainer""][""ModelDataUrl""] == ""/some/model/path""\n\n\n@patch(""sagemaker.local.local_session._LocalTransformJob"")\n@patch(""sagemaker.local.local_session.LocalSession"")\ndef test_create_transform_job(LocalSession, _LocalTransformJob):\n    local_sagemaker_client = sagemaker.local.local_session.LocalSagemakerClient()\n\n    local_sagemaker_client.create_transform_job(""transform-job"", ""some-model"", None, None, None)\n    _LocalTransformJob().start.assert_called_with(None, None, None)\n\n    local_sagemaker_client.describe_transform_job(""transform-job"")\n    _LocalTransformJob().describe.assert_called()\n\n\n@patch(""sagemaker.local.local_session._LocalTransformJob"")\n@patch(""sagemaker.local.local_session.LocalSession"")\ndef test_describe_transform_job_does_not_exist(LocalSession, _LocalTransformJob):\n    local_sagemaker_client = sagemaker.local.local_session.LocalSagemakerClient()\n\n    with pytest.raises(ClientError):\n        local_sagemaker_client.describe_transform_job(""transform-job-does-not-exist"")\n\n\n@patch(""sagemaker.local.local_session.LocalSession"")\ndef test_describe_endpoint_config(LocalSession):\n    local_sagemaker_client = sagemaker.local.local_session.LocalSagemakerClient()\n\n    # No Endpoint Config Created\n    with pytest.raises(ClientError):\n        local_sagemaker_client.describe_endpoint_config(""some-endpoint-config"")\n\n    production_variants = [{""InstanceType"": ""ml.c4.99xlarge"", ""InitialInstanceCount"": 10}]\n    local_sagemaker_client.create_endpoint_config(""test-endpoint-config"", production_variants)\n\n    response = local_sagemaker_client.describe_endpoint_config(""test-endpoint-config"")\n    assert response[""EndpointConfigName""] == ""test-endpoint-config""\n    assert response[""ProductionVariants""][0][""InstanceType""] == ""ml.c4.99xlarge""\n\n\n@patch(""sagemaker.local.local_session.LocalSession"")\ndef test_create_endpoint_config(LocalSession):\n    local_sagemaker_client = sagemaker.local.local_session.LocalSagemakerClient()\n    local_sagemaker_client.create_endpoint_config(ENDPOINT_CONFIG_NAME, PRODUCTION_VARIANTS)\n\n    assert (\n        ENDPOINT_CONFIG_NAME in sagemaker.local.local_session.LocalSagemakerClient._endpoint_configs\n    )\n\n\n@patch(""sagemaker.local.local_session.LocalSession"")\ndef test_delete_endpoint_config(LocalSession):\n    local_sagemaker_client = sagemaker.local.local_session.LocalSagemakerClient()\n\n    local_sagemaker_client.create_endpoint_config(ENDPOINT_CONFIG_NAME, PRODUCTION_VARIANTS)\n    assert (\n        ENDPOINT_CONFIG_NAME in sagemaker.local.local_session.LocalSagemakerClient._endpoint_configs\n    )\n\n    local_sagemaker_client.delete_endpoint_config(ENDPOINT_CONFIG_NAME)\n    assert (\n        ENDPOINT_CONFIG_NAME\n        not in sagemaker.local.local_session.LocalSagemakerClient._endpoint_configs\n    )\n\n\n@patch(""sagemaker.local.image._SageMakerContainer.serve"")\n@patch(""sagemaker.local.local_session.LocalSession"")\n@patch(""urllib3.PoolManager.request"")\n@patch(""sagemaker.local.local_session.LocalSagemakerClient.describe_endpoint_config"")\n@patch(""sagemaker.local.local_session.LocalSagemakerClient.describe_model"")\ndef test_describe_endpoint(describe_model, describe_endpoint_config, request, *args):\n    local_sagemaker_client = sagemaker.local.local_session.LocalSagemakerClient()\n\n    request.return_value = OK_RESPONSE\n    describe_endpoint_config.return_value = {\n        ""EndpointConfigName"": ""name"",\n        ""EndpointConfigArn"": ""local:arn-does-not-matter"",\n        ""CreationTime"": ""00:00:00"",\n        ""ProductionVariants"": [\n            {\n                ""InitialVariantWeight"": 1.0,\n                ""ModelName"": ""my-model"",\n                ""VariantName"": ""AllTraffic"",\n                ""InitialInstanceCount"": 1,\n                ""InstanceType"": ""local"",\n            }\n        ],\n    }\n\n    describe_model.return_value = {\n        ""ModelName"": ""my-model"",\n        ""CreationTime"": ""00:00;00"",\n        ""ExecutionRoleArn"": ""local:arn-does-not-matter"",\n        ""ModelArn"": ""local:arn-does-not-matter"",\n        ""PrimaryContainer"": {\n            ""Environment"": {""SAGEMAKER_REGION"": ""us-west-2""},\n            ""Image"": ""123.dkr.ecr-us-west-2.amazonaws.com/sagemaker-container:1.0"",\n            ""ModelDataUrl"": ""s3://sagemaker-us-west-2/some/model.tar.gz"",\n        },\n    }\n\n    with pytest.raises(ClientError):\n        local_sagemaker_client.describe_endpoint(""non-existing-endpoint"")\n\n    local_sagemaker_client.create_endpoint(""test-endpoint"", ""some-endpoint-config"")\n    response = local_sagemaker_client.describe_endpoint(""test-endpoint"")\n\n    assert response[""EndpointName""] == ""test-endpoint""\n\n\n@patch(""sagemaker.local.image._SageMakerContainer.serve"")\n@patch(""sagemaker.local.local_session.LocalSession"")\n@patch(""urllib3.PoolManager.request"")\n@patch(""sagemaker.local.local_session.LocalSagemakerClient.describe_endpoint_config"")\n@patch(""sagemaker.local.local_session.LocalSagemakerClient.describe_model"")\ndef test_create_endpoint(describe_model, describe_endpoint_config, request, *args):\n    local_sagemaker_client = sagemaker.local.local_session.LocalSagemakerClient()\n\n    request.return_value = OK_RESPONSE\n    describe_endpoint_config.return_value = {\n        ""EndpointConfigName"": ""name"",\n        ""EndpointConfigArn"": ""local:arn-does-not-matter"",\n        ""CreationTime"": ""00:00:00"",\n        ""ProductionVariants"": [\n            {\n                ""InitialVariantWeight"": 1.0,\n                ""ModelName"": ""my-model"",\n                ""VariantName"": ""AllTraffic"",\n                ""InitialInstanceCount"": 1,\n                ""InstanceType"": ""local"",\n            }\n        ],\n    }\n\n    describe_model.return_value = {\n        ""ModelName"": ""my-model"",\n        ""CreationTime"": ""00:00;00"",\n        ""ExecutionRoleArn"": ""local:arn-does-not-matter"",\n        ""ModelArn"": ""local:arn-does-not-matter"",\n        ""PrimaryContainer"": {\n            ""Environment"": {""SAGEMAKER_REGION"": ""us-west-2""},\n            ""Image"": ""123.dkr.ecr-us-west-2.amazonaws.com/sagemaker-container:1.0"",\n            ""ModelDataUrl"": ""s3://sagemaker-us-west-2/some/model.tar.gz"",\n        },\n    }\n\n    local_sagemaker_client.create_endpoint(""my-endpoint"", ""some-endpoint-config"")\n\n    assert ""my-endpoint"" in sagemaker.local.local_session.LocalSagemakerClient._endpoints\n\n\n@patch(""sagemaker.local.local_session.LocalSession"")\ndef test_update_endpoint(LocalSession):\n    local_sagemaker_client = sagemaker.local.local_session.LocalSagemakerClient()\n    endpoint_name = ""my-endpoint""\n    endpoint_config = ""my-endpoint-config""\n    expected_error_message = ""Update endpoint name is not supported in local session.""\n    with pytest.raises(NotImplementedError, match=expected_error_message):\n        local_sagemaker_client.update_endpoint(endpoint_name, endpoint_config)\n\n\n@patch(""sagemaker.local.image._SageMakerContainer.serve"")\n@patch(""urllib3.PoolManager.request"")\ndef test_serve_endpoint_with_correct_accelerator(request, *args):\n    mock_session = Mock(name=""sagemaker_session"")\n    mock_session.return_value.sagemaker_client = Mock(name=""sagemaker_client"")\n    mock_session.config = None\n\n    request.return_value = OK_RESPONSE\n    mock_session.sagemaker_client.describe_endpoint_config.return_value = {\n        ""ProductionVariants"": [\n            {\n                ""ModelName"": ""my-model"",\n                ""InitialInstanceCount"": 1,\n                ""InstanceType"": ""local"",\n                ""AcceleratorType"": ""local_sagemaker_notebook"",\n            }\n        ]\n    }\n\n    mock_session.sagemaker_client.describe_model.return_value = {\n        ""PrimaryContainer"": {\n            ""Environment"": {},\n            ""Image"": ""123.dkr.ecr-us-west-2.amazonaws.com/sagemaker-container:1.0"",\n            ""ModelDataUrl"": ""s3://sagemaker-us-west-2/some/model.tar.gz"",\n        }\n    }\n\n    endpoint = sagemaker.local.local_session._LocalEndpoint(\n        ""my-endpoint"", ""some-endpoint-config"", local_session=mock_session\n    )\n    endpoint.serve()\n\n    assert (\n        endpoint.primary_container[""Environment""][""SAGEMAKER_INFERENCE_ACCELERATOR_PRESENT""]\n        == ""true""\n    )\n\n\n@patch(""sagemaker.local.image._SageMakerContainer.serve"")\n@patch(""urllib3.PoolManager.request"")\ndef test_serve_endpoint_with_incorrect_accelerator(request, *args):\n    mock_session = Mock(name=""sagemaker_session"")\n    mock_session.return_value.sagemaker_client = Mock(name=""sagemaker_client"")\n    mock_session.config = None\n\n    request.return_value = OK_RESPONSE\n    mock_session.sagemaker_client.describe_endpoint_config.return_value = {\n        ""ProductionVariants"": [\n            {\n                ""ModelName"": ""my-model"",\n                ""InitialInstanceCount"": 1,\n                ""InstanceType"": ""local"",\n                ""AcceleratorType"": ""local"",\n            }\n        ]\n    }\n\n    mock_session.sagemaker_client.describe_model.return_value = {\n        ""PrimaryContainer"": {\n            ""Environment"": {},\n            ""Image"": ""123.dkr.ecr-us-west-2.amazonaws.com/sagemaker-container:1.0"",\n            ""ModelDataUrl"": ""s3://sagemaker-us-west-2/some/model.tar.gz"",\n        }\n    }\n\n    endpoint = sagemaker.local.local_session._LocalEndpoint(\n        ""my-endpoint"", ""some-endpoint-config"", local_session=mock_session\n    )\n    endpoint.serve()\n\n    with pytest.raises(KeyError):\n        assert (\n            endpoint.primary_container[""Environment""][""SAGEMAKER_INFERENCE_ACCELERATOR_PRESENT""]\n            == ""true""\n        )\n\n\ndef test_file_input_all_defaults():\n    prefix = ""pre""\n    actual = sagemaker.local.local_session.file_input(fileUri=prefix)\n    expected = {\n        ""DataSource"": {\n            ""FileDataSource"": {""FileDataDistributionType"": ""FullyReplicated"", ""FileUri"": prefix}\n        }\n    }\n    assert actual.config == expected\n\n\ndef test_file_input_content_type():\n    prefix = ""pre""\n    actual = sagemaker.local.local_session.file_input(fileUri=prefix, content_type=""text/csv"")\n    expected = {\n        ""DataSource"": {\n            ""FileDataSource"": {""FileDataDistributionType"": ""FullyReplicated"", ""FileUri"": prefix}\n        },\n        ""ContentType"": ""text/csv"",\n    }\n    assert actual.config == expected\n\n\ndef test_local_session_is_set_to_local_mode():\n    boto_session = Mock(region_name=""us-west-2"")\n    local_session = sagemaker.local.local_session.LocalSession(boto_session=boto_session)\n    assert local_session.local_mode\n\n\n@pytest.fixture()\ndef sagemaker_session_custom_endpoint():\n\n    boto_session = Mock(""boto_session"")\n    resource_mock = Mock(""resource"")\n    client_mock = Mock(""client"")\n    boto_attrs = {""region_name"": ""us-east-1""}\n    boto_session.configure_mock(**boto_attrs)\n    boto_session.resource = Mock(name=""resource"", return_value=resource_mock)\n    boto_session.client = Mock(name=""client"", return_value=client_mock)\n\n    local_session = sagemaker.local.local_session.LocalSession(\n        boto_session=boto_session, s3_endpoint_url=ENDPOINT_URL\n    )\n\n    local_session.default_bucket = Mock(name=""default_bucket"", return_value=BUCKET_NAME)\n    return local_session\n\n\ndef test_local_session_with_custom_s3_endpoint_url(sagemaker_session_custom_endpoint):\n\n    boto_session = sagemaker_session_custom_endpoint.boto_session\n\n    boto_session.client.assert_called_with(""s3"", endpoint_url=ENDPOINT_URL)\n    boto_session.resource.assert_called_with(""s3"", endpoint_url=ENDPOINT_URL)\n\n    assert sagemaker_session_custom_endpoint.s3_client is not None\n    assert sagemaker_session_custom_endpoint.s3_resource is not None\n\n\ndef test_local_session_download_with_custom_s3_endpoint_url(sagemaker_session_custom_endpoint):\n\n    DOWNLOAD_DATA_TESTS_FILES_DIR = os.path.join(DATA_DIR, ""download_data_tests"")\n    sagemaker_session_custom_endpoint.s3_client.list_objects_v2 = Mock(\n        name=""list_objects_v2"", return_value=LS_FILES\n    )\n    sagemaker_session_custom_endpoint.s3_client.download_file = Mock(name=""download_file"")\n\n    sagemaker_session_custom_endpoint.download_data(\n        DOWNLOAD_DATA_TESTS_FILES_DIR, BUCKET_NAME, key_prefix=""/data/test.csv""\n    )\n\n    sagemaker_session_custom_endpoint.s3_client.download_file.assert_called_with(\n        Bucket=BUCKET_NAME,\n        Key=""/data/test.csv"",\n        Filename=""{}/{}"".format(DOWNLOAD_DATA_TESTS_FILES_DIR, ""test.csv""),\n        ExtraArgs=None,\n    )\n'"
tests/unit/test_local_utils.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport pytest\nfrom mock import patch, Mock\n\nimport sagemaker.local.utils\n\n\n@patch(""shutil.rmtree"", Mock())\n@patch(""sagemaker.local.utils.recursive_copy"")\ndef test_move_to_destination_local(recursive_copy):\n    # local files will just be recursively copied\n    sagemaker.local.utils.move_to_destination(""/tmp/data"", ""file:///target/dir/"", ""job"", None)\n    recursive_copy.assert_called_with(""/tmp/data"", ""/target/dir/"")\n\n\n@patch(""shutil.rmtree"", Mock())\n@patch(""sagemaker.local.utils.recursive_copy"")\ndef test_move_to_destination_s3(recursive_copy):\n    sms = Mock()\n\n    # without trailing slash in prefix\n    sagemaker.local.utils.move_to_destination(""/tmp/data"", ""s3://bucket/path"", ""job"", sms)\n    sms.upload_data.assert_called_with(""/tmp/data"", ""bucket"", ""path/job"")\n    recursive_copy.assert_not_called()\n\n    # with trailing slash in prefix\n    sagemaker.local.utils.move_to_destination(""/tmp/data"", ""s3://bucket/path/"", ""job"", sms)\n    sms.upload_data.assert_called_with(""/tmp/data"", ""bucket"", ""path/job"")\n\n    # without path, with trailing slash\n    sagemaker.local.utils.move_to_destination(""/tmp/data"", ""s3://bucket/"", ""job"", sms)\n    sms.upload_data.assert_called_with(""/tmp/data"", ""bucket"", ""job"")\n\n    # without path, without trailing slash\n    sagemaker.local.utils.move_to_destination(""/tmp/data"", ""s3://bucket"", ""job"", sms)\n    sms.upload_data.assert_called_with(""/tmp/data"", ""bucket"", ""job"")\n\n\ndef test_move_to_destination_illegal_destination():\n    with pytest.raises(ValueError):\n        sagemaker.local.utils.move_to_destination(""/tmp/data"", ""ftp://ftp/in/2018"", ""job"", None)\n'"
tests/unit/test_multidatamodel.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport os\nimport pytest\nfrom mock import MagicMock, Mock, call, patch\n\nfrom sagemaker.multidatamodel import MULTI_MODEL_CONTAINER_MODE\nfrom sagemaker.multidatamodel import MultiDataModel\nfrom sagemaker.mxnet import MXNetModel, MXNetPredictor\n\nENDPOINT_DESC = {""EndpointConfigName"": ""test-endpoint""}\nENDPOINT_CONFIG_DESC = {""ProductionVariants"": [{""ModelName"": ""model-1""}]}\n\nENTRY_POINT = ""mock.py""\nMXNET_MODEL_DATA = ""s3://mybucket/mxnet_path/model.tar.gz""\nMXNET_MODEL_NAME = ""dummy-mxnet-model""\nMXNET_ROLE = ""DummyMXNetRole""\nMXNET_IMAGE = ""520713654638.dkr.ecr.us-west-2.amazonaws.com/sagemaker-mxnet:1.2-cpu-py2""\n\nDATA_DIR = os.path.join(os.path.dirname(__file__), "".."", ""data"")\nIMAGE = ""123456789012.dkr.ecr.dummyregion.amazonaws.com/dummyimage:latest""\nREGION = ""us-west-2""\nROLE = ""DummyRole""\nMODEL_NAME = ""dummy-model""\nVALID_MULTI_MODEL_DATA_PREFIX = ""s3://mybucket/path/""\nINVALID_S3_URL = ""https://my-training-bucket.s3.myregion.amazonaws.com/output/model.tar.gz""\nVALID_S3_URL = ""s3://my-training-bucket/output/model.tar.gz""\nS3_URL_SOURCE_BUCKET = ""my-training-bucket""\nS3_URL_SOURCE_PREFIX = ""output/model.tar.gz""\nDST_BUCKET = ""mybucket""\n\nMULTI_MODEL_ENDPOINT_NAME = ""multimodel-endpoint""\nINSTANCE_COUNT = 1\nINSTANCE_TYPE = ""ml.c4.4xlarge""\nEXPECTED_PROD_VARIANT = [\n    {\n        ""InitialVariantWeight"": 1,\n        ""InitialInstanceCount"": INSTANCE_COUNT,\n        ""InstanceType"": INSTANCE_TYPE,\n        ""ModelName"": MODEL_NAME,\n        ""VariantName"": ""AllTraffic"",\n    }\n]\n\n\n@pytest.fixture()\ndef sagemaker_session():\n    boto_mock = Mock(name=""boto_session"", region_name=REGION)\n    session = Mock(\n        name=""sagemaker_session"",\n        boto_session=boto_mock,\n        boto_region_name=REGION,\n        config=None,\n        local_mode=False,\n        s3_resource=None,\n        s3_client=None,\n    )\n    session.sagemaker_client.describe_endpoint = Mock(return_value=ENDPOINT_DESC)\n    session.sagemaker_client.describe_endpoint_config = Mock(return_value=ENDPOINT_CONFIG_DESC)\n    session.list_s3_files(\n        bucket=S3_URL_SOURCE_BUCKET, key_prefix=S3_URL_SOURCE_PREFIX\n    ).return_value = Mock()\n    session.upload_data = Mock(\n        name=""upload_data"",\n        return_value=os.path.join(VALID_MULTI_MODEL_DATA_PREFIX, ""mleap_model.tar.gz""),\n    )\n\n    s3_mock = Mock()\n    boto_mock.client(""s3"").return_value = s3_mock\n    boto_mock.client(""s3"").get_paginator(""list_objects_v2"").paginate.return_value = Mock()\n    s3_mock.reset_mock()\n\n    return session\n\n\n@pytest.fixture()\ndef multi_data_model(sagemaker_session):\n    return MultiDataModel(\n        name=MODEL_NAME,\n        model_data_prefix=VALID_MULTI_MODEL_DATA_PREFIX,\n        image=IMAGE,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n    )\n\n\n@pytest.fixture()\ndef mxnet_model(sagemaker_session):\n    return MXNetModel(\n        MXNET_MODEL_DATA,\n        role=MXNET_ROLE,\n        entry_point=ENTRY_POINT,\n        sagemaker_session=sagemaker_session,\n        name=MXNET_MODEL_NAME,\n        enable_network_isolation=True,\n    )\n\n\ndef test_multi_data_model_create_with_invalid_model_data_prefix():\n    invalid_model_data_prefix = ""https://mybucket/path/""\n    with pytest.raises(ValueError) as ex:\n        MultiDataModel(\n            name=MODEL_NAME, model_data_prefix=invalid_model_data_prefix, image=IMAGE, role=ROLE\n        )\n    err_msg = \'ValueError: Expecting S3 model prefix beginning with ""s3://"". Received: ""{}""\'.format(\n        invalid_model_data_prefix\n    )\n    assert err_msg in str(ex)\n\n\ndef test_multi_data_model_create_with_invalid_arguments(sagemaker_session, mxnet_model):\n    with pytest.raises(ValueError) as ex:\n        MultiDataModel(\n            name=MODEL_NAME,\n            model_data_prefix=VALID_MULTI_MODEL_DATA_PREFIX,\n            image=IMAGE,\n            role=ROLE,\n            sagemaker_session=sagemaker_session,\n            model=mxnet_model,\n        )\n    assert (\n        ""Parameters image, role or kwargs are not permitted when model parameter is passed.""\n        in str(ex)\n    )\n\n\ndef test_multi_data_model_create(sagemaker_session):\n    model = MultiDataModel(\n        name=MODEL_NAME,\n        model_data_prefix=VALID_MULTI_MODEL_DATA_PREFIX,\n        image=IMAGE,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n    )\n\n    assert model.sagemaker_session == sagemaker_session\n    assert model.name == MODEL_NAME\n    assert model.model_data_prefix == VALID_MULTI_MODEL_DATA_PREFIX\n    assert model.role == ROLE\n    assert model.image == IMAGE\n    assert model.vpc_config is None\n\n\n@patch(""sagemaker.multidatamodel.Session"", MagicMock())\ndef test_multi_data_model_create_with_model_arg_only(mxnet_model):\n    model = MultiDataModel(\n        name=MODEL_NAME, model_data_prefix=VALID_MULTI_MODEL_DATA_PREFIX, model=mxnet_model\n    )\n\n    assert model.model_data_prefix == VALID_MULTI_MODEL_DATA_PREFIX\n    assert model.model == mxnet_model\n    assert hasattr(model, ""role"") is False\n    assert hasattr(model, ""image"") is False\n\n\n@patch(""sagemaker.fw_utils.tar_and_upload_dir"", MagicMock())\ndef test_prepare_container_def_mxnet(sagemaker_session, mxnet_model):\n    expected_container_env_keys = [\n        ""SAGEMAKER_CONTAINER_LOG_LEVEL"",\n        ""SAGEMAKER_ENABLE_CLOUDWATCH_METRICS"",\n        ""SAGEMAKER_PROGRAM"",\n        ""SAGEMAKER_REGION"",\n        ""SAGEMAKER_SUBMIT_DIRECTORY"",\n    ]\n    model = MultiDataModel(\n        name=MODEL_NAME,\n        model_data_prefix=VALID_MULTI_MODEL_DATA_PREFIX,\n        sagemaker_session=sagemaker_session,\n        model=mxnet_model,\n    )\n\n    container_def = model.prepare_container_def(INSTANCE_TYPE)\n\n    assert container_def[""Image""] == MXNET_IMAGE\n    assert container_def[""ModelDataUrl""] == VALID_MULTI_MODEL_DATA_PREFIX\n    assert container_def[""Mode""] == MULTI_MODEL_CONTAINER_MODE\n    # Check if the environment variables defined only for MXNetModel\n    # are part of the MultiDataModel container definition\n    assert set(container_def[""Environment""].keys()) == set(expected_container_env_keys)\n\n\n@patch(""sagemaker.fw_utils.tar_and_upload_dir"", MagicMock())\ndef test_deploy_multi_data_model(sagemaker_session):\n    model = MultiDataModel(\n        name=MODEL_NAME,\n        model_data_prefix=VALID_MULTI_MODEL_DATA_PREFIX,\n        image=IMAGE,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        env={""EXTRA_ENV_MOCK"": ""MockValue""},\n    )\n    model.deploy(\n        initial_instance_count=INSTANCE_COUNT,\n        instance_type=INSTANCE_TYPE,\n        endpoint_name=MULTI_MODEL_ENDPOINT_NAME,\n    )\n\n    sagemaker_session.create_model.assert_called_with(\n        MODEL_NAME,\n        ROLE,\n        model.prepare_container_def(INSTANCE_TYPE),\n        vpc_config=None,\n        enable_network_isolation=False,\n        tags=None,\n    )\n    sagemaker_session.endpoint_from_production_variants.assert_called_with(\n        name=MULTI_MODEL_ENDPOINT_NAME,\n        wait=True,\n        tags=None,\n        kms_key=None,\n        data_capture_config_dict=None,\n        production_variants=EXPECTED_PROD_VARIANT,\n    )\n\n\n@patch(""sagemaker.fw_utils.tar_and_upload_dir"", MagicMock())\ndef test_deploy_multi_data_framework_model(sagemaker_session, mxnet_model):\n    model = MultiDataModel(\n        name=MODEL_NAME,\n        model_data_prefix=VALID_MULTI_MODEL_DATA_PREFIX,\n        sagemaker_session=sagemaker_session,\n        model=mxnet_model,\n    )\n\n    predictor = model.deploy(\n        initial_instance_count=INSTANCE_COUNT,\n        instance_type=INSTANCE_TYPE,\n        endpoint_name=MULTI_MODEL_ENDPOINT_NAME,\n    )\n\n    # Assert if this is called with mxnet_model parameters\n    sagemaker_session.create_model.assert_called_with(\n        MODEL_NAME,\n        MXNET_ROLE,\n        model.prepare_container_def(INSTANCE_TYPE),\n        vpc_config=None,\n        enable_network_isolation=True,\n        tags=None,\n    )\n    sagemaker_session.endpoint_from_production_variants.assert_called_with(\n        name=MULTI_MODEL_ENDPOINT_NAME,\n        wait=True,\n        tags=None,\n        kms_key=None,\n        data_capture_config_dict=None,\n        production_variants=EXPECTED_PROD_VARIANT,\n    )\n    sagemaker_session.create_endpoint_config.assert_not_called()\n    assert isinstance(predictor, MXNetPredictor)\n\n\n@patch(""sagemaker.fw_utils.tar_and_upload_dir"", MagicMock())\ndef test_deploy_model_update(sagemaker_session):\n    model = MultiDataModel(\n        name=MODEL_NAME,\n        model_data_prefix=VALID_MULTI_MODEL_DATA_PREFIX,\n        image=IMAGE,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n    )\n\n    model.deploy(\n        initial_instance_count=INSTANCE_COUNT,\n        instance_type=INSTANCE_TYPE,\n        endpoint_name=MULTI_MODEL_ENDPOINT_NAME,\n        update_endpoint=True,\n    )\n\n    sagemaker_session.create_model.assert_called()\n    sagemaker_session.create_endpoint_config.assert_called_with(\n        name=model.name,\n        model_name=model.name,\n        initial_instance_count=INSTANCE_COUNT,\n        instance_type=INSTANCE_TYPE,\n        accelerator_type=None,\n        tags=None,\n        kms_key=None,\n        data_capture_config_dict=None,\n    )\n\n    config_name = sagemaker_session.create_endpoint_config(\n        name=model.name,\n        model_name=model.name,\n        initial_instance_count=INSTANCE_COUNT,\n        instance_type=INSTANCE_TYPE,\n        accelerator_type=None,\n    )\n    sagemaker_session.update_endpoint.assert_called_with(\n        MULTI_MODEL_ENDPOINT_NAME, config_name, wait=True\n    )\n    sagemaker_session.create_endpoint.assert_not_called()\n\n\ndef test_add_model_local_file_path(multi_data_model):\n    valid_local_model_artifact_path = os.path.join(DATA_DIR, ""sparkml_model"", ""mleap_model.tar.gz"")\n    uploaded_s3_path = multi_data_model.add_model(valid_local_model_artifact_path)\n\n    assert uploaded_s3_path == os.path.join(VALID_MULTI_MODEL_DATA_PREFIX, ""mleap_model.tar.gz"")\n\n\ndef test_add_model_s3_path(multi_data_model):\n    uploaded_s3_path = multi_data_model.add_model(VALID_S3_URL)\n\n    assert uploaded_s3_path == os.path.join(VALID_MULTI_MODEL_DATA_PREFIX, ""output/model.tar.gz"")\n    multi_data_model.s3_client.copy.assert_called()\n    calls = [\n        call(\n            {""Bucket"": S3_URL_SOURCE_BUCKET, ""Key"": S3_URL_SOURCE_PREFIX},\n            DST_BUCKET,\n            ""path/output/model.tar.gz"",\n        )\n    ]\n    multi_data_model.s3_client.copy.assert_has_calls(calls)\n\n\ndef test_add_model_with_dst_path(multi_data_model):\n    uploaded_s3_path = multi_data_model.add_model(VALID_S3_URL, ""customer-a/model.tar.gz"")\n\n    assert uploaded_s3_path == os.path.join(\n        VALID_MULTI_MODEL_DATA_PREFIX, ""customer-a/model.tar.gz""\n    )\n    multi_data_model.s3_client.copy.assert_called()\n    calls = [\n        call(\n            {""Bucket"": S3_URL_SOURCE_BUCKET, ""Key"": S3_URL_SOURCE_PREFIX},\n            DST_BUCKET,\n            ""path/customer-a/model.tar.gz"",\n        )\n    ]\n    multi_data_model.s3_client.copy.assert_has_calls(calls)\n\n\ndef test_add_model_with_invalid_model_uri(multi_data_model):\n    with pytest.raises(ValueError) as ex:\n        multi_data_model.add_model(INVALID_S3_URL)\n\n    assert \'ValueError: model_source must either be a valid local file path or s3 uri. Received: ""{}""\'.format(\n        INVALID_S3_URL\n    ) in str(\n        ex\n    )\n\n\ndef test_list_models(multi_data_model):\n    multi_data_model.list_models()\n\n    multi_data_model.sagemaker_session.list_s3_files.assert_called()\n    assert multi_data_model.sagemaker_session.list_s3_files.called_with(\n        Bucket=S3_URL_SOURCE_BUCKET, Prefix=S3_URL_SOURCE_PREFIX\n    )\n'"
tests/unit/test_mxnet.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport logging\n\nimport json\nimport os\nimport pytest\nfrom mock import MagicMock, Mock\nfrom mock import patch\nfrom pkg_resources import parse_version\n\nfrom sagemaker.fw_utils import UploadedCode\nfrom sagemaker.mxnet import defaults\nfrom sagemaker.mxnet import MXNet\nfrom sagemaker.mxnet import MXNetPredictor, MXNetModel\n\nDATA_DIR = os.path.join(os.path.dirname(__file__), "".."", ""data"")\nSCRIPT_PATH = os.path.join(DATA_DIR, ""dummy_script.py"")\nSERVING_SCRIPT_FILE = ""another_dummy_script.py""\nMODEL_DATA = ""s3://mybucket/model""\nENV = {""DUMMY_ENV_VAR"": ""dummy_value""}\nTIMESTAMP = ""2017-11-06-14:14:15.672""\nTIME = 1507167947\nBUCKET_NAME = ""mybucket""\nINSTANCE_COUNT = 1\nINSTANCE_TYPE = ""ml.c4.4xlarge""\nACCELERATOR_TYPE = ""ml.eia.medium""\nIMAGE_REPO_NAME = ""sagemaker-mxnet""\nIMAGE_REPO_SERVING_NAME = ""sagemaker-mxnet-serving""\nJOB_NAME = ""{}-{}"".format(IMAGE_REPO_NAME, TIMESTAMP)\nCOMPILATION_JOB_NAME = ""{}-{}"".format(""compilation-sagemaker-mxnet"", TIMESTAMP)\nFRAMEWORK = ""mxnet""\nFULL_IMAGE_URI = ""520713654638.dkr.ecr.us-west-2.amazonaws.com/{}:{}-{}-{}""\nROLE = ""Dummy""\nREGION = ""us-west-2""\nGPU = ""ml.p2.xlarge""\nCPU = ""ml.c4.xlarge""\nCPU_C5 = ""ml.c5.xlarge""\nLAUNCH_PS_DISTRIBUTIONS_DICT = {""parameter_server"": {""enabled"": True}}\n\nENDPOINT_DESC = {""EndpointConfigName"": ""test-endpoint""}\n\nENDPOINT_CONFIG_DESC = {""ProductionVariants"": [{""ModelName"": ""model-1""}, {""ModelName"": ""model-2""}]}\n\nLIST_TAGS_RESULT = {""Tags"": [{""Key"": ""TagtestKey"", ""Value"": ""TagtestValue""}]}\n\nEXPERIMENT_CONFIG = {\n    ""ExperimentName"": ""exp"",\n    ""TrialName"": ""trial"",\n    ""TrialComponentDisplayName"": ""tc"",\n}\n\n\n@pytest.fixture()\ndef sagemaker_session():\n    boto_mock = Mock(name=""boto_session"", region_name=REGION)\n    session = Mock(\n        name=""sagemaker_session"",\n        boto_session=boto_mock,\n        boto_region_name=REGION,\n        config=None,\n        local_mode=False,\n        s3_resource=None,\n        s3_client=None,\n    )\n\n    describe = {""ModelArtifacts"": {""S3ModelArtifacts"": ""s3://m/m.tar.gz""}}\n    describe_compilation = {""ModelArtifacts"": {""S3ModelArtifacts"": ""s3://m/model_c5.tar.gz""}}\n    session.sagemaker_client.describe_training_job = Mock(return_value=describe)\n    session.sagemaker_client.describe_endpoint = Mock(return_value=ENDPOINT_DESC)\n    session.sagemaker_client.describe_endpoint_config = Mock(return_value=ENDPOINT_CONFIG_DESC)\n    session.sagemaker_client.list_tags = Mock(return_value=LIST_TAGS_RESULT)\n    session.wait_for_compilation_job = Mock(return_value=describe_compilation)\n    session.default_bucket = Mock(name=""default_bucket"", return_value=BUCKET_NAME)\n    session.expand_role = Mock(name=""expand_role"", return_value=ROLE)\n    return session\n\n\n@pytest.fixture()\ndef skip_if_mms_version(mxnet_version):\n    if parse_version(MXNetModel._LOWEST_MMS_VERSION) <= parse_version(mxnet_version):\n        pytest.skip(""Skipping because this version uses MMS"")\n\n\n@pytest.fixture()\ndef skip_if_not_mms_version(mxnet_version):\n    if parse_version(MXNetModel._LOWEST_MMS_VERSION) > parse_version(mxnet_version):\n        pytest.skip(""Skipping because this version does not use MMS"")\n\n\ndef _get_full_image_uri(version, repo=IMAGE_REPO_NAME, processor=""cpu"", py_version=""py2""):\n    return FULL_IMAGE_URI.format(repo, version, processor, py_version)\n\n\ndef _get_full_image_uri_with_ei(version, repo=IMAGE_REPO_NAME, processor=""cpu"", py_version=""py2""):\n    return FULL_IMAGE_URI.format(""{}-eia"".format(repo), version, processor, py_version)\n\n\ndef _create_train_job(version):\n    return {\n        ""image"": _get_full_image_uri(version),\n        ""input_mode"": ""File"",\n        ""input_config"": [\n            {\n                ""ChannelName"": ""training"",\n                ""DataSource"": {\n                    ""S3DataSource"": {\n                        ""S3DataDistributionType"": ""FullyReplicated"",\n                        ""S3DataType"": ""S3Prefix"",\n                    }\n                },\n            }\n        ],\n        ""role"": ROLE,\n        ""job_name"": JOB_NAME,\n        ""output_config"": {""S3OutputPath"": ""s3://{}/"".format(BUCKET_NAME)},\n        ""resource_config"": {\n            ""InstanceType"": ""ml.c4.4xlarge"",\n            ""InstanceCount"": 1,\n            ""VolumeSizeInGB"": 30,\n        },\n        ""hyperparameters"": {\n            ""sagemaker_program"": json.dumps(""dummy_script.py""),\n            ""sagemaker_enable_cloudwatch_metrics"": ""false"",\n            ""sagemaker_container_log_level"": str(logging.INFO),\n            ""sagemaker_job_name"": json.dumps(JOB_NAME),\n            ""sagemaker_submit_directory"": json.dumps(\n                ""s3://{}/{}/source/sourcedir.tar.gz"".format(BUCKET_NAME, JOB_NAME)\n            ),\n            ""sagemaker_region"": \'""us-west-2""\',\n        },\n        ""stop_condition"": {""MaxRuntimeInSeconds"": 24 * 60 * 60},\n        ""tags"": None,\n        ""vpc_config"": None,\n        ""metric_definitions"": None,\n        ""experiment_config"": None,\n        ""debugger_hook_config"": {\n            ""CollectionConfigurations"": [],\n            ""S3OutputPath"": ""s3://{}/"".format(BUCKET_NAME),\n        },\n    }\n\n\ndef _create_compilation_job(input_shape, output_location):\n    return {\n        ""input_model_config"": {\n            ""DataInputConfig"": input_shape,\n            ""Framework"": FRAMEWORK.upper(),\n            ""S3Uri"": ""s3://m/m.tar.gz"",\n        },\n        ""job_name"": COMPILATION_JOB_NAME,\n        ""output_model_config"": {""S3OutputLocation"": output_location, ""TargetDevice"": ""ml_c4""},\n        ""role"": ROLE,\n        ""stop_condition"": {""MaxRuntimeInSeconds"": 900},\n        ""tags"": None,\n    }\n\n\ndef _neo_inference_image(mxnet_version):\n    return ""301217895009.dkr.ecr.us-west-2.amazonaws.com/sagemaker-neo-{}:{}-cpu-py3"".format(\n        FRAMEWORK.lower(), mxnet_version\n    )\n\n\n@patch(""sagemaker.utils.create_tar_file"", MagicMock())\ndef test_create_model(sagemaker_session, mxnet_version):\n    container_log_level = \'""logging.INFO""\'\n    source_dir = ""s3://mybucket/source""\n    mx = MXNet(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        framework_version=mxnet_version,\n        container_log_level=container_log_level,\n        base_job_name=""job"",\n        source_dir=source_dir,\n    )\n\n    job_name = ""new_name""\n    mx.fit(inputs=""s3://mybucket/train"", job_name=job_name)\n    model = mx.create_model()\n\n    assert model.sagemaker_session == sagemaker_session\n    assert model.framework_version == mxnet_version\n    assert model.py_version == mx.py_version\n    assert model.entry_point == SCRIPT_PATH\n    assert model.role == ROLE\n    assert model.name == job_name\n    assert model.container_log_level == container_log_level\n    assert model.source_dir == source_dir\n    assert model.image is None\n    assert model.vpc_config is None\n\n\ndef test_create_model_with_optional_params(sagemaker_session):\n    container_log_level = \'""logging.INFO""\'\n    source_dir = ""s3://mybucket/source""\n    enable_cloudwatch_metrics = ""true""\n    mx = MXNet(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        container_log_level=container_log_level,\n        base_job_name=""job"",\n        source_dir=source_dir,\n        enable_cloudwatch_metrics=enable_cloudwatch_metrics,\n    )\n\n    mx.fit(inputs=""s3://mybucket/train"", job_name=""new_name"")\n\n    new_role = ""role""\n    model_server_workers = 2\n    vpc_config = {""Subnets"": [""foo""], ""SecurityGroupIds"": [""bar""]}\n    model_name = ""model-name""\n    model = mx.create_model(\n        role=new_role,\n        model_server_workers=model_server_workers,\n        vpc_config_override=vpc_config,\n        entry_point=SERVING_SCRIPT_FILE,\n        env=ENV,\n        name=model_name,\n    )\n\n    assert model.role == new_role\n    assert model.model_server_workers == model_server_workers\n    assert model.vpc_config == vpc_config\n    assert model.entry_point == SERVING_SCRIPT_FILE\n    assert model.env == ENV\n    assert model.name == model_name\n\n\ndef test_create_model_with_custom_image(sagemaker_session):\n    container_log_level = \'""logging.INFO""\'\n    source_dir = ""s3://mybucket/source""\n    custom_image = ""mxnet:2.0""\n    mx = MXNet(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        image_name=custom_image,\n        container_log_level=container_log_level,\n        base_job_name=""job"",\n        source_dir=source_dir,\n    )\n\n    job_name = ""new_name""\n    mx.fit(inputs=""s3://mybucket/train"", job_name=""new_name"")\n    model = mx.create_model()\n\n    assert model.sagemaker_session == sagemaker_session\n    assert model.image == custom_image\n    assert model.entry_point == SCRIPT_PATH\n    assert model.role == ROLE\n    assert model.name == job_name\n    assert model.container_log_level == container_log_level\n    assert model.source_dir == source_dir\n\n\n@patch(""sagemaker.utils.create_tar_file"", MagicMock())\n@patch(""time.strftime"", return_value=TIMESTAMP)\ndef test_mxnet(strftime, sagemaker_session, mxnet_version, skip_if_mms_version):\n    mx = MXNet(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        framework_version=mxnet_version,\n    )\n\n    inputs = ""s3://mybucket/train""\n\n    mx.fit(inputs=inputs, experiment_config=EXPERIMENT_CONFIG)\n\n    sagemaker_call_names = [c[0] for c in sagemaker_session.method_calls]\n    assert sagemaker_call_names == [""train"", ""logs_for_job""]\n    boto_call_names = [c[0] for c in sagemaker_session.boto_session.method_calls]\n    assert boto_call_names == [""resource""]\n\n    expected_train_args = _create_train_job(mxnet_version)\n    expected_train_args[""input_config""][0][""DataSource""][""S3DataSource""][""S3Uri""] = inputs\n    expected_train_args[""experiment_config""] = EXPERIMENT_CONFIG\n\n    actual_train_args = sagemaker_session.method_calls[0][2]\n    assert actual_train_args == expected_train_args\n\n    model = mx.create_model()\n\n    expected_image_base = ""520713654638.dkr.ecr.us-west-2.amazonaws.com/sagemaker-mxnet:{}-gpu-py2""\n    environment = {\n        ""Environment"": {\n            ""SAGEMAKER_SUBMIT_DIRECTORY"": ""s3://mybucket/sagemaker-mxnet-{}/source/sourcedir.tar.gz"".format(\n                TIMESTAMP\n            ),\n            ""SAGEMAKER_PROGRAM"": ""dummy_script.py"",\n            ""SAGEMAKER_ENABLE_CLOUDWATCH_METRICS"": ""false"",\n            ""SAGEMAKER_REGION"": ""us-west-2"",\n            ""SAGEMAKER_CONTAINER_LOG_LEVEL"": ""20"",\n        },\n        ""Image"": expected_image_base.format(mxnet_version),\n        ""ModelDataUrl"": ""s3://m/m.tar.gz"",\n    }\n    assert environment == model.prepare_container_def(GPU)\n\n    assert ""cpu"" in model.prepare_container_def(CPU)[""Image""]\n    predictor = mx.deploy(1, GPU)\n    assert isinstance(predictor, MXNetPredictor)\n\n\n@patch(""sagemaker.utils.repack_model"")\n@patch(""time.strftime"", return_value=TIMESTAMP)\ndef test_mxnet_mms_version(\n    strftime, repack_model, sagemaker_session, mxnet_version, skip_if_not_mms_version\n):\n    mx = MXNet(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        framework_version=mxnet_version,\n    )\n\n    inputs = ""s3://mybucket/train""\n\n    mx.fit(inputs=inputs)\n\n    sagemaker_call_names = [c[0] for c in sagemaker_session.method_calls]\n    assert sagemaker_call_names == [""train"", ""logs_for_job""]\n    boto_call_names = [c[0] for c in sagemaker_session.boto_session.method_calls]\n    assert boto_call_names == [""resource""]\n\n    expected_train_args = _create_train_job(mxnet_version)\n    expected_train_args[""input_config""][0][""DataSource""][""S3DataSource""][""S3Uri""] = inputs\n\n    actual_train_args = sagemaker_session.method_calls[0][2]\n    assert actual_train_args == expected_train_args\n\n    model = mx.create_model()\n\n    expected_image_base = _get_full_image_uri(mxnet_version, IMAGE_REPO_SERVING_NAME, ""gpu"")\n\n    environment = {\n        ""Environment"": {\n            ""SAGEMAKER_SUBMIT_DIRECTORY"": ""s3://mybucket/sagemaker-mxnet-2017-11-06-14:14:15.672/model.tar.gz"",\n            ""SAGEMAKER_PROGRAM"": ""dummy_script.py"",\n            ""SAGEMAKER_ENABLE_CLOUDWATCH_METRICS"": ""false"",\n            ""SAGEMAKER_REGION"": ""us-west-2"",\n            ""SAGEMAKER_CONTAINER_LOG_LEVEL"": ""20"",\n        },\n        ""Image"": expected_image_base.format(mxnet_version),\n        ""ModelDataUrl"": ""s3://mybucket/sagemaker-mxnet-2017-11-06-14:14:15.672/model.tar.gz"",\n    }\n    assert environment == model.prepare_container_def(GPU)\n\n    assert ""cpu"" in model.prepare_container_def(CPU)[""Image""]\n    predictor = mx.deploy(1, GPU)\n    assert isinstance(predictor, MXNetPredictor)\n\n\n@patch(""sagemaker.utils.create_tar_file"", MagicMock())\n@patch(""time.strftime"", return_value=TIMESTAMP)\ndef test_mxnet_neo(strftime, sagemaker_session, mxnet_version, skip_if_mms_version):\n    mx = MXNet(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        framework_version=mxnet_version,\n    )\n\n    inputs = ""s3://mybucket/train""\n\n    mx.fit(inputs=inputs)\n\n    input_shape = {""data"": [100, 1, 28, 28]}\n    output_location = ""s3://neo-sdk-test""\n\n    compiled_model = mx.compile_model(\n        target_instance_family=""ml_c4"", input_shape=input_shape, output_path=output_location\n    )\n\n    sagemaker_call_names = [c[0] for c in sagemaker_session.method_calls]\n    assert sagemaker_call_names == [\n        ""train"",\n        ""logs_for_job"",\n        ""sagemaker_client.describe_training_job"",\n        ""compile_model"",\n        ""wait_for_compilation_job"",\n    ]\n\n    expected_compile_model_args = _create_compilation_job(json.dumps(input_shape), output_location)\n    actual_compile_model_args = sagemaker_session.method_calls[3][2]\n    assert expected_compile_model_args == actual_compile_model_args\n\n    assert compiled_model.image == _neo_inference_image(mxnet_version)\n\n    predictor = mx.deploy(1, CPU, use_compiled_model=True)\n    assert isinstance(predictor, MXNetPredictor)\n\n    with pytest.raises(Exception) as wrong_target:\n        mx.deploy(1, CPU_C5, use_compiled_model=True)\n    assert str(wrong_target.value).startswith(""No compiled model for"")\n\n    # deploy without sagemaker Neo should continue to work\n    mx.deploy(1, CPU)\n\n\n@patch(""sagemaker.utils.create_tar_file"", MagicMock())\ndef test_model(sagemaker_session):\n    model = MXNetModel(\n        MODEL_DATA, role=ROLE, entry_point=SCRIPT_PATH, sagemaker_session=sagemaker_session\n    )\n    predictor = model.deploy(1, GPU)\n    assert isinstance(predictor, MXNetPredictor)\n\n\n@patch(""sagemaker.utils.repack_model"")\ndef test_model_mms_version(repack_model, sagemaker_session):\n    model_kms_key = ""kms-key""\n    model = MXNetModel(\n        MODEL_DATA,\n        role=ROLE,\n        entry_point=SCRIPT_PATH,\n        framework_version=MXNetModel._LOWEST_MMS_VERSION,\n        sagemaker_session=sagemaker_session,\n        name=""test-mxnet-model"",\n        model_kms_key=model_kms_key,\n    )\n    predictor = model.deploy(1, GPU)\n\n    repack_model.assert_called_once_with(\n        inference_script=SCRIPT_PATH,\n        source_directory=None,\n        dependencies=[],\n        model_uri=MODEL_DATA,\n        repacked_model_uri=""s3://mybucket/test-mxnet-model/model.tar.gz"",\n        sagemaker_session=sagemaker_session,\n        kms_key=model_kms_key,\n    )\n\n    assert model.model_data == MODEL_DATA\n    assert model.repacked_model_data == ""s3://mybucket/test-mxnet-model/model.tar.gz""\n    assert model.uploaded_code == UploadedCode(\n        s3_prefix=""s3://mybucket/test-mxnet-model/model.tar.gz"",\n        script_name=os.path.basename(SCRIPT_PATH),\n    )\n    assert isinstance(predictor, MXNetPredictor)\n\n\n@patch(""sagemaker.fw_utils.tar_and_upload_dir"", MagicMock())\ndef test_model_image_accelerator(sagemaker_session):\n    model = MXNetModel(\n        MODEL_DATA, role=ROLE, entry_point=SCRIPT_PATH, sagemaker_session=sagemaker_session\n    )\n    container_def = model.prepare_container_def(INSTANCE_TYPE, accelerator_type=ACCELERATOR_TYPE)\n    assert container_def[""Image""] == _get_full_image_uri_with_ei(defaults.MXNET_VERSION)\n\n\n@patch(""sagemaker.utils.repack_model"", MagicMock())\ndef test_model_image_accelerator_mms_version(sagemaker_session):\n    model = MXNetModel(\n        MODEL_DATA,\n        role=ROLE,\n        entry_point=SCRIPT_PATH,\n        framework_version=MXNetModel._LOWEST_MMS_VERSION,\n        sagemaker_session=sagemaker_session,\n    )\n    container_def = model.prepare_container_def(INSTANCE_TYPE, accelerator_type=ACCELERATOR_TYPE)\n    assert container_def[""Image""] == _get_full_image_uri_with_ei(\n        MXNetModel._LOWEST_MMS_VERSION, IMAGE_REPO_SERVING_NAME\n    )\n\n\ndef test_train_image_default(sagemaker_session):\n    mx = MXNet(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n    )\n\n    assert _get_full_image_uri(defaults.MXNET_VERSION) in mx.train_image()\n\n\ndef test_attach(sagemaker_session, mxnet_version):\n    training_image = ""1.dkr.ecr.us-west-2.amazonaws.com/sagemaker-mxnet-py2-cpu:{}-cpu-py2"".format(\n        mxnet_version\n    )\n    returned_job_description = {\n        ""AlgorithmSpecification"": {""TrainingInputMode"": ""File"", ""TrainingImage"": training_image},\n        ""HyperParameters"": {\n            ""sagemaker_submit_directory"": \'""s3://some/sourcedir.tar.gz""\',\n            ""sagemaker_program"": \'""iris-dnn-classifier.py""\',\n            ""sagemaker_s3_uri_training"": \'""sagemaker-3/integ-test-data/tf_iris""\',\n            ""sagemaker_enable_cloudwatch_metrics"": ""false"",\n            ""sagemaker_container_log_level"": \'""logging.INFO""\',\n            ""sagemaker_job_name"": \'""neo""\',\n            ""training_steps"": ""100"",\n            ""sagemaker_region"": \'""us-west-2""\',\n        },\n        ""RoleArn"": ""arn:aws:iam::366:role/SageMakerRole"",\n        ""ResourceConfig"": {\n            ""VolumeSizeInGB"": 30,\n            ""InstanceCount"": 1,\n            ""InstanceType"": ""ml.c4.xlarge"",\n        },\n        ""StoppingCondition"": {""MaxRuntimeInSeconds"": 24 * 60 * 60},\n        ""TrainingJobName"": ""neo"",\n        ""TrainingJobStatus"": ""Completed"",\n        ""TrainingJobArn"": ""arn:aws:sagemaker:us-west-2:336:training-job/neo"",\n        ""OutputDataConfig"": {""KmsKeyId"": """", ""S3OutputPath"": ""s3://place/output/neo""},\n        ""TrainingJobOutput"": {""S3TrainingJobOutput"": ""s3://here/output.tar.gz""},\n    }\n    sagemaker_session.sagemaker_client.describe_training_job = Mock(\n        name=""describe_training_job"", return_value=returned_job_description\n    )\n\n    estimator = MXNet.attach(training_job_name=""neo"", sagemaker_session=sagemaker_session)\n    assert estimator.latest_training_job.job_name == ""neo""\n    assert estimator.py_version == ""py2""\n    assert estimator.framework_version == mxnet_version\n    assert estimator.role == ""arn:aws:iam::366:role/SageMakerRole""\n    assert estimator.train_instance_count == 1\n    assert estimator.train_max_run == 24 * 60 * 60\n    assert estimator.input_mode == ""File""\n    assert estimator.base_job_name == ""neo""\n    assert estimator.output_path == ""s3://place/output/neo""\n    assert estimator.output_kms_key == """"\n    assert estimator.hyperparameters()[""training_steps""] == ""100""\n    assert estimator.source_dir == ""s3://some/sourcedir.tar.gz""\n    assert estimator.entry_point == ""iris-dnn-classifier.py""\n    assert estimator.tags == LIST_TAGS_RESULT[""Tags""]\n\n\ndef test_attach_old_container(sagemaker_session):\n    returned_job_description = {\n        ""AlgorithmSpecification"": {\n            ""TrainingInputMode"": ""File"",\n            ""TrainingImage"": ""1.dkr.ecr.us-west-2.amazonaws.com/sagemaker-mxnet-py2-cpu:1.0"",\n        },\n        ""HyperParameters"": {\n            ""sagemaker_submit_directory"": \'""s3://some/sourcedir.tar.gz""\',\n            ""sagemaker_program"": \'""iris-dnn-classifier.py""\',\n            ""sagemaker_s3_uri_training"": \'""sagemaker-3/integ-test-data/tf_iris""\',\n            ""sagemaker_enable_cloudwatch_metrics"": ""false"",\n            ""sagemaker_container_log_level"": \'""logging.INFO""\',\n            ""sagemaker_job_name"": \'""neo""\',\n            ""training_steps"": ""100"",\n            ""sagemaker_region"": \'""us-west-2""\',\n        },\n        ""RoleArn"": ""arn:aws:iam::366:role/SageMakerRole"",\n        ""ResourceConfig"": {\n            ""VolumeSizeInGB"": 30,\n            ""InstanceCount"": 1,\n            ""InstanceType"": ""ml.c4.xlarge"",\n        },\n        ""StoppingCondition"": {""MaxRuntimeInSeconds"": 24 * 60 * 60},\n        ""TrainingJobName"": ""neo"",\n        ""TrainingJobStatus"": ""Completed"",\n        ""TrainingJobArn"": ""arn:aws:sagemaker:us-west-2:336:training-job/neo"",\n        ""OutputDataConfig"": {""KmsKeyId"": """", ""S3OutputPath"": ""s3://place/output/neo""},\n        ""TrainingJobOutput"": {""S3TrainingJobOutput"": ""s3://here/output.tar.gz""},\n    }\n    sagemaker_session.sagemaker_client.describe_training_job = Mock(\n        name=""describe_training_job"", return_value=returned_job_description\n    )\n\n    estimator = MXNet.attach(training_job_name=""neo"", sagemaker_session=sagemaker_session)\n    assert estimator.latest_training_job.job_name == ""neo""\n    assert estimator.py_version == ""py2""\n    assert estimator.framework_version == ""0.12""\n    assert estimator.role == ""arn:aws:iam::366:role/SageMakerRole""\n    assert estimator.train_instance_count == 1\n    assert estimator.train_max_run == 24 * 60 * 60\n    assert estimator.input_mode == ""File""\n    assert estimator.base_job_name == ""neo""\n    assert estimator.output_path == ""s3://place/output/neo""\n    assert estimator.output_kms_key == """"\n    assert estimator.hyperparameters()[""training_steps""] == ""100""\n    assert estimator.source_dir == ""s3://some/sourcedir.tar.gz""\n    assert estimator.entry_point == ""iris-dnn-classifier.py""\n\n\ndef test_attach_wrong_framework(sagemaker_session):\n    rjd = {\n        ""AlgorithmSpecification"": {\n            ""TrainingInputMode"": ""File"",\n            ""TrainingImage"": ""1.dkr.ecr.us-west-2.amazonaws.com/sagemaker-tensorflow-py2-cpu:1.0.4"",\n        },\n        ""HyperParameters"": {\n            ""sagemaker_submit_directory"": \'""s3://some/sourcedir.tar.gz""\',\n            ""checkpoint_path"": \'""s3://other/1508872349""\',\n            ""sagemaker_program"": \'""iris-dnn-classifier.py""\',\n            ""sagemaker_enable_cloudwatch_metrics"": ""false"",\n            ""sagemaker_container_log_level"": \'""logging.INFO""\',\n            ""training_steps"": ""100"",\n            ""sagemaker_region"": \'""us-west-2""\',\n        },\n        ""RoleArn"": ""arn:aws:iam::366:role/SageMakerRole"",\n        ""ResourceConfig"": {\n            ""VolumeSizeInGB"": 30,\n            ""InstanceCount"": 1,\n            ""InstanceType"": ""ml.c4.xlarge"",\n        },\n        ""StoppingCondition"": {""MaxRuntimeInSeconds"": 24 * 60 * 60},\n        ""TrainingJobName"": ""neo"",\n        ""TrainingJobStatus"": ""Completed"",\n        ""TrainingJobArn"": ""arn:aws:sagemaker:us-west-2:336:training-job/neo"",\n        ""OutputDataConfig"": {""KmsKeyId"": """", ""S3OutputPath"": ""s3://place/output/neo""},\n        ""TrainingJobOutput"": {""S3TrainingJobOutput"": ""s3://here/output.tar.gz""},\n    }\n    sagemaker_session.sagemaker_client.describe_training_job = Mock(\n        name=""describe_training_job"", return_value=rjd\n    )\n\n    with pytest.raises(ValueError) as error:\n        MXNet.attach(training_job_name=""neo"", sagemaker_session=sagemaker_session)\n    assert ""didn\'t use image for requested framework"" in str(error)\n\n\ndef test_attach_custom_image(sagemaker_session):\n    training_image = ""ubuntu:latest""\n    returned_job_description = {\n        ""AlgorithmSpecification"": {""TrainingInputMode"": ""File"", ""TrainingImage"": training_image},\n        ""HyperParameters"": {\n            ""sagemaker_submit_directory"": \'""s3://some/sourcedir.tar.gz""\',\n            ""sagemaker_program"": \'""iris-dnn-classifier.py""\',\n            ""sagemaker_s3_uri_training"": \'""sagemaker-3/integ-test-data/tf_iris""\',\n            ""sagemaker_enable_cloudwatch_metrics"": ""false"",\n            ""sagemaker_container_log_level"": \'""logging.INFO""\',\n            ""sagemaker_job_name"": \'""neo""\',\n            ""training_steps"": ""100"",\n            ""sagemaker_region"": \'""us-west-2""\',\n        },\n        ""RoleArn"": ""arn:aws:iam::366:role/SageMakerRole"",\n        ""ResourceConfig"": {\n            ""VolumeSizeInGB"": 30,\n            ""InstanceCount"": 1,\n            ""InstanceType"": ""ml.c4.xlarge"",\n        },\n        ""StoppingCondition"": {""MaxRuntimeInSeconds"": 24 * 60 * 60},\n        ""TrainingJobName"": ""neo"",\n        ""TrainingJobStatus"": ""Completed"",\n        ""TrainingJobArn"": ""arn:aws:sagemaker:us-west-2:336:training-job/neo"",\n        ""OutputDataConfig"": {""KmsKeyId"": """", ""S3OutputPath"": ""s3://place/output/neo""},\n        ""TrainingJobOutput"": {""S3TrainingJobOutput"": ""s3://here/output.tar.gz""},\n    }\n    sagemaker_session.sagemaker_client.describe_training_job = Mock(\n        name=""describe_training_job"", return_value=returned_job_description\n    )\n\n    estimator = MXNet.attach(training_job_name=""neo"", sagemaker_session=sagemaker_session)\n    assert estimator.image_name == training_image\n    assert estimator.train_image() == training_image\n\n\n@patch(""sagemaker.mxnet.estimator.parameter_v2_rename_warning"")\ndef test_estimator_script_mode_launch_parameter_server(warning, sagemaker_session):\n    mx = MXNet(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        distributions=LAUNCH_PS_DISTRIBUTIONS_DICT,\n        framework_version=""1.3.0"",\n    )\n    assert mx.hyperparameters().get(MXNet.LAUNCH_PS_ENV_NAME) == ""true""\n    warning.assert_called_with(""distributions"", ""distribution"")\n\n\ndef test_estimator_script_mode_dont_launch_parameter_server(sagemaker_session):\n    mx = MXNet(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        distributions={""parameter_server"": {""enabled"": False}},\n        framework_version=""1.3.0"",\n    )\n    assert mx.hyperparameters().get(MXNet.LAUNCH_PS_ENV_NAME) == ""false""\n\n\ndef test_estimator_wrong_version_launch_parameter_server(sagemaker_session):\n    with pytest.raises(ValueError) as e:\n        MXNet(\n            entry_point=SCRIPT_PATH,\n            role=ROLE,\n            sagemaker_session=sagemaker_session,\n            train_instance_count=INSTANCE_COUNT,\n            train_instance_type=INSTANCE_TYPE,\n            distributions=LAUNCH_PS_DISTRIBUTIONS_DICT,\n            framework_version=""1.2.1"",\n        )\n    assert ""The distributions option is valid for only versions 1.3 and higher"" in str(e)\n\n\n@patch(""sagemaker.mxnet.estimator.python_deprecation_warning"")\ndef test_estimator_py2_warning(warning, sagemaker_session):\n    estimator = MXNet(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        py_version=""py2"",\n    )\n\n    assert estimator.py_version == ""py2""\n    warning.assert_called_with(estimator.__framework_name__, defaults.LATEST_PY2_VERSION)\n\n\n@patch(""sagemaker.mxnet.model.python_deprecation_warning"")\ndef test_model_py2_warning(warning, sagemaker_session):\n    model = MXNetModel(\n        MODEL_DATA,\n        role=ROLE,\n        entry_point=SCRIPT_PATH,\n        sagemaker_session=sagemaker_session,\n        py_version=""py2"",\n    )\n    assert model.py_version == ""py2""\n    warning.assert_called_with(model.__framework_name__, defaults.LATEST_PY2_VERSION)\n\n\n@patch(""sagemaker.mxnet.estimator.empty_framework_version_warning"")\ndef test_empty_framework_version(warning, sagemaker_session):\n    mx = MXNet(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        framework_version=None,\n    )\n\n    assert mx.framework_version == defaults.MXNET_VERSION\n    warning.assert_called_with(defaults.MXNET_VERSION, mx.LATEST_VERSION)\n\n\n@patch(""sagemaker.mxnet.model.empty_framework_version_warning"")\ndef test_model_empty_framework_version(warning, sagemaker_session):\n    model = MXNetModel(\n        MODEL_DATA,\n        role=ROLE,\n        entry_point=SCRIPT_PATH,\n        sagemaker_session=sagemaker_session,\n        framework_version=None,\n    )\n    assert model.framework_version == defaults.MXNET_VERSION\n    warning.assert_called_with(defaults.MXNET_VERSION, defaults.LATEST_VERSION)\n\n\ndef test_create_model_with_custom_hosting_image(sagemaker_session):\n    container_log_level = \'""logging.INFO""\'\n    source_dir = ""s3://mybucket/source""\n    custom_image = ""mxnet:2.0""\n    custom_hosting_image = ""mxnet_hosting:2.0""\n    mx = MXNet(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        image_name=custom_image,\n        container_log_level=container_log_level,\n        base_job_name=""job"",\n        source_dir=source_dir,\n    )\n\n    mx.fit(inputs=""s3://mybucket/train"", job_name=""new_name"")\n    model = mx.create_model(image_name=custom_hosting_image)\n\n    assert model.image == custom_hosting_image\n\n\ndef test_mx_enable_sm_metrics(sagemaker_session):\n    mx = MXNet(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        enable_sagemaker_metrics=True,\n    )\n    assert mx.enable_sagemaker_metrics\n\n\ndef test_mx_disable_sm_metrics(sagemaker_session):\n    mx = MXNet(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        enable_sagemaker_metrics=False,\n    )\n    assert not mx.enable_sagemaker_metrics\n\n\ndef test_mx_disable_sm_metrics_if_pt_ver_is_less_than_1_6(sagemaker_session):\n    for fw_version in [""1.1"", ""1.2"", ""1.3"", ""1.4"", ""1.5""]:\n        mx = MXNet(\n            entry_point=SCRIPT_PATH,\n            role=ROLE,\n            sagemaker_session=sagemaker_session,\n            train_instance_count=INSTANCE_COUNT,\n            train_instance_type=INSTANCE_TYPE,\n            framework_version=fw_version,\n        )\n        assert mx.enable_sagemaker_metrics is None\n\n\ndef test_mx_enable_sm_metrics_if_fw_ver_is_at_least_1_6(sagemaker_session):\n    for fw_version in [""1.6"", ""1.7"", ""2.0"", ""2.1""]:\n        mx = MXNet(\n            entry_point=SCRIPT_PATH,\n            role=ROLE,\n            sagemaker_session=sagemaker_session,\n            train_instance_count=INSTANCE_COUNT,\n            train_instance_type=INSTANCE_TYPE,\n            framework_version=fw_version,\n        )\n        assert mx.enable_sagemaker_metrics\n\n\ndef test_custom_image_estimator_deploy(sagemaker_session):\n    custom_image = ""mycustomimage:latest""\n    mx = MXNet(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n    )\n    mx.fit(inputs=""s3://mybucket/train"", job_name=""new_name"")\n    model = mx.create_model(image=custom_image)\n    assert model.image == custom_image\n'"
tests/unit/test_ntm.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport pytest\nfrom mock import Mock, patch\n\nfrom sagemaker.amazon.ntm import NTM, NTMPredictor\nfrom sagemaker.amazon.amazon_estimator import registry, RecordSet\n\nROLE = ""myrole""\nTRAIN_INSTANCE_COUNT = 1\nTRAIN_INSTANCE_TYPE = ""ml.c4.xlarge""\nNUM_TOPICS = 5\n\nCOMMON_TRAIN_ARGS = {\n    ""role"": ROLE,\n    ""train_instance_count"": TRAIN_INSTANCE_COUNT,\n    ""train_instance_type"": TRAIN_INSTANCE_TYPE,\n}\nALL_REQ_ARGS = dict({""num_topics"": NUM_TOPICS}, **COMMON_TRAIN_ARGS)\n\nREGION = ""us-west-2""\nBUCKET_NAME = ""Some-Bucket""\n\nDESCRIBE_TRAINING_JOB_RESULT = {""ModelArtifacts"": {""S3ModelArtifacts"": ""s3://bucket/model.tar.gz""}}\n\nENDPOINT_DESC = {""EndpointConfigName"": ""test-endpoint""}\n\nENDPOINT_CONFIG_DESC = {""ProductionVariants"": [{""ModelName"": ""model-1""}, {""ModelName"": ""model-2""}]}\n\n\n@pytest.fixture()\ndef sagemaker_session():\n    boto_mock = Mock(name=""boto_session"", region_name=REGION)\n    sms = Mock(\n        name=""sagemaker_session"",\n        boto_session=boto_mock,\n        region_name=REGION,\n        config=None,\n        local_mode=False,\n        s3_client=None,\n        s3_resource=None,\n    )\n    sms.boto_region_name = REGION\n    sms.default_bucket = Mock(name=""default_bucket"", return_value=BUCKET_NAME)\n    sms.sagemaker_client.describe_training_job = Mock(\n        name=""describe_training_job"", return_value=DESCRIBE_TRAINING_JOB_RESULT\n    )\n    sms.sagemaker_client.describe_endpoint = Mock(return_value=ENDPOINT_DESC)\n    sms.sagemaker_client.describe_endpoint_config = Mock(return_value=ENDPOINT_CONFIG_DESC)\n\n    return sms\n\n\ndef test_init_required_positional(sagemaker_session):\n    ntm = NTM(\n        ROLE,\n        TRAIN_INSTANCE_COUNT,\n        TRAIN_INSTANCE_TYPE,\n        NUM_TOPICS,\n        sagemaker_session=sagemaker_session,\n    )\n    assert ntm.role == ROLE\n    assert ntm.train_instance_count == TRAIN_INSTANCE_COUNT\n    assert ntm.train_instance_type == TRAIN_INSTANCE_TYPE\n    assert ntm.num_topics == NUM_TOPICS\n\n\ndef test_init_required_named(sagemaker_session):\n    ntm = NTM(sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n\n    assert ntm.role == COMMON_TRAIN_ARGS[""role""]\n    assert ntm.train_instance_count == TRAIN_INSTANCE_COUNT\n    assert ntm.train_instance_type == COMMON_TRAIN_ARGS[""train_instance_type""]\n    assert ntm.num_topics == ALL_REQ_ARGS[""num_topics""]\n\n\ndef test_all_hyperparameters(sagemaker_session):\n    ntm = NTM(\n        sagemaker_session=sagemaker_session,\n        encoder_layers=[1, 2, 3],\n        epochs=3,\n        encoder_layers_activation=""tanh"",\n        optimizer=""sgd"",\n        tolerance=0.05,\n        num_patience_epochs=2,\n        batch_norm=False,\n        rescale_gradient=0.5,\n        clip_gradient=0.5,\n        weight_decay=0.5,\n        learning_rate=0.5,\n        **ALL_REQ_ARGS\n    )\n    assert ntm.hyperparameters() == dict(\n        num_topics=str(ALL_REQ_ARGS[""num_topics""]),\n        encoder_layers=""[1, 2, 3]"",\n        epochs=""3"",\n        encoder_layers_activation=""tanh"",\n        optimizer=""sgd"",\n        tolerance=""0.05"",\n        num_patience_epochs=""2"",\n        batch_norm=""False"",\n        rescale_gradient=""0.5"",\n        clip_gradient=""0.5"",\n        weight_decay=""0.5"",\n        learning_rate=""0.5"",\n    )\n\n\ndef test_image(sagemaker_session):\n    ntm = NTM(sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n    assert ntm.train_image() == registry(REGION, ""ntm"") + ""/ntm:1""\n\n\n@pytest.mark.parametrize(""required_hyper_parameters, value"", [(""num_topics"", ""string"")])\ndef test_required_hyper_parameters_type(sagemaker_session, required_hyper_parameters, value):\n    with pytest.raises(ValueError):\n        test_params = ALL_REQ_ARGS.copy()\n        test_params[required_hyper_parameters] = value\n        NTM(sagemaker_session=sagemaker_session, **test_params)\n\n\n@pytest.mark.parametrize(\n    ""required_hyper_parameters, value"", [(""num_topics"", 0), (""num_topics"", 10000)]\n)\ndef test_required_hyper_parameters_value(sagemaker_session, required_hyper_parameters, value):\n    with pytest.raises(ValueError):\n        test_params = ALL_REQ_ARGS.copy()\n        test_params[required_hyper_parameters] = value\n        NTM(sagemaker_session=sagemaker_session, **test_params)\n\n\n@pytest.mark.parametrize(""iterable_hyper_parameters, value"", [(""encoder_layers"", 0)])\ndef test_iterable_hyper_parameters_type(sagemaker_session, iterable_hyper_parameters, value):\n    with pytest.raises(TypeError):\n        test_params = ALL_REQ_ARGS.copy()\n        test_params.update({iterable_hyper_parameters: value})\n        NTM(sagemaker_session=sagemaker_session, **test_params)\n\n\n@pytest.mark.parametrize(\n    ""optional_hyper_parameters, value"",\n    [\n        (""epochs"", ""string""),\n        (""encoder_layers_activation"", 0),\n        (""optimizer"", 0),\n        (""tolerance"", ""string""),\n        (""num_patience_epochs"", ""string""),\n        (""rescale_gradient"", ""string""),\n        (""clip_gradient"", ""string""),\n        (""weight_decay"", ""string""),\n        (""learning_rate"", ""string""),\n    ],\n)\ndef test_optional_hyper_parameters_type(sagemaker_session, optional_hyper_parameters, value):\n    with pytest.raises(ValueError):\n        test_params = ALL_REQ_ARGS.copy()\n        test_params.update({optional_hyper_parameters: value})\n        NTM(sagemaker_session=sagemaker_session, **test_params)\n\n\n@pytest.mark.parametrize(\n    ""optional_hyper_parameters, value"",\n    [\n        (""epochs"", 0),\n        (""epochs"", 1000),\n        (""encoder_layers_activation"", ""string""),\n        (""optimizer"", ""string""),\n        (""tolerance"", 0),\n        (""tolerance"", 0.5),\n        (""num_patience_epochs"", 0),\n        (""num_patience_epochs"", 100),\n        (""rescale_gradient"", 0),\n        (""rescale_gradient"", 10),\n        (""clip_gradient"", 0),\n        (""weight_decay"", -1),\n        (""weight_decay"", 2),\n        (""learning_rate"", 0),\n        (""learning_rate"", 2),\n    ],\n)\ndef test_optional_hyper_parameters_value(sagemaker_session, optional_hyper_parameters, value):\n    with pytest.raises(ValueError):\n        test_params = ALL_REQ_ARGS.copy()\n        test_params.update({optional_hyper_parameters: value})\n        NTM(sagemaker_session=sagemaker_session, **test_params)\n\n\nPREFIX = ""prefix""\nFEATURE_DIM = 10\nMINI_BATCH_SIZE = 200\n\n\n@patch(""sagemaker.amazon.amazon_estimator.AmazonAlgorithmEstimatorBase.fit"")\ndef test_call_fit(base_fit, sagemaker_session):\n    ntm = NTM(base_job_name=""ntm"", sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n\n    ntm.fit(data, MINI_BATCH_SIZE)\n\n    base_fit.assert_called_once()\n    assert len(base_fit.call_args[0]) == 2\n    assert base_fit.call_args[0][0] == data\n    assert base_fit.call_args[0][1] == MINI_BATCH_SIZE\n\n\ndef test_call_fit_none_mini_batch_size(sagemaker_session):\n    ntm = NTM(base_job_name=""ntm"", sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n    ntm.fit(data)\n\n\ndef test_prepare_for_training_wrong_type_mini_batch_size(sagemaker_session):\n    ntm = NTM(base_job_name=""ntm"", sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n\n    with pytest.raises((TypeError, ValueError)):\n        ntm._prepare_for_training(data, ""some"")\n\n\ndef test_prepare_for_training_wrong_value_lower_mini_batch_size(sagemaker_session):\n    ntm = NTM(base_job_name=""ntm"", sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n    with pytest.raises(ValueError):\n        ntm._prepare_for_training(data, 0)\n\n\ndef test_prepare_for_training_wrong_value_upper_mini_batch_size(sagemaker_session):\n    ntm = NTM(base_job_name=""ntm"", sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n    with pytest.raises(ValueError):\n        ntm._prepare_for_training(data, 10001)\n\n\ndef test_model_image(sagemaker_session):\n    ntm = NTM(sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n    ntm.fit(data, MINI_BATCH_SIZE)\n\n    model = ntm.create_model()\n    assert model.image == registry(REGION, ""ntm"") + ""/ntm:1""\n\n\ndef test_predictor_type(sagemaker_session):\n    ntm = NTM(sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n    ntm.fit(data, MINI_BATCH_SIZE)\n    model = ntm.create_model()\n    predictor = model.deploy(1, TRAIN_INSTANCE_TYPE)\n\n    assert isinstance(predictor, NTMPredictor)\n'"
tests/unit/test_object2vec.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport pytest\nfrom mock import Mock, patch\n\nfrom sagemaker.amazon.object2vec import Object2Vec\nfrom sagemaker.predictor import RealTimePredictor\nfrom sagemaker.amazon.amazon_estimator import registry, RecordSet\n\nROLE = ""myrole""\nTRAIN_INSTANCE_COUNT = 1\nTRAIN_INSTANCE_TYPE = ""ml.c4.xlarge""\nEPOCHS = 5\nENC0_MAX_SEQ_LEN = 100\nENC0_VOCAB_SIZE = 500\n\nMINI_BATCH_SIZE = 32\n\nCOMMON_TRAIN_ARGS = {\n    ""role"": ROLE,\n    ""train_instance_count"": TRAIN_INSTANCE_COUNT,\n    ""train_instance_type"": TRAIN_INSTANCE_TYPE,\n}\nALL_REQ_ARGS = dict(\n    {""epochs"": EPOCHS, ""enc0_max_seq_len"": ENC0_MAX_SEQ_LEN, ""enc0_vocab_size"": ENC0_VOCAB_SIZE},\n    **COMMON_TRAIN_ARGS\n)\n\nREGION = ""us-west-2""\nBUCKET_NAME = ""Some-Bucket""\n\nDESCRIBE_TRAINING_JOB_RESULT = {""ModelArtifacts"": {""S3ModelArtifacts"": ""s3://bucket/model.tar.gz""}}\n\nENDPOINT_DESC = {""EndpointConfigName"": ""test-endpoint""}\n\nENDPOINT_CONFIG_DESC = {""ProductionVariants"": [{""ModelName"": ""model-1""}, {""ModelName"": ""model-2""}]}\n\n\n@pytest.fixture()\ndef sagemaker_session():\n    boto_mock = Mock(name=""boto_session"", region_name=REGION)\n    sms = Mock(\n        name=""sagemaker_session"",\n        boto_session=boto_mock,\n        region_name=REGION,\n        config=None,\n        local_mode=False,\n        s3_client=None,\n        s3_resource=None,\n    )\n    sms.boto_region_name = REGION\n    sms.default_bucket = Mock(name=""default_bucket"", return_value=BUCKET_NAME)\n    sms.sagemaker_client.describe_training_job = Mock(\n        name=""describe_training_job"", return_value=DESCRIBE_TRAINING_JOB_RESULT\n    )\n    sms.sagemaker_client.describe_endpoint = Mock(return_value=ENDPOINT_DESC)\n    sms.sagemaker_client.describe_endpoint_config = Mock(return_value=ENDPOINT_CONFIG_DESC)\n\n    return sms\n\n\ndef test_init_required_positional(sagemaker_session):\n    object2vec = Object2Vec(\n        ROLE,\n        TRAIN_INSTANCE_COUNT,\n        TRAIN_INSTANCE_TYPE,\n        EPOCHS,\n        ENC0_MAX_SEQ_LEN,\n        ENC0_VOCAB_SIZE,\n        sagemaker_session=sagemaker_session,\n    )\n    assert object2vec.role == ROLE\n    assert object2vec.train_instance_count == TRAIN_INSTANCE_COUNT\n    assert object2vec.train_instance_type == TRAIN_INSTANCE_TYPE\n    assert object2vec.epochs == EPOCHS\n    assert object2vec.enc0_max_seq_len == ENC0_MAX_SEQ_LEN\n    assert object2vec.enc0_vocab_size == ENC0_VOCAB_SIZE\n\n\ndef test_init_required_named(sagemaker_session):\n    object2vec = Object2Vec(sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n\n    assert object2vec.role == COMMON_TRAIN_ARGS[""role""]\n    assert object2vec.train_instance_count == TRAIN_INSTANCE_COUNT\n    assert object2vec.train_instance_type == COMMON_TRAIN_ARGS[""train_instance_type""]\n    assert object2vec.epochs == ALL_REQ_ARGS[""epochs""]\n    assert object2vec.enc0_max_seq_len == ALL_REQ_ARGS[""enc0_max_seq_len""]\n    assert object2vec.enc0_vocab_size == ALL_REQ_ARGS[""enc0_vocab_size""]\n\n\ndef test_all_hyperparameters(sagemaker_session):\n    object2vec = Object2Vec(\n        sagemaker_session=sagemaker_session,\n        enc_dim=1024,\n        mini_batch_size=100,\n        early_stopping_patience=3,\n        early_stopping_tolerance=0.001,\n        dropout=0.1,\n        weight_decay=0.001,\n        bucket_width=0,\n        num_classes=5,\n        mlp_layers=3,\n        mlp_dim=1024,\n        mlp_activation=""tanh"",\n        output_layer=""softmax"",\n        optimizer=""adam"",\n        learning_rate=0.0001,\n        negative_sampling_rate=1,\n        comparator_list=""hadamard, abs_diff"",\n        tied_token_embedding_weight=True,\n        token_embedding_storage_type=""row_sparse"",\n        enc0_network=""bilstm"",\n        enc1_network=""hcnn"",\n        enc0_cnn_filter_width=3,\n        enc1_cnn_filter_width=3,\n        enc1_max_seq_len=300,\n        enc0_token_embedding_dim=300,\n        enc1_token_embedding_dim=300,\n        enc1_vocab_size=300,\n        enc0_layers=3,\n        enc1_layers=3,\n        enc0_freeze_pretrained_embedding=True,\n        enc1_freeze_pretrained_embedding=False,\n        **ALL_REQ_ARGS\n    )\n\n    hp = object2vec.hyperparameters()\n    assert hp[""epochs""] == str(EPOCHS)\n    assert hp[""mlp_activation""] == ""tanh""\n\n\ndef test_image(sagemaker_session):\n    object2vec = Object2Vec(sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n    assert object2vec.train_image() == registry(REGION, ""object2vec"") + ""/object2vec:1""\n\n\n@pytest.mark.parametrize(""required_hyper_parameters, value"", [(""epochs"", ""string"")])\ndef test_required_hyper_parameters_type(sagemaker_session, required_hyper_parameters, value):\n    with pytest.raises(ValueError):\n        test_params = ALL_REQ_ARGS.copy()\n        test_params[required_hyper_parameters] = value\n        Object2Vec(sagemaker_session=sagemaker_session, **test_params)\n\n\n@pytest.mark.parametrize(\n    ""required_hyper_parameters, value"", [(""enc0_vocab_size"", 0), (""enc0_vocab_size"", 1000000000)]\n)\ndef test_required_hyper_parameters_value(sagemaker_session, required_hyper_parameters, value):\n    with pytest.raises(ValueError):\n        test_params = ALL_REQ_ARGS.copy()\n        test_params[required_hyper_parameters] = value\n        Object2Vec(sagemaker_session=sagemaker_session, **test_params)\n\n\n@pytest.mark.parametrize(\n    ""optional_hyper_parameters, value"",\n    [\n        (""epochs"", ""string""),\n        (""optimizer"", 0),\n        (""enc0_cnn_filter_width"", ""string""),\n        (""weight_decay"", ""string""),\n        (""learning_rate"", ""string""),\n        (""negative_sampling_rate"", ""some_string""),\n        (""comparator_list"", 0),\n        (""comparator_list"", [""foobar""]),\n        (""token_embedding_storage_type"", 123),\n    ],\n)\ndef test_optional_hyper_parameters_type(sagemaker_session, optional_hyper_parameters, value):\n    with pytest.raises(ValueError):\n        test_params = ALL_REQ_ARGS.copy()\n        test_params.update({optional_hyper_parameters: value})\n        Object2Vec(sagemaker_session=sagemaker_session, **test_params)\n\n\n@pytest.mark.parametrize(\n    ""optional_hyper_parameters, value"",\n    [\n        (""epochs"", 0),\n        (""epochs"", 1000),\n        (""optimizer"", ""string""),\n        (""early_stopping_tolerance"", 0),\n        (""early_stopping_tolerance"", 0.5),\n        (""early_stopping_patience"", 0),\n        (""early_stopping_patience"", 100),\n        (""weight_decay"", -1),\n        (""weight_decay"", 200000),\n        (""enc0_cnn_filter_width"", 2000),\n        (""learning_rate"", 0),\n        (""learning_rate"", 2),\n        (""negative_sampling_rate"", -1),\n        (""comparator_list"", ""hadamard,foobar""),\n        (""token_embedding_storage_type"", ""foobar""),\n    ],\n)\ndef test_optional_hyper_parameters_value(sagemaker_session, optional_hyper_parameters, value):\n    with pytest.raises(ValueError):\n        test_params = ALL_REQ_ARGS.copy()\n        test_params.update({optional_hyper_parameters: value})\n        Object2Vec(sagemaker_session=sagemaker_session, **test_params)\n\n\nPREFIX = ""prefix""\nFEATURE_DIM = 10\n\n\n@patch(""sagemaker.amazon.amazon_estimator.AmazonAlgorithmEstimatorBase.fit"")\ndef test_call_fit(base_fit, sagemaker_session):\n    object2vec = Object2Vec(\n        base_job_name=""object2vec"", sagemaker_session=sagemaker_session, **ALL_REQ_ARGS\n    )\n\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n\n    object2vec.fit(data, MINI_BATCH_SIZE)\n\n    base_fit.assert_called_once()\n    assert len(base_fit.call_args[0]) == 2\n    assert base_fit.call_args[0][0] == data\n    assert base_fit.call_args[0][1] == MINI_BATCH_SIZE\n\n\ndef test_call_fit_none_mini_batch_size(sagemaker_session):\n    object2vec = Object2Vec(\n        base_job_name=""object2vec"", sagemaker_session=sagemaker_session, **ALL_REQ_ARGS\n    )\n\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n    object2vec.fit(data)\n\n\ndef test_prepare_for_training_wrong_type_mini_batch_size(sagemaker_session):\n    object2vec = Object2Vec(\n        base_job_name=""object2vec"", sagemaker_session=sagemaker_session, **ALL_REQ_ARGS\n    )\n\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n\n    with pytest.raises((TypeError, ValueError)):\n        object2vec._prepare_for_training(data, ""some"")\n\n\ndef test_prepare_for_training_wrong_value_lower_mini_batch_size(sagemaker_session):\n    object2vec = Object2Vec(\n        base_job_name=""object2vec"", sagemaker_session=sagemaker_session, **ALL_REQ_ARGS\n    )\n\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n    with pytest.raises(ValueError):\n        object2vec._prepare_for_training(data, 0)\n\n\ndef test_prepare_for_training_wrong_value_upper_mini_batch_size(sagemaker_session):\n    object2vec = Object2Vec(\n        base_job_name=""object2vec"", sagemaker_session=sagemaker_session, **ALL_REQ_ARGS\n    )\n\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n    with pytest.raises(ValueError):\n        object2vec._prepare_for_training(data, 10001)\n\n\ndef test_model_image(sagemaker_session):\n    object2vec = Object2Vec(sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n    object2vec.fit(data, MINI_BATCH_SIZE)\n\n    model = object2vec.create_model()\n    assert model.image == registry(REGION, ""object2vec"") + ""/object2vec:1""\n\n\ndef test_predictor_type(sagemaker_session):\n    object2vec = Object2Vec(sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n    object2vec.fit(data, MINI_BATCH_SIZE)\n    model = object2vec.create_model()\n    predictor = model.deploy(1, TRAIN_INSTANCE_TYPE)\n\n    assert isinstance(predictor, RealTimePredictor)\n'"
tests/unit/test_pca.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport pytest\nfrom mock import Mock, patch\n\nfrom sagemaker.amazon.pca import PCA, PCAPredictor\nfrom sagemaker.amazon.amazon_estimator import registry, RecordSet\n\nROLE = ""myrole""\nTRAIN_INSTANCE_COUNT = 1\nTRAIN_INSTANCE_TYPE = ""ml.c4.xlarge""\nNUM_COMPONENTS = 5\n\nCOMMON_TRAIN_ARGS = {\n    ""role"": ROLE,\n    ""train_instance_count"": TRAIN_INSTANCE_COUNT,\n    ""train_instance_type"": TRAIN_INSTANCE_TYPE,\n}\nALL_REQ_ARGS = dict({""num_components"": NUM_COMPONENTS}, **COMMON_TRAIN_ARGS)\n\nREGION = ""us-west-2""\nBUCKET_NAME = ""Some-Bucket""\n\nDESCRIBE_TRAINING_JOB_RESULT = {""ModelArtifacts"": {""S3ModelArtifacts"": ""s3://bucket/model.tar.gz""}}\n\nENDPOINT_DESC = {""EndpointConfigName"": ""test-endpoint""}\n\nENDPOINT_CONFIG_DESC = {""ProductionVariants"": [{""ModelName"": ""model-1""}, {""ModelName"": ""model-2""}]}\n\n\n@pytest.fixture()\ndef sagemaker_session():\n    boto_mock = Mock(name=""boto_session"", region_name=REGION)\n    sms = Mock(\n        name=""sagemaker_session"",\n        boto_session=boto_mock,\n        region_name=REGION,\n        config=None,\n        local_mode=False,\n        s3_client=None,\n        s3_resource=None,\n    )\n    sms.boto_region_name = REGION\n    sms.default_bucket = Mock(name=""default_bucket"", return_value=BUCKET_NAME)\n    sms.sagemaker_client.describe_training_job = Mock(\n        name=""describe_training_job"", return_value=DESCRIBE_TRAINING_JOB_RESULT\n    )\n    sms.sagemaker_client.describe_endpoint = Mock(return_value=ENDPOINT_DESC)\n    sms.sagemaker_client.describe_endpoint_config = Mock(return_value=ENDPOINT_CONFIG_DESC)\n\n    return sms\n\n\ndef test_init_required_positional(sagemaker_session):\n    pca = PCA(\n        ROLE,\n        TRAIN_INSTANCE_COUNT,\n        TRAIN_INSTANCE_TYPE,\n        NUM_COMPONENTS,\n        sagemaker_session=sagemaker_session,\n    )\n    assert pca.role == ROLE\n    assert pca.train_instance_count == TRAIN_INSTANCE_COUNT\n    assert pca.train_instance_type == TRAIN_INSTANCE_TYPE\n    assert pca.num_components == NUM_COMPONENTS\n\n\ndef test_init_required_named(sagemaker_session):\n    pca = PCA(sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n\n    assert pca.role == COMMON_TRAIN_ARGS[""role""]\n    assert pca.train_instance_count == TRAIN_INSTANCE_COUNT\n    assert pca.train_instance_type == COMMON_TRAIN_ARGS[""train_instance_type""]\n    assert pca.num_components == ALL_REQ_ARGS[""num_components""]\n\n\ndef test_all_hyperparameters(sagemaker_session):\n    pca = PCA(\n        sagemaker_session=sagemaker_session,\n        algorithm_mode=""regular"",\n        subtract_mean=""True"",\n        extra_components=1,\n        **ALL_REQ_ARGS\n    )\n    assert pca.hyperparameters() == dict(\n        num_components=str(ALL_REQ_ARGS[""num_components""]),\n        algorithm_mode=""regular"",\n        subtract_mean=""True"",\n        extra_components=""1"",\n    )\n\n\ndef test_image(sagemaker_session):\n    pca = PCA(sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n    assert pca.train_image() == registry(REGION, ""pca"") + ""/pca:1""\n\n\n@pytest.mark.parametrize(""required_hyper_parameters, value"", [(""num_components"", ""string"")])\ndef test_required_hyper_parameters_type(sagemaker_session, required_hyper_parameters, value):\n    with pytest.raises(ValueError):\n        test_params = ALL_REQ_ARGS.copy()\n        test_params[required_hyper_parameters] = value\n        PCA(sagemaker_session=sagemaker_session, **test_params)\n\n\n@pytest.mark.parametrize(""required_hyper_parameters, value"", [(""num_components"", 0)])\ndef test_required_hyper_parameters_value(sagemaker_session, required_hyper_parameters, value):\n    with pytest.raises(ValueError):\n        test_params = ALL_REQ_ARGS.copy()\n        test_params[required_hyper_parameters] = value\n        PCA(sagemaker_session=sagemaker_session, **test_params)\n\n\n@pytest.mark.parametrize(\n    ""optional_hyper_parameters, value"", [(""algorithm_mode"", 0), (""extra_components"", ""string"")]\n)\ndef test_optional_hyper_parameters_type(sagemaker_session, optional_hyper_parameters, value):\n    with pytest.raises(ValueError):\n        test_params = ALL_REQ_ARGS.copy()\n        test_params.update({optional_hyper_parameters: value})\n        PCA(sagemaker_session=sagemaker_session, **test_params)\n\n\n@pytest.mark.parametrize(""optional_hyper_parameters, value"", [(""algorithm_mode"", ""string"")])\ndef test_optional_hyper_parameters_value(sagemaker_session, optional_hyper_parameters, value):\n    with pytest.raises(ValueError):\n        test_params = ALL_REQ_ARGS.copy()\n        test_params.update({optional_hyper_parameters: value})\n        PCA(sagemaker_session=sagemaker_session, **test_params)\n\n\nPREFIX = ""prefix""\nFEATURE_DIM = 10\nMINI_BATCH_SIZE = 200\n\n\n@patch(""sagemaker.amazon.amazon_estimator.AmazonAlgorithmEstimatorBase.fit"")\ndef test_call_fit(base_fit, sagemaker_session):\n    pca = PCA(base_job_name=""pca"", sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n\n    pca.fit(data, MINI_BATCH_SIZE)\n\n    base_fit.assert_called_once()\n    assert len(base_fit.call_args[0]) == 2\n    assert base_fit.call_args[0][0] == data\n    assert base_fit.call_args[0][1] == MINI_BATCH_SIZE\n\n\ndef test_prepare_for_training_no_mini_batch_size(sagemaker_session):\n    pca = PCA(base_job_name=""pca"", sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n    pca._prepare_for_training(data)\n\n    assert pca.mini_batch_size == 1\n\n\ndef test_prepare_for_training_wrong_type_mini_batch_size(sagemaker_session):\n    pca = PCA(base_job_name=""pca"", sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n\n    with pytest.raises((TypeError, ValueError)):\n        pca.fit(data, ""some"")\n\n\ndef test_prepare_for_training_multiple_channel(sagemaker_session):\n    lr = PCA(base_job_name=""lr"", sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n\n    lr._prepare_for_training([data, data])\n\n    assert lr.mini_batch_size == 1\n\n\ndef test_prepare_for_training_multiple_channel_no_train(sagemaker_session):\n    lr = PCA(base_job_name=""lr"", sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""mock"",\n    )\n\n    with pytest.raises(ValueError) as ex:\n        lr._prepare_for_training([data, data])\n\n    assert ""Must provide train channel."" in str(ex)\n\n\ndef test_model_image(sagemaker_session):\n    pca = PCA(sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n    pca.fit(data, MINI_BATCH_SIZE)\n\n    model = pca.create_model()\n    assert model.image == registry(REGION, ""pca"") + ""/pca:1""\n\n\ndef test_predictor_type(sagemaker_session):\n    pca = PCA(sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n    pca.fit(data, MINI_BATCH_SIZE)\n    model = pca.create_model()\n    predictor = model.deploy(1, TRAIN_INSTANCE_TYPE)\n\n    assert isinstance(predictor, PCAPredictor)\n'"
tests/unit/test_pipeline_model.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport pytest\nfrom mock import Mock, patch\n\nfrom sagemaker.model import FrameworkModel\nfrom sagemaker.pipeline import PipelineModel\nfrom sagemaker.predictor import RealTimePredictor\nfrom sagemaker.session import ModelContainer\nfrom sagemaker.sparkml import SparkMLModel\n\nENTRY_POINT = ""blah.py""\nMODEL_DATA_1 = ""s3://bucket/model_1.tar.gz""\nMODEL_DATA_2 = ""s3://bucket/model_2.tar.gz""\nMODEL_IMAGE_1 = ""mi-1""\nMODEL_IMAGE_2 = ""mi-2""\nINSTANCE_TYPE = ""ml.m4.xlarge""\nROLE = ""some-role""\nENV_1 = {""SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT"": ""application/json""}\nENV_2 = {""SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT"": ""text/csv""}\nMODEL_CONTAINER_1 = ModelContainer(image=MODEL_IMAGE_1, model_data=MODEL_DATA_1, env=ENV_1)\nMODEL_CONTAINER_2 = ModelContainer(image=MODEL_IMAGE_2, model_data=MODEL_DATA_2, env=ENV_2)\nENDPOINT = ""some-ep""\n\n\nTIMESTAMP = ""2017-10-10-14-14-15""\nBUCKET_NAME = ""mybucket""\nINSTANCE_COUNT = 1\nIMAGE_NAME = ""fakeimage""\nREGION = ""us-west-2""\n\n\nclass DummyFrameworkModel(FrameworkModel):\n    def __init__(self, sagemaker_session, **kwargs):\n        super(DummyFrameworkModel, self).__init__(\n            MODEL_DATA_1,\n            MODEL_IMAGE_1,\n            ROLE,\n            ENTRY_POINT,\n            sagemaker_session=sagemaker_session,\n            **kwargs\n        )\n\n    def create_predictor(self, endpoint_name):\n        return RealTimePredictor(endpoint_name, self.sagemaker_session)\n\n\n@pytest.fixture()\ndef sagemaker_session():\n    boto_mock = Mock(name=""boto_session"", region_name=REGION)\n    sms = Mock(\n        name=""sagemaker_session"",\n        boto_session=boto_mock,\n        boto_region_name=REGION,\n        config=None,\n        local_mode=False,\n        s3_client=None,\n        s3_resource=None,\n    )\n    sms.default_bucket = Mock(name=""default_bucket"", return_value=BUCKET_NAME)\n    return sms\n\n\n@patch(""tarfile.open"")\n@patch(""time.strftime"", return_value=TIMESTAMP)\ndef test_prepare_container_def(tfo, time, sagemaker_session):\n    framework_model = DummyFrameworkModel(sagemaker_session)\n    sparkml_model = SparkMLModel(\n        model_data=MODEL_DATA_2,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        env={""SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT"": ""text/csv""},\n    )\n    model = PipelineModel(\n        models=[framework_model, sparkml_model], role=ROLE, sagemaker_session=sagemaker_session\n    )\n    assert model.pipeline_container_def(INSTANCE_TYPE) == [\n        {\n            ""Environment"": {\n                ""SAGEMAKER_PROGRAM"": ""blah.py"",\n                ""SAGEMAKER_SUBMIT_DIRECTORY"": ""s3://mybucket/mi-1-2017-10-10-14-14-15/sourcedir.tar.gz"",\n                ""SAGEMAKER_CONTAINER_LOG_LEVEL"": ""20"",\n                ""SAGEMAKER_REGION"": ""us-west-2"",\n                ""SAGEMAKER_ENABLE_CLOUDWATCH_METRICS"": ""false"",\n            },\n            ""Image"": ""mi-1"",\n            ""ModelDataUrl"": ""s3://bucket/model_1.tar.gz"",\n        },\n        {\n            ""Environment"": {""SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT"": ""text/csv""},\n            ""Image"": ""246618743249.dkr.ecr.us-west-2.amazonaws.com""\n            + ""/sagemaker-sparkml-serving:2.2"",\n            ""ModelDataUrl"": ""s3://bucket/model_2.tar.gz"",\n        },\n    ]\n\n\n@patch(""tarfile.open"")\n@patch(""time.strftime"", return_value=TIMESTAMP)\ndef test_deploy(tfo, time, sagemaker_session):\n    framework_model = DummyFrameworkModel(sagemaker_session)\n    sparkml_model = SparkMLModel(\n        model_data=MODEL_DATA_2, role=ROLE, sagemaker_session=sagemaker_session\n    )\n    model = PipelineModel(\n        models=[framework_model, sparkml_model], role=ROLE, sagemaker_session=sagemaker_session\n    )\n    model.deploy(instance_type=INSTANCE_TYPE, initial_instance_count=1)\n    sagemaker_session.endpoint_from_production_variants.assert_called_with(\n        name=""mi-1-2017-10-10-14-14-15"",\n        production_variants=[\n            {\n                ""InitialVariantWeight"": 1,\n                ""ModelName"": ""mi-1-2017-10-10-14-14-15"",\n                ""InstanceType"": INSTANCE_TYPE,\n                ""InitialInstanceCount"": 1,\n                ""VariantName"": ""AllTraffic"",\n            }\n        ],\n        tags=None,\n        wait=True,\n        data_capture_config_dict=None,\n    )\n\n\n@patch(""tarfile.open"")\n@patch(""time.strftime"", return_value=TIMESTAMP)\ndef test_deploy_endpoint_name(tfo, time, sagemaker_session):\n    framework_model = DummyFrameworkModel(sagemaker_session)\n    sparkml_model = SparkMLModel(\n        model_data=MODEL_DATA_2, role=ROLE, sagemaker_session=sagemaker_session\n    )\n    model = PipelineModel(\n        models=[framework_model, sparkml_model], role=ROLE, sagemaker_session=sagemaker_session\n    )\n    model.deploy(instance_type=INSTANCE_TYPE, initial_instance_count=1)\n    sagemaker_session.endpoint_from_production_variants.assert_called_with(\n        name=""mi-1-2017-10-10-14-14-15"",\n        production_variants=[\n            {\n                ""InitialVariantWeight"": 1,\n                ""ModelName"": ""mi-1-2017-10-10-14-14-15"",\n                ""InstanceType"": INSTANCE_TYPE,\n                ""InitialInstanceCount"": 1,\n                ""VariantName"": ""AllTraffic"",\n            }\n        ],\n        tags=None,\n        wait=True,\n        data_capture_config_dict=None,\n    )\n\n\n@patch(""tarfile.open"")\n@patch(""time.strftime"", return_value=TIMESTAMP)\ndef test_deploy_update_endpoint(tfo, time, sagemaker_session):\n    framework_model = DummyFrameworkModel(sagemaker_session)\n    endpoint_name = ""endpoint-name""\n    sparkml_model = SparkMLModel(\n        model_data=MODEL_DATA_2, role=ROLE, sagemaker_session=sagemaker_session\n    )\n    model = PipelineModel(\n        models=[framework_model, sparkml_model], role=ROLE, sagemaker_session=sagemaker_session\n    )\n    model.deploy(\n        instance_type=INSTANCE_TYPE,\n        initial_instance_count=1,\n        endpoint_name=endpoint_name,\n        update_endpoint=True,\n    )\n\n    sagemaker_session.create_endpoint_config.assert_called_with(\n        name=model.name,\n        model_name=model.name,\n        initial_instance_count=INSTANCE_COUNT,\n        instance_type=INSTANCE_TYPE,\n        tags=None,\n        data_capture_config_dict=None,\n    )\n    config_name = sagemaker_session.create_endpoint_config(\n        name=model.name,\n        model_name=model.name,\n        initial_instance_count=INSTANCE_COUNT,\n        instance_type=INSTANCE_TYPE,\n    )\n    sagemaker_session.update_endpoint.assert_called_with(endpoint_name, config_name, wait=True)\n    sagemaker_session.create_endpoint.assert_not_called()\n\n\n@patch(""tarfile.open"")\n@patch(""time.strftime"", return_value=TIMESTAMP)\ndef test_transformer(tfo, time, sagemaker_session):\n    framework_model = DummyFrameworkModel(sagemaker_session)\n    sparkml_model = SparkMLModel(\n        model_data=MODEL_DATA_2, role=ROLE, sagemaker_session=sagemaker_session\n    )\n    model_name = ""ModelName""\n    model = PipelineModel(\n        models=[framework_model, sparkml_model],\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        name=model_name,\n    )\n\n    instance_count = 55\n    strategy = ""MultiRecord""\n    assemble_with = ""Line""\n    output_path = ""s3://output/path""\n    output_kms_key = ""output:kms:key""\n    accept = ""application/jsonlines""\n    env = {""my_key"": ""my_value""}\n    max_concurrent_transforms = 20\n    max_payload = 5\n    tags = [{""my_tag"": ""my_value""}]\n    volume_kms_key = ""volume:kms:key""\n    transformer = model.transformer(\n        instance_type=INSTANCE_TYPE,\n        instance_count=instance_count,\n        strategy=strategy,\n        assemble_with=assemble_with,\n        output_path=output_path,\n        output_kms_key=output_kms_key,\n        accept=accept,\n        env=env,\n        max_concurrent_transforms=max_concurrent_transforms,\n        max_payload=max_payload,\n        tags=tags,\n        volume_kms_key=volume_kms_key,\n    )\n    assert transformer.instance_type == INSTANCE_TYPE\n    assert transformer.instance_count == instance_count\n    assert transformer.strategy == strategy\n    assert transformer.assemble_with == assemble_with\n    assert transformer.output_path == output_path\n    assert transformer.output_kms_key == output_kms_key\n    assert transformer.accept == accept\n    assert transformer.env == env\n    assert transformer.max_concurrent_transforms == max_concurrent_transforms\n    assert transformer.max_payload == max_payload\n    assert transformer.tags == tags\n    assert transformer.volume_kms_key == volume_kms_key\n    assert transformer.model_name == model_name\n\n\n@patch(""tarfile.open"")\n@patch(""time.strftime"", return_value=TIMESTAMP)\ndef test_deploy_tags(tfo, time, sagemaker_session):\n    framework_model = DummyFrameworkModel(sagemaker_session)\n    sparkml_model = SparkMLModel(\n        model_data=MODEL_DATA_2, role=ROLE, sagemaker_session=sagemaker_session\n    )\n    model = PipelineModel(\n        models=[framework_model, sparkml_model], role=ROLE, sagemaker_session=sagemaker_session\n    )\n    tags = [{""ModelName"": ""TestModel""}]\n    model.deploy(instance_type=INSTANCE_TYPE, initial_instance_count=1, tags=tags)\n    sagemaker_session.endpoint_from_production_variants.assert_called_with(\n        name=""mi-1-2017-10-10-14-14-15"",\n        production_variants=[\n            {\n                ""InitialVariantWeight"": 1,\n                ""ModelName"": ""mi-1-2017-10-10-14-14-15"",\n                ""InstanceType"": INSTANCE_TYPE,\n                ""InitialInstanceCount"": 1,\n                ""VariantName"": ""AllTraffic"",\n            }\n        ],\n        tags=tags,\n        wait=True,\n        data_capture_config_dict=None,\n    )\n\n\ndef test_delete_model_without_deploy(sagemaker_session):\n    pipeline_model = PipelineModel([], role=ROLE, sagemaker_session=sagemaker_session)\n\n    expected_error_message = ""The SageMaker model must be created before attempting to delete.""\n    with pytest.raises(ValueError, match=expected_error_message):\n        pipeline_model.delete_model()\n\n\n@patch(""tarfile.open"")\n@patch(""time.strftime"", return_value=TIMESTAMP)\ndef test_delete_model(tfo, time, sagemaker_session):\n    framework_model = DummyFrameworkModel(sagemaker_session)\n    pipeline_model = PipelineModel(\n        [framework_model], role=ROLE, sagemaker_session=sagemaker_session\n    )\n    pipeline_model.deploy(instance_type=INSTANCE_TYPE, initial_instance_count=1)\n\n    pipeline_model.delete_model()\n    sagemaker_session.delete_model.assert_called_with(pipeline_model.name)\n'"
tests/unit/test_predictor.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport io\nimport json\nimport os\nimport pytest\nfrom mock import Mock, call\n\nimport numpy as np\n\nfrom sagemaker.predictor import RealTimePredictor\nfrom sagemaker.predictor import (\n    json_serializer,\n    json_deserializer,\n    csv_serializer,\n    csv_deserializer,\n    BytesDeserializer,\n    StringDeserializer,\n    StreamDeserializer,\n    numpy_deserializer,\n    npy_serializer,\n    _NumpyDeserializer,\n)\nfrom tests.unit import DATA_DIR\n\n# testing serialization functions\n\n\ndef test_json_serializer_numpy_valid():\n    result = json_serializer(np.array([1, 2, 3]))\n\n    assert result == ""[1, 2, 3]""\n\n\ndef test_json_serializer_numpy_valid_2dimensional():\n    result = json_serializer(np.array([[1, 2, 3], [3, 4, 5]]))\n\n    assert result == ""[[1, 2, 3], [3, 4, 5]]""\n\n\ndef test_json_serializer_empty():\n    assert json_serializer(np.array([])) == ""[]""\n\n\ndef test_json_serializer_python_array():\n    result = json_serializer([1, 2, 3])\n\n    assert result == ""[1, 2, 3]""\n\n\ndef test_json_serializer_python_dictionary():\n    d = {""gender"": ""m"", ""age"": 22, ""city"": ""Paris""}\n\n    result = json_serializer(d)\n\n    assert json.loads(result) == d\n\n\ndef test_json_serializer_python_invalid_empty():\n    assert json_serializer([]) == ""[]""\n\n\ndef test_json_serializer_python_dictionary_invalid_empty():\n    assert json_serializer({}) == ""{}""\n\n\ndef test_json_serializer_csv_buffer():\n    csv_file_path = os.path.join(DATA_DIR, ""with_integers.csv"")\n    with open(csv_file_path) as csv_file:\n        validation_value = csv_file.read()\n        csv_file.seek(0)\n        result = json_serializer(csv_file)\n        assert result == validation_value\n\n\ndef test_csv_serializer_str():\n    original = ""1,2,3""\n    result = csv_serializer(""1,2,3"")\n\n    assert result == original\n\n\ndef test_csv_serializer_python_array():\n    result = csv_serializer([1, 2, 3])\n\n    assert result == ""1,2,3""\n\n\ndef test_csv_serializer_numpy_valid():\n    result = csv_serializer(np.array([1, 2, 3]))\n\n    assert result == ""1,2,3""\n\n\ndef test_csv_serializer_numpy_valid_2dimensional():\n    result = csv_serializer(np.array([[1, 2, 3], [3, 4, 5]]))\n\n    assert result == ""1,2,3\\n3,4,5""\n\n\ndef test_csv_serializer_list_of_str():\n    result = csv_serializer([""1,2,3"", ""4,5,6""])\n\n    assert result == ""1,2,3\\n4,5,6""\n\n\ndef test_csv_serializer_list_of_list():\n    result = csv_serializer([[1, 2, 3], [3, 4, 5]])\n\n    assert result == ""1,2,3\\n3,4,5""\n\n\ndef test_csv_serializer_list_of_empty():\n    with pytest.raises(ValueError) as invalid_input:\n        csv_serializer(np.array([[], []]))\n\n    assert ""empty array"" in str(invalid_input)\n\n\ndef test_csv_serializer_numpy_invalid_empty():\n    with pytest.raises(ValueError) as invalid_input:\n        csv_serializer(np.array([]))\n\n    assert ""empty array"" in str(invalid_input)\n\n\ndef test_csv_serializer_python_invalid_empty():\n    with pytest.raises(ValueError) as error:\n        csv_serializer([])\n    assert ""empty array"" in str(error)\n\n\ndef test_csv_serializer_csv_reader():\n    csv_file_path = os.path.join(DATA_DIR, ""with_integers.csv"")\n    with open(csv_file_path) as csv_file:\n        validation_data = csv_file.read()\n        csv_file.seek(0)\n        result = csv_serializer(csv_file)\n        assert result == validation_data\n\n\ndef test_csv_deserializer_single_element():\n    result = csv_deserializer(io.BytesIO(b""1""), ""text/csv"")\n    assert result == [[""1""]]\n\n\ndef test_csv_deserializer_array():\n    result = csv_deserializer(io.BytesIO(b""1,2,3""), ""text/csv"")\n    assert result == [[""1"", ""2"", ""3""]]\n\n\ndef test_csv_deserializer_2dimensional():\n    result = csv_deserializer(io.BytesIO(b""1,2,3\\n3,4,5""), ""text/csv"")\n    assert result == [[""1"", ""2"", ""3""], [""3"", ""4"", ""5""]]\n\n\ndef test_json_deserializer_array():\n    result = json_deserializer(io.BytesIO(b""[1, 2, 3]""), ""application/json"")\n\n    assert result == [1, 2, 3]\n\n\ndef test_json_deserializer_2dimensional():\n    result = json_deserializer(io.BytesIO(b""[[1, 2, 3], [3, 4, 5]]""), ""application/json"")\n\n    assert result == [[1, 2, 3], [3, 4, 5]]\n\n\ndef test_json_deserializer_invalid_data():\n    with pytest.raises(ValueError) as error:\n        json_deserializer(io.BytesIO(b""[[1]""), ""application/json"")\n    assert ""column"" in str(error)\n\n\ndef test_bytes_deserializer():\n    result = BytesDeserializer()(io.BytesIO(b""[1, 2, 3]""), ""application/json"")\n\n    assert result == b""[1, 2, 3]""\n\n\ndef test_string_deserializer():\n    result = StringDeserializer()(io.BytesIO(b""[1, 2, 3]""), ""application/json"")\n\n    assert result == ""[1, 2, 3]""\n\n\ndef test_stream_deserializer():\n    stream, content_type = StreamDeserializer()(io.BytesIO(b""[1, 2, 3]""), ""application/json"")\n    result = stream.read()\n    assert result == b""[1, 2, 3]""\n    assert content_type == ""application/json""\n\n\ndef test_npy_serializer_python_array():\n    array = [1, 2, 3]\n    result = npy_serializer(array)\n\n    assert np.array_equal(array, np.load(io.BytesIO(result)))\n\n\ndef test_npy_serializer_python_array_with_dtype():\n    array = [1, 2, 3]\n    dtype = ""float16""\n\n    result = npy_serializer(array, dtype)\n\n    deserialized = np.load(io.BytesIO(result))\n    assert np.array_equal(array, deserialized)\n    assert deserialized.dtype == dtype\n\n\ndef test_npy_serializer_numpy_valid_2_dimensional():\n    array = np.array([[1, 2, 3], [3, 4, 5]])\n    result = npy_serializer(array)\n\n    assert np.array_equal(array, np.load(io.BytesIO(result)))\n\n\ndef test_npy_serializer_numpy_valid_multidimensional():\n    array = np.ones((10, 10, 10, 10))\n    result = npy_serializer(array)\n\n    assert np.array_equal(array, np.load(io.BytesIO(result)))\n\n\ndef test_npy_serializer_numpy_valid_list_of_strings():\n    array = np.array([""one"", ""two"", ""three""])\n    result = npy_serializer(array)\n\n    assert np.array_equal(array, np.load(io.BytesIO(result)))\n\n\ndef test_npy_serializer_from_buffer_or_file():\n    array = np.ones((2, 3))\n    stream = io.BytesIO()\n    np.save(stream, array)\n    stream.seek(0)\n\n    result = npy_serializer(stream)\n\n    assert np.array_equal(array, np.load(io.BytesIO(result)))\n\n\ndef test_npy_serializer_object():\n    object = {1, 2, 3}\n\n    result = npy_serializer(object)\n\n    assert np.array_equal(np.array(object), np.load(io.BytesIO(result), allow_pickle=True))\n\n\ndef test_npy_serializer_list_of_empty():\n    with pytest.raises(ValueError) as invalid_input:\n        npy_serializer(np.array([[], []]))\n\n    assert ""empty array"" in str(invalid_input)\n\n\ndef test_npy_serializer_numpy_invalid_empty():\n    with pytest.raises(ValueError) as invalid_input:\n        npy_serializer(np.array([]))\n\n    assert ""empty array"" in str(invalid_input)\n\n\ndef test_npy_serializer_python_invalid_empty():\n    with pytest.raises(ValueError) as error:\n        npy_serializer([])\n    assert ""empty array"" in str(error)\n\n\ndef test_numpy_deser_from_csv():\n    arr = numpy_deserializer(io.BytesIO(b""1,2,3\\n4,5,6""), ""text/csv"")\n    assert np.array_equal(arr, np.array([[1, 2, 3], [4, 5, 6]]))\n\n\ndef test_numpy_deser_from_csv_ragged():\n    with pytest.raises(ValueError) as error:\n        numpy_deserializer(io.BytesIO(b""1,2,3\\n4,5,6,7""), ""text/csv"")\n    assert ""errors were detected"" in str(error)\n\n\ndef test_numpy_deser_from_csv_alpha():\n    arr = _NumpyDeserializer(dtype=""U5"")(io.BytesIO(b""hello,2,3\\n4,5,6""), ""text/csv"")\n    assert np.array_equal(arr, np.array([[""hello"", 2, 3], [4, 5, 6]]))\n\n\ndef test_numpy_deser_from_json():\n    arr = numpy_deserializer(io.BytesIO(b""[[1,2,3],\\n[4,5,6]]""), ""application/json"")\n    assert np.array_equal(arr, np.array([[1, 2, 3], [4, 5, 6]]))\n\n\n# Sadly, ragged arrays work fine in JSON (giving us a 1D array of Python lists\ndef test_numpy_deser_from_json_ragged():\n    arr = numpy_deserializer(io.BytesIO(b""[[1,2,3],\\n[4,5,6,7]]""), ""application/json"")\n    assert np.array_equal(arr, np.array([[1, 2, 3], [4, 5, 6, 7]]))\n\n\ndef test_numpy_deser_from_json_alpha():\n    arr = _NumpyDeserializer(dtype=""U5"")(\n        io.BytesIO(b\'[[""hello"",2,3],\\n[4,5,6]]\'), ""application/json""\n    )\n    assert np.array_equal(arr, np.array([[""hello"", 2, 3], [4, 5, 6]]))\n\n\ndef test_numpy_deser_from_npy():\n    array = np.ones((2, 3))\n    stream = io.BytesIO()\n    np.save(stream, array)\n    stream.seek(0)\n\n    result = numpy_deserializer(stream)\n\n    assert np.array_equal(array, result)\n\n\ndef test_numpy_deser_from_npy_object_array():\n    array = np.array([""one"", ""two""])\n    stream = io.BytesIO()\n    np.save(stream, array)\n    stream.seek(0)\n\n    result = numpy_deserializer(stream)\n\n    assert np.array_equal(array, result)\n\n\n# testing \'predict\' invocations\n\n\nENDPOINT = ""mxnet_endpoint""\nBUCKET_NAME = ""mxnet_endpoint""\nDEFAULT_CONTENT_TYPE = ""application/json""\nCSV_CONTENT_TYPE = ""text/csv""\nRETURN_VALUE = 0\nCSV_RETURN_VALUE = ""1,2,3\\r\\n""\n\nENDPOINT_DESC = {""EndpointConfigName"": ENDPOINT}\n\nENDPOINT_CONFIG_DESC = {""ProductionVariants"": [{""ModelName"": ""model-1""}, {""ModelName"": ""model-2""}]}\n\n\ndef empty_sagemaker_session():\n    ims = Mock(name=""sagemaker_session"")\n    ims.default_bucket = Mock(name=""default_bucket"", return_value=BUCKET_NAME)\n    ims.sagemaker_runtime_client = Mock(name=""sagemaker_runtime"")\n    ims.sagemaker_client.describe_endpoint = Mock(return_value=ENDPOINT_DESC)\n    ims.sagemaker_client.describe_endpoint_config = Mock(return_value=ENDPOINT_CONFIG_DESC)\n\n    response_body = Mock(""body"")\n    response_body.read = Mock(""read"", return_value=RETURN_VALUE)\n    response_body.close = Mock(""close"", return_value=None)\n    ims.sagemaker_runtime_client.invoke_endpoint = Mock(\n        name=""invoke_endpoint"", return_value={""Body"": response_body}\n    )\n    return ims\n\n\ndef test_predict_call_pass_through():\n    sagemaker_session = empty_sagemaker_session()\n    predictor = RealTimePredictor(ENDPOINT, sagemaker_session)\n\n    data = ""untouched""\n    result = predictor.predict(data)\n\n    assert sagemaker_session.sagemaker_runtime_client.invoke_endpoint.called\n\n    expected_request_args = {""Body"": data, ""EndpointName"": ENDPOINT}\n    call_args, kwargs = sagemaker_session.sagemaker_runtime_client.invoke_endpoint.call_args\n    assert kwargs == expected_request_args\n\n    assert result == RETURN_VALUE\n\n\ndef test_predict_call_with_headers():\n    sagemaker_session = empty_sagemaker_session()\n    predictor = RealTimePredictor(\n        ENDPOINT, sagemaker_session, content_type=DEFAULT_CONTENT_TYPE, accept=DEFAULT_CONTENT_TYPE\n    )\n\n    data = ""untouched""\n    result = predictor.predict(data)\n\n    assert sagemaker_session.sagemaker_runtime_client.invoke_endpoint.called\n\n    expected_request_args = {\n        ""Accept"": DEFAULT_CONTENT_TYPE,\n        ""Body"": data,\n        ""ContentType"": DEFAULT_CONTENT_TYPE,\n        ""EndpointName"": ENDPOINT,\n    }\n    call_args, kwargs = sagemaker_session.sagemaker_runtime_client.invoke_endpoint.call_args\n    assert kwargs == expected_request_args\n\n    assert result == RETURN_VALUE\n\n\ndef test_multi_model_predict_call_with_headers():\n    sagemaker_session = empty_sagemaker_session()\n    predictor = RealTimePredictor(\n        ENDPOINT, sagemaker_session, content_type=DEFAULT_CONTENT_TYPE, accept=DEFAULT_CONTENT_TYPE\n    )\n\n    data = ""untouched""\n    result = predictor.predict(data, target_model=""model.tar.gz"")\n\n    assert sagemaker_session.sagemaker_runtime_client.invoke_endpoint.called\n\n    expected_request_args = {\n        ""Accept"": DEFAULT_CONTENT_TYPE,\n        ""Body"": data,\n        ""ContentType"": DEFAULT_CONTENT_TYPE,\n        ""EndpointName"": ENDPOINT,\n        ""TargetModel"": ""model.tar.gz"",\n    }\n    call_args, kwargs = sagemaker_session.sagemaker_runtime_client.invoke_endpoint.call_args\n    assert kwargs == expected_request_args\n\n    assert result == RETURN_VALUE\n\n\ndef json_sagemaker_session():\n    ims = Mock(name=""sagemaker_session"")\n    ims.default_bucket = Mock(name=""default_bucket"", return_value=BUCKET_NAME)\n    ims.sagemaker_runtime_client = Mock(name=""sagemaker_runtime"")\n    ims.sagemaker_client.describe_endpoint = Mock(return_value=ENDPOINT_DESC)\n    ims.sagemaker_client.describe_endpoint_config = Mock(return_value=ENDPOINT_CONFIG_DESC)\n\n    ims.sagemaker_client.describe_endpoint = Mock(return_value=ENDPOINT_DESC)\n    ims.sagemaker_client.describe_endpoint_config = Mock(return_value=ENDPOINT_CONFIG_DESC)\n\n    response_body = Mock(""body"")\n    response_body.read = Mock(""read"", return_value=json.dumps([RETURN_VALUE]))\n    response_body.close = Mock(""close"", return_value=None)\n    ims.sagemaker_runtime_client.invoke_endpoint = Mock(\n        name=""invoke_endpoint"",\n        return_value={""Body"": response_body, ""ContentType"": DEFAULT_CONTENT_TYPE},\n    )\n    return ims\n\n\ndef test_predict_call_with_headers_and_json():\n    sagemaker_session = json_sagemaker_session()\n    predictor = RealTimePredictor(\n        ENDPOINT,\n        sagemaker_session,\n        content_type=""not/json"",\n        accept=""also/not-json"",\n        serializer=json_serializer,\n    )\n\n    data = [1, 2]\n    result = predictor.predict(data)\n\n    assert sagemaker_session.sagemaker_runtime_client.invoke_endpoint.called\n\n    expected_request_args = {\n        ""Accept"": ""also/not-json"",\n        ""Body"": json.dumps(data),\n        ""ContentType"": ""not/json"",\n        ""EndpointName"": ENDPOINT,\n    }\n    call_args, kwargs = sagemaker_session.sagemaker_runtime_client.invoke_endpoint.call_args\n    assert kwargs == expected_request_args\n\n    assert result == json.dumps([RETURN_VALUE])\n\n\ndef ret_csv_sagemaker_session():\n    ims = Mock(name=""sagemaker_session"")\n    ims.default_bucket = Mock(name=""default_bucket"", return_value=BUCKET_NAME)\n    ims.sagemaker_runtime_client = Mock(name=""sagemaker_runtime"")\n    ims.sagemaker_client.describe_endpoint = Mock(return_value=ENDPOINT_DESC)\n    ims.sagemaker_client.describe_endpoint_config = Mock(return_value=ENDPOINT_CONFIG_DESC)\n\n    ims.sagemaker_client.describe_endpoint = Mock(return_value=ENDPOINT_DESC)\n    ims.sagemaker_client.describe_endpoint_config = Mock(return_value=ENDPOINT_CONFIG_DESC)\n\n    response_body = Mock(""body"")\n    response_body.read = Mock(""read"", return_value=CSV_RETURN_VALUE)\n    response_body.close = Mock(""close"", return_value=None)\n    ims.sagemaker_runtime_client.invoke_endpoint = Mock(\n        name=""invoke_endpoint"",\n        return_value={""Body"": response_body, ""ContentType"": CSV_CONTENT_TYPE},\n    )\n    return ims\n\n\ndef test_predict_call_with_headers_and_csv():\n    sagemaker_session = ret_csv_sagemaker_session()\n    predictor = RealTimePredictor(\n        ENDPOINT, sagemaker_session, accept=CSV_CONTENT_TYPE, serializer=csv_serializer\n    )\n\n    data = [1, 2]\n    result = predictor.predict(data)\n\n    assert sagemaker_session.sagemaker_runtime_client.invoke_endpoint.called\n\n    expected_request_args = {\n        ""Accept"": CSV_CONTENT_TYPE,\n        ""Body"": ""1,2"",\n        ""ContentType"": CSV_CONTENT_TYPE,\n        ""EndpointName"": ENDPOINT,\n    }\n    call_args, kwargs = sagemaker_session.sagemaker_runtime_client.invoke_endpoint.call_args\n    assert kwargs == expected_request_args\n\n    assert result == CSV_RETURN_VALUE\n\n\ndef test_delete_endpoint_with_config():\n    sagemaker_session = empty_sagemaker_session()\n    sagemaker_session.sagemaker_client.describe_endpoint = Mock(\n        return_value={""EndpointConfigName"": ""endpoint-config""}\n    )\n    predictor = RealTimePredictor(ENDPOINT, sagemaker_session=sagemaker_session)\n    predictor.delete_endpoint()\n\n    sagemaker_session.delete_endpoint.assert_called_with(ENDPOINT)\n    sagemaker_session.delete_endpoint_config.assert_called_with(""endpoint-config"")\n\n\ndef test_delete_endpoint_only():\n    sagemaker_session = empty_sagemaker_session()\n    predictor = RealTimePredictor(ENDPOINT, sagemaker_session=sagemaker_session)\n    predictor.delete_endpoint(delete_endpoint_config=False)\n\n    sagemaker_session.delete_endpoint.assert_called_with(ENDPOINT)\n    sagemaker_session.delete_endpoint_config.assert_not_called()\n\n\ndef test_delete_model():\n    sagemaker_session = empty_sagemaker_session()\n    predictor = RealTimePredictor(ENDPOINT, sagemaker_session=sagemaker_session)\n\n    predictor.delete_model()\n\n    expected_call_count = 2\n    expected_call_args_list = [call(""model-1""), call(""model-2"")]\n    assert sagemaker_session.delete_model.call_count == expected_call_count\n    assert sagemaker_session.delete_model.call_args_list == expected_call_args_list\n\n\ndef test_delete_model_fail():\n    sagemaker_session = empty_sagemaker_session()\n    sagemaker_session.sagemaker_client.delete_model = Mock(\n        side_effect=Exception(""Could not find model."")\n    )\n    expected_error_message = ""One or more models cannot be deleted, please retry.""\n\n    predictor = RealTimePredictor(ENDPOINT, sagemaker_session=sagemaker_session)\n\n    with pytest.raises(Exception) as exception:\n        predictor.delete_model()\n        assert expected_error_message in str(exception.val)\n'"
tests/unit/test_processing.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport pytest\nfrom mock import Mock, patch, MagicMock\n\nfrom sagemaker.processing import (\n    ProcessingInput,\n    ProcessingOutput,\n    Processor,\n    ScriptProcessor,\n    ProcessingJob,\n)\nfrom sagemaker.sklearn.processing import SKLearnProcessor\nfrom sagemaker.network import NetworkConfig\n\nBUCKET_NAME = ""mybucket""\nREGION = ""us-west-2""\nROLE = ""arn:aws:iam::012345678901:role/SageMakerRole""\nECR_PREFIX = ""246618743249.dkr.ecr.us-west-2.amazonaws.com""\nCUSTOM_IMAGE_URI = ""012345678901.dkr.ecr.us-west-2.amazonaws.com/my-custom-image-uri""\n\nPROCESSING_JOB_DESCRIPTION = {\n    ""ProcessingInputs"": [\n        {\n            ""InputName"": ""my_dataset"",\n            ""S3Input"": {\n                ""S3Uri"": ""s3://path/to/my/dataset/census.csv"",\n                ""LocalPath"": ""/container/path/"",\n                ""S3DataType"": ""S3Prefix"",\n                ""S3InputMode"": ""File"",\n                ""S3DataDistributionType"": ""FullyReplicated"",\n                ""S3CompressionType"": ""None"",\n            },\n        },\n        {\n            ""InputName"": ""code"",\n            ""S3Input"": {\n                ""S3Uri"": ""mocked_s3_uri_from_upload_data"",\n                ""LocalPath"": ""/opt/ml/processing/input/code"",\n                ""S3DataType"": ""S3Prefix"",\n                ""S3InputMode"": ""File"",\n                ""S3DataDistributionType"": ""FullyReplicated"",\n                ""S3CompressionType"": ""None"",\n            },\n        },\n    ],\n    ""ProcessingOutputConfig"": {\n        ""Outputs"": [\n            {\n                ""OutputName"": ""my_output"",\n                ""S3Output"": {\n                    ""S3Uri"": ""s3://uri/"",\n                    ""LocalPath"": ""/container/path/"",\n                    ""S3UploadMode"": ""EndOfJob"",\n                },\n            }\n        ],\n        ""KmsKeyId"": ""arn:aws:kms:us-west-2:012345678901:key/output-kms-key"",\n    },\n}\n\n\n@pytest.fixture()\ndef sagemaker_session():\n    boto_mock = Mock(name=""boto_session"", region_name=REGION)\n    session_mock = MagicMock(\n        name=""sagemaker_session"",\n        boto_session=boto_mock,\n        boto_region_name=REGION,\n        config=None,\n        local_mode=False,\n    )\n    session_mock.default_bucket = Mock(name=""default_bucket"", return_value=BUCKET_NAME)\n\n    session_mock.upload_data = Mock(\n        name=""upload_data"", return_value=""mocked_s3_uri_from_upload_data""\n    )\n    session_mock.download_data = Mock(name=""download_data"")\n    session_mock.expand_role.return_value = ROLE\n    session_mock.describe_processing_job = MagicMock(\n        name=""describe_processing_job"", return_value=PROCESSING_JOB_DESCRIPTION\n    )\n    return session_mock\n\n\n@patch(""sagemaker.fw_registry.get_ecr_image_uri_prefix"", return_value=ECR_PREFIX)\n@patch(""os.path.exists"", return_value=True)\n@patch(""os.path.isfile"", return_value=True)\ndef test_sklearn_processor_with_required_parameters(\n    exists_mock, isfile_mock, ecr_prefix, sagemaker_session\n):\n    processor = SKLearnProcessor(\n        role=ROLE,\n        instance_type=""ml.m4.xlarge"",\n        framework_version=""0.20.0"",\n        instance_count=1,\n        sagemaker_session=sagemaker_session,\n    )\n\n    processor.run(code=""/local/path/to/processing_code.py"")\n\n    expected_args = _get_expected_args(processor._current_job_name)\n\n    sklearn_image_uri = (\n        ""246618743249.dkr.ecr.us-west-2.amazonaws.com/sagemaker-scikit-learn:0.20.0-cpu-py3""\n    )\n    expected_args[""app_specification""][""ImageUri""] = sklearn_image_uri\n\n    sagemaker_session.process.assert_called_with(**expected_args)\n\n\n@patch(""sagemaker.fw_registry.get_ecr_image_uri_prefix"", return_value=ECR_PREFIX)\n@patch(""os.path.exists"", return_value=True)\n@patch(""os.path.isfile"", return_value=True)\ndef test_sklearn_with_all_parameters(exists_mock, isfile_mock, ecr_prefix, sagemaker_session):\n    processor = SKLearnProcessor(\n        role=ROLE,\n        framework_version=""0.20.0"",\n        instance_type=""ml.m4.xlarge"",\n        instance_count=1,\n        volume_size_in_gb=100,\n        volume_kms_key=""arn:aws:kms:us-west-2:012345678901:key/volume-kms-key"",\n        output_kms_key=""arn:aws:kms:us-west-2:012345678901:key/output-kms-key"",\n        max_runtime_in_seconds=3600,\n        base_job_name=""my_sklearn_processor"",\n        env={""my_env_variable"": ""my_env_variable_value""},\n        tags=[{""Key"": ""my-tag"", ""Value"": ""my-tag-value""}],\n        network_config=NetworkConfig(\n            subnets=[""my_subnet_id""],\n            security_group_ids=[""my_security_group_id""],\n            enable_network_isolation=True,\n            encrypt_inter_container_traffic=True,\n        ),\n        sagemaker_session=sagemaker_session,\n    )\n\n    processor.run(\n        code=""/local/path/to/processing_code.py"",\n        inputs=[\n            ProcessingInput(\n                source=""s3://path/to/my/dataset/census.csv"",\n                destination=""/container/path/"",\n                input_name=""my_dataset"",\n                s3_data_type=""S3Prefix"",\n                s3_input_mode=""File"",\n                s3_data_distribution_type=""FullyReplicated"",\n                s3_compression_type=""None"",\n            )\n        ],\n        outputs=[\n            ProcessingOutput(\n                source=""/container/path/"",\n                destination=""s3://uri/"",\n                output_name=""my_output"",\n                s3_upload_mode=""EndOfJob"",\n            )\n        ],\n        arguments=[""--drop-columns"", ""\'SelfEmployed\'""],\n        wait=True,\n        logs=False,\n        job_name=""my_job_name"",\n        experiment_config={""ExperimentName"": ""AnExperiment""},\n    )\n\n    expected_args = _get_expected_args_all_parameters(processor._current_job_name)\n    sklearn_image_uri = (\n        ""246618743249.dkr.ecr.us-west-2.amazonaws.com/sagemaker-scikit-learn:0.20.0-cpu-py3""\n    )\n    expected_args[""app_specification""][""ImageUri""] = sklearn_image_uri\n\n    sagemaker_session.process.assert_called_with(**expected_args)\n\n\n@patch(""os.path.exists"", return_value=True)\n@patch(""os.path.isfile"", return_value=True)\ndef test_sklearn_processor_errors_with_invalid_framework_version(\n    exists_mock, isfile_mock, sagemaker_session\n):\n    with pytest.raises(ValueError):\n        SKLearnProcessor(\n            role=ROLE,\n            framework_version=""0.21.0"",\n            instance_type=""ml.m4.xlarge"",\n            instance_count=1,\n            sagemaker_session=sagemaker_session,\n        )\n\n\n@patch(""os.path.exists"", return_value=False)\ndef test_script_processor_errors_with_nonexistent_local_code(exists_mock, sagemaker_session):\n    processor = _get_script_processor(sagemaker_session)\n    with pytest.raises(ValueError):\n        processor.run(code=""/local/path/to/processing_code.py"")\n\n\n@patch(""os.path.exists"", return_value=True)\n@patch(""os.path.isfile"", return_value=False)\ndef test_script_processor_errors_with_code_directory(exists_mock, isfile_mock, sagemaker_session):\n    processor = _get_script_processor(sagemaker_session)\n    with pytest.raises(ValueError):\n        processor.run(code=""/local/path/to/code"")\n\n\n@patch(""os.path.exists"", return_value=True)\n@patch(""os.path.isfile"", return_value=True)\ndef test_script_processor_errors_with_invalid_code_url_scheme(\n    exists_mock, isfile_mock, sagemaker_session\n):\n    processor = _get_script_processor(sagemaker_session)\n    with pytest.raises(ValueError):\n        processor.run(code=""hdfs:///path/to/processing_code.py"")\n\n\n@patch(""os.path.exists"", return_value=True)\n@patch(""os.path.isfile"", return_value=True)\ndef test_script_processor_works_with_absolute_local_path(\n    exists_mock, isfile_mock, sagemaker_session\n):\n    processor = _get_script_processor(sagemaker_session)\n    processor.run(code=""/local/path/to/processing_code.py"")\n\n    expected_args = _get_expected_args(processor._current_job_name)\n\n    sagemaker_session.process.assert_called_with(**expected_args)\n\n\n@patch(""os.path.exists"", return_value=True)\n@patch(""os.path.isfile"", return_value=True)\ndef test_script_processor_works_with_relative_local_path(\n    exists_mock, isfile_mock, sagemaker_session\n):\n    processor = _get_script_processor(sagemaker_session)\n    processor.run(code=""processing_code.py"")\n\n    expected_args = _get_expected_args(processor._current_job_name)\n    sagemaker_session.process.assert_called_with(**expected_args)\n\n\n@patch(""os.path.exists"", return_value=True)\n@patch(""os.path.isfile"", return_value=True)\ndef test_script_processor_works_with_relative_local_path_with_directories(\n    exists_mock, isfile_mock, sagemaker_session\n):\n    processor = _get_script_processor(sagemaker_session)\n    processor.run(code=""path/to/processing_code.py"")\n    expected_args = _get_expected_args(processor._current_job_name)\n    sagemaker_session.process.assert_called_with(**expected_args)\n\n\n@patch(""os.path.exists"", return_value=True)\n@patch(""os.path.isfile"", return_value=True)\ndef test_script_processor_works_with_file_code_url_scheme(\n    exists_mock, isfile_mock, sagemaker_session\n):\n    processor = _get_script_processor(sagemaker_session)\n    processor.run(code=""file:///path/to/processing_code.py"")\n\n    expected_args = _get_expected_args(processor._current_job_name)\n    sagemaker_session.process.assert_called_with(**expected_args)\n\n\n@patch(""os.path.exists"", return_value=True)\n@patch(""os.path.isfile"", return_value=True)\ndef test_script_processor_works_with_s3_code_url(exists_mock, isfile_mock, sagemaker_session):\n    processor = _get_script_processor(sagemaker_session)\n    processor.run(code=""s3://bucket/path/to/processing_code.py"")\n\n    expected_args = _get_expected_args(\n        processor._current_job_name, ""s3://bucket/path/to/processing_code.py""\n    )\n    sagemaker_session.process.assert_called_with(**expected_args)\n\n\n@patch(""os.path.exists"", return_value=True)\n@patch(""os.path.isfile"", return_value=True)\ndef test_script_processor_with_one_input(exists_mock, isfile_mock, sagemaker_session):\n    processor = _get_script_processor(sagemaker_session)\n    processor.run(\n        code=""/local/path/to/processing_code.py"",\n        inputs=[\n            ProcessingInput(source=""/local/path/to/my/dataset/census.csv"", destination=""/data/"")\n        ],\n    )\n\n    expected_args = _get_expected_args(processor._current_job_name)\n    expected_args[""inputs""].insert(0, _get_data_input())\n\n    sagemaker_session.process.assert_called_with(**expected_args)\n\n\n@patch(""os.path.exists"", return_value=True)\n@patch(""os.path.isfile"", return_value=True)\ndef test_script_processor_with_required_parameters(exists_mock, isfile_mock, sagemaker_session):\n    processor = _get_script_processor(sagemaker_session)\n\n    processor.run(code=""/local/path/to/processing_code.py"")\n\n    expected_args = _get_expected_args(processor._current_job_name)\n    sagemaker_session.process.assert_called_with(**expected_args)\n\n\n@patch(""os.path.exists"", return_value=True)\n@patch(""os.path.isfile"", return_value=True)\ndef test_script_processor_with_all_parameters(exists_mock, isfile_mock, sagemaker_session):\n    processor = ScriptProcessor(\n        role=ROLE,\n        image_uri=CUSTOM_IMAGE_URI,\n        command=[""python3""],\n        instance_type=""ml.m4.xlarge"",\n        instance_count=1,\n        volume_size_in_gb=100,\n        volume_kms_key=""arn:aws:kms:us-west-2:012345678901:key/volume-kms-key"",\n        output_kms_key=""arn:aws:kms:us-west-2:012345678901:key/output-kms-key"",\n        max_runtime_in_seconds=3600,\n        base_job_name=""my_sklearn_processor"",\n        env={""my_env_variable"": ""my_env_variable_value""},\n        tags=[{""Key"": ""my-tag"", ""Value"": ""my-tag-value""}],\n        network_config=NetworkConfig(\n            subnets=[""my_subnet_id""],\n            security_group_ids=[""my_security_group_id""],\n            enable_network_isolation=True,\n            encrypt_inter_container_traffic=True,\n        ),\n        sagemaker_session=sagemaker_session,\n    )\n\n    processor.run(\n        code=""/local/path/to/processing_code.py"",\n        inputs=[\n            ProcessingInput(\n                source=""s3://path/to/my/dataset/census.csv"",\n                destination=""/container/path/"",\n                input_name=""my_dataset"",\n                s3_data_type=""S3Prefix"",\n                s3_input_mode=""File"",\n                s3_data_distribution_type=""FullyReplicated"",\n                s3_compression_type=""None"",\n            )\n        ],\n        outputs=[\n            ProcessingOutput(\n                source=""/container/path/"",\n                destination=""s3://uri/"",\n                output_name=""my_output"",\n                s3_upload_mode=""EndOfJob"",\n            )\n        ],\n        arguments=[""--drop-columns"", ""\'SelfEmployed\'""],\n        wait=True,\n        logs=False,\n        job_name=""my_job_name"",\n        experiment_config={""ExperimentName"": ""AnExperiment""},\n    )\n\n    expected_args = _get_expected_args_all_parameters(processor._current_job_name)\n\n    sagemaker_session.process.assert_called_with(**expected_args)\n    assert ""my_job_name"" in processor._current_job_name\n\n\ndef test_processor_with_required_parameters(sagemaker_session):\n    processor = Processor(\n        role=ROLE,\n        image_uri=CUSTOM_IMAGE_URI,\n        instance_count=1,\n        instance_type=""ml.m4.xlarge"",\n        sagemaker_session=sagemaker_session,\n    )\n\n    processor.run()\n\n    expected_args = _get_expected_args(processor._current_job_name)\n    del expected_args[""app_specification""][""ContainerEntrypoint""]\n    expected_args[""inputs""] = []\n\n    sagemaker_session.process.assert_called_with(**expected_args)\n\n\ndef test_processor_with_missing_network_config_parameters(sagemaker_session):\n    processor = Processor(\n        role=ROLE,\n        image_uri=CUSTOM_IMAGE_URI,\n        instance_count=1,\n        instance_type=""ml.m4.xlarge"",\n        sagemaker_session=sagemaker_session,\n        network_config=NetworkConfig(enable_network_isolation=True),\n    )\n\n    processor.run()\n\n    expected_args = _get_expected_args(processor._current_job_name)\n    del expected_args[""app_specification""][""ContainerEntrypoint""]\n    expected_args[""inputs""] = []\n    expected_args[""network_config""] = {""EnableNetworkIsolation"": True}\n\n    sagemaker_session.process.assert_called_with(**expected_args)\n\n\ndef test_processor_with_encryption_parameter_in_network_config(sagemaker_session):\n    processor = Processor(\n        role=ROLE,\n        image_uri=CUSTOM_IMAGE_URI,\n        instance_count=1,\n        instance_type=""ml.m4.xlarge"",\n        sagemaker_session=sagemaker_session,\n        network_config=NetworkConfig(encrypt_inter_container_traffic=False),\n    )\n\n    processor.run()\n\n    expected_args = _get_expected_args(processor._current_job_name)\n    del expected_args[""app_specification""][""ContainerEntrypoint""]\n    expected_args[""inputs""] = []\n    expected_args[""network_config""] = {\n        ""EnableNetworkIsolation"": False,\n        ""EnableInterContainerTrafficEncryption"": False,\n    }\n\n    sagemaker_session.process.assert_called_with(**expected_args)\n\n\ndef test_processor_with_all_parameters(sagemaker_session):\n    processor = Processor(\n        role=ROLE,\n        image_uri=CUSTOM_IMAGE_URI,\n        instance_count=1,\n        instance_type=""ml.m4.xlarge"",\n        sagemaker_session=sagemaker_session,\n        entrypoint=[""python3"", ""/opt/ml/processing/input/code/processing_code.py""],\n        volume_size_in_gb=100,\n        volume_kms_key=""arn:aws:kms:us-west-2:012345678901:key/volume-kms-key"",\n        output_kms_key=""arn:aws:kms:us-west-2:012345678901:key/output-kms-key"",\n        max_runtime_in_seconds=3600,\n        base_job_name=""processor_base_name"",\n        env={""my_env_variable"": ""my_env_variable_value""},\n        tags=[{""Key"": ""my-tag"", ""Value"": ""my-tag-value""}],\n        network_config=NetworkConfig(\n            subnets=[""my_subnet_id""],\n            security_group_ids=[""my_security_group_id""],\n            enable_network_isolation=True,\n            encrypt_inter_container_traffic=True,\n        ),\n    )\n\n    processor.run(\n        inputs=[\n            ProcessingInput(\n                source=""s3://path/to/my/dataset/census.csv"",\n                destination=""/container/path/"",\n                input_name=""my_dataset"",\n                s3_data_type=""S3Prefix"",\n                s3_input_mode=""File"",\n                s3_data_distribution_type=""FullyReplicated"",\n                s3_compression_type=""None"",\n            )\n        ],\n        outputs=[\n            ProcessingOutput(\n                source=""/container/path/"",\n                destination=""s3://uri/"",\n                output_name=""my_output"",\n                s3_upload_mode=""EndOfJob"",\n            )\n        ],\n        arguments=[""--drop-columns"", ""\'SelfEmployed\'""],\n        wait=True,\n        logs=False,\n        job_name=""my_job_name"",\n        experiment_config={""ExperimentName"": ""AnExperiment""},\n    )\n\n    expected_args = _get_expected_args_all_parameters(processor._current_job_name)\n    # Drop the ""code"" input from expected values.\n    expected_args[""inputs""] = [expected_args[""inputs""][0]]\n\n    sagemaker_session.process.assert_called_with(**expected_args)\n\n\ndef test_processing_job_from_processing_arn(sagemaker_session):\n    processing_job = ProcessingJob.from_processing_arn(\n        sagemaker_session=sagemaker_session,\n        processing_job_arn=""arn:aws:sagemaker:dummy-region:dummy-account-number:processing-job/dummy-job-name"",\n    )\n    assert isinstance(processing_job, ProcessingJob)\n    assert [\n        processing_input._to_request_dict() for processing_input in processing_job.inputs\n    ] == PROCESSING_JOB_DESCRIPTION[""ProcessingInputs""]\n    assert [\n        processing_output._to_request_dict() for processing_output in processing_job.outputs\n    ] == PROCESSING_JOB_DESCRIPTION[""ProcessingOutputConfig""][""Outputs""]\n    assert (\n        processing_job.output_kms_key\n        == PROCESSING_JOB_DESCRIPTION[""ProcessingOutputConfig""][""KmsKeyId""]\n    )\n\n\ndef _get_script_processor(sagemaker_session):\n    return ScriptProcessor(\n        role=ROLE,\n        image_uri=CUSTOM_IMAGE_URI,\n        command=[""python3""],\n        instance_type=""ml.m4.xlarge"",\n        instance_count=1,\n        sagemaker_session=sagemaker_session,\n    )\n\n\ndef _get_expected_args(job_name, code_s3_uri=""mocked_s3_uri_from_upload_data""):\n    return {\n        ""inputs"": [\n            {\n                ""InputName"": ""code"",\n                ""S3Input"": {\n                    ""S3Uri"": code_s3_uri,\n                    ""LocalPath"": ""/opt/ml/processing/input/code"",\n                    ""S3DataType"": ""S3Prefix"",\n                    ""S3InputMode"": ""File"",\n                    ""S3DataDistributionType"": ""FullyReplicated"",\n                    ""S3CompressionType"": ""None"",\n                },\n            }\n        ],\n        ""output_config"": {""Outputs"": []},\n        ""job_name"": job_name,\n        ""resources"": {\n            ""ClusterConfig"": {\n                ""InstanceType"": ""ml.m4.xlarge"",\n                ""InstanceCount"": 1,\n                ""VolumeSizeInGB"": 30,\n            }\n        },\n        ""stopping_condition"": None,\n        ""app_specification"": {\n            ""ImageUri"": CUSTOM_IMAGE_URI,\n            ""ContainerEntrypoint"": [""python3"", ""/opt/ml/processing/input/code/processing_code.py""],\n        },\n        ""environment"": None,\n        ""network_config"": None,\n        ""role_arn"": ROLE,\n        ""tags"": None,\n        ""experiment_config"": None,\n    }\n\n\ndef _get_data_input():\n    data_input = {\n        ""InputName"": ""input-1"",\n        ""S3Input"": {\n            ""S3Uri"": ""mocked_s3_uri_from_upload_data"",\n            ""LocalPath"": ""/data/"",\n            ""S3DataType"": ""S3Prefix"",\n            ""S3InputMode"": ""File"",\n            ""S3DataDistributionType"": ""FullyReplicated"",\n            ""S3CompressionType"": ""None"",\n        },\n    }\n    return data_input\n\n\ndef _get_expected_args_all_parameters(job_name):\n    return {\n        ""inputs"": [\n            {\n                ""InputName"": ""my_dataset"",\n                ""S3Input"": {\n                    ""S3Uri"": ""s3://path/to/my/dataset/census.csv"",\n                    ""LocalPath"": ""/container/path/"",\n                    ""S3DataType"": ""S3Prefix"",\n                    ""S3InputMode"": ""File"",\n                    ""S3DataDistributionType"": ""FullyReplicated"",\n                    ""S3CompressionType"": ""None"",\n                },\n            },\n            {\n                ""InputName"": ""code"",\n                ""S3Input"": {\n                    ""S3Uri"": ""mocked_s3_uri_from_upload_data"",\n                    ""LocalPath"": ""/opt/ml/processing/input/code"",\n                    ""S3DataType"": ""S3Prefix"",\n                    ""S3InputMode"": ""File"",\n                    ""S3DataDistributionType"": ""FullyReplicated"",\n                    ""S3CompressionType"": ""None"",\n                },\n            },\n        ],\n        ""output_config"": {\n            ""Outputs"": [\n                {\n                    ""OutputName"": ""my_output"",\n                    ""S3Output"": {\n                        ""S3Uri"": ""s3://uri/"",\n                        ""LocalPath"": ""/container/path/"",\n                        ""S3UploadMode"": ""EndOfJob"",\n                    },\n                }\n            ],\n            ""KmsKeyId"": ""arn:aws:kms:us-west-2:012345678901:key/output-kms-key"",\n        },\n        ""job_name"": job_name,\n        ""resources"": {\n            ""ClusterConfig"": {\n                ""InstanceType"": ""ml.m4.xlarge"",\n                ""InstanceCount"": 1,\n                ""VolumeSizeInGB"": 100,\n                ""VolumeKmsKeyId"": ""arn:aws:kms:us-west-2:012345678901:key/volume-kms-key"",\n            }\n        },\n        ""stopping_condition"": {""MaxRuntimeInSeconds"": 3600},\n        ""app_specification"": {\n            ""ImageUri"": ""012345678901.dkr.ecr.us-west-2.amazonaws.com/my-custom-image-uri"",\n            ""ContainerArguments"": [""--drop-columns"", ""\'SelfEmployed\'""],\n            ""ContainerEntrypoint"": [""python3"", ""/opt/ml/processing/input/code/processing_code.py""],\n        },\n        ""environment"": {""my_env_variable"": ""my_env_variable_value""},\n        ""network_config"": {\n            ""EnableNetworkIsolation"": True,\n            ""EnableInterContainerTrafficEncryption"": True,\n            ""VpcConfig"": {\n                ""SecurityGroupIds"": [""my_security_group_id""],\n                ""Subnets"": [""my_subnet_id""],\n            },\n        },\n        ""role_arn"": ROLE,\n        ""tags"": [{""Key"": ""my-tag"", ""Value"": ""my-tag-value""}],\n        ""experiment_config"": {""ExperimentName"": ""AnExperiment""},\n    }\n'"
tests/unit/test_pytorch.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\nimport logging\n\nimport json\nimport os\nimport pytest\nimport sys\nfrom mock import ANY, MagicMock, Mock, patch\n\nfrom sagemaker.pytorch import defaults\nfrom sagemaker.pytorch import PyTorch\nfrom sagemaker.pytorch import PyTorchPredictor, PyTorchModel\n\n\nDATA_DIR = os.path.join(os.path.dirname(__file__), "".."", ""data"")\nSCRIPT_PATH = os.path.join(DATA_DIR, ""dummy_script.py"")\nSERVING_SCRIPT_FILE = ""another_dummy_script.py""\nMODEL_DATA = ""s3://some/data.tar.gz""\nENV = {""DUMMY_ENV_VAR"": ""dummy_value""}\nTIMESTAMP = ""2017-11-06-14:14:15.672""\nTIME = 1507167947\nBUCKET_NAME = ""mybucket""\nINSTANCE_COUNT = 1\nINSTANCE_TYPE = ""ml.c4.4xlarge""\nACCELERATOR_TYPE = ""ml.eia.medium""\nPYTHON_VERSION = ""py"" + str(sys.version_info.major)\nIMAGE_NAME = ""sagemaker-pytorch""\nJOB_NAME = ""{}-{}"".format(IMAGE_NAME, TIMESTAMP)\nIMAGE_URI_FORMAT_STRING = ""520713654638.dkr.ecr.{}.amazonaws.com/{}:{}-{}-{}""\nROLE = ""Dummy""\nREGION = ""us-west-2""\nGPU = ""ml.p2.xlarge""\nCPU = ""ml.c4.xlarge""\n\nENDPOINT_DESC = {""EndpointConfigName"": ""test-endpoint""}\n\nENDPOINT_CONFIG_DESC = {""ProductionVariants"": [{""ModelName"": ""model-1""}, {""ModelName"": ""model-2""}]}\n\nLIST_TAGS_RESULT = {""Tags"": [{""Key"": ""TagtestKey"", ""Value"": ""TagtestValue""}]}\n\nEXPERIMENT_CONFIG = {\n    ""ExperimentName"": ""exp"",\n    ""TrialName"": ""trial"",\n    ""TrialComponentDisplayName"": ""tc"",\n}\n\n\n@pytest.fixture(name=""sagemaker_session"")\ndef fixture_sagemaker_session():\n    boto_mock = Mock(name=""boto_session"", region_name=REGION)\n    session = Mock(\n        name=""sagemaker_session"",\n        boto_session=boto_mock,\n        boto_region_name=REGION,\n        config=None,\n        local_mode=False,\n        s3_resource=None,\n        s3_client=None,\n    )\n\n    describe = {""ModelArtifacts"": {""S3ModelArtifacts"": ""s3://m/m.tar.gz""}}\n    session.sagemaker_client.describe_training_job = Mock(return_value=describe)\n    session.sagemaker_client.describe_endpoint = Mock(return_value=ENDPOINT_DESC)\n    session.sagemaker_client.describe_endpoint_config = Mock(return_value=ENDPOINT_CONFIG_DESC)\n    session.sagemaker_client.list_tags = Mock(return_value=LIST_TAGS_RESULT)\n    session.default_bucket = Mock(name=""default_bucket"", return_value=BUCKET_NAME)\n    session.expand_role = Mock(name=""expand_role"", return_value=ROLE)\n    return session\n\n\ndef _get_full_cpu_image_uri(version, py_version=PYTHON_VERSION):\n    return IMAGE_URI_FORMAT_STRING.format(REGION, IMAGE_NAME, version, ""cpu"", py_version)\n\n\ndef _get_full_gpu_image_uri(version, py_version=PYTHON_VERSION):\n    return IMAGE_URI_FORMAT_STRING.format(REGION, IMAGE_NAME, version, ""gpu"", py_version)\n\n\ndef _get_full_cpu_image_uri_with_ei(version, py_version=PYTHON_VERSION):\n    return _get_full_cpu_image_uri(version, py_version=py_version) + ""-eia""\n\n\ndef _pytorch_estimator(\n    sagemaker_session,\n    framework_version=defaults.PYTORCH_VERSION,\n    train_instance_type=None,\n    base_job_name=None,\n    **kwargs\n):\n    return PyTorch(\n        entry_point=SCRIPT_PATH,\n        framework_version=framework_version,\n        py_version=PYTHON_VERSION,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=train_instance_type if train_instance_type else INSTANCE_TYPE,\n        base_job_name=base_job_name,\n        **kwargs\n    )\n\n\ndef _create_train_job(version):\n    return {\n        ""image"": _get_full_cpu_image_uri(version),\n        ""input_mode"": ""File"",\n        ""input_config"": [\n            {\n                ""ChannelName"": ""training"",\n                ""DataSource"": {\n                    ""S3DataSource"": {\n                        ""S3DataDistributionType"": ""FullyReplicated"",\n                        ""S3DataType"": ""S3Prefix"",\n                    }\n                },\n            }\n        ],\n        ""role"": ROLE,\n        ""job_name"": JOB_NAME,\n        ""output_config"": {""S3OutputPath"": ""s3://{}/"".format(BUCKET_NAME)},\n        ""resource_config"": {\n            ""InstanceType"": ""ml.c4.4xlarge"",\n            ""InstanceCount"": 1,\n            ""VolumeSizeInGB"": 30,\n        },\n        ""hyperparameters"": {\n            ""sagemaker_program"": json.dumps(""dummy_script.py""),\n            ""sagemaker_enable_cloudwatch_metrics"": ""false"",\n            ""sagemaker_container_log_level"": str(logging.INFO),\n            ""sagemaker_job_name"": json.dumps(JOB_NAME),\n            ""sagemaker_submit_directory"": json.dumps(\n                ""s3://{}/{}/source/sourcedir.tar.gz"".format(BUCKET_NAME, JOB_NAME)\n            ),\n            ""sagemaker_region"": \'""us-west-2""\',\n        },\n        ""stop_condition"": {""MaxRuntimeInSeconds"": 24 * 60 * 60},\n        ""tags"": None,\n        ""vpc_config"": None,\n        ""metric_definitions"": None,\n        ""experiment_config"": None,\n        ""debugger_hook_config"": {\n            ""CollectionConfigurations"": [],\n            ""S3OutputPath"": ""s3://{}/"".format(BUCKET_NAME),\n        },\n    }\n\n\ndef test_create_model(sagemaker_session, pytorch_version):\n    container_log_level = \'""logging.INFO""\'\n    source_dir = ""s3://mybucket/source""\n    pytorch = PyTorch(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        framework_version=pytorch_version,\n        container_log_level=container_log_level,\n        base_job_name=""job"",\n        source_dir=source_dir,\n    )\n\n    job_name = ""new_name""\n    pytorch.fit(inputs=""s3://mybucket/train"", job_name=""new_name"")\n    model = pytorch.create_model()\n\n    assert model.sagemaker_session == sagemaker_session\n    assert model.framework_version == pytorch_version\n    assert model.py_version == pytorch.py_version\n    assert model.entry_point == SCRIPT_PATH\n    assert model.role == ROLE\n    assert model.name == job_name\n    assert model.container_log_level == container_log_level\n    assert model.source_dir == source_dir\n    assert model.vpc_config is None\n\n\ndef test_create_model_with_optional_params(sagemaker_session):\n    container_log_level = \'""logging.INFO""\'\n    source_dir = ""s3://mybucket/source""\n    enable_cloudwatch_metrics = ""true""\n    pytorch = PyTorch(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        container_log_level=container_log_level,\n        base_job_name=""job"",\n        source_dir=source_dir,\n        enable_cloudwatch_metrics=enable_cloudwatch_metrics,\n    )\n\n    pytorch.fit(inputs=""s3://mybucket/train"", job_name=""new_name"")\n\n    new_role = ""role""\n    model_server_workers = 2\n    vpc_config = {""Subnets"": [""foo""], ""SecurityGroupIds"": [""bar""]}\n    model_name = ""model-name""\n    model = pytorch.create_model(\n        role=new_role,\n        model_server_workers=model_server_workers,\n        vpc_config_override=vpc_config,\n        entry_point=SERVING_SCRIPT_FILE,\n        env=ENV,\n        name=model_name,\n    )\n\n    assert model.role == new_role\n    assert model.model_server_workers == model_server_workers\n    assert model.vpc_config == vpc_config\n    assert model.entry_point == SERVING_SCRIPT_FILE\n    assert model.env == ENV\n    assert model.name == model_name\n\n\ndef test_create_model_with_custom_image(sagemaker_session):\n    container_log_level = \'""logging.INFO""\'\n    source_dir = ""s3://mybucket/source""\n    image = ""pytorch:9000""\n    pytorch = PyTorch(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        container_log_level=container_log_level,\n        image_name=image,\n        base_job_name=""job"",\n        source_dir=source_dir,\n    )\n\n    job_name = ""new_name""\n    pytorch.fit(inputs=""s3://mybucket/train"", job_name=""new_name"")\n    model = pytorch.create_model()\n\n    assert model.sagemaker_session == sagemaker_session\n    assert model.image == image\n    assert model.entry_point == SCRIPT_PATH\n    assert model.role == ROLE\n    assert model.name == job_name\n    assert model.container_log_level == container_log_level\n    assert model.source_dir == source_dir\n\n\n@patch(""sagemaker.utils.create_tar_file"", MagicMock())\n@patch(""time.strftime"", return_value=TIMESTAMP)\ndef test_pytorch(strftime, sagemaker_session, pytorch_version):\n    pytorch = PyTorch(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        framework_version=pytorch_version,\n        py_version=PYTHON_VERSION,\n    )\n\n    inputs = ""s3://mybucket/train""\n\n    pytorch.fit(inputs=inputs, experiment_config=EXPERIMENT_CONFIG)\n\n    sagemaker_call_names = [c[0] for c in sagemaker_session.method_calls]\n    assert sagemaker_call_names == [""train"", ""logs_for_job""]\n    boto_call_names = [c[0] for c in sagemaker_session.boto_session.method_calls]\n    assert boto_call_names == [""resource""]\n\n    expected_train_args = _create_train_job(pytorch_version)\n    expected_train_args[""input_config""][0][""DataSource""][""S3DataSource""][""S3Uri""] = inputs\n    expected_train_args[""experiment_config""] = EXPERIMENT_CONFIG\n\n    actual_train_args = sagemaker_session.method_calls[0][2]\n    assert actual_train_args == expected_train_args\n\n    model = pytorch.create_model()\n\n    expected_image_base = ""520713654638.dkr.ecr.us-west-2.amazonaws.com/sagemaker-pytorch:{}-gpu-{}""\n    assert {\n        ""Environment"": {\n            ""SAGEMAKER_SUBMIT_DIRECTORY"": ""s3://mybucket/sagemaker-pytorch-{}/source/sourcedir.tar.gz"".format(\n                TIMESTAMP\n            ),\n            ""SAGEMAKER_PROGRAM"": ""dummy_script.py"",\n            ""SAGEMAKER_ENABLE_CLOUDWATCH_METRICS"": ""false"",\n            ""SAGEMAKER_REGION"": ""us-west-2"",\n            ""SAGEMAKER_CONTAINER_LOG_LEVEL"": ""20"",\n        },\n        ""Image"": expected_image_base.format(pytorch_version, PYTHON_VERSION),\n        ""ModelDataUrl"": ""s3://m/m.tar.gz"",\n    } == model.prepare_container_def(GPU)\n\n    assert ""cpu"" in model.prepare_container_def(CPU)[""Image""]\n    predictor = pytorch.deploy(1, GPU)\n    assert isinstance(predictor, PyTorchPredictor)\n\n\n@patch(""sagemaker.utils.create_tar_file"", MagicMock())\ndef test_model(sagemaker_session):\n    model = PyTorchModel(\n        MODEL_DATA, role=ROLE, entry_point=SCRIPT_PATH, sagemaker_session=sagemaker_session\n    )\n    predictor = model.deploy(1, GPU)\n    assert isinstance(predictor, PyTorchPredictor)\n\n\n@patch(""sagemaker.utils.create_tar_file"", MagicMock())\n@patch(""sagemaker.utils.repack_model"")\ndef test_mms_model(repack_model, sagemaker_session):\n    PyTorchModel(\n        MODEL_DATA,\n        role=ROLE,\n        entry_point=SCRIPT_PATH,\n        sagemaker_session=sagemaker_session,\n        framework_version=""1.2"",\n    ).deploy(1, GPU)\n\n    repack_model.assert_called_with(\n        dependencies=[],\n        inference_script=SCRIPT_PATH,\n        kms_key=None,\n        model_uri=""s3://some/data.tar.gz"",\n        repacked_model_uri=ANY,\n        sagemaker_session=sagemaker_session,\n        source_directory=None,\n    )\n\n\n@patch(""sagemaker.utils.create_tar_file"", MagicMock())\n@patch(""sagemaker.utils.repack_model"")\ndef test_non_mms_model(repack_model, sagemaker_session):\n    PyTorchModel(\n        MODEL_DATA,\n        role=ROLE,\n        entry_point=SCRIPT_PATH,\n        sagemaker_session=sagemaker_session,\n        framework_version=""1.1"",\n    ).deploy(1, GPU)\n\n    repack_model.assert_not_called()\n\n\n@patch(""sagemaker.fw_utils.tar_and_upload_dir"", MagicMock())\ndef test_model_image_accelerator(sagemaker_session):\n    with pytest.raises(ValueError) as error:\n        model = PyTorchModel(\n            MODEL_DATA,\n            role=ROLE,\n            entry_point=SCRIPT_PATH,\n            sagemaker_session=sagemaker_session,\n            framework_version=""1.3.1"",\n            py_version=""py2"",\n        )\n        model.deploy(1, CPU, accelerator_type=ACCELERATOR_TYPE)\n    assert ""pytorch-serving is not supported with Amazon Elastic Inference in Python 2."" in str(\n        error\n    )\n\n\ndef test_train_image_default(sagemaker_session):\n    pytorch = PyTorch(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n    )\n\n    assert (\n        _get_full_cpu_image_uri(defaults.PYTORCH_VERSION, defaults.PYTHON_VERSION)\n        in pytorch.train_image()\n    )\n\n\ndef test_train_image_cpu_instances(sagemaker_session, pytorch_version):\n    pytorch = _pytorch_estimator(\n        sagemaker_session, pytorch_version, train_instance_type=""ml.c2.2xlarge""\n    )\n    assert pytorch.train_image() == _get_full_cpu_image_uri(pytorch_version)\n\n    pytorch = _pytorch_estimator(\n        sagemaker_session, pytorch_version, train_instance_type=""ml.c4.2xlarge""\n    )\n    assert pytorch.train_image() == _get_full_cpu_image_uri(pytorch_version)\n\n    pytorch = _pytorch_estimator(sagemaker_session, pytorch_version, train_instance_type=""ml.m16"")\n    assert pytorch.train_image() == _get_full_cpu_image_uri(pytorch_version)\n\n\ndef test_train_image_gpu_instances(sagemaker_session, pytorch_version):\n    pytorch = _pytorch_estimator(\n        sagemaker_session, pytorch_version, train_instance_type=""ml.g2.2xlarge""\n    )\n    assert pytorch.train_image() == _get_full_gpu_image_uri(pytorch_version)\n\n    pytorch = _pytorch_estimator(\n        sagemaker_session, pytorch_version, train_instance_type=""ml.p2.2xlarge""\n    )\n    assert pytorch.train_image() == _get_full_gpu_image_uri(pytorch_version)\n\n\ndef test_attach(sagemaker_session, pytorch_version):\n    training_image = ""1.dkr.ecr.us-west-2.amazonaws.com/sagemaker-pytorch:{}-cpu-{}"".format(\n        pytorch_version, PYTHON_VERSION\n    )\n    returned_job_description = {\n        ""AlgorithmSpecification"": {""TrainingInputMode"": ""File"", ""TrainingImage"": training_image},\n        ""HyperParameters"": {\n            ""sagemaker_submit_directory"": \'""s3://some/sourcedir.tar.gz""\',\n            ""sagemaker_program"": \'""iris-dnn-classifier.py""\',\n            ""sagemaker_s3_uri_training"": \'""sagemaker-3/integ-test-data/tf_iris""\',\n            ""sagemaker_enable_cloudwatch_metrics"": ""false"",\n            ""sagemaker_container_log_level"": \'""logging.INFO""\',\n            ""sagemaker_job_name"": \'""neo""\',\n            ""training_steps"": ""100"",\n            ""sagemaker_region"": \'""us-west-2""\',\n        },\n        ""RoleArn"": ""arn:aws:iam::366:role/SageMakerRole"",\n        ""ResourceConfig"": {\n            ""VolumeSizeInGB"": 30,\n            ""InstanceCount"": 1,\n            ""InstanceType"": ""ml.c4.xlarge"",\n        },\n        ""StoppingCondition"": {""MaxRuntimeInSeconds"": 24 * 60 * 60},\n        ""TrainingJobName"": ""neo"",\n        ""TrainingJobStatus"": ""Completed"",\n        ""TrainingJobArn"": ""arn:aws:sagemaker:us-west-2:336:training-job/neo"",\n        ""OutputDataConfig"": {""KmsKeyId"": """", ""S3OutputPath"": ""s3://place/output/neo""},\n        ""TrainingJobOutput"": {""S3TrainingJobOutput"": ""s3://here/output.tar.gz""},\n    }\n    sagemaker_session.sagemaker_client.describe_training_job = Mock(\n        name=""describe_training_job"", return_value=returned_job_description\n    )\n\n    estimator = PyTorch.attach(training_job_name=""neo"", sagemaker_session=sagemaker_session)\n    assert estimator.latest_training_job.job_name == ""neo""\n    assert estimator.py_version == PYTHON_VERSION\n    assert estimator.framework_version == pytorch_version\n    assert estimator.role == ""arn:aws:iam::366:role/SageMakerRole""\n    assert estimator.train_instance_count == 1\n    assert estimator.train_max_run == 24 * 60 * 60\n    assert estimator.input_mode == ""File""\n    assert estimator.base_job_name == ""neo""\n    assert estimator.output_path == ""s3://place/output/neo""\n    assert estimator.output_kms_key == """"\n    assert estimator.hyperparameters()[""training_steps""] == ""100""\n    assert estimator.source_dir == ""s3://some/sourcedir.tar.gz""\n    assert estimator.entry_point == ""iris-dnn-classifier.py""\n\n\ndef test_attach_wrong_framework(sagemaker_session):\n    rjd = {\n        ""AlgorithmSpecification"": {\n            ""TrainingInputMode"": ""File"",\n            ""TrainingImage"": ""1.dkr.ecr.us-west-2.amazonaws.com/sagemaker-mxnet-py2-cpu:1.0.4"",\n        },\n        ""HyperParameters"": {\n            ""sagemaker_submit_directory"": \'""s3://some/sourcedir.tar.gz""\',\n            ""checkpoint_path"": \'""s3://other/1508872349""\',\n            ""sagemaker_program"": \'""iris-dnn-classifier.py""\',\n            ""sagemaker_enable_cloudwatch_metrics"": ""false"",\n            ""sagemaker_container_log_level"": \'""logging.INFO""\',\n            ""training_steps"": ""100"",\n            ""sagemaker_region"": \'""us-west-2""\',\n        },\n        ""RoleArn"": ""arn:aws:iam::366:role/SageMakerRole"",\n        ""ResourceConfig"": {\n            ""VolumeSizeInGB"": 30,\n            ""InstanceCount"": 1,\n            ""InstanceType"": ""ml.c4.xlarge"",\n        },\n        ""StoppingCondition"": {""MaxRuntimeInSeconds"": 24 * 60 * 60},\n        ""TrainingJobName"": ""neo"",\n        ""TrainingJobStatus"": ""Completed"",\n        ""TrainingJobArn"": ""arn:aws:sagemaker:us-west-2:336:training-job/neo"",\n        ""OutputDataConfig"": {""KmsKeyId"": """", ""S3OutputPath"": ""s3://place/output/neo""},\n        ""TrainingJobOutput"": {""S3TrainingJobOutput"": ""s3://here/output.tar.gz""},\n    }\n    sagemaker_session.sagemaker_client.describe_training_job = Mock(\n        name=""describe_training_job"", return_value=rjd\n    )\n\n    with pytest.raises(ValueError) as error:\n        PyTorch.attach(training_job_name=""neo"", sagemaker_session=sagemaker_session)\n    assert ""didn\'t use image for requested framework"" in str(error)\n\n\ndef test_attach_custom_image(sagemaker_session):\n    training_image = ""pytorch:latest""\n    returned_job_description = {\n        ""AlgorithmSpecification"": {""TrainingInputMode"": ""File"", ""TrainingImage"": training_image},\n        ""HyperParameters"": {\n            ""sagemaker_submit_directory"": \'""s3://some/sourcedir.tar.gz""\',\n            ""sagemaker_program"": \'""iris-dnn-classifier.py""\',\n            ""sagemaker_s3_uri_training"": \'""sagemaker-3/integ-test-data/tf_iris""\',\n            ""sagemaker_enable_cloudwatch_metrics"": ""false"",\n            ""sagemaker_container_log_level"": \'""logging.INFO""\',\n            ""sagemaker_job_name"": \'""neo""\',\n            ""training_steps"": ""100"",\n            ""sagemaker_region"": \'""us-west-2""\',\n        },\n        ""RoleArn"": ""arn:aws:iam::366:role/SageMakerRole"",\n        ""ResourceConfig"": {\n            ""VolumeSizeInGB"": 30,\n            ""InstanceCount"": 1,\n            ""InstanceType"": ""ml.c4.xlarge"",\n        },\n        ""StoppingCondition"": {""MaxRuntimeInSeconds"": 24 * 60 * 60},\n        ""TrainingJobName"": ""neo"",\n        ""TrainingJobStatus"": ""Completed"",\n        ""TrainingJobArn"": ""arn:aws:sagemaker:us-west-2:336:training-job/neo"",\n        ""OutputDataConfig"": {""KmsKeyId"": """", ""S3OutputPath"": ""s3://place/output/neo""},\n        ""TrainingJobOutput"": {""S3TrainingJobOutput"": ""s3://here/output.tar.gz""},\n    }\n    sagemaker_session.sagemaker_client.describe_training_job = Mock(\n        name=""describe_training_job"", return_value=returned_job_description\n    )\n\n    estimator = PyTorch.attach(training_job_name=""neo"", sagemaker_session=sagemaker_session)\n    assert estimator.latest_training_job.job_name == ""neo""\n    assert estimator.image_name == training_image\n    assert estimator.train_image() == training_image\n\n\n@patch(""sagemaker.pytorch.estimator.python_deprecation_warning"")\ndef test_estimator_py2_warning(warning, sagemaker_session):\n    estimator = PyTorch(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        py_version=""py2"",\n    )\n\n    assert estimator.py_version == ""py2""\n    warning.assert_called_with(estimator.__framework_name__, defaults.LATEST_PY2_VERSION)\n\n\n@patch(""sagemaker.pytorch.model.python_deprecation_warning"")\ndef test_model_py2_warning(warning, sagemaker_session):\n    model = PyTorchModel(\n        MODEL_DATA,\n        role=ROLE,\n        entry_point=SCRIPT_PATH,\n        sagemaker_session=sagemaker_session,\n        py_version=""py2"",\n    )\n    assert model.py_version == ""py2""\n    warning.assert_called_with(model.__framework_name__, defaults.LATEST_PY2_VERSION)\n\n\n@patch(""sagemaker.pytorch.estimator.empty_framework_version_warning"")\ndef test_empty_framework_version(warning, sagemaker_session):\n    estimator = PyTorch(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        framework_version=None,\n    )\n\n    assert estimator.framework_version == defaults.PYTORCH_VERSION\n    warning.assert_called_with(defaults.PYTORCH_VERSION, estimator.LATEST_VERSION)\n\n\n@patch(""sagemaker.pytorch.model.empty_framework_version_warning"")\ndef test_model_empty_framework_version(warning, sagemaker_session):\n    model = PyTorchModel(\n        MODEL_DATA,\n        role=ROLE,\n        entry_point=SCRIPT_PATH,\n        sagemaker_session=sagemaker_session,\n        framework_version=None,\n    )\n\n    assert model.framework_version == defaults.PYTORCH_VERSION\n    warning.assert_called_with(defaults.PYTORCH_VERSION, defaults.LATEST_VERSION)\n\n\ndef test_pt_enable_sm_metrics(sagemaker_session):\n    pytorch = _pytorch_estimator(sagemaker_session, enable_sagemaker_metrics=True)\n    assert pytorch.enable_sagemaker_metrics\n\n\ndef test_pt_disable_sm_metrics(sagemaker_session):\n    pytorch = _pytorch_estimator(sagemaker_session, enable_sagemaker_metrics=False)\n    assert not pytorch.enable_sagemaker_metrics\n\n\ndef test_pt_disable_sm_metrics_if_pt_ver_is_less_than_1_15(sagemaker_session):\n    for fw_version in [""1.1"", ""1.2""]:\n        pytorch = _pytorch_estimator(sagemaker_session, framework_version=fw_version)\n        assert pytorch.enable_sagemaker_metrics is None\n\n\ndef test_pt_enable_sm_metrics_if_fw_ver_is_at_least_1_15(sagemaker_session):\n    for fw_version in [""1.3"", ""1.4"", ""2.0"", ""2.1""]:\n        pytorch = _pytorch_estimator(sagemaker_session, framework_version=fw_version)\n        assert pytorch.enable_sagemaker_metrics\n\n\ndef test_custom_image_estimator_deploy(sagemaker_session):\n    custom_image = ""mycustomimage:latest""\n    pytorch = _pytorch_estimator(sagemaker_session)\n    pytorch.fit(inputs=""s3://mybucket/train"", job_name=""new_name"")\n    model = pytorch.create_model(image=custom_image)\n    assert model.image == custom_image\n'"
tests/unit/test_randomcutforest.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport pytest\nfrom mock import Mock, patch\n\nfrom sagemaker.amazon.randomcutforest import RandomCutForest, RandomCutForestPredictor\nfrom sagemaker.amazon.amazon_estimator import registry, RecordSet\n\nROLE = ""myrole""\nTRAIN_INSTANCE_COUNT = 1\nTRAIN_INSTANCE_TYPE = ""ml.c4.xlarge""\nNUM_SAMPLES_PER_TREE = 20\nNUM_TREES = 50\nEVAL_METRICS = [""accuracy"", ""precision_recall_fscore""]\n\nCOMMON_TRAIN_ARGS = {\n    ""role"": ROLE,\n    ""train_instance_count"": TRAIN_INSTANCE_COUNT,\n    ""train_instance_type"": TRAIN_INSTANCE_TYPE,\n}\nALL_REQ_ARGS = dict(**COMMON_TRAIN_ARGS)\n\nREGION = ""us-west-2""\nBUCKET_NAME = ""Some-Bucket""\n\nDESCRIBE_TRAINING_JOB_RESULT = {""ModelArtifacts"": {""S3ModelArtifacts"": ""s3://bucket/model.tar.gz""}}\n\nENDPOINT_DESC = {""EndpointConfigName"": ""test-endpoint""}\n\nENDPOINT_CONFIG_DESC = {""ProductionVariants"": [{""ModelName"": ""model-1""}, {""ModelName"": ""model-2""}]}\n\n\n@pytest.fixture()\ndef sagemaker_session():\n    boto_mock = Mock(name=""boto_session"", region_name=REGION)\n    sms = Mock(\n        name=""sagemaker_session"",\n        boto_session=boto_mock,\n        region_name=REGION,\n        config=None,\n        local_mode=False,\n    )\n    sms.boto_region_name = REGION\n    sms.default_bucket = Mock(name=""default_bucket"", return_value=BUCKET_NAME)\n    sms.sagemaker_client.describe_training_job = Mock(\n        name=""describe_training_job"", return_value=DESCRIBE_TRAINING_JOB_RESULT\n    )\n    sms.sagemaker_client.describe_endpoint = Mock(return_value=ENDPOINT_DESC)\n    sms.sagemaker_client.describe_endpoint_config = Mock(return_value=ENDPOINT_CONFIG_DESC)\n\n    return sms\n\n\ndef test_init_required_positional(sagemaker_session):\n    randomcutforest = RandomCutForest(\n        ROLE,\n        TRAIN_INSTANCE_COUNT,\n        TRAIN_INSTANCE_TYPE,\n        NUM_SAMPLES_PER_TREE,\n        NUM_TREES,\n        EVAL_METRICS,\n        sagemaker_session=sagemaker_session,\n    )\n    assert randomcutforest.role == ROLE\n    assert randomcutforest.train_instance_count == TRAIN_INSTANCE_COUNT\n    assert randomcutforest.train_instance_type == TRAIN_INSTANCE_TYPE\n    assert randomcutforest.num_trees == NUM_TREES\n    assert randomcutforest.num_samples_per_tree == NUM_SAMPLES_PER_TREE\n    assert randomcutforest.eval_metrics == EVAL_METRICS\n\n\ndef test_init_required_named(sagemaker_session):\n    randomcutforest = RandomCutForest(sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n\n    assert randomcutforest.role == COMMON_TRAIN_ARGS[""role""]\n    assert randomcutforest.train_instance_count == TRAIN_INSTANCE_COUNT\n    assert randomcutforest.train_instance_type == COMMON_TRAIN_ARGS[""train_instance_type""]\n\n\ndef test_all_hyperparameters(sagemaker_session):\n    randomcutforest = RandomCutForest(\n        sagemaker_session=sagemaker_session,\n        num_trees=NUM_TREES,\n        num_samples_per_tree=NUM_SAMPLES_PER_TREE,\n        eval_metrics=EVAL_METRICS,\n        **ALL_REQ_ARGS\n    )\n    assert randomcutforest.hyperparameters() == dict(\n        num_samples_per_tree=str(NUM_SAMPLES_PER_TREE),\n        num_trees=str(NUM_TREES),\n        eval_metrics=\'[""accuracy"", ""precision_recall_fscore""]\',\n    )\n\n\ndef test_image(sagemaker_session):\n    randomcutforest = RandomCutForest(sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n    assert (\n        randomcutforest.train_image() == registry(REGION, ""randomcutforest"") + ""/randomcutforest:1""\n    )\n\n\n@pytest.mark.parametrize(""iterable_hyper_parameters, value"", [(""eval_metrics"", 0)])\ndef test_iterable_hyper_parameters_type(sagemaker_session, iterable_hyper_parameters, value):\n    with pytest.raises(TypeError):\n        test_params = ALL_REQ_ARGS.copy()\n        test_params.update({iterable_hyper_parameters: value})\n        RandomCutForest(sagemaker_session=sagemaker_session, **test_params)\n\n\n@pytest.mark.parametrize(\n    ""optional_hyper_parameters, value"",\n    [(""num_trees"", ""string""), (""num_samples_per_tree"", ""string"")],\n)\ndef test_optional_hyper_parameters_type(sagemaker_session, optional_hyper_parameters, value):\n    with pytest.raises(ValueError):\n        test_params = ALL_REQ_ARGS.copy()\n        test_params.update({optional_hyper_parameters: value})\n        RandomCutForest(sagemaker_session=sagemaker_session, **test_params)\n\n\n@pytest.mark.parametrize(\n    ""optional_hyper_parameters, value"",\n    [\n        (""num_trees"", 49),\n        (""num_trees"", 1001),\n        (""num_samples_per_tree"", 0),\n        (""num_samples_per_tree"", 2049),\n    ],\n)\ndef test_optional_hyper_parameters_value(sagemaker_session, optional_hyper_parameters, value):\n    with pytest.raises(ValueError):\n        test_params = ALL_REQ_ARGS.copy()\n        test_params.update({optional_hyper_parameters: value})\n        RandomCutForest(sagemaker_session=sagemaker_session, **test_params)\n\n\nPREFIX = ""prefix""\nFEATURE_DIM = 10\nMAX_FEATURE_DIM = 10000\nMINI_BATCH_SIZE = 1000\n\n\n@patch(""sagemaker.amazon.amazon_estimator.AmazonAlgorithmEstimatorBase.fit"")\ndef test_call_fit(base_fit, sagemaker_session):\n    randomcutforest = RandomCutForest(\n        base_job_name=""randomcutforest"", sagemaker_session=sagemaker_session, **ALL_REQ_ARGS\n    )\n\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n\n    randomcutforest.fit(data, MINI_BATCH_SIZE)\n\n    base_fit.assert_called_once()\n    assert len(base_fit.call_args[0]) == 2\n    assert base_fit.call_args[0][0] == data\n    assert base_fit.call_args[0][1] == MINI_BATCH_SIZE\n\n\ndef test_prepare_for_training_no_mini_batch_size(sagemaker_session):\n    randomcutforest = RandomCutForest(\n        base_job_name=""randomcutforest"", sagemaker_session=sagemaker_session, **ALL_REQ_ARGS\n    )\n\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n    randomcutforest._prepare_for_training(data)\n\n    assert randomcutforest.mini_batch_size == MINI_BATCH_SIZE\n\n\ndef test_prepare_for_training_wrong_type_mini_batch_size(sagemaker_session):\n    randomcutforest = RandomCutForest(\n        base_job_name=""randomcutforest"", sagemaker_session=sagemaker_session, **ALL_REQ_ARGS\n    )\n\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n\n    with pytest.raises((TypeError, ValueError)):\n        randomcutforest._prepare_for_training(data, 1234)\n\n\ndef test_prepare_for_training_feature_dim_greater_than_max_allowed(sagemaker_session):\n    randomcutforest = RandomCutForest(\n        base_job_name=""randomcutforest"", sagemaker_session=sagemaker_session, **ALL_REQ_ARGS\n    )\n\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=MAX_FEATURE_DIM + 1,\n        channel=""train"",\n    )\n\n    with pytest.raises((TypeError, ValueError)):\n        randomcutforest._prepare_for_training(data)\n\n\ndef test_model_image(sagemaker_session):\n    randomcutforest = RandomCutForest(sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n    randomcutforest.fit(data, MINI_BATCH_SIZE)\n\n    model = randomcutforest.create_model()\n    assert model.image == registry(REGION, ""randomcutforest"") + ""/randomcutforest:1""\n\n\ndef test_predictor_type(sagemaker_session):\n    randomcutforest = RandomCutForest(sagemaker_session=sagemaker_session, **ALL_REQ_ARGS)\n    data = RecordSet(\n        ""s3://{}/{}"".format(BUCKET_NAME, PREFIX),\n        num_records=1,\n        feature_dim=FEATURE_DIM,\n        channel=""train"",\n    )\n    randomcutforest.fit(data, MINI_BATCH_SIZE)\n    model = randomcutforest.create_model()\n    predictor = model.deploy(1, TRAIN_INSTANCE_TYPE)\n\n    assert isinstance(predictor, RandomCutForestPredictor)\n'"
tests/unit/test_rl.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport json\nimport logging\nimport os\n\nimport pytest\nfrom mock import MagicMock, Mock\nfrom mock import patch\n\nfrom sagemaker.mxnet import MXNetModel, MXNetPredictor\nfrom sagemaker.rl import RLEstimator, RLFramework, RLToolkit, TOOLKIT_FRAMEWORK_VERSION_MAP\nimport sagemaker.tensorflow.serving as tfs\n\n\nDATA_DIR = os.path.join(os.path.dirname(__file__), "".."", ""data"")\nSCRIPT_PATH = os.path.join(DATA_DIR, ""dummy_script.py"")\nTIMESTAMP = ""2017-11-06-14:14:15.672""\nTIME = 1507167947\nBUCKET_NAME = ""notmybucket""\nINSTANCE_COUNT = 1\nINSTANCE_TYPE = ""ml.c4.4xlarge""\nIMAGE_NAME = ""sagemaker-rl""\nIMAGE_URI_FORMAT_STRING = ""520713654638.dkr.ecr.{}.amazonaws.com/{}-{}:{}{}-{}-py3""\nPYTHON_VERSION = ""py3""\nROLE = ""Dummy""\nREGION = ""us-west-2""\nGPU = ""ml.p2.xlarge""\nCPU = ""ml.c4.xlarge""\n\nENDPOINT_DESC = {""EndpointConfigName"": ""test-endpoint""}\n\nENDPOINT_CONFIG_DESC = {""ProductionVariants"": [{""ModelName"": ""model-1""}, {""ModelName"": ""model-2""}]}\n\nLIST_TAGS_RESULT = {""Tags"": [{""Key"": ""TagtestKey"", ""Value"": ""TagtestValue""}]}\n\nEXPERIMENT_CONFIG = {\n    ""ExperimentName"": ""exp"",\n    ""TrialName"": ""trial"",\n    ""TrialComponentDisplayName"": ""tc"",\n}\n\n\n@pytest.fixture(name=""sagemaker_session"")\ndef fixture_sagemaker_session():\n    boto_mock = Mock(name=""boto_session"", region_name=REGION)\n    session = Mock(\n        name=""sagemaker_session"",\n        boto_session=boto_mock,\n        boto_region_name=REGION,\n        config=None,\n        local_mode=False,\n        s3_resource=None,\n        s3_client=None,\n    )\n\n    describe = {""ModelArtifacts"": {""S3ModelArtifacts"": ""s3://m/m.tar.gz""}}\n    session.sagemaker_client.describe_training_job = Mock(return_value=describe)\n    session.sagemaker_client.describe_endpoint = Mock(return_value=ENDPOINT_DESC)\n    session.sagemaker_client.describe_endpoint_config = Mock(return_value=ENDPOINT_CONFIG_DESC)\n    session.sagemaker_client.list_tags = Mock(return_value=LIST_TAGS_RESULT)\n    session.default_bucket = Mock(name=""default_bucket"", return_value=BUCKET_NAME)\n    session.expand_role = Mock(name=""expand_role"", return_value=ROLE)\n    return session\n\n\ndef _get_full_cpu_image_uri(toolkit, toolkit_version, framework):\n    return IMAGE_URI_FORMAT_STRING.format(\n        REGION, IMAGE_NAME, framework, toolkit, toolkit_version, ""cpu""\n    )\n\n\ndef _get_full_gpu_image_uri(toolkit, toolkit_version, framework):\n    return IMAGE_URI_FORMAT_STRING.format(\n        REGION, IMAGE_NAME, framework, toolkit, toolkit_version, ""gpu""\n    )\n\n\ndef _rl_estimator(\n    sagemaker_session,\n    toolkit=RLToolkit.COACH,\n    toolkit_version=RLEstimator.COACH_LATEST_VERSION_MXNET,\n    framework=RLFramework.MXNET,\n    train_instance_type=None,\n    base_job_name=None,\n    **kwargs\n):\n    return RLEstimator(\n        entry_point=SCRIPT_PATH,\n        toolkit=toolkit,\n        toolkit_version=toolkit_version,\n        framework=framework,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=train_instance_type or INSTANCE_TYPE,\n        base_job_name=base_job_name,\n        **kwargs\n    )\n\n\ndef _create_train_job(toolkit, toolkit_version, framework):\n    job_name = ""{}-{}-{}"".format(IMAGE_NAME, framework, TIMESTAMP)\n    return {\n        ""image"": _get_full_cpu_image_uri(toolkit, toolkit_version, framework),\n        ""input_mode"": ""File"",\n        ""input_config"": [\n            {\n                ""ChannelName"": ""training"",\n                ""DataSource"": {\n                    ""S3DataSource"": {\n                        ""S3DataDistributionType"": ""FullyReplicated"",\n                        ""S3DataType"": ""S3Prefix"",\n                    }\n                },\n            }\n        ],\n        ""role"": ROLE,\n        ""job_name"": job_name,\n        ""output_config"": {""S3OutputPath"": ""s3://{}/"".format(BUCKET_NAME)},\n        ""resource_config"": {\n            ""InstanceType"": ""ml.c4.4xlarge"",\n            ""InstanceCount"": 1,\n            ""VolumeSizeInGB"": 30,\n        },\n        ""hyperparameters"": {\n            ""sagemaker_program"": json.dumps(""dummy_script.py""),\n            ""sagemaker_enable_cloudwatch_metrics"": ""false"",\n            ""sagemaker_estimator"": \'""RLEstimator""\',\n            ""sagemaker_container_log_level"": str(logging.INFO),\n            ""sagemaker_job_name"": json.dumps(job_name),\n            ""sagemaker_s3_output"": \'""s3://{}/""\'.format(BUCKET_NAME),\n            ""sagemaker_submit_directory"": json.dumps(\n                ""s3://{}/{}/source/sourcedir.tar.gz"".format(BUCKET_NAME, job_name)\n            ),\n            ""sagemaker_region"": \'""us-west-2""\',\n        },\n        ""stop_condition"": {""MaxRuntimeInSeconds"": 24 * 60 * 60},\n        ""tags"": None,\n        ""vpc_config"": None,\n        ""metric_definitions"": [\n            {""Name"": ""reward-training"", ""Regex"": ""^Training>.*Total reward=(.*?),""},\n            {""Name"": ""reward-testing"", ""Regex"": ""^Testing>.*Total reward=(.*?),""},\n        ],\n        ""experiment_config"": None,\n        ""debugger_hook_config"": {\n            ""CollectionConfigurations"": [],\n            ""S3OutputPath"": ""s3://{}/"".format(BUCKET_NAME),\n        },\n    }\n\n\ndef test_create_tf_model(sagemaker_session, rl_coach_tf_version):\n    container_log_level = \'""logging.INFO""\'\n    source_dir = ""s3://mybucket/source""\n    rl = RLEstimator(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        toolkit=RLToolkit.COACH,\n        toolkit_version=rl_coach_tf_version,\n        framework=RLFramework.TENSORFLOW,\n        container_log_level=container_log_level,\n        source_dir=source_dir,\n    )\n\n    job_name = ""new_name""\n    rl.fit(inputs=""s3://mybucket/train"", job_name=""new_name"")\n    model = rl.create_model()\n    supported_versions = TOOLKIT_FRAMEWORK_VERSION_MAP[RLToolkit.COACH.value]\n    framework_version = supported_versions[rl_coach_tf_version][RLFramework.TENSORFLOW.value]\n\n    assert isinstance(model, tfs.Model)\n    assert model.sagemaker_session == sagemaker_session\n    assert model._framework_version == framework_version\n    assert model.role == ROLE\n    assert model.name == job_name\n    assert model._container_log_level == container_log_level\n    assert model.vpc_config is None\n\n\ndef test_create_mxnet_model(sagemaker_session, rl_coach_mxnet_version):\n    container_log_level = \'""logging.INFO""\'\n    source_dir = ""s3://mybucket/source""\n    rl = RLEstimator(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        toolkit=RLToolkit.COACH,\n        toolkit_version=rl_coach_mxnet_version,\n        framework=RLFramework.MXNET,\n        container_log_level=container_log_level,\n        source_dir=source_dir,\n    )\n\n    job_name = ""new_name""\n    rl.fit(inputs=""s3://mybucket/train"", job_name=""new_name"")\n    model = rl.create_model()\n    supported_versions = TOOLKIT_FRAMEWORK_VERSION_MAP[RLToolkit.COACH.value]\n    framework_version = supported_versions[rl_coach_mxnet_version][RLFramework.MXNET.value]\n\n    assert isinstance(model, MXNetModel)\n    assert model.sagemaker_session == sagemaker_session\n    assert model.framework_version == framework_version\n    assert model.py_version == PYTHON_VERSION\n    assert model.entry_point == SCRIPT_PATH\n    assert model.role == ROLE\n    assert model.name == job_name\n    assert model.container_log_level == container_log_level\n    assert model.source_dir == source_dir\n    assert model.vpc_config is None\n\n\ndef test_create_model_with_optional_params(sagemaker_session, rl_coach_mxnet_version):\n    container_log_level = \'""logging.INFO""\'\n    source_dir = ""s3://mybucket/source""\n    rl = RLEstimator(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        toolkit=RLToolkit.COACH,\n        toolkit_version=rl_coach_mxnet_version,\n        framework=RLFramework.MXNET,\n        container_log_level=container_log_level,\n        source_dir=source_dir,\n    )\n\n    rl.fit(job_name=""new_name"")\n\n    new_role = ""role""\n    new_entry_point = ""deploy_script.py""\n    vpc_config = {""Subnets"": [""foo""], ""SecurityGroupIds"": [""bar""]}\n    model_name = ""model-name""\n    model = rl.create_model(\n        role=new_role, entry_point=new_entry_point, vpc_config_override=vpc_config, name=model_name\n    )\n\n    assert model.role == new_role\n    assert model.vpc_config == vpc_config\n    assert model.entry_point == new_entry_point\n    assert model.name == model_name\n\n\ndef test_create_model_with_custom_image(sagemaker_session):\n    container_log_level = \'""logging.INFO""\'\n    source_dir = ""s3://mybucket/source""\n    image = ""selfdrivingcars:9000""\n    rl = RLEstimator(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        image_name=image,\n        container_log_level=container_log_level,\n        source_dir=source_dir,\n    )\n\n    job_name = ""new_name""\n    rl.fit(job_name=job_name)\n    new_entry_point = ""deploy_script.py""\n    model = rl.create_model(entry_point=new_entry_point)\n\n    assert model.sagemaker_session == sagemaker_session\n    assert model.image == image\n    assert model.entry_point == new_entry_point\n    assert model.role == ROLE\n    assert model.name == job_name\n    assert model.container_log_level == container_log_level\n    assert model.source_dir == source_dir\n\n\n@patch(""sagemaker.utils.create_tar_file"", MagicMock())\n@patch(""time.strftime"", return_value=TIMESTAMP)\ndef test_rl(strftime, sagemaker_session, rl_coach_mxnet_version):\n    rl = RLEstimator(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        toolkit=RLToolkit.COACH,\n        toolkit_version=rl_coach_mxnet_version,\n        framework=RLFramework.MXNET,\n    )\n\n    inputs = ""s3://mybucket/train""\n\n    rl.fit(inputs=inputs, experiment_config=EXPERIMENT_CONFIG)\n\n    sagemaker_call_names = [c[0] for c in sagemaker_session.method_calls]\n    assert sagemaker_call_names == [""train"", ""logs_for_job""]\n    boto_call_names = [c[0] for c in sagemaker_session.boto_session.method_calls]\n    assert boto_call_names == [""resource""]\n\n    expected_train_args = _create_train_job(\n        RLToolkit.COACH.value, rl_coach_mxnet_version, RLFramework.MXNET.value\n    )\n    expected_train_args[""input_config""][0][""DataSource""][""S3DataSource""][""S3Uri""] = inputs\n    expected_train_args[""experiment_config""] = EXPERIMENT_CONFIG\n\n    actual_train_args = sagemaker_session.method_calls[0][2]\n    assert actual_train_args == expected_train_args\n\n    model = rl.create_model()\n    supported_versions = TOOLKIT_FRAMEWORK_VERSION_MAP[RLToolkit.COACH.value]\n    framework_version = supported_versions[rl_coach_mxnet_version][RLFramework.MXNET.value]\n\n    expected_image_base = ""520713654638.dkr.ecr.us-west-2.amazonaws.com/sagemaker-mxnet:{}-gpu-py3""\n    submit_dir = ""s3://notmybucket/sagemaker-rl-mxnet-{}/source/sourcedir.tar.gz"".format(TIMESTAMP)\n    assert {\n        ""Environment"": {\n            ""SAGEMAKER_SUBMIT_DIRECTORY"": submit_dir,\n            ""SAGEMAKER_PROGRAM"": ""dummy_script.py"",\n            ""SAGEMAKER_ENABLE_CLOUDWATCH_METRICS"": ""false"",\n            ""SAGEMAKER_REGION"": ""us-west-2"",\n            ""SAGEMAKER_CONTAINER_LOG_LEVEL"": ""20"",\n        },\n        ""Image"": expected_image_base.format(framework_version),\n        ""ModelDataUrl"": ""s3://m/m.tar.gz"",\n    } == model.prepare_container_def(GPU)\n\n    assert ""cpu"" in model.prepare_container_def(CPU)[""Image""]\n\n\n@patch(""sagemaker.utils.create_tar_file"", MagicMock())\ndef test_deploy_mxnet(sagemaker_session, rl_coach_mxnet_version):\n    rl = _rl_estimator(\n        sagemaker_session,\n        RLToolkit.COACH,\n        rl_coach_mxnet_version,\n        RLFramework.MXNET,\n        train_instance_type=""ml.g2.2xlarge"",\n    )\n    rl.fit()\n    predictor = rl.deploy(1, CPU)\n    assert isinstance(predictor, MXNetPredictor)\n\n\n@patch(""sagemaker.utils.create_tar_file"", MagicMock())\ndef test_deploy_tfs(sagemaker_session, rl_coach_tf_version):\n    rl = _rl_estimator(\n        sagemaker_session,\n        RLToolkit.COACH,\n        rl_coach_tf_version,\n        RLFramework.TENSORFLOW,\n        train_instance_type=""ml.g2.2xlarge"",\n    )\n    rl.fit()\n    predictor = rl.deploy(1, GPU)\n    assert isinstance(predictor, tfs.Predictor)\n\n\n@patch(""sagemaker.utils.create_tar_file"", MagicMock())\ndef test_deploy_ray(sagemaker_session, rl_ray_version):\n    rl = _rl_estimator(\n        sagemaker_session,\n        RLToolkit.RAY,\n        rl_ray_version,\n        RLFramework.TENSORFLOW,\n        train_instance_type=""ml.g2.2xlarge"",\n    )\n    rl.fit()\n    with pytest.raises(NotImplementedError) as e:\n        rl.deploy(1, GPU)\n    assert ""deployment of Ray models is not currently available"" in str(e.value)\n\n\ndef test_train_image_cpu_instances(sagemaker_session, rl_ray_version):\n    toolkit = RLToolkit.RAY\n    framework = RLFramework.TENSORFLOW\n    rl = _rl_estimator(\n        sagemaker_session, toolkit, rl_ray_version, framework, train_instance_type=""ml.c2.2xlarge""\n    )\n    assert rl.train_image() == _get_full_cpu_image_uri(\n        toolkit.value, rl_ray_version, framework.value\n    )\n\n    rl = _rl_estimator(\n        sagemaker_session, toolkit, rl_ray_version, framework, train_instance_type=""ml.c4.2xlarge""\n    )\n    assert rl.train_image() == _get_full_cpu_image_uri(\n        toolkit.value, rl_ray_version, framework.value\n    )\n\n    rl = _rl_estimator(\n        sagemaker_session, toolkit, rl_ray_version, framework, train_instance_type=""ml.m16""\n    )\n    assert rl.train_image() == _get_full_cpu_image_uri(\n        toolkit.value, rl_ray_version, framework.value\n    )\n\n\ndef test_train_image_gpu_instances(sagemaker_session, rl_coach_mxnet_version):\n    toolkit = RLToolkit.COACH\n    framework = RLFramework.MXNET\n    rl = _rl_estimator(\n        sagemaker_session,\n        toolkit,\n        rl_coach_mxnet_version,\n        framework,\n        train_instance_type=""ml.g2.2xlarge"",\n    )\n    assert rl.train_image() == _get_full_gpu_image_uri(\n        toolkit.value, rl_coach_mxnet_version, framework.value\n    )\n\n    rl = _rl_estimator(\n        sagemaker_session,\n        toolkit,\n        rl_coach_mxnet_version,\n        framework,\n        train_instance_type=""ml.p2.2xlarge"",\n    )\n    assert rl.train_image() == _get_full_gpu_image_uri(\n        toolkit.value, rl_coach_mxnet_version, framework.value\n    )\n\n\ndef test_attach(sagemaker_session, rl_coach_mxnet_version):\n    training_image = ""1.dkr.ecr.us-west-2.amazonaws.com/sagemaker-rl-{}:{}{}-cpu-py3"".format(\n        RLFramework.MXNET.value, RLToolkit.COACH.value, rl_coach_mxnet_version\n    )\n    supported_versions = TOOLKIT_FRAMEWORK_VERSION_MAP[RLToolkit.COACH.value]\n    framework_version = supported_versions[rl_coach_mxnet_version][RLFramework.MXNET.value]\n    returned_job_description = {\n        ""AlgorithmSpecification"": {""TrainingInputMode"": ""File"", ""TrainingImage"": training_image},\n        ""HyperParameters"": {\n            ""sagemaker_submit_directory"": \'""s3://some/sourcedir.tar.gz""\',\n            ""sagemaker_program"": \'""train_coach.py""\',\n            ""sagemaker_enable_cloudwatch_metrics"": ""false"",\n            ""sagemaker_container_log_level"": \'""logging.INFO""\',\n            ""sagemaker_job_name"": \'""neo""\',\n            ""training_steps"": ""100"",\n            ""sagemaker_region"": \'""us-west-2""\',\n        },\n        ""RoleArn"": ""arn:aws:iam::366:role/SageMakerRole"",\n        ""ResourceConfig"": {\n            ""VolumeSizeInGB"": 30,\n            ""InstanceCount"": 1,\n            ""InstanceType"": ""ml.c4.xlarge"",\n        },\n        ""StoppingCondition"": {""MaxRuntimeInSeconds"": 24 * 60 * 60},\n        ""TrainingJobName"": ""neo"",\n        ""TrainingJobStatus"": ""Completed"",\n        ""TrainingJobArn"": ""arn:aws:sagemaker:us-west-2:336:training-job/neo"",\n        ""OutputDataConfig"": {""KmsKeyId"": """", ""S3OutputPath"": ""s3://place/output/neo""},\n        ""TrainingJobOutput"": {""S3TrainingJobOutput"": ""s3://here/output.tar.gz""},\n    }\n    sagemaker_session.sagemaker_client.describe_training_job = Mock(\n        name=""describe_training_job"", return_value=returned_job_description\n    )\n\n    estimator = RLEstimator.attach(training_job_name=""neo"", sagemaker_session=sagemaker_session)\n    assert estimator.latest_training_job.job_name == ""neo""\n    assert estimator.framework == RLFramework.MXNET.value\n    assert estimator.toolkit == RLToolkit.COACH.value\n    assert estimator.framework_version == framework_version\n    assert estimator.toolkit_version == rl_coach_mxnet_version\n    assert estimator.role == ""arn:aws:iam::366:role/SageMakerRole""\n    assert estimator.train_instance_count == 1\n    assert estimator.train_max_run == 24 * 60 * 60\n    assert estimator.input_mode == ""File""\n    assert estimator.base_job_name == ""neo""\n    assert estimator.output_path == ""s3://place/output/neo""\n    assert estimator.output_kms_key == """"\n    assert estimator.hyperparameters()[""training_steps""] == ""100""\n    assert estimator.source_dir == ""s3://some/sourcedir.tar.gz""\n    assert estimator.entry_point == ""train_coach.py""\n    assert estimator.metric_definitions == RLEstimator.default_metric_definitions(RLToolkit.COACH)\n\n\ndef test_attach_wrong_framework(sagemaker_session):\n    training_image = ""1.dkr.ecr.us-west-2.amazonaws.com/sagemaker-mxnet-py2-cpu:1.0.4""\n    rjd = {\n        ""AlgorithmSpecification"": {""TrainingInputMode"": ""File"", ""TrainingImage"": training_image},\n        ""HyperParameters"": {\n            ""sagemaker_submit_directory"": \'""s3://some/sourcedir.tar.gz""\',\n            ""checkpoint_path"": \'""s3://other/1508872349""\',\n            ""sagemaker_program"": \'""iris-dnn-classifier.py""\',\n            ""sagemaker_enable_cloudwatch_metrics"": ""false"",\n            ""sagemaker_container_log_level"": \'""logging.INFO""\',\n            ""training_steps"": ""100"",\n            ""sagemaker_region"": \'""us-west-2""\',\n        },\n        ""RoleArn"": ""arn:aws:iam::366:role/SageMakerRole"",\n        ""ResourceConfig"": {\n            ""VolumeSizeInGB"": 30,\n            ""InstanceCount"": 1,\n            ""InstanceType"": ""ml.c4.xlarge"",\n        },\n        ""StoppingCondition"": {""MaxRuntimeInSeconds"": 24 * 60 * 60},\n        ""TrainingJobName"": ""neo"",\n        ""TrainingJobStatus"": ""Completed"",\n        ""TrainingJobArn"": ""arn:aws:sagemaker:us-west-2:336:training-job/neo"",\n        ""OutputDataConfig"": {""KmsKeyId"": """", ""S3OutputPath"": ""s3://place/output/neo""},\n        ""TrainingJobOutput"": {""S3TrainingJobOutput"": ""s3://here/output.tar.gz""},\n    }\n    sagemaker_session.sagemaker_client.describe_training_job = Mock(\n        name=""describe_training_job"", return_value=rjd\n    )\n\n    with pytest.raises(ValueError) as error:\n        RLEstimator.attach(training_job_name=""neo"", sagemaker_session=sagemaker_session)\n    assert ""didn\'t use image for requested framework"" in str(error)\n\n\ndef test_attach_custom_image(sagemaker_session):\n    training_image = ""rl:latest""\n    returned_job_description = {\n        ""AlgorithmSpecification"": {""TrainingInputMode"": ""File"", ""TrainingImage"": training_image},\n        ""HyperParameters"": {\n            ""sagemaker_submit_directory"": \'""s3://some/sourcedir.tar.gz""\',\n            ""sagemaker_program"": \'""iris-dnn-classifier.py""\',\n            ""sagemaker_s3_uri_training"": \'""sagemaker-3/integ-test-data/tf_iris""\',\n            ""sagemaker_enable_cloudwatch_metrics"": ""false"",\n            ""sagemaker_container_log_level"": \'""logging.INFO""\',\n            ""sagemaker_job_name"": \'""neo""\',\n            ""training_steps"": ""100"",\n            ""sagemaker_region"": \'""us-west-2""\',\n        },\n        ""RoleArn"": ""arn:aws:iam::366:role/SageMakerRole"",\n        ""ResourceConfig"": {\n            ""VolumeSizeInGB"": 30,\n            ""InstanceCount"": 1,\n            ""InstanceType"": ""ml.c4.xlarge"",\n        },\n        ""StoppingCondition"": {""MaxRuntimeInSeconds"": 24 * 60 * 60},\n        ""TrainingJobName"": ""neo"",\n        ""TrainingJobStatus"": ""Completed"",\n        ""TrainingJobArn"": ""arn:aws:sagemaker:us-west-2:336:training-job/neo"",\n        ""OutputDataConfig"": {""KmsKeyId"": """", ""S3OutputPath"": ""s3://place/output/neo""},\n        ""TrainingJobOutput"": {""S3TrainingJobOutput"": ""s3://here/output.tar.gz""},\n    }\n    sagemaker_session.sagemaker_client.describe_training_job = Mock(\n        name=""describe_training_job"", return_value=returned_job_description\n    )\n\n    estimator = RLEstimator.attach(training_job_name=""neo"", sagemaker_session=sagemaker_session)\n    assert estimator.latest_training_job.job_name == ""neo""\n    assert estimator.image_name == training_image\n    assert estimator.train_image() == training_image\n\n\ndef test_wrong_framework_format(sagemaker_session):\n    with pytest.raises(ValueError) as e:\n        RLEstimator(\n            toolkit=RLToolkit.RAY,\n            framework=""TF"",\n            toolkit_version=RLEstimator.RAY_LATEST_VERSION,\n            entry_point=SCRIPT_PATH,\n            role=ROLE,\n            sagemaker_session=sagemaker_session,\n            train_instance_count=INSTANCE_COUNT,\n            train_instance_type=INSTANCE_TYPE,\n            framework_version=None,\n        )\n\n    assert ""Invalid type"" in str(e.value)\n\n\ndef test_wrong_toolkit_format(sagemaker_session):\n    with pytest.raises(ValueError) as e:\n        RLEstimator(\n            toolkit=""coach"",\n            framework=RLFramework.TENSORFLOW,\n            toolkit_version=RLEstimator.COACH_LATEST_VERSION_TF,\n            entry_point=SCRIPT_PATH,\n            role=ROLE,\n            sagemaker_session=sagemaker_session,\n            train_instance_count=INSTANCE_COUNT,\n            train_instance_type=INSTANCE_TYPE,\n            framework_version=None,\n        )\n\n    assert ""Invalid type"" in str(e.value)\n\n\ndef test_missing_required_parameters(sagemaker_session):\n    with pytest.raises(AttributeError) as e:\n        RLEstimator(\n            entry_point=SCRIPT_PATH,\n            role=ROLE,\n            sagemaker_session=sagemaker_session,\n            train_instance_count=INSTANCE_COUNT,\n            train_instance_type=INSTANCE_TYPE,\n        )\n    assert (\n        ""Please provide `toolkit`, `toolkit_version`, `framework`"" + "" or `image_name` parameter.""\n        in str(e.value)\n    )\n\n\ndef test_wrong_type_parameters(sagemaker_session):\n    with pytest.raises(AttributeError) as e:\n        RLEstimator(\n            toolkit=RLToolkit.COACH,\n            framework=RLFramework.TENSORFLOW,\n            toolkit_version=RLEstimator.RAY_LATEST_VERSION,\n            entry_point=SCRIPT_PATH,\n            role=ROLE,\n            sagemaker_session=sagemaker_session,\n            train_instance_count=INSTANCE_COUNT,\n            train_instance_type=INSTANCE_TYPE,\n        )\n    assert ""combination is not supported."" in str(e.value)\n\n\ndef test_custom_image_estimator_deploy(sagemaker_session):\n    custom_image = ""mycustomimage:latest""\n    rl = _rl_estimator(sagemaker_session)\n    rl.fit(inputs=""s3://mybucket/train"", job_name=""new_name"")\n    model = rl.create_model(image=custom_image)\n    assert model.image == custom_image\n'"
tests/unit/test_s3.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport os\nimport pytest\nfrom mock import Mock\n\nfrom sagemaker.s3 import S3Uploader, S3Downloader\n\nBUCKET_NAME = ""mybucket""\nREGION = ""us-west-2""\nCURRENT_JOB_NAME = ""currentjobname""\nSOURCE_NAME = ""source""\nKMS_KEY = ""kmskey""\n\n\n@pytest.fixture()\ndef sagemaker_session():\n    boto_mock = Mock(name=""boto_session"", region_name=REGION)\n    session_mock = Mock(\n        name=""sagemaker_session"",\n        boto_session=boto_mock,\n        boto_region_name=REGION,\n        config=None,\n        local_mode=False,\n    )\n    session_mock.upload_data = Mock(name=""upload_data"", return_value=""s3_uri_to_uploaded_data"")\n    session_mock.download_data = Mock(name=""download_data"")\n    return session_mock\n\n\ndef test_upload(sagemaker_session, caplog):\n    desired_s3_uri = os.path.join(""s3://"", BUCKET_NAME, CURRENT_JOB_NAME, SOURCE_NAME)\n    S3Uploader.upload(\n        local_path=""/path/to/app.jar"", desired_s3_uri=desired_s3_uri, session=sagemaker_session\n    )\n    sagemaker_session.upload_data.assert_called_with(\n        path=""/path/to/app.jar"",\n        bucket=BUCKET_NAME,\n        key_prefix=os.path.join(CURRENT_JOB_NAME, SOURCE_NAME),\n        extra_args=None,\n    )\n    warning_message = (\n        ""Parameter \'session\' will be renamed to \'sagemaker_session\' "" ""in SageMaker Python SDK v2.""\n    )\n    assert warning_message in caplog.text\n\n\ndef test_upload_with_kms_key(sagemaker_session):\n    desired_s3_uri = os.path.join(""s3://"", BUCKET_NAME, CURRENT_JOB_NAME, SOURCE_NAME)\n    S3Uploader.upload(\n        local_path=""/path/to/app.jar"",\n        desired_s3_uri=desired_s3_uri,\n        kms_key=KMS_KEY,\n        session=sagemaker_session,\n    )\n    sagemaker_session.upload_data.assert_called_with(\n        path=""/path/to/app.jar"",\n        bucket=BUCKET_NAME,\n        key_prefix=os.path.join(CURRENT_JOB_NAME, SOURCE_NAME),\n        extra_args={""SSEKMSKeyId"": KMS_KEY},\n    )\n\n\ndef test_download(sagemaker_session):\n    s3_uri = os.path.join(""s3://"", BUCKET_NAME, CURRENT_JOB_NAME, SOURCE_NAME)\n    S3Downloader.download(\n        s3_uri=s3_uri, local_path=""/path/for/download/"", session=sagemaker_session\n    )\n    sagemaker_session.download_data.assert_called_with(\n        path=""/path/for/download/"",\n        bucket=BUCKET_NAME,\n        key_prefix=os.path.join(CURRENT_JOB_NAME, SOURCE_NAME),\n        extra_args=None,\n    )\n\n\ndef test_download_with_kms_key(sagemaker_session):\n    s3_uri = os.path.join(""s3://"", BUCKET_NAME, CURRENT_JOB_NAME, SOURCE_NAME)\n    S3Downloader.download(\n        s3_uri=s3_uri, local_path=""/path/for/download/"", kms_key=KMS_KEY, session=sagemaker_session\n    )\n    sagemaker_session.download_data.assert_called_with(\n        path=""/path/for/download/"",\n        bucket=BUCKET_NAME,\n        key_prefix=os.path.join(CURRENT_JOB_NAME, SOURCE_NAME),\n        extra_args={""SSECustomerKey"": KMS_KEY},\n    )\n'"
tests/unit/test_session.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport datetime\nimport io\nimport logging\nimport os\n\nimport pytest\nimport six\nfrom botocore.exceptions import ClientError\nfrom mock import ANY, MagicMock, Mock, patch, call, mock_open\n\nimport sagemaker\nfrom sagemaker import s3_input, Session, get_execution_role\nfrom sagemaker.session import (\n    _tuning_job_status,\n    _transform_job_status,\n    _train_done,\n    NOTEBOOK_METADATA_FILE,\n)\nfrom sagemaker.tuner import WarmStartConfig, WarmStartTypes\n\nSTATIC_HPs = {""feature_dim"": ""784""}\n\nSAMPLE_PARAM_RANGES = [{""Name"": ""mini_batch_size"", ""MinValue"": ""10"", ""MaxValue"": ""100""}]\n\nREGION = ""us-west-2""\nSTS_ENDPOINT = ""sts.us-west-2.amazonaws.com""\n\n\n@pytest.fixture()\ndef boto_session():\n    boto_mock = Mock(name=""boto_session"", region_name=REGION)\n\n    client_mock = Mock()\n    client_mock._client_config.user_agent = (\n        ""Boto3/1.9.69 Python/3.6.5 Linux/4.14.77-70.82.amzn1.x86_64 Botocore/1.12.69 Resource""\n    )\n    boto_mock.client.return_value = client_mock\n    return boto_mock\n\n\n@patch(""boto3.DEFAULT_SESSION"")\ndef test_default_session(boto3_default_session):\n    sess = Session()\n    assert sess.boto_session is boto3_default_session\n\n\n@patch(""boto3.Session"")\ndef test_new_session_created(boto3_session):\n    sess = Session()\n    assert sess.boto_session is boto3_session.return_value\n\n\ndef test_process(boto_session):\n    session = Session(boto_session)\n\n    process_request_args = {\n        ""inputs"": [\n            {\n                ""InputName"": ""input-1"",\n                ""S3Input"": {\n                    ""S3Uri"": ""mocked_s3_uri_from_upload_data"",\n                    ""LocalPath"": ""/container/path/"",\n                    ""S3DataType"": ""Archive"",\n                    ""S3InputMode"": ""File"",\n                    ""S3DownloadMode"": ""Continuous"",\n                    ""S3DataDistributionType"": ""FullyReplicated"",\n                    ""S3CompressionType"": ""None"",\n                },\n            },\n            {\n                ""InputName"": ""my_dataset"",\n                ""S3Input"": {\n                    ""S3Uri"": ""s3://path/to/my/dataset/census.csv"",\n                    ""LocalPath"": ""/container/path/"",\n                    ""S3DataType"": ""Archive"",\n                    ""S3InputMode"": ""File"",\n                    ""S3DownloadMode"": ""Continuous"",\n                    ""S3DataDistributionType"": ""FullyReplicated"",\n                    ""S3CompressionType"": ""None"",\n                },\n            },\n            {\n                ""InputName"": ""source"",\n                ""S3Input"": {\n                    ""S3Uri"": ""mocked_s3_uri_from_upload_data"",\n                    ""LocalPath"": ""/code/source"",\n                    ""S3DataType"": ""Archive"",\n                    ""S3InputMode"": ""File"",\n                    ""S3DownloadMode"": ""Continuous"",\n                    ""S3DataDistributionType"": ""FullyReplicated"",\n                    ""S3CompressionType"": ""None"",\n                },\n            },\n        ],\n        ""output_config"": {\n            ""Outputs"": [\n                {\n                    ""OutputName"": ""output-1"",\n                    ""S3Output"": {\n                        ""S3Uri"": ""s3://mybucket/current_job_name/output"",\n                        ""LocalPath"": ""/data/output"",\n                        ""S3UploadMode"": ""Continuous"",\n                    },\n                },\n                {\n                    ""OutputName"": ""my_output"",\n                    ""S3Output"": {\n                        ""S3Uri"": ""s3://uri/"",\n                        ""LocalPath"": ""/container/path/"",\n                        ""S3UploadMode"": ""Continuous"",\n                    },\n                },\n            ],\n            ""KmsKeyId"": ""arn:aws:kms:us-west-2:012345678901:key/kms-key"",\n        },\n        ""job_name"": ""current_job_name"",\n        ""resources"": {\n            ""ClusterConfig"": {\n                ""InstanceType"": ""ml.m4.xlarge"",\n                ""InstanceCount"": 1,\n                ""VolumeSizeInGB"": 100,\n            }\n        },\n        ""stopping_condition"": {""MaxRuntimeInSeconds"": 3600},\n        ""app_specification"": {\n            ""ImageUri"": ""520713654638.dkr.ecr.us-west-2.amazonaws.com/sagemaker-scikit-learn:0.20.0-cpu-py3"",\n            ""ContainerArguments"": [""--drop-columns"", ""\'SelfEmployed\'""],\n            ""ContainerEntrypoint"": [""python3"", ""/code/source/sklearn_transformer.py""],\n        },\n        ""environment"": {""my_env_variable"": 20},\n        ""network_config"": {\n            ""EnableInterContainerTrafficEncryption"": True,\n            ""EnableNetworkIsolation"": True,\n            ""VpcConfig"": {\n                ""SecurityGroupIds"": [""my_security_group_id""],\n                ""Subnets"": [""my_subnet_id""],\n            },\n        },\n        ""role_arn"": ROLE,\n        ""tags"": [{""Name"": ""my-tag"", ""Value"": ""my-tag-value""}],\n        ""experiment_config"": {""ExperimentName"": ""AnExperiment""},\n    }\n    session.process(**process_request_args)\n\n    expected_request = {\n        ""ProcessingJobName"": ""current_job_name"",\n        ""ProcessingResources"": {\n            ""ClusterConfig"": {\n                ""InstanceType"": ""ml.m4.xlarge"",\n                ""InstanceCount"": 1,\n                ""VolumeSizeInGB"": 100,\n            }\n        },\n        ""AppSpecification"": {\n            ""ImageUri"": ""520713654638.dkr.ecr.us-west-2.amazonaws.com/sagemaker-scikit-learn:0.20.0-cpu-py3"",\n            ""ContainerArguments"": [""--drop-columns"", ""\'SelfEmployed\'""],\n            ""ContainerEntrypoint"": [""python3"", ""/code/source/sklearn_transformer.py""],\n        },\n        ""RoleArn"": ROLE,\n        ""ProcessingInputs"": [\n            {\n                ""InputName"": ""input-1"",\n                ""S3Input"": {\n                    ""S3Uri"": ""mocked_s3_uri_from_upload_data"",\n                    ""LocalPath"": ""/container/path/"",\n                    ""S3DataType"": ""Archive"",\n                    ""S3InputMode"": ""File"",\n                    ""S3DownloadMode"": ""Continuous"",\n                    ""S3DataDistributionType"": ""FullyReplicated"",\n                    ""S3CompressionType"": ""None"",\n                },\n            },\n            {\n                ""InputName"": ""my_dataset"",\n                ""S3Input"": {\n                    ""S3Uri"": ""s3://path/to/my/dataset/census.csv"",\n                    ""LocalPath"": ""/container/path/"",\n                    ""S3DataType"": ""Archive"",\n                    ""S3InputMode"": ""File"",\n                    ""S3DownloadMode"": ""Continuous"",\n                    ""S3DataDistributionType"": ""FullyReplicated"",\n                    ""S3CompressionType"": ""None"",\n                },\n            },\n            {\n                ""InputName"": ""source"",\n                ""S3Input"": {\n                    ""S3Uri"": ""mocked_s3_uri_from_upload_data"",\n                    ""LocalPath"": ""/code/source"",\n                    ""S3DataType"": ""Archive"",\n                    ""S3InputMode"": ""File"",\n                    ""S3DownloadMode"": ""Continuous"",\n                    ""S3DataDistributionType"": ""FullyReplicated"",\n                    ""S3CompressionType"": ""None"",\n                },\n            },\n        ],\n        ""ProcessingOutputConfig"": {\n            ""Outputs"": [\n                {\n                    ""OutputName"": ""output-1"",\n                    ""S3Output"": {\n                        ""S3Uri"": ""s3://mybucket/current_job_name/output"",\n                        ""LocalPath"": ""/data/output"",\n                        ""S3UploadMode"": ""Continuous"",\n                    },\n                },\n                {\n                    ""OutputName"": ""my_output"",\n                    ""S3Output"": {\n                        ""S3Uri"": ""s3://uri/"",\n                        ""LocalPath"": ""/container/path/"",\n                        ""S3UploadMode"": ""Continuous"",\n                    },\n                },\n            ],\n            ""KmsKeyId"": ""arn:aws:kms:us-west-2:012345678901:key/kms-key"",\n        },\n        ""Environment"": {""my_env_variable"": 20},\n        ""NetworkConfig"": {\n            ""EnableInterContainerTrafficEncryption"": True,\n            ""EnableNetworkIsolation"": True,\n            ""VpcConfig"": {\n                ""SecurityGroupIds"": [""my_security_group_id""],\n                ""Subnets"": [""my_subnet_id""],\n            },\n        },\n        ""StoppingCondition"": {""MaxRuntimeInSeconds"": 3600},\n        ""Tags"": [{""Name"": ""my-tag"", ""Value"": ""my-tag-value""}],\n        ""ExperimentConfig"": {""ExperimentName"": ""AnExperiment""},\n    }\n\n    session.sagemaker_client.create_processing_job.assert_called_with(**expected_request)\n\n\ndef mock_exists(filepath_to_mock, exists_result):\n    unmocked_exists = os.path.exists\n\n    def side_effect(filepath):\n        if filepath == filepath_to_mock:\n            return exists_result\n        else:\n            return unmocked_exists(filepath)\n\n    return Mock(side_effect=side_effect)\n\n\ndef test_get_execution_role():\n    session = Mock()\n    session.get_caller_identity_arn.return_value = ""arn:aws:iam::369233609183:role/SageMakerRole""\n\n    actual = get_execution_role(session)\n    assert actual == ""arn:aws:iam::369233609183:role/SageMakerRole""\n\n\ndef test_get_execution_role_works_with_service_role():\n    session = Mock()\n    session.get_caller_identity_arn.return_value = (\n        ""arn:aws:iam::369233609183:role/service-role/AmazonSageMaker-ExecutionRole-20171129T072388""\n    )\n\n    actual = get_execution_role(session)\n    assert (\n        actual\n        == ""arn:aws:iam::369233609183:role/service-role/AmazonSageMaker-ExecutionRole-20171129T072388""\n    )\n\n\ndef test_get_execution_role_throws_exception_if_arn_is_not_role():\n    session = Mock()\n    session.get_caller_identity_arn.return_value = ""arn:aws:iam::369233609183:user/marcos""\n\n    with pytest.raises(ValueError) as error:\n        get_execution_role(session)\n    assert ""ValueError: The current AWS identity is not a role"" in str(error)\n\n\ndef test_get_execution_role_throws_exception_if_arn_is_not_role_with_role_in_name():\n    session = Mock()\n    session.get_caller_identity_arn.return_value = ""arn:aws:iam::369233609183:user/marcos-role""\n\n    with pytest.raises(ValueError) as error:\n        get_execution_role(session)\n    assert ""ValueError: The current AWS identity is not a role"" in str(error)\n\n\n@patch(""six.moves.builtins.open"", mock_open(read_data=\'{""ResourceName"": ""SageMakerInstance""}\'))\n@patch(""os.path.exists"", side_effect=mock_exists(NOTEBOOK_METADATA_FILE, True))\ndef test_get_caller_identity_arn_from_describe_notebook_instance(boto_session):\n    sess = Session(boto_session)\n    expected_role = ""arn:aws:iam::369233609183:role/service-role/SageMakerRole-20171129T072388""\n    sess.sagemaker_client.describe_notebook_instance.return_value = {""RoleArn"": expected_role}\n\n    actual = sess.get_caller_identity_arn()\n\n    assert actual == expected_role\n    sess.sagemaker_client.describe_notebook_instance.assert_called_once_with(\n        NotebookInstanceName=""SageMakerInstance""\n    )\n\n\n@patch(""six.moves.builtins.open"", mock_open(read_data=\'{""ResourceName"": ""SageMakerInstance""}\'))\n@patch(""os.path.exists"", side_effect=mock_exists(NOTEBOOK_METADATA_FILE, True))\n@patch(""sagemaker.session.sts_regional_endpoint"", return_value=STS_ENDPOINT)\ndef test_get_caller_identity_arn_from_a_role_after_describe_notebook_exception(\n    sts_regional_endpoint, boto_session\n):\n    sess = Session(boto_session)\n    exception = ClientError(\n        {""Error"": {""Code"": ""ValidationException"", ""Message"": ""RecordNotFound""}}, ""Operation""\n    )\n    sess.sagemaker_client.describe_notebook_instance.side_effect = exception\n\n    arn = (\n        ""arn:aws:sts::369233609183:assumed-role/SageMakerRole/6d009ef3-5306-49d5-8efc-78db644d8122""\n    )\n    sess.boto_session.client(""sts"", endpoint_url=STS_ENDPOINT).get_caller_identity.return_value = {\n        ""Arn"": arn\n    }\n\n    expected_role = ""arn:aws:iam::369233609183:role/SageMakerRole""\n    sess.boto_session.client(""iam"").get_role.return_value = {""Role"": {""Arn"": expected_role}}\n\n    with patch(""logging.Logger.debug"") as mock_logger:\n        actual = sess.get_caller_identity_arn()\n        mock_logger.assert_called_once()\n\n    sess.sagemaker_client.describe_notebook_instance.assert_called_once_with(\n        NotebookInstanceName=""SageMakerInstance""\n    )\n    assert actual == expected_role\n\n\n@patch(""os.path.exists"", side_effect=mock_exists(NOTEBOOK_METADATA_FILE, False))\n@patch(""sagemaker.session.sts_regional_endpoint"", return_value=STS_ENDPOINT)\ndef test_get_caller_identity_arn_from_a_user(sts_regional_endpoint, boto_session):\n    sess = Session(boto_session)\n    arn = ""arn:aws:iam::369233609183:user/mia""\n    sess.boto_session.client(""sts"", endpoint_url=STS_ENDPOINT).get_caller_identity.return_value = {\n        ""Arn"": arn\n    }\n    sess.boto_session.client(""iam"").get_role.return_value = {""Role"": {""Arn"": arn}}\n\n    actual = sess.get_caller_identity_arn()\n    assert actual == ""arn:aws:iam::369233609183:user/mia""\n\n\n@patch(""os.path.exists"", side_effect=mock_exists(NOTEBOOK_METADATA_FILE, False))\n@patch(""sagemaker.session.sts_regional_endpoint"", return_value=STS_ENDPOINT)\ndef test_get_caller_identity_arn_from_an_user_without_permissions(\n    sts_regional_endpoint, boto_session\n):\n    sess = Session(boto_session)\n    arn = ""arn:aws:iam::369233609183:user/mia""\n    sess.boto_session.client(""sts"", endpoint_url=STS_ENDPOINT).get_caller_identity.return_value = {\n        ""Arn"": arn\n    }\n    sess.boto_session.client(""iam"").get_role.side_effect = ClientError({}, {})\n\n    with patch(""logging.Logger.warning"") as mock_logger:\n        actual = sess.get_caller_identity_arn()\n        assert actual == ""arn:aws:iam::369233609183:user/mia""\n        mock_logger.assert_called_once()\n\n\n@patch(""os.path.exists"", side_effect=mock_exists(NOTEBOOK_METADATA_FILE, False))\n@patch(""sagemaker.session.sts_regional_endpoint"", return_value=STS_ENDPOINT)\ndef test_get_caller_identity_arn_from_a_role(sts_regional_endpoint, boto_session):\n    sess = Session(boto_session)\n    arn = (\n        ""arn:aws:sts::369233609183:assumed-role/SageMakerRole/6d009ef3-5306-49d5-8efc-78db644d8122""\n    )\n    sess.boto_session.client(""sts"", endpoint_url=STS_ENDPOINT).get_caller_identity.return_value = {\n        ""Arn"": arn\n    }\n\n    expected_role = ""arn:aws:iam::369233609183:role/SageMakerRole""\n    sess.boto_session.client(""iam"").get_role.return_value = {""Role"": {""Arn"": expected_role}}\n\n    actual = sess.get_caller_identity_arn()\n    assert actual == expected_role\n\n\n@patch(""os.path.exists"", side_effect=mock_exists(NOTEBOOK_METADATA_FILE, False))\n@patch(""sagemaker.session.sts_regional_endpoint"", return_value=STS_ENDPOINT)\ndef test_get_caller_identity_arn_from_an_execution_role(sts_regional_endpoint, boto_session):\n    sess = Session(boto_session)\n    arn = ""arn:aws:sts::369233609183:assumed-role/AmazonSageMaker-ExecutionRole-20171129T072388/SageMaker""\n    sess.boto_session.client(""sts"", endpoint_url=STS_ENDPOINT).get_caller_identity.return_value = {\n        ""Arn"": arn\n    }\n    sess.boto_session.client(""iam"").get_role.return_value = {""Role"": {""Arn"": arn}}\n\n    actual = sess.get_caller_identity_arn()\n    assert (\n        actual\n        == ""arn:aws:iam::369233609183:role/service-role/AmazonSageMaker-ExecutionRole-20171129T072388""\n    )\n\n\n@patch(""os.path.exists"", side_effect=mock_exists(NOTEBOOK_METADATA_FILE, False))\n@patch(""sagemaker.session.sts_regional_endpoint"", return_value=STS_ENDPOINT)\ndef test_get_caller_identity_arn_from_role_with_path(sts_regional_endpoint, boto_session):\n    sess = Session(boto_session)\n    arn_prefix = ""arn:aws:iam::369233609183:role""\n    role_name = ""name""\n    sess.boto_session.client(""sts"", endpoint_url=STS_ENDPOINT).get_caller_identity.return_value = {\n        ""Arn"": ""/"".join([arn_prefix, role_name])\n    }\n\n    role_path = ""path""\n    role_with_path = ""/"".join([arn_prefix, role_path, role_name])\n    sess.boto_session.client(""iam"").get_role.return_value = {""Role"": {""Arn"": role_with_path}}\n\n    actual = sess.get_caller_identity_arn()\n    assert actual == role_with_path\n\n\ndef test_delete_endpoint(boto_session):\n    sess = Session(boto_session)\n    sess.delete_endpoint(""my_endpoint"")\n\n    boto_session.client().delete_endpoint.assert_called_with(EndpointName=""my_endpoint"")\n\n\ndef test_delete_endpoint_config(boto_session):\n    sess = Session(boto_session)\n    sess.delete_endpoint_config(""my_endpoint_config"")\n\n    boto_session.client().delete_endpoint_config.assert_called_with(\n        EndpointConfigName=""my_endpoint_config""\n    )\n\n\ndef test_delete_model(boto_session):\n    sess = Session(boto_session)\n\n    model_name = ""my_model""\n    sess.delete_model(model_name)\n\n    boto_session.client().delete_model.assert_called_with(ModelName=model_name)\n\n\ndef test_user_agent_injected(boto_session):\n    assert (\n        ""AWS-SageMaker-Python-SDK"" not in boto_session.client(""sagemaker"")._client_config.user_agent\n    )\n\n    sess = Session(boto_session)\n\n    assert ""AWS-SageMaker-Python-SDK"" in sess.sagemaker_client._client_config.user_agent\n    assert ""AWS-SageMaker-Python-SDK"" in sess.sagemaker_runtime_client._client_config.user_agent\n    assert ""AWS-SageMaker-Notebook-Instance"" not in sess.sagemaker_client._client_config.user_agent\n    assert (\n        ""AWS-SageMaker-Notebook-Instance""\n        not in sess.sagemaker_runtime_client._client_config.user_agent\n    )\n\n\ndef test_user_agent_injected_with_nbi(boto_session):\n    assert (\n        ""AWS-SageMaker-Python-SDK"" not in boto_session.client(""sagemaker"")._client_config.user_agent\n    )\n\n    with patch(""six.moves.builtins.open"", mock_open(read_data=""120.0-0"")) as mo:\n        sess = Session(boto_session)\n\n        mo.assert_called_with(""/etc/opt/ml/sagemaker-notebook-instance-version.txt"")\n\n    assert ""AWS-SageMaker-Python-SDK"" in sess.sagemaker_client._client_config.user_agent\n    assert ""AWS-SageMaker-Python-SDK"" in sess.sagemaker_runtime_client._client_config.user_agent\n    assert ""AWS-SageMaker-Notebook-Instance"" in sess.sagemaker_client._client_config.user_agent\n    assert (\n        ""AWS-SageMaker-Notebook-Instance"" in sess.sagemaker_runtime_client._client_config.user_agent\n    )\n\n\ndef test_user_agent_injected_with_nbi_ioerror(boto_session):\n    assert (\n        ""AWS-SageMaker-Python-SDK"" not in boto_session.client(""sagemaker"")._client_config.user_agent\n    )\n\n    with patch(""six.moves.builtins.open"", MagicMock(side_effect=IOError(""File not found""))) as mo:\n        sess = Session(boto_session)\n\n        mo.assert_called_with(""/etc/opt/ml/sagemaker-notebook-instance-version.txt"")\n\n    assert ""AWS-SageMaker-Python-SDK"" in sess.sagemaker_client._client_config.user_agent\n    assert ""AWS-SageMaker-Python-SDK"" in sess.sagemaker_runtime_client._client_config.user_agent\n    assert ""AWS-SageMaker-Notebook-Instance"" not in sess.sagemaker_client._client_config.user_agent\n    assert (\n        ""AWS-SageMaker-Notebook-Instance""\n        not in sess.sagemaker_runtime_client._client_config.user_agent\n    )\n\n\ndef test_s3_input_all_defaults():\n    prefix = ""pre""\n    actual = s3_input(s3_data=prefix)\n    expected = {\n        ""DataSource"": {\n            ""S3DataSource"": {\n                ""S3DataDistributionType"": ""FullyReplicated"",\n                ""S3DataType"": ""S3Prefix"",\n                ""S3Uri"": prefix,\n            }\n        }\n    }\n    assert actual.config == expected\n\n\ndef test_s3_input_all_arguments():\n    prefix = ""pre""\n    distribution = ""FullyReplicated""\n    compression = ""Gzip""\n    content_type = ""text/csv""\n    record_wrapping = ""RecordIO""\n    s3_data_type = ""Manifestfile""\n    input_mode = ""Pipe""\n    result = s3_input(\n        s3_data=prefix,\n        distribution=distribution,\n        compression=compression,\n        input_mode=input_mode,\n        content_type=content_type,\n        record_wrapping=record_wrapping,\n        s3_data_type=s3_data_type,\n    )\n    expected = {\n        ""DataSource"": {\n            ""S3DataSource"": {\n                ""S3DataDistributionType"": distribution,\n                ""S3DataType"": s3_data_type,\n                ""S3Uri"": prefix,\n            }\n        },\n        ""CompressionType"": compression,\n        ""ContentType"": content_type,\n        ""RecordWrapperType"": record_wrapping,\n        ""InputMode"": input_mode,\n    }\n\n    assert result.config == expected\n\n\nIMAGE = ""myimage""\nS3_INPUT_URI = ""s3://mybucket/data""\nS3_OUTPUT = ""s3://sagemaker-123/output/jobname""\nROLE = ""SageMakerRole""\nEXPANDED_ROLE = ""arn:aws:iam::111111111111:role/ExpandedRole""\nINSTANCE_COUNT = 1\nINSTANCE_TYPE = ""ml.c4.xlarge""\nACCELERATOR_TYPE = ""ml.eia.medium""\nMAX_SIZE = 30\nMAX_TIME = 3 * 60 * 60\nJOB_NAME = ""jobname""\nTAGS = [{""Name"": ""some-tag"", ""Value"": ""value-for-tag""}]\nVPC_CONFIG = {""Subnets"": [""foo""], ""SecurityGroupIds"": [""bar""]}\nMETRIC_DEFINITONS = [{""Name"": ""validation-rmse"", ""Regex"": ""validation-rmse=(\\\\d+)""}]\nEXPERIMENT_CONFIG = {\n    ""ExperimentName"": ""dummyExp"",\n    ""TrialName"": ""dummyT"",\n    ""TrialComponentDisplayName"": ""dummyTC"",\n}\n\nDEFAULT_EXPECTED_TRAIN_JOB_ARGS = {\n    ""OutputDataConfig"": {""S3OutputPath"": S3_OUTPUT},\n    ""RoleArn"": EXPANDED_ROLE,\n    ""ResourceConfig"": {\n        ""InstanceCount"": INSTANCE_COUNT,\n        ""InstanceType"": INSTANCE_TYPE,\n        ""VolumeSizeInGB"": MAX_SIZE,\n    },\n    ""InputDataConfig"": [\n        {\n            ""DataSource"": {\n                ""S3DataSource"": {\n                    ""S3DataDistributionType"": ""FullyReplicated"",\n                    ""S3DataType"": ""S3Prefix"",\n                    ""S3Uri"": S3_INPUT_URI,\n                }\n            },\n            ""ChannelName"": ""training"",\n        }\n    ],\n    ""AlgorithmSpecification"": {""TrainingInputMode"": ""File"", ""TrainingImage"": IMAGE},\n    ""TrainingJobName"": JOB_NAME,\n    ""StoppingCondition"": {""MaxRuntimeInSeconds"": MAX_TIME},\n    ""VpcConfig"": VPC_CONFIG,\n    ""ExperimentConfig"": EXPERIMENT_CONFIG,\n}\n\nCOMPLETED_DESCRIBE_JOB_RESULT = dict(DEFAULT_EXPECTED_TRAIN_JOB_ARGS)\nCOMPLETED_DESCRIBE_JOB_RESULT.update(\n    {""TrainingJobArn"": ""arn:aws:sagemaker:us-west-2:336:training-job/"" + JOB_NAME}\n)\nCOMPLETED_DESCRIBE_JOB_RESULT.update({""TrainingJobStatus"": ""Completed""})\nCOMPLETED_DESCRIBE_JOB_RESULT.update(\n    {""ModelArtifacts"": {""S3ModelArtifacts"": S3_OUTPUT + ""/model/model.tar.gz""}}\n)\n# TrainingStartTime and TrainingEndTime are for billable seconds calculation\nCOMPLETED_DESCRIBE_JOB_RESULT.update(\n    {""TrainingStartTime"": datetime.datetime(2018, 2, 17, 7, 15, 0, 103000)}\n)\nCOMPLETED_DESCRIBE_JOB_RESULT.update(\n    {""TrainingEndTime"": datetime.datetime(2018, 2, 17, 7, 19, 34, 953000)}\n)\n\nSTOPPED_DESCRIBE_JOB_RESULT = dict(COMPLETED_DESCRIBE_JOB_RESULT)\nSTOPPED_DESCRIBE_JOB_RESULT.update({""TrainingJobStatus"": ""Stopped""})\n\nIN_PROGRESS_DESCRIBE_JOB_RESULT = dict(DEFAULT_EXPECTED_TRAIN_JOB_ARGS)\nIN_PROGRESS_DESCRIBE_JOB_RESULT.update({""TrainingJobStatus"": ""InProgress""})\n\nCOMPLETED_DESCRIBE_TRANSFORM_JOB_RESULT = {\n    ""TransformJobStatus"": ""Completed"",\n    ""ModelName"": ""some-model"",\n    ""TransformJobName"": JOB_NAME,\n    ""TransformResources"": {""InstanceCount"": INSTANCE_COUNT, ""InstanceType"": INSTANCE_TYPE},\n    ""TransformEndTime"": datetime.datetime(2018, 2, 17, 7, 19, 34, 953000),\n    ""TransformStartTime"": datetime.datetime(2018, 2, 17, 7, 15, 0, 103000),\n    ""TransformOutput"": {""AssembleWith"": ""None"", ""KmsKeyId"": """", ""S3OutputPath"": S3_OUTPUT},\n    ""TransformInput"": {\n        ""CompressionType"": ""None"",\n        ""ContentType"": ""text/csv"",\n        ""DataSource"": {""S3DataType"": ""S3Prefix"", ""S3Uri"": S3_INPUT_URI},\n        ""SplitType"": ""Line"",\n    },\n}\n\nSTOPPED_DESCRIBE_TRANSFORM_JOB_RESULT = dict(COMPLETED_DESCRIBE_TRANSFORM_JOB_RESULT)\nSTOPPED_DESCRIBE_TRANSFORM_JOB_RESULT.update({""TransformJobStatus"": ""Stopped""})\n\nIN_PROGRESS_DESCRIBE_TRANSFORM_JOB_RESULT = dict(COMPLETED_DESCRIBE_TRANSFORM_JOB_RESULT)\nIN_PROGRESS_DESCRIBE_TRANSFORM_JOB_RESULT.update({""TransformJobStatus"": ""InProgress""})\n\n\n@pytest.fixture()\ndef sagemaker_session():\n    boto_mock = Mock(name=""boto_session"")\n    boto_mock.client(""sts"", endpoint_url=STS_ENDPOINT).get_caller_identity.return_value = {\n        ""Account"": ""123""\n    }\n    ims = sagemaker.Session(boto_session=boto_mock, sagemaker_client=Mock())\n    ims.expand_role = Mock(return_value=EXPANDED_ROLE)\n    return ims\n\n\ndef test_train_pack_to_request(sagemaker_session):\n    in_config = [\n        {\n            ""ChannelName"": ""training"",\n            ""DataSource"": {\n                ""S3DataSource"": {\n                    ""S3DataDistributionType"": ""FullyReplicated"",\n                    ""S3DataType"": ""S3Prefix"",\n                    ""S3Uri"": S3_INPUT_URI,\n                }\n            },\n        }\n    ]\n\n    out_config = {""S3OutputPath"": S3_OUTPUT}\n\n    resource_config = {\n        ""InstanceCount"": INSTANCE_COUNT,\n        ""InstanceType"": INSTANCE_TYPE,\n        ""VolumeSizeInGB"": MAX_SIZE,\n    }\n\n    stop_cond = {""MaxRuntimeInSeconds"": MAX_TIME}\n\n    sagemaker_session.train(\n        image=IMAGE,\n        input_mode=""File"",\n        input_config=in_config,\n        role=EXPANDED_ROLE,\n        job_name=JOB_NAME,\n        output_config=out_config,\n        resource_config=resource_config,\n        hyperparameters=None,\n        stop_condition=stop_cond,\n        tags=None,\n        vpc_config=VPC_CONFIG,\n        metric_definitions=None,\n        experiment_config=EXPERIMENT_CONFIG,\n        enable_sagemaker_metrics=None,\n    )\n\n    assert sagemaker_session.sagemaker_client.method_calls[0] == (\n        ""create_training_job"",\n        (),\n        DEFAULT_EXPECTED_TRAIN_JOB_ARGS,\n    )\n\n\nSAMPLE_STOPPING_CONDITION = {""MaxRuntimeInSeconds"": MAX_TIME}\n\nRESOURCE_CONFIG = {\n    ""InstanceCount"": INSTANCE_COUNT,\n    ""InstanceType"": INSTANCE_TYPE,\n    ""VolumeSizeInGB"": MAX_SIZE,\n}\n\nSAMPLE_INPUT = [\n    {\n        ""DataSource"": {\n            ""S3DataSource"": {\n                ""S3DataDistributionType"": ""FullyReplicated"",\n                ""S3DataType"": ""S3Prefix"",\n                ""S3Uri"": S3_INPUT_URI,\n            }\n        },\n        ""ChannelName"": ""training"",\n    }\n]\n\nSAMPLE_OUTPUT = {""S3OutputPath"": S3_OUTPUT}\n\nSAMPLE_OBJECTIVE = {""Type"": ""Maximize"", ""MetricName"": ""val-score""}\nSAMPLE_OBJECTIVE_2 = {""Type"": ""Maximize"", ""MetricName"": ""value-score""}\n\nSAMPLE_METRIC_DEF = [{""Name"": ""train:progress"", ""Regex"": ""regex-1""}]\nSAMPLE_METRIC_DEF_2 = [{""Name"": ""value-score"", ""Regex"": ""regex-2""}]\n\nSTATIC_HPs = {""feature_dim"": ""784""}\nSTATIC_HPs_2 = {""gamma"": ""0.1""}\n\nSAMPLE_PARAM_RANGES = [{""Name"": ""mini_batch_size"", ""MinValue"": ""10"", ""MaxValue"": ""100""}]\nSAMPLE_PARAM_RANGES_2 = [{""Name"": ""kernel"", ""Values"": [""rbf"", ""sigmoid""]}]\n\nSAMPLE_TUNING_JOB_REQUEST = {\n    ""HyperParameterTuningJobName"": ""dummy-tuning-1"",\n    ""HyperParameterTuningJobConfig"": {\n        ""Strategy"": ""Bayesian"",\n        ""HyperParameterTuningJobObjective"": SAMPLE_OBJECTIVE,\n        ""ResourceLimits"": {""MaxNumberOfTrainingJobs"": 100, ""MaxParallelTrainingJobs"": 5},\n        ""ParameterRanges"": SAMPLE_PARAM_RANGES,\n        ""TrainingJobEarlyStoppingType"": ""Off"",\n    },\n    ""TrainingJobDefinition"": {\n        ""StaticHyperParameters"": STATIC_HPs,\n        ""AlgorithmSpecification"": {\n            ""TrainingImage"": ""dummy-image-1"",\n            ""TrainingInputMode"": ""File"",\n            ""MetricDefinitions"": SAMPLE_METRIC_DEF,\n        },\n        ""RoleArn"": EXPANDED_ROLE,\n        ""InputDataConfig"": SAMPLE_INPUT,\n        ""OutputDataConfig"": SAMPLE_OUTPUT,\n        ""ResourceConfig"": RESOURCE_CONFIG,\n        ""StoppingCondition"": SAMPLE_STOPPING_CONDITION,\n    },\n}\n\nSAMPLE_MULTI_ALGO_TUNING_JOB_REQUEST = {\n    ""HyperParameterTuningJobName"": ""dummy-tuning-1"",\n    ""HyperParameterTuningJobConfig"": {\n        ""Strategy"": ""Bayesian"",\n        ""ResourceLimits"": {""MaxNumberOfTrainingJobs"": 100, ""MaxParallelTrainingJobs"": 5},\n        ""TrainingJobEarlyStoppingType"": ""Off"",\n    },\n    ""TrainingJobDefinitions"": [\n        {\n            ""DefinitionName"": ""estimator_1"",\n            ""TuningObjective"": SAMPLE_OBJECTIVE,\n            ""HyperParameterRanges"": SAMPLE_PARAM_RANGES,\n            ""StaticHyperParameters"": STATIC_HPs,\n            ""AlgorithmSpecification"": {\n                ""TrainingImage"": ""dummy-image-1"",\n                ""TrainingInputMode"": ""File"",\n                ""MetricDefinitions"": SAMPLE_METRIC_DEF,\n            },\n            ""RoleArn"": EXPANDED_ROLE,\n            ""InputDataConfig"": SAMPLE_INPUT,\n            ""OutputDataConfig"": SAMPLE_OUTPUT,\n            ""ResourceConfig"": RESOURCE_CONFIG,\n            ""StoppingCondition"": SAMPLE_STOPPING_CONDITION,\n        },\n        {\n            ""DefinitionName"": ""estimator_2"",\n            ""TuningObjective"": SAMPLE_OBJECTIVE_2,\n            ""HyperParameterRanges"": SAMPLE_PARAM_RANGES_2,\n            ""StaticHyperParameters"": STATIC_HPs_2,\n            ""AlgorithmSpecification"": {\n                ""TrainingImage"": ""dummy-image-2"",\n                ""TrainingInputMode"": ""File"",\n                ""MetricDefinitions"": SAMPLE_METRIC_DEF_2,\n            },\n            ""RoleArn"": EXPANDED_ROLE,\n            ""InputDataConfig"": SAMPLE_INPUT,\n            ""OutputDataConfig"": SAMPLE_OUTPUT,\n            ""ResourceConfig"": RESOURCE_CONFIG,\n            ""StoppingCondition"": SAMPLE_STOPPING_CONDITION,\n        },\n    ],\n}\n\n\n@pytest.mark.parametrize(\n    ""warm_start_type, parents"",\n    [(""IdenticalDataAndAlgorithm"", {""p1"", ""p2"", ""p3""}), (""TransferLearning"", {""p1"", ""p2"", ""p3""})],\n)\ndef test_tune_warm_start(sagemaker_session, warm_start_type, parents):\n    def assert_create_tuning_job_request(**kwrags):\n        assert (\n            kwrags[""HyperParameterTuningJobConfig""]\n            == SAMPLE_TUNING_JOB_REQUEST[""HyperParameterTuningJobConfig""]\n        )\n        assert kwrags[""HyperParameterTuningJobName""] == ""dummy-tuning-1""\n        assert kwrags[""TrainingJobDefinition""] == SAMPLE_TUNING_JOB_REQUEST[""TrainingJobDefinition""]\n        assert kwrags[""WarmStartConfig""] == {\n            ""WarmStartType"": warm_start_type,\n            ""ParentHyperParameterTuningJobs"": [\n                {""HyperParameterTuningJobName"": parent} for parent in parents\n            ],\n        }\n\n    sagemaker_session.sagemaker_client.create_hyper_parameter_tuning_job.side_effect = (\n        assert_create_tuning_job_request\n    )\n    sagemaker_session.tune(\n        job_name=""dummy-tuning-1"",\n        strategy=""Bayesian"",\n        objective_type=""Maximize"",\n        objective_metric_name=""val-score"",\n        max_jobs=100,\n        max_parallel_jobs=5,\n        parameter_ranges=SAMPLE_PARAM_RANGES,\n        static_hyperparameters=STATIC_HPs,\n        image=""dummy-image-1"",\n        input_mode=""File"",\n        metric_definitions=SAMPLE_METRIC_DEF,\n        role=EXPANDED_ROLE,\n        input_config=SAMPLE_INPUT,\n        output_config=SAMPLE_OUTPUT,\n        resource_config=RESOURCE_CONFIG,\n        stop_condition=SAMPLE_STOPPING_CONDITION,\n        tags=None,\n        warm_start_config=WarmStartConfig(\n            warm_start_type=WarmStartTypes(warm_start_type), parents=parents\n        ).to_input_req(),\n    )\n\n\ndef test_create_tuning_job_without_training_config_or_list(sagemaker_session):\n    with pytest.raises(\n        ValueError, match=""Either training_config or training_config_list should be provided.""\n    ):\n        sagemaker_session.create_tuning_job(\n            job_name=""dummy-tuning-1"",\n            tuning_config={\n                ""strategy"": ""Bayesian"",\n                ""objective_type"": ""Maximize"",\n                ""objective_metric_name"": ""val-score"",\n                ""max_jobs"": 100,\n                ""max_parallel_jobs"": 5,\n                ""parameter_ranges"": SAMPLE_PARAM_RANGES,\n            },\n        )\n\n\ndef test_create_tuning_job_with_both_training_config_and_list(sagemaker_session):\n    with pytest.raises(\n        ValueError, match=""Only one of training_config and training_config_list should be provided.""\n    ):\n        sagemaker_session.create_tuning_job(\n            job_name=""dummy-tuning-1"",\n            tuning_config={\n                ""strategy"": ""Bayesian"",\n                ""objective_type"": ""Maximize"",\n                ""objective_metric_name"": ""val-score"",\n                ""max_jobs"": 100,\n                ""max_parallel_jobs"": 5,\n                ""parameter_ranges"": SAMPLE_PARAM_RANGES,\n            },\n            training_config={""static_hyperparameters"": STATIC_HPs, ""image"": ""dummy-image-1""},\n            training_config_list=[\n                {\n                    ""static_hyperparameters"": STATIC_HPs,\n                    ""image"": ""dummy-image-1"",\n                    ""estimator_name"": ""estimator_1"",\n                },\n                {\n                    ""static_hyperparameters"": STATIC_HPs_2,\n                    ""image"": ""dummy-image-2"",\n                    ""estimator_name"": ""estimator_2"",\n                },\n            ],\n        )\n\n\ndef test_create_tuning_job(sagemaker_session):\n    def assert_create_tuning_job_request(**kwrags):\n        assert (\n            kwrags[""HyperParameterTuningJobConfig""]\n            == SAMPLE_TUNING_JOB_REQUEST[""HyperParameterTuningJobConfig""]\n        )\n        assert kwrags[""HyperParameterTuningJobName""] == ""dummy-tuning-1""\n        assert kwrags[""TrainingJobDefinition""] == SAMPLE_TUNING_JOB_REQUEST[""TrainingJobDefinition""]\n        assert ""TrainingJobDefinitions"" not in kwrags\n        assert kwrags.get(""WarmStartConfig"", None) is None\n\n    sagemaker_session.sagemaker_client.create_hyper_parameter_tuning_job.side_effect = (\n        assert_create_tuning_job_request\n    )\n    sagemaker_session.create_tuning_job(\n        job_name=""dummy-tuning-1"",\n        tuning_config={\n            ""strategy"": ""Bayesian"",\n            ""objective_type"": ""Maximize"",\n            ""objective_metric_name"": ""val-score"",\n            ""max_jobs"": 100,\n            ""max_parallel_jobs"": 5,\n            ""parameter_ranges"": SAMPLE_PARAM_RANGES,\n        },\n        training_config={\n            ""static_hyperparameters"": STATIC_HPs,\n            ""image"": ""dummy-image-1"",\n            ""input_mode"": ""File"",\n            ""metric_definitions"": SAMPLE_METRIC_DEF,\n            ""role"": EXPANDED_ROLE,\n            ""input_config"": SAMPLE_INPUT,\n            ""output_config"": SAMPLE_OUTPUT,\n            ""resource_config"": RESOURCE_CONFIG,\n            ""stop_condition"": SAMPLE_STOPPING_CONDITION,\n        },\n        tags=None,\n        warm_start_config=None,\n    )\n\n\ndef test_create_tuning_job_multi_algo(sagemaker_session):\n    def assert_create_tuning_job_request(**kwrags):\n        expected_tuning_config = SAMPLE_MULTI_ALGO_TUNING_JOB_REQUEST[\n            ""HyperParameterTuningJobConfig""\n        ]\n        assert kwrags[""HyperParameterTuningJobConfig""] == expected_tuning_config\n        assert kwrags[""HyperParameterTuningJobName""] == ""dummy-tuning-1""\n        assert ""TrainingJobDefinition"" not in kwrags\n        assert (\n            kwrags[""TrainingJobDefinitions""]\n            == SAMPLE_MULTI_ALGO_TUNING_JOB_REQUEST[""TrainingJobDefinitions""]\n        )\n        assert kwrags.get(""WarmStartConfig"", None) is None\n\n    sagemaker_session.sagemaker_client.create_hyper_parameter_tuning_job.side_effect = (\n        assert_create_tuning_job_request\n    )\n    sagemaker_session.create_tuning_job(\n        job_name=""dummy-tuning-1"",\n        tuning_config={""strategy"": ""Bayesian"", ""max_jobs"": 100, ""max_parallel_jobs"": 5},\n        training_config_list=[\n            {\n                ""static_hyperparameters"": STATIC_HPs,\n                ""image"": ""dummy-image-1"",\n                ""input_mode"": ""File"",\n                ""metric_definitions"": SAMPLE_METRIC_DEF,\n                ""role"": EXPANDED_ROLE,\n                ""input_config"": SAMPLE_INPUT,\n                ""output_config"": SAMPLE_OUTPUT,\n                ""resource_config"": RESOURCE_CONFIG,\n                ""stop_condition"": SAMPLE_STOPPING_CONDITION,\n                ""estimator_name"": ""estimator_1"",\n                ""objective_type"": ""Maximize"",\n                ""objective_metric_name"": ""val-score"",\n                ""parameter_ranges"": SAMPLE_PARAM_RANGES,\n            },\n            {\n                ""static_hyperparameters"": STATIC_HPs_2,\n                ""image"": ""dummy-image-2"",\n                ""input_mode"": ""File"",\n                ""metric_definitions"": SAMPLE_METRIC_DEF_2,\n                ""role"": EXPANDED_ROLE,\n                ""input_config"": SAMPLE_INPUT,\n                ""output_config"": SAMPLE_OUTPUT,\n                ""resource_config"": RESOURCE_CONFIG,\n                ""stop_condition"": SAMPLE_STOPPING_CONDITION,\n                ""estimator_name"": ""estimator_2"",\n                ""objective_type"": ""Maximize"",\n                ""objective_metric_name"": ""value-score"",\n                ""parameter_ranges"": SAMPLE_PARAM_RANGES_2,\n            },\n        ],\n        tags=None,\n        warm_start_config=None,\n    )\n\n\ndef test_tune(sagemaker_session):\n    def assert_create_tuning_job_request(**kwrags):\n        assert (\n            kwrags[""HyperParameterTuningJobConfig""]\n            == SAMPLE_TUNING_JOB_REQUEST[""HyperParameterTuningJobConfig""]\n        )\n        assert kwrags[""HyperParameterTuningJobName""] == ""dummy-tuning-1""\n        assert kwrags[""TrainingJobDefinition""] == SAMPLE_TUNING_JOB_REQUEST[""TrainingJobDefinition""]\n        assert kwrags.get(""WarmStartConfig"", None) is None\n\n    sagemaker_session.sagemaker_client.create_hyper_parameter_tuning_job.side_effect = (\n        assert_create_tuning_job_request\n    )\n    sagemaker_session.tune(\n        job_name=""dummy-tuning-1"",\n        strategy=""Bayesian"",\n        objective_type=""Maximize"",\n        objective_metric_name=""val-score"",\n        max_jobs=100,\n        max_parallel_jobs=5,\n        parameter_ranges=SAMPLE_PARAM_RANGES,\n        static_hyperparameters=STATIC_HPs,\n        image=""dummy-image-1"",\n        input_mode=""File"",\n        metric_definitions=SAMPLE_METRIC_DEF,\n        role=EXPANDED_ROLE,\n        input_config=SAMPLE_INPUT,\n        output_config=SAMPLE_OUTPUT,\n        resource_config=RESOURCE_CONFIG,\n        stop_condition=SAMPLE_STOPPING_CONDITION,\n        tags=None,\n        warm_start_config=None,\n    )\n\n\ndef test_tune_with_encryption_flag(sagemaker_session):\n    def assert_create_tuning_job_request(**kwrags):\n        assert (\n            kwrags[""HyperParameterTuningJobConfig""]\n            == SAMPLE_TUNING_JOB_REQUEST[""HyperParameterTuningJobConfig""]\n        )\n        assert kwrags[""HyperParameterTuningJobName""] == ""dummy-tuning-1""\n        assert kwrags[""TrainingJobDefinition""][""EnableInterContainerTrafficEncryption""] is True\n        assert kwrags.get(""WarmStartConfig"", None) is None\n\n    sagemaker_session.sagemaker_client.create_hyper_parameter_tuning_job.side_effect = (\n        assert_create_tuning_job_request\n    )\n    sagemaker_session.tune(\n        job_name=""dummy-tuning-1"",\n        strategy=""Bayesian"",\n        objective_type=""Maximize"",\n        objective_metric_name=""val-score"",\n        max_jobs=100,\n        max_parallel_jobs=5,\n        parameter_ranges=SAMPLE_PARAM_RANGES,\n        static_hyperparameters=STATIC_HPs,\n        image=""dummy-image-1"",\n        input_mode=""File"",\n        metric_definitions=SAMPLE_METRIC_DEF,\n        role=EXPANDED_ROLE,\n        input_config=SAMPLE_INPUT,\n        output_config=SAMPLE_OUTPUT,\n        resource_config=RESOURCE_CONFIG,\n        stop_condition=SAMPLE_STOPPING_CONDITION,\n        tags=None,\n        warm_start_config=None,\n        encrypt_inter_container_traffic=True,\n    )\n\n\ndef test_tune_with_spot_and_checkpoints(sagemaker_session):\n    def assert_create_tuning_job_request(**kwargs):\n        assert (\n            kwargs[""HyperParameterTuningJobConfig""]\n            == SAMPLE_TUNING_JOB_REQUEST[""HyperParameterTuningJobConfig""]\n        )\n        assert kwargs[""HyperParameterTuningJobName""] == ""dummy-tuning-1""\n        assert kwargs[""TrainingJobDefinition""][""EnableManagedSpotTraining""] is True\n        assert (\n            kwargs[""TrainingJobDefinition""][""CheckpointConfig""][""S3Uri""]\n            == ""s3://mybucket/checkpoints/""\n        )\n        assert (\n            kwargs[""TrainingJobDefinition""][""CheckpointConfig""][""LocalPath""] == ""/tmp/checkpoints""\n        )\n        assert kwargs.get(""WarmStartConfig"", None) is None\n\n    sagemaker_session.sagemaker_client.create_hyper_parameter_tuning_job.side_effect = (\n        assert_create_tuning_job_request\n    )\n    sagemaker_session.tune(\n        job_name=""dummy-tuning-1"",\n        strategy=""Bayesian"",\n        objective_type=""Maximize"",\n        objective_metric_name=""val-score"",\n        max_jobs=100,\n        max_parallel_jobs=5,\n        parameter_ranges=SAMPLE_PARAM_RANGES,\n        static_hyperparameters=STATIC_HPs,\n        image=""dummy-image-1"",\n        input_mode=""File"",\n        metric_definitions=SAMPLE_METRIC_DEF,\n        role=EXPANDED_ROLE,\n        input_config=SAMPLE_INPUT,\n        output_config=SAMPLE_OUTPUT,\n        resource_config=RESOURCE_CONFIG,\n        stop_condition=SAMPLE_STOPPING_CONDITION,\n        tags=None,\n        warm_start_config=None,\n        train_use_spot_instances=True,\n        checkpoint_s3_uri=""s3://mybucket/checkpoints/"",\n        checkpoint_local_path=""/tmp/checkpoints"",\n    )\n\n\ndef test_stop_tuning_job(sagemaker_session):\n    sms = sagemaker_session\n    sms.sagemaker_client.stop_hyper_parameter_tuning_job = Mock(\n        name=""stop_hyper_parameter_tuning_job""\n    )\n\n    sagemaker_session.stop_tuning_job(JOB_NAME)\n    sms.sagemaker_client.stop_hyper_parameter_tuning_job.assert_called_once_with(\n        HyperParameterTuningJobName=JOB_NAME\n    )\n\n\ndef test_stop_tuning_job_client_error_already_stopped(sagemaker_session):\n    sms = sagemaker_session\n    exception = ClientError({""Error"": {""Code"": ""ValidationException""}}, ""Operation"")\n    sms.sagemaker_client.stop_hyper_parameter_tuning_job = Mock(\n        name=""stop_hyper_parameter_tuning_job"", side_effect=exception\n    )\n    sagemaker_session.stop_tuning_job(JOB_NAME)\n\n    sms.sagemaker_client.stop_hyper_parameter_tuning_job.assert_called_once_with(\n        HyperParameterTuningJobName=JOB_NAME\n    )\n\n\ndef test_stop_tuning_job_client_error(sagemaker_session):\n    error_response = {""Error"": {""Code"": ""MockException"", ""Message"": ""MockMessage""}}\n    operation = ""Operation""\n    exception = ClientError(error_response, operation)\n\n    sms = sagemaker_session\n    sms.sagemaker_client.stop_hyper_parameter_tuning_job = Mock(\n        name=""stop_hyper_parameter_tuning_job"", side_effect=exception\n    )\n\n    with pytest.raises(ClientError) as e:\n        sagemaker_session.stop_tuning_job(JOB_NAME)\n\n    sms.sagemaker_client.stop_hyper_parameter_tuning_job.assert_called_once_with(\n        HyperParameterTuningJobName=JOB_NAME\n    )\n    assert (\n        ""An error occurred (MockException) when calling the Operation operation: MockMessage""\n        in str(e)\n    )\n\n\ndef test_train_pack_to_request_with_optional_params(sagemaker_session):\n    in_config = [\n        {\n            ""ChannelName"": ""training"",\n            ""DataSource"": {\n                ""S3DataSource"": {\n                    ""S3DataDistributionType"": ""FullyReplicated"",\n                    ""S3DataType"": ""S3Prefix"",\n                    ""S3Uri"": S3_INPUT_URI,\n                }\n            },\n        }\n    ]\n\n    out_config = {""S3OutputPath"": S3_OUTPUT}\n\n    resource_config = {\n        ""InstanceCount"": INSTANCE_COUNT,\n        ""InstanceType"": INSTANCE_TYPE,\n        ""VolumeSizeInGB"": MAX_SIZE,\n    }\n\n    stop_cond = {""MaxRuntimeInSeconds"": MAX_TIME}\n    hyperparameters = {""foo"": ""bar""}\n\n    sagemaker_session.train(\n        image=IMAGE,\n        input_mode=""File"",\n        input_config=in_config,\n        role=EXPANDED_ROLE,\n        job_name=JOB_NAME,\n        output_config=out_config,\n        resource_config=resource_config,\n        vpc_config=VPC_CONFIG,\n        hyperparameters=hyperparameters,\n        stop_condition=stop_cond,\n        tags=TAGS,\n        metric_definitions=METRIC_DEFINITONS,\n        encrypt_inter_container_traffic=True,\n        train_use_spot_instances=True,\n        checkpoint_s3_uri=""s3://mybucket/checkpoints/"",\n        checkpoint_local_path=""/tmp/checkpoints"",\n        enable_sagemaker_metrics=True,\n    )\n\n    _, _, actual_train_args = sagemaker_session.sagemaker_client.method_calls[0]\n\n    assert actual_train_args[""VpcConfig""] == VPC_CONFIG\n    assert actual_train_args[""HyperParameters""] == hyperparameters\n    assert actual_train_args[""Tags""] == TAGS\n    assert actual_train_args[""AlgorithmSpecification""][""MetricDefinitions""] == METRIC_DEFINITONS\n    assert actual_train_args[""AlgorithmSpecification""][""EnableSageMakerMetricsTimeSeries""] is True\n    assert actual_train_args[""EnableInterContainerTrafficEncryption""] is True\n    assert actual_train_args[""EnableManagedSpotTraining""] is True\n    assert actual_train_args[""CheckpointConfig""][""S3Uri""] == ""s3://mybucket/checkpoints/""\n    assert actual_train_args[""CheckpointConfig""][""LocalPath""] == ""/tmp/checkpoints""\n\n\ndef test_transform_pack_to_request(sagemaker_session):\n    model_name = ""my-model""\n\n    in_config = {\n        ""CompressionType"": ""None"",\n        ""ContentType"": ""text/csv"",\n        ""SplitType"": ""None"",\n        ""DataSource"": {""S3DataSource"": {""S3DataType"": ""S3Prefix"", ""S3Uri"": S3_INPUT_URI}},\n    }\n\n    out_config = {""S3OutputPath"": S3_OUTPUT}\n\n    resource_config = {""InstanceCount"": INSTANCE_COUNT, ""InstanceType"": INSTANCE_TYPE}\n\n    data_processing = {""OutputFilter"": ""$"", ""InputFilter"": ""$"", ""JoinSource"": ""Input""}\n\n    expected_args = {\n        ""TransformJobName"": JOB_NAME,\n        ""ModelName"": model_name,\n        ""TransformInput"": in_config,\n        ""TransformOutput"": out_config,\n        ""TransformResources"": resource_config,\n        ""DataProcessing"": data_processing,\n    }\n\n    sagemaker_session.transform(\n        job_name=JOB_NAME,\n        model_name=model_name,\n        strategy=None,\n        max_concurrent_transforms=None,\n        max_payload=None,\n        env=None,\n        input_config=in_config,\n        output_config=out_config,\n        resource_config=resource_config,\n        experiment_config=None,\n        tags=None,\n        data_processing=data_processing,\n    )\n\n    _, _, actual_args = sagemaker_session.sagemaker_client.method_calls[0]\n    assert actual_args == expected_args\n\n\ndef test_transform_pack_to_request_with_optional_params(sagemaker_session):\n    strategy = ""strategy""\n    max_concurrent_transforms = 1\n    max_payload = 0\n    env = {""FOO"": ""BAR""}\n\n    sagemaker_session.transform(\n        job_name=JOB_NAME,\n        model_name=""my-model"",\n        strategy=strategy,\n        max_concurrent_transforms=max_concurrent_transforms,\n        env=env,\n        max_payload=max_payload,\n        input_config={},\n        output_config={},\n        resource_config={},\n        experiment_config=EXPERIMENT_CONFIG,\n        tags=TAGS,\n        data_processing=None,\n    )\n\n    _, _, actual_args = sagemaker_session.sagemaker_client.method_calls[0]\n    assert actual_args[""BatchStrategy""] == strategy\n    assert actual_args[""MaxConcurrentTransforms""] == max_concurrent_transforms\n    assert actual_args[""MaxPayloadInMB""] == max_payload\n    assert actual_args[""Environment""] == env\n    assert actual_args[""Tags""] == TAGS\n    assert actual_args[""ExperimentConfig""] == EXPERIMENT_CONFIG\n\n\n@patch(""sys.stdout"", new_callable=io.BytesIO if six.PY2 else io.StringIO)\ndef test_color_wrap(bio):\n    color_wrap = sagemaker.logs.ColorWrap()\n    color_wrap(0, ""hi there"")\n    assert bio.getvalue() == ""hi there\\n""\n\n\nclass MockBotoException(ClientError):\n    def __init__(self, code):\n        self.response = {""Error"": {""Code"": code}}\n\n\nDEFAULT_LOG_STREAMS = {""logStreams"": [{""logStreamName"": JOB_NAME + ""/xxxxxxxxx""}]}\nLIFECYCLE_LOG_STREAMS = [\n    MockBotoException(""ResourceNotFoundException""),\n    DEFAULT_LOG_STREAMS,\n    DEFAULT_LOG_STREAMS,\n    DEFAULT_LOG_STREAMS,\n    DEFAULT_LOG_STREAMS,\n    DEFAULT_LOG_STREAMS,\n    DEFAULT_LOG_STREAMS,\n]\n\nDEFAULT_LOG_EVENTS = [\n    {""nextForwardToken"": None, ""events"": [{""timestamp"": 1, ""message"": ""hi there #1""}]},\n    {""nextForwardToken"": None, ""events"": []},\n]\nSTREAM_LOG_EVENTS = [\n    {""nextForwardToken"": None, ""events"": [{""timestamp"": 1, ""message"": ""hi there #1""}]},\n    {""nextForwardToken"": None, ""events"": []},\n    {\n        ""nextForwardToken"": None,\n        ""events"": [\n            {""timestamp"": 1, ""message"": ""hi there #1""},\n            {""timestamp"": 2, ""message"": ""hi there #2""},\n        ],\n    },\n    {""nextForwardToken"": None, ""events"": []},\n    {\n        ""nextForwardToken"": None,\n        ""events"": [\n            {""timestamp"": 2, ""message"": ""hi there #2""},\n            {""timestamp"": 2, ""message"": ""hi there #2a""},\n            {""timestamp"": 3, ""message"": ""hi there #3""},\n        ],\n    },\n    {""nextForwardToken"": None, ""events"": []},\n]\n\n\n@pytest.fixture()\ndef sagemaker_session_complete():\n    boto_mock = Mock(name=""boto_session"")\n    boto_mock.client(""logs"").describe_log_streams.return_value = DEFAULT_LOG_STREAMS\n    boto_mock.client(""logs"").get_log_events.side_effect = DEFAULT_LOG_EVENTS\n    ims = sagemaker.Session(boto_session=boto_mock, sagemaker_client=Mock())\n    ims.sagemaker_client.describe_training_job.return_value = COMPLETED_DESCRIBE_JOB_RESULT\n    ims.sagemaker_client.describe_transform_job.return_value = (\n        COMPLETED_DESCRIBE_TRANSFORM_JOB_RESULT\n    )\n    return ims\n\n\n@pytest.fixture()\ndef sagemaker_session_stopped():\n    boto_mock = Mock(name=""boto_session"")\n    boto_mock.client(""logs"").describe_log_streams.return_value = DEFAULT_LOG_STREAMS\n    boto_mock.client(""logs"").get_log_events.side_effect = DEFAULT_LOG_EVENTS\n    ims = sagemaker.Session(boto_session=boto_mock, sagemaker_client=Mock())\n    ims.sagemaker_client.describe_training_job.return_value = STOPPED_DESCRIBE_JOB_RESULT\n    ims.sagemaker_client.describe_transform_job.return_value = STOPPED_DESCRIBE_TRANSFORM_JOB_RESULT\n    return ims\n\n\n@pytest.fixture()\ndef sagemaker_session_ready_lifecycle():\n    boto_mock = Mock(name=""boto_session"")\n    boto_mock.client(""logs"").describe_log_streams.return_value = DEFAULT_LOG_STREAMS\n    boto_mock.client(""logs"").get_log_events.side_effect = STREAM_LOG_EVENTS\n    ims = sagemaker.Session(boto_session=boto_mock, sagemaker_client=Mock())\n    ims.sagemaker_client.describe_training_job.side_effect = [\n        IN_PROGRESS_DESCRIBE_JOB_RESULT,\n        IN_PROGRESS_DESCRIBE_JOB_RESULT,\n        COMPLETED_DESCRIBE_JOB_RESULT,\n    ]\n    ims.sagemaker_client.describe_transform_job.side_effect = [\n        IN_PROGRESS_DESCRIBE_TRANSFORM_JOB_RESULT,\n        IN_PROGRESS_DESCRIBE_TRANSFORM_JOB_RESULT,\n        COMPLETED_DESCRIBE_TRANSFORM_JOB_RESULT,\n    ]\n    return ims\n\n\n@pytest.fixture()\ndef sagemaker_session_full_lifecycle():\n    boto_mock = Mock(name=""boto_session"")\n    boto_mock.client(""logs"").describe_log_streams.side_effect = LIFECYCLE_LOG_STREAMS\n    boto_mock.client(""logs"").get_log_events.side_effect = STREAM_LOG_EVENTS\n    ims = sagemaker.Session(boto_session=boto_mock, sagemaker_client=Mock())\n    ims.sagemaker_client.describe_training_job.side_effect = [\n        IN_PROGRESS_DESCRIBE_JOB_RESULT,\n        IN_PROGRESS_DESCRIBE_JOB_RESULT,\n        COMPLETED_DESCRIBE_JOB_RESULT,\n    ]\n    ims.sagemaker_client.describe_transform_job.side_effect = [\n        IN_PROGRESS_DESCRIBE_TRANSFORM_JOB_RESULT,\n        IN_PROGRESS_DESCRIBE_TRANSFORM_JOB_RESULT,\n        COMPLETED_DESCRIBE_TRANSFORM_JOB_RESULT,\n    ]\n    return ims\n\n\n@patch(""sagemaker.logs.ColorWrap"")\ndef test_logs_for_job_no_wait(cw, sagemaker_session_complete):\n    ims = sagemaker_session_complete\n    ims.logs_for_job(JOB_NAME)\n    ims.sagemaker_client.describe_training_job.assert_called_once_with(TrainingJobName=JOB_NAME)\n    cw().assert_called_with(0, ""hi there #1"")\n\n\n@patch(""sagemaker.logs.ColorWrap"")\ndef test_logs_for_job_no_wait_stopped_job(cw, sagemaker_session_stopped):\n    ims = sagemaker_session_stopped\n    ims.logs_for_job(JOB_NAME)\n    ims.sagemaker_client.describe_training_job.assert_called_once_with(TrainingJobName=JOB_NAME)\n    cw().assert_called_with(0, ""hi there #1"")\n\n\n@patch(""sagemaker.logs.ColorWrap"")\ndef test_logs_for_job_wait_on_completed(cw, sagemaker_session_complete):\n    ims = sagemaker_session_complete\n    ims.logs_for_job(JOB_NAME, wait=True, poll=0)\n    assert ims.sagemaker_client.describe_training_job.call_args_list == [\n        call(TrainingJobName=JOB_NAME)\n    ]\n    cw().assert_called_with(0, ""hi there #1"")\n\n\n@patch(""sagemaker.logs.ColorWrap"")\ndef test_logs_for_job_wait_on_stopped(cw, sagemaker_session_stopped):\n    ims = sagemaker_session_stopped\n    ims.logs_for_job(JOB_NAME, wait=True, poll=0)\n    assert ims.sagemaker_client.describe_training_job.call_args_list == [\n        call(TrainingJobName=JOB_NAME)\n    ]\n    cw().assert_called_with(0, ""hi there #1"")\n\n\n@patch(""sagemaker.logs.ColorWrap"")\ndef test_logs_for_job_no_wait_on_running(cw, sagemaker_session_ready_lifecycle):\n    ims = sagemaker_session_ready_lifecycle\n    ims.logs_for_job(JOB_NAME)\n    assert ims.sagemaker_client.describe_training_job.call_args_list == [\n        call(TrainingJobName=JOB_NAME)\n    ]\n    cw().assert_called_with(0, ""hi there #1"")\n\n\n@patch(""sagemaker.logs.ColorWrap"")\n@patch(""time.time"", side_effect=[0, 30, 60, 90, 120, 150, 180])\ndef test_logs_for_job_full_lifecycle(time, cw, sagemaker_session_full_lifecycle):\n    ims = sagemaker_session_full_lifecycle\n    ims.logs_for_job(JOB_NAME, wait=True, poll=0)\n    assert (\n        ims.sagemaker_client.describe_training_job.call_args_list\n        == [call(TrainingJobName=JOB_NAME)] * 3\n    )\n    assert cw().call_args_list == [\n        call(0, ""hi there #1""),\n        call(0, ""hi there #2""),\n        call(0, ""hi there #2a""),\n        call(0, ""hi there #3""),\n    ]\n\n\n@patch(""sagemaker.logs.ColorWrap"")\ndef test_logs_for_transform_job_no_wait(cw, sagemaker_session_complete):\n    ims = sagemaker_session_complete\n    ims.logs_for_transform_job(JOB_NAME)\n    ims.sagemaker_client.describe_transform_job.assert_called_once_with(TransformJobName=JOB_NAME)\n    cw().assert_called_with(0, ""hi there #1"")\n\n\n@patch(""sagemaker.logs.ColorWrap"")\ndef test_logs_for_transform_job_no_wait_stopped_job(cw, sagemaker_session_stopped):\n    ims = sagemaker_session_stopped\n    ims.logs_for_transform_job(JOB_NAME)\n    ims.sagemaker_client.describe_transform_job.assert_called_once_with(TransformJobName=JOB_NAME)\n    cw().assert_called_with(0, ""hi there #1"")\n\n\n@patch(""sagemaker.logs.ColorWrap"")\ndef test_logs_for_transform_job_wait_on_completed(cw, sagemaker_session_complete):\n    ims = sagemaker_session_complete\n    ims.logs_for_transform_job(JOB_NAME, wait=True, poll=0)\n    assert ims.sagemaker_client.describe_transform_job.call_args_list == [\n        call(TransformJobName=JOB_NAME)\n    ]\n    cw().assert_called_with(0, ""hi there #1"")\n\n\n@patch(""sagemaker.logs.ColorWrap"")\ndef test_logs_for_transform_job_wait_on_stopped(cw, sagemaker_session_stopped):\n    ims = sagemaker_session_stopped\n    ims.logs_for_transform_job(JOB_NAME, wait=True, poll=0)\n    assert ims.sagemaker_client.describe_transform_job.call_args_list == [\n        call(TransformJobName=JOB_NAME)\n    ]\n    cw().assert_called_with(0, ""hi there #1"")\n\n\n@patch(""sagemaker.logs.ColorWrap"")\ndef test_logs_for_transform_job_no_wait_on_running(cw, sagemaker_session_ready_lifecycle):\n    ims = sagemaker_session_ready_lifecycle\n    ims.logs_for_transform_job(JOB_NAME)\n    assert ims.sagemaker_client.describe_transform_job.call_args_list == [\n        call(TransformJobName=JOB_NAME)\n    ]\n    cw().assert_called_with(0, ""hi there #1"")\n\n\n@patch(""sagemaker.logs.ColorWrap"")\n@patch(""time.time"", side_effect=[0, 30, 60, 90, 120, 150, 180])\ndef test_logs_for_transform_job_full_lifecycle(time, cw, sagemaker_session_full_lifecycle):\n    ims = sagemaker_session_full_lifecycle\n    ims.logs_for_transform_job(JOB_NAME, wait=True, poll=0)\n    assert (\n        ims.sagemaker_client.describe_transform_job.call_args_list\n        == [call(TransformJobName=JOB_NAME)] * 3\n    )\n    assert cw().call_args_list == [\n        call(0, ""hi there #1""),\n        call(0, ""hi there #2""),\n        call(0, ""hi there #2a""),\n        call(0, ""hi there #3""),\n    ]\n\n\nMODEL_NAME = ""some-model""\nPRIMARY_CONTAINER = {\n    ""Environment"": {},\n    ""Image"": IMAGE,\n    ""ModelDataUrl"": ""s3://sagemaker-123/output/jobname/model/model.tar.gz"",\n}\n\n\n@patch(""sagemaker.session._expand_container_def"", return_value=PRIMARY_CONTAINER)\ndef test_create_model(expand_container_def, sagemaker_session):\n    model = sagemaker_session.create_model(MODEL_NAME, ROLE, PRIMARY_CONTAINER)\n\n    assert model == MODEL_NAME\n    sagemaker_session.sagemaker_client.create_model.assert_called_with(\n        ExecutionRoleArn=EXPANDED_ROLE, ModelName=MODEL_NAME, PrimaryContainer=PRIMARY_CONTAINER\n    )\n\n\n@patch(""sagemaker.session._expand_container_def"", return_value=PRIMARY_CONTAINER)\ndef test_create_model_with_tags(expand_container_def, sagemaker_session):\n    tags = [{""Key"": ""TagtestKey"", ""Value"": ""TagtestValue""}]\n    model = sagemaker_session.create_model(MODEL_NAME, ROLE, PRIMARY_CONTAINER, tags=tags)\n\n    assert model == MODEL_NAME\n    tags = [{""Value"": ""TagtestValue"", ""Key"": ""TagtestKey""}]\n    sagemaker_session.sagemaker_client.create_model.assert_called_with(\n        ExecutionRoleArn=EXPANDED_ROLE,\n        ModelName=MODEL_NAME,\n        PrimaryContainer=PRIMARY_CONTAINER,\n        Tags=tags,\n    )\n\n\n@patch(""sagemaker.session._expand_container_def"", return_value=PRIMARY_CONTAINER)\ndef test_create_model_with_primary_container(expand_container_def, sagemaker_session):\n    model = sagemaker_session.create_model(MODEL_NAME, ROLE, container_defs=PRIMARY_CONTAINER)\n\n    assert model == MODEL_NAME\n    sagemaker_session.sagemaker_client.create_model.assert_called_with(\n        ExecutionRoleArn=EXPANDED_ROLE, ModelName=MODEL_NAME, PrimaryContainer=PRIMARY_CONTAINER\n    )\n\n\n@patch(""sagemaker.session._expand_container_def"", return_value=PRIMARY_CONTAINER)\ndef test_create_model_with_both(expand_container_def, sagemaker_session):\n    with pytest.raises(ValueError):\n        sagemaker_session.create_model(\n            MODEL_NAME, ROLE, container_defs=PRIMARY_CONTAINER, primary_container=PRIMARY_CONTAINER\n        )\n\n\nCONTAINERS = [\n    {\n        ""Environment"": {""SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT"": ""application/json""},\n        ""Image"": ""mi-1"",\n        ""ModelDataUrl"": ""s3://bucket/model_1.tar.gz"",\n    },\n    {""Environment"": {}, ""Image"": ""mi-2"", ""ModelDataUrl"": ""s3://bucket/model_2.tar.gz""},\n]\n\n\n@patch(""sagemaker.session._expand_container_def"", return_value=PRIMARY_CONTAINER)\ndef test_create_pipeline_model(expand_container_def, sagemaker_session):\n    model = sagemaker_session.create_model(MODEL_NAME, ROLE, container_defs=CONTAINERS)\n\n    assert model == MODEL_NAME\n    sagemaker_session.sagemaker_client.create_model.assert_called_with(\n        ExecutionRoleArn=EXPANDED_ROLE, ModelName=MODEL_NAME, Containers=CONTAINERS\n    )\n\n\n@patch(""sagemaker.session._expand_container_def"", return_value=PRIMARY_CONTAINER)\ndef test_create_model_vpc_config(expand_container_def, sagemaker_session):\n    model = sagemaker_session.create_model(MODEL_NAME, ROLE, PRIMARY_CONTAINER, VPC_CONFIG)\n\n    assert model == MODEL_NAME\n    sagemaker_session.sagemaker_client.create_model.assert_called_with(\n        ExecutionRoleArn=EXPANDED_ROLE,\n        ModelName=MODEL_NAME,\n        PrimaryContainer=PRIMARY_CONTAINER,\n        VpcConfig=VPC_CONFIG,\n    )\n\n\n@patch(""sagemaker.session._expand_container_def"", return_value=PRIMARY_CONTAINER)\ndef test_create_pipeline_model_vpc_config(expand_container_def, sagemaker_session):\n    model = sagemaker_session.create_model(MODEL_NAME, ROLE, CONTAINERS, VPC_CONFIG)\n\n    assert model == MODEL_NAME\n    sagemaker_session.sagemaker_client.create_model.assert_called_with(\n        ExecutionRoleArn=EXPANDED_ROLE,\n        ModelName=MODEL_NAME,\n        Containers=CONTAINERS,\n        VpcConfig=VPC_CONFIG,\n    )\n\n\n@patch(""sagemaker.session._expand_container_def"", return_value=PRIMARY_CONTAINER)\ndef test_create_model_already_exists(expand_container_def, sagemaker_session, caplog):\n    error_response = {\n        ""Error"": {""Code"": ""ValidationException"", ""Message"": ""Cannot create already existing model""}\n    }\n    exception = ClientError(error_response, ""Operation"")\n    sagemaker_session.sagemaker_client.create_model.side_effect = exception\n\n    model = sagemaker_session.create_model(MODEL_NAME, ROLE, PRIMARY_CONTAINER)\n    assert model == MODEL_NAME\n\n    expected_warning = (\n        ""sagemaker"",\n        logging.WARNING,\n        ""Using already existing model: {}"".format(MODEL_NAME),\n    )\n    assert expected_warning in caplog.record_tuples\n\n\n@patch(""sagemaker.session._expand_container_def"", return_value=PRIMARY_CONTAINER)\ndef test_create_model_failure(expand_container_def, sagemaker_session):\n    error_message = ""this is expected""\n    sagemaker_session.sagemaker_client.create_model.side_effect = RuntimeError(error_message)\n\n    with pytest.raises(RuntimeError) as e:\n        sagemaker_session.create_model(MODEL_NAME, ROLE, PRIMARY_CONTAINER)\n\n    assert error_message in str(e)\n\n\ndef test_create_model_from_job(sagemaker_session):\n    ims = sagemaker_session\n    ims.sagemaker_client.describe_training_job.return_value = COMPLETED_DESCRIBE_JOB_RESULT\n    ims.create_model_from_job(JOB_NAME)\n\n    assert (\n        call(TrainingJobName=JOB_NAME) in ims.sagemaker_client.describe_training_job.call_args_list\n    )\n    ims.sagemaker_client.create_model.assert_called_with(\n        ExecutionRoleArn=EXPANDED_ROLE,\n        ModelName=JOB_NAME,\n        PrimaryContainer=PRIMARY_CONTAINER,\n        VpcConfig=VPC_CONFIG,\n    )\n\n\ndef test_create_model_from_job_with_tags(sagemaker_session):\n    ims = sagemaker_session\n    ims.sagemaker_client.describe_training_job.return_value = COMPLETED_DESCRIBE_JOB_RESULT\n    ims.create_model_from_job(JOB_NAME, tags=TAGS)\n\n    assert (\n        call(TrainingJobName=JOB_NAME) in ims.sagemaker_client.describe_training_job.call_args_list\n    )\n    ims.sagemaker_client.create_model.assert_called_with(\n        ExecutionRoleArn=EXPANDED_ROLE,\n        ModelName=JOB_NAME,\n        PrimaryContainer=PRIMARY_CONTAINER,\n        VpcConfig=VPC_CONFIG,\n        Tags=TAGS,\n    )\n\n\ndef test_create_model_from_job_with_image(sagemaker_session):\n    ims = sagemaker_session\n    ims.sagemaker_client.describe_training_job.return_value = COMPLETED_DESCRIBE_JOB_RESULT\n    ims.create_model_from_job(JOB_NAME, primary_container_image=""some-image"")\n    [create_model_call] = ims.sagemaker_client.create_model.call_args_list\n    assert dict(create_model_call[1][""PrimaryContainer""])[""Image""] == ""some-image""\n\n\ndef test_create_model_from_job_with_container_def(sagemaker_session):\n    ims = sagemaker_session\n    ims.sagemaker_client.describe_training_job.return_value = COMPLETED_DESCRIBE_JOB_RESULT\n    ims.create_model_from_job(\n        JOB_NAME, primary_container_image=""some-image"", model_data_url=""some-data"", env={""a"": ""b""}\n    )\n    [create_model_call] = ims.sagemaker_client.create_model.call_args_list\n    c_def = create_model_call[1][""PrimaryContainer""]\n    assert c_def[""Image""] == ""some-image""\n    assert c_def[""ModelDataUrl""] == ""some-data""\n    assert c_def[""Environment""] == {""a"": ""b""}\n\n\ndef test_create_model_from_job_with_vpc_config_override(sagemaker_session):\n    vpc_config_override = {""Subnets"": [""foo"", ""bar""], ""SecurityGroupIds"": [""baz""]}\n\n    ims = sagemaker_session\n    ims.sagemaker_client.describe_training_job.return_value = COMPLETED_DESCRIBE_JOB_RESULT\n    ims.create_model_from_job(JOB_NAME, vpc_config_override=vpc_config_override)\n    assert ims.sagemaker_client.create_model.call_args[1][""VpcConfig""] == vpc_config_override\n\n    ims.create_model_from_job(JOB_NAME, vpc_config_override=None)\n    assert ""VpcConfig"" not in ims.sagemaker_client.create_model.call_args[1]\n\n\ndef test_endpoint_from_production_variants(sagemaker_session):\n    ims = sagemaker_session\n    ims.sagemaker_client.describe_endpoint = Mock(return_value={""EndpointStatus"": ""InService""})\n    pvs = [\n        sagemaker.production_variant(""A"", ""ml.p2.xlarge""),\n        sagemaker.production_variant(""B"", ""p299.4096xlarge""),\n    ]\n    ex = ClientError(\n        {""Error"": {""Code"": ""ValidationException"", ""Message"": ""Could not find your thing""}}, ""b""\n    )\n    ims.sagemaker_client.describe_endpoint_config = Mock(side_effect=ex)\n    sagemaker_session.endpoint_from_production_variants(""some-endpoint"", pvs)\n    sagemaker_session.sagemaker_client.create_endpoint.assert_called_with(\n        EndpointConfigName=""some-endpoint"", EndpointName=""some-endpoint"", Tags=[]\n    )\n    sagemaker_session.sagemaker_client.create_endpoint_config.assert_called_with(\n        EndpointConfigName=""some-endpoint"", ProductionVariants=pvs\n    )\n\n\ndef test_create_endpoint_config_with_tags(sagemaker_session):\n    tags = [{""Key"": ""TagtestKey"", ""Value"": ""TagtestValue""}]\n\n    sagemaker_session.create_endpoint_config(""endpoint-test"", ""simple-model"", 1, ""local"", tags=tags)\n\n    sagemaker_session.sagemaker_client.create_endpoint_config.assert_called_with(\n        EndpointConfigName=""endpoint-test"", ProductionVariants=ANY, Tags=tags\n    )\n\n\ndef test_endpoint_from_production_variants_with_tags(sagemaker_session):\n    ims = sagemaker_session\n    ims.sagemaker_client.describe_endpoint = Mock(return_value={""EndpointStatus"": ""InService""})\n    pvs = [\n        sagemaker.production_variant(""A"", ""ml.p2.xlarge""),\n        sagemaker.production_variant(""B"", ""p299.4096xlarge""),\n    ]\n    ex = ClientError(\n        {""Error"": {""Code"": ""ValidationException"", ""Message"": ""Could not find your thing""}}, ""b""\n    )\n    ims.sagemaker_client.describe_endpoint_config = Mock(side_effect=ex)\n    tags = [{""ModelName"": ""TestModel""}]\n    sagemaker_session.endpoint_from_production_variants(""some-endpoint"", pvs, tags)\n    sagemaker_session.sagemaker_client.create_endpoint.assert_called_with(\n        EndpointConfigName=""some-endpoint"", EndpointName=""some-endpoint"", Tags=tags\n    )\n    sagemaker_session.sagemaker_client.create_endpoint_config.assert_called_with(\n        EndpointConfigName=""some-endpoint"", ProductionVariants=pvs, Tags=tags\n    )\n\n\ndef test_endpoint_from_production_variants_with_accelerator_type(sagemaker_session):\n    ims = sagemaker_session\n    ims.sagemaker_client.describe_endpoint = Mock(return_value={""EndpointStatus"": ""InService""})\n    pvs = [\n        sagemaker.production_variant(""A"", ""ml.p2.xlarge"", accelerator_type=ACCELERATOR_TYPE),\n        sagemaker.production_variant(""B"", ""p299.4096xlarge"", accelerator_type=ACCELERATOR_TYPE),\n    ]\n    ex = ClientError(\n        {""Error"": {""Code"": ""ValidationException"", ""Message"": ""Could not find your thing""}}, ""b""\n    )\n    ims.sagemaker_client.describe_endpoint_config = Mock(side_effect=ex)\n    tags = [{""ModelName"": ""TestModel""}]\n    sagemaker_session.endpoint_from_production_variants(""some-endpoint"", pvs, tags)\n    sagemaker_session.sagemaker_client.create_endpoint.assert_called_with(\n        EndpointConfigName=""some-endpoint"", EndpointName=""some-endpoint"", Tags=tags\n    )\n    sagemaker_session.sagemaker_client.create_endpoint_config.assert_called_with(\n        EndpointConfigName=""some-endpoint"", ProductionVariants=pvs, Tags=tags\n    )\n\n\ndef test_update_endpoint_succeed(sagemaker_session):\n    sagemaker_session.sagemaker_client.describe_endpoint = Mock(\n        return_value={""EndpointStatus"": ""InService""}\n    )\n    endpoint_name = ""some-endpoint""\n    endpoint_config = ""some-endpoint-config""\n    returned_endpoint_name = sagemaker_session.update_endpoint(endpoint_name, endpoint_config)\n    assert returned_endpoint_name == endpoint_name\n\n\ndef test_update_endpoint_no_wait(sagemaker_session):\n    sagemaker_session.sagemaker_client.describe_endpoint = Mock(\n        return_value={""EndpointStatus"": ""Updating""}\n    )\n    endpoint_name = ""some-endpoint""\n    endpoint_config = ""some-endpoint-config""\n    returned_endpoint_name = sagemaker_session.update_endpoint(\n        endpoint_name, endpoint_config, wait=False\n    )\n    assert returned_endpoint_name == endpoint_name\n\n\ndef test_update_endpoint_non_existing_endpoint(sagemaker_session):\n    error = ClientError(\n        {""Error"": {""Code"": ""ValidationException"", ""Message"": ""Could not find entity""}}, ""foo""\n    )\n    expected_error_message = (\n        ""Endpoint with name \'non-existing-endpoint\' does not exist; ""\n        ""please use an existing endpoint name""\n    )\n    sagemaker_session.sagemaker_client.describe_endpoint = Mock(side_effect=error)\n    with pytest.raises(ValueError, match=expected_error_message):\n        sagemaker_session.update_endpoint(""non-existing-endpoint"", ""non-existing-config"")\n\n\ndef test_create_endpoint_config_from_existing(sagemaker_session):\n    pvs = [sagemaker.production_variant(""A"", ""ml.m4.xlarge"")]\n    tags = [{""Key"": ""aws:cloudformation:stackname"", ""Value"": ""this-tag-should-be-ignored""}]\n    existing_endpoint_arn = ""arn:aws:sagemaker:us-west-2:123412341234:endpoint-config/foo""\n    kms_key = ""kms""\n    sagemaker_session.sagemaker_client.describe_endpoint_config.return_value = {\n        ""Tags"": tags,\n        ""ProductionVariants"": pvs,\n        ""EndpointConfigArn"": existing_endpoint_arn,\n        ""KmsKeyId"": kms_key,\n    }\n    sagemaker_session.sagemaker_client.list_tags.return_value = {""Tags"": tags}\n\n    existing_endpoint_name = ""foo""\n    new_endpoint_name = ""new-foo""\n    sagemaker_session.create_endpoint_config_from_existing(\n        existing_endpoint_name, new_endpoint_name\n    )\n\n    sagemaker_session.sagemaker_client.describe_endpoint_config.assert_called_with(\n        EndpointConfigName=existing_endpoint_name\n    )\n    sagemaker_session.sagemaker_client.list_tags.assert_called_with(\n        ResourceArn=existing_endpoint_arn, MaxResults=50\n    )\n    sagemaker_session.sagemaker_client.create_endpoint_config.assert_called_with(\n        EndpointConfigName=new_endpoint_name, ProductionVariants=pvs, KmsKeyId=kms_key\n    )\n\n\n@patch(""time.sleep"")\ndef test_wait_for_tuning_job(sleep, sagemaker_session):\n    hyperparameter_tuning_job_desc = {""HyperParameterTuningJobStatus"": ""Completed""}\n    sagemaker_session.sagemaker_client.describe_hyper_parameter_tuning_job = Mock(\n        name=""describe_hyper_parameter_tuning_job"", return_value=hyperparameter_tuning_job_desc\n    )\n\n    result = sagemaker_session.wait_for_tuning_job(JOB_NAME)\n    assert result[""HyperParameterTuningJobStatus""] == ""Completed""\n\n\ndef test_tune_job_status(sagemaker_session):\n    hyperparameter_tuning_job_desc = {""HyperParameterTuningJobStatus"": ""Completed""}\n    sagemaker_session.sagemaker_client.describe_hyper_parameter_tuning_job = Mock(\n        name=""describe_hyper_parameter_tuning_job"", return_value=hyperparameter_tuning_job_desc\n    )\n\n    result = _tuning_job_status(sagemaker_session.sagemaker_client, JOB_NAME)\n\n    assert result[""HyperParameterTuningJobStatus""] == ""Completed""\n\n\ndef test_tune_job_status_none(sagemaker_session):\n    hyperparameter_tuning_job_desc = {""HyperParameterTuningJobStatus"": ""InProgress""}\n    sagemaker_session.sagemaker_client.describe_hyper_parameter_tuning_job = Mock(\n        name=""describe_hyper_parameter_tuning_job"", return_value=hyperparameter_tuning_job_desc\n    )\n\n    result = _tuning_job_status(sagemaker_session.sagemaker_client, JOB_NAME)\n\n    assert result is None\n\n\n@patch(""time.sleep"")\ndef test_wait_for_transform_job_completed(sleep, sagemaker_session):\n    transform_job_desc = {""TransformJobStatus"": ""Completed""}\n    sagemaker_session.sagemaker_client.describe_transform_job = Mock(\n        name=""describe_transform_job"", return_value=transform_job_desc\n    )\n\n    assert sagemaker_session.wait_for_transform_job(JOB_NAME)[""TransformJobStatus""] == ""Completed""\n\n\n@patch(""time.sleep"")\ndef test_wait_for_transform_job_in_progress(sleep, sagemaker_session):\n    transform_job_desc_in_progress = {""TransformJobStatus"": ""InProgress""}\n    transform_job_desc_in_completed = {""TransformJobStatus"": ""Completed""}\n    sagemaker_session.sagemaker_client.describe_transform_job = Mock(\n        name=""describe_transform_job"",\n        side_effect=[transform_job_desc_in_progress, transform_job_desc_in_completed],\n    )\n\n    assert (\n        sagemaker_session.wait_for_transform_job(JOB_NAME, 1)[""TransformJobStatus""] == ""Completed""\n    )\n    assert 2 == sagemaker_session.sagemaker_client.describe_transform_job.call_count\n\n\ndef test_transform_job_status(sagemaker_session):\n    transform_job_desc = {""TransformJobStatus"": ""Completed""}\n    sagemaker_session.sagemaker_client.describe_transform_job = Mock(\n        name=""describe_transform_job"", return_value=transform_job_desc\n    )\n\n    result = _transform_job_status(sagemaker_session.sagemaker_client, JOB_NAME)\n    assert result[""TransformJobStatus""] == ""Completed""\n\n\ndef test_transform_job_status_none(sagemaker_session):\n    transform_job_desc = {""TransformJobStatus"": ""InProgress""}\n    sagemaker_session.sagemaker_client.describe_transform_job = Mock(\n        name=""describe_transform_job"", return_value=transform_job_desc\n    )\n\n    result = _transform_job_status(sagemaker_session.sagemaker_client, JOB_NAME)\n    assert result is None\n\n\ndef test_train_done_completed(sagemaker_session):\n    training_job_desc = {""TrainingJobStatus"": ""Completed""}\n    sagemaker_session.sagemaker_client.describe_training_job = Mock(\n        name=""describe_training_job"", return_value=training_job_desc\n    )\n\n    actual_job_desc, training_finished = _train_done(\n        sagemaker_session.sagemaker_client, JOB_NAME, None\n    )\n\n    assert actual_job_desc[""TrainingJobStatus""] == ""Completed""\n    assert training_finished is True\n\n\ndef test_train_done_in_progress(sagemaker_session):\n    training_job_desc = {""TrainingJobStatus"": ""InProgress""}\n    sagemaker_session.sagemaker_client.describe_training_job = Mock(\n        name=""describe_training_job"", return_value=training_job_desc\n    )\n\n    actual_job_desc, training_finished = _train_done(\n        sagemaker_session.sagemaker_client, JOB_NAME, None\n    )\n\n    assert actual_job_desc[""TrainingJobStatus""] == ""InProgress""\n    assert training_finished is False\n\n\nDEFAULT_EXPECTED_AUTO_ML_JOB_ARGS = {\n    ""AutoMLJobName"": JOB_NAME,\n    ""InputDataConfig"": [\n        {\n            ""DataSource"": {""S3DataSource"": {""S3DataType"": ""S3Prefix"", ""S3Uri"": S3_INPUT_URI}},\n            ""TargetAttributeName"": ""y"",\n        }\n    ],\n    ""OutputDataConfig"": {""S3OutputPath"": S3_OUTPUT},\n    ""AutoMLJobConfig"": {\n        ""CompletionCriteria"": {\n            ""MaxCandidates"": 10,\n            ""MaxAutoMLJobRuntimeInSeconds"": 36000,\n            ""MaxRuntimePerTrainingJobInSeconds"": 3600 * 2,\n        }\n    },\n    ""RoleArn"": EXPANDED_ROLE,\n    ""GenerateCandidateDefinitionsOnly"": False,\n}\n\n\nCOMPLETE_EXPECTED_AUTO_ML_JOB_ARGS = {\n    ""AutoMLJobName"": JOB_NAME,\n    ""InputDataConfig"": [\n        {\n            ""DataSource"": {""S3DataSource"": {""S3DataType"": ""S3Prefix"", ""S3Uri"": S3_INPUT_URI}},\n            ""CompressionType"": ""Gzip"",\n            ""TargetAttributeName"": ""y"",\n        }\n    ],\n    ""OutputDataConfig"": {""S3OutputPath"": S3_OUTPUT},\n    ""ProblemType"": ""Regression"",\n    ""AutoMLJobObjective"": {""Type"": ""type"", ""MetricName"": ""metric-name""},\n    ""AutoMLJobConfig"": {\n        ""CompletionCriteria"": {\n            ""MaxCandidates"": 10,\n            ""MaxAutoMLJobRuntimeInSeconds"": 36000,\n            ""MaxRuntimePerTrainingJobInSeconds"": 3600 * 2,\n        },\n        ""SecurityConfig"": {\n            ""VolumeKmsKeyId"": ""volume-kms-key-id-string"",\n            ""EnableInterContainerTrafficEncryption"": False,\n            ""VpcConfig"": {""SecurityGroupIds"": [""security-group-id""], ""Subnets"": [""subnet""]},\n        },\n    },\n    ""RoleArn"": EXPANDED_ROLE,\n    ""GenerateCandidateDefinitionsOnly"": True,\n    ""Tags"": [""tag""],\n}\n\nCOMPLETE_EXPECTED_LIST_CANDIDATES_ARGS = {\n    ""AutoMLJobName"": JOB_NAME,\n    ""StatusEquals"": ""Completed"",\n    ""SortOrder"": ""Descending"",\n    ""SortBy"": ""Status"",\n    ""MaxResults"": 10,\n}\n\n\ndef test_auto_ml_pack_to_request(sagemaker_session):\n    input_config = [\n        {\n            ""DataSource"": {""S3DataSource"": {""S3DataType"": ""S3Prefix"", ""S3Uri"": S3_INPUT_URI}},\n            ""TargetAttributeName"": ""y"",\n        }\n    ]\n\n    output_config = {""S3OutputPath"": S3_OUTPUT}\n\n    auto_ml_job_config = {\n        ""CompletionCriteria"": {\n            ""MaxCandidates"": 10,\n            ""MaxAutoMLJobRuntimeInSeconds"": 36000,\n            ""MaxRuntimePerTrainingJobInSeconds"": 3600 * 2,\n        }\n    }\n\n    job_name = JOB_NAME\n    role = EXPANDED_ROLE\n\n    sagemaker_session.auto_ml(input_config, output_config, auto_ml_job_config, role, job_name)\n\n    assert sagemaker_session.sagemaker_client.method_calls[0] == (\n        ""create_auto_ml_job"",\n        (),\n        DEFAULT_EXPECTED_AUTO_ML_JOB_ARGS,\n    )\n\n\ndef test_auto_ml_pack_to_request_with_optional_args(sagemaker_session):\n    input_config = [\n        {\n            ""DataSource"": {""S3DataSource"": {""S3DataType"": ""S3Prefix"", ""S3Uri"": S3_INPUT_URI}},\n            ""CompressionType"": ""Gzip"",\n            ""TargetAttributeName"": ""y"",\n        }\n    ]\n\n    output_config = {""S3OutputPath"": S3_OUTPUT}\n\n    auto_ml_job_config = {\n        ""CompletionCriteria"": {\n            ""MaxCandidates"": 10,\n            ""MaxAutoMLJobRuntimeInSeconds"": 36000,\n            ""MaxRuntimePerTrainingJobInSeconds"": 3600 * 2,\n        },\n        ""SecurityConfig"": {\n            ""VolumeKmsKeyId"": ""volume-kms-key-id-string"",\n            ""EnableInterContainerTrafficEncryption"": False,\n            ""VpcConfig"": {""SecurityGroupIds"": [""security-group-id""], ""Subnets"": [""subnet""]},\n        },\n    }\n\n    job_name = JOB_NAME\n    role = EXPANDED_ROLE\n\n    sagemaker_session.auto_ml(\n        input_config,\n        output_config,\n        auto_ml_job_config,\n        role,\n        job_name,\n        problem_type=""Regression"",\n        job_objective={""Type"": ""type"", ""MetricName"": ""metric-name""},\n        generate_candidate_definitions_only=True,\n        tags=[""tag""],\n    )\n\n    assert sagemaker_session.sagemaker_client.method_calls[0] == (\n        ""create_auto_ml_job"",\n        (),\n        COMPLETE_EXPECTED_AUTO_ML_JOB_ARGS,\n    )\n\n\ndef test_list_candidates_for_auto_ml_job_default(sagemaker_session):\n    sagemaker_session.list_candidates(job_name=JOB_NAME)\n    sagemaker_session.sagemaker_client.list_candidates_for_auto_ml_job.assert_called_once()\n    sagemaker_session.sagemaker_client.list_candidates_for_auto_ml_job.assert_called_with(\n        AutoMLJobName=JOB_NAME\n    )\n\n\ndef test_list_candidates_for_auto_ml_job_with_optional_args(sagemaker_session):\n    sagemaker_session.list_candidates(\n        job_name=JOB_NAME,\n        status_equals=""Completed"",\n        sort_order=""Descending"",\n        sort_by=""Status"",\n        max_results=10,\n    )\n    sagemaker_session.sagemaker_client.list_candidates_for_auto_ml_job.assert_called_once()\n    sagemaker_session.sagemaker_client.list_candidates_for_auto_ml_job.assert_called_with(\n        **COMPLETE_EXPECTED_LIST_CANDIDATES_ARGS\n    )\n'"
tests/unit/test_sklearn.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport logging\nimport json\nimport os\nimport pytest\n\nfrom mock import Mock\nfrom mock import patch\n\nfrom sagemaker.sklearn import defaults, SKLearn, SKLearnModel, SKLearnPredictor\nfrom sagemaker.fw_utils import UploadedCode\n\nDATA_DIR = os.path.join(os.path.dirname(__file__), "".."", ""data"")\nSCRIPT_PATH = os.path.join(DATA_DIR, ""dummy_script.py"")\nSERVING_SCRIPT_FILE = ""another_dummy_script.py""\nTIMESTAMP = ""2017-11-06-14:14:15.672""\nTIME = 1507167947\nBUCKET_NAME = ""mybucket""\nINSTANCE_COUNT = 1\nDIST_INSTANCE_COUNT = 2\nINSTANCE_TYPE = ""ml.c4.4xlarge""\nGPU_INSTANCE_TYPE = ""ml.p2.xlarge""\nPYTHON_VERSION = ""py3""\nIMAGE_NAME = ""sagemaker-scikit-learn""\nJOB_NAME = ""{}-{}"".format(IMAGE_NAME, TIMESTAMP)\nIMAGE_URI_FORMAT_STRING = ""246618743249.dkr.ecr.{}.amazonaws.com/{}:{}-{}-{}""\nROLE = ""Dummy""\nREGION = ""us-west-2""\nCPU = ""ml.c4.xlarge""\n\nENDPOINT_DESC = {""EndpointConfigName"": ""test-endpoint""}\n\nENDPOINT_CONFIG_DESC = {""ProductionVariants"": [{""ModelName"": ""model-1""}, {""ModelName"": ""model-2""}]}\n\nLIST_TAGS_RESULT = {""Tags"": [{""Key"": ""TagtestKey"", ""Value"": ""TagtestValue""}]}\n\nEXPERIMENT_CONFIG = {\n    ""ExperimentName"": ""exp"",\n    ""TrialName"": ""trial"",\n    ""TrialComponentDisplayName"": ""tc"",\n}\n\n\n@pytest.fixture()\ndef sagemaker_session():\n    boto_mock = Mock(name=""boto_session"", region_name=REGION)\n    session = Mock(\n        name=""sagemaker_session"",\n        boto_session=boto_mock,\n        boto_region_name=REGION,\n        config=None,\n        local_mode=False,\n        s3_resource=None,\n        s3_client=None,\n    )\n\n    describe = {""ModelArtifacts"": {""S3ModelArtifacts"": ""s3://m/m.tar.gz""}}\n    session.sagemaker_client.describe_training_job = Mock(return_value=describe)\n    session.sagemaker_client.describe_endpoint = Mock(return_value=ENDPOINT_DESC)\n    session.sagemaker_client.describe_endpoint_config = Mock(return_value=ENDPOINT_CONFIG_DESC)\n    session.sagemaker_client.list_tags = Mock(return_value=LIST_TAGS_RESULT)\n    session.default_bucket = Mock(name=""default_bucket"", return_value=BUCKET_NAME)\n    session.expand_role = Mock(name=""expand_role"", return_value=ROLE)\n    return session\n\n\ndef _get_full_cpu_image_uri(version):\n    return IMAGE_URI_FORMAT_STRING.format(REGION, IMAGE_NAME, version, ""cpu"", PYTHON_VERSION)\n\n\ndef _sklearn_estimator(\n    sagemaker_session,\n    framework_version=defaults.SKLEARN_VERSION,\n    train_instance_type=None,\n    base_job_name=None,\n    **kwargs\n):\n    return SKLearn(\n        entry_point=SCRIPT_PATH,\n        framework_version=framework_version,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_type=train_instance_type if train_instance_type else INSTANCE_TYPE,\n        base_job_name=base_job_name,\n        py_version=PYTHON_VERSION,\n        **kwargs\n    )\n\n\ndef _create_train_job(version):\n    return {\n        ""image"": _get_full_cpu_image_uri(version),\n        ""input_mode"": ""File"",\n        ""input_config"": [\n            {\n                ""ChannelName"": ""training"",\n                ""DataSource"": {\n                    ""S3DataSource"": {\n                        ""S3DataDistributionType"": ""FullyReplicated"",\n                        ""S3DataType"": ""S3Prefix"",\n                    }\n                },\n            }\n        ],\n        ""role"": ROLE,\n        ""job_name"": JOB_NAME,\n        ""output_config"": {""S3OutputPath"": ""s3://{}/"".format(BUCKET_NAME)},\n        ""resource_config"": {\n            ""InstanceType"": ""ml.c4.4xlarge"",\n            ""InstanceCount"": 1,\n            ""VolumeSizeInGB"": 30,\n        },\n        ""hyperparameters"": {\n            ""sagemaker_program"": json.dumps(""dummy_script.py""),\n            ""sagemaker_enable_cloudwatch_metrics"": ""false"",\n            ""sagemaker_container_log_level"": str(logging.INFO),\n            ""sagemaker_job_name"": json.dumps(JOB_NAME),\n            ""sagemaker_submit_directory"": json.dumps(\n                ""s3://{}/{}/source/sourcedir.tar.gz"".format(BUCKET_NAME, JOB_NAME)\n            ),\n            ""sagemaker_region"": \'""us-west-2""\',\n        },\n        ""stop_condition"": {""MaxRuntimeInSeconds"": 24 * 60 * 60},\n        ""metric_definitions"": None,\n        ""tags"": None,\n        ""vpc_config"": None,\n        ""experiment_config"": None,\n        ""debugger_hook_config"": {\n            ""CollectionConfigurations"": [],\n            ""S3OutputPath"": ""s3://{}/"".format(BUCKET_NAME),\n        },\n    }\n\n\ndef test_train_image(sagemaker_session, sklearn_version):\n    container_log_level = \'""logging.INFO""\'\n    source_dir = ""s3://mybucket/source""\n    sklearn = SKLearn(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_type=INSTANCE_TYPE,\n        framework_version=sklearn_version,\n        container_log_level=container_log_level,\n        py_version=PYTHON_VERSION,\n        base_job_name=""job"",\n        source_dir=source_dir,\n    )\n\n    train_image = sklearn.train_image()\n    assert (\n        train_image\n        == ""246618743249.dkr.ecr.us-west-2.amazonaws.com/sagemaker-scikit-learn:0.20.0-cpu-py3""\n    )\n\n\ndef test_create_model(sagemaker_session):\n    source_dir = ""s3://mybucket/source""\n\n    sklearn_model = SKLearnModel(\n        model_data=source_dir,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        entry_point=SCRIPT_PATH,\n    )\n    default_image_uri = _get_full_cpu_image_uri(""0.20.0"")\n    model_values = sklearn_model.prepare_container_def(CPU)\n    assert model_values[""Image""] == default_image_uri\n\n\n@patch(""sagemaker.model.FrameworkModel._upload_code"")\ndef test_create_model_with_network_isolation(upload, sagemaker_session):\n    source_dir = ""s3://mybucket/source""\n    repacked_model_data = ""s3://mybucket/prefix/model.tar.gz""\n\n    sklearn_model = SKLearnModel(\n        model_data=source_dir,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        entry_point=SCRIPT_PATH,\n        enable_network_isolation=True,\n    )\n    sklearn_model.uploaded_code = UploadedCode(s3_prefix=repacked_model_data, script_name=""script"")\n    sklearn_model.repacked_model_data = repacked_model_data\n    model_values = sklearn_model.prepare_container_def(CPU)\n    assert model_values[""Environment""][""SAGEMAKER_SUBMIT_DIRECTORY""] == ""/opt/ml/model/code""\n    assert model_values[""ModelDataUrl""] == repacked_model_data\n\n\ndef test_create_model_from_estimator(sagemaker_session, sklearn_version):\n    container_log_level = \'""logging.INFO""\'\n    source_dir = ""s3://mybucket/source""\n    sklearn = SKLearn(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_type=INSTANCE_TYPE,\n        framework_version=sklearn_version,\n        container_log_level=container_log_level,\n        py_version=PYTHON_VERSION,\n        base_job_name=""job"",\n        source_dir=source_dir,\n        enable_network_isolation=True,\n    )\n\n    job_name = ""new_name""\n    sklearn.fit(inputs=""s3://mybucket/train"", job_name=job_name)\n    model = sklearn.create_model()\n\n    assert model.sagemaker_session == sagemaker_session\n    assert model.framework_version == sklearn_version\n    assert model.py_version == sklearn.py_version\n    assert model.entry_point == SCRIPT_PATH\n    assert model.role == ROLE\n    assert model.name == job_name\n    assert model.container_log_level == container_log_level\n    assert model.source_dir == source_dir\n    assert model.vpc_config is None\n    assert model.enable_network_isolation()\n\n\ndef test_create_model_with_optional_params(sagemaker_session):\n    container_log_level = \'""logging.INFO""\'\n    source_dir = ""s3://mybucket/source""\n    enable_cloudwatch_metrics = ""true""\n    sklearn = SKLearn(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_type=INSTANCE_TYPE,\n        container_log_level=container_log_level,\n        py_version=PYTHON_VERSION,\n        base_job_name=""job"",\n        source_dir=source_dir,\n        enable_cloudwatch_metrics=enable_cloudwatch_metrics,\n    )\n\n    sklearn.fit(inputs=""s3://mybucket/train"", job_name=""new_name"")\n\n    custom_image = ""ubuntu:latest""\n    new_role = ""role""\n    model_server_workers = 2\n    vpc_config = {""Subnets"": [""foo""], ""SecurityGroupIds"": [""bar""]}\n    new_source_dir = ""s3://myotherbucket/source""\n    dependencies = [""/directory/a"", ""/directory/b""]\n    model_name = ""model-name""\n    model = sklearn.create_model(\n        image=custom_image,\n        role=new_role,\n        model_server_workers=model_server_workers,\n        vpc_config_override=vpc_config,\n        entry_point=SERVING_SCRIPT_FILE,\n        source_dir=new_source_dir,\n        dependencies=dependencies,\n        name=model_name,\n    )\n\n    assert model.image == custom_image\n    assert model.role == new_role\n    assert model.model_server_workers == model_server_workers\n    assert model.vpc_config == vpc_config\n    assert model.entry_point == SERVING_SCRIPT_FILE\n    assert model.source_dir == new_source_dir\n    assert model.dependencies == dependencies\n    assert model.name == model_name\n\n\ndef test_create_model_with_custom_image(sagemaker_session):\n    container_log_level = \'""logging.INFO""\'\n    source_dir = ""s3://mybucket/source""\n    custom_image = ""ubuntu:latest""\n    sklearn = SKLearn(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_type=INSTANCE_TYPE,\n        image_name=custom_image,\n        container_log_level=container_log_level,\n        py_version=PYTHON_VERSION,\n        base_job_name=""job"",\n        source_dir=source_dir,\n    )\n\n    sklearn.fit(inputs=""s3://mybucket/train"", job_name=""new_name"")\n    model = sklearn.create_model()\n\n    assert model.image == custom_image\n\n\n@patch(""time.strftime"", return_value=TIMESTAMP)\ndef test_sklearn(strftime, sagemaker_session, sklearn_version):\n    sklearn = SKLearn(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_type=INSTANCE_TYPE,\n        py_version=PYTHON_VERSION,\n        framework_version=sklearn_version,\n    )\n\n    inputs = ""s3://mybucket/train""\n\n    sklearn.fit(inputs=inputs, experiment_config=EXPERIMENT_CONFIG)\n\n    sagemaker_call_names = [c[0] for c in sagemaker_session.method_calls]\n    assert sagemaker_call_names == [""train"", ""logs_for_job""]\n    boto_call_names = [c[0] for c in sagemaker_session.boto_session.method_calls]\n    assert boto_call_names == [""resource""]\n\n    expected_train_args = _create_train_job(sklearn_version)\n    expected_train_args[""input_config""][0][""DataSource""][""S3DataSource""][""S3Uri""] = inputs\n    expected_train_args[""experiment_config""] = EXPERIMENT_CONFIG\n\n    actual_train_args = sagemaker_session.method_calls[0][2]\n    assert actual_train_args == expected_train_args\n\n    model = sklearn.create_model()\n\n    expected_image_base = (\n        ""246618743249.dkr.ecr.us-west-2.amazonaws.com/sagemaker-scikit-learn:{}-cpu-{}""\n    )\n    assert {\n        ""Environment"": {\n            ""SAGEMAKER_SUBMIT_DIRECTORY"": ""s3://mybucket/sagemaker-scikit-learn-{}/source/sourcedir.tar.gz"".format(\n                TIMESTAMP\n            ),\n            ""SAGEMAKER_PROGRAM"": ""dummy_script.py"",\n            ""SAGEMAKER_ENABLE_CLOUDWATCH_METRICS"": ""false"",\n            ""SAGEMAKER_REGION"": ""us-west-2"",\n            ""SAGEMAKER_CONTAINER_LOG_LEVEL"": ""20"",\n        },\n        ""Image"": expected_image_base.format(sklearn_version, PYTHON_VERSION),\n        ""ModelDataUrl"": ""s3://m/m.tar.gz"",\n    } == model.prepare_container_def(CPU)\n\n    assert ""cpu"" in model.prepare_container_def(CPU)[""Image""]\n    predictor = sklearn.deploy(1, CPU)\n    assert isinstance(predictor, SKLearnPredictor)\n\n\ndef test_transform_multiple_values_for_entry_point_issue(sagemaker_session, sklearn_version):\n    # https://github.com/aws/sagemaker-python-sdk/issues/974\n    sklearn = SKLearn(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_type=INSTANCE_TYPE,\n        py_version=PYTHON_VERSION,\n        framework_version=sklearn_version,\n    )\n\n    inputs = ""s3://mybucket/train""\n\n    sklearn.fit(inputs=inputs)\n\n    transformer = sklearn.transformer(instance_count=1, instance_type=""ml.m4.xlarge"")\n    # if we got here, we didn\'t get a ""multiple values"" error\n    assert transformer is not None\n\n\ndef test_fail_distributed_training(sagemaker_session, sklearn_version):\n    with pytest.raises(AttributeError) as error:\n        SKLearn(\n            entry_point=SCRIPT_PATH,\n            role=ROLE,\n            sagemaker_session=sagemaker_session,\n            train_instance_count=DIST_INSTANCE_COUNT,\n            train_instance_type=INSTANCE_TYPE,\n            py_version=PYTHON_VERSION,\n            framework_version=sklearn_version,\n        )\n    assert ""Scikit-Learn does not support distributed training."" in str(error)\n\n\ndef test_fail_GPU_training(sagemaker_session, sklearn_version):\n    with pytest.raises(ValueError) as error:\n        SKLearn(\n            entry_point=SCRIPT_PATH,\n            role=ROLE,\n            sagemaker_session=sagemaker_session,\n            train_instance_type=GPU_INSTANCE_TYPE,\n            py_version=PYTHON_VERSION,\n            framework_version=sklearn_version,\n        )\n    assert ""GPU training in not supported for Scikit-Learn."" in str(error)\n\n\ndef test_model(sagemaker_session):\n    model = SKLearnModel(\n        ""s3://some/data.tar.gz"",\n        role=ROLE,\n        entry_point=SCRIPT_PATH,\n        sagemaker_session=sagemaker_session,\n    )\n    predictor = model.deploy(1, CPU)\n    assert isinstance(predictor, SKLearnPredictor)\n\n\ndef test_train_image_default(sagemaker_session):\n    sklearn = SKLearn(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_type=INSTANCE_TYPE,\n        py_version=PYTHON_VERSION,\n    )\n\n    assert _get_full_cpu_image_uri(defaults.SKLEARN_VERSION) in sklearn.train_image()\n\n\ndef test_train_image_cpu_instances(sagemaker_session, sklearn_version):\n    sklearn = _sklearn_estimator(\n        sagemaker_session, sklearn_version, train_instance_type=""ml.c2.2xlarge""\n    )\n    assert sklearn.train_image() == _get_full_cpu_image_uri(sklearn_version)\n\n    sklearn = _sklearn_estimator(\n        sagemaker_session, sklearn_version, train_instance_type=""ml.c4.2xlarge""\n    )\n    assert sklearn.train_image() == _get_full_cpu_image_uri(sklearn_version)\n\n    sklearn = _sklearn_estimator(sagemaker_session, sklearn_version, train_instance_type=""ml.m16"")\n    assert sklearn.train_image() == _get_full_cpu_image_uri(sklearn_version)\n\n\ndef test_attach(sagemaker_session, sklearn_version):\n    training_image = ""1.dkr.ecr.us-west-2.amazonaws.com/sagemaker-scikit-learn:{}-cpu-{}"".format(\n        sklearn_version, PYTHON_VERSION\n    )\n    returned_job_description = {\n        ""AlgorithmSpecification"": {""TrainingInputMode"": ""File"", ""TrainingImage"": training_image},\n        ""HyperParameters"": {\n            ""sagemaker_submit_directory"": \'""s3://some/sourcedir.tar.gz""\',\n            ""sagemaker_program"": \'""iris-dnn-classifier.py""\',\n            ""sagemaker_s3_uri_training"": \'""sagemaker-3/integ-test-data/tf_iris""\',\n            ""sagemaker_enable_cloudwatch_metrics"": ""false"",\n            ""sagemaker_container_log_level"": \'""logging.INFO""\',\n            ""sagemaker_job_name"": \'""neo""\',\n            ""training_steps"": ""100"",\n            ""sagemaker_region"": \'""us-west-2""\',\n        },\n        ""RoleArn"": ""arn:aws:iam::366:role/SageMakerRole"",\n        ""ResourceConfig"": {\n            ""VolumeSizeInGB"": 30,\n            ""InstanceCount"": 1,\n            ""InstanceType"": ""ml.c4.xlarge"",\n        },\n        ""StoppingCondition"": {""MaxRuntimeInSeconds"": 24 * 60 * 60},\n        ""TrainingJobName"": ""neo"",\n        ""TrainingJobStatus"": ""Completed"",\n        ""TrainingJobArn"": ""arn:aws:sagemaker:us-west-2:336:training-job/neo"",\n        ""OutputDataConfig"": {""KmsKeyId"": """", ""S3OutputPath"": ""s3://place/output/neo""},\n        ""TrainingJobOutput"": {""S3TrainingJobOutput"": ""s3://here/output.tar.gz""},\n    }\n    sagemaker_session.sagemaker_client.describe_training_job = Mock(\n        name=""describe_training_job"", return_value=returned_job_description\n    )\n\n    estimator = SKLearn.attach(training_job_name=""neo"", sagemaker_session=sagemaker_session)\n    assert estimator._current_job_name == ""neo""\n    assert estimator.latest_training_job.job_name == ""neo""\n    assert estimator.py_version == PYTHON_VERSION\n    assert estimator.framework_version == sklearn_version\n    assert estimator.role == ""arn:aws:iam::366:role/SageMakerRole""\n    assert estimator.train_instance_count == 1\n    assert estimator.train_max_run == 24 * 60 * 60\n    assert estimator.input_mode == ""File""\n    assert estimator.base_job_name == ""neo""\n    assert estimator.output_path == ""s3://place/output/neo""\n    assert estimator.output_kms_key == """"\n    assert estimator.hyperparameters()[""training_steps""] == ""100""\n    assert estimator.source_dir == ""s3://some/sourcedir.tar.gz""\n    assert estimator.entry_point == ""iris-dnn-classifier.py""\n\n\ndef test_attach_wrong_framework(sagemaker_session):\n    rjd = {\n        ""AlgorithmSpecification"": {\n            ""TrainingInputMode"": ""File"",\n            ""TrainingImage"": ""1.dkr.ecr.us-west-2.amazonaws.com/sagemaker-mxnet-py3-cpu:1.0.4"",\n        },\n        ""HyperParameters"": {\n            ""sagemaker_submit_directory"": \'""s3://some/sourcedir.tar.gz""\',\n            ""checkpoint_path"": \'""s3://other/1508872349""\',\n            ""sagemaker_program"": \'""iris-dnn-classifier.py""\',\n            ""sagemaker_enable_cloudwatch_metrics"": ""false"",\n            ""sagemaker_container_log_level"": \'""logging.INFO""\',\n            ""training_steps"": ""100"",\n            ""sagemaker_region"": \'""us-west-2""\',\n        },\n        ""RoleArn"": ""arn:aws:iam::366:role/SageMakerRole"",\n        ""ResourceConfig"": {\n            ""VolumeSizeInGB"": 30,\n            ""InstanceCount"": 1,\n            ""InstanceType"": ""ml.c4.xlarge"",\n        },\n        ""StoppingCondition"": {""MaxRuntimeInSeconds"": 24 * 60 * 60},\n        ""TrainingJobName"": ""neo"",\n        ""TrainingJobStatus"": ""Completed"",\n        ""TrainingJobArn"": ""arn:aws:sagemaker:us-west-2:336:training-job/neo"",\n        ""OutputDataConfig"": {""KmsKeyId"": """", ""S3OutputPath"": ""s3://place/output/neo""},\n        ""TrainingJobOutput"": {""S3TrainingJobOutput"": ""s3://here/output.tar.gz""},\n    }\n    sagemaker_session.sagemaker_client.describe_training_job = Mock(\n        name=""describe_training_job"", return_value=rjd\n    )\n\n    with pytest.raises(ValueError) as error:\n        SKLearn.attach(training_job_name=""neo"", sagemaker_session=sagemaker_session)\n    assert ""didn\'t use image for requested framework"" in str(error)\n\n\ndef test_attach_custom_image(sagemaker_session):\n    training_image = ""1.dkr.ecr.us-west-2.amazonaws.com/my_custom_sklearn_image:latest""\n    returned_job_description = {\n        ""AlgorithmSpecification"": {""TrainingInputMode"": ""File"", ""TrainingImage"": training_image},\n        ""HyperParameters"": {\n            ""sagemaker_submit_directory"": \'""s3://some/sourcedir.tar.gz""\',\n            ""sagemaker_program"": \'""iris-dnn-classifier.py""\',\n            ""sagemaker_s3_uri_training"": \'""sagemaker-3/integ-test-data/tf_iris""\',\n            ""sagemaker_enable_cloudwatch_metrics"": ""false"",\n            ""sagemaker_container_log_level"": \'""logging.INFO""\',\n            ""sagemaker_job_name"": \'""neo""\',\n            ""training_steps"": ""100"",\n            ""sagemaker_region"": \'""us-west-2""\',\n        },\n        ""RoleArn"": ""arn:aws:iam::366:role/SageMakerRole"",\n        ""ResourceConfig"": {\n            ""VolumeSizeInGB"": 30,\n            ""InstanceCount"": 1,\n            ""InstanceType"": ""ml.c4.xlarge"",\n        },\n        ""StoppingCondition"": {""MaxRuntimeInSeconds"": 24 * 60 * 60},\n        ""TrainingJobName"": ""neo"",\n        ""TrainingJobStatus"": ""Completed"",\n        ""TrainingJobArn"": ""arn:aws:sagemaker:us-west-2:336:training-job/neo"",\n        ""OutputDataConfig"": {""KmsKeyId"": """", ""S3OutputPath"": ""s3://place/output/neo""},\n        ""TrainingJobOutput"": {""S3TrainingJobOutput"": ""s3://here/output.tar.gz""},\n    }\n    sagemaker_session.sagemaker_client.describe_training_job = Mock(\n        name=""describe_training_job"", return_value=returned_job_description\n    )\n\n    estimator = SKLearn.attach(training_job_name=""neo"", sagemaker_session=sagemaker_session)\n    assert estimator.image_name == training_image\n    assert estimator.train_image() == training_image\n\n\n@patch(""sagemaker.sklearn.estimator.python_deprecation_warning"")\ndef test_estimator_py2_warning(warning, sagemaker_session):\n    estimator = SKLearn(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        py_version=""py2"",\n    )\n\n    assert estimator.py_version == ""py2""\n    warning.assert_called_with(estimator.__framework_name__, defaults.LATEST_PY2_VERSION)\n\n\n@patch(""sagemaker.sklearn.model.python_deprecation_warning"")\ndef test_model_py2_warning(warning, sagemaker_session):\n    source_dir = ""s3://mybucket/source""\n\n    model = SKLearnModel(\n        model_data=source_dir,\n        role=ROLE,\n        entry_point=SCRIPT_PATH,\n        sagemaker_session=sagemaker_session,\n        py_version=""py2"",\n    )\n    assert model.py_version == ""py2""\n    warning.assert_called_with(model.__framework_name__, defaults.LATEST_PY2_VERSION)\n\n\ndef test_custom_image_estimator_deploy(sagemaker_session):\n    custom_image = ""mycustomimage:latest""\n    sklearn = _sklearn_estimator(sagemaker_session)\n    sklearn.fit(inputs=""s3://mybucket/train"", job_name=""new_name"")\n    model = sklearn.create_model(image=custom_image)\n    assert model.image == custom_image\n'"
tests/unit/test_sparkml_serving.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport pytest\nfrom mock import Mock\n\nfrom sagemaker.fw_registry import registry\nfrom sagemaker.sparkml import SparkMLModel, SparkMLPredictor\n\nMODEL_DATA = ""s3://bucket/model.tar.gz""\nROLE = ""myrole""\nTRAIN_INSTANCE_TYPE = ""ml.c4.xlarge""\n\nREGION = ""us-west-2""\nBUCKET_NAME = ""Some-Bucket""\nENDPOINT = ""some-endpoint""\n\nENDPOINT_DESC = {""EndpointConfigName"": ENDPOINT}\n\nENDPOINT_CONFIG_DESC = {""ProductionVariants"": [{""ModelName"": ""model-1""}, {""ModelName"": ""model-2""}]}\n\n\n@pytest.fixture()\ndef sagemaker_session():\n    boto_mock = Mock(name=""boto_session"", region_name=REGION)\n    sms = Mock(\n        name=""sagemaker_session"",\n        boto_session=boto_mock,\n        region_name=REGION,\n        config=None,\n        local_mode=False,\n    )\n    sms.boto_region_name = REGION\n    sms.sagemaker_client.describe_endpoint = Mock(return_value=ENDPOINT_DESC)\n    sms.sagemaker_client.describe_endpoint_config = Mock(return_value=ENDPOINT_CONFIG_DESC)\n    return sms\n\n\ndef test_sparkml_model(sagemaker_session):\n    sparkml = SparkMLModel(sagemaker_session=sagemaker_session, model_data=MODEL_DATA, role=ROLE)\n    assert sparkml.image == registry(REGION, ""sparkml-serving"") + ""/sagemaker-sparkml-serving:2.2""\n\n\ndef test_predictor_type(sagemaker_session):\n    sparkml = SparkMLModel(sagemaker_session=sagemaker_session, model_data=MODEL_DATA, role=ROLE)\n    predictor = sparkml.deploy(1, TRAIN_INSTANCE_TYPE)\n\n    assert isinstance(predictor, SparkMLPredictor)\n'"
tests/unit/test_sync_directories.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport filecmp\nimport os\nimport random\nimport shutil\n\nfrom sagemaker.tensorflow.estimator import Tensorboard\n\n\ndef create_test_directory(directory, variable_content=""hello world""):\n    """"""Create dummy data for testing Tensorboard._sync_directories with the\n    following structure:\n\n    <directory>\n    |_ child_directory\n        |_ hello.txt\n    |_ foo1.txt\n    |_ foo2.txt\n\n    Args:\n        directory (str): The path to a directory to create with fake files\n        variable_content (str): Content to put in one of the files\n    """"""\n    child_dir = os.path.join(directory, ""child_directory"")\n    os.mkdir(child_dir)\n    with open(os.path.join(directory, ""foo1.txt""), ""w"") as f:\n        f.write(""bar1"")\n    with open(os.path.join(directory, ""foo2.txt""), ""w"") as f:\n        f.write(""bar2"")\n    with open(os.path.join(child_dir, ""hello.txt""), ""w"") as f:\n        f.write(variable_content)\n\n\ndef same_dirs(a, b):\n    """"""Check that structure and files are the same for directories a and b\n\n    Args:\n        a (str): The path to the first directory\n        b (str): The path to the second directory\n    """"""\n    comp = filecmp.dircmp(a, b)\n    common = sorted(comp.common)\n    left = sorted(comp.left_list)\n    right = sorted(comp.right_list)\n    if left != common or right != common:\n        return False\n    if len(comp.diff_files):\n        return False\n    for subdir in comp.common_dirs:\n        left_subdir = os.path.join(a, subdir)\n        right_subdir = os.path.join(b, subdir)\n        return same_dirs(left_subdir, right_subdir)\n    return True\n\n\ndef test_to_directory_doesnt_exist():\n    with Tensorboard._temporary_directory() as from_dir:\n        create_test_directory(from_dir)\n        to_dir = ""./not_a_real_place_{}"".format(random.getrandbits(64))\n        Tensorboard._sync_directories(from_dir, to_dir)\n        assert same_dirs(from_dir, to_dir)\n        shutil.rmtree(to_dir)\n\n\ndef test_only_root_of_to_directory_exists():\n    with Tensorboard._temporary_directory() as from_dir:\n        with Tensorboard._temporary_directory() as to_dir:\n            create_test_directory(from_dir)\n            assert not same_dirs(from_dir, to_dir)\n            Tensorboard._sync_directories(from_dir, to_dir)\n            assert same_dirs(from_dir, to_dir)\n\n\ndef test_files_are_overwritten_when_they_already_exist():\n    with Tensorboard._temporary_directory() as from_dir:\n        with Tensorboard._temporary_directory() as to_dir:\n            create_test_directory(from_dir)\n            create_test_directory(to_dir, ""foo bar"")\n            assert not same_dirs(from_dir, to_dir)\n            Tensorboard._sync_directories(from_dir, to_dir)\n            assert same_dirs(from_dir, to_dir)\n'"
tests/unit/test_tf_estimator.py,58,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport json\nimport logging\nimport os\n\nimport pytest\nfrom mock import patch, Mock, MagicMock\n\nfrom sagemaker.fw_utils import create_image_uri\nfrom sagemaker.estimator import _TrainingJob\nfrom sagemaker.model import MODEL_SERVER_WORKERS_PARAM_NAME\nfrom sagemaker.session import s3_input\nfrom sagemaker.tensorflow import defaults, serving, TensorFlow, TensorFlowModel, TensorFlowPredictor\nimport sagemaker.tensorflow.estimator as tfe\n\nDATA_DIR = os.path.join(os.path.dirname(__file__), "".."", ""data"")\nSCRIPT_FILE = ""dummy_script.py""\nSCRIPT_PATH = os.path.join(DATA_DIR, SCRIPT_FILE)\nSERVING_SCRIPT_FILE = ""another_dummy_script.py""\nMODEL_DATA = ""s3://some/data.tar.gz""\nREQUIREMENTS_FILE = ""dummy_requirements.txt""\nTIMESTAMP = ""2017-11-06-14:14:15.673""\nTIME = 1510006209.073025\nBUCKET_NAME = ""mybucket""\nINSTANCE_COUNT = 1\nINSTANCE_TYPE = ""ml.c4.4xlarge""\nACCELERATOR_TYPE = ""ml.eia.medium""\nIMAGE_REPO_NAME = ""sagemaker-tensorflow""\nSM_IMAGE_REPO_NAME = ""sagemaker-tensorflow-scriptmode""\nJOB_NAME = ""{}-{}"".format(IMAGE_REPO_NAME, TIMESTAMP)\nSM_JOB_NAME = ""{}-{}"".format(SM_IMAGE_REPO_NAME, TIMESTAMP)\nROLE = ""Dummy""\nREGION = ""us-west-2""\nDOCKER_TAG = ""1.0""\nIMAGE_URI_FORMAT_STRING = ""520713654638.dkr.ecr.{}.amazonaws.com/{}:{}-{}-{}""\nSCRIPT_MODE_REPO_NAME = ""sagemaker-tensorflow-scriptmode""\nDISTRIBUTION_ENABLED = {""parameter_server"": {""enabled"": True}}\nDISTRIBUTION_MPI_ENABLED = {\n    ""mpi"": {""enabled"": True, ""custom_mpi_options"": ""options"", ""processes_per_host"": 2}\n}\n\nENDPOINT_DESC = {""EndpointConfigName"": ""test-endpoint""}\n\nENDPOINT_CONFIG_DESC = {""ProductionVariants"": [{""ModelName"": ""model-1""}, {""ModelName"": ""model-2""}]}\n\nLIST_TAGS_RESULT = {""Tags"": [{""Key"": ""TagtestKey"", ""Value"": ""TagtestValue""}]}\n\nEXPERIMENT_CONFIG = {\n    ""ExperimentName"": ""exp"",\n    ""TrialName"": ""trial"",\n    ""TrialComponentDisplayName"": ""tc"",\n}\n\n\n@pytest.fixture()\ndef sagemaker_session():\n    boto_mock = Mock(name=""boto_session"", region_name=REGION)\n    session = Mock(\n        name=""sagemaker_session"",\n        boto_session=boto_mock,\n        boto_region_name=REGION,\n        config=None,\n        local_mode=False,\n        s3_resource=None,\n        s3_client=None,\n    )\n    session.default_bucket = Mock(name=""default_bucket"", return_value=BUCKET_NAME)\n    session.expand_role = Mock(name=""expand_role"", return_value=ROLE)\n    describe = {""ModelArtifacts"": {""S3ModelArtifacts"": ""s3://m/m.tar.gz""}}\n    session.sagemaker_client.describe_training_job = Mock(return_value=describe)\n    session.sagemaker_client.describe_endpoint = Mock(return_value=ENDPOINT_DESC)\n    session.sagemaker_client.describe_endpoint_config = Mock(return_value=ENDPOINT_CONFIG_DESC)\n    session.sagemaker_client.list_tags = Mock(return_value=LIST_TAGS_RESULT)\n    return session\n\n\ndef _get_full_cpu_image_uri(version, repo=IMAGE_REPO_NAME, py_version=""py2""):\n    return IMAGE_URI_FORMAT_STRING.format(REGION, repo, version, ""cpu"", py_version)\n\n\ndef _get_full_gpu_image_uri(version, repo=IMAGE_REPO_NAME, py_version=""py2""):\n    return IMAGE_URI_FORMAT_STRING.format(REGION, repo, version, ""gpu"", py_version)\n\n\ndef _get_full_cpu_image_uri_with_ei(version):\n    return _get_full_cpu_image_uri(version, repo=""{}-eia"".format(IMAGE_REPO_NAME))\n\n\ndef _hyperparameters(script_mode=False, horovod=False):\n    job_name = SM_JOB_NAME if script_mode else JOB_NAME\n    hps = {\n        ""sagemaker_program"": json.dumps(""dummy_script.py""),\n        ""sagemaker_submit_directory"": json.dumps(\n            ""s3://{}/{}/source/sourcedir.tar.gz"".format(BUCKET_NAME, job_name)\n        ),\n        ""sagemaker_enable_cloudwatch_metrics"": ""false"",\n        ""sagemaker_container_log_level"": str(logging.INFO),\n        ""sagemaker_job_name"": json.dumps(job_name),\n        ""sagemaker_region"": json.dumps(""us-west-2""),\n    }\n    if script_mode:\n        if horovod:\n            hps[""model_dir""] = json.dumps(""/opt/ml/model"")\n        else:\n            hps[""model_dir""] = json.dumps(""s3://{}/{}/model"".format(BUCKET_NAME, job_name))\n    else:\n        hps[""checkpoint_path""] = json.dumps(""s3://{}/{}/checkpoints"".format(BUCKET_NAME, job_name))\n        hps[""training_steps""] = ""1000""\n        hps[""evaluation_steps""] = ""10""\n        hps[""sagemaker_requirements""] = \'""{}""\'.format(REQUIREMENTS_FILE)\n    return hps\n\n\ndef _create_train_job(\n    tf_version,\n    script_mode=False,\n    horovod=False,\n    ps=False,\n    repo_name=IMAGE_REPO_NAME,\n    py_version=""py2"",\n):\n    conf = {\n        ""image"": _get_full_cpu_image_uri(tf_version, repo=repo_name, py_version=py_version),\n        ""input_mode"": ""File"",\n        ""input_config"": [\n            {\n                ""ChannelName"": ""training"",\n                ""DataSource"": {\n                    ""S3DataSource"": {\n                        ""S3DataDistributionType"": ""FullyReplicated"",\n                        ""S3DataType"": ""S3Prefix"",\n                    }\n                },\n            }\n        ],\n        ""role"": ROLE,\n        ""job_name"": ""{}-{}"".format(repo_name, TIMESTAMP),\n        ""output_config"": {""S3OutputPath"": ""s3://{}/"".format(BUCKET_NAME)},\n        ""resource_config"": {\n            ""InstanceType"": ""ml.c4.4xlarge"",\n            ""InstanceCount"": 1,\n            ""VolumeSizeInGB"": 30,\n        },\n        ""hyperparameters"": _hyperparameters(script_mode, horovod),\n        ""stop_condition"": {""MaxRuntimeInSeconds"": 24 * 60 * 60},\n        ""tags"": None,\n        ""vpc_config"": None,\n        ""metric_definitions"": None,\n        ""experiment_config"": None,\n    }\n\n    if not ps:\n        conf[""debugger_hook_config""] = {\n            ""CollectionConfigurations"": [],\n            ""S3OutputPath"": ""s3://{}/"".format(BUCKET_NAME),\n        }\n\n    return conf\n\n\ndef _build_tf(\n    sagemaker_session,\n    framework_version=defaults.TF_VERSION,\n    train_instance_type=None,\n    checkpoint_path=None,\n    base_job_name=None,\n    training_steps=None,\n    evaluation_steps=None,\n    **kwargs\n):\n    return TensorFlow(\n        entry_point=SCRIPT_PATH,\n        training_steps=training_steps,\n        evaluation_steps=evaluation_steps,\n        framework_version=framework_version,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=train_instance_type if train_instance_type else INSTANCE_TYPE,\n        checkpoint_path=checkpoint_path,\n        base_job_name=base_job_name,\n        **kwargs\n    )\n\n\ndef test_tf_support_cpu_instances(sagemaker_session, tf_version):\n    tf = _build_tf(sagemaker_session, tf_version, train_instance_type=""ml.c2.2xlarge"")\n\n    assert tf.train_image() == _get_full_cpu_image_uri(tf_version)\n\n    tf = _build_tf(sagemaker_session, tf_version, train_instance_type=""ml.c4.2xlarge"")\n\n    assert tf.train_image() == _get_full_cpu_image_uri(tf_version)\n\n    tf = _build_tf(sagemaker_session, tf_version, train_instance_type=""ml.m16"")\n\n    assert tf.train_image() == _get_full_cpu_image_uri(tf_version)\n\n\ndef test_tf_support_gpu_instances(sagemaker_session, tf_version):\n    tf = _build_tf(sagemaker_session, tf_version, train_instance_type=""ml.g2.2xlarge"")\n\n    assert tf.train_image() == _get_full_gpu_image_uri(tf_version)\n\n    tf = _build_tf(sagemaker_session, tf_version, train_instance_type=""ml.p2.2xlarge"")\n\n    assert tf.train_image() == _get_full_gpu_image_uri(tf_version)\n\n\n@patch(""sagemaker.utils.create_tar_file"", MagicMock())\ndef test_tf_deploy_model_server_workers(sagemaker_session):\n    tf = _build_tf(sagemaker_session)\n    tf.fit(inputs=s3_input(""s3://mybucket/train""))\n\n    tf.deploy(initial_instance_count=1, instance_type=""ml.c2.2xlarge"", model_server_workers=2)\n\n    assert (\n        ""2""\n        == sagemaker_session.method_calls[3][1][2][""Environment""][\n            MODEL_SERVER_WORKERS_PARAM_NAME.upper()\n        ]\n    )\n\n\n@patch(""sagemaker.utils.create_tar_file"", MagicMock())\ndef test_tf_deploy_model_server_workers_unset(sagemaker_session):\n    tf = _build_tf(sagemaker_session)\n    tf.fit(inputs=s3_input(""s3://mybucket/train""))\n\n    tf.deploy(initial_instance_count=1, instance_type=""ml.c2.2xlarge"")\n\n    assert (\n        MODEL_SERVER_WORKERS_PARAM_NAME.upper()\n        not in sagemaker_session.method_calls[3][1][2][""Environment""]\n    )\n\n\ndef test_tf_invalid_requirements_path(sagemaker_session):\n    requirements_file = ""/foo/bar/requirements.txt""\n    with pytest.raises(ValueError) as e:\n        _build_tf(sagemaker_session, requirements_file=requirements_file, source_dir=DATA_DIR)\n    assert ""Requirements file {} is not a path relative to source_dir."".format(\n        requirements_file\n    ) in str(e.value)\n\n\ndef test_tf_nonexistent_requirements_path(sagemaker_session):\n    requirements_file = ""nonexistent_requirements.txt""\n    with pytest.raises(ValueError) as e:\n        _build_tf(sagemaker_session, requirements_file=requirements_file, source_dir=DATA_DIR)\n    assert ""Requirements file {} does not exist."".format(requirements_file) in str(e.value)\n\n\ndef test_create_model(sagemaker_session, tf_version):\n    container_log_level = \'""logging.INFO""\'\n    source_dir = ""s3://mybucket/source""\n    tf = TensorFlow(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        training_steps=1000,\n        evaluation_steps=10,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        framework_version=tf_version,\n        container_log_level=container_log_level,\n        base_job_name=""job"",\n        source_dir=source_dir,\n        enable_network_isolation=True,\n    )\n\n    job_name = ""doing something""\n    tf.fit(inputs=""s3://mybucket/train"", job_name=job_name)\n    model = tf.create_model()\n\n    assert model.sagemaker_session == sagemaker_session\n    assert model.framework_version == tf_version\n    assert model.py_version == tf.py_version\n    assert model.entry_point == SCRIPT_PATH\n    assert model.role == ROLE\n    assert model.name == job_name\n    assert model.container_log_level == container_log_level\n    assert model.source_dir == source_dir\n    assert model.vpc_config is None\n    assert model.enable_network_isolation()\n\n\ndef test_create_model_with_optional_params(sagemaker_session):\n    container_log_level = \'""logging.INFO""\'\n    source_dir = ""s3://mybucket/source""\n    enable_cloudwatch_metrics = ""true""\n    tf = TensorFlow(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        training_steps=1000,\n        evaluation_steps=10,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        container_log_level=container_log_level,\n        base_job_name=""job"",\n        source_dir=source_dir,\n        enable_cloudwatch_metrics=enable_cloudwatch_metrics,\n    )\n\n    job_name = ""doing something""\n    tf.fit(inputs=""s3://mybucket/train"", job_name=job_name)\n\n    new_role = ""role""\n    model_server_workers = 2\n    vpc_config = {""Subnets"": [""foo""], ""SecurityGroupIds"": [""bar""]}\n    model_name = ""model-name""\n    model = tf.create_model(\n        role=new_role,\n        model_server_workers=model_server_workers,\n        vpc_config_override=vpc_config,\n        entry_point=SERVING_SCRIPT_FILE,\n        name=model_name,\n        enable_network_isolation=True,\n    )\n\n    assert model.role == new_role\n    assert model.model_server_workers == model_server_workers\n    assert model.vpc_config == vpc_config\n    assert model.entry_point == SERVING_SCRIPT_FILE\n    assert model.name == model_name\n    assert model.enable_network_isolation()\n\n\n@patch(""sagemaker.tensorflow.estimator.TensorFlow.create_model"")\ndef test_transformer_creation_with_optional_args(create_model, sagemaker_session):\n    model = Mock()\n    create_model.return_value = model\n\n    tf = TensorFlow(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n    )\n    tf.latest_training_job = _TrainingJob(sagemaker_session, ""some-job-name"")\n\n    strategy = ""SingleRecord""\n    assemble_with = ""Line""\n    output_path = ""s3://{}/batch-output"".format(BUCKET_NAME)\n    kms_key = ""kms""\n    accept_type = ""text/bytes""\n    env = {""foo"": ""bar""}\n    max_concurrent_transforms = 3\n    max_payload = 100\n    tags = {""Key"": ""foo"", ""Value"": ""bar""}\n    new_role = ""role""\n    model_server_workers = 2\n    vpc_config = {""Subnets"": [""1234""], ""SecurityGroupIds"": [""5678""]}\n    model_name = ""model-name""\n\n    tf.transformer(\n        INSTANCE_COUNT,\n        INSTANCE_TYPE,\n        strategy=strategy,\n        assemble_with=assemble_with,\n        output_path=output_path,\n        output_kms_key=kms_key,\n        accept=accept_type,\n        env=env,\n        max_concurrent_transforms=max_concurrent_transforms,\n        max_payload=max_payload,\n        tags=tags,\n        role=new_role,\n        model_server_workers=model_server_workers,\n        volume_kms_key=kms_key,\n        endpoint_type=""tensorflow-serving"",\n        entry_point=SERVING_SCRIPT_FILE,\n        vpc_config_override=vpc_config,\n        enable_network_isolation=True,\n        model_name=model_name,\n    )\n\n    create_model.assert_called_with(\n        model_server_workers=model_server_workers,\n        role=new_role,\n        vpc_config_override=vpc_config,\n        endpoint_type=""tensorflow-serving"",\n        entry_point=SERVING_SCRIPT_FILE,\n        enable_network_isolation=True,\n        name=model_name,\n    )\n    model.transformer.assert_called_with(\n        INSTANCE_COUNT,\n        INSTANCE_TYPE,\n        accept=accept_type,\n        assemble_with=assemble_with,\n        env=env,\n        max_concurrent_transforms=max_concurrent_transforms,\n        max_payload=max_payload,\n        output_kms_key=kms_key,\n        output_path=output_path,\n        strategy=strategy,\n        tags=tags,\n        volume_kms_key=kms_key,\n    )\n\n\n@patch(""sagemaker.tensorflow.estimator.TensorFlow.create_model"")\ndef test_transformer_creation_without_optional_args(create_model, sagemaker_session):\n    model = Mock()\n    create_model.return_value = model\n\n    tf = TensorFlow(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n    )\n    tf.latest_training_job = _TrainingJob(sagemaker_session, ""some-job-name"")\n    tf.transformer(INSTANCE_COUNT, INSTANCE_TYPE)\n\n    create_model.assert_called_with(\n        endpoint_type=None,\n        model_server_workers=None,\n        role=ROLE,\n        vpc_config_override=""VPC_CONFIG_DEFAULT"",\n        entry_point=None,\n        enable_network_isolation=False,\n        name=None,\n    )\n    model.transformer.assert_called_with(\n        INSTANCE_COUNT,\n        INSTANCE_TYPE,\n        accept=None,\n        assemble_with=None,\n        env=None,\n        max_concurrent_transforms=None,\n        max_payload=None,\n        output_kms_key=None,\n        output_path=None,\n        strategy=None,\n        tags=None,\n        volume_kms_key=None,\n    )\n\n\ndef test_create_model_with_custom_image(sagemaker_session):\n    container_log_level = \'""logging.INFO""\'\n    source_dir = ""s3://mybucket/source""\n    custom_image = ""tensorflow:1.0""\n    tf = TensorFlow(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        training_steps=1000,\n        evaluation_steps=10,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        image_name=custom_image,\n        container_log_level=container_log_level,\n        base_job_name=""job"",\n        source_dir=source_dir,\n    )\n\n    job_name = ""doing something""\n    tf.fit(inputs=""s3://mybucket/train"", job_name=job_name)\n    model = tf.create_model()\n\n    assert model.image == custom_image\n\n\n@patch(""sagemaker.utils.create_tar_file"", MagicMock())\n@patch(""time.strftime"", MagicMock(return_value=TIMESTAMP))\n@patch(""time.time"", MagicMock(return_value=TIME))\ndef test_tf(sagemaker_session, tf_version):\n    tf = TensorFlow(\n        entry_point=SCRIPT_FILE,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        training_steps=1000,\n        evaluation_steps=10,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        framework_version=tf_version,\n        requirements_file=REQUIREMENTS_FILE,\n        source_dir=DATA_DIR,\n    )\n\n    inputs = ""s3://mybucket/train""\n\n    tf.fit(inputs=inputs, experiment_config=EXPERIMENT_CONFIG)\n\n    call_names = [c[0] for c in sagemaker_session.method_calls]\n    assert call_names == [""train"", ""logs_for_job""]\n\n    expected_train_args = _create_train_job(tf_version)\n    expected_train_args[""input_config""][0][""DataSource""][""S3DataSource""][""S3Uri""] = inputs\n    expected_train_args[""experiment_config""] = EXPERIMENT_CONFIG\n\n    actual_train_args = sagemaker_session.method_calls[0][2]\n    assert actual_train_args == expected_train_args\n\n    model = tf.create_model()\n\n    environment = {\n        ""Environment"": {\n            ""SAGEMAKER_SUBMIT_DIRECTORY"": ""s3://mybucket/sagemaker-tensorflow-2017-11-06-14:14:15.673/source/sourcedir.tar.gz"",  # noqa: E501\n            ""SAGEMAKER_PROGRAM"": ""dummy_script.py"",\n            ""SAGEMAKER_REQUIREMENTS"": ""dummy_requirements.txt"",\n            ""SAGEMAKER_ENABLE_CLOUDWATCH_METRICS"": ""false"",\n            ""SAGEMAKER_REGION"": ""us-west-2"",\n            ""SAGEMAKER_CONTAINER_LOG_LEVEL"": ""20"",\n        },\n        ""Image"": create_image_uri(""us-west-2"", ""tensorflow"", INSTANCE_TYPE, tf_version, ""py2""),\n        ""ModelDataUrl"": ""s3://m/m.tar.gz"",\n    }\n    assert environment == model.prepare_container_def(INSTANCE_TYPE)\n\n    assert ""cpu"" in model.prepare_container_def(INSTANCE_TYPE)[""Image""]\n    predictor = tf.deploy(1, INSTANCE_TYPE)\n    assert isinstance(predictor, TensorFlowPredictor)\n\n\n@patch(""time.strftime"", return_value=TIMESTAMP)\n@patch(""time.time"", return_value=TIME)\n@patch(""subprocess.Popen"")\n@patch(""subprocess.call"")\n@patch(""os.access"", return_value=False)\ndef test_run_tensorboard_locally_without_tensorboard_binary(\n    time, strftime, popen, call, access, sagemaker_session\n):\n    tf = TensorFlow(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n    )\n\n    with pytest.raises(EnvironmentError) as error:\n        tf.fit(inputs=""s3://mybucket/train"", run_tensorboard_locally=True)\n    assert (\n        str(error.value)\n        == ""TensorBoard is not installed in the system. Please install TensorBoard using the ""\n        ""following command: \\n pip install tensorboard""\n    )\n\n\n@patch(""sagemaker.utils.create_tar_file"", MagicMock())\ndef test_model(sagemaker_session, tf_version):\n    model = TensorFlowModel(\n        MODEL_DATA, role=ROLE, entry_point=SCRIPT_PATH, sagemaker_session=sagemaker_session\n    )\n    predictor = model.deploy(1, INSTANCE_TYPE)\n    assert isinstance(predictor, TensorFlowPredictor)\n\n\n@patch(""sagemaker.fw_utils.tar_and_upload_dir"", MagicMock())\ndef test_model_image_accelerator(sagemaker_session):\n    model = TensorFlowModel(\n        MODEL_DATA, role=ROLE, entry_point=SCRIPT_PATH, sagemaker_session=sagemaker_session\n    )\n    container_def = model.prepare_container_def(INSTANCE_TYPE, accelerator_type=ACCELERATOR_TYPE)\n    assert container_def[""Image""] == _get_full_cpu_image_uri_with_ei(defaults.TF_VERSION)\n\n\n@patch(""time.strftime"", return_value=TIMESTAMP)\n@patch(""time.time"", return_value=TIME)\n@patch(""subprocess.Popen"")\n@patch(""subprocess.call"")\n@patch(""os.access"", side_effect=[False, True])\ndef test_run_tensorboard_locally_without_awscli_binary(\n    time, strftime, popen, call, access, sagemaker_session\n):\n    tf = TensorFlow(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n    )\n\n    with pytest.raises(EnvironmentError) as error:\n        tf.fit(inputs=""s3://mybucket/train"", run_tensorboard_locally=True)\n    assert (\n        str(error.value)\n        == ""The AWS CLI is not installed in the system. Please install the AWS CLI using the ""\n        ""following command: \\n pip install awscli""\n    )\n\n\n@patch(""sagemaker.utils.create_tar_file"", MagicMock())\n@patch(""sagemaker.tensorflow.estimator.Tensorboard._sync_directories"")\n@patch(""tempfile.mkdtemp"", return_value=""/my/temp/folder"")\n@patch(""shutil.rmtree"")\n@patch(""os.access"", return_value=True)\n@patch(""subprocess.call"")\n@patch(""subprocess.Popen"")\n@patch(""time.strftime"", return_value=TIMESTAMP)\n@patch(""time.time"", return_value=TIME)\n@patch(""time.sleep"")\ndef test_run_tensorboard_locally(\n    sleep, time, strftime, popen, call, access, rmtree, mkdtemp, sync, sagemaker_session\n):\n    tf = TensorFlow(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n    )\n\n    popen().poll.return_value = None\n\n    tf.fit(inputs=""s3://mybucket/train"", run_tensorboard_locally=True)\n\n    popen.assert_called_with(\n        [""tensorboard"", ""--logdir"", ""/my/temp/folder"", ""--host"", ""localhost"", ""--port"", ""6006""],\n        stderr=-1,\n        stdout=-1,\n    )\n\n\n@patch(""sagemaker.utils.create_tar_file"", MagicMock())\n@patch(""sagemaker.tensorflow.estimator.Tensorboard._sync_directories"")\n@patch(""tempfile.mkdtemp"", return_value=""/my/temp/folder"")\n@patch(""shutil.rmtree"")\n@patch(""socket.socket"")\n@patch(""os.access"", return_value=True)\n@patch(""subprocess.call"")\n@patch(""subprocess.Popen"")\n@patch(""time.strftime"", return_value=TIMESTAMP)\n@patch(""time.time"", return_value=TIME)\n@patch(""time.sleep"")\ndef test_run_tensorboard_locally_port_in_use(\n    sleep, time, strftime, popen, call, access, socket, rmtree, mkdtemp, sync, sagemaker_session\n):\n    tf = TensorFlow(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n    )\n\n    popen().poll.side_effect = [-1, None]\n\n    tf.fit(inputs=""s3://mybucket/train"", run_tensorboard_locally=True)\n\n    popen.assert_any_call(\n        [""tensorboard"", ""--logdir"", ""/my/temp/folder"", ""--host"", ""localhost"", ""--port"", ""6006""],\n        stderr=-1,\n        stdout=-1,\n    )\n\n    popen.assert_any_call(\n        [""tensorboard"", ""--logdir"", ""/my/temp/folder"", ""--host"", ""localhost"", ""--port"", ""6007""],\n        stderr=-1,\n        stdout=-1,\n    )\n\n\n@patch(""sagemaker.utils.create_tar_file"", MagicMock())\ndef test_tf_checkpoint_not_set(sagemaker_session):\n    job_name = ""sagemaker-tensorflow-py2-gpu-2017-10-24-14-12-09""\n    tf = _build_tf(\n        sagemaker_session,\n        checkpoint_path=None,\n        base_job_name=job_name,\n        output_path=""s3://{}/"".format(sagemaker_session.default_bucket()),\n    )\n    tf.fit(inputs=s3_input(""s3://mybucket/train""), job_name=job_name)\n\n    expected_result = \'""s3://{}/{}/checkpoints""\'.format(\n        sagemaker_session.default_bucket(), job_name\n    )\n    assert tf.hyperparameters()[""checkpoint_path""] == expected_result\n\n\n@patch(""sagemaker.utils.create_tar_file"", MagicMock())\ndef test_tf_training_and_evaluation_steps_not_set(sagemaker_session):\n    job_name = ""sagemaker-tensorflow-py2-gpu-2017-10-24-14-12-09""\n    output_path = ""s3://{}/output/{}/"".format(sagemaker_session.default_bucket(), job_name)\n\n    tf = _build_tf(\n        sagemaker_session, training_steps=None, evaluation_steps=None, output_path=output_path\n    )\n    tf.fit(inputs=s3_input(""s3://mybucket/train""))\n    assert tf.hyperparameters()[""training_steps""] == ""null""\n    assert tf.hyperparameters()[""evaluation_steps""] == ""null""\n\n\n@patch(""sagemaker.utils.create_tar_file"", MagicMock())\ndef test_tf_training_and_evaluation_steps(sagemaker_session):\n    job_name = ""sagemaker-tensorflow-py2-gpu-2017-10-24-14-12-09""\n    output_path = ""s3://{}/output/{}/"".format(sagemaker_session.default_bucket(), job_name)\n\n    tf = _build_tf(\n        sagemaker_session, training_steps=123, evaluation_steps=456, output_path=output_path\n    )\n    tf.fit(inputs=s3_input(""s3://mybucket/train""))\n    assert tf.hyperparameters()[""training_steps""] == ""123""\n    assert tf.hyperparameters()[""evaluation_steps""] == ""456""\n\n\n@patch(""sagemaker.utils.create_tar_file"", MagicMock())\ndef test_tf_checkpoint_set(sagemaker_session):\n    tf = _build_tf(sagemaker_session, checkpoint_path=""s3://my_checkpoint_bucket"")\n    assert tf.hyperparameters()[""checkpoint_path""] == json.dumps(""s3://my_checkpoint_bucket"")\n\n\n@patch(""sagemaker.utils.create_tar_file"", MagicMock())\ndef test_train_image_default(sagemaker_session):\n    tf = TensorFlow(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n    )\n\n    assert _get_full_cpu_image_uri(defaults.TF_VERSION) in tf.train_image()\n\n\n@patch(""sagemaker.utils.create_tar_file"", MagicMock())\ndef test_attach(sagemaker_session, tf_version):\n    training_image = ""1.dkr.ecr.us-west-2.amazonaws.com/sagemaker-tensorflow-py2-cpu:{}-cpu-py2"".format(\n        tf_version\n    )\n    rjd = {\n        ""AlgorithmSpecification"": {""TrainingInputMode"": ""File"", ""TrainingImage"": training_image},\n        ""HyperParameters"": {\n            ""sagemaker_submit_directory"": \'""s3://some/sourcedir.tar.gz""\',\n            ""checkpoint_path"": \'""s3://other/1508872349""\',\n            ""sagemaker_program"": \'""iris-dnn-classifier.py""\',\n            ""sagemaker_enable_cloudwatch_metrics"": ""false"",\n            ""sagemaker_container_log_level"": \'""logging.INFO""\',\n            ""sagemaker_job_name"": \'""neo""\',\n            ""training_steps"": ""100"",\n            ""evaluation_steps"": ""10"",\n        },\n        ""RoleArn"": ""arn:aws:iam::366:role/SageMakerRole"",\n        ""ResourceConfig"": {\n            ""VolumeSizeInGB"": 30,\n            ""InstanceCount"": 1,\n            ""InstanceType"": ""ml.c4.xlarge"",\n        },\n        ""StoppingCondition"": {""MaxRuntimeInSeconds"": 24 * 60 * 60},\n        ""TrainingJobName"": ""neo"",\n        ""TrainingJobStatus"": ""Completed"",\n        ""TrainingJobArn"": ""arn:aws:sagemaker:us-west-2:336:training-job/neo"",\n        ""OutputDataConfig"": {""KmsKeyId"": """", ""S3OutputPath"": ""s3://place/output/neo""},\n        ""TrainingJobOutput"": {""S3TrainingJobOutput"": ""s3://here/output.tar.gz""},\n    }\n    sagemaker_session.sagemaker_client.describe_training_job = Mock(\n        name=""describe_training_job"", return_value=rjd\n    )\n\n    estimator = TensorFlow.attach(training_job_name=""neo"", sagemaker_session=sagemaker_session)\n    assert estimator.latest_training_job.job_name == ""neo""\n    assert estimator.py_version == ""py2""\n    assert estimator.framework_version == tf_version\n    assert estimator.role == ""arn:aws:iam::366:role/SageMakerRole""\n    assert estimator.train_instance_count == 1\n    assert estimator.train_max_run == 24 * 60 * 60\n    assert estimator.input_mode == ""File""\n    assert estimator.training_steps == 100\n    assert estimator.evaluation_steps == 10\n    assert estimator.input_mode == ""File""\n    assert estimator.base_job_name == ""neo""\n    assert estimator.output_path == ""s3://place/output/neo""\n    assert estimator.output_kms_key == """"\n    assert estimator.hyperparameters()[""training_steps""] == ""100""\n    assert estimator.source_dir == ""s3://some/sourcedir.tar.gz""\n    assert estimator.entry_point == ""iris-dnn-classifier.py""\n    assert estimator.checkpoint_path == ""s3://other/1508872349""\n\n\n@patch(""sagemaker.utils.create_tar_file"", MagicMock())\ndef test_attach_new_repo_name(sagemaker_session, tf_version):\n    training_image = ""520713654638.dkr.ecr.us-west-2.amazonaws.com/sagemaker-tensorflow:{}-cpu-py2"".format(\n        tf_version\n    )\n    rjd = {\n        ""AlgorithmSpecification"": {""TrainingInputMode"": ""File"", ""TrainingImage"": training_image},\n        ""HyperParameters"": {\n            ""sagemaker_submit_directory"": \'""s3://some/sourcedir.tar.gz""\',\n            ""checkpoint_path"": \'""s3://other/1508872349""\',\n            ""sagemaker_program"": \'""iris-dnn-classifier.py""\',\n            ""sagemaker_enable_cloudwatch_metrics"": ""false"",\n            ""sagemaker_container_log_level"": \'""logging.INFO""\',\n            ""sagemaker_job_name"": \'""neo""\',\n            ""training_steps"": ""100"",\n            ""evaluation_steps"": ""10"",\n        },\n        ""RoleArn"": ""arn:aws:iam::366:role/SageMakerRole"",\n        ""ResourceConfig"": {\n            ""VolumeSizeInGB"": 30,\n            ""InstanceCount"": 1,\n            ""InstanceType"": ""ml.c4.xlarge"",\n        },\n        ""StoppingCondition"": {""MaxRuntimeInSeconds"": 24 * 60 * 60},\n        ""TrainingJobName"": ""neo"",\n        ""TrainingJobStatus"": ""Completed"",\n        ""TrainingJobArn"": ""arn:aws:sagemaker:us-west-2:336:training-job/neo"",\n        ""OutputDataConfig"": {""KmsKeyId"": """", ""S3OutputPath"": ""s3://place/output/neo""},\n        ""TrainingJobOutput"": {""S3TrainingJobOutput"": ""s3://here/output.tar.gz""},\n    }\n    sagemaker_session.sagemaker_client.describe_training_job = Mock(\n        name=""describe_training_job"", return_value=rjd\n    )\n\n    estimator = TensorFlow.attach(training_job_name=""neo"", sagemaker_session=sagemaker_session)\n    assert estimator.latest_training_job.job_name == ""neo""\n    assert estimator.py_version == ""py2""\n    assert estimator.framework_version == tf_version\n    assert estimator.role == ""arn:aws:iam::366:role/SageMakerRole""\n    assert estimator.train_instance_count == 1\n    assert estimator.train_max_run == 24 * 60 * 60\n    assert estimator.input_mode == ""File""\n    assert estimator.training_steps == 100\n    assert estimator.evaluation_steps == 10\n    assert estimator.input_mode == ""File""\n    assert estimator.base_job_name == ""neo""\n    assert estimator.output_path == ""s3://place/output/neo""\n    assert estimator.output_kms_key == """"\n    assert estimator.hyperparameters()[""training_steps""] == ""100""\n    assert estimator.source_dir == ""s3://some/sourcedir.tar.gz""\n    assert estimator.entry_point == ""iris-dnn-classifier.py""\n    assert estimator.checkpoint_path == ""s3://other/1508872349""\n    assert estimator.train_image() == training_image\n\n\n@patch(""sagemaker.utils.create_tar_file"", MagicMock())\ndef test_attach_old_container(sagemaker_session):\n    training_image = ""1.dkr.ecr.us-west-2.amazonaws.com/sagemaker-tensorflow-py2-cpu:1.0""\n    rjd = {\n        ""AlgorithmSpecification"": {""TrainingInputMode"": ""File"", ""TrainingImage"": training_image},\n        ""HyperParameters"": {\n            ""sagemaker_submit_directory"": \'""s3://some/sourcedir.tar.gz""\',\n            ""checkpoint_path"": \'""s3://other/1508872349""\',\n            ""sagemaker_program"": \'""iris-dnn-classifier.py""\',\n            ""sagemaker_enable_cloudwatch_metrics"": ""false"",\n            ""sagemaker_container_log_level"": \'""logging.INFO""\',\n            ""sagemaker_job_name"": \'""neo""\',\n            ""training_steps"": ""100"",\n            ""evaluation_steps"": ""10"",\n        },\n        ""RoleArn"": ""arn:aws:iam::366:role/SageMakerRole"",\n        ""ResourceConfig"": {\n            ""VolumeSizeInGB"": 30,\n            ""InstanceCount"": 1,\n            ""InstanceType"": ""ml.c4.xlarge"",\n        },\n        ""StoppingCondition"": {""MaxRuntimeInSeconds"": 24 * 60 * 60},\n        ""TrainingJobName"": ""neo"",\n        ""TrainingJobStatus"": ""Completed"",\n        ""TrainingJobArn"": ""arn:aws:sagemaker:us-west-2:336:training-job/neo"",\n        ""OutputDataConfig"": {""KmsKeyId"": """", ""S3OutputPath"": ""s3://place/output/neo""},\n        ""TrainingJobOutput"": {""S3TrainingJobOutput"": ""s3://here/output.tar.gz""},\n    }\n    sagemaker_session.sagemaker_client.describe_training_job = Mock(\n        name=""describe_training_job"", return_value=rjd\n    )\n\n    estimator = TensorFlow.attach(training_job_name=""neo"", sagemaker_session=sagemaker_session)\n    assert estimator.latest_training_job.job_name == ""neo""\n    assert estimator.py_version == ""py2""\n    assert estimator.framework_version == ""1.4""\n    assert estimator.role == ""arn:aws:iam::366:role/SageMakerRole""\n    assert estimator.train_instance_count == 1\n    assert estimator.train_max_run == 24 * 60 * 60\n    assert estimator.input_mode == ""File""\n    assert estimator.training_steps == 100\n    assert estimator.evaluation_steps == 10\n    assert estimator.input_mode == ""File""\n    assert estimator.base_job_name == ""neo""\n    assert estimator.output_path == ""s3://place/output/neo""\n    assert estimator.output_kms_key == """"\n    assert estimator.hyperparameters()[""training_steps""] == ""100""\n    assert estimator.source_dir == ""s3://some/sourcedir.tar.gz""\n    assert estimator.entry_point == ""iris-dnn-classifier.py""\n    assert estimator.checkpoint_path == ""s3://other/1508872349""\n\n\ndef test_attach_wrong_framework(sagemaker_session):\n    returned_job_description = {\n        ""AlgorithmSpecification"": {\n            ""TrainingInputMode"": ""File"",\n            ""TrainingImage"": ""1.dkr.ecr.us-west-2.amazonaws.com/sagemaker-mxnet-py2-cpu:1.0"",\n        },\n        ""HyperParameters"": {\n            ""sagemaker_submit_directory"": \'""s3://some/sourcedir.tar.gz""\',\n            ""sagemaker_program"": \'""iris-dnn-classifier.py""\',\n            ""sagemaker_enable_cloudwatch_metrics"": ""false"",\n            ""sagemaker_container_log_level"": \'""logging.INFO""\',\n            ""training_steps"": ""100"",\n        },\n        ""RoleArn"": ""arn:aws:iam::366:role/SageMakerRole"",\n        ""ResourceConfig"": {\n            ""VolumeSizeInGB"": 30,\n            ""InstanceCount"": 1,\n            ""InstanceType"": ""ml.c4.xlarge"",\n        },\n        ""StoppingCondition"": {""MaxRuntimeInSeconds"": 24 * 60 * 60},\n        ""TrainingJobName"": ""neo"",\n        ""TrainingJobStatus"": ""Completed"",\n        ""TrainingJobArn"": ""arn:aws:sagemaker:us-west-2:336:training-job/neo"",\n        ""OutputDataConfig"": {""KmsKeyId"": """", ""S3OutputPath"": ""s3://place/output/neo""},\n        ""TrainingJobOutput"": {""S3TrainingJobOutput"": ""s3://here/output.tar.gz""},\n    }\n    sagemaker_session.sagemaker_client.describe_training_job = Mock(\n        name=""describe_training_job"", return_value=returned_job_description\n    )\n\n    with pytest.raises(ValueError) as error:\n        TensorFlow.attach(training_job_name=""neo"", sagemaker_session=sagemaker_session)\n    assert ""didn\'t use image for requested framework"" in str(error)\n\n\ndef test_attach_custom_image(sagemaker_session):\n    training_image = ""1.dkr.ecr.us-west-2.amazonaws.com/tensorflow_with_custom_binary:1.0""\n    rjd = {\n        ""AlgorithmSpecification"": {""TrainingInputMode"": ""File"", ""TrainingImage"": training_image},\n        ""HyperParameters"": {\n            ""sagemaker_submit_directory"": \'""s3://some/sourcedir.tar.gz""\',\n            ""checkpoint_path"": \'""s3://other/1508872349""\',\n            ""sagemaker_program"": \'""iris-dnn-classifier.py""\',\n            ""sagemaker_enable_cloudwatch_metrics"": ""false"",\n            ""sagemaker_container_log_level"": \'""logging.INFO""\',\n            ""sagemaker_job_name"": \'""neo""\',\n            ""training_steps"": ""100"",\n            ""evaluation_steps"": ""10"",\n        },\n        ""RoleArn"": ""arn:aws:iam::366:role/SageMakerRole"",\n        ""ResourceConfig"": {\n            ""VolumeSizeInGB"": 30,\n            ""InstanceCount"": 1,\n            ""InstanceType"": ""ml.c4.xlarge"",\n        },\n        ""StoppingCondition"": {""MaxRuntimeInSeconds"": 24 * 60 * 60},\n        ""TrainingJobName"": ""neo"",\n        ""TrainingJobStatus"": ""Completed"",\n        ""TrainingJobArn"": ""arn:aws:sagemaker:us-west-2:336:training-job/neo"",\n        ""OutputDataConfig"": {""KmsKeyId"": """", ""S3OutputPath"": ""s3://place/output/neo""},\n        ""TrainingJobOutput"": {""S3TrainingJobOutput"": ""s3://here/output.tar.gz""},\n    }\n    sagemaker_session.sagemaker_client.describe_training_job = Mock(\n        name=""describe_training_job"", return_value=rjd\n    )\n\n    estimator = TensorFlow.attach(training_job_name=""neo"", sagemaker_session=sagemaker_session)\n    assert estimator.image_name == training_image\n    assert estimator.train_image() == training_image\n\n\n@patch(""sagemaker.fw_utils.python_deprecation_warning"")\ndef test_estimator_py2_deprecation_warning(warning, sagemaker_session):\n    estimator = TensorFlow(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        py_version=""py2"",\n    )\n\n    assert estimator.py_version == ""py2""\n    warning.assert_called_with(estimator.__framework_name__, defaults.LATEST_PY2_VERSION)\n\n    model = TensorFlowModel(\n        MODEL_DATA,\n        role=ROLE,\n        entry_point=SCRIPT_PATH,\n        sagemaker_session=sagemaker_session,\n        py_version=""py2"",\n    )\n    assert model.py_version == ""py2""\n    warning.assert_called_with(model.__framework_name__, defaults.LATEST_PY2_VERSION)\n\n\n@patch(""sagemaker.fw_utils.empty_framework_version_warning"")\ndef test_empty_framework_version(warning, sagemaker_session):\n    estimator = TensorFlow(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        framework_version=None,\n    )\n\n    assert estimator.framework_version == defaults.TF_VERSION\n    warning.assert_called_with(defaults.TF_VERSION, estimator.LATEST_VERSION)\n\n    model = TensorFlowModel(\n        MODEL_DATA,\n        role=ROLE,\n        entry_point=SCRIPT_PATH,\n        sagemaker_session=sagemaker_session,\n        framework_version=None,\n    )\n\n    assert model.framework_version == defaults.TF_VERSION\n    warning.assert_called_with(defaults.TF_VERSION, defaults.LATEST_VERSION)\n\n\ndef _deprecated_args_msg(args):\n    return ""{} are deprecated in script mode. Please do not set {}."".format(\n        "", "".join(tfe._FRAMEWORK_MODE_ARGS), args\n    )\n\n\ndef test_script_mode_deprecated_args(sagemaker_session):\n    with pytest.raises(AttributeError) as e:\n        _build_tf(\n            sagemaker_session=sagemaker_session, py_version=""py3"", checkpoint_path=""some_path""\n        )\n    assert _deprecated_args_msg(""checkpoint_path"") in str(e.value)\n\n    with pytest.raises(AttributeError) as e:\n        _build_tf(sagemaker_session=sagemaker_session, py_version=""py3"", training_steps=1)\n    assert _deprecated_args_msg(""training_steps"") in str(e.value)\n\n    with pytest.raises(AttributeError) as e:\n        _build_tf(sagemaker_session=sagemaker_session, script_mode=True, evaluation_steps=1)\n    assert _deprecated_args_msg(""evaluation_steps"") in str(e.value)\n\n    with pytest.raises(AttributeError) as e:\n        _build_tf(\n            sagemaker_session=sagemaker_session, script_mode=True, requirements_file=""some_file""\n        )\n    assert _deprecated_args_msg(""requirements_file"") in str(e.value)\n\n    with pytest.raises(AttributeError) as e:\n        _build_tf(\n            sagemaker_session=sagemaker_session,\n            script_mode=True,\n            checkpoint_path=""some_path"",\n            requirements_file=""some_file"",\n            training_steps=1,\n            evaluation_steps=1,\n        )\n    assert _deprecated_args_msg(\n        ""training_steps, evaluation_steps, requirements_file, checkpoint_path""\n    ) in str(e.value)\n\n\ndef test_py2_version_deprecated(sagemaker_session):\n    with pytest.raises(AttributeError) as e:\n        TensorFlow(\n            entry_point=SCRIPT_PATH,\n            framework_version=""2.1.1"",\n            role=ROLE,\n            sagemaker_session=sagemaker_session,\n            train_instance_count=INSTANCE_COUNT,\n            train_instance_type=INSTANCE_TYPE,\n            py_version=""py2"",\n        )\n\n    msg = (\n        ""Python 2 containers are only available with 2.1.0 and lower versions. ""\n        ""Please use a Python 3 container.""\n    )\n    assert msg in str(e.value)\n\n\ndef test_py2_version_is_not_deprecated(sagemaker_session):\n    estimator = _build_tf(\n        sagemaker_session=sagemaker_session, framework_version=""1.15.0"", py_version=""py2""\n    )\n    assert estimator.py_version == ""py2""\n    estimator = _build_tf(\n        sagemaker_session=sagemaker_session, framework_version=""2.0.0"", py_version=""py2""\n    )\n    assert estimator.py_version == ""py2""\n\n\ndef test_py3_is_default_version_before_tf1_14(sagemaker_session):\n    estimator = _build_tf(sagemaker_session=sagemaker_session, framework_version=""1.13"")\n\n    assert estimator.py_version == ""py2""\n\n    estimator = _build_tf(sagemaker_session=sagemaker_session, framework_version=""1.10"")\n\n    assert estimator.py_version == ""py2""\n\n\ndef test_legacy_mode_deprecated(sagemaker_session):\n    tf = _build_tf(\n        sagemaker_session=sagemaker_session,\n        framework_version=""1.13.1"",\n        py_version=""py2"",\n        script_mode=False,\n    )\n    assert tf._script_mode_enabled() is True\n\n    tf = _build_tf(\n        sagemaker_session=sagemaker_session,\n        framework_version=""1.12"",\n        py_version=""py2"",\n        script_mode=False,\n    )\n    assert tf._script_mode_enabled() is False\n\n\ndef test_script_mode_enabled(sagemaker_session):\n    tf = _build_tf(sagemaker_session=sagemaker_session, py_version=""py3"")\n    assert tf._script_mode_enabled() is True\n\n    tf = _build_tf(sagemaker_session=sagemaker_session, script_mode=True)\n    assert tf._script_mode_enabled() is True\n\n    tf = _build_tf(sagemaker_session=sagemaker_session)\n    assert tf._script_mode_enabled() is False\n\n\ndef test_script_mode_create_model(sagemaker_session):\n    tf = _build_tf(\n        sagemaker_session=sagemaker_session, py_version=""py3"", enable_network_isolation=True\n    )\n    tf._prepare_for_training()  # set output_path and job name as if training happened\n\n    model = tf.create_model()\n\n    assert isinstance(model, serving.Model)\n\n    assert model.model_data == tf.model_data\n    assert model.role == tf.role\n    assert model.name == tf._current_job_name\n    assert model.container_log_level == tf.container_log_level\n    assert model._framework_version == ""1.11""\n    assert model.sagemaker_session == sagemaker_session\n    assert model.enable_network_isolation()\n\n\n@patch(""sagemaker.utils.create_tar_file"", MagicMock())\n@patch(""sagemaker.tensorflow.estimator.Tensorboard._sync_directories"")\n@patch(""sagemaker.tensorflow.estimator.Tensorboard.start"")\n@patch(""os.access"", return_value=True)\n@patch(""subprocess.call"")\n@patch(""subprocess.Popen"")\n@patch(""time.strftime"", return_value=TIMESTAMP)\n@patch(""time.time"", return_value=TIME)\n@patch(""time.sleep"")\ndef test_script_mode_tensorboard(\n    sleep, time, strftime, popen, call, access, start, sync, sagemaker_session\n):\n    tf = TensorFlow(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        framework_version=""1.0"",\n        script_mode=True,\n    )\n    popen().poll.return_value = None\n    tf.fit(inputs=""s3://mybucket/train"", run_tensorboard_locally=True)\n    start.assert_not_called()\n\n\n@patch(""time.strftime"", return_value=TIMESTAMP)\n@patch(""time.time"", return_value=TIME)\n@patch(""sagemaker.utils.create_tar_file"", MagicMock())\ndef test_tf_script_mode(time, strftime, sagemaker_session):\n    tf = TensorFlow(\n        entry_point=SCRIPT_FILE,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        py_version=""py3"",\n        train_instance_type=INSTANCE_TYPE,\n        train_instance_count=1,\n        framework_version=""1.11"",\n        source_dir=DATA_DIR,\n    )\n\n    inputs = ""s3://mybucket/train""\n    tf.fit(inputs=inputs)\n\n    call_names = [c[0] for c in sagemaker_session.method_calls]\n    assert call_names == [""train"", ""logs_for_job""]\n\n    expected_train_args = _create_train_job(\n        ""1.11"", script_mode=True, repo_name=SM_IMAGE_REPO_NAME, py_version=""py3""\n    )\n    expected_train_args[""input_config""][0][""DataSource""][""S3DataSource""][""S3Uri""] = inputs\n\n    actual_train_args = sagemaker_session.method_calls[0][2]\n    assert actual_train_args == expected_train_args\n\n\n@patch(""time.strftime"", return_value=TIMESTAMP)\n@patch(""time.time"", return_value=TIME)\n@patch(""sagemaker.utils.create_tar_file"", MagicMock())\ndef test_tf_script_mode_ps(time, strftime, sagemaker_session):\n    tf = TensorFlow(\n        entry_point=SCRIPT_FILE,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        py_version=""py3"",\n        train_instance_type=INSTANCE_TYPE,\n        train_instance_count=1,\n        framework_version=""1.11"",\n        source_dir=DATA_DIR,\n        distributions=DISTRIBUTION_ENABLED,\n    )\n\n    inputs = ""s3://mybucket/train""\n    tf.fit(inputs=inputs)\n\n    call_names = [c[0] for c in sagemaker_session.method_calls]\n    assert call_names == [""train"", ""logs_for_job""]\n\n    expected_train_args = _create_train_job(\n        ""1.11"", script_mode=True, ps=True, repo_name=SM_IMAGE_REPO_NAME, py_version=""py3""\n    )\n    expected_train_args[""input_config""][0][""DataSource""][""S3DataSource""][""S3Uri""] = inputs\n    expected_train_args[""hyperparameters""][TensorFlow.LAUNCH_PS_ENV_NAME] = json.dumps(True)\n\n    actual_train_args = sagemaker_session.method_calls[0][2]\n    assert actual_train_args == expected_train_args\n\n\n@patch(""time.strftime"", return_value=TIMESTAMP)\n@patch(""time.time"", return_value=TIME)\n@patch(""sagemaker.utils.create_tar_file"", MagicMock())\ndef test_tf_script_mode_mpi(time, strftime, sagemaker_session):\n    tf = TensorFlow(\n        entry_point=SCRIPT_FILE,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        py_version=""py3"",\n        train_instance_type=INSTANCE_TYPE,\n        train_instance_count=1,\n        framework_version=""1.11"",\n        source_dir=DATA_DIR,\n        distributions=DISTRIBUTION_MPI_ENABLED,\n    )\n\n    inputs = ""s3://mybucket/train""\n    tf.fit(inputs=inputs)\n\n    call_names = [c[0] for c in sagemaker_session.method_calls]\n    assert call_names == [""train"", ""logs_for_job""]\n\n    expected_train_args = _create_train_job(\n        ""1.11"", script_mode=True, horovod=True, repo_name=SM_IMAGE_REPO_NAME, py_version=""py3""\n    )\n    expected_train_args[""input_config""][0][""DataSource""][""S3DataSource""][""S3Uri""] = inputs\n    expected_train_args[""hyperparameters""][TensorFlow.LAUNCH_MPI_ENV_NAME] = json.dumps(True)\n    expected_train_args[""hyperparameters""][TensorFlow.MPI_NUM_PROCESSES_PER_HOST] = json.dumps(2)\n    expected_train_args[""hyperparameters""][TensorFlow.MPI_CUSTOM_MPI_OPTIONS] = json.dumps(\n        ""options""\n    )\n\n    actual_train_args = sagemaker_session.method_calls[0][2]\n    assert actual_train_args == expected_train_args\n\n\n@patch(""sagemaker.utils.create_tar_file"", MagicMock())\ndef test_tf_script_mode_attach(sagemaker_session, tf_version):\n    training_image = ""1.dkr.ecr.us-west-2.amazonaws.com/sagemaker-tensorflow-py3-cpu:{}-cpu-py3"".format(\n        tf_version\n    )\n    rjd = {\n        ""AlgorithmSpecification"": {""TrainingInputMode"": ""File"", ""TrainingImage"": training_image},\n        ""HyperParameters"": {\n            ""sagemaker_submit_directory"": \'""s3://some/sourcedir.tar.gz""\',\n            ""sagemaker_program"": \'""iris-dnn-classifier.py""\',\n            ""sagemaker_enable_cloudwatch_metrics"": ""false"",\n            ""sagemaker_container_log_level"": \'""logging.INFO""\',\n            ""sagemaker_job_name"": \'""neo""\',\n        },\n        ""RoleArn"": ""arn:aws:iam::366:role/SageMakerRole"",\n        ""ResourceConfig"": {\n            ""VolumeSizeInGB"": 30,\n            ""InstanceCount"": 1,\n            ""InstanceType"": ""ml.c4.xlarge"",\n        },\n        ""StoppingCondition"": {""MaxRuntimeInSeconds"": 24 * 60 * 60},\n        ""TrainingJobName"": ""neo"",\n        ""TrainingJobStatus"": ""Completed"",\n        ""TrainingJobArn"": ""arn:aws:sagemaker:us-west-2:336:training-job/neo"",\n        ""OutputDataConfig"": {""KmsKeyId"": """", ""S3OutputPath"": ""s3://place/output/neo""},\n        ""TrainingJobOutput"": {""S3TrainingJobOutput"": ""s3://here/output.tar.gz""},\n    }\n    sagemaker_session.sagemaker_client.describe_training_job = Mock(\n        name=""describe_training_job"", return_value=rjd\n    )\n\n    estimator = TensorFlow.attach(training_job_name=""neo"", sagemaker_session=sagemaker_session)\n    assert estimator.latest_training_job.job_name == ""neo""\n    assert estimator.py_version == ""py3""\n    assert estimator.framework_version == tf_version\n    assert estimator.role == ""arn:aws:iam::366:role/SageMakerRole""\n    assert estimator.train_instance_count == 1\n    assert estimator.train_max_run == 24 * 60 * 60\n    assert estimator.input_mode == ""File""\n    assert estimator.input_mode == ""File""\n    assert estimator.base_job_name == ""neo""\n    assert estimator.output_path == ""s3://place/output/neo""\n    assert estimator.output_kms_key == """"\n    assert estimator.hyperparameters() is not None\n    assert estimator.source_dir == ""s3://some/sourcedir.tar.gz""\n    assert estimator.entry_point == ""iris-dnn-classifier.py""\n\n\n@patch(""sagemaker.utils.create_tar_file"", MagicMock())\ndef test_tf_enable_sm_metrics(sagemaker_session):\n    tf = _build_tf(sagemaker_session, enable_sagemaker_metrics=True)\n    assert tf.enable_sagemaker_metrics\n\n\n@patch(""sagemaker.utils.create_tar_file"", MagicMock())\ndef test_tf_disable_sm_metrics(sagemaker_session):\n    tf = _build_tf(sagemaker_session, enable_sagemaker_metrics=False)\n    assert not tf.enable_sagemaker_metrics\n\n\n@patch(""sagemaker.utils.create_tar_file"", MagicMock())\ndef test_tf_disable_sm_metrics_if_fw_ver_is_less_than_1_15(sagemaker_session):\n    for fw_version in [""1.11"", ""1.12"", ""1.13"", ""1.14""]:\n        tf = _build_tf(sagemaker_session, framework_version=fw_version)\n        assert tf.enable_sagemaker_metrics is None\n\n\n@patch(""sagemaker.utils.create_tar_file"", MagicMock())\ndef test_tf_enable_sm_metrics_if_fw_ver_is_at_least_1_15(sagemaker_session):\n    for fw_version in [""1.15"", ""1.16"", ""2.0"", ""2.1""]:\n        tf = _build_tf(sagemaker_session, framework_version=fw_version)\n        assert tf.enable_sagemaker_metrics\n\n\ndef test_custom_image_estimator_deploy(sagemaker_session):\n    custom_image = ""mycustomimage:latest""\n    tf = _build_tf(sagemaker_session)\n    tf.fit(inputs=""s3://mybucket/train"", job_name=""new_name"")\n    model = tf.create_model(image=custom_image)\n    assert model.image == custom_image\n'"
tests/unit/test_tf_predictor.py,4,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport io\nimport json\nimport sys\n\nfrom google.protobuf import json_format\nimport numpy as np\nimport pytest\nfrom mock import Mock\nimport tensorflow as tf\nimport six\nfrom six import BytesIO\nfrom tensorflow.python.saved_model.signature_constants import (\n    DEFAULT_SERVING_SIGNATURE_DEF_KEY,\n    PREDICT_INPUTS,\n)\n\nfrom sagemaker.predictor import RealTimePredictor\nfrom sagemaker.tensorflow.predictor import (\n    tf_csv_serializer,\n    tf_deserializer,\n    tf_json_deserializer,\n    tf_json_serializer,\n    tf_serializer,\n)\nfrom sagemaker.tensorflow.tensorflow_serving.apis import classification_pb2\n\nBUCKET_NAME = ""mybucket""\nENDPOINT = ""myendpoint""\nREGION = ""us-west-2""\n\nCLASSIFICATION_RESPONSE = {\n    ""result"": {\n        ""classifications"": [\n            {\n                ""classes"": [\n                    {""label"": ""0"", ""score"": 0.0012890376383438706},\n                    {""label"": ""1"", ""score"": 0.9814321994781494},\n                    {""label"": ""2"", ""score"": 0.017278732731938362},\n                ]\n            }\n        ]\n    }\n}\n\nCSV_CONTENT_TYPE = ""text/csv""\nJSON_CONTENT_TYPE = ""application/json""\nPROTO_CONTENT_TYPE = ""application/octet-stream""\n\nENDPOINT_DESC = {""EndpointConfigName"": ENDPOINT}\n\nENDPOINT_CONFIG_DESC = {""ProductionVariants"": [{""ModelName"": ""model-1""}, {""ModelName"": ""model-2""}]}\n\n\n@pytest.fixture()\ndef sagemaker_session():\n    boto_mock = Mock(name=""boto_session"", region_name=REGION)\n    ims = Mock(name=""sagemaker_session"", boto_session=boto_mock)\n    ims.default_bucket = Mock(name=""default_bucket"", return_value=BUCKET_NAME)\n    ims.sagemaker_client.describe_endpoint = Mock(return_value=ENDPOINT_DESC)\n    ims.sagemaker_client.describe_endpoint_config = Mock(return_value=ENDPOINT_CONFIG_DESC)\n    return ims\n\n\ndef test_endpoint_initialization(sagemaker_session):\n    endpoint_name = ""endpoint""\n    predictor = RealTimePredictor(endpoint=endpoint_name, sagemaker_session=sagemaker_session)\n    assert predictor.endpoint == endpoint_name\n\n\ndef test_classification_request_json(sagemaker_session):\n    data = [1, 2, 3]\n    predictor = RealTimePredictor(\n        endpoint=ENDPOINT,\n        sagemaker_session=sagemaker_session,\n        deserializer=tf_json_deserializer,\n        serializer=tf_json_serializer,\n    )\n\n    mock_response(\n        json.dumps(CLASSIFICATION_RESPONSE).encode(""utf-8""), sagemaker_session, JSON_CONTENT_TYPE\n    )\n\n    result = predictor.predict(data)\n\n    sagemaker_session.sagemaker_runtime_client.invoke_endpoint.assert_called_once_with(\n        Accept=JSON_CONTENT_TYPE,\n        Body=""[1, 2, 3]"",\n        ContentType=JSON_CONTENT_TYPE,\n        EndpointName=""myendpoint"",\n    )\n\n    assert result == CLASSIFICATION_RESPONSE\n\n\ndef test_classification_request_csv(sagemaker_session):\n    data = [1, 2, 3]\n    predictor = RealTimePredictor(\n        serializer=tf_csv_serializer,\n        deserializer=tf_deserializer,\n        sagemaker_session=sagemaker_session,\n        endpoint=ENDPOINT,\n    )\n\n    expected_response = json_format.Parse(\n        json.dumps(CLASSIFICATION_RESPONSE), classification_pb2.ClassificationResponse()\n    ).SerializeToString()\n\n    mock_response(expected_response, sagemaker_session, PROTO_CONTENT_TYPE)\n\n    result = predictor.predict(data)\n\n    sagemaker_session.sagemaker_runtime_client.invoke_endpoint.assert_called_once_with(\n        Accept=PROTO_CONTENT_TYPE,\n        Body=""1,2,3"",\n        ContentType=CSV_CONTENT_TYPE,\n        EndpointName=""myendpoint"",\n    )\n\n    # python 2 and 3 protobuf serialization has different precision so I\'m checking\n    # the version here\n    if sys.version_info < (3, 0):\n        assert (\n            str(result)\n            == """"""result {\n  classifications {\n    classes {\n      label: ""0""\n      score: 0.00128903763834\n    }\n    classes {\n      label: ""1""\n      score: 0.981432199478\n    }\n    classes {\n      label: ""2""\n      score: 0.0172787327319\n    }\n  }\n}\n""""""\n        )\n    else:\n        assert (\n            str(result)\n            == """"""result {\n  classifications {\n    classes {\n      label: ""0""\n      score: 0.0012890376383438706\n    }\n    classes {\n      label: ""1""\n      score: 0.9814321994781494\n    }\n    classes {\n      label: ""2""\n      score: 0.017278732731938362\n    }\n  }\n}\n""""""\n        )\n\n\ndef test_json_deserializer_should_work_with_predict_response():\n    data = b""""""{\n""outputs"": {\n    ""example_strings"": {\n      ""dtype"": ""DT_STRING"",\n      ""tensorShape"": {\n        ""dim"": [\n          {\n            ""size"": ""3""\n          }\n        ]\n      },\n      ""stringVal"": [\n        ""YXBwbGU="",\n        ""YmFuYW5h"",\n        ""b3Jhbmdl""\n      ]\n    },\n    ""ages"": {\n      ""dtype"": ""DT_FLOAT"",\n      ""floatVal"": [\n        4.954165935516357\n      ],\n      ""tensorShape"": {\n        ""dim"": [\n          {\n            ""size"": ""1""\n          }\n        ]\n      }\n    }\n  },\n  ""modelSpec"": {\n    ""version"": ""1531758457"",\n    ""name"": ""generic_model"",\n    ""signatureName"": ""serving_default""\n  }\n}""""""\n\n    stream = BytesIO(data)\n\n    response = tf_json_deserializer(stream, ""application/json"")\n\n    if six.PY2:\n        string_vals = [""apple"", ""banana"", ""orange""]\n    else:\n        string_vals = [b""apple"", b""banana"", b""orange""]\n\n    assert response == {\n        ""model_spec"": {\n            ""name"": u""generic_model"",\n            ""signature_name"": u""serving_default"",\n            ""version"": {""value"": 1531758457.0 if six.PY2 else 1531758457},\n        },\n        ""outputs"": {\n            u""ages"": {\n                ""dtype"": 1,\n                ""float_val"": [4.954165935516357],\n                ""tensor_shape"": {""dim"": [{""size"": 1.0 if six.PY2 else 1}]},\n            },\n            u""example_strings"": {\n                ""dtype"": 7,\n                ""string_val"": string_vals,\n                ""tensor_shape"": {""dim"": [{""size"": 3.0 if six.PY2 else 3}]},\n            },\n        },\n    }\n\n\ndef test_classification_request_pb(sagemaker_session):\n    request = classification_pb2.ClassificationRequest()\n    request.model_spec.name = ""generic_model""\n    request.model_spec.signature_name = DEFAULT_SERVING_SIGNATURE_DEF_KEY\n    example = request.input.example_list.examples.add()\n    example.features.feature[PREDICT_INPUTS].float_list.value.extend([6.4, 3.2, 4.5, 1.5])\n\n    predictor = RealTimePredictor(\n        sagemaker_session=sagemaker_session,\n        endpoint=ENDPOINT,\n        deserializer=tf_deserializer,\n        serializer=tf_serializer,\n    )\n\n    expected_response = classification_pb2.ClassificationResponse()\n    classes = expected_response.result.classifications.add().classes\n\n    class_0 = classes.add()\n    class_0.label = ""0""\n    class_0.score = 0.00128903763834\n\n    class_1 = classes.add()\n    class_1.label = ""1""\n    class_1.score = 0.981432199478\n\n    class_2 = classes.add()\n    class_2.label = ""2""\n    class_2.score = 0.0172787327319\n\n    mock_response(expected_response.SerializeToString(), sagemaker_session, PROTO_CONTENT_TYPE)\n\n    result = predictor.predict(request)\n\n    sagemaker_session.sagemaker_runtime_client.invoke_endpoint.assert_called_once_with(\n        Accept=PROTO_CONTENT_TYPE,\n        Body=request.SerializeToString(),\n        ContentType=PROTO_CONTENT_TYPE,\n        EndpointName=""myendpoint"",\n    )\n\n    # python 2 and 3 protobuf serialization has different precision so I\'m checking\n    # the version here\n    if sys.version_info < (3, 0):\n        assert (\n            str(result)\n            == """"""result {\n  classifications {\n    classes {\n      label: ""0""\n      score: 0.00128903763834\n    }\n    classes {\n      label: ""1""\n      score: 0.981432199478\n    }\n    classes {\n      label: ""2""\n      score: 0.0172787327319\n    }\n  }\n}\n""""""\n        )\n    else:\n        assert (\n            str(result)\n            == """"""result {\n  classifications {\n    classes {\n      label: ""0""\n      score: 0.0012890376383438706\n    }\n    classes {\n      label: ""1""\n      score: 0.9814321994781494\n    }\n    classes {\n      label: ""2""\n      score: 0.017278732731938362\n    }\n  }\n}\n""""""\n        )\n\n\ndef test_predict_request_json(sagemaker_session):\n    data = [6.4, 3.2, 0.5, 1.5]\n    tensor_proto = tf.make_tensor_proto(\n        values=np.asarray(data), shape=[1, len(data)], dtype=tf.float32\n    )\n    predictor = RealTimePredictor(\n        sagemaker_session=sagemaker_session,\n        endpoint=ENDPOINT,\n        deserializer=tf_json_deserializer,\n        serializer=tf_json_serializer,\n    )\n\n    mock_response(\n        json.dumps(CLASSIFICATION_RESPONSE).encode(""utf-8""), sagemaker_session, JSON_CONTENT_TYPE\n    )\n\n    result = predictor.predict(tensor_proto)\n\n    sagemaker_session.sagemaker_runtime_client.invoke_endpoint.assert_called_once_with(\n        Accept=JSON_CONTENT_TYPE,\n        Body=json_format.MessageToJson(tensor_proto),\n        ContentType=JSON_CONTENT_TYPE,\n        EndpointName=""myendpoint"",\n    )\n\n    assert result == CLASSIFICATION_RESPONSE\n\n\ndef test_predict_tensor_request_csv(sagemaker_session):\n    data = [6.4, 3.2, 0.5, 1.5]\n    tensor_proto = tf.make_tensor_proto(\n        values=np.asarray(data), shape=[1, len(data)], dtype=tf.float32\n    )\n    predictor = RealTimePredictor(\n        serializer=tf_csv_serializer,\n        deserializer=tf_json_deserializer,\n        sagemaker_session=sagemaker_session,\n        endpoint=ENDPOINT,\n    )\n\n    mock_response(\n        json.dumps(CLASSIFICATION_RESPONSE).encode(""utf-8""), sagemaker_session, JSON_CONTENT_TYPE\n    )\n\n    result = predictor.predict(tensor_proto)\n\n    sagemaker_session.sagemaker_runtime_client.invoke_endpoint.assert_called_once_with(\n        Accept=JSON_CONTENT_TYPE,\n        Body=""6.4,3.2,0.5,1.5"",\n        ContentType=CSV_CONTENT_TYPE,\n        EndpointName=""myendpoint"",\n    )\n\n    assert result == CLASSIFICATION_RESPONSE\n\n\ndef mock_response(expected_response, sagemaker_session, content_type):\n    sagemaker_session.sagemaker_runtime_client.invoke_endpoint.return_value = {\n        ""ContentType"": content_type,\n        ""Body"": io.BytesIO(expected_response),\n    }\n\n\ndef test_json_serialize_dict():\n    data = {""tensor1"": [1, 2, 3], ""tensor2"": [4, 5, 6]}\n    serialized = tf_json_serializer(data)\n    # deserialize again for assertion, since dict order is not guaranteed\n    deserialized = json.loads(serialized)\n    assert deserialized == data\n\n\ndef test_json_serialize_dict_with_numpy():\n    data = {""tensor1"": np.asarray([1, 2, 3]), ""tensor2"": np.asarray([4, 5, 6])}\n    serialized = tf_json_serializer(data)\n    # deserialize again for assertion, since dict order is not guaranteed\n    deserialized = json.loads(serialized)\n    assert deserialized == {""tensor1"": [1, 2, 3], ""tensor2"": [4, 5, 6]}\n\n\ndef test_json_serialize_numpy():\n    data = np.asarray([[1, 2, 3], [4, 5, 6]])\n    assert tf_json_serializer(data) == ""[[1, 2, 3], [4, 5, 6]]""\n'"
tests/unit/test_tfs.py,2,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport io\nimport json\nimport logging\n\nimport mock\nimport pytest\nfrom mock import Mock\nfrom sagemaker.tensorflow import TensorFlow\nfrom sagemaker.tensorflow.predictor import csv_serializer\nfrom sagemaker.tensorflow.serving import Model, Predictor\n\nJSON_CONTENT_TYPE = ""application/json""\nCSV_CONTENT_TYPE = ""text/csv""\nINSTANCE_COUNT = 1\nINSTANCE_TYPE = ""ml.c4.4xlarge""\nACCELERATOR_TYPE = ""ml.eia1.medium""\nROLE = ""Dummy""\nREGION = ""us-west-2""\nPREDICT_INPUT = {""instances"": [1.0, 2.0, 5.0]}\nPREDICT_RESPONSE = {""predictions"": [[3.5, 4.0, 5.5], [3.5, 4.0, 5.5]]}\nCLASSIFY_INPUT = {\n    ""signature_name"": ""tensorflow/serving/classify"",\n    ""examples"": [{""x"": 1.0}, {""x"": 2.0}],\n}\nCLASSIFY_RESPONSE = {""result"": [[0.4, 0.6], [0.2, 0.8]]}\nREGRESS_INPUT = {\n    ""signature_name"": ""tensorflow/serving/regress"",\n    ""examples"": [{""x"": 1.0}, {""x"": 2.0}],\n}\nREGRESS_RESPONSE = {""results"": [3.5, 4.0]}\n\nENDPOINT_DESC = {""EndpointConfigName"": ""test-endpoint""}\n\nENDPOINT_CONFIG_DESC = {""ProductionVariants"": [{""ModelName"": ""model-1""}, {""ModelName"": ""model-2""}]}\n\n\n@pytest.fixture()\ndef sagemaker_session():\n    boto_mock = Mock(name=""boto_session"", region_name=REGION)\n    session = Mock(\n        name=""sagemaker_session"",\n        boto_session=boto_mock,\n        boto_region_name=REGION,\n        config=None,\n        local_mode=False,\n        s3_resource=None,\n        s3_client=None,\n    )\n    session.default_bucket = Mock(name=""default_bucket"", return_value=""my_bucket"")\n    session.expand_role = Mock(name=""expand_role"", return_value=ROLE)\n    describe = {""ModelArtifacts"": {""S3ModelArtifacts"": ""s3://m/m.tar.gz""}}\n    session.sagemaker_client.describe_training_job = Mock(return_value=describe)\n    session.sagemaker_client.describe_endpoint = Mock(return_value=ENDPOINT_DESC)\n    session.sagemaker_client.describe_endpoint_config = Mock(return_value=ENDPOINT_CONFIG_DESC)\n    return session\n\n\ndef test_tfs_model(sagemaker_session, tf_version):\n    model = Model(\n        ""s3://some/data.tar.gz"",\n        role=ROLE,\n        framework_version=tf_version,\n        sagemaker_session=sagemaker_session,\n    )\n    cdef = model.prepare_container_def(INSTANCE_TYPE)\n    assert cdef[""Image""].endswith(""sagemaker-tensorflow-serving:{}-cpu"".format(tf_version))\n    assert cdef[""Environment""] == {}\n\n    predictor = model.deploy(INSTANCE_COUNT, INSTANCE_TYPE)\n    assert isinstance(predictor, Predictor)\n\n\ndef test_tfs_model_image_accelerator(sagemaker_session, tf_version):\n    model = Model(\n        ""s3://some/data.tar.gz"",\n        role=ROLE,\n        framework_version=tf_version,\n        sagemaker_session=sagemaker_session,\n    )\n    cdef = model.prepare_container_def(INSTANCE_TYPE, accelerator_type=ACCELERATOR_TYPE)\n    assert cdef[""Image""].endswith(""sagemaker-tensorflow-serving-eia:{}-cpu"".format(tf_version))\n\n    predictor = model.deploy(INSTANCE_COUNT, INSTANCE_TYPE)\n    assert isinstance(predictor, Predictor)\n\n\ndef test_tfs_model_image_accelerator_not_supported(sagemaker_session):\n    model = Model(\n        ""s3://some/data.tar.gz"",\n        role=ROLE,\n        framework_version=""1.13.1"",\n        sagemaker_session=sagemaker_session,\n    )\n\n    # assert error is not raised\n\n    model.deploy(\n        instance_type=""ml.c4.xlarge"", initial_instance_count=1, accelerator_type=""ml.eia1.medium""\n    )\n\n    model = Model(\n        ""s3://some/data.tar.gz"",\n        role=ROLE,\n        framework_version=""2.1"",\n        sagemaker_session=sagemaker_session,\n    )\n\n    # assert error is not raised\n\n    model.deploy(instance_type=""ml.c4.xlarge"", initial_instance_count=1)\n\n    with pytest.raises(AttributeError) as e:\n        model.deploy(\n            instance_type=""ml.c4.xlarge"",\n            accelerator_type=""ml.eia1.medium"",\n            initial_instance_count=1,\n        )\n\n    assert str(e.value) == ""The TensorFlow version 2.1 doesn\'t support EIA.""\n\n\ndef test_tfs_model_with_log_level(sagemaker_session, tf_version):\n    model = Model(\n        ""s3://some/data.tar.gz"",\n        role=ROLE,\n        framework_version=tf_version,\n        container_log_level=logging.INFO,\n        sagemaker_session=sagemaker_session,\n    )\n    cdef = model.prepare_container_def(INSTANCE_TYPE)\n    assert cdef[""Environment""] == {Model.LOG_LEVEL_PARAM_NAME: ""info""}\n\n\ndef test_tfs_model_with_custom_image(sagemaker_session, tf_version):\n    model = Model(\n        ""s3://some/data.tar.gz"",\n        role=ROLE,\n        framework_version=tf_version,\n        image=""my-image"",\n        sagemaker_session=sagemaker_session,\n    )\n    cdef = model.prepare_container_def(INSTANCE_TYPE)\n    assert cdef[""Image""] == ""my-image""\n\n\n@mock.patch(""sagemaker.fw_utils.model_code_key_prefix"", return_value=""key-prefix"")\n@mock.patch(""sagemaker.utils.repack_model"")\ndef test_tfs_model_with_entry_point(\n    repack_model, model_code_key_prefix, sagemaker_session, tf_version\n):\n    model = Model(\n        ""s3://some/data.tar.gz"",\n        entry_point=""train.py"",\n        role=ROLE,\n        framework_version=tf_version,\n        image=""my-image"",\n        sagemaker_session=sagemaker_session,\n        model_kms_key=""kms-key"",\n    )\n\n    model.prepare_container_def(INSTANCE_TYPE)\n\n    model_code_key_prefix.assert_called_with(model.key_prefix, model.name, model.image)\n\n    repack_model.assert_called_with(\n        ""train.py"",\n        None,\n        [],\n        ""s3://some/data.tar.gz"",\n        ""s3://my_bucket/key-prefix/model.tar.gz"",\n        sagemaker_session,\n        kms_key=""kms-key"",\n    )\n\n\n@mock.patch(""sagemaker.fw_utils.model_code_key_prefix"", return_value=""key-prefix"")\n@mock.patch(""sagemaker.utils.repack_model"")\ndef test_tfs_model_with_source(repack_model, model_code_key_prefix, sagemaker_session, tf_version):\n    model = Model(\n        ""s3://some/data.tar.gz"",\n        entry_point=""train.py"",\n        source_dir=""src"",\n        role=ROLE,\n        framework_version=tf_version,\n        image=""my-image"",\n        sagemaker_session=sagemaker_session,\n    )\n\n    model.prepare_container_def(INSTANCE_TYPE)\n\n    model_code_key_prefix.assert_called_with(model.key_prefix, model.name, model.image)\n\n    repack_model.assert_called_with(\n        ""train.py"",\n        ""src"",\n        [],\n        ""s3://some/data.tar.gz"",\n        ""s3://my_bucket/key-prefix/model.tar.gz"",\n        sagemaker_session,\n        kms_key=None,\n    )\n\n\n@mock.patch(""sagemaker.fw_utils.model_code_key_prefix"", return_value=""key-prefix"")\n@mock.patch(""sagemaker.utils.repack_model"")\ndef test_tfs_model_with_dependencies(\n    repack_model, model_code_key_prefix, sagemaker_session, tf_version\n):\n    model = Model(\n        ""s3://some/data.tar.gz"",\n        entry_point=""train.py"",\n        dependencies=[""src"", ""lib""],\n        role=ROLE,\n        framework_version=tf_version,\n        image=""my-image"",\n        sagemaker_session=sagemaker_session,\n    )\n\n    model.prepare_container_def(INSTANCE_TYPE)\n\n    model_code_key_prefix.assert_called_with(model.key_prefix, model.name, model.image)\n\n    repack_model.assert_called_with(\n        ""train.py"",\n        None,\n        [""src"", ""lib""],\n        ""s3://some/data.tar.gz"",\n        ""s3://my_bucket/key-prefix/model.tar.gz"",\n        sagemaker_session,\n        kms_key=None,\n    )\n\n\ndef test_estimator_deploy(sagemaker_session):\n    container_log_level = \'""logging.INFO""\'\n    source_dir = ""s3://mybucket/source""\n    custom_image = ""custom:1.0""\n    tf = TensorFlow(\n        entry_point=""script.py"",\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        training_steps=1000,\n        evaluation_steps=10,\n        train_instance_count=INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        image_name=custom_image,\n        container_log_level=container_log_level,\n        base_job_name=""job"",\n        source_dir=source_dir,\n    )\n\n    job_name = ""doing something""\n    tf.fit(inputs=""s3://mybucket/train"", job_name=job_name)\n    predictor = tf.deploy(\n        INSTANCE_COUNT, INSTANCE_TYPE, endpoint_name=""endpoint"", endpoint_type=""tensorflow-serving""\n    )\n    assert isinstance(predictor, Predictor)\n\n\ndef test_predictor(sagemaker_session):\n    predictor = Predictor(""endpoint"", sagemaker_session)\n\n    mock_response(json.dumps(PREDICT_RESPONSE).encode(""utf-8""), sagemaker_session)\n    result = predictor.predict(PREDICT_INPUT)\n\n    assert_invoked(\n        sagemaker_session,\n        EndpointName=""endpoint"",\n        ContentType=JSON_CONTENT_TYPE,\n        Accept=JSON_CONTENT_TYPE,\n        Body=json.dumps(PREDICT_INPUT),\n    )\n\n    assert PREDICT_RESPONSE == result\n\n\ndef test_predictor_jsons(sagemaker_session):\n    predictor = Predictor(\n        ""endpoint"", sagemaker_session, serializer=None, content_type=""application/jsons""\n    )\n\n    mock_response(json.dumps(PREDICT_RESPONSE).encode(""utf-8""), sagemaker_session)\n    result = predictor.predict(""[1.0, 2.0, 3.0]\\n[4.0, 5.0, 6.0]"")\n\n    assert_invoked(\n        sagemaker_session,\n        EndpointName=""endpoint"",\n        ContentType=""application/jsons"",\n        Accept=JSON_CONTENT_TYPE,\n        Body=""[1.0, 2.0, 3.0]\\n[4.0, 5.0, 6.0]"",\n    )\n\n    assert PREDICT_RESPONSE == result\n\n\ndef test_predictor_csv(sagemaker_session):\n    predictor = Predictor(""endpoint"", sagemaker_session, serializer=csv_serializer)\n\n    mock_response(json.dumps(PREDICT_RESPONSE).encode(""utf-8""), sagemaker_session)\n    result = predictor.predict([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n\n    assert_invoked(\n        sagemaker_session,\n        EndpointName=""endpoint"",\n        ContentType=CSV_CONTENT_TYPE,\n        Accept=JSON_CONTENT_TYPE,\n        Body=""1.0,2.0,3.0\\n4.0,5.0,6.0"",\n    )\n\n    assert PREDICT_RESPONSE == result\n\n\ndef test_predictor_model_attributes(sagemaker_session):\n    predictor = Predictor(""endpoint"", sagemaker_session, model_name=""model"", model_version=""123"")\n\n    mock_response(json.dumps(PREDICT_RESPONSE).encode(""utf-8""), sagemaker_session)\n    result = predictor.predict(PREDICT_INPUT)\n\n    assert_invoked(\n        sagemaker_session,\n        EndpointName=""endpoint"",\n        ContentType=JSON_CONTENT_TYPE,\n        Accept=JSON_CONTENT_TYPE,\n        CustomAttributes=""tfs-model-name=model,tfs-model-version=123"",\n        Body=json.dumps(PREDICT_INPUT),\n    )\n\n    assert PREDICT_RESPONSE == result\n\n\ndef test_predictor_classify(sagemaker_session):\n    predictor = Predictor(""endpoint"", sagemaker_session)\n\n    mock_response(json.dumps(CLASSIFY_RESPONSE).encode(""utf-8""), sagemaker_session)\n    result = predictor.classify(CLASSIFY_INPUT)\n\n    assert_invoked_with_body_dict(\n        sagemaker_session,\n        EndpointName=""endpoint"",\n        ContentType=JSON_CONTENT_TYPE,\n        Accept=JSON_CONTENT_TYPE,\n        CustomAttributes=""tfs-method=classify"",\n        Body=json.dumps(CLASSIFY_INPUT),\n    )\n\n    assert CLASSIFY_RESPONSE == result\n\n\ndef test_predictor_regress(sagemaker_session):\n    predictor = Predictor(""endpoint"", sagemaker_session, model_name=""model"", model_version=""123"")\n\n    mock_response(json.dumps(REGRESS_RESPONSE).encode(""utf-8""), sagemaker_session)\n    result = predictor.regress(REGRESS_INPUT)\n\n    assert_invoked_with_body_dict(\n        sagemaker_session,\n        EndpointName=""endpoint"",\n        ContentType=JSON_CONTENT_TYPE,\n        Accept=JSON_CONTENT_TYPE,\n        CustomAttributes=""tfs-method=regress,tfs-model-name=model,tfs-model-version=123"",\n        Body=json.dumps(REGRESS_INPUT),\n    )\n\n    assert REGRESS_RESPONSE == result\n\n\ndef test_predictor_regress_bad_content_type(sagemaker_session):\n    predictor = Predictor(""endpoint"", sagemaker_session, csv_serializer)\n\n    with pytest.raises(ValueError):\n        predictor.regress(REGRESS_INPUT)\n\n\ndef test_predictor_classify_bad_content_type(sagemaker_session):\n    predictor = Predictor(""endpoint"", sagemaker_session, csv_serializer)\n\n    with pytest.raises(ValueError):\n        predictor.classify(CLASSIFY_INPUT)\n\n\ndef assert_invoked(sagemaker_session, **kwargs):\n    sagemaker_session.sagemaker_runtime_client.invoke_endpoint.assert_called_once_with(**kwargs)\n\n\ndef assert_invoked_with_body_dict(sagemaker_session, **kwargs):\n    call = sagemaker_session.sagemaker_runtime_client.invoke_endpoint.call_args\n    cargs, ckwargs = call\n    assert not cargs\n    assert len(kwargs) == len(ckwargs)\n    for k in ckwargs:\n        if k != ""Body"":\n            assert kwargs[k] == ckwargs[k]\n        else:\n            actual_body = json.loads(ckwargs[k])\n            expected_body = json.loads(kwargs[k])\n            assert len(actual_body) == len(expected_body)\n            for k2 in actual_body:\n                assert actual_body[k2] == expected_body[k2]\n\n\ndef mock_response(expected_response, sagemaker_session, content_type=JSON_CONTENT_TYPE):\n    sagemaker_session.sagemaker_runtime_client.invoke_endpoint.return_value = {\n        ""ContentType"": content_type,\n        ""Body"": io.BytesIO(expected_response),\n    }\n'"
tests/unit/test_timeout.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""\nThis class tests the timeout.py class in the integration tests.\nThis is to prevent regressions that cause the timeout function to hide failed tests.\n""""""\nfrom __future__ import absolute_import\n\nimport time\n\nimport pytest\nfrom mock import Mock, patch\nimport stopit\n\nfrom botocore.exceptions import ClientError\n\nfrom tests.integ.timeout import (\n    timeout,\n    timeout_and_delete_endpoint_by_name,\n    timeout_and_delete_model_with_transformer,\n)\n\n\nBOTO_SESSION_NAME = ""boto_session_name""\nSAGEMAKER_SESSION_NAME = ""sagemaker_session_name""\nDEFAULT_BUCKET_NAME = ""default_bucket_name""\nTRANSFORMER_NAME = ""transformer.name""\nREGION = ""us-west-2""\nBUCKET_NAME = ""bucket-name""\nENDPOINT_NAME = ""endpoint_name""\n\nEXCEPTION_MESSAGE = ""This Exception is expected and should not be swallowed by the timeout.""\nSHORT_TIMEOUT_TO_FORCE_TIMEOUT_TO_OCCUR = 0.001\nLONG_DURATION_TO_EXCEED_TIMEOUT = 0.002\nLONG_TIMEOUT_THAT_WILL_NEVER_BE_EXCEEDED = 10\nDURATION_TO_SLEEP_TO_ALLOW_BACKGROUND_THREAD_TO_COMPLETE = 0.2\n\n\n@pytest.fixture()\ndef session():\n    boto_mock = Mock(name=BOTO_SESSION_NAME, region_name=REGION)\n    sms = Mock(\n        name=SAGEMAKER_SESSION_NAME,\n        boto_session=boto_mock,\n        boto_region_name=REGION,\n        config=None,\n        local_mode=True,\n    )\n    sms.default_bucket = Mock(name=DEFAULT_BUCKET_NAME, return_value=BUCKET_NAME)\n    return sms\n\n\n@pytest.fixture()\ndef transformer():\n    return Mock(name=TRANSFORMER_NAME, region_name=REGION)\n\n\ndef test_timeout_fails_correctly_when_method_throws_exception():\n    with pytest.raises(ValueError) as exception:\n        with timeout(hours=0, minutes=0, seconds=LONG_TIMEOUT_THAT_WILL_NEVER_BE_EXCEEDED):\n            raise ValueError(EXCEPTION_MESSAGE)\n        assert EXCEPTION_MESSAGE in str(exception.value)\n\n\ndef test_timeout_does_not_throw_exception_when_method_ends_gracefully():\n    with timeout(hours=0, minutes=0, seconds=LONG_TIMEOUT_THAT_WILL_NEVER_BE_EXCEEDED):\n        pass\n\n\n@patch(""tests.integ.timeout._show_logs"", return_value=None, autospec=True)\n@patch(""tests.integ.timeout._cleanup_logs"", return_value=None, autospec=True)\n@patch(\n    ""tests.integ.timeout._delete_schedules_associated_with_endpoint"",\n    return_value=None,\n    autospec=True,\n)\ndef test_timeout_and_delete_endpoint_by_name_fails_when_method_throws_exception(\n    _show_logs, _cleanup_logs, _delete_schedules_associated_with_endpoint, session\n):\n    with pytest.raises(ValueError) as exception:\n        with timeout_and_delete_endpoint_by_name(\n            endpoint_name=ENDPOINT_NAME,\n            sagemaker_session=session,\n            hours=0,\n            minutes=0,\n            seconds=LONG_TIMEOUT_THAT_WILL_NEVER_BE_EXCEEDED,\n            sleep_between_cleanup_attempts=0,\n        ):\n            raise ValueError(EXCEPTION_MESSAGE)\n        assert EXCEPTION_MESSAGE in str(exception.value)\n    assert session.delete_endpoint.call_count == 1\n\n\n@patch(""tests.integ.timeout._show_logs"", return_value=None, autospec=True)\n@patch(""tests.integ.timeout._cleanup_logs"", return_value=None, autospec=True)\n@patch(\n    ""tests.integ.timeout._delete_schedules_associated_with_endpoint"",\n    return_value=None,\n    autospec=True,\n)\ndef test_timeout_and_delete_endpoint_by_name_throws_timeout_exception_when_method_times_out(\n    _show_logs, _cleanup_logs, _delete_schedules_associated_with_endpoint, session\n):\n    with pytest.raises(stopit.utils.TimeoutException):\n        with timeout_and_delete_endpoint_by_name(\n            endpoint_name=ENDPOINT_NAME,\n            sagemaker_session=session,\n            hours=0,\n            minutes=0,\n            seconds=SHORT_TIMEOUT_TO_FORCE_TIMEOUT_TO_OCCUR,\n            sleep_between_cleanup_attempts=0,\n        ):\n            time.sleep(LONG_DURATION_TO_EXCEED_TIMEOUT)\n\n\n@patch(""tests.integ.timeout._show_logs"", return_value=None, autospec=True)\n@patch(""tests.integ.timeout._cleanup_logs"", return_value=None, autospec=True)\n@patch(\n    ""tests.integ.timeout._delete_schedules_associated_with_endpoint"",\n    return_value=None,\n    autospec=True,\n)\ndef test_timeout_and_delete_endpoint_by_name_does_not_throw_exception_when_method_ends_gracefully(\n    _show_logs, _cleanup_logs, _delete_schedules_associated_with_endpoint, session\n):\n    with timeout_and_delete_endpoint_by_name(\n        endpoint_name=ENDPOINT_NAME,\n        sagemaker_session=session,\n        hours=0,\n        minutes=0,\n        seconds=LONG_TIMEOUT_THAT_WILL_NEVER_BE_EXCEEDED,\n        sleep_between_cleanup_attempts=0,\n    ):\n        pass\n    assert session.delete_endpoint.call_count == 1\n\n\n@patch(""tests.integ.timeout._show_logs"", return_value=None, autospec=True)\n@patch(""tests.integ.timeout._cleanup_logs"", return_value=None, autospec=True)\n@patch(\n    ""tests.integ.timeout._delete_schedules_associated_with_endpoint"",\n    return_value=None,\n    autospec=True,\n)\ndef test_timeout_and_delete_endpoint_by_name_retries_resource_deletion_on_failure(\n    _show_logs, _cleanup_logs, _delete_schedules_associated_with_endpoint, session\n):\n    session.delete_endpoint = Mock(\n        side_effect=ClientError(\n            error_response={""Error"": {""Code"": 403, ""Message"": ""ValidationException""}},\n            operation_name=""Unit Test"",\n        )\n    )\n\n    with timeout_and_delete_endpoint_by_name(\n        endpoint_name=ENDPOINT_NAME,\n        sagemaker_session=session,\n        hours=0,\n        minutes=0,\n        seconds=LONG_TIMEOUT_THAT_WILL_NEVER_BE_EXCEEDED,\n        sleep_between_cleanup_attempts=0,\n    ):\n        pass\n    assert session.delete_endpoint.call_count == 3\n\n\n@patch(""tests.integ.timeout._show_logs"", return_value=None, autospec=True)\n@patch(""tests.integ.timeout._cleanup_logs"", return_value=None, autospec=True)\n@patch(\n    ""tests.integ.timeout._delete_schedules_associated_with_endpoint"",\n    return_value=None,\n    autospec=True,\n)\ndef test_timeout_and_delete_model_with_transformer_fails_when_method_throws_exception(\n    _show_logs, _cleanup_logs, _delete_schedules_associated_with_endpoint, session, transformer\n):\n    with pytest.raises(ValueError) as exception:\n        with timeout_and_delete_model_with_transformer(\n            sagemaker_session=session,\n            transformer=transformer,\n            hours=0,\n            minutes=1,\n            sleep_between_cleanup_attempts=0,\n        ):\n            raise ValueError(EXCEPTION_MESSAGE)\n        assert EXCEPTION_MESSAGE in str(exception.value)\n    assert transformer.delete_model.call_count == 1\n\n\n@patch(""tests.integ.timeout._show_logs"", return_value=None, autospec=True)\n@patch(""tests.integ.timeout._cleanup_logs"", return_value=None, autospec=True)\n@patch(\n    ""tests.integ.timeout._delete_schedules_associated_with_endpoint"",\n    return_value=None,\n    autospec=True,\n)\ndef test_timeout_and_delete_model_with_transformer_throws_timeout_exception_when_method_times_out(\n    _show_logs, _cleanup_logs, _delete_schedules_associated_with_endpoint, session, transformer\n):\n    with pytest.raises(stopit.utils.TimeoutException):\n        with timeout_and_delete_model_with_transformer(\n            sagemaker_session=session,\n            transformer=transformer,\n            hours=0,\n            minutes=0,\n            seconds=SHORT_TIMEOUT_TO_FORCE_TIMEOUT_TO_OCCUR,\n            sleep_between_cleanup_attempts=0,\n        ):\n            time.sleep(LONG_DURATION_TO_EXCEED_TIMEOUT)\n\n\n@patch(""tests.integ.timeout._show_logs"", return_value=None, autospec=True)\n@patch(""tests.integ.timeout._cleanup_logs"", return_value=None, autospec=True)\n@patch(\n    ""tests.integ.timeout._delete_schedules_associated_with_endpoint"",\n    return_value=None,\n    autospec=True,\n)\ndef test_timeout_and_delete_model_with_transformer_does_not_throw_when_method_ends_gracefully(\n    _show_logs, _cleanup_logs, _delete_schedules_associated_with_endpoint, session, transformer\n):\n    with timeout_and_delete_model_with_transformer(\n        sagemaker_session=session,\n        transformer=transformer,\n        hours=0,\n        minutes=0,\n        seconds=LONG_TIMEOUT_THAT_WILL_NEVER_BE_EXCEEDED,\n        sleep_between_cleanup_attempts=0,\n    ):\n        pass\n    assert transformer.delete_model.call_count == 1\n\n\n@patch(""tests.integ.timeout._show_logs"", return_value=None, autospec=True)\n@patch(""tests.integ.timeout._cleanup_logs"", return_value=None, autospec=True)\n@patch(\n    ""tests.integ.timeout._delete_schedules_associated_with_endpoint"",\n    return_value=None,\n    autospec=True,\n)\ndef test_timeout_and_delete_model_with_transformer_retries_resource_deletion_on_failure(\n    _show_logs, _cleanup_logs, _delete_schedules_associated_with_endpoint, session, transformer\n):\n    transformer.delete_model = Mock(\n        side_effect=ClientError(\n            error_response={""Error"": {""Code"": 403, ""Message"": ""ValidationException""}},\n            operation_name=""Unit Test"",\n        )\n    )\n\n    with timeout_and_delete_model_with_transformer(\n        sagemaker_session=session,\n        transformer=transformer,\n        hours=0,\n        minutes=0,\n        seconds=LONG_TIMEOUT_THAT_WILL_NEVER_BE_EXCEEDED,\n        sleep_between_cleanup_attempts=0,\n    ):\n        pass\n    assert transformer.delete_model.call_count == 3\n'"
tests/unit/test_transformer.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport pytest\nfrom mock import MagicMock, Mock, patch\n\nfrom sagemaker.transformer import _TransformJob, Transformer\nfrom tests.integ import test_local_mode\n\nMODEL_NAME = ""model""\nIMAGE_NAME = ""image-for-model""\nJOB_NAME = ""job""\n\nINSTANCE_COUNT = 1\nINSTANCE_TYPE = ""ml.m4.xlarge""\nKMS_KEY_ID = ""kms-key-id""\n\nS3_DATA_TYPE = ""S3Prefix""\nS3_BUCKET = ""bucket""\nDATA = ""s3://{}/input-data"".format(S3_BUCKET)\nOUTPUT_PATH = ""s3://{}/output"".format(S3_BUCKET)\n\nTIMESTAMP = ""2018-07-12""\n\nINIT_PARAMS = {\n    ""model_name"": MODEL_NAME,\n    ""instance_count"": INSTANCE_COUNT,\n    ""instance_type"": INSTANCE_TYPE,\n    ""base_transform_job_name"": JOB_NAME,\n}\n\nMODEL_DESC_PRIMARY_CONTAINER = {""PrimaryContainer"": {""Image"": IMAGE_NAME}}\n\nMODEL_DESC_CONTAINERS_ONLY = {""Containers"": [{""Image"": IMAGE_NAME}]}\n\n\n@pytest.fixture(autouse=True)\ndef mock_create_tar_file():\n    with patch(""sagemaker.utils.create_tar_file"", MagicMock()) as create_tar_file:\n        yield create_tar_file\n\n\n@pytest.fixture()\ndef sagemaker_session():\n    boto_mock = Mock(name=""boto_session"")\n    return Mock(name=""sagemaker_session"", boto_session=boto_mock, local_mode=False)\n\n\n@pytest.fixture()\ndef transformer(sagemaker_session):\n    return Transformer(\n        MODEL_NAME,\n        INSTANCE_COUNT,\n        INSTANCE_TYPE,\n        output_path=OUTPUT_PATH,\n        sagemaker_session=sagemaker_session,\n        volume_kms_key=KMS_KEY_ID,\n    )\n\n\ndef test_delete_model(sagemaker_session):\n    transformer = Transformer(\n        MODEL_NAME, INSTANCE_COUNT, INSTANCE_TYPE, sagemaker_session=sagemaker_session\n    )\n    transformer.delete_model()\n    sagemaker_session.delete_model.assert_called_with(MODEL_NAME)\n\n\ndef test_transformer_fails_without_model():\n    transformer = Transformer(\n        model_name=""remote-model"",\n        sagemaker_session=test_local_mode.LocalNoS3Session(),\n        instance_type=""local"",\n        instance_count=1,\n    )\n\n    with pytest.raises(ValueError) as error:\n\n        transformer.transform(""empty-data"")\n\n    assert (\n        str(error.value) == ""Failed to fetch model information for remote-model. ""\n        ""Please ensure that the model exists. ""\n        ""Local instance types require locally created models.""\n    )\n\n\ndef test_transformer_init(sagemaker_session):\n    transformer = Transformer(\n        MODEL_NAME, INSTANCE_COUNT, INSTANCE_TYPE, sagemaker_session=sagemaker_session\n    )\n\n    assert transformer.model_name == MODEL_NAME\n    assert transformer.instance_count == INSTANCE_COUNT\n    assert transformer.instance_type == INSTANCE_TYPE\n    assert transformer.sagemaker_session == sagemaker_session\n\n    assert transformer._current_job_name is None\n    assert transformer.latest_transform_job is None\n    assert transformer._reset_output_path is False\n\n\ndef test_transformer_init_optional_params(sagemaker_session):\n    strategy = ""MultiRecord""\n    assemble_with = ""Line""\n    accept = ""text/csv""\n    max_concurrent_transforms = 100\n    max_payload = 100\n    tags = {""Key"": ""foo"", ""Value"": ""bar""}\n    env = {""FOO"": ""BAR""}\n\n    transformer = Transformer(\n        MODEL_NAME,\n        INSTANCE_COUNT,\n        INSTANCE_TYPE,\n        strategy=strategy,\n        assemble_with=assemble_with,\n        output_path=OUTPUT_PATH,\n        output_kms_key=KMS_KEY_ID,\n        accept=accept,\n        max_concurrent_transforms=max_concurrent_transforms,\n        max_payload=max_payload,\n        tags=tags,\n        env=env,\n        base_transform_job_name=JOB_NAME,\n        sagemaker_session=sagemaker_session,\n        volume_kms_key=KMS_KEY_ID,\n    )\n\n    assert transformer.model_name == MODEL_NAME\n    assert transformer.strategy == strategy\n    assert transformer.env == env\n    assert transformer.output_path == OUTPUT_PATH\n    assert transformer.output_kms_key == KMS_KEY_ID\n    assert transformer.accept == accept\n    assert transformer.assemble_with == assemble_with\n    assert transformer.instance_count == INSTANCE_COUNT\n    assert transformer.instance_type == INSTANCE_TYPE\n    assert transformer.volume_kms_key == KMS_KEY_ID\n    assert transformer.max_concurrent_transforms == max_concurrent_transforms\n    assert transformer.max_payload == max_payload\n    assert transformer.tags == tags\n    assert transformer.base_transform_job_name == JOB_NAME\n\n\n@patch(""sagemaker.transformer._TransformJob.start_new"")\ndef test_transform_with_all_params(start_new_job, transformer):\n    content_type = ""text/csv""\n    compression = ""Gzip""\n    split = ""Line""\n    input_filter = ""$.feature""\n    output_filter = ""$[\'sagemaker_output\', \'id\']""\n    join_source = ""Input""\n    experiment_config = {\n        ""ExperimentName"": ""exp"",\n        ""TrialName"": ""t"",\n        ""TrialComponentDisplayName"": ""tc"",\n    }\n\n    transformer.transform(\n        DATA,\n        S3_DATA_TYPE,\n        content_type=content_type,\n        compression_type=compression,\n        split_type=split,\n        job_name=JOB_NAME,\n        input_filter=input_filter,\n        output_filter=output_filter,\n        join_source=join_source,\n        experiment_config=experiment_config,\n    )\n\n    assert transformer._current_job_name == JOB_NAME\n    assert transformer.output_path == OUTPUT_PATH\n    start_new_job.assert_called_once_with(\n        transformer,\n        DATA,\n        S3_DATA_TYPE,\n        content_type,\n        compression,\n        split,\n        input_filter,\n        output_filter,\n        join_source,\n        experiment_config,\n    )\n\n\n@patch(""sagemaker.transformer.name_from_base"")\n@patch(""sagemaker.transformer._TransformJob.start_new"")\ndef test_transform_with_base_job_name_provided(start_new_job, name_from_base, transformer):\n    base_name = ""base-job-name""\n    full_name = ""{}-{}"".format(base_name, TIMESTAMP)\n\n    transformer.base_transform_job_name = base_name\n    name_from_base.return_value = full_name\n\n    transformer.transform(DATA)\n\n    name_from_base.assert_called_once_with(base_name)\n    assert transformer._current_job_name == full_name\n\n\n@patch(""sagemaker.transformer.Transformer._retrieve_base_name"", return_value=IMAGE_NAME)\n@patch(""sagemaker.transformer.name_from_base"")\n@patch(""sagemaker.transformer._TransformJob.start_new"")\ndef test_transform_with_base_name(start_new_job, name_from_base, retrieve_base_name, transformer):\n    full_name = ""{}-{}"".format(IMAGE_NAME, TIMESTAMP)\n    name_from_base.return_value = full_name\n\n    transformer.transform(DATA)\n\n    retrieve_base_name.assert_called_once_with()\n    name_from_base.assert_called_once_with(IMAGE_NAME)\n    assert transformer._current_job_name == full_name\n\n\n@patch(""sagemaker.transformer.Transformer._retrieve_image_name"", return_value=IMAGE_NAME)\n@patch(""sagemaker.transformer.name_from_base"")\n@patch(""sagemaker.transformer._TransformJob.start_new"")\ndef test_transform_with_job_name_based_on_image(\n    start_new_job, name_from_base, retrieve_image_name, transformer\n):\n    full_name = ""{}-{}"".format(IMAGE_NAME, TIMESTAMP)\n    name_from_base.return_value = full_name\n\n    transformer.transform(DATA)\n\n    retrieve_image_name.assert_called_once_with()\n    name_from_base.assert_called_once_with(IMAGE_NAME)\n    assert transformer._current_job_name == full_name\n\n\n@pytest.mark.parametrize(""model_desc"", [MODEL_DESC_PRIMARY_CONTAINER, MODEL_DESC_CONTAINERS_ONLY])\n@patch(""sagemaker.transformer.name_from_base"")\n@patch(""sagemaker.transformer._TransformJob.start_new"")\ndef test_transform_with_job_name_based_on_containers(\n    start_new_job, name_from_base, model_desc, transformer\n):\n    transformer.sagemaker_session.sagemaker_client.describe_model.return_value = model_desc\n\n    full_name = ""{}-{}"".format(IMAGE_NAME, TIMESTAMP)\n    name_from_base.return_value = full_name\n\n    transformer.transform(DATA)\n\n    transformer.sagemaker_session.sagemaker_client.describe_model.assert_called_once_with(\n        ModelName=MODEL_NAME\n    )\n    name_from_base.assert_called_once_with(IMAGE_NAME)\n    assert transformer._current_job_name == full_name\n\n\n@pytest.mark.parametrize(\n    ""model_desc"", [{""PrimaryContainer"": dict()}, {""Containers"": [dict()]}, dict()]\n)\n@patch(""sagemaker.transformer.name_from_base"")\n@patch(""sagemaker.transformer._TransformJob.start_new"")\ndef test_transform_with_job_name_based_on_model_name(\n    start_new_job, name_from_base, model_desc, transformer\n):\n    transformer.sagemaker_session.sagemaker_client.describe_model.return_value = model_desc\n\n    full_name = ""{}-{}"".format(MODEL_NAME, TIMESTAMP)\n    name_from_base.return_value = full_name\n\n    transformer.transform(DATA)\n\n    transformer.sagemaker_session.sagemaker_client.describe_model.assert_called_once_with(\n        ModelName=MODEL_NAME\n    )\n    name_from_base.assert_called_once_with(MODEL_NAME)\n    assert transformer._current_job_name == full_name\n\n\n@patch(""sagemaker.transformer._TransformJob.start_new"")\ndef test_transform_with_generated_output_path(start_new_job, transformer, sagemaker_session):\n    transformer.output_path = None\n    sagemaker_session.default_bucket.return_value = S3_BUCKET\n\n    transformer.transform(DATA, job_name=JOB_NAME)\n    assert transformer.output_path == ""s3://{}/{}"".format(S3_BUCKET, JOB_NAME)\n\n\ndef test_transform_with_invalid_s3_uri(transformer):\n    with pytest.raises(ValueError) as e:\n        transformer.transform(""not-an-s3-uri"")\n\n    assert ""Invalid S3 URI"" in str(e)\n\n\ndef test_retrieve_image_name(sagemaker_session, transformer):\n    sage_mock = Mock(name=""sagemaker_client"")\n    sage_mock.describe_model.return_value = {""PrimaryContainer"": {""Image"": IMAGE_NAME}}\n\n    sagemaker_session.sagemaker_client = sage_mock\n\n    assert transformer._retrieve_image_name() == IMAGE_NAME\n\n\n@patch(""sagemaker.transformer.Transformer._ensure_last_transform_job"")\ndef test_wait(ensure_last_transform_job, transformer):\n    transformer.latest_transform_job = Mock(name=""latest_transform_job"")\n\n    transformer.wait()\n\n    assert ensure_last_transform_job.called_once\n    assert transformer.latest_transform_job.wait.called_once\n\n\ndef test_ensure_last_transform_job_exists(transformer, sagemaker_session):\n    transformer.latest_transform_job = _TransformJob(sagemaker_session, ""some-transform-job"")\n    transformer._ensure_last_transform_job()\n\n\ndef test_ensure_last_transform_job_none(transformer):\n    transformer.latest_transform_job = None\n    with pytest.raises(ValueError) as e:\n        transformer._ensure_last_transform_job()\n\n    assert ""No transform job available"" in str(e)\n\n\n@patch(\n    ""sagemaker.transformer.Transformer._prepare_init_params_from_job_description"",\n    return_value=INIT_PARAMS,\n)\ndef test_attach(prepare_init_params, transformer, sagemaker_session):\n    sagemaker_session.sagemaker_client.describe_transform_job = Mock(name=""describe_transform_job"")\n    attached = Transformer.attach(JOB_NAME, sagemaker_session)\n\n    assert prepare_init_params.called_once\n    assert attached.latest_transform_job.job_name == JOB_NAME\n    assert attached.model_name == MODEL_NAME\n    assert attached.instance_count == INSTANCE_COUNT\n    assert attached.instance_type == INSTANCE_TYPE\n\n\ndef test_prepare_init_params_from_job_description_missing_keys(transformer):\n    job_details = {\n        ""ModelName"": MODEL_NAME,\n        ""TransformResources"": {""InstanceCount"": INSTANCE_COUNT, ""InstanceType"": INSTANCE_TYPE},\n        ""TransformOutput"": {""S3OutputPath"": None},\n        ""TransformJobName"": JOB_NAME,\n    }\n\n    init_params = transformer._prepare_init_params_from_job_description(job_details)\n\n    assert init_params[""model_name""] == MODEL_NAME\n    assert init_params[""instance_count""] == INSTANCE_COUNT\n    assert init_params[""instance_type""] == INSTANCE_TYPE\n\n\ndef test_prepare_init_params_from_job_description_all_keys(transformer):\n    job_details = {\n        ""ModelName"": MODEL_NAME,\n        ""TransformResources"": {\n            ""InstanceCount"": INSTANCE_COUNT,\n            ""InstanceType"": INSTANCE_TYPE,\n            ""VolumeKmsKeyId"": KMS_KEY_ID,\n        },\n        ""BatchStrategy"": None,\n        ""TransformOutput"": {\n            ""AssembleWith"": None,\n            ""S3OutputPath"": None,\n            ""KmsKeyId"": None,\n            ""Accept"": None,\n        },\n        ""MaxConcurrentTransforms"": None,\n        ""MaxPayloadInMB"": None,\n        ""TransformJobName"": JOB_NAME,\n    }\n\n    init_params = transformer._prepare_init_params_from_job_description(job_details)\n\n    assert init_params[""model_name""] == MODEL_NAME\n    assert init_params[""instance_count""] == INSTANCE_COUNT\n    assert init_params[""instance_type""] == INSTANCE_TYPE\n    assert init_params[""volume_kms_key""] == KMS_KEY_ID\n\n\n# _TransformJob tests\n@patch(""sagemaker.transformer._TransformJob._load_config"")\n@patch(""sagemaker.transformer._TransformJob._prepare_data_processing"")\ndef test_start_new(prepare_data_processing, load_config, sagemaker_session):\n    input_config = ""input""\n    output_config = ""output""\n    resource_config = ""resource""\n    load_config.return_value = {\n        ""input_config"": input_config,\n        ""output_config"": output_config,\n        ""resource_config"": resource_config,\n    }\n\n    strategy = ""MultiRecord""\n    max_concurrent_transforms = 100\n    max_payload = 100\n    tags = {""Key"": ""foo"", ""Value"": ""bar""}\n    env = {""FOO"": ""BAR""}\n\n    transformer = Transformer(\n        MODEL_NAME,\n        INSTANCE_COUNT,\n        INSTANCE_TYPE,\n        strategy=strategy,\n        output_path=OUTPUT_PATH,\n        max_concurrent_transforms=max_concurrent_transforms,\n        max_payload=max_payload,\n        tags=tags,\n        env=env,\n        sagemaker_session=sagemaker_session,\n    )\n    transformer._current_job_name = JOB_NAME\n\n    content_type = ""text/csv""\n    compression_type = ""Gzip""\n    split_type = ""Line""\n    io_filter = ""$""\n    join_source = ""Input""\n    job = _TransformJob.start_new(\n        transformer=transformer,\n        data=DATA,\n        data_type=S3_DATA_TYPE,\n        content_type=content_type,\n        compression_type=compression_type,\n        split_type=split_type,\n        input_filter=io_filter,\n        output_filter=io_filter,\n        join_source=join_source,\n        experiment_config={""ExperimentName"": ""exp""},\n    )\n\n    assert job.sagemaker_session == sagemaker_session\n    assert job.job_name == JOB_NAME\n\n    load_config.assert_called_with(\n        DATA, S3_DATA_TYPE, content_type, compression_type, split_type, transformer\n    )\n    prepare_data_processing.assert_called_with(io_filter, io_filter, join_source)\n\n    sagemaker_session.transform.assert_called_with(\n        job_name=JOB_NAME,\n        model_name=MODEL_NAME,\n        strategy=strategy,\n        max_concurrent_transforms=max_concurrent_transforms,\n        max_payload=max_payload,\n        env=env,\n        input_config=input_config,\n        output_config=output_config,\n        resource_config=resource_config,\n        experiment_config={""ExperimentName"": ""exp""},\n        tags=tags,\n        data_processing=prepare_data_processing.return_value,\n    )\n\n\ndef test_load_config(transformer):\n    expected_config = {\n        ""input_config"": {\n            ""DataSource"": {""S3DataSource"": {""S3DataType"": S3_DATA_TYPE, ""S3Uri"": DATA}}\n        },\n        ""output_config"": {""S3OutputPath"": OUTPUT_PATH},\n        ""resource_config"": {\n            ""InstanceCount"": INSTANCE_COUNT,\n            ""InstanceType"": INSTANCE_TYPE,\n            ""VolumeKmsKeyId"": KMS_KEY_ID,\n        },\n    }\n\n    actual_config = _TransformJob._load_config(DATA, S3_DATA_TYPE, None, None, None, transformer)\n    assert actual_config == expected_config\n\n\ndef test_format_inputs_to_input_config():\n    expected_config = {""DataSource"": {""S3DataSource"": {""S3DataType"": S3_DATA_TYPE, ""S3Uri"": DATA}}}\n\n    actual_config = _TransformJob._format_inputs_to_input_config(\n        DATA, S3_DATA_TYPE, None, None, None\n    )\n    assert actual_config == expected_config\n\n\ndef test_format_inputs_to_input_config_with_optional_params():\n    compression = ""Gzip""\n    content_type = ""text/csv""\n    split = ""Line""\n\n    expected_config = {\n        ""DataSource"": {""S3DataSource"": {""S3DataType"": S3_DATA_TYPE, ""S3Uri"": DATA}},\n        ""CompressionType"": compression,\n        ""ContentType"": content_type,\n        ""SplitType"": split,\n    }\n\n    actual_config = _TransformJob._format_inputs_to_input_config(\n        DATA, S3_DATA_TYPE, content_type, compression, split\n    )\n    assert actual_config == expected_config\n\n\ndef test_prepare_output_config():\n    config = _TransformJob._prepare_output_config(OUTPUT_PATH, None, None, None)\n\n    assert config == {""S3OutputPath"": OUTPUT_PATH}\n\n\ndef test_prepare_output_config_with_optional_params():\n    kms_key = ""key""\n    assemble_with = ""Line""\n    accept = ""text/csv""\n\n    expected_config = {\n        ""S3OutputPath"": OUTPUT_PATH,\n        ""KmsKeyId"": kms_key,\n        ""AssembleWith"": assemble_with,\n        ""Accept"": accept,\n    }\n\n    actual_config = _TransformJob._prepare_output_config(\n        OUTPUT_PATH, kms_key, assemble_with, accept\n    )\n    assert actual_config == expected_config\n\n\ndef test_prepare_resource_config():\n    config = _TransformJob._prepare_resource_config(INSTANCE_COUNT, INSTANCE_TYPE, KMS_KEY_ID)\n    assert config == {\n        ""InstanceCount"": INSTANCE_COUNT,\n        ""InstanceType"": INSTANCE_TYPE,\n        ""VolumeKmsKeyId"": KMS_KEY_ID,\n    }\n\n\ndef test_data_processing_config():\n    actual_config = _TransformJob._prepare_data_processing(""$"", None, None)\n    assert actual_config == {""InputFilter"": ""$""}\n\n    actual_config = _TransformJob._prepare_data_processing(None, ""$"", None)\n    assert actual_config == {""OutputFilter"": ""$""}\n\n    actual_config = _TransformJob._prepare_data_processing(None, None, ""Input"")\n    assert actual_config == {""JoinSource"": ""Input""}\n\n    actual_config = _TransformJob._prepare_data_processing(""$[0]"", ""$[1]"", ""Input"")\n    assert actual_config == {""InputFilter"": ""$[0]"", ""OutputFilter"": ""$[1]"", ""JoinSource"": ""Input""}\n\n    actual_config = _TransformJob._prepare_data_processing(None, None, None)\n    assert actual_config is None\n\n\ndef test_transform_job_wait(sagemaker_session):\n    job = _TransformJob(sagemaker_session, JOB_NAME)\n    job.wait()\n\n    assert sagemaker_session.wait_for_transform_job.called_once\n\n\n@patch(""sagemaker.transformer._TransformJob.start_new"")\ndef test_restart_output_path(start_new_job, transformer, sagemaker_session):\n    transformer.output_path = None\n    sagemaker_session.default_bucket.return_value = S3_BUCKET\n\n    transformer.transform(DATA, job_name=""job-1"")\n    assert transformer.output_path == ""s3://{}/{}"".format(S3_BUCKET, ""job-1"")\n\n    transformer.transform(DATA, job_name=""job-2"")\n    assert transformer.output_path == ""s3://{}/{}"".format(S3_BUCKET, ""job-2"")\n\n\ndef test_stop_transform_job(sagemaker_session, transformer):\n    sagemaker_session.stop_transform_job = Mock(name=""stop_transform_job"")\n    transformer.latest_transform_job = _TransformJob(sagemaker_session, JOB_NAME)\n\n    transformer.stop_transform_job()\n\n    sagemaker_session.stop_transform_job.assert_called_once_with(name=JOB_NAME)\n\n\ndef test_stop_transform_job_no_transform_job(transformer):\n    with pytest.raises(ValueError) as e:\n        transformer.stop_transform_job()\n    assert ""No transform job available"" in str(e)\n'"
tests/unit/test_tuner.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport copy\nimport os\nimport re\n\nimport pytest\nfrom mock import Mock, patch\n\nfrom sagemaker import RealTimePredictor\nfrom sagemaker.amazon.amazon_estimator import RecordSet\nfrom sagemaker.estimator import Framework\nfrom sagemaker.mxnet import MXNet\n\nfrom sagemaker.session import s3_input\n\nfrom sagemaker.parameter import ParameterRange\nfrom sagemaker.tuner import (\n    _TuningJob,\n    create_identical_dataset_and_algorithm_tuner,\n    create_transfer_learning_tuner,\n    HyperparameterTuner,\n)\n\nfrom .tuner_test_utils import *  # noqa: F403\n\n\n@pytest.fixture()\ndef sagemaker_session():\n    boto_mock = Mock(name=""boto_session"", region_name=REGION)\n    sms = Mock(name=""sagemaker_session"", boto_session=boto_mock, s3_client=None, s3_resource=None)\n    sms.boto_region_name = REGION\n    sms.default_bucket = Mock(name=""default_bucket"", return_value=BUCKET_NAME)\n    sms.config = None\n\n    sms.sagemaker_client.describe_endpoint = Mock(return_value=ENDPOINT_DESC)\n    sms.sagemaker_client.describe_endpoint_config = Mock(return_value=ENDPOINT_CONFIG_DESC)\n\n    return sms\n\n\n@pytest.fixture()\ndef estimator(sagemaker_session):\n    return Estimator(\n        IMAGE_NAME,\n        ROLE,\n        TRAIN_INSTANCE_COUNT,\n        TRAIN_INSTANCE_TYPE,\n        output_path=""s3://bucket/prefix"",\n        sagemaker_session=sagemaker_session,\n    )\n\n\n@pytest.fixture()\ndef tuner(estimator):\n    return HyperparameterTuner(\n        estimator, OBJECTIVE_METRIC_NAME, HYPERPARAMETER_RANGES, METRIC_DEFINITIONS\n    )\n\n\ndef test_prepare_for_training(tuner):\n    static_hyperparameters = {""validated"": 1, ""another_one"": 0}\n    tuner.estimator.set_hyperparameters(**static_hyperparameters)\n    tuner._prepare_for_tuning()\n\n    assert tuner._current_job_name.startswith(IMAGE_NAME)\n\n    assert len(tuner.static_hyperparameters) == 1\n    assert tuner.static_hyperparameters[""another_one""] == ""0""\n\n\ndef test_prepare_for_tuning_with_amazon_estimator(tuner, sagemaker_session):\n    tuner.estimator = PCA(\n        ROLE,\n        TRAIN_INSTANCE_COUNT,\n        TRAIN_INSTANCE_TYPE,\n        NUM_COMPONENTS,\n        sagemaker_session=sagemaker_session,\n    )\n\n    tuner._prepare_for_tuning()\n    assert ""sagemaker_estimator_class_name"" not in tuner.static_hyperparameters\n    assert ""sagemaker_estimator_module"" not in tuner.static_hyperparameters\n\n\ndef test_prepare_for_tuning_include_estimator_cls(tuner):\n    tuner._prepare_for_tuning(include_cls_metadata=True)\n    assert ""sagemaker_estimator_class_name"" in tuner.static_hyperparameters\n    assert ""sagemaker_estimator_module"" in tuner.static_hyperparameters\n\n\ndef test_prepare_for_tuning_with_job_name(tuner):\n    static_hyperparameters = {""validated"": 1, ""another_one"": 0}\n    tuner.estimator.set_hyperparameters(**static_hyperparameters)\n\n    tuner._prepare_for_tuning(job_name=""some-other-job-name"")\n    assert tuner._current_job_name == ""some-other-job-name""\n\n\ndef test_validate_parameter_ranges_number_validation_error(sagemaker_session):\n    pca = PCA(\n        ROLE,\n        TRAIN_INSTANCE_COUNT,\n        TRAIN_INSTANCE_TYPE,\n        NUM_COMPONENTS,\n        base_job_name=""pca"",\n        sagemaker_session=sagemaker_session,\n    )\n\n    invalid_hyperparameter_ranges = {""num_components"": IntegerParameter(-1, 2)}\n\n    with pytest.raises(ValueError) as e:\n        HyperparameterTuner(\n            estimator=pca,\n            objective_metric_name=OBJECTIVE_METRIC_NAME,\n            hyperparameter_ranges=invalid_hyperparameter_ranges,\n            metric_definitions=METRIC_DEFINITIONS,\n        )\n\n    assert ""Value must be an integer greater than zero"" in str(e)\n\n\ndef test_validate_parameter_ranges_string_value_validation_error(sagemaker_session):\n    pca = PCA(\n        ROLE,\n        TRAIN_INSTANCE_COUNT,\n        TRAIN_INSTANCE_TYPE,\n        NUM_COMPONENTS,\n        base_job_name=""pca"",\n        sagemaker_session=sagemaker_session,\n    )\n\n    invalid_hyperparameter_ranges = {""algorithm_mode"": CategoricalParameter([0, 5])}\n\n    with pytest.raises(ValueError) as e:\n        HyperparameterTuner(\n            estimator=pca,\n            objective_metric_name=OBJECTIVE_METRIC_NAME,\n            hyperparameter_ranges=invalid_hyperparameter_ranges,\n            metric_definitions=METRIC_DEFINITIONS,\n        )\n\n    assert \'Value must be one of ""regular"" and ""randomized""\' in str(e)\n\n\ndef test_fit_pca(sagemaker_session, tuner):\n    pca = PCA(\n        ROLE,\n        TRAIN_INSTANCE_COUNT,\n        TRAIN_INSTANCE_TYPE,\n        NUM_COMPONENTS,\n        base_job_name=""pca"",\n        sagemaker_session=sagemaker_session,\n    )\n\n    pca.algorithm_mode = ""randomized""\n    pca.subtract_mean = True\n    pca.extra_components = 5\n\n    tuner.estimator = pca\n\n    tags = [{""Name"": ""some-tag-without-a-value""}]\n    tuner.tags = tags\n\n    tuner._hyperparameter_ranges = HYPERPARAMETER_RANGES_TWO\n\n    records = RecordSet(s3_data=INPUTS, num_records=1, feature_dim=1)\n    tuner.fit(records, mini_batch_size=9999)\n\n    _, _, tune_kwargs = sagemaker_session.create_tuning_job.mock_calls[0]\n\n    assert tuner.estimator.mini_batch_size == 9999\n\n    assert tune_kwargs[""job_name""].startswith(""pca"")\n    assert tune_kwargs[""tags""] == tags\n\n    assert len(tune_kwargs[""tuning_config""][""parameter_ranges""][""IntegerParameterRanges""]) == 1\n    assert tune_kwargs[""tuning_config""][""early_stopping_type""] == ""Off""\n    assert tuner.estimator.mini_batch_size == 9999\n\n    assert ""training_config"" in tune_kwargs\n    assert ""training_config_list"" not in tune_kwargs\n\n    assert len(tune_kwargs[""training_config""][""static_hyperparameters""]) == 4\n    assert tune_kwargs[""training_config""][""static_hyperparameters""][""extra_components""] == ""5""\n\n    assert ""estimator_name"" not in tune_kwargs[""training_config""]\n    assert ""objective_type"" not in tune_kwargs[""training_config""]\n    assert ""objective_metric_name"" not in tune_kwargs[""training_config""]\n    assert ""parameter_ranges"" not in tune_kwargs[""training_config""]\n\n\ndef test_fit_pca_with_early_stopping(sagemaker_session, tuner):\n    pca = PCA(\n        ROLE,\n        TRAIN_INSTANCE_COUNT,\n        TRAIN_INSTANCE_TYPE,\n        NUM_COMPONENTS,\n        base_job_name=""pca"",\n        sagemaker_session=sagemaker_session,\n    )\n\n    tuner.estimator = pca\n    tuner.early_stopping_type = ""Auto""\n\n    records = RecordSet(s3_data=INPUTS, num_records=1, feature_dim=1)\n    tuner.fit(records, mini_batch_size=9999)\n\n    _, _, tune_kwargs = sagemaker_session.create_tuning_job.mock_calls[0]\n\n    assert tune_kwargs[""job_name""].startswith(""pca"")\n    assert tune_kwargs[""tuning_config""][""early_stopping_type""] == ""Auto""\n\n\ndef test_fit_pca_with_vpc_config(sagemaker_session, tuner):\n    subnets = [""foo""]\n    security_group_ids = [""bar""]\n\n    pca = PCA(\n        ROLE,\n        TRAIN_INSTANCE_COUNT,\n        TRAIN_INSTANCE_TYPE,\n        NUM_COMPONENTS,\n        base_job_name=""pca"",\n        sagemaker_session=sagemaker_session,\n        subnets=subnets,\n        security_group_ids=security_group_ids,\n    )\n    tuner.estimator = pca\n\n    records = RecordSet(s3_data=INPUTS, num_records=1, feature_dim=1)\n    tuner.fit(records, mini_batch_size=9999)\n\n    _, _, tune_kwargs = sagemaker_session.create_tuning_job.mock_calls[0]\n\n    assert tune_kwargs[""training_config""][""vpc_config""] == {\n        ""Subnets"": subnets,\n        ""SecurityGroupIds"": security_group_ids,\n    }\n\n\ndef test_s3_input_mode(sagemaker_session, tuner):\n    expected_input_mode = ""Pipe""\n\n    script_path = os.path.join(DATA_DIR, ""mxnet_mnist"", ""failure_script.py"")\n    mxnet = MXNet(\n        entry_point=script_path,\n        role=ROLE,\n        framework_version=FRAMEWORK_VERSION,\n        train_instance_count=TRAIN_INSTANCE_COUNT,\n        train_instance_type=TRAIN_INSTANCE_TYPE,\n        sagemaker_session=sagemaker_session,\n    )\n    tuner.estimator = mxnet\n\n    tags = [{""Name"": ""some-tag-without-a-value""}]\n    tuner.tags = tags\n\n    hyperparameter_ranges = {\n        ""num_components"": IntegerParameter(2, 4),\n        ""algorithm_mode"": CategoricalParameter([""regular"", ""randomized""]),\n    }\n    tuner._hyperparameter_ranges = hyperparameter_ranges\n\n    tuner.fit(inputs=s3_input(""s3://mybucket/train_manifest"", input_mode=expected_input_mode))\n\n    actual_input_mode = sagemaker_session.method_calls[1][2][""training_config""][""input_mode""]\n    assert actual_input_mode == expected_input_mode\n\n\ndef test_fit_pca_with_inter_container_traffic_encryption_flag(sagemaker_session, tuner):\n    pca = PCA(\n        ROLE,\n        TRAIN_INSTANCE_COUNT,\n        TRAIN_INSTANCE_TYPE,\n        NUM_COMPONENTS,\n        base_job_name=""pca"",\n        sagemaker_session=sagemaker_session,\n        encrypt_inter_container_traffic=True,\n    )\n\n    tuner.estimator = pca\n\n    records = RecordSet(s3_data=INPUTS, num_records=1, feature_dim=1)\n    tuner.fit(records, mini_batch_size=9999)\n\n    _, _, tune_kwargs = sagemaker_session.create_tuning_job.mock_calls[0]\n\n    assert tune_kwargs[""job_name""].startswith(""pca"")\n    assert tune_kwargs[""training_config""][""encrypt_inter_container_traffic""] is True\n\n\n@pytest.mark.parametrize(\n    ""inputs,include_cls_metadata,estimator_kwargs,error_message"",\n    [\n        (\n            RecordSet(s3_data=INPUTS, num_records=1, feature_dim=1),\n            {ESTIMATOR_NAME_TWO: True},\n            {},\n            re.compile(\n                ""Argument \'inputs\' must be a dictionary using \\\\[\'estimator_name\', \'estimator_name_two\'\\\\] as keys""\n            ),\n        ),\n        (\n            {ESTIMATOR_NAME: RecordSet(s3_data=INPUTS, num_records=1, feature_dim=1)},\n            False,\n            {},\n            re.compile(\n                ""Argument \'include_cls_metadata\' must be a dictionary using \\\\[\'estimator_name\', ""\n                ""\'estimator_name_two\'\\\\] as keys""\n            ),\n        ),\n        (\n            {ESTIMATOR_NAME: RecordSet(s3_data=INPUTS, num_records=1, feature_dim=1)},\n            {ESTIMATOR_NAME_TWO: True},\n            False,\n            re.compile(\n                ""Argument \'estimator_kwargs\' must be a dictionary using \\\\[\'estimator_name\', ""\n                ""\'estimator_name_two\'\\\\] as keys""\n            ),\n        ),\n        (\n            {\n                ESTIMATOR_NAME: RecordSet(s3_data=INPUTS, num_records=1, feature_dim=1),\n                ""Invalid estimator"": RecordSet(s3_data=INPUTS, num_records=10, feature_dim=5),\n            },\n            {ESTIMATOR_NAME_TWO: True},\n            None,\n            re.compile(\n                ""The keys of argument \'inputs\' must be a subset of \\\\[\'estimator_name\', \'estimator_name_two\'\\\\]""\n            ),\n        ),\n    ],\n)\ndef test_fit_multi_estimators_invalid_inputs(\n    sagemaker_session, inputs, include_cls_metadata, estimator_kwargs, error_message\n):\n    (tuner, estimator_one, estimator_two) = _create_multi_estimator_tuner(sagemaker_session)\n\n    with pytest.raises(ValueError, match=error_message):\n        tuner.fit(\n            inputs=inputs,\n            include_cls_metadata=include_cls_metadata,\n            estimator_kwargs=estimator_kwargs,\n        )\n\n\ndef test_fit_multi_estimators(sagemaker_session):\n\n    (tuner, estimator_one, estimator_two) = _create_multi_estimator_tuner(sagemaker_session)\n\n    records = {ESTIMATOR_NAME_TWO: RecordSet(s3_data=INPUTS, num_records=1, feature_dim=1)}\n\n    estimator_kwargs = {ESTIMATOR_NAME_TWO: {""mini_batch_size"": 4000}}\n\n    tuner.fit(inputs=records, include_cls_metadata={}, estimator_kwargs=estimator_kwargs)\n\n    _, _, tune_kwargs = sagemaker_session.create_tuning_job.mock_calls[0]\n\n    assert tune_kwargs[""job_name""].startswith(BASE_JOB_NAME)\n    assert tune_kwargs[""tags""] == TAGS\n\n    assert tune_kwargs[""tuning_config""][""strategy""] == STRATEGY\n    assert tune_kwargs[""tuning_config""][""max_jobs""] == MAX_JOBS\n    assert tune_kwargs[""tuning_config""][""max_parallel_jobs""] == MAX_PARALLEL_JOBS\n    assert tune_kwargs[""tuning_config""][""early_stopping_type""] == EARLY_STOPPING_TYPE\n\n    assert ""tuning_objective"" not in tune_kwargs[""tuning_config""]\n    assert ""parameter_ranges"" not in tune_kwargs[""tuning_config""]\n\n    assert ""training_config"" not in tune_kwargs\n    assert ""training_config_list"" in tune_kwargs\n\n    assert len(tune_kwargs[""training_config_list""]) == 2\n\n    training_config_one = tune_kwargs[""training_config_list""][0]\n    training_config_two = tune_kwargs[""training_config_list""][1]\n\n    assert training_config_one[""estimator_name""] == ESTIMATOR_NAME\n    assert training_config_one[""objective_type""] == ""Minimize""\n    assert training_config_one[""objective_metric_name""] == OBJECTIVE_METRIC_NAME\n    assert training_config_one[""input_config""] is None\n    assert training_config_one[""image""] == estimator_one.train_image()\n    assert training_config_one[""metric_definitions""] == METRIC_DEFINITIONS\n    assert (\n        training_config_one[""static_hyperparameters""][""sagemaker_estimator_module""]\n        == \'""sagemaker.mxnet.estimator""\'\n    )\n    _assert_parameter_ranges(\n        HYPERPARAMETER_RANGES,\n        training_config_one[""parameter_ranges""],\n        isinstance(estimator_one, Framework),\n    )\n\n    assert training_config_two[""estimator_name""] == ESTIMATOR_NAME_TWO\n    assert training_config_two[""objective_type""] == ""Minimize""\n    assert training_config_two[""objective_metric_name""] == OBJECTIVE_METRIC_NAME_TWO\n    assert len(training_config_two[""input_config""]) == 1\n    assert training_config_two[""input_config""][0][""DataSource""][""S3DataSource""][""S3Uri""] == INPUTS\n    assert training_config_two[""image""] == estimator_two.train_image()\n    assert training_config_two[""metric_definitions""] is None\n    assert training_config_two[""static_hyperparameters""][""mini_batch_size""] == ""4000""\n    _assert_parameter_ranges(\n        HYPERPARAMETER_RANGES_TWO,\n        training_config_two[""parameter_ranges""],\n        isinstance(estimator_two, Framework),\n    )\n\n\ndef _create_multi_estimator_tuner(sagemaker_session):\n    mxnet_script_path = os.path.join(DATA_DIR, ""mxnet_mnist"", ""failure_script.py"")\n    mxnet = MXNet(\n        entry_point=mxnet_script_path,\n        role=ROLE,\n        framework_version=FRAMEWORK_VERSION,\n        train_instance_count=TRAIN_INSTANCE_COUNT,\n        train_instance_type=TRAIN_INSTANCE_TYPE,\n        sagemaker_session=sagemaker_session,\n    )\n\n    pca = PCA(\n        ROLE,\n        TRAIN_INSTANCE_COUNT,\n        TRAIN_INSTANCE_TYPE,\n        NUM_COMPONENTS,\n        base_job_name=""pca"",\n        sagemaker_session=sagemaker_session,\n    )\n    pca.algorithm_mode = ""randomized""\n    pca.subtract_mean = True\n    pca.extra_components = 5\n\n    tuner = HyperparameterTuner.create(\n        base_tuning_job_name=BASE_JOB_NAME,\n        estimator_dict={ESTIMATOR_NAME: mxnet, ESTIMATOR_NAME_TWO: pca},\n        objective_metric_name_dict={\n            ESTIMATOR_NAME: OBJECTIVE_METRIC_NAME,\n            ESTIMATOR_NAME_TWO: OBJECTIVE_METRIC_NAME_TWO,\n        },\n        hyperparameter_ranges_dict={\n            ESTIMATOR_NAME: HYPERPARAMETER_RANGES,\n            ESTIMATOR_NAME_TWO: HYPERPARAMETER_RANGES_TWO,\n        },\n        metric_definitions_dict={ESTIMATOR_NAME: METRIC_DEFINITIONS},\n        strategy=STRATEGY,\n        objective_type=OBJECTIVE_TYPE,\n        max_jobs=MAX_JOBS,\n        max_parallel_jobs=MAX_PARALLEL_JOBS,\n        tags=TAGS,\n        warm_start_config=WARM_START_CONFIG,\n        early_stopping_type=EARLY_STOPPING_TYPE,\n    )\n\n    return tuner, mxnet, pca\n\n\ndef _assert_parameter_ranges(expected, actual, is_framework_estimator):\n    continuous_ranges = []\n    integer_ranges = []\n    categorical_ranges = []\n    for (name, param_range) in expected.items():\n        if isinstance(param_range, ContinuousParameter):\n            continuous_ranges.append(param_range.as_tuning_range(name))\n        elif isinstance(param_range, IntegerParameter):\n            integer_ranges.append(param_range.as_tuning_range(name))\n        else:\n            categorical_range = (\n                param_range.as_json_range(name)\n                if is_framework_estimator\n                else param_range.as_tuning_range(name)\n            )\n            categorical_ranges.append(categorical_range)\n\n    assert continuous_ranges == actual[""ContinuousParameterRanges""]\n    assert integer_ranges == actual[""IntegerParameterRanges""]\n    assert categorical_ranges == actual[""CategoricalParameterRanges""]\n\n\ndef test_attach_tuning_job_with_estimator_from_hyperparameters(sagemaker_session):\n    job_details = copy.deepcopy(TUNING_JOB_DETAILS)\n    sagemaker_session.sagemaker_client.describe_hyper_parameter_tuning_job = Mock(\n        name=""describe_tuning_job"", return_value=job_details\n    )\n    tuner = HyperparameterTuner.attach(JOB_NAME, sagemaker_session=sagemaker_session)\n\n    assert tuner.latest_tuning_job.name == JOB_NAME\n    assert tuner.objective_metric_name == OBJECTIVE_METRIC_NAME\n    assert tuner.max_jobs == 1\n    assert tuner.max_parallel_jobs == 1\n    assert tuner.metric_definitions == METRIC_DEFINITIONS\n    assert tuner.strategy == ""Bayesian""\n    assert tuner.objective_type == ""Minimize""\n    assert tuner.early_stopping_type == ""Off""\n\n    assert isinstance(tuner.estimator, PCA)\n    assert tuner.estimator.role == ROLE\n    assert tuner.estimator.train_instance_count == 1\n    assert tuner.estimator.train_max_run == 24 * 60 * 60\n    assert tuner.estimator.input_mode == ""File""\n    assert tuner.estimator.output_path == BUCKET_NAME\n    assert tuner.estimator.output_kms_key == """"\n\n    assert ""_tuning_objective_metric"" not in tuner.estimator.hyperparameters()\n    assert tuner.estimator.hyperparameters()[""num_components""] == ""10""\n\n\ndef test_attach_tuning_job_with_estimator_from_hyperparameters_with_early_stopping(\n    sagemaker_session\n):\n    job_details = copy.deepcopy(TUNING_JOB_DETAILS)\n    job_details[""HyperParameterTuningJobConfig""][""TrainingJobEarlyStoppingType""] = ""Auto""\n    sagemaker_session.sagemaker_client.describe_hyper_parameter_tuning_job = Mock(\n        name=""describe_tuning_job"", return_value=job_details\n    )\n    tuner = HyperparameterTuner.attach(JOB_NAME, sagemaker_session=sagemaker_session)\n\n    assert tuner.latest_tuning_job.name == JOB_NAME\n    assert tuner.early_stopping_type == ""Auto""\n\n    assert isinstance(tuner.estimator, PCA)\n\n\ndef test_attach_tuning_job_with_job_details(sagemaker_session):\n    job_details = copy.deepcopy(TUNING_JOB_DETAILS)\n    HyperparameterTuner.attach(\n        JOB_NAME, sagemaker_session=sagemaker_session, job_details=job_details\n    )\n    sagemaker_session.sagemaker_client.describe_hyper_parameter_tuning_job.assert_not_called\n\n\ndef test_attach_tuning_job_with_estimator_from_image(sagemaker_session):\n    job_details = copy.deepcopy(TUNING_JOB_DETAILS)\n    job_details[""TrainingJobDefinition""][""AlgorithmSpecification""][\n        ""TrainingImage""\n    ] = ""1111.amazonaws.com/pca:1""\n    sagemaker_session.sagemaker_client.describe_hyper_parameter_tuning_job = Mock(\n        name=""describe_tuning_job"", return_value=job_details\n    )\n\n    tuner = HyperparameterTuner.attach(JOB_NAME, sagemaker_session=sagemaker_session)\n    assert isinstance(tuner.estimator, PCA)\n\n\ndef test_attach_tuning_job_with_estimator_from_kwarg(sagemaker_session):\n    job_details = copy.deepcopy(TUNING_JOB_DETAILS)\n    sagemaker_session.sagemaker_client.describe_hyper_parameter_tuning_job = Mock(\n        name=""describe_tuning_job"", return_value=job_details\n    )\n    tuner = HyperparameterTuner.attach(\n        JOB_NAME, sagemaker_session=sagemaker_session, estimator_cls=""sagemaker.estimator.Estimator""\n    )\n    assert isinstance(tuner.estimator, Estimator)\n\n\ndef test_attach_with_no_specified_estimator(sagemaker_session):\n    job_details = copy.deepcopy(TUNING_JOB_DETAILS)\n    del job_details[""TrainingJobDefinition""][""StaticHyperParameters""][""sagemaker_estimator_module""]\n    del job_details[""TrainingJobDefinition""][""StaticHyperParameters""][\n        ""sagemaker_estimator_class_name""\n    ]\n    sagemaker_session.sagemaker_client.describe_hyper_parameter_tuning_job = Mock(\n        name=""describe_tuning_job"", return_value=job_details\n    )\n\n    tuner = HyperparameterTuner.attach(JOB_NAME, sagemaker_session=sagemaker_session)\n    assert isinstance(tuner.estimator, Estimator)\n\n\ndef test_attach_with_warm_start_config(sagemaker_session):\n    warm_start_config = WarmStartConfig(\n        warm_start_type=WarmStartTypes.TRANSFER_LEARNING, parents={""p1"", ""p2""}\n    )\n    job_details = copy.deepcopy(TUNING_JOB_DETAILS)\n    job_details[""WarmStartConfig""] = warm_start_config.to_input_req()\n\n    sagemaker_session.sagemaker_client.describe_hyper_parameter_tuning_job = Mock(\n        name=""describe_tuning_job"", return_value=job_details\n    )\n\n    tuner = HyperparameterTuner.attach(JOB_NAME, sagemaker_session=sagemaker_session)\n    assert tuner.warm_start_config.type == warm_start_config.type\n    assert tuner.warm_start_config.parents == warm_start_config.parents\n\n\ndef test_attach_tuning_job_with_multi_estimators(sagemaker_session):\n    job_details = copy.deepcopy(MULTI_ALGO_TUNING_JOB_DETAILS)\n    tuner = HyperparameterTuner.attach(\n        JOB_NAME,\n        sagemaker_session=sagemaker_session,\n        estimator_cls={ESTIMATOR_NAME_TWO: ""sagemaker.estimator.Estimator""},\n        job_details=job_details,\n    )\n\n    assert tuner.latest_tuning_job.name == JOB_NAME\n    assert tuner.strategy == ""Bayesian""\n    assert tuner.objective_type == ""Minimize""\n    assert tuner.max_jobs == 4\n    assert tuner.max_parallel_jobs == 2\n    assert tuner.early_stopping_type == ""Off""\n    assert tuner.warm_start_config is None\n\n    assert tuner.estimator is None\n    assert tuner.objective_metric_name is None\n    assert tuner._hyperparameter_ranges is None\n    assert tuner.metric_definitions is None\n\n    assert tuner.estimator_dict is not None\n    assert tuner.objective_metric_name_dict is not None\n    assert tuner._hyperparameter_ranges_dict is not None\n    assert tuner.metric_definitions_dict is not None\n\n    assert len(tuner.estimator_dict) == 2\n\n    estimator_names = tuner.estimator_dict.keys()\n    assert tuner.objective_metric_name_dict.keys() == estimator_names\n    assert tuner._hyperparameter_ranges_dict.keys() == estimator_names\n    assert set(tuner.metric_definitions_dict.keys()).issubset(set(estimator_names))\n\n    assert isinstance(tuner.estimator_dict[ESTIMATOR_NAME], PCA)\n    assert isinstance(tuner.estimator_dict[ESTIMATOR_NAME_TWO], Estimator)\n\n    assert tuner.objective_metric_name_dict[ESTIMATOR_NAME] == OBJECTIVE_METRIC_NAME\n    assert tuner.objective_metric_name_dict[ESTIMATOR_NAME_TWO] == OBJECTIVE_METRIC_NAME_TWO\n\n    parameter_ranges_one = tuner._hyperparameter_ranges_dict[ESTIMATOR_NAME]\n    assert len(parameter_ranges_one) == 1\n    assert isinstance(parameter_ranges_one.get(""mini_batch_size"", None), IntegerParameter)\n\n    parameter_ranges_two = tuner._hyperparameter_ranges_dict[ESTIMATOR_NAME_TWO]\n    assert len(parameter_ranges_two) == 2\n    assert isinstance(parameter_ranges_two.get(""kernel"", None), CategoricalParameter)\n    assert isinstance(parameter_ranges_two.get(""tree_count"", None), IntegerParameter)\n\n    assert len(tuner.metric_definitions_dict) == 1\n    assert tuner.metric_definitions_dict[ESTIMATOR_NAME_TWO] == METRIC_DEFINITIONS\n\n\ndef test_serialize_parameter_ranges(tuner):\n    hyperparameter_ranges = tuner.hyperparameter_ranges()\n\n    for key, value in HYPERPARAMETER_RANGES.items():\n        assert hyperparameter_ranges[value.__name__ + ""ParameterRanges""][0][""Name""] == key\n\n\ndef test_analytics(tuner):\n    tuner.latest_tuning_job = _TuningJob(tuner.sagemaker_session, ""testjob"")\n    tuner_analytics = tuner.analytics()\n    assert tuner_analytics is not None\n    assert tuner_analytics.name.find(""testjob"") > -1\n\n\ndef test_serialize_categorical_ranges_for_frameworks(sagemaker_session, tuner):\n    tuner.estimator = MXNet(\n        entry_point=SCRIPT_NAME,\n        role=ROLE,\n        framework_version=FRAMEWORK_VERSION,\n        train_instance_count=TRAIN_INSTANCE_COUNT,\n        train_instance_type=TRAIN_INSTANCE_TYPE,\n        sagemaker_session=sagemaker_session,\n    )\n\n    hyperparameter_ranges = tuner.hyperparameter_ranges()\n\n    assert hyperparameter_ranges[""CategoricalParameterRanges""][0][""Name""] == ""blank""\n    assert hyperparameter_ranges[""CategoricalParameterRanges""][0][""Values""] == [\'""0""\', \'""5""\']\n\n\ndef test_serialize_nonexistent_parameter_ranges(tuner):\n    temp_hyperparameter_ranges = HYPERPARAMETER_RANGES.copy()\n    parameter_type = temp_hyperparameter_ranges[""validated""].__name__\n\n    temp_hyperparameter_ranges[""validated""] = None\n    tuner._hyperparameter_ranges = temp_hyperparameter_ranges\n\n    ranges = tuner.hyperparameter_ranges()\n    assert len(ranges.keys()) == 3\n    assert not ranges[parameter_type + ""ParameterRanges""]\n\n\ndef test_stop_tuning_job(sagemaker_session, tuner):\n    sagemaker_session.stop_tuning_job = Mock(name=""stop_hyper_parameter_tuning_job"")\n    tuner.latest_tuning_job = _TuningJob(sagemaker_session, JOB_NAME)\n\n    tuner.stop_tuning_job()\n\n    sagemaker_session.stop_tuning_job.assert_called_once_with(name=JOB_NAME)\n\n\ndef test_stop_tuning_job_no_tuning_job(tuner):\n    with pytest.raises(ValueError) as e:\n        tuner.stop_tuning_job()\n    assert ""No tuning job available"" in str(e)\n\n\ndef test_best_tuning_job(tuner):\n    tuning_job_description = {""BestTrainingJob"": {""TrainingJobName"": JOB_NAME}}\n\n    tuner.estimator.sagemaker_session.sagemaker_client.describe_hyper_parameter_tuning_job = Mock(\n        name=""describe_hyper_parameter_tuning_job"", return_value=tuning_job_description\n    )\n\n    tuner.latest_tuning_job = _TuningJob(tuner.estimator.sagemaker_session, JOB_NAME)\n    best_training_job = tuner.best_training_job()\n\n    assert best_training_job == JOB_NAME\n    tuner.estimator.sagemaker_session.sagemaker_client.describe_hyper_parameter_tuning_job.assert_called_once_with(\n        HyperParameterTuningJobName=JOB_NAME\n    )\n\n\ndef test_best_tuning_job_no_latest_job(tuner):\n    with pytest.raises(Exception) as e:\n        tuner.best_training_job()\n\n    assert ""No tuning job available"" in str(e)\n\n\ndef test_best_tuning_job_no_best_job(tuner):\n    tuning_job_description = {""TuningJobName"": ""a_job""}\n\n    tuner.estimator.sagemaker_session.sagemaker_client.describe_hyper_parameter_tuning_job = Mock(\n        name=""describe_hyper_parameter_tuning_job"", return_value=tuning_job_description\n    )\n\n    tuner.latest_tuning_job = _TuningJob(tuner.estimator.sagemaker_session, JOB_NAME)\n\n    with pytest.raises(Exception) as e:\n        tuner.best_training_job()\n\n    tuner.estimator.sagemaker_session.sagemaker_client.describe_hyper_parameter_tuning_job.assert_called_once_with(\n        HyperParameterTuningJobName=JOB_NAME\n    )\n    assert ""Best training job not available for tuning job:"" in str(e)\n\n\ndef test_best_estimator(tuner):\n    tuner.sagemaker_session.sagemaker_client.describe_training_job = Mock(\n        name=""describe_training_job"", return_value=TRAINING_JOB_DESCRIPTION\n    )\n\n    tuner.sagemaker_session.sagemaker_client.describe_hyper_parameter_tuning_job = Mock(\n        name=""describe_hyper_parameter_tuning_job"",\n        return_value={""BestTrainingJob"": {""TrainingJobName"": TRAINING_JOB_NAME}},\n    )\n\n    tuner.sagemaker_session.sagemaker_client.list_tags = Mock(\n        name=""list_tags"", return_value=LIST_TAGS_RESULT\n    )\n\n    tuner.sagemaker_session.log_for_jobs = Mock(name=""log_for_jobs"")\n    tuner.latest_tuning_job = _TuningJob(tuner.sagemaker_session, JOB_NAME)\n\n    best_estimator = tuner.best_estimator()\n\n    assert best_estimator is not None\n    assert best_estimator.latest_training_job is not None\n    assert best_estimator.latest_training_job.job_name == TRAINING_JOB_NAME\n    assert best_estimator.sagemaker_session == tuner.sagemaker_session\n\n    tuner.estimator.sagemaker_session.sagemaker_client.describe_hyper_parameter_tuning_job.assert_called_once_with(\n        HyperParameterTuningJobName=JOB_NAME\n    )\n    tuner.sagemaker_session.sagemaker_client.describe_training_job.assert_called_once_with(\n        TrainingJobName=TRAINING_JOB_NAME\n    )\n\n\ndef test_deploy_default(tuner):\n    tuner.sagemaker_session.sagemaker_client.describe_training_job = Mock(\n        name=""describe_training_job"", return_value=TRAINING_JOB_DESCRIPTION\n    )\n\n    tuner.sagemaker_session.sagemaker_client.describe_hyper_parameter_tuning_job = Mock(\n        name=""describe_hyper_parameter_tuning_job"",\n        return_value={""BestTrainingJob"": {""TrainingJobName"": JOB_NAME}},\n    )\n\n    tuner.sagemaker_session.sagemaker_client.list_tags = Mock(\n        name=""list_tags"", return_value=LIST_TAGS_RESULT\n    )\n\n    tuner.sagemaker_session.log_for_jobs = Mock(name=""log_for_jobs"")\n\n    tuner.latest_tuning_job = _TuningJob(tuner.sagemaker_session, JOB_NAME)\n    predictor = tuner.deploy(TRAIN_INSTANCE_COUNT, TRAIN_INSTANCE_TYPE)\n\n    tuner.sagemaker_session.create_model.assert_called_once()\n    args = tuner.sagemaker_session.create_model.call_args[0]\n    assert args[0] == TRAINING_JOB_NAME\n    assert args[1] == ROLE\n    assert args[2][""Image""] == IMAGE_NAME\n    assert args[2][""ModelDataUrl""] == MODEL_DATA\n\n    assert isinstance(predictor, RealTimePredictor)\n    assert predictor.endpoint.startswith(JOB_NAME)\n    assert predictor.sagemaker_session == tuner.sagemaker_session\n\n\ndef test_deploy_estimator_dict(tuner):\n    tuner.estimator_dict = {ESTIMATOR_NAME: tuner.estimator}\n    tuner.estimator = None\n\n    tuner.sagemaker_session.sagemaker_client.describe_training_job = Mock(\n        name=""describe_training_job"", return_value=TRAINING_JOB_DESCRIPTION\n    )\n\n    tuner.sagemaker_session.sagemaker_client.describe_hyper_parameter_tuning_job = Mock(\n        name=""describe_hyper_parameter_tuning_job"",\n        return_value={\n            ""BestTrainingJob"": {\n                ""TrainingJobName"": JOB_NAME,\n                ""TrainingJobDefinitionName"": ESTIMATOR_NAME,\n            }\n        },\n    )\n\n    tuner.sagemaker_session.sagemaker_client.list_tags = Mock(\n        name=""list_tags"", return_value=LIST_TAGS_RESULT\n    )\n\n    tuner.sagemaker_session.log_for_jobs = Mock(name=""log_for_jobs"")\n\n    tuner.latest_tuning_job = _TuningJob(tuner.sagemaker_session, JOB_NAME)\n    predictor = tuner.deploy(TRAIN_INSTANCE_COUNT, TRAIN_INSTANCE_TYPE)\n\n    tuner.sagemaker_session.create_model.assert_called_once()\n    args = tuner.sagemaker_session.create_model.call_args[0]\n    assert args[0] == TRAINING_JOB_NAME\n    assert args[1] == ROLE\n    assert args[2][""Image""] == IMAGE_NAME\n    assert args[2][""ModelDataUrl""] == MODEL_DATA\n\n    assert isinstance(predictor, RealTimePredictor)\n    assert predictor.endpoint.startswith(JOB_NAME)\n    assert predictor.sagemaker_session == tuner.sagemaker_session\n\n\n@patch(""sagemaker.tuner.HyperparameterTuner.best_estimator"")\n@patch(""sagemaker.tuner.HyperparameterTuner._get_best_training_job"")\ndef test_deploy_optional_params(_get_best_training_job, best_estimator, tuner):\n    tuner.fit()\n\n    estimator = Mock()\n    best_estimator.return_value = estimator\n\n    training_job = ""best-job-ever""\n    _get_best_training_job.return_value = training_job\n\n    accelerator = ""ml.eia1.medium""\n    endpoint_name = ""foo""\n    model_name = ""bar""\n    kms_key = ""key""\n    kwargs = {""some_arg"": ""some_value""}\n\n    tuner.deploy(\n        TRAIN_INSTANCE_COUNT,\n        TRAIN_INSTANCE_TYPE,\n        accelerator_type=accelerator,\n        endpoint_name=endpoint_name,\n        wait=False,\n        model_name=model_name,\n        kms_key=kms_key,\n        **kwargs\n    )\n\n    best_estimator.assert_called_with(training_job)\n\n    estimator.deploy.assert_called_with(\n        initial_instance_count=TRAIN_INSTANCE_COUNT,\n        instance_type=TRAIN_INSTANCE_TYPE,\n        accelerator_type=accelerator,\n        endpoint_name=endpoint_name,\n        wait=False,\n        model_name=model_name,\n        kms_key=kms_key,\n        data_capture_config=None,\n        **kwargs\n    )\n\n\ndef test_wait(tuner):\n    tuner.latest_tuning_job = _TuningJob(tuner.estimator.sagemaker_session, JOB_NAME)\n    tuner.estimator.sagemaker_session.wait_for_tuning_job = Mock(name=""wait_for_tuning_job"")\n\n    tuner.wait()\n\n    tuner.estimator.sagemaker_session.wait_for_tuning_job.assert_called_once_with(JOB_NAME)\n\n\ndef test_delete_endpoint(tuner):\n    tuner.latest_tuning_job = _TuningJob(tuner.estimator.sagemaker_session, JOB_NAME)\n\n    tuning_job_description = {""BestTrainingJob"": {""TrainingJobName"": JOB_NAME}}\n    tuner.estimator.sagemaker_session.sagemaker_client.describe_hyper_parameter_tuning_job = Mock(\n        name=""describe_hyper_parameter_tuning_job"", return_value=tuning_job_description\n    )\n\n    tuner.delete_endpoint()\n    tuner.sagemaker_session.delete_endpoint.assert_called_with(JOB_NAME)\n\n\ndef test_fit_no_inputs(tuner, sagemaker_session):\n    script_path = os.path.join(DATA_DIR, ""mxnet_mnist"", ""failure_script.py"")\n    tuner.estimator = MXNet(\n        entry_point=script_path,\n        role=ROLE,\n        framework_version=FRAMEWORK_VERSION,\n        train_instance_count=TRAIN_INSTANCE_COUNT,\n        train_instance_type=TRAIN_INSTANCE_TYPE,\n        sagemaker_session=sagemaker_session,\n    )\n\n    tuner.fit()\n\n    _, _, tune_kwargs = sagemaker_session.create_tuning_job.mock_calls[0]\n\n    assert tune_kwargs[""training_config""][""input_config""] is None\n\n\ndef test_identical_dataset_and_algorithm_tuner(sagemaker_session):\n    job_details = copy.deepcopy(TUNING_JOB_DETAILS)\n    sagemaker_session.sagemaker_client.describe_hyper_parameter_tuning_job = Mock(\n        name=""describe_tuning_job"", return_value=job_details\n    )\n\n    tuner = HyperparameterTuner.attach(JOB_NAME, sagemaker_session=sagemaker_session)\n    parent_tuner = tuner.identical_dataset_and_algorithm_tuner(additional_parents={""p1"", ""p2""})\n    assert parent_tuner.warm_start_config.type == WarmStartTypes.IDENTICAL_DATA_AND_ALGORITHM\n    assert parent_tuner.warm_start_config.parents == {tuner.latest_tuning_job.name, ""p1"", ""p2""}\n\n\ndef test_transfer_learning_tuner_with_estimator(sagemaker_session, estimator):\n    job_details = copy.deepcopy(TUNING_JOB_DETAILS)\n    sagemaker_session.sagemaker_client.describe_hyper_parameter_tuning_job = Mock(\n        name=""describe_tuning_job"", return_value=job_details\n    )\n\n    tuner = HyperparameterTuner.attach(JOB_NAME, sagemaker_session=sagemaker_session)\n    parent_tuner = tuner.transfer_learning_tuner(\n        additional_parents={""p1"", ""p2""}, estimator=estimator\n    )\n\n    assert parent_tuner.warm_start_config.type == WarmStartTypes.TRANSFER_LEARNING\n    assert parent_tuner.warm_start_config.parents == {tuner.latest_tuning_job.name, ""p1"", ""p2""}\n    assert parent_tuner.estimator == estimator and parent_tuner.estimator != tuner.estimator\n\n\ndef test_transfer_learning_tuner(sagemaker_session):\n    job_details = copy.deepcopy(TUNING_JOB_DETAILS)\n    sagemaker_session.sagemaker_client.describe_hyper_parameter_tuning_job = Mock(\n        name=""describe_tuning_job"", return_value=job_details\n    )\n\n    tuner = HyperparameterTuner.attach(JOB_NAME, sagemaker_session=sagemaker_session)\n    parent_tuner = tuner.transfer_learning_tuner(additional_parents={""p1"", ""p2""})\n\n    assert parent_tuner.warm_start_config.type == WarmStartTypes.TRANSFER_LEARNING\n    assert parent_tuner.warm_start_config.parents == {tuner.latest_tuning_job.name, ""p1"", ""p2""}\n    assert parent_tuner.estimator == tuner.estimator\n\n\n@pytest.mark.parametrize(\n    ""estimator_dict,obj_metric_name_dict,param_ranges_dict,metric_def_dict"",\n    [\n        (\n            {ESTIMATOR_NAME: ESTIMATOR},\n            {ESTIMATOR_NAME: OBJECTIVE_METRIC_NAME},\n            {ESTIMATOR_NAME: HYPERPARAMETER_RANGES},\n            {ESTIMATOR_NAME: METRIC_DEFINITIONS},\n        ),\n        (\n            {ESTIMATOR_NAME: ESTIMATOR, ESTIMATOR_NAME_TWO: ESTIMATOR_TWO},\n            {ESTIMATOR_NAME: OBJECTIVE_METRIC_NAME, ESTIMATOR_NAME_TWO: OBJECTIVE_METRIC_NAME_TWO},\n            {\n                ESTIMATOR_NAME: HYPERPARAMETER_RANGES,\n                ESTIMATOR_NAME_TWO: {""gamma"": ContinuousParameter(0, 1.5)},\n            },\n            {ESTIMATOR_NAME: METRIC_DEFINITIONS},\n        ),\n    ],\n)\ndef test_create_tuner(estimator_dict, obj_metric_name_dict, param_ranges_dict, metric_def_dict):\n    tuner = HyperparameterTuner.create(\n        base_tuning_job_name=BASE_JOB_NAME,\n        estimator_dict=estimator_dict,\n        objective_metric_name_dict=obj_metric_name_dict,\n        hyperparameter_ranges_dict=param_ranges_dict,\n        metric_definitions_dict=metric_def_dict,\n        strategy=""Bayesian"",\n        objective_type=""Minimize"",\n        max_jobs=MAX_JOBS,\n        max_parallel_jobs=MAX_PARALLEL_JOBS,\n        tags=TAGS,\n        warm_start_config=WARM_START_CONFIG,\n        early_stopping_type=""Auto"",\n    )\n\n    assert tuner is not None\n\n    assert tuner.estimator_dict == estimator_dict\n    assert tuner.objective_metric_name_dict == obj_metric_name_dict\n    assert tuner._hyperparameter_ranges_dict == param_ranges_dict\n    assert tuner.metric_definitions_dict == metric_def_dict\n\n    assert tuner.base_tuning_job_name == BASE_JOB_NAME\n    assert tuner.strategy == ""Bayesian""\n    assert tuner.objective_type == ""Minimize""\n    assert tuner.max_jobs == MAX_JOBS\n    assert tuner.max_parallel_jobs == MAX_PARALLEL_JOBS\n    assert tuner.tags == TAGS\n    assert tuner.warm_start_config == WARM_START_CONFIG\n    assert tuner.early_stopping_type == ""Auto""\n\n    assert tuner.sagemaker_session == SAGEMAKER_SESSION\n\n\n@pytest.mark.parametrize(\n    ""estimator_dict,obj_metric_name_dict,param_ranges_dict,metric_def_dict,error_message"",\n    [\n        (\n            {},\n            {ESTIMATOR_NAME: OBJECTIVE_METRIC_NAME},\n            {ESTIMATOR_NAME: HYPERPARAMETER_RANGES},\n            {ESTIMATOR_NAME: METRIC_DEFINITIONS},\n            re.compile(""At least one estimator should be provided""),\n        ),\n        (\n            None,\n            {ESTIMATOR_NAME: OBJECTIVE_METRIC_NAME},\n            {ESTIMATOR_NAME: HYPERPARAMETER_RANGES},\n            {ESTIMATOR_NAME: METRIC_DEFINITIONS},\n            re.compile(""At least one estimator should be provided""),\n        ),\n        (\n            {None: ESTIMATOR},\n            {ESTIMATOR_NAME: OBJECTIVE_METRIC_NAME},\n            {ESTIMATOR_NAME: HYPERPARAMETER_RANGES},\n            {ESTIMATOR_NAME: METRIC_DEFINITIONS},\n            ""Estimator names cannot be None"",\n        ),\n        (\n            {ESTIMATOR_NAME: ESTIMATOR},\n            OBJECTIVE_METRIC_NAME,\n            {ESTIMATOR_NAME: HYPERPARAMETER_RANGES},\n            {ESTIMATOR_NAME: METRIC_DEFINITIONS},\n            re.compile(\n                ""Argument \'objective_metric_name_dict\' must be a dictionary using \\\\[\'estimator_name\'\\\\] as keys""\n            ),\n        ),\n        (\n            {ESTIMATOR_NAME: ESTIMATOR},\n            {ESTIMATOR_NAME + ""1"": OBJECTIVE_METRIC_NAME},\n            {ESTIMATOR_NAME: HYPERPARAMETER_RANGES},\n            {ESTIMATOR_NAME: METRIC_DEFINITIONS},\n            re.compile(\n                ""The keys of argument \'objective_metric_name_dict\' must be the same as \\\\[\'estimator_name\'\\\\]""\n            ),\n        ),\n        (\n            {ESTIMATOR_NAME: ESTIMATOR},\n            {ESTIMATOR_NAME: OBJECTIVE_METRIC_NAME},\n            {ESTIMATOR_NAME + ""1"": HYPERPARAMETER_RANGES},\n            {ESTIMATOR_NAME: METRIC_DEFINITIONS},\n            re.compile(\n                ""The keys of argument \'hyperparameter_ranges_dict\' must be the same as \\\\[\'estimator_name\'\\\\]""\n            ),\n        ),\n        (\n            {ESTIMATOR_NAME: ESTIMATOR},\n            {ESTIMATOR_NAME: OBJECTIVE_METRIC_NAME},\n            {ESTIMATOR_NAME: HYPERPARAMETER_RANGES},\n            {ESTIMATOR_NAME + ""1"": METRIC_DEFINITIONS},\n            re.compile(\n                ""The keys of argument \'metric_definitions_dict\' must be a subset of \\\\[\'estimator_name\'\\\\]""\n            ),\n        ),\n    ],\n)\ndef test_create_tuner_negative(\n    estimator_dict, obj_metric_name_dict, param_ranges_dict, metric_def_dict, error_message\n):\n    with pytest.raises(ValueError, match=error_message):\n        HyperparameterTuner.create(\n            base_tuning_job_name=BASE_JOB_NAME,\n            estimator_dict=estimator_dict,\n            objective_metric_name_dict=obj_metric_name_dict,\n            hyperparameter_ranges_dict=param_ranges_dict,\n            metric_definitions_dict=metric_def_dict,\n            strategy=""Bayesian"",\n            objective_type=""Minimize"",\n            max_jobs=MAX_JOBS,\n            max_parallel_jobs=MAX_PARALLEL_JOBS,\n            tags=TAGS,\n        )\n\n\n#################################################################################\n# _ParameterRange Tests\n\n\ndef test_continuous_parameter():\n    cont_param = ContinuousParameter(0.1, 1e-2)\n    assert isinstance(cont_param, ParameterRange)\n    assert cont_param.__name__ == ""Continuous""\n\n\ndef test_continuous_parameter_ranges():\n    cont_param = ContinuousParameter(0.1, 1e-2)\n    ranges = cont_param.as_tuning_range(""some"")\n    assert len(ranges.keys()) == 4\n    assert ranges[""Name""] == ""some""\n    assert ranges[""MinValue""] == ""0.1""\n    assert ranges[""MaxValue""] == ""0.01""\n    assert ranges[""ScalingType""] == ""Auto""\n\n\ndef test_continuous_parameter_scaling_type():\n    cont_param = ContinuousParameter(0.1, 2, scaling_type=""ReverseLogarithmic"")\n    cont_range = cont_param.as_tuning_range(""range"")\n    assert cont_range[""ScalingType""] == ""ReverseLogarithmic""\n\n\ndef test_integer_parameter():\n    int_param = IntegerParameter(1, 2)\n    assert isinstance(int_param, ParameterRange)\n    assert int_param.__name__ == ""Integer""\n\n\ndef test_integer_parameter_ranges():\n    int_param = IntegerParameter(1, 2)\n    ranges = int_param.as_tuning_range(""some"")\n    assert len(ranges.keys()) == 4\n    assert ranges[""Name""] == ""some""\n    assert ranges[""MinValue""] == ""1""\n    assert ranges[""MaxValue""] == ""2""\n    assert ranges[""ScalingType""] == ""Auto""\n\n\ndef test_integer_parameter_scaling_type():\n    int_param = IntegerParameter(2, 3, scaling_type=""Linear"")\n    int_range = int_param.as_tuning_range(""range"")\n    assert int_range[""ScalingType""] == ""Linear""\n\n\ndef test_categorical_parameter_list():\n    cat_param = CategoricalParameter([""a"", ""z""])\n    assert isinstance(cat_param, ParameterRange)\n    assert cat_param.__name__ == ""Categorical""\n\n\ndef test_categorical_parameter_list_ranges():\n    cat_param = CategoricalParameter([1, 10])\n    ranges = cat_param.as_tuning_range(""some"")\n    assert len(ranges.keys()) == 2\n    assert ranges[""Name""] == ""some""\n    assert ranges[""Values""] == [""1"", ""10""]\n\n\ndef test_categorical_parameter_value():\n    cat_param = CategoricalParameter(""a"")\n    assert isinstance(cat_param, ParameterRange)\n\n\ndef test_categorical_parameter_value_ranges():\n    cat_param = CategoricalParameter(""a"")\n    ranges = cat_param.as_tuning_range(""some"")\n    assert len(ranges.keys()) == 2\n    assert ranges[""Name""] == ""some""\n    assert ranges[""Values""] == [""a""]\n\n\n#################################################################################\n# _TuningJob Tests\n\n\ndef test_start_new(tuner, sagemaker_session):\n    tuning_job = _TuningJob(sagemaker_session, JOB_NAME)\n\n    tuner.static_hyperparameters = {}\n    started_tuning_job = tuning_job.start_new(tuner, INPUTS)\n\n    assert started_tuning_job.sagemaker_session == sagemaker_session\n    sagemaker_session.create_tuning_job.assert_called_once()\n\n\ndef test_stop(sagemaker_session):\n    tuning_job = _TuningJob(sagemaker_session, JOB_NAME)\n    tuning_job.stop()\n\n    sagemaker_session.stop_tuning_job.assert_called_once_with(name=JOB_NAME)\n\n\ndef test_tuning_job_wait(sagemaker_session):\n    sagemaker_session.wait_for_tuning_job = Mock(name=""wait_for_tuning_job"")\n\n    tuning_job = _TuningJob(sagemaker_session, JOB_NAME)\n    tuning_job.wait()\n\n    sagemaker_session.wait_for_tuning_job.assert_called_once_with(JOB_NAME)\n\n\n#################################################################################\n# WarmStartConfig Tests\n\n\n@pytest.mark.parametrize(\n    ""type, parents"",\n    [\n        (WarmStartTypes.IDENTICAL_DATA_AND_ALGORITHM, {""p1"", ""p2"", ""p3""}),\n        (WarmStartTypes.IDENTICAL_DATA_AND_ALGORITHM, {""p1"", ""p3"", ""p3""}),\n        (WarmStartTypes.TRANSFER_LEARNING, {""p3""}),\n    ],\n)\ndef test_warm_start_config_init(type, parents):\n    warm_start_config = WarmStartConfig(warm_start_type=type, parents=parents)\n\n    assert warm_start_config.type == type, ""Warm start type initialization failed.""\n    assert warm_start_config.parents == set(\n        parents\n    ), ""Warm start parents config initialization failed.""\n\n    warm_start_config_req = warm_start_config.to_input_req()\n    assert warm_start_config.type == WarmStartTypes(warm_start_config_req[""WarmStartType""])\n    for parent in warm_start_config_req[""ParentHyperParameterTuningJobs""]:\n        assert parent[""HyperParameterTuningJobName""] in parents\n\n\n@pytest.mark.parametrize(\n    ""type, parents"",\n    [\n        (""InvalidType"", {""p1"", ""p2"", ""p3""}),\n        (None, {""p1"", ""p2"", ""p3""}),\n        ("""", {""p1"", ""p2"", ""p3""}),\n        (WarmStartTypes.TRANSFER_LEARNING, None),\n        (WarmStartTypes.TRANSFER_LEARNING, {}),\n    ],\n)\ndef test_warm_start_config_init_negative(type, parents):\n    with pytest.raises(ValueError):\n        WarmStartConfig(warm_start_type=type, parents=parents)\n\n\n@pytest.mark.parametrize(\n    ""warm_start_config_req"",\n    [\n        ({}),\n        (None),\n        ({""WarmStartType"": ""TransferLearning""}),\n        ({""ParentHyperParameterTuningJobs"": []}),\n    ],\n)\ndef test_prepare_warm_start_config_cls_negative(warm_start_config_req):\n    warm_start_config = WarmStartConfig.from_job_desc(warm_start_config_req)\n    assert warm_start_config is None, ""Warm start config should be None for invalid type/parents""\n\n\n@pytest.mark.parametrize(\n    ""warm_start_config_req"",\n    [\n        (\n            {\n                ""WarmStartType"": ""TransferLearning"",\n                ""ParentHyperParameterTuningJobs"": [\n                    {""HyperParameterTuningJobName"": ""p1""},\n                    {""HyperParameterTuningJobName"": ""p2""},\n                ],\n            }\n        ),\n        (\n            {\n                ""WarmStartType"": ""IdenticalDataAndAlgorithm"",\n                ""ParentHyperParameterTuningJobs"": [\n                    {""HyperParameterTuningJobName"": ""p1""},\n                    {""HyperParameterTuningJobName"": ""p1""},\n                ],\n            }\n        ),\n    ],\n)\ndef test_prepare_warm_start_config_cls(warm_start_config_req):\n    warm_start_config = WarmStartConfig.from_job_desc(warm_start_config_req)\n\n    assert warm_start_config.type == WarmStartTypes(\n        warm_start_config_req[""WarmStartType""]\n    ), ""Warm start type initialization failed.""\n\n    for p in warm_start_config_req[""ParentHyperParameterTuningJobs""]:\n        assert (\n            p[""HyperParameterTuningJobName""] in warm_start_config.parents\n        ), ""Warm start parents config initialization failed.""\n\n\n@pytest.mark.parametrize(""additional_parents"", [{""p1"", ""p2""}, {}, None])\ndef test_create_identical_dataset_and_algorithm_tuner(sagemaker_session, additional_parents):\n    job_details = copy.deepcopy(TUNING_JOB_DETAILS)\n    sagemaker_session.sagemaker_client.describe_hyper_parameter_tuning_job = Mock(\n        name=""describe_tuning_job"", return_value=job_details\n    )\n\n    tuner = create_identical_dataset_and_algorithm_tuner(\n        parent=JOB_NAME, additional_parents=additional_parents, sagemaker_session=sagemaker_session\n    )\n\n    assert tuner.warm_start_config.type == WarmStartTypes.IDENTICAL_DATA_AND_ALGORITHM\n    if additional_parents:\n        additional_parents.add(JOB_NAME)\n        assert tuner.warm_start_config.parents == additional_parents\n    else:\n        assert tuner.warm_start_config.parents == {JOB_NAME}\n\n\n@pytest.mark.parametrize(""additional_parents"", [{""p1"", ""p2""}, {}, None])\ndef test_create_transfer_learning_tuner(sagemaker_session, estimator, additional_parents):\n    job_details = copy.deepcopy(TUNING_JOB_DETAILS)\n    sagemaker_session.sagemaker_client.describe_hyper_parameter_tuning_job = Mock(\n        name=""describe_tuning_job"", return_value=job_details\n    )\n\n    tuner = create_transfer_learning_tuner(\n        parent=JOB_NAME,\n        additional_parents=additional_parents,\n        sagemaker_session=sagemaker_session,\n        estimator=estimator,\n    )\n\n    assert tuner.warm_start_config.type == WarmStartTypes.TRANSFER_LEARNING\n    assert tuner.estimator == estimator\n    if additional_parents:\n        additional_parents.add(JOB_NAME)\n        assert tuner.warm_start_config.parents == additional_parents\n    else:\n        assert tuner.warm_start_config.parents == {JOB_NAME}\n\n\n@pytest.mark.parametrize(\n    ""warm_start_type"",\n    [WarmStartTypes.TRANSFER_LEARNING, WarmStartTypes.IDENTICAL_DATA_AND_ALGORITHM],\n)\ndef test_create_warm_start_tuner_with_multi_estimator_dict(\n    sagemaker_session, estimator, warm_start_type\n):\n    job_details = copy.deepcopy(MULTI_ALGO_TUNING_JOB_DETAILS)\n\n    sagemaker_session.sagemaker_client.describe_hyper_parameter_tuning_job = Mock(\n        name=""describe_tuning_job"", return_value=job_details\n    )\n\n    additional_parents = {""p1"", ""p2""}\n\n    with pytest.raises(\n        ValueError,\n        match=""Warm start is not supported currently for tuners with multiple estimators"",\n    ):\n        if warm_start_type == WarmStartTypes.TRANSFER_LEARNING:\n            create_transfer_learning_tuner(\n                parent=JOB_NAME,\n                additional_parents=additional_parents,\n                sagemaker_session=sagemaker_session,\n                estimator=estimator,\n            )\n        else:\n            create_identical_dataset_and_algorithm_tuner(\n                parent=JOB_NAME,\n                additional_parents=additional_parents,\n                sagemaker_session=sagemaker_session,\n            )\n\n\n@pytest.mark.parametrize(\n    ""warm_start_type"",\n    [WarmStartTypes.TRANSFER_LEARNING, WarmStartTypes.IDENTICAL_DATA_AND_ALGORITHM],\n)\ndef test_create_warm_start_tuner_with_single_estimator_dict(\n    sagemaker_session, estimator, warm_start_type\n):\n    job_details = _convert_tuning_job_details(TUNING_JOB_DETAILS, ESTIMATOR_NAME)\n\n    sagemaker_session.sagemaker_client.describe_hyper_parameter_tuning_job = Mock(\n        name=""describe_tuning_job"", return_value=job_details\n    )\n\n    additional_parents = {""p1"", ""p2""}\n\n    if warm_start_type == WarmStartTypes.TRANSFER_LEARNING:\n        tuner = create_transfer_learning_tuner(\n            parent=JOB_NAME,\n            additional_parents=additional_parents,\n            sagemaker_session=sagemaker_session,\n            estimator=estimator,\n        )\n    else:\n        tuner = create_identical_dataset_and_algorithm_tuner(\n            parent=JOB_NAME,\n            additional_parents=additional_parents,\n            sagemaker_session=sagemaker_session,\n        )\n\n    assert tuner.warm_start_config.type == warm_start_type\n\n    assert tuner.estimator is None\n    assert tuner.estimator_dict is not None\n\n    assert len(tuner.estimator_dict) == 1\n\n    if warm_start_type == WarmStartTypes.TRANSFER_LEARNING:\n        assert tuner.estimator_dict[ESTIMATOR_NAME] == estimator\n    else:\n        assert isinstance(tuner.estimator_dict[ESTIMATOR_NAME], PCA)\n\n    additional_parents.add(JOB_NAME)\n    assert tuner.warm_start_config.parents == additional_parents\n\n\ndef _convert_tuning_job_details(job_details, estimator_name):\n    """"""Convert a tuning job description using the \'TrainingJobDefinition\' field into a new one using a single-item\n       \'TrainingJobDefinitions\' field (list).\n    """"""\n    assert ""TrainingJobDefinition"" in job_details\n\n    job_details_copy = copy.deepcopy(job_details)\n\n    training_details = job_details_copy.pop(""TrainingJobDefinition"")\n\n    # When the \'TrainingJobDefinitions\' field is used, the \'DefinitionName\' field is required for each item in it.\n    training_details[""DefinitionName""] = estimator_name\n\n    # When the \'TrainingJobDefinitions\' field is used, tuning objective and parameter ranges must be set in each item\n    # in it instead of the tuning job config.\n    training_details[""TuningObjective""] = job_details_copy[""HyperParameterTuningJobConfig""].pop(\n        ""HyperParameterTuningJobObjective""\n    )\n    training_details[""HyperParameterRanges""] = job_details_copy[\n        ""HyperParameterTuningJobConfig""\n    ].pop(""ParameterRanges"")\n\n    job_details_copy[""TrainingJobDefinitions""] = [training_details]\n\n    return job_details_copy\n'"
tests/unit/test_upload_data.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport os\n\nfrom mock import Mock\nimport pytest\n\nimport sagemaker\nfrom tests.unit import DATA_DIR\n\nUPLOAD_DATA_TESTS_FILES_DIR = os.path.join(DATA_DIR, ""upload_data_tests"")\nSINGLE_FILE_NAME = ""file1.py""\nUPLOAD_DATA_TESTS_SINGLE_FILE = os.path.join(UPLOAD_DATA_TESTS_FILES_DIR, SINGLE_FILE_NAME)\nBUCKET_NAME = ""mybucket""\nAES_ENCRYPTION_ENABLED = {""ServerSideEncryption"": ""AES256""}\nENDPOINT_URL = ""http://127.0.0.1:9000""\n\n\n@pytest.fixture()\ndef sagemaker_session():\n    boto_mock = Mock(name=""boto_session"")\n    ims = sagemaker.Session(boto_session=boto_mock)\n    ims.default_bucket = Mock(name=""default_bucket"", return_value=BUCKET_NAME)\n    return ims\n\n\n@pytest.fixture()\ndef sagemaker_session_custom_endpoint():\n\n    boto_session = Mock(""boto_session"")\n    resource_mock = Mock(""resource"")\n    client_mock = Mock(""client"")\n    boto_attrs = {""region_name"": ""us-east-1""}\n    boto_session.configure_mock(**boto_attrs)\n    boto_session.resource = Mock(name=""resource"", return_value=resource_mock)\n    boto_session.client = Mock(name=""client"", return_value=client_mock)\n\n    local_session = sagemaker.local.local_session.LocalSession(\n        boto_session=boto_session, s3_endpoint_url=ENDPOINT_URL\n    )\n\n    local_session.default_bucket = Mock(name=""default_bucket"", return_value=BUCKET_NAME)\n    return local_session\n\n\ndef test_upload_data_absolute_dir(sagemaker_session):\n    result_s3_uri = sagemaker_session.upload_data(UPLOAD_DATA_TESTS_FILES_DIR)\n\n    uploaded_files_with_args = [\n        (args[0], kwargs)\n        for name, args, kwargs in sagemaker_session.boto_session.mock_calls\n        if name == ""resource().Object().upload_file""\n    ]\n    assert result_s3_uri == ""s3://{}/data"".format(BUCKET_NAME)\n    assert len(uploaded_files_with_args) == 4\n    for file, kwargs in uploaded_files_with_args:\n        assert os.path.exists(file)\n        assert kwargs[""ExtraArgs""] is None\n\n\ndef test_upload_data_absolute_dir_custom_endpoint(sagemaker_session_custom_endpoint):\n\n    sagemaker_session_custom_endpoint.s3_resource.Object = Mock()\n\n    result_s3_uri = sagemaker_session_custom_endpoint.upload_data(UPLOAD_DATA_TESTS_FILES_DIR)\n\n    uploaded_files_with_args = [\n        (args[0], kwargs)\n        for name, args, kwargs in sagemaker_session_custom_endpoint.s3_resource.mock_calls\n        if name == ""Object().upload_file""\n    ]\n    assert result_s3_uri == ""s3://{}/data"".format(BUCKET_NAME)\n    assert len(uploaded_files_with_args) == 4\n    for file, kwargs in uploaded_files_with_args:\n        assert os.path.exists(file)\n        assert kwargs[""ExtraArgs""] is None\n\n\ndef test_upload_data_absolute_file(sagemaker_session):\n    result_s3_uri = sagemaker_session.upload_data(UPLOAD_DATA_TESTS_SINGLE_FILE)\n\n    uploaded_files_with_args = [\n        (args[0], kwargs)\n        for name, args, kwargs in sagemaker_session.boto_session.mock_calls\n        if name == ""resource().Object().upload_file""\n    ]\n    assert result_s3_uri == ""s3://{}/data/{}"".format(BUCKET_NAME, SINGLE_FILE_NAME)\n    assert len(uploaded_files_with_args) == 1\n    (file, kwargs) = uploaded_files_with_args[0]\n    assert os.path.exists(file)\n    assert kwargs[""ExtraArgs""] is None\n\n\ndef test_upload_data_aes_encrypted_absolute_dir(sagemaker_session):\n    result_s3_uri = sagemaker_session.upload_data(\n        UPLOAD_DATA_TESTS_FILES_DIR, extra_args=AES_ENCRYPTION_ENABLED\n    )\n\n    uploaded_files_with_args = [\n        (args[0], kwargs)\n        for name, args, kwargs in sagemaker_session.boto_session.mock_calls\n        if name == ""resource().Object().upload_file""\n    ]\n    assert result_s3_uri == ""s3://{}/data"".format(BUCKET_NAME)\n    assert len(uploaded_files_with_args) == 4\n    for file, kwargs in uploaded_files_with_args:\n        assert os.path.exists(file)\n        assert kwargs[""ExtraArgs""] == AES_ENCRYPTION_ENABLED\n\n\ndef test_upload_data_aes_encrypted_absolute_file(sagemaker_session):\n    result_s3_uri = sagemaker_session.upload_data(\n        UPLOAD_DATA_TESTS_SINGLE_FILE, extra_args=AES_ENCRYPTION_ENABLED\n    )\n\n    uploaded_files_with_args = [\n        (args[0], kwargs)\n        for name, args, kwargs in sagemaker_session.boto_session.mock_calls\n        if name == ""resource().Object().upload_file""\n    ]\n    assert result_s3_uri == ""s3://{}/data/{}"".format(BUCKET_NAME, SINGLE_FILE_NAME)\n    assert len(uploaded_files_with_args) == 1\n    (file, kwargs) = uploaded_files_with_args[0]\n    assert os.path.exists(file)\n    assert kwargs[""ExtraArgs""] == AES_ENCRYPTION_ENABLED\n'"
tests/unit/test_upload_string_as_file_body.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport os\n\nfrom mock import Mock\nimport pytest\n\nimport sagemaker\n\nUPLOAD_DATA_TESTS_FILE_DIR = ""upload_data_tests""\nSINGLE_FILE_NAME = ""file1.py""\nBODY = \'print(""test"")\'\nDESTINATION_DATA_TESTS_FILE = os.path.join(UPLOAD_DATA_TESTS_FILE_DIR, SINGLE_FILE_NAME)\nBUCKET_NAME = ""mybucket""\nAES_ENCRYPTION_ENABLED = {""ServerSideEncryption"": ""AES256""}\n\n\n@pytest.fixture()\ndef sagemaker_session():\n    boto_mock = Mock(name=""boto_session"")\n    client_mock = Mock()\n    client_mock.get_caller_identity.return_value = {\n        ""UserId"": ""mock_user_id"",\n        ""Account"": ""012345678910"",\n        ""Arn"": ""arn:aws:iam::012345678910:user/mock-user"",\n    }\n    boto_mock.client.return_value = client_mock\n    ims = sagemaker.Session(boto_session=boto_mock)\n    ims.default_bucket = Mock(name=""default_bucket"", return_value=BUCKET_NAME)\n    return ims\n\n\ndef test_upload_string_file(sagemaker_session):\n    result_s3_uri = sagemaker_session.upload_string_as_file_body(\n        body=BODY, bucket=BUCKET_NAME, key=DESTINATION_DATA_TESTS_FILE\n    )\n\n    uploaded_files_with_args = [\n        kwargs\n        for name, args, kwargs in sagemaker_session.boto_session.mock_calls\n        if name == ""resource().Object().put""\n    ]\n\n    assert result_s3_uri == ""s3://{}/{}"".format(BUCKET_NAME, DESTINATION_DATA_TESTS_FILE)\n    assert len(uploaded_files_with_args) == 1\n    kwargs = uploaded_files_with_args[0]\n    assert kwargs[""Body""] == BODY\n\n\ndef test_upload_aes_encrypted_string_file(sagemaker_session):\n    result_s3_uri = sagemaker_session.upload_string_as_file_body(\n        body=BODY,\n        bucket=BUCKET_NAME,\n        key=DESTINATION_DATA_TESTS_FILE,\n        kms_key=AES_ENCRYPTION_ENABLED,\n    )\n\n    uploaded_files_with_args = [\n        kwargs\n        for name, args, kwargs in sagemaker_session.boto_session.mock_calls\n        if name == ""resource().Object().put""\n    ]\n\n    assert result_s3_uri == ""s3://{}/{}"".format(BUCKET_NAME, DESTINATION_DATA_TESTS_FILE)\n    assert len(uploaded_files_with_args) == 1\n    kwargs = uploaded_files_with_args[0]\n    assert kwargs[""Body""] == BODY\n    assert kwargs[""SSEKMSKeyId""] == AES_ENCRYPTION_ENABLED\n'"
tests/unit/test_utils.py,0,"b'# -*- coding: utf-8 -*-\n\n# Copyright 2018-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport shutil\nimport tarfile\nfrom datetime import datetime\nimport os\nimport re\nimport time\n\nfrom boto3 import exceptions\nimport botocore\nimport pytest\nfrom mock import call, patch, Mock, MagicMock\n\nimport sagemaker\n\nBUCKET_WITHOUT_WRITING_PERMISSION = ""s3://bucket-without-writing-permission""\n\nNAME = ""base_name""\nBUCKET_NAME = ""some_bucket""\n\n\ndef test_get_config_value():\n\n    config = {""local"": {""region_name"": ""us-west-2"", ""port"": ""123""}, ""other"": {""key"": 1}}\n\n    assert sagemaker.utils.get_config_value(""local.region_name"", config) == ""us-west-2""\n    assert sagemaker.utils.get_config_value(""local"", config) == {\n        ""region_name"": ""us-west-2"",\n        ""port"": ""123"",\n    }\n\n    assert sagemaker.utils.get_config_value(""does_not.exist"", config) is None\n    assert sagemaker.utils.get_config_value(""other.key"", None) is None\n\n\ndef test_get_short_version():\n    assert sagemaker.utils.get_short_version(""1.13.1"") == ""1.13""\n    assert sagemaker.utils.get_short_version(""1.13"") == ""1.13""\n\n\ndef test_deferred_error():\n    de = sagemaker.utils.DeferredError(ImportError(""pretend the import failed""))\n    with pytest.raises(ImportError) as _:  # noqa: F841\n        de.something()\n\n\ndef test_bad_import():\n    try:\n        import pandas_is_not_installed as pd\n    except ImportError as e:\n        pd = sagemaker.utils.DeferredError(e)\n    assert pd is not None\n    with pytest.raises(ImportError) as _:  # noqa: F841\n        pd.DataFrame()\n\n\n@patch(""sagemaker.utils.sagemaker_timestamp"")\ndef test_name_from_base(sagemaker_timestamp):\n    sagemaker.utils.name_from_base(NAME, short=False)\n    assert sagemaker_timestamp.called_once\n\n\n@patch(""sagemaker.utils.sagemaker_short_timestamp"")\ndef test_name_from_base_short(sagemaker_short_timestamp):\n    sagemaker.utils.name_from_base(NAME, short=True)\n    assert sagemaker_short_timestamp.called_once\n\n\ndef test_unique_name_from_base():\n    assert re.match(r""base-\\d{10}-[a-f0-9]{4}"", sagemaker.utils.unique_name_from_base(""base""))\n\n\ndef test_unique_name_from_base_truncated():\n    assert re.match(\n        r""real-\\d{10}-[a-f0-9]{4}"",\n        sagemaker.utils.unique_name_from_base(""really-long-name"", max_length=20),\n    )\n\n\ndef test_to_str_with_native_string():\n    value = ""some string""\n    assert sagemaker.utils.to_str(value) == value\n\n\ndef test_to_str_with_unicode_string():\n    value = u""\xc3\xa5\xc3\xb1\xc3\xb8th\xc3\xa9r str\xc3\xaeng""\n    assert sagemaker.utils.to_str(value) == value\n\n\ndef test_name_from_tuning_arn():\n    arn = ""arn:aws:sagemaker:us-west-2:968277160000:hyper-parameter-tuning-job/resnet-sgd-tuningjob-11-07-34-11""\n    name = sagemaker.utils.extract_name_from_job_arn(arn)\n    assert name == ""resnet-sgd-tuningjob-11-07-34-11""\n\n\ndef test_name_from_training_arn():\n    arn = ""arn:aws:sagemaker:us-west-2:968277160000:training-job/resnet-sgd-tuningjob-11-22-38-46-002-2927640b""\n    name = sagemaker.utils.extract_name_from_job_arn(arn)\n    assert name == ""resnet-sgd-tuningjob-11-22-38-46-002-2927640b""\n\n\nMESSAGE = ""message""\nSTATUS = ""status""\nTRAINING_JOB_DESCRIPTION_1 = {\n    ""SecondaryStatusTransitions"": [{""StatusMessage"": MESSAGE, ""Status"": STATUS}]\n}\nTRAINING_JOB_DESCRIPTION_2 = {\n    ""SecondaryStatusTransitions"": [{""StatusMessage"": ""different message"", ""Status"": STATUS}]\n}\n\nTRAINING_JOB_DESCRIPTION_EMPTY = {""SecondaryStatusTransitions"": []}\n\n\ndef test_secondary_training_status_changed_true():\n    changed = sagemaker.utils.secondary_training_status_changed(\n        TRAINING_JOB_DESCRIPTION_1, TRAINING_JOB_DESCRIPTION_2\n    )\n    assert changed is True\n\n\ndef test_secondary_training_status_changed_false():\n    changed = sagemaker.utils.secondary_training_status_changed(\n        TRAINING_JOB_DESCRIPTION_1, TRAINING_JOB_DESCRIPTION_1\n    )\n    assert changed is False\n\n\ndef test_secondary_training_status_changed_prev_missing():\n    changed = sagemaker.utils.secondary_training_status_changed(TRAINING_JOB_DESCRIPTION_1, {})\n    assert changed is True\n\n\ndef test_secondary_training_status_changed_prev_none():\n    changed = sagemaker.utils.secondary_training_status_changed(TRAINING_JOB_DESCRIPTION_1, None)\n    assert changed is True\n\n\ndef test_secondary_training_status_changed_current_missing():\n    changed = sagemaker.utils.secondary_training_status_changed({}, TRAINING_JOB_DESCRIPTION_1)\n    assert changed is False\n\n\ndef test_secondary_training_status_changed_empty():\n    changed = sagemaker.utils.secondary_training_status_changed(\n        TRAINING_JOB_DESCRIPTION_EMPTY, TRAINING_JOB_DESCRIPTION_1\n    )\n    assert changed is False\n\n\ndef test_secondary_training_status_message_status_changed():\n    now = datetime.now()\n    TRAINING_JOB_DESCRIPTION_1[""LastModifiedTime""] = now\n    expected = ""{} {} - {}"".format(\n        datetime.utcfromtimestamp(time.mktime(now.timetuple())).strftime(""%Y-%m-%d %H:%M:%S""),\n        STATUS,\n        MESSAGE,\n    )\n    assert (\n        sagemaker.utils.secondary_training_status_message(\n            TRAINING_JOB_DESCRIPTION_1, TRAINING_JOB_DESCRIPTION_EMPTY\n        )\n        == expected\n    )\n\n\ndef test_secondary_training_status_message_status_not_changed():\n    now = datetime.now()\n    TRAINING_JOB_DESCRIPTION_1[""LastModifiedTime""] = now\n    expected = ""{} {} - {}"".format(\n        datetime.utcfromtimestamp(time.mktime(now.timetuple())).strftime(""%Y-%m-%d %H:%M:%S""),\n        STATUS,\n        MESSAGE,\n    )\n    assert (\n        sagemaker.utils.secondary_training_status_message(\n            TRAINING_JOB_DESCRIPTION_1, TRAINING_JOB_DESCRIPTION_2\n        )\n        == expected\n    )\n\n\ndef test_secondary_training_status_message_prev_missing():\n    now = datetime.now()\n    TRAINING_JOB_DESCRIPTION_1[""LastModifiedTime""] = now\n    expected = ""{} {} - {}"".format(\n        datetime.utcfromtimestamp(time.mktime(now.timetuple())).strftime(""%Y-%m-%d %H:%M:%S""),\n        STATUS,\n        MESSAGE,\n    )\n    assert (\n        sagemaker.utils.secondary_training_status_message(TRAINING_JOB_DESCRIPTION_1, {})\n        == expected\n    )\n\n\ndef test_generate_tensorboard_url_valid_domain_and_bucket_paths():\n    domain = ""jupyterlab.us-east-2.abcdefgh.com""\n    bucket_paths = [""bucket1/path1"", ""bucket2/path2""]\n    expected = ""https://{}/tensorboard/default?{}"".format(\n        domain, ""s3urls=s3%3A%2F%2Fbucket1%2Fpath1,s3%3A%2F%2Fbucket2%2Fpath2""\n    )\n    assert sagemaker.utils.generate_tensorboard_url(domain, bucket_paths) == expected\n\n\ndef test_generate_tensorboard_url_valid_domain_and_bucket_paths_with_s3_prefixes():\n    domain = ""jupyterlab.us-east-2.abcdefgh.com""\n    bucket_paths = [""s3://bucket1/path1"", ""s3://bucket2/path2""]\n    expected = ""https://{}/tensorboard/default?{}"".format(\n        domain, ""s3urls=s3%3A%2F%2Fbucket1%2Fpath1,s3%3A%2F%2Fbucket2%2Fpath2""\n    )\n    assert sagemaker.utils.generate_tensorboard_url(domain, bucket_paths) == expected\n\n\ndef test_generate_tensorboard_url_valid_domain_and_bucket_paths_single():\n    domain = ""jupyterlab.us-east-2.abcdefgh.com""\n    bucket_paths = [""bucket1/path1""]\n    expected = ""https://{}/tensorboard/default?{}"".format(\n        domain, ""s3urls=s3%3A%2F%2Fbucket1%2Fpath1""\n    )\n    assert sagemaker.utils.generate_tensorboard_url(domain, bucket_paths) == expected\n\n\ndef test_generate_tensorboard_url_valid_domain_and_bucket_paths_string():\n    domain = ""jupyterlab.us-east-2.abcdefgh.com""\n    bucket_paths = ""bucket1/path1""\n    expected = ""https://{}/tensorboard/default?{}"".format(\n        domain, ""s3urls=s3%3A%2F%2Fbucket1%2Fpath1""\n    )\n    assert sagemaker.utils.generate_tensorboard_url(domain, bucket_paths) == expected\n\n\ndef test_generate_tensorboard_url_valid_domain_with_http_prefix_and_bucket_paths():\n    domain = ""http://jupyterlab.us-east-2.abcdefgh.com""\n    bucket_paths = [""bucket1/path1""]\n    expected = ""https://{}/tensorboard/default?{}"".format(\n        ""jupyterlab.us-east-2.abcdefgh.com"", ""s3urls=s3%3A%2F%2Fbucket1%2Fpath1""\n    )\n    assert sagemaker.utils.generate_tensorboard_url(domain, bucket_paths) == expected\n\n\ndef test_generate_tensorboard_url_valid_domain_with_https_prefix_and_bucket_paths():\n    domain = ""https://jupyterlab.us-east-2.abcdefgh.com""\n    bucket_paths = [""bucket1/path1""]\n    expected = ""https://{}/tensorboard/default?{}"".format(\n        ""jupyterlab.us-east-2.abcdefgh.com"", ""s3urls=s3%3A%2F%2Fbucket1%2Fpath1""\n    )\n    assert sagemaker.utils.generate_tensorboard_url(domain, bucket_paths) == expected\n\n\ndef test_generate_tensorboard_url_bucket_path_neither_string_nor_list():\n    domain = ""jupyterlab.us-east-2.abcdefgh.com""\n    bucket_paths = None\n    try:\n        sagemaker.utils.generate_tensorboard_url(domain, bucket_paths)\n    except AttributeError as error:\n        assert str(error) == ""bucket paths should be a list or a string""\n\n\ndef test_generate_tensorboard_url_empty_domain():\n    domain = """"\n    bucket_paths = [""bucket1/path1""]\n    try:\n        sagemaker.utils.generate_tensorboard_url(domain, bucket_paths)\n    except AttributeError as error:\n        assert str(error) == ""domain parameter should not be empty""\n\n\ndef test_generate_tensorboard_url_empty_bucket_paths():\n    domain = ""jupyterlab.us-east-2.abcdefgh.com""\n    bucket_paths = []\n    try:\n        sagemaker.utils.generate_tensorboard_url(domain, bucket_paths)\n    except AttributeError as error:\n        assert str(error) == ""bucket_paths parameter should not be empty list""\n\n\ndef test_generate_tensorboard_url_bucket_paths_with_empty_string():\n    domain = ""jupyterlab.us-east-2.abcdefgh.com""\n    bucket_paths = [""""]\n    try:\n        sagemaker.utils.generate_tensorboard_url(domain, bucket_paths)\n    except AttributeError as error:\n        assert str(error) == ""bucket_paths element should not be empty""\n\n\ndef test_generate_tensorboard_url_domain_non_string():\n    domain = None\n    bucket_paths = [""bucket1/path1""]\n    try:\n        sagemaker.utils.generate_tensorboard_url(domain, bucket_paths)\n    except AttributeError as error:\n        assert str(error) == ""domain parameter should be string""\n\n\n@patch(""os.makedirs"")\ndef test_download_folder(makedirs):\n    boto_mock = Mock(name=""boto_session"")\n    session = sagemaker.Session(boto_session=boto_mock, sagemaker_client=Mock())\n    s3_mock = boto_mock.resource(""s3"")\n\n    obj_mock = Mock()\n    s3_mock.Object.return_value = obj_mock\n\n    def obj_mock_download(path):\n        # Mock the S3 object to raise an error when the input to download_file\n        # is a ""folder""\n        if path in (""/tmp/"", os.path.join(""/tmp"", ""prefix"")):\n            raise botocore.exceptions.ClientError(\n                error_response={""Error"": {""Code"": ""404"", ""Message"": ""Not Found""}},\n                operation_name=""HeadObject"",\n            )\n        else:\n            return Mock()\n\n    obj_mock.download_file.side_effect = obj_mock_download\n\n    train_data = Mock()\n    validation_data = Mock()\n\n    train_data.bucket_name.return_value = BUCKET_NAME\n    train_data.key = ""prefix/train/train_data.csv""\n    validation_data.bucket_name.return_value = BUCKET_NAME\n    validation_data.key = ""prefix/train/validation_data.csv""\n\n    s3_files = [train_data, validation_data]\n    s3_mock.Bucket(BUCKET_NAME).objects.filter.return_value = s3_files\n\n    # all the S3 mocks are set, the test itself begins now.\n    sagemaker.utils.download_folder(BUCKET_NAME, ""/prefix"", ""/tmp"", session)\n\n    obj_mock.download_file.assert_called()\n    calls = [\n        call(os.path.join(""/tmp"", ""train"", ""train_data.csv"")),\n        call(os.path.join(""/tmp"", ""train"", ""validation_data.csv"")),\n    ]\n    obj_mock.download_file.assert_has_calls(calls)\n    assert s3_mock.Object.call_count == 3\n\n    s3_mock.reset_mock()\n    obj_mock.reset_mock()\n\n    # Test with a trailing slash for the prefix.\n    sagemaker.utils.download_folder(BUCKET_NAME, ""/prefix/"", ""/tmp"", session)\n    obj_mock.download_file.assert_called()\n    obj_mock.download_file.assert_has_calls(calls)\n    assert s3_mock.Object.call_count == 2\n\n\n@patch(""os.makedirs"")\ndef test_download_folder_points_to_single_file(makedirs):\n    boto_mock = Mock(name=""boto_session"")\n    boto_mock.client(""sts"").get_caller_identity.return_value = {""Account"": ""123""}\n\n    session = sagemaker.Session(boto_session=boto_mock, sagemaker_client=Mock())\n\n    train_data = Mock()\n\n    train_data.bucket_name.return_value = BUCKET_NAME\n    train_data.key = ""prefix/train/train_data.csv""\n\n    s3_files = [train_data]\n    boto_mock.resource(""s3"").Bucket(BUCKET_NAME).objects.filter.return_value = s3_files\n\n    obj_mock = Mock()\n    boto_mock.resource(""s3"").Object.return_value = obj_mock\n\n    # all the S3 mocks are set, the test itself begins now.\n    sagemaker.utils.download_folder(BUCKET_NAME, ""/prefix/train/train_data.csv"", ""/tmp"", session)\n\n    obj_mock.download_file.assert_called()\n    calls = [call(os.path.join(""/tmp"", ""train_data.csv""))]\n    obj_mock.download_file.assert_has_calls(calls)\n    boto_mock.resource(""s3"").Bucket(BUCKET_NAME).objects.filter.assert_not_called()\n    obj_mock.reset_mock()\n\n\ndef test_download_file():\n    boto_mock = Mock(name=""boto_session"")\n    boto_mock.client(""sts"").get_caller_identity.return_value = {""Account"": ""123""}\n    bucket_mock = Mock()\n    boto_mock.resource(""s3"").Bucket.return_value = bucket_mock\n    session = sagemaker.Session(boto_session=boto_mock, sagemaker_client=Mock())\n\n    sagemaker.utils.download_file(\n        BUCKET_NAME, ""/prefix/path/file.tar.gz"", ""/tmp/file.tar.gz"", session\n    )\n\n    bucket_mock.download_file.assert_called_with(""prefix/path/file.tar.gz"", ""/tmp/file.tar.gz"")\n\n\n@patch(""tarfile.open"")\ndef test_create_tar_file_with_provided_path(open):\n    files = mock_tarfile(open)\n\n    file_list = [""/tmp/a"", ""/tmp/b""]\n\n    path = sagemaker.utils.create_tar_file(file_list, target=""/my/custom/path.tar.gz"")\n    assert path == ""/my/custom/path.tar.gz""\n    assert files == [[""/tmp/a"", ""a""], [""/tmp/b"", ""b""]]\n\n\ndef mock_tarfile(open):\n    open.return_value = open\n    files = []\n\n    def add_files(filename, arcname):\n        files.append([filename, arcname])\n\n    open.__enter__ = Mock()\n    open.__enter__().add = add_files\n    open.__exit__ = Mock(return_value=None)\n    return files\n\n\n@patch(""tarfile.open"")\n@patch(""tempfile.mkstemp"", Mock(return_value=(None, ""/auto/generated/path"")))\ndef test_create_tar_file_with_auto_generated_path(open):\n    files = mock_tarfile(open)\n\n    path = sagemaker.utils.create_tar_file([""/tmp/a"", ""/tmp/b""])\n    assert path == ""/auto/generated/path""\n    assert files == [[""/tmp/a"", ""a""], [""/tmp/b"", ""b""]]\n\n\ndef create_file_tree(root, tree):\n    for file in tree:\n        try:\n            os.makedirs(os.path.join(root, os.path.dirname(file)))\n        except:  # noqa: E722 Using bare except because p2/3 incompatibility issues.\n            pass\n        with open(os.path.join(root, file), ""a"") as f:\n            f.write(file)\n\n\n@pytest.fixture()\ndef tmp(tmpdir):\n    yield str(tmpdir)\n\n\ndef test_repack_model_without_source_dir(tmp, fake_s3):\n\n    create_file_tree(\n        tmp,\n        [\n            ""model-dir/model"",\n            ""dependencies/a"",\n            ""dependencies/some/dir/b"",\n            ""aa"",\n            ""bb"",\n            ""source-dir/inference.py"",\n            ""source-dir/this-file-should-not-be-included.py"",\n        ],\n    )\n\n    fake_s3.tar_and_upload(""model-dir"", ""s3://fake/location"")\n\n    sagemaker.utils.repack_model(\n        inference_script=os.path.join(tmp, ""source-dir/inference.py""),\n        source_directory=None,\n        dependencies=[\n            os.path.join(tmp, ""dependencies/a""),\n            os.path.join(tmp, ""dependencies/some/dir""),\n            os.path.join(tmp, ""aa""),\n            os.path.join(tmp, ""bb""),\n        ],\n        model_uri=""s3://fake/location"",\n        repacked_model_uri=""s3://destination-bucket/model.tar.gz"",\n        sagemaker_session=fake_s3.sagemaker_session,\n    )\n\n    assert list_tar_files(fake_s3.fake_upload_path, tmp) == {\n        ""/model"",\n        ""/code/lib/a"",\n        ""/code/lib/aa"",\n        ""/code/lib/bb"",\n        ""/code/lib/dir/b"",\n        ""/code/inference.py"",\n    }\n\n\ndef test_repack_model_with_entry_point_without_path_without_source_dir(tmp, fake_s3):\n\n    create_file_tree(\n        tmp,\n        [\n            ""model-dir/model"",\n            ""source-dir/inference.py"",\n            ""source-dir/this-file-should-not-be-included.py"",\n        ],\n    )\n\n    fake_s3.tar_and_upload(""model-dir"", ""s3://fake/location"")\n\n    cwd = os.getcwd()\n    try:\n        os.chdir(os.path.join(tmp, ""source-dir""))\n\n        sagemaker.utils.repack_model(\n            ""inference.py"",\n            None,\n            None,\n            ""s3://fake/location"",\n            ""s3://destination-bucket/model.tar.gz"",\n            fake_s3.sagemaker_session,\n        )\n    finally:\n        os.chdir(cwd)\n\n    assert list_tar_files(fake_s3.fake_upload_path, tmp) == {""/code/inference.py"", ""/model""}\n\n\ndef test_repack_model_from_s3_to_s3(tmp, fake_s3):\n\n    create_file_tree(\n        tmp,\n        [\n            ""model-dir/model"",\n            ""source-dir/inference.py"",\n            ""source-dir/this-file-should-be-included.py"",\n        ],\n    )\n\n    fake_s3.tar_and_upload(""model-dir"", ""s3://fake/location"")\n\n    sagemaker.utils.repack_model(\n        ""inference.py"",\n        os.path.join(tmp, ""source-dir""),\n        None,\n        ""s3://fake/location"",\n        ""s3://destination-bucket/model.tar.gz"",\n        fake_s3.sagemaker_session,\n    )\n\n    assert list_tar_files(fake_s3.fake_upload_path, tmp) == {\n        ""/code/this-file-should-be-included.py"",\n        ""/code/inference.py"",\n        ""/model"",\n    }\n\n\ndef test_repack_model_from_file_to_file(tmp):\n    create_file_tree(tmp, [""model"", ""dependencies/a"", ""source-dir/inference.py""])\n\n    model_tar_path = os.path.join(tmp, ""model.tar.gz"")\n    sagemaker.utils.create_tar_file([os.path.join(tmp, ""model"")], model_tar_path)\n\n    sagemaker_session = MagicMock()\n\n    file_mode_path = ""file://%s"" % model_tar_path\n    destination_path = ""file://%s"" % os.path.join(tmp, ""repacked-model.tar.gz"")\n\n    sagemaker.utils.repack_model(\n        ""inference.py"",\n        os.path.join(tmp, ""source-dir""),\n        [os.path.join(tmp, ""dependencies/a"")],\n        file_mode_path,\n        destination_path,\n        sagemaker_session,\n    )\n\n    assert list_tar_files(destination_path, tmp) == {""/code/lib/a"", ""/code/inference.py"", ""/model""}\n\n\ndef test_repack_model_with_inference_code_should_replace_the_code(tmp, fake_s3):\n    create_file_tree(\n        tmp, [""model-dir/model"", ""source-dir/new-inference.py"", ""model-dir/code/old-inference.py""]\n    )\n\n    fake_s3.tar_and_upload(""model-dir"", ""s3://fake/location"")\n\n    sagemaker.utils.repack_model(\n        ""inference.py"",\n        os.path.join(tmp, ""source-dir""),\n        None,\n        ""s3://fake/location"",\n        ""s3://destination-bucket/repacked-model"",\n        fake_s3.sagemaker_session,\n    )\n\n    assert list_tar_files(fake_s3.fake_upload_path, tmp) == {""/code/new-inference.py"", ""/model""}\n\n\ndef test_repack_model_from_file_to_folder(tmp):\n    create_file_tree(tmp, [""model"", ""source-dir/inference.py""])\n\n    model_tar_path = os.path.join(tmp, ""model.tar.gz"")\n    sagemaker.utils.create_tar_file([os.path.join(tmp, ""model"")], model_tar_path)\n\n    file_mode_path = ""file://%s"" % model_tar_path\n\n    sagemaker.utils.repack_model(\n        ""inference.py"",\n        os.path.join(tmp, ""source-dir""),\n        [],\n        file_mode_path,\n        ""file://%s/repacked-model.tar.gz"" % tmp,\n        MagicMock(),\n    )\n\n    assert list_tar_files(""file://%s/repacked-model.tar.gz"" % tmp, tmp) == {\n        ""/code/inference.py"",\n        ""/model"",\n    }\n\n\ndef test_repack_model_with_inference_code_and_requirements(tmp, fake_s3):\n    create_file_tree(\n        tmp,\n        [\n            ""new-inference.py"",\n            ""model-dir/model"",\n            ""model-dir/code/old-inference.py"",\n            ""model-dir/code/requirements.txt"",\n        ],\n    )\n\n    fake_s3.tar_and_upload(""model-dir"", ""s3://fake/location"")\n\n    sagemaker.utils.repack_model(\n        os.path.join(tmp, ""new-inference.py""),\n        None,\n        None,\n        ""s3://fake/location"",\n        ""s3://destination-bucket/repacked-model"",\n        fake_s3.sagemaker_session,\n    )\n\n    assert list_tar_files(fake_s3.fake_upload_path, tmp) == {\n        ""/code/requirements.txt"",\n        ""/code/new-inference.py"",\n        ""/code/old-inference.py"",\n        ""/model"",\n    }\n\n\ndef test_repack_model_with_same_inference_file_name(tmp, fake_s3):\n    create_file_tree(\n        tmp,\n        [\n            ""inference.py"",\n            ""model-dir/model"",\n            ""model-dir/code/inference.py"",\n            ""model-dir/code/requirements.txt"",\n        ],\n    )\n\n    fake_s3.tar_and_upload(""model-dir"", ""s3://fake/location"")\n\n    sagemaker.utils.repack_model(\n        os.path.join(tmp, ""inference.py""),\n        None,\n        None,\n        ""s3://fake/location"",\n        ""s3://destination-bucket/repacked-model"",\n        fake_s3.sagemaker_session,\n    )\n\n    assert list_tar_files(fake_s3.fake_upload_path, tmp) == {\n        ""/code/requirements.txt"",\n        ""/code/inference.py"",\n        ""/model"",\n    }\n\n\nclass FakeS3(object):\n    def __init__(self, tmp):\n        self.tmp = tmp\n        self.sagemaker_session = MagicMock()\n        self.location_map = {}\n        self.current_bucket = None\n\n        self.sagemaker_session.boto_session.resource().Bucket().download_file.side_effect = (\n            self.download_file\n        )\n        self.sagemaker_session.boto_session.resource().Bucket.side_effect = self.bucket\n        self.fake_upload_path = self.mock_s3_upload()\n\n    def bucket(self, name):\n        self.current_bucket = name\n        return self\n\n    def download_file(self, path, target):\n        key = ""%s/%s"" % (self.current_bucket, path)\n        shutil.copy2(self.location_map[key], target)\n\n    def tar_and_upload(self, path, fake_location):\n        tar_location = os.path.join(self.tmp, ""model-%s.tar.gz"" % time.time())\n        with tarfile.open(tar_location, mode=""w:gz"") as t:\n            t.add(os.path.join(self.tmp, path), arcname=os.path.sep)\n\n        self.location_map[fake_location.replace(""s3://"", """")] = tar_location\n        return tar_location\n\n    def mock_s3_upload(self):\n        dst = os.path.join(self.tmp, ""dst"")\n\n        class MockS3Object(object):\n            def __init__(self, bucket, key):\n                self.bucket = bucket\n                self.key = key\n\n            def upload_file(self, target, **kwargs):\n                if self.bucket in BUCKET_WITHOUT_WRITING_PERMISSION:\n                    raise exceptions.S3UploadFailedError()\n                shutil.copy2(target, dst)\n\n        self.sagemaker_session.boto_session.resource().Object = MockS3Object\n        return dst\n\n\n@pytest.fixture()\ndef fake_s3(tmp):\n    return FakeS3(tmp)\n\n\ndef list_tar_files(tar_ball, tmp):\n    tar_ball = tar_ball.replace(""file://"", """")\n    startpath = os.path.join(tmp, ""startpath"")\n    os.mkdir(startpath)\n\n    with tarfile.open(name=tar_ball, mode=""r:gz"") as t:\n        t.extractall(path=startpath)\n\n    def walk():\n        for root, dirs, files in os.walk(startpath):\n            path = root.replace(startpath, """")\n            for f in files:\n                yield ""%s/%s"" % (path, f)\n\n    result = set(walk())\n    return result if result else {}\n\n\ndef test_get_ecr_image_uri_prefix():\n    ecr_prefix = sagemaker.utils.get_ecr_image_uri_prefix(""123456789012"", ""us-west-2"")\n    assert ecr_prefix == ""123456789012.dkr.ecr.us-west-2.amazonaws.com""\n\n    ecr_prefix = sagemaker.utils.get_ecr_image_uri_prefix(""123456789012"", ""us-iso-east-1"")\n    assert ecr_prefix == ""123456789012.dkr.ecr.us-iso-east-1.c2s.ic.gov""\n\n\ndef test_sts_regional_endpoint():\n    endpoint = sagemaker.utils.sts_regional_endpoint(""us-west-2"")\n    assert endpoint == ""https://sts.us-west-2.amazonaws.com""\n    assert botocore.utils.is_valid_endpoint_url(endpoint)\n\n    endpoint = sagemaker.utils.sts_regional_endpoint(""us-iso-east-1"")\n    assert endpoint == ""https://sts.us-iso-east-1.c2s.ic.gov""\n    assert botocore.utils.is_valid_endpoint_url(endpoint)\n\n\ndef test_partition_by_region():\n    assert sagemaker.utils._aws_partition(""us-west-2"") == ""aws""\n    assert sagemaker.utils._aws_partition(""cn-north-1"") == ""aws-cn""\n    assert sagemaker.utils._aws_partition(""us-gov-east-1"") == ""aws-us-gov""\n    assert sagemaker.utils._aws_partition(""us-iso-east-1"") == ""aws-iso""\n    assert sagemaker.utils._aws_partition(""us-isob-east-1"") == ""aws-iso-b""\n'"
tests/unit/test_vpc_utils.py,0,"b'# -*- coding: utf-8 -*-\n\n# Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport pytest\n\nfrom sagemaker.vpc_utils import SUBNETS_KEY, SECURITY_GROUP_IDS_KEY, to_dict, from_dict, sanitize\n\nsubnets = [""subnet""]\nsecurity_groups = [""sg""]\ngood_vpc_config = {SUBNETS_KEY: subnets, SECURITY_GROUP_IDS_KEY: security_groups}\nfoo_vpc_config = {SUBNETS_KEY: subnets, SECURITY_GROUP_IDS_KEY: security_groups, ""foo"": 1}\n\n\ndef test_to_dict():\n    assert to_dict(None, None) is None\n    assert to_dict(subnets, None) is None\n    assert to_dict(None, security_groups) is None\n\n    assert to_dict(subnets, security_groups) == {\n        SUBNETS_KEY: subnets,\n        SECURITY_GROUP_IDS_KEY: security_groups,\n    }\n\n\ndef test_from_dict():\n    assert from_dict(good_vpc_config) == (subnets, security_groups)\n    assert from_dict(foo_vpc_config) == (subnets, security_groups)\n\n    assert from_dict(None) == (None, None)\n    assert from_dict(None, do_sanitize=True) == (None, None)\n\n    with pytest.raises(KeyError):\n        from_dict({})\n    with pytest.raises(KeyError):\n        from_dict({SUBNETS_KEY: subnets})\n    with pytest.raises(KeyError):\n        from_dict({SECURITY_GROUP_IDS_KEY: security_groups})\n\n    with pytest.raises(ValueError):\n        from_dict({}, do_sanitize=True)\n\n\ndef test_sanitize():\n    assert sanitize(good_vpc_config) == good_vpc_config\n    assert sanitize(foo_vpc_config) == good_vpc_config\n\n    assert sanitize(None) is None\n\n    with pytest.raises(ValueError):\n        sanitize([])\n    with pytest.raises(ValueError):\n        sanitize({})\n\n    with pytest.raises(ValueError):\n        sanitize({SUBNETS_KEY: 1})\n    with pytest.raises(ValueError):\n        sanitize({SUBNETS_KEY: []})\n\n    with pytest.raises(ValueError):\n        sanitize({SECURITY_GROUP_IDS_KEY: 1, SUBNETS_KEY: subnets})\n    with pytest.raises(ValueError):\n        sanitize({SECURITY_GROUP_IDS_KEY: [], SUBNETS_KEY: subnets})\n'"
tests/unit/test_xgboost.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport logging\nimport json\nimport os\nimport pytest\n\nfrom mock import Mock\nfrom mock import patch\n\n\nfrom sagemaker.xgboost.defaults import XGBOOST_LATEST_VERSION\nfrom sagemaker.xgboost import XGBoost, XGBoostModel, XGBoostPredictor\n\n\nDATA_DIR = os.path.join(os.path.dirname(__file__), "".."", ""data"")\nSCRIPT_PATH = os.path.join(DATA_DIR, ""dummy_script.py"")\nSERVING_SCRIPT_FILE = ""another_dummy_script.py""\nTIMESTAMP = ""2017-11-06-14:14:15.672""\nTIME = 1507167947\nBUCKET_NAME = ""mybucket""\nINSTANCE_COUNT = 1\nDIST_INSTANCE_COUNT = 2\nINSTANCE_TYPE = ""ml.c4.4xlarge""\nGPU_INSTANCE_TYPE = ""ml.p2.xlarge""\nPYTHON_VERSION = ""py3""\nIMAGE_NAME = ""sagemaker-xgboost""\nJOB_NAME = ""{}-{}"".format(IMAGE_NAME, TIMESTAMP)\nIMAGE_URI_FORMAT_STRING = ""246618743249.dkr.ecr.{}.amazonaws.com/{}:{}-{}-{}""\nROLE = ""Dummy""\nREGION = ""us-west-2""\nCPU = ""ml.c4.xlarge""\n\nENDPOINT_DESC = {""EndpointConfigName"": ""test-endpoint""}\n\nENDPOINT_CONFIG_DESC = {""ProductionVariants"": [{""ModelName"": ""model-1""}, {""ModelName"": ""model-2""}]}\n\nLIST_TAGS_RESULT = {""Tags"": [{""Key"": ""TagtestKey"", ""Value"": ""TagtestValue""}]}\n\nEXPERIMENT_CONFIG = {\n    ""ExperimentName"": ""exp"",\n    ""TrialName"": ""trial"",\n    ""TrialComponentDisplayName"": ""tc"",\n}\n\n\n@pytest.fixture()\ndef sagemaker_session():\n    boto_mock = Mock(name=""boto_session"", region_name=REGION)\n    session = Mock(\n        name=""sagemaker_session"",\n        boto_session=boto_mock,\n        boto_region_name=REGION,\n        config=None,\n        local_mode=False,\n        s3_resource=None,\n        s3_client=None,\n    )\n\n    describe = {""ModelArtifacts"": {""S3ModelArtifacts"": ""s3://m/m.tar.gz""}}\n    session.sagemaker_client.describe_training_job = Mock(return_value=describe)\n    session.sagemaker_client.describe_endpoint = Mock(return_value=ENDPOINT_DESC)\n    session.sagemaker_client.describe_endpoint_config = Mock(return_value=ENDPOINT_CONFIG_DESC)\n    session.sagemaker_client.list_tags = Mock(return_value=LIST_TAGS_RESULT)\n    session.default_bucket = Mock(name=""default_bucket"", return_value=BUCKET_NAME)\n    session.expand_role = Mock(name=""expand_role"", return_value=ROLE)\n    return session\n\n\ndef _get_full_cpu_image_uri(version):\n    return IMAGE_URI_FORMAT_STRING.format(REGION, IMAGE_NAME, version, ""cpu"", PYTHON_VERSION)\n\n\ndef _xgboost_estimator(\n    sagemaker_session,\n    framework_version=XGBOOST_LATEST_VERSION,\n    train_instance_type=None,\n    train_instance_count=1,\n    base_job_name=None,\n    **kwargs\n):\n\n    return XGBoost(\n        entry_point=SCRIPT_PATH,\n        framework_version=framework_version,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_type=train_instance_type if train_instance_type else INSTANCE_TYPE,\n        train_instance_count=train_instance_count,\n        base_job_name=base_job_name,\n        py_version=PYTHON_VERSION,\n        **kwargs\n    )\n\n\ndef _create_train_job(version, instance_count=1):\n    return {\n        ""image"": _get_full_cpu_image_uri(version),\n        ""input_mode"": ""File"",\n        ""input_config"": [\n            {\n                ""ChannelName"": ""training"",\n                ""DataSource"": {\n                    ""S3DataSource"": {\n                        ""S3DataDistributionType"": ""FullyReplicated"",\n                        ""S3DataType"": ""S3Prefix"",\n                    }\n                },\n            }\n        ],\n        ""role"": ROLE,\n        ""job_name"": JOB_NAME,\n        ""output_config"": {""S3OutputPath"": ""s3://{}/"".format(BUCKET_NAME)},\n        ""resource_config"": {\n            ""InstanceType"": ""ml.c4.4xlarge"",\n            ""InstanceCount"": instance_count,\n            ""VolumeSizeInGB"": 30,\n        },\n        ""hyperparameters"": {\n            ""sagemaker_program"": json.dumps(""dummy_script.py""),\n            ""sagemaker_enable_cloudwatch_metrics"": ""false"",\n            ""sagemaker_container_log_level"": str(logging.INFO),\n            ""sagemaker_job_name"": json.dumps(JOB_NAME),\n            ""sagemaker_submit_directory"": json.dumps(\n                ""s3://{}/{}/source/sourcedir.tar.gz"".format(BUCKET_NAME, JOB_NAME)\n            ),\n            ""sagemaker_region"": \'""us-west-2""\',\n        },\n        ""stop_condition"": {""MaxRuntimeInSeconds"": 24 * 60 * 60},\n        ""metric_definitions"": None,\n        ""tags"": None,\n        ""vpc_config"": None,\n        ""experiment_config"": None,\n        ""debugger_hook_config"": {\n            ""CollectionConfigurations"": [],\n            ""S3OutputPath"": ""s3://{}/"".format(BUCKET_NAME),\n        },\n    }\n\n\ndef test_train_image(sagemaker_session, xgboost_version):\n    container_log_level = \'""logging.INFO""\'\n    source_dir = ""s3://mybucket/source""\n    xgboost = XGBoost(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_type=INSTANCE_TYPE,\n        train_instance_count=1,\n        framework_version=xgboost_version,\n        container_log_level=container_log_level,\n        py_version=PYTHON_VERSION,\n        base_job_name=""job"",\n        source_dir=source_dir,\n    )\n\n    train_image = xgboost.train_image()\n    assert (\n        train_image\n        == ""246618743249.dkr.ecr.us-west-2.amazonaws.com/sagemaker-xgboost:0.90-1-cpu-py3""\n    )\n\n\ndef test_create_model(sagemaker_session):\n    source_dir = ""s3://mybucket/source""\n\n    xgboost_model = XGBoostModel(\n        model_data=source_dir,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        entry_point=SCRIPT_PATH,\n        framework_version=XGBOOST_LATEST_VERSION,\n    )\n    default_image_uri = _get_full_cpu_image_uri(XGBOOST_LATEST_VERSION)\n    model_values = xgboost_model.prepare_container_def(CPU)\n    assert model_values[""Image""] == default_image_uri\n\n\ndef test_create_model_from_estimator(sagemaker_session, xgboost_version):\n    container_log_level = \'""logging.INFO""\'\n    source_dir = ""s3://mybucket/source""\n    xgboost = XGBoost(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_type=INSTANCE_TYPE,\n        train_instance_count=1,\n        framework_version=xgboost_version,\n        container_log_level=container_log_level,\n        py_version=PYTHON_VERSION,\n        base_job_name=""job"",\n        source_dir=source_dir,\n    )\n\n    job_name = ""new_name""\n    xgboost.fit(inputs=""s3://mybucket/train"", job_name=job_name)\n    model = xgboost.create_model()\n\n    assert model.sagemaker_session == sagemaker_session\n    assert model.framework_version == xgboost_version\n    assert model.py_version == xgboost.py_version\n    assert model.entry_point == SCRIPT_PATH\n    assert model.role == ROLE\n    assert model.name == job_name\n    assert model.container_log_level == container_log_level\n    assert model.source_dir == source_dir\n    assert model.vpc_config is None\n\n\ndef test_create_model_with_optional_params(sagemaker_session):\n    container_log_level = \'""logging.INFO""\'\n    source_dir = ""s3://mybucket/source""\n    enable_cloudwatch_metrics = ""true""\n    xgboost = XGBoost(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        framework_version=XGBOOST_LATEST_VERSION,\n        sagemaker_session=sagemaker_session,\n        train_instance_type=INSTANCE_TYPE,\n        train_instance_count=1,\n        container_log_level=container_log_level,\n        py_version=PYTHON_VERSION,\n        base_job_name=""job"",\n        source_dir=source_dir,\n        enable_cloudwatch_metrics=enable_cloudwatch_metrics,\n    )\n\n    xgboost.fit(inputs=""s3://mybucket/train"", job_name=""new_name"")\n\n    custom_image = ""ubuntu:latest""\n    new_role = ""role""\n    model_server_workers = 2\n    vpc_config = {""Subnets"": [""foo""], ""SecurityGroupIds"": [""bar""]}\n    new_source_dir = ""s3://myotherbucket/source""\n    dependencies = [""/directory/a"", ""/directory/b""]\n    model_name = ""model-name""\n    model = xgboost.create_model(\n        image=custom_image,\n        role=new_role,\n        model_server_workers=model_server_workers,\n        vpc_config_override=vpc_config,\n        entry_point=SERVING_SCRIPT_FILE,\n        source_dir=new_source_dir,\n        dependencies=dependencies,\n        name=model_name,\n    )\n\n    assert model.image == custom_image\n    assert model.role == new_role\n    assert model.model_server_workers == model_server_workers\n    assert model.vpc_config == vpc_config\n    assert model.entry_point == SERVING_SCRIPT_FILE\n    assert model.source_dir == new_source_dir\n    assert model.dependencies == dependencies\n    assert model.name == model_name\n\n\ndef test_create_model_with_custom_image(sagemaker_session):\n    container_log_level = \'""logging.INFO""\'\n    source_dir = ""s3://mybucket/source""\n    custom_image = ""ubuntu:latest""\n    xgboost = XGBoost(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        framework_version=XGBOOST_LATEST_VERSION,\n        sagemaker_session=sagemaker_session,\n        train_instance_type=INSTANCE_TYPE,\n        train_instance_count=1,\n        image_name=custom_image,\n        container_log_level=container_log_level,\n        py_version=PYTHON_VERSION,\n        base_job_name=""job"",\n        source_dir=source_dir,\n    )\n\n    xgboost.fit(inputs=""s3://mybucket/train"", job_name=""new_name"")\n    model = xgboost.create_model()\n\n    assert model.image == custom_image\n\n\n@patch(""time.strftime"", return_value=TIMESTAMP)\ndef test_xgboost(strftime, sagemaker_session, xgboost_version):\n    xgboost = XGBoost(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_type=INSTANCE_TYPE,\n        train_instance_count=1,\n        py_version=PYTHON_VERSION,\n        framework_version=xgboost_version,\n    )\n\n    inputs = ""s3://mybucket/train""\n\n    xgboost.fit(inputs=inputs, experiment_config=EXPERIMENT_CONFIG)\n\n    sagemaker_call_names = [c[0] for c in sagemaker_session.method_calls]\n    assert sagemaker_call_names == [""train"", ""logs_for_job""]\n    boto_call_names = [c[0] for c in sagemaker_session.boto_session.method_calls]\n    assert boto_call_names == [""resource""]\n\n    expected_train_args = _create_train_job(xgboost_version)\n    expected_train_args[""input_config""][0][""DataSource""][""S3DataSource""][""S3Uri""] = inputs\n    expected_train_args[""experiment_config""] = EXPERIMENT_CONFIG\n\n    actual_train_args = sagemaker_session.method_calls[0][2]\n    assert actual_train_args == expected_train_args\n\n    model = xgboost.create_model()\n\n    expected_image_base = ""246618743249.dkr.ecr.us-west-2.amazonaws.com/sagemaker-xgboost:{}-cpu-{}""\n    assert {\n        ""Environment"": {\n            ""SAGEMAKER_SUBMIT_DIRECTORY"": ""s3://mybucket/sagemaker-xgboost-{}/source/sourcedir.tar.gz"".format(\n                TIMESTAMP\n            ),\n            ""SAGEMAKER_PROGRAM"": ""dummy_script.py"",\n            ""SAGEMAKER_ENABLE_CLOUDWATCH_METRICS"": ""false"",\n            ""SAGEMAKER_REGION"": ""us-west-2"",\n            ""SAGEMAKER_CONTAINER_LOG_LEVEL"": ""20"",\n        },\n        ""Image"": expected_image_base.format(xgboost_version, PYTHON_VERSION),\n        ""ModelDataUrl"": ""s3://m/m.tar.gz"",\n    } == model.prepare_container_def(CPU)\n\n    assert ""cpu"" in model.prepare_container_def(CPU)[""Image""]\n    predictor = xgboost.deploy(1, CPU)\n    assert isinstance(predictor, XGBoostPredictor)\n\n\n@patch(""time.strftime"", return_value=TIMESTAMP)\ndef test_distributed_training(strftime, sagemaker_session, xgboost_version):\n    xgboost = XGBoost(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        sagemaker_session=sagemaker_session,\n        train_instance_count=DIST_INSTANCE_COUNT,\n        train_instance_type=INSTANCE_TYPE,\n        py_version=PYTHON_VERSION,\n        framework_version=xgboost_version,\n    )\n\n    inputs = ""s3://mybucket/train""\n\n    xgboost.fit(inputs=inputs)\n\n    sagemaker_call_names = [c[0] for c in sagemaker_session.method_calls]\n    assert sagemaker_call_names == [""train"", ""logs_for_job""]\n    boto_call_names = [c[0] for c in sagemaker_session.boto_session.method_calls]\n    assert boto_call_names == [""resource""]\n\n    expected_train_args = _create_train_job(xgboost_version, DIST_INSTANCE_COUNT)\n    expected_train_args[""input_config""][0][""DataSource""][""S3DataSource""][""S3Uri""] = inputs\n\n    actual_train_args = sagemaker_session.method_calls[0][2]\n    assert actual_train_args == expected_train_args\n\n    model = xgboost.create_model()\n\n    expected_image_base = ""246618743249.dkr.ecr.us-west-2.amazonaws.com/sagemaker-xgboost:{}-cpu-{}""\n    assert {\n        ""Environment"": {\n            ""SAGEMAKER_SUBMIT_DIRECTORY"": ""s3://mybucket/sagemaker-xgboost-{}/source/sourcedir.tar.gz"".format(\n                TIMESTAMP\n            ),\n            ""SAGEMAKER_PROGRAM"": ""dummy_script.py"",\n            ""SAGEMAKER_ENABLE_CLOUDWATCH_METRICS"": ""false"",\n            ""SAGEMAKER_REGION"": ""us-west-2"",\n            ""SAGEMAKER_CONTAINER_LOG_LEVEL"": ""20"",\n        },\n        ""Image"": expected_image_base.format(xgboost_version, PYTHON_VERSION),\n        ""ModelDataUrl"": ""s3://m/m.tar.gz"",\n    } == model.prepare_container_def(CPU)\n\n    assert ""cpu"" in model.prepare_container_def(CPU)[""Image""]\n    predictor = xgboost.deploy(1, CPU)\n    assert isinstance(predictor, XGBoostPredictor)\n\n\ndef test_model(sagemaker_session):\n    model = XGBoostModel(\n        ""s3://some/data.tar.gz"",\n        role=ROLE,\n        framework_version=XGBOOST_LATEST_VERSION,\n        entry_point=SCRIPT_PATH,\n        sagemaker_session=sagemaker_session,\n    )\n    predictor = model.deploy(1, CPU)\n    assert isinstance(predictor, XGBoostPredictor)\n\n\ndef test_train_image_default(sagemaker_session):\n    xgboost = XGBoost(\n        entry_point=SCRIPT_PATH,\n        role=ROLE,\n        framework_version=XGBOOST_LATEST_VERSION,\n        sagemaker_session=sagemaker_session,\n        train_instance_type=INSTANCE_TYPE,\n        train_instance_count=1,\n        py_version=PYTHON_VERSION,\n    )\n\n    assert _get_full_cpu_image_uri(XGBOOST_LATEST_VERSION) in xgboost.train_image()\n\n\ndef test_train_image_cpu_instances(sagemaker_session, xgboost_version):\n    xgboost = _xgboost_estimator(\n        sagemaker_session, xgboost_version, train_instance_type=""ml.c2.2xlarge""\n    )\n    assert xgboost.train_image() == _get_full_cpu_image_uri(xgboost_version)\n\n    xgboost = _xgboost_estimator(\n        sagemaker_session, xgboost_version, train_instance_type=""ml.c4.2xlarge""\n    )\n    assert xgboost.train_image() == _get_full_cpu_image_uri(xgboost_version)\n\n    xgboost = _xgboost_estimator(sagemaker_session, xgboost_version, train_instance_type=""ml.m16"")\n    assert xgboost.train_image() == _get_full_cpu_image_uri(xgboost_version)\n\n\ndef test_attach(sagemaker_session, xgboost_version):\n    training_image = ""1.dkr.ecr.us-west-2.amazonaws.com/sagemaker-xgboost:{}-cpu-{}"".format(\n        xgboost_version, PYTHON_VERSION\n    )\n    returned_job_description = {\n        ""AlgorithmSpecification"": {""TrainingInputMode"": ""File"", ""TrainingImage"": training_image},\n        ""HyperParameters"": {\n            ""sagemaker_submit_directory"": \'""s3://some/sourcedir.tar.gz""\',\n            ""sagemaker_program"": \'""iris-dnn-classifier.py""\',\n            ""sagemaker_s3_uri_training"": \'""sagemaker-3/integ-test-data/tf_iris""\',\n            ""sagemaker_enable_cloudwatch_metrics"": ""false"",\n            ""sagemaker_container_log_level"": \'""logging.INFO""\',\n            ""sagemaker_job_name"": \'""neo""\',\n            ""training_steps"": ""100"",\n            ""sagemaker_region"": \'""us-west-2""\',\n        },\n        ""RoleArn"": ""arn:aws:iam::366:role/SageMakerRole"",\n        ""ResourceConfig"": {\n            ""VolumeSizeInGB"": 30,\n            ""InstanceCount"": 1,\n            ""InstanceType"": ""ml.c4.xlarge"",\n        },\n        ""StoppingCondition"": {""MaxRuntimeInSeconds"": 24 * 60 * 60},\n        ""TrainingJobName"": ""neo"",\n        ""TrainingJobStatus"": ""Completed"",\n        ""TrainingJobArn"": ""arn:aws:sagemaker:us-west-2:336:training-job/neo"",\n        ""OutputDataConfig"": {""KmsKeyId"": """", ""S3OutputPath"": ""s3://place/output/neo""},\n        ""TrainingJobOutput"": {""S3TrainingJobOutput"": ""s3://here/output.tar.gz""},\n    }\n    sagemaker_session.sagemaker_client.describe_training_job = Mock(\n        name=""describe_training_job"", return_value=returned_job_description\n    )\n\n    estimator = XGBoost.attach(training_job_name=""neo"", sagemaker_session=sagemaker_session)\n    assert estimator._current_job_name == ""neo""\n    assert estimator.latest_training_job.job_name == ""neo""\n    assert estimator.py_version == PYTHON_VERSION\n    assert estimator.framework_version == xgboost_version\n    assert estimator.role == ""arn:aws:iam::366:role/SageMakerRole""\n    assert estimator.train_instance_count == 1\n    assert estimator.train_max_run == 24 * 60 * 60\n    assert estimator.input_mode == ""File""\n    assert estimator.base_job_name == ""neo""\n    assert estimator.output_path == ""s3://place/output/neo""\n    assert estimator.output_kms_key == """"\n    assert estimator.hyperparameters()[""training_steps""] == ""100""\n    assert estimator.source_dir == ""s3://some/sourcedir.tar.gz""\n    assert estimator.entry_point == ""iris-dnn-classifier.py""\n\n\ndef test_attach_wrong_framework(sagemaker_session):\n    rjd = {\n        ""AlgorithmSpecification"": {\n            ""TrainingInputMode"": ""File"",\n            ""TrainingImage"": ""1.dkr.ecr.us-west-2.amazonaws.com/sagemaker-mxnet-py3-cpu:1.0.4"",\n        },\n        ""HyperParameters"": {\n            ""sagemaker_submit_directory"": \'""s3://some/sourcedir.tar.gz""\',\n            ""checkpoint_path"": \'""s3://other/1508872349""\',\n            ""sagemaker_program"": \'""iris-dnn-classifier.py""\',\n            ""sagemaker_enable_cloudwatch_metrics"": ""false"",\n            ""sagemaker_container_log_level"": \'""logging.INFO""\',\n            ""training_steps"": ""100"",\n            ""sagemaker_region"": \'""us-west-2""\',\n        },\n        ""RoleArn"": ""arn:aws:iam::366:role/SageMakerRole"",\n        ""ResourceConfig"": {\n            ""VolumeSizeInGB"": 30,\n            ""InstanceCount"": 1,\n            ""InstanceType"": ""ml.c4.xlarge"",\n        },\n        ""StoppingCondition"": {""MaxRuntimeInSeconds"": 24 * 60 * 60},\n        ""TrainingJobName"": ""neo"",\n        ""TrainingJobStatus"": ""Completed"",\n        ""TrainingJobArn"": ""arn:aws:sagemaker:us-west-2:336:training-job/neo"",\n        ""OutputDataConfig"": {""KmsKeyId"": """", ""S3OutputPath"": ""s3://place/output/neo""},\n        ""TrainingJobOutput"": {""S3TrainingJobOutput"": ""s3://here/output.tar.gz""},\n    }\n    sagemaker_session.sagemaker_client.describe_training_job = Mock(\n        name=""describe_training_job"", return_value=rjd\n    )\n\n    with pytest.raises(ValueError) as error:\n        XGBoost.attach(training_job_name=""neo"", sagemaker_session=sagemaker_session)\n    assert ""didn\'t use image for requested framework"" in str(error)\n\n\ndef test_attach_custom_image(sagemaker_session):\n    training_image = ""1.dkr.ecr.us-west-2.amazonaws.com/my_custom_xgboost_image:latest""\n    returned_job_description = {\n        ""AlgorithmSpecification"": {""TrainingInputMode"": ""File"", ""TrainingImage"": training_image},\n        ""HyperParameters"": {\n            ""sagemaker_submit_directory"": \'""s3://some/sourcedir.tar.gz""\',\n            ""sagemaker_program"": \'""iris-dnn-classifier.py""\',\n            ""sagemaker_s3_uri_training"": \'""sagemaker-3/integ-test-data/tf_iris""\',\n            ""sagemaker_enable_cloudwatch_metrics"": ""false"",\n            ""sagemaker_container_log_level"": \'""logging.INFO""\',\n            ""sagemaker_job_name"": \'""neo""\',\n            ""training_steps"": ""100"",\n            ""sagemaker_region"": \'""us-west-2""\',\n        },\n        ""RoleArn"": ""arn:aws:iam::366:role/SageMakerRole"",\n        ""ResourceConfig"": {\n            ""VolumeSizeInGB"": 30,\n            ""InstanceCount"": 1,\n            ""InstanceType"": ""ml.c4.xlarge"",\n        },\n        ""StoppingCondition"": {""MaxRuntimeInSeconds"": 24 * 60 * 60},\n        ""TrainingJobName"": ""neo"",\n        ""TrainingJobStatus"": ""Completed"",\n        ""TrainingJobArn"": ""arn:aws:sagemaker:us-west-2:336:training-job/neo"",\n        ""OutputDataConfig"": {""KmsKeyId"": """", ""S3OutputPath"": ""s3://place/output/neo""},\n        ""TrainingJobOutput"": {""S3TrainingJobOutput"": ""s3://here/output.tar.gz""},\n    }\n    sagemaker_session.sagemaker_client.describe_training_job = Mock(\n        name=""describe_training_job"", return_value=returned_job_description\n    )\n\n    with pytest.raises(TypeError) as error:\n        XGBoost.attach(training_job_name=""neo"", sagemaker_session=sagemaker_session)\n    assert ""expected string"" in str(error)\n\n\ndef test_py2_xgboost_attribute_error(sagemaker_session):\n    with pytest.raises(AttributeError) as error1:\n        XGBoost(\n            entry_point=SCRIPT_PATH,\n            role=ROLE,\n            framework_version=XGBOOST_LATEST_VERSION,\n            sagemaker_session=sagemaker_session,\n            train_instance_type=INSTANCE_TYPE,\n            train_instance_count=1,\n            py_version=""py2"",\n        )\n\n    with pytest.raises(AttributeError) as error2:\n        XGBoostModel(\n            model_data=DATA_DIR,\n            role=ROLE,\n            sagemaker_session=sagemaker_session,\n            entry_point=SCRIPT_PATH,\n            framework_version=XGBOOST_LATEST_VERSION,\n            py_version=""py2"",\n        )\n\n    error_message = ""XGBoost container does not support Python 2, please use Python 3""\n    assert error_message in str(error1)\n    assert error_message in str(error2)\n'"
tests/unit/tuner_test_utils.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport os\n\nfrom mock import Mock\nfrom sagemaker.amazon.pca import PCA\nfrom sagemaker.estimator import Estimator\nfrom sagemaker.parameter import CategoricalParameter, ContinuousParameter, IntegerParameter\nfrom sagemaker.tuner import WarmStartConfig, WarmStartTypes\n\nDATA_DIR = os.path.join(os.path.dirname(__file__), "".."", ""data"")\nMODEL_DATA = ""s3://bucket/model.tar.gz""\n\nJOB_NAME = ""tuning_job""\nTRAINING_JOB_NAME = ""training_job_neo""\nBASE_JOB_NAME = ""base_tuning_job""\nREGION = ""us-west-2""\nBUCKET_NAME = ""Some-Bucket""\nROLE = ""myrole""\nIMAGE_NAME = ""image""\n\nTRAIN_INSTANCE_COUNT = 1\nTRAIN_INSTANCE_TYPE = ""ml.c4.xlarge""\nNUM_COMPONENTS = 5\n\nSCRIPT_NAME = ""my_script.py""\nFRAMEWORK_VERSION = ""1.0.0""\n\nINPUTS = ""s3://mybucket/train""\n\nSTRATEGY = (""Bayesian"",)\nOBJECTIVE_TYPE = ""Minimize""\nEARLY_STOPPING_TYPE = ""Auto""\n\nOBJECTIVE_METRIC_NAME = ""mock_metric""\nOBJECTIVE_METRIC_NAME_TWO = ""mock_metric_two""\n\nHYPERPARAMETER_RANGES = {\n    ""validated"": ContinuousParameter(0, 5),\n    ""elizabeth"": IntegerParameter(0, 5),\n    ""blank"": CategoricalParameter([0, 5]),\n}\nHYPERPARAMETER_RANGES_TWO = {\n    ""num_components"": IntegerParameter(2, 4),\n    ""algorithm_mode"": CategoricalParameter([""regular"", ""randomized""]),\n}\n\nMETRIC_DEFINITIONS = ""mock_metric_definitions""\n\nMAX_JOBS = 10\nMAX_PARALLEL_JOBS = 5\nTAGS = [{""key1"": ""value1""}]\n\nLIST_TAGS_RESULT = {""Tags"": [{""Key"": ""key1"", ""Value"": ""value1""}]}\n\nESTIMATOR_NAME = ""estimator_name""\nESTIMATOR_NAME_TWO = ""estimator_name_two""\n\nSAGEMAKER_SESSION = Mock()\n\nESTIMATOR = Estimator(\n    IMAGE_NAME,\n    ROLE,\n    TRAIN_INSTANCE_COUNT,\n    TRAIN_INSTANCE_TYPE,\n    output_path=""s3://bucket/prefix"",\n    sagemaker_session=SAGEMAKER_SESSION,\n)\nESTIMATOR_TWO = PCA(\n    ROLE,\n    TRAIN_INSTANCE_COUNT,\n    TRAIN_INSTANCE_TYPE,\n    NUM_COMPONENTS,\n    sagemaker_session=SAGEMAKER_SESSION,\n)\n\nWARM_START_CONFIG = WarmStartConfig(\n    warm_start_type=WarmStartTypes.IDENTICAL_DATA_AND_ALGORITHM, parents={""p1"", ""p2"", ""p3""}\n)\n\nTUNING_JOB_DETAILS = {\n    ""HyperParameterTuningJobConfig"": {\n        ""ResourceLimits"": {""MaxParallelTrainingJobs"": 1, ""MaxNumberOfTrainingJobs"": 1},\n        ""HyperParameterTuningJobObjective"": {\n            ""MetricName"": OBJECTIVE_METRIC_NAME,\n            ""Type"": ""Minimize"",\n        },\n        ""Strategy"": ""Bayesian"",\n        ""ParameterRanges"": {\n            ""CategoricalParameterRanges"": [],\n            ""ContinuousParameterRanges"": [],\n            ""IntegerParameterRanges"": [\n                {\n                    ""MaxValue"": ""100"",\n                    ""Name"": ""mini_batch_size"",\n                    ""MinValue"": ""10"",\n                    ""ScalingType"": ""Auto"",\n                }\n            ],\n        },\n        ""TrainingJobEarlyStoppingType"": ""Off"",\n    },\n    ""HyperParameterTuningJobName"": JOB_NAME,\n    ""TrainingJobDefinition"": {\n        ""RoleArn"": ROLE,\n        ""StaticHyperParameters"": {\n            ""num_components"": ""10"",\n            ""_tuning_objective_metric"": ""train:throughput"",\n            ""feature_dim"": ""784"",\n            ""sagemaker_estimator_module"": \'""sagemaker.amazon.pca""\',\n            ""sagemaker_estimator_class_name"": \'""PCA""\',\n        },\n        ""ResourceConfig"": {\n            ""VolumeSizeInGB"": 30,\n            ""InstanceType"": ""ml.c4.xlarge"",\n            ""InstanceCount"": 1,\n        },\n        ""AlgorithmSpecification"": {\n            ""TrainingImage"": IMAGE_NAME,\n            ""TrainingInputMode"": ""File"",\n            ""MetricDefinitions"": METRIC_DEFINITIONS,\n        },\n        ""InputDataConfig"": [\n            {\n                ""ChannelName"": ""train"",\n                ""DataSource"": {\n                    ""S3DataSource"": {\n                        ""S3DataDistributionType"": ""ShardedByS3Key"",\n                        ""S3Uri"": INPUTS,\n                        ""S3DataType"": ""ManifestFile"",\n                    }\n                },\n            }\n        ],\n        ""StoppingCondition"": {""MaxRuntimeInSeconds"": 86400},\n        ""OutputDataConfig"": {""S3OutputPath"": BUCKET_NAME},\n    },\n    ""TrainingJobCounters"": {\n        ""ClientError"": 0,\n        ""Completed"": 1,\n        ""InProgress"": 0,\n        ""Fault"": 0,\n        ""Stopped"": 0,\n    },\n    ""HyperParameterTuningEndTime"": 1526605831.0,\n    ""CreationTime"": 1526605605.0,\n    ""HyperParameterTuningJobArn"": ""arn:tuning_job"",\n}\n\nMULTI_ALGO_TUNING_JOB_DETAILS = {\n    ""HyperParameterTuningJobConfig"": {\n        ""ResourceLimits"": {""MaxParallelTrainingJobs"": 2, ""MaxNumberOfTrainingJobs"": 4},\n        ""Strategy"": ""Bayesian"",\n        ""TrainingJobEarlyStoppingType"": ""Off"",\n    },\n    ""HyperParameterTuningJobName"": JOB_NAME,\n    ""TrainingJobDefinitions"": [\n        {\n            ""DefinitionName"": ESTIMATOR_NAME,\n            ""TuningObjective"": {""MetricName"": OBJECTIVE_METRIC_NAME, ""Type"": ""Minimize""},\n            ""HyperParameterRanges"": {\n                ""CategoricalParameterRanges"": [],\n                ""ContinuousParameterRanges"": [],\n                ""IntegerParameterRanges"": [\n                    {\n                        ""MaxValue"": ""100"",\n                        ""Name"": ""mini_batch_size"",\n                        ""MinValue"": ""10"",\n                        ""ScalingType"": ""Auto"",\n                    }\n                ],\n            },\n            ""RoleArn"": ROLE,\n            ""StaticHyperParameters"": {\n                ""num_components"": ""1"",\n                ""_tuning_objective_metric"": ""train:throughput"",\n                ""feature_dim"": ""784"",\n                ""sagemaker_estimator_module"": \'""sagemaker.amazon.pca""\',\n                ""sagemaker_estimator_class_name"": \'""PCA""\',\n            },\n            ""ResourceConfig"": {\n                ""VolumeSizeInGB"": 30,\n                ""InstanceType"": ""ml.c4.xlarge"",\n                ""InstanceCount"": 1,\n            },\n            ""AlgorithmSpecification"": {""TrainingImage"": IMAGE_NAME, ""TrainingInputMode"": ""File""},\n            ""InputDataConfig"": [\n                {\n                    ""ChannelName"": ""train"",\n                    ""DataSource"": {\n                        ""S3DataSource"": {\n                            ""S3DataDistributionType"": ""ShardedByS3Key"",\n                            ""S3Uri"": INPUTS,\n                            ""S3DataType"": ""ManifestFile"",\n                        }\n                    },\n                }\n            ],\n            ""StoppingCondition"": {""MaxRuntimeInSeconds"": 86400},\n            ""OutputDataConfig"": {""S3OutputPath"": BUCKET_NAME},\n        },\n        {\n            ""DefinitionName"": ESTIMATOR_NAME_TWO,\n            ""TuningObjective"": {""MetricName"": OBJECTIVE_METRIC_NAME_TWO, ""Type"": ""Minimize""},\n            ""HyperParameterRanges"": {\n                ""CategoricalParameterRanges"": [{""Name"": ""kernel"", ""Values"": [""rbf"", ""sigmoid""]}],\n                ""ContinuousParameterRanges"": [],\n                ""IntegerParameterRanges"": [\n                    {""MaxValue"": ""10"", ""Name"": ""tree_count"", ""MinValue"": ""1"", ""ScalingType"": ""Auto""}\n                ],\n            },\n            ""RoleArn"": ROLE,\n            ""StaticHyperParameters"": {\n                ""blank"": ""1"",\n                ""_tuning_objective_metric"": OBJECTIVE_METRIC_NAME_TWO,\n            },\n            ""ResourceConfig"": {\n                ""VolumeSizeInGB"": 30,\n                ""InstanceType"": ""ml.m4.4xlarge"",\n                ""InstanceCount"": 1,\n            },\n            ""AlgorithmSpecification"": {\n                ""TrainingImage"": IMAGE_NAME,\n                ""TrainingInputMode"": ""File"",\n                ""MetricDefinitions"": METRIC_DEFINITIONS,\n            },\n            ""InputDataConfig"": [\n                {\n                    ""ChannelName"": ""train"",\n                    ""DataSource"": {\n                        ""S3DataSource"": {\n                            ""S3DataDistributionType"": ""ShardedByS3Key"",\n                            ""S3Uri"": INPUTS,\n                            ""S3DataType"": ""ManifestFile"",\n                        }\n                    },\n                }\n            ],\n            ""StoppingCondition"": {""MaxRuntimeInSeconds"": 86400},\n            ""OutputDataConfig"": {""S3OutputPath"": BUCKET_NAME},\n        },\n    ],\n    ""TrainingJobCounters"": {\n        ""ClientError"": 0,\n        ""Completed"": 1,\n        ""InProgress"": 0,\n        ""Fault"": 0,\n        ""Stopped"": 0,\n    },\n    ""HyperParameterTuningEndTime"": 1526605831.0,\n    ""CreationTime"": 1526605605.0,\n    ""HyperParameterTuningJobArn"": ""arn:tuning_job"",\n}\n\nTRAINING_JOB_DESCRIPTION = {\n    ""AlgorithmSpecification"": {\n        ""TrainingInputMode"": ""File"",\n        ""TrainingImage"": IMAGE_NAME,\n        ""MetricDefinitions"": METRIC_DEFINITIONS,\n    },\n    ""HyperParameters"": {\n        ""sagemaker_submit_directory"": \'""s3://some/sourcedir.tar.gz""\',\n        ""checkpoint_path"": \'""s3://other/1508872349""\',\n        ""sagemaker_program"": \'""iris-dnn-classifier.py""\',\n        ""sagemaker_enable_cloudwatch_metrics"": ""false"",\n        ""sagemaker_container_log_level"": \'""logging.INFO""\',\n        ""sagemaker_job_name"": \'""neo""\',\n        ""training_steps"": ""100"",\n        ""_tuning_objective_metric"": ""Validation-accuracy"",\n    },\n    ""RoleArn"": ROLE,\n    ""ResourceConfig"": {""VolumeSizeInGB"": 30, ""InstanceCount"": 1, ""InstanceType"": ""ml.c4.xlarge""},\n    ""StoppingCondition"": {""MaxRuntimeInSeconds"": 24 * 60 * 60},\n    ""TrainingJobName"": TRAINING_JOB_NAME,\n    ""TrainingJobStatus"": ""Completed"",\n    ""TrainingJobArn"": ""arn:aws:sagemaker:us-west-2:336:training-job/neo"",\n    ""OutputDataConfig"": {""KmsKeyId"": """", ""S3OutputPath"": ""s3://place/output/neo""},\n    ""TrainingJobOutput"": {""S3TrainingJobOutput"": ""s3://here/output.tar.gz""},\n    ""ModelArtifacts"": {""S3ModelArtifacts"": MODEL_DATA},\n}\n\nENDPOINT_DESC = {""EndpointConfigName"": ""test-endpoint""}\n\nENDPOINT_CONFIG_DESC = {""ProductionVariants"": [{""ModelName"": ""model-1""}, {""ModelName"": ""model-2""}]}\n'"
examples/cli/host/script.py,0,"b'from __future__ import print_function\n\nimport json\nimport mxnet as mx\nfrom mxnet import gluon\n\n\ndef model_fn(model_dir):\n    """"""Load the gluon model. Called once when hosting service starts.\n\n    Args:\n        model_dir: The directory where model files are stored.\n\n    Returns:\n        a model (in this case a Gluon network)\n    """"""\n    symbol = mx.sym.load(""%s/model.json"" % model_dir)\n    outputs = mx.symbol.softmax(data=symbol, name=""softmax_label"")\n    inputs = mx.sym.var(""data"")\n    param_dict = gluon.ParameterDict(""model_"")\n    net = gluon.SymbolBlock(outputs, inputs, param_dict)\n    net.load_params(""%s/model.params"" % model_dir, ctx=mx.cpu())\n    return net\n\n\ndef transform_fn(net, data, input_content_type, output_content_type):\n    """"""Transform a request using the Gluon model. Called once per request.\n\n    Args:\n        net: The Gluon model.\n        data: The request payload.\n        input_content_type: The request content type.\n        output_content_type: The (desired) response content type.\n\n    Returns:\n        response payload and content type.\n    """"""\n    # we can use content types to vary input/output handling, but\n    # here we just assume json for both\n    parsed = json.loads(data)\n    nda = mx.nd.array(parsed)\n    output = net(nda)\n    prediction = mx.nd.argmax(output, axis=1)\n    response_body = json.dumps(prediction.asnumpy().tolist())\n    return response_body, output_content_type\n'"
examples/cli/train/download_training_data.py,0,"b'from mxnet import gluon\n\n\ndef download_training_data():\n    gluon.data.vision.MNIST(""./data/training"", train=True)\n    gluon.data.vision.MNIST(""./data/training"", train=False)\n\n\nif __name__ == ""__main__"":\n    download_training_data()\n'"
examples/cli/train/script.py,0,"b'import logging\nimport time\n\nimport mxnet as mx\nimport numpy as np\nfrom mxnet import gluon, autograd\nfrom mxnet.gluon import nn\n\nlogger = logging.getLogger(__name__)\n\n\ndef train(channel_input_dirs, hyperparameters, **kwargs):\n    # SageMaker passes num_cpus, num_gpus and other args we can use to tailor training to\n    # the current container environment, but here we just use simple cpu context.\n    """"""\n    Args:\n        channel_input_dirs:\n        hyperparameters:\n        **kwargs:\n    """"""\n    ctx = mx.cpu()\n\n    # retrieve the hyperparameters we set in notebook (with some defaults)\n    batch_size = hyperparameters.get(""batch_size"", 100)\n    epochs = hyperparameters.get(""epochs"", 10)\n    learning_rate = hyperparameters.get(""learning_rate"", 0.1)\n    momentum = hyperparameters.get(""momentum"", 0.9)\n    log_interval = hyperparameters.get(""log_interval"", 100)\n\n    training_data = channel_input_dirs[""training""]\n\n    # load training and validation data\n    # we use the gluon.data.vision.MNIST class because of its built in mnist pre-processing logic,\n    # but point it at the location where SageMaker placed the data files, so it doesn\'t download them again.\n    train_data = get_train_data(training_data, batch_size)\n    val_data = get_val_data(training_data, batch_size)\n\n    # define the network\n    net = define_network()\n\n    # Collect all parameters from net and its children, then initialize them.\n    net.initialize(mx.init.Xavier(magnitude=2.24), ctx=ctx)\n    # Trainer is for updating parameters with gradient.\n    trainer = gluon.Trainer(\n        net.collect_params(), ""sgd"", {""learning_rate"": learning_rate, ""momentum"": momentum}\n    )\n    metric = mx.metric.Accuracy()\n    loss = gluon.loss.SoftmaxCrossEntropyLoss()\n\n    for epoch in range(epochs):\n        # reset data iterator and metric at begining of epoch.\n        metric.reset()\n        btic = time.time()\n        for i, (data, label) in enumerate(train_data):\n            # Copy data to ctx if necessary\n            data = data.as_in_context(ctx)\n            label = label.as_in_context(ctx)\n            # Start recording computation graph with record() section.\n            # Recorded graphs can then be differentiated with backward.\n            with autograd.record():\n                output = net(data)\n                L = loss(output, label)\n                L.backward()\n            # take a gradient step with batch_size equal to data.shape[0]\n            trainer.step(data.shape[0])\n            # update metric at last.\n            metric.update([label], [output])\n\n            if i % log_interval == 0 and i > 0:\n                name, acc = metric.get()\n                logger.info(\n                    ""[Epoch %d Batch %d] Training: %s=%f, %f samples/s""\n                    % (epoch, i, name, acc, batch_size / (time.time() - btic))\n                )\n\n            btic = time.time()\n\n        name, acc = metric.get()\n        logger.info(""[Epoch %d] Training: %s=%f"" % (epoch, name, acc))\n\n        name, val_acc = test(ctx, net, val_data)\n        logger.info(""[Epoch %d] Validation: %s=%f"" % (epoch, name, val_acc))\n\n    return net\n\n\ndef save(net, model_dir):\n    # save the model\n    """"""\n    Args:\n        net:\n        model_dir:\n    """"""\n    y = net(mx.sym.var(""data""))\n    y.save(""%s/model.json"" % model_dir)\n    net.collect_params().save(""%s/model.params"" % model_dir)\n\n\ndef define_network():\n    net = nn.Sequential()\n    with net.name_scope():\n        net.add(nn.Dense(128, activation=""relu""))\n        net.add(nn.Dense(64, activation=""relu""))\n        net.add(nn.Dense(10))\n    return net\n\n\ndef input_transformer(data, label):\n    """"""\n    Args:\n        data:\n        label:\n    """"""\n    data = data.reshape((-1,)).astype(np.float32) / 255\n    return data, label\n\n\ndef get_train_data(data_dir, batch_size):\n    """"""\n    Args:\n        data_dir:\n        batch_size:\n    """"""\n    return gluon.data.DataLoader(\n        gluon.data.vision.MNIST(data_dir, train=True, transform=input_transformer),\n        batch_size=batch_size,\n        shuffle=True,\n        last_batch=""discard"",\n    )\n\n\ndef get_val_data(data_dir, batch_size):\n    """"""\n    Args:\n        data_dir:\n        batch_size:\n    """"""\n    return gluon.data.DataLoader(\n        gluon.data.vision.MNIST(data_dir, train=False, transform=input_transformer),\n        batch_size=batch_size,\n        shuffle=False,\n    )\n\n\ndef test(ctx, net, val_data):\n    """"""\n    Args:\n        ctx:\n        net:\n        val_data:\n    """"""\n    metric = mx.metric.Accuracy()\n    for data, label in val_data:\n        data = data.as_in_context(ctx)\n        label = label.as_in_context(ctx)\n        output = net(data)\n        metric.update([label], [output])\n    return metric.get()\n'"
src/sagemaker/amazon/__init__.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n'"
src/sagemaker/amazon/amazon_estimator.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nimport json\nimport logging\nimport tempfile\n\nfrom six.moves.urllib.parse import urlparse\n\nfrom sagemaker.amazon import validation\nfrom sagemaker.amazon.hyperparameter import Hyperparameter as hp  # noqa\nfrom sagemaker.amazon.common import write_numpy_to_dense_tensor\nfrom sagemaker.estimator import EstimatorBase, _TrainingJob\nfrom sagemaker.inputs import FileSystemInput\nfrom sagemaker.model import NEO_IMAGE_ACCOUNT\nfrom sagemaker.session import s3_input\nfrom sagemaker.utils import sagemaker_timestamp, get_ecr_image_uri_prefix\nfrom sagemaker.xgboost.defaults import (\n    XGBOOST_1P_VERSIONS,\n    XGBOOST_LATEST_VERSION,\n    XGBOOST_NAME,\n    XGBOOST_SUPPORTED_VERSIONS,\n    XGBOOST_VERSION_EQUIVALENTS,\n)\nfrom sagemaker.xgboost.estimator import get_xgboost_image_uri\n\nlogger = logging.getLogger(__name__)\n\n\nclass AmazonAlgorithmEstimatorBase(EstimatorBase):\n    """"""Base class for Amazon first-party Estimator implementations. This class\n    isn\'t intended to be instantiated directly.\n    """"""\n\n    feature_dim = hp(""feature_dim"", validation.gt(0), data_type=int)\n    mini_batch_size = hp(""mini_batch_size"", validation.gt(0), data_type=int)\n    repo_name = None\n    repo_version = None\n\n    def __init__(\n        self,\n        role,\n        train_instance_count,\n        train_instance_type,\n        data_location=None,\n        enable_network_isolation=False,\n        **kwargs\n    ):\n        """"""Initialize an AmazonAlgorithmEstimatorBase.\n\n        Args:\n            role (str): An AWS IAM role (either name or full ARN). The Amazon\n                SageMaker training jobs and APIs that create Amazon SageMaker\n                endpoints use this role to access training data and model\n                artifacts. After the endpoint is created, the inference code\n                might use the IAM role, if it needs to access an AWS resource.\n            train_instance_count (int): Number of Amazon EC2 instances to use\n                for training.\n            train_instance_type (str): Type of EC2 instance to use for training,\n                for example, \'ml.c4.xlarge\'.\n            data_location (str or None): The s3 prefix to upload RecordSet\n                objects to, expressed as an S3 url. For example\n                ""s3://example-bucket/some-key-prefix/"". Objects will be saved in\n                a unique sub-directory of the specified location. If None, a\n                default data location will be used.\n            enable_network_isolation (bool): Specifies whether container will\n                run in network isolation mode. Network isolation mode restricts\n                the container access to outside networks (such as the internet).\n                Also known as internet-free mode (default: ``False``).\n            **kwargs: Additional parameters passed to\n                :class:`~sagemaker.estimator.EstimatorBase`.\n\n        .. tip::\n\n            You can find additional parameters for initializing this class at\n            :class:`~sagemaker.estimator.EstimatorBase`.\n        """"""\n        super(AmazonAlgorithmEstimatorBase, self).__init__(\n            role,\n            train_instance_count,\n            train_instance_type,\n            enable_network_isolation=enable_network_isolation,\n            **kwargs\n        )\n\n        data_location = data_location or ""s3://{}/sagemaker-record-sets/"".format(\n            self.sagemaker_session.default_bucket()\n        )\n        self._data_location = data_location\n\n    def train_image(self):\n        """"""Placeholder docstring""""""\n        return get_image_uri(\n            self.sagemaker_session.boto_region_name, type(self).repo_name, type(self).repo_version\n        )\n\n    def hyperparameters(self):\n        """"""Placeholder docstring""""""\n        return hp.serialize_all(self)\n\n    @property\n    def data_location(self):\n        """"""Placeholder docstring""""""\n        return self._data_location\n\n    @data_location.setter\n    def data_location(self, data_location):\n        """"""\n        Args:\n            data_location:\n        """"""\n        if not data_location.startswith(""s3://""):\n            raise ValueError(\n                \'Expecting an S3 URL beginning with ""s3://"". Got ""{}""\'.format(data_location)\n            )\n        if data_location[-1] != ""/"":\n            data_location = data_location + ""/""\n        self._data_location = data_location\n\n    @classmethod\n    def _prepare_init_params_from_job_description(cls, job_details, model_channel_name=None):\n        """"""Convert the job description to init params that can be handled by the\n        class constructor\n\n        Args:\n            job_details: the returned job details from a describe_training_job\n                API call.\n            model_channel_name (str): Name of the channel where pre-trained\n                model data will be downloaded.\n\n        Returns:\n            dictionary: The transformed init_params\n        """"""\n        init_params = super(\n            AmazonAlgorithmEstimatorBase, cls\n        )._prepare_init_params_from_job_description(job_details, model_channel_name)\n\n        # The hyperparam names may not be the same as the class attribute that holds them,\n        # for instance: local_lloyd_init_method is called local_init_method. We need to map these\n        # and pass the correct name to the constructor.\n        for attribute, value in cls.__dict__.items():\n            if isinstance(value, hp):\n                if value.name in init_params[""hyperparameters""]:\n                    init_params[attribute] = init_params[""hyperparameters""][value.name]\n\n        del init_params[""hyperparameters""]\n        del init_params[""image""]\n        return init_params\n\n    def prepare_workflow_for_training(self, records=None, mini_batch_size=None, job_name=None):\n        """"""Calls _prepare_for_training. Used when setting up a workflow.\n\n        Args:\n            records (:class:`~RecordSet`): The records to train this ``Estimator`` on.\n            mini_batch_size (int or None): The size of each mini-batch to use when\n                training. If ``None``, a default value will be used.\n            job_name (str): Name of the training job to be created. If not\n                specified, one is generated, using the base name given to the\n                constructor if applicable.\n        """"""\n        self._prepare_for_training(\n            records=records, mini_batch_size=mini_batch_size, job_name=job_name\n        )\n\n    def _prepare_for_training(self, records, mini_batch_size=None, job_name=None):\n        """"""Set hyperparameters needed for training.\n\n        Args:\n            records (:class:`~RecordSet`): The records to train this ``Estimator`` on.\n            mini_batch_size (int or None): The size of each mini-batch to use when\n                training. If ``None``, a default value will be used.\n            job_name (str): Name of the training job to be created. If not\n                specified, one is generated, using the base name given to the\n                constructor if applicable.\n        """"""\n        super(AmazonAlgorithmEstimatorBase, self)._prepare_for_training(job_name=job_name)\n\n        feature_dim = None\n\n        if isinstance(records, list):\n            for record in records:\n                if record.channel == ""train"":\n                    feature_dim = record.feature_dim\n                    break\n            if feature_dim is None:\n                raise ValueError(""Must provide train channel."")\n        else:\n            feature_dim = records.feature_dim\n\n        self.feature_dim = feature_dim\n        self.mini_batch_size = mini_batch_size\n\n    def fit(\n        self,\n        records,\n        mini_batch_size=None,\n        wait=True,\n        logs=True,\n        job_name=None,\n        experiment_config=None,\n    ):\n        """"""Fit this Estimator on serialized Record objects, stored in S3.\n\n        ``records`` should be an instance of :class:`~RecordSet`. This\n        defines a collection of S3 data files to train this ``Estimator`` on.\n\n        Training data is expected to be encoded as dense or sparse vectors in\n        the ""values"" feature on each Record. If the data is labeled, the label\n        is expected to be encoded as a list of scalas in the ""values"" feature of\n        the Record label.\n\n        More information on the Amazon Record format is available at:\n        https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-training.html\n\n        See :meth:`~AmazonAlgorithmEstimatorBase.record_set` to construct a\n        ``RecordSet`` object from :class:`~numpy.ndarray` arrays.\n\n        Args:\n            records (:class:`~RecordSet`): The records to train this ``Estimator`` on\n            mini_batch_size (int or None): The size of each mini-batch to use\n                when training. If ``None``, a default value will be used.\n            wait (bool): Whether the call should wait until the job completes\n                (default: True).\n            logs (bool): Whether to show the logs produced by the job. Only\n                meaningful when wait is True (default: True).\n            job_name (str): Training job name. If not specified, the estimator\n                generates a default job name, based on the training image name\n                and current timestamp.\n            experiment_config (dict[str, str]): Experiment management configuration.\n                Dictionary contains three optional keys, \'ExperimentName\',\n                \'TrialName\', and \'TrialComponentName\'\n                (default: ``None``).\n        """"""\n        self._prepare_for_training(records, job_name=job_name, mini_batch_size=mini_batch_size)\n\n        self.latest_training_job = _TrainingJob.start_new(\n            self, records, experiment_config=experiment_config\n        )\n        if wait:\n            self.latest_training_job.wait(logs=logs)\n\n    def record_set(self, train, labels=None, channel=""train"", encrypt=False):\n        """"""Build a :class:`~RecordSet` from a numpy :class:`~ndarray` matrix and\n        label vector.\n\n        For the 2D ``ndarray`` ``train``, each row is converted to a\n        :class:`~Record` object. The vector is stored in the ""values"" entry of\n        the ``features`` property of each Record. If ``labels`` is not None,\n        each corresponding label is assigned to the ""values"" entry of the\n        ``labels`` property of each Record.\n\n        The collection of ``Record`` objects are protobuf serialized and\n        uploaded to new S3 locations. A manifest file is generated containing\n        the list of objects created and also stored in S3.\n\n        The number of S3 objects created is controlled by the\n        ``train_instance_count`` property on this Estimator. One S3 object is\n        created per training instance.\n\n        Args:\n            train (numpy.ndarray): A 2D numpy array of training data.\n            labels (numpy.ndarray): A 1D numpy array of labels. Its length must\n                be equal to the number of rows in ``train``.\n            channel (str): The SageMaker TrainingJob channel this RecordSet\n                should be assigned to.\n            encrypt (bool): Specifies whether the objects uploaded to S3 are\n                encrypted on the server side using AES-256 (default: ``False``).\n\n        Returns:\n            RecordSet: A RecordSet referencing the encoded, uploading training\n            and label data.\n        """"""\n        s3 = self.sagemaker_session.boto_session.resource(\n            ""s3"", region_name=self.sagemaker_session.boto_region_name\n        )\n        parsed_s3_url = urlparse(self.data_location)\n        bucket, key_prefix = parsed_s3_url.netloc, parsed_s3_url.path\n        key_prefix = key_prefix + ""{}-{}/"".format(type(self).__name__, sagemaker_timestamp())\n        key_prefix = key_prefix.lstrip(""/"")\n        logger.debug(""Uploading to bucket %s and key_prefix %s"", bucket, key_prefix)\n        manifest_s3_file = upload_numpy_to_s3_shards(\n            self.train_instance_count, s3, bucket, key_prefix, train, labels, encrypt\n        )\n        logger.debug(""Created manifest file %s"", manifest_s3_file)\n        return RecordSet(\n            manifest_s3_file,\n            num_records=train.shape[0],\n            feature_dim=train.shape[1],\n            channel=channel,\n        )\n\n\nclass RecordSet(object):\n    """"""Placeholder docstring""""""\n\n    def __init__(\n        self, s3_data, num_records, feature_dim, s3_data_type=""ManifestFile"", channel=""train""\n    ):\n        """"""A collection of Amazon :class:~`Record` objects serialized and stored\n        in S3.\n\n        Args:\n            s3_data (str): The S3 location of the training data\n            num_records (int): The number of records in the set.\n            feature_dim (int): The dimensionality of ""values"" arrays in the\n                Record features, and label (if each Record is labeled).\n            s3_data_type (str): Valid values: \'S3Prefix\', \'ManifestFile\'. If\n                \'S3Prefix\', ``s3_data`` defines a prefix of s3 objects to train\n                on. All objects with s3 keys beginning with ``s3_data`` will be\n                used to train. If \'ManifestFile\', then ``s3_data`` defines a\n                single s3 manifest file, listing each s3 object to train on.\n            channel (str): The SageMaker Training Job channel this RecordSet\n                should be bound to\n        """"""\n        self.s3_data = s3_data\n        self.feature_dim = feature_dim\n        self.num_records = num_records\n        self.s3_data_type = s3_data_type\n        self.channel = channel\n\n    def __repr__(self):\n        """"""Return an unambiguous representation of this RecordSet""""""\n        return str((RecordSet, self.__dict__))\n\n    def data_channel(self):\n        """"""Return a dictionary to represent the training data in a channel for\n        use with ``fit()``\n        """"""\n        return {self.channel: self.records_s3_input()}\n\n    def records_s3_input(self):\n        """"""Return a s3_input to represent the training data""""""\n        return s3_input(self.s3_data, distribution=""ShardedByS3Key"", s3_data_type=self.s3_data_type)\n\n\nclass FileSystemRecordSet(object):\n    """"""Amazon SageMaker channel configuration for a file system data source\n    for Amazon algorithms.\n    """"""\n\n    def __init__(\n        self,\n        file_system_id,\n        file_system_type,\n        directory_path,\n        num_records,\n        feature_dim,\n        file_system_access_mode=""ro"",\n        channel=""train"",\n    ):\n        """"""Initialize a ``FileSystemRecordSet`` object.\n\n        Args:\n            file_system_id (str): An Amazon file system ID starting with \'fs-\'.\n            file_system_type (str): The type of file system used for the input.\n                Valid values: \'EFS\', \'FSxLustre\'.\n            directory_path (str): Absolute or normalized path to the root directory (mount point) in\n                the file system. Reference:\n                https://docs.aws.amazon.com/efs/latest/ug/mounting-fs.html and\n                https://docs.aws.amazon.com/efs/latest/ug/wt1-test.html\n            num_records (int): The number of records in the set.\n            feature_dim (int): The dimensionality of ""values"" arrays in the Record features,\n                and label (if each Record is labeled).\n            file_system_access_mode (str): Permissions for read and write.\n                Valid values: \'ro\' or \'rw\'. Defaults to \'ro\'.\n            channel (str): The SageMaker Training Job channel this RecordSet should be bound to\n        """"""\n\n        self.file_system_input = FileSystemInput(\n            file_system_id, file_system_type, directory_path, file_system_access_mode\n        )\n        self.feature_dim = feature_dim\n        self.num_records = num_records\n        self.channel = channel\n\n    def __repr__(self):\n        """"""Return an unambiguous representation of this RecordSet""""""\n        return str((FileSystemRecordSet, self.__dict__))\n\n    def data_channel(self):\n        """"""Return a dictionary to represent the training data in a channel for use with ``fit()``""""""\n        return {self.channel: self.file_system_input}\n\n\ndef _build_shards(num_shards, array):\n    """"""\n    Args:\n        num_shards:\n        array:\n    """"""\n    if num_shards < 1:\n        raise ValueError(""num_shards must be >= 1"")\n    shard_size = int(array.shape[0] / num_shards)\n    if shard_size == 0:\n        raise ValueError(""Array length is less than num shards"")\n    shards = [array[i * shard_size : i * shard_size + shard_size] for i in range(num_shards - 1)]\n    shards.append(array[(num_shards - 1) * shard_size :])\n    return shards\n\n\ndef upload_numpy_to_s3_shards(\n    num_shards, s3, bucket, key_prefix, array, labels=None, encrypt=False\n):\n    """"""Upload the training ``array`` and ``labels`` arrays to ``num_shards`` S3\n    objects, stored in ""s3:// ``bucket`` / ``key_prefix`` /"". Optionally\n    ``encrypt`` the S3 objects using AES-256.\n\n    Args:\n        num_shards:\n        s3:\n        bucket:\n        key_prefix:\n        array:\n        labels:\n        encrypt:\n    """"""\n    shards = _build_shards(num_shards, array)\n    if labels is not None:\n        label_shards = _build_shards(num_shards, labels)\n    uploaded_files = []\n    if key_prefix[-1] != ""/"":\n        key_prefix = key_prefix + ""/""\n    extra_put_kwargs = {""ServerSideEncryption"": ""AES256""} if encrypt else {}\n    try:\n        for shard_index, shard in enumerate(shards):\n            with tempfile.TemporaryFile() as file:\n                if labels is not None:\n                    write_numpy_to_dense_tensor(file, shard, label_shards[shard_index])\n                else:\n                    write_numpy_to_dense_tensor(file, shard)\n                file.seek(0)\n                shard_index_string = str(shard_index).zfill(len(str(len(shards))))\n                file_name = ""matrix_{}.pbr"".format(shard_index_string)\n                key = key_prefix + file_name\n                logger.debug(""Creating object %s in bucket %s"", key, bucket)\n                s3.Object(bucket, key).put(Body=file, **extra_put_kwargs)\n                uploaded_files.append(file_name)\n        manifest_key = key_prefix + "".amazon.manifest""\n        manifest_str = json.dumps(\n            [{""prefix"": ""s3://{}/{}"".format(bucket, key_prefix)}] + uploaded_files\n        )\n        s3.Object(bucket, manifest_key).put(Body=manifest_str.encode(""utf-8""), **extra_put_kwargs)\n        return ""s3://{}/{}"".format(bucket, manifest_key)\n    except Exception as ex:  # pylint: disable=broad-except\n        try:\n            for file in uploaded_files:\n                s3.Object(bucket, key_prefix + file).delete()\n        finally:\n            raise ex\n\n\ndef registry(region_name, algorithm=None):\n    """"""Return docker registry for the given AWS region\n\n    Note: Not all the algorithms listed below have an Amazon Estimator\n    implemented. For full list of pre-implemented Estimators, look at:\n\n    https://github.com/aws/sagemaker-python-sdk/tree/master/src/sagemaker/amazon\n\n    Args:\n        region_name (str): The region name for the account.\n        algorithm (str): The algorithm for the account.\n\n    Raises:\n        ValueError: If invalid algorithm passed in or if mapping does not exist for given algorithm\n            and region.\n    """"""\n    region_to_accounts = {}\n    if algorithm in [\n        None,\n        ""pca"",\n        ""kmeans"",\n        ""linear-learner"",\n        ""factorization-machines"",\n        ""ntm"",\n        ""randomcutforest"",\n        ""knn"",\n        ""object2vec"",\n        ""ipinsights"",\n    ]:\n        region_to_accounts = {\n            ""us-east-1"": ""382416733822"",\n            ""us-east-2"": ""404615174143"",\n            ""us-west-2"": ""174872318107"",\n            ""eu-west-1"": ""438346466558"",\n            ""eu-central-1"": ""664544806723"",\n            ""ap-northeast-1"": ""351501993468"",\n            ""ap-northeast-2"": ""835164637446"",\n            ""ap-southeast-2"": ""712309505854"",\n            ""us-gov-west-1"": ""226302683700"",\n            ""ap-southeast-1"": ""475088953585"",\n            ""ap-south-1"": ""991648021394"",\n            ""ca-central-1"": ""469771592824"",\n            ""eu-west-2"": ""644912444149"",\n            ""us-west-1"": ""632365934929"",\n            ""us-iso-east-1"": ""490574956308"",\n            ""ap-east-1"": ""286214385809"",\n            ""eu-north-1"": ""669576153137"",\n            ""eu-west-3"": ""749696950732"",\n            ""sa-east-1"": ""855470959533"",\n            ""me-south-1"": ""249704162688"",\n            ""cn-north-1"": ""390948362332"",\n            ""cn-northwest-1"": ""387376663083"",\n        }\n    elif algorithm in [""lda""]:\n        region_to_accounts = {\n            ""us-east-1"": ""766337827248"",\n            ""us-east-2"": ""999911452149"",\n            ""us-west-2"": ""266724342769"",\n            ""eu-west-1"": ""999678624901"",\n            ""eu-central-1"": ""353608530281"",\n            ""ap-northeast-1"": ""258307448986"",\n            ""ap-northeast-2"": ""293181348795"",\n            ""ap-southeast-2"": ""297031611018"",\n            ""us-gov-west-1"": ""226302683700"",\n            ""ap-southeast-1"": ""475088953585"",\n            ""ap-south-1"": ""991648021394"",\n            ""ca-central-1"": ""469771592824"",\n            ""eu-west-2"": ""644912444149"",\n            ""us-west-1"": ""632365934929"",\n            ""us-iso-east-1"": ""490574956308"",\n        }\n    elif algorithm in [""forecasting-deepar""]:\n        region_to_accounts = {\n            ""us-east-1"": ""522234722520"",\n            ""us-east-2"": ""566113047672"",\n            ""us-west-2"": ""156387875391"",\n            ""eu-west-1"": ""224300973850"",\n            ""eu-central-1"": ""495149712605"",\n            ""ap-northeast-1"": ""633353088612"",\n            ""ap-northeast-2"": ""204372634319"",\n            ""ap-southeast-2"": ""514117268639"",\n            ""us-gov-west-1"": ""226302683700"",\n            ""ap-southeast-1"": ""475088953585"",\n            ""ap-south-1"": ""991648021394"",\n            ""ca-central-1"": ""469771592824"",\n            ""eu-west-2"": ""644912444149"",\n            ""us-west-1"": ""632365934929"",\n            ""us-iso-east-1"": ""490574956308"",\n            ""ap-east-1"": ""286214385809"",\n            ""eu-north-1"": ""669576153137"",\n            ""eu-west-3"": ""749696950732"",\n            ""sa-east-1"": ""855470959533"",\n            ""me-south-1"": ""249704162688"",\n            ""cn-north-1"": ""390948362332"",\n            ""cn-northwest-1"": ""387376663083"",\n        }\n    elif algorithm in [\n        ""xgboost"",\n        ""seq2seq"",\n        ""image-classification"",\n        ""blazingtext"",\n        ""object-detection"",\n        ""semantic-segmentation"",\n    ]:\n        region_to_accounts = {\n            ""us-east-1"": ""811284229777"",\n            ""us-east-2"": ""825641698319"",\n            ""us-west-2"": ""433757028032"",\n            ""eu-west-1"": ""685385470294"",\n            ""eu-central-1"": ""813361260812"",\n            ""ap-northeast-1"": ""501404015308"",\n            ""ap-northeast-2"": ""306986355934"",\n            ""ap-southeast-2"": ""544295431143"",\n            ""us-gov-west-1"": ""226302683700"",\n            ""ap-southeast-1"": ""475088953585"",\n            ""ap-south-1"": ""991648021394"",\n            ""ca-central-1"": ""469771592824"",\n            ""eu-west-2"": ""644912444149"",\n            ""us-west-1"": ""632365934929"",\n            ""us-iso-east-1"": ""490574956308"",\n            ""ap-east-1"": ""286214385809"",\n            ""eu-north-1"": ""669576153137"",\n            ""eu-west-3"": ""749696950732"",\n            ""sa-east-1"": ""855470959533"",\n            ""me-south-1"": ""249704162688"",\n            ""cn-north-1"": ""390948362332"",\n            ""cn-northwest-1"": ""387376663083"",\n        }\n    elif algorithm in [""image-classification-neo"", ""xgboost-neo""]:\n        region_to_accounts = NEO_IMAGE_ACCOUNT\n    else:\n        raise ValueError(\n            ""Algorithm class:{} does not have mapping to account_id with images"".format(algorithm)\n        )\n\n    if region_name in region_to_accounts:\n        account_id = region_to_accounts[region_name]\n        return get_ecr_image_uri_prefix(account_id, region_name)\n\n    raise ValueError(\n        ""Algorithm ({algorithm}) is unsupported for region ({region_name})."".format(\n            algorithm=algorithm, region_name=region_name\n        )\n    )\n\n\ndef get_image_uri(region_name, repo_name, repo_version=1):\n    """"""Return algorithm image URI for the given AWS region, repository name, and\n    repository version\n\n    Args:\n        region_name:\n        repo_name:\n        repo_version:\n    """"""\n    logger.warning(\n        ""\'get_image_uri\' method will be deprecated in favor of \'ImageURIProvider\' class ""\n        ""in SageMaker Python SDK v2.""\n    )\n\n    repo_version = str(repo_version)\n\n    if repo_name == XGBOOST_NAME:\n\n        if repo_version in XGBOOST_1P_VERSIONS:\n            _warn_newer_xgboost_image()\n            return ""{}/{}:{}"".format(registry(region_name, repo_name), repo_name, repo_version)\n\n        if ""-"" not in repo_version:\n            xgboost_version_matches = [\n                version\n                for version in XGBOOST_SUPPORTED_VERSIONS\n                if repo_version == version.split(""-"")[0]\n            ]\n            if xgboost_version_matches:\n                # Assumes that XGBOOST_SUPPORTED_VERSION is sorted from oldest version to latest.\n                # When SageMaker version is not specified, we use the oldest one that matches\n                # XGBoost version for backward compatibility.\n                repo_version = xgboost_version_matches[0]\n\n        supported_framework_versions = [\n            version\n            for version in XGBOOST_SUPPORTED_VERSIONS\n            if repo_version in _generate_version_equivalents(version)\n        ]\n\n        if not supported_framework_versions:\n            raise ValueError(\n                ""SageMaker XGBoost version {} is not supported. Supported versions: {}"".format(\n                    repo_version, "", "".join(XGBOOST_SUPPORTED_VERSIONS)\n                )\n            )\n\n        if not _is_latest_xgboost_version(repo_version):\n            _warn_newer_xgboost_image()\n\n        return get_xgboost_image_uri(region_name, supported_framework_versions[-1])\n\n    repo = ""{}:{}"".format(repo_name, repo_version)\n    return ""{}/{}"".format(registry(region_name, repo_name), repo)\n\n\ndef _warn_newer_xgboost_image():\n    """"""Print a warning when there is a newer XGBoost image""""""\n    logging.warning(\n        ""There is a more up to date SageMaker XGBoost image. ""\n        ""To use the newer image, please set \'repo_version\'=""\n        ""\'%s\'. For example:\\n""\n        ""\\tget_image_uri(region, \'%s\', \'%s\')."",\n        XGBOOST_LATEST_VERSION,\n        XGBOOST_NAME,\n        XGBOOST_LATEST_VERSION,\n    )\n\n\ndef _is_latest_xgboost_version(repo_version):\n    """"""Compare xgboost image version with latest version\n\n    Args:\n        repo_version:\n    """"""\n    if repo_version in XGBOOST_1P_VERSIONS:\n        return False\n    return repo_version in _generate_version_equivalents(XGBOOST_LATEST_VERSION)\n\n\ndef _generate_version_equivalents(version):\n    """"""Returns a list of version equivalents for XGBoost\n\n    Args:\n        version:\n    """"""\n    return [version + suffix for suffix in XGBOOST_VERSION_EQUIVALENTS] + [version]\n'"
src/sagemaker/amazon/common.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nimport io\nimport struct\nimport sys\n\nimport numpy as np\nfrom scipy.sparse import issparse\n\nfrom sagemaker.amazon.record_pb2 import Record\n\n\nclass numpy_to_record_serializer(object):\n    """"""Placeholder docstring""""""\n\n    def __init__(self, content_type=""application/x-recordio-protobuf""):\n        """"""\n        Args:\n            content_type:\n        """"""\n        self.content_type = content_type\n\n    def __call__(self, array):\n        """"""\n        Args:\n            array:\n        """"""\n        if len(array.shape) == 1:\n            array = array.reshape(1, array.shape[0])\n        assert len(array.shape) == 2, ""Expecting a 1 or 2 dimensional array""\n        buf = io.BytesIO()\n        write_numpy_to_dense_tensor(buf, array)\n        buf.seek(0)\n        return buf\n\n\nclass record_deserializer(object):\n    """"""Placeholder docstring""""""\n\n    def __init__(self, accept=""application/x-recordio-protobuf""):\n        """"""\n        Args:\n            accept:\n        """"""\n        self.accept = accept\n\n    def __call__(self, stream, content_type):\n        """"""\n        Args:\n            stream:\n            content_type:\n        """"""\n        try:\n            return read_records(stream)\n        finally:\n            stream.close()\n\n\ndef _write_feature_tensor(resolved_type, record, vector):\n    """"""\n    Args:\n        resolved_type:\n        record:\n        vector:\n    """"""\n    if resolved_type == ""Int32"":\n        record.features[""values""].int32_tensor.values.extend(vector)\n    elif resolved_type == ""Float64"":\n        record.features[""values""].float64_tensor.values.extend(vector)\n    elif resolved_type == ""Float32"":\n        record.features[""values""].float32_tensor.values.extend(vector)\n\n\ndef _write_label_tensor(resolved_type, record, scalar):\n    """"""\n    Args:\n        resolved_type:\n        record:\n        scalar:\n    """"""\n    if resolved_type == ""Int32"":\n        record.label[""values""].int32_tensor.values.extend([scalar])\n    elif resolved_type == ""Float64"":\n        record.label[""values""].float64_tensor.values.extend([scalar])\n    elif resolved_type == ""Float32"":\n        record.label[""values""].float32_tensor.values.extend([scalar])\n\n\ndef _write_keys_tensor(resolved_type, record, vector):\n    """"""\n    Args:\n        resolved_type:\n        record:\n        vector:\n    """"""\n    if resolved_type == ""Int32"":\n        record.features[""values""].int32_tensor.keys.extend(vector)\n    elif resolved_type == ""Float64"":\n        record.features[""values""].float64_tensor.keys.extend(vector)\n    elif resolved_type == ""Float32"":\n        record.features[""values""].float32_tensor.keys.extend(vector)\n\n\ndef _write_shape(resolved_type, record, scalar):\n    """"""\n    Args:\n        resolved_type:\n        record:\n        scalar:\n    """"""\n    if resolved_type == ""Int32"":\n        record.features[""values""].int32_tensor.shape.extend([scalar])\n    elif resolved_type == ""Float64"":\n        record.features[""values""].float64_tensor.shape.extend([scalar])\n    elif resolved_type == ""Float32"":\n        record.features[""values""].float32_tensor.shape.extend([scalar])\n\n\ndef write_numpy_to_dense_tensor(file, array, labels=None):\n    """"""Writes a numpy array to a dense tensor\n\n    Args:\n        file:\n        array:\n        labels:\n    """"""\n\n    # Validate shape of array and labels, resolve array and label types\n    if not len(array.shape) == 2:\n        raise ValueError(""Array must be a Matrix"")\n    if labels is not None:\n        if not len(labels.shape) == 1:\n            raise ValueError(""Labels must be a Vector"")\n        if labels.shape[0] not in array.shape:\n            raise ValueError(\n                ""Label shape {} not compatible with array shape {}"".format(\n                    labels.shape, array.shape\n                )\n            )\n        resolved_label_type = _resolve_type(labels.dtype)\n    resolved_type = _resolve_type(array.dtype)\n\n    # Write each vector in array into a Record in the file object\n    record = Record()\n    for index, vector in enumerate(array):\n        record.Clear()\n        _write_feature_tensor(resolved_type, record, vector)\n        if labels is not None:\n            _write_label_tensor(resolved_label_type, record, labels[index])\n        _write_recordio(file, record.SerializeToString())\n\n\ndef write_spmatrix_to_sparse_tensor(file, array, labels=None):\n    """"""Writes a scipy sparse matrix to a sparse tensor\n\n    Args:\n        file:\n        array:\n        labels:\n    """"""\n\n    if not issparse(array):\n        raise TypeError(""Array must be sparse"")\n\n    # Validate shape of array and labels, resolve array and label types\n    if not len(array.shape) == 2:\n        raise ValueError(""Array must be a Matrix"")\n    if labels is not None:\n        if not len(labels.shape) == 1:\n            raise ValueError(""Labels must be a Vector"")\n        if labels.shape[0] not in array.shape:\n            raise ValueError(\n                ""Label shape {} not compatible with array shape {}"".format(\n                    labels.shape, array.shape\n                )\n            )\n        resolved_label_type = _resolve_type(labels.dtype)\n    resolved_type = _resolve_type(array.dtype)\n\n    csr_array = array.tocsr()\n    n_rows, n_cols = csr_array.shape\n\n    record = Record()\n    for row_idx in range(n_rows):\n        record.Clear()\n        row = csr_array.getrow(row_idx)\n        # Write values\n        _write_feature_tensor(resolved_type, record, row.data)\n        # Write keys\n        _write_keys_tensor(resolved_type, record, row.indices.astype(np.uint64))\n\n        # Write labels\n        if labels is not None:\n            _write_label_tensor(resolved_label_type, record, labels[row_idx])\n\n        # Write shape\n        _write_shape(resolved_type, record, n_cols)\n\n        _write_recordio(file, record.SerializeToString())\n\n\ndef read_records(file):\n    """"""Eagerly read a collection of amazon Record protobuf objects from file.\n\n    Args:\n        file:\n    """"""\n    records = []\n    for record_data in read_recordio(file):\n        record = Record()\n        record.ParseFromString(record_data)\n        records.append(record)\n    return records\n\n\n# MXNet requires recordio records have length in bytes that\'s a multiple of 4\n# This sets up padding bytes to append to the end of the record, for diferent\n# amounts of padding required.\npadding = {}\nfor amount in range(4):\n    if sys.version_info >= (3,):\n        padding[amount] = bytes([0x00 for _ in range(amount)])\n    else:\n        padding[amount] = bytearray([0x00 for _ in range(amount)])\n\n_kmagic = 0xCED7230A\n\n\ndef _write_recordio(f, data):\n    """"""Writes a single data point as a RecordIO record to the given file.\n\n    Args:\n        f:\n        data:\n    """"""\n    length = len(data)\n    f.write(struct.pack(""I"", _kmagic))\n    f.write(struct.pack(""I"", length))\n    pad = (((length + 3) >> 2) << 2) - length\n    f.write(data)\n    f.write(padding[pad])\n\n\ndef read_recordio(f):\n    """"""\n    Args:\n        f:\n    """"""\n    while True:\n        try:\n            read_kmagic, = struct.unpack(""I"", f.read(4))\n        except struct.error:\n            return\n        assert read_kmagic == _kmagic\n        len_record, = struct.unpack(""I"", f.read(4))\n        pad = (((len_record + 3) >> 2) << 2) - len_record\n        yield f.read(len_record)\n        if pad:\n            f.read(pad)\n\n\ndef _resolve_type(dtype):\n    """"""\n    Args:\n        dtype:\n    """"""\n    if dtype == np.dtype(int):\n        return ""Int32""\n    if dtype == np.dtype(float):\n        return ""Float64""\n    if dtype == np.dtype(""float32""):\n        return ""Float32""\n    raise ValueError(""Unsupported dtype {} on array"".format(dtype))\n'"
src/sagemaker/amazon/factorization_machines.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nfrom sagemaker.amazon.amazon_estimator import AmazonAlgorithmEstimatorBase, registry\nfrom sagemaker.amazon.common import numpy_to_record_serializer, record_deserializer\nfrom sagemaker.amazon.hyperparameter import Hyperparameter as hp  # noqa\nfrom sagemaker.amazon.validation import gt, isin, ge\nfrom sagemaker.predictor import RealTimePredictor\nfrom sagemaker.model import Model\nfrom sagemaker.session import Session\nfrom sagemaker.vpc_utils import VPC_CONFIG_DEFAULT\n\n\nclass FactorizationMachines(AmazonAlgorithmEstimatorBase):\n    """"""Placeholder docstring""""""\n\n    repo_name = ""factorization-machines""\n    repo_version = 1\n\n    num_factors = hp(""num_factors"", gt(0), ""An integer greater than zero"", int)\n    predictor_type = hp(\n        ""predictor_type"",\n        isin(""binary_classifier"", ""regressor""),\n        \'Value ""binary_classifier"" or ""regressor""\',\n        str,\n    )\n    epochs = hp(""epochs"", gt(0), ""An integer greater than 0"", int)\n    clip_gradient = hp(""clip_gradient"", (), ""A float value"", float)\n    eps = hp(""eps"", (), ""A float value"", float)\n    rescale_grad = hp(""rescale_grad"", (), ""A float value"", float)\n    bias_lr = hp(""bias_lr"", ge(0), ""A non-negative float"", float)\n    linear_lr = hp(""linear_lr"", ge(0), ""A non-negative float"", float)\n    factors_lr = hp(""factors_lr"", ge(0), ""A non-negative float"", float)\n    bias_wd = hp(""bias_wd"", ge(0), ""A non-negative float"", float)\n    linear_wd = hp(""linear_wd"", ge(0), ""A non-negative float"", float)\n    factors_wd = hp(""factors_wd"", ge(0), ""A non-negative float"", float)\n    bias_init_method = hp(\n        ""bias_init_method"",\n        isin(""normal"", ""uniform"", ""constant""),\n        \'Value ""normal"", ""uniform"" or ""constant""\',\n        str,\n    )\n    bias_init_scale = hp(""bias_init_scale"", ge(0), ""A non-negative float"", float)\n    bias_init_sigma = hp(""bias_init_sigma"", ge(0), ""A non-negative float"", float)\n    bias_init_value = hp(""bias_init_value"", (), ""A float value"", float)\n    linear_init_method = hp(\n        ""linear_init_method"",\n        isin(""normal"", ""uniform"", ""constant""),\n        \'Value ""normal"", ""uniform"" or ""constant""\',\n        str,\n    )\n    linear_init_scale = hp(""linear_init_scale"", ge(0), ""A non-negative float"", float)\n    linear_init_sigma = hp(""linear_init_sigma"", ge(0), ""A non-negative float"", float)\n    linear_init_value = hp(""linear_init_value"", (), ""A float value"", float)\n    factors_init_method = hp(\n        ""factors_init_method"",\n        isin(""normal"", ""uniform"", ""constant""),\n        \'Value ""normal"", ""uniform"" or ""constant""\',\n        str,\n    )\n    factors_init_scale = hp(""factors_init_scale"", ge(0), ""A non-negative float"", float)\n    factors_init_sigma = hp(""factors_init_sigma"", ge(0), ""A non-negative float"", float)\n    factors_init_value = hp(""factors_init_value"", (), ""A float value"", float)\n\n    def __init__(\n        self,\n        role,\n        train_instance_count,\n        train_instance_type,\n        num_factors,\n        predictor_type,\n        epochs=None,\n        clip_gradient=None,\n        eps=None,\n        rescale_grad=None,\n        bias_lr=None,\n        linear_lr=None,\n        factors_lr=None,\n        bias_wd=None,\n        linear_wd=None,\n        factors_wd=None,\n        bias_init_method=None,\n        bias_init_scale=None,\n        bias_init_sigma=None,\n        bias_init_value=None,\n        linear_init_method=None,\n        linear_init_scale=None,\n        linear_init_sigma=None,\n        linear_init_value=None,\n        factors_init_method=None,\n        factors_init_scale=None,\n        factors_init_sigma=None,\n        factors_init_value=None,\n        **kwargs\n    ):\n        """"""Factorization Machines is :class:`Estimator` for general-purpose\n        supervised learning.\n\n        Amazon SageMaker Factorization Machines is a general-purpose\n        supervised learning algorithm that you can use for both classification\n        and regression tasks. It is an extension of a linear model that is\n        designed to parsimoniously capture interactions between features within\n        high dimensional sparse datasets.\n\n        This Estimator may be fit via calls to\n        :meth:`~sagemaker.amazon.amazon_estimator.AmazonAlgorithmEstimatorBase.fit`.\n        It requires Amazon :class:`~sagemaker.amazon.record_pb2.Record` protobuf\n        serialized data to be stored in S3. There is an utility\n        :meth:`~sagemaker.amazon.amazon_estimator.AmazonAlgorithmEstimatorBase.record_set`\n        that can be used to upload data to S3 and creates\n        :class:`~sagemaker.amazon.amazon_estimator.RecordSet` to be passed to\n        the `fit` call.\n\n        To learn more about the Amazon protobuf Record class and how to\n        prepare bulk data in this format, please consult AWS technical\n        documentation:\n        https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-training.html\n\n        After this Estimator is fit, model data is stored in S3. The model\n        may be deployed to an Amazon SageMaker Endpoint by invoking\n        :meth:`~sagemaker.amazon.estimator.EstimatorBase.deploy`. As well as\n        deploying an Endpoint, deploy returns a\n        :class:`~sagemaker.amazon.pca.FactorizationMachinesPredictor` object\n        that can be used for inference calls using the trained model hosted in\n        the SageMaker Endpoint.\n\n        FactorizationMachines Estimators can be configured by setting\n        hyperparameters. The available hyperparameters for FactorizationMachines\n        are documented below.\n\n        For further information on the AWS FactorizationMachines algorithm,\n        please consult AWS technical documentation:\n        https://docs.aws.amazon.com/sagemaker/latest/dg/fact-machines.html\n\n        Args:\n            role (str): An AWS IAM role (either name or full ARN). The Amazon\n                SageMaker training jobs and APIs that create Amazon SageMaker\n                endpoints use this role to access training data and model\n                artifacts. After the endpoint is created, the inference code\n                might use the IAM role, if accessing AWS resource.\n            train_instance_count (int): Number of Amazon EC2 instances to use\n                for training.\n            train_instance_type (str): Type of EC2 instance to use for training,\n                for example, \'ml.c4.xlarge\'.\n            num_factors (int): Dimensionality of factorization.\n            predictor_type (str): Type of predictor \'binary_classifier\' or\n                \'regressor\'.\n            epochs (int): Number of training epochs to run.\n            clip_gradient (float): Optimizer parameter. Clip the gradient by\n                projecting onto the box [-clip_gradient, +clip_gradient]\n            eps (float): Optimizer parameter. Small value to avoid division by\n                0.\n            rescale_grad (float): Optimizer parameter. If set, multiplies the\n                gradient with rescale_grad before updating. Often choose to be\n                1.0/batch_size.\n            bias_lr (float): Non-negative learning rate for the bias term.\n            linear_lr (float): Non-negative learning rate for linear terms.\n            factors_lr (float): Noon-negative learning rate for factorization\n                terms.\n            bias_wd (float): Non-negative weight decay for the bias term.\n            linear_wd (float): Non-negative weight decay for linear terms.\n            factors_wd (float): Non-negative weight decay for factorization\n                terms.\n            bias_init_method (string): Initialization method for the bias term:\n                \'normal\', \'uniform\' or \'constant\'.\n            bias_init_scale (float): Non-negative range for initialization of\n                the bias term that takes effect when bias_init_method parameter\n                is \'uniform\'\n            bias_init_sigma (float): Non-negative standard deviation for\n                initialization of the bias term that takes effect when\n                bias_init_method parameter is \'normal\'.\n            bias_init_value (float): Initial value of the bias term that takes\n                effect when bias_init_method parameter is \'constant\'.\n            linear_init_method (string): Initialization method for linear term:\n                \'normal\', \'uniform\' or \'constant\'.\n            linear_init_scale (float): Non-negative range for initialization of\n                linear terms that takes effect when linear_init_method parameter\n                is \'uniform\'.\n            linear_init_sigma (float): Non-negative standard deviation for\n                initialization of linear terms that takes effect when\n                linear_init_method parameter is \'normal\'.\n            linear_init_value (float): Initial value of linear terms that takes\n                effect when linear_init_method parameter is \'constant\'.\n            factors_init_method (string): Initialization method for\n                factorization term: \'normal\', \'uniform\' or \'constant\'.\n            factors_init_scale (float): Non-negative range for initialization of\n                factorization terms that takes effect when factors_init_method\n                parameter is \'uniform\'.\n            factors_init_sigma (float): Non-negative standard deviation for\n                initialization of factorization terms that takes effect when\n                factors_init_method parameter is \'normal\'.\n            factors_init_value (float): Initial value of factorization terms\n                that takes effect when factors_init_method parameter is\n                \'constant\'.\n            **kwargs: base class keyword argument values.\n\n        .. tip::\n\n            You can find additional parameters for initializing this class at\n            :class:`~sagemaker.estimator.amazon_estimator.AmazonAlgorithmEstimatorBase` and\n            :class:`~sagemaker.estimator.EstimatorBase`.\n        """"""\n        super(FactorizationMachines, self).__init__(\n            role, train_instance_count, train_instance_type, **kwargs\n        )\n\n        self.num_factors = num_factors\n        self.predictor_type = predictor_type\n        self.epochs = epochs\n        self.clip_gradient = clip_gradient\n        self.eps = eps\n        self.rescale_grad = rescale_grad\n        self.bias_lr = bias_lr\n        self.linear_lr = linear_lr\n        self.factors_lr = factors_lr\n        self.bias_wd = bias_wd\n        self.linear_wd = linear_wd\n        self.factors_wd = factors_wd\n        self.bias_init_method = bias_init_method\n        self.bias_init_scale = bias_init_scale\n        self.bias_init_sigma = bias_init_sigma\n        self.bias_init_value = bias_init_value\n        self.linear_init_method = linear_init_method\n        self.linear_init_scale = linear_init_scale\n        self.linear_init_sigma = linear_init_sigma\n        self.linear_init_value = linear_init_value\n        self.factors_init_method = factors_init_method\n        self.factors_init_scale = factors_init_scale\n        self.factors_init_sigma = factors_init_sigma\n        self.factors_init_value = factors_init_value\n\n    def create_model(self, vpc_config_override=VPC_CONFIG_DEFAULT, **kwargs):\n        """"""Return a :class:`~sagemaker.amazon.FactorizationMachinesModel`\n        referencing the latest s3 model data produced by this Estimator.\n\n        Args:\n            vpc_config_override (dict[str, list[str]]): Optional override for VpcConfig set on\n                the model. Default: use subnets and security groups from this Estimator.\n                * \'Subnets\' (list[str]): List of subnet ids.\n                * \'SecurityGroupIds\' (list[str]): List of security group ids.\n            **kwargs: Additional kwargs passed to the FactorizationMachinesModel constructor.\n        """"""\n        return FactorizationMachinesModel(\n            self.model_data,\n            self.role,\n            sagemaker_session=self.sagemaker_session,\n            vpc_config=self.get_vpc_config(vpc_config_override),\n            **kwargs\n        )\n\n\nclass FactorizationMachinesPredictor(RealTimePredictor):\n    """"""Performs binary-classification or regression prediction from input\n    vectors.\n\n    The implementation of\n    :meth:`~sagemaker.predictor.RealTimePredictor.predict` in this\n    `RealTimePredictor` requires a numpy ``ndarray`` as input. The array should\n    contain the same number of columns as the feature-dimension of the data used\n    to fit the model this Predictor performs inference on.\n\n    :meth:`predict()` returns a list of\n    :class:`~sagemaker.amazon.record_pb2.Record` objects, one for each row in\n    the input ``ndarray``. The prediction is stored in the ``""score""`` key of\n    the ``Record.label`` field. Please refer to the formats details described:\n    https://docs.aws.amazon.com/sagemaker/latest/dg/fm-in-formats.html\n    """"""\n\n    def __init__(self, endpoint, sagemaker_session=None):\n        """"""\n        Args:\n            endpoint:\n            sagemaker_session:\n        """"""\n        super(FactorizationMachinesPredictor, self).__init__(\n            endpoint,\n            sagemaker_session,\n            serializer=numpy_to_record_serializer(),\n            deserializer=record_deserializer(),\n        )\n\n\nclass FactorizationMachinesModel(Model):\n    """"""Reference S3 model data created by FactorizationMachines estimator.\n    Calling :meth:`~sagemaker.model.Model.deploy` creates an Endpoint and\n    returns :class:`FactorizationMachinesPredictor`.\n    """"""\n\n    def __init__(self, model_data, role, sagemaker_session=None, **kwargs):\n        """"""\n        Args:\n            model_data:\n            role:\n            sagemaker_session:\n            **kwargs:\n        """"""\n        sagemaker_session = sagemaker_session or Session()\n        repo = ""{}:{}"".format(FactorizationMachines.repo_name, FactorizationMachines.repo_version)\n        image = ""{}/{}"".format(registry(sagemaker_session.boto_session.region_name), repo)\n        super(FactorizationMachinesModel, self).__init__(\n            model_data,\n            image,\n            role,\n            predictor_cls=FactorizationMachinesPredictor,\n            sagemaker_session=sagemaker_session,\n            **kwargs\n        )\n'"
src/sagemaker/amazon/hyperparameter.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nimport json\n\n\nclass Hyperparameter(object):\n    """"""An algorithm hyperparameter with optional validation. Implemented as a\n    python descriptor object.\n    """"""\n\n    def __init__(self, name, validate=lambda _: True, validation_message="""", data_type=str):\n        """"""Args: name (str): The name of this hyperparameter validate\n        (callable[object]->[bool]): A validation function or list of validation\n        functions.\n\n            Each function validates an object and returns False if the object\n            value is invalid for this hyperparameter.\n\n        validation_message (str): A usage guide to display on validation\n        failure.\n\n        Args:\n            name:\n            validate:\n            validation_message:\n            data_type:\n        """"""\n        self.validation = validate\n        self.validation_message = validation_message\n        self.name = name\n        self.data_type = data_type\n        try:\n            iter(self.validation)\n        except TypeError:\n            self.validation = [self.validation]\n\n    def validate(self, value):\n        """"""\n        Args:\n            value:\n        """"""\n        if value is None:  # We allow assignment from None, but Nones are not sent to training.\n            return\n\n        for valid in self.validation:\n            if not valid(value):\n                error_message = ""Invalid hyperparameter value {} for {}"".format(value, self.name)\n                if self.validation_message:\n                    error_message = error_message + "". Expecting: "" + self.validation_message\n                raise ValueError(error_message)\n\n    def __get__(self, obj, objtype):\n        """"""\n        Args:\n            obj:\n            objtype:\n        """"""\n        if ""_hyperparameters"" not in dir(obj) or self.name not in obj._hyperparameters:\n            raise AttributeError()\n        return obj._hyperparameters[self.name]\n\n    def __set__(self, obj, value):\n        """"""Validate the supplied value and set this hyperparameter to value\n\n        Args:\n            obj:\n            value:\n        """"""\n        value = None if value is None else self.data_type(value)\n        self.validate(value)\n        if ""_hyperparameters"" not in dir(obj):\n            obj._hyperparameters = dict()\n        obj._hyperparameters[self.name] = value\n\n    def __delete__(self, obj):\n        """"""Delete this hyperparameter\n\n        Args:\n            obj:\n        """"""\n        del obj._hyperparameters[self.name]\n\n    @staticmethod\n    def serialize_all(obj):\n        """"""Return all non-None ``hyperparameter`` values on ``obj`` as a\n        ``dict[str,str].``\n\n        Args:\n            obj:\n        """"""\n        if ""_hyperparameters"" not in dir(obj):\n            return {}\n        return {\n            k: json.dumps(v) if isinstance(v, list) else str(v)\n            for k, v in obj._hyperparameters.items()\n            if v is not None\n        }\n'"
src/sagemaker/amazon/ipinsights.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nfrom sagemaker.amazon.amazon_estimator import AmazonAlgorithmEstimatorBase, registry\nfrom sagemaker.amazon.hyperparameter import Hyperparameter as hp  # noqa\nfrom sagemaker.amazon.validation import ge, le\nfrom sagemaker.predictor import RealTimePredictor, csv_serializer, json_deserializer\nfrom sagemaker.model import Model\nfrom sagemaker.session import Session\nfrom sagemaker.vpc_utils import VPC_CONFIG_DEFAULT\n\n\nclass IPInsights(AmazonAlgorithmEstimatorBase):\n    """"""Placeholder docstring""""""\n\n    repo_name = ""ipinsights""\n    repo_version = 1\n    MINI_BATCH_SIZE = 10000\n\n    num_entity_vectors = hp(\n        ""num_entity_vectors"", (ge(1), le(250000000)), ""An integer in [1, 250000000]"", int\n    )\n    vector_dim = hp(""vector_dim"", (ge(4), le(4096)), ""An integer in [4, 4096]"", int)\n\n    batch_metrics_publish_interval = hp(\n        ""batch_metrics_publish_interval"", (ge(1)), ""An integer greater than 0"", int\n    )\n    epochs = hp(""epochs"", (ge(1)), ""An integer greater than 0"", int)\n    learning_rate = hp(""learning_rate"", (ge(1e-6), le(10.0)), ""A float in [1e-6, 10.0]"", float)\n    num_ip_encoder_layers = hp(\n        ""num_ip_encoder_layers"", (ge(0), le(100)), ""An integer in [0, 100]"", int\n    )\n    random_negative_sampling_rate = hp(\n        ""random_negative_sampling_rate"", (ge(0), le(500)), ""An integer in [0, 500]"", int\n    )\n    shuffled_negative_sampling_rate = hp(\n        ""shuffled_negative_sampling_rate"", (ge(0), le(500)), ""An integer in [0, 500]"", int\n    )\n    weight_decay = hp(""weight_decay"", (ge(0.0), le(10.0)), ""A float in [0.0, 10.0]"", float)\n\n    def __init__(\n        self,\n        role,\n        train_instance_count,\n        train_instance_type,\n        num_entity_vectors,\n        vector_dim,\n        batch_metrics_publish_interval=None,\n        epochs=None,\n        learning_rate=None,\n        num_ip_encoder_layers=None,\n        random_negative_sampling_rate=None,\n        shuffled_negative_sampling_rate=None,\n        weight_decay=None,\n        **kwargs\n    ):\n        """"""This estimator is for IP Insights, an unsupervised algorithm that\n        learns usage patterns of IP addresses.\n\n        This Estimator may be fit via calls to\n        :meth:`~sagemaker.amazon.amazon_estimator.AmazonAlgorithmEstimatorBase.fit`.\n        It requires CSV data to be stored in S3.\n\n        After this Estimator is fit, model data is stored in S3. The model\n        may be deployed to an Amazon SageMaker Endpoint by invoking\n        :meth:`~sagemaker.amazon.estimator.EstimatorBase.deploy`. As well as\n        deploying an Endpoint, deploy returns a\n        :class:`~sagemaker.amazon.IPInsightPredictor` object that can be used\n        for inference calls using the trained model hosted in the SageMaker\n        Endpoint.\n\n        IPInsights Estimators can be configured by setting hyperparamters.\n        The available hyperparamters are documented below.\n\n        For further information on the AWS IPInsights algorithm, please\n        consult AWS technical documentation:\n        https://docs.aws.amazon.com/sagemaker/latest/dg/ip-insights-hyperparameters.html\n\n        Args:\n            role (str): An AWS IAM role (either name or full ARN). The Amazon\n                SageMaker training jobs and APIs that create Amazon SageMaker\n                endpoints use this role to access training data and model\n                artifacts. After the endpoint is created, the inference code\n                might use the IAM role, if accessing AWS resource.\n            train_instance_count (int): Number of Amazon EC2 instances to use\n                for training.\n            train_instance_type (str): Type of EC2 instance to use for training,\n                for example, \'ml.m5.xlarge\'.\n            num_entity_vectors (int): Required. The number of embeddings to\n                train for entities accessing online resources. We recommend 2x\n                the total number of unique entity IDs.\n            vector_dim (int): Required. The size of the embedding vectors for\n                both entity and IP addresses.\n            batch_metrics_publish_interval (int): Optional. The period at which\n                to publish metrics (batches).\n            epochs (int): Optional. Maximum number of passes over the training\n                data.\n            learning_rate (float): Optional. Learning rate for the optimizer.\n            num_ip_encoder_layers (int): Optional. The number of fully-connected\n                layers to encode IP address embedding.\n            random_negative_sampling_rate (int): Optional. The ratio of random\n                negative samples to draw during training. Random negative\n                samples are randomly drawn IPv4 addresses.\n            shuffled_negative_sampling_rate (int): Optional. The ratio of\n                shuffled negative samples to draw during training. Shuffled\n                negative samples are IP addresses picked from within a batch.\n            weight_decay (float): Optional. Weight decay coefficient. Adds L2\n                regularization.\n            **kwargs: base class keyword argument values.\n\n        .. tip::\n\n            You can find additional parameters for initializing this class at\n            :class:`~sagemaker.estimator.amazon_estimator.AmazonAlgorithmEstimatorBase` and\n            :class:`~sagemaker.estimator.EstimatorBase`.\n        """"""\n        super(IPInsights, self).__init__(role, train_instance_count, train_instance_type, **kwargs)\n        self.num_entity_vectors = num_entity_vectors\n        self.vector_dim = vector_dim\n        self.batch_metrics_publish_interval = batch_metrics_publish_interval\n        self.epochs = epochs\n        self.learning_rate = learning_rate\n        self.num_ip_encoder_layers = num_ip_encoder_layers\n        self.random_negative_sampling_rate = random_negative_sampling_rate\n        self.shuffled_negative_sampling_rate = shuffled_negative_sampling_rate\n        self.weight_decay = weight_decay\n\n    def create_model(self, vpc_config_override=VPC_CONFIG_DEFAULT, **kwargs):\n        """"""Create a model for the latest s3 model produced by this estimator.\n\n        Args:\n            vpc_config_override (dict[str, list[str]]): Optional override for VpcConfig set on\n                the model.\n                Default: use subnets and security groups from this Estimator.\n                * \'Subnets\' (list[str]): List of subnet ids.\n                * \'SecurityGroupIds\' (list[str]): List of security group ids.\n            **kwargs: Additional kwargs passed to the IPInsightsModel constructor.\n        Returns:\n            :class:`~sagemaker.amazon.IPInsightsModel`: references the latest s3 model\n            data produced by this estimator.\n        """"""\n        return IPInsightsModel(\n            self.model_data,\n            self.role,\n            sagemaker_session=self.sagemaker_session,\n            vpc_config=self.get_vpc_config(vpc_config_override),\n            **kwargs\n        )\n\n    def _prepare_for_training(self, records, mini_batch_size=None, job_name=None):\n        """"""\n        Args:\n            records:\n            mini_batch_size:\n            job_name:\n        """"""\n        if mini_batch_size is not None and (mini_batch_size < 1 or mini_batch_size > 500000):\n            raise ValueError(""mini_batch_size must be in [1, 500000]"")\n        super(IPInsights, self)._prepare_for_training(\n            records, mini_batch_size=mini_batch_size, job_name=job_name\n        )\n\n\nclass IPInsightsPredictor(RealTimePredictor):\n    """"""Returns dot product of entity and IP address embeddings as a score for\n    compatibility.\n\n    The implementation of\n    :meth:`~sagemaker.predictor.RealTimePredictor.predict` in this\n    `RealTimePredictor` requires a numpy ``ndarray`` as input. The array should\n    contain two columns. The first column should contain the entity ID. The\n    second column should contain the IPv4 address in dot notation.\n    """"""\n\n    def __init__(self, endpoint, sagemaker_session=None):\n        """"""\n        Args:\n            endpoint:\n            sagemaker_session:\n        """"""\n        super(IPInsightsPredictor, self).__init__(\n            endpoint, sagemaker_session, serializer=csv_serializer, deserializer=json_deserializer\n        )\n\n\nclass IPInsightsModel(Model):\n    """"""Reference IPInsights s3 model data. Calling\n    :meth:`~sagemaker.model.Model.deploy` creates an Endpoint and returns a\n    Predictor that calculates anomaly scores for data points.\n    """"""\n\n    def __init__(self, model_data, role, sagemaker_session=None, **kwargs):\n        """"""\n        Args:\n            model_data:\n            role:\n            sagemaker_session:\n            **kwargs:\n        """"""\n        sagemaker_session = sagemaker_session or Session()\n        repo = ""{}:{}"".format(IPInsights.repo_name, IPInsights.repo_version)\n        image = ""{}/{}"".format(\n            registry(sagemaker_session.boto_session.region_name, IPInsights.repo_name), repo\n        )\n\n        super(IPInsightsModel, self).__init__(\n            model_data,\n            image,\n            role,\n            predictor_cls=IPInsightsPredictor,\n            sagemaker_session=sagemaker_session,\n            **kwargs\n        )\n'"
src/sagemaker/amazon/kmeans.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nfrom sagemaker.amazon.amazon_estimator import AmazonAlgorithmEstimatorBase, registry\nfrom sagemaker.amazon.common import numpy_to_record_serializer, record_deserializer\nfrom sagemaker.amazon.hyperparameter import Hyperparameter as hp  # noqa\nfrom sagemaker.amazon.validation import gt, isin, ge, le\nfrom sagemaker.predictor import RealTimePredictor\nfrom sagemaker.model import Model\nfrom sagemaker.session import Session\nfrom sagemaker.vpc_utils import VPC_CONFIG_DEFAULT\n\n\nclass KMeans(AmazonAlgorithmEstimatorBase):\n    """"""Placeholder docstring""""""\n\n    repo_name = ""kmeans""\n    repo_version = 1\n\n    k = hp(""k"", gt(1), ""An integer greater-than 1"", int)\n    init_method = hp(""init_method"", isin(""random"", ""kmeans++""), \'One of ""random"", ""kmeans++""\', str)\n    max_iterations = hp(""local_lloyd_max_iter"", gt(0), ""An integer greater-than 0"", int)\n    tol = hp(""local_lloyd_tol"", (ge(0), le(1)), ""An float in [0, 1]"", float)\n    num_trials = hp(""local_lloyd_num_trials"", gt(0), ""An integer greater-than 0"", int)\n    local_init_method = hp(\n        ""local_lloyd_init_method"", isin(""random"", ""kmeans++""), \'One of ""random"", ""kmeans++""\', str\n    )\n    half_life_time_size = hp(\n        ""half_life_time_size"", ge(0), ""An integer greater-than-or-equal-to 0"", int\n    )\n    epochs = hp(""epochs"", gt(0), ""An integer greater-than 0"", int)\n    center_factor = hp(""extra_center_factor"", gt(0), ""An integer greater-than 0"", int)\n    eval_metrics = hp(\n        name=""eval_metrics"",\n        validation_message=\'A comma separated list of ""msd"" or ""ssd""\',\n        data_type=list,\n    )\n\n    def __init__(\n        self,\n        role,\n        train_instance_count,\n        train_instance_type,\n        k,\n        init_method=None,\n        max_iterations=None,\n        tol=None,\n        num_trials=None,\n        local_init_method=None,\n        half_life_time_size=None,\n        epochs=None,\n        center_factor=None,\n        eval_metrics=None,\n        **kwargs\n    ):\n        """"""A k-means clustering\n        :class:`~sagemaker.amazon.AmazonAlgorithmEstimatorBase`. Finds k\n        clusters of data in an unlabeled dataset.\n\n        This Estimator may be fit via calls to\n        :meth:`~sagemaker.amazon.amazon_estimator.AmazonAlgorithmEstimatorBase.fit_ndarray`\n        or\n        :meth:`~sagemaker.amazon.amazon_estimator.AmazonAlgorithmEstimatorBase.fit`.\n        The former allows a KMeans model to be fit on a 2-dimensional numpy\n        array. The latter requires Amazon\n        :class:`~sagemaker.amazon.record_pb2.Record` protobuf serialized data to\n        be stored in S3.\n\n        To learn more about the Amazon protobuf Record class and how to\n        prepare bulk data in this format, please consult AWS technical\n        documentation:\n        https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-training.html.\n\n        After this Estimator is fit, model data is stored in S3. The model\n        may be deployed to an Amazon SageMaker Endpoint by invoking\n        :meth:`~sagemaker.amazon.estimator.EstimatorBase.deploy`. As well as\n        deploying an Endpoint, ``deploy`` returns a\n        :class:`~sagemaker.amazon.kmeans.KMeansPredictor` object that can be\n        used to k-means cluster assignments, using the trained k-means model\n        hosted in the SageMaker Endpoint.\n\n        KMeans Estimators can be configured by setting hyperparameters. The\n        available hyperparameters for KMeans are documented below. For further\n        information on the AWS KMeans algorithm, please consult AWS technical\n        documentation:\n        https://docs.aws.amazon.com/sagemaker/latest/dg/k-means.html.\n\n        Args:\n            role (str): An AWS IAM role (either name or full ARN). The Amazon\n                SageMaker training jobs and APIs that create Amazon SageMaker\n                endpoints use this role to access training data and model\n                artifacts. After the endpoint is created, the inference code\n                might use the IAM role, if accessing AWS resource.\n            train_instance_count (int): Number of Amazon EC2 instances to use\n                for training.\n            train_instance_type (str): Type of EC2 instance to use for training,\n                for example, \'ml.c4.xlarge\'.\n            k (int): The number of clusters to produce.\n            init_method (str): How to initialize cluster locations. One of\n                \'random\' or \'kmeans++\'.\n            max_iterations (int): Maximum iterations for Lloyds EM procedure in\n                the local kmeans used in finalize stage.\n            tol (float): Tolerance for change in ssd for early stopping in local\n                kmeans.\n            num_trials (int): Local version is run multiple times and the one\n                with the best loss is chosen. This determines how many times.\n            local_init_method (str): Initialization method for local version.\n                One of \'random\', \'kmeans++\'\n            half_life_time_size (int): The points can have a decayed weight.\n                When a point is observed its weight, with regard to the\n                computation of the cluster mean is 1. This weight will decay\n                exponentially as we observe more points. The exponent\n                coefficient is chosen such that after observing\n                ``half_life_time_size`` points after the mentioned point, its\n                weight will become 1/2. If set to 0, there will be no decay.\n            epochs (int): Number of passes done over the training data.\n            center_factor (int): The algorithm will create\n                ``num_clusters * extra_center_factor`` as it runs and reduce the\n                number of centers to ``k`` when finalizing\n            eval_metrics (list): JSON list of metrics types to be used for\n                reporting the score for the model. Allowed values are ""msd""\n                Means Square Error, ""ssd"": Sum of square distance. If test data\n                is provided, the score shall be reported in terms of all\n                requested metrics.\n            **kwargs: base class keyword argument values.\n\n        .. tip::\n\n            You can find additional parameters for initializing this class at\n            :class:`~sagemaker.estimator.amazon_estimator.AmazonAlgorithmEstimatorBase` and\n            :class:`~sagemaker.estimator.EstimatorBase`.\n        """"""\n        super(KMeans, self).__init__(role, train_instance_count, train_instance_type, **kwargs)\n        self.k = k\n        self.init_method = init_method\n        self.max_iterations = max_iterations\n        self.tol = tol\n        self.num_trials = num_trials\n        self.local_init_method = local_init_method\n        self.half_life_time_size = half_life_time_size\n        self.epochs = epochs\n        self.center_factor = center_factor\n        self.eval_metrics = eval_metrics\n\n    def create_model(self, vpc_config_override=VPC_CONFIG_DEFAULT, **kwargs):\n        """"""Return a :class:`~sagemaker.amazon.kmeans.KMeansModel` referencing\n        the latest s3 model data produced by this Estimator.\n\n        Args:\n            vpc_config_override (dict[str, list[str]]): Optional override for\n                VpcConfig set on the model.\n                Default: use subnets and security groups from this Estimator.\n                * \'Subnets\' (list[str]): List of subnet ids.\n                * \'SecurityGroupIds\' (list[str]): List of security group ids.\n            **kwargs: Additional kwargs passed to the KMeansModel constructor.\n        """"""\n        return KMeansModel(\n            self.model_data,\n            self.role,\n            self.sagemaker_session,\n            vpc_config=self.get_vpc_config(vpc_config_override),\n            **kwargs\n        )\n\n    def _prepare_for_training(self, records, mini_batch_size=5000, job_name=None):\n        """"""\n        Args:\n            records:\n            mini_batch_size:\n            job_name:\n        """"""\n        super(KMeans, self)._prepare_for_training(\n            records, mini_batch_size=mini_batch_size, job_name=job_name\n        )\n\n    def hyperparameters(self):\n        """"""Return the SageMaker hyperparameters for training this KMeans\n        Estimator\n        """"""\n        hp_dict = dict(force_dense=""True"")  # KMeans requires this hp to fit on Record objects\n        hp_dict.update(super(KMeans, self).hyperparameters())\n        return hp_dict\n\n\nclass KMeansPredictor(RealTimePredictor):\n    """"""Assigns input vectors to their closest cluster in a KMeans model.\n\n    The implementation of\n    :meth:`~sagemaker.predictor.RealTimePredictor.predict` in this\n    `RealTimePredictor` requires a numpy ``ndarray`` as input. The array should\n    contain the same number of columns as the feature-dimension of the data used\n    to fit the model this Predictor performs inference on.\n\n    ``predict()`` returns a list of\n    :class:`~sagemaker.amazon.record_pb2.Record` objects, one for each row in\n    the input ``ndarray``. The nearest cluster is stored in the\n    ``closest_cluster`` key of the ``Record.label`` field.\n    """"""\n\n    def __init__(self, endpoint, sagemaker_session=None):\n        """"""\n        Args:\n            endpoint:\n            sagemaker_session:\n        """"""\n        super(KMeansPredictor, self).__init__(\n            endpoint,\n            sagemaker_session,\n            serializer=numpy_to_record_serializer(),\n            deserializer=record_deserializer(),\n        )\n\n\nclass KMeansModel(Model):\n    """"""Reference KMeans s3 model data. Calling\n    :meth:`~sagemaker.model.Model.deploy` creates an Endpoint and return a\n    Predictor to performs k-means cluster assignment.\n    """"""\n\n    def __init__(self, model_data, role, sagemaker_session=None, **kwargs):\n        """"""\n        Args:\n            model_data:\n            role:\n            sagemaker_session:\n            **kwargs:\n        """"""\n        sagemaker_session = sagemaker_session or Session()\n        repo = ""{}:{}"".format(KMeans.repo_name, KMeans.repo_version)\n        image = ""{}/{}"".format(registry(sagemaker_session.boto_session.region_name), repo)\n        super(KMeansModel, self).__init__(\n            model_data,\n            image,\n            role,\n            predictor_cls=KMeansPredictor,\n            sagemaker_session=sagemaker_session,\n            **kwargs\n        )\n'"
src/sagemaker/amazon/knn.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nfrom sagemaker.amazon.amazon_estimator import AmazonAlgorithmEstimatorBase, registry\nfrom sagemaker.amazon.common import numpy_to_record_serializer, record_deserializer\nfrom sagemaker.amazon.hyperparameter import Hyperparameter as hp  # noqa\nfrom sagemaker.amazon.validation import ge, isin\nfrom sagemaker.predictor import RealTimePredictor\nfrom sagemaker.model import Model\nfrom sagemaker.session import Session\nfrom sagemaker.vpc_utils import VPC_CONFIG_DEFAULT\n\n\nclass KNN(AmazonAlgorithmEstimatorBase):\n    """"""Placeholder docstring""""""\n\n    repo_name = ""knn""\n    repo_version = 1\n\n    k = hp(""k"", (ge(1)), ""An integer greater than 0"", int)\n    sample_size = hp(""sample_size"", (ge(1)), ""An integer greater than 0"", int)\n    predictor_type = hp(\n        ""predictor_type"", isin(""classifier"", ""regressor""), \'One of ""classifier"" or ""regressor""\', str\n    )\n    dimension_reduction_target = hp(\n        ""dimension_reduction_target"",\n        (ge(1)),\n        ""An integer greater than 0 and less than feature_dim"",\n        int,\n    )\n    dimension_reduction_type = hp(\n        ""dimension_reduction_type"", isin(""sign"", ""fjlt""), \'One of ""sign"" or ""fjlt""\', str\n    )\n    index_metric = hp(\n        ""index_metric"",\n        isin(""COSINE"", ""INNER_PRODUCT"", ""L2""),\n        \'One of ""COSINE"", ""INNER_PRODUCT"", ""L2""\',\n        str,\n    )\n    index_type = hp(\n        ""index_type"",\n        isin(""faiss.Flat"", ""faiss.IVFFlat"", ""faiss.IVFPQ""),\n        \'One of ""faiss.Flat"", ""faiss.IVFFlat"", ""faiss.IVFPQ""\',\n        str,\n    )\n    faiss_index_ivf_nlists = hp(\n        ""faiss_index_ivf_nlists"", (), \'""auto"" or an integer greater than 0\', str\n    )\n    faiss_index_pq_m = hp(""faiss_index_pq_m"", (ge(1)), ""An integer greater than 0"", int)\n\n    def __init__(\n        self,\n        role,\n        train_instance_count,\n        train_instance_type,\n        k,\n        sample_size,\n        predictor_type,\n        dimension_reduction_type=None,\n        dimension_reduction_target=None,\n        index_type=None,\n        index_metric=None,\n        faiss_index_ivf_nlists=None,\n        faiss_index_pq_m=None,\n        **kwargs\n    ):\n        """"""k-nearest neighbors (KNN) is :class:`Estimator` used for\n        classification and regression. This Estimator may be fit via calls to\n        :meth:`~sagemaker.amazon.amazon_estimator.AmazonAlgorithmEstimatorBase.fit`.\n        It requires Amazon :class:`~sagemaker.amazon.record_pb2.Record` protobuf\n        serialized data to be stored in S3. There is an utility\n        :meth:`~sagemaker.amazon.amazon_estimator.AmazonAlgorithmEstimatorBase.record_set`\n        that can be used to upload data to S3 and creates\n        :class:`~sagemaker.amazon.amazon_estimator.RecordSet` to be passed to\n        the `fit` call. To learn more about the Amazon protobuf Record class and\n        how to prepare bulk data in this format, please consult AWS technical\n        documentation:\n        https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-training.html After\n        this Estimator is fit, model data is stored in S3. The model may be\n        deployed to an Amazon SageMaker Endpoint by invoking\n        :meth:`~sagemaker.amazon.estimator.EstimatorBase.deploy`. As well as\n        deploying an Endpoint, deploy returns a\n        :class:`~sagemaker.amazon.knn.KNNPredictor` object that can be used for\n        inference calls using the trained model hosted in the SageMaker\n        Endpoint. KNN Estimators can be configured by setting hyperparameters.\n        The available hyperparameters for KNN are documented below. For further\n        information on the AWS KNN algorithm, please consult AWS technical\n        documentation: https://docs.aws.amazon.com/sagemaker/latest/dg/knn.html\n\n        Args:\n            role (str): An AWS IAM role (either name or full ARN). The Amazon\n                SageMaker training jobs and APIs that create Amazon SageMaker\n                endpoints use this role to access training data and model\n                artifacts. After the endpoint is created, the inference code\n                might use the IAM role, if accessing AWS resource.\n            train_instance_count:\n            train_instance_type (str): Type of EC2 instance to use for training,\n                for example, \'ml.c4.xlarge\'.\n            k (int): Required. Number of nearest neighbors.\n            sample_size (int): Required. Number of data points to be sampled\n                from the training data set.\n            predictor_type (str): Required. Type of inference to use on the\n                data\'s labels, allowed values are \'classifier\' and \'regressor\'.\n            dimension_reduction_type (str): Optional. Type of dimension\n                reduction technique to use. Valid values: ""sign"", ""fjlt""\n            dimension_reduction_target (int): Optional. Target dimension to\n                reduce to. Required when dimension_reduction_type is specified.\n            index_type (str): Optional. Type of index to use. Valid values are\n                ""faiss.Flat"", ""faiss.IVFFlat"", ""faiss.IVFPQ"".\n            index_metric (str): Optional. Distance metric to measure between\n                points when finding nearest neighbors. Valid values are\n                ""COSINE"", ""INNER_PRODUCT"", ""L2""\n            faiss_index_ivf_nlists (str): Optional. Number of centroids to\n                construct in the index if index_type is ""faiss.IVFFlat"" or\n                ""faiss.IVFPQ"".\n            faiss_index_pq_m (int): Optional. Number of vector sub-components to\n                construct in the index, if index_type is ""faiss.IVFPQ"".\n            **kwargs: base class keyword argument values.\n\n        .. tip::\n\n            You can find additional parameters for initializing this class at\n            :class:`~sagemaker.estimator.amazon_estimator.AmazonAlgorithmEstimatorBase` and\n            :class:`~sagemaker.estimator.EstimatorBase`.\n        """"""\n\n        super(KNN, self).__init__(role, train_instance_count, train_instance_type, **kwargs)\n        self.k = k\n        self.sample_size = sample_size\n        self.predictor_type = predictor_type\n        self.dimension_reduction_type = dimension_reduction_type\n        self.dimension_reduction_target = dimension_reduction_target\n        self.index_type = index_type\n        self.index_metric = index_metric\n        self.faiss_index_ivf_nlists = faiss_index_ivf_nlists\n        self.faiss_index_pq_m = faiss_index_pq_m\n        if dimension_reduction_type and not dimension_reduction_target:\n            raise ValueError(\n                \'""dimension_reduction_target"" is required when ""dimension_reduction_type"" is set.\'\n            )\n\n    def create_model(self, vpc_config_override=VPC_CONFIG_DEFAULT, **kwargs):\n        """"""Return a :class:`~sagemaker.amazon.KNNModel` referencing the latest\n        s3 model data produced by this Estimator.\n\n        Args:\n            vpc_config_override (dict[str, list[str]]): Optional override for VpcConfig set on\n                the model. Default: use subnets and security groups from this Estimator.\n                * \'Subnets\' (list[str]): List of subnet ids.\n                * \'SecurityGroupIds\' (list[str]): List of security group ids.\n            **kwargs: Additional kwargs passed to the KNNModel constructor.\n        """"""\n        return KNNModel(\n            self.model_data,\n            self.role,\n            sagemaker_session=self.sagemaker_session,\n            vpc_config=self.get_vpc_config(vpc_config_override),\n            **kwargs\n        )\n\n    def _prepare_for_training(self, records, mini_batch_size=None, job_name=None):\n        """"""\n        Args:\n            records:\n            mini_batch_size:\n            job_name:\n        """"""\n        super(KNN, self)._prepare_for_training(\n            records, mini_batch_size=mini_batch_size, job_name=job_name\n        )\n\n\nclass KNNPredictor(RealTimePredictor):\n    """"""Performs classification or regression prediction from input vectors.\n\n    The implementation of\n    :meth:`~sagemaker.predictor.RealTimePredictor.predict` in this\n    `RealTimePredictor` requires a numpy ``ndarray`` as input. The array should\n    contain the same number of columns as the feature-dimension of the data used\n    to fit the model this Predictor performs inference on.\n\n    :func:`predict` returns a list of\n    :class:`~sagemaker.amazon.record_pb2.Record` objects, one for each row in\n    the input ``ndarray``. The prediction is stored in the ``""predicted_label""``\n    key of the ``Record.label`` field.\n    """"""\n\n    def __init__(self, endpoint, sagemaker_session=None):\n        """"""\n        Args:\n            endpoint:\n            sagemaker_session:\n        """"""\n        super(KNNPredictor, self).__init__(\n            endpoint,\n            sagemaker_session,\n            serializer=numpy_to_record_serializer(),\n            deserializer=record_deserializer(),\n        )\n\n\nclass KNNModel(Model):\n    """"""Reference S3 model data created by KNN estimator. Calling\n    :meth:`~sagemaker.model.Model.deploy` creates an Endpoint and returns\n    :class:`KNNPredictor`.\n    """"""\n\n    def __init__(self, model_data, role, sagemaker_session=None, **kwargs):\n        """"""\n        Args:\n            model_data:\n            role:\n            sagemaker_session:\n            **kwargs:\n        """"""\n        sagemaker_session = sagemaker_session or Session()\n        repo = ""{}:{}"".format(KNN.repo_name, KNN.repo_version)\n        image = ""{}/{}"".format(\n            registry(sagemaker_session.boto_session.region_name, KNN.repo_name), repo\n        )\n        super(KNNModel, self).__init__(\n            model_data,\n            image,\n            role,\n            predictor_cls=KNNPredictor,\n            sagemaker_session=sagemaker_session,\n            **kwargs\n        )\n'"
src/sagemaker/amazon/lda.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nfrom sagemaker.amazon.amazon_estimator import AmazonAlgorithmEstimatorBase, registry\nfrom sagemaker.amazon.common import numpy_to_record_serializer, record_deserializer\nfrom sagemaker.amazon.hyperparameter import Hyperparameter as hp  # noqa\nfrom sagemaker.amazon.validation import gt\nfrom sagemaker.predictor import RealTimePredictor\nfrom sagemaker.model import Model\nfrom sagemaker.session import Session\nfrom sagemaker.vpc_utils import VPC_CONFIG_DEFAULT\n\n\nclass LDA(AmazonAlgorithmEstimatorBase):\n    """"""Placeholder docstring""""""\n\n    repo_name = ""lda""\n    repo_version = 1\n\n    num_topics = hp(""num_topics"", gt(0), ""An integer greater than zero"", int)\n    alpha0 = hp(""alpha0"", gt(0), ""A positive float"", float)\n    max_restarts = hp(""max_restarts"", gt(0), ""An integer greater than zero"", int)\n    max_iterations = hp(""max_iterations"", gt(0), ""An integer greater than zero"", int)\n    tol = hp(""tol"", gt(0), ""A positive float"", float)\n\n    def __init__(\n        self,\n        role,\n        train_instance_type,\n        num_topics,\n        alpha0=None,\n        max_restarts=None,\n        max_iterations=None,\n        tol=None,\n        **kwargs\n    ):\n        """"""Latent Dirichlet Allocation (LDA) is :class:`Estimator` used for\n        unsupervised learning.\n\n        Amazon SageMaker Latent Dirichlet Allocation is an unsupervised\n        learning algorithm that attempts to describe a set of observations as a\n        mixture of distinct categories. LDA is most commonly used to discover a\n        user-specified number of topics shared by documents within a text\n        corpus. Here each observation is a document, the features are the\n        presence (or occurrence count) of each word, and the categories are the\n        topics.\n\n        This Estimator may be fit via calls to\n        :meth:`~sagemaker.amazon.amazon_estimator.AmazonAlgorithmEstimatorBase.fit`.\n        It requires Amazon :class:`~sagemaker.amazon.record_pb2.Record` protobuf\n        serialized data to be stored in S3. There is an utility\n        :meth:`~sagemaker.amazon.amazon_estimator.AmazonAlgorithmEstimatorBase.record_set`\n        that can be used to upload data to S3 and creates\n        :class:`~sagemaker.amazon.amazon_estimator.RecordSet` to be passed to\n        the `fit` call.\n\n        To learn more about the Amazon protobuf Record class and how to\n        prepare bulk data in this format, please consult AWS technical\n        documentation:\n        https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-training.html\n\n        After this Estimator is fit, model data is stored in S3. The model\n        may be deployed to an Amazon SageMaker Endpoint by invoking\n        :meth:`~sagemaker.amazon.estimator.EstimatorBase.deploy`. As well as\n        deploying an Endpoint, deploy returns a\n        :class:`~sagemaker.amazon.lda.LDAPredictor` object that can be used for\n        inference calls using the trained model hosted in the SageMaker\n        Endpoint.\n\n        LDA Estimators can be configured by setting hyperparameters. The\n        available hyperparameters for LDA are documented below.\n\n        For further information on the AWS LDA algorithm, please consult AWS\n        technical documentation:\n        https://docs.aws.amazon.com/sagemaker/latest/dg/lda.html\n\n        Args:\n            role (str): An AWS IAM role (either name or full ARN). The Amazon\n                SageMaker training jobs and APIs that create Amazon SageMaker\n                endpoints use this role to access training data and model\n                artifacts. After the endpoint is created, the inference code\n                might use the IAM role, if accessing AWS resource.\n            train_instance_type (str): Type of EC2 instance to use for training,\n                for example, \'ml.c4.xlarge\'.\n            num_topics (int): The number of topics for LDA to find within the\n                data.\n            alpha0 (float): Optional. Initial guess for the concentration\n                parameter\n            max_restarts (int): Optional. The number of restarts to perform\n                during the Alternating Least Squares (ALS) spectral\n                decomposition phase of the algorithm.\n            max_iterations (int): Optional. The maximum number of iterations to\n                perform during the ALS phase of the algorithm.\n            tol (float): Optional. Target error tolerance for the ALS phase of\n                the algorithm.\n            **kwargs: base class keyword argument values.\n\n        .. tip::\n\n            You can find additional parameters for initializing this class at\n            :class:`~sagemaker.estimator.amazon_estimator.AmazonAlgorithmEstimatorBase` and\n            :class:`~sagemaker.estimator.EstimatorBase`.\n        """"""\n        # this algorithm only supports single instance training\n        if kwargs.pop(""train_instance_count"", 1) != 1:\n            print(\n                ""LDA only supports single instance training. Defaulting to 1 {}."".format(\n                    train_instance_type\n                )\n            )\n\n        super(LDA, self).__init__(role, 1, train_instance_type, **kwargs)\n        self.num_topics = num_topics\n        self.alpha0 = alpha0\n        self.max_restarts = max_restarts\n        self.max_iterations = max_iterations\n        self.tol = tol\n\n    def create_model(self, vpc_config_override=VPC_CONFIG_DEFAULT, **kwargs):\n        """"""Return a :class:`~sagemaker.amazon.LDAModel` referencing the latest\n        s3 model data produced by this Estimator.\n\n        Args:\n            vpc_config_override (dict[str, list[str]]): Optional override for\n                VpcConfig set on the model.\n                Default: use subnets and security groups from this Estimator.\n                * \'Subnets\' (list[str]): List of subnet ids.\n                * \'SecurityGroupIds\' (list[str]): List of security group ids.\n            **kwargs: Additional kwargs passed to the LDAModel constructor.\n        """"""\n        return LDAModel(\n            self.model_data,\n            self.role,\n            sagemaker_session=self.sagemaker_session,\n            vpc_config=self.get_vpc_config(vpc_config_override),\n            **kwargs\n        )\n\n    def _prepare_for_training(  # pylint: disable=signature-differs\n        self, records, mini_batch_size, job_name=None\n    ):\n        # mini_batch_size is required, prevent explicit calls with None\n        """"""\n        Args:\n            records:\n            mini_batch_size:\n            job_name:\n        """"""\n        if mini_batch_size is None:\n            raise ValueError(""mini_batch_size must be set"")\n\n        super(LDA, self)._prepare_for_training(\n            records, mini_batch_size=mini_batch_size, job_name=job_name\n        )\n\n\nclass LDAPredictor(RealTimePredictor):\n    """"""Transforms input vectors to lower-dimesional representations.\n\n    The implementation of\n    :meth:`~sagemaker.predictor.RealTimePredictor.predict` in this\n    `RealTimePredictor` requires a numpy ``ndarray`` as input. The array should\n    contain the same number of columns as the feature-dimension of the data used\n    to fit the model this Predictor performs inference on.\n\n    :meth:`predict()` returns a list of\n    :class:`~sagemaker.amazon.record_pb2.Record` objects, one for each row in\n    the input ``ndarray``. The lower dimension vector result is stored in the\n    ``projection`` key of the ``Record.label`` field.\n    """"""\n\n    def __init__(self, endpoint, sagemaker_session=None):\n        """"""\n        Args:\n            endpoint:\n            sagemaker_session:\n        """"""\n        super(LDAPredictor, self).__init__(\n            endpoint,\n            sagemaker_session,\n            serializer=numpy_to_record_serializer(),\n            deserializer=record_deserializer(),\n        )\n\n\nclass LDAModel(Model):\n    """"""Reference LDA s3 model data. Calling\n    :meth:`~sagemaker.model.Model.deploy` creates an Endpoint and return a\n    Predictor that transforms vectors to a lower-dimensional representation.\n    """"""\n\n    def __init__(self, model_data, role, sagemaker_session=None, **kwargs):\n        """"""\n        Args:\n            model_data:\n            role:\n            sagemaker_session:\n            **kwargs:\n        """"""\n        sagemaker_session = sagemaker_session or Session()\n        repo = ""{}:{}"".format(LDA.repo_name, LDA.repo_version)\n        image = ""{}/{}"".format(\n            registry(sagemaker_session.boto_session.region_name, LDA.repo_name), repo\n        )\n        super(LDAModel, self).__init__(\n            model_data,\n            image,\n            role,\n            predictor_cls=LDAPredictor,\n            sagemaker_session=sagemaker_session,\n            **kwargs\n        )\n'"
src/sagemaker/amazon/linear_learner.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nfrom sagemaker.amazon.amazon_estimator import AmazonAlgorithmEstimatorBase, registry\nfrom sagemaker.amazon.common import numpy_to_record_serializer, record_deserializer\nfrom sagemaker.amazon.hyperparameter import Hyperparameter as hp  # noqa\nfrom sagemaker.amazon.validation import isin, gt, lt, ge, le\nfrom sagemaker.predictor import RealTimePredictor\nfrom sagemaker.model import Model\nfrom sagemaker.session import Session\nfrom sagemaker.vpc_utils import VPC_CONFIG_DEFAULT\n\n\nclass LinearLearner(AmazonAlgorithmEstimatorBase):\n    """"""Placeholder docstring""""""\n\n    repo_name = ""linear-learner""\n    repo_version = 1\n\n    DEFAULT_MINI_BATCH_SIZE = 1000\n\n    binary_classifier_model_selection_criteria = hp(\n        ""binary_classifier_model_selection_criteria"",\n        isin(\n            ""accuracy"",\n            ""f1"",\n            ""f_beta"",\n            ""precision_at_target_recall"",\n            ""recall_at_target_precision"",\n            ""cross_entropy_loss"",\n            ""loss_function"",\n        ),\n        data_type=str,\n    )\n    target_recall = hp(""target_recall"", (gt(0), lt(1)), ""A float in (0,1)"", float)\n    target_precision = hp(""target_precision"", (gt(0), lt(1)), ""A float in (0,1)"", float)\n    positive_example_weight_mult = hp(\n        ""positive_example_weight_mult"", (), ""A float greater than 0 or \'auto\' or \'balanced\'"", str\n    )\n    epochs = hp(""epochs"", gt(0), ""An integer greater-than 0"", int)\n    predictor_type = hp(\n        ""predictor_type"",\n        isin(""binary_classifier"", ""regressor"", ""multiclass_classifier""),\n        \'One of ""binary_classifier"" or ""multiclass_classifier"" or ""regressor""\',\n        str,\n    )\n    use_bias = hp(""use_bias"", (), ""Either True or False"", bool)\n    num_models = hp(""num_models"", gt(0), ""An integer greater-than 0"", int)\n    num_calibration_samples = hp(""num_calibration_samples"", gt(0), ""An integer greater-than 0"", int)\n    init_method = hp(""init_method"", isin(""uniform"", ""normal""), \'One of ""uniform"" or ""normal""\', str)\n    init_scale = hp(""init_scale"", gt(0), ""A float greater-than 0"", float)\n    init_sigma = hp(""init_sigma"", gt(0), ""A float greater-than 0"", float)\n    init_bias = hp(""init_bias"", (), ""A number"", float)\n    optimizer = hp(\n        ""optimizer"",\n        isin(""sgd"", ""adam"", ""rmsprop"", ""auto""),\n        \'One of ""sgd"", ""adam"", ""rmsprop"" or ""auto\',\n        str,\n    )\n    loss = hp(\n        ""loss"",\n        isin(\n            ""logistic"",\n            ""squared_loss"",\n            ""absolute_loss"",\n            ""hinge_loss"",\n            ""eps_insensitive_squared_loss"",\n            ""eps_insensitive_absolute_loss"",\n            ""quantile_loss"",\n            ""huber_loss"",\n            ""softmax_loss"",\n            ""auto"",\n        ),\n        \'""logistic"", ""squared_loss"", ""absolute_loss"", ""hinge_loss"", ""eps_insensitive_squared_loss"",\'\n        \' ""eps_insensitive_absolute_loss"", ""quantile_loss"", ""huber_loss"", ""softmax_loss"" or ""auto""\',\n        str,\n    )\n    wd = hp(""wd"", ge(0), ""A float greater-than or equal to 0"", float)\n    l1 = hp(""l1"", ge(0), ""A float greater-than or equal to 0"", float)\n    momentum = hp(""momentum"", (ge(0), lt(1)), ""A float in [0,1)"", float)\n    learning_rate = hp(""learning_rate"", gt(0), ""A float greater-than 0"", float)\n    beta_1 = hp(""beta_1"", (ge(0), lt(1)), ""A float in [0,1)"", float)\n    beta_2 = hp(""beta_2"", (ge(0), lt(1)), ""A float in [0,1)"", float)\n    bias_lr_mult = hp(""bias_lr_mult"", gt(0), ""A float greater-than 0"", float)\n    bias_wd_mult = hp(""bias_wd_mult"", ge(0), ""A float greater-than or equal to 0"", float)\n    use_lr_scheduler = hp(""use_lr_scheduler"", (), ""A boolean"", bool)\n    lr_scheduler_step = hp(""lr_scheduler_step"", gt(0), ""An integer greater-than 0"", int)\n    lr_scheduler_factor = hp(""lr_scheduler_factor"", (gt(0), lt(1)), ""A float in (0,1)"", float)\n    lr_scheduler_minimum_lr = hp(""lr_scheduler_minimum_lr"", gt(0), ""A float greater-than 0"", float)\n    normalize_data = hp(""normalize_data"", (), ""A boolean"", bool)\n    normalize_label = hp(""normalize_label"", (), ""A boolean"", bool)\n    unbias_data = hp(""unbias_data"", (), ""A boolean"", bool)\n    unbias_label = hp(""unbias_label"", (), ""A boolean"", bool)\n    num_point_for_scaler = hp(""num_point_for_scaler"", gt(0), ""An integer greater-than 0"", int)\n    margin = hp(""margin"", ge(0), ""A float greater-than or equal to 0"", float)\n    quantile = hp(""quantile"", (gt(0), lt(1)), ""A float in (0,1)"", float)\n    loss_insensitivity = hp(""loss_insensitivity"", gt(0), ""A float greater-than 0"", float)\n    huber_delta = hp(""huber_delta"", ge(0), ""A float greater-than or equal to 0"", float)\n    early_stopping_patience = hp(""early_stopping_patience"", gt(0), ""An integer greater-than 0"", int)\n    early_stopping_tolerance = hp(\n        ""early_stopping_tolerance"", gt(0), ""A float greater-than 0"", float\n    )\n    num_classes = hp(""num_classes"", (gt(0), le(1000000)), ""An integer in [1,1000000]"", int)\n    accuracy_top_k = hp(""accuracy_top_k"", (gt(0), le(1000000)), ""An integer in [1,1000000]"", int)\n    f_beta = hp(""f_beta"", gt(0), ""A float greater-than 0"", float)\n    balance_multiclass_weights = hp(""balance_multiclass_weights"", (), ""A boolean"", bool)\n\n    def __init__(\n        self,\n        role,\n        train_instance_count,\n        train_instance_type,\n        predictor_type,\n        binary_classifier_model_selection_criteria=None,\n        target_recall=None,\n        target_precision=None,\n        positive_example_weight_mult=None,\n        epochs=None,\n        use_bias=None,\n        num_models=None,\n        num_calibration_samples=None,\n        init_method=None,\n        init_scale=None,\n        init_sigma=None,\n        init_bias=None,\n        optimizer=None,\n        loss=None,\n        wd=None,\n        l1=None,\n        momentum=None,\n        learning_rate=None,\n        beta_1=None,\n        beta_2=None,\n        bias_lr_mult=None,\n        bias_wd_mult=None,\n        use_lr_scheduler=None,\n        lr_scheduler_step=None,\n        lr_scheduler_factor=None,\n        lr_scheduler_minimum_lr=None,\n        normalize_data=None,\n        normalize_label=None,\n        unbias_data=None,\n        unbias_label=None,\n        num_point_for_scaler=None,\n        margin=None,\n        quantile=None,\n        loss_insensitivity=None,\n        huber_delta=None,\n        early_stopping_patience=None,\n        early_stopping_tolerance=None,\n        num_classes=None,\n        accuracy_top_k=None,\n        f_beta=None,\n        balance_multiclass_weights=None,\n        **kwargs\n    ):\n        """"""An :class:`Estimator` for binary classification and regression.\n\n        Amazon SageMaker Linear Learner provides a solution for both\n        classification and regression problems, allowing for exploring different\n        training objectives simultaneously and choosing the best solution from a\n        validation set. It allows the user to explore a large number of models\n        and choose the best, which optimizes either continuous objectives such\n        as mean square error, cross entropy loss, absolute error, etc., or\n        discrete objectives suited for classification such as F1 measure,\n        precision@recall, accuracy. The implementation provides a significant\n        speedup over naive hyperparameter optimization techniques and an added\n        convenience, when compared with solutions providing a solution only to\n        continuous objectives.\n\n        This Estimator may be fit via calls to\n        :meth:`~sagemaker.amazon.amazon_estimator.AmazonAlgorithmEstimatorBase.fit_ndarray`\n        or\n        :meth:`~sagemaker.amazon.amazon_estimator.AmazonAlgorithmEstimatorBase.fit`.\n        The former allows a LinearLearner model to be fit on a 2-dimensional\n        numpy array. The latter requires Amazon\n        :class:`~sagemaker.amazon.record_pb2.Record` protobuf serialized data to\n        be stored in S3.\n\n        To learn more about the Amazon protobuf Record class and how to\n        prepare bulk data in this format, please consult AWS technical\n        documentation:\n        https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-training.html\n\n        After this Estimator is fit, model data is stored in S3. The model\n        may be deployed to an Amazon SageMaker Endpoint by invoking\n        :meth:`~sagemaker.amazon.estimator.EstimatorBase.deploy`. As well as\n        deploying an Endpoint, ``deploy`` returns a\n        :class:`~sagemaker.amazon.linear_learner.LinearLearnerPredictor` object\n        that can be used to make class or regression predictions, using the\n        trained model.\n\n        LinearLearner Estimators can be configured by setting\n        hyperparameters. The available hyperparameters for LinearLearner are\n        documented below. For further information on the AWS LinearLearner\n        algorithm, please consult AWS technical documentation:\n        https://docs.aws.amazon.com/sagemaker/latest/dg/linear-learner.html\n\n        Args:\n            role (str): An AWS IAM role (either name or full ARN). The Amazon\n                SageMaker training jobs and APIs that create Amazon SageMaker\n                endpoints use this role to access training data and model\n                artifacts. After the endpoint is created, the inference code\n                might use the IAM role, if accessing AWS resource.\n            train_instance_count (int): Number of Amazon EC2 instances to use\n                for training.\n            train_instance_type (str): Type of EC2 instance to use for training,\n                for example, \'ml.c4.xlarge\'.\n            predictor_type (str): The type of predictor to learn. Either\n                ""binary_classifier"" or ""multiclass_classifier"" or ""regressor"".\n            binary_classifier_model_selection_criteria (str): One of \'accuracy\',\n                \'f1\', \'f_beta\', \'precision_at_target_recall\', \'recall_at_target_precision\',\n                \'cross_entropy_loss\', \'loss_function\'\n            target_recall (float): Target recall. Only applicable if\n                binary_classifier_model_selection_criteria is\n                precision_at_target_recall.\n            target_precision (float): Target precision. Only applicable if\n                binary_classifier_model_selection_criteria is\n                recall_at_target_precision.\n            positive_example_weight_mult (float): The importance weight of\n                positive examples is multiplied by this constant. Useful for\n                skewed datasets. Only applies for classification tasks.\n            epochs (int): The maximum number of passes to make over the training\n                data.\n            use_bias (bool): Whether to include a bias field\n            num_models (int): Number of models to train in parallel. If not set,\n                the number of parallel models to train will be decided by the\n                algorithm itself. One model will be trained according to the\n                given training parameter (regularization, optimizer, loss) and\n                the rest by close by parameters.\n            num_calibration_samples (int): Number of observations to use from\n                validation dataset for doing model calibration (finding the best threshold).\n            init_method (str): Function to use to set the initial model weights.\n                One of ""uniform"" or ""normal""\n            init_scale (float): For ""uniform"" init, the range of values.\n            init_sigma (float): For ""normal"" init, the standard-deviation.\n            init_bias (float): Initial weight for bias term\n            optimizer (str): One of \'sgd\', \'adam\', \'rmsprop\' or \'auto\'\n            loss (str): One of \'logistic\', \'squared_loss\', \'absolute_loss\',\n                \'hinge_loss\', \'eps_insensitive_squared_loss\', \'eps_insensitive_absolute_loss\',\n                \'quantile_loss\', \'huber_loss\' or\n            \'softmax_loss\' or \'auto\'.\n            wd (float): L2 regularization parameter i.e. the weight decay\n                parameter. Use 0 for no L2 regularization.\n            l1 (float): L1 regularization parameter. Use 0 for no L1\n                regularization.\n            momentum (float): Momentum parameter of sgd optimizer.\n            learning_rate (float): The SGD learning rate\n            beta_1 (float): Exponential decay rate for first moment estimates.\n                Only applies for adam optimizer.\n            beta_2 (float): Exponential decay rate for second moment estimates.\n                Only applies for adam optimizer.\n            bias_lr_mult (float): Allows different learning rate for the bias\n                term. The actual learning rate for the bias is learning rate times bias_lr_mult.\n            bias_wd_mult (float): Allows different regularization for the bias\n                term. The actual L2 regularization weight for the bias is wd times bias_wd_mult.\n                By default there is no regularization on the bias term.\n            use_lr_scheduler (bool): If true, we use a scheduler for the\n                learning rate.\n            lr_scheduler_step (int): The number of steps between decreases of\n                the learning rate. Only applies to learning rate scheduler.\n            lr_scheduler_factor (float): Every lr_scheduler_step the learning\n                rate will decrease by this quantity. Only applies for learning\n                rate scheduler.\n            lr_scheduler_minimum_lr (float): The learning rate will never\n                decrease to a value lower than this. Only applies for learning rate scheduler.\n            normalize_data (bool): Normalizes the features before training to\n                have standard deviation of 1.0.\n            normalize_label (bool): Normalizes the regression label to have a\n                standard deviation of 1.0. If set for classification, it will be\n                ignored.\n            unbias_data (bool): If true, features are modified to have mean 0.0.\n            unbias_label (bool): If true, labels are modified to have mean 0.0.\n            num_point_for_scaler (int): The number of data points to use for\n                calculating the normalizing and unbiasing terms.\n            margin (float): the margin for hinge_loss.\n            quantile (float): Quantile for quantile loss. For quantile q, the\n                model will attempt to produce predictions such that true_label < prediction with\n                probability q.\n            loss_insensitivity (float): Parameter for epsilon insensitive loss\n                type. During training and metric evaluation, any error smaller than this is\n                considered to be zero.\n            huber_delta (float): Parameter for Huber loss. During training and\n                metric evaluation, compute L2 loss for errors smaller than delta and L1 loss for\n                errors larger than delta.\n            early_stopping_patience (int): the number of epochs to wait before ending training\n            if no improvement is made. The improvement is training loss if validation data is\n            not provided, or else it is the validation loss or the binary classification model\n            selection criteria like accuracy, f1-score etc. To disable early stopping,\n            set early_stopping_patience to a value larger than epochs.\n            early_stopping_tolerance (float): Relative tolerance to measure an\n                improvement in loss. If the ratio of the improvement in loss divided by the\n                previous best loss is smaller than this value, early stopping will\n            consider the improvement to be zero.\n            num_classes (int): The number of classes for the response variable.\n                Required when predictor_type is multiclass_classifier and ignored otherwise. The\n                classes are assumed to be labeled 0, ..., num_classes - 1.\n            accuracy_top_k (int): The value of k when computing the Top K\n                Accuracy metric for multiclass classification. An example is scored as correct\n                if the model assigns one of the top k scores to the true\n            label.\n            f_beta (float): The value of beta to use when calculating F score\n                metrics for binary or multiclass classification. Also used if\n                binary_classifier_model_selection_criteria is f_beta.\n            balance_multiclass_weights (bool): Whether to use class weights\n                which give each class equal importance in the loss function. Only used when\n                predictor_type is multiclass_classifier.\n            **kwargs: base class keyword argument values.\n\n        .. tip::\n\n            You can find additional parameters for initializing this class at\n            :class:`~sagemaker.estimator.amazon_estimator.AmazonAlgorithmEstimatorBase` and\n            :class:`~sagemaker.estimator.EstimatorBase`.\n        """"""\n        super(LinearLearner, self).__init__(\n            role, train_instance_count, train_instance_type, **kwargs\n        )\n        self.predictor_type = predictor_type\n        self.binary_classifier_model_selection_criteria = binary_classifier_model_selection_criteria\n        self.target_recall = target_recall\n        self.target_precision = target_precision\n        self.positive_example_weight_mult = positive_example_weight_mult\n        self.epochs = epochs\n        self.use_bias = use_bias\n        self.num_models = num_models\n        self.num_calibration_samples = num_calibration_samples\n        self.init_method = init_method\n        self.init_scale = init_scale\n        self.init_sigma = init_sigma\n        self.init_bias = init_bias\n        self.optimizer = optimizer\n        self.loss = loss\n        self.wd = wd\n        self.l1 = l1\n        self.momentum = momentum\n        self.learning_rate = learning_rate\n        self.beta_1 = beta_1\n        self.beta_2 = beta_2\n        self.bias_lr_mult = bias_lr_mult\n        self.bias_wd_mult = bias_wd_mult\n        self.use_lr_scheduler = use_lr_scheduler\n        self.lr_scheduler_step = lr_scheduler_step\n        self.lr_scheduler_factor = lr_scheduler_factor\n        self.lr_scheduler_minimum_lr = lr_scheduler_minimum_lr\n        self.normalize_data = normalize_data\n        self.normalize_label = normalize_label\n        self.unbias_data = unbias_data\n        self.unbias_label = unbias_label\n        self.num_point_for_scaler = num_point_for_scaler\n        self.margin = margin\n        self.quantile = quantile\n        self.loss_insensitivity = loss_insensitivity\n        self.huber_delta = huber_delta\n        self.early_stopping_patience = early_stopping_patience\n        self.early_stopping_tolerance = early_stopping_tolerance\n        self.num_classes = num_classes\n        self.accuracy_top_k = accuracy_top_k\n        self.f_beta = f_beta\n        self.balance_multiclass_weights = balance_multiclass_weights\n\n        if self.predictor_type == ""multiclass_classifier"" and (\n            num_classes is None or int(num_classes) < 3\n        ):\n            raise ValueError(\n                ""For predictor_type \'multiclass_classifier\', \'num_classes\' should be set to a ""\n                ""value greater than 2.""\n            )\n\n    def create_model(self, vpc_config_override=VPC_CONFIG_DEFAULT, **kwargs):\n        """"""Return a :class:`~sagemaker.amazon.LinearLearnerModel` referencing\n        the latest s3 model data produced by this Estimator.\n\n        Args:\n            vpc_config_override (dict[str, list[str]]): Optional override for VpcConfig set on\n                the model. Default: use subnets and security groups from this Estimator.\n                * \'Subnets\' (list[str]): List of subnet ids.\n                * \'SecurityGroupIds\' (list[str]): List of security group ids.\n            **kwargs: Additional kwargs passed to the LinearLearnerModel constructor.\n        """"""\n        return LinearLearnerModel(\n            self.model_data,\n            self.role,\n            self.sagemaker_session,\n            vpc_config=self.get_vpc_config(vpc_config_override),\n            **kwargs\n        )\n\n    def _prepare_for_training(self, records, mini_batch_size=None, job_name=None):\n        """"""\n        Args:\n            records:\n            mini_batch_size:\n            job_name:\n        """"""\n        num_records = None\n        if isinstance(records, list):\n            for record in records:\n                if record.channel == ""train"":\n                    num_records = record.num_records\n                    break\n            if num_records is None:\n                raise ValueError(""Must provide train channel."")\n        else:\n            num_records = records.num_records\n\n        # mini_batch_size can\'t be greater than number of records or training job fails\n        default_mini_batch_size = min(\n            self.DEFAULT_MINI_BATCH_SIZE, max(1, int(num_records / self.train_instance_count))\n        )\n        mini_batch_size = mini_batch_size or default_mini_batch_size\n        super(LinearLearner, self)._prepare_for_training(\n            records, mini_batch_size=mini_batch_size, job_name=job_name\n        )\n\n\nclass LinearLearnerPredictor(RealTimePredictor):\n    """"""Performs binary-classification or regression prediction from input\n    vectors.\n\n    The implementation of\n    :meth:`~sagemaker.predictor.RealTimePredictor.predict` in this\n    `RealTimePredictor` requires a numpy ``ndarray`` as input. The array should\n    contain the same number of columns as the feature-dimension of the data used\n    to fit the model this Predictor performs inference on.\n\n    :func:`predict` returns a list of\n    :class:`~sagemaker.amazon.record_pb2.Record` objects, one for each row in\n    the input ``ndarray``. The prediction is stored in the ``""predicted_label""``\n    key of the ``Record.label`` field.\n    """"""\n\n    def __init__(self, endpoint, sagemaker_session=None):\n        """"""\n        Args:\n            endpoint:\n            sagemaker_session:\n        """"""\n        super(LinearLearnerPredictor, self).__init__(\n            endpoint,\n            sagemaker_session,\n            serializer=numpy_to_record_serializer(),\n            deserializer=record_deserializer(),\n        )\n\n\nclass LinearLearnerModel(Model):\n    """"""Reference LinearLearner s3 model data. Calling\n    :meth:`~sagemaker.model.Model.deploy` creates an Endpoint and returns a\n    :class:`LinearLearnerPredictor`\n    """"""\n\n    def __init__(self, model_data, role, sagemaker_session=None, **kwargs):\n        """"""\n        Args:\n            model_data:\n            role:\n            sagemaker_session:\n            **kwargs:\n        """"""\n        sagemaker_session = sagemaker_session or Session()\n        repo = ""{}:{}"".format(LinearLearner.repo_name, LinearLearner.repo_version)\n        image = ""{}/{}"".format(registry(sagemaker_session.boto_session.region_name), repo)\n        super(LinearLearnerModel, self).__init__(\n            model_data,\n            image,\n            role,\n            predictor_cls=LinearLearnerPredictor,\n            sagemaker_session=sagemaker_session,\n            **kwargs\n        )\n'"
src/sagemaker/amazon/ntm.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nfrom sagemaker.amazon.amazon_estimator import AmazonAlgorithmEstimatorBase, registry\nfrom sagemaker.amazon.common import numpy_to_record_serializer, record_deserializer\nfrom sagemaker.amazon.hyperparameter import Hyperparameter as hp  # noqa\nfrom sagemaker.amazon.validation import ge, le, isin\nfrom sagemaker.predictor import RealTimePredictor\nfrom sagemaker.model import Model\nfrom sagemaker.session import Session\nfrom sagemaker.vpc_utils import VPC_CONFIG_DEFAULT\n\n\nclass NTM(AmazonAlgorithmEstimatorBase):\n    """"""Placeholder docstring""""""\n\n    repo_name = ""ntm""\n    repo_version = 1\n\n    num_topics = hp(""num_topics"", (ge(2), le(1000)), ""An integer in [2, 1000]"", int)\n    encoder_layers = hp(\n        name=""encoder_layers"",\n        validation_message=""A comma separated list of "" ""positive integers"",\n        data_type=list,\n    )\n    epochs = hp(""epochs"", (ge(1), le(100)), ""An integer in [1, 100]"", int)\n    encoder_layers_activation = hp(\n        ""encoder_layers_activation"",\n        isin(""sigmoid"", ""tanh"", ""relu""),\n        \'One of ""sigmoid"", ""tanh"" or ""relu""\',\n        str,\n    )\n    optimizer = hp(\n        ""optimizer"",\n        isin(""adagrad"", ""adam"", ""rmsprop"", ""sgd"", ""adadelta""),\n        \'One of ""adagrad"", ""adam"", ""rmsprop"", ""sgd"" and ""adadelta""\',\n        str,\n    )\n    tolerance = hp(""tolerance"", (ge(1e-6), le(0.1)), ""A float in [1e-6, 0.1]"", float)\n    num_patience_epochs = hp(""num_patience_epochs"", (ge(1), le(10)), ""An integer in [1, 10]"", int)\n    batch_norm = hp(name=""batch_norm"", validation_message=""Value must be a boolean"", data_type=bool)\n    rescale_gradient = hp(""rescale_gradient"", (ge(1e-3), le(1.0)), ""A float in [1e-3, 1.0]"", float)\n    clip_gradient = hp(""clip_gradient"", ge(1e-3), ""A float greater equal to 1e-3"", float)\n    weight_decay = hp(""weight_decay"", (ge(0.0), le(1.0)), ""A float in [0.0, 1.0]"", float)\n    learning_rate = hp(""learning_rate"", (ge(1e-6), le(1.0)), ""A float in [1e-6, 1.0]"", float)\n\n    def __init__(\n        self,\n        role,\n        train_instance_count,\n        train_instance_type,\n        num_topics,\n        encoder_layers=None,\n        epochs=None,\n        encoder_layers_activation=None,\n        optimizer=None,\n        tolerance=None,\n        num_patience_epochs=None,\n        batch_norm=None,\n        rescale_gradient=None,\n        clip_gradient=None,\n        weight_decay=None,\n        learning_rate=None,\n        **kwargs\n    ):\n        """"""Neural Topic Model (NTM) is :class:`Estimator` used for unsupervised\n        learning.\n\n        This Estimator may be fit via calls to\n        :meth:`~sagemaker.amazon.amazon_estimator.AmazonAlgorithmEstimatorBase.fit`.\n        It requires Amazon :class:`~sagemaker.amazon.record_pb2.Record` protobuf\n        serialized data to be stored in S3. There is an utility\n        :meth:`~sagemaker.amazon.amazon_estimator.AmazonAlgorithmEstimatorBase.record_set`\n        that can be used to upload data to S3 and creates\n        :class:`~sagemaker.amazon.amazon_estimator.RecordSet` to be passed to\n        the `fit` call.\n\n        To learn more about the Amazon protobuf Record class and how to\n        prepare bulk data in this format, please consult AWS technical\n        documentation:\n        https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-training.html\n\n        After this Estimator is fit, model data is stored in S3. The model\n        may be deployed to an Amazon SageMaker Endpoint by invoking\n        :meth:`~sagemaker.amazon.estimator.EstimatorBase.deploy`. As well as\n        deploying an Endpoint, deploy returns a\n        :class:`~sagemaker.amazon.ntm.NTMPredictor` object that can be used for\n        inference calls using the trained model hosted in the SageMaker\n        Endpoint.\n\n        NTM Estimators can be configured by setting hyperparameters. The\n        available hyperparameters for NTM are documented below.\n\n        For further information on the AWS NTM algorithm, please consult AWS\n        technical documentation:\n        https://docs.aws.amazon.com/sagemaker/latest/dg/ntm.html\n\n        Args:\n            role (str): An AWS IAM role (either name or full ARN). The Amazon\n                SageMaker training jobs and APIs that create Amazon SageMaker\n                endpoints use this role to access training data and model\n                artifacts. After the endpoint is created, the inference code\n                might use the IAM role, if accessing AWS resource.\n            train_instance_count:\n            train_instance_type (str): Type of EC2 instance to use for training,\n                for example, \'ml.c4.xlarge\'.\n            num_topics (int): Required. The number of topics for NTM to find\n                within the data.\n            encoder_layers (list): Optional. Represents number of layers in the\n                encoder and the output size of each layer.\n            epochs (int): Optional. Maximum number of passes over the training\n                data.\n            encoder_layers_activation (str): Optional. Activation function to\n                use in the encoder layers.\n            optimizer (str): Optional. Optimizer to use for training.\n            tolerance (float): Optional. Maximum relative change in the loss\n                function within the last num_patience_epochs number of epochs\n                below which early stopping is triggered.\n            num_patience_epochs (int): Optional. Number of successive epochs\n                over which early stopping criterion is evaluated.\n            batch_norm (bool): Optional. Whether to use batch normalization\n                during training.\n            rescale_gradient (float): Optional. Rescale factor for gradient.\n            clip_gradient (float): Optional. Maximum magnitude for each gradient\n                component.\n            weight_decay (float): Optional. Weight decay coefficient. Adds L2\n                regularization.\n            learning_rate (float): Optional. Learning rate for the optimizer.\n            **kwargs: base class keyword argument values.\n\n        .. tip::\n\n            You can find additional parameters for initializing this class at\n            :class:`~sagemaker.estimator.amazon_estimator.AmazonAlgorithmEstimatorBase` and\n            :class:`~sagemaker.estimator.EstimatorBase`.\n        """"""\n\n        super(NTM, self).__init__(role, train_instance_count, train_instance_type, **kwargs)\n        self.num_topics = num_topics\n        self.encoder_layers = encoder_layers\n        self.epochs = epochs\n        self.encoder_layers_activation = encoder_layers_activation\n        self.optimizer = optimizer\n        self.tolerance = tolerance\n        self.num_patience_epochs = num_patience_epochs\n        self.batch_norm = batch_norm\n        self.rescale_gradient = rescale_gradient\n        self.clip_gradient = clip_gradient\n        self.weight_decay = weight_decay\n        self.learning_rate = learning_rate\n\n    def create_model(self, vpc_config_override=VPC_CONFIG_DEFAULT, **kwargs):\n        """"""Return a :class:`~sagemaker.amazon.NTMModel` referencing the latest\n        s3 model data produced by this Estimator.\n\n        Args:\n            vpc_config_override (dict[str, list[str]]): Optional override for VpcConfig set on\n                the model. Default: use subnets and security groups from this Estimator.\n                * \'Subnets\' (list[str]): List of subnet ids.\n                * \'SecurityGroupIds\' (list[str]): List of security group ids.\n            **kwargs: Additional kwargs passed to the NTMModel constructor.\n        """"""\n        return NTMModel(\n            self.model_data,\n            self.role,\n            sagemaker_session=self.sagemaker_session,\n            vpc_config=self.get_vpc_config(vpc_config_override),\n            **kwargs\n        )\n\n    def _prepare_for_training(  # pylint: disable=signature-differs\n        self, records, mini_batch_size, job_name=None\n    ):\n        """"""\n        Args:\n            records:\n            mini_batch_size:\n            job_name:\n        """"""\n        if mini_batch_size is not None and (mini_batch_size < 1 or mini_batch_size > 10000):\n            raise ValueError(""mini_batch_size must be in [1, 10000]"")\n        super(NTM, self)._prepare_for_training(\n            records, mini_batch_size=mini_batch_size, job_name=job_name\n        )\n\n\nclass NTMPredictor(RealTimePredictor):\n    """"""Transforms input vectors to lower-dimesional representations.\n\n    The implementation of\n    :meth:`~sagemaker.predictor.RealTimePredictor.predict` in this\n    `RealTimePredictor` requires a numpy ``ndarray`` as input. The array should\n    contain the same number of columns as the feature-dimension of the data used\n    to fit the model this Predictor performs inference on.\n\n    :meth:`predict()` returns a list of\n    :class:`~sagemaker.amazon.record_pb2.Record` objects, one for each row in\n    the input ``ndarray``. The lower dimension vector result is stored in the\n    ``projection`` key of the ``Record.label`` field.\n    """"""\n\n    def __init__(self, endpoint, sagemaker_session=None):\n        """"""\n        Args:\n            endpoint:\n            sagemaker_session:\n        """"""\n        super(NTMPredictor, self).__init__(\n            endpoint,\n            sagemaker_session,\n            serializer=numpy_to_record_serializer(),\n            deserializer=record_deserializer(),\n        )\n\n\nclass NTMModel(Model):\n    """"""Reference NTM s3 model data. Calling\n    :meth:`~sagemaker.model.Model.deploy` creates an Endpoint and return a\n    Predictor that transforms vectors to a lower-dimensional representation.\n    """"""\n\n    def __init__(self, model_data, role, sagemaker_session=None, **kwargs):\n        """"""\n        Args:\n            model_data:\n            role:\n            sagemaker_session:\n            **kwargs:\n        """"""\n        sagemaker_session = sagemaker_session or Session()\n        repo = ""{}:{}"".format(NTM.repo_name, NTM.repo_version)\n        image = ""{}/{}"".format(\n            registry(sagemaker_session.boto_session.region_name, NTM.repo_name), repo\n        )\n        super(NTMModel, self).__init__(\n            model_data,\n            image,\n            role,\n            predictor_cls=NTMPredictor,\n            sagemaker_session=sagemaker_session,\n            **kwargs\n        )\n'"
src/sagemaker/amazon/object2vec.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nfrom sagemaker.amazon.amazon_estimator import AmazonAlgorithmEstimatorBase, registry\nfrom sagemaker.amazon.hyperparameter import Hyperparameter as hp  # noqa\nfrom sagemaker.amazon.validation import ge, le, isin\nfrom sagemaker.predictor import RealTimePredictor\nfrom sagemaker.model import Model\nfrom sagemaker.session import Session\nfrom sagemaker.vpc_utils import VPC_CONFIG_DEFAULT\n\n\ndef _list_check_subset(valid_super_list):\n    """"""\n    Args:\n        valid_super_list:\n    """"""\n    valid_superset = set(valid_super_list)\n\n    def validate(value):\n        if not isinstance(value, str):\n            return False\n\n        val_list = [s.strip() for s in value.split("","")]\n        return set(val_list).issubset(valid_superset)\n\n    return validate\n\n\nclass Object2Vec(AmazonAlgorithmEstimatorBase):\n    """"""Placeholder docstring""""""\n\n    repo_name = ""object2vec""\n    repo_version = 1\n    MINI_BATCH_SIZE = 32\n\n    enc_dim = hp(""enc_dim"", (ge(4), le(10000)), ""An integer in [4, 10000]"", int)\n    mini_batch_size = hp(""mini_batch_size"", (ge(1), le(10000)), ""An integer in [1, 10000]"", int)\n    epochs = hp(""epochs"", (ge(1), le(100)), ""An integer in [1, 100]"", int)\n    early_stopping_patience = hp(\n        ""early_stopping_patience"", (ge(1), le(5)), ""An integer in [1, 5]"", int\n    )\n    early_stopping_tolerance = hp(\n        ""early_stopping_tolerance"", (ge(1e-06), le(0.1)), ""A float in [1e-06, 0.1]"", float\n    )\n    dropout = hp(""dropout"", (ge(0.0), le(1.0)), ""A float in [0.0, 1.0]"", float)\n    weight_decay = hp(""weight_decay"", (ge(0.0), le(10000.0)), ""A float in [0.0, 10000.0]"", float)\n    bucket_width = hp(""bucket_width"", (ge(0), le(100)), ""An integer in [0, 100]"", int)\n    num_classes = hp(""num_classes"", (ge(2), le(30)), ""An integer in [2, 30]"", int)\n    mlp_layers = hp(""mlp_layers"", (ge(1), le(10)), ""An integer in [1, 10]"", int)\n    mlp_dim = hp(""mlp_dim"", (ge(2), le(10000)), ""An integer in [2, 10000]"", int)\n    mlp_activation = hp(\n        ""mlp_activation"", isin(""tanh"", ""relu"", ""linear""), \'One of ""tanh"", ""relu"", ""linear""\', str\n    )\n    output_layer = hp(\n        ""output_layer"",\n        isin(""softmax"", ""mean_squared_error""),\n        \'One of ""softmax"", ""mean_squared_error""\',\n        str,\n    )\n    optimizer = hp(\n        ""optimizer"",\n        isin(""adagrad"", ""adam"", ""rmsprop"", ""sgd"", ""adadelta""),\n        \'One of ""adagrad"", ""adam"", ""rmsprop"", ""sgd"", ""adadelta""\',\n        str,\n    )\n    learning_rate = hp(""learning_rate"", (ge(1e-06), le(1.0)), ""A float in [1e-06, 1.0]"", float)\n\n    negative_sampling_rate = hp(\n        ""negative_sampling_rate"", (ge(0), le(100)), ""An integer in [0, 100]"", int\n    )\n    comparator_list = hp(\n        ""comparator_list"",\n        _list_check_subset([""hadamard"", ""concat"", ""abs_diff""]),\n        \'Comma-separated of hadamard, concat, abs_diff. E.g. ""hadamard,abs_diff""\',\n        str,\n    )\n    tied_token_embedding_weight = hp(\n        ""tied_token_embedding_weight"", (), ""Either True or False"", bool\n    )\n    token_embedding_storage_type = hp(\n        ""token_embedding_storage_type"",\n        isin(""dense"", ""row_sparse""),\n        \'One of ""dense"", ""row_sparse""\',\n        str,\n    )\n\n    enc0_network = hp(\n        ""enc0_network"",\n        isin(""hcnn"", ""bilstm"", ""pooled_embedding""),\n        \'One of ""hcnn"", ""bilstm"", ""pooled_embedding""\',\n        str,\n    )\n    enc1_network = hp(\n        ""enc1_network"",\n        isin(""hcnn"", ""bilstm"", ""pooled_embedding"", ""enc0""),\n        \'One of ""hcnn"", ""bilstm"", ""pooled_embedding"", ""enc0""\',\n        str,\n    )\n    enc0_cnn_filter_width = hp(""enc0_cnn_filter_width"", (ge(1), le(9)), ""An integer in [1, 9]"", int)\n    enc1_cnn_filter_width = hp(""enc1_cnn_filter_width"", (ge(1), le(9)), ""An integer in [1, 9]"", int)\n    enc0_max_seq_len = hp(""enc0_max_seq_len"", (ge(1), le(5000)), ""An integer in [1, 5000]"", int)\n    enc1_max_seq_len = hp(""enc1_max_seq_len"", (ge(1), le(5000)), ""An integer in [1, 5000]"", int)\n    enc0_token_embedding_dim = hp(\n        ""enc0_token_embedding_dim"", (ge(2), le(1000)), ""An integer in [2, 1000]"", int\n    )\n    enc1_token_embedding_dim = hp(\n        ""enc1_token_embedding_dim"", (ge(2), le(1000)), ""An integer in [2, 1000]"", int\n    )\n    enc0_vocab_size = hp(""enc0_vocab_size"", (ge(2), le(3000000)), ""An integer in [2, 3000000]"", int)\n    enc1_vocab_size = hp(""enc1_vocab_size"", (ge(2), le(3000000)), ""An integer in [2, 3000000]"", int)\n    enc0_layers = hp(""enc0_layers"", (ge(1), le(4)), ""An integer in [1, 4]"", int)\n    enc1_layers = hp(""enc1_layers"", (ge(1), le(4)), ""An integer in [1, 4]"", int)\n    enc0_freeze_pretrained_embedding = hp(\n        ""enc0_freeze_pretrained_embedding"", (), ""Either True or False"", bool\n    )\n    enc1_freeze_pretrained_embedding = hp(\n        ""enc1_freeze_pretrained_embedding"", (), ""Either True or False"", bool\n    )\n\n    def __init__(\n        self,\n        role,\n        train_instance_count,\n        train_instance_type,\n        epochs,\n        enc0_max_seq_len,\n        enc0_vocab_size,\n        enc_dim=None,\n        mini_batch_size=None,\n        early_stopping_patience=None,\n        early_stopping_tolerance=None,\n        dropout=None,\n        weight_decay=None,\n        bucket_width=None,\n        num_classes=None,\n        mlp_layers=None,\n        mlp_dim=None,\n        mlp_activation=None,\n        output_layer=None,\n        optimizer=None,\n        learning_rate=None,\n        negative_sampling_rate=None,\n        comparator_list=None,\n        tied_token_embedding_weight=None,\n        token_embedding_storage_type=None,\n        enc0_network=None,\n        enc1_network=None,\n        enc0_cnn_filter_width=None,\n        enc1_cnn_filter_width=None,\n        enc1_max_seq_len=None,\n        enc0_token_embedding_dim=None,\n        enc1_token_embedding_dim=None,\n        enc1_vocab_size=None,\n        enc0_layers=None,\n        enc1_layers=None,\n        enc0_freeze_pretrained_embedding=None,\n        enc1_freeze_pretrained_embedding=None,\n        **kwargs\n    ):\n        """"""Object2Vec is :class:`Estimator` used for anomaly detection.\n\n        This Estimator may be fit via calls to\n        :meth:`~sagemaker.amazon.amazon_estimator.AmazonAlgorithmEstimatorBase.fit`.\n        There is an utility\n        :meth:`~sagemaker.amazon.amazon_estimator.AmazonAlgorithmEstimatorBase.record_set`\n        that can be used to upload data to S3 and creates\n        :class:`~sagemaker.amazon.amazon_estimator.RecordSet` to be passed to\n        the `fit` call.\n\n        After this Estimator is fit, model data is stored in S3. The model\n        may be deployed to an Amazon SageMaker Endpoint by invoking\n        :meth:`~sagemaker.amazon.estimator.EstimatorBase.deploy`. As well as\n        deploying an Endpoint, deploy returns a\n        :class:`~sagemaker.amazon.RealTimePredictor` object that can be used for\n        inference calls using the trained model hosted in the SageMaker\n        Endpoint.\n\n        Object2Vec Estimators can be configured by setting hyperparameters.\n        The available hyperparameters for Object2Vec are documented below.\n\n        For further information on the AWS Object2Vec algorithm, please\n        consult AWS technical documentation:\n        https://docs.aws.amazon.com/sagemaker/latest/dg/object2vec.html\n\n        Args:\n            role (str): An AWS IAM role (either name or full ARN). The Amazon\n                SageMaker training jobs and APIs that create Amazon SageMaker\n                endpoints use this role to access training data and model\n                artifacts. After the endpoint is created, the inference code\n                might use the IAM role, if accessing AWS resource.\n            train_instance_count (int): Number of Amazon EC2 instances to use\n                for training.\n            train_instance_type (str): Type of EC2 instance to use for training,\n                for example, \'ml.c4.xlarge\'.\n            epochs (int): Total number of epochs for SGD training\n            enc0_max_seq_len (int): Maximum sequence length\n            enc0_vocab_size (int): Vocabulary size of tokens\n            enc_dim (int): Optional. Dimension of the output of the embedding\n                layer\n            mini_batch_size (int): Optional. mini batch size for SGD training\n            early_stopping_patience (int): Optional. The allowed number of\n                consecutive epochs without improvement before early stopping is\n                applied\n            early_stopping_tolerance (float): Optional. The value used to\n                determine whether the algorithm has made improvement between two\n                consecutive epochs for early stopping\n            dropout (float): Optional. Dropout probability on network layers\n            weight_decay (float): Optional. Weight decay parameter during\n                optimization\n            bucket_width (int): Optional. The allowed difference between data\n                sequence length when bucketing is enabled\n            num_classes (int): Optional. Number of classes for classification\n                training (ignored for regression problems)\n            mlp_layers (int): Optional. Number of MLP layers in the network\n            mlp_dim (int): Optional. Dimension of the output of MLP layer\n            mlp_activation (str): Optional. Type of activation function for the\n                MLP layer\n            output_layer (str): Optional. Type of output layer\n            optimizer (str): Optional. Type of optimizer for training\n            learning_rate (float): Optional. Learning rate for SGD training\n            negative_sampling_rate (int): Optional. Negative sampling rate\n            comparator_list (str): Optional. Customization of comparator\n                operator\n            tied_token_embedding_weight (bool): Optional. Tying of token\n                embedding layer weight\n            token_embedding_storage_type (str): Optional. Type of token\n                embedding storage\n            enc0_network (str): Optional. Network model of encoder ""enc0""\n            enc1_network (str): Optional. Network model of encoder ""enc1""\n            enc0_cnn_filter_width (int): Optional. CNN filter width\n            enc1_cnn_filter_width (int): Optional. CNN filter width\n            enc1_max_seq_len (int): Optional. Maximum sequence length\n            enc0_token_embedding_dim (int): Optional. Output dimension of token\n                embedding layer\n            enc1_token_embedding_dim (int): Optional. Output dimension of token\n                embedding layer\n            enc1_vocab_size (int): Optional. Vocabulary size of tokens\n            enc0_layers (int): Optional. Number of layers in encoder\n            enc1_layers (int): Optional. Number of layers in encoder\n            enc0_freeze_pretrained_embedding (bool): Optional. Freeze pretrained\n                embedding weights\n            enc1_freeze_pretrained_embedding (bool): Optional. Freeze pretrained\n                embedding weights\n            **kwargs: base class keyword argument values.\n\n        .. tip::\n\n            You can find additional parameters for initializing this class at\n            :class:`~sagemaker.estimator.amazon_estimator.AmazonAlgorithmEstimatorBase` and\n            :class:`~sagemaker.estimator.EstimatorBase`.\n        """"""\n\n        super(Object2Vec, self).__init__(role, train_instance_count, train_instance_type, **kwargs)\n\n        self.enc_dim = enc_dim\n        self.mini_batch_size = mini_batch_size\n        self.epochs = epochs\n        self.early_stopping_patience = early_stopping_patience\n        self.early_stopping_tolerance = early_stopping_tolerance\n        self.dropout = dropout\n        self.weight_decay = weight_decay\n        self.bucket_width = bucket_width\n        self.num_classes = num_classes\n        self.mlp_layers = mlp_layers\n        self.mlp_dim = mlp_dim\n        self.mlp_activation = mlp_activation\n        self.output_layer = output_layer\n        self.optimizer = optimizer\n        self.learning_rate = learning_rate\n\n        self.negative_sampling_rate = negative_sampling_rate\n        self.comparator_list = comparator_list\n        self.tied_token_embedding_weight = tied_token_embedding_weight\n        self.token_embedding_storage_type = token_embedding_storage_type\n\n        self.enc0_network = enc0_network\n        self.enc1_network = enc1_network\n        self.enc0_cnn_filter_width = enc0_cnn_filter_width\n        self.enc1_cnn_filter_width = enc1_cnn_filter_width\n        self.enc0_max_seq_len = enc0_max_seq_len\n        self.enc1_max_seq_len = enc1_max_seq_len\n        self.enc0_token_embedding_dim = enc0_token_embedding_dim\n        self.enc1_token_embedding_dim = enc1_token_embedding_dim\n        self.enc0_vocab_size = enc0_vocab_size\n        self.enc1_vocab_size = enc1_vocab_size\n        self.enc0_layers = enc0_layers\n        self.enc1_layers = enc1_layers\n        self.enc0_freeze_pretrained_embedding = enc0_freeze_pretrained_embedding\n        self.enc1_freeze_pretrained_embedding = enc1_freeze_pretrained_embedding\n\n    def create_model(self, vpc_config_override=VPC_CONFIG_DEFAULT, **kwargs):\n        """"""Return a :class:`~sagemaker.amazon.Object2VecModel` referencing the\n        latest s3 model data produced by this Estimator.\n\n        Args:\n            vpc_config_override (dict[str, list[str]]): Optional override for VpcConfig set on\n                the model. Default: use subnets and security groups from this Estimator.\n                * \'Subnets\' (list[str]): List of subnet ids.\n                * \'SecurityGroupIds\' (list[str]): List of security group ids.\n            **kwargs: Additional kwargs passed to the Object2VecModel constructor.\n        """"""\n        return Object2VecModel(\n            self.model_data,\n            self.role,\n            sagemaker_session=self.sagemaker_session,\n            vpc_config=self.get_vpc_config(vpc_config_override),\n            **kwargs\n        )\n\n    def _prepare_for_training(self, records, mini_batch_size=None, job_name=None):\n        """"""\n        Args:\n            records:\n            mini_batch_size:\n            job_name:\n        """"""\n        if mini_batch_size is None:\n            mini_batch_size = self.MINI_BATCH_SIZE\n\n        super(Object2Vec, self)._prepare_for_training(\n            records, mini_batch_size=mini_batch_size, job_name=job_name\n        )\n\n\nclass Object2VecModel(Model):\n    """"""Reference Object2Vec s3 model data. Calling\n    :meth:`~sagemaker.model.Model.deploy` creates an Endpoint and returns a\n    Predictor that calculates anomaly scores for datapoints.\n    """"""\n\n    def __init__(self, model_data, role, sagemaker_session=None, **kwargs):\n        """"""\n        Args:\n            model_data:\n            role:\n            sagemaker_session:\n            **kwargs:\n        """"""\n        sagemaker_session = sagemaker_session or Session()\n        repo = ""{}:{}"".format(Object2Vec.repo_name, Object2Vec.repo_version)\n        image = ""{}/{}"".format(\n            registry(sagemaker_session.boto_session.region_name, Object2Vec.repo_name), repo\n        )\n        super(Object2VecModel, self).__init__(\n            model_data,\n            image,\n            role,\n            predictor_cls=RealTimePredictor,\n            sagemaker_session=sagemaker_session,\n            **kwargs\n        )\n'"
src/sagemaker/amazon/pca.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nfrom sagemaker.amazon.amazon_estimator import AmazonAlgorithmEstimatorBase, registry\nfrom sagemaker.amazon.common import numpy_to_record_serializer, record_deserializer\nfrom sagemaker.amazon.hyperparameter import Hyperparameter as hp  # noqa\nfrom sagemaker.amazon.validation import gt, isin\nfrom sagemaker.predictor import RealTimePredictor\nfrom sagemaker.model import Model\nfrom sagemaker.session import Session\nfrom sagemaker.vpc_utils import VPC_CONFIG_DEFAULT\n\n\nclass PCA(AmazonAlgorithmEstimatorBase):\n    """"""Placeholder docstring""""""\n\n    repo_name = ""pca""\n    repo_version = 1\n\n    DEFAULT_MINI_BATCH_SIZE = 500\n\n    num_components = hp(""num_components"", gt(0), ""Value must be an integer greater than zero"", int)\n    algorithm_mode = hp(\n        ""algorithm_mode"",\n        isin(""regular"", ""randomized""),\n        \'Value must be one of ""regular"" and ""randomized""\',\n        str,\n    )\n    subtract_mean = hp(\n        name=""subtract_mean"", validation_message=""Value must be a boolean"", data_type=bool\n    )\n    extra_components = hp(\n        name=""extra_components"",\n        validation_message=""Value must be an integer greater than or equal to 0, or -1."",\n        data_type=int,\n    )\n\n    def __init__(\n        self,\n        role,\n        train_instance_count,\n        train_instance_type,\n        num_components,\n        algorithm_mode=None,\n        subtract_mean=None,\n        extra_components=None,\n        **kwargs\n    ):\n        """"""A Principal Components Analysis (PCA)\n        :class:`~sagemaker.amazon.amazon_estimator.AmazonAlgorithmEstimatorBase`.\n\n        This Estimator may be fit via calls to\n        :meth:`~sagemaker.amazon.amazon_estimator.AmazonAlgorithmEstimatorBase.fit_ndarray`\n        or\n        :meth:`~sagemaker.amazon.amazon_estimator.AmazonAlgorithmEstimatorBase.fit`.\n        The former allows a PCA model to be fit on a 2-dimensional numpy array.\n        The latter requires Amazon :class:`~sagemaker.amazon.record_pb2.Record`\n        protobuf serialized data to be stored in S3.\n\n        To learn more about the Amazon protobuf Record class and how to\n        prepare bulk data in this format, please consult AWS technical\n        documentation:\n        https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-training.html\n\n        After this Estimator is fit, model data is stored in S3. The model\n        may be deployed to an Amazon SageMaker Endpoint by invoking\n        :meth:`~sagemaker.amazon.estimator.EstimatorBase.deploy`. As well as\n        deploying an Endpoint, deploy returns a\n        :class:`~sagemaker.amazon.pca.PCAPredictor` object that can be used to\n        project input vectors to the learned lower-dimensional representation,\n        using the trained PCA model hosted in the SageMaker Endpoint.\n\n        PCA Estimators can be configured by setting hyperparameters. The\n        available hyperparameters for PCA are documented below. For further\n        information on the AWS PCA algorithm, please consult AWS technical\n        documentation: https://docs.aws.amazon.com/sagemaker/latest/dg/pca.html\n\n        This Estimator uses Amazon SageMaker PCA to perform training and host\n        deployed models. To learn more about Amazon SageMaker PCA, please read:\n        https://docs.aws.amazon.com/sagemaker/latest/dg/how-pca-works.html\n\n        Args:\n            role (str): An AWS IAM role (either name or full ARN). The Amazon\n                SageMaker training jobs and APIs that create Amazon SageMaker\n                endpoints use this role to access training data and model\n                artifacts. After the endpoint is created, the inference code\n                might use the IAM role, if accessing AWS resource.\n            train_instance_count (int): Number of Amazon EC2 instances to use\n                for training.\n            train_instance_type (str): Type of EC2 instance to use for training,\n                for example, \'ml.c4.xlarge\'.\n            num_components (int): The number of principal components. Must be\n                greater than zero.\n            algorithm_mode (str): Mode for computing the principal components.\n                One of \'regular\' or \'randomized\'.\n            subtract_mean (bool): Whether the data should be unbiased both\n                during train and at inference.\n            extra_components (int): As the value grows larger, the solution\n                becomes more accurate but the runtime and memory consumption\n                increase linearly. If this value is unset or set to -1, then a\n                default value equal to the maximum of 10 and num_components will\n                be used. Valid for randomized mode only.\n            **kwargs: base class keyword argument values.\n\n        .. tip::\n\n            You can find additional parameters for initializing this class at\n            :class:`~sagemaker.estimator.amazon_estimator.AmazonAlgorithmEstimatorBase` and\n            :class:`~sagemaker.estimator.EstimatorBase`.\n        """"""\n        super(PCA, self).__init__(role, train_instance_count, train_instance_type, **kwargs)\n        self.num_components = num_components\n        self.algorithm_mode = algorithm_mode\n        self.subtract_mean = subtract_mean\n        self.extra_components = extra_components\n\n    def create_model(self, vpc_config_override=VPC_CONFIG_DEFAULT, **kwargs):\n        """"""Return a :class:`~sagemaker.amazon.pca.PCAModel` referencing the\n        latest s3 model data produced by this Estimator.\n\n        Args:\n            vpc_config_override (dict[str, list[str]]): Optional override for VpcConfig set on\n                the model. Default: use subnets and security groups from this Estimator.\n                * \'Subnets\' (list[str]): List of subnet ids.\n                * \'SecurityGroupIds\' (list[str]): List of security group ids.\n            **kwargs: Additional kwargs passed to the PCAModel constructor.\n        """"""\n        return PCAModel(\n            self.model_data,\n            self.role,\n            sagemaker_session=self.sagemaker_session,\n            vpc_config=self.get_vpc_config(vpc_config_override),\n            **kwargs\n        )\n\n    def _prepare_for_training(self, records, mini_batch_size=None, job_name=None):\n        """"""Set hyperparameters needed for training.\n\n        Args:\n            records (:class:`~RecordSet`): The records to train this ``Estimator`` on.\n            mini_batch_size (int or None): The size of each mini-batch to use when\n                training. If ``None``, a default value will be used.\n            job_name (str): Name of the training job to be created. If not\n                specified, one is generated, using the base name given to the\n                constructor if applicable.\n        """"""\n        num_records = None\n        if isinstance(records, list):\n            for record in records:\n                if record.channel == ""train"":\n                    num_records = record.num_records\n                    break\n            if num_records is None:\n                raise ValueError(""Must provide train channel."")\n        else:\n            num_records = records.num_records\n\n        # mini_batch_size is a required parameter\n        default_mini_batch_size = min(\n            self.DEFAULT_MINI_BATCH_SIZE, max(1, int(num_records / self.train_instance_count))\n        )\n        use_mini_batch_size = mini_batch_size or default_mini_batch_size\n\n        super(PCA, self)._prepare_for_training(\n            records=records, mini_batch_size=use_mini_batch_size, job_name=job_name\n        )\n\n\nclass PCAPredictor(RealTimePredictor):\n    """"""Transforms input vectors to lower-dimesional representations.\n\n    The implementation of\n    :meth:`~sagemaker.predictor.RealTimePredictor.predict` in this\n    `RealTimePredictor` requires a numpy ``ndarray`` as input. The array should\n    contain the same number of columns as the feature-dimension of the data used\n    to fit the model this Predictor performs inference on.\n\n    :meth:`predict()` returns a list of\n    :class:`~sagemaker.amazon.record_pb2.Record` objects, one for each row in\n    the input ``ndarray``. The lower dimension vector result is stored in the\n    ``projection`` key of the ``Record.label`` field.\n    """"""\n\n    def __init__(self, endpoint, sagemaker_session=None):\n        """"""\n        Args:\n            endpoint:\n            sagemaker_session:\n        """"""\n        super(PCAPredictor, self).__init__(\n            endpoint,\n            sagemaker_session,\n            serializer=numpy_to_record_serializer(),\n            deserializer=record_deserializer(),\n        )\n\n\nclass PCAModel(Model):\n    """"""Reference PCA s3 model data. Calling\n    :meth:`~sagemaker.model.Model.deploy` creates an Endpoint and return a\n    Predictor that transforms vectors to a lower-dimensional representation.\n    """"""\n\n    def __init__(self, model_data, role, sagemaker_session=None, **kwargs):\n        """"""\n        Args:\n            model_data:\n            role:\n            sagemaker_session:\n            **kwargs:\n        """"""\n        sagemaker_session = sagemaker_session or Session()\n        repo = ""{}:{}"".format(PCA.repo_name, PCA.repo_version)\n        image = ""{}/{}"".format(registry(sagemaker_session.boto_session.region_name), repo)\n        super(PCAModel, self).__init__(\n            model_data,\n            image,\n            role,\n            predictor_cls=PCAPredictor,\n            sagemaker_session=sagemaker_session,\n            **kwargs\n        )\n'"
src/sagemaker/amazon/randomcutforest.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nfrom sagemaker.amazon.amazon_estimator import AmazonAlgorithmEstimatorBase, registry\nfrom sagemaker.amazon.common import numpy_to_record_serializer, record_deserializer\nfrom sagemaker.amazon.hyperparameter import Hyperparameter as hp  # noqa\nfrom sagemaker.amazon.validation import ge, le\nfrom sagemaker.predictor import RealTimePredictor\nfrom sagemaker.model import Model\nfrom sagemaker.session import Session\nfrom sagemaker.vpc_utils import VPC_CONFIG_DEFAULT\n\n\nclass RandomCutForest(AmazonAlgorithmEstimatorBase):\n    """"""Placeholder docstring""""""\n\n    repo_name = ""randomcutforest""\n    repo_version = 1\n    MINI_BATCH_SIZE = 1000\n\n    eval_metrics = hp(\n        name=""eval_metrics"",\n        validation_message=\'A comma separated list of ""accuracy"" or ""precision_recall_fscore""\',\n        data_type=list,\n    )\n\n    num_trees = hp(""num_trees"", (ge(50), le(1000)), ""An integer in [50, 1000]"", int)\n    num_samples_per_tree = hp(\n        ""num_samples_per_tree"", (ge(1), le(2048)), ""An integer in [1, 2048]"", int\n    )\n    feature_dim = hp(""feature_dim"", (ge(1), le(10000)), ""An integer in [1, 10000]"", int)\n\n    def __init__(\n        self,\n        role,\n        train_instance_count,\n        train_instance_type,\n        num_samples_per_tree=None,\n        num_trees=None,\n        eval_metrics=None,\n        **kwargs\n    ):\n        """"""RandomCutForest is :class:`Estimator` used for anomaly detection.\n\n        This Estimator may be fit via calls to\n        :meth:`~sagemaker.amazon.amazon_estimator.AmazonAlgorithmEstimatorBase.fit`.\n        It requires Amazon :class:`~sagemaker.amazon.record_pb2.Record` protobuf\n        serialized data to be stored in S3. There is an utility\n        :meth:`~sagemaker.amazon.amazon_estimator.AmazonAlgorithmEstimatorBase.record_set`\n        that can be used to upload data to S3 and creates\n        :class:`~sagemaker.amazon.amazon_estimator.RecordSet` to be passed to\n        the `fit` call.\n\n        To learn more about the Amazon protobuf Record class and how to\n        prepare bulk data in this format, please consult AWS technical\n        documentation:\n        https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-training.html\n\n        After this Estimator is fit, model data is stored in S3. The model\n        may be deployed to an Amazon SageMaker Endpoint by invoking\n        :meth:`~sagemaker.amazon.estimator.EstimatorBase.deploy`. As well as\n        deploying an Endpoint, deploy returns a\n        :class:`~sagemaker.amazon.ntm.RandomCutForestPredictor` object that can\n        be used for inference calls using the trained model hosted in the\n        SageMaker Endpoint.\n\n        RandomCutForest Estimators can be configured by setting\n        hyperparameters. The available hyperparameters for RandomCutForest are\n        documented below.\n\n        For further information on the AWS Random Cut Forest algorithm,\n        please consult AWS technical documentation:\n        https://docs.aws.amazon.com/sagemaker/latest/dg/randomcutforest.html\n\n        Args:\n            role (str): An AWS IAM role (either name or full ARN). The Amazon\n                SageMaker training jobs and APIs that create Amazon SageMaker\n                endpoints use this role to access training data and model\n                artifacts. After the endpoint is created, the inference code\n                might use the IAM role, if accessing AWS resource.\n            train_instance_count (int): Number of Amazon EC2 instances to use\n                for training.\n            train_instance_type (str): Type of EC2 instance to use for training,\n                for example, \'ml.c4.xlarge\'.\n            num_samples_per_tree (int): Optional. The number of samples used to\n                build each tree in the forest. The total number of samples drawn\n                from the train dataset is num_trees * num_samples_per_tree.\n            num_trees (int): Optional. The number of trees used in the forest.\n            eval_metrics (list): Optional. JSON list of metrics types to be used\n                for reporting the score for the model. Allowed values are\n                ""accuracy"", ""precision_recall_fscore"": positive and negative\n                precision, recall, and f1 scores. If test data is provided, the\n                score shall be reported in terms of all requested metrics.\n            **kwargs: base class keyword argument values.\n\n        .. tip::\n\n            You can find additional parameters for initializing this class at\n            :class:`~sagemaker.estimator.amazon_estimator.AmazonAlgorithmEstimatorBase` and\n            :class:`~sagemaker.estimator.EstimatorBase`.\n        """"""\n\n        super(RandomCutForest, self).__init__(\n            role, train_instance_count, train_instance_type, **kwargs\n        )\n        self.num_samples_per_tree = num_samples_per_tree\n        self.num_trees = num_trees\n        self.eval_metrics = eval_metrics\n\n    def create_model(self, vpc_config_override=VPC_CONFIG_DEFAULT, **kwargs):\n        """"""Return a :class:`~sagemaker.amazon.RandomCutForestModel` referencing\n        the latest s3 model data produced by this Estimator.\n\n        Args:\n            vpc_config_override (dict[str, list[str]]): Optional override for VpcConfig set on\n                the model. Default: use subnets and security groups from this Estimator.\n                * \'Subnets\' (list[str]): List of subnet ids.\n                * \'SecurityGroupIds\' (list[str]): List of security group ids.\n            **kwargs: Additional kwargs passed to the RandomCutForestModel constructor.\n        """"""\n        return RandomCutForestModel(\n            self.model_data,\n            self.role,\n            sagemaker_session=self.sagemaker_session,\n            vpc_config=self.get_vpc_config(vpc_config_override),\n            **kwargs\n        )\n\n    def _prepare_for_training(self, records, mini_batch_size=None, job_name=None):\n        """"""\n        Args:\n            records:\n            mini_batch_size:\n            job_name:\n        """"""\n        if mini_batch_size is None:\n            mini_batch_size = self.MINI_BATCH_SIZE\n        elif mini_batch_size != self.MINI_BATCH_SIZE:\n            raise ValueError(\n                ""Random Cut Forest uses a fixed mini_batch_size of {}"".format(self.MINI_BATCH_SIZE)\n            )\n\n        super(RandomCutForest, self)._prepare_for_training(\n            records, mini_batch_size=mini_batch_size, job_name=job_name\n        )\n\n\nclass RandomCutForestPredictor(RealTimePredictor):\n    """"""Assigns an anomaly score to each of the datapoints provided.\n\n    The implementation of\n    :meth:`~sagemaker.predictor.RealTimePredictor.predict` in this\n    `RealTimePredictor` requires a numpy ``ndarray`` as input. The array should\n    contain the same number of columns as the feature-dimension of the data used\n    to fit the model this Predictor performs inference on.\n\n    :meth:`predict()` returns a list of\n    :class:`~sagemaker.amazon.record_pb2.Record` objects, one for each row in\n    the input. Each row\'s score is stored in the key ``score`` of the\n    ``Record.label`` field.\n    """"""\n\n    def __init__(self, endpoint, sagemaker_session=None):\n        """"""\n        Args:\n            endpoint:\n            sagemaker_session:\n        """"""\n        super(RandomCutForestPredictor, self).__init__(\n            endpoint,\n            sagemaker_session,\n            serializer=numpy_to_record_serializer(),\n            deserializer=record_deserializer(),\n        )\n\n\nclass RandomCutForestModel(Model):\n    """"""Reference RandomCutForest s3 model data. Calling\n    :meth:`~sagemaker.model.Model.deploy` creates an Endpoint and returns a\n    Predictor that calculates anomaly scores for datapoints.\n    """"""\n\n    def __init__(self, model_data, role, sagemaker_session=None, **kwargs):\n        """"""\n        Args:\n            model_data:\n            role:\n            sagemaker_session:\n            **kwargs:\n        """"""\n        sagemaker_session = sagemaker_session or Session()\n        repo = ""{}:{}"".format(RandomCutForest.repo_name, RandomCutForest.repo_version)\n        image = ""{}/{}"".format(\n            registry(sagemaker_session.boto_session.region_name, RandomCutForest.repo_name), repo\n        )\n        super(RandomCutForestModel, self).__init__(\n            model_data,\n            image,\n            role,\n            predictor_cls=RandomCutForestPredictor,\n            sagemaker_session=sagemaker_session,\n            **kwargs\n        )\n'"
src/sagemaker/amazon/record_pb2.py,0,"b'# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: record.proto\n\nimport sys\n\nfrom google.protobuf import descriptor as _descriptor\nfrom google.protobuf import message as _message\nfrom google.protobuf import reflection as _reflection\nfrom google.protobuf import symbol_database as _symbol_database\nfrom google.protobuf import descriptor_pb2\n\n_b = sys.version_info[0] < 3 and (lambda x: x) or (lambda x: x.encode(""latin1""))\n\n# @@protoc_insertion_point(imports)\n\n_sym_db = _symbol_database.Default()\n\n\nDESCRIPTOR = _descriptor.FileDescriptor(\n    name=""record.proto"",\n    package=""aialgs.data"",\n    syntax=""proto2"",\n    serialized_pb=_b(\n        \'\\n\\x0crecord.proto\\x12\\x0b\\x61ialgs.data""H\\n\\rFloat32Tensor\\x12\\x12\\n\\x06values\\x18\\x01 \\x03(\\x02\\x42\\x02\\x10\\x01\\x12\\x10\\n\\x04keys\\x18\\x02 \\x03(\\x04\\x42\\x02\\x10\\x01\\x12\\x11\\n\\x05shape\\x18\\x03 \\x03(\\x04\\x42\\x02\\x10\\x01""H\\n\\rFloat64Tensor\\x12\\x12\\n\\x06values\\x18\\x01 \\x03(\\x01\\x42\\x02\\x10\\x01\\x12\\x10\\n\\x04keys\\x18\\x02 \\x03(\\x04\\x42\\x02\\x10\\x01\\x12\\x11\\n\\x05shape\\x18\\x03 \\x03(\\x04\\x42\\x02\\x10\\x01""F\\n\\x0bInt32Tensor\\x12\\x12\\n\\x06values\\x18\\x01 \\x03(\\x05\\x42\\x02\\x10\\x01\\x12\\x10\\n\\x04keys\\x18\\x02 \\x03(\\x04\\x42\\x02\\x10\\x01\\x12\\x11\\n\\x05shape\\x18\\x03 \\x03(\\x04\\x42\\x02\\x10\\x01"",\\n\\x05\\x42ytes\\x12\\r\\n\\x05value\\x18\\x01 \\x03(\\x0c\\x12\\x14\\n\\x0c\\x63ontent_type\\x18\\x02 \\x01(\\t""\\xd3\\x01\\n\\x05Value\\x12\\x34\\n\\x0e\\x66loat32_tensor\\x18\\x02 \\x01(\\x0b\\x32\\x1a.aialgs.data.Float32TensorH\\x00\\x12\\x34\\n\\x0e\\x66loat64_tensor\\x18\\x03 \\x01(\\x0b\\x32\\x1a.aialgs.data.Float64TensorH\\x00\\x12\\x30\\n\\x0cint32_tensor\\x18\\x07 \\x01(\\x0b\\x32\\x18.aialgs.data.Int32TensorH\\x00\\x12#\\n\\x05\\x62ytes\\x18\\t \\x01(\\x0b\\x32\\x12.aialgs.data.BytesH\\x00\\x42\\x07\\n\\x05value""\\xa9\\x02\\n\\x06Record\\x12\\x33\\n\\x08\\x66\\x65\\x61tures\\x18\\x01 \\x03(\\x0b\\x32!.aialgs.data.Record.FeaturesEntry\\x12-\\n\\x05label\\x18\\x02 \\x03(\\x0b\\x32\\x1e.aialgs.data.Record.LabelEntry\\x12\\x0b\\n\\x03uid\\x18\\x03 \\x01(\\t\\x12\\x10\\n\\x08metadata\\x18\\x04 \\x01(\\t\\x12\\x15\\n\\rconfiguration\\x18\\x05 \\x01(\\t\\x1a\\x43\\n\\rFeaturesEntry\\x12\\x0b\\n\\x03key\\x18\\x01 \\x01(\\t\\x12!\\n\\x05value\\x18\\x02 \\x01(\\x0b\\x32\\x12.aialgs.data.Value:\\x02\\x38\\x01\\x1a@\\n\\nLabelEntry\\x12\\x0b\\n\\x03key\\x18\\x01 \\x01(\\t\\x12!\\n\\x05value\\x18\\x02 \\x01(\\x0b\\x32\\x12.aialgs.data.Value:\\x02\\x38\\x01\\x42\\x30\\n com.amazonaws.aialgorithms.protoB\\x0cRecordProtos\'\n    ),\n)\n\n\n_FLOAT32TENSOR = _descriptor.Descriptor(\n    name=""Float32Tensor"",\n    full_name=""aialgs.data.Float32Tensor"",\n    filename=None,\n    file=DESCRIPTOR,\n    containing_type=None,\n    fields=[\n        _descriptor.FieldDescriptor(\n            name=""values"",\n            full_name=""aialgs.data.Float32Tensor.values"",\n            index=0,\n            number=1,\n            type=2,\n            cpp_type=6,\n            label=3,\n            has_default_value=False,\n            default_value=[],\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(""\\020\\001"")),\n            file=DESCRIPTOR,\n        ),\n        _descriptor.FieldDescriptor(\n            name=""keys"",\n            full_name=""aialgs.data.Float32Tensor.keys"",\n            index=1,\n            number=2,\n            type=4,\n            cpp_type=4,\n            label=3,\n            has_default_value=False,\n            default_value=[],\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(""\\020\\001"")),\n            file=DESCRIPTOR,\n        ),\n        _descriptor.FieldDescriptor(\n            name=""shape"",\n            full_name=""aialgs.data.Float32Tensor.shape"",\n            index=2,\n            number=3,\n            type=4,\n            cpp_type=4,\n            label=3,\n            has_default_value=False,\n            default_value=[],\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(""\\020\\001"")),\n            file=DESCRIPTOR,\n        ),\n    ],\n    extensions=[],\n    nested_types=[],\n    enum_types=[],\n    options=None,\n    is_extendable=False,\n    syntax=""proto2"",\n    extension_ranges=[],\n    oneofs=[],\n    serialized_start=29,\n    serialized_end=101,\n)\n\n\n_FLOAT64TENSOR = _descriptor.Descriptor(\n    name=""Float64Tensor"",\n    full_name=""aialgs.data.Float64Tensor"",\n    filename=None,\n    file=DESCRIPTOR,\n    containing_type=None,\n    fields=[\n        _descriptor.FieldDescriptor(\n            name=""values"",\n            full_name=""aialgs.data.Float64Tensor.values"",\n            index=0,\n            number=1,\n            type=1,\n            cpp_type=5,\n            label=3,\n            has_default_value=False,\n            default_value=[],\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(""\\020\\001"")),\n            file=DESCRIPTOR,\n        ),\n        _descriptor.FieldDescriptor(\n            name=""keys"",\n            full_name=""aialgs.data.Float64Tensor.keys"",\n            index=1,\n            number=2,\n            type=4,\n            cpp_type=4,\n            label=3,\n            has_default_value=False,\n            default_value=[],\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(""\\020\\001"")),\n            file=DESCRIPTOR,\n        ),\n        _descriptor.FieldDescriptor(\n            name=""shape"",\n            full_name=""aialgs.data.Float64Tensor.shape"",\n            index=2,\n            number=3,\n            type=4,\n            cpp_type=4,\n            label=3,\n            has_default_value=False,\n            default_value=[],\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(""\\020\\001"")),\n            file=DESCRIPTOR,\n        ),\n    ],\n    extensions=[],\n    nested_types=[],\n    enum_types=[],\n    options=None,\n    is_extendable=False,\n    syntax=""proto2"",\n    extension_ranges=[],\n    oneofs=[],\n    serialized_start=103,\n    serialized_end=175,\n)\n\n\n_INT32TENSOR = _descriptor.Descriptor(\n    name=""Int32Tensor"",\n    full_name=""aialgs.data.Int32Tensor"",\n    filename=None,\n    file=DESCRIPTOR,\n    containing_type=None,\n    fields=[\n        _descriptor.FieldDescriptor(\n            name=""values"",\n            full_name=""aialgs.data.Int32Tensor.values"",\n            index=0,\n            number=1,\n            type=5,\n            cpp_type=1,\n            label=3,\n            has_default_value=False,\n            default_value=[],\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(""\\020\\001"")),\n            file=DESCRIPTOR,\n        ),\n        _descriptor.FieldDescriptor(\n            name=""keys"",\n            full_name=""aialgs.data.Int32Tensor.keys"",\n            index=1,\n            number=2,\n            type=4,\n            cpp_type=4,\n            label=3,\n            has_default_value=False,\n            default_value=[],\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(""\\020\\001"")),\n            file=DESCRIPTOR,\n        ),\n        _descriptor.FieldDescriptor(\n            name=""shape"",\n            full_name=""aialgs.data.Int32Tensor.shape"",\n            index=2,\n            number=3,\n            type=4,\n            cpp_type=4,\n            label=3,\n            has_default_value=False,\n            default_value=[],\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(""\\020\\001"")),\n            file=DESCRIPTOR,\n        ),\n    ],\n    extensions=[],\n    nested_types=[],\n    enum_types=[],\n    options=None,\n    is_extendable=False,\n    syntax=""proto2"",\n    extension_ranges=[],\n    oneofs=[],\n    serialized_start=177,\n    serialized_end=247,\n)\n\n\n_BYTES = _descriptor.Descriptor(\n    name=""Bytes"",\n    full_name=""aialgs.data.Bytes"",\n    filename=None,\n    file=DESCRIPTOR,\n    containing_type=None,\n    fields=[\n        _descriptor.FieldDescriptor(\n            name=""value"",\n            full_name=""aialgs.data.Bytes.value"",\n            index=0,\n            number=1,\n            type=12,\n            cpp_type=9,\n            label=3,\n            has_default_value=False,\n            default_value=[],\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n        _descriptor.FieldDescriptor(\n            name=""content_type"",\n            full_name=""aialgs.data.Bytes.content_type"",\n            index=1,\n            number=2,\n            type=9,\n            cpp_type=9,\n            label=1,\n            has_default_value=False,\n            default_value=_b("""").decode(""utf-8""),\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n    ],\n    extensions=[],\n    nested_types=[],\n    enum_types=[],\n    options=None,\n    is_extendable=False,\n    syntax=""proto2"",\n    extension_ranges=[],\n    oneofs=[],\n    serialized_start=249,\n    serialized_end=293,\n)\n\n\n_VALUE = _descriptor.Descriptor(\n    name=""Value"",\n    full_name=""aialgs.data.Value"",\n    filename=None,\n    file=DESCRIPTOR,\n    containing_type=None,\n    fields=[\n        _descriptor.FieldDescriptor(\n            name=""float32_tensor"",\n            full_name=""aialgs.data.Value.float32_tensor"",\n            index=0,\n            number=2,\n            type=11,\n            cpp_type=10,\n            label=1,\n            has_default_value=False,\n            default_value=None,\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n        _descriptor.FieldDescriptor(\n            name=""float64_tensor"",\n            full_name=""aialgs.data.Value.float64_tensor"",\n            index=1,\n            number=3,\n            type=11,\n            cpp_type=10,\n            label=1,\n            has_default_value=False,\n            default_value=None,\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n        _descriptor.FieldDescriptor(\n            name=""int32_tensor"",\n            full_name=""aialgs.data.Value.int32_tensor"",\n            index=2,\n            number=7,\n            type=11,\n            cpp_type=10,\n            label=1,\n            has_default_value=False,\n            default_value=None,\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n        _descriptor.FieldDescriptor(\n            name=""bytes"",\n            full_name=""aialgs.data.Value.bytes"",\n            index=3,\n            number=9,\n            type=11,\n            cpp_type=10,\n            label=1,\n            has_default_value=False,\n            default_value=None,\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n    ],\n    extensions=[],\n    nested_types=[],\n    enum_types=[],\n    options=None,\n    is_extendable=False,\n    syntax=""proto2"",\n    extension_ranges=[],\n    oneofs=[\n        _descriptor.OneofDescriptor(\n            name=""value"",\n            full_name=""aialgs.data.Value.value"",\n            index=0,\n            containing_type=None,\n            fields=[],\n        )\n    ],\n    serialized_start=296,\n    serialized_end=507,\n)\n\n\n_RECORD_FEATURESENTRY = _descriptor.Descriptor(\n    name=""FeaturesEntry"",\n    full_name=""aialgs.data.Record.FeaturesEntry"",\n    filename=None,\n    file=DESCRIPTOR,\n    containing_type=None,\n    fields=[\n        _descriptor.FieldDescriptor(\n            name=""key"",\n            full_name=""aialgs.data.Record.FeaturesEntry.key"",\n            index=0,\n            number=1,\n            type=9,\n            cpp_type=9,\n            label=1,\n            has_default_value=False,\n            default_value=_b("""").decode(""utf-8""),\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n        _descriptor.FieldDescriptor(\n            name=""value"",\n            full_name=""aialgs.data.Record.FeaturesEntry.value"",\n            index=1,\n            number=2,\n            type=11,\n            cpp_type=10,\n            label=1,\n            has_default_value=False,\n            default_value=None,\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n    ],\n    extensions=[],\n    nested_types=[],\n    enum_types=[],\n    options=_descriptor._ParseOptions(descriptor_pb2.MessageOptions(), _b(""8\\001"")),\n    is_extendable=False,\n    syntax=""proto2"",\n    extension_ranges=[],\n    oneofs=[],\n    serialized_start=674,\n    serialized_end=741,\n)\n\n_RECORD_LABELENTRY = _descriptor.Descriptor(\n    name=""LabelEntry"",\n    full_name=""aialgs.data.Record.LabelEntry"",\n    filename=None,\n    file=DESCRIPTOR,\n    containing_type=None,\n    fields=[\n        _descriptor.FieldDescriptor(\n            name=""key"",\n            full_name=""aialgs.data.Record.LabelEntry.key"",\n            index=0,\n            number=1,\n            type=9,\n            cpp_type=9,\n            label=1,\n            has_default_value=False,\n            default_value=_b("""").decode(""utf-8""),\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n        _descriptor.FieldDescriptor(\n            name=""value"",\n            full_name=""aialgs.data.Record.LabelEntry.value"",\n            index=1,\n            number=2,\n            type=11,\n            cpp_type=10,\n            label=1,\n            has_default_value=False,\n            default_value=None,\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n    ],\n    extensions=[],\n    nested_types=[],\n    enum_types=[],\n    options=_descriptor._ParseOptions(descriptor_pb2.MessageOptions(), _b(""8\\001"")),\n    is_extendable=False,\n    syntax=""proto2"",\n    extension_ranges=[],\n    oneofs=[],\n    serialized_start=743,\n    serialized_end=807,\n)\n\n_RECORD = _descriptor.Descriptor(\n    name=""Record"",\n    full_name=""aialgs.data.Record"",\n    filename=None,\n    file=DESCRIPTOR,\n    containing_type=None,\n    fields=[\n        _descriptor.FieldDescriptor(\n            name=""features"",\n            full_name=""aialgs.data.Record.features"",\n            index=0,\n            number=1,\n            type=11,\n            cpp_type=10,\n            label=3,\n            has_default_value=False,\n            default_value=[],\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n        _descriptor.FieldDescriptor(\n            name=""label"",\n            full_name=""aialgs.data.Record.label"",\n            index=1,\n            number=2,\n            type=11,\n            cpp_type=10,\n            label=3,\n            has_default_value=False,\n            default_value=[],\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n        _descriptor.FieldDescriptor(\n            name=""uid"",\n            full_name=""aialgs.data.Record.uid"",\n            index=2,\n            number=3,\n            type=9,\n            cpp_type=9,\n            label=1,\n            has_default_value=False,\n            default_value=_b("""").decode(""utf-8""),\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n        _descriptor.FieldDescriptor(\n            name=""metadata"",\n            full_name=""aialgs.data.Record.metadata"",\n            index=3,\n            number=4,\n            type=9,\n            cpp_type=9,\n            label=1,\n            has_default_value=False,\n            default_value=_b("""").decode(""utf-8""),\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n        _descriptor.FieldDescriptor(\n            name=""configuration"",\n            full_name=""aialgs.data.Record.configuration"",\n            index=4,\n            number=5,\n            type=9,\n            cpp_type=9,\n            label=1,\n            has_default_value=False,\n            default_value=_b("""").decode(""utf-8""),\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n    ],\n    extensions=[],\n    nested_types=[_RECORD_FEATURESENTRY, _RECORD_LABELENTRY],\n    enum_types=[],\n    options=None,\n    is_extendable=False,\n    syntax=""proto2"",\n    extension_ranges=[],\n    oneofs=[],\n    serialized_start=510,\n    serialized_end=807,\n)\n\n_VALUE.fields_by_name[""float32_tensor""].message_type = _FLOAT32TENSOR\n_VALUE.fields_by_name[""float64_tensor""].message_type = _FLOAT64TENSOR\n_VALUE.fields_by_name[""int32_tensor""].message_type = _INT32TENSOR\n_VALUE.fields_by_name[""bytes""].message_type = _BYTES\n_VALUE.oneofs_by_name[""value""].fields.append(_VALUE.fields_by_name[""float32_tensor""])\n_VALUE.fields_by_name[""float32_tensor""].containing_oneof = _VALUE.oneofs_by_name[""value""]\n_VALUE.oneofs_by_name[""value""].fields.append(_VALUE.fields_by_name[""float64_tensor""])\n_VALUE.fields_by_name[""float64_tensor""].containing_oneof = _VALUE.oneofs_by_name[""value""]\n_VALUE.oneofs_by_name[""value""].fields.append(_VALUE.fields_by_name[""int32_tensor""])\n_VALUE.fields_by_name[""int32_tensor""].containing_oneof = _VALUE.oneofs_by_name[""value""]\n_VALUE.oneofs_by_name[""value""].fields.append(_VALUE.fields_by_name[""bytes""])\n_VALUE.fields_by_name[""bytes""].containing_oneof = _VALUE.oneofs_by_name[""value""]\n_RECORD_FEATURESENTRY.fields_by_name[""value""].message_type = _VALUE\n_RECORD_FEATURESENTRY.containing_type = _RECORD\n_RECORD_LABELENTRY.fields_by_name[""value""].message_type = _VALUE\n_RECORD_LABELENTRY.containing_type = _RECORD\n_RECORD.fields_by_name[""features""].message_type = _RECORD_FEATURESENTRY\n_RECORD.fields_by_name[""label""].message_type = _RECORD_LABELENTRY\nDESCRIPTOR.message_types_by_name[""Float32Tensor""] = _FLOAT32TENSOR\nDESCRIPTOR.message_types_by_name[""Float64Tensor""] = _FLOAT64TENSOR\nDESCRIPTOR.message_types_by_name[""Int32Tensor""] = _INT32TENSOR\nDESCRIPTOR.message_types_by_name[""Bytes""] = _BYTES\nDESCRIPTOR.message_types_by_name[""Value""] = _VALUE\nDESCRIPTOR.message_types_by_name[""Record""] = _RECORD\n_sym_db.RegisterFileDescriptor(DESCRIPTOR)\n\nFloat32Tensor = _reflection.GeneratedProtocolMessageType(\n    ""Float32Tensor"",\n    (_message.Message,),\n    dict(\n        DESCRIPTOR=_FLOAT32TENSOR,\n        __module__=""record_pb2""\n        # @@protoc_insertion_point(class_scope:aialgs.data.Float32Tensor)\n    ),\n)\n_sym_db.RegisterMessage(Float32Tensor)\n\nFloat64Tensor = _reflection.GeneratedProtocolMessageType(\n    ""Float64Tensor"",\n    (_message.Message,),\n    dict(\n        DESCRIPTOR=_FLOAT64TENSOR,\n        __module__=""record_pb2""\n        # @@protoc_insertion_point(class_scope:aialgs.data.Float64Tensor)\n    ),\n)\n_sym_db.RegisterMessage(Float64Tensor)\n\nInt32Tensor = _reflection.GeneratedProtocolMessageType(\n    ""Int32Tensor"",\n    (_message.Message,),\n    dict(\n        DESCRIPTOR=_INT32TENSOR,\n        __module__=""record_pb2""\n        # @@protoc_insertion_point(class_scope:aialgs.data.Int32Tensor)\n    ),\n)\n_sym_db.RegisterMessage(Int32Tensor)\n\nBytes = _reflection.GeneratedProtocolMessageType(\n    ""Bytes"",\n    (_message.Message,),\n    dict(\n        DESCRIPTOR=_BYTES,\n        __module__=""record_pb2""\n        # @@protoc_insertion_point(class_scope:aialgs.data.Bytes)\n    ),\n)\n_sym_db.RegisterMessage(Bytes)\n\nValue = _reflection.GeneratedProtocolMessageType(\n    ""Value"",\n    (_message.Message,),\n    dict(\n        DESCRIPTOR=_VALUE,\n        __module__=""record_pb2""\n        # @@protoc_insertion_point(class_scope:aialgs.data.Value)\n    ),\n)\n_sym_db.RegisterMessage(Value)\n\nRecord = _reflection.GeneratedProtocolMessageType(\n    ""Record"",\n    (_message.Message,),\n    dict(\n        FeaturesEntry=_reflection.GeneratedProtocolMessageType(\n            ""FeaturesEntry"",\n            (_message.Message,),\n            dict(\n                DESCRIPTOR=_RECORD_FEATURESENTRY,\n                __module__=""record_pb2""\n                # @@protoc_insertion_point(class_scope:aialgs.data.Record.FeaturesEntry)\n            ),\n        ),\n        LabelEntry=_reflection.GeneratedProtocolMessageType(\n            ""LabelEntry"",\n            (_message.Message,),\n            dict(\n                DESCRIPTOR=_RECORD_LABELENTRY,\n                __module__=""record_pb2""\n                # @@protoc_insertion_point(class_scope:aialgs.data.Record.LabelEntry)\n            ),\n        ),\n        DESCRIPTOR=_RECORD,\n        __module__=""record_pb2""\n        # @@protoc_insertion_point(class_scope:aialgs.data.Record)\n    ),\n)\n_sym_db.RegisterMessage(Record)\n_sym_db.RegisterMessage(Record.FeaturesEntry)\n_sym_db.RegisterMessage(Record.LabelEntry)\n\n\nDESCRIPTOR.has_options = True\nDESCRIPTOR._options = _descriptor._ParseOptions(\n    descriptor_pb2.FileOptions(), _b(""\\n com.amazonaws.aialgorithms.protoB\\014RecordProtos"")\n)\n_FLOAT32TENSOR.fields_by_name[""values""].has_options = True\n_FLOAT32TENSOR.fields_by_name[""values""]._options = _descriptor._ParseOptions(\n    descriptor_pb2.FieldOptions(), _b(""\\020\\001"")\n)\n_FLOAT32TENSOR.fields_by_name[""keys""].has_options = True\n_FLOAT32TENSOR.fields_by_name[""keys""]._options = _descriptor._ParseOptions(\n    descriptor_pb2.FieldOptions(), _b(""\\020\\001"")\n)\n_FLOAT32TENSOR.fields_by_name[""shape""].has_options = True\n_FLOAT32TENSOR.fields_by_name[""shape""]._options = _descriptor._ParseOptions(\n    descriptor_pb2.FieldOptions(), _b(""\\020\\001"")\n)\n_FLOAT64TENSOR.fields_by_name[""values""].has_options = True\n_FLOAT64TENSOR.fields_by_name[""values""]._options = _descriptor._ParseOptions(\n    descriptor_pb2.FieldOptions(), _b(""\\020\\001"")\n)\n_FLOAT64TENSOR.fields_by_name[""keys""].has_options = True\n_FLOAT64TENSOR.fields_by_name[""keys""]._options = _descriptor._ParseOptions(\n    descriptor_pb2.FieldOptions(), _b(""\\020\\001"")\n)\n_FLOAT64TENSOR.fields_by_name[""shape""].has_options = True\n_FLOAT64TENSOR.fields_by_name[""shape""]._options = _descriptor._ParseOptions(\n    descriptor_pb2.FieldOptions(), _b(""\\020\\001"")\n)\n_INT32TENSOR.fields_by_name[""values""].has_options = True\n_INT32TENSOR.fields_by_name[""values""]._options = _descriptor._ParseOptions(\n    descriptor_pb2.FieldOptions(), _b(""\\020\\001"")\n)\n_INT32TENSOR.fields_by_name[""keys""].has_options = True\n_INT32TENSOR.fields_by_name[""keys""]._options = _descriptor._ParseOptions(\n    descriptor_pb2.FieldOptions(), _b(""\\020\\001"")\n)\n_INT32TENSOR.fields_by_name[""shape""].has_options = True\n_INT32TENSOR.fields_by_name[""shape""]._options = _descriptor._ParseOptions(\n    descriptor_pb2.FieldOptions(), _b(""\\020\\001"")\n)\n_RECORD_FEATURESENTRY.has_options = True\n_RECORD_FEATURESENTRY._options = _descriptor._ParseOptions(\n    descriptor_pb2.MessageOptions(), _b(""8\\001"")\n)\n_RECORD_LABELENTRY.has_options = True\n_RECORD_LABELENTRY._options = _descriptor._ParseOptions(\n    descriptor_pb2.MessageOptions(), _b(""8\\001"")\n)\n# @@protoc_insertion_point(module_scope)\n'"
src/sagemaker/amazon/validation.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\n\ndef gt(minimum):\n    """"""\n    Args:\n        minimum:\n    """"""\n\n    def validate(value):\n        return value > minimum\n\n    return validate\n\n\ndef ge(minimum):\n    """"""\n    Args:\n        minimum:\n    """"""\n\n    def validate(value):\n        return value >= minimum\n\n    return validate\n\n\ndef lt(maximum):\n    """"""\n    Args:\n        maximum:\n    """"""\n\n    def validate(value):\n        return value < maximum\n\n    return validate\n\n\ndef le(maximum):\n    """"""\n    Args:\n        maximum:\n    """"""\n\n    def validate(value):\n        return value <= maximum\n\n    return validate\n\n\ndef isin(*expected):\n    """"""\n    Args:\n        *expected:\n    """"""\n\n    def validate(value):\n        return value in expected\n\n    return validate\n\n\ndef istype(expected):\n    """"""\n    Args:\n        expected:\n    """"""\n\n    def validate(value):\n        return isinstance(value, expected)\n\n    return validate\n'"
src/sagemaker/automl/__init__.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n'"
src/sagemaker/automl/automl.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""A class for SageMaker AutoML Jobs.""""""\nfrom __future__ import absolute_import\n\nfrom six import string_types\n\nfrom sagemaker import Model, PipelineModel\nfrom sagemaker.automl.candidate_estimator import CandidateEstimator\nfrom sagemaker.job import _Job\nfrom sagemaker.session import Session\nfrom sagemaker.utils import name_from_base\n\n\nclass AutoML(object):\n    """"""A class for creating and interacting with SageMaker AutoML jobs\n    """"""\n\n    def __init__(\n        self,\n        role,\n        target_attribute_name,\n        output_kms_key=None,\n        output_path=None,\n        base_job_name=None,\n        compression_type=None,\n        sagemaker_session=None,\n        volume_kms_key=None,\n        encrypt_inter_container_traffic=False,\n        vpc_config=None,\n        problem_type=None,\n        max_candidates=None,\n        max_runtime_per_training_job_in_seconds=None,\n        total_job_runtime_in_seconds=None,\n        job_objective=None,\n        generate_candidate_definitions_only=False,\n        tags=None,\n    ):\n        self.role = role\n        self.output_kms_key = output_kms_key\n        self.output_path = output_path\n        self.base_job_name = base_job_name\n        self.compression_type = compression_type\n        self.volume_kms_key = volume_kms_key\n        self.encrypt_inter_container_traffic = encrypt_inter_container_traffic\n        self.vpc_config = vpc_config\n        self.problem_type = problem_type\n        self.max_candidate = max_candidates\n        self.max_runtime_per_training_job_in_seconds = max_runtime_per_training_job_in_seconds\n        self.total_job_runtime_in_seconds = total_job_runtime_in_seconds\n        self.target_attribute_name = target_attribute_name\n        self.job_objective = job_objective\n        self.generate_candidate_definitions_only = generate_candidate_definitions_only\n        self.tags = tags\n\n        self.current_job_name = None\n        self._auto_ml_job_desc = None\n        self._best_candidate = None\n        self.sagemaker_session = sagemaker_session or Session()\n\n        self._check_problem_type_and_job_objective(self.problem_type, self.job_objective)\n\n    def fit(self, inputs=None, wait=True, logs=True, job_name=None):\n        """"""Create an AutoML Job with the input dataset.\n\n        Args:\n            inputs (str or list[str] or AutoMLInput): Local path or S3 Uri where the training data\n                is stored. Or an AutoMLInput object. If a local path is provided, the dataset will\n                be uploaded to an S3 location.\n            wait (bool): Whether the call should wait until the job completes (default: True).\n            logs (bool): Whether to show the logs produced by the job.\n                Only meaningful when wait is True (default: True).\n            job_name (str): Training job name. If not specified, the estimator generates\n                a default job name, based on the training image name and current timestamp.\n        """"""\n        if logs and not wait:\n            raise ValueError(\n                """"""Logs can only be shown if wait is set to True.\n                Please either set wait to True or set logs to False.""""""\n            )\n\n        # upload data for users if provided local path\n        # validations are done in _Job._format_inputs_to_input_config\n        if isinstance(inputs, string_types):\n            if not inputs.startswith(""s3://""):\n                inputs = self.sagemaker_session.upload_data(inputs, key_prefix=""auto-ml-input-data"")\n        self._prepare_for_auto_ml_job(job_name=job_name)\n\n        self.latest_auto_ml_job = AutoMLJob.start_new(self, inputs)  # pylint: disable=W0201\n        if wait:\n            self.latest_auto_ml_job.wait(logs=logs)\n\n    def describe_auto_ml_job(self, job_name=None):\n        """"""Returns the job description of an AutoML job for the given job name.\n\n        Args:\n            job_name (str): The name of the AutoML job to describe.\n                If None, will use object\'s latest_auto_ml_job name.\n\n        Returns:\n            dict: A dictionary response with the AutoML Job description.\n        """"""\n        if job_name is None:\n            job_name = self.current_job_name\n        self._auto_ml_job_desc = self.sagemaker_session.describe_auto_ml_job(job_name)\n        return self._auto_ml_job_desc\n\n    def best_candidate(self, job_name=None):\n        """"""Returns the best candidate of an AutoML job for a given name\n\n        Args:\n            job_name (str): The name of the AutoML job. If None, will use object\'s\n                _current_auto_ml_job_name.\n        Returns:\n            dict: a dictionary with information of the best candidate\n        """"""\n        if self._best_candidate:\n            return self._best_candidate\n\n        if job_name is None:\n            job_name = self.current_job_name\n        if self._auto_ml_job_desc is None:\n            self._auto_ml_job_desc = self.sagemaker_session.describe_auto_ml_job(job_name)\n        elif self._auto_ml_job_desc[""AutoMLJobName""] != job_name:\n            self._auto_ml_job_desc = self.sagemaker_session.describe_auto_ml_job(job_name)\n\n        self._best_candidate = self._auto_ml_job_desc[""BestCandidate""]\n        return self._best_candidate\n\n    def list_candidates(\n        self,\n        job_name=None,\n        status_equals=None,\n        candidate_name=None,\n        candidate_arn=None,\n        sort_order=None,\n        sort_by=None,\n        max_results=None,\n    ):\n        """"""Returns the list of candidates of an AutoML job for a given name.\n\n        Args:\n            job_name (str): The name of the AutoML job. If None, will use object\'s\n                _current_job name.\n            status_equals (str): Filter the result with candidate status, values could be\n                ""Completed"", ""InProgress"", ""Failed"", ""Stopped"", ""Stopping""\n            candidate_name (str): The name of a specified candidate to list.\n                Default to None.\n            candidate_arn (str): The Arn of a specified candidate to list.\n                Default to None.\n            sort_order (str): The order that the candidates will be listed in result.\n                Default to None.\n            sort_by (str): The value that the candidates will be sorted by.\n                Default to None.\n            max_results (int): The number of candidates will be listed in results,\n                between 1 to 100. Default to None. If None, will return all the candidates.\n        Returns:\n            list: A list of dictionaries with candidates information\n        """"""\n        if job_name is None:\n            job_name = self.current_job_name\n\n        list_candidates_args = {""job_name"": job_name}\n\n        if status_equals:\n            list_candidates_args[""status_equals""] = status_equals\n        if candidate_name:\n            list_candidates_args[""candidate_name""] = candidate_name\n        if candidate_arn:\n            list_candidates_args[""candidate_arn""] = candidate_arn\n        if sort_order:\n            list_candidates_args[""sort_order""] = sort_order\n        if sort_by:\n            list_candidates_args[""sort_by""] = sort_by\n        if max_results:\n            list_candidates_args[""max_results""] = max_results\n\n        return self.sagemaker_session.list_candidates(**list_candidates_args)[""Candidates""]\n\n    def deploy(\n        self,\n        initial_instance_count,\n        instance_type,\n        candidate=None,\n        sagemaker_session=None,\n        name=None,\n        endpoint_name=None,\n        tags=None,\n        wait=True,\n        update_endpoint=False,\n        vpc_config=None,\n        enable_network_isolation=False,\n        model_kms_key=None,\n        predictor_cls=None,\n    ):\n        """"""Deploy a candidate to a SageMaker Inference Pipeline and return a Predictor\n\n        Args:\n            initial_instance_count (int): The initial number of instances to run\n                in the ``Endpoint`` created from this ``Model``.\n            instance_type (str): The EC2 instance type to deploy this Model to.\n                For example, \'ml.p2.xlarge\'.\n            candidate (CandidateEstimator or dict): a CandidateEstimator used for deploying\n                to a SageMaker Inference Pipeline. If None, the best candidate will\n                be used. If the candidate input is a dict, a CandidateEstimator will be\n                created from it.\n            sagemaker_session (sagemaker.session.Session): A SageMaker Session\n                object, used for SageMaker interactions (default: None). If not\n                specified, the one originally associated with the ``AutoML`` instance is used.\n            name (str): The pipeline model name. If None, a default model name will\n                be selected on each ``deploy``.\n            endpoint_name (str): The name of the endpoint to create (default:\n                None). If not specified, a unique endpoint name will be created.\n            tags (List[dict[str, str]]): The list of tags to attach to this\n                specific endpoint.\n            wait (bool): Whether the call should wait until the deployment of\n                model completes (default: True).\n            update_endpoint (bool): Flag to update the model in an existing\n                Amazon SageMaker endpoint. If True, this will deploy a new\n                EndpointConfig to an already existing endpoint and delete\n                resources corresponding to the previous EndpointConfig. If\n                False, a new endpoint will be created. Default: False\n            vpc_config (dict): Specifies a VPC that your training jobs and hosted models have\n                access to. Contents include ""SecurityGroupIds"" and ""Subnets"".\n            enable_network_isolation (bool): Isolates the training container. No inbound or\n                outbound network calls can be made, except for calls between peers within a\n                training cluster for distributed training. Default: False\n            model_kms_key (str): KMS key ARN used to encrypt the repacked\n                model archive file if the model is repacked\n            predictor_cls (callable[string, sagemaker.session.Session]): A\n                function to call to create a predictor (default: None). If\n                specified, ``deploy()``  returns the result of invoking this\n                function on the created endpoint name.\n\n        Returns:\n            callable[string, sagemaker.session.Session] or ``None``:\n                If ``predictor_cls`` is specified, the invocation of ``self.predictor_cls`` on\n                the created endpoint name. Otherwise, ``None``.\n        """"""\n        sagemaker_session = sagemaker_session or self.sagemaker_session\n\n        if candidate is None:\n            candidate_dict = self.best_candidate()\n            candidate = CandidateEstimator(candidate_dict, sagemaker_session=sagemaker_session)\n        elif isinstance(candidate, dict):\n            candidate = CandidateEstimator(candidate, sagemaker_session=sagemaker_session)\n\n        inference_containers = candidate.containers\n        endpoint_name = endpoint_name or self.current_job_name\n\n        return self._deploy_inference_pipeline(\n            inference_containers,\n            initial_instance_count=initial_instance_count,\n            instance_type=instance_type,\n            name=name,\n            sagemaker_session=sagemaker_session,\n            endpoint_name=endpoint_name,\n            tags=tags,\n            wait=wait,\n            update_endpoint=update_endpoint,\n            vpc_config=vpc_config,\n            enable_network_isolation=enable_network_isolation,\n            model_kms_key=model_kms_key,\n            predictor_cls=predictor_cls,\n        )\n\n    def _check_problem_type_and_job_objective(self, problem_type, job_objective):\n        """"""Validate if problem_type and job_objective are both None or are both provided.\n\n        Args:\n            problem_type (str): The type of problem of this AutoMLJob. Valid values are\n                ""Regression"", ""BinaryClassification"", ""MultiClassClassification"".\n            job_objective (dict): AutoMLJob objective, contains ""AutoMLJobObjectiveType"" (optional),\n                ""MetricName"" and ""Value"".\n\n        Raises (ValueError): raises ValueError if one of problem_type and job_objective is provided\n            while the other is None.\n\n        """"""\n        if not (problem_type and job_objective) and (problem_type or job_objective):\n            raise ValueError(\n                ""One of problem type and objective metric provided. ""\n                ""Either both of them should be provided or none of them should be provided.""\n            )\n\n    def _deploy_inference_pipeline(\n        self,\n        inference_containers,\n        initial_instance_count,\n        instance_type,\n        name=None,\n        sagemaker_session=None,\n        endpoint_name=None,\n        tags=None,\n        wait=True,\n        update_endpoint=False,\n        vpc_config=None,\n        enable_network_isolation=False,\n        model_kms_key=None,\n        predictor_cls=None,\n    ):\n        """"""Deploy a SageMaker Inference Pipeline.\n\n        Args:\n            inference_containers (list): a list of inference container definitions\n            initial_instance_count (int): The initial number of instances to run\n                in the ``Endpoint`` created from this ``Model``.\n            instance_type (str): The EC2 instance type to deploy this Model to.\n                For example, \'ml.p2.xlarge\'.\n            name (str): The pipeline model name. If None, a default model name will\n                be selected on each ``deploy``.\n            sagemaker_session (sagemaker.session.Session): A SageMaker Session\n                object, used for SageMaker interactions (default: None). If not\n                specified, one is created using the default AWS configuration\n                chain.\n            endpoint_name (str): The name of the endpoint to create (default:\n                None). If not specified, a unique endpoint name will be created.\n            tags (List[dict[str, str]]): The list of tags to attach to this\n                specific endpoint.\n            wait (bool): Whether the call should wait until the deployment of\n                model completes (default: True).\n            update_endpoint (bool): Flag to update the model in an existing\n                Amazon SageMaker endpoint. If True, this will deploy a new\n                EndpointConfig to an already existing endpoint and delete\n                resources corresponding to the previous EndpointConfig. If\n                False, a new endpoint will be created. Default: False\n            vpc_config (dict): information about vpc configuration, optionally\n                contains ""SecurityGroupIds"", ""Subnets""\n            model_kms_key (str): KMS key ARN used to encrypt the repacked\n                model archive file if the model is repacked\n            predictor_cls (callable[string, sagemaker.session.Session]): A\n                function to call to create a predictor (default: None). If\n                specified, ``deploy()``  returns the result of invoking this\n                function on the created endpoint name.\n        """"""\n        # construct Model objects\n        models = []\n        for container in inference_containers:\n            image = container[""Image""]\n            model_data = container[""ModelDataUrl""]\n            env = container[""Environment""]\n\n            model = Model(\n                image=image,\n                model_data=model_data,\n                role=self.role,\n                env=env,\n                vpc_config=vpc_config,\n                sagemaker_session=sagemaker_session or self.sagemaker_session,\n                enable_network_isolation=enable_network_isolation,\n                model_kms_key=model_kms_key,\n            )\n            models.append(model)\n\n        pipeline = PipelineModel(\n            models=models,\n            role=self.role,\n            predictor_cls=predictor_cls,\n            name=name,\n            vpc_config=vpc_config,\n            sagemaker_session=sagemaker_session or self.sagemaker_session,\n        )\n\n        return pipeline.deploy(\n            initial_instance_count=initial_instance_count,\n            instance_type=instance_type,\n            endpoint_name=endpoint_name,\n            tags=tags,\n            wait=wait,\n            update_endpoint=update_endpoint,\n        )\n\n    def _prepare_for_auto_ml_job(self, job_name=None):\n        """"""Set any values in the AutoMLJob that need to be set before creating request.\n\n        Args:\n            job_name (str): The name of the AutoML job. If None, a job name will be\n                created from base_job_name or ""sagemaker-auto-ml"".\n        """"""\n        if job_name is not None:\n            self.current_job_name = job_name\n        else:\n            if self.base_job_name:\n                base_name = self.base_job_name\n            else:\n                base_name = ""automl""\n            # CreateAutoMLJob API validates that member length less than or equal to 32\n            self.current_job_name = name_from_base(base_name, max_length=32)\n\n        if self.output_path is None:\n            self.output_path = ""s3://{}/"".format(self.sagemaker_session.default_bucket())\n\n\nclass AutoMLInput(object):\n    """"""Accepts parameters that specify an S3 input for an auto ml job and provides\n    a method to turn those parameters into a dictionary.""""""\n\n    def __init__(self, inputs, target_attribute_name, compression=None):\n        """"""Convert an S3 Uri or a list of S3 Uri to an AutoMLInput object.\n\n        :param inputs (str, list[str]): a string or a list of string that points to (a)\n            S3 location(s) where input data is stored.\n        :param target_attribute_name (str): the target attribute name for regression\n            or classification.\n        :param compression (str): if training data is compressed, the compression type.\n            The default value is None.\n        """"""\n        self.inputs = inputs\n        self.target_attribute_name = target_attribute_name\n        self.compression = compression\n\n    def to_request_dict(self):\n        """"""Generates a request dictionary using the parameters provided to the class.""""""\n        # Create the request dictionary.\n        auto_ml_input = []\n        if isinstance(self.inputs, string_types):\n            self.inputs = [self.inputs]\n        for entry in self.inputs:\n            input_entry = {\n                ""DataSource"": {""S3DataSource"": {""S3DataType"": ""S3Prefix"", ""S3Uri"": entry}},\n                ""TargetAttributeName"": self.target_attribute_name,\n            }\n            if self.compression is not None:\n                input_entry[""CompressionType""] = self.compression\n            auto_ml_input.append(input_entry)\n        return auto_ml_input\n\n\nclass AutoMLJob(_Job):\n    """"""A class for interacting with CreateAutoMLJob API.""""""\n\n    def __init__(self, sagemaker_session, job_name, inputs):\n        self.inputs = inputs\n        self.job_name = job_name\n        super(AutoMLJob, self).__init__(sagemaker_session=sagemaker_session, job_name=job_name)\n\n    @classmethod\n    def start_new(cls, auto_ml, inputs):\n        """"""Create a new Amazon SageMaker AutoML job from auto_ml.\n\n        Args:\n            auto_ml (sagemaker.automl.AutoML): AutoML object\n                created by the user.\n            inputs (str, list[str]): Parameters used when called\n                :meth:`~sagemaker.automl.AutoML.fit`.\n\n        Returns:\n            sagemaker.automl.AutoMLJob: Constructed object that captures\n            all information about the started AutoML job.\n        """"""\n        config = cls._load_config(inputs, auto_ml)\n        auto_ml_args = config.copy()\n        auto_ml_args[""job_name""] = auto_ml.current_job_name\n        auto_ml_args[""problem_type""] = auto_ml.problem_type\n        auto_ml_args[""job_objective""] = auto_ml.job_objective\n        auto_ml_args[""tags""] = auto_ml.tags\n\n        auto_ml.sagemaker_session.auto_ml(**auto_ml_args)\n        return cls(auto_ml.sagemaker_session, auto_ml.current_job_name, inputs)\n\n    @classmethod\n    def _load_config(cls, inputs, auto_ml, expand_role=True, validate_uri=True):\n        """"""Load job_config, input_config and output config from auto_ml and inputs.\n\n        Args:\n            inputs (str): S3 Uri where the training data is stored, must start\n                with ""s3://"".\n            auto_ml (AutoML): an AutoML object that user initiated.\n            expand_role (str): The expanded role arn that allows for Sagemaker\n                executionts.\n            validate_uri (bool): indicate whether to validate the S3 uri.\n\n        Returns (dict): a config dictionary that contains input_config, output_config,\n            job_config and role information.\n\n        """"""\n        # JobConfig\n        # InputDataConfig\n        # OutputConfig\n\n        if isinstance(inputs, AutoMLInput):\n            input_config = inputs.to_request_dict()\n        else:\n            input_config = cls._format_inputs_to_input_config(\n                inputs, validate_uri, auto_ml.compression_type, auto_ml.target_attribute_name\n            )\n        output_config = _Job._prepare_output_config(auto_ml.output_path, auto_ml.output_kms_key)\n\n        role = auto_ml.sagemaker_session.expand_role(auto_ml.role) if expand_role else auto_ml.role\n\n        stop_condition = cls._prepare_auto_ml_stop_condition(\n            auto_ml.max_candidate,\n            auto_ml.max_runtime_per_training_job_in_seconds,\n            auto_ml.total_job_runtime_in_seconds,\n        )\n\n        auto_ml_job_config = {\n            ""CompletionCriteria"": stop_condition,\n            ""SecurityConfig"": {\n                ""EnableInterContainerTrafficEncryption"": auto_ml.encrypt_inter_container_traffic\n            },\n        }\n\n        if auto_ml.volume_kms_key:\n            auto_ml_job_config[""SecurityConfig""][""VolumeKmsKeyId""] = auto_ml.volume_kms_key\n        if auto_ml.vpc_config:\n            auto_ml_job_config[""SecurityConfig""][""VpcConfig""] = auto_ml.vpc_config\n\n        config = {\n            ""input_config"": input_config,\n            ""output_config"": output_config,\n            ""auto_ml_job_config"": auto_ml_job_config,\n            ""role"": role,\n            ""generate_candidate_definitions_only"": auto_ml.generate_candidate_definitions_only,\n        }\n        return config\n\n    @classmethod\n    def _format_inputs_to_input_config(\n        cls, inputs, validate_uri=True, compression=None, target_attribute_name=None\n    ):\n        """"""Convert inputs to AutoML InputDataConfig.\n\n        Args:\n            inputs (str, list[str]): local path(s) or S3 uri(s) of input datasets.\n            validate_uri (bool): indicates whether it is needed to validate S3 uri.\n            compression (str):\n            target_attribute_name (str): the target attribute name for classification\n                or regression.\n\n        Returns (dict): a dict of AutoML InputDataConfig\n\n        """"""\n        if inputs is None:\n            return None\n\n        channels = []\n        if isinstance(inputs, AutoMLInput):\n            channels.append(inputs.to_request_dict())\n        elif isinstance(inputs, string_types):\n            channel = _Job._format_string_uri_input(\n                inputs,\n                validate_uri,\n                compression=compression,\n                target_attribute_name=target_attribute_name,\n            ).config\n            channels.append(channel)\n        elif isinstance(inputs, list):\n            for input_entry in inputs:\n                channel = _Job._format_string_uri_input(\n                    input_entry,\n                    validate_uri,\n                    compression=compression,\n                    target_attribute_name=target_attribute_name,\n                ).config\n                channels.append(channel)\n        else:\n            msg = ""Cannot format input {}. Expecting a string or a list of strings.""\n            raise ValueError(msg.format(inputs))\n\n        for channel in channels:\n            if channel[""TargetAttributeName""] is None:\n                raise ValueError(""TargetAttributeName cannot be None."")\n\n        return channels\n\n    @classmethod\n    def _prepare_auto_ml_stop_condition(\n        cls, max_candidates, max_runtime_per_training_job_in_seconds, total_job_runtime_in_seconds\n    ):\n        """"""Defines the CompletionCriteria of an AutoMLJob.\n\n        Args:\n            max_candidates (int): the maximum number of candidates returned by an\n                AutoML job.\n            max_runtime_per_training_job_in_seconds (int): the maximum time of each\n                training job in seconds.\n            total_job_runtime_in_seconds (int): the total wait time of an AutoML job.\n\n        Returns (dict): an AutoML CompletionCriteria.\n\n        """"""\n        stopping_condition = {""MaxCandidates"": max_candidates}\n\n        if max_runtime_per_training_job_in_seconds is not None:\n            stopping_condition[\n                ""MaxRuntimePerTrainingJobInSeconds""\n            ] = max_runtime_per_training_job_in_seconds\n        if total_job_runtime_in_seconds is not None:\n            stopping_condition[""MaxAutoMLJobRuntimeInSeconds""] = total_job_runtime_in_seconds\n\n        return stopping_condition\n\n    def describe(self):\n        """"""Prints out a response from the DescribeAutoMLJob API call.""""""\n        return self.sagemaker_session.describe_auto_ml_job(self.job_name)\n\n    def wait(self, logs=True):\n        """"""Wait for the AutoML job to finish.\n        Args:\n            logs (bool): indicate whether to output logs.\n        """"""\n        if logs:\n            self.sagemaker_session.logs_for_auto_ml_job(self.job_name, wait=True)\n        else:\n            self.sagemaker_session.wait_for_auto_ml_job(self.job_name)\n'"
src/sagemaker/automl/candidate_estimator.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""A class for AutoML Job\'s Candidate.""""""\nfrom __future__ import absolute_import\n\nfrom six import string_types\n\nfrom sagemaker import Session\nfrom sagemaker.job import _Job\nfrom sagemaker.utils import name_from_base\n\n\nclass CandidateEstimator(object):\n    """"""A class for SageMaker AutoML Job Candidate""""""\n\n    def __init__(self, candidate, sagemaker_session=None):\n        """"""Constructor of CandidateEstimator.\n\n        Args:\n            candidate (dict): a dictionary of candidate returned by AutoML.list_candidates()\n                or AutoML.best_candidate().\n            sagemaker_session (sagemaker.session.Session): A SageMaker Session\n                object, used for SageMaker interactions (default: None). If not\n                specified, one is created using the default AWS configuration\n                chain.\n        """"""\n        self.name = candidate[""CandidateName""]\n        self.containers = candidate[""InferenceContainers""]\n        self.steps = self._process_steps(candidate[""CandidateSteps""])\n        self.sagemaker_session = sagemaker_session or Session()\n\n    def get_steps(self):\n        """"""Get the step job of a candidate so that users can construct estimators/transformers\n\n        Returns:\n            list: a list of dictionaries that provide information about each step job\'s name,\n                type, inputs and description\n        """"""\n        candidate_steps = []\n        for step in self.steps:\n            step_type = step[""type""]\n            step_name = step[""name""]\n            if step_type == ""TrainingJob"":\n                training_job = self.sagemaker_session.sagemaker_client.describe_training_job(\n                    TrainingJobName=step_name\n                )\n\n                inputs = training_job[""InputDataConfig""]\n                candidate_step = CandidateStep(step_name, inputs, step_type, training_job)\n                candidate_steps.append(candidate_step)\n            elif step_type == ""TransformJob"":\n                transform_job = self.sagemaker_session.sagemaker_client.describe_transform_job(\n                    TransformJobName=step_name\n                )\n                inputs = transform_job[""TransformInput""]\n                candidate_step = CandidateStep(step_name, inputs, step_type, transform_job)\n                candidate_steps.append(candidate_step)\n        return candidate_steps\n\n    def fit(\n        self,\n        inputs,\n        candidate_name=None,\n        volume_kms_key=None,\n        encrypt_inter_container_traffic=False,\n        vpc_config=None,\n        wait=True,\n        logs=True,\n    ):\n        """"""Rerun a candidate\'s step jobs with new input datasets or security config.\n\n        Args:\n            inputs (str or list[str]): Local path or S3 Uri where the training data is stored. If a\n                local path is provided, the dataset will be uploaded to an S3 location.\n            candidate_name (str): name of the candidate to be rerun, if None, candidate\'s original\n                name will be used.\n            volume_kms_key (str): The KMS key id to encrypt data on the storage volume attached to\n                the ML compute instance(s).\n            encrypt_inter_container_traffic (bool): To encrypt all communications between ML compute\n                instances in distributed training. Default: False.\n            vpc_config (dict): Specifies a VPC that jobs and hosted models have access to.\n                Control access to and from training and model containers by configuring the VPC\n            wait (bool): Whether the call should wait until all jobs completes (default: True).\n            logs (bool): Whether to show the logs produced by the job.\n                Only meaningful when wait is True (default: True).\n        """"""\n        if logs and not wait:\n            raise ValueError(\n                """"""Logs can only be shown if wait is set to True.\n                Please either set wait to True or set logs to False.""""""\n            )\n\n        self.name = candidate_name or self.name\n        running_jobs = {}\n\n        # convert inputs to s3_input format\n        if isinstance(inputs, string_types):\n            if not inputs.startswith(""s3://""):\n                inputs = self.sagemaker_session.upload_data(inputs, key_prefix=""auto-ml-input-data"")\n\n        for step in self.steps:\n            step_type = step[""type""]\n            step_name = step[""name""]\n            if step_type == ""TrainingJob"":\n                # prepare inputs\n                input_dict = {}\n                if isinstance(inputs, string_types):\n                    input_dict[""train""] = _Job._format_string_uri_input(inputs)\n                else:\n                    msg = ""Cannot format input {}. Expecting a string.""\n                    raise ValueError(msg.format(inputs))\n\n                channels = [\n                    _Job._convert_input_to_channel(name, input)\n                    for name, input in input_dict.items()\n                ]\n\n                desc = self.sagemaker_session.sagemaker_client.describe_training_job(\n                    TrainingJobName=step_name\n                )\n                base_name = ""sagemaker-automl-training-rerun""\n                step_name = name_from_base(base_name)\n                step[""name""] = step_name\n                train_args = self._get_train_args(\n                    desc,\n                    channels,\n                    step_name,\n                    volume_kms_key,\n                    encrypt_inter_container_traffic,\n                    vpc_config,\n                )\n                self.sagemaker_session.train(**train_args)\n                running_jobs[step_name] = True\n\n            elif step_type == ""TransformJob"":\n                # prepare inputs\n                if not isinstance(inputs, string_types) or not inputs.startswith(""s3://""):\n                    msg = ""Cannot format input {}. Expecting a string starts with file:// or s3://""\n                    raise ValueError(msg.format(inputs))\n\n                desc = self.sagemaker_session.sagemaker_client.describe_transform_job(\n                    TransformJobName=step_name\n                )\n                base_name = ""sagemaker-automl-transform-rerun""\n                step_name = name_from_base(base_name)\n                step[""name""] = step_name\n                transform_args = self._get_transform_args(desc, inputs, step_name, volume_kms_key)\n                self.sagemaker_session.transform(**transform_args)\n                running_jobs[step_name] = True\n\n        if wait:\n            while True:\n                for step in self.steps:\n                    status = None\n                    step_type = step[""type""]\n                    step_name = step[""name""]\n                    if step_type == ""TrainingJob"":\n                        status = self.sagemaker_session.sagemaker_client.describe_training_job(\n                            TrainingJobName=step_name\n                        )[""TrainingJobStatus""]\n                    elif step_type == ""TransformJob"":\n                        status = self.sagemaker_session.sagemaker_client.describe_transform_job(\n                            TransformJobName=step_name\n                        )[""TransformJobStatus""]\n                    if status in (""Completed"", ""Failed"", ""Stopped""):\n                        running_jobs[step_name] = False\n                if self._check_all_job_finished(running_jobs):\n                    break\n\n    def _check_all_job_finished(self, running_jobs):\n        """"""Check if all step jobs are finished.\n\n        Args:\n            running_jobs (dict): a dictionary that keeps track of the status\n                of each step job.\n\n        Returns (bool): True if all step jobs are finished. False if one or\n            more step jobs are still running.\n        """"""\n        for _, v in running_jobs.items():\n            if v:\n                return False\n        return True\n\n    def _get_train_args(\n        self, desc, inputs, name, volume_kms_key, encrypt_inter_container_traffic, vpc_config\n    ):\n        """"""Format training args to pass in sagemaker_session.train.\n\n        Args:\n            desc (dict): the response from DescribeTrainingJob API.\n            inputs (list): a list of input data channels.\n            name (str): the name of the step job.\n            volume_kms_key (str): The KMS key id to encrypt data on the storage volume attached to\n                the ML compute instance(s).\n            encrypt_inter_container_traffic (bool): To encrypt all communications between ML compute\n                instances in distributed training.\n            vpc_config (dict): Specifies a VPC that jobs and hosted models have access to.\n                Control access to and from training and model containers by configuring the VPC\n\n        Returns (dcit): a dictionary that can be used as args of\n            sagemaker_session.train method.\n        """"""\n        train_args = {}\n        train_args[""input_config""] = inputs\n        train_args[""job_name""] = name\n        train_args[""input_mode""] = desc[""AlgorithmSpecification""][""TrainingInputMode""]\n        train_args[""role""] = desc[""RoleArn""]\n        train_args[""output_config""] = desc[""OutputDataConfig""]\n        train_args[""resource_config""] = desc[""ResourceConfig""]\n        train_args[""image""] = desc[""AlgorithmSpecification""][""TrainingImage""]\n        train_args[""enable_network_isolation""] = desc[""EnableNetworkIsolation""]\n        train_args[""encrypt_inter_container_traffic""] = encrypt_inter_container_traffic\n        train_args[""train_use_spot_instances""] = desc[""EnableManagedSpotTraining""]\n        train_args[""hyperparameters""] = {}\n        train_args[""stop_condition""] = {}\n        train_args[""metric_definitions""] = None\n        train_args[""checkpoint_s3_uri""] = None\n        train_args[""checkpoint_local_path""] = None\n        train_args[""tags""] = []\n        train_args[""vpc_config""] = None\n\n        if volume_kms_key is not None:\n            train_args[""resource_config""][""VolumeKmsKeyId""] = volume_kms_key\n        if ""VpcConfig"" in desc:\n            train_args[""vpc_config""] = desc[""VpcConfig""]\n        elif vpc_config is not None:\n            train_args[""vpc_config""] = vpc_config\n        if ""Hyperparameters"" in desc:\n            train_args[""hyperparameters""] = desc[""Hyperparameters""]\n        if ""CheckpointConfig"" in desc:\n            train_args[""checkpoint_s3_uri""] = desc[""CheckpointConfig""][""S3Uri""]\n            train_args[""checkpoint_local_path""] = desc[""CheckpointConfig""][""LocalPath""]\n        if ""StoppingCondition"" in desc:\n            train_args[""stop_condition""] = desc[""StoppingCondition""]\n        return train_args\n\n    def _get_transform_args(self, desc, inputs, name, volume_kms_key):\n        """"""Format training args to pass in sagemaker_session.train.\n\n        Args:\n            desc (dict): the response from DescribeTrainingJob API.\n            inputs (str): an S3 uri where new input dataset is stored.\n            name (str): the name of the step job.\n            volume_kms_key (str): The KMS key id to encrypt data on the storage volume attached to\n                the ML compute instance(s).\n\n        Returns (dcit): a dictionary that can be used as args of\n            sagemaker_session.transform method.\n        """"""\n        transform_args = {}\n        transform_args[""job_name""] = name\n        transform_args[""model_name""] = desc[""ModelName""]\n        transform_args[""output_config""] = desc[""TransformOutput""]\n        transform_args[""resource_config""] = desc[""TransformResources""]\n        transform_args[""data_processing""] = desc[""DataProcessing""]\n        transform_args[""tags""] = []\n        transform_args[""strategy""] = None\n        transform_args[""max_concurrent_transforms""] = None\n        transform_args[""max_payload""] = None\n        transform_args[""env""] = None\n        transform_args[""experiment_config""] = None\n\n        input_config = desc[""TransformInput""]\n        input_config[""DataSource""][""S3DataSource""][""S3Uri""] = inputs\n        transform_args[""input_config""] = input_config\n\n        if volume_kms_key is not None:\n            transform_args[""resource_config""][""VolumeKmsKeyId""] = volume_kms_key\n        if ""BatchStrategy"" in desc:\n            transform_args[""strategy""] = desc[""BatchStrategy""]\n        if ""MaxConcurrentTransforms"" in desc:\n            transform_args[""max_concurrent_transforms""] = desc[""MaxConcurrentTransforms""]\n        if ""MaxPayloadInMB"" in desc:\n            transform_args[""max_payload""] = desc[""MaxPayloadInMB""]\n        if ""Environment"" in desc:\n            transform_args[""env""] = desc[""Environment""]\n\n        return transform_args\n\n    def _process_steps(self, steps):\n        """"""Extract candidate\'s step jobs name and type.\n\n        Args:\n            steps (list): a list of a candidate\'s step jobs.\n\n        Returns (list): a list of extracted information about step jobs\'\n            name and type.\n        """"""\n        processed_steps = []\n        for step in steps:\n            step_name = step[""CandidateStepName""]\n            step_type = step[""CandidateStepType""].split(""::"")[2]\n            processed_steps.append({""name"": step_name, ""type"": step_type})\n        return processed_steps\n\n\nclass CandidateStep(object):\n    """"""A class that maintains an AutoML Candidate step\'s name, inputs, type, and description.""""""\n\n    def __init__(self, name, inputs, step_type, description):\n        self._name = name\n        self._inputs = inputs\n        self._type = step_type\n        self._description = description\n\n    @property\n    def name(self):\n        """"""Name of the candidate step -> (str)""""""\n        return self._name\n\n    @property\n    def inputs(self):\n        """"""Inputs of the candidate step -> (dict)""""""\n        return self._inputs\n\n    @property\n    def type(self):\n        """"""Type of the candidate step, Training or Transform -> (str)""""""\n        return self._type\n\n    @property\n    def description(self):\n        """"""Description of candidate step job -> (dict)""""""\n        return self._description\n'"
src/sagemaker/chainer/__init__.py,0,"b'# Copyright 2018-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nfrom sagemaker.chainer.estimator import Chainer  # noqa: F401\nfrom sagemaker.chainer.model import ChainerModel, ChainerPredictor  # noqa: F401\n'"
src/sagemaker/chainer/defaults.py,0,"b'# Copyright 2018-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nCHAINER_VERSION = ""4.1.0""\n""""""Default Chainer version for when the framework version is not specified.\nThis is no longer updated so as to not break existing workflows.\n""""""\n\nLATEST_VERSION = ""5.0.0""\n""""""The latest version of Chainer included in the SageMaker pre-built Docker images.""""""\n\nLATEST_PY2_VERSION = ""5.0.0""\n'"
src/sagemaker/chainer/estimator.py,0,"b'# Copyright 2018-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nimport logging\n\nfrom sagemaker.estimator import Framework\nfrom sagemaker.fw_utils import (\n    framework_name_from_image,\n    framework_version_from_tag,\n    empty_framework_version_warning,\n    python_deprecation_warning,\n)\nfrom sagemaker.chainer import defaults\nfrom sagemaker.chainer.model import ChainerModel\nfrom sagemaker.vpc_utils import VPC_CONFIG_DEFAULT\n\nlogger = logging.getLogger(""sagemaker"")\n\n\nclass Chainer(Framework):\n    """"""Handle end-to-end training and deployment of custom Chainer code.""""""\n\n    __framework_name__ = ""chainer""\n\n    # Hyperparameters\n    _use_mpi = ""sagemaker_use_mpi""\n    _num_processes = ""sagemaker_num_processes""\n    _process_slots_per_host = ""sagemaker_process_slots_per_host""\n    _additional_mpi_options = ""sagemaker_additional_mpi_options""\n\n    LATEST_VERSION = defaults.LATEST_VERSION\n\n    def __init__(\n        self,\n        entry_point,\n        use_mpi=None,\n        num_processes=None,\n        process_slots_per_host=None,\n        additional_mpi_options=None,\n        source_dir=None,\n        hyperparameters=None,\n        py_version=""py3"",\n        framework_version=None,\n        image_name=None,\n        **kwargs\n    ):\n        """"""This ``Estimator`` executes an Chainer script in a managed Chainer\n        execution environment, within a SageMaker Training Job. The managed\n        Chainer environment is an Amazon-built Docker container that executes\n        functions defined in the supplied ``entry_point`` Python script.\n\n        Training is started by calling\n        :meth:`~sagemaker.amazon.estimator.Framework.fit` on this Estimator.\n        After training is complete, calling\n        :meth:`~sagemaker.amazon.estimator.Framework.deploy` creates a hosted\n        SageMaker endpoint and returns an\n        :class:`~sagemaker.amazon.chainer.model.ChainerPredictor` instance that\n        can be used to perform inference against the hosted model.\n\n        Technical documentation on preparing Chainer scripts for SageMaker\n        training and using the Chainer Estimator is available on the project\n        home-page: https://github.com/aws/sagemaker-python-sdk\n\n        Args:\n            entry_point (str): Path (absolute or relative) to the Python source\n                file which should be executed as the entry point to training.\n                If ``source_dir`` is specified, then ``entry_point``\n                must point to a file located at the root of ``source_dir``.\n            use_mpi (bool): If true, entry point is run as an MPI script. By\n                default, the Chainer Framework runs the entry point with\n                \'mpirun\' if more than one instance is used.\n            num_processes (int): Total number of processes to run the entry\n                point with. By default, the Chainer Framework runs one process\n                per GPU (on GPU instances), or one process per host (on CPU\n                instances).\n            process_slots_per_host (int): The number of processes that can run\n                on each instance. By default, this is set to the number of GPUs\n                on the instance (on GPU instances), or one (on CPU instances).\n            additional_mpi_options (str): String of options to the \'mpirun\'\n                command used to run the entry point. For example, \'-X\n                NCCL_DEBUG=WARN\' will pass that option string to the mpirun\n                command.\n            source_dir (str): Path (absolute or relative) to a directory with\n                any other training source code dependencies aside from the entry\n                point file (default: None). Structure within this directory are\n                preserved when training on Amazon SageMaker.\n            hyperparameters (dict): Hyperparameters that will be used for\n                training (default: None). The hyperparameters are made\n                accessible as a dict[str, str] to the training code on\n                SageMaker. For convenience, this accepts other types for keys\n                and values, but ``str()`` will be called to convert them before\n                training.\n            py_version (str): Python version you want to use for executing your\n                model training code (default: \'py2\'). One of \'py2\' or \'py3\'.\n            framework_version (str): Chainer version you want to use for\n                executing your model training code. List of supported versions\n                https://github.com/aws/sagemaker-python-sdk#chainer-sagemaker-estimators.\n                If not specified, this will default to 4.1.\n            image_name (str): If specified, the estimator will use this image\n                for training and hosting, instead of selecting the appropriate\n                SageMaker official image based on framework_version and\n                py_version. It can be an ECR url or dockerhub image and tag.\n\n                Examples\n                    * ``123412341234.dkr.ecr.us-west-2.amazonaws.com/my-custom-image:1.0``\n                    * ``custom-image:latest``\n\n            **kwargs: Additional kwargs passed to the\n                :class:`~sagemaker.estimator.Framework` constructor.\n\n        .. tip::\n\n            You can find additional parameters for initializing this class at\n            :class:`~sagemaker.estimator.Framework` and\n            :class:`~sagemaker.estimator.EstimatorBase`.\n        """"""\n        if framework_version is None:\n            logger.warning(\n                empty_framework_version_warning(defaults.CHAINER_VERSION, self.LATEST_VERSION)\n            )\n        self.framework_version = framework_version or defaults.CHAINER_VERSION\n\n        super(Chainer, self).__init__(\n            entry_point, source_dir, hyperparameters, image_name=image_name, **kwargs\n        )\n\n        if py_version == ""py2"":\n            logger.warning(\n                python_deprecation_warning(self.__framework_name__, defaults.LATEST_PY2_VERSION)\n            )\n\n        self.py_version = py_version\n        self.use_mpi = use_mpi\n        self.num_processes = num_processes\n        self.process_slots_per_host = process_slots_per_host\n        self.additional_mpi_options = additional_mpi_options\n\n    def hyperparameters(self):\n        """"""Return hyperparameters used by your custom Chainer code during\n        training.\n        """"""\n        hyperparameters = super(Chainer, self).hyperparameters()\n\n        additional_hyperparameters = {\n            Chainer._use_mpi: self.use_mpi,\n            Chainer._num_processes: self.num_processes,\n            Chainer._process_slots_per_host: self.process_slots_per_host,\n            Chainer._additional_mpi_options: self.additional_mpi_options,\n        }\n\n        # remove unset keys.\n        additional_hyperparameters = {k: v for k, v in additional_hyperparameters.items() if v}\n        hyperparameters.update(Framework._json_encode_hyperparameters(additional_hyperparameters))\n        return hyperparameters\n\n    def create_model(\n        self,\n        model_server_workers=None,\n        role=None,\n        vpc_config_override=VPC_CONFIG_DEFAULT,\n        entry_point=None,\n        source_dir=None,\n        dependencies=None,\n        **kwargs\n    ):\n        """"""Create a SageMaker ``ChainerModel`` object that can be deployed to an\n        ``Endpoint``.\n\n        Args:\n            model_server_workers (int): Optional. The number of worker processes\n                used by the inference server. If None, server will use one\n                worker per vCPU.\n            role (str): The ``ExecutionRoleArn`` IAM Role ARN for the ``Model``,\n                which is also used during transform jobs. If not specified, the\n                role from the Estimator will be used.\n            vpc_config_override (dict[str, list[str]]): Optional override for VpcConfig set on\n                the model. Default: use subnets and security groups from this Estimator.\n\n                * \'Subnets\' (list[str]): List of subnet ids.\n                * \'SecurityGroupIds\' (list[str]): List of security group ids.\n\n            entry_point (str): Path (absolute or relative) to the local Python source file which\n                should be executed as the entry point to training. If ``source_dir`` is specified,\n                then ``entry_point`` must point to a file located at the root of ``source_dir``.\n                If not specified, the training entry point is used.\n            source_dir (str): Path (absolute or relative) to a directory with any other serving\n                source code dependencies aside from the entry point file.\n                If not specified, the model source directory from training is used.\n            dependencies (list[str]): A list of paths to directories (absolute or relative) with\n                any additional libraries that will be exported to the container.\n                If not specified, the dependencies from training are used.\n            **kwargs: Additional kwargs passed to the ChainerModel constructor.\n\n        Returns:\n            sagemaker.chainer.model.ChainerModel: A SageMaker ``ChainerModel``\n            object. See :func:`~sagemaker.chainer.model.ChainerModel` for full details.\n        """"""\n        if ""image"" not in kwargs:\n            kwargs[""image""] = self.image_name\n\n        if ""name"" not in kwargs:\n            kwargs[""name""] = self._current_job_name\n\n        return ChainerModel(\n            self.model_data,\n            role or self.role,\n            entry_point or self.entry_point,\n            source_dir=(source_dir or self._model_source_dir()),\n            enable_cloudwatch_metrics=self.enable_cloudwatch_metrics,\n            container_log_level=self.container_log_level,\n            code_location=self.code_location,\n            py_version=self.py_version,\n            framework_version=self.framework_version,\n            model_server_workers=model_server_workers,\n            sagemaker_session=self.sagemaker_session,\n            vpc_config=self.get_vpc_config(vpc_config_override),\n            dependencies=(dependencies or self.dependencies),\n            **kwargs\n        )\n\n    @classmethod\n    def _prepare_init_params_from_job_description(cls, job_details, model_channel_name=None):\n        """"""Convert the job description to init params that can be handled by the\n        class constructor\n\n        Args:\n            job_details: the returned job details from a describe_training_job\n                API call.\n            model_channel_name (str): Name of the channel where pre-trained\n                model data will be downloaded.\n\n        Returns:\n            dictionary: The transformed init_params\n        """"""\n        init_params = super(Chainer, cls)._prepare_init_params_from_job_description(\n            job_details, model_channel_name\n        )\n\n        for argument in [\n            Chainer._use_mpi,\n            Chainer._num_processes,\n            Chainer._process_slots_per_host,\n            Chainer._additional_mpi_options,\n        ]:\n\n            value = init_params[""hyperparameters""].pop(argument, None)\n            if value:\n                init_params[argument[len(""sagemaker_"") :]] = value\n\n        image_name = init_params.pop(""image"")\n        framework, py_version, tag, _ = framework_name_from_image(image_name)\n\n        if not framework:\n            # If we were unable to parse the framework name from the image it is not one of our\n            # officially supported images, in this case just add the image to the init params.\n            init_params[""image_name""] = image_name\n            return init_params\n\n        init_params[""py_version""] = py_version\n        init_params[""framework_version""] = framework_version_from_tag(tag)\n\n        training_job_name = init_params[""base_job_name""]\n\n        if framework != cls.__framework_name__:\n            raise ValueError(\n                ""Training job: {} didn\'t use image for requested framework"".format(\n                    training_job_name\n                )\n            )\n        return init_params\n'"
src/sagemaker/chainer/model.py,0,"b'# Copyright 2018-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nimport logging\n\nfrom sagemaker import fw_utils\n\nimport sagemaker\nfrom sagemaker.fw_utils import (\n    create_image_uri,\n    model_code_key_prefix,\n    python_deprecation_warning,\n    empty_framework_version_warning,\n)\nfrom sagemaker.model import FrameworkModel, MODEL_SERVER_WORKERS_PARAM_NAME\nfrom sagemaker.chainer import defaults\nfrom sagemaker.predictor import RealTimePredictor, npy_serializer, numpy_deserializer\n\nlogger = logging.getLogger(""sagemaker"")\n\n\nclass ChainerPredictor(RealTimePredictor):\n    """"""A RealTimePredictor for inference against Chainer Endpoints.\n\n    This is able to serialize Python lists, dictionaries, and numpy arrays to\n    multidimensional tensors for Chainer inference.\n    """"""\n\n    def __init__(self, endpoint_name, sagemaker_session=None):\n        """"""Initialize an ``ChainerPredictor``.\n\n        Args:\n            endpoint_name (str): The name of the endpoint to perform inference\n                on.\n            sagemaker_session (sagemaker.session.Session): Session object which\n                manages interactions with Amazon SageMaker APIs and any other\n                AWS services needed. If not specified, the estimator creates one\n                using the default AWS configuration chain.\n        """"""\n        super(ChainerPredictor, self).__init__(\n            endpoint_name, sagemaker_session, npy_serializer, numpy_deserializer\n        )\n\n\nclass ChainerModel(FrameworkModel):\n    """"""An Chainer SageMaker ``Model`` that can be deployed to a SageMaker\n    ``Endpoint``.\n    """"""\n\n    __framework_name__ = ""chainer""\n\n    def __init__(\n        self,\n        model_data,\n        role,\n        entry_point,\n        image=None,\n        py_version=""py3"",\n        framework_version=None,\n        predictor_cls=ChainerPredictor,\n        model_server_workers=None,\n        **kwargs\n    ):\n        """"""Initialize an ChainerModel.\n\n        Args:\n            model_data (str): The S3 location of a SageMaker model data\n                ``.tar.gz`` file.\n            role (str): An AWS IAM role (either name or full ARN). The Amazon\n                SageMaker training jobs and APIs that create Amazon SageMaker\n                endpoints use this role to access training data and model\n                artifacts. After the endpoint is created, the inference code\n                might use the IAM role, if it needs to access an AWS resource.\n            entry_point (str): Path (absolute or relative) to the Python source\n                file which should be executed as the entry point to model\n                hosting. If ``source_dir`` is specified, then ``entry_point``\n                must point to a file located at the root of ``source_dir``.\n            image (str): A Docker image URI (default: None). If not specified, a\n                default image for Chainer will be used.\n            py_version (str): Python version you want to use for executing your\n                model training code (default: \'py2\').\n            framework_version (str): Chainer version you want to use for\n                executing your model training code.\n            predictor_cls (callable[str, sagemaker.session.Session]): A function\n                to call to create a predictor with an endpoint name and\n                SageMaker ``Session``. If specified, ``deploy()`` returns the\n                result of invoking this function on the created endpoint name.\n            model_server_workers (int): Optional. The number of worker processes\n                used by the inference server. If None, server will use one\n                worker per vCPU.\n            **kwargs: Keyword arguments passed to the\n                :class:`~sagemaker.model.FrameworkModel` initializer.\n\n        .. tip::\n\n            You can find additional parameters for initializing this class at\n            :class:`~sagemaker.model.FrameworkModel` and\n            :class:`~sagemaker.model.Model`.\n        """"""\n        super(ChainerModel, self).__init__(\n            model_data, image, role, entry_point, predictor_cls=predictor_cls, **kwargs\n        )\n        if py_version == ""py2"":\n            logger.warning(\n                python_deprecation_warning(self.__framework_name__, defaults.LATEST_PY2_VERSION)\n            )\n\n        if framework_version is None:\n            logger.warning(\n                empty_framework_version_warning(defaults.CHAINER_VERSION, defaults.LATEST_VERSION)\n            )\n\n        self.py_version = py_version\n        self.framework_version = framework_version or defaults.CHAINER_VERSION\n        self.model_server_workers = model_server_workers\n\n    def prepare_container_def(self, instance_type, accelerator_type=None):\n        """"""Return a container definition with framework configuration set in\n        model environment variables.\n\n        Args:\n            instance_type (str): The EC2 instance type to deploy this Model to.\n                For example, \'ml.p2.xlarge\'.\n            accelerator_type (str): The Elastic Inference accelerator type to\n                deploy to the instance for loading and making inferences to the\n                model. For example, \'ml.eia1.medium\'.\n\n        Returns:\n            dict[str, str]: A container definition object usable with the\n            CreateModel API.\n        """"""\n        deploy_image = self.image\n        if not deploy_image:\n            region_name = self.sagemaker_session.boto_session.region_name\n            deploy_image = create_image_uri(\n                region_name,\n                self.__framework_name__,\n                instance_type,\n                self.framework_version,\n                self.py_version,\n                accelerator_type=accelerator_type,\n            )\n\n        deploy_key_prefix = model_code_key_prefix(self.key_prefix, self.name, deploy_image)\n        self._upload_code(deploy_key_prefix)\n        deploy_env = dict(self.env)\n        deploy_env.update(self._framework_env_vars())\n\n        if self.model_server_workers:\n            deploy_env[MODEL_SERVER_WORKERS_PARAM_NAME.upper()] = str(self.model_server_workers)\n        return sagemaker.container_def(deploy_image, self.model_data, deploy_env)\n\n    def serving_image_uri(self, region_name, instance_type):\n        """"""Create a URI for the serving image.\n\n        Args:\n            region_name (str): AWS region where the image is uploaded.\n            instance_type (str): SageMaker instance type. Used to determine device type\n                (cpu/gpu/family-specific optimized).\n\n        Returns:\n            str: The appropriate image URI based on the given parameters.\n\n        """"""\n        return fw_utils.create_image_uri(\n            region_name,\n            self.__framework_name__,\n            instance_type,\n            self.framework_version,\n            self.py_version,\n        )\n'"
src/sagemaker/cli/__init__.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n'"
src/sagemaker/cli/common.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nimport json\nimport logging\nimport os\nimport shutil\nimport tarfile\nimport tempfile\n\nimport sagemaker\n\nlogger = logging.getLogger(__name__)\n\n\nclass HostCommand(object):\n    """"""Placeholder docstring""""""\n\n    def __init__(self, args):\n        """"""\n        Args:\n            args:\n        """"""\n        self.endpoint_name = args.job_name\n        self.bucket = args.bucket_name  # may be None\n        self.role_name = args.role_name\n        self.python = args.python\n        self.data = args.data\n        self.script = args.script\n        self.instance_type = args.instance_type\n        self.instance_count = args.instance_count\n        self.environment = {k: v for k, v in (kv.split(""="") for kv in args.env)}\n\n        self.session = sagemaker.Session()\n\n    def upload_model(self):\n        """"""Placeholder docstring""""""\n        prefix = ""{}/model"".format(self.endpoint_name)\n\n        archive = self.create_model_archive(self.data)\n        model_uri = self.session.upload_data(path=archive, bucket=self.bucket, key_prefix=prefix)\n        shutil.rmtree(os.path.dirname(archive))\n\n        return model_uri\n\n    @staticmethod\n    def create_model_archive(src):\n        """"""\n        Args:\n            src:\n        """"""\n        if os.path.isdir(src):\n            arcname = "".""\n        else:\n            arcname = os.path.basename(src)\n\n        tmp = tempfile.mkdtemp()\n        archive = os.path.join(tmp, ""model.tar.gz"")\n\n        with tarfile.open(archive, mode=""w:gz"") as t:\n            t.add(src, arcname=arcname)\n        return archive\n\n    def create_model(self, model_url):\n        """"""\n        Args:\n            model_url:\n        """"""\n        raise NotImplementedError  # subclasses must override\n\n    def start(self):\n        """"""Placeholder docstring""""""\n        model_url = self.upload_model()\n        model = self.create_model(model_url)\n        predictor = model.deploy(\n            initial_instance_count=self.instance_count, instance_type=self.instance_type\n        )\n\n        return predictor\n\n\nclass TrainCommand(object):\n    """"""Placeholder docstring""""""\n\n    def __init__(self, args):\n        """"""\n        Args:\n            args:\n        """"""\n        self.job_name = args.job_name\n        self.bucket = args.bucket_name  # may be None\n        self.role_name = args.role_name\n        self.python = args.python\n        self.data = args.data\n        self.script = args.script\n        self.instance_type = args.instance_type\n        self.instance_count = args.instance_count\n        self.hyperparameters = self.load_hyperparameters(args.hyperparameters)\n\n        self.session = sagemaker.Session()\n\n    @staticmethod\n    def load_hyperparameters(src):\n        """"""\n        Args:\n            src:\n        """"""\n        hp = {}\n        if src and os.path.exists(src):\n            with open(src, ""r"") as f:\n                hp = json.load(f)\n        return hp\n\n    def upload_training_data(self):\n        """"""Placeholder docstring""""""\n        prefix = ""{}/data"".format(self.job_name)\n        data_url = self.session.upload_data(path=self.data, bucket=self.bucket, key_prefix=prefix)\n        return data_url\n\n    def create_estimator(self):\n        """"""Placeholder docstring""""""\n        raise NotImplementedError  # subclasses must override\n\n    def start(self):\n        """"""Placeholder docstring""""""\n        data_url = self.upload_training_data()\n        estimator = self.create_estimator()\n        estimator.fit(data_url)\n        logger.debug(""code location: %s"", estimator.uploaded_code.s3_prefix)\n        logger.debug(\n            ""model location: %s%s/output/model.tar.gz"",\n            estimator.output_path,\n            estimator._current_job_name,\n        )\n'"
src/sagemaker/cli/main.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nimport argparse\nimport logging\nimport sys\n\nimport sagemaker\nimport sagemaker.cli.mxnet\nimport sagemaker.cli.tensorflow\n\nlogger = logging.getLogger(__name__)\n\nDEFAULT_LOG_LEVEL = ""info""\nDEFAULT_BOTOCORE_LOG_LEVEL = ""warning""\n\n\ndef parse_arguments(args):\n    """"""\n    Args:\n        args:\n    """"""\n    parser = argparse.ArgumentParser(\n        description=""Launch SageMaker training jobs or hosting endpoints""\n    )\n    parser.set_defaults(func=lambda x: parser.print_usage())\n\n    # common args for training/hosting/all frameworks\n    common_parser = argparse.ArgumentParser(add_help=False)\n    common_parser.add_argument(\n        ""--role-name"", help=""SageMaker execution role name"", type=str, required=True\n    )\n    common_parser.add_argument(\n        ""--data"", help=""path to training data or model files"", type=str, default=""./data""\n    )\n    common_parser.add_argument(""--script"", help=""path to script"", type=str, default=""./script.py"")\n    common_parser.add_argument(""--job-name"", help=""job or endpoint name"", type=str, default=None)\n    common_parser.add_argument(\n        ""--bucket-name"",\n        help=""S3 bucket for training/model data and script files"",\n        type=str,\n        default=None,\n    )\n    common_parser.add_argument(""--python"", help=""python version"", type=str, default=""py2"")\n\n    instance_group = common_parser.add_argument_group(""instance settings"")\n    instance_group.add_argument(\n        ""--instance-type"", type=str, help=""instance type"", default=""ml.m4.xlarge""\n    )\n    instance_group.add_argument(""--instance-count"", type=int, help=""instance count"", default=1)\n\n    # common training args\n    common_train_parser = argparse.ArgumentParser(add_help=False)\n    common_train_parser.add_argument(\n        ""--hyperparameters"",\n        help=""path to training hyperparameters file"",\n        type=str,\n        default=""./hyperparameters.json"",\n    )\n\n    # common hosting args\n    common_host_parser = argparse.ArgumentParser(add_help=False)\n    common_host_parser.add_argument(\n        ""--env"", help=""hosting environment variable(s)"", type=str, nargs=""*"", default=[]\n    )\n\n    subparsers = parser.add_subparsers()\n\n    # framework/algo subcommands\n    mxnet_parser = subparsers.add_parser(""mxnet"", help=""use MXNet"", parents=[])\n    mxnet_subparsers = mxnet_parser.add_subparsers()\n    mxnet_train_parser = mxnet_subparsers.add_parser(\n        ""train"", help=""start a training job"", parents=[common_parser, common_train_parser]\n    )\n    mxnet_train_parser.set_defaults(func=sagemaker.cli.mxnet.train)\n\n    mxnet_host_parser = mxnet_subparsers.add_parser(\n        ""host"", help=""start a hosting endpoint"", parents=[common_parser, common_host_parser]\n    )\n    mxnet_host_parser.set_defaults(func=sagemaker.cli.mxnet.host)\n\n    tensorflow_parser = subparsers.add_parser(""tensorflow"", help=""use TensorFlow"", parents=[])\n    tensorflow_subparsers = tensorflow_parser.add_subparsers()\n    tensorflow_train_parser = tensorflow_subparsers.add_parser(\n        ""train"", help=""start a training job"", parents=[common_parser, common_train_parser]\n    )\n    tensorflow_train_parser.add_argument(\n        ""--training-steps"",\n        help=""number of training steps (tensorflow only)"",\n        type=int,\n        default=None,\n    )\n    tensorflow_train_parser.add_argument(\n        ""--evaluation-steps"",\n        help=""number of evaluation steps (tensorflow only)"",\n        type=int,\n        default=None,\n    )\n    tensorflow_train_parser.set_defaults(func=sagemaker.cli.tensorflow.train)\n\n    tensorflow_host_parser = tensorflow_subparsers.add_parser(\n        ""host"", help=""start a hosting endpoint"", parents=[common_parser, common_host_parser]\n    )\n    tensorflow_host_parser.set_defaults(func=sagemaker.cli.tensorflow.host)\n\n    log_group = parser.add_argument_group(""optional log settings"")\n    log_group.add_argument(\n        ""--log-level"", help=""log level for this command"", type=str, default=DEFAULT_LOG_LEVEL\n    )\n    log_group.add_argument(\n        ""--botocore-log-level"",\n        help=""log level for botocore"",\n        type=str,\n        default=DEFAULT_BOTOCORE_LOG_LEVEL,\n    )\n\n    return parser.parse_args(args)\n\n\ndef configure_logging(args):\n    """"""\n    Args:\n        args:\n    """"""\n    log_format = ""%(asctime)s %(levelname)s %(name)s: %(message)s""\n    log_level = logging.getLevelName(args.log_level.upper())\n    logging.basicConfig(format=log_format, level=log_level)\n    logging.getLogger(""botocore"").setLevel(args.botocore_log_level.upper())\n\n\ndef main():\n    """"""Placeholder docstring""""""\n    args = parse_arguments(sys.argv[1:])\n    configure_logging(args)\n    logger.debug(""args: %s"", args)\n    args.func(args)\n\n\nif __name__ == ""__main__"":\n    main()\n'"
src/sagemaker/cli/mxnet.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nfrom sagemaker.cli.common import HostCommand, TrainCommand\n\n\ndef train(args):\n    """"""\n    Args:\n        args:\n    """"""\n    MXNetTrainCommand(args).start()\n\n\ndef host(args):\n    """"""\n    Args:\n        args:\n    """"""\n    MXNetHostCommand(args).start()\n\n\nclass MXNetTrainCommand(TrainCommand):\n    """"""Placeholder docstring""""""\n\n    def create_estimator(self):\n        """"""Placeholder docstring""""""\n        from sagemaker.mxnet.estimator import MXNet\n\n        return MXNet(\n            self.script,\n            role=self.role_name,\n            base_job_name=self.job_name,\n            train_instance_count=self.instance_count,\n            train_instance_type=self.instance_type,\n            hyperparameters=self.hyperparameters,\n            py_version=self.python,\n        )\n\n\nclass MXNetHostCommand(HostCommand):\n    """"""Placeholder docstring""""""\n\n    def create_model(self, model_url):\n        """"""\n        Args:\n            model_url:\n        """"""\n        from sagemaker.mxnet.model import MXNetModel\n\n        return MXNetModel(\n            model_data=model_url,\n            role=self.role_name,\n            entry_point=self.script,\n            py_version=self.python,\n            name=self.endpoint_name,\n            env=self.environment,\n        )\n'"
src/sagemaker/cli/tensorflow.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nfrom sagemaker.cli.common import HostCommand, TrainCommand\n\n\ndef train(args):\n    """"""\n    Args:\n        args:\n    """"""\n    TensorFlowTrainCommand(args).start()\n\n\ndef host(args):\n    """"""\n    Args:\n        args:\n    """"""\n    TensorFlowHostCommand(args).start()\n\n\nclass TensorFlowTrainCommand(TrainCommand):\n    """"""Placeholder docstring""""""\n\n    def __init__(self, args):\n        """"""\n        Args:\n            args:\n        """"""\n        super(TensorFlowTrainCommand, self).__init__(args)\n        self.training_steps = args.training_steps\n        self.evaluation_steps = args.evaluation_steps\n\n    def create_estimator(self):\n        from sagemaker.tensorflow import TensorFlow\n\n        return TensorFlow(\n            training_steps=self.training_steps,\n            evaluation_steps=self.evaluation_steps,\n            py_version=self.python,\n            entry_point=self.script,\n            role=self.role_name,\n            base_job_name=self.job_name,\n            train_instance_count=self.instance_count,\n            train_instance_type=self.instance_type,\n            hyperparameters=self.hyperparameters,\n        )\n\n\nclass TensorFlowHostCommand(HostCommand):\n    """"""Placeholder docstring""""""\n\n    def create_model(self, model_url):\n        """"""\n        Args:\n            model_url:\n        """"""\n        from sagemaker.tensorflow.model import TensorFlowModel\n\n        return TensorFlowModel(\n            model_data=model_url,\n            role=self.role_name,\n            entry_point=self.script,\n            py_version=self.python,\n            name=self.endpoint_name,\n            env=self.environment,\n        )\n'"
src/sagemaker/local/__init__.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nfrom .local_session import (  # noqa: F401\n    file_input,\n    LocalSagemakerClient,\n    LocalSagemakerRuntimeClient,\n    LocalSession,\n)\n'"
src/sagemaker/local/data.py,0,"b'# Copyright 2018-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nimport os\nimport platform\nimport sys\nimport tempfile\nfrom abc import ABCMeta\nfrom abc import abstractmethod\nfrom six import with_metaclass\n\nfrom six.moves.urllib.parse import urlparse\n\nimport sagemaker.amazon.common\nimport sagemaker.local.utils\nimport sagemaker.utils\n\n\ndef get_data_source_instance(data_source, sagemaker_session):\n    """"""Return an Instance of :class:`sagemaker.local.data.DataSource` that can\n    handle the provided data_source URI.\n\n    data_source can be either file:// or s3://\n\n    Args:\n        data_source (str): a valid URI that points to a data source.\n        sagemaker_session (:class:`sagemaker.session.Session`): a SageMaker Session to\n            interact with S3 if required.\n\n    Returns:\n        sagemaker.local.data.DataSource: an Instance of a Data Source\n\n    Raises:\n        ValueError: If parsed_uri scheme is neither `file` nor `s3` , raise an\n            error.\n    """"""\n    parsed_uri = urlparse(data_source)\n    if parsed_uri.scheme == ""file"":\n        return LocalFileDataSource(parsed_uri.netloc + parsed_uri.path)\n    if parsed_uri.scheme == ""s3"":\n        return S3DataSource(parsed_uri.netloc, parsed_uri.path, sagemaker_session)\n    raise ValueError(\n        ""data_source must be either file or s3. parsed_uri.scheme: {}"".format(parsed_uri.scheme)\n    )\n\n\ndef get_splitter_instance(split_type):\n    """"""Return an Instance of :class:`sagemaker.local.data.Splitter` according to\n    the specified `split_type` .\n\n    Args:\n        split_type (str): either \'Line\' or \'RecordIO\'. Can be left as None to\n            signal no data split will happen.\n\n    Returns\n        :class:`sagemaker.local.data.Splitter`: an Instance of a Splitter\n    """"""\n    if split_type is None:\n        return NoneSplitter()\n    if split_type == ""Line"":\n        return LineSplitter()\n    if split_type == ""RecordIO"":\n        return RecordIOSplitter()\n    raise ValueError(""Invalid Split Type: %s"" % split_type)\n\n\ndef get_batch_strategy_instance(strategy, splitter):\n    """"""Return an Instance of :class:`sagemaker.local.data.BatchStrategy` according to `strategy`\n\n    Args:\n        strategy (str): Either \'SingleRecord\' or \'MultiRecord\'\n        splitter (:class:`sagemaker.local.data.Splitter): splitter to get the data from.\n\n    Returns\n        :class:`sagemaker.local.data.BatchStrategy`: an Instance of a BatchStrategy\n    """"""\n    if strategy == ""SingleRecord"":\n        return SingleRecordStrategy(splitter)\n    if strategy == ""MultiRecord"":\n        return MultiRecordStrategy(splitter)\n    raise ValueError(\'Invalid Batch Strategy: %s - Valid Strategies: ""SingleRecord"", ""MultiRecord""\')\n\n\nclass DataSource(with_metaclass(ABCMeta, object)):\n    """"""Placeholder docstring""""""\n\n    @abstractmethod\n    def get_file_list(self):\n        """"""Retrieve the list of absolute paths to all the files in this data\n        source.\n\n        Returns:\n            List[str]: List of absolute paths.\n        """"""\n\n    @abstractmethod\n    def get_root_dir(self):\n        """"""Retrieve the absolute path to the root directory of this data source.\n\n        Returns:\n            str: absolute path to the root directory of this data source.\n        """"""\n\n\nclass LocalFileDataSource(DataSource):\n    """"""Represents a data source within the local filesystem.""""""\n\n    def __init__(self, root_path):\n        """"""\n        Args:\n            root_path:\n        """"""\n        super(LocalFileDataSource, self).__init__()\n\n        self.root_path = os.path.abspath(root_path)\n        if not os.path.exists(self.root_path):\n            raise RuntimeError(""Invalid data source: %s does not exist."" % self.root_path)\n\n    def get_file_list(self):\n        """"""Retrieve the list of absolute paths to all the files in this data\n        source.\n\n        Returns:\n            List[str] List of absolute paths.\n        """"""\n        if os.path.isdir(self.root_path):\n            return [\n                os.path.join(self.root_path, f)\n                for f in os.listdir(self.root_path)\n                if os.path.isfile(os.path.join(self.root_path, f))\n            ]\n        return [self.root_path]\n\n    def get_root_dir(self):\n        """"""Retrieve the absolute path to the root directory of this data source.\n\n        Returns:\n            str: absolute path to the root directory of this data source.\n        """"""\n        if os.path.isdir(self.root_path):\n            return self.root_path\n        return os.path.dirname(self.root_path)\n\n\nclass S3DataSource(DataSource):\n    """"""Defines a data source given by a bucket and S3 prefix. The contents will\n    be downloaded and then processed as local data.\n    """"""\n\n    def __init__(self, bucket, prefix, sagemaker_session):\n        """"""Create an S3DataSource instance\n\n        Args:\n            bucket (str): S3 bucket name\n            prefix (str): S3 prefix path to the data\n            sagemaker_session (:class:`sagemaker.session.Session`): a sagemaker_session with the\n            desired settings\n                to talk to S3\n        """"""\n        super(S3DataSource, self).__init__()\n\n        # Create a temporary dir to store the S3 contents\n        root_dir = sagemaker.utils.get_config_value(\n            ""local.container_root"", sagemaker_session.config\n        )\n        if root_dir:\n            root_dir = os.path.abspath(root_dir)\n\n        working_dir = tempfile.mkdtemp(dir=root_dir)\n        # Docker cannot mount Mac OS /var folder properly see\n        # https://forums.docker.com/t/var-folders-isnt-mounted-properly/9600\n        # Only apply this workaround if the user didn\'t provide an alternate storage root dir.\n        if root_dir is None and platform.system() == ""Darwin"":\n            working_dir = ""/private{}"".format(working_dir)\n\n        sagemaker.utils.download_folder(bucket, prefix, working_dir, sagemaker_session)\n        self.files = LocalFileDataSource(working_dir)\n\n    def get_file_list(self):\n        """"""Retrieve the list of absolute paths to all the files in this data\n        source.\n\n        Returns:\n            List[str]: List of absolute paths.\n        """"""\n        return self.files.get_file_list()\n\n    def get_root_dir(self):\n        """"""Retrieve the absolute path to the root directory of this data source.\n\n        Returns:\n            str: absolute path to the root directory of this data source.\n        """"""\n        return self.files.get_root_dir()\n\n\nclass Splitter(with_metaclass(ABCMeta, object)):\n    """"""Placeholder docstring""""""\n\n    @abstractmethod\n    def split(self, file):\n        """"""Split a file into records using a specific strategy\n\n        Args:\n            file (str): path to the file to split\n\n        Returns:\n            generator for the individual records that were split from the file\n        """"""\n\n\nclass NoneSplitter(Splitter):\n    """"""Does not split records, essentially reads the whole file.""""""\n\n    # non-utf8 characters.\n    _textchars = bytearray({7, 8, 9, 10, 12, 13, 27} | set(range(0x20, 0x100)) - {0x7F})\n\n    def split(self, filename):\n        """"""Split a file into records using a specific strategy.\n\n        For this NoneSplitter there is no actual split happening and the file\n        is returned as a whole.\n\n        Args:\n            filename (str): path to the file to split\n\n        Returns: generator for the individual records that were split from\n        the file\n        """"""\n        with open(filename, ""rb"") as f:\n            buf = f.read()\n            if not self._is_binary(buf):\n                buf = buf.decode()\n            yield buf\n\n    def _is_binary(self, buf):\n        """"""binary check.\n        Check whether `buf` contains binary data.\n        Returns true if `buf` contains any non-utf-8 characters.\n\n        Args:\n                    buf (bytes): data to inspect\n\n        Returns:\n                   True if data is binary, otherwise False\n        """"""\n        return bool(buf.translate(None, self._textchars))\n\n\nclass LineSplitter(Splitter):\n    """"""Split records by new line.""""""\n\n    def split(self, file):\n        """"""Split a file into records using a specific strategy\n\n        This LineSplitter splits the file on each line break.\n\n        Args:\n            file (str): path to the file to split\n\n        Returns: generator for the individual records that were split from\n        the file\n        """"""\n        with open(file, ""r"") as f:\n            for line in f:\n                yield line\n\n\nclass RecordIOSplitter(Splitter):\n    """"""Split using Amazon Recordio.\n\n    Not useful for string content.\n    """"""\n\n    def split(self, file):\n        """"""Split a file into records using a specific strategy\n\n        This RecordIOSplitter splits the data into individual RecordIO\n        records.\n\n        Args:\n            file (str): path to the file to split\n\n        Returns: generator for the individual records that were split from\n        the file\n        """"""\n        with open(file, ""rb"") as f:\n            for record in sagemaker.amazon.common.read_recordio(f):\n                yield record\n\n\nclass BatchStrategy(with_metaclass(ABCMeta, object)):\n    """"""Placeholder docstring""""""\n\n    def __init__(self, splitter):\n        """"""Create a Batch Strategy Instance\n\n        Args:\n            splitter (sagemaker.local.data.Splitter): A Splitter to pre-process\n                the data before batching.\n        """"""\n        self.splitter = splitter\n\n    @abstractmethod\n    def pad(self, file, size):\n        """"""Group together as many records as possible to fit in the specified\n        size\n\n        Args:\n            file (str): file path to read the records from.\n            size (int): maximum size in MB that each group of records will be\n                fitted to. passing 0 means unlimited size.\n\n        Returns:\n            generator of records\n        """"""\n\n\nclass MultiRecordStrategy(BatchStrategy):\n    """"""Feed multiple records at a time for batch inference.\n\n    Will group up as many records as possible within the payload specified.\n    """"""\n\n    def pad(self, file, size=6):\n        """"""Group together as many records as possible to fit in the specified\n        size\n\n        Args:\n            file (str): file path to read the records from.\n            size (int): maximum size in MB that each group of records will be\n                fitted to. passing 0 means unlimited size.\n\n        Returns:\n            generator of records\n        """"""\n        buffer = """"\n        for element in self.splitter.split(file):\n            if _payload_size_within_limit(buffer + element, size):\n                buffer += element\n            else:\n                tmp = buffer\n                buffer = element\n                yield tmp\n        if _validate_payload_size(buffer, size):\n            yield buffer\n\n\nclass SingleRecordStrategy(BatchStrategy):\n    """"""Feed a single record at a time for batch inference.\n\n    If a single record does not fit within the payload specified it will\n    throw a RuntimeError.\n    """"""\n\n    def pad(self, file, size=6):\n        """"""Group together as many records as possible to fit in the specified\n        size\n\n        This SingleRecordStrategy will not group any record and will return\n        them one by one as long as they are within the maximum size.\n\n        Args:\n            file (str): file path to read the records from.\n            size (int): maximum size in MB that each group of records will be\n                fitted to. passing 0 means unlimited size.\n\n        Returns:\n            generator of records\n        """"""\n        for element in self.splitter.split(file):\n            if _validate_payload_size(element, size):\n                yield element\n\n\ndef _payload_size_within_limit(payload, size):\n    """"""\n    Args:\n        payload:\n        size:\n    """"""\n    size_in_bytes = size * 1024 * 1024\n    if size == 0:\n        return True\n    return sys.getsizeof(payload) < size_in_bytes\n\n\ndef _validate_payload_size(payload, size):\n    """"""Check if a payload is within the size in MB threshold. Raise an exception\n    otherwise.\n\n    Args:\n        payload: data that will be checked\n        size (int): max size in MB\n\n    Returns:\n        bool: True if within bounds. if size=0 it will always return True\n\n    Raises:\n        RuntimeError: If the payload is larger a runtime error is thrown.\n    """"""\n\n    if _payload_size_within_limit(payload, size):\n        return True\n    raise RuntimeError(""Record is larger than %sMB. Please increase your max_payload"" % size)\n'"
src/sagemaker/local/entities.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nimport datetime\nimport json\nimport logging\nimport os\nimport tempfile\nimport time\n\nimport sagemaker.local.data\nfrom sagemaker.local.image import _SageMakerContainer\nfrom sagemaker.local.utils import copy_directory_structure, move_to_destination\nfrom sagemaker.utils import DeferredError, get_config_value\n\ntry:\n    import urllib3\nexcept ImportError as e:\n    logging.warning(""urllib3 failed to import. Local mode features will be impaired or broken."")\n    # Any subsequent attempt to use urllib3 will raise the ImportError\n    urllib3 = DeferredError(e)\n\n\nlogger = logging.getLogger(__name__)\n\n_UNUSED_ARN = ""local:arn-does-not-matter""\nHEALTH_CHECK_TIMEOUT_LIMIT = 120\n\n\nclass _LocalTrainingJob(object):\n    """"""Placeholder docstring""""""\n\n    _STARTING = ""Starting""\n    _TRAINING = ""Training""\n    _COMPLETED = ""Completed""\n    _states = [""Starting"", ""Training"", ""Completed""]\n\n    def __init__(self, container):\n        """"""\n        Args:\n            container:\n        """"""\n        self.container = container\n        self.model_artifacts = None\n        self.state = ""created""\n        self.start_time = None\n        self.end_time = None\n\n    def start(self, input_data_config, output_data_config, hyperparameters, job_name):\n        """"""\n        Args:\n            input_data_config:\n            output_data_config:\n            hyperparameters:\n            job_name:\n        """"""\n        for channel in input_data_config:\n            if channel[""DataSource""] and ""S3DataSource"" in channel[""DataSource""]:\n                data_distribution = channel[""DataSource""][""S3DataSource""][""S3DataDistributionType""]\n                data_uri = channel[""DataSource""][""S3DataSource""][""S3Uri""]\n            elif channel[""DataSource""] and ""FileDataSource"" in channel[""DataSource""]:\n                data_distribution = channel[""DataSource""][""FileDataSource""][\n                    ""FileDataDistributionType""\n                ]\n                data_uri = channel[""DataSource""][""FileDataSource""][""FileUri""]\n            else:\n                raise ValueError(\n                    ""Need channel[\'DataSource\'] to have [\'S3DataSource\'] or [\'FileDataSource\']""\n                )\n\n            # use a single Data URI - this makes handling S3 and File Data easier down the stack\n            channel[""DataUri""] = data_uri\n\n            if data_distribution != ""FullyReplicated"":\n                raise RuntimeError(\n                    ""DataDistribution: %s is not currently supported in Local Mode""\n                    % data_distribution\n                )\n\n        self.start_time = datetime.datetime.now()\n        self.state = self._TRAINING\n\n        self.model_artifacts = self.container.train(\n            input_data_config, output_data_config, hyperparameters, job_name\n        )\n        self.end_time = datetime.datetime.now()\n        self.state = self._COMPLETED\n\n    def describe(self):\n        """"""Placeholder docstring""""""\n        response = {\n            ""ResourceConfig"": {""InstanceCount"": self.container.instance_count},\n            ""TrainingJobStatus"": self.state,\n            ""TrainingStartTime"": self.start_time,\n            ""TrainingEndTime"": self.end_time,\n            ""ModelArtifacts"": {""S3ModelArtifacts"": self.model_artifacts},\n        }\n        return response\n\n\nclass _LocalTransformJob(object):\n    """"""Placeholder docstring""""""\n\n    _CREATING = ""Creating""\n    _COMPLETED = ""Completed""\n\n    def __init__(self, transform_job_name, model_name, local_session=None):\n        """"""\n        Args:\n            transform_job_name:\n            model_name:\n            local_session:\n        """"""\n        from sagemaker.local import LocalSession\n\n        self.local_session = local_session or LocalSession()\n        local_client = self.local_session.sagemaker_client\n\n        self.name = transform_job_name\n        self.model_name = model_name\n\n        # TODO - support SageMaker Models not just local models. This is not\n        # ideal but it may be a good thing to do.\n        self.primary_container = local_client.describe_model(model_name)[""PrimaryContainer""]\n        self.container = None\n        self.start_time = None\n        self.end_time = None\n        self.batch_strategy = None\n        self.transform_resources = None\n        self.input_data = None\n        self.output_data = None\n        self.environment = {}\n        self.state = _LocalTransformJob._CREATING\n\n    def start(self, input_data, output_data, transform_resources, **kwargs):\n        """"""Start the Local Transform Job\n\n        Args:\n            input_data (dict): Describes the dataset to be transformed and the\n                location where it is stored.\n            output_data (dict): Identifies the location where to save the\n                results from the transform job\n            transform_resources (dict): compute instances for the transform job.\n                Currently only supports local or local_gpu\n            **kwargs: additional arguments coming from the boto request object\n        """"""\n        self.transform_resources = transform_resources\n        self.input_data = input_data\n        self.output_data = output_data\n\n        image = self.primary_container[""Image""]\n        instance_type = transform_resources[""InstanceType""]\n        instance_count = 1\n\n        environment = self._get_container_environment(**kwargs)\n\n        # Start the container, pass the environment and wait for it to start up\n        self.container = _SageMakerContainer(\n            instance_type, instance_count, image, self.local_session\n        )\n        self.container.serve(self.primary_container[""ModelDataUrl""], environment)\n\n        serving_port = get_config_value(""local.serving_port"", self.local_session.config) or 8080\n        _wait_for_serving_container(serving_port)\n\n        # Get capabilities from Container if needed\n        endpoint_url = ""http://localhost:%s/execution-parameters"" % serving_port\n        response, code = _perform_request(endpoint_url)\n        if code == 200:\n            execution_parameters = json.loads(response.read())\n            # MaxConcurrentTransforms is ignored because we currently only support 1\n            for setting in (""BatchStrategy"", ""MaxPayloadInMB""):\n                if setting not in kwargs and setting in execution_parameters:\n                    kwargs[setting] = execution_parameters[setting]\n\n        # Apply Defaults if none was provided\n        kwargs.update(self._get_required_defaults(**kwargs))\n\n        self.start_time = datetime.datetime.now()\n        self.batch_strategy = kwargs[""BatchStrategy""]\n        if ""Environment"" in kwargs:\n            self.environment = kwargs[""Environment""]\n\n        # run the batch inference requests\n        self._perform_batch_inference(input_data, output_data, **kwargs)\n        self.end_time = datetime.datetime.now()\n        self.state = self._COMPLETED\n\n    def describe(self):\n        """"""Describe this _LocalTransformJob\n\n        The response is a JSON-like dictionary that follows the response of\n        the boto describe_transform_job() API.\n\n        Returns:\n            dict: description of this _LocalTransformJob\n        """"""\n        response = {\n            ""TransformJobStatus"": self.state,\n            ""ModelName"": self.model_name,\n            ""TransformJobName"": self.name,\n            ""TransformJobArn"": _UNUSED_ARN,\n            ""TransformEndTime"": self.end_time,\n            ""CreationTime"": self.start_time,\n            ""TransformStartTime"": self.start_time,\n            ""Environment"": {},\n            ""BatchStrategy"": self.batch_strategy,\n        }\n\n        if self.transform_resources:\n            response[""TransformResources""] = self.transform_resources\n\n        if self.output_data:\n            response[""TransformOutput""] = self.output_data\n\n        if self.input_data:\n            response[""TransformInput""] = self.input_data\n\n        return response\n\n    def _get_container_environment(self, **kwargs):\n        """"""Get all the Environment variables that will be passed to the\n        container\n\n        Certain input fields such as BatchStrategy have different values for\n        the API vs the Environment variables, such as SingleRecord vs\n        SINGLE_RECORD. This method also handles this conversion.\n\n        Args:\n            **kwargs: existing transform arguments\n\n        Returns:\n            dict: All the environment variables that should be set in the\n            container\n        """"""\n        environment = {}\n        environment.update(self.primary_container[""Environment""])\n        environment[""SAGEMAKER_BATCH""] = ""True""\n        if ""MaxPayloadInMB"" in kwargs:\n            environment[""SAGEMAKER_MAX_PAYLOAD_IN_MB""] = str(kwargs[""MaxPayloadInMB""])\n\n        if ""BatchStrategy"" in kwargs:\n            if kwargs[""BatchStrategy""] == ""SingleRecord"":\n                strategy_env_value = ""SINGLE_RECORD""\n            elif kwargs[""BatchStrategy""] == ""MultiRecord"":\n                strategy_env_value = ""MULTI_RECORD""\n            else:\n                raise ValueError(""Invalid BatchStrategy, must be \'SingleRecord\' or \'MultiRecord\'"")\n            environment[""SAGEMAKER_BATCH_STRATEGY""] = strategy_env_value\n\n        # we only do 1 max concurrent transform in Local Mode\n        if ""MaxConcurrentTransforms"" in kwargs and int(kwargs[""MaxConcurrentTransforms""]) > 1:\n            logger.warning(\n                ""Local Mode only supports 1 ConcurrentTransform. Setting MaxConcurrentTransforms ""\n                ""to 1""\n            )\n        environment[""SAGEMAKER_MAX_CONCURRENT_TRANSFORMS""] = ""1""\n\n        # if there were environment variables passed to the Transformer we will pass them to the\n        # container as well.\n        if ""Environment"" in kwargs:\n            environment.update(kwargs[""Environment""])\n        return environment\n\n    def _get_required_defaults(self, **kwargs):\n        """"""Return the default values for anything that was not provided by\n        either the user or the container\n\n        Args:\n            **kwargs: current transform arguments\n\n        Returns:\n            dict: key/values for the default parameters that are missing.\n        """"""\n        defaults = {}\n        if ""BatchStrategy"" not in kwargs:\n            defaults[""BatchStrategy""] = ""MultiRecord""\n\n        if ""MaxPayloadInMB"" not in kwargs:\n            defaults[""MaxPayloadInMB""] = 6\n\n        return defaults\n\n    def _get_working_directory(self):\n        """"""Placeholder docstring""""""\n        # Root dir to use for intermediate data location. To make things simple we will write here\n        # regardless of the final destination. At the end the files will either be moved or\n        # uploaded to S3 and deleted.\n        root_dir = get_config_value(""local.container_root"", self.local_session.config)\n        if root_dir:\n            root_dir = os.path.abspath(root_dir)\n\n        working_dir = tempfile.mkdtemp(dir=root_dir)\n        return working_dir\n\n    def _prepare_data_transformation(self, input_data, batch_strategy):\n        """"""\n        Args:\n            input_data:\n            batch_strategy:\n        """"""\n        input_path = input_data[""DataSource""][""S3DataSource""][""S3Uri""]\n        data_source = sagemaker.local.data.get_data_source_instance(input_path, self.local_session)\n\n        split_type = input_data[""SplitType""] if ""SplitType"" in input_data else None\n        splitter = sagemaker.local.data.get_splitter_instance(split_type)\n\n        batch_provider = sagemaker.local.data.get_batch_strategy_instance(batch_strategy, splitter)\n        return data_source, batch_provider\n\n    def _perform_batch_inference(self, input_data, output_data, **kwargs):\n        # Transform the input data to feed the serving container. We need to first gather the files\n        # from S3 or Local FileSystem. Split them as required (Line, RecordIO, None) and finally\n        # batch them according to the batch strategy and limit the request size.\n\n        """"""\n        Args:\n            input_data:\n            output_data:\n            **kwargs:\n        """"""\n        batch_strategy = kwargs[""BatchStrategy""]\n        max_payload = int(kwargs[""MaxPayloadInMB""])\n        data_source, batch_provider = self._prepare_data_transformation(input_data, batch_strategy)\n\n        # Output settings\n        accept = output_data[""Accept""] if ""Accept"" in output_data else None\n\n        working_dir = self._get_working_directory()\n        dataset_dir = data_source.get_root_dir()\n\n        for file in data_source.get_file_list():\n\n            relative_path = os.path.dirname(os.path.relpath(file, dataset_dir))\n            filename = os.path.basename(file)\n            copy_directory_structure(working_dir, relative_path)\n            destination_path = os.path.join(working_dir, relative_path, filename + "".out"")\n\n            with open(destination_path, ""wb"") as f:\n                for item in batch_provider.pad(file, max_payload):\n                    # call the container and add the result to inference.\n                    response = self.local_session.sagemaker_runtime_client.invoke_endpoint(\n                        item, """", input_data[""ContentType""], accept\n                    )\n\n                    response_body = response[""Body""]\n                    data = response_body.read()\n                    response_body.close()\n                    f.write(data)\n                    if ""AssembleWith"" in output_data and output_data[""AssembleWith""] == ""Line"":\n                        f.write(b""\\n"")\n\n        move_to_destination(working_dir, output_data[""S3OutputPath""], self.name, self.local_session)\n        self.container.stop_serving()\n\n\nclass _LocalModel(object):\n    """"""Placeholder docstring""""""\n\n    def __init__(self, model_name, primary_container):\n        """"""\n        Args:\n            model_name:\n            primary_container:\n        """"""\n        self.model_name = model_name\n        self.primary_container = primary_container\n        self.creation_time = datetime.datetime.now()\n\n    def describe(self):\n        """"""Placeholder docstring""""""\n        response = {\n            ""ModelName"": self.model_name,\n            ""CreationTime"": self.creation_time,\n            ""ExecutionRoleArn"": _UNUSED_ARN,\n            ""ModelArn"": _UNUSED_ARN,\n            ""PrimaryContainer"": self.primary_container,\n        }\n        return response\n\n\nclass _LocalEndpointConfig(object):\n    """"""Placeholder docstring""""""\n\n    def __init__(self, config_name, production_variants, tags=None):\n        """"""\n        Args:\n            config_name:\n            production_variants:\n            tags:\n        """"""\n        self.name = config_name\n        self.production_variants = production_variants\n        self.tags = tags\n        self.creation_time = datetime.datetime.now()\n\n    def describe(self):\n        """"""Placeholder docstring""""""\n        response = {\n            ""EndpointConfigName"": self.name,\n            ""EndpointConfigArn"": _UNUSED_ARN,\n            ""Tags"": self.tags,\n            ""CreationTime"": self.creation_time,\n            ""ProductionVariants"": self.production_variants,\n        }\n        return response\n\n\nclass _LocalEndpoint(object):\n    """"""Placeholder docstring""""""\n\n    _CREATING = ""Creating""\n    _IN_SERVICE = ""InService""\n    _FAILED = ""Failed""\n\n    def __init__(self, endpoint_name, endpoint_config_name, tags=None, local_session=None):\n        # runtime import since there is a cyclic dependency between entities and local_session\n        """"""\n        Args:\n            endpoint_name:\n            endpoint_config_name:\n            tags:\n            local_session:\n        """"""\n        from sagemaker.local import LocalSession\n\n        self.local_session = local_session or LocalSession()\n        local_client = self.local_session.sagemaker_client\n\n        self.name = endpoint_name\n        self.endpoint_config = local_client.describe_endpoint_config(endpoint_config_name)\n        self.production_variant = self.endpoint_config[""ProductionVariants""][0]\n        self.tags = tags\n\n        model_name = self.production_variant[""ModelName""]\n        self.primary_container = local_client.describe_model(model_name)[""PrimaryContainer""]\n\n        self.container = None\n        self.create_time = None\n        self.state = _LocalEndpoint._CREATING\n\n    def serve(self):\n        """"""Placeholder docstring""""""\n        image = self.primary_container[""Image""]\n        instance_type = self.production_variant[""InstanceType""]\n        instance_count = self.production_variant[""InitialInstanceCount""]\n\n        accelerator_type = self.production_variant.get(""AcceleratorType"")\n        if accelerator_type == ""local_sagemaker_notebook"":\n            self.primary_container[""Environment""][\n                ""SAGEMAKER_INFERENCE_ACCELERATOR_PRESENT""\n            ] = ""true""\n\n        self.create_time = datetime.datetime.now()\n        self.container = _SageMakerContainer(\n            instance_type, instance_count, image, self.local_session\n        )\n        self.container.serve(\n            self.primary_container[""ModelDataUrl""], self.primary_container[""Environment""]\n        )\n\n        serving_port = get_config_value(""local.serving_port"", self.local_session.config) or 8080\n        _wait_for_serving_container(serving_port)\n        # the container is running and it passed the healthcheck status is now InService\n        self.state = _LocalEndpoint._IN_SERVICE\n\n    def stop(self):\n        """"""Placeholder docstring""""""\n        if self.container:\n            self.container.stop_serving()\n\n    def describe(self):\n        """"""Placeholder docstring""""""\n        response = {\n            ""EndpointConfigName"": self.endpoint_config[""EndpointConfigName""],\n            ""CreationTime"": self.create_time,\n            ""ProductionVariants"": self.endpoint_config[""ProductionVariants""],\n            ""Tags"": self.tags,\n            ""EndpointName"": self.name,\n            ""EndpointArn"": _UNUSED_ARN,\n            ""EndpointStatus"": self.state,\n        }\n        return response\n\n\ndef _wait_for_serving_container(serving_port):\n    """"""\n    Args:\n        serving_port:\n    """"""\n    i = 0\n    http = urllib3.PoolManager()\n\n    endpoint_url = ""http://localhost:%s/ping"" % serving_port\n    while True:\n        i += 5\n        if i >= HEALTH_CHECK_TIMEOUT_LIMIT:\n            raise RuntimeError(""Giving up, endpoint didn\'t launch correctly"")\n\n        logger.info(""Checking if serving container is up, attempt: %s"", i)\n        _, code = _perform_request(endpoint_url, http)\n        if code != 200:\n            logger.info(""Container still not up, got: %s"", code)\n        else:\n            return\n\n        time.sleep(5)\n\n\ndef _perform_request(endpoint_url, pool_manager=None):\n    """"""\n    Args:\n        endpoint_url:\n        pool_manager:\n    """"""\n    http = pool_manager or urllib3.PoolManager()\n    try:\n        r = http.request(""GET"", endpoint_url)\n        code = r.status\n    except urllib3.exceptions.RequestError:\n        return None, -1\n    return r, code\n'"
src/sagemaker/local/image.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nimport base64\nimport errno\nimport json\nimport logging\nimport os\nimport platform\nimport random\nimport re\nimport shlex\nimport shutil\nimport string\nimport subprocess\nimport sys\nimport tarfile\nimport tempfile\n\nfrom distutils.spawn import find_executable\nfrom threading import Thread\nfrom six.moves.urllib.parse import urlparse\n\nimport sagemaker\nimport sagemaker.local.data\nimport sagemaker.local.utils\nimport sagemaker.utils\n\nCONTAINER_PREFIX = ""algo""\nDOCKER_COMPOSE_FILENAME = ""docker-compose.yaml""\nDOCKER_COMPOSE_HTTP_TIMEOUT_ENV = ""COMPOSE_HTTP_TIMEOUT""\nDOCKER_COMPOSE_HTTP_TIMEOUT = ""120""\n\n# Environment variables to be set during training\nREGION_ENV_NAME = ""AWS_REGION""\nTRAINING_JOB_NAME_ENV_NAME = ""TRAINING_JOB_NAME""\nS3_ENDPOINT_URL_ENV_NAME = ""S3_ENDPOINT_URL""\n\nlogger = logging.getLogger(__name__)\n\n\nclass _SageMakerContainer(object):\n    """"""Handle the lifecycle and configuration of a local docker container\n    execution.\n\n    This class is responsible for creating the directories and configuration\n    files that the docker containers will use for either training or serving.\n    """"""\n\n    def __init__(self, instance_type, instance_count, image, sagemaker_session=None):\n        """"""Initialize a SageMakerContainer instance\n\n        It uses a :class:`sagemaker.session.Session` for general interaction\n        with user configuration such as getting the default sagemaker S3 bucket.\n        However this class does not call any of the SageMaker APIs.\n\n        Args:\n            instance_type (str): The instance type to use. Either \'local\' or\n                \'local_gpu\'\n            instance_count (int): The number of instances to create.\n            image (str): docker image to use.\n            sagemaker_session (sagemaker.session.Session): a sagemaker session\n                to use when interacting with SageMaker.\n        """"""\n        from sagemaker.local.local_session import LocalSession\n\n        # check if docker-compose is installed\n        if find_executable(""docker-compose"") is None:\n            raise ImportError(\n                ""\'docker-compose\' is not installed. ""\n                ""Local Mode features will not work without docker-compose. ""\n                ""For more information on how to install \'docker-compose\', please, see ""\n                ""https://docs.docker.com/compose/install/""\n            )\n\n        self.sagemaker_session = sagemaker_session or LocalSession()\n        self.instance_type = instance_type\n        self.instance_count = instance_count\n        self.image = image\n        # Since we are using a single docker network, Generate a random suffix to attach to the\n        # container names. This way multiple jobs can run in parallel.\n        suffix = """".join(random.choice(string.ascii_lowercase + string.digits) for _ in range(5))\n        self.hosts = [\n            ""{}-{}-{}"".format(CONTAINER_PREFIX, i, suffix)\n            for i in range(1, self.instance_count + 1)\n        ]\n        self.container_root = None\n        self.container = None\n\n    def train(self, input_data_config, output_data_config, hyperparameters, job_name):\n        """"""Run a training job locally using docker-compose.\n\n        Args:\n            input_data_config (dict): The Input Data Configuration, this contains data such as the\n                channels to be used for training.\n            output_data_config:\n            hyperparameters (dict): The HyperParameters for the training job.\n            job_name (str): Name of the local training job being run.\n\n        Returns (str): Location of the trained model.\n        """"""\n        self.container_root = self._create_tmp_folder()\n        os.mkdir(os.path.join(self.container_root, ""output""))\n        # create output/data folder since sagemaker-containers 2.0 expects it\n        os.mkdir(os.path.join(self.container_root, ""output"", ""data""))\n        # A shared directory for all the containers. It is only mounted if the training script is\n        # Local.\n        shared_dir = os.path.join(self.container_root, ""shared"")\n        os.mkdir(shared_dir)\n\n        data_dir = self._create_tmp_folder()\n        volumes = self._prepare_training_volumes(\n            data_dir, input_data_config, output_data_config, hyperparameters\n        )\n        # If local, source directory needs to be updated to mounted /opt/ml/code path\n        hyperparameters = self._update_local_src_path(\n            hyperparameters, key=sagemaker.estimator.DIR_PARAM_NAME\n        )\n\n        # Create the configuration files for each container that we will create\n        # Each container will map the additional local volumes (if any).\n        for host in self.hosts:\n            _create_config_file_directories(self.container_root, host)\n            self.write_config_files(host, hyperparameters, input_data_config)\n            shutil.copytree(data_dir, os.path.join(self.container_root, host, ""input"", ""data""))\n\n        training_env_vars = {\n            REGION_ENV_NAME: self.sagemaker_session.boto_region_name,\n            TRAINING_JOB_NAME_ENV_NAME: job_name,\n        }\n        if self.sagemaker_session.s3_resource is not None:\n            training_env_vars[\n                S3_ENDPOINT_URL_ENV_NAME\n            ] = self.sagemaker_session.s3_resource.meta.client._endpoint.host\n\n        compose_data = self._generate_compose_file(\n            ""train"", additional_volumes=volumes, additional_env_vars=training_env_vars\n        )\n        compose_command = self._compose()\n\n        if _ecr_login_if_needed(self.sagemaker_session.boto_session, self.image):\n            _pull_image(self.image)\n\n        process = subprocess.Popen(\n            compose_command, stdout=subprocess.PIPE, stderr=subprocess.STDOUT\n        )\n\n        try:\n            _stream_output(process)\n        except RuntimeError as e:\n            # _stream_output() doesn\'t have the command line. We will handle the exception\n            # which contains the exit code and append the command line to it.\n            msg = ""Failed to run: %s, %s"" % (compose_command, str(e))\n            raise RuntimeError(msg)\n        finally:\n            artifacts = self.retrieve_artifacts(compose_data, output_data_config, job_name)\n\n            # free up the training data directory as it may contain\n            # lots of data downloaded from S3. This doesn\'t delete any local\n            # data that was just mounted to the container.\n            dirs_to_delete = [data_dir, shared_dir]\n            self._cleanup(dirs_to_delete)\n\n        # Print our Job Complete line to have a similar experience to training on SageMaker where\n        # you see this line at the end.\n        print(""===== Job Complete ====="")\n        return artifacts\n\n    def serve(self, model_dir, environment):\n        """"""Host a local endpoint using docker-compose.\n        Args:\n            primary_container (dict): dictionary containing the container runtime settings\n                for serving. Expected keys:\n                - \'ModelDataUrl\' pointing to a file or s3:// location.\n                - \'Environment\' a dictionary of environment variables to be passed to the\n                    hosting container.\n\n        """"""\n        logger.info(""serving"")\n\n        self.container_root = self._create_tmp_folder()\n        logger.info(""creating hosting dir in %s"", self.container_root)\n\n        volumes = self._prepare_serving_volumes(model_dir)\n\n        # If the user script was passed as a file:// mount it to the container.\n        if sagemaker.estimator.DIR_PARAM_NAME.upper() in environment:\n            script_dir = environment[sagemaker.estimator.DIR_PARAM_NAME.upper()]\n            parsed_uri = urlparse(script_dir)\n            if parsed_uri.scheme == ""file"":\n                volumes.append(_Volume(parsed_uri.path, ""/opt/ml/code""))\n                # Update path to mount location\n                environment = environment.copy()\n                environment[sagemaker.estimator.DIR_PARAM_NAME.upper()] = ""/opt/ml/code""\n\n        if _ecr_login_if_needed(self.sagemaker_session.boto_session, self.image):\n            _pull_image(self.image)\n\n        self._generate_compose_file(\n            ""serve"", additional_env_vars=environment, additional_volumes=volumes\n        )\n        compose_command = self._compose()\n\n        self.container = _HostingContainer(compose_command)\n        self.container.start()\n\n    def stop_serving(self):\n        """"""Stop the serving container.\n\n        The serving container runs in async mode to allow the SDK to do other\n        tasks.\n        """"""\n        if self.container:\n            self.container.down()\n            self.container.join()\n            self._cleanup()\n        # for serving we can delete everything in the container root.\n        _delete_tree(self.container_root)\n\n    def retrieve_artifacts(self, compose_data, output_data_config, job_name):\n        """"""Get the model artifacts from all the container nodes.\n\n        Used after training completes to gather the data from all the\n        individual containers. As the official SageMaker Training Service, it\n        will override duplicate files if multiple containers have the same file\n        names.\n\n        Args:\n            compose_data (dict): Docker-Compose configuration in dictionary\n                format.\n            output_data_config:\n            job_name:\n\n        Returns: Local path to the collected model artifacts.\n        """"""\n        # We need a directory to store the artfiacts from all the nodes\n        # and another one to contained the compressed final artifacts\n        artifacts = os.path.join(self.container_root, ""artifacts"")\n        compressed_artifacts = os.path.join(self.container_root, ""compressed_artifacts"")\n        os.mkdir(artifacts)\n\n        model_artifacts = os.path.join(artifacts, ""model"")\n        output_artifacts = os.path.join(artifacts, ""output"")\n\n        artifact_dirs = [model_artifacts, output_artifacts, compressed_artifacts]\n        for d in artifact_dirs:\n            os.mkdir(d)\n\n        # Gather the artifacts from all nodes into artifacts/model and artifacts/output\n        for host in self.hosts:\n            volumes = compose_data[""services""][str(host)][""volumes""]\n            for volume in volumes:\n                if re.search(r""^[A-Za-z]:"", volume):\n                    unit, host_dir, container_dir = volume.split("":"")\n                    host_dir = unit + "":"" + host_dir\n                else:\n                    host_dir, container_dir = volume.split("":"")\n                if container_dir == ""/opt/ml/model"":\n                    sagemaker.local.utils.recursive_copy(host_dir, model_artifacts)\n                elif container_dir == ""/opt/ml/output"":\n                    sagemaker.local.utils.recursive_copy(host_dir, output_artifacts)\n\n        # Tar Artifacts -> model.tar.gz and output.tar.gz\n        model_files = [os.path.join(model_artifacts, name) for name in os.listdir(model_artifacts)]\n        output_files = [\n            os.path.join(output_artifacts, name) for name in os.listdir(output_artifacts)\n        ]\n        sagemaker.utils.create_tar_file(\n            model_files, os.path.join(compressed_artifacts, ""model.tar.gz"")\n        )\n        sagemaker.utils.create_tar_file(\n            output_files, os.path.join(compressed_artifacts, ""output.tar.gz"")\n        )\n\n        if output_data_config[""S3OutputPath""] == """":\n            output_data = ""file://%s"" % compressed_artifacts\n        else:\n            # Now we just need to move the compressed artifacts to wherever they are required\n            output_data = sagemaker.local.utils.move_to_destination(\n                compressed_artifacts,\n                output_data_config[""S3OutputPath""],\n                job_name,\n                self.sagemaker_session,\n            )\n\n        _delete_tree(model_artifacts)\n        _delete_tree(output_artifacts)\n\n        return os.path.join(output_data, ""model.tar.gz"")\n\n    def write_config_files(self, host, hyperparameters, input_data_config):\n        """"""Write the config files for the training containers.\n\n        This method writes the hyperparameters, resources and input data\n        configuration files.\n\n        Returns: None\n\n        Args:\n            host (str): Host to write the configuration for\n            hyperparameters (dict): Hyperparameters for training.\n            input_data_config (dict): Training input channels to be used for\n                training.\n        """"""\n        config_path = os.path.join(self.container_root, host, ""input"", ""config"")\n\n        resource_config = {""current_host"": host, ""hosts"": self.hosts}\n\n        json_input_data_config = {}\n        for c in input_data_config:\n            channel_name = c[""ChannelName""]\n            json_input_data_config[channel_name] = {""TrainingInputMode"": ""File""}\n            if ""ContentType"" in c:\n                json_input_data_config[channel_name][""ContentType""] = c[""ContentType""]\n\n        _write_json_file(os.path.join(config_path, ""hyperparameters.json""), hyperparameters)\n        _write_json_file(os.path.join(config_path, ""resourceconfig.json""), resource_config)\n        _write_json_file(os.path.join(config_path, ""inputdataconfig.json""), json_input_data_config)\n\n    def _prepare_training_volumes(\n        self, data_dir, input_data_config, output_data_config, hyperparameters\n    ):\n        """"""\n        Args:\n            data_dir:\n            input_data_config:\n            output_data_config:\n            hyperparameters:\n        """"""\n        shared_dir = os.path.join(self.container_root, ""shared"")\n        model_dir = os.path.join(self.container_root, ""model"")\n        volumes = []\n\n        volumes.append(_Volume(model_dir, ""/opt/ml/model""))\n        # Set up the channels for the containers. For local data we will\n        # mount the local directory to the container. For S3 Data we will download the S3 data\n        # first.\n        for channel in input_data_config:\n            uri = channel[""DataUri""]\n            channel_name = channel[""ChannelName""]\n            channel_dir = os.path.join(data_dir, channel_name)\n            os.mkdir(channel_dir)\n\n            data_source = sagemaker.local.data.get_data_source_instance(uri, self.sagemaker_session)\n            volumes.append(_Volume(data_source.get_root_dir(), channel=channel_name))\n\n        # If there is a training script directory and it is a local directory,\n        # mount it to the container.\n        if sagemaker.estimator.DIR_PARAM_NAME in hyperparameters:\n            training_dir = json.loads(hyperparameters[sagemaker.estimator.DIR_PARAM_NAME])\n            parsed_uri = urlparse(training_dir)\n            if parsed_uri.scheme == ""file"":\n                volumes.append(_Volume(parsed_uri.path, ""/opt/ml/code""))\n                # Also mount a directory that all the containers can access.\n                volumes.append(_Volume(shared_dir, ""/opt/ml/shared""))\n\n        parsed_uri = urlparse(output_data_config[""S3OutputPath""])\n        if (\n            parsed_uri.scheme == ""file""\n            and sagemaker.model.SAGEMAKER_OUTPUT_LOCATION in hyperparameters\n        ):\n            intermediate_dir = os.path.join(parsed_uri.path, ""output"", ""intermediate"")\n            if not os.path.exists(intermediate_dir):\n                os.makedirs(intermediate_dir)\n            volumes.append(_Volume(intermediate_dir, ""/opt/ml/output/intermediate""))\n\n        return volumes\n\n    def _update_local_src_path(self, params, key):\n        """"""\n        Args:\n            params:\n            key:\n        """"""\n        if key in params:\n            src_dir = json.loads(params[key])\n            parsed_uri = urlparse(src_dir)\n            if parsed_uri.scheme == ""file"":\n                new_params = params.copy()\n                new_params[key] = json.dumps(""/opt/ml/code"")\n                return new_params\n        return params\n\n    def _prepare_serving_volumes(self, model_location):\n        """"""\n        Args:\n            model_location:\n        """"""\n        volumes = []\n        host = self.hosts[0]\n        # Make the model available to the container. If this is a local file just mount it to\n        # the container as a volume. If it is an S3 location, the DataSource will download it, we\n        # just need to extract the tar file.\n        host_dir = os.path.join(self.container_root, host)\n        os.makedirs(host_dir)\n\n        model_data_source = sagemaker.local.data.get_data_source_instance(\n            model_location, self.sagemaker_session\n        )\n\n        for filename in model_data_source.get_file_list():\n            if tarfile.is_tarfile(filename):\n                with tarfile.open(filename) as tar:\n                    tar.extractall(path=model_data_source.get_root_dir())\n\n        volumes.append(_Volume(model_data_source.get_root_dir(), ""/opt/ml/model""))\n\n        return volumes\n\n    def _generate_compose_file(self, command, additional_volumes=None, additional_env_vars=None):\n        """"""Writes a config file describing a training/hosting environment.\n\n        This method generates a docker compose configuration file, it has an\n        entry for each container that will be created (based on self.hosts). it\n        calls\n        :meth:~sagemaker.local_session.SageMakerContainer._create_docker_host to\n        generate the config for each individual container.\n\n        Args:\n            command (str): either \'train\' or \'serve\'\n            additional_volumes (list): a list of volumes that will be mapped to\n                the containers\n            additional_env_vars (dict): a dictionary with additional environment\n                variables to be passed on to the containers.\n\n        Returns: (dict) A dictionary representation of the configuration that was written.\n        """"""\n        boto_session = self.sagemaker_session.boto_session\n        additional_volumes = additional_volumes or []\n        additional_env_vars = additional_env_vars or {}\n        environment = []\n        optml_dirs = set()\n\n        aws_creds = _aws_credentials(boto_session)\n        if aws_creds is not None:\n            environment.extend(aws_creds)\n\n        additional_env_var_list = [""{}={}"".format(k, v) for k, v in additional_env_vars.items()]\n        environment.extend(additional_env_var_list)\n\n        if os.environ.get(DOCKER_COMPOSE_HTTP_TIMEOUT_ENV) is None:\n            os.environ[DOCKER_COMPOSE_HTTP_TIMEOUT_ENV] = DOCKER_COMPOSE_HTTP_TIMEOUT\n\n        if command == ""train"":\n            optml_dirs = {""output"", ""output/data"", ""input""}\n\n        services = {\n            h: self._create_docker_host(h, environment, optml_dirs, command, additional_volumes)\n            for h in self.hosts\n        }\n\n        content = {\n            # Use version 2.3 as a minimum so that we can specify the runtime\n            ""version"": ""2.3"",\n            ""services"": services,\n            ""networks"": {""sagemaker-local"": {""name"": ""sagemaker-local""}},\n        }\n\n        docker_compose_path = os.path.join(self.container_root, DOCKER_COMPOSE_FILENAME)\n\n        try:\n            import yaml\n        except ImportError as e:\n            logging.error(sagemaker.utils._module_import_error(""yaml"", ""Local mode"", ""local""))\n            raise e\n\n        yaml_content = yaml.dump(content, default_flow_style=False)\n        logger.info(""docker compose file: \\n%s"", yaml_content)\n        with open(docker_compose_path, ""w"") as f:\n            f.write(yaml_content)\n\n        return content\n\n    def _compose(self, detached=False):\n        """"""\n        Args:\n            detached:\n        """"""\n        compose_cmd = ""docker-compose""\n\n        command = [\n            compose_cmd,\n            ""-f"",\n            os.path.join(self.container_root, DOCKER_COMPOSE_FILENAME),\n            ""up"",\n            ""--build"",\n            ""--abort-on-container-exit"" if not detached else ""--detach"",  # mutually exclusive\n        ]\n\n        logger.info(""docker command: %s"", "" "".join(command))\n        return command\n\n    def _create_docker_host(self, host, environment, optml_subdirs, command, volumes):\n        """"""\n        Args:\n            host:\n            environment:\n            optml_subdirs:\n            command:\n            volumes:\n        """"""\n        optml_volumes = self._build_optml_volumes(host, optml_subdirs)\n        optml_volumes.extend(volumes)\n\n        host_config = {\n            ""image"": self.image,\n            ""stdin_open"": True,\n            ""tty"": True,\n            ""volumes"": [v.map for v in optml_volumes],\n            ""environment"": environment,\n            ""command"": command,\n            ""networks"": {""sagemaker-local"": {""aliases"": [host]}},\n        }\n\n        # for GPU support pass in nvidia as the runtime, this is equivalent\n        # to setting --runtime=nvidia in the docker commandline.\n        if self.instance_type == ""local_gpu"":\n            host_config[""runtime""] = ""nvidia""\n\n        if command == ""serve"":\n            serving_port = (\n                sagemaker.utils.get_config_value(\n                    ""local.serving_port"", self.sagemaker_session.config\n                )\n                or 8080\n            )\n            host_config.update({""ports"": [""%s:8080"" % serving_port]})\n\n        return host_config\n\n    def _create_tmp_folder(self):\n        """"""Placeholder docstring""""""\n        root_dir = sagemaker.utils.get_config_value(\n            ""local.container_root"", self.sagemaker_session.config\n        )\n        if root_dir:\n            root_dir = os.path.abspath(root_dir)\n\n        working_dir = tempfile.mkdtemp(dir=root_dir)\n\n        # Docker cannot mount Mac OS /var folder properly see\n        # https://forums.docker.com/t/var-folders-isnt-mounted-properly/9600\n        # Only apply this workaround if the user didn\'t provide an alternate storage root dir.\n        if root_dir is None and platform.system() == ""Darwin"":\n            working_dir = ""/private{}"".format(working_dir)\n\n        return os.path.abspath(working_dir)\n\n    def _build_optml_volumes(self, host, subdirs):\n        """"""Generate a list of :class:`~sagemaker.local_session.Volume` required\n        for the container to start.\n\n        It takes a folder with the necessary files for training and creates a\n        list of opt volumes that the Container needs to start.\n\n        Args:\n            host (str): container for which the volumes will be generated.\n            subdirs (list): list of subdirectories that will be mapped. For\n                example: [\'input\', \'output\', \'model\']\n\n        Returns: (list) List of :class:`~sagemaker.local_session.Volume`\n        """"""\n        volumes = []\n\n        for subdir in subdirs:\n            host_dir = os.path.join(self.container_root, host, subdir)\n            container_dir = ""/opt/ml/{}"".format(subdir)\n            volume = _Volume(host_dir, container_dir)\n            volumes.append(volume)\n\n        return volumes\n\n    def _cleanup(self, dirs_to_delete=None):\n        """"""\n        Args:\n            dirs_to_delete:\n        """"""\n        if dirs_to_delete:\n            for d in dirs_to_delete:\n                _delete_tree(d)\n\n        # Free the container config files.\n        for host in self.hosts:\n            container_config_path = os.path.join(self.container_root, host)\n            _delete_tree(container_config_path)\n\n\nclass _HostingContainer(Thread):\n    """"""Placeholder docstring""""""\n\n    def __init__(self, command):\n        """"""\n        Args:\n            command:\n        """"""\n        Thread.__init__(self)\n        self.command = command\n        self.process = None\n\n    def run(self):\n        """"""Placeholder docstring""""""\n        self.process = subprocess.Popen(\n            self.command, stdout=subprocess.PIPE, stderr=subprocess.PIPE\n        )\n        try:\n            _stream_output(self.process)\n        except RuntimeError as e:\n            # _stream_output() doesn\'t have the command line. We will handle the exception\n            # which contains the exit code and append the command line to it.\n            msg = ""Failed to run: %s, %s"" % (self.command, str(e))\n            raise RuntimeError(msg)\n\n    def down(self):\n        """"""Placeholder docstring""""""\n        self.process.terminate()\n\n\nclass _Volume(object):\n    """"""Represent a Volume that will be mapped to a container.""""""\n\n    def __init__(self, host_dir, container_dir=None, channel=None):\n        """"""Create a Volume instance\n\n        the container path can be provided as a container_dir or as a channel name but not both.\n        Args:\n            host_dir (str): path to the volume data in the host\n            container_dir (str): path inside the container that host_dir will be mapped to\n            channel (str): channel name that the host_dir represents. It will be mapped as\n                /opt/ml/input/data/<channel> in the container.\n        """"""\n        if not container_dir and not channel:\n            raise ValueError(""Either container_dir or channel must be declared."")\n\n        if container_dir and channel:\n            raise ValueError(""container_dir and channel cannot be declared together."")\n\n        self.container_dir = container_dir if container_dir else ""/opt/ml/input/data/"" + channel\n        self.host_dir = host_dir\n        if platform.system() == ""Darwin"" and host_dir.startswith(""/var""):\n            self.host_dir = os.path.join(""/private"", host_dir)\n\n        self.map = ""{}:{}"".format(self.host_dir, self.container_dir)\n\n\ndef _stream_output(process):\n    """"""Stream the output of a process to stdout\n\n    This function takes an existing process that will be polled for output.\n    Only stdout will be polled and sent to sys.stdout.\n\n    Args:\n        process (subprocess.Popen): a process that has been started with\n            stdout=PIPE and stderr=STDOUT\n\n    Returns (int): process exit code\n    """"""\n    exit_code = None\n\n    while exit_code is None:\n        stdout = process.stdout.readline().decode(""utf-8"")\n        sys.stdout.write(stdout)\n        exit_code = process.poll()\n\n    if exit_code != 0:\n        raise RuntimeError(""Process exited with code: %s"" % exit_code)\n\n    return exit_code\n\n\ndef _check_output(cmd, *popenargs, **kwargs):\n    """"""\n    Args:\n        cmd:\n        *popenargs:\n        **kwargs:\n    """"""\n    if isinstance(cmd, str):\n        cmd = shlex.split(cmd)\n\n    success = True\n    try:\n        output = subprocess.check_output(cmd, *popenargs, **kwargs)\n    except subprocess.CalledProcessError as e:\n        output = e.output\n        success = False\n\n    output = output.decode(""utf-8"")\n    if not success:\n        logger.error(""Command output: %s"", output)\n        raise Exception(""Failed to run %s"" % "","".join(cmd))\n\n    return output\n\n\ndef _create_config_file_directories(root, host):\n    """"""\n    Args:\n        root:\n        host:\n    """"""\n    for d in [""input"", ""input/config"", ""output"", ""model""]:\n        os.makedirs(os.path.join(root, host, d))\n\n\ndef _delete_tree(path):\n    """"""\n    Args:\n        path:\n    """"""\n    try:\n        shutil.rmtree(path)\n    except OSError as exc:\n        # on Linux, when docker writes to any mounted volume, it uses the container\'s user. In most\n        # cases this is root. When the container exits and we try to delete them we can\'t because\n        # root owns those files. We expect this to happen, so we handle EACCESS. Any other error\n        # we will raise the exception up.\n        if exc.errno == errno.EACCES:\n            logger.warning(""Failed to delete: %s Please remove it manually."", path)\n        else:\n            logger.error(""Failed to delete: %s"", path)\n            raise\n\n\ndef _aws_credentials(session):\n    """"""\n    Args:\n        session:\n    """"""\n    try:\n        creds = session.get_credentials()\n        access_key = creds.access_key\n        secret_key = creds.secret_key\n        token = creds.token\n\n        # The presence of a token indicates the credentials are short-lived and as such are risky\n        # to be used as they might expire while running.\n        # Long-lived credentials are available either through\n        # 1. boto session\n        # 2. EC2 Metadata Service (SageMaker Notebook instances or EC2 instances with roles\n        #       attached them)\n        # Short-lived credentials available via boto session are permitted to support running on\n        # machines with no EC2 Metadata Service but a warning is provided about their danger\n        if token is None:\n            logger.info(""Using the long-lived AWS credentials found in session"")\n            return [\n                ""AWS_ACCESS_KEY_ID=%s"" % (str(access_key)),\n                ""AWS_SECRET_ACCESS_KEY=%s"" % (str(secret_key)),\n            ]\n        if not _aws_credentials_available_in_metadata_service():\n            logger.warning(\n                ""Using the short-lived AWS credentials found in session. They might expire while ""\n                ""running.""\n            )\n            return [\n                ""AWS_ACCESS_KEY_ID=%s"" % (str(access_key)),\n                ""AWS_SECRET_ACCESS_KEY=%s"" % (str(secret_key)),\n                ""AWS_SESSION_TOKEN=%s"" % (str(token)),\n            ]\n        logger.info(\n            ""No AWS credentials found in session but credentials from EC2 Metadata Service are ""\n            ""available.""\n        )\n        return None\n    except Exception as e:  # pylint: disable=broad-except\n        logger.info(""Could not get AWS credentials: %s"", e)\n\n    return None\n\n\ndef _aws_credentials_available_in_metadata_service():\n    """"""Placeholder docstring""""""\n    import botocore\n    from botocore.credentials import InstanceMetadataProvider\n    from botocore.utils import InstanceMetadataFetcher\n\n    session = botocore.session.Session()\n    instance_metadata_provider = InstanceMetadataProvider(\n        iam_role_fetcher=InstanceMetadataFetcher(\n            timeout=session.get_config_variable(""metadata_service_timeout""),\n            num_attempts=session.get_config_variable(""metadata_service_num_attempts""),\n            user_agent=session.user_agent(),\n        )\n    )\n    return not instance_metadata_provider.load() is None\n\n\ndef _write_json_file(filename, content):\n    """"""\n    Args:\n        filename:\n        content:\n    """"""\n    with open(filename, ""w"") as f:\n        json.dump(content, f)\n\n\ndef _ecr_login_if_needed(boto_session, image):\n    # Only ECR images need login\n    """"""\n    Args:\n        boto_session:\n        image:\n    """"""\n    sagemaker_pattern = re.compile(sagemaker.utils.ECR_URI_PATTERN)\n    sagemaker_match = sagemaker_pattern.match(image)\n    if not sagemaker_match:\n        return False\n\n    # do we have the image?\n    if _check_output(""docker images -q %s"" % image).strip():\n        return False\n\n    if not boto_session:\n        raise RuntimeError(\n            ""A boto session is required to login to ECR.""\n            ""Please pull the image: %s manually."" % image\n        )\n\n    ecr = boto_session.client(""ecr"")\n    auth = ecr.get_authorization_token(registryIds=[image.split(""."")[0]])\n    authorization_data = auth[""authorizationData""][0]\n\n    raw_token = base64.b64decode(authorization_data[""authorizationToken""])\n    token = raw_token.decode(""utf-8"").strip(""AWS:"")\n    ecr_url = auth[""authorizationData""][0][""proxyEndpoint""]\n\n    cmd = ""docker login -u AWS -p %s %s"" % (token, ecr_url)\n    subprocess.check_output(cmd, shell=True)\n\n    return True\n\n\ndef _pull_image(image):\n    """"""\n    Args:\n        image:\n    """"""\n    pull_image_command = (""docker pull %s"" % image).strip()\n    logger.info(""docker command: %s"", pull_image_command)\n\n    subprocess.check_output(pull_image_command, shell=True)\n    logger.info(""image pulled: %s"", image)\n'"
src/sagemaker/local/local_session.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nimport logging\nimport os\nimport platform\n\nimport boto3\nfrom botocore.exceptions import ClientError\n\nfrom sagemaker.local.image import _SageMakerContainer\nfrom sagemaker.local.entities import (\n    _LocalEndpointConfig,\n    _LocalEndpoint,\n    _LocalModel,\n    _LocalTrainingJob,\n    _LocalTransformJob,\n)\nfrom sagemaker.session import Session\nfrom sagemaker.utils import get_config_value, _module_import_error\n\nlogger = logging.getLogger(__name__)\n\n\nclass LocalSagemakerClient(object):\n    """"""A SageMakerClient that implements the API calls locally.\n\n    Used for doing local training and hosting local endpoints. It still needs access to\n    a boto client to interact with S3 but it won\'t perform any SageMaker call.\n\n    Implements the methods with the same signature as the boto SageMakerClient.\n\n    Args:\n\n    Returns:\n\n    """"""\n\n    _training_jobs = {}\n    _transform_jobs = {}\n    _models = {}\n    _endpoint_configs = {}\n    _endpoints = {}\n\n    def __init__(self, sagemaker_session=None):\n        """"""Initialize a LocalSageMakerClient.\n\n        Args:\n            sagemaker_session (sagemaker.session.Session): a session to use to read configurations\n                from, and use its boto client.\n        """"""\n        self.sagemaker_session = sagemaker_session or LocalSession()\n\n    def create_training_job(\n        self,\n        TrainingJobName,\n        AlgorithmSpecification,\n        OutputDataConfig,\n        ResourceConfig,\n        InputDataConfig=None,\n        **kwargs\n    ):\n        """"""Create a training job in Local Mode\n\n        Args:\n          TrainingJobName(str): local training job name.\n          AlgorithmSpecification(dict): Identifies the training algorithm to use.\n          InputDataConfig(dict, optional): Describes the training dataset and the location where\n            it is stored. (Default value = None)\n          OutputDataConfig(dict): Identifies the location where you want to save the results of\n            model training.\n          ResourceConfig(dict): Identifies the resources to use for local model training.\n          HyperParameters(dict) [optional]: Specifies these algorithm-specific parameters to\n            influence the quality of the final model.\n          **kwargs:\n\n        Returns:\n\n        """"""\n        InputDataConfig = InputDataConfig or {}\n        container = _SageMakerContainer(\n            ResourceConfig[""InstanceType""],\n            ResourceConfig[""InstanceCount""],\n            AlgorithmSpecification[""TrainingImage""],\n            self.sagemaker_session,\n        )\n        training_job = _LocalTrainingJob(container)\n        hyperparameters = kwargs[""HyperParameters""] if ""HyperParameters"" in kwargs else {}\n        logger.info(""Starting training job"")\n        training_job.start(InputDataConfig, OutputDataConfig, hyperparameters, TrainingJobName)\n\n        LocalSagemakerClient._training_jobs[TrainingJobName] = training_job\n\n    def describe_training_job(self, TrainingJobName):\n        """"""Describe a local training job.\n\n        Args:\n          TrainingJobName(str): Training job name to describe.\n        Returns: (dict) DescribeTrainingJob Response.\n\n        Returns:\n\n        """"""\n        if TrainingJobName not in LocalSagemakerClient._training_jobs:\n            error_response = {\n                ""Error"": {\n                    ""Code"": ""ValidationException"",\n                    ""Message"": ""Could not find local training job"",\n                }\n            }\n            raise ClientError(error_response, ""describe_training_job"")\n        return LocalSagemakerClient._training_jobs[TrainingJobName].describe()\n\n    def create_transform_job(\n        self,\n        TransformJobName,\n        ModelName,\n        TransformInput,\n        TransformOutput,\n        TransformResources,\n        **kwargs\n    ):\n        """"""\n\n        Args:\n          TransformJobName:\n          ModelName:\n          TransformInput:\n          TransformOutput:\n          TransformResources:\n          **kwargs:\n\n        Returns:\n\n        """"""\n        transform_job = _LocalTransformJob(TransformJobName, ModelName, self.sagemaker_session)\n        LocalSagemakerClient._transform_jobs[TransformJobName] = transform_job\n        transform_job.start(TransformInput, TransformOutput, TransformResources, **kwargs)\n\n    def describe_transform_job(self, TransformJobName):\n        """"""\n\n        Args:\n          TransformJobName:\n\n        Returns:\n\n        """"""\n        if TransformJobName not in LocalSagemakerClient._transform_jobs:\n            error_response = {\n                ""Error"": {\n                    ""Code"": ""ValidationException"",\n                    ""Message"": ""Could not find local transform job"",\n                }\n            }\n            raise ClientError(error_response, ""describe_transform_job"")\n        return LocalSagemakerClient._transform_jobs[TransformJobName].describe()\n\n    def create_model(\n        self, ModelName, PrimaryContainer, *args, **kwargs\n    ):  # pylint: disable=unused-argument\n        """"""Create a Local Model Object\n\n\n        Args:\n          ModelName (str): the Model Name\n          PrimaryContainer (dict): a SageMaker primary container definition\n          *args:\n          **kwargs:\n\n        Returns:\n        """"""\n        LocalSagemakerClient._models[ModelName] = _LocalModel(ModelName, PrimaryContainer)\n\n    def describe_model(self, ModelName):\n        """"""\n\n        Args:\n          ModelName:\n\n        Returns:\n\n        """"""\n        if ModelName not in LocalSagemakerClient._models:\n            error_response = {\n                ""Error"": {""Code"": ""ValidationException"", ""Message"": ""Could not find local model""}\n            }\n            raise ClientError(error_response, ""describe_model"")\n        return LocalSagemakerClient._models[ModelName].describe()\n\n    def describe_endpoint_config(self, EndpointConfigName):\n        """"""\n\n        Args:\n          EndpointConfigName:\n\n        Returns:\n\n        """"""\n        if EndpointConfigName not in LocalSagemakerClient._endpoint_configs:\n            error_response = {\n                ""Error"": {\n                    ""Code"": ""ValidationException"",\n                    ""Message"": ""Could not find local endpoint config"",\n                }\n            }\n            raise ClientError(error_response, ""describe_endpoint_config"")\n        return LocalSagemakerClient._endpoint_configs[EndpointConfigName].describe()\n\n    def create_endpoint_config(self, EndpointConfigName, ProductionVariants, Tags=None):\n        """"""\n\n        Args:\n          EndpointConfigName:\n          ProductionVariants:\n          Tags:  (Default value = None)\n\n        Returns:\n\n        """"""\n        LocalSagemakerClient._endpoint_configs[EndpointConfigName] = _LocalEndpointConfig(\n            EndpointConfigName, ProductionVariants, Tags\n        )\n\n    def describe_endpoint(self, EndpointName):\n        """"""\n\n        Args:\n          EndpointName:\n\n        Returns:\n\n        """"""\n        if EndpointName not in LocalSagemakerClient._endpoints:\n            error_response = {\n                ""Error"": {""Code"": ""ValidationException"", ""Message"": ""Could not find local endpoint""}\n            }\n            raise ClientError(error_response, ""describe_endpoint"")\n        return LocalSagemakerClient._endpoints[EndpointName].describe()\n\n    def create_endpoint(self, EndpointName, EndpointConfigName, Tags=None):\n        """"""\n\n        Args:\n          EndpointName:\n          EndpointConfigName:\n          Tags:  (Default value = None)\n\n        Returns:\n\n        """"""\n        endpoint = _LocalEndpoint(EndpointName, EndpointConfigName, Tags, self.sagemaker_session)\n        LocalSagemakerClient._endpoints[EndpointName] = endpoint\n        endpoint.serve()\n\n    def update_endpoint(self, EndpointName, EndpointConfigName):  # pylint: disable=unused-argument\n        """"""\n\n        Args:\n          EndpointName:\n          EndpointConfigName:\n\n        Returns:\n\n        """"""\n        raise NotImplementedError(""Update endpoint name is not supported in local session."")\n\n    def delete_endpoint(self, EndpointName):\n        """"""\n\n        Args:\n          EndpointName:\n\n        Returns:\n\n        """"""\n        if EndpointName in LocalSagemakerClient._endpoints:\n            LocalSagemakerClient._endpoints[EndpointName].stop()\n\n    def delete_endpoint_config(self, EndpointConfigName):\n        """"""\n\n        Args:\n          EndpointConfigName:\n\n        Returns:\n\n        """"""\n        if EndpointConfigName in LocalSagemakerClient._endpoint_configs:\n            del LocalSagemakerClient._endpoint_configs[EndpointConfigName]\n\n    def delete_model(self, ModelName):\n        """"""\n\n        Args:\n          ModelName:\n\n        Returns:\n\n        """"""\n        if ModelName in LocalSagemakerClient._models:\n            del LocalSagemakerClient._models[ModelName]\n\n\nclass LocalSagemakerRuntimeClient(object):\n    """"""A SageMaker Runtime client that calls a local endpoint only.""""""\n\n    def __init__(self, config=None):\n        """"""Initializes a LocalSageMakerRuntimeClient\n\n        Args:\n            config (dict): Optional configuration for this client. In particular only\n                the local port is read.\n        """"""\n        try:\n            import urllib3\n        except ImportError as e:\n            logging.error(_module_import_error(""urllib3"", ""Local mode"", ""local""))\n            raise e\n\n        self.http = urllib3.PoolManager()\n        self.serving_port = 8080\n        self.config = config\n        self.serving_port = get_config_value(""local.serving_port"", config) or 8080\n\n    def invoke_endpoint(\n        self,\n        Body,\n        EndpointName,  # pylint: disable=unused-argument\n        ContentType=None,\n        Accept=None,\n        CustomAttributes=None,\n        TargetModel=None,\n    ):\n        """"""\n\n        Args:\n          Body:\n          EndpointName:\n          Accept:  (Default value = None)\n          CustomAttributes:  (Default value = None)\n\n        Returns:\n\n        """"""\n        url = ""http://localhost:%s/invocations"" % self.serving_port\n        headers = {}\n\n        if ContentType is not None:\n            headers[""Content-type""] = ContentType\n\n        if Accept is not None:\n            headers[""Accept""] = Accept\n\n        if CustomAttributes is not None:\n            headers[""X-Amzn-SageMaker-Custom-Attributes""] = CustomAttributes\n\n        if TargetModel is not None:\n            headers[""X-Amzn-SageMaker-Target-Model""] = TargetModel\n\n        r = self.http.request(""POST"", url, body=Body, preload_content=False, headers=headers)\n\n        return {""Body"": r, ""ContentType"": Accept}\n\n\nclass LocalSession(Session):\n    """"""Placeholder docstring""""""\n\n    def __init__(self, boto_session=None, s3_endpoint_url=None):\n        self.s3_endpoint_url = s3_endpoint_url\n\n        super(LocalSession, self).__init__(boto_session)\n\n        if platform.system() == ""Windows"":\n            logger.warning(""Windows Support for Local Mode is Experimental"")\n\n    def _initialize(self, boto_session, sagemaker_client, sagemaker_runtime_client):\n        """"""Initialize this Local SageMaker Session.\n\n        Args:\n          boto_session:\n          sagemaker_client:\n          sagemaker_runtime_client:\n\n        Returns:\n\n        """"""\n\n        self.boto_session = boto_session or boto3.Session()\n        self._region_name = self.boto_session.region_name\n\n        if self._region_name is None:\n            raise ValueError(\n                ""Must setup local AWS configuration with a region supported by SageMaker.""\n            )\n\n        self.sagemaker_client = LocalSagemakerClient(self)\n        self.sagemaker_runtime_client = LocalSagemakerRuntimeClient(self.config)\n        self.local_mode = True\n\n        if self.s3_endpoint_url is not None:\n            self.s3_resource = boto_session.resource(""s3"", endpoint_url=self.s3_endpoint_url)\n            self.s3_client = boto_session.client(""s3"", endpoint_url=self.s3_endpoint_url)\n\n        sagemaker_config_file = os.path.join(os.path.expanduser(""~""), "".sagemaker"", ""config.yaml"")\n        if os.path.exists(sagemaker_config_file):\n            try:\n                import yaml\n            except ImportError as e:\n                logging.error(_module_import_error(""yaml"", ""Local mode"", ""local""))\n                raise e\n\n            self.config = yaml.load(open(sagemaker_config_file, ""r""))\n\n    def logs_for_job(self, job_name, wait=False, poll=5, log_type=""All""):\n        """"""\n\n        Args:\n          job_name:\n          wait:  (Default value = False)\n          poll:  (Default value = 5)\n\n        Returns:\n\n        """"""\n        # override logs_for_job() as it doesn\'t need to perform any action\n        # on local mode.\n        pass  # pylint: disable=unnecessary-pass\n\n\nclass file_input(object):\n    """"""Amazon SageMaker channel configuration for FILE data sources, used in local mode.""""""\n\n    def __init__(self, fileUri, content_type=None):\n        """"""Create a definition for input data used by an SageMaker training job in local mode.\n        """"""\n        self.config = {\n            ""DataSource"": {\n                ""FileDataSource"": {\n                    ""FileDataDistributionType"": ""FullyReplicated"",\n                    ""FileUri"": fileUri,\n                }\n            }\n        }\n\n        if content_type is not None:\n            self.config[""ContentType""] = content_type\n'"
src/sagemaker/local/utils.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nimport os\nimport shutil\n\nfrom distutils.dir_util import copy_tree\nfrom six.moves.urllib.parse import urlparse\n\n\ndef copy_directory_structure(destination_directory, relative_path):\n    """"""Create all the intermediate directories required for relative_path to\n    exist within destination_directory. This assumes that relative_path is a\n    directory located within root_dir.\n\n    Examples:\n        destination_directory: /tmp/destination relative_path: test/unit/\n\n        will create: /tmp/destination/test/unit\n\n    Args:\n        destination_directory (str): root of the destination directory where the\n            directory structure will be created.\n        relative_path (str): relative path that will be created within\n            destination_directory\n    """"""\n    full_path = os.path.join(destination_directory, relative_path)\n    if os.path.exists(full_path):\n        return\n\n    os.makedirs(destination_directory, relative_path)\n\n\ndef move_to_destination(source, destination, job_name, sagemaker_session):\n    """"""move source to destination. Can handle uploading to S3\n\n    Args:\n        source (str): root directory to move\n        destination (str): file:// or s3:// URI that source will be moved to.\n        job_name (str): SageMaker job name.\n        sagemaker_session (sagemaker.Session): a sagemaker_session to interact\n            with S3 if needed\n\n    Returns:\n        (str): destination URI\n    """"""\n    parsed_uri = urlparse(destination)\n    if parsed_uri.scheme == ""file"":\n        recursive_copy(source, parsed_uri.path)\n        final_uri = destination\n    elif parsed_uri.scheme == ""s3"":\n        bucket = parsed_uri.netloc\n        path = _create_s3_prefix(parsed_uri.path, job_name)\n        final_uri = ""s3://%s/%s"" % (bucket, path)\n        sagemaker_session.upload_data(source, bucket, path)\n    else:\n        raise ValueError(""Invalid destination URI, must be s3:// or file://, got: %s"" % destination)\n\n    shutil.rmtree(source)\n    return final_uri\n\n\ndef _create_s3_prefix(path, job_name):\n    """"""Constructs a path out of the given path and job name to be\n    used as an S3 prefix.\n\n    Args:\n        path (str): the original path. If the path is only ``""/""``,\n            then it is ignored.\n        job_name (str): the job name to be appended to the path.\n\n    Returns:\n        str: an S3 prefix of the form ``""path/job_name""``\n    """"""\n    path = path.strip(""/"")\n    return job_name if path == """" else ""/"".join((path, job_name))\n\n\ndef recursive_copy(source, destination):\n    """"""A wrapper around distutils.dir_util.copy_tree but won\'t throw any\n    exception when the source directory does not exist.\n\n    Args:\n        source (str): source path\n        destination (str): destination path\n    """"""\n    if os.path.isdir(source):\n        copy_tree(source, destination)\n'"
src/sagemaker/model_monitor/__init__.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Imports the classes in this module to simplify customer imports\n\nExample:\n    >>> from sagemaker.model_monitor import ModelMonitor\n\n""""""\nfrom __future__ import absolute_import\n\nfrom sagemaker.model_monitor.model_monitoring import ModelMonitor  # noqa: F401\nfrom sagemaker.model_monitor.model_monitoring import DefaultModelMonitor  # noqa: F401\nfrom sagemaker.model_monitor.model_monitoring import BaseliningJob  # noqa: F401\nfrom sagemaker.model_monitor.model_monitoring import MonitoringExecution  # noqa: F401\nfrom sagemaker.model_monitor.model_monitoring import EndpointInput  # noqa: F401\nfrom sagemaker.model_monitor.model_monitoring import MonitoringOutput  # noqa: F401\n\nfrom sagemaker.model_monitor.cron_expression_generator import CronExpressionGenerator  # noqa: F401\nfrom sagemaker.model_monitor.monitoring_files import Statistics  # noqa: F401\nfrom sagemaker.model_monitor.monitoring_files import Constraints  # noqa: F401\nfrom sagemaker.model_monitor.monitoring_files import ConstraintViolations  # noqa: F401\n\nfrom sagemaker.model_monitor.data_capture_config import DataCaptureConfig  # noqa: F401\nfrom sagemaker.model_monitor.dataset_format import DatasetFormat  # noqa: F401\n\nfrom sagemaker.network import NetworkConfig  # noqa: F401\n'"
src/sagemaker/model_monitor/cron_expression_generator.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""This module contains code related to the CronExpressionGenerator class, which is used\nfor generating cron expressions compatible with Amazon SageMaker Model Monitoring Schedules.\n""""""\nfrom __future__ import print_function, absolute_import\n\n\nclass CronExpressionGenerator(object):\n    """"""Generates cron expression strings for use with the Amazon SageMaker Model Monitoring Schedule\n    API.\n    """"""\n\n    @staticmethod\n    def hourly():\n        """"""Generates hourly cron expression that denotes that a job runs at the top of every hour.\n\n        Returns:\n            str: The cron expression format accepted by the Amazon SageMaker Model Monitoring\n                Schedule API.\n\n        """"""\n        return ""cron(0 * ? * * *)""\n\n    @staticmethod\n    def daily(hour=0):\n        """"""Generates daily cron expression that denotes that a job runs at the top of every hour.\n\n        Args:\n            hour (int): The hour in HH24 format (UTC) to run the job at, on a daily schedule.\n                Examples:\n                    - 00\n                    - 12\n                    - 17\n                    - 23\n\n        Returns:\n            str: The cron expression format accepted by the Amazon SageMaker Model Monitoring\n                Schedule API.\n\n        """"""\n        return ""cron(0 {} ? * * *)"".format(hour)\n\n    @staticmethod\n    def daily_every_x_hours(hour_interval, starting_hour=0):\n        """"""Generates ""daily every x hours"" cron expression that denotes that a job runs every day\n        at the specified hour, and then every x hours, as specified in hour_interval.\n\n         Example:\n             >>> daily_every_x_hours(hour_interval=2, starting_hour=0)\n             This will run every 2 hours starting at midnight.\n\n             >>> daily_every_x_hours(hour_interval=10, starting_hour=0)\n             This will run at midnight, 10am, and 8pm every day.\n\n        Args:\n            hour_interval (int): The hour interval to run the job at.\n            starting_hour (int): The hour at which to begin in HH24 format (UTC).\n\n        Returns:\n            str: The cron expression format accepted by the Amazon SageMaker Model Monitoring\n                Schedule API.\n\n        """"""\n        return ""cron(0 {}/{} ? * * *)"".format(starting_hour, hour_interval)\n'"
src/sagemaker/model_monitor/data_capture_config.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""This module contains code related to the DataCaptureConfig class, which is used\nfor configuring capture, collection, and storage, for prediction requests and responses\nfor models hosted on SageMaker Endpoints.\n""""""\nfrom __future__ import print_function, absolute_import\n\nimport os\n\nfrom sagemaker.session import Session\n\n_MODEL_MONITOR_S3_PATH = ""model-monitor""\n_DATA_CAPTURE_S3_PATH = ""data-capture""\n\n\nclass DataCaptureConfig(object):\n    """"""Configuration object passed in when deploying models to Amazon SageMaker Endpoints.\n    This object specifies configuration related to endpoint data capture for use with\n    Amazon SageMaker Model Monitoring.\n    """"""\n\n    API_MAPPING = {""REQUEST"": ""Input"", ""RESPONSE"": ""Output""}\n\n    def __init__(\n        self,\n        enable_capture,\n        sampling_percentage=20,\n        destination_s3_uri=None,\n        kms_key_id=None,\n        capture_options=None,\n        csv_content_types=None,\n        json_content_types=None,\n        sagemaker_session=None,\n    ):\n        """"""Initialize a DataCaptureConfig object for capturing data from Amazon SageMaker Endpoints.\n\n        Args:\n            enable_capture (bool): Required. Whether data capture should be enabled or not.\n            sampling_percentage (int): Optional. Default=20. The percentage of data to sample.\n                Must be between 0 and 100.\n            destination_s3_uri (str): Optional. Defaults to ""s3://<default-session-bucket>/\n                model-monitor/data-capture"".\n            kms_key_id (str): Optional. Default=None. The kms key to use when writing to S3.\n            capture_options ([str]): Optional. Must be a list containing any combination of the\n                following values: ""REQUEST"", ""RESPONSE"". Default=[""REQUEST"", ""RESPONSE""]. Denotes\n                which data to capture between request and response.\n            csv_content_types ([str]): Optional. Default=[""text/csv""].\n            json_content_types([str]): Optional. Default=[""application/json""].\n            sagemaker_session (sagemaker.session.Session): A SageMaker Session\n                object, used for SageMaker interactions (default: None). If not\n                specified, one is created using the default AWS configuration\n                chain.\n        """"""\n        self.enable_capture = enable_capture\n        self.sampling_percentage = sampling_percentage\n        self.destination_s3_uri = destination_s3_uri\n        if self.destination_s3_uri is None:\n            sagemaker_session = sagemaker_session or Session()\n            self.destination_s3_uri = os.path.join(\n                ""s3://"",\n                sagemaker_session.default_bucket(),\n                _MODEL_MONITOR_S3_PATH,\n                _DATA_CAPTURE_S3_PATH,\n            )\n\n        self.kms_key_id = kms_key_id\n        self.capture_options = capture_options or [""REQUEST"", ""RESPONSE""]\n        self.csv_content_types = csv_content_types or [""text/csv""]\n        self.json_content_types = json_content_types or [""application/json""]\n\n    def _to_request_dict(self):\n        """"""Generates a request dictionary using the parameters provided to the class.""""""\n        request_dict = {\n            ""EnableCapture"": self.enable_capture,\n            ""InitialSamplingPercentage"": self.sampling_percentage,\n            ""DestinationS3Uri"": self.destination_s3_uri,\n            ""CaptureOptions"": [\n                #  Convert to API values or pass value directly through if unable to convert.\n                {""CaptureMode"": self.API_MAPPING.get(capture_option.upper(), capture_option)}\n                for capture_option in self.capture_options\n            ],\n        }\n\n        if self.kms_key_id is not None:\n            request_dict[""KmsKeyId""] = self.kms_key_id\n\n        if self.csv_content_types is not None or self.json_content_types is not None:\n            request_dict[""CaptureContentTypeHeader""] = {}\n\n        if self.csv_content_types is not None:\n            request_dict[""CaptureContentTypeHeader""][""CsvContentTypes""] = self.csv_content_types\n\n        if self.json_content_types is not None:\n            request_dict[""CaptureContentTypeHeader""][""JsonContentTypes""] = self.json_content_types\n\n        return request_dict\n'"
src/sagemaker/model_monitor/dataset_format.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""This module contains code related to the DatasetFormat class, which is used\nfor managing the constraints JSON file generated and consumed by Amazon SageMaker Model Monitoring\nSchedules.\n""""""\nfrom __future__ import print_function, absolute_import\n\n\nclass DatasetFormat(object):\n    """"""Represents a Dataset Format that is used when calling a DefaultModelMonitor.\n    """"""\n\n    @staticmethod\n    def csv(header=True, output_columns_position=""START""):\n        """"""Returns a DatasetFormat JSON string for use with a DefaultModelMonitor.\n\n        Args:\n            header (bool): Whether the csv dataset to baseline and monitor has a header.\n                Default: True.\n            output_columns_position (str): The position of the output columns.\n                Must be one of (""START"", ""END""). Default: ""START"".\n\n        Returns:\n            dict: JSON string containing DatasetFormat to be used by DefaultModelMonitor.\n\n        """"""\n        return {""csv"": {""header"": header, ""output_columns_position"": output_columns_position}}\n\n    @staticmethod\n    def json(lines=True):\n        """"""Returns a DatasetFormat JSON string for use with a DefaultModelMonitor.\n\n        Args:\n            lines (bool): Whether the file should be read as a json object per line. Default: True.\n\n        Returns:\n            dict: JSON string containing DatasetFormat to be used by DefaultModelMonitor.\n\n        """"""\n        return {""json"": {""lines"": lines}}\n\n    @staticmethod\n    def sagemaker_capture_json():\n        """"""Returns a DatasetFormat SageMaker Capture Json string for use with a DefaultModelMonitor.\n\n        Returns:\n            dict: JSON string containing DatasetFormat to be used by DefaultModelMonitor.\n\n        """"""\n        return {""sagemakerCaptureJson"": {}}\n'"
src/sagemaker/model_monitor/model_monitoring.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""This module contains code related to Amazon SageMaker Model Monitoring. These classes\nassist with suggesting baselines and creating monitoring schedules for data captured\nby SageMaker Endpoints.\n""""""\nfrom __future__ import print_function, absolute_import\n\nimport copy\nimport json\nimport os\nimport logging\nimport uuid\n\nfrom six import string_types\nfrom six.moves.urllib.parse import urlparse\nfrom botocore.exceptions import ClientError\n\nfrom sagemaker.exceptions import UnexpectedStatusException\nfrom sagemaker.model_monitor.monitoring_files import Constraints, ConstraintViolations, Statistics\nfrom sagemaker.network import NetworkConfig\nfrom sagemaker.processing import Processor, ProcessingInput, ProcessingJob, ProcessingOutput\nfrom sagemaker.s3 import S3Uploader\nfrom sagemaker.session import Session\nfrom sagemaker.utils import name_from_base, retries, get_ecr_image_uri_prefix\n\n_DEFAULT_MONITOR_IMAGE_URI_WITH_PLACEHOLDERS = ""{}/sagemaker-model-monitor-analyzer""\n\n_DEFAULT_MONITOR_IMAGE_REGION_ACCOUNT_MAPPING = {\n    ""eu-north-1"": ""895015795356"",\n    ""me-south-1"": ""607024016150"",\n    ""ap-south-1"": ""126357580389"",\n    ""us-east-2"": ""777275614652"",\n    ""eu-west-1"": ""468650794304"",\n    ""eu-central-1"": ""048819808253"",\n    ""sa-east-1"": ""539772159869"",\n    ""ap-east-1"": ""001633400207"",\n    ""us-east-1"": ""156813124566"",\n    ""ap-northeast-2"": ""709848358524"",\n    ""eu-west-2"": ""749857270468"",\n    ""eu-west-3"": ""680080141114"",\n    ""ap-northeast-1"": ""574779866223"",\n    ""us-west-2"": ""159807026194"",\n    ""us-west-1"": ""890145073186"",\n    ""ap-southeast-1"": ""245545462676"",\n    ""ap-southeast-2"": ""563025443158"",\n    ""ca-central-1"": ""536280801234"",\n    ""cn-north-1"": ""453000072557"",\n    ""cn-northwest-1"": ""453252182341"",\n}\n\nSTATISTICS_JSON_DEFAULT_FILE_NAME = ""statistics.json""\nCONSTRAINTS_JSON_DEFAULT_FILE_NAME = ""constraints.json""\nCONSTRAINT_VIOLATIONS_JSON_DEFAULT_FILE_NAME = ""constraint_violations.json""\n\n_CONTAINER_BASE_PATH = ""/opt/ml/processing""\n_CONTAINER_INPUT_PATH = ""input""\n_CONTAINER_ENDPOINT_INPUT_PATH = ""endpoint""\n_BASELINE_DATASET_INPUT_NAME = ""baseline_dataset_input""\n_RECORD_PREPROCESSOR_SCRIPT_INPUT_NAME = ""record_preprocessor_script_input""\n_POST_ANALYTICS_PROCESSOR_SCRIPT_INPUT_NAME = ""post_analytics_processor_script_input""\n_CONTAINER_OUTPUT_PATH = ""output""\n_DEFAULT_OUTPUT_NAME = ""monitoring_output""\n_MODEL_MONITOR_S3_PATH = ""model-monitor""\n_BASELINING_S3_PATH = ""baselining""\n_MONITORING_S3_PATH = ""monitoring""\n_RESULTS_S3_PATH = ""results""\n_INPUT_S3_PATH = ""input""\n\n_SUGGESTION_JOB_BASE_NAME = ""baseline-suggestion-job""\n_MONITORING_SCHEDULE_BASE_NAME = ""monitoring-schedule""\n\n_DATASET_SOURCE_PATH_ENV_NAME = ""dataset_source""\n_DATASET_FORMAT_ENV_NAME = ""dataset_format""\n_OUTPUT_PATH_ENV_NAME = ""output_path""\n_RECORD_PREPROCESSOR_SCRIPT_ENV_NAME = ""record_preprocessor_script""\n_POST_ANALYTICS_PROCESSOR_SCRIPT_ENV_NAME = ""post_analytics_processor_script""\n_PUBLISH_CLOUDWATCH_METRICS_ENV_NAME = ""publish_cloudwatch_metrics""\n\n_LOGGER = logging.getLogger(__name__)\n\n\nclass ModelMonitor(object):\n    """"""Sets up Amazon SageMaker Monitoring Schedules and baseline suggestions. Use this class when\n    you want to provide your own container image containing the code you\'d like to run, in order\n    to produce your own statistics and constraint validation files.\n    For a more guided experience, consider using the DefaultModelMonitor class instead.\n    """"""\n\n    def __init__(\n        self,\n        role,\n        image_uri,\n        instance_count=1,\n        instance_type=""ml.m5.xlarge"",\n        entrypoint=None,\n        volume_size_in_gb=30,\n        volume_kms_key=None,\n        output_kms_key=None,\n        max_runtime_in_seconds=None,\n        base_job_name=None,\n        sagemaker_session=None,\n        env=None,\n        tags=None,\n        network_config=None,\n    ):\n        """"""Initializes a ``Monitor`` instance. The Monitor handles baselining datasets and\n        creating Amazon SageMaker Monitoring Schedules to monitor SageMaker endpoints.\n\n        Args:\n            role (str): An AWS IAM role. The Amazon SageMaker jobs use this role.\n            image_uri (str): The uri of the image to use for the jobs started by\n                the Monitor.\n            instance_count (int): The number of instances to run\n                the jobs with.\n            instance_type (str): Type of EC2 instance to use for\n                the job, for example, \'ml.m5.xlarge\'.\n            entrypoint ([str]): The entrypoint for the job.\n            volume_size_in_gb (int): Size in GB of the EBS volume\n                to use for storing data during processing (default: 30).\n            volume_kms_key (str): A KMS key for the job\'s volume.\n            output_kms_key (str): The KMS key id for the job\'s outputs.\n            max_runtime_in_seconds (int): Timeout in seconds. After this amount of\n                time, Amazon SageMaker terminates the job regardless of its current status.\n                Default: 3600\n            base_job_name (str): Prefix for the job name. If not specified,\n                a default name is generated based on the training image name and\n                current timestamp.\n            sagemaker_session (sagemaker.session.Session): Session object which\n                manages interactions with Amazon SageMaker APIs and any other\n                AWS services needed. If not specified, one is created using\n                the default AWS configuration chain.\n            env (dict): Environment variables to be passed to the job.\n            tags ([dict]): List of tags to be passed to the job.\n            network_config (sagemaker.network.NetworkConfig): A NetworkConfig\n                object that configures network isolation, encryption of\n                inter-container traffic, security group IDs, and subnets.\n\n        """"""\n        self.role = role\n        self.image_uri = image_uri\n        self.instance_count = instance_count\n        self.instance_type = instance_type\n        self.entrypoint = entrypoint\n        self.volume_size_in_gb = volume_size_in_gb\n        self.volume_kms_key = volume_kms_key\n        self.output_kms_key = output_kms_key\n        self.max_runtime_in_seconds = max_runtime_in_seconds\n        self.base_job_name = base_job_name\n        self.sagemaker_session = sagemaker_session or Session()\n        self.env = env\n        self.tags = tags\n        self.network_config = network_config\n\n        self.baselining_jobs = []\n        self.latest_baselining_job = None\n        self.arguments = None\n        self.latest_baselining_job_name = None\n        self.monitoring_schedule_name = None\n\n    def run_baseline(\n        self, baseline_inputs, output, arguments=None, wait=True, logs=True, job_name=None\n    ):\n        """"""Run a processing job meant to baseline your dataset.\n\n        Args:\n            baseline_inputs ([sagemaker.processing.ProcessingInput]): Input files for the processing\n                job. These must be provided as ProcessingInput objects.\n            output (sagemaker.processing.ProcessingOutput): Destination of the constraint_violations\n                and statistics json files.\n            arguments ([str]): A list of string arguments to be passed to a processing job.\n            wait (bool): Whether the call should wait until the job completes (default: True).\n            logs (bool): Whether to show the logs produced by the job.\n                Only meaningful when wait is True (default: True).\n            job_name (str): Processing job name. If not specified, the processor generates\n                a default job name, based on the image name and current timestamp.\n\n        """"""\n        self.latest_baselining_job_name = self._generate_baselining_job_name(job_name=job_name)\n        self.arguments = arguments\n        normalized_baseline_inputs = self._normalize_baseline_inputs(\n            baseline_inputs=baseline_inputs\n        )\n        normalized_output = self._normalize_processing_output(output=output)\n\n        baselining_processor = Processor(\n            role=self.role,\n            image_uri=self.image_uri,\n            instance_count=self.instance_count,\n            instance_type=self.instance_type,\n            entrypoint=self.entrypoint,\n            volume_size_in_gb=self.volume_size_in_gb,\n            volume_kms_key=self.volume_kms_key,\n            output_kms_key=self.output_kms_key,\n            max_runtime_in_seconds=self.max_runtime_in_seconds,\n            base_job_name=self.base_job_name,\n            sagemaker_session=self.sagemaker_session,\n            env=self.env,\n            tags=self.tags,\n            network_config=self.network_config,\n        )\n\n        baselining_processor.run(\n            inputs=normalized_baseline_inputs,\n            outputs=[normalized_output],\n            arguments=self.arguments,\n            wait=wait,\n            logs=logs,\n            job_name=self.latest_baselining_job_name,\n        )\n\n        self.latest_baselining_job = BaseliningJob.from_processing_job(\n            processing_job=baselining_processor.latest_job\n        )\n        self.baselining_jobs.append(self.latest_baselining_job)\n\n    def create_monitoring_schedule(\n        self,\n        endpoint_input,\n        output,\n        statistics=None,\n        constraints=None,\n        monitor_schedule_name=None,\n        schedule_cron_expression=None,\n    ):\n        """"""Creates a monitoring schedule to monitor an Amazon SageMaker Endpoint.\n\n        If constraints and statistics are provided, or if they are able to be retrieved from a\n        previous baselining job associated with this monitor, those will be used.\n        If constraints and statistics cannot be automatically retrieved, baseline_inputs will be\n        required in order to kick off a baselining job.\n\n        Args:\n            endpoint_input (str or sagemaker.model_monitor.EndpointInput): The endpoint to monitor.\n                This can either be the endpoint name or an EndpointInput.\n            output (sagemaker.model_monitor.MonitoringOutput): The output of the monitoring\n                schedule.\n            statistics (sagemaker.model_monitor.Statistic or str): If provided alongside\n                constraints, these will be used for monitoring the endpoint. This can be a\n                sagemaker.model_monitor.Constraints object or an S3 uri pointing to a constraints\n                JSON file.\n            constraints (sagemaker.model_monitor.Constraints or str): If provided alongside\n                statistics, these will be used for monitoring the endpoint. This can be a\n                sagemaker.model_monitor.Constraints object or an S3 uri pointing to a constraints\n                JSON file.\n            monitor_schedule_name (str): Schedule name. If not specified, the processor generates\n                a default job name, based on the image name and current timestamp.\n            schedule_cron_expression (str): The cron expression that dictates the frequency that\n                this job runs at. See sagemaker.model_monitor.CronExpressionGenerator for valid\n                expressions. Default: Daily.\n\n        """"""\n        if self.monitoring_schedule_name is not None:\n            message = (\n                ""It seems that this object was already used to create an Amazon Model ""\n                ""Monitoring Schedule. To create another, first delete the existing one ""\n                ""using my_monitor.delete_monitoring_schedule().""\n            )\n            print(message)\n            raise ValueError(message)\n\n        self.monitoring_schedule_name = self._generate_monitoring_schedule_name(\n            schedule_name=monitor_schedule_name\n        )\n\n        normalized_endpoint_input = self._normalize_endpoint_input(endpoint_input=endpoint_input)\n\n        normalized_monitoring_output = self._normalize_monitoring_output(output=output)\n\n        statistics_object, constraints_object = self._get_baseline_files(\n            statistics=statistics, constraints=constraints, sagemaker_session=self.sagemaker_session\n        )\n\n        statistics_s3_uri = None\n        if statistics_object is not None:\n            statistics_s3_uri = statistics_object.file_s3_uri\n\n        constraints_s3_uri = None\n        if constraints_object is not None:\n            constraints_s3_uri = constraints_object.file_s3_uri\n\n        monitoring_output_config = {\n            ""MonitoringOutputs"": [normalized_monitoring_output._to_request_dict()]\n        }\n\n        if self.output_kms_key is not None:\n            monitoring_output_config[""KmsKeyId""] = self.output_kms_key\n\n        self.monitoring_schedule_name = (\n            monitor_schedule_name\n            or self._generate_monitoring_schedule_name(schedule_name=monitor_schedule_name)\n        )\n\n        network_config_dict = None\n        if self.network_config is not None:\n            network_config_dict = self.network_config._to_request_dict()\n            self._validate_network_config(network_config_dict)\n\n        self.sagemaker_session.create_monitoring_schedule(\n            monitoring_schedule_name=self.monitoring_schedule_name,\n            schedule_expression=schedule_cron_expression,\n            statistics_s3_uri=statistics_s3_uri,\n            constraints_s3_uri=constraints_s3_uri,\n            monitoring_inputs=[normalized_endpoint_input._to_request_dict()],\n            monitoring_output_config=monitoring_output_config,\n            instance_count=self.instance_count,\n            instance_type=self.instance_type,\n            volume_size_in_gb=self.volume_size_in_gb,\n            volume_kms_key=self.volume_kms_key,\n            image_uri=self.image_uri,\n            entrypoint=self.entrypoint,\n            arguments=self.arguments,\n            record_preprocessor_source_uri=None,\n            post_analytics_processor_source_uri=None,\n            max_runtime_in_seconds=self.max_runtime_in_seconds,\n            environment=self.env,\n            network_config=network_config_dict,\n            role_arn=self.sagemaker_session.expand_role(self.role),\n            tags=self.tags,\n        )\n\n    def update_monitoring_schedule(\n        self,\n        endpoint_input=None,\n        output=None,\n        statistics=None,\n        constraints=None,\n        schedule_cron_expression=None,\n        instance_count=None,\n        instance_type=None,\n        entrypoint=None,\n        volume_size_in_gb=None,\n        volume_kms_key=None,\n        output_kms_key=None,\n        arguments=None,\n        max_runtime_in_seconds=None,\n        env=None,\n        network_config=None,\n        role=None,\n        image_uri=None,\n    ):\n        """"""Updates the existing monitoring schedule.\n\n        Args:\n            endpoint_input (str or sagemaker.model_monitor.EndpointInput): The endpoint to monitor.\n                This can either be the endpoint name or an EndpointInput.\n            output (sagemaker.model_monitor.MonitoringOutput): The output of the monitoring\n                schedule.\n            statistics (sagemaker.model_monitor.Statistic or str): If provided alongside\n                constraints, these will be used for monitoring the endpoint. This can be a\n                sagemaker.model_monitor.Constraints object or an S3 uri pointing to a constraints\n                JSON file.\n            constraints (sagemaker.model_monitor.Constraints or str): If provided alongside\n                statistics, these will be used for monitoring the endpoint. This can be a\n                sagemaker.model_monitor.Constraints object or an S3 uri pointing to a constraints\n                JSON file.\n            schedule_cron_expression (str): The cron expression that dictates the frequency that\n                this job runs at.  See sagemaker.model_monitor.CronExpressionGenerator for valid\n                expressions.\n            instance_count (int): The number of instances to run\n                the jobs with.\n            instance_type (str): Type of EC2 instance to use for\n                the job, for example, \'ml.m5.xlarge\'.\n            entrypoint (str): The entrypoint for the job.\n            volume_size_in_gb (int): Size in GB of the EBS volume\n                to use for storing data during processing (default: 30).\n            volume_kms_key (str): A KMS key for the job\'s volume.\n            output_kms_key (str): The KMS key id for the job\'s outputs.\n            arguments ([str]): A list of string arguments to be passed to a processing job.\n            max_runtime_in_seconds (int): Timeout in seconds. After this amount of\n                time, Amazon SageMaker terminates the job regardless of its current status.\n                Default: 3600\n            env (dict): Environment variables to be passed to the job.\n            network_config (sagemaker.network.NetworkConfig): A NetworkConfig\n                object that configures network isolation, encryption of\n                inter-container traffic, security group IDs, and subnets.\n            role (str): An AWS IAM role name or ARN. The Amazon SageMaker jobs use this role.\n            image_uri (str): The uri of the image to use for the jobs started by\n                the Monitor.\n\n        """"""\n        monitoring_inputs = None\n        if endpoint_input is not None:\n            monitoring_inputs = [\n                self._normalize_endpoint_input(endpoint_input=endpoint_input)._to_request_dict()\n            ]\n\n        monitoring_output_config = None\n        if output is not None:\n            normalized_monitoring_output = self._normalize_monitoring_output(output=output)\n            monitoring_output_config = {\n                ""MonitoringOutputs"": [normalized_monitoring_output._to_request_dict()]\n            }\n\n        statistics_object, constraints_object = self._get_baseline_files(\n            statistics=statistics, constraints=constraints, sagemaker_session=self.sagemaker_session\n        )\n\n        statistics_s3_uri = None\n        if statistics_object is not None:\n            statistics_s3_uri = statistics_object.file_s3_uri\n\n        constraints_s3_uri = None\n        if constraints_object is not None:\n            constraints_s3_uri = constraints_object.file_s3_uri\n\n        if instance_type is not None:\n            self.instance_type = instance_type\n\n        if instance_count is not None:\n            self.instance_count = instance_count\n\n        if entrypoint is not None:\n            self.entrypoint = entrypoint\n\n        if volume_size_in_gb is not None:\n            self.volume_size_in_gb = volume_size_in_gb\n\n        if volume_kms_key is not None:\n            self.volume_kms_key = volume_kms_key\n\n        if output_kms_key is not None:\n            self.output_kms_key = output_kms_key\n            monitoring_output_config[""KmsKeyId""] = self.output_kms_key\n\n        if arguments is not None:\n            self.arguments = arguments\n\n        if max_runtime_in_seconds is not None:\n            self.max_runtime_in_seconds = max_runtime_in_seconds\n\n        if env is not None:\n            self.env = env\n\n        if network_config is not None:\n            self.network_config = network_config\n\n        if role is not None:\n            self.role = role\n\n        if image_uri is not None:\n            self.image_uri = image_uri\n\n        network_config_dict = None\n        if self.network_config is not None:\n            network_config_dict = self.network_config._to_request_dict()\n            self._validate_network_config(network_config_dict)\n\n        self.sagemaker_session.update_monitoring_schedule(\n            monitoring_schedule_name=self.monitoring_schedule_name,\n            schedule_expression=schedule_cron_expression,\n            statistics_s3_uri=statistics_s3_uri,\n            constraints_s3_uri=constraints_s3_uri,\n            monitoring_inputs=monitoring_inputs,\n            monitoring_output_config=monitoring_output_config,\n            instance_count=instance_count,\n            instance_type=instance_type,\n            volume_size_in_gb=volume_size_in_gb,\n            volume_kms_key=volume_kms_key,\n            image_uri=image_uri,\n            entrypoint=entrypoint,\n            arguments=arguments,\n            max_runtime_in_seconds=max_runtime_in_seconds,\n            environment=env,\n            network_config=network_config_dict,\n            role_arn=self.sagemaker_session.expand_role(self.role),\n        )\n\n        self._wait_for_schedule_changes_to_apply()\n\n    def start_monitoring_schedule(self):\n        """"""Starts the monitoring schedule.""""""\n        self.sagemaker_session.start_monitoring_schedule(\n            monitoring_schedule_name=self.monitoring_schedule_name\n        )\n\n        self._wait_for_schedule_changes_to_apply()\n\n    def stop_monitoring_schedule(self):\n        """"""Stops the monitoring schedule.""""""\n        self.sagemaker_session.stop_monitoring_schedule(\n            monitoring_schedule_name=self.monitoring_schedule_name\n        )\n\n        self._wait_for_schedule_changes_to_apply()\n\n    def delete_monitoring_schedule(self):\n        """"""Deletes the monitoring schedule.""""""\n        self.sagemaker_session.delete_monitoring_schedule(\n            monitoring_schedule_name=self.monitoring_schedule_name\n        )\n        self.monitoring_schedule_name = None\n\n    def baseline_statistics(self, file_name=STATISTICS_JSON_DEFAULT_FILE_NAME):\n        """"""Returns a Statistics object representing the statistics json file generated by the\n        latest baselining job.\n\n        Args:\n            file_name (str): The name of the .json statistics file\n\n        Returns:\n            sagemaker.model_monitor.Statistics: The Statistics object representing the file that\n                was generated by the job.\n\n        """"""\n        return self.latest_baselining_job.baseline_statistics(\n            file_name=file_name, kms_key=self.output_kms_key\n        )\n\n    def suggested_constraints(self, file_name=CONSTRAINTS_JSON_DEFAULT_FILE_NAME):\n        """"""Returns a Statistics object representing the constraints json file generated by the\n        latest baselining job\n\n        Args:\n            file_name (str): The name of the .json constraints file\n\n        Returns:\n            sagemaker.model_monitor.Constraints: The Constraints object representing the file that\n                was generated by the job.\n\n        """"""\n        return self.latest_baselining_job.suggested_constraints(\n            file_name=file_name, kms_key=self.output_kms_key\n        )\n\n    def latest_monitoring_statistics(self, file_name=STATISTICS_JSON_DEFAULT_FILE_NAME):\n        """"""Returns the sagemaker.model_monitor.Statistics generated by the latest monitoring\n        execution.\n\n        Args:\n            file_name (str): The name of the statistics file to be retrieved. Only override if\n                generating a custom file name.\n\n        Returns:\n            sagemaker.model_monitoring.Statistics: The Statistics object representing the file\n                generated by the latest monitoring execution.\n\n        """"""\n        executions = self.list_executions()\n        if len(executions) == 0:\n            print(\n                ""No executions found for schedule. monitoring_schedule_name: {}"".format(\n                    self.monitoring_schedule_name\n                )\n            )\n            return None\n\n        latest_monitoring_execution = executions[-1]\n        return latest_monitoring_execution.statistics(file_name=file_name)\n\n    def latest_monitoring_constraint_violations(\n        self, file_name=CONSTRAINT_VIOLATIONS_JSON_DEFAULT_FILE_NAME\n    ):\n        """"""Returns the sagemaker.model_monitor.ConstraintViolations generated by the latest\n        monitoring execution.\n\n        Args:\n            file_name (str): The name of the constraint violdations file to be retrieved. Only\n                override if generating a custom file name.\n\n        Returns:\n            sagemaker.model_monitoring.ConstraintViolations: The ConstraintViolations object\n                representing the file generated by the latest monitoring execution.\n\n        """"""\n        executions = self.list_executions()\n        if len(executions) == 0:\n            print(\n                ""No executions found for schedule. monitoring_schedule_name: {}"".format(\n                    self.monitoring_schedule_name\n                )\n            )\n            return None\n\n        latest_monitoring_execution = executions[-1]\n        return latest_monitoring_execution.constraint_violations(file_name=file_name)\n\n    def describe_latest_baselining_job(self):\n        """"""Describe the latest baselining job kicked off by the suggest workflow.\n        """"""\n        if self.latest_baselining_job is None:\n            raise ValueError(""No suggestion jobs were kicked off."")\n        return self.latest_baselining_job.describe()\n\n    def describe_schedule(self):\n        """"""Describes the schedule that this object represents.\n\n        Returns:\n            dict: A dictionary response with the monitoring schedule description.\n\n        """"""\n        return self.sagemaker_session.describe_monitoring_schedule(\n            monitoring_schedule_name=self.monitoring_schedule_name\n        )\n\n    def list_executions(self):\n        """"""Get the list of the latest monitoring executions in descending order of ""ScheduledTime"".\n        Statistics or violations can be called following this example:\n        Example:\n            >>> my_executions = my_monitor.list_executions()\n            >>> second_to_last_execution_statistics = my_executions[-1].statistics()\n            >>> second_to_last_execution_violations = my_executions[-1].constraint_violations()\n\n        Returns:\n            [sagemaker.model_monitor.MonitoringExecution]: List of MonitoringExecutions in\n                descending order of ""ScheduledTime"".\n\n        """"""\n        monitoring_executions_dict = self.sagemaker_session.list_monitoring_executions(\n            monitoring_schedule_name=self.monitoring_schedule_name\n        )\n\n        if len(monitoring_executions_dict[""MonitoringExecutionSummaries""]) == 0:\n            print(\n                ""No executions found for schedule. monitoring_schedule_name: {}"".format(\n                    self.monitoring_schedule_name\n                )\n            )\n            return []\n\n        processing_job_arns = [\n            execution_dict[""ProcessingJobArn""]\n            for execution_dict in monitoring_executions_dict[""MonitoringExecutionSummaries""]\n            if execution_dict.get(""ProcessingJobArn"") is not None\n        ]\n        monitoring_executions = [\n            MonitoringExecution.from_processing_arn(\n                sagemaker_session=self.sagemaker_session, processing_job_arn=processing_job_arn\n            )\n            for processing_job_arn in processing_job_arns\n        ]\n        monitoring_executions.reverse()\n\n        return monitoring_executions\n\n    @classmethod\n    def attach(cls, monitor_schedule_name, sagemaker_session=None):\n        """"""Sets this object\'s schedule name to point to the Amazon Sagemaker Monitoring Schedule\n        name provided. This allows subsequent describe_schedule or list_executions calls to point\n        to the given schedule.\n\n        Args:\n            monitor_schedule_name (str): The name of the schedule to attach to.\n            sagemaker_session (sagemaker.session.Session): Session object which\n                manages interactions with Amazon SageMaker APIs and any other\n                AWS services needed. If not specified, one is created using\n                the default AWS configuration chain.\n\n        """"""\n        sagemaker_session = sagemaker_session or Session()\n        schedule_desc = sagemaker_session.describe_monitoring_schedule(\n            monitoring_schedule_name=monitor_schedule_name\n        )\n\n        role = schedule_desc[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][""RoleArn""]\n        image_uri = schedule_desc[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringAppSpecification""\n        ][""ImageUri""]\n        instance_count = schedule_desc[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""InstanceCount""]\n        instance_type = schedule_desc[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""InstanceType""]\n        entrypoint = schedule_desc[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringAppSpecification""\n        ].get(""ContainerEntrypoint"")\n        volume_size_in_gb = schedule_desc[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""VolumeSizeInGB""]\n        volume_kms_key = schedule_desc[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""].get(""VolumeKmsKeyId"")\n        output_kms_key = schedule_desc[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringOutputConfig""\n        ].get(""KmsKeyId"")\n\n        max_runtime_in_seconds = None\n        if schedule_desc[""MonitoringScheduleConfig""][""MonitoringJobDefinition""].get(\n            ""StoppingCondition""\n        ):\n            max_runtime_in_seconds = schedule_desc[""MonitoringScheduleConfig""][\n                ""MonitoringJobDefinition""\n            ][""StoppingCondition""].get(""MaxRuntimeInSeconds"")\n\n        env = schedule_desc[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][""Environment""]\n\n        network_config_dict = schedule_desc[""MonitoringScheduleConfig""][\n            ""MonitoringJobDefinition""\n        ].get(""NetworkConfig"")\n\n        vpc_config = schedule_desc[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""NetworkConfig""\n        ].get(""VpcConfig"")\n\n        security_group_ids = None\n        if vpc_config is not None:\n            security_group_ids = vpc_config[""SecurityGroupIds""]\n\n        subnets = None\n        if vpc_config is not None:\n            subnets = vpc_config[""Subnets""]\n\n        if network_config_dict:\n            network_config = NetworkConfig(\n                enable_network_isolation=network_config_dict[""EnableNetworkIsolation""],\n                security_group_ids=security_group_ids,\n                subnets=subnets,\n            )\n\n        tags = sagemaker_session.list_tags(resource_arn=schedule_desc[""MonitoringScheduleArn""])\n\n        attached_monitor = cls(\n            role=role,\n            image_uri=image_uri,\n            instance_count=instance_count,\n            instance_type=instance_type,\n            entrypoint=entrypoint,\n            volume_size_in_gb=volume_size_in_gb,\n            volume_kms_key=volume_kms_key,\n            output_kms_key=output_kms_key,\n            max_runtime_in_seconds=max_runtime_in_seconds,\n            sagemaker_session=sagemaker_session,\n            env=env,\n            tags=tags,\n            network_config=network_config,\n        )\n        attached_monitor.monitoring_schedule_name = monitor_schedule_name\n        return attached_monitor\n\n    def _generate_baselining_job_name(self, job_name=None):\n        """"""Generate the job name before running a suggestion processing job.\n\n        Args:\n            job_name (str): Name of the suggestion processing job to be created. If not\n                specified, one is generated using the base name given to the\n                constructor, if applicable.\n\n        Returns:\n            str: The supplied or generated job name.\n\n        """"""\n        if job_name is not None:\n            return job_name\n\n        if self.base_job_name:\n            base_name = self.base_job_name\n        else:\n            base_name = _SUGGESTION_JOB_BASE_NAME\n\n        return name_from_base(base=base_name)\n\n    def _generate_monitoring_schedule_name(self, schedule_name=None):\n        """"""Generate the monitoring schedule name.\n\n        Args:\n            schedule_name (str): Name of the monitoring schedule to be created. If not\n                specified, one is generated using the base name given to the\n                constructor, if applicable.\n\n        Returns:\n            str: The supplied or generated job name.\n\n        """"""\n        if schedule_name is not None:\n            return schedule_name\n\n        if self.base_job_name:\n            base_name = self.base_job_name\n        else:\n            base_name = _MONITORING_SCHEDULE_BASE_NAME\n\n        return name_from_base(base=base_name)\n\n    @staticmethod\n    def _get_baseline_files(statistics, constraints, sagemaker_session=None):\n        """"""Populates baseline values if possible.\n\n        Args:\n            statistics (sagemaker.model_monitor.Statistics or str): The statistics object or str.\n                If none, this method will attempt to retrieve a previously baselined constraints\n                object.\n            constraints (sagemaker.model_monitor.Constraints or str): The constraints object or str.\n                If none, this method will attempt to retrieve a previously baselined constraints\n                object.\n            sagemaker_session (sagemaker.session.Session): Session object which manages interactions\n                with Amazon SageMaker APIs and any other AWS services needed. If not specified, one\n                is created using the default AWS configuration chain.\n\n        Returns:\n            sagemaker.model_monitor.Statistics, sagemaker.model_monitor.Constraints: The Statistics\n                and Constraints objects that were provided or created by the latest\n                baselining job. If none were found, returns None.\n\n        """"""\n        if statistics is not None and isinstance(statistics, string_types):\n            statistics = Statistics.from_s3_uri(\n                statistics_file_s3_uri=statistics, sagemaker_session=sagemaker_session\n            )\n        if constraints is not None and isinstance(constraints, string_types):\n            constraints = Constraints.from_s3_uri(\n                constraints_file_s3_uri=constraints, sagemaker_session=sagemaker_session\n            )\n\n        return statistics, constraints\n\n    def _normalize_endpoint_input(self, endpoint_input):\n        """"""Ensure that the input is an EndpointInput object.\n\n        Args:\n            endpoint_input ([str or sagemaker.processing.EndpointInput]): An endpoint input\n                to be normalized. Can be either a string or a EndpointInput object.\n\n        Returns:\n            sagemaker.processing.EndpointInput: The normalized EndpointInput object.\n\n        """"""\n        # If the input is a string, turn it into an EndpointInput object.\n        if isinstance(endpoint_input, string_types):\n            endpoint_input = EndpointInput(\n                endpoint_name=endpoint_input,\n                destination=os.path.join(\n                    _CONTAINER_BASE_PATH, _CONTAINER_INPUT_PATH, _CONTAINER_ENDPOINT_INPUT_PATH\n                ),\n            )\n\n        return endpoint_input\n\n    def _normalize_baseline_inputs(self, baseline_inputs=None):\n        """"""Ensure that all the ProcessingInput objects have names and S3 uris.\n\n        Args:\n            baseline_inputs ([sagemaker.processing.ProcessingInput]): A list of ProcessingInput\n                objects to be normalized.\n\n        Returns:\n            [sagemaker.processing.ProcessingInput]: The list of normalized\n                ProcessingInput objects.\n\n        """"""\n        # Initialize a list of normalized ProcessingInput objects.\n        normalized_inputs = []\n        if baseline_inputs is not None:\n            # Iterate through the provided list of inputs.\n            for count, file_input in enumerate(baseline_inputs, 1):\n                if not isinstance(file_input, ProcessingInput):\n                    raise TypeError(""Your inputs must be provided as ProcessingInput objects."")\n                # Generate a name for the ProcessingInput if it doesn\'t have one.\n                if file_input.input_name is None:\n                    file_input.input_name = ""input-{}"".format(count)\n                # If the source is a local path, upload it to S3\n                # and save the S3 uri in the ProcessingInput source.\n                parse_result = urlparse(file_input.source)\n                if parse_result.scheme != ""s3"":\n                    s3_uri = os.path.join(\n                        ""s3://"",\n                        self.sagemaker_session.default_bucket(),\n                        self.latest_baselining_job_name,\n                        file_input.input_name,\n                    )\n                    S3Uploader.upload(\n                        local_path=file_input.source,\n                        desired_s3_uri=s3_uri,\n                        session=self.sagemaker_session,\n                    )\n                    file_input.source = s3_uri\n                normalized_inputs.append(file_input)\n        return normalized_inputs\n\n    def _normalize_processing_output(self, output=None):\n        """"""Ensure that the output is a ProcessingOutput object.\n\n        Args:\n            output (str or sagemaker.processing.ProcessingOutput): An output to be normalized.\n\n        Returns:\n            sagemaker.processing.ProcessingOutput: The normalized ProcessingOutput object.\n\n        """"""\n        # If the output is a string, turn it into a ProcessingOutput object.\n        if isinstance(output, string_types):\n            s3_uri = os.path.join(\n                ""s3://"",\n                self.sagemaker_session.default_bucket(),\n                self.latest_baselining_job_name,\n                ""output"",\n            )\n            output = ProcessingOutput(\n                source=output, destination=s3_uri, output_name=_DEFAULT_OUTPUT_NAME\n            )\n\n        return output\n\n    def _normalize_monitoring_output(self, output=None):\n        """"""Ensure that output has the correct fields.\n\n        Args:\n            output (sagemaker.processing.MonitoringOutput): An output to be normalized.\n\n        Returns:\n            sagemaker.processing.MonitoringOutput: The normalized MonitoringOutput object.\n\n        """"""\n        # If the output is a string, turn it into a ProcessingOutput object.\n        if output.destination is None:\n            output.destination = os.path.join(\n                ""s3://"",\n                self.sagemaker_session.default_bucket(),\n                self.monitoring_schedule_name,\n                ""output"",\n            )\n\n        return output\n\n    def _s3_uri_from_local_path(self, path):\n        """"""If path is local, uploads to S3 and returns S3 uri. Otherwise returns S3 uri as-is.\n\n        Args:\n            path (str): Path to file. This can be a local path or an S3 path.\n\n        Returns:\n            str: S3 uri to file.\n\n        """"""\n        parse_result = urlparse(path)\n        if parse_result.scheme != ""s3"":\n            s3_uri = os.path.join(\n                ""s3://"",\n                self.sagemaker_session.default_bucket(),\n                _MODEL_MONITOR_S3_PATH,\n                _MONITORING_S3_PATH,\n                self.monitoring_schedule_name,\n                _INPUT_S3_PATH,\n                str(uuid.uuid4()),\n            )\n            S3Uploader.upload(\n                local_path=path, desired_s3_uri=s3_uri, session=self.sagemaker_session\n            )\n            path = os.path.join(s3_uri, os.path.basename(path))\n        return path\n\n    def _wait_for_schedule_changes_to_apply(self):\n        """"""Waits for the schedule associated with this monitor to no longer be in the \'Pending\'\n        state.\n\n        """"""\n        for _ in retries(\n            max_retry_count=36,  # 36*5 = 3min\n            exception_message_prefix=""Waiting for schedule to leave \'Pending\' status"",\n            seconds_to_sleep=5,\n        ):\n            schedule_desc = self.describe_schedule()\n            if schedule_desc[""MonitoringScheduleStatus""] != ""Pending"":\n                break\n\n    def _validate_network_config(self, network_config_dict):\n        """"""Validates that EnableInterContainerTrafficEncryption is not set in the provided\n        NetworkConfig request dictionary.\n\n        Args:\n            network_config_dict (dict): NetworkConfig request dictionary.\n                Contains parameters from :class:`~sagemaker.network.NetworkConfig` object\n                that configures network isolation, encryption of\n                inter-container traffic, security group IDs, and subnets.\n\n        """"""\n        if ""EnableInterContainerTrafficEncryption"" in network_config_dict:\n            message = (\n                ""EnableInterContainerTrafficEncryption is not supported in Model Monitor. ""\n                ""Please ensure that encrypt_inter_container_traffic=None ""\n                ""when creating your NetworkConfig object. ""\n                ""Current encrypt_inter_container_traffic value: {}"".format(\n                    self.network_config.encrypt_inter_container_traffic\n                )\n            )\n            _LOGGER.info(message)\n            raise ValueError(message)\n\n\nclass DefaultModelMonitor(ModelMonitor):\n    """"""Sets up Amazon SageMaker Monitoring Schedules and baseline suggestions. Use this class when\n    you want to utilize Amazon SageMaker Monitoring\'s plug-and-play solution that only requires\n    your dataset and optional pre/postprocessing scripts.\n    For a more customized experience, consider using the ModelMonitor class instead.\n    """"""\n\n    def __init__(\n        self,\n        role,\n        instance_count=1,\n        instance_type=""ml.m5.xlarge"",\n        volume_size_in_gb=30,\n        volume_kms_key=None,\n        output_kms_key=None,\n        max_runtime_in_seconds=None,\n        base_job_name=None,\n        sagemaker_session=None,\n        env=None,\n        tags=None,\n        network_config=None,\n    ):\n        """"""Initializes a ``Monitor`` instance. The Monitor handles baselining datasets and\n        creating Amazon SageMaker Monitoring Schedules to monitor SageMaker endpoints.\n\n        Args:\n            role (str): An AWS IAM role name or ARN. The Amazon SageMaker jobs use this role.\n            instance_count (int): The number of instances to run the jobs with.\n            instance_type (str): Type of EC2 instance to use for the job, for example,\n                \'ml.m5.xlarge\'.\n            volume_size_in_gb (int): Size in GB of the EBS volume\n                to use for storing data during processing (default: 30).\n            volume_kms_key (str): A KMS key for the processing volume.\n            output_kms_key (str): The KMS key id for the job\'s outputs.\n            max_runtime_in_seconds (int): Timeout in seconds. After this amount of\n                time, Amazon SageMaker terminates the job regardless of its current status.\n                Default: 3600\n            base_job_name (str): Prefix for the job name. If not specified,\n                a default name is generated based on the training image name and\n                current timestamp.\n            sagemaker_session (sagemaker.session.Session): Session object which\n                manages interactions with Amazon SageMaker APIs and any other\n                AWS services needed. If not specified, one is created using\n                the default AWS configuration chain.\n            env (dict): Environment variables to be passed to the job.\n            tags ([dict]): List of tags to be passed to the job.\n            network_config (sagemaker.network.NetworkConfig): A NetworkConfig\n                object that configures network isolation, encryption of\n                inter-container traffic, security group IDs, and subnets.\n\n        """"""\n        session = sagemaker_session or Session()\n        super(DefaultModelMonitor, self).__init__(\n            role=role,\n            image_uri=DefaultModelMonitor._get_default_image_uri(session.boto_session.region_name),\n            instance_count=instance_count,\n            instance_type=instance_type,\n            volume_size_in_gb=volume_size_in_gb,\n            volume_kms_key=volume_kms_key,\n            output_kms_key=output_kms_key,\n            max_runtime_in_seconds=max_runtime_in_seconds,\n            base_job_name=base_job_name,\n            sagemaker_session=sagemaker_session,\n            env=env,\n            tags=tags,\n            network_config=network_config,\n        )\n\n    def suggest_baseline(\n        self,\n        baseline_dataset,\n        dataset_format,\n        record_preprocessor_script=None,\n        post_analytics_processor_script=None,\n        output_s3_uri=None,\n        wait=True,\n        logs=True,\n        job_name=None,\n    ):\n        """"""Suggest baselines for use with Amazon SageMaker Model Monitoring Schedules.\n\n        Args:\n            baseline_dataset (str): The path to the baseline_dataset file. This can be a local path\n                or an S3 uri.\n            dataset_format (dict): The format of the baseline_dataset.\n            record_preprocessor_script (str): The path to the record preprocessor script. This can\n                be a local path or an S3 uri.\n            post_analytics_processor_script (str): The path to the record post-analytics processor\n                script. This can be a local path or an S3 uri.\n            output_s3_uri (str): Desired S3 destination Destination of the constraint_violations\n                and statistics json files.\n                Default: ""s3://<default_session_bucket>/<job_name>/output""\n            wait (bool): Whether the call should wait until the job completes (default: True).\n            logs (bool): Whether to show the logs produced by the job.\n                Only meaningful when wait is True (default: True).\n            job_name (str): Processing job name. If not specified, the processor generates\n                a default job name, based on the image name and current timestamp.\n\n        Returns:\n            sagemaker.processing.ProcessingJob: The ProcessingJob object representing the\n                baselining job.\n\n        """"""\n        self.latest_baselining_job_name = self._generate_baselining_job_name(job_name=job_name)\n\n        normalized_baseline_dataset_input = self._upload_and_convert_to_processing_input(\n            source=baseline_dataset,\n            destination=os.path.join(\n                _CONTAINER_BASE_PATH, _CONTAINER_INPUT_PATH, _BASELINE_DATASET_INPUT_NAME\n            ),\n            name=_BASELINE_DATASET_INPUT_NAME,\n        )\n\n        # Unlike other input, dataset must be a directory for the Monitoring image.\n        baseline_dataset_container_path = normalized_baseline_dataset_input.destination\n\n        normalized_record_preprocessor_script_input = self._upload_and_convert_to_processing_input(\n            source=record_preprocessor_script,\n            destination=os.path.join(\n                _CONTAINER_BASE_PATH, _CONTAINER_INPUT_PATH, _RECORD_PREPROCESSOR_SCRIPT_INPUT_NAME\n            ),\n            name=_RECORD_PREPROCESSOR_SCRIPT_INPUT_NAME,\n        )\n\n        record_preprocessor_script_container_path = None\n        if normalized_record_preprocessor_script_input is not None:\n            record_preprocessor_script_container_path = os.path.join(\n                normalized_record_preprocessor_script_input.destination,\n                os.path.basename(record_preprocessor_script),\n            )\n\n        normalized_post_processor_script_input = self._upload_and_convert_to_processing_input(\n            source=post_analytics_processor_script,\n            destination=os.path.join(\n                _CONTAINER_BASE_PATH,\n                _CONTAINER_INPUT_PATH,\n                _POST_ANALYTICS_PROCESSOR_SCRIPT_INPUT_NAME,\n            ),\n            name=_POST_ANALYTICS_PROCESSOR_SCRIPT_INPUT_NAME,\n        )\n\n        post_processor_script_container_path = None\n        if normalized_post_processor_script_input is not None:\n            post_processor_script_container_path = os.path.join(\n                normalized_post_processor_script_input.destination,\n                os.path.basename(post_analytics_processor_script),\n            )\n\n        normalized_baseline_output = self._normalize_baseline_output(output_s3_uri=output_s3_uri)\n\n        normalized_env = self._generate_env_map(\n            env=self.env,\n            dataset_format=dataset_format,\n            output_path=normalized_baseline_output.source,\n            enable_cloudwatch_metrics=False,  # Only supported for monitoring schedules\n            dataset_source_container_path=baseline_dataset_container_path,\n            record_preprocessor_script_container_path=record_preprocessor_script_container_path,\n            post_processor_script_container_path=post_processor_script_container_path,\n        )\n\n        baselining_processor = Processor(\n            role=self.role,\n            image_uri=self.image_uri,\n            instance_count=self.instance_count,\n            instance_type=self.instance_type,\n            entrypoint=self.entrypoint,\n            volume_size_in_gb=self.volume_size_in_gb,\n            volume_kms_key=self.volume_kms_key,\n            output_kms_key=self.output_kms_key,\n            max_runtime_in_seconds=self.max_runtime_in_seconds,\n            base_job_name=self.base_job_name,\n            sagemaker_session=self.sagemaker_session,\n            env=normalized_env,\n            tags=self.tags,\n            network_config=self.network_config,\n        )\n\n        baseline_job_inputs_with_nones = [\n            normalized_baseline_dataset_input,\n            normalized_record_preprocessor_script_input,\n            normalized_post_processor_script_input,\n        ]\n\n        baseline_job_inputs = [\n            baseline_job_input\n            for baseline_job_input in baseline_job_inputs_with_nones\n            if baseline_job_input is not None\n        ]\n\n        baselining_processor.run(\n            inputs=baseline_job_inputs,\n            outputs=[normalized_baseline_output],\n            arguments=self.arguments,\n            wait=wait,\n            logs=logs,\n            job_name=self.latest_baselining_job_name,\n        )\n\n        self.latest_baselining_job = BaseliningJob.from_processing_job(\n            processing_job=baselining_processor.latest_job\n        )\n        self.baselining_jobs.append(self.latest_baselining_job)\n        return baselining_processor.latest_job\n\n    def create_monitoring_schedule(\n        self,\n        endpoint_input,\n        record_preprocessor_script=None,\n        post_analytics_processor_script=None,\n        output_s3_uri=None,\n        constraints=None,\n        statistics=None,\n        monitor_schedule_name=None,\n        schedule_cron_expression=None,\n        enable_cloudwatch_metrics=True,\n    ):\n        """"""Creates a monitoring schedule to monitor an Amazon SageMaker Endpoint.\n\n        If constraints and statistics are provided, or if they are able to be retrieved from a\n        previous baselining job associated with this monitor, those will be used.\n        If constraints and statistics cannot be automatically retrieved, baseline_inputs will be\n        required in order to kick off a baselining job.\n\n        Args:\n            endpoint_input (str or sagemaker.model_monitor.EndpointInput): The endpoint to monitor.\n                This can either be the endpoint name or an EndpointInput.\n            record_preprocessor_script (str): The path to the record preprocessor script. This can\n                be a local path or an S3 uri.\n            post_analytics_processor_script (str): The path to the record post-analytics processor\n                script. This can be a local path or an S3 uri.\n            output_s3_uri (str): Desired S3 destination of the constraint_violations and\n                statistics json files.\n                Default: ""s3://<default_session_bucket>/<job_name>/output""\n            constraints (sagemaker.model_monitor.Constraints or str): If provided alongside\n                statistics, these will be used for monitoring the endpoint. This can be a\n                sagemaker.model_monitor.Constraints object or an s3_uri pointing to a constraints\n                JSON file.\n            statistics (sagemaker.model_monitor.Statistic or str): If provided alongside\n                constraints, these will be used for monitoring the endpoint. This can be a\n                sagemaker.model_monitor.Constraints object or an s3_uri pointing to a constraints\n                JSON file.\n            monitor_schedule_name (str): Schedule name. If not specified, the processor generates\n                a default job name, based on the image name and current timestamp.\n            schedule_cron_expression (str): The cron expression that dictates the frequency that\n                this job run. See sagemaker.model_monitor.CronExpressionGenerator for valid\n                expressions. Default: Daily.\n            enable_cloudwatch_metrics (bool): Whether to publish cloudwatch metrics as part of\n                the baselining or monitoring jobs.\n\n        """"""\n        if self.monitoring_schedule_name is not None:\n            message = (\n                ""It seems that this object was already used to create an Amazon Model ""\n                ""Monitoring Schedule. To create another, first delete the existing one ""\n                ""using my_monitor.delete_monitoring_schedule().""\n            )\n            print(message)\n            raise ValueError(message)\n\n        self.monitoring_schedule_name = self._generate_monitoring_schedule_name(\n            schedule_name=monitor_schedule_name\n        )\n\n        print()\n        print(""Creating Monitoring Schedule with name: {}"".format(self.monitoring_schedule_name))\n\n        normalized_endpoint_input = self._normalize_endpoint_input(endpoint_input=endpoint_input)\n\n        record_preprocessor_script_s3_uri = None\n        if record_preprocessor_script is not None:\n            record_preprocessor_script_s3_uri = self._s3_uri_from_local_path(\n                path=record_preprocessor_script\n            )\n\n        post_analytics_processor_script_s3_uri = None\n        if post_analytics_processor_script is not None:\n            post_analytics_processor_script_s3_uri = self._s3_uri_from_local_path(\n                path=post_analytics_processor_script\n            )\n\n        normalized_monitoring_output = self._normalize_monitoring_output(\n            output_s3_uri=output_s3_uri\n        )\n\n        statistics_object, constraints_object = self._get_baseline_files(\n            statistics=statistics, constraints=constraints, sagemaker_session=self.sagemaker_session\n        )\n\n        constraints_s3_uri = None\n        if constraints_object is not None:\n            constraints_s3_uri = constraints_object.file_s3_uri\n\n        statistics_s3_uri = None\n        if statistics_object is not None:\n            statistics_s3_uri = statistics_object.file_s3_uri\n\n        normalized_env = self._generate_env_map(\n            env=self.env, enable_cloudwatch_metrics=enable_cloudwatch_metrics\n        )\n\n        monitoring_output_config = {\n            ""MonitoringOutputs"": [normalized_monitoring_output._to_request_dict()]\n        }\n\n        if self.output_kms_key is not None:\n            monitoring_output_config[""KmsKeyId""] = self.output_kms_key\n\n        network_config_dict = None\n        if self.network_config is not None:\n            network_config_dict = self.network_config._to_request_dict()\n            super(DefaultModelMonitor, self)._validate_network_config(network_config_dict)\n\n        self.sagemaker_session.create_monitoring_schedule(\n            monitoring_schedule_name=self.monitoring_schedule_name,\n            schedule_expression=schedule_cron_expression,\n            constraints_s3_uri=constraints_s3_uri,\n            statistics_s3_uri=statistics_s3_uri,\n            monitoring_inputs=[normalized_endpoint_input._to_request_dict()],\n            monitoring_output_config=monitoring_output_config,\n            instance_count=self.instance_count,\n            instance_type=self.instance_type,\n            volume_size_in_gb=self.volume_size_in_gb,\n            volume_kms_key=self.volume_kms_key,\n            image_uri=self.image_uri,\n            entrypoint=self.entrypoint,\n            arguments=self.arguments,\n            record_preprocessor_source_uri=record_preprocessor_script_s3_uri,\n            post_analytics_processor_source_uri=post_analytics_processor_script_s3_uri,\n            max_runtime_in_seconds=self.max_runtime_in_seconds,\n            environment=normalized_env,\n            network_config=network_config_dict,\n            role_arn=self.sagemaker_session.expand_role(self.role),\n            tags=self.tags,\n        )\n\n    def update_monitoring_schedule(\n        self,\n        endpoint_input=None,\n        record_preprocessor_script=None,\n        post_analytics_processor_script=None,\n        output_s3_uri=None,\n        statistics=None,\n        constraints=None,\n        schedule_cron_expression=None,\n        instance_count=None,\n        instance_type=None,\n        volume_size_in_gb=None,\n        volume_kms_key=None,\n        output_kms_key=None,\n        max_runtime_in_seconds=None,\n        env=None,\n        network_config=None,\n        enable_cloudwatch_metrics=None,\n        role=None,\n    ):\n        """"""Updates the existing monitoring schedule.\n\n        Args:\n            endpoint_input (str or sagemaker.model_monitor.EndpointInput): The endpoint to monitor.\n                This can either be the endpoint name or an EndpointInput.\n            record_preprocessor_script (str): The path to the record preprocessor script. This can\n                be a local path or an S3 uri.\n            post_analytics_processor_script (str): The path to the record post-analytics processor\n                script. This can be a local path or an S3 uri.\n            output_s3_uri (str): Desired S3 destination of the constraint_violations and\n                statistics json files.\n            statistics (sagemaker.model_monitor.Statistic or str): If provided alongside\n                constraints, these will be used for monitoring the endpoint. This can be a\n                sagemaker.model_monitor.Constraints object or an S3 uri pointing to a constraints\n                JSON file.\n            constraints (sagemaker.model_monitor.Constraints or str): If provided alongside\n                statistics, these will be used for monitoring the endpoint. This can be a\n                sagemaker.model_monitor.Constraints object or an S3 uri pointing to a constraints\n                JSON file.\n            schedule_cron_expression (str): The cron expression that dictates the frequency that\n                this job runs at. See sagemaker.model_monitor.CronExpressionGenerator for valid\n                expressions.\n            instance_count (int): The number of instances to run\n                the jobs with.\n            instance_type (str): Type of EC2 instance to use for\n                the job, for example, \'ml.m5.xlarge\'.\n            volume_size_in_gb (int): Size in GB of the EBS volume\n                to use for storing data during processing (default: 30).\n            volume_kms_key (str): A KMS key for the job\'s volume.\n            output_kms_key (str): The KMS key id for the job\'s outputs.\n            max_runtime_in_seconds (int): Timeout in seconds. After this amount of\n                time, Amazon SageMaker terminates the job regardless of its current status.\n                Default: 3600\n            env (dict): Environment variables to be passed to the job.\n            network_config (sagemaker.network.NetworkConfig): A NetworkConfig\n                object that configures network isolation, encryption of\n                inter-container traffic, security group IDs, and subnets.\n            enable_cloudwatch_metrics (bool): Whether to publish cloudwatch metrics as part of\n                the baselining or monitoring jobs.\n            role (str): An AWS IAM role name or ARN. The Amazon SageMaker jobs use this role.\n\n        """"""\n        monitoring_inputs = None\n        if endpoint_input is not None:\n            monitoring_inputs = [self._normalize_endpoint_input(endpoint_input)._to_request_dict()]\n\n        record_preprocessor_script_s3_uri = None\n        if record_preprocessor_script is not None:\n            record_preprocessor_script_s3_uri = self._s3_uri_from_local_path(\n                path=record_preprocessor_script\n            )\n\n        post_analytics_processor_script_s3_uri = None\n        if post_analytics_processor_script is not None:\n            post_analytics_processor_script_s3_uri = self._s3_uri_from_local_path(\n                path=post_analytics_processor_script\n            )\n\n        monitoring_output_config = None\n        output_path = None\n        if output_s3_uri is not None:\n            normalized_monitoring_output = self._normalize_monitoring_output(\n                output_s3_uri=output_s3_uri\n            )\n            monitoring_output_config = {\n                ""MonitoringOutputs"": [normalized_monitoring_output._to_request_dict()]\n            }\n            output_path = normalized_monitoring_output.source\n\n        if env is not None:\n            self.env = env\n\n        normalized_env = self._generate_env_map(\n            env=env, output_path=output_path, enable_cloudwatch_metrics=enable_cloudwatch_metrics\n        )\n\n        statistics_object, constraints_object = self._get_baseline_files(\n            statistics=statistics, constraints=constraints, sagemaker_session=self.sagemaker_session\n        )\n\n        statistics_s3_uri = None\n        if statistics_object is not None:\n            statistics_s3_uri = statistics_object.file_s3_uri\n\n        constraints_s3_uri = None\n        if constraints_object is not None:\n            constraints_s3_uri = constraints_object.file_s3_uri\n\n        if instance_type is not None:\n            self.instance_type = instance_type\n\n        if instance_count is not None:\n            self.instance_count = instance_count\n\n        if volume_size_in_gb is not None:\n            self.volume_size_in_gb = volume_size_in_gb\n\n        if volume_kms_key is not None:\n            self.volume_kms_key = volume_kms_key\n\n        if output_kms_key is not None:\n            self.output_kms_key = output_kms_key\n            monitoring_output_config[""KmsKeyId""] = self.output_kms_key\n\n        if max_runtime_in_seconds is not None:\n            self.max_runtime_in_seconds = max_runtime_in_seconds\n\n        if network_config is not None:\n            self.network_config = network_config\n\n        network_config_dict = None\n        if self.network_config is not None:\n            network_config_dict = self.network_config._to_request_dict()\n            super(DefaultModelMonitor, self)._validate_network_config(network_config_dict)\n\n        if role is not None:\n            self.role = role\n\n        self.sagemaker_session.update_monitoring_schedule(\n            monitoring_schedule_name=self.monitoring_schedule_name,\n            schedule_expression=schedule_cron_expression,\n            constraints_s3_uri=constraints_s3_uri,\n            statistics_s3_uri=statistics_s3_uri,\n            monitoring_inputs=monitoring_inputs,\n            monitoring_output_config=monitoring_output_config,\n            instance_count=instance_count,\n            instance_type=instance_type,\n            volume_size_in_gb=volume_size_in_gb,\n            volume_kms_key=volume_kms_key,\n            record_preprocessor_source_uri=record_preprocessor_script_s3_uri,\n            post_analytics_processor_source_uri=post_analytics_processor_script_s3_uri,\n            max_runtime_in_seconds=max_runtime_in_seconds,\n            environment=normalized_env,\n            network_config=network_config_dict,\n            role_arn=self.sagemaker_session.expand_role(self.role),\n        )\n\n        self._wait_for_schedule_changes_to_apply()\n\n    def run_baseline(self):\n        """"""\'.run_baseline()\' is only allowed for ModelMonitor objects. Please use suggest_baseline\n        for DefaultModelMonitor objects, instead.""""""\n        raise NotImplementedError(\n            ""\'.run_baseline()\' is only allowed for ModelMonitor objects. ""\n            ""Please use suggest_baseline for DefaultModelMonitor objects, instead.""\n        )\n\n    @classmethod\n    def attach(cls, monitor_schedule_name, sagemaker_session=None):\n        """"""Sets this object\'s schedule name to point to the Amazon Sagemaker Monitoring Schedule\n        name provided. This allows subsequent describe_schedule or list_executions calls to point\n        to the given schedule.\n\n        Args:\n            monitor_schedule_name (str): The name of the schedule to attach to.\n            sagemaker_session (sagemaker.session.Session): Session object which\n                manages interactions with Amazon SageMaker APIs and any other\n                AWS services needed. If not specified, one is created using\n                the default AWS configuration chain.\n\n        """"""\n        sagemaker_session = sagemaker_session or Session()\n        schedule_desc = sagemaker_session.describe_monitoring_schedule(\n            monitoring_schedule_name=monitor_schedule_name\n        )\n\n        role = schedule_desc[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][""RoleArn""]\n        instance_count = schedule_desc[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""InstanceCount""]\n        instance_type = schedule_desc[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""InstanceType""]\n        volume_size_in_gb = schedule_desc[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""][""VolumeSizeInGB""]\n        volume_kms_key = schedule_desc[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringResources""\n        ][""ClusterConfig""].get(""VolumeKmsKeyId"")\n        output_kms_key = schedule_desc[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n            ""MonitoringOutputConfig""\n        ].get(""KmsKeyId"")\n\n        max_runtime_in_seconds = None\n        if schedule_desc[""MonitoringScheduleConfig""][""MonitoringJobDefinition""].get(\n            ""StoppingCondition""\n        ):\n            max_runtime_in_seconds = schedule_desc[""MonitoringScheduleConfig""][\n                ""MonitoringJobDefinition""\n            ][""StoppingCondition""].get(""MaxRuntimeInSeconds"")\n\n        env = schedule_desc[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][""Environment""]\n\n        network_config_dict = schedule_desc[""MonitoringScheduleConfig""][\n            ""MonitoringJobDefinition""\n        ].get(""NetworkConfig"")\n\n        vpc_config = None\n        if (\n            schedule_desc[""MonitoringScheduleConfig""][""MonitoringJobDefinition""].get(\n                ""NetworkConfig""\n            )\n            is not None\n        ):\n            vpc_config = schedule_desc[""MonitoringScheduleConfig""][""MonitoringJobDefinition""][\n                ""NetworkConfig""\n            ].get(""VpcConfig"")\n\n        security_group_ids = None\n        if vpc_config is not None:\n            security_group_ids = vpc_config[""SecurityGroupIds""]\n\n        subnets = None\n        if vpc_config is not None:\n            subnets = vpc_config[""Subnets""]\n\n        network_config = None\n        if network_config_dict:\n            network_config = NetworkConfig(\n                enable_network_isolation=network_config_dict[""EnableNetworkIsolation""],\n                security_group_ids=security_group_ids,\n                subnets=subnets,\n            )\n\n        tags = sagemaker_session.list_tags(resource_arn=schedule_desc[""MonitoringScheduleArn""])\n\n        attached_monitor = cls(\n            role=role,\n            instance_count=instance_count,\n            instance_type=instance_type,\n            volume_size_in_gb=volume_size_in_gb,\n            volume_kms_key=volume_kms_key,\n            output_kms_key=output_kms_key,\n            max_runtime_in_seconds=max_runtime_in_seconds,\n            sagemaker_session=sagemaker_session,\n            env=env,\n            tags=tags,\n            network_config=network_config,\n        )\n        attached_monitor.monitoring_schedule_name = monitor_schedule_name\n        return attached_monitor\n\n    def latest_monitoring_statistics(self):\n        """"""Returns the sagemaker.model_monitor.Statistics generated by the latest monitoring\n        execution.\n\n        Returns:\n            sagemaker.model_monitoring.Statistics: The Statistics object representing the file\n                generated by the latest monitoring execution.\n\n        """"""\n        executions = self.list_executions()\n        if len(executions) == 0:\n            print(\n                ""No executions found for schedule. monitoring_schedule_name: {}"".format(\n                    self.monitoring_schedule_name\n                )\n            )\n            return None\n\n        latest_monitoring_execution = executions[-1]\n\n        try:\n            return latest_monitoring_execution.statistics()\n        except ClientError:\n            status = latest_monitoring_execution.describe()[""ProcessingJobStatus""]\n            print(\n                ""Unable to retrieve statistics as job is in status \'{}\'. Latest statistics only ""\n                ""available for completed executions."".format(status)\n            )\n\n    def latest_monitoring_constraint_violations(self):\n        """"""Returns the sagemaker.model_monitor.ConstraintViolations generated by the latest\n        monitoring execution.\n\n        Returns:\n            sagemaker.model_monitoring.ConstraintViolations: The ConstraintViolations object\n                representing the file generated by the latest monitoring execution.\n\n        """"""\n        executions = self.list_executions()\n        if len(executions) == 0:\n            print(\n                ""No executions found for schedule. monitoring_schedule_name: {}"".format(\n                    self.monitoring_schedule_name\n                )\n            )\n            return None\n\n        latest_monitoring_execution = executions[-1]\n        try:\n            return latest_monitoring_execution.constraint_violations()\n        except ClientError:\n            status = latest_monitoring_execution.describe()[""ProcessingJobStatus""]\n            print(\n                ""Unable to retrieve constraint violations as job is in status \'{}\'. Latest ""\n                ""violations only available for completed executions."".format(status)\n            )\n\n    def _normalize_baseline_output(self, output_s3_uri=None):\n        """"""Ensure that the output is a ProcessingOutput object.\n\n        Args:\n            output_s3_uri (str): The output S3 uri to deposit the baseline files in.\n\n        Returns:\n            sagemaker.processing.ProcessingOutput: The normalized ProcessingOutput object.\n\n        """"""\n        s3_uri = output_s3_uri or os.path.join(\n            ""s3://"",\n            self.sagemaker_session.default_bucket(),\n            _MODEL_MONITOR_S3_PATH,\n            _BASELINING_S3_PATH,\n            self.latest_baselining_job_name,\n            _RESULTS_S3_PATH,\n        )\n        return ProcessingOutput(\n            source=os.path.join(_CONTAINER_BASE_PATH, _CONTAINER_OUTPUT_PATH),\n            destination=s3_uri,\n            output_name=_DEFAULT_OUTPUT_NAME,\n        )\n\n    def _normalize_monitoring_output(self, output_s3_uri=None):\n        """"""Ensure that the output is a MonitoringOutput object.\n\n        Args:\n            output_s3_uri (str): The output S3 uri to deposit the monitoring evaluation files in.\n\n        Returns:\n            sagemaker.model_monitor.MonitoringOutput: The normalized MonitoringOutput object.\n\n        """"""\n        s3_uri = output_s3_uri or os.path.join(\n            ""s3://"",\n            self.sagemaker_session.default_bucket(),\n            _MODEL_MONITOR_S3_PATH,\n            _MONITORING_S3_PATH,\n            self.monitoring_schedule_name,\n            _RESULTS_S3_PATH,\n        )\n        output = MonitoringOutput(\n            source=os.path.join(_CONTAINER_BASE_PATH, _CONTAINER_OUTPUT_PATH), destination=s3_uri\n        )\n\n        return output\n\n    @staticmethod\n    def _generate_env_map(\n        env,\n        output_path=None,\n        enable_cloudwatch_metrics=None,\n        record_preprocessor_script_container_path=None,\n        post_processor_script_container_path=None,\n        dataset_format=None,\n        dataset_source_container_path=None,\n    ):\n        """"""Generate a list of environment variables from first-class parameters.\n\n        Args:\n            dataset_format (dict): The format of the baseline_dataset.\n            output_path (str): Local path to the output.\n            record_preprocessor_script_container_path (str): The path to the record preprocessor\n                script.\n            post_processor_script_container_path (str): The path to the post analytics processor\n                script.\n            dataset_source_container_path (str): The path to the dataset source.\n\n        Returns:\n            dict: Dictionary of environment keys and values.\n\n        """"""\n        cloudwatch_env_map = {True: ""Enabled"", False: ""Disabled""}\n\n        if env is not None:\n            env = copy.deepcopy(env)\n        env = env or {}\n\n        if output_path is not None:\n            env[_OUTPUT_PATH_ENV_NAME] = output_path\n\n        if enable_cloudwatch_metrics is not None:\n            env[_PUBLISH_CLOUDWATCH_METRICS_ENV_NAME] = cloudwatch_env_map[\n                enable_cloudwatch_metrics\n            ]\n\n        if dataset_format is not None:\n            env[_DATASET_FORMAT_ENV_NAME] = json.dumps(dataset_format)\n\n        if record_preprocessor_script_container_path is not None:\n            env[_RECORD_PREPROCESSOR_SCRIPT_ENV_NAME] = record_preprocessor_script_container_path\n\n        if post_processor_script_container_path is not None:\n            env[_POST_ANALYTICS_PROCESSOR_SCRIPT_ENV_NAME] = post_processor_script_container_path\n\n        if dataset_source_container_path is not None:\n            env[_DATASET_SOURCE_PATH_ENV_NAME] = dataset_source_container_path\n\n        return env\n\n    def _upload_and_convert_to_processing_input(self, source, destination, name):\n        """"""Generates a ProcessingInput object from a source. Source can be a local path or an S3\n        uri.\n\n        Args:\n            source (str): The source of the data. This can be a local path or an S3 uri.\n            destination (str): The desired container path for the data to be downloaded to.\n            name (str): The name of the ProcessingInput.\n\n        Returns:\n            sagemaker.processing.ProcessingInput: The ProcessingInput object.\n\n        """"""\n        if source is None:\n            return None\n\n        parse_result = urlparse(url=source)\n\n        if parse_result.scheme != ""s3"":\n            s3_uri = os.path.join(\n                ""s3://"",\n                self.sagemaker_session.default_bucket(),\n                _MODEL_MONITOR_S3_PATH,\n                _BASELINING_S3_PATH,\n                self.latest_baselining_job_name,\n                _INPUT_S3_PATH,\n                name,\n            )\n            S3Uploader.upload(\n                local_path=source, desired_s3_uri=s3_uri, session=self.sagemaker_session\n            )\n            source = s3_uri\n\n        return ProcessingInput(source=source, destination=destination, input_name=name)\n\n    @staticmethod\n    def _get_default_image_uri(region):\n        """"""Returns the Default Model Monitoring image uri based on the region.\n\n        Args:\n            region (str): The AWS region.\n\n        Returns:\n            str: The Default Model Monitoring image uri based on the region.\n        """"""\n        return _DEFAULT_MONITOR_IMAGE_URI_WITH_PLACEHOLDERS.format(\n            get_ecr_image_uri_prefix(_DEFAULT_MONITOR_IMAGE_REGION_ACCOUNT_MAPPING[region], region)\n        )\n\n\nclass BaseliningJob(ProcessingJob):\n    """"""Provides functionality to retrieve baseline-specific files output from baselining job.""""""\n\n    def __init__(self, sagemaker_session, job_name, inputs, outputs, output_kms_key=None):\n        """"""Initializes a Baselining job that tracks a baselining job kicked off by the suggest\n        workflow.\n\n        Args:\n            sagemaker_session (sagemaker.session.Session): Session object which\n                manages interactions with Amazon SageMaker APIs and any other\n                AWS services needed. If not specified, one is created using\n                the default AWS configuration chain.\n            job_name (str): Name of the Amazon SageMaker Model Monitoring Baselining Job.\n            inputs ([sagemaker.processing.ProcessingInput]): A list of ProcessingInput objects.\n            outputs ([sagemaker.processing.ProcessingOutput]): A list of ProcessingOutput objects.\n            output_kms_key (str): The output kms key associated with the job. Defaults to None\n                if not provided.\n\n        """"""\n        self.inputs = inputs\n        self.outputs = outputs\n        super(BaseliningJob, self).__init__(\n            sagemaker_session=sagemaker_session,\n            job_name=job_name,\n            inputs=inputs,\n            outputs=outputs,\n            output_kms_key=output_kms_key,\n        )\n\n    @classmethod\n    def from_processing_job(cls, processing_job):\n        """"""Initializes a Baselining job from a processing job.\n\n        Args:\n            processing_job (sagemaker.processing.ProcessingJob): The ProcessingJob used for\n                baselining instance.\n\n        Returns:\n            sagemaker.processing.BaseliningJob: The instance of ProcessingJob created\n                using the current job name.\n\n        """"""\n        return cls(\n            processing_job.sagemaker_session,\n            processing_job.job_name,\n            processing_job.inputs,\n            processing_job.outputs,\n            processing_job.output_kms_key,\n        )\n\n    def baseline_statistics(self, file_name=STATISTICS_JSON_DEFAULT_FILE_NAME, kms_key=None):\n        """"""Returns a sagemaker.model_monitor.Statistics object representing the statistics\n        JSON file generated by this baselining job.\n\n        Args:\n            file_name (str): The name of the json-formatted statistics file\n            kms_key (str): The kms key to use when retrieving the file.\n\n        Returns:\n            sagemaker.model_monitor.Statistics: The Statistics object representing the file that\n                was generated by the job.\n\n        Raises:\n            UnexpectedStatusException: This is thrown if the job is not in a \'Complete\' state.\n\n        """"""\n        try:\n            baselining_job_output_s3_path = self.outputs[0].destination\n            return Statistics.from_s3_uri(\n                statistics_file_s3_uri=os.path.join(baselining_job_output_s3_path, file_name),\n                kms_key=kms_key,\n                sagemaker_session=self.sagemaker_session,\n            )\n        except ClientError as client_error:\n            if client_error.response[""Error""][""Code""] == ""NoSuchKey"":\n                status = self.sagemaker_session.describe_processing_job(job_name=self.job_name)[\n                    ""ProcessingJobStatus""\n                ]\n                if status != ""Completed"":\n                    raise UnexpectedStatusException(\n                        message=""The underlying job is not in \'Completed\' state. You may only ""\n                        ""retrieve files for a job that has completed successfully."",\n                        allowed_statuses=""Completed"",\n                        actual_status=status,\n                    )\n            else:\n                raise client_error\n\n    def suggested_constraints(self, file_name=CONSTRAINTS_JSON_DEFAULT_FILE_NAME, kms_key=None):\n        """"""Returns a sagemaker.model_monitor.Constraints object representing the constraints\n        JSON file generated by this baselining job.\n\n        Args:\n            file_name (str): The name of the json-formatted constraints file\n            kms_key (str): The kms key to use when retrieving the file.\n\n        Returns:\n            sagemaker.model_monitor.Constraints: The Constraints object representing the file that\n                was generated by the job.\n\n        Raises:\n            UnexpectedStatusException: This is thrown if the job is not in a \'Complete\' state.\n\n        """"""\n        try:\n            baselining_job_output_s3_path = self.outputs[0].destination\n            return Constraints.from_s3_uri(\n                constraints_file_s3_uri=os.path.join(baselining_job_output_s3_path, file_name),\n                kms_key=kms_key,\n                sagemaker_session=self.sagemaker_session,\n            )\n        except ClientError as client_error:\n            if client_error.response[""Error""][""Code""] == ""NoSuchKey"":\n                status = self.sagemaker_session.describe_processing_job(job_name=self.job_name)[\n                    ""ProcessingJobStatus""\n                ]\n                if status != ""Completed"":\n                    raise UnexpectedStatusException(\n                        message=""The underlying job is not in \'Completed\' state. You may only ""\n                        ""retrieve files for a job that has completed successfully."",\n                        allowed_statuses=""Completed"",\n                        actual_status=status,\n                    )\n            else:\n                raise client_error\n\n\nclass MonitoringExecution(ProcessingJob):\n    """"""Provides functionality to retrieve monitoring-specific files output from monitoring\n    executions\n    """"""\n\n    def __init__(self, sagemaker_session, job_name, inputs, output, output_kms_key=None):\n        """"""Initializes a MonitoringExecution job that tracks a monitoring execution kicked off by\n        an Amazon SageMaker Model Monitoring Schedule.\n\n        Args:\n            sagemaker_session (sagemaker.session.Session): Session object which\n                manages interactions with Amazon SageMaker APIs and any other\n                AWS services needed. If not specified, one is created using\n                the default AWS configuration chain.\n            job_name (str): The name of the monitoring execution job.\n            output (sagemaker.Processing.ProcessingOutput): The output associated with the\n                monitoring execution.\n            output_kms_key (str): The output kms key associated with the job. Defaults to None\n                if not provided.\n\n        """"""\n        self.output = output\n        super(MonitoringExecution, self).__init__(\n            sagemaker_session=sagemaker_session,\n            job_name=job_name,\n            inputs=inputs,\n            outputs=[output],\n            output_kms_key=output_kms_key,\n        )\n\n    @classmethod\n    def from_processing_arn(cls, sagemaker_session, processing_job_arn):\n        """"""Initializes a Baselining job from a processing arn.\n\n        Args:\n            processing_job_arn (str): ARN of the processing job to create a MonitoringExecution\n            out of.\n            sagemaker_session (sagemaker.session.Session): Session object which\n                manages interactions with Amazon SageMaker APIs and any other\n                AWS services needed. If not specified, one is created using\n                the default AWS configuration chain.\n\n        Returns:\n            sagemaker.processing.BaseliningJob: The instance of ProcessingJob created\n                using the current job name.\n\n        """"""\n        processing_job_name = processing_job_arn.split("":"")[5][\n            len(""processing-job/"") :\n        ]  # This is necessary while the API only vends an arn.\n        job_desc = sagemaker_session.describe_processing_job(job_name=processing_job_name)\n\n        return cls(\n            sagemaker_session=sagemaker_session,\n            job_name=processing_job_name,\n            inputs=[\n                ProcessingInput(\n                    source=processing_input[""S3Input""][""S3Uri""],\n                    destination=processing_input[""S3Input""][""LocalPath""],\n                    input_name=processing_input[""InputName""],\n                    s3_data_type=processing_input[""S3Input""].get(""S3DataType""),\n                    s3_input_mode=processing_input[""S3Input""].get(""S3InputMode""),\n                    s3_data_distribution_type=processing_input[""S3Input""].get(\n                        ""S3DataDistributionType""\n                    ),\n                    s3_compression_type=processing_input[""S3Input""].get(""S3CompressionType""),\n                )\n                for processing_input in job_desc[""ProcessingInputs""]\n            ],\n            output=ProcessingOutput(\n                source=job_desc[""ProcessingOutputConfig""][""Outputs""][0][""S3Output""][""LocalPath""],\n                destination=job_desc[""ProcessingOutputConfig""][""Outputs""][0][""S3Output""][""S3Uri""],\n                output_name=job_desc[""ProcessingOutputConfig""][""Outputs""][0][""OutputName""],\n            ),\n            output_kms_key=job_desc[""ProcessingOutputConfig""].get(""KmsKeyId""),\n        )\n\n    def statistics(self, file_name=STATISTICS_JSON_DEFAULT_FILE_NAME, kms_key=None):\n        """"""Returns a sagemaker.model_monitor.Statistics object representing the statistics\n        JSON file generated by this monitoring execution.\n\n        Args:\n            file_name (str): The name of the json-formatted statistics file\n            kms_key (str): The kms key to use when retrieving the file.\n\n        Returns:\n            sagemaker.model_monitor.Statistics: The Statistics object representing the file that\n                was generated by the execution.\n\n        Raises:\n            UnexpectedStatusException: This is thrown if the job is not in a \'Complete\' state.\n\n        """"""\n        try:\n            baselining_job_output_s3_path = self.outputs[0].destination\n            return Statistics.from_s3_uri(\n                statistics_file_s3_uri=os.path.join(baselining_job_output_s3_path, file_name),\n                kms_key=kms_key,\n                sagemaker_session=self.sagemaker_session,\n            )\n        except ClientError as client_error:\n            if client_error.response[""Error""][""Code""] == ""NoSuchKey"":\n                status = self.sagemaker_session.describe_processing_job(job_name=self.job_name)[\n                    ""ProcessingJobStatus""\n                ]\n                if status != ""Completed"":\n                    raise UnexpectedStatusException(\n                        message=""The underlying job is not in \'Completed\' state. You may only ""\n                        ""retrieve files for a job that has completed successfully."",\n                        allowed_statuses=""Completed"",\n                        actual_status=status,\n                    )\n            else:\n                raise client_error\n\n    def constraint_violations(\n        self, file_name=CONSTRAINT_VIOLATIONS_JSON_DEFAULT_FILE_NAME, kms_key=None\n    ):\n        """"""Returns a sagemaker.model_monitor.ConstraintViolations object representing the\n        constraint violations JSON file generated by this monitoring execution.\n\n        Args:\n            file_name (str): The name of the json-formatted constraint violations file.\n            kms_key (str): The kms key to use when retrieving the file.\n\n        Returns:\n            sagemaker.model_monitor.ConstraintViolations: The ConstraintViolations object\n                representing the file that was generated by the monitoring execution.\n\n        Raises:\n            UnexpectedStatusException: This is thrown if the job is not in a \'Complete\' state.\n\n        """"""\n        try:\n            baselining_job_output_s3_path = self.outputs[0].destination\n            return ConstraintViolations.from_s3_uri(\n                constraint_violations_file_s3_uri=os.path.join(\n                    baselining_job_output_s3_path, file_name\n                ),\n                kms_key=kms_key,\n                sagemaker_session=self.sagemaker_session,\n            )\n        except ClientError as client_error:\n            if client_error.response[""Error""][""Code""] == ""NoSuchKey"":\n                status = self.sagemaker_session.describe_processing_job(job_name=self.job_name)[\n                    ""ProcessingJobStatus""\n                ]\n                if status != ""Completed"":\n                    raise UnexpectedStatusException(\n                        message=""The underlying job is not in \'Completed\' state. You may only ""\n                        ""retrieve files for a job that has completed successfully."",\n                        allowed_statuses=""Completed"",\n                        actual_status=status,\n                    )\n            else:\n                raise client_error\n\n\nclass EndpointInput(object):\n    """"""Accepts parameters that specify an endpoint input for a monitoring execution and provides\n    a method to turn those parameters into a dictionary.""""""\n\n    def __init__(\n        self,\n        endpoint_name,\n        destination,\n        s3_input_mode=""File"",\n        s3_data_distribution_type=""FullyReplicated"",\n    ):\n        """"""Initialize an ``EndpointInput`` instance. EndpointInput accepts parameters\n        that specify an endpoint input for a monitoring job and provides a method\n        to turn those parameters into a dictionary.\n\n        Args:\n            endpoint_name (str): The name of the endpoint.\n            destination (str): The destination of the input.\n            s3_input_mode (str): The S3 input mode. Can be one of: ""File"", ""Pipe. Default: ""File"".\n            s3_data_distribution_type (str): The S3 Data Distribution Type. Can be one of:\n                ""FullyReplicated"", ""ShardedByS3Key""\n\n        """"""\n        self.endpoint_name = endpoint_name\n        self.destination = destination\n        self.s3_input_mode = s3_input_mode\n        self.s3_data_distribution_type = s3_data_distribution_type\n\n    def _to_request_dict(self):\n        """"""Generates a request dictionary using the parameters provided to the class.""""""\n        endpoint_input_request = {\n            ""EndpointInput"": {\n                ""EndpointName"": self.endpoint_name,\n                ""LocalPath"": self.destination,\n                ""S3InputMode"": self.s3_input_mode,\n                ""S3DataDistributionType"": self.s3_data_distribution_type,\n            }\n        }\n\n        return endpoint_input_request\n\n\nclass MonitoringOutput(object):\n    """"""Accepts parameters that specify an S3 output for a monitoring job and provides\n    a method to turn those parameters into a dictionary.""""""\n\n    def __init__(self, source, destination=None, s3_upload_mode=""Continuous""):\n        """"""Initialize a ``MonitoringOutput`` instance. MonitoringOutput accepts parameters that\n        specify an S3 output for a monitoring job and provides a method to turn\n        those parameters into a dictionary.\n\n        Args:\n            source (str): The source for the output.\n            destination (str): The destination of the output. Optional.\n                Default: s3://<default-session-bucket/schedule_name/output\n            s3_upload_mode (str): The S3 upload mode.\n\n        """"""\n        self.source = source\n        self.destination = destination\n        self.s3_upload_mode = s3_upload_mode\n\n    def _to_request_dict(self):\n        """"""Generates a request dictionary using the parameters provided to the class.\n\n        Returns:\n            dict: The request dictionary.\n\n        """"""\n        s3_output_request = {\n            ""S3Output"": {\n                ""S3Uri"": self.destination,\n                ""LocalPath"": self.source,\n                ""S3UploadMode"": self.s3_upload_mode,\n            }\n        }\n\n        return s3_output_request\n'"
src/sagemaker/model_monitor/monitoring_files.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""This module contains code related to the ModelMonitoringFile class, which is used\nfor managing the constraints and statistics JSON files generated and consumed by\nAmazon SageMaker Model Monitoring Schedules.\n""""""\nfrom __future__ import print_function, absolute_import\n\nimport json\nimport os\nimport uuid\n\nfrom botocore.exceptions import ClientError\n\nfrom sagemaker.session import Session\nfrom sagemaker.s3 import S3Downloader\nfrom sagemaker.s3 import S3Uploader\n\nNO_SUCH_KEY_CODE = ""NoSuchKey""\n\n\nclass ModelMonitoringFile(object):\n    """"""Represents a file with a body and an S3 uri.\n    """"""\n\n    def __init__(self, body_dict, file_s3_uri, kms_key, sagemaker_session):\n        """"""Initializes a file with a body and an S3 uri.\n\n        Args:\n            body_dict (str): The body of the JSON file.\n            file_s3_uri (str): The uri of the JSON file.\n            kms_key (str): The kms key to be used to decrypt the file in S3.\n            sagemaker_session (sagemaker.session.Session): A SageMaker Session\n                object, used for SageMaker interactions (default: None). If not\n                specified, one is created using the default AWS configuration\n                chain.\n\n        """"""\n        self.body_dict = body_dict\n        self.file_s3_uri = file_s3_uri\n        self.kms_key = kms_key\n        self.session = sagemaker_session\n\n    def save(self, new_save_location_s3_uri=None):\n        """"""Save the current instance\'s body to s3 using the instance\'s s3 path.\n        The S3 path can be overridden by providing one. This also overrides the\n        default save location for this object.\n\n        Args:\n            new_save_location_s3_uri (str): Optional. The S3 path to save the file to. If not\n                provided, the file is saved in place in S3. If provided, the file\'s S3 path is\n                permanently updated.\n\n        Returns:\n            str: The s3 location to which the file was saved.\n\n        """"""\n        if new_save_location_s3_uri is not None:\n            self.file_s3_uri = new_save_location_s3_uri\n\n        return S3Uploader.upload_string_as_file_body(\n            body=json.dumps(self.body_dict),\n            desired_s3_uri=self.file_s3_uri,\n            kms_key=self.kms_key,\n            session=self.session,\n        )\n\n\nclass Statistics(ModelMonitoringFile):\n    """"""Represents the statistics JSON file used in Amazon SageMaker Model Monitoring.\n    """"""\n\n    def __init__(self, body_dict, statistics_file_s3_uri, kms_key=None, sagemaker_session=None):\n        """"""Initializes the Statistics object used in Amazon SageMaker Model Monitoring.\n\n        Args:\n            body_dict (str): The body of the statistics JSON file.\n            statistics_file_s3_uri (str): The uri of the statistics JSON file.\n            kms_key (str): The kms key to be used to decrypt the file in S3.\n            sagemaker_session (sagemaker.session.Session): A SageMaker Session\n                object, used for SageMaker interactions (default: None). If not\n                specified, one is created using the default AWS configuration\n                chain.\n\n        """"""\n        super(Statistics, self).__init__(\n            body_dict=body_dict,\n            file_s3_uri=statistics_file_s3_uri,\n            kms_key=kms_key,\n            sagemaker_session=sagemaker_session,\n        )\n\n    @classmethod\n    def from_s3_uri(cls, statistics_file_s3_uri, kms_key=None, sagemaker_session=None):\n        """"""Generates a Statistics object from an s3 uri.\n\n        Args:\n            statistics_file_s3_uri (str): The uri of the statistics JSON file.\n            kms_key (str): The kms key to be used to decrypt the file in S3.\n            sagemaker_session (sagemaker.session.Session): A SageMaker Session\n                object, used for SageMaker interactions (default: None). If not\n                specified, one is created using the default AWS configuration\n                chain.\n\n        Returns:\n            sagemaker.model_monitor.Statistics: The instance of Statistics generated from\n                the s3 uri.\n\n        """"""\n        try:\n            body_dict = json.loads(\n                S3Downloader.read_file(s3_uri=statistics_file_s3_uri, session=sagemaker_session)\n            )\n        except ClientError as error:\n            print(\n                ""\\nCould not retrieve statistics file at location \'{}\'. ""\n                ""To manually retrieve Statistics object from a given uri, ""\n                ""use \'my_model_monitor.statistics(my_s3_uri)\' or ""\n                ""\'Statistics.from_s3_uri(my_s3_uri)\'"".format(statistics_file_s3_uri)\n            )\n            raise error\n\n        return cls(\n            body_dict=body_dict, statistics_file_s3_uri=statistics_file_s3_uri, kms_key=kms_key\n        )\n\n    @classmethod\n    def from_string(\n        cls, statistics_file_string, kms_key=None, file_name=None, sagemaker_session=None\n    ):\n        """"""Generates a Statistics object from an s3 uri.\n\n        Args:\n            statistics_file_string (str): The uri of the statistics JSON file.\n            kms_key (str): The kms key to be used to encrypt the file in S3.\n            file_name (str): The file name to use when uploading to S3.\n            sagemaker_session (sagemaker.session.Session): A SageMaker Session\n                object, used for SageMaker interactions (default: None). If not\n                specified, one is created using the default AWS configuration\n                chain.\n\n        Returns:\n            sagemaker.model_monitor.Statistics: The instance of Statistics generated from\n                the s3 uri.\n\n        """"""\n        sagemaker_session = sagemaker_session or Session()\n        file_name = file_name or ""statistics.json""\n        desired_s3_uri = os.path.join(\n            ""s3://"", sagemaker_session.default_bucket(), ""monitoring"", str(uuid.uuid4()), file_name\n        )\n        s3_uri = S3Uploader.upload_string_as_file_body(\n            body=statistics_file_string,\n            desired_s3_uri=desired_s3_uri,\n            kms_key=kms_key,\n            session=sagemaker_session,\n        )\n\n        return Statistics.from_s3_uri(\n            statistics_file_s3_uri=s3_uri, kms_key=kms_key, sagemaker_session=sagemaker_session\n        )\n\n    @classmethod\n    def from_file_path(cls, statistics_file_path, kms_key=None, sagemaker_session=None):\n        """"""Initializes a Statistics object from a file path.\n\n        Args:\n            statistics_file_path (str): The path to the statistics file.\n            kms_key (str): The kms_key to use when encrypting the file in S3.\n            sagemaker_session (sagemaker.session.Session): A SageMaker Session\n                object, used for SageMaker interactions (default: None). If not\n                specified, one is created using the default AWS configuration\n                chain.\n\n        Returns:\n            sagemaker.model_monitor.Statistics: The instance of Statistics generated from\n                the local file path.\n\n        """"""\n        file_name = os.path.basename(statistics_file_path)\n\n        with open(statistics_file_path, ""r"") as f:\n            file_body = f.read()\n\n        return Statistics.from_string(\n            statistics_file_string=file_body,\n            file_name=file_name,\n            kms_key=kms_key,\n            sagemaker_session=sagemaker_session,\n        )\n\n\nclass Constraints(ModelMonitoringFile):\n    """"""Represents the constraints JSON file used in Amazon SageMaker Model Monitoring.\n    """"""\n\n    def __init__(self, body_dict, constraints_file_s3_uri, kms_key=None, sagemaker_session=None):\n        """"""Initializes the Constraints object used in Amazon SageMaker Model Monitoring.\n\n        Args:\n            body_dict (str): The body of the constraints JSON file.\n            constraints_file_s3_uri (str): The uri of the constraints JSON file.\n            kms_key (str): The kms key to be used to decrypt the file in S3.\n            sagemaker_session (sagemaker.session.Session): A SageMaker Session\n                object, used for SageMaker interactions (default: None). If not\n                specified, one is created using the default AWS configuration\n                chain.\n\n        """"""\n        super(Constraints, self).__init__(\n            body_dict=body_dict,\n            file_s3_uri=constraints_file_s3_uri,\n            kms_key=kms_key,\n            sagemaker_session=sagemaker_session,\n        )\n\n    @classmethod\n    def from_s3_uri(cls, constraints_file_s3_uri, kms_key=None, sagemaker_session=None):\n        """"""Generates a Constraints object from an s3 uri.\n\n        Args:\n            constraints_file_s3_uri (str): The uri of the constraints JSON file.\n            kms_key (str): The kms key to be used to decrypt the file in S3.\n            sagemaker_session (sagemaker.session.Session): A SageMaker Session\n                object, used for SageMaker interactions (default: None). If not\n                specified, one is created using the default AWS configuration\n                chain.\n\n        Returns:\n            sagemaker.model_monitor.Constraints: The instance of Constraints generated from\n                the s3 uri.\n\n        """"""\n        try:\n            body_dict = json.loads(\n                S3Downloader.read_file(s3_uri=constraints_file_s3_uri, session=sagemaker_session)\n            )\n        except ClientError as error:\n            print(\n                ""\\nCould not retrieve constraints file at location \'{}\'. ""\n                ""To manually retrieve Constraints object from a given uri, ""\n                ""use \'my_model_monitor.constraints(my_s3_uri)\' or ""\n                ""\'Constraints.from_s3_uri(my_s3_uri)\'"".format(constraints_file_s3_uri)\n            )\n            raise error\n\n        return cls(\n            body_dict=body_dict,\n            constraints_file_s3_uri=constraints_file_s3_uri,\n            kms_key=kms_key,\n            sagemaker_session=sagemaker_session,\n        )\n\n    @classmethod\n    def from_string(\n        cls, constraints_file_string, kms_key=None, file_name=None, sagemaker_session=None\n    ):\n        """"""Generates a Constraints object from an s3 uri.\n\n        Args:\n            constraints_file_string (str): The uri of the constraints JSON file.\n            kms_key (str): The kms key to be used to encrypt the file in S3.\n            file_name (str): The file name to use when uploading to S3.\n            sagemaker_session (sagemaker.session.Session): A SageMaker Session\n                object, used for SageMaker interactions (default: None). If not\n                specified, one is created using the default AWS configuration\n                chain.\n\n        Returns:\n            sagemaker.model_monitor.Constraints: The instance of Constraints generated from\n                the s3 uri.\n\n        """"""\n        sagemaker_session = sagemaker_session or Session()\n        file_name = file_name or ""constraints.json""\n        desired_s3_uri = os.path.join(\n            ""s3://"", sagemaker_session.default_bucket(), ""monitoring"", str(uuid.uuid4()), file_name\n        )\n        s3_uri = S3Uploader.upload_string_as_file_body(\n            body=constraints_file_string,\n            desired_s3_uri=desired_s3_uri,\n            kms_key=kms_key,\n            session=sagemaker_session,\n        )\n\n        return Constraints.from_s3_uri(\n            constraints_file_s3_uri=s3_uri, kms_key=kms_key, sagemaker_session=sagemaker_session\n        )\n\n    @classmethod\n    def from_file_path(cls, constraints_file_path, kms_key=None, sagemaker_session=None):\n        """"""Initializes a Constraints object from a file path.\n\n        Args:\n            constraints_file_path (str): The path to the constraints file.\n            kms_key (str): The kms_key to use when encrypting the file in S3.\n            sagemaker_session (sagemaker.session.Session): A SageMaker Session\n                object, used for SageMaker interactions (default: None). If not\n                specified, one is created using the default AWS configuration\n                chain.\n\n        Returns:\n            sagemaker.model_monitor.Constraints: The instance of Constraints generated from\n                the local file path.\n\n        """"""\n        file_name = os.path.basename(constraints_file_path)\n\n        with open(constraints_file_path, ""r"") as f:\n            file_body = f.read()\n\n        return Constraints.from_string(\n            constraints_file_string=file_body,\n            file_name=file_name,\n            kms_key=kms_key,\n            sagemaker_session=sagemaker_session,\n        )\n\n    def set_monitoring(self, enable_monitoring, feature_name=None):\n        """"""Sets the monitoring flags on this Constraints object.\n        If feature-name is provided, modify the feature-level override.\n        Else, modify the top-level monitoring flag.\n\n        Args:\n            enable_monitoring (bool): Whether to enable monitoring or not.\n            feature_name (str): Sets the feature-level monitoring flag if provided. Otherwise,\n                sets the file-level override.\n\n        """"""\n        monitoring_api_map = {True: ""Enabled"", False: ""Disabled""}\n        flag = monitoring_api_map[enable_monitoring]\n        if feature_name is None:\n            self.body_dict[""monitoring_config""][""evaluate_constraints""] = flag\n        else:\n            for feature in self.body_dict[""features""]:\n                if feature[""name""] == feature_name:\n                    string_constraints = feature[""string_constraints""]\n                    if string_constraints.get(""monitoring_config_overrides"") is None:\n                        string_constraints[""monitoring_config_overrides""] = {}\n                    string_constraints[""monitoring_config_overrides""][""evaluate_constraints""] = flag\n\n\nclass ConstraintViolations(ModelMonitoringFile):\n    """"""Represents the constraint violations JSON file used in Amazon SageMaker Model Monitoring.\n    """"""\n\n    def __init__(\n        self, body_dict, constraint_violations_file_s3_uri, kms_key=None, sagemaker_session=None\n    ):\n        """"""Initializes the ConstraintViolations object used in Amazon SageMaker Model Monitoring.\n\n        Args:\n            body_dict (str): The body of the constraint violations JSON file.\n            constraint_violations_file_s3_uri (str): The uri of the constraint violations JSON file.\n            kms_key (str): The kms key to be used to decrypt the file in S3.\n            sagemaker_session (sagemaker.session.Session): A SageMaker Session\n                object, used for SageMaker interactions (default: None). If not\n                specified, one is created using the default AWS configuration\n                chain.\n\n        """"""\n        super(ConstraintViolations, self).__init__(\n            body_dict=body_dict,\n            file_s3_uri=constraint_violations_file_s3_uri,\n            kms_key=kms_key,\n            sagemaker_session=sagemaker_session,\n        )\n\n    @classmethod\n    def from_s3_uri(cls, constraint_violations_file_s3_uri, kms_key=None, sagemaker_session=None):\n        """"""Generates a ConstraintViolations object from an s3 uri.\n\n        Args:\n            constraint_violations_file_s3_uri (str): The uri of the constraint violations JSON file.\n            kms_key (str): The kms key to be used to decrypt the file in S3.\n            sagemaker_session (sagemaker.session.Session): A SageMaker Session\n                object, used for SageMaker interactions (default: None). If not\n                specified, one is created using the default AWS configuration\n                chain.\n\n        Returns:\n            sagemaker.model_monitor.ConstraintViolations: The instance of ConstraintViolations\n                generated from the s3 uri.\n\n        """"""\n        try:\n            body_dict = json.loads(\n                S3Downloader.read_file(\n                    s3_uri=constraint_violations_file_s3_uri, session=sagemaker_session\n                )\n            )\n        except ClientError as error:\n            print(\n                ""\\nCould not retrieve constraints file at location \'{}\'. ""\n                ""To manually retrieve ConstraintViolations object from a given uri, ""\n                ""use \'my_model_monitor.constraints(my_s3_uri)\' or ""\n                ""\'ConstraintViolations.from_s3_uri(my_s3_uri)\'"".format(\n                    constraint_violations_file_s3_uri\n                )\n            )\n            raise error\n\n        return cls(\n            body_dict=body_dict,\n            constraint_violations_file_s3_uri=constraint_violations_file_s3_uri,\n            kms_key=kms_key,\n        )\n\n    @classmethod\n    def from_string(\n        cls, constraint_violations_file_string, kms_key=None, file_name=None, sagemaker_session=None\n    ):\n        """"""Generates a ConstraintViolations object from an s3 uri.\n\n        Args:\n            constraint_violations_file_string (str): The uri of the constraint violations JSON file.\n            kms_key (str): The kms key to be used to encrypt the file in S3.\n            file_name (str): The file name to use when uploading to S3.\n            sagemaker_session (sagemaker.session.Session): A SageMaker Session\n                object, used for SageMaker interactions (default: None). If not\n                specified, one is created using the default AWS configuration\n                chain.\n\n        Returns:\n            sagemaker.model_monitor.ConstraintViolations: The instance of ConstraintViolations\n                generated from the s3 uri.\n\n        """"""\n        sagemaker_session = sagemaker_session or Session()\n        file_name = file_name or ""constraint_violations.json""\n        desired_s3_uri = os.path.join(\n            ""s3://"", sagemaker_session.default_bucket(), ""monitoring"", str(uuid.uuid4()), file_name\n        )\n        s3_uri = S3Uploader.upload_string_as_file_body(\n            body=constraint_violations_file_string,\n            desired_s3_uri=desired_s3_uri,\n            kms_key=kms_key,\n            session=sagemaker_session,\n        )\n\n        return ConstraintViolations.from_s3_uri(\n            constraint_violations_file_s3_uri=s3_uri,\n            kms_key=kms_key,\n            sagemaker_session=sagemaker_session,\n        )\n\n    @classmethod\n    def from_file_path(cls, constraint_violations_file_path, kms_key=None, sagemaker_session=None):\n        """"""Initializes a ConstraintViolations object from a file path.\n\n        Args:\n            constraint_violations_file_path (str): The path to the constraint violations file.\n            kms_key (str): The kms_key to use when encrypting the file in S3.\n            sagemaker_session (sagemaker.session.Session): A SageMaker Session\n                object, used for SageMaker interactions (default: None). If not\n                specified, one is created using the default AWS configuration\n                chain.\n\n        Returns:\n            sagemaker.model_monitor.ConstraintViolations: The instance of ConstraintViolations\n                generated from the local file path.\n\n        """"""\n        file_name = os.path.basename(constraint_violations_file_path)\n\n        with open(constraint_violations_file_path, ""r"") as f:\n            file_body = f.read()\n\n        return ConstraintViolations.from_string(\n            constraint_violations_file_string=file_body,\n            file_name=file_name,\n            kms_key=kms_key,\n            sagemaker_session=sagemaker_session,\n        )\n'"
src/sagemaker/mxnet/__init__.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import  # noqa: F401\n\nfrom sagemaker.mxnet.estimator import MXNet  # noqa: F401\nfrom sagemaker.mxnet.model import MXNetModel, MXNetPredictor  # noqa: F401\n'"
src/sagemaker/mxnet/defaults.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nMXNET_VERSION = ""1.2""\n""""""Default MXNet version for when the framework version is not specified.\nThis is no longer updated so as to not break existing workflows.\n""""""\n\nLATEST_VERSION = ""1.6.0""\n""""""The latest version of MXNet included in the SageMaker pre-built Docker images.""""""\n\nLATEST_PY2_VERSION = ""1.6.0""\n'"
src/sagemaker/mxnet/estimator.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nimport logging\n\nfrom sagemaker.estimator import Framework\nfrom sagemaker.fw_utils import (\n    framework_name_from_image,\n    framework_version_from_tag,\n    empty_framework_version_warning,\n    python_deprecation_warning,\n    parameter_v2_rename_warning,\n    is_version_equal_or_higher,\n    warn_if_parameter_server_with_multi_gpu,\n)\nfrom sagemaker.mxnet import defaults\nfrom sagemaker.mxnet.model import MXNetModel\nfrom sagemaker.vpc_utils import VPC_CONFIG_DEFAULT\n\nlogger = logging.getLogger(""sagemaker"")\n\n\nclass MXNet(Framework):\n    """"""Handle end-to-end training and deployment of custom MXNet code.""""""\n\n    __framework_name__ = ""mxnet""\n    _LOWEST_SCRIPT_MODE_VERSION = [""1"", ""3""]\n\n    LATEST_VERSION = defaults.LATEST_VERSION\n\n    def __init__(\n        self,\n        entry_point,\n        source_dir=None,\n        hyperparameters=None,\n        py_version=""py2"",\n        framework_version=None,\n        image_name=None,\n        distributions=None,\n        **kwargs\n    ):\n        """"""This ``Estimator`` executes an MXNet script in a managed MXNet\n        execution environment, within a SageMaker Training Job. The managed\n        MXNet environment is an Amazon-built Docker container that executes\n        functions defined in the supplied ``entry_point`` Python script.\n\n        Training is started by calling\n        :meth:`~sagemaker.amazon.estimator.Framework.fit` on this Estimator.\n        After training is complete, calling\n        :meth:`~sagemaker.amazon.estimator.Framework.deploy` creates a hosted\n        SageMaker endpoint and returns an\n        :class:`~sagemaker.amazon.mxnet.model.MXNetPredictor` instance that can\n        be used to perform inference against the hosted model.\n\n        Technical documentation on preparing MXNet scripts for SageMaker\n        training and using the MXNet Estimator is available on the project\n        home-page: https://github.com/aws/sagemaker-python-sdk\n\n        Args:\n            entry_point (str): Path (absolute or relative) to the Python source\n                file which should be executed as the entry point to training.\n                If ``source_dir`` is specified, then ``entry_point``\n                must point to a file located at the root of ``source_dir``.\n            source_dir (str): Path (absolute, relative or an S3 URI) to a directory\n                with any other training source code dependencies aside from the entry\n                point file (default: None). If ``source_dir`` is an S3 URI, it must\n                point to a tar.gz file. Structure within this directory are preserved\n                when training on Amazon SageMaker.\n            hyperparameters (dict): Hyperparameters that will be used for\n                training (default: None). The hyperparameters are made\n                accessible as a dict[str, str] to the training code on\n                SageMaker. For convenience, this accepts other types for keys\n                and values, but ``str()`` will be called to convert them before\n                training.\n            py_version (str): Python version you want to use for executing your\n                model training code (default: \'py2\'). One of \'py2\' or \'py3\'.\n            framework_version (str): MXNet version you want to use for executing\n                your model training code. List of supported versions\n                https://github.com/aws/sagemaker-python-sdk#mxnet-sagemaker-estimators.\n                If not specified, this will default to 1.2.1.\n            image_name (str): If specified, the estimator will use this image for training and\n                hosting, instead of selecting the appropriate SageMaker official image based on\n                framework_version and py_version. It can be an ECR url or dockerhub image and tag.\n\n                Examples:\n                    * ``123412341234.dkr.ecr.us-west-2.amazonaws.com/my-custom-image:1.0``\n                    * ``custom-image:latest``\n\n            distributions (dict): A dictionary with information on how to run distributed\n                training (default: None). To have parameter servers launched for training,\n                set this value to be ``{\'parameter_server\': {\'enabled\': True}}``.\n            **kwargs: Additional kwargs passed to the\n                :class:`~sagemaker.estimator.Framework` constructor.\n\n        .. tip::\n\n            You can find additional parameters for initializing this class at\n            :class:`~sagemaker.estimator.Framework` and\n            :class:`~sagemaker.estimator.EstimatorBase`.\n        """"""\n        if framework_version is None:\n            logger.warning(\n                empty_framework_version_warning(defaults.MXNET_VERSION, self.LATEST_VERSION)\n            )\n        self.framework_version = framework_version or defaults.MXNET_VERSION\n\n        if ""enable_sagemaker_metrics"" not in kwargs:\n            # enable sagemaker metrics for MXNet v1.6 or greater:\n            if is_version_equal_or_higher([1, 6], self.framework_version):\n                kwargs[""enable_sagemaker_metrics""] = True\n\n        super(MXNet, self).__init__(\n            entry_point, source_dir, hyperparameters, image_name=image_name, **kwargs\n        )\n\n        if py_version == ""py2"":\n            logger.warning(\n                python_deprecation_warning(self.__framework_name__, defaults.LATEST_PY2_VERSION)\n            )\n\n        if distributions is not None:\n            logger.warning(parameter_v2_rename_warning(""distributions"", ""distribution""))\n            train_instance_type = kwargs.get(""train_instance_type"")\n            warn_if_parameter_server_with_multi_gpu(\n                training_instance_type=train_instance_type, distributions=distributions\n            )\n\n        self.py_version = py_version\n        self._configure_distribution(distributions)\n\n    def _configure_distribution(self, distributions):\n        """"""\n        Args:\n            distributions:\n        """"""\n        if distributions is None:\n            return\n\n        if self.framework_version.split(""."") < self._LOWEST_SCRIPT_MODE_VERSION:\n            raise ValueError(\n                ""The distributions option is valid for only versions {} and higher"".format(\n                    ""."".join(self._LOWEST_SCRIPT_MODE_VERSION)\n                )\n            )\n\n        if ""parameter_server"" in distributions:\n            enabled = distributions[""parameter_server""].get(""enabled"", False)\n            self._hyperparameters[self.LAUNCH_PS_ENV_NAME] = enabled\n\n    def create_model(\n        self,\n        model_server_workers=None,\n        role=None,\n        vpc_config_override=VPC_CONFIG_DEFAULT,\n        entry_point=None,\n        source_dir=None,\n        dependencies=None,\n        image_name=None,\n        **kwargs\n    ):\n        """"""Create a SageMaker ``MXNetModel`` object that can be deployed to an\n        ``Endpoint``.\n\n        Args:\n            model_server_workers (int): Optional. The number of worker processes\n                used by the inference server. If None, server will use one\n                worker per vCPU.\n            role (str): The ``ExecutionRoleArn`` IAM Role ARN for the ``Model``,\n                which is also used during transform jobs. If not specified, the\n                role from the Estimator will be used.\n            vpc_config_override (dict[str, list[str]]): Optional override for VpcConfig set on\n                the model. Default: use subnets and security groups from this Estimator.\n\n                * \'Subnets\' (list[str]): List of subnet ids.\n                * \'SecurityGroupIds\' (list[str]): List of security group ids.\n\n            entry_point (str): Path (absolute or relative) to the local Python source file which\n                should be executed as the entry point to training. If ``source_dir`` is specified,\n                then ``entry_point`` must point to a file located at the root of ``source_dir``.\n                If not specified, the training entry point is used.\n            source_dir (str): Path (absolute or relative) to a directory with any other serving\n                source code dependencies aside from the entry point file.\n                If not specified, the model source directory from training is used.\n            dependencies (list[str]): A list of paths to directories (absolute or relative) with\n                any additional libraries that will be exported to the container.\n                If not specified, the dependencies from training are used.\n            image_name (str): If specified, the estimator will use this image for hosting, instead\n                of selecting the appropriate SageMaker official image based on framework_version\n                and py_version. It can be an ECR url or dockerhub image and tag.\n\n                Examples:\n                    * ``123412341234.dkr.ecr.us-west-2.amazonaws.com/my-custom-image:1.0``\n                    * ``custom-image:latest``\n\n            **kwargs: Additional kwargs passed to the :class:`~sagemaker.mxnet.model.MXNetModel`\n                constructor.\n\n        Returns:\n            sagemaker.mxnet.model.MXNetModel: A SageMaker ``MXNetModel`` object.\n            See :func:`~sagemaker.mxnet.model.MXNetModel` for full details.\n        """"""\n        if ""image"" not in kwargs:\n            kwargs[""image""] = image_name or self.image_name\n\n        if ""name"" not in kwargs:\n            kwargs[""name""] = self._current_job_name\n\n        return MXNetModel(\n            self.model_data,\n            role or self.role,\n            entry_point or self.entry_point,\n            source_dir=(source_dir or self._model_source_dir()),\n            enable_cloudwatch_metrics=self.enable_cloudwatch_metrics,\n            container_log_level=self.container_log_level,\n            code_location=self.code_location,\n            py_version=self.py_version,\n            framework_version=self.framework_version,\n            model_server_workers=model_server_workers,\n            sagemaker_session=self.sagemaker_session,\n            vpc_config=self.get_vpc_config(vpc_config_override),\n            dependencies=(dependencies or self.dependencies),\n            **kwargs\n        )\n\n    @classmethod\n    def _prepare_init_params_from_job_description(cls, job_details, model_channel_name=None):\n        """"""Convert the job description to init params that can be handled by the\n        class constructor\n\n        Args:\n            job_details: the returned job details from a describe_training_job\n                API call.\n            model_channel_name (str): Name of the channel where pre-trained\n                model data will be downloaded.\n\n        Returns:\n            dictionary: The transformed init_params\n        """"""\n        init_params = super(MXNet, cls)._prepare_init_params_from_job_description(\n            job_details, model_channel_name\n        )\n        image_name = init_params.pop(""image"")\n        framework, py_version, tag, _ = framework_name_from_image(image_name)\n\n        if not framework:\n            # If we were unable to parse the framework name from the image it is not one of our\n            # officially supported images, in this case just add the image to the init params.\n            init_params[""image_name""] = image_name\n            return init_params\n\n        init_params[""py_version""] = py_version\n\n        # We switched image tagging scheme from regular image version (e.g. \'1.0\') to more\n        # expressive containing framework version, device type and python version\n        # (e.g. \'0.12-gpu-py2\'). For backward compatibility map deprecated image tag \'1.0\' to a\n        # \'0.12\' framework version otherwise extract framework version from the tag itself.\n        init_params[""framework_version""] = (\n            ""0.12"" if tag == ""1.0"" else framework_version_from_tag(tag)\n        )\n\n        training_job_name = init_params[""base_job_name""]\n\n        if framework != cls.__framework_name__:\n            raise ValueError(\n                ""Training job: {} didn\'t use image for requested framework"".format(\n                    training_job_name\n                )\n            )\n\n        return init_params\n'"
src/sagemaker/mxnet/model.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nimport logging\n\nimport packaging.version\n\nimport sagemaker\nfrom sagemaker.fw_utils import (\n    create_image_uri,\n    model_code_key_prefix,\n    python_deprecation_warning,\n    empty_framework_version_warning,\n)\nfrom sagemaker.model import FrameworkModel, MODEL_SERVER_WORKERS_PARAM_NAME\nfrom sagemaker.mxnet import defaults\nfrom sagemaker.predictor import RealTimePredictor, json_serializer, json_deserializer\n\nlogger = logging.getLogger(""sagemaker"")\n\n\nclass MXNetPredictor(RealTimePredictor):\n    """"""A RealTimePredictor for inference against MXNet Endpoints.\n\n    This is able to serialize Python lists, dictionaries, and numpy arrays to\n    multidimensional tensors for MXNet inference.\n    """"""\n\n    def __init__(self, endpoint_name, sagemaker_session=None):\n        """"""Initialize an ``MXNetPredictor``.\n\n        Args:\n            endpoint_name (str): The name of the endpoint to perform inference\n                on.\n            sagemaker_session (sagemaker.session.Session): Session object which\n                manages interactions with Amazon SageMaker APIs and any other\n                AWS services needed. If not specified, the estimator creates one\n                using the default AWS configuration chain.\n        """"""\n        super(MXNetPredictor, self).__init__(\n            endpoint_name, sagemaker_session, json_serializer, json_deserializer\n        )\n\n\nclass MXNetModel(FrameworkModel):\n    """"""An MXNet SageMaker ``Model`` that can be deployed to a SageMaker ``Endpoint``.""""""\n\n    __framework_name__ = ""mxnet""\n    _LOWEST_MMS_VERSION = ""1.4.0""\n\n    def __init__(\n        self,\n        model_data,\n        role,\n        entry_point,\n        image=None,\n        py_version=""py2"",\n        framework_version=None,\n        predictor_cls=MXNetPredictor,\n        model_server_workers=None,\n        **kwargs\n    ):\n        """"""Initialize an MXNetModel.\n\n        Args:\n            model_data (str): The S3 location of a SageMaker model data\n                ``.tar.gz`` file.\n            role (str): An AWS IAM role (either name or full ARN). The Amazon\n                SageMaker training jobs and APIs that create Amazon SageMaker\n                endpoints use this role to access training data and model\n                artifacts. After the endpoint is created, the inference code\n                might use the IAM role, if it needs to access an AWS resource.\n            entry_point (str): Path (absolute or relative) to the Python source\n                file which should be executed as the entry point to model\n                hosting. If ``source_dir`` is specified, then ``entry_point``\n                must point to a file located at the root of ``source_dir``.\n            image (str): A Docker image URI (default: None). If not specified, a\n                default image for MXNet will be used.\n            py_version (str): Python version you want to use for executing your\n                model training code (default: \'py2\').\n            framework_version (str): MXNet version you want to use for executing\n                your model training code.\n            predictor_cls (callable[str, sagemaker.session.Session]): A function\n                to call to create a predictor with an endpoint name and\n                SageMaker ``Session``. If specified, ``deploy()`` returns the\n                result of invoking this function on the created endpoint name.\n            model_server_workers (int): Optional. The number of worker processes\n                used by the inference server. If None, server will use one\n                worker per vCPU.\n            **kwargs: Keyword arguments passed to the ``FrameworkModel``\n                initializer.\n\n        .. tip::\n\n            You can find additional parameters for initializing this class at\n            :class:`~sagemaker.model.FrameworkModel` and\n            :class:`~sagemaker.model.Model`.\n        """"""\n        super(MXNetModel, self).__init__(\n            model_data, image, role, entry_point, predictor_cls=predictor_cls, **kwargs\n        )\n\n        if py_version == ""py2"":\n            logger.warning(\n                python_deprecation_warning(self.__framework_name__, defaults.LATEST_PY2_VERSION)\n            )\n\n        if framework_version is None:\n            logger.warning(\n                empty_framework_version_warning(defaults.MXNET_VERSION, defaults.LATEST_VERSION)\n            )\n\n        self.py_version = py_version\n        self.framework_version = framework_version or defaults.MXNET_VERSION\n        self.model_server_workers = model_server_workers\n\n    def prepare_container_def(self, instance_type, accelerator_type=None):\n        """"""Return a container definition with framework configuration set in\n        model environment variables.\n\n        Args:\n            instance_type (str): The EC2 instance type to deploy this Model to.\n                For example, \'ml.p2.xlarge\'.\n            accelerator_type (str): The Elastic Inference accelerator type to\n                deploy to the instance for loading and making inferences to the\n                model. For example, \'ml.eia1.medium\'.\n\n        Returns:\n            dict[str, str]: A container definition object usable with the\n            CreateModel API.\n        """"""\n        deploy_image = self.image\n        if not deploy_image:\n            region_name = self.sagemaker_session.boto_session.region_name\n            deploy_image = self.serving_image_uri(\n                region_name, instance_type, accelerator_type=accelerator_type\n            )\n\n        deploy_key_prefix = model_code_key_prefix(self.key_prefix, self.name, deploy_image)\n        self._upload_code(deploy_key_prefix, self._is_mms_version())\n        deploy_env = dict(self.env)\n        deploy_env.update(self._framework_env_vars())\n\n        if self.model_server_workers:\n            deploy_env[MODEL_SERVER_WORKERS_PARAM_NAME.upper()] = str(self.model_server_workers)\n        return sagemaker.container_def(\n            deploy_image, self.repacked_model_data or self.model_data, deploy_env\n        )\n\n    def serving_image_uri(self, region_name, instance_type, accelerator_type=None):\n        """"""Create a URI for the serving image.\n\n        Args:\n            region_name (str): AWS region where the image is uploaded.\n            instance_type (str): SageMaker instance type. Used to determine device type\n                (cpu/gpu/family-specific optimized).\n            accelerator_type (str): The Elastic Inference accelerator type to\n                deploy to the instance for loading and making inferences to the\n                model (default: None). For example, \'ml.eia1.medium\'.\n\n        Returns:\n            str: The appropriate image URI based on the given parameters.\n\n        """"""\n        framework_name = self.__framework_name__\n        if self._is_mms_version():\n            framework_name = ""{}-serving"".format(framework_name)\n\n        return create_image_uri(\n            region_name,\n            framework_name,\n            instance_type,\n            self.framework_version,\n            self.py_version,\n            accelerator_type=accelerator_type,\n        )\n\n    def _is_mms_version(self):\n        """"""Whether the framework version corresponds to an inference image using\n        the Multi-Model Server (https://github.com/awslabs/multi-model-server).\n\n        Returns:\n            bool: If the framework version corresponds to an image using MMS.\n        """"""\n        lowest_mms_version = packaging.version.Version(self._LOWEST_MMS_VERSION)\n        framework_version = packaging.version.Version(self.framework_version)\n        return framework_version >= lowest_mms_version\n'"
src/sagemaker/pytorch/__init__.py,0,"b'# Copyright 2018-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nfrom sagemaker.pytorch.estimator import PyTorch  # noqa: F401\nfrom sagemaker.pytorch.model import PyTorchModel, PyTorchPredictor  # noqa: F401\n'"
src/sagemaker/pytorch/defaults.py,0,"b'# Copyright 2018-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nPYTORCH_VERSION = ""0.4""\n""""""Default PyTorch version for when the framework version is not specified.\nThe default version is no longer updated so as to not break existing workflows.\n""""""\n\nLATEST_VERSION = ""1.5.0""\n""""""The latest version of PyTorch included in the SageMaker pre-built Docker images.""""""\n\nPYTHON_VERSION = ""py3""\n\nLATEST_PY2_VERSION = ""1.3.1""\n'"
src/sagemaker/pytorch/estimator.py,0,"b'# Copyright 2018-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nimport logging\n\nfrom sagemaker.estimator import Framework\nfrom sagemaker.fw_utils import (\n    framework_name_from_image,\n    framework_version_from_tag,\n    empty_framework_version_warning,\n    python_deprecation_warning,\n    is_version_equal_or_higher,\n)\nfrom sagemaker.pytorch import defaults\nfrom sagemaker.pytorch.model import PyTorchModel\nfrom sagemaker.vpc_utils import VPC_CONFIG_DEFAULT\n\nlogger = logging.getLogger(""sagemaker"")\n\n\nclass PyTorch(Framework):\n    """"""Handle end-to-end training and deployment of custom PyTorch code.""""""\n\n    __framework_name__ = ""pytorch""\n\n    LATEST_VERSION = defaults.LATEST_VERSION\n\n    def __init__(\n        self,\n        entry_point,\n        source_dir=None,\n        hyperparameters=None,\n        py_version=defaults.PYTHON_VERSION,\n        framework_version=None,\n        image_name=None,\n        **kwargs\n    ):\n        """"""This ``Estimator`` executes an PyTorch script in a managed PyTorch\n        execution environment, within a SageMaker Training Job. The managed\n        PyTorch environment is an Amazon-built Docker container that executes\n        functions defined in the supplied ``entry_point`` Python script.\n\n        Training is started by calling\n        :meth:`~sagemaker.amazon.estimator.Framework.fit` on this Estimator.\n        After training is complete, calling\n        :meth:`~sagemaker.amazon.estimator.Framework.deploy` creates a hosted\n        SageMaker endpoint and returns an\n        :class:`~sagemaker.amazon.pytorch.model.PyTorchPredictor` instance that\n        can be used to perform inference against the hosted model.\n\n        Technical documentation on preparing PyTorch scripts for SageMaker\n        training and using the PyTorch Estimator is available on the project\n        home-page: https://github.com/aws/sagemaker-python-sdk\n\n        Args:\n            entry_point (str): Path (absolute or relative) to the Python source\n                file which should be executed as the entry point to training.\n                If ``source_dir`` is specified, then ``entry_point``\n                must point to a file located at the root of ``source_dir``.\n            source_dir (str): Path (absolute, relative or an S3 URI) to a directory\n                with any other training source code dependencies aside from the entry\n                point file (default: None). If ``source_dir`` is an S3 URI, it must\n                point to a tar.gz file. Structure within this directory are preserved\n                when training on Amazon SageMaker.\n            hyperparameters (dict): Hyperparameters that will be used for\n                training (default: None). The hyperparameters are made\n                accessible as a dict[str, str] to the training code on\n                SageMaker. For convenience, this accepts other types for keys\n                and values, but ``str()`` will be called to convert them before\n                training.\n            py_version (str): Python version you want to use for executing your\n                model training code (default: \'py3\'). One of \'py2\' or \'py3\'.\n            framework_version (str): PyTorch version you want to use for\n                executing your model training code. List of supported versions\n                https://github.com/aws/sagemaker-python-sdk#pytorch-sagemaker-estimators.\n                If not specified, this will default to 0.4.\n            image_name (str): If specified, the estimator will use this image\n                for training and hosting, instead of selecting the appropriate\n                SageMaker official image based on framework_version and\n                py_version. It can be an ECR url or dockerhub image and tag.\n\n                Examples:\n                    * ``123412341234.dkr.ecr.us-west-2.amazonaws.com/my-custom-image:1.0``\n                    * ``custom-image:latest``\n\n            **kwargs: Additional kwargs passed to the :class:`~sagemaker.estimator.Framework`\n                constructor.\n\n        .. tip::\n\n            You can find additional parameters for initializing this class at\n            :class:`~sagemaker.estimator.Framework` and\n            :class:`~sagemaker.estimator.EstimatorBase`.\n        """"""\n        if framework_version is None:\n            logger.warning(\n                empty_framework_version_warning(defaults.PYTORCH_VERSION, self.LATEST_VERSION)\n            )\n        self.framework_version = framework_version or defaults.PYTORCH_VERSION\n\n        if ""enable_sagemaker_metrics"" not in kwargs:\n            # enable sagemaker metrics for PT v1.3 or greater:\n            if is_version_equal_or_higher([1, 3], self.framework_version):\n                kwargs[""enable_sagemaker_metrics""] = True\n\n        super(PyTorch, self).__init__(\n            entry_point, source_dir, hyperparameters, image_name=image_name, **kwargs\n        )\n\n        if py_version == ""py2"":\n            logger.warning(\n                python_deprecation_warning(self.__framework_name__, defaults.LATEST_PY2_VERSION)\n            )\n\n        self.py_version = py_version\n\n    def create_model(\n        self,\n        model_server_workers=None,\n        role=None,\n        vpc_config_override=VPC_CONFIG_DEFAULT,\n        entry_point=None,\n        source_dir=None,\n        dependencies=None,\n        **kwargs\n    ):\n        """"""Create a SageMaker ``PyTorchModel`` object that can be deployed to an\n        ``Endpoint``.\n\n        Args:\n            model_server_workers (int): Optional. The number of worker processes\n                used by the inference server. If None, server will use one\n                worker per vCPU.\n            role (str): The ``ExecutionRoleArn`` IAM Role ARN for the ``Model``,\n                which is also used during transform jobs. If not specified, the\n                role from the Estimator will be used.\n            vpc_config_override (dict[str, list[str]]): Optional override for VpcConfig set on\n                the model. Default: use subnets and security groups from this Estimator.\n                * \'Subnets\' (list[str]): List of subnet ids.\n                * \'SecurityGroupIds\' (list[str]): List of security group ids.\n            entry_point (str): Path (absolute or relative) to the local Python source file which\n                should be executed as the entry point to training. If ``source_dir`` is specified,\n                then ``entry_point`` must point to a file located at the root of ``source_dir``.\n                If not specified, the training entry point is used.\n            source_dir (str): Path (absolute or relative) to a directory with any other serving\n                source code dependencies aside from the entry point file.\n                If not specified, the model source directory from training is used.\n            dependencies (list[str]): A list of paths to directories (absolute or relative) with\n                any additional libraries that will be exported to the container.\n                If not specified, the dependencies from training are used.\n            **kwargs: Additional kwargs passed to the :class:`~sagemaker.pytorch.model.PyTorchModel`\n                constructor.\n\n        Returns:\n            sagemaker.pytorch.model.PyTorchModel: A SageMaker ``PyTorchModel``\n            object. See :func:`~sagemaker.pytorch.model.PyTorchModel` for full details.\n        """"""\n        if ""image"" not in kwargs:\n            kwargs[""image""] = self.image_name\n\n        if ""name"" not in kwargs:\n            kwargs[""name""] = self._current_job_name\n\n        return PyTorchModel(\n            self.model_data,\n            role or self.role,\n            entry_point or self.entry_point,\n            source_dir=(source_dir or self._model_source_dir()),\n            enable_cloudwatch_metrics=self.enable_cloudwatch_metrics,\n            container_log_level=self.container_log_level,\n            code_location=self.code_location,\n            py_version=self.py_version,\n            framework_version=self.framework_version,\n            model_server_workers=model_server_workers,\n            sagemaker_session=self.sagemaker_session,\n            vpc_config=self.get_vpc_config(vpc_config_override),\n            dependencies=(dependencies or self.dependencies),\n            **kwargs\n        )\n\n    @classmethod\n    def _prepare_init_params_from_job_description(cls, job_details, model_channel_name=None):\n        """"""Convert the job description to init params that can be handled by the\n        class constructor\n\n        Args:\n            job_details: the returned job details from a describe_training_job\n                API call.\n            model_channel_name (str): Name of the channel where pre-trained\n                model data will be downloaded.\n\n        Returns:\n            dictionary: The transformed init_params\n        """"""\n        init_params = super(PyTorch, cls)._prepare_init_params_from_job_description(\n            job_details, model_channel_name\n        )\n        image_name = init_params.pop(""image"")\n        framework, py_version, tag, _ = framework_name_from_image(image_name)\n\n        if not framework:\n            # If we were unable to parse the framework name from the image it is not one of our\n            # officially supported images, in this case just add the image to the init params.\n            init_params[""image_name""] = image_name\n            return init_params\n\n        init_params[""py_version""] = py_version\n        init_params[""framework_version""] = framework_version_from_tag(tag)\n\n        training_job_name = init_params[""base_job_name""]\n\n        if framework != cls.__framework_name__:\n            raise ValueError(\n                ""Training job: {} didn\'t use image for requested framework"".format(\n                    training_job_name\n                )\n            )\n\n        return init_params\n'"
src/sagemaker/pytorch/model.py,0,"b'# Copyright 2018-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nimport logging\nimport packaging.version\n\nimport sagemaker\nfrom sagemaker.fw_utils import (\n    create_image_uri,\n    model_code_key_prefix,\n    python_deprecation_warning,\n    empty_framework_version_warning,\n)\nfrom sagemaker.model import FrameworkModel, MODEL_SERVER_WORKERS_PARAM_NAME\nfrom sagemaker.pytorch import defaults\nfrom sagemaker.predictor import RealTimePredictor, npy_serializer, numpy_deserializer\n\nlogger = logging.getLogger(""sagemaker"")\n\n\nclass PyTorchPredictor(RealTimePredictor):\n    """"""A RealTimePredictor for inference against PyTorch Endpoints.\n\n    This is able to serialize Python lists, dictionaries, and numpy arrays to\n    multidimensional tensors for PyTorch inference.\n    """"""\n\n    def __init__(self, endpoint_name, sagemaker_session=None):\n        """"""Initialize an ``PyTorchPredictor``.\n\n        Args:\n            endpoint_name (str): The name of the endpoint to perform inference\n                on.\n            sagemaker_session (sagemaker.session.Session): Session object which\n                manages interactions with Amazon SageMaker APIs and any other\n                AWS services needed. If not specified, the estimator creates one\n                using the default AWS configuration chain.\n        """"""\n        super(PyTorchPredictor, self).__init__(\n            endpoint_name, sagemaker_session, npy_serializer, numpy_deserializer\n        )\n\n\nclass PyTorchModel(FrameworkModel):\n    """"""An PyTorch SageMaker ``Model`` that can be deployed to a SageMaker\n    ``Endpoint``.\n    """"""\n\n    __framework_name__ = ""pytorch""\n    _LOWEST_MMS_VERSION = ""1.2""\n\n    def __init__(\n        self,\n        model_data,\n        role,\n        entry_point,\n        image=None,\n        py_version=defaults.PYTHON_VERSION,\n        framework_version=None,\n        predictor_cls=PyTorchPredictor,\n        model_server_workers=None,\n        **kwargs\n    ):\n        """"""Initialize an PyTorchModel.\n\n        Args:\n            model_data (str): The S3 location of a SageMaker model data\n                ``.tar.gz`` file.\n            role (str): An AWS IAM role (either name or full ARN). The Amazon\n                SageMaker training jobs and APIs that create Amazon SageMaker\n                endpoints use this role to access training data and model\n                artifacts. After the endpoint is created, the inference code\n                might use the IAM role, if it needs to access an AWS resource.\n            entry_point (str): Path (absolute or relative) to the Python source\n                file which should be executed as the entry point to model\n                hosting. If ``source_dir`` is specified, then ``entry_point``\n                must point to a file located at the root of ``source_dir``.\n            image (str): A Docker image URI (default: None). If not specified, a\n                default image for PyTorch will be used.\n            py_version (str): Python version you want to use for executing your\n                model training code (default: \'py3\').\n            framework_version (str): PyTorch version you want to use for\n                executing your model training code.\n            predictor_cls (callable[str, sagemaker.session.Session]): A function\n                to call to create a predictor with an endpoint name and\n                SageMaker ``Session``. If specified, ``deploy()`` returns the\n                result of invoking this function on the created endpoint name.\n            model_server_workers (int): Optional. The number of worker processes\n                used by the inference server. If None, server will use one\n                worker per vCPU.\n            **kwargs: Keyword arguments passed to the ``FrameworkModel``\n                initializer.\n\n        .. tip::\n\n            You can find additional parameters for initializing this class at\n            :class:`~sagemaker.model.FrameworkModel` and\n            :class:`~sagemaker.model.Model`.\n        """"""\n        super(PyTorchModel, self).__init__(\n            model_data, image, role, entry_point, predictor_cls=predictor_cls, **kwargs\n        )\n\n        if py_version == ""py2"":\n            logger.warning(\n                python_deprecation_warning(self.__framework_name__, defaults.LATEST_PY2_VERSION)\n            )\n\n        if framework_version is None:\n            logger.warning(\n                empty_framework_version_warning(defaults.PYTORCH_VERSION, defaults.LATEST_VERSION)\n            )\n\n        self.py_version = py_version\n        self.framework_version = framework_version or defaults.PYTORCH_VERSION\n        self.model_server_workers = model_server_workers\n\n    def prepare_container_def(self, instance_type, accelerator_type=None):\n        """"""Return a container definition with framework configuration set in\n        model environment variables.\n\n        Args:\n            instance_type (str): The EC2 instance type to deploy this Model to.\n                For example, \'ml.p2.xlarge\'.\n            accelerator_type (str): The Elastic Inference accelerator type to\n                deploy to the instance for loading and making inferences to the\n                model.\n\n        Returns:\n            dict[str, str]: A container definition object usable with the\n            CreateModel API.\n        """"""\n        deploy_image = self.image\n        if not deploy_image:\n            region_name = self.sagemaker_session.boto_session.region_name\n            deploy_image = self.serving_image_uri(\n                region_name, instance_type, accelerator_type=accelerator_type\n            )\n\n        deploy_key_prefix = model_code_key_prefix(self.key_prefix, self.name, deploy_image)\n        self._upload_code(deploy_key_prefix, repack=self._is_mms_version())\n        deploy_env = dict(self.env)\n        deploy_env.update(self._framework_env_vars())\n\n        if self.model_server_workers:\n            deploy_env[MODEL_SERVER_WORKERS_PARAM_NAME.upper()] = str(self.model_server_workers)\n        return sagemaker.container_def(\n            deploy_image, self.repacked_model_data or self.model_data, deploy_env\n        )\n\n    def serving_image_uri(self, region_name, instance_type, accelerator_type=None):\n        """"""Create a URI for the serving image.\n\n        Args:\n            region_name (str): AWS region where the image is uploaded.\n            instance_type (str): SageMaker instance type. Used to determine device type\n                (cpu/gpu/family-specific optimized).\n            accelerator_type (str): The Elastic Inference accelerator type to\n                deploy to the instance for loading and making inferences to the\n                model.\n\n        Returns:\n            str: The appropriate image URI based on the given parameters.\n\n        """"""\n        framework_name = self.__framework_name__\n        if self._is_mms_version():\n            framework_name = ""{}-serving"".format(framework_name)\n\n        return create_image_uri(\n            region_name,\n            framework_name,\n            instance_type,\n            self.framework_version,\n            self.py_version,\n            accelerator_type=accelerator_type,\n        )\n\n    def _is_mms_version(self):\n        """"""Whether the framework version corresponds to an inference image using\n        the Multi-Model Server (https://github.com/awslabs/multi-model-server).\n\n        Returns:\n            bool: If the framework version corresponds to an image using MMS.\n        """"""\n        lowest_mms_version = packaging.version.Version(self._LOWEST_MMS_VERSION)\n        framework_version = packaging.version.Version(self.framework_version)\n        return framework_version >= lowest_mms_version\n'"
src/sagemaker/rl/__init__.py,0,"b'# Copyright 2018-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nfrom sagemaker.rl.estimator import (  # noqa: F401\n    RLEstimator,\n    RLFramework,\n    RLToolkit,\n    TOOLKIT_FRAMEWORK_VERSION_MAP,\n)\n'"
src/sagemaker/rl/estimator.py,0,"b'# Copyright 2018-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nimport enum\nimport logging\nimport re\n\nfrom sagemaker.estimator import Framework\nimport sagemaker.fw_utils as fw_utils\nfrom sagemaker.model import FrameworkModel, SAGEMAKER_OUTPUT_LOCATION\nfrom sagemaker.mxnet.model import MXNetModel\nfrom sagemaker.vpc_utils import VPC_CONFIG_DEFAULT\n\nlogger = logging.getLogger(""sagemaker"")\n\nSAGEMAKER_ESTIMATOR = ""sagemaker_estimator""\nSAGEMAKER_ESTIMATOR_VALUE = ""RLEstimator""\nPYTHON_VERSION = ""py3""\nTOOLKIT_FRAMEWORK_VERSION_MAP = {\n    ""coach"": {\n        ""0.10.1"": {""tensorflow"": ""1.11""},\n        ""0.10"": {""tensorflow"": ""1.11""},\n        ""0.11.0"": {""tensorflow"": ""1.11"", ""mxnet"": ""1.3""},\n        ""0.11.1"": {""tensorflow"": ""1.12""},\n        ""0.11"": {""tensorflow"": ""1.12"", ""mxnet"": ""1.3""},\n    },\n    ""ray"": {\n        ""0.5.3"": {""tensorflow"": ""1.11""},\n        ""0.5"": {""tensorflow"": ""1.11""},\n        ""0.6.5"": {""tensorflow"": ""1.12""},\n        ""0.6"": {""tensorflow"": ""1.12""},\n    },\n}\n\n\nclass RLToolkit(enum.Enum):\n    """"""Placeholder docstring""""""\n\n    COACH = ""coach""\n    RAY = ""ray""\n\n\nclass RLFramework(enum.Enum):\n    """"""Placeholder docstring""""""\n\n    TENSORFLOW = ""tensorflow""\n    MXNET = ""mxnet""\n\n\nclass RLEstimator(Framework):\n    """"""Handle end-to-end training and deployment of custom RLEstimator code.""""""\n\n    COACH_LATEST_VERSION_TF = ""0.11.1""\n    COACH_LATEST_VERSION_MXNET = ""0.11.0""\n    RAY_LATEST_VERSION = ""0.6.5""\n\n    def __init__(\n        self,\n        entry_point,\n        toolkit=None,\n        toolkit_version=None,\n        framework=None,\n        source_dir=None,\n        hyperparameters=None,\n        image_name=None,\n        metric_definitions=None,\n        **kwargs\n    ):\n        """"""This Estimator executes an RLEstimator script in a managed\n        Reinforcement Learning (RL) execution environment within a SageMaker\n        Training Job. The managed RL environment is an Amazon-built Docker\n        container that executes functions defined in the supplied\n        ``entry_point`` Python script.\n\n        Training is started by calling\n        :meth:`~sagemaker.amazon.estimator.Framework.fit` on this Estimator.\n        After training is complete, calling\n        :meth:`~sagemaker.amazon.estimator.Framework.deploy` creates a hosted\n        SageMaker endpoint and based on the specified framework returns an\n        :class:`~sagemaker.amazon.mxnet.model.MXNetPredictor` or\n        :class:`~sagemaker.amazon.tensorflow.serving.Predictor` instance that\n        can be used to perform inference against the hosted model.\n\n        Technical documentation on preparing RLEstimator scripts for\n        SageMaker training and using the RLEstimator is available on the project\n        homepage: https://github.com/aws/sagemaker-python-sdk\n\n        Args:\n            entry_point (str): Path (absolute or relative) to the Python source\n                file which should be executed as the entry point to training.\n                If ``source_dir`` is specified, then ``entry_point``\n                must point to a file located at the root of ``source_dir``.\n            toolkit (sagemaker.rl.RLToolkit): RL toolkit you want to use for\n                executing your model training code.\n            toolkit_version (str): RL toolkit version you want to be use for\n                executing your model training code.\n            framework (sagemaker.rl.RLFramework): Framework (MXNet or\n                TensorFlow) you want to be used as a toolkit backed for\n                reinforcement learning training.\n            source_dir (str): Path (absolute, relative or an S3 URI) to a directory\n                with any other training source code dependencies aside from the entry\n                point file (default: None). If ``source_dir`` is an S3 URI, it must\n                point to a tar.gz file. Structure within this directory are preserved\n                when training on Amazon SageMaker.\n            hyperparameters (dict): Hyperparameters that will be used for\n                training (default: None). The hyperparameters are made\n                accessible as a dict[str, str] to the training code on\n                SageMaker. For convenience, this accepts other types for keys\n                and values.\n            image_name (str): An ECR url. If specified, the estimator will use\n                this image for training and hosting, instead of selecting the\n                appropriate SageMaker official image based on framework_version\n                and py_version. Example:\n                123.dkr.ecr.us-west-2.amazonaws.com/my-custom-image:1.0\n            metric_definitions (list[dict]): A list of dictionaries that defines\n                the metric(s) used to evaluate the training jobs. Each\n                dictionary contains two keys: \'Name\' for the name of the metric,\n                and \'Regex\' for the regular expression used to extract the\n                metric from the logs. This should be defined only for jobs that\n                don\'t use an Amazon algorithm.\n            **kwargs: Additional kwargs passed to the\n                :class:`~sagemaker.estimator.Framework` constructor.\n\n        .. tip::\n\n            You can find additional parameters for initializing this class at\n            :class:`~sagemaker.estimator.Framework` and\n            :class:`~sagemaker.estimator.EstimatorBase`.\n        """"""\n        self._validate_images_args(toolkit, toolkit_version, framework, image_name)\n\n        if not image_name:\n            self._validate_toolkit_support(toolkit.value, toolkit_version, framework.value)\n            self.toolkit = toolkit.value\n            self.toolkit_version = toolkit_version\n            self.framework = framework.value\n            self.framework_version = TOOLKIT_FRAMEWORK_VERSION_MAP[self.toolkit][\n                self.toolkit_version\n            ][self.framework]\n\n            # set default metric_definitions based on the toolkit\n            if not metric_definitions:\n                metric_definitions = self.default_metric_definitions(toolkit)\n\n        super(RLEstimator, self).__init__(\n            entry_point,\n            source_dir,\n            hyperparameters,\n            image_name=image_name,\n            metric_definitions=metric_definitions,\n            **kwargs\n        )\n\n    def create_model(\n        self,\n        role=None,\n        vpc_config_override=VPC_CONFIG_DEFAULT,\n        entry_point=None,\n        source_dir=None,\n        dependencies=None,\n        **kwargs\n    ):\n        """"""Create a SageMaker ``RLEstimatorModel`` object that can be deployed\n        to an Endpoint.\n\n        Args:\n            role (str): The ``ExecutionRoleArn`` IAM Role ARN for the ``Model``,\n                which is also used during transform jobs. If not specified, the\n                role from the Estimator will be used.\n            vpc_config_override (dict[str, list[str]]): Optional override for VpcConfig set on\n                the model. Default: use subnets and security groups from this Estimator.\n\n                * \'Subnets\' (list[str]): List of subnet ids.\n                * \'SecurityGroupIds\' (list[str]): List of security group ids.\n\n            entry_point (str): Path (absolute or relative) to the Python source\n                file which should be executed as the entry point for MXNet\n                hosting (default: self.entry_point). If ``source_dir`` is specified,\n                then ``entry_point`` must point to a file located at the root of ``source_dir``.\n            source_dir (str): Path (absolute or relative) to a directory with\n                any other training source code dependencies aside from the entry\n                point file (default: self.source_dir). Structure within this\n                directory are preserved when hosting on Amazon SageMaker.\n            dependencies (list[str]): A list of paths to directories (absolute\n                or relative) with any additional libraries that will be exported\n                to the container (default: self.dependencies). The library\n                folders will be copied to SageMaker in the same folder where the\n                entry_point is copied. If the ```source_dir``` points to S3,\n                code will be uploaded and the S3 location will be used instead.\n            **kwargs: Additional kwargs passed to the :class:`~sagemaker.model.FrameworkModel`\n                constructor.\n\n        Returns:\n            sagemaker.model.FrameworkModel: Depending on input parameters returns\n                one of the following:\n\n                * :class:`~sagemaker.model.FrameworkModel` - if ``image_name`` was specified\n                    on the estimator;\n                * :class:`~sagemaker.mxnet.MXNetModel` - if ``image_name`` wasn\'t specified and\n                    MXNet was used as the RL backend;\n                * :class:`~sagemaker.tensorflow.serving.Model` - if ``image_name`` wasn\'t specified\n                    and TensorFlow was used as the RL backend.\n\n        Raises:\n            ValueError: If image_name was not specified and framework enum is not valid.\n        """"""\n        base_args = dict(\n            model_data=self.model_data,\n            role=role or self.role,\n            image=kwargs.get(""image"", self.image_name),\n            name=kwargs.get(""name"", self._current_job_name),\n            container_log_level=self.container_log_level,\n            sagemaker_session=self.sagemaker_session,\n            vpc_config=self.get_vpc_config(vpc_config_override),\n        )\n\n        if not entry_point and (source_dir or dependencies):\n            raise AttributeError(""Please provide an `entry_point`."")\n\n        entry_point = entry_point or self.entry_point\n        source_dir = source_dir or self._model_source_dir()\n        dependencies = dependencies or self.dependencies\n\n        extended_args = dict(\n            entry_point=entry_point,\n            source_dir=source_dir,\n            code_location=self.code_location,\n            dependencies=dependencies,\n            enable_cloudwatch_metrics=self.enable_cloudwatch_metrics,\n        )\n        extended_args.update(base_args)\n\n        if self.image_name:\n            return FrameworkModel(**extended_args)\n\n        if self.toolkit == RLToolkit.RAY.value:\n            raise NotImplementedError(\n                ""Automatic deployment of Ray models is not currently available.""\n                "" Train policy parameters are available in model checkpoints""\n                "" in the TrainingJob output.""\n            )\n\n        if self.framework == RLFramework.TENSORFLOW.value:\n            from sagemaker.tensorflow.serving import Model as tfsModel\n\n            return tfsModel(framework_version=self.framework_version, **base_args)\n        if self.framework == RLFramework.MXNET.value:\n            return MXNetModel(\n                framework_version=self.framework_version, py_version=PYTHON_VERSION, **extended_args\n            )\n        raise ValueError(\n            ""An unknown RLFramework enum was passed in. framework: {}"".format(self.framework)\n        )\n\n    def train_image(self):\n        """"""Return the Docker image to use for training.\n\n        The :meth:`~sagemaker.estimator.EstimatorBase.fit` method, which does\n        the model training, calls this method to find the image to use for model\n        training.\n\n        Returns:\n            str: The URI of the Docker image.\n        """"""\n        if self.image_name:\n            return self.image_name\n        return fw_utils.create_image_uri(\n            self.sagemaker_session.boto_region_name,\n            self._image_framework(),\n            self.train_instance_type,\n            self._image_version(),\n            py_version=PYTHON_VERSION,\n        )\n\n    @classmethod\n    def _prepare_init_params_from_job_description(cls, job_details, model_channel_name=None):\n        """"""Convert the job description to init params that can be handled by the\n        class constructor\n\n        Args:\n            job_details: the returned job details from a describe_training_job\n                API call.\n            model_channel_name (str): Name of the channel where pre-trained\n                model data will be downloaded.\n\n        Returns:\n            dictionary: The transformed init_params\n        """"""\n        init_params = super(RLEstimator, cls)._prepare_init_params_from_job_description(\n            job_details, model_channel_name\n        )\n\n        image_name = init_params.pop(""image"")\n        framework, _, tag, _ = fw_utils.framework_name_from_image(image_name)\n\n        if not framework:\n            # If we were unable to parse the framework name from the image it is not one of our\n            # officially supported images, in this case just add the image to the init params.\n            init_params[""image_name""] = image_name\n            return init_params\n\n        toolkit, toolkit_version = cls._toolkit_and_version_from_tag(tag)\n\n        if not cls._is_combination_supported(toolkit, toolkit_version, framework):\n            training_job_name = init_params[""base_job_name""]\n            raise ValueError(\n                ""Training job: {} didn\'t use image for requested framework"".format(\n                    training_job_name\n                )\n            )\n\n        init_params[""toolkit""] = RLToolkit(toolkit)\n        init_params[""toolkit_version""] = toolkit_version\n        init_params[""framework""] = RLFramework(framework)\n\n        return init_params\n\n    def hyperparameters(self):\n        """"""Return hyperparameters used by your custom TensorFlow code during\n        model training.\n        """"""\n        hyperparameters = super(RLEstimator, self).hyperparameters()\n\n        additional_hyperparameters = {\n            SAGEMAKER_OUTPUT_LOCATION: self.output_path,\n            # TODO: can be applied to all other estimators\n            SAGEMAKER_ESTIMATOR: SAGEMAKER_ESTIMATOR_VALUE,\n        }\n\n        hyperparameters.update(Framework._json_encode_hyperparameters(additional_hyperparameters))\n        return hyperparameters\n\n    @classmethod\n    def _toolkit_and_version_from_tag(cls, image_tag):\n        """"""\n        Args:\n            image_tag:\n        """"""\n        tag_pattern = re.compile(\n            ""^([A-Z]*|[a-z]*)(\\d.*)-(cpu|gpu)-(py2|py3)$""  # noqa: W605,E501 pylint: disable=anomalous-backslash-in-string\n        )\n        tag_match = tag_pattern.match(image_tag)\n        if tag_match is not None:\n            return tag_match.group(1), tag_match.group(2)\n        return None, None\n\n    @classmethod\n    def _validate_framework_format(cls, framework):\n        """"""\n        Args:\n            framework:\n        """"""\n        if framework and framework not in RLFramework:\n            raise ValueError(\n                ""Invalid type: {}, valid RL frameworks types are: [{}]"".format(\n                    framework, [t for t in RLFramework]\n                )\n            )\n\n    @classmethod\n    def _validate_toolkit_format(cls, toolkit):\n        """"""\n        Args:\n            toolkit:\n        """"""\n        if toolkit and toolkit not in RLToolkit:\n            raise ValueError(\n                ""Invalid type: {}, valid RL toolkits types are: [{}]"".format(\n                    toolkit, [t for t in RLToolkit]\n                )\n            )\n\n    @classmethod\n    def _validate_images_args(cls, toolkit, toolkit_version, framework, image_name):\n        """"""\n        Args:\n            toolkit:\n            toolkit_version:\n            framework:\n            image_name:\n        """"""\n        cls._validate_toolkit_format(toolkit)\n        cls._validate_framework_format(framework)\n\n        if not image_name:\n            not_found_args = []\n            if not toolkit:\n                not_found_args.append(""toolkit"")\n            if not toolkit_version:\n                not_found_args.append(""toolkit_version"")\n            if not framework:\n                not_found_args.append(""framework"")\n            if not_found_args:\n                raise AttributeError(\n                    ""Please provide `{}` or `image_name` parameter."".format(\n                        ""`, `"".join(not_found_args)\n                    )\n                )\n        else:\n            found_args = []\n            if toolkit:\n                found_args.append(""toolkit"")\n            if toolkit_version:\n                found_args.append(""toolkit_version"")\n            if framework:\n                found_args.append(""framework"")\n            if found_args:\n                logger.warning(\n                    ""Parameter `image_name` is specified, ""\n                    ""`%s` are going to be ignored when choosing the image."",\n                    ""`, `"".join(found_args),\n                )\n\n    @classmethod\n    def _is_combination_supported(cls, toolkit, toolkit_version, framework):\n        """"""\n        Args:\n            toolkit:\n            toolkit_version:\n            framework:\n        """"""\n        supported_versions = TOOLKIT_FRAMEWORK_VERSION_MAP.get(toolkit, None)\n        if supported_versions:\n            supported_frameworks = supported_versions.get(toolkit_version, None)\n            if supported_frameworks and supported_frameworks.get(framework, None):\n                return True\n        return False\n\n    @classmethod\n    def _validate_toolkit_support(cls, toolkit, toolkit_version, framework):\n        """"""\n        Args:\n            toolkit:\n            toolkit_version:\n            framework:\n        """"""\n        if not cls._is_combination_supported(toolkit, toolkit_version, framework):\n            raise AttributeError(\n                ""Provided `{}-{}` and `{}` combination is not supported."".format(\n                    toolkit, toolkit_version, framework\n                )\n            )\n\n    def _image_version(self):\n        """"""Placeholder docstring""""""\n        return ""{}{}"".format(self.toolkit, self.toolkit_version)\n\n    def _image_framework(self):\n        """"""Placeholder docstring""""""\n        return ""rl-{}"".format(self.framework)\n\n    @classmethod\n    def default_metric_definitions(cls, toolkit):\n        """"""Provides default metric definitions based on provided toolkit.\n\n        Args:\n            toolkit (sagemaker.rl.RLToolkit): RL Toolkit to be used for\n                training.\n\n        Returns:\n            list: metric definitions\n\n        Raises:\n            ValueError: If toolkit enum is not valid.\n        """"""\n        if toolkit is RLToolkit.COACH:\n            return [\n                {""Name"": ""reward-training"", ""Regex"": ""^Training>.*Total reward=(.*?),""},\n                {""Name"": ""reward-testing"", ""Regex"": ""^Testing>.*Total reward=(.*?),""},\n            ]\n        if toolkit is RLToolkit.RAY:\n            float_regex = ""[-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?""  # noqa: W605, E501\n\n            return [\n                {""Name"": ""episode_reward_mean"", ""Regex"": ""episode_reward_mean: (%s)"" % float_regex},\n                {""Name"": ""episode_reward_max"", ""Regex"": ""episode_reward_max: (%s)"" % float_regex},\n            ]\n        raise ValueError(""An unknown RLToolkit enum was passed in. toolkit: {}"".format(toolkit))\n'"
src/sagemaker/sklearn/__init__.py,0,"b'# Copyright 2018-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nfrom sagemaker.sklearn.estimator import SKLearn  # noqa: F401\nfrom sagemaker.sklearn.model import SKLearnModel, SKLearnPredictor  # noqa: F401\nfrom sagemaker.sklearn.processing import SKLearnProcessor  # noqa: F401\n'"
src/sagemaker/sklearn/defaults.py,0,"b'# Copyright 2018-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nSKLEARN_NAME = ""scikit-learn""\n\nSKLEARN_VERSION = ""0.20.0""\n\nLATEST_PY2_VERSION = ""0.20.0""\n'"
src/sagemaker/sklearn/estimator.py,0,"b'# Copyright 2018-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nimport logging\n\nfrom sagemaker.estimator import Framework\nfrom sagemaker.fw_registry import default_framework_uri\nfrom sagemaker.fw_utils import (\n    framework_name_from_image,\n    empty_framework_version_warning,\n    python_deprecation_warning,\n)\nfrom sagemaker.sklearn import defaults\nfrom sagemaker.sklearn.model import SKLearnModel\nfrom sagemaker.vpc_utils import VPC_CONFIG_DEFAULT\n\nlogger = logging.getLogger(""sagemaker"")\n\n\nclass SKLearn(Framework):\n    """"""Handle end-to-end training and deployment of custom Scikit-learn code.""""""\n\n    __framework_name__ = defaults.SKLEARN_NAME\n\n    def __init__(\n        self,\n        entry_point,\n        framework_version=defaults.SKLEARN_VERSION,\n        source_dir=None,\n        hyperparameters=None,\n        py_version=""py3"",\n        image_name=None,\n        **kwargs\n    ):\n        """"""This ``Estimator`` executes an Scikit-learn script in a managed\n        Scikit-learn execution environment, within a SageMaker Training Job. The\n        managed Scikit-learn environment is an Amazon-built Docker container\n        that executes functions defined in the supplied ``entry_point`` Python\n        script.\n\n        Training is started by calling\n        :meth:`~sagemaker.amazon.estimator.Framework.fit` on this Estimator.\n        After training is complete, calling\n        :meth:`~sagemaker.amazon.estimator.Framework.deploy` creates a hosted\n        SageMaker endpoint and returns an\n        :class:`~sagemaker.amazon.sklearn.model.SKLearnPredictor` instance that\n        can be used to perform inference against the hosted model.\n\n        Technical documentation on preparing Scikit-learn scripts for\n        SageMaker training and using the Scikit-learn Estimator is available on\n        the project home-page: https://github.com/aws/sagemaker-python-sdk\n\n        Args:\n            entry_point (str): Path (absolute or relative) to the Python source\n                file which should be executed as the entry point to training.\n                If ``source_dir`` is specified, then ``entry_point``\n                must point to a file located at the root of ``source_dir``.\n            framework_version (str): Scikit-learn version you want to use for\n                executing your model training code. List of supported versions\n                https://github.com/aws/sagemaker-python-sdk#sklearn-sagemaker-estimators\n            source_dir (str): Path (absolute, relative or an S3 URI) to a directory\n                with any other training source code dependencies aside from the entry\n                point file (default: None). If ``source_dir`` is an S3 URI, it must\n                point to a tar.gz file. Structure within this directory are preserved\n                when training on Amazon SageMaker.\n            hyperparameters (dict): Hyperparameters that will be used for\n                training (default: None). The hyperparameters are made\n                accessible as a dict[str, str] to the training code on\n                SageMaker. For convenience, this accepts other types for keys\n                and values, but ``str()`` will be called to convert them before\n                training.\n            py_version (str): Python version you want to use for executing your\n                model training code (default: \'py3\'). One of \'py2\' or \'py3\'.\n            image_name (str): If specified, the estimator will use this image\n                for training and hosting, instead of selecting the appropriate\n                SageMaker official image based on framework_version and\n                py_version. It can be an ECR url or dockerhub image and tag.\n                Examples:\n                    123.dkr.ecr.us-west-2.amazonaws.com/my-custom-image:1.0\n                    custom-image:latest.\n            **kwargs: Additional kwargs passed to the\n                :class:`~sagemaker.estimator.Framework` constructor.\n\n        .. tip::\n\n            You can find additional parameters for initializing this class at\n            :class:`~sagemaker.estimator.Framework` and\n            :class:`~sagemaker.estimator.EstimatorBase`.\n        """"""\n        # SciKit-Learn does not support distributed training or training on GPU instance types.\n        # Fail fast.\n        train_instance_type = kwargs.get(""train_instance_type"")\n        _validate_not_gpu_instance_type(train_instance_type)\n\n        train_instance_count = kwargs.get(""train_instance_count"")\n        if train_instance_count:\n            if train_instance_count != 1:\n                raise AttributeError(\n                    ""Scikit-Learn does not support distributed training. ""\n                    ""Please remove the \'train_instance_count\' argument or set ""\n                    ""\'train_instance_count=1\' when initializing SKLearn.""\n                )\n        super(SKLearn, self).__init__(\n            entry_point,\n            source_dir,\n            hyperparameters,\n            image_name=image_name,\n            **dict(kwargs, train_instance_count=1)\n        )\n\n        if py_version == ""py2"":\n            logger.warning(\n                python_deprecation_warning(self.__framework_name__, defaults.LATEST_PY2_VERSION)\n            )\n\n        self.py_version = py_version\n\n        if framework_version is None:\n            logger.warning(\n                empty_framework_version_warning(defaults.SKLEARN_VERSION, defaults.SKLEARN_VERSION)\n            )\n        self.framework_version = framework_version or defaults.SKLEARN_VERSION\n\n        if image_name is None:\n            image_tag = ""{}-{}-{}"".format(framework_version, ""cpu"", py_version)\n            self.image_name = default_framework_uri(\n                SKLearn.__framework_name__, self.sagemaker_session.boto_region_name, image_tag\n            )\n\n    def create_model(\n        self,\n        model_server_workers=None,\n        role=None,\n        vpc_config_override=VPC_CONFIG_DEFAULT,\n        entry_point=None,\n        source_dir=None,\n        dependencies=None,\n        **kwargs\n    ):\n        """"""Create a SageMaker ``SKLearnModel`` object that can be deployed to an\n        ``Endpoint``.\n\n        Args:\n            model_server_workers (int): Optional. The number of worker processes\n                used by the inference server. If None, server will use one\n                worker per vCPU.\n            role (str): The ``ExecutionRoleArn`` IAM Role ARN for the ``Model``,\n                which is also used during transform jobs. If not specified, the\n                role from the Estimator will be used.\n            vpc_config_override (dict[str, list[str]]): Optional override for VpcConfig set on\n                the model. Default: use subnets and security groups from this Estimator.\n                * \'Subnets\' (list[str]): List of subnet ids.\n                * \'SecurityGroupIds\' (list[str]): List of security group ids.\n            entry_point (str): Path (absolute or relative) to the local Python source file which\n                should be executed as the entry point to training. If ``source_dir`` is specified,\n                then ``entry_point`` must point to a file located at the root of ``source_dir``.\n                If not specified, the training entry point is used.\n            source_dir (str): Path (absolute or relative) to a directory with any other serving\n                source code dependencies aside from the entry point file.\n                If not specified, the model source directory from training is used.\n            dependencies (list[str]): A list of paths to directories (absolute or relative) with\n                any additional libraries that will be exported to the container.\n                If not specified, the dependencies from training are used.\n            **kwargs: Additional kwargs passed to the :class:`~sagemaker.sklearn.model.SKLearnModel`\n                constructor.\n\n        Returns:\n            sagemaker.sklearn.model.SKLearnModel: A SageMaker ``SKLearnModel``\n            object. See :func:`~sagemaker.sklearn.model.SKLearnModel` for full details.\n        """"""\n        role = role or self.role\n\n        if ""image"" not in kwargs:\n            kwargs[""image""] = self.image_name\n\n        if ""enable_network_isolation"" not in kwargs:\n            kwargs[""enable_network_isolation""] = self.enable_network_isolation()\n\n        if ""name"" not in kwargs:\n            kwargs[""name""] = self._current_job_name\n\n        return SKLearnModel(\n            self.model_data,\n            role,\n            entry_point or self.entry_point,\n            source_dir=(source_dir or self._model_source_dir()),\n            enable_cloudwatch_metrics=self.enable_cloudwatch_metrics,\n            container_log_level=self.container_log_level,\n            code_location=self.code_location,\n            py_version=self.py_version,\n            framework_version=self.framework_version,\n            model_server_workers=model_server_workers,\n            sagemaker_session=self.sagemaker_session,\n            vpc_config=self.get_vpc_config(vpc_config_override),\n            dependencies=(dependencies or self.dependencies),\n            **kwargs\n        )\n\n    @classmethod\n    def _prepare_init_params_from_job_description(cls, job_details, model_channel_name=None):\n        """"""Convert the job description to init params that can be handled by the\n        class constructor\n\n        Args:\n            job_details: the returned job details from a describe_training_job\n                API call.\n            model_channel_name:\n\n        Returns:\n            dictionary: The transformed init_params\n        """"""\n        init_params = super(SKLearn, cls)._prepare_init_params_from_job_description(job_details)\n\n        image_name = init_params.pop(""image"")\n        framework, py_version, _, _ = framework_name_from_image(image_name)\n        init_params[""py_version""] = py_version\n\n        if framework and framework != cls.__framework_name__:\n            training_job_name = init_params[""base_job_name""]\n            raise ValueError(\n                ""Training job: {} didn\'t use image for requested framework"".format(\n                    training_job_name\n                )\n            )\n        if not framework:\n            # If we were unable to parse the framework name from the image it is not one of our\n            # officially supported images, in this case just add the image to the init params.\n            init_params[""image_name""] = image_name\n        return init_params\n\n\ndef _validate_not_gpu_instance_type(training_instance_type):\n    """"""\n    Args:\n        training_instance_type:\n    """"""\n    gpu_instance_types = [\n        ""ml.p2.xlarge"",\n        ""ml.p2.8xlarge"",\n        ""ml.p2.16xlarge"",\n        ""ml.p3.xlarge"",\n        ""ml.p3.8xlarge"",\n        ""ml.p3.16xlarge"",\n    ]\n\n    if training_instance_type in gpu_instance_types:\n        raise ValueError(\n            ""GPU training in not supported for Scikit-Learn. ""\n            ""Please pick a different instance type from here: ""\n            ""https://aws.amazon.com/ec2/instance-types/""\n        )\n'"
src/sagemaker/sklearn/model.py,0,"b'# Copyright 2018-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nimport logging\n\nfrom sagemaker import fw_utils\n\nimport sagemaker\nfrom sagemaker.fw_utils import model_code_key_prefix, python_deprecation_warning\nfrom sagemaker.fw_registry import default_framework_uri\nfrom sagemaker.model import FrameworkModel, MODEL_SERVER_WORKERS_PARAM_NAME\nfrom sagemaker.predictor import RealTimePredictor, npy_serializer, numpy_deserializer\nfrom sagemaker.sklearn import defaults\n\nlogger = logging.getLogger(""sagemaker"")\n\n\nclass SKLearnPredictor(RealTimePredictor):\n    """"""A RealTimePredictor for inference against Scikit-learn Endpoints.\n\n    This is able to serialize Python lists, dictionaries, and numpy arrays to\n    multidimensional tensors for Scikit-learn inference.\n    """"""\n\n    def __init__(self, endpoint_name, sagemaker_session=None):\n        """"""Initialize an ``SKLearnPredictor``.\n\n        Args:\n            endpoint_name (str): The name of the endpoint to perform inference\n                on.\n            sagemaker_session (sagemaker.session.Session): Session object which\n                manages interactions with Amazon SageMaker APIs and any other\n                AWS services needed. If not specified, the estimator creates one\n                using the default AWS configuration chain.\n        """"""\n        super(SKLearnPredictor, self).__init__(\n            endpoint_name, sagemaker_session, npy_serializer, numpy_deserializer\n        )\n\n\nclass SKLearnModel(FrameworkModel):\n    """"""An Scikit-learn SageMaker ``Model`` that can be deployed to a SageMaker\n    ``Endpoint``.\n    """"""\n\n    __framework_name__ = defaults.SKLEARN_NAME\n\n    def __init__(\n        self,\n        model_data,\n        role,\n        entry_point,\n        image=None,\n        py_version=""py3"",\n        framework_version=defaults.SKLEARN_VERSION,\n        predictor_cls=SKLearnPredictor,\n        model_server_workers=None,\n        **kwargs\n    ):\n        """"""Initialize an SKLearnModel.\n\n        Args:\n            model_data (str): The S3 location of a SageMaker model data\n                ``.tar.gz`` file.\n            role (str): An AWS IAM role (either name or full ARN). The Amazon\n                SageMaker training jobs and APIs that create Amazon SageMaker\n                endpoints use this role to access training data and model\n                artifacts. After the endpoint is created, the inference code\n                might use the IAM role, if it needs to access an AWS resource.\n            entry_point (str): Path (absolute or relative) to the Python source\n                file which should be executed as the entry point to model\n                hosting. If ``source_dir`` is specified, then ``entry_point``\n                must point to a file located at the root of ``source_dir``.\n            image (str): A Docker image URI (default: None). If not specified, a\n                default image for Scikit-learn will be used.\n            py_version (str): Python version you want to use for executing your\n                model training code (default: \'py3\').\n            framework_version (str): Scikit-learn version you want to use for\n                executing your model training code.\n            predictor_cls (callable[str, sagemaker.session.Session]): A function\n                to call to create a predictor with an endpoint name and\n                SageMaker ``Session``. If specified, ``deploy()`` returns the\n                result of invoking this function on the created endpoint name.\n            model_server_workers (int): Optional. The number of worker processes\n                used by the inference server. If None, server will use one\n                worker per vCPU.\n            **kwargs: Keyword arguments passed to the ``FrameworkModel``\n                initializer.\n\n        .. tip::\n\n            You can find additional parameters for initializing this class at\n            :class:`~sagemaker.model.FrameworkModel` and\n            :class:`~sagemaker.model.Model`.\n        """"""\n        super(SKLearnModel, self).__init__(\n            model_data, image, role, entry_point, predictor_cls=predictor_cls, **kwargs\n        )\n\n        if py_version == ""py2"":\n            logger.warning(\n                python_deprecation_warning(self.__framework_name__, defaults.LATEST_PY2_VERSION)\n            )\n\n        self.py_version = py_version\n        self.framework_version = framework_version\n        self.model_server_workers = model_server_workers\n\n    def prepare_container_def(self, instance_type, accelerator_type=None):\n        """"""Return a container definition with framework configuration set in\n        model environment variables.\n\n        Args:\n            instance_type (str): The EC2 instance type to deploy this Model to.\n                For example, \'ml.p2.xlarge\'.\n            accelerator_type (str): The Elastic Inference accelerator type to\n                deploy to the instance for loading and making inferences to the\n                model. For example, \'ml.eia1.medium\'. Note: accelerator types\n                are not supported by SKLearnModel.\n\n        Returns:\n            dict[str, str]: A container definition object usable with the\n            CreateModel API.\n        """"""\n        if accelerator_type:\n            raise ValueError(""Accelerator types are not supported for Scikit-Learn."")\n\n        deploy_image = self.image\n        if not deploy_image:\n            image_tag = ""{}-{}-{}"".format(self.framework_version, ""cpu"", self.py_version)\n            deploy_image = default_framework_uri(\n                self.__framework_name__, self.sagemaker_session.boto_region_name, image_tag\n            )\n\n        deploy_key_prefix = model_code_key_prefix(self.key_prefix, self.name, deploy_image)\n        self._upload_code(key_prefix=deploy_key_prefix, repack=self.enable_network_isolation())\n        deploy_env = dict(self.env)\n        deploy_env.update(self._framework_env_vars())\n\n        if self.model_server_workers:\n            deploy_env[MODEL_SERVER_WORKERS_PARAM_NAME.upper()] = str(self.model_server_workers)\n        model_data_uri = (\n            self.repacked_model_data if self.enable_network_isolation() else self.model_data\n        )\n        return sagemaker.container_def(deploy_image, model_data_uri, deploy_env)\n\n    def serving_image_uri(self, region_name, instance_type):\n        """"""Create a URI for the serving image.\n\n        Args:\n            region_name (str): AWS region where the image is uploaded.\n            instance_type (str): SageMaker instance type. Used to determine device type\n                (cpu/gpu/family-specific optimized).\n\n        Returns:\n            str: The appropriate image URI based on the given parameters.\n\n        """"""\n        return fw_utils.create_image_uri(\n            region_name,\n            self.__framework_name__,\n            instance_type,\n            self.framework_version,\n            self.py_version,\n        )\n'"
src/sagemaker/sklearn/processing.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""This module contains code related to SKLearn Processors, which are used\nfor Processing jobs. These jobs let customers perform data pre-processing,\npost-processing, feature engineering, data validation, and model evaluation\nand interpretation on SageMaker.\n""""""\nfrom __future__ import absolute_import\n\nfrom sagemaker.fw_registry import default_framework_uri\n\nfrom sagemaker import Session\nfrom sagemaker.processing import ScriptProcessor\n\n\nclass SKLearnProcessor(ScriptProcessor):\n    """"""Handles Amazon SageMaker processing tasks for jobs using scikit-learn.""""""\n\n    _valid_framework_versions = [""0.20.0""]\n\n    def __init__(\n        self,\n        framework_version,\n        role,\n        instance_type,\n        instance_count,\n        command=None,\n        volume_size_in_gb=30,\n        volume_kms_key=None,\n        output_kms_key=None,\n        max_runtime_in_seconds=None,\n        base_job_name=None,\n        sagemaker_session=None,\n        env=None,\n        tags=None,\n        network_config=None,\n    ):\n        """"""Initialize an ``SKLearnProcessor`` instance. The SKLearnProcessor\n        handles Amazon SageMaker processing tasks for jobs using scikit-learn.\n\n        Args:\n            framework_version (str): The version of scikit-learn.\n            role (str): An AWS IAM role name or ARN. The Amazon SageMaker training jobs\n                and APIs that create Amazon SageMaker endpoints use this role\n                to access training data and model artifacts. After the endpoint\n                is created, the inference code might use the IAM role, if it\n                needs to access an AWS resource.\n            instance_type (str): Type of EC2 instance to use for\n                processing, for example, \'ml.c4.xlarge\'.\n            instance_count (int): The number of instances to run\n                the Processing job with. Defaults to 1.\n            command ([str]): The command to run, along with any command-line flags.\n                Example: [""python3"", ""-v""]. If not provided, [""python3""] or [""python2""]\n                will be chosen based on the py_version parameter.\n            volume_size_in_gb (int): Size in GB of the EBS volume to\n                use for storing data during processing (default: 30).\n            volume_kms_key (str): A KMS key for the processing\n                volume.\n            output_kms_key (str): The KMS key id for all ProcessingOutputs.\n            max_runtime_in_seconds (int): Timeout in seconds.\n                After this amount of time Amazon SageMaker terminates the job\n                regardless of its current status.\n            base_job_name (str): Prefix for processing name. If not specified,\n                the processor generates a default job name, based on the\n                training image name and current timestamp.\n            sagemaker_session (sagemaker.session.Session): Session object which\n                manages interactions with Amazon SageMaker APIs and any other\n                AWS services needed. If not specified, the processor creates one\n                using the default AWS configuration chain.\n            env (dict): Environment variables to be passed to the processing job.\n            tags ([dict]): List of tags to be passed to the processing job.\n            network_config (sagemaker.network.NetworkConfig): A NetworkConfig\n                object that configures network isolation, encryption of\n                inter-container traffic, security group IDs, and subnets.\n        """"""\n        session = sagemaker_session or Session()\n        region = session.boto_region_name\n\n        if framework_version not in self._valid_framework_versions:\n            raise ValueError(\n                ""scikit-learn version {} is not supported. Supported versions are {}"".format(\n                    framework_version, self._valid_framework_versions\n                )\n            )\n\n        if not command:\n            command = [""python3""]\n\n        image_tag = ""{}-{}-{}"".format(framework_version, ""cpu"", ""py3"")\n        image_uri = default_framework_uri(""scikit-learn"", region, image_tag)\n\n        super(SKLearnProcessor, self).__init__(\n            role=role,\n            image_uri=image_uri,\n            instance_count=instance_count,\n            instance_type=instance_type,\n            command=command,\n            volume_size_in_gb=volume_size_in_gb,\n            volume_kms_key=volume_kms_key,\n            output_kms_key=output_kms_key,\n            max_runtime_in_seconds=max_runtime_in_seconds,\n            base_job_name=base_job_name,\n            sagemaker_session=session,\n            env=env,\n            tags=tags,\n            network_config=network_config,\n        )\n'"
src/sagemaker/sparkml/__init__.py,0,"b'# Copyright 2018-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nfrom sagemaker.sparkml.model import SparkMLModel, SparkMLPredictor  # noqa: F401\n'"
src/sagemaker/sparkml/model.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nfrom sagemaker import Model, RealTimePredictor, Session\nfrom sagemaker.content_types import CONTENT_TYPE_CSV\nfrom sagemaker.fw_registry import registry\nfrom sagemaker.predictor import csv_serializer\n\nframework_name = ""sparkml-serving""\nrepo_name = ""sagemaker-sparkml-serving""\n\n\nclass SparkMLPredictor(RealTimePredictor):\n    """"""Performs predictions against an MLeap serialized SparkML model.\n\n    The implementation of\n    :meth:`~sagemaker.predictor.RealTimePredictor.predict` in this\n    `RealTimePredictor` requires a json as input. The input should follow the\n    json format as documented.\n\n    ``predict()`` returns a csv output, comma separated if the output is a\n    list.\n    """"""\n\n    def __init__(self, endpoint, sagemaker_session=None):\n        """"""Initializes a SparkMLPredictor which should be used with SparkMLModel\n        to perform predictions against SparkML models serialized via MLeap. The\n        response is returned in text/csv format which is the default response\n        format for SparkML Serving container.\n\n        Args:\n            endpoint (str): The name of the endpoint to perform inference on.\n            sagemaker_session (sagemaker.session.Session): Session object which\n                manages interactions with Amazon SageMaker APIs and any other\n                AWS services needed. If not specified, the estimator creates one\n                using the default AWS configuration chain.\n        """"""\n        sagemaker_session = sagemaker_session or Session()\n        super(SparkMLPredictor, self).__init__(\n            endpoint=endpoint,\n            sagemaker_session=sagemaker_session,\n            serializer=csv_serializer,\n            content_type=CONTENT_TYPE_CSV,\n        )\n\n\nclass SparkMLModel(Model):\n    """"""Model data and S3 location holder for MLeap serialized SparkML model.\n    Calling :meth:`~sagemaker.model.Model.deploy` creates an Endpoint and return\n    a Predictor to performs predictions against an MLeap serialized SparkML\n    model .\n    """"""\n\n    def __init__(self, model_data, role=None, spark_version=2.2, sagemaker_session=None, **kwargs):\n        """"""Initialize a SparkMLModel.\n\n        Args:\n            model_data (str): The S3 location of a SageMaker model data\n                ``.tar.gz`` file. For SparkML, this will be the output that has\n                been produced by the Spark job after serializing the Model via\n                MLeap.\n            role (str): An AWS IAM role (either name or full ARN). The Amazon\n                SageMaker training jobs and APIs that create Amazon SageMaker\n                endpoints use this role to access training data and model\n                artifacts. After the endpoint is created, the inference code\n                might use the IAM role, if it needs to access an AWS resource.\n            spark_version (str): Spark version you want to use for executing the\n                inference (default: \'2.2\').\n            sagemaker_session (sagemaker.session.Session): Session object which\n                manages interactions with Amazon SageMaker APIs and any other\n                AWS services needed. If not specified, the estimator creates one\n                using the default AWS configuration chain. For local mode,\n                please do not pass this variable.\n            **kwargs: Additional parameters passed to the\n                :class:`~sagemaker.model.Model` constructor.\n\n        .. tip::\n\n            You can find additional parameters for initializing this class at\n            :class:`~sagemaker.model.Model`.\n        """"""\n        # For local mode, sagemaker_session should be passed as None but we need a session to get\n        # boto_region_name\n        region_name = (sagemaker_session or Session()).boto_region_name\n        image = ""{}/{}:{}"".format(registry(region_name, framework_name), repo_name, spark_version)\n        super(SparkMLModel, self).__init__(\n            model_data,\n            image,\n            role,\n            predictor_cls=SparkMLPredictor,\n            sagemaker_session=sagemaker_session,\n            **kwargs\n        )\n'"
src/sagemaker/tensorflow/__init__.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nimport sys\nimport os\n\n# Hack to use our local copy of tensorflow_serving.apis, which contains the protobuf-generated\n# classes for tensorflow serving. Currently tensorflow_serving_api can only be pip-installed for\n# python 2.\nsys.path.append(os.path.dirname(__file__))\n\nfrom sagemaker.tensorflow.estimator import (  # noqa: E402, F401 # pylint: disable=wrong-import-position\n    TensorFlow,\n)\nfrom sagemaker.tensorflow.model import (  # noqa: E402, F401 # pylint: disable=wrong-import-position\n    TensorFlowModel,\n    TensorFlowPredictor,\n)\n'"
src/sagemaker/tensorflow/defaults.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nTF_VERSION = ""1.11""\n""""""Default TF version for when the framework version is not specified.\nThis is no longer updated so as to not break existing workflows.\n""""""\n\nLATEST_VERSION = ""2.2.0""\n""""""The latest version of TensorFlow included in the SageMaker pre-built Docker images.""""""\n\nLATEST_SERVING_VERSION = ""2.1.0""\n""""""The latest version of TensorFlow Serving included in the SageMaker pre-built Docker images.""""""\n\nLATEST_PY2_VERSION = ""2.1.0""\n'"
src/sagemaker/tensorflow/estimator.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nimport contextlib\nimport logging\nimport os\nimport shutil\nimport subprocess\nimport tempfile\nimport threading\nimport time\n\nfrom sagemaker.debugger import DebuggerHookConfig\nfrom sagemaker.estimator import Framework\nimport sagemaker.fw_utils as fw\nfrom sagemaker.tensorflow import defaults\nfrom sagemaker.tensorflow.model import TensorFlowModel\nfrom sagemaker.tensorflow.serving import Model\nfrom sagemaker.transformer import Transformer\nfrom sagemaker import utils\nfrom sagemaker.vpc_utils import VPC_CONFIG_DEFAULT\n\nlogger = logging.getLogger(""sagemaker"")\n\n\n_FRAMEWORK_MODE_ARGS = (\n    ""training_steps"",\n    ""evaluation_steps"",\n    ""requirements_file"",\n    ""checkpoint_path"",\n)\n_SCRIPT_MODE = ""tensorflow-scriptmode""\n_SCRIPT_MODE_SERVING_ERROR_MSG = (\n    ""Script mode containers does not support serving yet. ""\n    ""Please use our new tensorflow-serving container by creating the model ""\n    ""with \'endpoint_type\' set to \'tensorflow-serving\'.""\n)\n_SCRIPT_MODE_TENSORBOARD_WARNING = (\n    ""Tensorboard is not supported with script mode. You can run the following ""\n    ""command: tensorboard --logdir %s --host localhost --port 6006 This can be ""\n    ""run from anywhere with access to the S3 URI used as the logdir.""\n)\n\n\nclass Tensorboard(threading.Thread):\n    """"""Placeholder docstring""""""\n\n    def __init__(self, estimator, logdir=None):\n        """"""Initialize ``Tensorboard`` instance.\n\n        Args:\n            estimator (sagemaker.estimator.Framework): A SageMaker ``Estimator``.\n            logdir (str): Directory for logs (default: None). If not specified, a temporary\n                directory is made.\n        """"""\n        threading.Thread.__init__(self)\n        self.event = threading.Event()\n        self.estimator = estimator\n        self.logdir = logdir or tempfile.mkdtemp()\n\n    @staticmethod\n    def _cmd_exists(cmd):\n        """"""Placeholder docstring""""""\n        for path in os.environ[""PATH""].split(os.pathsep):\n            try:\n                if os.access(os.path.join(path, cmd), os.X_OK):\n                    return True\n            except StopIteration:\n                return False\n        return False\n\n    @staticmethod\n    def _sync_directories(from_directory, to_directory):\n        """"""Sync to_directory with from_directory by copying each file in\n        to_directory with new contents. Files in to_directory will be\n        overwritten by files of the same name in from_directory. We need to\n        keep two copies of the log directory because otherwise TensorBoard\n        picks up temp files from `aws s3 sync` and then stops reading the\n        correct tfevent files. We walk the directory and copy each file\n        individually because the directory that TensorBoard watches needs to\n        always exist.\n\n        Args:\n            from_directory (str): The directory with updated files.\n            to_directory (str): The directory to be synced.\n        """"""\n        if not os.path.exists(to_directory):\n            os.mkdir(to_directory)\n        for root, dirs, files in os.walk(from_directory):\n            to_root = root.replace(from_directory, to_directory)\n            for directory in dirs:\n                to_child_dir = os.path.join(to_root, directory)\n                if not os.path.exists(to_child_dir):\n                    os.mkdir(to_child_dir)\n            for fname in files:\n                from_file = os.path.join(root, fname)\n                to_file = os.path.join(to_root, fname)\n                with open(from_file, ""rb"") as a, open(to_file, ""wb"") as b:\n                    b.write(a.read())\n\n    @staticmethod\n    @contextlib.contextmanager\n    def _temporary_directory():\n        """"""Context manager for a temporary directory. This is similar to\n        tempfile.TemporaryDirectory in python>=3.2.\n        """"""\n        name = tempfile.mkdtemp()\n        try:\n            yield name\n        finally:\n            shutil.rmtree(name)\n\n    def validate_requirements(self):\n        """"""Ensure that TensorBoard and the AWS CLI are installed.\n\n        These dependencies are required for using TensorBoard.\n\n        Raises:\n            EnvironmentError: If at least one requirement is not installed.\n        """"""\n        if not self._cmd_exists(""tensorboard""):\n            raise EnvironmentError(\n                ""TensorBoard is not installed in the system. Please install TensorBoard using the""\n                "" following command: \\n pip install tensorboard""\n            )\n\n        if not self._cmd_exists(""aws""):\n            raise EnvironmentError(\n                ""The AWS CLI is not installed in the system. Please install the AWS CLI using the""\n                "" following command: \\n pip install awscli""\n            )\n\n    def create_tensorboard_process(self):\n        """"""Create a TensorBoard process.\n\n        Returns:\n            tuple: A tuple containing:\n                int: The port number.\n                process: The TensorBoard process.\n\n        Raises:\n            OSError: If no ports between 6006 and 6105 are available for starting TensorBoard.\n        """"""\n        port = 6006\n\n        for _ in range(100):\n            p = subprocess.Popen(\n                [\n                    ""tensorboard"",\n                    ""--logdir"",\n                    self.logdir,\n                    ""--host"",\n                    ""localhost"",\n                    ""--port"",\n                    str(port),\n                ],\n                stdout=subprocess.PIPE,\n                stderr=subprocess.PIPE,\n            )\n            self.event.wait(5)\n            if p.poll():\n                port += 1\n            else:\n                return port, p\n\n        raise OSError(\n            ""No available ports to start TensorBoard. Attempted all ports between 6006 and 6105""\n        )\n\n    def run(self):\n        """"""Run TensorBoard process.""""""\n        port, tensorboard_process = self.create_tensorboard_process()\n\n        logger.info(""TensorBoard 0.1.7 at http://localhost:%s"", port)\n        while not self.estimator.checkpoint_path:\n            self.event.wait(1)\n        with self._temporary_directory() as aws_sync_dir:\n            while not self.event.is_set():\n                args = [""aws"", ""s3"", ""sync"", self.estimator.checkpoint_path, aws_sync_dir]\n                subprocess.call(args, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n                self._sync_directories(aws_sync_dir, self.logdir)\n                self.event.wait(10)\n        tensorboard_process.terminate()\n\n\nclass TensorFlow(Framework):\n    """"""Handle end-to-end training and deployment of user-provided TensorFlow code.""""""\n\n    __framework_name__ = ""tensorflow""\n\n    LATEST_VERSION = defaults.LATEST_VERSION\n\n    _LATEST_1X_VERSION = ""1.15.2""\n\n    _LOWEST_SCRIPT_MODE_ONLY_VERSION = [1, 13]\n    # 2.0.0 still supports py2\n    # we will need to update this version number if future versions still support py2\n    _HIGHEST_PYTHON_2_VERSION = [2, 1, 0]\n\n    def __init__(\n        self,\n        training_steps=None,\n        evaluation_steps=None,\n        checkpoint_path=None,\n        py_version=None,\n        framework_version=None,\n        model_dir=None,\n        requirements_file="""",\n        image_name=None,\n        script_mode=False,\n        distributions=None,\n        **kwargs\n    ):\n        """"""Initialize a ``TensorFlow`` estimator.\n\n        Args:\n            training_steps (int): Perform this many steps of training. `None`, the default means\n                train forever.\n            evaluation_steps (int): Perform this many steps of evaluation. `None`, the default\n                means that evaluation runs until input from eval_input_fn is exhausted (or another\n                exception is raised).\n            checkpoint_path (str): Identifies S3 location where checkpoint data during model\n                training can be saved (default: None). For distributed model training, this\n                parameter is required.\n            py_version (str): Python version you want to use for executing your model training\n                code (default: \'py2\').\n            framework_version (str): TensorFlow version you want to use for executing your model\n                training code. List of supported versions\n                https://github.com/aws/sagemaker-python-sdk#tensorflow-sagemaker-estimators.\n                If not specified, this will default to 1.11.\n            model_dir (str): S3 location where the checkpoint data and models can be exported to\n                during training (default: None). It will be passed in the training script as one of\n                the command line arguments. If not specified, one is provided based on\n                your training configuration:\n\n                * *distributed training with MPI* - ``/opt/ml/model``\n                * *single-machine training or distributed training without MPI* - \\\n                    ``s3://{output_path}/model``\n                * *Local Mode with local sources (file:// instead of s3://)* - \\\n                    ``/opt/ml/shared/model``\n\n            requirements_file (str): Path to a ``requirements.txt`` file (default: \'\'). The path\n                should be within and relative to ``source_dir``. Details on the format can be\n                found in the Pip User Guide:\n                <https://pip.pypa.io/en/stable/reference/pip_install/#requirements-file-format>\n            image_name (str): If specified, the estimator will use this image for training and\n                hosting, instead of selecting the appropriate SageMaker official image based on\n                framework_version and py_version. It can be an ECR url or dockerhub image and tag.\n\n                Examples:\n                    123.dkr.ecr.us-west-2.amazonaws.com/my-custom-image:1.0\n                    custom-image:latest.\n            script_mode (bool): If set to True will the estimator will use the Script Mode\n                containers (default: False). This will be ignored if py_version is set to \'py3\'.\n            distributions (dict): A dictionary with information on how to run distributed training\n                (default: None). Currently we support distributed training with parameter servers\n                and MPI.\n                To enable parameter server use the following setup:\n\n                .. code:: python\n\n                    {\n                        \'parameter_server\':\n                        {\n                            \'enabled\': True\n                        }\n                    }\n\n                To enable MPI:\n\n                .. code:: python\n\n                    {\n                        \'mpi\':\n                        {\n                            \'enabled\': True\n                        }\n                    }\n\n            **kwargs: Additional kwargs passed to the Framework constructor.\n\n        .. tip::\n\n            You can find additional parameters for initializing this class at\n            :class:`~sagemaker.estimator.Framework` and\n            :class:`~sagemaker.estimator.EstimatorBase`.\n        """"""\n        if framework_version is None:\n            logger.warning(\n                fw.empty_framework_version_warning(defaults.TF_VERSION, self.LATEST_VERSION)\n            )\n        self.framework_version = framework_version or defaults.TF_VERSION\n\n        if not py_version:\n            py_version = ""py3"" if self._only_python_3_supported() else ""py2""\n        if py_version == ""py2"":\n            logger.warning(\n                fw.python_deprecation_warning(self.__framework_name__, defaults.LATEST_PY2_VERSION)\n            )\n\n        if distributions is not None:\n            logger.warning(fw.parameter_v2_rename_warning(""distribution"", distributions))\n            train_instance_type = kwargs.get(""train_instance_type"")\n            fw.warn_if_parameter_server_with_multi_gpu(\n                training_instance_type=train_instance_type, distributions=distributions\n            )\n\n        if ""enable_sagemaker_metrics"" not in kwargs:\n            # enable sagemaker metrics for TF v1.15 or greater:\n            if fw.is_version_equal_or_higher([1, 15], self.framework_version):\n                kwargs[""enable_sagemaker_metrics""] = True\n\n        super(TensorFlow, self).__init__(image_name=image_name, **kwargs)\n        self.checkpoint_path = checkpoint_path\n\n        self.py_version = py_version\n        self.training_steps = training_steps\n        self.evaluation_steps = evaluation_steps\n        self.model_dir = model_dir\n        self.script_mode = script_mode\n        self.distributions = distributions or {}\n\n        self._validate_args(\n            py_version=py_version,\n            script_mode=script_mode,\n            framework_version=self.framework_version,\n            training_steps=training_steps,\n            evaluation_steps=evaluation_steps,\n            requirements_file=requirements_file,\n            checkpoint_path=checkpoint_path,\n        )\n        self._validate_requirements_file(requirements_file)\n        self.requirements_file = requirements_file\n\n    def _validate_args(\n        self,\n        py_version,\n        script_mode,\n        framework_version,\n        training_steps,\n        evaluation_steps,\n        requirements_file,\n        checkpoint_path,\n    ):\n        """"""Placeholder docstring""""""\n\n        if py_version == ""py3"" or script_mode:\n\n            if framework_version is None:\n                raise AttributeError(fw.EMPTY_FRAMEWORK_VERSION_ERROR)\n\n            found_args = []\n            if training_steps:\n                found_args.append(""training_steps"")\n            if evaluation_steps:\n                found_args.append(""evaluation_steps"")\n            if requirements_file:\n                found_args.append(""requirements_file"")\n            if checkpoint_path:\n                found_args.append(""checkpoint_path"")\n            if found_args:\n                raise AttributeError(\n                    ""{} are deprecated in script mode. Please do not set {}."".format(\n                        "", "".join(_FRAMEWORK_MODE_ARGS), "", "".join(found_args)\n                    )\n                )\n\n        if py_version == ""py2"" and self._only_python_3_supported():\n            msg = (\n                ""Python 2 containers are only available with {} and lower versions. ""\n                ""Please use a Python 3 container."".format(defaults.LATEST_PY2_VERSION)\n            )\n            raise AttributeError(msg)\n\n        if (not self._script_mode_enabled()) and self._only_script_mode_supported():\n            logger.warning(\n                ""Legacy mode is deprecated in versions 1.13 and higher. Using script mode instead. ""\n                ""Legacy mode and its training parameters will be deprecated in ""\n                ""SageMaker Python SDK v2. Please use TF 1.13 or higher and script mode.""\n            )\n            self.script_mode = True\n\n    def _only_script_mode_supported(self):\n        """"""Placeholder docstring""""""\n        return [\n            int(s) for s in self.framework_version.split(""."")\n        ] >= self._LOWEST_SCRIPT_MODE_ONLY_VERSION\n\n    def _only_python_3_supported(self):\n        """"""Placeholder docstring""""""\n        return [int(s) for s in self.framework_version.split(""."")] > self._HIGHEST_PYTHON_2_VERSION\n\n    def _validate_requirements_file(self, requirements_file):\n        """"""Placeholder docstring""""""\n        if not requirements_file:\n            return\n\n        if not self.source_dir:\n            raise ValueError(""Must specify source_dir along with a requirements file."")\n\n        if self.source_dir.lower().startswith(""s3://""):\n            return\n\n        if os.path.isabs(requirements_file):\n            raise ValueError(\n                ""Requirements file {} is not a path relative to source_dir."".format(\n                    requirements_file\n                )\n            )\n\n        if not os.path.exists(os.path.join(self.source_dir, requirements_file)):\n            raise ValueError(""Requirements file {} does not exist."".format(requirements_file))\n\n    def fit(\n        self,\n        inputs=None,\n        wait=True,\n        logs=True,\n        job_name=None,\n        experiment_config=None,\n        run_tensorboard_locally=False,\n    ):\n        """"""Train a model using the input training dataset.\n\n        See :func:`~sagemaker.estimator.EstimatorBase.fit` for more details.\n\n        Args:\n            inputs (str or dict or sagemaker.session.s3_input): Information about the training data.\n                This can be one of three types:\n\n                * (str) - the S3 location where training data is saved.\n                * (dict[str, str] or dict[str, sagemaker.session.s3_input]) - If using multiple\n                    channels for training data, you can specify a dict mapping channel names\n                    to strings or :func:`~sagemaker.session.s3_input` objects.\n                * (sagemaker.session.s3_input) - channel configuration for S3 data sources that\n                    can provide additional information as well as the path to the training dataset.\n                    See :func:`sagemaker.session.s3_input` for full details.\n\n            wait (bool): Whether the call should wait until the job completes (default: True).\n            logs (bool): Whether to show the logs produced by the job.\n                Only meaningful when wait is True (default: True).\n            job_name (str): Training job name. If not specified, the estimator generates a default\n                job name, based on the training image name and current timestamp.\n            experiment_config (dict[str, str]): Experiment management configuration.\n            run_tensorboard_locally (bool): Whether to execute TensorBoard in a different process\n                with downloaded checkpoint information (default: False). This is an experimental\n                feature, and requires TensorBoard and AWS CLI to be installed. It terminates\n                TensorBoard when execution ends.\n        """"""\n\n        def fit_super():\n            super(TensorFlow, self).fit(inputs, wait, logs, job_name, experiment_config)\n\n        if run_tensorboard_locally and wait is False:\n            raise ValueError(""Tensorboard is not supported with async fit"")\n\n        if self._script_mode_enabled() and run_tensorboard_locally:\n            logger.warning(_SCRIPT_MODE_TENSORBOARD_WARNING, self.model_dir)\n            fit_super()\n        elif run_tensorboard_locally:\n            tensorboard = Tensorboard(self)\n            tensorboard.validate_requirements()\n\n            try:\n                tensorboard.start()\n                fit_super()\n            finally:\n                # sleep 20 secs for tensorboard start up if fit() quits instantly\n                time.sleep(20)\n                tensorboard.event.set()\n                tensorboard.join()\n        else:\n            fit_super()\n\n    @classmethod\n    def _prepare_init_params_from_job_description(cls, job_details, model_channel_name=None):\n        """"""Convert the job description to init params that can be handled by the class constructor\n\n        Args:\n            job_details: the returned job details from a describe_training_job API call.\n\n        Returns:\n             dictionary: The transformed init_params\n\n        """"""\n        init_params = super(TensorFlow, cls)._prepare_init_params_from_job_description(\n            job_details, model_channel_name\n        )\n\n        # Move some of the tensorflow specific init params from hyperparameters into the main init\n        # params.\n        for argument in (""checkpoint_path"", ""training_steps"", ""evaluation_steps"", ""model_dir""):\n            value = init_params[""hyperparameters""].pop(argument, None)\n            if value is not None:\n                init_params[argument] = value\n\n        image_name = init_params.pop(""image"")\n        framework, py_version, tag, script_mode = fw.framework_name_from_image(image_name)\n        if not framework:\n            # If we were unable to parse the framework name from the image it is not one of our\n            # officially supported images, in this case just add the image to the init params.\n            init_params[""image_name""] = image_name\n            return init_params\n\n        if script_mode:\n            init_params[""script_mode""] = True\n\n        init_params[""py_version""] = py_version\n\n        # We switched image tagging scheme from regular image version (e.g. \'1.0\') to more\n        # expressive containing framework version, device type and python version\n        # (e.g. \'1.5-gpu-py2\'). For backward compatibility map deprecated image tag \'1.0\' to a\n        # \'1.4\' framework version otherwise extract framework version from the tag itself.\n        init_params[""framework_version""] = (\n            ""1.4"" if tag == ""1.0"" else fw.framework_version_from_tag(tag)\n        )\n\n        training_job_name = init_params[""base_job_name""]\n        if framework != cls.__framework_name__:\n            raise ValueError(\n                ""Training job: {} didn\'t use image for requested framework"".format(\n                    training_job_name\n                )\n            )\n\n        return init_params\n\n    def create_model(\n        self,\n        model_server_workers=None,\n        role=None,\n        vpc_config_override=VPC_CONFIG_DEFAULT,\n        endpoint_type=None,\n        entry_point=None,\n        source_dir=None,\n        dependencies=None,\n        **kwargs\n    ):\n        """"""Create a ``Model`` object that can be used for creating SageMaker model entities,\n        deploying to a SageMaker endpoint, or starting SageMaker Batch Transform jobs.\n\n        Args:\n            role (str): The ``ExecutionRoleArn`` IAM Role ARN for the ``Model``, which is also\n                used during transform jobs. If not specified, the role from the Estimator will be\n                used.\n            model_server_workers (int): Optional. The number of worker processes used by the\n                inference server. If None, server will use one worker per vCPU.\n            vpc_config_override (dict[str, list[str]]): Optional override for VpcConfig set on the\n                model. Default: use subnets and security groups from this Estimator.\n\n                * \'Subnets\' (list[str]): List of subnet ids.\n                * \'SecurityGroupIds\' (list[str]): List of security group ids.\n\n            endpoint_type (str): Optional. Selects the software stack used by the inference server.\n                If  not specified, the model will be configured to use the default\n                SageMaker model server. If \'tensorflow-serving\', the model will be configured to\n                use the SageMaker Tensorflow Serving container.\n            entry_point (str): Path (absolute or relative) to the local Python source file which\n                should be executed as the entry point to training. If ``source_dir`` is specified,\n                then ``entry_point`` must point to a file located at the root of ``source_dir``.\n                If not specified and ``endpoint_type`` is \'tensorflow-serving\',\n                no entry point is used. If ``endpoint_type`` is also ``None``,\n                then the training entry point is used.\n            source_dir (str): Path (absolute or relative or an S3 URI) to a directory with any\n                other serving source code dependencies aside from the entry point file. If\n                ``source_dir`` is an S3 URI, it must point to a tar.gz file. If not specified\n                and ``endpoint_type`` is \'tensorflow-serving\', no source_dir is used. If\n                ``endpoint_type`` is also ``None``, then the model source directory from\n                training is used.\n            dependencies (list[str]): A list of paths to directories (absolute or relative) with\n                any additional libraries that will be exported to the container.\n                If not specified and ``endpoint_type`` is \'tensorflow-serving\', ``dependencies`` is\n                set to ``None``.\n                If ``endpoint_type`` is also ``None``, then the dependencies from training are used.\n            **kwargs: Additional kwargs passed to :class:`~sagemaker.tensorflow.serving.Model`\n                and :class:`~sagemaker.tensorflow.model.TensorFlowModel` constructors.\n\n        Returns:\n            sagemaker.tensorflow.model.TensorFlowModel or sagemaker.tensorflow.serving.Model: A\n                ``Model`` object. See :class:`~sagemaker.tensorflow.serving.Model` or\n                :class:`~sagemaker.tensorflow.model.TensorFlowModel` for full details.\n        """"""\n        role = role or self.role\n\n        if ""image"" not in kwargs:\n            kwargs[""image""] = self.image_name\n\n        if ""name"" not in kwargs:\n            kwargs[""name""] = self._current_job_name\n\n        if ""enable_network_isolation"" not in kwargs:\n            kwargs[""enable_network_isolation""] = self.enable_network_isolation()\n\n        if endpoint_type == ""tensorflow-serving"" or self._script_mode_enabled():\n            return self._create_tfs_model(\n                role=role,\n                vpc_config_override=vpc_config_override,\n                entry_point=entry_point,\n                source_dir=source_dir,\n                dependencies=dependencies,\n                **kwargs\n            )\n\n        return self._create_default_model(\n            model_server_workers=model_server_workers,\n            role=role,\n            vpc_config_override=vpc_config_override,\n            entry_point=entry_point,\n            source_dir=source_dir,\n            dependencies=dependencies,\n            **kwargs\n        )\n\n    def _create_tfs_model(\n        self,\n        role=None,\n        vpc_config_override=VPC_CONFIG_DEFAULT,\n        entry_point=None,\n        source_dir=None,\n        dependencies=None,\n        **kwargs\n    ):\n        """"""Placeholder docstring""""""\n        return Model(\n            model_data=self.model_data,\n            role=role,\n            container_log_level=self.container_log_level,\n            framework_version=utils.get_short_version(self.framework_version),\n            sagemaker_session=self.sagemaker_session,\n            vpc_config=self.get_vpc_config(vpc_config_override),\n            entry_point=entry_point,\n            source_dir=source_dir,\n            dependencies=dependencies,\n            **kwargs\n        )\n\n    def _create_default_model(\n        self,\n        model_server_workers,\n        role,\n        vpc_config_override,\n        entry_point=None,\n        source_dir=None,\n        dependencies=None,\n        **kwargs\n    ):\n        """"""Placeholder docstring""""""\n        return TensorFlowModel(\n            self.model_data,\n            role,\n            entry_point or self.entry_point,\n            source_dir=source_dir or self._model_source_dir(),\n            enable_cloudwatch_metrics=self.enable_cloudwatch_metrics,\n            env={""SAGEMAKER_REQUIREMENTS"": self.requirements_file},\n            container_log_level=self.container_log_level,\n            code_location=self.code_location,\n            py_version=self.py_version,\n            framework_version=self.framework_version,\n            model_server_workers=model_server_workers,\n            sagemaker_session=self.sagemaker_session,\n            vpc_config=self.get_vpc_config(vpc_config_override),\n            dependencies=dependencies or self.dependencies,\n            **kwargs\n        )\n\n    def hyperparameters(self):\n        """"""Return hyperparameters used by your custom TensorFlow code during model training.""""""\n        hyperparameters = super(TensorFlow, self).hyperparameters()\n\n        self.checkpoint_path = self.checkpoint_path or self._default_s3_path(""checkpoints"")\n        mpi_enabled = False\n\n        if self._script_mode_enabled():\n            additional_hyperparameters = {}\n\n            if ""parameter_server"" in self.distributions:\n                ps_enabled = self.distributions[""parameter_server""].get(""enabled"", False)\n                additional_hyperparameters[self.LAUNCH_PS_ENV_NAME] = ps_enabled\n\n            if ""mpi"" in self.distributions:\n                mpi_dict = self.distributions[""mpi""]\n                mpi_enabled = mpi_dict.get(""enabled"", False)\n                additional_hyperparameters[self.LAUNCH_MPI_ENV_NAME] = mpi_enabled\n\n                if mpi_dict.get(""processes_per_host""):\n                    additional_hyperparameters[self.MPI_NUM_PROCESSES_PER_HOST] = mpi_dict.get(\n                        ""processes_per_host""\n                    )\n\n                additional_hyperparameters[self.MPI_CUSTOM_MPI_OPTIONS] = mpi_dict.get(\n                    ""custom_mpi_options"", """"\n                )\n\n            self.model_dir = self.model_dir or self._default_s3_path(""model"", mpi=mpi_enabled)\n            additional_hyperparameters[""model_dir""] = self.model_dir\n        else:\n            additional_hyperparameters = {\n                ""checkpoint_path"": self.checkpoint_path,\n                ""training_steps"": self.training_steps,\n                ""evaluation_steps"": self.evaluation_steps,\n                ""sagemaker_requirements"": self.requirements_file,\n            }\n\n        hyperparameters.update(Framework._json_encode_hyperparameters(additional_hyperparameters))\n        return hyperparameters\n\n    def _default_s3_path(self, directory, mpi=False):\n        """"""Placeholder docstring""""""\n        local_code = utils.get_config_value(""local.local_code"", self.sagemaker_session.config)\n        if self.sagemaker_session.local_mode and local_code:\n            return ""/opt/ml/shared/{}"".format(directory)\n        if mpi:\n            return ""/opt/ml/model""\n        if self._current_job_name:\n            return os.path.join(self.output_path, self._current_job_name, directory)\n        return None\n\n    def _script_mode_enabled(self):\n        """"""Placeholder docstring""""""\n        return self.py_version == ""py3"" or self.script_mode\n\n    def _validate_and_set_debugger_configs(self):\n        """"""\n        Disable Debugger Hook Config for ParameterServer (PS) as it is not\n        supported in smdebug.\n\n        Else, set default HookConfig\n        """"""\n        ps_enabled = ""parameter_server"" in self.distributions and self.distributions[\n            ""parameter_server""\n        ].get(""enabled"", False)\n        if ps_enabled:\n            if self.debugger_hook_config is not None or self.debugger_rule_configs is not None:\n                logger.info(\n                    ""Amazon SageMaker Debugger does not currently support ""\n                    ""Parameter Server distribution""\n                )\n            self.debugger_hook_config = None\n            self.debugger_rule_configs = None\n        elif self.debugger_hook_config is None and fw._region_supports_debugger(\n            self.sagemaker_session.boto_session.region_name\n        ):\n            # Set defaults for debugging.\n            self.debugger_hook_config = DebuggerHookConfig(s3_output_path=self.output_path)\n\n    def train_image(self):\n        """"""Placeholder docstring""""""\n        if self.image_name:\n            return self.image_name\n\n        if self._script_mode_enabled():\n            return fw.create_image_uri(\n                self.sagemaker_session.boto_region_name,\n                _SCRIPT_MODE,\n                self.train_instance_type,\n                self.framework_version,\n                self.py_version,\n            )\n\n        return super(TensorFlow, self).train_image()\n\n    def transformer(\n        self,\n        instance_count,\n        instance_type,\n        strategy=None,\n        assemble_with=None,\n        output_path=None,\n        output_kms_key=None,\n        accept=None,\n        env=None,\n        max_concurrent_transforms=None,\n        max_payload=None,\n        tags=None,\n        role=None,\n        model_server_workers=None,\n        volume_kms_key=None,\n        endpoint_type=None,\n        entry_point=None,\n        vpc_config_override=VPC_CONFIG_DEFAULT,\n        enable_network_isolation=None,\n        model_name=None,\n    ):\n        """"""Return a ``Transformer`` that uses a SageMaker Model based on the training job. It\n        reuses the SageMaker Session and base job name used by the Estimator.\n\n        Args:\n            instance_count (int): Number of EC2 instances to use.\n            instance_type (str): Type of EC2 instance to use, for example, \'ml.c4.xlarge\'.\n            strategy (str): The strategy used to decide how to batch records in a single request\n                (default: None). Valid values: \'MultiRecord\' and \'SingleRecord\'.\n            assemble_with (str): How the output is assembled (default: None). Valid values: \'Line\'\n                or \'None\'.\n            output_path (str): S3 location for saving the transform result. If not specified,\n                results are stored to a default bucket.\n            output_kms_key (str): Optional. KMS key ID for encrypting the transform output\n                (default: None).\n            accept (str): The accept header passed by the client to\n                the inference endpoint. If it is supported by the endpoint,\n                it will be the format of the batch transform output.\n            env (dict): Environment variables to be set for use during the transform job\n                (default: None).\n            max_concurrent_transforms (int): The maximum number of HTTP requests to be made to\n                each individual transform container at one time.\n            max_payload (int): Maximum size of the payload in a single HTTP request to the\n                container in MB.\n            tags (list[dict]): List of tags for labeling a transform job. If none specified, then\n                the tags used for the training job are used for the transform job.\n            role (str): The ``ExecutionRoleArn`` IAM Role ARN for the ``Model``, which is also\n                used during transform jobs. If not specified, the role from the Estimator will be\n                used.\n            model_server_workers (int): Optional. The number of worker processes used by the\n                inference server. If None, server will use one worker per vCPU.\n            volume_kms_key (str): Optional. KMS key ID for encrypting the volume attached to the ML\n                compute instance (default: None).\n            endpoint_type (str): Optional. Selects the software stack used by the inference server.\n                If not specified, the model will be configured to use the default\n                SageMaker model server.\n                If \'tensorflow-serving\', the model will be configured to\n                use the SageMaker Tensorflow Serving container.\n            entry_point (str): Path (absolute or relative) to the local Python source file which\n                should be executed as the entry point to training. If ``source_dir`` is specified,\n                then ``entry_point`` must point to a file located at the root of ``source_dir``.\n                If not specified and ``endpoint_type`` is \'tensorflow-serving\',\n                no entry point is used. If ``endpoint_type`` is also ``None``,\n                then the training entry point is used.\n            vpc_config_override (dict[str, list[str]]): Optional override for\n                the VpcConfig set on the model.\n                Default: use subnets and security groups from this Estimator.\n\n                * \'Subnets\' (list[str]): List of subnet ids.\n                * \'SecurityGroupIds\' (list[str]): List of security group ids.\n\n            enable_network_isolation (bool): Specifies whether container will\n                run in network isolation mode. Network isolation mode restricts\n                the container access to outside networks (such as the internet).\n                The container does not make any inbound or outbound network\n                calls. If True, a channel named ""code"" will be created for any\n                user entry script for inference. Also known as Internet-free mode.\n                If not specified, this setting is taken from the estimator\'s\n                current configuration.\n            model_name (str): Name to use for creating an Amazon SageMaker\n                model. If not specified, the name of the training job is used.\n        """"""\n        role = role or self.role\n\n        if self.latest_training_job is None:\n            logging.warning(\n                ""No finished training job found associated with this estimator. Please make sure ""\n                ""this estimator is only used for building workflow config""\n            )\n            return Transformer(\n                model_name or self._current_job_name,\n                instance_count,\n                instance_type,\n                strategy=strategy,\n                assemble_with=assemble_with,\n                output_path=output_path,\n                output_kms_key=output_kms_key,\n                accept=accept,\n                max_concurrent_transforms=max_concurrent_transforms,\n                max_payload=max_payload,\n                env=env or {},\n                tags=tags,\n                base_transform_job_name=self.base_job_name,\n                volume_kms_key=volume_kms_key,\n                sagemaker_session=self.sagemaker_session,\n            )\n\n        if enable_network_isolation is None:\n            enable_network_isolation = self.enable_network_isolation()\n\n        model = self.create_model(\n            model_server_workers=model_server_workers,\n            role=role,\n            vpc_config_override=vpc_config_override,\n            endpoint_type=endpoint_type,\n            entry_point=entry_point,\n            enable_network_isolation=enable_network_isolation,\n            name=model_name,\n        )\n\n        return model.transformer(\n            instance_count,\n            instance_type,\n            strategy=strategy,\n            assemble_with=assemble_with,\n            output_path=output_path,\n            output_kms_key=output_kms_key,\n            accept=accept,\n            env=env,\n            max_concurrent_transforms=max_concurrent_transforms,\n            max_payload=max_payload,\n            tags=tags,\n            volume_kms_key=volume_kms_key,\n        )\n'"
src/sagemaker/tensorflow/model.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nimport logging\n\nimport sagemaker\nfrom sagemaker.fw_utils import (\n    create_image_uri,\n    model_code_key_prefix,\n    python_deprecation_warning,\n    empty_framework_version_warning,\n)\nfrom sagemaker.model import FrameworkModel, MODEL_SERVER_WORKERS_PARAM_NAME\nfrom sagemaker.predictor import RealTimePredictor\nfrom sagemaker.tensorflow import defaults\nfrom sagemaker.tensorflow.predictor import tf_json_serializer, tf_json_deserializer\n\nlogger = logging.getLogger(""sagemaker"")\n\n\nclass TensorFlowPredictor(RealTimePredictor):\n    """"""A ``RealTimePredictor`` for inference against TensorFlow endpoint.\n\n    This is able to serialize Python lists, dictionaries, and numpy arrays to\n    multidimensional tensors for inference\n    """"""\n\n    def __init__(self, endpoint_name, sagemaker_session=None):\n        """"""Initialize an ``TensorFlowPredictor``.\n\n        Args:\n            endpoint_name (str): The name of the endpoint to perform inference\n                on.\n            sagemaker_session (sagemaker.session.Session): Session object which\n                manages interactions with Amazon SageMaker APIs and any other\n                AWS services needed. If not specified, the estimator creates one\n                using the default AWS configuration chain.\n        """"""\n        super(TensorFlowPredictor, self).__init__(\n            endpoint_name, sagemaker_session, tf_json_serializer, tf_json_deserializer\n        )\n\n\nclass TensorFlowModel(FrameworkModel):\n    """"""Placeholder docstring""""""\n\n    __framework_name__ = ""tensorflow""\n\n    def __init__(\n        self,\n        model_data,\n        role,\n        entry_point,\n        image=None,\n        py_version=""py2"",\n        framework_version=None,\n        predictor_cls=TensorFlowPredictor,\n        model_server_workers=None,\n        **kwargs\n    ):\n        """"""Initialize an TensorFlowModel.\n\n        Args:\n            model_data (str): The S3 location of a SageMaker model data\n                ``.tar.gz`` file.\n            role (str): An AWS IAM role (either name or full ARN). The Amazon\n                SageMaker training jobs and APIs that create Amazon SageMaker\n                endpoints use this role to access training data and model\n                artifacts. After the endpoint is created, the inference code\n                might use the IAM role, if it needs to access an AWS resource.\n            entry_point (str): Path (absolute or relative) to the Python source\n                file which should be executed as the entry point to model\n                hosting. If ``source_dir`` is specified, then ``entry_point``\n                must point to a file located at the root of ``source_dir``.\n            image (str): A Docker image URI (default: None). If not specified, a\n                default image for TensorFlow will be used.\n            py_version (str): Python version you want to use for executing your\n                model training code (default: \'py2\').\n            framework_version (str): TensorFlow version you want to use for\n                executing your model training code.\n            predictor_cls (callable[str, sagemaker.session.Session]): A function\n                to call to create a predictor with an endpoint name and\n                SageMaker ``Session``. If specified, ``deploy()`` returns the\n                result of invoking this function on the created endpoint name.\n            model_server_workers (int): Optional. The number of worker processes\n                used by the inference server. If None, server will use one\n                worker per vCPU.\n            **kwargs: Keyword arguments passed to the ``FrameworkModel``\n                initializer.\n\n        .. tip::\n\n            You can find additional parameters for initializing this class at\n            :class:`~sagemaker.model.FrameworkModel` and\n            :class:`~sagemaker.model.Model`.\n        """"""\n        super(TensorFlowModel, self).__init__(\n            model_data, image, role, entry_point, predictor_cls=predictor_cls, **kwargs\n        )\n\n        if py_version == ""py2"":\n            logger.warning(\n                python_deprecation_warning(self.__framework_name__, defaults.LATEST_PY2_VERSION)\n            )\n\n        if framework_version is None:\n            logger.warning(\n                empty_framework_version_warning(defaults.TF_VERSION, defaults.LATEST_VERSION)\n            )\n\n        self.py_version = py_version\n        self.framework_version = framework_version or defaults.TF_VERSION\n        self.model_server_workers = model_server_workers\n\n    def prepare_container_def(self, instance_type, accelerator_type=None):\n        """"""Return a container definition with framework configuration set in\n        model environment variables.\n\n        This also uploads user-supplied code to S3.\n\n        Args:\n            instance_type (str): The EC2 instance type to deploy this Model to.\n                For example, \'ml.p2.xlarge\'.\n            accelerator_type (str): The Elastic Inference accelerator type to\n                deploy to the instance for loading and making inferences to the\n                model. For example, \'ml.eia1.medium\'.\n\n        Returns:\n            dict[str, str]: A container definition object usable with the\n            CreateModel API.\n        """"""\n        deploy_image = self.image\n        if not deploy_image:\n            region_name = self.sagemaker_session.boto_region_name\n            deploy_image = self.serving_image_uri(\n                region_name, instance_type, accelerator_type=accelerator_type\n            )\n\n        deploy_key_prefix = model_code_key_prefix(self.key_prefix, self.name, deploy_image)\n        self._upload_code(deploy_key_prefix)\n        deploy_env = dict(self.env)\n        deploy_env.update(self._framework_env_vars())\n\n        if self.model_server_workers:\n            deploy_env[MODEL_SERVER_WORKERS_PARAM_NAME.upper()] = str(self.model_server_workers)\n\n        return sagemaker.container_def(deploy_image, self.model_data, deploy_env)\n\n    def serving_image_uri(self, region_name, instance_type, accelerator_type=None):\n        """"""Create a URI for the serving image.\n\n        Args:\n            region_name (str): AWS region where the image is uploaded.\n            instance_type (str): SageMaker instance type. Used to determine device type\n                (cpu/gpu/family-specific optimized).\n            accelerator_type (str): The Elastic Inference accelerator type to\n                deploy to the instance for loading and making inferences to the\n                model (default: None). For example, \'ml.eia1.medium\'.\n\n        Returns:\n            str: The appropriate image URI based on the given parameters.\n\n        """"""\n        return create_image_uri(\n            region_name,\n            self.__framework_name__,\n            instance_type,\n            self.framework_version,\n            self.py_version,\n            accelerator_type=accelerator_type,\n        )\n'"
src/sagemaker/tensorflow/predictor.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nimport json\n\nimport google.protobuf.json_format as json_format\nfrom google.protobuf.message import DecodeError\nfrom protobuf_to_dict import protobuf_to_dict\nfrom sagemaker.content_types import CONTENT_TYPE_JSON, CONTENT_TYPE_OCTET_STREAM, CONTENT_TYPE_CSV\nfrom sagemaker.predictor import json_serializer, csv_serializer\n\n\ndef _possible_responses():\n    """"""\n    Returns: Possible available request types.\n    """"""\n    from tensorflow.core.framework import tensor_pb2  # pylint: disable=no-name-in-module\n    from tensorflow_serving.apis import (\n        predict_pb2,\n        classification_pb2,\n        inference_pb2,\n        regression_pb2,\n    )\n\n    return [\n        predict_pb2.PredictResponse,\n        classification_pb2.ClassificationResponse,\n        inference_pb2.MultiInferenceResponse,\n        regression_pb2.RegressionResponse,\n        tensor_pb2.TensorProto,\n    ]\n\n\nREGRESSION_REQUEST = ""RegressionRequest""\nMULTI_INFERENCE_REQUEST = ""MultiInferenceRequest""\nCLASSIFICATION_REQUEST = ""ClassificationRequest""\nPREDICT_REQUEST = ""PredictRequest""\n\n\nclass _TFProtobufSerializer(object):\n    """"""Placeholder docstring""""""\n\n    def __init__(self):\n        self.content_type = CONTENT_TYPE_OCTET_STREAM\n\n    def __call__(self, data):\n        # isinstance does not work here because a same protobuf message can be imported from a\n        # different module. For example sagemaker.tensorflow.tensorflow_serving.regression_pb2 and\n        # tensorflow_serving.apis.regression_pb2\n        """"""\n        Args:\n            data:\n        """"""\n        predict_type = data.__class__.__name__\n\n        available_requests = [\n            PREDICT_REQUEST,\n            CLASSIFICATION_REQUEST,\n            MULTI_INFERENCE_REQUEST,\n            REGRESSION_REQUEST,\n        ]\n\n        if predict_type not in available_requests:\n            raise ValueError(""request type {} is not supported"".format(predict_type))\n        return data.SerializeToString()\n\n\ntf_serializer = _TFProtobufSerializer()\n\n\nclass _TFProtobufDeserializer(object):\n    """"""Placeholder docstring""""""\n\n    def __init__(self):\n        """"""Placeholder docstring""""""\n        self.accept = CONTENT_TYPE_OCTET_STREAM\n\n    def __call__(self, stream, content_type):\n        """"""\n        Args:\n            stream:\n            content_type:\n        """"""\n        try:\n            data = stream.read()\n        finally:\n            stream.close()\n\n        for possible_response in _possible_responses():\n            try:\n                response = possible_response()\n                response.ParseFromString(data)\n                return response\n            except (UnicodeDecodeError, DecodeError):\n                # given that the payload does not have the response type, there no way to infer\n                # the response without keeping state, so I\'m iterating all the options.\n                pass\n        raise ValueError(""data is not in the expected format"")\n\n\ntf_deserializer = _TFProtobufDeserializer()\n\n\nclass _TFJsonSerializer(object):\n    """"""Placeholder docstring""""""\n\n    def __init__(self):\n        self.content_type = CONTENT_TYPE_JSON\n\n    def __call__(self, data):\n        """"""\n        Args:\n            data:\n        """"""\n\n        from tensorflow.core.framework import tensor_pb2  # pylint: disable=no-name-in-module\n\n        if isinstance(data, tensor_pb2.TensorProto):\n            return json_format.MessageToJson(data)\n        return json_serializer(data)\n\n\ntf_json_serializer = _TFJsonSerializer()\n\n\nclass _TFJsonDeserializer(object):\n    """"""Placeholder docstring""""""\n\n    def __init__(self):\n        self.accept = CONTENT_TYPE_JSON\n\n    def __call__(self, stream, content_type):\n        """"""\n        Args:\n            stream:\n            content_type:\n        """"""\n        try:\n            data = stream.read()\n        finally:\n            stream.close()\n\n        for possible_response in _possible_responses():\n            try:\n                return protobuf_to_dict(json_format.Parse(data, possible_response()))\n            except (UnicodeDecodeError, DecodeError, json_format.ParseError):\n                # given that the payload does not have the response type, there no way to infer\n                # the response without keeping state, so I\'m iterating all the options.\n                pass\n        return json.loads(data.decode())\n\n\ntf_json_deserializer = _TFJsonDeserializer()\n\n\nclass _TFCsvSerializer(object):\n    """"""Placeholder docstring""""""\n\n    def __init__(self):\n        self.content_type = CONTENT_TYPE_CSV\n\n    def __call__(self, data):\n        """"""\n        Args:\n            data:\n        """"""\n        to_serialize = data\n\n        from tensorflow.core.framework import tensor_pb2  # pylint: disable=no-name-in-module\n        from tensorflow.python.framework import tensor_util  # pylint: disable=no-name-in-module\n\n        if isinstance(data, tensor_pb2.TensorProto):\n            to_serialize = tensor_util.MakeNdarray(data)\n        return csv_serializer(to_serialize)\n\n\ntf_csv_serializer = _TFCsvSerializer()\n'"
src/sagemaker/tensorflow/serving.py,0,"b'# Copyright 2018-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nimport logging\n\nimport sagemaker\nfrom sagemaker.content_types import CONTENT_TYPE_JSON\nfrom sagemaker.fw_utils import create_image_uri\nfrom sagemaker.predictor import json_serializer, json_deserializer\nfrom sagemaker.tensorflow.defaults import TF_VERSION\n\n\nclass Predictor(sagemaker.RealTimePredictor):\n    """"""A ``RealTimePredictor`` implementation for inference against TensorFlow\n    Serving endpoints.\n    """"""\n\n    def __init__(\n        self,\n        endpoint_name,\n        sagemaker_session=None,\n        serializer=json_serializer,\n        deserializer=json_deserializer,\n        content_type=None,\n        model_name=None,\n        model_version=None,\n    ):\n        """"""Initialize a ``TFSPredictor``. See ``sagemaker.RealTimePredictor``\n        for more info about parameters.\n\n        Args:\n            endpoint_name (str): The name of the endpoint to perform inference\n                on.\n            sagemaker_session (sagemaker.session.Session): Session object which\n                manages interactions with Amazon SageMaker APIs and any other\n                AWS services needed. If not specified, the estimator creates one\n                using the default AWS configuration chain.\n            serializer (callable): Optional. Default serializes input data to\n                json. Handles dicts, lists, and numpy arrays.\n            deserializer (callable): Optional. Default parses the response using\n                ``json.load(...)``.\n            content_type (str): Optional. The ""ContentType"" for invocation\n                requests. If specified, overrides the ``content_type`` from the\n                serializer (default: None).\n            model_name (str): Optional. The name of the SavedModel model that\n                should handle the request. If not specified, the endpoint\'s\n                default model will handle the request.\n            model_version (str): Optional. The version of the SavedModel model\n                that should handle the request. If not specified, the latest\n                version of the model will be used.\n        """"""\n        super(Predictor, self).__init__(\n            endpoint_name, sagemaker_session, serializer, deserializer, content_type\n        )\n\n        attributes = []\n        if model_name:\n            attributes.append(""tfs-model-name={}"".format(model_name))\n        if model_version:\n            attributes.append(""tfs-model-version={}"".format(model_version))\n        self._model_attributes = "","".join(attributes) if attributes else None\n\n    def classify(self, data):\n        """"""\n        Args:\n            data:\n        """"""\n        return self._classify_or_regress(data, ""classify"")\n\n    def regress(self, data):\n        """"""\n        Args:\n            data:\n        """"""\n        return self._classify_or_regress(data, ""regress"")\n\n    def _classify_or_regress(self, data, method):\n        """"""\n        Args:\n            data:\n            method:\n        """"""\n        if method not in [""classify"", ""regress""]:\n            raise ValueError(""invalid TensorFlow Serving method: {}"".format(method))\n\n        if self.content_type != CONTENT_TYPE_JSON:\n            raise ValueError(""The {} api requires json requests."".format(method))\n\n        args = {""CustomAttributes"": ""tfs-method={}"".format(method)}\n\n        return self.predict(data, args)\n\n    def predict(self, data, initial_args=None):\n        """"""\n        Args:\n            data:\n            initial_args:\n        """"""\n        args = dict(initial_args) if initial_args else {}\n        if self._model_attributes:\n            if ""CustomAttributes"" in args:\n                args[""CustomAttributes""] += "","" + self._model_attributes\n            else:\n                args[""CustomAttributes""] = self._model_attributes\n\n        return super(Predictor, self).predict(data, args)\n\n\nclass Model(sagemaker.model.FrameworkModel):\n    """"""Placeholder docstring""""""\n\n    FRAMEWORK_NAME = ""tensorflow-serving""\n    LOG_LEVEL_PARAM_NAME = ""SAGEMAKER_TFS_NGINX_LOGLEVEL""\n    LOG_LEVEL_MAP = {\n        logging.DEBUG: ""debug"",\n        logging.INFO: ""info"",\n        logging.WARNING: ""warn"",\n        logging.ERROR: ""error"",\n        logging.CRITICAL: ""crit"",\n    }\n    LATEST_EIA_VERSION = [2, 0]\n\n    def __init__(\n        self,\n        model_data,\n        role,\n        entry_point=None,\n        image=None,\n        framework_version=TF_VERSION,\n        container_log_level=None,\n        predictor_cls=Predictor,\n        **kwargs\n    ):\n        """"""Initialize a Model.\n\n        Args:\n            model_data (str): The S3 location of a SageMaker model data\n                ``.tar.gz`` file.\n            role (str): An AWS IAM role (either name or full ARN). The Amazon\n                SageMaker APIs that create Amazon SageMaker endpoints use this\n                role to access model artifacts.\n            entry_point:\n            image (str): A Docker image URI (default: None). If not specified, a\n                default image for TensorFlow Serving will be used.\n            framework_version (str): Optional. TensorFlow Serving version you\n                want to use.\n            container_log_level (int): Log level to use within the container\n                (default: logging.ERROR). Valid values are defined in the Python\n                logging module.\n            predictor_cls (callable[str, sagemaker.session.Session]): A function\n                to call to create a predictor with an endpoint name and\n                SageMaker ``Session``. If specified, ``deploy()`` returns the\n                result of invoking this function on the created endpoint name.\n            **kwargs: Keyword arguments passed to the ``Model`` initializer.\n\n        .. tip::\n\n            You can find additional parameters for initializing this class at\n            :class:`~sagemaker.model.FrameworkModel` and\n            :class:`~sagemaker.model.Model`.\n        """"""\n        super(Model, self).__init__(\n            model_data=model_data,\n            role=role,\n            image=image,\n            predictor_cls=predictor_cls,\n            entry_point=entry_point,\n            **kwargs\n        )\n        self._framework_version = framework_version\n        self._container_log_level = container_log_level\n\n    def deploy(\n        self,\n        initial_instance_count,\n        instance_type,\n        accelerator_type=None,\n        endpoint_name=None,\n        update_endpoint=False,\n        tags=None,\n        kms_key=None,\n        wait=True,\n        data_capture_config=None,\n    ):\n\n        if accelerator_type and not self._eia_supported():\n            msg = ""The TensorFlow version %s doesn\'t support EIA."" % self._framework_version\n\n            raise AttributeError(msg)\n        return super(Model, self).deploy(\n            initial_instance_count=initial_instance_count,\n            instance_type=instance_type,\n            accelerator_type=accelerator_type,\n            endpoint_name=endpoint_name,\n            update_endpoint=update_endpoint,\n            tags=tags,\n            kms_key=kms_key,\n            wait=wait,\n            data_capture_config=data_capture_config,\n        )\n\n    def _eia_supported(self):\n        """"""Return true if TF version is EIA enabled""""""\n        return [int(s) for s in self._framework_version.split(""."")][:2] <= self.LATEST_EIA_VERSION\n\n    def prepare_container_def(self, instance_type, accelerator_type=None):\n        """"""\n        Args:\n            instance_type:\n            accelerator_type:\n        """"""\n        image = self._get_image_uri(instance_type, accelerator_type)\n        env = self._get_container_env()\n\n        if self.entry_point:\n            key_prefix = sagemaker.fw_utils.model_code_key_prefix(self.key_prefix, self.name, image)\n\n            bucket = self.bucket or self.sagemaker_session.default_bucket()\n            model_data = ""s3://{}/{}/model.tar.gz"".format(bucket, key_prefix)\n\n            sagemaker.utils.repack_model(\n                self.entry_point,\n                self.source_dir,\n                self.dependencies,\n                self.model_data,\n                model_data,\n                self.sagemaker_session,\n                kms_key=self.model_kms_key,\n            )\n        else:\n            model_data = self.model_data\n\n        return sagemaker.container_def(image, model_data, env)\n\n    def _get_container_env(self):\n        """"""Placeholder docstring""""""\n        if not self._container_log_level:\n            return self.env\n\n        if self._container_log_level not in Model.LOG_LEVEL_MAP:\n            logging.warning(""ignoring invalid container log level: %s"", self._container_log_level)\n            return self.env\n\n        env = dict(self.env)\n        env[Model.LOG_LEVEL_PARAM_NAME] = Model.LOG_LEVEL_MAP[self._container_log_level]\n        return env\n\n    def _get_image_uri(self, instance_type, accelerator_type=None):\n        """"""\n        Args:\n            instance_type:\n            accelerator_type:\n        """"""\n        if self.image:\n            return self.image\n\n        region_name = self.sagemaker_session.boto_region_name\n        return create_image_uri(\n            region_name,\n            Model.FRAMEWORK_NAME,\n            instance_type,\n            self._framework_version,\n            accelerator_type=accelerator_type,\n        )\n\n    def serving_image_uri(\n        self, region_name, instance_type, accelerator_type=None\n    ):  # pylint: disable=unused-argument\n        """"""Create a URI for the serving image.\n\n        Args:\n            region_name (str): AWS region where the image is uploaded.\n            instance_type (str): SageMaker instance type. Used to determine device type\n                (cpu/gpu/family-specific optimized).\n            accelerator_type (str): The Elastic Inference accelerator type to\n                deploy to the instance for loading and making inferences to the\n                model (default: None). For example, \'ml.eia1.medium\'.\n\n        Returns:\n            str: The appropriate image URI based on the given parameters.\n\n        """"""\n        return self._get_image_uri(instance_type=instance_type, accelerator_type=accelerator_type)\n'"
src/sagemaker/workflow/__init__.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n'"
src/sagemaker/workflow/airflow.py,2,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import print_function, absolute_import\n\nimport os\nimport re\n\nimport sagemaker\nfrom sagemaker import fw_utils, job, utils, session, vpc_utils\nfrom sagemaker.amazon import amazon_estimator\n\n\ndef prepare_framework(estimator, s3_operations):\n    """"""Prepare S3 operations (specify where to upload `source_dir` ) and\n    environment variables related to framework.\n\n    Args:\n        estimator (sagemaker.estimator.Estimator): The framework estimator to\n            get information from and update.\n        s3_operations (dict): The dict to specify s3 operations (upload\n            `source_dir` ).\n    """"""\n    if estimator.code_location is not None:\n        bucket, key = fw_utils.parse_s3_url(estimator.code_location)\n        key = os.path.join(key, estimator._current_job_name, ""source"", ""sourcedir.tar.gz"")\n    elif estimator.uploaded_code is not None:\n        bucket, key = fw_utils.parse_s3_url(estimator.uploaded_code.s3_prefix)\n    else:\n        bucket = estimator.sagemaker_session._default_bucket\n        key = os.path.join(estimator._current_job_name, ""source"", ""sourcedir.tar.gz"")\n\n    script = os.path.basename(estimator.entry_point)\n\n    if estimator.source_dir and estimator.source_dir.lower().startswith(""s3://""):\n        code_dir = estimator.source_dir\n        estimator.uploaded_code = fw_utils.UploadedCode(s3_prefix=code_dir, script_name=script)\n    else:\n        code_dir = ""s3://{}/{}"".format(bucket, key)\n        estimator.uploaded_code = fw_utils.UploadedCode(s3_prefix=code_dir, script_name=script)\n        s3_operations[""S3Upload""] = [\n            {\n                ""Path"": estimator.source_dir or estimator.entry_point,\n                ""Bucket"": bucket,\n                ""Key"": key,\n                ""Tar"": True,\n            }\n        ]\n    estimator._hyperparameters[sagemaker.model.DIR_PARAM_NAME] = code_dir\n    estimator._hyperparameters[sagemaker.model.SCRIPT_PARAM_NAME] = script\n    estimator._hyperparameters[\n        sagemaker.model.CLOUDWATCH_METRICS_PARAM_NAME\n    ] = estimator.enable_cloudwatch_metrics\n    estimator._hyperparameters[\n        sagemaker.model.CONTAINER_LOG_LEVEL_PARAM_NAME\n    ] = estimator.container_log_level\n    estimator._hyperparameters[sagemaker.model.JOB_NAME_PARAM_NAME] = estimator._current_job_name\n    estimator._hyperparameters[\n        sagemaker.model.SAGEMAKER_REGION_PARAM_NAME\n    ] = estimator.sagemaker_session.boto_region_name\n\n\ndef prepare_amazon_algorithm_estimator(estimator, inputs, mini_batch_size=None):\n    """"""Set up amazon algorithm estimator, adding the required `feature_dim`\n    hyperparameter from training data.\n\n    Args:\n        estimator (sagemaker.amazon.amazon_estimator.AmazonAlgorithmEstimatorBase): An estimator\n            for a built-in Amazon algorithm to get information from and update.\n        inputs: The training data.\n           * (sagemaker.amazon.amazon_estimator.RecordSet) - A collection of\n\n                Amazon :class:~`Record` objects serialized and stored in S3. For\n                use with an estimator for an Amazon algorithm.\n\n            * (list[sagemaker.amazon.amazon_estimator.RecordSet]) - A list of\n                  :class:~`sagemaker.amazon.amazon_estimator.RecordSet` objects,\n                  where each instance is a different channel of training data.\n        mini_batch_size:\n    """"""\n    if isinstance(inputs, list):\n        for record in inputs:\n            if isinstance(record, amazon_estimator.RecordSet) and record.channel == ""train"":\n                estimator.feature_dim = record.feature_dim\n                break\n    elif isinstance(inputs, amazon_estimator.RecordSet):\n        estimator.feature_dim = inputs.feature_dim\n    else:\n        raise TypeError(""Training data must be represented in RecordSet or list of RecordSets"")\n    estimator.mini_batch_size = mini_batch_size\n\n\ndef training_base_config(estimator, inputs=None, job_name=None, mini_batch_size=None):  # noqa: C901\n    """"""Export Airflow base training config from an estimator\n\n    Args:\n        estimator (sagemaker.estimator.EstimatorBase): The estimator to export\n            training config from. Can be a BYO estimator, Framework estimator or\n            Amazon algorithm estimator.\n        inputs: Information about the training data. Please refer to the ``fit()``\n            method of\n                the associated estimator, as this can take any of the following\n                forms:\n\n            * (str) - The S3 location where training data is saved.\n\n            * (dict[str, str] or dict[str, sagemaker.session.s3_input]) - If using multiple\n                  channels for training data, you can specify a dict mapping channel names to\n                  strings or :func:`~sagemaker.session.s3_input` objects.\n\n            * (sagemaker.session.s3_input) - Channel configuration for S3 data sources that can\n                  provide additional information about the training dataset. See\n                  :func:`sagemaker.session.s3_input` for full details.\n\n            * (sagemaker.amazon.amazon_estimator.RecordSet) - A collection of\n                  Amazon :class:~`Record` objects serialized and stored in S3.\n                  For use with an estimator for an Amazon algorithm.\n\n            * (list[sagemaker.amazon.amazon_estimator.RecordSet]) - A list of\n                  :class:~`sagemaker.amazon.amazon_estimator.RecordSet` objects,\n                  where each instance is a different channel of training data.\n        job_name (str): Specify a training job name if needed.\n        mini_batch_size (int): Specify this argument only when estimator is a\n            built-in estimator of an Amazon algorithm. For other estimators,\n            batch size should be specified in the estimator.\n\n    Returns:\n        dict: Training config that can be directly used by\n        SageMakerTrainingOperator in Airflow.\n    """"""\n    if isinstance(estimator, sagemaker.amazon.amazon_estimator.AmazonAlgorithmEstimatorBase):\n        estimator.prepare_workflow_for_training(\n            records=inputs, mini_batch_size=mini_batch_size, job_name=job_name\n        )\n    else:\n        estimator.prepare_workflow_for_training(job_name=job_name)\n\n    default_bucket = estimator.sagemaker_session.default_bucket()\n    s3_operations = {}\n\n    if job_name is not None:\n        estimator._current_job_name = job_name\n    else:\n        base_name = estimator.base_job_name or utils.base_name_from_image(estimator.train_image())\n        estimator._current_job_name = utils.name_from_base(base_name)\n\n    if estimator.output_path is None:\n        estimator.output_path = ""s3://{}/"".format(default_bucket)\n\n    if isinstance(estimator, sagemaker.estimator.Framework):\n        prepare_framework(estimator, s3_operations)\n\n    elif isinstance(estimator, amazon_estimator.AmazonAlgorithmEstimatorBase):\n        prepare_amazon_algorithm_estimator(estimator, inputs, mini_batch_size)\n    job_config = job._Job._load_config(inputs, estimator, expand_role=False, validate_uri=False)\n\n    train_config = {\n        ""AlgorithmSpecification"": {\n            ""TrainingImage"": estimator.train_image(),\n            ""TrainingInputMode"": estimator.input_mode,\n        },\n        ""OutputDataConfig"": job_config[""output_config""],\n        ""StoppingCondition"": job_config[""stop_condition""],\n        ""ResourceConfig"": job_config[""resource_config""],\n        ""RoleArn"": job_config[""role""],\n    }\n\n    if job_config[""input_config""] is not None:\n        train_config[""InputDataConfig""] = job_config[""input_config""]\n\n    if job_config[""vpc_config""] is not None:\n        train_config[""VpcConfig""] = job_config[""vpc_config""]\n\n    if estimator.hyperparameters() is not None:\n        hyperparameters = {str(k): str(v) for (k, v) in estimator.hyperparameters().items()}\n\n    if hyperparameters and len(hyperparameters) > 0:\n        train_config[""HyperParameters""] = hyperparameters\n\n    if s3_operations:\n        train_config[""S3Operations""] = s3_operations\n\n    return train_config\n\n\ndef training_config(estimator, inputs=None, job_name=None, mini_batch_size=None):\n    """"""Export Airflow training config from an estimator\n\n    Args:\n        estimator (sagemaker.estimator.EstimatorBase): The estimator to export\n            training config from. Can be a BYO estimator, Framework estimator or\n            Amazon algorithm estimator.\n        inputs: Information about the training data. Please refer to the ``fit()``\n            method of the associated estimator, as this can take any of the following forms:\n            * (str) - The S3 location where training data is saved.\n\n            * (dict[str, str] or dict[str, sagemaker.session.s3_input]) - If using multiple\n                  channels for training data, you can specify a dict mapping channel names to\n                  strings or :func:`~sagemaker.session.s3_input` objects.\n\n            * (sagemaker.session.s3_input) - Channel configuration for S3 data sources that can\n                  provide additional information about the training dataset. See\n                  :func:`sagemaker.session.s3_input` for full details.\n\n            * (sagemaker.amazon.amazon_estimator.RecordSet) - A collection of\n                  Amazon :class:~`Record` objects serialized and stored in S3.\n                  For use with an estimator for an Amazon algorithm.\n\n            * (list[sagemaker.amazon.amazon_estimator.RecordSet]) - A list of\n                  :class:~`sagemaker.amazon.amazon_estimator.RecordSet` objects,\n                  where each instance is a different channel of training data.\n        job_name (str): Specify a training job name if needed.\n        mini_batch_size (int): Specify this argument only when estimator is a\n            built-in estimator of an Amazon algorithm. For other estimators,\n            batch size should be specified in the estimator.\n\n    Returns:\n        dict: Training config that can be directly used by\n        SageMakerTrainingOperator in Airflow.\n    """"""\n\n    train_config = training_base_config(estimator, inputs, job_name, mini_batch_size)\n\n    train_config[""TrainingJobName""] = estimator._current_job_name\n\n    if estimator.tags is not None:\n        train_config[""Tags""] = estimator.tags\n\n    if estimator.metric_definitions is not None:\n        train_config[""AlgorithmSpecification""][""MetricDefinitions""] = estimator.metric_definitions\n\n    return train_config\n\n\ndef tuning_config(tuner, inputs, job_name=None, include_cls_metadata=False, mini_batch_size=None):\n    """"""Export Airflow tuning config from a HyperparameterTuner\n\n    Args:\n        tuner (sagemaker.tuner.HyperparameterTuner): The tuner to export tuning\n            config from.\n        inputs: Information about the training data. Please refer to the ``fit()``\n            method of the associated estimator in the tuner, as this can take any of the\n            following forms:\n\n            * (str) - The S3 location where training data is saved.\n\n            * (dict[str, str] or dict[str, sagemaker.session.s3_input]) - If using multiple\n                  channels for training data, you can specify a dict mapping channel names to\n                  strings or :func:`~sagemaker.session.s3_input` objects.\n\n            * (sagemaker.session.s3_input) - Channel configuration for S3 data sources that can\n                  provide additional information about the training dataset. See\n                  :func:`sagemaker.session.s3_input` for full details.\n\n            * (sagemaker.amazon.amazon_estimator.RecordSet) - A collection of\n                  Amazon :class:~`Record` objects serialized and stored in S3.\n                  For use with an estimator for an Amazon algorithm.\n\n            * (list[sagemaker.amazon.amazon_estimator.RecordSet]) - A list of\n                  :class:~`sagemaker.amazon.amazon_estimator.RecordSet` objects,\n                  where each instance is a different channel of training data.\n\n            * (dict[str, one the forms above]): Required by only tuners created via\n                  the factory method ``HyperparameterTuner.create()``. The keys should be the\n                  same estimator names as keys for the ``estimator_dict`` argument of the\n                  ``HyperparameterTuner.create()`` method.\n        job_name (str): Specify a tuning job name if needed.\n        include_cls_metadata: It can take one of the following two forms.\n\n            * (bool) - Whether or not the hyperparameter tuning job should include information\n                about the estimator class (default: False). This information is passed as a\n                hyperparameter, so if the algorithm you are using cannot handle unknown\n                hyperparameters (e.g. an Amazon SageMaker built-in algorithm that does not\n                have a custom estimator in the Python SDK), then set ``include_cls_metadata``\n                to ``False``.\n            * (dict[str, bool]) - This version should be used for tuners created via the factory\n                method ``HyperparameterTuner.create()``, to specify the flag for individual\n                estimators provided in the ``estimator_dict`` argument of the method. The keys\n                would be the same estimator names as in ``estimator_dict``. If one estimator\n                doesn\'t need the flag set, then no need to include it in the dictionary. If none\n                of the estimators need the flag set, then an empty dictionary ``{}`` must be used.\n\n        mini_batch_size: It can take one of the following two forms.\n\n            * (int) - Specify this argument only when estimator is a built-in estimator of an\n                Amazon algorithm. For other estimators, batch size should be specified in the\n                estimator.\n            * (dict[str, int]) - This version should be used for tuners created via the factory\n                method ``HyperparameterTuner.create()``, to specify the value for individual\n                estimators provided in the ``estimator_dict`` argument of the method. The keys\n                would be the same estimator names as in ``estimator_dict``. If one estimator\n                doesn\'t need the value set, then no need to include it in the dictionary. If\n                none of the estimators need the value set, then an empty dictionary ``{}``\n                must be used.\n\n    Returns:\n        dict: Tuning config that can be directly used by SageMakerTuningOperator in Airflow.\n    """"""\n\n    tuner._prepare_job_name_for_tuning(job_name=job_name)\n\n    tune_config = {\n        ""HyperParameterTuningJobName"": tuner._current_job_name,\n        ""HyperParameterTuningJobConfig"": _extract_tuning_job_config(tuner),\n    }\n\n    if tuner.estimator:\n        tune_config[\n            ""TrainingJobDefinition""\n        ], s3_operations = _extract_training_config_from_estimator(\n            tuner, inputs, include_cls_metadata, mini_batch_size\n        )\n    else:\n        tune_config[\n            ""TrainingJobDefinitions""\n        ], s3_operations = _extract_training_config_list_from_estimator_dict(\n            tuner, inputs, include_cls_metadata, mini_batch_size\n        )\n\n    if s3_operations:\n        tune_config[""S3Operations""] = s3_operations\n\n    if tuner.tags:\n        tune_config[""Tags""] = tuner.tags\n\n    if tuner.warm_start_config:\n        tune_config[""WarmStartConfig""] = tuner.warm_start_config.to_input_req()\n\n    return tune_config\n\n\ndef _extract_tuning_job_config(tuner):\n    """"""Extract tuning job config from a HyperparameterTuner""""""\n    tuning_job_config = {\n        ""Strategy"": tuner.strategy,\n        ""ResourceLimits"": {\n            ""MaxNumberOfTrainingJobs"": tuner.max_jobs,\n            ""MaxParallelTrainingJobs"": tuner.max_parallel_jobs,\n        },\n        ""TrainingJobEarlyStoppingType"": tuner.early_stopping_type,\n    }\n\n    if tuner.objective_metric_name:\n        tuning_job_config[""HyperParameterTuningJobObjective""] = {\n            ""Type"": tuner.objective_type,\n            ""MetricName"": tuner.objective_metric_name,\n        }\n\n    parameter_ranges = tuner.hyperparameter_ranges()\n    if parameter_ranges:\n        tuning_job_config[""ParameterRanges""] = parameter_ranges\n\n    return tuning_job_config\n\n\ndef _extract_training_config_from_estimator(tuner, inputs, include_cls_metadata, mini_batch_size):\n    """"""Extract training job config from a HyperparameterTuner that uses the ``estimator`` field""""""\n    train_config = training_base_config(tuner.estimator, inputs, mini_batch_size)\n    train_config.pop(""HyperParameters"", None)\n\n    tuner._prepare_static_hyperparameters_for_tuning(include_cls_metadata=include_cls_metadata)\n    train_config[""StaticHyperParameters""] = tuner.static_hyperparameters\n\n    if tuner.metric_definitions:\n        train_config[""AlgorithmSpecification""][""MetricDefinitions""] = tuner.metric_definitions\n\n    s3_operations = train_config.pop(""S3Operations"", None)\n    return train_config, s3_operations\n\n\ndef _extract_training_config_list_from_estimator_dict(\n    tuner, inputs, include_cls_metadata, mini_batch_size\n):\n    """"""\n    Extract a list of training job configs from a HyperparameterTuner that uses the\n    ``estimator_dict`` field\n    """"""\n    estimator_names = sorted(tuner.estimator_dict.keys())\n    tuner._validate_dict_argument(name=""inputs"", value=inputs, allowed_keys=estimator_names)\n    tuner._validate_dict_argument(\n        name=""include_cls_metadata"", value=include_cls_metadata, allowed_keys=estimator_names\n    )\n    tuner._validate_dict_argument(\n        name=""mini_batch_size"", value=mini_batch_size, allowed_keys=estimator_names\n    )\n\n    train_config_dict = {}\n    for (estimator_name, estimator) in tuner.estimator_dict.items():\n        train_config_dict[estimator_name] = training_base_config(\n            estimator=estimator,\n            inputs=inputs.get(estimator_name) if inputs else None,\n            mini_batch_size=mini_batch_size.get(estimator_name) if mini_batch_size else None,\n        )\n\n    tuner._prepare_static_hyperparameters_for_tuning(include_cls_metadata=include_cls_metadata)\n\n    train_config_list = []\n    s3_operations_list = []\n\n    for estimator_name in sorted(train_config_dict.keys()):\n        train_config = train_config_dict[estimator_name]\n        train_config.pop(""HyperParameters"", None)\n        train_config[""StaticHyperParameters""] = tuner.static_hyperparameters_dict[estimator_name]\n\n        train_config[""AlgorithmSpecification""][\n            ""MetricDefinitions""\n        ] = tuner.metric_definitions_dict.get(estimator_name)\n\n        train_config[""DefinitionName""] = estimator_name\n        train_config[""TuningObjective""] = {\n            ""Type"": tuner.objective_type,\n            ""MetricName"": tuner.objective_metric_name_dict[estimator_name],\n        }\n        train_config[""HyperParameterRanges""] = tuner.hyperparameter_ranges_dict()[estimator_name]\n\n        s3_operations_list.append(train_config.pop(""S3Operations"", {}))\n\n        train_config_list.append(train_config)\n\n    return train_config_list, _merge_s3_operations(s3_operations_list)\n\n\ndef _merge_s3_operations(s3_operations_list):\n    """"""Merge a list of S3 operation dictionaries into one""""""\n    s3_operations_merged = {}\n    for s3_operations in s3_operations_list:\n        for (key, operations) in s3_operations.items():\n            if key not in s3_operations_merged:\n                s3_operations_merged[key] = []\n            for operation in operations:\n                if operation not in s3_operations_merged[key]:\n                    s3_operations_merged[key].append(operation)\n    return s3_operations_merged\n\n\ndef update_submit_s3_uri(estimator, job_name):\n    """"""Updated the S3 URI of the framework source directory in given estimator.\n\n    Args:\n        estimator (sagemaker.estimator.Framework): The Framework estimator to\n            update.\n        job_name (str): The new job name included in the submit S3 URI\n\n    Returns:\n        str: The updated S3 URI of framework source directory\n    """"""\n    if estimator.uploaded_code is None:\n        return\n\n    pattern = r""(?<=/)[^/]+?(?=/source/sourcedir.tar.gz)""\n\n    # update the S3 URI with the latest training job.\n    # s3://path/old_job/source/sourcedir.tar.gz will become s3://path/new_job/source/sourcedir.tar.gz\n    submit_uri = estimator.uploaded_code.s3_prefix\n    submit_uri = re.sub(pattern, job_name, submit_uri)\n    script_name = estimator.uploaded_code.script_name\n    estimator.uploaded_code = fw_utils.UploadedCode(submit_uri, script_name)\n\n\ndef update_estimator_from_task(estimator, task_id, task_type):\n    """"""Update training job of the estimator from a task in the DAG\n\n    Args:\n        estimator (sagemaker.estimator.EstimatorBase): The estimator to update\n        task_id (str): The task id of any\n            airflow.contrib.operators.SageMakerTrainingOperator or\n            airflow.contrib.operators.SageMakerTuningOperator that generates\n            training jobs in the DAG.\n        task_type (str): Whether the task is from SageMakerTrainingOperator or\n            SageMakerTuningOperator. Values can be \'training\', \'tuning\' or None\n            (which means training job is not from any task).\n    """"""\n    if task_type is None:\n        return\n    if task_type.lower() == ""training"":\n        training_job = ""{{ ti.xcom_pull(task_ids=\'%s\')[\'Training\'][\'TrainingJobName\'] }}"" % task_id\n        job_name = training_job\n    elif task_type.lower() == ""tuning"":\n        training_job = (\n            ""{{ ti.xcom_pull(task_ids=\'%s\')[\'Tuning\'][\'BestTrainingJob\'][\'TrainingJobName\'] }}""\n            % task_id\n        )\n        # need to strip the double quotes in json to get the string\n        job_name = (\n            ""{{ ti.xcom_pull(task_ids=\'%s\')[\'Tuning\'][\'TrainingJobDefinition\']""\n            ""[\'StaticHyperParameters\'][\'sagemaker_job_name\'].strip(\'%s\') }}"" % (task_id, \'""\')\n        )\n    else:\n        raise ValueError(""task_type must be either \'training\', \'tuning\' or None."")\n    estimator._current_job_name = training_job\n    if isinstance(estimator, sagemaker.estimator.Framework):\n        update_submit_s3_uri(estimator, job_name)\n\n\ndef prepare_framework_container_def(model, instance_type, s3_operations):\n    """"""Prepare the framework model container information. Specify related S3\n    operations for Airflow to perform. (Upload `source_dir` )\n\n    Args:\n        model (sagemaker.model.FrameworkModel): The framework model\n        instance_type (str): The EC2 instance type to deploy this Model to. For\n            example, \'ml.p2.xlarge\'.\n        s3_operations (dict): The dict to specify S3 operations (upload\n            `source_dir` ).\n\n    Returns:\n        dict: The container information of this framework model.\n    """"""\n    deploy_image = model.image\n    if not deploy_image:\n        region_name = model.sagemaker_session.boto_session.region_name\n        deploy_image = model.serving_image_uri(region_name, instance_type)\n\n    base_name = utils.base_name_from_image(deploy_image)\n    model.name = model.name or utils.name_from_base(base_name)\n\n    bucket = model.bucket or model.sagemaker_session._default_bucket\n    if model.entry_point is not None:\n        script = os.path.basename(model.entry_point)\n        key = ""{}/source/sourcedir.tar.gz"".format(model.name)\n\n        if model.source_dir and model.source_dir.lower().startswith(""s3://""):\n            code_dir = model.source_dir\n            model.uploaded_code = fw_utils.UploadedCode(s3_prefix=code_dir, script_name=script)\n        else:\n            code_dir = ""s3://{}/{}"".format(bucket, key)\n            model.uploaded_code = fw_utils.UploadedCode(s3_prefix=code_dir, script_name=script)\n            s3_operations[""S3Upload""] = [\n                {""Path"": model.source_dir or script, ""Bucket"": bucket, ""Key"": key, ""Tar"": True}\n            ]\n\n    deploy_env = dict(model.env)\n    deploy_env.update(model._framework_env_vars())\n\n    try:\n        if model.model_server_workers:\n            deploy_env[sagemaker.model.MODEL_SERVER_WORKERS_PARAM_NAME.upper()] = str(\n                model.model_server_workers\n            )\n    except AttributeError:\n        # This applies to a FrameworkModel which is not SageMaker Deep Learning Framework Model\n        pass\n\n    return sagemaker.container_def(deploy_image, model.model_data, deploy_env)\n\n\ndef model_config(instance_type, model, role=None, image=None):\n    """"""Export Airflow model config from a SageMaker model\n\n    Args:\n        instance_type (str): The EC2 instance type to deploy this Model to. For\n            example, \'ml.p2.xlarge\'\n        model (sagemaker.model.FrameworkModel): The SageMaker model to export\n            Airflow config from\n        role (str): The ``ExecutionRoleArn`` IAM Role ARN for the model\n        image (str): An container image to use for deploying the model\n\n    Returns:\n        dict: Model config that can be directly used by SageMakerModelOperator\n        in Airflow. It can also be part of the config used by\n        SageMakerEndpointOperator and SageMakerTransformOperator in Airflow.\n    """"""\n    s3_operations = {}\n    model.image = image or model.image\n\n    if isinstance(model, sagemaker.model.FrameworkModel):\n        container_def = prepare_framework_container_def(model, instance_type, s3_operations)\n    else:\n        container_def = model.prepare_container_def(instance_type)\n        base_name = utils.base_name_from_image(container_def[""Image""])\n        model.name = model.name or utils.name_from_base(base_name)\n\n    primary_container = session._expand_container_def(container_def)\n\n    config = {\n        ""ModelName"": model.name,\n        ""PrimaryContainer"": primary_container,\n        ""ExecutionRoleArn"": role or model.role,\n    }\n\n    if model.vpc_config:\n        config[""VpcConfig""] = model.vpc_config\n\n    if s3_operations:\n        config[""S3Operations""] = s3_operations\n\n    return config\n\n\ndef model_config_from_estimator(\n    instance_type,\n    estimator,\n    task_id,\n    task_type,\n    role=None,\n    image=None,\n    name=None,\n    model_server_workers=None,\n    vpc_config_override=vpc_utils.VPC_CONFIG_DEFAULT,\n):\n    """"""Export Airflow model config from a SageMaker estimator\n\n    Args:\n        instance_type (str): The EC2 instance type to deploy this Model to. For\n            example, \'ml.p2.xlarge\'\n        estimator (sagemaker.model.EstimatorBase): The SageMaker estimator to\n            export Airflow config from. It has to be an estimator associated\n            with a training job.\n        task_id (str): The task id of any\n            airflow.contrib.operators.SageMakerTrainingOperator or\n            airflow.contrib.operators.SageMakerTuningOperator that generates\n            training jobs in the DAG. The model config is built based on the\n            training job generated in this operator.\n        task_type (str): Whether the task is from SageMakerTrainingOperator or\n            SageMakerTuningOperator. Values can be \'training\', \'tuning\' or None\n            (which means training job is not from any task).\n        role (str): The ``ExecutionRoleArn`` IAM Role ARN for the model\n        image (str): An container image to use for deploying the model\n        name (str): Name of the model\n        model_server_workers (int): The number of worker processes used by the\n            inference server. If None, server will use one worker per vCPU. Only\n            effective when estimator is a SageMaker framework.\n        vpc_config_override (dict[str, list[str]]): Override for VpcConfig set on\n            the model. Default: use subnets and security groups from this Estimator.\n            * \'Subnets\' (list[str]): List of subnet ids.\n            * \'SecurityGroupIds\' (list[str]): List of security group ids.\n\n    Returns:\n        dict: Model config that can be directly used by SageMakerModelOperator in Airflow. It can\n            also be part of the config used by SageMakerEndpointOperator in Airflow.\n    """"""\n    update_estimator_from_task(estimator, task_id, task_type)\n    if isinstance(estimator, sagemaker.estimator.Estimator):\n        model = estimator.create_model(\n            role=role, image=image, vpc_config_override=vpc_config_override\n        )\n    elif isinstance(estimator, sagemaker.amazon.amazon_estimator.AmazonAlgorithmEstimatorBase):\n        model = estimator.create_model(vpc_config_override=vpc_config_override)\n    elif isinstance(estimator, sagemaker.estimator.Framework):\n        model = estimator.create_model(\n            model_server_workers=model_server_workers,\n            role=role,\n            vpc_config_override=vpc_config_override,\n            entry_point=estimator.entry_point,\n        )\n    else:\n        raise TypeError(\n            ""Estimator must be one of sagemaker.estimator.Estimator, sagemaker.estimator.Framework""\n            "" or sagemaker.amazon.amazon_estimator.AmazonAlgorithmEstimatorBase.""\n        )\n    model.name = name\n\n    return model_config(instance_type, model, role, image)\n\n\ndef transform_config(\n    transformer,\n    data,\n    data_type=""S3Prefix"",\n    content_type=None,\n    compression_type=None,\n    split_type=None,\n    job_name=None,\n    input_filter=None,\n    output_filter=None,\n    join_source=None,\n):\n    """"""Export Airflow transform config from a SageMaker transformer\n\n    Args:\n        transformer (sagemaker.transformer.Transformer): The SageMaker\n            transformer to export Airflow config from.\n        data (str): Input data location in S3.\n        data_type (str): What the S3 location defines (default: \'S3Prefix\').\n            Valid values:\n\n            * \'S3Prefix\' - the S3 URI defines a key name prefix. All objects with this prefix will\n                  be used as inputs for the transform job.\n\n            * \'ManifestFile\' - the S3 URI points to a single manifest file listing each S3 object\n                  to use as an input for the transform job.\n\n        content_type (str): MIME type of the input data (default: None).\n        compression_type (str): Compression type of the input data, if\n            compressed (default: None). Valid values: \'Gzip\', None.\n        split_type (str): The record delimiter for the input object (default:\n            \'None\'). Valid values: \'None\', \'Line\', \'RecordIO\', and \'TFRecord\'.\n        job_name (str): job name (default: None). If not specified, one will be\n            generated.\n        input_filter (str): A JSONPath to select a portion of the input to\n            pass to the algorithm container for inference. If you omit the\n            field, it gets the value \'$\', representing the entire input.\n            For CSV data, each row is taken as a JSON array,\n            so only index-based JSONPaths can be applied, e.g. $[0], $[1:].\n            CSV data should follow the `RFC format <https://tools.ietf.org/html/rfc4180>`_.\n            See `Supported JSONPath Operators\n            <https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform-data-processing.html#data-processing-operators>`_\n            for a table of supported JSONPath operators.\n            For more information, see the SageMaker API documentation for\n            `CreateTransformJob\n            <https://docs.aws.amazon.com/sagemaker/latest/dg/API_CreateTransformJob.html>`_.\n            Some examples: ""$[1:]"", ""$.features"" (default: None).\n        output_filter (str): A JSONPath to select a portion of the\n            joined/original output to return as the output.\n            For more information, see the SageMaker API documentation for\n            `CreateTransformJob\n            <https://docs.aws.amazon.com/sagemaker/latest/dg/API_CreateTransformJob.html>`_.\n            Some examples: ""$[1:]"", ""$.prediction"" (default: None).\n        join_source (str): The source of data to be joined to the transform\n            output. It can be set to \'Input\' meaning the entire input record\n            will be joined to the inference result. You can use OutputFilter\n            to select the useful portion before uploading to S3. (default:\n            None). Valid values: Input, None.\n\n    Returns:\n        dict: Transform config that can be directly used by\n        SageMakerTransformOperator in Airflow.\n    """"""\n    if job_name is not None:\n        transformer._current_job_name = job_name\n    else:\n        base_name = transformer.base_transform_job_name\n        transformer._current_job_name = (\n            utils.name_from_base(base_name) if base_name is not None else transformer.model_name\n        )\n\n    if transformer.output_path is None:\n        transformer.output_path = ""s3://{}/{}"".format(\n            transformer.sagemaker_session.default_bucket(), transformer._current_job_name\n        )\n\n    job_config = sagemaker.transformer._TransformJob._load_config(\n        data, data_type, content_type, compression_type, split_type, transformer\n    )\n\n    config = {\n        ""TransformJobName"": transformer._current_job_name,\n        ""ModelName"": transformer.model_name,\n        ""TransformInput"": job_config[""input_config""],\n        ""TransformOutput"": job_config[""output_config""],\n        ""TransformResources"": job_config[""resource_config""],\n    }\n\n    data_processing = sagemaker.transformer._TransformJob._prepare_data_processing(\n        input_filter, output_filter, join_source\n    )\n    if data_processing is not None:\n        config[""DataProcessing""] = data_processing\n\n    if transformer.strategy is not None:\n        config[""BatchStrategy""] = transformer.strategy\n\n    if transformer.max_concurrent_transforms is not None:\n        config[""MaxConcurrentTransforms""] = transformer.max_concurrent_transforms\n\n    if transformer.max_payload is not None:\n        config[""MaxPayloadInMB""] = transformer.max_payload\n\n    if transformer.env is not None:\n        config[""Environment""] = transformer.env\n\n    if transformer.tags is not None:\n        config[""Tags""] = transformer.tags\n\n    return config\n\n\ndef transform_config_from_estimator(\n    estimator,\n    task_id,\n    task_type,\n    instance_count,\n    instance_type,\n    data,\n    data_type=""S3Prefix"",\n    content_type=None,\n    compression_type=None,\n    split_type=None,\n    job_name=None,\n    model_name=None,\n    strategy=None,\n    assemble_with=None,\n    output_path=None,\n    output_kms_key=None,\n    accept=None,\n    env=None,\n    max_concurrent_transforms=None,\n    max_payload=None,\n    tags=None,\n    role=None,\n    volume_kms_key=None,\n    model_server_workers=None,\n    image=None,\n    vpc_config_override=None,\n    input_filter=None,\n    output_filter=None,\n    join_source=None,\n):\n    """"""Export Airflow transform config from a SageMaker estimator\n\n    Args:\n        estimator (sagemaker.model.EstimatorBase): The SageMaker estimator to\n            export Airflow config from. It has to be an estimator associated\n            with a training job.\n        task_id (str): The task id of any\n            airflow.contrib.operators.SageMakerTrainingOperator or\n            airflow.contrib.operators.SageMakerTuningOperator that generates\n            training jobs in the DAG. The transform config is built based on the\n            training job generated in this operator.\n        task_type (str): Whether the task is from SageMakerTrainingOperator or\n            SageMakerTuningOperator. Values can be \'training\', \'tuning\' or None\n            (which means training job is not from any task).\n        instance_count (int): Number of EC2 instances to use.\n        instance_type (str): Type of EC2 instance to use, for example,\n            \'ml.c4.xlarge\'.\n        data (str): Input data location in S3.\n        data_type (str): What the S3 location defines (default: \'S3Prefix\').\n            Valid values:\n\n            * \'S3Prefix\' - the S3 URI defines a key name prefix. All objects with this prefix will\n                  be used as inputs for the transform job.\n\n            * \'ManifestFile\' - the S3 URI points to a single manifest file listing each S3 object\n                  to use as an input for the transform job.\n        content_type (str): MIME type of the input data (default: None).\n        compression_type (str): Compression type of the input data, if\n            compressed (default: None). Valid values: \'Gzip\', None.\n        split_type (str): The record delimiter for the input object (default:\n            \'None\'). Valid values: \'None\', \'Line\', \'RecordIO\', and \'TFRecord\'.\n        job_name (str): transform job name (default: None). If not specified,\n            one will be generated.\n        model_name (str): model name (default: None). If not specified, one will\n            be generated.\n        strategy (str): The strategy used to decide how to batch records in a\n            single request (default: None). Valid values: \'MultiRecord\' and\n            \'SingleRecord\'.\n        assemble_with (str): How the output is assembled (default: None). Valid\n            values: \'Line\' or \'None\'.\n        output_path (str): S3 location for saving the transform result. If not\n            specified, results are stored to a default bucket.\n        output_kms_key (str): Optional. KMS key ID for encrypting the transform\n            output (default: None).\n        accept (str): The accept header passed by the client to\n            the inference endpoint. If it is supported by the endpoint,\n            it will be the format of the batch transform output.\n        env (dict): Environment variables to be set for use during the transform\n            job (default: None).\n        max_concurrent_transforms (int): The maximum number of HTTP requests to\n            be made to each individual transform container at one time.\n        max_payload (int): Maximum size of the payload in a single HTTP request\n            to the container in MB.\n        tags (list[dict]): List of tags for labeling a transform job. If none\n            specified, then the tags used for the training job are used for the\n            transform job.\n        role (str): The ``ExecutionRoleArn`` IAM Role ARN for the ``Model``,\n            which is also used during transform jobs. If not specified, the role\n            from the Estimator will be used.\n        volume_kms_key (str): Optional. KMS key ID for encrypting the volume\n            attached to the ML compute instance (default: None).\n        model_server_workers (int): Optional. The number of worker processes\n            used by the inference server. If None, server will use one worker\n            per vCPU.\n        image (str): An container image to use for deploying the model\n        vpc_config_override (dict[str, list[str]]): Override for VpcConfig set on\n            the model. Default: use subnets and security groups from this Estimator.\n\n            * \'Subnets\' (list[str]): List of subnet ids.\n            * \'SecurityGroupIds\' (list[str]): List of security group ids.\n\n        input_filter (str): A JSONPath to select a portion of the input to\n            pass to the algorithm container for inference. If you omit the\n            field, it gets the value \'$\', representing the entire input.\n            For CSV data, each row is taken as a JSON array,\n            so only index-based JSONPaths can be applied, e.g. $[0], $[1:].\n            CSV data should follow the `RFC format <https://tools.ietf.org/html/rfc4180>`_.\n            See `Supported JSONPath Operators\n            <https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform-data-processing.html#data-processing-operators>`_\n            for a table of supported JSONPath operators.\n            For more information, see the SageMaker API documentation for\n            `CreateTransformJob\n            <https://docs.aws.amazon.com/sagemaker/latest/dg/API_CreateTransformJob.html>`_.\n            Some examples: ""$[1:]"", ""$.features"" (default: None).\n        output_filter (str): A JSONPath to select a portion of the\n            joined/original output to return as the output.\n            For more information, see the SageMaker API documentation for\n            `CreateTransformJob\n            <https://docs.aws.amazon.com/sagemaker/latest/dg/API_CreateTransformJob.html>`_.\n            Some examples: ""$[1:]"", ""$.prediction"" (default: None).\n        join_source (str): The source of data to be joined to the transform\n            output. It can be set to \'Input\' meaning the entire input record\n            will be joined to the inference result. You can use OutputFilter\n            to select the useful portion before uploading to S3. (default:\n            None). Valid values: Input, None.\n\n    Returns:\n        dict: Transform config that can be directly used by\n        SageMakerTransformOperator in Airflow.\n    """"""\n    model_base_config = model_config_from_estimator(\n        instance_type=instance_type,\n        estimator=estimator,\n        task_id=task_id,\n        task_type=task_type,\n        role=role,\n        image=image,\n        name=model_name,\n        model_server_workers=model_server_workers,\n        vpc_config_override=vpc_config_override,\n    )\n\n    if isinstance(estimator, sagemaker.estimator.Framework):\n        transformer = estimator.transformer(\n            instance_count,\n            instance_type,\n            strategy,\n            assemble_with,\n            output_path,\n            output_kms_key,\n            accept,\n            env,\n            max_concurrent_transforms,\n            max_payload,\n            tags,\n            role,\n            model_server_workers,\n            volume_kms_key,\n        )\n    else:\n        transformer = estimator.transformer(\n            instance_count,\n            instance_type,\n            strategy,\n            assemble_with,\n            output_path,\n            output_kms_key,\n            accept,\n            env,\n            max_concurrent_transforms,\n            max_payload,\n            tags,\n            role,\n            volume_kms_key,\n        )\n    transformer.model_name = model_base_config[""ModelName""]\n\n    transform_base_config = transform_config(\n        transformer,\n        data,\n        data_type,\n        content_type,\n        compression_type,\n        split_type,\n        job_name,\n        input_filter,\n        output_filter,\n        join_source,\n    )\n\n    config = {""Model"": model_base_config, ""Transform"": transform_base_config}\n\n    return config\n\n\ndef deploy_config(model, initial_instance_count, instance_type, endpoint_name=None, tags=None):\n    """"""Export Airflow deploy config from a SageMaker model\n\n    Args:\n        model (sagemaker.model.Model): The SageMaker model to export the Airflow\n            config from.\n        initial_instance_count (int): The initial number of instances to run in\n            the ``Endpoint`` created from this ``Model``.\n        instance_type (str): The EC2 instance type to deploy this Model to. For\n            example, \'ml.p2.xlarge\'.\n        endpoint_name (str): The name of the endpoint to create (default: None).\n            If not specified, a unique endpoint name will be created.\n        tags (list[dict]): List of tags for labeling a training job. For more,\n            see https://docs.aws.amazon.com/sagemaker/latest/dg/API_Tag.html.\n\n    Returns:\n        dict: Deploy config that can be directly used by\n        SageMakerEndpointOperator in Airflow.\n    """"""\n    model_base_config = model_config(instance_type, model)\n\n    production_variant = sagemaker.production_variant(\n        model.name, instance_type, initial_instance_count\n    )\n    name = model.name\n    config_options = {""EndpointConfigName"": name, ""ProductionVariants"": [production_variant]}\n    if tags is not None:\n        config_options[""Tags""] = tags\n\n    endpoint_name = endpoint_name or name\n    endpoint_base_config = {""EndpointName"": endpoint_name, ""EndpointConfigName"": name}\n\n    config = {\n        ""Model"": model_base_config,\n        ""EndpointConfig"": config_options,\n        ""Endpoint"": endpoint_base_config,\n    }\n\n    # if there is s3 operations needed for model, move it to root level of config\n    s3_operations = model_base_config.pop(""S3Operations"", None)\n    if s3_operations is not None:\n        config[""S3Operations""] = s3_operations\n\n    return config\n\n\ndef deploy_config_from_estimator(\n    estimator,\n    task_id,\n    task_type,\n    initial_instance_count,\n    instance_type,\n    model_name=None,\n    endpoint_name=None,\n    tags=None,\n    **kwargs\n):\n    """"""Export Airflow deploy config from a SageMaker estimator\n\n    Args:\n        estimator (sagemaker.model.EstimatorBase): The SageMaker estimator to\n            export Airflow config from. It has to be an estimator associated\n            with a training job.\n        task_id (str): The task id of any\n            airflow.contrib.operators.SageMakerTrainingOperator or\n            airflow.contrib.operators.SageMakerTuningOperator that generates\n            training jobs in the DAG. The endpoint config is built based on the\n            training job generated in this operator.\n        task_type (str): Whether the task is from SageMakerTrainingOperator or\n            SageMakerTuningOperator. Values can be \'training\', \'tuning\' or None\n            (which means training job is not from any task).\n        initial_instance_count (int): Minimum number of EC2 instances to deploy\n            to an endpoint for prediction.\n        instance_type (str): Type of EC2 instance to deploy to an endpoint for\n            prediction, for example, \'ml.c4.xlarge\'.\n        model_name (str): Name to use for creating an Amazon SageMaker model. If\n            not specified, one will be generated.\n        endpoint_name (str): Name to use for creating an Amazon SageMaker\n            endpoint. If not specified, the name of the SageMaker model is used.\n        tags (list[dict]): List of tags for labeling a training job. For more,\n            see https://docs.aws.amazon.com/sagemaker/latest/dg/API_Tag.html.\n        **kwargs: Passed to invocation of ``create_model()``. Implementations\n            may customize ``create_model()`` to accept ``**kwargs`` to customize\n            model creation during deploy. For more, see the implementation docs.\n\n    Returns:\n        dict: Deploy config that can be directly used by\n        SageMakerEndpointOperator in Airflow.\n    """"""\n    update_estimator_from_task(estimator, task_id, task_type)\n    model = estimator.create_model(**kwargs)\n    model.name = model_name\n    config = deploy_config(model, initial_instance_count, instance_type, endpoint_name, tags)\n    return config\n'"
src/sagemaker/xgboost/__init__.py,0,"b'# Copyright 2018-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom sagemaker.xgboost.defaults import XGBOOST_NAME, XGBOOST_LATEST_VERSION  # noqa: F401\nfrom sagemaker.xgboost.estimator import XGBoost  # noqa: F401\nfrom sagemaker.xgboost.model import XGBoostModel, XGBoostPredictor  # noqa: F401\n'"
src/sagemaker/xgboost/defaults.py,0,"b'# Copyright 2018-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nXGBOOST_NAME = ""xgboost""\nXGBOOST_1P_VERSIONS = [""1"", ""latest""]\nXGBOOST_VERSION_0_90 = ""0.90""\nXGBOOST_VERSION_0_90_1 = ""0.90-1""\nXGBOOST_VERSION_0_90_2 = ""0.90-2""\nXGBOOST_LATEST_VERSION = ""1.0-1""\n# XGBOOST_SUPPORTED_VERSIONS has XGBoost Framework versions sorted from oldest to latest\nXGBOOST_SUPPORTED_VERSIONS = [\n    XGBOOST_VERSION_0_90_1,\n    XGBOOST_VERSION_0_90_2,\n    XGBOOST_LATEST_VERSION,\n]\nXGBOOST_VERSION_EQUIVALENTS = [""-cpu-py3""]\n'"
src/sagemaker/xgboost/estimator.py,0,"b'# Copyright 2018-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nimport logging\n\nfrom sagemaker.estimator import Framework, _TrainingJob\nfrom sagemaker.fw_registry import default_framework_uri\nfrom sagemaker.fw_utils import (\n    framework_name_from_image,\n    framework_version_from_tag,\n    get_unsupported_framework_version_error,\n    UploadedCode,\n)\nfrom sagemaker.session import Session\nfrom sagemaker.vpc_utils import VPC_CONFIG_DEFAULT\nfrom sagemaker.xgboost import defaults\nfrom sagemaker.xgboost.model import XGBoostModel\n\nlogger = logging.getLogger(""sagemaker"")\n\n\ndef get_xgboost_image_uri(region, framework_version, py_version=""py3""):\n    """"""Get XGBoost framework image URI""""""\n    image_tag = ""{}-{}-{}"".format(framework_version, ""cpu"", py_version)\n    return default_framework_uri(XGBoost.__framework_name__, region, image_tag)\n\n\nclass XGBoost(Framework):\n    """"""Handle end-to-end training and deployment of XGBoost booster training or training using\n    customer provided XGBoost entry point script.""""""\n\n    __framework_name__ = defaults.XGBOOST_NAME\n\n    def __init__(\n        self,\n        entry_point,\n        framework_version,\n        source_dir=None,\n        hyperparameters=None,\n        py_version=""py3"",\n        image_name=None,\n        **kwargs\n    ):\n        """"""\n        This ``Estimator`` executes an XGBoost based SageMaker Training Job.\n        The managed XGBoost environment is an Amazon-built Docker container thatexecutes functions\n        defined in the supplied ``entry_point`` Python script.\n\n        Training is started by calling :meth:`~sagemaker.amazon.estimator.Framework.fit` on this\n        Estimator. After training is complete, calling\n        :meth:`~sagemaker.amazon.estimator.Framework.deploy` creates a hosted SageMaker endpoint\n        and returns an :class:`~sagemaker.amazon.xgboost.model.XGBoostPredictor` instance that\n        can be used to perform inference against the hosted model.\n\n        Technical documentation on preparing XGBoost scripts for SageMaker training and using the\n        XGBoost Estimator is available on the project home-page:\n        https://github.com/aws/sagemaker-python-sdk\n\n        Args:\n            entry_point (str): Path (absolute or relative) to the Python source file which should\n                be executed as the entry point to training.  If ``source_dir`` is specified,\n                then ``entry_point`` must point to a file located at the root of ``source_dir``.\n            framework_version (str): XGBoost version you want to use for executing your model\n                training code.  List of supported versions\n                https://github.com/aws/sagemaker-python-sdk#xgboost-sagemaker-estimators\n            source_dir (str): Path (absolute, relative or an S3 URI) to a directory\n                with any other training source code dependencies aside from the entry\n                point file (default: None). If ``source_dir`` is an S3 URI, it must\n                point to a tar.gz file. Structure within this directory are preserved\n                when training on Amazon SageMaker.\n            hyperparameters (dict): Hyperparameters that will be used for training (default: None).\n                The hyperparameters are made accessible as a dict[str, str] to the training code\n                on SageMaker. For convenience, this accepts other types for keys and values, but\n                ``str()`` will be called to convert them before training.\n            py_version (str): Python version you want to use for executing your model\n                training code (default: \'py3\'). One of \'py2\' or \'py3\'.\n            image_name (str): If specified, the estimator will use this image for training and\n                hosting, instead of selecting the appropriate SageMaker official image\n                based on framework_version and py_version. It can be an ECR url or\n                dockerhub image and tag.\n                Examples:\n                    123.dkr.ecr.us-west-2.amazonaws.com/my-custom-image:1.0\n                    custom-image:latest.\n            **kwargs: Additional kwargs passed to the\n                :class:`~sagemaker.estimator.Framework` constructor.\n\n        .. tip::\n\n            You can find additional parameters for initializing this class at\n            :class:`~sagemaker.estimator.Framework` and\n            :class:`~sagemaker.estimator.EstimatorBase`.\n        """"""\n        super(XGBoost, self).__init__(\n            entry_point, source_dir, hyperparameters, image_name=image_name, **kwargs\n        )\n\n        if py_version == ""py2"":\n            raise AttributeError(""XGBoost container does not support Python 2, please use Python 3"")\n        self.py_version = py_version\n\n        if framework_version in defaults.XGBOOST_SUPPORTED_VERSIONS:\n            self.framework_version = framework_version\n        else:\n            raise ValueError(\n                get_unsupported_framework_version_error(\n                    self.__framework_name__, framework_version, defaults.XGBOOST_SUPPORTED_VERSIONS\n                )\n            )\n\n        if image_name is None:\n            self.image_name = get_xgboost_image_uri(\n                self.sagemaker_session.boto_region_name, framework_version\n            )\n\n    def create_model(\n        self,\n        model_server_workers=None,\n        role=None,\n        vpc_config_override=VPC_CONFIG_DEFAULT,\n        entry_point=None,\n        source_dir=None,\n        dependencies=None,\n        **kwargs\n    ):\n        """"""Create a SageMaker ``XGBoostModel`` object that can be deployed to an ``Endpoint``.\n\n        Args:\n            role (str): The ``ExecutionRoleArn`` IAM Role ARN for the ``Model``, which is also used\n                during transform jobs. If not specified, the role from the Estimator will be used.\n            model_server_workers (int): Optional. The number of worker processes used by the\n                inference server. If None, server will use one worker per vCPU.\n            vpc_config_override (dict[str, list[str]]): Optional override for VpcConfig set on the\n                model.\n                Default: use subnets and security groups from this Estimator.\n                * \'Subnets\' (list[str]): List of subnet ids.\n                * \'SecurityGroupIds\' (list[str]): List of security group ids.\n            entry_point (str): Path (absolute or relative) to the local Python source file which\n                should be executed as the entry point to training. If ``source_dir`` is specified,\n                then ``entry_point`` must point to a file located at the root of ``source_dir``.\n                If not specified, the training entry point is used.\n            source_dir (str): Path (absolute or relative) to a directory with any other serving\n                source code dependencies aside from the entry point file.\n                If not specified, the model source directory from training is used.\n            dependencies (list[str]): A list of paths to directories (absolute or relative) with\n                any additional libraries that will be exported to the container.\n                If not specified, the dependencies from training are used.\n            **kwargs: Additional kwargs passed to the :class:`~sagemaker.xgboost.model.XGBoostModel`\n                constructor.\n\n        Returns:\n            sagemaker.xgboost.model.XGBoostModel: A SageMaker ``XGBoostModel`` object.\n                See :func:`~sagemaker.xgboost.model.XGBoostModel` for full details.\n        """"""\n        role = role or self.role\n\n        if ""image"" not in kwargs:\n            kwargs[""image""] = self.image_name\n\n        if ""name"" not in kwargs:\n            kwargs[""name""] = self._current_job_name\n\n        return XGBoostModel(\n            self.model_data,\n            role,\n            entry_point or self.entry_point,\n            framework_version=self.framework_version,\n            source_dir=(source_dir or self._model_source_dir()),\n            enable_cloudwatch_metrics=self.enable_cloudwatch_metrics,\n            container_log_level=self.container_log_level,\n            code_location=self.code_location,\n            py_version=self.py_version,\n            model_server_workers=model_server_workers,\n            sagemaker_session=self.sagemaker_session,\n            vpc_config=self.get_vpc_config(vpc_config_override),\n            dependencies=(dependencies or self.dependencies),\n            **kwargs\n        )\n\n    @classmethod\n    def attach(cls, training_job_name, sagemaker_session=None, model_channel_name=""model""):\n        """"""Attach to an existing training job.\n\n        Create an Estimator bound to an existing training job, each subclass\n        is responsible to implement\n        ``_prepare_init_params_from_job_description()`` as this method delegates\n        the actual conversion of a training job description to the arguments\n        that the class constructor expects. After attaching, if the training job\n        has a Complete status, it can be ``deploy()`` ed to create a SageMaker\n        Endpoint and return a ``Predictor``.\n\n        If the training job is in progress, attach will block and display log\n        messages from the training job, until the training job completes.\n\n        Examples:\n            >>> my_estimator.fit(wait=False)\n            >>> training_job_name = my_estimator.latest_training_job.name\n            Later on:\n            >>> attached_estimator = Estimator.attach(training_job_name)\n            >>> attached_estimator.deploy()\n\n        Args:\n            training_job_name (str): The name of the training job to attach to.\n            sagemaker_session (sagemaker.session.Session): Session object which\n                manages interactions with Amazon SageMaker APIs and any other\n                AWS services needed. If not specified, the estimator creates one\n                using the default AWS configuration chain.\n            model_channel_name (str): Name of the channel where pre-trained\n                model data will be downloaded (default: \'model\'). If no channel\n                with the same name exists in the training job, this option will\n                be ignored.\n\n        Returns:\n            Instance of the calling ``Estimator`` Class with the attached\n            training job.\n        """"""\n        sagemaker_session = sagemaker_session or Session()\n\n        job_details = sagemaker_session.sagemaker_client.describe_training_job(\n            TrainingJobName=training_job_name\n        )\n        init_params = cls._prepare_init_params_from_job_description(job_details, model_channel_name)\n        tags = sagemaker_session.sagemaker_client.list_tags(\n            ResourceArn=job_details[""TrainingJobArn""]\n        )[""Tags""]\n        init_params.update(tags=tags)\n\n        estimator = cls(sagemaker_session=sagemaker_session, **init_params)\n        estimator.latest_training_job = _TrainingJob(\n            sagemaker_session=sagemaker_session, job_name=init_params[""base_job_name""]\n        )\n        estimator._current_job_name = estimator.latest_training_job.name\n        estimator.latest_training_job.wait()\n\n        # pylint gets confused thinking that estimator is an EstimatorBase instance, but it actually\n        # is a Framework or any of its derived classes. We can safely ignore the no-member errors.\n        estimator.uploaded_code = UploadedCode(\n            estimator.source_dir, estimator.entry_point  # pylint: disable=no-member\n        )\n        return estimator\n\n    @classmethod\n    def _prepare_init_params_from_job_description(cls, job_details, model_channel_name=None):\n        """"""Convert the job description to init params that can be handled by the class constructor\n\n        Args:\n            job_details: the returned job details from a describe_training_job API call.\n\n        Returns:\n             dictionary: The transformed init_params\n\n        """"""\n        init_params = super(XGBoost, cls)._prepare_init_params_from_job_description(job_details)\n\n        image_name = init_params.pop(""image"")\n        framework, py_version, tag, _ = framework_name_from_image(image_name)\n        init_params[""py_version""] = py_version\n\n        if framework and framework != cls.__framework_name__:\n            training_job_name = init_params[""base_job_name""]\n            raise ValueError(\n                ""Training job: {} didn\'t use image for requested framework"".format(\n                    training_job_name\n                )\n            )\n        init_params[""framework_version""] = framework_version_from_tag(tag)\n\n        if not framework:\n            # If we were unable to parse the framework name from the image it is not one of our\n            # officially supported images, in this case just add the image to the init params.\n            init_params[""image_name""] = image_name\n        return init_params\n'"
src/sagemaker/xgboost/model.py,0,"b'# Copyright 2018-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n""""""Placeholder docstring""""""\nfrom __future__ import absolute_import\n\nimport logging\n\nfrom sagemaker import fw_utils\n\nimport sagemaker\nfrom sagemaker.fw_utils import model_code_key_prefix\nfrom sagemaker.fw_registry import default_framework_uri\nfrom sagemaker.model import FrameworkModel, MODEL_SERVER_WORKERS_PARAM_NAME\nfrom sagemaker.predictor import RealTimePredictor, npy_serializer, csv_deserializer\nfrom sagemaker.xgboost.defaults import XGBOOST_NAME\n\nlogger = logging.getLogger(""sagemaker"")\n\n\nclass XGBoostPredictor(RealTimePredictor):\n    """"""A RealTimePredictor for inference against XGBoost Endpoints.\n\n    This is able to serialize Python lists, dictionaries, and numpy arrays to xgb.DMatrix\n     for XGBoost inference.""""""\n\n    def __init__(self, endpoint_name, sagemaker_session=None):\n        """"""Initialize an ``XGBoostPredictor``.\n\n        Args:\n            endpoint_name (str): The name of the endpoint to perform inference on.\n            sagemaker_session (sagemaker.session.Session): Session object which manages\n                interactions with Amazon SageMaker APIs and any other AWS services needed.\n                If not specified, the estimator creates one using the default AWS configuration\n                chain.\n        """"""\n        super(XGBoostPredictor, self).__init__(\n            endpoint_name, sagemaker_session, npy_serializer, csv_deserializer\n        )\n\n\nclass XGBoostModel(FrameworkModel):\n    """"""An XGBoost SageMaker ``Model`` that can be deployed to a SageMaker ``Endpoint``.""""""\n\n    __framework_name__ = XGBOOST_NAME\n\n    def __init__(\n        self,\n        model_data,\n        role,\n        entry_point,\n        framework_version,\n        image=None,\n        py_version=""py3"",\n        predictor_cls=XGBoostPredictor,\n        model_server_workers=None,\n        **kwargs\n    ):\n        """"""Initialize an XGBoostModel.\n\n        Args:\n            model_data (str): The S3 location of a SageMaker model data ``.tar.gz`` file.\n            role (str): An AWS IAM role (either name or full ARN). The Amazon SageMaker training\n                jobs and APIs that create Amazon SageMaker endpoints use this role to access\n                training data and model artifacts. After the endpoint is created, the inference\n                code might use the IAM role, if it needs to access an AWS resource.\n            entry_point (str): Path (absolute or relative) to the Python source file which should\n                be executed  as the entry point to model hosting. If ``source_dir`` is specified,\n                then ``entry_point`` must point to a file located at the root of ``source_dir``.\n            image (str): A Docker image URI (default: None). If not specified, a default image for\n                XGBoos will be used.\n            py_version (str): Python version you want to use for executing your model training code\n                (default: \'py2\').\n            framework_version (str): XGBoost version you want to use for executing your model\n                training code.\n            predictor_cls (callable[str, sagemaker.session.Session]): A function to call to create\n                a predictor with an endpoint name and SageMaker ``Session``.\n                If specified, ``deploy()`` returns the result of invoking this function on the\n                created endpoint name.\n            model_server_workers (int): Optional. The number of worker processes used by the\n                inference server. If None, server will use one worker per vCPU.\n            **kwargs: Keyword arguments passed to the ``FrameworkModel`` initializer.\n\n        .. tip::\n\n            You can find additional parameters for initializing this class at\n            :class:`~sagemaker.model.FrameworkModel` and\n            :class:`~sagemaker.model.Model`.\n        """"""\n        super(XGBoostModel, self).__init__(\n            model_data, image, role, entry_point, predictor_cls=predictor_cls, **kwargs\n        )\n\n        if py_version == ""py2"":\n            raise AttributeError(""XGBoost container does not support Python 2, please use Python 3"")\n\n        self.py_version = py_version\n        self.framework_version = framework_version\n        self.model_server_workers = model_server_workers\n\n    def prepare_container_def(self, instance_type, accelerator_type=None):\n        """"""Return a container definition with framework configuration\n        set in model environment variables.\n\n        Args:\n            instance_type (str): The EC2 instance type to deploy this Model to. For example,\n                \'ml.m5.xlarge\'.\n            accelerator_type (str): The Elastic Inference accelerator type to deploy to the\n            instance for loading and making inferences to the model. For example,\n                \'ml.eia1.medium\'.\n            Note: accelerator types are not supported by XGBoostModel.\n\n        Returns:\n            dict[str, str]: A container definition object usable with the CreateModel API.\n        """"""\n        deploy_image = self.image\n        if not deploy_image:\n            image_tag = ""{}-{}-{}"".format(self.framework_version, ""cpu"", self.py_version)\n            deploy_image = default_framework_uri(\n                self.__framework_name__, self.sagemaker_session.boto_region_name, image_tag\n            )\n\n        deploy_key_prefix = model_code_key_prefix(self.key_prefix, self.name, deploy_image)\n        self._upload_code(deploy_key_prefix)\n        deploy_env = dict(self.env)\n        deploy_env.update(self._framework_env_vars())\n\n        if self.model_server_workers:\n            deploy_env[MODEL_SERVER_WORKERS_PARAM_NAME.upper()] = str(self.model_server_workers)\n        return sagemaker.container_def(deploy_image, self.model_data, deploy_env)\n\n    def serving_image_uri(self, region_name, instance_type):\n        """"""Create a URI for the serving image.\n\n        Args:\n            region_name (str): AWS region where the image is uploaded.\n            instance_type (str): SageMaker instance type. Used to determine device type\n                (cpu/gpu/family-specific optimized).\n\n        Returns:\n            str: The appropriate image URI based on the given parameters.\n\n        """"""\n        return fw_utils.create_image_uri(\n            region_name,\n            self.__framework_name__,\n            instance_type,\n            self.framework_version,\n            self.py_version,\n        )\n'"
tests/data/chainer_mnist/distributed_mnist.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import print_function\n\nimport argparse\nimport logging\nimport os\n\nimport chainer\nfrom chainer import serializers, training\nfrom chainer.datasets import tuple_dataset\nimport chainer.functions as F\nimport chainer.links as L\nfrom chainer.training import extensions\nimport chainermn\nimport numpy as np\nimport sagemaker_containers\n\nlogger = logging.getLogger(__name__)\nlogger.setLevel(logging.INFO)\n\n\nclass MLP(chainer.Chain):\n    def __init__(self, n_units, n_out):\n        super(MLP, self).__init__()\n        with self.init_scope():\n            # the size of the inputs to each layer will be inferred\n            self.l1 = L.Linear(None, n_units)  # n_in -> n_units\n            self.l2 = L.Linear(None, n_units)  # n_units -> n_units\n            self.l3 = L.Linear(None, n_out)  # n_units -> n_out\n\n    def __call__(self, x):\n        h1 = F.relu(self.l1(x))\n        h2 = F.relu(self.l2(h1))\n        return self.l3(h2)\n\n\ndef _preprocess_mnist(raw, withlabel, ndim, scale, image_dtype, label_dtype, rgb_format):\n    images = raw[""x""][-100:]\n    if ndim == 2:\n        images = images.reshape(-1, 28, 28)\n    elif ndim == 3:\n        images = images.reshape(-1, 1, 28, 28)\n        if rgb_format:\n            images = np.broadcast_to(images, (len(images), 3) + images.shape[2:])\n    elif ndim != 1:\n        raise ValueError(""invalid ndim for MNIST dataset"")\n    images = images.astype(image_dtype)\n    images *= scale / 255.0\n\n    if withlabel:\n        labels = raw[""y""][-100:].astype(label_dtype)\n        return tuple_dataset.TupleDataset(images, labels)\n    return images\n\n\nif __name__ == ""__main__"":\n    env = sagemaker_containers.training_env()\n\n    parser = argparse.ArgumentParser()\n\n    # Data and model checkpoints directories\n    parser.add_argument(""--epochs"", type=int, default=1)\n    parser.add_argument(""--batch-size"", type=int, default=64)\n    parser.add_argument(""--communicator"", type=str, default=""pure_nccl"")\n    parser.add_argument(""--frequency"", type=int, default=20)\n    parser.add_argument(""--units"", type=int, default=1000)\n\n    parser.add_argument(""--model-dir"", type=str)\n    parser.add_argument(""--output-data-dir"", type=str, default=env.output_data_dir)\n    parser.add_argument(""--host"", type=str, default=env.current_host)\n    parser.add_argument(""--num-gpus"", type=int, default=env.num_gpus)\n\n    parser.add_argument(""--train"", type=str, default=env.channel_input_dirs[""train""])\n    parser.add_argument(""--test"", type=str, default=env.channel_input_dirs[""test""])\n\n    args = parser.parse_args()\n\n    train_file = np.load(os.path.join(args.train, ""train.npz""))\n    test_file = np.load(os.path.join(args.test, ""test.npz""))\n\n    logger.info(""Current host: {}"".format(args.host))\n\n    communicator = ""naive"" if args.num_gpus == 0 else args.communicator\n\n    comm = chainermn.create_communicator(communicator)\n    device = comm.intra_rank if args.num_gpus > 0 else -1\n\n    print(""=========================================="")\n    print(""Using {} communicator"".format(comm))\n    print(""Num unit: {}"".format(args.units))\n    print(""Num Minibatch-size: {}"".format(args.batch_size))\n    print(""Num epoch: {}"".format(args.epochs))\n    print(""=========================================="")\n\n    model = L.Classifier(MLP(args.units, 10))\n    if device >= 0:\n        chainer.cuda.get_device(device).use()\n\n    # Create a multi node optimizer from a standard Chainer optimizer.\n    optimizer = chainermn.create_multi_node_optimizer(chainer.optimizers.Adam(), comm)\n    optimizer.setup(model)\n\n    preprocess_mnist_options = {\n        ""withlabel"": True,\n        ""ndim"": 1,\n        ""scale"": 1.0,\n        ""image_dtype"": np.float32,\n        ""label_dtype"": np.int32,\n        ""rgb_format"": False,\n    }\n\n    train_dataset = _preprocess_mnist(train_file, **preprocess_mnist_options)\n    test_dataset = _preprocess_mnist(test_file, **preprocess_mnist_options)\n\n    train_iter = chainer.iterators.SerialIterator(train_dataset, args.batch_size)\n    test_iter = chainer.iterators.SerialIterator(\n        test_dataset, args.batch_size, repeat=False, shuffle=False\n    )\n\n    updater = training.StandardUpdater(train_iter, optimizer, device=device)\n    trainer = training.Trainer(updater, (args.epochs, ""epoch""), out=args.output_data_dir)\n\n    # Create a multi node evaluator from a standard Chainer evaluator.\n    evaluator = extensions.Evaluator(test_iter, model, device=device)\n    evaluator = chainermn.create_multi_node_evaluator(evaluator, comm)\n    trainer.extend(evaluator)\n\n    # Some display and output extensions are necessary only for one worker.\n    # (Otherwise, there would just be repeated outputs.)\n    if comm.rank == 0:\n        if extensions.PlotReport.available():\n            trainer.extend(\n                extensions.PlotReport(\n                    [""main/loss"", ""validation/main/loss""], ""epoch"", file_name=""loss.png""\n                )\n            )\n            trainer.extend(\n                extensions.PlotReport(\n                    [""main/accuracy"", ""validation/main/accuracy""], ""epoch"", file_name=""accuracy.png""\n                )\n            )\n        trainer.extend(extensions.snapshot(), trigger=(args.frequency, ""epoch""))\n        trainer.extend(extensions.dump_graph(""main/loss""))\n        trainer.extend(extensions.LogReport())\n        trainer.extend(\n            extensions.PrintReport(\n                [\n                    ""epoch"",\n                    ""main/loss"",\n                    ""validation/main/loss"",\n                    ""main/accuracy"",\n                    ""validation/main/accuracy"",\n                    ""elapsed_time"",\n                ]\n            )\n        )\n        trainer.extend(extensions.ProgressBar())\n\n    trainer.run()\n\n    # only save the model in the master node\n    if args.host == env.hosts[0]:\n        serializers.save_npz(os.path.join(env.model_dir, ""model.npz""), model)\n\n\ndef model_fn(model_dir):\n    model = L.Classifier(MLP(1000, 10))\n    serializers.load_npz(os.path.join(model_dir, ""model.npz""), model)\n    return model.predictor\n'"
tests/data/chainer_mnist/mnist.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import print_function\n\nimport argparse\nimport os\n\nimport chainer\nfrom chainer import serializers, training\nfrom chainer.datasets import tuple_dataset\nimport chainer.functions as F\nimport chainer.links as L\nfrom chainer.training import extensions\nimport numpy as np\n\nimport sagemaker_containers\n\n\nclass MLP(chainer.Chain):\n    def __init__(self, n_units, n_out):\n        super(MLP, self).__init__()\n        with self.init_scope():\n            # the size of the inputs to each layer will be inferred\n            self.l1 = L.Linear(None, n_units)  # n_in -> n_units\n            self.l2 = L.Linear(None, n_units)  # n_units -> n_units\n            self.l3 = L.Linear(None, n_out)  # n_units -> n_out\n\n    def __call__(self, x):\n        h1 = F.relu(self.l1(x))\n        h2 = F.relu(self.l2(h1))\n        return self.l3(h2)\n\n\ndef _preprocess_mnist(raw, withlabel, ndim, scale, image_dtype, label_dtype, rgb_format):\n    images = raw[""x""][-100:]\n    if ndim == 2:\n        images = images.reshape(-1, 28, 28)\n    elif ndim == 3:\n        images = images.reshape(-1, 1, 28, 28)\n        if rgb_format:\n            images = np.broadcast_to(images, (len(images), 3) + images.shape[2:])\n    elif ndim != 1:\n        raise ValueError(""invalid ndim for MNIST dataset"")\n    images = images.astype(image_dtype)\n    images *= scale / 255.0\n\n    if withlabel:\n        labels = raw[""y""][-100:].astype(label_dtype)\n        return tuple_dataset.TupleDataset(images, labels)\n    else:\n        return images\n\n\nif __name__ == ""__main__"":\n    env = sagemaker_containers.training_env()\n\n    parser = argparse.ArgumentParser()\n\n    # Data and model checkpoints directories\n    parser.add_argument(""--units"", type=int, default=1000)\n    parser.add_argument(""--epochs"", type=int, default=20)\n    parser.add_argument(""--frequency"", type=int, default=20)\n    parser.add_argument(""--batch-size"", type=int, default=100)\n    parser.add_argument(""--alpha"", type=float, default=0.001)\n    parser.add_argument(""--model-dir"", type=str, default=env.model_dir)\n\n    parser.add_argument(""--train"", type=str, default=env.channel_input_dirs[""train""])\n    parser.add_argument(""--test"", type=str, default=env.channel_input_dirs[""test""])\n\n    parser.add_argument(""--num-gpus"", type=int, default=env.num_gpus)\n\n    args = parser.parse_args()\n\n    train_file = np.load(os.path.join(args.train, ""train.npz""))\n    test_file = np.load(os.path.join(args.test, ""test.npz""))\n\n    preprocess_mnist_options = {\n        ""withlabel"": True,\n        ""ndim"": 1,\n        ""scale"": 1.0,\n        ""image_dtype"": np.float32,\n        ""label_dtype"": np.int32,\n        ""rgb_format"": False,\n    }\n\n    train = _preprocess_mnist(train_file, **preprocess_mnist_options)\n    test = _preprocess_mnist(test_file, **preprocess_mnist_options)\n\n    # Set up a neural network to train\n    # Classifier reports softmax cross entropy loss and accuracy at every\n    # iteration, which will be used by the PrintReport extension below.\n    model = L.Classifier(MLP(args.units, 10))\n\n    if chainer.cuda.available:\n        chainer.cuda.get_device_from_id(0).use()\n\n    # Setup an optimizer\n    optimizer = chainer.optimizers.Adam(alpha=args.alpha)\n    optimizer.setup(model)\n\n    # Load the MNIST dataset\n    train_iter = chainer.iterators.SerialIterator(train, args.batch_size)\n    test_iter = chainer.iterators.SerialIterator(test, args.batch_size, repeat=False, shuffle=False)\n\n    # Set up a trainer\n    device = 0 if chainer.cuda.available else -1  # -1 indicates CPU, 0 indicates first GPU device.\n    if chainer.cuda.available:\n\n        def device_name(device_intra_rank):\n            return ""main"" if device_intra_rank == 0 else str(device_intra_rank)\n\n        devices = {device_name(device): device for device in range(args.num_gpus)}\n        updater = training.updater.ParallelUpdater(\n            train_iter,\n            optimizer,\n            # The device of the name \'main\' is used as a ""master"", while others are\n            # used as slaves. Names other than \'main\' are arbitrary.\n            devices=devices,\n        )\n    else:\n        updater = training.updater.StandardUpdater(train_iter, optimizer, device=device)\n\n    # Write output files to output_data_dir.\n    # These are zipped and uploaded to S3 output path as output.tar.gz.\n    trainer = training.Trainer(updater, (args.epochs, ""epoch""), out=env.output_data_dir)\n\n    # Evaluate the model with the test dataset for each epoch\n\n    trainer.extend(extensions.Evaluator(test_iter, model, device=device))\n\n    # Dump a computational graph from \'loss\' variable at the first iteration\n    # The ""main"" refers to the target link of the ""main"" optimizer.\n    trainer.extend(extensions.dump_graph(""main/loss""))\n\n    # Take a snapshot for each specified epoch\n    trainer.extend(extensions.snapshot(), trigger=(args.frequency, ""epoch""))\n\n    # Write a log of evaluation statistics for each epoch\n    trainer.extend(extensions.LogReport())\n\n    # Save two plot images to the result dir\n    if extensions.PlotReport.available():\n        trainer.extend(\n            extensions.PlotReport(\n                [""main/loss"", ""validation/main/loss""], ""epoch"", file_name=""loss.png""\n            )\n        )\n        trainer.extend(\n            extensions.PlotReport(\n                [""main/accuracy"", ""validation/main/accuracy""], ""epoch"", file_name=""accuracy.png""\n            )\n        )\n\n    # Print selected entries of the log to stdout\n    # Here ""main"" refers to the target link of the ""main"" optimizer again, and\n    # ""validation"" refers to the default name of the Evaluator extension.\n    # Entries other than \'epoch\' are reported by the Classifier link, called by\n    # either the updater or the evaluator.\n    trainer.extend(\n        extensions.PrintReport(\n            [\n                ""epoch"",\n                ""main/loss"",\n                ""validation/main/loss"",\n                ""main/accuracy"",\n                ""validation/main/accuracy"",\n                ""elapsed_time"",\n            ]\n        )\n    )\n\n    # Print a progress bar to stdout\n    trainer.extend(extensions.ProgressBar())\n\n    # Run the training\n    trainer.run()\n\n    serializers.save_npz(os.path.join(args.model_dir, ""model.npz""), model)\n\n\ndef model_fn(model_dir):\n    model = L.Classifier(MLP(1000, 10))\n    serializers.load_npz(os.path.join(model_dir, ""model.npz""), model)\n    return model.predictor\n'"
tests/data/coach_cartpole/mxnet_deploy.py,0,"b'import os\nimport json\nimport mxnet as mx\nfrom mxnet.contrib import onnx as onnx_mxnet\nfrom mxnet import gluon, nd\n\n\ndef model_fn(model_dir):\n    """"""\n    Load the onnx model. Called once when hosting service starts.\n\n    :param: model_dir The directory where model files are stored.\n    :return: a model\n    """"""\n    onnx_path = os.path.join(model_dir, ""model.onnx"")\n    ctx = mx.cpu()  # todo: pass into function\n    # load onnx model symbol and parameters\n    sym, arg_params, aux_params = onnx_mxnet.import_model(onnx_path)\n    model_metadata = onnx_mxnet.get_model_metadata(onnx_path)\n    # first index is name, second index is shape\n    input_names = [inputs[0] for inputs in model_metadata.get(""input_tensor_data"")]\n    input_symbols = [mx.sym.var(i) for i in input_names]\n    net = gluon.nn.SymbolBlock(outputs=sym, inputs=input_symbols)\n    net_params = net.collect_params()\n    # set parameters (on correct context)\n    for param in arg_params:\n        if param in net_params:\n            net_params[param]._load_init(arg_params[param], ctx=ctx)\n    for param in aux_params:\n        if param in net_params:\n            net_params[param]._load_init(aux_params[param], ctx=ctx)\n    # hybridize for increase performance\n    net.hybridize()\n    return net\n\n\ndef transform_fn(net, data, input_content_type, output_content_type):\n    """"""\n    Transform a request using the Gluon model. Called once per request.\n\n    :param mod: The super resolution model.\n    :param data: The request payload.\n    :param input_content_type: The request content type.\n    :param output_content_type: The (desired) response content type.\n    :return: response payload and content type.\n    """"""\n    input_list = json.loads(data)\n    input_nd = mx.nd.array(input_list).expand_dims(0)\n    output_nd = net(input_nd)\n    output_np = output_nd.asnumpy()\n    output_list = output_np.tolist()\n    return json.dumps(output_list), output_content_type\n'"
tests/data/coach_cartpole/preset_cartpole_clippedppo.py,0,"b'from rl_coach.agents.clipped_ppo_agent import ClippedPPOAgentParameters\nfrom rl_coach.architectures.layers import Dense\nfrom rl_coach.base_parameters import (\n    VisualizationParameters,\n    PresetValidationParameters,\n    DistributedCoachSynchronizationType,\n)\nfrom rl_coach.core_types import TrainingSteps, EnvironmentEpisodes, EnvironmentSteps, RunPhase\nfrom rl_coach.environments.gym_environment import GymVectorEnvironment, mujoco_v2\nfrom rl_coach.exploration_policies.additive_noise import AdditiveNoiseParameters\nfrom rl_coach.exploration_policies.e_greedy import EGreedyParameters\nfrom rl_coach.filters.observation.observation_normalization_filter import (\n    ObservationNormalizationFilter,\n)\nfrom rl_coach.graph_managers.basic_rl_graph_manager import BasicRLGraphManager\nfrom rl_coach.graph_managers.graph_manager import ScheduleParameters\nfrom rl_coach.schedules import LinearSchedule\n\n####################\n# Graph Scheduling #\n####################\n\nschedule_params = ScheduleParameters()\n# schedule_params.improve_steps = TrainingSteps(500)\n# schedule_params.steps_between_evaluation_periods = EnvironmentSteps(20)\n# schedule_params.evaluation_steps = EnvironmentEpisodes(5)\n# schedule_params.heatup_steps = EnvironmentSteps(0)\n\nschedule_params.improve_steps = TrainingSteps(10000)\nschedule_params.steps_between_evaluation_periods = EnvironmentSteps(204)\nschedule_params.evaluation_steps = EnvironmentEpisodes(5)\nschedule_params.heatup_steps = EnvironmentSteps(0)\n\n#########\n# Agent #\n#########\nagent_params = ClippedPPOAgentParameters()\n\n\nagent_params.network_wrappers[""main""].learning_rate = 0.0003\nagent_params.network_wrappers[""main""].input_embedders_parameters[\n    ""observation""\n].activation_function = ""tanh""\nagent_params.network_wrappers[""main""].input_embedders_parameters[""observation""].scheme = [Dense(64)]\nagent_params.network_wrappers[""main""].middleware_parameters.scheme = [Dense(64)]\nagent_params.network_wrappers[""main""].middleware_parameters.activation_function = ""tanh""\nagent_params.network_wrappers[""main""].batch_size = 64\nagent_params.network_wrappers[""main""].optimizer_epsilon = 1e-5\nagent_params.network_wrappers[""main""].adam_optimizer_beta2 = 0.999\n\nagent_params.algorithm.clip_likelihood_ratio_using_epsilon = 0.2\nagent_params.algorithm.clipping_decay_schedule = LinearSchedule(1.0, 0, 1000000)\nagent_params.algorithm.beta_entropy = 0\nagent_params.algorithm.gae_lambda = 0.95\nagent_params.algorithm.discount = 0.99\nagent_params.algorithm.optimization_epochs = 10\nagent_params.algorithm.estimate_state_value_using_gae = True\nagent_params.algorithm.num_steps_between_copying_online_weights_to_target = EnvironmentSteps(2048)\n\n# Distributed Coach synchronization type.\nagent_params.algorithm.distributed_coach_synchronization_type = (\n    DistributedCoachSynchronizationType.SYNC\n)\n\nagent_params.exploration = EGreedyParameters()\nagent_params.exploration.epsilon_schedule = LinearSchedule(1.0, 0.01, 10000)\nagent_params.pre_network_filter.add_observation_filter(\n    ""observation"",\n    ""normalize_observation"",\n    ObservationNormalizationFilter(name=""normalize_observation""),\n)\n\n###############\n# Environment #\n###############\nenv_params = GymVectorEnvironment(level=""CartPole-v0"")\n\n#################\n# Visualization #\n#################\n\nvis_params = VisualizationParameters()\nvis_params.dump_gifs = True\n\n########\n# Test #\n########\npreset_validation_params = PresetValidationParameters()\npreset_validation_params.test = True\npreset_validation_params.min_reward_threshold = 150\npreset_validation_params.max_episodes_to_achieve_reward = 400\n\ngraph_manager = BasicRLGraphManager(\n    agent_params=agent_params,\n    env_params=env_params,\n    schedule_params=schedule_params,\n    vis_params=vis_params,\n    preset_validation_params=preset_validation_params,\n)\n'"
tests/data/coach_cartpole/train_coach.py,0,"b'from sagemaker_rl.coach_launcher import SageMakerCoachPresetLauncher\n\n\nclass MyLauncher(SageMakerCoachPresetLauncher):\n    def default_preset_name(self):\n        """"""This points to a .py file that configures everything about the RL job.\n        It can be overridden at runtime by specifying the RLCOACH_PRESET hyperparameter.\n        """"""\n        return ""preset-cartpole-dqn""\n\n    def map_hyperparameter(self, name, value):\n        """"""Here we configure some shortcut names for hyperparameters that we expect to use frequently.\n        Essentially anything in the preset file can be overridden through a hyperparameter with a name\n        like ""rl.agent_params.algorithm.etc"".\n        """"""\n        # maps from alias (key) to fully qualified coach parameter (value)\n        mapping = {\n            ""discount"": ""rl.agent_params.algorithm.discount"",\n            ""evaluation_episodes"": ""rl.evaluation_steps:EnvironmentEpisodes"",\n            ""improve_steps"": ""rl.improve_steps:TrainingSteps"",\n        }\n        if name in mapping:\n            self.apply_hyperparameter(mapping[name], value)\n        else:\n            super().map_hyperparameter(name, value)\n\n\nif __name__ == ""__main__"":\n    MyLauncher.train_main()\n'"
tests/data/horovod/hvd_basic.py,0,"b'import json\nimport os\n\nimport horovod.tensorflow as hvd\n\nif __name__ == ""__main__"":\n\n    hvd.init()\n\n    with open(os.path.join(""/opt/ml/model/rank-%s"" % hvd.rank()), ""w+"") as f:\n        basic_info = {""rank"": hvd.rank(), ""size"": hvd.size()}\n\n        json.dump(basic_info, f)\n        print(\'Saved file ""rank-%s"": %s\' % (hvd.rank(), basic_info))\n'"
tests/data/iris/failure_script.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\n\ndef estimator_fn(run_config, params):\n    """"""For use with integration tests expecting failures.""""""\n    raise Exception(""This failure is expected."")\n'"
tests/data/iris/iris-dnn-classifier.py,7,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport numpy as np\nimport os\nimport tensorflow as tf\n\n\ndef estimator_fn(run_config, hyperparameters):\n    input_tensor_name = hyperparameters.get(""input_tensor_name"", ""inputs"")\n    learning_rate = hyperparameters.get(""learning_rate"", 0.05)\n    feature_columns = [tf.feature_column.numeric_column(input_tensor_name, shape=[4])]\n    return tf.estimator.DNNClassifier(\n        feature_columns=feature_columns,\n        hidden_units=[10, 20, 10],\n        optimizer=tf.train.AdagradOptimizer(learning_rate=learning_rate),\n        n_classes=3,\n        config=run_config,\n    )\n\n\ndef serving_input_fn(hyperparameters):\n    input_tensor_name = hyperparameters[""input_tensor_name""]\n    feature_spec = {input_tensor_name: tf.FixedLenFeature(dtype=tf.float32, shape=[4])}\n    return tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)()\n\n\ndef train_input_fn(training_dir, hyperparameters):\n    """"""Returns input function that would feed the model during training""""""\n    return _generate_input_fn(training_dir, ""iris_training.csv"", hyperparameters)\n\n\ndef eval_input_fn(training_dir, hyperparameters):\n    """"""Returns input function that would feed the model during evaluation""""""\n    return _generate_input_fn(training_dir, ""iris_test.csv"", hyperparameters)\n\n\ndef _generate_input_fn(training_dir, training_filename, hyperparameters):\n    input_tensor_name = hyperparameters[""input_tensor_name""]\n\n    training_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n        filename=os.path.join(training_dir, training_filename),\n        target_dtype=np.int,\n        features_dtype=np.float32,\n    )\n\n    return tf.estimator.inputs.numpy_input_fn(\n        x={input_tensor_name: np.array(training_set.data)},\n        y=np.array(training_set.target),\n        num_epochs=None,\n        shuffle=True,\n    )()\n'"
tests/data/monitor/postprocessor.py,0,"b'def postprocess_handler():\n    print(""postprocessor.py::postprocess_handler was called."")\n'"
tests/data/monitor/preprocessor.py,0,"b'import json\nimport random\n\n\n# sample preprocess_handler (to be implemented by customer)\n# This is a trivial example, where we demonstrate an echo preprocessor for json data\n# for others though, we are generating random data (real customers would not do that obviously/hopefully)\ndef preprocess_handler(inference_record):\n    event_data = inference_record.event_data\n    input_data = {}\n    output_data = {}\n\n    # If the input data is JSON encoded, the following code just echoes it back\n    if event_data.endpointInput.encoding == ""JSON"":\n        input_data = json.loads(event_data.endpointInput.data)\n\n    if event_data.endpointOutput.encoding == ""JSON"":\n        output_data = json.loads(event_data.endpointOutput.data)\n\n    # for non JSON data, this code just generates something random\n    # real customers would read the event_data and transform it into a json\n    if not input_data:\n        input_data[""feature0""] = random.uniform(0, 1)\n        input_data[""feature1""] = random.uniform(0, 1)\n\n    if not output_data:\n        output_data[""prediction""] = random.uniform(0, 1)\n\n    return {**input_data, **output_data}\n'"
tests/data/mxnet_mnist/failure_script.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\n\n# For use with integration tests expecting failures.\nraise Exception(""This failure is expected."")\n'"
tests/data/mxnet_mnist/mnist.py,0,"b'# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport argparse\nimport gzip\nimport json\nimport logging\nimport os\nimport struct\n\nimport mxnet as mx\nimport numpy as np\n\n\ndef load_data(path):\n    with gzip.open(find_file(path, ""labels.gz"")) as flbl:\n        struct.unpack("">II"", flbl.read(8))\n        labels = np.fromstring(flbl.read(), dtype=np.int8)\n    with gzip.open(find_file(path, ""images.gz"")) as fimg:\n        _, _, rows, cols = struct.unpack("">IIII"", fimg.read(16))\n        images = np.fromstring(fimg.read(), dtype=np.uint8).reshape(len(labels), rows, cols)\n        images = images.reshape(images.shape[0], 1, 28, 28).astype(np.float32) / 255\n    return labels, images\n\n\ndef find_file(root_path, file_name):\n    for root, dirs, files in os.walk(root_path):\n        if file_name in files:\n            return os.path.join(root, file_name)\n\n\ndef build_graph():\n    data = mx.sym.var(""data"")\n    data = mx.sym.flatten(data=data)\n    fc1 = mx.sym.FullyConnected(data=data, num_hidden=128)\n    act1 = mx.sym.Activation(data=fc1, act_type=""relu"")\n    fc2 = mx.sym.FullyConnected(data=act1, num_hidden=64)\n    act2 = mx.sym.Activation(data=fc2, act_type=""relu"")\n    fc3 = mx.sym.FullyConnected(data=act2, num_hidden=10)\n    return mx.sym.SoftmaxOutput(data=fc3, name=""softmax"")\n\n\ndef get_train_context(num_gpus):\n    if num_gpus:\n        return [mx.gpu(i) for i in range(num_gpus)]\n    else:\n        return mx.cpu()\n\n\ndef train(\n    batch_size,\n    epochs,\n    learning_rate,\n    num_gpus,\n    training_channel,\n    testing_channel,\n    hosts,\n    current_host,\n    model_dir,\n):\n    (train_labels, train_images) = load_data(training_channel)\n    (test_labels, test_images) = load_data(testing_channel)\n\n    # Data parallel training - shard the data so each host\n    # only trains on a subset of the total data.\n    shard_size = len(train_images) // len(hosts)\n    for i, host in enumerate(hosts):\n        if host == current_host:\n            start = shard_size * i\n            end = start + shard_size\n            break\n\n    train_iter = mx.io.NDArrayIter(\n        train_images[start:end], train_labels[start:end], batch_size, shuffle=True\n    )\n    val_iter = mx.io.NDArrayIter(test_images, test_labels, batch_size)\n\n    logging.getLogger().setLevel(logging.DEBUG)\n\n    kvstore = ""local"" if len(hosts) == 1 else ""dist_sync""\n\n    mlp_model = mx.mod.Module(symbol=build_graph(), context=get_train_context(num_gpus))\n    mlp_model.fit(\n        train_iter,\n        eval_data=val_iter,\n        kvstore=kvstore,\n        optimizer=""sgd"",\n        optimizer_params={""learning_rate"": learning_rate},\n        eval_metric=""acc"",\n        batch_end_callback=mx.callback.Speedometer(batch_size, 100),\n        num_epoch=epochs,\n    )\n\n    if len(hosts) == 1 or current_host == hosts[0]:\n        save(model_dir, mlp_model)\n\n\ndef save(model_dir, model):\n    model.symbol.save(os.path.join(model_dir, ""model-symbol.json""))\n    model.save_params(os.path.join(model_dir, ""model-0000.params""))\n\n    signature = [\n        {""name"": data_desc.name, ""shape"": [dim for dim in data_desc.shape]}\n        for data_desc in model.data_shapes\n    ]\n    with open(os.path.join(model_dir, ""model-shapes.json""), ""w"") as f:\n        json.dump(signature, f)\n\n\nif __name__ == ""__main__"":\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument(""--batch-size"", type=int, default=100)\n    parser.add_argument(""--epochs"", type=int, default=10)\n    parser.add_argument(""--learning-rate"", type=float, default=0.1)\n\n    parser.add_argument(""--model-dir"", type=str, default=os.environ[""SM_MODEL_DIR""])\n    parser.add_argument(""--train"", type=str, default=os.environ[""SM_CHANNEL_TRAIN""])\n    parser.add_argument(""--test"", type=str, default=os.environ[""SM_CHANNEL_TEST""])\n\n    parser.add_argument(""--current-host"", type=str, default=os.environ[""SM_CURRENT_HOST""])\n    parser.add_argument(""--hosts"", type=list, default=json.loads(os.environ[""SM_HOSTS""]))\n\n    args = parser.parse_args()\n\n    num_gpus = int(os.environ[""SM_NUM_GPUS""])\n\n    train(\n        args.batch_size,\n        args.epochs,\n        args.learning_rate,\n        num_gpus,\n        args.train,\n        args.test,\n        args.hosts,\n        args.current_host,\n        args.model_dir,\n    )\n'"
tests/data/mxnet_mnist/mnist_gluon.py,0,"b'# Standard Library\nimport argparse\nimport random\n\n# Third Party\nimport mxnet as mx\nimport numpy as np\nfrom mxnet import autograd, gluon\nfrom mxnet.gluon import nn\n\n\ndef parse_args():\n    parser = argparse.ArgumentParser(\n        description=""Train a mxnet gluon model for FashonMNIST dataset""\n    )\n    parser.add_argument(""--batch-size"", type=int, default=256, help=""Batch size"")\n    parser.add_argument(""--epochs"", type=int, default=1, help=""Number of Epochs"")\n    parser.add_argument(""--learning_rate"", type=float, default=0.1)\n    parser.add_argument(\n        ""--context"", type=str, default=""cpu"", help=""Context can be either cpu or gpu""\n    )\n    parser.add_argument(\n        ""--validate"", type=bool, default=True, help=""Run validation if running with smdebug""\n    )\n\n    opt = parser.parse_args()\n    return opt\n\n\ndef test(ctx, net, val_data):\n    metric = mx.metric.Accuracy()\n    for i, (data, label) in enumerate(val_data):\n        data = data.as_in_context(ctx)\n        label = label.as_in_context(ctx)\n        output = net(data)\n        metric.update([label], [output])\n\n    return metric.get()\n\n\ndef train_model(net, epochs, ctx, learning_rate, momentum, train_data, val_data):\n    # Collect all parameters from net and its children, then initialize them.\n    net.initialize(mx.init.Xavier(magnitude=2.24), ctx=ctx)\n    # Trainer is for updating parameters with gradient.\n    trainer = gluon.Trainer(\n        net.collect_params(), ""sgd"", {""learning_rate"": learning_rate, ""momentum"": momentum}\n    )\n    metric = mx.metric.Accuracy()\n    loss = gluon.loss.SoftmaxCrossEntropyLoss()\n\n    for epoch in range(epochs):\n        # reset data iterator and metric at begining of epoch.\n        metric.reset()\n        for i, (data, label) in enumerate(train_data):\n            # Copy data to ctx if necessary\n            data = data.as_in_context(ctx)\n            label = label.as_in_context(ctx)\n            # Start recording computation graph with record() section.\n            # Recorded graphs can then be differentiated with backward.\n            with autograd.record():\n                output = net(data)\n                L = loss(output, label)\n                L.backward()\n            # take a gradient step with batch_size equal to data.shape[0]\n            trainer.step(data.shape[0])\n            # update metric at last.\n            metric.update([label], [output])\n\n            if i % 100 == 0 and i > 0:\n                name, acc = metric.get()\n                print(""[Epoch %d Batch %d] Training: %s=%f"" % (epoch, i, name, acc))\n\n        name, acc = metric.get()\n        print(""[Epoch %d] Training: %s=%f"" % (epoch, name, acc))\n        name, val_acc = test(ctx, net, val_data)\n        print(""[Epoch %d] Validation: %s=%f"" % (epoch, name, val_acc))\n\n\ndef transformer(data, label):\n    data = data.reshape((-1,)).astype(np.float32) / 255\n    return data, label\n\n\ndef prepare_data(batch_size):\n    train_data = gluon.data.DataLoader(\n        gluon.data.vision.MNIST(""/tmp"", train=True, transform=transformer),\n        batch_size=batch_size,\n        shuffle=True,\n        last_batch=""discard"",\n    )\n\n    val_data = gluon.data.DataLoader(\n        gluon.data.vision.MNIST(""/tmp"", train=False, transform=transformer),\n        batch_size=batch_size,\n        shuffle=False,\n    )\n    return train_data, val_data\n\n\n# Create a model using gluon API. The hook is currently\n# supports MXNet gluon models only.\ndef create_gluon_model():\n    net = nn.Sequential()\n    with net.name_scope():\n        net.add(nn.Dense(128, activation=""relu""))\n        net.add(nn.Dense(64, activation=""relu""))\n        net.add(nn.Dense(10))\n    return net\n\n\ndef main():\n    opt = parse_args()\n    mx.random.seed(128)\n    random.seed(12)\n    np.random.seed(2)\n\n    context = mx.cpu() if opt.context.lower() == ""cpu"" else mx.gpu()\n    # Create a Gluon Model.\n    net = create_gluon_model()\n\n    # Start the training.\n    train_data, val_data = prepare_data(opt.batch_size)\n\n    train_model(\n        net=net,\n        epochs=opt.epochs,\n        ctx=context,\n        learning_rate=opt.learning_rate,\n        momentum=0.9,\n        train_data=train_data,\n        val_data=val_data,\n    )\n\n\nif __name__ == ""__main__"":\n    main()\n'"
tests/data/mxnet_mnist/mnist_hosting_with_custom_handlers.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport gzip\nimport json\nimport mxnet as mx\nimport numpy as np\nimport os\nimport struct\n\n\n# --- this example demonstrates how to extend default behavior during model hosting ---\n\n# --- Model preparation ---\n# it is possible to specify own code to load the model, otherwise a default model loading takes place\ndef model_fn(path_to_model_files):\n    from mxnet.io import DataDesc\n\n    loaded_symbol = mx.symbol.load(os.path.join(path_to_model_files, ""symbol""))\n    created_module = mx.mod.Module(symbol=loaded_symbol)\n    created_module.bind([DataDesc(""data"", (1, 1, 28, 28))])\n    created_module.load_params(os.path.join(path_to_model_files, ""params""))\n    return created_module\n\n\n# --- Option 1 - provide just 1 entry point for end2end prediction ---\n# if this function is specified, no other overwriting described in Option 2 will have effect\n# returns serialized data and content type it has used\ndef transform_fn(model, request_data, input_content_type, requested_output_content_type):\n    # for demonstration purposes we will be calling handlers from Option2\n    return (\n        output_fn(\n            process_request_fn(model, request_data, input_content_type),\n            requested_output_content_type,\n        ),\n        requested_output_content_type,\n    )\n\n\n# --- Option 2 - overwrite container\'s default input/output behavior with handlers ---\n# there are 2 data handlers: input and output, you need to conform to their interface to fit into default execution\ndef process_request_fn(model, data, input_content_type):\n    if input_content_type == ""text/s3_file_path"":\n        prediction_input = handle_s3_file_path(data)\n    elif input_content_type == ""application/json"":\n        prediction_input = handle_json_input(data)\n    else:\n        raise NotImplementedError(\n            ""This model doesnt support requested input type: "" + input_content_type\n        )\n\n    return model.predict(prediction_input)\n\n\n# for this example S3 path points to a file that is same format as in test/images.gz\ndef handle_s3_file_path(path):\n    import sys\n\n    if sys.version_info.major == 2:\n        import urlparse\n\n        parse_cmd = urlparse.urlparse\n    else:\n        import urllib\n\n        parse_cmd = urllib.parse.urlparse\n\n    import boto3\n    from botocore.exceptions import ClientError\n\n    # parse the path\n    parsed_url = parse_cmd(path)\n\n    # get S3 client\n    s3 = boto3.resource(""s3"")\n\n    # read file content and pass it down\n    obj = s3.Object(parsed_url.netloc, parsed_url.path.lstrip(""/""))\n    print(""loading file: "" + str(obj))\n\n    try:\n        data = obj.get()[""Body""]\n    except ClientError as ce:\n        raise ValueError(\n            ""Can\'t download from S3 path: "" + path + "" : "" + ce.response[""Error""][""Message""]\n        )\n\n    import StringIO\n\n    buf = StringIO(data.read())\n    img = gzip.GzipFile(mode=""rb"", fileobj=buf)\n\n    _, _, rows, cols = struct.unpack("">IIII"", img.read(16))\n    images = np.fromstring(img.read(), dtype=np.uint8).reshape(10000, rows, cols)\n    images = images.reshape(images.shape[0], 1, 28, 28).astype(np.float32) / 255\n\n    return mx.io.NDArrayIter(images, None, 1)\n\n\n# for this example it is assumed that the client is passing data that can be ""directly"" provided to the model\ndef handle_json_input(data):\n    nda = mx.nd.array(json.loads(data))\n    return mx.io.NDArrayIter(nda, None, 1)\n\n\ndef output_fn(prediction_output, requested_output_content_type):\n    # output from the model is NDArray\n\n    data_to_return = prediction_output.asnumpy()\n\n    if requested_output_content_type == ""application/json"":\n        json.dumps(data_to_return.tolist), requested_output_content_type\n\n    raise NotImplementedError(\n        ""Model doesn\'t support requested output type: "" + requested_output_content_type\n    )\n'"
tests/data/mxnet_mnist/mnist_neo.py,0,"b'# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport argparse\nimport gzip\nimport json\nimport logging\nimport os\nimport struct\n\nimport mxnet as mx\nimport numpy as np\n\n\ndef load_data(path):\n    with gzip.open(find_file(path, ""labels.gz"")) as flbl:\n        struct.unpack("">II"", flbl.read(8))\n        labels = np.fromstring(flbl.read(), dtype=np.int8)\n    with gzip.open(find_file(path, ""images.gz"")) as fimg:\n        _, _, rows, cols = struct.unpack("">IIII"", fimg.read(16))\n        images = np.fromstring(fimg.read(), dtype=np.uint8).reshape(len(labels), rows, cols)\n        images = images.reshape(images.shape[0], 1, 28, 28).astype(np.float32) / 255\n    return labels, images\n\n\ndef find_file(root_path, file_name):\n    for root, dirs, files in os.walk(root_path):\n        if file_name in files:\n            return os.path.join(root, file_name)\n\n\ndef build_graph():\n    data = mx.sym.var(""data"")\n    data = mx.sym.flatten(data=data)\n    fc1 = mx.sym.FullyConnected(data=data, num_hidden=128)\n    act1 = mx.sym.Activation(data=fc1, act_type=""relu"")\n    fc2 = mx.sym.FullyConnected(data=act1, num_hidden=64)\n    act2 = mx.sym.Activation(data=fc2, act_type=""relu"")\n    fc3 = mx.sym.FullyConnected(data=act2, num_hidden=10)\n    return mx.sym.SoftmaxOutput(data=fc3, name=""softmax"")\n\n\ndef get_train_context(num_gpus):\n    if num_gpus:\n        return [mx.gpu(i) for i in range(num_gpus)]\n    else:\n        return mx.cpu()\n\n\ndef train(\n    batch_size,\n    epochs,\n    learning_rate,\n    num_gpus,\n    training_channel,\n    testing_channel,\n    hosts,\n    current_host,\n    model_dir,\n):\n    (train_labels, train_images) = load_data(training_channel)\n    (test_labels, test_images) = load_data(testing_channel)\n\n    # Data parallel training - shard the data so each host\n    # only trains on a subset of the total data.\n    shard_size = len(train_images) // len(hosts)\n    for i, host in enumerate(hosts):\n        if host == current_host:\n            start = shard_size * i\n            end = start + shard_size\n            break\n\n    train_iter = mx.io.NDArrayIter(\n        train_images[start:end], train_labels[start:end], batch_size, shuffle=True\n    )\n    val_iter = mx.io.NDArrayIter(test_images, test_labels, batch_size)\n\n    logging.getLogger().setLevel(logging.DEBUG)\n\n    kvstore = ""local"" if len(hosts) == 1 else ""dist_sync""\n\n    mlp_model = mx.mod.Module(symbol=build_graph(), context=get_train_context(num_gpus))\n    mlp_model.fit(\n        train_iter,\n        eval_data=val_iter,\n        kvstore=kvstore,\n        optimizer=""sgd"",\n        optimizer_params={""learning_rate"": learning_rate},\n        eval_metric=""acc"",\n        batch_end_callback=mx.callback.Speedometer(batch_size, 100),\n        num_epoch=epochs,\n    )\n\n    if len(hosts) == 1 or current_host == scheduler_host(hosts):\n        save(model_dir, mlp_model)\n\n\ndef neo_preprocess(payload, content_type):\n    logging.info(""Invoking user-defined pre-processing function"")\n\n    if content_type != ""application/vnd+python.numpy+binary"":\n        raise RuntimeError(""Content type must be application/vnd+python.numpy+binary"")\n\n    return np.asarray(json.loads(payload.decode(""utf-8"")))\n\n\n# NOTE: this function cannot use MXNet\ndef neo_postprocess(result):\n    logging.info(""Invoking user-defined post-processing function"")\n\n    # Softmax (assumes batch size 1)\n    result = np.squeeze(result)\n    result_exp = np.exp(result - np.max(result))\n    result = result_exp / np.sum(result_exp)\n\n    response_body = json.dumps(result.tolist())\n    content_type = ""application/json""\n\n    return response_body, content_type\n\n\nif __name__ == ""__main__"":\n    # Import here to prevent import during serving\n    from sagemaker_mxnet_container.training_utils import scheduler_host, save\n\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument(""--batch-size"", type=int, default=100)\n    parser.add_argument(""--epochs"", type=int, default=10)\n    parser.add_argument(""--learning-rate"", type=float, default=0.1)\n\n    parser.add_argument(""--model-dir"", type=str, default=os.environ[""SM_MODEL_DIR""])\n    parser.add_argument(""--train"", type=str, default=os.environ[""SM_CHANNEL_TRAIN""])\n    parser.add_argument(""--test"", type=str, default=os.environ[""SM_CHANNEL_TEST""])\n\n    parser.add_argument(""--current-host"", type=str, default=os.environ[""SM_CURRENT_HOST""])\n    parser.add_argument(""--hosts"", type=list, default=json.loads(os.environ[""SM_HOSTS""]))\n\n    args = parser.parse_args()\n\n    num_gpus = int(os.environ[""SM_NUM_GPUS""])\n\n    train(\n        args.batch_size,\n        args.epochs,\n        args.learning_rate,\n        num_gpus,\n        args.train,\n        args.test,\n        args.hosts,\n        args.current_host,\n        args.model_dir,\n    )\n'"
tests/data/mxnet_mnist/my_custom_rule.py,0,"b'from smdebug.rules.rule import Rule\n\n\nclass CustomGradientRule(Rule):\n    def __init__(self, base_trial, threshold=10.0):\n        super().__init__(base_trial)\n        self.threshold = float(threshold)\n\n    def set_required_tensors(self, step):\n        for tname in self.base_trial.tensor_names(collection=""gradients""):\n            self.req_tensors.add(tname, steps=[step])\n\n    def invoke_at_step(self, step):\n        return False\n'"
tests/data/pytorch_eia/empty_inference_script.py,0,"b'# Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n# This file is intentionally left blank to invoke default model_fn and predict_fn\n'"
tests/data/pytorch_mnist/mnist.py,0,"b'import argparse\nimport json\nimport logging\nimport os\nimport sys\nimport torch\nimport torch.distributed as dist\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.utils.data\nimport torch.utils.data.distributed\nfrom torchvision import datasets, transforms\n\nlogger = logging.getLogger(__name__)\nlogger.setLevel(logging.DEBUG)\nlogger.addHandler(logging.StreamHandler(sys.stdout))\n\n\nclass Net(nn.Module):\n    # Based on https://github.com/pytorch/examples/blob/master/mnist/main.py\n    def __init__(self):\n        logger.info(""Create neural network module"")\n\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(320, 50)\n        self.fc2 = nn.Linear(50, 10)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n        x = x.view(-1, 320)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.log_softmax(x, dim=1)\n\n\ndef _get_train_data_loader(training_dir, is_distributed, batch_size, **kwargs):\n    logger.info(""Get train data loader"")\n    dataset = datasets.MNIST(\n        training_dir,\n        train=True,\n        transform=transforms.Compose(\n            [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n        ),\n        download=False,  # True sets a dependency on an external site for our canaries.\n    )\n    train_sampler = (\n        torch.utils.data.distributed.DistributedSampler(dataset) if is_distributed else None\n    )\n    train_loader = torch.utils.data.DataLoader(\n        dataset,\n        batch_size=batch_size,\n        shuffle=train_sampler is None,\n        sampler=train_sampler,\n        **kwargs\n    )\n    return train_sampler, train_loader\n\n\ndef _get_test_data_loader(training_dir, **kwargs):\n    logger.info(""Get test data loader"")\n    return torch.utils.data.DataLoader(\n        datasets.MNIST(\n            training_dir,\n            train=False,\n            transform=transforms.Compose(\n                [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n            ),\n            download=False,  # True sets a dependency on an external site for our canaries.\n        ),\n        batch_size=1000,\n        shuffle=True,\n        **kwargs\n    )\n\n\ndef _average_gradients(model):\n    # Gradient averaging.\n    size = float(dist.get_world_size())\n    for param in model.parameters():\n        dist.all_reduce(param.grad.data, op=dist.reduce_op.SUM, group=0)\n        param.grad.data /= size\n\n\ndef train(args):\n    world_size = len(args.hosts)\n    is_distributed = world_size > 1\n    logger.debug(""Number of hosts {}. Distributed training - {}"".format(world_size, is_distributed))\n    use_cuda = args.num_gpus > 0\n    logger.debug(""Number of gpus available - {}"".format(args.num_gpus))\n    kwargs = {""num_workers"": 1, ""pin_memory"": True} if use_cuda else {}\n    device = torch.device(""cuda"" if use_cuda else ""cpu"")\n\n    if is_distributed:\n        # Initialize the distributed environment.\n        backend = ""gloo""\n        os.environ[""WORLD_SIZE""] = str(world_size)\n        host_rank = args.hosts.index(args.current_host)\n        dist.init_process_group(backend=backend, rank=host_rank, world_size=world_size)\n        logger.info(\n            ""Initialized the distributed environment: \'{}\' backend on {} nodes. "".format(\n                backend, dist.get_world_size()\n            )\n            + ""Current host rank is {}. Is cuda available: {}. Number of gpus: {}"".format(\n                dist.get_rank(), torch.cuda.is_available(), args.num_gpus\n            )\n        )\n\n    # set the seed for generating random numbers\n    seed = 1\n    torch.manual_seed(seed)\n    if use_cuda:\n        torch.cuda.manual_seed(seed)\n\n    train_sampler, train_loader = _get_train_data_loader(\n        args.data_dir, is_distributed, args.batch_size, **kwargs\n    )\n    test_loader = _get_test_data_loader(args.data_dir, **kwargs)\n\n    logger.debug(\n        ""Processes {}/{} ({:.0f}%) of train data"".format(\n            len(train_loader.sampler),\n            len(train_loader.dataset),\n            100.0 * len(train_loader.sampler) / len(train_loader.dataset),\n        )\n    )\n\n    logger.debug(\n        ""Processes {}/{} ({:.0f}%) of test data"".format(\n            len(test_loader.sampler),\n            len(test_loader.dataset),\n            100.0 * len(test_loader.sampler) / len(test_loader.dataset),\n        )\n    )\n\n    model = Net().to(device)\n    if is_distributed and use_cuda:\n        # multi-machine multi-gpu case\n        logger.debug(""Multi-machine multi-gpu: using DistributedDataParallel."")\n        model = torch.nn.parallel.DistributedDataParallel(model)\n    elif use_cuda:\n        # single-machine multi-gpu case\n        logger.debug(""Single-machine multi-gpu: using DataParallel().cuda()."")\n        model = torch.nn.DataParallel(model)\n    else:\n        # single-machine or multi-machine cpu case\n        logger.debug(""Single-machine/multi-machine cpu: using DataParallel."")\n        model = torch.nn.DataParallel(model)\n\n    optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.5)\n\n    log_interval = 100\n    for epoch in range(1, args.epochs + 1):\n        if is_distributed:\n            train_sampler.set_epoch(epoch)\n        model.train()\n        for batch_idx, (data, target) in enumerate(train_loader, 1):\n            data, target = data.to(device), target.to(device)\n            optimizer.zero_grad()\n            output = model(data)\n            loss = F.nll_loss(output, target)\n            loss.backward()\n            if is_distributed and not use_cuda:\n                # average gradients manually for multi-machine cpu case only\n                _average_gradients(model)\n            optimizer.step()\n            if batch_idx % log_interval == 0:\n                logger.debug(\n                    ""Train Epoch: {} [{}/{} ({:.0f}%)] Loss: {:.6f}"".format(\n                        epoch,\n                        batch_idx * len(data),\n                        len(train_loader.sampler),\n                        100.0 * batch_idx / len(train_loader),\n                        loss.item(),\n                    )\n                )\n        accuracy = test(model, test_loader, device)\n    save_model(model, args.model_dir)\n\n    logger.debug(""Overall test accuracy: {}"".format(accuracy))\n\n\ndef test(model, test_loader, device):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    with torch.no_grad():\n        for data, target in test_loader:\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n            test_loss += F.nll_loss(output, target, size_average=False).item()  # sum up batch loss\n            pred = output.max(1, keepdim=True)[1]  # get the index of the max log-probability\n            correct += pred.eq(target.view_as(pred)).sum().item()\n\n    test_loss /= len(test_loader.dataset)\n    accuracy = 100.0 * correct / len(test_loader.dataset)\n\n    logger.debug(\n        ""Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n"".format(\n            test_loss, correct, len(test_loader.dataset), accuracy\n        )\n    )\n\n    return accuracy\n\n\ndef model_fn(model_dir):\n    model = torch.nn.DataParallel(Net())\n    with open(os.path.join(model_dir, ""model.pth""), ""rb"") as f:\n        model.load_state_dict(torch.load(f))\n    return model\n\n\ndef save_model(model, model_dir):\n    logger.info(""Saving the model."")\n    path = os.path.join(model_dir, ""model.pth"")\n    # recommended way from http://pytorch.org/docs/master/notes/serialization.html\n    torch.save(model.state_dict(), path)\n\n\nif __name__ == ""__main__"":\n    parser = argparse.ArgumentParser()\n    parser.add_argument(""--epochs"", type=int, default=1, metavar=""N"")\n    parser.add_argument(""--batch-size"", type=int, default=64, metavar=""N"")\n\n    # Container environment\n    parser.add_argument(""--hosts"", type=list, default=json.loads(os.environ[""SM_HOSTS""]))\n    parser.add_argument(""--current-host"", type=str, default=os.environ[""SM_CURRENT_HOST""])\n    parser.add_argument(""--model-dir"", type=str, default=os.environ[""SM_MODEL_DIR""])\n    parser.add_argument(""--data-dir"", type=str, default=os.environ[""SM_CHANNEL_TRAINING""])\n    parser.add_argument(""--num-gpus"", type=int, default=os.environ[""SM_NUM_GPUS""])\n    parser.add_argument(""--num-cpus"", type=int, default=os.environ[""SM_NUM_CPUS""])\n\n    train(parser.parse_args())\n'"
tests/data/pytorch_source_dirs/train.py,0,"b'# Copyright 2018-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport alexa\nimport json\n\nMODEL = ""/opt/ml/model/answer""\n\n\ndef model_fn(anything):\n    with open(MODEL) as model:\n        return json.load(model)\n\n\ndef predict_fn(input_object, model):\n    return input_object + model\n\n\nif __name__ == ""__main__"":\n    with open(MODEL, ""w"") as model:\n        json.dump(alexa.question(""How many roads must a man walk down?""), model)\n'"
tests/data/ray_cartpole/train_ray.py,0,"b'import os\n\nimport ray\nimport ray.rllib.agents.ppo as ppo\nfrom ray.tune.logger import pretty_print\n\n# Based on https://github.com/ray-project/ray/blob/master/doc/source/rllib-training.rst#python-api\nray.init(log_to_driver=False)\nconfig = ppo.DEFAULT_CONFIG.copy()\nconfig[""num_gpus""] = int(os.environ.get(""SM_NUM_GPUS"", 0))\ncheckpoint_dir = os.environ.get(""SM_MODEL_DIR"", ""/Users/nadzeya/gym"")\nconfig[""num_workers""] = 1\nagent = ppo.PPOAgent(config=config, env=""CartPole-v0"")\n\n# Can optionally call agent.restore(path) to load a checkpoint.\n\nfor i in range(5):\n    # Perform one iteration of training the policy with PPO\n    result = agent.train()\n    print(pretty_print(result))\n\n    checkpoint = agent.save(checkpoint_dir=checkpoint_dir)\n    print(""checkpoint saved at"", checkpoint)\n'"
tests/data/sagemaker_rl/__init__.py,0,b''
tests/data/sagemaker_rl/coach_launcher.py,7,"b'from rl_coach.agents.clipped_ppo_agent import ClippedPPOAgentParameters\nfrom rl_coach.agents.policy_gradients_agent import PolicyGradientsAgentParameters\nfrom rl_coach.graph_managers.basic_rl_graph_manager import BasicRLGraphManager\nfrom rl_coach.graph_managers.graph_manager import ScheduleParameters\nfrom rl_coach.base_parameters import VisualizationParameters, TaskParameters, Frameworks\nfrom rl_coach.utils import short_dynamic_import\nfrom rl_coach.core_types import SelectedPhaseOnlyDumpFilter, MaxDumpFilter, RunPhase\nimport rl_coach.core_types\nfrom rl_coach import logger\nfrom rl_coach.logger import screen\nimport argparse\nimport copy\nimport logging\nimport os\nimport sys\nimport shutil\nimport glob\nimport re\n\n\nfrom .configuration_list import ConfigurationList\n\n\ntry:\n    from rl_coach.coach import CoachLauncher\nexcept ImportError:\n    raise RuntimeError(\n        ""Please upgrade to coach-0.11.0.  e.g. 388651196716.dkr.ecr.us-west-2.amazonaws.com/sagemaker-tensorflow-rl-beta:1.11.0-coach11-cpu-py3""\n    )\n\n\nscreen.set_use_colors(False)  # Simple text logging so it looks good in CloudWatch\n\n\nclass CoachConfigurationList(ConfigurationList):\n    """"""Helper Object for converting CLI arguments (or SageMaker hyperparameters) \n    into Coach configuration.\n    """"""\n\n    # Being security-paranoid and not instantiating any arbitrary string the customer passes in\n    ALLOWED_TYPES = {\n        ""Frames"": rl_coach.core_types.Frames,\n        ""EnvironmentSteps"": rl_coach.core_types.EnvironmentSteps,\n        ""EnvironmentEpisodes"": rl_coach.core_types.EnvironmentEpisodes,\n        ""TrainingSteps"": rl_coach.core_types.TrainingSteps,\n        ""Time"": rl_coach.core_types.Time,\n    }\n\n\nclass SageMakerCoachPresetLauncher(CoachLauncher):\n    """"""Base class for training RL tasks using RL-Coach.\n    Customers subclass this to define specific kinds of workloads, overriding these methods as needed.\n    """"""\n\n    def __init__(self):\n        super().__init__()\n        self.hyperparams = None\n\n    def get_config_args(self, parser: argparse.ArgumentParser) -> argparse.Namespace:\n        """"""Overrides the default CLI parsing.\n        Sets the configuration parameters for what a SageMaker run should do.\n        Note, this does not support the ""play"" mode.\n        """"""\n        # first, convert the parser to a Namespace object with all default values.\n        empty_arg_list = []\n        args, _ = parser.parse_known_args(args=empty_arg_list)\n\n        # Now fill in the args that we care about.\n        sagemaker_job_name = os.environ.get(""sagemaker_job_name"", ""sagemaker-experiment"")\n        args.experiment_name = logger.get_experiment_name(sagemaker_job_name)\n\n        # Override experiment_path used for outputs\n        args.experiment_path = ""/opt/ml/output/intermediate""\n        rl_coach.logger.experiment_path = ""/opt/ml/output/intermediate""  # for gifs\n\n        args.checkpoint_save_dir = ""/opt/ml/output/data/checkpoint""\n        args.checkpoint_save_secs = 10  # should avoid hardcoding\n        # onnx for deployment for mxnet (not tensorflow)\n        args.export_onnx_graph = os.getenv(""COACH_BACKEND"", ""tensorflow"") == ""mxnet""\n\n        args.no_summary = True\n\n        parser = self.sagemaker_argparser()\n        sage_args, unknown = parser.parse_known_args()\n        args.num_workers = sage_args.num_workers\n        args.framework = Frameworks[sage_args.framework.lower()]\n        args.preset = sage_args.RLCOACH_PRESET\n        # args.apply_stop_condition = True # uncomment for old coach behaviour\n\n        self.hyperparameters = CoachConfigurationList()\n        if len(unknown) % 2 == 1:\n            raise ValueError(""Odd number of command-line arguments specified. Key without value."")\n\n        for i in range(0, len(unknown), 2):\n            name = unknown[i]\n            if name.startswith(""--""):\n                name = name[2:]\n            else:\n                raise ValueError(""Unknown command-line argument %s"" % name)\n            val = unknown[i + 1]\n            self.map_hyperparameter(name, val)\n\n        return args\n\n    def map_hyperparameter(self, name, value):\n        """"""This is a good method to override where customers can specify custom shortcuts\n        for hyperparameters.  Default takes everything starting with ""rl."" and sends it\n        straight to the graph manager.\n        """"""\n        if name.startswith(""rl.""):\n            self.apply_hyperparameter(name, value)\n        else:\n            raise ValueError(""Unknown hyperparameter %s"" % name)\n\n    def apply_hyperparameter(self, name, value):\n        """"""Save this hyperparameter to be applied to the graph_manager object when\n        it\'s ready.\n        """"""\n        print(""Applying RL hyperparameter %s=%s"" % (name, value))\n        self.hyperparameters.store(name, value)\n\n    def default_preset_name(self):\n        """"""\n        Sub-classes will typically return a single hard-coded string.\n        """"""\n        try:\n            # TODO: remove this after converting all samples.\n            default_preset = self.DEFAULT_PRESET\n            screen.warning(\n                ""Deprecated configuration of default preset.  Please implement default_preset_name()""\n            )\n            return default_preset\n        except:\n            pass\n        raise NotImplementedError(\n            ""Sub-classes must specify the name of the default preset ""\n            + ""for this RL problem.  This will be the name of a python ""\n            + ""file (without .py) that defines a graph_manager variable""\n        )\n\n    def sagemaker_argparser(self) -> argparse.ArgumentParser:\n        """"""\n        Expose only the CLI arguments that make sense in the SageMaker context.\n        """"""\n        parser = argparse.ArgumentParser()\n\n        # Arguably this would be cleaner if we copied the config from the base class argparser.\n        parser.add_argument(\n            ""-n"",\n            ""--num_workers"",\n            help=""(int) Number of workers for multi-process based agents, e.g. A3C"",\n            default=1,\n            type=int,\n        )\n        parser.add_argument(\n            ""-f"",\n            ""--framework"",\n            help=""(string) Neural network framework. Available values: tensorflow, mxnet"",\n            default=os.getenv(""COACH_BACKEND"", ""tensorflow""),\n            type=str,\n        )\n        parser.add_argument(\n            ""-p"",\n            ""--RLCOACH_PRESET"",\n            help=""(string) Name of the file with the RLCoach preset"",\n            default=self.default_preset_name(),\n            type=str,\n        )\n        parser.add_argument(\n            ""--save_model"",\n            help=""(int) Flag to save model artifact after training finish"",\n            default=0,\n            type=int,\n        )\n        return parser\n\n    def path_of_main_launcher(self):\n        """"""\n        A bit of python magic to find the path of the file that launched the current process.\n        """"""\n        main_mod = sys.modules[""__main__""]\n        try:\n            launcher_file = os.path.abspath(sys.modules[""__main__""].__file__)\n            return os.path.dirname(launcher_file)\n        except AttributeError:\n            # If __main__.__file__ is missing, then we\'re probably in an interactive python shell\n            return os.getcwd()\n\n    def preset_from_name(self, preset_name):\n        preset_path = self.path_of_main_launcher()\n        print(""Loading preset %s from %s"" % (preset_name, preset_path))\n        preset_path = os.path.join(self.path_of_main_launcher(), preset_name) + "".py:graph_manager""\n        graph_manager = short_dynamic_import(preset_path, ignore_module_case=True)\n        return graph_manager\n\n    def get_graph_manager_from_args(self, args):\n        # First get the graph manager for the customer-specified (or default) preset\n        graph_manager = self.preset_from_name(args.preset)\n        # Now override whatever config is specified in hyperparameters.\n        self.hyperparameters.apply_subset(graph_manager, ""rl."")\n        # Set framework\n        # Note: Some graph managers (e.g. HAC preset) create multiple agents and the attribute is called agents_params\n        if hasattr(graph_manager, ""agent_params""):\n            for network_parameters in graph_manager.agent_params.network_wrappers.values():\n                network_parameters.framework = args.framework\n        elif hasattr(graph_manager, ""agents_params""):\n            for ap in graph_manager.agents_params:\n                for network_parameters in ap.network_wrappers.values():\n                    network_parameters.framework = args.framework\n        return graph_manager\n\n    def _save_tf_model(self):\n        import tensorflow as tf\n\n        ckpt_dir = ""/opt/ml/output/data/checkpoint""\n        model_dir = ""/opt/ml/model""\n\n        # Re-Initialize from the checkpoint so that you will have the latest models up.\n        tf.train.init_from_checkpoint(\n            ckpt_dir, {""main_level/agent/online/network_0/"": ""main_level/agent/online/network_0""}\n        )\n        tf.train.init_from_checkpoint(\n            ckpt_dir, {""main_level/agent/online/network_1/"": ""main_level/agent/online/network_1""}\n        )\n\n        # Create a new session with a new tf graph.\n        sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n        sess.run(tf.global_variables_initializer())  # initialize the checkpoint.\n\n        # This is the node that will accept the input.\n        input_nodes = tf.get_default_graph().get_tensor_by_name(\n            ""main_level/agent/main/online/"" + ""network_0/observation/observation:0""\n        )\n        # This is the node that will produce the output.\n        output_nodes = tf.get_default_graph().get_operation_by_name(\n            ""main_level/agent/main/online/"" + ""network_1/ppo_head_0/policy""\n        )\n        # Save the model as a servable model.\n        tf.saved_model.simple_save(\n            session=sess,\n            export_dir=""model"",\n            inputs={""observation"": input_nodes},\n            outputs={""policy"": output_nodes.outputs[0]},\n        )\n        # Move to the appropriate folder. Don\'t mind the directory, this just works.\n        # rl-cart-pole is the name of the model. Remember it.\n        shutil.move(""model/"", model_dir + ""/model/tf-model/00000001/"")\n        # EASE will pick it up and upload to the right path.\n        print(""Success"")\n\n    def _save_onnx_model(self):\n        ckpt_dir = ""/opt/ml/output/data/checkpoint""\n        model_dir = ""/opt/ml/model""\n        # find latest onnx file\n        # currently done by name, expected to be changed in future release of coach.\n        glob_pattern = os.path.join(ckpt_dir, ""*.onnx"")\n        onnx_files = [file for file in glob.iglob(glob_pattern, recursive=True)]\n        if len(onnx_files) > 0:\n            extract_step = lambda string: int(\n                re.search(""/(\\d*)_Step.*"", string, re.IGNORECASE).group(1)\n            )\n            onnx_files.sort(key=extract_step)\n            latest_onnx_file = onnx_files[-1]\n            # move to model directory\n            filepath_from = os.path.abspath(latest_onnx_file)\n            filepath_to = os.path.join(model_dir, ""model.onnx"")\n            shutil.move(filepath_from, filepath_to)\n        else:\n            screen.warning(""No ONNX files found in {}"".format(ckpt_dir))\n\n    @classmethod\n    def train_main(cls):\n        """"""Entrypoint for training.  \n        Parses command-line arguments and starts training.\n        """"""\n        trainer = cls()\n        trainer.launch()\n\n        # Create model artifact for model.tar.gz\n        parser = trainer.sagemaker_argparser()\n        sage_args, unknown = parser.parse_known_args()\n        if sage_args.save_model == 1:\n            backend = os.getenv(""COACH_BACKEND"", ""tensorflow"")\n            if backend == ""tensorflow"":\n                trainer._save_tf_model()\n            if backend == ""mxnet"":\n                trainer._save_onnx_model()\n\n\nclass SageMakerCoachLauncher(SageMakerCoachPresetLauncher):\n    """"""\n    Older version of the launcher that doesn\'t use preset, but instead effectively has a single preset built in.\n    """"""\n\n    def __init__(self):\n        super().__init__()\n        screen.warning(""DEPRECATION WARNING: Please switch to SageMakerCoachPresetLauncher"")\n        # TODO: Remove this whole class when nobody\'s using it any more.\n\n    def define_environment(self):\n        return NotImplementedEror(\n            ""Sub-class must define environment e.g. GymVectorEnvironment(level=\'your_module:YourClass\')""\n        )\n\n    def get_graph_manager_from_args(self, args):\n        """"""Returns the GraphManager object for coach to use to train by calling improve()\n        """"""\n        # NOTE: TaskParameters are not configurable at this time.\n\n        # Visualization\n        vis_params = VisualizationParameters()\n        self.config_visualization(vis_params)\n        self.hyperparameters.apply_subset(vis_params, ""vis_params."")\n\n        # Schedule\n        schedule_params = ScheduleParameters()\n        self.config_schedule(schedule_params)\n        self.hyperparameters.apply_subset(schedule_params, ""schedule_params."")\n\n        # Agent\n        agent_params = self.define_agent()\n        self.hyperparameters.apply_subset(agent_params, ""agent_params."")\n\n        # Environment\n        env_params = self.define_environment()\n        self.hyperparameters.apply_subset(env_params, ""env_params."")\n\n        graph_manager = BasicRLGraphManager(\n            agent_params=agent_params,\n            env_params=env_params,\n            schedule_params=schedule_params,\n            vis_params=vis_params,\n        )\n\n        return graph_manager\n\n    def config_schedule(self, schedule_params):\n        pass\n\n    def define_agent(self):\n        raise NotImplementedError(\n            ""Subclass must create define_agent() method which returns an AgentParameters object. e.g.\\n""\n            ""   return rl_coach.agents.dqn_agent.DQNAgentParameters()""\n        )\n\n    def config_visualization(self, vis_params):\n        vis_params.dump_gifs = True\n        vis_params.video_dump_methods = [\n            SelectedPhaseOnlyDumpFilter(RunPhase.TEST),\n            MaxDumpFilter(),\n        ]\n        vis_params.print_networks_summary = True\n        return vis_params\n'"
tests/data/sagemaker_rl/configuration_list.py,0,"b'import logging\n\n\nclass ConfigurationList(object):\n    """"""Helper Object for converting CLI arguments (or SageMaker hyperparameters) \n    into Coach configuration.\n    """"""\n\n    def __init__(self):\n        """"""Args:\n            - arg_list [list]: list of arguments on the command-line like [key1, value1, key2, value2, ...]\n            - prefix [str]: Prefix for every key that must be present, e.g. ""--"" for common command-line args\n        """"""\n        self.hp_dict = {}\n\n    def store(self, name, value):\n        """"""Store a key/value hyperparameter combination\n        """"""\n        self.hp_dict[name] = value\n\n    def apply_subset(self, config_object, prefix):\n        """"""Merges configured hyperparameters in the params dict into the config_object.\n        Recognized arguments are consumed out of self.hp_dict\n\n        Args:\n            config_object (obj):  will be something like a Coach TaskParameters object, where we\'re setting properties\n            params (dict): comes from the command line (and thus customer-specified hyperparameters)\n            prefix (str): string prefix for which items in params to use.  (e.g. ""rl.task_params."")\n        """"""\n        # Materialize a copy of the dict as tuples so we can modify the original dict as we go.\n        for key, val in list(self.hp_dict.items()):\n            if key.startswith(prefix):\n                logging.debug(""Configuring %s with %s=%s"" % (prefix, key, val))\n                subkey = key[len(prefix) :]\n                msg = ""%s%s=%s"" % (prefix, subkey, val)\n                try:\n                    self._set_rl_property_value(config_object, subkey, val, prefix)\n                except:\n                    print(""Failure while applying hyperparameter %s"" % msg)\n                    raise\n                del self.hp_dict[key]\n\n    def _set_rl_property_value(self, obj, key, val, path=""""):\n        """"""Sets a property on obj to val, or to a sub-object within obj if key looks like ""foo.bar""\n        """"""\n        if key.find(""."") >= 0:\n            top_key, sub_keys = key_list = key.split(""."", 1)\n            if top_key.startswith(""__""):\n                raise ValueError(""Attempting to set unsafe property name %s"" % top_key)\n            if isinstance(obj, dict):\n                sub_obj = obj[top_key]\n            else:\n                sub_obj = obj.__dict__[top_key]\n            # Recurse\n            return self._set_rl_property_value(sub_obj, sub_keys, val, ""%s.%s"" % (path, top_key))\n        else:\n            key, val = self._parse_type(key, val)\n            if key.startswith(""__""):\n                raise ValueError(""Attempting to set unsafe property name %s"" % key)\n            if isinstance(obj, dict):\n                obj[key] = val\n            else:\n                obj.__dict__[key] = val\n\n    def _autotype(self, val):\n        """"""Converts string to an int or float as possible.\n        """"""\n        try:\n            return int(val)\n        except ValueError:\n            pass\n        try:\n            return float(val)\n        except ValueError:\n            pass\n        return val\n\n    # Being security-paranoid and not instantiating any arbitrary string the customer passes in\n    ALLOWED_TYPES = {}\n\n    def _parse_type(self, key, val):\n        """"""Converts the val to an appropriately typed Python object.\n        Automatically detects ints and floats when possible.\n        If the key takes the form ""foo:bar"" then it looks in ALLOWED_TYPES\n        for an entry of bar, and instantiates one of those objects, passing\n        val to the constructor.  So if key=""foo:EnvironmentSteps"" then \n        """"""\n        val = self._autotype(val)\n        if key.find("":"") > 0:\n            key, obj_type = key.split("":"", 1)\n            cls = self.ALLOWED_TYPES.get(obj_type)\n            if not cls:\n                raise ValueError(\n                    ""Unrecognized object type %s.  Allowed values are %s""\n                    % (obj_type, self.ALLOWED_TYPES.keys())\n                )\n            val = cls(val)\n        return key, val\n'"
tests/data/sklearn_mnist/__init__.py,0,b''
tests/data/sklearn_mnist/failure_script.py,0,"b'if __name__ == ""__main__"":\n    """"""For use with integration tests expecting failures.""""""\n    raise Exception(""This failure is expected."")\n'"
tests/data/sklearn_mnist/mnist.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import print_function, absolute_import\n\nimport argparse\nimport numpy as np\nimport os\n\nfrom sklearn import svm\nfrom sklearn.externals import joblib\n\n\ndef preprocess_mnist(raw, withlabel, ndim, scale, image_dtype, label_dtype, rgb_format):\n    images = raw[""x""]\n    if ndim == 2:\n        images = images.reshape(-1, 28, 28)\n    elif ndim == 3:\n        images = images.reshape(-1, 1, 28, 28)\n        if rgb_format:\n            images = np.broadcast_to(images, (len(images), 3) + images.shape[2:])\n\n    elif ndim != 1:\n        raise ValueError(""invalid ndim for MNIST dataset"")\n    images = images.astype(image_dtype)\n    images *= scale / 255.0\n\n    if withlabel:\n        labels = raw[""y""].astype(label_dtype)\n        return images, labels\n    return images\n\n\nif __name__ == ""__main__"":\n    parser = argparse.ArgumentParser()\n\n    # Data and model checkpoints directories\n    parser.add_argument(""--epochs"", type=int, default=-1)\n    parser.add_argument(""--output-data-dir"", type=str, default=os.environ[""SM_OUTPUT_DATA_DIR""])\n    parser.add_argument(""--model-dir"", type=str, default=os.environ[""SM_MODEL_DIR""])\n    parser.add_argument(""--train"", type=str, default=os.environ[""SM_CHANNEL_TRAIN""])\n    parser.add_argument(""--test"", type=str, default=os.environ[""SM_CHANNEL_TEST""])\n\n    args = parser.parse_args()\n\n    train_file = np.load(os.path.join(args.train, ""train.npz""))\n    test_file = np.load(os.path.join(args.test, ""test.npz""))\n\n    preprocess_mnist_options = {\n        ""withlabel"": True,\n        ""ndim"": 1,\n        ""scale"": 1.0,\n        ""image_dtype"": np.float32,\n        ""label_dtype"": np.int32,\n        ""rgb_format"": False,\n    }\n\n    # Preprocess MNIST data\n    train_images, train_labels = preprocess_mnist(train_file, **preprocess_mnist_options)\n    test_images, test_labels = preprocess_mnist(test_file, **preprocess_mnist_options)\n\n    # Set up a Support Vector Machine classifier to predict digit from images\n    clf = svm.SVC(gamma=0.001, C=100.0, max_iter=args.epochs)\n\n    # Fit the SVM classifier with the images and the corresponding labels\n    clf.fit(train_images, train_labels)\n\n    # Print the coefficients of the trained classifier, and save the coefficients\n    joblib.dump(clf, os.path.join(args.model_dir, ""model.joblib""))\n\n\ndef model_fn(model_dir):\n    clf = joblib.load(os.path.join(model_dir, ""model.joblib""))\n    return clf\n'"
tests/data/tensorflow_mnist/mnist.py,33,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import, division, print_function\n\nimport argparse\nimport json\nimport numpy as np\nimport os\nimport tensorflow as tf\n\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.DEBUG)\n\n\ndef cnn_model_fn(features, labels, mode):\n    """"""Model function for CNN.""""""\n    # Input Layer\n    # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n    # MNIST images are 28x28 pixels, and have one color channel\n    input_layer = tf.reshape(features[""x""], [-1, 28, 28, 1])\n\n    # Convolutional Layer #1\n    # Computes 32 features using a 5x5 filter with ReLU activation.\n    # Padding is added to preserve width and height.\n    # Input Tensor Shape: [batch_size, 28, 28, 1]\n    # Output Tensor Shape: [batch_size, 28, 28, 32]\n    conv1 = tf.compat.v1.layers.conv2d(\n        inputs=input_layer, filters=32, kernel_size=[5, 5], padding=""same"", activation=tf.nn.relu\n    )\n\n    # Pooling Layer #1\n    # First max pooling layer with a 2x2 filter and stride of 2\n    # Input Tensor Shape: [batch_size, 28, 28, 32]\n    # Output Tensor Shape: [batch_size, 14, 14, 32]\n    pool1 = tf.compat.v1.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n\n    # Convolutional Layer #2\n    # Computes 64 features using a 5x5 filter.\n    # Padding is added to preserve width and height.\n    # Input Tensor Shape: [batch_size, 14, 14, 32]\n    # Output Tensor Shape: [batch_size, 14, 14, 64]\n    conv2 = tf.compat.v1.layers.conv2d(\n        inputs=pool1, filters=64, kernel_size=[5, 5], padding=""same"", activation=tf.nn.relu\n    )\n\n    # Pooling Layer #2\n    # Second max pooling layer with a 2x2 filter and stride of 2\n    # Input Tensor Shape: [batch_size, 14, 14, 64]\n    # Output Tensor Shape: [batch_size, 7, 7, 64]\n    pool2 = tf.compat.v1.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n\n    # Flatten tensor into a batch of vectors\n    # Input Tensor Shape: [batch_size, 7, 7, 64]\n    # Output Tensor Shape: [batch_size, 7 * 7 * 64]\n    pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n\n    # Dense Layer\n    # Densely connected layer with 1024 neurons\n    # Input Tensor Shape: [batch_size, 7 * 7 * 64]\n    # Output Tensor Shape: [batch_size, 1024]\n    dense = tf.compat.v1.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n\n    # Add dropout operation; 0.6 probability that element will be kept\n    dropout = tf.compat.v1.layers.dropout(\n        inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN\n    )\n\n    # Logits layer\n    # Input Tensor Shape: [batch_size, 1024]\n    # Output Tensor Shape: [batch_size, 10]\n    logits = tf.compat.v1.layers.dense(inputs=dropout, units=10)\n\n    predictions = {\n        # Generate predictions (for PREDICT and EVAL mode)\n        ""classes"": tf.argmax(input=logits, axis=1),\n        # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n        # `logging_hook`.\n        ""probabilities"": tf.nn.softmax(logits, name=""softmax_tensor""),\n    }\n    if mode == tf.estimator.ModeKeys.PREDICT:\n        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n\n    # Calculate Loss (for both TRAIN and EVAL modes)\n    loss = tf.compat.v1.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n\n    # Configure the Training Op (for TRAIN mode)\n    if mode == tf.estimator.ModeKeys.TRAIN:\n        optimizer = tf.compat.v1.train.GradientDescentOptimizer(learning_rate=0.001)\n        train_op = optimizer.minimize(loss=loss, global_step=tf.compat.v1.train.get_global_step())\n        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n\n    # Add evaluation metrics (for EVAL mode)\n    eval_metric_ops = {\n        ""accuracy"": tf.compat.v1.metrics.accuracy(labels=labels, predictions=predictions[""classes""])\n    }\n    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n\n\ndef _load_training_data(base_dir):\n    x_train = np.load(os.path.join(base_dir, ""train_data.npy""))\n    y_train = np.load(os.path.join(base_dir, ""train_labels.npy""))\n    return x_train, y_train\n\n\ndef _load_testing_data(base_dir):\n    x_test = np.load(os.path.join(base_dir, ""eval_data.npy""))\n    y_test = np.load(os.path.join(base_dir, ""eval_labels.npy""))\n    return x_test, y_test\n\n\ndef _parse_args():\n\n    parser = argparse.ArgumentParser()\n\n    # hyperparameters sent by the client are passed as command-line arguments to the script.\n    parser.add_argument(""--epochs"", type=int, default=1)\n    # Data, model, and output directories\n    parser.add_argument(""--output-data-dir"", type=str, default=os.environ.get(""SM_OUTPUT_DATA_DIR""))\n    parser.add_argument(""--model_dir"", type=str)\n    parser.add_argument(""--train"", type=str, default=os.environ.get(""SM_CHANNEL_TRAINING""))\n    parser.add_argument(""--hosts"", type=list, default=json.loads(os.environ.get(""SM_HOSTS"")))\n    parser.add_argument(""--current-host"", type=str, default=os.environ.get(""SM_CURRENT_HOST""))\n\n    return parser.parse_known_args()\n\n\ndef serving_input_fn():\n    inputs = {""x"": tf.compat.v1.placeholder(tf.float32, [None, 784])}\n    return tf.estimator.export.ServingInputReceiver(inputs, inputs)\n\n\nif __name__ == ""__main__"":\n    args, unknown = _parse_args()\n\n    if args.model_dir.startswith(""s3://""):\n        os.environ[""S3_REGION""] = ""us-west-2""\n        os.environ[""TF_CPP_MIN_LOG_LEVEL""] = ""1""\n        os.environ[""S3_USE_HTTPS""] = ""1""\n\n    train_data, train_labels = _load_training_data(args.train)\n    eval_data, eval_labels = _load_testing_data(args.train)\n\n    # Create the Estimator\n    mnist_classifier = tf.estimator.Estimator(model_fn=cnn_model_fn, model_dir=args.model_dir)\n\n    # Set up logging for predictions\n    # Log the values in the ""Softmax"" tensor with label ""probabilities""\n    tensors_to_log = {""probabilities"": ""softmax_tensor""}\n    logging_hook = tf.estimator.LoggingTensorHook(tensors=tensors_to_log, every_n_iter=50)\n\n    # Train the model\n    train_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(\n        x={""x"": train_data}, y=train_labels, batch_size=50, num_epochs=None, shuffle=True\n    )\n\n    # Evaluate the model and print results\n    eval_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(\n        x={""x"": eval_data}, y=eval_labels, num_epochs=1, shuffle=False\n    )\n\n    train_spec = tf.estimator.TrainSpec(train_input_fn, max_steps=1000)\n    eval_spec = tf.estimator.EvalSpec(eval_input_fn)\n    tf.estimator.train_and_evaluate(mnist_classifier, train_spec, eval_spec)\n\n    if args.current_host == args.hosts[0]:\n        mnist_classifier.export_saved_model(""/opt/ml/model"", serving_input_fn)\n'"
tests/data/upload_data_tests/file1.py,0,"b'""""""\r\nThis is a file used in the upload_data tests in the test_session.py unit tests\r\n""""""\r\n'"
tests/data/upload_data_tests/file2.py,0,"b'""""""\r\nThis is a file used in the upload_data tests in the test_session.py unit tests\r\n""""""\r\n'"
tests/unit/sagemaker/__init__.py,0,b''
src/sagemaker/tensorflow/tensorflow_serving/__init__.py,0,b''
tests/data/multimodel/container/dockerd-entrypoint.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport sys\n\nimport shlex\nimport subprocess\nfrom retrying import retry\nfrom sagemaker_inference import model_server\nfrom subprocess import CalledProcessError\n\n\ndef _retry_if_error(exception):\n    return isinstance(exception, CalledProcessError or OSError)\n\n\n@retry(stop_max_delay=1000 * 50, retry_on_exception=_retry_if_error)\ndef _start_mms():\n    # by default the number of workers per model is 1, but we can configure it through the\n    # environment variable below if desired.\n    # os.environ[\'SAGEMAKER_MODEL_SERVER_WORKERS\'] = \'2\'\n    model_server.start_model_server(handler_service=""/home/model-server/model_handler.py:handle"")\n\n\ndef main():\n    if sys.argv[1] == ""serve"":\n        _start_mms()\n    else:\n        subprocess.check_call(shlex.split("" "".join(sys.argv[1:])))\n\n    # prevent docker exit\n    subprocess.call([""tail"", ""-f"", ""/dev/null""])\n\n\nmain()\n'"
tests/data/multimodel/container/model_handler.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\n""""""\nModelHandler defines a dummy base model handler.\nReturns invoked model name.\n""""""\nimport logging\n\n\nclass ModelHandler(object):\n    """"""\n    A base Model handler implementation.\n    """"""\n\n    def __init__(self):\n        self.error = None\n        self._context = None\n        self.initialized = False\n\n    def initialize(self, context):\n        """"""\n        Initialize model. This will be called during model loading time\n\n        :param context: Initial context contains model server system properties.\n        :return:\n        """"""\n        self._context = context\n        self.initialized = True\n\n    def handle(self, data, context):\n        """"""\n        Custom service entry point function.\n\n        :param data: list of objects, raw input from request\n        :param context: model server context\n        :return: list of target model to send back to client\n        """"""\n        self.error = None  # reset earlier errors\n\n        try:\n            target_model = context.get_request_header(0, ""X-Amzn-SageMaker-Target-Model"")\n            return [""Invoked model: {}"".format(target_model)]\n        except Exception as e:\n            logging.error(e, exc_info=True)\n            request_processor = context.request_processor\n            request_processor.report_status(500, ""Unknown inference error"")\n            return str(e)\n'"
tests/data/tfs/tfs-test-entrypoint-and-dependencies/dependency.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n'"
tests/data/tfs/tfs-test-entrypoint-and-dependencies/inference.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport json\n\nimport dependency\n\n\ndef input_handler(data, context):\n    data = json.loads(data.read().decode(""utf-8""))\n    new_values = [x + 1 for x in data[""instances""]]\n    dumps = json.dumps({""instances"": new_values})\n    return dumps\n\n\ndef output_handler(data, context):\n    response_content_type = context.accept_header\n    prediction = data.content\n    return prediction, response_content_type\n'"
tests/data/tfs/tfs-test-entrypoint-with-handler/inference.py,0,"b'# Copyright 2018-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport json\n\n\ndef input_handler(data, context):\n    data = json.loads(data.read().decode(""utf-8""))\n    new_values = [x + 1 for x in data[""instances""]]\n    dumps = json.dumps({""instances"": new_values})\n    return dumps\n\n\ndef output_handler(data, context):\n    response_content_type = context.accept_header\n    prediction = data.content\n    return prediction, response_content_type\n'"
tests/data/tfs/tfs-test-entrypoint-with-handler/training.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\n\n""""""Exports a toy TensorFlow model.\nExports a TensorFlow model to /opt/ml/model/\nThis graph calculates,\n  y = a*x + b\nwhere a and b are variables with a=0.5 and b=2.\n""""""\nimport shutil\n\n\ndef save_model():\n    shutil.copytree(""/opt/ml/code/123"", ""/opt/ml/model/123"")\n\n\nif __name__ == ""__main__"":\n    save_model()\n'"
tests/data/upload_data_tests/nested_dir/file3.py,0,"b'""""""\r\nThis is a file used in the upload_data tests in the test_session.py unit tests\r\n""""""\r\n'"
tests/data/upload_data_tests/nested_dir/file4.py,0,"b'""""""\r\nThis is a file used in the upload_data tests in the test_session.py unit tests\r\n""""""\r\n'"
tests/unit/sagemaker/automl/test_auto_ml.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport pytest\nfrom mock import Mock, patch\nfrom sagemaker import AutoML, AutoMLJob, AutoMLInput, CandidateEstimator\nfrom sagemaker.predictor import RealTimePredictor\n\nMODEL_DATA = ""s3://bucket/model.tar.gz""\nMODEL_IMAGE = ""mi""\nENTRY_POINT = ""blah.py""\n\nTIMESTAMP = ""2017-11-06-14:14:15.671""\nBUCKET_NAME = ""mybucket""\nINSTANCE_COUNT = 1\nINSTANCE_TYPE = ""ml.c5.2xlarge""\nRESOURCE_POOLS = [{""InstanceType"": INSTANCE_TYPE, ""PoolSize"": INSTANCE_COUNT}]\nROLE = ""DummyRole""\nTARGET_ATTRIBUTE_NAME = ""target""\nREGION = ""us-west-2""\nDEFAULT_S3_INPUT_DATA = ""s3://{}/data"".format(BUCKET_NAME)\nDEFAULT_OUTPUT_PATH = ""s3://{}/"".format(BUCKET_NAME)\nLOCAL_DATA_PATH = ""file://data""\nDEFAULT_MAX_CANDIDATES = None\nDEFAULT_JOB_NAME = ""automl-{}"".format(TIMESTAMP)\n\nJOB_NAME = ""default-job-name""\nJOB_NAME_2 = ""banana-auto-ml-job""\nVOLUME_KMS_KEY = ""volume-kms-key-id-string""\nOUTPUT_KMS_KEY = ""output-kms-key-id-string""\nOUTPUT_PATH = ""s3://my_other_bucket/""\nBASE_JOB_NAME = ""banana""\nPROBLEM_TYPE = ""BinaryClassification""\nBLACKLISTED_ALGORITHM = [""xgboost""]\nMAX_CANDIDATES = 10\nMAX_RUNTIME_PER_TRAINING_JOB = 3600\nTOTAL_JOB_RUNTIME = 36000\nTARGET_OBJECTIVE = ""0.01""\nJOB_OBJECTIVE = {""fake job objective""}\nTAGS = [{""Name"": ""some-tag"", ""Value"": ""value-for-tag""}]\nVPC_CONFIG = {""SecurityGroupIds"": [""group""], ""Subnets"": [""subnet""]}\nCOMPRESSION_TYPE = ""Gzip""\nENCRYPT_INTER_CONTAINER_TRAFFIC = False\nGENERATE_CANDIDATE_DEFINITIONS_ONLY = False\nBEST_CANDIDATE = {""best-candidate"": ""best-trial""}\nBEST_CANDIDATE_2 = {""best-candidate"": ""best-trial-2""}\nAUTO_ML_DESC = {""AutoMLJobName"": JOB_NAME, ""BestCandidate"": BEST_CANDIDATE}\nAUTO_ML_DESC_2 = {""AutoMLJobName"": JOB_NAME_2, ""BestCandidate"": BEST_CANDIDATE_2}\n\nINFERENCE_CONTAINERS = [\n    {\n        ""Environment"": {""SAGEMAKER_PROGRAM"": ""sagemaker_serve""},\n        ""Image"": ""account.dkr.ecr.us-west-2.amazonaws.com/sagemaker-auto-ml-data-processing:1.0-cpu-py3"",\n        ""ModelDataUrl"": ""s3://sagemaker-us-west-2-account/sagemaker-auto-ml-gamma/data-processing/output"",\n    },\n    {\n        ""Environment"": {""MAX_CONTENT_LENGTH"": ""20000000""},\n        ""Image"": ""account.dkr.ecr.us-west-2.amazonaws.com/sagemaker-auto-ml-training:1.0-cpu-py3"",\n        ""ModelDataUrl"": ""s3://sagemaker-us-west-2-account/sagemaker-auto-ml-gamma/training/output"",\n    },\n    {\n        ""Environment"": {""INVERSE_LABEL_TRANSFORM"": ""1""},\n        ""Image"": ""account.dkr.ecr.us-west-2.amazonaws.com/sagemaker-auto-ml-transform:1.0-cpu-py3"",\n        ""ModelDataUrl"": ""s3://sagemaker-us-west-2-account/sagemaker-auto-ml-gamma/transform/output"",\n    },\n]\n\nCANDIDATE_STEPS = [\n    {\n        ""CandidateStepName"": ""training-job/sagemaker-auto-ml-gamma/data-processing"",\n        ""CandidateStepType"": ""AWS::Sagemaker::TrainingJob"",\n    },\n    {\n        ""CandidateStepName"": ""transform-job/sagemaker-auto-ml-gamma/transform"",\n        ""CandidateStepType"": ""AWS::Sagemaker::TransformJob"",\n    },\n    {\n        ""CandidateStepName"": ""training-job/sagemaker-auto-ml-gamma/training"",\n        ""CandidateStepType"": ""AWS::Sagemaker::TrainingJob"",\n    },\n]\n\nCANDIDATE_DICT = {\n    ""CandidateName"": ""candidate_mock"",\n    ""InferenceContainers"": INFERENCE_CONTAINERS,\n    ""CandidateSteps"": CANDIDATE_STEPS,\n}\n\nTRAINING_JOB = {\n    ""AlgorithmSpecification"": {\n        ""AlgorithmName"": ""string"",\n        ""TrainingImage"": ""string"",\n        ""TrainingInputMode"": ""string"",\n    },\n    ""CheckpointConfig"": {""LocalPath"": ""string"", ""S3Uri"": ""string""},\n    ""EnableInterContainerTrafficEncryption"": False,\n    ""EnableManagedSpotTraining"": False,\n    ""EnableNetworkIsolation"": False,\n    ""InputDataConfig"": [\n        {""DataSource"": {""S3DataSource"": {""S3DataType"": ""string"", ""S3Uri"": ""string""}}}\n    ],\n    ""OutputDataConfig"": {""KmsKeyId"": ""string"", ""S3OutputPath"": ""string""},\n    ""ResourceConfig"": {},\n    ""RoleArn"": ""string"",\n    ""StoppingCondition"": {},\n    ""TrainingJobArn"": ""string"",\n    ""TrainingJobName"": ""string"",\n    ""TrainingJobStatus"": ""string"",\n    ""VpcConfig"": {},\n}\n\nTRANSFORM_JOB = {\n    ""BatchStrategy"": ""string"",\n    ""DataProcessing"": {},\n    ""Environment"": {""string"": ""string""},\n    ""FailureReason"": ""string"",\n    ""LabelingJobArn"": ""string"",\n    ""MaxConcurrentTransforms"": 1,\n    ""MaxPayloadInMB"": 2000,\n    ""ModelName"": ""string"",\n    ""TransformInput"": {""DataSource"": {""S3DataSource"": {""S3DataType"": ""string"", ""S3Uri"": ""string""}}},\n    ""TransformJobStatus"": ""string"",\n    ""TransformJobArn"": ""string"",\n    ""TransformJobName"": ""string"",\n    ""TransformOutput"": {},\n    ""TransformResources"": {},\n}\n\n\ndef describe_auto_ml_job_mock(job_name=None):\n    if job_name is None or job_name == JOB_NAME:\n        return AUTO_ML_DESC\n    elif job_name == JOB_NAME_2:\n        return AUTO_ML_DESC_2\n\n\n@pytest.fixture()\ndef sagemaker_session():\n    boto_mock = Mock(name=""boto_session"", region_name=REGION)\n    sms = Mock(\n        name=""sagemaker_session"",\n        boto_session=boto_mock,\n        boto_region_name=REGION,\n        config=None,\n        local_mode=False,\n    )\n    sms.default_bucket = Mock(name=""default_bucket"", return_value=BUCKET_NAME)\n    sms.upload_data = Mock(name=""upload_data"", return_value=DEFAULT_S3_INPUT_DATA)\n    sms.expand_role = Mock(name=""expand_role"", return_value=ROLE)\n    sms.describe_auto_ml_job = Mock(\n        name=""describe_auto_ml_job"", side_effect=describe_auto_ml_job_mock\n    )\n    sms.sagemaker_client.describe_training_job = Mock(\n        name=""describe_training_job"", return_value=TRAINING_JOB\n    )\n    sms.sagemaker_client.describe_transform_job = Mock(\n        name=""describe_transform_job"", return_value=TRANSFORM_JOB\n    )\n    sms.list_candidates = Mock(name=""list_candidates"", return_value={""Candidates"": []})\n\n    return sms\n\n\n@pytest.fixture()\ndef candidate_mock(sagemaker_session):\n    candidate = Mock(\n        name=""candidate_mock"",\n        containers=INFERENCE_CONTAINERS,\n        steps=CANDIDATE_STEPS,\n        sagemaker_session=sagemaker_session,\n    )\n    return candidate\n\n\ndef test_auto_ml_default_channel_name(sagemaker_session):\n    auto_ml = AutoML(\n        role=ROLE, target_attribute_name=TARGET_ATTRIBUTE_NAME, sagemaker_session=sagemaker_session\n    )\n    inputs = DEFAULT_S3_INPUT_DATA\n    AutoMLJob.start_new(auto_ml, inputs)\n    sagemaker_session.auto_ml.assert_called_once()\n    _, args = sagemaker_session.auto_ml.call_args\n    assert args[""input_config""] == [\n        {\n            ""DataSource"": {\n                ""S3DataSource"": {""S3DataType"": ""S3Prefix"", ""S3Uri"": DEFAULT_S3_INPUT_DATA}\n            },\n            ""TargetAttributeName"": TARGET_ATTRIBUTE_NAME,\n        }\n    ]\n\n\ndef test_auto_ml_invalid_input_data_format(sagemaker_session):\n    auto_ml = AutoML(\n        role=ROLE, target_attribute_name=TARGET_ATTRIBUTE_NAME, sagemaker_session=sagemaker_session\n    )\n    inputs = {}\n\n    expected_error_msg = ""Cannot format input {}. Expecting one of str or list of strings.""\n    with pytest.raises(ValueError, message=expected_error_msg.format(inputs)):\n        AutoMLJob.start_new(auto_ml, inputs)\n    sagemaker_session.auto_ml.assert_not_called()\n\n\ndef test_auto_ml_only_one_of_problem_type_and_job_objective_provided(sagemaker_session):\n    with pytest.raises(\n        ValueError,\n        message=""One of problem type and objective metric provided. ""\n        ""Either both of them should be provided or none of ""\n        ""them should be provided."",\n    ):\n        AutoML(\n            role=ROLE,\n            target_attribute_name=TARGET_ATTRIBUTE_NAME,\n            sagemaker_session=sagemaker_session,\n            problem_type=PROBLEM_TYPE,\n        )\n\n\ndef test_auto_ml_additional_optional_params(sagemaker_session):\n    auto_ml = AutoML(\n        role=ROLE,\n        target_attribute_name=TARGET_ATTRIBUTE_NAME,\n        sagemaker_session=sagemaker_session,\n        volume_kms_key=VOLUME_KMS_KEY,\n        vpc_config=VPC_CONFIG,\n        encrypt_inter_container_traffic=ENCRYPT_INTER_CONTAINER_TRAFFIC,\n        compression_type=COMPRESSION_TYPE,\n        output_kms_key=OUTPUT_KMS_KEY,\n        output_path=OUTPUT_PATH,\n        problem_type=PROBLEM_TYPE,\n        max_candidates=MAX_CANDIDATES,\n        max_runtime_per_training_job_in_seconds=MAX_RUNTIME_PER_TRAINING_JOB,\n        total_job_runtime_in_seconds=TOTAL_JOB_RUNTIME,\n        job_objective=JOB_OBJECTIVE,\n        generate_candidate_definitions_only=GENERATE_CANDIDATE_DEFINITIONS_ONLY,\n        tags=TAGS,\n    )\n    inputs = DEFAULT_S3_INPUT_DATA\n    auto_ml.fit(inputs, job_name=JOB_NAME)\n    sagemaker_session.auto_ml.assert_called_once()\n    _, args = sagemaker_session.auto_ml.call_args\n\n    assert args == {\n        ""input_config"": [\n            {\n                ""CompressionType"": COMPRESSION_TYPE,\n                ""DataSource"": {\n                    ""S3DataSource"": {""S3DataType"": ""S3Prefix"", ""S3Uri"": DEFAULT_S3_INPUT_DATA}\n                },\n                ""TargetAttributeName"": TARGET_ATTRIBUTE_NAME,\n            }\n        ],\n        ""output_config"": {""S3OutputPath"": OUTPUT_PATH, ""KmsKeyId"": OUTPUT_KMS_KEY},\n        ""auto_ml_job_config"": {\n            ""CompletionCriteria"": {\n                ""MaxAutoMLJobRuntimeInSeconds"": TOTAL_JOB_RUNTIME,\n                ""MaxCandidates"": MAX_CANDIDATES,\n                ""MaxRuntimePerTrainingJobInSeconds"": MAX_RUNTIME_PER_TRAINING_JOB,\n            },\n            ""SecurityConfig"": {\n                ""VolumeKmsKeyId"": VOLUME_KMS_KEY,\n                ""VpcConfig"": VPC_CONFIG,\n                ""EnableInterContainerTrafficEncryption"": ENCRYPT_INTER_CONTAINER_TRAFFIC,\n            },\n        },\n        ""job_name"": JOB_NAME,\n        ""role"": ROLE,\n        ""job_objective"": JOB_OBJECTIVE,\n        ""problem_type"": PROBLEM_TYPE,\n        ""generate_candidate_definitions_only"": GENERATE_CANDIDATE_DEFINITIONS_ONLY,\n        ""tags"": TAGS,\n    }\n\n\n@patch(""time.strftime"", return_value=TIMESTAMP)\ndef test_auto_ml_default_fit(strftime, sagemaker_session):\n    auto_ml = AutoML(\n        role=ROLE, target_attribute_name=TARGET_ATTRIBUTE_NAME, sagemaker_session=sagemaker_session\n    )\n    inputs = DEFAULT_S3_INPUT_DATA\n    auto_ml.fit(inputs)\n    sagemaker_session.auto_ml.assert_called_once()\n    _, args = sagemaker_session.auto_ml.call_args\n    assert args == {\n        ""input_config"": [\n            {\n                ""DataSource"": {\n                    ""S3DataSource"": {""S3DataType"": ""S3Prefix"", ""S3Uri"": DEFAULT_S3_INPUT_DATA}\n                },\n                ""TargetAttributeName"": TARGET_ATTRIBUTE_NAME,\n            }\n        ],\n        ""output_config"": {""S3OutputPath"": DEFAULT_OUTPUT_PATH},\n        ""auto_ml_job_config"": {\n            ""CompletionCriteria"": {""MaxCandidates"": DEFAULT_MAX_CANDIDATES},\n            ""SecurityConfig"": {\n                ""EnableInterContainerTrafficEncryption"": ENCRYPT_INTER_CONTAINER_TRAFFIC\n            },\n        },\n        ""role"": ROLE,\n        ""job_name"": DEFAULT_JOB_NAME,\n        ""problem_type"": None,\n        ""job_objective"": None,\n        ""generate_candidate_definitions_only"": GENERATE_CANDIDATE_DEFINITIONS_ONLY,\n        ""tags"": None,\n    }\n\n\ndef test_auto_ml_local_input(sagemaker_session):\n    auto_ml = AutoML(\n        role=ROLE, target_attribute_name=TARGET_ATTRIBUTE_NAME, sagemaker_session=sagemaker_session\n    )\n    inputs = DEFAULT_S3_INPUT_DATA\n    auto_ml.fit(inputs)\n    sagemaker_session.auto_ml.assert_called_once()\n    _, args = sagemaker_session.auto_ml.call_args\n    assert args[""input_config""][0][""DataSource""][""S3DataSource""][""S3Uri""] == DEFAULT_S3_INPUT_DATA\n\n\ndef test_auto_ml_input(sagemaker_session):\n    inputs = AutoMLInput(\n        inputs=DEFAULT_S3_INPUT_DATA, target_attribute_name=""target"", compression=""Gzip""\n    )\n    auto_ml = AutoML(\n        role=ROLE, target_attribute_name=TARGET_ATTRIBUTE_NAME, sagemaker_session=sagemaker_session\n    )\n    auto_ml.fit(inputs)\n    _, args = sagemaker_session.auto_ml.call_args\n    assert args[""input_config""] == [\n        {\n            ""CompressionType"": ""Gzip"",\n            ""DataSource"": {\n                ""S3DataSource"": {""S3DataType"": ""S3Prefix"", ""S3Uri"": DEFAULT_S3_INPUT_DATA}\n            },\n            ""TargetAttributeName"": TARGET_ATTRIBUTE_NAME,\n        }\n    ]\n\n\ndef test_describe_auto_ml_job(sagemaker_session):\n    auto_ml = AutoML(\n        role=ROLE, target_attribute_name=TARGET_ATTRIBUTE_NAME, sagemaker_session=sagemaker_session\n    )\n    auto_ml.describe_auto_ml_job(job_name=JOB_NAME)\n    sagemaker_session.describe_auto_ml_job.assert_called_once()\n    sagemaker_session.describe_auto_ml_job.assert_called_with(JOB_NAME)\n\n\ndef test_list_candidates_default(sagemaker_session):\n    auto_ml = AutoML(\n        role=ROLE, target_attribute_name=TARGET_ATTRIBUTE_NAME, sagemaker_session=sagemaker_session\n    )\n    auto_ml.current_job_name = ""current_job_name""\n    auto_ml.list_candidates()\n    sagemaker_session.list_candidates.assert_called_once()\n    sagemaker_session.list_candidates.assert_called_with(job_name=auto_ml.current_job_name)\n\n\ndef test_list_candidates_with_optional_args(sagemaker_session):\n    auto_ml = AutoML(\n        role=ROLE, target_attribute_name=TARGET_ATTRIBUTE_NAME, sagemaker_session=sagemaker_session\n    )\n    auto_ml.list_candidates(\n        job_name=JOB_NAME,\n        status_equals=""Completed"",\n        candidate_name=""candidate-name"",\n        candidate_arn=""candidate-arn"",\n        sort_order=""Ascending"",\n        sort_by=""Status"",\n        max_results=99,\n    )\n    sagemaker_session.list_candidates.assert_called_once()\n    _, args = sagemaker_session.list_candidates.call_args\n    assert args == {\n        ""job_name"": JOB_NAME,\n        ""status_equals"": ""Completed"",\n        ""candidate_name"": ""candidate-name"",\n        ""candidate_arn"": ""candidate-arn"",\n        ""sort_order"": ""Ascending"",\n        ""sort_by"": ""Status"",\n        ""max_results"": 99,\n    }\n\n\ndef test_best_candidate_with_existing_best_candidate(sagemaker_session):\n    auto_ml = AutoML(\n        role=ROLE, target_attribute_name=TARGET_ATTRIBUTE_NAME, sagemaker_session=sagemaker_session\n    )\n    auto_ml._best_candidate = BEST_CANDIDATE\n    best_candidate = auto_ml.best_candidate()\n    sagemaker_session.describe_auto_ml_job.assert_not_called()\n    assert best_candidate == BEST_CANDIDATE\n\n\ndef test_best_candidate_default_job_name(sagemaker_session):\n    auto_ml = AutoML(\n        role=ROLE, target_attribute_name=TARGET_ATTRIBUTE_NAME, sagemaker_session=sagemaker_session\n    )\n    auto_ml.current_job_name = JOB_NAME\n    auto_ml._auto_ml_job_desc = AUTO_ML_DESC\n    best_candidate = auto_ml.best_candidate()\n    sagemaker_session.describe_auto_ml_job.assert_not_called()\n    assert best_candidate == BEST_CANDIDATE\n\n\ndef test_best_candidate_job_no_desc(sagemaker_session):\n    auto_ml = AutoML(\n        role=ROLE, target_attribute_name=TARGET_ATTRIBUTE_NAME, sagemaker_session=sagemaker_session\n    )\n    auto_ml.current_job_name = JOB_NAME\n    best_candidate = auto_ml.best_candidate()\n    sagemaker_session.describe_auto_ml_job.assert_called_once()\n    sagemaker_session.describe_auto_ml_job.assert_called_with(JOB_NAME)\n    assert best_candidate == BEST_CANDIDATE\n\n\ndef test_best_candidate_no_desc_no_job_name(sagemaker_session):\n    auto_ml = AutoML(\n        role=ROLE, target_attribute_name=TARGET_ATTRIBUTE_NAME, sagemaker_session=sagemaker_session\n    )\n    best_candidate = auto_ml.best_candidate(job_name=JOB_NAME)\n    sagemaker_session.describe_auto_ml_job.assert_called_once()\n    sagemaker_session.describe_auto_ml_job.assert_called_with(JOB_NAME)\n    assert best_candidate == BEST_CANDIDATE\n\n\ndef test_best_candidate_job_name_not_match(sagemaker_session):\n    auto_ml = AutoML(\n        role=ROLE, target_attribute_name=TARGET_ATTRIBUTE_NAME, sagemaker_session=sagemaker_session\n    )\n    auto_ml.current_job_name = JOB_NAME\n    auto_ml._auto_ml_job_desc = AUTO_ML_DESC\n    best_candidate = auto_ml.best_candidate(job_name=JOB_NAME_2)\n    sagemaker_session.describe_auto_ml_job.assert_called_once()\n    sagemaker_session.describe_auto_ml_job.assert_called_with(JOB_NAME_2)\n    assert best_candidate == BEST_CANDIDATE_2\n\n\ndef test_deploy(sagemaker_session, candidate_mock):\n    auto_ml = AutoML(\n        role=ROLE, target_attribute_name=TARGET_ATTRIBUTE_NAME, sagemaker_session=sagemaker_session\n    )\n    auto_ml.best_candidate = Mock(name=""best_candidate"", return_value=CANDIDATE_DICT)\n    auto_ml._deploy_inference_pipeline = Mock(""_deploy_inference_pipeline"", return_value=None)\n    auto_ml.deploy(\n        initial_instance_count=INSTANCE_COUNT,\n        instance_type=INSTANCE_TYPE,\n        sagemaker_session=sagemaker_session,\n    )\n    auto_ml._deploy_inference_pipeline.assert_called_once()\n    auto_ml._deploy_inference_pipeline.assert_called_with(\n        candidate_mock.containers,\n        initial_instance_count=INSTANCE_COUNT,\n        instance_type=INSTANCE_TYPE,\n        name=None,\n        sagemaker_session=sagemaker_session,\n        endpoint_name=None,\n        tags=None,\n        wait=True,\n        update_endpoint=False,\n        vpc_config=None,\n        enable_network_isolation=False,\n        model_kms_key=None,\n        predictor_cls=None,\n    )\n\n\n@patch(""sagemaker.automl.automl.CandidateEstimator"")\ndef test_deploy_optional_args(candidate_estimator, sagemaker_session, candidate_mock):\n    candidate_estimator.return_value = candidate_mock\n\n    auto_ml = AutoML(\n        role=ROLE, target_attribute_name=TARGET_ATTRIBUTE_NAME, sagemaker_session=sagemaker_session\n    )\n    auto_ml._deploy_inference_pipeline = Mock(""_deploy_inference_pipeline"", return_value=None)\n\n    auto_ml.deploy(\n        initial_instance_count=INSTANCE_COUNT,\n        instance_type=INSTANCE_TYPE,\n        candidate=CANDIDATE_DICT,\n        sagemaker_session=sagemaker_session,\n        name=JOB_NAME,\n        endpoint_name=JOB_NAME,\n        tags=TAGS,\n        wait=False,\n        update_endpoint=True,\n        vpc_config=VPC_CONFIG,\n        enable_network_isolation=True,\n        model_kms_key=OUTPUT_KMS_KEY,\n        predictor_cls=RealTimePredictor,\n    )\n    auto_ml._deploy_inference_pipeline.assert_called_once()\n    auto_ml._deploy_inference_pipeline.assert_called_with(\n        candidate_mock.containers,\n        initial_instance_count=INSTANCE_COUNT,\n        instance_type=INSTANCE_TYPE,\n        name=JOB_NAME,\n        sagemaker_session=sagemaker_session,\n        endpoint_name=JOB_NAME,\n        tags=TAGS,\n        wait=False,\n        update_endpoint=True,\n        vpc_config=VPC_CONFIG,\n        enable_network_isolation=True,\n        model_kms_key=OUTPUT_KMS_KEY,\n        predictor_cls=RealTimePredictor,\n    )\n\n    candidate_estimator.assert_called_with(CANDIDATE_DICT, sagemaker_session=sagemaker_session)\n\n\ndef test_candidate_estimator_get_steps(sagemaker_session):\n    candidate_estimator = CandidateEstimator(CANDIDATE_DICT, sagemaker_session=sagemaker_session)\n    steps = candidate_estimator.get_steps()\n    assert len(steps) == 3\n\n\ndef test_candidate_estimator_fit(sagemaker_session):\n    candidate_estimator = CandidateEstimator(CANDIDATE_DICT, sagemaker_session=sagemaker_session)\n    candidate_estimator._check_all_job_finished = Mock(\n        name=""_check_all_job_finished"", return_value=True\n    )\n    inputs = DEFAULT_S3_INPUT_DATA\n    candidate_estimator.fit(inputs)\n    sagemaker_session.train.assert_called()\n    sagemaker_session.transform.assert_called()\n'"
tests/unit/sagemaker/model/test_deploy.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport copy\n\nimport pytest\nfrom mock import Mock, patch\n\nimport sagemaker\nfrom sagemaker.model import Model\n\nMODEL_DATA = ""s3://bucket/model.tar.gz""\nMODEL_IMAGE = ""mi""\nTIMESTAMP = ""2017-10-10-14-14-15""\nMODEL_NAME = ""{}-{}"".format(MODEL_IMAGE, TIMESTAMP)\n\nACCELERATOR_TYPE = ""ml.eia.medium""\nINSTANCE_COUNT = 2\nINSTANCE_TYPE = ""ml.c4.4xlarge""\nROLE = ""some-role""\n\nBASE_PRODUCTION_VARIANT = {\n    ""ModelName"": MODEL_NAME,\n    ""InstanceType"": INSTANCE_TYPE,\n    ""InitialInstanceCount"": INSTANCE_COUNT,\n    ""VariantName"": ""AllTraffic"",\n    ""InitialVariantWeight"": 1,\n}\n\n\n@pytest.fixture\ndef sagemaker_session():\n    return Mock()\n\n\n@patch(""sagemaker.production_variant"")\n@patch(""sagemaker.model.Model.prepare_container_def"")\n@patch(""sagemaker.utils.name_from_image"")\ndef test_deploy(name_from_image, prepare_container_def, production_variant, sagemaker_session):\n    name_from_image.return_value = MODEL_NAME\n    production_variant.return_value = BASE_PRODUCTION_VARIANT\n\n    container_def = {""Image"": MODEL_IMAGE, ""Environment"": {}, ""ModelDataUrl"": MODEL_DATA}\n    prepare_container_def.return_value = container_def\n\n    model = Model(MODEL_DATA, MODEL_IMAGE, role=ROLE, sagemaker_session=sagemaker_session)\n    model.deploy(instance_type=INSTANCE_TYPE, initial_instance_count=INSTANCE_COUNT)\n\n    name_from_image.assert_called_with(MODEL_IMAGE)\n    prepare_container_def.assert_called_with(INSTANCE_TYPE, accelerator_type=None)\n    production_variant.assert_called_with(\n        MODEL_NAME, INSTANCE_TYPE, INSTANCE_COUNT, accelerator_type=None\n    )\n\n    sagemaker_session.create_model.assert_called_with(\n        MODEL_NAME, ROLE, container_def, vpc_config=None, enable_network_isolation=False, tags=None\n    )\n\n    sagemaker_session.endpoint_from_production_variants.assert_called_with(\n        name=MODEL_NAME,\n        production_variants=[BASE_PRODUCTION_VARIANT],\n        tags=None,\n        kms_key=None,\n        wait=True,\n        data_capture_config_dict=None,\n    )\n\n\n@patch(""sagemaker.model.Model._create_sagemaker_model"")\n@patch(""sagemaker.production_variant"")\ndef test_deploy_accelerator_type(production_variant, create_sagemaker_model, sagemaker_session):\n    model = Model(\n        MODEL_DATA, MODEL_IMAGE, role=ROLE, name=MODEL_NAME, sagemaker_session=sagemaker_session\n    )\n\n    production_variant_result = copy.deepcopy(BASE_PRODUCTION_VARIANT)\n    production_variant_result[""AcceleratorType""] = ACCELERATOR_TYPE\n    production_variant.return_value = production_variant_result\n\n    model.deploy(\n        instance_type=INSTANCE_TYPE,\n        initial_instance_count=INSTANCE_COUNT,\n        accelerator_type=ACCELERATOR_TYPE,\n    )\n\n    create_sagemaker_model.assert_called_with(INSTANCE_TYPE, ACCELERATOR_TYPE, None)\n    production_variant.assert_called_with(\n        MODEL_NAME, INSTANCE_TYPE, INSTANCE_COUNT, accelerator_type=ACCELERATOR_TYPE\n    )\n\n    sagemaker_session.endpoint_from_production_variants.assert_called_with(\n        name=MODEL_NAME,\n        production_variants=[production_variant_result],\n        tags=None,\n        kms_key=None,\n        wait=True,\n        data_capture_config_dict=None,\n    )\n\n\n@patch(""sagemaker.utils.name_from_image"", Mock())\n@patch(""sagemaker.model.Model._create_sagemaker_model"", Mock())\n@patch(""sagemaker.production_variant"", return_value=BASE_PRODUCTION_VARIANT)\ndef test_deploy_endpoint_name(sagemaker_session):\n    model = Model(MODEL_DATA, MODEL_IMAGE, role=ROLE, sagemaker_session=sagemaker_session)\n\n    endpoint_name = ""blah""\n    model.deploy(\n        endpoint_name=endpoint_name,\n        instance_type=INSTANCE_TYPE,\n        initial_instance_count=INSTANCE_COUNT,\n    )\n\n    sagemaker_session.endpoint_from_production_variants.assert_called_with(\n        name=endpoint_name,\n        production_variants=[BASE_PRODUCTION_VARIANT],\n        tags=None,\n        kms_key=None,\n        wait=True,\n        data_capture_config_dict=None,\n    )\n\n\n@patch(""sagemaker.production_variant"", return_value=BASE_PRODUCTION_VARIANT)\n@patch(""sagemaker.model.Model._create_sagemaker_model"")\ndef test_deploy_tags(create_sagemaker_model, production_variant, sagemaker_session):\n    model = Model(\n        MODEL_DATA, MODEL_IMAGE, role=ROLE, name=MODEL_NAME, sagemaker_session=sagemaker_session\n    )\n\n    tags = [{""Key"": ""ModelName"", ""Value"": ""TestModel""}]\n    model.deploy(instance_type=INSTANCE_TYPE, initial_instance_count=INSTANCE_COUNT, tags=tags)\n\n    create_sagemaker_model.assert_called_with(INSTANCE_TYPE, None, tags)\n    sagemaker_session.endpoint_from_production_variants.assert_called_with(\n        name=MODEL_NAME,\n        production_variants=[BASE_PRODUCTION_VARIANT],\n        tags=tags,\n        kms_key=None,\n        wait=True,\n        data_capture_config_dict=None,\n    )\n\n\n@patch(""sagemaker.model.Model._create_sagemaker_model"", Mock())\n@patch(""sagemaker.production_variant"", return_value=BASE_PRODUCTION_VARIANT)\ndef test_deploy_kms_key(production_variant, sagemaker_session):\n    model = Model(\n        MODEL_DATA, MODEL_IMAGE, role=ROLE, name=MODEL_NAME, sagemaker_session=sagemaker_session\n    )\n\n    key = ""some-key-arn""\n    model.deploy(instance_type=INSTANCE_TYPE, initial_instance_count=INSTANCE_COUNT, kms_key=key)\n\n    sagemaker_session.endpoint_from_production_variants.assert_called_with(\n        name=MODEL_NAME,\n        production_variants=[BASE_PRODUCTION_VARIANT],\n        tags=None,\n        kms_key=key,\n        wait=True,\n        data_capture_config_dict=None,\n    )\n\n\n@patch(""sagemaker.model.Model._create_sagemaker_model"", Mock())\n@patch(""sagemaker.production_variant"", return_value=BASE_PRODUCTION_VARIANT)\ndef test_deploy_async(production_variant, sagemaker_session):\n    model = Model(\n        MODEL_DATA, MODEL_IMAGE, role=ROLE, name=MODEL_NAME, sagemaker_session=sagemaker_session\n    )\n\n    model.deploy(instance_type=INSTANCE_TYPE, initial_instance_count=INSTANCE_COUNT, wait=False)\n\n    sagemaker_session.endpoint_from_production_variants.assert_called_with(\n        name=MODEL_NAME,\n        production_variants=[BASE_PRODUCTION_VARIANT],\n        tags=None,\n        kms_key=None,\n        wait=False,\n        data_capture_config_dict=None,\n    )\n\n\n@patch(""sagemaker.model.Model._create_sagemaker_model"", Mock())\n@patch(""sagemaker.production_variant"", return_value=BASE_PRODUCTION_VARIANT)\ndef test_deploy_data_capture_config(production_variant, sagemaker_session):\n    model = Model(\n        MODEL_DATA, MODEL_IMAGE, role=ROLE, name=MODEL_NAME, sagemaker_session=sagemaker_session\n    )\n\n    data_capture_config = Mock()\n    data_capture_config_dict = {""EnableCapture"": True}\n    data_capture_config._to_request_dict.return_value = data_capture_config_dict\n    model.deploy(\n        instance_type=INSTANCE_TYPE,\n        initial_instance_count=INSTANCE_COUNT,\n        data_capture_config=data_capture_config,\n    )\n\n    data_capture_config._to_request_dict.assert_called_with()\n    sagemaker_session.endpoint_from_production_variants.assert_called_with(\n        name=MODEL_NAME,\n        production_variants=[BASE_PRODUCTION_VARIANT],\n        tags=None,\n        kms_key=None,\n        wait=True,\n        data_capture_config_dict=data_capture_config_dict,\n    )\n\n\n@patch(""sagemaker.session.Session"")\n@patch(""sagemaker.local.LocalSession"")\ndef test_deploy_creates_correct_session(local_session, session):\n    # We expect a LocalSession when deploying to instance_type = \'local\'\n    model = Model(MODEL_DATA, MODEL_IMAGE, role=ROLE)\n    model.deploy(endpoint_name=""blah"", instance_type=""local"", initial_instance_count=1)\n    assert model.sagemaker_session == local_session.return_value\n\n    # We expect a real Session when deploying to instance_type != local/local_gpu\n    model = Model(MODEL_DATA, MODEL_IMAGE, role=ROLE)\n    model.deploy(\n        endpoint_name=""remote_endpoint"", instance_type=""ml.m4.4xlarge"", initial_instance_count=2\n    )\n    assert model.sagemaker_session == session.return_value\n\n\ndef test_deploy_no_role(sagemaker_session):\n    model = Model(MODEL_DATA, MODEL_IMAGE, sagemaker_session=sagemaker_session)\n\n    with pytest.raises(ValueError, match=""Role can not be null for deploying a model""):\n        model.deploy(instance_type=INSTANCE_TYPE, initial_instance_count=INSTANCE_COUNT)\n\n\n@patch(""sagemaker.model.Model._create_sagemaker_model"", Mock())\n@patch(""sagemaker.predictor.RealTimePredictor._get_endpoint_config_name"", Mock())\n@patch(""sagemaker.predictor.RealTimePredictor._get_model_names"", Mock())\n@patch(""sagemaker.production_variant"", return_value=BASE_PRODUCTION_VARIANT)\ndef test_deploy_predictor_cls(production_variant, sagemaker_session):\n    model = Model(\n        MODEL_DATA,\n        MODEL_IMAGE,\n        role=ROLE,\n        name=MODEL_NAME,\n        predictor_cls=sagemaker.predictor.RealTimePredictor,\n        sagemaker_session=sagemaker_session,\n    )\n\n    endpoint_name = ""foo""\n    predictor = model.deploy(\n        instance_type=INSTANCE_TYPE,\n        initial_instance_count=INSTANCE_COUNT,\n        endpoint_name=endpoint_name,\n    )\n\n    assert isinstance(predictor, sagemaker.predictor.RealTimePredictor)\n    assert predictor.endpoint == endpoint_name\n    assert predictor.sagemaker_session == sagemaker_session\n\n\ndef test_deploy_update_endpoint(sagemaker_session):\n    model = Model(MODEL_DATA, MODEL_IMAGE, role=ROLE, sagemaker_session=sagemaker_session)\n    model.deploy(\n        instance_type=INSTANCE_TYPE, initial_instance_count=INSTANCE_COUNT, update_endpoint=True\n    )\n    sagemaker_session.create_endpoint_config.assert_called_with(\n        name=model.name,\n        model_name=model.name,\n        initial_instance_count=INSTANCE_COUNT,\n        instance_type=INSTANCE_TYPE,\n        accelerator_type=None,\n        tags=None,\n        kms_key=None,\n        data_capture_config_dict=None,\n    )\n    config_name = sagemaker_session.create_endpoint_config(\n        name=model.name,\n        model_name=model.name,\n        initial_instance_count=INSTANCE_COUNT,\n        instance_type=INSTANCE_TYPE,\n        accelerator_type=ACCELERATOR_TYPE,\n    )\n    sagemaker_session.update_endpoint.assert_called_with(model.name, config_name, wait=True)\n    sagemaker_session.create_endpoint.assert_not_called()\n\n\ndef test_deploy_update_endpoint_optional_args(sagemaker_session):\n    endpoint_name = ""endpoint-name""\n    tags = [{""Key"": ""Value""}]\n    kms_key = ""foo""\n    data_capture_config = Mock()\n\n    model = Model(MODEL_DATA, MODEL_IMAGE, role=ROLE, sagemaker_session=sagemaker_session)\n    model.deploy(\n        instance_type=INSTANCE_TYPE,\n        initial_instance_count=INSTANCE_COUNT,\n        update_endpoint=True,\n        endpoint_name=endpoint_name,\n        accelerator_type=ACCELERATOR_TYPE,\n        tags=tags,\n        kms_key=kms_key,\n        wait=False,\n        data_capture_config=data_capture_config,\n    )\n    sagemaker_session.create_endpoint_config.assert_called_with(\n        name=model.name,\n        model_name=model.name,\n        initial_instance_count=INSTANCE_COUNT,\n        instance_type=INSTANCE_TYPE,\n        accelerator_type=ACCELERATOR_TYPE,\n        tags=tags,\n        kms_key=kms_key,\n        data_capture_config_dict=data_capture_config._to_request_dict(),\n    )\n    config_name = sagemaker_session.create_endpoint_config(\n        name=model.name,\n        model_name=model.name,\n        initial_instance_count=INSTANCE_COUNT,\n        instance_type=INSTANCE_TYPE,\n        accelerator_type=ACCELERATOR_TYPE,\n        wait=False,\n    )\n    sagemaker_session.update_endpoint.assert_called_with(endpoint_name, config_name, wait=False)\n    sagemaker_session.create_endpoint.assert_not_called()\n'"
tests/unit/sagemaker/model/test_framework_model.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport os\nimport subprocess\n\nfrom sagemaker.model import FrameworkModel\nfrom sagemaker.predictor import RealTimePredictor\n\nimport pytest\nfrom mock import MagicMock, Mock, patch\n\nMODEL_DATA = ""s3://bucket/model.tar.gz""\nMODEL_IMAGE = ""mi""\nENTRY_POINT = ""blah.py""\nROLE = ""some-role""\n\nDATA_DIR = os.path.join(os.path.dirname(__file__), "".."", ""data"")\nSCRIPT_NAME = ""dummy_script.py""\nSCRIPT_PATH = os.path.join(DATA_DIR, SCRIPT_NAME)\nTIMESTAMP = ""2017-10-10-14-14-15""\nBUCKET_NAME = ""mybucket""\nINSTANCE_COUNT = 1\nINSTANCE_TYPE = ""c4.4xlarge""\nREGION = ""us-west-2""\nMODEL_NAME = ""{}-{}"".format(MODEL_IMAGE, TIMESTAMP)\nGIT_REPO = ""https://github.com/aws/sagemaker-python-sdk.git""\nBRANCH = ""test-branch-git-config""\nCOMMIT = ""ae15c9d7d5b97ea95ea451e4662ee43da3401d73""\nPRIVATE_GIT_REPO_SSH = ""git@github.com:testAccount/private-repo.git""\nPRIVATE_GIT_REPO = ""https://github.com/testAccount/private-repo.git""\nPRIVATE_BRANCH = ""test-branch""\nPRIVATE_COMMIT = ""329bfcf884482002c05ff7f44f62599ebc9f445a""\nCODECOMMIT_REPO = ""https://git-codecommit.us-west-2.amazonaws.com/v1/repos/test-repo/""\nCODECOMMIT_REPO_SSH = ""ssh://git-codecommit.us-west-2.amazonaws.com/v1/repos/test-repo/""\nCODECOMMIT_BRANCH = ""master""\nREPO_DIR = ""/tmp/repo_dir""\n\n\nclass DummyFrameworkModel(FrameworkModel):\n    def __init__(self, sagemaker_session, **kwargs):\n        super(DummyFrameworkModel, self).__init__(\n            MODEL_DATA,\n            MODEL_IMAGE,\n            ROLE,\n            ENTRY_POINT,\n            sagemaker_session=sagemaker_session,\n            **kwargs\n        )\n\n    def create_predictor(self, endpoint_name):\n        return RealTimePredictor(endpoint_name, sagemaker_session=self.sagemaker_session)\n\n\nclass DummyFrameworkModelForGit(FrameworkModel):\n    def __init__(self, sagemaker_session, entry_point, **kwargs):\n        super(DummyFrameworkModelForGit, self).__init__(\n            MODEL_DATA,\n            MODEL_IMAGE,\n            ROLE,\n            entry_point=entry_point,\n            sagemaker_session=sagemaker_session,\n            **kwargs\n        )\n\n    def create_predictor(self, endpoint_name):\n        return RealTimePredictor(endpoint_name, sagemaker_session=self.sagemaker_session)\n\n\n@pytest.fixture()\ndef sagemaker_session():\n    boto_mock = Mock(name=""boto_session"", region_name=REGION)\n    sms = Mock(\n        name=""sagemaker_session"",\n        boto_session=boto_mock,\n        boto_region_name=REGION,\n        config=None,\n        local_mode=False,\n        s3_client=None,\n        s3_resource=None,\n    )\n    sms.default_bucket = Mock(name=""default_bucket"", return_value=BUCKET_NAME)\n    return sms\n\n\n@patch(""shutil.rmtree"", MagicMock())\n@patch(""tarfile.open"", MagicMock())\n@patch(""os.listdir"", MagicMock(return_value=[""blah.py""]))\n@patch(""time.strftime"", return_value=TIMESTAMP)\ndef test_prepare_container_def(time, sagemaker_session):\n    model = DummyFrameworkModel(sagemaker_session)\n    assert model.prepare_container_def(INSTANCE_TYPE) == {\n        ""Environment"": {\n            ""SAGEMAKER_PROGRAM"": ENTRY_POINT,\n            ""SAGEMAKER_SUBMIT_DIRECTORY"": ""s3://mybucket/mi-2017-10-10-14-14-15/sourcedir.tar.gz"",\n            ""SAGEMAKER_CONTAINER_LOG_LEVEL"": ""20"",\n            ""SAGEMAKER_REGION"": REGION,\n            ""SAGEMAKER_ENABLE_CLOUDWATCH_METRICS"": ""false"",\n        },\n        ""Image"": MODEL_IMAGE,\n        ""ModelDataUrl"": MODEL_DATA,\n    }\n\n\n@patch(""shutil.rmtree"", MagicMock())\n@patch(""tarfile.open"", MagicMock())\n@patch(""os.listdir"", MagicMock(return_value=[""blah.py""]))\n@patch(""time.strftime"", return_value=TIMESTAMP)\ndef test_prepare_container_def_with_network_isolation(time, sagemaker_session):\n    model = DummyFrameworkModel(sagemaker_session, enable_network_isolation=True)\n    assert model.prepare_container_def(INSTANCE_TYPE) == {\n        ""Environment"": {\n            ""SAGEMAKER_PROGRAM"": ENTRY_POINT,\n            ""SAGEMAKER_SUBMIT_DIRECTORY"": ""/opt/ml/model/code"",\n            ""SAGEMAKER_CONTAINER_LOG_LEVEL"": ""20"",\n            ""SAGEMAKER_REGION"": REGION,\n            ""SAGEMAKER_ENABLE_CLOUDWATCH_METRICS"": ""false"",\n        },\n        ""Image"": MODEL_IMAGE,\n        ""ModelDataUrl"": MODEL_DATA,\n    }\n\n\n@patch(""shutil.rmtree"", MagicMock())\n@patch(""tarfile.open"", MagicMock())\n@patch(""os.path.exists"", MagicMock(return_value=True))\n@patch(""os.path.isdir"", MagicMock(return_value=True))\n@patch(""os.listdir"", MagicMock(return_value=[""blah.py""]))\n@patch(""time.strftime"", MagicMock(return_value=TIMESTAMP))\ndef test_prepare_container_def_no_model_defaults(sagemaker_session, tmpdir):\n    model = DummyFrameworkModel(\n        sagemaker_session,\n        source_dir=""sd"",\n        env={""a"": ""a""},\n        name=""name"",\n        enable_cloudwatch_metrics=True,\n        container_log_level=55,\n        code_location=""s3://cb/cp"",\n    )\n\n    assert model.prepare_container_def(INSTANCE_TYPE) == {\n        ""Environment"": {\n            ""SAGEMAKER_PROGRAM"": ENTRY_POINT,\n            ""SAGEMAKER_SUBMIT_DIRECTORY"": ""s3://cb/cp/name/sourcedir.tar.gz"",\n            ""SAGEMAKER_CONTAINER_LOG_LEVEL"": ""55"",\n            ""SAGEMAKER_REGION"": REGION,\n            ""SAGEMAKER_ENABLE_CLOUDWATCH_METRICS"": ""true"",\n            ""a"": ""a"",\n        },\n        ""Image"": MODEL_IMAGE,\n        ""ModelDataUrl"": MODEL_DATA,\n    }\n\n\n@patch(""sagemaker.git_utils.git_clone_repo"")\n@patch(""sagemaker.model.fw_utils.tar_and_upload_dir"")\ndef test_git_support_succeed(tar_and_upload_dir, git_clone_repo, sagemaker_session):\n    git_clone_repo.side_effect = lambda gitconfig, entrypoint, sourcedir, dependency: {\n        ""entry_point"": ""entry_point"",\n        ""source_dir"": ""/tmp/repo_dir/source_dir"",\n        ""dependencies"": [""/tmp/repo_dir/foo"", ""/tmp/repo_dir/bar""],\n    }\n    entry_point = ""entry_point""\n    source_dir = ""source_dir""\n    dependencies = [""foo"", ""bar""]\n    git_config = {""repo"": GIT_REPO, ""branch"": BRANCH, ""commit"": COMMIT}\n    model = DummyFrameworkModelForGit(\n        sagemaker_session=sagemaker_session,\n        entry_point=entry_point,\n        source_dir=source_dir,\n        dependencies=dependencies,\n        git_config=git_config,\n    )\n    model.prepare_container_def(instance_type=INSTANCE_TYPE)\n    git_clone_repo.assert_called_with(git_config, entry_point, source_dir, dependencies)\n    assert model.entry_point == ""entry_point""\n    assert model.source_dir == ""/tmp/repo_dir/source_dir""\n    assert model.dependencies == [""/tmp/repo_dir/foo"", ""/tmp/repo_dir/bar""]\n\n\ndef test_git_support_repo_not_provided(sagemaker_session):\n    entry_point = ""source_dir/entry_point""\n    git_config = {""branch"": BRANCH, ""commit"": COMMIT}\n    with pytest.raises(ValueError) as error:\n        model = DummyFrameworkModelForGit(\n            sagemaker_session=sagemaker_session, entry_point=entry_point, git_config=git_config\n        )\n        model.prepare_container_def(instance_type=INSTANCE_TYPE)\n    assert ""Please provide a repo for git_config."" in str(error)\n\n\n@patch(\n    ""sagemaker.git_utils.git_clone_repo"",\n    side_effect=subprocess.CalledProcessError(\n        returncode=1, cmd=""git clone https://github.com/aws/no-such-repo.git /tmp/repo_dir""\n    ),\n)\ndef test_git_support_git_clone_fail(sagemaker_session):\n    entry_point = ""source_dir/entry_point""\n    git_config = {""repo"": ""https://github.com/aws/no-such-repo.git"", ""branch"": BRANCH}\n    with pytest.raises(subprocess.CalledProcessError) as error:\n        model = DummyFrameworkModelForGit(\n            sagemaker_session=sagemaker_session, entry_point=entry_point, git_config=git_config\n        )\n        model.prepare_container_def(instance_type=INSTANCE_TYPE)\n    assert ""returned non-zero exit status"" in str(error)\n\n\n@patch(\n    ""sagemaker.git_utils.git_clone_repo"",\n    side_effect=subprocess.CalledProcessError(\n        returncode=1, cmd=""git checkout branch-that-does-not-exist""\n    ),\n)\ndef test_git_support_branch_not_exist(git_clone_repo, sagemaker_session):\n    entry_point = ""source_dir/entry_point""\n    git_config = {""repo"": GIT_REPO, ""branch"": ""branch-that-does-not-exist"", ""commit"": COMMIT}\n    with pytest.raises(subprocess.CalledProcessError) as error:\n        model = DummyFrameworkModelForGit(\n            sagemaker_session=sagemaker_session, entry_point=entry_point, git_config=git_config\n        )\n        model.prepare_container_def(instance_type=INSTANCE_TYPE)\n    assert ""returned non-zero exit status"" in str(error)\n\n\n@patch(\n    ""sagemaker.git_utils.git_clone_repo"",\n    side_effect=subprocess.CalledProcessError(\n        returncode=1, cmd=""git checkout commit-sha-that-does-not-exist""\n    ),\n)\ndef test_git_support_commit_not_exist(git_clone_repo, sagemaker_session):\n    entry_point = ""source_dir/entry_point""\n    git_config = {""repo"": GIT_REPO, ""branch"": BRANCH, ""commit"": ""commit-sha-that-does-not-exist""}\n    with pytest.raises(subprocess.CalledProcessError) as error:\n        model = DummyFrameworkModelForGit(\n            sagemaker_session=sagemaker_session, entry_point=entry_point, git_config=git_config\n        )\n        model.prepare_container_def(instance_type=INSTANCE_TYPE)\n    assert ""returned non-zero exit status"" in str(error)\n\n\n@patch(\n    ""sagemaker.git_utils.git_clone_repo"",\n    side_effect=ValueError(""Entry point does not exist in the repo.""),\n)\ndef test_git_support_entry_point_not_exist(sagemaker_session):\n    entry_point = ""source_dir/entry_point""\n    git_config = {""repo"": GIT_REPO, ""branch"": BRANCH, ""commit"": COMMIT}\n    with pytest.raises(ValueError) as error:\n        model = DummyFrameworkModelForGit(\n            sagemaker_session=sagemaker_session, entry_point=entry_point, git_config=git_config\n        )\n        model.prepare_container_def(instance_type=INSTANCE_TYPE)\n    assert ""Entry point does not exist in the repo."" in str(error)\n\n\n@patch(\n    ""sagemaker.git_utils.git_clone_repo"",\n    side_effect=ValueError(""Source directory does not exist in the repo.""),\n)\ndef test_git_support_source_dir_not_exist(sagemaker_session):\n    entry_point = ""entry_point""\n    source_dir = ""source_dir_that_does_not_exist""\n    git_config = {""repo"": GIT_REPO, ""branch"": BRANCH, ""commit"": COMMIT}\n    with pytest.raises(ValueError) as error:\n        model = DummyFrameworkModelForGit(\n            sagemaker_session=sagemaker_session,\n            entry_point=entry_point,\n            source_dir=source_dir,\n            git_config=git_config,\n        )\n        model.prepare_container_def(instance_type=INSTANCE_TYPE)\n    assert ""Source directory does not exist in the repo."" in str(error)\n\n\n@patch(\n    ""sagemaker.git_utils.git_clone_repo"",\n    side_effect=ValueError(""Dependency no-such-dir does not exist in the repo.""),\n)\ndef test_git_support_dependencies_not_exist(sagemaker_session):\n    entry_point = ""entry_point""\n    dependencies = [""foo"", ""no_such_dir""]\n    git_config = {""repo"": GIT_REPO, ""branch"": BRANCH, ""commit"": COMMIT}\n    with pytest.raises(ValueError) as error:\n        model = DummyFrameworkModelForGit(\n            sagemaker_session=sagemaker_session,\n            entry_point=entry_point,\n            dependencies=dependencies,\n            git_config=git_config,\n        )\n        model.prepare_container_def(instance_type=INSTANCE_TYPE)\n    assert ""Dependency"", ""does not exist in the repo."" in str(error)\n\n\n@patch(\n    ""sagemaker.git_utils.git_clone_repo"",\n    side_effect=lambda gitconfig, entrypoint, source_dir=None, dependencies=None: {\n        ""entry_point"": ""/tmp/repo_dir/entry_point"",\n        ""source_dir"": None,\n        ""dependencies"": None,\n    },\n)\n@patch(""sagemaker.model.fw_utils.tar_and_upload_dir"")\ndef test_git_support_with_username_password_no_2fa(\n    tar_and_upload_dir, git_clone_repo, sagemaker_session\n):\n    entry_point = ""entry_point""\n    git_config = {\n        ""repo"": PRIVATE_GIT_REPO,\n        ""branch"": PRIVATE_BRANCH,\n        ""commit"": PRIVATE_COMMIT,\n        ""username"": ""username"",\n        ""password"": ""passw0rd!"",\n    }\n    model = DummyFrameworkModelForGit(\n        sagemaker_session=sagemaker_session, entry_point=entry_point, git_config=git_config\n    )\n    model.prepare_container_def(instance_type=INSTANCE_TYPE)\n    git_clone_repo.assert_called_with(git_config, entry_point, None, [])\n    assert model.entry_point == ""/tmp/repo_dir/entry_point""\n\n\n@patch(\n    ""sagemaker.git_utils.git_clone_repo"",\n    side_effect=lambda gitconfig, entrypoint, source_dir=None, dependencies=None: {\n        ""entry_point"": ""/tmp/repo_dir/entry_point"",\n        ""source_dir"": None,\n        ""dependencies"": None,\n    },\n)\n@patch(""sagemaker.model.fw_utils.tar_and_upload_dir"")\ndef test_git_support_with_token_2fa(tar_and_upload_dir, git_clone_repo, sagemaker_session):\n    entry_point = ""entry_point""\n    git_config = {\n        ""repo"": PRIVATE_GIT_REPO,\n        ""branch"": PRIVATE_BRANCH,\n        ""commit"": PRIVATE_COMMIT,\n        ""token"": ""my-token"",\n        ""2FA_enabled"": True,\n    }\n    model = DummyFrameworkModelForGit(\n        sagemaker_session=sagemaker_session, entry_point=entry_point, git_config=git_config\n    )\n    model.prepare_container_def(instance_type=INSTANCE_TYPE)\n    git_clone_repo.assert_called_with(git_config, entry_point, None, [])\n    assert model.entry_point == ""/tmp/repo_dir/entry_point""\n\n\n@patch(\n    ""sagemaker.git_utils.git_clone_repo"",\n    side_effect=lambda gitconfig, entrypoint, source_dir=None, dependencies=None: {\n        ""entry_point"": ""/tmp/repo_dir/entry_point"",\n        ""source_dir"": None,\n        ""dependencies"": None,\n    },\n)\n@patch(""sagemaker.model.fw_utils.tar_and_upload_dir"")\ndef test_git_support_ssh_no_passphrase_needed(\n    tar_and_upload_dir, git_clone_repo, sagemaker_session\n):\n    entry_point = ""entry_point""\n    git_config = {""repo"": PRIVATE_GIT_REPO_SSH, ""branch"": PRIVATE_BRANCH, ""commit"": PRIVATE_COMMIT}\n    model = DummyFrameworkModelForGit(\n        sagemaker_session=sagemaker_session, entry_point=entry_point, git_config=git_config\n    )\n    model.prepare_container_def(instance_type=INSTANCE_TYPE)\n    git_clone_repo.assert_called_with(git_config, entry_point, None, [])\n    assert model.entry_point == ""/tmp/repo_dir/entry_point""\n\n\n@patch(\n    ""sagemaker.git_utils.git_clone_repo"",\n    side_effect=subprocess.CalledProcessError(\n        returncode=1, cmd=""git clone {} {}"".format(PRIVATE_GIT_REPO_SSH, REPO_DIR)\n    ),\n)\n@patch(""sagemaker.model.fw_utils.tar_and_upload_dir"")\ndef test_git_support_ssh_passphrase_required(tar_and_upload_dir, git_clone_repo, sagemaker_session):\n    entry_point = ""entry_point""\n    git_config = {""repo"": PRIVATE_GIT_REPO_SSH, ""branch"": PRIVATE_BRANCH, ""commit"": PRIVATE_COMMIT}\n    with pytest.raises(subprocess.CalledProcessError) as error:\n        model = DummyFrameworkModelForGit(\n            sagemaker_session=sagemaker_session, entry_point=entry_point, git_config=git_config\n        )\n        model.prepare_container_def(instance_type=INSTANCE_TYPE)\n    assert ""returned non-zero exit status"" in str(error)\n\n\n@patch(\n    ""sagemaker.git_utils.git_clone_repo"",\n    side_effect=lambda gitconfig, entrypoint, source_dir=None, dependencies=None: {\n        ""entry_point"": ""/tmp/repo_dir/entry_point"",\n        ""source_dir"": None,\n        ""dependencies"": None,\n    },\n)\n@patch(""sagemaker.model.fw_utils.tar_and_upload_dir"")\ndef test_git_support_codecommit_with_username_and_password_succeed(\n    tar_and_upload_dir, git_clone_repo, sagemaker_session\n):\n    entry_point = ""entry_point""\n    git_config = {\n        ""repo"": CODECOMMIT_REPO,\n        ""branch"": CODECOMMIT_BRANCH,\n        ""username"": ""username"",\n        ""password"": ""passw0rd!"",\n    }\n    model = DummyFrameworkModelForGit(\n        sagemaker_session=sagemaker_session, entry_point=entry_point, git_config=git_config\n    )\n    model.prepare_container_def(instance_type=INSTANCE_TYPE)\n    git_clone_repo.assert_called_with(git_config, entry_point, None, [])\n    assert model.entry_point == ""/tmp/repo_dir/entry_point""\n\n\n@patch(\n    ""sagemaker.git_utils.git_clone_repo"",\n    side_effect=lambda gitconfig, entrypoint, source_dir=None, dependencies=None: {\n        ""entry_point"": ""/tmp/repo_dir/entry_point"",\n        ""source_dir"": None,\n        ""dependencies"": None,\n    },\n)\n@patch(""sagemaker.model.fw_utils.tar_and_upload_dir"")\ndef test_git_support_codecommit_ssh_no_passphrase_needed(\n    tar_and_upload_dir, git_clone_repo, sagemaker_session\n):\n    entry_point = ""entry_point""\n    git_config = {""repo"": CODECOMMIT_REPO_SSH, ""branch"": CODECOMMIT_BRANCH}\n    model = DummyFrameworkModelForGit(\n        sagemaker_session=sagemaker_session, entry_point=entry_point, git_config=git_config\n    )\n    model.prepare_container_def(instance_type=INSTANCE_TYPE)\n    git_clone_repo.assert_called_with(git_config, entry_point, None, [])\n    assert model.entry_point == ""/tmp/repo_dir/entry_point""\n\n\n@patch(\n    ""sagemaker.git_utils.git_clone_repo"",\n    side_effect=subprocess.CalledProcessError(\n        returncode=1, cmd=""git clone {} {}"".format(PRIVATE_GIT_REPO_SSH, REPO_DIR)\n    ),\n)\n@patch(""sagemaker.model.fw_utils.tar_and_upload_dir"")\ndef test_git_support_codecommit_ssh_passphrase_required(\n    tar_and_upload_dir, git_clone_repo, sagemaker_session\n):\n    entry_point = ""entry_point""\n    git_config = {""repo"": CODECOMMIT_REPO_SSH, ""branch"": CODECOMMIT_BRANCH}\n    with pytest.raises(subprocess.CalledProcessError) as error:\n        model = DummyFrameworkModelForGit(\n            sagemaker_session=sagemaker_session, entry_point=entry_point, git_config=git_config\n        )\n        model.prepare_container_def(instance_type=INSTANCE_TYPE)\n    assert ""returned non-zero exit status"" in str(error)\n'"
tests/unit/sagemaker/model/test_model.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport pytest\nfrom mock import Mock, patch\n\nimport sagemaker\nfrom sagemaker.model import Model\n\nMODEL_DATA = ""s3://bucket/model.tar.gz""\nMODEL_IMAGE = ""mi""\nTIMESTAMP = ""2017-10-10-14-14-15""\nMODEL_NAME = ""{}-{}"".format(MODEL_IMAGE, TIMESTAMP)\n\nINSTANCE_COUNT = 2\nINSTANCE_TYPE = ""ml.c4.4xlarge""\nROLE = ""some-role""\n\n\n@pytest.fixture\ndef sagemaker_session():\n    return Mock()\n\n\ndef test_prepare_container_def():\n    env = {""FOO"": ""BAR""}\n    model = Model(MODEL_DATA, MODEL_IMAGE, env=env)\n\n    container_def = model.prepare_container_def(INSTANCE_TYPE, ""ml.eia.medium"")\n\n    expected = {""Image"": MODEL_IMAGE, ""Environment"": env, ""ModelDataUrl"": MODEL_DATA}\n    assert expected == container_def\n\n\ndef test_model_enable_network_isolation():\n    model = Model(MODEL_DATA, MODEL_IMAGE)\n    assert model.enable_network_isolation() is False\n\n    model = Model(MODEL_DATA, MODEL_IMAGE, enable_network_isolation=True)\n    assert model.enable_network_isolation()\n\n\n@patch(""sagemaker.model.Model.prepare_container_def"")\n@patch(""sagemaker.utils.name_from_image"")\ndef test_create_sagemaker_model(name_from_image, prepare_container_def, sagemaker_session):\n    name_from_image.return_value = MODEL_NAME\n\n    container_def = {""Image"": MODEL_IMAGE, ""Environment"": {}, ""ModelDataUrl"": MODEL_DATA}\n    prepare_container_def.return_value = container_def\n\n    model = Model(MODEL_DATA, MODEL_IMAGE, sagemaker_session=sagemaker_session)\n    model._create_sagemaker_model(INSTANCE_TYPE)\n\n    prepare_container_def.assert_called_with(INSTANCE_TYPE, accelerator_type=None)\n    name_from_image.assert_called_with(MODEL_IMAGE)\n\n    sagemaker_session.create_model.assert_called_with(\n        MODEL_NAME, None, container_def, vpc_config=None, enable_network_isolation=False, tags=None\n    )\n\n\n@patch(""sagemaker.utils.name_from_image"", Mock())\n@patch(""sagemaker.model.Model.prepare_container_def"")\ndef test_create_sagemaker_model_accelerator_type(prepare_container_def, sagemaker_session):\n    model = Model(MODEL_DATA, MODEL_IMAGE, sagemaker_session=sagemaker_session)\n\n    accelerator_type = ""ml.eia.medium""\n    model._create_sagemaker_model(INSTANCE_TYPE, accelerator_type=accelerator_type)\n\n    prepare_container_def.assert_called_with(INSTANCE_TYPE, accelerator_type=accelerator_type)\n\n\n@patch(""sagemaker.model.Model.prepare_container_def"")\n@patch(""sagemaker.utils.name_from_image"")\ndef test_create_sagemaker_model_tags(name_from_image, prepare_container_def, sagemaker_session):\n    container_def = {""Image"": MODEL_IMAGE, ""Environment"": {}, ""ModelDataUrl"": MODEL_DATA}\n    prepare_container_def.return_value = container_def\n\n    name_from_image.return_value = MODEL_NAME\n\n    model = Model(MODEL_DATA, MODEL_IMAGE, sagemaker_session=sagemaker_session)\n\n    tags = {""Key"": ""foo"", ""Value"": ""bar""}\n    model._create_sagemaker_model(INSTANCE_TYPE, tags=tags)\n\n    sagemaker_session.create_model.assert_called_with(\n        MODEL_NAME, None, container_def, vpc_config=None, enable_network_isolation=False, tags=tags\n    )\n\n\n@patch(""sagemaker.model.Model.prepare_container_def"")\n@patch(""sagemaker.utils.name_from_image"")\ndef test_create_sagemaker_model_optional_model_params(\n    name_from_image, prepare_container_def, sagemaker_session\n):\n    container_def = {""Image"": MODEL_IMAGE, ""Environment"": {}, ""ModelDataUrl"": MODEL_DATA}\n    prepare_container_def.return_value = container_def\n\n    vpc_config = {""Subnets"": [""123""], ""SecurityGroupIds"": [""456"", ""789""]}\n\n    model = Model(\n        MODEL_DATA,\n        MODEL_IMAGE,\n        name=MODEL_NAME,\n        role=ROLE,\n        vpc_config=vpc_config,\n        enable_network_isolation=True,\n        sagemaker_session=sagemaker_session,\n    )\n    model._create_sagemaker_model(INSTANCE_TYPE)\n\n    name_from_image.assert_not_called()\n\n    sagemaker_session.create_model.assert_called_with(\n        MODEL_NAME,\n        ROLE,\n        container_def,\n        vpc_config=vpc_config,\n        enable_network_isolation=True,\n        tags=None,\n    )\n\n\n@patch(""sagemaker.session.Session"")\n@patch(""sagemaker.local.LocalSession"")\ndef test_create_sagemaker_model_creates_correct_session(local_session, session):\n    model = Model(MODEL_DATA, MODEL_IMAGE)\n    model._create_sagemaker_model(""local"")\n    assert model.sagemaker_session == local_session.return_value\n\n    model = Model(MODEL_DATA, MODEL_IMAGE)\n    model._create_sagemaker_model(""ml.m5.xlarge"")\n    assert model.sagemaker_session == session.return_value\n\n\n@patch(""sagemaker.model.Model._create_sagemaker_model"")\ndef test_model_create_transformer(create_sagemaker_model, sagemaker_session):\n    model_name = ""auto-generated-model""\n    model = Model(MODEL_DATA, MODEL_IMAGE, name=model_name, sagemaker_session=sagemaker_session)\n\n    instance_type = ""ml.m4.xlarge""\n    transformer = model.transformer(instance_count=1, instance_type=instance_type)\n\n    create_sagemaker_model.assert_called_with(instance_type, tags=None)\n\n    assert isinstance(transformer, sagemaker.transformer.Transformer)\n    assert transformer.model_name == model_name\n    assert transformer.instance_type == instance_type\n    assert transformer.instance_count == 1\n    assert transformer.sagemaker_session == sagemaker_session\n    assert transformer.base_transform_job_name == model_name\n\n    assert transformer.strategy is None\n    assert transformer.env is None\n    assert transformer.output_path is None\n    assert transformer.output_kms_key is None\n    assert transformer.accept is None\n    assert transformer.assemble_with is None\n    assert transformer.volume_kms_key is None\n    assert transformer.max_concurrent_transforms is None\n    assert transformer.max_payload is None\n    assert transformer.tags is None\n\n\n@patch(""sagemaker.model.Model._create_sagemaker_model"")\ndef test_model_create_transformer_optional_params(create_sagemaker_model, sagemaker_session):\n    model = Model(MODEL_DATA, MODEL_IMAGE, sagemaker_session=sagemaker_session)\n\n    instance_type = ""ml.m4.xlarge""\n    strategy = ""MultiRecord""\n    assemble_with = ""Line""\n    output_path = ""s3://bucket/path""\n    kms_key = ""key""\n    accept = ""text/csv""\n    env = {""test"": True}\n    max_concurrent_transforms = 1\n    max_payload = 6\n    tags = [{""Key"": ""k"", ""Value"": ""v""}]\n\n    transformer = model.transformer(\n        instance_count=1,\n        instance_type=instance_type,\n        strategy=strategy,\n        assemble_with=assemble_with,\n        output_path=output_path,\n        output_kms_key=kms_key,\n        accept=accept,\n        env=env,\n        max_concurrent_transforms=max_concurrent_transforms,\n        max_payload=max_payload,\n        tags=tags,\n        volume_kms_key=kms_key,\n    )\n\n    create_sagemaker_model.assert_called_with(instance_type, tags=tags)\n\n    assert isinstance(transformer, sagemaker.transformer.Transformer)\n    assert transformer.strategy == strategy\n    assert transformer.assemble_with == assemble_with\n    assert transformer.output_path == output_path\n    assert transformer.output_kms_key == kms_key\n    assert transformer.accept == accept\n    assert transformer.max_concurrent_transforms == max_concurrent_transforms\n    assert transformer.max_payload == max_payload\n    assert transformer.env == env\n    assert transformer.tags == tags\n    assert transformer.volume_kms_key == kms_key\n\n\n@patch(""sagemaker.model.Model._create_sagemaker_model"")\ndef test_model_create_transformer_network_isolation(create_sagemaker_model, sagemaker_session):\n    model = Model(\n        MODEL_DATA, MODEL_IMAGE, sagemaker_session=sagemaker_session, enable_network_isolation=True\n    )\n\n    transformer = model.transformer(1, ""ml.m4.xlarge"", env={""should_be"": ""overwritten""})\n    assert transformer.env is None\n\n\n@patch(""sagemaker.session.Session"")\n@patch(""sagemaker.local.LocalSession"")\ndef test_transformer_creates_correct_session(local_session, session):\n    model = Model(MODEL_DATA, MODEL_IMAGE, sagemaker_session=None)\n    transformer = model.transformer(instance_count=1, instance_type=""local"")\n    assert model.sagemaker_session == local_session.return_value\n    assert transformer.sagemaker_session == local_session.return_value\n\n    model = Model(MODEL_DATA, MODEL_IMAGE, sagemaker_session=None)\n    transformer = model.transformer(instance_count=1, instance_type=""ml.m5.xlarge"")\n    assert model.sagemaker_session == session.return_value\n    assert transformer.sagemaker_session == session.return_value\n\n\ndef test_delete_model(sagemaker_session):\n    model = Model(MODEL_DATA, MODEL_IMAGE, name=MODEL_NAME, sagemaker_session=sagemaker_session)\n\n    model.delete_model()\n    sagemaker_session.delete_model.assert_called_with(model.name)\n\n\ndef test_delete_model_no_name(sagemaker_session):\n    model = Model(MODEL_DATA, MODEL_IMAGE, sagemaker_session=sagemaker_session)\n\n    with pytest.raises(\n        ValueError, match=""The SageMaker model must be created first before attempting to delete.""\n    ):\n        model.delete_model()\n    sagemaker_session.delete_model.assert_not_called()\n'"
tests/unit/sagemaker/model/test_model_package.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport copy\n\nimport pytest\nfrom mock import Mock, patch\n\nimport sagemaker\nfrom sagemaker.model import ModelPackage\n\nDESCRIBE_MODEL_PACKAGE_RESPONSE = {\n    ""InferenceSpecification"": {\n        ""SupportedResponseMIMETypes"": [""text""],\n        ""SupportedContentTypes"": [""text/csv""],\n        ""SupportedTransformInstanceTypes"": [""ml.m4.xlarge"", ""ml.m4.2xlarge""],\n        ""Containers"": [\n            {\n                ""Image"": ""1.dkr.ecr.us-east-2.amazonaws.com/decision-trees-sample:latest"",\n                ""ImageDigest"": ""sha256:1234556789"",\n                ""ModelDataUrl"": ""s3://bucket/output/model.tar.gz"",\n            }\n        ],\n        ""SupportedRealtimeInferenceInstanceTypes"": [""ml.m4.xlarge"", ""ml.m4.2xlarge""],\n    },\n    ""ModelPackageDescription"": ""Model Package created from training with ""\n    ""arn:aws:sagemaker:us-east-2:1234:algorithm/scikit-decision-trees"",\n    ""CreationTime"": 1542752036.687,\n    ""ModelPackageArn"": ""arn:aws:sagemaker:us-east-2:123:model-package/mp-scikit-decision-trees"",\n    ""ModelPackageStatusDetails"": {""ValidationStatuses"": [], ""ImageScanStatuses"": []},\n    ""SourceAlgorithmSpecification"": {\n        ""SourceAlgorithms"": [\n            {\n                ""ModelDataUrl"": ""s3://bucket/output/model.tar.gz"",\n                ""AlgorithmName"": ""arn:aws:sagemaker:us-east-2:1234:algorithm/scikit-decision-trees"",\n            }\n        ]\n    },\n    ""ModelPackageStatus"": ""Completed"",\n    ""ModelPackageName"": ""mp-scikit-decision-trees-1542410022-2018-11-20-22-13-56-502"",\n    ""CertifyForMarketplace"": False,\n}\n\n\n@pytest.fixture\ndef sagemaker_session():\n    return Mock()\n\n\ndef test_model_package_enable_network_isolation_with_no_product_id(sagemaker_session):\n    sagemaker_session.sagemaker_client.describe_model_package = Mock(\n        return_value=DESCRIBE_MODEL_PACKAGE_RESPONSE\n    )\n\n    model_package = ModelPackage(\n        role=""role"", model_package_arn=""my-model-package"", sagemaker_session=sagemaker_session\n    )\n    assert model_package.enable_network_isolation() is False\n\n\ndef test_model_package_enable_network_isolation_with_product_id(sagemaker_session):\n    model_package_response = copy.deepcopy(DESCRIBE_MODEL_PACKAGE_RESPONSE)\n    model_package_response[""InferenceSpecification""][""Containers""].append(\n        {\n            ""Image"": ""1.dkr.ecr.us-east-2.amazonaws.com/some-container:latest"",\n            ""ModelDataUrl"": ""s3://bucket/output/model.tar.gz"",\n            ""ProductId"": ""some-product-id"",\n        }\n    )\n    sagemaker_session.sagemaker_client.describe_model_package = Mock(\n        return_value=model_package_response\n    )\n\n    model_package = ModelPackage(\n        role=""role"", model_package_arn=""my-model-package"", sagemaker_session=sagemaker_session\n    )\n    assert model_package.enable_network_isolation() is True\n\n\n@patch(""sagemaker.model.ModelPackage._create_sagemaker_model"", Mock())\ndef test_model_package_create_transformer(sagemaker_session):\n    sagemaker_session.sagemaker_client.describe_model_package = Mock(\n        return_value=DESCRIBE_MODEL_PACKAGE_RESPONSE\n    )\n\n    model_package = ModelPackage(\n        role=""role"", model_package_arn=""my-model-package"", sagemaker_session=sagemaker_session\n    )\n    model_package.name = ""auto-generated-model""\n    transformer = model_package.transformer(\n        instance_count=1, instance_type=""ml.m4.xlarge"", env={""test"": True}\n    )\n    assert isinstance(transformer, sagemaker.transformer.Transformer)\n    assert transformer.model_name == ""auto-generated-model""\n    assert transformer.instance_type == ""ml.m4.xlarge""\n    assert transformer.env == {""test"": True}\n\n\n@patch(""sagemaker.model.ModelPackage._create_sagemaker_model"", Mock())\ndef test_model_package_create_transformer_with_product_id(sagemaker_session):\n    model_package_response = copy.deepcopy(DESCRIBE_MODEL_PACKAGE_RESPONSE)\n    model_package_response[""InferenceSpecification""][""Containers""].append(\n        {\n            ""Image"": ""1.dkr.ecr.us-east-2.amazonaws.com/some-container:latest"",\n            ""ModelDataUrl"": ""s3://bucket/output/model.tar.gz"",\n            ""ProductId"": ""some-product-id"",\n        }\n    )\n    sagemaker_session.sagemaker_client.describe_model_package = Mock(\n        return_value=model_package_response\n    )\n\n    model_package = ModelPackage(\n        role=""role"", model_package_arn=""my-model-package"", sagemaker_session=sagemaker_session\n    )\n    model_package.name = ""auto-generated-model""\n    transformer = model_package.transformer(\n        instance_count=1, instance_type=""ml.m4.xlarge"", env={""test"": True}\n    )\n    assert isinstance(transformer, sagemaker.transformer.Transformer)\n    assert transformer.model_name == ""auto-generated-model""\n    assert transformer.instance_type == ""ml.m4.xlarge""\n    assert transformer.env is None\n'"
tests/unit/sagemaker/model/test_neo.py,0,"b'# Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport boto3\nimport pytest\nfrom mock import Mock, patch\n\nfrom sagemaker.model import Model\nfrom tests.unit import NEO_REGION_LIST\n\nMODEL_DATA = ""s3://bucket/model.tar.gz""\nMODEL_IMAGE = ""mi""\n\nREGION = ""us-west-2""\n\nNEO_REGION_ACCOUNT = ""301217895009""\nDESCRIBE_COMPILATION_JOB_RESPONSE = {\n    ""CompilationJobStatus"": ""Completed"",\n    ""ModelArtifacts"": {""S3ModelArtifacts"": ""s3://output-path/model.tar.gz""},\n}\n\n\n@pytest.fixture\ndef sagemaker_session():\n    return Mock(boto_region_name=REGION)\n\n\ndef _create_model(sagemaker_session=None):\n    return Model(MODEL_DATA, MODEL_IMAGE, sagemaker_session=sagemaker_session)\n\n\ndef test_compile_model_for_inferentia(sagemaker_session):\n    sagemaker_session.wait_for_compilation_job = Mock(\n        return_value=DESCRIBE_COMPILATION_JOB_RESPONSE\n    )\n    model = _create_model(sagemaker_session)\n    model.compile(\n        target_instance_family=""ml_inf"",\n        input_shape={""data"": [1, 3, 1024, 1024]},\n        output_path=""s3://output"",\n        role=""role"",\n        framework=""tensorflow"",\n        framework_version=""1.15.0"",\n        job_name=""compile-model"",\n    )\n    assert (\n        ""{}.dkr.ecr.{}.amazonaws.com/sagemaker-neo-tensorflow:1.15.0-inf-py3"".format(\n            NEO_REGION_ACCOUNT, REGION\n        )\n        == model.image\n    )\n    assert model._is_compiled_model is True\n\n\ndef test_compile_model_for_edge_device(sagemaker_session):\n    sagemaker_session.wait_for_compilation_job = Mock(\n        return_value=DESCRIBE_COMPILATION_JOB_RESPONSE\n    )\n    model = _create_model(sagemaker_session)\n    model.compile(\n        target_instance_family=""deeplens"",\n        input_shape={""data"": [1, 3, 1024, 1024]},\n        output_path=""s3://output"",\n        role=""role"",\n        framework=""tensorflow"",\n        job_name=""compile-model"",\n    )\n    assert model._is_compiled_model is False\n\n\ndef test_compile_model_for_edge_device_tflite(sagemaker_session):\n    sagemaker_session.wait_for_compilation_job = Mock(\n        return_value=DESCRIBE_COMPILATION_JOB_RESPONSE\n    )\n    model = _create_model(sagemaker_session)\n    model.compile(\n        target_instance_family=""deeplens"",\n        input_shape={""data"": [1, 3, 1024, 1024]},\n        output_path=""s3://output"",\n        role=""role"",\n        framework=""tflite"",\n        job_name=""tflite-compile-model"",\n    )\n    assert model._is_compiled_model is False\n\n\ndef test_compile_model_for_cloud(sagemaker_session):\n    sagemaker_session.wait_for_compilation_job = Mock(\n        return_value=DESCRIBE_COMPILATION_JOB_RESPONSE\n    )\n    model = _create_model(sagemaker_session)\n    model.compile(\n        target_instance_family=""ml_c4"",\n        input_shape={""data"": [1, 3, 1024, 1024]},\n        output_path=""s3://output"",\n        role=""role"",\n        framework=""tensorflow"",\n        job_name=""compile-model"",\n    )\n    assert model._is_compiled_model is True\n\n\ndef test_compile_model_for_cloud_tflite(sagemaker_session):\n    sagemaker_session.wait_for_compilation_job = Mock(\n        return_value=DESCRIBE_COMPILATION_JOB_RESPONSE\n    )\n    model = _create_model(sagemaker_session)\n    model.compile(\n        target_instance_family=""ml_c4"",\n        input_shape={""data"": [1, 3, 1024, 1024]},\n        output_path=""s3://output"",\n        role=""role"",\n        framework=""tflite"",\n        job_name=""tflite-compile-model"",\n    )\n    assert model._is_compiled_model is True\n\n\n@patch(""sagemaker.session.Session"")\ndef test_compile_creates_session(session):\n    session.return_value.boto_region_name = REGION\n\n    model = _create_model()\n    model.compile(\n        target_instance_family=""ml_c4"",\n        input_shape={""data"": [1, 3, 1024, 1024]},\n        output_path=""s3://output"",\n        role=""role"",\n        framework=""tensorflow"",\n        job_name=""compile-model"",\n    )\n\n    assert session.return_value == model.sagemaker_session\n\n\ndef test_check_neo_region(sagemaker_session):\n    sagemaker_session.wait_for_compilation_job = Mock(\n        return_value=DESCRIBE_COMPILATION_JOB_RESPONSE\n    )\n    model = _create_model(sagemaker_session)\n\n    boto_session = boto3.Session()\n    for partition in boto_session.get_available_partitions():\n        for region_name in boto_session.get_available_regions(""ec2"", partition_name=partition):\n            assert (region_name in NEO_REGION_LIST) is model.check_neo_region(region_name)\n'"
tests/unit/sagemaker/monitor/__init__.py,0,b''
tests/unit/sagemaker/monitor/test_cron_expression_generator.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nfrom sagemaker.model_monitor import CronExpressionGenerator\n\n\ndef test_cron_expression_generator_hourly_returns_expected_value():\n    assert CronExpressionGenerator.hourly() == ""cron(0 * ? * * *)""\n\n\ndef test_cron_expression_generator_daily_returns_expected_value_when_called_with_no_parameters():\n    assert CronExpressionGenerator.daily() == ""cron(0 0 ? * * *)""\n\n\ndef test_cron_expression_generator_daily_returns_expected_value_when_called_with_parameters():\n    assert CronExpressionGenerator.daily(hour=5) == ""cron(0 5 ? * * *)""\n\n\ndef test_cron_expression_generator_daily_every_x_hours_returns_expected_value_when_called_without_customizations():\n    assert CronExpressionGenerator.daily_every_x_hours(hour_interval=6) == ""cron(0 0/6 ? * * *)""\n\n\ndef test_cron_expression_generator_daily_every_x_hours_returns_expected_value_when_called_with_customizations():\n    assert (\n        CronExpressionGenerator.daily_every_x_hours(hour_interval=7, starting_hour=8)\n        == ""cron(0 8/7 ? * * *)""\n    )\n'"
tests/unit/sagemaker/monitor/test_data_capture_config.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nfrom mock import Mock\n\nfrom sagemaker.model_monitor import DataCaptureConfig\n\nDEFAULT_ENABLE_CAPTURE = True\nDEFAULT_SAMPLING_PERCENTAGE = 20\nDEFAULT_BUCKET_NAME = ""default-bucket""\nDEFAULT_DESTINATION_S3_URI = ""s3://{}/model-monitor/data-capture"".format(DEFAULT_BUCKET_NAME)\nDEFAULT_KMS_KEY_ID = None\nDEFAULT_CAPTURE_MODES = [""REQUEST"", ""RESPONSE""]\nDEFAULT_CSV_CONTENT_TYPES = [""text/csv""]\nDEFAULT_JSON_CONTENT_TYPES = [""application/json""]\n\nNON_DEFAULT_ENABLE_CAPTURE = False\nNON_DEFAULT_CAPTURE_STATUS = ""STOPPED""\nNON_DEFAULT_SAMPLING_PERCENTAGE = 97\nNON_DEFAULT_DESTINATION_S3_URI = ""s3://uri/""\nNON_DEFAULT_KMS_KEY_ID = ""my_kms_key_id""\nNON_DEFAULT_CAPTURE_MODES = [""RESPONSE""]\nNON_DEFAULT_CSV_CONTENT_TYPES = [""custom/csv-format""]\nNON_DEFAULT_JSON_CONTENT_TYPES = [""custom/json-format""]\n\n\ndef test_init_when_non_defaults_provided():\n    data_capture_config = DataCaptureConfig(\n        enable_capture=NON_DEFAULT_ENABLE_CAPTURE,\n        sampling_percentage=NON_DEFAULT_SAMPLING_PERCENTAGE,\n        destination_s3_uri=NON_DEFAULT_DESTINATION_S3_URI,\n        kms_key_id=NON_DEFAULT_KMS_KEY_ID,\n        csv_content_types=NON_DEFAULT_CSV_CONTENT_TYPES,\n        json_content_types=NON_DEFAULT_JSON_CONTENT_TYPES,\n    )\n\n    assert data_capture_config.enable_capture == NON_DEFAULT_ENABLE_CAPTURE\n    assert data_capture_config.sampling_percentage == NON_DEFAULT_SAMPLING_PERCENTAGE\n    assert data_capture_config.destination_s3_uri == NON_DEFAULT_DESTINATION_S3_URI\n    assert data_capture_config.kms_key_id == NON_DEFAULT_KMS_KEY_ID\n    assert data_capture_config.csv_content_types == NON_DEFAULT_CSV_CONTENT_TYPES\n    assert data_capture_config.json_content_types == NON_DEFAULT_JSON_CONTENT_TYPES\n\n\ndef test_init_when_optionals_not_provided():\n    sagemaker_session = Mock()\n    sagemaker_session.default_bucket.return_value = DEFAULT_BUCKET_NAME\n\n    data_capture_config = DataCaptureConfig(\n        enable_capture=DEFAULT_ENABLE_CAPTURE, sagemaker_session=sagemaker_session\n    )\n\n    assert data_capture_config.enable_capture == DEFAULT_ENABLE_CAPTURE\n    assert data_capture_config.sampling_percentage == DEFAULT_SAMPLING_PERCENTAGE\n    assert data_capture_config.destination_s3_uri == DEFAULT_DESTINATION_S3_URI\n    assert data_capture_config.kms_key_id == DEFAULT_KMS_KEY_ID\n    assert data_capture_config.csv_content_types == DEFAULT_CSV_CONTENT_TYPES\n    assert data_capture_config.json_content_types == DEFAULT_JSON_CONTENT_TYPES\n'"
tests/unit/sagemaker/monitor/test_model_monitoring.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nfrom __future__ import absolute_import\n\nimport pytest\nfrom mock import Mock  # , patch, mock_open, MagicMock\n\n# from mock import patch\n\n# from sagemaker.model_monitor import ModelMonitor\nfrom sagemaker.model_monitor import DefaultModelMonitor\nfrom sagemaker.model_monitor import ModelMonitor\nfrom sagemaker.model_monitor import MonitoringOutput\n\n# from sagemaker.processing import ProcessingInput, ProcessingOutput, Processor, ScriptProcessor\n# from sagemaker.sklearn.processing import SKLearnProcessor\nfrom sagemaker.model_monitor.dataset_format import DatasetFormat\nfrom sagemaker.network import NetworkConfig\n\n# from sagemaker.processing import ProcessingJob\n\nREGION = ""us-west-2""\nBUCKET_NAME = ""mybucket""\n\nROLE = ""arn:aws:iam::012345678901:role/SageMakerRole""\nINSTANCE_COUNT = 1\nINSTANCE_TYPE = ""ml.m5.10xlarge""\nVOLUME_SIZE_IN_GB = 2\nVOLUME_KMS_KEY = ""volume-kms-key""\nOUTPUT_KMS_KEY = ""output-kms-key""\nMAX_RUNTIME_IN_SECONDS = 3\nBASE_JOB_NAME = ""base-job-name""\nENV_KEY_1 = ""env_key_1""\nENV_VALUE_1 = ""env_key_1""\nENVIRONMENT = {ENV_KEY_1: ENV_VALUE_1}\nTAG_KEY_1 = ""tag_key_1""\nTAG_VALUE_1 = ""tag_value_1""\nTAGS = [{""Key"": TAG_KEY_1, ""Value"": TAG_VALUE_1}]\nNETWORK_CONFIG = NetworkConfig(enable_network_isolation=True)\nENABLE_CLOUDWATCH_METRICS = True\n\nBASELINE_DATASET_PATH = ""/my/local/path/baseline.csv""\nPREPROCESSOR_PATH = ""/my/local/path/preprocessor.py""\nPOSTPROCESSOR_PATH = ""/my/local/path/postprocessor.py""\nOUTPUT_S3_URI = ""s3://output-s3-uri/""\n\n\nCUSTOM_IMAGE_URI = ""012345678901.dkr.ecr.us-west-2.amazonaws.com/my-custom-image-uri""\n\nINTER_CONTAINER_ENCRYPTION_EXCEPTION_MSG = (\n    ""EnableInterContainerTrafficEncryption is not supported in Model Monitor. Please ensure that ""\n)\n""encrypt_inter_container_traffic=None when creating your NetworkConfig object.""\n\n\n# TODO-reinvent-2019: Continue to flesh these out.\n@pytest.fixture()\ndef sagemaker_session():\n    boto_mock = Mock(name=""boto_session"", region_name=REGION)\n    session_mock = Mock(\n        name=""sagemaker_session"",\n        boto_session=boto_mock,\n        boto_region_name=REGION,\n        config=None,\n        local_mode=False,\n    )\n    session_mock.default_bucket = Mock(name=""default_bucket"", return_value=BUCKET_NAME)\n    session_mock.upload_data = Mock(\n        name=""upload_data"", return_value=""mocked_s3_uri_from_upload_data""\n    )\n    session_mock.download_data = Mock(name=""download_data"")\n    return session_mock\n\n\n# @patch(""sagemaker.processing.Processor"")\n# @patch(""sagemaker.processing.Processor.run"")\n# @patch(""sagemaker.processing.Processor.processing_job"", return_value=ProcessingJob(\n#     sagemaker_session=sagemaker_session,\n#     inputs="""",\n#     outputs=""""\n# ))\ndef test_default_model_monitor_suggest_baseline(sagemaker_session):\n    my_default_monitor = DefaultModelMonitor(\n        role=ROLE,\n        instance_count=INSTANCE_COUNT,\n        instance_type=INSTANCE_TYPE,\n        volume_size_in_gb=VOLUME_SIZE_IN_GB,\n        volume_kms_key=VOLUME_KMS_KEY,\n        output_kms_key=OUTPUT_KMS_KEY,\n        max_runtime_in_seconds=MAX_RUNTIME_IN_SECONDS,\n        base_job_name=BASE_JOB_NAME,\n        sagemaker_session=sagemaker_session,\n        env=ENVIRONMENT,\n        tags=TAGS,\n        network_config=NETWORK_CONFIG,\n    )\n\n    my_default_monitor.suggest_baseline(\n        baseline_dataset=BASELINE_DATASET_PATH,\n        dataset_format=DatasetFormat.csv(header=False),\n        record_preprocessor_script=PREPROCESSOR_PATH,\n        post_analytics_processor_script=POSTPROCESSOR_PATH,\n        output_s3_uri=OUTPUT_S3_URI,\n        wait=False,\n        logs=False,\n    )\n\n    assert my_default_monitor.role == ROLE\n    assert my_default_monitor.instance_count == INSTANCE_COUNT\n    assert my_default_monitor.instance_type == INSTANCE_TYPE\n    assert my_default_monitor.volume_size_in_gb == VOLUME_SIZE_IN_GB\n    assert my_default_monitor.volume_kms_key == VOLUME_KMS_KEY\n    assert my_default_monitor.output_kms_key == OUTPUT_KMS_KEY\n    assert my_default_monitor.max_runtime_in_seconds == MAX_RUNTIME_IN_SECONDS\n    assert my_default_monitor.base_job_name == BASE_JOB_NAME\n    assert my_default_monitor.sagemaker_session == sagemaker_session\n    assert my_default_monitor.tags == TAGS\n    assert my_default_monitor.network_config == NETWORK_CONFIG\n\n    assert BASE_JOB_NAME in my_default_monitor.latest_baselining_job_name\n    assert my_default_monitor.latest_baselining_job_name != BASE_JOB_NAME\n\n    assert my_default_monitor.env[ENV_KEY_1] == ENV_VALUE_1\n\n    # processor().run.assert_called_once(\n    #\n    # )\n\n\ndef test_default_model_monitor_with_invalid_network_config(sagemaker_session):\n    invalid_network_config = NetworkConfig(encrypt_inter_container_traffic=False)\n    my_default_monitor = DefaultModelMonitor(\n        role=ROLE, sagemaker_session=sagemaker_session, network_config=invalid_network_config\n    )\n    with pytest.raises(ValueError) as exception:\n        my_default_monitor.create_monitoring_schedule(endpoint_input=""test_endpoint"")\n    assert INTER_CONTAINER_ENCRYPTION_EXCEPTION_MSG in str(exception.value)\n\n    with pytest.raises(ValueError) as exception:\n        my_default_monitor.update_monitoring_schedule()\n    assert INTER_CONTAINER_ENCRYPTION_EXCEPTION_MSG in str(exception.value)\n\n\ndef test_model_monitor_with_invalid_network_config(sagemaker_session):\n    invalid_network_config = NetworkConfig(encrypt_inter_container_traffic=False)\n    my_model_monitor = ModelMonitor(\n        role=ROLE,\n        image_uri=CUSTOM_IMAGE_URI,\n        sagemaker_session=sagemaker_session,\n        network_config=invalid_network_config,\n    )\n    with pytest.raises(ValueError) as exception:\n        my_model_monitor.create_monitoring_schedule(\n            endpoint_input=""test_endpoint"",\n            output=MonitoringOutput(\n                source=""/opt/ml/processing/output"", destination=""/opt/ml/processing/output""\n            ),\n        )\n    assert INTER_CONTAINER_ENCRYPTION_EXCEPTION_MSG in str(exception.value)\n\n    with pytest.raises(ValueError) as exception:\n        my_model_monitor.update_monitoring_schedule()\n    assert INTER_CONTAINER_ENCRYPTION_EXCEPTION_MSG in str(exception.value)\n'"
src/sagemaker/tensorflow/tensorflow_serving/apis/__init__.py,0,b''
src/sagemaker/tensorflow/tensorflow_serving/apis/classification_pb2.py,0,"b'# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: tensorflow_serving/apis/classification.proto\n\nimport sys\n\n_b = sys.version_info[0] < 3 and (lambda x: x) or (lambda x: x.encode(""latin1""))\nfrom google.protobuf import descriptor as _descriptor\nfrom google.protobuf import message as _message\nfrom google.protobuf import reflection as _reflection\nfrom google.protobuf import symbol_database as _symbol_database\nfrom google.protobuf import descriptor_pb2\n\n# @@protoc_insertion_point(imports)\n\n_sym_db = _symbol_database.Default()\n\n\nfrom tensorflow_serving.apis import input_pb2 as tensorflow__serving_dot_apis_dot_input__pb2\nfrom tensorflow_serving.apis import model_pb2 as tensorflow__serving_dot_apis_dot_model__pb2\n\n\nDESCRIPTOR = _descriptor.FileDescriptor(\n    name=""tensorflow_serving/apis/classification.proto"",\n    package=""tensorflow.serving"",\n    syntax=""proto3"",\n    serialized_pb=_b(\n        \'\\n,tensorflow_serving/apis/classification.proto\\x12\\x12tensorflow.serving\\x1a#tensorflow_serving/apis/input.proto\\x1a#tensorflow_serving/apis/model.proto""%\\n\\x05\\x43lass\\x12\\r\\n\\x05label\\x18\\x01 \\x01(\\t\\x12\\r\\n\\x05score\\x18\\x02 \\x01(\\x02""=\\n\\x0f\\x43lassifications\\x12*\\n\\x07\\x63lasses\\x18\\x01 \\x03(\\x0b\\x32\\x19.tensorflow.serving.Class""T\\n\\x14\\x43lassificationResult\\x12<\\n\\x0f\\x63lassifications\\x18\\x01 \\x03(\\x0b\\x32#.tensorflow.serving.Classifications""t\\n\\x15\\x43lassificationRequest\\x12\\x31\\n\\nmodel_spec\\x18\\x01 \\x01(\\x0b\\x32\\x1d.tensorflow.serving.ModelSpec\\x12(\\n\\x05input\\x18\\x02 \\x01(\\x0b\\x32\\x19.tensorflow.serving.Input""\\x85\\x01\\n\\x16\\x43lassificationResponse\\x12\\x31\\n\\nmodel_spec\\x18\\x02 \\x01(\\x0b\\x32\\x1d.tensorflow.serving.ModelSpec\\x12\\x38\\n\\x06result\\x18\\x01 \\x01(\\x0b\\x32(.tensorflow.serving.ClassificationResultB\\x03\\xf8\\x01\\x01\\x62\\x06proto3\'\n    ),\n    dependencies=[\n        tensorflow__serving_dot_apis_dot_input__pb2.DESCRIPTOR,\n        tensorflow__serving_dot_apis_dot_model__pb2.DESCRIPTOR,\n    ],\n)\n\n\n_CLASS = _descriptor.Descriptor(\n    name=""Class"",\n    full_name=""tensorflow.serving.Class"",\n    filename=None,\n    file=DESCRIPTOR,\n    containing_type=None,\n    fields=[\n        _descriptor.FieldDescriptor(\n            name=""label"",\n            full_name=""tensorflow.serving.Class.label"",\n            index=0,\n            number=1,\n            type=9,\n            cpp_type=9,\n            label=1,\n            has_default_value=False,\n            default_value=_b("""").decode(""utf-8""),\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n        _descriptor.FieldDescriptor(\n            name=""score"",\n            full_name=""tensorflow.serving.Class.score"",\n            index=1,\n            number=2,\n            type=2,\n            cpp_type=6,\n            label=1,\n            has_default_value=False,\n            default_value=float(0),\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n    ],\n    extensions=[],\n    nested_types=[],\n    enum_types=[],\n    options=None,\n    is_extendable=False,\n    syntax=""proto3"",\n    extension_ranges=[],\n    oneofs=[],\n    serialized_start=142,\n    serialized_end=179,\n)\n\n\n_CLASSIFICATIONS = _descriptor.Descriptor(\n    name=""Classifications"",\n    full_name=""tensorflow.serving.Classifications"",\n    filename=None,\n    file=DESCRIPTOR,\n    containing_type=None,\n    fields=[\n        _descriptor.FieldDescriptor(\n            name=""classes"",\n            full_name=""tensorflow.serving.Classifications.classes"",\n            index=0,\n            number=1,\n            type=11,\n            cpp_type=10,\n            label=3,\n            has_default_value=False,\n            default_value=[],\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        )\n    ],\n    extensions=[],\n    nested_types=[],\n    enum_types=[],\n    options=None,\n    is_extendable=False,\n    syntax=""proto3"",\n    extension_ranges=[],\n    oneofs=[],\n    serialized_start=181,\n    serialized_end=242,\n)\n\n\n_CLASSIFICATIONRESULT = _descriptor.Descriptor(\n    name=""ClassificationResult"",\n    full_name=""tensorflow.serving.ClassificationResult"",\n    filename=None,\n    file=DESCRIPTOR,\n    containing_type=None,\n    fields=[\n        _descriptor.FieldDescriptor(\n            name=""classifications"",\n            full_name=""tensorflow.serving.ClassificationResult.classifications"",\n            index=0,\n            number=1,\n            type=11,\n            cpp_type=10,\n            label=3,\n            has_default_value=False,\n            default_value=[],\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        )\n    ],\n    extensions=[],\n    nested_types=[],\n    enum_types=[],\n    options=None,\n    is_extendable=False,\n    syntax=""proto3"",\n    extension_ranges=[],\n    oneofs=[],\n    serialized_start=244,\n    serialized_end=328,\n)\n\n\n_CLASSIFICATIONREQUEST = _descriptor.Descriptor(\n    name=""ClassificationRequest"",\n    full_name=""tensorflow.serving.ClassificationRequest"",\n    filename=None,\n    file=DESCRIPTOR,\n    containing_type=None,\n    fields=[\n        _descriptor.FieldDescriptor(\n            name=""model_spec"",\n            full_name=""tensorflow.serving.ClassificationRequest.model_spec"",\n            index=0,\n            number=1,\n            type=11,\n            cpp_type=10,\n            label=1,\n            has_default_value=False,\n            default_value=None,\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n        _descriptor.FieldDescriptor(\n            name=""input"",\n            full_name=""tensorflow.serving.ClassificationRequest.input"",\n            index=1,\n            number=2,\n            type=11,\n            cpp_type=10,\n            label=1,\n            has_default_value=False,\n            default_value=None,\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n    ],\n    extensions=[],\n    nested_types=[],\n    enum_types=[],\n    options=None,\n    is_extendable=False,\n    syntax=""proto3"",\n    extension_ranges=[],\n    oneofs=[],\n    serialized_start=330,\n    serialized_end=446,\n)\n\n\n_CLASSIFICATIONRESPONSE = _descriptor.Descriptor(\n    name=""ClassificationResponse"",\n    full_name=""tensorflow.serving.ClassificationResponse"",\n    filename=None,\n    file=DESCRIPTOR,\n    containing_type=None,\n    fields=[\n        _descriptor.FieldDescriptor(\n            name=""model_spec"",\n            full_name=""tensorflow.serving.ClassificationResponse.model_spec"",\n            index=0,\n            number=2,\n            type=11,\n            cpp_type=10,\n            label=1,\n            has_default_value=False,\n            default_value=None,\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n        _descriptor.FieldDescriptor(\n            name=""result"",\n            full_name=""tensorflow.serving.ClassificationResponse.result"",\n            index=1,\n            number=1,\n            type=11,\n            cpp_type=10,\n            label=1,\n            has_default_value=False,\n            default_value=None,\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n    ],\n    extensions=[],\n    nested_types=[],\n    enum_types=[],\n    options=None,\n    is_extendable=False,\n    syntax=""proto3"",\n    extension_ranges=[],\n    oneofs=[],\n    serialized_start=449,\n    serialized_end=582,\n)\n\n_CLASSIFICATIONS.fields_by_name[""classes""].message_type = _CLASS\n_CLASSIFICATIONRESULT.fields_by_name[""classifications""].message_type = _CLASSIFICATIONS\n_CLASSIFICATIONREQUEST.fields_by_name[\n    ""model_spec""\n].message_type = tensorflow__serving_dot_apis_dot_model__pb2._MODELSPEC\n_CLASSIFICATIONREQUEST.fields_by_name[\n    ""input""\n].message_type = tensorflow__serving_dot_apis_dot_input__pb2._INPUT\n_CLASSIFICATIONRESPONSE.fields_by_name[\n    ""model_spec""\n].message_type = tensorflow__serving_dot_apis_dot_model__pb2._MODELSPEC\n_CLASSIFICATIONRESPONSE.fields_by_name[""result""].message_type = _CLASSIFICATIONRESULT\nDESCRIPTOR.message_types_by_name[""Class""] = _CLASS\nDESCRIPTOR.message_types_by_name[""Classifications""] = _CLASSIFICATIONS\nDESCRIPTOR.message_types_by_name[""ClassificationResult""] = _CLASSIFICATIONRESULT\nDESCRIPTOR.message_types_by_name[""ClassificationRequest""] = _CLASSIFICATIONREQUEST\nDESCRIPTOR.message_types_by_name[""ClassificationResponse""] = _CLASSIFICATIONRESPONSE\n_sym_db.RegisterFileDescriptor(DESCRIPTOR)\n\nClass = _reflection.GeneratedProtocolMessageType(\n    ""Class"",\n    (_message.Message,),\n    dict(\n        DESCRIPTOR=_CLASS,\n        __module__=""tensorflow_serving.apis.classification_pb2""\n        # @@protoc_insertion_point(class_scope:tensorflow.serving.Class)\n    ),\n)\n_sym_db.RegisterMessage(Class)\n\nClassifications = _reflection.GeneratedProtocolMessageType(\n    ""Classifications"",\n    (_message.Message,),\n    dict(\n        DESCRIPTOR=_CLASSIFICATIONS,\n        __module__=""tensorflow_serving.apis.classification_pb2""\n        # @@protoc_insertion_point(class_scope:tensorflow.serving.Classifications)\n    ),\n)\n_sym_db.RegisterMessage(Classifications)\n\nClassificationResult = _reflection.GeneratedProtocolMessageType(\n    ""ClassificationResult"",\n    (_message.Message,),\n    dict(\n        DESCRIPTOR=_CLASSIFICATIONRESULT,\n        __module__=""tensorflow_serving.apis.classification_pb2""\n        # @@protoc_insertion_point(class_scope:tensorflow.serving.ClassificationResult)\n    ),\n)\n_sym_db.RegisterMessage(ClassificationResult)\n\nClassificationRequest = _reflection.GeneratedProtocolMessageType(\n    ""ClassificationRequest"",\n    (_message.Message,),\n    dict(\n        DESCRIPTOR=_CLASSIFICATIONREQUEST,\n        __module__=""tensorflow_serving.apis.classification_pb2""\n        # @@protoc_insertion_point(class_scope:tensorflow.serving.ClassificationRequest)\n    ),\n)\n_sym_db.RegisterMessage(ClassificationRequest)\n\nClassificationResponse = _reflection.GeneratedProtocolMessageType(\n    ""ClassificationResponse"",\n    (_message.Message,),\n    dict(\n        DESCRIPTOR=_CLASSIFICATIONRESPONSE,\n        __module__=""tensorflow_serving.apis.classification_pb2""\n        # @@protoc_insertion_point(class_scope:tensorflow.serving.ClassificationResponse)\n    ),\n)\n_sym_db.RegisterMessage(ClassificationResponse)\n\n\nDESCRIPTOR.has_options = True\nDESCRIPTOR._options = _descriptor._ParseOptions(descriptor_pb2.FileOptions(), _b(""\\370\\001\\001""))\n# @@protoc_insertion_point(module_scope)\n'"
src/sagemaker/tensorflow/tensorflow_serving/apis/get_model_metadata_pb2.py,0,"b'# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: tensorflow_serving/apis/get_model_metadata.proto\n\nimport sys\n\n_b = sys.version_info[0] < 3 and (lambda x: x) or (lambda x: x.encode(""latin1""))\nfrom google.protobuf import descriptor as _descriptor\nfrom google.protobuf import message as _message\nfrom google.protobuf import reflection as _reflection\nfrom google.protobuf import symbol_database as _symbol_database\nfrom google.protobuf import descriptor_pb2\n\n# @@protoc_insertion_point(imports)\n\n_sym_db = _symbol_database.Default()\n\n\nfrom google.protobuf import any_pb2 as google_dot_protobuf_dot_any__pb2\nfrom tensorflow.core.protobuf import (\n    meta_graph_pb2 as tensorflow_dot_core_dot_protobuf_dot_meta__graph__pb2,\n)\nfrom tensorflow_serving.apis import model_pb2 as tensorflow__serving_dot_apis_dot_model__pb2\n\n\nDESCRIPTOR = _descriptor.FileDescriptor(\n    name=""tensorflow_serving/apis/get_model_metadata.proto"",\n    package=""tensorflow.serving"",\n    syntax=""proto3"",\n    serialized_pb=_b(\n        \'\\n0tensorflow_serving/apis/get_model_metadata.proto\\x12\\x12tensorflow.serving\\x1a\\x19google/protobuf/any.proto\\x1a)tensorflow/core/protobuf/meta_graph.proto\\x1a#tensorflow_serving/apis/model.proto""\\xae\\x01\\n\\x0fSignatureDefMap\\x12L\\n\\rsignature_def\\x18\\x01 \\x03(\\x0b\\x32\\x35.tensorflow.serving.SignatureDefMap.SignatureDefEntry\\x1aM\\n\\x11SignatureDefEntry\\x12\\x0b\\n\\x03key\\x18\\x01 \\x01(\\t\\x12\\\'\\n\\x05value\\x18\\x02 \\x01(\\x0b\\x32\\x18.tensorflow.SignatureDef:\\x02\\x38\\x01""d\\n\\x17GetModelMetadataRequest\\x12\\x31\\n\\nmodel_spec\\x18\\x01 \\x01(\\x0b\\x32\\x1d.tensorflow.serving.ModelSpec\\x12\\x16\\n\\x0emetadata_field\\x18\\x02 \\x03(\\t""\\xe2\\x01\\n\\x18GetModelMetadataResponse\\x12\\x31\\n\\nmodel_spec\\x18\\x01 \\x01(\\x0b\\x32\\x1d.tensorflow.serving.ModelSpec\\x12L\\n\\x08metadata\\x18\\x02 \\x03(\\x0b\\x32:.tensorflow.serving.GetModelMetadataResponse.MetadataEntry\\x1a\\x45\\n\\rMetadataEntry\\x12\\x0b\\n\\x03key\\x18\\x01 \\x01(\\t\\x12#\\n\\x05value\\x18\\x02 \\x01(\\x0b\\x32\\x14.google.protobuf.Any:\\x02\\x38\\x01\\x42\\x03\\xf8\\x01\\x01\\x62\\x06proto3\'\n    ),\n    dependencies=[\n        google_dot_protobuf_dot_any__pb2.DESCRIPTOR,\n        tensorflow_dot_core_dot_protobuf_dot_meta__graph__pb2.DESCRIPTOR,\n        tensorflow__serving_dot_apis_dot_model__pb2.DESCRIPTOR,\n    ],\n)\n\n\n_SIGNATUREDEFMAP_SIGNATUREDEFENTRY = _descriptor.Descriptor(\n    name=""SignatureDefEntry"",\n    full_name=""tensorflow.serving.SignatureDefMap.SignatureDefEntry"",\n    filename=None,\n    file=DESCRIPTOR,\n    containing_type=None,\n    fields=[\n        _descriptor.FieldDescriptor(\n            name=""key"",\n            full_name=""tensorflow.serving.SignatureDefMap.SignatureDefEntry.key"",\n            index=0,\n            number=1,\n            type=9,\n            cpp_type=9,\n            label=1,\n            has_default_value=False,\n            default_value=_b("""").decode(""utf-8""),\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n        _descriptor.FieldDescriptor(\n            name=""value"",\n            full_name=""tensorflow.serving.SignatureDefMap.SignatureDefEntry.value"",\n            index=1,\n            number=2,\n            type=11,\n            cpp_type=10,\n            label=1,\n            has_default_value=False,\n            default_value=None,\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n    ],\n    extensions=[],\n    nested_types=[],\n    enum_types=[],\n    options=_descriptor._ParseOptions(descriptor_pb2.MessageOptions(), _b(""8\\001"")),\n    is_extendable=False,\n    syntax=""proto3"",\n    extension_ranges=[],\n    oneofs=[],\n    serialized_start=277,\n    serialized_end=354,\n)\n\n_SIGNATUREDEFMAP = _descriptor.Descriptor(\n    name=""SignatureDefMap"",\n    full_name=""tensorflow.serving.SignatureDefMap"",\n    filename=None,\n    file=DESCRIPTOR,\n    containing_type=None,\n    fields=[\n        _descriptor.FieldDescriptor(\n            name=""signature_def"",\n            full_name=""tensorflow.serving.SignatureDefMap.signature_def"",\n            index=0,\n            number=1,\n            type=11,\n            cpp_type=10,\n            label=3,\n            has_default_value=False,\n            default_value=[],\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        )\n    ],\n    extensions=[],\n    nested_types=[_SIGNATUREDEFMAP_SIGNATUREDEFENTRY],\n    enum_types=[],\n    options=None,\n    is_extendable=False,\n    syntax=""proto3"",\n    extension_ranges=[],\n    oneofs=[],\n    serialized_start=180,\n    serialized_end=354,\n)\n\n\n_GETMODELMETADATAREQUEST = _descriptor.Descriptor(\n    name=""GetModelMetadataRequest"",\n    full_name=""tensorflow.serving.GetModelMetadataRequest"",\n    filename=None,\n    file=DESCRIPTOR,\n    containing_type=None,\n    fields=[\n        _descriptor.FieldDescriptor(\n            name=""model_spec"",\n            full_name=""tensorflow.serving.GetModelMetadataRequest.model_spec"",\n            index=0,\n            number=1,\n            type=11,\n            cpp_type=10,\n            label=1,\n            has_default_value=False,\n            default_value=None,\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n        _descriptor.FieldDescriptor(\n            name=""metadata_field"",\n            full_name=""tensorflow.serving.GetModelMetadataRequest.metadata_field"",\n            index=1,\n            number=2,\n            type=9,\n            cpp_type=9,\n            label=3,\n            has_default_value=False,\n            default_value=[],\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n    ],\n    extensions=[],\n    nested_types=[],\n    enum_types=[],\n    options=None,\n    is_extendable=False,\n    syntax=""proto3"",\n    extension_ranges=[],\n    oneofs=[],\n    serialized_start=356,\n    serialized_end=456,\n)\n\n\n_GETMODELMETADATARESPONSE_METADATAENTRY = _descriptor.Descriptor(\n    name=""MetadataEntry"",\n    full_name=""tensorflow.serving.GetModelMetadataResponse.MetadataEntry"",\n    filename=None,\n    file=DESCRIPTOR,\n    containing_type=None,\n    fields=[\n        _descriptor.FieldDescriptor(\n            name=""key"",\n            full_name=""tensorflow.serving.GetModelMetadataResponse.MetadataEntry.key"",\n            index=0,\n            number=1,\n            type=9,\n            cpp_type=9,\n            label=1,\n            has_default_value=False,\n            default_value=_b("""").decode(""utf-8""),\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n        _descriptor.FieldDescriptor(\n            name=""value"",\n            full_name=""tensorflow.serving.GetModelMetadataResponse.MetadataEntry.value"",\n            index=1,\n            number=2,\n            type=11,\n            cpp_type=10,\n            label=1,\n            has_default_value=False,\n            default_value=None,\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n    ],\n    extensions=[],\n    nested_types=[],\n    enum_types=[],\n    options=_descriptor._ParseOptions(descriptor_pb2.MessageOptions(), _b(""8\\001"")),\n    is_extendable=False,\n    syntax=""proto3"",\n    extension_ranges=[],\n    oneofs=[],\n    serialized_start=616,\n    serialized_end=685,\n)\n\n_GETMODELMETADATARESPONSE = _descriptor.Descriptor(\n    name=""GetModelMetadataResponse"",\n    full_name=""tensorflow.serving.GetModelMetadataResponse"",\n    filename=None,\n    file=DESCRIPTOR,\n    containing_type=None,\n    fields=[\n        _descriptor.FieldDescriptor(\n            name=""model_spec"",\n            full_name=""tensorflow.serving.GetModelMetadataResponse.model_spec"",\n            index=0,\n            number=1,\n            type=11,\n            cpp_type=10,\n            label=1,\n            has_default_value=False,\n            default_value=None,\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n        _descriptor.FieldDescriptor(\n            name=""metadata"",\n            full_name=""tensorflow.serving.GetModelMetadataResponse.metadata"",\n            index=1,\n            number=2,\n            type=11,\n            cpp_type=10,\n            label=3,\n            has_default_value=False,\n            default_value=[],\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n    ],\n    extensions=[],\n    nested_types=[_GETMODELMETADATARESPONSE_METADATAENTRY],\n    enum_types=[],\n    options=None,\n    is_extendable=False,\n    syntax=""proto3"",\n    extension_ranges=[],\n    oneofs=[],\n    serialized_start=459,\n    serialized_end=685,\n)\n\n_SIGNATUREDEFMAP_SIGNATUREDEFENTRY.fields_by_name[\n    ""value""\n].message_type = tensorflow_dot_core_dot_protobuf_dot_meta__graph__pb2._SIGNATUREDEF\n_SIGNATUREDEFMAP_SIGNATUREDEFENTRY.containing_type = _SIGNATUREDEFMAP\n_SIGNATUREDEFMAP.fields_by_name[""signature_def""].message_type = _SIGNATUREDEFMAP_SIGNATUREDEFENTRY\n_GETMODELMETADATAREQUEST.fields_by_name[\n    ""model_spec""\n].message_type = tensorflow__serving_dot_apis_dot_model__pb2._MODELSPEC\n_GETMODELMETADATARESPONSE_METADATAENTRY.fields_by_name[\n    ""value""\n].message_type = google_dot_protobuf_dot_any__pb2._ANY\n_GETMODELMETADATARESPONSE_METADATAENTRY.containing_type = _GETMODELMETADATARESPONSE\n_GETMODELMETADATARESPONSE.fields_by_name[\n    ""model_spec""\n].message_type = tensorflow__serving_dot_apis_dot_model__pb2._MODELSPEC\n_GETMODELMETADATARESPONSE.fields_by_name[\n    ""metadata""\n].message_type = _GETMODELMETADATARESPONSE_METADATAENTRY\nDESCRIPTOR.message_types_by_name[""SignatureDefMap""] = _SIGNATUREDEFMAP\nDESCRIPTOR.message_types_by_name[""GetModelMetadataRequest""] = _GETMODELMETADATAREQUEST\nDESCRIPTOR.message_types_by_name[""GetModelMetadataResponse""] = _GETMODELMETADATARESPONSE\n_sym_db.RegisterFileDescriptor(DESCRIPTOR)\n\nSignatureDefMap = _reflection.GeneratedProtocolMessageType(\n    ""SignatureDefMap"",\n    (_message.Message,),\n    dict(\n        SignatureDefEntry=_reflection.GeneratedProtocolMessageType(\n            ""SignatureDefEntry"",\n            (_message.Message,),\n            dict(\n                DESCRIPTOR=_SIGNATUREDEFMAP_SIGNATUREDEFENTRY,\n                __module__=""tensorflow_serving.apis.get_model_metadata_pb2""\n                # @@protoc_insertion_point(class_scope:tensorflow.serving.SignatureDefMap.SignatureDefEntry)\n            ),\n        ),\n        DESCRIPTOR=_SIGNATUREDEFMAP,\n        __module__=""tensorflow_serving.apis.get_model_metadata_pb2""\n        # @@protoc_insertion_point(class_scope:tensorflow.serving.SignatureDefMap)\n    ),\n)\n_sym_db.RegisterMessage(SignatureDefMap)\n_sym_db.RegisterMessage(SignatureDefMap.SignatureDefEntry)\n\nGetModelMetadataRequest = _reflection.GeneratedProtocolMessageType(\n    ""GetModelMetadataRequest"",\n    (_message.Message,),\n    dict(\n        DESCRIPTOR=_GETMODELMETADATAREQUEST,\n        __module__=""tensorflow_serving.apis.get_model_metadata_pb2""\n        # @@protoc_insertion_point(class_scope:tensorflow.serving.GetModelMetadataRequest)\n    ),\n)\n_sym_db.RegisterMessage(GetModelMetadataRequest)\n\nGetModelMetadataResponse = _reflection.GeneratedProtocolMessageType(\n    ""GetModelMetadataResponse"",\n    (_message.Message,),\n    dict(\n        MetadataEntry=_reflection.GeneratedProtocolMessageType(\n            ""MetadataEntry"",\n            (_message.Message,),\n            dict(\n                DESCRIPTOR=_GETMODELMETADATARESPONSE_METADATAENTRY,\n                __module__=""tensorflow_serving.apis.get_model_metadata_pb2""\n                # @@protoc_insertion_point(class_scope:tensorflow.serving.GetModelMetadataResponse.MetadataEntry)\n            ),\n        ),\n        DESCRIPTOR=_GETMODELMETADATARESPONSE,\n        __module__=""tensorflow_serving.apis.get_model_metadata_pb2""\n        # @@protoc_insertion_point(class_scope:tensorflow.serving.GetModelMetadataResponse)\n    ),\n)\n_sym_db.RegisterMessage(GetModelMetadataResponse)\n_sym_db.RegisterMessage(GetModelMetadataResponse.MetadataEntry)\n\n\nDESCRIPTOR.has_options = True\nDESCRIPTOR._options = _descriptor._ParseOptions(descriptor_pb2.FileOptions(), _b(""\\370\\001\\001""))\n_SIGNATUREDEFMAP_SIGNATUREDEFENTRY.has_options = True\n_SIGNATUREDEFMAP_SIGNATUREDEFENTRY._options = _descriptor._ParseOptions(\n    descriptor_pb2.MessageOptions(), _b(""8\\001"")\n)\n_GETMODELMETADATARESPONSE_METADATAENTRY.has_options = True\n_GETMODELMETADATARESPONSE_METADATAENTRY._options = _descriptor._ParseOptions(\n    descriptor_pb2.MessageOptions(), _b(""8\\001"")\n)\n# @@protoc_insertion_point(module_scope)\n'"
src/sagemaker/tensorflow/tensorflow_serving/apis/inference_pb2.py,0,"b'# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: tensorflow_serving/apis/inference.proto\n\nimport sys\n\n_b = sys.version_info[0] < 3 and (lambda x: x) or (lambda x: x.encode(""latin1""))\nfrom google.protobuf import descriptor as _descriptor\nfrom google.protobuf import message as _message\nfrom google.protobuf import reflection as _reflection\nfrom google.protobuf import symbol_database as _symbol_database\nfrom google.protobuf import descriptor_pb2\n\n# @@protoc_insertion_point(imports)\n\n_sym_db = _symbol_database.Default()\n\n\nfrom tensorflow_serving.apis import (\n    classification_pb2 as tensorflow__serving_dot_apis_dot_classification__pb2,\n)\nfrom tensorflow_serving.apis import input_pb2 as tensorflow__serving_dot_apis_dot_input__pb2\nfrom tensorflow_serving.apis import model_pb2 as tensorflow__serving_dot_apis_dot_model__pb2\nfrom tensorflow_serving.apis import (\n    regression_pb2 as tensorflow__serving_dot_apis_dot_regression__pb2,\n)\n\n\nDESCRIPTOR = _descriptor.FileDescriptor(\n    name=""tensorflow_serving/apis/inference.proto"",\n    package=""tensorflow.serving"",\n    syntax=""proto3"",\n    serialized_pb=_b(\n        \'\\n\\\'tensorflow_serving/apis/inference.proto\\x12\\x12tensorflow.serving\\x1a,tensorflow_serving/apis/classification.proto\\x1a#tensorflow_serving/apis/input.proto\\x1a#tensorflow_serving/apis/model.proto\\x1a(tensorflow_serving/apis/regression.proto""W\\n\\rInferenceTask\\x12\\x31\\n\\nmodel_spec\\x18\\x01 \\x01(\\x0b\\x32\\x1d.tensorflow.serving.ModelSpec\\x12\\x13\\n\\x0bmethod_name\\x18\\x02 \\x01(\\t""\\xdc\\x01\\n\\x0fInferenceResult\\x12\\x31\\n\\nmodel_spec\\x18\\x01 \\x01(\\x0b\\x32\\x1d.tensorflow.serving.ModelSpec\\x12I\\n\\x15\\x63lassification_result\\x18\\x02 \\x01(\\x0b\\x32(.tensorflow.serving.ClassificationResultH\\x00\\x12\\x41\\n\\x11regression_result\\x18\\x03 \\x01(\\x0b\\x32$.tensorflow.serving.RegressionResultH\\x00\\x42\\x08\\n\\x06result""s\\n\\x15MultiInferenceRequest\\x12\\x30\\n\\x05tasks\\x18\\x01 \\x03(\\x0b\\x32!.tensorflow.serving.InferenceTask\\x12(\\n\\x05input\\x18\\x02 \\x01(\\x0b\\x32\\x19.tensorflow.serving.Input""N\\n\\x16MultiInferenceResponse\\x12\\x34\\n\\x07results\\x18\\x01 \\x03(\\x0b\\x32#.tensorflow.serving.InferenceResultB\\x03\\xf8\\x01\\x01\\x62\\x06proto3\'\n    ),\n    dependencies=[\n        tensorflow__serving_dot_apis_dot_classification__pb2.DESCRIPTOR,\n        tensorflow__serving_dot_apis_dot_input__pb2.DESCRIPTOR,\n        tensorflow__serving_dot_apis_dot_model__pb2.DESCRIPTOR,\n        tensorflow__serving_dot_apis_dot_regression__pb2.DESCRIPTOR,\n    ],\n)\n\n\n_INFERENCETASK = _descriptor.Descriptor(\n    name=""InferenceTask"",\n    full_name=""tensorflow.serving.InferenceTask"",\n    filename=None,\n    file=DESCRIPTOR,\n    containing_type=None,\n    fields=[\n        _descriptor.FieldDescriptor(\n            name=""model_spec"",\n            full_name=""tensorflow.serving.InferenceTask.model_spec"",\n            index=0,\n            number=1,\n            type=11,\n            cpp_type=10,\n            label=1,\n            has_default_value=False,\n            default_value=None,\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n        _descriptor.FieldDescriptor(\n            name=""method_name"",\n            full_name=""tensorflow.serving.InferenceTask.method_name"",\n            index=1,\n            number=2,\n            type=9,\n            cpp_type=9,\n            label=1,\n            has_default_value=False,\n            default_value=_b("""").decode(""utf-8""),\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n    ],\n    extensions=[],\n    nested_types=[],\n    enum_types=[],\n    options=None,\n    is_extendable=False,\n    syntax=""proto3"",\n    extension_ranges=[],\n    oneofs=[],\n    serialized_start=225,\n    serialized_end=312,\n)\n\n\n_INFERENCERESULT = _descriptor.Descriptor(\n    name=""InferenceResult"",\n    full_name=""tensorflow.serving.InferenceResult"",\n    filename=None,\n    file=DESCRIPTOR,\n    containing_type=None,\n    fields=[\n        _descriptor.FieldDescriptor(\n            name=""model_spec"",\n            full_name=""tensorflow.serving.InferenceResult.model_spec"",\n            index=0,\n            number=1,\n            type=11,\n            cpp_type=10,\n            label=1,\n            has_default_value=False,\n            default_value=None,\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n        _descriptor.FieldDescriptor(\n            name=""classification_result"",\n            full_name=""tensorflow.serving.InferenceResult.classification_result"",\n            index=1,\n            number=2,\n            type=11,\n            cpp_type=10,\n            label=1,\n            has_default_value=False,\n            default_value=None,\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n        _descriptor.FieldDescriptor(\n            name=""regression_result"",\n            full_name=""tensorflow.serving.InferenceResult.regression_result"",\n            index=2,\n            number=3,\n            type=11,\n            cpp_type=10,\n            label=1,\n            has_default_value=False,\n            default_value=None,\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n    ],\n    extensions=[],\n    nested_types=[],\n    enum_types=[],\n    options=None,\n    is_extendable=False,\n    syntax=""proto3"",\n    extension_ranges=[],\n    oneofs=[\n        _descriptor.OneofDescriptor(\n            name=""result"",\n            full_name=""tensorflow.serving.InferenceResult.result"",\n            index=0,\n            containing_type=None,\n            fields=[],\n        )\n    ],\n    serialized_start=315,\n    serialized_end=535,\n)\n\n\n_MULTIINFERENCEREQUEST = _descriptor.Descriptor(\n    name=""MultiInferenceRequest"",\n    full_name=""tensorflow.serving.MultiInferenceRequest"",\n    filename=None,\n    file=DESCRIPTOR,\n    containing_type=None,\n    fields=[\n        _descriptor.FieldDescriptor(\n            name=""tasks"",\n            full_name=""tensorflow.serving.MultiInferenceRequest.tasks"",\n            index=0,\n            number=1,\n            type=11,\n            cpp_type=10,\n            label=3,\n            has_default_value=False,\n            default_value=[],\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n        _descriptor.FieldDescriptor(\n            name=""input"",\n            full_name=""tensorflow.serving.MultiInferenceRequest.input"",\n            index=1,\n            number=2,\n            type=11,\n            cpp_type=10,\n            label=1,\n            has_default_value=False,\n            default_value=None,\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n    ],\n    extensions=[],\n    nested_types=[],\n    enum_types=[],\n    options=None,\n    is_extendable=False,\n    syntax=""proto3"",\n    extension_ranges=[],\n    oneofs=[],\n    serialized_start=537,\n    serialized_end=652,\n)\n\n\n_MULTIINFERENCERESPONSE = _descriptor.Descriptor(\n    name=""MultiInferenceResponse"",\n    full_name=""tensorflow.serving.MultiInferenceResponse"",\n    filename=None,\n    file=DESCRIPTOR,\n    containing_type=None,\n    fields=[\n        _descriptor.FieldDescriptor(\n            name=""results"",\n            full_name=""tensorflow.serving.MultiInferenceResponse.results"",\n            index=0,\n            number=1,\n            type=11,\n            cpp_type=10,\n            label=3,\n            has_default_value=False,\n            default_value=[],\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        )\n    ],\n    extensions=[],\n    nested_types=[],\n    enum_types=[],\n    options=None,\n    is_extendable=False,\n    syntax=""proto3"",\n    extension_ranges=[],\n    oneofs=[],\n    serialized_start=654,\n    serialized_end=732,\n)\n\n_INFERENCETASK.fields_by_name[\n    ""model_spec""\n].message_type = tensorflow__serving_dot_apis_dot_model__pb2._MODELSPEC\n_INFERENCERESULT.fields_by_name[\n    ""model_spec""\n].message_type = tensorflow__serving_dot_apis_dot_model__pb2._MODELSPEC\n_INFERENCERESULT.fields_by_name[\n    ""classification_result""\n].message_type = tensorflow__serving_dot_apis_dot_classification__pb2._CLASSIFICATIONRESULT\n_INFERENCERESULT.fields_by_name[\n    ""regression_result""\n].message_type = tensorflow__serving_dot_apis_dot_regression__pb2._REGRESSIONRESULT\n_INFERENCERESULT.oneofs_by_name[""result""].fields.append(\n    _INFERENCERESULT.fields_by_name[""classification_result""]\n)\n_INFERENCERESULT.fields_by_name[\n    ""classification_result""\n].containing_oneof = _INFERENCERESULT.oneofs_by_name[""result""]\n_INFERENCERESULT.oneofs_by_name[""result""].fields.append(\n    _INFERENCERESULT.fields_by_name[""regression_result""]\n)\n_INFERENCERESULT.fields_by_name[\n    ""regression_result""\n].containing_oneof = _INFERENCERESULT.oneofs_by_name[""result""]\n_MULTIINFERENCEREQUEST.fields_by_name[""tasks""].message_type = _INFERENCETASK\n_MULTIINFERENCEREQUEST.fields_by_name[\n    ""input""\n].message_type = tensorflow__serving_dot_apis_dot_input__pb2._INPUT\n_MULTIINFERENCERESPONSE.fields_by_name[""results""].message_type = _INFERENCERESULT\nDESCRIPTOR.message_types_by_name[""InferenceTask""] = _INFERENCETASK\nDESCRIPTOR.message_types_by_name[""InferenceResult""] = _INFERENCERESULT\nDESCRIPTOR.message_types_by_name[""MultiInferenceRequest""] = _MULTIINFERENCEREQUEST\nDESCRIPTOR.message_types_by_name[""MultiInferenceResponse""] = _MULTIINFERENCERESPONSE\n_sym_db.RegisterFileDescriptor(DESCRIPTOR)\n\nInferenceTask = _reflection.GeneratedProtocolMessageType(\n    ""InferenceTask"",\n    (_message.Message,),\n    dict(\n        DESCRIPTOR=_INFERENCETASK,\n        __module__=""tensorflow_serving.apis.inference_pb2""\n        # @@protoc_insertion_point(class_scope:tensorflow.serving.InferenceTask)\n    ),\n)\n_sym_db.RegisterMessage(InferenceTask)\n\nInferenceResult = _reflection.GeneratedProtocolMessageType(\n    ""InferenceResult"",\n    (_message.Message,),\n    dict(\n        DESCRIPTOR=_INFERENCERESULT,\n        __module__=""tensorflow_serving.apis.inference_pb2""\n        # @@protoc_insertion_point(class_scope:tensorflow.serving.InferenceResult)\n    ),\n)\n_sym_db.RegisterMessage(InferenceResult)\n\nMultiInferenceRequest = _reflection.GeneratedProtocolMessageType(\n    ""MultiInferenceRequest"",\n    (_message.Message,),\n    dict(\n        DESCRIPTOR=_MULTIINFERENCEREQUEST,\n        __module__=""tensorflow_serving.apis.inference_pb2""\n        # @@protoc_insertion_point(class_scope:tensorflow.serving.MultiInferenceRequest)\n    ),\n)\n_sym_db.RegisterMessage(MultiInferenceRequest)\n\nMultiInferenceResponse = _reflection.GeneratedProtocolMessageType(\n    ""MultiInferenceResponse"",\n    (_message.Message,),\n    dict(\n        DESCRIPTOR=_MULTIINFERENCERESPONSE,\n        __module__=""tensorflow_serving.apis.inference_pb2""\n        # @@protoc_insertion_point(class_scope:tensorflow.serving.MultiInferenceResponse)\n    ),\n)\n_sym_db.RegisterMessage(MultiInferenceResponse)\n\n\nDESCRIPTOR.has_options = True\nDESCRIPTOR._options = _descriptor._ParseOptions(descriptor_pb2.FileOptions(), _b(""\\370\\001\\001""))\n# @@protoc_insertion_point(module_scope)\n'"
src/sagemaker/tensorflow/tensorflow_serving/apis/input_pb2.py,0,"b'# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: tensorflow_serving/apis/input.proto\n\nimport sys\n\n_b = sys.version_info[0] < 3 and (lambda x: x) or (lambda x: x.encode(""latin1""))\nfrom google.protobuf import descriptor as _descriptor\nfrom google.protobuf import message as _message\nfrom google.protobuf import reflection as _reflection\nfrom google.protobuf import symbol_database as _symbol_database\nfrom google.protobuf import descriptor_pb2\n\n# @@protoc_insertion_point(imports)\n\n_sym_db = _symbol_database.Default()\n\n\nfrom tensorflow.core.example import example_pb2 as tensorflow_dot_core_dot_example_dot_example__pb2\n\n\nDESCRIPTOR = _descriptor.FileDescriptor(\n    name=""tensorflow_serving/apis/input.proto"",\n    package=""tensorflow.serving"",\n    syntax=""proto3"",\n    serialized_pb=_b(\n        \'\\n#tensorflow_serving/apis/input.proto\\x12\\x12tensorflow.serving\\x1a%tensorflow/core/example/example.proto""4\\n\\x0b\\x45xampleList\\x12%\\n\\x08\\x65xamples\\x18\\x01 \\x03(\\x0b\\x32\\x13.tensorflow.Example""e\\n\\x16\\x45xampleListWithContext\\x12%\\n\\x08\\x65xamples\\x18\\x01 \\x03(\\x0b\\x32\\x13.tensorflow.Example\\x12$\\n\\x07\\x63ontext\\x18\\x02 \\x01(\\x0b\\x32\\x13.tensorflow.Example""\\xa1\\x01\\n\\x05Input\\x12;\\n\\x0c\\x65xample_list\\x18\\x01 \\x01(\\x0b\\x32\\x1f.tensorflow.serving.ExampleListB\\x02(\\x01H\\x00\\x12S\\n\\x19\\x65xample_list_with_context\\x18\\x02 \\x01(\\x0b\\x32*.tensorflow.serving.ExampleListWithContextB\\x02(\\x01H\\x00\\x42\\x06\\n\\x04kindB\\x03\\xf8\\x01\\x01\\x62\\x06proto3\'\n    ),\n    dependencies=[tensorflow_dot_core_dot_example_dot_example__pb2.DESCRIPTOR],\n)\n\n\n_EXAMPLELIST = _descriptor.Descriptor(\n    name=""ExampleList"",\n    full_name=""tensorflow.serving.ExampleList"",\n    filename=None,\n    file=DESCRIPTOR,\n    containing_type=None,\n    fields=[\n        _descriptor.FieldDescriptor(\n            name=""examples"",\n            full_name=""tensorflow.serving.ExampleList.examples"",\n            index=0,\n            number=1,\n            type=11,\n            cpp_type=10,\n            label=3,\n            has_default_value=False,\n            default_value=[],\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        )\n    ],\n    extensions=[],\n    nested_types=[],\n    enum_types=[],\n    options=None,\n    is_extendable=False,\n    syntax=""proto3"",\n    extension_ranges=[],\n    oneofs=[],\n    serialized_start=98,\n    serialized_end=150,\n)\n\n\n_EXAMPLELISTWITHCONTEXT = _descriptor.Descriptor(\n    name=""ExampleListWithContext"",\n    full_name=""tensorflow.serving.ExampleListWithContext"",\n    filename=None,\n    file=DESCRIPTOR,\n    containing_type=None,\n    fields=[\n        _descriptor.FieldDescriptor(\n            name=""examples"",\n            full_name=""tensorflow.serving.ExampleListWithContext.examples"",\n            index=0,\n            number=1,\n            type=11,\n            cpp_type=10,\n            label=3,\n            has_default_value=False,\n            default_value=[],\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n        _descriptor.FieldDescriptor(\n            name=""context"",\n            full_name=""tensorflow.serving.ExampleListWithContext.context"",\n            index=1,\n            number=2,\n            type=11,\n            cpp_type=10,\n            label=1,\n            has_default_value=False,\n            default_value=None,\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n    ],\n    extensions=[],\n    nested_types=[],\n    enum_types=[],\n    options=None,\n    is_extendable=False,\n    syntax=""proto3"",\n    extension_ranges=[],\n    oneofs=[],\n    serialized_start=152,\n    serialized_end=253,\n)\n\n\n_INPUT = _descriptor.Descriptor(\n    name=""Input"",\n    full_name=""tensorflow.serving.Input"",\n    filename=None,\n    file=DESCRIPTOR,\n    containing_type=None,\n    fields=[\n        _descriptor.FieldDescriptor(\n            name=""example_list"",\n            full_name=""tensorflow.serving.Input.example_list"",\n            index=0,\n            number=1,\n            type=11,\n            cpp_type=10,\n            label=1,\n            has_default_value=False,\n            default_value=None,\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(""(\\001"")),\n            file=DESCRIPTOR,\n        ),\n        _descriptor.FieldDescriptor(\n            name=""example_list_with_context"",\n            full_name=""tensorflow.serving.Input.example_list_with_context"",\n            index=1,\n            number=2,\n            type=11,\n            cpp_type=10,\n            label=1,\n            has_default_value=False,\n            default_value=None,\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(""(\\001"")),\n            file=DESCRIPTOR,\n        ),\n    ],\n    extensions=[],\n    nested_types=[],\n    enum_types=[],\n    options=None,\n    is_extendable=False,\n    syntax=""proto3"",\n    extension_ranges=[],\n    oneofs=[\n        _descriptor.OneofDescriptor(\n            name=""kind"",\n            full_name=""tensorflow.serving.Input.kind"",\n            index=0,\n            containing_type=None,\n            fields=[],\n        )\n    ],\n    serialized_start=256,\n    serialized_end=417,\n)\n\n_EXAMPLELIST.fields_by_name[\n    ""examples""\n].message_type = tensorflow_dot_core_dot_example_dot_example__pb2._EXAMPLE\n_EXAMPLELISTWITHCONTEXT.fields_by_name[\n    ""examples""\n].message_type = tensorflow_dot_core_dot_example_dot_example__pb2._EXAMPLE\n_EXAMPLELISTWITHCONTEXT.fields_by_name[\n    ""context""\n].message_type = tensorflow_dot_core_dot_example_dot_example__pb2._EXAMPLE\n_INPUT.fields_by_name[""example_list""].message_type = _EXAMPLELIST\n_INPUT.fields_by_name[""example_list_with_context""].message_type = _EXAMPLELISTWITHCONTEXT\n_INPUT.oneofs_by_name[""kind""].fields.append(_INPUT.fields_by_name[""example_list""])\n_INPUT.fields_by_name[""example_list""].containing_oneof = _INPUT.oneofs_by_name[""kind""]\n_INPUT.oneofs_by_name[""kind""].fields.append(_INPUT.fields_by_name[""example_list_with_context""])\n_INPUT.fields_by_name[""example_list_with_context""].containing_oneof = _INPUT.oneofs_by_name[""kind""]\nDESCRIPTOR.message_types_by_name[""ExampleList""] = _EXAMPLELIST\nDESCRIPTOR.message_types_by_name[""ExampleListWithContext""] = _EXAMPLELISTWITHCONTEXT\nDESCRIPTOR.message_types_by_name[""Input""] = _INPUT\n_sym_db.RegisterFileDescriptor(DESCRIPTOR)\n\nExampleList = _reflection.GeneratedProtocolMessageType(\n    ""ExampleList"",\n    (_message.Message,),\n    dict(\n        DESCRIPTOR=_EXAMPLELIST,\n        __module__=""tensorflow_serving.apis.input_pb2""\n        # @@protoc_insertion_point(class_scope:tensorflow.serving.ExampleList)\n    ),\n)\n_sym_db.RegisterMessage(ExampleList)\n\nExampleListWithContext = _reflection.GeneratedProtocolMessageType(\n    ""ExampleListWithContext"",\n    (_message.Message,),\n    dict(\n        DESCRIPTOR=_EXAMPLELISTWITHCONTEXT,\n        __module__=""tensorflow_serving.apis.input_pb2""\n        # @@protoc_insertion_point(class_scope:tensorflow.serving.ExampleListWithContext)\n    ),\n)\n_sym_db.RegisterMessage(ExampleListWithContext)\n\nInput = _reflection.GeneratedProtocolMessageType(\n    ""Input"",\n    (_message.Message,),\n    dict(\n        DESCRIPTOR=_INPUT,\n        __module__=""tensorflow_serving.apis.input_pb2""\n        # @@protoc_insertion_point(class_scope:tensorflow.serving.Input)\n    ),\n)\n_sym_db.RegisterMessage(Input)\n\n\nDESCRIPTOR.has_options = True\nDESCRIPTOR._options = _descriptor._ParseOptions(descriptor_pb2.FileOptions(), _b(""\\370\\001\\001""))\n_INPUT.fields_by_name[""example_list""].has_options = True\n_INPUT.fields_by_name[""example_list""]._options = _descriptor._ParseOptions(\n    descriptor_pb2.FieldOptions(), _b(""(\\001"")\n)\n_INPUT.fields_by_name[""example_list_with_context""].has_options = True\n_INPUT.fields_by_name[""example_list_with_context""]._options = _descriptor._ParseOptions(\n    descriptor_pb2.FieldOptions(), _b(""(\\001"")\n)\n# @@protoc_insertion_point(module_scope)\n'"
src/sagemaker/tensorflow/tensorflow_serving/apis/model_pb2.py,0,"b'# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: tensorflow_serving/apis/model.proto\n\nimport sys\n\n_b = sys.version_info[0] < 3 and (lambda x: x) or (lambda x: x.encode(""latin1""))\nfrom google.protobuf import descriptor as _descriptor\nfrom google.protobuf import message as _message\nfrom google.protobuf import reflection as _reflection\nfrom google.protobuf import symbol_database as _symbol_database\nfrom google.protobuf import descriptor_pb2\n\n# @@protoc_insertion_point(imports)\n\n_sym_db = _symbol_database.Default()\n\n\nfrom google.protobuf import wrappers_pb2 as google_dot_protobuf_dot_wrappers__pb2\n\n\nDESCRIPTOR = _descriptor.FileDescriptor(\n    name=""tensorflow_serving/apis/model.proto"",\n    package=""tensorflow.serving"",\n    syntax=""proto3"",\n    serialized_pb=_b(\n        \'\\n#tensorflow_serving/apis/model.proto\\x12\\x12tensorflow.serving\\x1a\\x1egoogle/protobuf/wrappers.proto""_\\n\\tModelSpec\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12,\\n\\x07version\\x18\\x02 \\x01(\\x0b\\x32\\x1b.google.protobuf.Int64Value\\x12\\x16\\n\\x0esignature_name\\x18\\x03 \\x01(\\tB\\x03\\xf8\\x01\\x01\\x62\\x06proto3\'\n    ),\n    dependencies=[google_dot_protobuf_dot_wrappers__pb2.DESCRIPTOR],\n)\n\n\n_MODELSPEC = _descriptor.Descriptor(\n    name=""ModelSpec"",\n    full_name=""tensorflow.serving.ModelSpec"",\n    filename=None,\n    file=DESCRIPTOR,\n    containing_type=None,\n    fields=[\n        _descriptor.FieldDescriptor(\n            name=""name"",\n            full_name=""tensorflow.serving.ModelSpec.name"",\n            index=0,\n            number=1,\n            type=9,\n            cpp_type=9,\n            label=1,\n            has_default_value=False,\n            default_value=_b("""").decode(""utf-8""),\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n        _descriptor.FieldDescriptor(\n            name=""version"",\n            full_name=""tensorflow.serving.ModelSpec.version"",\n            index=1,\n            number=2,\n            type=11,\n            cpp_type=10,\n            label=1,\n            has_default_value=False,\n            default_value=None,\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n        _descriptor.FieldDescriptor(\n            name=""signature_name"",\n            full_name=""tensorflow.serving.ModelSpec.signature_name"",\n            index=2,\n            number=3,\n            type=9,\n            cpp_type=9,\n            label=1,\n            has_default_value=False,\n            default_value=_b("""").decode(""utf-8""),\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n    ],\n    extensions=[],\n    nested_types=[],\n    enum_types=[],\n    options=None,\n    is_extendable=False,\n    syntax=""proto3"",\n    extension_ranges=[],\n    oneofs=[],\n    serialized_start=91,\n    serialized_end=186,\n)\n\n_MODELSPEC.fields_by_name[\n    ""version""\n].message_type = google_dot_protobuf_dot_wrappers__pb2._INT64VALUE\nDESCRIPTOR.message_types_by_name[""ModelSpec""] = _MODELSPEC\n_sym_db.RegisterFileDescriptor(DESCRIPTOR)\n\nModelSpec = _reflection.GeneratedProtocolMessageType(\n    ""ModelSpec"",\n    (_message.Message,),\n    dict(\n        DESCRIPTOR=_MODELSPEC,\n        __module__=""tensorflow_serving.apis.model_pb2""\n        # @@protoc_insertion_point(class_scope:tensorflow.serving.ModelSpec)\n    ),\n)\n_sym_db.RegisterMessage(ModelSpec)\n\n\nDESCRIPTOR.has_options = True\nDESCRIPTOR._options = _descriptor._ParseOptions(descriptor_pb2.FileOptions(), _b(""\\370\\001\\001""))\n# @@protoc_insertion_point(module_scope)\n'"
src/sagemaker/tensorflow/tensorflow_serving/apis/model_service_pb2.py,0,"b'# Copyright 2018 Google Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: tensorflow_serving/apis/model_service.proto\n# To regenerate run\n# python -m grpc.tools.protoc --python_out=. --grpc_python_out=. -I. tensorflow_serving/apis/model_service.proto\n\nimport sys\n\n_b = sys.version_info[0] < 3 and (lambda x: x) or (lambda x: x.encode(""latin1""))\nfrom google.protobuf import descriptor as _descriptor\nfrom google.protobuf import message as _message\nfrom google.protobuf import reflection as _reflection\nfrom google.protobuf import symbol_database as _symbol_database\nfrom google.protobuf import descriptor_pb2\n\n# @@protoc_insertion_point(imports)\n\n_sym_db = _symbol_database.Default()\n\n\nfrom tensorflow_serving.apis import (\n    get_model_status_pb2 as tensorflow__serving_dot_apis_dot_get__model__status__pb2,\n)\n\n\nDESCRIPTOR = _descriptor.FileDescriptor(\n    name=""tensorflow_serving/apis/model_service.proto"",\n    package=""tensorflow.serving"",\n    syntax=""proto3"",\n    serialized_pb=_b(\n        ""\\n+tensorflow_serving/apis/model_service.proto\\x12\\x12tensorflow.serving\\x1a.tensorflow_serving/apis/get_model_status.proto2w\\n\\x0cModelService\\x12g\\n\\x0eGetModelStatus\\x12).tensorflow.serving.GetModelStatusRequest\\x1a*.tensorflow.serving.GetModelStatusResponseB\\x03\\xf8\\x01\\x01\\x62\\x06proto3""\n    ),\n    dependencies=[tensorflow__serving_dot_apis_dot_get__model__status__pb2.DESCRIPTOR],\n)\n_sym_db.RegisterFileDescriptor(DESCRIPTOR)\n\n\nDESCRIPTOR.has_options = True\nDESCRIPTOR._options = _descriptor._ParseOptions(descriptor_pb2.FileOptions(), _b(""\\370\\001\\001""))\ntry:\n    # THESE ELEMENTS WILL BE DEPRECATED.\n    # Please use the generated *_pb2_grpc.py files instead.\n    import grpc\n    from grpc.framework.common import cardinality\n    from grpc.framework.interfaces.face import utilities as face_utilities\n    from grpc.beta import implementations as beta_implementations\n    from grpc.beta import interfaces as beta_interfaces\n\n    class ModelServiceStub(object):\n        """"""ModelService provides access to information about model versions\n    that have been handled by the model server.\n    """"""\n\n        def __init__(self, channel):\n            """"""Constructor.\n\n      Args:\n        channel: A grpc.Channel.\n      """"""\n            self.GetModelStatus = channel.unary_unary(\n                ""/tensorflow.serving.ModelService/GetModelStatus"",\n                request_serializer=tensorflow__serving_dot_apis_dot_get__model__status__pb2.GetModelStatusRequest.SerializeToString,\n                response_deserializer=tensorflow__serving_dot_apis_dot_get__model__status__pb2.GetModelStatusResponse.FromString,\n            )\n\n    class ModelServiceServicer(object):\n        """"""ModelService provides access to information about model versions\n    that have been handled by the model server.\n    """"""\n\n        def GetModelStatus(self, request, context):\n            """"""Gets status of model. If the ModelSpec in the request does not specify\n      version, information about all versions of the model will be returned. If\n      the ModelSpec in the request does specify a version, the status of only\n      that version will be returned.\n      """"""\n            context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n            context.set_details(""Method not implemented!"")\n            raise NotImplementedError(""Method not implemented!"")\n\n    def add_ModelServiceServicer_to_server(servicer, server):\n        rpc_method_handlers = {\n            ""GetModelStatus"": grpc.unary_unary_rpc_method_handler(\n                servicer.GetModelStatus,\n                request_deserializer=tensorflow__serving_dot_apis_dot_get__model__status__pb2.GetModelStatusRequest.FromString,\n                response_serializer=tensorflow__serving_dot_apis_dot_get__model__status__pb2.GetModelStatusResponse.SerializeToString,\n            )\n        }\n        generic_handler = grpc.method_handlers_generic_handler(\n            ""tensorflow.serving.ModelService"", rpc_method_handlers\n        )\n        server.add_generic_rpc_handlers((generic_handler,))\n\n    class BetaModelServiceServicer(object):\n        """"""The Beta API is deprecated for 0.15.0 and later.\n\n    It is recommended to use the GA API (classes and functions in this\n    file not marked beta) for all further purposes. This class was generated\n    only to ease transition from grpcio<0.15.0 to grpcio>=0.15.0.""""""\n\n        """"""ModelService provides access to information about model versions\n    that have been handled by the model server.\n    """"""\n\n        def GetModelStatus(self, request, context):\n            """"""Gets status of model. If the ModelSpec in the request does not specify\n      version, information about all versions of the model will be returned. If\n      the ModelSpec in the request does specify a version, the status of only\n      that version will be returned.\n      """"""\n            context.code(beta_interfaces.StatusCode.UNIMPLEMENTED)\n\n    class BetaModelServiceStub(object):\n        """"""The Beta API is deprecated for 0.15.0 and later.\n\n    It is recommended to use the GA API (classes and functions in this\n    file not marked beta) for all further purposes. This class was generated\n    only to ease transition from grpcio<0.15.0 to grpcio>=0.15.0.""""""\n\n        """"""ModelService provides access to information about model versions\n    that have been handled by the model server.\n    """"""\n\n        def GetModelStatus(\n            self, request, timeout, metadata=None, with_call=False, protocol_options=None\n        ):\n            """"""Gets status of model. If the ModelSpec in the request does not specify\n      version, information about all versions of the model will be returned. If\n      the ModelSpec in the request does specify a version, the status of only\n      that version will be returned.\n      """"""\n            raise NotImplementedError()\n\n        GetModelStatus.future = None\n\n    def beta_create_ModelService_server(\n        servicer, pool=None, pool_size=None, default_timeout=None, maximum_timeout=None\n    ):\n        """"""The Beta API is deprecated for 0.15.0 and later.\n\n    It is recommended to use the GA API (classes and functions in this\n    file not marked beta) for all further purposes. This function was\n    generated only to ease transition from grpcio<0.15.0 to grpcio>=0.15.0""""""\n        request_deserializers = {\n            (\n                ""tensorflow.serving.ModelService"",\n                ""GetModelStatus"",\n            ): tensorflow__serving_dot_apis_dot_get__model__status__pb2.GetModelStatusRequest.FromString\n        }\n        response_serializers = {\n            (\n                ""tensorflow.serving.ModelService"",\n                ""GetModelStatus"",\n            ): tensorflow__serving_dot_apis_dot_get__model__status__pb2.GetModelStatusResponse.SerializeToString\n        }\n        method_implementations = {\n            (\n                ""tensorflow.serving.ModelService"",\n                ""GetModelStatus"",\n            ): face_utilities.unary_unary_inline(servicer.GetModelStatus)\n        }\n        server_options = beta_implementations.server_options(\n            request_deserializers=request_deserializers,\n            response_serializers=response_serializers,\n            thread_pool=pool,\n            thread_pool_size=pool_size,\n            default_timeout=default_timeout,\n            maximum_timeout=maximum_timeout,\n        )\n        return beta_implementations.server(method_implementations, options=server_options)\n\n    def beta_create_ModelService_stub(\n        channel, host=None, metadata_transformer=None, pool=None, pool_size=None\n    ):\n        """"""The Beta API is deprecated for 0.15.0 and later.\n\n    It is recommended to use the GA API (classes and functions in this\n    file not marked beta) for all further purposes. This function was\n    generated only to ease transition from grpcio<0.15.0 to grpcio>=0.15.0""""""\n        request_serializers = {\n            (\n                ""tensorflow.serving.ModelService"",\n                ""GetModelStatus"",\n            ): tensorflow__serving_dot_apis_dot_get__model__status__pb2.GetModelStatusRequest.SerializeToString\n        }\n        response_deserializers = {\n            (\n                ""tensorflow.serving.ModelService"",\n                ""GetModelStatus"",\n            ): tensorflow__serving_dot_apis_dot_get__model__status__pb2.GetModelStatusResponse.FromString\n        }\n        cardinalities = {""GetModelStatus"": cardinality.Cardinality.UNARY_UNARY}\n        stub_options = beta_implementations.stub_options(\n            host=host,\n            metadata_transformer=metadata_transformer,\n            request_serializers=request_serializers,\n            response_deserializers=response_deserializers,\n            thread_pool=pool,\n            thread_pool_size=pool_size,\n        )\n        return beta_implementations.dynamic_stub(\n            channel, ""tensorflow.serving.ModelService"", cardinalities, options=stub_options\n        )\n\n\nexcept ImportError:\n    pass\n# @@protoc_insertion_point(module_scope)\n'"
src/sagemaker/tensorflow/tensorflow_serving/apis/model_service_pb2_grpc.py,0,"b'# Copyright 2018 Google Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: tensorflow_serving/apis/model_service.proto\n# To regenerate run\n# python -m grpc.tools.protoc --python_out=. --grpc_python_out=. -I. tensorflow_serving/apis/model_service.proto\n\nimport grpc\nfrom grpc.framework.common import cardinality\nfrom grpc.framework.interfaces.face import utilities as face_utilities\n\nimport tensorflow_serving.apis.get_model_status_pb2 as tensorflow__serving_dot_apis_dot_get__model__status__pb2\n\n\nclass ModelServiceStub(object):\n    """"""ModelService provides access to information about model versions\n  that have been handled by the model server.\n  """"""\n\n    def __init__(self, channel):\n        """"""Constructor.\n\n    Args:\n      channel: A grpc.Channel.\n    """"""\n        self.GetModelStatus = channel.unary_unary(\n            ""/tensorflow.serving.ModelService/GetModelStatus"",\n            request_serializer=tensorflow__serving_dot_apis_dot_get__model__status__pb2.GetModelStatusRequest.SerializeToString,\n            response_deserializer=tensorflow__serving_dot_apis_dot_get__model__status__pb2.GetModelStatusResponse.FromString,\n        )\n\n\nclass ModelServiceServicer(object):\n    """"""ModelService provides access to information about model versions\n  that have been handled by the model server.\n  """"""\n\n    def GetModelStatus(self, request, context):\n        """"""Gets status of model. If the ModelSpec in the request does not specify\n    version, information about all versions of the model will be returned. If\n    the ModelSpec in the request does specify a version, the status of only\n    that version will be returned.\n    """"""\n        context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n        context.set_details(""Method not implemented!"")\n        raise NotImplementedError(""Method not implemented!"")\n\n\ndef add_ModelServiceServicer_to_server(servicer, server):\n    rpc_method_handlers = {\n        ""GetModelStatus"": grpc.unary_unary_rpc_method_handler(\n            servicer.GetModelStatus,\n            request_deserializer=tensorflow__serving_dot_apis_dot_get__model__status__pb2.GetModelStatusRequest.FromString,\n            response_serializer=tensorflow__serving_dot_apis_dot_get__model__status__pb2.GetModelStatusResponse.SerializeToString,\n        )\n    }\n    generic_handler = grpc.method_handlers_generic_handler(\n        ""tensorflow.serving.ModelService"", rpc_method_handlers\n    )\n    server.add_generic_rpc_handlers((generic_handler,))\n'"
src/sagemaker/tensorflow/tensorflow_serving/apis/predict_pb2.py,0,"b'# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: tensorflow_serving/apis/predict.proto\n\nimport sys\n\n_b = sys.version_info[0] < 3 and (lambda x: x) or (lambda x: x.encode(""latin1""))\nfrom google.protobuf import descriptor as _descriptor\nfrom google.protobuf import message as _message\nfrom google.protobuf import reflection as _reflection\nfrom google.protobuf import symbol_database as _symbol_database\nfrom google.protobuf import descriptor_pb2\n\n# @@protoc_insertion_point(imports)\n\n_sym_db = _symbol_database.Default()\n\n\nfrom tensorflow.core.framework import (\n    tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2,\n)\nfrom tensorflow_serving.apis import model_pb2 as tensorflow__serving_dot_apis_dot_model__pb2\n\n\nDESCRIPTOR = _descriptor.FileDescriptor(\n    name=""tensorflow_serving/apis/predict.proto"",\n    package=""tensorflow.serving"",\n    syntax=""proto3"",\n    serialized_pb=_b(\n        \'\\n%tensorflow_serving/apis/predict.proto\\x12\\x12tensorflow.serving\\x1a&tensorflow/core/framework/tensor.proto\\x1a#tensorflow_serving/apis/model.proto""\\xe2\\x01\\n\\x0ePredictRequest\\x12\\x31\\n\\nmodel_spec\\x18\\x01 \\x01(\\x0b\\x32\\x1d.tensorflow.serving.ModelSpec\\x12>\\n\\x06inputs\\x18\\x02 \\x03(\\x0b\\x32..tensorflow.serving.PredictRequest.InputsEntry\\x12\\x15\\n\\routput_filter\\x18\\x03 \\x03(\\t\\x1a\\x46\\n\\x0bInputsEntry\\x12\\x0b\\n\\x03key\\x18\\x01 \\x01(\\t\\x12&\\n\\x05value\\x18\\x02 \\x01(\\x0b\\x32\\x17.tensorflow.TensorProto:\\x02\\x38\\x01""\\xd0\\x01\\n\\x0fPredictResponse\\x12\\x31\\n\\nmodel_spec\\x18\\x02 \\x01(\\x0b\\x32\\x1d.tensorflow.serving.ModelSpec\\x12\\x41\\n\\x07outputs\\x18\\x01 \\x03(\\x0b\\x32\\x30.tensorflow.serving.PredictResponse.OutputsEntry\\x1aG\\n\\x0cOutputsEntry\\x12\\x0b\\n\\x03key\\x18\\x01 \\x01(\\t\\x12&\\n\\x05value\\x18\\x02 \\x01(\\x0b\\x32\\x17.tensorflow.TensorProto:\\x02\\x38\\x01\\x42\\x03\\xf8\\x01\\x01\\x62\\x06proto3\'\n    ),\n    dependencies=[\n        tensorflow_dot_core_dot_framework_dot_tensor__pb2.DESCRIPTOR,\n        tensorflow__serving_dot_apis_dot_model__pb2.DESCRIPTOR,\n    ],\n)\n\n\n_PREDICTREQUEST_INPUTSENTRY = _descriptor.Descriptor(\n    name=""InputsEntry"",\n    full_name=""tensorflow.serving.PredictRequest.InputsEntry"",\n    filename=None,\n    file=DESCRIPTOR,\n    containing_type=None,\n    fields=[\n        _descriptor.FieldDescriptor(\n            name=""key"",\n            full_name=""tensorflow.serving.PredictRequest.InputsEntry.key"",\n            index=0,\n            number=1,\n            type=9,\n            cpp_type=9,\n            label=1,\n            has_default_value=False,\n            default_value=_b("""").decode(""utf-8""),\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n        _descriptor.FieldDescriptor(\n            name=""value"",\n            full_name=""tensorflow.serving.PredictRequest.InputsEntry.value"",\n            index=1,\n            number=2,\n            type=11,\n            cpp_type=10,\n            label=1,\n            has_default_value=False,\n            default_value=None,\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n    ],\n    extensions=[],\n    nested_types=[],\n    enum_types=[],\n    options=_descriptor._ParseOptions(descriptor_pb2.MessageOptions(), _b(""8\\001"")),\n    is_extendable=False,\n    syntax=""proto3"",\n    extension_ranges=[],\n    oneofs=[],\n    serialized_start=295,\n    serialized_end=365,\n)\n\n_PREDICTREQUEST = _descriptor.Descriptor(\n    name=""PredictRequest"",\n    full_name=""tensorflow.serving.PredictRequest"",\n    filename=None,\n    file=DESCRIPTOR,\n    containing_type=None,\n    fields=[\n        _descriptor.FieldDescriptor(\n            name=""model_spec"",\n            full_name=""tensorflow.serving.PredictRequest.model_spec"",\n            index=0,\n            number=1,\n            type=11,\n            cpp_type=10,\n            label=1,\n            has_default_value=False,\n            default_value=None,\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n        _descriptor.FieldDescriptor(\n            name=""inputs"",\n            full_name=""tensorflow.serving.PredictRequest.inputs"",\n            index=1,\n            number=2,\n            type=11,\n            cpp_type=10,\n            label=3,\n            has_default_value=False,\n            default_value=[],\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n        _descriptor.FieldDescriptor(\n            name=""output_filter"",\n            full_name=""tensorflow.serving.PredictRequest.output_filter"",\n            index=2,\n            number=3,\n            type=9,\n            cpp_type=9,\n            label=3,\n            has_default_value=False,\n            default_value=[],\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n    ],\n    extensions=[],\n    nested_types=[_PREDICTREQUEST_INPUTSENTRY],\n    enum_types=[],\n    options=None,\n    is_extendable=False,\n    syntax=""proto3"",\n    extension_ranges=[],\n    oneofs=[],\n    serialized_start=139,\n    serialized_end=365,\n)\n\n\n_PREDICTRESPONSE_OUTPUTSENTRY = _descriptor.Descriptor(\n    name=""OutputsEntry"",\n    full_name=""tensorflow.serving.PredictResponse.OutputsEntry"",\n    filename=None,\n    file=DESCRIPTOR,\n    containing_type=None,\n    fields=[\n        _descriptor.FieldDescriptor(\n            name=""key"",\n            full_name=""tensorflow.serving.PredictResponse.OutputsEntry.key"",\n            index=0,\n            number=1,\n            type=9,\n            cpp_type=9,\n            label=1,\n            has_default_value=False,\n            default_value=_b("""").decode(""utf-8""),\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n        _descriptor.FieldDescriptor(\n            name=""value"",\n            full_name=""tensorflow.serving.PredictResponse.OutputsEntry.value"",\n            index=1,\n            number=2,\n            type=11,\n            cpp_type=10,\n            label=1,\n            has_default_value=False,\n            default_value=None,\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n    ],\n    extensions=[],\n    nested_types=[],\n    enum_types=[],\n    options=_descriptor._ParseOptions(descriptor_pb2.MessageOptions(), _b(""8\\001"")),\n    is_extendable=False,\n    syntax=""proto3"",\n    extension_ranges=[],\n    oneofs=[],\n    serialized_start=505,\n    serialized_end=576,\n)\n\n_PREDICTRESPONSE = _descriptor.Descriptor(\n    name=""PredictResponse"",\n    full_name=""tensorflow.serving.PredictResponse"",\n    filename=None,\n    file=DESCRIPTOR,\n    containing_type=None,\n    fields=[\n        _descriptor.FieldDescriptor(\n            name=""model_spec"",\n            full_name=""tensorflow.serving.PredictResponse.model_spec"",\n            index=0,\n            number=2,\n            type=11,\n            cpp_type=10,\n            label=1,\n            has_default_value=False,\n            default_value=None,\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n        _descriptor.FieldDescriptor(\n            name=""outputs"",\n            full_name=""tensorflow.serving.PredictResponse.outputs"",\n            index=1,\n            number=1,\n            type=11,\n            cpp_type=10,\n            label=3,\n            has_default_value=False,\n            default_value=[],\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n    ],\n    extensions=[],\n    nested_types=[_PREDICTRESPONSE_OUTPUTSENTRY],\n    enum_types=[],\n    options=None,\n    is_extendable=False,\n    syntax=""proto3"",\n    extension_ranges=[],\n    oneofs=[],\n    serialized_start=368,\n    serialized_end=576,\n)\n\n_PREDICTREQUEST_INPUTSENTRY.fields_by_name[\n    ""value""\n].message_type = tensorflow_dot_core_dot_framework_dot_tensor__pb2._TENSORPROTO\n_PREDICTREQUEST_INPUTSENTRY.containing_type = _PREDICTREQUEST\n_PREDICTREQUEST.fields_by_name[\n    ""model_spec""\n].message_type = tensorflow__serving_dot_apis_dot_model__pb2._MODELSPEC\n_PREDICTREQUEST.fields_by_name[""inputs""].message_type = _PREDICTREQUEST_INPUTSENTRY\n_PREDICTRESPONSE_OUTPUTSENTRY.fields_by_name[\n    ""value""\n].message_type = tensorflow_dot_core_dot_framework_dot_tensor__pb2._TENSORPROTO\n_PREDICTRESPONSE_OUTPUTSENTRY.containing_type = _PREDICTRESPONSE\n_PREDICTRESPONSE.fields_by_name[\n    ""model_spec""\n].message_type = tensorflow__serving_dot_apis_dot_model__pb2._MODELSPEC\n_PREDICTRESPONSE.fields_by_name[""outputs""].message_type = _PREDICTRESPONSE_OUTPUTSENTRY\nDESCRIPTOR.message_types_by_name[""PredictRequest""] = _PREDICTREQUEST\nDESCRIPTOR.message_types_by_name[""PredictResponse""] = _PREDICTRESPONSE\n_sym_db.RegisterFileDescriptor(DESCRIPTOR)\n\nPredictRequest = _reflection.GeneratedProtocolMessageType(\n    ""PredictRequest"",\n    (_message.Message,),\n    dict(\n        InputsEntry=_reflection.GeneratedProtocolMessageType(\n            ""InputsEntry"",\n            (_message.Message,),\n            dict(\n                DESCRIPTOR=_PREDICTREQUEST_INPUTSENTRY,\n                __module__=""tensorflow_serving.apis.predict_pb2""\n                # @@protoc_insertion_point(class_scope:tensorflow.serving.PredictRequest.InputsEntry)\n            ),\n        ),\n        DESCRIPTOR=_PREDICTREQUEST,\n        __module__=""tensorflow_serving.apis.predict_pb2""\n        # @@protoc_insertion_point(class_scope:tensorflow.serving.PredictRequest)\n    ),\n)\n_sym_db.RegisterMessage(PredictRequest)\n_sym_db.RegisterMessage(PredictRequest.InputsEntry)\n\nPredictResponse = _reflection.GeneratedProtocolMessageType(\n    ""PredictResponse"",\n    (_message.Message,),\n    dict(\n        OutputsEntry=_reflection.GeneratedProtocolMessageType(\n            ""OutputsEntry"",\n            (_message.Message,),\n            dict(\n                DESCRIPTOR=_PREDICTRESPONSE_OUTPUTSENTRY,\n                __module__=""tensorflow_serving.apis.predict_pb2""\n                # @@protoc_insertion_point(class_scope:tensorflow.serving.PredictResponse.OutputsEntry)\n            ),\n        ),\n        DESCRIPTOR=_PREDICTRESPONSE,\n        __module__=""tensorflow_serving.apis.predict_pb2""\n        # @@protoc_insertion_point(class_scope:tensorflow.serving.PredictResponse)\n    ),\n)\n_sym_db.RegisterMessage(PredictResponse)\n_sym_db.RegisterMessage(PredictResponse.OutputsEntry)\n\n\nDESCRIPTOR.has_options = True\nDESCRIPTOR._options = _descriptor._ParseOptions(descriptor_pb2.FileOptions(), _b(""\\370\\001\\001""))\n_PREDICTREQUEST_INPUTSENTRY.has_options = True\n_PREDICTREQUEST_INPUTSENTRY._options = _descriptor._ParseOptions(\n    descriptor_pb2.MessageOptions(), _b(""8\\001"")\n)\n_PREDICTRESPONSE_OUTPUTSENTRY.has_options = True\n_PREDICTRESPONSE_OUTPUTSENTRY._options = _descriptor._ParseOptions(\n    descriptor_pb2.MessageOptions(), _b(""8\\001"")\n)\n# @@protoc_insertion_point(module_scope)\n'"
src/sagemaker/tensorflow/tensorflow_serving/apis/prediction_service_pb2.py,0,"b'# Copyright 2016 Google Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: tensorflow_serving/apis/prediction_service.proto\n# To regenerate run\n# python -m grpc.tools.protoc --python_out=. --grpc_python_out=. -I. tensorflow_serving/apis/prediction_service.proto\n\nimport sys\n\n_b = sys.version_info[0] < 3 and (lambda x: x) or (lambda x: x.encode(""latin1""))\nfrom google.protobuf import descriptor as _descriptor\nfrom google.protobuf import message as _message\nfrom google.protobuf import reflection as _reflection\nfrom google.protobuf import symbol_database as _symbol_database\nfrom google.protobuf import descriptor_pb2\n\n# @@protoc_insertion_point(imports)\n\n_sym_db = _symbol_database.Default()\n\n\nfrom tensorflow_serving.apis import (\n    classification_pb2 as tensorflow__serving_dot_apis_dot_classification__pb2,\n)\nfrom tensorflow_serving.apis import (\n    get_model_metadata_pb2 as tensorflow__serving_dot_apis_dot_get__model__metadata__pb2,\n)\nfrom tensorflow_serving.apis import inference_pb2 as tensorflow__serving_dot_apis_dot_inference__pb2\nfrom tensorflow_serving.apis import predict_pb2 as tensorflow__serving_dot_apis_dot_predict__pb2\nfrom tensorflow_serving.apis import (\n    regression_pb2 as tensorflow__serving_dot_apis_dot_regression__pb2,\n)\n\n\nDESCRIPTOR = _descriptor.FileDescriptor(\n    name=""tensorflow_serving/apis/prediction_service.proto"",\n    package=""tensorflow.serving"",\n    syntax=""proto3"",\n    serialized_pb=_b(\n        ""\\n0tensorflow_serving/apis/prediction_service.proto\\x12\\x12tensorflow.serving\\x1a,tensorflow_serving/apis/classification.proto\\x1a\\x30tensorflow_serving/apis/get_model_metadata.proto\\x1a\'tensorflow_serving/apis/inference.proto\\x1a%tensorflow_serving/apis/predict.proto\\x1a(tensorflow_serving/apis/regression.proto2\\xfc\\x03\\n\\x11PredictionService\\x12\\x61\\n\\x08\\x43lassify\\x12).tensorflow.serving.ClassificationRequest\\x1a*.tensorflow.serving.ClassificationResponse\\x12X\\n\\x07Regress\\x12%.tensorflow.serving.RegressionRequest\\x1a&.tensorflow.serving.RegressionResponse\\x12R\\n\\x07Predict\\x12\\"".tensorflow.serving.PredictRequest\\x1a#.tensorflow.serving.PredictResponse\\x12g\\n\\x0eMultiInference\\x12).tensorflow.serving.MultiInferenceRequest\\x1a*.tensorflow.serving.MultiInferenceResponse\\x12m\\n\\x10GetModelMetadata\\x12+.tensorflow.serving.GetModelMetadataRequest\\x1a,.tensorflow.serving.GetModelMetadataResponseB\\x03\\xf8\\x01\\x01\\x62\\x06proto3""\n    ),\n    dependencies=[\n        tensorflow__serving_dot_apis_dot_classification__pb2.DESCRIPTOR,\n        tensorflow__serving_dot_apis_dot_get__model__metadata__pb2.DESCRIPTOR,\n        tensorflow__serving_dot_apis_dot_inference__pb2.DESCRIPTOR,\n        tensorflow__serving_dot_apis_dot_predict__pb2.DESCRIPTOR,\n        tensorflow__serving_dot_apis_dot_regression__pb2.DESCRIPTOR,\n    ],\n)\n_sym_db.RegisterFileDescriptor(DESCRIPTOR)\n\n\nDESCRIPTOR.has_options = True\nDESCRIPTOR._options = _descriptor._ParseOptions(descriptor_pb2.FileOptions(), _b(""\\370\\001\\001""))\ntry:\n    # THESE ELEMENTS WILL BE DEPRECATED.\n    # Please use the generated *_pb2_grpc.py files instead.\n    import grpc\n    from grpc.framework.common import cardinality\n    from grpc.framework.interfaces.face import utilities as face_utilities\n    from grpc.beta import implementations as beta_implementations\n    from grpc.beta import interfaces as beta_interfaces\n\n    class PredictionServiceStub(object):\n        """"""open source marker; do not remove\n    PredictionService provides access to machine-learned models loaded by\n    model_servers.\n    """"""\n\n        def __init__(self, channel):\n            """"""Constructor.\n\n      Args:\n        channel: A grpc.Channel.\n      """"""\n            self.Classify = channel.unary_unary(\n                ""/tensorflow.serving.PredictionService/Classify"",\n                request_serializer=tensorflow__serving_dot_apis_dot_classification__pb2.ClassificationRequest.SerializeToString,\n                response_deserializer=tensorflow__serving_dot_apis_dot_classification__pb2.ClassificationResponse.FromString,\n            )\n            self.Regress = channel.unary_unary(\n                ""/tensorflow.serving.PredictionService/Regress"",\n                request_serializer=tensorflow__serving_dot_apis_dot_regression__pb2.RegressionRequest.SerializeToString,\n                response_deserializer=tensorflow__serving_dot_apis_dot_regression__pb2.RegressionResponse.FromString,\n            )\n            self.Predict = channel.unary_unary(\n                ""/tensorflow.serving.PredictionService/Predict"",\n                request_serializer=tensorflow__serving_dot_apis_dot_predict__pb2.PredictRequest.SerializeToString,\n                response_deserializer=tensorflow__serving_dot_apis_dot_predict__pb2.PredictResponse.FromString,\n            )\n            self.MultiInference = channel.unary_unary(\n                ""/tensorflow.serving.PredictionService/MultiInference"",\n                request_serializer=tensorflow__serving_dot_apis_dot_inference__pb2.MultiInferenceRequest.SerializeToString,\n                response_deserializer=tensorflow__serving_dot_apis_dot_inference__pb2.MultiInferenceResponse.FromString,\n            )\n            self.GetModelMetadata = channel.unary_unary(\n                ""/tensorflow.serving.PredictionService/GetModelMetadata"",\n                request_serializer=tensorflow__serving_dot_apis_dot_get__model__metadata__pb2.GetModelMetadataRequest.SerializeToString,\n                response_deserializer=tensorflow__serving_dot_apis_dot_get__model__metadata__pb2.GetModelMetadataResponse.FromString,\n            )\n\n    class PredictionServiceServicer(object):\n        """"""open source marker; do not remove\n    PredictionService provides access to machine-learned models loaded by\n    model_servers.\n    """"""\n\n        def Classify(self, request, context):\n            """"""Classify.\n      """"""\n            context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n            context.set_details(""Method not implemented!"")\n            raise NotImplementedError(""Method not implemented!"")\n\n        def Regress(self, request, context):\n            """"""Regress.\n      """"""\n            context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n            context.set_details(""Method not implemented!"")\n            raise NotImplementedError(""Method not implemented!"")\n\n        def Predict(self, request, context):\n            """"""Predict -- provides access to loaded TensorFlow model.\n      """"""\n            context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n            context.set_details(""Method not implemented!"")\n            raise NotImplementedError(""Method not implemented!"")\n\n        def MultiInference(self, request, context):\n            """"""MultiInference API for multi-headed models.\n      """"""\n            context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n            context.set_details(""Method not implemented!"")\n            raise NotImplementedError(""Method not implemented!"")\n\n        def GetModelMetadata(self, request, context):\n            """"""GetModelMetadata - provides access to metadata for loaded models.\n      """"""\n            context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n            context.set_details(""Method not implemented!"")\n            raise NotImplementedError(""Method not implemented!"")\n\n    def add_PredictionServiceServicer_to_server(servicer, server):\n        rpc_method_handlers = {\n            ""Classify"": grpc.unary_unary_rpc_method_handler(\n                servicer.Classify,\n                request_deserializer=tensorflow__serving_dot_apis_dot_classification__pb2.ClassificationRequest.FromString,\n                response_serializer=tensorflow__serving_dot_apis_dot_classification__pb2.ClassificationResponse.SerializeToString,\n            ),\n            ""Regress"": grpc.unary_unary_rpc_method_handler(\n                servicer.Regress,\n                request_deserializer=tensorflow__serving_dot_apis_dot_regression__pb2.RegressionRequest.FromString,\n                response_serializer=tensorflow__serving_dot_apis_dot_regression__pb2.RegressionResponse.SerializeToString,\n            ),\n            ""Predict"": grpc.unary_unary_rpc_method_handler(\n                servicer.Predict,\n                request_deserializer=tensorflow__serving_dot_apis_dot_predict__pb2.PredictRequest.FromString,\n                response_serializer=tensorflow__serving_dot_apis_dot_predict__pb2.PredictResponse.SerializeToString,\n            ),\n            ""MultiInference"": grpc.unary_unary_rpc_method_handler(\n                servicer.MultiInference,\n                request_deserializer=tensorflow__serving_dot_apis_dot_inference__pb2.MultiInferenceRequest.FromString,\n                response_serializer=tensorflow__serving_dot_apis_dot_inference__pb2.MultiInferenceResponse.SerializeToString,\n            ),\n            ""GetModelMetadata"": grpc.unary_unary_rpc_method_handler(\n                servicer.GetModelMetadata,\n                request_deserializer=tensorflow__serving_dot_apis_dot_get__model__metadata__pb2.GetModelMetadataRequest.FromString,\n                response_serializer=tensorflow__serving_dot_apis_dot_get__model__metadata__pb2.GetModelMetadataResponse.SerializeToString,\n            ),\n        }\n        generic_handler = grpc.method_handlers_generic_handler(\n            ""tensorflow.serving.PredictionService"", rpc_method_handlers\n        )\n        server.add_generic_rpc_handlers((generic_handler,))\n\n    class BetaPredictionServiceServicer(object):\n        """"""The Beta API is deprecated for 0.15.0 and later.\n\n    It is recommended to use the GA API (classes and functions in this\n    file not marked beta) for all further purposes. This class was generated\n    only to ease transition from grpcio<0.15.0 to grpcio>=0.15.0.""""""\n\n        """"""open source marker; do not remove\n    PredictionService provides access to machine-learned models loaded by\n    model_servers.\n    """"""\n\n        def Classify(self, request, context):\n            """"""Classify.\n      """"""\n            context.code(beta_interfaces.StatusCode.UNIMPLEMENTED)\n\n        def Regress(self, request, context):\n            """"""Regress.\n      """"""\n            context.code(beta_interfaces.StatusCode.UNIMPLEMENTED)\n\n        def Predict(self, request, context):\n            """"""Predict -- provides access to loaded TensorFlow model.\n      """"""\n            context.code(beta_interfaces.StatusCode.UNIMPLEMENTED)\n\n        def MultiInference(self, request, context):\n            """"""MultiInference API for multi-headed models.\n      """"""\n            context.code(beta_interfaces.StatusCode.UNIMPLEMENTED)\n\n        def GetModelMetadata(self, request, context):\n            """"""GetModelMetadata - provides access to metadata for loaded models.\n      """"""\n            context.code(beta_interfaces.StatusCode.UNIMPLEMENTED)\n\n    class BetaPredictionServiceStub(object):\n        """"""The Beta API is deprecated for 0.15.0 and later.\n\n    It is recommended to use the GA API (classes and functions in this\n    file not marked beta) for all further purposes. This class was generated\n    only to ease transition from grpcio<0.15.0 to grpcio>=0.15.0.""""""\n\n        """"""open source marker; do not remove\n    PredictionService provides access to machine-learned models loaded by\n    model_servers.\n    """"""\n\n        def Classify(self, request, timeout, metadata=None, with_call=False, protocol_options=None):\n            """"""Classify.\n      """"""\n            raise NotImplementedError()\n\n        Classify.future = None\n\n        def Regress(self, request, timeout, metadata=None, with_call=False, protocol_options=None):\n            """"""Regress.\n      """"""\n            raise NotImplementedError()\n\n        Regress.future = None\n\n        def Predict(self, request, timeout, metadata=None, with_call=False, protocol_options=None):\n            """"""Predict -- provides access to loaded TensorFlow model.\n      """"""\n            raise NotImplementedError()\n\n        Predict.future = None\n\n        def MultiInference(\n            self, request, timeout, metadata=None, with_call=False, protocol_options=None\n        ):\n            """"""MultiInference API for multi-headed models.\n      """"""\n            raise NotImplementedError()\n\n        MultiInference.future = None\n\n        def GetModelMetadata(\n            self, request, timeout, metadata=None, with_call=False, protocol_options=None\n        ):\n            """"""GetModelMetadata - provides access to metadata for loaded models.\n      """"""\n            raise NotImplementedError()\n\n        GetModelMetadata.future = None\n\n    def beta_create_PredictionService_server(\n        servicer, pool=None, pool_size=None, default_timeout=None, maximum_timeout=None\n    ):\n        """"""The Beta API is deprecated for 0.15.0 and later.\n\n    It is recommended to use the GA API (classes and functions in this\n    file not marked beta) for all further purposes. This function was\n    generated only to ease transition from grpcio<0.15.0 to grpcio>=0.15.0""""""\n        request_deserializers = {\n            (\n                ""tensorflow.serving.PredictionService"",\n                ""Classify"",\n            ): tensorflow__serving_dot_apis_dot_classification__pb2.ClassificationRequest.FromString,\n            (\n                ""tensorflow.serving.PredictionService"",\n                ""GetModelMetadata"",\n            ): tensorflow__serving_dot_apis_dot_get__model__metadata__pb2.GetModelMetadataRequest.FromString,\n            (\n                ""tensorflow.serving.PredictionService"",\n                ""MultiInference"",\n            ): tensorflow__serving_dot_apis_dot_inference__pb2.MultiInferenceRequest.FromString,\n            (\n                ""tensorflow.serving.PredictionService"",\n                ""Predict"",\n            ): tensorflow__serving_dot_apis_dot_predict__pb2.PredictRequest.FromString,\n            (\n                ""tensorflow.serving.PredictionService"",\n                ""Regress"",\n            ): tensorflow__serving_dot_apis_dot_regression__pb2.RegressionRequest.FromString,\n        }\n        response_serializers = {\n            (\n                ""tensorflow.serving.PredictionService"",\n                ""Classify"",\n            ): tensorflow__serving_dot_apis_dot_classification__pb2.ClassificationResponse.SerializeToString,\n            (\n                ""tensorflow.serving.PredictionService"",\n                ""GetModelMetadata"",\n            ): tensorflow__serving_dot_apis_dot_get__model__metadata__pb2.GetModelMetadataResponse.SerializeToString,\n            (\n                ""tensorflow.serving.PredictionService"",\n                ""MultiInference"",\n            ): tensorflow__serving_dot_apis_dot_inference__pb2.MultiInferenceResponse.SerializeToString,\n            (\n                ""tensorflow.serving.PredictionService"",\n                ""Predict"",\n            ): tensorflow__serving_dot_apis_dot_predict__pb2.PredictResponse.SerializeToString,\n            (\n                ""tensorflow.serving.PredictionService"",\n                ""Regress"",\n            ): tensorflow__serving_dot_apis_dot_regression__pb2.RegressionResponse.SerializeToString,\n        }\n        method_implementations = {\n            (""tensorflow.serving.PredictionService"", ""Classify""): face_utilities.unary_unary_inline(\n                servicer.Classify\n            ),\n            (\n                ""tensorflow.serving.PredictionService"",\n                ""GetModelMetadata"",\n            ): face_utilities.unary_unary_inline(servicer.GetModelMetadata),\n            (\n                ""tensorflow.serving.PredictionService"",\n                ""MultiInference"",\n            ): face_utilities.unary_unary_inline(servicer.MultiInference),\n            (""tensorflow.serving.PredictionService"", ""Predict""): face_utilities.unary_unary_inline(\n                servicer.Predict\n            ),\n            (""tensorflow.serving.PredictionService"", ""Regress""): face_utilities.unary_unary_inline(\n                servicer.Regress\n            ),\n        }\n        server_options = beta_implementations.server_options(\n            request_deserializers=request_deserializers,\n            response_serializers=response_serializers,\n            thread_pool=pool,\n            thread_pool_size=pool_size,\n            default_timeout=default_timeout,\n            maximum_timeout=maximum_timeout,\n        )\n        return beta_implementations.server(method_implementations, options=server_options)\n\n    def beta_create_PredictionService_stub(\n        channel, host=None, metadata_transformer=None, pool=None, pool_size=None\n    ):\n        """"""The Beta API is deprecated for 0.15.0 and later.\n\n    It is recommended to use the GA API (classes and functions in this\n    file not marked beta) for all further purposes. This function was\n    generated only to ease transition from grpcio<0.15.0 to grpcio>=0.15.0""""""\n        request_serializers = {\n            (\n                ""tensorflow.serving.PredictionService"",\n                ""Classify"",\n            ): tensorflow__serving_dot_apis_dot_classification__pb2.ClassificationRequest.SerializeToString,\n            (\n                ""tensorflow.serving.PredictionService"",\n                ""GetModelMetadata"",\n            ): tensorflow__serving_dot_apis_dot_get__model__metadata__pb2.GetModelMetadataRequest.SerializeToString,\n            (\n                ""tensorflow.serving.PredictionService"",\n                ""MultiInference"",\n            ): tensorflow__serving_dot_apis_dot_inference__pb2.MultiInferenceRequest.SerializeToString,\n            (\n                ""tensorflow.serving.PredictionService"",\n                ""Predict"",\n            ): tensorflow__serving_dot_apis_dot_predict__pb2.PredictRequest.SerializeToString,\n            (\n                ""tensorflow.serving.PredictionService"",\n                ""Regress"",\n            ): tensorflow__serving_dot_apis_dot_regression__pb2.RegressionRequest.SerializeToString,\n        }\n        response_deserializers = {\n            (\n                ""tensorflow.serving.PredictionService"",\n                ""Classify"",\n            ): tensorflow__serving_dot_apis_dot_classification__pb2.ClassificationResponse.FromString,\n            (\n                ""tensorflow.serving.PredictionService"",\n                ""GetModelMetadata"",\n            ): tensorflow__serving_dot_apis_dot_get__model__metadata__pb2.GetModelMetadataResponse.FromString,\n            (\n                ""tensorflow.serving.PredictionService"",\n                ""MultiInference"",\n            ): tensorflow__serving_dot_apis_dot_inference__pb2.MultiInferenceResponse.FromString,\n            (\n                ""tensorflow.serving.PredictionService"",\n                ""Predict"",\n            ): tensorflow__serving_dot_apis_dot_predict__pb2.PredictResponse.FromString,\n            (\n                ""tensorflow.serving.PredictionService"",\n                ""Regress"",\n            ): tensorflow__serving_dot_apis_dot_regression__pb2.RegressionResponse.FromString,\n        }\n        cardinalities = {\n            ""Classify"": cardinality.Cardinality.UNARY_UNARY,\n            ""GetModelMetadata"": cardinality.Cardinality.UNARY_UNARY,\n            ""MultiInference"": cardinality.Cardinality.UNARY_UNARY,\n            ""Predict"": cardinality.Cardinality.UNARY_UNARY,\n            ""Regress"": cardinality.Cardinality.UNARY_UNARY,\n        }\n        stub_options = beta_implementations.stub_options(\n            host=host,\n            metadata_transformer=metadata_transformer,\n            request_serializers=request_serializers,\n            response_deserializers=response_deserializers,\n            thread_pool=pool,\n            thread_pool_size=pool_size,\n        )\n        return beta_implementations.dynamic_stub(\n            channel, ""tensorflow.serving.PredictionService"", cardinalities, options=stub_options\n        )\n\n\nexcept ImportError:\n    pass\n# @@protoc_insertion_point(module_scope)\n'"
src/sagemaker/tensorflow/tensorflow_serving/apis/regression_pb2.py,0,"b'# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: tensorflow_serving/apis/regression.proto\n\nimport sys\n\n_b = sys.version_info[0] < 3 and (lambda x: x) or (lambda x: x.encode(""latin1""))\nfrom google.protobuf import descriptor as _descriptor\nfrom google.protobuf import message as _message\nfrom google.protobuf import reflection as _reflection\nfrom google.protobuf import symbol_database as _symbol_database\nfrom google.protobuf import descriptor_pb2\n\n# @@protoc_insertion_point(imports)\n\n_sym_db = _symbol_database.Default()\n\n\nfrom tensorflow_serving.apis import input_pb2 as tensorflow__serving_dot_apis_dot_input__pb2\nfrom tensorflow_serving.apis import model_pb2 as tensorflow__serving_dot_apis_dot_model__pb2\n\n\nDESCRIPTOR = _descriptor.FileDescriptor(\n    name=""tensorflow_serving/apis/regression.proto"",\n    package=""tensorflow.serving"",\n    syntax=""proto3"",\n    serialized_pb=_b(\n        \'\\n(tensorflow_serving/apis/regression.proto\\x12\\x12tensorflow.serving\\x1a#tensorflow_serving/apis/input.proto\\x1a#tensorflow_serving/apis/model.proto""\\x1b\\n\\nRegression\\x12\\r\\n\\x05value\\x18\\x01 \\x01(\\x02""G\\n\\x10RegressionResult\\x12\\x33\\n\\x0bregressions\\x18\\x01 \\x03(\\x0b\\x32\\x1e.tensorflow.serving.Regression""p\\n\\x11RegressionRequest\\x12\\x31\\n\\nmodel_spec\\x18\\x01 \\x01(\\x0b\\x32\\x1d.tensorflow.serving.ModelSpec\\x12(\\n\\x05input\\x18\\x02 \\x01(\\x0b\\x32\\x19.tensorflow.serving.Input""}\\n\\x12RegressionResponse\\x12\\x31\\n\\nmodel_spec\\x18\\x02 \\x01(\\x0b\\x32\\x1d.tensorflow.serving.ModelSpec\\x12\\x34\\n\\x06result\\x18\\x01 \\x01(\\x0b\\x32$.tensorflow.serving.RegressionResultB\\x03\\xf8\\x01\\x01\\x62\\x06proto3\'\n    ),\n    dependencies=[\n        tensorflow__serving_dot_apis_dot_input__pb2.DESCRIPTOR,\n        tensorflow__serving_dot_apis_dot_model__pb2.DESCRIPTOR,\n    ],\n)\n\n\n_REGRESSION = _descriptor.Descriptor(\n    name=""Regression"",\n    full_name=""tensorflow.serving.Regression"",\n    filename=None,\n    file=DESCRIPTOR,\n    containing_type=None,\n    fields=[\n        _descriptor.FieldDescriptor(\n            name=""value"",\n            full_name=""tensorflow.serving.Regression.value"",\n            index=0,\n            number=1,\n            type=2,\n            cpp_type=6,\n            label=1,\n            has_default_value=False,\n            default_value=float(0),\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        )\n    ],\n    extensions=[],\n    nested_types=[],\n    enum_types=[],\n    options=None,\n    is_extendable=False,\n    syntax=""proto3"",\n    extension_ranges=[],\n    oneofs=[],\n    serialized_start=138,\n    serialized_end=165,\n)\n\n\n_REGRESSIONRESULT = _descriptor.Descriptor(\n    name=""RegressionResult"",\n    full_name=""tensorflow.serving.RegressionResult"",\n    filename=None,\n    file=DESCRIPTOR,\n    containing_type=None,\n    fields=[\n        _descriptor.FieldDescriptor(\n            name=""regressions"",\n            full_name=""tensorflow.serving.RegressionResult.regressions"",\n            index=0,\n            number=1,\n            type=11,\n            cpp_type=10,\n            label=3,\n            has_default_value=False,\n            default_value=[],\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        )\n    ],\n    extensions=[],\n    nested_types=[],\n    enum_types=[],\n    options=None,\n    is_extendable=False,\n    syntax=""proto3"",\n    extension_ranges=[],\n    oneofs=[],\n    serialized_start=167,\n    serialized_end=238,\n)\n\n\n_REGRESSIONREQUEST = _descriptor.Descriptor(\n    name=""RegressionRequest"",\n    full_name=""tensorflow.serving.RegressionRequest"",\n    filename=None,\n    file=DESCRIPTOR,\n    containing_type=None,\n    fields=[\n        _descriptor.FieldDescriptor(\n            name=""model_spec"",\n            full_name=""tensorflow.serving.RegressionRequest.model_spec"",\n            index=0,\n            number=1,\n            type=11,\n            cpp_type=10,\n            label=1,\n            has_default_value=False,\n            default_value=None,\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n        _descriptor.FieldDescriptor(\n            name=""input"",\n            full_name=""tensorflow.serving.RegressionRequest.input"",\n            index=1,\n            number=2,\n            type=11,\n            cpp_type=10,\n            label=1,\n            has_default_value=False,\n            default_value=None,\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n    ],\n    extensions=[],\n    nested_types=[],\n    enum_types=[],\n    options=None,\n    is_extendable=False,\n    syntax=""proto3"",\n    extension_ranges=[],\n    oneofs=[],\n    serialized_start=240,\n    serialized_end=352,\n)\n\n\n_REGRESSIONRESPONSE = _descriptor.Descriptor(\n    name=""RegressionResponse"",\n    full_name=""tensorflow.serving.RegressionResponse"",\n    filename=None,\n    file=DESCRIPTOR,\n    containing_type=None,\n    fields=[\n        _descriptor.FieldDescriptor(\n            name=""model_spec"",\n            full_name=""tensorflow.serving.RegressionResponse.model_spec"",\n            index=0,\n            number=2,\n            type=11,\n            cpp_type=10,\n            label=1,\n            has_default_value=False,\n            default_value=None,\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n        _descriptor.FieldDescriptor(\n            name=""result"",\n            full_name=""tensorflow.serving.RegressionResponse.result"",\n            index=1,\n            number=1,\n            type=11,\n            cpp_type=10,\n            label=1,\n            has_default_value=False,\n            default_value=None,\n            message_type=None,\n            enum_type=None,\n            containing_type=None,\n            is_extension=False,\n            extension_scope=None,\n            options=None,\n            file=DESCRIPTOR,\n        ),\n    ],\n    extensions=[],\n    nested_types=[],\n    enum_types=[],\n    options=None,\n    is_extendable=False,\n    syntax=""proto3"",\n    extension_ranges=[],\n    oneofs=[],\n    serialized_start=354,\n    serialized_end=479,\n)\n\n_REGRESSIONRESULT.fields_by_name[""regressions""].message_type = _REGRESSION\n_REGRESSIONREQUEST.fields_by_name[\n    ""model_spec""\n].message_type = tensorflow__serving_dot_apis_dot_model__pb2._MODELSPEC\n_REGRESSIONREQUEST.fields_by_name[\n    ""input""\n].message_type = tensorflow__serving_dot_apis_dot_input__pb2._INPUT\n_REGRESSIONRESPONSE.fields_by_name[\n    ""model_spec""\n].message_type = tensorflow__serving_dot_apis_dot_model__pb2._MODELSPEC\n_REGRESSIONRESPONSE.fields_by_name[""result""].message_type = _REGRESSIONRESULT\nDESCRIPTOR.message_types_by_name[""Regression""] = _REGRESSION\nDESCRIPTOR.message_types_by_name[""RegressionResult""] = _REGRESSIONRESULT\nDESCRIPTOR.message_types_by_name[""RegressionRequest""] = _REGRESSIONREQUEST\nDESCRIPTOR.message_types_by_name[""RegressionResponse""] = _REGRESSIONRESPONSE\n_sym_db.RegisterFileDescriptor(DESCRIPTOR)\n\nRegression = _reflection.GeneratedProtocolMessageType(\n    ""Regression"",\n    (_message.Message,),\n    dict(\n        DESCRIPTOR=_REGRESSION,\n        __module__=""tensorflow_serving.apis.regression_pb2""\n        # @@protoc_insertion_point(class_scope:tensorflow.serving.Regression)\n    ),\n)\n_sym_db.RegisterMessage(Regression)\n\nRegressionResult = _reflection.GeneratedProtocolMessageType(\n    ""RegressionResult"",\n    (_message.Message,),\n    dict(\n        DESCRIPTOR=_REGRESSIONRESULT,\n        __module__=""tensorflow_serving.apis.regression_pb2""\n        # @@protoc_insertion_point(class_scope:tensorflow.serving.RegressionResult)\n    ),\n)\n_sym_db.RegisterMessage(RegressionResult)\n\nRegressionRequest = _reflection.GeneratedProtocolMessageType(\n    ""RegressionRequest"",\n    (_message.Message,),\n    dict(\n        DESCRIPTOR=_REGRESSIONREQUEST,\n        __module__=""tensorflow_serving.apis.regression_pb2""\n        # @@protoc_insertion_point(class_scope:tensorflow.serving.RegressionRequest)\n    ),\n)\n_sym_db.RegisterMessage(RegressionRequest)\n\nRegressionResponse = _reflection.GeneratedProtocolMessageType(\n    ""RegressionResponse"",\n    (_message.Message,),\n    dict(\n        DESCRIPTOR=_REGRESSIONRESPONSE,\n        __module__=""tensorflow_serving.apis.regression_pb2""\n        # @@protoc_insertion_point(class_scope:tensorflow.serving.RegressionResponse)\n    ),\n)\n_sym_db.RegisterMessage(RegressionResponse)\n\n\nDESCRIPTOR.has_options = True\nDESCRIPTOR._options = _descriptor._ParseOptions(descriptor_pb2.FileOptions(), _b(""\\370\\001\\001""))\n# @@protoc_insertion_point(module_scope)\n'"
tests/data/tfs/tfs-test-model-with-inference/code/inference.py,0,"b'# Copyright 2019-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License""). You\n# may not use this file except in compliance with the License. A copy of\n# the License is located at\n#\n#     http://aws.amazon.com/apache2.0/\n#\n# or in the ""license"" file accompanying this file. This file is\n# distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\n# ANY KIND, either express or implied. See the License for the specific\n# language governing permissions and limitations under the License.\nimport json\n\n\ndef input_handler(data, context):\n    data = json.loads(data.read().decode(""utf-8""))\n    new_values = [x + 1 for x in data[""instances""]]\n    dumps = json.dumps({""instances"": new_values})\n    return dumps\n\n\ndef output_handler(data, context):\n    response_content_type = context.accept_header\n    prediction = data.content\n    return prediction, response_content_type\n'"
