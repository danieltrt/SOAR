file_path,api_count,code
cfn-bootstrap/dl_cfn_setup.py,0,"b'#!/usr/bin/python\n\n#  Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n#  Licensed under the Amazon Software License (the ""License"").\n#  You may not use this file except in compliance with the License.\n#  A copy of the License is located at\n#\n#  http://aws.amazon.com/asl/\n#\n#  or in the ""license"" file accompanying this file. This file is distributed\n#  on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n#  express or implied. See the License for the specific language governing\n#  permissions and limitations under the License.\n\nimport os\nimport boto\nimport boto.utils\nfrom sets import Set\nimport logging\nimport json\nimport subprocess\nimport time\nimport sys\nimport datetime\nimport pwd\nimport grp\nimport os\nimport boto.ec2\nimport boto.ec2.autoscale\nimport boto.sqs\nimport boto.cloudformation\n\nHOST_FILE = \'/etc/hosts\'\nWORKER_FILE = \'/opt/deeplearning/workers\'\nSLEEP_INTERVAL_IN_SECS = 30\nSQS_RECEIVE_INTERVAL_IN_SECS = 20\nAWS_DL_NODE_TYPE = None\nAWS_DL_MASTER_QUEUE = None\nAWS_DL_WORKER_QUEUE = None\nAWS_DL_SETUP_TIMEOUT = None\nAWS_DL_MASTERLAUNCH_TIMEOUT = None\nAWS_DL_STACK_ID = None\nAWS_DL_WAIT_HANDLE = None\nAWS_REGION = None\nAWS_DL_ROLE_NAME = None\nAWS_DL_DEFAULT_USER = None\nEFS_MOUNT = None\n\nAWS_GPU_INSTANCE_TYPES = [ ""g3.4xlarge"", ""g3.8xlarge"", ""g3.16xlarge"", ""p2.xlarge"", ""p2.8xlarge"", ""p2.16xlarge"", ""p3.2xlarge"", ""p3.8xlarge"", ""p3.16xlarge"" ]\n\n\'\'\'\nSetup Logger and LogLevel\n\'\'\'\ndef setup_logging(log_loc=\'/var/log\'):\n\n    log_file = \'{}/dl_cfn_setup.log\'.format(log_loc)\n    LOGGER = logging.getLogger(\'dl-cfn-setup\')\n    LOGGER.setLevel(logging.INFO)\n    formatter = logging.Formatter(\'%(asctime)s %(levelname)s: %(filename)s:%(lineno)d %(message)s\')\n    file_handler = logging.FileHandler(log_file)\n    file_handler.setFormatter(formatter)\n    console_handler = logging.StreamHandler()\n    console_handler.setFormatter(formatter)\n\n    LOGGER.addHandler(file_handler)\n    LOGGER.addHandler(console_handler)\n\n    return LOGGER\n\ndef ping_host(hostname):\n    res = os.system(""ping -c 1 -w 10 "" + hostname)\n    return res == 0\n\ndef get_gpu_count():\n    LOGGER.info(\'setup_gpu_count\')\n\n    instance_type = boto.utils.get_instance_metadata()[\'instance-type\']\n    if instance_type not in AWS_GPU_INSTANCE_TYPES:\n        LOGGER.info(\'Not a GPU Instance, number of GPUs: {}\'.format(0))\n        return 0\n    try:\n        output = subprocess.check_output([\'nvidia-smi\', \'-L\'])\n        gpu_count = output.count(\'\\n\')\n        LOGGER.info(""number of GPUs:{}"".format(gpu_count))\n        return gpu_count\n    except subprocess.CalledProcessError as e:\n        LOGGER.exception(""Error executing nvidia-smi: {}"".format(e))\n        return 0\n\ndef setup_env_variables(master_instance_ip, worker_instance_ips, default_user, efs_mount):\n    LOGGER.info(""setup_env_variables"")\n\n    with open(HOST_FILE, \'a\') as hosts, open(WORKER_FILE, \'w+\') as w:\n        hosts.write(""{} deeplearning-master\\n"".format(master_instance_ip))\n        worker_index=1\n        for worker_ip in worker_instance_ips:\n            hosts.write(""{} deeplearning-worker{}\\n"".format(worker_ip, worker_index) )\n            w.write(""deeplearning-worker{}\\n"".format(worker_index))\n            worker_index += 1\n\n    gpu_count = get_gpu_count()\n    with open(""/etc/profile.d/deeplearning.sh"", ""a"") as f:\n        num_workers = sum(1 for line in open(WORKER_FILE, ""r""))\n        f.write(""export DEEPLEARNING_WORKERS_COUNT={}\\n"".format(num_workers))\n        f.write(""export DEEPLEARNING_WORKERS_PATH={}\\n"".format(WORKER_FILE))\n        f.write(""export DEEPLEARNING_WORKER_GPU_COUNT={}\\n"".format(gpu_count))\n        f.write(""export EFS_MOUNT={}\\n"".format(efs_mount))\n    \n    #change ownership to ec2-user\n    uid = pwd.getpwnam(default_user).pw_uid\n    gid = grp.getgrnam(default_user).gr_gid\n    os.chown(WORKER_FILE, uid, gid)\n    \n    return\n\n\'\'\'\nwait for asg setup success message from the lambda function\nmessage will be of the format\n{""min"": 1, ""desired"": 1, ""max"": 1, ""launched"": 1, ""status"": ""success"", ""asg"": ""cfn-test-WorkerAutoScalingGroup-1HPKVL6PJEVQS"", ""event"": ""asg-setup""}\n\'\'\'\ndef wait_until_asg_success(master_queue_name, region, timeout):\n    LOGGER.info(\'wait_until_asg_success on queue_name:{}, timeout:{}\'.format(master_queue_name, timeout))\n    sqs_con = boto.sqs.connect_to_region(region_name=region)\n    sqs_queue = sqs_con.get_queue(queue_name = master_queue_name)\n    asg_success_message = {}\n\n    start_time = time.time()\n    next_execution_ts = start_time\n    \n    while True:\n        LOGGER.info(\'checking autoscaling group success message at {}\'.format(datetime.datetime.now()))\n\n        recvd_messages = sqs_con.receive_message(queue=sqs_queue,number_messages=10, visibility_timeout=60)\n        LOGGER.info(\'number of messages received: {}\'.format(len(recvd_messages)))\n        for msg in recvd_messages:\n            msg_body = msg.get_body()\n            LOGGER.info(\'received message with body:{}\'.format(msg_body))\n            try:\n                content = json.loads(msg_body)\n                if content is not None and content[\'event\'] == \'asg-setup\' and content[\'status\'] == \'success\':\n                    # http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/standard-queues.html#standard-queues-at-least-once-delivery\n                    # ignore duplicate message\n                    if content[\'asg\'] not in asg_success_message:\n                        LOGGER.info(\'autosclaing_group: {} succeeded at {}\'.format(content[\'asg\'], datetime.datetime.now()))\n                        asg_success_message[content[\'asg\']] = content\n                    else:\n                        LOGGER.info(\'received duplicate sqs message for {} at {}\'.format(content[\'asg\'], datetime.datetime.now()))\n                sqs_con.delete_message(queue=sqs_queue, message=msg)\n            except (TypeError, KeyError) as e:\n                LOGGER.exception(e)\n                LOGGER.error(msg)\n                continue\n\n        if len(asg_success_message) is 2:\n            LOGGER.info(\'status of all autoscaling_groups received\')\n            break\n\n        next_execution_ts = next_execution_ts + SLEEP_INTERVAL_IN_SECS\n        if (next_execution_ts > (start_time + timeout)):\n            LOGGER.info(\'timeout while checking asg status after {} seconds\'.format(timeout))\n            break\n        \n        LOGGER.info(\'not received all autoscaling group success at {}, WAITING :{}\'.format(datetime.datetime.now(), SLEEP_INTERVAL_IN_SECS))\n        time.sleep(next_execution_ts - time.time())\n\n    return asg_success_message\n\ndef wait_for_worker_setup_message(worker_queue_name, timeout, region):\n    LOGGER.info(\'wait_for_worker_setup_message, worker_queue_name:{}, timeout:{}\'.format(worker_queue_name, timeout))\n    sqs_con = boto.sqs.connect_to_region(region_name=region)\n    sqs_queue = sqs_con.get_queue(queue_name = worker_queue_name)\n\n    start_time = time.time()\n    next_execution_ts = start_time\n    \n    while True:\n        LOGGER.info(\'checking for worker_setup message at {}\'.format(datetime.datetime.now()))\n        #visibility_timeout is set to 0, so that other workers can simultaneously act on this message\n        recvd_messages = sqs_con.receive_message(queue=sqs_queue,number_messages=10, visibility_timeout=0)\n        LOGGER.info(\'number of messages received: {}\'.format(len(recvd_messages)))\n        for msg in recvd_messages:\n            msg_body = msg.get_body()\n            LOGGER.info(\'received message with body:{}\'.format(msg_body))\n            try:\n                content = json.loads(msg_body)\n                if content is not None and content[\'event\'] == \'worker-setup\':\n                    LOGGER.info(\'received worker-setup success message: {}\'.format(content))\n                    # do not delete the message, other workers need to consume this.\n                    return content[\'master-ip\'], content[\'worker-ips\']\n                else:\n                    #don\'t act on other messages\n                    continue\n            except (TypeError, KeyError) as e:\n                LOGGER.error(e)\n                LOGGER.error(msg)\n                continue\n\n        next_execution_ts = next_execution_ts + SLEEP_INTERVAL_IN_SECS\n        if (next_execution_ts > (start_time + timeout)):\n            LOGGER.info(\'did not receive worker-setup success even after {} seconds\'.format(timeout))\n            return None        \n        \n        LOGGER.info(\'worker setup not complete is not complete at {}\'.format(datetime.datetime.now()))\n        time.sleep(next_execution_ts - time.time())\n\n    return None\n\ndef wait_until_instances_active(autoscaling_groups, timeout, region):\n    LOGGER.info(\'wait_until_instances_active, asgs:{}, timeout:{}\'.format(autoscaling_groups, timeout))\n\n    autoscale_con = boto.ec2.autoscale.connect_to_region(region_name=region)\n    ec2_con = boto.ec2.connect_to_region(region_name=region)\n    start_time = time.time()\n    next_execution_ts = start_time\n    master_instance_ids = []\n    worker_instance_ids = []\n    master_instances = {}\n    worker_instances = {}\n    try:\n        # http://boto.cloudhackers.com/en/latest/ref/autoscale.html#boto.ec2.autoscale.group.AutoScalingGroup\n        # does not specify how to get the next token for pagination,\n        # since there are only 2 groups in our case, we will assume they will be returned in one call\n        groups = autoscale_con.get_all_groups(names=autoscaling_groups)\n\n        for asg in groups:\n            instance_ids=[]\n            for instance in asg.instances:\n                if instance.health_status == \'Healthy\':\n                    instance_ids.append(instance.instance_id)\n\n            if \'master\' in asg.name.lower():\n                master_instance_ids.extend(instance_ids)\n            else:\n                worker_instance_ids.extend(instance_ids)\n                LOGGER.info(\'from autoscale, found instances:{} for asg:{}\'.format(instance_ids, asg.name))\n\n        LOGGER.info(\'worker_asg_instane_ids:{}, master_ids:{}\'.format(worker_instance_ids, master_instance_ids))\n        next_token = None\n        pending_instance_ids = master_instance_ids + worker_instance_ids\n\n        while(True):\n            LOGGER.info(\'getting ec2 instance info:{}\'.format(pending_instance_ids))\n            reservations = ec2_con.get_all_reservations(instance_ids = pending_instance_ids, next_token = next_token)\n            next_token = reservations.next_token\n\n            for r in reservations:\n                for i in r.instances:\n                    if i.state.lower() == \'running\':\n                        if i.id in master_instance_ids:\n                            LOGGER.info(\'master instance in running state, id:{}, ip:{}\'.format(i.id, i.private_ip_address))\n                            master_instances[i.id] = i.private_ip_address\n                        elif i.id in worker_instance_ids:\n                            LOGGER.info(\'worker instance in running state, id:{}, ip:{}\'.format(i.id, i.private_ip_address))\n                            worker_instances[i.id] = i.private_ip_address\n                            LOGGER.info(\'worker:{}\'.format(worker_instances))\n                        pending_instance_ids.remove(i.id)\n                    elif i.state.lower() == \'pending\':\n                        LOGGER.info(\'instance is still in pending state, instance id:{}\'.format(i.id))\n                        continue\n            \n            next_execution_ts = next_execution_ts + SLEEP_INTERVAL_IN_SECS\n            if (len(pending_instance_ids) == 0):\n                LOGGER.info(\'received info of all instances, master: {}, worker: {}\'.format(master_instances, worker_instances))\n                break\n            elif (next_token is not None):\n                LOGGER.info(\'next_token is not None, will continue fetching more instances\')\n                continue\n            elif (next_execution_ts < start_time + timeout):\n                LOGGER.error(\'Reached timeout, pending_instance_ids:{}, next_token:{}\'.format(pending_instance_ids, next_token))\n                break                \n            else:\n                LOGGER.info(\'not all instance info is available, pending: {}, waiting for {} seconds\'.format(pending_instance_ids, SLEEP_INTERVAL_IN_SECS))\n                time.sleep(next_execution_ts - time.time())\n            \n        LOGGER.info(\'master: {}, worker: {}\'.format(master_instances, worker_instances))\n        return master_instances, worker_instances\n    except Exception as e:\n        LOGGER.exception(e)\n        return ({},{})\n\'\'\'\nThis method will send success signal to the wait handle url\nits assumed cfn-signal aws cli tool is available on the instance\n\'\'\'\ndef send_cfn_success_signal(stack_id, wait_handle_url, aws_region):\n    try:\n        instance_id = boto.utils.get_instance_metadata()[\'instance-id\']\n        command_args = [\'/opt/aws/bin/cfn-signal\', \'--region\', aws_region, \'--stack\', \\\n        stack_id, \'--success\', \'true\', \'--id\', instance_id, wait_handle_url]\n        LOGGER.info(\'cfn-signal command: {}\'.format(\' \'.join(map(str, command_args))))\n        output = subprocess.check_output(command_args)\n        LOGGER.info(output)\n    except subprocess.CalledProcessError as e:\n        LOGGER.exception(\'FAILED to send cfn-signal\')\n        sys.exit(1)\n    return\n\n\'\'\'\nwaits for a message on SQS for asg setup complete and instances are active.\nfetches private ip addresses of the instances and sets up metadata\n\'\'\'\ndef setup_worker_metadata(setup_timeout, master_queue_name, stack_id, region):\n    LOGGER.info(\'setup_worker_metadata\')\n\n    start_time = time.time()\n    asg_setup_messages = wait_until_asg_success(master_queue_name, region, setup_timeout)\n    if len(asg_setup_messages) is not 2:\n        LOGGER.error(\'did not receive asg success message for all autoscaling_groups, received only: {}\'.format(asg_setup_messages))\n        sys.exit(1)\n\n    master_asg_message = None\n    worker_asg_message = None\n    for key, value in asg_setup_messages.iteritems():\n        LOGGER.info(\'asg success message:{}\'.format(value))\n        if \'master\' in key.lower():\n            master_asg_message = value\n        else:\n            worker_asg_message = value\n\n    timeout = setup_timeout - (time.time() - start_time)\n    start_time = time.time()\n\n    (master_instances, worker_instances) = wait_until_instances_active([master_asg_message[\'asg\'], worker_asg_message[\'asg\']], timeout, region)\n    LOGGER.info(\'from wait_until_instances_active, master: {}, worker:{}\'.format(master_instances, worker_instances))\n    if (len(master_instances) != 1):\n        LOGGER.error(\'expected single master, instead got instance ips:{}\', master_instances)\n        sys.exit(1)\n    master_instance_ip = master_instances.values()[0]\n    worker_instance_ips = [master_instance_ip]\n    \n    if len(worker_instances) is 0:\n        LOGGER.info(\'no worker is launched, using only master instance as worker\')\n    else:\n        worker_instance_ips.extend(worker_instances.values())        \n        \n        if (len(worker_instances) != worker_asg_message[\'launched\']):\n            LOGGER.error(\'expected {} number of instances to be running, instead got instance_ids: {}, ips: {}\' \\\n            .format(worker_asg_message[\'launched\'], worker_instances.keys(), worker_instances.values()) )\n        \n    worker_instance_ips = sorted(worker_instance_ips)\n\n    return master_instance_ip, worker_instance_ips\n\ndef send_worker_setup_msg(worker_queue_name, master_instance_ip, worker_instance_ips, region):\n    LOGGER.info(\'send_worker_setup_msg:{}\'.format(send_worker_setup_msg))\n    \n    sqs_con = boto.sqs.connect_to_region(region_name=region)\n    sqs_queue = sqs_con.get_queue(queue_name = worker_queue_name)\n\n    worker_setup_message={\'event\' : \'worker-setup\'}\n    worker_setup_message[\'master-ip\'] = master_instance_ip\n    worker_setup_message[\'worker-ips\'] = worker_instance_ips\n\n    LOGGER.info(\'sending worker-setup message:{}\'.format(json.dumps(worker_setup_message)))\n    sqs_con.send_message(queue=sqs_queue, message_content=json.dumps(worker_setup_message))\n\ndef check_instance_role_availability(role_name, timeout):\n    LOGGER.info(\'check_instance_role_availability, role_name:{}, timeout: {}\'.format(role_name, timeout))\n\n    start_time = time.time()\n    next_execution_ts = start_time\n    while True:\n        LOGGER.info(\'checking presence of instance role: {}, @ :{}\'.format(role_name, datetime.datetime.now()))\n\n        try:\n            metadata = boto.utils.get_instance_metadata(version=\'latest\',timeout=30, num_retries=5)\n            instance_role = metadata[\'iam\'][\'security-credentials\'][role_name]\n            # we don\'t want to log the credentials\n            del instance_role[\'AccessKeyId\']\n            del instance_role[\'SecretAccessKey\']\n            del instance_role[\'Token\']\n            LOGGER.info(\'SUCCESS getting instance role {}\'.format(instance_role))\n            return True\n        except KeyError as e:\n            LOGGER.info(\'FAILED to get instance role: {} @ {}\'.format(role_name, datetime.datetime.now()))\n            pass\n        next_execution_ts = next_execution_ts + SLEEP_INTERVAL_IN_SECS\n        if (next_execution_ts > (start_time + timeout)):\n            LOGGER.info(\'TIMEOUT while checking instance role after {} seconds\'.format(timeout))\n            break\n\n        LOGGER.info(\'WAITING :{} to get instance_role:{} @ {}\'.format(SLEEP_INTERVAL_IN_SECS, role_name, datetime.datetime.now()))\n        time.sleep(next_execution_ts - time.time())\n    return False\n\nLOGGER = setup_logging()    \ndef main():\n    LOGGER.info(""main"")\n\n    try:\n        AWS_DL_NODE_TYPE = os.environ[""AWS_DL_NODE_TYPE""]\n        AWS_DL_MASTER_QUEUE = os.environ[\'AWS_DL_MASTER_QUEUE\']\n        AWS_DL_WORKER_QUEUE = os.environ[\'AWS_DL_WORKER_QUEUE\']        \n        AWS_DL_WAITCONDITION_TIMEOUT = float(os.environ[\'AWS_DL_WAITCONDITION_TIMEOUT\'])\n        AWS_DL_MASTERLAUNCH_TIMEOUT = float(os.environ[\'AWS_DL_MASTERLAUNCH_TIMEOUT\'])\n        AWS_DL_STACK_ID = os.environ[\'AWS_DL_STACK_ID\']\n        AWS_DL_WAIT_HANDLE = os.environ[\'AWS_DL_WAIT_HANDLE\']\n        AWS_DL_ROLE_NAME = os.environ[\'AWS_DL_ROLE_NAME\']\n        AWS_DL_DEFAULT_USER = os.environ[\'AWS_DL_DEFAULT_USER\']\n        AWS_REGION = os.environ[\'AWS_REGION\']\n        EFS_MOUNT = os.environ[\'EFS_MOUNT\']\n\n        LOGGER.info(\'AWS_DL_NODE_TYPE:{}\\n AWS_DL_MASTER_QUEUE:{}\\n AWS_DL_WORKER_QUEUE:{}\\n AWS_DL_WAITCONDITION_TIMEOUT:{}\\n, AWS_DL_MASTERLAUNCH_TIMEOUT:{}\\n AWS_DL_STACK_ID:{}\\n \\\n            AWS_DL_WAIT_HANDLE:{}\\n AWS_DL_ROLE_NAME:{}\\n AWS_REGION:{}, AWS_DL_DEFAULT_USER:{}, EFS_MOUNT:{}\\n\'.format(AWS_DL_NODE_TYPE, AWS_DL_MASTER_QUEUE, AWS_DL_WORKER_QUEUE, \\\n            AWS_DL_WAITCONDITION_TIMEOUT, AWS_DL_MASTERLAUNCH_TIMEOUT, AWS_DL_STACK_ID, AWS_DL_WAIT_HANDLE, AWS_DL_ROLE_NAME, AWS_REGION, AWS_DL_DEFAULT_USER, EFS_MOUNT)\n        )\n\n        # we want to make sure we finish before the timeout expires\n        setup_timeout = AWS_DL_WAITCONDITION_TIMEOUT - AWS_DL_MASTERLAUNCH_TIMEOUT\n        start_time = time.time()\n        check_instance_role_availability(AWS_DL_ROLE_NAME, setup_timeout)\n        setup_timeout = setup_timeout - (time.time() - start_time)\n\n        # get master ips\n        if (AWS_DL_NODE_TYPE.lower() == \'master\'):\n            master_instance_ip, worker_instance_ips = setup_worker_metadata(setup_timeout, AWS_DL_MASTER_QUEUE, AWS_DL_STACK_ID, AWS_REGION)\n            setup_env_variables(master_instance_ip, worker_instance_ips, AWS_DL_DEFAULT_USER, EFS_MOUNT)\n            send_worker_setup_msg(AWS_DL_WORKER_QUEUE, master_instance_ip, worker_instance_ips, AWS_REGION)\n            send_cfn_success_signal(AWS_DL_STACK_ID, AWS_DL_WAIT_HANDLE, AWS_REGION)\n\n        elif (AWS_DL_NODE_TYPE.lower() == \'worker\'):\n            master_instance_ip, worker_instance_ips = wait_for_worker_setup_message(AWS_DL_WORKER_QUEUE, setup_timeout, AWS_REGION)\n            if master_instance_ip is None or worker_instance_ips is None:\n                LOGGER.error(\'FAILED worker metadata setup : master_ip:{}, worker_ips:{}\'.format(master_instance_ip, worker_instance_ips))\n                sys.exit(1)\n            setup_env_variables(master_instance_ip, worker_instance_ips, AWS_DL_DEFAULT_USER, EFS_MOUNT)\n        else:\n            LOGGER.error(\'unknown node type: {}\'.format(AWS_DL_NODE_TYPE))\n            sys.exit(1)\n\n    except Exception as e:\n        LOGGER.exception(e)\n        sys.exit(1)\n    \nif  __name__ ==\'__main__\':\n    main()\n'"
cfn-bootstrap/dl_cfn_setup_v2.py,0,"b'#!/usr/bin/python\n\n#  Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n#  Licensed under the Amazon Software License (the ""License"").\n#  You may not use this file except in compliance with the License.\n#  A copy of the License is located at\n#\n#  http://aws.amazon.com/asl/\n#\n#  or in the ""license"" file accompanying this file. This file is distributed\n#  on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n#  express or implied. See the License for the specific language governing\n#  permissions and limitations under the License.\n\nimport os\nimport boto\nimport boto.utils\nfrom sets import Set\nimport logging\nimport json\nimport subprocess\nimport time\nimport sys\nimport datetime\nimport pwd\nimport grp\nimport os\nimport boto.ec2\nimport boto.ec2.autoscale\nimport boto.sqs\nimport boto.cloudformation\n\nHOST_FILE = \'/etc/hosts\'\nWORKER_FILE = \'/opt/deeplearning/workers\'\nSLEEP_INTERVAL_IN_SECS = 30\nSQS_RECEIVE_INTERVAL_IN_SECS = 20\nAWS_DL_NODE_TYPE = None\nAWS_DL_MASTER_QUEUE = None\nAWS_DL_WORKER_QUEUE = None\nAWS_DL_SETUP_TIMEOUT = None\nAWS_DL_MASTERLAUNCH_TIMEOUT = None\nAWS_DL_STACK_ID = None\nAWS_DL_WAIT_HANDLE = None\nAWS_REGION = None\nAWS_DL_ROLE_NAME = None\nAWS_DL_DEFAULT_USER = None\nEFS_MOUNT = None\nCFN_PATH = None\n\nAWS_GPU_INSTANCE_TYPES = [ ""g3.4xlarge"", ""g3.8xlarge"", ""g3.16xlarge"", ""p2.xlarge"", ""p2.8xlarge"", ""p2.16xlarge"", ""p3.2xlarge"", ""p3.8xlarge"", ""p3.16xlarge"" ]\n\n\'\'\'\nSetup Logger and LogLevel\n\'\'\'\ndef setup_logging(log_loc=\'/var/log\'):\n\n    log_file = \'{}/dl_cfn_setup.log\'.format(log_loc)\n    LOGGER = logging.getLogger(\'dl-cfn-setup\')\n    LOGGER.setLevel(logging.INFO)\n    formatter = logging.Formatter(\'%(asctime)s %(levelname)s: %(filename)s:%(lineno)d %(message)s\')\n    file_handler = logging.FileHandler(log_file)\n    file_handler.setFormatter(formatter)\n    console_handler = logging.StreamHandler()\n    console_handler.setFormatter(formatter)\n\n    LOGGER.addHandler(file_handler)\n    LOGGER.addHandler(console_handler)\n\n    return LOGGER\n\ndef ping_host(hostname):\n    res = os.system(""ping -c 1 -w 10 "" + hostname)\n    return res == 0\n\ndef get_gpu_count():\n    LOGGER.info(\'setup_gpu_count\')\n\n    instance_type = boto.utils.get_instance_metadata()[\'instance-type\']\n    if instance_type not in AWS_GPU_INSTANCE_TYPES:\n        LOGGER.info(\'Not a GPU Instance, number of GPUs: {}\'.format(0))\n        return 0\n    try:\n        output = subprocess.check_output([\'nvidia-smi\', \'-L\'])\n        gpu_count = output.count(\'\\n\')\n        LOGGER.info(""number of GPUs:{}"".format(gpu_count))\n        return gpu_count\n    except subprocess.CalledProcessError as e:\n        LOGGER.exception(""Error executing nvidia-smi: {}"".format(e))\n        return 0\n\ndef setup_env_variables(master_instance_ip, worker_instance_ips, default_user, efs_mount):\n    LOGGER.info(""setup_env_variables"")\n\n    with open(HOST_FILE, \'a\') as hosts, open(WORKER_FILE, \'w+\') as w:\n        hosts.write(""{} deeplearning-master\\n"".format(master_instance_ip))\n        worker_index=1\n        for worker_ip in worker_instance_ips:\n            hosts.write(""{} deeplearning-worker{}\\n"".format(worker_ip, worker_index) )\n            w.write(""deeplearning-worker{}\\n"".format(worker_index))\n            worker_index += 1\n\n    gpu_count = get_gpu_count()\n    with open(""/etc/profile.d/deeplearning.sh"", ""a"") as f:\n        num_workers = sum(1 for line in open(WORKER_FILE, ""r""))\n        f.write(""export DEEPLEARNING_WORKERS_COUNT={}\\n"".format(num_workers))\n        f.write(""export DEEPLEARNING_WORKERS_PATH={}\\n"".format(WORKER_FILE))\n        f.write(""export DEEPLEARNING_WORKER_GPU_COUNT={}\\n"".format(gpu_count))\n        f.write(""export EFS_MOUNT={}\\n"".format(efs_mount))\n\n    #change ownership to ec2-user\n    uid = pwd.getpwnam(default_user).pw_uid\n    gid = grp.getgrnam(default_user).gr_gid\n    os.chown(WORKER_FILE, uid, gid)\n\n    return\n\n\'\'\'\nwait for asg setup success message from the lambda function\nmessage will be of the format\n{""min"": 1, ""desired"": 1, ""max"": 1, ""launched"": 1, ""status"": ""success"", ""asg"": ""cfn-test-WorkerAutoScalingGroup-1HPKVL6PJEVQS"", ""event"": ""asg-setup""}\n\'\'\'\ndef wait_until_asg_success(master_queue_name, region, timeout):\n    LOGGER.info(\'wait_until_asg_success on queue_name:{}, timeout:{}\'.format(master_queue_name, timeout))\n    sqs_con = boto.sqs.connect_to_region(region_name=region)\n    sqs_queue = sqs_con.get_queue(queue_name = master_queue_name)\n    asg_success_message = {}\n\n    start_time = time.time()\n    next_execution_ts = start_time\n\n    while True:\n        LOGGER.info(\'checking autoscaling group success message at {}\'.format(datetime.datetime.now()))\n\n        recvd_messages = sqs_con.receive_message(queue=sqs_queue,number_messages=10, visibility_timeout=60)\n        LOGGER.info(\'number of messages received: {}\'.format(len(recvd_messages)))\n        for msg in recvd_messages:\n            msg_body = msg.get_body()\n            LOGGER.info(\'received message with body:{}\'.format(msg_body))\n            try:\n                content = json.loads(msg_body)\n                if content is not None and content[\'event\'] == \'asg-setup\' and content[\'status\'] == \'success\':\n                    # http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/standard-queues.html#standard-queues-at-least-once-delivery\n                    # ignore duplicate message\n                    if content[\'asg\'] not in asg_success_message:\n                        LOGGER.info(\'autosclaing_group: {} succeeded at {}\'.format(content[\'asg\'], datetime.datetime.now()))\n                        asg_success_message[content[\'asg\']] = content\n                    else:\n                        LOGGER.info(\'received duplicate sqs message for {} at {}\'.format(content[\'asg\'], datetime.datetime.now()))\n                sqs_con.delete_message(queue=sqs_queue, message=msg)\n            except (TypeError, KeyError) as e:\n                LOGGER.exception(e)\n                LOGGER.error(msg)\n                continue\n\n        if len(asg_success_message) is 2:\n            LOGGER.info(\'status of all autoscaling_groups received\')\n            break\n\n        next_execution_ts = next_execution_ts + SLEEP_INTERVAL_IN_SECS\n        if (next_execution_ts > (start_time + timeout)):\n            LOGGER.info(\'timeout while checking asg status after {} seconds\'.format(timeout))\n            break\n\n        LOGGER.info(\'not received all autoscaling group success at {}, WAITING :{}\'.format(datetime.datetime.now(), SLEEP_INTERVAL_IN_SECS))\n        time.sleep(next_execution_ts - time.time())\n\n    return asg_success_message\n\ndef wait_for_worker_setup_message(worker_queue_name, timeout, region):\n    LOGGER.info(\'wait_for_worker_setup_message, worker_queue_name:{}, timeout:{}\'.format(worker_queue_name, timeout))\n    sqs_con = boto.sqs.connect_to_region(region_name=region)\n    sqs_queue = sqs_con.get_queue(queue_name = worker_queue_name)\n\n    start_time = time.time()\n    next_execution_ts = start_time\n\n    while True:\n        LOGGER.info(\'checking for worker_setup message at {}\'.format(datetime.datetime.now()))\n        #visibility_timeout is set to 0, so that other workers can simultaneously act on this message\n        recvd_messages = sqs_con.receive_message(queue=sqs_queue,number_messages=10, visibility_timeout=0)\n        LOGGER.info(\'number of messages received: {}\'.format(len(recvd_messages)))\n        for msg in recvd_messages:\n            msg_body = msg.get_body()\n            LOGGER.info(\'received message with body:{}\'.format(msg_body))\n            try:\n                content = json.loads(msg_body)\n                if content is not None and content[\'event\'] == \'worker-setup\':\n                    LOGGER.info(\'received worker-setup success message: {}\'.format(content))\n                    # do not delete the message, other workers need to consume this.\n                    return content[\'master-ip\'], content[\'worker-ips\']\n                else:\n                    #don\'t act on other messages\n                    continue\n            except (TypeError, KeyError) as e:\n                LOGGER.error(e)\n                LOGGER.error(msg)\n                continue\n\n        next_execution_ts = next_execution_ts + SLEEP_INTERVAL_IN_SECS\n        if (next_execution_ts > (start_time + timeout)):\n            LOGGER.info(\'did not receive worker-setup success even after {} seconds\'.format(timeout))\n            return None\n\n        LOGGER.info(\'worker setup not complete is not complete at {}\'.format(datetime.datetime.now()))\n        time.sleep(next_execution_ts - time.time())\n\n    return None\n\ndef wait_until_instances_active(autoscaling_groups, timeout, region):\n    LOGGER.info(\'wait_until_instances_active, asgs:{}, timeout:{}\'.format(autoscaling_groups, timeout))\n\n    autoscale_con = boto.ec2.autoscale.connect_to_region(region_name=region)\n    ec2_con = boto.ec2.connect_to_region(region_name=region)\n    start_time = time.time()\n    next_execution_ts = start_time\n    master_instance_ids = []\n    worker_instance_ids = []\n    master_instances = {}\n    worker_instances = {}\n    try:\n        # http://boto.cloudhackers.com/en/latest/ref/autoscale.html#boto.ec2.autoscale.group.AutoScalingGroup\n        # does not specify how to get the next token for pagination,\n        # since there are only 2 groups in our case, we will assume they will be returned in one call\n        groups = autoscale_con.get_all_groups(names=autoscaling_groups)\n\n        for asg in groups:\n            instance_ids=[]\n            for instance in asg.instances:\n                if instance.health_status == \'Healthy\':\n                    instance_ids.append(instance.instance_id)\n\n            if \'master\' in asg.name.lower():\n                master_instance_ids.extend(instance_ids)\n            else:\n                worker_instance_ids.extend(instance_ids)\n                LOGGER.info(\'from autoscale, found instances:{} for asg:{}\'.format(instance_ids, asg.name))\n\n        LOGGER.info(\'worker_asg_instane_ids:{}, master_ids:{}\'.format(worker_instance_ids, master_instance_ids))\n        next_token = None\n        pending_instance_ids = master_instance_ids + worker_instance_ids\n\n        while(True):\n            LOGGER.info(\'getting ec2 instance info:{}\'.format(pending_instance_ids))\n            reservations = ec2_con.get_all_reservations(instance_ids = pending_instance_ids, next_token = next_token)\n            next_token = reservations.next_token\n\n            for r in reservations:\n                for i in r.instances:\n                    if i.state.lower() == \'running\':\n                        if i.id in master_instance_ids:\n                            LOGGER.info(\'master instance in running state, id:{}, ip:{}\'.format(i.id, i.private_ip_address))\n                            master_instances[i.id] = i.private_ip_address\n                        elif i.id in worker_instance_ids:\n                            LOGGER.info(\'worker instance in running state, id:{}, ip:{}\'.format(i.id, i.private_ip_address))\n                            worker_instances[i.id] = i.private_ip_address\n                            LOGGER.info(\'worker:{}\'.format(worker_instances))\n                        pending_instance_ids.remove(i.id)\n                    elif i.state.lower() == \'pending\':\n                        LOGGER.info(\'instance is still in pending state, instance id:{}\'.format(i.id))\n                        continue\n\n            next_execution_ts = next_execution_ts + SLEEP_INTERVAL_IN_SECS\n            if (len(pending_instance_ids) == 0):\n                LOGGER.info(\'received info of all instances, master: {}, worker: {}\'.format(master_instances, worker_instances))\n                break\n            elif (next_token is not None):\n                LOGGER.info(\'next_token is not None, will continue fetching more instances\')\n                continue\n            elif (next_execution_ts < start_time + timeout):\n                LOGGER.error(\'Reached timeout, pending_instance_ids:{}, next_token:{}\'.format(pending_instance_ids, next_token))\n                break\n            else:\n                LOGGER.info(\'not all instance info is available, pending: {}, waiting for {} seconds\'.format(pending_instance_ids, SLEEP_INTERVAL_IN_SECS))\n                time.sleep(next_execution_ts - time.time())\n\n        LOGGER.info(\'master: {}, worker: {}\'.format(master_instances, worker_instances))\n        return master_instances, worker_instances\n    except Exception as e:\n        LOGGER.exception(e)\n        return ({},{})\n\'\'\'\nThis method will send success signal to the wait handle url\nits assumed cfn-signal aws cli tool is available on the instance\n\'\'\'\ndef send_cfn_success_signal(stack_id, wait_handle_url, aws_region, cfn_path):\n    try:\n        instance_id = boto.utils.get_instance_metadata()[\'instance-id\']\n        cfn_success_signal_command = cfn_path + \'/cfn-signal\'\n        command_args = [cfn_success_signal_command, \'--region\', aws_region, \'--stack\', \\\n        stack_id, \'--success\', \'true\', \'--id\', instance_id, wait_handle_url]\n        LOGGER.info(\'{} command: {}\'.format(cfn_success_signal_command, \' \'.join(map(str, command_args))))\n        output = subprocess.check_output(command_args)\n        LOGGER.info(output)\n    except subprocess.CalledProcessError as e:\n        LOGGER.exception(\'FAILED to send cfn-signal\')\n        sys.exit(1)\n    return\n\n\'\'\'\nwaits for a message on SQS for asg setup complete and instances are active.\nfetches private ip addresses of the instances and sets up metadata\n\'\'\'\ndef setup_worker_metadata(setup_timeout, master_queue_name, stack_id, region):\n    LOGGER.info(\'setup_worker_metadata\')\n\n    start_time = time.time()\n    asg_setup_messages = wait_until_asg_success(master_queue_name, region, setup_timeout)\n    if len(asg_setup_messages) is not 2:\n        LOGGER.error(\'did not receive asg success message for all autoscaling_groups, received only: {}\'.format(asg_setup_messages))\n        sys.exit(1)\n\n    master_asg_message = None\n    worker_asg_message = None\n    for key, value in asg_setup_messages.iteritems():\n        LOGGER.info(\'asg success message:{}\'.format(value))\n        if \'master\' in key.lower():\n            master_asg_message = value\n        else:\n            worker_asg_message = value\n\n    timeout = setup_timeout - (time.time() - start_time)\n    start_time = time.time()\n\n    (master_instances, worker_instances) = wait_until_instances_active([master_asg_message[\'asg\'], worker_asg_message[\'asg\']], timeout, region)\n    LOGGER.info(\'from wait_until_instances_active, master: {}, worker:{}\'.format(master_instances, worker_instances))\n    if (len(master_instances) != 1):\n        LOGGER.error(\'expected single master, instead got instance ips:{}\', master_instances)\n        sys.exit(1)\n    master_instance_ip = master_instances.values()[0]\n    worker_instance_ips = [master_instance_ip]\n\n    if len(worker_instances) is 0:\n        LOGGER.info(\'no worker is launched, using only master instance as worker\')\n    else:\n        worker_instance_ips.extend(worker_instances.values())\n\n        if (len(worker_instances) != worker_asg_message[\'launched\']):\n            LOGGER.error(\'expected {} number of instances to be running, instead got instance_ids: {}, ips: {}\' \\\n            .format(worker_asg_message[\'launched\'], worker_instances.keys(), worker_instances.values()) )\n\n    worker_instance_ips = sorted(worker_instance_ips)\n\n    return master_instance_ip, worker_instance_ips\n\ndef send_worker_setup_msg(worker_queue_name, master_instance_ip, worker_instance_ips, region):\n    LOGGER.info(\'send_worker_setup_msg:{}\'.format(send_worker_setup_msg))\n\n    sqs_con = boto.sqs.connect_to_region(region_name=region)\n    sqs_queue = sqs_con.get_queue(queue_name = worker_queue_name)\n\n    worker_setup_message={\'event\' : \'worker-setup\'}\n    worker_setup_message[\'master-ip\'] = master_instance_ip\n    worker_setup_message[\'worker-ips\'] = worker_instance_ips\n\n    LOGGER.info(\'sending worker-setup message:{}\'.format(json.dumps(worker_setup_message)))\n    sqs_con.send_message(queue=sqs_queue, message_content=json.dumps(worker_setup_message))\n\ndef check_instance_role_availability(role_name, timeout):\n    LOGGER.info(\'check_instance_role_availability, role_name:{}, timeout: {}\'.format(role_name, timeout))\n\n    start_time = time.time()\n    next_execution_ts = start_time\n    while True:\n        LOGGER.info(\'checking presence of instance role: {}, @ :{}\'.format(role_name, datetime.datetime.now()))\n\n        try:\n            metadata = boto.utils.get_instance_metadata(version=\'latest\',timeout=30, num_retries=5)\n            instance_role = metadata[\'iam\'][\'security-credentials\'][role_name]\n            # we don\'t want to log the credentials\n            del instance_role[\'AccessKeyId\']\n            del instance_role[\'SecretAccessKey\']\n            del instance_role[\'Token\']\n            LOGGER.info(\'SUCCESS getting instance role {}\'.format(instance_role))\n            return True\n        except KeyError as e:\n            LOGGER.info(\'FAILED to get instance role: {} @ {}\'.format(role_name, datetime.datetime.now()))\n            pass\n        next_execution_ts = next_execution_ts + SLEEP_INTERVAL_IN_SECS\n        if (next_execution_ts > (start_time + timeout)):\n            LOGGER.info(\'TIMEOUT while checking instance role after {} seconds\'.format(timeout))\n            break\n\n        LOGGER.info(\'WAITING :{} to get instance_role:{} @ {}\'.format(SLEEP_INTERVAL_IN_SECS, role_name, datetime.datetime.now()))\n        time.sleep(next_execution_ts - time.time())\n    return False\n\nLOGGER = setup_logging()\ndef main():\n    LOGGER.info(""main"")\n\n    try:\n        AWS_DL_NODE_TYPE = os.environ[""AWS_DL_NODE_TYPE""]\n        AWS_DL_MASTER_QUEUE = os.environ[\'AWS_DL_MASTER_QUEUE\']\n        AWS_DL_WORKER_QUEUE = os.environ[\'AWS_DL_WORKER_QUEUE\']\n        AWS_DL_WAITCONDITION_TIMEOUT = float(os.environ[\'AWS_DL_WAITCONDITION_TIMEOUT\'])\n        AWS_DL_MASTERLAUNCH_TIMEOUT = float(os.environ[\'AWS_DL_MASTERLAUNCH_TIMEOUT\'])\n        AWS_DL_STACK_ID = os.environ[\'AWS_DL_STACK_ID\']\n        AWS_DL_WAIT_HANDLE = os.environ[\'AWS_DL_WAIT_HANDLE\']\n        AWS_DL_ROLE_NAME = os.environ[\'AWS_DL_ROLE_NAME\']\n        AWS_DL_DEFAULT_USER = os.environ[\'AWS_DL_DEFAULT_USER\']\n        AWS_REGION = os.environ[\'AWS_REGION\']\n        EFS_MOUNT = os.environ[\'EFS_MOUNT\']\n        CFN_PATH = os.environ[\'CFN_PATH\']\n\n        LOGGER.info(\'AWS_DL_NODE_TYPE:{}\\n AWS_DL_MASTER_QUEUE:{}\\n AWS_DL_WORKER_QUEUE:{}\\n AWS_DL_WAITCONDITION_TIMEOUT:{}\\n, AWS_DL_MASTERLAUNCH_TIMEOUT:{}\\n AWS_DL_STACK_ID:{}\\n \\\n            AWS_DL_WAIT_HANDLE:{}\\n AWS_DL_ROLE_NAME:{}\\n AWS_REGION:{}, AWS_DL_DEFAULT_USER:{}, EFS_MOUNT:{}, CFN_PATH:{}\\n\'.format(AWS_DL_NODE_TYPE, AWS_DL_MASTER_QUEUE, AWS_DL_WORKER_QUEUE, \\\n            AWS_DL_WAITCONDITION_TIMEOUT, AWS_DL_MASTERLAUNCH_TIMEOUT, AWS_DL_STACK_ID, AWS_DL_WAIT_HANDLE, AWS_DL_ROLE_NAME, AWS_REGION, AWS_DL_DEFAULT_USER, EFS_MOUNT, CFN_PATH)\n        )\n\n        # we want to make sure we finish before the timeout expires\n        setup_timeout = AWS_DL_WAITCONDITION_TIMEOUT - AWS_DL_MASTERLAUNCH_TIMEOUT\n        start_time = time.time()\n        check_instance_role_availability(AWS_DL_ROLE_NAME, setup_timeout)\n        setup_timeout = setup_timeout - (time.time() - start_time)\n\n        # get master ips\n        if (AWS_DL_NODE_TYPE.lower() == \'master\'):\n            master_instance_ip, worker_instance_ips = setup_worker_metadata(setup_timeout, AWS_DL_MASTER_QUEUE, AWS_DL_STACK_ID, AWS_REGION)\n            setup_env_variables(master_instance_ip, worker_instance_ips, AWS_DL_DEFAULT_USER, EFS_MOUNT)\n            send_worker_setup_msg(AWS_DL_WORKER_QUEUE, master_instance_ip, worker_instance_ips, AWS_REGION)\n            send_cfn_success_signal(AWS_DL_STACK_ID, AWS_DL_WAIT_HANDLE, AWS_REGION, CFN_PATH)\n\n        elif (AWS_DL_NODE_TYPE.lower() == \'worker\'):\n            master_instance_ip, worker_instance_ips = wait_for_worker_setup_message(AWS_DL_WORKER_QUEUE, setup_timeout, AWS_REGION)\n            if master_instance_ip is None or worker_instance_ips is None:\n                LOGGER.error(\'FAILED worker metadata setup : master_ip:{}, worker_ips:{}\'.format(master_instance_ip, worker_instance_ips))\n                sys.exit(1)\n            setup_env_variables(master_instance_ip, worker_instance_ips, AWS_DL_DEFAULT_USER, EFS_MOUNT)\n        else:\n            LOGGER.error(\'unknown node type: {}\'.format(AWS_DL_NODE_TYPE))\n            sys.exit(1)\n\n    except Exception as e:\n        LOGGER.exception(e)\n        sys.exit(1)\n\nif  __name__ ==\'__main__\':\n    main()\n'"
cfn-lambda_function/lambda_function.py,0,"b'#  Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n#  Licensed under the Amazon Software License (the ""License"").\n#  You may not use this file except in compliance with the License.\n#  A copy of the License is located at\n#\n#  http://aws.amazon.com/asl/\n#\n#  or in the ""license"" file accompanying this file. This file is distributed\n#  on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n#  express or implied. See the License for the specific language governing\n#  permissions and limitations under the License.\n\nfrom __future__ import print_function\n\nimport json\nimport os\nimport boto3\nimport collections\n\nprint(\'Loading function\')\nASGInstanceCount = collections.namedtuple(\'ASGInstanceCount\', [\'min\', \'desired\', \'max\', \'launched\'])\n\ndef lambda_handler(event, context):\n    # print(""Received event: "" + json.dumps(event, indent=2))\n    message = json.loads(event[\'Records\'][0][\'Sns\'][\'Message\'])\n    # print(""From SNS: "" + event[\'Records\'][0][\'Sns\'][\'Message\'])\n    # print(\'AWS_STACK_ID: \' + os.environ[\'AWS_STACK_ID\'])\n    if message[\'Event\']:\n        print(\'EVENT: \', message[\'Event\'])\n        return eval(get_handler(message[\'Event\']))(message)\n    else:\n        return do_nothing(message)\n\n    return message\n\ndef get_handler(Event):\n    return {\n        \'autoscaling:EC2_INSTANCE_LAUNCH\': \'on_instance_launch\',\n        \'autoscaling:EC2_INSTANCE_LAUNCH_ERROR\': \'on_instance_launch_error\',\n        \'autoscaling:EC2_INSTANCE_TERMINATE\': \'on_instance_terminate\',\n        \'autoscaling:EC2_INSTANCE_TERMINATE_ERROR\': \'on_instance_terminate_error\',\n        \'autoscaling:TEST_NOTIFICATION\' : \'do_nothing\'\n    }[Event]\n\ndef do_nothing(message):\n    print(\'do_nothing\')\n    print(""Unknown Event. Received message: "" + json.dumps(message, indent=2))\n    return\n\ndef send_asg_success(status, asg, asg_instance_counts):\n     sqs_url = os.environ[\'AWS_DL_MASTER_SQS_URL\']\n     print(""sqs_url: "", sqs_url)\n     sqs_con = boto3.client(\'sqs\')\n     msg_dict = asg_instance_counts._asdict()\n     msg_dict[\'status\'] = status.lower()\n     msg_dict[\'asg\'] = asg\n     msg_dict[\'event\'] = \'asg-setup\'\n \n     print(\'sending message to sqs:\', json.dumps(msg_dict))\n     sqs_con.send_message(QueueUrl=sqs_url, MessageBody=json.dumps(msg_dict))\n     return\n\n\'\'\'\n    get various instance counts associated with the asg\n\'\'\'\ndef get_instance_count(autoscaling_group_name):\n    print(\'get_instance_count\')\n\n    autoscale_con = boto3.client(\'autoscaling\')\n    \n    asg = autoscale_con.describe_auto_scaling_groups(AutoScalingGroupNames=[autoscaling_group_name])[\'AutoScalingGroups\'][0]\n    num_instances_healthy = 0\n\n#   TODO: check if pagination needs to be handled for asg.instances\n    for each_instance in asg[\'Instances\']:\n        \'\'\'         \n        we will only consider instances that are inService or are in Pending state \n        http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-lifecycle.html\n        since this lambda function is expected to run during stack creation, we\'ll ignore the \n        case where the User could go and Stop the Instance and can move the instance state to \'Pending\'\n        \'\'\'\n        if each_instance[\'LifecycleState\'] == \'InService\' and each_instance[\'HealthStatus\'] == \'Healthy\':\n            num_instances_healthy += 1\n        elif each_instance[\'LifecycleState\'] == \'Pending\' and each_instance[\'HealthStatus\'] == \'Healthy\':\n            num_instances_healthy += 1\n        else:\n            continue    \n    \n    asg_instance_counts = ASGInstanceCount(min=asg[\'MinSize\'], max=asg[\'MaxSize\'], desired=asg[\'DesiredCapacity\'], launched=num_instances_healthy)\n    print(asg_instance_counts._asdict())\n    return asg_instance_counts\n\ndef on_instance_launch(message):\n    print(\'on_instance_launch\')\n\n    autoscaling_group_name = message[\'AutoScalingGroupName\']\n    availability_zone = message[\'Details\'][\'Availability Zone\']\n    start_time = message[\'StartTime\']\n    instance_id = message[\'EC2InstanceId\']\n    request_id = message[\'RequestId\']\n\n    if autoscaling_group_name and \'WorkerAutoScalingGroup\' in autoscaling_group_name:\n        autoscaling_group = \'WorkerAutoScalingGroup\'\n    elif autoscaling_group_name and \'MasterAutoScalingGroup\' in autoscaling_group_name:\n        autoscaling_group = \'MasterAutoScalingGroup\'\n    else:\n        print(\'Unknown AutoScaling group,message :\',message)\n        return\n    \n    print(\'AutoScalingGroupName: \', autoscaling_group_name, \', EC2InstanceId: \', instance_id, \\\n    \', Availability Zone: \', availability_zone, \', Instance StartTime: \', start_time, \', RequestId: \',request_id)\n    \n    logical_resource_id = None\n    asg_instance_counts = get_instance_count(autoscaling_group_name)\n\n    if asg_instance_counts.launched == asg_instance_counts.desired:\n        print(\'Launched desired number of instances:\', asg_instance_counts.launched)\n        send_asg_success(\'SUCCESS\', autoscaling_group_name, asg_instance_counts)\n\n        if autoscaling_group is \'MasterAutoScalingGroup\':\n            cfn_con = boto3.client(\'cloudformation\')\n            print(\'Sending cfn-signal SUCCESS to:\', autoscaling_group_name, \'with instance Id: \', instance_id)\n            try:\n                cfn_con.signal_resource(StackName=os.environ[\'AWS_DL_STACK_ID\'], LogicalResourceId=autoscaling_group, \\\n                    UniqueId=instance_id,Status=\'SUCCESS\')\n            except Exception as e:\n                print(\'exception sending cfn-signal: \', e.message)\n        else:\n            autoscale_con = boto3.client(\'autoscaling\')\n            print(\'Suspending ReplaceUnhealthy processes for the asg: \', autoscaling_group_name)\n            autoscale_con.suspend_processes(AutoScalingGroupName=autoscaling_group_name, ScalingProcesses=[\'ReplaceUnhealthy\'])\n\n    return\n\n\'\'\'\nsuspend autoscaling policy\nchange desired capacity\nsend success message to sqs\n\n\'\'\'\ndef on_instance_launch_error(message):\n    print(\'on_instance_launch_error\')\n\n    autoscaling_group_name = message[\'AutoScalingGroupName\']\n    availability_zone = message[\'Details\'][\'Availability Zone\']\n    start_time = message[\'StartTime\']\n    instance_id = message[\'EC2InstanceId\']\n    request_id = message[\'RequestId\']\n\n    print(\'AutoScalingGroupName: \', autoscaling_group_name, \', EC2InstanceId: \', instance_id, \\\n    \', Availability Zone: \', availability_zone, \', Instance StartTime: \', start_time, \', RequestId: \',request_id)\n    print(\'StatusCode: \', message[\'StatusCode\'],  \'StatusMessage: \', message[\'StatusMessage\'])\n    \n    autoscale_con = boto3.client(\'autoscaling\')\n    asg_instance_counts = get_instance_count(autoscaling_group_name)\n\n    \'\'\'\n    change desired capacity and suspend processes only if we have atleast the min_size requested\n    \'\'\'\n    if asg_instance_counts.launched >= asg_instance_counts.min:\n        print(\'setting desired capacity of asg: \', autoscaling_group_name, \' to number of Healthy instances: \', asg_instance_counts.launched)\n        autoscale_con.set_desired_capacity(AutoScalingGroupName=autoscaling_group_name, DesiredCapacity=asg_instance_counts.launched)\n        print(\'Suspending ReplaceUnhealthy processes for the asg: \', autoscaling_group_name)\n        autoscale_con.suspend_processes(AutoScalingGroupName=autoscaling_group_name, ScalingProcesses=[\'ReplaceUnhealthy\'])\n        print(\'sending worker asg setup message complete to sqs\')\n        send_asg_success(\'SUCCESS\', autoscaling_group_name, asg_instance_counts)\n \n    return\n\n\'\'\'\n\'\'\'\ndef on_instance_terminate(message):\n    print(\'on_instance_terminate\')\n\n    autoscaling_group_name = message[\'AutoScalingGroupName\']\n    availability_zone = message[\'Details\'][\'Availability Zone\']\n    start_time = message[\'StartTime\']\n    instance_id = message[\'EC2InstanceId\']\n    request_id = message[\'RequestId\']\n\n    print(\'AutoScalingGroupName: \', autoscaling_group_name, \', EC2InstanceId: \', instance_id, \\\n    \', Availability Zone: \', availability_zone, \', Instance StartTime: \', start_time, \', RequestId: \',request_id)\n\n    return\n\ndef on_instance_terminate_error():\n    print(\'on_instance_terminate_error\')\n\n    autoscaling_group_name = message[\'AutoScalingGroupName\']\n    availability_zone = message[\'Details\'][\'Availability Zone\']\n    start_time = message[\'StartTime\']\n    instance_id = message[\'EC2InstanceId\']\n    request_id = message[\'RequestId\']\n\n    print(\'AutoScalingGroupName: \', autoscaling_group_name, \', EC2InstanceId: \', instance_id, \\\n    \', Availability Zone: \', availability_zone, \', Instance StartTime: \', start_time, \', RequestId: \',request_id)\n\n    return\n'"
examples/tensorflow/cifar10_multi_machine_train.py,19,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom datetime import datetime\nimport sys\nimport os.path\nsys.path.insert(0, os.path.dirname(__file__) + \'/models/tutorials/image/cifar10/\')\n\nimport cifar10\nimport re\nimport time\nimport argparse\nimport numpy as np\nfrom six.moves import xrange  # pylint: disable=redefined-builtin\nimport tensorflow as tf\n\n\nFLAGS = tf.app.flags.FLAGS\n\ntf.app.flags.DEFINE_integer(\'max_steps\', 1000000,\n                            """"""Number of batches to run."""""")\ntf.app.flags.DEFINE_string(""ps_hosts"", """",\n                           ""Comma-separated list of hostname:port pairs"")\ntf.app.flags.DEFINE_string(""worker_hosts"", """",\n                           ""Comma-separated list of hostname:port pairs"")\n\ntf.app.flags.DEFINE_string(""job_name"", """", ""One of \'ps\', \'worker\'"")\n\ntf.app.flags.DEFINE_integer(""task_index"", 0, ""Index of task within the job"")\n\ntf.app.flags.DEFINE_string(\'train_dir\', \'/tmp/cifar10_train\',\n                           """"""Directory where to write event logs """"""\n                           """"""and checkpoint."""""")\n\ndef main(_):\n\n    class _LoggerHook(tf.train.SessionRunHook):\n        """"""Logs loss and runtime.""""""\n\n        def begin(self):\n            self._step = -1\n\n        def before_run(self, run_context):\n            self._step += 1\n            self._start_time = time.time()\n            return tf.train.SessionRunArgs(loss)  # Asks for loss value.\n\n        def after_run(self, run_context, run_values):\n            duration = time.time() - self._start_time\n            loss_value = run_values.results\n            if self._step % 10 == 0:\n                num_examples_per_step = FLAGS.batch_size\n                examples_per_sec = num_examples_per_step / duration\n                sec_per_batch = float(duration)\n\n                format_str = (\'%s: step %d, loss = %.2f (%.1f examples/sec; %.3f \'\n                            \'sec/batch)\')\n                print (format_str % (datetime.now(), self._step, loss_value,\n                                    examples_per_sec, sec_per_batch))\n    ps_hosts = FLAGS.ps_hosts.split("","")\n    worker_hosts = FLAGS.worker_hosts.split("","")\n\n    # Create a cluster from the parameter server and worker hosts.\n    cluster = tf.train.ClusterSpec({""ps"": ps_hosts, ""worker"": worker_hosts})\n\n    # Create and start a server for the local task.\n    server = tf.train.Server(cluster,\n                            job_name=FLAGS.job_name,\n                            task_index=FLAGS.task_index)\n\n    if FLAGS.job_name == ""ps"":\n        server.join()\n    elif FLAGS.job_name == ""worker"":\n\n        # Assigns ops to the local worker by default.\n        with tf.device(tf.train.replica_device_setter(\n            worker_device=""/job:worker/task:%d"" % FLAGS.task_index,\n            cluster=cluster)):\n\n            global_step = tf.contrib.framework.get_or_create_global_step()\n\n            # Get images and labels for CIFAR-10.\n            images, labels = cifar10.distorted_inputs()\n\n            # Build inference Graph.\n            logits = cifar10.inference(images)\n\n            # Build the portion of the Graph calculating the losses. Note that we will\n            # assemble the total_loss using a custom function below.\n            loss = cifar10.loss(logits, labels)\n\n            # Build a Graph that trains the model with one batch of examples and\n            # updates the model parameters.\n            train_op = cifar10.train(loss,global_step)\n\n        # The StopAtStepHook handles stopping after running given steps.\n        hooks=[tf.train.StopAtStepHook(last_step=FLAGS.max_steps), _LoggerHook()]\n\n        # The MonitoredTrainingSession takes care of session initialization,\n        # restoring from a checkpoint, saving to a checkpoint, and closing when done\n        # or an error occurs.\n        with tf.train.MonitoredTrainingSession(master=server.target,\n                                                is_chief=(FLAGS.task_index == 0),\n                                                checkpoint_dir=FLAGS.train_dir,\n                                                save_checkpoint_secs=60,\n                                                hooks=hooks) as mon_sess:\n            while not mon_sess.should_stop():\n                # Run a training step asynchronously.\n                # See `tf.train.SyncReplicasOptimizer` for additional details on how to\n                # perform *synchronous* training.\n                # mon_sess.run handles AbortedError in case of preempted PS.\n                mon_sess.run(train_op)\n\nif __name__ == ""__main__"":\n    if tf.gfile.Exists(FLAGS.train_dir) is False:\n        tf.gfile.MakeDirs(FLAGS.train_dir)\n    tf.app.run()\n'"
examples/tensorflow/generate_trainer.py,0,"b'import sys, getopt, os, argparse\n\n#parse arguments\ndef parse_args():\n    parser = argparse.ArgumentParser(description=\'Run Benchmark on various imagenet networks using train_imagenent.py\')\n    parser.add_argument(\'--trainer_script_dir\', type=str, help=\'location where distributed trainer scripts should be stored, use a shared file system like efs\',required=True)\n    parser.add_argument(\'--log_dir\', type=str, default=""/tmp/"", help=\'location where the logs should be stored\',required=False)\n    parser.add_argument(\'--workers_file_path\', type=str, help=\'worker file path\', required=True)\n    parser.add_argument(\'--worker_count\', type=int, help=\'number of workers\', required=True)\n    parser.add_argument(\'--worker_gpu_count\', type=int, help=\'number of gpus on each worker to use\', required=True)\n    parser.add_argument(\'--training_script\', nargs=\'+\', help = \'training script and its arguments, e.g: --script cifar10_train.py --batch_size 8 --data_dir /myEFSVolume/data\')\n    args, unknown = parser.parse_known_args()\n    args.training_script += unknown\n    args.training_script = \' \'.join(args.training_script)\n    return args\n\n# generates a list of workers where the training will be run. \n# one worker per GPU\ndef get_worker_list(nodes, gpu_per_node):\n    lst = []\n    for node in nodes:\n        for index in range(gpu_per_node):\n            port = str(2230 + (index%gpu_per_node))\n            lst.append( node + "":"" + port )\n    return \',\'.join(lst)\n\n# generates a list of parameter servers\n# one parameter server per node\ndef get_ps_list(nodes):\n    return \',\'.join( [n + "":2222"" for n in nodes] )\n\n#creates list of commands that has to be run on each node\ndef get_script(training_script, workers_list, ps_list, index, gpu_per_node, log_dir):\n   \n    script = \'source /etc/profile\'\n    script += ""\\n\\n""\n\n    script += ""CUDA_VISIBLE_DEVICES=\'\' python "" + training_script + "" "" \\\n                + ""--ps_hosts="" + ps_list + "" "" \\\n                + ""--worker_hosts="" + workers_list + "" "" \\\n                + ""--job_name=ps "" \\\n                + ""--task_index="" + str(index) \\\n                + "" > "" + log_dir + ""/ps"" + str(index) \\\n                + "" 2>&1"" \\\n                + "" &"" \n                \n    script += ""\\n\\n""\n\n    for i in range(gpu_per_node):    \n        script += ""CUDA_VISIBLE_DEVICES=\'"" + str(i) + ""\' "" \\\n                    + ""python "" + training_script + "" "" \\\n                    + ""--ps_hosts="" + ps_list + "" "" \\\n                    + ""--worker_hosts="" + workers_list + "" "" \\\n                    + ""--job_name=worker "" \\\n                    + ""--task_index="" + str(index*gpu_per_node + i) \\\n                    + "" > ""+ log_dir + ""/worker"" + str(index*gpu_per_node + i) \\\n                    + "" 2>&1"" \\\n                    + "" &""\n                \n        script += ""\\n\\n""\n    \n    return script    \n\ndef gen_scripts(training_script, nodes_file, trainer_script_dir, num_nodes, gpu_per_node, log_dir):\n\n    with open(nodes_file, \'r\') as f:\n        nodes = f.read().splitlines()\n    \n    workers_list = get_worker_list(nodes, gpu_per_node)\n    ps_list = get_ps_list(nodes)\n\n    for index, host in enumerate(nodes):\n        script = get_script(training_script, workers_list, ps_list, index, gpu_per_node, log_dir)\n        file_name = trainer_script_dir + ""/"" + host + "".sh""\n        with open(file_name, ""w"") as sh_file:\n            sh_file.write(script)\n\ndef main():\n    args = parse_args()\n    if not os.path.exists(args.log_dir):\n        os.makedirs(args.log_dir)  \n    gen_scripts(args.training_script, args.workers_file_path, args.trainer_script_dir, \n        args.worker_count, args.worker_gpu_count, args.log_dir)\n\nif __name__ == ""__main__"":\n    main()\n'"
