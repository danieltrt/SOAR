file_path,api_count,code
input_data.py,0,"b'""""""Functions for downloading and reading MNIST data.""""""\nfrom __future__ import print_function\nimport gzip\nimport os\nimport urllib\nimport numpy\nSOURCE_URL = \'http://yann.lecun.com/exdb/mnist/\'\ndef maybe_download(filename, work_directory):\n  """"""Download the data from Yann\'s website, unless it\'s already here.""""""\n  if not os.path.exists(work_directory):\n    os.mkdir(work_directory)\n  filepath = os.path.join(work_directory, filename)\n  if not os.path.exists(filepath):\n    filepath, _ = urllib.urlretrieve(SOURCE_URL + filename, filepath)\n    statinfo = os.stat(filepath)\n    print(\'Succesfully downloaded\', filename, statinfo.st_size, \'bytes.\')\n  return filepath\ndef _read32(bytestream):\n  dt = numpy.dtype(numpy.uint32).newbyteorder(\'>\')\n  return numpy.frombuffer(bytestream.read(4), dtype=dt)\ndef extract_images(filename):\n  """"""Extract the images into a 4D uint8 numpy array [index, y, x, depth].""""""\n  print(\'Extracting\', filename)\n  with gzip.open(filename) as bytestream:\n    magic = _read32(bytestream)\n    if magic != 2051:\n      raise ValueError(\n          \'Invalid magic number %d in MNIST image file: %s\' %\n          (magic, filename))\n    num_images = _read32(bytestream)\n    rows = _read32(bytestream)\n    cols = _read32(bytestream)\n    buf = bytestream.read(rows * cols * num_images)\n    data = numpy.frombuffer(buf, dtype=numpy.uint8)\n    data = data.reshape(num_images, rows, cols, 1)\n    return data\ndef dense_to_one_hot(labels_dense, num_classes=10):\n  """"""Convert class labels from scalars to one-hot vectors.""""""\n  num_labels = labels_dense.shape[0]\n  index_offset = numpy.arange(num_labels) * num_classes\n  labels_one_hot = numpy.zeros((num_labels, num_classes))\n  labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n  return labels_one_hot\ndef extract_labels(filename, one_hot=False):\n  """"""Extract the labels into a 1D uint8 numpy array [index].""""""\n  print(\'Extracting\', filename)\n  with gzip.open(filename) as bytestream:\n    magic = _read32(bytestream)\n    if magic != 2049:\n      raise ValueError(\n          \'Invalid magic number %d in MNIST label file: %s\' %\n          (magic, filename))\n    num_items = _read32(bytestream)\n    buf = bytestream.read(num_items)\n    labels = numpy.frombuffer(buf, dtype=numpy.uint8)\n    if one_hot:\n      return dense_to_one_hot(labels)\n    return labels\nclass DataSet(object):\n  def __init__(self, images, labels, fake_data=False):\n    if fake_data:\n      self._num_examples = 10000\n    else:\n      assert images.shape[0] == labels.shape[0], (\n          ""images.shape: %s labels.shape: %s"" % (images.shape,\n                                                 labels.shape))\n      self._num_examples = images.shape[0]\n      # Convert shape from [num examples, rows, columns, depth]\n      # to [num examples, rows*columns] (assuming depth == 1)\n      assert images.shape[3] == 1\n      images = images.reshape(images.shape[0],\n                              images.shape[1] * images.shape[2])\n      # Convert from [0, 255] -> [0.0, 1.0].\n      images = images.astype(numpy.float32)\n      images = numpy.multiply(images, 1.0 / 255.0)\n    self._images = images\n    self._labels = labels\n    self._epochs_completed = 0\n    self._index_in_epoch = 0\n  @property\n  def images(self):\n    return self._images\n  @property\n  def labels(self):\n    return self._labels\n  @property\n  def num_examples(self):\n    return self._num_examples\n  @property\n  def epochs_completed(self):\n    return self._epochs_completed\n  def next_batch(self, batch_size, fake_data=False):\n    """"""Return the next `batch_size` examples from this data set.""""""\n    if fake_data:\n      fake_image = [1.0 for _ in xrange(784)]\n      fake_label = 0\n      return [fake_image for _ in xrange(batch_size)], [\n          fake_label for _ in xrange(batch_size)]\n    start = self._index_in_epoch\n    self._index_in_epoch += batch_size\n    if self._index_in_epoch > self._num_examples:\n      # Finished epoch\n      self._epochs_completed += 1\n      # Shuffle the data\n      perm = numpy.arange(self._num_examples)\n      numpy.random.shuffle(perm)\n      self._images = self._images[perm]\n      self._labels = self._labels[perm]\n      # Start next epoch\n      start = 0\n      self._index_in_epoch = batch_size\n      assert batch_size <= self._num_examples\n    end = self._index_in_epoch\n    return self._images[start:end], self._labels[start:end]\ndef read_data_sets(train_dir, fake_data=False, one_hot=False):\n  class DataSets(object):\n    pass\n  data_sets = DataSets()\n  if fake_data:\n    data_sets.train = DataSet([], [], fake_data=True)\n    data_sets.validation = DataSet([], [], fake_data=True)\n    data_sets.test = DataSet([], [], fake_data=True)\n    return data_sets\n  TRAIN_IMAGES = \'train-images-idx3-ubyte.gz\'\n  TRAIN_LABELS = \'train-labels-idx1-ubyte.gz\'\n  TEST_IMAGES = \'t10k-images-idx3-ubyte.gz\'\n  TEST_LABELS = \'t10k-labels-idx1-ubyte.gz\'\n  VALIDATION_SIZE = 5000\n  local_file = maybe_download(TRAIN_IMAGES, train_dir)\n  train_images = extract_images(local_file)\n  local_file = maybe_download(TRAIN_LABELS, train_dir)\n  train_labels = extract_labels(local_file, one_hot=one_hot)\n  local_file = maybe_download(TEST_IMAGES, train_dir)\n  test_images = extract_images(local_file)\n  local_file = maybe_download(TEST_LABELS, train_dir)\n  test_labels = extract_labels(local_file, one_hot=one_hot)\n  validation_images = train_images[:VALIDATION_SIZE]\n  validation_labels = train_labels[:VALIDATION_SIZE]\n  train_images = train_images[VALIDATION_SIZE:]\n  train_labels = train_labels[VALIDATION_SIZE:]\n  data_sets.train = DataSet(train_images, train_labels)\n  data_sets.validation = DataSet(validation_images, validation_labels)\n  data_sets.test = DataSet(test_images, test_labels)\n  return data_sets'"
examples/1_Introduction/basic_eager_api.py,9,"b'\'\'\'\nBasic introduction to TensorFlow\'s Eager API.\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n\nWhat is Eager API?\n"" Eager execution is an imperative, define-by-run interface where operations are\nexecuted immediately as they are called from Python. This makes it easier to\nget started with TensorFlow, and can make research and development more\nintuitive. A vast majority of the TensorFlow API remains the same whether eager\nexecution is enabled or not. As a result, the exact same code that constructs\nTensorFlow graphs (e.g. using the layers API) can be executed imperatively\nby using eager execution. Conversely, most models written with Eager enabled\ncan be converted to a graph that can be further optimized and/or extracted\nfor deployment in production without changing code. "" - Rajat Monga\n\n\'\'\'\nfrom __future__ import absolute_import, division, print_function\n\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow.contrib.eager as tfe\n\n# Set Eager API\nprint(""Setting Eager mode..."")\ntfe.enable_eager_execution()\n\n# Define constant tensors\nprint(""Define constant tensors"")\na = tf.constant(2)\nprint(""a = %i"" % a)\nb = tf.constant(3)\nprint(""b = %i"" % b)\n\n# Run the operation without the need for tf.Session\nprint(""Running operations, without tf.Session"")\nc = a + b\nprint(""a + b = %i"" % c)\nd = a * b\nprint(""a * b = %i"" % d)\n\n\n# Full compatibility with Numpy\nprint(""Mixing operations with Tensors and Numpy Arrays"")\n\n# Define constant tensors\na = tf.constant([[2., 1.],\n                 [1., 0.]], dtype=tf.float32)\nprint(""Tensor:\\n a = %s"" % a)\nb = np.array([[3., 0.],\n              [5., 1.]], dtype=np.float32)\nprint(""NumpyArray:\\n b = %s"" % b)\n\n# Run the operation without the need for tf.Session\nprint(""Running operations, without tf.Session"")\n\nc = a + b\nprint(""a + b = %s"" % c)\n\nd = tf.matmul(a, b)\nprint(""a * b = %s"" % d)\n\nprint(""Iterate through Tensor \'a\':"")\nfor i in range(a.shape[0]):\n    for j in range(a.shape[1]):\n        print(a[i][j])\n\n'"
examples/1_Introduction/basic_operations.py,12,"b'\'\'\'\nBasic Operations example using TensorFlow library.\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n\'\'\'\n\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\n# Basic constant operations\n# The value returned by the constructor represents the output\n# of the Constant op.\na = tf.constant(2)\nb = tf.constant(3)\n\n# Launch the default graph.\nwith tf.Session() as sess:\n    print(""a=2, b=3"")\n    print(""Addition with constants: %i"" % sess.run(a+b))\n    print(""Multiplication with constants: %i"" % sess.run(a*b))\n\n# Basic Operations with variable as graph input\n# The value returned by the constructor represents the output\n# of the Variable op. (define as input when running session)\n# tf Graph input\na = tf.placeholder(tf.int16)\nb = tf.placeholder(tf.int16)\n\n# Define some operations\nadd = tf.add(a, b)\nmul = tf.multiply(a, b)\n\n# Launch the default graph.\nwith tf.Session() as sess:\n    # Run every operation with variable input\n    print(""Addition with variables: %i"" % sess.run(add, feed_dict={a: 2, b: 3}))\n    print(""Multiplication with variables: %i"" % sess.run(mul, feed_dict={a: 2, b: 3}))\n\n\n# ----------------\n# More in details:\n# Matrix Multiplication from TensorFlow official tutorial\n\n# Create a Constant op that produces a 1x2 matrix.  The op is\n# added as a node to the default graph.\n#\n# The value returned by the constructor represents the output\n# of the Constant op.\nmatrix1 = tf.constant([[3., 3.]])\n\n# Create another Constant that produces a 2x1 matrix.\nmatrix2 = tf.constant([[2.],[2.]])\n\n# Create a Matmul op that takes \'matrix1\' and \'matrix2\' as inputs.\n# The returned value, \'product\', represents the result of the matrix\n# multiplication.\nproduct = tf.matmul(matrix1, matrix2)\n\n# To run the matmul op we call the session \'run()\' method, passing \'product\'\n# which represents the output of the matmul op.  This indicates to the call\n# that we want to get the output of the matmul op back.\n#\n# All inputs needed by the op are run automatically by the session.  They\n# typically are run in parallel.\n#\n# The call \'run(product)\' thus causes the execution of threes ops in the\n# graph: the two constants and matmul.\n#\n# The output of the op is returned in \'result\' as a numpy `ndarray` object.\nwith tf.Session() as sess:\n    result = sess.run(product)\n    print(result)\n    # ==> [[ 12.]]\n'"
examples/1_Introduction/helloworld.py,2,"b""'''\nHelloWorld example using TensorFlow library.\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n'''\n\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\n# Simple hello world using TensorFlow\n\n# Create a Constant op\n# The op is added as a node to the default graph.\n#\n# The value returned by the constructor represents the output\n# of the Constant op.\nhello = tf.constant('Hello, TensorFlow!')\n\n# Start tf session\nsess = tf.Session()\n\n# Run the op\nprint(sess.run(hello))\n"""
examples/2_BasicModels/gradient_boosted_decision_tree.py,5,"b'"""""" Gradient Boosted Decision Tree (GBDT).\n\nImplement a Gradient Boosted Decision tree with TensorFlow to classify\nhandwritten digit images. This example is using the MNIST database of\nhandwritten digits as training samples (http://yann.lecun.com/exdb/mnist/).\n\nLinks:\n    [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n""""""\n\nfrom __future__ import print_function\n\nimport tensorflow as tf\nfrom tensorflow.contrib.boosted_trees.estimator_batch.estimator import GradientBoostedDecisionTreeClassifier\nfrom tensorflow.contrib.boosted_trees.proto import learner_pb2 as gbdt_learner\n\n# Ignore all GPUs (current TF GBDT does not support GPU).\nimport os\nos.environ[""CUDA_VISIBLE_DEVICES""] = """"\n\n# Import MNIST data\n# Set verbosity to display errors only (Remove this line for showing warnings)\ntf.logging.set_verbosity(tf.logging.ERROR)\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""/tmp/data/"", one_hot=False,\n                                  source_url=\'http://yann.lecun.com/exdb/mnist/\')\n\n# Parameters\nbatch_size = 4096 # The number of samples per batch\nnum_classes = 10 # The 10 digits\nnum_features = 784 # Each image is 28x28 pixels\nmax_steps = 10000\n\n# GBDT Parameters\nlearning_rate = 0.1\nl1_regul = 0.\nl2_regul = 1.\nexamples_per_layer = 1000\nnum_trees = 10\nmax_depth = 16\n\n# Fill GBDT parameters into the config proto\nlearner_config = gbdt_learner.LearnerConfig()\nlearner_config.learning_rate_tuner.fixed.learning_rate = learning_rate\nlearner_config.regularization.l1 = l1_regul\nlearner_config.regularization.l2 = l2_regul / examples_per_layer\nlearner_config.constraints.max_tree_depth = max_depth\ngrowing_mode = gbdt_learner.LearnerConfig.LAYER_BY_LAYER\nlearner_config.growing_mode = growing_mode\nrun_config = tf.contrib.learn.RunConfig(save_checkpoints_secs=300)\nlearner_config.multi_class_strategy = (\n    gbdt_learner.LearnerConfig.DIAGONAL_HESSIAN)\\\n\n# Create a TensorFlor GBDT Estimator\ngbdt_model = GradientBoostedDecisionTreeClassifier(\n    model_dir=None, # No save directory specified\n    learner_config=learner_config,\n    n_classes=num_classes,\n    examples_per_layer=examples_per_layer,\n    num_trees=num_trees,\n    center_bias=False,\n    config=run_config)\n\n# Display TF info logs\ntf.logging.set_verbosity(tf.logging.INFO)\n\n# Define the input function for training\ninput_fn = tf.estimator.inputs.numpy_input_fn(\n    x={\'images\': mnist.train.images}, y=mnist.train.labels,\n    batch_size=batch_size, num_epochs=None, shuffle=True)\n# Train the Model\ngbdt_model.fit(input_fn=input_fn, max_steps=max_steps)\n\n# Evaluate the Model\n# Define the input function for evaluating\ninput_fn = tf.estimator.inputs.numpy_input_fn(\n    x={\'images\': mnist.test.images}, y=mnist.test.labels,\n    batch_size=batch_size, shuffle=False)\n# Use the Estimator \'evaluate\' method\ne = gbdt_model.evaluate(input_fn=input_fn)\n\nprint(""Testing Accuracy:"", e[\'accuracy\'])\n'"
examples/2_BasicModels/kmeans.py,9,"b'"""""" K-Means.\n\nImplement K-Means algorithm with TensorFlow, and apply it to classify\nhandwritten digit images. This example is using the MNIST database of\nhandwritten digits as training samples (http://yann.lecun.com/exdb/mnist/).\n\nNote: This example requires TensorFlow v1.1.0 or over.\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n""""""\n\nfrom __future__ import print_function\n\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.contrib.factorization import KMeans\n\n# Ignore all GPUs, tf k-means does not benefit from it.\nimport os\nos.environ[""CUDA_VISIBLE_DEVICES""] = """"\n\n# Import MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""/tmp/data/"", one_hot=True)\nfull_data_x = mnist.train.images\n\n# Parameters\nnum_steps = 50 # Total steps to train\nbatch_size = 1024 # The number of samples per batch\nk = 25 # The number of clusters\nnum_classes = 10 # The 10 digits\nnum_features = 784 # Each image is 28x28 pixels\n\n# Input images\nX = tf.placeholder(tf.float32, shape=[None, num_features])\n# Labels (for assigning a label to a centroid and testing)\nY = tf.placeholder(tf.float32, shape=[None, num_classes])\n\n# K-Means Parameters\nkmeans = KMeans(inputs=X, num_clusters=k, distance_metric=\'cosine\',\n                use_mini_batch=True)\n\n# Build KMeans graph\ntraining_graph = kmeans.training_graph()\n\nif len(training_graph) > 6: # Tensorflow 1.4+\n    (all_scores, cluster_idx, scores, cluster_centers_initialized,\n     cluster_centers_var, init_op, train_op) = training_graph\nelse:\n    (all_scores, cluster_idx, scores, cluster_centers_initialized,\n     init_op, train_op) = training_graph\n\ncluster_idx = cluster_idx[0] # fix for cluster_idx being a tuple\navg_distance = tf.reduce_mean(scores)\n\n# Initialize the variables (i.e. assign their default value)\ninit_vars = tf.global_variables_initializer()\n\n# Start TensorFlow session\nsess = tf.Session()\n\n# Run the initializer\nsess.run(init_vars, feed_dict={X: full_data_x})\nsess.run(init_op, feed_dict={X: full_data_x})\n\n# Training\nfor i in range(1, num_steps + 1):\n    _, d, idx = sess.run([train_op, avg_distance, cluster_idx],\n                         feed_dict={X: full_data_x})\n    if i % 10 == 0 or i == 1:\n        print(""Step %i, Avg Distance: %f"" % (i, d))\n\n# Assign a label to each centroid\n# Count total number of labels per centroid, using the label of each training\n# sample to their closest centroid (given by \'idx\')\ncounts = np.zeros(shape=(k, num_classes))\nfor i in range(len(idx)):\n    counts[idx[i]] += mnist.train.labels[i]\n# Assign the most frequent label to the centroid\nlabels_map = [np.argmax(c) for c in counts]\nlabels_map = tf.convert_to_tensor(labels_map)\n\n# Evaluation ops\n# Lookup: centroid_id -> label\ncluster_label = tf.nn.embedding_lookup(labels_map, cluster_idx)\n# Compute accuracy\ncorrect_prediction = tf.equal(cluster_label, tf.cast(tf.argmax(Y, 1), tf.int32))\naccuracy_op = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\n# Test Model\ntest_x, test_y = mnist.test.images, mnist.test.labels\nprint(""Test Accuracy:"", sess.run(accuracy_op, feed_dict={X: test_x, Y: test_y}))\n'"
examples/2_BasicModels/linear_regression.py,10,"b'\'\'\'\nA linear regression learning algorithm example using TensorFlow library.\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n\'\'\'\n\nfrom __future__ import print_function\n\nimport tensorflow as tf\nimport numpy\nimport matplotlib.pyplot as plt\nrng = numpy.random\n\n# Parameters\nlearning_rate = 0.01\ntraining_epochs = 1000\ndisplay_step = 50\n\n# Training Data\ntrain_X = numpy.asarray([3.3,4.4,5.5,6.71,6.93,4.168,9.779,6.182,7.59,2.167,\n                         7.042,10.791,5.313,7.997,5.654,9.27,3.1])\ntrain_Y = numpy.asarray([1.7,2.76,2.09,3.19,1.694,1.573,3.366,2.596,2.53,1.221,\n                         2.827,3.465,1.65,2.904,2.42,2.94,1.3])\nn_samples = train_X.shape[0]\n\n# tf Graph Input\nX = tf.placeholder(""float"")\nY = tf.placeholder(""float"")\n\n# Set model weights\nW = tf.Variable(rng.randn(), name=""weight"")\nb = tf.Variable(rng.randn(), name=""bias"")\n\n# Construct a linear model\npred = tf.add(tf.multiply(X, W), b)\n\n# Mean squared error\ncost = tf.reduce_sum(tf.pow(pred-Y, 2))/(2*n_samples)\n# Gradient descent\n#  Note, minimize() knows to modify W and b because Variable objects are trainable=True by default\noptimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n\n# Initialize the variables (i.e. assign their default value)\ninit = tf.global_variables_initializer()\n\n# Start training\nwith tf.Session() as sess:\n\n    # Run the initializer\n    sess.run(init)\n\n    # Fit all training data\n    for epoch in range(training_epochs):\n        for (x, y) in zip(train_X, train_Y):\n            sess.run(optimizer, feed_dict={X: x, Y: y})\n\n        # Display logs per epoch step\n        if (epoch+1) % display_step == 0:\n            c = sess.run(cost, feed_dict={X: train_X, Y:train_Y})\n            print(""Epoch:"", \'%04d\' % (epoch+1), ""cost="", ""{:.9f}"".format(c), \\\n                ""W="", sess.run(W), ""b="", sess.run(b))\n\n    print(""Optimization Finished!"")\n    training_cost = sess.run(cost, feed_dict={X: train_X, Y: train_Y})\n    print(""Training cost="", training_cost, ""W="", sess.run(W), ""b="", sess.run(b), \'\\n\')\n\n    # Graphic display\n    plt.plot(train_X, train_Y, \'ro\', label=\'Original data\')\n    plt.plot(train_X, sess.run(W) * train_X + sess.run(b), label=\'Fitted line\')\n    plt.legend()\n    plt.show()\n\n    # Testing example, as requested (Issue #2)\n    test_X = numpy.asarray([6.83, 4.668, 8.9, 7.91, 5.7, 8.7, 3.1, 2.1])\n    test_Y = numpy.asarray([1.84, 2.273, 3.2, 2.831, 2.92, 3.24, 1.35, 1.03])\n\n    print(""Testing... (Mean square loss Comparison)"")\n    testing_cost = sess.run(\n        tf.reduce_sum(tf.pow(pred - Y, 2)) / (2 * test_X.shape[0]),\n        feed_dict={X: test_X, Y: test_Y})  # same function as cost above\n    print(""Testing cost="", testing_cost)\n    print(""Absolute mean square loss difference:"", abs(\n        training_cost - testing_cost))\n\n    plt.plot(test_X, test_Y, \'bo\', label=\'Testing data\')\n    plt.plot(train_X, sess.run(W) * train_X + sess.run(b), label=\'Fitted line\')\n    plt.legend()\n    plt.show()\n'"
examples/2_BasicModels/linear_regression_eager_api.py,4,"b'\'\'\' Linear Regression with Eager API.\n\nA linear regression learning algorithm example using TensorFlow\'s Eager API.\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n\'\'\'\nfrom __future__ import absolute_import, division, print_function\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\n\n# Set Eager API\ntf.enable_eager_execution()\ntfe = tf.contrib.eager\n\n# Training Data\ntrain_X = [3.3, 4.4, 5.5, 6.71, 6.93, 4.168, 9.779, 6.182, 7.59, 2.167,\n           7.042, 10.791, 5.313, 7.997, 5.654, 9.27, 3.1]\ntrain_Y = [1.7, 2.76, 2.09, 3.19, 1.694, 1.573, 3.366, 2.596, 2.53, 1.221,\n           2.827, 3.465, 1.65, 2.904, 2.42, 2.94, 1.3]\nn_samples = len(train_X)\n\n# Parameters\nlearning_rate = 0.01\ndisplay_step = 100\nnum_steps = 1000\n\n# Weight and Bias\nW = tfe.Variable(np.random.randn())\nb = tfe.Variable(np.random.randn())\n\n\n# Linear regression (Wx + b)\ndef linear_regression(inputs):\n    return inputs * W + b\n\n\n# Mean square error\ndef mean_square_fn(model_fn, inputs, labels):\n    return tf.reduce_sum(tf.pow(model_fn(inputs) - labels, 2)) / (2 * n_samples)\n\n\n# SGD Optimizer\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n# Compute gradients\ngrad = tfe.implicit_gradients(mean_square_fn)\n\n# Initial cost, before optimizing\nprint(""Initial cost= {:.9f}"".format(\n    mean_square_fn(linear_regression, train_X, train_Y)),\n    ""W="", W.numpy(), ""b="", b.numpy())\n\n# Training\nfor step in range(num_steps):\n\n    optimizer.apply_gradients(grad(linear_regression, train_X, train_Y))\n\n    if (step + 1) % display_step == 0 or step == 0:\n        print(""Epoch:"", \'%04d\' % (step + 1), ""cost="",\n              ""{:.9f}"".format(mean_square_fn(linear_regression, train_X, train_Y)),\n              ""W="", W.numpy(), ""b="", b.numpy())\n\n# Graphic display\nplt.plot(train_X, train_Y, \'ro\', label=\'Original data\')\nplt.plot(train_X, np.array(W * train_X + b), label=\'Fitted line\')\nplt.legend()\nplt.show()\n'"
examples/2_BasicModels/logistic_regression.py,11,"b'\'\'\'\nA logistic regression learning algorithm example using TensorFlow library.\nThis example is using the MNIST database of handwritten digits\n(http://yann.lecun.com/exdb/mnist/)\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n\'\'\'\n\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\n# Import MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""/tmp/data/"", one_hot=True)\n\n# Parameters\nlearning_rate = 0.01\ntraining_epochs = 25\nbatch_size = 100\ndisplay_step = 1\n\n# tf Graph Input\nx = tf.placeholder(tf.float32, [None, 784]) # mnist data image of shape 28*28=784\ny = tf.placeholder(tf.float32, [None, 10]) # 0-9 digits recognition => 10 classes\n\n# Set model weights\nW = tf.Variable(tf.zeros([784, 10]))\nb = tf.Variable(tf.zeros([10]))\n\n# Construct model\npred = tf.nn.softmax(tf.matmul(x, W) + b) # Softmax\n\n# Minimize error using cross entropy\ncost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred), reduction_indices=1))\n# Gradient Descent\noptimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n\n# Initialize the variables (i.e. assign their default value)\ninit = tf.global_variables_initializer()\n\n# Start training\nwith tf.Session() as sess:\n\n    # Run the initializer\n    sess.run(init)\n\n    # Training cycle\n    for epoch in range(training_epochs):\n        avg_cost = 0.\n        total_batch = int(mnist.train.num_examples/batch_size)\n        # Loop over all batches\n        for i in range(total_batch):\n            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n            # Run optimization op (backprop) and cost op (to get loss value)\n            _, c = sess.run([optimizer, cost], feed_dict={x: batch_xs,\n                                                          y: batch_ys})\n            # Compute average loss\n            avg_cost += c / total_batch\n        # Display logs per epoch step\n        if (epoch+1) % display_step == 0:\n            print(""Epoch:"", \'%04d\' % (epoch+1), ""cost="", ""{:.9f}"".format(avg_cost))\n\n    print(""Optimization Finished!"")\n\n    # Test model\n    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n    # Calculate accuracy\n    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n    print(""Accuracy:"", accuracy.eval({x: mnist.test.images, y: mnist.test.labels}))\n'"
examples/2_BasicModels/logistic_regression_eager_api.py,12,"b'\'\'\' Logistic Regression with Eager API.\n\nA logistic regression learning algorithm example using TensorFlow\'s Eager API.\nThis example is using the MNIST database of handwritten digits\n(http://yann.lecun.com/exdb/mnist/)\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n\'\'\'\nfrom __future__ import absolute_import, division, print_function\n\nimport tensorflow as tf\n\n# Set Eager API\ntf.enable_eager_execution()\ntfe = tf.contrib.eager\n\n# Import MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""/tmp/data/"", one_hot=False)\n\n# Parameters\nlearning_rate = 0.1\nbatch_size = 128\nnum_steps = 1000\ndisplay_step = 100\n\ndataset = tf.data.Dataset.from_tensor_slices(\n    (mnist.train.images, mnist.train.labels))\ndataset = dataset.repeat().batch(batch_size).prefetch(batch_size)\ndataset_iter = tfe.Iterator(dataset)\n\n# Variables\nW = tfe.Variable(tf.zeros([784, 10]), name=\'weights\')\nb = tfe.Variable(tf.zeros([10]), name=\'bias\')\n\n\n# Logistic regression (Wx + b)\ndef logistic_regression(inputs):\n    return tf.matmul(inputs, W) + b\n\n\n# Cross-Entropy loss function\ndef loss_fn(inference_fn, inputs, labels):\n    # Using sparse_softmax cross entropy\n    return tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n        logits=inference_fn(inputs), labels=labels))\n\n\n# Calculate accuracy\ndef accuracy_fn(inference_fn, inputs, labels):\n    prediction = tf.nn.softmax(inference_fn(inputs))\n    correct_pred = tf.equal(tf.argmax(prediction, 1), labels)\n    return tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\n\n# SGD Optimizer\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n# Compute gradients\ngrad = tfe.implicit_gradients(loss_fn)\n\n# Training\naverage_loss = 0.\naverage_acc = 0.\nfor step in range(num_steps):\n\n    # Iterate through the dataset\n    d = dataset_iter.next()\n\n    # Images\n    x_batch = d[0]\n    # Labels\n    y_batch = tf.cast(d[1], dtype=tf.int64)\n\n    # Compute the batch loss\n    batch_loss = loss_fn(logistic_regression, x_batch, y_batch)\n    average_loss += batch_loss\n    # Compute the batch accuracy\n    batch_accuracy = accuracy_fn(logistic_regression, x_batch, y_batch)\n    average_acc += batch_accuracy\n\n    if step == 0:\n        # Display the initial cost, before optimizing\n        print(""Initial loss= {:.9f}"".format(average_loss))\n\n    # Update the variables following gradients info\n    optimizer.apply_gradients(grad(logistic_regression, x_batch, y_batch))\n\n    # Display info\n    if (step + 1) % display_step == 0 or step == 0:\n        if step > 0:\n            average_loss /= display_step\n            average_acc /= display_step\n        print(""Step:"", \'%04d\' % (step + 1), "" loss="",\n              ""{:.9f}"".format(average_loss), "" accuracy="",\n              ""{:.4f}"".format(average_acc))\n        average_loss = 0.\n        average_acc = 0.\n\n# Evaluate model on the test image set\ntestX = mnist.test.images\ntestY = mnist.test.labels\n\ntest_acc = accuracy_fn(logistic_regression, testX, testY)\nprint(""Testset Accuracy: {:.4f}"".format(test_acc))\n'"
examples/2_BasicModels/nearest_neighbor.py,6,"b'\'\'\'\nA nearest neighbor learning algorithm example using TensorFlow library.\nThis example is using the MNIST database of handwritten digits\n(http://yann.lecun.com/exdb/mnist/)\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n\'\'\'\n\nfrom __future__ import print_function\n\nimport numpy as np\nimport tensorflow as tf\n\n# Import MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""/tmp/data/"", one_hot=True)\n\n# In this example, we limit mnist data\nXtr, Ytr = mnist.train.next_batch(5000) #5000 for training (nn candidates)\nXte, Yte = mnist.test.next_batch(200) #200 for testing\n\n# tf Graph Input\nxtr = tf.placeholder(""float"", [None, 784])\nxte = tf.placeholder(""float"", [784])\n\n# Nearest Neighbor calculation using L1 Distance\n# Calculate L1 Distance\ndistance = tf.reduce_sum(tf.abs(tf.add(xtr, tf.negative(xte))), reduction_indices=1)\n# Prediction: Get min distance index (Nearest neighbor)\npred = tf.arg_min(distance, 0)\n\naccuracy = 0.\n\n# Initialize the variables (i.e. assign their default value)\ninit = tf.global_variables_initializer()\n\n# Start training\nwith tf.Session() as sess:\n\n    # Run the initializer\n    sess.run(init)\n\n    # loop over test data\n    for i in range(len(Xte)):\n        # Get nearest neighbor\n        nn_index = sess.run(pred, feed_dict={xtr: Xtr, xte: Xte[i, :]})\n        # Get nearest neighbor class label and compare it to its true label\n        print(""Test"", i, ""Prediction:"", np.argmax(Ytr[nn_index]), \\\n            ""True Class:"", np.argmax(Yte[i]))\n        # Calculate accuracy\n        if np.argmax(Ytr[nn_index]) == np.argmax(Yte[i]):\n            accuracy += 1./len(Xte)\n    print(""Done!"")\n    print(""Accuracy:"", accuracy)\n'"
examples/2_BasicModels/random_forest.py,6,"b'"""""" Random Forest.\n\nImplement Random Forest algorithm with TensorFlow, and apply it to classify \nhandwritten digit images. This example is using the MNIST database of \nhandwritten digits as training samples (http://yann.lecun.com/exdb/mnist/).\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n""""""\n\nfrom __future__ import print_function\n\nimport tensorflow as tf\nfrom tensorflow.contrib.tensor_forest.python import tensor_forest\nfrom tensorflow.python.ops import resources\n\n# Ignore all GPUs, tf random forest does not benefit from it.\nimport os\nos.environ[""CUDA_VISIBLE_DEVICES""] = """"\n\n# Import MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""/tmp/data/"", one_hot=False)\n\n# Parameters\nnum_steps = 500 # Total steps to train\nbatch_size = 1024 # The number of samples per batch\nnum_classes = 10 # The 10 digits\nnum_features = 784 # Each image is 28x28 pixels\nnum_trees = 10\nmax_nodes = 1000\n\n# Input and Target data\nX = tf.placeholder(tf.float32, shape=[None, num_features])\n# For random forest, labels must be integers (the class id)\nY = tf.placeholder(tf.int32, shape=[None])\n\n# Random Forest Parameters\nhparams = tensor_forest.ForestHParams(num_classes=num_classes,\n                                      num_features=num_features,\n                                      num_trees=num_trees,\n                                      max_nodes=max_nodes).fill()\n\n# Build the Random Forest\nforest_graph = tensor_forest.RandomForestGraphs(hparams)\n# Get training graph and loss\ntrain_op = forest_graph.training_graph(X, Y)\nloss_op = forest_graph.training_loss(X, Y)\n\n# Measure the accuracy\ninfer_op, _, _ = forest_graph.inference_graph(X)\ncorrect_prediction = tf.equal(tf.argmax(infer_op, 1), tf.cast(Y, tf.int64))\naccuracy_op = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\n# Initialize the variables (i.e. assign their default value) and forest resources\ninit_vars = tf.group(tf.global_variables_initializer(),\n    resources.initialize_resources(resources.shared_resources()))\n\n# Start TensorFlow session\nsess = tf.Session()\n\n# Run the initializer\nsess.run(init_vars)\n\n# Training\nfor i in range(1, num_steps + 1):\n    # Prepare Data\n    # Get the next batch of MNIST data (only images are needed, not labels)\n    batch_x, batch_y = mnist.train.next_batch(batch_size)\n    _, l = sess.run([train_op, loss_op], feed_dict={X: batch_x, Y: batch_y})\n    if i % 50 == 0 or i == 1:\n        acc = sess.run(accuracy_op, feed_dict={X: batch_x, Y: batch_y})\n        print(\'Step %i, Loss: %f, Acc: %f\' % (i, l, acc))\n\n# Test Model\ntest_x, test_y = mnist.test.images, mnist.test.labels\nprint(""Test Accuracy:"", sess.run(accuracy_op, feed_dict={X: test_x, Y: test_y}))\n'"
examples/2_BasicModels/word2vec.py,15,"b'"""""" Word2Vec.\n\nImplement Word2Vec algorithm to compute vector representations of words.\nThis example is using a small chunk of Wikipedia articles to train from.\n\nReferences:\n    - Mikolov, Tomas et al. ""Efficient Estimation of Word Representations\n    in Vector Space."", 2013.\n\nLinks:\n    - [Word2Vec] https://arxiv.org/pdf/1301.3781.pdf\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n""""""\nfrom __future__ import division, print_function, absolute_import\n\nimport collections\nimport os\nimport random\nimport urllib\nimport zipfile\n\nimport numpy as np\nimport tensorflow as tf\n\n# Training Parameters\nlearning_rate = 0.1\nbatch_size = 128\nnum_steps = 3000000\ndisplay_step = 10000\neval_step = 200000\n\n# Evaluation Parameters\neval_words = [\'five\', \'of\', \'going\', \'hardware\', \'american\', \'britain\']\n\n# Word2Vec Parameters\nembedding_size = 200 # Dimension of the embedding vector\nmax_vocabulary_size = 50000 # Total number of different words in the vocabulary\nmin_occurrence = 10 # Remove all words that does not appears at least n times\nskip_window = 3 # How many words to consider left and right\nnum_skips = 2 # How many times to reuse an input to generate a label\nnum_sampled = 64 # Number of negative examples to sample\n\n\n# Download a small chunk of Wikipedia articles collection\nurl = \'http://mattmahoney.net/dc/text8.zip\'\ndata_path = \'text8.zip\'\nif not os.path.exists(data_path):\n    print(""Downloading the dataset... (It may take some time)"")\n    filename, _ = urllib.urlretrieve(url, data_path)\n    print(""Done!"")\n# Unzip the dataset file. Text has already been processed\nwith zipfile.ZipFile(data_path) as f:\n    text_words = f.read(f.namelist()[0]).lower().split()\n\n# Build the dictionary and replace rare words with UNK token\ncount = [(\'UNK\', -1)]\n# Retrieve the most common words\ncount.extend(collections.Counter(text_words).most_common(max_vocabulary_size - 1))\n# Remove samples with less than \'min_occurrence\' occurrences\nfor i in range(len(count) - 1, -1, -1):\n    if count[i][1] < min_occurrence:\n        count.pop(i)\n    else:\n        # The collection is ordered, so stop when \'min_occurrence\' is reached\n        break\n# Compute the vocabulary size\nvocabulary_size = len(count)\n# Assign an id to each word\nword2id = dict()\nfor i, (word, _)in enumerate(count):\n    word2id[word] = i\n\ndata = list()\nunk_count = 0\nfor word in text_words:\n    # Retrieve a word id, or assign it index 0 (\'UNK\') if not in dictionary\n    index = word2id.get(word, 0)\n    if index == 0:\n        unk_count += 1\n    data.append(index)\ncount[0] = (\'UNK\', unk_count)\nid2word = dict(zip(word2id.values(), word2id.keys()))\n\nprint(""Words count:"", len(text_words))\nprint(""Unique words:"", len(set(text_words)))\nprint(""Vocabulary size:"", vocabulary_size)\nprint(""Most common words:"", count[:10])\n\ndata_index = 0\n# Generate training batch for the skip-gram model\ndef next_batch(batch_size, num_skips, skip_window):\n    global data_index\n    assert batch_size % num_skips == 0\n    assert num_skips <= 2 * skip_window\n    batch = np.ndarray(shape=(batch_size), dtype=np.int32)\n    labels = np.ndarray(shape=(batch_size, 1), dtype=np.int32)\n    # get window size (words left and right + current one)\n    span = 2 * skip_window + 1\n    buffer = collections.deque(maxlen=span)\n    if data_index + span > len(data):\n        data_index = 0\n    buffer.extend(data[data_index:data_index + span])\n    data_index += span\n    for i in range(batch_size // num_skips):\n        context_words = [w for w in range(span) if w != skip_window]\n        words_to_use = random.sample(context_words, num_skips)\n        for j, context_word in enumerate(words_to_use):\n            batch[i * num_skips + j] = buffer[skip_window]\n            labels[i * num_skips + j, 0] = buffer[context_word]\n        if data_index == len(data):\n            buffer.extend(data[0:span])\n            data_index = span\n        else:\n            buffer.append(data[data_index])\n            data_index += 1\n    # Backtrack a little bit to avoid skipping words in the end of a batch\n    data_index = (data_index + len(data) - span) % len(data)\n    return batch, labels\n\n\n# Input data\nX = tf.placeholder(tf.int32, shape=[None])\n# Input label\nY = tf.placeholder(tf.int32, shape=[None, 1])\n\n# Ensure the following ops & var are assigned on CPU\n# (some ops are not compatible on GPU)\nwith tf.device(\'/cpu:0\'):\n    # Create the embedding variable (each row represent a word embedding vector)\n    embedding = tf.Variable(tf.random_normal([vocabulary_size, embedding_size]))\n    # Lookup the corresponding embedding vectors for each sample in X\n    X_embed = tf.nn.embedding_lookup(embedding, X)\n\n    # Construct the variables for the NCE loss\n    nce_weights = tf.Variable(tf.random_normal([vocabulary_size, embedding_size]))\n    nce_biases = tf.Variable(tf.zeros([vocabulary_size]))\n\n# Compute the average NCE loss for the batch\nloss_op = tf.reduce_mean(\n    tf.nn.nce_loss(weights=nce_weights,\n                   biases=nce_biases,\n                   labels=Y,\n                   inputs=X_embed,\n                   num_sampled=num_sampled,\n                   num_classes=vocabulary_size))\n\n# Define the optimizer\noptimizer = tf.train.GradientDescentOptimizer(learning_rate)\ntrain_op = optimizer.minimize(loss_op)\n\n# Evaluation\n# Compute the cosine similarity between input data embedding and every embedding vectors\nX_embed_norm = X_embed / tf.sqrt(tf.reduce_sum(tf.square(X_embed)))\nembedding_norm = embedding / tf.sqrt(tf.reduce_sum(tf.square(embedding), 1, keepdims=True))\ncosine_sim_op = tf.matmul(X_embed_norm, embedding_norm, transpose_b=True)\n\n# Initialize the variables (i.e. assign their default value)\ninit = tf.global_variables_initializer()\n\nwith tf.Session() as sess:\n\n    # Run the initializer\n    sess.run(init)\n\n    # Testing data\n    x_test = np.array([word2id[w] for w in eval_words])\n\n    average_loss = 0\n    for step in xrange(1, num_steps + 1):\n        # Get a new batch of data\n        batch_x, batch_y = next_batch(batch_size, num_skips, skip_window)\n        # Run training op\n        _, loss = sess.run([train_op, loss_op], feed_dict={X: batch_x, Y: batch_y})\n        average_loss += loss\n\n        if step % display_step == 0 or step == 1:\n            if step > 1:\n                average_loss /= display_step\n            print(""Step "" + str(step) + "", Average Loss= "" + \\\n                  ""{:.4f}"".format(average_loss))\n            average_loss = 0\n\n        # Evaluation\n        if step % eval_step == 0 or step == 1:\n            print(""Evaluation..."")\n            sim = sess.run(cosine_sim_op, feed_dict={X: x_test})\n            for i in xrange(len(eval_words)):\n                top_k = 8  # number of nearest neighbors\n                nearest = (-sim[i, :]).argsort()[1:top_k + 1]\n                log_str = \'""%s"" nearest neighbors:\' % eval_words[i]\n                for k in xrange(top_k):\n                    log_str = \'%s %s,\' % (log_str, id2word[nearest[k]])\n                print(log_str)\n'"
examples/3_NeuralNetworks/autoencoder.py,17,"b'"""""" Auto Encoder Example.\n\nBuild a 2 layers auto-encoder with TensorFlow to compress images to a\nlower latent space and then reconstruct them.\n\nReferences:\n    Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. ""Gradient-based\n    learning applied to document recognition."" Proceedings of the IEEE,\n    86(11):2278-2324, November 1998.\n\nLinks:\n    [MNIST Dataset] http://yann.lecun.com/exdb/mnist/\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n""""""\nfrom __future__ import division, print_function, absolute_import\n\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Import MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""/tmp/data/"", one_hot=True)\n\n# Training Parameters\nlearning_rate = 0.01\nnum_steps = 30000\nbatch_size = 256\n\ndisplay_step = 1000\nexamples_to_show = 10\n\n# Network Parameters\nnum_hidden_1 = 256 # 1st layer num features\nnum_hidden_2 = 128 # 2nd layer num features (the latent dim)\nnum_input = 784 # MNIST data input (img shape: 28*28)\n\n# tf Graph input (only pictures)\nX = tf.placeholder(""float"", [None, num_input])\n\nweights = {\n    \'encoder_h1\': tf.Variable(tf.random_normal([num_input, num_hidden_1])),\n    \'encoder_h2\': tf.Variable(tf.random_normal([num_hidden_1, num_hidden_2])),\n    \'decoder_h1\': tf.Variable(tf.random_normal([num_hidden_2, num_hidden_1])),\n    \'decoder_h2\': tf.Variable(tf.random_normal([num_hidden_1, num_input])),\n}\nbiases = {\n    \'encoder_b1\': tf.Variable(tf.random_normal([num_hidden_1])),\n    \'encoder_b2\': tf.Variable(tf.random_normal([num_hidden_2])),\n    \'decoder_b1\': tf.Variable(tf.random_normal([num_hidden_1])),\n    \'decoder_b2\': tf.Variable(tf.random_normal([num_input])),\n}\n\n# Building the encoder\ndef encoder(x):\n    # Encoder Hidden layer with sigmoid activation #1\n    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights[\'encoder_h1\']),\n                                   biases[\'encoder_b1\']))\n    # Encoder Hidden layer with sigmoid activation #2\n    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights[\'encoder_h2\']),\n                                   biases[\'encoder_b2\']))\n    return layer_2\n\n\n# Building the decoder\ndef decoder(x):\n    # Decoder Hidden layer with sigmoid activation #1\n    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights[\'decoder_h1\']),\n                                   biases[\'decoder_b1\']))\n    # Decoder Hidden layer with sigmoid activation #2\n    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights[\'decoder_h2\']),\n                                   biases[\'decoder_b2\']))\n    return layer_2\n\n# Construct model\nencoder_op = encoder(X)\ndecoder_op = decoder(encoder_op)\n\n# Prediction\ny_pred = decoder_op\n# Targets (Labels) are the input data.\ny_true = X\n\n# Define loss and optimizer, minimize the squared error\nloss = tf.reduce_mean(tf.pow(y_true - y_pred, 2))\noptimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(loss)\n\n# Initialize the variables (i.e. assign their default value)\ninit = tf.global_variables_initializer()\n\n# Start Training\n# Start a new TF session\nwith tf.Session() as sess:\n\n    # Run the initializer\n    sess.run(init)\n\n    # Training\n    for i in range(1, num_steps+1):\n        # Prepare Data\n        # Get the next batch of MNIST data (only images are needed, not labels)\n        batch_x, _ = mnist.train.next_batch(batch_size)\n\n        # Run optimization op (backprop) and cost op (to get loss value)\n        _, l = sess.run([optimizer, loss], feed_dict={X: batch_x})\n        # Display logs per step\n        if i % display_step == 0 or i == 1:\n            print(\'Step %i: Minibatch Loss: %f\' % (i, l))\n\n    # Testing\n    # Encode and decode images from test set and visualize their reconstruction.\n    n = 4\n    canvas_orig = np.empty((28 * n, 28 * n))\n    canvas_recon = np.empty((28 * n, 28 * n))\n    for i in range(n):\n        # MNIST test set\n        batch_x, _ = mnist.test.next_batch(n)\n        # Encode and decode the digit image\n        g = sess.run(decoder_op, feed_dict={X: batch_x})\n\n        # Display original images\n        for j in range(n):\n            # Draw the original digits\n            canvas_orig[i * 28:(i + 1) * 28, j * 28:(j + 1) * 28] = \\\n                batch_x[j].reshape([28, 28])\n        # Display reconstructed images\n        for j in range(n):\n            # Draw the reconstructed digits\n            canvas_recon[i * 28:(i + 1) * 28, j * 28:(j + 1) * 28] = \\\n                g[j].reshape([28, 28])\n\n    print(""Original Images"")\n    plt.figure(figsize=(n, n))\n    plt.imshow(canvas_orig, origin=""upper"", cmap=""gray"")\n    plt.show()\n\n    print(""Reconstructed Images"")\n    plt.figure(figsize=(n, n))\n    plt.imshow(canvas_recon, origin=""upper"", cmap=""gray"")\n    plt.show()\n'"
examples/3_NeuralNetworks/bidirectional_rnn.py,15,"b'"""""" Bi-directional Recurrent Neural Network.\n\nA Bi-directional Recurrent Neural Network (LSTM) implementation example using \nTensorFlow library. This example is using the MNIST database of handwritten \ndigits (http://yann.lecun.com/exdb/mnist/)\n\nLinks:\n    [Long Short Term Memory](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf)\n    [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n""""""\n\nfrom __future__ import print_function\n\nimport tensorflow as tf\nfrom tensorflow.contrib import rnn\nimport numpy as np\n\n# Import MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""/tmp/data/"", one_hot=True)\n\n\'\'\'\nTo classify images using a bidirectional recurrent neural network, we consider\nevery image row as a sequence of pixels. Because MNIST image shape is 28*28px,\nwe will then handle 28 sequences of 28 steps for every sample.\n\'\'\'\n\n# Training Parameters\nlearning_rate = 0.001\ntraining_steps = 10000\nbatch_size = 128\ndisplay_step = 200\n\n# Network Parameters\nnum_input = 28 # MNIST data input (img shape: 28*28)\ntimesteps = 28 # timesteps\nnum_hidden = 128 # hidden layer num of features\nnum_classes = 10 # MNIST total classes (0-9 digits)\n\n# tf Graph input\nX = tf.placeholder(""float"", [None, timesteps, num_input])\nY = tf.placeholder(""float"", [None, num_classes])\n\n# Define weights\nweights = {\n    # Hidden layer weights => 2*n_hidden because of forward + backward cells\n    \'out\': tf.Variable(tf.random_normal([2*num_hidden, num_classes]))\n}\nbiases = {\n    \'out\': tf.Variable(tf.random_normal([num_classes]))\n}\n\n\ndef BiRNN(x, weights, biases):\n\n    # Prepare data shape to match `rnn` function requirements\n    # Current data input shape: (batch_size, timesteps, n_input)\n    # Required shape: \'timesteps\' tensors list of shape (batch_size, num_input)\n\n    # Unstack to get a list of \'timesteps\' tensors of shape (batch_size, num_input)\n    x = tf.unstack(x, timesteps, 1)\n\n    # Define lstm cells with tensorflow\n    # Forward direction cell\n    lstm_fw_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n    # Backward direction cell\n    lstm_bw_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n\n    # Get lstm cell output\n    try:\n        outputs, _, _ = rnn.static_bidirectional_rnn(lstm_fw_cell, lstm_bw_cell, x,\n                                              dtype=tf.float32)\n    except Exception: # Old TensorFlow version only returns outputs not states\n        outputs = rnn.static_bidirectional_rnn(lstm_fw_cell, lstm_bw_cell, x,\n                                        dtype=tf.float32)\n\n    # Linear activation, using rnn inner loop last output\n    return tf.matmul(outputs[-1], weights[\'out\']) + biases[\'out\']\n\nlogits = BiRNN(X, weights, biases)\nprediction = tf.nn.softmax(logits)\n\n# Define loss and optimizer\nloss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n    logits=logits, labels=Y))\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\ntrain_op = optimizer.minimize(loss_op)\n\n# Evaluate model (with test logits, for dropout to be disabled)\ncorrect_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\n# Initialize the variables (i.e. assign their default value)\ninit = tf.global_variables_initializer()\n\n# Start training\nwith tf.Session() as sess:\n\n    # Run the initializer\n    sess.run(init)\n\n    for step in range(1, training_steps+1):\n        batch_x, batch_y = mnist.train.next_batch(batch_size)\n        # Reshape data to get 28 seq of 28 elements\n        batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n        # Run optimization op (backprop)\n        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n        if step % display_step == 0 or step == 1:\n            # Calculate batch loss and accuracy\n            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n                                                                 Y: batch_y})\n            print(""Step "" + str(step) + "", Minibatch Loss= "" + \\\n                  ""{:.4f}"".format(loss) + "", Training Accuracy= "" + \\\n                  ""{:.3f}"".format(acc))\n\n    print(""Optimization Finished!"")\n\n    # Calculate accuracy for 128 mnist test images\n    test_len = 128\n    test_data = mnist.test.images[:test_len].reshape((-1, timesteps, num_input))\n    test_label = mnist.test.labels[:test_len]\n    print(""Testing Accuracy:"", \\\n        sess.run(accuracy, feed_dict={X: test_data, Y: test_label}))\n'"
examples/3_NeuralNetworks/convolutional_network.py,23,"b'"""""" Convolutional Neural Network.\n\nBuild and train a convolutional neural network with TensorFlow.\nThis example is using the MNIST database of handwritten digits\n(http://yann.lecun.com/exdb/mnist/)\n\nThis example is using TensorFlow layers API, see \'convolutional_network_raw\' \nexample for a raw implementation with variables.\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n""""""\nfrom __future__ import division, print_function, absolute_import\n\n# Import MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""/tmp/data/"", one_hot=False)\n\nimport tensorflow as tf\n\n# Training Parameters\nlearning_rate = 0.001\nnum_steps = 2000\nbatch_size = 128\n\n# Network Parameters\nnum_input = 784 # MNIST data input (img shape: 28*28)\nnum_classes = 10 # MNIST total classes (0-9 digits)\ndropout = 0.25 # Dropout, probability to drop a unit\n\n\n# Create the neural network\ndef conv_net(x_dict, n_classes, dropout, reuse, is_training):\n    # Define a scope for reusing the variables\n    with tf.variable_scope(\'ConvNet\', reuse=reuse):\n        # TF Estimator input is a dict, in case of multiple inputs\n        x = x_dict[\'images\']\n\n        # MNIST data input is a 1-D vector of 784 features (28*28 pixels)\n        # Reshape to match picture format [Height x Width x Channel]\n        # Tensor input become 4-D: [Batch Size, Height, Width, Channel]\n        x = tf.reshape(x, shape=[-1, 28, 28, 1])\n\n        # Convolution Layer with 32 filters and a kernel size of 5\n        conv1 = tf.layers.conv2d(x, 32, 5, activation=tf.nn.relu)\n        # Max Pooling (down-sampling) with strides of 2 and kernel size of 2\n        conv1 = tf.layers.max_pooling2d(conv1, 2, 2)\n\n        # Convolution Layer with 64 filters and a kernel size of 3\n        conv2 = tf.layers.conv2d(conv1, 64, 3, activation=tf.nn.relu)\n        # Max Pooling (down-sampling) with strides of 2 and kernel size of 2\n        conv2 = tf.layers.max_pooling2d(conv2, 2, 2)\n\n        # Flatten the data to a 1-D vector for the fully connected layer\n        fc1 = tf.contrib.layers.flatten(conv2)\n\n        # Fully connected layer (in tf contrib folder for now)\n        fc1 = tf.layers.dense(fc1, 1024)\n        # Apply Dropout (if is_training is False, dropout is not applied)\n        fc1 = tf.layers.dropout(fc1, rate=dropout, training=is_training)\n\n        # Output layer, class prediction\n        out = tf.layers.dense(fc1, n_classes)\n\n    return out\n\n\n# Define the model function (following TF Estimator Template)\ndef model_fn(features, labels, mode):\n    # Build the neural network\n    # Because Dropout have different behavior at training and prediction time, we\n    # need to create 2 distinct computation graphs that still share the same weights.\n    logits_train = conv_net(features, num_classes, dropout, reuse=False,\n                            is_training=True)\n    logits_test = conv_net(features, num_classes, dropout, reuse=True,\n                           is_training=False)\n\n    # Predictions\n    pred_classes = tf.argmax(logits_test, axis=1)\n    pred_probas = tf.nn.softmax(logits_test)\n\n    # If prediction mode, early return\n    if mode == tf.estimator.ModeKeys.PREDICT:\n        return tf.estimator.EstimatorSpec(mode, predictions=pred_classes)\n\n        # Define loss and optimizer\n    loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n        logits=logits_train, labels=tf.cast(labels, dtype=tf.int32)))\n    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n    train_op = optimizer.minimize(loss_op,\n                                  global_step=tf.train.get_global_step())\n\n    # Evaluate the accuracy of the model\n    acc_op = tf.metrics.accuracy(labels=labels, predictions=pred_classes)\n\n    # TF Estimators requires to return a EstimatorSpec, that specify\n    # the different ops for training, evaluating, ...\n    estim_specs = tf.estimator.EstimatorSpec(\n        mode=mode,\n        predictions=pred_classes,\n        loss=loss_op,\n        train_op=train_op,\n        eval_metric_ops={\'accuracy\': acc_op})\n\n    return estim_specs\n\n# Build the Estimator\nmodel = tf.estimator.Estimator(model_fn)\n\n# Define the input function for training\ninput_fn = tf.estimator.inputs.numpy_input_fn(\n    x={\'images\': mnist.train.images}, y=mnist.train.labels,\n    batch_size=batch_size, num_epochs=None, shuffle=True)\n# Train the Model\nmodel.train(input_fn, steps=num_steps)\n\n# Evaluate the Model\n# Define the input function for evaluating\ninput_fn = tf.estimator.inputs.numpy_input_fn(\n    x={\'images\': mnist.test.images}, y=mnist.test.labels,\n    batch_size=batch_size, shuffle=False)\n# Use the Estimator \'evaluate\' method\ne = model.evaluate(input_fn)\n\nprint(""Testing Accuracy:"", e[\'accuracy\'])\n'"
examples/3_NeuralNetworks/convolutional_network_raw.py,28,"b'"""""" Convolutional Neural Network.\n\nBuild and train a convolutional neural network with TensorFlow.\nThis example is using the MNIST database of handwritten digits\n(http://yann.lecun.com/exdb/mnist/)\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n""""""\n\nfrom __future__ import division, print_function, absolute_import\n\nimport tensorflow as tf\n\n# Import MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""/tmp/data/"", one_hot=True)\n\n# Training Parameters\nlearning_rate = 0.001\nnum_steps = 200\nbatch_size = 128\ndisplay_step = 10\n\n# Network Parameters\nnum_input = 784 # MNIST data input (img shape: 28*28)\nnum_classes = 10 # MNIST total classes (0-9 digits)\ndropout = 0.75 # Dropout, probability to keep units\n\n# tf Graph input\nX = tf.placeholder(tf.float32, [None, num_input])\nY = tf.placeholder(tf.float32, [None, num_classes])\nkeep_prob = tf.placeholder(tf.float32) # dropout (keep probability)\n\n\n# Create some wrappers for simplicity\ndef conv2d(x, W, b, strides=1):\n    # Conv2D wrapper, with bias and relu activation\n    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding=\'SAME\')\n    x = tf.nn.bias_add(x, b)\n    return tf.nn.relu(x)\n\n\ndef maxpool2d(x, k=2):\n    # MaxPool2D wrapper\n    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n                          padding=\'SAME\')\n\n\n# Create model\ndef conv_net(x, weights, biases, dropout):\n    # MNIST data input is a 1-D vector of 784 features (28*28 pixels)\n    # Reshape to match picture format [Height x Width x Channel]\n    # Tensor input become 4-D: [Batch Size, Height, Width, Channel]\n    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n\n    # Convolution Layer\n    conv1 = conv2d(x, weights[\'wc1\'], biases[\'bc1\'])\n    # Max Pooling (down-sampling)\n    conv1 = maxpool2d(conv1, k=2)\n\n    # Convolution Layer\n    conv2 = conv2d(conv1, weights[\'wc2\'], biases[\'bc2\'])\n    # Max Pooling (down-sampling)\n    conv2 = maxpool2d(conv2, k=2)\n\n    # Fully connected layer\n    # Reshape conv2 output to fit fully connected layer input\n    fc1 = tf.reshape(conv2, [-1, weights[\'wd1\'].get_shape().as_list()[0]])\n    fc1 = tf.add(tf.matmul(fc1, weights[\'wd1\']), biases[\'bd1\'])\n    fc1 = tf.nn.relu(fc1)\n    # Apply Dropout\n    fc1 = tf.nn.dropout(fc1, dropout)\n\n    # Output, class prediction\n    out = tf.add(tf.matmul(fc1, weights[\'out\']), biases[\'out\'])\n    return out\n\n# Store layers weight & bias\nweights = {\n    # 5x5 conv, 1 input, 32 outputs\n    \'wc1\': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n    # 5x5 conv, 32 inputs, 64 outputs\n    \'wc2\': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n    # fully connected, 7*7*64 inputs, 1024 outputs\n    \'wd1\': tf.Variable(tf.random_normal([7*7*64, 1024])),\n    # 1024 inputs, 10 outputs (class prediction)\n    \'out\': tf.Variable(tf.random_normal([1024, num_classes]))\n}\n\nbiases = {\n    \'bc1\': tf.Variable(tf.random_normal([32])),\n    \'bc2\': tf.Variable(tf.random_normal([64])),\n    \'bd1\': tf.Variable(tf.random_normal([1024])),\n    \'out\': tf.Variable(tf.random_normal([num_classes]))\n}\n\n# Construct model\nlogits = conv_net(X, weights, biases, keep_prob)\nprediction = tf.nn.softmax(logits)\n\n# Define loss and optimizer\nloss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n    logits=logits, labels=Y))\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\ntrain_op = optimizer.minimize(loss_op)\n\n\n# Evaluate model\ncorrect_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\n# Initialize the variables (i.e. assign their default value)\ninit = tf.global_variables_initializer()\n\n# Start training\nwith tf.Session() as sess:\n\n    # Run the initializer\n    sess.run(init)\n\n    for step in range(1, num_steps+1):\n        batch_x, batch_y = mnist.train.next_batch(batch_size)\n        # Run optimization op (backprop)\n        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y, keep_prob: 0.8})\n        if step % display_step == 0 or step == 1:\n            # Calculate batch loss and accuracy\n            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n                                                                 Y: batch_y,\n                                                                 keep_prob: 1.0})\n            print(""Step "" + str(step) + "", Minibatch Loss= "" + \\\n                  ""{:.4f}"".format(loss) + "", Training Accuracy= "" + \\\n                  ""{:.3f}"".format(acc))\n\n    print(""Optimization Finished!"")\n\n    # Calculate accuracy for 256 MNIST test images\n    print(""Testing Accuracy:"", \\\n        sess.run(accuracy, feed_dict={X: mnist.test.images[:256],\n                                      Y: mnist.test.labels[:256],\n                                      keep_prob: 1.0}))\n'"
examples/3_NeuralNetworks/dcgan.py,31,"b'"""""" Deep Convolutional Generative Adversarial Network (DCGAN).\n\nUsing deep convolutional generative adversarial networks (DCGAN) to generate\ndigit images from a noise distribution.\n\nReferences:\n    - Unsupervised representation learning with deep convolutional generative\n    adversarial networks. A Radford, L Metz, S Chintala. arXiv:1511.06434.\n\nLinks:\n    - [DCGAN Paper](https://arxiv.org/abs/1511.06434).\n    - [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n""""""\n\nfrom __future__ import division, print_function, absolute_import\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\n\n# Import MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""/tmp/data/"", one_hot=True)\n\n# Training Params\nnum_steps = 20000\nbatch_size = 32\n\n# Network Params\nimage_dim = 784 # 28*28 pixels * 1 channel\ngen_hidden_dim = 256\ndisc_hidden_dim = 256\nnoise_dim = 200 # Noise data points\n\n\n# Generator Network\n# Input: Noise, Output: Image\ndef generator(x, reuse=False):\n    with tf.variable_scope(\'Generator\', reuse=reuse):\n        # TensorFlow Layers automatically create variables and calculate their\n        # shape, based on the input.\n        x = tf.layers.dense(x, units=6 * 6 * 128)\n        x = tf.nn.tanh(x)\n        # Reshape to a 4-D array of images: (batch, height, width, channels)\n        # New shape: (batch, 6, 6, 128)\n        x = tf.reshape(x, shape=[-1, 6, 6, 128])\n        # Deconvolution, image shape: (batch, 14, 14, 64)\n        x = tf.layers.conv2d_transpose(x, 64, 4, strides=2)\n        # Deconvolution, image shape: (batch, 28, 28, 1)\n        x = tf.layers.conv2d_transpose(x, 1, 2, strides=2)\n        # Apply sigmoid to clip values between 0 and 1\n        x = tf.nn.sigmoid(x)\n        return x\n\n\n# Discriminator Network\n# Input: Image, Output: Prediction Real/Fake Image\ndef discriminator(x, reuse=False):\n    with tf.variable_scope(\'Discriminator\', reuse=reuse):\n        # Typical convolutional neural network to classify images.\n        x = tf.layers.conv2d(x, 64, 5)\n        x = tf.nn.tanh(x)\n        x = tf.layers.average_pooling2d(x, 2, 2)\n        x = tf.layers.conv2d(x, 128, 5)\n        x = tf.nn.tanh(x)\n        x = tf.layers.average_pooling2d(x, 2, 2)\n        x = tf.contrib.layers.flatten(x)\n        x = tf.layers.dense(x, 1024)\n        x = tf.nn.tanh(x)\n        # Output 2 classes: Real and Fake images\n        x = tf.layers.dense(x, 2)\n    return x\n\n# Build Networks\n# Network Inputs\nnoise_input = tf.placeholder(tf.float32, shape=[None, noise_dim])\nreal_image_input = tf.placeholder(tf.float32, shape=[None, 28, 28, 1])\n\n# Build Generator Network\ngen_sample = generator(noise_input)\n\n# Build 2 Discriminator Networks (one from real image input, one from generated samples)\ndisc_real = discriminator(real_image_input)\ndisc_fake = discriminator(gen_sample, reuse=True)\ndisc_concat = tf.concat([disc_real, disc_fake], axis=0)\n\n# Build the stacked generator/discriminator\nstacked_gan = discriminator(gen_sample, reuse=True)\n\n# Build Targets (real or fake images)\ndisc_target = tf.placeholder(tf.int32, shape=[None])\ngen_target = tf.placeholder(tf.int32, shape=[None])\n\n# Build Loss\ndisc_loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n    logits=disc_concat, labels=disc_target))\ngen_loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n    logits=stacked_gan, labels=gen_target))\n\n# Build Optimizers\noptimizer_gen = tf.train.AdamOptimizer(learning_rate=0.001)\noptimizer_disc = tf.train.AdamOptimizer(learning_rate=0.001)\n\n# Training Variables for each optimizer\n# By default in TensorFlow, all variables are updated by each optimizer, so we\n# need to precise for each one of them the specific variables to update.\n# Generator Network Variables\ngen_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\'Generator\')\n# Discriminator Network Variables\ndisc_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\'Discriminator\')\n\n# Create training operations\ntrain_gen = optimizer_gen.minimize(gen_loss, var_list=gen_vars)\ntrain_disc = optimizer_disc.minimize(disc_loss, var_list=disc_vars)\n\n# Initialize the variables (i.e. assign their default value)\ninit = tf.global_variables_initializer()\n\n# Start training\nwith tf.Session() as sess:\n\n    # Run the initializer\n    sess.run(init)\n\n    for i in range(1, num_steps+1):\n\n        # Prepare Input Data\n        # Get the next batch of MNIST data (only images are needed, not labels)\n        batch_x, _ = mnist.train.next_batch(batch_size)\n        batch_x = np.reshape(batch_x, newshape=[-1, 28, 28, 1])\n        # Generate noise to feed to the generator\n        z = np.random.uniform(-1., 1., size=[batch_size, noise_dim])\n\n        # Prepare Targets (Real image: 1, Fake image: 0)\n        # The first half of data fed to the discriminator are real images,\n        # the other half are fake images (coming from the generator).\n        batch_disc_y = np.concatenate(\n            [np.ones([batch_size]), np.zeros([batch_size])], axis=0)\n        # Generator tries to fool the discriminator, thus targets are 1.\n        batch_gen_y = np.ones([batch_size])\n\n        # Training\n        feed_dict = {real_image_input: batch_x, noise_input: z,\n                     disc_target: batch_disc_y, gen_target: batch_gen_y}\n        _, _, gl, dl = sess.run([train_gen, train_disc, gen_loss, disc_loss],\n                                feed_dict=feed_dict)\n        if i % 100 == 0 or i == 1:\n            print(\'Step %i: Generator Loss: %f, Discriminator Loss: %f\' % (i, gl, dl))\n\n    # Generate images from noise, using the generator network.\n    f, a = plt.subplots(4, 10, figsize=(10, 4))\n    for i in range(10):\n        # Noise input.\n        z = np.random.uniform(-1., 1., size=[4, noise_dim])\n        g = sess.run(gen_sample, feed_dict={noise_input: z})\n        for j in range(4):\n            # Generate image from noise. Extend to 3 channels for matplot figure.\n            img = np.reshape(np.repeat(g[j][:, :, np.newaxis], 3, axis=2),\n                             newshape=(28, 28, 3))\n            a[j][i].imshow(img)\n\n    f.show()\n    plt.draw()\n    plt.waitforbuttonpress()\n'"
examples/3_NeuralNetworks/dynamic_rnn.py,20,"b'"""""" Dynamic Recurrent Neural Network.\n\nTensorFlow implementation of a Recurrent Neural Network (LSTM) that performs\ndynamic computation over sequences with variable length. This example is using\na toy dataset to classify linear sequences. The generated sequences have\nvariable length.\n\nLinks:\n    [Long Short Term Memory](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf)\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n""""""\n\nfrom __future__ import print_function\n\nimport tensorflow as tf\nimport random\n\n\n# ====================\n#  TOY DATA GENERATOR\n# ====================\nclass ToySequenceData(object):\n    """""" Generate sequence of data with dynamic length.\n    This class generate samples for training:\n    - Class 0: linear sequences (i.e. [0, 1, 2, 3,...])\n    - Class 1: random sequences (i.e. [1, 3, 10, 7,...])\n\n    NOTICE:\n    We have to pad each sequence to reach \'max_seq_len\' for TensorFlow\n    consistency (we cannot feed a numpy array with inconsistent\n    dimensions). The dynamic calculation will then be perform thanks to\n    \'seqlen\' attribute that records every actual sequence length.\n    """"""\n    def __init__(self, n_samples=1000, max_seq_len=20, min_seq_len=3,\n                 max_value=1000):\n        self.data = []\n        self.labels = []\n        self.seqlen = []\n        for i in range(n_samples):\n            # Random sequence length\n            len = random.randint(min_seq_len, max_seq_len)\n            # Monitor sequence length for TensorFlow dynamic calculation\n            self.seqlen.append(len)\n            # Add a random or linear int sequence (50% prob)\n            if random.random() < .5:\n                # Generate a linear sequence\n                rand_start = random.randint(0, max_value - len)\n                s = [[float(i)/max_value] for i in\n                     range(rand_start, rand_start + len)]\n                # Pad sequence for dimension consistency\n                s += [[0.] for i in range(max_seq_len - len)]\n                self.data.append(s)\n                self.labels.append([1., 0.])\n            else:\n                # Generate a random sequence\n                s = [[float(random.randint(0, max_value))/max_value]\n                     for i in range(len)]\n                # Pad sequence for dimension consistency\n                s += [[0.] for i in range(max_seq_len - len)]\n                self.data.append(s)\n                self.labels.append([0., 1.])\n        self.batch_id = 0\n\n    def next(self, batch_size):\n        """""" Return a batch of data. When dataset end is reached, start over.\n        """"""\n        if self.batch_id == len(self.data):\n            self.batch_id = 0\n        batch_data = (self.data[self.batch_id:min(self.batch_id +\n                                                  batch_size, len(self.data))])\n        batch_labels = (self.labels[self.batch_id:min(self.batch_id +\n                                                  batch_size, len(self.data))])\n        batch_seqlen = (self.seqlen[self.batch_id:min(self.batch_id +\n                                                  batch_size, len(self.data))])\n        self.batch_id = min(self.batch_id + batch_size, len(self.data))\n        return batch_data, batch_labels, batch_seqlen\n\n\n# ==========\n#   MODEL\n# ==========\n\n# Parameters\nlearning_rate = 0.01\ntraining_steps = 10000\nbatch_size = 128\ndisplay_step = 200\n\n# Network Parameters\nseq_max_len = 20 # Sequence max length\nn_hidden = 64 # hidden layer num of features\nn_classes = 2 # linear sequence or not\n\ntrainset = ToySequenceData(n_samples=1000, max_seq_len=seq_max_len)\ntestset = ToySequenceData(n_samples=500, max_seq_len=seq_max_len)\n\n# tf Graph input\nx = tf.placeholder(""float"", [None, seq_max_len, 1])\ny = tf.placeholder(""float"", [None, n_classes])\n# A placeholder for indicating each sequence length\nseqlen = tf.placeholder(tf.int32, [None])\n\n# Define weights\nweights = {\n    \'out\': tf.Variable(tf.random_normal([n_hidden, n_classes]))\n}\nbiases = {\n    \'out\': tf.Variable(tf.random_normal([n_classes]))\n}\n\n\ndef dynamicRNN(x, seqlen, weights, biases):\n\n    # Prepare data shape to match `rnn` function requirements\n    # Current data input shape: (batch_size, n_steps, n_input)\n    # Required shape: \'n_steps\' tensors list of shape (batch_size, n_input)\n    \n    # Unstack to get a list of \'n_steps\' tensors of shape (batch_size, n_input)\n    x = tf.unstack(x, seq_max_len, 1)\n\n    # Define a lstm cell with tensorflow\n    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden)\n\n    # Get lstm cell output, providing \'sequence_length\' will perform dynamic\n    # calculation.\n    outputs, states = tf.contrib.rnn.static_rnn(lstm_cell, x, dtype=tf.float32,\n                                sequence_length=seqlen)\n\n    # When performing dynamic calculation, we must retrieve the last\n    # dynamically computed output, i.e., if a sequence length is 10, we need\n    # to retrieve the 10th output.\n    # However TensorFlow doesn\'t support advanced indexing yet, so we build\n    # a custom op that for each sample in batch size, get its length and\n    # get the corresponding relevant output.\n\n    # \'outputs\' is a list of output at every timestep, we pack them in a Tensor\n    # and change back dimension to [batch_size, n_step, n_input]\n    outputs = tf.stack(outputs)\n    outputs = tf.transpose(outputs, [1, 0, 2])\n\n    # Hack to build the indexing and retrieve the right output.\n    batch_size = tf.shape(outputs)[0]\n    # Start indices for each sample\n    index = tf.range(0, batch_size) * seq_max_len + (seqlen - 1)\n    # Indexing\n    outputs = tf.gather(tf.reshape(outputs, [-1, n_hidden]), index)\n\n    # Linear activation, using outputs computed above\n    return tf.matmul(outputs, weights[\'out\']) + biases[\'out\']\n\npred = dynamicRNN(x, seqlen, weights, biases)\n\n# Define loss and optimizer\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n\n# Evaluate model\ncorrect_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\n# Initialize the variables (i.e. assign their default value)\ninit = tf.global_variables_initializer()\n\n# Start training\nwith tf.Session() as sess:\n\n    # Run the initializer\n    sess.run(init)\n\n    for step in range(1, training_steps + 1):\n        batch_x, batch_y, batch_seqlen = trainset.next(batch_size)\n        # Run optimization op (backprop)\n        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y,\n                                       seqlen: batch_seqlen})\n        if step % display_step == 0 or step == 1:\n            # Calculate batch accuracy & loss\n            acc, loss = sess.run([accuracy, cost], feed_dict={x: batch_x, y: batch_y,\n                                                seqlen: batch_seqlen})\n            print(""Step "" + str(step*batch_size) + "", Minibatch Loss= "" + \\\n                  ""{:.6f}"".format(loss) + "", Training Accuracy= "" + \\\n                  ""{:.5f}"".format(acc))\n\n    print(""Optimization Finished!"")\n\n    # Calculate accuracy\n    test_data = testset.data\n    test_label = testset.labels\n    test_seqlen = testset.seqlen\n    print(""Testing Accuracy:"", \\\n        sess.run(accuracy, feed_dict={x: test_data, y: test_label,\n                                      seqlen: test_seqlen}))\n'"
examples/3_NeuralNetworks/gan.py,29,"b'"""""" Generative Adversarial Networks (GAN).\n\nUsing generative adversarial networks (GAN) to generate digit images from a\nnoise distribution.\n\nReferences:\n    - Generative adversarial nets. I Goodfellow, J Pouget-Abadie, M Mirza,\n    B Xu, D Warde-Farley, S Ozair, Y. Bengio. Advances in neural information\n    processing systems, 2672-2680.\n    - Understanding the difficulty of training deep feedforward neural networks.\n    X Glorot, Y Bengio. Aistats 9, 249-256\n\nLinks:\n    - [GAN Paper](https://arxiv.org/pdf/1406.2661.pdf).\n    - [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).\n    - [Xavier Glorot Init](www.cs.cmu.edu/~bhiksha/courses/deeplearning/Fall.../AISTATS2010_Glorot.pdf).\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n""""""\n\nfrom __future__ import division, print_function, absolute_import\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\n\n# Import MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""/tmp/data/"", one_hot=True)\n\n# Training Params\nnum_steps = 100000\nbatch_size = 128\nlearning_rate = 0.0002\n\n# Network Params\nimage_dim = 784 # 28*28 pixels\ngen_hidden_dim = 256\ndisc_hidden_dim = 256\nnoise_dim = 100 # Noise data points\n\n# A custom initialization (see Xavier Glorot init)\ndef glorot_init(shape):\n    return tf.random_normal(shape=shape, stddev=1. / tf.sqrt(shape[0] / 2.))\n\n# Store layers weight & bias\nweights = {\n    \'gen_hidden1\': tf.Variable(glorot_init([noise_dim, gen_hidden_dim])),\n    \'gen_out\': tf.Variable(glorot_init([gen_hidden_dim, image_dim])),\n    \'disc_hidden1\': tf.Variable(glorot_init([image_dim, disc_hidden_dim])),\n    \'disc_out\': tf.Variable(glorot_init([disc_hidden_dim, 1])),\n}\nbiases = {\n    \'gen_hidden1\': tf.Variable(tf.zeros([gen_hidden_dim])),\n    \'gen_out\': tf.Variable(tf.zeros([image_dim])),\n    \'disc_hidden1\': tf.Variable(tf.zeros([disc_hidden_dim])),\n    \'disc_out\': tf.Variable(tf.zeros([1])),\n}\n\n\n# Generator\ndef generator(x):\n    hidden_layer = tf.matmul(x, weights[\'gen_hidden1\'])\n    hidden_layer = tf.add(hidden_layer, biases[\'gen_hidden1\'])\n    hidden_layer = tf.nn.relu(hidden_layer)\n    out_layer = tf.matmul(hidden_layer, weights[\'gen_out\'])\n    out_layer = tf.add(out_layer, biases[\'gen_out\'])\n    out_layer = tf.nn.sigmoid(out_layer)\n    return out_layer\n\n\n# Discriminator\ndef discriminator(x):\n    hidden_layer = tf.matmul(x, weights[\'disc_hidden1\'])\n    hidden_layer = tf.add(hidden_layer, biases[\'disc_hidden1\'])\n    hidden_layer = tf.nn.relu(hidden_layer)\n    out_layer = tf.matmul(hidden_layer, weights[\'disc_out\'])\n    out_layer = tf.add(out_layer, biases[\'disc_out\'])\n    out_layer = tf.nn.sigmoid(out_layer)\n    return out_layer\n\n# Build Networks\n# Network Inputs\ngen_input = tf.placeholder(tf.float32, shape=[None, noise_dim], name=\'input_noise\')\ndisc_input = tf.placeholder(tf.float32, shape=[None, image_dim], name=\'disc_input\')\n\n# Build Generator Network\ngen_sample = generator(gen_input)\n\n# Build 2 Discriminator Networks (one from noise input, one from generated samples)\ndisc_real = discriminator(disc_input)\ndisc_fake = discriminator(gen_sample)\n\n# Build Loss\ngen_loss = -tf.reduce_mean(tf.log(disc_fake))\ndisc_loss = -tf.reduce_mean(tf.log(disc_real) + tf.log(1. - disc_fake))\n\n# Build Optimizers\noptimizer_gen = tf.train.AdamOptimizer(learning_rate=learning_rate)\noptimizer_disc = tf.train.AdamOptimizer(learning_rate=learning_rate)\n\n# Training Variables for each optimizer\n# By default in TensorFlow, all variables are updated by each optimizer, so we\n# need to precise for each one of them the specific variables to update.\n# Generator Network Variables\ngen_vars = [weights[\'gen_hidden1\'], weights[\'gen_out\'],\n            biases[\'gen_hidden1\'], biases[\'gen_out\']]\n# Discriminator Network Variables\ndisc_vars = [weights[\'disc_hidden1\'], weights[\'disc_out\'],\n            biases[\'disc_hidden1\'], biases[\'disc_out\']]\n\n# Create training operations\ntrain_gen = optimizer_gen.minimize(gen_loss, var_list=gen_vars)\ntrain_disc = optimizer_disc.minimize(disc_loss, var_list=disc_vars)\n\n# Initialize the variables (i.e. assign their default value)\ninit = tf.global_variables_initializer()\n\n# Start training\nwith tf.Session() as sess:\n\n    # Run the initializer\n    sess.run(init)\n\n    for i in range(1, num_steps+1):\n        # Prepare Data\n        # Get the next batch of MNIST data (only images are needed, not labels)\n        batch_x, _ = mnist.train.next_batch(batch_size)\n        # Generate noise to feed to the generator\n        z = np.random.uniform(-1., 1., size=[batch_size, noise_dim])\n\n        # Train\n        feed_dict = {disc_input: batch_x, gen_input: z}\n        _, _, gl, dl = sess.run([train_gen, train_disc, gen_loss, disc_loss],\n                                feed_dict=feed_dict)\n        if i % 1000 == 0 or i == 1:\n            print(\'Step %i: Generator Loss: %f, Discriminator Loss: %f\' % (i, gl, dl))\n\n    # Generate images from noise, using the generator network.\n    f, a = plt.subplots(4, 10, figsize=(10, 4))\n    for i in range(10):\n        # Noise input.\n        z = np.random.uniform(-1., 1., size=[4, noise_dim])\n        g = sess.run([gen_sample], feed_dict={gen_input: z})\n        g = np.reshape(g, newshape=(4, 28, 28, 1))\n        # Reverse colours for better display\n        g = -1 * (g - 1)\n        for j in range(4):\n            # Generate image from noise. Extend to 3 channels for matplot figure.\n            img = np.reshape(np.repeat(g[j][:, :, np.newaxis], 3, axis=2),\n                             newshape=(28, 28, 3))\n            a[j][i].imshow(img)\n\n    f.show()\n    plt.draw()\n    plt.waitforbuttonpress()\n'"
examples/3_NeuralNetworks/multilayer_perceptron.py,18,"b'"""""" Multilayer Perceptron.\n\nA Multilayer Perceptron (Neural Network) implementation example using\nTensorFlow library. This example is using the MNIST database of handwritten\ndigits (http://yann.lecun.com/exdb/mnist/).\n\nLinks:\n    [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n""""""\n\n# ------------------------------------------------------------------\n#\n# THIS EXAMPLE HAS BEEN RENAMED \'neural_network.py\', FOR SIMPLICITY.\n#\n# ------------------------------------------------------------------\n\n\nfrom __future__ import print_function\n\n# Import MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""/tmp/data/"", one_hot=True)\n\nimport tensorflow as tf\n\n# Parameters\nlearning_rate = 0.001\ntraining_epochs = 15\nbatch_size = 100\ndisplay_step = 1\n\n# Network Parameters\nn_hidden_1 = 256 # 1st layer number of neurons\nn_hidden_2 = 256 # 2nd layer number of neurons\nn_input = 784 # MNIST data input (img shape: 28*28)\nn_classes = 10 # MNIST total classes (0-9 digits)\n\n# tf Graph input\nX = tf.placeholder(""float"", [None, n_input])\nY = tf.placeholder(""float"", [None, n_classes])\n\n# Store layers weight & bias\nweights = {\n    \'h1\': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n    \'h2\': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n    \'out\': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n}\nbiases = {\n    \'b1\': tf.Variable(tf.random_normal([n_hidden_1])),\n    \'b2\': tf.Variable(tf.random_normal([n_hidden_2])),\n    \'out\': tf.Variable(tf.random_normal([n_classes]))\n}\n\n\n# Create model\ndef multilayer_perceptron(x):\n    # Hidden fully connected layer with 256 neurons\n    layer_1 = tf.add(tf.matmul(x, weights[\'h1\']), biases[\'b1\'])\n    # Hidden fully connected layer with 256 neurons\n    layer_2 = tf.add(tf.matmul(layer_1, weights[\'h2\']), biases[\'b2\'])\n    # Output fully connected layer with a neuron for each class\n    out_layer = tf.matmul(layer_2, weights[\'out\']) + biases[\'out\']\n    return out_layer\n\n# Construct model\nlogits = multilayer_perceptron(X)\n\n# Define loss and optimizer\nloss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n    logits=logits, labels=Y))\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\ntrain_op = optimizer.minimize(loss_op)\n# Initializing the variables\ninit = tf.global_variables_initializer()\n\nwith tf.Session() as sess:\n    sess.run(init)\n\n    # Training cycle\n    for epoch in range(training_epochs):\n        avg_cost = 0.\n        total_batch = int(mnist.train.num_examples/batch_size)\n        # Loop over all batches\n        for i in range(total_batch):\n            batch_x, batch_y = mnist.train.next_batch(batch_size)\n            # Run optimization op (backprop) and cost op (to get loss value)\n            _, c = sess.run([train_op, loss_op], feed_dict={X: batch_x,\n                                                            Y: batch_y})\n            # Compute average loss\n            avg_cost += c / total_batch\n        # Display logs per epoch step\n        if epoch % display_step == 0:\n            print(""Epoch:"", \'%04d\' % (epoch+1), ""cost={:.9f}"".format(avg_cost))\n    print(""Optimization Finished!"")\n\n    # Test model\n    pred = tf.nn.softmax(logits)  # Apply softmax to logits\n    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(Y, 1))\n    # Calculate accuracy\n    accuracy = tf.reduce_mean(tf.cast(correct_prediction, ""float""))\n    print(""Accuracy:"", accuracy.eval({X: mnist.test.images, Y: mnist.test.labels}))\n'"
examples/3_NeuralNetworks/neural_network.py,16,"b'"""""" Neural Network.\n\nA 2-Hidden Layers Fully Connected Neural Network (a.k.a Multilayer Perceptron)\nimplementation with TensorFlow. This example is using the MNIST database\nof handwritten digits (http://yann.lecun.com/exdb/mnist/).\n\nThis example is using TensorFlow layers, see \'neural_network_raw\' example for\na raw implementation with variables.\n\nLinks:\n    [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n""""""\n\nfrom __future__ import print_function\n\n# Import MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""/tmp/data/"", one_hot=False)\n\nimport tensorflow as tf\n\n# Parameters\nlearning_rate = 0.1\nnum_steps = 1000\nbatch_size = 128\ndisplay_step = 100\n\n# Network Parameters\nn_hidden_1 = 256 # 1st layer number of neurons\nn_hidden_2 = 256 # 2nd layer number of neurons\nnum_input = 784 # MNIST data input (img shape: 28*28)\nnum_classes = 10 # MNIST total classes (0-9 digits)\n\n\n# Define the neural network\ndef neural_net(x_dict):\n    # TF Estimator input is a dict, in case of multiple inputs\n    x = x_dict[\'images\']\n    # Hidden fully connected layer with 256 neurons\n    layer_1 = tf.layers.dense(x, n_hidden_1)\n    # Hidden fully connected layer with 256 neurons\n    layer_2 = tf.layers.dense(layer_1, n_hidden_2)\n    # Output fully connected layer with a neuron for each class\n    out_layer = tf.layers.dense(layer_2, num_classes)\n    return out_layer\n\n\n# Define the model function (following TF Estimator Template)\ndef model_fn(features, labels, mode):\n    # Build the neural network\n    logits = neural_net(features)\n\n    # Predictions\n    pred_classes = tf.argmax(logits, axis=1)\n    pred_probas = tf.nn.softmax(logits)\n\n    # If prediction mode, early return\n    if mode == tf.estimator.ModeKeys.PREDICT:\n        return tf.estimator.EstimatorSpec(mode, predictions=pred_classes)\n\n    # Define loss and optimizer\n    loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n        logits=logits, labels=tf.cast(labels, dtype=tf.int32)))\n    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n    train_op = optimizer.minimize(loss_op,\n                                  global_step=tf.train.get_global_step())\n\n    # Evaluate the accuracy of the model\n    acc_op = tf.metrics.accuracy(labels=labels, predictions=pred_classes)\n\n    # TF Estimators requires to return a EstimatorSpec, that specify\n    # the different ops for training, evaluating, ...\n    estim_specs = tf.estimator.EstimatorSpec(\n        mode=mode,\n        predictions=pred_classes,\n        loss=loss_op,\n        train_op=train_op,\n        eval_metric_ops={\'accuracy\': acc_op})\n\n    return estim_specs\n\n# Build the Estimator\nmodel = tf.estimator.Estimator(model_fn)\n\n# Define the input function for training\ninput_fn = tf.estimator.inputs.numpy_input_fn(\n    x={\'images\': mnist.train.images}, y=mnist.train.labels,\n    batch_size=batch_size, num_epochs=None, shuffle=True)\n# Train the Model\nmodel.train(input_fn, steps=num_steps)\n\n# Evaluate the Model\n# Define the input function for evaluating\ninput_fn = tf.estimator.inputs.numpy_input_fn(\n    x={\'images\': mnist.test.images}, y=mnist.test.labels,\n    batch_size=batch_size, shuffle=False)\n# Use the Estimator \'evaluate\' method\ne = model.evaluate(input_fn)\n\nprint(""Testing Accuracy:"", e[\'accuracy\'])\n'"
examples/3_NeuralNetworks/neural_network_eager_api.py,13,"b'"""""" Neural Network with Eager API.\n\nA 2-Hidden Layers Fully Connected Neural Network (a.k.a Multilayer Perceptron)\nimplementation with TensorFlow\'s Eager API. This example is using the MNIST database\nof handwritten digits (http://yann.lecun.com/exdb/mnist/).\n\nThis example is using TensorFlow layers, see \'neural_network_raw\' example for\na raw implementation with variables.\n\nLinks:\n    [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n""""""\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\n# Set Eager API\ntf.enable_eager_execution()\ntfe = tf.contrib.eager\n\n# Import MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""/tmp/data/"", one_hot=False)\n\n# Parameters\nlearning_rate = 0.001\nnum_steps = 1000\nbatch_size = 128\ndisplay_step = 100\n\n# Network Parameters\nn_hidden_1 = 256 # 1st layer number of neurons\nn_hidden_2 = 256 # 2nd layer number of neurons\nnum_input = 784 # MNIST data input (img shape: 28*28)\nnum_classes = 10 # MNIST total classes (0-9 digits)\n\n# Using TF Dataset to split data into batches\ndataset = tf.data.Dataset.from_tensor_slices(\n    (mnist.train.images, mnist.train.labels))\ndataset = dataset.repeat().batch(batch_size).prefetch(batch_size)\ndataset_iter = tfe.Iterator(dataset)\n\n\n# Define the neural network. To use eager API and tf.layers API together,\n# we must instantiate a tfe.Network class as follow:\nclass NeuralNet(tfe.Network):\n    def __init__(self):\n        # Define each layer\n        super(NeuralNet, self).__init__()\n        # Hidden fully connected layer with 256 neurons\n        self.layer1 = self.track_layer(\n            tf.layers.Dense(n_hidden_1, activation=tf.nn.relu))\n        # Hidden fully connected layer with 256 neurons\n        self.layer2 = self.track_layer(\n            tf.layers.Dense(n_hidden_2, activation=tf.nn.relu))\n        # Output fully connected layer with a neuron for each class\n        self.out_layer = self.track_layer(tf.layers.Dense(num_classes))\n\n    def call(self, x):\n        x = self.layer1(x)\n        x = self.layer2(x)\n        return self.out_layer(x)\n\n\nneural_net = NeuralNet()\n\n\n# Cross-Entropy loss function\ndef loss_fn(inference_fn, inputs, labels):\n    # Using sparse_softmax cross entropy\n    return tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n        logits=inference_fn(inputs), labels=labels))\n\n\n# Calculate accuracy\ndef accuracy_fn(inference_fn, inputs, labels):\n    prediction = tf.nn.softmax(inference_fn(inputs))\n    correct_pred = tf.equal(tf.argmax(prediction, 1), labels)\n    return tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\n\n# SGD Optimizer\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n# Compute gradients\ngrad = tfe.implicit_gradients(loss_fn)\n\n# Training\naverage_loss = 0.\naverage_acc = 0.\nfor step in range(num_steps):\n\n    # Iterate through the dataset\n    d = dataset_iter.next()\n\n    # Images\n    x_batch = d[0]\n    # Labels\n    y_batch = tf.cast(d[1], dtype=tf.int64)\n\n    # Compute the batch loss\n    batch_loss = loss_fn(neural_net, x_batch, y_batch)\n    average_loss += batch_loss\n    # Compute the batch accuracy\n    batch_accuracy = accuracy_fn(neural_net, x_batch, y_batch)\n    average_acc += batch_accuracy\n\n    if step == 0:\n        # Display the initial cost, before optimizing\n        print(""Initial loss= {:.9f}"".format(average_loss))\n\n    # Update the variables following gradients info\n    optimizer.apply_gradients(grad(neural_net, x_batch, y_batch))\n\n    # Display info\n    if (step + 1) % display_step == 0 or step == 0:\n        if step > 0:\n            average_loss /= display_step\n            average_acc /= display_step\n        print(""Step:"", \'%04d\' % (step + 1), "" loss="",\n              ""{:.9f}"".format(average_loss), "" accuracy="",\n              ""{:.4f}"".format(average_acc))\n        average_loss = 0.\n        average_acc = 0.\n\n# Evaluate model on the test image set\ntestX = mnist.test.images\ntestY = mnist.test.labels\n\ntest_acc = accuracy_fn(neural_net, testX, testY)\nprint(""Testset Accuracy: {:.4f}"".format(test_acc))\n'"
examples/3_NeuralNetworks/neural_network_raw.py,18,"b'"""""" Neural Network.\n\nA 2-Hidden Layers Fully Connected Neural Network (a.k.a Multilayer Perceptron)\nimplementation with TensorFlow. This example is using the MNIST database\nof handwritten digits (http://yann.lecun.com/exdb/mnist/).\n\nLinks:\n    [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n""""""\n\nfrom __future__ import print_function\n\n# Import MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""/tmp/data/"", one_hot=True)\n\nimport tensorflow as tf\n\n# Parameters\nlearning_rate = 0.1\nnum_steps = 500\nbatch_size = 128\ndisplay_step = 100\n\n# Network Parameters\nn_hidden_1 = 256 # 1st layer number of neurons\nn_hidden_2 = 256 # 2nd layer number of neurons\nnum_input = 784 # MNIST data input (img shape: 28*28)\nnum_classes = 10 # MNIST total classes (0-9 digits)\n\n# tf Graph input\nX = tf.placeholder(""float"", [None, num_input])\nY = tf.placeholder(""float"", [None, num_classes])\n\n# Store layers weight & bias\nweights = {\n    \'h1\': tf.Variable(tf.random_normal([num_input, n_hidden_1])),\n    \'h2\': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n    \'out\': tf.Variable(tf.random_normal([n_hidden_2, num_classes]))\n}\nbiases = {\n    \'b1\': tf.Variable(tf.random_normal([n_hidden_1])),\n    \'b2\': tf.Variable(tf.random_normal([n_hidden_2])),\n    \'out\': tf.Variable(tf.random_normal([num_classes]))\n}\n\n\n# Create model\ndef neural_net(x):\n    # Hidden fully connected layer with 256 neurons\n    layer_1 = tf.add(tf.matmul(x, weights[\'h1\']), biases[\'b1\'])\n    # Hidden fully connected layer with 256 neurons\n    layer_2 = tf.add(tf.matmul(layer_1, weights[\'h2\']), biases[\'b2\'])\n    # Output fully connected layer with a neuron for each class\n    out_layer = tf.matmul(layer_2, weights[\'out\']) + biases[\'out\']\n    return out_layer\n\n# Construct model\nlogits = neural_net(X)\nprediction = tf.nn.softmax(logits)\n\n# Define loss and optimizer\nloss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n    logits=logits, labels=Y))\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\ntrain_op = optimizer.minimize(loss_op)\n\n# Evaluate model\ncorrect_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\n# Initialize the variables (i.e. assign their default value)\ninit = tf.global_variables_initializer()\n\n# Start training\nwith tf.Session() as sess:\n\n    # Run the initializer\n    sess.run(init)\n\n    for step in range(1, num_steps+1):\n        batch_x, batch_y = mnist.train.next_batch(batch_size)\n        # Run optimization op (backprop)\n        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n        if step % display_step == 0 or step == 1:\n            # Calculate batch loss and accuracy\n            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n                                                                 Y: batch_y})\n            print(""Step "" + str(step) + "", Minibatch Loss= "" + \\\n                  ""{:.4f}"".format(loss) + "", Training Accuracy= "" + \\\n                  ""{:.3f}"".format(acc))\n\n    print(""Optimization Finished!"")\n\n    # Calculate accuracy for MNIST test images\n    print(""Testing Accuracy:"", \\\n        sess.run(accuracy, feed_dict={X: mnist.test.images,\n                                      Y: mnist.test.labels}))\n'"
examples/3_NeuralNetworks/recurrent_network.py,14,"b'"""""" Recurrent Neural Network.\n\nA Recurrent Neural Network (LSTM) implementation example using TensorFlow library.\nThis example is using the MNIST database of handwritten digits (http://yann.lecun.com/exdb/mnist/)\n\nLinks:\n    [Long Short Term Memory](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf)\n    [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n""""""\n\nfrom __future__ import print_function\n\nimport tensorflow as tf\nfrom tensorflow.contrib import rnn\n\n# Import MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""/tmp/data/"", one_hot=True)\n\n\'\'\'\nTo classify images using a recurrent neural network, we consider every image\nrow as a sequence of pixels. Because MNIST image shape is 28*28px, we will then\nhandle 28 sequences of 28 steps for every sample.\n\'\'\'\n\n# Training Parameters\nlearning_rate = 0.001\ntraining_steps = 10000\nbatch_size = 128\ndisplay_step = 200\n\n# Network Parameters\nnum_input = 28 # MNIST data input (img shape: 28*28)\ntimesteps = 28 # timesteps\nnum_hidden = 128 # hidden layer num of features\nnum_classes = 10 # MNIST total classes (0-9 digits)\n\n# tf Graph input\nX = tf.placeholder(""float"", [None, timesteps, num_input])\nY = tf.placeholder(""float"", [None, num_classes])\n\n# Define weights\nweights = {\n    \'out\': tf.Variable(tf.random_normal([num_hidden, num_classes]))\n}\nbiases = {\n    \'out\': tf.Variable(tf.random_normal([num_classes]))\n}\n\n\ndef RNN(x, weights, biases):\n\n    # Prepare data shape to match `rnn` function requirements\n    # Current data input shape: (batch_size, timesteps, n_input)\n    # Required shape: \'timesteps\' tensors list of shape (batch_size, n_input)\n\n    # Unstack to get a list of \'timesteps\' tensors of shape (batch_size, n_input)\n    x = tf.unstack(x, timesteps, 1)\n\n    # Define a lstm cell with tensorflow\n    lstm_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n\n    # Get lstm cell output\n    outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n\n    # Linear activation, using rnn inner loop last output\n    return tf.matmul(outputs[-1], weights[\'out\']) + biases[\'out\']\n\nlogits = RNN(X, weights, biases)\nprediction = tf.nn.softmax(logits)\n\n# Define loss and optimizer\nloss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n    logits=logits, labels=Y))\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\ntrain_op = optimizer.minimize(loss_op)\n\n# Evaluate model (with test logits, for dropout to be disabled)\ncorrect_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\n# Initialize the variables (i.e. assign their default value)\ninit = tf.global_variables_initializer()\n\n# Start training\nwith tf.Session() as sess:\n\n    # Run the initializer\n    sess.run(init)\n\n    for step in range(1, training_steps+1):\n        batch_x, batch_y = mnist.train.next_batch(batch_size)\n        # Reshape data to get 28 seq of 28 elements\n        batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n        # Run optimization op (backprop)\n        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n        if step % display_step == 0 or step == 1:\n            # Calculate batch loss and accuracy\n            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n                                                                 Y: batch_y})\n            print(""Step "" + str(step) + "", Minibatch Loss= "" + \\\n                  ""{:.4f}"".format(loss) + "", Training Accuracy= "" + \\\n                  ""{:.3f}"".format(acc))\n\n    print(""Optimization Finished!"")\n\n    # Calculate accuracy for 128 mnist test images\n    test_len = 128\n    test_data = mnist.test.images[:test_len].reshape((-1, timesteps, num_input))\n    test_label = mnist.test.labels[:test_len]\n    print(""Testing Accuracy:"", \\\n        sess.run(accuracy, feed_dict={X: test_data, Y: test_label}))\n'"
examples/3_NeuralNetworks/variational_autoencoder.py,36,"b'"""""" Variational Auto-Encoder Example.\n\nUsing a variational auto-encoder to generate digits images from noise.\nMNIST handwritten digits are used as training examples.\n\nReferences:\n    - Auto-Encoding Variational Bayes The International Conference on Learning\n    Representations (ICLR), Banff, 2014. D.P. Kingma, M. Welling\n    - Understanding the difficulty of training deep feedforward neural networks.\n    X Glorot, Y Bengio. Aistats 9, 249-256\n    - Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. ""Gradient-based\n    learning applied to document recognition."" Proceedings of the IEEE,\n    86(11):2278-2324, November 1998.\n\nLinks:\n    - [VAE Paper] https://arxiv.org/abs/1312.6114\n    - [Xavier Glorot Init](www.cs.cmu.edu/~bhiksha/courses/deeplearning/Fall.../AISTATS2010_Glorot.pdf).\n    - [MNIST Dataset] http://yann.lecun.com/exdb/mnist/\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n""""""\nfrom __future__ import division, print_function, absolute_import\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\nimport tensorflow as tf\n\n# Import MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""/tmp/data/"", one_hot=True)\n\n# Parameters\nlearning_rate = 0.001\nnum_steps = 30000\nbatch_size = 64\n\n# Network Parameters\nimage_dim = 784 # MNIST images are 28x28 pixels\nhidden_dim = 512\nlatent_dim = 2\n\n# A custom initialization (see Xavier Glorot init)\ndef glorot_init(shape):\n    return tf.random_normal(shape=shape, stddev=1. / tf.sqrt(shape[0] / 2.))\n\n# Variables\nweights = {\n    \'encoder_h1\': tf.Variable(glorot_init([image_dim, hidden_dim])),\n    \'z_mean\': tf.Variable(glorot_init([hidden_dim, latent_dim])),\n    \'z_std\': tf.Variable(glorot_init([hidden_dim, latent_dim])),\n    \'decoder_h1\': tf.Variable(glorot_init([latent_dim, hidden_dim])),\n    \'decoder_out\': tf.Variable(glorot_init([hidden_dim, image_dim]))\n}\nbiases = {\n    \'encoder_b1\': tf.Variable(glorot_init([hidden_dim])),\n    \'z_mean\': tf.Variable(glorot_init([latent_dim])),\n    \'z_std\': tf.Variable(glorot_init([latent_dim])),\n    \'decoder_b1\': tf.Variable(glorot_init([hidden_dim])),\n    \'decoder_out\': tf.Variable(glorot_init([image_dim]))\n}\n\n# Building the encoder\ninput_image = tf.placeholder(tf.float32, shape=[None, image_dim])\nencoder = tf.matmul(input_image, weights[\'encoder_h1\']) + biases[\'encoder_b1\']\nencoder = tf.nn.tanh(encoder)\nz_mean = tf.matmul(encoder, weights[\'z_mean\']) + biases[\'z_mean\']\nz_std = tf.matmul(encoder, weights[\'z_std\']) + biases[\'z_std\']\n\n# Sampler: Normal (gaussian) random distribution\neps = tf.random_normal(tf.shape(z_std), dtype=tf.float32, mean=0., stddev=1.0,\n                       name=\'epsilon\')\nz = z_mean + tf.exp(z_std / 2) * eps\n\n# Building the decoder (with scope to re-use these layers later)\ndecoder = tf.matmul(z, weights[\'decoder_h1\']) + biases[\'decoder_b1\']\ndecoder = tf.nn.tanh(decoder)\ndecoder = tf.matmul(decoder, weights[\'decoder_out\']) + biases[\'decoder_out\']\ndecoder = tf.nn.sigmoid(decoder)\n\n\n# Define VAE Loss\ndef vae_loss(x_reconstructed, x_true):\n    # Reconstruction loss\n    encode_decode_loss = x_true * tf.log(1e-10 + x_reconstructed) \\\n                         + (1 - x_true) * tf.log(1e-10 + 1 - x_reconstructed)\n    encode_decode_loss = -tf.reduce_sum(encode_decode_loss, 1)\n    # KL Divergence loss\n    kl_div_loss = 1 + z_std - tf.square(z_mean) - tf.exp(z_std)\n    kl_div_loss = -0.5 * tf.reduce_sum(kl_div_loss, 1)\n    return tf.reduce_mean(encode_decode_loss + kl_div_loss)\n\nloss_op = vae_loss(decoder, input_image)\noptimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate)\ntrain_op = optimizer.minimize(loss_op)\n\n# Initialize the variables (i.e. assign their default value)\ninit = tf.global_variables_initializer()\n\n# Start training\nwith tf.Session() as sess:\n\n    # Run the initializer\n    sess.run(init)\n\n    for i in range(1, num_steps+1):\n        # Prepare Data\n        # Get the next batch of MNIST data (only images are needed, not labels)\n        batch_x, _ = mnist.train.next_batch(batch_size)\n\n        # Train\n        feed_dict = {input_image: batch_x}\n        _, l = sess.run([train_op, loss_op], feed_dict=feed_dict)\n        if i % 1000 == 0 or i == 1:\n            print(\'Step %i, Loss: %f\' % (i, l))\n\n    # Testing\n    # Generator takes noise as input\n    noise_input = tf.placeholder(tf.float32, shape=[None, latent_dim])\n    # Rebuild the decoder to create image from noise\n    decoder = tf.matmul(noise_input, weights[\'decoder_h1\']) + biases[\'decoder_b1\']\n    decoder = tf.nn.tanh(decoder)\n    decoder = tf.matmul(decoder, weights[\'decoder_out\']) + biases[\'decoder_out\']\n    decoder = tf.nn.sigmoid(decoder)\n\n    # Building a manifold of generated digits\n    n = 20\n    x_axis = np.linspace(-3, 3, n)\n    y_axis = np.linspace(-3, 3, n)\n\n    canvas = np.empty((28 * n, 28 * n))\n    for i, yi in enumerate(x_axis):\n        for j, xi in enumerate(y_axis):\n            z_mu = np.array([[xi, yi]] * batch_size)\n            x_mean = sess.run(decoder, feed_dict={noise_input: z_mu})\n            canvas[(n - i - 1) * 28:(n - i) * 28, j * 28:(j + 1) * 28] = \\\n            x_mean[0].reshape(28, 28)\n\n    plt.figure(figsize=(8, 10))\n    Xi, Yi = np.meshgrid(x_axis, y_axis)\n    plt.imshow(canvas, origin=""upper"", cmap=""gray"")\n    plt.show()\n'"
examples/4_Utils/save_restore_model.py,23,"b'\'\'\'\nSave and Restore a model using TensorFlow.\nThis example is using the MNIST database of handwritten digits\n(http://yann.lecun.com/exdb/mnist/)\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n\'\'\'\n\nfrom __future__ import print_function\n\n# Import MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""MNIST_data/"", one_hot=True)\n\nimport tensorflow as tf\n\n# Parameters\nlearning_rate = 0.001\nbatch_size = 100\ndisplay_step = 1\nmodel_path = ""/tmp/model.ckpt""\n\n# Network Parameters\nn_hidden_1 = 256 # 1st layer number of features\nn_hidden_2 = 256 # 2nd layer number of features\nn_input = 784 # MNIST data input (img shape: 28*28)\nn_classes = 10 # MNIST total classes (0-9 digits)\n\n# tf Graph input\nx = tf.placeholder(""float"", [None, n_input])\ny = tf.placeholder(""float"", [None, n_classes])\n\n\n# Create model\ndef multilayer_perceptron(x, weights, biases):\n    # Hidden layer with RELU activation\n    layer_1 = tf.add(tf.matmul(x, weights[\'h1\']), biases[\'b1\'])\n    layer_1 = tf.nn.relu(layer_1)\n    # Hidden layer with RELU activation\n    layer_2 = tf.add(tf.matmul(layer_1, weights[\'h2\']), biases[\'b2\'])\n    layer_2 = tf.nn.relu(layer_2)\n    # Output layer with linear activation\n    out_layer = tf.matmul(layer_2, weights[\'out\']) + biases[\'out\']\n    return out_layer\n\n# Store layers weight & bias\nweights = {\n    \'h1\': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n    \'h2\': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n    \'out\': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n}\nbiases = {\n    \'b1\': tf.Variable(tf.random_normal([n_hidden_1])),\n    \'b2\': tf.Variable(tf.random_normal([n_hidden_2])),\n    \'out\': tf.Variable(tf.random_normal([n_classes]))\n}\n\n# Construct model\npred = multilayer_perceptron(x, weights, biases)\n\n# Define loss and optimizer\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n\n# Initialize the variables (i.e. assign their default value)\ninit = tf.global_variables_initializer()\n\n# \'Saver\' op to save and restore all the variables\nsaver = tf.train.Saver()\n\n# Running first session\nprint(""Starting 1st session..."")\nwith tf.Session() as sess:\n\n    # Run the initializer\n    sess.run(init)\n\n    # Training cycle\n    for epoch in range(3):\n        avg_cost = 0.\n        total_batch = int(mnist.train.num_examples/batch_size)\n        # Loop over all batches\n        for i in range(total_batch):\n            batch_x, batch_y = mnist.train.next_batch(batch_size)\n            # Run optimization op (backprop) and cost op (to get loss value)\n            _, c = sess.run([optimizer, cost], feed_dict={x: batch_x,\n                                                          y: batch_y})\n            # Compute average loss\n            avg_cost += c / total_batch\n        # Display logs per epoch step\n        if epoch % display_step == 0:\n            print(""Epoch:"", \'%04d\' % (epoch+1), ""cost="", \\\n                ""{:.9f}"".format(avg_cost))\n    print(""First Optimization Finished!"")\n\n    # Test model\n    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n    # Calculate accuracy\n    accuracy = tf.reduce_mean(tf.cast(correct_prediction, ""float""))\n    print(""Accuracy:"", accuracy.eval({x: mnist.test.images, y: mnist.test.labels}))\n\n    # Save model weights to disk\n    save_path = saver.save(sess, model_path)\n    print(""Model saved in file: %s"" % save_path)\n\n# Running a new session\nprint(""Starting 2nd session..."")\nwith tf.Session() as sess:\n    # Initialize variables\n    sess.run(init)\n\n    # Restore model weights from previously saved model\n    saver.restore(sess, model_path)\n    print(""Model restored from file: %s"" % save_path)\n\n    # Resume training\n    for epoch in range(7):\n        avg_cost = 0.\n        total_batch = int(mnist.train.num_examples / batch_size)\n        # Loop over all batches\n        for i in range(total_batch):\n            batch_x, batch_y = mnist.train.next_batch(batch_size)\n            # Run optimization op (backprop) and cost op (to get loss value)\n            _, c = sess.run([optimizer, cost], feed_dict={x: batch_x,\n                                                          y: batch_y})\n            # Compute average loss\n            avg_cost += c / total_batch\n        # Display logs per epoch step\n        if epoch % display_step == 0:\n            print(""Epoch:"", \'%04d\' % (epoch + 1), ""cost="", \\\n                ""{:.9f}"".format(avg_cost))\n    print(""Second Optimization Finished!"")\n\n    # Test model\n    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n    # Calculate accuracy\n    accuracy = tf.reduce_mean(tf.cast(correct_prediction, ""float""))\n    print(""Accuracy:"", accuracy.eval(\n        {x: mnist.test.images, y: mnist.test.labels}))\n'"
examples/4_Utils/tensorboard_advanced.py,35,"b'\'\'\'\nGraph and Loss visualization using Tensorboard.\nThis example is using the MNIST database of handwritten digits\n(http://yann.lecun.com/exdb/mnist/)\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n\'\'\'\n\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\n# Import MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""/tmp/data/"", one_hot=True)\n\n# Parameters\nlearning_rate = 0.01\ntraining_epochs = 25\nbatch_size = 100\ndisplay_step = 1\nlogs_path = \'/tmp/tensorflow_logs/example/\'\n\n# Network Parameters\nn_hidden_1 = 256 # 1st layer number of features\nn_hidden_2 = 256 # 2nd layer number of features\nn_input = 784 # MNIST data input (img shape: 28*28)\nn_classes = 10 # MNIST total classes (0-9 digits)\n\n# tf Graph Input\n# mnist data image of shape 28*28=784\nx = tf.placeholder(tf.float32, [None, 784], name=\'InputData\')\n# 0-9 digits recognition => 10 classes\ny = tf.placeholder(tf.float32, [None, 10], name=\'LabelData\')\n\n\n# Create model\ndef multilayer_perceptron(x, weights, biases):\n    # Hidden layer with RELU activation\n    layer_1 = tf.add(tf.matmul(x, weights[\'w1\']), biases[\'b1\'])\n    layer_1 = tf.nn.relu(layer_1)\n    # Create a summary to visualize the first layer ReLU activation\n    tf.summary.histogram(""relu1"", layer_1)\n    # Hidden layer with RELU activation\n    layer_2 = tf.add(tf.matmul(layer_1, weights[\'w2\']), biases[\'b2\'])\n    layer_2 = tf.nn.relu(layer_2)\n    # Create another summary to visualize the second layer ReLU activation\n    tf.summary.histogram(""relu2"", layer_2)\n    # Output layer\n    out_layer = tf.add(tf.matmul(layer_2, weights[\'w3\']), biases[\'b3\'])\n    return out_layer\n\n# Store layers weight & bias\nweights = {\n    \'w1\': tf.Variable(tf.random_normal([n_input, n_hidden_1]), name=\'W1\'),\n    \'w2\': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2]), name=\'W2\'),\n    \'w3\': tf.Variable(tf.random_normal([n_hidden_2, n_classes]), name=\'W3\')\n}\nbiases = {\n    \'b1\': tf.Variable(tf.random_normal([n_hidden_1]), name=\'b1\'),\n    \'b2\': tf.Variable(tf.random_normal([n_hidden_2]), name=\'b2\'),\n    \'b3\': tf.Variable(tf.random_normal([n_classes]), name=\'b3\')\n}\n\n# Encapsulating all ops into scopes, making Tensorboard\'s Graph\n# Visualization more convenient\nwith tf.name_scope(\'Model\'):\n    # Build model\n    pred = multilayer_perceptron(x, weights, biases)\n\nwith tf.name_scope(\'Loss\'):\n    # Softmax Cross entropy (cost function)\n    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n\nwith tf.name_scope(\'SGD\'):\n    # Gradient Descent\n    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n    # Op to calculate every variable gradient\n    grads = tf.gradients(loss, tf.trainable_variables())\n    grads = list(zip(grads, tf.trainable_variables()))\n    # Op to update all variables according to their gradient\n    apply_grads = optimizer.apply_gradients(grads_and_vars=grads)\n\nwith tf.name_scope(\'Accuracy\'):\n    # Accuracy\n    acc = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n    acc = tf.reduce_mean(tf.cast(acc, tf.float32))\n\n# Initialize the variables (i.e. assign their default value)\ninit = tf.global_variables_initializer()\n\n# Create a summary to monitor cost tensor\ntf.summary.scalar(""loss"", loss)\n# Create a summary to monitor accuracy tensor\ntf.summary.scalar(""accuracy"", acc)\n# Create summaries to visualize weights\nfor var in tf.trainable_variables():\n    tf.summary.histogram(var.name, var)\n# Summarize all gradients\nfor grad, var in grads:\n    tf.summary.histogram(var.name + \'/gradient\', grad)\n# Merge all summaries into a single op\nmerged_summary_op = tf.summary.merge_all()\n\n# Start training\nwith tf.Session() as sess:\n\n    # Run the initializer\n    sess.run(init)\n\n    # op to write logs to Tensorboard\n    summary_writer = tf.summary.FileWriter(logs_path,\n                                            graph=tf.get_default_graph())\n\n    # Training cycle\n    for epoch in range(training_epochs):\n        avg_cost = 0.\n        total_batch = int(mnist.train.num_examples/batch_size)\n        # Loop over all batches\n        for i in range(total_batch):\n            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n            # Run optimization op (backprop), cost op (to get loss value)\n            # and summary nodes\n            _, c, summary = sess.run([apply_grads, loss, merged_summary_op],\n                                     feed_dict={x: batch_xs, y: batch_ys})\n            # Write logs at every iteration\n            summary_writer.add_summary(summary, epoch * total_batch + i)\n            # Compute average loss\n            avg_cost += c / total_batch\n        # Display logs per epoch step\n        if (epoch+1) % display_step == 0:\n            print(""Epoch:"", \'%04d\' % (epoch+1), ""cost="", ""{:.9f}"".format(avg_cost))\n\n    print(""Optimization Finished!"")\n\n    # Test model\n    # Calculate accuracy\n    print(""Accuracy:"", acc.eval({x: mnist.test.images, y: mnist.test.labels}))\n\n    print(""Run the command line:\\n"" \\\n          ""--> tensorboard --logdir=/tmp/tensorflow_logs "" \\\n          ""\\nThen open http://0.0.0.0:6006/ into your web browser"")\n'"
examples/4_Utils/tensorboard_basic.py,19,"b'\'\'\'\nGraph and Loss visualization using Tensorboard.\nThis example is using the MNIST database of handwritten digits\n(http://yann.lecun.com/exdb/mnist/)\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n\'\'\'\n\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\n# Import MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""/tmp/data/"", one_hot=True)\n\n# Parameters\nlearning_rate = 0.01\ntraining_epochs = 25\nbatch_size = 100\ndisplay_epoch = 1\nlogs_path = \'/tmp/tensorflow_logs/example/\'\n\n# tf Graph Input\n# mnist data image of shape 28*28=784\nx = tf.placeholder(tf.float32, [None, 784], name=\'InputData\')\n# 0-9 digits recognition => 10 classes\ny = tf.placeholder(tf.float32, [None, 10], name=\'LabelData\')\n\n# Set model weights\nW = tf.Variable(tf.zeros([784, 10]), name=\'Weights\')\nb = tf.Variable(tf.zeros([10]), name=\'Bias\')\n\n# Construct model and encapsulating all ops into scopes, making\n# Tensorboard\'s Graph visualization more convenient\nwith tf.name_scope(\'Model\'):\n    # Model\n    pred = tf.nn.softmax(tf.matmul(x, W) + b) # Softmax\nwith tf.name_scope(\'Loss\'):\n    # Minimize error using cross entropy\n    cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred), reduction_indices=1))\nwith tf.name_scope(\'SGD\'):\n    # Gradient Descent\n    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\nwith tf.name_scope(\'Accuracy\'):\n    # Accuracy\n    acc = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n    acc = tf.reduce_mean(tf.cast(acc, tf.float32))\n\n# Initialize the variables (i.e. assign their default value)\ninit = tf.global_variables_initializer()\n\n# Create a summary to monitor cost tensor\ntf.summary.scalar(""loss"", cost)\n# Create a summary to monitor accuracy tensor\ntf.summary.scalar(""accuracy"", acc)\n# Merge all summaries into a single op\nmerged_summary_op = tf.summary.merge_all()\n\n# Start training\nwith tf.Session() as sess:\n\n    # Run the initializer\n    sess.run(init)\n\n    # op to write logs to Tensorboard\n    summary_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n\n    # Training cycle\n    for epoch in range(training_epochs):\n        avg_cost = 0.\n        total_batch = int(mnist.train.num_examples/batch_size)\n        # Loop over all batches\n        for i in range(total_batch):\n            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n            # Run optimization op (backprop), cost op (to get loss value)\n            # and summary nodes\n            _, c, summary = sess.run([optimizer, cost, merged_summary_op],\n                                     feed_dict={x: batch_xs, y: batch_ys})\n            # Write logs at every iteration\n            summary_writer.add_summary(summary, epoch * total_batch + i)\n            # Compute average loss\n            avg_cost += c / total_batch\n        # Display logs per epoch step\n        if (epoch+1) % display_epoch == 0:\n            print(""Epoch:"", \'%04d\' % (epoch+1), ""cost="", ""{:.9f}"".format(avg_cost))\n\n    print(""Optimization Finished!"")\n\n    # Test model\n    # Calculate accuracy\n    print(""Accuracy:"", acc.eval({x: mnist.test.images, y: mnist.test.labels}))\n\n    print(""Run the command line:\\n"" \\\n          ""--> tensorboard --logdir=/tmp/tensorflow_logs "" \\\n          ""\\nThen open http://0.0.0.0:6006/ into your web browser"")\n'"
examples/5_DataManagement/build_an_image_dataset.py,25,"b'"""""" Build an Image Dataset in TensorFlow.\n\nFor this example, you need to make your own set of images (JPEG).\nWe will show 2 different ways to build that dataset:\n\n- From a root folder, that will have a sub-folder containing images for each class\n    ```\n    ROOT_FOLDER\n       |-------- SUBFOLDER (CLASS 0)\n       |             |\n       |             | ----- image1.jpg\n       |             | ----- image2.jpg\n       |             | ----- etc...\n       |             \n       |-------- SUBFOLDER (CLASS 1)\n       |             |\n       |             | ----- image1.jpg\n       |             | ----- image2.jpg\n       |             | ----- etc...\n    ```\n\n- From a plain text file, that will list all images with their class ID:\n    ```\n    /path/to/image/1.jpg CLASS_ID\n    /path/to/image/2.jpg CLASS_ID\n    /path/to/image/3.jpg CLASS_ID\n    /path/to/image/4.jpg CLASS_ID\n    etc...\n    ```\n\nBelow, there are some parameters that you need to change (Marked \'CHANGE HERE\'), \nsuch as the dataset path.\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n""""""\nfrom __future__ import print_function\n\nimport tensorflow as tf\nimport os\n\n# Dataset Parameters - CHANGE HERE\nMODE = \'folder\' # or \'file\', if you choose a plain text file (see above).\nDATASET_PATH = \'/path/to/dataset/\' # the dataset file or root folder path.\n\n# Image Parameters\nN_CLASSES = 2 # CHANGE HERE, total number of classes\nIMG_HEIGHT = 64 # CHANGE HERE, the image height to be resized to\nIMG_WIDTH = 64 # CHANGE HERE, the image width to be resized to\nCHANNELS = 3 # The 3 color channels, change to 1 if grayscale\n\n\n# Reading the dataset\n# 2 modes: \'file\' or \'folder\'\ndef read_images(dataset_path, mode, batch_size):\n    imagepaths, labels = list(), list()\n    if mode == \'file\':\n        # Read dataset file\n        with open(dataset_path) as f:\n            data = f.read().splitlines()\n        for d in data:\n            imagepaths.append(d.split(\' \')[0])\n            labels.append(int(d.split(\' \')[1]))\n    elif mode == \'folder\':\n        # An ID will be affected to each sub-folders by alphabetical order\n        label = 0\n        # List the directory\n        try:  # Python 2\n            classes = sorted(os.walk(dataset_path).next()[1])\n        except Exception:  # Python 3\n            classes = sorted(os.walk(dataset_path).__next__()[1])\n        # List each sub-directory (the classes)\n        for c in classes:\n            c_dir = os.path.join(dataset_path, c)\n            try:  # Python 2\n                walk = os.walk(c_dir).next()\n            except Exception:  # Python 3\n                walk = os.walk(c_dir).__next__()\n            # Add each image to the training set\n            for sample in walk[2]:\n                # Only keeps jpeg images\n                if sample.endswith(\'.jpg\') or sample.endswith(\'.jpeg\'):\n                    imagepaths.append(os.path.join(c_dir, sample))\n                    labels.append(label)\n            label += 1\n    else:\n        raise Exception(""Unknown mode."")\n\n    # Convert to Tensor\n    imagepaths = tf.convert_to_tensor(imagepaths, dtype=tf.string)\n    labels = tf.convert_to_tensor(labels, dtype=tf.int32)\n    # Build a TF Queue, shuffle data\n    image, label = tf.train.slice_input_producer([imagepaths, labels],\n                                                 shuffle=True)\n\n    # Read images from disk\n    image = tf.read_file(image)\n    image = tf.image.decode_jpeg(image, channels=CHANNELS)\n\n    # Resize images to a common size\n    image = tf.image.resize_images(image, [IMG_HEIGHT, IMG_WIDTH])\n\n    # Normalize\n    image = image * 1.0/127.5 - 1.0\n\n    # Create batches\n    X, Y = tf.train.batch([image, label], batch_size=batch_size,\n                          capacity=batch_size * 8,\n                          num_threads=4)\n\n    return X, Y\n\n# -----------------------------------------------\n# THIS IS A CLASSIC CNN (see examples, section 3)\n# -----------------------------------------------\n# Note that a few elements have changed (usage of queues).\n\n# Parameters\nlearning_rate = 0.001\nnum_steps = 10000\nbatch_size = 128\ndisplay_step = 100\n\n# Network Parameters\ndropout = 0.75 # Dropout, probability to keep units\n\n# Build the data input\nX, Y = read_images(DATASET_PATH, MODE, batch_size)\n\n\n# Create model\ndef conv_net(x, n_classes, dropout, reuse, is_training):\n    # Define a scope for reusing the variables\n    with tf.variable_scope(\'ConvNet\', reuse=reuse):\n\n        # Convolution Layer with 32 filters and a kernel size of 5\n        conv1 = tf.layers.conv2d(x, 32, 5, activation=tf.nn.relu)\n        # Max Pooling (down-sampling) with strides of 2 and kernel size of 2\n        conv1 = tf.layers.max_pooling2d(conv1, 2, 2)\n\n        # Convolution Layer with 32 filters and a kernel size of 5\n        conv2 = tf.layers.conv2d(conv1, 64, 3, activation=tf.nn.relu)\n        # Max Pooling (down-sampling) with strides of 2 and kernel size of 2\n        conv2 = tf.layers.max_pooling2d(conv2, 2, 2)\n\n        # Flatten the data to a 1-D vector for the fully connected layer\n        fc1 = tf.contrib.layers.flatten(conv2)\n\n        # Fully connected layer (in contrib folder for now)\n        fc1 = tf.layers.dense(fc1, 1024)\n        # Apply Dropout (if is_training is False, dropout is not applied)\n        fc1 = tf.layers.dropout(fc1, rate=dropout, training=is_training)\n\n        # Output layer, class prediction\n        out = tf.layers.dense(fc1, n_classes)\n        # Because \'softmax_cross_entropy_with_logits\' already apply softmax,\n        # we only apply softmax to testing network\n        out = tf.nn.softmax(out) if not is_training else out\n\n    return out\n\n\n# Because Dropout have different behavior at training and prediction time, we\n# need to create 2 distinct computation graphs that share the same weights.\n\n# Create a graph for training\nlogits_train = conv_net(X, N_CLASSES, dropout, reuse=False, is_training=True)\n# Create another graph for testing that reuse the same weights\nlogits_test = conv_net(X, N_CLASSES, dropout, reuse=True, is_training=False)\n\n# Define loss and optimizer (with train logits, for dropout to take effect)\nloss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n    logits=logits_train, labels=Y))\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\ntrain_op = optimizer.minimize(loss_op)\n\n# Evaluate model (with test logits, for dropout to be disabled)\ncorrect_pred = tf.equal(tf.argmax(logits_test, 1), tf.cast(Y, tf.int64))\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\n# Initialize the variables (i.e. assign their default value)\ninit = tf.global_variables_initializer()\n\n# Saver object\nsaver = tf.train.Saver()\n\n# Start training\nwith tf.Session() as sess:\n\n    # Run the initializer\n    sess.run(init)\n\n    # Start the data queue\n    tf.train.start_queue_runners()\n\n    # Training cycle\n    for step in range(1, num_steps+1):\n\n        if step % display_step == 0:\n            # Run optimization and calculate batch loss and accuracy\n            _, loss, acc = sess.run([train_op, loss_op, accuracy])\n            print(""Step "" + str(step) + "", Minibatch Loss= "" + \\\n                  ""{:.4f}"".format(loss) + "", Training Accuracy= "" + \\\n                  ""{:.3f}"".format(acc))\n        else:\n            # Only run the optimization op (backprop)\n            sess.run(train_op)\n\n    print(""Optimization Finished!"")\n\n    # Save your model\n    saver.save(sess, \'my_tf_model\')\n'"
examples/5_DataManagement/tensorflow_dataset_api.py,18,"b'"""""" TensorFlow Dataset API.\n\nIn this example, we will show how to load numpy array data into the new \nTensorFlow \'Dataset\' API. The Dataset API implements an optimized data pipeline\nwith queues, that make data processing and training faster (especially on GPU).\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n""""""\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\n# Import MNIST data (Numpy format)\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""/tmp/data/"", one_hot=True)\n\n# Parameters\nlearning_rate = 0.001\nnum_steps = 2000\nbatch_size = 128\ndisplay_step = 100\n\n# Network Parameters\nn_input = 784 # MNIST data input (img shape: 28*28)\nn_classes = 10 # MNIST total classes (0-9 digits)\ndropout = 0.75 # Dropout, probability to keep units\n\nsess = tf.Session()\n\n# Create a dataset tensor from the images and the labels\ndataset = tf.data.Dataset.from_tensor_slices(\n    (mnist.train.images, mnist.train.labels))\n# Automatically refill the data queue when empty\ndataset = dataset.repeat()\n# Create batches of data\ndataset = dataset.batch(batch_size)\n# Prefetch data for faster consumption\ndataset = dataset.prefetch(batch_size)\n\n# Create an iterator over the dataset\niterator = dataset.make_initializable_iterator()\n# Initialize the iterator\nsess.run(iterator.initializer)\n\n# Neural Net Input (images, labels)\nX, Y = iterator.get_next()\n\n\n# -----------------------------------------------\n# THIS IS A CLASSIC CNN (see examples, section 3)\n# -----------------------------------------------\n# Note that a few elements have changed (usage of sess run).\n\n# Create model\ndef conv_net(x, n_classes, dropout, reuse, is_training):\n    # Define a scope for reusing the variables\n    with tf.variable_scope(\'ConvNet\', reuse=reuse):\n        # MNIST data input is a 1-D vector of 784 features (28*28 pixels)\n        # Reshape to match picture format [Height x Width x Channel]\n        # Tensor input become 4-D: [Batch Size, Height, Width, Channel]\n        x = tf.reshape(x, shape=[-1, 28, 28, 1])\n\n        # Convolution Layer with 32 filters and a kernel size of 5\n        conv1 = tf.layers.conv2d(x, 32, 5, activation=tf.nn.relu)\n        # Max Pooling (down-sampling) with strides of 2 and kernel size of 2\n        conv1 = tf.layers.max_pooling2d(conv1, 2, 2)\n\n        # Convolution Layer with 32 filters and a kernel size of 5\n        conv2 = tf.layers.conv2d(conv1, 64, 3, activation=tf.nn.relu)\n        # Max Pooling (down-sampling) with strides of 2 and kernel size of 2\n        conv2 = tf.layers.max_pooling2d(conv2, 2, 2)\n\n        # Flatten the data to a 1-D vector for the fully connected layer\n        fc1 = tf.contrib.layers.flatten(conv2)\n\n        # Fully connected layer (in contrib folder for now)\n        fc1 = tf.layers.dense(fc1, 1024)\n        # Apply Dropout (if is_training is False, dropout is not applied)\n        fc1 = tf.layers.dropout(fc1, rate=dropout, training=is_training)\n\n        # Output layer, class prediction\n        out = tf.layers.dense(fc1, n_classes)\n        # Because \'softmax_cross_entropy_with_logits\' already apply softmax,\n        # we only apply softmax to testing network\n        out = tf.nn.softmax(out) if not is_training else out\n\n    return out\n\n\n# Because Dropout have different behavior at training and prediction time, we\n# need to create 2 distinct computation graphs that share the same weights.\n\n# Create a graph for training\nlogits_train = conv_net(X, n_classes, dropout, reuse=False, is_training=True)\n# Create another graph for testing that reuse the same weights, but has\n# different behavior for \'dropout\' (not applied).\nlogits_test = conv_net(X, n_classes, dropout, reuse=True, is_training=False)\n\n# Define loss and optimizer (with train logits, for dropout to take effect)\nloss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n    logits=logits_train, labels=Y))\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\ntrain_op = optimizer.minimize(loss_op)\n\n# Evaluate model (with test logits, for dropout to be disabled)\ncorrect_pred = tf.equal(tf.argmax(logits_test, 1), tf.argmax(Y, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\n# Initialize the variables (i.e. assign their default value)\ninit = tf.global_variables_initializer()\n\n# Run the initializer\nsess.run(init)\n\n# Training cycle\nfor step in range(1, num_steps + 1):\n\n    # Run optimization\n    sess.run(train_op)\n\n    if step % display_step == 0 or step == 1:\n        # Calculate batch loss and accuracy\n        # (note that this consume a new batch of data)\n        loss, acc = sess.run([loss_op, accuracy])\n        print(""Step "" + str(step) + "", Minibatch Loss= "" + \\\n              ""{:.4f}"".format(loss) + "", Training Accuracy= "" + \\\n              ""{:.3f}"".format(acc))\n\nprint(""Optimization Finished!"")\n'"
examples/6_MultiGPU/multigpu_basics.py,14,"b'from __future__ import print_function\n\'\'\'\nBasic Multi GPU computation example using TensorFlow library.\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n\'\'\'\n\n\'\'\'\nThis tutorial requires your machine to have 2 GPUs\n""/cpu:0"": The CPU of your machine.\n""/gpu:0"": The first GPU of your machine\n""/gpu:1"": The second GPU of your machine\n\'\'\'\n\n\n\nimport numpy as np\nimport tensorflow as tf\nimport datetime\n\n# Processing Units logs\nlog_device_placement = True\n\n# Num of multiplications to perform\nn = 10\n\n\'\'\'\nExample: compute A^n + B^n on 2 GPUs\nResults on 8 cores with 2 GTX-980:\n * Single GPU computation time: 0:00:11.277449\n * Multi GPU computation time: 0:00:07.131701\n\'\'\'\n# Create random large matrix\nA = np.random.rand(10000, 10000).astype(\'float32\')\nB = np.random.rand(10000, 10000).astype(\'float32\')\n\n# Create a graph to store results\nc1 = []\nc2 = []\n\ndef matpow(M, n):\n    if n < 1: #Abstract cases where n < 1\n        return M\n    else:\n        return tf.matmul(M, matpow(M, n-1))\n\n\'\'\'\nSingle GPU computing\n\'\'\'\nwith tf.device(\'/gpu:0\'):\n    a = tf.placeholder(tf.float32, [10000, 10000])\n    b = tf.placeholder(tf.float32, [10000, 10000])\n    # Compute A^n and B^n and store results in c1\n    c1.append(matpow(a, n))\n    c1.append(matpow(b, n))\n\nwith tf.device(\'/cpu:0\'):\n  sum = tf.add_n(c1) #Addition of all elements in c1, i.e. A^n + B^n\n\nt1_1 = datetime.datetime.now()\nwith tf.Session(config=tf.ConfigProto(log_device_placement=log_device_placement)) as sess:\n    # Run the op.\n    sess.run(sum, {a:A, b:B})\nt2_1 = datetime.datetime.now()\n\n\n\'\'\'\nMulti GPU computing\n\'\'\'\n# GPU:0 computes A^n\nwith tf.device(\'/gpu:0\'):\n    # Compute A^n and store result in c2\n    a = tf.placeholder(tf.float32, [10000, 10000])\n    c2.append(matpow(a, n))\n\n# GPU:1 computes B^n\nwith tf.device(\'/gpu:1\'):\n    # Compute B^n and store result in c2\n    b = tf.placeholder(tf.float32, [10000, 10000])\n    c2.append(matpow(b, n))\n\nwith tf.device(\'/cpu:0\'):\n  sum = tf.add_n(c2) #Addition of all elements in c2, i.e. A^n + B^n\n\nt1_2 = datetime.datetime.now()\nwith tf.Session(config=tf.ConfigProto(log_device_placement=log_device_placement)) as sess:\n    # Run the op.\n    sess.run(sum, {a:A, b:B})\nt2_2 = datetime.datetime.now()\n\n\nprint(""Single GPU computation time: "" + str(t2_1-t1_1))\nprint(""Multi GPU computation time: "" + str(t2_2-t1_2))\n'"
examples/6_MultiGPU/multigpu_cnn.py,28,"b'\'\'\' Multi-GPU Training Example.\n\nTrain a convolutional neural network on multiple GPU with TensorFlow.\n\nThis example is using TensorFlow layers, see \'convolutional_network_raw\' example\nfor a raw TensorFlow implementation with variables.\n\nThis example is using the MNIST database of handwritten digits\n(http://yann.lecun.com/exdb/mnist/)\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n\'\'\'\n\nfrom __future__ import division, print_function, absolute_import\n\nimport numpy as np\nimport tensorflow as tf\nimport time\n\n# Import MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""/tmp/data/"", one_hot=True)\n\n# Training Parameters\nnum_gpus = 2\nnum_steps = 200\nlearning_rate = 0.001\nbatch_size = 1024\ndisplay_step = 10\n\n# Network Parameters\nnum_input = 784 # MNIST data input (img shape: 28*28)\nnum_classes = 10 # MNIST total classes (0-9 digits)\ndropout = 0.75 # Dropout, probability to keep units\n\n\n# Build a convolutional neural network\ndef conv_net(x, n_classes, dropout, reuse, is_training):\n    # Define a scope for reusing the variables\n    with tf.variable_scope(\'ConvNet\', reuse=reuse):\n        # MNIST data input is a 1-D vector of 784 features (28*28 pixels)\n        # Reshape to match picture format [Height x Width x Channel]\n        # Tensor input become 4-D: [Batch Size, Height, Width, Channel]\n        x = tf.reshape(x, shape=[-1, 28, 28, 1])\n\n        # Convolution Layer with 64 filters and a kernel size of 5\n        x = tf.layers.conv2d(x, 64, 5, activation=tf.nn.relu)\n        # Max Pooling (down-sampling) with strides of 2 and kernel size of 2\n        x = tf.layers.max_pooling2d(x, 2, 2)\n\n        # Convolution Layer with 256 filters and a kernel size of 5\n        x = tf.layers.conv2d(x, 256, 3, activation=tf.nn.relu)\n        # Convolution Layer with 512 filters and a kernel size of 5\n        x = tf.layers.conv2d(x, 512, 3, activation=tf.nn.relu)\n        # Max Pooling (down-sampling) with strides of 2 and kernel size of 2\n        x = tf.layers.max_pooling2d(x, 2, 2)\n\n        # Flatten the data to a 1-D vector for the fully connected layer\n        x = tf.contrib.layers.flatten(x)\n\n        # Fully connected layer (in contrib folder for now)\n        x = tf.layers.dense(x, 2048)\n        # Apply Dropout (if is_training is False, dropout is not applied)\n        x = tf.layers.dropout(x, rate=dropout, training=is_training)\n\n        # Fully connected layer (in contrib folder for now)\n        x = tf.layers.dense(x, 1024)\n        # Apply Dropout (if is_training is False, dropout is not applied)\n        x = tf.layers.dropout(x, rate=dropout, training=is_training)\n\n        # Output layer, class prediction\n        out = tf.layers.dense(x, n_classes)\n        # Because \'softmax_cross_entropy_with_logits\' loss already apply\n        # softmax, we only apply softmax to testing network\n        out = tf.nn.softmax(out) if not is_training else out\n\n    return out\n\n\ndef average_gradients(tower_grads):\n    average_grads = []\n    for grad_and_vars in zip(*tower_grads):\n        # Note that each grad_and_vars looks like the following:\n        #   ((grad0_gpu0, var0_gpu0), ... , (grad0_gpuN, var0_gpuN))\n        grads = []\n        for g, _ in grad_and_vars:\n            # Add 0 dimension to the gradients to represent the tower.\n            expanded_g = tf.expand_dims(g, 0)\n\n            # Append on a \'tower\' dimension which we will average over below.\n            grads.append(expanded_g)\n\n        # Average over the \'tower\' dimension.\n        grad = tf.concat(grads, 0)\n        grad = tf.reduce_mean(grad, 0)\n\n        # Keep in mind that the Variables are redundant because they are shared\n        # across towers. So .. we will just return the first tower\'s pointer to\n        # the Variable.\n        v = grad_and_vars[0][1]\n        grad_and_var = (grad, v)\n        average_grads.append(grad_and_var)\n    return average_grads\n\n\n# By default, all variables will be placed on \'/gpu:0\'\n# So we need a custom device function, to assign all variables to \'/cpu:0\'\n# Note: If GPUs are peered, \'/gpu:0\' can be a faster option\nPS_OPS = [\'Variable\', \'VariableV2\', \'AutoReloadVariable\']\n\ndef assign_to_device(device, ps_device=\'/cpu:0\'):\n    def _assign(op):\n        node_def = op if isinstance(op, tf.NodeDef) else op.node_def\n        if node_def.op in PS_OPS:\n            return ""/"" + ps_device\n        else:\n            return device\n\n    return _assign\n\n\n# Place all ops on CPU by default\nwith tf.device(\'/cpu:0\'):\n    tower_grads = []\n    reuse_vars = False\n\n    # tf Graph input\n    X = tf.placeholder(tf.float32, [None, num_input])\n    Y = tf.placeholder(tf.float32, [None, num_classes])\n\n    # Loop over all GPUs and construct their own computation graph\n    for i in range(num_gpus):\n        with tf.device(assign_to_device(\'/gpu:{}\'.format(i), ps_device=\'/cpu:0\')):\n\n            # Split data between GPUs\n            _x = X[i * batch_size: (i+1) * batch_size]\n            _y = Y[i * batch_size: (i+1) * batch_size]\n\n            # Because Dropout have different behavior at training and prediction time, we\n            # need to create 2 distinct computation graphs that share the same weights.\n\n            # Create a graph for training\n            logits_train = conv_net(_x, num_classes, dropout,\n                                    reuse=reuse_vars, is_training=True)\n            # Create another graph for testing that reuse the same weights\n            logits_test = conv_net(_x, num_classes, dropout,\n                                   reuse=True, is_training=False)\n\n            # Define loss and optimizer (with train logits, for dropout to take effect)\n            loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n                logits=logits_train, labels=_y))\n            optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n            grads = optimizer.compute_gradients(loss_op)\n\n            # Only first GPU compute accuracy\n            if i == 0:\n                # Evaluate model (with test logits, for dropout to be disabled)\n                correct_pred = tf.equal(tf.argmax(logits_test, 1), tf.argmax(_y, 1))\n                accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\n            reuse_vars = True\n            tower_grads.append(grads)\n\n    tower_grads = average_gradients(tower_grads)\n    train_op = optimizer.apply_gradients(tower_grads)\n\n    # Initialize the variables (i.e. assign their default value)\n    init = tf.global_variables_initializer()\n\n    # Start Training\n    with tf.Session() as sess:\n\n        # Run the initializer\n        sess.run(init)\n\n        # Keep training until reach max iterations\n        for step in range(1, num_steps + 1):\n            # Get a batch for each GPU\n            batch_x, batch_y = mnist.train.next_batch(batch_size * num_gpus)\n            # Run optimization op (backprop)\n            ts = time.time()\n            sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n            te = time.time() - ts\n            if step % display_step == 0 or step == 1:\n                # Calculate batch loss and accuracy\n                loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n                                                                     Y: batch_y})\n                print(""Step "" + str(step) + "": Minibatch Loss= "" + \\\n                      ""{:.4f}"".format(loss) + "", Training Accuracy= "" + \\\n                      ""{:.3f}"".format(acc) + "", %i Examples/sec"" % int(len(batch_x)/te))\n            step += 1\n        print(""Optimization Finished!"")\n\n        # Calculate accuracy for MNIST test images\n        print(""Testing Accuracy:"", \\\n            np.mean([sess.run(accuracy, feed_dict={X: mnist.test.images[i:i+batch_size],\n            Y: mnist.test.labels[i:i+batch_size]}) for i in range(0, len(mnist.test.images), batch_size)]))\n'"
tensorflow_v1/examples/1_Introduction/basic_eager_api.py,9,"b'\'\'\'\nBasic introduction to TensorFlow\'s Eager API.\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n\nWhat is Eager API?\n"" Eager execution is an imperative, define-by-run interface where operations are\nexecuted immediately as they are called from Python. This makes it easier to\nget started with TensorFlow, and can make research and development more\nintuitive. A vast majority of the TensorFlow API remains the same whether eager\nexecution is enabled or not. As a result, the exact same code that constructs\nTensorFlow graphs (e.g. using the layers API) can be executed imperatively\nby using eager execution. Conversely, most models written with Eager enabled\ncan be converted to a graph that can be further optimized and/or extracted\nfor deployment in production without changing code. "" - Rajat Monga\n\n\'\'\'\nfrom __future__ import absolute_import, division, print_function\n\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow.contrib.eager as tfe\n\n# Set Eager API\nprint(""Setting Eager mode..."")\ntfe.enable_eager_execution()\n\n# Define constant tensors\nprint(""Define constant tensors"")\na = tf.constant(2)\nprint(""a = %i"" % a)\nb = tf.constant(3)\nprint(""b = %i"" % b)\n\n# Run the operation without the need for tf.Session\nprint(""Running operations, without tf.Session"")\nc = a + b\nprint(""a + b = %i"" % c)\nd = a * b\nprint(""a * b = %i"" % d)\n\n\n# Full compatibility with Numpy\nprint(""Mixing operations with Tensors and Numpy Arrays"")\n\n# Define constant tensors\na = tf.constant([[2., 1.],\n                 [1., 0.]], dtype=tf.float32)\nprint(""Tensor:\\n a = %s"" % a)\nb = np.array([[3., 0.],\n              [5., 1.]], dtype=np.float32)\nprint(""NumpyArray:\\n b = %s"" % b)\n\n# Run the operation without the need for tf.Session\nprint(""Running operations, without tf.Session"")\n\nc = a + b\nprint(""a + b = %s"" % c)\n\nd = tf.matmul(a, b)\nprint(""a * b = %s"" % d)\n\nprint(""Iterate through Tensor \'a\':"")\nfor i in range(a.shape[0]):\n    for j in range(a.shape[1]):\n        print(a[i][j])\n\n'"
tensorflow_v1/examples/1_Introduction/basic_operations.py,12,"b'\'\'\'\nBasic Operations example using TensorFlow library.\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n\'\'\'\n\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\n# Basic constant operations\n# The value returned by the constructor represents the output\n# of the Constant op.\na = tf.constant(2)\nb = tf.constant(3)\n\n# Launch the default graph.\nwith tf.Session() as sess:\n    print(""a=2, b=3"")\n    print(""Addition with constants: %i"" % sess.run(a+b))\n    print(""Multiplication with constants: %i"" % sess.run(a*b))\n\n# Basic Operations with variable as graph input\n# The value returned by the constructor represents the output\n# of the Variable op. (define as input when running session)\n# tf Graph input\na = tf.placeholder(tf.int16)\nb = tf.placeholder(tf.int16)\n\n# Define some operations\nadd = tf.add(a, b)\nmul = tf.multiply(a, b)\n\n# Launch the default graph.\nwith tf.Session() as sess:\n    # Run every operation with variable input\n    print(""Addition with variables: %i"" % sess.run(add, feed_dict={a: 2, b: 3}))\n    print(""Multiplication with variables: %i"" % sess.run(mul, feed_dict={a: 2, b: 3}))\n\n\n# ----------------\n# More in details:\n# Matrix Multiplication from TensorFlow official tutorial\n\n# Create a Constant op that produces a 1x2 matrix.  The op is\n# added as a node to the default graph.\n#\n# The value returned by the constructor represents the output\n# of the Constant op.\nmatrix1 = tf.constant([[3., 3.]])\n\n# Create another Constant that produces a 2x1 matrix.\nmatrix2 = tf.constant([[2.],[2.]])\n\n# Create a Matmul op that takes \'matrix1\' and \'matrix2\' as inputs.\n# The returned value, \'product\', represents the result of the matrix\n# multiplication.\nproduct = tf.matmul(matrix1, matrix2)\n\n# To run the matmul op we call the session \'run()\' method, passing \'product\'\n# which represents the output of the matmul op.  This indicates to the call\n# that we want to get the output of the matmul op back.\n#\n# All inputs needed by the op are run automatically by the session.  They\n# typically are run in parallel.\n#\n# The call \'run(product)\' thus causes the execution of threes ops in the\n# graph: the two constants and matmul.\n#\n# The output of the op is returned in \'result\' as a numpy `ndarray` object.\nwith tf.Session() as sess:\n    result = sess.run(product)\n    print(result)\n    # ==> [[ 12.]]\n'"
tensorflow_v1/examples/1_Introduction/helloworld.py,2,"b""'''\nHelloWorld example using TensorFlow library.\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n'''\n\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\n# Simple hello world using TensorFlow\n\n# Create a Constant op\n# The op is added as a node to the default graph.\n#\n# The value returned by the constructor represents the output\n# of the Constant op.\nhello = tf.constant('Hello, TensorFlow!')\n\n# Start tf session\nsess = tf.Session()\n\n# Run the op\nprint(sess.run(hello))\n"""
tensorflow_v1/examples/2_BasicModels/gradient_boosted_decision_tree.py,5,"b'"""""" Gradient Boosted Decision Tree (GBDT).\n\nImplement a Gradient Boosted Decision tree with TensorFlow to classify\nhandwritten digit images. This example is using the MNIST database of\nhandwritten digits as training samples (http://yann.lecun.com/exdb/mnist/).\n\nLinks:\n    [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n""""""\n\nfrom __future__ import print_function\n\nimport tensorflow as tf\nfrom tensorflow.contrib.boosted_trees.estimator_batch.estimator import GradientBoostedDecisionTreeClassifier\nfrom tensorflow.contrib.boosted_trees.proto import learner_pb2 as gbdt_learner\n\n# Ignore all GPUs (current TF GBDT does not support GPU).\nimport os\nos.environ[""CUDA_VISIBLE_DEVICES""] = """"\n\n# Import MNIST data\n# Set verbosity to display errors only (Remove this line for showing warnings)\ntf.logging.set_verbosity(tf.logging.ERROR)\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""/tmp/data/"", one_hot=False,\n                                  source_url=\'http://yann.lecun.com/exdb/mnist/\')\n\n# Parameters\nbatch_size = 4096 # The number of samples per batch\nnum_classes = 10 # The 10 digits\nnum_features = 784 # Each image is 28x28 pixels\nmax_steps = 10000\n\n# GBDT Parameters\nlearning_rate = 0.1\nl1_regul = 0.\nl2_regul = 1.\nexamples_per_layer = 1000\nnum_trees = 10\nmax_depth = 16\n\n# Fill GBDT parameters into the config proto\nlearner_config = gbdt_learner.LearnerConfig()\nlearner_config.learning_rate_tuner.fixed.learning_rate = learning_rate\nlearner_config.regularization.l1 = l1_regul\nlearner_config.regularization.l2 = l2_regul / examples_per_layer\nlearner_config.constraints.max_tree_depth = max_depth\ngrowing_mode = gbdt_learner.LearnerConfig.LAYER_BY_LAYER\nlearner_config.growing_mode = growing_mode\nrun_config = tf.contrib.learn.RunConfig(save_checkpoints_secs=300)\nlearner_config.multi_class_strategy = (\n    gbdt_learner.LearnerConfig.DIAGONAL_HESSIAN)\\\n\n# Create a TensorFlor GBDT Estimator\ngbdt_model = GradientBoostedDecisionTreeClassifier(\n    model_dir=None, # No save directory specified\n    learner_config=learner_config,\n    n_classes=num_classes,\n    examples_per_layer=examples_per_layer,\n    num_trees=num_trees,\n    center_bias=False,\n    config=run_config)\n\n# Display TF info logs\ntf.logging.set_verbosity(tf.logging.INFO)\n\n# Define the input function for training\ninput_fn = tf.estimator.inputs.numpy_input_fn(\n    x={\'images\': mnist.train.images}, y=mnist.train.labels,\n    batch_size=batch_size, num_epochs=None, shuffle=True)\n# Train the Model\ngbdt_model.fit(input_fn=input_fn, max_steps=max_steps)\n\n# Evaluate the Model\n# Define the input function for evaluating\ninput_fn = tf.estimator.inputs.numpy_input_fn(\n    x={\'images\': mnist.test.images}, y=mnist.test.labels,\n    batch_size=batch_size, shuffle=False)\n# Use the Estimator \'evaluate\' method\ne = gbdt_model.evaluate(input_fn=input_fn)\n\nprint(""Testing Accuracy:"", e[\'accuracy\'])\n'"
tensorflow_v1/examples/2_BasicModels/kmeans.py,9,"b'"""""" K-Means.\n\nImplement K-Means algorithm with TensorFlow, and apply it to classify\nhandwritten digit images. This example is using the MNIST database of\nhandwritten digits as training samples (http://yann.lecun.com/exdb/mnist/).\n\nNote: This example requires TensorFlow v1.1.0 or over.\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n""""""\n\nfrom __future__ import print_function\n\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.contrib.factorization import KMeans\n\n# Ignore all GPUs, tf k-means does not benefit from it.\nimport os\nos.environ[""CUDA_VISIBLE_DEVICES""] = """"\n\n# Import MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""/tmp/data/"", one_hot=True)\nfull_data_x = mnist.train.images\n\n# Parameters\nnum_steps = 50 # Total steps to train\nbatch_size = 1024 # The number of samples per batch\nk = 25 # The number of clusters\nnum_classes = 10 # The 10 digits\nnum_features = 784 # Each image is 28x28 pixels\n\n# Input images\nX = tf.placeholder(tf.float32, shape=[None, num_features])\n# Labels (for assigning a label to a centroid and testing)\nY = tf.placeholder(tf.float32, shape=[None, num_classes])\n\n# K-Means Parameters\nkmeans = KMeans(inputs=X, num_clusters=k, distance_metric=\'cosine\',\n                use_mini_batch=True)\n\n# Build KMeans graph\ntraining_graph = kmeans.training_graph()\n\nif len(training_graph) > 6: # Tensorflow 1.4+\n    (all_scores, cluster_idx, scores, cluster_centers_initialized,\n     cluster_centers_var, init_op, train_op) = training_graph\nelse:\n    (all_scores, cluster_idx, scores, cluster_centers_initialized,\n     init_op, train_op) = training_graph\n\ncluster_idx = cluster_idx[0] # fix for cluster_idx being a tuple\navg_distance = tf.reduce_mean(scores)\n\n# Initialize the variables (i.e. assign their default value)\ninit_vars = tf.global_variables_initializer()\n\n# Start TensorFlow session\nsess = tf.Session()\n\n# Run the initializer\nsess.run(init_vars, feed_dict={X: full_data_x})\nsess.run(init_op, feed_dict={X: full_data_x})\n\n# Training\nfor i in range(1, num_steps + 1):\n    _, d, idx = sess.run([train_op, avg_distance, cluster_idx],\n                         feed_dict={X: full_data_x})\n    if i % 10 == 0 or i == 1:\n        print(""Step %i, Avg Distance: %f"" % (i, d))\n\n# Assign a label to each centroid\n# Count total number of labels per centroid, using the label of each training\n# sample to their closest centroid (given by \'idx\')\ncounts = np.zeros(shape=(k, num_classes))\nfor i in range(len(idx)):\n    counts[idx[i]] += mnist.train.labels[i]\n# Assign the most frequent label to the centroid\nlabels_map = [np.argmax(c) for c in counts]\nlabels_map = tf.convert_to_tensor(labels_map)\n\n# Evaluation ops\n# Lookup: centroid_id -> label\ncluster_label = tf.nn.embedding_lookup(labels_map, cluster_idx)\n# Compute accuracy\ncorrect_prediction = tf.equal(cluster_label, tf.cast(tf.argmax(Y, 1), tf.int32))\naccuracy_op = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\n# Test Model\ntest_x, test_y = mnist.test.images, mnist.test.labels\nprint(""Test Accuracy:"", sess.run(accuracy_op, feed_dict={X: test_x, Y: test_y}))\n'"
tensorflow_v1/examples/2_BasicModels/linear_regression.py,10,"b'\'\'\'\nA linear regression learning algorithm example using TensorFlow library.\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n\'\'\'\n\nfrom __future__ import print_function\n\nimport tensorflow as tf\nimport numpy\nimport matplotlib.pyplot as plt\nrng = numpy.random\n\n# Parameters\nlearning_rate = 0.01\ntraining_epochs = 1000\ndisplay_step = 50\n\n# Training Data\ntrain_X = numpy.asarray([3.3,4.4,5.5,6.71,6.93,4.168,9.779,6.182,7.59,2.167,\n                         7.042,10.791,5.313,7.997,5.654,9.27,3.1])\ntrain_Y = numpy.asarray([1.7,2.76,2.09,3.19,1.694,1.573,3.366,2.596,2.53,1.221,\n                         2.827,3.465,1.65,2.904,2.42,2.94,1.3])\nn_samples = train_X.shape[0]\n\n# tf Graph Input\nX = tf.placeholder(""float"")\nY = tf.placeholder(""float"")\n\n# Set model weights\nW = tf.Variable(rng.randn(), name=""weight"")\nb = tf.Variable(rng.randn(), name=""bias"")\n\n# Construct a linear model\npred = tf.add(tf.multiply(X, W), b)\n\n# Mean squared error\ncost = tf.reduce_sum(tf.pow(pred-Y, 2))/(2*n_samples)\n# Gradient descent\n#  Note, minimize() knows to modify W and b because Variable objects are trainable=True by default\noptimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n\n# Initialize the variables (i.e. assign their default value)\ninit = tf.global_variables_initializer()\n\n# Start training\nwith tf.Session() as sess:\n\n    # Run the initializer\n    sess.run(init)\n\n    # Fit all training data\n    for epoch in range(training_epochs):\n        for (x, y) in zip(train_X, train_Y):\n            sess.run(optimizer, feed_dict={X: x, Y: y})\n\n        # Display logs per epoch step\n        if (epoch+1) % display_step == 0:\n            c = sess.run(cost, feed_dict={X: train_X, Y:train_Y})\n            print(""Epoch:"", \'%04d\' % (epoch+1), ""cost="", ""{:.9f}"".format(c), \\\n                ""W="", sess.run(W), ""b="", sess.run(b))\n\n    print(""Optimization Finished!"")\n    training_cost = sess.run(cost, feed_dict={X: train_X, Y: train_Y})\n    print(""Training cost="", training_cost, ""W="", sess.run(W), ""b="", sess.run(b), \'\\n\')\n\n    # Graphic display\n    plt.plot(train_X, train_Y, \'ro\', label=\'Original data\')\n    plt.plot(train_X, sess.run(W) * train_X + sess.run(b), label=\'Fitted line\')\n    plt.legend()\n    plt.show()\n\n    # Testing example, as requested (Issue #2)\n    test_X = numpy.asarray([6.83, 4.668, 8.9, 7.91, 5.7, 8.7, 3.1, 2.1])\n    test_Y = numpy.asarray([1.84, 2.273, 3.2, 2.831, 2.92, 3.24, 1.35, 1.03])\n\n    print(""Testing... (Mean square loss Comparison)"")\n    testing_cost = sess.run(\n        tf.reduce_sum(tf.pow(pred - Y, 2)) / (2 * test_X.shape[0]),\n        feed_dict={X: test_X, Y: test_Y})  # same function as cost above\n    print(""Testing cost="", testing_cost)\n    print(""Absolute mean square loss difference:"", abs(\n        training_cost - testing_cost))\n\n    plt.plot(test_X, test_Y, \'bo\', label=\'Testing data\')\n    plt.plot(train_X, sess.run(W) * train_X + sess.run(b), label=\'Fitted line\')\n    plt.legend()\n    plt.show()\n'"
tensorflow_v1/examples/2_BasicModels/linear_regression_eager_api.py,4,"b'\'\'\' Linear Regression with Eager API.\n\nA linear regression learning algorithm example using TensorFlow\'s Eager API.\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n\'\'\'\nfrom __future__ import absolute_import, division, print_function\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\n\n# Set Eager API\ntf.enable_eager_execution()\ntfe = tf.contrib.eager\n\n# Training Data\ntrain_X = [3.3, 4.4, 5.5, 6.71, 6.93, 4.168, 9.779, 6.182, 7.59, 2.167,\n           7.042, 10.791, 5.313, 7.997, 5.654, 9.27, 3.1]\ntrain_Y = [1.7, 2.76, 2.09, 3.19, 1.694, 1.573, 3.366, 2.596, 2.53, 1.221,\n           2.827, 3.465, 1.65, 2.904, 2.42, 2.94, 1.3]\nn_samples = len(train_X)\n\n# Parameters\nlearning_rate = 0.01\ndisplay_step = 100\nnum_steps = 1000\n\n# Weight and Bias\nW = tfe.Variable(np.random.randn())\nb = tfe.Variable(np.random.randn())\n\n\n# Linear regression (Wx + b)\ndef linear_regression(inputs):\n    return inputs * W + b\n\n\n# Mean square error\ndef mean_square_fn(model_fn, inputs, labels):\n    return tf.reduce_sum(tf.pow(model_fn(inputs) - labels, 2)) / (2 * n_samples)\n\n\n# SGD Optimizer\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n# Compute gradients\ngrad = tfe.implicit_gradients(mean_square_fn)\n\n# Initial cost, before optimizing\nprint(""Initial cost= {:.9f}"".format(\n    mean_square_fn(linear_regression, train_X, train_Y)),\n    ""W="", W.numpy(), ""b="", b.numpy())\n\n# Training\nfor step in range(num_steps):\n\n    optimizer.apply_gradients(grad(linear_regression, train_X, train_Y))\n\n    if (step + 1) % display_step == 0 or step == 0:\n        print(""Epoch:"", \'%04d\' % (step + 1), ""cost="",\n              ""{:.9f}"".format(mean_square_fn(linear_regression, train_X, train_Y)),\n              ""W="", W.numpy(), ""b="", b.numpy())\n\n# Graphic display\nplt.plot(train_X, train_Y, \'ro\', label=\'Original data\')\nplt.plot(train_X, np.array(W * train_X + b), label=\'Fitted line\')\nplt.legend()\nplt.show()\n'"
tensorflow_v1/examples/2_BasicModels/logistic_regression.py,11,"b'\'\'\'\nA logistic regression learning algorithm example using TensorFlow library.\nThis example is using the MNIST database of handwritten digits\n(http://yann.lecun.com/exdb/mnist/)\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n\'\'\'\n\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\n# Import MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""/tmp/data/"", one_hot=True)\n\n# Parameters\nlearning_rate = 0.01\ntraining_epochs = 25\nbatch_size = 100\ndisplay_step = 1\n\n# tf Graph Input\nx = tf.placeholder(tf.float32, [None, 784]) # mnist data image of shape 28*28=784\ny = tf.placeholder(tf.float32, [None, 10]) # 0-9 digits recognition => 10 classes\n\n# Set model weights\nW = tf.Variable(tf.zeros([784, 10]))\nb = tf.Variable(tf.zeros([10]))\n\n# Construct model\npred = tf.nn.softmax(tf.matmul(x, W) + b) # Softmax\n\n# Minimize error using cross entropy\ncost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred), reduction_indices=1))\n# Gradient Descent\noptimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n\n# Initialize the variables (i.e. assign their default value)\ninit = tf.global_variables_initializer()\n\n# Start training\nwith tf.Session() as sess:\n\n    # Run the initializer\n    sess.run(init)\n\n    # Training cycle\n    for epoch in range(training_epochs):\n        avg_cost = 0.\n        total_batch = int(mnist.train.num_examples/batch_size)\n        # Loop over all batches\n        for i in range(total_batch):\n            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n            # Run optimization op (backprop) and cost op (to get loss value)\n            _, c = sess.run([optimizer, cost], feed_dict={x: batch_xs,\n                                                          y: batch_ys})\n            # Compute average loss\n            avg_cost += c / total_batch\n        # Display logs per epoch step\n        if (epoch+1) % display_step == 0:\n            print(""Epoch:"", \'%04d\' % (epoch+1), ""cost="", ""{:.9f}"".format(avg_cost))\n\n    print(""Optimization Finished!"")\n\n    # Test model\n    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n    # Calculate accuracy\n    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n    print(""Accuracy:"", accuracy.eval({x: mnist.test.images, y: mnist.test.labels}))\n'"
tensorflow_v1/examples/2_BasicModels/logistic_regression_eager_api.py,12,"b'\'\'\' Logistic Regression with Eager API.\n\nA logistic regression learning algorithm example using TensorFlow\'s Eager API.\nThis example is using the MNIST database of handwritten digits\n(http://yann.lecun.com/exdb/mnist/)\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n\'\'\'\nfrom __future__ import absolute_import, division, print_function\n\nimport tensorflow as tf\n\n# Set Eager API\ntf.enable_eager_execution()\ntfe = tf.contrib.eager\n\n# Import MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""/tmp/data/"", one_hot=False)\n\n# Parameters\nlearning_rate = 0.1\nbatch_size = 128\nnum_steps = 1000\ndisplay_step = 100\n\ndataset = tf.data.Dataset.from_tensor_slices(\n    (mnist.train.images, mnist.train.labels))\ndataset = dataset.repeat().batch(batch_size).prefetch(batch_size)\ndataset_iter = tfe.Iterator(dataset)\n\n# Variables\nW = tfe.Variable(tf.zeros([784, 10]), name=\'weights\')\nb = tfe.Variable(tf.zeros([10]), name=\'bias\')\n\n\n# Logistic regression (Wx + b)\ndef logistic_regression(inputs):\n    return tf.matmul(inputs, W) + b\n\n\n# Cross-Entropy loss function\ndef loss_fn(inference_fn, inputs, labels):\n    # Using sparse_softmax cross entropy\n    return tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n        logits=inference_fn(inputs), labels=labels))\n\n\n# Calculate accuracy\ndef accuracy_fn(inference_fn, inputs, labels):\n    prediction = tf.nn.softmax(inference_fn(inputs))\n    correct_pred = tf.equal(tf.argmax(prediction, 1), labels)\n    return tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\n\n# SGD Optimizer\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n# Compute gradients\ngrad = tfe.implicit_gradients(loss_fn)\n\n# Training\naverage_loss = 0.\naverage_acc = 0.\nfor step in range(num_steps):\n\n    # Iterate through the dataset\n    d = dataset_iter.next()\n\n    # Images\n    x_batch = d[0]\n    # Labels\n    y_batch = tf.cast(d[1], dtype=tf.int64)\n\n    # Compute the batch loss\n    batch_loss = loss_fn(logistic_regression, x_batch, y_batch)\n    average_loss += batch_loss\n    # Compute the batch accuracy\n    batch_accuracy = accuracy_fn(logistic_regression, x_batch, y_batch)\n    average_acc += batch_accuracy\n\n    if step == 0:\n        # Display the initial cost, before optimizing\n        print(""Initial loss= {:.9f}"".format(average_loss))\n\n    # Update the variables following gradients info\n    optimizer.apply_gradients(grad(logistic_regression, x_batch, y_batch))\n\n    # Display info\n    if (step + 1) % display_step == 0 or step == 0:\n        if step > 0:\n            average_loss /= display_step\n            average_acc /= display_step\n        print(""Step:"", \'%04d\' % (step + 1), "" loss="",\n              ""{:.9f}"".format(average_loss), "" accuracy="",\n              ""{:.4f}"".format(average_acc))\n        average_loss = 0.\n        average_acc = 0.\n\n# Evaluate model on the test image set\ntestX = mnist.test.images\ntestY = mnist.test.labels\n\ntest_acc = accuracy_fn(logistic_regression, testX, testY)\nprint(""Testset Accuracy: {:.4f}"".format(test_acc))\n'"
tensorflow_v1/examples/2_BasicModels/nearest_neighbor.py,6,"b'\'\'\'\nA nearest neighbor learning algorithm example using TensorFlow library.\nThis example is using the MNIST database of handwritten digits\n(http://yann.lecun.com/exdb/mnist/)\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n\'\'\'\n\nfrom __future__ import print_function\n\nimport numpy as np\nimport tensorflow as tf\n\n# Import MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""/tmp/data/"", one_hot=True)\n\n# In this example, we limit mnist data\nXtr, Ytr = mnist.train.next_batch(5000) #5000 for training (nn candidates)\nXte, Yte = mnist.test.next_batch(200) #200 for testing\n\n# tf Graph Input\nxtr = tf.placeholder(""float"", [None, 784])\nxte = tf.placeholder(""float"", [784])\n\n# Nearest Neighbor calculation using L1 Distance\n# Calculate L1 Distance\ndistance = tf.reduce_sum(tf.abs(tf.add(xtr, tf.negative(xte))), reduction_indices=1)\n# Prediction: Get min distance index (Nearest neighbor)\npred = tf.arg_min(distance, 0)\n\naccuracy = 0.\n\n# Initialize the variables (i.e. assign their default value)\ninit = tf.global_variables_initializer()\n\n# Start training\nwith tf.Session() as sess:\n\n    # Run the initializer\n    sess.run(init)\n\n    # loop over test data\n    for i in range(len(Xte)):\n        # Get nearest neighbor\n        nn_index = sess.run(pred, feed_dict={xtr: Xtr, xte: Xte[i, :]})\n        # Get nearest neighbor class label and compare it to its true label\n        print(""Test"", i, ""Prediction:"", np.argmax(Ytr[nn_index]), \\\n            ""True Class:"", np.argmax(Yte[i]))\n        # Calculate accuracy\n        if np.argmax(Ytr[nn_index]) == np.argmax(Yte[i]):\n            accuracy += 1./len(Xte)\n    print(""Done!"")\n    print(""Accuracy:"", accuracy)\n'"
tensorflow_v1/examples/2_BasicModels/random_forest.py,6,"b'"""""" Random Forest.\n\nImplement Random Forest algorithm with TensorFlow, and apply it to classify \nhandwritten digit images. This example is using the MNIST database of \nhandwritten digits as training samples (http://yann.lecun.com/exdb/mnist/).\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n""""""\n\nfrom __future__ import print_function\n\nimport tensorflow as tf\nfrom tensorflow.contrib.tensor_forest.python import tensor_forest\nfrom tensorflow.python.ops import resources\n\n# Ignore all GPUs, tf random forest does not benefit from it.\nimport os\nos.environ[""CUDA_VISIBLE_DEVICES""] = """"\n\n# Import MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""/tmp/data/"", one_hot=False)\n\n# Parameters\nnum_steps = 500 # Total steps to train\nbatch_size = 1024 # The number of samples per batch\nnum_classes = 10 # The 10 digits\nnum_features = 784 # Each image is 28x28 pixels\nnum_trees = 10\nmax_nodes = 1000\n\n# Input and Target data\nX = tf.placeholder(tf.float32, shape=[None, num_features])\n# For random forest, labels must be integers (the class id)\nY = tf.placeholder(tf.int32, shape=[None])\n\n# Random Forest Parameters\nhparams = tensor_forest.ForestHParams(num_classes=num_classes,\n                                      num_features=num_features,\n                                      num_trees=num_trees,\n                                      max_nodes=max_nodes).fill()\n\n# Build the Random Forest\nforest_graph = tensor_forest.RandomForestGraphs(hparams)\n# Get training graph and loss\ntrain_op = forest_graph.training_graph(X, Y)\nloss_op = forest_graph.training_loss(X, Y)\n\n# Measure the accuracy\ninfer_op, _, _ = forest_graph.inference_graph(X)\ncorrect_prediction = tf.equal(tf.argmax(infer_op, 1), tf.cast(Y, tf.int64))\naccuracy_op = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\n# Initialize the variables (i.e. assign their default value) and forest resources\ninit_vars = tf.group(tf.global_variables_initializer(),\n    resources.initialize_resources(resources.shared_resources()))\n\n# Start TensorFlow session\nsess = tf.Session()\n\n# Run the initializer\nsess.run(init_vars)\n\n# Training\nfor i in range(1, num_steps + 1):\n    # Prepare Data\n    # Get the next batch of MNIST data (only images are needed, not labels)\n    batch_x, batch_y = mnist.train.next_batch(batch_size)\n    _, l = sess.run([train_op, loss_op], feed_dict={X: batch_x, Y: batch_y})\n    if i % 50 == 0 or i == 1:\n        acc = sess.run(accuracy_op, feed_dict={X: batch_x, Y: batch_y})\n        print(\'Step %i, Loss: %f, Acc: %f\' % (i, l, acc))\n\n# Test Model\ntest_x, test_y = mnist.test.images, mnist.test.labels\nprint(""Test Accuracy:"", sess.run(accuracy_op, feed_dict={X: test_x, Y: test_y}))\n'"
tensorflow_v1/examples/2_BasicModels/word2vec.py,15,"b'"""""" Word2Vec.\n\nImplement Word2Vec algorithm to compute vector representations of words.\nThis example is using a small chunk of Wikipedia articles to train from.\n\nReferences:\n    - Mikolov, Tomas et al. ""Efficient Estimation of Word Representations\n    in Vector Space."", 2013.\n\nLinks:\n    - [Word2Vec] https://arxiv.org/pdf/1301.3781.pdf\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n""""""\nfrom __future__ import division, print_function, absolute_import\n\nimport collections\nimport os\nimport random\nimport urllib\nimport zipfile\n\nimport numpy as np\nimport tensorflow as tf\n\n# Training Parameters\nlearning_rate = 0.1\nbatch_size = 128\nnum_steps = 3000000\ndisplay_step = 10000\neval_step = 200000\n\n# Evaluation Parameters\neval_words = [\'five\', \'of\', \'going\', \'hardware\', \'american\', \'britain\']\n\n# Word2Vec Parameters\nembedding_size = 200 # Dimension of the embedding vector\nmax_vocabulary_size = 50000 # Total number of different words in the vocabulary\nmin_occurrence = 10 # Remove all words that does not appears at least n times\nskip_window = 3 # How many words to consider left and right\nnum_skips = 2 # How many times to reuse an input to generate a label\nnum_sampled = 64 # Number of negative examples to sample\n\n\n# Download a small chunk of Wikipedia articles collection\nurl = \'http://mattmahoney.net/dc/text8.zip\'\ndata_path = \'text8.zip\'\nif not os.path.exists(data_path):\n    print(""Downloading the dataset... (It may take some time)"")\n    filename, _ = urllib.urlretrieve(url, data_path)\n    print(""Done!"")\n# Unzip the dataset file. Text has already been processed\nwith zipfile.ZipFile(data_path) as f:\n    text_words = f.read(f.namelist()[0]).lower().split()\n\n# Build the dictionary and replace rare words with UNK token\ncount = [(\'UNK\', -1)]\n# Retrieve the most common words\ncount.extend(collections.Counter(text_words).most_common(max_vocabulary_size - 1))\n# Remove samples with less than \'min_occurrence\' occurrences\nfor i in range(len(count) - 1, -1, -1):\n    if count[i][1] < min_occurrence:\n        count.pop(i)\n    else:\n        # The collection is ordered, so stop when \'min_occurrence\' is reached\n        break\n# Compute the vocabulary size\nvocabulary_size = len(count)\n# Assign an id to each word\nword2id = dict()\nfor i, (word, _)in enumerate(count):\n    word2id[word] = i\n\ndata = list()\nunk_count = 0\nfor word in text_words:\n    # Retrieve a word id, or assign it index 0 (\'UNK\') if not in dictionary\n    index = word2id.get(word, 0)\n    if index == 0:\n        unk_count += 1\n    data.append(index)\ncount[0] = (\'UNK\', unk_count)\nid2word = dict(zip(word2id.values(), word2id.keys()))\n\nprint(""Words count:"", len(text_words))\nprint(""Unique words:"", len(set(text_words)))\nprint(""Vocabulary size:"", vocabulary_size)\nprint(""Most common words:"", count[:10])\n\ndata_index = 0\n# Generate training batch for the skip-gram model\ndef next_batch(batch_size, num_skips, skip_window):\n    global data_index\n    assert batch_size % num_skips == 0\n    assert num_skips <= 2 * skip_window\n    batch = np.ndarray(shape=(batch_size), dtype=np.int32)\n    labels = np.ndarray(shape=(batch_size, 1), dtype=np.int32)\n    # get window size (words left and right + current one)\n    span = 2 * skip_window + 1\n    buffer = collections.deque(maxlen=span)\n    if data_index + span > len(data):\n        data_index = 0\n    buffer.extend(data[data_index:data_index + span])\n    data_index += span\n    for i in range(batch_size // num_skips):\n        context_words = [w for w in range(span) if w != skip_window]\n        words_to_use = random.sample(context_words, num_skips)\n        for j, context_word in enumerate(words_to_use):\n            batch[i * num_skips + j] = buffer[skip_window]\n            labels[i * num_skips + j, 0] = buffer[context_word]\n        if data_index == len(data):\n            buffer.extend(data[0:span])\n            data_index = span\n        else:\n            buffer.append(data[data_index])\n            data_index += 1\n    # Backtrack a little bit to avoid skipping words in the end of a batch\n    data_index = (data_index + len(data) - span) % len(data)\n    return batch, labels\n\n\n# Input data\nX = tf.placeholder(tf.int32, shape=[None])\n# Input label\nY = tf.placeholder(tf.int32, shape=[None, 1])\n\n# Ensure the following ops & var are assigned on CPU\n# (some ops are not compatible on GPU)\nwith tf.device(\'/cpu:0\'):\n    # Create the embedding variable (each row represent a word embedding vector)\n    embedding = tf.Variable(tf.random_normal([vocabulary_size, embedding_size]))\n    # Lookup the corresponding embedding vectors for each sample in X\n    X_embed = tf.nn.embedding_lookup(embedding, X)\n\n    # Construct the variables for the NCE loss\n    nce_weights = tf.Variable(tf.random_normal([vocabulary_size, embedding_size]))\n    nce_biases = tf.Variable(tf.zeros([vocabulary_size]))\n\n# Compute the average NCE loss for the batch\nloss_op = tf.reduce_mean(\n    tf.nn.nce_loss(weights=nce_weights,\n                   biases=nce_biases,\n                   labels=Y,\n                   inputs=X_embed,\n                   num_sampled=num_sampled,\n                   num_classes=vocabulary_size))\n\n# Define the optimizer\noptimizer = tf.train.GradientDescentOptimizer(learning_rate)\ntrain_op = optimizer.minimize(loss_op)\n\n# Evaluation\n# Compute the cosine similarity between input data embedding and every embedding vectors\nX_embed_norm = X_embed / tf.sqrt(tf.reduce_sum(tf.square(X_embed)))\nembedding_norm = embedding / tf.sqrt(tf.reduce_sum(tf.square(embedding), 1, keepdims=True))\ncosine_sim_op = tf.matmul(X_embed_norm, embedding_norm, transpose_b=True)\n\n# Initialize the variables (i.e. assign their default value)\ninit = tf.global_variables_initializer()\n\nwith tf.Session() as sess:\n\n    # Run the initializer\n    sess.run(init)\n\n    # Testing data\n    x_test = np.array([word2id[w] for w in eval_words])\n\n    average_loss = 0\n    for step in xrange(1, num_steps + 1):\n        # Get a new batch of data\n        batch_x, batch_y = next_batch(batch_size, num_skips, skip_window)\n        # Run training op\n        _, loss = sess.run([train_op, loss_op], feed_dict={X: batch_x, Y: batch_y})\n        average_loss += loss\n\n        if step % display_step == 0 or step == 1:\n            if step > 1:\n                average_loss /= display_step\n            print(""Step "" + str(step) + "", Average Loss= "" + \\\n                  ""{:.4f}"".format(average_loss))\n            average_loss = 0\n\n        # Evaluation\n        if step % eval_step == 0 or step == 1:\n            print(""Evaluation..."")\n            sim = sess.run(cosine_sim_op, feed_dict={X: x_test})\n            for i in xrange(len(eval_words)):\n                top_k = 8  # number of nearest neighbors\n                nearest = (-sim[i, :]).argsort()[1:top_k + 1]\n                log_str = \'""%s"" nearest neighbors:\' % eval_words[i]\n                for k in xrange(top_k):\n                    log_str = \'%s %s,\' % (log_str, id2word[nearest[k]])\n                print(log_str)\n'"
tensorflow_v1/examples/3_NeuralNetworks/autoencoder.py,17,"b'"""""" Auto Encoder Example.\n\nBuild a 2 layers auto-encoder with TensorFlow to compress images to a\nlower latent space and then reconstruct them.\n\nReferences:\n    Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. ""Gradient-based\n    learning applied to document recognition."" Proceedings of the IEEE,\n    86(11):2278-2324, November 1998.\n\nLinks:\n    [MNIST Dataset] http://yann.lecun.com/exdb/mnist/\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n""""""\nfrom __future__ import division, print_function, absolute_import\n\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Import MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""/tmp/data/"", one_hot=True)\n\n# Training Parameters\nlearning_rate = 0.01\nnum_steps = 30000\nbatch_size = 256\n\ndisplay_step = 1000\nexamples_to_show = 10\n\n# Network Parameters\nnum_hidden_1 = 256 # 1st layer num features\nnum_hidden_2 = 128 # 2nd layer num features (the latent dim)\nnum_input = 784 # MNIST data input (img shape: 28*28)\n\n# tf Graph input (only pictures)\nX = tf.placeholder(""float"", [None, num_input])\n\nweights = {\n    \'encoder_h1\': tf.Variable(tf.random_normal([num_input, num_hidden_1])),\n    \'encoder_h2\': tf.Variable(tf.random_normal([num_hidden_1, num_hidden_2])),\n    \'decoder_h1\': tf.Variable(tf.random_normal([num_hidden_2, num_hidden_1])),\n    \'decoder_h2\': tf.Variable(tf.random_normal([num_hidden_1, num_input])),\n}\nbiases = {\n    \'encoder_b1\': tf.Variable(tf.random_normal([num_hidden_1])),\n    \'encoder_b2\': tf.Variable(tf.random_normal([num_hidden_2])),\n    \'decoder_b1\': tf.Variable(tf.random_normal([num_hidden_1])),\n    \'decoder_b2\': tf.Variable(tf.random_normal([num_input])),\n}\n\n# Building the encoder\ndef encoder(x):\n    # Encoder Hidden layer with sigmoid activation #1\n    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights[\'encoder_h1\']),\n                                   biases[\'encoder_b1\']))\n    # Encoder Hidden layer with sigmoid activation #2\n    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights[\'encoder_h2\']),\n                                   biases[\'encoder_b2\']))\n    return layer_2\n\n\n# Building the decoder\ndef decoder(x):\n    # Decoder Hidden layer with sigmoid activation #1\n    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights[\'decoder_h1\']),\n                                   biases[\'decoder_b1\']))\n    # Decoder Hidden layer with sigmoid activation #2\n    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights[\'decoder_h2\']),\n                                   biases[\'decoder_b2\']))\n    return layer_2\n\n# Construct model\nencoder_op = encoder(X)\ndecoder_op = decoder(encoder_op)\n\n# Prediction\ny_pred = decoder_op\n# Targets (Labels) are the input data.\ny_true = X\n\n# Define loss and optimizer, minimize the squared error\nloss = tf.reduce_mean(tf.pow(y_true - y_pred, 2))\noptimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(loss)\n\n# Initialize the variables (i.e. assign their default value)\ninit = tf.global_variables_initializer()\n\n# Start Training\n# Start a new TF session\nwith tf.Session() as sess:\n\n    # Run the initializer\n    sess.run(init)\n\n    # Training\n    for i in range(1, num_steps+1):\n        # Prepare Data\n        # Get the next batch of MNIST data (only images are needed, not labels)\n        batch_x, _ = mnist.train.next_batch(batch_size)\n\n        # Run optimization op (backprop) and cost op (to get loss value)\n        _, l = sess.run([optimizer, loss], feed_dict={X: batch_x})\n        # Display logs per step\n        if i % display_step == 0 or i == 1:\n            print(\'Step %i: Minibatch Loss: %f\' % (i, l))\n\n    # Testing\n    # Encode and decode images from test set and visualize their reconstruction.\n    n = 4\n    canvas_orig = np.empty((28 * n, 28 * n))\n    canvas_recon = np.empty((28 * n, 28 * n))\n    for i in range(n):\n        # MNIST test set\n        batch_x, _ = mnist.test.next_batch(n)\n        # Encode and decode the digit image\n        g = sess.run(decoder_op, feed_dict={X: batch_x})\n\n        # Display original images\n        for j in range(n):\n            # Draw the original digits\n            canvas_orig[i * 28:(i + 1) * 28, j * 28:(j + 1) * 28] = \\\n                batch_x[j].reshape([28, 28])\n        # Display reconstructed images\n        for j in range(n):\n            # Draw the reconstructed digits\n            canvas_recon[i * 28:(i + 1) * 28, j * 28:(j + 1) * 28] = \\\n                g[j].reshape([28, 28])\n\n    print(""Original Images"")\n    plt.figure(figsize=(n, n))\n    plt.imshow(canvas_orig, origin=""upper"", cmap=""gray"")\n    plt.show()\n\n    print(""Reconstructed Images"")\n    plt.figure(figsize=(n, n))\n    plt.imshow(canvas_recon, origin=""upper"", cmap=""gray"")\n    plt.show()\n'"
tensorflow_v1/examples/3_NeuralNetworks/bidirectional_rnn.py,15,"b'"""""" Bi-directional Recurrent Neural Network.\n\nA Bi-directional Recurrent Neural Network (LSTM) implementation example using \nTensorFlow library. This example is using the MNIST database of handwritten \ndigits (http://yann.lecun.com/exdb/mnist/)\n\nLinks:\n    [Long Short Term Memory](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf)\n    [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n""""""\n\nfrom __future__ import print_function\n\nimport tensorflow as tf\nfrom tensorflow.contrib import rnn\nimport numpy as np\n\n# Import MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""/tmp/data/"", one_hot=True)\n\n\'\'\'\nTo classify images using a bidirectional recurrent neural network, we consider\nevery image row as a sequence of pixels. Because MNIST image shape is 28*28px,\nwe will then handle 28 sequences of 28 steps for every sample.\n\'\'\'\n\n# Training Parameters\nlearning_rate = 0.001\ntraining_steps = 10000\nbatch_size = 128\ndisplay_step = 200\n\n# Network Parameters\nnum_input = 28 # MNIST data input (img shape: 28*28)\ntimesteps = 28 # timesteps\nnum_hidden = 128 # hidden layer num of features\nnum_classes = 10 # MNIST total classes (0-9 digits)\n\n# tf Graph input\nX = tf.placeholder(""float"", [None, timesteps, num_input])\nY = tf.placeholder(""float"", [None, num_classes])\n\n# Define weights\nweights = {\n    # Hidden layer weights => 2*n_hidden because of forward + backward cells\n    \'out\': tf.Variable(tf.random_normal([2*num_hidden, num_classes]))\n}\nbiases = {\n    \'out\': tf.Variable(tf.random_normal([num_classes]))\n}\n\n\ndef BiRNN(x, weights, biases):\n\n    # Prepare data shape to match `rnn` function requirements\n    # Current data input shape: (batch_size, timesteps, n_input)\n    # Required shape: \'timesteps\' tensors list of shape (batch_size, num_input)\n\n    # Unstack to get a list of \'timesteps\' tensors of shape (batch_size, num_input)\n    x = tf.unstack(x, timesteps, 1)\n\n    # Define lstm cells with tensorflow\n    # Forward direction cell\n    lstm_fw_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n    # Backward direction cell\n    lstm_bw_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n\n    # Get lstm cell output\n    try:\n        outputs, _, _ = rnn.static_bidirectional_rnn(lstm_fw_cell, lstm_bw_cell, x,\n                                              dtype=tf.float32)\n    except Exception: # Old TensorFlow version only returns outputs not states\n        outputs = rnn.static_bidirectional_rnn(lstm_fw_cell, lstm_bw_cell, x,\n                                        dtype=tf.float32)\n\n    # Linear activation, using rnn inner loop last output\n    return tf.matmul(outputs[-1], weights[\'out\']) + biases[\'out\']\n\nlogits = BiRNN(X, weights, biases)\nprediction = tf.nn.softmax(logits)\n\n# Define loss and optimizer\nloss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n    logits=logits, labels=Y))\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\ntrain_op = optimizer.minimize(loss_op)\n\n# Evaluate model (with test logits, for dropout to be disabled)\ncorrect_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\n# Initialize the variables (i.e. assign their default value)\ninit = tf.global_variables_initializer()\n\n# Start training\nwith tf.Session() as sess:\n\n    # Run the initializer\n    sess.run(init)\n\n    for step in range(1, training_steps+1):\n        batch_x, batch_y = mnist.train.next_batch(batch_size)\n        # Reshape data to get 28 seq of 28 elements\n        batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n        # Run optimization op (backprop)\n        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n        if step % display_step == 0 or step == 1:\n            # Calculate batch loss and accuracy\n            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n                                                                 Y: batch_y})\n            print(""Step "" + str(step) + "", Minibatch Loss= "" + \\\n                  ""{:.4f}"".format(loss) + "", Training Accuracy= "" + \\\n                  ""{:.3f}"".format(acc))\n\n    print(""Optimization Finished!"")\n\n    # Calculate accuracy for 128 mnist test images\n    test_len = 128\n    test_data = mnist.test.images[:test_len].reshape((-1, timesteps, num_input))\n    test_label = mnist.test.labels[:test_len]\n    print(""Testing Accuracy:"", \\\n        sess.run(accuracy, feed_dict={X: test_data, Y: test_label}))\n'"
tensorflow_v1/examples/3_NeuralNetworks/convolutional_network.py,23,"b'"""""" Convolutional Neural Network.\n\nBuild and train a convolutional neural network with TensorFlow.\nThis example is using the MNIST database of handwritten digits\n(http://yann.lecun.com/exdb/mnist/)\n\nThis example is using TensorFlow layers API, see \'convolutional_network_raw\' \nexample for a raw implementation with variables.\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n""""""\nfrom __future__ import division, print_function, absolute_import\n\n# Import MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""/tmp/data/"", one_hot=False)\n\nimport tensorflow as tf\n\n# Training Parameters\nlearning_rate = 0.001\nnum_steps = 2000\nbatch_size = 128\n\n# Network Parameters\nnum_input = 784 # MNIST data input (img shape: 28*28)\nnum_classes = 10 # MNIST total classes (0-9 digits)\ndropout = 0.25 # Dropout, probability to drop a unit\n\n\n# Create the neural network\ndef conv_net(x_dict, n_classes, dropout, reuse, is_training):\n    # Define a scope for reusing the variables\n    with tf.variable_scope(\'ConvNet\', reuse=reuse):\n        # TF Estimator input is a dict, in case of multiple inputs\n        x = x_dict[\'images\']\n\n        # MNIST data input is a 1-D vector of 784 features (28*28 pixels)\n        # Reshape to match picture format [Height x Width x Channel]\n        # Tensor input become 4-D: [Batch Size, Height, Width, Channel]\n        x = tf.reshape(x, shape=[-1, 28, 28, 1])\n\n        # Convolution Layer with 32 filters and a kernel size of 5\n        conv1 = tf.layers.conv2d(x, 32, 5, activation=tf.nn.relu)\n        # Max Pooling (down-sampling) with strides of 2 and kernel size of 2\n        conv1 = tf.layers.max_pooling2d(conv1, 2, 2)\n\n        # Convolution Layer with 64 filters and a kernel size of 3\n        conv2 = tf.layers.conv2d(conv1, 64, 3, activation=tf.nn.relu)\n        # Max Pooling (down-sampling) with strides of 2 and kernel size of 2\n        conv2 = tf.layers.max_pooling2d(conv2, 2, 2)\n\n        # Flatten the data to a 1-D vector for the fully connected layer\n        fc1 = tf.contrib.layers.flatten(conv2)\n\n        # Fully connected layer (in tf contrib folder for now)\n        fc1 = tf.layers.dense(fc1, 1024)\n        # Apply Dropout (if is_training is False, dropout is not applied)\n        fc1 = tf.layers.dropout(fc1, rate=dropout, training=is_training)\n\n        # Output layer, class prediction\n        out = tf.layers.dense(fc1, n_classes)\n\n    return out\n\n\n# Define the model function (following TF Estimator Template)\ndef model_fn(features, labels, mode):\n    # Build the neural network\n    # Because Dropout have different behavior at training and prediction time, we\n    # need to create 2 distinct computation graphs that still share the same weights.\n    logits_train = conv_net(features, num_classes, dropout, reuse=False,\n                            is_training=True)\n    logits_test = conv_net(features, num_classes, dropout, reuse=True,\n                           is_training=False)\n\n    # Predictions\n    pred_classes = tf.argmax(logits_test, axis=1)\n    pred_probas = tf.nn.softmax(logits_test)\n\n    # If prediction mode, early return\n    if mode == tf.estimator.ModeKeys.PREDICT:\n        return tf.estimator.EstimatorSpec(mode, predictions=pred_classes)\n\n        # Define loss and optimizer\n    loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n        logits=logits_train, labels=tf.cast(labels, dtype=tf.int32)))\n    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n    train_op = optimizer.minimize(loss_op,\n                                  global_step=tf.train.get_global_step())\n\n    # Evaluate the accuracy of the model\n    acc_op = tf.metrics.accuracy(labels=labels, predictions=pred_classes)\n\n    # TF Estimators requires to return a EstimatorSpec, that specify\n    # the different ops for training, evaluating, ...\n    estim_specs = tf.estimator.EstimatorSpec(\n        mode=mode,\n        predictions=pred_classes,\n        loss=loss_op,\n        train_op=train_op,\n        eval_metric_ops={\'accuracy\': acc_op})\n\n    return estim_specs\n\n# Build the Estimator\nmodel = tf.estimator.Estimator(model_fn)\n\n# Define the input function for training\ninput_fn = tf.estimator.inputs.numpy_input_fn(\n    x={\'images\': mnist.train.images}, y=mnist.train.labels,\n    batch_size=batch_size, num_epochs=None, shuffle=True)\n# Train the Model\nmodel.train(input_fn, steps=num_steps)\n\n# Evaluate the Model\n# Define the input function for evaluating\ninput_fn = tf.estimator.inputs.numpy_input_fn(\n    x={\'images\': mnist.test.images}, y=mnist.test.labels,\n    batch_size=batch_size, shuffle=False)\n# Use the Estimator \'evaluate\' method\ne = model.evaluate(input_fn)\n\nprint(""Testing Accuracy:"", e[\'accuracy\'])\n'"
tensorflow_v1/examples/3_NeuralNetworks/convolutional_network_raw.py,28,"b'"""""" Convolutional Neural Network.\n\nBuild and train a convolutional neural network with TensorFlow.\nThis example is using the MNIST database of handwritten digits\n(http://yann.lecun.com/exdb/mnist/)\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n""""""\n\nfrom __future__ import division, print_function, absolute_import\n\nimport tensorflow as tf\n\n# Import MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""/tmp/data/"", one_hot=True)\n\n# Training Parameters\nlearning_rate = 0.001\nnum_steps = 200\nbatch_size = 128\ndisplay_step = 10\n\n# Network Parameters\nnum_input = 784 # MNIST data input (img shape: 28*28)\nnum_classes = 10 # MNIST total classes (0-9 digits)\ndropout = 0.75 # Dropout, probability to keep units\n\n# tf Graph input\nX = tf.placeholder(tf.float32, [None, num_input])\nY = tf.placeholder(tf.float32, [None, num_classes])\nkeep_prob = tf.placeholder(tf.float32) # dropout (keep probability)\n\n\n# Create some wrappers for simplicity\ndef conv2d(x, W, b, strides=1):\n    # Conv2D wrapper, with bias and relu activation\n    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding=\'SAME\')\n    x = tf.nn.bias_add(x, b)\n    return tf.nn.relu(x)\n\n\ndef maxpool2d(x, k=2):\n    # MaxPool2D wrapper\n    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n                          padding=\'SAME\')\n\n\n# Create model\ndef conv_net(x, weights, biases, dropout):\n    # MNIST data input is a 1-D vector of 784 features (28*28 pixels)\n    # Reshape to match picture format [Height x Width x Channel]\n    # Tensor input become 4-D: [Batch Size, Height, Width, Channel]\n    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n\n    # Convolution Layer\n    conv1 = conv2d(x, weights[\'wc1\'], biases[\'bc1\'])\n    # Max Pooling (down-sampling)\n    conv1 = maxpool2d(conv1, k=2)\n\n    # Convolution Layer\n    conv2 = conv2d(conv1, weights[\'wc2\'], biases[\'bc2\'])\n    # Max Pooling (down-sampling)\n    conv2 = maxpool2d(conv2, k=2)\n\n    # Fully connected layer\n    # Reshape conv2 output to fit fully connected layer input\n    fc1 = tf.reshape(conv2, [-1, weights[\'wd1\'].get_shape().as_list()[0]])\n    fc1 = tf.add(tf.matmul(fc1, weights[\'wd1\']), biases[\'bd1\'])\n    fc1 = tf.nn.relu(fc1)\n    # Apply Dropout\n    fc1 = tf.nn.dropout(fc1, dropout)\n\n    # Output, class prediction\n    out = tf.add(tf.matmul(fc1, weights[\'out\']), biases[\'out\'])\n    return out\n\n# Store layers weight & bias\nweights = {\n    # 5x5 conv, 1 input, 32 outputs\n    \'wc1\': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n    # 5x5 conv, 32 inputs, 64 outputs\n    \'wc2\': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n    # fully connected, 7*7*64 inputs, 1024 outputs\n    \'wd1\': tf.Variable(tf.random_normal([7*7*64, 1024])),\n    # 1024 inputs, 10 outputs (class prediction)\n    \'out\': tf.Variable(tf.random_normal([1024, num_classes]))\n}\n\nbiases = {\n    \'bc1\': tf.Variable(tf.random_normal([32])),\n    \'bc2\': tf.Variable(tf.random_normal([64])),\n    \'bd1\': tf.Variable(tf.random_normal([1024])),\n    \'out\': tf.Variable(tf.random_normal([num_classes]))\n}\n\n# Construct model\nlogits = conv_net(X, weights, biases, keep_prob)\nprediction = tf.nn.softmax(logits)\n\n# Define loss and optimizer\nloss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n    logits=logits, labels=Y))\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\ntrain_op = optimizer.minimize(loss_op)\n\n\n# Evaluate model\ncorrect_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\n# Initialize the variables (i.e. assign their default value)\ninit = tf.global_variables_initializer()\n\n# Start training\nwith tf.Session() as sess:\n\n    # Run the initializer\n    sess.run(init)\n\n    for step in range(1, num_steps+1):\n        batch_x, batch_y = mnist.train.next_batch(batch_size)\n        # Run optimization op (backprop)\n        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y, keep_prob: 0.8})\n        if step % display_step == 0 or step == 1:\n            # Calculate batch loss and accuracy\n            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n                                                                 Y: batch_y,\n                                                                 keep_prob: 1.0})\n            print(""Step "" + str(step) + "", Minibatch Loss= "" + \\\n                  ""{:.4f}"".format(loss) + "", Training Accuracy= "" + \\\n                  ""{:.3f}"".format(acc))\n\n    print(""Optimization Finished!"")\n\n    # Calculate accuracy for 256 MNIST test images\n    print(""Testing Accuracy:"", \\\n        sess.run(accuracy, feed_dict={X: mnist.test.images[:256],\n                                      Y: mnist.test.labels[:256],\n                                      keep_prob: 1.0}))\n'"
tensorflow_v1/examples/3_NeuralNetworks/dcgan.py,31,"b'"""""" Deep Convolutional Generative Adversarial Network (DCGAN).\n\nUsing deep convolutional generative adversarial networks (DCGAN) to generate\ndigit images from a noise distribution.\n\nReferences:\n    - Unsupervised representation learning with deep convolutional generative\n    adversarial networks. A Radford, L Metz, S Chintala. arXiv:1511.06434.\n\nLinks:\n    - [DCGAN Paper](https://arxiv.org/abs/1511.06434).\n    - [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n""""""\n\nfrom __future__ import division, print_function, absolute_import\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\n\n# Import MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""/tmp/data/"", one_hot=True)\n\n# Training Params\nnum_steps = 20000\nbatch_size = 32\n\n# Network Params\nimage_dim = 784 # 28*28 pixels * 1 channel\ngen_hidden_dim = 256\ndisc_hidden_dim = 256\nnoise_dim = 200 # Noise data points\n\n\n# Generator Network\n# Input: Noise, Output: Image\ndef generator(x, reuse=False):\n    with tf.variable_scope(\'Generator\', reuse=reuse):\n        # TensorFlow Layers automatically create variables and calculate their\n        # shape, based on the input.\n        x = tf.layers.dense(x, units=6 * 6 * 128)\n        x = tf.nn.tanh(x)\n        # Reshape to a 4-D array of images: (batch, height, width, channels)\n        # New shape: (batch, 6, 6, 128)\n        x = tf.reshape(x, shape=[-1, 6, 6, 128])\n        # Deconvolution, image shape: (batch, 14, 14, 64)\n        x = tf.layers.conv2d_transpose(x, 64, 4, strides=2)\n        # Deconvolution, image shape: (batch, 28, 28, 1)\n        x = tf.layers.conv2d_transpose(x, 1, 2, strides=2)\n        # Apply sigmoid to clip values between 0 and 1\n        x = tf.nn.sigmoid(x)\n        return x\n\n\n# Discriminator Network\n# Input: Image, Output: Prediction Real/Fake Image\ndef discriminator(x, reuse=False):\n    with tf.variable_scope(\'Discriminator\', reuse=reuse):\n        # Typical convolutional neural network to classify images.\n        x = tf.layers.conv2d(x, 64, 5)\n        x = tf.nn.tanh(x)\n        x = tf.layers.average_pooling2d(x, 2, 2)\n        x = tf.layers.conv2d(x, 128, 5)\n        x = tf.nn.tanh(x)\n        x = tf.layers.average_pooling2d(x, 2, 2)\n        x = tf.contrib.layers.flatten(x)\n        x = tf.layers.dense(x, 1024)\n        x = tf.nn.tanh(x)\n        # Output 2 classes: Real and Fake images\n        x = tf.layers.dense(x, 2)\n    return x\n\n# Build Networks\n# Network Inputs\nnoise_input = tf.placeholder(tf.float32, shape=[None, noise_dim])\nreal_image_input = tf.placeholder(tf.float32, shape=[None, 28, 28, 1])\n\n# Build Generator Network\ngen_sample = generator(noise_input)\n\n# Build 2 Discriminator Networks (one from real image input, one from generated samples)\ndisc_real = discriminator(real_image_input)\ndisc_fake = discriminator(gen_sample, reuse=True)\ndisc_concat = tf.concat([disc_real, disc_fake], axis=0)\n\n# Build the stacked generator/discriminator\nstacked_gan = discriminator(gen_sample, reuse=True)\n\n# Build Targets (real or fake images)\ndisc_target = tf.placeholder(tf.int32, shape=[None])\ngen_target = tf.placeholder(tf.int32, shape=[None])\n\n# Build Loss\ndisc_loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n    logits=disc_concat, labels=disc_target))\ngen_loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n    logits=stacked_gan, labels=gen_target))\n\n# Build Optimizers\noptimizer_gen = tf.train.AdamOptimizer(learning_rate=0.001)\noptimizer_disc = tf.train.AdamOptimizer(learning_rate=0.001)\n\n# Training Variables for each optimizer\n# By default in TensorFlow, all variables are updated by each optimizer, so we\n# need to precise for each one of them the specific variables to update.\n# Generator Network Variables\ngen_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\'Generator\')\n# Discriminator Network Variables\ndisc_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\'Discriminator\')\n\n# Create training operations\ntrain_gen = optimizer_gen.minimize(gen_loss, var_list=gen_vars)\ntrain_disc = optimizer_disc.minimize(disc_loss, var_list=disc_vars)\n\n# Initialize the variables (i.e. assign their default value)\ninit = tf.global_variables_initializer()\n\n# Start training\nwith tf.Session() as sess:\n\n    # Run the initializer\n    sess.run(init)\n\n    for i in range(1, num_steps+1):\n\n        # Prepare Input Data\n        # Get the next batch of MNIST data (only images are needed, not labels)\n        batch_x, _ = mnist.train.next_batch(batch_size)\n        batch_x = np.reshape(batch_x, newshape=[-1, 28, 28, 1])\n        # Generate noise to feed to the generator\n        z = np.random.uniform(-1., 1., size=[batch_size, noise_dim])\n\n        # Prepare Targets (Real image: 1, Fake image: 0)\n        # The first half of data fed to the discriminator are real images,\n        # the other half are fake images (coming from the generator).\n        batch_disc_y = np.concatenate(\n            [np.ones([batch_size]), np.zeros([batch_size])], axis=0)\n        # Generator tries to fool the discriminator, thus targets are 1.\n        batch_gen_y = np.ones([batch_size])\n\n        # Training\n        feed_dict = {real_image_input: batch_x, noise_input: z,\n                     disc_target: batch_disc_y, gen_target: batch_gen_y}\n        _, _, gl, dl = sess.run([train_gen, train_disc, gen_loss, disc_loss],\n                                feed_dict=feed_dict)\n        if i % 100 == 0 or i == 1:\n            print(\'Step %i: Generator Loss: %f, Discriminator Loss: %f\' % (i, gl, dl))\n\n    # Generate images from noise, using the generator network.\n    f, a = plt.subplots(4, 10, figsize=(10, 4))\n    for i in range(10):\n        # Noise input.\n        z = np.random.uniform(-1., 1., size=[4, noise_dim])\n        g = sess.run(gen_sample, feed_dict={noise_input: z})\n        for j in range(4):\n            # Generate image from noise. Extend to 3 channels for matplot figure.\n            img = np.reshape(np.repeat(g[j][:, :, np.newaxis], 3, axis=2),\n                             newshape=(28, 28, 3))\n            a[j][i].imshow(img)\n\n    f.show()\n    plt.draw()\n    plt.waitforbuttonpress()\n'"
tensorflow_v1/examples/3_NeuralNetworks/dynamic_rnn.py,20,"b'"""""" Dynamic Recurrent Neural Network.\n\nTensorFlow implementation of a Recurrent Neural Network (LSTM) that performs\ndynamic computation over sequences with variable length. This example is using\na toy dataset to classify linear sequences. The generated sequences have\nvariable length.\n\nLinks:\n    [Long Short Term Memory](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf)\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n""""""\n\nfrom __future__ import print_function\n\nimport tensorflow as tf\nimport random\n\n\n# ====================\n#  TOY DATA GENERATOR\n# ====================\nclass ToySequenceData(object):\n    """""" Generate sequence of data with dynamic length.\n    This class generate samples for training:\n    - Class 0: linear sequences (i.e. [0, 1, 2, 3,...])\n    - Class 1: random sequences (i.e. [1, 3, 10, 7,...])\n\n    NOTICE:\n    We have to pad each sequence to reach \'max_seq_len\' for TensorFlow\n    consistency (we cannot feed a numpy array with inconsistent\n    dimensions). The dynamic calculation will then be perform thanks to\n    \'seqlen\' attribute that records every actual sequence length.\n    """"""\n    def __init__(self, n_samples=1000, max_seq_len=20, min_seq_len=3,\n                 max_value=1000):\n        self.data = []\n        self.labels = []\n        self.seqlen = []\n        for i in range(n_samples):\n            # Random sequence length\n            len = random.randint(min_seq_len, max_seq_len)\n            # Monitor sequence length for TensorFlow dynamic calculation\n            self.seqlen.append(len)\n            # Add a random or linear int sequence (50% prob)\n            if random.random() < .5:\n                # Generate a linear sequence\n                rand_start = random.randint(0, max_value - len)\n                s = [[float(i)/max_value] for i in\n                     range(rand_start, rand_start + len)]\n                # Pad sequence for dimension consistency\n                s += [[0.] for i in range(max_seq_len - len)]\n                self.data.append(s)\n                self.labels.append([1., 0.])\n            else:\n                # Generate a random sequence\n                s = [[float(random.randint(0, max_value))/max_value]\n                     for i in range(len)]\n                # Pad sequence for dimension consistency\n                s += [[0.] for i in range(max_seq_len - len)]\n                self.data.append(s)\n                self.labels.append([0., 1.])\n        self.batch_id = 0\n\n    def next(self, batch_size):\n        """""" Return a batch of data. When dataset end is reached, start over.\n        """"""\n        if self.batch_id == len(self.data):\n            self.batch_id = 0\n        batch_data = (self.data[self.batch_id:min(self.batch_id +\n                                                  batch_size, len(self.data))])\n        batch_labels = (self.labels[self.batch_id:min(self.batch_id +\n                                                  batch_size, len(self.data))])\n        batch_seqlen = (self.seqlen[self.batch_id:min(self.batch_id +\n                                                  batch_size, len(self.data))])\n        self.batch_id = min(self.batch_id + batch_size, len(self.data))\n        return batch_data, batch_labels, batch_seqlen\n\n\n# ==========\n#   MODEL\n# ==========\n\n# Parameters\nlearning_rate = 0.01\ntraining_steps = 10000\nbatch_size = 128\ndisplay_step = 200\n\n# Network Parameters\nseq_max_len = 20 # Sequence max length\nn_hidden = 64 # hidden layer num of features\nn_classes = 2 # linear sequence or not\n\ntrainset = ToySequenceData(n_samples=1000, max_seq_len=seq_max_len)\ntestset = ToySequenceData(n_samples=500, max_seq_len=seq_max_len)\n\n# tf Graph input\nx = tf.placeholder(""float"", [None, seq_max_len, 1])\ny = tf.placeholder(""float"", [None, n_classes])\n# A placeholder for indicating each sequence length\nseqlen = tf.placeholder(tf.int32, [None])\n\n# Define weights\nweights = {\n    \'out\': tf.Variable(tf.random_normal([n_hidden, n_classes]))\n}\nbiases = {\n    \'out\': tf.Variable(tf.random_normal([n_classes]))\n}\n\n\ndef dynamicRNN(x, seqlen, weights, biases):\n\n    # Prepare data shape to match `rnn` function requirements\n    # Current data input shape: (batch_size, n_steps, n_input)\n    # Required shape: \'n_steps\' tensors list of shape (batch_size, n_input)\n    \n    # Unstack to get a list of \'n_steps\' tensors of shape (batch_size, n_input)\n    x = tf.unstack(x, seq_max_len, 1)\n\n    # Define a lstm cell with tensorflow\n    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden)\n\n    # Get lstm cell output, providing \'sequence_length\' will perform dynamic\n    # calculation.\n    outputs, states = tf.contrib.rnn.static_rnn(lstm_cell, x, dtype=tf.float32,\n                                sequence_length=seqlen)\n\n    # When performing dynamic calculation, we must retrieve the last\n    # dynamically computed output, i.e., if a sequence length is 10, we need\n    # to retrieve the 10th output.\n    # However TensorFlow doesn\'t support advanced indexing yet, so we build\n    # a custom op that for each sample in batch size, get its length and\n    # get the corresponding relevant output.\n\n    # \'outputs\' is a list of output at every timestep, we pack them in a Tensor\n    # and change back dimension to [batch_size, n_step, n_input]\n    outputs = tf.stack(outputs)\n    outputs = tf.transpose(outputs, [1, 0, 2])\n\n    # Hack to build the indexing and retrieve the right output.\n    batch_size = tf.shape(outputs)[0]\n    # Start indices for each sample\n    index = tf.range(0, batch_size) * seq_max_len + (seqlen - 1)\n    # Indexing\n    outputs = tf.gather(tf.reshape(outputs, [-1, n_hidden]), index)\n\n    # Linear activation, using outputs computed above\n    return tf.matmul(outputs, weights[\'out\']) + biases[\'out\']\n\npred = dynamicRNN(x, seqlen, weights, biases)\n\n# Define loss and optimizer\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n\n# Evaluate model\ncorrect_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\n# Initialize the variables (i.e. assign their default value)\ninit = tf.global_variables_initializer()\n\n# Start training\nwith tf.Session() as sess:\n\n    # Run the initializer\n    sess.run(init)\n\n    for step in range(1, training_steps + 1):\n        batch_x, batch_y, batch_seqlen = trainset.next(batch_size)\n        # Run optimization op (backprop)\n        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y,\n                                       seqlen: batch_seqlen})\n        if step % display_step == 0 or step == 1:\n            # Calculate batch accuracy & loss\n            acc, loss = sess.run([accuracy, cost], feed_dict={x: batch_x, y: batch_y,\n                                                seqlen: batch_seqlen})\n            print(""Step "" + str(step*batch_size) + "", Minibatch Loss= "" + \\\n                  ""{:.6f}"".format(loss) + "", Training Accuracy= "" + \\\n                  ""{:.5f}"".format(acc))\n\n    print(""Optimization Finished!"")\n\n    # Calculate accuracy\n    test_data = testset.data\n    test_label = testset.labels\n    test_seqlen = testset.seqlen\n    print(""Testing Accuracy:"", \\\n        sess.run(accuracy, feed_dict={x: test_data, y: test_label,\n                                      seqlen: test_seqlen}))\n'"
tensorflow_v1/examples/3_NeuralNetworks/gan.py,29,"b'"""""" Generative Adversarial Networks (GAN).\n\nUsing generative adversarial networks (GAN) to generate digit images from a\nnoise distribution.\n\nReferences:\n    - Generative adversarial nets. I Goodfellow, J Pouget-Abadie, M Mirza,\n    B Xu, D Warde-Farley, S Ozair, Y. Bengio. Advances in neural information\n    processing systems, 2672-2680.\n    - Understanding the difficulty of training deep feedforward neural networks.\n    X Glorot, Y Bengio. Aistats 9, 249-256\n\nLinks:\n    - [GAN Paper](https://arxiv.org/pdf/1406.2661.pdf).\n    - [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).\n    - [Xavier Glorot Init](www.cs.cmu.edu/~bhiksha/courses/deeplearning/Fall.../AISTATS2010_Glorot.pdf).\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n""""""\n\nfrom __future__ import division, print_function, absolute_import\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\n\n# Import MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""/tmp/data/"", one_hot=True)\n\n# Training Params\nnum_steps = 100000\nbatch_size = 128\nlearning_rate = 0.0002\n\n# Network Params\nimage_dim = 784 # 28*28 pixels\ngen_hidden_dim = 256\ndisc_hidden_dim = 256\nnoise_dim = 100 # Noise data points\n\n# A custom initialization (see Xavier Glorot init)\ndef glorot_init(shape):\n    return tf.random_normal(shape=shape, stddev=1. / tf.sqrt(shape[0] / 2.))\n\n# Store layers weight & bias\nweights = {\n    \'gen_hidden1\': tf.Variable(glorot_init([noise_dim, gen_hidden_dim])),\n    \'gen_out\': tf.Variable(glorot_init([gen_hidden_dim, image_dim])),\n    \'disc_hidden1\': tf.Variable(glorot_init([image_dim, disc_hidden_dim])),\n    \'disc_out\': tf.Variable(glorot_init([disc_hidden_dim, 1])),\n}\nbiases = {\n    \'gen_hidden1\': tf.Variable(tf.zeros([gen_hidden_dim])),\n    \'gen_out\': tf.Variable(tf.zeros([image_dim])),\n    \'disc_hidden1\': tf.Variable(tf.zeros([disc_hidden_dim])),\n    \'disc_out\': tf.Variable(tf.zeros([1])),\n}\n\n\n# Generator\ndef generator(x):\n    hidden_layer = tf.matmul(x, weights[\'gen_hidden1\'])\n    hidden_layer = tf.add(hidden_layer, biases[\'gen_hidden1\'])\n    hidden_layer = tf.nn.relu(hidden_layer)\n    out_layer = tf.matmul(hidden_layer, weights[\'gen_out\'])\n    out_layer = tf.add(out_layer, biases[\'gen_out\'])\n    out_layer = tf.nn.sigmoid(out_layer)\n    return out_layer\n\n\n# Discriminator\ndef discriminator(x):\n    hidden_layer = tf.matmul(x, weights[\'disc_hidden1\'])\n    hidden_layer = tf.add(hidden_layer, biases[\'disc_hidden1\'])\n    hidden_layer = tf.nn.relu(hidden_layer)\n    out_layer = tf.matmul(hidden_layer, weights[\'disc_out\'])\n    out_layer = tf.add(out_layer, biases[\'disc_out\'])\n    out_layer = tf.nn.sigmoid(out_layer)\n    return out_layer\n\n# Build Networks\n# Network Inputs\ngen_input = tf.placeholder(tf.float32, shape=[None, noise_dim], name=\'input_noise\')\ndisc_input = tf.placeholder(tf.float32, shape=[None, image_dim], name=\'disc_input\')\n\n# Build Generator Network\ngen_sample = generator(gen_input)\n\n# Build 2 Discriminator Networks (one from noise input, one from generated samples)\ndisc_real = discriminator(disc_input)\ndisc_fake = discriminator(gen_sample)\n\n# Build Loss\ngen_loss = -tf.reduce_mean(tf.log(disc_fake))\ndisc_loss = -tf.reduce_mean(tf.log(disc_real) + tf.log(1. - disc_fake))\n\n# Build Optimizers\noptimizer_gen = tf.train.AdamOptimizer(learning_rate=learning_rate)\noptimizer_disc = tf.train.AdamOptimizer(learning_rate=learning_rate)\n\n# Training Variables for each optimizer\n# By default in TensorFlow, all variables are updated by each optimizer, so we\n# need to precise for each one of them the specific variables to update.\n# Generator Network Variables\ngen_vars = [weights[\'gen_hidden1\'], weights[\'gen_out\'],\n            biases[\'gen_hidden1\'], biases[\'gen_out\']]\n# Discriminator Network Variables\ndisc_vars = [weights[\'disc_hidden1\'], weights[\'disc_out\'],\n            biases[\'disc_hidden1\'], biases[\'disc_out\']]\n\n# Create training operations\ntrain_gen = optimizer_gen.minimize(gen_loss, var_list=gen_vars)\ntrain_disc = optimizer_disc.minimize(disc_loss, var_list=disc_vars)\n\n# Initialize the variables (i.e. assign their default value)\ninit = tf.global_variables_initializer()\n\n# Start training\nwith tf.Session() as sess:\n\n    # Run the initializer\n    sess.run(init)\n\n    for i in range(1, num_steps+1):\n        # Prepare Data\n        # Get the next batch of MNIST data (only images are needed, not labels)\n        batch_x, _ = mnist.train.next_batch(batch_size)\n        # Generate noise to feed to the generator\n        z = np.random.uniform(-1., 1., size=[batch_size, noise_dim])\n\n        # Train\n        feed_dict = {disc_input: batch_x, gen_input: z}\n        _, _, gl, dl = sess.run([train_gen, train_disc, gen_loss, disc_loss],\n                                feed_dict=feed_dict)\n        if i % 1000 == 0 or i == 1:\n            print(\'Step %i: Generator Loss: %f, Discriminator Loss: %f\' % (i, gl, dl))\n\n    # Generate images from noise, using the generator network.\n    f, a = plt.subplots(4, 10, figsize=(10, 4))\n    for i in range(10):\n        # Noise input.\n        z = np.random.uniform(-1., 1., size=[4, noise_dim])\n        g = sess.run([gen_sample], feed_dict={gen_input: z})\n        g = np.reshape(g, newshape=(4, 28, 28, 1))\n        # Reverse colours for better display\n        g = -1 * (g - 1)\n        for j in range(4):\n            # Generate image from noise. Extend to 3 channels for matplot figure.\n            img = np.reshape(np.repeat(g[j][:, :, np.newaxis], 3, axis=2),\n                             newshape=(28, 28, 3))\n            a[j][i].imshow(img)\n\n    f.show()\n    plt.draw()\n    plt.waitforbuttonpress()\n'"
tensorflow_v1/examples/3_NeuralNetworks/multilayer_perceptron.py,18,"b'"""""" Multilayer Perceptron.\n\nA Multilayer Perceptron (Neural Network) implementation example using\nTensorFlow library. This example is using the MNIST database of handwritten\ndigits (http://yann.lecun.com/exdb/mnist/).\n\nLinks:\n    [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n""""""\n\n# ------------------------------------------------------------------\n#\n# THIS EXAMPLE HAS BEEN RENAMED \'neural_network.py\', FOR SIMPLICITY.\n#\n# ------------------------------------------------------------------\n\n\nfrom __future__ import print_function\n\n# Import MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""/tmp/data/"", one_hot=True)\n\nimport tensorflow as tf\n\n# Parameters\nlearning_rate = 0.001\ntraining_epochs = 15\nbatch_size = 100\ndisplay_step = 1\n\n# Network Parameters\nn_hidden_1 = 256 # 1st layer number of neurons\nn_hidden_2 = 256 # 2nd layer number of neurons\nn_input = 784 # MNIST data input (img shape: 28*28)\nn_classes = 10 # MNIST total classes (0-9 digits)\n\n# tf Graph input\nX = tf.placeholder(""float"", [None, n_input])\nY = tf.placeholder(""float"", [None, n_classes])\n\n# Store layers weight & bias\nweights = {\n    \'h1\': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n    \'h2\': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n    \'out\': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n}\nbiases = {\n    \'b1\': tf.Variable(tf.random_normal([n_hidden_1])),\n    \'b2\': tf.Variable(tf.random_normal([n_hidden_2])),\n    \'out\': tf.Variable(tf.random_normal([n_classes]))\n}\n\n\n# Create model\ndef multilayer_perceptron(x):\n    # Hidden fully connected layer with 256 neurons\n    layer_1 = tf.add(tf.matmul(x, weights[\'h1\']), biases[\'b1\'])\n    # Hidden fully connected layer with 256 neurons\n    layer_2 = tf.add(tf.matmul(layer_1, weights[\'h2\']), biases[\'b2\'])\n    # Output fully connected layer with a neuron for each class\n    out_layer = tf.matmul(layer_2, weights[\'out\']) + biases[\'out\']\n    return out_layer\n\n# Construct model\nlogits = multilayer_perceptron(X)\n\n# Define loss and optimizer\nloss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n    logits=logits, labels=Y))\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\ntrain_op = optimizer.minimize(loss_op)\n# Initializing the variables\ninit = tf.global_variables_initializer()\n\nwith tf.Session() as sess:\n    sess.run(init)\n\n    # Training cycle\n    for epoch in range(training_epochs):\n        avg_cost = 0.\n        total_batch = int(mnist.train.num_examples/batch_size)\n        # Loop over all batches\n        for i in range(total_batch):\n            batch_x, batch_y = mnist.train.next_batch(batch_size)\n            # Run optimization op (backprop) and cost op (to get loss value)\n            _, c = sess.run([train_op, loss_op], feed_dict={X: batch_x,\n                                                            Y: batch_y})\n            # Compute average loss\n            avg_cost += c / total_batch\n        # Display logs per epoch step\n        if epoch % display_step == 0:\n            print(""Epoch:"", \'%04d\' % (epoch+1), ""cost={:.9f}"".format(avg_cost))\n    print(""Optimization Finished!"")\n\n    # Test model\n    pred = tf.nn.softmax(logits)  # Apply softmax to logits\n    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(Y, 1))\n    # Calculate accuracy\n    accuracy = tf.reduce_mean(tf.cast(correct_prediction, ""float""))\n    print(""Accuracy:"", accuracy.eval({X: mnist.test.images, Y: mnist.test.labels}))\n'"
tensorflow_v1/examples/3_NeuralNetworks/neural_network.py,16,"b'"""""" Neural Network.\n\nA 2-Hidden Layers Fully Connected Neural Network (a.k.a Multilayer Perceptron)\nimplementation with TensorFlow. This example is using the MNIST database\nof handwritten digits (http://yann.lecun.com/exdb/mnist/).\n\nThis example is using TensorFlow layers, see \'neural_network_raw\' example for\na raw implementation with variables.\n\nLinks:\n    [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n""""""\n\nfrom __future__ import print_function\n\n# Import MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""/tmp/data/"", one_hot=False)\n\nimport tensorflow as tf\n\n# Parameters\nlearning_rate = 0.1\nnum_steps = 1000\nbatch_size = 128\ndisplay_step = 100\n\n# Network Parameters\nn_hidden_1 = 256 # 1st layer number of neurons\nn_hidden_2 = 256 # 2nd layer number of neurons\nnum_input = 784 # MNIST data input (img shape: 28*28)\nnum_classes = 10 # MNIST total classes (0-9 digits)\n\n\n# Define the neural network\ndef neural_net(x_dict):\n    # TF Estimator input is a dict, in case of multiple inputs\n    x = x_dict[\'images\']\n    # Hidden fully connected layer with 256 neurons\n    layer_1 = tf.layers.dense(x, n_hidden_1)\n    # Hidden fully connected layer with 256 neurons\n    layer_2 = tf.layers.dense(layer_1, n_hidden_2)\n    # Output fully connected layer with a neuron for each class\n    out_layer = tf.layers.dense(layer_2, num_classes)\n    return out_layer\n\n\n# Define the model function (following TF Estimator Template)\ndef model_fn(features, labels, mode):\n    # Build the neural network\n    logits = neural_net(features)\n\n    # Predictions\n    pred_classes = tf.argmax(logits, axis=1)\n    pred_probas = tf.nn.softmax(logits)\n\n    # If prediction mode, early return\n    if mode == tf.estimator.ModeKeys.PREDICT:\n        return tf.estimator.EstimatorSpec(mode, predictions=pred_classes)\n\n    # Define loss and optimizer\n    loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n        logits=logits, labels=tf.cast(labels, dtype=tf.int32)))\n    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n    train_op = optimizer.minimize(loss_op,\n                                  global_step=tf.train.get_global_step())\n\n    # Evaluate the accuracy of the model\n    acc_op = tf.metrics.accuracy(labels=labels, predictions=pred_classes)\n\n    # TF Estimators requires to return a EstimatorSpec, that specify\n    # the different ops for training, evaluating, ...\n    estim_specs = tf.estimator.EstimatorSpec(\n        mode=mode,\n        predictions=pred_classes,\n        loss=loss_op,\n        train_op=train_op,\n        eval_metric_ops={\'accuracy\': acc_op})\n\n    return estim_specs\n\n# Build the Estimator\nmodel = tf.estimator.Estimator(model_fn)\n\n# Define the input function for training\ninput_fn = tf.estimator.inputs.numpy_input_fn(\n    x={\'images\': mnist.train.images}, y=mnist.train.labels,\n    batch_size=batch_size, num_epochs=None, shuffle=True)\n# Train the Model\nmodel.train(input_fn, steps=num_steps)\n\n# Evaluate the Model\n# Define the input function for evaluating\ninput_fn = tf.estimator.inputs.numpy_input_fn(\n    x={\'images\': mnist.test.images}, y=mnist.test.labels,\n    batch_size=batch_size, shuffle=False)\n# Use the Estimator \'evaluate\' method\ne = model.evaluate(input_fn)\n\nprint(""Testing Accuracy:"", e[\'accuracy\'])\n'"
tensorflow_v1/examples/3_NeuralNetworks/neural_network_eager_api.py,13,"b'"""""" Neural Network with Eager API.\n\nA 2-Hidden Layers Fully Connected Neural Network (a.k.a Multilayer Perceptron)\nimplementation with TensorFlow\'s Eager API. This example is using the MNIST database\nof handwritten digits (http://yann.lecun.com/exdb/mnist/).\n\nThis example is using TensorFlow layers, see \'neural_network_raw\' example for\na raw implementation with variables.\n\nLinks:\n    [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n""""""\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\n# Set Eager API\ntf.enable_eager_execution()\ntfe = tf.contrib.eager\n\n# Import MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""/tmp/data/"", one_hot=False)\n\n# Parameters\nlearning_rate = 0.001\nnum_steps = 1000\nbatch_size = 128\ndisplay_step = 100\n\n# Network Parameters\nn_hidden_1 = 256 # 1st layer number of neurons\nn_hidden_2 = 256 # 2nd layer number of neurons\nnum_input = 784 # MNIST data input (img shape: 28*28)\nnum_classes = 10 # MNIST total classes (0-9 digits)\n\n# Using TF Dataset to split data into batches\ndataset = tf.data.Dataset.from_tensor_slices(\n    (mnist.train.images, mnist.train.labels))\ndataset = dataset.repeat().batch(batch_size).prefetch(batch_size)\ndataset_iter = tfe.Iterator(dataset)\n\n\n# Define the neural network. To use eager API and tf.layers API together,\n# we must instantiate a tfe.Network class as follow:\nclass NeuralNet(tfe.Network):\n    def __init__(self):\n        # Define each layer\n        super(NeuralNet, self).__init__()\n        # Hidden fully connected layer with 256 neurons\n        self.layer1 = self.track_layer(\n            tf.layers.Dense(n_hidden_1, activation=tf.nn.relu))\n        # Hidden fully connected layer with 256 neurons\n        self.layer2 = self.track_layer(\n            tf.layers.Dense(n_hidden_2, activation=tf.nn.relu))\n        # Output fully connected layer with a neuron for each class\n        self.out_layer = self.track_layer(tf.layers.Dense(num_classes))\n\n    def call(self, x):\n        x = self.layer1(x)\n        x = self.layer2(x)\n        return self.out_layer(x)\n\n\nneural_net = NeuralNet()\n\n\n# Cross-Entropy loss function\ndef loss_fn(inference_fn, inputs, labels):\n    # Using sparse_softmax cross entropy\n    return tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n        logits=inference_fn(inputs), labels=labels))\n\n\n# Calculate accuracy\ndef accuracy_fn(inference_fn, inputs, labels):\n    prediction = tf.nn.softmax(inference_fn(inputs))\n    correct_pred = tf.equal(tf.argmax(prediction, 1), labels)\n    return tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\n\n# SGD Optimizer\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n# Compute gradients\ngrad = tfe.implicit_gradients(loss_fn)\n\n# Training\naverage_loss = 0.\naverage_acc = 0.\nfor step in range(num_steps):\n\n    # Iterate through the dataset\n    d = dataset_iter.next()\n\n    # Images\n    x_batch = d[0]\n    # Labels\n    y_batch = tf.cast(d[1], dtype=tf.int64)\n\n    # Compute the batch loss\n    batch_loss = loss_fn(neural_net, x_batch, y_batch)\n    average_loss += batch_loss\n    # Compute the batch accuracy\n    batch_accuracy = accuracy_fn(neural_net, x_batch, y_batch)\n    average_acc += batch_accuracy\n\n    if step == 0:\n        # Display the initial cost, before optimizing\n        print(""Initial loss= {:.9f}"".format(average_loss))\n\n    # Update the variables following gradients info\n    optimizer.apply_gradients(grad(neural_net, x_batch, y_batch))\n\n    # Display info\n    if (step + 1) % display_step == 0 or step == 0:\n        if step > 0:\n            average_loss /= display_step\n            average_acc /= display_step\n        print(""Step:"", \'%04d\' % (step + 1), "" loss="",\n              ""{:.9f}"".format(average_loss), "" accuracy="",\n              ""{:.4f}"".format(average_acc))\n        average_loss = 0.\n        average_acc = 0.\n\n# Evaluate model on the test image set\ntestX = mnist.test.images\ntestY = mnist.test.labels\n\ntest_acc = accuracy_fn(neural_net, testX, testY)\nprint(""Testset Accuracy: {:.4f}"".format(test_acc))\n'"
tensorflow_v1/examples/3_NeuralNetworks/neural_network_raw.py,18,"b'"""""" Neural Network.\n\nA 2-Hidden Layers Fully Connected Neural Network (a.k.a Multilayer Perceptron)\nimplementation with TensorFlow. This example is using the MNIST database\nof handwritten digits (http://yann.lecun.com/exdb/mnist/).\n\nLinks:\n    [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n""""""\n\nfrom __future__ import print_function\n\n# Import MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""/tmp/data/"", one_hot=True)\n\nimport tensorflow as tf\n\n# Parameters\nlearning_rate = 0.1\nnum_steps = 500\nbatch_size = 128\ndisplay_step = 100\n\n# Network Parameters\nn_hidden_1 = 256 # 1st layer number of neurons\nn_hidden_2 = 256 # 2nd layer number of neurons\nnum_input = 784 # MNIST data input (img shape: 28*28)\nnum_classes = 10 # MNIST total classes (0-9 digits)\n\n# tf Graph input\nX = tf.placeholder(""float"", [None, num_input])\nY = tf.placeholder(""float"", [None, num_classes])\n\n# Store layers weight & bias\nweights = {\n    \'h1\': tf.Variable(tf.random_normal([num_input, n_hidden_1])),\n    \'h2\': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n    \'out\': tf.Variable(tf.random_normal([n_hidden_2, num_classes]))\n}\nbiases = {\n    \'b1\': tf.Variable(tf.random_normal([n_hidden_1])),\n    \'b2\': tf.Variable(tf.random_normal([n_hidden_2])),\n    \'out\': tf.Variable(tf.random_normal([num_classes]))\n}\n\n\n# Create model\ndef neural_net(x):\n    # Hidden fully connected layer with 256 neurons\n    layer_1 = tf.add(tf.matmul(x, weights[\'h1\']), biases[\'b1\'])\n    # Hidden fully connected layer with 256 neurons\n    layer_2 = tf.add(tf.matmul(layer_1, weights[\'h2\']), biases[\'b2\'])\n    # Output fully connected layer with a neuron for each class\n    out_layer = tf.matmul(layer_2, weights[\'out\']) + biases[\'out\']\n    return out_layer\n\n# Construct model\nlogits = neural_net(X)\nprediction = tf.nn.softmax(logits)\n\n# Define loss and optimizer\nloss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n    logits=logits, labels=Y))\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\ntrain_op = optimizer.minimize(loss_op)\n\n# Evaluate model\ncorrect_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\n# Initialize the variables (i.e. assign their default value)\ninit = tf.global_variables_initializer()\n\n# Start training\nwith tf.Session() as sess:\n\n    # Run the initializer\n    sess.run(init)\n\n    for step in range(1, num_steps+1):\n        batch_x, batch_y = mnist.train.next_batch(batch_size)\n        # Run optimization op (backprop)\n        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n        if step % display_step == 0 or step == 1:\n            # Calculate batch loss and accuracy\n            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n                                                                 Y: batch_y})\n            print(""Step "" + str(step) + "", Minibatch Loss= "" + \\\n                  ""{:.4f}"".format(loss) + "", Training Accuracy= "" + \\\n                  ""{:.3f}"".format(acc))\n\n    print(""Optimization Finished!"")\n\n    # Calculate accuracy for MNIST test images\n    print(""Testing Accuracy:"", \\\n        sess.run(accuracy, feed_dict={X: mnist.test.images,\n                                      Y: mnist.test.labels}))\n'"
tensorflow_v1/examples/3_NeuralNetworks/recurrent_network.py,14,"b'"""""" Recurrent Neural Network.\n\nA Recurrent Neural Network (LSTM) implementation example using TensorFlow library.\nThis example is using the MNIST database of handwritten digits (http://yann.lecun.com/exdb/mnist/)\n\nLinks:\n    [Long Short Term Memory](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf)\n    [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n""""""\n\nfrom __future__ import print_function\n\nimport tensorflow as tf\nfrom tensorflow.contrib import rnn\n\n# Import MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""/tmp/data/"", one_hot=True)\n\n\'\'\'\nTo classify images using a recurrent neural network, we consider every image\nrow as a sequence of pixels. Because MNIST image shape is 28*28px, we will then\nhandle 28 sequences of 28 steps for every sample.\n\'\'\'\n\n# Training Parameters\nlearning_rate = 0.001\ntraining_steps = 10000\nbatch_size = 128\ndisplay_step = 200\n\n# Network Parameters\nnum_input = 28 # MNIST data input (img shape: 28*28)\ntimesteps = 28 # timesteps\nnum_hidden = 128 # hidden layer num of features\nnum_classes = 10 # MNIST total classes (0-9 digits)\n\n# tf Graph input\nX = tf.placeholder(""float"", [None, timesteps, num_input])\nY = tf.placeholder(""float"", [None, num_classes])\n\n# Define weights\nweights = {\n    \'out\': tf.Variable(tf.random_normal([num_hidden, num_classes]))\n}\nbiases = {\n    \'out\': tf.Variable(tf.random_normal([num_classes]))\n}\n\n\ndef RNN(x, weights, biases):\n\n    # Prepare data shape to match `rnn` function requirements\n    # Current data input shape: (batch_size, timesteps, n_input)\n    # Required shape: \'timesteps\' tensors list of shape (batch_size, n_input)\n\n    # Unstack to get a list of \'timesteps\' tensors of shape (batch_size, n_input)\n    x = tf.unstack(x, timesteps, 1)\n\n    # Define a lstm cell with tensorflow\n    lstm_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n\n    # Get lstm cell output\n    outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n\n    # Linear activation, using rnn inner loop last output\n    return tf.matmul(outputs[-1], weights[\'out\']) + biases[\'out\']\n\nlogits = RNN(X, weights, biases)\nprediction = tf.nn.softmax(logits)\n\n# Define loss and optimizer\nloss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n    logits=logits, labels=Y))\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\ntrain_op = optimizer.minimize(loss_op)\n\n# Evaluate model (with test logits, for dropout to be disabled)\ncorrect_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\n# Initialize the variables (i.e. assign their default value)\ninit = tf.global_variables_initializer()\n\n# Start training\nwith tf.Session() as sess:\n\n    # Run the initializer\n    sess.run(init)\n\n    for step in range(1, training_steps+1):\n        batch_x, batch_y = mnist.train.next_batch(batch_size)\n        # Reshape data to get 28 seq of 28 elements\n        batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n        # Run optimization op (backprop)\n        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n        if step % display_step == 0 or step == 1:\n            # Calculate batch loss and accuracy\n            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n                                                                 Y: batch_y})\n            print(""Step "" + str(step) + "", Minibatch Loss= "" + \\\n                  ""{:.4f}"".format(loss) + "", Training Accuracy= "" + \\\n                  ""{:.3f}"".format(acc))\n\n    print(""Optimization Finished!"")\n\n    # Calculate accuracy for 128 mnist test images\n    test_len = 128\n    test_data = mnist.test.images[:test_len].reshape((-1, timesteps, num_input))\n    test_label = mnist.test.labels[:test_len]\n    print(""Testing Accuracy:"", \\\n        sess.run(accuracy, feed_dict={X: test_data, Y: test_label}))\n'"
tensorflow_v1/examples/3_NeuralNetworks/variational_autoencoder.py,36,"b'"""""" Variational Auto-Encoder Example.\n\nUsing a variational auto-encoder to generate digits images from noise.\nMNIST handwritten digits are used as training examples.\n\nReferences:\n    - Auto-Encoding Variational Bayes The International Conference on Learning\n    Representations (ICLR), Banff, 2014. D.P. Kingma, M. Welling\n    - Understanding the difficulty of training deep feedforward neural networks.\n    X Glorot, Y Bengio. Aistats 9, 249-256\n    - Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. ""Gradient-based\n    learning applied to document recognition."" Proceedings of the IEEE,\n    86(11):2278-2324, November 1998.\n\nLinks:\n    - [VAE Paper] https://arxiv.org/abs/1312.6114\n    - [Xavier Glorot Init](www.cs.cmu.edu/~bhiksha/courses/deeplearning/Fall.../AISTATS2010_Glorot.pdf).\n    - [MNIST Dataset] http://yann.lecun.com/exdb/mnist/\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n""""""\nfrom __future__ import division, print_function, absolute_import\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\nimport tensorflow as tf\n\n# Import MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""/tmp/data/"", one_hot=True)\n\n# Parameters\nlearning_rate = 0.001\nnum_steps = 30000\nbatch_size = 64\n\n# Network Parameters\nimage_dim = 784 # MNIST images are 28x28 pixels\nhidden_dim = 512\nlatent_dim = 2\n\n# A custom initialization (see Xavier Glorot init)\ndef glorot_init(shape):\n    return tf.random_normal(shape=shape, stddev=1. / tf.sqrt(shape[0] / 2.))\n\n# Variables\nweights = {\n    \'encoder_h1\': tf.Variable(glorot_init([image_dim, hidden_dim])),\n    \'z_mean\': tf.Variable(glorot_init([hidden_dim, latent_dim])),\n    \'z_std\': tf.Variable(glorot_init([hidden_dim, latent_dim])),\n    \'decoder_h1\': tf.Variable(glorot_init([latent_dim, hidden_dim])),\n    \'decoder_out\': tf.Variable(glorot_init([hidden_dim, image_dim]))\n}\nbiases = {\n    \'encoder_b1\': tf.Variable(glorot_init([hidden_dim])),\n    \'z_mean\': tf.Variable(glorot_init([latent_dim])),\n    \'z_std\': tf.Variable(glorot_init([latent_dim])),\n    \'decoder_b1\': tf.Variable(glorot_init([hidden_dim])),\n    \'decoder_out\': tf.Variable(glorot_init([image_dim]))\n}\n\n# Building the encoder\ninput_image = tf.placeholder(tf.float32, shape=[None, image_dim])\nencoder = tf.matmul(input_image, weights[\'encoder_h1\']) + biases[\'encoder_b1\']\nencoder = tf.nn.tanh(encoder)\nz_mean = tf.matmul(encoder, weights[\'z_mean\']) + biases[\'z_mean\']\nz_std = tf.matmul(encoder, weights[\'z_std\']) + biases[\'z_std\']\n\n# Sampler: Normal (gaussian) random distribution\neps = tf.random_normal(tf.shape(z_std), dtype=tf.float32, mean=0., stddev=1.0,\n                       name=\'epsilon\')\nz = z_mean + tf.exp(z_std / 2) * eps\n\n# Building the decoder (with scope to re-use these layers later)\ndecoder = tf.matmul(z, weights[\'decoder_h1\']) + biases[\'decoder_b1\']\ndecoder = tf.nn.tanh(decoder)\ndecoder = tf.matmul(decoder, weights[\'decoder_out\']) + biases[\'decoder_out\']\ndecoder = tf.nn.sigmoid(decoder)\n\n\n# Define VAE Loss\ndef vae_loss(x_reconstructed, x_true):\n    # Reconstruction loss\n    encode_decode_loss = x_true * tf.log(1e-10 + x_reconstructed) \\\n                         + (1 - x_true) * tf.log(1e-10 + 1 - x_reconstructed)\n    encode_decode_loss = -tf.reduce_sum(encode_decode_loss, 1)\n    # KL Divergence loss\n    kl_div_loss = 1 + z_std - tf.square(z_mean) - tf.exp(z_std)\n    kl_div_loss = -0.5 * tf.reduce_sum(kl_div_loss, 1)\n    return tf.reduce_mean(encode_decode_loss + kl_div_loss)\n\nloss_op = vae_loss(decoder, input_image)\noptimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate)\ntrain_op = optimizer.minimize(loss_op)\n\n# Initialize the variables (i.e. assign their default value)\ninit = tf.global_variables_initializer()\n\n# Start training\nwith tf.Session() as sess:\n\n    # Run the initializer\n    sess.run(init)\n\n    for i in range(1, num_steps+1):\n        # Prepare Data\n        # Get the next batch of MNIST data (only images are needed, not labels)\n        batch_x, _ = mnist.train.next_batch(batch_size)\n\n        # Train\n        feed_dict = {input_image: batch_x}\n        _, l = sess.run([train_op, loss_op], feed_dict=feed_dict)\n        if i % 1000 == 0 or i == 1:\n            print(\'Step %i, Loss: %f\' % (i, l))\n\n    # Testing\n    # Generator takes noise as input\n    noise_input = tf.placeholder(tf.float32, shape=[None, latent_dim])\n    # Rebuild the decoder to create image from noise\n    decoder = tf.matmul(noise_input, weights[\'decoder_h1\']) + biases[\'decoder_b1\']\n    decoder = tf.nn.tanh(decoder)\n    decoder = tf.matmul(decoder, weights[\'decoder_out\']) + biases[\'decoder_out\']\n    decoder = tf.nn.sigmoid(decoder)\n\n    # Building a manifold of generated digits\n    n = 20\n    x_axis = np.linspace(-3, 3, n)\n    y_axis = np.linspace(-3, 3, n)\n\n    canvas = np.empty((28 * n, 28 * n))\n    for i, yi in enumerate(x_axis):\n        for j, xi in enumerate(y_axis):\n            z_mu = np.array([[xi, yi]] * batch_size)\n            x_mean = sess.run(decoder, feed_dict={noise_input: z_mu})\n            canvas[(n - i - 1) * 28:(n - i) * 28, j * 28:(j + 1) * 28] = \\\n            x_mean[0].reshape(28, 28)\n\n    plt.figure(figsize=(8, 10))\n    Xi, Yi = np.meshgrid(x_axis, y_axis)\n    plt.imshow(canvas, origin=""upper"", cmap=""gray"")\n    plt.show()\n'"
tensorflow_v1/examples/4_Utils/save_restore_model.py,23,"b'\'\'\'\nSave and Restore a model using TensorFlow.\nThis example is using the MNIST database of handwritten digits\n(http://yann.lecun.com/exdb/mnist/)\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n\'\'\'\n\nfrom __future__ import print_function\n\n# Import MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""MNIST_data/"", one_hot=True)\n\nimport tensorflow as tf\n\n# Parameters\nlearning_rate = 0.001\nbatch_size = 100\ndisplay_step = 1\nmodel_path = ""/tmp/model.ckpt""\n\n# Network Parameters\nn_hidden_1 = 256 # 1st layer number of features\nn_hidden_2 = 256 # 2nd layer number of features\nn_input = 784 # MNIST data input (img shape: 28*28)\nn_classes = 10 # MNIST total classes (0-9 digits)\n\n# tf Graph input\nx = tf.placeholder(""float"", [None, n_input])\ny = tf.placeholder(""float"", [None, n_classes])\n\n\n# Create model\ndef multilayer_perceptron(x, weights, biases):\n    # Hidden layer with RELU activation\n    layer_1 = tf.add(tf.matmul(x, weights[\'h1\']), biases[\'b1\'])\n    layer_1 = tf.nn.relu(layer_1)\n    # Hidden layer with RELU activation\n    layer_2 = tf.add(tf.matmul(layer_1, weights[\'h2\']), biases[\'b2\'])\n    layer_2 = tf.nn.relu(layer_2)\n    # Output layer with linear activation\n    out_layer = tf.matmul(layer_2, weights[\'out\']) + biases[\'out\']\n    return out_layer\n\n# Store layers weight & bias\nweights = {\n    \'h1\': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n    \'h2\': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n    \'out\': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n}\nbiases = {\n    \'b1\': tf.Variable(tf.random_normal([n_hidden_1])),\n    \'b2\': tf.Variable(tf.random_normal([n_hidden_2])),\n    \'out\': tf.Variable(tf.random_normal([n_classes]))\n}\n\n# Construct model\npred = multilayer_perceptron(x, weights, biases)\n\n# Define loss and optimizer\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n\n# Initialize the variables (i.e. assign their default value)\ninit = tf.global_variables_initializer()\n\n# \'Saver\' op to save and restore all the variables\nsaver = tf.train.Saver()\n\n# Running first session\nprint(""Starting 1st session..."")\nwith tf.Session() as sess:\n\n    # Run the initializer\n    sess.run(init)\n\n    # Training cycle\n    for epoch in range(3):\n        avg_cost = 0.\n        total_batch = int(mnist.train.num_examples/batch_size)\n        # Loop over all batches\n        for i in range(total_batch):\n            batch_x, batch_y = mnist.train.next_batch(batch_size)\n            # Run optimization op (backprop) and cost op (to get loss value)\n            _, c = sess.run([optimizer, cost], feed_dict={x: batch_x,\n                                                          y: batch_y})\n            # Compute average loss\n            avg_cost += c / total_batch\n        # Display logs per epoch step\n        if epoch % display_step == 0:\n            print(""Epoch:"", \'%04d\' % (epoch+1), ""cost="", \\\n                ""{:.9f}"".format(avg_cost))\n    print(""First Optimization Finished!"")\n\n    # Test model\n    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n    # Calculate accuracy\n    accuracy = tf.reduce_mean(tf.cast(correct_prediction, ""float""))\n    print(""Accuracy:"", accuracy.eval({x: mnist.test.images, y: mnist.test.labels}))\n\n    # Save model weights to disk\n    save_path = saver.save(sess, model_path)\n    print(""Model saved in file: %s"" % save_path)\n\n# Running a new session\nprint(""Starting 2nd session..."")\nwith tf.Session() as sess:\n    # Initialize variables\n    sess.run(init)\n\n    # Restore model weights from previously saved model\n    saver.restore(sess, model_path)\n    print(""Model restored from file: %s"" % save_path)\n\n    # Resume training\n    for epoch in range(7):\n        avg_cost = 0.\n        total_batch = int(mnist.train.num_examples / batch_size)\n        # Loop over all batches\n        for i in range(total_batch):\n            batch_x, batch_y = mnist.train.next_batch(batch_size)\n            # Run optimization op (backprop) and cost op (to get loss value)\n            _, c = sess.run([optimizer, cost], feed_dict={x: batch_x,\n                                                          y: batch_y})\n            # Compute average loss\n            avg_cost += c / total_batch\n        # Display logs per epoch step\n        if epoch % display_step == 0:\n            print(""Epoch:"", \'%04d\' % (epoch + 1), ""cost="", \\\n                ""{:.9f}"".format(avg_cost))\n    print(""Second Optimization Finished!"")\n\n    # Test model\n    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n    # Calculate accuracy\n    accuracy = tf.reduce_mean(tf.cast(correct_prediction, ""float""))\n    print(""Accuracy:"", accuracy.eval(\n        {x: mnist.test.images, y: mnist.test.labels}))\n'"
tensorflow_v1/examples/4_Utils/tensorboard_advanced.py,35,"b'\'\'\'\nGraph and Loss visualization using Tensorboard.\nThis example is using the MNIST database of handwritten digits\n(http://yann.lecun.com/exdb/mnist/)\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n\'\'\'\n\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\n# Import MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""/tmp/data/"", one_hot=True)\n\n# Parameters\nlearning_rate = 0.01\ntraining_epochs = 25\nbatch_size = 100\ndisplay_step = 1\nlogs_path = \'/tmp/tensorflow_logs/example/\'\n\n# Network Parameters\nn_hidden_1 = 256 # 1st layer number of features\nn_hidden_2 = 256 # 2nd layer number of features\nn_input = 784 # MNIST data input (img shape: 28*28)\nn_classes = 10 # MNIST total classes (0-9 digits)\n\n# tf Graph Input\n# mnist data image of shape 28*28=784\nx = tf.placeholder(tf.float32, [None, 784], name=\'InputData\')\n# 0-9 digits recognition => 10 classes\ny = tf.placeholder(tf.float32, [None, 10], name=\'LabelData\')\n\n\n# Create model\ndef multilayer_perceptron(x, weights, biases):\n    # Hidden layer with RELU activation\n    layer_1 = tf.add(tf.matmul(x, weights[\'w1\']), biases[\'b1\'])\n    layer_1 = tf.nn.relu(layer_1)\n    # Create a summary to visualize the first layer ReLU activation\n    tf.summary.histogram(""relu1"", layer_1)\n    # Hidden layer with RELU activation\n    layer_2 = tf.add(tf.matmul(layer_1, weights[\'w2\']), biases[\'b2\'])\n    layer_2 = tf.nn.relu(layer_2)\n    # Create another summary to visualize the second layer ReLU activation\n    tf.summary.histogram(""relu2"", layer_2)\n    # Output layer\n    out_layer = tf.add(tf.matmul(layer_2, weights[\'w3\']), biases[\'b3\'])\n    return out_layer\n\n# Store layers weight & bias\nweights = {\n    \'w1\': tf.Variable(tf.random_normal([n_input, n_hidden_1]), name=\'W1\'),\n    \'w2\': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2]), name=\'W2\'),\n    \'w3\': tf.Variable(tf.random_normal([n_hidden_2, n_classes]), name=\'W3\')\n}\nbiases = {\n    \'b1\': tf.Variable(tf.random_normal([n_hidden_1]), name=\'b1\'),\n    \'b2\': tf.Variable(tf.random_normal([n_hidden_2]), name=\'b2\'),\n    \'b3\': tf.Variable(tf.random_normal([n_classes]), name=\'b3\')\n}\n\n# Encapsulating all ops into scopes, making Tensorboard\'s Graph\n# Visualization more convenient\nwith tf.name_scope(\'Model\'):\n    # Build model\n    pred = multilayer_perceptron(x, weights, biases)\n\nwith tf.name_scope(\'Loss\'):\n    # Softmax Cross entropy (cost function)\n    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n\nwith tf.name_scope(\'SGD\'):\n    # Gradient Descent\n    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n    # Op to calculate every variable gradient\n    grads = tf.gradients(loss, tf.trainable_variables())\n    grads = list(zip(grads, tf.trainable_variables()))\n    # Op to update all variables according to their gradient\n    apply_grads = optimizer.apply_gradients(grads_and_vars=grads)\n\nwith tf.name_scope(\'Accuracy\'):\n    # Accuracy\n    acc = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n    acc = tf.reduce_mean(tf.cast(acc, tf.float32))\n\n# Initialize the variables (i.e. assign their default value)\ninit = tf.global_variables_initializer()\n\n# Create a summary to monitor cost tensor\ntf.summary.scalar(""loss"", loss)\n# Create a summary to monitor accuracy tensor\ntf.summary.scalar(""accuracy"", acc)\n# Create summaries to visualize weights\nfor var in tf.trainable_variables():\n    tf.summary.histogram(var.name, var)\n# Summarize all gradients\nfor grad, var in grads:\n    tf.summary.histogram(var.name + \'/gradient\', grad)\n# Merge all summaries into a single op\nmerged_summary_op = tf.summary.merge_all()\n\n# Start training\nwith tf.Session() as sess:\n\n    # Run the initializer\n    sess.run(init)\n\n    # op to write logs to Tensorboard\n    summary_writer = tf.summary.FileWriter(logs_path,\n                                            graph=tf.get_default_graph())\n\n    # Training cycle\n    for epoch in range(training_epochs):\n        avg_cost = 0.\n        total_batch = int(mnist.train.num_examples/batch_size)\n        # Loop over all batches\n        for i in range(total_batch):\n            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n            # Run optimization op (backprop), cost op (to get loss value)\n            # and summary nodes\n            _, c, summary = sess.run([apply_grads, loss, merged_summary_op],\n                                     feed_dict={x: batch_xs, y: batch_ys})\n            # Write logs at every iteration\n            summary_writer.add_summary(summary, epoch * total_batch + i)\n            # Compute average loss\n            avg_cost += c / total_batch\n        # Display logs per epoch step\n        if (epoch+1) % display_step == 0:\n            print(""Epoch:"", \'%04d\' % (epoch+1), ""cost="", ""{:.9f}"".format(avg_cost))\n\n    print(""Optimization Finished!"")\n\n    # Test model\n    # Calculate accuracy\n    print(""Accuracy:"", acc.eval({x: mnist.test.images, y: mnist.test.labels}))\n\n    print(""Run the command line:\\n"" \\\n          ""--> tensorboard --logdir=/tmp/tensorflow_logs "" \\\n          ""\\nThen open http://0.0.0.0:6006/ into your web browser"")\n'"
tensorflow_v1/examples/4_Utils/tensorboard_basic.py,19,"b'\'\'\'\nGraph and Loss visualization using Tensorboard.\nThis example is using the MNIST database of handwritten digits\n(http://yann.lecun.com/exdb/mnist/)\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n\'\'\'\n\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\n# Import MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""/tmp/data/"", one_hot=True)\n\n# Parameters\nlearning_rate = 0.01\ntraining_epochs = 25\nbatch_size = 100\ndisplay_epoch = 1\nlogs_path = \'/tmp/tensorflow_logs/example/\'\n\n# tf Graph Input\n# mnist data image of shape 28*28=784\nx = tf.placeholder(tf.float32, [None, 784], name=\'InputData\')\n# 0-9 digits recognition => 10 classes\ny = tf.placeholder(tf.float32, [None, 10], name=\'LabelData\')\n\n# Set model weights\nW = tf.Variable(tf.zeros([784, 10]), name=\'Weights\')\nb = tf.Variable(tf.zeros([10]), name=\'Bias\')\n\n# Construct model and encapsulating all ops into scopes, making\n# Tensorboard\'s Graph visualization more convenient\nwith tf.name_scope(\'Model\'):\n    # Model\n    pred = tf.nn.softmax(tf.matmul(x, W) + b) # Softmax\nwith tf.name_scope(\'Loss\'):\n    # Minimize error using cross entropy\n    cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred), reduction_indices=1))\nwith tf.name_scope(\'SGD\'):\n    # Gradient Descent\n    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\nwith tf.name_scope(\'Accuracy\'):\n    # Accuracy\n    acc = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n    acc = tf.reduce_mean(tf.cast(acc, tf.float32))\n\n# Initialize the variables (i.e. assign their default value)\ninit = tf.global_variables_initializer()\n\n# Create a summary to monitor cost tensor\ntf.summary.scalar(""loss"", cost)\n# Create a summary to monitor accuracy tensor\ntf.summary.scalar(""accuracy"", acc)\n# Merge all summaries into a single op\nmerged_summary_op = tf.summary.merge_all()\n\n# Start training\nwith tf.Session() as sess:\n\n    # Run the initializer\n    sess.run(init)\n\n    # op to write logs to Tensorboard\n    summary_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n\n    # Training cycle\n    for epoch in range(training_epochs):\n        avg_cost = 0.\n        total_batch = int(mnist.train.num_examples/batch_size)\n        # Loop over all batches\n        for i in range(total_batch):\n            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n            # Run optimization op (backprop), cost op (to get loss value)\n            # and summary nodes\n            _, c, summary = sess.run([optimizer, cost, merged_summary_op],\n                                     feed_dict={x: batch_xs, y: batch_ys})\n            # Write logs at every iteration\n            summary_writer.add_summary(summary, epoch * total_batch + i)\n            # Compute average loss\n            avg_cost += c / total_batch\n        # Display logs per epoch step\n        if (epoch+1) % display_epoch == 0:\n            print(""Epoch:"", \'%04d\' % (epoch+1), ""cost="", ""{:.9f}"".format(avg_cost))\n\n    print(""Optimization Finished!"")\n\n    # Test model\n    # Calculate accuracy\n    print(""Accuracy:"", acc.eval({x: mnist.test.images, y: mnist.test.labels}))\n\n    print(""Run the command line:\\n"" \\\n          ""--> tensorboard --logdir=/tmp/tensorflow_logs "" \\\n          ""\\nThen open http://0.0.0.0:6006/ into your web browser"")\n'"
tensorflow_v1/examples/5_DataManagement/build_an_image_dataset.py,25,"b'"""""" Build an Image Dataset in TensorFlow.\n\nFor this example, you need to make your own set of images (JPEG).\nWe will show 2 different ways to build that dataset:\n\n- From a root folder, that will have a sub-folder containing images for each class\n    ```\n    ROOT_FOLDER\n       |-------- SUBFOLDER (CLASS 0)\n       |             |\n       |             | ----- image1.jpg\n       |             | ----- image2.jpg\n       |             | ----- etc...\n       |             \n       |-------- SUBFOLDER (CLASS 1)\n       |             |\n       |             | ----- image1.jpg\n       |             | ----- image2.jpg\n       |             | ----- etc...\n    ```\n\n- From a plain text file, that will list all images with their class ID:\n    ```\n    /path/to/image/1.jpg CLASS_ID\n    /path/to/image/2.jpg CLASS_ID\n    /path/to/image/3.jpg CLASS_ID\n    /path/to/image/4.jpg CLASS_ID\n    etc...\n    ```\n\nBelow, there are some parameters that you need to change (Marked \'CHANGE HERE\'), \nsuch as the dataset path.\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n""""""\nfrom __future__ import print_function\n\nimport tensorflow as tf\nimport os\n\n# Dataset Parameters - CHANGE HERE\nMODE = \'folder\' # or \'file\', if you choose a plain text file (see above).\nDATASET_PATH = \'/path/to/dataset/\' # the dataset file or root folder path.\n\n# Image Parameters\nN_CLASSES = 2 # CHANGE HERE, total number of classes\nIMG_HEIGHT = 64 # CHANGE HERE, the image height to be resized to\nIMG_WIDTH = 64 # CHANGE HERE, the image width to be resized to\nCHANNELS = 3 # The 3 color channels, change to 1 if grayscale\n\n\n# Reading the dataset\n# 2 modes: \'file\' or \'folder\'\ndef read_images(dataset_path, mode, batch_size):\n    imagepaths, labels = list(), list()\n    if mode == \'file\':\n        # Read dataset file\n        with open(dataset_path) as f:\n            data = f.read().splitlines()\n        for d in data:\n            imagepaths.append(d.split(\' \')[0])\n            labels.append(int(d.split(\' \')[1]))\n    elif mode == \'folder\':\n        # An ID will be affected to each sub-folders by alphabetical order\n        label = 0\n        # List the directory\n        try:  # Python 2\n            classes = sorted(os.walk(dataset_path).next()[1])\n        except Exception:  # Python 3\n            classes = sorted(os.walk(dataset_path).__next__()[1])\n        # List each sub-directory (the classes)\n        for c in classes:\n            c_dir = os.path.join(dataset_path, c)\n            try:  # Python 2\n                walk = os.walk(c_dir).next()\n            except Exception:  # Python 3\n                walk = os.walk(c_dir).__next__()\n            # Add each image to the training set\n            for sample in walk[2]:\n                # Only keeps jpeg images\n                if sample.endswith(\'.jpg\') or sample.endswith(\'.jpeg\'):\n                    imagepaths.append(os.path.join(c_dir, sample))\n                    labels.append(label)\n            label += 1\n    else:\n        raise Exception(""Unknown mode."")\n\n    # Convert to Tensor\n    imagepaths = tf.convert_to_tensor(imagepaths, dtype=tf.string)\n    labels = tf.convert_to_tensor(labels, dtype=tf.int32)\n    # Build a TF Queue, shuffle data\n    image, label = tf.train.slice_input_producer([imagepaths, labels],\n                                                 shuffle=True)\n\n    # Read images from disk\n    image = tf.read_file(image)\n    image = tf.image.decode_jpeg(image, channels=CHANNELS)\n\n    # Resize images to a common size\n    image = tf.image.resize_images(image, [IMG_HEIGHT, IMG_WIDTH])\n\n    # Normalize\n    image = image * 1.0/127.5 - 1.0\n\n    # Create batches\n    X, Y = tf.train.batch([image, label], batch_size=batch_size,\n                          capacity=batch_size * 8,\n                          num_threads=4)\n\n    return X, Y\n\n# -----------------------------------------------\n# THIS IS A CLASSIC CNN (see examples, section 3)\n# -----------------------------------------------\n# Note that a few elements have changed (usage of queues).\n\n# Parameters\nlearning_rate = 0.001\nnum_steps = 10000\nbatch_size = 128\ndisplay_step = 100\n\n# Network Parameters\ndropout = 0.75 # Dropout, probability to keep units\n\n# Build the data input\nX, Y = read_images(DATASET_PATH, MODE, batch_size)\n\n\n# Create model\ndef conv_net(x, n_classes, dropout, reuse, is_training):\n    # Define a scope for reusing the variables\n    with tf.variable_scope(\'ConvNet\', reuse=reuse):\n\n        # Convolution Layer with 32 filters and a kernel size of 5\n        conv1 = tf.layers.conv2d(x, 32, 5, activation=tf.nn.relu)\n        # Max Pooling (down-sampling) with strides of 2 and kernel size of 2\n        conv1 = tf.layers.max_pooling2d(conv1, 2, 2)\n\n        # Convolution Layer with 32 filters and a kernel size of 5\n        conv2 = tf.layers.conv2d(conv1, 64, 3, activation=tf.nn.relu)\n        # Max Pooling (down-sampling) with strides of 2 and kernel size of 2\n        conv2 = tf.layers.max_pooling2d(conv2, 2, 2)\n\n        # Flatten the data to a 1-D vector for the fully connected layer\n        fc1 = tf.contrib.layers.flatten(conv2)\n\n        # Fully connected layer (in contrib folder for now)\n        fc1 = tf.layers.dense(fc1, 1024)\n        # Apply Dropout (if is_training is False, dropout is not applied)\n        fc1 = tf.layers.dropout(fc1, rate=dropout, training=is_training)\n\n        # Output layer, class prediction\n        out = tf.layers.dense(fc1, n_classes)\n        # Because \'softmax_cross_entropy_with_logits\' already apply softmax,\n        # we only apply softmax to testing network\n        out = tf.nn.softmax(out) if not is_training else out\n\n    return out\n\n\n# Because Dropout have different behavior at training and prediction time, we\n# need to create 2 distinct computation graphs that share the same weights.\n\n# Create a graph for training\nlogits_train = conv_net(X, N_CLASSES, dropout, reuse=False, is_training=True)\n# Create another graph for testing that reuse the same weights\nlogits_test = conv_net(X, N_CLASSES, dropout, reuse=True, is_training=False)\n\n# Define loss and optimizer (with train logits, for dropout to take effect)\nloss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n    logits=logits_train, labels=Y))\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\ntrain_op = optimizer.minimize(loss_op)\n\n# Evaluate model (with test logits, for dropout to be disabled)\ncorrect_pred = tf.equal(tf.argmax(logits_test, 1), tf.cast(Y, tf.int64))\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\n# Initialize the variables (i.e. assign their default value)\ninit = tf.global_variables_initializer()\n\n# Saver object\nsaver = tf.train.Saver()\n\n# Start training\nwith tf.Session() as sess:\n\n    # Run the initializer\n    sess.run(init)\n\n    # Start the data queue\n    tf.train.start_queue_runners()\n\n    # Training cycle\n    for step in range(1, num_steps+1):\n\n        if step % display_step == 0:\n            # Run optimization and calculate batch loss and accuracy\n            _, loss, acc = sess.run([train_op, loss_op, accuracy])\n            print(""Step "" + str(step) + "", Minibatch Loss= "" + \\\n                  ""{:.4f}"".format(loss) + "", Training Accuracy= "" + \\\n                  ""{:.3f}"".format(acc))\n        else:\n            # Only run the optimization op (backprop)\n            sess.run(train_op)\n\n    print(""Optimization Finished!"")\n\n    # Save your model\n    saver.save(sess, \'my_tf_model\')\n'"
tensorflow_v1/examples/5_DataManagement/tensorflow_dataset_api.py,18,"b'"""""" TensorFlow Dataset API.\n\nIn this example, we will show how to load numpy array data into the new \nTensorFlow \'Dataset\' API. The Dataset API implements an optimized data pipeline\nwith queues, that make data processing and training faster (especially on GPU).\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n""""""\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\n# Import MNIST data (Numpy format)\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""/tmp/data/"", one_hot=True)\n\n# Parameters\nlearning_rate = 0.001\nnum_steps = 2000\nbatch_size = 128\ndisplay_step = 100\n\n# Network Parameters\nn_input = 784 # MNIST data input (img shape: 28*28)\nn_classes = 10 # MNIST total classes (0-9 digits)\ndropout = 0.75 # Dropout, probability to keep units\n\nsess = tf.Session()\n\n# Create a dataset tensor from the images and the labels\ndataset = tf.data.Dataset.from_tensor_slices(\n    (mnist.train.images, mnist.train.labels))\n# Automatically refill the data queue when empty\ndataset = dataset.repeat()\n# Create batches of data\ndataset = dataset.batch(batch_size)\n# Prefetch data for faster consumption\ndataset = dataset.prefetch(batch_size)\n\n# Create an iterator over the dataset\niterator = dataset.make_initializable_iterator()\n# Initialize the iterator\nsess.run(iterator.initializer)\n\n# Neural Net Input (images, labels)\nX, Y = iterator.get_next()\n\n\n# -----------------------------------------------\n# THIS IS A CLASSIC CNN (see examples, section 3)\n# -----------------------------------------------\n# Note that a few elements have changed (usage of sess run).\n\n# Create model\ndef conv_net(x, n_classes, dropout, reuse, is_training):\n    # Define a scope for reusing the variables\n    with tf.variable_scope(\'ConvNet\', reuse=reuse):\n        # MNIST data input is a 1-D vector of 784 features (28*28 pixels)\n        # Reshape to match picture format [Height x Width x Channel]\n        # Tensor input become 4-D: [Batch Size, Height, Width, Channel]\n        x = tf.reshape(x, shape=[-1, 28, 28, 1])\n\n        # Convolution Layer with 32 filters and a kernel size of 5\n        conv1 = tf.layers.conv2d(x, 32, 5, activation=tf.nn.relu)\n        # Max Pooling (down-sampling) with strides of 2 and kernel size of 2\n        conv1 = tf.layers.max_pooling2d(conv1, 2, 2)\n\n        # Convolution Layer with 32 filters and a kernel size of 5\n        conv2 = tf.layers.conv2d(conv1, 64, 3, activation=tf.nn.relu)\n        # Max Pooling (down-sampling) with strides of 2 and kernel size of 2\n        conv2 = tf.layers.max_pooling2d(conv2, 2, 2)\n\n        # Flatten the data to a 1-D vector for the fully connected layer\n        fc1 = tf.contrib.layers.flatten(conv2)\n\n        # Fully connected layer (in contrib folder for now)\n        fc1 = tf.layers.dense(fc1, 1024)\n        # Apply Dropout (if is_training is False, dropout is not applied)\n        fc1 = tf.layers.dropout(fc1, rate=dropout, training=is_training)\n\n        # Output layer, class prediction\n        out = tf.layers.dense(fc1, n_classes)\n        # Because \'softmax_cross_entropy_with_logits\' already apply softmax,\n        # we only apply softmax to testing network\n        out = tf.nn.softmax(out) if not is_training else out\n\n    return out\n\n\n# Because Dropout have different behavior at training and prediction time, we\n# need to create 2 distinct computation graphs that share the same weights.\n\n# Create a graph for training\nlogits_train = conv_net(X, n_classes, dropout, reuse=False, is_training=True)\n# Create another graph for testing that reuse the same weights, but has\n# different behavior for \'dropout\' (not applied).\nlogits_test = conv_net(X, n_classes, dropout, reuse=True, is_training=False)\n\n# Define loss and optimizer (with train logits, for dropout to take effect)\nloss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n    logits=logits_train, labels=Y))\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\ntrain_op = optimizer.minimize(loss_op)\n\n# Evaluate model (with test logits, for dropout to be disabled)\ncorrect_pred = tf.equal(tf.argmax(logits_test, 1), tf.argmax(Y, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\n# Initialize the variables (i.e. assign their default value)\ninit = tf.global_variables_initializer()\n\n# Run the initializer\nsess.run(init)\n\n# Training cycle\nfor step in range(1, num_steps + 1):\n\n    # Run optimization\n    sess.run(train_op)\n\n    if step % display_step == 0 or step == 1:\n        # Calculate batch loss and accuracy\n        # (note that this consume a new batch of data)\n        loss, acc = sess.run([loss_op, accuracy])\n        print(""Step "" + str(step) + "", Minibatch Loss= "" + \\\n              ""{:.4f}"".format(loss) + "", Training Accuracy= "" + \\\n              ""{:.3f}"".format(acc))\n\nprint(""Optimization Finished!"")\n'"
tensorflow_v1/examples/6_MultiGPU/multigpu_basics.py,14,"b'from __future__ import print_function\n\'\'\'\nBasic Multi GPU computation example using TensorFlow library.\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n\'\'\'\n\n\'\'\'\nThis tutorial requires your machine to have 2 GPUs\n""/cpu:0"": The CPU of your machine.\n""/gpu:0"": The first GPU of your machine\n""/gpu:1"": The second GPU of your machine\n\'\'\'\n\n\n\nimport numpy as np\nimport tensorflow as tf\nimport datetime\n\n# Processing Units logs\nlog_device_placement = True\n\n# Num of multiplications to perform\nn = 10\n\n\'\'\'\nExample: compute A^n + B^n on 2 GPUs\nResults on 8 cores with 2 GTX-980:\n * Single GPU computation time: 0:00:11.277449\n * Multi GPU computation time: 0:00:07.131701\n\'\'\'\n# Create random large matrix\nA = np.random.rand(10000, 10000).astype(\'float32\')\nB = np.random.rand(10000, 10000).astype(\'float32\')\n\n# Create a graph to store results\nc1 = []\nc2 = []\n\ndef matpow(M, n):\n    if n < 1: #Abstract cases where n < 1\n        return M\n    else:\n        return tf.matmul(M, matpow(M, n-1))\n\n\'\'\'\nSingle GPU computing\n\'\'\'\nwith tf.device(\'/gpu:0\'):\n    a = tf.placeholder(tf.float32, [10000, 10000])\n    b = tf.placeholder(tf.float32, [10000, 10000])\n    # Compute A^n and B^n and store results in c1\n    c1.append(matpow(a, n))\n    c1.append(matpow(b, n))\n\nwith tf.device(\'/cpu:0\'):\n  sum = tf.add_n(c1) #Addition of all elements in c1, i.e. A^n + B^n\n\nt1_1 = datetime.datetime.now()\nwith tf.Session(config=tf.ConfigProto(log_device_placement=log_device_placement)) as sess:\n    # Run the op.\n    sess.run(sum, {a:A, b:B})\nt2_1 = datetime.datetime.now()\n\n\n\'\'\'\nMulti GPU computing\n\'\'\'\n# GPU:0 computes A^n\nwith tf.device(\'/gpu:0\'):\n    # Compute A^n and store result in c2\n    a = tf.placeholder(tf.float32, [10000, 10000])\n    c2.append(matpow(a, n))\n\n# GPU:1 computes B^n\nwith tf.device(\'/gpu:1\'):\n    # Compute B^n and store result in c2\n    b = tf.placeholder(tf.float32, [10000, 10000])\n    c2.append(matpow(b, n))\n\nwith tf.device(\'/cpu:0\'):\n  sum = tf.add_n(c2) #Addition of all elements in c2, i.e. A^n + B^n\n\nt1_2 = datetime.datetime.now()\nwith tf.Session(config=tf.ConfigProto(log_device_placement=log_device_placement)) as sess:\n    # Run the op.\n    sess.run(sum, {a:A, b:B})\nt2_2 = datetime.datetime.now()\n\n\nprint(""Single GPU computation time: "" + str(t2_1-t1_1))\nprint(""Multi GPU computation time: "" + str(t2_2-t1_2))\n'"
tensorflow_v1/examples/6_MultiGPU/multigpu_cnn.py,28,"b'\'\'\' Multi-GPU Training Example.\n\nTrain a convolutional neural network on multiple GPU with TensorFlow.\n\nThis example is using TensorFlow layers, see \'convolutional_network_raw\' example\nfor a raw TensorFlow implementation with variables.\n\nThis example is using the MNIST database of handwritten digits\n(http://yann.lecun.com/exdb/mnist/)\n\nAuthor: Aymeric Damien\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\n\'\'\'\n\nfrom __future__ import division, print_function, absolute_import\n\nimport numpy as np\nimport tensorflow as tf\nimport time\n\n# Import MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""/tmp/data/"", one_hot=True)\n\n# Training Parameters\nnum_gpus = 2\nnum_steps = 200\nlearning_rate = 0.001\nbatch_size = 1024\ndisplay_step = 10\n\n# Network Parameters\nnum_input = 784 # MNIST data input (img shape: 28*28)\nnum_classes = 10 # MNIST total classes (0-9 digits)\ndropout = 0.75 # Dropout, probability to keep units\n\n\n# Build a convolutional neural network\ndef conv_net(x, n_classes, dropout, reuse, is_training):\n    # Define a scope for reusing the variables\n    with tf.variable_scope(\'ConvNet\', reuse=reuse):\n        # MNIST data input is a 1-D vector of 784 features (28*28 pixels)\n        # Reshape to match picture format [Height x Width x Channel]\n        # Tensor input become 4-D: [Batch Size, Height, Width, Channel]\n        x = tf.reshape(x, shape=[-1, 28, 28, 1])\n\n        # Convolution Layer with 64 filters and a kernel size of 5\n        x = tf.layers.conv2d(x, 64, 5, activation=tf.nn.relu)\n        # Max Pooling (down-sampling) with strides of 2 and kernel size of 2\n        x = tf.layers.max_pooling2d(x, 2, 2)\n\n        # Convolution Layer with 256 filters and a kernel size of 5\n        x = tf.layers.conv2d(x, 256, 3, activation=tf.nn.relu)\n        # Convolution Layer with 512 filters and a kernel size of 5\n        x = tf.layers.conv2d(x, 512, 3, activation=tf.nn.relu)\n        # Max Pooling (down-sampling) with strides of 2 and kernel size of 2\n        x = tf.layers.max_pooling2d(x, 2, 2)\n\n        # Flatten the data to a 1-D vector for the fully connected layer\n        x = tf.contrib.layers.flatten(x)\n\n        # Fully connected layer (in contrib folder for now)\n        x = tf.layers.dense(x, 2048)\n        # Apply Dropout (if is_training is False, dropout is not applied)\n        x = tf.layers.dropout(x, rate=dropout, training=is_training)\n\n        # Fully connected layer (in contrib folder for now)\n        x = tf.layers.dense(x, 1024)\n        # Apply Dropout (if is_training is False, dropout is not applied)\n        x = tf.layers.dropout(x, rate=dropout, training=is_training)\n\n        # Output layer, class prediction\n        out = tf.layers.dense(x, n_classes)\n        # Because \'softmax_cross_entropy_with_logits\' loss already apply\n        # softmax, we only apply softmax to testing network\n        out = tf.nn.softmax(out) if not is_training else out\n\n    return out\n\n\ndef average_gradients(tower_grads):\n    average_grads = []\n    for grad_and_vars in zip(*tower_grads):\n        # Note that each grad_and_vars looks like the following:\n        #   ((grad0_gpu0, var0_gpu0), ... , (grad0_gpuN, var0_gpuN))\n        grads = []\n        for g, _ in grad_and_vars:\n            # Add 0 dimension to the gradients to represent the tower.\n            expanded_g = tf.expand_dims(g, 0)\n\n            # Append on a \'tower\' dimension which we will average over below.\n            grads.append(expanded_g)\n\n        # Average over the \'tower\' dimension.\n        grad = tf.concat(grads, 0)\n        grad = tf.reduce_mean(grad, 0)\n\n        # Keep in mind that the Variables are redundant because they are shared\n        # across towers. So .. we will just return the first tower\'s pointer to\n        # the Variable.\n        v = grad_and_vars[0][1]\n        grad_and_var = (grad, v)\n        average_grads.append(grad_and_var)\n    return average_grads\n\n\n# By default, all variables will be placed on \'/gpu:0\'\n# So we need a custom device function, to assign all variables to \'/cpu:0\'\n# Note: If GPUs are peered, \'/gpu:0\' can be a faster option\nPS_OPS = [\'Variable\', \'VariableV2\', \'AutoReloadVariable\']\n\ndef assign_to_device(device, ps_device=\'/cpu:0\'):\n    def _assign(op):\n        node_def = op if isinstance(op, tf.NodeDef) else op.node_def\n        if node_def.op in PS_OPS:\n            return ""/"" + ps_device\n        else:\n            return device\n\n    return _assign\n\n\n# Place all ops on CPU by default\nwith tf.device(\'/cpu:0\'):\n    tower_grads = []\n    reuse_vars = False\n\n    # tf Graph input\n    X = tf.placeholder(tf.float32, [None, num_input])\n    Y = tf.placeholder(tf.float32, [None, num_classes])\n\n    # Loop over all GPUs and construct their own computation graph\n    for i in range(num_gpus):\n        with tf.device(assign_to_device(\'/gpu:{}\'.format(i), ps_device=\'/cpu:0\')):\n\n            # Split data between GPUs\n            _x = X[i * batch_size: (i+1) * batch_size]\n            _y = Y[i * batch_size: (i+1) * batch_size]\n\n            # Because Dropout have different behavior at training and prediction time, we\n            # need to create 2 distinct computation graphs that share the same weights.\n\n            # Create a graph for training\n            logits_train = conv_net(_x, num_classes, dropout,\n                                    reuse=reuse_vars, is_training=True)\n            # Create another graph for testing that reuse the same weights\n            logits_test = conv_net(_x, num_classes, dropout,\n                                   reuse=True, is_training=False)\n\n            # Define loss and optimizer (with train logits, for dropout to take effect)\n            loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n                logits=logits_train, labels=_y))\n            optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n            grads = optimizer.compute_gradients(loss_op)\n\n            # Only first GPU compute accuracy\n            if i == 0:\n                # Evaluate model (with test logits, for dropout to be disabled)\n                correct_pred = tf.equal(tf.argmax(logits_test, 1), tf.argmax(_y, 1))\n                accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\n            reuse_vars = True\n            tower_grads.append(grads)\n\n    tower_grads = average_gradients(tower_grads)\n    train_op = optimizer.apply_gradients(tower_grads)\n\n    # Initialize the variables (i.e. assign their default value)\n    init = tf.global_variables_initializer()\n\n    # Start Training\n    with tf.Session() as sess:\n\n        # Run the initializer\n        sess.run(init)\n\n        # Keep training until reach max iterations\n        for step in range(1, num_steps + 1):\n            # Get a batch for each GPU\n            batch_x, batch_y = mnist.train.next_batch(batch_size * num_gpus)\n            # Run optimization op (backprop)\n            ts = time.time()\n            sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n            te = time.time() - ts\n            if step % display_step == 0 or step == 1:\n                # Calculate batch loss and accuracy\n                loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n                                                                     Y: batch_y})\n                print(""Step "" + str(step) + "": Minibatch Loss= "" + \\\n                      ""{:.4f}"".format(loss) + "", Training Accuracy= "" + \\\n                      ""{:.3f}"".format(acc) + "", %i Examples/sec"" % int(len(batch_x)/te))\n            step += 1\n        print(""Optimization Finished!"")\n\n        # Calculate accuracy for MNIST test images\n        print(""Testing Accuracy:"", \\\n            np.mean([sess.run(accuracy, feed_dict={X: mnist.test.images[i:i+batch_size],\n            Y: mnist.test.labels[i:i+batch_size]}) for i in range(0, len(mnist.test.images), batch_size)]))\n'"
