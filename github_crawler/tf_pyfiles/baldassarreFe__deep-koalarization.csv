file_path,api_count,code
setup.py,0,"b'""""""setup script""""""\nfrom setuptools import setup, find_packages\nimport os\nimport glob\n\nthis_directory = os.path.abspath(os.path.dirname(__file__))\nwith open(os.path.join(this_directory, ""README.md"")) as f:\n    long_description = f.read()\n\nwith open(os.path.join(this_directory, ""requirements.txt"")) as f:\n    requirements = f.readlines()\n\nsetup(\n    name=""deep-koalarization"",\n    version=""0.2.0"",\n    description=""Keras/Tensorflow implementation of our paper Grayscale Image Colorization using deep CNN and ""\n    ""Inception-ResNet-v2"",\n    long_description=long_description,\n    long_description_content_type=""text/markdown"",\n    url=""http://github.com/baldassarreFe/deep-koalarization"",\n    author=""Federico Baldassare, Diego Gonz\xc3\xa1lez Mor\xc3\xadn, Lucas Rod\xc3\xa9s-Guirao"",\n    license=""GPL-v3"",\n    install_requires=requirements,\n    extras_require={""gpu"": [""tensorflow-gpu==1.3.0""]},\n    packages=find_packages(""src""),\n    package_dir={"""": ""src""},\n    # namespace_packages=[\'koalarization\'],\n    py_modules=[\n        os.path.splitext(os.path.basename(path))[0] for path in glob.glob(""src/*.py"")\n    ],\n    include_package_data=True,\n    zip_safe=False,\n    classifiers=[\n        ""Development Status :: 3 - Alpha"",\n        ""Programming Language :: Python :: 3.6"",\n    ],\n    keywords=""Image colorization using Deep Learning CNNs"",\n    project_urls={\n        ""Website"": ""https://lcsrg.me/deep-koalarization"",\n        ""Github"": ""http://github.com/baldassarreFe/deep-koalarization"",\n    },\n    python_requires="">=3.5"",\n)\n'"
tests/__init__.py,0,b''
src/koalarization/__init__.py,0,"b'from koalarization.fusion_layer import FusionLayer\nfrom koalarization.network_definition import Colorization\nfrom koalarization.training_utils import (\n    l_to_rgb,\n    evaluation_pipeline,\n    plot_evaluation,\n    lab_to_rgb,\n)\n\n__all__ = [\n    ""FusionLayer"",\n    ""Colorization"",\n    ""l_to_rgb"",\n    ""evaluation_pipeline"",\n    ""plot_evaluation"",\n    ""lab_to_rgb"",\n]\n\n__version__ = ""0.2.0""\n__import__(""pkg_resources"").declare_namespace(__name__)\n'"
src/koalarization/evaluate.py,5,"b'import argparse\nfrom pathlib import Path\n\nimport tensorflow as tf\nfrom keras import backend as K\n\nfrom .network_definition import Colorization\nfrom .training_utils import (\n    evaluation_pipeline,\n    checkpointing_system,\n    plot_evaluation,\n    metrics_system,\n)\n\nparser = argparse.ArgumentParser(description=""Eval"")\nparser.add_argument(\n    ""tfrecords"",\n    type=str,\n    metavar=""TFRECORDS_DIR"",\n    help=""evaluate using all tfrecords in TFRECORDS_DIR"",\n)\nparser.add_argument(\n    ""output"",\n    type=str,\n    metavar=""OUR_DIR"",\n    help=""use OUR_DIR to load checkpoints and write images"",\n)\nparser.add_argument(\n    ""--run-id"",\n    required=True,\n    type=str,\n    metavar=""RUN_ID"",\n    help=""load checkpoint from the run RUN_ID"",\n)\nargs = parser.parse_args()\ndir_tfrecords = Path(args.tfrecords).expanduser().resolve().as_posix()\ndir_output = Path(args.output).expanduser().resolve().joinpath(args.run_id).as_posix()\n\n# PARAMETERS\nrun_id = args.run_id\nval_number_of_images = 100\n\n# START\nsess = tf.Session()\nK.set_session(sess)\n\n# Build the network and the various operations\ncol = Colorization(256)\nevaluations_ops = evaluation_pipeline(col, val_number_of_images, dir_tfrecords)\nsummary_writer = metrics_system(sess, dir_output)\nsaver, checkpoint_paths, latest_checkpoint = checkpointing_system(dir_output)\n\nwith sess.as_default():\n    # Initialize\n    sess.run(tf.global_variables_initializer())\n    sess.run(tf.local_variables_initializer())\n\n    # Coordinate the loading of image files.\n    coord = tf.train.Coordinator()\n    threads = tf.train.start_queue_runners(coord=coord)\n\n    # Restore\n    if latest_checkpoint is not None:\n        print(f""Restoring from: {latest_checkpoint}"")\n        saver.restore(sess, latest_checkpoint)\n    else:\n        print(f""No checkpoint found in: {checkpoint_paths}"")\n        exit(1)\n\n    res = sess.run(evaluations_ops)\n    print(""Cost: {}"".format(res[""cost""]))\n    plot_evaluation(res, ""eval"", dir_output)\n\n    # Finish off the filename queue coordinator.\n    coord.request_stop()\n    coord.join(threads)\n'"
src/koalarization/fusion_layer.py,0,"b'from keras import backend as K\nfrom keras.engine import Layer\n\n\nclass FusionLayer(Layer):\n    def call(self, inputs, mask=None):\n        imgs, embs = inputs\n        reshaped_shape = imgs.shape[:3].concatenate(embs.shape[1])\n        embs = K.repeat(embs, imgs.shape[1] * imgs.shape[2])\n        embs = K.reshape(embs, reshaped_shape)\n        return K.concatenate([imgs, embs], axis=3)\n\n    def compute_output_shape(self, input_shapes):\n        # Must have 2 tensors as input\n        assert input_shapes and len(input_shapes) == 2\n        imgs_shape, embs_shape = input_shapes\n\n        # The batch size of the two tensors must match\n        assert imgs_shape[0] == embs_shape[0]\n\n        # (batch_size, width, height, embedding_len + depth)\n        return imgs_shape[:3] + (imgs_shape[3] + embs_shape[1],)\n'"
src/koalarization/network_definition.py,0,"b'""""""\nGiven the L channel of an Lab image (range [-1, +1]), output a prediction over\nthe a and b channels in the range [-1, 1].\nIn the neck of the conv-deconv network use the features from a feature extractor\n(e.g. Inception) and fuse them with the conv output.\n""""""\n\nfrom keras.engine import InputLayer\nfrom keras.layers import Conv2D, UpSampling2D\nfrom keras.models import Sequential\n\nfrom .fusion_layer import FusionLayer\n\n\nclass Colorization:\n    def __init__(self, depth_after_fusion):\n        self.encoder = _build_encoder()\n        self.fusion = FusionLayer()\n        self.after_fusion = Conv2D(depth_after_fusion, (1, 1), activation=""relu"")\n        self.decoder = _build_decoder(depth_after_fusion)\n\n    def build(self, img_l, img_emb):\n        img_enc = self.encoder(img_l)\n\n        fusion = self.fusion([img_enc, img_emb])\n        fusion = self.after_fusion(fusion)\n\n        return self.decoder(fusion)\n\n\ndef _build_encoder():\n    model = Sequential(name=""encoder"")\n    model.add(InputLayer(input_shape=(None, None, 1)))\n    model.add(Conv2D(64, (3, 3), activation=""relu"", padding=""same"", strides=2))\n    model.add(Conv2D(128, (3, 3), activation=""relu"", padding=""same""))\n    model.add(Conv2D(128, (3, 3), activation=""relu"", padding=""same"", strides=2))\n    model.add(Conv2D(256, (3, 3), activation=""relu"", padding=""same""))\n    model.add(Conv2D(256, (3, 3), activation=""relu"", padding=""same"", strides=2))\n    model.add(Conv2D(512, (3, 3), activation=""relu"", padding=""same""))\n    model.add(Conv2D(512, (3, 3), activation=""relu"", padding=""same""))\n    model.add(Conv2D(256, (3, 3), activation=""relu"", padding=""same""))\n    return model\n\n\ndef _build_decoder(encoding_depth):\n    model = Sequential(name=""decoder"")\n    model.add(InputLayer(input_shape=(None, None, encoding_depth)))\n    model.add(Conv2D(128, (3, 3), activation=""relu"", padding=""same""))\n    model.add(UpSampling2D((2, 2)))\n    model.add(Conv2D(64, (3, 3), activation=""relu"", padding=""same""))\n    model.add(Conv2D(64, (3, 3), activation=""relu"", padding=""same""))\n    model.add(UpSampling2D((2, 2)))\n    model.add(Conv2D(32, (3, 3), activation=""relu"", padding=""same""))\n    model.add(Conv2D(2, (3, 3), activation=""tanh"", padding=""same""))\n    model.add(UpSampling2D((2, 2)))\n    return model\n'"
src/koalarization/train.py,5,"b'import argparse\nfrom pathlib import Path\n\nimport tensorflow as tf\nfrom keras import backend as K\n\nfrom .network_definition import Colorization\nfrom .training_utils import (\n    evaluation_pipeline,\n    checkpointing_system,\n    plot_evaluation,\n    training_pipeline,\n    metrics_system,\n    Logger,\n)\n\nparser = argparse.ArgumentParser(description=""Train"")\nparser.add_argument(\n    ""tfrecords"",\n    type=str,\n    metavar=""TFRECORDS_DIR"",\n    help=""train using all tfrecords in TFRECORDS_DIR"",\n)\nparser.add_argument(\n    ""output"",\n    type=str,\n    metavar=""OUR_DIR"",\n    help=""save metrics and checkpoints in OUR_DIR"",\n)\nparser.add_argument(\n    ""--run-id"", type=str, required=True, metavar=""RUN_ID"", help=""unique run identifier""\n)\nparser.add_argument(\n    ""--train-steps"",\n    type=int,\n    required=True,\n    metavar=""STEPS"",\n    help=""train for STEPS steps"",\n)\nparser.add_argument(\n    ""--val-every"",\n    type=int,\n    required=True,\n    metavar=""STEPS"",\n    help=""run validation and save checkpoint every STEPS steps"",\n)\nargs = parser.parse_args()\ndir_tfrecords = Path(args.tfrecords).expanduser().resolve().as_posix()\ndir_output = Path(args.output).expanduser().resolve().joinpath(args.run_id).as_posix()\n\n# PARAMETERS\nrun_id = args.run_id\nval_number_of_images = 10\nbatch_size = 100\nlearning_rate = 0.001\n\n# START\nsess = tf.Session()\nK.set_session(sess)\n\n# Build the network and the various operations\ncol = Colorization(256)\nopt_operations = training_pipeline(col, learning_rate, batch_size, dir_tfrecords)\nevaluations_ops = evaluation_pipeline(col, val_number_of_images, dir_tfrecords)\nsummary_writer = metrics_system(sess, dir_output)\nsaver, checkpoint_paths, latest_checkpoint = checkpointing_system(dir_output)\nlogger = Logger(f""{dir_output}/output.txt"")\n\nwith sess.as_default():\n    # Initialize\n    sess.run(tf.global_variables_initializer())\n    sess.run(tf.local_variables_initializer())\n\n    # Coordinate the loading of image files.\n    coord = tf.train.Coordinator()\n    threads = tf.train.start_queue_runners(coord=coord)\n\n    # Restore\n    if latest_checkpoint is not None:\n        logger.write(""Restoring from: {}"".format(latest_checkpoint))\n        saver.restore(sess, latest_checkpoint)\n        logger.write("" done!"")\n    else:\n        logger.write(""No checkpoint found in: {}"".format(checkpoint_paths))\n\n    # Training loop\n    for batch_idx in range(args.train_steps):\n        logger.write(f""Batch: {batch_idx}/{args.train_steps}"")\n        res = sess.run(opt_operations)\n        global_step = res[""global_step""]\n        logger.write(f\'Cost: {res[""cost""]} Global step: {global_step}\')\n        summary_writer.add_summary(res[""summary""], global_step)\n\n        if (batch_idx + 1) % args.val_every == 0:\n            # Save the variables to disk\n            save_path = saver.save(sess, checkpoint_paths, global_step)\n            logger.write(""Model saved in: %s"" % save_path)\n\n            # Evaluation step\n            res = sess.run(evaluations_ops)\n            summary_writer.add_summary(res[""summary""], global_step)\n            plot_evaluation(res, global_step, dir_output)\n\n    # Finish off the filename queue coordinator.\n    coord.request_stop()\n    coord.join(threads)\n'"
src/koalarization/training_utils.py,7,"b'import pickle\nimport time\nfrom os.path import join\n\nimport matplotlib\nimport numpy as np\nimport tensorflow as tf\nfrom skimage import color\n\nfrom .dataset.labels import inception_labels\nfrom .dataset.shared import maybe_create_folder\nfrom .dataset.tfrecords import LabImageRecordReader\n\nmatplotlib.use(""Agg"")\nmatplotlib.rcParams[""figure.figsize""] = (10.0, 4.0)\nimport matplotlib.pyplot as plt\n\n\ndef loss_with_metrics(img_ab_out, img_ab_true, name=""""):\n    # Loss is mean square erros\n    cost = tf.reduce_mean(tf.squared_difference(img_ab_out, img_ab_true), name=""mse"")\n    # Metrics for tensorboard\n    summary = tf.summary.scalar(""cost "" + name, cost)\n    return cost, summary\n\n\ndef training_pipeline(col, learning_rate, batch_size, dir_tfrecord):\n    # Set up training (input queues, graph, optimizer)\n    irr = LabImageRecordReader(""lab_images_*.tfrecord"", dir_tfrecord)\n    read_batched_examples = irr.read_batch(batch_size, shuffle=True)\n    # read_batched_examples = irr.read_one()\n    imgs_l = read_batched_examples[""image_l""]\n    imgs_true_ab = read_batched_examples[""image_ab""]\n    imgs_emb = read_batched_examples[""image_embedding""]\n    imgs_ab = col.build(imgs_l, imgs_emb)\n    cost, summary = loss_with_metrics(imgs_ab, imgs_true_ab, ""training"")\n    global_step = tf.Variable(0, name=""global_step"", trainable=False)\n    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(\n        cost, global_step=global_step\n    )\n    return {\n        ""global_step"": global_step,\n        ""optimizer"": optimizer,\n        ""cost"": cost,\n        ""summary"": summary,\n    }  # , irr, read_batched_examples\n\n\ndef evaluation_pipeline(col, number_of_images, dir_tfrecord):\n    # Set up validation (input queues, graph)\n    irr = LabImageRecordReader(""val_lab_images_*.tfrecord"", dir_tfrecord)\n    read_batched_examples = irr.read_batch(number_of_images, shuffle=False)\n    imgs_l_val = read_batched_examples[""image_l""]\n    imgs_true_ab_val = read_batched_examples[""image_ab""]\n    imgs_emb_val = read_batched_examples[""image_embedding""]\n    imgs_ab_val = col.build(imgs_l_val, imgs_emb_val)\n    cost, summary = loss_with_metrics(imgs_ab_val, imgs_true_ab_val, ""validation"")\n    return {\n        ""imgs_l"": imgs_l_val,\n        ""imgs_ab"": imgs_ab_val,\n        ""imgs_true_ab"": imgs_true_ab_val,\n        ""imgs_emb"": imgs_emb_val,\n        ""cost"": cost,\n        ""summary"": summary,\n    }\n\n\nclass Logger(object):\n    def __init__(self, path):\n        self.f = open(path, ""a"")\n\n    def write(self, text):\n        self.f.write(f\'[{time.strftime(""%c"")}] {text}\\n\')\n        self.f.flush()\n\n\ndef metrics_system(sess, dir_metrics):\n    # Merge all the summaries and set up the writers\n    train_writer = tf.summary.FileWriter(dir_metrics, sess.graph)\n    return train_writer\n\n\ndef checkpointing_system(dir_checkpoints):\n    # Add ops to save and restore all the variables.\n    saver = tf.train.Saver()\n    latest_checkpoint = tf.train.latest_checkpoint(dir_checkpoints)\n    checkpoint_paths = join(dir_checkpoints, ""weights"")\n    return saver, checkpoint_paths, latest_checkpoint\n\n\ndef plot_evaluation(res, global_step, dir_images):\n    maybe_create_folder(dir_images)\n    for k in range(len(res[""imgs_l""])):\n        img_gray = l_to_rgb(res[""imgs_l""][k][:, :, 0])\n        img_output = lab_to_rgb(res[""imgs_l""][k][:, :, 0], res[""imgs_ab""][k])\n        img_true = lab_to_rgb(res[""imgs_l""][k][:, :, 0], res[""imgs_true_ab""][k])\n        top_5 = np.argsort(res[""imgs_emb""][k])[-5:]\n        try:\n            top_5 = "" / "".join(inception_labels[i] for i in top_5)\n        except:\n            ptop_5 = str(top_5)\n\n        plt.subplot(1, 3, 1)\n        plt.imshow(img_gray)\n        plt.title(""Input (grayscale)"")\n        plt.axis(""off"")\n        plt.subplot(1, 3, 2)\n        plt.imshow(img_output)\n        plt.title(""Network output"")\n        plt.axis(""off"")\n        plt.subplot(1, 3, 3)\n        plt.imshow(img_true)\n        plt.title(""Target (original)"")\n        plt.axis(""off"")\n        plt.suptitle(top_5, fontsize=7)\n\n        plt.savefig(join(dir_images, f""{global_step}_{k}.png""))\n        plt.clf()\n        plt.close()\n\n\ndef l_to_rgb(img_l):\n    """"""\n    Convert a numpy array (l channel) into an rgb image\n    :param img_l:\n    :return:\n    """"""\n    lab = np.squeeze(255 * (img_l + 1) / 2)\n    return color.gray2rgb(lab) / 255\n\n\ndef lab_to_rgb(img_l, img_ab):\n    """"""\n    Convert a pair of numpy arrays (l channel and ab channels) into an rgb image\n    :param img_l:\n    :return:\n    """"""\n    lab = np.empty([*img_l.shape[0:2], 3])\n    lab[:, :, 0] = np.squeeze(((img_l + 1) * 50))\n    lab[:, :, 1:] = img_ab * 127\n    return color.lab2rgb(lab)\n'"
tests/batching/__init__.py,0,b''
tests/batching/test_filename_queues.py,6,"b'import time\nimport unittest\n\nimport tensorflow as tf\n\nfrom koalarization.dataset.tfrecords import queue_single_images_from_folder\n\n\nDIR_RESIZED = \'./tests/data/resized/\'\n\n\nclass TestFilenameQueues(unittest.TestCase):\n    def test_one(self):\n        """"""Load all images from a folder once and print the result.""""""\n        # Create the queue operations\n        image_key, image_tensor, image_shape = queue_single_images_from_folder(\n            DIR_RESIZED\n        )\n\n        # Start a new session to run the operations\n        with tf.Session() as sess:\n            sess.run(tf.global_variables_initializer())\n            sess.run(tf.local_variables_initializer())\n\n            # Coordinate the loading of image files.\n            coord = tf.train.Coordinator()\n            threads = tf.train.start_queue_runners(coord=coord)\n            count = 0\n            start_time = time.time()\n\n            # These are the only lines where something happens:\n            # we execute the operations to get one image and print everything.\n            try:\n                while not coord.should_stop():\n                    key, img, shape = sess.run([image_key, image_tensor, image_shape])\n                    print(key)\n                    count += 1\n            except tf.errors.OutOfRangeError:\n                # It\'s all right, it\'s just the string_input_producer queue telling\n                # us that it has run out of strings\n                pass\n            finally:\n                # Ask the threads (filename queue) to stop.\n                coord.request_stop()\n                print(\n                    ""Finished listing {} pairs in {:.2f}s"".format(\n                        count, time.time() - start_time\n                    )\n                )\n\n            # Wait for threads to finish.\n            coord.join(threads)\n\n\nif __name__ == ""__main__"":\n    unittest.main()\n'"
tests/batching/test_write_read_base.py,10,"b'""""""\nWrite some simple type examples in a tfrecord, then read them one at the time\nor in batch (all the tensors have the same shape, so this is ok)\n\nRun from the top folder as:\npython3 -m tests.batching.test_write_read_base\n""""""\nimport unittest\n\nimport tensorflow as tf\n\nfrom koalarization.dataset.tfrecords import RecordWriter, BatchableRecordReader\n\n\nDIR_TFRECORDS = \'./tests/data/tfrecords\'\n\n\nclass BaseTypesRecordWriter(RecordWriter):\n    def write_test(self, i):\n        example = tf.train.Example(\n            features=tf.train.Features(\n                feature={\n                    ""string"": self._bytes_feature(""hey {}"".format(i).encode(""ascii"")),\n                    ""int"": self._int64(42),\n                    ""float"": self._float32(3.14),\n                }\n            )\n        )\n        self.write(example.SerializeToString())\n\n\nclass BaseTypesRecordReader(BatchableRecordReader):\n    """"""\n    All the tensors returned have fixed shape, so the read operations\n    are batchable\n    """"""\n\n    def _create_read_operation(self):\n        features = tf.parse_single_example(\n            self._tfrecord_serialized,\n            features={\n                ""string"": tf.FixedLenFeature([], tf.string),\n                ""int"": tf.FixedLenFeature([], tf.int64),\n                ""float"": tf.FixedLenFeature([], tf.float32),\n            },\n        )\n\n        return {\n            ""string"": features[""string""],\n            ""int"": features[""int""],\n            ""float"": features[""float""],\n        }\n\n\nclass TestBaseRecords(unittest.TestCase):\n    number_of_records = 5\n    samples_per_record = 10\n\n    def test_base_records(self):\n        # WRITING\n        for i in range(self.number_of_records):\n            record_name = ""base_type_{}.tfrecord"".format(i)\n            with BaseTypesRecordWriter(record_name, DIR_TFRECORDS) as writer:\n                for j in range(self.samples_per_record):\n                    writer.write_test(i * self.number_of_records + j)\n\n        # READING\n        # Important: read_batch MUST be called before start_queue_runners,\n        # otherwise the internal shuffle queue gets created but its\n        # threads won\'t start\n\n        reader = BaseTypesRecordReader(""base_type_*.tfrecord"", DIR_TFRECORDS)\n        read_one_example = reader.read_operation\n        read_batched_examples = reader.read_batch(50)\n\n        with tf.Session() as sess:\n            sess.run(\n                [tf.global_variables_initializer(), tf.local_variables_initializer()]\n            )\n\n            # Coordinate the queue of tfrecord files.\n            coord = tf.train.Coordinator()\n            threads = tf.train.start_queue_runners(coord=coord)\n\n            # Reading examples sequentially one by one\n            for j in range(50):\n                fetches = sess.run(read_one_example)\n                print(""Read:"", fetches)\n\n            # Reading a batch of examples\n            results = sess.run(read_batched_examples)\n            for i in range(len(results[""string""])):\n                print(\n                    results[""string""][i],\n                    results[""int""][i],\n                    results[""float""][i],\n                    sep=""\\t"",\n                )\n\n            # Finish off the queue coordinator.\n            coord.request_stop()\n            coord.join(threads)\n\n\nif __name__ == ""__main__"":\n    unittest.main()\n'"
tests/batching/test_write_read_fixed.py,13,"b'""""""\nWrite some fixed size examples in a tfrecord, then read them one at the time\nor in batch (all the tensors have the same shape, so this is ok)\n\nRun from the top folder as:\npython3 -m tests.batching.test_write_read_fixed\n""""""\nimport unittest\n\nimport numpy as np\nimport tensorflow as tf\n\nfrom koalarization.dataset.tfrecords import RecordWriter, BatchableRecordReader\n\n\nDIR_TFRECORDS = \'./tests/data/tfrecords\'\n\n\nclass FixedSizeTypesRecordWriter(RecordWriter):\n    def write_test(self):\n        # Fixed size lists\n        list_ints = np.array([4, 8, 15, 16, 23, 42], dtype=np.int64)\n        list_floats = np.array([2.71, 3.14], dtype=np.float32)\n\n        # Fixed size matrices (will be flattened before serializing)\n        mat_ints = np.arange(6, dtype=np.int64).reshape(2, 3)\n        mat_floats = np.random.random((3, 2)).astype(np.float32)\n\n        example = tf.train.Example(\n            features=tf.train.Features(\n                feature={\n                    ""list_ints"": self._int64_list(list_ints),\n                    ""list_floats"": self._float32_list(list_floats),\n                    ""mat_ints"": self._int64_list(mat_ints.flatten()),\n                    ""mat_floats"": self._float32_list(mat_floats.flatten()),\n                }\n            )\n        )\n        self.write(example.SerializeToString())\n\n\nclass FixedSizeTypesRecordReader(BatchableRecordReader):\n    """"""\n    All the tensors returned have fixed shape, so the read operations\n    are batchable\n    """"""\n\n    def _create_read_operation(self):\n        features = tf.parse_single_example(\n            self._tfrecord_serialized,\n            features={\n                ""list_ints"": tf.FixedLenFeature([6], tf.int64),\n                ""list_floats"": tf.FixedLenFeature([2], tf.float32),\n                ""mat_ints"": tf.FixedLenFeature([6], tf.int64),\n                ""mat_floats"": tf.FixedLenFeature([6], tf.float32),\n            },\n        )\n\n        return {\n            ""list_ints"": features[""list_ints""],\n            ""list_floats"": features[""list_floats""],\n            ""mat_ints"": tf.reshape(features[""mat_ints""], [2, 3]),\n            ""mat_floats"": tf.reshape(features[""mat_floats""], [3, 2]),\n        }\n\n\nclass TestFixedSizeRecords(unittest.TestCase):\n    def test_fixed_size_record(self):\n        # WRITING\n        with FixedSizeTypesRecordWriter(""fixed_size.tfrecord"", DIR_TFRECORDS) as writer:\n            writer.write_test()\n            writer.write_test()\n\n        # READING\n        # Important: read_batch MUST be called before start_queue_runners,\n        # otherwise the internal shuffle queue gets created but its\n        # threads won\'t start\n        reader = FixedSizeTypesRecordReader(""fixed_size.tfrecord"", DIR_TFRECORDS)\n        read_one_example = reader.read_operation\n        read_batched_examples = reader.read_batch(4)\n\n        with tf.Session() as sess:\n            sess.run(\n                [tf.global_variables_initializer(), tf.local_variables_initializer()]\n            )\n\n            # Coordinate the queue of tfrecord files.\n            coord = tf.train.Coordinator()\n            threads = tf.train.start_queue_runners(coord=coord)\n\n            # Reading examples sequentially one by one\n            for j in range(3):\n                fetches = sess.run(read_one_example)\n                print(""Read:"", fetches)\n\n            # Reading a batch of examples\n            results = sess.run(read_batched_examples)\n            print(results)\n\n            # Finish off the queue coordinator.\n            coord.request_stop()\n            coord.join(threads)\n\n\nif __name__ == ""__main__"":\n    unittest.main()\n'"
tests/batching/test_write_read_lab_image.py,10,"b'""""""\nRead and show single images from a tfrecord\n\nRun from the top folder as:\npython3 -m tests.batching.test_write_read_lab_image\n""""""\nimport time\nimport unittest\nfrom os.path import basename\n\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\nfrom koalarization import l_to_rgb\nfrom koalarization import lab_to_rgb\nfrom koalarization.dataset.tfrecords import LabImageRecordReader\nfrom koalarization.dataset.tfrecords import LabImageRecordWriter\nfrom koalarization.dataset.tfrecords import queue_single_images_from_folder\n\n\nDIR_RESIZED = \'./tests/data/resized/\'\nDIR_TFRECORDS = \'./tests/data/tfrecords\'\n\n\nclass TestLabImageWriteRead(unittest.TestCase):\n    def test_lab_image_write_read(self):\n        self._lab_image_write()\n        self._lab_image_read()\n\n    def _lab_image_write(self):\n        # Create the queue operations\n        img_key, img_tensor, _ = queue_single_images_from_folder(DIR_RESIZED)\n        img_emb = tf.truncated_normal(shape=[1001])\n\n        # Create a writer to write_image the images\n        lab_writer = LabImageRecordWriter(""test_lab_images.tfrecord"", DIR_TFRECORDS)\n\n        # Start a new session to run the operations\n        with tf.Session() as sess:\n            sess.run(\n                [tf.global_variables_initializer(), tf.local_variables_initializer()]\n            )\n\n            # Coordinate the loading of image files.\n            coord = tf.train.Coordinator()\n            threads = tf.train.start_queue_runners(coord=coord)\n\n            count = 0\n            start_time = time.time()\n            try:\n                while not coord.should_stop():\n                    key, img, emb = sess.run([img_key, img_tensor, img_emb])\n                    lab_writer.write_image(key, img, emb)\n                    print(""Written: {}"".format(key))\n                    count += 1\n                    # Just write 10 images\n                    if count > 10:\n                        break\n            except tf.errors.OutOfRangeError:\n                # The string_input_producer queue ran out of strings\n                pass\n            finally:\n                # Ask the threads (filename queue) to stop.\n                coord.request_stop()\n                print(\n                    ""Finished writing {} images in {:.2f}s"".format(\n                        count, time.time() - start_time\n                    )\n                )\n\n            # Wait for threads to finish.\n            coord.join(threads)\n\n        lab_writer.close()\n\n    def _lab_image_read(self):\n        # Important: read_batch MUST be called before start_queue_runners,\n        # otherwise the internal shuffle queue gets created but its\n        # threads won\'t start\n        irr = LabImageRecordReader(""test_lab_images.tfrecord"", DIR_TFRECORDS)\n        read_one_example = irr.read_operation\n        read_batched_examples = irr.read_batch(20)\n\n        with tf.Session() as sess:\n            sess.run(\n                [tf.global_variables_initializer(), tf.local_variables_initializer()]\n            )\n\n            # Coordinate the loading of image files.\n            coord = tf.train.Coordinator()\n            threads = tf.train.start_queue_runners(coord=coord)\n\n            # Reading images sequentially one by one\n            for i in range(0, 12, 2):\n                res = sess.run(read_one_example)\n                img = lab_to_rgb(res[""image_l""], res[""image_ab""])\n                img_gray = l_to_rgb(res[""image_l""])\n                plt.subplot(3, 4, i + 1)\n                plt.imshow(img_gray)\n                plt.axis(""off"")\n                plt.subplot(3, 4, i + 2)\n                plt.imshow(img)\n                plt.axis(""off"")\n                print(""Read"", basename(res[""image_name""]))\n            plt.show()\n\n            # Reading images in batch\n            res = sess.run(read_batched_examples)\n            print(\n                res[""image_name""],\n                res[""image_l""].shape,\n                res[""image_ab""].shape,\n                res[""image_embedding""].shape,\n                sep=""\\n"",\n            )\n\n            # Finish off the filename queue coordinator.\n            coord.request_stop()\n            coord.join(threads)\n\n\nif __name__ == ""__main__"":\n    unittest.main()\n'"
tests/batching/test_write_read_single_image.py,9,"b'""""""\nRead and show single images from a tfrecord\n\nRun from the top folder as:\npython3 -m tests.batching.test_write_read_single_image\n""""""\nimport time\nimport unittest\nfrom os.path import basename\n\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\nfrom koalarization.dataset.tfrecords import (\n    SingleImageRecordWriter,\n    SingleImageRecordReader,\n)\nfrom koalarization.dataset.tfrecords import queue_single_images_from_folder\n\n\nDIR_RESIZED = \'./tests/data/resized\'\nDIR_TFRECORDS = \'./tests/data/tfrecords\'\n\n\nclass TestSingleImageWriteRead(unittest.TestCase):\n    def test_single_image_write_read(self):\n        self._single_image_write()\n        self._single_image_read()\n\n    def _single_image_write(self):\n        # Create the queue operations\n        img_key, img_tensor, _ = queue_single_images_from_folder(DIR_RESIZED)\n\n        # Create a writer to write_image the images\n        single_writer = SingleImageRecordWriter(""single_images.tfrecord"", DIR_TFRECORDS)\n\n        # Start a new session to run the operations\n        with tf.Session() as sess:\n            sess.run(\n                [tf.global_variables_initializer(), tf.local_variables_initializer()]\n            )\n\n            # Coordinate the loading of image files.\n            coord = tf.train.Coordinator()\n            threads = tf.train.start_queue_runners(coord=coord)\n\n            count = 0\n            start_time = time.time()\n            try:\n                while not coord.should_stop():\n                    key, img = sess.run([img_key, img_tensor])\n                    single_writer.write_image(key, img)\n                    print(""Written: {}"".format(key))\n                    count += 1\n            except tf.errors.OutOfRangeError:\n                # The string_input_producer queue ran out of strings\n                pass\n            finally:\n                # Ask the threads (filename queue) to stop.\n                coord.request_stop()\n                print(\n                    ""Finished writing {} images in {:.2f}s"".format(\n                        count, time.time() - start_time\n                    )\n                )\n\n            # Wait for threads to finish.\n            coord.join(threads)\n\n        single_writer.close()\n\n    def _single_image_read(self):\n        # Important: read_batch MUST be called before start_queue_runners,\n        # otherwise the internal shuffle queue gets created but its\n        # threads won\'t start\n        irr = SingleImageRecordReader(""single_images.tfrecord"", DIR_TFRECORDS)\n        read_one_example = irr.read_operation\n        read_batched_examples = irr.read_batch(10)\n\n        with tf.Session() as sess:\n            sess.run(\n                [tf.global_variables_initializer(), tf.local_variables_initializer()]\n            )\n\n            # Coordinate the loading of image files.\n            coord = tf.train.Coordinator()\n            threads = tf.train.start_queue_runners(coord=coord)\n\n            # Reading images sequentially one by one\n            for i in range(6):\n                res = sess.run(read_one_example)\n                plt.subplot(2, 3, i + 1)\n                plt.imshow(res[""image""])\n                plt.axis(""off"")\n                print(""Read"", basename(res[""key""]))\n            plt.show()\n\n            # Reading images in batch\n            res = sess.run(read_batched_examples)\n            print(res[""key""], res[""image""].shape)\n\n            # Finish off the filename queue coordinator.\n            coord.request_stop()\n            coord.join(threads)\n\n\nif __name__ == ""__main__"":\n    unittest.main()\n'"
tests/batching/test_write_read_variable.py,15,"b'""""""\nWrite some variable size examples in a tfrecord, then read them one at the time\n(all the tensors have differente shapes, so we can\'t batch them)\n\nRun from the top folder as:\npython3 -m tests.batching.test_write_read_variable\n""""""\nimport unittest\n\nimport numpy as np\nimport tensorflow as tf\n\nfrom koalarization.dataset.tfrecords import RecordWriter, RecordReader\n\n\nDIR_TFRECORDS = \'./tests/data/tfrecords\'\n\n\nclass VariableSizeTypesRecordWriter(RecordWriter):\n    """"""\n    The tensors returned don\'t have the same shape, so the read operations\n    are not batchable. Also here we have types that are not int64 or\n    float32, so we serialize them as raw bytes.\n    """"""\n\n    def write_test(self):\n        # Shape must be an int32 for the reshape operation during reading\n        # to succeed (we\'ll need to serialize the shape too)\n        shape = np.random.randint(2, 4, 2, dtype=np.int32)\n\n        # Variable size matrices of uint8 (like an image) and float16\n        mat_ints = np.random.randint(0, 255, shape, dtype=np.uint8)\n        mat_floats = np.random.random(shape).astype(np.float16)\n\n        example = tf.train.Example(\n            features=tf.train.Features(\n                feature={\n                    ""shape"": self._bytes_feature(shape.tobytes()),\n                    ""mat_ints"": self._bytes_feature(mat_ints.tobytes()),\n                    ""mat_floats"": self._bytes_feature(mat_floats.tobytes()),\n                }\n            )\n        )\n        self.write(example.SerializeToString())\n\n\nclass VariableSizeTypesRecordReader(RecordReader):\n    """"""\n    All the tensors returned have fixed shape, so the read operations\n    are batchable\n    """"""\n\n    def _create_read_operation(self):\n        features = tf.parse_single_example(\n            self._tfrecord_serialized,\n            features={\n                ""shape"": tf.FixedLenFeature([], tf.string),\n                ""mat_ints"": tf.FixedLenFeature([], tf.string),\n                ""mat_floats"": tf.FixedLenFeature([], tf.string),\n            },\n        )\n\n        shape = tf.decode_raw(features[""shape""], tf.int32)\n\n        mat_ints = tf.decode_raw(features[""mat_ints""], tf.uint8)\n        mat_ints = tf.reshape(mat_ints, shape)\n\n        mat_floats = tf.decode_raw(features[""mat_floats""], tf.float16)\n        mat_floats = tf.reshape(mat_floats, shape)\n\n        return {""shape"": shape, ""mat_ints"": mat_ints, ""mat_floats"": mat_floats}\n\n\nclass TestVariableSizeRecords(unittest.TestCase):\n    def test_variable_size_record(self):\n        # WRITING\n        with VariableSizeTypesRecordWriter(""variable.tfrecord"", DIR_TFRECORDS) as writer:\n            for i in range(2):\n                writer.write_test()\n\n        # READING\n        reader = VariableSizeTypesRecordReader(""variable.tfrecord"", DIR_TFRECORDS)\n        read_one_example = reader.read_operation\n\n        with tf.Session() as sess:\n            sess.run(\n                [tf.global_variables_initializer(), tf.initialize_local_variables()]\n            )\n\n            # Coordinate the queue of tfrecord files.\n            coord = tf.train.Coordinator()\n            threads = tf.train.start_queue_runners(coord=coord)\n\n            # Reading examples sequentially one by one\n            for j in range(3):\n                fetches = sess.run(read_one_example)\n                print(""Read:"", fetches)\n\n            # Finish off the queue coordinator.\n            coord.request_stop()\n            coord.join(threads)\n\n\nif __name__ == ""__main__"":\n    unittest.main()\n'"
tests/network/__init__.py,0,b''
tests/network/test_colorization.py,11,"b'""""""\nTrain the network on a single sample, a colored checkboard pattern, for 100 epochs\n""""""\n\nimport unittest\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\nfrom skimage import color\n\nfrom koalarization import Colorization, lab_to_rgb, l_to_rgb\n\n\nNUM_EPOCHS = 10\n\n\nclass TestColorization(unittest.TestCase):\n    def test_colorization(self):\n        imgs_l, imgs_true_ab, imgs_emb = self._tensors()\n\n        # Build the network and the optimizer step\n        col = Colorization(256)\n        imgs_ab = col.build(imgs_l, imgs_emb)\n        cost = tf.reduce_mean(tf.squared_difference(imgs_ab, imgs_true_ab))\n        optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n\n        opt_operations = {""cost"": cost, ""optimizer"": optimizer}\n\n        self._run(imgs_l, imgs_ab, imgs_true_ab, opt_operations)\n\n    def _run(self, imgs_l, imgs_ab, imgs_true_ab, opt_operations):\n        with tf.Session() as sess:\n            sess.run(tf.global_variables_initializer())\n            sess.run(tf.local_variables_initializer())\n\n            # Coordinate the loading of image files.\n            coord = tf.train.Coordinator()\n            threads = tf.train.start_queue_runners(coord=coord)\n\n            res = sess.run(\n                {""imgs_l"": imgs_l, ""imgs_ab"": imgs_ab, ""imgs_true_ab"": imgs_true_ab,}\n            )\n\n            img_gray = l_to_rgb(res[""imgs_l""][0][:, :, 0])\n            img_output = lab_to_rgb(res[""imgs_l""][0][:, :, 0], res[""imgs_ab""][0])\n            img_true = lab_to_rgb(res[""imgs_l""][0][:, :, 0], res[""imgs_true_ab""][0])\n\n            plt.subplot(2, 3, 1)\n            plt.imshow(img_gray)\n            plt.title(""Input (grayscale)"")\n            plt.axis(""off"")\n            plt.subplot(2, 3, 2)\n            plt.imshow(img_output)\n            plt.title(""Network output"")\n            plt.axis(""off"")\n            plt.subplot(2, 3, 3)\n            plt.imshow(img_true)\n            plt.title(""Target (original)"")\n            plt.axis(""off"")\n\n            for epoch in range(NUM_EPOCHS):\n                print(""Epoch:"", epoch, end="" "")\n                res = sess.run(opt_operations)\n                print(""Cost:"", res[""cost""])\n\n            res = sess.run(\n                {""imgs_l"": imgs_l, ""imgs_ab"": imgs_ab, ""imgs_true_ab"": imgs_true_ab,}\n            )\n\n            img_gray = l_to_rgb(res[""imgs_l""][0][:, :, 0])\n            img_output = lab_to_rgb(res[""imgs_l""][0][:, :, 0], res[""imgs_ab""][0])\n            img_true = lab_to_rgb(res[""imgs_l""][0][:, :, 0], res[""imgs_true_ab""][0])\n\n            plt.subplot(2, 3, 4)\n            plt.imshow(img_gray)\n            plt.title(""Input (grayscale)"")\n            plt.axis(""off"")\n            plt.subplot(2, 3, 5)\n            plt.imshow(img_output)\n            plt.title(""Network output"")\n            plt.axis(""off"")\n            plt.subplot(2, 3, 6)\n            plt.imshow(img_true)\n            plt.title(""Target (original)"")\n            plt.axis(""off"")\n\n            plt.show()\n\n            # Finish off the queue coordinator.\n            coord.request_stop()\n            coord.join(threads)\n\n    def _tensors(self):\n        """"""\n        Create the input and target tensors to feed the network.\n        Even if the actual sample is just one, it is batched in a batch of 10\n        :return:\n        """"""\n        # Image sizes\n        width = 128\n        height = 64\n\n        # The target image is a simple checkboard pattern\n        img = np.zeros((width, height, 3), dtype=np.uint8)\n        img[: width // 2, :, 0] = 255\n        img[:, height // 2 :, 1] = 255\n        img[: width // 2, : height // 2, 2] = 255\n\n        # Simulate a batch of Lab images with size [width, height]\n        # and Lab values in the range [-1, 1]\n        lab = color.rgb2lab(img).astype(np.float32)\n        l, ab = lab[:, :, 0], lab[:, :, 1:]\n        l = 2 * l / 100 - 1\n        l = l.reshape([width, height, 1])\n        ab /= 127\n\n        imgs_l, imgs_ab, imgs_emb = tf.train.batch(\n            [\n                tf.convert_to_tensor(l),\n                tf.convert_to_tensor(ab),\n                tf.truncated_normal(shape=[1001]),\n            ],\n            batch_size=10,\n        )\n        return imgs_l, imgs_ab, imgs_emb\n\n\nif __name__ == ""__main__"":\n    unittest.main()\n'"
src/koalarization/dataset/__init__.py,0,b''
src/koalarization/dataset/download.py,0,"b'""""""Getting the images from Imagenet\n\nTo download ImageNet dataset, we provide a script which requires an input `txt` file containing the URLs to the images.\n\n> Note: There used to be a file containing the image URLs for ImageNet 2011 available without registration on the\n> official website. Since the link appears to be down, you may want to use a non-official file (see DATASET.md).\n\n```\npython -m koalarization.dataset.download urls.txt path/to/dest\n```\n\nUse `-h` to see the available options\n""""""\n\n\nimport argparse\nimport hashlib\nimport imghdr\nimport sys\nimport tarfile\nimport urllib.request\nfrom itertools import islice\nfrom os.path import join, isfile\nfrom typing import List\n\nfrom .shared import maybe_create_folder\n\n\nclass ImagenetDownloader:\n    """"""Class instance to download the images""""""\n\n    def __init__(self, links_source, dest_dir):\n        """"""Constructor.\n\n        Args:\n            links_source (str): Link or path to file containing dataset URLs. Use local file to boost performance.\n            dest_dir (str): Destination folder to save downloaded images.\n\n        """"""\n        print(links_source)\n        # Destination folder\n        maybe_create_folder(dest_dir)\n        self.dest_dir = dest_dir\n        # If the source is a link download it\n        if links_source.startswith(""http://""):\n            print(\n                ""Using urllib.request for the link archive is extremely"",\n                ""slow, it is better to download the tgz archive manually"",\n                ""and pass its path to this constructor"",\n                file=sys.stderr,\n            )\n            links_source, _ = urllib.request.urlretrieve(\n                links_source,\n                \'imagenet_fall11_urls.txt\'\n            )\n\n        # If the source is an archive extract it\n        if links_source.endswith(\'.tgz\'):\n            with tarfile.open(links_source, \'r:gz\') as tar:\n                tar.extractall(path=\'.\')\n                links_source = \'imagenet_fall11_urls.txt\'\n\n        # if not isfile(links_source):\n        #     raise Exception(\'Links source not valid: {}\'.format(links_source))\n\n        self.links_source = links_source\n\n    def download_images(self, size=None, skip=0):\n        """"""Download images.\n\n        Args:\n            size (int, optional): Number of images to download. Defaults to all images.\n            skip (int, optional): Number of images to skip at first. Defaults to 0.\n\n        Returns:\n            List[str]: List with image paths.\n\n        """"""\n        urls = self._image_urls_generator()\n        urls = islice(urls, skip, None if size is None else skip+size)\n        downloaded_images = map(self._download_img, urls)\n        valid_images = filter(lambda x: x is not None, downloaded_images)\n        return list(valid_images)\n\n    def _download_img(self, image_url: str):\n        """"""Download single image.\n\n        Args:\n            image_url (str): Image url.\n\n        Returns:\n            Union[str, None]: Image path if image was succesfully downloaded. Otherwise, None.\n        """"""\n        image_name = self._encode_image_name(image_url)\n        image_path = join(self.dest_dir, image_name)\n        if not isfile(image_path):\n            try:\n                # TODO use request.get with accept jpg?\n                request = urllib.request.urlopen(image_url, timeout=5)\n                image = request.read()\n                if imghdr.what("""", image) == ""jpeg"":\n                    with open(image_path, ""wb"") as f:\n                        f.write(image)\n            except Exception as e:\n                print(""Error downloading {}: {}"".format(image_url, e), file=sys.stderr)\n                return None\n        return image_path\n\n    def _image_urls_generator(self):\n        """"""Generate image URL.\n\n        Returns:\n            Union[str, None]: List of image URLs.\n\n        Yields:\n            Iterator[Union[str, None]]: Iterator over image URLs.\n\n        """"""\n        with open(self.links_source) as sources:\n            while True:\n                try:\n                    line = sources.readline()\n                    if line.startswith(\'#\') or line == \'\\n\':\n                        # Comments or empty lines\n                        continue\n                    if line == \'\':\n                        # End of file\n                        return\n                    url = line.rsplit(maxsplit=1)[-1]\n                    if url.startswith(\'http\'):\n                        yield url\n                except UnicodeDecodeError as ue:\n                    print(""Unicode error: {}"".format(ue), file=sys.stderr)\n\n    @staticmethod\n    def _encode_image_name(image_url: str) -> str:\n        """"""Image name encoding.\n\n        Args:\n            image_url (str): Image URL.\n\n        Returns:\n            str: Encoded image name.\n\n        """"""\n\n        hash = hashlib.md5(image_url.encode(\'utf-8\')).hexdigest()\n        encoded_name = f\'{hash}.jpeg\'\n        return encoded_name\n\n\ndef _parse_args():\n    """"""Get args.\n\n    Returns:\n        Namespace: Contains args\n\n    """"""\n    # Argparse setup\n    parser = argparse.ArgumentParser(\n        description=\'Download and process images from a file of URLs.\'\n    )\n    parser.add_argument(\n        \'-c\', \'--count\',\n        default=None,\n        type=int,\n        help=\'download only COUNT images (default all)\'\n    )\n    parser.add_argument(\n        \'-s\', \'--skip\',\n        default=0,\n        type=int,\n        metavar=\'N\',\n        help=\'skip the first N images (default 0)\'\n    )\n    parser.add_argument(\n        \'source\',\n        type=str,\n        metavar=\'SOURCE\',\n        help=\'set source for the image links, can be the url, the archive or the file itself\'\n    )\n    parser.add_argument(\n        \'output\',\n        default=\'.\',\n        type=str,\n        metavar=\'OUT_DIR\',\n        help=\'save downloaded images in OUT_DIR\'\n    )\n\n    args = parser.parse_args()\n    return args\n\n\nif __name__ == \'__main__\':\n    args = _parse_args()\n    ImagenetDownloader(links_source=args.source, dest_dir=args.output).download_images(\n        size=args.count, skip=args.skip\n    )\n    print(""Done"")\n'"
src/koalarization/dataset/lab_batch.py,12,"b'""""""Converting to TFRecords (requires Inception checkpoint).\n\n```\npython -m koalarization.dataset.lab_batch -c inception.ckpt path/to/resized path/to/tfrecords\n```\n\nPassing -c is highly recommended over passing a url. To download the checkpoint separately:\n\n```\nwget http://download.tensorflow.org/models/inception_resnet_v2_2016_08_30.tar.gz\ntar -xvf inception_resnet_v2_2016_08_30.tar.gz\n```\n\nUse `-h` to see the available options\n""""""\nimport time\nfrom os.path import isdir, join, basename\nimport argparse\n\nimport tensorflow as tf\nimport tensorflow.contrib.slim as slim\n\nfrom .embedding import (\n    prepare_image_for_inception,\n    maybe_download_inception,\n    inception_resnet_v2,\n    inception_resnet_v2_arg_scope,\n)\nfrom .shared import maybe_create_folder\nfrom .shared import progressive_filename_generator\nfrom .tfrecords import batch_operations\nfrom .tfrecords.images.lab_image_record import LabImageRecordWriter\nfrom .tfrecords.images_queue import queue_single_images_from_folder\n\n\nclass LabImagenetBatcher:\n    """"""Class instance to create TFRecords.""""""\n\n    def __init__(\n        self,\n        inputs_dir: str,\n        records_dir: str,\n        checkpoint_source: str,\n        verbose: int = 0,\n    ):\n        """"""Constructor.\n\n        Args:\n            inputs_dir (str): Path to folder containing all resized images (input).\n            records_dir (str): Path to folder with the TFRecords (output).\n            checkpoint_source (str): Set trained inception weights checkpoint, can be the url, the archive or the\n                                        file itself.\n            verbose (int): Verbosity.\n\n        Raises:\n            Exception: If resized image folder does not exist.\n\n        """"""\n        if not isdir(inputs_dir):\n            raise FileNotFoundError(f""Input folder does not exists: {inputs_dir}"")\n        self.inputs_dir = inputs_dir\n        self.verbose = verbose\n\n        # Destination folder\n        maybe_create_folder(records_dir)\n        self.records_dir = records_dir\n\n        # Inception checkpoint\n        self.checkpoint_file = maybe_download_inception(checkpoint_source)\n\n        # Utils\n        self._examples_count = 0\n        self.records_names_gen = progressive_filename_generator(\n            join(records_dir, ""lab_images_{}.tfrecord"")\n        )\n\n    def batch_all(self, examples_per_record):\n        """""".\n\n        Args:\n            examples_per_record (int): Batch size.\n        """"""\n        operations = self._create_operations(examples_per_record)\n\n        with tf.Session() as sess:\n            self._initialize_session(sess)\n            self._run_session(sess, operations, examples_per_record)\n\n    def _initialize_session(self, sess):\n        """"""Initialize a new session to run the operations.\n\n        Args:\n            sess (tf.Session): Tensorflow session.\n\n        """"""\n\n        # Initialize the the variables that we introduced (like queues etc.)\n        sess.run(tf.global_variables_initializer())\n        sess.run(tf.local_variables_initializer())\n\n        # Restore the weights from Inception\n        # (do not call a global/local variable initializer after this call)\n        saver = tf.train.Saver()\n        saver.restore(sess, self.checkpoint_file)\n\n    def _create_operations(self, examples_per_record):\n        """"""Create the operations to read images from the queue and extract inception features.\n\n        Args:\n            examples_per_record (int): Batch size.\n\n        Returns:\n            tuple: Containing all these operations.\n\n        """"""\n        # Create the queue operations\n        image_key, image_tensor, _ = queue_single_images_from_folder(self.inputs_dir)\n\n        # Build Inception Resnet v2 operations using the image as input\n        # - from rgb to grayscale to loose the color information\n        # - from grayscale to rgb just to have 3 identical channels\n        # - from a [0, 255] int8 range to [-1,+1] float32\n        # - feed the image into inception and get the embedding\n        img_for_inception = tf.image.rgb_to_grayscale(image_tensor)\n        img_for_inception = tf.image.grayscale_to_rgb(img_for_inception)\n        img_for_inception = prepare_image_for_inception(img_for_inception)\n        with slim.arg_scope(inception_resnet_v2_arg_scope()):\n            input_embedding, _ = inception_resnet_v2(\n                img_for_inception, is_training=False\n            )\n\n        operations = image_key, image_tensor, input_embedding\n\n        return batch_operations(operations, examples_per_record)\n\n    def _run_session(self, sess, operations, examples_per_record):\n        """"""Run the whole reading -> extracting features -> writing to records pipeline in a TensorFlow session.\n\n        Args:\n            sess (tf.Session): Tensorflow session.\n            operations (tuple): Operations.\n            examples_per_record (int): Batch size.\n\n        """"""\n        # Coordinate the loading of image files.\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(coord=coord)\n        start_time = time.time()\n        self._examples_count = 0\n\n        # These are the only lines where something happens:\n        # we execute the operations to get the image, compute the\n        # embedding and write everything in the TFRecord\n        try:\n            while not coord.should_stop():\n                self._write_record(examples_per_record, operations, sess)\n        except tf.errors.OutOfRangeError:\n            # The string_input_producer queue ran out of strings\n            pass\n        finally:\n            # Ask the threads (filename queue) to stop.\n            coord.request_stop()\n            print(\n                ""Finished writing {} images in {:.2f}s"".format(\n                    self._examples_count, time.time() - start_time\n                )\n            )\n\n        # Wait for threads to finish.\n        coord.join(threads)\n\n    def _write_record(self, examples_per_record, operations, sess):\n        """"""Write records.\n\n        Args:\n            examples_per_record (int): Batch size.\n            operations (tuple): Operations.\n            sess (tf.Session): Tensorflow session.\n        """"""\n        # The base queue_operation is [a, b, c]\n        # The batched queue_operation is [[a1, a2], [b1,b2], [c1, c2]]\n        # and not [[a1, b1, c1], [a2, b2, c3]]\n        # The result will have the same structure as the batched operations\n        results = sess.run(operations)\n\n        # Create a writer to write the images\n        with LabImageRecordWriter(next(self.records_names_gen)) as writer:\n            # Iterate over each result in the results\n            for one_res in zip(*results):\n                writer.write_image(*one_res)\n                if self.verbose > 0:\n                    filename = one_res[0].decode()\n                    print(""Written"", basename(filename))\n\n            self._examples_count += len(results[0])\n            print(""Record ready:"", writer.path)\n\n\ndef _parse_args():\n    """"""Get args.\n\n    Returns:\n        Namespace: Get arguments.\n\n    """"""\n    import argparse\n    from .embedding.inception_utils import CHECKPOINT_URL\n\n    DEFAULT_BATCH_SIZE = 500\n\n    parser = argparse.ArgumentParser(\n        description=""Takes one folders containing 299x299 images, extracts ""\n        ""the inception resnet v2 features from the image, ""\n        ""serializes the image in Lab space and the embedding and ""\n        ""writes everything in tfrecord files ""\n        ""files in batches on N images""\n    )\n    parser.add_argument(\n        ""source"", type=str, metavar=""SRC_DIR"", help=""process all images in SRC_DIR""\n    ),\n    parser.add_argument(\n        ""output"", type=str, metavar=""OUT_DIR"", help=""save tfrecords in OUR_DIR""\n    )\n    parser.add_argument(\n        ""-c"",\n        ""--checkpoint"",\n        default=CHECKPOINT_URL,\n        type=str,\n        dest=""checkpoint"",\n        help=f""set the source for the trained inception weights, can be the url, the archive or the file itself (default: {CHECKPOINT_URL}) "",\n    )\n    parser.add_argument(\n        ""-b"",\n        ""--batch-size"",\n        default=DEFAULT_BATCH_SIZE,\n        type=int,\n        metavar=""N"",\n        dest=""batch_size"",\n        help=f""every batch will contain N images, except maybe the last one (default: {DEFAULT_BATCH_SIZE})"",\n    )\n    parser.add_argument(""--verbose"", ""-v"", action=""count"", default=0)\n    args = parser.parse_args()\n    return args\n\n\nif __name__ == ""__main__"":\n    args = _parse_args()\n    LabImagenetBatcher(\n        inputs_dir=args.source,\n        records_dir=args.output,\n        checkpoint_source=args.checkpoint,\n        verbose=args.verbose,\n    ).batch_all(examples_per_record=args.batch_size)\n'"
src/koalarization/dataset/labels.py,0,"b'inception_labels = [\n    ""tench, Tinca tinca"",\n    ""goldfish, Carassius auratus"",\n    ""great white shark, white shark, man-eater, man-eating shark, Carcharodon carcharias"",\n    ""tiger shark, Galeocerdo cuvieri"",\n    ""hammerhead, hammerhead shark"",\n    ""electric ray, crampfish, numbfish, torpedo"",\n    ""stingray"",\n    ""cock"",\n    ""hen"",\n    ""ostrich, Struthio camelus"",\n    ""brambling, Fringilla montifringilla"",\n    ""goldfinch, Carduelis carduelis"",\n    ""house finch, linnet, Carpodacus mexicanus"",\n    ""junco, snowbird"",\n    ""indigo bunting, indigo finch, indigo bird, Passerina cyanea"",\n    ""robin, American robin, Turdus migratorius"",\n    ""bulbul"",\n    ""jay"",\n    ""magpie"",\n    ""chickadee"",\n    ""water ouzel, dipper"",\n    ""kite"",\n    ""bald eagle, American eagle, Haliaeetus leucocephalus"",\n    ""vulture"",\n    ""great grey owl, great gray owl, Strix nebulosa"",\n    ""European fire salamander, Salamandra salamandra"",\n    ""common newt, Triturus vulgaris"",\n    ""eft"",\n    ""spotted salamander, Ambystoma maculatum"",\n    ""axolotl, mud puppy, Ambystoma mexicanum"",\n    ""bullfrog, Rana catesbeiana"",\n    ""tree frog, tree-frog"",\n    ""tailed frog, bell toad, ribbed toad, tailed toad, Ascaphus trui"",\n    ""loggerhead, loggerhead turtle, Caretta caretta"",\n    ""leatherback turtle, leatherback, leathery turtle, Dermochelys coriacea"",\n    ""mud turtle"",\n    ""terrapin"",\n    ""box turtle, box tortoise"",\n    ""banded gecko"",\n    ""common iguana, iguana, Iguana iguana"",\n    ""American chameleon, anole, Anolis carolinensis"",\n    ""whiptail, whiptail lizard"",\n    ""agama"",\n    ""frilled lizard, Chlamydosaurus kingi"",\n    ""alligator lizard"",\n    ""Gila monster, Heloderma suspectum"",\n    ""green lizard, Lacerta viridis"",\n    ""African chameleon, Chamaeleo chamaeleon"",\n    ""Komodo dragon, Komodo lizard, dragon lizard, giant lizard, Varanus komodoensis"",\n    ""African crocodile, Nile crocodile, Crocodylus niloticus"",\n    ""American alligator, Alligator mississipiensis"",\n    ""triceratops"",\n    ""thunder snake, worm snake, Carphophis amoenus"",\n    ""ringneck snake, ring-necked snake, ring snake"",\n    ""hognose snake, puff adder, sand viper"",\n    ""green snake, grass snake"",\n    ""king snake, kingsnake"",\n    ""garter snake, grass snake"",\n    ""water snake"",\n    ""vine snake"",\n    ""night snake, Hypsiglena torquata"",\n    ""boa constrictor, Constrictor constrictor"",\n    ""rock python, rock snake, Python sebae"",\n    ""Indian cobra, Naja naja"",\n    ""green mamba"",\n    ""sea snake"",\n    ""horned viper, cerastes, sand viper, horned asp, Cerastes cornutus"",\n    ""diamondback, diamondback rattlesnake, Crotalus adamanteus"",\n    ""sidewinder, horned rattlesnake, Crotalus cerastes"",\n    ""trilobite"",\n    ""harvestman, daddy longlegs, Phalangium opilio"",\n    ""scorpion"",\n    ""black and gold garden spider, Argiope aurantia"",\n    ""barn spider, Araneus cavaticus"",\n    ""garden spider, Aranea diademata"",\n    ""black widow, Latrodectus mactans"",\n    ""tarantula"",\n    ""wolf spider, hunting spider"",\n    ""tick"",\n    ""centipede"",\n    ""black grouse"",\n    ""ptarmigan"",\n    ""ruffed grouse, partridge, Bonasa umbellus"",\n    ""prairie chicken, prairie grouse, prairie fowl"",\n    ""peacock"",\n    ""quail"",\n    ""partridge"",\n    ""African grey, African gray, Psittacus erithacus"",\n    ""macaw"",\n    ""sulphur-crested cockatoo, Kakatoe galerita, Cacatua galerita"",\n    ""lorikeet"",\n    ""coucal"",\n    ""bee eater"",\n    ""hornbill"",\n    ""hummingbird"",\n    ""jacamar"",\n    ""toucan"",\n    ""drake"",\n    ""red-breasted merganser, Mergus serrator"",\n    ""goose"",\n    ""black swan, Cygnus atratus"",\n    ""tusker"",\n    ""echidna, spiny anteater, anteater"",\n    ""platypus, duckbill, duckbilled platypus, duck-billed platypus, Ornithorhynchus anatinus"",\n    ""wallaby, brush kangaroo"",\n    ""koala, koala bear, kangaroo bear, native bear, Phascolarctos cinereus"",\n    ""wombat"",\n    ""jellyfish"",\n    ""sea anemone, anemone"",\n    ""brain coral"",\n    ""flatworm, platyhelminth"",\n    ""nematode, nematode worm, roundworm"",\n    ""conch"",\n    ""snail"",\n    ""slug"",\n    ""sea slug, nudibranch"",\n    ""chiton, coat-of-mail shell, sea cradle, polyplacophore"",\n    ""chambered nautilus, pearly nautilus, nautilus"",\n    ""Dungeness crab, Cancer magister"",\n    ""rock crab, Cancer irroratus"",\n    ""fiddler crab"",\n    ""king crab, Alaska crab, Alaskan king crab, Alaska king crab, Paralithodes camtschatica"",\n    ""American lobster, Northern lobster, Maine lobster, Homarus americanus"",\n    ""spiny lobster, langouste, rock lobster, crawfish, crayfish, sea crawfish"",\n    ""crayfish, crawfish, crawdad, crawdaddy"",\n    ""hermit crab"",\n    ""isopod"",\n    ""white stork, Ciconia ciconia"",\n    ""black stork, Ciconia nigra"",\n    ""spoonbill"",\n    ""flamingo"",\n    ""little blue heron, Egretta caerulea"",\n    ""American egret, great white heron, Egretta albus"",\n    ""bittern"",\n    ""crane"",\n    ""limpkin, Aramus pictus"",\n    ""European gallinule, Porphyrio porphyrio"",\n    ""American coot, marsh hen, mud hen, water hen, Fulica americana"",\n    ""bustard"",\n    ""ruddy turnstone, Arenaria interpres"",\n    ""red-backed sandpiper, dunlin, Erolia alpina"",\n    ""redshank, Tringa totanus"",\n    ""dowitcher"",\n    ""oystercatcher, oyster catcher"",\n    ""pelican"",\n    ""king penguin, Aptenodytes patagonica"",\n    ""albatross, mollymawk"",\n    ""grey whale, gray whale, devilfish, Eschrichtius gibbosus, Eschrichtius robustus"",\n    ""killer whale, killer, orca, grampus, sea wolf, Orcinus orca"",\n    ""dugong, Dugong dugon"",\n    ""sea lion"",\n    ""Chihuahua"",\n    ""Japanese spaniel"",\n    ""Maltese dog, Maltese terrier, Maltese"",\n    ""Pekinese, Pekingese, Peke"",\n    ""Shih-Tzu"",\n    ""Blenheim spaniel"",\n    ""papillon"",\n    ""toy terrier"",\n    ""Rhodesian ridgeback"",\n    ""Afghan hound, Afghan"",\n    ""basset, basset hound"",\n    ""beagle"",\n    ""bloodhound, sleuthhound"",\n    ""bluetick"",\n    ""black-and-tan coonhound"",\n    ""Walker hound, Walker foxhound"",\n    ""English foxhound"",\n    ""redbone"",\n    ""borzoi, Russian wolfhound"",\n    ""Irish wolfhound"",\n    ""Italian greyhound"",\n    ""whippet"",\n    ""Ibizan hound, Ibizan Podenco"",\n    ""Norwegian elkhound, elkhound"",\n    ""otterhound, otter hound"",\n    ""Saluki, gazelle hound"",\n    ""Scottish deerhound, deerhound"",\n    ""Weimaraner"",\n    ""Staffordshire bullterrier, Staffordshire bull terrier"",\n    ""American Staffordshire terrier, Staffordshire terrier, American pit bull terrier, pit bull terrier"",\n    ""Bedlington terrier"",\n    ""Border terrier"",\n    ""Kerry blue terrier"",\n    ""Irish terrier"",\n    ""Norfolk terrier"",\n    ""Norwich terrier"",\n    ""Yorkshire terrier"",\n    ""wire-haired fox terrier"",\n    ""Lakeland terrier"",\n    ""Sealyham terrier, Sealyham"",\n    ""Airedale, Airedale terrier"",\n    ""cairn, cairn terrier"",\n    ""Australian terrier"",\n    ""Dandie Dinmont, Dandie Dinmont terrier"",\n    ""Boston bull, Boston terrier"",\n    ""miniature schnauzer"",\n    ""giant schnauzer"",\n    ""standard schnauzer"",\n    ""Scotch terrier, Scottish terrier, Scottie"",\n    ""Tibetan terrier, chrysanthemum dog"",\n    ""silky terrier, Sydney silky"",\n    ""soft-coated wheaten terrier"",\n    ""West Highland white terrier"",\n    ""Lhasa, Lhasa apso"",\n    ""flat-coated retriever"",\n    ""curly-coated retriever"",\n    ""golden retriever"",\n    ""Labrador retriever"",\n    ""Chesapeake Bay retriever"",\n    ""German short-haired pointer"",\n    ""vizsla, Hungarian pointer"",\n    ""English setter"",\n    ""Irish setter, red setter"",\n    ""Gordon setter"",\n    ""Brittany spaniel"",\n    ""clumber, clumber spaniel"",\n    ""English springer, English springer spaniel"",\n    ""Welsh springer spaniel"",\n    ""cocker spaniel, English cocker spaniel, cocker"",\n    ""Sussex spaniel"",\n    ""Irish water spaniel"",\n    ""kuvasz"",\n    ""schipperke"",\n    ""groenendael"",\n    ""malinois"",\n    ""briard"",\n    ""kelpie"",\n    ""komondor"",\n    ""Old English sheepdog, bobtail"",\n    ""Shetland sheepdog, Shetland sheep dog, Shetland"",\n    ""collie"",\n    ""Border collie"",\n    ""Bouvier des Flandres, Bouviers des Flandres"",\n    ""Rottweiler"",\n    ""German shepherd, German shepherd dog, German police dog, alsatian"",\n    ""Doberman, Doberman pinscher"",\n    ""miniature pinscher"",\n    ""Greater Swiss Mountain dog"",\n    ""Bernese mountain dog"",\n    ""Appenzeller"",\n    ""EntleBucher"",\n    ""boxer"",\n    ""bull mastiff"",\n    ""Tibetan mastiff"",\n    ""French bulldog"",\n    ""Great Dane"",\n    ""Saint Bernard, St Bernard"",\n    ""Eskimo dog, husky"",\n    ""malamute, malemute, Alaskan malamute"",\n    ""Siberian husky"",\n    ""dalmatian, coach dog, carriage dog"",\n    ""affenpinscher, monkey pinscher, monkey dog"",\n    ""basenji"",\n    ""pug, pug-dog"",\n    ""Leonberg"",\n    ""Newfoundland, Newfoundland dog"",\n    ""Great Pyrenees"",\n    ""Samoyed, Samoyede"",\n    ""Pomeranian"",\n    ""chow, chow chow"",\n    ""keeshond"",\n    ""Brabancon griffon"",\n    ""Pembroke, Pembroke Welsh corgi"",\n    ""Cardigan, Cardigan Welsh corgi"",\n    ""toy poodle"",\n    ""miniature poodle"",\n    ""standard poodle"",\n    ""Mexican hairless"",\n    ""timber wolf, grey wolf, gray wolf, Canis lupus"",\n    ""white wolf, Arctic wolf, Canis lupus tundrarum"",\n    ""red wolf, maned wolf, Canis rufus, Canis niger"",\n    ""coyote, prairie wolf, brush wolf, Canis latrans"",\n    ""dingo, warrigal, warragal, Canis dingo"",\n    ""dhole, Cuon alpinus"",\n    ""African hunting dog, hyena dog, Cape hunting dog, Lycaon pictus"",\n    ""hyena, hyaena"",\n    ""red fox, Vulpes vulpes"",\n    ""kit fox, Vulpes macrotis"",\n    ""Arctic fox, white fox, Alopex lagopus"",\n    ""grey fox, gray fox, Urocyon cinereoargenteus"",\n    ""tabby, tabby cat"",\n    ""tiger cat"",\n    ""Persian cat"",\n    ""Siamese cat, Siamese"",\n    ""Egyptian cat"",\n    ""cougar, puma, catamount, mountain lion, painter, panther, Felis concolor"",\n    ""lynx, catamount"",\n    ""leopard, Panthera pardus"",\n    ""snow leopard, ounce, Panthera uncia"",\n    ""jaguar, panther, Panthera onca, Felis onca"",\n    ""lion, king of beasts, Panthera leo"",\n    ""tiger, Panthera tigris"",\n    ""cheetah, chetah, Acinonyx jubatus"",\n    ""brown bear, bruin, Ursus arctos"",\n    ""American black bear, black bear, Ursus americanus, Euarctos americanus"",\n    ""ice bear, polar bear, Ursus Maritimus, Thalarctos maritimus"",\n    ""sloth bear, Melursus ursinus, Ursus ursinus"",\n    ""mongoose"",\n    ""meerkat, mierkat"",\n    ""tiger beetle"",\n    ""ladybug, ladybeetle, lady beetle, ladybird, ladybird beetle"",\n    ""ground beetle, carabid beetle"",\n    ""long-horned beetle, longicorn, longicorn beetle"",\n    ""leaf beetle, chrysomelid"",\n    ""dung beetle"",\n    ""rhinoceros beetle"",\n    ""weevil"",\n    ""fly"",\n    ""bee"",\n    ""ant, emmet, pismire"",\n    ""grasshopper, hopper"",\n    ""cricket"",\n    ""walking stick, walkingstick, stick insect"",\n    ""cockroach, roach"",\n    ""mantis, mantid"",\n    ""cicada, cicala"",\n    ""leafhopper"",\n    ""lacewing, lacewing fly"",\n    ""dragonfly, darning needle, devil\'s darning needle, sewing needle, snake feeder, snake doctor, mosquito hawk, skeeter hawk"",\n    ""damselfly"",\n    ""admiral"",\n    ""ringlet, ringlet butterfly"",\n    ""monarch, monarch butterfly, milkweed butterfly, Danaus plexippus"",\n    ""cabbage butterfly"",\n    ""sulphur butterfly, sulfur butterfly"",\n    ""lycaenid, lycaenid butterfly"",\n    ""starfish, sea star"",\n    ""sea urchin"",\n    ""sea cucumber, holothurian"",\n    ""wood rabbit, cottontail, cottontail rabbit"",\n    ""hare"",\n    ""Angora, Angora rabbit"",\n    ""hamster"",\n    ""porcupine, hedgehog"",\n    ""fox squirrel, eastern fox squirrel, Sciurus niger"",\n    ""marmot"",\n    ""beaver"",\n    ""guinea pig, Cavia cobaya"",\n    ""sorrel"",\n    ""zebra"",\n    ""hog, pig, grunter, squealer, Sus scrofa"",\n    ""wild boar, boar, Sus scrofa"",\n    ""warthog"",\n    ""hippopotamus, hippo, river horse, Hippopotamus amphibius"",\n    ""ox"",\n    ""water buffalo, water ox, Asiatic buffalo, Bubalus bubalis"",\n    ""bison"",\n    ""ram, tup"",\n    ""bighorn, bighorn sheep, cimarron, Rocky Mountain bighorn, Rocky Mountain sheep, Ovis canadensis"",\n    ""ibex, Capra ibex"",\n    ""hartebeest"",\n    ""impala, Aepyceros melampus"",\n    ""gazelle"",\n    ""Arabian camel, dromedary, Camelus dromedarius"",\n    ""llama"",\n    ""weasel"",\n    ""mink"",\n    ""polecat, fitch, foulmart, foumart, Mustela putorius"",\n    ""black-footed ferret, ferret, Mustela nigripes"",\n    ""otter"",\n    ""skunk, polecat, wood pussy"",\n    ""badger"",\n    ""armadillo"",\n    ""three-toed sloth, ai, Bradypus tridactylus"",\n    ""orangutan, orang, orangutang, Pongo pygmaeus"",\n    ""gorilla, Gorilla gorilla"",\n    ""chimpanzee, chimp, Pan troglodytes"",\n    ""gibbon, Hylobates lar"",\n    ""siamang, Hylobates syndactylus, Symphalangus syndactylus"",\n    ""guenon, guenon monkey"",\n    ""patas, hussar monkey, Erythrocebus patas"",\n    ""baboon"",\n    ""macaque"",\n    ""langur"",\n    ""colobus, colobus monkey"",\n    ""proboscis monkey, Nasalis larvatus"",\n    ""marmoset"",\n    ""capuchin, ringtail, Cebus capucinus"",\n    ""howler monkey, howler"",\n    ""titi, titi monkey"",\n    ""spider monkey, Ateles geoffroyi"",\n    ""squirrel monkey, Saimiri sciureus"",\n    ""Madagascar cat, ring-tailed lemur, Lemur catta"",\n    ""indri, indris, Indri indri, Indri brevicaudatus"",\n    ""Indian elephant, Elephas maximus"",\n    ""African elephant, Loxodonta africana"",\n    ""lesser panda, red panda, panda, bear cat, cat bear, Ailurus fulgens"",\n    ""giant panda, panda, panda bear, coon bear, Ailuropoda melanoleuca"",\n    ""barracouta, snoek"",\n    ""eel"",\n    ""coho, cohoe, coho salmon, blue jack, silver salmon, Oncorhynchus kisutch"",\n    ""rock beauty, Holocanthus tricolor"",\n    ""anemone fish"",\n    ""sturgeon"",\n    ""gar, garfish, garpike, billfish, Lepisosteus osseus"",\n    ""lionfish"",\n    ""puffer, pufferfish, blowfish, globefish"",\n    ""abacus"",\n    ""abaya"",\n    ""academic gown, academic robe, judge\'s robe"",\n    ""accordion, piano accordion, squeeze box"",\n    ""acoustic guitar"",\n    ""aircraft carrier, carrier, flattop, attack aircraft carrier"",\n    ""airliner"",\n    ""airship, dirigible"",\n    ""altar"",\n    ""ambulance"",\n    ""amphibian, amphibious vehicle"",\n    ""analog clock"",\n    ""apiary, bee house"",\n    ""apron"",\n    ""ashcan, trash can, garbage can, wastebin, ash bin, ash-bin, ashbin, dustbin, trash barrel, trash bin"",\n    ""assault rifle, assault gun"",\n    ""backpack, back pack, knapsack, packsack, rucksack, haversack"",\n    ""bakery, bakeshop, bakehouse"",\n    ""balance beam, beam"",\n    ""balloon"",\n    ""ballpoint, ballpoint pen, ballpen, Biro"",\n    ""Band Aid"",\n    ""banjo"",\n    ""bannister, banister, balustrade, balusters, handrail"",\n    ""barbell"",\n    ""barber chair"",\n    ""barbershop"",\n    ""barn"",\n    ""barometer"",\n    ""barrel, cask"",\n    ""barrow, garden cart, lawn cart, wheelbarrow"",\n    ""baseball"",\n    ""basketball"",\n    ""bassinet"",\n    ""bassoon"",\n    ""bathing cap, swimming cap"",\n    ""bath towel"",\n    ""bathtub, bathing tub, bath, tub"",\n    ""beach wagon, station wagon, wagon, estate car, beach waggon, station waggon, waggon"",\n    ""beacon, lighthouse, beacon light, pharos"",\n    ""beaker"",\n    ""bearskin, busby, shako"",\n    ""beer bottle"",\n    ""beer glass"",\n    ""bell cote, bell cot"",\n    ""bib"",\n    ""bicycle-built-for-two, tandem bicycle, tandem"",\n    ""bikini, two-piece"",\n    ""binder, ring-binder"",\n    ""binoculars, field glasses, opera glasses"",\n    ""birdhouse"",\n    ""boathouse"",\n    ""bobsled, bobsleigh, bob"",\n    ""bolo tie, bolo, bola tie, bola"",\n    ""bonnet, poke bonnet"",\n    ""bookcase"",\n    ""bookshop, bookstore, bookstall"",\n    ""bottlecap"",\n    ""bow"",\n    ""bow tie, bow-tie, bowtie"",\n    ""brass, memorial tablet, plaque"",\n    ""brassiere, bra, bandeau"",\n    ""breakwater, groin, groyne, mole, bulwark, seawall, jetty"",\n    ""breastplate, aegis, egis"",\n    ""broom"",\n    ""bucket, pail"",\n    ""buckle"",\n    ""bulletproof vest"",\n    ""bullet train, bullet"",\n    ""butcher shop, meat market"",\n    ""cab, hack, taxi, taxicab"",\n    ""caldron, cauldron"",\n    ""candle, taper, wax light"",\n    ""cannon"",\n    ""canoe"",\n    ""can opener, tin opener"",\n    ""cardigan"",\n    ""car mirror"",\n    ""carousel, carrousel, merry-go-round, roundabout, whirligig"",\n    ""carpenter\'s kit, tool kit"",\n    ""carton"",\n    ""car wheel"",\n    ""cash machine, cash dispenser, automated teller machine, automatic teller machine, automated teller, automatic teller, ATM"",\n    ""cassette"",\n    ""cassette player"",\n    ""castle"",\n    ""catamaran"",\n    ""CD player"",\n    ""cello, violoncello"",\n    ""cellular telephone, cellular phone, cellphone, cell, mobile phone"",\n    ""chain"",\n    ""chainlink fence"",\n    ""chain mail, ring mail, mail, chain armor, chain armour, ring armor, ring armour"",\n    ""chain saw, chainsaw"",\n    ""chest"",\n    ""chiffonier, commode"",\n    ""chime, bell, gong"",\n    ""china cabinet, china closet"",\n    ""Christmas stocking"",\n    ""church, church building"",\n    ""cinema, movie theater, movie theatre, movie house, picture palace"",\n    ""cleaver, meat cleaver, chopper"",\n    ""cliff dwelling"",\n    ""cloak"",\n    ""clog, geta, patten, sabot"",\n    ""cocktail shaker"",\n    ""coffee mug"",\n    ""coffeepot"",\n    ""coil, spiral, volute, whorl, helix"",\n    ""combination lock"",\n    ""computer keyboard, keypad"",\n    ""confectionery, confectionary, candy store"",\n    ""container ship, containership, container vessel"",\n    ""convertible"",\n    ""corkscrew, bottle screw"",\n    ""cornet, horn, trumpet, trump"",\n    ""cowboy boot"",\n    ""cowboy hat, ten-gallon hat"",\n    ""cradle"",\n    ""crane"",\n    ""crash helmet"",\n    ""crate"",\n    ""crib, cot"",\n    ""Crock Pot"",\n    ""croquet ball"",\n    ""crutch"",\n    ""cuirass"",\n    ""dam, dike, dyke"",\n    ""desk"",\n    ""desktop computer"",\n    ""dial telephone, dial phone"",\n    ""diaper, nappy, napkin"",\n    ""digital clock"",\n    ""digital watch"",\n    ""dining table, board"",\n    ""dishrag, dishcloth"",\n    ""dishwasher, dish washer, dishwashing machine"",\n    ""disk brake, disc brake"",\n    ""dock, dockage, docking facility"",\n    ""dogsled, dog sled, dog sleigh"",\n    ""dome"",\n    ""doormat, welcome mat"",\n    ""drilling platform, offshore rig"",\n    ""drum, membranophone, tympan"",\n    ""drumstick"",\n    ""dumbbell"",\n    ""Dutch oven"",\n    ""electric fan, blower"",\n    ""electric guitar"",\n    ""electric locomotive"",\n    ""entertainment center"",\n    ""envelope"",\n    ""espresso maker"",\n    ""face powder"",\n    ""feather boa, boa"",\n    ""file, file cabinet, filing cabinet"",\n    ""fireboat"",\n    ""fire engine, fire truck"",\n    ""fire screen, fireguard"",\n    ""flagpole, flagstaff"",\n    ""flute, transverse flute"",\n    ""folding chair"",\n    ""football helmet"",\n    ""forklift"",\n    ""fountain"",\n    ""fountain pen"",\n    ""four-poster"",\n    ""freight car"",\n    ""French horn, horn"",\n    ""frying pan, frypan, skillet"",\n    ""fur coat"",\n    ""garbage truck, dustcart"",\n    ""gasmask, respirator, gas helmet"",\n    ""gas pump, gasoline pump, petrol pump, island dispenser"",\n    ""goblet"",\n    ""go-kart"",\n    ""golf ball"",\n    ""golfcart, golf cart"",\n    ""gondola"",\n    ""gong, tam-tam"",\n    ""gown"",\n    ""grand piano, grand"",\n    ""greenhouse, nursery, glasshouse"",\n    ""grille, radiator grille"",\n    ""grocery store, grocery, food market, market"",\n    ""guillotine"",\n    ""hair slide"",\n    ""hair spray"",\n    ""half track"",\n    ""hammer"",\n    ""hamper"",\n    ""hand blower, blow dryer, blow drier, hair dryer, hair drier"",\n    ""hand-held computer, hand-held microcomputer"",\n    ""handkerchief, hankie, hanky, hankey"",\n    ""hard disc, hard disk, fixed disk"",\n    ""harmonica, mouth organ, harp, mouth harp"",\n    ""harp"",\n    ""harvester, reaper"",\n    ""hatchet"",\n    ""holster"",\n    ""home theater, home theatre"",\n    ""honeycomb"",\n    ""hook, claw"",\n    ""hoopskirt, crinoline"",\n    ""horizontal bar, high bar"",\n    ""horse cart, horse-cart"",\n    ""hourglass"",\n    ""iPod"",\n    ""iron, smoothing iron"",\n    ""jack-o\'-lantern"",\n    ""jean, blue jean, denim"",\n    ""jeep, landrover"",\n    ""jersey, T-shirt, tee shirt"",\n    ""jigsaw puzzle"",\n    ""jinrikisha, ricksha, rickshaw"",\n    ""joystick"",\n    ""kimono"",\n    ""knee pad"",\n    ""knot"",\n    ""lab coat, laboratory coat"",\n    ""ladle"",\n    ""lampshade, lamp shade"",\n    ""laptop, laptop computer"",\n    ""lawn mower, mower"",\n    ""lens cap, lens cover"",\n    ""letter opener, paper knife, paperknife"",\n    ""library"",\n    ""lifeboat"",\n    ""lighter, light, igniter, ignitor"",\n    ""limousine, limo"",\n    ""liner, ocean liner"",\n    ""lipstick, lip rouge"",\n    ""Loafer"",\n    ""lotion"",\n    ""loudspeaker, speaker, speaker unit, loudspeaker system, speaker system"",\n    ""loupe, jeweler\'s loupe"",\n    ""lumbermill, sawmill"",\n    ""magnetic compass"",\n    ""mailbag, postbag"",\n    ""mailbox, letter box"",\n    ""maillot"",\n    ""maillot, tank suit"",\n    ""manhole cover"",\n    ""maraca"",\n    ""marimba, xylophone"",\n    ""mask"",\n    ""matchstick"",\n    ""maypole"",\n    ""maze, labyrinth"",\n    ""measuring cup"",\n    ""medicine chest, medicine cabinet"",\n    ""megalith, megalithic structure"",\n    ""microphone, mike"",\n    ""microwave, microwave oven"",\n    ""military uniform"",\n    ""milk can"",\n    ""minibus"",\n    ""miniskirt, mini"",\n    ""minivan"",\n    ""missile"",\n    ""mitten"",\n    ""mixing bowl"",\n    ""mobile home, manufactured home"",\n    ""Model T"",\n    ""modem"",\n    ""monastery"",\n    ""monitor"",\n    ""moped"",\n    ""mortar"",\n    ""mortarboard"",\n    ""mosque"",\n    ""mosquito net"",\n    ""motor scooter, scooter"",\n    ""mountain bike, all-terrain bike, off-roader"",\n    ""mountain tent"",\n    ""mouse, computer mouse"",\n    ""mousetrap"",\n    ""moving van"",\n    ""muzzle"",\n    ""nail"",\n    ""neck brace"",\n    ""necklace"",\n    ""nipple"",\n    ""notebook, notebook computer"",\n    ""obelisk"",\n    ""oboe, hautboy, hautbois"",\n    ""ocarina, sweet potato"",\n    ""odometer, hodometer, mileometer, milometer"",\n    ""oil filter"",\n    ""organ, pipe organ"",\n    ""oscilloscope, scope, cathode-ray oscilloscope, CRO"",\n    ""overskirt"",\n    ""oxcart"",\n    ""oxygen mask"",\n    ""packet"",\n    ""paddle, boat paddle"",\n    ""paddlewheel, paddle wheel"",\n    ""padlock"",\n    ""paintbrush"",\n    ""pajama, pyjama, pj\'s, jammies"",\n    ""palace"",\n    ""panpipe, pandean pipe, syrinx"",\n    ""paper towel"",\n    ""parachute, chute"",\n    ""parallel bars, bars"",\n    ""park bench"",\n    ""parking meter"",\n    ""passenger car, coach, carriage"",\n    ""patio, terrace"",\n    ""pay-phone, pay-station"",\n    ""pedestal, plinth, footstall"",\n    ""pencil box, pencil case"",\n    ""pencil sharpener"",\n    ""perfume, essence"",\n    ""Petri dish"",\n    ""photocopier"",\n    ""pick, plectrum, plectron"",\n    ""pickelhaube"",\n    ""picket fence, paling"",\n    ""pickup, pickup truck"",\n    ""pier"",\n    ""piggy bank, penny bank"",\n    ""pill bottle"",\n    ""pillow"",\n    ""ping-pong ball"",\n    ""pinwheel"",\n    ""pirate, pirate ship"",\n    ""pitcher, ewer"",\n    ""plane, carpenter\'s plane, woodworking plane"",\n    ""planetarium"",\n    ""plastic bag"",\n    ""plate rack"",\n    ""plow, plough"",\n    ""plunger, plumber\'s helper"",\n    ""Polaroid camera, Polaroid Land camera"",\n    ""pole"",\n    ""police van, police wagon, paddy wagon, patrol wagon, wagon, black Maria"",\n    ""poncho"",\n    ""pool table, billiard table, snooker table"",\n    ""pop bottle, soda bottle"",\n    ""pot, flowerpot"",\n    ""potter\'s wheel"",\n    ""power drill"",\n    ""prayer rug, prayer mat"",\n    ""printer"",\n    ""prison, prison house"",\n    ""projectile, missile"",\n    ""projector"",\n    ""puck, hockey puck"",\n    ""punching bag, punch bag, punching ball, punchball"",\n    ""purse"",\n    ""quill, quill pen"",\n    ""quilt, comforter, comfort, puff"",\n    ""racer, race car, racing car"",\n    ""racket, racquet"",\n    ""radiator"",\n    ""radio, wireless"",\n    ""radio telescope, radio reflector"",\n    ""rain barrel"",\n    ""recreational vehicle, RV, R.V."",\n    ""reel"",\n    ""reflex camera"",\n    ""refrigerator, icebox"",\n    ""remote control, remote"",\n    ""restaurant, eating house, eating place, eatery"",\n    ""revolver, six-gun, six-shooter"",\n    ""rifle"",\n    ""rocking chair, rocker"",\n    ""rotisserie"",\n    ""rubber eraser, rubber, pencil eraser"",\n    ""rugby ball"",\n    ""rule, ruler"",\n    ""running shoe"",\n    ""safe"",\n    ""safety pin"",\n    ""saltshaker, salt shaker"",\n    ""sandal"",\n    ""sarong"",\n    ""sax, saxophone"",\n    ""scabbard"",\n    ""scale, weighing machine"",\n    ""school bus"",\n    ""schooner"",\n    ""scoreboard"",\n    ""screen, CRT screen"",\n    ""screw"",\n    ""screwdriver"",\n    ""seat belt, seatbelt"",\n    ""sewing machine"",\n    ""shield, buckler"",\n    ""shoe shop, shoe-shop, shoe store"",\n    ""shoji"",\n    ""shopping basket"",\n    ""shopping cart"",\n    ""shovel"",\n    ""shower cap"",\n    ""shower curtain"",\n    ""ski"",\n    ""ski mask"",\n    ""sleeping bag"",\n    ""slide rule, slipstick"",\n    ""sliding door"",\n    ""slot, one-armed bandit"",\n    ""snorkel"",\n    ""snowmobile"",\n    ""snowplow, snowplough"",\n    ""soap dispenser"",\n    ""soccer ball"",\n    ""sock"",\n    ""solar dish, solar collector, solar furnace"",\n    ""sombrero"",\n    ""soup bowl"",\n    ""space bar"",\n    ""space heater"",\n    ""space shuttle"",\n    ""spatula"",\n    ""speedboat"",\n    ""spider web, spider\'s web"",\n    ""spindle"",\n    ""sports car, sport car"",\n    ""spotlight, spot"",\n    ""stage"",\n    ""steam locomotive"",\n    ""steel arch bridge"",\n    ""steel drum"",\n    ""stethoscope"",\n    ""stole"",\n    ""stone wall"",\n    ""stopwatch, stop watch"",\n    ""stove"",\n    ""strainer"",\n    ""streetcar, tram, tramcar, trolley, trolley car"",\n    ""stretcher"",\n    ""studio couch, day bed"",\n    ""stupa, tope"",\n    ""submarine, pigboat, sub, U-boat"",\n    ""suit, suit of clothes"",\n    ""sundial"",\n    ""sunglass"",\n    ""sunglasses, dark glasses, shades"",\n    ""sunscreen, sunblock, sun blocker"",\n    ""suspension bridge"",\n    ""swab, swob, mop"",\n    ""sweatshirt"",\n    ""swimming trunks, bathing trunks"",\n    ""swing"",\n    ""switch, electric switch, electrical switch"",\n    ""syringe"",\n    ""table lamp"",\n    ""tank, army tank, armored combat vehicle, armoured combat vehicle"",\n    ""tape player"",\n    ""teapot"",\n    ""teddy, teddy bear"",\n    ""television, television system"",\n    ""tennis ball"",\n    ""thatch, thatched roof"",\n    ""theater curtain, theatre curtain"",\n    ""thimble"",\n    ""thresher, thrasher, threshing machine"",\n    ""throne"",\n    ""tile roof"",\n    ""toaster"",\n    ""tobacco shop, tobacconist shop, tobacconist"",\n    ""toilet seat"",\n    ""torch"",\n    ""totem pole"",\n    ""tow truck, tow car, wrecker"",\n    ""toyshop"",\n    ""tractor"",\n    ""trailer truck, tractor trailer, trucking rig, rig, articulated lorry, semi"",\n    ""tray"",\n    ""trench coat"",\n    ""tricycle, trike, velocipede"",\n    ""trimaran"",\n    ""tripod"",\n    ""triumphal arch"",\n    ""trolleybus, trolley coach, trackless trolley"",\n    ""trombone"",\n    ""tub, vat"",\n    ""turnstile"",\n    ""typewriter keyboard"",\n    ""umbrella"",\n    ""unicycle, monocycle"",\n    ""upright, upright piano"",\n    ""vacuum, vacuum cleaner"",\n    ""vase"",\n    ""vault"",\n    ""velvet"",\n    ""vending machine"",\n    ""vestment"",\n    ""viaduct"",\n    ""violin, fiddle"",\n    ""volleyball"",\n    ""waffle iron"",\n    ""wall clock"",\n    ""wallet, billfold, notecase, pocketbook"",\n    ""wardrobe, closet, press"",\n    ""warplane, military plane"",\n    ""washbasin, handbasin, washbowl, lavabo, wash-hand basin"",\n    ""washer, automatic washer, washing machine"",\n    ""water bottle"",\n    ""water jug"",\n    ""water tower"",\n    ""whiskey jug"",\n    ""whistle"",\n    ""wig"",\n    ""window screen"",\n    ""window shade"",\n    ""Windsor tie"",\n    ""wine bottle"",\n    ""wing"",\n    ""wok"",\n    ""wooden spoon"",\n    ""wool, woolen, woollen"",\n    ""worm fence, snake fence, snake-rail fence, Virginia fence"",\n    ""wreck"",\n    ""yawl"",\n    ""yurt"",\n    ""web site, website, internet site, site"",\n    ""comic book"",\n    ""crossword puzzle, crossword"",\n    ""street sign"",\n    ""traffic light, traffic signal, stoplight"",\n    ""book jacket, dust cover, dust jacket, dust wrapper"",\n    ""menu"",\n    ""plate"",\n    ""guacamole"",\n    ""consomme"",\n    ""hot pot, hotpot"",\n    ""trifle"",\n    ""ice cream, icecream"",\n    ""ice lolly, lolly, lollipop, popsicle"",\n    ""French loaf"",\n    ""bagel, beigel"",\n    ""pretzel"",\n    ""cheeseburger"",\n    ""hotdog, hot dog, red hot"",\n    ""mashed potato"",\n    ""head cabbage"",\n    ""broccoli"",\n    ""cauliflower"",\n    ""zucchini, courgette"",\n    ""spaghetti squash"",\n    ""acorn squash"",\n    ""butternut squash"",\n    ""cucumber, cuke"",\n    ""artichoke, globe artichoke"",\n    ""bell pepper"",\n    ""cardoon"",\n    ""mushroom"",\n    ""Granny Smith"",\n    ""strawberry"",\n    ""orange"",\n    ""lemon"",\n    ""fig"",\n    ""pineapple, ananas"",\n    ""banana"",\n    ""jackfruit, jak, jack"",\n    ""custard apple"",\n    ""pomegranate"",\n    ""hay"",\n    ""carbonara"",\n    ""chocolate sauce, chocolate syrup"",\n    ""dough"",\n    ""meat loaf, meatloaf"",\n    ""pizza, pizza pie"",\n    ""potpie"",\n    ""burrito"",\n    ""red wine"",\n    ""espresso"",\n    ""cup"",\n    ""eggnog"",\n    ""alp"",\n    ""bubble"",\n    ""cliff, drop, drop-off"",\n    ""coral reef"",\n    ""geyser"",\n    ""lakeside, lakeshore"",\n    ""promontory, headland, head, foreland"",\n    ""sandbar, sand bar"",\n    ""seashore, coast, seacoast, sea-coast"",\n    ""valley, vale"",\n    ""volcano"",\n    ""ballplayer, baseball player"",\n    ""groom, bridegroom"",\n    ""scuba diver"",\n    ""rapeseed"",\n    ""daisy"",\n    ""yellow lady\'s slipper, yellow lady-slipper, Cypripedium calceolus, Cypripedium parviflorum"",\n    ""corn"",\n    ""acorn"",\n    ""hip, rose hip, rosehip"",\n    ""buckeye, horse chestnut, conker"",\n    ""coral fungus"",\n    ""agaric"",\n    ""gyromitra"",\n    ""stinkhorn, carrion fungus"",\n    ""earthstar"",\n    ""hen-of-the-woods, hen of the woods, Polyporus frondosus, Grifola frondosa"",\n    ""bolete"",\n    ""ear, spike, capitulum"",\n    ""toilet tissue, toilet paper, bathroom tissue"",\n]\n'"
src/koalarization/dataset/resize.py,0,"b'""""""Resizing the images for the model\n\nTo be able to train in batches, we resize all images to a common shape (299x299).\nUse the following script to achieve this:\n\n```\npython3 -m koalarization.dataset.resize path/to/original path/to/resized\n```\n\nUse `-h` to see the available options\n""""""\n\n\nimport argparse\nfrom os import listdir\nfrom os.path import join, isfile, isdir\n\nfrom PIL import Image\nfrom resizeimage import resizeimage\n\nfrom .shared import maybe_create_folder\n\n\nclass ImagenetResizer:\n    """"""Class instance to resize the images.""""""\n\n    def __init__(self, source_dir, dest_dir):\n        """"""Constructor.\n\n        Args:\n            source_dir (str): Path to folder containing all original images.\n            dest_dir (str): Path where to store resized images.\n\n        Raises:\n            Exception: If source_dir does not exist.\n\n        """"""\n        if not isdir(source_dir):\n            raise Exception(""Input folder does not exists: {}"".format(source_dir))\n        self.source_dir = source_dir\n\n        # Destination folder\n        maybe_create_folder(dest_dir)\n        self.dest_dir = dest_dir\n\n    def resize_img(self, filename, size=(299, 299)):\n        """"""Resize image using padding.\n\n        Resized image is stored in `dest_dir`.\n\n        Args:\n            filename (str): Filename of specific image.\n            size (Tuple[int, int], optional): Output image shape. Defaults to (299, 299).\n\n        """"""\n        img = Image.open(join(self.source_dir, filename))\n        orig_width, orig_height = img.size\n        wanted_width, wanted_height = size\n        ratio_w, ratio_h = wanted_width / orig_width, wanted_height / orig_height\n\n        enlarge_factor = min(ratio_h, ratio_w)\n        if enlarge_factor > 1:\n            # Both sides of the image are shorter than the desired dimension,\n            # so take the side that\'s closer in size and enlarge the image\n            # in both directions to make that one fit\n            enlarged_size = (\n                int(orig_width * enlarge_factor),\n                int(orig_height * enlarge_factor),\n            )\n            img = img.resize(enlarged_size)\n\n        # Now we have an image that\'s either larger than the desired shape\n        # or at least one side matches the desired shape and we can resize\n        # with contain\n        res = resizeimage.resize_contain(img, size).convert(""RGB"")\n        res.save(join(self.dest_dir, filename), res.format)\n\n    def resize_all(self, size=(299, 299)):\n        """"""Resizes all images within `source_dir`.\n\n        Args:\n            size (tuple, optional): Output image shape. Defaults to (299, 299).\n        """"""\n        for filename in listdir(self.source_dir):\n            img_path = join(self.source_dir, filename)\n            if filename.endswith(("".jpg"", "".jpeg"")) and isfile(img_path):\n                self.resize_img(filename, size)\n\n\ndef _parse_args():\n    """"""Argparse setup.\n\n    Returns:\n        Namespace: Arguments.\n\n    """"""\n\n    def size_tuple(size: str):\n        size = tuple(map(int, size.split("","", maxsplit=1)))\n        if len(size) == 1:\n            size = size[0]\n            size = (size, size)\n        return size\n\n    parser = argparse.ArgumentParser(\n        description=""Resize all images in a folder to a common size.""\n    )\n    parser.add_argument(\n        ""source"", type=str, metavar=""SRC_DIR"", help=""resize all images in SRC_DIR""\n    )\n    parser.add_argument(\n        ""output"", type=str, metavar=""OUR_DIR"", help=""save resized images in OUR_DIR""\n    )\n    parser.add_argument(\n        ""-s --size"",\n        type=size_tuple,\n        default=(299, 299),\n        metavar=""SIZE"",\n        dest=""size"",\n        help=""resize images to SIZE, can be a single integer or two comma-separated (W,H)"",\n    )\n\n    args = parser.parse_args()\n    return args\n\n\nif __name__ == ""__main__"":\n    args = _parse_args()\n    ImagenetResizer(source_dir=args.source, dest_dir=args.output).resize_all(\n        size=args.size\n    )\n    print(""Done"")\n'"
src/koalarization/dataset/shared.py,0,"b'import itertools\nfrom os import makedirs\n\ndef maybe_create_folder(folder):\n    makedirs(folder, exist_ok=True)\n\n\ndef progressive_filename_generator(pattern=""file_{}.ext""):\n    for i in itertools.count():\n        yield pattern.format(i)\n'"
src/koalarization/dataset/embedding/__init__.py,0,"b'from .inception_resnet_v2 import inception_resnet_v2, inception_resnet_v2_arg_scope\nfrom .inception_utils import (\n    maybe_download_inception,\n    prepare_image_for_inception,\n    CHECKPOINT_URL,\n)\n'"
src/koalarization/dataset/embedding/inception_resnet_v2.py,42,"b'# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Contains the definition of the Inception Resnet V2 architecture.\n\nAs described in http://arxiv.org/abs/1602.07261.\n\n  Inception-v4, Inception-ResNet and the Impact of Residual Connections\n    on Learning\n  Christian Szegedy, Sergey Ioffe, Vincent Vanhoucke, Alex Alemi\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\nslim = tf.contrib.slim\n\n\ndef block35(net, scale=1.0, activation_fn=tf.nn.relu, scope=None, reuse=None):\n    """"""Builds the 35x35 resnet block.\n\n    Args:\n        net (Network): .\n        scale (float, optional): [description]. Defaults to 1.0.\n        activation_fn ([type], optional): [description]. Defaults to tf.nn.relu.\n        scope ([type], optional): [description]. Defaults to None.\n        reuse ([type], optional): [description]. Defaults to None.\n\n    Returns:\n        Network: Network.\n\n    """"""\n    with tf.variable_scope(scope, ""Block35"", [net], reuse=reuse):\n        with tf.variable_scope(""Branch_0""):\n            tower_conv = slim.conv2d(net, 32, 1, scope=""Conv2d_1x1"")\n        with tf.variable_scope(""Branch_1""):\n            tower_conv1_0 = slim.conv2d(net, 32, 1, scope=""Conv2d_0a_1x1"")\n            tower_conv1_1 = slim.conv2d(tower_conv1_0, 32, 3, scope=""Conv2d_0b_3x3"")\n        with tf.variable_scope(""Branch_2""):\n            tower_conv2_0 = slim.conv2d(net, 32, 1, scope=""Conv2d_0a_1x1"")\n            tower_conv2_1 = slim.conv2d(tower_conv2_0, 48, 3, scope=""Conv2d_0b_3x3"")\n            tower_conv2_2 = slim.conv2d(tower_conv2_1, 64, 3, scope=""Conv2d_0c_3x3"")\n        mixed = tf.concat(axis=3, values=[tower_conv, tower_conv1_1, tower_conv2_2])\n        up = slim.conv2d(\n            mixed,\n            net.get_shape()[3],\n            1,\n            normalizer_fn=None,\n            activation_fn=None,\n            scope=""Conv2d_1x1"",\n        )\n        net += scale * up\n        if activation_fn:\n            net = activation_fn(net)\n    return net\n\n\ndef block17(net, scale=1.0, activation_fn=tf.nn.relu, scope=None, reuse=None):\n    """"""Builds the 17x17 resnet block.\n\n    Args:\n        net ([type]): [description]\n        scale (float, optional): [description]. Defaults to 1.0.\n        activation_fn ([type], optional): [description]. Defaults to tf.nn.relu.\n        scope ([type], optional): [description]. Defaults to None.\n        reuse ([type], optional): [description]. Defaults to None.\n\n    Returns:\n        [type]: [description]\n\n    """"""\n    with tf.variable_scope(scope, ""Block17"", [net], reuse=reuse):\n        with tf.variable_scope(""Branch_0""):\n            tower_conv = slim.conv2d(net, 192, 1, scope=""Conv2d_1x1"")\n        with tf.variable_scope(""Branch_1""):\n            tower_conv1_0 = slim.conv2d(net, 128, 1, scope=""Conv2d_0a_1x1"")\n            tower_conv1_1 = slim.conv2d(\n                tower_conv1_0, 160, [1, 7], scope=""Conv2d_0b_1x7""\n            )\n            tower_conv1_2 = slim.conv2d(\n                tower_conv1_1, 192, [7, 1], scope=""Conv2d_0c_7x1""\n            )\n        mixed = tf.concat(axis=3, values=[tower_conv, tower_conv1_2])\n        up = slim.conv2d(\n            mixed,\n            net.get_shape()[3],\n            1,\n            normalizer_fn=None,\n            activation_fn=None,\n            scope=""Conv2d_1x1"",\n        )\n        net += scale * up\n        if activation_fn:\n            net = activation_fn(net)\n    return net\n\n\ndef block8(net, scale=1.0, activation_fn=tf.nn.relu, scope=None, reuse=None):\n    """"""Builds the 8x8 resnet block.\n\n    Args:\n        net ([type]): [description]\n        scale (float, optional): [description]. Defaults to 1.0.\n        activation_fn ([type], optional): [description]. Defaults to tf.nn.relu.\n        scope ([type], optional): [description]. Defaults to None.\n        reuse ([type], optional): [description]. Defaults to None.\n\n    Returns:\n        [type]: [description]\n\n    """"""\n    with tf.variable_scope(scope, ""Block8"", [net], reuse=reuse):\n        with tf.variable_scope(""Branch_0""):\n            tower_conv = slim.conv2d(net, 192, 1, scope=""Conv2d_1x1"")\n        with tf.variable_scope(""Branch_1""):\n            tower_conv1_0 = slim.conv2d(net, 192, 1, scope=""Conv2d_0a_1x1"")\n            tower_conv1_1 = slim.conv2d(\n                tower_conv1_0, 224, [1, 3], scope=""Conv2d_0b_1x3""\n            )\n            tower_conv1_2 = slim.conv2d(\n                tower_conv1_1, 256, [3, 1], scope=""Conv2d_0c_3x1""\n            )\n        mixed = tf.concat(axis=3, values=[tower_conv, tower_conv1_2])\n        up = slim.conv2d(\n            mixed,\n            net.get_shape()[3],\n            1,\n            normalizer_fn=None,\n            activation_fn=None,\n            scope=""Conv2d_1x1"",\n        )\n        net += scale * up\n        if activation_fn:\n            net = activation_fn(net)\n    return net\n\n\ndef inception_resnet_v2(\n    inputs,\n    num_classes=1001,\n    is_training=True,\n    dropout_keep_prob=0.8,\n    reuse=None,\n    scope=""InceptionResnetV2"",\n):\n    """"""Creates the Inception Resnet V2 model.\n\n    Args:\n        inputs ([type]): A 4-D tensor of size [batch_size, height, width, 3].\n        num_classes (int, optional): Number of predicted classes. Defaults to 1001.\n        is_training (bool, optional): Whether is training or not.. Defaults to True.\n        dropout_keep_prob (float, optional): Float, the fraction to keep before final layer.. Defaults to 0.8.\n        reuse ([type], optional): Whether or not the unfiltering and its variables should be reused. To be\n                                    able to reuse \'scope\' must be given. Defaults to None.\n        scope (str, optional): Optional variable_scope. Defaults to \'InceptionResnetV2\'.\n\n    Returns:\n        logits: the logits outputs of the model.\n        end_points: the set of end_points from the inception model.\n\n    """"""\n    end_points = {}\n\n    with tf.variable_scope(scope, ""InceptionResnetV2"", [inputs], reuse=reuse):\n        with slim.arg_scope([slim.batch_norm, slim.dropout], is_training=is_training):\n            with slim.arg_scope(\n                [slim.conv2d, slim.max_pool2d, slim.avg_pool2d],\n                stride=1,\n                padding=""SAME"",\n            ):\n                # 149 x 149 x 32\n                net = slim.conv2d(\n                    inputs, 32, 3, stride=2, padding=""VALID"", scope=""Conv2d_1a_3x3""\n                )\n                end_points[""Conv2d_1a_3x3""] = net\n                # 147 x 147 x 32\n                net = slim.conv2d(net, 32, 3, padding=""VALID"", scope=""Conv2d_2a_3x3"")\n                end_points[""Conv2d_2a_3x3""] = net\n                # 147 x 147 x 64\n                net = slim.conv2d(net, 64, 3, scope=""Conv2d_2b_3x3"")\n                end_points[""Conv2d_2b_3x3""] = net\n                # 73 x 73 x 64\n                net = slim.max_pool2d(\n                    net, 3, stride=2, padding=""VALID"", scope=""MaxPool_3a_3x3""\n                )\n                end_points[""MaxPool_3a_3x3""] = net\n                # 73 x 73 x 80\n                net = slim.conv2d(net, 80, 1, padding=""VALID"", scope=""Conv2d_3b_1x1"")\n                end_points[""Conv2d_3b_1x1""] = net\n                # 71 x 71 x 192\n                net = slim.conv2d(net, 192, 3, padding=""VALID"", scope=""Conv2d_4a_3x3"")\n                end_points[""Conv2d_4a_3x3""] = net\n                # 35 x 35 x 192\n                net = slim.max_pool2d(\n                    net, 3, stride=2, padding=""VALID"", scope=""MaxPool_5a_3x3""\n                )\n                end_points[""MaxPool_5a_3x3""] = net\n\n                # 35 x 35 x 320\n                with tf.variable_scope(""Mixed_5b""):\n                    with tf.variable_scope(""Branch_0""):\n                        tower_conv = slim.conv2d(net, 96, 1, scope=""Conv2d_1x1"")\n                    with tf.variable_scope(""Branch_1""):\n                        tower_conv1_0 = slim.conv2d(net, 48, 1, scope=""Conv2d_0a_1x1"")\n                        tower_conv1_1 = slim.conv2d(\n                            tower_conv1_0, 64, 5, scope=""Conv2d_0b_5x5""\n                        )\n                    with tf.variable_scope(""Branch_2""):\n                        tower_conv2_0 = slim.conv2d(net, 64, 1, scope=""Conv2d_0a_1x1"")\n                        tower_conv2_1 = slim.conv2d(\n                            tower_conv2_0, 96, 3, scope=""Conv2d_0b_3x3""\n                        )\n                        tower_conv2_2 = slim.conv2d(\n                            tower_conv2_1, 96, 3, scope=""Conv2d_0c_3x3""\n                        )\n                    with tf.variable_scope(""Branch_3""):\n                        tower_pool = slim.avg_pool2d(\n                            net, 3, stride=1, padding=""SAME"", scope=""AvgPool_0a_3x3""\n                        )\n                        tower_pool_1 = slim.conv2d(\n                            tower_pool, 64, 1, scope=""Conv2d_0b_1x1""\n                        )\n                    net = tf.concat(\n                        axis=3,\n                        values=[tower_conv, tower_conv1_1, tower_conv2_2, tower_pool_1],\n                    )\n\n                end_points[""Mixed_5b""] = net\n                net = slim.repeat(net, 10, block35, scale=0.17)\n\n                # 17 x 17 x 1088\n                with tf.variable_scope(""Mixed_6a""):\n                    with tf.variable_scope(""Branch_0""):\n                        tower_conv = slim.conv2d(\n                            net,\n                            384,\n                            3,\n                            stride=2,\n                            padding=""VALID"",\n                            scope=""Conv2d_1a_3x3"",\n                        )\n                    with tf.variable_scope(""Branch_1""):\n                        tower_conv1_0 = slim.conv2d(net, 256, 1, scope=""Conv2d_0a_1x1"")\n                        tower_conv1_1 = slim.conv2d(\n                            tower_conv1_0, 256, 3, scope=""Conv2d_0b_3x3""\n                        )\n                        tower_conv1_2 = slim.conv2d(\n                            tower_conv1_1,\n                            384,\n                            3,\n                            stride=2,\n                            padding=""VALID"",\n                            scope=""Conv2d_1a_3x3"",\n                        )\n                    with tf.variable_scope(""Branch_2""):\n                        tower_pool = slim.max_pool2d(\n                            net, 3, stride=2, padding=""VALID"", scope=""MaxPool_1a_3x3""\n                        )\n                    net = tf.concat(\n                        axis=3, values=[tower_conv, tower_conv1_2, tower_pool]\n                    )\n\n                end_points[""Mixed_6a""] = net\n                net = slim.repeat(net, 20, block17, scale=0.10)\n\n                # Auxiliary tower\n                with tf.variable_scope(""AuxLogits""):\n                    aux = slim.avg_pool2d(\n                        net, 5, stride=3, padding=""VALID"", scope=""Conv2d_1a_3x3""\n                    )\n                    aux = slim.conv2d(aux, 128, 1, scope=""Conv2d_1b_1x1"")\n                    aux = slim.conv2d(\n                        aux,\n                        768,\n                        aux.get_shape()[1:3],\n                        padding=""VALID"",\n                        scope=""Conv2d_2a_5x5"",\n                    )\n                    aux = slim.flatten(aux)\n                    aux = slim.fully_connected(\n                        aux, num_classes, activation_fn=None, scope=""Logits""\n                    )\n                    end_points[""AuxLogits""] = aux\n\n                with tf.variable_scope(""Mixed_7a""):\n                    with tf.variable_scope(""Branch_0""):\n                        tower_conv = slim.conv2d(net, 256, 1, scope=""Conv2d_0a_1x1"")\n                        tower_conv_1 = slim.conv2d(\n                            tower_conv,\n                            384,\n                            3,\n                            stride=2,\n                            padding=""VALID"",\n                            scope=""Conv2d_1a_3x3"",\n                        )\n                    with tf.variable_scope(""Branch_1""):\n                        tower_conv1 = slim.conv2d(net, 256, 1, scope=""Conv2d_0a_1x1"")\n                        tower_conv1_1 = slim.conv2d(\n                            tower_conv1,\n                            288,\n                            3,\n                            stride=2,\n                            padding=""VALID"",\n                            scope=""Conv2d_1a_3x3"",\n                        )\n                    with tf.variable_scope(""Branch_2""):\n                        tower_conv2 = slim.conv2d(net, 256, 1, scope=""Conv2d_0a_1x1"")\n                        tower_conv2_1 = slim.conv2d(\n                            tower_conv2, 288, 3, scope=""Conv2d_0b_3x3""\n                        )\n                        tower_conv2_2 = slim.conv2d(\n                            tower_conv2_1,\n                            320,\n                            3,\n                            stride=2,\n                            padding=""VALID"",\n                            scope=""Conv2d_1a_3x3"",\n                        )\n                    with tf.variable_scope(""Branch_3""):\n                        tower_pool = slim.max_pool2d(\n                            net, 3, stride=2, padding=""VALID"", scope=""MaxPool_1a_3x3""\n                        )\n                    net = tf.concat(\n                        axis=3,\n                        values=[tower_conv_1, tower_conv1_1, tower_conv2_2, tower_pool],\n                    )\n\n                end_points[""Mixed_7a""] = net\n\n                net = slim.repeat(net, 9, block8, scale=0.20)\n                net = block8(net, activation_fn=None)\n\n                net = slim.conv2d(net, 1536, 1, scope=""Conv2d_7b_1x1"")\n                end_points[""Conv2d_7b_1x1""] = net\n\n                with tf.variable_scope(""Logits""):\n                    end_points[""PrePool""] = net\n                    net = slim.avg_pool2d(\n                        net,\n                        net.get_shape()[1:3],\n                        padding=""VALID"",\n                        scope=""AvgPool_1a_8x8"",\n                    )\n                    net = slim.flatten(net)\n\n                    net = slim.dropout(\n                        net, dropout_keep_prob, is_training=is_training, scope=""Dropout""\n                    )\n\n                    end_points[""PreLogitsFlatten""] = net\n                    logits = slim.fully_connected(\n                        net, num_classes, activation_fn=None, scope=""Logits""\n                    )\n                    end_points[""Logits""] = logits\n                    end_points[""Predictions""] = tf.nn.softmax(\n                        logits, name=""Predictions""\n                    )\n\n        return logits, end_points\n\n\ninception_resnet_v2.default_image_size = 299\n\n\ndef inception_resnet_v2_arg_scope(\n    weight_decay=0.00004, batch_norm_decay=0.9997, batch_norm_epsilon=0.001\n):\n    """"""Yields the scope with the default parameters for inception_resnet_v2.\n\n    Args:\n        weight_decay (float, optional): The weight decay for weights variables.. Defaults to 0.00004.\n        batch_norm_decay (float, optional): Decay for the moving average of batch_norm momentums. \n                                            Defaults to 0.9997.\n        batch_norm_epsilon (float, optional): Small float added to variance to avoid dividing by zero. \n                                                Defaults to 0.001.\n\n    Returns:\n        arg_scope with the parameters needed for inception_resnet_v2.\n    """"""\n    # Set weight_decay for weights in conv2d and fully_connected layers.\n    with slim.arg_scope(\n        [slim.conv2d, slim.fully_connected],\n        weights_regularizer=slim.l2_regularizer(weight_decay),\n        biases_regularizer=slim.l2_regularizer(weight_decay),\n    ):\n        batch_norm_params = {\n            ""decay"": batch_norm_decay,\n            ""epsilon"": batch_norm_epsilon,\n        }\n        # Set activation_fn and parameters for batch_norm.\n        with slim.arg_scope(\n            [slim.conv2d],\n            activation_fn=tf.nn.relu,\n            normalizer_fn=slim.batch_norm,\n            normalizer_params=batch_norm_params,\n        ) as scope:\n            return scope\n'"
src/koalarization/dataset/embedding/inception_utils.py,2,"b'import sys\nimport tarfile\nimport urllib\nimport urllib.request\nfrom os.path import isfile, expanduser\n\nimport tensorflow as tf\n\nCHECKPOINT_URL = (\n    ""http://download.tensorflow.org/models/inception_resnet_v2_2016_08_30.tar.gz""\n)\n\n\ndef maybe_download_inception(checkpoint_source):\n    """"""Ensure that the checkpoint for Inception Resnet v2 exists.\n\n    Args:\n        checkpoint_source (str): if a link it gets downloaded; if an archive it gets extracted; if a path in the \n                                    filesystem, it just check it exists\n\n    Raises:\n        Exception: If file does not exist.\n\n    Returns:\n        str : the [downloaded] [uncompressed] ready-for-use file path\n    """"""\n    # If the source is a link download it\n    if checkpoint_source.startswith(""http://""):\n        print(\n            ""Using urllib.request for the checkpoint file is extremely"",\n            ""slow, it\'s better to download the tgz archive manualy"",\n            ""and pass its path to this constructor"",\n            file=sys.stderr,\n        )\n        checkpoint_source, _ = urllib.request.urlretrieve(\n            checkpoint_source, ""inception_resnet_v2_2016_08_30.ckpt.tgz""\n        )\n\n    # If the source is an archive extract it\n    if checkpoint_source.endswith("".tgz""):\n        with tarfile.open(checkpoint_source, ""r:gz"") as tar:\n            tar.extractall(path=""."")\n            checkpoint_source = ""inception_resnet_v2_2016_08_30.ckpt""\n\n    checkpoint_source = expanduser(checkpoint_source)\n    if not isfile(checkpoint_source):\n        raise Exception(""Checkpoint not valid: {}"".format(checkpoint_source))\n\n    return checkpoint_source\n\n\ndef prepare_image_for_inception(input_tensor):\n    """""" Pre-processes an image tensor ``(int8, range [0, 255])`` to be fed into inception ``(float32, range [-1, +1])``\n\n    Args:\n        input_tensor (tensor): input\n\n    Returns:\n        tensor: result\n    """"""\n    res = tf.cast(input_tensor, dtype=tf.float32)\n    res = 2 * res / 255 - 1\n    res = tf.reshape(res, [-1, 299, 299, 3])\n    return res\n'"
src/koalarization/dataset/tfrecords/__init__.py,0,"b'from .base import *\nfrom .images import *\nfrom .images_queue import batch_operations, queue_single_images_from_folder\n'"
src/koalarization/dataset/tfrecords/images_queue.py,7,"b'import multiprocessing\nfrom os.path import join, expanduser\n\nimport tensorflow as tf\n\n\ndef queue_single_images_from_folder(folder):\n    """"""Create queue of images.\n\n    Args:\n        folder (str): Folder.\n\n    """"""\n    # Normalize the path\n    folder = expanduser(folder)\n\n    # This queue will yield a filename every time it is polled\n    file_matcher = tf.train.match_filenames_once(join(folder, ""*.jpeg""))\n\n    # NOTE: if num_epochs is set to something different than None, then we\n    # need to run tf.local_variables_initializer when launching the session!!\n    # https://www.tensorflow.org/api_docs/python/tf/train/string_input_producer\n    filename_queue = tf.train.string_input_producer(\n        file_matcher, shuffle=False, num_epochs=1\n    )\n\n    # This is the reader we\'ll use to read each image given the file name\n    image_reader = tf.WholeFileReader()\n\n    # This operation polls the queue and reads the image\n    image_key, image_file = image_reader.read(filename_queue)\n\n    # The file needs to be decoded as image and we also need its dimensions\n    image_tensor = tf.image.decode_jpeg(image_file)\n    image_shape = tf.shape(image_tensor)\n\n    # Note: nothing has happened yet, we\'ve only defined operations,\n    # what we return are tensors\n    return image_key, image_tensor, image_shape\n\n\ndef batch_operations(operations, batch_size):\n    """"""Once you have created the operation(s) with the other methods of this class,\n    use this method to batch it (them).\n\n    Args:\n        operations: Can be a tensor or a list of tensors.\n        batch_size (int): Batch\n\n    Returns:\n        [type]: [description]\n    """"""\n    # Recommended configuration for these parameters (found online)\n    num_threads = multiprocessing.cpu_count()\n    min_after_dequeue = 3 * batch_size\n    capacity = min_after_dequeue + (num_threads + 1) * batch_size\n    return tf.train.batch(\n        operations,\n        batch_size,\n        num_threads,\n        capacity,\n        dynamic_pad=True,\n        allow_smaller_final_batch=True,\n    )\n'"
src/koalarization/dataset/tfrecords/base/__init__.py,0,b'from .batchable_reader import BatchableRecordReader\nfrom .reader import RecordReader\nfrom .writer import RecordWriter\n'
src/koalarization/dataset/tfrecords/base/batchable_reader.py,2,"b'import multiprocessing\n\nimport tensorflow as tf\n\nfrom .reader import RecordReader\n\n\nclass BatchableRecordReader(RecordReader):\n    """"""\n    Provides the same functionality as the parent RecordReader, adding the\n    possibility to get a batched version of the ``read_operation``\n\n    For a read operation to be batchable, all of its tensor must have fixed\n    sizes at compile time, this rules out e.g. cases where each record\n    represents an image and each image can have different size\n    """"""\n\n    def read_batch(self, batch_size, shuffle=False):\n        # Recommended configuration for these parameters (found online)\n        num_threads = multiprocessing.cpu_count()\n        min_after_dequeue = 10 * batch_size\n        capacity = min_after_dequeue + (num_threads + 1) * batch_size\n\n        if shuffle:\n            return tf.train.shuffle_batch(\n                self.read_operation,\n                batch_size,\n                capacity,\n                min_after_dequeue,\n                num_threads,\n                allow_smaller_final_batch=False,\n            )\n        else:\n            return tf.train.batch(\n                self.read_operation,\n                batch_size,\n                num_threads,\n                capacity,\n                allow_smaller_final_batch=False,\n            )\n'"
src/koalarization/dataset/tfrecords/base/reader.py,3,"b'from abc import abstractmethod, ABC\nfrom os.path import join, expanduser\n\nimport tensorflow as tf\n\nfrom .writer import compression\n\n\nclass RecordReader(ABC):\n    """"""\n    A class to read examples from all the TFRecord matching a certain\n    filename pattern. The implementation of the read operation is left\n    to the subclasses, while the logic to queue all the record files as\n    a single data source is provided here.\n    """"""\n\n    def __init__(self, tfrecord_pattern, folder=""""):\n        # Normalize the folder and build the path\n        tfrecord_pattern = join(expanduser(folder), tfrecord_pattern)\n\n        # This queue will yield a filename every time it is polled\n        file_matcher = tf.train.match_filenames_once(tfrecord_pattern)\n\n        filename_queue = tf.train.string_input_producer(file_matcher)\n        reader = tf.TFRecordReader(options=compression)\n        tfrecord_key, self._tfrecord_serialized = reader.read(filename_queue)\n\n        self._path = tfrecord_key\n        self._read_operation = None\n\n    @property\n    def read_operation(self):\n        if self._read_operation is None:\n            self._read_operation = self._create_read_operation()\n        return self._read_operation\n\n    @abstractmethod\n    def _create_read_operation(self):\n        """"""\n        Build the specific read operation that should be used to read\n        from the TFRecords in the queue, one Example at the time\n\n        Note: in order to prevent the creation of multiple identical operations,\n        this method will be called once, then the operation will be available\n        as ``read_operation``\n        """"""\n        pass\n'"
src/koalarization/dataset/tfrecords/base/writer.py,7,"b'from os.path import join\n\nimport tensorflow as tf\n\ncompression = tf.python_io.TFRecordOptions(tf.python_io.TFRecordCompressionType.NONE)\n\n\nclass RecordWriter(tf.python_io.TFRecordWriter):\n    """"""\n    A commodity subclass of TFRecordWriter that adds the methods to\n    easily serialize different data types.\n    """"""\n\n    def __init__(self, tfrecord_name, dest_folder=""""):\n        self.path = join(dest_folder, tfrecord_name)\n        super().__init__(self.path, options=compression)\n\n    @staticmethod\n    def _bytes_feature(value):\n        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\n    @staticmethod\n    def _int64(single_int):\n        return tf.train.Feature(int64_list=tf.train.Int64List(value=[single_int]))\n\n    @staticmethod\n    def _int64_list(list_of_int):\n        return tf.train.Feature(int64_list=tf.train.Int64List(value=list_of_int))\n\n    @staticmethod\n    def _float32(single_float):\n        return tf.train.Feature(float_list=tf.train.FloatList(value=[single_float]))\n\n    @staticmethod\n    def _float32_list(list_of_floats):\n        return tf.train.Feature(float_list=tf.train.FloatList(value=list_of_floats))\n'"
src/koalarization/dataset/tfrecords/images/__init__.py,0,"b'from .lab_image_record import LabImageRecordReader, LabImageRecordWriter\nfrom .single_image_record import SingleImageRecordReader, SingleImageRecordWriter\n'"
src/koalarization/dataset/tfrecords/images/lab_image_record.py,9,"b'import numpy as np\nimport tensorflow as tf\nfrom skimage import color, transform\n\nfrom ..base import BatchableRecordReader, RecordWriter\n\nwidth = 224\nheight = 224\ndepth = 3\nimg_shape = (width, height, depth)\nembedding_size = 1001\n\n\nclass LabImageRecordWriter(RecordWriter):\n    img_shape = img_shape\n    embedding_size = embedding_size\n\n    def write_image(self, img_file, image, img_embedding):\n        img = transform.resize(image, img_shape, mode=""constant"")\n        lab = color.rgb2lab(img).astype(np.float32)\n        l_channel = 2 * lab[:, :, 0] / 100 - 1\n        ab_channels = lab[:, :, 1:] / 127\n        example = tf.train.Example(\n            features=tf.train.Features(\n                feature={\n                    ""image_name"": self._bytes_feature(img_file),\n                    ""image_l"": self._float32_list(l_channel.flatten()),\n                    ""image_ab"": self._float32_list(ab_channels.flatten()),\n                    ""image_embedding"": self._float32_list(img_embedding.flatten()),\n                }\n            )\n        )\n        self.write(example.SerializeToString())\n\n\nclass LabImageRecordReader(BatchableRecordReader):\n    img_shape = img_shape\n    embedding_size = embedding_size\n\n    def _create_read_operation(self):\n        features = tf.parse_single_example(\n            self._tfrecord_serialized,\n            features={\n                ""image_name"": tf.FixedLenFeature([], tf.string),\n                ""image_l"": tf.FixedLenFeature([width * height], tf.float32),\n                ""image_ab"": tf.FixedLenFeature([width * height * 2], tf.float32),\n                ""image_embedding"": tf.FixedLenFeature([embedding_size], tf.float32),\n            },\n        )\n\n        image_l = tf.reshape(features[""image_l""], shape=[width, height, 1])\n        image_ab = tf.reshape(features[""image_ab""], shape=[width, height, 2])\n\n        return {\n            ""image_name"": features[""image_name""],\n            ""image_l"": image_l,\n            ""image_ab"": image_ab,\n            ""image_embedding"": features[""image_embedding""],\n        }\n'"
src/koalarization/dataset/tfrecords/images/single_image_record.py,8,"b'import tensorflow as tf\n\nfrom ..base import BatchableRecordReader, RecordWriter\n\n\nclass SingleImageRecordWriter(RecordWriter):\n    def __init__(self, tfrecord_name, dest_folder="""", img_shape=(299, 299, 3)):\n        super().__init__(tfrecord_name, dest_folder)\n        self.img_shape = img_shape\n\n    def write_image(self, key, img):\n        assert img.shape == self.img_shape\n        example = tf.train.Example(\n            features=tf.train.Features(\n                feature={\n                    ""key"": self._bytes_feature(key),\n                    ""image"": self._bytes_feature(img.tobytes()),\n                }\n            )\n        )\n        self.write(example.SerializeToString())\n\n\nclass SingleImageRecordReader(BatchableRecordReader):\n    def __init__(self, tfrecord_name, dest_folder="""", img_shape=(299, 299, 3)):\n        super().__init__(tfrecord_name, dest_folder)\n        self.img_shape = img_shape\n\n    def _create_read_operation(self):\n        features = tf.parse_single_example(\n            self._tfrecord_serialized,\n            features={\n                ""key"": tf.FixedLenFeature([], tf.string),\n                ""image"": tf.FixedLenFeature([], tf.string),\n            },\n        )\n\n        image = tf.decode_raw(features[""image""], tf.uint8)\n        image = tf.reshape(image, shape=self.img_shape)\n        image = tf.cast(image, tf.float32) * (1.0 / 255)\n\n        return {""key"": features[""key""], ""image"": image}\n'"
