file_path,api_count,code
augment_image.py,0,"b'import imgaug as ia\nfrom imgaug import augmenters as iaa\nimport numpy as np\nimport random\n\n\nbrightness = iaa.Add((-7, 7), per_channel=0.5)\ncontrast = iaa.ContrastNormalization((0.8, 1.6), per_channel=0.5)\nperspective = iaa.PerspectiveTransform(scale=(0.025, 0.090))\ngaussian_noise = iaa.AdditiveGaussianNoise(loc=0, scale=(0.03*255, 0.04*255), per_channel=0.5)\ncrop = iaa.Crop(px=(0, 25))\n\n\ndef aug_image(my_image):\n    image = my_image.copy()\n    if random.choice([0,0,1]):\n        image = perspective.augment_image(image)\n    if random.choice([0,0,1]):\n        image = brightness.augment_image(image)\n    if random.choice([0,0,1]):\n        image = contrast.augment_image(image)\n    if random.choice([0,0,1]):\n        image = gaussian_noise.augment_image(image)\n    if random.choice([0,0,1]):\n        image = crop.augment_image(image)\n    return image\n\n\nif __name__ == ""__main__"":\n    import cv2\n    image = cv2.imread(\'/home/ben/work/compare_myntra/test_image/test_images/taken_15324282418.jpg\')\n    aug_images = aug_image(image)\n    aug_images = [aug_images]\n    print(len(aug_images))\n    image =  cv2.resize(image, (600,600))\n    image_1 =  cv2.resize(aug_images[0], (600,600))\n    cv2.imshow(\'1\', image)\n    cv2.waitKey(0)\n    cv2.imshow(\'2\', image_1)\n    cv2.waitKey(0)\n'"
dataloader.py,0,"b'import numpy as np\nimport os\nfrom random import shuffle\n\n\nDATA_PATH = ""data/prepared_data/train""\nTEST_PATH = ""data/prepared_data/test""\n\n\nclass Data():\n\n\tdef __init__(self):\n\t\tself.X_counter = 0\n\t\tself.file_counter = 0\n\t\tself.files = os.listdir(DATA_PATH)\n\t\tself.files = [file for file in self.files if \'.npy\' in file]\n\t\tshuffle(self.files)\n\t\tself._load_data()\n\n\tdef _load_data(self):\n\t\tdatas = np.load(os.path.join(DATA_PATH, self.files[self.file_counter]))\n\t\tself.X = []\n\t\tfor data in datas:\n\t\t\tself.X.append(data)\n\t\tshuffle(self.X)\n\t\tself.X = np.asarray(self.X)\n\t\tself.file_counter += 1\n\n\tdef get_data(self, batch_size):\n\t\tif self.X_counter >= len(self.X):\n\t\t\tif self.file_counter > len(self.files) - 1:\n\t\t\t\tprint(""Data exhausted, Re Initialize"")\n\t\t\t\tself.__init__()\n\t\t\t\treturn None\n\t\t\telse:\n\t\t\t\tself._load_data()\n\t\t\t\tself.X_counter = 0\n\n\t\tif self.X_counter + batch_size <= len(self.X):\n\t\t\tremaining = len(self.X) - (self.X_counter)\n\t\t\tX = self.X[self.X_counter: self.X_counter + batch_size]\n\t\telse:\n\t\t\tX = self.X[self.X_counter: ]\n\n\t\tself.X_counter += batch_size\n\t\treturn X\n\n\nclass TestData():\n\n\tdef __init__(self):\n\t\tself.X_counter = 0\n\t\tself.file_counter = 0\n\t\tself.files = os.listdir(TEST_PATH)\n\t\tself.files = [file for file in self.files if \'.npy\' in file]\n\t\tshuffle(self.files)\n\t\tself._load_data()\n\n\tdef _load_data(self):\n\t\tdatas = np.load(os.path.join(TEST_PATH, self.files[self.file_counter]))\n\t\tself.X = []\n\t\tfor data in datas:\n\t\t\tself.X.append(data)\n\t\tshuffle(self.X)\n\t\tself.X = np.asarray(self.X)\n\t\tself.file_counter += 1\n\n\tdef get_data(self, batch_size):\n\t\tif self.X_counter >= len(self.X):\n\t\t\tif self.file_counter > len(self.files) - 1:\n\t\t\t\tprint(""Data exhausted, Re Initialize"")\n\t\t\t\tself.__init__()\n\t\t\t\treturn None\n\t\t\telse:\n\t\t\t\tself._load_data()\n\t\t\t\tself.X_counter = 0\n\n\t\tif self.X_counter + batch_size <= len(self.X):\n\t\t\tremaining = len(self.X) - (self.X_counter)\n\t\t\tX = self.X[self.X_counter: self.X_counter + batch_size]\n\t\telse:\n\t\t\tX = self.X[self.X_counter: ]\n\n\t\tself.X_counter += batch_size\n\t\treturn X\n'"
prepare_data.py,0,"b'import numpy as np\nimport os\nimport cv2\nimport random\nfrom augment_image import aug_image\n\n# raw_data_path: directory where the downloaded images are\n# save_path: directory where the numpy images will be\nraw_data_path = ""data/raw_data/beach_image""\ntrain_save_path = ""data/prepared_data/train""\ntest_save_path = ""data/prepared_data/test""\n\n# Train/Test Data split\ntrain_percen = 0.9\n\nfiles = os.listdir(raw_data_path)\nrandom.shuffle(files)\ntrain_files = files[: int(len(files) * train_percen)]\ntest_files = files[int(len(files) * train_percen) + 1:]\n\n\ntotal_train_images = 0\ntotal_test_images = 0\n\n# Augment both train and test dataset by N times\naugment_times = 2\n\ninput_shape = (256, 256)\n\n# batch: each file will have N images\nbatch = 2000\n\n# Dumping numpy batch images to save_path\ntrain_dump_counter = 0\ntest_dump_counter = 0\ndef dump_numpy(data, is_train_data=True):\n\tglobal train_dump_counter, test_dump_counter\n\trandom.shuffle(data)\n\tif is_train_data:\n\t\ttrain_dump_counter += 1\n\t\tpath = os.path.join(train_save_path, \'train_data_\' + str(train_dump_counter))\n\telse:\n\t\ttest_dump_counter += 1\n\t\tpath = os.path.join(test_save_path, \'test_data_\' + str(test_dump_counter))\n\tnp.save(path, data)\n\n\ndef create_data(files_path, is_train_data=True, augment_times=augment_times):\n\tglobal total_test_images, total_train_images\n\tbulk = []\n\timage_counter = 0\n\tfor i, file in enumerate(files_path, 1):\n\t\timage_path = os.path.join(raw_data_path, file)\n\t\ttry:\n\t\t\timage = cv2.imread(image_path)\n\t\t\timage = cv2.resize(image, input_shape)\n\t\t\tbulk.append(image)\n\t\t\timage_counter += 1\n\t\t\tfor _ in range(augment_times):\n\t\t\t\tnew_image = aug_image(image)\n\t\t\t\timage_counter += 1\n\t\t\t\tbulk.append(new_image)\n\t\texcept Exception as e:\n\t\t\tprint(""error: "", e)\n\t\t\tprint(""file name: "", image_path)\n\n\t\tprint(""Proccessed: "", image_counter)\n\n\t\tif len(bulk) >= batch or i == len(files_path):\n\t\t\tprint(""Dumping batch: "", len(bulk))\n\t\t\tdump_numpy(bulk, is_train_data=is_train_data)\n\t\t\tbulk = []\n\n\tif is_train_data:\n\t\ttotal_train_images += image_counter\n\telse:\n\t\ttotal_test_images += image_counter\n\n# Create Train Dataset\nprint(""CREATING TRAIN DATASET"")\ncreate_data(train_files, is_train_data=True)\n\n# CREATE TEST DATASET\nprint(""CREATING TEST DATASET"")\ncreate_data(test_files, is_train_data=False)\n\nprint(""*""*50)\nprint(""Data preparation completed"")\nprint(""*""*50)\nprint(""Total train images: "", total_train_images)\nprint(""Total test images: "", total_test_images)'"
