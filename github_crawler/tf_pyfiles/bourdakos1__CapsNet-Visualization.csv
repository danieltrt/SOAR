file_path,api_count,code
extract_weights.py,3,"b""from tensorflow.python.tools.inspect_checkpoint import print_tensors_in_checkpoint_file\nimport tensorflow as tf\nimport numpy as np\nimport os\n\nPATH_TO_CKPT = 'tensorflow_checkpoint'\nMODEL_VERSION = 'model_epoch_0047_step_20591'\nPATH_TO_MODEL = os.path.join(PATH_TO_CKPT, MODEL_VERSION)\n\nPATH_TO_WEIGHTS = 'numpy_weights'\nPATH_TO_CONV1 = os.path.join(PATH_TO_WEIGHTS, 'conv1.weights.npz')\nPATH_TO_CONV1_BIAS = os.path.join(PATH_TO_WEIGHTS, 'conv1.bias.npz')\nPATH_TO_PRIMARY_CAPS = os.path.join(PATH_TO_WEIGHTS, 'primary_caps.weights.npz')\nPATH_TO_PRIMARY_CAPS_BIAS = os.path.join(PATH_TO_WEIGHTS, 'primary_caps.bias.npz')\nPATH_TO_DIGIT_CAPS = os.path.join(PATH_TO_WEIGHTS, 'digit_caps.weights.npz')\nPATH_TO_FULLY_CONNECTED1 = os.path.join(PATH_TO_WEIGHTS, 'fully_connected1.weights.npz')\nPATH_TO_FULLY_CONNECTED2 = os.path.join(PATH_TO_WEIGHTS, 'fully_connected2.weights.npz')\nPATH_TO_FULLY_CONNECTED3 = os.path.join(PATH_TO_WEIGHTS, 'fully_connected3.weights.npz')\nPATH_TO_FULLY_CONNECTED1_BIAS = os.path.join(PATH_TO_WEIGHTS, 'fully_connected1.bias.npz')\nPATH_TO_FULLY_CONNECTED2_BIAS = os.path.join(PATH_TO_WEIGHTS, 'fully_connected2.bias.npz')\nPATH_TO_FULLY_CONNECTED3_BIAS = os.path.join(PATH_TO_WEIGHTS, 'fully_connected3.bias.npz')\n\nprint_tensors_in_checkpoint_file(file_name=PATH_TO_MODEL, tensor_name='', all_tensors=False)\n\nsess = tf.Session()\nnew_saver = tf.train.import_meta_graph(PATH_TO_MODEL + '.meta')\nnew_saver.restore(sess, tf.train.latest_checkpoint(PATH_TO_CKPT))\n\n# Conv1_layer/Conv/weights (DT_FLOAT) [9,9,1,256]\nweights = sess.run('Conv1_layer/Conv/weights:0')\nwith open(PATH_TO_CONV1, 'wb') as outfile:\n    np.save(outfile, weights)\n\n# Conv1_layer/Conv/biases (DT_FLOAT) [256]\nbias = sess.run('Conv1_layer/Conv/biases:0')\nwith open(PATH_TO_CONV1_BIAS, 'wb') as outfile:\n    np.save(outfile, bias)\n\n# PrimaryCaps_layer/Conv/weights (DT_FLOAT) [9,9,256,256]\nweights = sess.run('PrimaryCaps_layer/Conv/weights:0')\nwith open(PATH_TO_PRIMARY_CAPS, 'wb') as outfile:\n    np.save(outfile, weights)\n\n# PrimaryCaps_layer/Conv/biases (DT_FLOAT) [256]\nbias = sess.run('PrimaryCaps_layer/Conv/biases:0')\nwith open(PATH_TO_PRIMARY_CAPS_BIAS, 'wb') as outfile:\n    np.save(outfile, bias)\n\n# DigitCaps_layer/routing/Weight (DT_FLOAT) [1,1152,10,8,16]\nweights = sess.run('DigitCaps_layer/routing/Weight:0')\nwith open(PATH_TO_DIGIT_CAPS, 'wb') as outfile:\n    np.save(outfile, weights)\n\n# Decoder/fully_connected/weights (DT_FLOAT) [16,512]\nweights = sess.run('Decoder/fully_connected/weights:0')\nwith open(PATH_TO_FULLY_CONNECTED1, 'wb') as outfile:\n    np.save(outfile, weights)\n\n# Decoder/fully_connected_1/weights (DT_FLOAT) [512,1024]\nweights = sess.run('Decoder/fully_connected_1/weights:0')\nwith open(PATH_TO_FULLY_CONNECTED2, 'wb') as outfile:\n    np.save(outfile, weights)\n\n# Decoder/fully_connected_2/weights (DT_FLOAT) [1024,784]\nweights = sess.run('Decoder/fully_connected_2/weights:0')\nwith open(PATH_TO_FULLY_CONNECTED3, 'wb') as outfile:\n    np.save(outfile, weights)\n\n# Decoder/fully_connected/biases (DT_FLOAT) [512]\nbias = sess.run('Decoder/fully_connected/biases:0')\nwith open(PATH_TO_FULLY_CONNECTED1_BIAS, 'wb') as outfile:\n    np.save(outfile, bias)\n\n# Decoder/fully_connected_1/biases (DT_FLOAT) [1024]\nbias = sess.run('Decoder/fully_connected_1/biases:0')\nwith open(PATH_TO_FULLY_CONNECTED2_BIAS, 'wb') as outfile:\n    np.save(outfile, bias)\n\n# Decoder/fully_connected_2/biases (DT_FLOAT) [784]\nbias = sess.run('Decoder/fully_connected_2/biases:0')\nwith open(PATH_TO_FULLY_CONNECTED3_BIAS, 'wb') as outfile:\n    np.save(outfile, bias)\n"""
render.py,0,"b'import os\nimport sys\nimport numpy as np\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport matplotlib.image as image\nfrom scipy import signal\nfrom matplotlib.colors import LinearSegmentedColormap\nimport json\n\nPATH_TO_TEST_IMAGES_DIR = \'test_images\'\nPATH_TO_TEST_IMAGE = sys.argv[1]\n\n# Black and white color map going from (0, 0, 0) ""black"" to (1, 1, 1) ""white"".\nCMAP = LinearSegmentedColormap.from_list(\'greyscale\', ((0, 0, 0), (1, 1, 1)), N=256, gamma=1.0)\n\n# Output directories for visualizations.\nPATH_TO_ROOT = \'visualizations\'\nPATH_TO_VISUALIZATIONS = os.path.join(PATH_TO_ROOT, PATH_TO_TEST_IMAGE)\nif not os.path.exists(PATH_TO_VISUALIZATIONS):\n    os.mkdir(PATH_TO_VISUALIZATIONS)\n\nPATH_TO_INPUT_IMAGE = os.path.join(PATH_TO_VISUALIZATIONS, \'0\')\nPATH_TO_CONV1_KERNEL = os.path.join(PATH_TO_VISUALIZATIONS, \'1\')\nPATH_TO_RELU = os.path.join(PATH_TO_VISUALIZATIONS, \'2\')\nPATH_TO_PRIMARY_CAPS = os.path.join(PATH_TO_VISUALIZATIONS, \'3\')\nPATH_TO_DIGIT_CAPS = os.path.join(PATH_TO_VISUALIZATIONS, \'4\')\nPATH_TO_RECONSTRUCTION = os.path.join(PATH_TO_VISUALIZATIONS, \'5\')\nPATH_TO_RECONSTRUCTION_JSON_PARAMS = os.path.join(PATH_TO_VISUALIZATIONS, \'6\')\n\nif not os.path.exists(PATH_TO_INPUT_IMAGE):\n    os.mkdir(PATH_TO_INPUT_IMAGE)\nif not os.path.exists(PATH_TO_CONV1_KERNEL):\n    os.mkdir(PATH_TO_CONV1_KERNEL)\nif not os.path.exists(PATH_TO_RELU):\n    os.mkdir(PATH_TO_RELU)\nif not os.path.exists(PATH_TO_PRIMARY_CAPS):\n    os.mkdir(PATH_TO_PRIMARY_CAPS)\nif not os.path.exists(PATH_TO_DIGIT_CAPS):\n    os.mkdir(PATH_TO_DIGIT_CAPS)\nif not os.path.exists(PATH_TO_RECONSTRUCTION):\n    os.mkdir(PATH_TO_RECONSTRUCTION)\nif not os.path.exists(PATH_TO_RECONSTRUCTION_JSON_PARAMS):\n    os.mkdir(PATH_TO_RECONSTRUCTION_JSON_PARAMS)\n\n# Input directories for layer weights.\nPATH_TO_WEIGHTS = \'numpy_weights\'\nPATH_TO_WEIGHTS_CONV1 = os.path.join(PATH_TO_WEIGHTS, \'conv1.weights.npz\')\nPATH_TO_WEIGHTS_CONV1_BIAS = os.path.join(PATH_TO_WEIGHTS, \'conv1.bias.npz\')\nPATH_TO_WEIGHTS_PRIMARY_CAPS = os.path.join(PATH_TO_WEIGHTS, \'primary_caps.weights.npz\')\nPATH_TO_WEIGHTS_PRIMARY_CAPS_BIAS = os.path.join(PATH_TO_WEIGHTS, \'primary_caps.bias.npz\')\nPATH_TO_WEIGHTS_DIGIT_CAPS = os.path.join(PATH_TO_WEIGHTS, \'digit_caps.weights.npz\')\nPATH_TO_WEIGHTS_FULLY_CONNECTED1 = os.path.join(PATH_TO_WEIGHTS, \'fully_connected1.weights.npz\')\nPATH_TO_WEIGHTS_FULLY_CONNECTED2 = os.path.join(PATH_TO_WEIGHTS, \'fully_connected2.weights.npz\')\nPATH_TO_WEIGHTS_FULLY_CONNECTED3 = os.path.join(PATH_TO_WEIGHTS, \'fully_connected3.weights.npz\')\nPATH_TO_WEIGHTS_FULLY_CONNECTED1_BIAS = os.path.join(PATH_TO_WEIGHTS, \'fully_connected1.bias.npz\')\nPATH_TO_WEIGHTS_FULLY_CONNECTED2_BIAS = os.path.join(PATH_TO_WEIGHTS, \'fully_connected2.bias.npz\')\nPATH_TO_WEIGHTS_FULLY_CONNECTED3_BIAS = os.path.join(PATH_TO_WEIGHTS, \'fully_connected3.bias.npz\')\n\n# Number of routing iterations to do in DigitCaps layer.\nNUMBER_OF_ROUNDS = 3\n\n# Load the weights with numpy.\nconv1_weights = np.load(PATH_TO_WEIGHTS_CONV1)\nconv1_bias = np.load(PATH_TO_WEIGHTS_CONV1_BIAS)\nprimary_caps_weights = np.load(PATH_TO_WEIGHTS_PRIMARY_CAPS)\nprimary_caps_bias = np.load(PATH_TO_WEIGHTS_PRIMARY_CAPS_BIAS)\ndigit_caps = np.load(PATH_TO_WEIGHTS_DIGIT_CAPS)\nfully_connected1 = np.load(PATH_TO_WEIGHTS_FULLY_CONNECTED1)\nfully_connected2 = np.load(PATH_TO_WEIGHTS_FULLY_CONNECTED2)\nfully_connected3 = np.load(PATH_TO_WEIGHTS_FULLY_CONNECTED3)\nfully_connected1_bias = np.load(PATH_TO_WEIGHTS_FULLY_CONNECTED1_BIAS)\nfully_connected2_bias = np.load(PATH_TO_WEIGHTS_FULLY_CONNECTED2_BIAS)\nfully_connected3_bias = np.load(PATH_TO_WEIGHTS_FULLY_CONNECTED3_BIAS)\n\n################################################################################\n# Helper Functions\n################################################################################\ndef squash(s, axis=-1, epsilon=1e-9):\n    squared_norm = np.sum(np.square(s), axis=axis, keepdims=True)\n    safe_norm = np.sqrt(squared_norm + epsilon)\n    squash_factor = squared_norm / (1. + squared_norm)\n    unit_vector = s / safe_norm\n    return squash_factor * unit_vector\n\n\ndef safe_norm(s, axis=-1, epsilon=1e-9, keepdims=False):\n    squared_norm = np.sum(np.square(s), axis=axis, keepdims=keepdims)\n    return np.sqrt(squared_norm + epsilon)\n\n\nexpit = lambda x: 1.0 / (1 + np.exp(-x))\ndef sigmoid_function(signal):\n    # Prevent overflow.\n    signal = np.clip(signal, -500, 500)\n    # Calculate activation signal\n    return expit(signal)\n\n\ndef ReLU_function(signal):\n    # Return the activation signal\n    return np.maximum(0, signal)\n\n\n################################################################################\n# Load Input Image\n################################################################################\nimg = Image.open(os.path.join(PATH_TO_TEST_IMAGES_DIR, PATH_TO_TEST_IMAGE))\n# Save original image to the visualization folder\nimage.imsave(os.path.join(PATH_TO_INPUT_IMAGE, \'{}.png\'.format(0)), img)\ninput_image = np.array(img.getdata(), dtype=np.uint8)\ninput_image = np.resize(input_image, (img.size[1], img.size[0], 4))\ninput_image = input_image[:, :, 1]\n\n\n################################################################################\n# Convolution 1\n################################################################################\nconv1_output = np.empty((20, 20, 256))\nfor i in range(conv1_weights.shape[3]):\n    # Get the 9x9 kernel\n    extracted_filter = conv1_weights[:, :, :, i]\n    extracted_filter = np.squeeze(extracted_filter)\n\n    # Save image of the kernel\n    image.imsave(os.path.join(PATH_TO_CONV1_KERNEL, \'{}.png\'.format(i)), extracted_filter, vmin=-0.6064218, vmax=0.24946211)\n\n    # Apply convolution\n    conv1 = signal.correlate2d(input_image, extracted_filter, \'valid\')\n    conv1 = conv1 + conv1_bias[i]\n\n    # ReLU\n    conv1 = np.maximum(0, conv1)\n    conv1_output[:, :, i] = conv1\n\n    # Save image of the the convolution and ReLU\n    image.imsave(os.path.join(PATH_TO_RELU, \'{}.png\'.format(i)), conv1, cmap=CMAP, vmin=0, vmax=255)\n\n\n################################################################################\n# PrimaryCaps\n################################################################################\nprimary_caps_output = np.empty((6, 6, 256))\nfor i in range(primary_caps_weights.shape[3]):\n    # Get the 9x9x256 kernel\n    extracted_filter = primary_caps_weights[:, :, :, i]\n\n    # Apply convolution\n    conv2 = signal.correlate(conv1_output, extracted_filter, \'valid\')\n    conv2 = conv2 + primary_caps_bias[i]\n\n    # Outputs 12x12, but we need 6x6 so we drop every other item\n    conv2 = conv2[::2, ::2, :]\n    conv2 = np.squeeze(conv2)\n\n    # ReLU\n    conv2 = np.maximum(0, conv2)\n    primary_caps_output[:, :, i] = conv2\n\n\n# The paper says that a PrimaryCaps layer is a 6x6 matrix of 8 dimensional\n# vectors and there should be 32 PrimaryCaps layers. Meaning we have 6x6x32 vectors\n# which equals 1,152 vectors.\n# We only really need a list of all the 8d vectors hence we can reshape the matrix\n# to: (1152, 8, 1)\nprimary_caps_output = np.reshape(primary_caps_output, (-1, 8, 1))\n# Squash\nsquashed_caps_output = squash(primary_caps_output)\n\n# Render the Capsule Layers after squashing\nnormed_squashed_caps_output = np.reshape(safe_norm(squashed_caps_output, axis=-2), (6, 6, 32))\nfor i in range(normed_squashed_caps_output.shape[2]):\n    image.imsave(os.path.join(PATH_TO_PRIMARY_CAPS, \'{}.png\'.format(i)), normed_squashed_caps_output[:, :, i], cmap=CMAP, vmin=0, vmax=1)\n\n\n################################################################################\n# DigitCaps and Routing\n################################################################################\n\n# Add in a blank dimension: (1, 1152, 1, 8, 1)\nsquashed_caps_output = np.reshape(squashed_caps_output, (-1, 1, squashed_caps_output.shape[-2], 1))\n# Tile the capsules in the inserted dimension: (1, 1152, 10, 8, 1)\ncaps_output_tiled = np.tile(squashed_caps_output, [1, 1, 10, 1, 1])\n\n# Transpose DigitCaps (1, 1152, 10, 8, 16) -> (1, 1152, 10, 16, 8)\n# matmul caps_output_tiled (1152, 10, 8, 1) by digit_caps (1, 1152, 10, 16, 8)\n# It\'s doing a matrix multiplication on the last 2 dimensions:\n#                 \xe2\x94\x82 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n#                 \xe2\x94\x82 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n#                 \xe2\x94\x82 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n#                 \xe2\x94\x82 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n#                 \xe2\x94\x82 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n#                 \xe2\x94\x82 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n#                 \xe2\x94\x82 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n#                 \xe2\x94\x82 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n# \xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\xbc\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\xe2\x94\x80\n# 1 2 3 4 5 6 7 8 \xe2\x94\x82 1 2 3 4 5 6 7 8 0 0 0 0 0 0 0 0\n\ncaps2_predicted = np.matmul(np.transpose(digit_caps, (0, 1, 2, 4, 3)), caps_output_tiled)\n\nraw_weights = np.zeros([1, 1152, 10, 1, 1])\n\n# Routing iterations\nfor x in range(0, NUMBER_OF_ROUNDS):\n    # Softmax\n    routing_weights = np.exp(raw_weights) / np.sum(np.exp(raw_weights), axis=2, keepdims=True)\n    # Sumation of the element wise multiplication\n    weighted_predictions = np.multiply(routing_weights, caps2_predicted)\n    weighted_sum = np.sum(weighted_predictions, axis=1, keepdims=True)\n    # Squash\n    caps2_output = squash(weighted_sum, axis=-2)\n\n    # We don\'t need to recalcute raw weights on the last iteration\n    if x < NUMBER_OF_ROUNDS:\n        # Add dot product to the weights\n        caps2_output_tiled = np.tile(caps2_output, [1, 1152, 1, 1, 1])\n        agreement = np.matmul(np.transpose(caps2_predicted, (0, 1, 2, 4, 3)), caps2_output_tiled)\n        raw_weights = np.add(raw_weights, agreement)\n\n\n# Estimate class\ny_proba = safe_norm(caps2_output, axis=-2)\n\ndigit_caps_image = y_proba.reshape(10, 1)\nimage.imsave(os.path.join(PATH_TO_DIGIT_CAPS, \'{}.png\'.format(0)), digit_caps_image, cmap=CMAP, vmin=0, vmax=1)\n\n\n################################################################################\n# Prediction\n################################################################################\n\ny_proba_argmax = np.argmax(y_proba, axis=2)\ny_pred = np.squeeze(y_proba_argmax, axis=[1,2])\n\nprint(\'Prediction: {}\'.format(y_pred))\n\n\n################################################################################\n# Reconstruction\n################################################################################\n\ncaps2_output = np.squeeze(caps2_output)\nreconstruction_input = caps2_output[y_pred]\n\noutput = reconstruction_input\n\njson_params = { \'vector\': output.tolist(), \'prediction\': int(y_pred)}\nwith open(os.path.join(PATH_TO_RECONSTRUCTION_JSON_PARAMS, \'{}.json\'.format(0)), \'w\') as outfile:\n    json.dump(json_params, outfile)\n\nfully_connected1 = fully_connected1.reshape(10, 16, 512)[y_pred]\n\nsignal = np.dot(output, fully_connected1) + fully_connected1_bias # bias\noutput = ReLU_function(signal)\n\nsignal = np.dot(output, fully_connected2) + fully_connected2_bias # bias\noutput = ReLU_function(signal)\n\nsignal = np.dot(output, fully_connected3) + fully_connected3_bias # bias\noutput = sigmoid_function(signal)\n\noutput = output.reshape(28,28)\n\nimage.imsave(os.path.join(PATH_TO_RECONSTRUCTION, \'{}.png\'.format(0)), output, cmap=CMAP, vmin=0, vmax=1)\n'"
run_visualization.py,0,"b""import os\nimport fnmatch\nimport re\nimport numpy as np\nfrom PIL import Image\nimport uuid\nimport matplotlib.image as image\nfrom matplotlib.colors import LinearSegmentedColormap\nfrom flask import Flask, send_from_directory, jsonify, request\n\napp = Flask(__name__, static_folder='client/build')\n\n@app.route('/', defaults={'path': ''})\n@app.route('/<path:path>')\ndef serve(path):\n    if path == '':\n        return send_from_directory('client/build', 'index.html')\n    else:\n        if os.path.exists('client/build/' + path):\n            return send_from_directory('client/build', path)\n        if os.path.exists(path):\n            return send_from_directory('', path)\n        else:\n            return send_from_directory('client/build', 'index.html')\n\n\ntokenize = re.compile(r'(\\d+)|(\\D+)').findall\ndef natural_sortkey(string):\n    return tuple(int(num) if num else alpha for num, alpha in tokenize(string))\n\n\n@app.route('/images')\ndef get_images():\n    res = {}\n    for input_dir in os.listdir('visualizations'):\n        res[input_dir] = []\n        layers_path = os.path.join('visualizations', input_dir)\n        if os.path.isdir(layers_path):\n            for i, layer_dir in enumerate(sorted(os.listdir(layers_path), key=natural_sortkey)):\n                res[input_dir].append([])\n                images_path = os.path.join(layers_path, layer_dir)\n                if os.path.isdir(images_path):\n                    for image_file in sorted(os.listdir(images_path), key=natural_sortkey):\n                        if fnmatch.fnmatch(image_file, '*.png') or fnmatch.fnmatch(image_file, '*.json'):\n                            image_path = os.path.join(images_path, image_file)\n                            res[input_dir][i].append(image_path)\n    return jsonify(res)\n\n\nexpit = lambda x: 1.0 / (1 + np.exp(-x))\ndef sigmoid_function(signal):\n    # Prevent overflow.\n    signal = np.clip(signal, -500, 500)\n\n    # Calculate activation signal\n    return expit(signal)\n\n\ndef ReLU_function(signal):\n    # Return the activation signal\n    return np.maximum(0, signal)\n\n\n@app.route('/api/reconstruct', methods=['POST'])\ndef reconstruct():\n    CMAP = LinearSegmentedColormap.from_list('greyscale', ((0, 0, 0), (1, 1, 1)), N=256, gamma=1.0)\n\n    PATH_TO_WEIGHTS = 'numpy_weights'\n    PATH_TO_WEIGHTS_FULLY_CONNECTED1 = os.path.join(PATH_TO_WEIGHTS, 'fully_connected1.weights.npz')\n    PATH_TO_WEIGHTS_FULLY_CONNECTED2 = os.path.join(PATH_TO_WEIGHTS, 'fully_connected2.weights.npz')\n    PATH_TO_WEIGHTS_FULLY_CONNECTED3 = os.path.join(PATH_TO_WEIGHTS, 'fully_connected3.weights.npz')\n    PATH_TO_WEIGHTS_FULLY_CONNECTED1_BIAS = os.path.join(PATH_TO_WEIGHTS, 'fully_connected1.bias.npz')\n    PATH_TO_WEIGHTS_FULLY_CONNECTED2_BIAS = os.path.join(PATH_TO_WEIGHTS, 'fully_connected2.bias.npz')\n    PATH_TO_WEIGHTS_FULLY_CONNECTED3_BIAS = os.path.join(PATH_TO_WEIGHTS, 'fully_connected3.bias.npz')\n\n    fully_connected1 = np.load(PATH_TO_WEIGHTS_FULLY_CONNECTED1)\n    fully_connected2 = np.load(PATH_TO_WEIGHTS_FULLY_CONNECTED2)\n    fully_connected3 = np.load(PATH_TO_WEIGHTS_FULLY_CONNECTED3)\n    fully_connected1_bias = np.load(PATH_TO_WEIGHTS_FULLY_CONNECTED1_BIAS)\n    fully_connected2_bias = np.load(PATH_TO_WEIGHTS_FULLY_CONNECTED2_BIAS)\n    fully_connected3_bias = np.load(PATH_TO_WEIGHTS_FULLY_CONNECTED3_BIAS)\n\n    output = np.array(request.json['vector'])\n\n    fully_connected1 = fully_connected1.reshape(10, 16, 512)[request.json['predicted']]\n\n    signal = np.dot(output, fully_connected1) + fully_connected1_bias # bias\n    output = ReLU_function(signal)\n\n    signal = np.dot(output, fully_connected2) + fully_connected2_bias # bias\n    output = ReLU_function(signal)\n\n    signal = np.dot(output, fully_connected3) + fully_connected3_bias # bias\n    output = sigmoid_function(signal)\n\n    output = output.reshape(28,28)\n\n    folder = 'reconstructions'\n    for the_file in os.listdir(folder):\n        file_path = os.path.join(folder, the_file)\n        try:\n            if os.path.isfile(file_path):\n                os.unlink(file_path)\n        except Exception as e:\n            print(e)\n\n    path = os.path.join('reconstructions', '{}.png').format(str(uuid.uuid4()))\n    image.imsave(path, output, cmap=CMAP, vmin=0, vmax=1)\n\n    return jsonify({'url': path})\n\n\nif __name__ == '__main__':\n    app.run(debug=True)\n"""
