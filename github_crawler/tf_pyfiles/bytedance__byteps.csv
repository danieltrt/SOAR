file_path,api_count,code
pre_setup.py,0,"b'# For internal use. Please do not modify this file.\n\ndef setup():\n    return\n\ndef extra_make_option():\n    return """"\n'"
setup.py,7,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\n# Note: To use the \'upload\' functionality of this file, you must:\n#   $ pip install twine\n\nimport io\nimport os\nimport sys\nimport re\nimport shutil\nfrom shutil import rmtree\nimport textwrap\nimport shlex\nimport subprocess\n\nfrom setuptools import find_packages, setup, Command, Extension\nfrom setuptools.command.build_ext import build_ext\nfrom distutils.errors import CompileError, DistutilsError, DistutilsPlatformError, LinkError, DistutilsSetupError\nfrom distutils import log as distutils_logger\nfrom distutils.version import LooseVersion\nimport traceback\n\nimport pre_setup\n\nserver_lib = Extension(\'byteps.server.c_lib\', [])\ntensorflow_lib = Extension(\'byteps.tensorflow.c_lib\', [])\nmxnet_lib = Extension(\'byteps.mxnet.c_lib\', [])\npytorch_lib = Extension(\'byteps.torch.c_lib\', [])\n\n# Package meta-data.\nNAME = \'byteps\'\nDESCRIPTION = \'A high-performance cross-framework Parameter Server for Deep Learning\'\nURL = \'https://github.com/bytedance/byteps\'\nEMAIL = \'lab-hr@bytedance.com\'\nAUTHOR = \'Bytedance Inc.\'\nREQUIRES_PYTHON = \'>=2.7.0\'\nVERSION = None\n\n# What packages are required for this module to be executed?\nREQUIRED = [\n    # \'cffi>=1.4.0\',\n]\n\n# What packages are optional?\nEXTRAS = {\n    # \'fancy feature\': [\'django\'],\n}\n\n# The rest you shouldn\'t have to touch too much :)\n# ------------------------------------------------\n# Except, perhaps the License and Trove Classifiers!\n# If you do change the License, remember to change the Trove Classifier for that!\n\nhere = os.path.abspath(os.path.dirname(__file__))\n\n# Import the README and use it as the long-description.\n# Note: this will only work if \'README.md\' is present in your MANIFEST.in file!\ntry:\n    with io.open(os.path.join(here, \'README.md\'), encoding=\'utf-8\') as f:\n        long_description = \'\\n\' + f.read()\nexcept OSError:\n    long_description = DESCRIPTION\n\n# Load the package\'s __version__.py module as a dictionary.\nabout = {}\nif not VERSION:\n    with open(os.path.join(here, NAME, \'__version__.py\')) as f:\n        exec(f.read(), about)\nelse:\n    about[\'__version__\'] = VERSION\n\n\ndef is_build_action():\n    if len(sys.argv) <= 1:\n        return False\n\n    if sys.argv[1].startswith(\'build\'):\n        return True\n\n    if sys.argv[1].startswith(\'bdist\'):\n        return True\n\n    if sys.argv[1].startswith(\'install\'):\n        return True\n\n\nclass UploadCommand(Command):\n    """"""Support setup.py upload.""""""\n\n    description = \'Build and publish the package.\'\n    user_options = []\n\n    @staticmethod\n    def status(s):\n        """"""Prints things in bold.""""""\n        print(\'\\033[1m{0}\\033[0m\'.format(s))\n\n    def initialize_options(self):\n        pass\n\n    def finalize_options(self):\n        pass\n\n    def run(self):\n        try:\n            self.status(\'Removing previous builds\xe2\x80\xa6\')\n            rmtree(os.path.join(here, \'dist\'))\n        except OSError:\n            pass\n\n        self.status(\'Building Source and Wheel (universal) distribution\xe2\x80\xa6\')\n        os.system(\n            \'{0} setup.py sdist bdist_wheel --universal\'.format(sys.executable))\n\n        self.status(\'Uploading the package to PyPI via Twine\xe2\x80\xa6\')\n        os.system(\'twine upload dist/*\')\n\n        self.status(\'Pushing git tags\xe2\x80\xa6\')\n        os.system(\'git tag v{0}\'.format(about[\'__version__\']))\n        os.system(\'git push --tags\')\n\n        sys.exit()\n\n\n# Start to build c libs\n# ------------------------------------------------\ndef test_compile(build_ext, name, code, libraries=None, include_dirs=None, library_dirs=None,\n                 macros=None, extra_compile_preargs=None, extra_link_preargs=None):\n    test_compile_dir = os.path.join(build_ext.build_temp, \'test_compile\')\n    if not os.path.exists(test_compile_dir):\n        os.makedirs(test_compile_dir)\n\n    source_file = os.path.join(test_compile_dir, \'%s.cc\' % name)\n    with open(source_file, \'w\') as f:\n        f.write(code)\n\n    compiler = build_ext.compiler\n    [object_file] = compiler.object_filenames([source_file])\n    shared_object_file = compiler.shared_object_filename(\n        name, output_dir=test_compile_dir)\n\n    compiler.compile([source_file], extra_preargs=extra_compile_preargs,\n                     include_dirs=include_dirs, macros=macros)\n    compiler.link_shared_object(\n        [object_file], shared_object_file, libraries=libraries, library_dirs=library_dirs,\n        extra_preargs=extra_link_preargs)\n\n    return shared_object_file\n\n\ndef get_mpi_flags():\n    show_command = os.environ.get(\'BYTEPS_MPICXX_SHOW\', \'mpicxx -show\')\n    try:\n        mpi_show_output = subprocess.check_output(\n            shlex.split(show_command), universal_newlines=True).strip()\n        mpi_show_args = shlex.split(mpi_show_output)\n        if not mpi_show_args[0].startswith(\'-\'):\n            # Open MPI and MPICH print compiler name as a first word, skip it\n            mpi_show_args = mpi_show_args[1:]\n        # strip off compiler call portion and always escape each arg\n        return \' \'.join([\'""\' + arg.replace(\'""\', \'""\\\'""\\\'""\') + \'""\'\n                         for arg in mpi_show_args])\n    except Exception:\n        raise DistutilsPlatformError(\n            \'%s failed (see error below), is MPI in $PATH?\\n\'\n            \'Note: If your version of MPI has a custom command to show compilation flags, \'\n            \'please specify it with the BYTEPS_MPICXX_SHOW environment variable.\\n\\n\'\n            \'%s\' % (show_command, traceback.format_exc()))\n\n\ndef get_cpp_flags(build_ext):\n    last_err = None\n    default_flags = [\'-std=c++11\', \'-fPIC\', \'-O2\', \'-Wall\', \'-fopenmp\']\n    avx_flags = [\'-mf16c\', \'-mavx\']\n    flags_to_try = []\n    if sys.platform == \'darwin\':\n        # Darwin most likely will have Clang, which has libc++.\n        flags_to_try = [default_flags + [\'-stdlib=libc++\'] + avx_flags,\n                        default_flags + avx_flags,\n                        default_flags + [\'-stdlib=libc++\'],\n                        default_flags]\n    else:\n        flags_to_try = [default_flags + avx_flags,\n                        default_flags + [\'-stdlib=libc++\'] + avx_flags,\n                        default_flags,\n                        default_flags + [\'-stdlib=libc++\']]\n    for cpp_flags in flags_to_try:\n        try:\n            test_compile(build_ext, \'test_cpp_flags\', extra_compile_preargs=cpp_flags,\n                         code=textwrap.dedent(\'\'\'\\\n                    #include <unordered_map>\n                    void test() {\n                    }\n                    \'\'\'))\n\n            return cpp_flags\n        except (CompileError, LinkError):\n            last_err = \'Unable to determine C++ compilation flags (see error above).\'\n        except Exception:\n            last_err = \'Unable to determine C++ compilation flags.  \' \\\n                       \'Last error:\\n\\n%s\' % traceback.format_exc()\n\n    raise DistutilsPlatformError(last_err)\n\n\ndef get_link_flags(build_ext):\n    last_err = None\n    libtool_flags = [\'-Wl,-exported_symbols_list,byteps.exp\']\n    ld_flags = [\'-Wl,--version-script=byteps.lds\', \'-fopenmp\']\n    flags_to_try = []\n    if sys.platform == \'darwin\':\n        flags_to_try = [libtool_flags, ld_flags]\n    else:\n        flags_to_try = [ld_flags, libtool_flags]\n    for link_flags in flags_to_try:\n        try:\n            test_compile(build_ext, \'test_link_flags\', extra_link_preargs=link_flags,\n                         code=textwrap.dedent(\'\'\'\\\n                    void test() {\n                    }\n                    \'\'\'))\n\n            return link_flags\n        except (CompileError, LinkError):\n            last_err = \'Unable to determine C++ link flags (see error above).\'\n        except Exception:\n            last_err = \'Unable to determine C++ link flags.  \' \\\n                       \'Last error:\\n\\n%s\' % traceback.format_exc()\n\n    raise DistutilsPlatformError(last_err)\n\ndef has_rdma_header():\n    ret_code = subprocess.call(\n        ""echo \'#include <rdma/rdma_cma.h>\' | cpp -H -o /dev/null 2>/dev/null"", shell=True)\n    if ret_code != 0:\n        import warnings\n        warnings.warn(""\\n\\n No RDMA header file detected. Will disable RDMA for compilation! \\n\\n"")\n    return ret_code==0\n\ndef get_common_options(build_ext):\n    cpp_flags = get_cpp_flags(build_ext)\n    link_flags = get_link_flags(build_ext)\n\n    MACROS = [(\'EIGEN_MPL2_ONLY\', 1)]\n    INCLUDES = [\'3rdparty/ps-lite/include\']\n    SOURCES = [\'byteps/common/common.cc\',\n               \'byteps/common/operations.cc\',\n               \'byteps/common/core_loops.cc\',\n               \'byteps/common/global.cc\',\n               \'byteps/common/logging.cc\',\n               \'byteps/common/communicator.cc\',\n               \'byteps/common/scheduled_queue.cc\',\n               \'byteps/common/ready_table.cc\',\n               \'byteps/common/shared_memory.cc\',\n               \'byteps/common/nccl_manager.cc\',\n               \'byteps/common/cpu_reducer.cc\']\n    if ""BYTEPS_USE_MPI"" in os.environ and os.environ[""BYTEPS_USE_MPI""] == ""1"":\n        mpi_flags = get_mpi_flags()\n        COMPILE_FLAGS = cpp_flags + \\\n            shlex.split(mpi_flags) + [""-DBYTEPS_USE_MPI""]\n        LINK_FLAGS = link_flags + shlex.split(mpi_flags)\n    else:\n        COMPILE_FLAGS = cpp_flags\n        LINK_FLAGS = link_flags\n    LIBRARY_DIRS = []\n    LIBRARIES = []\n\n    nccl_include_dirs, nccl_lib_dirs, nccl_libs = get_nccl_vals()\n    INCLUDES += nccl_include_dirs\n    LIBRARY_DIRS += nccl_lib_dirs\n    LIBRARIES += nccl_libs\n\n    # RDMA and NUMA libs\n    LIBRARIES += [\'numa\']\n\n    # auto-detect rdma\n    if has_rdma_header():\n        LIBRARIES += [\'rdmacm\', \'ibverbs\', \'rt\']\n\n    # ps-lite\n    EXTRA_OBJECTS = [\'3rdparty/ps-lite/build/libps.a\',\n                     \'3rdparty/ps-lite/deps/lib/libzmq.a\']\n\n    return dict(MACROS=MACROS,\n                INCLUDES=INCLUDES,\n                SOURCES=SOURCES,\n                COMPILE_FLAGS=COMPILE_FLAGS,\n                LINK_FLAGS=LINK_FLAGS,\n                LIBRARY_DIRS=LIBRARY_DIRS,\n                LIBRARIES=LIBRARIES,\n                EXTRA_OBJECTS=EXTRA_OBJECTS)\n\n\ndef build_server(build_ext, options):\n    server_lib.define_macros = options[\'MACROS\']\n    server_lib.include_dirs = options[\'INCLUDES\']\n    server_lib.sources = [\'byteps/server/server.cc\',\n                          \'byteps/common/cpu_reducer.cc\',\n                          \'byteps/common/logging.cc\']\n    server_lib.extra_compile_args = options[\'COMPILE_FLAGS\'] + \\\n        [\'-DBYTEPS_BUILDING_SERVER\']\n    server_lib.extra_link_args = options[\'LINK_FLAGS\']\n    server_lib.extra_objects = options[\'EXTRA_OBJECTS\']\n    server_lib.library_dirs = options[\'LIBRARY_DIRS\']\n\n    # auto-detect rdma\n    if has_rdma_header():\n        server_lib.libraries = [\'rdmacm\', \'ibverbs\', \'rt\']\n    else:\n        server_lib.libraries = []\n\n    build_ext.build_extension(server_lib)\n\n\ndef check_tf_version():\n    try:\n        import tensorflow as tf\n        if LooseVersion(tf.__version__) < LooseVersion(\'1.1.0\'):\n            raise DistutilsPlatformError(\n                \'Your TensorFlow version %s is outdated.  \'\n                \'BytePS requires tensorflow>=1.1.0\' % tf.__version__)\n    except ImportError:\n        raise DistutilsPlatformError(\n            \'import tensorflow failed, is it installed?\\n\\n%s\' % traceback.format_exc())\n    except AttributeError:\n        # This means that tf.__version__ was not exposed, which makes it *REALLY* old.\n        raise DistutilsPlatformError(\n            \'Your TensorFlow version is outdated. BytePS requires tensorflow>=1.1.0\')\n\n\ndef get_tf_include_dirs():\n    import tensorflow as tf\n    tf_inc = tf.sysconfig.get_include()\n    return [tf_inc, \'%s/external/nsync/public\' % tf_inc]\n\n\ndef get_tf_lib_dirs():\n    import tensorflow as tf\n    tf_lib = tf.sysconfig.get_lib()\n    return [tf_lib]\n\n\ndef get_tf_libs(build_ext, lib_dirs, cpp_flags):\n    last_err = None\n    for tf_libs in [[\'tensorflow_framework\'], []]:\n        try:\n            lib_file = test_compile(build_ext, \'test_tensorflow_libs\',\n                                    library_dirs=lib_dirs, libraries=tf_libs,\n                                    extra_compile_preargs=cpp_flags,\n                                    code=textwrap.dedent(\'\'\'\\\n                    void test() {\n                    }\n                    \'\'\'))\n\n            from tensorflow.python.framework import load_library\n            load_library.load_op_library(lib_file)\n\n            return tf_libs\n        except (CompileError, LinkError):\n            last_err = \'Unable to determine -l link flags to use with TensorFlow (see error above).\'\n        except Exception:\n            last_err = \'Unable to determine -l link flags to use with TensorFlow.  \' \\\n                       \'Last error:\\n\\n%s\' % traceback.format_exc()\n\n    raise DistutilsPlatformError(last_err)\n\n\ndef get_tf_abi(build_ext, include_dirs, lib_dirs, libs, cpp_flags):\n    last_err = None\n    cxx11_abi_macro = \'_GLIBCXX_USE_CXX11_ABI\'\n    for cxx11_abi in [\'0\', \'1\']:\n        try:\n            lib_file = test_compile(build_ext, \'test_tensorflow_abi\',\n                                    macros=[(cxx11_abi_macro, cxx11_abi)],\n                                    include_dirs=include_dirs, library_dirs=lib_dirs,\n                                    libraries=libs, extra_compile_preargs=cpp_flags,\n                                    code=textwrap.dedent(\'\'\'\\\n                #include <string>\n                #include ""tensorflow/core/framework/op.h""\n                #include ""tensorflow/core/framework/op_kernel.h""\n                #include ""tensorflow/core/framework/shape_inference.h""\n                void test() {\n                    auto ignore = tensorflow::strings::StrCat(""a"", ""b"");\n                }\n                \'\'\'))\n\n            from tensorflow.python.framework import load_library\n            load_library.load_op_library(lib_file)\n\n            return cxx11_abi_macro, cxx11_abi\n        except (CompileError, LinkError):\n            last_err = \'Unable to determine CXX11 ABI to use with TensorFlow (see error above).\'\n        except Exception:\n            last_err = \'Unable to determine CXX11 ABI to use with TensorFlow.  \' \\\n                       \'Last error:\\n\\n%s\' % traceback.format_exc()\n\n    raise DistutilsPlatformError(last_err)\n\n\ndef get_tf_flags(build_ext, cpp_flags):\n    import tensorflow as tf\n    try:\n        return tf.sysconfig.get_compile_flags(), tf.sysconfig.get_link_flags()\n    except AttributeError:\n        # fallback to the previous logic\n        tf_include_dirs = get_tf_include_dirs()\n        tf_lib_dirs = get_tf_lib_dirs()\n        tf_libs = get_tf_libs(build_ext, tf_lib_dirs, cpp_flags)\n        tf_abi = get_tf_abi(build_ext, tf_include_dirs,\n                            tf_lib_dirs, tf_libs, cpp_flags)\n\n        compile_flags = []\n        for include_dir in tf_include_dirs:\n            compile_flags.append(\'-I%s\' % include_dir)\n        if tf_abi:\n            compile_flags.append(\'-D%s=%s\' % tf_abi)\n\n        link_flags = []\n        for lib_dir in tf_lib_dirs:\n            link_flags.append(\'-L%s\' % lib_dir)\n        for lib in tf_libs:\n            link_flags.append(\'-l%s\' % lib)\n\n        return compile_flags, link_flags\n\n\ndef build_tf_extension(build_ext, options):\n    check_tf_version()\n    tf_compile_flags, tf_link_flags = get_tf_flags(\n        build_ext, options[\'COMPILE_FLAGS\'])\n\n    # We assume we have CUDA\n    cuda_include_dirs, cuda_lib_dirs = get_cuda_dirs(\n        build_ext, options[\'COMPILE_FLAGS\'])\n    options[\'MACROS\'] += [(\'HAVE_CUDA\', \'1\')]\n    options[\'INCLUDES\'] += cuda_include_dirs\n    options[\'LIBRARY_DIRS\'] += cuda_lib_dirs\n    options[\'LIBRARIES\'] += [\'cudart\']\n\n    tensorflow_lib.define_macros = options[\'MACROS\']\n    tensorflow_lib.include_dirs = options[\'INCLUDES\']\n    tensorflow_lib.sources = options[\'SOURCES\'] + \\\n        [\'byteps/tensorflow/ops.cc\']\n    tensorflow_lib.extra_compile_args = options[\'COMPILE_FLAGS\'] + \\\n        tf_compile_flags\n    tensorflow_lib.extra_link_args = options[\'LINK_FLAGS\'] + tf_link_flags\n    tensorflow_lib.library_dirs = options[\'LIBRARY_DIRS\']\n    tensorflow_lib.libraries = options[\'LIBRARIES\']\n    tensorflow_lib.extra_objects = options[\'EXTRA_OBJECTS\']\n\n    build_ext.build_extension(tensorflow_lib)\n\n\ndef check_mx_version():\n    try:\n        import mxnet as mx\n        if mx.__version__ < \'1.4.0\':\n            raise DistutilsPlatformError(\n                \'Your MXNet version %s is outdated.  \'\n                \'BytePS requires mxnet>=1.4.0\' % mx.__version__)\n    except ImportError:\n        raise DistutilsPlatformError(\n            \'import mxnet failed, is it installed?\\n\\n%s\' % traceback.format_exc())\n    except AttributeError:\n        raise DistutilsPlatformError(\n            \'Your MXNet version is outdated. BytePS requires mxnet>=1.4.0\')\n\n\ndef get_mx_include_dirs():\n    try:\n        import mxnet as mx\n        path = mx.libinfo.find_include_path()\n        return path\n    except:\n        # Try to find the path automatically\n        tmp_mxnet_dir = os.getenv(\n            ""BYTEPS_SERVER_MXNET_PATH"", ""/root/mxnet15-rdma"")\n        MXNET_ROOT = os.getenv(""MXNET_SOURCE_ROOT"", tmp_mxnet_dir)\n        return os.path.join(MXNET_ROOT, \'include/\')\n\n\ndef get_mx_lib_dirs():\n    import mxnet as mx\n    mx_libs = mx.libinfo.find_lib_path()\n    mx_lib_dirs = [os.path.dirname(mx_lib) for mx_lib in mx_libs]\n    return mx_lib_dirs\n\n\ndef get_mx_libs(build_ext, lib_dirs, cpp_flags):\n    last_err = None\n    cpp_flags.append(\'-DDMLC_USE_RDMA\')\n    for mx_libs in [[\'mxnet\'], []]:\n        try:\n            lib_file = test_compile(build_ext, \'test_mx_libs\',\n                                    library_dirs=lib_dirs, libraries=mx_libs,\n                                    extra_compile_preargs=cpp_flags,\n                                    code=textwrap.dedent(\'\'\'\\\n                    void test() {\n                    }\n                    \'\'\'))\n            return mx_libs\n        except (CompileError, LinkError):\n            last_err = \'Unable to determine -l link flags to use with MXNet (see error above).\'\n        except Exception:\n            last_err = \'Unable to determine -l link flags to use with MXNet.  \' \\\n                       \'Last error:\\n\\n%s\' % traceback.format_exc()\n\n    raise DistutilsPlatformError(last_err)\n\n\ndef get_mx_flags(build_ext, cpp_flags):\n    mx_include_dirs = [get_mx_include_dirs()]\n    mx_lib_dirs = get_mx_lib_dirs()\n    mx_libs = get_mx_libs(build_ext, mx_lib_dirs, cpp_flags)\n\n    compile_flags = []\n    has_mkldnn = is_mx_mkldnn()\n    for include_dir in mx_include_dirs:\n        compile_flags.append(\'-I%s\' % include_dir)\n        if has_mkldnn:\n            mkldnn_include = os.path.join(include_dir, \'mkldnn\')\n            compile_flags.append(\'-I%s\' % mkldnn_include)\n\n    link_flags = []\n    for lib_dir in mx_lib_dirs:\n        link_flags.append(\'-Wl,-rpath,%s\' % lib_dir)\n        link_flags.append(\'-L%s\' % lib_dir)\n\n    for lib in mx_libs:\n        link_flags.append(\'-l%s\' % lib)\n\n    return compile_flags, link_flags\n\n\ndef check_macro(macros, key):\n    return any(k == key and v for k, v in macros)\n\n\ndef set_macro(macros, key, new_value):\n    if any(k == key for k, _ in macros):\n        return [(k, new_value if k == key else v) for k, v in macros]\n    else:\n        return macros + [(key, new_value)]\n\n\ndef is_mx_cuda():\n    try:\n        from mxnet import runtime\n        features = runtime.Features()\n        return features.is_enabled(\'CUDA\')\n    except Exception:\n        if \'linux\' in sys.platform:\n            try:\n                import mxnet as mx\n                mx_libs = mx.libinfo.find_lib_path()\n                for mx_lib in mx_libs:\n                    output = subprocess.check_output([\'readelf\', \'-d\', mx_lib])\n                    if \'cuda\' in str(output):\n                        return True\n                return False\n            except Exception:\n                return False\n    return False\n\n\ndef get_cuda_dirs(build_ext, cpp_flags):\n    cuda_include_dirs = []\n    cuda_lib_dirs = []\n\n    cuda_home = os.environ.get(\'BYTEPS_CUDA_HOME\')\n    if cuda_home:\n        cuda_include_dirs += [\'%s/include\' % cuda_home]\n        cuda_lib_dirs += [\'%s/lib\' % cuda_home, \'%s/lib64\' % cuda_home]\n\n    cuda_include = os.environ.get(\'BYTEPS_CUDA_INCLUDE\')\n    if cuda_include:\n        cuda_include_dirs += [cuda_include]\n\n    cuda_lib = os.environ.get(\'BYTEPS_CUDA_LIB\')\n    if cuda_lib:\n        cuda_lib_dirs += [cuda_lib]\n\n    if not cuda_include_dirs and not cuda_lib_dirs:\n        # default to /usr/local/cuda\n        cuda_include_dirs += [\'/usr/local/cuda/include\']\n        cuda_lib_dirs += [\'/usr/local/cuda/lib\', \'/usr/local/cuda/lib64\']\n\n    try:\n        test_compile(build_ext, \'test_cuda\', libraries=[\'cudart\'], include_dirs=cuda_include_dirs,\n                     library_dirs=cuda_lib_dirs, extra_compile_preargs=cpp_flags,\n                     code=textwrap.dedent(\'\'\'\\\n            #include <cuda_runtime.h>\n            void test() {\n                cudaSetDevice(0);\n            }\n            \'\'\'))\n    except (CompileError, LinkError):\n        raise DistutilsPlatformError(\n            \'CUDA library was not found (see error above).\\n\'\n            \'Please specify correct CUDA location with the BYTEPS_CUDA_HOME \'\n            \'environment variable or combination of BYTEPS_CUDA_INCLUDE and \'\n            \'BYTEPS_CUDA_LIB environment variables.\\n\\n\'\n            \'BYTEPS_CUDA_HOME - path where CUDA include and lib directories can be found\\n\'\n            \'BYTEPS_CUDA_INCLUDE - path to CUDA include directory\\n\'\n            \'BYTEPS_CUDA_LIB - path to CUDA lib directory\')\n\n    return cuda_include_dirs, cuda_lib_dirs\n\n\ndef get_nccl_vals():\n    nccl_include_dirs = []\n    nccl_lib_dirs = []\n    nccl_libs = []\n\n    nccl_home = os.environ.get(\'BYTEPS_NCCL_HOME\', \'/usr/local/nccl\')\n    if nccl_home:\n        nccl_include_dirs += [\'%s/include\' % nccl_home]\n        nccl_lib_dirs += [\'%s/lib\' % nccl_home, \'%s/lib64\' % nccl_home]\n\n    nccl_link_mode = os.environ.get(\'BYTEPS_NCCL_LINK\', \'STATIC\')\n    if nccl_link_mode.upper() == \'SHARED\':\n        nccl_libs += [\'nccl\']\n    else:\n        nccl_libs += [\'nccl_static\']\n\n    return nccl_include_dirs, nccl_lib_dirs, nccl_libs\n\ndef is_mx_mkldnn():\n    try:\n        from mxnet import runtime\n        features = runtime.Features()\n        return features.is_enabled(\'MKLDNN\')\n    except Exception:\n        msg = \'INFO: Cannot detect if MKLDNN is enabled in MXNet. Please \\\n            set MXNET_USE_MKLDNN=1 if MKLDNN is enabled in your MXNet build.\'\n        if \'linux\' not in sys.platform:\n            # MKLDNN is only enabled by default in MXNet Linux build. Return \n            # False by default for non-linux build but still allow users to \n            # enable it by using MXNET_USE_MKLDNN env variable. \n            print(msg)\n            return os.environ.get(\'MXNET_USE_MKLDNN\', \'0\') == \'1\'\n        else:\n            try:\n                import mxnet as mx\n                mx_libs = mx.libinfo.find_lib_path()\n                for mx_lib in mx_libs:\n                    output = subprocess.check_output([\'readelf\', \'-d\', mx_lib])\n                    if \'mkldnn\' in str(output):\n                        return True\n                return False\n            except Exception:\n                print(msg)\n                return os.environ.get(\'MXNET_USE_MKLDNN\', \'0\') == \'1\'\n\n\ndef build_mx_extension(build_ext, options):\n    # clear ROLE -- installation does not need this\n    os.environ.pop(""DMLC_ROLE"", None)\n\n    check_mx_version()\n    mx_compile_flags, mx_link_flags = get_mx_flags(\n        build_ext, options[\'COMPILE_FLAGS\'])\n\n    mx_have_cuda = is_mx_cuda()\n    macro_have_cuda = check_macro(options[\'MACROS\'], \'HAVE_CUDA\')\n    if not mx_have_cuda and macro_have_cuda:\n        raise DistutilsPlatformError(\n            \'BytePS build with GPU support was requested, but this MXNet \'\n            \'installation does not support CUDA.\')\n\n    # Update HAVE_CUDA to mean that MXNet supports CUDA.\n    if mx_have_cuda and not macro_have_cuda:\n        cuda_include_dirs, cuda_lib_dirs = get_cuda_dirs(\n            build_ext, options[\'COMPILE_FLAGS\'])\n        options[\'MACROS\'] += [(\'HAVE_CUDA\', \'1\')]\n        options[\'INCLUDES\'] += cuda_include_dirs\n        options[\'LIBRARY_DIRS\'] += cuda_lib_dirs\n        options[\'LIBRARIES\'] += [\'cudart\']\n\n    mxnet_lib.define_macros = options[\'MACROS\']\n    if check_macro(options[\'MACROS\'], \'HAVE_CUDA\'):\n        mxnet_lib.define_macros += [(\'MSHADOW_USE_CUDA\', \'1\')]\n    else:\n        mxnet_lib.define_macros += [(\'MSHADOW_USE_CUDA\', \'0\')]\n    if is_mx_mkldnn():\n        mxnet_lib.define_macros += [(\'MXNET_USE_MKLDNN\', \'1\')]\n    else:\n        mxnet_lib.define_macros += [(\'MXNET_USE_MKLDNN\', \'0\')]  \n    mxnet_lib.define_macros += [(\'MSHADOW_USE_MKL\', \'0\')]\n\n    # use MXNet\'s DMLC headers first instead of ps-lite\'s\n    options[\'INCLUDES\'].insert(0, get_mx_include_dirs())\n    mxnet_lib.include_dirs = options[\'INCLUDES\']\n    mxnet_lib.sources = options[\'SOURCES\'] + \\\n        [\'byteps/mxnet/ops.cc\',\n         \'byteps/mxnet/ready_event.cc\',\n         \'byteps/mxnet/tensor_util.cc\',\n         \'byteps/mxnet/cuda_util.cc\',\n         \'byteps/mxnet/adapter.cc\']\n    mxnet_lib.extra_compile_args = options[\'COMPILE_FLAGS\'] + \\\n        mx_compile_flags\n    mxnet_lib.extra_link_args = options[\'LINK_FLAGS\'] + mx_link_flags\n    mxnet_lib.extra_objects = options[\'EXTRA_OBJECTS\']\n    mxnet_lib.library_dirs = options[\'LIBRARY_DIRS\']\n    mxnet_lib.libraries = options[\'LIBRARIES\']\n\n    build_ext.build_extension(mxnet_lib)\n\n\ndef dummy_import_torch():\n    try:\n        import torch\n    except:\n        pass\n\n\ndef parse_version(version_str):\n    if ""dev"" in version_str:\n        return 9999999999\n    m = re.match(\'^(\\d+)(?:\\.(\\d+))?(?:\\.(\\d+))?(?:\\.(\\d+))?\', version_str)\n    if m is None:\n        return None\n\n    # turn version string to long integer\n    version = int(m.group(1)) * 10 ** 9\n    if m.group(2) is not None:\n        version += int(m.group(2)) * 10 ** 6\n    if m.group(3) is not None:\n        version += int(m.group(3)) * 10 ** 3\n    if m.group(4) is not None:\n        version += int(m.group(4))\n    return version\n\n\ndef check_torch_version():\n    try:\n        import torch\n        if torch.__version__ < \'1.0.1\':\n            raise DistutilsPlatformError(\n                \'Your torch version %s is outdated.  \'\n                \'BytePS requires torch>=1.0.1\' % torch.__version__)\n    except ImportError:\n            print(\'import torch failed, is it installed?\\n\\n%s\' %\n                  traceback.format_exc())\n\n    # parse version\n    version = parse_version(torch.__version__)\n    if version is None:\n        raise DistutilsPlatformError(\n            \'Unable to determine PyTorch version from the version string \\\'%s\\\'\' % torch.__version__)\n    return version\n\n\ndef is_torch_cuda(build_ext, include_dirs, extra_compile_args):\n    try:\n        from torch.utils.cpp_extension import include_paths\n        test_compile(build_ext, \'test_torch_cuda\', include_dirs=include_dirs + include_paths(cuda=True),\n                     extra_compile_preargs=extra_compile_args, code=textwrap.dedent(\'\'\'\\\n            #include <THC/THC.h>\n            void test() {\n            }\n            \'\'\'))\n        return True\n    except (CompileError, LinkError, EnvironmentError):\n        print(\'INFO: Above error indicates that this PyTorch installation does not support CUDA.\')\n        return False\n\n\ndef build_torch_extension(build_ext, options, torch_version):\n    pytorch_compile_flags = [""-std=c++14"" if flag == ""-std=c++11"" \n                             else flag for flag in options[\'COMPILE_FLAGS\']]\n    have_cuda = is_torch_cuda(build_ext, include_dirs=options[\'INCLUDES\'],\n                              extra_compile_args=pytorch_compile_flags)\n    if not have_cuda and check_macro(options[\'MACROS\'], \'HAVE_CUDA\'):\n        raise DistutilsPlatformError(\n            \'byteps build with GPU support was requested, but this PyTorch \'\n            \'installation does not support CUDA.\')\n\n    # Update HAVE_CUDA to mean that PyTorch supports CUDA.\n    updated_macros = set_macro(\n        options[\'MACROS\'], \'HAVE_CUDA\', str(int(have_cuda)))\n\n    # Export TORCH_VERSION equal to our representation of torch.__version__. Internally it\'s\n    # used for backwards compatibility checks.\n    updated_macros = set_macro(\n       updated_macros, \'TORCH_VERSION\', str(torch_version))\n\n    # Always set _GLIBCXX_USE_CXX11_ABI, since PyTorch can only detect whether it was set to 1.\n    import torch\n    updated_macros = set_macro(updated_macros, \'_GLIBCXX_USE_CXX11_ABI\',\n                               str(int(torch.compiled_with_cxx11_abi())))\n\n    # PyTorch requires -DTORCH_API_INCLUDE_EXTENSION_H\n    updated_macros = set_macro(\n        updated_macros, \'TORCH_API_INCLUDE_EXTENSION_H\', \'1\')\n\n    if have_cuda:\n        from torch.utils.cpp_extension import CUDAExtension as TorchExtension\n    else:\n        # CUDAExtension fails with `ld: library not found for -lcudart` if CUDA is not present\n        from torch.utils.cpp_extension import CppExtension as TorchExtension\n\n    ext = TorchExtension(pytorch_lib.name,\n                         define_macros=updated_macros,\n                         include_dirs=options[\'INCLUDES\'],\n                         sources=options[\'SOURCES\'] + [\'byteps/torch/ops.cc\',\n                                                       \'byteps/torch/ready_event.cc\',\n                                                       \'byteps/torch/cuda_util.cc\',\n                                                       \'byteps/torch/adapter.cc\',\n                                                       \'byteps/torch/handle_manager.cc\'],\n                         extra_compile_args=pytorch_compile_flags,\n                         extra_link_args=options[\'LINK_FLAGS\'],\n                         extra_objects=options[\'EXTRA_OBJECTS\'],\n                         library_dirs=options[\'LIBRARY_DIRS\'],\n                         libraries=options[\'LIBRARIES\'])\n\n    # Patch an existing pytorch_lib extension object.\n    for k, v in ext.__dict__.items():\n        pytorch_lib.__dict__[k] = v\n    build_ext.build_extension(pytorch_lib)\n\n\n# run the customize_compiler\nclass custom_build_ext(build_ext):\n    def build_extensions(self):\n        pre_setup.setup()\n\n        make_option = """"\n        # To resolve tf-gcc incompatibility\n        has_cxx_flag = False\n        glibcxx_flag = False\n        if not int(os.environ.get(\'BYTEPS_WITHOUT_TENSORFLOW\', 0)):\n            try:\n                import tensorflow as tf\n                make_option += \'ADD_CFLAGS=""\'\n                for flag in tf.sysconfig.get_compile_flags():\n                    if \'D_GLIBCXX_USE_CXX11_ABI\' in flag:\n                        has_cxx_flag = True\n                        glibcxx_flag = False if (flag[-1]==\'0\') else True\n                        make_option += flag + \' \'\n                        break\n                make_option += \'"" \'\n            except:\n                pass\n\n        # To resolve torch-gcc incompatibility\n        if not int(os.environ.get(\'BYTEPS_WITHOUT_PYTORCH\', 0)):\n            try:\n                import torch\n                torch_flag = torch.compiled_with_cxx11_abi()\n                if has_cxx_flag:\n                    if glibcxx_flag != torch_flag:\n                        raise DistutilsError(\n                            \'-D_GLIBCXX_USE_CXX11_ABI is not consistent between TensorFlow and PyTorch, \'\n                            \'consider install them separately.\')\n                    else:\n                        pass\n                else:\n                    make_option += \'ADD_CFLAGS=-D_GLIBCXX_USE_CXX11_ABI=\' + \\\n                                    str(int(torch_flag)) + \' \'\n                    has_cxx_flag = True\n                    glibcxx_flag = torch_flag\n            except:\n                pass\n\n        if not os.path.exists(""3rdparty/ps-lite/build/libps.a"") or \\\n           not os.path.exists(""3rdparty/ps-lite/deps/lib""):\n            if os.environ.get(\'CI\', \'false\') == \'false\':\n                make_option += ""-j ""\n            if has_rdma_header():\n                make_option += ""USE_RDMA=1 ""\n\n            make_option += pre_setup.extra_make_option()\n\n\n            make_process = subprocess.Popen(\'make \' + make_option,\n                                            cwd=\'3rdparty/ps-lite\',\n                                            stdout=sys.stdout,\n                                            stderr=sys.stderr,\n                                            shell=True)\n            make_process.communicate()\n            if make_process.returncode:\n                raise DistutilsSetupError(\'An ERROR occured while running the \'\n                                          \'Makefile for the ps-lite library. \'\n                                          \'Exit code: {0}\'.format(make_process.returncode))\n\n        options = get_common_options(self)\n        if has_cxx_flag:\n            options[\'COMPILE_FLAGS\'] += [\'-D_GLIBCXX_USE_CXX11_ABI=\' + str(int(glibcxx_flag))]\n\n        built_plugins = []\n        try:\n            build_server(self, options)\n        except:\n            raise DistutilsSetupError(\'An ERROR occured while building the server module.\\n\\n\'\n                                      \'%s\' % traceback.format_exc())\n\n        # If PyTorch is installed, it must be imported before others, otherwise\n        # we may get an error: dlopen: cannot load any more object with static TLS\n        if not int(os.environ.get(\'BYTEPS_WITHOUT_PYTORCH\', 0)):\n            dummy_import_torch()\n\n        if not int(os.environ.get(\'BYTEPS_WITHOUT_TENSORFLOW\', 0)):\n            try:\n                build_tf_extension(self, options)\n                built_plugins.append(True)\n                print(\'INFO: Tensorflow extension is built successfully.\')\n            except:\n                if not int(os.environ.get(\'BYTEPS_WITH_TENSORFLOW\', 0)):\n                    print(\'INFO: Unable to build TensorFlow plugin, will skip it.\\n\\n\'\n                          \'%s\' % traceback.format_exc())\n                    built_plugins.append(False)\n                else:\n                    raise\n        if not int(os.environ.get(\'BYTEPS_WITHOUT_PYTORCH\', 0)):\n            try:\n                torch_version = check_torch_version()\n                build_torch_extension(self, options, torch_version)\n                built_plugins.append(True)\n                print(\'INFO: PyTorch extension is built successfully.\')\n            except:\n                if not int(os.environ.get(\'BYTEPS_WITH_PYTORCH\', 0)):\n                    print(\'INFO: Unable to build PyTorch plugin, will skip it.\\n\\n\'\n                          \'%s\' % traceback.format_exc())\n                    built_plugins.append(False)\n                else:\n                    raise\n        if not int(os.environ.get(\'BYTEPS_WITHOUT_MXNET\', 0)):\n            # fix ""libcuda.so.1 not found"" issue\n            cuda_home = os.environ.get(\'BYTEPS_CUDA_HOME\', \'/usr/local/cuda\')\n            cuda_stub_path = cuda_home + \'/lib64/stubs\'\n            ln_command = ""cd "" + cuda_stub_path + ""; ln -sf libcuda.so libcuda.so.1""\n            os.system(ln_command)\n            try:\n                build_mx_extension(self, options)\n                built_plugins.append(True)\n                print(\'INFO: MXNet extension is built successfully.\')\n            except:\n                if not int(os.environ.get(\'BYTEPS_WITH_MXNET\', 0)):\n                    print(\'INFO: Unable to build MXNet plugin, will skip it.\\n\\n\'\n                          \'%s\' % traceback.format_exc())\n                    built_plugins.append(False)\n                else:\n                    raise\n            finally:\n                os.system(""rm -rf "" + cuda_stub_path + ""/libcuda.so.1"")\n\n        if not built_plugins:\n            print(\'INFO: Only server module is built.\')\n            return\n\n        if not any(built_plugins):\n            raise DistutilsError(\n                \'None of TensorFlow, MXNet, PyTorch plugins were built. See errors above.\')\n\n\n# Where the magic happens:\n\nif os.path.exists(\'launcher/launch.py\'):\n    if not os.path.exists(\'bin\'):\n        os.mkdir(\'bin\')\n    shutil.copyfile(\'launcher/launch.py\', \'bin/bpslaunch\')\n\nsetup(\n    name=NAME,\n    version=about[\'__version__\'],\n    description=DESCRIPTION,\n    long_description=long_description,\n    long_description_content_type=\'text/markdown\',\n    author=AUTHOR,\n    author_email=EMAIL,\n    python_requires=REQUIRES_PYTHON,\n    url=URL,\n    packages=find_packages(exclude=(\'tests\',)),\n    install_requires=REQUIRED,\n    extras_require=EXTRAS,\n    include_package_data=True,\n    license=\'Apache\',\n    classifiers=[\n        # Trove classifiers\n        # Full list: https://pypi.python.org/pypi?%3Aaction=list_classifiers\n        \'License :: OSI Approved :: Apache Software License\',\n        \'Programming Language :: Python\',\n        \'Programming Language :: Python :: 3\',\n        \'Programming Language :: Python :: 3.6\',\n        \'Programming Language :: Python :: Implementation :: CPython\',\n        \'Programming Language :: Python :: Implementation :: PyPy\',\n        \'Operating System :: POSIX :: Linux\'\n    ],\n    ext_modules=[server_lib, tensorflow_lib, mxnet_lib, pytorch_lib],\n    # $ setup.py publish support.\n    cmdclass={\n        \'upload\': UploadCommand,\n        \'build_ext\': custom_build_ext\n    },\n    # cffi is required for PyTorch\n    # If cffi is specified in setup_requires, it will need libffi to be installed on the machine,\n    # which is undesirable.  Luckily, `install` action will install cffi before executing build,\n    # so it\'s only necessary for `build*` or `bdist*` actions.\n    setup_requires=[],\n    scripts=[\'bin/bpslaunch\']\n)\n'"
byteps/__init__.py,0,b''
byteps/__version__.py,0,"b""VERSION = (0, 2, 4)\n\n__version__ = '.'.join(map(str, VERSION))\n"""
launcher/dist_launcher.py,0,"b'#!/usr/bin/python\n""""""\nLaunch a distributed job for BytePS\n""""""\nimport argparse\nimport os, sys\nimport signal\nimport logging\nimport subprocess\nfrom multiprocessing import Pool, Process\nfrom threading import Thread\n\ndef preprocess_envs(args_envs):\n    envs_map = {}\n    for item in args_envs:\n        i = item.find("":"")\n        if i != -1:\n            key = item[:i]\n            val = item[i+1:]\n        envs_map[key] = val\n    return envs_map\n\ndef get_env(envs_map):\n    envs = []\n    # get system envs\n    keys = [\'OMP_NUM_THREADS\', \'KMP_AFFINITY\']\n    for k in keys:\n        v = os.getenv(k)\n        if v is not None:\n            envs.append(\'export \' + k + \'=\' + v + \';\')\n    # get ass_envs\n    for k, v in envs_map.items():\n        envs.append(\'export \' + str(k) + \'=\' + str(v) + \';\')\n    return (\' \'.join(envs))\n\ndef get_hosts_from_file(filename):\n    with open(filename) as f:\n        tmp = f.readlines()\n    assert len(tmp) > 0\n    hosts = []\n    for h in tmp:\n        if len(h.strip()) > 0:\n            # parse addresses of the form ip:port\n            h = h.strip()\n            i = h.find("":"")\n            p = ""22""\n            if i != -1:\n                p = h[i+1:]\n                h = h[:i]\n            # hosts now contain the pair ip, port\n            hosts.append((h, p))\n    return hosts\n\n\ndef start_ssh(prog, node, port, username, fname):\n    def run(prog):\n        subprocess.check_call(prog, shell=True)\n\n    dirname = \'sshlog\'\n    if not os.path.exists(dirname):\n        os.mkdir(dirname)\n\n    pname = dirname + \'/\' + fname\n    if username is not None:\n        prog = \'ssh -o StrictHostKeyChecking=no \' + \' -l \' + username \\\n               + \' \' + node + \' -p \' + port + \' \\\'\' + prog + \'\\\'\' \\\n               + \' > \' + pname + \'.stdout\' + \' 2>\' + pname + \'.stderr&\'\n    else:\n        prog = \'ssh -o StrictHostKeyChecking=no \' + node + \' -p \' + port + \' \\\'\' + prog + \'\\\'\' \\\n               + \' > \' + pname + \'.stdout\' + \' 2>\' + pname + \'.stderr&\'\n\n    thread = Thread(target=run, args=(prog,))\n    thread.setDaemon(True)\n    thread.start()\n    return thread\n\n\ndef submit(args):\n    worker_hosts = get_hosts_from_file(args.worker_hostfile)\n    server_hosts = get_hosts_from_file(args.server_hostfile)\n    num_worker = len(worker_hosts)\n    num_server = len(server_hosts)\n    assert num_worker >= 1\n    assert num_server >= 1\n    print(\'Launch %d workers and %d servers\' % (num_worker, num_server))\n\n    # common env\n    pass_envs = preprocess_envs(args.env)\n    pass_envs[\'DMLC_NUM_WORKER\'] = str(num_worker)\n    pass_envs[\'DMLC_NUM_SERVER\'] = str(num_server)\n    pass_envs[\'DMLC_INTERFACE\'] = str(args.interface)\n    pass_envs[\'DMLC_PS_ROOT_URI\'] = str(args.scheduler_ip)\n    pass_envs[\'DMLC_PS_ROOT_PORT\'] = str(args.scheduler_port)\n\n    username = \'\'\n    if args.username is not None:\n        username = args.username\n\n    threads = []\n    for (node, port) in [(args.scheduler_ip, args.scheduler_ssh_port)]:\n        name = \'scheduler\'\n        pass_envs[\'DMLC_ROLE\'] = name\n        prog = get_env(pass_envs) + (\' \'.join(args.command))\n        threads.append(start_ssh(prog, node, port, username, name))\n    for i, (node, port) in enumerate(worker_hosts):\n        name = \'worker\'\n        pass_envs[\'DMLC_ROLE\'] = name\n        pass_envs[\'DMLC_WORKER_ID\'] = str(i)\n        prog = get_env(pass_envs) + (\' \'.join(args.command))\n        threads.append(start_ssh(prog, node, port, username, name + str(i)))\n    for i, (node, port) in enumerate(server_hosts):\n        name = \'server\'\n        pass_envs[\'DMLC_ROLE\'] = name\n        prog = get_env(pass_envs) + (\' \'.join(args.command))\n        threads.append(start_ssh(prog, node, port, username, name + str(i)))\n\n    for t in threads:\n        t.join()\n\n\ndef main():\n    parser = argparse.ArgumentParser(description=\'Launch a distributed training job for BytePS\')\n    parser.add_argument(\'-WH\', \'--worker-hostfile\', required=True, type=str,\n                        help = \'the hostfile of worker machines which will run the job.\')\n    parser.add_argument(\'-SH\', \'--server-hostfile\', required=True, type=str,\n                        help = \'the hostfile of server machines which will run the job.\')\n    parser.add_argument(\'--scheduler-ip\', required=True, type=str,\n                        help = \'the ip address of the scheduler\')\n    parser.add_argument(\'--scheduler-port\', required=True, type=int,\n                        help = \'the port of the scheduler\')\n    parser.add_argument(\'--interface\', type=str, default=\'eth0\',\n                        help = \'the network interface to use\')\n    parser.add_argument(\'--env\', action=\'append\', default=[],\n                        help = \'Given a pair of environment_variable:value, sets this value of \\\n                        environment variable for all workers and servers. Example OMP_NUM_THREADS:3\')\n    parser.add_argument(\'--username\', type=str,\n                        help = \'the username for ssh\')\n    parser.add_argument(\'--scheduler-ssh-port\', type=str, default=\'22\',\n                        help = \'the ssh port of the scheduler\')\n    parser.add_argument(\'command\', nargs=\'+\',\n                        help = \'command for launching the program\')\n\n    args = parser.parse_args()\n\n    # check necessary args\n    assert args.worker_hostfile\n    assert args.server_hostfile\n    assert args.scheduler_ip\n    assert args.scheduler_port\n\n    submit(args)\n\n\ndef signal_handler(signal, frame):\n    logging.info(\'Stop launcher\')\n    sys.exit(0)\n\nif __name__ == \'__main__\':\n    fmt = \'%(asctime)s %(levelname)s %(message)s\'\n    logging.basicConfig(format=fmt, level=logging.INFO)\n    signal.signal(signal.SIGINT, signal_handler)\n    main()'"
launcher/launch.py,0,"b'#!/usr/bin/python\n\nfrom __future__ import print_function\nimport os\nimport subprocess\nimport threading\nimport sys\nimport time\n\n\nclass PropagatingThread(threading.Thread):\n    """""" propagate exceptions to the parent\'s thread\n    refer to https://stackoverflow.com/a/31614591/9601110\n    """"""\n\n    def run(self):\n        self.exc = None\n        try:\n            if hasattr(self, \'_Thread__target\'):\n                #  python 2.x\n                self.ret = self._Thread__target(\n                    *self._Thread__args, **self._Thread__kwargs)\n            else:\n                # python 3.x\n                self.ret = self._target(*self._args, **self._kwargs)\n        except BaseException as e:\n            self.exc = e\n\n    def join(self):\n        super(PropagatingThread, self).join()\n        if self.exc:\n            raise self.exc\n        return self.exc\n\n\nCOMMON_REQUIRED_ENVS = [""DMLC_ROLE"", ""DMLC_NUM_WORKER"", ""DMLC_NUM_SERVER"",\n                        ""DMLC_PS_ROOT_URI"", ""DMLC_PS_ROOT_PORT""]\nWORKER_REQUIRED_ENVS = [""DMLC_WORKER_ID""]\n\n\ndef check_env():\n    assert ""DMLC_ROLE"" in os.environ and \\\n           os.environ[""DMLC_ROLE""].lower() in [""worker"", ""server"", ""scheduler""]\n    required_envs = COMMON_REQUIRED_ENVS\n    if os.environ[""DMLC_ROLE""] == ""worker"":\n        assert ""DMLC_NUM_WORKER"" in os.environ\n        num_worker = int(os.environ[""DMLC_NUM_WORKER""])\n        assert num_worker >= 1\n        if num_worker == 1:\n            required_envs = []\n        required_envs += WORKER_REQUIRED_ENVS\n    for env in required_envs:\n        if env not in os.environ:\n            print(""The env "" + env + "" is missing"")\n            os._exit(0)\n\n\ndef worker(local_rank, local_size, command):\n    my_env = os.environ.copy()\n    my_env[""BYTEPS_LOCAL_RANK""] = str(local_rank)\n    my_env[""BYTEPS_LOCAL_SIZE""] = str(local_size)\n    if int(os.getenv(""BYTEPS_ENABLE_GDB"", 0)):\n        if command.find(""python"") != 0:\n            command = ""python "" + command\n        command = ""gdb -ex \'run\' -ex \'bt\' -batch --args "" + command\n\n    if os.environ.get(""BYTEPS_TRACE_ON"", """") == ""1"":\n        print(""\\n!!!Enable profiling for WORKER_ID: %s and local_rank: %d!!!"" %\n              (os.environ.get(""DMLC_WORKER_ID""), local_rank))\n        print(""BYTEPS_TRACE_START_STEP: %s\\tBYTEPS_TRACE_END_STEP: %s\\t BYTEPS_TRACE_DIR: %s"" % (os.environ.get(\n            ""BYTEPS_TRACE_START_STEP"", """"), os.environ.get(""BYTEPS_TRACE_END_STEP"", """"), os.environ.get(""BYTEPS_TRACE_DIR"", """")))\n        print(""Command: %s\\n"" % command)\n        sys.stdout.flush()\n        trace_path = os.path.join(os.environ.get(\n            ""BYTEPS_TRACE_DIR"", "".""), str(local_rank))\n        if not os.path.exists(trace_path):\n            os.makedirs(trace_path)\n    subprocess.check_call(command, env=my_env,\n                          stdout=sys.stdout, stderr=sys.stderr, shell=True)\n\n\ndef launch_bps():\n    print(""BytePS launching "" + os.environ[""DMLC_ROLE""])\n    sys.stdout.flush()\n    check_env()\n    if os.environ[""DMLC_ROLE""] == ""worker"":\n        if ""NVIDIA_VISIBLE_DEVICES"" in os.environ:\n            local_size = len(os.environ[""NVIDIA_VISIBLE_DEVICES""].split("",""))\n        else:\n            local_size = 1\n        t = [None] * local_size\n        for i in range(local_size):\n            command = \' \'.join(sys.argv[1:])\n            t[i] = PropagatingThread(target=worker, args=[\n                                    i, local_size, command])\n            t[i].daemon = True\n            t[i].start()\n\n        for i in range(local_size):\n            t[i].join()\n\n    else:\n        import byteps.server\n\n\nif __name__ == ""__main__"":\n    launch_bps()\n'"
tests/test_mxnet.py,0,"b'# Copyright 2018 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport byteps.mxnet as bps\nimport itertools\nimport mxnet as mx\nimport os\nimport numpy as np\nimport unittest\nfrom mxnet.base import MXNetError\nfrom mxnet.test_utils import same\n\nhas_gpu = mx.context.num_gpus() > 0\n\n# MLSL supports only byte, float and double data types\nmlsl_supported_types = set([\'float32\', \'float64\'])\n\nclass MXTest:\n    """"""\n    Tests for ops in byteps.mxnet.\n    """"""\n\n    def _current_context(self):\n        if has_gpu:\n            return mx.gpu(bps.local_rank())\n        else:\n            return mx.current_context()\n\n    def filter_supported_types(self, types):\n        if \'MLSL_ROOT\' in os.environ:\n           types = [t for t in types if t in mlsl_supported_types]\n        return types\n\n    def test_byteps_trainer_param_order(self):\n        size = bps.size()\n        dtypes = self.filter_supported_types([\'float32\'])\n        dims = [1]\n        ctx = self._current_context()\n        net = mx.gluon.nn.Sequential()\n        # layers may be added in a random order for all workers\n        layers = {\'ones_\': 1, \'zeros_\': 0}\n        for name, init in layers.items():\n            net.add(mx.gluon.nn.Dense(10, in_units=10, weight_initializer=mx.init.Constant(init),\n                                      use_bias=False, prefix=name))\n        params = net.collect_params()\n        net.initialize()\n        trainer = bps.DistributedTrainer(params, \'sgd\')\n        trainer._init_params()\n        # check the result of bps_broadcast\n        for name, init in layers.items():\n            weight = params[name + \'weight\'].data()[0].asnumpy()\n            expected = np.full(shape=weight.shape, fill_value=init, dtype=weight.dtype)\n            assert np.array_equal(weight, expected), (weight, expected)\n\n        print(\'test_byteps_trainer_param_order passed\')\n\n    def test_byteps_push_pull(self):\n        """"""Test that the byteps_push_pull correctly sums 1D, 2D, 3D tensors.""""""\n        size = bps.size()\n        dtypes = self.filter_supported_types([\'float32\'])\n        dims = [1]\n        ctx = self._current_context()\n        count = 100\n        shapes = [(), (17)]\n        for dtype, dim in itertools.product(dtypes, dims):\n            # MXNet uses gpu_id as part of the seed, so to get identical seeds\n            # we must set a context.\n            mx.random.seed(10 + 10 * bps.rank(), ctx=ctx)\n            tensor = mx.nd.random.uniform(-100, 100, shape=shapes[dim],\n                                          ctx=ctx)\n            tensor = tensor.astype(dtype)\n\n            print(""tensor before push_pull:"", tensor)\n            bps.byteps_declare_tensor(""tensor_"" + str(count))\n            bps.byteps_push_pull(tensor, name=""tensor_""+str(count))\n            tensor.wait_to_read()\n            print(""tensor after push_pull:"", tensor)\n\n        print(\'test_byteps_push_pull passed\')\n\n\n    def test_byteps_push_pull_inplace(self):\n        """"""Test that the byteps_push_pull correctly sums 1D, 2D, 3D tensors.""""""\n        size = bps.size()\n        dtypes = self.filter_supported_types([\'int32\',   \'int64\',\n                                              \'float32\', \'float64\'])\n        dims = [1, 2, 3]\n        ctx = self._current_context()\n        count = 200\n        shapes = [(), (17), (17, 17), (17, 17, 17)]\n        for dtype, dim in itertools.product(dtypes, dims):\n            mx.random.seed(1234, ctx=ctx)\n            tensor = mx.nd.random.uniform(-100, 100, shape=shapes[dim],\n                                          ctx=ctx)\n            tensor = tensor.astype(dtype)\n            multiplied = tensor.copy()\n            bps.byteps_declare_tensor(""tensor_"" + str(count))\n            bps.byteps_push_pull(tensor, name= ""tensor_"" + str(count))\n            max_difference = mx.nd.max(mx.nd.subtract(tensor, multiplied))\n            count += 1\n\n            # Threshold for floating point equality depends on number of\n            # ranks, since we\'re comparing against precise multiplication.\n            if size <= 3 or dtype in [\'int32\', \'int64\']:\n                threshold = 0\n            elif size < 10:\n                threshold = 1e-4\n            elif size < 15:\n                threshold = 5e-4\n            else:\n                break\n\n            if max_difference > threshold:\n                print(""self"", count, dtype, dim, max_difference, threshold)\n                print(""tensor"", bps.rank(), tensor)\n                print(""multiplied"", bps.rank(), multiplied)\n            assert max_difference <= threshold, \'bps.byteps_push_pull produces \\\n                                                 incorrect results for self\'\n\n        print(\'test_byteps_push_pull_inplace passed\')\n\n\n    def test_byteps_broadcast(self):\n        """"""Test that the broadcast correctly broadcasts 1D, 2D, 3D tensors.""""""\n        rank = bps.rank()\n        size = bps.size()\n\n        # This test does not apply if there is only one worker.\n        if size == 1:\n            return\n\n        dtypes = [\'int32\',   \'int64\',\n                  \'float32\', \'float64\']\n        dims = [1, 2, 3]\n        ctx = self._current_context()\n        count = 300\n        shapes = [(), (17), (17, 17), (17, 17, 17)]\n        root_ranks = list(range(size))\n        for dtype, dim, root_rank in itertools.product(dtypes, dims,\n                                                       root_ranks):\n            tensor = mx.nd.ones(shapes[dim], ctx=ctx) * rank\n            root_tensor = mx.nd.ones(shapes[dim], ctx=ctx) * root_rank\n            tensor = tensor.astype(dtype)\n            root_tensor = root_tensor.astype(dtype)\n\n            broadcast_tensor = bps.broadcast(tensor, root_rank=root_rank,\n                                             name=str(count))\n            if rank != root_rank:\n                if same(tensor.asnumpy(), root_tensor.asnumpy()):\n                    print(""broadcast"", count, dtype, dim,\n                          mx.nd.max(tensor == root_tensor))\n                    print(""tensor"", bps.rank(), tensor)\n                    print(""root_tensor"", bps.rank(), root_tensor)\n                    print(""comparison"", bps.rank(), tensor == root_tensor)\n                assert not same(tensor.asnumpy(), root_tensor.asnumpy()), \\\n                    \'bps.broadcast modifies source tensor\'\n            if not same(broadcast_tensor.asnumpy(), root_tensor.asnumpy()):\n                print(""broadcast"", count, dtype, dim)\n                print(""broadcast_tensor"", bps.rank(), broadcast_tensor)\n                print(""root_tensor"", bps.rank(), root_tensor)\n                print(""comparison"", bps.rank(),\n                      broadcast_tensor == root_tensor)\n            assert same(broadcast_tensor.asnumpy(), root_tensor.asnumpy()), \\\n                \'bps.broadcast produces incorrect broadcasted tensor\'\n\n\nif __name__ == \'__main__\':\n    mxtest = MXTest()\n    bps.init()\n    mxtest.test_byteps_push_pull()\n    mxtest.test_byteps_trainer_param_order()\n    #mxtest.test_byteps_broadcast()\n    mxtest.test_byteps_push_pull_inplace()\n'"
tests/test_tensorflow_keras.py,1,"b'# Copyright 2018 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\n""""""Tests for byteps.keras.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\nimport numpy as np\nimport warnings\n\nfrom distutils.version import LooseVersion\nfrom tensorflow import keras\nfrom tensorflow.python.keras import backend as K\n\nimport byteps.tensorflow.keras as bps\n\nclass TfKerasTests:\n    """"""\n    Tests for ops in byteps.keras.\n    """"""\n\n    def __init__(self, *args, **kwargs):\n        super(TfKerasTests, self).__init__(*args, **kwargs)\n        warnings.simplefilter(\'module\')\n        bps.init()\n\n        self.config = tf.ConfigProto()\n        self.config.gpu_options.allow_growth = True\n        self.config.gpu_options.visible_device_list = str(bps.local_rank())\n\n    def test_train_model(self):\n        with self.test_session(config=self.config) as sess:\n            K.set_session(sess)\n\n            opt = keras.optimizers.RMSprop(lr=0.0001)\n            opt = bps.DistributedOptimizer(opt)\n\n            model = keras.models.Sequential()\n            model.add(keras.layers.Dense(2, input_shape=(3,)))\n            model.add(keras.layers.RepeatVector(3))\n            model.add(keras.layers.ThresholdedReLU(0.5))\n            model.compile(loss=keras.losses.mean_squared_error,\n                          optimizer=opt,\n                          metrics=[keras.metrics.categorical_accuracy],\n                          sample_weight_mode=\'temporal\')\n\n            x = np.random.random((1, 3))\n            y = np.random.random((1, 3, 3))\n\n            def generator():\n                while 1:\n                    yield (x, y)\n\n            print (\'x is: \', x)\n            print (\'y is: \', y)\n            # No assertions, we just need to verify that it doesn\'t hang\n            callbacks = [bps.callbacks.BroadcastGlobalVariablesCallback(0)]\n            model.fit_generator(generator(),\n                                steps_per_epoch=10,\n                                callbacks=callbacks,\n                                epochs=0,\n                                verbose=0,\n                                workers=4,\n                                initial_epoch=1)\n            print (\'x-trained is: \', x)\n            print (\'y-trained is: \', y)\n\n    def test_sparse_as_dense(self):\n        with self.test_session(config=self.config) as sess:\n            K.set_session(sess)\n\n            opt = keras.optimizers.RMSprop(lr=0.0001)\n            opt = bps.DistributedOptimizer(opt, sparse_as_dense=True)\n\n            model = keras.models.Sequential()\n            model.add(keras.layers.Embedding(1000, 64, input_length=10))\n            model.compile(loss=keras.losses.mean_squared_error,\n                          optimizer=opt)\n\n            x = np.random.randint(1000, size=(32, 10))\n            y = np.random.random((32, 10, 64))\n            # No assertions, we just need to verify that it doesn\'t hang\n            model.train_on_batch(x, y)\n\n\nif __name__ == \'__main__\':\n    keras_test = TfKerasTests()\n    keras_test.test_train_model()\n'"
byteps/_keras/__init__.py,5,"b'# Copyright 2019 Bytedance Inc. or its affiliates. All Rights Reserved.\n# Copyright 2017 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport byteps.tensorflow as bps\nimport tensorflow as tf\n\ndef create_distributed_optimizer(keras, optimizer, name, device_dense, device_sparse,\n                                 compression, sparse_as_dense):\n    class _DistributedOptimizer(keras.optimizers.Optimizer):\n        _HAS_AGGREGATE_GRAD = True\n        def __init__(self, **kwargs):\n            self._name = name or ""Distributed%s"" % self.__class__.__base__.__name__\n            self._device_dense = device_dense\n            self._device_sparse = device_sparse\n            self._compression = compression\n            self._sparse_as_dense = sparse_as_dense\n            self._aggregated_gradients = False\n            super(self.__class__, self).__init__(**kwargs)\n\n        def get_gradients(self, loss, params):\n            """"""\n            Compute gradients of all trainable variables.\n            See Optimizer.get_gradients() for more info.\n            In DistributedOptimizer, get_gradients() is overriden to also\n            push_pull the gradients before returning them.\n            """"""\n            gradients = super(self.__class__, self).get_gradients(loss, params)\n            return self._push_pull(gradients)\n\n        def _aggregate_gradients(self, grads_and_vars):\n            gradients = [grad for grad, var in grads_and_vars]\n            return self._push_pull(gradients)\n\n        def _push_pull(self, gradients):\n            self._aggregated_gradients = True\n            if bps.size() > 1:\n                averaged_gradients = []\n                with tf.name_scope(self._name + ""_Push_Pull"") as scope:\n                    for grad in gradients:\n                        if grad is not None:\n                            if self._sparse_as_dense and \\\n                                    isinstance(grad, tf.IndexedSlices):\n                                grad = tf.convert_to_tensor(grad)\n                            avg_grad = bps.push_pull(grad, scope,\n                                                     device_dense=self._device_dense,\n                                                     device_sparse=self._device_sparse,\n                                                     compression=self._compression)\n                            averaged_gradients.append(avg_grad)\n                        else:\n                            averaged_gradients.append(None)\n                    return averaged_gradients\n            else:\n                return gradients\n\n        def apply_gradients(self, *args, **kwargs):\n            if not self._aggregated_gradients:\n                raise Exception(\'`apply_gradients()` was called without a call to \'\n                                \'`get_gradients()` or `_aggregate_gradients`. If you\\\'re \'\n                                \'using TensorFlow 2.0, please specify \'\n                                \'`experimental_run_tf_function=False` in `compile()`.\')\n            return super(self.__class__, self).apply_gradients(*args, **kwargs)\n\n    # We dynamically create a new class that inherits from the optimizer that was passed in.\n    # The goal is to override get_gradients() method with an push_pull implementation.\n    # This class will have the same name as the optimizer it\'s wrapping, so that the saved\n    # model could be easily restored without BytePS.\n    cls = type(optimizer.__class__.__name__, (optimizer.__class__,),\n               dict(_DistributedOptimizer.__dict__))\n    return cls.from_config(optimizer.get_config())\n\n\ndef _eval(backend, op_or_result):\n    if bps._executing_eagerly():\n        return op_or_result\n    else:\n        return backend.get_session().run(op_or_result)\n\n\nif hasattr(bps, \'broadcast_global_variables\'):\n    def broadcast_global_variables(backend, root_rank):\n        return _eval(backend, bps.broadcast_global_variables(root_rank))\n\n\ndef push_pull(backend, value, name, average):\n    return _eval(backend,  bps.push_pull(tf.constant(value, name=name), average=average))\n\n\ndef broadcast(backend, value, root_rank, name):\n    return _eval(backend, bps.broadcast(tf.constant(value, name=name), root_rank, is_variable=False))\n\n\ndef load_model(keras, wrap_optimizer, optimizer_modules, filepath, custom_optimizers, custom_objects):\n    byteps_objects = {\n        subclass.__name__.lower(): wrap_optimizer(subclass)\n        for subclass in keras.optimizers.Optimizer.__subclasses__()\n        if subclass.__module__ in optimizer_modules\n    }\n\n    if custom_optimizers is not None:\n        byteps_objects.update({\n            cls.__name__: wrap_optimizer(cls)\n            for cls in custom_optimizers\n        })\n\n    if custom_objects is not None:\n        byteps_objects.update(custom_objects)\n\n    return keras.models.load_model(filepath, custom_objects=byteps_objects)\n'"
byteps/_keras/callbacks.py,4,"b'# Copyright 2019 Bytedance Inc. or its affiliates. All Rights Reserved.\n# Copyright 2018 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport warnings\n\nimport byteps.tensorflow as bps\nimport tensorflow as tf\n\n\nclass BroadcastGlobalVariablesCallbackImpl(object):\n    def __init__(self, backend, root_rank, device=\'\', *args):\n        super(BroadcastGlobalVariablesCallbackImpl, self).__init__(*args)\n        self.backend = backend\n        self.root_rank = root_rank\n        self.device = device\n        self.broadcast_done = False\n\n    def on_batch_end(self, batch, logs=None):\n        if self.broadcast_done:\n            return\n\n        if bps.size() <= 1:\n            return\n\n        with tf.device(self.device):\n            if bps._executing_eagerly() and hasattr(self.model, \'variables\'):\n                # TensorFlow 2.0 or TensorFlow eager\n                bps.broadcast_variables(self.model.variables,\n                                        root_rank=self.root_rank)\n                bps.broadcast_variables(self.model.optimizer.variables(),\n                                        root_rank=self.root_rank)\n            else:\n                bcast_op = bps.broadcast_global_variables(self.root_rank)\n                self.backend.get_session().run(bcast_op)\n\n        self.broadcast_done = True\n\nclass MetricAverageCallbackImpl(object):\n    def __init__(self, backend, device=\'\', *args):\n        super(MetricAverageCallbackImpl, self).__init__(*args)\n        self.backend = backend\n        self.variables = {}\n        self.push_pull_ops = {}\n        self.device = device\n\n    def _make_variable(self, metric, value):\n        with tf.name_scope(\'MetricAverageCallback\') as scope:\n            var = tf.Variable(value, name=metric)\n            self.backend.get_session().run(var.initializer)\n            push_pull_op = bps.push_pull(var, scope, device_dense=self.device)\n            return var, push_pull_op\n\n    def _average_metrics_in_place(self, logs):\n        logs = logs or {}\n        reduced_logs = {}\n        # Reduce every metric among workers. Sort metrics by name\n        # to ensure consistent order.\n        for metric, value in sorted(logs.items()):\n            if bps._executing_eagerly():\n                with tf.device(self.device):\n                    reduced_logs[metric] = \\\n                        bps.push_pull(self.backend.constant(value, name=metric)).numpy()\n            else:\n                if metric not in self.variables:\n                    self.variables[metric], self.push_pull_ops[metric] = \\\n                        self._make_variable(metric, value)\n                else:\n                    self.backend.set_value(self.variables[metric], value)\n                reduced_logs[metric] = \\\n                    self.backend.get_session().run(self.push_pull_ops[metric])\n        # Override the reduced values back into logs dictionary\n        # for other callbacks to use.\n        for metric, value in reduced_logs.items():\n            logs[metric] = value\n\n    def on_epoch_end(self, epoch, logs=None):\n        self._average_metrics_in_place(logs)\n\n\nclass LearningRateScheduleCallbackImpl(object):\n    def __init__(self, backend, multiplier, start_epoch=0, end_epoch=None, staircase=True,\n                 momentum_correction=True, steps_per_epoch=None, initial_lr=None, *args):\n        super(LearningRateScheduleCallbackImpl, self).__init__(*args)\n        self.backend = backend\n        self.start_epoch = start_epoch\n        self.end_epoch = end_epoch\n        self.staircase = staircase\n        self.momentum_correction = momentum_correction\n        self.initial_lr = initial_lr\n        self.restore_momentum = None\n        self.steps_per_epoch = steps_per_epoch\n        self.current_epoch = None\n\n        if not callable(multiplier):\n            self.staircase = True\n            self.multiplier = lambda epoch: multiplier\n        else:\n            self.multiplier = multiplier\n\n        if self.initial_lr is None:\n            warnings.warn(\'Parameter `initial_lr` will be required in the future\', DeprecationWarning)\n\n    def _autodetect_steps_per_epoch(self):\n        if self.params.get(\'steps\'):\n            # The number of steps is provided in the parameters.\n            return self.params[\'steps\']\n        elif self.params.get(\'samples\') and self.params.get(\'batch_size\'):\n            # Compute the number of steps per epoch using # of samples and a batch size.\n            return self.params[\'samples\'] // self.params[\'batch_size\']\n        else:\n            raise ValueError(\'Could not autodetect the number of steps per epoch. \'\n                             \'Please specify the steps_per_epoch parameter to the \'\n                             \'%s() or upgrade to the latest version of Keras.\'\n                             % self.__class__.__name__)\n\n    def _adjust_learning_rate(self, epoch):\n        old_lr = self.backend.get_value(self.model.optimizer.lr)\n        new_lr = self.initial_lr * self.multiplier(epoch)\n        self.backend.set_value(self.model.optimizer.lr, new_lr)\n\n        if hasattr(self.model.optimizer, \'momentum\') and self.momentum_correction:\n            # See the paper cited above for more information about momentum correction.\n            self.restore_momentum = self.backend.get_value(self.model.optimizer.momentum)\n            self.backend.set_value(self.model.optimizer.momentum,\n                                   self.restore_momentum * new_lr / old_lr)\n\n    def _restore_momentum_if_needed(self):\n        if self.restore_momentum:\n            self.backend.set_value(self.model.optimizer.momentum, self.restore_momentum)\n            self.restore_momentum = None\n\n    def on_train_begin(self, logs=None):\n        if self.initial_lr is None:\n            self.initial_lr = self.backend.get_value(self.model.optimizer.lr)\n        if not self.staircase and not self.steps_per_epoch:\n            self.steps_per_epoch = self._autodetect_steps_per_epoch()\n\n    def on_epoch_begin(self, epoch, logs=None):\n        self.current_epoch = epoch\n\n    def on_batch_begin(self, batch, logs=None):\n        if (self.current_epoch < self.start_epoch or\n                (self.end_epoch is not None and self.current_epoch >= self.end_epoch)):\n            # Outside of the adjustment scope.\n            return\n\n        if self.staircase and batch == 0:\n            # Do on first batch of every epoch.\n            self._adjust_learning_rate(self.current_epoch)\n        elif not self.staircase:\n            epoch = self.current_epoch + float(batch) / self.steps_per_epoch\n            self._adjust_learning_rate(epoch)\n\n    def on_batch_end(self, batch, logs=None):\n        self._restore_momentum_if_needed()\n\n    def on_epoch_end(self, epoch, logs=None):\n        if logs is not None:\n            # Log current learning rate.\n            logs[\'lr\'] = self.backend.get_value(self.model.optimizer.lr)\n\n\nclass LearningRateWarmupCallbackImpl(LearningRateScheduleCallbackImpl):\n    def __init__(self, backend, warmup_epochs=5, momentum_correction=True, steps_per_epoch=None,\n                 verbose=0, initial_lr=None, *args):\n        def multiplier(epoch):\n            # Adjust epoch to produce round numbers at the end of each epoch, so that TensorBoard\n            # learning rate graphs look better.\n            epoch += 1. / self.steps_per_epoch\n            return 1. / bps.size() * (epoch * (bps.size() - 1) / warmup_epochs + 1)\n        super(LearningRateWarmupCallbackImpl, self).__init__(\n            backend, multiplier, start_epoch=0, end_epoch=warmup_epochs, staircase=False,\n            momentum_correction=momentum_correction, steps_per_epoch=steps_per_epoch, initial_lr=initial_lr,\n            *args)\n        self.verbose = verbose\n\n    def on_epoch_end(self, epoch, logs=None):\n        super(LearningRateWarmupCallbackImpl, self).on_epoch_end(epoch, logs)\n\n        if epoch == self.end_epoch - 1 and self.verbose > 0:\n            new_lr = self.backend.get_value(self.model.optimizer.lr)\n            print(\'\\nEpoch %d: finished gradual learning rate warmup to %g.\' %\n                  (epoch + 1, new_lr))\n'"
byteps/common/__init__.py,0,"b'# Copyright 2019 Bytedance Inc. or its affiliates. All Rights Reserved.\n# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n# Modifications copyright (C) 2018 Uber Technologies, Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# =============================================================================\n\nimport ctypes\nimport os\nimport sysconfig\nimport atexit\n\n\ndef get_ext_suffix():\n    """"""Determine library extension for various versions of Python.""""""\n    ext_suffix = sysconfig.get_config_var(\'EXT_SUFFIX\')\n    if ext_suffix:\n        return ext_suffix\n\n    ext_suffix = sysconfig.get_config_var(\'SO\')\n    if ext_suffix:\n        return ext_suffix\n\n    return \'.so\'\n\n\ndef get_extension_full_path(pkg_path, *args):\n    assert len(args) >= 1\n    dir_path = os.path.join(os.path.dirname(pkg_path), *args[:-1])\n    full_path = os.path.join(dir_path, args[-1] + get_ext_suffix())\n    return full_path\n\n\ndef check_extension(ext_name, ext_env_var, pkg_path, *args):\n    full_path = get_extension_full_path(pkg_path, *args)\n    if not os.path.exists(full_path):\n        raise ImportError(\n            \'Extension %s has not been built.  If this is not expected, reinstall \'\n            \'BytePS with %s=1 to debug the build error.\' % (ext_name, ext_env_var))\n\n\nclass BytePSBasics(object):\n    """"""Wrapper class for the basic BytePS API.""""""\n\n    def __init__(self, pkg_path, *args):\n        full_path = get_extension_full_path(pkg_path, *args)\n        self.C_LIB_CTYPES = ctypes.CDLL(full_path, mode=ctypes.RTLD_GLOBAL)\n\n    def init(self, lazy=True):\n        """"""A function that inits BytePS.""""""\n        atexit.register(self.shutdown)\n        if lazy:\n            return self.C_LIB_CTYPES.byteps_lazy_init()\n        else:\n            return self.C_LIB_CTYPES.byteps_init()\n\n    def shutdown(self):\n        """"""A function that shuts BytePS down.""""""\n        return self.C_LIB_CTYPES.byteps_shutdown()\n\n    def suspend(self):\n        """"""A function that suspends BytePS for elastic training.""""""\n        return self.C_LIB_CTYPES.byteps_suspend()\n\n    def resume(self, num_workers, num_servers, global_rank, context=None):\n        """"""A function that restarts BytePS after being suspended, for elastic training.""""""\n        # set DMLC environment variables here\n        os.environ[\'DMLC_NUM_WORKER\'] = str(num_workers)\n        os.environ[\'DMLC_NUM_SERVER\'] = str(num_servers)\n        os.environ[\'BYTEPS_GLOBAL_RANK\'] = str(global_rank)\n        return self.C_LIB_CTYPES.byteps_resume(num_workers, num_servers)\n\n    def size(self):\n        """"""A function that returns the number of BytePS processes.\n        Returns:\n          An integer scalar containing the number of BytePS processes.\n        """"""\n        size = self.C_LIB_CTYPES.byteps_size()\n        if size == -1:\n            raise ValueError(\n                \'BytePS has not been initialized; use bps.init().\')\n        return size\n\n    def local_size(self):\n        """"""A function that returns the number of BytePS processes within the\n        node the current process is running on.\n        Returns:\n          An integer scalar containing the number of local BytePS processes.\n        """"""\n        local_size = self.C_LIB_CTYPES.byteps_local_size()\n        if local_size == -1:\n            raise ValueError(\n                \'BytePS has not been initialized; use bps.init().\')\n        return local_size\n\n    def rank(self):\n        """"""A function that returns the BytePS rank of the calling process.\n        Returns:\n          An integer scalar with the BytePS rank of the calling process.\n        """"""\n        rank = self.C_LIB_CTYPES.byteps_rank()\n        if rank == -1:\n            raise ValueError(\n                \'BytePS has not been initialized; use bps.init().\')\n        return rank\n\n    def local_rank(self):\n        """"""A function that returns the local BytePS rank of the calling process, within the\n        node that it is running on. For example, if there are seven processes running\n        on a node, their local ranks will be zero through six, inclusive.\n        Returns:\n          An integer scalar with the local BytePS rank of the calling process.\n        """"""\n        local_rank = self.C_LIB_CTYPES.byteps_local_rank()\n        if local_rank == -1:\n            raise ValueError(\n                \'BytePS has not been initialized; use bps.init().\')\n        return local_rank\n'"
byteps/keras/__init__.py,0,"b'# Copyright 2019 Bytedance Inc. or its affiliates. All Rights Reserved.\n# Copyright 2017 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport keras\nimport keras.backend as K\n\nfrom byteps.tensorflow import init\nfrom byteps.tensorflow import shutdown\nfrom byteps.tensorflow import size\nfrom byteps.tensorflow import local_size\nfrom byteps.tensorflow import rank\nfrom byteps.tensorflow import local_rank\nfrom byteps.tensorflow import Compression\n\nfrom byteps.keras import callbacks\nimport byteps._keras as _impl\n\n\ndef DistributedOptimizer(optimizer, name=None,\n                         device_dense=\'\', device_sparse=\'\',\n                         compression=Compression.none,\n                         sparse_as_dense=False):\n    """"""\n    An optimizer that wraps another keras.optimizers.Optimizer, using an push_pull to\n    average gradient values before applying gradients to model weights.\n    Args:\n        optimizer: Optimizer to use for computing gradients and applying updates.\n        name: Optional name prefix for the operations created when applying\n              gradients. Defaults to ""Distributed"" followed by the provided\n              optimizer type.\n        device_dense: Device to be used for dense tensors. Uses GPU by default\n        device_sparse: Device to be used for sparse tensors. Uses GPU by default\n        compression: Compression algorithm used to reduce the amount of data\n                     sent and received by each worker node.  Defaults to not\n                     using compression.\n        sparse_as_dense: Treat all sparse gradients as dense tensors.  This can\n                         help improve performance and memory utilization if\n                         the original sparse gradient has high density.\n                         Defaults to false.\n    """"""\n    return _impl.create_distributed_optimizer(keras, optimizer, name,\n                                              device_dense, device_sparse, compression,\n                                              sparse_as_dense)\n\n\ndef broadcast_global_variables(root_rank):\n    """"""Broadcasts all global variables from root rank to all other processes.\n    Arguments:\n        root_rank: Rank of the process from which global variables will be broadcasted\n                   to all other processes.\n    """"""\n    return _impl.broadcast_global_variables(K, root_rank)\n\n\ndef push_pull(value, name=None, average=True):\n    """"""\n    Perform an push_pull on a tensor-compatible value.\n    Arguments:\n        value: A tensor-compatible value to reduce.\n               The shape of the input must be identical across all ranks.\n        name: Optional name for the constants created by this operation.\n        average: If True, computes the average over all ranks.\n                 Otherwise, computes the sum over all ranks.\n    """"""\n    return _impl.push_pull(K, value, name, average)\n\n\ndef broadcast(value, root_rank, name=None):\n    """"""\n    Perform a broadcast on a tensor-compatible value.\n    Arguments:\n        value: A tensor-compatible value to reduce.\n               The shape of the input must be identical across all ranks.\n        root_rank: Rank of the process from which global variables will be\n                   broadcasted to all other processes.\n        name: Optional name for the constants created by this operation.\n    """"""\n    return _impl.broadcast(K, value, root_rank, name)\n\n\ndef load_model(filepath, custom_optimizers=None, custom_objects=None, compression=Compression.none):\n    """"""\n    Loads a saved Keras model with a BytePS DistributedOptimizer.\n    The DistributedOptimizer will wrap the underlying optimizer used to train\n    the saved model, so that the optimizer state (params and weights) will\n    be picked up for retraining.\n    By default, all optimizers in the module `keras.optimizers` will be loaded\n    and wrapped without needing to specify any `custom_optimizers` or\n    `custom_objects`.\n    # Arguments\n        filepath: One of the following:\n            - string, path to the saved model, or\n            - h5py.File object from which to load the model\n        custom_optimizers: Optional list of Optimizer subclasses to support\n            during loading.\n        custom_objects: Optional dictionary mapping names (strings) to custom\n            classes or functions to be considered during deserialization.\n        compression: Compression algorithm used to reduce the amount of data\n                     sent and received by each worker node.  Defaults to not\n                     using compression.\n    # Returns\n        A Keras model instance.\n    # Raises\n        ImportError: If h5py is not available.\n        ValueError: In case of an invalid savefile.\n    """"""\n    def wrap_optimizer(cls):\n        return lambda **kwargs: DistributedOptimizer(cls(**kwargs), compression=compression)\n    optimizer_modules = {keras.optimizers.Optimizer.__module__}\n    return _impl.load_model(keras, wrap_optimizer, optimizer_modules, filepath, custom_optimizers, custom_objects)\n'"
byteps/keras/callbacks.py,0,"b'# Copyright 2019 Bytedance Inc. or its affiliates. All Rights Reserved.\n# Copyright 2018 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport keras\nimport keras.backend as K\n\nfrom byteps._keras import callbacks as _impl\n\n\nclass BroadcastGlobalVariablesCallback(_impl.BroadcastGlobalVariablesCallbackImpl, keras.callbacks.Callback):\n    """"""\n    Keras Callback that will broadcast all global variables from root rank\n    to all other processes during initialization.\n    This is necessary to ensure consistent initialization of all workers when\n    training is started with random weights or restored from a checkpoint.\n    """"""\n\n    def __init__(self, root_rank, device=\'\'):\n        """"""\n        Construct a new BroadcastGlobalVariablesCallback that will broadcast all\n        global variables from root rank to all other processes during initialization.\n        Args:\n            root_rank: Rank that will send data, other ranks will receive data.\n            device: Device to be used for broadcasting. Uses GPU by default.\n        """"""\n        super(BroadcastGlobalVariablesCallback, self).__init__(K, root_rank, device)\n\n\nclass MetricAverageCallback(_impl.MetricAverageCallbackImpl, keras.callbacks.Callback):\n    """"""\n    Keras Callback that will average metrics across all processes at the\n    end of the epoch. Useful in conjuction with ReduceLROnPlateau,\n    TensorBoard and other metrics-based callbacks.\n    Note: This callback must be added to the callback list before the\n    ReduceLROnPlateau, TensorBoard or other metrics-based callbacks.\n    """"""\n\n    def __init__(self, device=\'\'):\n        """"""\n        Construct a new MetricAverageCallback that will average metrics\n        across all processes at the end of the epoch.\n        Args:\n            device: Device to be used for push_pull. Uses GPU by default.\n        """"""\n        super(MetricAverageCallback, self).__init__(K, device)\n\n\nclass LearningRateScheduleCallback(_impl.LearningRateScheduleCallbackImpl, keras.callbacks.Callback):\n    """"""\n    LearningRateScheduleCallback sets learning rate between epochs `start_epoch` and\n    `end_epoch` to be `initial_lr * multiplier`.  `multiplier` can be a constant or\n    a function `f(epoch) = lr\'`.\n    If `multiplier` is a function and `staircase=True`, learning rate adjustment will\n    happen at the beginning of each epoch and the epoch passed to the `multiplier`\n    function will be an integer.\n    If `multiplier` is a function and `staircase=False`, learning rate adjustment will\n    happen at the beginning of each batch and the epoch passed to the `multiplier`\n    function will be a floating number: `epoch\' = epoch + batch / steps_per_epoch`.\n    This functionality is useful for smooth learning rate adjustment schedulers, such\n    as `LearningRateWarmupCallback`.\n    `initial_lr` is the learning rate of the model optimizer at the start of the training.\n    """"""\n\n    def __init__(self, multiplier, start_epoch=0, end_epoch=None, staircase=True,\n                 momentum_correction=True, steps_per_epoch=None, initial_lr=None):\n        """"""\n        Construct a new LearningRateScheduleCallback.\n        Args:\n            multiplier: A constant multiplier or a function `f(epoch) = lr\'`\n            start_epoch: The first epoch this adjustment will be applied to. Defaults to 0.\n            end_epoch: The epoch this adjustment will stop applying (exclusive end).\n                       Defaults to None.\n            staircase: Whether to adjust learning rate at the start of epoch (`staircase=True`)\n                       or at the start of every batch (`staircase=False`).\n            momentum_correction: Apply momentum correction to optimizers that have momentum.\n                                 Defaults to True.\n            steps_per_epoch: The callback will attempt to autodetect number of batches per\n                             epoch with Keras >= 2.0.0. Provide this value if you have an older\n                             version of Keras.\n            initial_lr: Initial learning rate at the start of training.\n\n                .. warning:: Will be required in the future.\n\n        """"""\n        super(LearningRateScheduleCallback, self).__init__(K, multiplier, start_epoch, end_epoch,\n                                                           staircase, momentum_correction, steps_per_epoch,\n                                                           initial_lr)\n\n\nclass LearningRateWarmupCallback(_impl.LearningRateWarmupCallbackImpl, keras.callbacks.Callback):\n    """"""\n    Implements gradual learning rate warmup:\n        `lr = initial_lr / bps.size()` ---> `lr = initial_lr`\n    `initial_lr` is the learning rate of the model optimizer at the start of the training.\n    This technique was described in the paper ""Accurate, Large Minibatch SGD: Training\n    ImageNet in 1 Hour"". See https://arxiv.org/pdf/1706.02677.pdf for details.\n    Math recap:\n                                                 batch\n        epoch               = full_epochs + ---------------\n                                            steps_per_epoch\n                               lr     size - 1\n        lr\'(epoch)          = ---- * (-------- * epoch + 1)\n                              size     warmup\n                               lr\n        lr\'(epoch = 0)      = ----\n                              size\n        lr\'(epoch = warmup) = lr\n    """"""\n\n    def __init__(self, warmup_epochs=5, momentum_correction=True, steps_per_epoch=None,\n                 verbose=0, initial_lr=None):\n        """"""\n        Construct a new LearningRateWarmupCallback that will gradually warm up the learning rate.\n        Args:\n            warmup_epochs: The number of epochs of the warmup phase. Defaults to 5.\n            momentum_correction: Apply momentum correction to optimizers that have momentum.\n                                 Defaults to True.\n            steps_per_epoch: The callback will attempt to autodetect number of batches per\n                             epoch with Keras >= 2.0.0. Provide this value if you have an older\n                             version of Keras.\n            verbose: verbosity mode, 0 or 1.\n            initial_lr: Initial learning rate at the start of training.\n\n                .. warning:: Will be required in the future.\n        """"""\n        super(LearningRateWarmupCallback, self).__init__(K, warmup_epochs, momentum_correction,\n                                                         steps_per_epoch, verbose, initial_lr)\n'"
byteps/misc/__init__.py,0,b''
byteps/mxnet/__init__.py,0,"b'# Copyright 2019 Bytedance Inc. or its affiliates. All Rights Reserved.\n# Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport warnings\nimport mxnet as mx\nimport os\n\nfrom byteps.mxnet.ops import byteps_push_pull, byteps_declare_tensor\nfrom byteps.mxnet.ops import init, shutdown, suspend, resume\nfrom byteps.mxnet.ops import size, local_size, rank, local_rank\n\nparameter_index = 0\n\n\nclass DistributedOptimizer(mx.optimizer.Optimizer):\n    """"""This is where BytePS\'s DistributedOptimizer wrapper for MXNet goes""""""\n    def __init__(self, optimizer):\n        self._optimizer = optimizer\n        self._enable_async = (int(os.getenv(\'BYTEPS_ENABLE_ASYNC\', 0)) != 0)\n        if self._enable_async:\n            assert int(os.getenv(\'DMLC_NUM_WORKER\'))>1, \\\n                ""Async is only valid for distributed training""\n            print(\'BytePS: enable asynchronous training\')\n\n    def __getattr__(self, item):\n        return getattr(self._optimizer, item)\n\n    def create_state_multi_precision(self, index, weight):\n        return self._optimizer.create_state_multi_precision(index, weight)\n\n    def _do_push_pull(self, index, grad):\n        if isinstance(index, (tuple, list)):\n            for i in range(len(index)):\n                byteps_declare_tensor(""gradient_"" + str(index[i]))\n                byteps_push_pull(grad[i], version=0, priority=-index[i],\n                                 name=""gradient_"" + str(index[i]), is_average=True)\n        else:\n            byteps_declare_tensor(""gradient_"" + str(index))\n            byteps_push_pull(grad, version=0, priority=-index,\n                             name=""gradient_"" + str(index), is_average=True)\n\n    def _do_push_pull_param(self, index, delta_weight):\n        if isinstance(index, (tuple, list)):\n            for i in range(len(index)):\n                byteps_declare_tensor(""weight_"" + str(index[i]))\n                byteps_push_pull(delta_weight[i], version=0, priority=-index[i],\n                                 name=""weight_"" + str(index[i]), is_average=False)\n        else:\n            byteps_declare_tensor(""weight_"" + str(index))\n            byteps_push_pull(delta_weight, version=0, priority=-index,\n                             name=""weight_"" + str(index), is_average=False)\n\n    def update(self, index, weight, grad, state):\n        if self._enable_async:\n            # create a tmp list for storing the original weight\n            temp_weight_list = [w.copy() for w in weight]\n            assert len(temp_weight_list) == len(weight)\n\n            # update parameter locally\n            self._optimizer.update(index, weight, grad, state)\n\n            # get delta weight\n            for i, temp_weight in enumerate(temp_weight_list):\n                weight[i].__isub__(temp_weight)\n\n            # push delta weight, and pull weight back to the same tensor\n            self._do_push_pull_param(index, weight)\n\n        else:\n            self._do_push_pull(index, grad)\n            self._optimizer.update(index, weight, grad, state)\n\n    def update_multi_precision(self, index, weight, grad, state):\n        if self._enable_async:\n            # create a tmp list for storing the original weight\n            temp_weight_list = [w.copy() for w in weight]\n            assert len(temp_weight_list) == len(weight)\n\n            # update parameter locally\n            self._optimizer.update_multi_precision(index, weight, grad, state)\n\n            # get delta weight\n            for i, temp_weight in enumerate(temp_weight_list):\n                weight[i].__isub__(temp_weight)\n\n            # push delta weight, and pull weight back to the same tensor\n            self._do_push_pull_param(index, weight)\n\n        else:\n            self._do_push_pull(index, grad)\n            self._optimizer.update_multi_precision(index, weight, grad, state)\n\n    def set_learning_rate(self, lr):\n        self._optimizer.set_learning_rate(lr)\n\n    def set_lr_mult(self, args_lr_mult):\n        self._optimizer.set_lr_mult(args_lr_mult)\n\n    def set_wd_mult(self, args_wd_mult):\n        self._optimizer.set_wd_mult(args_wd_mult)\n\n\ndef broadcast_parameters(params, root_rank=0):\n    """"""\n    Broadcasts the parameters from root rank to all other processes.\n    Typical usage is to broadcast the `Module.get_params()`.\n\n    Arguments:\n        params: dict of parameters to broadcast\n        root_rank: The rank of the process from which parameters will be\n                   broadcasted to all other processes.\n    """"""\n    global parameter_index\n\n    if isinstance(params, dict):\n        tensors = [p for _, p in sorted(params.items())]\n\n        # Run tensor initilization\n        for i in range(len(tensors)):\n            byteps_declare_tensor(""parameter_"" + str(parameter_index))\n            # Broadcast is implemented as push + pull in BytePS\n            # To broadcast: we should zero-out all non-root tensors, and disable push_pull average\n            if rank() != root_rank:\n                tensors[i].__imul__(0)\n            byteps_push_pull(tensors[i], version=0, priority=0,\n                             name=""parameter_"" + str(parameter_index), is_average=False)\n            parameter_index += 1\n\n        # Make sure tensors pushed to MXNet engine get processed such that all\n        # workers are synced before starting training.\n        for tensor in tensors:\n            tensor.wait_to_read()\n\n    elif isinstance(params, mx.gluon.parameter.ParameterDict):\n        raise TypeError(""For gluon users, you should not call this function. ""\n                        ""DistributedTrainer will broadcast all parameters at ""\n                        ""the first training step."")\n\n    else:\n        raise ValueError(\'Invalid params of type: %s\' % type(params))\n\n\nclass DistributedTrainer(mx.gluon.Trainer):\n    """"""A subclass of MXNet gluon.Trainer.\n\n    There are two differences between DistributedTrainer and Trainer:\n    1. DistributedTrainer calculates gradients using BytePS push pull\n       API while Trainer does it using kvstore push/pull APIs;\n    2. DistributedTrainer performs push_pull(summation) and average,\n       while Trainer only performs push_pull(summation).\n\n    Parameters\n    ----------\n    params : ParameterDict\n        The set of parameters to optimize.\n    optimizer : str or Optimizer\n        The optimizer to use. See\n        `help <http://mxnet.io/api/python/optimization/optimization.html#the-mxnet-optimizer-package>`_\n        on Optimizer for a list of available optimizers.\n    optimizer_params : dict\n        Key-word arguments to be passed to optimizer constructor. For example,\n        `{\'learning_rate\': 0.1}`. All optimizers accept learning_rate, wd (weight decay),\n        clip_gradient, and lr_scheduler. See each optimizer\'s\n        constructor for a list of additional supported arguments.\n    """"""\n\n    def __init__(self, params, optimizer, optimizer_params=None, root_rank=0):\n        if isinstance(optimizer, DistributedOptimizer):\n            optimizer = optimizer._optimizer\n            warnings.warn(""DistributedTrainer does not take DistributedOptimizer ""\n                          ""as its optimizer. We have unwrapped it for you."")\n\n        param_list = []\n        if isinstance(params, mx.gluon.ParameterDict):\n            for key in sorted(list(params.keys())):\n                param_list.append(params[key])\n\n        super(DistributedTrainer, self).__init__(\n            param_list, optimizer, optimizer_params=optimizer_params, kvstore=None)\n\n        # _scale is used to check and set rescale_grad for optimizer in Trainer.step()\n        # function. Normalizing it by BytePS size, which is equivalent to performing\n        # average in push_pull, has better performance.\n        self._scale /= size()\n        self.root_rank = root_rank\n        for i, param in enumerate(self._params):\n            byteps_declare_tensor(""parameter_"" + str(i))\n            if param.grad_req != \'null\':\n                byteps_declare_tensor(""gradient_"" + str(i))\n\n\n    def _allreduce_grads(self):\n        for i, param in enumerate(self._params):\n            if param.grad_req != \'null\':\n                byteps_push_pull(param.list_grad()[0], is_average=False,\n                                 name=""gradient_"" + str(i), priority=-i)\n\n    def _init_params(self):\n        tensors = []\n        for param in self._params_to_init:\n            if param._deferred_init:\n                tensors.append(param)\n            else:\n                param_arrays = param._check_and_get(param._data, list)\n                idx = self._param2idx[param.name]\n\n                if rank() != self.root_rank:\n                    param_arrays[0].__imul__(0)\n                byteps_push_pull(param_arrays[0], version=0, priority=0,\n                                 name=""parameter_"" + str(idx), is_average=False)\n\n        self._params_to_init = tensors\n'"
byteps/mxnet/ops.py,0,"b'# Copyright 2019 Bytedance Inc. or its affiliates. All Rights Reserved.\n# Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\n# Load all the necessary MXNet C types.\nimport ctypes\nimport os\n\nimport mxnet as mx\nfrom mxnet.base import c_str, check_call, string_types\n\nfrom byteps.common import get_ext_suffix\nfrom byteps.common import BytePSBasics as _BytePSBasics\n_basics = _BytePSBasics(__file__, \'c_lib\')\n\n# import basic methods\ninit = _basics.init\nshutdown = _basics.shutdown\nsuspend = _basics.suspend\nresume = _basics.resume\nsize = _basics.size\nlocal_size = _basics.local_size\nrank = _basics.rank\nlocal_rank = _basics.local_rank\n\ndll_path = os.path.join(os.path.dirname(__file__),\n                        \'c_lib\' + get_ext_suffix())\nMXNET_LIB_CTYPES = ctypes.CDLL(dll_path, ctypes.RTLD_GLOBAL)\n\n\ndef byteps_push_pull(tensor, version=0, priority=0, name=None, is_average=True):\n    """"""\n    A function that performs pushing and pulling tensors\n\n    The operation is keyed by the name. If name is not provided, an\n    incremented auto-generated name is used. The tensor type and shape must be\n    the same on all BytePS processes for a given name. The reduction will not\n    start until all processes are ready to send and receive the tensor.\n\n    This acts as a thin wrapper around an autograd function.  If your input\n    tensor requires tensors, then callings this function will allow tensors\n    to be computed and backpropagated.\n\n    Arguments:\n        tensor: A tensor to average and sum.\n        average: A flag indicating whether to compute average or summation,\n                 defaults to average.\n        name: A name of the reduction operation.\n\n    Returns:\n        None\n    """"""\n\n    c_in = tensor.handle\n    if isinstance(name, string_types):\n        check_call(MXNET_LIB_CTYPES.byteps_mxnet_push_pull_async(c_in,\n                                                                 c_str(name), ctypes.c_int(version), ctypes.c_int(priority), ctypes.c_bool(is_average)))\n    else:\n        check_call(MXNET_LIB_CTYPES.byteps_mxnet_push_pull_async(c_in,\n                                                                 name, ctypes.c_int(version), ctypes.c_int(priority), ctypes.c_bool(is_average)))\n\n    return\n\n\ndef byteps_declare_tensor(name):\n    check_call(MXNET_LIB_CTYPES.byteps_mxnet_declare_tensor(c_str(name)))\n'"
byteps/server/__init__.py,0,"b'# Copyright 2019 Bytedance Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport ctypes\nimport os\nfrom byteps.common import get_ext_suffix\n\n\ndef run():\n    dll_path = os.path.join(os.path.dirname(__file__),\n                            \'c_lib\' + get_ext_suffix())\n    SERVER_LIB_CTYPES = ctypes.CDLL(dll_path, ctypes.RTLD_GLOBAL)\n    SERVER_LIB_CTYPES.byteps_server()\n\nrun()\n'"
byteps/tensorflow/__init__.py,31,"b'# Copyright 2019 Bytedance Inc. All Rights Reserved.\n# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n# Modifications copyright (C) 2019 Uber Technologies, Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n# pylint: disable=g-short-docstring-punctuation\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport warnings\n\nfrom byteps.tensorflow.compression import Compression\nfrom byteps.tensorflow.ops import broadcast, _push_pull\nfrom byteps.tensorflow.ops import init, shutdown, suspend, resume\nfrom byteps.tensorflow.ops import size, local_size, rank, local_rank\nfrom byteps.tensorflow.ops import handle_average_backwards_compatibility\nfrom byteps.tensorflow.util import _executing_eagerly\n\nimport tensorflow as tf\nfrom tensorflow.python.ops import control_flow_ops\n\nAverage = ""Average""\nSum = ""Sum""\nAdasum = ""Adasum""\n\ndef push_pull(tensor, scope=\'\', average=None, device_dense=\'\', device_sparse=\'\',\n              compression=Compression.none, op=None, enable_async=False):\n    """"""Perform an push_pull on a tf.Tensor or tf.IndexedSlices.\n    Arguments:\n        tensor: tf.Tensor, tf.Variable, or tf.IndexedSlices to reduce.\n                The shape of the input must be identical across all ranks.\n        average:\n            .. warning:: .. deprecated\n\n                Use `op` instead. Will be removed.\n\n        scope: the graph name scope\n        average: If True, computes the average over all ranks.\n                 Otherwise, computes the sum over all ranks.\n        device_dense: Device to be used for dense tensors. Uses GPU by default.\n        device_sparse: Device to be used for sparse tensors. Uses GPU by default.\n        compression: Compression algorithm used to reduce the amount of data\n                     sent and received by each worker node.  Defaults to not\n                     using compression.\n        op: The reduction operation to combine tensors across different ranks.\n            Defaults to Average if None is given.\n\n    Returns:\n        A tensor of the same shape and type as `tensor`, summed across all\n        processes.\n    """"""\n    op = handle_average_backwards_compatibility(op, average)\n    # Averaging happens in framework code, so translate that to Sum for the actual call\n    true_op = Sum if op == Average else op\n\n    with tf.device(device_dense):\n        byteps_size = tf.cast(size(), dtype=tensor.dtype)\n        tensor_compressed, ctx = compression.compress(tensor)\n        summed_tensor_compressed = _push_pull(tensor_compressed, scope)\n        summed_tensor = compression.decompress(summed_tensor_compressed, ctx)\n        if not enable_async:\n            _div = tf.div if hasattr(tf, \'div\') else tf.math.divide\n            new_tensor = (_div(summed_tensor, byteps_size)\n                          if op == Average else summed_tensor)\n        else: # no need to average for async training\n            new_tensor = summed_tensor\n    return new_tensor\n\n\ntry:\n    _global_variables = tf.global_variables\nexcept AttributeError:\n    try:\n        _global_variables = tf.compat.v1.global_variables\n    except AttributeError:\n        _global_variables = None\n\nif _global_variables is not None:\n    def broadcast_global_variables(root_rank):\n        """"""Broadcasts all global variables from root rank to all other processes.\n\n        **NOTE:** deprecated in TensorFlow 2.0.\n\n        Arguments:\n            root_rank: rank of the process from which global variables will be broadcasted\n                       to all other processes.\n        """"""\n        if _executing_eagerly():\n            raise RuntimeError(\n                ""bps.broadcast_global_variables() does not support eager execution. ""\n                ""Please use `bps.broadcast_variables(<model/optimizer variables>)` instead.""\n            )\n\n        return broadcast_variables(_global_variables(), root_rank)\n\ndef broadcast_variables(variables, root_rank, scope=\'\'):\n    """"""Broadcasts variables from root rank to all other processes.\n    Arguments:\n        variables: variables for broadcast\n        root_rank: rank of the process from which global variables will be broadcasted\n                   to all other processes.\n        scope: the graph name scope\n    """"""\n    _assign = tf.assign if hasattr(tf, \'assign\') else tf.compat.v1.assign\n    return tf.group(*[_assign(var, broadcast(var, root_rank, scope))\n                      for var in variables])\n\ntry:\n    _get_default_graph = tf.get_default_graph\nexcept AttributeError:\n    try:\n        _get_default_graph = tf.compat.v1.get_default_graph\n    except AttributeError:\n        _get_default_graph = None\n\ntry:\n    _SessionRunHook = tf.estimator.SessionRunHook\nexcept AttributeError:\n    try:\n        _SessionRunHook = tf.train.SessionRunHook\n    except AttributeError:\n        _SessionRunHook = None\n\nif _SessionRunHook is not None and _get_default_graph is not None:\n    class BroadcastGlobalVariablesHook(_SessionRunHook):\n        """"""\n        SessionRunHook that will broadcast all global variables from root rank\n        to all other processes during initialization.\n\n        This is necessary to ensure consistent initialization of all workers when\n        training is started with random weights or restored from a checkpoint.\n\n        **NOTE:** deprecated in TensorFlow 2.0.\n        """"""\n\n        def __init__(self, root_rank, device=\'\'):\n            """"""Construct a new BroadcastGlobalVariablesHook that will broadcast all\n            global variables from root rank to all other processes during initialization.\n\n            Args:\n              root_rank:\n                Rank that will send data, other ranks will receive data.\n              device:\n                Device to be used for broadcasting. Uses GPU by default.\n            """"""\n            super(BroadcastGlobalVariablesHook, self).__init__()\n            self.root_rank = root_rank\n            self.bcast_op = None\n            self.device = device\n\n        def begin(self):\n            if not self.bcast_op or self.bcast_op.graph != _get_default_graph():\n                with tf.device(self.device):\n                    self.bcast_op = broadcast_global_variables(self.root_rank)\n\n        def after_create_session(self, session, coord):\n            session.run(self.bcast_op)\n\ntry:\n    # TensorFlow 2.x\n    _LegacyOptimizer = tf.compat.v1.train.Optimizer\nexcept AttributeError:\n    try:\n        # TensorFlow 1.x\n        _LegacyOptimizer = tf.train.Optimizer\n    except AttributeError:\n        # Future TensorFlow versions\n        _LegacyOptimizer = None\n\nif _LegacyOptimizer is not None:\n    class _DistributedOptimizer(_LegacyOptimizer):\n        """"""An optimizer that wraps another tf.Optimizer, using an push_pull to\n        average gradient values before applying gradients to model weights.""""""\n\n        def __init__(self, optimizer, name=None, use_locking=False, device_dense=\'\',\n                    device_sparse=\'\', compression=Compression.none,\n                    sparse_as_dense=False, op=Average):\n            if name is None:\n                name = ""Distributed{}"".format(type(optimizer).__name__)\n            super(_DistributedOptimizer, self).__init__(name=name, use_locking=use_locking)\n\n            self._optimizer = optimizer\n            self._device_dense = device_dense\n            self._device_sparse = device_sparse\n            self._compression = compression\n            self._sparse_as_dense = sparse_as_dense\n\n            self._enable_async = (int(os.getenv(\'BYTEPS_ENABLE_ASYNC\', 0)) != 0)\n            if self._enable_async:\n                assert int(os.getenv(\'DMLC_NUM_WORKER\')) > 1, \\\n                    ""Async is only valid for distributed training""\n                print(\'BytePS: enable asynchronous training\')\n\n            def push_pull_grads(grads):\n                with tf.name_scope(self._name + ""_Push_Pull"") as scope:\n                    if self._sparse_as_dense:\n                        grads = [tf.convert_to_tensor(grad)\n                                if grad is not None and isinstance(grad, tf.IndexedSlices)\n                                else grad for grad in grads]\n\n                    return [push_pull(grad, scope,\n                                    device_dense=self._device_dense,\n                                    device_sparse=self._device_sparse,\n                                    compression=self._compression,\n                                    enable_async=self._enable_async)\n                            if grad is not None else grad\n                            for grad in grads]\n\n            if _executing_eagerly():\n                self._push_pull_grads = tf.contrib.eager.defun(push_pull_grads)\n            else:\n                self._push_pull_grads = push_pull_grads\n\n        def compute_gradients(self, *args, **kwargs):\n            """"""Compute gradients of all trainable variables.\n            See Optimizer.compute_gradients() for more info.\n            In DistributedOptimizer, compute_gradients() is overriden to also\n            push_pull the gradients before returning them.\n            """"""\n            gradients = self._optimizer.compute_gradients(*args, **kwargs)\n            if size() > 1 and not self._enable_async:\n                grads, vars = zip(*gradients)\n                avg_grads = self._push_pull_grads(grads)\n                return list(zip(avg_grads, vars))\n            else:\n                return gradients\n\n        def apply_gradients(self, *args, **kwargs):\n            """"""Calls this same method on the underlying optimizer.""""""\n            if self._enable_async: # async training\n                grads_and_vars = args[0]\n                _, vars = zip(*grads_and_vars)\n                old_tensors = []\n                for var in vars:\n                    old_tensors.append(tf.convert_to_tensor(var))\n                apply_ops = self._optimizer.apply_gradients(*args, **kwargs)\n                with tf.control_dependencies([apply_ops]):\n                    # get the delta\n                    for i, var in enumerate(vars):\n                        old_tensors[i] = tf.subtract(var, old_tensors[i])\n\n                    # reuse the _push_pul_grads(), but is transferring parameters\n                    updated_tensors = self._push_pull_grads(old_tensors)\n\n                    # copy the updated variable back\n                    assign_op_list = []\n                    for i, tensor in enumerate(updated_tensors):\n                        assign_op_list.append(tf.assign(vars[i], tensor))\n\n                return control_flow_ops.group(*assign_op_list)\n            else:\n                return self._optimizer.apply_gradients(*args, **kwargs)\n\n        def get_slot(self, *args, **kwargs):\n            """"""Calls this same method on the underlying optimizer.""""""\n            return self._optimizer.get_slot(*args, **kwargs)\n\n        def get_slot_names(self, *args, **kwargs):\n            """"""Calls this same method on the underlying optimizer.""""""\n            return self._optimizer.get_slot_names(*args, **kwargs)\n\n        def variables(self, *args, **kwargs):\n            """"""Calls this same method on the underlying optimizer.""""""\n            return self._optimizer.variables(*args, **kwargs)\n\ndef DistributedOptimizer(optimizer, name=None, use_locking=False, device_dense=\'\',\n                         device_sparse=\'\', compression=Compression.none,\n                         sparse_as_dense=False, backward_passes_per_step=1,\n                         op=Average):\n    """"""Construct a new DistributedOptimizer, which uses another optimizer\n    under the hood for computing single-process gradient values and\n    applying gradient updates after the gradient values have been combined\n    across all the BytePS ranks.\n\n    Args:\n      optimizer:\n        Optimizer to use for computing gradients and applying updates.\n      name:\n        Optional name prefix for the operations created when applying\n        gradients. Defaults to ""Distributed"" followed by the provided\n        optimizer type.\n      use_locking:\n        Whether to use locking when updating variables.\n        See Optimizer.__init__ for more info.\n      device_dense:\n        Device to be used for dense tensors. Uses GPU by default.\n      device_sparse:\n        Device to be used for sparse tensors. Uses GPU by default.\n      compression:\n        Compression algorithm used during push_pull to reduce the amount\n        of data sent during each parameter update step.  Defaults to\n        not using compression.\n      sparse_as_dense:\n        Treat all sparse gradients as dense tensors.  This can help improve\n        performance and memory utilization if the original sparse gradient\n        has high density.  Defaults to false.\n      backward_passes_per_step:\n        Number of backward passes to perform before calling bps.push_pull\n        This allows accumulating updates over multiple mini-batches before\n        reducing and applying them.\n      op:\n        The reduction operation to use when combining gradients across\n        different ranks.\n    """"""\n    if isinstance(optimizer, _LegacyOptimizer):\n        if op == Adasum:\n            raise ValueError(\'op == Adasum is not supported yet with \')\n        else:\n            if backward_passes_per_step > 1:\n                raise ValueError(\'backward_passes_per_step>1 is not supported yet with \'\n                                 \'op != Adasum\')\n            return _DistributedOptimizer(optimizer, name, use_locking, device_dense,\n                                        device_sparse, compression, sparse_as_dense, op)\n    elif isinstance(optimizer, tf.keras.optimizers.Optimizer):\n        if op == Adasum:\n            raise ValueError(\'op == Adasum is not supported yet with Keras\')\n        if backward_passes_per_step > 1:\n            raise ValueError(\'backward_passes_per_step > 1 is not supported yet with Keras\')\n        import byteps.tensorflow.keras as bps_k\n        return bps_k.DistributedOptimizer(optimizer, name, device_dense, device_sparse,\n                                          compression, sparse_as_dense)\n    else:\n        raise ValueError(\'Provided optimizer doesn\\\'t inherit from either legacy \'\n                         \'TensorFlow or Keras optimizer: %s\' % optimizer)\n\n\nif hasattr(tf, \'GradientTape\'):\n    class _DistributedGradientTape(tf.GradientTape):\n        def __init__(self, tape, device_dense, device_sparse, compression, sparse_as_dense, op,\n                     persistent=False, watch_accessed_variables=True):\n            if hasattr(tape, \'_watch_accessed_variables\'):\n                super(self.__class__, self).__init__(persistent, watch_accessed_variables)\n            else:\n                super(self.__class__, self).__init__(persistent)\n\n            self._tape = tape\n            self._persistent = persistent\n            self._watch_accessed_variables = watch_accessed_variables\n            self._name = ""Distributed""\n            self._device_dense = device_dense\n            self._device_sparse = device_sparse\n            self._compression = compression\n            self._sparse_as_dense = sparse_as_dense\n\n            def push_pull_grads(grads):\n                with tf.name_scope(self._name + ""_Push_Pull"") as scope:\n                    if self._sparse_as_dense:\n                        grads = [tf.convert_to_tensor(grad)\n                                 if grad is not None and isinstance(grad, tf.IndexedSlices)\n                                 else grad for grad in grads]\n                    return [push_pull(grad, scope,\n                                      device_dense=self._device_dense,\n                                      device_sparse=self._device_sparse,\n                                      compression=self._compression)\n                            if grad is not None else grad\n                            for grad in grads]\n\n            self._push_pull_grads = push_pull_grads\n\n        def gradient(self, target, sources, output_gradients=None):\n            gradients = super(self.__class__, self).gradient(target, sources, output_gradients)\n            if size() > 1:\n                avg_grads = self._push_pull_grads(gradients)\n                return avg_grads\n            else:\n                return gradients\n\n\n    def DistributedGradientTape(gradtape, device_dense=\'\', device_sparse=\'\',\n                                compression=Compression.none, sparse_as_dense=False,\n                                op=Average):\n        """"""An tape that wraps another tf.GradientTape, using an push_pull to\n        average gradient values before applying gradients to model weights.\n        Args:\n          gradtape:\n            GradientTape to use for computing gradients and applying updates.\n          device_dense:\n            Device to be used for dense tensors. Uses GPU by default.\n          device_sparse:\n            Device to be used for sparse tensors. Uses GPU by default.\n          compression:\n            Compression algorithm used during push_pull to reduce the amount\n            of data sent during the each parameter update step.  Defaults to\n            not using compression.\n          sparse_as_dense:\n            Treat all sparse gradients as dense tensors.  This can help improve\n            performance and memory utilization if the original sparse gradient\n            has high density.  Defaults to false.\n          op:\n            The reduction operation to use when combining gradients across\n            different ranks.\n        """"""\n        cls = type(gradtape.__class__.__name__, (gradtape.__class__,),\n                   dict(_DistributedGradientTape.__dict__))\n        if hasattr(gradtape, \'_watch_accessed_variables\'):\n            return cls(gradtape._tape, device_dense, device_sparse, compression,\n                       sparse_as_dense, op, gradtape._persistent,\n                       gradtape._watch_accessed_variables)\n        else:\n            return cls(gradtape._tape, device_dense, device_sparse, compression,\n                       sparse_as_dense, op, gradtape._persistent)\n'"
byteps/tensorflow/compression.py,2,"b'# Copyright 2019 Bytedance Inc. All Rights Reserved.\n# Copyright 2018 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Gradient compression algorithms.""""""\n\nimport tensorflow as tf\n\n\nclass Compressor(object):\n    """"""Interface for compressing and decompressing a given tensor.""""""\n    @staticmethod\n    def compress(tensor):\n        """"""Compresses a tensor and returns it with the context needed to decompress it.""""""\n        pass\n\n    @staticmethod\n    def decompress(tensor, ctx):\n        """"""Decompress the tensor with the given context.""""""\n        pass\n\n\nclass NoneCompressor(Compressor):\n    """"""Default no-op compression.""""""\n    @staticmethod\n    def compress(tensor):\n        """"""Returns the tensor unmodified.""""""\n        return tensor, None\n\n    @staticmethod\n    def decompress(tensor, ctx):\n        """"""Returns the tensor unmodified.""""""\n        return tensor\n\n\nclass FP16Compressor(Compressor):\n    """"""Compress all floating point gradients to 16-bit.""""""\n    @staticmethod\n    def compress(tensor):\n        """"""Downcasts the tensor to 16-bit.""""""\n        tensor_compressed = tensor\n        if tensor.dtype.is_floating:\n            # Only allow compression from other floating point types\n            tensor_compressed = tf.cast(tensor, dtype=tf.float16)\n        return tensor_compressed, tensor.dtype\n\n    @staticmethod\n    def decompress(tensor, ctx):\n        """"""Upcasts the tensor to the initialization dtype.""""""\n        tensor_decompressed = tensor\n        dtype = ctx\n        if dtype.is_floating:\n            tensor_decompressed = tf.cast(tensor, dtype=dtype)\n        return tensor_decompressed\n\n\nclass Compression(object):\n    """"""Optional gradient compression algorithm used during push_pull.""""""\n\n    """"""Do not compress the gradients. This is the default.""""""\n    none = NoneCompressor\n\n    """"""Compress all floating point gradients to 16-bit.""""""\n    fp16 = FP16Compressor\n'"
byteps/tensorflow/ops.py,10,"b'# Copyright 2019 Bytedance Inc. All Rights Reserved.\n# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n# Modifications copyright (C) 2019 Uber Technologies, Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# =============================================================================\n""""""Inter-process communication using BytePS.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport re\nimport os\nimport ctypes\nfrom enum import Enum\nimport random\nimport string\n\nfrom tensorflow.python.framework import load_library\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.platform import resource_loader\n\nfrom byteps.common import get_ext_suffix\nfrom byteps.common import BytePSBasics as _BytePSBasics\nfrom byteps.tensorflow.util import _executing_eagerly\nimport tensorflow as tf\n\n\ndef _load_library(name):\n    """"""Loads a .so file containing the specified operators.\n    Args:\n      name: The name of the .so file to load.\n    Raises:\n      NotFoundError if were not able to load .so file.\n    """"""\n    filename = resource_loader.get_path_to_datafile(name)\n    library = load_library.load_op_library(filename)\n    return library\n\n\nC_LIB = _load_library(\'c_lib\' + get_ext_suffix())\n\n_basics = _BytePSBasics(__file__, \'c_lib\')\n\n# import basic methods\ninit = _basics.init\nshutdown = _basics.shutdown\nsuspend = _basics.suspend\nresume = _basics.resume\nsize = _basics.size\nlocal_size = _basics.local_size\nrank = _basics.rank\nlocal_rank = _basics.local_rank\n\ndll_path = os.path.join(os.path.dirname(__file__),\n                        \'c_lib\' + get_ext_suffix())\nTF_LIB_CTYPES = ctypes.CDLL(dll_path, ctypes.RTLD_GLOBAL)\n\ndef get_average_backwards_compatibility_fun(reduce_ops):\n    """"""\n    Handle backwards compatibility between the old average and the new op parameters.\n    Old code using the average parameter (e.g. bps.PushPull(tensor, average=False))\n    gets unchanged behavior, but mixing old and new is disallowed (e.g. no\n    bps.PushPull(tensor, average=False, op=bps.Adasum)).\n    """"""\n    def impl(op, average):\n        if op != None:\n            if average != None:\n                raise ValueError(\'The op parameter supersedes average. Please provide only one of them.\')\n            return op\n        elif average != None:\n            warnings.warn(\'Parameter `average` has been replaced with `op` and will be removed\',\n                          DeprecationWarning)\n            return reduce_ops.Average if average else reduce_ops.Sum\n        else:\n            return reduce_ops.Average\n    return impl\n\nclass ReduceOps(Enum):\n    # This value should never appear past framework code, as\n    # averaging is taken care of there.\n    Average = ""Average""\n    Sum = ""Sum""\n    Adsum = ""Adsum""\n\nhandle_average_backwards_compatibility = get_average_backwards_compatibility_fun(ReduceOps)\n\n\ndef _normalize_name(name):\n    """"""Normalizes operation name to TensorFlow rules.""""""\n    return re.sub(\'[^a-zA-Z0-9_]\', \'_\', name)\n\ndef randomString(stringLength=16):\n    letters = string.ascii_lowercase\n    return \'\'.join(random.choice(letters) for i in range(stringLength))\n\ndef _push_pull(tensor, scope=\'\', name=None):\n    """"""An op which sums an input tensor over all the BytePS processes.\n    The reduction operation is keyed by the name of the op. The tensor type and\n    shape must be the same on all BytePS processes for a given name. The reduction\n    will not start until all processes are ready to send and receive the tensor.\n    Returns:\n      A tensor of the same shape and type as `tensor`, summed across all\n      processes.\n    """"""\n    if name is None and not _executing_eagerly():\n        name = \'BytePSPushPull_%s\' % _normalize_name(tensor.name)\n    if scope == \'\' and not _executing_eagerly():\n        if \'v1\' in dir(tf.compat):\n            scope = tf.compat.v1.get_default_graph().get_name_scope()\n        else:\n            scope = tf.get_default_graph().get_name_scope()\n        if scope != \'\':\n            scope += \'/\'\n    if not name:\n        name = \'\'\n    full_name = scope + name\n    if not full_name:\n        full_name = ""empty_name_"" + randomString()\n    full_name_ascii = full_name.encode(""ascii"")\n    TF_LIB_CTYPES.byteps_tensorflow_declare_tensor(ctypes.c_char_p(full_name_ascii))\n    return C_LIB.byteps_push_pull(tensor, name=name, input_name = full_name)\n\n\n@ops.RegisterGradient(\'BytePSPushPull\')\ndef _push_pull_grad(op, grad):\n    """"""Gradient for push_pull op.\n    Args:\n      op: An operation.\n      grad: `Tensor` gradient with respect to the output of the op.\n    Returns:\n      The gradient with respect to the input of the op.\n    """"""\n    return _push_pull(grad)\n\n\ndef broadcast(tensor, root_rank, scope=\'\', name=None, is_variable=True):\n    """"""An op which broadcasts the input tensor on root rank to the same input tensor\n    on all other BytePS processes.\n    The broadcast operation is keyed by the name of the op. The tensor type and\n    shape must be the same on all BytePS processes for a given name. The broadcast\n    will not start until all processes are ready to send and receive the tensor.\n    Returns:\n      A tensor of the same shape and type as `tensor`, with the value broadcasted\n      from root rank.\n    """"""\n    # Broadcast is implemented as push + pull after zero-ing non-root tensors\n    if name is None and not _executing_eagerly():\n        name = \'BytePSBroadcast_%s\' % _normalize_name(tensor.name)\n    if scope == \'\' and not _executing_eagerly():\n        if \'v1\' in dir(tf.compat):\n            scope = tf.compat.v1.get_default_graph().get_name_scope()\n        else:\n            scope = tf.get_default_graph().get_name_scope()\n        if scope != \'\':\n            scope += \'/\'\n    if not name:\n        name = \'\'\n    full_name = scope + name\n    if not full_name:\n        full_name = ""empty_name_"" + randomString()\n    full_name_ascii = full_name.encode(""ascii"")\n\n    TF_LIB_CTYPES.byteps_tensorflow_declare_tensor(ctypes.c_char_p(full_name_ascii))\n    if root_rank != rank():\n        if is_variable:\n            if hasattr(tf, \'assign_sub\'):\n                with tf.control_dependencies([tf.assign_sub(tensor, tensor)]):\n                    return C_LIB.byteps_push_pull(tensor, name=name)\n            else:\n                with tf.control_dependencies([tf.compat.v1.assign_sub(tensor, tensor)]):\n                    return C_LIB.byteps_push_pull(tensor, name=name, input_name = full_name)\n        else:\n            with tf.device(tensor.device):\n                input_tensor = tf.zeros_like(tensor)\n            return C_LIB.byteps_push_pull(input_tensor, name=name, input_name = full_name)\n    else:\n        return C_LIB.byteps_push_pull(tensor, name=name, input_name = full_name)\n\n\n@ops.RegisterGradient(\'BytePSBroadcast\')\ndef _broadcast_grad(op, grad):\n    """"""Gradient for broadcast op.\n    Args:\n      op: An operation.\n      grad: `Tensor` gradient with respect to the output of the op.\n    Returns:\n      The gradient with respect to the input of the op.\n    """"""\n    root_rank = op.get_attr(\'root_rank\')\n    grad_reduced = _push_pull(grad)\n    if rank() != root_rank:\n        return grad_reduced * 0\n    return grad_reduced\n'"
byteps/tensorflow/util.py,1,"b'# Copyright 2018 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\nfrom distutils.version import LooseVersion\n\nimport tensorflow as tf\n\n\nif LooseVersion(tf.__version__) >= LooseVersion(""1.9.0""):\n    from tensorflow.python.eager import context\n    _has_eager = True\nelse:\n    _has_eager = False\n\n\ndef _executing_eagerly():\n    """"""Returns true if eager execution is supported and enabled.""""""\n    return _has_eager and context.in_eager_mode()\n'"
byteps/torch/__init__.py,0,"b'# Copyright 2019 Bytedance Inc. All Rights Reserved.\n# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom contextlib import contextmanager\n\nfrom byteps.torch.compression import Compression\nfrom byteps.torch.ops import push_pull_async_inplace as byteps_push_pull\nfrom byteps.torch.ops import push_pull\nfrom byteps.torch.ops import poll, synchronize, declare\nfrom byteps.torch.ops import init, shutdown, suspend, resume\nfrom byteps.torch.ops import size, local_size, rank, local_rank\n\nimport os\nimport torch\nimport collections\n\n\nclass _DistributedOptimizer(torch.optim.Optimizer):\n    def __init__(self, params, named_parameters, compression,\n                 backward_passes_per_step=1):\n        super(self.__class__, self).__init__(params)\n        self._compression = compression\n\n        if named_parameters is not None:\n            named_parameters = list(named_parameters)\n        else:\n            named_parameters = []\n\n        self._enable_async = (int(os.getenv(\'BYTEPS_ENABLE_ASYNC\', 0)) != 0)\n        if self._enable_async:\n            assert int(os.getenv(\'DMLC_NUM_WORKER\')) > 1, \\\n                ""Async is only valid for distributed training""\n            print(\'BytePS: enable asynchronous training\')\n\n        # make sure that named_parameters are tuples\n        if any([not isinstance(p, tuple) for p in named_parameters]):\n            raise ValueError(\'named_parameters should be a sequence of \'\n                             \'tuples (name, parameter), usually produced by \'\n                             \'model.named_parameters().\')\n\n        dups = _DistributedOptimizer.find_duplicates([k for k, _ in named_parameters])\n        if len(dups) > 0:\n            raise ValueError(\'Parameter names in named_parameters must be unique. \'\n                             \'Found duplicates: %s\' % \', \'.join(dups))\n\n        if len(named_parameters) > 0:\n            if isinstance(named_parameters[0][1], torch.Tensor):\n                if any([not isinstance(p, torch.Tensor) for name, p in named_parameters]):\n                    raise ValueError(\'named_parameters should consistently be a sequence of \'\n                                     \'tuples (name, torch.Tensor)\')\n                self._is_tensor_instance = True\n                # there is an issue when using torch.Tensor as key, so use its hash instead\n                # https://github.com/pytorch/pytorch/issues/7733\n                self._parameter_names = {v.__hash__(): k for k, v\n                                         in sorted(named_parameters)}\n                self._tensor_list = [tensor for name, tensor in named_parameters]\n            else:\n                self._is_tensor_instance = False\n                self._parameter_names = {v: k for k, v\n                                         in sorted(named_parameters)}\n        else:\n            self._is_tensor_instance = False\n            self._parameter_names = {v: \'push_pull.noname.%s\' % i\n                                     for param_group in self.param_groups\n                                     for i, v in enumerate(param_group[\'params\'])}\n        self.backward_passes_per_step = backward_passes_per_step\n        self._push_pull_delay = {v: self.backward_passes_per_step\n                                 for _, v in sorted(named_parameters)}\n        self._handles = {}\n        self._grad_accs = []\n        self._requires_update = set()\n        self._should_sync = True\n        if size() > 1:\n            self._register_hooks()\n\n        # declare tensors\n        for name in sorted(self._parameter_names.values()):\n            declare(""Gradient.""+name)\n        # We use two loops for load-balancing\n        for name in sorted(self._parameter_names.values()):\n            declare(""Parameter.""+name)\n\n    @staticmethod\n    def find_duplicates(lst):\n        seen = set()\n        dups = set()\n        for el in lst:\n            if el in seen:\n                dups.add(el)\n            seen.add(el)\n        return dups\n\n    def set_backward_passes_per_step(self, passes):\n        self.backward_passes_per_step = passes\n        for p in self._push_pull_delay:\n            self._push_pull_delay[p] = self.backward_passes_per_step\n\n    def _register_hooks(self):\n        for param_group in self.param_groups:\n            for p in param_group[\'params\']:\n                if p.requires_grad:\n                    p.grad = p.data.new(p.size()).zero_()\n                    self._requires_update.add(p)\n                    p_tmp = p.expand_as(p)\n                    grad_acc = p_tmp.grad_fn.next_functions[0][0]\n                    grad_acc.register_hook(self._make_hook(p))\n                    self._grad_accs.append(grad_acc)\n\n    def _push_pull_grad_async(self, p):\n        if self._is_tensor_instance:\n            name = self._parameter_names.get(p.__hash__())\n        else:\n            name = self._parameter_names.get(p)\n        if self._enable_async:\n            # the real handle will be created in step()\n            handle, ctx = None, None\n        else:\n            tensor = p.grad\n            tensor_compressed, ctx = self._compression.compress(tensor)\n            handle = byteps_push_pull(tensor_compressed, average=True, name=""Gradient.""+name)\n        return handle, ctx\n\n    def _make_hook(self, p):\n        def hook(*ignore):\n            if p in self._handles and self._handles[p][0] is not None:\n                if self._push_pull_delay[p] <= 0:\n                    raise AssertionError(\n                        ""Gradients were computed more than ""\n                        ""backward_passes_per_step times before call ""\n                        ""to step(). Increase backward_passes_per_step to ""\n                        ""accumulate gradients locally."")\n            assert not p.grad.requires_grad\n            assert self._push_pull_delay[p] > 0\n            handle, ctx = None, None\n            self._push_pull_delay[p] -= 1\n            if self._push_pull_delay[p] == 0:\n                handle, ctx = self._push_pull_grad_async(p)\n            self._handles[p] = (handle, ctx)\n        return hook\n\n    def synchronize(self):\n        missing_p = self._requires_update - set(self._handles.keys())\n        for p in missing_p:\n            handle, ctx = self._push_pull_grad_async(p)\n            self._handles[p] = (handle, ctx)\n\n        for p, value in self._handles.items():\n            handle, ctx = value\n            if handle is None:\n                handle, ctx = self._push_pull_grad_async(p)\n                self._handles[p] = (handle, ctx)\n        for p, (handle, _) in self._handles.items():\n            output = synchronize(handle)\n            self._push_pull_delay[p] = self.backward_passes_per_step\n            if not self._enable_async:\n                p.grad.set_(self._compression.decompress(output, ctx))\n        self._handles.clear()\n\n    @contextmanager\n    def skip_synchronize(self):\n        if self._enable_async:\n            raise AssertionError(""skip_synchronize cannot be used in async training"")\n        self._should_sync = False\n        try:\n            yield\n        finally:\n            self._should_sync = True\n\n    def step(self, closure=None):\n        if self._enable_async:\n            old_weight_map = {}\n            # store the weights before update\n            for p, _ in self._handles.items():\n                old_weight_map[p] = p.data.clone().detach()\n            # update\n            loss = super(self.__class__, self).step(closure)\n\n            for p, (h, _) in self._handles.items():\n                # get the diff for each weight (in-place)\n                p.data.sub_(old_weight_map.get(p))\n                if h is None:\n                    # create the handler now\n                    if self._is_tensor_instance:\n                        name = self._parameter_names.get(p.__hash__())\n                    else:\n                        name = self._parameter_names.get(p)\n                    handle = byteps_push_pull(p, average=False, name=""AsyncParam.""+name)\n                    _, ctx = self._compression.compress(p)\n                    self._handles[p] = (handle, ctx)\n\n            self.synchronize()\n            return loss\n        else:\n            # skip sync if calling skip_synchronize\n            if self._should_sync:\n                self.synchronize()\n            return super(self.__class__, self).step(closure)\n\n\ndef DistributedOptimizer(optimizer, named_parameters=None,\n                         compression=Compression.none,\n                         backward_passes_per_step=1):\n    """"""\n    An optimizer that wraps another torch.optim.Optimizer, using an push_pull to\n    average gradient values before applying gradients to model weights.\n    push_pull operations are executed after each gradient is computed by `loss.backward()`\n    in parallel with each other. The `step()` method ensures that all push_pull operations are\n    finished before applying gradients to the model.\n    DistributedOptimizer exposes the `synchronize()` method, which forces push_pull operations\n    to finish before continuing the execution. It\'s useful in conjunction with gradient\n    clipping, or other operations that modify gradients in place before `step()` is executed.\n    Example of gradient clipping:\n    ```\n    output = model(data)\n    loss = F.nll_loss(output, target)\n    loss.backward()\n    optimizer.synchronize()\n    torch.nn.utils.clip_grad_norm(model.parameters(), args.clip)\n    optimizer.step()\n    ```\n    Arguments:\n        optimizer: Optimizer to use for computing gradients and applying updates.\n        named_parameters: A mapping between parameter names and values. Used for naming of\n                          push_pull operations. Typically just `model.named_parameters()`.\n        compression: Compression algorithm used during push_pull to reduce the amount\n                     of data sent during the each parameter update step.  Defaults to\n                     not using compression.\n        backward_passes_per_step: Number of expected backward passes to perform\n                                  before calling step()/synchronize(). This\n                                  allows accumulating gradients over multiple\n                                  mini-batches before executing averaging and\n                                  applying them.\n    """"""\n    # We dynamically create a new class that inherits from the optimizer that was passed in.\n    # The goal is to override the `step()` method with an push_pull implementation.\n    cls = type(optimizer.__class__.__name__, (optimizer.__class__,),\n               dict(_DistributedOptimizer.__dict__))\n    return cls(optimizer.param_groups, named_parameters,\n               compression, backward_passes_per_step)\n\n\ndef broadcast_parameters(params, root_rank):\n    """"""\n    Broadcasts the parameters from root rank to all other processes.\n    Typical usage is to broadcast the `model.state_dict()`,\n    `model.named_parameters()`, or `model.parameters()`.\n    Arguments:\n        params: One of the following:\n            - list of parameters to broadcast\n            - dict of parameters to broadcast\n        root_rank: The rank of the process from which parameters will be\n                   broadcasted to all other processes.\n    """"""\n    if isinstance(params, dict):\n        params = sorted(params.items())\n    elif isinstance(params, list):\n        # support both named_parameters() and regular parameters()\n        params = [p if isinstance(p, tuple) else (None, p) for p in params]\n    else:\n        raise ValueError(\'invalid params of type: %s\' % type(params))\n\n    # Run synchronous broadcasts.\n    for name, p in params:\n        # Broadcast is implemented as push + pull in BytePS\n        # To make it a real broadcast, we set the non-root tensors all 0.\n        if rank() != root_rank:\n            p.fill_(0)\n        # Remember to disable averaging because we are doing broadcast\n        if name:\n            handle = byteps_push_pull(p, average=False, name=""Parameter.""+name)\n        else:\n            handle = byteps_push_pull(p, average=False)\n        synchronize(handle)\n\n\ndef broadcast_optimizer_state(optimizer, root_rank):\n    """"""\n    Broadcasts an optimizer state from root rank to all other processes.\n    Arguments:\n        optimizer: An optimizer.\n        root_rank: The rank of the process from which the optimizer will be\n                   broadcasted to all other processes.\n    """"""\n    if isinstance(optimizer, torch.optim.LBFGS):\n        # TODO(travis): L-BFGS cannot be easily supported without serializing\n        # the entire state_dict, as its structure is deeply nested and contains\n        # None type parameter values\n        raise ValueError(\'cannot broadcast torch.optim.LBFGS state\')\n\n    state_dict = optimizer.state_dict()\n\n    # Newly created optimizers will not have their state initialized, so\n    # do that initialization here\n    if len(state_dict[\'state\']) == 0:\n        for group in optimizer.param_groups:\n            for p in group[\'params\']:\n                p.grad = p.data.new(p.size()).zero_()\n        # This function accepts a torch.optim.Optimizer or a DistributedOptimizer\n        # wrapped around a torch optimizer. Calling step() with a DistributedOptimizer\n        # forces push_pull on all model parameters, which will result in deadlock\n        # unless every rank calls step(). Therefore, to finish state initialization\n        # only call optimizer.step() with a torch.optim.Optimizer.\n        if optimizer.__module__ == DistributedOptimizer.__module__:\n            super(optimizer.__class__, optimizer).step()\n        else:\n            optimizer.step()\n        state_dict = optimizer.state_dict()\n\n    # If the state_dict is still empty after initialization, then\n    # the optimizer is stateless, and there is nothing to broadcast.\n    # Furthermore, attempting to access the state dict would result in\n    # an error.\n    if len(state_dict[\'state\']) == 0:\n        return\n\n    params = []\n    callbacks = {}\n    occurrences = collections.defaultdict(int)\n\n    # Returns the full type structure of the possibly nested objects for recursive casting back\n    def _get_types(x):\n        if isinstance(x, collections.Iterable):\n            return type(x), [_get_types(xi) for xi in x]\n        else:\n            return type(x)\n\n    # Casts an object encoded in a tensor back into its original type and subtypes\n    def _recursive_cast(x, dtype):\n        if isinstance(dtype, tuple):\n            t, dtypes = dtype\n            x = t(x)\n            return t([_recursive_cast(x[i], dtypes[i]) for i in range(len(x))])\n        else:\n            return dtype(x)\n\n    # Some optimizer parameters may be represented as scalars instead of\n    # tensors.  In such cases, we need to wrap the scalar in a tensor, then\n    # broadcast, then update the appropriate value in the state_dict with the\n    # new unwrapped scalar value via a callback.\n    def _create_callback(pid, name, t, p):\n        def _from_tensor():\n            state_dict[\'state\'][pid][name] = t(p.cpu().numpy()[0])\n        return _from_tensor\n\n    def _create_option_callback(index, option_key, option_tensor, dtypes):\n        def _from_tensor():\n            optimizer.param_groups[index][option_key] = _recursive_cast(\n                option_tensor.cpu().numpy()[0], dtypes)\n        return _from_tensor\n\n    # Param groups are an ordered list, normally there is only one per model,\n    # but users can add additional param groups for example to train\n    # previously frozen layers\n    for index, group in enumerate(state_dict[\'param_groups\']):\n        # Broadcast options like learning rate\n        for option_key, option_value in group.items():\n            if option_key == \'params\':\n                continue\n\n            # Options like the learning rate are scalar, and need to be wrapped in tensors\n            key = \'%s.%d\' % (option_key, index)\n            dtypes = _get_types(option_value)\n            option_tensor = torch.Tensor([option_value]).cuda()\n            callbacks[key] = _create_option_callback(index, option_key, option_tensor, dtypes)\n            params.append((key, option_tensor))\n\n        # The params list here is ordered by the layers in the model\n        for pid in group[\'params\']:\n            param_state = state_dict[\'state\'][pid]\n            for name, p in param_state.items():\n                # Some parameter names may appear more than once, in which\n                # case we ensure they have a unique identifier defined by\n                # their order\n                occurrences[name] += 1\n                key = \'%s.%d\' % (str(name), occurrences[name])\n\n                if not torch.is_tensor(p):\n                    # Wrap the scalar in a FloatTensor, and remember its type\n                    # so we can cast it back after unwrapping\n                    t = type(p)\n                    p = torch.Tensor([p]).cuda()\n                    callbacks[key] = _create_callback(pid, name, t, p)\n\n                params.append((key, p))\n\n    # Synchronized broadcast of all parameters\n    broadcast_parameters(params, root_rank)\n\n    # Post-broadcast clenaup for non-tensor parameters\n    for key, p in params:\n        if key in callbacks:\n            callbacks[key]()\n'"
byteps/torch/compression.py,0,"b'# Copyright 2019 Bytedance Inc. All Rights Reserved.\n# Copyright 2018 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Gradient compression algorithms.""""""\n\nimport torch\n\n\nclass Compressor(object):\n    """"""Interface for compressing and decompressing a given tensor.""""""\n    @staticmethod\n    def compress(tensor):\n        """"""Compresses a tensor and returns it with the context needed to decompress it.""""""\n        pass\n\n    @staticmethod\n    def decompress(tensor, ctx):\n        """"""Decompress the tensor with the given context.""""""\n        pass\n\n\nclass NoneCompressor(Compressor):\n    """"""Default no-op compression.""""""\n    @staticmethod\n    def compress(tensor):\n        """"""Returns the tensor unmodified.""""""\n        return tensor, None\n\n    @staticmethod\n    def decompress(tensor, ctx):\n        """"""Returns the tensor unmodified.""""""\n        return tensor\n\n\nclass FP16Compressor(Compressor):\n    """"""Compress all floating point gradients to 16-bit.""""""\n    @staticmethod\n    def compress(tensor):\n        """"""Downcasts the tensor to 16-bit.""""""\n        tensor_compressed = tensor\n        if tensor.dtype.is_floating_point:\n            # Only allow compression from other floating point types\n            tensor_compressed = tensor.type(torch.float16)\n        return tensor_compressed, tensor.dtype\n\n    @staticmethod\n    def decompress(tensor, ctx):\n        """"""Upcasts the tensor to the initialization dtype.""""""\n        tensor_decompressed = tensor\n        dtype = ctx\n        if dtype.is_floating_point:\n            tensor_decompressed = tensor.type(dtype)\n        return tensor_decompressed\n\n\nclass Compression(object):\n    """"""Optional gradient compression algorithm used during push_pull.""""""\n\n    """"""Do not compress the gradients. This is the default.""""""\n    none = NoneCompressor\n\n    """"""Compress all floating point gradients to 16-bit.""""""\n    fp16 = FP16Compressor\n'"
byteps/torch/cross_barrier.py,0,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom byteps.torch.compression import Compression\nfrom byteps.torch.ops import push_pull_async_inplace as byteps_push_pull\nfrom byteps.torch.ops import poll, synchronize\nfrom byteps.torch.ops import init, shutdown\nfrom byteps.torch.ops import size, local_size, rank, local_rank\n\nimport threading\nimport logging\ntry:\n    import queue\nexcept ImportError:\n    import Queue as queue\nimport time\nimport math\nimport torch\nimport byteps.torch as bps\n\n_DistributedOptimizer = bps._DistributedOptimizer\n_bps_DistributedOptimizer = bps.DistributedOptimizer\nbroadcast_parameters = bps.broadcast_parameters\nbroadcast_optimizer_state = bps.broadcast_optimizer_state\n\n\nclass _CrossBarrier(_DistributedOptimizer):\n    """"""An optimizer that wraps a _DistributedOptimizer, intercepting push-pull operations.\n    This class enables overlapping gradient push-pull with both backward and forward propagation while maintaining\n    correct dependencies. It can achieve even higher training performance than the default BytePS with proper system\n    parameters. To understand the principles behind barrier crossing, check the paper\n    https://dl.acm.org/citation.cfm?id=3359642\n    """"""\n    def __init__(self, model, byteps_opt, num_steps=10**6):\n        """"""Construct a new ScheduledOptimizer, which uses byteps optimizer under the hood for averaging gradients\n         across all workers.\n        Args:\n            model: The training model. BytePS uses the model object to register hooks.\n            byteps_opt: Optimizer to use for averaging gradients and applying updates.\n            num_steps: The maximum number of training steps. BytePS needs to know when to stop cross-iteration\n            scheduling.\n        """"""\n        self._model = model\n        self._opt = byteps_opt\n        self._logger = logging.getLogger(""CrossBarrier"")\n\n        self._logger.info(""CrossBarrier is enabled."")\n        self._logger.debug(""byteps size {}, rank {}"".format(size(), rank()))\n        self._desc = ""rank {}"".format(rank())\n\n        # Track training steps\n        self._step = 0\n        self._final_step = num_steps\n\n        # Use lock to block the forward propagation of each parameter.\n        self._locks = {}\n        for param_group in self.param_groups:\n            for p in param_group[\'params\']:\n                self._locks[p] = threading.Lock()\n\n        if size() > 1:\n            self._register_forward_hooks()\n            self._register_hooks()\n\n            # Poll whether the tensor push-pull is finished.\n            self._event_queue = queue.Queue()\n            self._poller = threading.Thread(target=self._poll, args=())\n            self._poller.start()\n\n    def __getattr__(self, item):\n        return getattr(self._opt, item)\n\n    def step(self, closure=None):\n        """"""Override the default step function.""""""\n        self._logger.debug(""{} calls step() {}"".format(self._desc, self._step))\n\n        # Step 0 is called for parameter initialization after parameter broadcast\n        if size() > 1 and self._step > 0:\n            self._synchronize()\n            # if it is the final training step, wait for the completion of all tensors\n            if self._step == self._final_step:\n                self._logger.debug(""final step {}, waiting for push-pull completion."".format(self._final_step))\n                while not self._event_queue.empty():\n                    time.sleep(0.001)\n                self._event_queue.put((None, None, None))\n                self._poller.join()\n                self._logger.info(""training finished!"")\n            loss = None\n            if closure is not None:\n                loss = closure()\n            self._step += 1\n            return loss\n        else:\n            # Optimizer.step() will be triggered when user calls byteps.broadcast_optimizer_sate()\n            super(self._opt.__class__, self._opt).step()\n            self._step += 1\n\n    def zero_grad(self):\n        """"""Override the default zero_grad function.\n        Clears the gradients of all optimized tensors.\n        """"""\n        self._logger.debug(""{} calls zero_grad() of step {}"".format(self._desc, self._step))\n        if size() > 1 and self._step > 0:\n            return\n        else:\n            self._opt.zero_grad()\n\n    def _get_parameter_name(self, p):\n        if self._is_tensor_instance:\n            name = self._parameter_names.get(p.__hash__())\n        else:\n            name = self._parameter_names.get(p)\n        return name\n\n    def _register_hooks(self):\n        for param_group in self.param_groups:\n            for p in param_group[\'params\']:\n                if p.requires_grad:\n                    p.grad = p.data.new(p.size()).zero_()\n                    self._requires_update.add(p)\n                    p_tmp = p.expand_as(p)\n                    grad_acc = p_tmp.grad_fn.next_functions[0][0]\n                    grad_acc.register_hook(self._make_hook(p))\n                    self._grad_accs.append(grad_acc)\n\n    def _synchronize(self):\n        """"""Push pull missing parameters""""""\n        missing_p = self._requires_update - set(self._handles.keys())\n        for p in missing_p:\n            handle, ctx = self._push_pull_grad_async(p)\n            self._handles[p] = (handle, ctx)\n\n        for p, value in self._handles.items():\n            handle, ctx = value\n            if handle is None:\n                handle, ctx = self._push_pull_grad_async(p)\n                self._handles[p] = (handle, ctx)\n\n    def _push_pull_grad_async(self, p):\n        """"""Call byteps API to push-pull gradient asynchronously\n        Arguments:\n            tensor: The tensor to push-pull.\n            name: The name of the tensor.\n        Returns:\n            an push-pull handle and context\n        """"""\n        name = self._get_parameter_name(p)\n        tensor = p.grad\n        tensor_compressed, ctx = self._compression.compress(tensor)\n\n        self._locks[p].acquire()\n        handle = byteps_push_pull(tensor_compressed, average=True, name=""Gradient.""+name)\n        self._logger.debug(""{} calls byteps_push_pull for {}"".format(self._desc, self._get_parameter_name(p)))\n        # Add to queue to poll completion\n        self._event_queue.put((p, handle, ctx))\n        return handle, ctx\n\n    def _poll(self):\n        """"""Poll the completion of the tensor\'s backward or push-pull from a FIFO event_queue""""""\n        while True:\n            p, handle, ctx = self._event_queue.get()\n            if p is None:\n                self._logger.debug(""poller exits."")\n                break\n            # Check whether the push-pull is finished. If so, start updating parameters.\n            if handle is not None and poll(handle):\n                output = synchronize(handle)\n                p.grad.set_(self._compression.decompress(output, ctx))\n                self._logger.debug(""{} {} finished push-pull"".format(self._desc, self._get_parameter_name(p)))\n                self._push_pull_delay[p] = self.backward_passes_per_step\n                # So only support SGD, Adam and RMSprop optimizers in torch\n                if isinstance(self._opt, torch.optim.SGD):\n                    self._sgd(p)\n                elif isinstance(self._opt, torch.optim.Adam):\n                    self._adam(p)\n                elif isinstance(self._opt, torch.optim.RMSprop):\n                    self._rmsprop(p)\n                else:\n                    raise ValueError(""Invalid optimizer! Only support SGD, Adam and RMSprop."")\n                self._zero_one_grad(p)\n                # notify update completion and parameter is ready for forward propagation\n                if p in self._locks:\n                    self._locks[p].release()\n            else:\n                self._event_queue.put((p, handle, ctx))\n\n    def _register_forward_hooks(self):\n        """"""Add hook before forward propagation of each layer to block forward computation until the push-pull and\n        parameter update is finished. The blocking is implemented using a lock.""""""\n        # Recursively find all submodules\n        submodules = []\n        q = queue.LifoQueue()\n        for mod in self._model.children():\n            q.put(mod)\n        while not q.empty():\n            mod = q.get()\n            if len(list(mod.children())) == 0:\n                submodules.append(mod)\n            else:\n                for m in mod.children():\n                    q.put(m)\n\n        def pre_forward_hook(mod, input):\n            for p in mod.parameters():\n                if p in self._handles:\n                    del self._handles[p]\n                if p not in self._locks:\n                    continue\n                with self._locks[p]:\n                    self._logger.debug(""{} {} is ready."".format(self._desc, self._get_parameter_name(p)))\n\n            self._logger.debug(""{} starts forward {}."".format(self._desc, mod))\n\n        def after_forward_hook(mod, input, result):\n            self._logger.debug(""{} finished forward {}."".format(self._desc, mod))\n\n        # Register pre-hook and hook for each module\n        for mod in reversed(submodules):\n            self._logger.debug(""{} registers forward hook on module {}"".format(self._desc, mod))\n            mod.register_forward_pre_hook(pre_forward_hook)\n            mod.register_forward_hook(after_forward_hook)\n\n    def _zero_one_grad(self, p):\n        """"""Clears the gradient of one variable as torch accumulates gradients by default.\n        Arguments:\n            p: the parameter.\n        """"""\n        if p.grad is not None:\n            p.grad.detach_()\n            p.grad.zero_()\n\n    """"""Below are the implementations of optimizers, e.g., SGD, Adam, RMSprop.\n    The implementation is derived from Torch\'s code, except that we update one parameter each time.""""""\n\n    def _sgd(self, p):\n        """"""Performs a single optimization step using SGD optimizer on a parameter.\n        Arguments:\n            p: The parameter to be updated.\n        """"""\n        for group in self.param_groups:\n            weight_decay = group[\'weight_decay\']\n            momentum = group[\'momentum\']\n            dampening = group[\'dampening\']\n            nesterov = group[\'nesterov\']\n\n            for gp in group[\'params\']:\n                if self._get_parameter_name(p) != self._get_parameter_name(gp) or gp.shape != p.shape:\n                    continue\n                self._logger.debug(""{} is updating {}"".format(self._desc, self._get_parameter_name(p)))\n                if p.grad is None:\n                    continue\n                d_p = p.grad.data\n                if weight_decay != 0:\n                    d_p.add_(weight_decay, p.data)\n                if momentum != 0:\n                    param_state = self.state[p]\n                    if \'momentum_buffer\' not in param_state:\n                        buf = param_state[\'momentum_buffer\'] = torch.zeros_like(p.data)\n                        buf.mul_(momentum).add_(d_p)\n                    else:\n                        buf = param_state[\'momentum_buffer\']\n                        buf.mul_(momentum).add_(1 - dampening, d_p)\n                    if nesterov:\n                        d_p = d_p.add(momentum, buf)\n                    else:\n                        d_p = buf\n                p.data.add_(-group[\'lr\'], d_p)\n                break\n\n    def _adam(self, p):\n        """"""Performs a single optimization step using Adam optimizer on a parameter.\n        Arguments:\n            p: The parameter to be updated.\n        """"""\n        for group in self.param_groups:\n            for gp in group[\'params\']:\n                if self._get_parameter_name(p) != self._get_parameter_name(gp) or gp.shape != p.shape:\n                    continue\n                self._logger.debug(""{} is updating {}"".format(self._desc, self._get_parameter_name(p)))\n                if p.grad is None:\n                    continue\n                grad = p.grad.data\n                if grad.is_sparse:\n                    raise RuntimeError(\'Adam does not support sparse gradients, please consider SparseAdam instead\')\n                amsgrad = group[\'amsgrad\']\n\n                state = self.state[p]\n\n                # State initialization\n                if len(state) == 0:\n                    state[\'step\'] = 0\n\n                    # Exponential moving average of gradient values\n                    state[\'exp_avg\'] = torch.zeros_like(p.data)\n\n                    # Exponential moving average of squared gradient values\n                    state[\'exp_avg_sq\'] = torch.zeros_like(p.data)\n                    if amsgrad:\n                        # Maintains max of all exp. moving avg. of sq. grad. values\n                        state[\'max_exp_avg_sq\'] = torch.zeros_like(p.data)\n\n                exp_avg, exp_avg_sq = state[\'exp_avg\'], state[\'exp_avg_sq\']\n                if amsgrad:\n                    max_exp_avg_sq = state[\'max_exp_avg_sq\']\n                beta1, beta2 = group[\'betas\']\n\n                state[\'step\'] += 1\n\n                if group[\'weight_decay\'] != 0:\n                    grad.add_(group[\'weight_decay\'], p.data)\n\n                # Decay the first and second moment running average coefficient\n                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n                if amsgrad:\n                    # Maintains the maximum of all 2nd moment running avg. till now\n                    torch.max(max_exp_avg_sq, exp_avg_sq, out=max_exp_avg_sq)\n\n                    # Use the max. for normalizing running avg. of gradient\n                    denom = max_exp_avg_sq.sqrt().add_(group[\'eps\'])\n                else:\n                    denom = exp_avg_sq.sqrt().add_(group[\'eps\'])\n\n                bias_correction1 = 1 - beta1 ** state[\'step\']\n                bias_correction2 = 1 - beta2 ** state[\'step\']\n                step_size = group[\'lr\'] * math.sqrt(bias_correction2) / bias_correction1\n\n                p.data.addcdiv_(-step_size, exp_avg, denom)\n                break\n\n    def _rmsprop(self, p):\n        """"""Performs a single optimization step using RMSprop optimizer on a parameter.\n        Arguments:\n            p: The parameter to be updated.\n        """"""\n        for group in self.param_groups:\n            for gp in group[\'params\']:\n                if self._get_parameter_name(p) != self._get_parameter_name(gp) or gp.shape != p.shape:\n                    continue\n                self._logger.debug(""{} is updating {}"".format(self._desc, self._get_parameter_name(p)))\n                if p.grad is None:\n                    continue\n                grad = p.grad.data\n                if grad.is_sparse:\n                    raise RuntimeError(\'RMSprop does not support sparse gradients\')\n                state = self.state[p]\n\n                # State initialization\n                if len(state) == 0:\n                    state[\'step\'] = 0\n                    state[\'square_avg\'] = torch.zeros_like(p.data)\n                    if group[\'momentum\'] > 0:\n                        state[\'momentum_buffer\'] = torch.zeros_like(p.data)\n                    if group[\'centered\']:\n                        state[\'grad_avg\'] = torch.zeros_like(p.data)\n\n                square_avg = state[\'square_avg\']\n                alpha = group[\'alpha\']\n\n                state[\'step\'] += 1\n\n                if group[\'weight_decay\'] != 0:\n                    grad = grad.add(group[\'weight_decay\'], p.data)\n\n                square_avg.mul_(alpha).addcmul_(1 - alpha, grad, grad)\n\n                if group[\'centered\']:\n                    grad_avg = state[\'grad_avg\']\n                    grad_avg.mul_(alpha).add_(1 - alpha, grad)\n                    avg = square_avg.addcmul(-1, grad_avg, grad_avg).sqrt().add_(group[\'eps\'])\n                else:\n                    avg = square_avg.sqrt().add_(group[\'eps\'])\n\n                if group[\'momentum\'] > 0:\n                    buf = state[\'momentum_buffer\']\n                    buf.mul_(group[\'momentum\']).addcdiv_(grad, avg)\n                    p.data.add_(-group[\'lr\'], buf)\n                else:\n                    p.data.addcdiv_(-group[\'lr\'], grad, avg)\n                break\n\n\ndef _init_bsc():\n    """"""Replace _register_hook() function in _DistributedOptimizer with empty function.""""""\n\n    def hijack(obj, func_name):\n        orig_func = getattr(obj, func_name)\n        # print(""hijack function {}"".format(orig_func))\n\n        def wrapped_func(*args, **kwargs):\n            # print(""function {} is hijacked to do nothing."".format(orig_func))\n            return\n        setattr(obj, func_name, wrapped_func)\n\n    hijack(_DistributedOptimizer, \'_register_hooks\')\n\n\ndef _init_logger():\n    logger = logging.getLogger(""CrossBarrier"")\n    formatter = logging.Formatter(\'%(asctime)s.%(msecs)03d %(filename)s:%(lineno)s %(levelname)s: %(message)s\',\n                                  \'%H:%M:%S\')\n    sh = logging.StreamHandler()\n    sh.setFormatter(formatter)\n    logger.addHandler(sh)\n    fh = logging.FileHandler(\'cross_barrier.log\', \'w\')\n    fh.setFormatter(formatter)\n    logger.addHandler(fh)\n    logger.propagate = False\n    logger.setLevel(logging.INFO)\n\n\ndef CrossBarrier(model,\n                 optimizer,\n                 named_parameters=None,\n                 compression=Compression.none,\n                 backward_passes_per_step=1,\n                 num_steps=10**6):\n    """"""Wrap Torch optimizer using BytePS DistributedOptimizer and _CrossBarrier.""""""\n    bps_opt = _bps_DistributedOptimizer(optimizer, named_parameters, compression, backward_passes_per_step)\n    return _CrossBarrier(model, bps_opt, num_steps)\n\n\n_init_bsc()\n_init_logger()\n'"
byteps/torch/ops.py,0,"b'# Copyright 2019 ByteDance, Inc. All Rights Reserved.\n# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom distutils.version import LooseVersion\n\n# Load all the necessary PyTorch C types.\nimport torch\n\n# PyTorch must be >= 1.0.0 (including nightly builds)\n# This should be guaranteed by setup.py\n# TODO: we may not support older pytorch. Raise exception here\nfrom byteps.torch import c_lib\nfrom byteps.common import BytePSBasics as _BytePSBasics\n_basics = _BytePSBasics(__file__, \'c_lib\')\n_NULL = """"\n\n\nfrom byteps.torch.compression import Compression\n\n# import basic methods\ninit = _basics.init\nshutdown = _basics.shutdown\nsuspend = _basics.suspend\nresume = _basics.resume\nsize = _basics.size\nlocal_size = _basics.local_size\nrank = _basics.rank\nlocal_rank = _basics.local_rank\n\n\n# Schema: handle -> input, output\n# We keep input in order to make sure it does not get garbage collected\n# before the operation is finished.\n_handle_map = {}\n\n\ndef _check_function(function_factory, tensor):\n    function = function_factory(tensor)\n    if not hasattr(c_lib, function):\n        raise ValueError(\'Tensor type %s is not supported.\' % tensor.type())\n    if not tensor.is_contiguous():\n        raise ValueError(\'Tensor is required to be contiguous.\')\n    return function\n\n\ndef _push_pull_function_factory(tensor):\n    return \'byteps_torch_push_pull_async_\' + tensor.type().replace(\'.\', \'_\')\n\ndef _push_pull_group_function_factory(tensor):\n    return \'byteps_torch_push_pull_group_sync_\' + tensor.type().replace(\'.\', \'_\')\n\ndef _do_push_pull_async(tensor, output, average, name, version=0, priority=0):\n    c_lib.byteps_torch_declare_tensor(name.encode() if name is not None else _NULL)\n    function = _check_function(_push_pull_function_factory, tensor)\n    handle = getattr(c_lib, function)(tensor, output, average,\n                                      name.encode() if name is not None else _NULL,\n                                      version, priority)\n    _handle_map[handle] = (tensor, output)\n    return handle\n\ndef _do_push_pull_group_sync(tensor, output, average, name, version=0, priority=0):\n    c_lib.byteps_torch_declare_tensor(name.encode() if name is not None else _NULL)\n    function = _check_function(_push_pull_group_function_factory, tensor)\n    handle, curr_count = getattr(c_lib, function)(tensor, output, average,\n                                      name.encode() if name is not None else _NULL,\n                                      version, priority)\n    _handle_map[handle] = (tensor, output)\n    return handle, curr_count\n\n\ndef push_pull_async(tensor, average=True, name=None, version=0, priority=0):\n    """"""\n    A function that performs asynchronous averaging or summation of the input tensor\n    over all the BytePS processes. The input tensor is not modified.\n    The reduction operation is keyed by the name. If name is not provided, an incremented\n    auto-generated name is used. The tensor type and shape must be the same on all\n    BytePS processes for a given name. The reduction will not start until all processes\n    are ready to send and receive the tensor.\n    Arguments:\n        tensor: A tensor to average and sum.\n        average: A flag indicating whether to compute average or summation,\n                 defaults to average.\n        name: A name of the reduction operation.\n    Returns:\n        A handle to the push_pull operation that can be used with `poll()` or\n        `synchronize()`.\n    """"""\n    output = tensor.new(tensor.shape)\n    return _do_push_pull_async(tensor, output, average, name, version, priority)\n\n\nclass BytePSPushPull(torch.autograd.Function):\n    """"""An autograd function that performs push_pull on a tensor.""""""\n\n    @staticmethod\n    def forward(ctx, tensor, average, name, version, priority):\n        ctx.average = average\n        ctx.name = name\n        ctx.version = version\n        ctx.priority = priority\n        handle = push_pull_async(tensor, average, name, version, priority)\n        return synchronize(handle)\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        return push_pull(grad_output,\n                         ctx.average, ctx.name, ctx.version, ctx.priority), None, None\n\n\ndef push_pull(tensor, average=True, name=None, version=0, priority=0, compression=Compression.none):\n    """"""\n    A function that performs averaging or summation of the input tensor over all the\n    BytePS processes. The input tensor is not modified. The reduction operation is keyed\n    by the name. The name must be provided. The tensor type and shape must be the same on all\n    BytePS processes for a given name. The reduction will not start until all processes\n    are ready to send and receive the tensor.\n    This acts as a thin wrapper around an autograd function.  If your input\n    tensor requires gradients, then callings this function will allow gradients\n    to be computed and backpropagated.\n    Arguments:\n        tensor: A tensor to average and sum.\n        average: A flag indicating whether to compute average or summation,\n                 defaults to average.\n        name: A name of the reduction operation.\n        compression: Compression algorithm used during push_pull to reduce the amount\n                     of data sent during the each parameter update step.  Defaults to\n                     not using compression.\n    Returns:\n        A tensor of the same shape and type as `tensor`, averaged or summed across all\n        processes.\n    """"""\n    if name == None:\n        raise AssertionError(""To manually call push_pull, you must specify a name by name=..."")\n    tensor_compressed, ctx = compression.compress(tensor)\n    summed_tensor_compressed = BytePSPushPull.apply(\n        tensor_compressed, average, name, version, priority)\n    return compression.decompress(summed_tensor_compressed, ctx)\n\n\ndef push_pull_async_inplace(tensor, average=True, name=None, version=0, priority=0):\n    """"""\n    A function that performs asynchronous in-place averaging or summation of the input\n    tensor over all the BytePS processes.\n    The reduction operation is keyed by the name. If name is not provided, an incremented\n    auto-generated name is used. The tensor type and shape must be the same on all\n    BytePS processes for a given name. The reduction will not start until all processes\n    are ready to send and receive the tensor.\n    Arguments:\n        tensor: A tensor to average and sum.\n        average: A flag indicating whether to compute average or summation,\n                 defaults to average.\n        name: A name of the reduction operation.\n    Returns:\n        A handle to the push_pull operation that can be used with `poll()` or\n        `synchronize()`.\n    """"""\n    return _do_push_pull_async(tensor, tensor, average, name, version, priority)\n\ndef push_pull_group_sync_inplace(tensor, average=True, name=None, version=0, priority=0):\n    return _do_push_pull_group_sync(tensor, tensor, average, name, version, priority)\n\ndef push_pull_inplace(tensor, average=True, name=None, version=0, priority=0):\n    """"""\n    A function that performs in-place averaging or summation of the input tensor over\n    all the BytePS processes.\n    The reduction operation is keyed by the name. If name is not provided, an incremented\n    auto-generated name is used. The tensor type and shape must be the same on all\n    BytePS processes for a given name. The reduction will not start until all processes\n    are ready to send and receive the tensor.\n    Arguments:\n        tensor: A tensor to average and sum.\n        average: A flag indicating whether to compute average or summation,\n                 defaults to average.\n        name: A name of the reduction operation.\n    Returns:\n        A tensor of the same shape and type as `tensor`, averaged or summed across all\n        processes.\n    """"""\n    handle = push_pull_async_inplace(tensor, average, name, version, priority)\n    return synchronize(handle)\n\n\ndef poll(handle):\n    """"""\n    Polls an push_pull handle to determine whether underlying\n    asynchronous operation has completed. After `poll()` returns `True`, `synchronize()`\n    will return without blocking.\n    Arguments:\n        handle: A handle returned by an push_pull asynchronous\n                operation.\n    Returns:\n        A flag indicating whether the operation has completed.\n    """"""\n    return c_lib.byteps_torch_poll(handle) != 0\n\n\ndef declare(name):\n    c_lib.byteps_torch_declare_tensor(name.encode())\n    return 0\n\ndef byteps_torch_set_num_grads(num_grads_):\n    c_lib.byteps_torch_set_num_grads(num_grads_)\n    return 0\n\ndef synchronize(handle):\n    """"""\n    Synchronizes an asynchronous push_pull operation until\n    it\'s completed. Returns the result of the operation.\n    Arguments:\n        handle: A handle returned by an push_pull asynchronous\n                operation.\n    Returns:\n        An output tensor of the operation.\n    """"""\n    if handle not in _handle_map:\n        return\n    c_lib.byteps_torch_wait_and_clear(handle)\n    _, output = _handle_map.pop(handle)\n    return output\n'"
example/keras/keras_imagenet_resnet50.py,2,"b""# Copyright 2019 Bytedance Inc. or its affiliates. All Rights Reserved.\n# Copyright 2017 Uber Technologies, Inc. All Rights Reserved.\n#\n# ResNet-50 model training using Keras and BytePS.\n#\n# This model is an example of a computation-intensive model that achieves good accuracy on an image\n# classification task.  It brings together distributed training concepts such as learning rate\n# schedule adjustments with a warmup, randomized data reading, and checkpointing on the first worker\n# only.\n#\n# Note: This model uses Keras native ImageDataGenerator and not the sophisticated preprocessing\n# pipeline that is typically used to train state-of-the-art ResNet-50 model.  This results in ~0.5%\n# increase in the top-1 validation error compared to the single-crop top-1 validation error from\n# https://github.com/KaimingHe/deep-residual-networks.\n#\nfrom __future__ import print_function\n\nimport argparse\nimport tensorflow.keras as keras\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.preprocessing import image\nimport tensorflow as tf\nimport byteps.keras as bps\nimport os\n\nparser = argparse.ArgumentParser(description='Keras ImageNet Example',\n                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)\nparser.add_argument('--train-dir', default=os.path.expanduser('~/imagenet/train'),\n                    help='path to training data')\nparser.add_argument('--val-dir', default=os.path.expanduser('~/imagenet/validation'),\n                    help='path to validation data')\nparser.add_argument('--log-dir', default='./logs',\n                    help='tensorboard log directory')\nparser.add_argument('--checkpoint-format', default='./checkpoint-{epoch}.h5',\n                    help='checkpoint file format')\nparser.add_argument('--fp16-pushpull', action='store_true', default=False,\n                    help='use fp16 compression during pushpull')\n\n# Default settings from https://arxiv.org/abs/1706.02677.\nparser.add_argument('--batch-size', type=int, default=32,\n                    help='input batch size for training')\nparser.add_argument('--val-batch-size', type=int, default=32,\n                    help='input batch size for validation')\nparser.add_argument('--epochs', type=int, default=90,\n                    help='number of epochs to train')\nparser.add_argument('--base-lr', type=float, default=0.0125,\n                    help='learning rate for a single GPU')\nparser.add_argument('--warmup-epochs', type=float, default=5,\n                    help='number of warmup epochs')\nparser.add_argument('--momentum', type=float, default=0.9,\n                    help='SGD momentum')\nparser.add_argument('--wd', type=float, default=0.00005,\n                    help='weight decay')\n\nargs = parser.parse_args()\n\n# initialize BytePS\nbps.init()\n\n# BytePS: pin GPU to be used to process local rank (one GPU per process)\nconfig = tf.ConfigProto()\nconfig.gpu_options.allow_growth = True\nconfig.gpu_options.visible_device_list = str(bps.local_rank())\nK.set_session(tf.Session(config=config))\n\n# If set > 0, will resume training from a given checkpoint.\nresume_from_epoch = 0\nfor try_epoch in range(args.epochs, 0, -1):\n    if os.path.exists(args.checkpoint_format.format(epoch=try_epoch)):\n        resume_from_epoch = try_epoch\n        break\n\n# BytePS: broadcast resume_from_epoch from rank 0 (which will have\n# checkpoints) to other ranks.\nresume_from_epoch = bps.broadcast(resume_from_epoch, 0, name='resume_from_epoch')\n\n# BytePS: print logs on the first worker.\nverbose = 1 if bps.rank() == 0 else 0\n\n# Training data iterator.\ntrain_gen = image.ImageDataGenerator(\n    width_shift_range=0.33, height_shift_range=0.33, zoom_range=0.5, horizontal_flip=True,\n    preprocessing_function=keras.applications.resnet50.preprocess_input)\ntrain_iter = train_gen.flow_from_directory(args.train_dir,\n                                           batch_size=args.batch_size,\n                                           target_size=(224, 224))\n\n# Validation data iterator.\ntest_gen = image.ImageDataGenerator(\n    zoom_range=(0.875, 0.875), preprocessing_function=keras.applications.resnet50.preprocess_input)\ntest_iter = test_gen.flow_from_directory(args.val_dir,\n                                         batch_size=args.val_batch_size,\n                                         target_size=(224, 224))\n\n# Set up standard ResNet-50 model.\nmodel = keras.applications.resnet50.ResNet50(weights=None)\n\n# BytePS: (optional) compression algorithm.\ncompression = bps.Compression.fp16 if args.fp16_pushpull else bps.Compression.none\n\n# Restore from a previous checkpoint, if initial_epoch is specified.\n# BytePS: restore on the first worker which will broadcast both model and optimizer weights\n# to other workers.\nif resume_from_epoch > 0 and bps.rank() == 0:\n    model = bps.load_model(args.checkpoint_format.format(epoch=resume_from_epoch),\n                           compression=compression)\nelse:\n    # ResNet-50 model that is included with Keras is optimized for inference.\n    # Add L2 weight decay & adjust BN settings.\n    model_config = model.get_config()\n    for layer, layer_config in zip(model.layers, model_config['layers']):\n        if hasattr(layer, 'kernel_regularizer'):\n            regularizer = keras.regularizers.l2(args.wd)\n            layer_config['config']['kernel_regularizer'] = \\\n                {'class_name': regularizer.__class__.__name__,\n                 'config': regularizer.get_config()}\n        if type(layer) == keras.layers.BatchNormalization:\n            layer_config['config']['momentum'] = 0.9\n            layer_config['config']['epsilon'] = 1e-5\n\n    model = keras.models.Model.from_config(model_config)\n\n    # BytePS: adjust learning rate based on number of GPUs.\n    opt = keras.optimizers.SGD(lr=args.base_lr * bps.size(),\n                               momentum=args.momentum)\n\n    # BytePS: add BytePS Distributed Optimizer.\n    opt = bps.DistributedOptimizer(opt, compression=compression)\n\n    model.compile(loss=keras.losses.categorical_crossentropy,\n                  optimizer=opt,\n                  metrics=['accuracy', 'top_k_categorical_accuracy'])\n\ncallbacks = [\n    # BytePS: broadcast initial variable states from rank 0 to all other processes.\n    # This is necessary to ensure consistent initialization of all workers when\n    # training is started with random weights or restored from a checkpoint.\n    bps.callbacks.BroadcastGlobalVariablesCallback(0),\n\n    # BytePS: average metrics among workers at the end of every epoch.\n    #\n    # Note: This callback must be in the list before the ReduceLROnPlateau,\n    # TensorBoard, or other metrics-based callbacks.\n    bps.callbacks.MetricAverageCallback(),\n\n    # BytePS: using `lr = 1.0 * bps.size()` from the very beginning leads to worse final\n    # accuracy. Scale the learning rate `lr = 1.0` ---> `lr = 1.0 * bps.size()` during\n    # the first five epochs. See https://arxiv.org/abs/1706.02677 for details.\n    bps.callbacks.LearningRateWarmupCallback(warmup_epochs=args.warmup_epochs, verbose=verbose),\n\n    # BytePS: after the warmup reduce learning rate by 10 on the 30th, 60th and 80th epochs.\n    bps.callbacks.LearningRateScheduleCallback(start_epoch=args.warmup_epochs, end_epoch=30, multiplier=1.),\n    bps.callbacks.LearningRateScheduleCallback(start_epoch=30, end_epoch=60, multiplier=1e-1),\n    bps.callbacks.LearningRateScheduleCallback(start_epoch=60, end_epoch=80, multiplier=1e-2),\n    bps.callbacks.LearningRateScheduleCallback(start_epoch=80, multiplier=1e-3),\n]\n\n# BytePS: save checkpoints only on the first worker to prevent other workers from corrupting them.\nif bps.rank() == 0:\n    callbacks.append(keras.callbacks.ModelCheckpoint(args.checkpoint_format))\n    callbacks.append(keras.callbacks.TensorBoard(args.log_dir))\n\n# Train the model. The training will randomly sample 1 / N batches of training data and\n# 3 / N batches of validation data on every worker, where N is the number of workers.\n# Over-sampling of validation data helps to increase probability that every validation\n# example will be evaluated.\nmodel.fit_generator(train_iter,\n                    steps_per_epoch=len(train_iter) // bps.size(),\n                    callbacks=callbacks,\n                    epochs=args.epochs,\n                    verbose=verbose,\n                    workers=4,\n                    initial_epoch=resume_from_epoch,\n                    validation_data=test_iter,\n                    validation_steps=3 * len(test_iter) // bps.size())\n\n# Evaluate the model on the full data set.\nscore = bps.push_pull(model.evaluate_generator(test_iter, len(test_iter), workers=4))\nif verbose:\n    print('Test loss:', score[0])\n    print('Test accuracy:', score[1])\n"""
example/keras/keras_mnist.py,2,"b""from __future__ import absolute_import, division, print_function\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras import backend as K\nimport math\nimport tensorflow as tf\nimport byteps.keras as bps\n\n# BytePS: initialize BytePS.\nbps.init()\n\n# BytePS: pin GPU to be used to process local rank (one GPU per process)\nconfig = tf.ConfigProto()\nconfig.gpu_options.allow_growth = True\nconfig.gpu_options.visible_device_list = str(bps.local_rank())\nK.set_session(tf.Session(config=config))\n\nbatch_size = 128\nnum_classes = 10\n\n# BytePS: adjust number of epochs based on number of GPUs.\nepochs = int(math.ceil(12.0 / bps.size()))\n\n# Input image dimensions\nimg_rows, img_cols = 28, 28\n\n# The data, shuffled and split between train and test sets\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nif K.image_data_format() == 'channels_first':\n    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n    input_shape = (1, img_rows, img_cols)\nelse:\n    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n    input_shape = (img_rows, img_cols, 1)\n\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train /= 255\nx_test /= 255\nprint('x_train shape:', x_train.shape)\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')\n\n# Convert class vectors to binary class matrices\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)\n\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation='softmax'))\n\n# BytePS: adjust learning rate based on number of GPUs.\nopt = keras.optimizers.Adadelta(1.0 * bps.size())\n\n# BytePS: add BytePS Distributed Optimizer.\nopt = bps.DistributedOptimizer(opt)\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=opt,\n              metrics=['accuracy'])\n\ncallbacks = [\n    # BytePS: broadcast initial variable states from rank 0 to all other processes.\n    # This is necessary to ensure consistent initialization of all workers when\n    # training is started with random weights or restored from a checkpoint.\n    bps.callbacks.BroadcastGlobalVariablesCallback(0),\n]\n\n# BytePS: save checkpoints only on worker 0 to prevent other workers from corrupting them.\nif bps.rank() == 0:\n    callbacks.append(keras.callbacks.ModelCheckpoint('./checkpoint-{epoch}.h5'))\n\nmodel.fit(x_train, y_train,\n          batch_size=batch_size,\n          callbacks=callbacks,\n          epochs=epochs,\n          verbose=1 if bps.rank() == 0 else 0,\n          validation_data=(x_test, y_test))\nscore = model.evaluate(x_test, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])\n"""
example/keras/keras_mnist_advanced.py,2,"b""from __future__ import print_function\nfrom tensorflow import keras\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import backend as K\nimport tensorflow as tf\nimport byteps.keras as bps\n\n# BytePS: initialize BytePS.\nbps.init()\n\n# BytePS: pin GPU to be used to process local rank (one GPU per process)\nconfig = tf.ConfigProto()\nconfig.gpu_options.allow_growth = True\nconfig.gpu_options.visible_device_list = str(bps.local_rank())\nK.set_session(tf.Session(config=config))\n\nbatch_size = 128\nnum_classes = 10\n\n# Enough epochs to demonstrate learning rate warmup and the reduction of\n# learning rate when training plateaues.\nepochs = 24\n\n# Input image dimensions\nimg_rows, img_cols = 28, 28\n\n# The data, shuffled and split between train and test sets\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\n# Determine how many batches are there in train and test sets\ntrain_batches = len(x_train) // batch_size\ntest_batches = len(x_test) // batch_size\n\nif K.image_data_format() == 'channels_first':\n    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n    input_shape = (1, img_rows, img_cols)\nelse:\n    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n    input_shape = (img_rows, img_cols, 1)\n\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train /= 255\nx_test /= 255\nprint('x_train shape:', x_train.shape)\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')\n\n# Convert class vectors to binary class matrices\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)\n\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation='softmax'))\n\n# BytePS: adjust learning rate based on number of GPUs.\nopt = keras.optimizers.Adadelta(lr=1.0 * bps.size())\n\n# BytePS: add BytePS Distributed Optimizer.\nopt = bps.DistributedOptimizer(opt)\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=opt,\n              metrics=['accuracy'])\n\ncallbacks = [\n    # BytePS: broadcast initial variable states from rank 0 to all other processes.\n    # This is necessary to ensure consistent initialization of all workers when\n    # training is started with random weights or restored from a checkpoint.\n    bps.callbacks.BroadcastGlobalVariablesCallback(0),\n\n    # BytePS: average metrics among workers at the end of every epoch.\n    #\n    # Note: This callback must be in the list before the ReduceLROnPlateau,\n    # TensorBoard or other metrics-based callbacks.\n    bps.callbacks.MetricAverageCallback(),\n\n    # BytePS: using `lr = 1.0 * bps.size()` from the very beginning leads to worse final\n    # accuracy. Scale the learning rate `lr = 1.0` ---> `lr = 1.0 * bps.size()` during\n    # the first five epochs. See https://arxiv.org/abs/1706.02677 for details.\n    bps.callbacks.LearningRateWarmupCallback(warmup_epochs=5, verbose=1),\n\n    # Reduce the learning rate if training plateaues.\n    keras.callbacks.ReduceLROnPlateau(patience=10, verbose=1),\n]\n\n# BytePS: save checkpoints only on worker 0 to prevent other workers from corrupting them.\nif bps.rank() == 0:\n    callbacks.append(keras.callbacks.ModelCheckpoint('./checkpoint-{epoch}.h5'))\n\n# Set up ImageDataGenerators to do data augmentation for the training images.\ntrain_gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n                               height_shift_range=0.08, zoom_range=0.08)\ntest_gen = ImageDataGenerator()\n\n# Train the model.\n# BytePS: the training will randomly sample 1 / N batches of training data and\n# 3 / N batches of validation data on every worker, where N is the number of workers.\n# Over-sampling of validation data helps to increase probability that every validation\n# example will be evaluated.\nmodel.fit_generator(train_gen.flow(x_train, y_train, batch_size=batch_size),\n                    steps_per_epoch=train_batches // bps.size(),\n                    callbacks=callbacks,\n                    epochs=epochs,\n                    verbose=1,\n                    validation_data=test_gen.flow(x_test, y_test, batch_size=batch_size),\n                    validation_steps=3 * test_batches // bps.size())\n\n# Evaluate the model on the full data set.\nscore = model.evaluate(x_test, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])"""
example/keras/keras_synthetic_benchmark_tf2.py,9,"b'from __future__ import absolute_import, division, print_function\n\nimport argparse\nimport os\nimport numpy as np\nimport timeit\n\nimport tensorflow as tf\nimport byteps.tensorflow.keras as bps\nfrom tensorflow.keras import applications\n\ntf.compat.v1.disable_eager_execution()\n\n# Benchmark settings\nparser = argparse.ArgumentParser(description=\'TensorFlow Synthetic Benchmark\',\n                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)\nparser.add_argument(\'--fp16-allreduce\', action=\'store_true\', default=False,\n                    help=\'use fp16 compression during allreduce\')\n\nparser.add_argument(\'--model\', type=str, default=\'ResNet50\',\n                    help=\'model to benchmark\')\nparser.add_argument(\'--batch-size\', type=int, default=32,\n                    help=\'input batch size\')\n\nparser.add_argument(\'--num-warmup-batches\', type=int, default=10,\n                    help=\'number of warm-up batches that don\\\'t count towards benchmark\')\nparser.add_argument(\'--num-batches-per-iter\', type=int, default=10,\n                    help=\'number of batches per benchmark iteration\')\nparser.add_argument(\'--num-iters\', type=int, default=10,\n                    help=\'number of benchmark iterations\')\n\nparser.add_argument(\'--no-cuda\', action=\'store_true\', default=False,\n                    help=\'disables CUDA training\')\n\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda\n\nbps.init()\n\n# pin GPU to be used to process local rank (one GPU per process)\nif args.cuda:\n    gpus = tf.config.experimental.list_physical_devices(\'GPU\')\n    for gpu in gpus:\n        tf.config.experimental.set_memory_growth(gpu, True)\n    if gpus:\n        tf.config.experimental.set_visible_devices(gpus[bps.local_rank()], \'GPU\')\nelse:\n    os.environ[""CUDA_VISIBLE_DEVICES""] = ""-1""\n\ndata = tf.random.uniform([args.batch_size, 224, 224, 3])\ntarget = tf.random.uniform([args.batch_size, 1], minval=0, maxval=999, dtype=tf.int64)\n\ncallbacks = [\n    # BytePS: broadcast initial variable states from rank 0 to all other processes.\n    # This is necessary to ensure consistent initialization of all workers when\n    # training is started with random weights or restored from a checkpoint.\n    bps.callbacks.BroadcastGlobalVariablesCallback(0),\n]\n# Set up standard model.\nmodel = getattr(applications, args.model)(weights=None)\nopt = tf.keras.optimizers.Adam(0.01)\nopt = tf.keras.mixed_precision.experimental.LossScaleOptimizer(opt, loss_scale=""dynamic"")\nopt = bps.DistributedOptimizer(opt)\n\nmodel.compile(loss=tf.keras.losses.categorical_crossentropy,\n              optimizer=opt,\n              metrics=[\'accuracy\', \'top_k_categorical_accuracy\'],\n              experimental_run_tf_function=False)\nmodel.fit(data, target, epochs=10, steps_per_epoch=16, callbacks=callbacks)\n\ntest_loss, test_acc, test_topk = model.evaluate(data, target, verbose=2, steps=16)\nprint(\'\\nTest accuracy:\', test_acc)\n'"
example/mxnet/train_gluon_mnist_byteps.py,0,"b'# Copyright 2019 Bytedance Inc. or its affiliates. All Rights Reserved.\n# Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""This file is modified from `horovod/examples/mxnet_mnist.py`, using gluon style MNIST dataset and data_loader.""""""\nimport time\n\nimport argparse\nimport logging\n\nimport mxnet as mx\nimport byteps.mxnet as bps\nfrom mxnet import autograd, gluon, nd\nfrom mxnet.gluon.data.vision import MNIST\n\n\n# Higher download speed for chinese users\n# os.environ[\'MXNET_GLUON_REPO\'] = \'https://apache-mxnet.s3.cn-north-1.amazonaws.com.cn/\'\n\n# Training settings\nparser = argparse.ArgumentParser(description=\'MXNet MNIST Example\')\n\nparser.add_argument(\'--batch-size\', type=int, default=64,\n                    help=\'training batch size (default: 64)\')\nparser.add_argument(\'--dtype\', type=str, default=\'float32\',\n                    help=\'training data type (default: float32)\')\nparser.add_argument(\'--epochs\', type=int, default=5,\n                    help=\'number of training epochs (default: 5)\')\nparser.add_argument(\'--j\', type=int, default=2,\n                    help=\'number of cpu processes for dataloader\')\nparser.add_argument(\'--lr\', type=float, default=0.01,\n                    help=\'learning rate (default: 0.01)\')\nparser.add_argument(\'--momentum\', type=float, default=0.9,\n                    help=\'SGD momentum (default: 0.9)\')\nparser.add_argument(\'--no-cuda\', action=\'store_true\', default=False,\n                    help=\'disable training on GPU (default: False)\')\nargs = parser.parse_args()\n\nif not args.no_cuda:\n    # Disable CUDA if there are no GPUs.\n    if mx.context.num_gpus() == 0:\n        args.no_cuda = True\n\nlogging.basicConfig(level=logging.INFO)\nlogging.info(args)\n\n\ndef dummy_transform(data, label):\n    im = data.astype(args.dtype, copy=False) / 255 - 0.5\n    im = nd.transpose(im, (2, 0, 1))\n    return im, label\n\n\n# Function to get mnist iterator\ndef get_mnist_iterator():\n    train_set = MNIST(train=True, transform=dummy_transform)\n    train_iter = gluon.data.DataLoader(train_set, args.batch_size, True, num_workers=args.j, last_batch=\'discard\')\n    val_set = MNIST(train=False, transform=dummy_transform)\n    val_iter = gluon.data.DataLoader(val_set, args.batch_size, False, num_workers=args.j)\n\n    return train_iter, val_iter, len(train_set)\n\n\n# Function to define neural network\ndef conv_nets():\n    net = gluon.nn.HybridSequential()\n    with net.name_scope():\n        net.add(gluon.nn.Conv2D(channels=20, kernel_size=5, activation=\'relu\'))\n        net.add(gluon.nn.MaxPool2D(pool_size=2, strides=2))\n        net.add(gluon.nn.Conv2D(channels=50, kernel_size=5, activation=\'relu\'))\n        net.add(gluon.nn.MaxPool2D(pool_size=2, strides=2))\n        net.add(gluon.nn.Flatten())\n        net.add(gluon.nn.Dense(512, activation=""relu""))\n        net.add(gluon.nn.Dense(10))\n    return net\n\n\n# Function to evaluate accuracy for a model\ndef evaluate(model, data_iter, context):\n    metric = mx.metric.Accuracy()\n    for _, batch in enumerate(data_iter):\n        data = batch[0].as_in_context(context)\n        label = batch[1].as_in_context(context)\n        output = model(data.astype(args.dtype, copy=False))\n        metric.update([label], [output])\n\n    return metric.get()\n\n\n# Load training and validation data\ntrain_data, val_data, train_size = get_mnist_iterator()\n\n# Initialize BytePS\nbps.init()\n\n# BytePS: pin context to local rank\ncontext = mx.cpu(bps.local_rank()) if args.no_cuda else mx.gpu(bps.local_rank())\nnum_workers = bps.size()\n\n# Build model\nmodel = conv_nets()\nmodel.cast(args.dtype)\n\n# Initialize parameters\nmodel.initialize(mx.init.MSRAPrelu(), ctx=context)\n# if bps.rank() == 0:\nmodel.summary(nd.ones((1, 1, 28, 28), ctx=mx.gpu(bps.local_rank())))\nmodel.hybridize()\n\nparams = model.collect_params()\n\n# BytePS: create DistributedTrainer, a subclass of gluon.Trainer\noptimizer_params = {\'momentum\': args.momentum, \'learning_rate\': args.lr * num_workers}\ntrainer = bps.DistributedTrainer(params, ""sgd"", optimizer_params)\n\n# Create loss function and train metric\nloss_fn = gluon.loss.SoftmaxCrossEntropyLoss()\nmetric = mx.metric.Accuracy()\n\n# Train model\nfor epoch in range(args.epochs):\n    tic = time.time()\n    metric.reset()\n    for i, batch in enumerate(train_data):\n        data = batch[0].as_in_context(context)\n        label = batch[1].as_in_context(context)\n\n        with autograd.record():\n            output = model(data)\n            loss = loss_fn(output, label)\n\n        loss.backward()\n        trainer.step(args.batch_size)\n        metric.update([label], [output])\n\n        if i % 100 == 0:\n            name, acc = metric.get()\n            logging.info(\'[Epoch %d Batch %d] Training: %s=%f\' %\n                         (epoch, i, name, acc))\n\n    if bps.rank() == 0:\n        elapsed = time.time() - tic\n        speed = train_size * num_workers / elapsed\n        logging.info(\'Epoch[%d]\\tSpeed=%.2f samples/s\\tTime cost=%f\',\n                     epoch, speed, elapsed)\n\n    # Evaluate model accuracy\n    _, train_acc = metric.get()\n    name, val_acc = evaluate(model, val_data, context)\n    if bps.rank() == 0:\n        logging.info(\'Epoch[%d]\\tTrain: %s=%f\\tValidation: %s=%f\', epoch, name,\n                     train_acc, name, val_acc)\n\n    if bps.rank() == 0 and epoch == args.epochs - 1:\n        assert val_acc > 0.96, ""Achieved accuracy (%f) is lower than expected\\\n                                (0.96)"" % val_acc\n'"
example/mxnet/train_imagenet_byteps.py,0,"b'#!/usr/bin/env python\n\n# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# ""License""); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n\nimport os\nimport argparse\nimport logging\nlogging.basicConfig(level=logging.DEBUG)\nfrom common import find_mxnet\nfrom common import data_byteps as data\nfrom common import fit_byteps as fit\nfrom common.util import download_file\nimport byteps.mxnet as bps\nimport mxnet as mx\n\nif __name__ == \'__main__\':\n    # init byteps\n    bps.init()\n\n    # parse args\n    parser = argparse.ArgumentParser(description=""train imagenet-1k"",\n                                     formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n    fit.add_fit_args(parser)\n    data.add_data_args(parser)\n    data.add_data_aug_args(parser)\n    # use a large aug level\n    data.set_data_aug_level(parser, 3)\n    parser.set_defaults(\n        # network\n        network          = \'resnet\',\n        num_layers       = 50,\n        # data\n        num_classes      = 1000,\n        num_examples     = 1281167,\n        image_shape      = \'3,224,224\',\n        min_random_scale = 1, # if input image has min size k, suggest to use\n                              # 256.0/x, e.g. 0.533 for 480\n        # train\n        num_epochs       = 80,\n        lr_step_epochs   = \'30,60\',\n        dtype            = \'float32\'\n    )\n    args = parser.parse_args()\n\n    # load network\n    from importlib import import_module\n    net = import_module(\'symbols.\'+args.network)\n    sym = net.get_symbol(**vars(args))\n\n    # train\n    fit.fit(args, sym, data.get_rec_iter)\n'"
example/pytorch/benchmark_byteps.py,0,"b""from __future__ import print_function\n\nimport argparse\nimport torch.backends.cudnn as cudnn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.utils.data.distributed\nfrom torchvision import models\nimport byteps.torch as bps\nimport timeit\nimport numpy as np\nimport os, sys\n\n# Benchmark settings\nparser = argparse.ArgumentParser(description='PyTorch Synthetic Benchmark',\n                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)\nparser.add_argument('--fp16-pushpull', action='store_true', default=False,\n                    help='use fp16 compression during byteps pushpull')\n\nparser.add_argument('--model', type=str, default='resnet50',\n                    help='model to benchmark')\nparser.add_argument('--batch-size', type=int, default=32,\n                    help='input batch size')\n\nparser.add_argument('--num-warmup-batches', type=int, default=10,\n                    help='number of warm-up batches that don\\'t count towards benchmark')\nparser.add_argument('--num-batches-per-iter', type=int, default=10,\n                    help='number of batches per benchmark iteration')\nparser.add_argument('--num-iters', type=int, default=10,\n                    help='number of benchmark iterations')\nparser.add_argument('--num-classes', type=int, default=1000,\n                    help='number of classes')\n\nparser.add_argument('--no-cuda', action='store_true', default=False,\n                    help='disables CUDA training')\nparser.add_argument('--profiler', action='store_true', default=False,\n                    help='disables profiler')\nparser.add_argument('--partition', type=int, default=None,\n                    help='partition size')\n\n\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\n\nbps.init()\n\nif args.cuda:\n    # BytePS: pin GPU to local rank.\n    torch.cuda.set_device(bps.local_rank())\n\ncudnn.benchmark = True\n\n# Set up standard model.\nmodel = getattr(models, args.model)(num_classes=args.num_classes)\n\nif args.cuda:\n    # Move model to GPU.\n    model.cuda()\n\noptimizer = optim.SGD(model.parameters(), lr=0.01)\n\n# BytePS: (optional) compression algorithm.\ncompression = bps.Compression.fp16 if args.fp16_pushpull else bps.Compression.none\n\n# BytePS: wrap optimizer with DistributedOptimizer.\noptimizer = bps.DistributedOptimizer(optimizer,\n                                     named_parameters=model.named_parameters(),\n                                     compression=compression)\n\n# BytePS: broadcast parameters & optimizer state.\nbps.broadcast_parameters(model.state_dict(), root_rank=0)\nbps.broadcast_optimizer_state(optimizer, root_rank=0)\n\n# Set up fake data\ndatasets = []\nfor _ in range(100):\n    data = torch.rand(args.batch_size, 3, 224, 224)\n    target = torch.LongTensor(args.batch_size).random_() % 1000\n    if args.cuda:\n        data, target = data.cuda(), target.cuda()\n    datasets.append(data)\ndata_index = 0\n\ndef benchmark_step():\n    global data_index\n\n    data = datasets[data_index%len(datasets)]\n    data_index += 1\n    optimizer.zero_grad()\n    output = model(data)\n    loss = F.cross_entropy(output, target)\n    loss.backward()\n    optimizer.step()\n\n\ndef log(s, nl=True):\n    if bps.local_rank() != 0:\n        return\n    print(s, end='\\n' if nl else '')\n    sys.stdout.flush()\n\n\nlog('Model: %s' % args.model)\nlog('Batch size: %d' % args.batch_size)\ndevice = 'GPU' if args.cuda else 'CPU'\nlog('Number of %ss: %d' % (device, bps.size()))\n\n# Warm-up\nlog('Running warmup...')\ntimeit.timeit(benchmark_step, number=args.num_warmup_batches)\n\n# Benchmark\nlog('Running benchmark...')\nimg_secs = []\nenable_profiling = args.profiler & (bps.rank() == 0)\n\nwith torch.autograd.profiler.profile(enable_profiling, True) as prof:\n    for x in range(args.num_iters):\n        time = timeit.timeit(benchmark_step, number=args.num_batches_per_iter)\n        img_sec = args.batch_size * args.num_batches_per_iter / time\n        log('Iter #%d: %.1f img/sec per %s' % (x, img_sec, device))\n        img_secs.append(img_sec)\n\n\n# Results\nimg_sec_mean = np.mean(img_secs)\nimg_sec_conf = 1.96 * np.std(img_secs)\nlog('Img/sec per %s: %.1f +-%.1f' % (device, img_sec_mean, img_sec_conf))\nlog('Total img/sec on %d %s(s): %.1f +-%.1f' %\n    (bps.size(), device, bps.size() * img_sec_mean, bps.size() * img_sec_conf))\n\n"""
example/pytorch/benchmark_byteps_ddp.py,0,"b""from __future__ import print_function\n\nimport argparse\nimport torch.backends.cudnn as cudnn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.utils.data.distributed\nfrom torchvision import models\nimport byteps.torch as bps\nimport timeit\nimport numpy as np\nimport os, sys\nfrom byteps.torch.parallel import DistributedDataParallel as DDP\n\n# Benchmark settings\nparser = argparse.ArgumentParser(description='PyTorch Synthetic Benchmark',\n                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)\nparser.add_argument('--fp16-pushpull', action='store_true', default=False,\n                    help='use fp16 compression during byteps pushpull')\n\nparser.add_argument('--model', type=str, default='resnet50',\n                    help='model to benchmark')\nparser.add_argument('--batch-size', type=int, default=32,\n                    help='input batch size')\n\nparser.add_argument('--num-warmup-batches', type=int, default=10,\n                    help='number of warm-up batches that don\\'t count towards benchmark')\nparser.add_argument('--num-batches-per-iter', type=int, default=10,\n                    help='number of batches per benchmark iteration')\nparser.add_argument('--num-iters', type=int, default=10,\n                    help='number of benchmark iterations')\nparser.add_argument('--num-classes', type=int, default=1000,\n                    help='number of classes')\n\nparser.add_argument('--no-cuda', action='store_true', default=False,\n                    help='disables CUDA training')\nparser.add_argument('--profiler', action='store_true', default=False,\n                    help='disables profiler')\nparser.add_argument('--partition', type=int, default=None,\n                    help='partition size')\n\n\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\n\nbps.init()\n\nif args.cuda:\n    # BytePS: pin GPU to local rank.\n    torch.cuda.set_device(bps.local_rank())\n\ncudnn.benchmark = True\n\n# Set up standard model.\nmodel = getattr(models, args.model)(num_classes=args.num_classes)\n\nif args.cuda:\n    # Move model to GPU.\n    model.cuda()\n\noptimizer = optim.SGD(model.parameters(), lr=0.01)\n\nmodel = DDP(model, device_ids=[bps.local_rank()])\n# BytePS: (optional) compression algorithm.\n#compression = bps.Compression.fp16 if args.fp16_pushpull else bps.Compression.none\n\n# BytePS: wrap optimizer with DistributedOptimizer.\n#optimizer = bps.DistributedOptimizer(optimizer,\n#                                     named_parameters=model.named_parameters(),\n#                                     compression=compression)\n\n# BytePS: broadcast parameters & optimizer state.\nbps.broadcast_parameters(model.state_dict(), root_rank=0)\nbps.broadcast_optimizer_state(optimizer, root_rank=0)\n\n# Set up fake data\ndatasets = []\nfor _ in range(100):\n    data = torch.rand(args.batch_size, 3, 224, 224)\n    target = torch.LongTensor(args.batch_size).random_() % 1000\n    if args.cuda:\n        data, target = data.cuda(), target.cuda()\n    datasets.append(data)\ndata_index = 0\n\ndef benchmark_step():\n    global data_index\n\n    data = datasets[data_index%len(datasets)]\n    data_index += 1\n    optimizer.zero_grad()\n    output = model(data)\n    loss = F.cross_entropy(output, target)\n    loss.backward()\n    optimizer.step()\n\n\ndef log(s, nl=True):\n    if bps.local_rank() != 0:\n        return\n    print(s, end='\\n' if nl else '')\n    sys.stdout.flush()\n\n\nlog('Model: %s' % args.model)\nlog('Batch size: %d' % args.batch_size)\ndevice = 'GPU' if args.cuda else 'CPU'\nlog('Number of %ss: %d' % (device, bps.size()))\n\n# Warm-up\nlog('Running warmup...')\ntimeit.timeit(benchmark_step, number=args.num_warmup_batches)\n\n# Benchmark\nlog('Running benchmark...')\nimg_secs = []\nenable_profiling = args.profiler & (bps.rank() == 0)\n\nwith torch.autograd.profiler.profile(enable_profiling, True) as prof:\n    for x in range(args.num_iters):\n        time = timeit.timeit(benchmark_step, number=args.num_batches_per_iter)\n        img_sec = args.batch_size * args.num_batches_per_iter / time\n        log('Iter #%d: %.1f img/sec per %s' % (x, img_sec, device))\n        img_secs.append(img_sec)\n\n\n# Results\nimg_sec_mean = np.mean(img_secs)\nimg_sec_conf = 1.96 * np.std(img_secs)\nlog('Img/sec per %s: %.1f +-%.1f' % (device, img_sec_mean, img_sec_conf))\nlog('Total img/sec on %d %s(s): %.1f +-%.1f' %\n    (bps.size(), device, bps.size() * img_sec_mean, bps.size() * img_sec_conf))\n\n"""
example/pytorch/benchmark_cross_barrier_byteps.py,0,"b'from __future__ import print_function\n\nimport argparse\nimport torch.backends.cudnn as cudnn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.utils.data.distributed\nfrom torchvision import models\nimport timeit\nimport numpy as np\nimport os\nimport byteps.torch.cross_barrier as bps\n\n""""""\nThis example shows how to enable barrier crossing on top of BytePS in PyTorch. Note that you can use BytePS without\ncrossing barrier at all.\n\nCrossing barrier enables overlapping gradient push-pull with both backward computation and forward computation, while\nmaintaining correct dependencies, e.g., the forward computation of a layer will not start until the parameter of this\nlayer is updated. Hence it can further improves training performance beyond BytePS. See the paper\nhttps://dl.acm.org/citation.cfm?id=3359642 for more details.\n\nTo use it, just change the import statement and add two more arugments (i.e., model, num_steps) when wrapping the Torch\noptimizer, as shown below:\n```\nimport byteps.torch.cross_barrier as bps\noptimizer = bps.CrossBarrier(model, optimizer, named_parameters, compression, backward_passes_per_step, num_steps)\n```\nSo far we support SGD, Adam and RMSprop optimizers. Please submit a ticket if you need support for\nany other optimizers.\n\nTo see performance gain, the system parameters should be properly set, including BYTEPS_PARTITION_BYTES and\nBYTEPS_SCHEDULING_CREDIT.\n""""""\n\n# Benchmark settings\nparser = argparse.ArgumentParser(description=\'PyTorch Synthetic Benchmark Without Barrier\',\n                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)\nparser.add_argument(\'--fp16-allreduce\', action=\'store_true\', default=False,\n                    help=\'use fp16 compression during allreduce\')\n\nparser.add_argument(\'--model\', type=str, default=\'resnet50\',\n                    help=\'model to benchmark\')\nparser.add_argument(\'--batch-size\', type=int, default=32,\n                    help=\'input batch size\')\n\nparser.add_argument(\'--num-warmup-batches\', type=int, default=10,\n                    help=\'number of warm-up batches that don\\\'t count towards benchmark\')\nparser.add_argument(\'--num-batches-per-iter\', type=int, default=10,\n                    help=\'number of batches per benchmark iteration\')\nparser.add_argument(\'--num-iters\', type=int, default=10,\n                    help=\'number of benchmark iterations\')\nparser.add_argument(\'--num-classes\', type=int, default=1000,\n                    help=\'number of classes\')\n\nparser.add_argument(\'--no-cuda\', action=\'store_true\', default=False,\n                    help=\'disables CUDA training\')\nparser.add_argument(\'--profiler\', action=\'store_true\', default=False,\n                    help=\'disables profiler\')\nparser.add_argument(\'--partition\', type=int, default=None,\n                    help=\'partition size\')\n\n\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\n\nbps.init()\n\nif args.cuda:\n    # BytePS: pin GPU to local rank.\n    torch.cuda.set_device(bps.local_rank())\n\ncudnn.benchmark = True\n\n# Set up standard model.\nmodel = getattr(models, args.model)(num_classes=args.num_classes)\n\nif args.cuda:\n    # Move model to GPU.\n    model.cuda()\n\n# You may try one of the following optimizers\noptimizer = optim.SGD(model.parameters(), lr=0.01)\n# optimizer = optim.Adam(model.parameters(), lr=0.01)\n# optimizer = optim.RMSprop(model.parameters(), lr=0.01)\n\n# BytePS: (optional) compression algorithm.\ncompression = bps.Compression.fp16 if args.fp16_allreduce else bps.Compression.none\n\n# Wrap Torch optimizer with CrossBarrier.\n# You need to specify two additional args, i.e., model and num_steps.\n# Note that we only support SGD, Adam and RMSProp optimizers so far.\noptimizer = bps.CrossBarrier(model,\n                                     optimizer,\n                                     named_parameters=model.named_parameters(),\n                                     compression=compression,\n                                     num_steps=args.num_warmup_batches + args.num_iters * args.num_batches_per_iter)\n\n# BytePS: broadcast parameters & optimizer state.\nbps.broadcast_parameters(model.state_dict(), root_rank=0)\nbps.broadcast_optimizer_state(optimizer, root_rank=0)\n\n# Set up fake data\ndatasets = []\nfor _ in range(100):\n    data = torch.rand(args.batch_size, 3, 224, 224)\n    target = torch.LongTensor(args.batch_size).random_() % 1000\n    if args.cuda:\n        data, target = data.cuda(), target.cuda()\n    datasets.append(data)\ndata_index = 0\n\n\ndef benchmark_step():\n    global data_index\n\n    data = datasets[data_index%len(datasets)]\n    data_index += 1\n    optimizer.zero_grad()\n    output = model(data)\n    loss = F.cross_entropy(output, target)\n    loss.backward()\n    optimizer.step()\n\n\ndef log(s, nl=True):\n    if bps.rank() != 0:\n        return\n    print(s, end=\'\\n\' if nl else \'\')\n\n\nlog(\'Model: %s\' % args.model)\nlog(\'Batch size: %d\' % args.batch_size)\ndevice = \'GPU\' if args.cuda else \'CPU\'\nlog(\'Number of %ss: %d\' % (device, bps.size()))\n\n# Warm-up\nlog(\'Running warmup...\')\ntimeit.timeit(benchmark_step, number=args.num_warmup_batches)\n\n# Benchmark\nlog(\'Running benchmark...\')\nimg_secs = []\nenable_profiling = args.profiler & (bps.rank() == 0)\n\nwith torch.autograd.profiler.profile(enable_profiling, True) as prof:\n    for x in range(args.num_iters):\n        time = timeit.timeit(benchmark_step, number=args.num_batches_per_iter)\n        img_sec = args.batch_size * args.num_batches_per_iter / time\n        log(\'Iter #%d: %.1f img/sec per %s\' % (x, img_sec, device))\n        img_secs.append(img_sec)\n\n\n# Results\nimg_sec_mean = np.mean(img_secs)\nimg_sec_conf = 1.96 * np.std(img_secs)\nlog(\'Img/sec per %s: %.1f +-%.1f\' % (device, img_sec_mean, img_sec_conf))\nlog(\'Total img/sec on %d %s(s): %.1f +-%.1f\' %\n    (bps.size(), device, bps.size() * img_sec_mean, bps.size() * img_sec_conf))\n\n'"
example/pytorch/elastic_benchmark_byteps.py,0,"b""from __future__ import print_function\n\nimport argparse\nimport torch.backends.cudnn as cudnn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.utils.data.distributed\nfrom torchvision import models\nimport byteps.torch as bps\nimport timeit\nimport numpy as np\nimport os, sys\n\n# Benchmark settings\nparser = argparse.ArgumentParser(description='PyTorch Synthetic Benchmark',\n                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)\nparser.add_argument('--fp16-pushpull', action='store_true', default=False,\n                    help='use fp16 compression during byteps pushpull')\n\nparser.add_argument('--model', type=str, default='resnet50',\n                    help='model to benchmark')\nparser.add_argument('--batch-size', type=int, default=32,\n                    help='input batch size')\n\nparser.add_argument('--num-warmup-batches', type=int, default=10,\n                    help='number of warm-up batches that don\\'t count towards benchmark')\nparser.add_argument('--num-batches-per-iter', type=int, default=10,\n                    help='number of batches per benchmark iteration')\nparser.add_argument('--num-iters', type=int, default=10,\n                    help='number of benchmark iterations')\nparser.add_argument('--num-classes', type=int, default=1000,\n                    help='number of classes')\n\nparser.add_argument('--no-cuda', action='store_true', default=False,\n                    help='disables CUDA training')\nparser.add_argument('--profiler', action='store_true', default=False,\n                    help='disables profiler')\nparser.add_argument('--partition', type=int, default=None,\n                    help='partition size')\n\n\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\n\nbps.init()\n\nif args.cuda:\n    # BytePS: pin GPU to local rank.\n    torch.cuda.set_device(bps.local_rank())\n\ncudnn.benchmark = True\n\n# Set up standard model.\nmodel = getattr(models, args.model)(num_classes=args.num_classes)\n\nif args.cuda:\n    # Move model to GPU.\n    model.cuda()\n\noptimizer = optim.SGD(model.parameters(), lr=0.01)\n\n# BytePS: (optional) compression algorithm.\ncompression = bps.Compression.fp16 if args.fp16_pushpull else bps.Compression.none\n\n# BytePS: wrap optimizer with DistributedOptimizer.\noptimizer = bps.DistributedOptimizer(optimizer,\n                                     named_parameters=model.named_parameters(),\n                                     compression=compression)\n\n# BytePS: broadcast parameters & optimizer state.\nbps.broadcast_parameters(model.state_dict(), root_rank=0)\nbps.broadcast_optimizer_state(optimizer, root_rank=0)\n\n# Set up fake data\ndatasets = []\nfor _ in range(100):\n    data = torch.rand(args.batch_size, 3, 224, 224)\n    target = torch.LongTensor(args.batch_size).random_() % 1000\n    if args.cuda:\n        data, target = data.cuda(), target.cuda()\n    datasets.append(data)\ndata_index = 0\n\ndef benchmark_step():\n    global data_index\n\n    data = datasets[data_index%len(datasets)]\n    data_index += 1\n    optimizer.zero_grad()\n    output = model(data)\n    loss = F.cross_entropy(output, target)\n    loss.backward()\n    optimizer.step()\n\n\ndef log(s, nl=True):\n    if bps.local_rank() != 0:\n        return\n    print(s, end='\\n' if nl else '')\n    sys.stdout.flush()\n\n\nlog('Model: %s' % args.model)\nlog('Batch size: %d' % args.batch_size)\ndevice = 'GPU' if args.cuda else 'CPU'\nlog('Number of %ss: %d' % (device, bps.size()))\n\n# Warm-up\nlog('Running warmup...')\ntimeit.timeit(benchmark_step, number=args.num_warmup_batches)\n\n# Benchmark\nlog('Running benchmark...')\nimg_secs = []\nenable_profiling = args.profiler & (bps.rank() == 0)\n\nwith torch.autograd.profiler.profile(enable_profiling, True) as prof:\n    for x in range(args.num_iters):\n        time = timeit.timeit(benchmark_step, number=args.num_batches_per_iter)\n        img_sec = args.batch_size * args.num_batches_per_iter / time\n        log('Iter #%d: %.1f img/sec per %s' % (x, img_sec, device))\n        img_secs.append(img_sec)\n\n# Below is testing the elastic training feature enabled by the suspend and resume APIs.\nlog('elastic training...')\nbps.suspend()\nlog('bps is suspended.')\n\n# barrier: shutdown and start other workers altogether\n\n# assume 2 workers, 1 server and this worker id is 0\nbps.resume(2, 1, 0)\nlog('bps is resumed.')\n\n# Results\nimg_sec_mean = np.mean(img_secs)\nimg_sec_conf = 1.96 * np.std(img_secs)\nlog('Img/sec per %s: %.1f +-%.1f' % (device, img_sec_mean, img_sec_conf))\nlog('Total img/sec on %d %s(s): %.1f +-%.1f' %\n    (bps.size(), device, bps.size() * img_sec_mean, bps.size() * img_sec_conf))\n\n"""
example/pytorch/mnist-distributed.py,0,"b'import os\nfrom datetime import datetime\nimport argparse\nimport torch.multiprocessing as mp\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch\nimport torch.nn as nn\nimport torch.distributed as dist\nfrom nn.parallel import DistributedDataParallel as DDP\n\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'-n\', \'--nodes\', default=4, type=int, metavar=\'N\',\n                        help=\'number of data loading workers (default: 4)\')\n    parser.add_argument(\'-g\', \'--gpus\', default=1, type=int,\n                        help=\'number of gpus per node\')\n    parser.add_argument(\'-nr\', \'--nr\', default=0, type=int,\n                        help=\'ranking within the nodes\')\n    parser.add_argument(\'--epochs\', default=2, type=int, metavar=\'N\',\n                        help=\'number of total epochs to run\')\n    args = parser.parse_args()\n    args.world_size = args.gpus * args.nodes\n    os.environ[\'MASTER_ADDR\'] = \'10.57.23.164\'\n    os.environ[\'MASTER_PORT\'] = \'8888\'\n    mp.spawn(train, nprocs=args.gpus, args=(args,))\n\n\nclass ConvNet(nn.Module):\n    def __init__(self, num_classes=10):\n        super(ConvNet, self).__init__()\n        self.layer1 = nn.Sequential(\n            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n            nn.BatchNorm2d(16),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2))\n        self.layer2 = nn.Sequential(\n            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2))\n        self.fc = nn.Linear(7*7*32, num_classes)\n\n    def forward(self, x):\n        out = self.layer1(x)\n        out = self.layer2(out)\n        out = out.reshape(out.size(0), -1)\n        out = self.fc(out)\n        return out\n\n\ndef train(gpu, args):\n    rank = args.nr * args.gpus + gpu\n    dist.init_process_group(\n        backend=\'nccl\',\n        init_method=\'env://\',\n        world_size=args.world_size,\n        rank=rank)\n    torch.manual_seed(0)\n    model = ConvNet()\n    torch.cuda.set_device(gpu)\n    model.cuda(gpu)\n    batch_size = 100\n    # define loss function (criterion) and optimizer\n    criterion = nn.CrossEntropyLoss().cuda(gpu)\n    optimizer = torch.optim.SGD(model.parameters(), 1e-4)\n    # Wrap the model\n\n    model = DDP(model, device_ids=[gpu])\n    # Data loading code\n    train_dataset = torchvision.datasets.MNIST(\n        root=\'./data\',\n        train=True,\n        transform=transforms.ToTensor(),\n        download=True\n    )\n    train_sampler = torch.utils.data.distributed.DistributedSampler(\n        train_dataset,\n        num_replicas=args.world_size,\n        rank=rank)\n    train_loader = torch.utils.data.DataLoader(\n        dataset=train_dataset,\n        batch_size=batch_size,\n        shuffle=False,\n        num_workers=0,\n        pin_memory=True,\n        sampler=train_sampler\n    )\n\n    start = datetime.now()\n    total_step = len(train_loader)\n    for epoch in range(args.epochs):\n        for i, (images, labels) in enumerate(train_loader):\n            images = images.cuda(non_blocking=True)\n            labels = labels.cuda(non_blocking=True)\n            # Forward pass\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n            # Backward and optimize\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            if (i + 1) % 100 == 0 and gpu == 0:\n                print(\'Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}\'.format(epoch + 1, args.epochs, i + 1, total_step,\n                                                                         loss.item()))\n    if gpu == 0:\n        print(""Training complete in: "" + str(datetime.now() - start))\n\n\nif __name__ == \'__main__\':\n    main()\n'"
example/pytorch/train_imagenet_resnet50_byteps.py,0,"b""from __future__ import print_function\n\nimport torch\nimport argparse\nimport torch.backends.cudnn as cudnn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.utils.data.distributed\nfrom torchvision import datasets, transforms, models\nimport byteps.torch as bps\nimport tensorboardX\nimport os\nimport math\nfrom tqdm import tqdm\n\n# Training settings\nparser = argparse.ArgumentParser(description='PyTorch ImageNet Example',\n                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)\nparser.add_argument('--train-dir', default=os.path.expanduser('~/imagenet/train'),\n                    help='path to training data')\nparser.add_argument('--val-dir', default=os.path.expanduser('~/imagenet/validation'),\n                    help='path to validation data')\nparser.add_argument('--log-dir', default='./logs',\n                    help='tensorboard log directory')\nparser.add_argument('--checkpoint-format', default='./checkpoint-{epoch}.pth.tar',\n                    help='checkpoint file format')\nparser.add_argument('--fp16-pushpull', action='store_true', default=False,\n                    help='use fp16 compression during pushpull')\nparser.add_argument('--batches-per-pushpull', type=int, default=1,\n                    help='number of batches processed locally before '\n                         'executing pushpull across workers; it multiplies '\n                         'total batch size.')\n\n# Default settings from https://arxiv.org/abs/1706.02677.\nparser.add_argument('--batch-size', type=int, default=32,\n                    help='input batch size for training')\nparser.add_argument('--val-batch-size', type=int, default=32,\n                    help='input batch size for validation')\nparser.add_argument('--epochs', type=int, default=90,\n                    help='number of epochs to train')\nparser.add_argument('--base-lr', type=float, default=0.0125,\n                    help='learning rate for a single GPU')\nparser.add_argument('--warmup-epochs', type=float, default=5,\n                    help='number of warmup epochs')\nparser.add_argument('--momentum', type=float, default=0.9,\n                    help='SGD momentum')\nparser.add_argument('--wd', type=float, default=0.00005,\n                    help='weight decay')\n\nparser.add_argument('--no-cuda', action='store_true', default=False,\n                    help='disables CUDA training')\nparser.add_argument('--seed', type=int, default=42,\n                    help='random seed')\n\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\n\npushpull_batch_size = args.batch_size * args.batches_per_pushpull\n\nbps.init()\ntorch.manual_seed(args.seed)\n\nif args.cuda:\n    # BytePS: pin GPU to local rank.\n    torch.cuda.set_device(bps.local_rank())\n    torch.cuda.manual_seed(args.seed)\n\ncudnn.benchmark = True\n\n# If set > 0, will resume training from a given checkpoint.\nresume_from_epoch = 0\nfor try_epoch in range(args.epochs, 0, -1):\n    if os.path.exists(args.checkpoint_format.format(epoch=try_epoch)):\n        resume_from_epoch = try_epoch\n        break\n\n# BytePS: broadcast resume_from_epoch from rank 0 (which will have\n# checkpoints) to other ranks.\n#resume_from_epoch = bps.broadcast(torch.tensor(resume_from_epoch), root_rank=0,\n#                                  name='resume_from_epoch').item()\n\n# BytePS: print logs on the first worker.\nverbose = 1 if bps.rank() == 0 else 0\n\n# BytePS: write TensorBoard logs on first worker.\nlog_writer = tensorboardX.SummaryWriter(args.log_dir) if bps.rank() == 0 else None\n\n\nkwargs = {'num_workers': 4, 'pin_memory': True} if args.cuda else {}\ntrain_dataset = \\\n    datasets.ImageFolder(args.train_dir,\n                         transform=transforms.Compose([\n                             transforms.RandomResizedCrop(224),\n                             transforms.RandomHorizontalFlip(),\n                             transforms.ToTensor(),\n                             transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                                  std=[0.229, 0.224, 0.225])\n                         ]))\n# BytePS: use DistributedSampler to partition data among workers. Manually specify\n# `num_replicas=bps.size()` and `rank=bps.rank()`.\ntrain_sampler = torch.utils.data.distributed.DistributedSampler(\n    train_dataset, num_replicas=bps.size(), rank=bps.rank())\ntrain_loader = torch.utils.data.DataLoader(\n    train_dataset, batch_size=pushpull_batch_size,\n    sampler=train_sampler, **kwargs)\n\nval_dataset = \\\n    datasets.ImageFolder(args.val_dir,\n                         transform=transforms.Compose([\n                             transforms.Resize(256),\n                             transforms.CenterCrop(224),\n                             transforms.ToTensor(),\n                             transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                                  std=[0.229, 0.224, 0.225])\n                         ]))\nval_sampler = torch.utils.data.distributed.DistributedSampler(\n    val_dataset, num_replicas=bps.size(), rank=bps.rank())\nval_loader = torch.utils.data.DataLoader(val_dataset, batch_size=args.val_batch_size,\n                                         sampler=val_sampler, **kwargs)\n\n\n# Set up standard ResNet-50 model.\nmodel = models.resnet50()\n\nif args.cuda:\n    # Move model to GPU.\n    model.cuda()\n\n# BytePS: scale learning rate by the number of GPUs.\n# Gradient Accumulation: scale learning rate by batches_per_pushpull\noptimizer = optim.SGD(model.parameters(),\n                      lr=(args.base_lr *\n                          args.batches_per_pushpull * bps.size()),\n                      momentum=args.momentum, weight_decay=args.wd)\n\n# BytePS: (optional) compression algorithm.\ncompression = bps.Compression.fp16 if args.fp16_pushpull else bps.Compression.none\n\n# BytePS: wrap optimizer with DistributedOptimizer.\noptimizer = bps.DistributedOptimizer(\n    optimizer, named_parameters=model.named_parameters(),\n    compression=compression,\n    backward_passes_per_step=args.batches_per_pushpull)\n\n# Restore from a previous checkpoint, if initial_epoch is specified.\n# BytePS: restore on the first worker which will broadcast weights to other workers.\nif resume_from_epoch > 0 and bps.rank() == 0:\n    filepath = args.checkpoint_format.format(epoch=resume_from_epoch)\n    checkpoint = torch.load(filepath)\n    model.load_state_dict(checkpoint['model'])\n    optimizer.load_state_dict(checkpoint['optimizer'])\n\n# BytePS: broadcast parameters & optimizer state.\nbps.broadcast_parameters(model.state_dict(), root_rank=0)\nbps.broadcast_optimizer_state(optimizer, root_rank=0)\n\ndef train(epoch):\n    model.train()\n    train_sampler.set_epoch(epoch)\n    train_loss = Metric('train_loss')\n    train_accuracy = Metric('train_accuracy')\n\n    with tqdm(total=len(train_loader),\n              desc='Train Epoch     #{}'.format(epoch + 1),\n              disable=not verbose) as t:\n        for batch_idx, (data, target) in enumerate(train_loader):\n            adjust_learning_rate(epoch, batch_idx)\n\n            if args.cuda:\n                data, target = data.cuda(), target.cuda()\n            optimizer.zero_grad()\n            # Split data into sub-batches of size batch_size\n            for i in range(0, len(data), args.batch_size):\n                data_batch = data[i:i + args.batch_size]\n                target_batch = target[i:i + args.batch_size]\n                output = model(data_batch)\n                train_accuracy.update(accuracy(output, target_batch))\n                loss = F.cross_entropy(output, target_batch)\n                train_loss.update(loss.item())\n                # Average gradients among sub-batches\n                loss.div_(math.ceil(float(len(data)) / args.batch_size))\n                loss.backward()\n            # Gradient is applied across all ranks\n            optimizer.step()\n            t.set_postfix({'loss': train_loss.avg.item(),\n                           'accuracy': 100. * train_accuracy.avg.item()})\n            t.update(1)\n\n    if log_writer:\n        log_writer.add_scalar('train/loss', train_loss.avg, epoch)\n        log_writer.add_scalar('train/accuracy', train_accuracy.avg, epoch)\n\n\ndef validate(epoch):\n    model.eval()\n    val_loss = Metric('val_loss')\n    val_accuracy = Metric('val_accuracy')\n\n    with tqdm(total=len(val_loader),\n              desc='Validate Epoch  #{}'.format(epoch + 1),\n              disable=not verbose) as t:\n        with torch.no_grad():\n            for data, target in val_loader:\n                if args.cuda:\n                    data, target = data.cuda(), target.cuda()\n                output = model(data)\n\n                val_loss.update(F.cross_entropy(output, target))\n                val_accuracy.update(accuracy(output, target))\n                t.set_postfix({'loss': val_loss.avg.item(),\n                               'accuracy': 100. * val_accuracy.avg.item()})\n                t.update(1)\n\n    if log_writer:\n        log_writer.add_scalar('val/loss', val_loss.avg, epoch)\n        log_writer.add_scalar('val/accuracy', val_accuracy.avg, epoch)\n\n\n# BytePS: using `lr = base_lr * bps.size()` from the very beginning leads to worse final\n# accuracy. Scale the learning rate `lr = base_lr` ---> `lr = base_lr * bps.size()` during\n# the first five epochs. See https://arxiv.org/abs/1706.02677 for details.\n# After the warmup reduce learning rate by 10 on the 30th, 60th and 80th epochs.\ndef adjust_learning_rate(epoch, batch_idx):\n    if epoch < args.warmup_epochs:\n        epoch += float(batch_idx + 1) / len(train_loader)\n        lr_adj = 1. / bps.size() * (epoch * (bps.size() - 1) / args.warmup_epochs + 1)\n    elif epoch < 30:\n        lr_adj = 1.\n    elif epoch < 60:\n        lr_adj = 1e-1\n    elif epoch < 80:\n        lr_adj = 1e-2\n    else:\n        lr_adj = 1e-3\n    for param_group in optimizer.param_groups:\n        param_group['lr'] = args.base_lr * bps.size() * args.batches_per_pushpull * lr_adj\n\n\ndef accuracy(output, target):\n    # get the index of the max log-probability\n    pred = output.max(1, keepdim=True)[1]\n    return pred.eq(target.view_as(pred)).float().mean()\n\n\ndef save_checkpoint(epoch):\n    if bps.rank() == 0:\n        filepath = args.checkpoint_format.format(epoch=epoch + 1)\n        state = {\n            'model': model.state_dict(),\n            'optimizer': optimizer.state_dict(),\n        }\n        torch.save(state, filepath)\n\n\n# BytePS: average metrics from distributed training.\nclass Metric(object):\n    def __init__(self, name):\n        self.name = name\n        self.sum = torch.tensor(0.)\n        self.n = torch.tensor(0.)\n\n    def update(self, val):\n        if not isinstance(val, torch.Tensor):\n            val = torch.tensor(val)\n        self.sum += val\n        self.n += 1\n\n    @property\n    def avg(self):\n        return self.sum / self.n\n\n\nfor epoch in range(resume_from_epoch, args.epochs):\n    train(epoch)\n    validate(epoch)\n    save_checkpoint(epoch)"""
example/pytorch/train_imagenet_resnet_byteps_ddp.py,0,"b'# this example is adapted from the official PyTorch example: https://github.com/pytorch/examples/blob/69d2798ec7fb4f87b320a1848203da5346675b95/imagenet/main.py\n# example usage:\n#\n#  bpslaunch python train_imagenet_resnet_byteps_ddp.py -a resnet18 --dist-url \'tcp://127.0.0.1:12345\' --dist-backend \'nccl\' --multiprocessing-distributed --world-size 1 --rank 0 /path/to/imagenet/training/data/\n#\n# see this page for a more detailed explanation: https://github.com/pytorch/examples/tree/69d2798ec7fb4f87b320a1848203da5346675b95/imagenet\n\nimport argparse\nimport os\nimport random\nimport shutil\nimport time\nimport warnings\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.distributed as dist\nimport torch.optim\nimport torch.multiprocessing as mp\nimport torch.utils.data\nimport torch.utils.data.distributed\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torchvision.models as models\nfrom byteps.torch.parallel import DistributedDataParallel as DDP\nimport byteps.torch as bps\n\nmodel_names = sorted(name for name in models.__dict__\n    if name.islower() and not name.startswith(""__"")\n    and callable(models.__dict__[name]))\n\nparser = argparse.ArgumentParser(description=\'PyTorch ImageNet Training\')\nparser.add_argument(\'data\', metavar=\'DIR\',\n                    help=\'path to dataset\')\nparser.add_argument(\'-a\', \'--arch\', metavar=\'ARCH\', default=\'resnet18\',\n                    choices=model_names,\n                    help=\'model architecture: \' +\n                        \' | \'.join(model_names) +\n                        \' (default: resnet18)\')\nparser.add_argument(\'-j\', \'--workers\', default=4, type=int, metavar=\'N\',\n                    help=\'number of data loading workers (default: 4)\')\nparser.add_argument(\'--epochs\', default=90, type=int, metavar=\'N\',\n                    help=\'number of total epochs to run\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\',\n                    help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'-b\', \'--batch-size\', default=256, type=int,\n                    metavar=\'N\',\n                    help=\'mini-batch size (default: 256), this is the total \'\n                         \'batch size of all GPUs on the current node when \'\n                         \'using Data Parallel or Distributed Data Parallel\')\nparser.add_argument(\'--lr\', \'--learning-rate\', default=0.1, type=float,\n                    metavar=\'LR\', help=\'initial learning rate\', dest=\'lr\')\nparser.add_argument(\'--momentum\', default=0.9, type=float, metavar=\'M\',\n                    help=\'momentum\')\nparser.add_argument(\'--wd\', \'--weight-decay\', default=1e-4, type=float,\n                    metavar=\'W\', help=\'weight decay (default: 1e-4)\',\n                    dest=\'weight_decay\')\nparser.add_argument(\'-p\', \'--print-freq\', default=10, type=int,\n                    metavar=\'N\', help=\'print frequency (default: 10)\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'-e\', \'--evaluate\', dest=\'evaluate\', action=\'store_true\',\n                    help=\'evaluate model on validation set\')\nparser.add_argument(\'--pretrained\', dest=\'pretrained\', action=\'store_true\',\n                    help=\'use pre-trained model\')\nparser.add_argument(\'--world-size\', default=-1, type=int,\n                    help=\'number of nodes for distributed training\')\nparser.add_argument(\'--rank\', default=-1, type=int,\n                    help=\'node rank for distributed training\')\nparser.add_argument(\'--dist-url\', default=\'tcp://224.66.41.62:23456\', type=str,\n                    help=\'url used to set up distributed training\')\nparser.add_argument(\'--dist-backend\', default=\'nccl\', type=str,\n                    help=\'distributed backend\')\nparser.add_argument(\'--seed\', default=None, type=int,\n                    help=\'seed for initializing training. \')\nparser.add_argument(\'--gpu\', default=None, type=int,\n                    help=\'GPU id to use.\')\nparser.add_argument(\'--print_freq\', default=10, type=int,\n                    help=\'print frequency\')\nparser.add_argument(\'--no_broadcast_buffers\', dest=\'broadcast_buffers\',\n                    action=\'store_false\', help=\'broadcast_buffers\')\nparser.add_argument(\'--multiprocessing-distributed\', action=\'store_true\',\n                    help=\'Use multi-processing distributed training to launch \'\n                         \'N processes per node, which has N GPUs. This is the \'\n                         \'fastest way to use PyTorch for either single node or \'\n                         \'multi node data parallel training\')\n\nbest_acc1 = 0\n\n\ndef main():\n    args = parser.parse_args()\n    bps.init()\n\n    if args.seed is not None:\n        random.seed(args.seed)\n        torch.manual_seed(args.seed)\n        cudnn.deterministic = True\n        warnings.warn(\'You have chosen to seed training. \'\n                      \'This will turn on the CUDNN deterministic setting, \'\n                      \'which can slow down your training considerably! \'\n                      \'You may see unexpected behavior when restarting \'\n                      \'from checkpoints.\')\n\n    if args.gpu is not None:\n        warnings.warn(\'You have chosen a specific GPU. This will completely \'\n                      \'disable data parallelism.\')\n\n    if args.dist_url == ""env://"" and args.world_size == -1:\n        args.world_size = int(os.environ[""WORLD_SIZE""])\n\n    args.distributed = args.world_size > 1 or args.multiprocessing_distributed\n\n    ngpus_per_node = torch.cuda.device_count()\n    if args.multiprocessing_distributed:\n        # Since we have ngpus_per_node processes per node, the total world_size\n        # needs to be adjusted accordingly\n        args.world_size = ngpus_per_node * args.world_size\n        # Use torch.multiprocessing.spawn to launch distributed processes: the\n        # main_worker process function\n        args.gpu = bps.local_rank()\n        main_worker(args.gpu, ngpus_per_node, args)\n    else:\n        # Simply call main_worker function\n        main_worker(args.gpu, ngpus_per_node, args)\n\n\ndef main_worker(gpu, ngpus_per_node, args):\n    global best_acc1\n    args.gpu = gpu\n\n    if args.gpu is not None:\n        print(""Use GPU: {} for training"".format(args.gpu))\n\n    if args.distributed:\n        if args.dist_url == ""env://"" and args.rank == -1:\n            args.rank = int(os.environ[""RANK""])\n        if args.multiprocessing_distributed:\n            # For multiprocessing distributed training, rank needs to be the\n            # global rank among all the processes\n            args.rank = args.rank * ngpus_per_node + gpu\n\n    # create model\n    if args.pretrained:\n        print(""=> using pre-trained model \'{}\'"".format(args.arch))\n        model = models.__dict__[args.arch](pretrained=True)\n    else:\n        print(""=> creating model \'{}\'"".format(args.arch))\n        model = models.__dict__[args.arch]()\n\n    if args.distributed:\n        # For multiprocessing distributed, DistributedDataParallel constructor\n        # should always set the single device scope, otherwise,\n        # DistributedDataParallel will use all available devices.\n        if args.gpu is not None:\n            torch.cuda.set_device(args.gpu)\n            model.cuda(args.gpu)\n            # When using a single GPU per process and per\n            # DistributedDataParallel, we need to divide the batch size\n            # ourselves based on the total number of GPUs we have\n            args.batch_size = int(args.batch_size / ngpus_per_node)\n            args.workers = int((args.workers + ngpus_per_node - 1) / ngpus_per_node)\n            model = DDP(model, device_ids=[args.gpu], broadcast_buffers=args.broadcast_buffers)\n\n    # define loss function (criterion) and optimizer\n    criterion = nn.CrossEntropyLoss().cuda(args.gpu)\n\n    optimizer = torch.optim.SGD(model.parameters(), args.lr,\n                                momentum=args.momentum,\n                                weight_decay=args.weight_decay)\n\n    # optionally resume from a checkpoint\n    if args.resume:\n        if os.path.isfile(args.resume):\n            print(""=> loading checkpoint \'{}\'"".format(args.resume))\n            if args.gpu is None:\n                checkpoint = torch.load(args.resume)\n            else:\n                # Map model to be loaded to specified single gpu.\n                loc = \'cuda:{}\'.format(args.gpu)\n                checkpoint = torch.load(args.resume, map_location=loc)\n            args.start_epoch = checkpoint[\'epoch\']\n            best_acc1 = checkpoint[\'best_acc1\']\n            if args.gpu is not None:\n                # best_acc1 may be from a checkpoint from a different GPU\n                best_acc1 = best_acc1.to(args.gpu)\n            model.load_state_dict(checkpoint[\'state_dict\'])\n            optimizer.load_state_dict(checkpoint[\'optimizer\'])\n            print(""=> loaded checkpoint \'{}\' (epoch {})""\n                  .format(args.resume, checkpoint[\'epoch\']))\n        else:\n            print(""=> no checkpoint found at \'{}\'"".format(args.resume))\n\n    cudnn.benchmark = True\n\n    # Data loading code\n    traindir = os.path.join(args.data, \'train\')\n    valdir = os.path.join(args.data, \'val\')\n    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])\n\n    train_dataset = datasets.ImageFolder(\n        traindir,\n        transforms.Compose([\n            transforms.RandomResizedCrop(224),\n            transforms.RandomHorizontalFlip(),\n            transforms.ToTensor(),\n            normalize,\n        ]))\n\n    if args.distributed:\n        train_sampler = torch.utils.data.distributed.DistributedSampler(\n                train_dataset, num_replicas=bps.size(), rank=bps.rank())\n    else:\n        train_sampler = None\n\n    train_loader = torch.utils.data.DataLoader(\n        train_dataset, batch_size=args.batch_size, shuffle=(train_sampler is None),\n        num_workers=args.workers, pin_memory=True, sampler=train_sampler)\n\n    val_loader = torch.utils.data.DataLoader(\n        datasets.ImageFolder(valdir, transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            normalize,\n        ])),\n        batch_size=args.batch_size, shuffle=False,\n        num_workers=args.workers, pin_memory=True)\n\n    if args.evaluate:\n        validate(val_loader, model, criterion, args)\n        return\n\n    for epoch in range(args.start_epoch, args.epochs):\n        if args.distributed:\n            train_sampler.set_epoch(epoch)\n        adjust_learning_rate(optimizer, epoch, args)\n\n        # train for one epoch\n        train(train_loader, model, criterion, optimizer, epoch, args)\n\n        # evaluate on validation set\n        acc1 = validate(val_loader, model, criterion, args)\n\n        # remember best acc@1 and save checkpoint\n        is_best = acc1 > best_acc1\n        best_acc1 = max(acc1, best_acc1)\n\n        if not args.multiprocessing_distributed or (args.multiprocessing_distributed\n                and args.rank % ngpus_per_node == 0):\n            save_checkpoint({\n                \'epoch\': epoch + 1,\n                \'arch\': args.arch,\n                \'state_dict\': model.state_dict(),\n                \'best_acc1\': best_acc1,\n                \'optimizer\' : optimizer.state_dict(),\n            }, is_best)\n\n\ndef train(train_loader, model, criterion, optimizer, epoch, args):\n    batch_time = AverageMeter(\'Time\', \':6.3f\')\n    data_time = AverageMeter(\'Data\', \':6.3f\')\n    losses = AverageMeter(\'Loss\', \':.4e\')\n    top1 = AverageMeter(\'Acc@1\', \':6.2f\')\n    top5 = AverageMeter(\'Acc@5\', \':6.2f\')\n    progress = ProgressMeter(\n        len(train_loader),\n        [batch_time, data_time, losses, top1, top5],\n        prefix=""Epoch: [{}]"".format(epoch))\n\n    # switch to train mode\n    model.train()\n\n    end = time.time()\n    for i, (images, target) in enumerate(train_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        if args.gpu is not None:\n            images = images.cuda(args.gpu, non_blocking=True)\n        target = target.cuda(args.gpu, non_blocking=True)\n\n        # compute output\n        output = model(images)\n        loss = criterion(output, target)\n\n        # measure accuracy and record loss\n        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n        losses.update(loss.item(), images.size(0))\n        top1.update(acc1[0], images.size(0))\n        top5.update(acc5[0], images.size(0))\n\n        # compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n#        model.synchronize()\n\n        optimizer.step()\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            progress.display(i)\n\n\ndef validate(val_loader, model, criterion, args):\n    batch_time = AverageMeter(\'Time\', \':6.3f\')\n    losses = AverageMeter(\'Loss\', \':.4e\')\n    top1 = AverageMeter(\'Acc@1\', \':6.2f\')\n    top5 = AverageMeter(\'Acc@5\', \':6.2f\')\n    progress = ProgressMeter(\n        len(val_loader),\n        [batch_time, losses, top1, top5],\n        prefix=\'Test: \')\n\n    # switch to evaluate mode\n    model.eval()\n\n    with torch.no_grad():\n        end = time.time()\n        for i, (images, target) in enumerate(val_loader):\n            if args.gpu is not None:\n                images = images.cuda(args.gpu, non_blocking=True)\n            target = target.cuda(args.gpu, non_blocking=True)\n\n            # compute output\n            output = model(images)\n            loss = criterion(output, target)\n\n            # measure accuracy and record loss\n            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n            losses.update(loss.item(), images.size(0))\n            top1.update(acc1[0], images.size(0))\n            top5.update(acc5[0], images.size(0))\n\n            # measure elapsed time\n            batch_time.update(time.time() - end)\n            end = time.time()\n\n            if i % args.print_freq == 0:\n                progress.display(i)\n\n        # TODO: this should also be done with the ProgressMeter\n        print(\' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}\'\n              .format(top1=top1, top5=top5))\n\n    return top1.avg\n\n\ndef save_checkpoint(state, is_best, filename=\'checkpoint.pth.tar\'):\n    torch.save(state, filename)\n    if is_best:\n        shutil.copyfile(filename, \'model_best.pth.tar\')\n\n\nclass AverageMeter(object):\n    """"""Computes and stores the average and current value""""""\n    def __init__(self, name, fmt=\':f\'):\n        self.name = name\n        self.fmt = fmt\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n    def __str__(self):\n        fmtstr = \'{name} {val\' + self.fmt + \'} ({avg\' + self.fmt + \'})\'\n        return fmtstr.format(**self.__dict__)\n\n\nclass ProgressMeter(object):\n    def __init__(self, num_batches, meters, prefix=""""):\n        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n        self.meters = meters\n        self.prefix = prefix\n\n    def display(self, batch):\n        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n        entries += [str(meter) for meter in self.meters]\n        print(\'\\t\'.join(entries))\n\n    def _get_batch_fmtstr(self, num_batches):\n        num_digits = len(str(num_batches // 1))\n        fmt = \'{:\' + str(num_digits) + \'d}\'\n        return \'[\' + fmt + \'/\' + fmt.format(num_batches) + \']\'\n\n\ndef adjust_learning_rate(optimizer, epoch, args):\n    """"""Sets the learning rate to the initial LR decayed by 10 every 30 epochs""""""\n    lr = args.lr * (0.1 ** (epoch // 30))\n    for param_group in optimizer.param_groups:\n        param_group[\'lr\'] = lr\n\n\ndef accuracy(output, target, topk=(1,)):\n    """"""Computes the accuracy over the k top predictions for the specified values of k""""""\n    with torch.no_grad():\n        maxk = max(topk)\n        batch_size = target.size(0)\n\n        _, pred = output.topk(maxk, 1, True, True)\n        pred = pred.t()\n        correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n        res = []\n        for k in topk:\n            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n            res.append(correct_k.mul_(100.0 / batch_size))\n        return res\n\n\nif __name__ == \'__main__\':\n    main()\n'"
example/pytorch/train_mnist_byteps.py,0,"b""from __future__ import print_function\nimport argparse\nimport os\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nimport torch.utils.data.distributed\nimport byteps.torch as bps\n\n# Training settings\nparser = argparse.ArgumentParser(description='PyTorch MNIST Example')\nparser.add_argument('--batch-size', type=int, default=64, metavar='N',\n                    help='input batch size for training (default: 64)')\nparser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n                    help='input batch size for testing (default: 1000)')\nparser.add_argument('--epochs', type=int, default=100, metavar='N',\n                    help='number of epochs to train (default: 100)')\nparser.add_argument('--lr', type=float, default=0.01, metavar='LR',\n                    help='learning rate (default: 0.01)')\nparser.add_argument('--momentum', type=float, default=0.5, metavar='M',\n                    help='SGD momentum (default: 0.5)')\nparser.add_argument('--no-cuda', action='store_true', default=False,\n                    help='disables CUDA training')\nparser.add_argument('--seed', type=int, default=42, metavar='S',\n                    help='random seed (default: 42)')\nparser.add_argument('--log-interval', type=int, default=10, metavar='N',\n                    help='how many batches to wait before logging training status')\nparser.add_argument('--fp16-pushpull', action='store_true', default=False,\n                    help='use fp16 compression during pushpull')\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\n\n# BytePS: initialize library.\nbps.init()\ntorch.manual_seed(args.seed)\n\nif args.cuda:\n    # BytePS: pin GPU to local rank.\n    torch.cuda.set_device(bps.local_rank())\n    torch.cuda.manual_seed(args.seed)\n\n\nkwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}\ntrain_dataset = \\\n    datasets.MNIST('data-%d' % bps.rank(), train=True, download=True,\n                   transform=transforms.Compose([\n                       transforms.ToTensor(),\n                       transforms.Normalize((0.1307,), (0.3081,))\n                   ]))\n# BytePS: use DistributedSampler to partition the training data.\ntrain_sampler = torch.utils.data.distributed.DistributedSampler(\n    train_dataset, num_replicas=bps.size(), rank=bps.rank())\ntrain_loader = torch.utils.data.DataLoader(\n    train_dataset, batch_size=args.batch_size, sampler=train_sampler, **kwargs)\n\ntest_dataset = \\\n    datasets.MNIST('data-%d' % bps.rank(), train=False, transform=transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.1307,), (0.3081,))\n    ]))\n# BytePS: use DistributedSampler to partition the test data.\ntest_sampler = torch.utils.data.distributed.DistributedSampler(\n    test_dataset, num_replicas=bps.size(), rank=bps.rank())\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.test_batch_size,\n                                          sampler=test_sampler, **kwargs)\n\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(320, 50)\n        self.fc2 = nn.Linear(50, 10)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n        x = x.view(-1, 320)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.log_softmax(x)\n\n\nmodel = Net()\n\nif args.cuda:\n    # Move model to GPU.\n    model.cuda()\n\n# BytePS: scale learning rate by the number of GPUs.\noptimizer = optim.SGD(model.parameters(), lr=args.lr * bps.size(),\n                      momentum=args.momentum)\n\n# BytePS: (optional) compression algorithm.\ncompression = bps.Compression.fp16 if args.fp16_pushpull else bps.Compression.none\n\n# BytePS: wrap optimizer with DistributedOptimizer.\noptimizer = bps.DistributedOptimizer(optimizer,\n                                     named_parameters=model.named_parameters(),\n                                     compression=compression)\n\n\n# BytePS: broadcast parameters.\nbps.broadcast_parameters(model.state_dict(), root_rank=0)\nbps.broadcast_optimizer_state(optimizer, root_rank=0)\n\ndef train(epoch):\n    model.train()\n    # BytePS: set epoch to sampler for shuffling.\n    train_sampler.set_epoch(epoch)\n    for batch_idx, (data, target) in enumerate(train_loader):\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        optimizer.zero_grad()\n        output = model(data)\n        loss = F.nll_loss(output, target)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % args.log_interval == 0:\n            # BytePS: use train_sampler to determine the number of examples in\n            # this worker's partition.\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * len(data), len(train_sampler),\n                100. * batch_idx / len(train_loader), loss.item()))\n\n\ndef metric_average(val, name):\n    tensor = torch.tensor(val)\n    avg_tensor = bps.push_pull(tensor, name=name)\n    return avg_tensor.item()\n\n\ndef test():\n    model.eval()\n    test_loss = 0.\n    test_accuracy = 0.\n    for data, target in test_loader:\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        output = model(data)\n        # sum up batch loss\n        test_loss += F.nll_loss(output, target, size_average=False).item()\n        # get the index of the max log-probability\n        pred = output.data.max(1, keepdim=True)[1]\n        test_accuracy += pred.eq(target.data.view_as(pred)).cpu().float().sum()\n\n    # BytePS: use test_sampler to determine the number of examples in\n    # this worker's partition.\n    test_loss /= len(test_sampler)\n    test_accuracy /= len(test_sampler)\n\n    # BytePS: average metric values across workers.\n    test_loss = metric_average(test_loss, 'avg_loss')\n    test_accuracy = metric_average(test_accuracy, 'avg_accuracy')\n\n    # BytePS: print output only on first rank.\n    if bps.rank() == 0:\n        print('\\nTest set: Average loss: {:.4f}, Accuracy: {:.2f}%\\n'.format(\n            test_loss, 100. * test_accuracy))\n\n\nfor epoch in range(1, args.epochs + 1):\n    train(epoch)\n    test()\n"""
example/tensorflow/synthetic_benchmark.py,10,"b'\nfrom __future__ import absolute_import, division, print_function\n\nimport argparse\nimport os, sys\nimport numpy as np\nimport timeit\n\nimport byteps.tensorflow as bps\nfrom tensorflow.keras import applications\nimport tensorflow as tf\n\n# Benchmark settings\nparser = argparse.ArgumentParser(description=\'TensorFlow Synthetic Benchmark\',\n                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)\nparser.add_argument(\'--fp16-pushpull\', action=\'store_true\', default=False,\n                    help=\'use fp16 compression during pushpull\')\n\nparser.add_argument(\'--model\', type=str, default=\'ResNet50\',\n                    help=\'model to benchmark\')\nparser.add_argument(\'--batch-size\', type=int, default=32,\n                    help=\'input batch size\')\n\nparser.add_argument(\'--num-warmup-batches\', type=int, default=10,\n                    help=\'number of warm-up batches that don\\\'t count towards benchmark\')\nparser.add_argument(\'--num-batches-per-iter\', type=int, default=10,\n                    help=\'number of batches per benchmark iteration\')\nparser.add_argument(\'--num-iters\', type=int, default=10,\n                    help=\'number of benchmark iterations\')\n\nparser.add_argument(\'--eager\', action=\'store_true\', default=False,\n                    help=\'enables eager execution\')\nparser.add_argument(\'--no-cuda\', action=\'store_true\', default=False,\n                    help=\'disables CUDA training\')\n\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda\n\nbps.init()\n\n# BytePS: pin GPU to be used to process local rank (one GPU per process)\nconfig = tf.ConfigProto()\nif args.cuda:\n    config.gpu_options.allow_growth = True\n    config.gpu_options.visible_device_list = str(bps.local_rank())\nelse:\n    os.environ[""CUDA_VISIBLE_DEVICES""] = ""-1""\n    config.gpu_options.allow_growth = False\n    config.gpu_options.visible_device_list = \'\'\n\nif args.eager:\n    tf.enable_eager_execution(config)\n\n# Set up standard model.\n# Check https://github.com/keras-team/keras-applications for all supported models, e.g., ResNet50, VGG16\nmodel = getattr(applications, args.model)(weights=None)\n\nopt = tf.train.GradientDescentOptimizer(0.01)\n\n# BytePS: (optional) compression algorithm.\ncompression = bps.Compression.fp16 if args.fp16_pushpull else bps.Compression.none\n\n# BytePS: wrap optimizer with DistributedOptimizer.\nopt = bps.DistributedOptimizer(opt, compression=compression)\n\ninit = tf.global_variables_initializer()\nbcast_op = bps.broadcast_global_variables(0)\n\ndata = tf.random_uniform([args.batch_size, 224, 224, 3])\ntarget = tf.random_uniform([args.batch_size, 1], minval=0, maxval=999, dtype=tf.int64)\n\n\ndef loss_function():\n    logits = model(data, training=True)\n    return tf.losses.sparse_softmax_cross_entropy(target, logits)\n\n\ndef log(s, nl=True):\n    if bps.rank() != 0:\n        return\n    print(s, end=\'\\n\' if nl else \'\')\n    sys.stdout.flush()\n\nlog(\'Model: %s\' % args.model)\nlog(\'Batch size: %d\' % args.batch_size)\ndevice = \'GPU\' if args.cuda else \'CPU\'\nlog(\'Number of %ss: %d\' % (device, bps.size()))\n\n\ndef run(benchmark_step):\n    # Warm-up\n    log(\'Running warmup...\')\n    timeit.timeit(benchmark_step, number=args.num_warmup_batches)\n\n    # Benchmark\n    log(\'Running benchmark...\')\n    img_secs = []\n    for x in range(args.num_iters):\n        time = timeit.timeit(benchmark_step, number=args.num_batches_per_iter)\n        img_sec = args.batch_size * args.num_batches_per_iter / time\n        log(\'Iter #%d: %.1f img/sec per %s\' % (x, img_sec, device))\n        img_secs.append(img_sec)\n\n    # Results\n    img_sec_mean = np.mean(img_secs)\n    img_sec_conf = 1.96 * np.std(img_secs)\n    log(\'Img/sec per %s: %.1f +-%.1f\' % (device, img_sec_mean, img_sec_conf))\n    log(\'Total img/sec on %d %s(s): %.1f +-%.1f\' %\n        (bps.size(), device, bps.size() * img_sec_mean, bps.size() * img_sec_conf))\n\n\nif tf.executing_eagerly():\n    with tf.device(device):\n        run(lambda: opt.minimize(loss_function, var_list=model.trainable_variables))\nelse:\n    with tf.Session(config=config) as session:\n        init.run()\n        bcast_op.run()\n\n        loss = loss_function()\n        train_opt = opt.minimize(loss)\n        run(lambda: session.run(train_opt))'"
example/tensorflow/synthetic_benchmark_tf2.py,10,"b'from __future__ import absolute_import, division, print_function\n\nimport argparse\nimport os\nimport numpy as np\nimport timeit\n\nimport tensorflow as tf\nimport byteps.tensorflow as bps\nfrom tensorflow.keras import applications\n\n# Benchmark settings\nparser = argparse.ArgumentParser(description=\'TensorFlow Synthetic Benchmark\',\n                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)\nparser.add_argument(\'--fp16-allreduce\', action=\'store_true\', default=False,\n                    help=\'use fp16 compression during allreduce\')\n\nparser.add_argument(\'--model\', type=str, default=\'ResNet50\',\n                    help=\'model to benchmark\')\nparser.add_argument(\'--batch-size\', type=int, default=32,\n                    help=\'input batch size\')\n\nparser.add_argument(\'--num-warmup-batches\', type=int, default=10,\n                    help=\'number of warm-up batches that don\\\'t count towards benchmark\')\nparser.add_argument(\'--num-batches-per-iter\', type=int, default=10,\n                    help=\'number of batches per benchmark iteration\')\nparser.add_argument(\'--num-iters\', type=int, default=10,\n                    help=\'number of benchmark iterations\')\n\nparser.add_argument(\'--no-cuda\', action=\'store_true\', default=False,\n                    help=\'disables CUDA training\')\n\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda\n\nbps.init()\n\n# pin GPU to be used to process local rank (one GPU per process)\nif args.cuda:\n    gpus = tf.config.experimental.list_physical_devices(\'GPU\')\n    for gpu in gpus:\n        tf.config.experimental.set_memory_growth(gpu, True)\n    if gpus:\n        tf.config.experimental.set_visible_devices(gpus[bps.local_rank()], \'GPU\')\nelse:\n    os.environ[""CUDA_VISIBLE_DEVICES""] = ""-1""\n\n# Set up standard model.\nmodel = getattr(applications, args.model)(weights=None)\nopt = tf.optimizers.SGD(0.01)\n\ndata = tf.random.uniform([args.batch_size, 224, 224, 3])\ntarget = tf.random.uniform([args.batch_size, 1], minval=0, maxval=999, dtype=tf.int64)\n\n\n@tf.function\ndef benchmark_step(first_batch):\n    # BytePS: (optional) compression algorithm.\n    compression = bps.Compression.fp16 if args.fp16_allreduce else bps.Compression.none\n\n    # BytePS: use DistributedGradientTape\n    with tf.GradientTape() as tape:\n        probs = model(data, training=True)\n        loss = tf.losses.categorical_crossentropy(target, probs)\n\n    # BytePS: add bps Distributed GradientTape.\n    tape = bps.DistributedGradientTape(tape, compression=compression)\n\n    gradients = tape.gradient(loss, model.trainable_variables)\n    opt.apply_gradients(zip(gradients, model.trainable_variables))\n\n    # Broadcast initial variable states from rank 0 to all other processes.\n    # This is necessary to ensure consistent initialization of all workers when\n    # training is started with random weights or restored from a checkpoint.\n    #\n    # Note: broadcast should be done after the first gradient step to ensure optimizer\n    # initialization.\n    if first_batch:\n        bps.broadcast_variables(model.variables, root_rank=0)\n        bps.broadcast_variables(opt.variables(), root_rank=0)\n\n\ndef log(s, nl=True):\n    if bps.rank() != 0:\n        return\n    print(s, end=\'\\n\' if nl else \'\')\n\n\nlog(\'Model: %s\' % args.model)\nlog(\'Batch size: %d\' % args.batch_size)\ndevice = \'GPU\' if args.cuda else \'CPU\'\nlog(\'Number of %ss: %d\' % (device, bps.size()))\n\n\nwith tf.device(device):\n    # Warm-up\n    log(\'Running warmup...\')\n    benchmark_step(first_batch=True)\n    timeit.timeit(lambda: benchmark_step(first_batch=False),\n                  number=args.num_warmup_batches)\n\n    # Benchmark\n    log(\'Running benchmark...\')\n    img_secs = []\n    for x in range(args.num_iters):\n        time = timeit.timeit(lambda: benchmark_step(first_batch=False),\n                             number=args.num_batches_per_iter)\n        img_sec = args.batch_size * args.num_batches_per_iter / time\n        log(\'Iter #%d: %.1f img/sec per %s\' % (x, img_sec, device))\n        img_secs.append(img_sec)\n\n    # Results\n    img_sec_mean = np.mean(img_secs)\n    img_sec_conf = 1.96 * np.std(img_secs)\n    log(\'Img/sec per %s: %.1f +-%.1f\' % (device, img_sec_mean, img_sec_conf))\n    log(\'Total img/sec on %d %s(s): %.1f +-%.1f\' %\n        (bps.size(), device, bps.size() * img_sec_mean, bps.size() * img_sec_conf))\n'"
example/tensorflow/tensorflow2_keras_mnist.py,20,"b'# Copyright 2020 Uber Technologies, Inc. All Rights Reserved.\n# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\nfrom __future__ import absolute_import, division, print_function\n\nimport tensorflow as tf\nimport byteps.tensorflow.keras as bps\n\n# tf.compat.v1.disable_eager_execution()\n\n# byteps: initialize byteps.\nbps.init()\n\n# byteps: pin GPU to be used to process local rank (one GPU per process)\ngpus = tf.config.experimental.list_physical_devices(\'GPU\')\nfor gpu in gpus:\n    tf.config.experimental.set_memory_growth(gpu, True)\nif gpus:\n    tf.config.experimental.set_visible_devices(gpus[bps.local_rank()], \'GPU\')\n\n(mnist_images, mnist_labels), _ = \\\n    tf.keras.datasets.mnist.load_data(path=\'mnist-%d.npz\' % bps.rank())\n\ndataset = tf.data.Dataset.from_tensor_slices(\n    (tf.cast(mnist_images[..., tf.newaxis] / 255.0, tf.float32),\n             tf.cast(mnist_labels, tf.int64))\n)\ndataset = dataset.repeat().shuffle(10000).batch(128)\n\nmnist_model = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(32, [3, 3], activation=\'relu\'),\n    tf.keras.layers.Conv2D(64, [3, 3], activation=\'relu\'),\n    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n    tf.keras.layers.Dropout(0.25),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation=\'relu\'),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(10, activation=\'softmax\')\n])\n\n# byteps: adjust learning rate based on number of GPUs.\nscaled_lr = 0.001 * bps.size()\nopt = tf.optimizers.Adam(scaled_lr)\n\n# byteps: add byteps DistributedOptimizer.\nopt = bps.DistributedOptimizer(opt)\n\n# byteps: Specify `experimental_run_tf_function=False` to ensure TensorFlow\n# uses bps.DistributedOptimizer() to compute gradients.\nmnist_model.compile(loss=tf.losses.SparseCategoricalCrossentropy(),\n                    optimizer=opt,\n                    metrics=[\'accuracy\'],\n                    experimental_run_tf_function=False)\n\ncallbacks = [\n    # byteps: broadcast initial variable states from rank 0 to all other processes.\n    # This is necessary to ensure consistent initialization of all workers when\n    # training is started with random weights or restored from a checkpoint.\n    bps.callbacks.BroadcastGlobalVariablesCallback(0, device=""GPU:0""),\n\n    # byteps: average metrics among workers at the end of every epoch.\n    #\n    # Note: This callback must be in the list before the ReduceLROnPlateau,\n    # TensorBoard or other metrics-based callbacks.\n    bps.callbacks.MetricAverageCallback(device=""GPU:0""),\n\n    # byteps: using `lr = 1.0 * bps.size()` from the very beginning leads to worse final\n    # accuracy. Scale the learning rate `lr = 1.0` ---> `lr = 1.0 * bps.size()` during\n    # the first three epochs. See https://arxiv.org/abs/1706.02677 for details.\n    bps.callbacks.LearningRateWarmupCallback(warmup_epochs=3, initial_lr=scaled_lr, verbose=1),\n]\n\n# byteps: save checkpoints only on worker 0 to prevent other workers from corrupting them.\nif bps.rank() == 0:\n    callbacks.append(tf.keras.callbacks.ModelCheckpoint(\'./checkpoint-{epoch}.h5\'))\n\n# byteps: write logs on worker 0.\nverbose = 1 if bps.rank() == 0 else 0\n\n# Train the model.\n# byteps: adjust number of steps based on number of GPUs.\nmnist_model.fit(dataset, steps_per_epoch=500 // bps.size(), callbacks=callbacks, epochs=24, verbose=verbose)\n'"
example/tensorflow/tensorflow2_mnist.py,21,"b""import tensorflow as tf\nimport byteps.tensorflow as bps\n\nbps.init()\n\n# BytePS: pin GPU to be used to process local rank (one GPU per process)\ngpus = tf.config.experimental.list_physical_devices('GPU')\nfor gpu in gpus:\n    tf.config.experimental.set_memory_growth(gpu, True)\nif gpus:\n    tf.config.experimental.set_visible_devices(gpus[bps.local_rank()], 'GPU')\n\n# Before launching, need to fist download the dataset to ~/.keras/datasets\n(mnist_images, mnist_labels), _ = \\\n    tf.keras.datasets.mnist.load_data(path='mnist-%d.npz' % bps.rank())\n\ndataset = tf.data.Dataset.from_tensor_slices(\n    (tf.cast(mnist_images[..., tf.newaxis] / 255.0, tf.float32),\n             tf.cast(mnist_labels, tf.int64))\n)\ndataset = dataset.repeat().shuffle(10000).batch(128)\n\nmnist_model = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(32, [3, 3], activation='relu'),\n    tf.keras.layers.Conv2D(64, [3, 3], activation='relu'),\n    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n    tf.keras.layers.Dropout(0.25),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\nloss = tf.losses.SparseCategoricalCrossentropy()\n\nopt = tf.optimizers.Adam(0.001 * bps.size())\n\ncheckpoint_dir = './checkpoints'\ncheckpoint = tf.train.Checkpoint(model=mnist_model, optimizer=opt)\n\n\n@tf.function\ndef training_step(images, labels, first_batch):\n    with tf.GradientTape() as tape:\n        probs = mnist_model(images, training=True)\n        loss_value = loss(labels, probs)\n\n    tape = bps.DistributedGradientTape(tape)\n\n    grads = tape.gradient(loss_value, mnist_model.trainable_variables)\n    opt.apply_gradients(zip(grads, mnist_model.trainable_variables))\n\n    # Note: broadcast should be done after the first gradient step to ensure optimizer\n    # initialization.\n    if first_batch:\n        bps.broadcast_variables(mnist_model.variables, root_rank=0)\n        bps.broadcast_variables(opt.variables(), root_rank=0)\n\n    return loss_value\n\n\n# BytePS: adjust number of steps based on number of GPUs.\nfor batch, (images, labels) in enumerate(dataset.take(10000 // bps.size())):\n    loss_value = training_step(images, labels, batch == 0)\n\n    if batch % 10 == 0 and bps.local_rank() == 0:\n        print('Step #%d\\tLoss: %.6f' % (batch, loss_value))\n\nif bps.rank() == 0:\n    checkpoint.save(checkpoint_dir)"""
example/tensorflow/tensorflow_keras_mnist.py,2,"b""from __future__ import absolute_import, division, print_function\nfrom tensorflow import keras\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras import backend as K\nimport math\nimport tensorflow as tf\nimport byteps.keras as bps\n\n# BytePS: initialize BytePS.\nbps.init()\n\n# BytePS: pin GPU to be used to process local rank (one GPU per process)\nconfig = tf.ConfigProto()\nconfig.gpu_options.allow_growth = True\nconfig.gpu_options.visible_device_list = str(bps.local_rank())\nK.set_session(tf.Session(config=config))\n\nbatch_size = 128\nnum_classes = 10\n\n# BytePS: adjust number of epochs based on number of GPUs.\nepochs = int(math.ceil(12.0 / bps.size()))\n\n# Input image dimensions\nimg_rows, img_cols = 28, 28\n\n# The data, shuffled and split between train and test sets\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nif K.image_data_format() == 'channels_first':\n    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n    input_shape = (1, img_rows, img_cols)\nelse:\n    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n    input_shape = (img_rows, img_cols, 1)\n\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train /= 255\nx_test /= 255\nprint('x_train shape:', x_train.shape)\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')\n\n# Convert class vectors to binary class matrices\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)\n\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation='softmax'))\n\n# BytePS: adjust learning rate based on number of GPUs.\nopt = keras.optimizers.Adadelta(1.0 * bps.size())\n\n# BytePS: add BytePS Distributed Optimizer.\nopt = bps.DistributedOptimizer(opt)\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=opt,\n              metrics=['accuracy'])\n\ncallbacks = [\n    # BytePS: broadcast initial variable states from rank 0 to all other processes.\n    # This is necessary to ensure consistent initialization of all workers when\n    # training is started with random weights or restored from a checkpoint.\n    bps.callbacks.BroadcastGlobalVariablesCallback(0),\n]\n\n# BytePS: save checkpoints only on worker 0 to prevent other workers from corrupting them.\nif bps.rank() == 0:\n    callbacks.append(keras.callbacks.ModelCheckpoint('./checkpoint-{epoch}.h5'))\n\nmodel.fit(x_train, y_train,\n          batch_size=batch_size,\n          callbacks=callbacks,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test, y_test))\nscore = model.evaluate(x_test, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])\n"""
example/tensorflow/tensorflow_mnist.py,26,"b'#!/usr/bin/env python\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport os\nimport errno\nimport byteps.tensorflow as bps\nimport numpy as np\n\nfrom tensorflow import keras\nimport tensorflow as tf\n\nlayers = tf.layers\n\ntf.logging.set_verbosity(tf.logging.INFO)\n\n\ndef conv_model(feature, target, mode):\n    """"""2-layer convolution model.""""""\n    # Convert the target to a one-hot tensor of shape (batch_size, 10) and\n    # with a on-value of 1 for each one-hot vector of length 10.\n    target = tf.one_hot(tf.cast(target, tf.int32), 10, 1, 0)\n\n    # Reshape feature to 4d tensor with 2nd and 3rd dimensions being\n    # image width and height final dimension being the number of color channels.\n    feature = tf.reshape(feature, [-1, 28, 28, 1])\n\n    # First conv layer will compute 32 features for each 5x5 patch\n    with tf.variable_scope(\'conv_layer1\'):\n        h_conv1 = layers.conv2d(feature, 32, kernel_size=[5, 5],\n                                activation=tf.nn.relu, padding=""SAME"")\n        h_pool1 = tf.nn.max_pool(\n            h_conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\'SAME\')\n\n    # Second conv layer will compute 64 features for each 5x5 patch.\n    with tf.variable_scope(\'conv_layer2\'):\n        h_conv2 = layers.conv2d(h_pool1, 64, kernel_size=[5, 5],\n                                activation=tf.nn.relu, padding=""SAME"")\n        h_pool2 = tf.nn.max_pool(\n            h_conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\'SAME\')\n        # reshape tensor into a batch of vectors\n        h_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 * 64])\n\n    # Densely connected layer with 1024 neurons.\n    h_fc1 = layers.dropout(\n        layers.dense(h_pool2_flat, 1024, activation=tf.nn.relu),\n        rate=0.5, training=mode == tf.estimator.ModeKeys.TRAIN)\n\n    # Compute logits (1 per class) and compute loss.\n    logits = layers.dense(h_fc1, 10, activation=None)\n    loss = tf.losses.softmax_cross_entropy(target, logits)\n\n    return tf.argmax(logits, 1), loss\n\n\ndef train_input_generator(x_train, y_train, batch_size=64):\n    assert len(x_train) == len(y_train)\n    while True:\n        p = np.random.permutation(len(x_train))\n        x_train, y_train = x_train[p], y_train[p]\n        index = 0\n        while index <= len(x_train) - batch_size:\n            yield x_train[index:index + batch_size], \\\n                  y_train[index:index + batch_size],\n            index += batch_size\n\n\ndef main(_):\n    # BytePS: initialize BytePS.\n    bps.init()\n\n    # Keras automatically creates a cache directory in ~/.keras/datasets for\n    # storing the downloaded MNIST data. This creates a race\n    # condition among the workers that share the same filesystem. If the\n    # directory already exists by the time this worker gets around to creating\n    # it, ignore the resulting exception and continue.\n    cache_dir = os.path.join(os.path.expanduser(\'~\'), \'.keras\', \'datasets\')\n    if not os.path.exists(cache_dir):\n        try:\n            os.mkdir(cache_dir)\n        except OSError as e:\n            if e.errno == errno.EEXIST and os.path.isdir(cache_dir):\n                pass\n            else:\n                raise\n\n    # Download and load MNIST dataset.\n    (x_train, y_train), (x_test, y_test) = \\\n        keras.datasets.mnist.load_data(\'MNIST-data-%d\' % bps.rank())\n\n    # The shape of downloaded data is (-1, 28, 28), hence we need to reshape it\n    # into (-1, 784) to feed into our network. Also, need to normalize the\n    # features between 0 and 1.\n    x_train = np.reshape(x_train, (-1, 784)) / 255.0\n    x_test = np.reshape(x_test, (-1, 784)) / 255.0\n\n    # Build model...\n    with tf.name_scope(\'input\'):\n        image = tf.placeholder(tf.float32, [None, 784], name=\'image\')\n        label = tf.placeholder(tf.float32, [None], name=\'label\')\n    predict, loss = conv_model(image, label, tf.estimator.ModeKeys.TRAIN)\n\n    # BytePS: adjust learning rate based on number of GPUs.\n    opt = tf.train.RMSPropOptimizer(0.001 * bps.size())\n\n    # BytePS: add BytePS Distributed Optimizer.\n    opt = bps.DistributedOptimizer(opt)\n\n    global_step = tf.train.get_or_create_global_step()\n    train_op = opt.minimize(loss, global_step=global_step)\n\n    hooks = [\n        # BytePS: BroadcastGlobalVariablesHook broadcasts initial variable states\n        # from rank 0 to all other processes. This is necessary to ensure consistent\n        # initialization of all workers when training is started with random weights\n        # or restored from a checkpoint.\n        bps.BroadcastGlobalVariablesHook(0),\n\n        # BytePS: adjust number of steps based on number of GPUs.\n        tf.train.StopAtStepHook(last_step=200000 // bps.size()),\n\n        tf.train.LoggingTensorHook(tensors={\'step\': global_step, \'loss\': loss},\n                                   every_n_iter=10),\n    ]\n\n    # BytePS: pin GPU to be used to process local rank (one GPU per process)\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    config.gpu_options.visible_device_list = str(bps.local_rank())\n\n    # BytePS: save checkpoints only on worker 0 to prevent other workers from\n    # corrupting them.\n    checkpoint_dir = \'./checkpoints\' if bps.rank() == 0 else None\n    training_batch_generator = train_input_generator(x_train,\n                                                     y_train, batch_size=100)\n    # The MonitoredTrainingSession takes care of session initialization,\n    # restoring from a checkpoint, saving to a checkpoint, and closing when done\n    # or an error occurs.\n    with tf.train.MonitoredTrainingSession(checkpoint_dir=checkpoint_dir,\n                                           hooks=hooks,\n                                           config=config) as mon_sess:\n        while not mon_sess.should_stop():\n            # Run a training step synchronously.\n            image_, label_ = next(training_batch_generator)\n            mon_sess.run(train_op, feed_dict={image: image_, label: label_})\n\n\nif __name__ == ""__main__"":\n    tf.app.run()'"
byteps/misc/imagenet18/__init__.py,0,"b'# Copyright 2019 Bytedance Inc. All Rights Reserved.\n# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom byteps.torch import _DistributedOptimizer\nfrom byteps.torch.compression import Compression\nfrom byteps.torch.ops import push_pull_async_inplace as byteps_push_pull\nfrom byteps.torch.ops import push_pull\nfrom byteps.torch.ops import poll, synchronize, declare\nfrom byteps.torch.ops import init, shutdown\nfrom byteps.torch.ops import size, local_size, rank, local_rank\n\nimport time\nimport threading\ntry:\n    import queue\nexcept ImportError:\n    import Queue as queue\nimport torch\nimport collections\n\n\nclass _HalfPrecisionDistributedOptimizer(torch.optim.Optimizer):\n    def  __init__(self, params, named_parameters, model, fp16_params, fp32_params, loss_scale,\n                 compression, backward_passes_per_step=1):\n        super(self.__class__, self).__init__(params)\n        self._compression = compression\n\n        if named_parameters is not None:\n            named_parameters = list(named_parameters)\n        else:\n            named_parameters = []\n\n        self._model = model\n        self.fp32_params = fp32_params\n        self.fp16_params = fp16_params\n        self.loss_scale = loss_scale\n\n        # Track training steps\n        # self._step = 0\n\n        # make sure that named_parameters are tuples\n        if any([not isinstance(p, tuple) for p in named_parameters]):\n            raise ValueError(\'named_parameters should be a sequence of \'\n                             \'tuples (name, parameter), usually produced by \'\n                             \'model.named_parameters().\')\n\n        dups = _HalfPrecisionDistributedOptimizer.find_duplicates([k for k, _ in named_parameters])\n        if len(dups) > 0:\n            raise ValueError(\'Parameter names in named_parameters must be unique. \'\n                             \'Found duplicates: %s\' % \', \'.join(dups))\n\n        if len(named_parameters) > 0:\n            if isinstance(named_parameters[0][1], torch.Tensor):\n                if any([not isinstance(p, torch.Tensor) for name, p in named_parameters]):\n                    raise ValueError(\'named_parameters should consistently be a sequence of \'\n                                     \'tuples (name, torch.Tensor)\')\n                self._is_tensor_instance = True\n                # there is an issue when using torch.Tensor as key, so use its hash instead\n                # https://github.com/pytorch/pytorch/issues/7733\n                self._parameter_names = {v.__hash__(): k for k, v\n                                         in sorted(named_parameters)}\n                self._tensor_list = [tensor for name, tensor in named_parameters]\n            else:\n                self._is_tensor_instance = False\n                self._parameter_names = {v: k for k, v\n                                         in sorted(named_parameters)}\n        else:\n            self._is_tensor_instance = False\n            self._parameter_names = {v: \'push_pull.noname.%s\' % i\n                                     for param_group in self.param_groups\n                                     for i, v in enumerate(param_group[\'params\'])}\n\n        self._fp32_to_fp16_map = {}\n        self._fp16_to_fp32_map = {}\n        for fp16_p, fp32_p in zip(self.fp16_params, self.fp32_params):\n            if self._is_tensor_instance:\n                self._fp32_to_fp16_map[fp32_p.__hash__()] = fp16_p\n            else:\n                self._fp32_to_fp16_map[fp32_p] = fp16_p\n            self._fp16_to_fp32_map[fp16_p] = fp32_p\n\n        self.backward_passes_per_step = backward_passes_per_step\n        self._push_pull_delay = {v: self.backward_passes_per_step\n                                 for _, v in sorted(named_parameters)}\n        self._handles = {}\n        self._grad_accs = []\n        self._requires_update = set()\n\n        if size() > 1:\n            self._register_forward_hooks()\n            self._register_backward_hooks()\n\n        self._lock = threading.Lock()\n\n        # declare tensors\n        for name in self._parameter_names.values():\n            declare(""Gradient.""+name)\n        # We use two loops for load-balancing\n        for name in self._parameter_names.values():\n            declare(""Parameter.""+name)\n\n        self.priorities = {}\n        self.gradient_count = 0\n\n    @staticmethod\n    def find_duplicates(lst):\n        seen = set()\n        dups = set()\n        for el in lst:\n            if el in seen:\n                dups.add(el)\n            seen.add(el)\n        return dups\n\n    def set_backward_passes_per_step(self, passes):\n        self.backward_passes_per_step = passes\n        for p in self._push_pull_delay:\n            self._push_pull_delay[p] = self.backward_passes_per_step\n\n    def _register_forward_hooks(self):\n        """"""Add hook before forward propagation of each layer to block forward computation until the push-pull and\n        parameter update is finished. The blocking is implemented using a lock.""""""\n        # Recursively find all submodules\n        submodules = []\n        q = queue.LifoQueue()\n        for mod in self._model.children():\n            q.put(mod)\n        while not q.empty():\n            mod = q.get()\n            if len(list(mod.children())) == 0:\n                submodules.append(mod)\n            else:\n                for m in mod.children():\n                    q.put(m)\n\n        def pre_forward_hook(mod, input):\n            for p in mod.parameters():\n                fp32_p = self._fp16_to_fp32_map[p]\n                if fp32_p in self._handles:\n                    while True:\n                        with self._lock:\n                            if fp32_p not in self._handles:\n                                break\n                            if self._try_to_synchronize(fp32_p):\n                                break\n                            else:\n                                # In order not to waste GPU cycles, we find another handle to synchronize\n                                params = list(self._handles.keys())\n                                for other_p in params:\n                                    if other_p.__hash__() == fp32_p.__hash__():\n                                        continue\n                                    if self._try_to_synchronize(other_p):\n                                        break\n                        time.sleep(0.0001)\n\n        def after_forward_hook(mod, input, result):\n            for p in mod.parameters():\n                self._zero_one_grad(p)\n\n        # Register pre-hook and hook for each module\n        for mod in reversed(submodules):\n            mod.register_forward_pre_hook(pre_forward_hook)\n            mod.register_forward_hook(after_forward_hook)\n\n    def _register_backward_hooks(self):\n        for param_group in self.param_groups:\n            for p in param_group[\'params\']:\n                if p.requires_grad:\n                    p.grad = p.data.new(p.size()).zero_()\n                    self._requires_update.add(p)\n                    if self._is_tensor_instance:\n                        fp16_p = self._fp32_to_fp16_map.get(p.__hash__())\n                    else:\n                        fp16_p = self._fp32_to_fp16_map.get(p)\n                    p_tmp = fp16_p.expand_as(fp16_p)\n                    grad_acc = p_tmp.grad_fn.next_functions[0][0]\n                    grad_acc.register_hook(self._make_hook(p))\n                    self._grad_accs.append(grad_acc)\n\n    def _push_pull_grad_async(self, p):\n        if self._is_tensor_instance:\n            name = self._parameter_names.get(p.__hash__())\n            fp16_p = self._fp32_to_fp16_map.get(p.__hash__())\n        else:\n            name = self._parameter_names.get(p)\n            fp16_p = self._fp32_to_fp16_map.get(p)\n        tensor = fp16_p.grad\n        tensor_compressed, ctx = self._compression.compress(tensor)\n        if fp16_p not in self.priorities:\n            self.priorities[fp16_p] = self.gradient_count\n            self.gradient_count += 1\n        handle = byteps_push_pull(tensor_compressed, average=False, name=""Gradient.""+name, priority=self.priorities[fp16_p])\n        return handle, ctx\n\n    def _make_hook(self, p):\n        def hook(*ignore):\n            if p in self._handles and self._handles[p][0] is not None:\n                if self._push_pull_delay[p] <= 0:\n                    raise AssertionError(\n                        ""Gradients were computed more than ""\n                        ""backward_passes_per_step times before call ""\n                        ""to step(). Increase backward_passes_per_step to ""\n                        ""accumulate gradients locally."")\n            assert not p.grad.requires_grad\n            assert self._push_pull_delay[p] > 0\n            handle, ctx = None, None\n            self._push_pull_delay[p] -= 1\n            if self._push_pull_delay[p] == 0:\n                handle, ctx = self._push_pull_grad_async(p)\n            self._handles[p] = (handle, ctx)\n        return hook\n\n    def _sync_missing_gradients(self):\n        missing_p = self._requires_update - set(self._handles.keys())\n        for p in missing_p:\n            handle, ctx = self._push_pull_grad_async(p)\n            self._handles[p] = (handle, ctx)\n\n        for p, value in self._handles.items():\n            handle, ctx = value\n            if handle is None:\n                handle, ctx = self._push_pull_grad_async(p)\n                self._handles[p] = (handle, ctx)\n\n    def step(self, closure=None, wait_for_finish=True):\n        if size() > 1:\n            self._sync_missing_gradients()\n            if wait_for_finish:\n                self._wait_for_all()\n            loss = None\n            if closure is not None:\n                loss = closure()\n            return loss\n        else:\n            super(self.__class__, self).step()\n\n\n    def _step_one_param(self, param, closure=None):\n        """"""Performs a single optimization step. Only applicable to SGD.\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        """"""\n        loss = None\n        if closure is not None:\n            loss = closure()\n\n        for group in self.param_groups:\n            weight_decay = group[\'weight_decay\']\n            momentum = group[\'momentum\']\n            dampening = group[\'dampening\']\n            nesterov = group[\'nesterov\']\n\n            for p in group[\'params\']:\n                if p.__hash__() != param.__hash__():\n                    continue\n                if p.grad is None:\n                    continue\n                d_p = p.grad.data\n                if weight_decay != 0:\n                    d_p.add_(weight_decay, p.data)\n                if momentum != 0:\n                    param_state = self.state[p]\n                    if \'momentum_buffer\' not in param_state:\n                        buf = param_state[\'momentum_buffer\'] = torch.clone(d_p).detach()\n                    else:\n                        buf = param_state[\'momentum_buffer\']\n                        buf.mul_(momentum).add_(1 - dampening, d_p)\n                    if nesterov:\n                        d_p = d_p.add(momentum, buf)\n                    else:\n                        d_p = buf\n\n                p.data.add_(-group[\'lr\'], d_p)\n\n        return loss\n\n    def _zero_one_grad(self, p):\n        """"""Clears the gradient of one variable as torch accumulates gradients by default.\n        Arguments:\n            p: the parameter.\n        """"""\n        if p.grad is not None:\n            p.grad.detach_()\n            p.grad.zero_()\n\n    def _wait_for_all(self):\n        while len(self._handles.keys()) > 0:\n            params = list(self._handles.keys())\n            for p in params:\n                self._try_to_synchronize(p)\n\n    def _try_to_synchronize(self, p):\n        handle, ctx = self._handles[p]\n        if poll(handle):\n            output = synchronize(handle)\n            self._push_pull_delay[p] = self.backward_passes_per_step\n            if self._is_tensor_instance:\n                fp16_p = self._fp32_to_fp16_map.get(p.__hash__())\n            else:\n                fp16_p = self._fp32_to_fp16_map.get(p)\n            fp16_p.grad.set_(self._compression.decompress(output, ctx))\n            p.grad.data.copy_(fp16_p.grad.data)\n            p.grad.data = p.grad.data / (self.loss_scale * size())\n            self._step_one_param(p)\n            fp16_p.data.copy_(p.data)\n            self._handles.pop(p)\n            return True\n        else:\n            return False\n\n\ndef DistributedOptimizer(optimizer, named_parameters=None,\n                         compression=Compression.none,\n                         backward_passes_per_step=1,\n                         half=False,\n                         model=None,\n                         fp16_params=None,\n                         fp32_params=None,\n                         loss_scale=1024):\n    """"""\n    An optimizer that wraps another torch.optim.Optimizer, using an push_pull to\n    average gradient values before applying gradients to model weights.\n    push_pull operations are executed after each gradient is computed by `loss.backward()`\n    in parallel with each other. The `step()` method ensures that all push_pull operations are\n    finished before applying gradients to the model.\n    DistributedOptimizer exposes the `synchronize()` method, which forces push_pull operations\n    to finish before continuing the execution. It\'s useful in conjunction with gradient\n    clipping, or other operations that modify gradients in place before `step()` is executed.\n    Example of gradient clipping:\n    ```\n    output = model(data)\n    loss = F.nll_loss(output, target)\n    loss.backward()\n    optimizer.synchronize()\n    torch.nn.utils.clip_grad_norm(model.parameters(), args.clip)\n    optimizer.step()\n    ```\n    Arguments:\n        optimizer: Optimizer to use for computing gradients and applying updates.\n        named_parameters: A mapping between parameter names and values. Used for naming of\n                          push_pull operations. Typically just `model.named_parameters()`.\n        compression: Compression algorithm used during push_pull to reduce the amount\n                     of data sent during the each parameter update step.  Defaults to\n                     not using compression.\n        backward_passes_per_step: Number of expected backward passes to perform\n                                  before calling step()/synchronize(). This\n                                  allows accumulating gradients over multiple\n                                  mini-batches before executing averaging and\n                                  applying them.\n    """"""\n    # We dynamically create a new class that inherits from the optimizer that was passed in.\n    # The goal is to override the `step()` method with an push_pull implementation.\n    if half:\n        cls = type(optimizer.__class__.__name__, (optimizer.__class__,),\n                   dict(_HalfPrecisionDistributedOptimizer.__dict__))\n        return cls(optimizer.param_groups, named_parameters, model,\n                   fp16_params, fp32_params, loss_scale, compression, backward_passes_per_step)\n    else:\n        cls = type(optimizer.__class__.__name__, (optimizer.__class__,),\n                   dict(_DistributedOptimizer.__dict__))\n        return cls(optimizer.param_groups, named_parameters,\n                   compression, backward_passes_per_step)\n\n\ndef broadcast_parameters(params, root_rank):\n    """"""\n    Broadcasts the parameters from root rank to all other processes.\n    Typical usage is to broadcast the `model.state_dict()`,\n    `model.named_parameters()`, or `model.parameters()`.\n    Arguments:\n        params: One of the following:\n            - list of parameters to broadcast\n            - dict of parameters to broadcast\n        root_rank: The rank of the process from which parameters will be\n                   broadcasted to all other processes.\n    """"""\n    if isinstance(params, dict):\n        params = sorted(params.items())\n    elif isinstance(params, list):\n        # support both named_parameters() and regular parameters()\n        params = [p if isinstance(p, tuple) else (None, p) for p in params]\n    else:\n        raise ValueError(\'invalid params of type: %s\' % type(params))\n\n    # Run synchronous broadcasts.\n    for name, p in params:\n        # Broadcast is implemented as push + pull in BytePS\n        # To make it a real broadcast, we set the non-root tensors all 0.\n        if rank() != root_rank:\n            p.fill_(0)\n        # Remember to disable averaging because we are doing broadcast\n        handle = byteps_push_pull(p, average=False, name=""Parameter.""+name)\n        synchronize(handle)\n\n\ndef broadcast_optimizer_state(optimizer, root_rank):\n    """"""\n    Broadcasts an optimizer state from root rank to all other processes.\n    Arguments:\n        optimizer: An optimizer.\n        root_rank: The rank of the process from which the optimizer will be\n                   broadcasted to all other processes.\n    """"""\n    if isinstance(optimizer, torch.optim.LBFGS):\n        # TODO(travis): L-BFGS cannot be easily supported without serializing\n        # the entire state_dict, as its structure is deeply nested and contains\n        # None type parameter values\n        raise ValueError(\'cannot broadcast torch.optim.LBFGS state\')\n\n    state_dict = optimizer.state_dict()\n\n    # Newly created optimizers will not have their state initialized, so\n    # do that initialization here\n    if len(state_dict[\'state\']) == 0:\n        for group in optimizer.param_groups:\n            for p in group[\'params\']:\n                p.grad = p.data.new(p.size()).zero_()\n        # This function accepts a torch.optim.Optimizer or a DistributedOptimizer\n        # wrapped around a torch optimizer. Calling step() with a DistributedOptimizer\n        # forces push_pull on all model parameters, which will result in deadlock\n        # unless every rank calls step(). Therefore, to finish state initialization\n        # only call optimizer.step() with a torch.optim.Optimizer.\n        if optimizer.__module__ == DistributedOptimizer.__module__:\n            super(optimizer.__class__, optimizer).step()\n        else:\n            optimizer.step()\n        state_dict = optimizer.state_dict()\n\n    # If the state_dict is still empty after initialization, then\n    # the optimizer is stateless, and there is nothing to broadcast.\n    # Furthermore, attempting to access the state dict would result in\n    # an error.\n    if len(state_dict[\'state\']) == 0:\n        return\n\n    params = []\n    callbacks = {}\n    occurrences = collections.defaultdict(int)\n\n    # Returns the full type structure of the possibly nested objects for recursive casting back\n    def _get_types(x):\n        if isinstance(x, collections.Iterable):\n            return type(x), [_get_types(xi) for xi in x]\n        else:\n            return type(x)\n\n    # Casts an object encoded in a tensor back into its original type and subtypes\n    def _recursive_cast(x, dtype):\n        if isinstance(dtype, tuple):\n            t, dtypes = dtype\n            x = t(x)\n            return t([_recursive_cast(x[i], dtypes[i]) for i in range(len(x))])\n        else:\n            return dtype(x)\n\n    # Some optimizer parameters may be represented as scalars instead of\n    # tensors.  In such cases, we need to wrap the scalar in a tensor, then\n    # broadcast, then update the appropriate value in the state_dict with the\n    # new unwrapped scalar value via a callback.\n    def _create_callback(pid, name, t, p):\n        def _from_tensor():\n            state_dict[\'state\'][pid][name] = t(p.numpy()[0])\n        return _from_tensor\n\n    def _create_option_callback(index, option_key, option_tensor, dtypes):\n        def _from_tensor():\n            optimizer.param_groups[index][option_key] = _recursive_cast(\n                option_tensor.numpy()[0], dtypes)\n        return _from_tensor\n\n    # Param groups are an ordered list, normally there is only one per model,\n    # but users can add additional param groups for example to train\n    # previously frozen layers\n    for index, group in enumerate(state_dict[\'param_groups\']):\n        # Broadcast options like learning rate\n        for option_key, option_value in group.items():\n            if option_key == \'params\':\n                continue\n\n            # Options like the learning rate are scalar, and need to be wrapped in tensors\n            key = \'%s.%d\' % (option_key, index)\n            dtypes = _get_types(option_value)\n            option_tensor = torch.Tensor([option_value])\n            callbacks[key] = _create_option_callback(index, option_key, option_tensor, dtypes)\n            params.append((key, option_tensor))\n\n        # The params list here is ordered by the layers in the model\n        for pid in group[\'params\']:\n            param_state = state_dict[\'state\'][pid]\n            for name, p in param_state.items():\n                # Some parameter names may appear more than once, in which\n                # case we ensure they have a unique identifier defined by\n                # their order\n                occurrences[name] += 1\n                key = \'%s.%d\' % (str(name), occurrences[name])\n\n                if not torch.is_tensor(p):\n                    # Wrap the scalar in a FloatTensor, and remember its type\n                    # so we can cast it back after unwrapping\n                    t = type(p)\n                    p = torch.Tensor([p])\n                    callbacks[key] = _create_callback(pid, name, t, p)\n\n                params.append((key, p))\n\n    # Synchronized broadcast of all parameters\n    broadcast_parameters(params, root_rank)\n\n    # Post-broadcast clenaup for non-tensor parameters\n    for key, p in params:\n        if key in callbacks:\n            callbacks[key]()\n'"
byteps/tensorflow/keras/__init__.py,1,"b'# Copyright 2017 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport inspect\n\nimport tensorflow as tf\n\nfrom distutils.version import LooseVersion\nif LooseVersion(tf.__version__) >= LooseVersion(""1.4.0""):\n    from tensorflow import keras\n    from tensorflow.python.keras import backend as K\nelse:\n    from tensorflow.contrib import keras\n    from tensorflow.contrib.keras import backend as K\n\nfrom byteps.tensorflow import init\nfrom byteps.tensorflow import shutdown\nfrom byteps.tensorflow import size\nfrom byteps.tensorflow import local_size\nfrom byteps.tensorflow import rank\nfrom byteps.tensorflow import local_rank\nfrom byteps.tensorflow import Compression\n\nimport byteps._keras as _impl\nfrom byteps.tensorflow.keras import callbacks\n\n\ndef DistributedOptimizer(optimizer, name=None,\n                         device_dense=\'\', device_sparse=\'\',\n                         compression=Compression.none,\n                         sparse_as_dense=False):\n    """"""\n    An optimizer that wraps another keras.optimizers.Optimizer, using an push_pull to\n    average gradient values before applying gradients to model weights.\n    Args:\n        optimizer: Optimizer to use for computing gradients and applying updates.\n        name: Optional name prefix for the operations created when applying\n              gradients. Defaults to ""Distributed"" followed by the provided\n              optimizer type.\n        device_dense: Device to be used for dense tensors. Uses GPU by default.\n        device_sparse: Device to be used for sparse tensors. Uses GPU by default.\n        compression: Compression algorithm used to reduce the amount of data\n                     sent and received by each worker node.  Defaults to not\n                     using compression.\n        sparse_as_dense: Treat all sparse gradients as dense tensors.  This can\n                         help improve performance and memory utilization if\n                         the original sparse gradient has high density.\n                         Defaults to false.\n    """"""\n    return _impl.create_distributed_optimizer(keras, optimizer, name,\n                                              device_dense, device_sparse, compression,\n                                              sparse_as_dense)\n\n\ndef broadcast_global_variables(root_rank):\n    """"""Broadcasts all global variables from root rank to all other processes.\n    Arguments:\n        root_rank: Rank of the process from which global variables will be broadcasted\n                   to all other processes.\n    """"""\n    return _impl.broadcast_global_variables(K, root_rank)\n\n\ndef push_pull(value, name=None, average=True):\n    """"""\n    Perform an push_pull on a tensor-compatible value.\n    Arguments:\n        value: A tensor-compatible value to reduce.\n               The shape of the input must be identical across all ranks.\n        name: Optional name for the constants created by this operation.\n        average: If True, computes the average over all ranks.\n                 Otherwise, computes the sum over all ranks.\n    """"""\n    return _impl.push_pull(K, value, name, average)\n\n\ndef broadcast(value, root_rank, name=None):\n    """"""\n    Perform a broadcast on a tensor-compatible value.\n    Arguments:\n        value: A tensor-compatible value to reduce.\n               The shape of the input must be identical across all ranks.\n        root_rank: Rank of the process from which global variables will be\n                   broadcasted to all other processes.\n        name: Optional name for the constants created by this operation.\n    """"""\n    return _impl.broadcast(K, value, root_rank, name)\n\n\ndef load_model(filepath, custom_optimizers=None, custom_objects=None, compression=Compression.none):\n    """"""\n    Loads a saved Keras model with a BytePS DistributedOptimizer.\n    The DistributedOptimizer will wrap the underlying optimizer used to train\n    the saved model, so that the optimizer state (params and weights) will\n    be picked up for retraining.\n    By default, all optimizers in the module `keras.optimizers` will be loaded\n    and wrapped without needing to specify any `custom_optimizers` or\n    `custom_objects`.\n    # Arguments\n        filepath: One of the following:\n            - string, path to the saved model, or\n            - h5py.File object from which to load the model\n        custom_optimizers: Optional list of Optimizer subclasses to support\n            during loading.\n        custom_objects: Optional dictionary mapping names (strings) to custom\n            classes or functions to be considered during deserialization.\n        compression: Compression algorithm used to reduce the amount of data\n                     sent and received by each worker node.  Defaults to not\n                     using compression.\n    # Returns\n        A Keras model instance.\n    # Raises\n        ImportError: If h5py is not available.\n        ValueError: In case of an invalid savefile.\n    """"""\n    def wrap_optimizer(cls):\n        return lambda **kwargs: DistributedOptimizer(cls(**kwargs), compression=compression)\n    optimizer_modules = {keras.optimizers.Optimizer.__module__}\n    return _impl.load_model(keras, wrap_optimizer, optimizer_modules, filepath, custom_optimizers, custom_objects)\n'"
byteps/tensorflow/keras/callbacks.py,1,"b'# Copyright 2018 Uber Technologies, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport tensorflow as tf\n\nfrom distutils.version import LooseVersion\nif LooseVersion(tf.__version__) >= LooseVersion(""1.4.0""):\n    from tensorflow import keras\n    from tensorflow.python.keras import backend as K\nelse:\n    from tensorflow.contrib import keras\n    from tensorflow.contrib.keras import backend as K\n\nfrom byteps._keras import callbacks as _impl\n\n\nclass BroadcastGlobalVariablesCallback(_impl.BroadcastGlobalVariablesCallbackImpl, keras.callbacks.Callback):\n    """"""\n    Keras Callback that will broadcast all global variables from root rank\n    to all other processes during initialization.\n    This is necessary to ensure consistent initialization of all workers when\n    training is started with random weights or restored from a checkpoint.\n    """"""\n\n    def __init__(self, root_rank, device=\'\'):\n        """"""\n        Construct a new BroadcastGlobalVariablesCallback that will broadcast all\n        global variables from root rank to all other processes during initialization.\n        Args:\n            root_rank: Rank that will send data, other ranks will receive data.\n            device: Device to be used for broadcasting. Uses GPU by default.\n        """"""\n        super(BroadcastGlobalVariablesCallback, self).__init__(K, root_rank, device)\n\n\nclass MetricAverageCallback(_impl.MetricAverageCallbackImpl, keras.callbacks.Callback):\n    """"""\n    Keras Callback that will average metrics across all processes at the\n    end of the epoch. Useful in conjuction with ReduceLROnPlateau,\n    TensorBoard and other metrics-based callbacks.\n    Note: This callback must be added to the callback list before the\n    ReduceLROnPlateau, TensorBoard or other metrics-based callbacks.\n    """"""\n\n    def __init__(self, device=\'\'):\n        """"""\n        Construct a new MetricAverageCallback that will average metrics\n        across all processes at the end of the epoch.\n        Args:\n            device: Device to be used for push_pull. Uses GPU by default.\n        """"""\n        super(MetricAverageCallback, self).__init__(K, device)\n\n\nclass LearningRateScheduleCallback(_impl.LearningRateScheduleCallbackImpl, keras.callbacks.Callback):\n    """"""\n    LearningRateScheduleCallback sets learning rate between epochs `start_epoch` and\n    `end_epoch` to be `initial_lr * multiplier`.  `multiplier` can be a constant or\n    a function `f(epoch) = lr\'`.\n    If `multiplier` is a function and `staircase=True`, learning rate adjustment will\n    happen at the beginning of each epoch and the epoch passed to the `multiplier`\n    function will be an integer.\n    If `multiplier` is a function and `staircase=False`, learning rate adjustment will\n    happen at the beginning of each batch and the epoch passed to the `multiplier`\n    function will be a floating number: `epoch\' = epoch + batch / steps_per_epoch`.\n    This functionality is useful for smooth learning rate adjustment schedulers, such\n    as `LearningRateWarmupCallback`.\n    `initial_lr` is the learning rate of the model optimizer at the start of the training.\n    """"""\n\n    def __init__(self, multiplier, start_epoch=0, end_epoch=None, staircase=True,\n                 momentum_correction=True, steps_per_epoch=None, initial_lr=None):\n        """"""\n        Construct a new LearningRateScheduleCallback.\n        Args:\n            multiplier: A constant multiplier or a function `f(epoch) = lr\'`\n            start_epoch: The first epoch this adjustment will be applied to. Defaults to 0.\n            end_epoch: The epoch this adjustment will stop applying (exclusive end).\n                       Defaults to None.\n            staircase: Whether to adjust learning rate at the start of epoch (`staircase=True`)\n                       or at the start of every batch (`staircase=False`).\n            momentum_correction: Apply momentum correction to optimizers that have momentum.\n                                 Defaults to True.\n            steps_per_epoch: The callback will attempt to autodetect number of batches per\n                             epoch with Keras >= 2.0.0. Provide this value if you have an older\n                             version of Keras.\n            initial_lr: Initial learning rate at the start of training.\n\n                .. warning:: Will be required in the future.\n\n        """"""\n        super(LearningRateScheduleCallback, self).__init__(K, multiplier, start_epoch, end_epoch,\n                                                           staircase, momentum_correction, steps_per_epoch,\n                                                           initial_lr)\n\n\nclass LearningRateWarmupCallback(_impl.LearningRateWarmupCallbackImpl, keras.callbacks.Callback):\n    """"""\n    Implements gradual learning rate warmup:\n        `lr = initial_lr / bps.size()` ---> `lr = initial_lr`\n    `initial_lr` is the learning rate of the model optimizer at the start of the training.\n    This technique was described in the paper ""Accurate, Large Minibatch SGD: Training\n    ImageNet in 1 Hour"". See https://arxiv.org/pdf/1706.02677.pdf for details.\n    Math recap:\n                                                 batch\n        epoch               = full_epochs + ---------------\n                                            steps_per_epoch\n                               lr     size - 1\n        lr\'(epoch)          = ---- * (-------- * epoch + 1)\n                              size     warmup\n                               lr\n        lr\'(epoch = 0)      = ----\n                              size\n        lr\'(epoch = warmup) = lr\n    """"""\n\n    def __init__(self, warmup_epochs=5, momentum_correction=True, steps_per_epoch=None,\n                 verbose=0, initial_lr=None):\n        """"""\n        Construct a new LearningRateWarmupCallback that will gradually warm up the learning rate.\n        Args:\n            warmup_epochs: The number of epochs of the warmup phase. Defaults to 5.\n            momentum_correction: Apply momentum correction to optimizers that have momentum.\n                                 Defaults to True.\n            steps_per_epoch: The callback will attempt to autodetect number of batches per\n                             epoch with Keras >= 2.0.0. Provide this value if you have an older\n                             version of Keras.\n            verbose: verbosity mode, 0 or 1.\n            initial_lr: Initial learning rate at the start of training.\n\n                .. warning:: Will be required in the future.\n        """"""\n        super(LearningRateWarmupCallback, self).__init__(K, warmup_epochs, momentum_correction,\n                                                         steps_per_epoch, verbose, initial_lr)\n'"
byteps/torch/parallel/__init__.py,0,b'from .distributed import  DistributedDataParallel\n'
byteps/torch/parallel/distributed.py,0,"b'import torch\nfrom torch.nn.modules import Module\nfrom byteps.torch.ops import push_pull_group_sync_inplace as byteps_push_pull_group\nfrom byteps.torch.ops import push_pull_async_inplace as byteps_push_pull\nfrom byteps.torch.ops import poll, synchronize, declare, byteps_torch_set_num_grads\nfrom byteps.torch.ops import size, local_size, rank, local_rank\nfrom contextlib import contextmanager\nimport byteps as bps\nfrom byteps.torch.compression import Compression\nfrom torch.cuda._utils import _get_device_index\nimport os\n\nclass DistributedDataParallel(Module):\n    r""""""Implements distributed data parallelism that is based on\n    byteps push-pull.\n\n    This container parallelizes the application of the given module by splitting\n    the input across multiple devices, and each device handles a portion of the\n    input. During the backwards pass, gradients from each node are averaged.\n\n    ``DistributedDataParallel`` can be used in the following way:\n\n    Single-Process Single-GPU\n\n    This is currently the only way to use ``DistributedDataParallel``, with\n    multiple processes, each of which operates on a single GPU.\n\n    Here is how to use it: on each host with N GPUs, you should spawn up N\n    processes, while ensuring that each process individually works on a single\n    GPU from 0 to N-1. Therefore, it is your job to ensure that your training\n    script operates on a single given GPU by calling:\n\n        >>> torch.cuda.set_device(i)\n\n    where i is from 0 to N-1. In each process, you should refer the following\n    to construct this module:\n\n        >>> model = DistributedDataParallel(model, device_ids=[i])\n\n    In order to spawn up multiple processes per node, you can use either\n    ``torch.distributed.launch`` or ``torch.multiprocessing.spawn``\n\n    .. note:: If you use ``torch.save`` on one process to checkpoint the module,\n        and ``torch.load`` on some other processes to recover it, make sure that\n        ``map_location`` is configured properly for every process. Without\n        ``map_location``, ``torch.load`` would recover the module to devices\n        where the module was saved from.\n\n    .. warning::\n        This module works only with the ``device_ids`` containing one entry.\n\n    .. warning::\n        Constructor, forward method, and differentiation of the output (or a\n        function of the output of this module) is a distributed synchronization\n        point. Take that into account in case different processes might be\n        executing different code.\n\n    .. warning::\n        This module assumes all parameters are registered in the model by the\n        time it is created. No parameters should be added nor removed later.\n        Same applies to buffers.\n\n    .. warning::\n        This module assumes all buffers and gradients are dense.\n\n    .. warning::\n        This module doesn\'t work with :func:`torch.autograd.grad` (i.e. it will\n        only work if gradients are to be accumulated in ``.grad`` attributes of\n        parameters).\n\n    .. warning::\n        Forward and backward hooks defined on :attr:`module` and its submodules\n        won\'t be invoked anymore, unless the hooks are initialized in the\n        :meth:`forward` method.\n\n    .. warning::\n        You should never try to change your model\'s parameters after wrapping\n        up your model with DistributedDataParallel. In other words, when\n        wrapping up your model with DistributedDataParallel, the constructor of\n        DistributedDataParallel will register the additional gradient\n        reduction functions on all the parameters of the model itself at the\n        time of construction. If you change the model\'s parameters after\n        the DistributedDataParallel construction, this is not supported and\n        unexpected behaviors can happen, since some parameters\' gradient\n        reduction functions might not get called.\n\n    .. note::\n        Parameters are never broadcast between processes. The module performs\n        an all-reduce step on gradients and assumes that they will be modified\n        by the optimizer in all processes in the same way. Buffers\n        (e.g. BatchNorm stats) are broadcast from the module in rank 0 to all\n        other replicas in the system in every iteration.\n\n    .. note::\n        Some models have branches, part of the model is skipped during the\n        forward pass. In that case it\'s required to call the\n        DistributedDataParallel.synchronize() after loss.backward(), e.g:\n\n            >>> model = DistributedDataParallel(model, device_ids=[i])\n            >>> output = model(data)\n            >>> loss = F.nll_loss(output, target)\n            >>> loss.backward()\n            >>> model.synchronize()\n            >>> optimizer.step()\n\n    Args:\n        module (Module): module to be parallelized\n        device_ids (list of int or torch.device): CUDA devices. This should\n                   contain only one entry. The `module` replica is placed on\n                   ``device_ids[0]``.\n        broadcast_buffers (bool): flag that enables syncing (broadcasting) buffers of\n                          the module at beginning of the forward function.\n                          (default: ``True``)\n\n    Attributes:\n        module (Module): the module to be parallelized\n\n    Example::\n\n        >>> net = torch.nn.DistributedDataParallel(model, device_ids=[2])\n    """"""\n    def __init__(self, module, device_ids=None,\n            broadcast_buffers=True,\n            compression=Compression.none\n            ):\n        super(DistributedDataParallel, self).__init__()\n\n        assert device_ids and len(device_ids) == 1, (\n                ""DistributedDataParallel device_ids contain exactlyone entry,""\n                "" but got {}."").format(device_ids)\n        self.device_ids = list(map(lambda x: _get_device_index(x, True), device_ids))\n        self.module = module\n        self.broadcast_buffers = broadcast_buffers\n        self.require_forward_param_sync = broadcast_buffers\n        self._handles = {}\n        self._grad_accs = []\n        self._requires_update = set()\n        self._num_grads = 1\n\n        self.modules_buffers = [list(self.module.buffers())]\n        self._compression = compression\n        self._enable_async = False\n        named_parameters = self.module.named_parameters()\n        named_parameters = list(named_parameters)\n        if len(named_parameters) > 0:\n            if isinstance(named_parameters[0][1], torch.Tensor):\n                if any([not isinstance(p, torch.Tensor) for name, p in named_parameters]):\n                    raise ValueError(\'named_parameters should consistently be a sequence of \'\n                                     \'tuples (name, torch.Tensor)\')\n                self._is_tensor_instance = True\n                # there is an issue when using torch.Tensor as key, so use its hash instead\n                # https://github.com/pytorch/pytorch/issues/7733\n                self._parameter_names = {v.__hash__(): k for k, v\n                                         in sorted(named_parameters)}\n                self._tensor_list = [tensor for name, tensor in named_parameters]\n            else:\n                self._is_tensor_instance = False\n                self._parameter_names = {v: k for k, v\n                                         in sorted(named_parameters)}\n        else:\n            self._is_tensor_instance = False\n            self._parameter_names = {v: \'push_pull.noname.%s\' % i\n                                     for param_group in self.param_groups\n                                     for i, v in enumerate(param_group[\'params\'])}\n        if size() > 1:\n            self._register_hooks()\n            named_params = self.module.named_parameters()\n            self._num_grads = sum(p.requires_grad for _, p in named_params)\n            byteps_torch_set_num_grads(self._num_grads)\n\n        # declare tensors\n        for name in sorted(self._parameter_names.values()):\n            declare(""Gradient.""+name)\n        # We use two loops for load-balancing\n        for name in sorted(self._parameter_names.values()):\n            declare(""Parameter.""+name)\n\n        # broadcast model state\n        module_states = list(self.module.state_dict().values())\n        if len(module_states) > 0:\n            bps.torch.broadcast_parameters(self.module.state_dict(), root_rank=0)\n\n    def forward(self, *inputs, **kwargs):\n        if self.require_forward_param_sync:\n            self._sync_params()\n        return self.module(*inputs, **kwargs)\n\n    def _sync_params(self):\n        with torch.no_grad():\n            # sync module buffers\n            if self.broadcast_buffers and len(self.modules_buffers[0]) > 0:\n                # Synchronize buffers across processes.\n                # The process with rank 0 is considered the authoritative copy.\n                bps.torch.broadcast_parameters(list(self.module.named_buffers()), root_rank=0)\n\n    def _register_hooks(self):\n        for _, p in self.module.named_parameters():\n            if p.requires_grad:\n                p.grad = p.data.new(p.size()).zero_()\n                self._requires_update.add(p)\n                p_tmp = p.expand_as(p)\n                grad_acc = p_tmp.grad_fn.next_functions[0][0]\n                grad_acc.register_hook(self._make_hook(p, self._num_grads))\n                self._grad_accs.append(grad_acc)\n\n    def _push_pull_grad_group_sync(self, p, num_grads_):\n        if self._is_tensor_instance:\n            name = self._parameter_names.get(p.__hash__())\n        else:\n            name = self._parameter_names.get(p)\n        if self._enable_async:\n            # the real handle will be created in step()\n            handle, ctx = None, None\n        else:\n            tensor = p.grad\n            tensor_compressed, ctx = self._compression.compress(tensor)\n            handle, grad_count = byteps_push_pull_group(tensor_compressed, average=True,\n                    name=""Gradient.""+name)\n        return handle, ctx, grad_count\n\n    def _push_pull_grad_async(self, p):\n        if self._is_tensor_instance:\n            name = self._parameter_names.get(p.__hash__())\n        else:\n            name = self._parameter_names.get(p)\n        if self._enable_async:\n            # the real handle will be created in step()\n            handle, ctx = None, None\n        else:\n            tensor = p.grad\n            tensor_compressed, ctx = self._compression.compress(tensor)\n            handle = byteps_push_pull(tensor_compressed, average=True, name=""Gradient.""+name)\n        return handle, ctx\n\n    def _make_hook(self, p, num_grads):\n        def hook(*ignore):\n            handle, ctx = None, None\n            handle, ctx, grad_count = self._push_pull_grad_group_sync(p, num_grads)\n            self._handles[p] = (handle, ctx)\n            # sync if we have processed all gradients\n            if grad_count == self._num_grads:\n                self.synchronize()\n        return hook\n\n    def synchronize(self):\n        missing_p = self._requires_update - set(self._handles.keys())\n        for p in missing_p:\n            handle, ctx, grad_count = self._push_pull_grad_group_sync(p, self._num_grads)\n            self._handles[p] = (handle, ctx)\n\n        for p, value in self._handles.items():\n            handle, ctx = value\n            if handle is None:\n                handle, ctx, grad_count = self._push_pull_grad_group_sync(p)\n                self._handles[p] = (handle, ctx)\n        for p, (handle, _) in self._handles.items():\n            output = synchronize(handle)\n            if not self._enable_async:\n                p.grad.set_(self._compression.decompress(output, ctx))\n        self._handles.clear()\n'"
example/mxnet/common/__init__.py,0,b''
example/mxnet/common/data.py,0,"b'# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# ""License""); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n\nimport mxnet as mx\nimport random\nfrom mxnet.io import DataBatch, DataIter\nimport numpy as np\n\ndef add_data_args(parser):\n    data = parser.add_argument_group(\'Data\', \'the input images\')\n    data.add_argument(\'--data-train\', type=str, help=\'the training data\')\n    data.add_argument(\'--data-train-idx\', type=str, default=\'\', help=\'the index of training data\')\n    data.add_argument(\'--data-val\', type=str, help=\'the validation data\')\n    data.add_argument(\'--data-val-idx\', type=str, default=\'\', help=\'the index of validation data\')\n    data.add_argument(\'--rgb-mean\', type=str, default=\'123.68,116.779,103.939\',\n                      help=\'a tuple of size 3 for the mean rgb\')\n    data.add_argument(\'--rgb-std\', type=str, default=\'1,1,1\',\n                      help=\'a tuple of size 3 for the std rgb\')\n    data.add_argument(\'--pad-size\', type=int, default=0,\n                      help=\'padding the input image\')\n    data.add_argument(\'--fill-value\', type=int, default=127,\n                      help=\'Set the padding pixels value to fill_value\')\n    data.add_argument(\'--image-shape\', type=str,\n                      help=\'the image shape feed into the network, e.g. (3,224,224)\')\n    data.add_argument(\'--num-classes\', type=int, help=\'the number of classes\')\n    data.add_argument(\'--num-examples\', type=int, help=\'the number of training examples\')\n    data.add_argument(\'--data-nthreads\', type=int, default=4,\n                      help=\'number of threads for data decoding\')\n    data.add_argument(\'--benchmark\', type=int, default=0,\n                      help=\'if 1, then feed the network with synthetic data\')\n    return data\n\ndef add_data_aug_args(parser):\n    aug = parser.add_argument_group(\n        \'Image augmentations\', \'implemented in src/io/image_aug_default.cc\')\n    aug.add_argument(\'--random-crop\', type=int, default=0,\n                     help=\'if or not randomly crop the image\')\n    aug.add_argument(\'--random-mirror\', type=int, default=0,\n                     help=\'if or not randomly flip horizontally\')\n    aug.add_argument(\'--max-random-h\', type=int, default=0,\n                     help=\'max change of hue, whose range is [0, 180]\')\n    aug.add_argument(\'--max-random-s\', type=int, default=0,\n                     help=\'max change of saturation, whose range is [0, 255]\')\n    aug.add_argument(\'--max-random-l\', type=int, default=0,\n                     help=\'max change of intensity, whose range is [0, 255]\')\n    aug.add_argument(\'--min-random-aspect-ratio\', type=float, default=None,\n                     help=\'min value of aspect ratio, whose value is either None or a positive value.\')\n    aug.add_argument(\'--max-random-aspect-ratio\', type=float, default=0,\n                     help=\'max value of aspect ratio. If min_random_aspect_ratio is None, \'\n                          \'the aspect ratio range is [1-max_random_aspect_ratio, \'\n                          \'1+max_random_aspect_ratio], otherwise it is \'\n                          \'[min_random_aspect_ratio, max_random_aspect_ratio].\')\n    aug.add_argument(\'--max-random-rotate-angle\', type=int, default=0,\n                     help=\'max angle to rotate, whose range is [0, 360]\')\n    aug.add_argument(\'--max-random-shear-ratio\', type=float, default=0,\n                     help=\'max ratio to shear, whose range is [0, 1]\')\n    aug.add_argument(\'--max-random-scale\', type=float, default=1,\n                     help=\'max ratio to scale\')\n    aug.add_argument(\'--min-random-scale\', type=float, default=1,\n                     help=\'min ratio to scale, should >= img_size/input_shape. \'\n                          \'otherwise use --pad-size\')\n    aug.add_argument(\'--max-random-area\', type=float, default=1,\n                     help=\'max area to crop in random resized crop, whose range is [0, 1]\')\n    aug.add_argument(\'--min-random-area\', type=float, default=1,\n                     help=\'min area to crop in random resized crop, whose range is [0, 1]\')\n    aug.add_argument(\'--min-crop-size\', type=int, default=-1,\n                     help=\'Crop both width and height into a random size in \'\n                          \'[min_crop_size, max_crop_size]\')\n    aug.add_argument(\'--max-crop-size\', type=int, default=-1,\n                     help=\'Crop both width and height into a random size in \'\n                          \'[min_crop_size, max_crop_size]\')\n    aug.add_argument(\'--brightness\', type=float, default=0,\n                     help=\'brightness jittering, whose range is [0, 1]\')\n    aug.add_argument(\'--contrast\', type=float, default=0,\n                     help=\'contrast jittering, whose range is [0, 1]\')\n    aug.add_argument(\'--saturation\', type=float, default=0,\n                     help=\'saturation jittering, whose range is [0, 1]\')\n    aug.add_argument(\'--pca-noise\', type=float, default=0,\n                     help=\'pca noise, whose range is [0, 1]\')\n    aug.add_argument(\'--random-resized-crop\', type=int, default=0,\n                     help=\'whether to use random resized crop\')\n    return aug\n\nclass SyntheticDataIter(DataIter):\n    def __init__(self, num_classes, data_shape, max_iter, dtype):\n        self.batch_size = data_shape[0]\n        self.cur_iter = 0\n        self.max_iter = max_iter\n        self.dtype = dtype\n        label = np.random.randint(0, num_classes, [self.batch_size,])\n        data = np.random.uniform(-1, 1, data_shape)\n        self.data = mx.nd.array(data, dtype=self.dtype, ctx=mx.Context(\'cpu_pinned\', 0))\n        self.label = mx.nd.array(label, dtype=self.dtype, ctx=mx.Context(\'cpu_pinned\', 0))\n    def __iter__(self):\n        return self\n    @property\n    def provide_data(self):\n        return [mx.io.DataDesc(\'data\', self.data.shape, self.dtype)]\n    @property\n    def provide_label(self):\n        return [mx.io.DataDesc(\'softmax_label\', (self.batch_size,), self.dtype)]\n    def next(self):\n        self.cur_iter += 1\n        if self.cur_iter <= self.max_iter:\n            return DataBatch(data=(self.data,),\n                             label=(self.label,),\n                             pad=0,\n                             index=None,\n                             provide_data=self.provide_data,\n                             provide_label=self.provide_label)\n        else:\n            raise StopIteration\n    def __next__(self):\n        return self.next()\n    def reset(self):\n        self.cur_iter = 0\n\ndef get_rec_iter(args, kv=None):\n    image_shape = tuple([int(l) for l in args.image_shape.split(\',\')])\n    if \'benchmark\' in args and args.benchmark:\n        data_shape = (args.batch_size,) + image_shape\n        train = SyntheticDataIter(args.num_classes, data_shape,\n                args.num_examples / args.batch_size, np.float32)\n        return (train, None)\n    if kv:\n        (rank, nworker) = (kv.rank, kv.num_workers)\n    else:\n        (rank, nworker) = (0, 1)\n    rgb_mean = [float(i) for i in args.rgb_mean.split(\',\')]\n    rgb_std = [float(i) for i in args.rgb_std.split(\',\')]\n    train = mx.io.ImageRecordIter(\n        path_imgrec         = args.data_train,\n        path_imgidx         = args.data_train_idx,\n        label_width         = 1,\n        mean_r              = rgb_mean[0],\n        mean_g              = rgb_mean[1],\n        mean_b              = rgb_mean[2],\n        std_r               = rgb_std[0],\n        std_g               = rgb_std[1],\n        std_b               = rgb_std[2],\n        data_name           = \'data\',\n        label_name          = \'softmax_label\',\n        data_shape          = image_shape,\n        batch_size          = args.batch_size,\n        rand_crop           = args.random_crop,\n        max_random_scale    = args.max_random_scale,\n        pad                 = args.pad_size,\n        fill_value          = args.fill_value,\n        random_resized_crop = args.random_resized_crop,\n        min_random_scale    = args.min_random_scale,\n        max_aspect_ratio    = args.max_random_aspect_ratio,\n        min_aspect_ratio    = args.min_random_aspect_ratio,\n        max_random_area     = args.max_random_area,\n        min_random_area     = args.min_random_area,\n        min_crop_size       = args.min_crop_size,\n        max_crop_size       = args.max_crop_size,\n        brightness          = args.brightness,\n        contrast            = args.contrast,\n        saturation          = args.saturation,\n        pca_noise           = args.pca_noise,\n        random_h            = args.max_random_h,\n        random_s            = args.max_random_s,\n        random_l            = args.max_random_l,\n        max_rotate_angle    = args.max_random_rotate_angle,\n        max_shear_ratio     = args.max_random_shear_ratio,\n        rand_mirror         = args.random_mirror,\n        preprocess_threads  = args.data_nthreads,\n        shuffle             = True,\n        num_parts           = nworker,\n        part_index          = rank)\n    if args.data_val is None:\n        return (train, None)\n    val = mx.io.ImageRecordIter(\n        path_imgrec         = args.data_val,\n        path_imgidx         = args.data_val_idx,\n        label_width         = 1,\n        mean_r              = rgb_mean[0],\n        mean_g              = rgb_mean[1],\n        mean_b              = rgb_mean[2],\n        std_r               = rgb_std[0],\n        std_g               = rgb_std[1],\n        std_b               = rgb_std[2],\n        data_name           = \'data\',\n        label_name          = \'softmax_label\',\n        batch_size          = args.batch_size,\n        data_shape          = image_shape,\n        preprocess_threads  = args.data_nthreads,\n        rand_crop           = False,\n        rand_mirror         = False,\n        num_parts           = nworker,\n        part_index          = rank)\n    return (train, val)\n'"
example/mxnet/common/data_byteps.py,0,"b'# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# ""License""); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n\nimport mxnet as mx\nimport random\nfrom mxnet.io import DataBatch, DataIter\nimport numpy as np\n\ndef add_data_args(parser):\n    data = parser.add_argument_group(\'Data\', \'the input images\')\n    data.add_argument(\'--data-train\', type=str, help=\'the training data\')\n    data.add_argument(\'--data-train-idx\', type=str, default=\'\', help=\'the index of training data\')\n    data.add_argument(\'--data-val\', type=str, help=\'the validation data\')\n    data.add_argument(\'--data-val-idx\', type=str, default=\'\', help=\'the index of validation data\')\n    data.add_argument(\'--rgb-mean\', type=str, default=\'123.68,116.779,103.939\',\n                      help=\'a tuple of size 3 for the mean rgb\')\n    data.add_argument(\'--pad-size\', type=int, default=0,\n                      help=\'padding the input image\')\n    data.add_argument(\'--image-shape\', type=str,\n                      help=\'the image shape feed into the network, e.g. (3,224,224)\')\n    data.add_argument(\'--num-classes\', type=int, help=\'the number of classes\')\n    data.add_argument(\'--num-examples\', type=int, help=\'the number of training examples\')\n    data.add_argument(\'--data-nthreads\', type=int, default=4,\n                      help=\'number of threads for data decoding\')\n    data.add_argument(\'--benchmark\', type=int, default=0,\n                      help=\'if 1, then feed the network with synthetic data\')\n    return data\n\ndef add_data_aug_args(parser):\n    aug = parser.add_argument_group(\n        \'Image augmentations\', \'implemented in src/io/image_aug_default.cc\')\n    aug.add_argument(\'--random-crop\', type=int, default=1,\n                     help=\'if or not randomly crop the image\')\n    aug.add_argument(\'--random-mirror\', type=int, default=1,\n                     help=\'if or not randomly flip horizontally\')\n    aug.add_argument(\'--max-random-h\', type=int, default=0,\n                     help=\'max change of hue, whose range is [0, 180]\')\n    aug.add_argument(\'--max-random-s\', type=int, default=0,\n                     help=\'max change of saturation, whose range is [0, 255]\')\n    aug.add_argument(\'--max-random-l\', type=int, default=0,\n                     help=\'max change of intensity, whose range is [0, 255]\')\n    aug.add_argument(\'--max-random-aspect-ratio\', type=float, default=0,\n                     help=\'max change of aspect ratio, whose range is [0, 1]\')\n    aug.add_argument(\'--max-random-rotate-angle\', type=int, default=0,\n                     help=\'max angle to rotate, whose range is [0, 360]\')\n    aug.add_argument(\'--max-random-shear-ratio\', type=float, default=0,\n                     help=\'max ratio to shear, whose range is [0, 1]\')\n    aug.add_argument(\'--max-random-scale\', type=float, default=1,\n                     help=\'max ratio to scale\')\n    aug.add_argument(\'--min-random-scale\', type=float, default=1,\n                     help=\'min ratio to scale, should >= img_size/input_shape. otherwise use --pad-size\')\n    return aug\n\ndef set_data_aug_level(aug, level):\n    if level >= 1:\n        aug.set_defaults(random_crop=1, random_mirror=1)\n    if level >= 2:\n        aug.set_defaults(max_random_h=36, max_random_s=50, max_random_l=50)\n    if level >= 3:\n        aug.set_defaults(max_random_rotate_angle=10, max_random_shear_ratio=0.1, max_random_aspect_ratio=0.25)\n\n\nclass SyntheticDataIter(DataIter):\n    def __init__(self, num_classes, data_shape, max_iter, dtype):\n        self.batch_size = data_shape[0]\n        self.cur_iter = 0\n        self.max_iter = max_iter\n        self.dtype = dtype\n        label = np.random.randint(0, num_classes, [self.batch_size,])\n        data = np.random.uniform(-1, 1, data_shape)\n        self.data = mx.nd.array(data, dtype=self.dtype, ctx=mx.Context(\'cpu_pinned\', -1))\n        self.label = mx.nd.array(label, dtype=self.dtype, ctx=mx.Context(\'cpu_pinned\', -1))\n    def __iter__(self):\n        return self\n    @property\n    def provide_data(self):\n        return [mx.io.DataDesc(\'data\', self.data.shape, self.dtype)]\n    @property\n    def provide_label(self):\n        return [mx.io.DataDesc(\'softmax_label\', (self.batch_size,), self.dtype)]\n    def next(self):\n        self.cur_iter += 1\n        if self.cur_iter <= self.max_iter:\n            return DataBatch(data=(self.data,),\n                             label=(self.label,),\n                             pad=0,\n                             index=None,\n                             provide_data=self.provide_data,\n                             provide_label=self.provide_label)\n        else:\n            raise StopIteration\n    def __next__(self):\n        return self.next()\n    def reset(self):\n        self.cur_iter = 0\n\ndef get_rec_iter(args, rank=None):\n    image_shape = tuple([int(l) for l in args.image_shape.split(\',\')])\n    if \'benchmark\' in args and args.benchmark:\n        data_shape = (args.batch_size,) + image_shape\n        train = SyntheticDataIter(args.num_classes, data_shape,\n                args.num_examples / args.batch_size, np.float32)\n        return (train, None)\n    if rank:\n        (rank, nworker) = (rank[0], rank[1])\n    else:\n        (rank, nworker) = (0, 1)\n    rgb_mean = [float(i) for i in args.rgb_mean.split(\',\')]\n    train = mx.io.ImageRecordIter(\n        path_imgrec         = args.data_train,\n        path_imgidx         = args.data_train_idx,\n        label_width         = 1,\n        mean_r              = rgb_mean[0],\n        mean_g              = rgb_mean[1],\n        mean_b              = rgb_mean[2],\n        data_name           = \'data\',\n        label_name          = \'softmax_label\',\n        data_shape          = image_shape,\n        batch_size          = args.batch_size,\n        rand_crop           = args.random_crop,\n        max_random_scale    = args.max_random_scale,\n        pad                 = args.pad_size,\n        fill_value          = 127,\n        min_random_scale    = args.min_random_scale,\n        max_aspect_ratio    = args.max_random_aspect_ratio,\n        random_h            = args.max_random_h,\n        random_s            = args.max_random_s,\n        random_l            = args.max_random_l,\n        max_rotate_angle    = args.max_random_rotate_angle,\n        max_shear_ratio     = args.max_random_shear_ratio,\n        rand_mirror         = args.random_mirror,\n        preprocess_threads  = args.data_nthreads,\n        shuffle             = True,\n        num_parts           = nworker,\n        part_index          = rank)\n    if args.data_val is None:\n        return (train, None)\n    val = mx.io.ImageRecordIter(\n        path_imgrec         = args.data_val,\n        path_imgidx         = args.data_val_idx,\n        label_width         = 1,\n        mean_r              = rgb_mean[0],\n        mean_g              = rgb_mean[1],\n        mean_b              = rgb_mean[2],\n        data_name           = \'data\',\n        label_name          = \'softmax_label\',\n        batch_size          = args.batch_size,\n        data_shape          = image_shape,\n        preprocess_threads  = args.data_nthreads,\n        rand_crop           = False,\n        rand_mirror         = False,\n        num_parts           = nworker,\n        part_index          = rank)\n    return (train, val)\n'"
example/mxnet/common/find_mxnet.py,0,"b'# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# ""License""); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n\nimport os, sys\ntry:\n    import mxnet as mx\nexcept ImportError:\n    curr_path = os.path.abspath(os.path.dirname(__file__))\n    sys.path.append(os.path.join(curr_path, ""../../../python""))\n    import mxnet as mx\n'"
example/mxnet/common/fit.py,0,"b'# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# ""License""); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n\n"""""" example train fit utility """"""\nimport logging\nimport os\nimport time\nimport re\nimport math\nimport mxnet as mx\n\ndef get_epoch_size(args, kv):\n    return math.ceil(int(args.num_examples / kv.num_workers) / args.batch_size)\n\ndef _get_lr_scheduler(args, kv):\n    if \'lr_factor\' not in args or args.lr_factor >= 1:\n        return (args.lr, None)\n    epoch_size = get_epoch_size(args, kv)\n    begin_epoch = args.load_epoch if args.load_epoch else 0\n    if \'pow\' in args.lr_step_epochs:\n        lr = args.lr\n        max_up = args.num_epochs * epoch_size\n        pwr = float(re.sub(\'pow[- ]*\', \'\', args.lr_step_epochs))\n        poly_sched = mx.lr_scheduler.PolyScheduler(max_up, lr, pwr)\n        return (lr, poly_sched)\n    step_epochs = [int(l) for l in args.lr_step_epochs.split(\',\')]\n    lr = args.lr\n    for s in step_epochs:\n        if begin_epoch >= s:\n            lr *= args.lr_factor\n    if lr != args.lr:\n        logging.info(\'Adjust learning rate to %e for epoch %d\',\n                     lr, begin_epoch)\n\n    steps = [epoch_size * (x - begin_epoch)\n             for x in step_epochs if x - begin_epoch > 0]\n    if steps:\n        return (lr, mx.lr_scheduler.MultiFactorScheduler(step=steps, factor=args.lr_factor,\n                                                         base_lr=args.lr))\n    else:\n        return (lr, None)\n\ndef _load_model(args, rank=0):\n    if \'load_epoch\' not in args or args.load_epoch is None:\n        return (None, None, None)\n    assert args.model_prefix is not None\n    model_prefix = args.model_prefix\n    if rank > 0 and os.path.exists(""%s-%d-symbol.json"" % (model_prefix, rank)):\n        model_prefix += ""-%d"" % (rank)\n    sym, arg_params, aux_params = mx.model.load_checkpoint(\n        model_prefix, args.load_epoch)\n    logging.info(\'Loaded model %s_%04d.params\', model_prefix, args.load_epoch)\n    return (sym, arg_params, aux_params)\n\n\ndef _save_model(args, rank=0):\n    if args.model_prefix is None:\n        return None\n    return mx.callback.do_checkpoint(args.model_prefix if rank == 0 else ""%s-%d"" % (\n        args.model_prefix, rank), period=args.save_period)\n\n\ndef add_fit_args(parser):\n    """"""\n    parser : argparse.ArgumentParser\n    return a parser added with args required by fit\n    """"""\n    train = parser.add_argument_group(\'Training\', \'model training\')\n    train.add_argument(\'--network\', type=str,\n                       help=\'the neural network to use\')\n    train.add_argument(\'--num-layers\', type=int,\n                       help=\'number of layers in the neural network, \\\n                             required by some networks such as resnet\')\n    train.add_argument(\'--gpus\', type=str,\n                       help=\'list of gpus to run, e.g. 0 or 0,2,5. empty means using cpu\')\n    train.add_argument(\'--kv-store\', type=str, default=\'device\',\n                       help=\'key-value store type\')\n    train.add_argument(\'--num-epochs\', type=int, default=100,\n                       help=\'max num of epochs\')\n    train.add_argument(\'--lr\', type=float, default=0.1,\n                       help=\'initial learning rate\')\n    train.add_argument(\'--lr-factor\', type=float, default=0.1,\n                       help=\'the ratio to reduce lr on each step\')\n    train.add_argument(\'--lr-step-epochs\', type=str,\n                       help=\'the epochs to reduce the lr, e.g. 30,60\')\n    train.add_argument(\'--initializer\', type=str, default=\'default\',\n                       help=\'the initializer type\')\n    train.add_argument(\'--optimizer\', type=str, default=\'sgd\',\n                       help=\'the optimizer type\')\n    train.add_argument(\'--mom\', type=float, default=0.9,\n                       help=\'momentum for sgd\')\n    train.add_argument(\'--wd\', type=float, default=0.0001,\n                       help=\'weight decay for sgd\')\n    train.add_argument(\'--batch-size\', type=int, default=128,\n                       help=\'the batch size\')\n    train.add_argument(\'--disp-batches\', type=int, default=20,\n                       help=\'show progress for every n batches\')\n    train.add_argument(\'--model-prefix\', type=str,\n                       help=\'model prefix\')\n    train.add_argument(\'--save-period\', type=int, default=1, help=\'params saving period\')\n    parser.add_argument(\'--monitor\', dest=\'monitor\', type=int, default=0,\n                        help=\'log network parameters every N iters if larger than 0\')\n    train.add_argument(\'--load-epoch\', type=int,\n                       help=\'load the model on an epoch using the model-load-prefix\')\n    train.add_argument(\'--top-k\', type=int, default=0,\n                       help=\'report the top-k accuracy. 0 means no report.\')\n    train.add_argument(\'--loss\', type=str, default=\'\',\n                       help=\'show the cross-entropy or nll loss. ce strands for cross-entropy, nll-loss stands for likelihood loss\')\n    train.add_argument(\'--test-io\', type=int, default=0,\n                       help=\'1 means test reading speed without training\')\n    train.add_argument(\'--dtype\', type=str, default=\'float32\',\n                       help=\'precision: float32 or float16\')\n    train.add_argument(\'--gc-type\', type=str, default=\'none\',\n                       help=\'type of gradient compression to use, \\\n                             takes `2bit` or `none` for now\')\n    train.add_argument(\'--gc-threshold\', type=float, default=0.5,\n                       help=\'threshold for 2bit gradient compression\')\n    # additional parameters for large batch sgd\n    train.add_argument(\'--macrobatch-size\', type=int, default=0,\n                       help=\'distributed effective batch size\')\n    train.add_argument(\'--warmup-epochs\', type=int, default=5,\n                       help=\'the epochs to ramp-up lr to scaled large-batch value\')\n    train.add_argument(\'--warmup-strategy\', type=str, default=\'linear\',\n                       help=\'the ramping-up strategy for large batch sgd\')\n    train.add_argument(\'--profile-worker-suffix\', type=str, default=\'\',\n                       help=\'profile workers actions into this file. During distributed training\\\n                             filename saved will be rank1_ followed by this suffix\')\n    train.add_argument(\'--profile-server-suffix\', type=str, default=\'\',\n                       help=\'profile server actions into a file with name like rank1_ followed by this suffix \\\n                             during distributed training\')\n    return train\n\n\ndef fit(args, network, data_loader, **kwargs):\n    """"""\n    train a model\n    args : argparse returns\n    network : the symbol definition of the nerual network\n    data_loader : function that returns the train and val data iterators\n    """"""\n    # kvstore\n    kv = mx.kvstore.create(args.kv_store)\n\n    if args.gc_type != \'none\':\n        kv.set_gradient_compression({\'type\': args.gc_type,\n                                     \'threshold\': args.gc_threshold})\n    if args.profile_server_suffix:\n        mx.profiler.set_config(filename=args.profile_server_suffix, profile_all=True, profile_process=\'server\')\n        mx.profiler.set_state(state=\'run\', profile_process=\'server\')\n\n    if args.profile_worker_suffix:\n        if kv.num_workers > 1:\n            filename = \'rank\' + str(kv.rank) + \'_\' + args.profile_worker_suffix\n        else:\n            filename = args.profile_worker_suffix\n        mx.profiler.set_config(filename=filename, profile_all=True, profile_process=\'worker\')\n        mx.profiler.set_state(state=\'run\', profile_process=\'worker\')\n\n    # logging\n    head = \'%(asctime)-15s Node[\' + str(kv.rank) + \'] %(message)s\'\n    logging.basicConfig(level=logging.DEBUG, format=head)\n    logging.info(\'start with arguments %s\', args)\n\n    epoch_size = get_epoch_size(args, kv)\n\n    # data iterators\n    (train, val) = data_loader(args, kv)\n    if \'dist\' in args.kv_store and not \'async\' in args.kv_store:\n        logging.info(\'Resizing training data to %d batches per machine\', epoch_size)\n        # resize train iter to ensure each machine has same number of batches per epoch\n        # if not, dist_sync can hang at the end with one machine waiting for other machines\n        train = mx.io.ResizeIter(train, epoch_size)\n\n    if args.test_io:\n        tic = time.time()\n        for i, batch in enumerate(train):\n            if isinstance(batch, list):\n                for b in batch:\n                    for j in b.data:\n                        j.wait_to_read()\n            else:\n                for j in batch.data:\n                    j.wait_to_read()\n            if (i + 1) % args.disp_batches == 0:\n                logging.info(\'Batch [%d]\\tSpeed: %.2f samples/sec\', i,\n                             args.disp_batches * args.batch_size / (time.time() - tic))\n                tic = time.time()\n        return\n\n    # load model\n    if \'arg_params\' in kwargs and \'aux_params\' in kwargs:\n        arg_params = kwargs[\'arg_params\']\n        aux_params = kwargs[\'aux_params\']\n    else:\n        sym, arg_params, aux_params = _load_model(args, kv.rank)\n        if sym is not None:\n            assert sym.tojson() == network.tojson()\n\n    # save model\n    checkpoint = _save_model(args, kv.rank)\n\n    # devices for training\n    devs = mx.cpu() if args.gpus is None or args.gpus == """" else [\n        mx.gpu(int(i)) for i in args.gpus.split(\',\')]\n\n    # learning rate\n    lr, lr_scheduler = _get_lr_scheduler(args, kv)\n\n    # create model\n    model = mx.mod.Module(\n        context=devs,\n        symbol=network\n    )\n\n    lr_scheduler = lr_scheduler\n    optimizer_params = {\n        \'learning_rate\': lr,\n        \'wd\': args.wd,\n        \'lr_scheduler\': lr_scheduler,\n        \'multi_precision\': True}\n\n    # Only a limited number of optimizers have \'momentum\' property\n    has_momentum = {\'sgd\', \'dcasgd\', \'nag\', \'signum\', \'lbsgd\'}\n    if args.optimizer in has_momentum:\n        optimizer_params[\'momentum\'] = args.mom\n\n    monitor = mx.mon.Monitor(\n        args.monitor, pattern="".*"") if args.monitor > 0 else None\n\n    # A limited number of optimizers have a warmup period\n    has_warmup = {\'lbsgd\', \'lbnag\'}\n    if args.optimizer in has_warmup:\n        nworkers = kv.num_workers\n        if epoch_size < 1:\n            epoch_size = 1\n        macrobatch_size = args.macrobatch_size\n        if macrobatch_size < args.batch_size * nworkers:\n            macrobatch_size = args.batch_size * nworkers\n        #batch_scale = round(float(macrobatch_size) / args.batch_size / nworkers +0.4999)\n        batch_scale = math.ceil(\n            float(macrobatch_size) / args.batch_size / nworkers)\n        optimizer_params[\'updates_per_epoch\'] = epoch_size\n        optimizer_params[\'begin_epoch\'] = args.load_epoch if args.load_epoch else 0\n        optimizer_params[\'batch_scale\'] = batch_scale\n        optimizer_params[\'warmup_strategy\'] = args.warmup_strategy\n        optimizer_params[\'warmup_epochs\'] = args.warmup_epochs\n        optimizer_params[\'num_epochs\'] = args.num_epochs\n\n    if args.initializer == \'default\':\n        if args.network == \'alexnet\':\n            # AlexNet will not converge using Xavier\n            initializer = mx.init.Normal()\n            # VGG will not trend to converge using Xavier-Gaussian\n        elif args.network and \'vgg\' in args.network:\n            initializer = mx.init.Xavier()\n        else:\n            initializer = mx.init.Xavier(\n                rnd_type=\'gaussian\', factor_type=""in"", magnitude=2)\n    # initializer   = mx.init.Xavier(factor_type=""in"", magnitude=2.34),\n    elif args.initializer == \'xavier\':\n        initializer = mx.init.Xavier()\n    elif args.initializer == \'msra\':\n        initializer = mx.init.MSRAPrelu()\n    elif args.initializer == \'orthogonal\':\n        initializer = mx.init.Orthogonal()\n    elif args.initializer == \'normal\':\n        initializer = mx.init.Normal()\n    elif args.initializer == \'uniform\':\n        initializer = mx.init.Uniform()\n    elif args.initializer == \'one\':\n        initializer = mx.init.One()\n    elif args.initializer == \'zero\':\n        initializer = mx.init.Zero()\n\n    # evaluation metrices\n    eval_metrics = [\'accuracy\']\n    if args.top_k > 0:\n        eval_metrics.append(mx.metric.create(\n            \'top_k_accuracy\', top_k=args.top_k))\n\n    supported_loss = [\'ce\', \'nll_loss\']\n    if len(args.loss) > 0:\n        # ce or nll loss is only applicable to softmax output\n        loss_type_list = args.loss.split(\',\')\n        if \'softmax_output\' in network.list_outputs():\n            for loss_type in loss_type_list:\n                loss_type = loss_type.strip()\n                if loss_type == \'nll\':\n                    loss_type = \'nll_loss\'\n                if loss_type not in supported_loss:\n                    logging.warning(loss_type + \' is not an valid loss type, only cross-entropy or \' \\\n                                    \'negative likelihood loss is supported!\')\n                else:\n                    eval_metrics.append(mx.metric.create(loss_type))\n        else:\n            logging.warning(""The output is not softmax_output, loss argument will be skipped!"")\n\n    # callbacks that run after each batch\n    batch_end_callbacks = [mx.callback.Speedometer(\n        args.batch_size, args.disp_batches)]\n    if \'batch_end_callback\' in kwargs:\n        cbs = kwargs[\'batch_end_callback\']\n        batch_end_callbacks += cbs if isinstance(cbs, list) else [cbs]\n\n    # run\n    model.fit(train,\n              begin_epoch=args.load_epoch if args.load_epoch else 0,\n              num_epoch=args.num_epochs,\n              eval_data=val,\n              eval_metric=eval_metrics,\n              kvstore=kv,\n              optimizer=args.optimizer,\n              optimizer_params=optimizer_params,\n              initializer=initializer,\n              arg_params=arg_params,\n              aux_params=aux_params,\n              batch_end_callback=batch_end_callbacks,\n              epoch_end_callback=checkpoint,\n              allow_missing=True,\n              monitor=monitor)\n\n    if args.profile_server_suffix:\n        mx.profiler.set_state(state=\'run\', profile_process=\'server\')\n    if args.profile_worker_suffix:\n        mx.profiler.set_state(state=\'run\', profile_process=\'worker\')'"
example/mxnet/common/fit_byteps.py,0,"b'# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# ""License""); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n\n"""""" example train fit utility """"""\nimport logging\nimport os\nimport time\nimport re\nimport math\nimport byteps.mxnet as bps\nimport mxnet as mx\n\n\ndef _get_lr_scheduler(args):\n    if \'lr_factor\' not in args or args.lr_factor >= 1:\n        return (args.lr, None)\n    epoch_size = args.num_examples / args.batch_size\n    if bps.size() > 1:\n        epoch_size /= bps.size()\n    begin_epoch = args.load_epoch if args.load_epoch else 0\n    if \'pow\' in args.lr_step_epochs:\n        lr = args.lr\n        max_up = args.num_epochs * epoch_size\n        pwr = float(re.sub(\'pow[- ]*\', \'\', args.lr_step_epochs))\n        poly_sched = mx.lr_scheduler.PolyScheduler(max_up, lr, pwr)\n        return (lr, poly_sched)\n    step_epochs = [int(l) for l in args.lr_step_epochs.split(\',\')]\n    lr = args.lr\n    for s in step_epochs:\n        if begin_epoch >= s:\n            lr *= args.lr_factor\n    if lr != args.lr:\n        logging.info(\'Adjust learning rate to %e for epoch %d\',\n                     lr, begin_epoch)\n\n    steps = [epoch_size * (x - begin_epoch)\n             for x in step_epochs if x - begin_epoch > 0]\n    return (lr, mx.lr_scheduler.MultiFactorScheduler(step=steps, factor=args.lr_factor))\n\n\ndef _load_model(args, rank=0):\n    if \'load_epoch\' not in args or args.load_epoch is None:\n        return (None, None, None)\n    assert args.model_prefix is not None\n    model_prefix = args.model_prefix\n    if rank > 0 and os.path.exists(""%s-%d-symbol.json"" % (model_prefix, rank)):\n        model_prefix += ""-%d"" % (rank)\n    sym, arg_params, aux_params = mx.model.load_checkpoint(\n        model_prefix, args.load_epoch)\n    logging.info(\'Loaded model %s_%04d.params\', model_prefix, args.load_epoch)\n    return (sym, arg_params, aux_params)\n\n\ndef _save_model(args, rank=0):\n    if args.model_prefix is None:\n        return None\n    dst_dir = os.path.dirname(args.model_prefix)\n    if not os.path.isdir(dst_dir):\n        os.mkdir(dst_dir)\n    return mx.callback.do_checkpoint(args.model_prefix if rank == 0 else ""%s-%d"" % (\n        args.model_prefix, rank))\n\n\ndef add_fit_args(parser):\n    """"""\n    parser : argparse.ArgumentParser\n    return a parser added with args required by fit\n    """"""\n    train = parser.add_argument_group(\'Training\', \'model training\')\n    train.add_argument(\'--network\', type=str,\n                       help=\'the neural network to use\')\n    train.add_argument(\'--num-layers\', type=int,\n                       help=\'number of layers in the neural network, \\\n                             required by some networks such as resnet\')\n    train.add_argument(\'--kv-store\', type=str, default=\'device\',\n                       help=\'key-value store type\')\n    train.add_argument(\'--num-epochs\', type=int, default=100,\n                       help=\'max num of epochs\')\n    train.add_argument(\'--lr\', type=float, default=0.1,\n                       help=\'initial learning rate\')\n    train.add_argument(\'--lr-factor\', type=float, default=0.1,\n                       help=\'the ratio to reduce lr on each step\')\n    train.add_argument(\'--lr-step-epochs\', type=str,\n                       help=\'the epochs to reduce the lr, e.g. 30,60\')\n    train.add_argument(\'--initializer\', type=str, default=\'default\',\n                       help=\'the initializer type\')\n    train.add_argument(\'--optimizer\', type=str, default=\'sgd\',\n                       help=\'the optimizer type\')\n    train.add_argument(\'--mom\', type=float, default=0.9,\n                       help=\'momentum for sgd\')\n    train.add_argument(\'--wd\', type=float, default=0.0001,\n                       help=\'weight decay for sgd\')\n    train.add_argument(\'--batch-size\', type=int, default=128,\n                       help=\'the batch size\')\n    train.add_argument(\'--disp-batches\', type=int, default=20,\n                       help=\'show progress for every n batches\')\n    train.add_argument(\'--model-prefix\', type=str,\n                       help=\'model prefix\')\n    parser.add_argument(\'--monitor\', dest=\'monitor\', type=int, default=0,\n                        help=\'log network parameters every N iters if larger than 0\')\n    train.add_argument(\'--load-epoch\', type=int,\n                       help=\'load the model on an epoch using the model-load-prefix\')\n    train.add_argument(\'--top-k\', type=int, default=0,\n                       help=\'report the top-k accuracy. 0 means no report.\')\n    train.add_argument(\'--loss\', type=str, default=\'\',\n                       help=\'show the cross-entropy or nll loss. ce strands for cross-entropy, nll-loss stands for likelihood loss\')\n    train.add_argument(\'--test-io\', type=int, default=0,\n                       help=\'1 means test reading speed without training\')\n    train.add_argument(\'--dtype\', type=str, default=\'float32\',\n                       help=\'precision: float32 or float16\')\n    train.add_argument(\'--gc-type\', type=str, default=\'none\',\n                       help=\'type of gradient compression to use, \\\n                             takes `2bit` or `none` for now\')\n    train.add_argument(\'--gc-threshold\', type=float, default=0.5,\n                       help=\'threshold for 2bit gradient compression\')\n    # additional parameters for large batch sgd\n    train.add_argument(\'--macrobatch-size\', type=int, default=0,\n                       help=\'distributed effective batch size\')\n    train.add_argument(\'--warmup-epochs\', type=int, default=5,\n                       help=\'the epochs to ramp-up lr to scaled large-batch value\')\n    train.add_argument(\'--warmup-strategy\', type=str, default=\'linear\',\n                       help=\'the ramping-up strategy for large batch sgd\')\n    train.add_argument(\'--cpu-train\', type=bool, default=False,\n                       help=\'whether to train on CPU, default is on GPU\')\n    return train\n\n\ndef fit(args, network, data_loader, **kwargs):\n    """"""\n    train a model\n    args : argparse returns\n    network : the symbol definition of the nerual network\n    data_loader : function that returns the train and val data iterators\n    """"""\n    # kvstore\n    # kv = mx.kvstore.create(args.kv_store)\n    # if args.gc_type != \'none\':\n    #     kv.set_gradient_compression({\'type\': args.gc_type,\n    #                                  \'threshold\': args.gc_threshold})\n\n    # logging\n    head = \'%(asctime)-15s Node[\' + str(bps.rank()) + \'] %(message)s\'\n    logging.basicConfig(level=logging.DEBUG, format=head)\n    logging.info(\'start with arguments %s\', args)\n\n    # data iterators\n    (train, val) = data_loader(args, (bps.rank(), bps.size()))\n    if args.test_io:\n        tic = time.time()\n        for i, batch in enumerate(train):\n            for j in batch.data:\n                j.wait_to_read()\n            if (i + 1) % args.disp_batches == 0:\n                logging.info(\'Batch [%d]\\tSpeed: %.2f samples/sec\', i,\n                             args.disp_batches * args.batch_size / (time.time() - tic))\n                tic = time.time()\n\n        return\n\n    # load model\n    if \'arg_params\' in kwargs and \'aux_params\' in kwargs:\n        arg_params = kwargs[\'arg_params\']\n        aux_params = kwargs[\'aux_params\']\n    else:\n        sym, arg_params, aux_params = _load_model(args, bps.rank())\n        if sym is not None:\n            assert sym.tojson() == network.tojson()\n\n    # save model\n    checkpoint = _save_model(args, bps.rank())\n\n    # devices for training\n    if args.cpu_train:\n        devs = [mx.cpu(bps.local_rank())]\n    else:\n        logging.info(\'Launch BytePS process on GPU-%d\', bps.local_rank())\n        devs = [mx.gpu(bps.local_rank())]\n\n    # learning rate\n    lr, lr_scheduler = _get_lr_scheduler(args)\n\n    # create model\n    model = mx.mod.Module(\n        context=devs,\n        symbol=network\n    )\n\n    lr_scheduler = lr_scheduler\n    optimizer_params = {\n        \'learning_rate\': lr,\n        \'wd\': args.wd,\n        \'lr_scheduler\': lr_scheduler,\n        \'multi_precision\': True}\n\n    # Only a limited number of optimizers have \'momentum\' property\n    has_momentum = {\'sgd\', \'dcasgd\', \'nag\'}\n    if args.optimizer in has_momentum:\n        optimizer_params[\'momentum\'] = args.mom\n\n    monitor = mx.mon.Monitor(\n        args.monitor, pattern="".*"") if args.monitor > 0 else None\n\n    # A limited number of optimizers have a warmup period\n    has_warmup = {\'lbsgd\', \'lbnag\'}\n    if args.optimizer in has_warmup:\n        if bps.size() > 1:\n            nworkers = bps.size()\n        else:\n            nworkers = 1\n        epoch_size = args.num_examples / args.batch_size / nworkers\n        if epoch_size < 1:\n            epoch_size = 1\n        macrobatch_size = args.macrobatch_size\n        if macrobatch_size < args.batch_size * nworkers:\n            macrobatch_size = args.batch_size * nworkers\n        #batch_scale = round(float(macrobatch_size) / args.batch_size / nworkers +0.4999)\n        batch_scale = math.ceil(\n            float(macrobatch_size) / args.batch_size / nworkers)\n        optimizer_params[\'updates_per_epoch\'] = epoch_size\n        optimizer_params[\'begin_epoch\'] = args.load_epoch if args.load_epoch else 0\n        optimizer_params[\'batch_scale\'] = batch_scale\n        optimizer_params[\'warmup_strategy\'] = args.warmup_strategy\n        optimizer_params[\'warmup_epochs\'] = args.warmup_epochs\n        optimizer_params[\'num_epochs\'] = args.num_epochs\n\n    if args.initializer == \'default\':\n        if args.network == \'alexnet\':\n            # AlexNet will not converge using Xavier\n            initializer = mx.init.Normal()\n            # VGG will not trend to converge using Xavier-Gaussian\n        elif \'vgg\' in args.network:\n            initializer = mx.init.Xavier()\n        else:\n            initializer = mx.init.Xavier(\n                rnd_type=\'gaussian\', factor_type=""in"", magnitude=2)\n    # initializer   = mx.init.Xavier(factor_type=""in"", magnitude=2.34),\n    elif args.initializer == \'xavier\':\n        initializer = mx.init.Xavier()\n    elif args.initializer == \'msra\':\n        initializer = mx.init.MSRAPrelu()\n    elif args.initializer == \'orthogonal\':\n        initializer = mx.init.Orthogonal()\n    elif args.initializer == \'normal\':\n        initializer = mx.init.Normal()\n    elif args.initializer == \'uniform\':\n        initializer = mx.init.Uniform()\n    elif args.initializer == \'one\':\n        initializer = mx.init.One()\n    elif args.initializer == \'zero\':\n        initializer = mx.init.Zero()\n\n    # evaluation metrices\n    eval_metrics = [\'accuracy\']\n    if args.top_k > 0:\n        eval_metrics.append(mx.metric.create(\n            \'top_k_accuracy\', top_k=args.top_k))\n\n    supported_loss = [\'ce\', \'nll_loss\']\n    if len(args.loss) > 0:\n        # ce or nll loss is only applicable to softmax output\n        loss_type_list = args.loss.split(\',\')\n        if \'softmax_output\' in network.list_outputs():\n            for loss_type in loss_type_list:\n                loss_type = loss_type.strip()\n                if loss_type == \'nll\':\n                    loss_type = \'nll_loss\'\n                if loss_type not in supported_loss:\n                    logging.warning(loss_type + \' is not an valid loss type, only cross-entropy or \' \\\n                                    \'negative likelihood loss is supported!\')\n                else:\n                    eval_metrics.append(mx.metric.create(loss_type))\n        else:\n            logging.warning(""The output is not softmax_output, loss argument will be skipped!"")\n\n    # callbacks that run after each batch\n    batch_end_callbacks = [mx.callback.Speedometer(\n        args.batch_size, args.disp_batches)]\n    if \'batch_end_callback\' in kwargs:\n        cbs = kwargs[\'batch_end_callback\']\n        batch_end_callbacks += cbs if isinstance(cbs, list) else [cbs]\n\n    # BytePS wrapper\n    opt = mx.optimizer.create(args.optimizer, sym=network, **optimizer_params)\n    # opt = bps.DistributedOptimizer(opt)\n    print(str(os.environ) + ""============="" + str(bps.rank()))\n\n    # else:\n    opt = bps.DistributedOptimizer(opt)\n\n    # BytePS: better to explicitly init\n\n    model.bind(data_shapes=train.provide_data,\n           label_shapes=train.provide_label)\n    if arg_params is None and aux_params is None:\n        model.init_params(initializer)\n        (arg_params, aux_params) = model.get_params()\n    if arg_params is not None:\n        bps.broadcast_parameters(arg_params, root_rank=0)\n    if aux_params is not None:\n        bps.broadcast_parameters(aux_params, root_rank=0)\n    model.set_params(arg_params=arg_params, aux_params=aux_params)\n\n    # run\n    model.fit(train,\n              begin_epoch=args.load_epoch if args.load_epoch else 0,\n              num_epoch=args.num_epochs,\n              eval_data=val,\n              eval_metric=eval_metrics,\n              kvstore=None,\n              optimizer=opt,\n              optimizer_params=optimizer_params,\n              batch_end_callback=batch_end_callbacks,\n              epoch_end_callback=checkpoint,\n              allow_missing=True,\n              monitor=monitor)\n\n'"
example/mxnet/common/modelzoo.py,0,"b'# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# ""License""); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n\nimport os\nfrom common.util import download_file\n\n_base_model_url = \'http://data.mxnet.io/models/\'\n_default_model_info = {\n    \'imagenet1k-inception-bn\': {\'symbol\':_base_model_url+\'imagenet/inception-bn/Inception-BN-symbol.json\',\n                             \'params\':_base_model_url+\'imagenet/inception-bn/Inception-BN-0126.params\'},\n    \'imagenet1k-resnet-18\': {\'symbol\':_base_model_url+\'imagenet/resnet/18-layers/resnet-18-symbol.json\',\n                             \'params\':_base_model_url+\'imagenet/resnet/18-layers/resnet-18-0000.params\'},\n    \'imagenet1k-resnet-34\': {\'symbol\':_base_model_url+\'imagenet/resnet/34-layers/resnet-34-symbol.json\',\n                             \'params\':_base_model_url+\'imagenet/resnet/34-layers/resnet-34-0000.params\'},\n    \'imagenet1k-resnet-50\': {\'symbol\':_base_model_url+\'imagenet/resnet/50-layers/resnet-50-symbol.json\',\n                             \'params\':_base_model_url+\'imagenet/resnet/50-layers/resnet-50-0000.params\'},\n    \'imagenet1k-resnet-101\': {\'symbol\':_base_model_url+\'imagenet/resnet/101-layers/resnet-101-symbol.json\',\n                             \'params\':_base_model_url+\'imagenet/resnet/101-layers/resnet-101-0000.params\'},\n    \'imagenet1k-resnet-152\': {\'symbol\':_base_model_url+\'imagenet/resnet/152-layers/resnet-152-symbol.json\',\n                             \'params\':_base_model_url+\'imagenet/resnet/152-layers/resnet-152-0000.params\'},\n    \'imagenet1k-resnext-50\': {\'symbol\':_base_model_url+\'imagenet/resnext/50-layers/resnext-50-symbol.json\',\n                             \'params\':_base_model_url+\'imagenet/resnext/50-layers/resnext-50-0000.params\'},\n    \'imagenet1k-resnext-101\': {\'symbol\':_base_model_url+\'imagenet/resnext/101-layers/resnext-101-symbol.json\',\n                             \'params\':_base_model_url+\'imagenet/resnext/101-layers/resnext-101-0000.params\'},\n    \'imagenet1k-resnext-101-64x4d\': {\'symbol\':_base_model_url+\'imagenet/resnext/101-layers/resnext-101-64x4d-symbol.json\',\n                                     \'params\':_base_model_url+\'imagenet/resnext/101-layers/resnext-101-64x4d-0000.params\'},\n    \'imagenet11k-resnet-152\': {\'symbol\':_base_model_url+\'imagenet-11k/resnet-152/resnet-152-symbol.json\',\n                             \'params\':_base_model_url+\'imagenet-11k/resnet-152/resnet-152-0000.params\'},\n    \'imagenet11k-place365ch-resnet-152\': {\'symbol\':_base_model_url+\'imagenet-11k-place365-ch/resnet-152-symbol.json\',\n                                          \'params\':_base_model_url+\'imagenet-11k-place365-ch/resnet-152-0000.params\'},\n    \'imagenet11k-place365ch-resnet-50\': {\'symbol\':_base_model_url+\'imagenet-11k-place365-ch/resnet-50-symbol.json\',\n                                         \'params\':_base_model_url+\'imagenet-11k-place365-ch/resnet-50-0000.params\'},\n}\n\ndef download_model(model_name, dst_dir=\'./\', meta_info=None):\n    if meta_info is None:\n        meta_info = _default_model_info\n    meta_info = dict(meta_info)\n    if model_name not in meta_info:\n        return (None, 0)\n    if not os.path.isdir(dst_dir):\n        os.mkdir(dst_dir)\n    meta = dict(meta_info[model_name])\n    assert \'symbol\' in meta, ""missing symbol url""\n    model_name = os.path.join(dst_dir, model_name)\n    download_file(meta[\'symbol\'], model_name+\'-symbol.json\')\n    assert \'params\' in meta, ""mssing parameter file url""\n    download_file(meta[\'params\'], model_name+\'-0000.params\')\n    return (model_name, 0)\n'"
example/mxnet/common/util.py,0,"b'# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# ""License""); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n\nimport subprocess\nimport os\nimport errno\n\ndef download_file(url, local_fname=None, force_write=False):\n    # requests is not default installed\n    import requests\n    if local_fname is None:\n        local_fname = url.split(\'/\')[-1]\n    if not force_write and os.path.exists(local_fname):\n        return local_fname\n\n    dir_name = os.path.dirname(local_fname)\n\n    if dir_name != """":\n        if not os.path.exists(dir_name):\n            try: # try to create the directory if it doesn\'t exists\n                os.makedirs(dir_name)\n            except OSError as exc:\n                if exc.errno != errno.EEXIST:\n                    raise\n\n    r = requests.get(url, stream=True)\n    assert r.status_code == 200, ""failed to open %s"" % url\n    with open(local_fname, \'wb\') as f:\n        for chunk in r.iter_content(chunk_size=1024):\n            if chunk: # filter out keep-alive new chunks\n                f.write(chunk)\n    return local_fname\n\ndef get_gpus():\n    """"""\n    return a list of GPUs\n    """"""\n    try:\n        re = subprocess.check_output([""nvidia-smi"", ""-L""], universal_newlines=True)\n    except OSError:\n        return []\n    return range(len([i for i in re.split(\'\\n\') if \'GPU\' in i]))\n'"
example/mxnet/symbols/__init__.py,0,b''
example/mxnet/symbols/alexnet.py,0,"b'# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# ""License""); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n\n""""""\nReference:\n\nKrizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. ""Imagenet classification with deep convolutional neural networks."" Advances in neural information processing systems. 2012.\n""""""\nimport mxnet as mx\nimport numpy as np\n\ndef get_symbol(num_classes, dtype=\'float32\', **kwargs):\n    input_data = mx.sym.Variable(name=""data"")\n    if dtype == \'float16\':\n        input_data = mx.sym.Cast(data=input_data, dtype=np.float16)\n    # stage 1\n    conv1 = mx.sym.Convolution(name=\'conv1\',\n        data=input_data, kernel=(11, 11), stride=(4, 4), num_filter=96)\n    relu1 = mx.sym.Activation(data=conv1, act_type=""relu"")\n    lrn1 = mx.sym.LRN(data=relu1, alpha=0.0001, beta=0.75, knorm=2, nsize=5)\n    pool1 = mx.sym.Pooling(\n        data=lrn1, pool_type=""max"", kernel=(3, 3), stride=(2,2))\n    # stage 2\n    conv2 = mx.sym.Convolution(name=\'conv2\',\n        data=pool1, kernel=(5, 5), pad=(2, 2), num_filter=256)\n    relu2 = mx.sym.Activation(data=conv2, act_type=""relu"")\n    lrn2 = mx.sym.LRN(data=relu2, alpha=0.0001, beta=0.75, knorm=2, nsize=5)\n    pool2 = mx.sym.Pooling(data=lrn2, kernel=(3, 3), stride=(2, 2), pool_type=""max"")\n    # stage 3\n    conv3 = mx.sym.Convolution(name=\'conv3\',\n        data=pool2, kernel=(3, 3), pad=(1, 1), num_filter=384)\n    relu3 = mx.sym.Activation(data=conv3, act_type=""relu"")\n    conv4 = mx.sym.Convolution(name=\'conv4\',\n        data=relu3, kernel=(3, 3), pad=(1, 1), num_filter=384)\n    relu4 = mx.sym.Activation(data=conv4, act_type=""relu"")\n    conv5 = mx.sym.Convolution(name=\'conv5\',\n        data=relu4, kernel=(3, 3), pad=(1, 1), num_filter=256)\n    relu5 = mx.sym.Activation(data=conv5, act_type=""relu"")\n    pool3 = mx.sym.Pooling(data=relu5, kernel=(3, 3), stride=(2, 2), pool_type=""max"")\n    # stage 4\n    flatten = mx.sym.Flatten(data=pool3)\n    fc1 = mx.sym.FullyConnected(name=\'fc1\', data=flatten, num_hidden=4096)\n    relu6 = mx.sym.Activation(data=fc1, act_type=""relu"")\n    dropout1 = mx.sym.Dropout(data=relu6, p=0.5)\n    # stage 5\n    fc2 = mx.sym.FullyConnected(name=\'fc2\', data=dropout1, num_hidden=4096)\n    relu7 = mx.sym.Activation(data=fc2, act_type=""relu"")\n    dropout2 = mx.sym.Dropout(data=relu7, p=0.5)\n    # stage 6\n    fc3 = mx.sym.FullyConnected(name=\'fc3\', data=dropout2, num_hidden=num_classes)\n    if dtype == \'float16\':\n        fc3 = mx.sym.Cast(data=fc3, dtype=np.float32)\n    softmax = mx.sym.SoftmaxOutput(data=fc3, name=\'softmax\')\n    return softmax\n'"
example/mxnet/symbols/googlenet.py,0,"b'# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# ""License""); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n\n""""""References:\n\nSzegedy, Christian, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir\nAnguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. ""Going deeper\nwith convolutions."" arXiv preprint arXiv:1409.4842 (2014).\n\n""""""\n\nimport mxnet as mx\n\ndef ConvFactory(data, num_filter, kernel, stride=(1,1), pad=(0, 0), name=None, suffix=\'\'):\n    conv = mx.symbol.Convolution(data=data, num_filter=num_filter, kernel=kernel, stride=stride, pad=pad, name=\'conv_%s%s\' %(name, suffix))\n    act = mx.symbol.Activation(data=conv, act_type=\'relu\', name=\'relu_%s%s\' %(name, suffix))\n    return act\n\ndef InceptionFactory(data, num_1x1, num_3x3red, num_3x3, num_d5x5red, num_d5x5, pool, proj, name):\n    # 1x1\n    c1x1 = ConvFactory(data=data, num_filter=num_1x1, kernel=(1, 1), name=(\'%s_1x1\' % name))\n    # 3x3 reduce + 3x3\n    c3x3r = ConvFactory(data=data, num_filter=num_3x3red, kernel=(1, 1), name=(\'%s_3x3\' % name), suffix=\'_reduce\')\n    c3x3 = ConvFactory(data=c3x3r, num_filter=num_3x3, kernel=(3, 3), pad=(1, 1), name=(\'%s_3x3\' % name))\n    # double 3x3 reduce + double 3x3\n    cd5x5r = ConvFactory(data=data, num_filter=num_d5x5red, kernel=(1, 1), name=(\'%s_5x5\' % name), suffix=\'_reduce\')\n    cd5x5 = ConvFactory(data=cd5x5r, num_filter=num_d5x5, kernel=(5, 5), pad=(2, 2), name=(\'%s_5x5\' % name))\n    # pool + proj\n    pooling = mx.symbol.Pooling(data=data, kernel=(3, 3), stride=(1, 1), pad=(1, 1), pool_type=pool, name=(\'%s_pool_%s_pool\' % (pool, name)))\n    cproj = ConvFactory(data=pooling, num_filter=proj, kernel=(1, 1), name=(\'%s_proj\' %  name))\n    # concat\n    concat = mx.symbol.Concat(*[c1x1, c3x3, cd5x5, cproj], name=\'ch_concat_%s_chconcat\' % name)\n    return concat\n\ndef get_symbol(num_classes = 1000, **kwargs):\n    data = mx.sym.Variable(""data"")\n    conv1 = ConvFactory(data, 64, kernel=(7, 7), stride=(2,2), pad=(3, 3), name=""conv1"")\n    pool1 = mx.sym.Pooling(conv1, kernel=(3, 3), stride=(2, 2), pool_type=""max"")\n    conv2 = ConvFactory(pool1, 64, kernel=(1, 1), stride=(1,1), name=""conv2"")\n    conv3 = ConvFactory(conv2, 192, kernel=(3, 3), stride=(1, 1), pad=(1,1), name=""conv3"")\n    pool3 = mx.sym.Pooling(conv3, kernel=(3, 3), stride=(2, 2), pool_type=""max"")\n\n    in3a = InceptionFactory(pool3, 64, 96, 128, 16, 32, ""max"", 32, name=""in3a"")\n    in3b = InceptionFactory(in3a, 128, 128, 192, 32, 96, ""max"", 64, name=""in3b"")\n    pool4 = mx.sym.Pooling(in3b, kernel=(3, 3), stride=(2, 2), pool_type=""max"")\n    in4a = InceptionFactory(pool4, 192, 96, 208, 16, 48, ""max"", 64, name=""in4a"")\n    in4b = InceptionFactory(in4a, 160, 112, 224, 24, 64, ""max"", 64, name=""in4b"")\n    in4c = InceptionFactory(in4b, 128, 128, 256, 24, 64, ""max"", 64, name=""in4c"")\n    in4d = InceptionFactory(in4c, 112, 144, 288, 32, 64, ""max"", 64, name=""in4d"")\n    in4e = InceptionFactory(in4d, 256, 160, 320, 32, 128, ""max"", 128, name=""in4e"")\n    pool5 = mx.sym.Pooling(in4e, kernel=(3, 3), stride=(2, 2), pool_type=""max"")\n    in5a = InceptionFactory(pool5, 256, 160, 320, 32, 128, ""max"", 128, name=""in5a"")\n    in5b = InceptionFactory(in5a, 384, 192, 384, 48, 128, ""max"", 128, name=""in5b"")\n    pool6 = mx.sym.Pooling(in5b, kernel=(7, 7), stride=(1,1), global_pool=True, pool_type=""avg"")\n    flatten = mx.sym.Flatten(data=pool6)\n    fc1 = mx.sym.FullyConnected(data=flatten, num_hidden=num_classes)\n    softmax = mx.symbol.SoftmaxOutput(data=fc1, name=\'softmax\')\n    return softmax\n'"
example/mxnet/symbols/inception-bn.py,0,"b'# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# ""License""); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n\n""""""\n\nInception + BN, suitable for images with around 224 x 224\n\nReference:\n\nSergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep\nnetwork training by reducing internal covariate shift. arXiv preprint\narXiv:1502.03167, 2015.\n\n""""""\nimport mxnet as mx\n\neps = 1e-10 + 1e-5\nbn_mom = 0.9\nfix_gamma = False\n\n\ndef ConvFactory(data, num_filter, kernel, stride=(1,1), pad=(0, 0), name=None, suffix=\'\', attr={}):\n    conv = mx.symbol.Convolution(data=data, num_filter=num_filter, kernel=kernel, stride=stride, pad=pad, name=\'conv_%s%s\' %(name, suffix))\n    bn = mx.symbol.BatchNorm(data=conv, fix_gamma=fix_gamma, eps=eps, momentum=bn_mom, name=\'bn_%s%s\' %(name, suffix))\n    act = mx.symbol.Activation(data=bn, act_type=\'relu\', name=\'relu_%s%s\' %(name, suffix), attr=attr)\n    return act\n\ndef InceptionFactoryA(data, num_1x1, num_3x3red, num_3x3, num_d3x3red, num_d3x3, pool, proj, name):\n    # 1x1\n    c1x1 = ConvFactory(data=data, num_filter=num_1x1, kernel=(1, 1), name=(\'%s_1x1\' % name))\n    # 3x3 reduce + 3x3\n    c3x3r = ConvFactory(data=data, num_filter=num_3x3red, kernel=(1, 1), name=(\'%s_3x3\' % name), suffix=\'_reduce\')\n    c3x3 = ConvFactory(data=c3x3r, num_filter=num_3x3, kernel=(3, 3), pad=(1, 1), name=(\'%s_3x3\' % name))\n    # double 3x3 reduce + double 3x3\n    cd3x3r = ConvFactory(data=data, num_filter=num_d3x3red, kernel=(1, 1), name=(\'%s_double_3x3\' % name), suffix=\'_reduce\')\n    cd3x3 = ConvFactory(data=cd3x3r, num_filter=num_d3x3, kernel=(3, 3), pad=(1, 1), name=(\'%s_double_3x3_0\' % name))\n    cd3x3 = ConvFactory(data=cd3x3, num_filter=num_d3x3, kernel=(3, 3), pad=(1, 1), name=(\'%s_double_3x3_1\' % name))\n    # pool + proj\n    pooling = mx.symbol.Pooling(data=data, kernel=(3, 3), stride=(1, 1), pad=(1, 1), pool_type=pool, name=(\'%s_pool_%s_pool\' % (pool, name)))\n    cproj = ConvFactory(data=pooling, num_filter=proj, kernel=(1, 1), name=(\'%s_proj\' %  name))\n    # concat\n    concat = mx.symbol.Concat(*[c1x1, c3x3, cd3x3, cproj], name=\'ch_concat_%s_chconcat\' % name)\n    return concat\n\ndef InceptionFactoryB(data, num_3x3red, num_3x3, num_d3x3red, num_d3x3, name):\n    # 3x3 reduce + 3x3\n    c3x3r = ConvFactory(data=data, num_filter=num_3x3red, kernel=(1, 1), name=(\'%s_3x3\' % name), suffix=\'_reduce\')\n    c3x3 = ConvFactory(data=c3x3r, num_filter=num_3x3, kernel=(3, 3), pad=(1, 1), stride=(2, 2), name=(\'%s_3x3\' % name))\n    # double 3x3 reduce + double 3x3\n    cd3x3r = ConvFactory(data=data, num_filter=num_d3x3red, kernel=(1, 1),  name=(\'%s_double_3x3\' % name), suffix=\'_reduce\')\n    cd3x3 = ConvFactory(data=cd3x3r, num_filter=num_d3x3, kernel=(3, 3), pad=(1, 1), stride=(1, 1), name=(\'%s_double_3x3_0\' % name))\n    cd3x3 = ConvFactory(data=cd3x3, num_filter=num_d3x3, kernel=(3, 3), pad=(1, 1), stride=(2, 2), name=(\'%s_double_3x3_1\' % name))\n    # pool + proj\n    pooling = mx.symbol.Pooling(data=data, kernel=(3, 3), stride=(2, 2), pad=(1, 1), pool_type=""max"", name=(\'max_pool_%s_pool\' % name))\n    # concat\n    concat = mx.symbol.Concat(*[c3x3, cd3x3, pooling], name=\'ch_concat_%s_chconcat\' % name)\n    return concat\n\n# A Simple Downsampling Factory\ndef DownsampleFactory(data, ch_3x3, name, attr):\n    # conv 3x3\n    conv = ConvFactory(data=data, name=name+\'_conv\',kernel=(3, 3), stride=(2, 2), num_filter=ch_3x3, pad=(1, 1), attr=attr)\n    # pool\n    pool = mx.symbol.Pooling(data=data, name=name+\'_pool\',kernel=(3, 3), stride=(2, 2), pad=(1, 1), pool_type=\'max\', attr=attr)\n    # concat\n    concat = mx.symbol.Concat(*[conv, pool], name=name+\'_ch_concat\')\n    return concat\n\n# A Simple module\ndef SimpleFactory(data, ch_1x1, ch_3x3, name, attr):\n    # 1x1\n    conv1x1 = ConvFactory(data=data, name=name+\'_1x1\', kernel=(1, 1), pad=(0, 0), num_filter=ch_1x1, attr=attr)\n    # 3x3\n    conv3x3 = ConvFactory(data=data, name=name+\'_3x3\', kernel=(3, 3), pad=(1, 1), num_filter=ch_3x3, attr=attr)\n    #concat\n    concat = mx.symbol.Concat(*[conv1x1, conv3x3], name=name+\'_ch_concat\')\n    return concat\n\n\ndef get_symbol(num_classes, image_shape, **kwargs):\n    image_shape = [int(l) for l in image_shape.split(\',\')]\n    (nchannel, height, width) = image_shape\n    # attr = {\'force_mirroring\': \'true\'}\n    attr = {}\n\n    # data\n    data = mx.symbol.Variable(name=""data"")\n    if height <= 28:\n        # a simper version\n        conv1 = ConvFactory(data=data, kernel=(3,3), pad=(1,1), name=""1"", num_filter=96, attr=attr)\n        in3a = SimpleFactory(conv1, 32, 32, \'in3a\', attr)\n        in3b = SimpleFactory(in3a, 32, 48, \'in3b\', attr)\n        in3c = DownsampleFactory(in3b, 80, \'in3c\', attr)\n        in4a = SimpleFactory(in3c, 112, 48, \'in4a\', attr)\n        in4b = SimpleFactory(in4a, 96, 64, \'in4b\', attr)\n        in4c = SimpleFactory(in4b, 80, 80, \'in4c\', attr)\n        in4d = SimpleFactory(in4c, 48, 96, \'in4d\', attr)\n        in4e = DownsampleFactory(in4d, 96, \'in4e\', attr)\n        in5a = SimpleFactory(in4e, 176, 160, \'in5a\', attr)\n        in5b = SimpleFactory(in5a, 176, 160, \'in5b\', attr)\n        pool = mx.symbol.Pooling(data=in5b, pool_type=""avg"", kernel=(7,7), name=""global_pool"", attr=attr)\n    else:\n        # stage 1\n        conv1 = ConvFactory(data=data, num_filter=64, kernel=(7, 7), stride=(2, 2), pad=(3, 3), name=\'1\')\n        pool1 = mx.symbol.Pooling(data=conv1, kernel=(3, 3), stride=(2, 2), name=\'pool_1\', pool_type=\'max\')\n        # stage 2\n        conv2red = ConvFactory(data=pool1, num_filter=64, kernel=(1, 1), stride=(1, 1), name=\'2_red\')\n        conv2 = ConvFactory(data=conv2red, num_filter=192, kernel=(3, 3), stride=(1, 1), pad=(1, 1), name=\'2\')\n        pool2 = mx.symbol.Pooling(data=conv2, kernel=(3, 3), stride=(2, 2), name=\'pool_2\', pool_type=\'max\')\n        # stage 2\n        in3a = InceptionFactoryA(pool2, 64, 64, 64, 64, 96, ""avg"", 32, \'3a\')\n        in3b = InceptionFactoryA(in3a, 64, 64, 96, 64, 96, ""avg"", 64, \'3b\')\n        in3c = InceptionFactoryB(in3b, 128, 160, 64, 96, \'3c\')\n        # stage 3\n        in4a = InceptionFactoryA(in3c, 224, 64, 96, 96, 128, ""avg"", 128, \'4a\')\n        in4b = InceptionFactoryA(in4a, 192, 96, 128, 96, 128, ""avg"", 128, \'4b\')\n        in4c = InceptionFactoryA(in4b, 160, 128, 160, 128, 160, ""avg"", 128, \'4c\')\n        in4d = InceptionFactoryA(in4c, 96, 128, 192, 160, 192, ""avg"", 128, \'4d\')\n        in4e = InceptionFactoryB(in4d, 128, 192, 192, 256, \'4e\')\n        # stage 4\n        in5a = InceptionFactoryA(in4e, 352, 192, 320, 160, 224, ""avg"", 128, \'5a\')\n        in5b = InceptionFactoryA(in5a, 352, 192, 320, 192, 224, ""max"", 128, \'5b\')\n        # global avg pooling\n        pool = mx.symbol.Pooling(data=in5b, kernel=(7, 7), stride=(1, 1), name=""global_pool"", pool_type=\'avg\')\n\n    # linear classifier\n    flatten = mx.symbol.Flatten(data=pool)\n    fc1 = mx.symbol.FullyConnected(data=flatten, num_hidden=num_classes)\n    softmax = mx.symbol.SoftmaxOutput(data=fc1, name=\'softmax\')\n    return softmax\n'"
example/mxnet/symbols/inception-resnet-v2.py,0,"b'# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# ""License""); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n\n""""""\nContains the definition of the Inception Resnet V2 architecture.\nAs described in http://arxiv.org/abs/1602.07261.\nInception-v4, Inception-ResNet and the Impact of Residual Connections\non Learning\nChristian Szegedy, Sergey Ioffe, Vincent Vanhoucke, Alex Alemi\n""""""\nimport mxnet as mx\n\n\ndef ConvFactory(data, num_filter, kernel, stride=(1, 1), pad=(0, 0), act_type=""relu"", mirror_attr={}, with_act=True):\n    conv = mx.symbol.Convolution(\n        data=data, num_filter=num_filter, kernel=kernel, stride=stride, pad=pad)\n    bn = mx.symbol.BatchNorm(data=conv)\n    if with_act:\n        act = mx.symbol.Activation(\n            data=bn, act_type=act_type, attr=mirror_attr)\n        return act\n    else:\n        return bn\n\n\ndef block35(net, input_num_channels, scale=1.0, with_act=True, act_type=\'relu\', mirror_attr={}):\n    tower_conv = ConvFactory(net, 32, (1, 1))\n    tower_conv1_0 = ConvFactory(net, 32, (1, 1))\n    tower_conv1_1 = ConvFactory(tower_conv1_0, 32, (3, 3), pad=(1, 1))\n    tower_conv2_0 = ConvFactory(net, 32, (1, 1))\n    tower_conv2_1 = ConvFactory(tower_conv2_0, 48, (3, 3), pad=(1, 1))\n    tower_conv2_2 = ConvFactory(tower_conv2_1, 64, (3, 3), pad=(1, 1))\n    tower_mixed = mx.symbol.Concat(*[tower_conv, tower_conv1_1, tower_conv2_2])\n    tower_out = ConvFactory(\n        tower_mixed, input_num_channels, (1, 1), with_act=False)\n\n    net = net + scale * tower_out\n    if with_act:\n        act = mx.symbol.Activation(\n            data=net, act_type=act_type, attr=mirror_attr)\n        return act\n    else:\n        return net\n\n\ndef block17(net, input_num_channels, scale=1.0, with_act=True, act_type=\'relu\', mirror_attr={}):\n    tower_conv = ConvFactory(net, 192, (1, 1))\n    tower_conv1_0 = ConvFactory(net, 129, (1, 1))\n    tower_conv1_1 = ConvFactory(tower_conv1_0, 160, (1, 7), pad=(1, 2))\n    tower_conv1_2 = ConvFactory(tower_conv1_1, 192, (7, 1), pad=(2, 1))\n    tower_mixed = mx.symbol.Concat(*[tower_conv, tower_conv1_2])\n    tower_out = ConvFactory(\n        tower_mixed, input_num_channels, (1, 1), with_act=False)\n    net = net + scale * tower_out\n    if with_act:\n        act = mx.symbol.Activation(\n            data=net, act_type=act_type, attr=mirror_attr)\n        return act\n    else:\n        return net\n\n\ndef block8(net, input_num_channels, scale=1.0, with_act=True, act_type=\'relu\', mirror_attr={}):\n    tower_conv = ConvFactory(net, 192, (1, 1))\n    tower_conv1_0 = ConvFactory(net, 192, (1, 1))\n    tower_conv1_1 = ConvFactory(tower_conv1_0, 224, (1, 3), pad=(0, 1))\n    tower_conv1_2 = ConvFactory(tower_conv1_1, 256, (3, 1), pad=(1, 0))\n    tower_mixed = mx.symbol.Concat(*[tower_conv, tower_conv1_2])\n    tower_out = ConvFactory(\n        tower_mixed, input_num_channels, (1, 1), with_act=False)\n    net = net + scale * tower_out\n    if with_act:\n        act = mx.symbol.Activation(\n            data=net, act_type=act_type, attr=mirror_attr)\n        return act\n    else:\n        return net\n\n\ndef repeat(inputs, repetitions, layer, *args, **kwargs):\n    outputs = inputs\n    for i in range(repetitions):\n        outputs = layer(outputs, *args, **kwargs)\n    return outputs\n\n\ndef get_symbol(num_classes=1000, **kwargs):\n    data = mx.symbol.Variable(name=\'data\')\n    conv1a_3_3 = ConvFactory(data=data, num_filter=32,\n                             kernel=(3, 3), stride=(2, 2))\n    conv2a_3_3 = ConvFactory(conv1a_3_3, 32, (3, 3))\n    conv2b_3_3 = ConvFactory(conv2a_3_3, 64, (3, 3), pad=(1, 1))\n    maxpool3a_3_3 = mx.symbol.Pooling(\n        data=conv2b_3_3, kernel=(3, 3), stride=(2, 2), pool_type=\'max\')\n    conv3b_1_1 = ConvFactory(maxpool3a_3_3, 80, (1, 1))\n    conv4a_3_3 = ConvFactory(conv3b_1_1, 192, (3, 3))\n    maxpool5a_3_3 = mx.symbol.Pooling(\n        data=conv4a_3_3, kernel=(3, 3), stride=(2, 2), pool_type=\'max\')\n\n    tower_conv = ConvFactory(maxpool5a_3_3, 96, (1, 1))\n    tower_conv1_0 = ConvFactory(maxpool5a_3_3, 48, (1, 1))\n    tower_conv1_1 = ConvFactory(tower_conv1_0, 64, (5, 5), pad=(2, 2))\n\n    tower_conv2_0 = ConvFactory(maxpool5a_3_3, 64, (1, 1))\n    tower_conv2_1 = ConvFactory(tower_conv2_0, 96, (3, 3), pad=(1, 1))\n    tower_conv2_2 = ConvFactory(tower_conv2_1, 96, (3, 3), pad=(1, 1))\n\n    tower_pool3_0 = mx.symbol.Pooling(data=maxpool5a_3_3, kernel=(\n        3, 3), stride=(1, 1), pad=(1, 1), pool_type=\'avg\')\n    tower_conv3_1 = ConvFactory(tower_pool3_0, 64, (1, 1))\n    tower_5b_out = mx.symbol.Concat(\n        *[tower_conv, tower_conv1_1, tower_conv2_2, tower_conv3_1])\n    net = repeat(tower_5b_out, 10, block35, scale=0.17, input_num_channels=320)\n    tower_conv = ConvFactory(net, 384, (3, 3), stride=(2, 2))\n    tower_conv1_0 = ConvFactory(net, 256, (1, 1))\n    tower_conv1_1 = ConvFactory(tower_conv1_0, 256, (3, 3), pad=(1, 1))\n    tower_conv1_2 = ConvFactory(tower_conv1_1, 384, (3, 3), stride=(2, 2))\n    tower_pool = mx.symbol.Pooling(net, kernel=(\n        3, 3), stride=(2, 2), pool_type=\'max\')\n    net = mx.symbol.Concat(*[tower_conv, tower_conv1_2, tower_pool])\n    net = repeat(net, 20, block17, scale=0.1, input_num_channels=1088)\n    tower_conv = ConvFactory(net, 256, (1, 1))\n    tower_conv0_1 = ConvFactory(tower_conv, 384, (3, 3), stride=(2, 2))\n    tower_conv1 = ConvFactory(net, 256, (1, 1))\n    tower_conv1_1 = ConvFactory(tower_conv1, 288, (3, 3), stride=(2, 2))\n    tower_conv2 = ConvFactory(net, 256, (1, 1))\n    tower_conv2_1 = ConvFactory(tower_conv2, 288, (3, 3), pad=(1, 1))\n    tower_conv2_2 = ConvFactory(tower_conv2_1, 320, (3, 3),  stride=(2, 2))\n    tower_pool = mx.symbol.Pooling(net, kernel=(\n        3, 3), stride=(2, 2), pool_type=\'max\')\n    net = mx.symbol.Concat(\n        *[tower_conv0_1, tower_conv1_1, tower_conv2_2, tower_pool])\n\n    net = repeat(net, 9, block8, scale=0.2, input_num_channels=2080)\n    net = block8(net, with_act=False, input_num_channels=2080)\n\n    net = ConvFactory(net, 1536, (1, 1))\n    net = mx.symbol.Pooling(net, kernel=(\n        1, 1), global_pool=True, stride=(2, 2), pool_type=\'avg\')\n    net = mx.symbol.Flatten(net)\n    net = mx.symbol.Dropout(data=net, p=0.2)\n    net = mx.symbol.FullyConnected(data=net, num_hidden=num_classes)\n    softmax = mx.symbol.SoftmaxOutput(data=net, name=\'softmax\')\n    return softmax\n'"
example/mxnet/symbols/inception-v3.py,0,"b'# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# ""License""); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n\n""""""\nInception V3, suitable for images with around 299 x 299\n\nReference:\n\nSzegedy, Christian, et al. ""Rethinking the Inception Architecture for Computer Vision."" arXiv preprint arXiv:1512.00567 (2015).\n""""""\nimport mxnet as mx\nimport numpy as np\n\ndef Conv(data, num_filter, kernel=(1, 1), stride=(1, 1), pad=(0, 0), name=None, suffix=\'\'):\n    conv = mx.sym.Convolution(data=data, num_filter=num_filter, kernel=kernel, stride=stride, pad=pad, no_bias=True, name=\'%s%s_conv2d\' %(name, suffix))\n    bn = mx.sym.BatchNorm(data=conv, name=\'%s%s_batchnorm\' %(name, suffix), fix_gamma=True)\n    act = mx.sym.Activation(data=bn, act_type=\'relu\', name=\'%s%s_relu\' %(name, suffix))\n    return act\n\n\ndef Inception7A(data,\n                num_1x1,\n                num_3x3_red, num_3x3_1, num_3x3_2,\n                num_5x5_red, num_5x5,\n                pool, proj,\n                name):\n    tower_1x1 = Conv(data, num_1x1, name=(\'%s_conv\' % name))\n    tower_5x5 = Conv(data, num_5x5_red, name=(\'%s_tower\' % name), suffix=\'_conv\')\n    tower_5x5 = Conv(tower_5x5, num_5x5, kernel=(5, 5), pad=(2, 2), name=(\'%s_tower\' % name), suffix=\'_conv_1\')\n    tower_3x3 = Conv(data, num_3x3_red, name=(\'%s_tower_1\' % name), suffix=\'_conv\')\n    tower_3x3 = Conv(tower_3x3, num_3x3_1, kernel=(3, 3), pad=(1, 1), name=(\'%s_tower_1\' % name), suffix=\'_conv_1\')\n    tower_3x3 = Conv(tower_3x3, num_3x3_2, kernel=(3, 3), pad=(1, 1), name=(\'%s_tower_1\' % name), suffix=\'_conv_2\')\n    pooling = mx.sym.Pooling(data=data, kernel=(3, 3), stride=(1, 1), pad=(1, 1), pool_type=pool, name=(\'%s_pool_%s_pool\' % (pool, name)))\n    cproj = Conv(pooling, proj, name=(\'%s_tower_2\' %  name), suffix=\'_conv\')\n    concat = mx.sym.Concat(*[tower_1x1, tower_5x5, tower_3x3, cproj], name=\'ch_concat_%s_chconcat\' % name)\n    return concat\n\n# First Downsample\ndef Inception7B(data,\n                num_3x3,\n                num_d3x3_red, num_d3x3_1, num_d3x3_2,\n                pool,\n                name):\n    tower_3x3 = Conv(data, num_3x3, kernel=(3, 3), pad=(0, 0), stride=(2, 2), name=(\'%s_conv\' % name))\n    tower_d3x3 = Conv(data, num_d3x3_red, name=(\'%s_tower\' % name), suffix=\'_conv\')\n    tower_d3x3 = Conv(tower_d3x3, num_d3x3_1, kernel=(3, 3), pad=(1, 1), stride=(1, 1), name=(\'%s_tower\' % name), suffix=\'_conv_1\')\n    tower_d3x3 = Conv(tower_d3x3, num_d3x3_2, kernel=(3, 3), pad=(0, 0), stride=(2, 2), name=(\'%s_tower\' % name), suffix=\'_conv_2\')\n    pooling = mx.sym.Pooling(data=data, kernel=(3, 3), stride=(2, 2), pad=(0,0), pool_type=""max"", name=(\'max_pool_%s_pool\' % name))\n    concat = mx.sym.Concat(*[tower_3x3, tower_d3x3, pooling], name=\'ch_concat_%s_chconcat\' % name)\n    return concat\n\ndef Inception7C(data,\n                num_1x1,\n                num_d7_red, num_d7_1, num_d7_2,\n                num_q7_red, num_q7_1, num_q7_2, num_q7_3, num_q7_4,\n                pool, proj,\n                name):\n    tower_1x1 = Conv(data=data, num_filter=num_1x1, kernel=(1, 1), name=(\'%s_conv\' % name))\n    tower_d7 = Conv(data=data, num_filter=num_d7_red, name=(\'%s_tower\' % name), suffix=\'_conv\')\n    tower_d7 = Conv(data=tower_d7, num_filter=num_d7_1, kernel=(1, 7), pad=(0, 3), name=(\'%s_tower\' % name), suffix=\'_conv_1\')\n    tower_d7 = Conv(data=tower_d7, num_filter=num_d7_2, kernel=(7, 1), pad=(3, 0), name=(\'%s_tower\' % name), suffix=\'_conv_2\')\n    tower_q7 = Conv(data=data, num_filter=num_q7_red, name=(\'%s_tower_1\' % name), suffix=\'_conv\')\n    tower_q7 = Conv(data=tower_q7, num_filter=num_q7_1, kernel=(7, 1), pad=(3, 0), name=(\'%s_tower_1\' % name), suffix=\'_conv_1\')\n    tower_q7 = Conv(data=tower_q7, num_filter=num_q7_2, kernel=(1, 7), pad=(0, 3), name=(\'%s_tower_1\' % name), suffix=\'_conv_2\')\n    tower_q7 = Conv(data=tower_q7, num_filter=num_q7_3, kernel=(7, 1), pad=(3, 0), name=(\'%s_tower_1\' % name), suffix=\'_conv_3\')\n    tower_q7 = Conv(data=tower_q7, num_filter=num_q7_4, kernel=(1, 7), pad=(0, 3), name=(\'%s_tower_1\' % name), suffix=\'_conv_4\')\n    pooling = mx.sym.Pooling(data=data, kernel=(3, 3), stride=(1, 1), pad=(1, 1), pool_type=pool, name=(\'%s_pool_%s_pool\' % (pool, name)))\n    cproj = Conv(data=pooling, num_filter=proj, kernel=(1, 1), name=(\'%s_tower_2\' %  name), suffix=\'_conv\')\n    # concat\n    concat = mx.sym.Concat(*[tower_1x1, tower_d7, tower_q7, cproj], name=\'ch_concat_%s_chconcat\' % name)\n    return concat\n\ndef Inception7D(data,\n                num_3x3_red, num_3x3,\n                num_d7_3x3_red, num_d7_1, num_d7_2, num_d7_3x3,\n                pool,\n                name):\n    tower_3x3 = Conv(data=data, num_filter=num_3x3_red, name=(\'%s_tower\' % name), suffix=\'_conv\')\n    tower_3x3 = Conv(data=tower_3x3, num_filter=num_3x3, kernel=(3, 3), pad=(0,0), stride=(2, 2), name=(\'%s_tower\' % name), suffix=\'_conv_1\')\n    tower_d7_3x3 = Conv(data=data, num_filter=num_d7_3x3_red, name=(\'%s_tower_1\' % name), suffix=\'_conv\')\n    tower_d7_3x3 = Conv(data=tower_d7_3x3, num_filter=num_d7_1, kernel=(1, 7), pad=(0, 3), name=(\'%s_tower_1\' % name), suffix=\'_conv_1\')\n    tower_d7_3x3 = Conv(data=tower_d7_3x3, num_filter=num_d7_2, kernel=(7, 1), pad=(3, 0), name=(\'%s_tower_1\' % name), suffix=\'_conv_2\')\n    tower_d7_3x3 = Conv(data=tower_d7_3x3, num_filter=num_d7_3x3, kernel=(3, 3), stride=(2, 2), name=(\'%s_tower_1\' % name), suffix=\'_conv_3\')\n    pooling = mx.sym.Pooling(data=data, kernel=(3, 3), stride=(2, 2), pool_type=pool, name=(\'%s_pool_%s_pool\' % (pool, name)))\n    # concat\n    concat = mx.sym.Concat(*[tower_3x3, tower_d7_3x3, pooling], name=\'ch_concat_%s_chconcat\' % name)\n    return concat\n\ndef Inception7E(data,\n                num_1x1,\n                num_d3_red, num_d3_1, num_d3_2,\n                num_3x3_d3_red, num_3x3, num_3x3_d3_1, num_3x3_d3_2,\n                pool, proj,\n                name):\n    tower_1x1 = Conv(data=data, num_filter=num_1x1, kernel=(1, 1), name=(\'%s_conv\' % name))\n    tower_d3 = Conv(data=data, num_filter=num_d3_red, name=(\'%s_tower\' % name), suffix=\'_conv\')\n    tower_d3_a = Conv(data=tower_d3, num_filter=num_d3_1, kernel=(1, 3), pad=(0, 1), name=(\'%s_tower\' % name), suffix=\'_mixed_conv\')\n    tower_d3_b = Conv(data=tower_d3, num_filter=num_d3_2, kernel=(3, 1), pad=(1, 0), name=(\'%s_tower\' % name), suffix=\'_mixed_conv_1\')\n    tower_3x3_d3 = Conv(data=data, num_filter=num_3x3_d3_red, name=(\'%s_tower_1\' % name), suffix=\'_conv\')\n    tower_3x3_d3 = Conv(data=tower_3x3_d3, num_filter=num_3x3, kernel=(3, 3), pad=(1, 1), name=(\'%s_tower_1\' % name), suffix=\'_conv_1\')\n    tower_3x3_d3_a = Conv(data=tower_3x3_d3, num_filter=num_3x3_d3_1, kernel=(1, 3), pad=(0, 1), name=(\'%s_tower_1\' % name), suffix=\'_mixed_conv\')\n    tower_3x3_d3_b = Conv(data=tower_3x3_d3, num_filter=num_3x3_d3_2, kernel=(3, 1), pad=(1, 0), name=(\'%s_tower_1\' % name), suffix=\'_mixed_conv_1\')\n    pooling = mx.sym.Pooling(data=data, kernel=(3, 3), stride=(1, 1), pad=(1, 1), pool_type=pool, name=(\'%s_pool_%s_pool\' % (pool, name)))\n    cproj = Conv(data=pooling, num_filter=proj, kernel=(1, 1), name=(\'%s_tower_2\' %  name), suffix=\'_conv\')\n    # concat\n    concat = mx.sym.Concat(*[tower_1x1, tower_d3_a, tower_d3_b, tower_3x3_d3_a, tower_3x3_d3_b, cproj], name=\'ch_concat_%s_chconcat\' % name)\n    return concat\n\n# In[49]:\n\ndef get_symbol(num_classes=1000, dtype=\'float32\', **kwargs):\n    data = mx.sym.Variable(name=""data"")\n    if dtype == \'float32\':\n        data = mx.sym.identity(data=data, name=\'id\')\n    else:\n        if dtype == \'float16\':\n            data = mx.sym.Cast(data=data, dtype=np.float16)\n    # stage 1\n    conv = Conv(data, 32, kernel=(3, 3), stride=(2, 2), name=""conv"")\n    conv_1 = Conv(conv, 32, kernel=(3, 3), name=""conv_1"")\n    conv_2 = Conv(conv_1, 64, kernel=(3, 3), pad=(1, 1), name=""conv_2"")\n    pool = mx.sym.Pooling(data=conv_2, kernel=(3, 3), stride=(2, 2), pool_type=""max"", name=""pool"")\n    # stage 2\n    conv_3 = Conv(pool, 80, kernel=(1, 1), name=""conv_3"")\n    conv_4 = Conv(conv_3, 192, kernel=(3, 3), name=""conv_4"")\n    pool1 = mx.sym.Pooling(data=conv_4, kernel=(3, 3), stride=(2, 2), pool_type=""max"", name=""pool1"")\n    # stage 3\n    in3a = Inception7A(pool1, 64,\n                       64, 96, 96,\n                       48, 64,\n                       ""avg"", 32, ""mixed"")\n    in3b = Inception7A(in3a, 64,\n                       64, 96, 96,\n                       48, 64,\n                       ""avg"", 64, ""mixed_1"")\n    in3c = Inception7A(in3b, 64,\n                       64, 96, 96,\n                       48, 64,\n                       ""avg"", 64, ""mixed_2"")\n    in3d = Inception7B(in3c, 384,\n                       64, 96, 96,\n                       ""max"", ""mixed_3"")\n    # stage 4\n    in4a = Inception7C(in3d, 192,\n                       128, 128, 192,\n                       128, 128, 128, 128, 192,\n                       ""avg"", 192, ""mixed_4"")\n    in4b = Inception7C(in4a, 192,\n                       160, 160, 192,\n                       160, 160, 160, 160, 192,\n                       ""avg"", 192, ""mixed_5"")\n    in4c = Inception7C(in4b, 192,\n                       160, 160, 192,\n                       160, 160, 160, 160, 192,\n                       ""avg"", 192, ""mixed_6"")\n    in4d = Inception7C(in4c, 192,\n                       192, 192, 192,\n                       192, 192, 192, 192, 192,\n                       ""avg"", 192, ""mixed_7"")\n    in4e = Inception7D(in4d, 192, 320,\n                       192, 192, 192, 192,\n                       ""max"", ""mixed_8"")\n    # stage 5\n    in5a = Inception7E(in4e, 320,\n                       384, 384, 384,\n                       448, 384, 384, 384,\n                       ""avg"", 192, ""mixed_9"")\n    in5b = Inception7E(in5a, 320,\n                       384, 384, 384,\n                       448, 384, 384, 384,\n                       ""max"", 192, ""mixed_10"")\n    # pool\n    pool = mx.sym.Pooling(data=in5b, kernel=(8, 8), stride=(1, 1), pool_type=""avg"", name=""global_pool"")\n    flatten = mx.sym.Flatten(data=pool, name=""flatten"")\n    fc1 = mx.sym.FullyConnected(data=flatten, num_hidden=num_classes, name=\'fc1\')\n    if dtype == \'float16\':\n        fc1 = mx.sym.Cast(data=fc1, dtype=np.float32)\n    softmax = mx.sym.SoftmaxOutput(data=fc1, name=\'softmax\')\n    return softmax\n'"
example/mxnet/symbols/inception-v4.py,0,"b'# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# ""License""); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n\n# -*- coding:utf-8 -*-\n__author__ = \'zhangshuai\'\nmodified_date = \'16/7/5\'\n__modify__ = \'anchengwu\'\nmodified_date = \'17/2/22\'\n\n\'\'\'\nInception v4 , suittable for image with around 299 x 299\n\nReference:\n    Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning\n    Christian Szegedy, Sergey Ioffe, Vincent Vanhoucke\n    arXiv.1602.07261\n\'\'\'\nimport mxnet as mx\nimport numpy as np\n\ndef Conv(data, num_filter, kernel=(1, 1), stride=(1, 1), pad=(0, 0), name=None, suffix=\'\'):\n    conv = mx.sym.Convolution(data=data, num_filter=num_filter, kernel=kernel, stride=stride, pad=pad, no_bias=True, name=\'%s%s_conv2d\' %(name, suffix))\n    bn = mx.sym.BatchNorm(data=conv, name=\'%s%s_batchnorm\' %(name, suffix), fix_gamma=True)\n    act = mx.sym.Activation(data=bn, act_type=\'relu\', name=\'%s%s_relu\' %(name, suffix))\n\n    return act\n\n\ndef Inception_stem(data, name= None):\n    c = Conv(data, 32, kernel=(3, 3), stride=(2, 2), name=\'%s_conv1_3*3\' %name)\n    c = Conv(c, 32, kernel=(3, 3), name=\'%s_conv2_3*3\' %name)\n    c = Conv(c, 64, kernel=(3, 3), pad=(1, 1), name=\'%s_conv3_3*3\' %name)\n\n    p1 = mx.sym.Pooling(c, kernel=(3, 3), stride=(2, 2), pool_type=\'max\', name=\'%s_maxpool_1\' %name)\n    c2 = Conv(c, 96, kernel=(3, 3), stride=(2, 2), name=\'%s_conv4_3*3\' %name)\n    concat = mx.sym.Concat(*[p1, c2], name=\'%s_concat_1\' %name)\n\n    c1 = Conv(concat, 64, kernel=(1, 1), pad=(0, 0), name=\'%s_conv5_1*1\' %name)\n    c1 = Conv(c1, 96, kernel=(3, 3), name=\'%s_conv6_3*3\' %name)\n\n    c2 = Conv(concat, 64, kernel=(1, 1), pad=(0, 0), name=\'%s_conv7_1*1\' %name)\n    c2 = Conv(c2, 64, kernel=(7, 1), pad=(3, 0), name=\'%s_conv8_7*1\' %name)\n    c2 = Conv(c2, 64, kernel=(1, 7), pad=(0, 3), name=\'%s_conv9_1*7\' %name)\n    c2 = Conv(c2, 96, kernel=(3, 3), pad=(0, 0), name=\'%s_conv10_3*3\' %name)\n\n    concat = mx.sym.Concat(*[c1, c2], name=\'%s_concat_2\' %name)\n\n    c1 = Conv(concat, 192, kernel=(3, 3), stride=(2, 2), name=\'%s_conv11_3*3\' %name)\n    p1 = mx.sym.Pooling(concat, kernel=(3, 3), stride=(2, 2), pool_type=\'max\', name=\'%s_maxpool_2\' %name)\n\n    concat = mx.sym.Concat(*[c1, p1], name=\'%s_concat_3\' %name)\n\n    return concat\n\n\ndef InceptionA(input, name=None):\n    p1 = mx.sym.Pooling(input, kernel=(3, 3), pad=(1, 1), pool_type=\'avg\', name=\'%s_avgpool_1\' %name)\n    c1 = Conv(p1, 96, kernel=(1, 1), pad=(0, 0), name=\'%s_conv1_1*1\' %name)\n\n    c2 = Conv(input, 96, kernel=(1, 1), pad=(0, 0), name=\'%s_conv2_1*1\' %name)\n\n    c3 = Conv(input, 64, kernel=(1, 1), pad=(0, 0), name=\'%s_conv3_1*1\' %name)\n    c3 = Conv(c3, 96, kernel=(3, 3), pad=(1, 1), name=\'%s_conv4_3*3\' %name)\n\n    c4 = Conv(input, 64, kernel=(1, 1), pad=(0, 0), name=\'%s_conv5_1*1\' % name)\n    c4 = Conv(c4, 96, kernel=(3, 3), pad=(1, 1), name=\'%s_conv6_3*3\' % name)\n    c4 = Conv(c4, 96, kernel=(3, 3), pad=(1, 1), name=\'%s_conv7_3*3\' %name)\n\n    concat = mx.sym.Concat(*[c1, c2, c3, c4], name=\'%s_concat_1\' %name)\n\n    return concat\n\n\ndef ReductionA(input, name=None):\n    p1 = mx.sym.Pooling(input, kernel=(3, 3), stride=(2, 2), pool_type=\'max\', name=\'%s_maxpool_1\' %name)\n\n    c2 = Conv(input, 384, kernel=(3, 3), stride=(2, 2), name=\'%s_conv1_3*3\' %name)\n\n    c3 = Conv(input, 192, kernel=(1, 1), pad=(0, 0), name=\'%s_conv2_1*1\' %name)\n    c3 = Conv(c3, 224, kernel=(3, 3), pad=(1, 1), name=\'%s_conv3_3*3\' %name)\n    c3 = Conv(c3, 256, kernel=(3, 3), stride=(2, 2), pad=(0, 0), name=\'%s_conv4_3*3\' %name)\n\n    concat = mx.sym.Concat(*[p1, c2, c3], name=\'%s_concat_1\' %name)\n\n    return concat\n\ndef InceptionB(input, name=None):\n    p1 = mx.sym.Pooling(input, kernel=(3, 3), pad=(1, 1), pool_type=\'avg\', name=\'%s_avgpool_1\' %name)\n    c1 = Conv(p1, 128, kernel=(1, 1), pad=(0, 0), name=\'%s_conv1_1*1\' %name)\n\n    c2 = Conv(input, 384, kernel=(1, 1), pad=(0, 0), name=\'%s_conv2_1*1\' %name)\n\n    c3 = Conv(input, 192, kernel=(1, 1), pad=(0, 0), name=\'%s_conv3_1*1\' %name)\n    c3 = Conv(c3, 224, kernel=(1, 7), pad=(0, 3), name=\'%s_conv4_1*7\' %name)\n    #paper wrong\n    c3 = Conv(c3, 256, kernel=(7, 1), pad=(3, 0), name=\'%s_conv5_1*7\' %name)\n\n    c4 = Conv(input, 192, kernel=(1, 1), pad=(0, 0), name=\'%s_conv6_1*1\' %name)\n    c4 = Conv(c4, 192, kernel=(1, 7), pad=(0, 3), name=\'%s_conv7_1*7\' %name)\n    c4 = Conv(c4, 224, kernel=(7, 1), pad=(3, 0), name=\'%s_conv8_7*1\' %name)\n    c4 = Conv(c4, 224, kernel=(1, 7), pad=(0, 3), name=\'%s_conv9_1*7\' %name)\n    c4 = Conv(c4, 256, kernel=(7, 1), pad=(3, 0), name=\'%s_conv10_7*1\' %name)\n\n    concat = mx.sym.Concat(*[c1, c2, c3, c4], name=\'%s_concat_1\' %name)\n\n    return concat\n\ndef ReductionB(input,name=None):\n    p1 = mx.sym.Pooling(input, kernel=(3, 3), stride=(2, 2), pool_type=\'max\', name=\'%s_maxpool_1\' %name)\n\n    c2 = Conv(input, 192, kernel=(1, 1), pad=(0, 0), name=\'%s_conv1_1*1\' %name)\n    c2 = Conv(c2, 192, kernel=(3, 3), stride=(2, 2), name=\'%s_conv2_3*3\' %name)\n\n    c3 = Conv(input, 256, kernel=(1, 1), pad=(0, 0), name=\'%s_conv3_1*1\' %name)\n    c3 = Conv(c3, 256, kernel=(1, 7), pad=(0, 3), name=\'%s_conv4_1*7\' %name)\n    c3 = Conv(c3, 320, kernel=(7, 1), pad=(3, 0), name=\'%s_conv5_7*1\' %name)\n    c3 = Conv(c3, 320, kernel=(3, 3), stride=(2, 2), name=\'%s_conv6_3*3\' %name)\n\n    concat = mx.sym.Concat(*[p1, c2, c3], name=\'%s_concat_1\' %name)\n\n    return concat\n\n\ndef InceptionC(input, name=None):\n    p1 = mx.sym.Pooling(input, kernel=(3, 3), pad=(1, 1), pool_type=\'avg\', name=\'%s_avgpool_1\' %name)\n    c1 = Conv(p1, 256, kernel=(1, 1), pad=(0, 0), name=\'%s_conv1_1*1\' %name)\n\n    c2 = Conv(input, 256, kernel=(1, 1), pad=(0, 0), name=\'%s_conv2_1*1\' %name)\n\n    c3 = Conv(input, 384, kernel=(1, 1), pad=(0, 0), name=\'%s_conv3_1*1\' %name)\n    c3_1 = Conv(c3, 256, kernel=(1, 3), pad=(0, 1), name=\'%s_conv4_3*1\' %name)\n    c3_2 = Conv(c3, 256, kernel=(3, 1), pad=(1, 0), name=\'%s_conv5_1*3\' %name)\n\n    c4 = Conv(input, 384, kernel=(1, 1), pad=(0, 0), name=\'%s_conv6_1*1\' %name)\n    c4 = Conv(c4, 448, kernel=(1, 3), pad=(0, 1), name=\'%s_conv7_1*3\' %name)\n    c4 = Conv(c4, 512, kernel=(3, 1), pad=(1, 0), name=\'%s_conv8_3*1\' %name)\n    c4_1 = Conv(c4, 256, kernel=(3, 1), pad=(1, 0), name=\'%s_conv9_1*3\' %name)\n    c4_2 = Conv(c4, 256, kernel=(1, 3), pad=(0, 1), name=\'%s_conv10_3*1\' %name)\n\n    concat = mx.sym.Concat(*[c1, c2, c3_1, c3_2, c4_1, c4_2], name=\'%s_concat\' %name)\n\n    return concat\n\n\ndef get_symbol(num_classes=1000, dtype=\'float32\', **kwargs):\n    data = mx.sym.Variable(name=""data"")\n    if dtype == \'float32\':\n        data = mx.sym.identity(data=data, name=\'id\')\n    else:\n        if dtype == \'float16\':\n            data = mx.sym.Cast(data=data, dtype=np.float16)\n    x = Inception_stem(data, name=\'in_stem\')\n\n    #4 * InceptionA\n    # x = InceptionA(x, name=\'in1A\')\n    # x = InceptionA(x, name=\'in2A\')\n    # x = InceptionA(x, name=\'in3A\')\n    # x = InceptionA(x, name=\'in4A\')\n\n    for i in range(4):\n        x = InceptionA(x, name=\'in%dA\' %(i+1))\n\n    #Reduction A\n    x = ReductionA(x, name=\'re1A\')\n\n    #7 * InceptionB\n    # x = InceptionB(x, name=\'in1B\')\n    # x = InceptionB(x, name=\'in2B\')\n    # x = InceptionB(x, name=\'in3B\')\n    # x = InceptionB(x, name=\'in4B\')\n    # x = InceptionB(x, name=\'in5B\')\n    # x = InceptionB(x, name=\'in6B\')\n    # x = InceptionB(x, name=\'in7B\')\n\n    for i in range(7):\n        x = InceptionB(x, name=\'in%dB\' %(i+1))\n\n    #ReductionB\n    x = ReductionB(x, name=\'re1B\')\n\n    #3 * InceptionC\n    # x = InceptionC(x, name=\'in1C\')\n    # x = InceptionC(x, name=\'in2C\')\n    # x = InceptionC(x, name=\'in3C\')\n\n    for i in range(3):\n        x = InceptionC(x, name=\'in%dC\' %(i+1))\n\n    #Average Pooling\n    x = mx.sym.Pooling(x, kernel=(8, 8), pad=(1, 1), pool_type=\'avg\', name=\'global_avgpool\')\n\n    #Dropout\n    x = mx.sym.Dropout(x, p=0.2)\n\n    flatten = mx.sym.Flatten(x, name=\'flatten\')\n    fc1 = mx.sym.FullyConnected(flatten, num_hidden=num_classes, name=\'fc1\')\n    if dtype == \'float16\':\n        fc1 = mx.sym.Cast(data=fc1, dtype=np.float32)\n    softmax = mx.sym.SoftmaxOutput(fc1, name=\'softmax\')\n\n    return softmax\n'"
example/mxnet/symbols/lenet.py,0,"b'# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# ""License""); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n\n""""""\nLeCun, Yann, Leon Bottou, Yoshua Bengio, and Patrick Haffner.\nGradient-based learning applied to document recognition.\nProceedings of the IEEE (1998)\n""""""\nimport mxnet as mx\n\ndef get_loc(data, attr={\'lr_mult\':\'0.01\'}):\n    """"""\n    the localisation network in lenet-stn, it will increase acc about more than 1%,\n    when num-epoch >=15\n    """"""\n    loc = mx.symbol.Convolution(data=data, num_filter=30, kernel=(5, 5), stride=(2,2))\n    loc = mx.symbol.Activation(data = loc, act_type=\'relu\')\n    loc = mx.symbol.Pooling(data=loc, kernel=(2, 2), stride=(2, 2), pool_type=\'max\')\n    loc = mx.symbol.Convolution(data=loc, num_filter=60, kernel=(3, 3), stride=(1,1), pad=(1, 1))\n    loc = mx.symbol.Activation(data = loc, act_type=\'relu\')\n    loc = mx.symbol.Pooling(data=loc, global_pool=True, kernel=(2, 2), pool_type=\'avg\')\n    loc = mx.symbol.Flatten(data=loc)\n    loc = mx.symbol.FullyConnected(data=loc, num_hidden=6, name=""stn_loc"", attr=attr)\n    return loc\n\n\ndef get_symbol(num_classes=10, add_stn=False, **kwargs):\n    data = mx.symbol.Variable(\'data\')\n    if add_stn:\n        data = mx.sym.SpatialTransformer(data=data, loc=get_loc(data), target_shape = (28,28),\n                                         transform_type=""affine"", sampler_type=""bilinear"")\n    # first conv\n    conv1 = mx.symbol.Convolution(data=data, kernel=(5,5), num_filter=20)\n    tanh1 = mx.symbol.Activation(data=conv1, act_type=""tanh"")\n    pool1 = mx.symbol.Pooling(data=tanh1, pool_type=""max"",\n                              kernel=(2,2), stride=(2,2))\n    # second conv\n    conv2 = mx.symbol.Convolution(data=pool1, kernel=(5,5), num_filter=50)\n    tanh2 = mx.symbol.Activation(data=conv2, act_type=""tanh"")\n    pool2 = mx.symbol.Pooling(data=tanh2, pool_type=""max"",\n                              kernel=(2,2), stride=(2,2))\n    # first fullc\n    flatten = mx.symbol.Flatten(data=pool2)\n    fc1 = mx.symbol.FullyConnected(data=flatten, num_hidden=500)\n    tanh3 = mx.symbol.Activation(data=fc1, act_type=""tanh"")\n    # second fullc\n    fc2 = mx.symbol.FullyConnected(data=tanh3, num_hidden=num_classes)\n    # loss\n    lenet = mx.symbol.SoftmaxOutput(data=fc2, name=\'softmax\')\n    return lenet\n'"
example/mxnet/symbols/mlp.py,0,"b'# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# ""License""); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n\n""""""\na simple multilayer perceptron\n""""""\nimport mxnet as mx\n\ndef get_symbol(num_classes=10, **kwargs):\n    data = mx.symbol.Variable(\'data\')\n    data = mx.sym.Flatten(data=data)\n    fc1  = mx.symbol.FullyConnected(data = data, name=\'fc1\', num_hidden=128)\n    act1 = mx.symbol.Activation(data = fc1, name=\'relu1\', act_type=""relu"")\n    fc2  = mx.symbol.FullyConnected(data = act1, name = \'fc2\', num_hidden = 64)\n    act2 = mx.symbol.Activation(data = fc2, name=\'relu2\', act_type=""relu"")\n    fc3  = mx.symbol.FullyConnected(data = act2, name=\'fc3\', num_hidden=num_classes)\n    mlp  = mx.symbol.SoftmaxOutput(data = fc3, name = \'softmax\')\n    return mlp\n'"
example/mxnet/symbols/mobilenet.py,0,"b'# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# ""License""); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n# -*- coding:utf-8 -*-\n\'\'\'\nmobilenet\nSuittable for image with around resolution x resolution, resolution is multiple of 32.\n\nReference:\nMobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications\nhttps://arxiv.org/abs/1704.04861\n\'\'\'\n\n__author__ = \'qingzhouzhen\'\n__date__ = \'17/8/5\'\n__modify__ = \'dwSun\'\n__modified_date__ = \'17/11/30\'\n\n\nimport mxnet as mx\n\nalpha_values = [0.25, 0.50, 0.75, 1.0]\n\n\ndef Conv(data, num_filter=1, kernel=(1, 1), stride=(1, 1), pad=(0, 0), num_group=1, name=\'\', suffix=\'\'):\n    conv = mx.sym.Convolution(data=data, num_filter=num_filter, kernel=kernel, num_group=num_group, stride=stride, pad=pad, no_bias=True, name=\'%s%s_conv2d\' % (name, suffix))\n    bn = mx.sym.BatchNorm(data=conv, name=\'%s%s_batchnorm\' % (name, suffix), fix_gamma=True)\n    act = mx.sym.Activation(data=bn, act_type=\'relu\', name=\'%s%s_relu\' % (name, suffix))\n    return act\n\n\ndef Conv_DPW(data, depth=1, stride=(1, 1), name=\'\', idx=0, suffix=\'\'):\n    conv_dw = Conv(data, num_group=depth, num_filter=depth, kernel=(3, 3), pad=(1, 1), stride=stride, name=""conv_%d_dw"" % (idx), suffix=suffix)\n    conv = Conv(conv_dw, num_filter=depth * stride[0], kernel=(1, 1), pad=(0, 0), stride=(1, 1), name=""conv_%d"" % (idx), suffix=suffix)\n    return conv\n\n\ndef get_symbol_compact(num_classes, alpha=1, resolution=224, **kwargs):\n    assert alpha in alpha_values, \'Invalid alpha={0}, must be one of {1}\'.format(alpha, alpha_values)\n    assert resolution % 32 == 0, \'resolution must be multiple of 32\'\n\n    base = int(32 * alpha)\n\n    data = mx.symbol.Variable(name=""data"")  # 224\n    conv_1 = Conv(data, num_filter=base, kernel=(3, 3), pad=(1, 1), stride=(2, 2), name=""conv_1"")  # 32*alpha, 224/112\n\n    conv_2_dw = Conv(conv_1, num_group=base, num_filter=base, kernel=(3, 3), pad=(1, 1), stride=(1, 1), name=""conv_2_dw"")  # 112/112\n    conv_2 = Conv(conv_2_dw, num_filter=base * 2, kernel=(1, 1), pad=(0, 0), stride=(1, 1), name=""conv_2"")  # 32*alpha, 112/112\n\n    conv_3_dpw = Conv_DPW(conv_2, depth=base * 2, stride=(2, 2), idx=3)  # 64*alpha, 112/56 => 56/56\n    conv_4_dpw = Conv_DPW(conv_3_dpw, depth=base * 4, stride=(1, 1), idx=4)  # 128*alpha, 56/56 =>56/56\n    conv_5_dpw = Conv_DPW(conv_4_dpw, depth=base * 4, stride=(2, 2), idx=5)  # 128*alpha, 56/28 => 28/28\n    conv_6_dpw = Conv_DPW(conv_5_dpw, depth=base * 8, stride=(1, 1), idx=6)  # 256*alpha, 28/28 => 28/28\n    conv_7_dpw = Conv_DPW(conv_6_dpw, depth=base * 8, stride=(2, 2), idx=7)  # 256*alpha, 28/14 => 14/14\n    conv_dpw = conv_7_dpw\n\n    for idx in range(8, 13):\n        conv_dpw = Conv_DPW(conv_dpw, depth=base * 16, stride=(1, 1), idx=idx)  # 512*alpha, 14/14\n\n    conv_12_dpw = conv_dpw\n    conv_13_dpw = Conv_DPW(conv_12_dpw, depth=base * 16, stride=(2, 2), idx=13)  # 512*alpha, 14/7 => 7/7\n    conv_14_dpw = Conv_DPW(conv_13_dpw, depth=base * 32, stride=(1, 1), idx=14)  # 1024*alpha, 7/7 => 7/7\n\n    pool_size = int(resolution / 32)\n    pool = mx.sym.Pooling(data=conv_14_dpw, kernel=(pool_size, pool_size), stride=(1, 1), pool_type=""avg"", name=""global_pool"")\n    flatten = mx.sym.Flatten(data=pool, name=""flatten"")\n    fc = mx.symbol.FullyConnected(data=flatten, num_hidden=num_classes, name=\'fc\')\n    softmax = mx.symbol.SoftmaxOutput(data=fc, name=\'softmax\')\n    return softmax\n\n\ndef get_symbol(num_classes, alpha=1, resolution=224, **kwargs):\n    assert alpha in alpha_values, \'Invalid alpha=[{0}], must be one of [{1}]\'.format(alpha, alpha_values)\n    assert resolution % 32 == 0, \'resolution must be multpile of 32\'\n\n    base = int(32 * alpha)\n\n    data = mx.symbol.Variable(name=""data"")  # 224\n    depth = base  # 32*alpha\n    conv_1 = Conv(data, num_filter=depth, kernel=(3, 3), pad=(1, 1), stride=(2, 2), name=""conv_1"")  # 224/112\n\n    depth = base  # 32*alpha\n    conv_2_dw = Conv(conv_1, num_group=depth, num_filter=depth, kernel=(3, 3), pad=(1, 1), stride=(1, 1), name=""conv_2_dw"")  # 112/112\n    conv_2 = Conv(conv_2_dw, num_filter=depth * 2, kernel=(1, 1), pad=(0, 0), stride=(1, 1), name=""conv_2"")  # 112/112\n\n    depth = base * 2  # 64*alpha\n    conv_3_dw = Conv(conv_2, num_group=depth, num_filter=depth, kernel=(3, 3), pad=(1, 1), stride=(2, 2), name=""conv_3_dw"")  # 112/56\n    conv_3 = Conv(conv_3_dw, num_filter=depth * 2, kernel=(1, 1), pad=(0, 0), stride=(1, 1), name=""conv_3"")  # 56/56\n\n    depth = base * 4  # 128*alpha\n    conv_4_dw = Conv(conv_3, num_group=depth, num_filter=depth, kernel=(3, 3), pad=(1, 1), stride=(1, 1), name=""conv_4_dw"")  # 56/56\n    conv_4 = Conv(conv_4_dw, num_filter=depth, kernel=(1, 1), pad=(0, 0), stride=(1, 1), name=""conv_4"")  # 56/56\n\n    depth = base * 4  # 128*alpha\n    conv_5_dw = Conv(conv_4, num_group=depth, num_filter=depth, kernel=(3, 3), pad=(1, 1), stride=(2, 2), name=""conv_5_dw"")  # 56/28\n    conv_5 = Conv(conv_5_dw, num_filter=depth * 2, kernel=(1, 1), pad=(0, 0), stride=(1, 1), name=""conv_5"")  # 28/28\n\n    depth = base * 8  # 256*alpha\n    conv_6_dw = Conv(conv_5, num_group=depth, num_filter=depth, kernel=(3, 3), pad=(1, 1), stride=(1, 1), name=""conv_6_dw"")  # 28/28\n    conv_6 = Conv(conv_6_dw, num_filter=depth, kernel=(1, 1), pad=(0, 0), stride=(1, 1), name=""conv_6"")  # 28/28\n\n    depth = base * 8  # 256*alpha\n    conv_7_dw = Conv(conv_6, num_group=depth, num_filter=depth, kernel=(3, 3), pad=(1, 1), stride=(2, 2), name=""conv_7_dw"")  # 28/14\n    conv_7 = Conv(conv_7_dw, num_filter=depth * 2, kernel=(1, 1), pad=(0, 0), stride=(1, 1), name=""conv_7"")  # 14/14\n\n    depth = base * 16  # 512*alpha\n    conv_8_dw = Conv(conv_7, num_group=depth, num_filter=depth, kernel=(3, 3), pad=(1, 1), stride=(1, 1), name=""conv_8_dw"")  # 14/14\n    conv_8 = Conv(conv_8_dw, num_filter=depth, kernel=(1, 1), pad=(0, 0), stride=(1, 1), name=""conv_8"")  # 14/14\n    conv_9_dw = Conv(conv_8, num_group=depth, num_filter=depth, kernel=(3, 3), pad=(1, 1), stride=(1, 1), name=""conv_9_dw"")  # 14/14\n    conv_9 = Conv(conv_9_dw, num_filter=depth, kernel=(1, 1), pad=(0, 0), stride=(1, 1), name=""conv_9"")  # 14/14\n    conv_10_dw = Conv(conv_9, num_group=depth, num_filter=depth, kernel=(3, 3), pad=(1, 1), stride=(1, 1), name=""conv_10_dw"")  # 14/14\n    conv_10 = Conv(conv_10_dw, num_filter=depth, kernel=(1, 1), pad=(0, 0), stride=(1, 1), name=""conv_10"")  # 14/14\n    conv_11_dw = Conv(conv_10, num_group=depth, num_filter=depth, kernel=(3, 3), pad=(1, 1), stride=(1, 1), name=""conv_11_dw"")  # 14/14\n    conv_11 = Conv(conv_11_dw, num_filter=depth, kernel=(1, 1), pad=(0, 0), stride=(1, 1), name=""conv_11"")  # 14/14\n    conv_12_dw = Conv(conv_11, num_group=depth, num_filter=depth, kernel=(3, 3), pad=(1, 1), stride=(1, 1), name=""conv_12_dw"")  # 14/14\n    conv_12 = Conv(conv_12_dw, num_filter=depth, kernel=(1, 1), pad=(0, 0), stride=(1, 1), name=""conv_12"")  # 14/14\n\n    depth = base * 16  # 512*alpha\n    conv_13_dw = Conv(conv_12, num_group=depth, num_filter=depth, kernel=(3, 3), pad=(1, 1), stride=(2, 2), name=""conv_13_dw"")  # 14/7\n    conv_13 = Conv(conv_13_dw, num_filter=depth * 2, kernel=(1, 1), pad=(0, 0), stride=(1, 1), name=""conv_13"")  # 7/7\n\n    depth = base * 32  # 1024*alpha\n    conv_14_dw = Conv(conv_13, num_group=depth, num_filter=depth, kernel=(3, 3), pad=(1, 1), stride=(1, 1), name=""conv_14_dw"")  # 7/7\n    conv_14 = Conv(conv_14_dw, num_filter=depth, kernel=(1, 1), pad=(0, 0), stride=(1, 1), name=""conv_14"")  # 7/7\n\n    pool_size = int(resolution / 32)\n    pool = mx.sym.Pooling(data=conv_14, kernel=(pool_size, pool_size), stride=(1, 1), pool_type=""avg"", name=""global_pool"")\n    flatten = mx.sym.Flatten(data=pool, name=""flatten"")\n    fc = mx.symbol.FullyConnected(data=flatten, num_hidden=num_classes, name=\'fc\')\n    softmax = mx.symbol.SoftmaxOutput(data=fc, name=\'softmax\')\n    return softmax\n'"
example/mxnet/symbols/mobilenetv2.py,0,"b'# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# ""License""); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n\n# -*- coding:utf-8 -*-\n\'\'\'\nMobileNetV2, implemented in built-in symbols.\n\nReference:\nInverted Residuals and Linear Bottlenecks:\nMobile Networks for Classification, Detection and Segmentation\nhttps://arxiv.org/abs/1801.04381\n\'\'\'\n__author__ = \'liangfu\'\n__date__ = \'18/4/3\'\n\nimport mxnet as mx\n\ndef relu6(data, prefix):\n    return mx.sym.clip(data,0,6,name=\'%s-relu6\'%prefix)\n\ndef shortcut(data_in, data_residual, prefix):\n    out=mx.sym.elemwise_add(data_in, data_residual, name=\'%s-shortcut\'%prefix)\n    return out\n\ndef mobilenet_unit(data, num_filter=1, kernel=(1, 1), stride=(1, 1), pad=(0, 0), num_group=1, if_act=True, prefix=\'\'):\n    conv = mx.sym.Convolution(\n        data=data,\n        num_filter=num_filter,\n        kernel=kernel,\n        num_group=num_group,\n        stride=stride,\n        pad=pad,\n        no_bias=True,\n        name=\'%s-conv2d\'%prefix)\n    bn = mx.sym.BatchNorm(data=conv, name=\'%s-batchnorm\'%prefix, fix_gamma=False, use_global_stats=False, eps=1e-5)\n    if if_act:\n        act = relu6(bn, prefix)\n        return act\n    else:\n        return bn\n\ndef inverted_residual_unit(data, num_in_filter, num_filter, ifshortcut, stride, kernel, pad, expansion_factor, prefix):\n    num_expfilter = int(round(num_in_filter*expansion_factor))\n\n    channel_expand = mobilenet_unit(\n        data=data,\n        num_filter=num_expfilter,\n        kernel=(1,1),\n        stride=(1,1),\n        pad=(0,0),\n        num_group=1,\n        if_act=True,\n        prefix=\'%s-exp\'%prefix,\n    )\n    bottleneck_conv = mobilenet_unit(\n        data= channel_expand,\n        num_filter=num_expfilter,\n        stride=stride,\n        kernel=kernel,\n        pad=pad,\n        num_group=num_expfilter,\n        if_act=True,\n        prefix=\'%s-depthwise\'%prefix,\n    )\n    linear_out = mobilenet_unit(\n        data=bottleneck_conv,\n        num_filter=num_filter,\n        kernel=(1, 1),\n        stride=(1, 1),\n        pad=(0, 0),\n        num_group=1,\n        if_act=False,\n        prefix=\'%s-linear\'%prefix\n    )\n    if ifshortcut:\n        out = shortcut(\n            data_in=data,\n            data_residual=linear_out,\n            prefix=prefix,\n        )\n        return out\n    else:\n        return linear_out\n\ndef inverted_residual_blocks(data, in_c, t, c, n, s, prefix):\n    first_block = inverted_residual_unit(\n        data=data,\n        num_in_filter=in_c,\n        num_filter=c,\n        ifshortcut=False,\n        stride=(s,s),\n        kernel=(3,3),\n        pad=(1,1),\n        expansion_factor=t,\n        prefix=\'%s-block0\'%prefix\n    )\n\n    last_residual_block = first_block\n    last_c = c\n\n    for i in range(1,n):\n        last_residual_block = inverted_residual_unit(\n            data=last_residual_block,\n            num_in_filter=last_c,\n            num_filter=c,\n            ifshortcut=True,\n            stride=(1,1),\n            kernel=(3,3),\n            pad=(1,1),\n            expansion_factor=t,\n            prefix=\'%s-block%d\'%(prefix, i)\n        )\n    return last_residual_block\n\nMNETV2_CONFIGS_MAP = {\n    (224,224):{\n        \'firstconv_filter_num\': 32, # 3*224*224 -> 32*112*112\n        # t, c, n, s\n        \'bottleneck_params_list\':[\n            (1, 16, 1, 1), # 32x112x112 -> 16x112x112\n            (6, 24, 2, 2), # 16x112x112 -> 24x56x56\n            (6, 32, 3, 2), # 24x56x56 -> 32x28x28\n            (6, 64, 4, 2), # 32x28x28 -> 64x14x14\n            (6, 96, 3, 1), # 64x14x14 -> 96x14x14\n            (6, 160, 3, 2), # 96x14x14 -> 160x7x7\n            (6, 320, 1, 1), # 160x7x7 -> 320x7x7\n        ],\n        \'filter_num_before_gp\': 1280, # 320x7x7 -> 1280x7x7\n    }\n}\n\nclass MobileNetV2(object):\n    def __init__(self, data_wh, multiplier, **kargs):\n        super(MobileNetV2, self).__init__()\n        self.data_wh=data_wh\n        self.multiplier=multiplier\n        if self.data_wh in MNETV2_CONFIGS_MAP:\n            self.config_map=MNETV2_CONFIGS_MAP[self.data_wh]\n        else:\n            self.config_map=MNETV2_CONFIGS_MAP[(224, 224)]\n\n    def build_network(self, class_num=1000, **configs):\n        data = mx.sym.Variable(\'data\')\n        self.config_map.update(configs)\n        # first conv2d block\n        first_c = int(round(self.config_map[\'firstconv_filter_num\']*self.multiplier))\n        first_layer = mobilenet_unit(\n            data=data,\n            num_filter=first_c,\n            kernel=(3,3),\n            stride=(2,2),\n            pad=(1,1),\n            if_act=True,\n            prefix=\'first-3x3-conv\'\n        )\n        last_bottleneck_layer = first_layer\n        in_c = first_c\n        # bottleneck sequences\n        for i, layer_setting in enumerate(self.config_map[\'bottleneck_params_list\']):\n            t, c, n, s = layer_setting\n            last_bottleneck_layer = inverted_residual_blocks(\n                data=last_bottleneck_layer,\n                in_c=in_c, t=t, c=int(round(c*self.multiplier)), n=n, s=s,\n                prefix=\'seq-%d\'%i\n            )\n            in_c = int(round(c*self.multiplier))\n        # last conv2d block before global pooling\n        last_fm = mobilenet_unit(\n            data=last_bottleneck_layer,\n            num_filter=int(1280 * self.multiplier) if self.multiplier > 1.0 else 1280,\n            kernel=(1,1),\n            stride=(1,1),\n            pad=(0,0),\n            if_act=True,\n            prefix=\'last-1x1-conv\'\n        )\n        # global average pooling\n        pool_size = int(self.data_wh[0] / 32)\n        pool = mx.sym.Pooling(data=last_fm, kernel=(pool_size, pool_size), stride=(1, 1),\n                              pool_type=""avg"", name=""global_pool"", global_pool=True)\n        flatten = mx.sym.Flatten(data=pool, name=""flatten"")\n        fc = mx.symbol.FullyConnected(data=flatten, num_hidden=class_num, name=\'fc\')\n        softmax = mx.symbol.SoftmaxOutput(data=fc, name=\'softmax\')\n\n        return softmax\n\n    def __call__(self, class_num=1000, layer_out=None, **configs):\n        # build the whole architecture of mobilenet v2 here\n        sym = self.build_network(class_num=class_num,**configs)\n        if layer_out is None:\n            return sym\n\n        internals = sym.get_internals()\n        if type(layer_out) is list or type(layer_out) is tuple:\n            layers_out = [internals[layer_nm.strip() + \'_output\'] for layer_nm in layer_out]\n            return layers_out\n        else:\n            layer_out = internals[layer_out.strip() + \'_output\']\n            return layer_out\n\ndef get_symbol(num_classes=1000, multiplier=1.0):\n    mnetgen = MobileNetV2((224,224), multiplier=multiplier)\n    mnetv2_sym = mnetgen(class_num=num_classes, layer_out=None)\n    return mnetv2_sym\n'"
example/mxnet/symbols/resnet-v1.py,0,"b'# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# ""License""); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n\n\'\'\'\nAdapted from https://github.com/tornadomeet/ResNet/blob/master/symbol_resnet.py\n(Original author Wei Wu) by Antti-Pekka Hynninen\n\nImplementing the original resnet ILSVRC 2015 winning network from:\n\nKaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun. ""Deep Residual Learning for Image Recognition""\n\'\'\'\nimport mxnet as mx\nimport numpy as np\n\ndef residual_unit(data, num_filter, stride, dim_match, name, bottle_neck=True, bn_mom=0.9, workspace=256, memonger=False):\n    """"""Return ResNet Unit symbol for building ResNet\n    Parameters\n    ----------\n    data : str\n        Input data\n    num_filter : int\n        Number of output channels\n    bnf : int\n        Bottle neck channels factor with regard to num_filter\n    stride : tuple\n        Stride used in convolution\n    dim_match : Boolean\n        True means channel number between input and output is the same, otherwise means differ\n    name : str\n        Base name of the operators\n    workspace : int\n        Workspace used in convolution operator\n    """"""\n    if bottle_neck:\n        conv1 = mx.sym.Convolution(data=data, num_filter=int(num_filter*0.25), kernel=(1,1), stride=stride, pad=(0,0),\n                                   no_bias=True, workspace=workspace, name=name + \'_conv1\')\n        bn1 = mx.sym.BatchNorm(data=conv1, fix_gamma=False, eps=2e-5, momentum=bn_mom, name=name + \'_bn1\')\n        act1 = mx.sym.Activation(data=bn1, act_type=\'relu\', name=name + \'_relu1\')\n        conv2 = mx.sym.Convolution(data=act1, num_filter=int(num_filter*0.25), kernel=(3,3), stride=(1,1), pad=(1,1),\n                                   no_bias=True, workspace=workspace, name=name + \'_conv2\')\n        bn2 = mx.sym.BatchNorm(data=conv2, fix_gamma=False, eps=2e-5, momentum=bn_mom, name=name + \'_bn2\')\n        act2 = mx.sym.Activation(data=bn2, act_type=\'relu\', name=name + \'_relu2\')\n        conv3 = mx.sym.Convolution(data=act2, num_filter=num_filter, kernel=(1,1), stride=(1,1), pad=(0,0), no_bias=True,\n                                   workspace=workspace, name=name + \'_conv3\')\n        bn3 = mx.sym.BatchNorm(data=conv3, fix_gamma=False, eps=2e-5, momentum=bn_mom, name=name + \'_bn3\')\n\n        if dim_match:\n            shortcut = data\n        else:\n            conv1sc = mx.sym.Convolution(data=data, num_filter=num_filter, kernel=(1,1), stride=stride, no_bias=True,\n                                            workspace=workspace, name=name+\'_conv1sc\')\n            shortcut = mx.sym.BatchNorm(data=conv1sc, fix_gamma=False, eps=2e-5, momentum=bn_mom, name=name + \'_sc\')\n        if memonger:\n            shortcut._set_attr(mirror_stage=\'True\')\n        return mx.sym.Activation(data=bn3 + shortcut, act_type=\'relu\', name=name + \'_relu3\')\n    else:\n        conv1 = mx.sym.Convolution(data=data, num_filter=num_filter, kernel=(3,3), stride=stride, pad=(1,1),\n                                      no_bias=True, workspace=workspace, name=name + \'_conv1\')\n        bn1 = mx.sym.BatchNorm(data=conv1, fix_gamma=False, momentum=bn_mom, eps=2e-5, name=name + \'_bn1\')\n        act1 = mx.sym.Activation(data=bn1, act_type=\'relu\', name=name + \'_relu1\')\n        conv2 = mx.sym.Convolution(data=act1, num_filter=num_filter, kernel=(3,3), stride=(1,1), pad=(1,1),\n                                      no_bias=True, workspace=workspace, name=name + \'_conv2\')\n        bn2 = mx.sym.BatchNorm(data=conv2, fix_gamma=False, momentum=bn_mom, eps=2e-5, name=name + \'_bn2\')\n\n        if dim_match:\n            shortcut = data\n        else:\n            conv1sc = mx.sym.Convolution(data=data, num_filter=num_filter, kernel=(1,1), stride=stride, no_bias=True,\n                                            workspace=workspace, name=name+\'_conv1sc\')\n            shortcut = mx.sym.BatchNorm(data=conv1sc, fix_gamma=False, momentum=bn_mom, eps=2e-5, name=name + \'_sc\')\n        if memonger:\n            shortcut._set_attr(mirror_stage=\'True\')\n        return mx.sym.Activation(data=bn2 + shortcut, act_type=\'relu\', name=name + \'_relu3\')\n\ndef resnet(units, num_stages, filter_list, num_classes, image_shape, bottle_neck=True, bn_mom=0.9, workspace=256, dtype=\'float32\', memonger=False):\n    """"""Return ResNet symbol of\n    Parameters\n    ----------\n    units : list\n        Number of units in each stage\n    num_stages : int\n        Number of stage\n    filter_list : list\n        Channel size of each stage\n    num_classes : int\n        Ouput size of symbol\n    dataset : str\n        Dataset type, only cifar10 and imagenet supports\n    workspace : int\n        Workspace used in convolution operator\n    dtype : str\n        Precision (float32 or float16)\n    """"""\n    num_unit = len(units)\n    assert(num_unit == num_stages)\n    data = mx.sym.Variable(name=\'data\')\n    if dtype == \'float32\':\n        data = mx.sym.identity(data=data, name=\'id\')\n    else:\n        if dtype == \'float16\':\n            data = mx.sym.Cast(data=data, dtype=np.float16)\n    (nchannel, height, width) = image_shape\n    if height <= 32:            # such as cifar10\n        body = mx.sym.Convolution(data=data, num_filter=filter_list[0], kernel=(3, 3), stride=(1,1), pad=(1, 1),\n                                  no_bias=True, name=""conv0"", workspace=workspace)\n        # Is this BatchNorm supposed to be here?\n        body = mx.sym.BatchNorm(data=body, fix_gamma=False, eps=2e-5, momentum=bn_mom, name=\'bn0\')\n    else:                       # often expected to be 224 such as imagenet\n        body = mx.sym.Convolution(data=data, num_filter=filter_list[0], kernel=(7, 7), stride=(2,2), pad=(3, 3),\n                                  no_bias=True, name=""conv0"", workspace=workspace)\n        body = mx.sym.BatchNorm(data=body, fix_gamma=False, eps=2e-5, momentum=bn_mom, name=\'bn0\')\n        body = mx.sym.Activation(data=body, act_type=\'relu\', name=\'relu0\')\n        body = mx.sym.Pooling(data=body, kernel=(3, 3), stride=(2,2), pad=(1,1), pool_type=\'max\')\n\n    for i in range(num_stages):\n        body = residual_unit(body, filter_list[i+1], (1 if i==0 else 2, 1 if i==0 else 2), False,\n                             name=\'stage%d_unit%d\' % (i + 1, 1), bottle_neck=bottle_neck, workspace=workspace,\n                             memonger=memonger)\n        for j in range(units[i]-1):\n            body = residual_unit(body, filter_list[i+1], (1,1), True, name=\'stage%d_unit%d\' % (i + 1, j + 2),\n                                 bottle_neck=bottle_neck, workspace=workspace, memonger=memonger)\n    # bn1 = mx.sym.BatchNorm(data=body, fix_gamma=False, eps=2e-5, momentum=bn_mom, name=\'bn1\')\n    # relu1 = mx.sym.Activation(data=bn1, act_type=\'relu\', name=\'relu1\')\n    # Although kernel is not used here when global_pool=True, we should put one\n    pool1 = mx.sym.Pooling(data=body, global_pool=True, kernel=(7, 7), pool_type=\'avg\', name=\'pool1\')\n    flat = mx.sym.Flatten(data=pool1)\n    fc1 = mx.sym.FullyConnected(data=flat, num_hidden=num_classes, name=\'fc1\')\n    if dtype == \'float16\':\n        fc1 = mx.sym.Cast(data=fc1, dtype=np.float32)\n    return mx.sym.SoftmaxOutput(data=fc1, name=\'softmax\')\n\ndef get_symbol(num_classes, num_layers, image_shape, conv_workspace=256, dtype=\'float32\', **kwargs):\n    """"""\n    Adapted from https://github.com/tornadomeet/ResNet/blob/master/symbol_resnet.py\n    (Original author Wei Wu) by Antti-Pekka Hynninen\n    Implementing the original resnet ILSVRC 2015 winning network from:\n    Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun. ""Deep Residual Learning for Image Recognition""\n    """"""\n    image_shape = [int(l) for l in image_shape.split(\',\')]\n    (nchannel, height, width) = image_shape\n    if height <= 28:\n        num_stages = 3\n        if (num_layers-2) % 9 == 0 and num_layers >= 164:\n            per_unit = [(num_layers-2)//9]\n            filter_list = [16, 64, 128, 256]\n            bottle_neck = True\n        elif (num_layers-2) % 6 == 0 and num_layers < 164:\n            per_unit = [(num_layers-2)//6]\n            filter_list = [16, 16, 32, 64]\n            bottle_neck = False\n        else:\n            raise ValueError(""no experiments done on num_layers {}, you can do it yourself"".format(num_layers))\n        units = per_unit * num_stages\n    else:\n        if num_layers >= 50:\n            filter_list = [64, 256, 512, 1024, 2048]\n            bottle_neck = True\n        else:\n            filter_list = [64, 64, 128, 256, 512]\n            bottle_neck = False\n        num_stages = 4\n        if num_layers == 18:\n            units = [2, 2, 2, 2]\n        elif num_layers == 34:\n            units = [3, 4, 6, 3]\n        elif num_layers == 50:\n            units = [3, 4, 6, 3]\n        elif num_layers == 101:\n            units = [3, 4, 23, 3]\n        elif num_layers == 152:\n            units = [3, 8, 36, 3]\n        elif num_layers == 200:\n            units = [3, 24, 36, 3]\n        elif num_layers == 269:\n            units = [3, 30, 48, 8]\n        else:\n            raise ValueError(""no experiments done on num_layers {}, you can do it yourself"".format(num_layers))\n\n    return resnet(units       = units,\n                  num_stages  = num_stages,\n                  filter_list = filter_list,\n                  num_classes = num_classes,\n                  image_shape = image_shape,\n                  bottle_neck = bottle_neck,\n                  workspace   = conv_workspace,\n                  dtype       = dtype)\n'"
example/mxnet/symbols/resnet.py,0,"b'# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# ""License""); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n\n\'\'\'\nAdapted from https://github.com/tornadomeet/ResNet/blob/master/symbol_resnet.py\nOriginal author Wei Wu\n\nImplemented the following paper:\n\nKaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun. ""Identity Mappings in Deep Residual Networks""\n\'\'\'\nimport mxnet as mx\nimport numpy as np\n\ndef residual_unit(data, num_filter, stride, dim_match, name, bottle_neck=True, bn_mom=0.9, workspace=256, memonger=False):\n    """"""Return ResNet Unit symbol for building ResNet\n    Parameters\n    ----------\n    data : str\n        Input data\n    num_filter : int\n        Number of output channels\n    bnf : int\n        Bottle neck channels factor with regard to num_filter\n    stride : tuple\n        Stride used in convolution\n    dim_match : Boolean\n        True means channel number between input and output is the same, otherwise means differ\n    name : str\n        Base name of the operators\n    workspace : int\n        Workspace used in convolution operator\n    """"""\n    if bottle_neck:\n        # the same as https://github.com/facebook/fb.resnet.torch#notes, a bit difference with origin paper\n        bn1 = mx.sym.BatchNorm(data=data, fix_gamma=False, eps=2e-5, momentum=bn_mom, name=name + \'_bn1\')\n        act1 = mx.sym.Activation(data=bn1, act_type=\'relu\', name=name + \'_relu1\')\n        conv1 = mx.sym.Convolution(data=act1, num_filter=int(num_filter*0.25), kernel=(1,1), stride=(1,1), pad=(0,0),\n                                   no_bias=True, workspace=workspace, name=name + \'_conv1\')\n        bn2 = mx.sym.BatchNorm(data=conv1, fix_gamma=False, eps=2e-5, momentum=bn_mom, name=name + \'_bn2\')\n        act2 = mx.sym.Activation(data=bn2, act_type=\'relu\', name=name + \'_relu2\')\n        conv2 = mx.sym.Convolution(data=act2, num_filter=int(num_filter*0.25), kernel=(3,3), stride=stride, pad=(1,1),\n                                   no_bias=True, workspace=workspace, name=name + \'_conv2\')\n        bn3 = mx.sym.BatchNorm(data=conv2, fix_gamma=False, eps=2e-5, momentum=bn_mom, name=name + \'_bn3\')\n        act3 = mx.sym.Activation(data=bn3, act_type=\'relu\', name=name + \'_relu3\')\n        conv3 = mx.sym.Convolution(data=act3, num_filter=num_filter, kernel=(1,1), stride=(1,1), pad=(0,0), no_bias=True,\n                                   workspace=workspace, name=name + \'_conv3\')\n        if dim_match:\n            shortcut = data\n        else:\n            shortcut = mx.sym.Convolution(data=act1, num_filter=num_filter, kernel=(1,1), stride=stride, no_bias=True,\n                                            workspace=workspace, name=name+\'_sc\')\n        if memonger:\n            shortcut._set_attr(mirror_stage=\'True\')\n        return conv3 + shortcut\n    else:\n        bn1 = mx.sym.BatchNorm(data=data, fix_gamma=False, momentum=bn_mom, eps=2e-5, name=name + \'_bn1\')\n        act1 = mx.sym.Activation(data=bn1, act_type=\'relu\', name=name + \'_relu1\')\n        conv1 = mx.sym.Convolution(data=act1, num_filter=num_filter, kernel=(3,3), stride=stride, pad=(1,1),\n                                      no_bias=True, workspace=workspace, name=name + \'_conv1\')\n        bn2 = mx.sym.BatchNorm(data=conv1, fix_gamma=False, momentum=bn_mom, eps=2e-5, name=name + \'_bn2\')\n        act2 = mx.sym.Activation(data=bn2, act_type=\'relu\', name=name + \'_relu2\')\n        conv2 = mx.sym.Convolution(data=act2, num_filter=num_filter, kernel=(3,3), stride=(1,1), pad=(1,1),\n                                      no_bias=True, workspace=workspace, name=name + \'_conv2\')\n        if dim_match:\n            shortcut = data\n        else:\n            shortcut = mx.sym.Convolution(data=act1, num_filter=num_filter, kernel=(1,1), stride=stride, no_bias=True,\n                                            workspace=workspace, name=name+\'_sc\')\n        if memonger:\n            shortcut._set_attr(mirror_stage=\'True\')\n        return conv2 + shortcut\n\ndef resnet(units, num_stages, filter_list, num_classes, image_shape, bottle_neck=True, bn_mom=0.9, workspace=256, dtype=\'float32\', memonger=False):\n    """"""Return ResNet symbol of\n    Parameters\n    ----------\n    units : list\n        Number of units in each stage\n    num_stages : int\n        Number of stage\n    filter_list : list\n        Channel size of each stage\n    num_classes : int\n        Ouput size of symbol\n    dataset : str\n        Dataset type, only cifar10 and imagenet supports\n    workspace : int\n        Workspace used in convolution operator\n    dtype : str\n        Precision (float32 or float16)\n    """"""\n    num_unit = len(units)\n    assert(num_unit == num_stages)\n    data = mx.sym.Variable(name=\'data\')\n    if dtype == \'float32\':\n        data = mx.sym.identity(data=data, name=\'id\')\n    else:\n        if dtype == \'float16\':\n            data = mx.sym.Cast(data=data, dtype=np.float16)\n    data = mx.sym.BatchNorm(data=data, fix_gamma=True, eps=2e-5, momentum=bn_mom, name=\'bn_data\')\n    (nchannel, height, width) = image_shape\n    if height <= 32:            # such as cifar10\n        body = mx.sym.Convolution(data=data, num_filter=filter_list[0], kernel=(3, 3), stride=(1,1), pad=(1, 1),\n                                  no_bias=True, name=""conv0"", workspace=workspace)\n    else:                       # often expected to be 224 such as imagenet\n        body = mx.sym.Convolution(data=data, num_filter=filter_list[0], kernel=(7, 7), stride=(2,2), pad=(3, 3),\n                                  no_bias=True, name=""conv0"", workspace=workspace)\n        body = mx.sym.BatchNorm(data=body, fix_gamma=False, eps=2e-5, momentum=bn_mom, name=\'bn0\')\n        body = mx.sym.Activation(data=body, act_type=\'relu\', name=\'relu0\')\n        body = mx.sym.Pooling(data=body, kernel=(3, 3), stride=(2,2), pad=(1,1), pool_type=\'max\')\n\n    for i in range(num_stages):\n        body = residual_unit(body, filter_list[i+1], (1 if i==0 else 2, 1 if i==0 else 2), False,\n                             name=\'stage%d_unit%d\' % (i + 1, 1), bottle_neck=bottle_neck, workspace=workspace,\n                             memonger=memonger)\n        for j in range(units[i]-1):\n            body = residual_unit(body, filter_list[i+1], (1,1), True, name=\'stage%d_unit%d\' % (i + 1, j + 2),\n                                 bottle_neck=bottle_neck, workspace=workspace, memonger=memonger)\n    bn1 = mx.sym.BatchNorm(data=body, fix_gamma=False, eps=2e-5, momentum=bn_mom, name=\'bn1\')\n    relu1 = mx.sym.Activation(data=bn1, act_type=\'relu\', name=\'relu1\')\n    # Although kernel is not used here when global_pool=True, we should put one\n    pool1 = mx.sym.Pooling(data=relu1, global_pool=True, kernel=(7, 7), pool_type=\'avg\', name=\'pool1\')\n    flat = mx.sym.Flatten(data=pool1)\n    fc1 = mx.sym.FullyConnected(data=flat, num_hidden=num_classes, name=\'fc1\')\n    if dtype == \'float16\':\n        fc1 = mx.sym.Cast(data=fc1, dtype=np.float32)\n    return mx.sym.SoftmaxOutput(data=fc1, name=\'softmax\')\n\ndef get_symbol(num_classes, num_layers, image_shape, conv_workspace=256, dtype=\'float32\', **kwargs):\n    """"""\n    Adapted from https://github.com/tornadomeet/ResNet/blob/master/train_resnet.py\n    Original author Wei Wu\n    """"""\n    image_shape = [int(l) for l in image_shape.split(\',\')]\n    (nchannel, height, width) = image_shape\n    if height <= 28:\n        num_stages = 3\n        if (num_layers-2) % 9 == 0 and num_layers >= 164:\n            per_unit = [(num_layers-2)//9]\n            filter_list = [16, 64, 128, 256]\n            bottle_neck = True\n        elif (num_layers-2) % 6 == 0 and num_layers < 164:\n            per_unit = [(num_layers-2)//6]\n            filter_list = [16, 16, 32, 64]\n            bottle_neck = False\n        else:\n            raise ValueError(""no experiments done on num_layers {}, you can do it yourself"".format(num_layers))\n        units = per_unit * num_stages\n    else:\n        if num_layers >= 50:\n            filter_list = [64, 256, 512, 1024, 2048]\n            bottle_neck = True\n        else:\n            filter_list = [64, 64, 128, 256, 512]\n            bottle_neck = False\n        num_stages = 4\n        if num_layers == 18:\n            units = [2, 2, 2, 2]\n        elif num_layers == 34:\n            units = [3, 4, 6, 3]\n        elif num_layers == 50:\n            units = [3, 4, 6, 3]\n        elif num_layers == 101:\n            units = [3, 4, 23, 3]\n        elif num_layers == 152:\n            units = [3, 8, 36, 3]\n        elif num_layers == 200:\n            units = [3, 24, 36, 3]\n        elif num_layers == 269:\n            units = [3, 30, 48, 8]\n        else:\n            raise ValueError(""no experiments done on num_layers {}, you can do it yourself"".format(num_layers))\n\n    return resnet(units       = units,\n                  num_stages  = num_stages,\n                  filter_list = filter_list,\n                  num_classes = num_classes,\n                  image_shape = image_shape,\n                  bottle_neck = bottle_neck,\n                  workspace   = conv_workspace,\n                  dtype       = dtype)\n'"
example/mxnet/symbols/resnetv1.py,0,"b'# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# ""License""); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n\n\'\'\'\nAdapted from https://github.com/tornadomeet/ResNet/blob/master/symbol_resnet.py\n(Original author Wei Wu) by Antti-Pekka Hynninen\n\nImplementing the original resnet ILSVRC 2015 winning network from:\n\nKaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun. ""Deep Residual Learning for Image Recognition""\n\'\'\'\nimport mxnet as mx\nimport numpy as np\n\ndef residual_unit(data, num_filter, stride, dim_match, name, bottle_neck=True, bn_mom=0.9, workspace=256, memonger=False):\n    """"""Return ResNet Unit symbol for building ResNet\n    Parameters\n    ----------\n    data : str\n        Input data\n    num_filter : int\n        Number of output channels\n    bnf : int\n        Bottle neck channels factor with regard to num_filter\n    stride : tuple\n        Stride used in convolution\n    dim_match : Boolean\n        True means channel number between input and output is the same, otherwise means differ\n    name : str\n        Base name of the operators\n    workspace : int\n        Workspace used in convolution operator\n    """"""\n    if bottle_neck:\n        conv1 = mx.sym.Convolution(data=data, num_filter=int(num_filter*0.25), kernel=(1,1), stride=stride, pad=(0,0),\n                                   no_bias=True, workspace=workspace, name=name + \'_conv1\')\n        bn1 = mx.sym.BatchNorm(data=conv1, fix_gamma=False, eps=2e-5, momentum=bn_mom, name=name + \'_bn1\')\n        act1 = mx.sym.Activation(data=bn1, act_type=\'relu\', name=name + \'_relu1\')\n        conv2 = mx.sym.Convolution(data=act1, num_filter=int(num_filter*0.25), kernel=(3,3), stride=(1,1), pad=(1,1),\n                                   no_bias=True, workspace=workspace, name=name + \'_conv2\')\n        bn2 = mx.sym.BatchNorm(data=conv2, fix_gamma=False, eps=2e-5, momentum=bn_mom, name=name + \'_bn2\')\n        act2 = mx.sym.Activation(data=bn2, act_type=\'relu\', name=name + \'_relu2\')\n        conv3 = mx.sym.Convolution(data=act2, num_filter=num_filter, kernel=(1,1), stride=(1,1), pad=(0,0), no_bias=True,\n                                   workspace=workspace, name=name + \'_conv3\')\n        bn3 = mx.sym.BatchNorm(data=conv3, fix_gamma=False, eps=2e-5, momentum=bn_mom, name=name + \'_bn3\')\n\n        if dim_match:\n            shortcut = data\n        else:\n            conv1sc = mx.sym.Convolution(data=data, num_filter=num_filter, kernel=(1,1), stride=stride, no_bias=True,\n                                            workspace=workspace, name=name+\'_conv1sc\')\n            shortcut = mx.sym.BatchNorm(data=conv1sc, fix_gamma=False, eps=2e-5, momentum=bn_mom, name=name + \'_sc\')\n        if memonger:\n            shortcut._set_attr(mirror_stage=\'True\')\n        return mx.sym.Activation(data=bn3 + shortcut, act_type=\'relu\', name=name + \'_relu3\')\n    else:\n        conv1 = mx.sym.Convolution(data=data, num_filter=num_filter, kernel=(3,3), stride=stride, pad=(1,1),\n                                      no_bias=True, workspace=workspace, name=name + \'_conv1\')\n        bn1 = mx.sym.BatchNorm(data=conv1, fix_gamma=False, momentum=bn_mom, eps=2e-5, name=name + \'_bn1\')\n        act1 = mx.sym.Activation(data=bn1, act_type=\'relu\', name=name + \'_relu1\')\n        conv2 = mx.sym.Convolution(data=act1, num_filter=num_filter, kernel=(3,3), stride=(1,1), pad=(1,1),\n                                      no_bias=True, workspace=workspace, name=name + \'_conv2\')\n        bn2 = mx.sym.BatchNorm(data=conv2, fix_gamma=False, momentum=bn_mom, eps=2e-5, name=name + \'_bn2\')\n\n        if dim_match:\n            shortcut = data\n        else:\n            conv1sc = mx.sym.Convolution(data=data, num_filter=num_filter, kernel=(1,1), stride=stride, no_bias=True,\n                                            workspace=workspace, name=name+\'_conv1sc\')\n            shortcut = mx.sym.BatchNorm(data=conv1sc, fix_gamma=False, momentum=bn_mom, eps=2e-5, name=name + \'_sc\')\n        if memonger:\n            shortcut._set_attr(mirror_stage=\'True\')\n        return mx.sym.Activation(data=bn2 + shortcut, act_type=\'relu\', name=name + \'_relu3\')\n\ndef resnet(units, num_stages, filter_list, num_classes, image_shape, bottle_neck=True, bn_mom=0.9, workspace=256, dtype=\'float32\', memonger=False):\n    """"""Return ResNet symbol of\n    Parameters\n    ----------\n    units : list\n        Number of units in each stage\n    num_stages : int\n        Number of stage\n    filter_list : list\n        Channel size of each stage\n    num_classes : int\n        Ouput size of symbol\n    dataset : str\n        Dataset type, only cifar10 and imagenet supports\n    workspace : int\n        Workspace used in convolution operator\n    dtype : str\n        Precision (float32 or float16)\n    """"""\n    num_unit = len(units)\n    assert(num_unit == num_stages)\n    data = mx.sym.Variable(name=\'data\')\n    if dtype == \'float32\':\n        data = mx.sym.identity(data=data, name=\'id\')\n    else:\n        if dtype == \'float16\':\n            data = mx.sym.Cast(data=data, dtype=np.float16)\n    (nchannel, height, width) = image_shape\n    if height <= 32:            # such as cifar10\n        body = mx.sym.Convolution(data=data, num_filter=filter_list[0], kernel=(3, 3), stride=(1,1), pad=(1, 1),\n                                  no_bias=True, name=""conv0"", workspace=workspace)\n        # Is this BatchNorm supposed to be here?\n        body = mx.sym.BatchNorm(data=body, fix_gamma=False, eps=2e-5, momentum=bn_mom, name=\'bn0\')\n    else:                       # often expected to be 224 such as imagenet\n        body = mx.sym.Convolution(data=data, num_filter=filter_list[0], kernel=(7, 7), stride=(2,2), pad=(3, 3),\n                                  no_bias=True, name=""conv0"", workspace=workspace)\n        body = mx.sym.BatchNorm(data=body, fix_gamma=False, eps=2e-5, momentum=bn_mom, name=\'bn0\')\n        body = mx.sym.Activation(data=body, act_type=\'relu\', name=\'relu0\')\n        body = mx.sym.Pooling(data=body, kernel=(3, 3), stride=(2,2), pad=(1,1), pool_type=\'max\')\n\n    for i in range(num_stages):\n        body = residual_unit(body, filter_list[i+1], (1 if i==0 else 2, 1 if i==0 else 2), False,\n                             name=\'stage%d_unit%d\' % (i + 1, 1), bottle_neck=bottle_neck, workspace=workspace,\n                             memonger=memonger)\n        for j in range(units[i]-1):\n            body = residual_unit(body, filter_list[i+1], (1,1), True, name=\'stage%d_unit%d\' % (i + 1, j + 2),\n                                 bottle_neck=bottle_neck, workspace=workspace, memonger=memonger)\n    # bn1 = mx.sym.BatchNorm(data=body, fix_gamma=False, eps=2e-5, momentum=bn_mom, name=\'bn1\')\n    # relu1 = mx.sym.Activation(data=bn1, act_type=\'relu\', name=\'relu1\')\n    # Although kernel is not used here when global_pool=True, we should put one\n    pool1 = mx.sym.Pooling(data=body, global_pool=True, kernel=(7, 7), pool_type=\'avg\', name=\'pool1\')\n    flat = mx.sym.Flatten(data=pool1)\n    fc1 = mx.sym.FullyConnected(data=flat, num_hidden=num_classes, name=\'fc1\')\n    if dtype == \'float16\':\n        fc1 = mx.sym.Cast(data=fc1, dtype=np.float32)\n    return mx.sym.SoftmaxOutput(data=fc1, name=\'softmax\')\n\ndef get_symbol(num_classes, num_layers, image_shape, conv_workspace=256, dtype=\'float32\', **kwargs):\n    """"""\n    Adapted from https://github.com/tornadomeet/ResNet/blob/master/symbol_resnet.py\n    (Original author Wei Wu) by Antti-Pekka Hynninen\n    Implementing the original resnet ILSVRC 2015 winning network from:\n    Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun. ""Deep Residual Learning for Image Recognition""\n    """"""\n    image_shape = [int(l) for l in image_shape.split(\',\')]\n    (nchannel, height, width) = image_shape\n    if height <= 28:\n        num_stages = 3\n        if (num_layers-2) % 9 == 0 and num_layers >= 164:\n            per_unit = [(num_layers-2)//9]\n            filter_list = [16, 64, 128, 256]\n            bottle_neck = True\n        elif (num_layers-2) % 6 == 0 and num_layers < 164:\n            per_unit = [(num_layers-2)//6]\n            filter_list = [16, 16, 32, 64]\n            bottle_neck = False\n        else:\n            raise ValueError(""no experiments done on num_layers {}, you can do it yourself"".format(num_layers))\n        units = per_unit * num_stages\n    else:\n        if num_layers >= 50:\n            filter_list = [64, 256, 512, 1024, 2048]\n            bottle_neck = True\n        else:\n            filter_list = [64, 64, 128, 256, 512]\n            bottle_neck = False\n        num_stages = 4\n        if num_layers == 18:\n            units = [2, 2, 2, 2]\n        elif num_layers == 34:\n            units = [3, 4, 6, 3]\n        elif num_layers == 50:\n            units = [3, 4, 6, 3]\n        elif num_layers == 101:\n            units = [3, 4, 23, 3]\n        elif num_layers == 152:\n            units = [3, 8, 36, 3]\n        elif num_layers == 200:\n            units = [3, 24, 36, 3]\n        elif num_layers == 269:\n            units = [3, 30, 48, 8]\n        else:\n            raise ValueError(""no experiments done on num_layers {}, you can do it yourself"".format(num_layers))\n\n    return resnet(units       = units,\n                  num_stages  = num_stages,\n                  filter_list = filter_list,\n                  num_classes = num_classes,\n                  image_shape = image_shape,\n                  bottle_neck = bottle_neck,\n                  workspace   = conv_workspace,\n                  dtype       = dtype)\n'"
example/mxnet/symbols/resnext.py,0,"b'# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# ""License""); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n\n\'\'\'\nAdapted from https://github.com/tornadomeet/ResNet/blob/master/symbol_resnet.py\nOriginal author Wei Wu\n\nImplemented the following paper:\nSaining Xie, Ross Girshick, Piotr Dollar, Zhuowen Tu, Kaiming He. ""Aggregated Residual Transformations for Deep Neural Network""\n\'\'\'\nimport mxnet as mx\nimport numpy as np\n\ndef residual_unit(data, num_filter, stride, dim_match, name, bottle_neck=True, num_group=32, bn_mom=0.9, workspace=256, memonger=False):\n    """"""Return ResNet Unit symbol for building ResNet\n    Parameters\n    ----------\n    data : str\n        Input data\n    num_filter : int\n        Number of output channels\n    bnf : int\n        Bottle neck channels factor with regard to num_filter\n    stride : tuple\n        Stride used in convolution\n    dim_match : Boolean\n        True means channel number between input and output is the same, otherwise means differ\n    name : str\n        Base name of the operators\n    workspace : int\n        Workspace used in convolution operator\n    """"""\n    if bottle_neck:\n        # the same as https://github.com/facebook/fb.resnet.torch#notes, a bit difference with origin paper\n\n        conv1 = mx.sym.Convolution(data=data, num_filter=int(num_filter*0.5), kernel=(1,1), stride=(1,1), pad=(0,0),\n                                      no_bias=True, workspace=workspace, name=name + \'_conv1\')\n        bn1 = mx.sym.BatchNorm(data=conv1, fix_gamma=False, eps=2e-5, momentum=bn_mom, name=name + \'_bn1\')\n        act1 = mx.sym.Activation(data=bn1, act_type=\'relu\', name=name + \'_relu1\')\n\n\n        conv2 = mx.sym.Convolution(data=act1, num_filter=int(num_filter*0.5), num_group=num_group, kernel=(3,3), stride=stride, pad=(1,1),\n                                      no_bias=True, workspace=workspace, name=name + \'_conv2\')\n        bn2 = mx.sym.BatchNorm(data=conv2, fix_gamma=False, eps=2e-5, momentum=bn_mom, name=name + \'_bn2\')\n        act2 = mx.sym.Activation(data=bn2, act_type=\'relu\', name=name + \'_relu2\')\n\n\n        conv3 = mx.sym.Convolution(data=act2, num_filter=num_filter, kernel=(1,1), stride=(1,1), pad=(0,0), no_bias=True,\n                                   workspace=workspace, name=name + \'_conv3\')\n        bn3 = mx.sym.BatchNorm(data=conv3, fix_gamma=False, eps=2e-5, momentum=bn_mom, name=name + \'_bn3\')\n\n        if dim_match:\n            shortcut = data\n        else:\n            shortcut_conv = mx.sym.Convolution(data=data, num_filter=num_filter, kernel=(1,1), stride=stride, no_bias=True,\n                                            workspace=workspace, name=name+\'_sc\')\n            shortcut = mx.sym.BatchNorm(data=shortcut_conv, fix_gamma=False, eps=2e-5, momentum=bn_mom, name=name + \'_sc_bn\')\n\n        if memonger:\n            shortcut._set_attr(mirror_stage=\'True\')\n        eltwise =  bn3 + shortcut\n        return mx.sym.Activation(data=eltwise, act_type=\'relu\', name=name + \'_relu\')\n    else:\n\n        conv1 = mx.sym.Convolution(data=data, num_filter=num_filter, kernel=(3,3), stride=stride, pad=(1,1),\n                                      no_bias=True, workspace=workspace, name=name + \'_conv1\')\n        bn1 = mx.sym.BatchNorm(data=conv1, fix_gamma=False, momentum=bn_mom, eps=2e-5, name=name + \'_bn1\')\n        act1 = mx.sym.Activation(data=bn1, act_type=\'relu\', name=name + \'_relu1\')\n\n\n        conv2 = mx.sym.Convolution(data=act1, num_filter=num_filter, kernel=(3,3), stride=(1,1), pad=(1,1),\n                                      no_bias=True, workspace=workspace, name=name + \'_conv2\')\n        bn2 = mx.sym.BatchNorm(data=conv2, fix_gamma=False, momentum=bn_mom, eps=2e-5, name=name + \'_bn2\')\n\n        if dim_match:\n            shortcut = data\n        else:\n            shortcut_conv = mx.sym.Convolution(data=data, num_filter=num_filter, kernel=(1,1), stride=stride, no_bias=True,\n                                            workspace=workspace, name=name+\'_sc\')\n            shortcut = mx.sym.BatchNorm(data=shortcut_conv, fix_gamma=False, eps=2e-5, momentum=bn_mom, name=name + \'_sc_bn\')\n\n        if memonger:\n            shortcut._set_attr(mirror_stage=\'True\')\n        eltwise = bn2 + shortcut\n        return mx.sym.Activation(data=eltwise, act_type=\'relu\', name=name + \'_relu\')\n\ndef resnext(units, num_stages, filter_list, num_classes, num_group, image_shape, bottle_neck=True, bn_mom=0.9, workspace=256, dtype=\'float32\', memonger=False):\n    """"""Return ResNeXt symbol of\n    Parameters\n    ----------\n    units : list\n        Number of units in each stage\n    num_stages : int\n        Number of stage\n    filter_list : list\n        Channel size of each stage\n    num_classes : int\n        Ouput size of symbol\n    num_groupes: int\n    Number of conv groups\n    dataset : str\n        Dataset type, only cifar10 and imagenet supports\n    workspace : int\n        Workspace used in convolution operator\n    dtype : str\n        Precision (float32 or float16)\n    """"""\n    num_unit = len(units)\n    assert(num_unit == num_stages)\n    data = mx.sym.Variable(name=\'data\')\n    if dtype == \'float32\':\n        data = mx.sym.identity(data=data, name=\'id\')\n    else:\n        if dtype == \'float16\':\n            data = mx.sym.Cast(data=data, dtype=np.float16)\n    data = mx.sym.BatchNorm(data=data, fix_gamma=True, eps=2e-5, momentum=bn_mom, name=\'bn_data\')\n    (nchannel, height, width) = image_shape\n    if height <= 32:            # such as cifar10\n        body = mx.sym.Convolution(data=data, num_filter=filter_list[0], kernel=(3, 3), stride=(1,1), pad=(1, 1),\n                                  no_bias=True, name=""conv0"", workspace=workspace)\n    else:                       # often expected to be 224 such as imagenet\n        body = mx.sym.Convolution(data=data, num_filter=filter_list[0], kernel=(7, 7), stride=(2,2), pad=(3, 3),\n                                  no_bias=True, name=""conv0"", workspace=workspace)\n        body = mx.sym.BatchNorm(data=body, fix_gamma=False, eps=2e-5, momentum=bn_mom, name=\'bn0\')\n        body = mx.sym.Activation(data=body, act_type=\'relu\', name=\'relu0\')\n        body = mx.sym.Pooling(data=body, kernel=(3, 3), stride=(2,2), pad=(1,1), pool_type=\'max\')\n\n    for i in range(num_stages):\n        body = residual_unit(body, filter_list[i+1], (1 if i==0 else 2, 1 if i==0 else 2), False,\n                             name=\'stage%d_unit%d\' % (i + 1, 1), bottle_neck=bottle_neck, num_group=num_group,\n                             bn_mom=bn_mom, workspace=workspace, memonger=memonger)\n        for j in range(units[i]-1):\n            body = residual_unit(body, filter_list[i+1], (1,1), True, name=\'stage%d_unit%d\' % (i + 1, j + 2),\n                                 bottle_neck=bottle_neck, num_group=num_group, bn_mom=bn_mom, workspace=workspace, memonger=memonger)\n\n    pool1 = mx.sym.Pooling(data=body, global_pool=True, kernel=(7, 7), pool_type=\'avg\', name=\'pool1\')\n    flat = mx.sym.Flatten(data=pool1)\n    fc1 = mx.sym.FullyConnected(data=flat, num_hidden=num_classes, name=\'fc1\')\n    if dtype == \'float16\':\n        fc1 = mx.sym.Cast(data=fc1, dtype=np.float32)\n    return mx.sym.SoftmaxOutput(data=fc1, name=\'softmax\')\n\ndef get_symbol(num_classes, num_layers, image_shape, num_group=32, conv_workspace=256, dtype=\'float32\', **kwargs):\n    """"""\n    Adapted from https://github.com/tornadomeet/ResNet/blob/master/train_resnet.py\n    Original author Wei Wu\n    """"""\n    image_shape = [int(l) for l in image_shape.split(\',\')]\n    (nchannel, height, width) = image_shape\n    if height <= 32:\n        num_stages = 3\n        if (num_layers-2) % 9 == 0 and num_layers >= 164:\n            per_unit = [(num_layers-2)//9]\n            filter_list = [16, 64, 128, 256]\n            bottle_neck = True\n        elif (num_layers-2) % 6 == 0 and num_layers < 164:\n            per_unit = [(num_layers-2)//6]\n            filter_list = [16, 16, 32, 64]\n            bottle_neck = False\n        else:\n            raise ValueError(""no experiments done on num_layers {}, you can do it yourself"".format(num_layers))\n        units = per_unit * num_stages\n    else:\n        if num_layers >= 50:\n            filter_list = [64, 256, 512, 1024, 2048]\n            bottle_neck = True\n        else:\n            filter_list = [64, 64, 128, 256, 512]\n            bottle_neck = False\n        num_stages = 4\n        if num_layers == 18:\n            units = [2, 2, 2, 2]\n        elif num_layers == 34:\n            units = [3, 4, 6, 3]\n        elif num_layers == 50:\n            units = [3, 4, 6, 3]\n        elif num_layers == 101:\n            units = [3, 4, 23, 3]\n        elif num_layers == 152:\n            units = [3, 8, 36, 3]\n        elif num_layers == 200:\n            units = [3, 24, 36, 3]\n        elif num_layers == 269:\n            units = [3, 30, 48, 8]\n        else:\n            raise ValueError(""no experiments done on num_layers {}, you can do it yourself"".format(num_layers))\n\n    return resnext(units      = units,\n                  num_stages  = num_stages,\n                  filter_list = filter_list,\n                  num_classes = num_classes,\n                  num_group   = num_group,\n                  image_shape = image_shape,\n                  bottle_neck = bottle_neck,\n                  workspace   = conv_workspace,\n                  dtype       = dtype)\n'"
example/mxnet/symbols/vgg.py,0,"b'# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# ""License""); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n\n""""""References:\n\nSimonyan, Karen, and Andrew Zisserman. ""Very deep convolutional networks for\nlarge-scale image recognition."" arXiv preprint arXiv:1409.1556 (2014).\n""""""\n\nimport mxnet as mx\nimport numpy as np\n\ndef get_feature(internel_layer, layers, filters, batch_norm = False, **kwargs):\n    for i, num in enumerate(layers):\n        for j in range(num):\n            internel_layer = mx.sym.Convolution(data = internel_layer, kernel=(3, 3), pad=(1, 1), num_filter=filters[i], name=""conv%s_%s"" %(i + 1, j + 1))\n            if batch_norm:\n                internel_layer = mx.symbol.BatchNorm(data=internel_layer, name=""bn%s_%s"" %(i + 1, j + 1))\n            internel_layer = mx.sym.Activation(data=internel_layer, act_type=""relu"", name=""relu%s_%s"" %(i + 1, j + 1))\n        internel_layer = mx.sym.Pooling(data=internel_layer, pool_type=""max"", kernel=(2, 2), stride=(2,2), name=""pool%s"" %(i + 1))\n    return internel_layer\n\ndef get_classifier(input_data, num_classes, **kwargs):\n    flatten = mx.sym.Flatten(data=input_data, name=""flatten"")\n    fc6 = mx.sym.FullyConnected(data=flatten, num_hidden=4096, name=""fc6"")\n    relu6 = mx.sym.Activation(data=fc6, act_type=""relu"", name=""relu6"")\n    drop6 = mx.sym.Dropout(data=relu6, p=0.5, name=""drop6"")\n    fc7 = mx.sym.FullyConnected(data=drop6, num_hidden=4096, name=""fc7"")\n    relu7 = mx.sym.Activation(data=fc7, act_type=""relu"", name=""relu7"")\n    drop7 = mx.sym.Dropout(data=relu7, p=0.5, name=""drop7"")\n    fc8 = mx.sym.FullyConnected(data=drop7, num_hidden=num_classes, name=""fc8"")\n    return fc8\n\ndef get_symbol(num_classes, num_layers=11, batch_norm=False, dtype=\'float32\', **kwargs):\n    """"""\n    Parameters\n    ----------\n    num_classes : int, default 1000\n        Number of classification classes.\n    num_layers : int\n        Number of layers for the variant of densenet. Options are 11, 13, 16, 19.\n    batch_norm : bool, default False\n        Use batch normalization.\n    dtype: str, float32 or float16\n        Data precision.\n    """"""\n    vgg_spec = {11: ([1, 1, 2, 2, 2], [64, 128, 256, 512, 512]),\n                13: ([2, 2, 2, 2, 2], [64, 128, 256, 512, 512]),\n                16: ([2, 2, 3, 3, 3], [64, 128, 256, 512, 512]),\n                19: ([2, 2, 4, 4, 4], [64, 128, 256, 512, 512])}\n    if num_layers not in vgg_spec:\n        raise ValueError(""Invalide num_layers {}. Possible choices are 11,13,16,19."".format(num_layers))\n    layers, filters = vgg_spec[num_layers]\n    data = mx.sym.Variable(name=""data"")\n    if dtype == \'float16\':\n        data = mx.sym.Cast(data=data, dtype=np.float16)\n    feature = get_feature(data, layers, filters, batch_norm)\n    classifier = get_classifier(feature, num_classes)\n    if dtype == \'float16\':\n        classifier = mx.sym.Cast(data=classifier, dtype=np.float32)\n    symbol = mx.sym.SoftmaxOutput(data=classifier, name=\'softmax\')\n    return symbol\n'"
