file_path,api_count,code
configuration.py,0,"b'# some training parameters\nEPOCHS = 50\nBATCH_SIZE = 8\nNUM_CLASSES = 5\nIMAGE_HEIGHT = 224\nIMAGE_WIDTH = 224\nCHANNELS = 3\n\nsave_model_dir = ""saved_model/""\nsave_every_n_epoch = 10\ntest_image_dir = """"\n\ndataset_dir = ""dataset/""\ntrain_dir = dataset_dir + ""train""\nvalid_dir = dataset_dir + ""valid""\ntest_dir = dataset_dir + ""test""\ntrain_tfrecord = dataset_dir + ""train.tfrecord""\nvalid_tfrecord = dataset_dir + ""valid.tfrecord""\ntest_tfrecord = dataset_dir + ""test.tfrecord""\n# VALID_SET_RATIO = 1 - TRAIN_SET_RATIO - TEST_SET_RATIO\nTRAIN_SET_RATIO = 0.6\nTEST_SET_RATIO = 0.2\n\n# choose a network\n# 0: mobilenet_v1, 1: mobilenet_v2, 2: mobilenet_v3_large, 3: mobilenet_v3_small\n# 4: efficient_net_b0, 5: efficient_net_b1, 6: efficient_net_b2, 7: efficient_net_b3\n# 8: efficient_net_b4, 9: efficient_net_b5, 10: efficient_net_b6, 11: efficient_net_b7\n# 12: ResNeXt50, 13: ResNeXt101\n# 14: InceptionV4, 15: InceptionResNetV1, 16: InceptionResNetV2\n# 17: SE_ResNet_50, 18: SE_ResNet_101, 19: SE_ResNet_152\n# 20: SqueezeNet\n# 21: DenseNet_121, 22: DenseNet_169, 23: DenseNet_201, 24: DenseNet_269\n# 25 ~ 28 : ShuffleNetV2 (0.5x, 1.0x, 1.5x, 2.0x)\n# 29: ResNet_18, 30: ResNet_34, 31: ResNet_50, 32: ResNet_101, 33: ResNet_152\n# 34: SEResNeXt_50, 35: SEResNeXt_101\n\n# EfficientNets:\n# b0 = (1.0, 1.0, 224, 0.2)\n# b1 = (1.0, 1.1, 240, 0.2)\n# b2 = (1.1, 1.2, 260, 0.3)\n# b3 = (1.2, 1.4, 300, 0.3)\n# b4 = (1.4, 1.8, 380, 0.4)\n# b5 = (1.6, 2.2, 456, 0.4)\n# b6 = (1.8, 2.6, 528, 0.5)\n# b7 = (2.0, 3.1, 600, 0.5)\nmodel_index = 35\n\n'"
evaluate.py,7,"b'import tensorflow as tf\nfrom configuration import save_model_dir\nfrom prepare_data import generate_datasets\nfrom train import get_model, process_features\n\nif __name__ == \'__main__\':\n\n    # GPU settings\n    gpus = tf.config.list_physical_devices(\'GPU\')\n    if gpus:\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n\n    # get the original_dataset\n    train_dataset, valid_dataset, test_dataset, train_count, valid_count, test_count = generate_datasets()\n    # load the model\n    model = get_model()\n    model.load_weights(filepath=save_model_dir)\n    # model = tf.saved_model.load(save_model_dir)\n\n    # Get the accuracy on the test set\n    loss_object = tf.keras.metrics.SparseCategoricalCrossentropy()\n    test_loss = tf.keras.metrics.Mean()\n    test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n\n    # @tf.function\n    def test_step(images, labels):\n        predictions = model(images, training=False)\n        t_loss = loss_object(labels, predictions)\n        test_loss(t_loss)\n        test_accuracy(labels, predictions)\n\n    for features in test_dataset:\n        test_images, test_labels = process_features(features, data_augmentation=False)\n        test_step(test_images, test_labels)\n        print(""loss: {:.5f}, test accuracy: {:.5f}"".format(test_loss.result(),\n                                                           test_accuracy.result()))\n\n    print(""The accuracy on test set is: {:.3f}%"".format(test_accuracy.result()*100))'"
parse_tfrecord.py,5,"b""import tensorflow as tf\n\n\ndef _parse_image_function(example_proto):\n    # Parse the input tf.Example proto.\n    return tf.io.parse_single_example(example_proto, {\n        'label': tf.io.FixedLenFeature([], tf.dtypes.int64),\n        'image_raw': tf.io.FixedLenFeature([], tf.dtypes.string),\n    })\n\n\ndef get_parsed_dataset(tfrecord_name):\n    raw_dataset = tf.data.TFRecordDataset(tfrecord_name)\n    parsed_dataset = raw_dataset.map(_parse_image_function)\n\n    return parsed_dataset"""
predict.py,5,"b'import tensorflow as tf\nfrom configuration import save_model_dir, test_image_dir\nfrom prepare_data import load_and_preprocess_image\nfrom train import get_model\n\n\ndef get_single_picture_prediction(model, picture_dir):\n    image_tensor = load_and_preprocess_image(tf.io.read_file(filename=picture_dir), data_augmentation=False)\n    image = tf.expand_dims(image_tensor, axis=0)\n    prediction = model(image, training=False)\n    pred_class = tf.math.argmax(prediction, axis=-1)\n    return pred_class\n\n\nif __name__ == \'__main__\':\n    # GPU settings\n    gpus = tf.config.list_physical_devices(\'GPU\')\n    if gpus:\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n\n    # load the model\n    model = get_model()\n    model.load_weights(filepath=save_model_dir+""model"")\n\n    pred_class = get_single_picture_prediction(model, test_image_dir)\n    print(pred_class)'"
prepare_data.py,6,"b""import tensorflow as tf\nimport pathlib\nfrom configuration import IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS, \\\n    BATCH_SIZE, train_tfrecord, valid_tfrecord, test_tfrecord\nfrom parse_tfrecord import get_parsed_dataset\n\n\ndef load_and_preprocess_image(image_raw, data_augmentation=False):\n    # decode\n    image_tensor = tf.io.decode_image(contents=image_raw, channels=CHANNELS, dtype=tf.dtypes.float32)\n\n    if data_augmentation:\n        image = tf.image.random_flip_left_right(image=image_tensor)\n        image = tf.image.resize_with_crop_or_pad(image=image,\n                                                 target_height=int(IMAGE_HEIGHT * 1.2),\n                                                 target_width=int(IMAGE_WIDTH * 1.2))\n        image = tf.image.random_crop(value=image, size=[IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS])\n        image = tf.image.random_brightness(image=image, max_delta=0.5)\n    else:\n        image = tf.image.resize(image_tensor, [IMAGE_HEIGHT, IMAGE_WIDTH])\n\n    return image\n\n\ndef get_images_and_labels(data_root_dir):\n    # get all images' paths (format: string)\n    data_root = pathlib.Path(data_root_dir)\n    all_image_path = [str(path) for path in list(data_root.glob('*/*'))]\n    # get labels' names\n    label_names = sorted(item.name for item in data_root.glob('*/'))\n    # dict: {label : index}\n    label_to_index = dict((label, index) for index, label in enumerate(label_names))\n    # get all images' labels\n    all_image_label = [label_to_index[pathlib.Path(single_image_path).parent.name] for single_image_path in all_image_path]\n\n    return all_image_path, all_image_label\n\n\ndef get_the_length_of_dataset(dataset):\n    count = 0\n    for i in dataset:\n        count += 1\n    return count\n\n\ndef generate_datasets():\n    train_dataset = get_parsed_dataset(tfrecord_name=train_tfrecord)\n    valid_dataset = get_parsed_dataset(tfrecord_name=valid_tfrecord)\n    test_dataset = get_parsed_dataset(tfrecord_name=test_tfrecord)\n\n    train_count = get_the_length_of_dataset(train_dataset)\n    valid_count = get_the_length_of_dataset(valid_dataset)\n    test_count = get_the_length_of_dataset(test_dataset)\n\n    # read the dataset in the form of batch\n    train_dataset = train_dataset.batch(batch_size=BATCH_SIZE)\n    valid_dataset = valid_dataset.batch(batch_size=BATCH_SIZE)\n    test_dataset = test_dataset.batch(batch_size=BATCH_SIZE)\n\n    return train_dataset, valid_dataset, test_dataset, train_count, valid_count, test_count\n"""
split_dataset.py,0,"b'import os\nimport random\nimport shutil\nfrom configuration import TRAIN_SET_RATIO, TEST_SET_RATIO\n\nclass SplitDataset():\n    def __init__(self, dataset_dir, saved_dataset_dir, train_ratio=TRAIN_SET_RATIO, test_ratio=TEST_SET_RATIO, show_progress=False):\n        self.dataset_dir = dataset_dir\n        self.saved_dataset_dir = saved_dataset_dir\n        self.saved_train_dir = saved_dataset_dir + ""/train/""\n        self.saved_valid_dir = saved_dataset_dir + ""/valid/""\n        self.saved_test_dir = saved_dataset_dir + ""/test/""\n\n\n        self.train_ratio = train_ratio\n        self.test_radio = test_ratio\n        self.valid_ratio = 1 - train_ratio - test_ratio\n\n        self.train_file_path = []\n        self.valid_file_path = []\n        self.test_file_path = []\n\n        self.index_label_dict = {}\n\n        self.show_progress = show_progress\n\n        if not os.path.exists(self.saved_train_dir):\n            os.mkdir(self.saved_train_dir)\n        if not os.path.exists(self.saved_test_dir):\n            os.mkdir(self.saved_test_dir)\n        if not os.path.exists(self.saved_valid_dir):\n            os.mkdir(self.saved_valid_dir)\n\n\n    def __get_label_names(self):\n        label_names = []\n        for item in os.listdir(self.dataset_dir):\n            item_path = os.path.join(self.dataset_dir, item)\n            if os.path.isdir(item_path):\n                label_names.append(item)\n        return label_names\n\n    def __get_all_file_path(self):\n        all_file_path = []\n        index = 0\n        for file_type in self.__get_label_names():\n            self.index_label_dict[index] = file_type\n            index += 1\n            type_file_path = os.path.join(self.dataset_dir, file_type)\n            file_path = []\n            for file in os.listdir(type_file_path):\n                single_file_path = os.path.join(type_file_path, file)\n                file_path.append(single_file_path)\n            all_file_path.append(file_path)\n        return all_file_path\n\n    def __copy_files(self, type_path, type_saved_dir):\n        for item in type_path:\n            src_path_list = item[1]\n            dst_path = type_saved_dir + ""%s/"" % (item[0])\n            if not os.path.exists(dst_path):\n                os.mkdir(dst_path)\n            for src_path in src_path_list:\n                shutil.copy(src_path, dst_path)\n                if self.show_progress:\n                    print(""Copying file ""+src_path+"" to ""+dst_path)\n\n    def __split_dataset(self):\n        all_file_paths = self.__get_all_file_path()\n        for index in range(len(all_file_paths)):\n            file_path_list = all_file_paths[index]\n            file_path_list_length = len(file_path_list)\n            random.shuffle(file_path_list)\n\n            train_num = int(file_path_list_length * self.train_ratio)\n            test_num = int(file_path_list_length * self.test_radio)\n\n            self.train_file_path.append([self.index_label_dict[index], file_path_list[: train_num]])\n            self.test_file_path.append([self.index_label_dict[index], file_path_list[train_num:train_num + test_num]])\n            self.valid_file_path.append([self.index_label_dict[index], file_path_list[train_num + test_num:]])\n\n    def start_splitting(self):\n        self.__split_dataset()\n        self.__copy_files(type_path=self.train_file_path, type_saved_dir=self.saved_train_dir)\n        self.__copy_files(type_path=self.valid_file_path, type_saved_dir=self.saved_valid_dir)\n        self.__copy_files(type_path=self.test_file_path, type_saved_dir=self.saved_test_dir)\n\n\nif __name__ == \'__main__\':\n    split_dataset = SplitDataset(dataset_dir=""original_dataset"",\n                                 saved_dataset_dir=""dataset"",\n                                 show_progress=True)\n    split_dataset.start_splitting()'"
test_single_image.py,5,"b'import tensorflow as tf\nimport os\n\nfrom configuration import save_model_dir, test_image_dir\nfrom train import get_model\nfrom prepare_data import load_and_preprocess_image\n\n\ndef get_class_id(image_root):\n    id_cls = {}\n    for i, item in enumerate(os.listdir(image_root)):\n        if os.path.isdir(os.path.join(image_root, item)):\n            id_cls[i] = item\n    return id_cls\n\n\nif __name__ == \'__main__\':\n    # GPU settings\n    gpus = tf.config.list_physical_devices(\'GPU\')\n    if gpus:\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n\n    model = get_model()\n    model.load_weights(filepath=save_model_dir)\n\n    image_raw = tf.io.read_file(filename=test_image_dir)\n    image_tensor = load_and_preprocess_image(image_raw)\n    image_tensor = tf.expand_dims(image_tensor, axis=0)\n\n    pred = model(image_tensor, training=False)\n    idx = tf.math.argmax(pred, axis=-1).numpy()[0]\n\n    id_cls = get_class_id(""./original_dataset"")\n\n    print(""The predicted category of this picture is: {}"".format(id_cls[idx]))'"
to_tfrecord.py,7,"b'import tensorflow as tf\nfrom configuration import train_dir, valid_dir, test_dir, train_tfrecord, valid_tfrecord, test_tfrecord\nfrom prepare_data import get_images_and_labels\nimport random\n\n# convert a value to a type compatible tf.train.Feature\ndef _bytes_feature(value):\n    # Returns a bytes_list from a string / byte.\n    if isinstance(value, type(tf.constant(0.))):\n        value = value.numpy()   # BytesList won\'t unpack a string from an EagerTensor.\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\n\ndef _float_feature(value):\n    # Returns a float_list from a float / double.\n    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n\n\ndef _int64_feature(value):\n    # Returns an int64_list from a bool / enum / int / uint.\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n\n\n# Create a dictionary with features that may be relevant.\ndef image_example(image_string, label):\n    feature = {\n        \'label\': _int64_feature(label),\n        \'image_raw\': _bytes_feature(image_string),\n    }\n\n    return tf.train.Example(features=tf.train.Features(feature=feature))\n\n\ndef shuffle_dict(original_dict):\n    keys = []\n    shuffled_dict = {}\n    for k in original_dict.keys():\n        keys.append(k)\n    random.shuffle(keys)\n    for item in keys:\n        shuffled_dict[item] = original_dict[item]\n    return shuffled_dict\n\n\ndef dataset_to_tfrecord(dataset_dir, tfrecord_name):\n    image_paths, image_labels = get_images_and_labels(dataset_dir)\n    image_paths_and_labels_dict = {}\n    for i in range(len(image_paths)):\n        image_paths_and_labels_dict[image_paths[i]] = image_labels[i]\n    # shuffle the dict\n    image_paths_and_labels_dict = shuffle_dict(image_paths_and_labels_dict)\n    # write the images and labels to tfrecord format file\n    with tf.io.TFRecordWriter(path=tfrecord_name) as writer:\n        for image_path, label in image_paths_and_labels_dict.items():\n            print(""Writing to tfrecord: {}"".format(image_path))\n            image_string = open(image_path, \'rb\').read()\n            tf_example = image_example(image_string, label)\n            writer.write(tf_example.SerializeToString())\n\n\nif __name__ == \'__main__\':\n    dataset_to_tfrecord(dataset_dir=train_dir, tfrecord_name=train_tfrecord)\n    dataset_to_tfrecord(dataset_dir=valid_dir, tfrecord_name=valid_tfrecord)\n    dataset_to_tfrecord(dataset_dir=test_dir, tfrecord_name=test_tfrecord)'"
train.py,15,"b'from __future__ import absolute_import, division, print_function\nimport tensorflow as tf\nfrom configuration import IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS, \\\n    EPOCHS, BATCH_SIZE, save_model_dir, model_index, save_every_n_epoch\nfrom prepare_data import generate_datasets, load_and_preprocess_image\nimport math\nfrom models import mobilenet_v1, mobilenet_v2, mobilenet_v3_large, mobilenet_v3_small, \\\n    efficientnet, resnext, inception_v4, inception_resnet_v1, inception_resnet_v2, \\\n    se_resnet, squeezenet, densenet, shufflenet_v2, resnet, se_resnext\n\n\ndef get_model():\n    if model_index == 0:\n        return mobilenet_v1.MobileNetV1()\n    elif model_index == 1:\n        return mobilenet_v2.MobileNetV2()\n    elif model_index == 2:\n        return mobilenet_v3_large.MobileNetV3Large()\n    elif model_index == 3:\n        return mobilenet_v3_small.MobileNetV3Small()\n    elif model_index == 4:\n        return efficientnet.efficient_net_b0()\n    elif model_index == 5:\n        return efficientnet.efficient_net_b1()\n    elif model_index == 6:\n        return efficientnet.efficient_net_b2()\n    elif model_index == 7:\n        return efficientnet.efficient_net_b3()\n    elif model_index == 8:\n        return efficientnet.efficient_net_b4()\n    elif model_index == 9:\n        return efficientnet.efficient_net_b5()\n    elif model_index == 10:\n        return efficientnet.efficient_net_b6()\n    elif model_index == 11:\n        return efficientnet.efficient_net_b7()\n    elif model_index == 12:\n        return resnext.ResNeXt50()\n    elif model_index == 13:\n        return resnext.ResNeXt101()\n    elif model_index == 14:\n        return inception_v4.InceptionV4()\n    elif model_index == 15:\n        return inception_resnet_v1.InceptionResNetV1()\n    elif model_index == 16:\n        return inception_resnet_v2.InceptionResNetV2()\n    elif model_index == 17:\n        return se_resnet.se_resnet_50()\n    elif model_index == 18:\n        return se_resnet.se_resnet_101()\n    elif model_index == 19:\n        return se_resnet.se_resnet_152()\n    elif model_index == 20:\n        return squeezenet.SqueezeNet()\n    elif model_index == 21:\n        return densenet.densenet_121()\n    elif model_index == 22:\n        return densenet.densenet_169()\n    elif model_index == 23:\n        return densenet.densenet_201()\n    elif model_index == 24:\n        return densenet.densenet_264()\n    elif model_index == 25:\n        return shufflenet_v2.shufflenet_0_5x()\n    elif model_index == 26:\n        return shufflenet_v2.shufflenet_1_0x()\n    elif model_index == 27:\n        return shufflenet_v2.shufflenet_1_5x()\n    elif model_index == 28:\n        return shufflenet_v2.shufflenet_2_0x()\n    elif model_index == 29:\n        return resnet.resnet_18()\n    elif model_index == 30:\n        return resnet.resnet_34()\n    elif model_index == 31:\n        return resnet.resnet_50()\n    elif model_index == 32:\n        return resnet.resnet_101()\n    elif model_index == 33:\n        return resnet.resnet_152()\n    elif model_index == 34:\n        return se_resnext.SEResNeXt50()\n    elif model_index == 35:\n        return se_resnext.SEResNeXt101()\n    else:\n        raise ValueError(""The model_index does not exist."")\n\n\ndef print_model_summary(network):\n    network.build(input_shape=(None, IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS))\n    network.summary()\n\n\ndef process_features(features, data_augmentation):\n    image_raw = features[\'image_raw\'].numpy()\n    image_tensor_list = []\n    for image in image_raw:\n        image_tensor = load_and_preprocess_image(image, data_augmentation=data_augmentation)\n        image_tensor_list.append(image_tensor)\n    images = tf.stack(image_tensor_list, axis=0)\n    labels = features[\'label\'].numpy()\n\n    return images, labels\n\n\nif __name__ == \'__main__\':\n    # GPU settings\n    gpus = tf.config.list_physical_devices(""GPU"")\n    if gpus:\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n\n    # get the dataset\n    train_dataset, valid_dataset, test_dataset, train_count, valid_count, test_count = generate_datasets()\n\n    # create model\n    model = get_model()\n    print_model_summary(network=model)\n\n    # define loss and optimizer\n    loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n    optimizer = tf.keras.optimizers.RMSprop()\n\n    train_loss = tf.keras.metrics.Mean(name=\'train_loss\')\n    train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=\'train_accuracy\')\n\n    valid_loss = tf.keras.metrics.Mean(name=\'valid_loss\')\n    valid_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=\'valid_accuracy\')\n\n    # @tf.function\n    def train_step(image_batch, label_batch):\n        with tf.GradientTape() as tape:\n            predictions = model(image_batch, training=True)\n            loss = loss_object(y_true=label_batch, y_pred=predictions)\n        gradients = tape.gradient(loss, model.trainable_variables)\n        optimizer.apply_gradients(grads_and_vars=zip(gradients, model.trainable_variables))\n\n        train_loss.update_state(values=loss)\n        train_accuracy.update_state(y_true=label_batch, y_pred=predictions)\n\n    # @tf.function\n    def valid_step(image_batch, label_batch):\n        predictions = model(image_batch, training=False)\n        v_loss = loss_object(label_batch, predictions)\n\n        valid_loss.update_state(values=v_loss)\n        valid_accuracy.update_state(y_true=label_batch, y_pred=predictions)\n\n    # start training\n    for epoch in range(EPOCHS):\n        step = 0\n        for features in train_dataset:\n            step += 1\n            images, labels = process_features(features, data_augmentation=True)\n            train_step(images, labels)\n            print(""Epoch: {}/{}, step: {}/{}, loss: {:.5f}, accuracy: {:.5f}"".format(epoch,\n                                                                                     EPOCHS,\n                                                                                     step,\n                                                                                     math.ceil(train_count / BATCH_SIZE),\n                                                                                     train_loss.result().numpy(),\n                                                                                     train_accuracy.result().numpy()))\n\n        for features in valid_dataset:\n            valid_images, valid_labels = process_features(features, data_augmentation=False)\n            valid_step(valid_images, valid_labels)\n\n        print(""Epoch: {}/{}, train loss: {:.5f}, train accuracy: {:.5f}, ""\n              ""valid loss: {:.5f}, valid accuracy: {:.5f}"".format(epoch,\n                                                                  EPOCHS,\n                                                                  train_loss.result().numpy(),\n                                                                  train_accuracy.result().numpy(),\n                                                                  valid_loss.result().numpy(),\n                                                                  valid_accuracy.result().numpy()))\n        train_loss.reset_states()\n        train_accuracy.reset_states()\n        valid_loss.reset_states()\n        valid_accuracy.reset_states()\n\n        if epoch % save_every_n_epoch == 0:\n            model.save_weights(filepath=save_model_dir+""epoch-{}"".format(epoch), save_format=\'tf\')\n\n\n    # save weights\n    model.save_weights(filepath=save_model_dir+""model"", save_format=\'tf\')\n\n    # save the whole model\n    # tf.saved_model.save(model, save_model_dir)\n\n    # convert to tensorflow lite format\n    # model._set_inputs(inputs=tf.random.normal(shape=(1, IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS)))\n    # converter = tf.lite.TFLiteConverter.from_keras_model(model)\n    # tflite_model = converter.convert()\n    # open(""converted_model.tflite"", ""wb"").write(tflite_model)\n\n'"
models/__init__.py,0,b''
models/densenet.py,23,"b'import tensorflow as tf\nfrom configuration import NUM_CLASSES\n\n\nclass BottleNeck(tf.keras.layers.Layer):\n    def __init__(self, growth_rate, drop_rate):\n        super(BottleNeck, self).__init__()\n        self.bn1 = tf.keras.layers.BatchNormalization()\n        self.conv1 = tf.keras.layers.Conv2D(filters=4 * growth_rate,\n                                            kernel_size=(1, 1),\n                                            strides=1,\n                                            padding=""same"")\n        self.bn2 = tf.keras.layers.BatchNormalization()\n        self.conv2 = tf.keras.layers.Conv2D(filters=growth_rate,\n                                            kernel_size=(3, 3),\n                                            strides=1,\n                                            padding=""same"")\n        self.dropout = tf.keras.layers.Dropout(rate=drop_rate)\n\n    def call(self, inputs, training=None, **kwargs):\n        x = self.bn1(inputs, training=training)\n        x = tf.nn.relu(x)\n        x = self.conv1(x)\n        x = self.bn2(x, training=training)\n        x = tf.nn.relu(x)\n        x = self.conv2(x)\n        x = self.dropout(x, training=training)\n        return x\n\n\nclass DenseBlock(tf.keras.layers.Layer):\n    def __init__(self, num_layers, growth_rate, drop_rate):\n        super(DenseBlock, self).__init__()\n        self.num_layers = num_layers\n        self.growth_rate = growth_rate\n        self.drop_rate = drop_rate\n        self.features_list = []\n        self.bottle_necks = []\n        for i in range(self.num_layers):\n            self.bottle_necks.append(BottleNeck(growth_rate=self.growth_rate, drop_rate=self.drop_rate))\n\n    def call(self, inputs, training=None, **kwargs):\n        self.features_list.append(inputs)\n        x = inputs\n        for i in range(self.num_layers):\n            y = self.bottle_necks[i](x, training=training)\n            self.features_list.append(y)\n            x = tf.concat(self.features_list, axis=-1)\n        self.features_list.clear()\n        return x\n\n\nclass TransitionLayer(tf.keras.layers.Layer):\n    def __init__(self, out_channels):\n        super(TransitionLayer, self).__init__()\n        self.bn = tf.keras.layers.BatchNormalization()\n        self.conv = tf.keras.layers.Conv2D(filters=out_channels,\n                                           kernel_size=(1, 1),\n                                           strides=1,\n                                           padding=""same"")\n        self.pool = tf.keras.layers.MaxPool2D(pool_size=(2, 2),\n                                              strides=2,\n                                              padding=""same"")\n\n    def call(self, inputs, training=None, **kwargs):\n        x = self.bn(inputs, training=training)\n        x = tf.nn.relu(x)\n        x = self.conv(x)\n        x = self.pool(x)\n        return x\n\n\nclass DenseNet(tf.keras.Model):\n    def __init__(self, num_init_features, growth_rate, block_layers, compression_rate, drop_rate):\n        super(DenseNet, self).__init__()\n        self.conv = tf.keras.layers.Conv2D(filters=num_init_features,\n                                           kernel_size=(7, 7),\n                                           strides=2,\n                                           padding=""same"")\n        self.bn = tf.keras.layers.BatchNormalization()\n        self.pool = tf.keras.layers.MaxPool2D(pool_size=(3, 3),\n                                              strides=2,\n                                              padding=""same"")\n        self.num_channels = num_init_features\n        self.dense_block_1 = DenseBlock(num_layers=block_layers[0], growth_rate=growth_rate, drop_rate=drop_rate)\n        self.num_channels += growth_rate * block_layers[0]\n        self.num_channels = compression_rate * self.num_channels\n        self.transition_1 = TransitionLayer(out_channels=int(self.num_channels))\n        self.dense_block_2 = DenseBlock(num_layers=block_layers[1], growth_rate=growth_rate, drop_rate=drop_rate)\n        self.num_channels += growth_rate * block_layers[1]\n        self.num_channels = compression_rate * self.num_channels\n        self.transition_2 = TransitionLayer(out_channels=int(self.num_channels))\n        self.dense_block_3 = DenseBlock(num_layers=block_layers[2], growth_rate=growth_rate, drop_rate=drop_rate)\n        self.num_channels += growth_rate * block_layers[2]\n        self.num_channels = compression_rate * self.num_channels\n        self.transition_3 = TransitionLayer(out_channels=int(self.num_channels))\n        self.dense_block_4 = DenseBlock(num_layers=block_layers[3], growth_rate=growth_rate, drop_rate=drop_rate)\n\n        self.avgpool = tf.keras.layers.GlobalAveragePooling2D()\n        self.fc = tf.keras.layers.Dense(units=NUM_CLASSES,\n                                        activation=tf.keras.activations.softmax)\n\n    def call(self, inputs, training=None, mask=None):\n        x = self.conv(inputs)\n        x = self.bn(x, training=training)\n        x = tf.nn.relu(x)\n        x = self.pool(x)\n\n        x = self.dense_block_1(x, training=training)\n        x = self.transition_1(x, training=training)\n        x = self.dense_block_2(x, training=training)\n        x = self.transition_2(x, training=training)\n        x = self.dense_block_3(x, training=training)\n        x = self.transition_3(x, training=training)\n        x = self.dense_block_4(x, training=training)\n\n        x = self.avgpool(x)\n        x = self.fc(x)\n\n        return x\n\n\ndef densenet_121():\n    return DenseNet(num_init_features=64, growth_rate=32, block_layers=[6, 12, 24, 16], compression_rate=0.5, drop_rate=0.5)\n\n\ndef densenet_169():\n    return DenseNet(num_init_features=64, growth_rate=32, block_layers=[6, 12, 32, 32], compression_rate=0.5, drop_rate=0.5)\n\n\ndef densenet_201():\n    return DenseNet(num_init_features=64, growth_rate=32, block_layers=[6, 12, 48, 32], compression_rate=0.5, drop_rate=0.5)\n\n\ndef densenet_264():\n    return DenseNet(num_init_features=64, growth_rate=32, block_layers=[6, 12, 64, 48], compression_rate=0.5, drop_rate=0.5)\n'"
models/efficientnet.py,31,"b'import tensorflow as tf\nimport math\nfrom configuration import NUM_CLASSES\n\n\ndef round_filters(filters, multiplier):\n    depth_divisor = 8\n    min_depth = None\n    min_depth = min_depth or depth_divisor\n    filters = filters * multiplier\n    new_filters = max(min_depth, int(filters + depth_divisor / 2) // depth_divisor * depth_divisor)\n    if new_filters < 0.9 * filters:\n        new_filters += depth_divisor\n    return int(new_filters)\n\n\ndef round_repeats(repeats, multiplier):\n    if not multiplier:\n        return repeats\n    return int(math.ceil(multiplier * repeats))\n\n\nclass SEBlock(tf.keras.layers.Layer):\n    def __init__(self, input_channels, ratio=0.25):\n        super(SEBlock, self).__init__()\n        self.num_reduced_filters = max(1, int(input_channels * ratio))\n        self.pool = tf.keras.layers.GlobalAveragePooling2D()\n        self.reduce_conv = tf.keras.layers.Conv2D(filters=self.num_reduced_filters,\n                                                  kernel_size=(1, 1),\n                                                  strides=1,\n                                                  padding=""same"")\n        self.expand_conv = tf.keras.layers.Conv2D(filters=input_channels,\n                                                  kernel_size=(1, 1),\n                                                  strides=1,\n                                                  padding=""same"")\n\n    def call(self, inputs, **kwargs):\n        branch = self.pool(inputs)\n        branch = tf.expand_dims(input=branch, axis=1)\n        branch = tf.expand_dims(input=branch, axis=1)\n        branch = self.reduce_conv(branch)\n        branch = tf.nn.swish(branch)\n        branch = self.expand_conv(branch)\n        branch = tf.nn.sigmoid(branch)\n        output = inputs * branch\n        return output\n\n\nclass MBConv(tf.keras.layers.Layer):\n    def __init__(self, in_channels, out_channels, expansion_factor, stride, k, drop_connect_rate):\n        super(MBConv, self).__init__()\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.stride = stride\n        self.drop_connect_rate = drop_connect_rate\n        self.conv1 = tf.keras.layers.Conv2D(filters=in_channels * expansion_factor,\n                                            kernel_size=(1, 1),\n                                            strides=1,\n                                            padding=""same"",\n                                            use_bias=False)\n        self.bn1 = tf.keras.layers.BatchNormalization()\n        self.dwconv = tf.keras.layers.DepthwiseConv2D(kernel_size=(k, k),\n                                                      strides=stride,\n                                                      padding=""same"",\n                                                      use_bias=False)\n        self.bn2 = tf.keras.layers.BatchNormalization()\n        self.se = SEBlock(input_channels=in_channels * expansion_factor)\n        self.conv2 = tf.keras.layers.Conv2D(filters=out_channels,\n                                            kernel_size=(1, 1),\n                                            strides=1,\n                                            padding=""same"",\n                                            use_bias=False)\n        self.bn3 = tf.keras.layers.BatchNormalization()\n        self.dropout = tf.keras.layers.Dropout(rate=drop_connect_rate)\n\n    def call(self, inputs, training=None, **kwargs):\n        x = self.conv1(inputs)\n        x = self.bn1(x, training=training)\n        x = tf.nn.swish(x)\n        x = self.dwconv(x)\n        x = self.bn2(x, training=training)\n        x = self.se(x)\n        x = tf.nn.swish(x)\n        x = self.conv2(x)\n        x = self.bn3(x, training=training)\n        if self.stride == 1 and self.in_channels == self.out_channels:\n            if self.drop_connect_rate:\n                x = self.dropout(x, training=training)\n            x = tf.keras.layers.add([x, inputs])\n        return x\n\n\ndef build_mbconv_block(in_channels, out_channels, layers, stride, expansion_factor, k, drop_connect_rate):\n    block = tf.keras.Sequential()\n    for i in range(layers):\n        if i == 0:\n            block.add(MBConv(in_channels=in_channels,\n                             out_channels=out_channels,\n                             expansion_factor=expansion_factor,\n                             stride=stride,\n                             k=k,\n                             drop_connect_rate=drop_connect_rate))\n        else:\n            block.add(MBConv(in_channels=out_channels,\n                             out_channels=out_channels,\n                             expansion_factor=expansion_factor,\n                             stride=1,\n                             k=k,\n                             drop_connect_rate=drop_connect_rate))\n    return block\n\n\nclass EfficientNet(tf.keras.Model):\n    def __init__(self, width_coefficient, depth_coefficient, dropout_rate, drop_connect_rate=0.2):\n        super(EfficientNet, self).__init__()\n\n        self.conv1 = tf.keras.layers.Conv2D(filters=round_filters(32, width_coefficient),\n                                            kernel_size=(3, 3),\n                                            strides=2,\n                                            padding=""same"",\n                                            use_bias=False)\n        self.bn1 = tf.keras.layers.BatchNormalization()\n        self.block1 = build_mbconv_block(in_channels=round_filters(32, width_coefficient),\n                                         out_channels=round_filters(16, width_coefficient),\n                                         layers=round_repeats(1, depth_coefficient),\n                                         stride=1,\n                                         expansion_factor=1, k=3, drop_connect_rate=drop_connect_rate)\n        self.block2 = build_mbconv_block(in_channels=round_filters(16, width_coefficient),\n                                         out_channels=round_filters(24, width_coefficient),\n                                         layers=round_repeats(2, depth_coefficient),\n                                         stride=2,\n                                         expansion_factor=6, k=3, drop_connect_rate=drop_connect_rate)\n        self.block3 = build_mbconv_block(in_channels=round_filters(24, width_coefficient),\n                                         out_channels=round_filters(40, width_coefficient),\n                                         layers=round_repeats(2, depth_coefficient),\n                                         stride=2,\n                                         expansion_factor=6, k=5, drop_connect_rate=drop_connect_rate)\n        self.block4 = build_mbconv_block(in_channels=round_filters(40, width_coefficient),\n                                         out_channels=round_filters(80, width_coefficient),\n                                         layers=round_repeats(3, depth_coefficient),\n                                         stride=2,\n                                         expansion_factor=6, k=3, drop_connect_rate=drop_connect_rate)\n        self.block5 = build_mbconv_block(in_channels=round_filters(80, width_coefficient),\n                                         out_channels=round_filters(112, width_coefficient),\n                                         layers=round_repeats(3, depth_coefficient),\n                                         stride=1,\n                                         expansion_factor=6, k=5, drop_connect_rate=drop_connect_rate)\n        self.block6 = build_mbconv_block(in_channels=round_filters(112, width_coefficient),\n                                         out_channels=round_filters(192, width_coefficient),\n                                         layers=round_repeats(4, depth_coefficient),\n                                         stride=2,\n                                         expansion_factor=6, k=5, drop_connect_rate=drop_connect_rate)\n        self.block7 = build_mbconv_block(in_channels=round_filters(192, width_coefficient),\n                                         out_channels=round_filters(320, width_coefficient),\n                                         layers=round_repeats(1, depth_coefficient),\n                                         stride=1,\n                                         expansion_factor=6, k=3, drop_connect_rate=drop_connect_rate)\n\n        self.conv2 = tf.keras.layers.Conv2D(filters=round_filters(1280, width_coefficient),\n                                            kernel_size=(1, 1),\n                                            strides=1,\n                                            padding=""same"",\n                                            use_bias=False)\n        self.bn2 = tf.keras.layers.BatchNormalization()\n        self.pool = tf.keras.layers.GlobalAveragePooling2D()\n        self.dropout = tf.keras.layers.Dropout(rate=dropout_rate)\n        self.fc = tf.keras.layers.Dense(units=NUM_CLASSES,\n                                        activation=tf.keras.activations.softmax)\n\n    def call(self, inputs, training=None, mask=None):\n        x = self.conv1(inputs)\n        x = self.bn1(x, training=training)\n        x = tf.nn.swish(x)\n\n        x = self.block1(x)\n        x = self.block2(x)\n        x = self.block3(x)\n        x = self.block4(x)\n        x = self.block5(x)\n        x = self.block6(x)\n        x = self.block7(x)\n\n        x = self.conv2(x)\n        x = self.bn2(x, training=training)\n        x = tf.nn.swish(x)\n        x = self.pool(x)\n        x = self.dropout(x, training=training)\n        x = self.fc(x)\n\n        return x\n\n\ndef get_efficient_net(width_coefficient, depth_coefficient, resolution, dropout_rate):\n    net = EfficientNet(width_coefficient=width_coefficient,\n                       depth_coefficient=depth_coefficient,\n                       dropout_rate=dropout_rate)\n\n    return net\n\n\ndef efficient_net_b0():\n    return get_efficient_net(1.0, 1.0, 224, 0.2)\n\n\ndef efficient_net_b1():\n    return get_efficient_net(1.0, 1.1, 240, 0.2)\n\n\ndef efficient_net_b2():\n    return get_efficient_net(1.1, 1.2, 260, 0.3)\n\n\ndef efficient_net_b3():\n    return get_efficient_net(1.2, 1.4, 300, 0.3)\n\n\ndef efficient_net_b4():\n    return get_efficient_net(1.4, 1.8, 380, 0.4)\n\n\ndef efficient_net_b5():\n    return get_efficient_net(1.6, 2.2, 456, 0.4)\n\n\ndef efficient_net_b6():\n    return get_efficient_net(1.8, 2.6, 528, 0.5)\n\n\ndef efficient_net_b7():\n    return get_efficient_net(2.0, 3.1, 600, 0.5)\n\n'"
models/group_convolution.py,6,"b'import tensorflow as tf\nfrom tensorflow.keras import initializers, regularizers, constraints\nfrom tensorflow.keras import activations\n\n\nclass GroupConv2D(tf.keras.layers.Layer):\n    def __init__(self,\n                 input_channels,\n                 output_channels,\n                 kernel_size,\n                 strides=(1, 1),\n                 padding=\'valid\',\n                 data_format=None,\n                 dilation_rate=(1, 1),\n                 activation=None,\n                 groups=1,\n                 use_bias=True,\n                 kernel_initializer=\'glorot_uniform\',\n                 bias_initializer=\'zeros\',\n                 kernel_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        super(GroupConv2D, self).__init__()\n\n        if not input_channels % groups == 0:\n            raise ValueError(""The value of input_channels must be divisible by the value of groups."")\n        if not output_channels % groups == 0:\n            raise ValueError(""The value of output_channels must be divisible by the value of groups."")\n\n        self.input_channels = input_channels\n        self.output_channels = output_channels\n        self.kernel_size = kernel_size\n        self.strides = strides\n        self.padding = padding\n        self.data_format = data_format\n        self.dilation_rate = dilation_rate\n        self.activation = activation\n        self.groups = groups\n        self.use_bias = use_bias\n        self.kernel_initializer = kernel_initializer\n        self.bias_initializer = bias_initializer\n        self.kernel_regularizer = kernel_regularizer\n        self.bias_regularizer = bias_regularizer\n        self.activity_regularizer = activity_regularizer\n        self.kernel_constraint = kernel_constraint\n        self.bias_constraint = bias_constraint\n\n        self.group_in_num = input_channels // groups\n        self.group_out_num = output_channels // groups\n        self.conv_list = []\n        for i in range(self.groups):\n            self.conv_list.append(tf.keras.layers.Conv2D(filters=self.group_out_num,\n                                                         kernel_size=kernel_size,\n                                                         strides=strides,\n                                                         padding=padding,\n                                                         data_format=data_format,\n                                                         dilation_rate=dilation_rate,\n                                                         activation=activations.get(activation),\n                                                         use_bias=use_bias,\n                                                         kernel_initializer=initializers.get(kernel_initializer),\n                                                         bias_initializer=initializers.get(bias_initializer),\n                                                         kernel_regularizer=regularizers.get(kernel_regularizer),\n                                                         bias_regularizer=regularizers.get(bias_regularizer),\n                                                         activity_regularizer=regularizers.get(activity_regularizer),\n                                                         kernel_constraint=constraints.get(kernel_constraint),\n                                                         bias_constraint=constraints.get(bias_constraint),\n                                                         **kwargs))\n\n    def call(self, inputs, **kwargs):\n        feature_map_list = []\n        for i in range(self.groups):\n            x_i = self.conv_list[i](inputs[:, :, :, i*self.group_in_num: (i + 1) * self.group_in_num])\n            feature_map_list.append(x_i)\n        out = tf.concat(feature_map_list, axis=-1)\n        return out\n\n    def get_config(self):\n        config = {\n            ""input_channels"": self.input_channels,\n            ""output_channels"": self.output_channels,\n            ""kernel_size"": self.kernel_size,\n            ""strides"": self.strides,\n            ""padding"": self.padding,\n            ""data_format"": self.data_format,\n            ""dilation_rate"": self.dilation_rate,\n            ""activation"": activations.serialize(self.activation),\n            ""groups"": self.groups,\n            ""use_bias"": self.use_bias,\n            ""kernel_initializer"": initializers.serialize(self.kernel_initializer),\n            ""bias_initializer"": initializers.serialize(self.bias_initializer),\n            ""kernel_regularizer"": regularizers.serialize(self.kernel_regularizer),\n            ""bias_regularizer"": regularizers.serialize(self.bias_regularizer),\n            ""activity_regularizer"": regularizers.serialize(self.activity_regularizer),\n            ""kernel_constraint"": constraints.serialize(self.kernel_constraint),\n            ""bias_constraint"": constraints.serialize(self.bias_constraint)\n        }\n        base_config = super(GroupConv2D, self).get_config()\n        return {**base_config, **config}\n\n\nclass GroupConv2DTranspose(tf.keras.layers.Layer):\n    def __init__(self,\n                 input_channels,\n                 output_channels,\n                 kernel_size,\n                 strides=(1, 1),\n                 padding=\'valid\',\n                 output_padding=None,\n                 data_format=None,\n                 dilation_rate=(1, 1),\n                 activation=None,\n                 groups=1,\n                 use_bias=True,\n                 kernel_initializer=\'glorot_uniform\',\n                 bias_initializer=\'zeros\',\n                 kernel_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 bias_constraint=None,\n                 **kwargs\n                 ):\n        super(GroupConv2DTranspose, self).__init__()\n\n        if not input_channels % groups == 0:\n            raise ValueError(""The value of input_channels must be divisible by the value of groups."")\n        if not output_channels % groups == 0:\n            raise ValueError(""The value of output_channels must be divisible by the value of groups."")\n\n        self.input_channels = input_channels\n        self.output_channels = output_channels\n        self.kernel_size = kernel_size\n        self.strides = strides\n        self.padding = padding\n        self.output_padding = output_padding\n        self.data_format = data_format\n        self.dilation_rate = dilation_rate\n        self.activation = activation\n        self.groups = groups\n        self.use_bias = use_bias\n        self.kernel_initializer = kernel_initializer\n        self.bias_initializer = bias_initializer\n        self.kernel_regularizer = kernel_regularizer\n        self.bias_regularizer = bias_regularizer\n        self.activity_regularizer = activity_regularizer\n        self.kernel_constraint = kernel_constraint\n        self.bias_constraint = bias_constraint\n\n        self.group_in_num = input_channels // groups\n        self.group_out_num = output_channels // groups\n        self.conv_list = []\n        for i in range(self.groups):\n            self.conv_list.append(tf.keras.layers.Conv2DTranspose(filters=self.group_out_num,\n                                                                  kernel_size=kernel_size,\n                                                                  strides=strides,\n                                                                  padding=padding,\n                                                                  output_padding=output_padding,\n                                                                  data_format=data_format,\n                                                                  dilation_rate=dilation_rate,\n                                                                  activation=activations.get(activation),\n                                                                  use_bias=use_bias,\n                                                                  kernel_initializer=initializers.get(kernel_initializer),\n                                                                  bias_initializer=initializers.get(bias_initializer),\n                                                                  kernel_regularizer=regularizers.get(kernel_regularizer),\n                                                                  bias_regularizer=regularizers.get(bias_regularizer),\n                                                                  activity_regularizer=regularizers.get(activity_regularizer),\n                                                                  kernel_constraint=constraints.get(kernel_constraint),\n                                                                  bias_constraint=constraints.get(bias_constraint),\n                                                                  **kwargs))\n\n    def call(self, inputs, **kwargs):\n        feature_map_list = []\n        for i in range(self.groups):\n            x_i = self.conv_list[i](inputs[:, :, :, i*self.group_in_num: (i + 1) * self.group_in_num])\n            feature_map_list.append(x_i)\n        out = tf.concat(feature_map_list, axis=-1)\n        return out\n\n    def get_config(self):\n        config = {\n            ""input_channels"": self.input_channels,\n            ""output_channels"": self.output_channels,\n            ""kernel_size"": self.kernel_size,\n            ""strides"": self.strides,\n            ""padding"": self.padding,\n            ""output_padding"": self.output_padding,\n            ""data_format"": self.data_format,\n            ""dilation_rate"": self.dilation_rate,\n            ""activation"": activations.serialize(self.activation),\n            ""groups"": self.groups,\n            ""use_bias"": self.use_bias,\n            ""kernel_initializer"": initializers.serialize(self.kernel_initializer),\n            ""bias_initializer"": initializers.serialize(self.bias_initializer),\n            ""kernel_regularizer"": regularizers.serialize(self.kernel_regularizer),\n            ""bias_regularizer"": regularizers.serialize(self.bias_regularizer),\n            ""activity_regularizer"": regularizers.serialize(self.activity_regularizer),\n            ""kernel_constraint"": constraints.serialize(self.kernel_constraint),\n            ""bias_constraint"": constraints.serialize(self.bias_constraint)\n        }\n        base_config = super(GroupConv2DTranspose, self).get_config()\n        return {**base_config, **config}\n'"
models/inception_modules.py,28,"b'import tensorflow as tf\n\n\nclass BasicConv2D(tf.keras.layers.Layer):\n    def __init__(self, filters, kernel_size, strides, padding):\n        super(BasicConv2D, self).__init__()\n        self.conv = tf.keras.layers.Conv2D(filters=filters,\n                                           kernel_size=kernel_size,\n                                           strides=strides,\n                                           padding=padding)\n        self.bn = tf.keras.layers.BatchNormalization()\n\n    def call(self, inputs, training=None, **kwargs):\n        x = self.conv(inputs)\n        x = self.bn(x, training=training)\n        x = tf.nn.relu(x)\n\n        return x\n\n\nclass Conv2DLinear(tf.keras.layers.Layer):\n    def __init__(self, filters, kernel_size, strides, padding):\n        super(Conv2DLinear, self).__init__()\n        self.conv = tf.keras.layers.Conv2D(filters=filters,\n                                           kernel_size=kernel_size,\n                                           strides=strides,\n                                           padding=padding)\n        self.bn = tf.keras.layers.BatchNormalization()\n\n    def call(self, inputs, training=None, **kwargs):\n        x = self.conv(inputs)\n        x = self.bn(x, training=training)\n\n        return x\n\n\nclass Stem(tf.keras.layers.Layer):\n    def __init__(self):\n        super(Stem, self).__init__()\n        self.conv1 = BasicConv2D(filters=32,\n                                 kernel_size=(3, 3),\n                                 strides=2,\n                                 padding=""valid"")\n        self.conv2 = BasicConv2D(filters=32,\n                                 kernel_size=(3, 3),\n                                 strides=1,\n                                 padding=""valid"")\n        self.conv3 = BasicConv2D(filters=64,\n                                 kernel_size=(3, 3),\n                                 strides=1,\n                                 padding=""same"")\n        self.b1_maxpool = tf.keras.layers.MaxPool2D(pool_size=(3, 3),\n                                                    strides=2,\n                                                    padding=""valid"")\n        self.b2_conv = BasicConv2D(filters=96,\n                                   kernel_size=(3, 3),\n                                   strides=2,\n                                   padding=""valid"")\n        self.b3_conv1 = BasicConv2D(filters=64,\n                                    kernel_size=(1, 1),\n                                    strides=1,\n                                    padding=""same"")\n        self.b3_conv2 = BasicConv2D(filters=96,\n                                    kernel_size=(3, 3),\n                                    strides=1,\n                                    padding=""valid"")\n        self.b4_conv1 = BasicConv2D(filters=64,\n                                    kernel_size=(1, 1),\n                                    strides=1,\n                                    padding=""same"")\n        self.b4_conv2 = BasicConv2D(filters=64,\n                                    kernel_size=(7, 1),\n                                    strides=1,\n                                    padding=""same"")\n        self.b4_conv3 = BasicConv2D(filters=64,\n                                    kernel_size=(1, 7),\n                                    strides=1,\n                                    padding=""same"")\n        self.b4_conv4 = BasicConv2D(filters=96,\n                                    kernel_size=(3, 3),\n                                    strides=1,\n                                    padding=""valid"")\n        self.b5_conv = BasicConv2D(filters=192,\n                                   kernel_size=(3, 3),\n                                   strides=2,\n                                   padding=""valid"")\n        self.b6_maxpool = tf.keras.layers.MaxPool2D(pool_size=(3, 3),\n                                                    strides=2,\n                                                    padding=""valid"")\n\n    def call(self, inputs, training=None, **kwargs):\n        x = self.conv1(inputs, training=training)\n        x = self.conv2(x, training=training)\n        x = self.conv3(x, training=training)\n        branch_1 = self.b1_maxpool(x)\n        branch_2 = self.b2_conv(x, training=training)\n        x = tf.concat(values=[branch_1, branch_2], axis=-1)\n        branch_3 = self.b3_conv1(x, training=training)\n        branch_3 = self.b3_conv2(branch_3, training=training)\n        branch_4 = self.b4_conv1(x, training=training)\n        branch_4 = self.b4_conv2(branch_4, training=training)\n        branch_4 = self.b4_conv3(branch_4, training=training)\n        branch_4 = self.b4_conv4(branch_4, training=training)\n        x = tf.concat(values=[branch_3, branch_4], axis=-1)\n        branch_5 = self.b5_conv(x, training=training)\n        branch_6 = self.b6_maxpool(x, training=training)\n        x = tf.concat(values=[branch_5, branch_6], axis=-1)\n\n        return x\n\n\nclass InceptionBlockA(tf.keras.layers.Layer):\n    def __init__(self):\n        super(InceptionBlockA, self).__init__()\n        self.b1_pool = tf.keras.layers.AveragePooling2D(pool_size=(3, 3),\n                                                        strides=1,\n                                                        padding=""same"")\n        self.b1_conv = BasicConv2D(filters=96,\n                                   kernel_size=(1, 1),\n                                   strides=1,\n                                   padding=""same"")\n        self.b2_conv = BasicConv2D(filters=96,\n                                   kernel_size=(1, 1),\n                                   strides=1,\n                                   padding=""same"")\n        self.b3_conv1 = BasicConv2D(filters=64,\n                                    kernel_size=(1, 1),\n                                    strides=1,\n                                    padding=""same"")\n        self.b3_conv2 = BasicConv2D(filters=96,\n                                    kernel_size=(3, 3),\n                                    strides=1,\n                                    padding=""same"")\n        self.b4_conv1 = BasicConv2D(filters=64,\n                                    kernel_size=(1, 1),\n                                    strides=1,\n                                    padding=""same"")\n        self.b4_conv2 = BasicConv2D(filters=96,\n                                    kernel_size=(3, 3),\n                                    strides=1,\n                                    padding=""same"")\n        self.b4_conv3 = BasicConv2D(filters=96,\n                                    kernel_size=(3, 3),\n                                    strides=1,\n                                    padding=""same"")\n\n    def call(self, inputs, training=None, **kwargs):\n        b1 = self.b1_pool(inputs)\n        b1 = self.b1_conv(b1, training=training)\n\n        b2 = self.b2_conv(inputs, training=training)\n\n        b3 = self.b3_conv1(inputs, training=training)\n        b3 = self.b3_conv2(b3, training=training)\n\n        b4 = self.b4_conv1(inputs, training=training)\n        b4 = self.b4_conv2(b4, training=training)\n        b4 = self.b4_conv3(b4, training=training)\n\n        return tf.concat(values=[b1, b2, b3, b4], axis=-1)\n\n\nclass ReductionA(tf.keras.layers.Layer):\n    def __init__(self, k, l, m, n):\n        super(ReductionA, self).__init__()\n        self.b1_pool = tf.keras.layers.MaxPool2D(pool_size=(3, 3),\n                                                 strides=2,\n                                                 padding=""valid"")\n        self.b2_conv = BasicConv2D(filters=n,\n                                   kernel_size=(3, 3),\n                                   strides=2,\n                                   padding=""valid"")\n        self.b3_conv1 = BasicConv2D(filters=k,\n                                    kernel_size=(1, 1),\n                                    strides=1,\n                                    padding=""same"")\n        self.b3_conv2 = BasicConv2D(filters=l,\n                                    kernel_size=(3, 3),\n                                    strides=1,\n                                    padding=""same"")\n        self.b3_conv3 = BasicConv2D(filters=m,\n                                    kernel_size=(3, 3),\n                                    strides=2,\n                                    padding=""valid"")\n\n    def call(self, inputs, training=None, **kwargs):\n        b1 = self.b1_pool(inputs)\n\n        b2 = self.b2_conv(inputs, training=training)\n\n        b3 = self.b3_conv1(inputs, training=training)\n        b3 = self.b3_conv2(b3, training=training)\n        b3 = self.b3_conv3(b3, training=training)\n\n        return tf.concat(values=[b1, b2, b3], axis=-1)\n\n\nclass InceptionBlockB(tf.keras.layers.Layer):\n    def __init__(self):\n        super(InceptionBlockB, self).__init__()\n        self.b1_pool = tf.keras.layers.AveragePooling2D(pool_size=(3, 3),\n                                                        strides=1,\n                                                        padding=""same"")\n        self.b1_conv = BasicConv2D(filters=128,\n                                   kernel_size=(1, 1),\n                                   strides=1,\n                                   padding=""same"")\n        self.b2_conv = BasicConv2D(filters=384,\n                                   kernel_size=(1, 1),\n                                   strides=1,\n                                   padding=""same"")\n        self.b3_conv1 = BasicConv2D(filters=192,\n                                    kernel_size=(1, 1),\n                                    strides=1,\n                                    padding=""same"")\n        self.b3_conv2 = BasicConv2D(filters=224,\n                                    kernel_size=(1, 7),\n                                    strides=1,\n                                    padding=""same"")\n        self.b3_conv3 = BasicConv2D(filters=256,\n                                    kernel_size=(1, 7),\n                                    strides=1,\n                                    padding=""same"")\n        self.b4_conv1 = BasicConv2D(filters=192,\n                                    kernel_size=(1, 1),\n                                    strides=1,\n                                    padding=""same"")\n        self.b4_conv2 = BasicConv2D(filters=192,\n                                    kernel_size=(1, 7),\n                                    strides=1,\n                                    padding=""same"")\n        self.b4_conv3 = BasicConv2D(filters=224,\n                                    kernel_size=(7, 1),\n                                    strides=1,\n                                    padding=""same"")\n        self.b4_conv4 = BasicConv2D(filters=224,\n                                    kernel_size=(1, 7),\n                                    strides=1,\n                                    padding=""same"")\n        self.b4_conv5 = BasicConv2D(filters=256,\n                                    kernel_size=(7, 1),\n                                    strides=1,\n                                    padding=""same"")\n\n    def call(self, inputs, training=None, **kwargs):\n        b1 = self.b1_pool(inputs)\n        b1 = self.b1_conv(b1, training=training)\n\n        b2 = self.b2_conv(inputs, training=training)\n\n        b3 = self.b3_conv1(inputs, training=training)\n        b3 = self.b3_conv2(b3, training=training)\n        b3 = self.b3_conv3(b3, training=training)\n\n        b4 = self.b4_conv1(inputs, training=training)\n        b4 = self.b4_conv2(b4, training=training)\n        b4 = self.b4_conv3(b4, training=training)\n        b4 = self.b4_conv4(b4, training=training)\n        b4 = self.b4_conv5(b4, training=training)\n\n        return tf.concat(values=[b1, b2, b3, b4], axis=-1)\n\n\nclass ReductionB(tf.keras.layers.Layer):\n    def __init__(self):\n        super(ReductionB, self).__init__()\n        self.b1_pool = tf.keras.layers.MaxPool2D(pool_size=(3, 3),\n                                                 strides=2,\n                                                 padding=""valid"")\n        self.b2_conv1 = BasicConv2D(filters=192,\n                                    kernel_size=(1, 1),\n                                    strides=1,\n                                    padding=""same"")\n        self.b2_conv2 = BasicConv2D(filters=192,\n                                    kernel_size=(3, 3),\n                                    strides=2,\n                                    padding=""valid"")\n        self.b3_conv1 = BasicConv2D(filters=256,\n                                    kernel_size=(1, 1),\n                                    strides=1,\n                                    padding=""same"")\n        self.b3_conv2 = BasicConv2D(filters=256,\n                                    kernel_size=(1, 7),\n                                    strides=1,\n                                    padding=""same"")\n        self.b3_conv3 = BasicConv2D(filters=320,\n                                    kernel_size=(7, 1),\n                                    strides=1,\n                                    padding=""same"")\n        self.b3_conv4 = BasicConv2D(filters=320,\n                                    kernel_size=(3, 3),\n                                    strides=2,\n                                    padding=""valid"")\n\n    def call(self, inputs, training=None, **kwargs):\n        b1 = self.b1_pool(inputs)\n\n        b2 = self.b2_conv1(inputs, training=training)\n        b2 = self.b2_conv2(b2, training=training)\n\n        b3 = self.b3_conv1(inputs, training=training)\n        b3 = self.b3_conv2(b3, training=training)\n        b3 = self.b3_conv3(b3, training=training)\n        b3 = self.b3_conv4(b3, training=training)\n\n        return tf.concat(values=[b1, b2, b3], axis=-1)\n\n\nclass InceptionBlockC(tf.keras.layers.Layer):\n    def __init__(self):\n        super(InceptionBlockC, self).__init__()\n        self.b1_pool = tf.keras.layers.AveragePooling2D(pool_size=(3, 3),\n                                                        strides=1,\n                                                        padding=""same"")\n        self.b1_conv = BasicConv2D(filters=256,\n                                   kernel_size=(1, 1),\n                                   strides=1,\n                                   padding=""same"")\n        self.b2_conv = BasicConv2D(filters=256,\n                                   kernel_size=(1, 1),\n                                   strides=1,\n                                   padding=""same"")\n        self.b3_conv1 = BasicConv2D(filters=384,\n                                    kernel_size=(1, 1),\n                                    strides=1,\n                                    padding=""same"")\n        self.b3_conv2 = BasicConv2D(filters=256,\n                                    kernel_size=(1, 3),\n                                    strides=1,\n                                    padding=""same"")\n        self.b3_conv3 = BasicConv2D(filters=256,\n                                    kernel_size=(3, 1),\n                                    strides=1,\n                                    padding=""same"")\n        self.b4_conv1 = BasicConv2D(filters=384,\n                                    kernel_size=(1, 1),\n                                    strides=1,\n                                    padding=""same"")\n        self.b4_conv2 = BasicConv2D(filters=448,\n                                    kernel_size=(1, 3),\n                                    strides=1,\n                                    padding=""same"")\n        self.b4_conv3 = BasicConv2D(filters=512,\n                                    kernel_size=(3, 1),\n                                    strides=1,\n                                    padding=""same"")\n        self.b4_conv4 = BasicConv2D(filters=256,\n                                    kernel_size=(3, 1),\n                                    strides=1,\n                                    padding=""same"")\n        self.b4_conv5 = BasicConv2D(filters=256,\n                                    kernel_size=(1, 3),\n                                    strides=1,\n                                    padding=""same"")\n\n    def call(self, inputs, training=None, **kwargs):\n        b1 = self.b1_pool(inputs)\n        b1 = self.b1_conv(b1, training=training)\n\n        b2 = self.b2_conv(inputs, training=training)\n\n        b3 = self.b3_conv1(inputs, training=training)\n        b3_1 = self.b3_conv2(b3, training=training)\n        b3_2 = self.b3_conv3(b3, training=training)\n\n        b4 = self.b4_conv1(inputs, training=training)\n        b4 = self.b4_conv2(b4, training=training)\n        b4 = self.b4_conv3(b4, training=training)\n        b4_1 = self.b4_conv4(b4, training=training)\n        b4_2 = self.b4_conv5(b4, training=training)\n\n        return tf.concat(values=[b1, b2, b3_1, b3_2, b4_1, b4_2], axis=-1)\n'"
models/inception_resnet_v1.py,26,"b'import tensorflow as tf\nfrom models.inception_modules import BasicConv2D, Conv2DLinear, ReductionA\nfrom configuration import NUM_CLASSES\n\n\nclass Stem(tf.keras.layers.Layer):\n    def __init__(self):\n        super(Stem, self).__init__()\n        self.conv1 = BasicConv2D(filters=32,\n                                 kernel_size=(3, 3),\n                                 strides=2,\n                                 padding=""valid"")\n        self.conv2 = BasicConv2D(filters=32,\n                                 kernel_size=(3, 3),\n                                 strides=1,\n                                 padding=""valid"")\n        self.conv3 = BasicConv2D(filters=64,\n                                 kernel_size=(3, 3),\n                                 strides=1,\n                                 padding=""same"")\n        self.maxpool = tf.keras.layers.MaxPool2D(pool_size=(3, 3),\n                                                 strides=2,\n                                                 padding=""valid"")\n        self.conv4 = BasicConv2D(filters=80,\n                                 kernel_size=(1, 1),\n                                 strides=1,\n                                 padding=""same"")\n        self.conv5 = BasicConv2D(filters=192,\n                                 kernel_size=(3, 3),\n                                 strides=1,\n                                 padding=""valid"")\n        self.conv6 = BasicConv2D(filters=256,\n                                 kernel_size=(3, 3),\n                                 strides=2,\n                                 padding=""valid"")\n\n    def call(self, inputs, training=None, **kwargs):\n        x = self.conv1(inputs, training=training)\n        x = self.conv2(x, training=training)\n        x = self.conv3(x, training=training)\n        x = self.maxpool(x)\n        x = self.conv4(x, training=training)\n        x = self.conv5(x, training=training)\n        x = self.conv6(x, training=training)\n\n        return x\n\n\nclass InceptionResNetA(tf.keras.layers.Layer):\n    def __init__(self):\n        super(InceptionResNetA, self).__init__()\n        self.b1_conv = BasicConv2D(filters=32,\n                                   kernel_size=(1, 1),\n                                   strides=1,\n                                   padding=""same"")\n        self.b2_conv1 = BasicConv2D(filters=32,\n                                    kernel_size=(1, 1),\n                                    strides=1,\n                                    padding=""same"")\n        self.b2_conv2 = BasicConv2D(filters=32,\n                                    kernel_size=(3, 3),\n                                    strides=1,\n                                    padding=""same"")\n        self.b3_conv1 = BasicConv2D(filters=32,\n                                    kernel_size=(1, 1),\n                                    strides=1,\n                                    padding=""same"")\n        self.b3_conv2 = BasicConv2D(filters=32,\n                                    kernel_size=(3, 3),\n                                    strides=1,\n                                    padding=""same"")\n        self.b3_conv3 = BasicConv2D(filters=32,\n                                    kernel_size=(3, 3),\n                                    strides=1,\n                                    padding=""same"")\n        self.conv = Conv2DLinear(filters=256,\n                                 kernel_size=(1, 1),\n                                 strides=1,\n                                 padding=""same"")\n\n    def call(self, inputs, training=None, **kwargs):\n        b1 = self.b1_conv(inputs, training=training)\n        b2 = self.b2_conv1(inputs, training=training)\n        b2 = self.b2_conv2(b2, training=training)\n        b3 = self.b3_conv1(inputs, training=training)\n        b3 = self.b3_conv2(b3, training=training)\n        b3 = self.b3_conv3(b3, training=training)\n\n        x = tf.concat(values=[b1, b2, b3], axis=-1)\n        x = self.conv(x, training=training)\n\n        output = tf.keras.layers.add([x, inputs])\n        return tf.nn.relu(output)\n\n\nclass InceptionResNetB(tf.keras.layers.Layer):\n    def __init__(self):\n        super(InceptionResNetB, self).__init__()\n        self.b1_conv = BasicConv2D(filters=128,\n                                   kernel_size=(1, 1),\n                                   strides=1,\n                                   padding=""same"")\n        self.b2_conv1 = BasicConv2D(filters=128,\n                                    kernel_size=(1, 1),\n                                    strides=1,\n                                    padding=""same"")\n        self.b2_conv2 = BasicConv2D(filters=128,\n                                    kernel_size=(1, 7),\n                                    strides=1,\n                                    padding=""same"")\n        self.b2_conv3 = BasicConv2D(filters=128,\n                                    kernel_size=(7, 1),\n                                    strides=1,\n                                    padding=""same"")\n        self.conv = Conv2DLinear(filters=896,\n                                 kernel_size=(1, 1),\n                                 strides=1,\n                                 padding=""same"")\n\n    def call(self, inputs, training=None, **kwargs):\n        b1 = self.b1_conv(inputs, training=training)\n\n        b2 = self.b2_conv1(inputs, training=training)\n        b2 = self.b2_conv2(b2, training=training)\n        b2 = self.b2_conv3(b2, training=training)\n\n        x = tf.concat(values=[b1, b2], axis=-1)\n        x = self.conv(x, training=training)\n\n        output = tf.keras.layers.add([x, inputs])\n        return tf.nn.relu(output)\n\n\nclass ReductionB(tf.keras.layers.Layer):\n    def __init__(self):\n        super(ReductionB, self).__init__()\n        self.b1_maxpool = tf.keras.layers.MaxPool2D(pool_size=(3, 3),\n                                                    strides=2,\n                                                    padding=""valid"")\n        self.b2_conv1 = BasicConv2D(filters=256,\n                                    kernel_size=(1, 1),\n                                    strides=1,\n                                    padding=""same"")\n        self.b2_conv2 = BasicConv2D(filters=384,\n                                    kernel_size=(3, 3),\n                                    strides=2,\n                                    padding=""valid"")\n        self.b3_conv1 = BasicConv2D(filters=256,\n                                    kernel_size=(1, 1),\n                                    strides=1,\n                                    padding=""same"")\n        self.b3_conv2 = BasicConv2D(filters=256,\n                                    kernel_size=(3, 3),\n                                    strides=2,\n                                    padding=""valid"")\n        self.b4_conv1 = BasicConv2D(filters=256,\n                                    kernel_size=(1, 1),\n                                    strides=1,\n                                    padding=""same"")\n        self.b4_conv2 = BasicConv2D(filters=256,\n                                    kernel_size=(3, 3),\n                                    strides=1,\n                                    padding=""same"")\n        self.b4_conv3 = BasicConv2D(filters=256,\n                                    kernel_size=(3, 3),\n                                    strides=2,\n                                    padding=""valid"")\n\n    def call(self, inputs, training=None, **kwargs):\n        b1 = self.b1_maxpool(inputs)\n\n        b2 = self.b2_conv1(inputs, training=training)\n        b2 = self.b2_conv2(b2, training=training)\n\n        b3 = self.b3_conv1(inputs, training=training)\n        b3 = self.b3_conv2(b3, training=training)\n\n        b4 = self.b4_conv1(inputs, training=training)\n        b4 = self.b4_conv2(b4, training=training)\n        b4 = self.b4_conv3(b4, training=training)\n\n        return tf.concat(values=[b1, b2, b3, b4], axis=-1)\n\n\nclass InceptionResNetC(tf.keras.layers.Layer):\n    def __init__(self):\n        super(InceptionResNetC, self).__init__()\n        self.b1_conv = BasicConv2D(filters=192,\n                                   kernel_size=(1, 1),\n                                   strides=1,\n                                   padding=""same"")\n        self.b2_conv1 = BasicConv2D(filters=192,\n                                    kernel_size=(1, 1),\n                                    strides=1,\n                                    padding=""same"")\n        self.b2_conv2 = BasicConv2D(filters=192,\n                                    kernel_size=(1, 3),\n                                    strides=1,\n                                    padding=""same"")\n        self.b2_conv3 = BasicConv2D(filters=192,\n                                    kernel_size=(3, 1),\n                                    strides=1,\n                                    padding=""same"")\n        self.conv = Conv2DLinear(filters=1792,\n                                 kernel_size=(1, 1),\n                                 strides=1,\n                                 padding=""same"")\n\n    def call(self, inputs, training=None, **kwargs):\n        b1 = self.b1_conv(inputs, training=training)\n        b2 = self.b2_conv1(inputs, training=training)\n        b2 = self.b2_conv2(b2, training=training)\n        b2 = self.b2_conv3(b2, training=training)\n\n        x = tf.concat(values=[b1, b2], axis=-1)\n        x = self.conv(x, training=training)\n\n        output = tf.keras.layers.add([x, inputs])\n        return tf.nn.relu(output)\n\n\ndef build_inception_resnet_a(n):\n    block = tf.keras.Sequential()\n    for _ in range(n):\n        block.add(InceptionResNetA())\n    return block\n\n\ndef build_inception_resnet_b(n):\n    block = tf.keras.Sequential()\n    for _ in range(n):\n        block.add(InceptionResNetB())\n    return block\n\n\ndef build_inception_resnet_c(n):\n    block = tf.keras.Sequential()\n    for _ in range(n):\n        block.add(InceptionResNetC())\n    return block\n\n\nclass InceptionResNetV1(tf.keras.Model):\n    def __init__(self):\n        super(InceptionResNetV1, self).__init__()\n        self.stem = Stem()\n        self.inception_resnet_a = build_inception_resnet_a(5)\n        self.reduction_a = ReductionA(k=192, l=192, m=256, n=384)\n        self.inception_resnet_b = build_inception_resnet_b(10)\n        self.reduction_b = ReductionB()\n        self.inception_resnet_c = build_inception_resnet_c(5)\n        self.avgpool = tf.keras.layers.AveragePooling2D(pool_size=(8, 8))\n        self.dropout = tf.keras.layers.Dropout(rate=0.2)\n        self.flat = tf.keras.layers.Flatten()\n        self.fc = tf.keras.layers.Dense(units=NUM_CLASSES,\n                                        activation=tf.keras.activations.softmax)\n\n    def call(self, inputs, training=None, mask=None):\n        x = self.stem(inputs, training=training)\n        x = self.inception_resnet_a(x, training=training)\n        x = self.reduction_a(x, training=training)\n        x = self.inception_resnet_b(x, training=training)\n        x = self.reduction_b(x, training=training)\n        x = self.inception_resnet_c(x, training=training)\n        x = self.avgpool(x)\n        x = self.dropout(x, training=training)\n        x = self.flat(x)\n        x = self.fc(x)\n\n        return x'"
models/inception_resnet_v2.py,24,"b'import tensorflow as tf\nfrom models.inception_modules import Stem, ReductionA, BasicConv2D, Conv2DLinear\nfrom configuration import NUM_CLASSES\n\n\nclass InceptionResNetA(tf.keras.layers.Layer):\n    def __init__(self):\n        super(InceptionResNetA, self).__init__()\n        self.b1_conv = BasicConv2D(filters=32,\n                                   kernel_size=(1, 1),\n                                   strides=1,\n                                   padding=""same"")\n        self.b2_conv1 = BasicConv2D(filters=32,\n                                    kernel_size=(1, 1),\n                                    strides=1,\n                                    padding=""same"")\n        self.b2_conv2 = BasicConv2D(filters=32,\n                                    kernel_size=(3, 3),\n                                    strides=1,\n                                    padding=""same"")\n        self.b3_conv1 = BasicConv2D(filters=32,\n                                    kernel_size=(1, 1),\n                                    strides=1,\n                                    padding=""same"")\n        self.b3_conv2 = BasicConv2D(filters=48,\n                                    kernel_size=(3, 3),\n                                    strides=1,\n                                    padding=""same"")\n        self.b3_conv3 = BasicConv2D(filters=64,\n                                    kernel_size=(3, 3),\n                                    strides=1,\n                                    padding=""same"")\n        self.conv = Conv2DLinear(filters=384,\n                                 kernel_size=(1, 1),\n                                 strides=1,\n                                 padding=""same"")\n\n    def call(self, inputs, training=None, **kwargs):\n        b1 = self.b1_conv(inputs, training=training)\n        b2 = self.b2_conv1(inputs, training=training)\n        b2 = self.b2_conv2(b2, training=training)\n        b3 = self.b3_conv1(inputs, training=training)\n        b3 = self.b3_conv2(b3, training=training)\n        b3 = self.b3_conv3(b3, training=training)\n\n        x = tf.concat(values=[b1, b2, b3], axis=-1)\n        x = self.conv(x, training=training)\n\n        output = tf.keras.layers.add([x, inputs])\n        return tf.nn.relu(output)\n\n\nclass InceptionResNetB(tf.keras.layers.Layer):\n    def __init__(self):\n        super(InceptionResNetB, self).__init__()\n        self.b1_conv = BasicConv2D(filters=192,\n                                   kernel_size=(1, 1),\n                                   strides=1,\n                                   padding=""same"")\n        self.b2_conv1 = BasicConv2D(filters=128,\n                                    kernel_size=(1, 1),\n                                    strides=1,\n                                    padding=""same"")\n        self.b2_conv2 = BasicConv2D(filters=160,\n                                    kernel_size=(1, 7),\n                                    strides=1,\n                                    padding=""same"")\n        self.b2_conv3 = BasicConv2D(filters=192,\n                                    kernel_size=(7, 1),\n                                    strides=1,\n                                    padding=""same"")\n        self.conv = Conv2DLinear(filters=1152,\n                                 kernel_size=(1, 1),\n                                 strides=1,\n                                 padding=""same"")\n\n    def call(self, inputs, training=None, **kwargs):\n        b1 = self.b1_conv(inputs, training=training)\n        b2 = self.b2_conv1(inputs, training=training)\n        b2 = self.b2_conv2(b2, training=training)\n        b2 = self.b2_conv3(b2, training=training)\n\n        x = tf.concat(values=[b1, b2], axis=-1)\n        x = self.conv(x, training=training)\n\n        output = tf.keras.layers.add([x, inputs])\n\n        return tf.nn.relu(output)\n\n\nclass InceptionResNetC(tf.keras.layers.Layer):\n    def __init__(self):\n        super(InceptionResNetC, self).__init__()\n        self.b1_conv = BasicConv2D(filters=192,\n                                   kernel_size=(1, 1),\n                                   strides=1,\n                                   padding=""same"")\n        self.b2_conv1 = BasicConv2D(filters=192,\n                                    kernel_size=(1, 1),\n                                    strides=1,\n                                    padding=""same"")\n        self.b2_conv2 = BasicConv2D(filters=224,\n                                    kernel_size=(1, 3),\n                                    strides=1,\n                                    padding=""same"")\n        self.b2_conv3 = BasicConv2D(filters=256,\n                                    kernel_size=(3, 1),\n                                    strides=1,\n                                    padding=""same"")\n        self.conv = Conv2DLinear(filters=2144,\n                                 kernel_size=(1, 1),\n                                 strides=1,\n                                 padding=""same"")\n\n    def call(self, inputs, training=None, **kwargs):\n        b1 = self.b1_conv(inputs, training=training)\n        b2 = self.b2_conv1(inputs, training=training)\n        b2 = self.b2_conv2(b2, training=training)\n        b2 = self.b2_conv3(b2, training=training)\n\n        x = tf.concat(values=[b1, b2], axis=-1)\n        x = self.conv(x, training=training)\n\n        output = tf.keras.layers.add([x, inputs])\n\n        return tf.nn.relu(output)\n\n\nclass ReductionB(tf.keras.layers.Layer):\n    def __init__(self):\n        super(ReductionB, self).__init__()\n        self.b1_maxpool = tf.keras.layers.MaxPool2D(pool_size=(3, 3),\n                                                    strides=2,\n                                                    padding=""valid"")\n        self.b2_conv1 = BasicConv2D(filters=256,\n                                    kernel_size=(1, 1),\n                                    strides=1,\n                                    padding=""same"")\n        self.b2_conv2 = BasicConv2D(filters=384,\n                                    kernel_size=(3, 3),\n                                    strides=2,\n                                    padding=""valid"")\n        self.b3_conv1 = BasicConv2D(filters=256,\n                                    kernel_size=(1, 1),\n                                    strides=1,\n                                    padding=""same"")\n        self.b3_conv2 = BasicConv2D(filters=288,\n                                    kernel_size=(3, 3),\n                                    strides=2,\n                                    padding=""valid"")\n        self.b4_conv1 = BasicConv2D(filters=256,\n                                    kernel_size=(1, 1),\n                                    strides=1,\n                                    padding=""same"")\n        self.b4_conv2 = BasicConv2D(filters=288,\n                                    kernel_size=(3, 3),\n                                    strides=1,\n                                    padding=""same"")\n        self.b4_conv3 = BasicConv2D(filters=320,\n                                    kernel_size=(3, 3),\n                                    strides=2,\n                                    padding=""valid"")\n\n    def call(self, inputs, training=None, **kwargs):\n        b1 = self.b1_maxpool(inputs)\n\n        b2 = self.b2_conv1(inputs, training=training)\n        b2 = self.b2_conv2(b2, training=training)\n\n        b3 = self.b3_conv1(inputs, training=training)\n        b3 = self.b3_conv2(b3, training=training)\n\n        b4 = self.b4_conv1(inputs, training=training)\n        b4 = self.b4_conv2(b4, training=training)\n        b4 = self.b4_conv3(b4, training=training)\n\n        return tf.concat(values=[b1, b2, b3, b4], axis=-1)\n\n\ndef build_inception_resnet_a(n):\n    block = tf.keras.Sequential()\n    for _ in range(n):\n        block.add(InceptionResNetA())\n    return block\n\n\ndef build_inception_resnet_b(n):\n    block = tf.keras.Sequential()\n    for _ in range(n):\n        block.add(InceptionResNetB())\n    return block\n\n\ndef build_inception_resnet_c(n):\n    block = tf.keras.Sequential()\n    for _ in range(n):\n        block.add(InceptionResNetC())\n    return block\n\n\nclass InceptionResNetV2(tf.keras.Model):\n    def __init__(self):\n        super(InceptionResNetV2, self).__init__()\n        self.stem = Stem()\n        self.inception_resnet_a = build_inception_resnet_a(5)\n        self.reduction_a = ReductionA(k=256, l=256, m=384, n=384)\n        self.inception_resnet_b = build_inception_resnet_b(10)\n        self.reduction_b = ReductionB()\n        self.inception_resnet_c = build_inception_resnet_c(5)\n        self.avgpool = tf.keras.layers.AveragePooling2D(pool_size=(8, 8))\n        self.dropout = tf.keras.layers.Dropout(rate=0.2)\n        self.flat = tf.keras.layers.Flatten()\n        self.fc = tf.keras.layers.Dense(units=NUM_CLASSES,\n                                        activation=tf.keras.activations.softmax)\n\n    def call(self, inputs, training=None, mask=None):\n        x = self.stem(inputs, training=training)\n        x = self.inception_resnet_a(x, training=training)\n        x = self.reduction_a(x, training=training)\n        x = self.inception_resnet_b(x, training=training)\n        x = self.reduction_b(x, training=training)\n        x = self.inception_resnet_c(x, training=training)\n        x = self.avgpool(x)\n        x = self.dropout(x, training=training)\n        x = self.flat(x)\n        x = self.fc(x)\n\n        return x'"
models/inception_v4.py,9,"b'import tensorflow as tf\nfrom models.inception_modules import Stem, InceptionBlockA, InceptionBlockB, \\\n    InceptionBlockC, ReductionA, ReductionB\nfrom configuration import NUM_CLASSES\n\n\ndef build_inception_block_a(n):\n    block = tf.keras.Sequential()\n    for _ in range(n):\n        block.add(InceptionBlockA())\n    return block\n\n\ndef build_inception_block_b(n):\n    block = tf.keras.Sequential()\n    for _ in range(n):\n        block.add(InceptionBlockB())\n    return block\n\n\ndef build_inception_block_c(n):\n    block = tf.keras.Sequential()\n    for _ in range(n):\n        block.add(InceptionBlockC())\n    return block\n\n\nclass InceptionV4(tf.keras.Model):\n    def __init__(self):\n        super(InceptionV4, self).__init__()\n        self.stem = Stem()\n        self.inception_a = build_inception_block_a(4)\n        self.reduction_a = ReductionA(k=192, l=224, m=256, n=384)\n        self.inception_b = build_inception_block_b(7)\n        self.reduction_b = ReductionB()\n        self.inception_c = build_inception_block_c(3)\n        self.avgpool = tf.keras.layers.AveragePooling2D(pool_size=(8, 8))\n        self.dropout = tf.keras.layers.Dropout(rate=0.2)\n        self.flat = tf.keras.layers.Flatten()\n        self.fc = tf.keras.layers.Dense(units=NUM_CLASSES,\n                                        activation=tf.keras.activations.softmax)\n\n    def call(self, inputs, training=True, mask=None):\n        x = self.stem(inputs, training=training)\n        x = self.inception_a(x, training=training)\n        x = self.reduction_a(x, training=training)\n        x = self.inception_b(x, training=training)\n        x = self.reduction_b(x, training=training)\n        x = self.inception_c(x, training=training)\n        x = self.avgpool(x)\n        x = self.dropout(x, training=training)\n        x = self.flat(x)\n        x = self.fc(x)\n\n        return x\n'"
models/mobilenet_v1.py,18,"b'import tensorflow as tf\nfrom configuration import NUM_CLASSES\n\n\nclass MobileNetV1(tf.keras.Model):\n    def __init__(self):\n        super(MobileNetV1, self).__init__()\n        self.conv1 = tf.keras.layers.Conv2D(filters=32,\n                                            kernel_size=(3, 3),\n                                            strides=2,\n                                            padding=""same"")\n        self.separable_conv_1 = tf.keras.layers.SeparableConv2D(filters=64,\n                                                                kernel_size=(3, 3),\n                                                                strides=1,\n                                                                padding=""same"")\n        self.separable_conv_2 = tf.keras.layers.SeparableConv2D(filters=128,\n                                                                kernel_size=(3, 3),\n                                                                strides=2,\n                                                                padding=""same"")\n        self.separable_conv_3 = tf.keras.layers.SeparableConv2D(filters=128,\n                                                                kernel_size=(3, 3),\n                                                                strides=1,\n                                                                padding=""same"")\n        self.separable_conv_4 = tf.keras.layers.SeparableConv2D(filters=256,\n                                                                kernel_size=(3, 3),\n                                                                strides=2,\n                                                                padding=""same"")\n        self.separable_conv_5 = tf.keras.layers.SeparableConv2D(filters=256,\n                                                                kernel_size=(3, 3),\n                                                                strides=1,\n                                                                padding=""same"")\n        self.separable_conv_6 = tf.keras.layers.SeparableConv2D(filters=512,\n                                                                kernel_size=(3, 3),\n                                                                strides=2,\n                                                                padding=""same"")\n\n        self.separable_conv_7 = tf.keras.layers.SeparableConv2D(filters=512,\n                                                                kernel_size=(3, 3),\n                                                                strides=1,\n                                                                padding=""same"")\n        self.separable_conv_8 = tf.keras.layers.SeparableConv2D(filters=512,\n                                                                kernel_size=(3, 3),\n                                                                strides=1,\n                                                                padding=""same"")\n        self.separable_conv_9 = tf.keras.layers.SeparableConv2D(filters=512,\n                                                                kernel_size=(3, 3),\n                                                                strides=1,\n                                                                padding=""same"")\n        self.separable_conv_10 = tf.keras.layers.SeparableConv2D(filters=512,\n                                                                 kernel_size=(3, 3),\n                                                                 strides=1,\n                                                                 padding=""same"")\n        self.separable_conv_11 = tf.keras.layers.SeparableConv2D(filters=512,\n                                                                 kernel_size=(3, 3),\n                                                                 strides=1,\n                                                                 padding=""same"")\n\n        self.separable_conv_12 = tf.keras.layers.SeparableConv2D(filters=1024,\n                                                                 kernel_size=(3, 3),\n                                                                 strides=2,\n                                                                 padding=""same"")\n        self.separable_conv_13 = tf.keras.layers.SeparableConv2D(filters=1024,\n                                                                 kernel_size=(3, 3),\n                                                                 strides=1,\n                                                                 padding=""same"")\n\n        self.avg_pool = tf.keras.layers.AveragePooling2D(pool_size=(7, 7),\n                                                         strides=1)\n        self.fc = tf.keras.layers.Dense(units=NUM_CLASSES,\n                                        activation=tf.keras.activations.softmax)\n\n    def call(self, inputs, training=None, mask=None):\n        x = self.conv1(inputs)\n        x = self.separable_conv_1(x)\n        x = self.separable_conv_2(x)\n        x = self.separable_conv_3(x)\n        x = self.separable_conv_4(x)\n        x = self.separable_conv_5(x)\n        x = self.separable_conv_6(x)\n        x = self.separable_conv_7(x)\n        x = self.separable_conv_8(x)\n        x = self.separable_conv_9(x)\n        x = self.separable_conv_10(x)\n        x = self.separable_conv_11(x)\n        x = self.separable_conv_12(x)\n        x = self.separable_conv_13(x)\n\n        x = self.avg_pool(x)\n        x = self.fc(x)\n\n        return x\n    \n'"
models/mobilenet_v2.py,18,"b'import tensorflow as tf\nfrom configuration import NUM_CLASSES\n\n\nclass BottleNeck(tf.keras.layers.Layer):\n    def __init__(self, input_channels, output_channels, expansion_factor, stride):\n        self.stride = stride\n        self.input_channels = input_channels\n        self.output_channels = output_channels\n        super(BottleNeck, self).__init__()\n        self.conv1 = tf.keras.layers.Conv2D(filters=input_channels * expansion_factor,\n                                            kernel_size=(1, 1),\n                                            strides=1,\n                                            padding=""same"")\n        self.bn1 = tf.keras.layers.BatchNormalization()\n        self.dwconv = tf.keras.layers.DepthwiseConv2D(kernel_size=(3, 3),\n                                                      strides=stride,\n                                                      padding=""same"")\n        self.bn2 = tf.keras.layers.BatchNormalization()\n        self.conv2 = tf.keras.layers.Conv2D(filters=output_channels,\n                                            kernel_size=(1, 1),\n                                            strides=1,\n                                            padding=""same"")\n        self.bn3 = tf.keras.layers.BatchNormalization()\n        self.linear = tf.keras.layers.Activation(tf.keras.activations.linear)\n\n    def call(self, inputs, training=None, **kwargs):\n        x = self.conv1(inputs)\n        x = self.bn1(x, training=training)\n        x = tf.nn.relu6(x)\n        x = self.dwconv(x)\n        x = self.bn2(x, training=training)\n        x = tf.nn.relu6(x)\n        x = self.conv2(x)\n        x = self.bn3(x, training=training)\n        x = self.linear(x)\n        if self.stride == 1 and self.input_channels == self.output_channels:\n            x = tf.keras.layers.add([x, inputs])\n        return x\n\n\ndef build_bottleneck(t, in_channel_num, out_channel_num, n, s):\n    # t : expansion factor\n    # s : stride\n    # n : repeat times\n    bottleneck = tf.keras.Sequential()\n    for i in range(n):\n        if i == 0:\n            bottleneck.add(BottleNeck(input_channels=in_channel_num,\n                                      output_channels=out_channel_num,\n                                      expansion_factor=t,\n                                      stride=s))\n        else:\n            bottleneck.add(BottleNeck(input_channels=out_channel_num,\n                                      output_channels=out_channel_num,\n                                      expansion_factor=t,\n                                      stride=1))\n\n    return bottleneck\n\n\nclass MobileNetV2(tf.keras.Model):\n    def __init__(self):\n        super(MobileNetV2, self).__init__()\n        self.conv1 = tf.keras.layers.Conv2D(filters=32,\n                                            kernel_size=(3, 3),\n                                            strides=2,\n                                            padding=""same"")\n        self.bottleneck_1 = build_bottleneck(t=1,\n                                             in_channel_num=32,\n                                             out_channel_num=16,\n                                             n=1,\n                                             s=1)\n        self.bottleneck_2 = build_bottleneck(t=6,\n                                             in_channel_num=16,\n                                             out_channel_num=24,\n                                             n=2,\n                                             s=2)\n        self.bottleneck_3 = build_bottleneck(t=6,\n                                             in_channel_num=24,\n                                             out_channel_num=32,\n                                             n=3,\n                                             s=2)\n        self.bottleneck_4 = build_bottleneck(t=6,\n                                             in_channel_num=32,\n                                             out_channel_num=64,\n                                             n=4,\n                                             s=2)\n        self.bottleneck_5 = build_bottleneck(t=6,\n                                             in_channel_num=64,\n                                             out_channel_num=96,\n                                             n=3,\n                                             s=1)\n        self.bottleneck_6 = build_bottleneck(t=6,\n                                             in_channel_num=96,\n                                             out_channel_num=160,\n                                             n=3,\n                                             s=2)\n        self.bottleneck_7 = build_bottleneck(t=6,\n                                             in_channel_num=160,\n                                             out_channel_num=320,\n                                             n=1,\n                                             s=1)\n\n        self.conv2 = tf.keras.layers.Conv2D(filters=1280,\n                                            kernel_size=(1, 1),\n                                            strides=1,\n                                            padding=""same"")\n        self.avgpool = tf.keras.layers.AveragePooling2D(pool_size=(7, 7))\n        self.conv3 = tf.keras.layers.Conv2D(filters=NUM_CLASSES,\n                                            kernel_size=(1, 1),\n                                            strides=1,\n                                            padding=""same"",\n                                            activation=tf.keras.activations.softmax)\n\n    def call(self, inputs, training=None, mask=None):\n        x = self.conv1(inputs)\n        x = self.bottleneck_1(x, training=training)\n        x = self.bottleneck_2(x, training=training)\n        x = self.bottleneck_3(x, training=training)\n        x = self.bottleneck_4(x, training=training)\n        x = self.bottleneck_5(x, training=training)\n        x = self.bottleneck_6(x, training=training)\n        x = self.bottleneck_7(x, training=training)\n\n        x = self.conv2(x)\n        x = self.avgpool(x)\n        x = self.conv3(x)\n\n        return x\n\n'"
models/mobilenet_v3_block.py,19,"b'import tensorflow as tf\n\n\ndef h_sigmoid(x):\n    return tf.nn.relu6(x + 3) / 6\n\n\ndef h_swish(x):\n    return x * h_sigmoid(x)\n\n\nclass SEBlock(tf.keras.layers.Layer):\n    def __init__(self, input_channels, r=16):\n        super(SEBlock, self).__init__()\n        self.pool = tf.keras.layers.GlobalAveragePooling2D()\n        self.fc1 = tf.keras.layers.Dense(units=input_channels // r)\n        self.fc2 = tf.keras.layers.Dense(units=input_channels)\n\n    def call(self, inputs, **kwargs):\n        branch = self.pool(inputs)\n        branch = self.fc1(branch)\n        branch = tf.nn.relu(branch)\n        branch = self.fc2(branch)\n        branch = h_sigmoid(branch)\n        branch = tf.expand_dims(input=branch, axis=1)\n        branch = tf.expand_dims(input=branch, axis=1)\n        output = inputs * branch\n        return output\n\n\nclass BottleNeck(tf.keras.layers.Layer):\n    def __init__(self, in_size, exp_size, out_size, s, is_se_existing, NL, k):\n        super(BottleNeck, self).__init__()\n        self.stride = s\n        self.in_size = in_size\n        self.out_size = out_size\n        self.is_se_existing = is_se_existing\n        self.NL = NL\n        self.conv1 = tf.keras.layers.Conv2D(filters=exp_size,\n                                            kernel_size=(1, 1),\n                                            strides=1,\n                                            padding=""same"")\n        self.bn1 = tf.keras.layers.BatchNormalization()\n        self.dwconv = tf.keras.layers.DepthwiseConv2D(kernel_size=(k, k),\n                                                      strides=s,\n                                                      padding=""same"")\n        self.bn2 = tf.keras.layers.BatchNormalization()\n        self.se = SEBlock(input_channels=exp_size)\n        self.conv2 = tf.keras.layers.Conv2D(filters=out_size,\n                                            kernel_size=(1, 1),\n                                            strides=1,\n                                            padding=""same"")\n        self.bn3 = tf.keras.layers.BatchNormalization()\n        self.linear = tf.keras.layers.Activation(tf.keras.activations.linear)\n\n    def call(self, inputs, training=None, **kwargs):\n        x = self.conv1(inputs)\n        x = self.bn1(x, training=training)\n        if self.NL == ""HS"":\n            x = h_swish(x)\n        elif self.NL == ""RE"":\n            x = tf.nn.relu6(x)\n        x = self.dwconv(x)\n        x = self.bn2(x, training=training)\n        if self.NL == ""HS"":\n            x = h_swish(x)\n        elif self.NL == ""RE"":\n            x = tf.nn.relu6(x)\n        if self.is_se_existing:\n            x = self.se(x)\n        x = self.conv2(x)\n        x = self.bn3(x, training=training)\n        x = self.linear(x)\n\n        if self.stride == 1 and self.in_size == self.out_size:\n            x = tf.keras.layers.add([x, inputs])\n\n        return x\n'"
models/mobilenet_v3_large.py,9,"b'import tensorflow as tf\nfrom models.mobilenet_v3_block import BottleNeck, h_swish\nfrom configuration import NUM_CLASSES\n\n\nclass MobileNetV3Large(tf.keras.Model):\n    def __init__(self):\n        super(MobileNetV3Large, self).__init__()\n        self.conv1 = tf.keras.layers.Conv2D(filters=16,\n                                            kernel_size=(3, 3),\n                                            strides=2,\n                                            padding=""same"")\n        self.bn1 = tf.keras.layers.BatchNormalization()\n        self.bneck1 = BottleNeck(in_size=16, exp_size=16, out_size=16, s=1, is_se_existing=False, NL=""RE"", k=3)\n        self.bneck2 = BottleNeck(in_size=16, exp_size=64, out_size=24, s=2, is_se_existing=False, NL=""RE"", k=3)\n        self.bneck3 = BottleNeck(in_size=24, exp_size=72, out_size=24, s=1, is_se_existing=False, NL=""RE"", k=3)\n        self.bneck4 = BottleNeck(in_size=24, exp_size=72, out_size=40, s=2, is_se_existing=True, NL=""RE"", k=5)\n        self.bneck5 = BottleNeck(in_size=40, exp_size=120, out_size=40, s=1, is_se_existing=True, NL=""RE"", k=5)\n        self.bneck6 = BottleNeck(in_size=40, exp_size=120, out_size=40, s=1, is_se_existing=True, NL=""RE"", k=5)\n        self.bneck7 = BottleNeck(in_size=40, exp_size=240, out_size=80, s=2, is_se_existing=False, NL=""HS"", k=3)\n        self.bneck8 = BottleNeck(in_size=80, exp_size=200, out_size=80, s=1, is_se_existing=False, NL=""HS"", k=3)\n        self.bneck9 = BottleNeck(in_size=80, exp_size=184, out_size=80, s=1, is_se_existing=False, NL=""HS"", k=3)\n        self.bneck10 = BottleNeck(in_size=80, exp_size=184, out_size=80, s=1, is_se_existing=False, NL=""HS"", k=3)\n        self.bneck11 = BottleNeck(in_size=80, exp_size=480, out_size=112, s=1, is_se_existing=True, NL=""HS"", k=3)\n        self.bneck12 = BottleNeck(in_size=112, exp_size=672, out_size=112, s=1, is_se_existing=True, NL=""HS"", k=3)\n        self.bneck13 = BottleNeck(in_size=112, exp_size=672, out_size=160, s=2, is_se_existing=True, NL=""HS"", k=5)\n        self.bneck14 = BottleNeck(in_size=160, exp_size=960, out_size=160, s=1, is_se_existing=True, NL=""HS"", k=5)\n        self.bneck15 = BottleNeck(in_size=160, exp_size=960, out_size=160, s=1, is_se_existing=True, NL=""HS"", k=5)\n\n        self.conv2 = tf.keras.layers.Conv2D(filters=960,\n                                            kernel_size=(1, 1),\n                                            strides=1,\n                                            padding=""same"")\n        self.bn2 = tf.keras.layers.BatchNormalization()\n        self.avgpool = tf.keras.layers.AveragePooling2D(pool_size=(7, 7),\n                                                        strides=1)\n        self.conv3 = tf.keras.layers.Conv2D(filters=1280,\n                                            kernel_size=(1, 1),\n                                            strides=1,\n                                            padding=""same"")\n        self.conv4 = tf.keras.layers.Conv2D(filters=NUM_CLASSES,\n                                            kernel_size=(1, 1),\n                                            strides=1,\n                                            padding=""same"",\n                                            activation=tf.keras.activations.softmax)\n\n    def call(self, inputs, training=None, mask=None):\n        x = self.conv1(inputs)\n        x = self.bn1(x, training=training)\n        x = h_swish(x)\n\n        x = self.bneck1(x, training=training)\n        x = self.bneck2(x, training=training)\n        x = self.bneck3(x, training=training)\n        x = self.bneck4(x, training=training)\n        x = self.bneck5(x, training=training)\n        x = self.bneck6(x, training=training)\n        x = self.bneck7(x, training=training)\n        x = self.bneck8(x, training=training)\n        x = self.bneck9(x, training=training)\n        x = self.bneck10(x, training=training)\n        x = self.bneck11(x, training=training)\n        x = self.bneck12(x, training=training)\n        x = self.bneck13(x, training=training)\n        x = self.bneck14(x, training=training)\n        x = self.bneck15(x, training=training)\n\n        x = self.conv2(x)\n        x = self.bn2(x, training=training)\n        x = h_swish(x)\n        x = self.avgpool(x)\n        x = self.conv3(x)\n        x = h_swish(x)\n        x = self.conv4(x)\n\n        return x\n'"
models/mobilenet_v3_small.py,9,"b'import tensorflow as tf\nfrom models.mobilenet_v3_block import BottleNeck, h_swish\nfrom configuration import NUM_CLASSES\n\n\nclass MobileNetV3Small(tf.keras.Model):\n    def __init__(self):\n        super(MobileNetV3Small, self).__init__()\n        self.conv1 = tf.keras.layers.Conv2D(filters=16,\n                                            kernel_size=(3, 3),\n                                            strides=2,\n                                            padding=""same"")\n        self.bn1 = tf.keras.layers.BatchNormalization()\n        self.bneck1 = BottleNeck(in_size=16, exp_size=16, out_size=16, s=2, is_se_existing=True, NL=""RE"", k=3)\n        self.bneck2 = BottleNeck(in_size=16, exp_size=72, out_size=24, s=2, is_se_existing=False, NL=""RE"", k=3)\n        self.bneck3 = BottleNeck(in_size=24, exp_size=88, out_size=24, s=1, is_se_existing=False, NL=""RE"", k=3)\n        self.bneck4 = BottleNeck(in_size=24, exp_size=96, out_size=40, s=2, is_se_existing=True, NL=""HS"", k=5)\n        self.bneck5 = BottleNeck(in_size=40, exp_size=240, out_size=40, s=1, is_se_existing=True, NL=""HS"", k=5)\n        self.bneck6 = BottleNeck(in_size=40, exp_size=240, out_size=40, s=1, is_se_existing=True, NL=""HS"", k=5)\n        self.bneck7 = BottleNeck(in_size=40, exp_size=120, out_size=48, s=1, is_se_existing=True, NL=""HS"", k=5)\n        self.bneck8 = BottleNeck(in_size=48, exp_size=144, out_size=48, s=1, is_se_existing=True, NL=""HS"", k=5)\n        self.bneck9 = BottleNeck(in_size=48, exp_size=288, out_size=96, s=2, is_se_existing=True, NL=""HS"", k=5)\n        self.bneck10 = BottleNeck(in_size=96, exp_size=576, out_size=96, s=1, is_se_existing=True, NL=""HS"", k=5)\n        self.bneck11 = BottleNeck(in_size=96, exp_size=576, out_size=96, s=1, is_se_existing=True, NL=""HS"", k=5)\n\n        self.conv2 = tf.keras.layers.Conv2D(filters=576,\n                                            kernel_size=(1, 1),\n                                            strides=1,\n                                            padding=""same"")\n        self.bn2 = tf.keras.layers.BatchNormalization()\n        self.avgpool = tf.keras.layers.AveragePooling2D(pool_size=(7, 7),\n                                                        strides=1)\n        self.conv3 = tf.keras.layers.Conv2D(filters=1280,\n                                            kernel_size=(1, 1),\n                                            strides=1,\n                                            padding=""same"")\n        self.conv4 = tf.keras.layers.Conv2D(filters=NUM_CLASSES,\n                                            kernel_size=(1, 1),\n                                            strides=1,\n                                            padding=""same"",\n                                            activation=tf.keras.activations.softmax)\n\n    def call(self, inputs, training=None, mask=None):\n        x = self.conv1(inputs)\n        x = self.bn1(x, training=training)\n        x = h_swish(x)\n\n        x = self.bneck1(x, training=training)\n        x = self.bneck2(x, training=training)\n        x = self.bneck3(x, training=training)\n        x = self.bneck4(x, training=training)\n        x = self.bneck5(x, training=training)\n        x = self.bneck6(x, training=training)\n        x = self.bneck7(x, training=training)\n        x = self.bneck8(x, training=training)\n        x = self.bneck9(x, training=training)\n        x = self.bneck10(x, training=training)\n        x = self.bneck11(x, training=training)\n\n        x = self.conv2(x)\n        x = self.bn2(x, training=training)\n        x = h_swish(x)\n        x = self.avgpool(x)\n        x = self.conv3(x)\n        x = h_swish(x)\n        x = self.conv4(x)\n\n        return x\n\n'"
models/residual_block.py,25,"b'import tensorflow as tf\n\n\nclass BasicBlock(tf.keras.layers.Layer):\n\n    def __init__(self, filter_num, stride=1):\n        super(BasicBlock, self).__init__()\n        self.conv1 = tf.keras.layers.Conv2D(filters=filter_num,\n                                            kernel_size=(3, 3),\n                                            strides=stride,\n                                            padding=""same"")\n        self.bn1 = tf.keras.layers.BatchNormalization()\n        self.conv2 = tf.keras.layers.Conv2D(filters=filter_num,\n                                            kernel_size=(3, 3),\n                                            strides=1,\n                                            padding=""same"")\n        self.bn2 = tf.keras.layers.BatchNormalization()\n        if stride != 1:\n            self.downsample = tf.keras.Sequential()\n            self.downsample.add(tf.keras.layers.Conv2D(filters=filter_num,\n                                                       kernel_size=(1, 1),\n                                                       strides=stride))\n            self.downsample.add(tf.keras.layers.BatchNormalization())\n        else:\n            self.downsample = lambda x: x\n\n    def call(self, inputs, training=None, **kwargs):\n        residual = self.downsample(inputs)\n\n        x = self.conv1(inputs)\n        x = self.bn1(x, training=training)\n        x = tf.nn.relu(x)\n        x = self.conv2(x)\n        x = self.bn2(x, training=training)\n\n        output = tf.nn.relu(tf.keras.layers.add([residual, x]))\n\n        return output\n\n\nclass BottleNeck(tf.keras.layers.Layer):\n    def __init__(self, filter_num, stride=1):\n        super(BottleNeck, self).__init__()\n        self.conv1 = tf.keras.layers.Conv2D(filters=filter_num,\n                                            kernel_size=(1, 1),\n                                            strides=1,\n                                            padding=\'same\')\n        self.bn1 = tf.keras.layers.BatchNormalization()\n        self.conv2 = tf.keras.layers.Conv2D(filters=filter_num,\n                                            kernel_size=(3, 3),\n                                            strides=stride,\n                                            padding=\'same\')\n        self.bn2 = tf.keras.layers.BatchNormalization()\n        self.conv3 = tf.keras.layers.Conv2D(filters=filter_num * 4,\n                                            kernel_size=(1, 1),\n                                            strides=1,\n                                            padding=\'same\')\n        self.bn3 = tf.keras.layers.BatchNormalization()\n\n        self.downsample = tf.keras.Sequential()\n        self.downsample.add(tf.keras.layers.Conv2D(filters=filter_num * 4,\n                                                   kernel_size=(1, 1),\n                                                   strides=stride))\n        self.downsample.add(tf.keras.layers.BatchNormalization())\n\n    def call(self, inputs, training=None, **kwargs):\n        residual = self.downsample(inputs)\n\n        x = self.conv1(inputs)\n        x = self.bn1(x, training=training)\n        x = tf.nn.relu(x)\n        x = self.conv2(x)\n        x = self.bn2(x, training=training)\n        x = tf.nn.relu(x)\n        x = self.conv3(x)\n        x = self.bn3(x, training=training)\n\n        output = tf.nn.relu(tf.keras.layers.add([residual, x]))\n\n        return output\n\n\ndef make_basic_block_layer(filter_num, blocks, stride=1):\n    res_block = tf.keras.Sequential()\n    res_block.add(BasicBlock(filter_num, stride=stride))\n\n    for _ in range(1, blocks):\n        res_block.add(BasicBlock(filter_num, stride=1))\n\n    return res_block\n\n\ndef make_bottleneck_layer(filter_num, blocks, stride=1):\n    res_block = tf.keras.Sequential()\n    res_block.add(BottleNeck(filter_num, stride=stride))\n\n    for _ in range(1, blocks):\n        res_block.add(BottleNeck(filter_num, stride=1))\n\n    return res_block\n'"
models/resnet.py,14,"b'import tensorflow as tf\nfrom configuration import NUM_CLASSES\nfrom models.residual_block import make_basic_block_layer, make_bottleneck_layer\n\n\nclass ResNetTypeI(tf.keras.Model):\n    def __init__(self, layer_params):\n        super(ResNetTypeI, self).__init__()\n\n        self.conv1 = tf.keras.layers.Conv2D(filters=64,\n                                            kernel_size=(7, 7),\n                                            strides=2,\n                                            padding=""same"")\n        self.bn1 = tf.keras.layers.BatchNormalization()\n        self.pool1 = tf.keras.layers.MaxPool2D(pool_size=(3, 3),\n                                               strides=2,\n                                               padding=""same"")\n\n        self.layer1 = make_basic_block_layer(filter_num=64,\n                                             blocks=layer_params[0])\n        self.layer2 = make_basic_block_layer(filter_num=128,\n                                             blocks=layer_params[1],\n                                             stride=2)\n        self.layer3 = make_basic_block_layer(filter_num=256,\n                                             blocks=layer_params[2],\n                                             stride=2)\n        self.layer4 = make_basic_block_layer(filter_num=512,\n                                             blocks=layer_params[3],\n                                             stride=2)\n\n        self.avgpool = tf.keras.layers.GlobalAveragePooling2D()\n        self.fc = tf.keras.layers.Dense(units=NUM_CLASSES, activation=tf.keras.activations.softmax)\n\n    def call(self, inputs, training=None, mask=None):\n        x = self.conv1(inputs)\n        x = self.bn1(x, training=training)\n        x = tf.nn.relu(x)\n        x = self.pool1(x)\n        x = self.layer1(x, training=training)\n        x = self.layer2(x, training=training)\n        x = self.layer3(x, training=training)\n        x = self.layer4(x, training=training)\n        x = self.avgpool(x)\n        output = self.fc(x)\n\n        return output\n\n\nclass ResNetTypeII(tf.keras.Model):\n    def __init__(self, layer_params):\n        super(ResNetTypeII, self).__init__()\n        self.conv1 = tf.keras.layers.Conv2D(filters=64,\n                                            kernel_size=(7, 7),\n                                            strides=2,\n                                            padding=""same"")\n        self.bn1 = tf.keras.layers.BatchNormalization()\n        self.pool1 = tf.keras.layers.MaxPool2D(pool_size=(3, 3),\n                                               strides=2,\n                                               padding=""same"")\n\n        self.layer1 = make_bottleneck_layer(filter_num=64,\n                                            blocks=layer_params[0])\n        self.layer2 = make_bottleneck_layer(filter_num=128,\n                                            blocks=layer_params[1],\n                                            stride=2)\n        self.layer3 = make_bottleneck_layer(filter_num=256,\n                                            blocks=layer_params[2],\n                                            stride=2)\n        self.layer4 = make_bottleneck_layer(filter_num=512,\n                                            blocks=layer_params[3],\n                                            stride=2)\n\n        self.avgpool = tf.keras.layers.GlobalAveragePooling2D()\n        self.fc = tf.keras.layers.Dense(units=NUM_CLASSES, activation=tf.keras.activations.softmax)\n\n    def call(self, inputs, training=None, mask=None):\n        x = self.conv1(inputs)\n        x = self.bn1(x, training=training)\n        x = tf.nn.relu(x)\n        x = self.pool1(x)\n        x = self.layer1(x, training=training)\n        x = self.layer2(x, training=training)\n        x = self.layer3(x, training=training)\n        x = self.layer4(x, training=training)\n        x = self.avgpool(x)\n        output = self.fc(x)\n\n        return output\n\n\ndef resnet_18():\n    return ResNetTypeI(layer_params=[2, 2, 2, 2])\n\n\ndef resnet_34():\n    return ResNetTypeI(layer_params=[3, 4, 6, 3])\n\n\ndef resnet_50():\n    return ResNetTypeII(layer_params=[3, 4, 6, 3])\n\n\ndef resnet_101():\n    return ResNetTypeII(layer_params=[3, 4, 23, 3])\n\n\ndef resnet_152():\n    return ResNetTypeII(layer_params=[3, 8, 36, 3])\n'"
models/resnext.py,8,"b'import tensorflow as tf\nfrom models.resnext_block import build_ResNeXt_block\nfrom configuration import NUM_CLASSES\n\n\nclass ResNeXt(tf.keras.Model):\n    def __init__(self, repeat_num_list, cardinality):\n        if len(repeat_num_list) != 4:\n            raise ValueError(""The length of repeat_num_list must be four."")\n        super(ResNeXt, self).__init__()\n        self.conv1 = tf.keras.layers.Conv2D(filters=64,\n                                            kernel_size=(7, 7),\n                                            strides=2,\n                                            padding=""same"")\n        self.bn1 = tf.keras.layers.BatchNormalization()\n        self.pool1 = tf.keras.layers.MaxPool2D(pool_size=(3, 3),\n                                               strides=2,\n                                               padding=""same"")\n        self.block1 = build_ResNeXt_block(filters=128,\n                                          strides=1,\n                                          groups=cardinality,\n                                          repeat_num=repeat_num_list[0])\n        self.block2 = build_ResNeXt_block(filters=256,\n                                          strides=2,\n                                          groups=cardinality,\n                                          repeat_num=repeat_num_list[1])\n        self.block3 = build_ResNeXt_block(filters=512,\n                                          strides=2,\n                                          groups=cardinality,\n                                          repeat_num=repeat_num_list[2])\n        self.block4 = build_ResNeXt_block(filters=1024,\n                                          strides=2,\n                                          groups=cardinality,\n                                          repeat_num=repeat_num_list[3])\n        self.pool2 = tf.keras.layers.GlobalAveragePooling2D()\n        self.fc = tf.keras.layers.Dense(units=NUM_CLASSES,\n                                        activation=tf.keras.activations.softmax)\n\n    def call(self, inputs, training=None, mask=None):\n        x = self.conv1(inputs)\n        x = self.bn1(x, training=training)\n        x = tf.nn.relu(x)\n        x = self.pool1(x)\n\n        x = self.block1(x, training=training)\n        x = self.block2(x, training=training)\n        x = self.block3(x, training=training)\n        x = self.block4(x, training=training)\n\n        x = self.pool2(x)\n        x = self.fc(x)\n\n        return x\n\n\ndef ResNeXt50():\n    return ResNeXt(repeat_num_list=[3, 4, 6, 3],\n                   cardinality=32)\n\n\ndef ResNeXt101():\n    return ResNeXt(repeat_num_list=[3, 4, 23, 3],\n                   cardinality=32)'"
models/resnext_block.py,12,"b'import tensorflow as tf\nfrom models.group_convolution import GroupConv2D\n\n\nclass ResNeXt_BottleNeck(tf.keras.layers.Layer):\n    def __init__(self, filters, strides, groups):\n        super(ResNeXt_BottleNeck, self).__init__()\n        self.conv1 = tf.keras.layers.Conv2D(filters=filters,\n                                            kernel_size=(1, 1),\n                                            strides=1,\n                                            padding=""same"")\n        self.bn1 = tf.keras.layers.BatchNormalization()\n        self.group_conv = GroupConv2D(input_channels=filters,\n                                      output_channels=filters,\n                                      kernel_size=(3, 3),\n                                      strides=strides,\n                                      padding=""same"",\n                                      groups=groups)\n        self.bn2 = tf.keras.layers.BatchNormalization()\n        self.conv2 = tf.keras.layers.Conv2D(filters=2 * filters,\n                                            kernel_size=(1, 1),\n                                            strides=1,\n                                            padding=""same"")\n        self.bn3 = tf.keras.layers.BatchNormalization()\n        self.shortcut_conv = tf.keras.layers.Conv2D(filters=2 * filters,\n                                                    kernel_size=(1, 1),\n                                                    strides=strides,\n                                                    padding=""same"")\n        self.shortcut_bn = tf.keras.layers.BatchNormalization()\n\n    def call(self, inputs, training=None, **kwargs):\n        x = self.conv1(inputs)\n        x = self.bn1(x, training=training)\n        x = tf.nn.relu(x)\n        x = self.group_conv(x)\n        x = self.bn2(x, training=training)\n        x = tf.nn.relu(x)\n        x = self.conv2(x)\n        x = self.bn3(x, training=training)\n\n        shortcut = self.shortcut_conv(inputs)\n        shortcut = self.shortcut_bn(shortcut, training=training)\n\n        output = tf.nn.relu(tf.keras.layers.add([x, shortcut]))\n        return output\n\n\ndef build_ResNeXt_block(filters, strides, groups, repeat_num):\n    block = tf.keras.Sequential()\n    block.add(ResNeXt_BottleNeck(filters=filters,\n                                 strides=strides,\n                                 groups=groups))\n    for _ in range(1, repeat_num):\n        block.add(ResNeXt_BottleNeck(filters=filters,\n                                     strides=1,\n                                     groups=groups))\n\n    return block'"
models/se_resnet.py,30,"b""import tensorflow as tf\nfrom configuration import NUM_CLASSES\n\n\nclass SEBlock(tf.keras.layers.Layer):\n    def __init__(self, input_channels, r=16):\n        super(SEBlock, self).__init__()\n        self.pool = tf.keras.layers.GlobalAveragePooling2D()\n        self.fc1 = tf.keras.layers.Dense(units=input_channels // r)\n        self.fc2 = tf.keras.layers.Dense(units=input_channels)\n\n    def call(self, inputs, **kwargs):\n        branch = self.pool(inputs)\n        branch = self.fc1(branch)\n        branch = tf.nn.relu(branch)\n        branch = self.fc2(branch)\n        branch = tf.nn.sigmoid(branch)\n        branch = tf.expand_dims(input=branch, axis=1)\n        branch = tf.expand_dims(input=branch, axis=1)\n        output = tf.keras.layers.multiply(inputs=[inputs, branch])\n        return output\n\n\nclass BottleNeck(tf.keras.layers.Layer):\n    def __init__(self, filter_num, stride=1):\n        super(BottleNeck, self).__init__()\n        self.conv1 = tf.keras.layers.Conv2D(filters=filter_num,\n                                            kernel_size=(1, 1),\n                                            strides=1,\n                                            padding='same')\n        self.bn1 = tf.keras.layers.BatchNormalization()\n        self.conv2 = tf.keras.layers.Conv2D(filters=filter_num,\n                                            kernel_size=(3, 3),\n                                            strides=stride,\n                                            padding='same')\n        self.bn2 = tf.keras.layers.BatchNormalization()\n        self.conv3 = tf.keras.layers.Conv2D(filters=filter_num * 4,\n                                            kernel_size=(1, 1),\n                                            strides=1,\n                                            padding='same')\n        self.bn3 = tf.keras.layers.BatchNormalization()\n        self.se = SEBlock(input_channels=filter_num * 4)\n\n        self.downsample = tf.keras.Sequential()\n        self.downsample.add(tf.keras.layers.Conv2D(filters=filter_num * 4,\n                                                   kernel_size=(1, 1),\n                                                   strides=stride))\n        self.downsample.add(tf.keras.layers.BatchNormalization())\n\n    def call(self, inputs, training=None):\n        identity = self.downsample(inputs)\n\n        x = self.conv1(inputs)\n        x = self.bn1(x, training=training)\n        x = tf.nn.relu(x)\n        x = self.conv2(x)\n        x = self.bn2(x, training=training)\n        x = tf.nn.relu(x)\n        x = self.conv3(x)\n        x = self.bn3(x, training=training)\n        x = self.se(x)\n        output = tf.nn.relu(tf.keras.layers.add([identity, x]))\n        return output\n\n\nclass SEResNet(tf.keras.Model):\n    def __init__(self, block_num):\n        super(SEResNet, self).__init__()\n\n        self.pre1 = tf.keras.layers.Conv2D(filters=64,\n                                           kernel_size=(7, 7),\n                                           strides=2,\n                                           padding='same')\n        self.pre2 = tf.keras.layers.BatchNormalization()\n        self.pre3 = tf.keras.layers.Activation(tf.keras.activations.relu)\n        self.pre4 = tf.keras.layers.MaxPool2D(pool_size=(3, 3),\n                                              strides=2)\n\n        self.layer1 = self._make_res_block(filter_num=64,\n                                           blocks=block_num[0])\n        self.layer2 = self._make_res_block(filter_num=128,\n                                           blocks=block_num[1],\n                                           stride=2)\n        self.layer3 = self._make_res_block(filter_num=256,\n                                           blocks=block_num[2],\n                                           stride=2)\n        self.layer4 = self._make_res_block(filter_num=512,\n                                           blocks=block_num[3],\n                                           stride=2)\n\n        self.avgpool = tf.keras.layers.GlobalAveragePooling2D()\n        self.fc = tf.keras.layers.Dense(units=NUM_CLASSES, activation=tf.keras.activations.softmax)\n\n    def _make_res_block(self, filter_num, blocks, stride=1):\n        res_block = tf.keras.Sequential()\n        res_block.add(BottleNeck(filter_num, stride=stride))\n\n        for _ in range(1, blocks):\n            res_block.add(BottleNeck(filter_num, stride=1))\n\n        return res_block\n\n    def call(self, inputs, training=None, mask=None):\n        pre1 = self.pre1(inputs)\n        pre2 = self.pre2(pre1, training=training)\n        pre3 = self.pre3(pre2)\n        pre4 = self.pre4(pre3)\n        l1 = self.layer1(pre4, training=training)\n        l2 = self.layer2(l1, training=training)\n        l3 = self.layer3(l2, training=training)\n        l4 = self.layer4(l3, training=training)\n        avgpool = self.avgpool(l4)\n        out = self.fc(avgpool)\n        return out\n\n\ndef se_resnet_50():\n    return SEResNet(block_num=[3, 4, 6, 3])\n\n\ndef se_resnet_101():\n    return SEResNet(block_num=[3, 4, 23, 3])\n\n\ndef se_resnet_152():\n    return SEResNet(block_num=[3, 8, 36, 3])"""
models/se_resnext.py,29,"b'import tensorflow as tf\n\nfrom configuration import NUM_CLASSES\nfrom models.group_convolution import GroupConv2D\n\n\nclass SEBlock(tf.keras.layers.Layer):\n    def __init__(self, input_channels, r=16):\n        super(SEBlock, self).__init__()\n        self.pool = tf.keras.layers.GlobalAveragePooling2D()\n        self.fc1 = tf.keras.layers.Dense(units=input_channels // r)\n        self.fc2 = tf.keras.layers.Dense(units=input_channels)\n\n    def call(self, inputs, **kwargs):\n        branch = self.pool(inputs)\n        branch = self.fc1(branch)\n        branch = tf.nn.relu(branch)\n        branch = self.fc2(branch)\n        branch = tf.nn.sigmoid(branch)\n        branch = tf.expand_dims(input=branch, axis=1)\n        branch = tf.expand_dims(input=branch, axis=1)\n        output = tf.keras.layers.multiply(inputs=[inputs, branch])\n        return output\n\n\nclass BottleNeck(tf.keras.layers.Layer):\n    def __init__(self, filters, strides, groups):\n        super(BottleNeck, self).__init__()\n        self.conv1 = tf.keras.layers.Conv2D(filters=filters,\n                                            kernel_size=(1, 1),\n                                            strides=1,\n                                            padding=""same"")\n        self.bn1 = tf.keras.layers.BatchNormalization()\n        self.group_conv = GroupConv2D(input_channels=filters,\n                                      output_channels=filters,\n                                      kernel_size=(3, 3),\n                                      strides=strides,\n                                      padding=""same"",\n                                      groups=groups)\n        self.bn2 = tf.keras.layers.BatchNormalization()\n        self.conv2 = tf.keras.layers.Conv2D(filters=2 * filters,\n                                            kernel_size=(1, 1),\n                                            strides=1,\n                                            padding=""same"")\n        self.bn3 = tf.keras.layers.BatchNormalization()\n        self.se = SEBlock(input_channels=2 * filters)\n\n        self.shortcut_conv = tf.keras.layers.Conv2D(filters=2 * filters,\n                                                    kernel_size=(1, 1),\n                                                    strides=strides,\n                                                    padding=""same"")\n        self.shortcut_bn = tf.keras.layers.BatchNormalization()\n\n    def call(self, inputs, training=None, **kwargs):\n        x = self.conv1(inputs)\n        x = self.bn1(x, training=training)\n        x = tf.nn.relu(x)\n        x = self.group_conv(x)\n        x = self.bn2(x, training=training)\n        x = tf.nn.relu(x)\n        x = self.conv2(x)\n        x = self.bn3(x, training=training)\n        x = self.se(x)\n\n        shortcut = self.shortcut_conv(inputs)\n        shortcut = self.shortcut_bn(shortcut, training=training)\n\n        output = tf.nn.relu(tf.keras.layers.add([x, shortcut]))\n        return output\n\n\nclass SEResNeXt(tf.keras.Model):\n    def __init__(self, repeat_num_list, cardinality):\n        super(SEResNeXt, self).__init__()\n        self.conv1 = tf.keras.layers.Conv2D(filters=64,\n                                            kernel_size=(7, 7),\n                                            strides=2,\n                                            padding=""same"")\n        self.bn1 = tf.keras.layers.BatchNormalization()\n        self.pool1 = tf.keras.layers.MaxPool2D(pool_size=(3, 3),\n                                               strides=2,\n                                               padding=""same"")\n        self.block1 = SEResNeXt.__make_layer(filters=128,\n                                             strides=1,\n                                             groups=cardinality,\n                                             repeat_num=repeat_num_list[0])\n        self.block2 = SEResNeXt.__make_layer(filters=256,\n                                             strides=2,\n                                             groups=cardinality,\n                                             repeat_num=repeat_num_list[1])\n        self.block3 = SEResNeXt.__make_layer(filters=512,\n                                             strides=2,\n                                             groups=cardinality,\n                                             repeat_num=repeat_num_list[2])\n        self.block4 = SEResNeXt.__make_layer(filters=1024,\n                                             strides=2,\n                                             groups=cardinality,\n                                             repeat_num=repeat_num_list[3])\n        self.pool2 = tf.keras.layers.GlobalAveragePooling2D()\n        self.fc = tf.keras.layers.Dense(units=NUM_CLASSES,\n                                        activation=tf.keras.activations.softmax)\n\n    @staticmethod\n    def __make_layer(filters, strides, groups, repeat_num):\n        block = tf.keras.Sequential()\n        block.add(BottleNeck(filters=filters,\n                             strides=strides,\n                             groups=groups))\n        for _ in range(1, repeat_num):\n            block.add(BottleNeck(filters=filters,\n                                 strides=1,\n                                 groups=groups))\n\n        return block\n\n    def call(self, inputs, training=None, mask=None):\n        x = self.conv1(inputs)\n        x = self.bn1(x, training=training)\n        x = tf.nn.relu(x)\n        x = self.pool1(x)\n\n        x = self.block1(x, training=training)\n        x = self.block2(x, training=training)\n        x = self.block3(x, training=training)\n        x = self.block4(x, training=training)\n\n        x = self.pool2(x)\n        x = self.fc(x)\n\n        return x\n\n\ndef SEResNeXt50():\n    return SEResNeXt(repeat_num_list=[3, 4, 6, 3], cardinality=32)\n\n\ndef SEResNeXt101():\n    return SEResNeXt(repeat_num_list=[3, 4, 23, 3], cardinality=32)'"
models/shufflenet_v2.py,40,"b'import tensorflow as tf\n\nfrom configuration import NUM_CLASSES\n\n\ndef channel_shuffle(feature, group):\n    channel_num = feature.shape[-1]\n    if channel_num % group != 0:\n        raise ValueError(""The group must be divisible by the shape of the last dimension of the feature."")\n    x = tf.reshape(feature, shape=(-1, feature.shape[1], feature.shape[2], group, channel_num // group))\n    x = tf.transpose(x, perm=[0, 1, 2, 4, 3])\n    x = tf.reshape(x, shape=(-1, feature.shape[1], feature.shape[2], channel_num))\n    return x\n\n\nclass ShuffleBlockS1(tf.keras.layers.Layer):\n    def __init__(self, in_channels, out_channels):\n        super(ShuffleBlockS1, self).__init__()\n        self.conv1 = tf.keras.layers.Conv2D(filters=out_channels // 2,\n                                            kernel_size=(1, 1),\n                                            strides=1,\n                                            padding=""same"")\n        self.bn1 = tf.keras.layers.BatchNormalization()\n        self.dwconv = tf.keras.layers.DepthwiseConv2D(kernel_size=(3, 3), strides=1, padding=""same"")\n        self.dw_bn = tf.keras.layers.BatchNormalization()\n        self.conv2 = tf.keras.layers.Conv2D(filters=out_channels // 2,\n                                            kernel_size=(1, 1),\n                                            strides=1,\n                                            padding=""same"")\n        self.bn2 = tf.keras.layers.BatchNormalization()\n\n    def call(self, inputs, training=None, **kwargs):\n        branch, x = tf.split(inputs, num_or_size_splits=2, axis=-1)\n        x = self.conv1(x)\n        x = self.bn1(x, training=training)\n        x = tf.nn.relu(x)\n        x = self.dwconv(x)\n        x = self.dw_bn(x, training=training)\n        x = self.conv2(x)\n        x = self.bn2(x, training=training)\n        x = tf.nn.relu(x)\n\n        outputs = tf.concat(values=[branch, x], axis=-1)\n        outputs = channel_shuffle(feature=outputs, group=2)\n        return outputs\n\n\nclass ShuffleBlockS2(tf.keras.layers.Layer):\n    def __init__(self, in_channels, out_channels):\n        super(ShuffleBlockS2, self).__init__()\n        self.conv1 = tf.keras.layers.Conv2D(filters=out_channels // 2,\n                                            kernel_size=(1, 1),\n                                            strides=1,\n                                            padding=""same"")\n        self.bn1 = tf.keras.layers.BatchNormalization()\n        self.dwconv = tf.keras.layers.DepthwiseConv2D(kernel_size=(3, 3), strides=2, padding=""same"")\n        self.dw_bn = tf.keras.layers.BatchNormalization()\n        self.conv2 = tf.keras.layers.Conv2D(filters=out_channels - in_channels,\n                                            kernel_size=(1, 1),\n                                            strides=1,\n                                            padding=""same"")\n        self.bn2 = tf.keras.layers.BatchNormalization()\n\n        self.branch_dwconv = tf.keras.layers.DepthwiseConv2D(kernel_size=(3, 3), strides=2, padding=""same"")\n        self.branch_dwbn = tf.keras.layers.BatchNormalization()\n        self.branch_conv = tf.keras.layers.Conv2D(filters=in_channels,\n                                                  kernel_size=(1, 1),\n                                                  strides=1,\n                                                  padding=""same"")\n        self.branch_bn = tf.keras.layers.BatchNormalization()\n\n    def call(self, inputs, training=None, **kwargs):\n        x = self.conv1(inputs)\n        x = self.bn1(x, training=training)\n        x = tf.nn.relu(x)\n        x = self.dwconv(x)\n        x = self.dw_bn(x, training=training)\n        x = self.conv2(x)\n        x = self.bn2(x, training=training)\n        x = tf.nn.relu(x)\n\n        branch = self.branch_dwconv(inputs)\n        branch = self.branch_dwbn(branch, training=training)\n        branch = self.branch_conv(branch)\n        branch = self.branch_bn(branch, training=training)\n        branch = tf.nn.relu(branch)\n\n        outputs = tf.concat(values=[x, branch], axis=-1)\n        outputs = channel_shuffle(feature=outputs, group=2)\n        return outputs\n\n\nclass ShuffleNetV2(tf.keras.Model):\n    def __init__(self, channel_scale):\n        super(ShuffleNetV2, self).__init__()\n        self.conv1 = tf.keras.layers.Conv2D(filters=24, kernel_size=(3, 3), strides=2, padding=""same"")\n        self.bn1 = tf.keras.layers.BatchNormalization()\n        self.maxpool = tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides=2, padding=""same"")\n        self.stage1 = self._make_layer(repeat_num=4, in_channels=24, out_channels=channel_scale[0])\n        self.stage2 = self._make_layer(repeat_num=8, in_channels=channel_scale[0], out_channels=channel_scale[1])\n        self.stage3 = self._make_layer(repeat_num=4, in_channels=channel_scale[1], out_channels=channel_scale[2])\n        self.conv5 = tf.keras.layers.Conv2D(filters=channel_scale[3], kernel_size=(1, 1), strides=1, padding=""same"")\n        self.bn5 = tf.keras.layers.BatchNormalization()\n        self.avgpool = tf.keras.layers.GlobalAveragePooling2D()\n        self.fc = tf.keras.layers.Dense(units=NUM_CLASSES, activation=tf.keras.activations.softmax)\n\n    def _make_layer(self, repeat_num, in_channels, out_channels):\n        block = tf.keras.Sequential()\n        block.add(ShuffleBlockS2(in_channels=in_channels, out_channels=out_channels))\n        for i in range(1, repeat_num):\n            block.add(ShuffleBlockS1(in_channels=out_channels, out_channels=out_channels))\n        return block\n\n    def call(self, inputs, training=None, mask=None):\n        x = self.conv1(inputs)\n        x = self.bn1(x, training=training)\n        x = tf.nn.relu(x)\n        x = self.maxpool(x)\n        x = self.stage1(x, training=training)\n        x = self.stage2(x, training=training)\n        x = self.stage3(x, training=training)\n        x = self.conv5(x)\n        x = self.bn5(x, training=training)\n        x = tf.nn.relu(x)\n        x = self.avgpool(x)\n        x = self.fc(x)\n        return x\n\n\ndef shufflenet_0_5x():\n    return ShuffleNetV2(channel_scale=[48, 96, 192, 1024])\n\n\ndef shufflenet_1_0x():\n    return ShuffleNetV2(channel_scale=[116, 232, 464, 1024])\n\n\ndef shufflenet_1_5x():\n    return ShuffleNetV2(channel_scale=[176, 352, 704, 1024])\n\n\ndef shufflenet_2_0x():\n    return ShuffleNetV2(channel_scale=[244, 488, 976, 2048])\n'"
models/squeezenet.py,17,"b'import tensorflow as tf\nfrom configuration import NUM_CLASSES\n\n\nclass FireModule(tf.keras.layers.Layer):\n    def __init__(self, s1, e1, e3):\n        super(FireModule, self).__init__()\n        self.squeeze_layer = tf.keras.layers.Conv2D(filters=s1,\n                                                    kernel_size=(1, 1),\n                                                    strides=1,\n                                                    padding=""same"")\n        self.expand_1x1 = tf.keras.layers.Conv2D(filters=e1,\n                                                 kernel_size=(1, 1),\n                                                 strides=1,\n                                                 padding=""same"")\n        self.expand_3x3 = tf.keras.layers.Conv2D(filters=e3,\n                                                 kernel_size=(3, 3),\n                                                 strides=1,\n                                                 padding=""same"")\n\n    def call(self, inputs, **kwargs):\n        x = self.squeeze_layer(inputs)\n        x = tf.nn.relu(x)\n        y1 = self.expand_1x1(x)\n        y1 = tf.nn.relu(y1)\n        y2 = self.expand_3x3(x)\n        y2 = tf.nn.relu(y2)\n        return tf.concat(values=[y1, y2], axis=-1)\n\n\nclass SqueezeNet(tf.keras.Model):\n    def __init__(self):\n        super(SqueezeNet, self).__init__()\n        self.conv1 = tf.keras.layers.Conv2D(filters=96,\n                                            kernel_size=(7, 7),\n                                            strides=2,\n                                            padding=""same"")\n        self.maxpool1 = tf.keras.layers.MaxPool2D(pool_size=(3, 3),\n                                                  strides=2)\n        self.fire2 = FireModule(s1=16, e1=64, e3=64)\n        self.fire3 = FireModule(s1=16, e1=64, e3=64)\n        self.fire4 = FireModule(s1=32, e1=128, e3=128)\n        self.maxpool4 = tf.keras.layers.MaxPool2D(pool_size=(3, 3),\n                                                  strides=2)\n        self.fire5 = FireModule(s1=32, e1=128, e3=128)\n        self.fire6 = FireModule(s1=48, e1=192, e3=192)\n        self.fire7 = FireModule(s1=48, e1=192, e3=192)\n        self.fire8 = FireModule(s1=64, e1=256, e3=256)\n        self.maxpool8 = tf.keras.layers.MaxPool2D(pool_size=(3, 3),\n                                                  strides=2)\n        self.fire9 = FireModule(s1=64, e1=256, e3=256)\n        self.dropout = tf.keras.layers.Dropout(rate=0.5)\n        self.conv10 = tf.keras.layers.Conv2D(filters=NUM_CLASSES,\n                                             kernel_size=(1, 1),\n                                             strides=1,\n                                             padding=""same"")\n        self.avgpool10 = tf.keras.layers.GlobalAveragePooling2D()\n\n    def call(self, inputs, training=None, mask=None):\n        x = self.conv1(inputs)\n        x = self.maxpool1(x)\n        x = self.fire2(x)\n        x = self.fire3(x)\n        x = self.fire4(x)\n        x = self.maxpool4(x)\n        x = self.fire5(x)\n        x = self.fire6(x)\n        x = self.fire7(x)\n        x = self.fire8(x)\n        x = self.maxpool8(x)\n        x = self.fire9(x)\n        x = self.dropout(x, training=training)\n        x = self.conv10(x)\n        x = self.avgpool10(x)\n\n        return tf.nn.softmax(x)\n\n'"
