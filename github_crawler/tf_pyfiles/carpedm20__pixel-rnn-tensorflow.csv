file_path,api_count,code
cifar10.py,25,"b'# Copyright 2015 Google Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\n""""""Routine for decoding the CIFAR-10 binary file format.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nfrom six.moves import xrange  # pylint: disable=redefined-builtin\nimport tensorflow as tf\n\n# Process images of this size. Note that this differs from the original CIFAR\n# image size of 32 x 32. If one alters this number, then the entire model\n# architecture will change and any model would need to be retrained.\nIMAGE_SIZE = 24\n\n# Global constants describing the CIFAR-10 data set.\nNUM_CLASSES = 10\nNUM_EXAMPLES_PER_EPOCH_FOR_TRAIN = 50000\nNUM_EXAMPLES_PER_EPOCH_FOR_EVAL = 10000\n\n\ndef read_cifar10(filename_queue):\n  """"""Reads and parses examples from CIFAR10 data files.\n\n  Recommendation: if you want N-way read parallelism, call this function\n  N times.  This will give you N independent Readers reading different\n  files & positions within those files, which will give better mixing of\n  examples.\n\n  Args:\n    filename_queue: A queue of strings with the filenames to read from.\n\n  Returns:\n    An object representing a single example, with the following fields:\n      height: number of rows in the result (32)\n      width: number of columns in the result (32)\n      depth: number of color channels in the result (3)\n      key: a scalar string Tensor describing the filename & record number\n        for this example.\n      label: an int32 Tensor with the label in the range 0..9.\n      uint8image: a [height, width, depth] uint8 Tensor with the image data\n  """"""\n\n  class CIFAR10Record(object):\n    pass\n  result = CIFAR10Record()\n\n  # Dimensions of the images in the CIFAR-10 dataset.\n  # See http://www.cs.toronto.edu/~kriz/cifar.html for a description of the\n  # input format.\n  label_bytes = 1  # 2 for CIFAR-100\n  result.height = 32\n  result.width = 32\n  result.depth = 3\n  image_bytes = result.height * result.width * result.depth\n  # Every record consists of a label followed by the image, with a\n  # fixed number of bytes for each.\n  record_bytes = label_bytes + image_bytes\n\n  # Read a record, getting filenames from the filename_queue.  No\n  # header or footer in the CIFAR-10 format, so we leave header_bytes\n  # and footer_bytes at their default of 0.\n  reader = tf.FixedLengthRecordReader(record_bytes=record_bytes)\n  result.key, value = reader.read(filename_queue)\n\n  # Convert from a string to a vector of uint8 that is record_bytes long.\n  record_bytes = tf.decode_raw(value, tf.uint8)\n\n  # The first bytes represent the label, which we convert from uint8->int32.\n  result.label = tf.cast(\n      tf.slice(record_bytes, [0], [label_bytes]), tf.int32)\n\n  # The remaining bytes after the label represent the image, which we reshape\n  # from [depth * height * width] to [depth, height, width].\n  depth_major = tf.reshape(tf.slice(record_bytes, [label_bytes], [image_bytes]),\n                           [result.depth, result.height, result.width])\n  # Convert from [depth, height, width] to [height, width, depth].\n  result.uint8image = tf.transpose(depth_major, [1, 2, 0])\n\n  return result\n\n\ndef _generate_image_and_label_batch(image, label, min_queue_examples,\n                                    batch_size):\n  """"""Construct a queued batch of images and labels.\n\n  Args:\n    image: 3-D Tensor of [height, width, 3] of type.float32.\n    label: 1-D Tensor of type.int32\n    min_queue_examples: int32, minimum number of samples to retain\n      in the queue that provides of batches of examples.\n    batch_size: Number of images per batch.\n\n  Returns:\n    images: Images. 4D tensor of [batch_size, height, width, 3] size.\n    labels: Labels. 1D tensor of [batch_size] size.\n  """"""\n  # Create a queue that shuffles the examples, and then\n  # read \'batch_size\' images + labels from the example queue.\n  num_preprocess_threads = 16\n  images, label_batch = tf.train.shuffle_batch(\n      [image, label],\n      batch_size=batch_size,\n      num_threads=num_preprocess_threads,\n      capacity=min_queue_examples + 3 * batch_size,\n      min_after_dequeue=min_queue_examples)\n\n  # Display the training images in the visualizer.\n  # FIXED pre-1.0 # tf.image_summary(\'images\', images)\n  tf.summary.image(\'images\', images)\n\n  return images, tf.reshape(label_batch, [batch_size])\n\n\ndef distorted_inputs(data_dir, batch_size):\n  """"""Construct distorted input for CIFAR training using the Reader ops.\n\n  Args:\n    data_dir: Path to the CIFAR-10 data directory.\n    batch_size: Number of images per batch.\n\n  Returns:\n    images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.\n    labels: Labels. 1D tensor of [batch_size] size.\n  """"""\n  filenames = [os.path.join(data_dir, \'data_batch_%d.bin\' % i)\n               for i in xrange(1, 6)]\n  for f in filenames:\n    if not tf.gfile.Exists(f):\n      raise ValueError(\'Failed to find file: \' + f)\n\n  # Create a queue that produces the filenames to read.\n  filename_queue = tf.train.string_input_producer(filenames)\n\n  # Read examples from files in the filename queue.\n  read_input = read_cifar10(filename_queue)\n  reshaped_image = tf.cast(read_input.uint8image, tf.float32)\n\n  height = IMAGE_SIZE\n  width = IMAGE_SIZE\n\n  # Image processing for training the network. Note the many random\n  # distortions applied to the image.\n\n  # Randomly crop a [height, width] section of the image.\n  distorted_image = tf.random_crop(reshaped_image, [height, width, 3])\n\n  # Randomly flip the image horizontally.\n  distorted_image = tf.image.random_flip_left_right(distorted_image)\n\n  # Because these operations are not commutative, consider randomizing\n  # randomize the order their operation.\n  distorted_image = tf.image.random_brightness(distorted_image,\n                                               max_delta=63)\n  distorted_image = tf.image.random_contrast(distorted_image,\n                                             lower=0.2, upper=1.8)\n\n  # Subtract off the mean and divide by the variance of the pixels.\n  # FIXED pre-1.0 # float_image = tf.image.per_image_whitening(distorted_image)\n  float_image = tf.image.per_image_standardization(distorted_image)\n\n  # Ensure that the random shuffling has good mixing properties.\n  min_fraction_of_examples_in_queue = 0.4\n  min_queue_examples = int(NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN *\n                           min_fraction_of_examples_in_queue)\n  print (\'Filling queue with %d CIFAR images before starting to train. \'\n         \'This will take a few minutes.\' % min_queue_examples)\n\n  # Generate a batch of images and labels by building up a queue of examples.\n  return _generate_image_and_label_batch(float_image, read_input.label,\n                                         min_queue_examples, batch_size)\n\n\ndef inputs(eval_data, data_dir, batch_size):\n  """"""Construct input for CIFAR evaluation using the Reader ops.\n\n  Args:\n    eval_data: bool, indicating if one should use the train or eval data set.\n    data_dir: Path to the CIFAR-10 data directory.\n    batch_size: Number of images per batch.\n\n  Returns:\n    images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.\n    labels: Labels. 1D tensor of [batch_size] size.\n  """"""\n  if not eval_data:\n    filenames = [os.path.join(data_dir, \'data_batch_%d.bin\' % i)\n                 for i in xrange(1, 6)]\n    num_examples_per_epoch = NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN\n  else:\n    filenames = [os.path.join(data_dir, \'test_batch.bin\')]\n    num_examples_per_epoch = NUM_EXAMPLES_PER_EPOCH_FOR_EVAL\n\n  for f in filenames:\n    if not tf.gfile.Exists(f):\n      raise ValueError(\'Failed to find file: \' + f)\n\n  # Create a queue that produces the filenames to read.\n  filename_queue = tf.train.string_input_producer(filenames)\n\n  # Read examples from files in the filename queue.\n  read_input = read_cifar10(filename_queue)\n  reshaped_image = tf.cast(read_input.uint8image, tf.float32)\n\n  height = IMAGE_SIZE\n  width = IMAGE_SIZE\n\n  # Image processing for evaluation.\n  # Crop the central [height, width] of the image.\n  resized_image = tf.image.resize_image_with_crop_or_pad(reshaped_image,\n                                                         width, height)\n\n  # Subtract off the mean and divide by the variance of the pixels.\n  # FIXED pre-1.0 # float_image = tf.image.per_image_whitening(resized_image)\n  float_image = tf.image.per_image_standardization(resized_image)\n\n  # Ensure that the random shuffling has good mixing properties.\n  min_fraction_of_examples_in_queue = 0.4\n  min_queue_examples = int(num_examples_per_epoch *\n                           min_fraction_of_examples_in_queue)\n\n  # Generate a batch of images and labels by building up a queue of examples.\n  return _generate_image_and_label_batch(float_image, read_input.label,\n                                         min_queue_examples, batch_size)\n'"
main.py,5,"b'import os\nimport logging\nlogging.basicConfig(format=""[%(asctime)s] %(message)s"", datefmt=""%m-%d %H:%M:%S"")\n\nimport numpy as np\nfrom tqdm import trange\nimport tensorflow as tf\n\nfrom utils import *\nfrom network import Network\nfrom statistic import Statistic\n\nflags = tf.app.flags\n\n# network\nflags.DEFINE_string(""model"", ""pixel_cnn"", ""name of model [pixel_rnn, pixel_cnn]"")\nflags.DEFINE_integer(""batch_size"", 100, ""size of a batch"")\nflags.DEFINE_integer(""hidden_dims"", 16, ""dimesion of hidden states of LSTM or Conv layers"")\nflags.DEFINE_integer(""recurrent_length"", 7, ""the length of LSTM or Conv layers"")\nflags.DEFINE_integer(""out_hidden_dims"", 32, ""dimesion of hidden states of output Conv layers"")\nflags.DEFINE_integer(""out_recurrent_length"", 2, ""the length of output Conv layers"")\nflags.DEFINE_boolean(""use_residual"", False, ""whether to use residual connections or not"")\n# flags.DEFINE_boolean(""use_dynamic_rnn"", False, ""whether to use dynamic_rnn or not"")\n\n# training\nflags.DEFINE_integer(""max_epoch"", 100000, ""# of step in an epoch"")\nflags.DEFINE_integer(""test_step"", 100, ""# of step to test a model"")\nflags.DEFINE_integer(""save_step"", 1000, ""# of step to save a model"")\nflags.DEFINE_float(""learning_rate"", 1e-3, ""learning rate"")\nflags.DEFINE_float(""grad_clip"", 1, ""value of gradient to be used for clipping"")\nflags.DEFINE_boolean(""use_gpu"", True, ""whether to use gpu for training"")\n\n# data\nflags.DEFINE_string(""data"", ""mnist"", ""name of dataset [mnist, cifar]"")\nflags.DEFINE_string(""data_dir"", ""data"", ""name of data directory"")\nflags.DEFINE_string(""sample_dir"", ""samples"", ""name of sample directory"")\n\n# Debug\nflags.DEFINE_boolean(""is_train"", True, ""training or testing"")\nflags.DEFINE_boolean(""display"", False, ""whether to display the training results or not"")\nflags.DEFINE_string(""log_level"", ""INFO"", ""log level [DEBUG, INFO, WARNING, ERROR, CRITICAL]"")\nflags.DEFINE_integer(""random_seed"", 123, ""random seed for python"")\n\nconf = flags.FLAGS\n\n# logging\nlogger = logging.getLogger()\nlogger.setLevel(conf.log_level)\n\n# random seed\ntf.set_random_seed(conf.random_seed)\nnp.random.seed(conf.random_seed)\n\ndef main(_):\n  model_dir = get_model_dir(conf,\n      [\'data_dir\', \'sample_dir\', \'max_epoch\', \'test_step\', \'save_step\',\n       \'is_train\', \'random_seed\', \'log_level\', \'display\'])\n  preprocess_conf(conf)\n\n  DATA_DIR = os.path.join(conf.data_dir, conf.data)\n  SAMPLE_DIR = os.path.join(conf.sample_dir, conf.data, model_dir)\n\n  check_and_create_dir(DATA_DIR)\n  check_and_create_dir(SAMPLE_DIR)\n\n  # 0. prepare datasets\n  if conf.data == ""mnist"":\n    from tensorflow.examples.tutorials.mnist import input_data\n    mnist = input_data.read_data_sets(DATA_DIR, one_hot=True)\n\n    next_train_batch = lambda x: mnist.train.next_batch(x)[0]\n    next_test_batch = lambda x: mnist.test.next_batch(x)[0]\n\n    height, width, channel = 28, 28, 1\n\n    train_step_per_epoch = mnist.train.num_examples / conf.batch_size\n    test_step_per_epoch = mnist.test.num_examples / conf.batch_size\n  elif conf.data == ""cifar"":\n    from cifar10 import IMAGE_SIZE, inputs\n\n    maybe_download_and_extract(DATA_DIR)\n    images, labels = inputs(eval_data=False,\n        data_dir=os.path.join(DATA_DIR, \'cifar-10-batches-bin\'), batch_size=conf.batch_size)\n\n    height, width, channel = IMAGE_SIZE, IMAGE_SIZE, 3\n\n  with tf.Session() as sess:\n    network = Network(sess, conf, height, width, channel)\n\n    stat = Statistic(sess, conf.data, model_dir, tf.trainable_variables(), conf.test_step)\n    stat.load_model()\n\n    if conf.is_train:\n      logger.info(""Training starts!"")\n\n      initial_step = stat.get_t() if stat else 0\n      iterator = trange(conf.max_epoch, ncols=70, initial=initial_step)\n\n      for epoch in iterator:\n        # 1. train\n        total_train_costs = []\n        for idx in xrange(train_step_per_epoch):\n          images = binarize(next_train_batch(conf.batch_size)) \\\n            .reshape([conf.batch_size, height, width, channel])\n\n          cost = network.test(images, with_update=True)\n          total_train_costs.append(cost)\n\n        # 2. test\n        total_test_costs = []\n        for idx in xrange(test_step_per_epoch):\n          images = binarize(next_test_batch(conf.batch_size)) \\\n            .reshape([conf.batch_size, height, width, channel])\n\n          cost = network.test(images, with_update=False)\n          total_test_costs.append(cost)\n\n        avg_train_cost, avg_test_cost = np.mean(total_train_costs), np.mean(total_test_costs)\n\n        stat.on_step(avg_train_cost, avg_test_cost)\n\n        # 3. generate samples\n        samples = network.generate()\n        save_images(samples, height, width, 10, 10,\n            directory=SAMPLE_DIR, prefix=""epoch_%s"" % epoch)\n\n        iterator.set_description(""train l: %.3f, test l: %.3f"" % (avg_train_cost, avg_test_cost))\n        print\n    else:\n      logger.info(""Image generation starts!"")\n\n      samples = network.generate()\n      save_images(samples, height, width, 10, 10, directory=SAMPLE_DIR)\n\n\nif __name__ == ""__main__"":\n  tf.app.run()\n'"
network.py,24,"b'import tensorflow as tf\nfrom logging import getLogger\n\nfrom ops import *\nfrom utils import *\n\nlogger = getLogger(__name__)\n\nclass Network:\n  def __init__(self, sess, conf, height, width, channel):\n    logger.info(""Building %s starts!"" % conf.model)\n\n    self.sess = sess\n    self.data = conf.data\n    self.height, self.width, self.channel = height, width, channel\n\n    if conf.use_gpu:\n      data_format = ""NHWC""\n    else:\n      data_format = ""NCHW""\n\n    if data_format == ""NHWC"":\n      input_shape = [None, height, width, channel]\n    elif data_format == ""NCHW"":\n      input_shape = [None, channel, height, width]\n    else:\n      raise ValueError(""Unknown data_format: %s"" % data_format)\n\n    self.l = {}\n\n    self.l[\'inputs\'] = tf.placeholder(tf.float32, [None, height, width, channel],)\n\n    if conf.data ==\'mnist\':\n      self.l[\'normalized_inputs\'] = self.l[\'inputs\']\n    else:\n      self.l[\'normalized_inputs\'] = tf.div(self.l[\'inputs\'], 255., name=""normalized_inputs"")\n\n    # input of main reccurent layers\n    scope = ""conv_inputs""\n    logger.info(""Building %s"" % scope)\n\n    if conf.use_residual and conf.model == ""pixel_rnn"":\n      self.l[scope] = conv2d(self.l[\'normalized_inputs\'], conf.hidden_dims * 2, [7, 7], ""A"", scope=scope)\n    else:\n      self.l[scope] = conv2d(self.l[\'normalized_inputs\'], conf.hidden_dims, [7, 7], ""A"", scope=scope)\n\n    # main reccurent layers\n    l_hid = self.l[scope]\n    for idx in xrange(conf.recurrent_length):\n      if conf.model == ""pixel_rnn"":\n        scope = \'LSTM%d\' % idx\n        self.l[scope] = l_hid = diagonal_bilstm(l_hid, conf, scope=scope)\n      elif conf.model == ""pixel_cnn"":\n        scope = \'CONV%d\' % idx\n        self.l[scope] = l_hid = conv2d(l_hid, 3, [1, 1], ""B"", scope=scope)\n      else:\n        raise ValueError(""wrong type of model: %s"" % (conf.model))\n      logger.info(""Building %s"" % scope)\n\n    # output reccurent layers\n    for idx in xrange(conf.out_recurrent_length):\n      scope = \'CONV_OUT%d\' % idx\n      self.l[scope] = l_hid = tf.nn.relu(conv2d(l_hid, conf.out_hidden_dims, [1, 1], ""B"", scope=scope))\n      logger.info(""Building %s"" % scope)\n\n    if channel == 1:\n      self.l[\'conv2d_out_logits\'] = conv2d(l_hid, 1, [1, 1], ""B"", scope=\'conv2d_out_logits\')\n      self.l[\'output\'] = tf.nn.sigmoid(self.l[\'conv2d_out_logits\'])\n\n      logger.info(""Building loss and optims"")\n      # FIXED pre-1.0\n      # self.loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n      #     self.l[\'conv2d_out_logits\'], self.l[\'normalized_inputs\'], name=\'loss\'))\n      self.loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n          logits=self.l[\'conv2d_out_logits\'], labels=self.l[\'normalized_inputs\'], name=\'loss\'))\n    else:\n      raise ValueError(""Implementation in progress for RGB colors"")\n\n      COLOR_DIM = 256\n\n      self.l[\'conv2d_out_logits\'] = conv2d(l_hid, COLOR_DIM, [1, 1], ""B"", scope=\'conv2d_out_logits\')\n\n      self.l[\'conv2d_out_logits_flat\'] = tf.reshape(\n          self.l[\'conv2d_out_logits\'], [-1, self.height * self.width, COLOR_DIM])\n      self.l[\'normalized_inputs_flat\'] = tf.reshape(\n          self.l[\'normalized_inputs\'], [-1, self.height * self.width, COLOR_DIM])\n\n      # FIXED pre-1.0 # pred_pixels = [tf.squeeze(pixel, squeeze_dims=[1])\n      pred_pixels = [tf.squeeze(pixel, axis=[1])\n          # FIXED pre-1.0 # for pixel in tf.split(1, self.height * self.width, self.l[\'conv2d_out_logits_flat\'])]\n          for pixel in tf.split(self.l[\'conv2d_out_logits_flat\'], self.height * self.width, 1)]\n      # FIXED pre-1.0 # target_pixels = [tf.squeeze(pixel, squeeze_dims=[1])\n      target_pixels = [tf.squeeze(pixel, axis=[1])\n          # FIXED pre-1.0 # for pixel in tf.split(1, self.height * self.width, self.l[\'normalized_inputs_flat\'])]\n          for pixel in tf.split(self.l[\'normalized_inputs_flat\'], self.height * self.width, 1)]\n\n      softmaxed_pixels = [tf.nn.softmax(pixel) for pixel in pred_pixels]\n\n      losses = [tf.nn.sampled_softmax_loss(\n          pred_pixel, tf.zeros_like(pred_pixel), pred_pixel, target_pixel, 1, COLOR_DIM) \\\n              for pred_pixel, target_pixel in zip(pred_pixels, target_pixels)]\n\n      self.l[\'output\'] = tf.nn.softmax(self.l[\'conv2d_out_logits\'])\n\n      logger.info(""Building loss and optims"")\n      # FIXED pre-1.0\n      # self.loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n      #     self.l[\'conv2d_out_logits\'], self.l[\'normalized_inputs\'], name=\'loss\'))\n      self.loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n          logits=self.l[\'conv2d_out_logits\'], labels=self.l[\'normalized_inputs\'], name=\'loss\'))\n\n    optimizer = tf.train.RMSPropOptimizer(conf.learning_rate)\n    grads_and_vars = optimizer.compute_gradients(self.loss)\n\n    new_grads_and_vars = \\\n        [(tf.clip_by_value(gv[0], -conf.grad_clip, conf.grad_clip), gv[1]) for gv in grads_and_vars]\n    self.optim = optimizer.apply_gradients(new_grads_and_vars)\n\n    show_all_variables()\n\n    logger.info(""Building %s finished!"" % conf.model)\n\n  def predict(self, images):\n    return self.sess.run(self.l[\'output\'], {self.l[\'inputs\']: images})\n\n  def test(self, images, with_update=False):\n    if with_update:\n      _, cost = self.sess.run([\n          self.optim, self.loss,\n        ], feed_dict={ self.l[\'inputs\']: images })\n    else:\n      cost = self.sess.run(self.loss, feed_dict={ self.l[\'inputs\']: images })\n    return cost\n\n  def generate(self):\n    samples = np.zeros((100, self.height, self.width, 1), dtype=\'float32\')\n\n    for i in xrange(self.height):\n      for j in xrange(self.width):\n        for k in xrange(self.channel):\n          next_sample = binarize(self.predict(samples))\n          samples[:, i, j, k] = next_sample[:, i, j, k]\n\n          if self.data == \'mnist\':\n            print ""="" * (self.width/2), ""(%2d, %2d)"" % (i, j), ""="" * (self.width/2)\n            mprint(next_sample[0,:,:,:])\n\n    return samples\n'"
ops.py,94,"b'import logging\nlogging.basicConfig(format=""[%(asctime)s] %(message)s"", datefmt=""%m-%d %H:%M:%S"")\n\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.python.ops import rnn_cell\nfrom tensorflow.examples.tutorials.mnist import input_data\nfrom tensorflow.contrib.layers import variance_scaling_initializer\n\nWEIGHT_INITIALIZER = tf.contrib.layers.xavier_initializer()\n#WEIGHT_INITIALIZER = tf.uniform_unit_scaling_initializer()\n\nlogger = logging.getLogger(__name__)\n\nhe_uniform = variance_scaling_initializer(factor=2.0, mode=""FAN_IN"", uniform=False)\ndata_format = ""NCHW""\n\ndef get_shape(layer):\n  return layer.get_shape().as_list()\n\n#def get_shape(layer):\n#  if data_format == ""NHWC"":\n#    batch, height, width, channel = layer.get_shape().as_list()\n#  elif data_format == ""NCHW"":\n#    batch, channel, height, width = layer.get_shape().as_list()\n#  else:\n#    raise ValueError(""Unknown data_format: %s"" % data_format)\n#  return batch, height, width, channel\n\ndef skew(inputs, scope=""skew""):\n  with tf.name_scope(scope):\n    batch, height, width, channel = get_shape(inputs) # [batch, height, width, channel]\n    # FIXED pre-1.0 # rows = tf.split(1, height, inputs) # [batch, 1, width, channel]\n    rows = tf.split(inputs, height, 1) # [batch, 1, width, channel]\n\n    new_width = width + height - 1\n    new_rows = []\n\n    for idx, row in enumerate(rows):\n      transposed_row = tf.transpose(tf.squeeze(row, [1]), [0, 2, 1]) # [batch, channel, width]\n      squeezed_row = tf.reshape(transposed_row, [-1, width]) # [batch*channel, width]\n      padded_row = tf.pad(squeezed_row, ((0, 0), (idx, height - 1 - idx))) # [batch*channel, width*2-1]\n\n      unsqueezed_row = tf.reshape(padded_row, [-1, channel, new_width]) # [batch, channel, width*2-1]\n      untransposed_row = tf.transpose(unsqueezed_row, [0, 2, 1]) # [batch, width*2-1, channel]\n\n      assert get_shape(untransposed_row) == [batch, new_width, channel], ""wrong shape of skewed row""\n      new_rows.append(untransposed_row)\n\n    # FIXED pre-1.0 # outputs = tf.pack(new_rows, axis=1, name=""output"")\n    outputs = tf.stack(new_rows, axis=1, name=""output"")\n    assert get_shape(outputs) == [None, height, new_width, channel], ""wrong shape of skewed output""\n\n  logger.debug(\'[skew] %s : %s %s -> %s %s\' \\\n      % (scope, inputs.name, inputs.get_shape(), outputs.name, outputs.get_shape()))\n  return outputs\n\ndef unskew(inputs, width=None, scope=""unskew""):\n  with tf.name_scope(scope):\n    batch, height, skewed_width, channel = get_shape(inputs)\n    width = width if width else height\n\n    new_rows = []\n    # FIXED pre-1.0 # rows = tf.split(1, height, inputs)\n    rows = tf.split(inputs, height, 1)\n\n    for idx, row in enumerate(rows):\n      new_rows.append(tf.slice(row, [0, 0, idx, 0], [-1, -1, width, -1]))\n    # FIXED pre-1.0 # outputs = tf.concat(1, new_rows, name=""output"")\n    outputs = tf.concat(new_rows, 1, name=""output"")\n\n  logger.debug(\'[unskew] %s : %s %s -> %s %s\' \\\n      % (scope, inputs.name, inputs.get_shape(), outputs.name, outputs.get_shape()))\n  return outputs\n\ndef conv2d(\n    inputs,\n    num_outputs,\n    kernel_shape, # [kernel_height, kernel_width]\n    mask_type, # None, ""A"" or ""B"",\n    strides=[1, 1], # [column_wise_stride, row_wise_stride]\n    padding=""SAME"",\n    activation_fn=None,\n    weights_initializer=WEIGHT_INITIALIZER,\n    weights_regularizer=None,\n    # FIXED pre-1.0 # biases_initializer=tf.zeros_initializer,\n    biases_initializer=tf.zeros_initializer(),\n    biases_regularizer=None,\n    scope=""conv2d""):\n  with tf.variable_scope(scope):\n    mask_type = mask_type.lower()\n    batch_size, height, width, channel = inputs.get_shape().as_list()\n\n    kernel_h, kernel_w = kernel_shape\n    stride_h, stride_w = strides\n\n    assert kernel_h % 2 == 1 and kernel_w % 2 == 1, \\\n      ""kernel height and width should be odd number""\n\n    center_h = kernel_h // 2\n    center_w = kernel_w // 2\n\n    weights_shape = [kernel_h, kernel_w, channel, num_outputs]\n    weights = tf.get_variable(""weights"", weights_shape,\n      tf.float32, weights_initializer, weights_regularizer)\n\n    if mask_type is not None:\n      mask = np.ones(\n        (kernel_h, kernel_w, channel, num_outputs), dtype=np.float32)\n\n      mask[center_h, center_w+1: ,: ,:] = 0.\n      mask[center_h+1:, :, :, :] = 0.\n\n      if mask_type == \'a\':\n        mask[center_h,center_w,:,:] = 0.\n\n      weights *= tf.constant(mask, dtype=tf.float32)\n      tf.add_to_collection(\'conv2d_weights_%s\' % mask_type, weights)\n\n    outputs = tf.nn.conv2d(inputs,\n        weights, [1, stride_h, stride_w, 1], padding=padding, name=\'outputs\')\n    tf.add_to_collection(\'conv2d_outputs\', outputs)\n\n    if biases_initializer != None:\n      biases = tf.get_variable(""biases"", [num_outputs,],\n          tf.float32, biases_initializer, biases_regularizer)\n      outputs = tf.nn.bias_add(outputs, biases, name=\'outputs_plus_b\')\n\n    if activation_fn:\n      outputs = activation_fn(outputs, name=\'outputs_with_fn\')\n\n    logger.debug(\'[conv2d_%s] %s : %s %s -> %s %s\' \\\n        % (mask_type, scope, inputs.name, inputs.get_shape(), outputs.name, outputs.get_shape()))\n\n    return outputs\n\ndef conv1d(\n    inputs,\n    num_outputs,\n    kernel_size,\n    strides=[1, 1], # [column_wise_stride, row_wise_stride]\n    padding=""SAME"",\n    activation_fn=None,\n    weights_initializer=WEIGHT_INITIALIZER,\n    weights_regularizer=None,\n    # FIXED pre-1.0 # biases_initializer=tf.zeros_initializer,\n    biases_initializer=tf.zeros_initializer(),\n    biases_regularizer=None,\n    scope=""conv1d""):\n  with tf.variable_scope(scope):\n    batch_size, height, _, channel = inputs.get_shape().as_list() # [batch, height, 1, channel]\n\n    kernel_h, kernel_w = kernel_size, 1\n    stride_h, stride_w = strides\n\n    weights_shape = [kernel_h, kernel_w, channel, num_outputs]\n    weights = tf.get_variable(""weights"", weights_shape,\n      tf.float32, weights_initializer, weights_regularizer)\n    tf.add_to_collection(\'conv1d_weights\', weights)\n\n    outputs = tf.nn.conv2d(inputs,\n        weights, [1, stride_h, stride_w, 1], padding=padding, name=\'outputs\')\n    tf.add_to_collection(\'conv1d_outputs\', weights)\n\n    if biases_initializer != None:\n      biases = tf.get_variable(""biases"", [num_outputs,],\n          tf.float32, biases_initializer, biases_regularizer)\n      outputs = tf.nn.bias_add(outputs, biases, name=\'outputs_plus_b\')\n\n    if activation_fn:\n      outputs = activation_fn(outputs, name=\'outputs_with_fn\')\n\n    logger.debug(\'[conv1d] %s : %s %s -> %s %s\' \\\n        % (scope, inputs.name, inputs.get_shape(), outputs.name, outputs.get_shape()))\n\n    return outputs\n\ndef diagonal_bilstm(inputs, conf, scope=\'diagonal_bilstm\'):\n  with tf.variable_scope(scope):\n    def reverse(inputs):\n      # FIXED pre-1.0 # return tf.reverse(inputs, [False, False, True, False])\n      return tf.reverse(inputs, [2]) # [False, False, True, False])\n\n    output_state_fw = diagonal_lstm(inputs, conf, scope=\'output_state_fw\')\n    output_state_bw = reverse(diagonal_lstm(reverse(inputs), conf, scope=\'output_state_bw\'))\n\n    tf.add_to_collection(\'output_state_fw\', output_state_fw)\n    tf.add_to_collection(\'output_state_bw\', output_state_bw)\n\n    if conf.use_residual:\n      residual_state_fw = conv2d(output_state_fw, conf.hidden_dims * 2, [1, 1], ""B"", scope=""residual_fw"")\n      output_state_fw = residual_state_fw + inputs\n\n      residual_state_bw = conv2d(output_state_bw, conf.hidden_dims * 2, [1, 1], ""B"", scope=""residual_bw"")\n      output_state_bw = residual_state_bw + inputs\n\n      tf.add_to_collection(\'residual_state_fw\', residual_state_fw)\n      tf.add_to_collection(\'residual_state_bw\', residual_state_bw)\n      tf.add_to_collection(\'residual_output_state_fw\', output_state_fw)\n      tf.add_to_collection(\'residual_output_state_bw\', output_state_bw)\n\n    batch, height, width, channel = get_shape(output_state_bw)\n\n    output_state_bw_except_last = tf.slice(output_state_bw, [0, 0, 0, 0], [-1, height-1, -1, -1])\n    output_state_bw_only_last = tf.slice(output_state_bw, [0, height-1, 0, 0], [-1, 1, -1, -1])\n    dummy_zeros = tf.zeros_like(output_state_bw_only_last)\n\n    # FIXED pre-1.0 # output_state_bw_with_last_zeros = tf.concat(1, [output_state_bw_except_last, dummy_zeros])\n    output_state_bw_with_last_zeros = tf.concat([output_state_bw_except_last, dummy_zeros], 1)\n\n    tf.add_to_collection(\'output_state_bw_with_last_zeros\', output_state_bw_with_last_zeros)\n\n    return output_state_fw + output_state_bw_with_last_zeros\n\ndef diagonal_lstm(inputs, conf, scope=\'diagonal_lstm\'):\n  with tf.variable_scope(scope):\n    tf.add_to_collection(\'lstm_inputs\', inputs)\n\n    skewed_inputs = skew(inputs, scope=""skewed_i"")\n    tf.add_to_collection(\'skewed_lstm_inputs\', skewed_inputs)\n\n    # input-to-state (K_is * x_i) : 1x1 convolution. generate 4h x n x n tensor.\n    input_to_state = conv2d(skewed_inputs, conf.hidden_dims * 4, [1, 1], ""B"", scope=""i_to_s"")\n    column_wise_inputs = tf.transpose(\n        input_to_state, [0, 2, 1, 3]) # [batch, width, height, hidden_dims * 4]\n\n    tf.add_to_collection(\'skewed_conv_inputs\', input_to_state)\n    tf.add_to_collection(\'column_wise_inputs\', column_wise_inputs)\n\n    batch, width, height, channel = get_shape(column_wise_inputs)\n    rnn_inputs = tf.reshape(column_wise_inputs,\n        [-1, width, height * channel]) # [batch, max_time, height * hidden_dims * 4]\n\n    tf.add_to_collection(\'rnn_inputs\', rnn_inputs)\n\n    # FIXED pre-1.0 # rnn_input_list = [tf.squeeze(rnn_input, squeeze_dims=[1])\n    rnn_input_list = [tf.squeeze(rnn_input, axis=[1])\n        # FIXED pre-1.0 # for rnn_input in tf.split(split_dim=1, num_split=width, value=rnn_inputs)]\n        for rnn_input in tf.split(rnn_inputs, width, 1)]\n\n    cell = DiagonalLSTMCell(conf.hidden_dims, height, channel)\n\n    # if conf.use_dynamic_rnn:\n    if True:\n      # XXX FIXME: sequence_length ?\n      outputs, states = tf.nn.dynamic_rnn(cell,\n          inputs=rnn_inputs, dtype=tf.float32) # [batch, width, height * hidden_dims]\n      packed_outputs = outputs # dynaic_rnn(), [batch, width, height * hidden_dims]\n\n    # else:\n    #   output_list, state_list = tf.nn.rnn(cell,\n    #       inputs=rnn_input_list, dtype=tf.float32) # width * [batch, height * hidden_dims]\n\n    #     # FIXED pre-1.0 # packed_outputs = tf.pack(output_list, 1) # [batch, width, height * hidden_dims]\n    #     packed_outputs = tf.stack(output_list, 1) # [batch, width, height * hidden_dims]\n\n    width_first_outputs = tf.reshape(packed_outputs,\n        [-1, width, height, conf.hidden_dims]) # [batch, width, height, hidden_dims]\n\n    skewed_outputs = tf.transpose(width_first_outputs, [0, 2, 1, 3])\n    tf.add_to_collection(\'skewed_outputs\', skewed_outputs)\n\n    outputs = unskew(skewed_outputs)\n    tf.add_to_collection(\'unskewed_outputs\', outputs)\n\n    return outputs\n\nclass DiagonalLSTMCell(rnn_cell.RNNCell):\n  def __init__(self, hidden_dims, height, channel):\n    self._num_unit_shards = 1\n    self._forget_bias = 1.\n\n    self._height = height\n    self._channel = channel\n\n    self._hidden_dims = hidden_dims\n    self._num_units = self._hidden_dims * self._height\n    self._state_size = self._num_units * 2\n    self._output_size = self._num_units\n\n  @property\n  def state_size(self):\n    return self._state_size\n\n  @property\n  def output_size(self):\n    return self._output_size\n\n  def __call__(self, i_to_s, state, scope=""DiagonalBiLSTMCell""):\n    c_prev = tf.slice(state, [0, 0], [-1, self._num_units])\n    h_prev = tf.slice(state, [0, self._num_units], [-1, self._num_units]) # [batch, height * hidden_dims]\n\n    # i_to_s : [batch, 4 * height * hidden_dims]\n    input_size = i_to_s.get_shape().with_rank(2)[1]\n\n    if input_size.value is None:\n      raise ValueError(""Could not infer input size from inputs.get_shape()[-1]"")\n\n    with tf.variable_scope(scope):\n      # input-to-state (K_ss * h_{i-1}) : 2x1 convolution. generate 4h x n x n tensor.\n      conv1d_inputs = tf.reshape(h_prev,\n          [-1, self._height, 1, self._hidden_dims], name=\'conv1d_inputs\') # [batch, height, 1, hidden_dims]\n\n      tf.add_to_collection(\'i_to_s\', i_to_s)\n      tf.add_to_collection(\'conv1d_inputs\', conv1d_inputs)\n\n      conv_s_to_s = conv1d(conv1d_inputs,\n          4 * self._hidden_dims, 2, scope=\'s_to_s\') # [batch, height, 1, hidden_dims * 4]\n      s_to_s = tf.reshape(conv_s_to_s,\n          [-1, self._height * self._hidden_dims * 4]) # [batch, height * hidden_dims * 4]\n\n      tf.add_to_collection(\'conv_s_to_s\', conv_s_to_s)\n      tf.add_to_collection(\'s_to_s\', s_to_s)\n\n      lstm_matrix = tf.sigmoid(s_to_s + i_to_s)\n\n      # i = input_gate, g = new_input, f = forget_gate, o = output_gate\n      # FIXED pre-1.0 # i, g, f, o = tf.split(1, 4, lstm_matrix)\n      i, g, f, o = tf.split(lstm_matrix, 4, 1)\n\n      c = f * c_prev + i * g\n      # FIXED pre-1.0 # h = tf.mul(o, tf.tanh(c), name=\'hid\')\n      h = tf.multiply(o, tf.tanh(c), name=\'hid\')\n\n    logger.debug(\'[DiagonalLSTMCell] %s : %s %s -> %s %s\' \\\n        % (scope, i_to_s.name, i_to_s.get_shape(), h.name, h.get_shape()))\n\n    # FIXED pre-1.0 # new_state = tf.concat(1, [c, h])\n    new_state = tf.concat([c, h], 1)\n    return h, new_state\n\nclass RowLSTMCell(rnn_cell.RNNCell):\n  def __init__(self, num_units, kernel_shape=[3, 1]):\n    self._num_units = num_units\n    self._state_size = num_units * 2\n    self._output_size = num_units\n    self._kernel_shape = kernel_shape\n\n  @property\n  def state_size(self):\n    return self._state_size\n\n  @property\n  def output_size(self):\n    return self._output_size\n\n  def __call__(self, inputs, state, scope=""RowLSTMCell""):\n    raise Exception(""Not implemented"")\n'"
statistic.py,12,"b'import os\nimport numpy as np\nimport tensorflow as tf\nfrom logging import getLogger\n\nlogger = getLogger(__name__)\n\nclass Statistic(object):\n  def __init__(self, sess, data, model_dir, variables, test_step, max_to_keep=20):\n    self.sess = sess\n    self.test_step = test_step\n    self.reset()\n\n    with tf.variable_scope(\'t\'):\n      self.t_op = tf.Variable(0, trainable=False, name=\'t\')\n      self.t_add_op = self.t_op.assign_add(1)\n\n    self.model_dir = model_dir\n    self.saver = tf.train.Saver(variables + [self.t_op], max_to_keep=max_to_keep)\n    # FIXED pre-1.0 # self.writer = tf.train.SummaryWriter(\'./logs/%s\' % self.model_dir, self.sess.graph)\n    self.writer = tf.summary.FileWriter(\'./logs/%s\' % self.model_dir, self.sess.graph)\n\n    with tf.variable_scope(\'summary\'):\n      scalar_summary_tags = [\'train_l\', \'test_l\']\n\n      self.summary_placeholders = {}\n      self.summary_ops = {}\n\n      for tag in scalar_summary_tags:\n        self.summary_placeholders[tag] = tf.placeholder(\'float32\', None, name=tag.replace(\' \', \'_\'))\n        # FIXED pre-1.0 # self.summary_ops[tag]  = tf.scalar_summary(\'%s/%s\' % (data, tag), self.summary_placeholders[tag])\n        self.summary_ops[tag]  = tf.summary.scalar(\'%s/%s\' % (data, tag), self.summary_placeholders[tag])\n\n  def reset(self):\n    pass\n\n  def on_step(self, train_l, test_l):\n    self.t = self.t_add_op.eval(session=self.sess)\n\n    self.inject_summary({\'train_l\': train_l, \'test_l\': test_l}, self.t)\n\n    self.save_model(self.t)\n    self.reset()\n\n  def get_t(self):\n    return self.t_op.eval(session=self.sess)\n\n  def inject_summary(self, tag_dict, t):\n    summary_str_lists = self.sess.run([self.summary_ops[tag] for tag in tag_dict.keys()], {\n      self.summary_placeholders[tag]: value for tag, value in tag_dict.items()\n    })\n    for summary_str in summary_str_lists:\n      self.writer.add_summary(summary_str, t)\n\n  def save_model(self, t):\n    logger.info(""Saving checkpoints..."")\n    model_name = type(self).__name__\n\n    if not os.path.exists(self.model_dir):\n      os.makedirs(self.model_dir)\n    self.saver.save(self.sess, self.model_dir, global_step=t)\n\n  def load_model(self):\n    logger.info(""Initializing all variables"")\n    # FIXED pre-1.0 # tf.initialize_all_variables().run()\n    tf.global_variables_initializer().run()\n\n    logger.info(""Loading checkpoints..."")\n    ckpt = tf.train.get_checkpoint_state(self.model_dir)\n    if ckpt and ckpt.model_checkpoint_path:\n      ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n      fname = os.path.join(self.model_dir, ckpt_name)\n      self.saver.restore(self.sess, fname)\n      logger.info(""Load SUCCESS: %s"" % fname)\n    else:\n      logger.info(""Load FAILED: %s"" % self.model_dir)\n\n    self.t = self.t_add_op.eval(session=self.sess)\n'"
utils.py,1,"b'import logging\nlogging.basicConfig(format=""[%(asctime)s] %(message)s"", datefmt=""%m-%d %H:%M:%S"")\n\nimport os\nimport sys\nimport urllib\nimport pprint\nimport tarfile\nimport tensorflow as tf\n\nimport datetime\nimport dateutil.tz\nimport numpy as np\n\nimport scipy.misc\n\npp = pprint.PrettyPrinter().pprint\nlogger = logging.getLogger(__name__)\n\ndef mprint(matrix, pivot=0.5):\n  for array in matrix:\n    print """".join(""#"" if i > pivot else "" "" for i in array)\n\ndef show_all_variables():\n  total_count = 0\n  for idx, op in enumerate(tf.trainable_variables()):\n    shape = op.get_shape()\n    count = np.prod(shape)\n    print ""[%2d] %s %s = %s"" % (idx, op.name, shape, count)\n    total_count += int(count)\n  print ""[Total] variable size: %s"" % ""{:,}"".format(total_count)\n\ndef get_timestamp():\n  now = datetime.datetime.now(dateutil.tz.tzlocal())\n  return now.strftime(\'%Y_%m_%d_%H_%M_%S\')\n\ndef binarize(images):\n  return (np.random.uniform(size=images.shape) < images).astype(\'float32\')\n\ndef save_images(images, height, width, n_row, n_col, \n      cmin=0.0, cmax=1.0, directory=""./"", prefix=""sample""):\n  images = images.reshape((n_row, n_col, height, width))\n  images = images.transpose(1, 2, 0, 3)\n  images = images.reshape((height * n_row, width * n_col))\n\n  filename = \'%s_%s.jpg\' % (prefix, get_timestamp())\n  scipy.misc.toimage(images, cmin=cmin, cmax=cmax) \\\n      .save(os.path.join(directory, filename))\n\ndef get_model_dir(config, exceptions=None):\n  attrs = config.__dict__[\'__flags\']\n  pp(attrs)\n\n  keys = attrs.keys()\n  keys.sort()\n  keys.remove(\'data\')\n  keys = [\'data\'] + keys\n\n  names =[]\n  for key in keys:\n    # Only use useful flags\n    if key not in exceptions:\n      names.append(""%s=%s"" % (key, "","".join([str(i) for i in attrs[key]])\n          if type(attrs[key]) == list else attrs[key]))\n  return os.path.join(\'checkpoints\', *names) + \'/\'\n\ndef preprocess_conf(conf):\n  options = conf.__flags\n\n  for option, value in options.items():\n    option = option.lower()\n\ndef check_and_create_dir(directory):\n  if not os.path.exists(directory):\n    logger.info(\'Creating directory: %s\' % directory)\n    os.makedirs(directory)\n  else:\n    logger.info(\'Skip creating directory: %s\' % directory)\n\ndef maybe_download_and_extract(dest_directory):\n  """"""\n  Download and extract the tarball from Alex\'s website.\n  From https://github.com/tensorflow/tensorflow/blob/r0.9/tensorflow/models/image/cifar10/cifar10.py\n  """"""\n  DATA_URL = \'http://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz\'\n\n  if not os.path.exists(dest_directory):\n    os.makedirs(dest_directory)\n\n  filename = DATA_URL.split(\'/\')[-1]\n  filepath = os.path.join(dest_directory, filename)\n\n  if not os.path.exists(filepath):\n    def _progress(count, block_size, total_size):\n      sys.stdout.write(\'\\r>> Downloading %s %.1f%%\' % (filename,\n          float(count * block_size) / float(total_size) * 100.0))\n      sys.stdout.flush()\n    filepath, _ = urllib.urlretrieve(DATA_URL, filepath, _progress)\n    print()\n    statinfo = os.stat(filepath)\n    print(\'Successfully downloaded\', filename, statinfo.st_size, \'bytes.\')\n    tarfile.open(filepath, \'r:gz\').extractall(dest_directory)\n'"
