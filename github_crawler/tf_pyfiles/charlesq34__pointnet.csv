file_path,api_count,code
evaluate.py,6,"b'import tensorflow as tf\nimport numpy as np\nimport argparse\nimport socket\nimport importlib\nimport time\nimport os\nimport scipy.misc\nimport sys\nBASE_DIR = os.path.dirname(os.path.abspath(__file__))\nsys.path.append(BASE_DIR)\nsys.path.append(os.path.join(BASE_DIR, \'models\'))\nsys.path.append(os.path.join(BASE_DIR, \'utils\'))\nimport provider\nimport pc_util\n\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\'--gpu\', type=int, default=0, help=\'GPU to use [default: GPU 0]\')\nparser.add_argument(\'--model\', default=\'pointnet_cls\', help=\'Model name: pointnet_cls or pointnet_cls_basic [default: pointnet_cls]\')\nparser.add_argument(\'--batch_size\', type=int, default=4, help=\'Batch Size during training [default: 1]\')\nparser.add_argument(\'--num_point\', type=int, default=1024, help=\'Point Number [256/512/1024/2048] [default: 1024]\')\nparser.add_argument(\'--model_path\', default=\'log/model.ckpt\', help=\'model checkpoint file path [default: log/model.ckpt]\')\nparser.add_argument(\'--dump_dir\', default=\'dump\', help=\'dump folder path [dump]\')\nparser.add_argument(\'--visu\', action=\'store_true\', help=\'Whether to dump image for error case [default: False]\')\nFLAGS = parser.parse_args()\n\n\nBATCH_SIZE = FLAGS.batch_size\nNUM_POINT = FLAGS.num_point\nMODEL_PATH = FLAGS.model_path\nGPU_INDEX = FLAGS.gpu\nMODEL = importlib.import_module(FLAGS.model) # import network module\nDUMP_DIR = FLAGS.dump_dir\nif not os.path.exists(DUMP_DIR): os.mkdir(DUMP_DIR)\nLOG_FOUT = open(os.path.join(DUMP_DIR, \'log_evaluate.txt\'), \'w\')\nLOG_FOUT.write(str(FLAGS)+\'\\n\')\n\nNUM_CLASSES = 40\nSHAPE_NAMES = [line.rstrip() for line in \\\n    open(os.path.join(BASE_DIR, \'data/modelnet40_ply_hdf5_2048/shape_names.txt\'))] \n\nHOSTNAME = socket.gethostname()\n\n# ModelNet40 official train/test split\nTRAIN_FILES = provider.getDataFiles( \\\n    os.path.join(BASE_DIR, \'data/modelnet40_ply_hdf5_2048/train_files.txt\'))\nTEST_FILES = provider.getDataFiles(\\\n    os.path.join(BASE_DIR, \'data/modelnet40_ply_hdf5_2048/test_files.txt\'))\n\ndef log_string(out_str):\n    LOG_FOUT.write(out_str+\'\\n\')\n    LOG_FOUT.flush()\n    print(out_str)\n\ndef evaluate(num_votes):\n    is_training = False\n     \n    with tf.device(\'/gpu:\'+str(GPU_INDEX)):\n        pointclouds_pl, labels_pl = MODEL.placeholder_inputs(BATCH_SIZE, NUM_POINT)\n        is_training_pl = tf.placeholder(tf.bool, shape=())\n\n        # simple model\n        pred, end_points = MODEL.get_model(pointclouds_pl, is_training_pl)\n        loss = MODEL.get_loss(pred, labels_pl, end_points)\n        \n        # Add ops to save and restore all the variables.\n        saver = tf.train.Saver()\n        \n    # Create a session\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    config.allow_soft_placement = True\n    config.log_device_placement = True\n    sess = tf.Session(config=config)\n\n    # Restore variables from disk.\n    saver.restore(sess, MODEL_PATH)\n    log_string(""Model restored."")\n\n    ops = {\'pointclouds_pl\': pointclouds_pl,\n           \'labels_pl\': labels_pl,\n           \'is_training_pl\': is_training_pl,\n           \'pred\': pred,\n           \'loss\': loss}\n\n    eval_one_epoch(sess, ops, num_votes)\n\n   \ndef eval_one_epoch(sess, ops, num_votes=1, topk=1):\n    error_cnt = 0\n    is_training = False\n    total_correct = 0\n    total_seen = 0\n    loss_sum = 0\n    total_seen_class = [0 for _ in range(NUM_CLASSES)]\n    total_correct_class = [0 for _ in range(NUM_CLASSES)]\n    fout = open(os.path.join(DUMP_DIR, \'pred_label.txt\'), \'w\')\n    for fn in range(len(TEST_FILES)):\n        log_string(\'----\'+str(fn)+\'----\')\n        current_data, current_label = provider.loadDataFile(TEST_FILES[fn])\n        current_data = current_data[:,0:NUM_POINT,:]\n        current_label = np.squeeze(current_label)\n        print(current_data.shape)\n        \n        file_size = current_data.shape[0]\n        num_batches = file_size // BATCH_SIZE\n        print(file_size)\n        \n        for batch_idx in range(num_batches):\n            start_idx = batch_idx * BATCH_SIZE\n            end_idx = (batch_idx+1) * BATCH_SIZE\n            cur_batch_size = end_idx - start_idx\n            \n            # Aggregating BEG\n            batch_loss_sum = 0 # sum of losses for the batch\n            batch_pred_sum = np.zeros((cur_batch_size, NUM_CLASSES)) # score for classes\n            batch_pred_classes = np.zeros((cur_batch_size, NUM_CLASSES)) # 0/1 for classes\n            for vote_idx in range(num_votes):\n                rotated_data = provider.rotate_point_cloud_by_angle(current_data[start_idx:end_idx, :, :],\n                                                  vote_idx/float(num_votes) * np.pi * 2)\n                feed_dict = {ops[\'pointclouds_pl\']: rotated_data,\n                             ops[\'labels_pl\']: current_label[start_idx:end_idx],\n                             ops[\'is_training_pl\']: is_training}\n                loss_val, pred_val = sess.run([ops[\'loss\'], ops[\'pred\']],\n                                          feed_dict=feed_dict)\n                batch_pred_sum += pred_val\n                batch_pred_val = np.argmax(pred_val, 1)\n                for el_idx in range(cur_batch_size):\n                    batch_pred_classes[el_idx, batch_pred_val[el_idx]] += 1\n                batch_loss_sum += (loss_val * cur_batch_size / float(num_votes))\n            # pred_val_topk = np.argsort(batch_pred_sum, axis=-1)[:,-1*np.array(range(topk))-1]\n            # pred_val = np.argmax(batch_pred_classes, 1)\n            pred_val = np.argmax(batch_pred_sum, 1)\n            # Aggregating END\n            \n            correct = np.sum(pred_val == current_label[start_idx:end_idx])\n            # correct = np.sum(pred_val_topk[:,0:topk] == label_val)\n            total_correct += correct\n            total_seen += cur_batch_size\n            loss_sum += batch_loss_sum\n\n            for i in range(start_idx, end_idx):\n                l = current_label[i]\n                total_seen_class[l] += 1\n                total_correct_class[l] += (pred_val[i-start_idx] == l)\n                fout.write(\'%d, %d\\n\' % (pred_val[i-start_idx], l))\n                \n                if pred_val[i-start_idx] != l and FLAGS.visu: # ERROR CASE, DUMP!\n                    img_filename = \'%d_label_%s_pred_%s.jpg\' % (error_cnt, SHAPE_NAMES[l],\n                                                           SHAPE_NAMES[pred_val[i-start_idx]])\n                    img_filename = os.path.join(DUMP_DIR, img_filename)\n                    output_img = pc_util.point_cloud_three_views(np.squeeze(current_data[i, :, :]))\n                    scipy.misc.imsave(img_filename, output_img)\n                    error_cnt += 1\n                \n    log_string(\'eval mean loss: %f\' % (loss_sum / float(total_seen)))\n    log_string(\'eval accuracy: %f\' % (total_correct / float(total_seen)))\n    log_string(\'eval avg class acc: %f\' % (np.mean(np.array(total_correct_class)/np.array(total_seen_class,dtype=np.float))))\n    \n    class_accuracies = np.array(total_correct_class)/np.array(total_seen_class,dtype=np.float)\n    for i, name in enumerate(SHAPE_NAMES):\n        log_string(\'%10s:\\t%0.3f\' % (name, class_accuracies[i]))\n    \n\n\nif __name__==\'__main__\':\n    with tf.Graph().as_default():\n        evaluate(num_votes=1)\n    LOG_FOUT.close()\n'"
provider.py,0,"b'import os\nimport sys\nimport numpy as np\nimport h5py\nBASE_DIR = os.path.dirname(os.path.abspath(__file__))\nsys.path.append(BASE_DIR)\n\n# Download dataset for point cloud classification\nDATA_DIR = os.path.join(BASE_DIR, \'data\')\nif not os.path.exists(DATA_DIR):\n    os.mkdir(DATA_DIR)\nif not os.path.exists(os.path.join(DATA_DIR, \'modelnet40_ply_hdf5_2048\')):\n    www = \'https://shapenet.cs.stanford.edu/media/modelnet40_ply_hdf5_2048.zip\'\n    zipfile = os.path.basename(www)\n    os.system(\'wget %s; unzip %s\' % (www, zipfile))\n    os.system(\'mv %s %s\' % (zipfile[:-4], DATA_DIR))\n    os.system(\'rm %s\' % (zipfile))\n\n\ndef shuffle_data(data, labels):\n    """""" Shuffle data and labels.\n        Input:\n          data: B,N,... numpy array\n          label: B,... numpy array\n        Return:\n          shuffled data, label and shuffle indices\n    """"""\n    idx = np.arange(len(labels))\n    np.random.shuffle(idx)\n    return data[idx, ...], labels[idx], idx\n\n\ndef rotate_point_cloud(batch_data):\n    """""" Randomly rotate the point clouds to augument the dataset\n        rotation is per shape based along up direction\n        Input:\n          BxNx3 array, original batch of point clouds\n        Return:\n          BxNx3 array, rotated batch of point clouds\n    """"""\n    rotated_data = np.zeros(batch_data.shape, dtype=np.float32)\n    for k in range(batch_data.shape[0]):\n        rotation_angle = np.random.uniform() * 2 * np.pi\n        cosval = np.cos(rotation_angle)\n        sinval = np.sin(rotation_angle)\n        rotation_matrix = np.array([[cosval, 0, sinval],\n                                    [0, 1, 0],\n                                    [-sinval, 0, cosval]])\n        shape_pc = batch_data[k, ...]\n        rotated_data[k, ...] = np.dot(shape_pc.reshape((-1, 3)), rotation_matrix)\n    return rotated_data\n\n\ndef rotate_point_cloud_by_angle(batch_data, rotation_angle):\n    """""" Rotate the point cloud along up direction with certain angle.\n        Input:\n          BxNx3 array, original batch of point clouds\n        Return:\n          BxNx3 array, rotated batch of point clouds\n    """"""\n    rotated_data = np.zeros(batch_data.shape, dtype=np.float32)\n    for k in range(batch_data.shape[0]):\n        #rotation_angle = np.random.uniform() * 2 * np.pi\n        cosval = np.cos(rotation_angle)\n        sinval = np.sin(rotation_angle)\n        rotation_matrix = np.array([[cosval, 0, sinval],\n                                    [0, 1, 0],\n                                    [-sinval, 0, cosval]])\n        shape_pc = batch_data[k, ...]\n        rotated_data[k, ...] = np.dot(shape_pc.reshape((-1, 3)), rotation_matrix)\n    return rotated_data\n\n\ndef jitter_point_cloud(batch_data, sigma=0.01, clip=0.05):\n    """""" Randomly jitter points. jittering is per point.\n        Input:\n          BxNx3 array, original batch of point clouds\n        Return:\n          BxNx3 array, jittered batch of point clouds\n    """"""\n    B, N, C = batch_data.shape\n    assert(clip > 0)\n    jittered_data = np.clip(sigma * np.random.randn(B, N, C), -1*clip, clip)\n    jittered_data += batch_data\n    return jittered_data\n\ndef getDataFiles(list_filename):\n    return [line.rstrip() for line in open(list_filename)]\n\ndef load_h5(h5_filename):\n    f = h5py.File(h5_filename)\n    data = f[\'data\'][:]\n    label = f[\'label\'][:]\n    return (data, label)\n\ndef loadDataFile(filename):\n    return load_h5(filename)\n\ndef load_h5_data_label_seg(h5_filename):\n    f = h5py.File(h5_filename)\n    data = f[\'data\'][:]\n    label = f[\'label\'][:]\n    seg = f[\'pid\'][:]\n    return (data, label, seg)\n\n\ndef loadDataFile_with_seg(filename):\n    return load_h5_data_label_seg(filename)\n'"
train.py,24,"b'import argparse\nimport math\nimport h5py\nimport numpy as np\nimport tensorflow as tf\nimport socket\nimport importlib\nimport os\nimport sys\nBASE_DIR = os.path.dirname(os.path.abspath(__file__))\nsys.path.append(BASE_DIR)\nsys.path.append(os.path.join(BASE_DIR, \'models\'))\nsys.path.append(os.path.join(BASE_DIR, \'utils\'))\nimport provider\nimport tf_util\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\'--gpu\', type=int, default=0, help=\'GPU to use [default: GPU 0]\')\nparser.add_argument(\'--model\', default=\'pointnet_cls\', help=\'Model name: pointnet_cls or pointnet_cls_basic [default: pointnet_cls]\')\nparser.add_argument(\'--log_dir\', default=\'log\', help=\'Log dir [default: log]\')\nparser.add_argument(\'--num_point\', type=int, default=1024, help=\'Point Number [256/512/1024/2048] [default: 1024]\')\nparser.add_argument(\'--max_epoch\', type=int, default=250, help=\'Epoch to run [default: 250]\')\nparser.add_argument(\'--batch_size\', type=int, default=32, help=\'Batch Size during training [default: 32]\')\nparser.add_argument(\'--learning_rate\', type=float, default=0.001, help=\'Initial learning rate [default: 0.001]\')\nparser.add_argument(\'--momentum\', type=float, default=0.9, help=\'Initial learning rate [default: 0.9]\')\nparser.add_argument(\'--optimizer\', default=\'adam\', help=\'adam or momentum [default: adam]\')\nparser.add_argument(\'--decay_step\', type=int, default=200000, help=\'Decay step for lr decay [default: 200000]\')\nparser.add_argument(\'--decay_rate\', type=float, default=0.7, help=\'Decay rate for lr decay [default: 0.8]\')\nFLAGS = parser.parse_args()\n\n\nBATCH_SIZE = FLAGS.batch_size\nNUM_POINT = FLAGS.num_point\nMAX_EPOCH = FLAGS.max_epoch\nBASE_LEARNING_RATE = FLAGS.learning_rate\nGPU_INDEX = FLAGS.gpu\nMOMENTUM = FLAGS.momentum\nOPTIMIZER = FLAGS.optimizer\nDECAY_STEP = FLAGS.decay_step\nDECAY_RATE = FLAGS.decay_rate\n\nMODEL = importlib.import_module(FLAGS.model) # import network module\nMODEL_FILE = os.path.join(BASE_DIR, \'models\', FLAGS.model+\'.py\')\nLOG_DIR = FLAGS.log_dir\nif not os.path.exists(LOG_DIR): os.mkdir(LOG_DIR)\nos.system(\'cp %s %s\' % (MODEL_FILE, LOG_DIR)) # bkp of model def\nos.system(\'cp train.py %s\' % (LOG_DIR)) # bkp of train procedure\nLOG_FOUT = open(os.path.join(LOG_DIR, \'log_train.txt\'), \'w\')\nLOG_FOUT.write(str(FLAGS)+\'\\n\')\n\nMAX_NUM_POINT = 2048\nNUM_CLASSES = 40\n\nBN_INIT_DECAY = 0.5\nBN_DECAY_DECAY_RATE = 0.5\nBN_DECAY_DECAY_STEP = float(DECAY_STEP)\nBN_DECAY_CLIP = 0.99\n\nHOSTNAME = socket.gethostname()\n\n# ModelNet40 official train/test split\nTRAIN_FILES = provider.getDataFiles( \\\n    os.path.join(BASE_DIR, \'data/modelnet40_ply_hdf5_2048/train_files.txt\'))\nTEST_FILES = provider.getDataFiles(\\\n    os.path.join(BASE_DIR, \'data/modelnet40_ply_hdf5_2048/test_files.txt\'))\n\ndef log_string(out_str):\n    LOG_FOUT.write(out_str+\'\\n\')\n    LOG_FOUT.flush()\n    print(out_str)\n\n\ndef get_learning_rate(batch):\n    learning_rate = tf.train.exponential_decay(\n                        BASE_LEARNING_RATE,  # Base learning rate.\n                        batch * BATCH_SIZE,  # Current index into the dataset.\n                        DECAY_STEP,          # Decay step.\n                        DECAY_RATE,          # Decay rate.\n                        staircase=True)\n    learning_rate = tf.maximum(learning_rate, 0.00001) # CLIP THE LEARNING RATE!\n    return learning_rate        \n\ndef get_bn_decay(batch):\n    bn_momentum = tf.train.exponential_decay(\n                      BN_INIT_DECAY,\n                      batch*BATCH_SIZE,\n                      BN_DECAY_DECAY_STEP,\n                      BN_DECAY_DECAY_RATE,\n                      staircase=True)\n    bn_decay = tf.minimum(BN_DECAY_CLIP, 1 - bn_momentum)\n    return bn_decay\n\ndef train():\n    with tf.Graph().as_default():\n        with tf.device(\'/gpu:\'+str(GPU_INDEX)):\n            pointclouds_pl, labels_pl = MODEL.placeholder_inputs(BATCH_SIZE, NUM_POINT)\n            is_training_pl = tf.placeholder(tf.bool, shape=())\n            print(is_training_pl)\n            \n            # Note the global_step=batch parameter to minimize. \n            # That tells the optimizer to helpfully increment the \'batch\' parameter for you every time it trains.\n            batch = tf.Variable(0)\n            bn_decay = get_bn_decay(batch)\n            tf.summary.scalar(\'bn_decay\', bn_decay)\n\n            # Get model and loss \n            pred, end_points = MODEL.get_model(pointclouds_pl, is_training_pl, bn_decay=bn_decay)\n            loss = MODEL.get_loss(pred, labels_pl, end_points)\n            tf.summary.scalar(\'loss\', loss)\n\n            correct = tf.equal(tf.argmax(pred, 1), tf.to_int64(labels_pl))\n            accuracy = tf.reduce_sum(tf.cast(correct, tf.float32)) / float(BATCH_SIZE)\n            tf.summary.scalar(\'accuracy\', accuracy)\n\n            # Get training operator\n            learning_rate = get_learning_rate(batch)\n            tf.summary.scalar(\'learning_rate\', learning_rate)\n            if OPTIMIZER == \'momentum\':\n                optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=MOMENTUM)\n            elif OPTIMIZER == \'adam\':\n                optimizer = tf.train.AdamOptimizer(learning_rate)\n            train_op = optimizer.minimize(loss, global_step=batch)\n            \n            # Add ops to save and restore all the variables.\n            saver = tf.train.Saver()\n            \n        # Create a session\n        config = tf.ConfigProto()\n        config.gpu_options.allow_growth = True\n        config.allow_soft_placement = True\n        config.log_device_placement = False\n        sess = tf.Session(config=config)\n\n        # Add summary writers\n        #merged = tf.merge_all_summaries()\n        merged = tf.summary.merge_all()\n        train_writer = tf.summary.FileWriter(os.path.join(LOG_DIR, \'train\'),\n                                  sess.graph)\n        test_writer = tf.summary.FileWriter(os.path.join(LOG_DIR, \'test\'))\n\n        # Init variables\n        init = tf.global_variables_initializer()\n        # To fix the bug introduced in TF 0.12.1 as in\n        # http://stackoverflow.com/questions/41543774/invalidargumenterror-for-tensor-bool-tensorflow-0-12-1\n        #sess.run(init)\n        sess.run(init, {is_training_pl: True})\n\n        ops = {\'pointclouds_pl\': pointclouds_pl,\n               \'labels_pl\': labels_pl,\n               \'is_training_pl\': is_training_pl,\n               \'pred\': pred,\n               \'loss\': loss,\n               \'train_op\': train_op,\n               \'merged\': merged,\n               \'step\': batch}\n\n        for epoch in range(MAX_EPOCH):\n            log_string(\'**** EPOCH %03d ****\' % (epoch))\n            sys.stdout.flush()\n             \n            train_one_epoch(sess, ops, train_writer)\n            eval_one_epoch(sess, ops, test_writer)\n            \n            # Save the variables to disk.\n            if epoch % 10 == 0:\n                save_path = saver.save(sess, os.path.join(LOG_DIR, ""model.ckpt""))\n                log_string(""Model saved in file: %s"" % save_path)\n\n\n\ndef train_one_epoch(sess, ops, train_writer):\n    """""" ops: dict mapping from string to tf ops """"""\n    is_training = True\n    \n    # Shuffle train files\n    train_file_idxs = np.arange(0, len(TRAIN_FILES))\n    np.random.shuffle(train_file_idxs)\n    \n    for fn in range(len(TRAIN_FILES)):\n        log_string(\'----\' + str(fn) + \'-----\')\n        current_data, current_label = provider.loadDataFile(TRAIN_FILES[train_file_idxs[fn]])\n        current_data = current_data[:,0:NUM_POINT,:]\n        current_data, current_label, _ = provider.shuffle_data(current_data, np.squeeze(current_label))            \n        current_label = np.squeeze(current_label)\n        \n        file_size = current_data.shape[0]\n        num_batches = file_size // BATCH_SIZE\n        \n        total_correct = 0\n        total_seen = 0\n        loss_sum = 0\n       \n        for batch_idx in range(num_batches):\n            start_idx = batch_idx * BATCH_SIZE\n            end_idx = (batch_idx+1) * BATCH_SIZE\n            \n            # Augment batched point clouds by rotation and jittering\n            rotated_data = provider.rotate_point_cloud(current_data[start_idx:end_idx, :, :])\n            jittered_data = provider.jitter_point_cloud(rotated_data)\n            feed_dict = {ops[\'pointclouds_pl\']: jittered_data,\n                         ops[\'labels_pl\']: current_label[start_idx:end_idx],\n                         ops[\'is_training_pl\']: is_training,}\n            summary, step, _, loss_val, pred_val = sess.run([ops[\'merged\'], ops[\'step\'],\n                ops[\'train_op\'], ops[\'loss\'], ops[\'pred\']], feed_dict=feed_dict)\n            train_writer.add_summary(summary, step)\n            pred_val = np.argmax(pred_val, 1)\n            correct = np.sum(pred_val == current_label[start_idx:end_idx])\n            total_correct += correct\n            total_seen += BATCH_SIZE\n            loss_sum += loss_val\n        \n        log_string(\'mean loss: %f\' % (loss_sum / float(num_batches)))\n        log_string(\'accuracy: %f\' % (total_correct / float(total_seen)))\n\n        \ndef eval_one_epoch(sess, ops, test_writer):\n    """""" ops: dict mapping from string to tf ops """"""\n    is_training = False\n    total_correct = 0\n    total_seen = 0\n    loss_sum = 0\n    total_seen_class = [0 for _ in range(NUM_CLASSES)]\n    total_correct_class = [0 for _ in range(NUM_CLASSES)]\n    \n    for fn in range(len(TEST_FILES)):\n        log_string(\'----\' + str(fn) + \'-----\')\n        current_data, current_label = provider.loadDataFile(TEST_FILES[fn])\n        current_data = current_data[:,0:NUM_POINT,:]\n        current_label = np.squeeze(current_label)\n        \n        file_size = current_data.shape[0]\n        num_batches = file_size // BATCH_SIZE\n        \n        for batch_idx in range(num_batches):\n            start_idx = batch_idx * BATCH_SIZE\n            end_idx = (batch_idx+1) * BATCH_SIZE\n\n            feed_dict = {ops[\'pointclouds_pl\']: current_data[start_idx:end_idx, :, :],\n                         ops[\'labels_pl\']: current_label[start_idx:end_idx],\n                         ops[\'is_training_pl\']: is_training}\n            summary, step, loss_val, pred_val = sess.run([ops[\'merged\'], ops[\'step\'],\n                ops[\'loss\'], ops[\'pred\']], feed_dict=feed_dict)\n            pred_val = np.argmax(pred_val, 1)\n            correct = np.sum(pred_val == current_label[start_idx:end_idx])\n            total_correct += correct\n            total_seen += BATCH_SIZE\n            loss_sum += (loss_val*BATCH_SIZE)\n            for i in range(start_idx, end_idx):\n                l = current_label[i]\n                total_seen_class[l] += 1\n                total_correct_class[l] += (pred_val[i-start_idx] == l)\n            \n    log_string(\'eval mean loss: %f\' % (loss_sum / float(total_seen)))\n    log_string(\'eval accuracy: %f\'% (total_correct / float(total_seen)))\n    log_string(\'eval avg class acc: %f\' % (np.mean(np.array(total_correct_class)/np.array(total_seen_class,dtype=np.float))))\n         \n\n\nif __name__ == ""__main__"":\n    train()\n    LOG_FOUT.close()\n'"
models/pointnet_cls.py,19,"b'import tensorflow as tf\nimport numpy as np\nimport math\nimport sys\nimport os\nBASE_DIR = os.path.dirname(os.path.abspath(__file__))\nsys.path.append(BASE_DIR)\nsys.path.append(os.path.join(BASE_DIR, \'../utils\'))\nimport tf_util\nfrom transform_nets import input_transform_net, feature_transform_net\n\ndef placeholder_inputs(batch_size, num_point):\n    pointclouds_pl = tf.placeholder(tf.float32, shape=(batch_size, num_point, 3))\n    labels_pl = tf.placeholder(tf.int32, shape=(batch_size))\n    return pointclouds_pl, labels_pl\n\n\ndef get_model(point_cloud, is_training, bn_decay=None):\n    """""" Classification PointNet, input is BxNx3, output Bx40 """"""\n    batch_size = point_cloud.get_shape()[0].value\n    num_point = point_cloud.get_shape()[1].value\n    end_points = {}\n\n    with tf.variable_scope(\'transform_net1\') as sc:\n        transform = input_transform_net(point_cloud, is_training, bn_decay, K=3)\n    point_cloud_transformed = tf.matmul(point_cloud, transform)\n    input_image = tf.expand_dims(point_cloud_transformed, -1)\n\n    net = tf_util.conv2d(input_image, 64, [1,3],\n                         padding=\'VALID\', stride=[1,1],\n                         bn=True, is_training=is_training,\n                         scope=\'conv1\', bn_decay=bn_decay)\n    net = tf_util.conv2d(net, 64, [1,1],\n                         padding=\'VALID\', stride=[1,1],\n                         bn=True, is_training=is_training,\n                         scope=\'conv2\', bn_decay=bn_decay)\n\n    with tf.variable_scope(\'transform_net2\') as sc:\n        transform = feature_transform_net(net, is_training, bn_decay, K=64)\n    end_points[\'transform\'] = transform\n    net_transformed = tf.matmul(tf.squeeze(net, axis=[2]), transform)\n    net_transformed = tf.expand_dims(net_transformed, [2])\n\n    net = tf_util.conv2d(net_transformed, 64, [1,1],\n                         padding=\'VALID\', stride=[1,1],\n                         bn=True, is_training=is_training,\n                         scope=\'conv3\', bn_decay=bn_decay)\n    net = tf_util.conv2d(net, 128, [1,1],\n                         padding=\'VALID\', stride=[1,1],\n                         bn=True, is_training=is_training,\n                         scope=\'conv4\', bn_decay=bn_decay)\n    net = tf_util.conv2d(net, 1024, [1,1],\n                         padding=\'VALID\', stride=[1,1],\n                         bn=True, is_training=is_training,\n                         scope=\'conv5\', bn_decay=bn_decay)\n\n    # Symmetric function: max pooling\n    net = tf_util.max_pool2d(net, [num_point,1],\n                             padding=\'VALID\', scope=\'maxpool\')\n\n    net = tf.reshape(net, [batch_size, -1])\n    net = tf_util.fully_connected(net, 512, bn=True, is_training=is_training,\n                                  scope=\'fc1\', bn_decay=bn_decay)\n    net = tf_util.dropout(net, keep_prob=0.7, is_training=is_training,\n                          scope=\'dp1\')\n    net = tf_util.fully_connected(net, 256, bn=True, is_training=is_training,\n                                  scope=\'fc2\', bn_decay=bn_decay)\n    net = tf_util.dropout(net, keep_prob=0.7, is_training=is_training,\n                          scope=\'dp2\')\n    net = tf_util.fully_connected(net, 40, activation_fn=None, scope=\'fc3\')\n\n    return net, end_points\n\n\ndef get_loss(pred, label, end_points, reg_weight=0.001):\n    """""" pred: B*NUM_CLASSES,\n        label: B, """"""\n    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=pred, labels=label)\n    classify_loss = tf.reduce_mean(loss)\n    tf.summary.scalar(\'classify loss\', classify_loss)\n\n    # Enforce the transformation as orthogonal matrix\n    transform = end_points[\'transform\'] # BxKxK\n    K = transform.get_shape()[1].value\n    mat_diff = tf.matmul(transform, tf.transpose(transform, perm=[0,2,1]))\n    mat_diff -= tf.constant(np.eye(K), dtype=tf.float32)\n    mat_diff_loss = tf.nn.l2_loss(mat_diff) \n    tf.summary.scalar(\'mat loss\', mat_diff_loss)\n\n    return classify_loss + mat_diff_loss * reg_weight\n\n\nif __name__==\'__main__\':\n    with tf.Graph().as_default():\n        inputs = tf.zeros((32,1024,3))\n        outputs = get_model(inputs, tf.constant(True))\n        print(outputs)\n'"
models/pointnet_cls_basic.py,10,"b'import tensorflow as tf\nimport numpy as np\nimport math\nimport sys\nimport os\nBASE_DIR = os.path.dirname(os.path.abspath(__file__))\nsys.path.append(BASE_DIR)\nsys.path.append(os.path.join(BASE_DIR, \'../utils\'))\nimport tf_util\n\ndef placeholder_inputs(batch_size, num_point):\n    pointclouds_pl = tf.placeholder(tf.float32, shape=(batch_size, num_point, 3))\n    labels_pl = tf.placeholder(tf.int32, shape=(batch_size))\n    return pointclouds_pl, labels_pl\n\n\ndef get_model(point_cloud, is_training, bn_decay=None):\n    """""" Classification PointNet, input is BxNx3, output Bx40 """"""\n    batch_size = point_cloud.get_shape()[0].value\n    num_point = point_cloud.get_shape()[1].value\n    end_points = {}\n    input_image = tf.expand_dims(point_cloud, -1)\n    \n    # Point functions (MLP implemented as conv2d)\n    net = tf_util.conv2d(input_image, 64, [1,3],\n                         padding=\'VALID\', stride=[1,1],\n                         bn=True, is_training=is_training,\n                         scope=\'conv1\', bn_decay=bn_decay)\n    net = tf_util.conv2d(net, 64, [1,1],\n                         padding=\'VALID\', stride=[1,1],\n                         bn=True, is_training=is_training,\n                         scope=\'conv2\', bn_decay=bn_decay)\n    net = tf_util.conv2d(net, 64, [1,1],\n                         padding=\'VALID\', stride=[1,1],\n                         bn=True, is_training=is_training,\n                         scope=\'conv3\', bn_decay=bn_decay)\n    net = tf_util.conv2d(net, 128, [1,1],\n                         padding=\'VALID\', stride=[1,1],\n                         bn=True, is_training=is_training,\n                         scope=\'conv4\', bn_decay=bn_decay)\n    net = tf_util.conv2d(net, 1024, [1,1],\n                         padding=\'VALID\', stride=[1,1],\n                         bn=True, is_training=is_training,\n                         scope=\'conv5\', bn_decay=bn_decay)\n\n    # Symmetric function: max pooling\n    net = tf_util.max_pool2d(net, [num_point,1],\n                             padding=\'VALID\', scope=\'maxpool\')\n    \n    # MLP on global point cloud vector\n    net = tf.reshape(net, [batch_size, -1])\n    net = tf_util.fully_connected(net, 512, bn=True, is_training=is_training,\n                                  scope=\'fc1\', bn_decay=bn_decay)\n    net = tf_util.fully_connected(net, 256, bn=True, is_training=is_training,\n                                  scope=\'fc2\', bn_decay=bn_decay)\n    net = tf_util.dropout(net, keep_prob=0.7, is_training=is_training,\n                          scope=\'dp1\')\n    net = tf_util.fully_connected(net, 40, activation_fn=None, scope=\'fc3\')\n\n    return net, end_points\n\n\ndef get_loss(pred, label, end_points):\n    """""" pred: B*NUM_CLASSES,\n        label: B, """"""\n    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=pred, labels=label)\n    classify_loss = tf.reduce_mean(loss)\n    tf.summary.scalar(\'classify loss\', classify_loss)\n    return classify_loss\n\n\nif __name__==\'__main__\':\n    with tf.Graph().as_default():\n        inputs = tf.zeros((32,1024,3))\n        outputs = get_model(inputs, tf.constant(True))\n        print(outputs)\n'"
models/pointnet_seg.py,21,"b'import tensorflow as tf\nimport numpy as np\nimport math\nimport sys\nimport os\nBASE_DIR = os.path.dirname(os.path.abspath(__file__))\nsys.path.append(BASE_DIR)\nsys.path.append(os.path.join(BASE_DIR, \'../utils\'))\nimport tf_util\nfrom transform_nets import input_transform_net, feature_transform_net\n\ndef placeholder_inputs(batch_size, num_point):\n    pointclouds_pl = tf.placeholder(tf.float32,\n                                     shape=(batch_size, num_point, 3))\n    labels_pl = tf.placeholder(tf.int32,\n                                shape=(batch_size, num_point))\n    return pointclouds_pl, labels_pl\n\n\ndef get_model(point_cloud, is_training, bn_decay=None):\n    """""" Classification PointNet, input is BxNx3, output BxNx50 """"""\n    batch_size = point_cloud.get_shape()[0].value\n    num_point = point_cloud.get_shape()[1].value\n    end_points = {}\n\n    with tf.variable_scope(\'transform_net1\') as sc:\n        transform = input_transform_net(point_cloud, is_training, bn_decay, K=3)\n    point_cloud_transformed = tf.matmul(point_cloud, transform)\n    input_image = tf.expand_dims(point_cloud_transformed, -1)\n\n    net = tf_util.conv2d(input_image, 64, [1,3],\n                         padding=\'VALID\', stride=[1,1],\n                         bn=True, is_training=is_training,\n                         scope=\'conv1\', bn_decay=bn_decay)\n    net = tf_util.conv2d(net, 64, [1,1],\n                         padding=\'VALID\', stride=[1,1],\n                         bn=True, is_training=is_training,\n                         scope=\'conv2\', bn_decay=bn_decay)\n\n    with tf.variable_scope(\'transform_net2\') as sc:\n        transform = feature_transform_net(net, is_training, bn_decay, K=64)\n    end_points[\'transform\'] = transform\n    net_transformed = tf.matmul(tf.squeeze(net, axis=[2]), transform)\n    point_feat = tf.expand_dims(net_transformed, [2])\n    print(point_feat)\n\n    net = tf_util.conv2d(point_feat, 64, [1,1],\n                         padding=\'VALID\', stride=[1,1],\n                         bn=True, is_training=is_training,\n                         scope=\'conv3\', bn_decay=bn_decay)\n    net = tf_util.conv2d(net, 128, [1,1],\n                         padding=\'VALID\', stride=[1,1],\n                         bn=True, is_training=is_training,\n                         scope=\'conv4\', bn_decay=bn_decay)\n    net = tf_util.conv2d(net, 1024, [1,1],\n                         padding=\'VALID\', stride=[1,1],\n                         bn=True, is_training=is_training,\n                         scope=\'conv5\', bn_decay=bn_decay)\n    global_feat = tf_util.max_pool2d(net, [num_point,1],\n                                     padding=\'VALID\', scope=\'maxpool\')\n    print(global_feat)\n\n    global_feat_expand = tf.tile(global_feat, [1, num_point, 1, 1])\n    concat_feat = tf.concat(3, [point_feat, global_feat_expand])\n    print(concat_feat)\n\n    net = tf_util.conv2d(concat_feat, 512, [1,1],\n                         padding=\'VALID\', stride=[1,1],\n                         bn=True, is_training=is_training,\n                         scope=\'conv6\', bn_decay=bn_decay)\n    net = tf_util.conv2d(net, 256, [1,1],\n                         padding=\'VALID\', stride=[1,1],\n                         bn=True, is_training=is_training,\n                         scope=\'conv7\', bn_decay=bn_decay)\n    net = tf_util.conv2d(net, 128, [1,1],\n                         padding=\'VALID\', stride=[1,1],\n                         bn=True, is_training=is_training,\n                         scope=\'conv8\', bn_decay=bn_decay)\n    net = tf_util.conv2d(net, 128, [1,1],\n                         padding=\'VALID\', stride=[1,1],\n                         bn=True, is_training=is_training,\n                         scope=\'conv9\', bn_decay=bn_decay)\n\n    net = tf_util.conv2d(net, 50, [1,1],\n                         padding=\'VALID\', stride=[1,1], activation_fn=None,\n                         scope=\'conv10\')\n    net = tf.squeeze(net, [2]) # BxNxC\n\n    return net, end_points\n\n\ndef get_loss(pred, label, end_points, reg_weight=0.001):\n    """""" pred: BxNxC,\n        label: BxN, """"""\n    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=pred, labels=label)\n    classify_loss = tf.reduce_mean(loss)\n    tf.scalar_summary(\'classify loss\', classify_loss)\n\n    # Enforce the transformation as orthogonal matrix\n    transform = end_points[\'transform\'] # BxKxK\n    K = transform.get_shape()[1].value\n    mat_diff = tf.matmul(transform, tf.transpose(transform, perm=[0,2,1]))\n    mat_diff -= tf.constant(np.eye(K), dtype=tf.float32)\n    mat_diff_loss = tf.nn.l2_loss(mat_diff) \n    tf.scalar_summary(\'mat_loss\', mat_diff_loss)\n\n    return classify_loss + mat_diff_loss * reg_weight\n\n\nif __name__==\'__main__\':\n    with tf.Graph().as_default():\n        inputs = tf.zeros((32,1024,3))\n        outputs = get_model(inputs, tf.constant(True))\n        print(outputs)\n'"
models/transform_nets.py,25,"b'import tensorflow as tf\nimport numpy as np\nimport sys\nimport os\nBASE_DIR = os.path.dirname(os.path.abspath(__file__))\nsys.path.append(BASE_DIR)\nsys.path.append(os.path.join(BASE_DIR, \'../utils\'))\nimport tf_util\n\ndef input_transform_net(point_cloud, is_training, bn_decay=None, K=3):\n    """""" Input (XYZ) Transform Net, input is BxNx3 gray image\n        Return:\n            Transformation matrix of size 3xK """"""\n    batch_size = point_cloud.get_shape()[0].value\n    num_point = point_cloud.get_shape()[1].value\n\n    input_image = tf.expand_dims(point_cloud, -1)\n    net = tf_util.conv2d(input_image, 64, [1,3],\n                         padding=\'VALID\', stride=[1,1],\n                         bn=True, is_training=is_training,\n                         scope=\'tconv1\', bn_decay=bn_decay)\n    net = tf_util.conv2d(net, 128, [1,1],\n                         padding=\'VALID\', stride=[1,1],\n                         bn=True, is_training=is_training,\n                         scope=\'tconv2\', bn_decay=bn_decay)\n    net = tf_util.conv2d(net, 1024, [1,1],\n                         padding=\'VALID\', stride=[1,1],\n                         bn=True, is_training=is_training,\n                         scope=\'tconv3\', bn_decay=bn_decay)\n    net = tf_util.max_pool2d(net, [num_point,1],\n                             padding=\'VALID\', scope=\'tmaxpool\')\n\n    net = tf.reshape(net, [batch_size, -1])\n    net = tf_util.fully_connected(net, 512, bn=True, is_training=is_training,\n                                  scope=\'tfc1\', bn_decay=bn_decay)\n    net = tf_util.fully_connected(net, 256, bn=True, is_training=is_training,\n                                  scope=\'tfc2\', bn_decay=bn_decay)\n\n    with tf.variable_scope(\'transform_XYZ\') as sc:\n        assert(K==3)\n        weights = tf.get_variable(\'weights\', [256, 3*K],\n                                  initializer=tf.constant_initializer(0.0),\n                                  dtype=tf.float32)\n        biases = tf.get_variable(\'biases\', [3*K],\n                                 initializer=tf.constant_initializer(0.0),\n                                 dtype=tf.float32)\n        biases += tf.constant([1,0,0,0,1,0,0,0,1], dtype=tf.float32)\n        transform = tf.matmul(net, weights)\n        transform = tf.nn.bias_add(transform, biases)\n\n    transform = tf.reshape(transform, [batch_size, 3, K])\n    return transform\n\n\ndef feature_transform_net(inputs, is_training, bn_decay=None, K=64):\n    """""" Feature Transform Net, input is BxNx1xK\n        Return:\n            Transformation matrix of size KxK """"""\n    batch_size = inputs.get_shape()[0].value\n    num_point = inputs.get_shape()[1].value\n\n    net = tf_util.conv2d(inputs, 64, [1,1],\n                         padding=\'VALID\', stride=[1,1],\n                         bn=True, is_training=is_training,\n                         scope=\'tconv1\', bn_decay=bn_decay)\n    net = tf_util.conv2d(net, 128, [1,1],\n                         padding=\'VALID\', stride=[1,1],\n                         bn=True, is_training=is_training,\n                         scope=\'tconv2\', bn_decay=bn_decay)\n    net = tf_util.conv2d(net, 1024, [1,1],\n                         padding=\'VALID\', stride=[1,1],\n                         bn=True, is_training=is_training,\n                         scope=\'tconv3\', bn_decay=bn_decay)\n    net = tf_util.max_pool2d(net, [num_point,1],\n                             padding=\'VALID\', scope=\'tmaxpool\')\n\n    net = tf.reshape(net, [batch_size, -1])\n    net = tf_util.fully_connected(net, 512, bn=True, is_training=is_training,\n                                  scope=\'tfc1\', bn_decay=bn_decay)\n    net = tf_util.fully_connected(net, 256, bn=True, is_training=is_training,\n                                  scope=\'tfc2\', bn_decay=bn_decay)\n\n    with tf.variable_scope(\'transform_feat\') as sc:\n        weights = tf.get_variable(\'weights\', [256, K*K],\n                                  initializer=tf.constant_initializer(0.0),\n                                  dtype=tf.float32)\n        biases = tf.get_variable(\'biases\', [K*K],\n                                 initializer=tf.constant_initializer(0.0),\n                                 dtype=tf.float32)\n        biases += tf.constant(np.eye(K).flatten(), dtype=tf.float32)\n        transform = tf.matmul(net, weights)\n        transform = tf.nn.bias_add(transform, biases)\n\n    transform = tf.reshape(transform, [batch_size, K, K])\n    return transform\n'"
part_seg/pointnet_part_seg.py,35,"b'import tensorflow as tf\nimport numpy as np\nimport math\nimport os\nimport sys\nBASE_DIR = os.path.dirname(os.path.abspath(__file__))\nsys.path.append(os.path.dirname(BASE_DIR))\nsys.path.append(os.path.join(BASE_DIR, \'../utils\'))\nimport tf_util\n\n\ndef get_transform_K(inputs, is_training, bn_decay=None, K = 3):\n    """""" Transform Net, input is BxNx1xK gray image\n        Return:\n            Transformation matrix of size KxK """"""\n    batch_size = inputs.get_shape()[0].value\n    num_point = inputs.get_shape()[1].value\n\n    net = tf_util.conv2d(inputs, 256, [1,1], padding=\'VALID\', stride=[1,1],\n                         bn=True, is_training=is_training, scope=\'tconv1\', bn_decay=bn_decay)\n    net = tf_util.conv2d(net, 1024, [1,1], padding=\'VALID\', stride=[1,1],\n                         bn=True, is_training=is_training, scope=\'tconv2\', bn_decay=bn_decay)\n    net = tf_util.max_pool2d(net, [num_point,1], padding=\'VALID\', scope=\'tmaxpool\')\n\n    net = tf.reshape(net, [batch_size, -1])\n    net = tf_util.fully_connected(net, 512, bn=True, is_training=is_training, scope=\'tfc1\', bn_decay=bn_decay)\n    net = tf_util.fully_connected(net, 256, bn=True, is_training=is_training, scope=\'tfc2\', bn_decay=bn_decay)\n\n    with tf.variable_scope(\'transform_feat\') as sc:\n        weights = tf.get_variable(\'weights\', [256, K*K], initializer=tf.constant_initializer(0.0), dtype=tf.float32)\n        biases = tf.get_variable(\'biases\', [K*K], initializer=tf.constant_initializer(0.0), dtype=tf.float32) + tf.constant(np.eye(K).flatten(), dtype=tf.float32)\n        transform = tf.matmul(net, weights)\n        transform = tf.nn.bias_add(transform, biases)\n\n    #transform = tf_util.fully_connected(net, 3*K, activation_fn=None, scope=\'tfc3\')\n    transform = tf.reshape(transform, [batch_size, K, K])\n    return transform\n\n\n\n\n\ndef get_transform(point_cloud, is_training, bn_decay=None, K = 3):\n    """""" Transform Net, input is BxNx3 gray image\n        Return:\n            Transformation matrix of size 3xK """"""\n    batch_size = point_cloud.get_shape()[0].value\n    num_point = point_cloud.get_shape()[1].value\n\n    input_image = tf.expand_dims(point_cloud, -1)\n    net = tf_util.conv2d(input_image, 64, [1,3], padding=\'VALID\', stride=[1,1],\n                         bn=True, is_training=is_training, scope=\'tconv1\', bn_decay=bn_decay)\n    net = tf_util.conv2d(net, 128, [1,1], padding=\'VALID\', stride=[1,1],\n                         bn=True, is_training=is_training, scope=\'tconv3\', bn_decay=bn_decay)\n    net = tf_util.conv2d(net, 1024, [1,1], padding=\'VALID\', stride=[1,1],\n                         bn=True, is_training=is_training, scope=\'tconv4\', bn_decay=bn_decay)\n    net = tf_util.max_pool2d(net, [num_point,1], padding=\'VALID\', scope=\'tmaxpool\')\n\n    net = tf.reshape(net, [batch_size, -1])\n    net = tf_util.fully_connected(net, 128, bn=True, is_training=is_training, scope=\'tfc1\', bn_decay=bn_decay)\n    net = tf_util.fully_connected(net, 128, bn=True, is_training=is_training, scope=\'tfc2\', bn_decay=bn_decay)\n\n    with tf.variable_scope(\'transform_XYZ\') as sc:\n        assert(K==3)\n        weights = tf.get_variable(\'weights\', [128, 3*K], initializer=tf.constant_initializer(0.0), dtype=tf.float32)\n        biases = tf.get_variable(\'biases\', [3*K], initializer=tf.constant_initializer(0.0), dtype=tf.float32) + tf.constant([1,0,0,0,1,0,0,0,1], dtype=tf.float32)\n        transform = tf.matmul(net, weights)\n        transform = tf.nn.bias_add(transform, biases)\n\n    #transform = tf_util.fully_connected(net, 3*K, activation_fn=None, scope=\'tfc3\')\n    transform = tf.reshape(transform, [batch_size, 3, K])\n    return transform\n\n\ndef get_model(point_cloud, input_label, is_training, cat_num, part_num, \\\n\t\tbatch_size, num_point, weight_decay, bn_decay=None):\n    """""" ConvNet baseline, input is BxNx3 gray image """"""\n    end_points = {}\n\n    with tf.variable_scope(\'transform_net1\') as sc:\n        K = 3\n        transform = get_transform(point_cloud, is_training, bn_decay, K = 3)\n    point_cloud_transformed = tf.matmul(point_cloud, transform)\n\n    input_image = tf.expand_dims(point_cloud_transformed, -1)\n    out1 = tf_util.conv2d(input_image, 64, [1,K], padding=\'VALID\', stride=[1,1],\n                         bn=True, is_training=is_training, scope=\'conv1\', bn_decay=bn_decay)\n    out2 = tf_util.conv2d(out1, 128, [1,1], padding=\'VALID\', stride=[1,1],\n                         bn=True, is_training=is_training, scope=\'conv2\', bn_decay=bn_decay)\n    out3 = tf_util.conv2d(out2, 128, [1,1], padding=\'VALID\', stride=[1,1],\n                         bn=True, is_training=is_training, scope=\'conv3\', bn_decay=bn_decay)\n\n\n    with tf.variable_scope(\'transform_net2\') as sc:\n        K = 128\n        transform = get_transform_K(out3, is_training, bn_decay, K)\n\n    end_points[\'transform\'] = transform\n\n    squeezed_out3 = tf.reshape(out3, [batch_size, num_point, 128])\n    net_transformed = tf.matmul(squeezed_out3, transform)\n    net_transformed = tf.expand_dims(net_transformed, [2])\n\n    out4 = tf_util.conv2d(net_transformed, 512, [1,1], padding=\'VALID\', stride=[1,1],\n                         bn=True, is_training=is_training, scope=\'conv4\', bn_decay=bn_decay)\n    out5 = tf_util.conv2d(out4, 2048, [1,1], padding=\'VALID\', stride=[1,1],\n                         bn=True, is_training=is_training, scope=\'conv5\', bn_decay=bn_decay)\n    out_max = tf_util.max_pool2d(out5, [num_point,1], padding=\'VALID\', scope=\'maxpool\')\n\n    # classification network\n    net = tf.reshape(out_max, [batch_size, -1])\n    net = tf_util.fully_connected(net, 256, bn=True, is_training=is_training, scope=\'cla/fc1\', bn_decay=bn_decay)\n    net = tf_util.fully_connected(net, 256, bn=True, is_training=is_training, scope=\'cla/fc2\', bn_decay=bn_decay)\n    net = tf_util.dropout(net, keep_prob=0.7, is_training=is_training, scope=\'cla/dp1\')\n    net = tf_util.fully_connected(net, cat_num, activation_fn=None, scope=\'cla/fc3\')\n\n    # segmentation network\n    one_hot_label_expand = tf.reshape(input_label, [batch_size, 1, 1, cat_num])\n    out_max = tf.concat(axis=3, values=[out_max, one_hot_label_expand])\n\n    expand = tf.tile(out_max, [1, num_point, 1, 1])\n    concat = tf.concat(axis=3, values=[expand, out1, out2, out3, out4, out5])\n\n    net2 = tf_util.conv2d(concat, 256, [1,1], padding=\'VALID\', stride=[1,1], bn_decay=bn_decay,\n                        bn=True, is_training=is_training, scope=\'seg/conv1\', weight_decay=weight_decay)\n    net2 = tf_util.dropout(net2, keep_prob=0.8, is_training=is_training, scope=\'seg/dp1\')\n    net2 = tf_util.conv2d(net2, 256, [1,1], padding=\'VALID\', stride=[1,1], bn_decay=bn_decay,\n                        bn=True, is_training=is_training, scope=\'seg/conv2\', weight_decay=weight_decay)\n    net2 = tf_util.dropout(net2, keep_prob=0.8, is_training=is_training, scope=\'seg/dp2\')\n    net2 = tf_util.conv2d(net2, 128, [1,1], padding=\'VALID\', stride=[1,1], bn_decay=bn_decay,\n                        bn=True, is_training=is_training, scope=\'seg/conv3\', weight_decay=weight_decay)\n    net2 = tf_util.conv2d(net2, part_num, [1,1], padding=\'VALID\', stride=[1,1], activation_fn=None, \n                        bn=False, scope=\'seg/conv4\', weight_decay=weight_decay)\n\n    net2 = tf.reshape(net2, [batch_size, num_point, part_num])\n\n    return net, net2, end_points\n\ndef get_loss(l_pred, seg_pred, label, seg, weight, end_points):\n    per_instance_label_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=l_pred, labels=label)\n    label_loss = tf.reduce_mean(per_instance_label_loss)\n\n    # size of seg_pred is batch_size x point_num x part_cat_num\n    # size of seg is batch_size x point_num\n    per_instance_seg_loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=seg_pred, labels=seg), axis=1)\n    seg_loss = tf.reduce_mean(per_instance_seg_loss)\n\n    per_instance_seg_pred_res = tf.argmax(seg_pred, 2)\n    \n    # Enforce the transformation as orthogonal matrix\n    transform = end_points[\'transform\'] # BxKxK\n    K = transform.get_shape()[1].value\n    mat_diff = tf.matmul(transform, tf.transpose(transform, perm=[0,2,1])) - tf.constant(np.eye(K), dtype=tf.float32)\n    mat_diff_loss = tf.nn.l2_loss(mat_diff) \n    \n\n    total_loss = weight * seg_loss + (1 - weight) * label_loss + mat_diff_loss * 1e-3\n\n    return total_loss, label_loss, per_instance_label_loss, seg_loss, per_instance_seg_loss, per_instance_seg_pred_res\n\n'"
part_seg/test.py,8,"b""import argparse\nimport tensorflow as tf\nimport json\nimport numpy as np\nimport os\nimport sys\nBASE_DIR = os.path.dirname(os.path.abspath(__file__))\nsys.path.append(BASE_DIR)\nsys.path.append(os.path.dirname(BASE_DIR))\nimport provider\nimport pointnet_part_seg as model\n\nparser = argparse.ArgumentParser()\nparser.add_argument('--model_path', default='train_results/trained_models/epoch_190.ckpt', help='Model checkpoint path')\nFLAGS = parser.parse_args()\n\n\n# DEFAULT SETTINGS\npretrained_model_path = FLAGS.model_path # os.path.join(BASE_DIR, './pretrained_model/model.ckpt')\nhdf5_data_dir = os.path.join(BASE_DIR, './hdf5_data')\nply_data_dir = os.path.join(BASE_DIR, './PartAnnotation')\ngpu_to_use = 0\noutput_dir = os.path.join(BASE_DIR, './test_results')\noutput_verbose = True   # If true, output all color-coded part segmentation obj files\n\n# MAIN SCRIPT\npoint_num = 3000            # the max number of points in the all testing data shapes\nbatch_size = 1\n\ntest_file_list = os.path.join(BASE_DIR, 'testing_ply_file_list.txt')\n\noid2cpid = json.load(open(os.path.join(hdf5_data_dir, 'overallid_to_catid_partid.json'), 'r'))\n\nobject2setofoid = {}\nfor idx in range(len(oid2cpid)):\n    objid, pid = oid2cpid[idx]\n    if not objid in object2setofoid.keys():\n        object2setofoid[objid] = []\n    object2setofoid[objid].append(idx)\n\nall_obj_cat_file = os.path.join(hdf5_data_dir, 'all_object_categories.txt')\nfin = open(all_obj_cat_file, 'r')\nlines = [line.rstrip() for line in fin.readlines()]\nobjcats = [line.split()[1] for line in lines]\nobjnames = [line.split()[0] for line in lines]\non2oid = {objcats[i]:i for i in range(len(objcats))}\nfin.close()\n\ncolor_map_file = os.path.join(hdf5_data_dir, 'part_color_mapping.json')\ncolor_map = json.load(open(color_map_file, 'r'))\n\nNUM_OBJ_CATS = 16\nNUM_PART_CATS = 50\n\ncpid2oid = json.load(open(os.path.join(hdf5_data_dir, 'catid_partid_to_overallid.json'), 'r'))\n\ndef printout(flog, data):\n\tprint(data)\n\tflog.write(data + '\\n')\n\ndef output_color_point_cloud(data, seg, out_file):\n    with open(out_file, 'w') as f:\n        l = len(seg)\n        for i in range(l):\n            color = color_map[seg[i]]\n            f.write('v %f %f %f %f %f %f\\n' % (data[i][0], data[i][1], data[i][2], color[0], color[1], color[2]))\n\ndef output_color_point_cloud_red_blue(data, seg, out_file):\n    with open(out_file, 'w') as f:\n        l = len(seg)\n        for i in range(l):\n            if seg[i] == 1:\n                color = [0, 0, 1]\n            elif seg[i] == 0:\n                color = [1, 0, 0]\n            else:\n                color = [0, 0, 0]\n\n            f.write('v %f %f %f %f %f %f\\n' % (data[i][0], data[i][1], data[i][2], color[0], color[1], color[2]))\n\n\ndef pc_normalize(pc):\n    l = pc.shape[0]\n    centroid = np.mean(pc, axis=0)\n    pc = pc - centroid\n    m = np.max(np.sqrt(np.sum(pc**2, axis=1)))\n    pc = pc / m\n    return pc\n\ndef placeholder_inputs():\n    pointclouds_ph = tf.placeholder(tf.float32, shape=(batch_size, point_num, 3))\n    input_label_ph = tf.placeholder(tf.float32, shape=(batch_size, NUM_OBJ_CATS))\n    return pointclouds_ph, input_label_ph\n\ndef output_color_point_cloud(data, seg, out_file):\n    with open(out_file, 'w') as f:\n        l = len(seg)\n        for i in range(l):\n            color = color_map[seg[i]]\n            f.write('v %f %f %f %f %f %f\\n' % (data[i][0], data[i][1], data[i][2], color[0], color[1], color[2]))\n\ndef load_pts_seg_files(pts_file, seg_file, catid):\n    with open(pts_file, 'r') as f:\n        pts_str = [item.rstrip() for item in f.readlines()]\n        pts = np.array([np.float32(s.split()) for s in pts_str], dtype=np.float32)\n    with open(seg_file, 'r') as f:\n        part_ids = np.array([int(item.rstrip()) for item in f.readlines()], dtype=np.uint8)\n        seg = np.array([cpid2oid[catid+'_'+str(x)] for x in part_ids])\n    return pts, seg\n\ndef pc_augment_to_point_num(pts, pn):\n    assert(pts.shape[0] <= pn)\n    cur_len = pts.shape[0]\n    res = np.array(pts)\n    while cur_len < pn:\n        res = np.concatenate((res, pts))\n        cur_len += pts.shape[0]\n    return res[:pn, :]\n\ndef convert_label_to_one_hot(labels):\n    label_one_hot = np.zeros((labels.shape[0], NUM_OBJ_CATS))\n    for idx in range(labels.shape[0]):\n        label_one_hot[idx, labels[idx]] = 1\n    return label_one_hot\n\ndef predict():\n    is_training = False\n    \n    with tf.device('/gpu:'+str(gpu_to_use)):\n        pointclouds_ph, input_label_ph = placeholder_inputs()\n        is_training_ph = tf.placeholder(tf.bool, shape=())\n\n        # simple model\n        pred, seg_pred, end_points = model.get_model(pointclouds_ph, input_label_ph, \\\n                cat_num=NUM_OBJ_CATS, part_num=NUM_PART_CATS, is_training=is_training_ph, \\\n                batch_size=batch_size, num_point=point_num, weight_decay=0.0, bn_decay=None)\n        \n    # Add ops to save and restore all the variables.\n    saver = tf.train.Saver()\n\n    # Later, launch the model, use the saver to restore variables from disk, and\n    # do some work with the model.\n    \n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    config.allow_soft_placement = True\n\n    with tf.Session(config=config) as sess:\n        if not os.path.exists(output_dir):\n            os.mkdir(output_dir)\n\n        flog = open(os.path.join(output_dir, 'log.txt'), 'w')\n\n        # Restore variables from disk.\n        printout(flog, 'Loading model %s' % pretrained_model_path)\n        saver.restore(sess, pretrained_model_path)\n        printout(flog, 'Model restored.')\n        \n        # Note: the evaluation for the model with BN has to have some statistics\n        # Using some test datas as the statistics\n        batch_data = np.zeros([batch_size, point_num, 3]).astype(np.float32)\n\n        total_acc = 0.0\n        total_seen = 0\n        total_acc_iou = 0.0\n\n        total_per_cat_acc = np.zeros((NUM_OBJ_CATS)).astype(np.float32)\n        total_per_cat_iou = np.zeros((NUM_OBJ_CATS)).astype(np.float32)\n        total_per_cat_seen = np.zeros((NUM_OBJ_CATS)).astype(np.int32)\n\n        ffiles = open(test_file_list, 'r')\n        lines = [line.rstrip() for line in ffiles.readlines()]\n        pts_files = [line.split()[0] for line in lines]\n        seg_files = [line.split()[1] for line in lines]\n        labels = [line.split()[2] for line in lines]\n        ffiles.close()\n\n        len_pts_files = len(pts_files)\n        for shape_idx in range(len_pts_files):\n            if shape_idx % 100 == 0:\n                printout(flog, '%d/%d ...' % (shape_idx, len_pts_files))\n\n            cur_gt_label = on2oid[labels[shape_idx]]\n\n            cur_label_one_hot = np.zeros((1, NUM_OBJ_CATS), dtype=np.float32)\n            cur_label_one_hot[0, cur_gt_label] = 1\n\n            pts_file_to_load = os.path.join(ply_data_dir, pts_files[shape_idx])\n            seg_file_to_load = os.path.join(ply_data_dir, seg_files[shape_idx])\n\n            pts, seg = load_pts_seg_files(pts_file_to_load, seg_file_to_load, objcats[cur_gt_label])\n            ori_point_num = len(seg)\n\n            batch_data[0, ...] = pc_augment_to_point_num(pc_normalize(pts), point_num)\n\n            label_pred_val, seg_pred_res = sess.run([pred, seg_pred], feed_dict={\n                        pointclouds_ph: batch_data,\n                        input_label_ph: cur_label_one_hot, \n                        is_training_ph: is_training,\n                    })\n\n            label_pred_val = np.argmax(label_pred_val[0, :])\n            \n            seg_pred_res = seg_pred_res[0, ...]\n\n            iou_oids = object2setofoid[objcats[cur_gt_label]]\n            non_cat_labels = list(set(np.arange(NUM_PART_CATS)).difference(set(iou_oids)))\n\n            mini = np.min(seg_pred_res)\n            seg_pred_res[:, non_cat_labels] = mini - 1000\n\n            seg_pred_val = np.argmax(seg_pred_res, axis=1)[:ori_point_num]\n\n            seg_acc = np.mean(seg_pred_val == seg)\n\n            total_acc += seg_acc\n            total_seen += 1\n\n            total_per_cat_seen[cur_gt_label] += 1\n            total_per_cat_acc[cur_gt_label] += seg_acc\n\n            mask = np.int32(seg_pred_val == seg)\n\n            total_iou = 0.0\n            iou_log = ''\n            for oid in iou_oids:\n                n_pred = np.sum(seg_pred_val == oid)\n                n_gt = np.sum(seg == oid)\n                n_intersect = np.sum(np.int32(seg == oid) * mask)\n                n_union = n_pred + n_gt - n_intersect\n                iou_log += '_' + str(n_pred)+'_'+str(n_gt)+'_'+str(n_intersect)+'_'+str(n_union)+'_'\n                if n_union == 0:\n                    total_iou += 1\n                    iou_log += '_1\\n'\n                else:\n                    total_iou += n_intersect * 1.0 / n_union\n                    iou_log += '_'+str(n_intersect * 1.0 / n_union)+'\\n'\n\n            avg_iou = total_iou / len(iou_oids)\n            total_acc_iou += avg_iou\n            total_per_cat_iou[cur_gt_label] += avg_iou\n            \n            if output_verbose:\n                output_color_point_cloud(pts, seg, os.path.join(output_dir, str(shape_idx)+'_gt.obj'))\n                output_color_point_cloud(pts, seg_pred_val, os.path.join(output_dir, str(shape_idx)+'_pred.obj'))\n                output_color_point_cloud_red_blue(pts, np.int32(seg == seg_pred_val), \n                        os.path.join(output_dir, str(shape_idx)+'_diff.obj'))\n\n                with open(os.path.join(output_dir, str(shape_idx)+'.log'), 'w') as fout:\n                    fout.write('Total Point: %d\\n\\n' % ori_point_num)\n                    fout.write('Ground Truth: %s\\n' % objnames[cur_gt_label])\n                    fout.write('Predict: %s\\n\\n' % objnames[label_pred_val])\n                    fout.write('Accuracy: %f\\n' % seg_acc)\n                    fout.write('IoU: %f\\n\\n' % avg_iou)\n                    fout.write('IoU details: %s\\n' % iou_log)\n\n        printout(flog, 'Accuracy: %f' % (total_acc / total_seen))\n        printout(flog, 'IoU: %f' % (total_acc_iou / total_seen))\n\n        for cat_idx in range(NUM_OBJ_CATS):\n            printout(flog, '\\t ' + objcats[cat_idx] + ' Total Number: ' + str(total_per_cat_seen[cat_idx]))\n            if total_per_cat_seen[cat_idx] > 0:\n                printout(flog, '\\t ' + objcats[cat_idx] + ' Accuracy: ' + \\\n                        str(total_per_cat_acc[cat_idx] / total_per_cat_seen[cat_idx]))\n                printout(flog, '\\t ' + objcats[cat_idx] + ' IoU: '+ \\\n                        str(total_per_cat_iou[cat_idx] / total_per_cat_seen[cat_idx]))\n\n                \nwith tf.Graph().as_default():\n    predict()\n"""
part_seg/train.py,47,"b""import argparse\nimport subprocess\nimport tensorflow as tf\nimport numpy as np\nfrom datetime import datetime\nimport json\nimport os\nimport sys\nBASE_DIR = os.path.dirname(os.path.abspath(__file__))\nsys.path.append(BASE_DIR)\nsys.path.append(os.path.dirname(BASE_DIR))\nimport provider\nimport pointnet_part_seg as model\n\n# DEFAULT SETTINGS\nparser = argparse.ArgumentParser()\nparser.add_argument('--gpu', type=int, default=1, help='GPU to use [default: GPU 0]')\nparser.add_argument('--batch', type=int, default=32, help='Batch Size during training [default: 32]')\nparser.add_argument('--epoch', type=int, default=200, help='Epoch to run [default: 50]')\nparser.add_argument('--point_num', type=int, default=2048, help='Point Number [256/512/1024/2048]')\nparser.add_argument('--output_dir', type=str, default='train_results', help='Directory that stores all training logs and trained models')\nparser.add_argument('--wd', type=float, default=0, help='Weight Decay [Default: 0.0]')\nFLAGS = parser.parse_args()\n\nhdf5_data_dir = os.path.join(BASE_DIR, './hdf5_data')\n\n# MAIN SCRIPT\npoint_num = FLAGS.point_num\nbatch_size = FLAGS.batch\noutput_dir = FLAGS.output_dir\n\nif not os.path.exists(output_dir):\n    os.mkdir(output_dir)\n\ncolor_map_file = os.path.join(hdf5_data_dir, 'part_color_mapping.json')\ncolor_map = json.load(open(color_map_file, 'r'))\n\nall_obj_cats_file = os.path.join(hdf5_data_dir, 'all_object_categories.txt')\nfin = open(all_obj_cats_file, 'r')\nlines = [line.rstrip() for line in fin.readlines()]\nall_obj_cats = [(line.split()[0], line.split()[1]) for line in lines]\nfin.close()\n\nall_cats = json.load(open(os.path.join(hdf5_data_dir, 'overallid_to_catid_partid.json'), 'r'))\nNUM_CATEGORIES = 16\nNUM_PART_CATS = len(all_cats)\n\nprint('#### Batch Size: {0}'.format(batch_size))\nprint('#### Point Number: {0}'.format(point_num))\nprint('#### Training using GPU: {0}'.format(FLAGS.gpu))\n\nDECAY_STEP = 16881 * 20\nDECAY_RATE = 0.5\n\nLEARNING_RATE_CLIP = 1e-5\n\nBN_INIT_DECAY = 0.5\nBN_DECAY_DECAY_RATE = 0.5\nBN_DECAY_DECAY_STEP = float(DECAY_STEP * 2)\nBN_DECAY_CLIP = 0.99\n\nBASE_LEARNING_RATE = 0.001\nMOMENTUM = 0.9\nTRAINING_EPOCHES = FLAGS.epoch\nprint('### Training epoch: {0}'.format(TRAINING_EPOCHES))\n\nTRAINING_FILE_LIST = os.path.join(hdf5_data_dir, 'train_hdf5_file_list.txt')\nTESTING_FILE_LIST = os.path.join(hdf5_data_dir, 'val_hdf5_file_list.txt')\n\nMODEL_STORAGE_PATH = os.path.join(output_dir, 'trained_models')\nif not os.path.exists(MODEL_STORAGE_PATH):\n    os.mkdir(MODEL_STORAGE_PATH)\n\nLOG_STORAGE_PATH = os.path.join(output_dir, 'logs')\nif not os.path.exists(LOG_STORAGE_PATH):\n    os.mkdir(LOG_STORAGE_PATH)\n\nSUMMARIES_FOLDER =  os.path.join(output_dir, 'summaries')\nif not os.path.exists(SUMMARIES_FOLDER):\n    os.mkdir(SUMMARIES_FOLDER)\n\ndef printout(flog, data):\n\tprint(data)\n\tflog.write(data + '\\n')\n\ndef placeholder_inputs():\n    pointclouds_ph = tf.placeholder(tf.float32, shape=(batch_size, point_num, 3))\n    input_label_ph = tf.placeholder(tf.float32, shape=(batch_size, NUM_CATEGORIES))\n    labels_ph = tf.placeholder(tf.int32, shape=(batch_size))\n    seg_ph = tf.placeholder(tf.int32, shape=(batch_size, point_num))\n    return pointclouds_ph, input_label_ph, labels_ph, seg_ph\n\ndef convert_label_to_one_hot(labels):\n    label_one_hot = np.zeros((labels.shape[0], NUM_CATEGORIES))\n    for idx in range(labels.shape[0]):\n        label_one_hot[idx, labels[idx]] = 1\n    return label_one_hot\n\ndef train():\n    with tf.Graph().as_default():\n        with tf.device('/gpu:'+str(FLAGS.gpu)):\n            pointclouds_ph, input_label_ph, labels_ph, seg_ph = placeholder_inputs()\n            is_training_ph = tf.placeholder(tf.bool, shape=())\n\n            batch = tf.Variable(0, trainable=False)\n            learning_rate = tf.train.exponential_decay(\n                            BASE_LEARNING_RATE,     # base learning rate\n                            batch * batch_size,     # global_var indicating the number of steps\n                            DECAY_STEP,             # step size\n                            DECAY_RATE,             # decay rate\n                            staircase=True          # Stair-case or continuous decreasing\n                            )\n            learning_rate = tf.maximum(learning_rate, LEARNING_RATE_CLIP)\n        \n            bn_momentum = tf.train.exponential_decay(\n                      BN_INIT_DECAY,\n                      batch*batch_size,\n                      BN_DECAY_DECAY_STEP,\n                      BN_DECAY_DECAY_RATE,\n                      staircase=True)\n            bn_decay = tf.minimum(BN_DECAY_CLIP, 1 - bn_momentum)\n\n            lr_op = tf.summary.scalar('learning_rate', learning_rate)\n            batch_op = tf.summary.scalar('batch_number', batch)\n            bn_decay_op = tf.summary.scalar('bn_decay', bn_decay)\n \n            labels_pred, seg_pred, end_points = model.get_model(pointclouds_ph, input_label_ph, \\\n                    is_training=is_training_ph, bn_decay=bn_decay, cat_num=NUM_CATEGORIES, \\\n                    part_num=NUM_PART_CATS, batch_size=batch_size, num_point=point_num, weight_decay=FLAGS.wd)\n\n            # model.py defines both classification net and segmentation net, which share the common global feature extractor network.\n            # In model.get_loss, we define the total loss to be weighted sum of the classification and segmentation losses.\n            # Here, we only train for segmentation network. Thus, we set weight to be 1.0.\n            loss, label_loss, per_instance_label_loss, seg_loss, per_instance_seg_loss, per_instance_seg_pred_res  \\\n                = model.get_loss(labels_pred, seg_pred, labels_ph, seg_ph, 1.0, end_points)\n\n            total_training_loss_ph = tf.placeholder(tf.float32, shape=())\n            total_testing_loss_ph = tf.placeholder(tf.float32, shape=())\n\n            label_training_loss_ph = tf.placeholder(tf.float32, shape=())\n            label_testing_loss_ph = tf.placeholder(tf.float32, shape=())\n\n            seg_training_loss_ph = tf.placeholder(tf.float32, shape=())\n            seg_testing_loss_ph = tf.placeholder(tf.float32, shape=())\n\n            label_training_acc_ph = tf.placeholder(tf.float32, shape=())\n            label_testing_acc_ph = tf.placeholder(tf.float32, shape=())\n            label_testing_acc_avg_cat_ph = tf.placeholder(tf.float32, shape=())\n\n            seg_training_acc_ph = tf.placeholder(tf.float32, shape=())\n            seg_testing_acc_ph = tf.placeholder(tf.float32, shape=())\n            seg_testing_acc_avg_cat_ph = tf.placeholder(tf.float32, shape=())\n\n            total_train_loss_sum_op = tf.summary.scalar('total_training_loss', total_training_loss_ph)\n            total_test_loss_sum_op = tf.summary.scalar('total_testing_loss', total_testing_loss_ph)\n\n            label_train_loss_sum_op = tf.summary.scalar('label_training_loss', label_training_loss_ph)\n            label_test_loss_sum_op = tf.summary.scalar('label_testing_loss', label_testing_loss_ph)\n\n            seg_train_loss_sum_op = tf.summary.scalar('seg_training_loss', seg_training_loss_ph)\n            seg_test_loss_sum_op = tf.summary.scalar('seg_testing_loss', seg_testing_loss_ph)\n\n            label_train_acc_sum_op = tf.summary.scalar('label_training_acc', label_training_acc_ph)\n            label_test_acc_sum_op = tf.summary.scalar('label_testing_acc', label_testing_acc_ph)\n            label_test_acc_avg_cat_op = tf.summary.scalar('label_testing_acc_avg_cat', label_testing_acc_avg_cat_ph)\n\n            seg_train_acc_sum_op = tf.summary.scalar('seg_training_acc', seg_training_acc_ph)\n            seg_test_acc_sum_op = tf.summary.scalar('seg_testing_acc', seg_testing_acc_ph)\n            seg_test_acc_avg_cat_op = tf.summary.scalar('seg_testing_acc_avg_cat', seg_testing_acc_avg_cat_ph)\n\n            train_variables = tf.trainable_variables()\n\n            trainer = tf.train.AdamOptimizer(learning_rate)\n            train_op = trainer.minimize(loss, var_list=train_variables, global_step=batch)\n\n        saver = tf.train.Saver()\n\n        config = tf.ConfigProto()\n        config.gpu_options.allow_growth = True\n        config.allow_soft_placement = True\n        sess = tf.Session(config=config)\n        \n        init = tf.global_variables_initializer()\n        sess.run(init)\n\n        train_writer = tf.summary.FileWriter(SUMMARIES_FOLDER + '/train', sess.graph)\n        test_writer = tf.summary.FileWriter(SUMMARIES_FOLDER + '/test')\n\n        train_file_list = provider.getDataFiles(TRAINING_FILE_LIST)\n        num_train_file = len(train_file_list)\n        test_file_list = provider.getDataFiles(TESTING_FILE_LIST)\n        num_test_file = len(test_file_list)\n\n        fcmd = open(os.path.join(LOG_STORAGE_PATH, 'cmd.txt'), 'w')\n        fcmd.write(str(FLAGS))\n        fcmd.close()\n\n        # write logs to the disk\n        flog = open(os.path.join(LOG_STORAGE_PATH, 'log.txt'), 'w')\n\n        def train_one_epoch(train_file_idx, epoch_num):\n            is_training = True\n\n            for i in range(num_train_file):\n                cur_train_filename = os.path.join(hdf5_data_dir, train_file_list[train_file_idx[i]])\n                printout(flog, 'Loading train file ' + cur_train_filename)\n\n                cur_data, cur_labels, cur_seg = provider.loadDataFile_with_seg(cur_train_filename)\n                cur_data, cur_labels, order = provider.shuffle_data(cur_data, np.squeeze(cur_labels))\n                cur_seg = cur_seg[order, ...]\n\n                cur_labels_one_hot = convert_label_to_one_hot(cur_labels)\n\n                num_data = len(cur_labels)\n                num_batch = num_data // batch_size\n\n                total_loss = 0.0\n                total_label_loss = 0.0\n                total_seg_loss = 0.0\n                total_label_acc = 0.0\n                total_seg_acc = 0.0\n\n                for j in range(num_batch):\n                    begidx = j * batch_size\n                    endidx = (j + 1) * batch_size\n\n                    feed_dict = {\n                            pointclouds_ph: cur_data[begidx: endidx, ...], \n                            labels_ph: cur_labels[begidx: endidx, ...], \n                            input_label_ph: cur_labels_one_hot[begidx: endidx, ...], \n                            seg_ph: cur_seg[begidx: endidx, ...],\n                            is_training_ph: is_training, \n                            }\n\n                    _, loss_val, label_loss_val, seg_loss_val, per_instance_label_loss_val, \\\n                            per_instance_seg_loss_val, label_pred_val, seg_pred_val, pred_seg_res \\\n                            = sess.run([train_op, loss, label_loss, seg_loss, per_instance_label_loss, \\\n                            per_instance_seg_loss, labels_pred, seg_pred, per_instance_seg_pred_res], \\\n                            feed_dict=feed_dict)\n\n                    per_instance_part_acc = np.mean(pred_seg_res == cur_seg[begidx: endidx, ...], axis=1)\n                    average_part_acc = np.mean(per_instance_part_acc)\n\n                    total_loss += loss_val\n                    total_label_loss += label_loss_val\n                    total_seg_loss += seg_loss_val\n                    \n                    per_instance_label_pred = np.argmax(label_pred_val, axis=1)\n                    total_label_acc += np.mean(np.float32(per_instance_label_pred == cur_labels[begidx: endidx, ...]))\n                    total_seg_acc += average_part_acc\n\n                total_loss = total_loss * 1.0 / num_batch\n                total_label_loss = total_label_loss * 1.0 / num_batch\n                total_seg_loss = total_seg_loss * 1.0 / num_batch\n                total_label_acc = total_label_acc * 1.0 / num_batch\n                total_seg_acc = total_seg_acc * 1.0 / num_batch\n\n                lr_sum, bn_decay_sum, batch_sum, train_loss_sum, train_label_acc_sum, \\\n                        train_label_loss_sum, train_seg_loss_sum, train_seg_acc_sum = sess.run(\\\n                        [lr_op, bn_decay_op, batch_op, total_train_loss_sum_op, label_train_acc_sum_op, \\\n                        label_train_loss_sum_op, seg_train_loss_sum_op, seg_train_acc_sum_op], \\\n                        feed_dict={total_training_loss_ph: total_loss, label_training_loss_ph: total_label_loss, \\\n                        seg_training_loss_ph: total_seg_loss, label_training_acc_ph: total_label_acc, \\\n                        seg_training_acc_ph: total_seg_acc})\n\n                train_writer.add_summary(train_loss_sum, i + epoch_num * num_train_file)\n                train_writer.add_summary(train_label_loss_sum, i + epoch_num * num_train_file)\n                train_writer.add_summary(train_seg_loss_sum, i + epoch_num * num_train_file)\n                train_writer.add_summary(lr_sum, i + epoch_num * num_train_file)\n                train_writer.add_summary(bn_decay_sum, i + epoch_num * num_train_file)\n                train_writer.add_summary(train_label_acc_sum, i + epoch_num * num_train_file)\n                train_writer.add_summary(train_seg_acc_sum, i + epoch_num * num_train_file)\n                train_writer.add_summary(batch_sum, i + epoch_num * num_train_file)\n\n                printout(flog, '\\tTraining Total Mean_loss: %f' % total_loss)\n                printout(flog, '\\t\\tTraining Label Mean_loss: %f' % total_label_loss)\n                printout(flog, '\\t\\tTraining Label Accuracy: %f' % total_label_acc)\n                printout(flog, '\\t\\tTraining Seg Mean_loss: %f' % total_seg_loss)\n                printout(flog, '\\t\\tTraining Seg Accuracy: %f' % total_seg_acc)\n\n        def eval_one_epoch(epoch_num):\n            is_training = False\n\n            total_loss = 0.0\n            total_label_loss = 0.0\n            total_seg_loss = 0.0\n            total_label_acc = 0.0\n            total_seg_acc = 0.0\n            total_seen = 0\n\n            total_label_acc_per_cat = np.zeros((NUM_CATEGORIES)).astype(np.float32)\n            total_seg_acc_per_cat = np.zeros((NUM_CATEGORIES)).astype(np.float32)\n            total_seen_per_cat = np.zeros((NUM_CATEGORIES)).astype(np.int32)\n\n            for i in range(num_test_file):\n                cur_test_filename = os.path.join(hdf5_data_dir, test_file_list[i])\n                printout(flog, 'Loading test file ' + cur_test_filename)\n\n                cur_data, cur_labels, cur_seg = provider.loadDataFile_with_seg(cur_test_filename)\n                cur_labels = np.squeeze(cur_labels)\n\n                cur_labels_one_hot = convert_label_to_one_hot(cur_labels)\n\n                num_data = len(cur_labels)\n                num_batch = num_data // batch_size\n\n                for j in range(num_batch):\n                    begidx = j * batch_size\n                    endidx = (j + 1) * batch_size\n                    feed_dict = {\n                            pointclouds_ph: cur_data[begidx: endidx, ...], \n                            labels_ph: cur_labels[begidx: endidx, ...], \n                            input_label_ph: cur_labels_one_hot[begidx: endidx, ...], \n                            seg_ph: cur_seg[begidx: endidx, ...],\n                            is_training_ph: is_training, \n                            }\n\n                    loss_val, label_loss_val, seg_loss_val, per_instance_label_loss_val, \\\n                            per_instance_seg_loss_val, label_pred_val, seg_pred_val, pred_seg_res \\\n                            = sess.run([loss, label_loss, seg_loss, per_instance_label_loss, \\\n                            per_instance_seg_loss, labels_pred, seg_pred, per_instance_seg_pred_res], \\\n                            feed_dict=feed_dict)\n\n                    per_instance_part_acc = np.mean(pred_seg_res == cur_seg[begidx: endidx, ...], axis=1)\n                    average_part_acc = np.mean(per_instance_part_acc)\n\n                    total_seen += 1\n                    total_loss += loss_val\n                    total_label_loss += label_loss_val\n                    total_seg_loss += seg_loss_val\n                    \n                    per_instance_label_pred = np.argmax(label_pred_val, axis=1)\n                    total_label_acc += np.mean(np.float32(per_instance_label_pred == cur_labels[begidx: endidx, ...]))\n                    total_seg_acc += average_part_acc\n\n                    for shape_idx in range(begidx, endidx):\n                        total_seen_per_cat[cur_labels[shape_idx]] += 1\n                        total_label_acc_per_cat[cur_labels[shape_idx]] += np.int32(per_instance_label_pred[shape_idx-begidx] == cur_labels[shape_idx])\n                        total_seg_acc_per_cat[cur_labels[shape_idx]] += per_instance_part_acc[shape_idx - begidx]\n\n            total_loss = total_loss * 1.0 / total_seen\n            total_label_loss = total_label_loss * 1.0 / total_seen\n            total_seg_loss = total_seg_loss * 1.0 / total_seen\n            total_label_acc = total_label_acc * 1.0 / total_seen\n            total_seg_acc = total_seg_acc * 1.0 / total_seen\n\n            test_loss_sum, test_label_acc_sum, test_label_loss_sum, test_seg_loss_sum, test_seg_acc_sum = sess.run(\\\n                    [total_test_loss_sum_op, label_test_acc_sum_op, label_test_loss_sum_op, seg_test_loss_sum_op, seg_test_acc_sum_op], \\\n                    feed_dict={total_testing_loss_ph: total_loss, label_testing_loss_ph: total_label_loss, \\\n                    seg_testing_loss_ph: total_seg_loss, label_testing_acc_ph: total_label_acc, seg_testing_acc_ph: total_seg_acc})\n\n            test_writer.add_summary(test_loss_sum, (epoch_num+1) * num_train_file-1)\n            test_writer.add_summary(test_label_loss_sum, (epoch_num+1) * num_train_file-1)\n            test_writer.add_summary(test_seg_loss_sum, (epoch_num+1) * num_train_file-1)\n            test_writer.add_summary(test_label_acc_sum, (epoch_num+1) * num_train_file-1)\n            test_writer.add_summary(test_seg_acc_sum, (epoch_num+1) * num_train_file-1)\n\n            printout(flog, '\\tTesting Total Mean_loss: %f' % total_loss)\n            printout(flog, '\\t\\tTesting Label Mean_loss: %f' % total_label_loss)\n            printout(flog, '\\t\\tTesting Label Accuracy: %f' % total_label_acc)\n            printout(flog, '\\t\\tTesting Seg Mean_loss: %f' % total_seg_loss)\n            printout(flog, '\\t\\tTesting Seg Accuracy: %f' % total_seg_acc)\n\n            for cat_idx in range(NUM_CATEGORIES):\n                if total_seen_per_cat[cat_idx] > 0:\n                    printout(flog, '\\n\\t\\tCategory %s Object Number: %d' % (all_obj_cats[cat_idx][0], total_seen_per_cat[cat_idx]))\n                    printout(flog, '\\t\\tCategory %s Label Accuracy: %f' % (all_obj_cats[cat_idx][0], total_label_acc_per_cat[cat_idx]/total_seen_per_cat[cat_idx]))\n                    printout(flog, '\\t\\tCategory %s Seg Accuracy: %f' % (all_obj_cats[cat_idx][0], total_seg_acc_per_cat[cat_idx]/total_seen_per_cat[cat_idx]))\n\n        if not os.path.exists(MODEL_STORAGE_PATH):\n            os.mkdir(MODEL_STORAGE_PATH)\n\n        for epoch in range(TRAINING_EPOCHES):\n            printout(flog, '\\n<<< Testing on the test dataset ...')\n            eval_one_epoch(epoch)\n\n            printout(flog, '\\n>>> Training for the epoch %d/%d ...' % (epoch, TRAINING_EPOCHES))\n\n            train_file_idx = np.arange(0, len(train_file_list))\n            np.random.shuffle(train_file_idx)\n\n            train_one_epoch(train_file_idx, epoch)\n\n            if (epoch+1) % 10 == 0:\n                cp_filename = saver.save(sess, os.path.join(MODEL_STORAGE_PATH, 'epoch_' + str(epoch+1)+'.ckpt'))\n                printout(flog, 'Successfully store the checkpoint model into ' + cp_filename)\n\n            flog.flush()\n\n        flog.close()\n\nif __name__=='__main__':\n    train()\n"""
sem_seg/batch_inference.py,7,"b'import argparse\nimport os\nimport sys\nBASE_DIR = os.path.dirname(os.path.abspath(__file__))\nROOT_DIR = os.path.dirname(BASE_DIR)\nsys.path.append(BASE_DIR)\nfrom model import *\nimport indoor3d_util\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\'--gpu\', type=int, default=0, help=\'GPU to use [default: GPU 0]\')\nparser.add_argument(\'--batch_size\', type=int, default=1, help=\'Batch Size during training [default: 1]\')\nparser.add_argument(\'--num_point\', type=int, default=4096, help=\'Point number [default: 4096]\')\nparser.add_argument(\'--model_path\', required=True, help=\'model checkpoint file path\')\nparser.add_argument(\'--dump_dir\', required=True, help=\'dump folder path\')\nparser.add_argument(\'--output_filelist\', required=True, help=\'TXT filename, filelist, each line is an output for a room\')\nparser.add_argument(\'--room_data_filelist\', required=True, help=\'TXT filename, filelist, each line is a test room data label file.\')\nparser.add_argument(\'--no_clutter\', action=\'store_true\', help=\'If true, donot count the clutter class\')\nparser.add_argument(\'--visu\', action=\'store_true\', help=\'Whether to output OBJ file for prediction visualization.\')\nFLAGS = parser.parse_args()\n\nBATCH_SIZE = FLAGS.batch_size\nNUM_POINT = FLAGS.num_point\nMODEL_PATH = FLAGS.model_path\nGPU_INDEX = FLAGS.gpu\nDUMP_DIR = FLAGS.dump_dir\nif not os.path.exists(DUMP_DIR): os.mkdir(DUMP_DIR)\nLOG_FOUT = open(os.path.join(DUMP_DIR, \'log_evaluate.txt\'), \'w\')\nLOG_FOUT.write(str(FLAGS)+\'\\n\')\nROOM_PATH_LIST = [os.path.join(ROOT_DIR,line.rstrip()) for line in open(FLAGS.room_data_filelist)]\n\nNUM_CLASSES = 13\n\ndef log_string(out_str):\n    LOG_FOUT.write(out_str+\'\\n\')\n    LOG_FOUT.flush()\n    print(out_str)\n\ndef evaluate():\n    is_training = False\n     \n    with tf.device(\'/gpu:\'+str(GPU_INDEX)):\n        pointclouds_pl, labels_pl = placeholder_inputs(BATCH_SIZE, NUM_POINT)\n        is_training_pl = tf.placeholder(tf.bool, shape=())\n\n        # simple model\n        pred = get_model(pointclouds_pl, is_training_pl)\n        loss = get_loss(pred, labels_pl)\n        pred_softmax = tf.nn.softmax(pred)\n \n        # Add ops to save and restore all the variables.\n        saver = tf.train.Saver()\n        \n    # Create a session\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    config.allow_soft_placement = True\n    config.log_device_placement = True\n    sess = tf.Session(config=config)\n\n    # Restore variables from disk.\n    saver.restore(sess, MODEL_PATH)\n    log_string(""Model restored."")\n\n    ops = {\'pointclouds_pl\': pointclouds_pl,\n           \'labels_pl\': labels_pl,\n           \'is_training_pl\': is_training_pl,\n           \'pred\': pred,\n           \'pred_softmax\': pred_softmax,\n           \'loss\': loss}\n    \n    total_correct = 0\n    total_seen = 0\n    fout_out_filelist = open(FLAGS.output_filelist, \'w\')\n    for room_path in ROOM_PATH_LIST:\n        out_data_label_filename = os.path.basename(room_path)[:-4] + \'_pred.txt\'\n        out_data_label_filename = os.path.join(DUMP_DIR, out_data_label_filename)\n        out_gt_label_filename = os.path.basename(room_path)[:-4] + \'_gt.txt\'\n        out_gt_label_filename = os.path.join(DUMP_DIR, out_gt_label_filename)\n        print(room_path, out_data_label_filename)\n        a, b = eval_one_epoch(sess, ops, room_path, out_data_label_filename, out_gt_label_filename)\n        total_correct += a\n        total_seen += b\n        fout_out_filelist.write(out_data_label_filename+\'\\n\')\n    fout_out_filelist.close()\n    log_string(\'all room eval accuracy: %f\'% (total_correct / float(total_seen)))\n\ndef eval_one_epoch(sess, ops, room_path, out_data_label_filename, out_gt_label_filename):\n    error_cnt = 0\n    is_training = False\n    total_correct = 0\n    total_seen = 0\n    loss_sum = 0\n    total_seen_class = [0 for _ in range(NUM_CLASSES)]\n    total_correct_class = [0 for _ in range(NUM_CLASSES)]\n    if FLAGS.visu:\n        fout = open(os.path.join(DUMP_DIR, os.path.basename(room_path)[:-4]+\'_pred.obj\'), \'w\')\n        fout_gt = open(os.path.join(DUMP_DIR, os.path.basename(room_path)[:-4]+\'_gt.obj\'), \'w\')\n    fout_data_label = open(out_data_label_filename, \'w\')\n    fout_gt_label = open(out_gt_label_filename, \'w\')\n    \n    current_data, current_label = indoor3d_util.room2blocks_wrapper_normalized(room_path, NUM_POINT)\n    current_data = current_data[:,0:NUM_POINT,:]\n    current_label = np.squeeze(current_label)\n    # Get room dimension..\n    data_label = np.load(room_path)\n    data = data_label[:,0:6]\n    max_room_x = max(data[:,0])\n    max_room_y = max(data[:,1])\n    max_room_z = max(data[:,2])\n    \n    file_size = current_data.shape[0]\n    num_batches = file_size // BATCH_SIZE\n    print(file_size)\n\n    \n    for batch_idx in range(num_batches):\n        start_idx = batch_idx * BATCH_SIZE\n        end_idx = (batch_idx+1) * BATCH_SIZE\n        cur_batch_size = end_idx - start_idx\n        \n        feed_dict = {ops[\'pointclouds_pl\']: current_data[start_idx:end_idx, :, :],\n                     ops[\'labels_pl\']: current_label[start_idx:end_idx],\n                     ops[\'is_training_pl\']: is_training}\n        loss_val, pred_val = sess.run([ops[\'loss\'], ops[\'pred_softmax\']],\n                                      feed_dict=feed_dict)\n\n        if FLAGS.no_clutter:\n            pred_label = np.argmax(pred_val[:,:,0:12], 2) # BxN\n        else:\n            pred_label = np.argmax(pred_val, 2) # BxN\n        # Save prediction labels to OBJ file\n        for b in range(BATCH_SIZE):\n            pts = current_data[start_idx+b, :, :]\n            l = current_label[start_idx+b,:]\n            pts[:,6] *= max_room_x\n            pts[:,7] *= max_room_y\n            pts[:,8] *= max_room_z\n            pts[:,3:6] *= 255.0\n            pred = pred_label[b, :]\n            for i in range(NUM_POINT):\n                color = indoor3d_util.g_label2color[pred[i]]\n                color_gt = indoor3d_util.g_label2color[current_label[start_idx+b, i]]\n                if FLAGS.visu:\n                    fout.write(\'v %f %f %f %d %d %d\\n\' % (pts[i,6], pts[i,7], pts[i,8], color[0], color[1], color[2]))\n                    fout_gt.write(\'v %f %f %f %d %d %d\\n\' % (pts[i,6], pts[i,7], pts[i,8], color_gt[0], color_gt[1], color_gt[2]))\n                fout_data_label.write(\'%f %f %f %d %d %d %f %d\\n\' % (pts[i,6], pts[i,7], pts[i,8], pts[i,3], pts[i,4], pts[i,5], pred_val[b,i,pred[i]], pred[i]))\n                fout_gt_label.write(\'%d\\n\' % (l[i]))\n        correct = np.sum(pred_label == current_label[start_idx:end_idx,:])\n        total_correct += correct\n        total_seen += (cur_batch_size*NUM_POINT)\n        loss_sum += (loss_val*BATCH_SIZE)\n        for i in range(start_idx, end_idx):\n            for j in range(NUM_POINT):\n                l = current_label[i, j]\n                total_seen_class[l] += 1\n                total_correct_class[l] += (pred_label[i-start_idx, j] == l)\n\n    log_string(\'eval mean loss: %f\' % (loss_sum / float(total_seen/NUM_POINT)))\n    log_string(\'eval accuracy: %f\'% (total_correct / float(total_seen)))\n    fout_data_label.close()\n    fout_gt_label.close()\n    if FLAGS.visu:\n        fout.close()\n        fout_gt.close()\n    return total_correct, total_seen\n\n\nif __name__==\'__main__\':\n    with tf.Graph().as_default():\n        evaluate()\n    LOG_FOUT.close()\n'"
sem_seg/collect_indoor3d_data.py,0,"b""import os\nimport sys\nBASE_DIR = os.path.dirname(os.path.abspath(__file__))\nROOT_DIR = os.path.dirname(BASE_DIR)\nsys.path.append(BASE_DIR)\nimport indoor3d_util\n\nanno_paths = [line.rstrip() for line in open(os.path.join(BASE_DIR, 'meta/anno_paths.txt'))]\nanno_paths = [os.path.join(indoor3d_util.DATA_PATH, p) for p in anno_paths]\n\noutput_folder = os.path.join(ROOT_DIR, 'data/stanford_indoor3d') \nif not os.path.exists(output_folder):\n    os.mkdir(output_folder)\n\n# Note: there is an extra character in the v1.2 data in Area_5/hallway_6. It's fixed manually.\nfor anno_path in anno_paths:\n    print(anno_path)\n    try:\n        elements = anno_path.split('/')\n        out_filename = elements[-3]+'_'+elements[-2]+'.npy' # Area_1_hallway_1.npy\n        indoor3d_util.collect_point_label(anno_path, os.path.join(output_folder, out_filename), 'numpy')\n    except:\n        print(anno_path, 'ERROR!!')\n"""
sem_seg/eval_iou_accuracy.py,0,"b""import numpy as np\n\npred_data_label_filenames = [line.rstrip() for line in open('all_pred_data_label_filelist.txt')]\ngt_label_filenames = [f.rstrip('_pred\\.txt') + '_gt.txt' for f in pred_data_label_filenames]\nnum_room = len(gt_label_filenames)\n\n\ngt_classes = [0 for _ in range(13)]\npositive_classes = [0 for _ in range(13)]\ntrue_positive_classes = [0 for _ in range(13)]\nfor i in range(num_room):\n    print(i)\n    data_label = np.loadtxt(pred_data_label_filenames[i])\n    pred_label = data_label[:,-1]\n    gt_label = np.loadtxt(gt_label_filenames[i])\n    print(gt_label.shape)\n    for j in xrange(gt_label.shape[0]):\n        gt_l = int(gt_label[j])\n        pred_l = int(pred_label[j])\n        gt_classes[gt_l] += 1\n        positive_classes[pred_l] += 1\n        true_positive_classes[gt_l] += int(gt_l==pred_l)\n\n\nprint(gt_classes)\nprint(positive_classes)\nprint(true_positive_classes)\n\n\nprint('Overall accuracy: {0}'.format(sum(true_positive_classes)/float(sum(positive_classes))))\n\nprint 'IoU:'\niou_list = []\nfor i in range(13):\n    iou = true_positive_classes[i]/float(gt_classes[i]+positive_classes[i]-true_positive_classes[i]) \n    print(iou)\n    iou_list.append(iou)\n\nprint(sum(iou_list)/13.0)\n"""
sem_seg/gen_indoor3d_h5.py,0,"b'import os\nimport numpy as np\nimport sys\nBASE_DIR = os.path.dirname(os.path.abspath(__file__))\nROOT_DIR = os.path.dirname(BASE_DIR)\nsys.path.append(BASE_DIR)\nsys.path.append(os.path.join(ROOT_DIR, \'utils\'))\nimport data_prep_util\nimport indoor3d_util\n\n# Constants\ndata_dir = os.path.join(ROOT_DIR, \'data\')\nindoor3d_data_dir = os.path.join(data_dir, \'stanford_indoor3d\')\nNUM_POINT = 4096\nH5_BATCH_SIZE = 1000\ndata_dim = [NUM_POINT, 9]\nlabel_dim = [NUM_POINT]\ndata_dtype = \'float32\'\nlabel_dtype = \'uint8\'\n\n# Set paths\nfilelist = os.path.join(BASE_DIR, \'meta/all_data_label.txt\')\ndata_label_files = [os.path.join(indoor3d_data_dir, line.rstrip()) for line in open(filelist)]\noutput_dir = os.path.join(data_dir, \'indoor3d_sem_seg_hdf5_data\')\nif not os.path.exists(output_dir):\n    os.mkdir(output_dir)\noutput_filename_prefix = os.path.join(output_dir, \'ply_data_all\')\noutput_room_filelist = os.path.join(output_dir, \'room_filelist.txt\')\nfout_room = open(output_room_filelist, \'w\')\n\n# --------------------------------------\n# ----- BATCH WRITE TO HDF5 -----\n# --------------------------------------\nbatch_data_dim = [H5_BATCH_SIZE] + data_dim\nbatch_label_dim = [H5_BATCH_SIZE] + label_dim\nh5_batch_data = np.zeros(batch_data_dim, dtype = np.float32)\nh5_batch_label = np.zeros(batch_label_dim, dtype = np.uint8)\nbuffer_size = 0  # state: record how many samples are currently in buffer\nh5_index = 0 # state: the next h5 file to save\n\ndef insert_batch(data, label, last_batch=False):\n    global h5_batch_data, h5_batch_label\n    global buffer_size, h5_index\n    data_size = data.shape[0]\n    # If there is enough space, just insert\n    if buffer_size + data_size <= h5_batch_data.shape[0]:\n        h5_batch_data[buffer_size:buffer_size+data_size, ...] = data\n        h5_batch_label[buffer_size:buffer_size+data_size] = label\n        buffer_size += data_size\n    else: # not enough space\n        capacity = h5_batch_data.shape[0] - buffer_size\n        assert(capacity>=0)\n        if capacity > 0:\n           h5_batch_data[buffer_size:buffer_size+capacity, ...] = data[0:capacity, ...] \n           h5_batch_label[buffer_size:buffer_size+capacity, ...] = label[0:capacity, ...] \n        # Save batch data and label to h5 file, reset buffer_size\n        h5_filename =  output_filename_prefix + \'_\' + str(h5_index) + \'.h5\'\n        data_prep_util.save_h5(h5_filename, h5_batch_data, h5_batch_label, data_dtype, label_dtype) \n        print(\'Stored {0} with size {1}\'.format(h5_filename, h5_batch_data.shape[0]))\n        h5_index += 1\n        buffer_size = 0\n        # recursive call\n        insert_batch(data[capacity:, ...], label[capacity:, ...], last_batch)\n    if last_batch and buffer_size > 0:\n        h5_filename =  output_filename_prefix + \'_\' + str(h5_index) + \'.h5\'\n        data_prep_util.save_h5(h5_filename, h5_batch_data[0:buffer_size, ...], h5_batch_label[0:buffer_size, ...], data_dtype, label_dtype)\n        print(\'Stored {0} with size {1}\'.format(h5_filename, buffer_size))\n        h5_index += 1\n        buffer_size = 0\n    return\n\n\nsample_cnt = 0\nfor i, data_label_filename in enumerate(data_label_files):\n    print(data_label_filename)\n    data, label = indoor3d_util.room2blocks_wrapper_normalized(data_label_filename, NUM_POINT, block_size=1.0, stride=0.5,\n                                                 random_sample=False, sample_num=None)\n    print(\'{0}, {1}\'.format(data.shape, label.shape))\n    for _ in range(data.shape[0]):\n        fout_room.write(os.path.basename(data_label_filename)[0:-4]+\'\\n\')\n\n    sample_cnt += data.shape[0]\n    insert_batch(data, label, i == len(data_label_files)-1)\n\nfout_room.close()\nprint(""Total samples: {0}"".format(sample_cnt))\n'"
sem_seg/indoor3d_util.py,0,"b'import numpy as np\nimport glob\nimport os\nimport sys\nBASE_DIR = os.path.dirname(os.path.abspath(__file__))\nROOT_DIR = os.path.dirname(BASE_DIR)\nsys.path.append(BASE_DIR)\n\n# -----------------------------------------------------------------------------\n# CONSTANTS\n# -----------------------------------------------------------------------------\n\nDATA_PATH = os.path.join(ROOT_DIR, \'data\', \'Stanford3dDataset_v1.2_Aligned_Version\')\ng_classes = [x.rstrip() for x in open(os.path.join(BASE_DIR, \'meta/class_names.txt\'))]\ng_class2label = {cls: i for i,cls in enumerate(g_classes)}\ng_class2color = {\'ceiling\':\t[0,255,0],\n                 \'floor\':\t[0,0,255],\n                 \'wall\':\t[0,255,255],\n                 \'beam\':        [255,255,0],\n                 \'column\':      [255,0,255],\n                 \'window\':      [100,100,255],\n                 \'door\':        [200,200,100],\n                 \'table\':       [170,120,200],\n                 \'chair\':       [255,0,0],\n                 \'sofa\':        [200,100,100],\n                 \'bookcase\':    [10,200,100],\n                 \'board\':       [200,200,200],\n                 \'clutter\':     [50,50,50]} \ng_easy_view_labels = [7,8,9,10,11,1]\ng_label2color = {g_classes.index(cls): g_class2color[cls] for cls in g_classes}\n\n\n# -----------------------------------------------------------------------------\n# CONVERT ORIGINAL DATA TO OUR DATA_LABEL FILES\n# -----------------------------------------------------------------------------\n\ndef collect_point_label(anno_path, out_filename, file_format=\'txt\'):\n    """""" Convert original dataset files to data_label file (each line is XYZRGBL).\n        We aggregated all the points from each instance in the room.\n\n    Args:\n        anno_path: path to annotations. e.g. Area_1/office_2/Annotations/\n        out_filename: path to save collected points and labels (each line is XYZRGBL)\n        file_format: txt or numpy, determines what file format to save.\n    Returns:\n        None\n    Note:\n        the points are shifted before save, the most negative point is now at origin.\n    """"""\n    points_list = []\n    \n    for f in glob.glob(os.path.join(anno_path, \'*.txt\')):\n        cls = os.path.basename(f).split(\'_\')[0]\n        if cls not in g_classes: # note: in some room there is \'staris\' class..\n            cls = \'clutter\'\n        points = np.loadtxt(f)\n        labels = np.ones((points.shape[0],1)) * g_class2label[cls]\n        points_list.append(np.concatenate([points, labels], 1)) # Nx7\n    \n    data_label = np.concatenate(points_list, 0)\n    xyz_min = np.amin(data_label, axis=0)[0:3]\n    data_label[:, 0:3] -= xyz_min\n    \n    if file_format==\'txt\':\n        fout = open(out_filename, \'w\')\n        for i in range(data_label.shape[0]):\n            fout.write(\'%f %f %f %d %d %d %d\\n\' % \\\n                          (data_label[i,0], data_label[i,1], data_label[i,2],\n                           data_label[i,3], data_label[i,4], data_label[i,5],\n                           data_label[i,6]))\n        fout.close()\n    elif file_format==\'numpy\':\n        np.save(out_filename, data_label)\n    else:\n        print(\'ERROR!! Unknown file format: %s, please use txt or numpy.\' % \\\n            (file_format))\n        exit()\n\ndef point_label_to_obj(input_filename, out_filename, label_color=True, easy_view=False, no_wall=False):\n    """""" For visualization of a room from data_label file,\n\tinput_filename: each line is X Y Z R G B L\n\tout_filename: OBJ filename,\n            visualize input file by coloring point with label color\n        easy_view: only visualize furnitures and floor\n    """"""\n    data_label = np.loadtxt(input_filename)\n    data = data_label[:, 0:6]\n    label = data_label[:, -1].astype(int)\n    fout = open(out_filename, \'w\')\n    for i in range(data.shape[0]):\n        color = g_label2color[label[i]]\n        if easy_view and (label[i] not in g_easy_view_labels):\n            continue\n        if no_wall and ((label[i] == 2) or (label[i]==0)):\n            continue\n        if label_color:\n            fout.write(\'v %f %f %f %d %d %d\\n\' % \\\n                (data[i,0], data[i,1], data[i,2], color[0], color[1], color[2]))\n        else:\n            fout.write(\'v %f %f %f %d %d %d\\n\' % \\\n                (data[i,0], data[i,1], data[i,2], data[i,3], data[i,4], data[i,5]))\n    fout.close()\n \n\n\n# -----------------------------------------------------------------------------\n# PREPARE BLOCK DATA FOR DEEPNETS TRAINING/TESTING\n# -----------------------------------------------------------------------------\n\ndef sample_data(data, num_sample):\n    """""" data is in N x ...\n        we want to keep num_samplexC of them.\n        if N > num_sample, we will randomly keep num_sample of them.\n        if N < num_sample, we will randomly duplicate samples.\n    """"""\n    N = data.shape[0]\n    if (N == num_sample):\n        return data, range(N)\n    elif (N > num_sample):\n        sample = np.random.choice(N, num_sample)\n        return data[sample, ...], sample\n    else:\n        sample = np.random.choice(N, num_sample-N)\n        dup_data = data[sample, ...]\n        return np.concatenate([data, dup_data], 0), range(N)+list(sample)\n\ndef sample_data_label(data, label, num_sample):\n    new_data, sample_indices = sample_data(data, num_sample)\n    new_label = label[sample_indices]\n    return new_data, new_label\n    \ndef room2blocks(data, label, num_point, block_size=1.0, stride=1.0,\n                random_sample=False, sample_num=None, sample_aug=1):\n    """""" Prepare block training data.\n    Args:\n        data: N x 6 numpy array, 012 are XYZ in meters, 345 are RGB in [0,1]\n            assumes the data is shifted (min point is origin) and aligned\n            (aligned with XYZ axis)\n        label: N size uint8 numpy array from 0-12\n        num_point: int, how many points to sample in each block\n        block_size: float, physical size of the block in meters\n        stride: float, stride for block sweeping\n        random_sample: bool, if True, we will randomly sample blocks in the room\n        sample_num: int, if random sample, how many blocks to sample\n            [default: room area]\n        sample_aug: if random sample, how much aug\n    Returns:\n        block_datas: K x num_point x 6 np array of XYZRGB, RGB is in [0,1]\n        block_labels: K x num_point x 1 np array of uint8 labels\n        \n    TODO: for this version, blocking is in fixed, non-overlapping pattern.\n    """"""\n    assert(stride<=block_size)\n\n    limit = np.amax(data, 0)[0:3]\n     \n    # Get the corner location for our sampling blocks    \n    xbeg_list = []\n    ybeg_list = []\n    if not random_sample:\n        num_block_x = int(np.ceil((limit[0] - block_size) / stride)) + 1\n        num_block_y = int(np.ceil((limit[1] - block_size) / stride)) + 1\n        for i in range(num_block_x):\n            for j in range(num_block_y):\n                xbeg_list.append(i*stride)\n                ybeg_list.append(j*stride)\n    else:\n        num_block_x = int(np.ceil(limit[0] / block_size))\n        num_block_y = int(np.ceil(limit[1] / block_size))\n        if sample_num is None:\n            sample_num = num_block_x * num_block_y * sample_aug\n        for _ in range(sample_num):\n            xbeg = np.random.uniform(-block_size, limit[0]) \n            ybeg = np.random.uniform(-block_size, limit[1]) \n            xbeg_list.append(xbeg)\n            ybeg_list.append(ybeg)\n\n    # Collect blocks\n    block_data_list = []\n    block_label_list = []\n    idx = 0\n    for idx in range(len(xbeg_list)): \n       xbeg = xbeg_list[idx]\n       ybeg = ybeg_list[idx]\n       xcond = (data[:,0]<=xbeg+block_size) & (data[:,0]>=xbeg)\n       ycond = (data[:,1]<=ybeg+block_size) & (data[:,1]>=ybeg)\n       cond = xcond & ycond\n       if np.sum(cond) < 100: # discard block if there are less than 100 pts.\n           continue\n       \n       block_data = data[cond, :]\n       block_label = label[cond]\n       \n       # randomly subsample data\n       block_data_sampled, block_label_sampled = \\\n           sample_data_label(block_data, block_label, num_point)\n       block_data_list.append(np.expand_dims(block_data_sampled, 0))\n       block_label_list.append(np.expand_dims(block_label_sampled, 0))\n            \n    return np.concatenate(block_data_list, 0), \\\n           np.concatenate(block_label_list, 0)\n\n\ndef room2blocks_plus(data_label, num_point, block_size, stride,\n                     random_sample, sample_num, sample_aug):\n    """""" room2block with input filename and RGB preprocessing.\n    """"""\n    data = data_label[:,0:6]\n    data[:,3:6] /= 255.0\n    label = data_label[:,-1].astype(np.uint8)\n    \n    return room2blocks(data, label, num_point, block_size, stride,\n                       random_sample, sample_num, sample_aug)\n   \ndef room2blocks_wrapper(data_label_filename, num_point, block_size=1.0, stride=1.0,\n                        random_sample=False, sample_num=None, sample_aug=1):\n    if data_label_filename[-3:] == \'txt\':\n        data_label = np.loadtxt(data_label_filename)\n    elif data_label_filename[-3:] == \'npy\':\n        data_label = np.load(data_label_filename)\n    else:\n        print(\'Unknown file type! exiting.\')\n        exit()\n    return room2blocks_plus(data_label, num_point, block_size, stride,\n                            random_sample, sample_num, sample_aug)\n\ndef room2blocks_plus_normalized(data_label, num_point, block_size, stride,\n                                random_sample, sample_num, sample_aug):\n    """""" room2block, with input filename and RGB preprocessing.\n        for each block centralize XYZ, add normalized XYZ as 678 channels\n    """"""\n    data = data_label[:,0:6]\n    data[:,3:6] /= 255.0\n    label = data_label[:,-1].astype(np.uint8)\n    max_room_x = max(data[:,0])\n    max_room_y = max(data[:,1])\n    max_room_z = max(data[:,2])\n    \n    data_batch, label_batch = room2blocks(data, label, num_point, block_size, stride,\n                                          random_sample, sample_num, sample_aug)\n    new_data_batch = np.zeros((data_batch.shape[0], num_point, 9))\n    for b in range(data_batch.shape[0]):\n        new_data_batch[b, :, 6] = data_batch[b, :, 0]/max_room_x\n        new_data_batch[b, :, 7] = data_batch[b, :, 1]/max_room_y\n        new_data_batch[b, :, 8] = data_batch[b, :, 2]/max_room_z\n        minx = min(data_batch[b, :, 0])\n        miny = min(data_batch[b, :, 1])\n        data_batch[b, :, 0] -= (minx+block_size/2)\n        data_batch[b, :, 1] -= (miny+block_size/2)\n    new_data_batch[:, :, 0:6] = data_batch\n    return new_data_batch, label_batch\n\n\ndef room2blocks_wrapper_normalized(data_label_filename, num_point, block_size=1.0, stride=1.0,\n                                   random_sample=False, sample_num=None, sample_aug=1):\n    if data_label_filename[-3:] == \'txt\':\n        data_label = np.loadtxt(data_label_filename)\n    elif data_label_filename[-3:] == \'npy\':\n        data_label = np.load(data_label_filename)\n    else:\n        print(\'Unknown file type! exiting.\')\n        exit()\n    return room2blocks_plus_normalized(data_label, num_point, block_size, stride,\n                                       random_sample, sample_num, sample_aug)\n\ndef room2samples(data, label, sample_num_point):\n    """""" Prepare whole room samples.\n\n    Args:\n        data: N x 6 numpy array, 012 are XYZ in meters, 345 are RGB in [0,1]\n            assumes the data is shifted (min point is origin) and\n            aligned (aligned with XYZ axis)\n        label: N size uint8 numpy array from 0-12\n        sample_num_point: int, how many points to sample in each sample\n    Returns:\n        sample_datas: K x sample_num_point x 9\n                     numpy array of XYZRGBX\'Y\'Z\', RGB is in [0,1]\n        sample_labels: K x sample_num_point x 1 np array of uint8 labels\n    """"""\n    N = data.shape[0]\n    order = np.arange(N)\n    np.random.shuffle(order) \n    data = data[order, :]\n    label = label[order]\n\n    batch_num = int(np.ceil(N / float(sample_num_point)))\n    sample_datas = np.zeros((batch_num, sample_num_point, 6))\n    sample_labels = np.zeros((batch_num, sample_num_point, 1))\n\n    for i in range(batch_num):\n        beg_idx = i*sample_num_point\n        end_idx = min((i+1)*sample_num_point, N)\n        num = end_idx - beg_idx\n        sample_datas[i,0:num,:] = data[beg_idx:end_idx, :]\n        sample_labels[i,0:num,0] = label[beg_idx:end_idx]\n        if num < sample_num_point:\n            makeup_indices = np.random.choice(N, sample_num_point - num)\n            sample_datas[i,num:,:] = data[makeup_indices, :]\n            sample_labels[i,num:,0] = label[makeup_indices]\n    return sample_datas, sample_labels\n\ndef room2samples_plus_normalized(data_label, num_point):\n    """""" room2sample, with input filename and RGB preprocessing.\n        for each block centralize XYZ, add normalized XYZ as 678 channels\n    """"""\n    data = data_label[:,0:6]\n    data[:,3:6] /= 255.0\n    label = data_label[:,-1].astype(np.uint8)\n    max_room_x = max(data[:,0])\n    max_room_y = max(data[:,1])\n    max_room_z = max(data[:,2])\n    #print(max_room_x, max_room_y, max_room_z)\n    \n    data_batch, label_batch = room2samples(data, label, num_point)\n    new_data_batch = np.zeros((data_batch.shape[0], num_point, 9))\n    for b in range(data_batch.shape[0]):\n        new_data_batch[b, :, 6] = data_batch[b, :, 0]/max_room_x\n        new_data_batch[b, :, 7] = data_batch[b, :, 1]/max_room_y\n        new_data_batch[b, :, 8] = data_batch[b, :, 2]/max_room_z\n        #minx = min(data_batch[b, :, 0])\n        #miny = min(data_batch[b, :, 1])\n        #data_batch[b, :, 0] -= (minx+block_size/2)\n        #data_batch[b, :, 1] -= (miny+block_size/2)\n    new_data_batch[:, :, 0:6] = data_batch\n    return new_data_batch, label_batch\n\n\ndef room2samples_wrapper_normalized(data_label_filename, num_point):\n    if data_label_filename[-3:] == \'txt\':\n        data_label = np.loadtxt(data_label_filename)\n    elif data_label_filename[-3:] == \'npy\':\n        data_label = np.load(data_label_filename)\n    else:\n        print(\'Unknown file type! exiting.\')\n        exit()\n    return room2samples_plus_normalized(data_label, num_point)\n\n\n# -----------------------------------------------------------------------------\n# EXTRACT INSTANCE BBOX FROM ORIGINAL DATA (for detection evaluation)\n# -----------------------------------------------------------------------------\n\ndef collect_bounding_box(anno_path, out_filename):\n    """""" Compute bounding boxes from each instance in original dataset files on\n        one room. **We assume the bbox is aligned with XYZ coordinate.**\n    \n    Args:\n        anno_path: path to annotations. e.g. Area_1/office_2/Annotations/\n        out_filename: path to save instance bounding boxes for that room.\n            each line is x1 y1 z1 x2 y2 z2 label,\n            where (x1,y1,z1) is the point on the diagonal closer to origin\n    Returns:\n        None\n    Note:\n        room points are shifted, the most negative point is now at origin.\n    """"""\n    bbox_label_list = []\n\n    for f in glob.glob(os.path.join(anno_path, \'*.txt\')):\n        cls = os.path.basename(f).split(\'_\')[0]\n        if cls not in g_classes: # note: in some room there is \'staris\' class..\n            cls = \'clutter\'\n        points = np.loadtxt(f)\n        label = g_class2label[cls]\n        # Compute tightest axis aligned bounding box\n        xyz_min = np.amin(points[:, 0:3], axis=0)\n        xyz_max = np.amax(points[:, 0:3], axis=0)\n        ins_bbox_label = np.expand_dims(\n            np.concatenate([xyz_min, xyz_max, np.array([label])], 0), 0)\n        bbox_label_list.append(ins_bbox_label)\n\n    bbox_label = np.concatenate(bbox_label_list, 0)\n    room_xyz_min = np.amin(bbox_label[:, 0:3], axis=0)\n    bbox_label[:, 0:3] -= room_xyz_min \n    bbox_label[:, 3:6] -= room_xyz_min \n\n    fout = open(out_filename, \'w\')\n    for i in range(bbox_label.shape[0]):\n        fout.write(\'%f %f %f %f %f %f %d\\n\' % \\\n                      (bbox_label[i,0], bbox_label[i,1], bbox_label[i,2],\n                       bbox_label[i,3], bbox_label[i,4], bbox_label[i,5],\n                       bbox_label[i,6]))\n    fout.close()\n\ndef bbox_label_to_obj(input_filename, out_filename_prefix, easy_view=False):\n    """""" Visualization of bounding boxes.\n    \n    Args:\n        input_filename: each line is x1 y1 z1 x2 y2 z2 label\n        out_filename_prefix: OBJ filename prefix,\n            visualize object by g_label2color\n        easy_view: if True, only visualize furniture and floor\n    Returns:\n        output a list of OBJ file and MTL files with the same prefix\n    """"""\n    bbox_label = np.loadtxt(input_filename)\n    bbox = bbox_label[:, 0:6]\n    label = bbox_label[:, -1].astype(int)\n    v_cnt = 0 # count vertex\n    ins_cnt = 0 # count instance\n    for i in range(bbox.shape[0]):\n        if easy_view and (label[i] not in g_easy_view_labels):\n            continue\n        obj_filename = out_filename_prefix+\'_\'+g_classes[label[i]]+\'_\'+str(ins_cnt)+\'.obj\'\n        mtl_filename = out_filename_prefix+\'_\'+g_classes[label[i]]+\'_\'+str(ins_cnt)+\'.mtl\'\n        fout_obj = open(obj_filename, \'w\')\n        fout_mtl = open(mtl_filename, \'w\')\n        fout_obj.write(\'mtllib %s\\n\' % (os.path.basename(mtl_filename)))\n\n        length = bbox[i, 3:6] - bbox[i, 0:3]\n        a = length[0]\n        b = length[1]\n        c = length[2]\n        x = bbox[i, 0]\n        y = bbox[i, 1]\n        z = bbox[i, 2]\n        color = np.array(g_label2color[label[i]], dtype=float) / 255.0\n\n        material = \'material%d\' % (ins_cnt)\n        fout_obj.write(\'usemtl %s\\n\' % (material))\n        fout_obj.write(\'v %f %f %f\\n\' % (x,y,z+c))\n        fout_obj.write(\'v %f %f %f\\n\' % (x,y+b,z+c))\n        fout_obj.write(\'v %f %f %f\\n\' % (x+a,y+b,z+c))\n        fout_obj.write(\'v %f %f %f\\n\' % (x+a,y,z+c))\n        fout_obj.write(\'v %f %f %f\\n\' % (x,y,z))\n        fout_obj.write(\'v %f %f %f\\n\' % (x,y+b,z))\n        fout_obj.write(\'v %f %f %f\\n\' % (x+a,y+b,z))\n        fout_obj.write(\'v %f %f %f\\n\' % (x+a,y,z))\n        fout_obj.write(\'g default\\n\')\n        v_cnt = 0 # for individual box\n        fout_obj.write(\'f %d %d %d %d\\n\' % (4+v_cnt, 3+v_cnt, 2+v_cnt, 1+v_cnt))\n        fout_obj.write(\'f %d %d %d %d\\n\' % (1+v_cnt, 2+v_cnt, 6+v_cnt, 5+v_cnt))\n        fout_obj.write(\'f %d %d %d %d\\n\' % (7+v_cnt, 6+v_cnt, 2+v_cnt, 3+v_cnt))\n        fout_obj.write(\'f %d %d %d %d\\n\' % (4+v_cnt, 8+v_cnt, 7+v_cnt, 3+v_cnt))\n        fout_obj.write(\'f %d %d %d %d\\n\' % (5+v_cnt, 8+v_cnt, 4+v_cnt, 1+v_cnt))\n        fout_obj.write(\'f %d %d %d %d\\n\' % (5+v_cnt, 6+v_cnt, 7+v_cnt, 8+v_cnt))\n        fout_obj.write(\'\\n\')\n\n        fout_mtl.write(\'newmtl %s\\n\' % (material))\n        fout_mtl.write(\'Kd %f %f %f\\n\' % (color[0], color[1], color[2]))\n        fout_mtl.write(\'\\n\')\n        fout_obj.close()\n        fout_mtl.close() \n\n        v_cnt += 8\n        ins_cnt += 1\n\ndef bbox_label_to_obj_room(input_filename, out_filename_prefix, easy_view=False, permute=None, center=False, exclude_table=False):\n    """""" Visualization of bounding boxes.\n    \n    Args:\n        input_filename: each line is x1 y1 z1 x2 y2 z2 label\n        out_filename_prefix: OBJ filename prefix,\n            visualize object by g_label2color\n        easy_view: if True, only visualize furniture and floor\n        permute: if not None, permute XYZ for rendering, e.g. [0 2 1]\n        center: if True, move obj to have zero origin\n    Returns:\n        output a list of OBJ file and MTL files with the same prefix\n    """"""\n    bbox_label = np.loadtxt(input_filename)\n    bbox = bbox_label[:, 0:6]\n    if permute is not None:\n        assert(len(permute)==3)\n        permute = np.array(permute)\n        bbox[:,0:3] = bbox[:,permute]\n        bbox[:,3:6] = bbox[:,permute+3]\n    if center:\n        xyz_max = np.amax(bbox[:,3:6], 0)\n        bbox[:,0:3] -= (xyz_max/2.0)\n        bbox[:,3:6] -= (xyz_max/2.0)\n        bbox /= np.max(xyz_max/2.0)\n    label = bbox_label[:, -1].astype(int)\n    obj_filename = out_filename_prefix+\'.obj\' \n    mtl_filename = out_filename_prefix+\'.mtl\'\n\n    fout_obj = open(obj_filename, \'w\')\n    fout_mtl = open(mtl_filename, \'w\')\n    fout_obj.write(\'mtllib %s\\n\' % (os.path.basename(mtl_filename)))\n    v_cnt = 0 # count vertex\n    ins_cnt = 0 # count instance\n    for i in range(bbox.shape[0]):\n        if easy_view and (label[i] not in g_easy_view_labels):\n            continue\n        if exclude_table and label[i] == g_classes.index(\'table\'):\n            continue\n\n        length = bbox[i, 3:6] - bbox[i, 0:3]\n        a = length[0]\n        b = length[1]\n        c = length[2]\n        x = bbox[i, 0]\n        y = bbox[i, 1]\n        z = bbox[i, 2]\n        color = np.array(g_label2color[label[i]], dtype=float) / 255.0\n\n        material = \'material%d\' % (ins_cnt)\n        fout_obj.write(\'usemtl %s\\n\' % (material))\n        fout_obj.write(\'v %f %f %f\\n\' % (x,y,z+c))\n        fout_obj.write(\'v %f %f %f\\n\' % (x,y+b,z+c))\n        fout_obj.write(\'v %f %f %f\\n\' % (x+a,y+b,z+c))\n        fout_obj.write(\'v %f %f %f\\n\' % (x+a,y,z+c))\n        fout_obj.write(\'v %f %f %f\\n\' % (x,y,z))\n        fout_obj.write(\'v %f %f %f\\n\' % (x,y+b,z))\n        fout_obj.write(\'v %f %f %f\\n\' % (x+a,y+b,z))\n        fout_obj.write(\'v %f %f %f\\n\' % (x+a,y,z))\n        fout_obj.write(\'g default\\n\')\n        fout_obj.write(\'f %d %d %d %d\\n\' % (4+v_cnt, 3+v_cnt, 2+v_cnt, 1+v_cnt))\n        fout_obj.write(\'f %d %d %d %d\\n\' % (1+v_cnt, 2+v_cnt, 6+v_cnt, 5+v_cnt))\n        fout_obj.write(\'f %d %d %d %d\\n\' % (7+v_cnt, 6+v_cnt, 2+v_cnt, 3+v_cnt))\n        fout_obj.write(\'f %d %d %d %d\\n\' % (4+v_cnt, 8+v_cnt, 7+v_cnt, 3+v_cnt))\n        fout_obj.write(\'f %d %d %d %d\\n\' % (5+v_cnt, 8+v_cnt, 4+v_cnt, 1+v_cnt))\n        fout_obj.write(\'f %d %d %d %d\\n\' % (5+v_cnt, 6+v_cnt, 7+v_cnt, 8+v_cnt))\n        fout_obj.write(\'\\n\')\n\n        fout_mtl.write(\'newmtl %s\\n\' % (material))\n        fout_mtl.write(\'Kd %f %f %f\\n\' % (color[0], color[1], color[2]))\n        fout_mtl.write(\'\\n\')\n\n        v_cnt += 8\n        ins_cnt += 1\n\n    fout_obj.close()\n    fout_mtl.close() \n\n\ndef collect_point_bounding_box(anno_path, out_filename, file_format):\n    """""" Compute bounding boxes from each instance in original dataset files on\n        one room. **We assume the bbox is aligned with XYZ coordinate.**\n        Save both the point XYZRGB and the bounding box for the point\'s\n        parent element.\n \n    Args:\n        anno_path: path to annotations. e.g. Area_1/office_2/Annotations/\n        out_filename: path to save instance bounding boxes for each point,\n            plus the point\'s XYZRGBL\n            each line is XYZRGBL offsetX offsetY offsetZ a b c,\n            where cx = X+offsetX, cy=X+offsetY, cz=Z+offsetZ\n            where (cx,cy,cz) is center of the box, a,b,c are distances from center\n            to the surfaces of the box, i.e. x1 = cx-a, x2 = cx+a, y1=cy-b etc.\n        file_format: output file format, txt or numpy\n    Returns:\n        None\n\n    Note:\n        room points are shifted, the most negative point is now at origin.\n    """"""\n    point_bbox_list = []\n\n    for f in glob.glob(os.path.join(anno_path, \'*.txt\')):\n        cls = os.path.basename(f).split(\'_\')[0]\n        if cls not in g_classes: # note: in some room there is \'staris\' class..\n            cls = \'clutter\'\n        points = np.loadtxt(f) # Nx6\n        label = g_class2label[cls] # N,\n        # Compute tightest axis aligned bounding box\n        xyz_min = np.amin(points[:, 0:3], axis=0) # 3,\n        xyz_max = np.amax(points[:, 0:3], axis=0) # 3,\n        xyz_center = (xyz_min + xyz_max) / 2\n        dimension = (xyz_max - xyz_min) / 2\n\n        xyz_offsets = xyz_center - points[:,0:3] # Nx3\n        dimensions = np.ones((points.shape[0],3)) * dimension # Nx3\n        labels = np.ones((points.shape[0],1)) * label # N\n        point_bbox_list.append(np.concatenate([points, labels,\n                                           xyz_offsets, dimensions], 1)) # Nx13\n\n    point_bbox = np.concatenate(point_bbox_list, 0) # KxNx13\n    room_xyz_min = np.amin(point_bbox[:, 0:3], axis=0)\n    point_bbox[:, 0:3] -= room_xyz_min \n\n    if file_format == \'txt\':\n        fout = open(out_filename, \'w\')\n        for i in range(point_bbox.shape[0]):\n            fout.write(\'%f %f %f %d %d %d %d %f %f %f %f %f %f\\n\' % \\\n                          (point_bbox[i,0], point_bbox[i,1], point_bbox[i,2],\n                           point_bbox[i,3], point_bbox[i,4], point_bbox[i,5],\n                           point_bbox[i,6],\n                           point_bbox[i,7], point_bbox[i,8], point_bbox[i,9],\n                           point_bbox[i,10], point_bbox[i,11], point_bbox[i,12]))\n        \n        fout.close()\n    elif file_format == \'numpy\':\n        np.save(out_filename, point_bbox)\n    else:\n        print(\'ERROR!! Unknown file format: %s, please use txt or numpy.\' % \\\n            (file_format))\n        exit()\n\n\n'"
sem_seg/model.py,14,"b'import tensorflow as tf\nimport math\nimport time\nimport numpy as np\nimport os\nimport sys\nBASE_DIR = os.path.dirname(os.path.abspath(__file__))\nROOT_DIR = os.path.dirname(BASE_DIR)\nsys.path.append(os.path.join(ROOT_DIR, \'utils\'))\nimport tf_util\n\ndef placeholder_inputs(batch_size, num_point):\n    pointclouds_pl = tf.placeholder(tf.float32,\n                                     shape=(batch_size, num_point, 9))\n    labels_pl = tf.placeholder(tf.int32,\n                                shape=(batch_size, num_point))\n    return pointclouds_pl, labels_pl\n\ndef get_model(point_cloud, is_training, bn_decay=None):\n    """""" ConvNet baseline, input is BxNx3 gray image """"""\n    batch_size = point_cloud.get_shape()[0].value\n    num_point = point_cloud.get_shape()[1].value\n\n    input_image = tf.expand_dims(point_cloud, -1)\n    # CONV\n    net = tf_util.conv2d(input_image, 64, [1,9], padding=\'VALID\', stride=[1,1],\n                         bn=True, is_training=is_training, scope=\'conv1\', bn_decay=bn_decay)\n    net = tf_util.conv2d(net, 64, [1,1], padding=\'VALID\', stride=[1,1],\n                         bn=True, is_training=is_training, scope=\'conv2\', bn_decay=bn_decay)\n    net = tf_util.conv2d(net, 64, [1,1], padding=\'VALID\', stride=[1,1],\n                         bn=True, is_training=is_training, scope=\'conv3\', bn_decay=bn_decay)\n    net = tf_util.conv2d(net, 128, [1,1], padding=\'VALID\', stride=[1,1],\n                         bn=True, is_training=is_training, scope=\'conv4\', bn_decay=bn_decay)\n    points_feat1 = tf_util.conv2d(net, 1024, [1,1], padding=\'VALID\', stride=[1,1],\n                         bn=True, is_training=is_training, scope=\'conv5\', bn_decay=bn_decay)\n    # MAX\n    pc_feat1 = tf_util.max_pool2d(points_feat1, [num_point,1], padding=\'VALID\', scope=\'maxpool1\')\n    # FC\n    pc_feat1 = tf.reshape(pc_feat1, [batch_size, -1])\n    pc_feat1 = tf_util.fully_connected(pc_feat1, 256, bn=True, is_training=is_training, scope=\'fc1\', bn_decay=bn_decay)\n    pc_feat1 = tf_util.fully_connected(pc_feat1, 128, bn=True, is_training=is_training, scope=\'fc2\', bn_decay=bn_decay)\n    print(pc_feat1)\n   \n    # CONCAT \n    pc_feat1_expand = tf.tile(tf.reshape(pc_feat1, [batch_size, 1, 1, -1]), [1, num_point, 1, 1])\n    points_feat1_concat = tf.concat(axis=3, values=[points_feat1, pc_feat1_expand])\n    \n    # CONV \n    net = tf_util.conv2d(points_feat1_concat, 512, [1,1], padding=\'VALID\', stride=[1,1],\n                         bn=True, is_training=is_training, scope=\'conv6\')\n    net = tf_util.conv2d(net, 256, [1,1], padding=\'VALID\', stride=[1,1],\n                         bn=True, is_training=is_training, scope=\'conv7\')\n    net = tf_util.dropout(net, keep_prob=0.7, is_training=is_training, scope=\'dp1\')\n    net = tf_util.conv2d(net, 13, [1,1], padding=\'VALID\', stride=[1,1],\n                         activation_fn=None, scope=\'conv8\')\n    net = tf.squeeze(net, [2])\n\n    return net\n\ndef get_loss(pred, label):\n    """""" pred: B,N,13\n        label: B,N """"""\n    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=pred, labels=label)\n    return tf.reduce_mean(loss)\n\nif __name__ == ""__main__"":\n    with tf.Graph().as_default():\n        a = tf.placeholder(tf.float32, shape=(32,4096,9))\n        net = get_model(a, tf.constant(True))\n        with tf.Session() as sess:\n            init = tf.global_variables_initializer()\n            sess.run(init)\n            start = time.time()\n            for i in range(100):\n                print(i)\n                sess.run(net, feed_dict={a:np.random.rand(32,4096,9)})\n            print(time.time() - start)\n'"
sem_seg/train.py,23,"b'import argparse\nimport math\nimport h5py\nimport numpy as np\nimport tensorflow as tf\nimport socket\n\nimport os\nimport sys\nBASE_DIR = os.path.dirname(os.path.abspath(__file__))\nROOT_DIR = os.path.dirname(BASE_DIR)\nsys.path.append(BASE_DIR)\nsys.path.append(ROOT_DIR)\nsys.path.append(os.path.join(ROOT_DIR, \'utils\'))\nimport provider\nimport tf_util\nfrom model import *\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\'--gpu\', type=int, default=0, help=\'GPU to use [default: GPU 0]\')\nparser.add_argument(\'--log_dir\', default=\'log\', help=\'Log dir [default: log]\')\nparser.add_argument(\'--num_point\', type=int, default=4096, help=\'Point number [default: 4096]\')\nparser.add_argument(\'--max_epoch\', type=int, default=50, help=\'Epoch to run [default: 50]\')\nparser.add_argument(\'--batch_size\', type=int, default=24, help=\'Batch Size during training [default: 24]\')\nparser.add_argument(\'--learning_rate\', type=float, default=0.001, help=\'Initial learning rate [default: 0.001]\')\nparser.add_argument(\'--momentum\', type=float, default=0.9, help=\'Initial learning rate [default: 0.9]\')\nparser.add_argument(\'--optimizer\', default=\'adam\', help=\'adam or momentum [default: adam]\')\nparser.add_argument(\'--decay_step\', type=int, default=300000, help=\'Decay step for lr decay [default: 300000]\')\nparser.add_argument(\'--decay_rate\', type=float, default=0.5, help=\'Decay rate for lr decay [default: 0.5]\')\nparser.add_argument(\'--test_area\', type=int, default=6, help=\'Which area to use for test, option: 1-6 [default: 6]\')\nFLAGS = parser.parse_args()\n\n\nBATCH_SIZE = FLAGS.batch_size\nNUM_POINT = FLAGS.num_point\nMAX_EPOCH = FLAGS.max_epoch\nNUM_POINT = FLAGS.num_point\nBASE_LEARNING_RATE = FLAGS.learning_rate\nGPU_INDEX = FLAGS.gpu\nMOMENTUM = FLAGS.momentum\nOPTIMIZER = FLAGS.optimizer\nDECAY_STEP = FLAGS.decay_step\nDECAY_RATE = FLAGS.decay_rate\n\nLOG_DIR = FLAGS.log_dir\nif not os.path.exists(LOG_DIR): os.mkdir(LOG_DIR)\nos.system(\'cp model.py %s\' % (LOG_DIR)) # bkp of model def\nos.system(\'cp train.py %s\' % (LOG_DIR)) # bkp of train procedure\nLOG_FOUT = open(os.path.join(LOG_DIR, \'log_train.txt\'), \'w\')\nLOG_FOUT.write(str(FLAGS)+\'\\n\')\n\nMAX_NUM_POINT = 4096\nNUM_CLASSES = 13\n\nBN_INIT_DECAY = 0.5\nBN_DECAY_DECAY_RATE = 0.5\n#BN_DECAY_DECAY_STEP = float(DECAY_STEP * 2)\nBN_DECAY_DECAY_STEP = float(DECAY_STEP)\nBN_DECAY_CLIP = 0.99\n\nHOSTNAME = socket.gethostname()\n\nALL_FILES = provider.getDataFiles(\'indoor3d_sem_seg_hdf5_data/all_files.txt\')\nroom_filelist = [line.rstrip() for line in open(\'indoor3d_sem_seg_hdf5_data/room_filelist.txt\')]\n\n# Load ALL data\ndata_batch_list = []\nlabel_batch_list = []\nfor h5_filename in ALL_FILES:\n    data_batch, label_batch = provider.loadDataFile(h5_filename)\n    data_batch_list.append(data_batch)\n    label_batch_list.append(label_batch)\ndata_batches = np.concatenate(data_batch_list, 0)\nlabel_batches = np.concatenate(label_batch_list, 0)\nprint(data_batches.shape)\nprint(label_batches.shape)\n\ntest_area = \'Area_\'+str(FLAGS.test_area)\ntrain_idxs = []\ntest_idxs = []\nfor i,room_name in enumerate(room_filelist):\n    if test_area in room_name:\n        test_idxs.append(i)\n    else:\n        train_idxs.append(i)\n\ntrain_data = data_batches[train_idxs,...]\ntrain_label = label_batches[train_idxs]\ntest_data = data_batches[test_idxs,...]\ntest_label = label_batches[test_idxs]\nprint(train_data.shape, train_label.shape)\nprint(test_data.shape, test_label.shape)\n\n\n\n\ndef log_string(out_str):\n    LOG_FOUT.write(out_str+\'\\n\')\n    LOG_FOUT.flush()\n    print(out_str)\n\n\ndef get_learning_rate(batch):\n    learning_rate = tf.train.exponential_decay(\n                        BASE_LEARNING_RATE,  # Base learning rate.\n                        batch * BATCH_SIZE,  # Current index into the dataset.\n                        DECAY_STEP,          # Decay step.\n                        DECAY_RATE,          # Decay rate.\n                        staircase=True)\n    learning_rate = tf.maximum(learning_rate, 0.00001) # CLIP THE LEARNING RATE!!\n    return learning_rate        \n\ndef get_bn_decay(batch):\n    bn_momentum = tf.train.exponential_decay(\n                      BN_INIT_DECAY,\n                      batch*BATCH_SIZE,\n                      BN_DECAY_DECAY_STEP,\n                      BN_DECAY_DECAY_RATE,\n                      staircase=True)\n    bn_decay = tf.minimum(BN_DECAY_CLIP, 1 - bn_momentum)\n    return bn_decay\n\ndef train():\n    with tf.Graph().as_default():\n        with tf.device(\'/gpu:\'+str(GPU_INDEX)):\n            pointclouds_pl, labels_pl = placeholder_inputs(BATCH_SIZE, NUM_POINT)\n            is_training_pl = tf.placeholder(tf.bool, shape=())\n            \n            # Note the global_step=batch parameter to minimize. \n            # That tells the optimizer to helpfully increment the \'batch\' parameter for you every time it trains.\n            batch = tf.Variable(0)\n            bn_decay = get_bn_decay(batch)\n            tf.summary.scalar(\'bn_decay\', bn_decay)\n\n            # Get model and loss \n            pred = get_model(pointclouds_pl, is_training_pl, bn_decay=bn_decay)\n            loss = get_loss(pred, labels_pl)\n            tf.summary.scalar(\'loss\', loss)\n\n            correct = tf.equal(tf.argmax(pred, 2), tf.to_int64(labels_pl))\n            accuracy = tf.reduce_sum(tf.cast(correct, tf.float32)) / float(BATCH_SIZE*NUM_POINT)\n            tf.summary.scalar(\'accuracy\', accuracy)\n\n            # Get training operator\n            learning_rate = get_learning_rate(batch)\n            tf.summary.scalar(\'learning_rate\', learning_rate)\n            if OPTIMIZER == \'momentum\':\n                optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=MOMENTUM)\n            elif OPTIMIZER == \'adam\':\n                optimizer = tf.train.AdamOptimizer(learning_rate)\n            train_op = optimizer.minimize(loss, global_step=batch)\n            \n            # Add ops to save and restore all the variables.\n            saver = tf.train.Saver()\n            \n        # Create a session\n        config = tf.ConfigProto()\n        config.gpu_options.allow_growth = True\n        config.allow_soft_placement = True\n        config.log_device_placement = True\n        sess = tf.Session(config=config)\n\n        # Add summary writers\n        merged = tf.summary.merge_all()\n        train_writer = tf.summary.FileWriter(os.path.join(LOG_DIR, \'train\'),\n                                  sess.graph)\n        test_writer = tf.summary.FileWriter(os.path.join(LOG_DIR, \'test\'))\n\n        # Init variables\n        init = tf.global_variables_initializer()\n        sess.run(init, {is_training_pl:True})\n\n        ops = {\'pointclouds_pl\': pointclouds_pl,\n               \'labels_pl\': labels_pl,\n               \'is_training_pl\': is_training_pl,\n               \'pred\': pred,\n               \'loss\': loss,\n               \'train_op\': train_op,\n               \'merged\': merged,\n               \'step\': batch}\n\n        for epoch in range(MAX_EPOCH):\n            log_string(\'**** EPOCH %03d ****\' % (epoch))\n            sys.stdout.flush()\n             \n            train_one_epoch(sess, ops, train_writer)\n            eval_one_epoch(sess, ops, test_writer)\n            \n            # Save the variables to disk.\n            if epoch % 10 == 0:\n                save_path = saver.save(sess, os.path.join(LOG_DIR, ""model.ckpt""))\n                log_string(""Model saved in file: %s"" % save_path)\n\n\n\ndef train_one_epoch(sess, ops, train_writer):\n    """""" ops: dict mapping from string to tf ops """"""\n    is_training = True\n    \n    log_string(\'----\')\n    current_data, current_label, _ = provider.shuffle_data(train_data[:,0:NUM_POINT,:], train_label) \n    \n    file_size = current_data.shape[0]\n    num_batches = file_size // BATCH_SIZE\n    \n    total_correct = 0\n    total_seen = 0\n    loss_sum = 0\n    \n    for batch_idx in range(num_batches):\n        if batch_idx % 100 == 0:\n            print(\'Current batch/total batch num: %d/%d\'%(batch_idx,num_batches))\n        start_idx = batch_idx * BATCH_SIZE\n        end_idx = (batch_idx+1) * BATCH_SIZE\n        \n        feed_dict = {ops[\'pointclouds_pl\']: current_data[start_idx:end_idx, :, :],\n                     ops[\'labels_pl\']: current_label[start_idx:end_idx],\n                     ops[\'is_training_pl\']: is_training,}\n        summary, step, _, loss_val, pred_val = sess.run([ops[\'merged\'], ops[\'step\'], ops[\'train_op\'], ops[\'loss\'], ops[\'pred\']],\n                                         feed_dict=feed_dict)\n        train_writer.add_summary(summary, step)\n        pred_val = np.argmax(pred_val, 2)\n        correct = np.sum(pred_val == current_label[start_idx:end_idx])\n        total_correct += correct\n        total_seen += (BATCH_SIZE*NUM_POINT)\n        loss_sum += loss_val\n    \n    log_string(\'mean loss: %f\' % (loss_sum / float(num_batches)))\n    log_string(\'accuracy: %f\' % (total_correct / float(total_seen)))\n\n        \ndef eval_one_epoch(sess, ops, test_writer):\n    """""" ops: dict mapping from string to tf ops """"""\n    is_training = False\n    total_correct = 0\n    total_seen = 0\n    loss_sum = 0\n    total_seen_class = [0 for _ in range(NUM_CLASSES)]\n    total_correct_class = [0 for _ in range(NUM_CLASSES)]\n    \n    log_string(\'----\')\n    current_data = test_data[:,0:NUM_POINT,:]\n    current_label = np.squeeze(test_label)\n    \n    file_size = current_data.shape[0]\n    num_batches = file_size // BATCH_SIZE\n    \n    for batch_idx in range(num_batches):\n        start_idx = batch_idx * BATCH_SIZE\n        end_idx = (batch_idx+1) * BATCH_SIZE\n\n        feed_dict = {ops[\'pointclouds_pl\']: current_data[start_idx:end_idx, :, :],\n                     ops[\'labels_pl\']: current_label[start_idx:end_idx],\n                     ops[\'is_training_pl\']: is_training}\n        summary, step, loss_val, pred_val = sess.run([ops[\'merged\'], ops[\'step\'], ops[\'loss\'], ops[\'pred\']],\n                                      feed_dict=feed_dict)\n        test_writer.add_summary(summary, step)\n        pred_val = np.argmax(pred_val, 2)\n        correct = np.sum(pred_val == current_label[start_idx:end_idx])\n        total_correct += correct\n        total_seen += (BATCH_SIZE*NUM_POINT)\n        loss_sum += (loss_val*BATCH_SIZE)\n        for i in range(start_idx, end_idx):\n            for j in range(NUM_POINT):\n                l = current_label[i, j]\n                total_seen_class[l] += 1\n                total_correct_class[l] += (pred_val[i-start_idx, j] == l)\n            \n    log_string(\'eval mean loss: %f\' % (loss_sum / float(total_seen/NUM_POINT)))\n    log_string(\'eval accuracy: %f\'% (total_correct / float(total_seen)))\n    log_string(\'eval avg class acc: %f\' % (np.mean(np.array(total_correct_class)/np.array(total_seen_class,dtype=np.float))))\n         \n\n\nif __name__ == ""__main__"":\n    train()\n    LOG_FOUT.close()\n'"
utils/data_prep_util.py,0,"b""import os\nimport sys\nBASE_DIR = os.path.dirname(os.path.abspath(__file__))\nsys.path.append(BASE_DIR)\nfrom plyfile import (PlyData, PlyElement, make2d, PlyParseError, PlyProperty)\nimport numpy as np\nimport h5py\n\nSAMPLING_BIN = os.path.join(BASE_DIR, 'third_party/mesh_sampling/build/pcsample')\n\nSAMPLING_POINT_NUM = 2048\nSAMPLING_LEAF_SIZE = 0.005\n\nMODELNET40_PATH = '../datasets/modelnet40'\ndef export_ply(pc, filename):\n\tvertex = np.zeros(pc.shape[0], dtype=[('x', 'f4'), ('y', 'f4'), ('z', 'f4')])\n\tfor i in range(pc.shape[0]):\n\t\tvertex[i] = (pc[i][0], pc[i][1], pc[i][2])\n\tply_out = PlyData([PlyElement.describe(vertex, 'vertex', comments=['vertices'])])\n\tply_out.write(filename)\n\n# Sample points on the obj shape\ndef get_sampling_command(obj_filename, ply_filename):\n    cmd = SAMPLING_BIN + ' ' + obj_filename\n    cmd += ' ' + ply_filename\n    cmd += ' -n_samples %d ' % SAMPLING_POINT_NUM\n    cmd += ' -leaf_size %f ' % SAMPLING_LEAF_SIZE\n    return cmd\n\n# --------------------------------------------------------------\n# Following are the helper functions to load MODELNET40 shapes\n# --------------------------------------------------------------\n\n# Read in the list of categories in MODELNET40\ndef get_category_names():\n    shape_names_file = os.path.join(MODELNET40_PATH, 'shape_names.txt')\n    shape_names = [line.rstrip() for line in open(shape_names_file)]\n    return shape_names\n\n# Return all the filepaths for the shapes in MODELNET40 \ndef get_obj_filenames():\n    obj_filelist_file = os.path.join(MODELNET40_PATH, 'filelist.txt')\n    obj_filenames = [os.path.join(MODELNET40_PATH, line.rstrip()) for line in open(obj_filelist_file)]\n    print('Got %d obj files in modelnet40.' % len(obj_filenames))\n    return obj_filenames\n\n# Helper function to create the father folder and all subdir folders if not exist\ndef batch_mkdir(output_folder, subdir_list):\n    if not os.path.exists(output_folder):\n        os.mkdir(output_folder)\n    for subdir in subdir_list:\n        if not os.path.exists(os.path.join(output_folder, subdir)):\n            os.mkdir(os.path.join(output_folder, subdir))\n\n# ----------------------------------------------------------------\n# Following are the helper functions to load save/load HDF5 files\n# ----------------------------------------------------------------\n\n# Write numpy array data and label to h5_filename\ndef save_h5_data_label_normal(h5_filename, data, label, normal, \n\t\tdata_dtype='float32', label_dtype='uint8', normal_dtype='float32'):\n    h5_fout = h5py.File(h5_filename)\n    h5_fout.create_dataset(\n            'data', data=data,\n            compression='gzip', compression_opts=4,\n            dtype=data_dtype)\n    h5_fout.create_dataset(\n            'normal', data=normal,\n            compression='gzip', compression_opts=4,\n            dtype=normal_dtype)\n    h5_fout.create_dataset(\n            'label', data=label,\n            compression='gzip', compression_opts=1,\n            dtype=label_dtype)\n    h5_fout.close()\n\n\n# Write numpy array data and label to h5_filename\ndef save_h5(h5_filename, data, label, data_dtype='uint8', label_dtype='uint8'):\n    h5_fout = h5py.File(h5_filename)\n    h5_fout.create_dataset(\n            'data', data=data,\n            compression='gzip', compression_opts=4,\n            dtype=data_dtype)\n    h5_fout.create_dataset(\n            'label', data=label,\n            compression='gzip', compression_opts=1,\n            dtype=label_dtype)\n    h5_fout.close()\n\n# Read numpy array data and label from h5_filename\ndef load_h5_data_label_normal(h5_filename):\n    f = h5py.File(h5_filename)\n    data = f['data'][:]\n    label = f['label'][:]\n    normal = f['normal'][:]\n    return (data, label, normal)\n\n# Read numpy array data and label from h5_filename\ndef load_h5_data_label_seg(h5_filename):\n    f = h5py.File(h5_filename)\n    data = f['data'][:]\n    label = f['label'][:]\n    seg = f['pid'][:]\n    return (data, label, seg)\n\n# Read numpy array data and label from h5_filename\ndef load_h5(h5_filename):\n    f = h5py.File(h5_filename)\n    data = f['data'][:]\n    label = f['label'][:]\n    return (data, label)\n\n# ----------------------------------------------------------------\n# Following are the helper functions to load save/load PLY files\n# ----------------------------------------------------------------\n\n# Load PLY file\ndef load_ply_data(filename, point_num):\n    plydata = PlyData.read(filename)\n    pc = plydata['vertex'].data[:point_num]\n    pc_array = np.array([[x, y, z] for x,y,z in pc])\n    return pc_array\n\n# Load PLY file\ndef load_ply_normal(filename, point_num):\n    plydata = PlyData.read(filename)\n    pc = plydata['normal'].data[:point_num]\n    pc_array = np.array([[x, y, z] for x,y,z in pc])\n    return pc_array\n\n# Make up rows for Nxk array\n# Input Pad is 'edge' or 'constant'\ndef pad_arr_rows(arr, row, pad='edge'):\n    assert(len(arr.shape) == 2)\n    assert(arr.shape[0] <= row)\n    assert(pad == 'edge' or pad == 'constant')\n    if arr.shape[0] == row:\n        return arr\n    if pad == 'edge':\n        return np.lib.pad(arr, ((0, row-arr.shape[0]), (0, 0)), 'edge')\n    if pad == 'constant':\n        return np.lib.pad(arr, ((0, row-arr.shape[0]), (0, 0)), 'constant', (0, 0))\n\n\n"""
utils/eulerangles.py,0,"b'# emacs: -*- mode: python-mode; py-indent-offset: 4; indent-tabs-mode: nil -*-\n# vi: set ft=python sts=4 ts=4 sw=4 et:\n### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ##\n#\n#   See COPYING file distributed along with the NiBabel package for the\n#   copyright and license terms.\n#\n### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ##\n\'\'\' Module implementing Euler angle rotations and their conversions\n\nSee:\n\n* http://en.wikipedia.org/wiki/Rotation_matrix\n* http://en.wikipedia.org/wiki/Euler_angles\n* http://mathworld.wolfram.com/EulerAngles.html\n\nSee also: *Representing Attitude with Euler Angles and Quaternions: A\nReference* (2006) by James Diebel. A cached PDF link last found here:\n\nhttp://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.110.5134\n\nEuler\'s rotation theorem tells us that any rotation in 3D can be\ndescribed by 3 angles.  Let\'s call the 3 angles the *Euler angle vector*\nand call the angles in the vector :math:`alpha`, :math:`beta` and\n:math:`gamma`.  The vector is [ :math:`alpha`,\n:math:`beta`. :math:`gamma` ] and, in this description, the order of the\nparameters specifies the order in which the rotations occur (so the\nrotation corresponding to :math:`alpha` is applied first).\n\nIn order to specify the meaning of an *Euler angle vector* we need to\nspecify the axes around which each of the rotations corresponding to\n:math:`alpha`, :math:`beta` and :math:`gamma` will occur.\n\nThere are therefore three axes for the rotations :math:`alpha`,\n:math:`beta` and :math:`gamma`; let\'s call them :math:`i` :math:`j`,\n:math:`k`.\n\nLet us express the rotation :math:`alpha` around axis `i` as a 3 by 3\nrotation matrix `A`.  Similarly :math:`beta` around `j` becomes 3 x 3\nmatrix `B` and :math:`gamma` around `k` becomes matrix `G`.  Then the\nwhole rotation expressed by the Euler angle vector [ :math:`alpha`,\n:math:`beta`. :math:`gamma` ], `R` is given by::\n\n   R = np.dot(G, np.dot(B, A))\n\nSee http://mathworld.wolfram.com/EulerAngles.html\n\nThe order :math:`G B A` expresses the fact that the rotations are\nperformed in the order of the vector (:math:`alpha` around axis `i` =\n`A` first).\n\nTo convert a given Euler angle vector to a meaningful rotation, and a\nrotation matrix, we need to define:\n\n* the axes `i`, `j`, `k`\n* whether a rotation matrix should be applied on the left of a vector to\n  be transformed (vectors are column vectors) or on the right (vectors\n  are row vectors).\n* whether the rotations move the axes as they are applied (intrinsic\n  rotations) - compared the situation where the axes stay fixed and the\n  vectors move within the axis frame (extrinsic)\n* the handedness of the coordinate system\n\nSee: http://en.wikipedia.org/wiki/Rotation_matrix#Ambiguities\n\nWe are using the following conventions:\n\n* axes `i`, `j`, `k` are the `z`, `y`, and `x` axes respectively.  Thus\n  an Euler angle vector [ :math:`alpha`, :math:`beta`. :math:`gamma` ]\n  in our convention implies a :math:`alpha` radian rotation around the\n  `z` axis, followed by a :math:`beta` rotation around the `y` axis,\n  followed by a :math:`gamma` rotation around the `x` axis.\n* the rotation matrix applies on the left, to column vectors on the\n  right, so if `R` is the rotation matrix, and `v` is a 3 x N matrix\n  with N column vectors, the transformed vector set `vdash` is given by\n  ``vdash = np.dot(R, v)``.\n* extrinsic rotations - the axes are fixed, and do not move with the\n  rotations.\n* a right-handed coordinate system\n\nThe convention of rotation around ``z``, followed by rotation around\n``y``, followed by rotation around ``x``, is known (confusingly) as\n""xyz"", pitch-roll-yaw, Cardan angles, or Tait-Bryan angles.\n\'\'\'\n\nimport math\n\nimport sys\nif sys.version_info >= (3,0):\n    from functools import reduce\n\nimport numpy as np\n\n\n_FLOAT_EPS_4 = np.finfo(float).eps * 4.0\n\n\ndef euler2mat(z=0, y=0, x=0):\n    \'\'\' Return matrix for rotations around z, y and x axes\n\n    Uses the z, then y, then x convention above\n\n    Parameters\n    ----------\n    z : scalar\n       Rotation angle in radians around z-axis (performed first)\n    y : scalar\n       Rotation angle in radians around y-axis\n    x : scalar\n       Rotation angle in radians around x-axis (performed last)\n\n    Returns\n    -------\n    M : array shape (3,3)\n       Rotation matrix giving same rotation as for given angles\n\n    Examples\n    --------\n    >>> zrot = 1.3 # radians\n    >>> yrot = -0.1\n    >>> xrot = 0.2\n    >>> M = euler2mat(zrot, yrot, xrot)\n    >>> M.shape == (3, 3)\n    True\n\n    The output rotation matrix is equal to the composition of the\n    individual rotations\n\n    >>> M1 = euler2mat(zrot)\n    >>> M2 = euler2mat(0, yrot)\n    >>> M3 = euler2mat(0, 0, xrot)\n    >>> composed_M = np.dot(M3, np.dot(M2, M1))\n    >>> np.allclose(M, composed_M)\n    True\n\n    You can specify rotations by named arguments\n\n    >>> np.all(M3 == euler2mat(x=xrot))\n    True\n\n    When applying M to a vector, the vector should column vector to the\n    right of M.  If the right hand side is a 2D array rather than a\n    vector, then each column of the 2D array represents a vector.\n\n    >>> vec = np.array([1, 0, 0]).reshape((3,1))\n    >>> v2 = np.dot(M, vec)\n    >>> vecs = np.array([[1, 0, 0],[0, 1, 0]]).T # giving 3x2 array\n    >>> vecs2 = np.dot(M, vecs)\n\n    Rotations are counter-clockwise.\n\n    >>> zred = np.dot(euler2mat(z=np.pi/2), np.eye(3))\n    >>> np.allclose(zred, [[0, -1, 0],[1, 0, 0], [0, 0, 1]])\n    True\n    >>> yred = np.dot(euler2mat(y=np.pi/2), np.eye(3))\n    >>> np.allclose(yred, [[0, 0, 1],[0, 1, 0], [-1, 0, 0]])\n    True\n    >>> xred = np.dot(euler2mat(x=np.pi/2), np.eye(3))\n    >>> np.allclose(xred, [[1, 0, 0],[0, 0, -1], [0, 1, 0]])\n    True\n\n    Notes\n    -----\n    The direction of rotation is given by the right-hand rule (orient\n    the thumb of the right hand along the axis around which the rotation\n    occurs, with the end of the thumb at the positive end of the axis;\n    curl your fingers; the direction your fingers curl is the direction\n    of rotation).  Therefore, the rotations are counterclockwise if\n    looking along the axis of rotation from positive to negative.\n    \'\'\'\n    Ms = []\n    if z:\n        cosz = math.cos(z)\n        sinz = math.sin(z)\n        Ms.append(np.array(\n                [[cosz, -sinz, 0],\n                 [sinz, cosz, 0],\n                 [0, 0, 1]]))\n    if y:\n        cosy = math.cos(y)\n        siny = math.sin(y)\n        Ms.append(np.array(\n                [[cosy, 0, siny],\n                 [0, 1, 0],\n                 [-siny, 0, cosy]]))\n    if x:\n        cosx = math.cos(x)\n        sinx = math.sin(x)\n        Ms.append(np.array(\n                [[1, 0, 0],\n                 [0, cosx, -sinx],\n                 [0, sinx, cosx]]))\n    if Ms:\n        return reduce(np.dot, Ms[::-1])\n    return np.eye(3)\n\n\ndef mat2euler(M, cy_thresh=None):\n    \'\'\' Discover Euler angle vector from 3x3 matrix\n\n    Uses the conventions above.\n\n    Parameters\n    ----------\n    M : array-like, shape (3,3)\n    cy_thresh : None or scalar, optional\n       threshold below which to give up on straightforward arctan for\n       estimating x rotation.  If None (default), estimate from\n       precision of input.\n\n    Returns\n    -------\n    z : scalar\n    y : scalar\n    x : scalar\n       Rotations in radians around z, y, x axes, respectively\n\n    Notes\n    -----\n    If there was no numerical error, the routine could be derived using\n    Sympy expression for z then y then x rotation matrix, which is::\n\n      [                       cos(y)*cos(z),                       -cos(y)*sin(z),         sin(y)],\n      [cos(x)*sin(z) + cos(z)*sin(x)*sin(y), cos(x)*cos(z) - sin(x)*sin(y)*sin(z), -cos(y)*sin(x)],\n      [sin(x)*sin(z) - cos(x)*cos(z)*sin(y), cos(z)*sin(x) + cos(x)*sin(y)*sin(z),  cos(x)*cos(y)]\n\n    with the obvious derivations for z, y, and x\n\n       z = atan2(-r12, r11)\n       y = asin(r13)\n       x = atan2(-r23, r33)\n\n    Problems arise when cos(y) is close to zero, because both of::\n\n       z = atan2(cos(y)*sin(z), cos(y)*cos(z))\n       x = atan2(cos(y)*sin(x), cos(x)*cos(y))\n\n    will be close to atan2(0, 0), and highly unstable.\n\n    The ``cy`` fix for numerical instability below is from: *Graphics\n    Gems IV*, Paul Heckbert (editor), Academic Press, 1994, ISBN:\n    0123361559.  Specifically it comes from EulerAngles.c by Ken\n    Shoemake, and deals with the case where cos(y) is close to zero:\n\n    See: http://www.graphicsgems.org/\n\n    The code appears to be licensed (from the website) as ""can be used\n    without restrictions"".\n    \'\'\'\n    M = np.asarray(M)\n    if cy_thresh is None:\n        try:\n            cy_thresh = np.finfo(M.dtype).eps * 4\n        except ValueError:\n            cy_thresh = _FLOAT_EPS_4\n    r11, r12, r13, r21, r22, r23, r31, r32, r33 = M.flat\n    # cy: sqrt((cos(y)*cos(z))**2 + (cos(x)*cos(y))**2)\n    cy = math.sqrt(r33*r33 + r23*r23)\n    if cy > cy_thresh: # cos(y) not close to zero, standard form\n        z = math.atan2(-r12,  r11) # atan2(cos(y)*sin(z), cos(y)*cos(z))\n        y = math.atan2(r13,  cy) # atan2(sin(y), cy)\n        x = math.atan2(-r23, r33) # atan2(cos(y)*sin(x), cos(x)*cos(y))\n    else: # cos(y) (close to) zero, so x -> 0.0 (see above)\n        # so r21 -> sin(z), r22 -> cos(z) and\n        z = math.atan2(r21,  r22)\n        y = math.atan2(r13,  cy) # atan2(sin(y), cy)\n        x = 0.0\n    return z, y, x\n\n\ndef euler2quat(z=0, y=0, x=0):\n    \'\'\' Return quaternion corresponding to these Euler angles\n\n    Uses the z, then y, then x convention above\n\n    Parameters\n    ----------\n    z : scalar\n       Rotation angle in radians around z-axis (performed first)\n    y : scalar\n       Rotation angle in radians around y-axis\n    x : scalar\n       Rotation angle in radians around x-axis (performed last)\n\n    Returns\n    -------\n    quat : array shape (4,)\n       Quaternion in w, x, y z (real, then vector) format\n\n    Notes\n    -----\n    We can derive this formula in Sympy using:\n\n    1. Formula giving quaternion corresponding to rotation of theta radians\n       about arbitrary axis:\n       http://mathworld.wolfram.com/EulerParameters.html\n    2. Generated formulae from 1.) for quaternions corresponding to\n       theta radians rotations about ``x, y, z`` axes\n    3. Apply quaternion multiplication formula -\n       http://en.wikipedia.org/wiki/Quaternions#Hamilton_product - to\n       formulae from 2.) to give formula for combined rotations.\n    \'\'\'\n    z = z/2.0\n    y = y/2.0\n    x = x/2.0\n    cz = math.cos(z)\n    sz = math.sin(z)\n    cy = math.cos(y)\n    sy = math.sin(y)\n    cx = math.cos(x)\n    sx = math.sin(x)\n    return np.array([\n             cx*cy*cz - sx*sy*sz,\n             cx*sy*sz + cy*cz*sx,\n             cx*cz*sy - sx*cy*sz,\n             cx*cy*sz + sx*cz*sy])\n\n\ndef quat2euler(q):\n    \'\'\' Return Euler angles corresponding to quaternion `q`\n\n    Parameters\n    ----------\n    q : 4 element sequence\n       w, x, y, z of quaternion\n\n    Returns\n    -------\n    z : scalar\n       Rotation angle in radians around z-axis (performed first)\n    y : scalar\n       Rotation angle in radians around y-axis\n    x : scalar\n       Rotation angle in radians around x-axis (performed last)\n\n    Notes\n    -----\n    It\'s possible to reduce the amount of calculation a little, by\n    combining parts of the ``quat2mat`` and ``mat2euler`` functions, but\n    the reduction in computation is small, and the code repetition is\n    large.\n    \'\'\'\n    # delayed import to avoid cyclic dependencies\n    import nibabel.quaternions as nq\n    return mat2euler(nq.quat2mat(q))\n\n\ndef euler2angle_axis(z=0, y=0, x=0):\n    \'\'\' Return angle, axis corresponding to these Euler angles\n\n    Uses the z, then y, then x convention above\n\n    Parameters\n    ----------\n    z : scalar\n       Rotation angle in radians around z-axis (performed first)\n    y : scalar\n       Rotation angle in radians around y-axis\n    x : scalar\n       Rotation angle in radians around x-axis (performed last)\n\n    Returns\n    -------\n    theta : scalar\n       angle of rotation\n    vector : array shape (3,)\n       axis around which rotation occurs\n\n    Examples\n    --------\n    >>> theta, vec = euler2angle_axis(0, 1.5, 0)\n    >>> print(theta)\n    1.5\n    >>> np.allclose(vec, [0, 1, 0])\n    True\n    \'\'\'\n    # delayed import to avoid cyclic dependencies\n    import nibabel.quaternions as nq\n    return nq.quat2angle_axis(euler2quat(z, y, x))\n\n\ndef angle_axis2euler(theta, vector, is_normalized=False):\n    \'\'\' Convert angle, axis pair to Euler angles\n\n    Parameters\n    ----------\n    theta : scalar\n       angle of rotation\n    vector : 3 element sequence\n       vector specifying axis for rotation.\n    is_normalized : bool, optional\n       True if vector is already normalized (has norm of 1).  Default\n       False\n\n    Returns\n    -------\n    z : scalar\n    y : scalar\n    x : scalar\n       Rotations in radians around z, y, x axes, respectively\n\n    Examples\n    --------\n    >>> z, y, x = angle_axis2euler(0, [1, 0, 0])\n    >>> np.allclose((z, y, x), 0)\n    True\n\n    Notes\n    -----\n    It\'s possible to reduce the amount of calculation a little, by\n    combining parts of the ``angle_axis2mat`` and ``mat2euler``\n    functions, but the reduction in computation is small, and the code\n    repetition is large.\n    \'\'\'\n    # delayed import to avoid cyclic dependencies\n    import nibabel.quaternions as nq\n    M = nq.angle_axis2mat(theta, vector, is_normalized)\n    return mat2euler(M)\n'"
utils/pc_util.py,0,"b'"""""" Utility functions for processing point clouds.\n\nAuthor: Charles R. Qi, Hao Su\nDate: November 2016\n""""""\n\nimport os\nimport sys\nBASE_DIR = os.path.dirname(os.path.abspath(__file__))\nsys.path.append(BASE_DIR)\n\n# Draw point cloud\nfrom eulerangles import euler2mat\n\n# Point cloud IO\nimport numpy as np\nfrom plyfile import PlyData, PlyElement\n\n \n# ----------------------------------------\n# Point Cloud/Volume Conversions\n# ----------------------------------------\n\ndef point_cloud_to_volume_batch(point_clouds, vsize=12, radius=1.0, flatten=True):\n    """""" Input is BxNx3 batch of point cloud\n        Output is Bx(vsize^3)\n    """"""\n    vol_list = []\n    for b in range(point_clouds.shape[0]):\n        vol = point_cloud_to_volume(np.squeeze(point_clouds[b,:,:]), vsize, radius)\n        if flatten:\n            vol_list.append(vol.flatten())\n        else:\n            vol_list.append(np.expand_dims(np.expand_dims(vol, -1), 0))\n    if flatten:\n        return np.vstack(vol_list)\n    else:\n        return np.concatenate(vol_list, 0)\n\n\ndef point_cloud_to_volume(points, vsize, radius=1.0):\n    """""" input is Nx3 points.\n        output is vsize*vsize*vsize\n        assumes points are in range [-radius, radius]\n    """"""\n    vol = np.zeros((vsize,vsize,vsize))\n    voxel = 2*radius/float(vsize)\n    locations = (points + radius)/voxel\n    locations = locations.astype(int)\n    vol[locations[:,0],locations[:,1],locations[:,2]] = 1.0\n    return vol\n\n#a = np.zeros((16,1024,3))\n#print point_cloud_to_volume_batch(a, 12, 1.0, False).shape\n\ndef volume_to_point_cloud(vol):\n    """""" vol is occupancy grid (value = 0 or 1) of size vsize*vsize*vsize\n        return Nx3 numpy array.\n    """"""\n    vsize = vol.shape[0]\n    assert(vol.shape[1] == vsize and vol.shape[1] == vsize)\n    points = []\n    for a in range(vsize):\n        for b in range(vsize):\n            for c in range(vsize):\n                if vol[a,b,c] == 1:\n                    points.append(np.array([a,b,c]))\n    if len(points) == 0:\n        return np.zeros((0,3))\n    points = np.vstack(points)\n    return points\n\n# ----------------------------------------\n# Point cloud IO\n# ----------------------------------------\n\ndef read_ply(filename):\n    """""" read XYZ point cloud from filename PLY file """"""\n    plydata = PlyData.read(filename)\n    pc = plydata[\'vertex\'].data\n    pc_array = np.array([[x, y, z] for x,y,z in pc])\n    return pc_array\n\n\ndef write_ply(points, filename, text=True):\n    """""" input: Nx3, write points to filename as PLY format. """"""\n    points = [(points[i,0], points[i,1], points[i,2]) for i in range(points.shape[0])]\n    vertex = np.array(points, dtype=[(\'x\', \'f4\'), (\'y\', \'f4\'),(\'z\', \'f4\')])\n    el = PlyElement.describe(vertex, \'vertex\', comments=[\'vertices\'])\n    PlyData([el], text=text).write(filename)\n\n\n# ----------------------------------------\n# Simple Point cloud and Volume Renderers\n# ----------------------------------------\n\ndef draw_point_cloud(input_points, canvasSize=500, space=200, diameter=25,\n                     xrot=0, yrot=0, zrot=0, switch_xyz=[0,1,2], normalize=True):\n    """""" Render point cloud to image with alpha channel.\n        Input:\n            points: Nx3 numpy array (+y is up direction)\n        Output:\n            gray image as numpy array of size canvasSizexcanvasSize\n    """"""\n    image = np.zeros((canvasSize, canvasSize))\n    if input_points is None or input_points.shape[0] == 0:\n        return image\n\n    points = input_points[:, switch_xyz]\n    M = euler2mat(zrot, yrot, xrot)\n    points = (np.dot(M, points.transpose())).transpose()\n\n    # Normalize the point cloud\n    # We normalize scale to fit points in a unit sphere\n    if normalize:\n        centroid = np.mean(points, axis=0)\n        points -= centroid\n        furthest_distance = np.max(np.sqrt(np.sum(abs(points)**2,axis=-1)))\n        points /= furthest_distance\n\n    # Pre-compute the Gaussian disk\n    radius = (diameter-1)/2.0\n    disk = np.zeros((diameter, diameter))\n    for i in range(diameter):\n        for j in range(diameter):\n            if (i - radius) * (i-radius) + (j-radius) * (j-radius) <= radius * radius:\n                disk[i, j] = np.exp((-(i-radius)**2 - (j-radius)**2)/(radius**2))\n    mask = np.argwhere(disk > 0)\n    dx = mask[:, 0]\n    dy = mask[:, 1]\n    dv = disk[disk > 0]\n    \n    # Order points by z-buffer\n    zorder = np.argsort(points[:, 2])\n    points = points[zorder, :]\n    points[:, 2] = (points[:, 2] - np.min(points[:, 2])) / (np.max(points[:, 2] - np.min(points[:, 2])))\n    max_depth = np.max(points[:, 2])\n       \n    for i in range(points.shape[0]):\n        j = points.shape[0] - i - 1\n        x = points[j, 0]\n        y = points[j, 1]\n        xc = canvasSize/2 + (x*space)\n        yc = canvasSize/2 + (y*space)\n        xc = int(np.round(xc))\n        yc = int(np.round(yc))\n        \n        px = dx + xc\n        py = dy + yc\n        \n        image[px, py] = image[px, py] * 0.7 + dv * (max_depth - points[j, 2]) * 0.3\n    \n    image = image / np.max(image)\n    return image\n\ndef point_cloud_three_views(points):\n    """""" input points Nx3 numpy array (+y is up direction).\n        return an numpy array gray image of size 500x1500. """""" \n    # +y is up direction\n    # xrot is azimuth\n    # yrot is in-plane\n    # zrot is elevation\n    img1 = draw_point_cloud(points, zrot=110/180.0*np.pi, xrot=45/180.0*np.pi, yrot=0/180.0*np.pi)\n    img2 = draw_point_cloud(points, zrot=70/180.0*np.pi, xrot=135/180.0*np.pi, yrot=0/180.0*np.pi)\n    img3 = draw_point_cloud(points, zrot=180.0/180.0*np.pi, xrot=90/180.0*np.pi, yrot=0/180.0*np.pi)\n    image_large = np.concatenate([img1, img2, img3], 1)\n    return image_large\n\n\nfrom PIL import Image\ndef point_cloud_three_views_demo():\n    """""" Demo for draw_point_cloud function """"""\n    points = read_ply(\'../third_party/mesh_sampling/piano.ply\')\n    im_array = point_cloud_three_views(points)\n    img = Image.fromarray(np.uint8(im_array*255.0))\n    img.save(\'piano.jpg\')\n\nif __name__==""__main__"":\n    point_cloud_three_views_demo()\n\n\nimport matplotlib.pyplot as plt\ndef pyplot_draw_point_cloud(points, output_filename):\n    """""" points is a Nx3 numpy array """"""\n    fig = plt.figure()\n    ax = fig.add_subplot(111, projection=\'3d\')\n    ax.scatter(points[:,0], points[:,1], points[:,2])\n    ax.set_xlabel(\'x\')\n    ax.set_ylabel(\'y\')\n    ax.set_zlabel(\'z\')\n    #savefig(output_filename)\n\ndef pyplot_draw_volume(vol, output_filename):\n    """""" vol is of size vsize*vsize*vsize\n        output an image to output_filename\n    """"""\n    points = volume_to_point_cloud(vol)\n    pyplot_draw_point_cloud(points, output_filename)\n'"
utils/plyfile.py,0,"b'#   Copyright 2014 Darsh Ranjan\n#\n#   This file is part of python-plyfile.\n#\n#   python-plyfile is free software: you can redistribute it and/or\n#   modify it under the terms of the GNU General Public License as\n#   published by the Free Software Foundation, either version 3 of the\n#   License, or (at your option) any later version.\n#\n#   python-plyfile is distributed in the hope that it will be useful,\n#   but WITHOUT ANY WARRANTY; without even the implied warranty of\n#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n#   General Public License for more details.\n#\n#   You should have received a copy of the GNU General Public License\n#   along with python-plyfile.  If not, see\n#       <http://www.gnu.org/licenses/>.\n\nfrom itertools import islice as _islice\n\nimport numpy as _np\nfrom sys import byteorder as _byteorder\n\n\ntry:\n    _range = xrange\nexcept NameError:\n    _range = range\n\n\n# Many-many relation\n_data_type_relation = [\n    (\'int8\', \'i1\'),\n    (\'char\', \'i1\'),\n    (\'uint8\', \'u1\'),\n    (\'uchar\', \'b1\'),\n    (\'uchar\', \'u1\'),\n    (\'int16\', \'i2\'),\n    (\'short\', \'i2\'),\n    (\'uint16\', \'u2\'),\n    (\'ushort\', \'u2\'),\n    (\'int32\', \'i4\'),\n    (\'int\', \'i4\'),\n    (\'uint32\', \'u4\'),\n    (\'uint\', \'u4\'),\n    (\'float32\', \'f4\'),\n    (\'float\', \'f4\'),\n    (\'float64\', \'f8\'),\n    (\'double\', \'f8\')\n]\n\n_data_types = dict(_data_type_relation)\n_data_type_reverse = dict((b, a) for (a, b) in _data_type_relation)\n\n_types_list = []\n_types_set = set()\nfor (_a, _b) in _data_type_relation:\n    if _a not in _types_set:\n        _types_list.append(_a)\n        _types_set.add(_a)\n    if _b not in _types_set:\n        _types_list.append(_b)\n        _types_set.add(_b)\n\n\n_byte_order_map = {\n    \'ascii\': \'=\',\n    \'binary_little_endian\': \'<\',\n    \'binary_big_endian\': \'>\'\n}\n\n_byte_order_reverse = {\n    \'<\': \'binary_little_endian\',\n    \'>\': \'binary_big_endian\'\n}\n\n_native_byte_order = {\'little\': \'<\', \'big\': \'>\'}[_byteorder]\n\n\ndef _lookup_type(type_str):\n    if type_str not in _data_type_reverse:\n        try:\n            type_str = _data_types[type_str]\n        except KeyError:\n            raise ValueError(""field type %r not in %r"" %\n                             (type_str, _types_list))\n\n    return _data_type_reverse[type_str]\n\n\ndef _split_line(line, n):\n    fields = line.split(None, n)\n    if len(fields) == n:\n        fields.append(\'\')\n\n    assert len(fields) == n + 1\n\n    return fields\n\n\ndef make2d(array, cols=None, dtype=None):\n    \'\'\'\n    Make a 2D array from an array of arrays.  The `cols\' and `dtype\'\n    arguments can be omitted if the array is not empty.\n\n    \'\'\'\n    if (cols is None or dtype is None) and not len(array):\n        raise RuntimeError(""cols and dtype must be specified for empty ""\n                           ""array"")\n\n    if cols is None:\n        cols = len(array[0])\n\n    if dtype is None:\n        dtype = array[0].dtype\n\n    return _np.fromiter(array, [(\'_\', dtype, (cols,))],\n                        count=len(array))[\'_\']\n\n\nclass PlyParseError(Exception):\n\n    \'\'\'\n    Raised when a PLY file cannot be parsed.\n\n    The attributes `element\', `row\', `property\', and `message\' give\n    additional information.\n\n    \'\'\'\n\n    def __init__(self, message, element=None, row=None, prop=None):\n        self.message = message\n        self.element = element\n        self.row = row\n        self.prop = prop\n\n        s = \'\'\n        if self.element:\n            s += \'element %r: \' % self.element.name\n        if self.row is not None:\n            s += \'row %d: \' % self.row\n        if self.prop:\n            s += \'property %r: \' % self.prop.name\n        s += self.message\n\n        Exception.__init__(self, s)\n\n    def __repr__(self):\n        return (\'PlyParseError(%r, element=%r, row=%r, prop=%r)\' %\n                self.message, self.element, self.row, self.prop)\n\n\nclass PlyData(object):\n\n    \'\'\'\n    PLY file header and data.\n\n    A PlyData instance is created in one of two ways: by the static\n    method PlyData.read (to read a PLY file), or directly from __init__\n    given a sequence of elements (which can then be written to a PLY\n    file).\n\n    \'\'\'\n\n    def __init__(self, elements=[], text=False, byte_order=\'=\',\n                 comments=[], obj_info=[]):\n        \'\'\'\n        elements: sequence of PlyElement instances.\n\n        text: whether the resulting PLY file will be text (True) or\n            binary (False).\n\n        byte_order: \'<\' for little-endian, \'>\' for big-endian, or \'=\'\n            for native.  This is only relevant if `text\' is False.\n\n        comments: sequence of strings that will be placed in the header\n            between the \'ply\' and \'format ...\' lines.\n\n        obj_info: like comments, but will be placed in the header with\n            ""obj_info ..."" instead of ""comment ..."".\n\n        \'\'\'\n        if byte_order == \'=\' and not text:\n            byte_order = _native_byte_order\n\n        self.byte_order = byte_order\n        self.text = text\n\n        self.comments = list(comments)\n        self.obj_info = list(obj_info)\n        self.elements = elements\n\n    def _get_elements(self):\n        return self._elements\n\n    def _set_elements(self, elements):\n        self._elements = tuple(elements)\n        self._index()\n\n    elements = property(_get_elements, _set_elements)\n\n    def _get_byte_order(self):\n        return self._byte_order\n\n    def _set_byte_order(self, byte_order):\n        if byte_order not in [\'<\', \'>\', \'=\']:\n            raise ValueError(""byte order must be \'<\', \'>\', or \'=\'"")\n\n        self._byte_order = byte_order\n\n    byte_order = property(_get_byte_order, _set_byte_order)\n\n    def _index(self):\n        self._element_lookup = dict((elt.name, elt) for elt in\n                                    self._elements)\n        if len(self._element_lookup) != len(self._elements):\n            raise ValueError(""two elements with same name"")\n\n    @staticmethod\n    def _parse_header(stream):\n        \'\'\'\n        Parse a PLY header from a readable file-like stream.\n\n        \'\'\'\n        lines = []\n        comments = {\'comment\': [], \'obj_info\': []}\n        while True:\n            line = stream.readline().decode(\'ascii\').strip()\n            fields = _split_line(line, 1)\n\n            if fields[0] == \'end_header\':\n                break\n\n            elif fields[0] in comments.keys():\n                lines.append(fields)\n            else:\n                lines.append(line.split())\n\n        a = 0\n        if lines[a] != [\'ply\']:\n            raise PlyParseError(""expected \'ply\'"")\n\n        a += 1\n        while lines[a][0] in comments.keys():\n            comments[lines[a][0]].append(lines[a][1])\n            a += 1\n\n        if lines[a][0] != \'format\':\n            raise PlyParseError(""expected \'format\'"")\n\n        if lines[a][2] != \'1.0\':\n            raise PlyParseError(""expected version \'1.0\'"")\n\n        if len(lines[a]) != 3:\n            raise PlyParseError(""too many fields after \'format\'"")\n\n        fmt = lines[a][1]\n\n        if fmt not in _byte_order_map:\n            raise PlyParseError(""don\'t understand format %r"" % fmt)\n\n        byte_order = _byte_order_map[fmt]\n        text = fmt == \'ascii\'\n\n        a += 1\n        while a < len(lines) and lines[a][0] in comments.keys():\n            comments[lines[a][0]].append(lines[a][1])\n            a += 1\n\n        return PlyData(PlyElement._parse_multi(lines[a:]),\n                       text, byte_order,\n                       comments[\'comment\'], comments[\'obj_info\'])\n\n    @staticmethod\n    def read(stream):\n        \'\'\'\n        Read PLY data from a readable file-like object or filename.\n\n        \'\'\'\n        (must_close, stream) = _open_stream(stream, \'read\')\n        try:\n            data = PlyData._parse_header(stream)\n            for elt in data:\n                elt._read(stream, data.text, data.byte_order)\n        finally:\n            if must_close:\n                stream.close()\n\n        return data\n\n    def write(self, stream):\n        \'\'\'\n        Write PLY data to a writeable file-like object or filename.\n\n        \'\'\'\n        (must_close, stream) = _open_stream(stream, \'write\')\n        try:\n            stream.write(self.header.encode(\'ascii\'))\n            stream.write(b\'\\r\\n\')\n            for elt in self:\n                elt._write(stream, self.text, self.byte_order)\n        finally:\n            if must_close:\n                stream.close()\n\n    @property\n    def header(self):\n        \'\'\'\n        Provide PLY-formatted metadata for the instance.\n\n        \'\'\'\n        lines = [\'ply\']\n\n        if self.text:\n            lines.append(\'format ascii 1.0\')\n        else:\n            lines.append(\'format \' +\n                         _byte_order_reverse[self.byte_order] +\n                         \' 1.0\')\n\n        # Some information is lost here, since all comments are placed\n        # between the \'format\' line and the first element.\n        for c in self.comments:\n            lines.append(\'comment \' + c)\n\n        for c in self.obj_info:\n            lines.append(\'obj_info \' + c)\n\n        lines.extend(elt.header for elt in self.elements)\n        lines.append(\'end_header\')\n        return \'\\r\\n\'.join(lines)\n\n    def __iter__(self):\n        return iter(self.elements)\n\n    def __len__(self):\n        return len(self.elements)\n\n    def __contains__(self, name):\n        return name in self._element_lookup\n\n    def __getitem__(self, name):\n        return self._element_lookup[name]\n\n    def __str__(self):\n        return self.header\n\n    def __repr__(self):\n        return (\'PlyData(%r, text=%r, byte_order=%r, \'\n                \'comments=%r, obj_info=%r)\' %\n                (self.elements, self.text, self.byte_order,\n                 self.comments, self.obj_info))\n\n\ndef _open_stream(stream, read_or_write):\n    if hasattr(stream, read_or_write):\n        return (False, stream)\n    try:\n        return (True, open(stream, read_or_write[0] + \'b\'))\n    except TypeError:\n        raise RuntimeError(""expected open file or filename"")\n\n\nclass PlyElement(object):\n\n    \'\'\'\n    PLY file element.\n\n    A client of this library doesn\'t normally need to instantiate this\n    directly, so the following is only for the sake of documenting the\n    internals.\n\n    Creating a PlyElement instance is generally done in one of two ways:\n    as a byproduct of PlyData.read (when reading a PLY file) and by\n    PlyElement.describe (before writing a PLY file).\n\n    \'\'\'\n\n    def __init__(self, name, properties, count, comments=[]):\n        \'\'\'\n        This is not part of the public interface.  The preferred methods\n        of obtaining PlyElement instances are PlyData.read (to read from\n        a file) and PlyElement.describe (to construct from a numpy\n        array).\n\n        \'\'\'\n        self._name = str(name)\n        self._check_name()\n        self._count = count\n\n        self._properties = tuple(properties)\n        self._index()\n\n        self.comments = list(comments)\n\n        self._have_list = any(isinstance(p, PlyListProperty)\n                              for p in self.properties)\n\n    @property\n    def count(self):\n        return self._count\n\n    def _get_data(self):\n        return self._data\n\n    def _set_data(self, data):\n        self._data = data\n        self._count = len(data)\n        self._check_sanity()\n\n    data = property(_get_data, _set_data)\n\n    def _check_sanity(self):\n        for prop in self.properties:\n            if prop.name not in self._data.dtype.fields:\n                raise ValueError(""dangling property %r"" % prop.name)\n\n    def _get_properties(self):\n        return self._properties\n\n    def _set_properties(self, properties):\n        self._properties = tuple(properties)\n        self._check_sanity()\n        self._index()\n\n    properties = property(_get_properties, _set_properties)\n\n    def _index(self):\n        self._property_lookup = dict((prop.name, prop)\n                                     for prop in self._properties)\n        if len(self._property_lookup) != len(self._properties):\n            raise ValueError(""two properties with same name"")\n\n    def ply_property(self, name):\n        return self._property_lookup[name]\n\n    @property\n    def name(self):\n        return self._name\n\n    def _check_name(self):\n        if any(c.isspace() for c in self._name):\n            msg = ""element name %r contains spaces"" % self._name\n            raise ValueError(msg)\n\n    def dtype(self, byte_order=\'=\'):\n        \'\'\'\n        Return the numpy dtype of the in-memory representation of the\n        data.  (If there are no list properties, and the PLY format is\n        binary, then this also accurately describes the on-disk\n        representation of the element.)\n\n        \'\'\'\n        return [(prop.name, prop.dtype(byte_order))\n                for prop in self.properties]\n\n    @staticmethod\n    def _parse_multi(header_lines):\n        \'\'\'\n        Parse a list of PLY element definitions.\n\n        \'\'\'\n        elements = []\n        while header_lines:\n            (elt, header_lines) = PlyElement._parse_one(header_lines)\n            elements.append(elt)\n\n        return elements\n\n    @staticmethod\n    def _parse_one(lines):\n        \'\'\'\n        Consume one element definition.  The unconsumed input is\n        returned along with a PlyElement instance.\n\n        \'\'\'\n        a = 0\n        line = lines[a]\n\n        if line[0] != \'element\':\n            raise PlyParseError(""expected \'element\'"")\n        if len(line) > 3:\n            raise PlyParseError(""too many fields after \'element\'"")\n        if len(line) < 3:\n            raise PlyParseError(""too few fields after \'element\'"")\n\n        (name, count) = (line[1], int(line[2]))\n\n        comments = []\n        properties = []\n        while True:\n            a += 1\n            if a >= len(lines):\n                break\n\n            if lines[a][0] == \'comment\':\n                comments.append(lines[a][1])\n            elif lines[a][0] == \'property\':\n                properties.append(PlyProperty._parse_one(lines[a]))\n            else:\n                break\n\n        return (PlyElement(name, properties, count, comments),\n                lines[a:])\n\n    @staticmethod\n    def describe(data, name, len_types={}, val_types={},\n                 comments=[]):\n        \'\'\'\n        Construct a PlyElement from an array\'s metadata.\n\n        len_types and val_types can be given as mappings from list\n        property names to type strings (like \'u1\', \'f4\', etc., or\n        \'int8\', \'float32\', etc.). These can be used to define the length\n        and value types of list properties.  List property lengths\n        always default to type \'u1\' (8-bit unsigned integer), and value\n        types default to \'i4\' (32-bit integer).\n\n        \'\'\'\n        if not isinstance(data, _np.ndarray):\n            raise TypeError(""only numpy arrays are supported"")\n\n        if len(data.shape) != 1:\n            raise ValueError(""only one-dimensional arrays are ""\n                             ""supported"")\n\n        count = len(data)\n\n        properties = []\n        descr = data.dtype.descr\n\n        for t in descr:\n            if not isinstance(t[1], str):\n                raise ValueError(""nested records not supported"")\n\n            if not t[0]:\n                raise ValueError(""field with empty name"")\n\n            if len(t) != 2 or t[1][1] == \'O\':\n                # non-scalar field, which corresponds to a list\n                # property in PLY.\n\n                if t[1][1] == \'O\':\n                    if len(t) != 2:\n                        raise ValueError(""non-scalar object fields not ""\n                                         ""supported"")\n\n                len_str = _data_type_reverse[len_types.get(t[0], \'u1\')]\n                if t[1][1] == \'O\':\n                    val_type = val_types.get(t[0], \'i4\')\n                    val_str = _lookup_type(val_type)\n                else:\n                    val_str = _lookup_type(t[1][1:])\n\n                prop = PlyListProperty(t[0], len_str, val_str)\n            else:\n                val_str = _lookup_type(t[1][1:])\n                prop = PlyProperty(t[0], val_str)\n\n            properties.append(prop)\n\n        elt = PlyElement(name, properties, count, comments)\n        elt.data = data\n\n        return elt\n\n    def _read(self, stream, text, byte_order):\n        \'\'\'\n        Read the actual data from a PLY file.\n\n        \'\'\'\n        if text:\n            self._read_txt(stream)\n        else:\n            if self._have_list:\n                # There are list properties, so a simple load is\n                # impossible.\n                self._read_bin(stream, byte_order)\n            else:\n                # There are no list properties, so loading the data is\n                # much more straightforward.\n                self._data = _np.fromfile(stream,\n                                          self.dtype(byte_order),\n                                          self.count)\n\n        if len(self._data) < self.count:\n            k = len(self._data)\n            del self._data\n            raise PlyParseError(""early end-of-file"", self, k)\n\n        self._check_sanity()\n\n    def _write(self, stream, text, byte_order):\n        \'\'\'\n        Write the data to a PLY file.\n\n        \'\'\'\n        if text:\n            self._write_txt(stream)\n        else:\n            if self._have_list:\n                # There are list properties, so serialization is\n                # slightly complicated.\n                self._write_bin(stream, byte_order)\n            else:\n                # no list properties, so serialization is\n                # straightforward.\n                self.data.astype(self.dtype(byte_order),\n                                 copy=False).tofile(stream)\n\n    def _read_txt(self, stream):\n        \'\'\'\n        Load a PLY element from an ASCII-format PLY file.  The element\n        may contain list properties.\n\n        \'\'\'\n        self._data = _np.empty(self.count, dtype=self.dtype())\n\n        k = 0\n        for line in _islice(iter(stream.readline, b\'\'), self.count):\n            fields = iter(line.strip().split())\n            for prop in self.properties:\n                try:\n                    self._data[prop.name][k] = prop._from_fields(fields)\n                except StopIteration:\n                    raise PlyParseError(""early end-of-line"",\n                                        self, k, prop)\n                except ValueError:\n                    raise PlyParseError(""malformed input"",\n                                        self, k, prop)\n            try:\n                next(fields)\n            except StopIteration:\n                pass\n            else:\n                raise PlyParseError(""expected end-of-line"", self, k)\n            k += 1\n\n        if k < self.count:\n            del self._data\n            raise PlyParseError(""early end-of-file"", self, k)\n\n    def _write_txt(self, stream):\n        \'\'\'\n        Save a PLY element to an ASCII-format PLY file.  The element may\n        contain list properties.\n\n        \'\'\'\n        for rec in self.data:\n            fields = []\n            for prop in self.properties:\n                fields.extend(prop._to_fields(rec[prop.name]))\n\n            _np.savetxt(stream, [fields], \'%.18g\', newline=\'\\r\\n\')\n\n    def _read_bin(self, stream, byte_order):\n        \'\'\'\n        Load a PLY element from a binary PLY file.  The element may\n        contain list properties.\n\n        \'\'\'\n        self._data = _np.empty(self.count, dtype=self.dtype(byte_order))\n\n        for k in _range(self.count):\n            for prop in self.properties:\n                try:\n                    self._data[prop.name][k] = \\\n                        prop._read_bin(stream, byte_order)\n                except StopIteration:\n                    raise PlyParseError(""early end-of-file"",\n                                        self, k, prop)\n\n    def _write_bin(self, stream, byte_order):\n        \'\'\'\n        Save a PLY element to a binary PLY file.  The element may\n        contain list properties.\n\n        \'\'\'\n        for rec in self.data:\n            for prop in self.properties:\n                prop._write_bin(rec[prop.name], stream, byte_order)\n\n    @property\n    def header(self):\n        \'\'\'\n        Format this element\'s metadata as it would appear in a PLY\n        header.\n\n        \'\'\'\n        lines = [\'element %s %d\' % (self.name, self.count)]\n\n        # Some information is lost here, since all comments are placed\n        # between the \'element\' line and the first property definition.\n        for c in self.comments:\n            lines.append(\'comment \' + c)\n\n        lines.extend(list(map(str, self.properties)))\n\n        return \'\\r\\n\'.join(lines)\n\n    def __getitem__(self, key):\n        return self.data[key]\n\n    def __setitem__(self, key, value):\n        self.data[key] = value\n\n    def __str__(self):\n        return self.header\n\n    def __repr__(self):\n        return (\'PlyElement(%r, %r, count=%d, comments=%r)\' %\n                (self.name, self.properties, self.count,\n                 self.comments))\n\n\nclass PlyProperty(object):\n\n    \'\'\'\n    PLY property description.  This class is pure metadata; the data\n    itself is contained in PlyElement instances.\n\n    \'\'\'\n\n    def __init__(self, name, val_dtype):\n        self._name = str(name)\n        self._check_name()\n        self.val_dtype = val_dtype\n\n    def _get_val_dtype(self):\n        return self._val_dtype\n\n    def _set_val_dtype(self, val_dtype):\n        self._val_dtype = _data_types[_lookup_type(val_dtype)]\n\n    val_dtype = property(_get_val_dtype, _set_val_dtype)\n\n    @property\n    def name(self):\n        return self._name\n\n    def _check_name(self):\n        if any(c.isspace() for c in self._name):\n            msg = ""Error: property name %r contains spaces"" % self._name\n            raise RuntimeError(msg)\n\n    @staticmethod\n    def _parse_one(line):\n        assert line[0] == \'property\'\n\n        if line[1] == \'list\':\n            if len(line) > 5:\n                raise PlyParseError(""too many fields after ""\n                                    ""\'property list\'"")\n            if len(line) < 5:\n                raise PlyParseError(""too few fields after ""\n                                    ""\'property list\'"")\n\n            return PlyListProperty(line[4], line[2], line[3])\n\n        else:\n            if len(line) > 3:\n                raise PlyParseError(""too many fields after ""\n                                    ""\'property\'"")\n            if len(line) < 3:\n                raise PlyParseError(""too few fields after ""\n                                    ""\'property\'"")\n\n            return PlyProperty(line[2], line[1])\n\n    def dtype(self, byte_order=\'=\'):\n        \'\'\'\n        Return the numpy dtype description for this property (as a tuple\n        of strings).\n\n        \'\'\'\n        return byte_order + self.val_dtype\n\n    def _from_fields(self, fields):\n        \'\'\'\n        Parse from generator.  Raise StopIteration if the property could\n        not be read.\n\n        \'\'\'\n        return _np.dtype(self.dtype()).type(next(fields))\n\n    def _to_fields(self, data):\n        \'\'\'\n        Return generator over one item.\n\n        \'\'\'\n        yield _np.dtype(self.dtype()).type(data)\n\n    def _read_bin(self, stream, byte_order):\n        \'\'\'\n        Read data from a binary stream.  Raise StopIteration if the\n        property could not be read.\n\n        \'\'\'\n        try:\n            return _np.fromfile(stream, self.dtype(byte_order), 1)[0]\n        except IndexError:\n            raise StopIteration\n\n    def _write_bin(self, data, stream, byte_order):\n        \'\'\'\n        Write data to a binary stream.\n\n        \'\'\'\n        _np.dtype(self.dtype(byte_order)).type(data).tofile(stream)\n\n    def __str__(self):\n        val_str = _data_type_reverse[self.val_dtype]\n        return \'property %s %s\' % (val_str, self.name)\n\n    def __repr__(self):\n        return \'PlyProperty(%r, %r)\' % (self.name,\n                                        _lookup_type(self.val_dtype))\n\n\nclass PlyListProperty(PlyProperty):\n\n    \'\'\'\n    PLY list property description.\n\n    \'\'\'\n\n    def __init__(self, name, len_dtype, val_dtype):\n        PlyProperty.__init__(self, name, val_dtype)\n\n        self.len_dtype = len_dtype\n\n    def _get_len_dtype(self):\n        return self._len_dtype\n\n    def _set_len_dtype(self, len_dtype):\n        self._len_dtype = _data_types[_lookup_type(len_dtype)]\n\n    len_dtype = property(_get_len_dtype, _set_len_dtype)\n\n    def dtype(self, byte_order=\'=\'):\n        \'\'\'\n        List properties always have a numpy dtype of ""object"".\n\n        \'\'\'\n        return \'|O\'\n\n    def list_dtype(self, byte_order=\'=\'):\n        \'\'\'\n        Return the pair (len_dtype, val_dtype) (both numpy-friendly\n        strings).\n\n        \'\'\'\n        return (byte_order + self.len_dtype,\n                byte_order + self.val_dtype)\n\n    def _from_fields(self, fields):\n        (len_t, val_t) = self.list_dtype()\n\n        n = int(_np.dtype(len_t).type(next(fields)))\n\n        data = _np.loadtxt(list(_islice(fields, n)), val_t, ndmin=1)\n        if len(data) < n:\n            raise StopIteration\n\n        return data\n\n    def _to_fields(self, data):\n        \'\'\'\n        Return generator over the (numerical) PLY representation of the\n        list data (length followed by actual data).\n\n        \'\'\'\n        (len_t, val_t) = self.list_dtype()\n\n        data = _np.asarray(data, dtype=val_t).ravel()\n\n        yield _np.dtype(len_t).type(data.size)\n        for x in data:\n            yield x\n\n    def _read_bin(self, stream, byte_order):\n        (len_t, val_t) = self.list_dtype(byte_order)\n\n        try:\n            n = _np.fromfile(stream, len_t, 1)[0]\n        except IndexError:\n            raise StopIteration\n\n        data = _np.fromfile(stream, val_t, n)\n        if len(data) < n:\n            raise StopIteration\n\n        return data\n\n    def _write_bin(self, data, stream, byte_order):\n        \'\'\'\n        Write data to a binary stream.\n\n        \'\'\'\n        (len_t, val_t) = self.list_dtype(byte_order)\n\n        data = _np.asarray(data, dtype=val_t).ravel()\n\n        _np.array(data.size, dtype=len_t).tofile(stream)\n        data.tofile(stream)\n\n    def __str__(self):\n        len_str = _data_type_reverse[self.len_dtype]\n        val_str = _data_type_reverse[self.val_dtype]\n        return \'property list %s %s %s\' % (len_str, val_str, self.name)\n\n    def __repr__(self):\n        return (\'PlyListProperty(%r, %r, %r)\' %\n                (self.name,\n                 _lookup_type(self.len_dtype),\n                 _lookup_type(self.val_dtype)))\n'"
utils/tf_util.py,60,"b'"""""" Wrapper functions for TensorFlow layers.\n\nAuthor: Charles R. Qi\nDate: November 2016\n""""""\n\nimport numpy as np\nimport tensorflow as tf\n\ndef _variable_on_cpu(name, shape, initializer, use_fp16=False):\n  """"""Helper to create a Variable stored on CPU memory.\n  Args:\n    name: name of the variable\n    shape: list of ints\n    initializer: initializer for Variable\n  Returns:\n    Variable Tensor\n  """"""\n  with tf.device(\'/cpu:0\'):\n    dtype = tf.float16 if use_fp16 else tf.float32\n    var = tf.get_variable(name, shape, initializer=initializer, dtype=dtype)\n  return var\n\ndef _variable_with_weight_decay(name, shape, stddev, wd, use_xavier=True):\n  """"""Helper to create an initialized Variable with weight decay.\n\n  Note that the Variable is initialized with a truncated normal distribution.\n  A weight decay is added only if one is specified.\n\n  Args:\n    name: name of the variable\n    shape: list of ints\n    stddev: standard deviation of a truncated Gaussian\n    wd: add L2Loss weight decay multiplied by this float. If None, weight\n        decay is not added for this Variable.\n    use_xavier: bool, whether to use xavier initializer\n\n  Returns:\n    Variable Tensor\n  """"""\n  if use_xavier:\n    initializer = tf.contrib.layers.xavier_initializer()\n  else:\n    initializer = tf.truncated_normal_initializer(stddev=stddev)\n  var = _variable_on_cpu(name, shape, initializer)\n  if wd is not None:\n    weight_decay = tf.multiply(tf.nn.l2_loss(var), wd, name=\'weight_loss\')\n    tf.add_to_collection(\'losses\', weight_decay)\n  return var\n\n\ndef conv1d(inputs,\n           num_output_channels,\n           kernel_size,\n           scope,\n           stride=1,\n           padding=\'SAME\',\n           use_xavier=True,\n           stddev=1e-3,\n           weight_decay=0.0,\n           activation_fn=tf.nn.relu,\n           bn=False,\n           bn_decay=None,\n           is_training=None):\n  """""" 1D convolution with non-linear operation.\n\n  Args:\n    inputs: 3-D tensor variable BxLxC\n    num_output_channels: int\n    kernel_size: int\n    scope: string\n    stride: int\n    padding: \'SAME\' or \'VALID\'\n    use_xavier: bool, use xavier_initializer if true\n    stddev: float, stddev for truncated_normal init\n    weight_decay: float\n    activation_fn: function\n    bn: bool, whether to use batch norm\n    bn_decay: float or float tensor variable in [0,1]\n    is_training: bool Tensor variable\n\n  Returns:\n    Variable tensor\n  """"""\n  with tf.variable_scope(scope) as sc:\n    num_in_channels = inputs.get_shape()[-1].value\n    kernel_shape = [kernel_size,\n                    num_in_channels, num_output_channels]\n    kernel = _variable_with_weight_decay(\'weights\',\n                                         shape=kernel_shape,\n                                         use_xavier=use_xavier,\n                                         stddev=stddev,\n                                         wd=weight_decay)\n    outputs = tf.nn.conv1d(inputs, kernel,\n                           stride=stride,\n                           padding=padding)\n    biases = _variable_on_cpu(\'biases\', [num_output_channels],\n                              tf.constant_initializer(0.0))\n    outputs = tf.nn.bias_add(outputs, biases)\n\n    if bn:\n      outputs = batch_norm_for_conv1d(outputs, is_training,\n                                      bn_decay=bn_decay, scope=\'bn\')\n\n    if activation_fn is not None:\n      outputs = activation_fn(outputs)\n    return outputs\n\n\n\n\ndef conv2d(inputs,\n           num_output_channels,\n           kernel_size,\n           scope,\n           stride=[1, 1],\n           padding=\'SAME\',\n           use_xavier=True,\n           stddev=1e-3,\n           weight_decay=0.0,\n           activation_fn=tf.nn.relu,\n           bn=False,\n           bn_decay=None,\n           is_training=None):\n  """""" 2D convolution with non-linear operation.\n\n  Args:\n    inputs: 4-D tensor variable BxHxWxC\n    num_output_channels: int\n    kernel_size: a list of 2 ints\n    scope: string\n    stride: a list of 2 ints\n    padding: \'SAME\' or \'VALID\'\n    use_xavier: bool, use xavier_initializer if true\n    stddev: float, stddev for truncated_normal init\n    weight_decay: float\n    activation_fn: function\n    bn: bool, whether to use batch norm\n    bn_decay: float or float tensor variable in [0,1]\n    is_training: bool Tensor variable\n\n  Returns:\n    Variable tensor\n  """"""\n  with tf.variable_scope(scope) as sc:\n      kernel_h, kernel_w = kernel_size\n      num_in_channels = inputs.get_shape()[-1].value\n      kernel_shape = [kernel_h, kernel_w,\n                      num_in_channels, num_output_channels]\n      kernel = _variable_with_weight_decay(\'weights\',\n                                           shape=kernel_shape,\n                                           use_xavier=use_xavier,\n                                           stddev=stddev,\n                                           wd=weight_decay)\n      stride_h, stride_w = stride\n      outputs = tf.nn.conv2d(inputs, kernel,\n                             [1, stride_h, stride_w, 1],\n                             padding=padding)\n      biases = _variable_on_cpu(\'biases\', [num_output_channels],\n                                tf.constant_initializer(0.0))\n      outputs = tf.nn.bias_add(outputs, biases)\n\n      if bn:\n        outputs = batch_norm_for_conv2d(outputs, is_training,\n                                        bn_decay=bn_decay, scope=\'bn\')\n\n      if activation_fn is not None:\n        outputs = activation_fn(outputs)\n      return outputs\n\n\ndef conv2d_transpose(inputs,\n                     num_output_channels,\n                     kernel_size,\n                     scope,\n                     stride=[1, 1],\n                     padding=\'SAME\',\n                     use_xavier=True,\n                     stddev=1e-3,\n                     weight_decay=0.0,\n                     activation_fn=tf.nn.relu,\n                     bn=False,\n                     bn_decay=None,\n                     is_training=None):\n  """""" 2D convolution transpose with non-linear operation.\n\n  Args:\n    inputs: 4-D tensor variable BxHxWxC\n    num_output_channels: int\n    kernel_size: a list of 2 ints\n    scope: string\n    stride: a list of 2 ints\n    padding: \'SAME\' or \'VALID\'\n    use_xavier: bool, use xavier_initializer if true\n    stddev: float, stddev for truncated_normal init\n    weight_decay: float\n    activation_fn: function\n    bn: bool, whether to use batch norm\n    bn_decay: float or float tensor variable in [0,1]\n    is_training: bool Tensor variable\n\n  Returns:\n    Variable tensor\n\n  Note: conv2d(conv2d_transpose(a, num_out, ksize, stride), a.shape[-1], ksize, stride) == a\n  """"""\n  with tf.variable_scope(scope) as sc:\n      kernel_h, kernel_w = kernel_size\n      num_in_channels = inputs.get_shape()[-1].value\n      kernel_shape = [kernel_h, kernel_w,\n                      num_output_channels, num_in_channels] # reversed to conv2d\n      kernel = _variable_with_weight_decay(\'weights\',\n                                           shape=kernel_shape,\n                                           use_xavier=use_xavier,\n                                           stddev=stddev,\n                                           wd=weight_decay)\n      stride_h, stride_w = stride\n      \n      # from slim.convolution2d_transpose\n      def get_deconv_dim(dim_size, stride_size, kernel_size, padding):\n          dim_size *= stride_size\n\n          if padding == \'VALID\' and dim_size is not None:\n            dim_size += max(kernel_size - stride_size, 0)\n          return dim_size\n\n      # caculate output shape\n      batch_size = inputs.get_shape()[0].value\n      height = inputs.get_shape()[1].value\n      width = inputs.get_shape()[2].value\n      out_height = get_deconv_dim(height, stride_h, kernel_h, padding)\n      out_width = get_deconv_dim(width, stride_w, kernel_w, padding)\n      output_shape = [batch_size, out_height, out_width, num_output_channels]\n\n      outputs = tf.nn.conv2d_transpose(inputs, kernel, output_shape,\n                             [1, stride_h, stride_w, 1],\n                             padding=padding)\n      biases = _variable_on_cpu(\'biases\', [num_output_channels],\n                                tf.constant_initializer(0.0))\n      outputs = tf.nn.bias_add(outputs, biases)\n\n      if bn:\n        outputs = batch_norm_for_conv2d(outputs, is_training,\n                                        bn_decay=bn_decay, scope=\'bn\')\n\n      if activation_fn is not None:\n        outputs = activation_fn(outputs)\n      return outputs\n\n   \n\ndef conv3d(inputs,\n           num_output_channels,\n           kernel_size,\n           scope,\n           stride=[1, 1, 1],\n           padding=\'SAME\',\n           use_xavier=True,\n           stddev=1e-3,\n           weight_decay=0.0,\n           activation_fn=tf.nn.relu,\n           bn=False,\n           bn_decay=None,\n           is_training=None):\n  """""" 3D convolution with non-linear operation.\n\n  Args:\n    inputs: 5-D tensor variable BxDxHxWxC\n    num_output_channels: int\n    kernel_size: a list of 3 ints\n    scope: string\n    stride: a list of 3 ints\n    padding: \'SAME\' or \'VALID\'\n    use_xavier: bool, use xavier_initializer if true\n    stddev: float, stddev for truncated_normal init\n    weight_decay: float\n    activation_fn: function\n    bn: bool, whether to use batch norm\n    bn_decay: float or float tensor variable in [0,1]\n    is_training: bool Tensor variable\n\n  Returns:\n    Variable tensor\n  """"""\n  with tf.variable_scope(scope) as sc:\n    kernel_d, kernel_h, kernel_w = kernel_size\n    num_in_channels = inputs.get_shape()[-1].value\n    kernel_shape = [kernel_d, kernel_h, kernel_w,\n                    num_in_channels, num_output_channels]\n    kernel = _variable_with_weight_decay(\'weights\',\n                                         shape=kernel_shape,\n                                         use_xavier=use_xavier,\n                                         stddev=stddev,\n                                         wd=weight_decay)\n    stride_d, stride_h, stride_w = stride\n    outputs = tf.nn.conv3d(inputs, kernel,\n                           [1, stride_d, stride_h, stride_w, 1],\n                           padding=padding)\n    biases = _variable_on_cpu(\'biases\', [num_output_channels],\n                              tf.constant_initializer(0.0))\n    outputs = tf.nn.bias_add(outputs, biases)\n    \n    if bn:\n      outputs = batch_norm_for_conv3d(outputs, is_training,\n                                      bn_decay=bn_decay, scope=\'bn\')\n\n    if activation_fn is not None:\n      outputs = activation_fn(outputs)\n    return outputs\n\ndef fully_connected(inputs,\n                    num_outputs,\n                    scope,\n                    use_xavier=True,\n                    stddev=1e-3,\n                    weight_decay=0.0,\n                    activation_fn=tf.nn.relu,\n                    bn=False,\n                    bn_decay=None,\n                    is_training=None):\n  """""" Fully connected layer with non-linear operation.\n  \n  Args:\n    inputs: 2-D tensor BxN\n    num_outputs: int\n  \n  Returns:\n    Variable tensor of size B x num_outputs.\n  """"""\n  with tf.variable_scope(scope) as sc:\n    num_input_units = inputs.get_shape()[-1].value\n    weights = _variable_with_weight_decay(\'weights\',\n                                          shape=[num_input_units, num_outputs],\n                                          use_xavier=use_xavier,\n                                          stddev=stddev,\n                                          wd=weight_decay)\n    outputs = tf.matmul(inputs, weights)\n    biases = _variable_on_cpu(\'biases\', [num_outputs],\n                             tf.constant_initializer(0.0))\n    outputs = tf.nn.bias_add(outputs, biases)\n     \n    if bn:\n      outputs = batch_norm_for_fc(outputs, is_training, bn_decay, \'bn\')\n\n    if activation_fn is not None:\n      outputs = activation_fn(outputs)\n    return outputs\n\n\ndef max_pool2d(inputs,\n               kernel_size,\n               scope,\n               stride=[2, 2],\n               padding=\'VALID\'):\n  """""" 2D max pooling.\n\n  Args:\n    inputs: 4-D tensor BxHxWxC\n    kernel_size: a list of 2 ints\n    stride: a list of 2 ints\n  \n  Returns:\n    Variable tensor\n  """"""\n  with tf.variable_scope(scope) as sc:\n    kernel_h, kernel_w = kernel_size\n    stride_h, stride_w = stride\n    outputs = tf.nn.max_pool(inputs,\n                             ksize=[1, kernel_h, kernel_w, 1],\n                             strides=[1, stride_h, stride_w, 1],\n                             padding=padding,\n                             name=sc.name)\n    return outputs\n\ndef avg_pool2d(inputs,\n               kernel_size,\n               scope,\n               stride=[2, 2],\n               padding=\'VALID\'):\n  """""" 2D avg pooling.\n\n  Args:\n    inputs: 4-D tensor BxHxWxC\n    kernel_size: a list of 2 ints\n    stride: a list of 2 ints\n  \n  Returns:\n    Variable tensor\n  """"""\n  with tf.variable_scope(scope) as sc:\n    kernel_h, kernel_w = kernel_size\n    stride_h, stride_w = stride\n    outputs = tf.nn.avg_pool(inputs,\n                             ksize=[1, kernel_h, kernel_w, 1],\n                             strides=[1, stride_h, stride_w, 1],\n                             padding=padding,\n                             name=sc.name)\n    return outputs\n\n\ndef max_pool3d(inputs,\n               kernel_size,\n               scope,\n               stride=[2, 2, 2],\n               padding=\'VALID\'):\n  """""" 3D max pooling.\n\n  Args:\n    inputs: 5-D tensor BxDxHxWxC\n    kernel_size: a list of 3 ints\n    stride: a list of 3 ints\n  \n  Returns:\n    Variable tensor\n  """"""\n  with tf.variable_scope(scope) as sc:\n    kernel_d, kernel_h, kernel_w = kernel_size\n    stride_d, stride_h, stride_w = stride\n    outputs = tf.nn.max_pool3d(inputs,\n                               ksize=[1, kernel_d, kernel_h, kernel_w, 1],\n                               strides=[1, stride_d, stride_h, stride_w, 1],\n                               padding=padding,\n                               name=sc.name)\n    return outputs\n\ndef avg_pool3d(inputs,\n               kernel_size,\n               scope,\n               stride=[2, 2, 2],\n               padding=\'VALID\'):\n  """""" 3D avg pooling.\n\n  Args:\n    inputs: 5-D tensor BxDxHxWxC\n    kernel_size: a list of 3 ints\n    stride: a list of 3 ints\n  \n  Returns:\n    Variable tensor\n  """"""\n  with tf.variable_scope(scope) as sc:\n    kernel_d, kernel_h, kernel_w = kernel_size\n    stride_d, stride_h, stride_w = stride\n    outputs = tf.nn.avg_pool3d(inputs,\n                               ksize=[1, kernel_d, kernel_h, kernel_w, 1],\n                               strides=[1, stride_d, stride_h, stride_w, 1],\n                               padding=padding,\n                               name=sc.name)\n    return outputs\n\n\n\n\n\ndef batch_norm_template(inputs, is_training, scope, moments_dims, bn_decay):\n  """""" Batch normalization on convolutional maps and beyond...\n  Ref.: http://stackoverflow.com/questions/33949786/how-could-i-use-batch-normalization-in-tensorflow\n  \n  Args:\n      inputs:        Tensor, k-D input ... x C could be BC or BHWC or BDHWC\n      is_training:   boolean tf.Varialbe, true indicates training phase\n      scope:         string, variable scope\n      moments_dims:  a list of ints, indicating dimensions for moments calculation\n      bn_decay:      float or float tensor variable, controling moving average weight\n  Return:\n      normed:        batch-normalized maps\n  """"""\n  with tf.variable_scope(scope) as sc:\n    num_channels = inputs.get_shape()[-1].value\n    beta = tf.Variable(tf.constant(0.0, shape=[num_channels]),\n                       name=\'beta\', trainable=True)\n    gamma = tf.Variable(tf.constant(1.0, shape=[num_channels]),\n                        name=\'gamma\', trainable=True)\n    batch_mean, batch_var = tf.nn.moments(inputs, moments_dims, name=\'moments\')\n    decay = bn_decay if bn_decay is not None else 0.9\n    ema = tf.train.ExponentialMovingAverage(decay=decay)\n    # Operator that maintains moving averages of variables.\n    ema_apply_op = tf.cond(is_training,\n                           lambda: ema.apply([batch_mean, batch_var]),\n                           lambda: tf.no_op())\n    \n    # Update moving average and return current batch\'s avg and var.\n    def mean_var_with_update():\n      with tf.control_dependencies([ema_apply_op]):\n        return tf.identity(batch_mean), tf.identity(batch_var)\n    \n    # ema.average returns the Variable holding the average of var.\n    mean, var = tf.cond(is_training,\n                        mean_var_with_update,\n                        lambda: (ema.average(batch_mean), ema.average(batch_var)))\n    normed = tf.nn.batch_normalization(inputs, mean, var, beta, gamma, 1e-3)\n  return normed\n\n\ndef batch_norm_for_fc(inputs, is_training, bn_decay, scope):\n  """""" Batch normalization on FC data.\n  \n  Args:\n      inputs:      Tensor, 2D BxC input\n      is_training: boolean tf.Varialbe, true indicates training phase\n      bn_decay:    float or float tensor variable, controling moving average weight\n      scope:       string, variable scope\n  Return:\n      normed:      batch-normalized maps\n  """"""\n  return batch_norm_template(inputs, is_training, scope, [0,], bn_decay)\n\n\ndef batch_norm_for_conv1d(inputs, is_training, bn_decay, scope):\n  """""" Batch normalization on 1D convolutional maps.\n  \n  Args:\n      inputs:      Tensor, 3D BLC input maps\n      is_training: boolean tf.Varialbe, true indicates training phase\n      bn_decay:    float or float tensor variable, controling moving average weight\n      scope:       string, variable scope\n  Return:\n      normed:      batch-normalized maps\n  """"""\n  return batch_norm_template(inputs, is_training, scope, [0,1], bn_decay)\n\n\n\n  \ndef batch_norm_for_conv2d(inputs, is_training, bn_decay, scope):\n  """""" Batch normalization on 2D convolutional maps.\n  \n  Args:\n      inputs:      Tensor, 4D BHWC input maps\n      is_training: boolean tf.Varialbe, true indicates training phase\n      bn_decay:    float or float tensor variable, controling moving average weight\n      scope:       string, variable scope\n  Return:\n      normed:      batch-normalized maps\n  """"""\n  return batch_norm_template(inputs, is_training, scope, [0,1,2], bn_decay)\n\n\n\ndef batch_norm_for_conv3d(inputs, is_training, bn_decay, scope):\n  """""" Batch normalization on 3D convolutional maps.\n  \n  Args:\n      inputs:      Tensor, 5D BDHWC input maps\n      is_training: boolean tf.Varialbe, true indicates training phase\n      bn_decay:    float or float tensor variable, controling moving average weight\n      scope:       string, variable scope\n  Return:\n      normed:      batch-normalized maps\n  """"""\n  return batch_norm_template(inputs, is_training, scope, [0,1,2,3], bn_decay)\n\n\ndef dropout(inputs,\n            is_training,\n            scope,\n            keep_prob=0.5,\n            noise_shape=None):\n  """""" Dropout layer.\n\n  Args:\n    inputs: tensor\n    is_training: boolean tf.Variable\n    scope: string\n    keep_prob: float in [0,1]\n    noise_shape: list of ints\n\n  Returns:\n    tensor variable\n  """"""\n  with tf.variable_scope(scope) as sc:\n    outputs = tf.cond(is_training,\n                      lambda: tf.nn.dropout(inputs, keep_prob, noise_shape),\n                      lambda: inputs)\n    return outputs\n'"
