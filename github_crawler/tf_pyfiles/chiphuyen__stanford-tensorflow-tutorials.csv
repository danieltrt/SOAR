file_path,api_count,code
examples/02_lazy_loading.py,14,"b'"""""" Example of lazy vs normal loading\nCreated by Chip Huyen (chiphuyen@cs.stanford.edu)\nCS20: ""TensorFlow for Deep Learning Research""\ncs20.stanford.edu\nLecture 02\n""""""\nimport os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\n\nimport tensorflow as tf \n\n######################################## \n## NORMAL LOADING   \t\t\t      ##\n## print out a graph with 1 Add node  ## \n########################################\n\nx = tf.Variable(10, name=\'x\')\ny = tf.Variable(20, name=\'y\')\nz = tf.add(x, y)\n\nwith tf.Session() as sess:\n\tsess.run(tf.global_variables_initializer())\n\twriter = tf.summary.FileWriter(\'graphs/normal_loading\', sess.graph)\n\tfor _ in range(10):\n\t\tsess.run(z)\n\tprint(tf.get_default_graph().as_graph_def())\n\twriter.close()\n\n######################################## \n## LAZY LOADING   \t\t\t\t\t  ##\n## print out a graph with 10 Add nodes## \n########################################\n\nx = tf.Variable(10, name=\'x\')\ny = tf.Variable(20, name=\'y\')\n\nwith tf.Session() as sess:\n\tsess.run(tf.global_variables_initializer())\n\twriter = tf.summary.FileWriter(\'graphs/lazy_loading\', sess.graph)\n\tfor _ in range(10):\n\t\tsess.run(tf.add(x, y))\n\tprint(tf.get_default_graph().as_graph_def()) \n\twriter.close()'"
examples/02_placeholder.py,9,"b'"""""" Placeholder and feed_dict example\nCreated by Chip Huyen (chiphuyen@cs.stanford.edu)\nCS20: ""TensorFlow for Deep Learning Research""\ncs20.stanford.edu\nLecture 02\n""""""\nimport os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\n\nimport tensorflow as tf\n\n# Example 1: feed_dict with placeholder\n\n# a is a placeholderfor a vector of 3 elements, type tf.float32\na = tf.placeholder(tf.float32, shape=[3])\nb = tf.constant([5, 5, 5], tf.float32)\n\n# use the placeholder as you would a constant\nc = a + b  # short for tf.add(a, b)\n\nwriter = tf.summary.FileWriter(\'graphs/placeholders\', tf.get_default_graph())\nwith tf.Session() as sess:\n    # compute the value of c given the value of a is [1, 2, 3]\n    print(sess.run(c, {a: [1, 2, 3]}))                 # [6. 7. 8.]\nwriter.close()\n\n\n# Example 2: feed_dict with variables\na = tf.add(2, 5)\nb = tf.multiply(a, 3)\n\nwith tf.Session() as sess:\n    print(sess.run(b))                                 # >> 21\n    # compute the value of b given the value of a is 15\n    print(sess.run(b, feed_dict={a: 15}))              # >> 45'"
examples/02_simple_tf.py,30,"b'"""""" Simple TensorFlow\'s ops\nCreated by Chip Huyen (chiphuyen@cs.stanford.edu)\nCS20: ""TensorFlow for Deep Learning Research""\ncs20.stanford.edu\n""""""\nimport os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\n\nimport numpy as np\nimport tensorflow as tf\n\n# Example 1: Simple ways to create log file writer\na = tf.constant(2, name=\'a\')\nb = tf.constant(3, name=\'b\')\nx = tf.add(a, b, name=\'add\')\nwriter = tf.summary.FileWriter(\'./graphs/simple\', tf.get_default_graph()) \nwith tf.Session() as sess:\n    # writer = tf.summary.FileWriter(\'./graphs\', sess.graph) \n    print(sess.run(x))\nwriter.close() # close the writer when you\xe2\x80\x99re done using it\n\n# Example 2: The wonderful wizard of div\na = tf.constant([2, 2], name=\'a\')\nb = tf.constant([[0, 1], [2, 3]], name=\'b\')\n\nwith tf.Session() as sess:\n    print(sess.run(tf.div(b, a)))\n    print(sess.run(tf.divide(b, a)))\n    print(sess.run(tf.truediv(b, a)))\n    print(sess.run(tf.floordiv(b, a)))\n    # print(sess.run(tf.realdiv(b, a)))\n    print(sess.run(tf.truncatediv(b, a)))\n    print(sess.run(tf.floor_div(b, a)))\n\n# Example 3: multiplying tensors\na = tf.constant([10, 20], name=\'a\')\nb = tf.constant([2, 3], name=\'b\')\n\nwith tf.Session() as sess:\n    print(sess.run(tf.multiply(a, b)))\n    print(sess.run(tf.tensordot(a, b, 1)))\n\n# Example 4: Python native type\nt_0 = 19 \nx = tf.zeros_like(t_0) \t\t\t\t\t# ==> 0\ny = tf.ones_like(t_0) \t\t\t\t\t# ==> 1\n\nt_1 = [\'apple\', \'peach\', \'banana\']\nx = tf.zeros_like(t_1) \t\t\t\t\t# ==> [\'\' \'\' \'\']\n# y = tf.ones_like(t_1) \t\t\t\t# ==> TypeError: Expected string, got 1 of type \'int\' instead.\n\nt_2 = [[True, False, False],\n       [False, False, True],\n       [False, True, False]] \nx = tf.zeros_like(t_2) \t\t\t\t\t# ==> 3x3 tensor, all elements are False\ny = tf.ones_like(t_2) \t\t\t\t\t# ==> 3x3 tensor, all elements are True\n\nprint(tf.int32.as_numpy_dtype())\n\n# Example 5: printing your graph\'s definition\nmy_const = tf.constant([1.0, 2.0], name=\'my_const\')\nprint(tf.get_default_graph().as_graph_def())'"
examples/02_variables.py,24,"b'"""""" Variable exmaples\nCreated by Chip Huyen (chiphuyen@cs.stanford.edu)\nCS20: ""TensorFlow for Deep Learning Research""\ncs20.stanford.edu\nLecture 02\n""""""\nimport os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\n\nimport numpy as np\nimport tensorflow as tf\n\n# Example 1: creating variables\ns = tf.Variable(2, name=\'scalar\') \nm = tf.Variable([[0, 1], [2, 3]], name=\'matrix\') \nW = tf.Variable(tf.zeros([784,10]), name=\'big_matrix\')\nV = tf.Variable(tf.truncated_normal([784, 10]), name=\'normal_matrix\')\n\ns = tf.get_variable(\'scalar\', initializer=tf.constant(2)) \nm = tf.get_variable(\'matrix\', initializer=tf.constant([[0, 1], [2, 3]]))\nW = tf.get_variable(\'big_matrix\', shape=(784, 10), initializer=tf.zeros_initializer())\nV = tf.get_variable(\'normal_matrix\', shape=(784, 10), initializer=tf.truncated_normal_initializer())\n\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    print(V.eval())\n\n# Example 2: assigning values to variables\nW = tf.Variable(10)\nW.assign(100)\nwith tf.Session() as sess:\n    sess.run(W.initializer)\n    print(sess.run(W))                    \t# >> 10\n\nW = tf.Variable(10)\nassign_op = W.assign(100)\nwith tf.Session() as sess:\n    sess.run(assign_op)\n    print(W.eval())                     \t# >> 100\n\n# create a variable whose original value is 2\na = tf.get_variable(\'scalar\', initializer=tf.constant(2)) \na_times_two = a.assign(a * 2)\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer()) \n    sess.run(a_times_two)                 \t# >> 4\n    sess.run(a_times_two)                 \t# >> 8\n    sess.run(a_times_two)                 \t# >> 16\n\nW = tf.Variable(10)\nwith tf.Session() as sess:\n    sess.run(W.initializer)\n    print(sess.run(W.assign_add(10)))     \t# >> 20\n    print(sess.run(W.assign_sub(2)))     \t# >> 18\n\n# Example 3: Each session has its own copy of variable\nW = tf.Variable(10)\nsess1 = tf.Session()\nsess2 = tf.Session()\nsess1.run(W.initializer)\nsess2.run(W.initializer)\nprint(sess1.run(W.assign_add(10)))        \t# >> 20\nprint(sess2.run(W.assign_sub(2)))        \t# >> 8\nprint(sess1.run(W.assign_add(100)))        \t# >> 120\nprint(sess2.run(W.assign_sub(50)))        \t# >> -42\nsess1.close()\nsess2.close()\n\n# Example 4: create a variable with the initial value depending on another variable\nW = tf.Variable(tf.truncated_normal([700, 10]))\nU = tf.Variable(W * 2)'"
examples/03_linreg_dataset.py,10,"b'"""""" Solution for simple linear regression example using tf.data\nCreated by Chip Huyen (chiphuyen@cs.stanford.edu)\nCS20: ""TensorFlow for Deep Learning Research""\ncs20.stanford.edu\nLecture 03\n""""""\nimport os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\nimport time\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\nimport utils\n\nDATA_FILE = \'data/birth_life_2010.txt\'\n\n# Step 1: read in the data\ndata, n_samples = utils.read_birth_life_data(DATA_FILE)\n\n# Step 2: create Dataset and iterator\ndataset = tf.data.Dataset.from_tensor_slices((data[:,0], data[:,1]))\n\niterator = dataset.make_initializable_iterator()\nX, Y = iterator.get_next()\n\n# Step 3: create weight and bias, initialized to 0\nw = tf.get_variable(\'weights\', initializer=tf.constant(0.0))\nb = tf.get_variable(\'bias\', initializer=tf.constant(0.0))\n\n# Step 4: build model to predict Y\nY_predicted = X * w + b\n\n# Step 5: use the square error as the loss function\nloss = tf.square(Y - Y_predicted, name=\'loss\')\n# loss = utils.huber_loss(Y, Y_predicted)\n\n# Step 6: using gradient descent with learning rate of 0.001 to minimize loss\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(loss)\n\nstart = time.time()\nwith tf.Session() as sess:\n    # Step 7: initialize the necessary variables, in this case, w and b\n    sess.run(tf.global_variables_initializer()) \n    writer = tf.summary.FileWriter(\'./graphs/linear_reg\', sess.graph)\n    \n    # Step 8: train the model for 100 epochs\n    for i in range(100):\n        sess.run(iterator.initializer) # initialize the iterator\n        total_loss = 0\n        try:\n            while True:\n                _, l = sess.run([optimizer, loss]) \n                total_loss += l\n        except tf.errors.OutOfRangeError:\n            pass\n            \n        print(\'Epoch {0}: {1}\'.format(i, total_loss/n_samples))\n\n    # close the writer when you\'re done using it\n    writer.close() \n    \n    # Step 9: output the values of w and b\n    w_out, b_out = sess.run([w, b]) \n    print(\'w: %f, b: %f\' %(w_out, b_out))\nprint(\'Took: %f seconds\' %(time.time() - start))\n\n# plot the results\nplt.plot(data[:,0], data[:,1], \'bo\', label=\'Real data\')\nplt.plot(data[:,0], data[:,0] * w_out + b_out, \'r\', label=\'Predicted data with squared error\')\n# plt.plot(data[:,0], data[:,0] * (-5.883589) + 85.124306, \'g\', label=\'Predicted data with Huber loss\')\nplt.legend()\nplt.show()'"
examples/03_linreg_placeholder.py,9,"b'"""""" Solution for simple linear regression example using placeholders\nCreated by Chip Huyen (chiphuyen@cs.stanford.edu)\nCS20: ""TensorFlow for Deep Learning Research""\ncs20.stanford.edu\nLecture 03\n""""""\nimport os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\nimport time\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\nimport utils\n\nDATA_FILE = \'data/birth_life_2010.txt\'\n\n# Step 1: read in data from the .txt file\ndata, n_samples = utils.read_birth_life_data(DATA_FILE)\n\n# Step 2: create placeholders for X (birth rate) and Y (life expectancy)\nX = tf.placeholder(tf.float32, name=\'X\')\nY = tf.placeholder(tf.float32, name=\'Y\')\n\n# Step 3: create weight and bias, initialized to 0\nw = tf.get_variable(\'weights\', initializer=tf.constant(0.0))\nb = tf.get_variable(\'bias\', initializer=tf.constant(0.0))\n\n# Step 4: build model to predict Y\nY_predicted = w * X + b \n\n# Step 5: use the squared error as the loss function\n# you can use either mean squared error or Huber loss\nloss = tf.square(Y - Y_predicted, name=\'loss\')\n# loss = utils.huber_loss(Y, Y_predicted)\n\n# Step 6: using gradient descent with learning rate of 0.001 to minimize loss\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(loss)\n\n\nstart = time.time()\nwriter = tf.summary.FileWriter(\'./graphs/linear_reg\', tf.get_default_graph())\nwith tf.Session() as sess:\n\t# Step 7: initialize the necessary variables, in this case, w and b\n\tsess.run(tf.global_variables_initializer()) \n\t\n\t# Step 8: train the model for 100 epochs\n\tfor i in range(100): \n\t\ttotal_loss = 0\n\t\tfor x, y in data:\n\t\t\t# Session execute optimizer and fetch values of loss\n\t\t\t_, l = sess.run([optimizer, loss], feed_dict={X: x, Y:y}) \n\t\t\ttotal_loss += l\n\t\tprint(\'Epoch {0}: {1}\'.format(i, total_loss/n_samples))\n\n\t# close the writer when you\'re done using it\n\twriter.close() \n\t\n\t# Step 9: output the values of w and b\n\tw_out, b_out = sess.run([w, b]) \n\nprint(\'Took: %f seconds\' %(time.time() - start))\n\n# plot the results\nplt.plot(data[:,0], data[:,1], \'bo\', label=\'Real data\')\nplt.plot(data[:,0], data[:,0] * w_out + b_out, \'r\', label=\'Predicted data\')\nplt.legend()\nplt.show()'"
examples/03_linreg_starter.py,3,"b'"""""" Starter code for simple linear regression example using placeholders\nCreated by Chip Huyen (huyenn@cs.stanford.edu)\nCS20: ""TensorFlow for Deep Learning Research""\ncs20.stanford.edu\nLecture 03\n""""""\nimport os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\nimport time\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\nimport utils\n\nDATA_FILE = \'data/birth_life_2010.txt\'\n\n# Step 1: read in data from the .txt file\ndata, n_samples = utils.read_birth_life_data(DATA_FILE)\n\n# Step 2: create placeholders for X (birth rate) and Y (life expectancy)\n# Remember both X and Y are scalars with type float\nX, Y = None, None\n#############################\n########## TO DO ############\n#############################\n\n# Step 3: create weight and bias, initialized to 0.0\n# Make sure to use tf.get_variable\nw, b = None, None\n#############################\n########## TO DO ############\n#############################\n\n# Step 4: build model to predict Y\n# e.g. how would you derive at Y_predicted given X, w, and b\nY_predicted = None\n#############################\n########## TO DO ############\n#############################\n\n# Step 5: use the square error as the loss function\nloss = None\n#############################\n########## TO DO ############\n#############################\n\n# Step 6: using gradient descent with learning rate of 0.001 to minimize loss\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(loss)\n\nstart = time.time()\n\n# Create a filewriter to write the model\'s graph to TensorBoard\n#############################\n########## TO DO ############\n#############################\n\nwith tf.Session() as sess:\n    # Step 7: initialize the necessary variables, in this case, w and b\n    #############################\n    ########## TO DO ############\n    #############################\n\n    # Step 8: train the model for 100 epochs\n    for i in range(100):\n        total_loss = 0\n        for x, y in data:\n            # Execute train_op and get the value of loss.\n            # Don\'t forget to feed in data for placeholders\n            _, loss = ########## TO DO ############\n            total_loss += loss\n\n        print(\'Epoch {0}: {1}\'.format(i, total_loss/n_samples))\n\n    # close the writer when you\'re done using it\n    #############################\n    ########## TO DO ############\n    #############################\n    writer.close()\n    \n    # Step 9: output the values of w and b\n    w_out, b_out = None, None\n    #############################\n    ########## TO DO ############\n    #############################\n\nprint(\'Took: %f seconds\' %(time.time() - start))\n\n# uncomment the following lines to see the plot \n# plt.plot(data[:,0], data[:,1], \'bo\', label=\'Real data\')\n# plt.plot(data[:,0], data[:,0] * w_out + b_out, \'r\', label=\'Predicted data\')\n# plt.legend()\n# plt.show()'"
examples/03_logreg.py,19,"b'"""""" Solution for simple logistic regression model for MNIST\nwith tf.data module\nMNIST dataset: yann.lecun.com/exdb/mnist/\nCreated by Chip Huyen (chiphuyen@cs.stanford.edu)\nCS20: ""TensorFlow for Deep Learning Research""\ncs20.stanford.edu\nLecture 03\n""""""\nimport os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\n\nimport numpy as np\nimport tensorflow as tf\nimport time\n\nimport utils\n\n# Define paramaters for the model\nlearning_rate = 0.01\nbatch_size = 128\nn_epochs = 30\nn_train = 60000\nn_test = 10000\n\n# Step 1: Read in data\nmnist_folder = \'data/mnist\'\nutils.download_mnist(mnist_folder)\ntrain, val, test = utils.read_mnist(mnist_folder, flatten=True)\n\n# Step 2: Create datasets and iterator\ntrain_data = tf.data.Dataset.from_tensor_slices(train)\ntrain_data = train_data.shuffle(10000) # if you want to shuffle your data\ntrain_data = train_data.batch(batch_size)\n\ntest_data = tf.data.Dataset.from_tensor_slices(test)\ntest_data = test_data.batch(batch_size)\n\niterator = tf.data.Iterator.from_structure(train_data.output_types, \n                                           train_data.output_shapes)\nimg, label = iterator.get_next()\n\ntrain_init = iterator.make_initializer(train_data)\t# initializer for train_data\ntest_init = iterator.make_initializer(test_data)\t# initializer for train_data\n\n# Step 3: create weights and bias\n# w is initialized to random variables with mean of 0, stddev of 0.01\n# b is initialized to 0\n# shape of w depends on the dimension of X and Y so that Y = tf.matmul(X, w)\n# shape of b depends on Y\nw = tf.get_variable(name=\'weights\', shape=(784, 10), initializer=tf.random_normal_initializer(0, 0.01))\nb = tf.get_variable(name=\'bias\', shape=(1, 10), initializer=tf.zeros_initializer())\n\n# Step 4: build model\n# the model that returns the logits.\n# this logits will be later passed through softmax layer\nlogits = tf.matmul(img, w) + b \n\n# Step 5: define loss function\n# use cross entropy of softmax of logits as the loss function\nentropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=label, name=\'entropy\')\nloss = tf.reduce_mean(entropy, name=\'loss\') # computes the mean over all the examples in the batch\n\n# Step 6: define training op\n# using gradient descent with learning rate of 0.01 to minimize loss\noptimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n\n# Step 7: calculate accuracy with test set\npreds = tf.nn.softmax(logits)\ncorrect_preds = tf.equal(tf.argmax(preds, 1), tf.argmax(label, 1))\naccuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32))\n\nwriter = tf.summary.FileWriter(\'./graphs/logreg\', tf.get_default_graph())\nwith tf.Session() as sess:\n   \n    start_time = time.time()\n    sess.run(tf.global_variables_initializer())\n\n    # train the model n_epochs times\n    for i in range(n_epochs): \t\n        sess.run(train_init)\t# drawing samples from train_data\n        total_loss = 0\n        n_batches = 0\n        try:\n            while True:\n                _, l = sess.run([optimizer, loss])\n                total_loss += l\n                n_batches += 1\n        except tf.errors.OutOfRangeError:\n            pass\n        print(\'Average loss epoch {0}: {1}\'.format(i, total_loss/n_batches))\n    print(\'Total time: {0} seconds\'.format(time.time() - start_time))\n\n    # test the model\n    sess.run(test_init)\t\t\t# drawing samples from test_data\n    total_correct_preds = 0\n    try:\n        while True:\n            accuracy_batch = sess.run(accuracy)\n            total_correct_preds += accuracy_batch\n    except tf.errors.OutOfRangeError:\n        pass\n\n    print(\'Accuracy {0}\'.format(total_correct_preds/n_test))\nwriter.close()\n'"
examples/03_logreg_placeholder.py,16,"b'"""""" Solution for simple logistic regression model for MNIST\nwith placeholder\nMNIST dataset: yann.lecun.com/exdb/mnist/\nCreated by Chip Huyen (huyenn@cs.stanford.edu)\nCS20: ""TensorFlow for Deep Learning Research""\ncs20.stanford.edu\nLecture 03\n""""""\nimport os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\n\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.examples.tutorials.mnist import input_data\nimport time\n\nimport utils\n\n# Define paramaters for the model\nlearning_rate = 0.01\nbatch_size = 128\nn_epochs = 30\n\n# Step 1: Read in data\n# using TF Learn\'s built in function to load MNIST data to the folder data/mnist\nmnist = input_data.read_data_sets(\'data/mnist\', one_hot=True)\nX_batch, Y_batch = mnist.train.next_batch(batch_size)\n\n# Step 2: create placeholders for features and labels\n# each image in the MNIST data is of shape 28*28 = 784\n# therefore, each image is represented with a 1x784 tensor\n# there are 10 classes for each image, corresponding to digits 0 - 9. \n# each lable is one hot vector.\nX = tf.placeholder(tf.float32, [batch_size, 784], name=\'image\') \nY = tf.placeholder(tf.int32, [batch_size, 10], name=\'label\')\n\n# Step 3: create weights and bias\n# w is initialized to random variables with mean of 0, stddev of 0.01\n# b is initialized to 0\n# shape of w depends on the dimension of X and Y so that Y = tf.matmul(X, w)\n# shape of b depends on Y\nw = tf.get_variable(name=\'weights\', shape=(784, 10), initializer=tf.random_normal_initializer())\nb = tf.get_variable(name=\'bias\', shape=(1, 10), initializer=tf.zeros_initializer())\n\n# Step 4: build model\n# the model that returns the logits.\n# this logits will be later passed through softmax layer\nlogits = tf.matmul(X, w) + b \n\n# Step 5: define loss function\n# use cross entropy of softmax of logits as the loss function\nentropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y, name=\'loss\')\nloss = tf.reduce_mean(entropy) # computes the mean over all the examples in the batch\n# loss = tf.reduce_mean(-tf.reduce_sum(tf.nn.softmax(logits) * tf.log(Y), reduction_indices=[1]))\n\n# Step 6: define training op\n# using gradient descent with learning rate of 0.01 to minimize loss\noptimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n\n# Step 7: calculate accuracy with test set\npreds = tf.nn.softmax(logits)\ncorrect_preds = tf.equal(tf.argmax(preds, 1), tf.argmax(Y, 1))\naccuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32))\n\nwriter = tf.summary.FileWriter(\'./graphs/logreg_placeholder\', tf.get_default_graph())\nwith tf.Session() as sess:\n\tstart_time = time.time()\n\tsess.run(tf.global_variables_initializer())\t\n\tn_batches = int(mnist.train.num_examples/batch_size)\n\t\n\t# train the model n_epochs times\n\tfor i in range(n_epochs): \n\t\ttotal_loss = 0\n\n\t\tfor j in range(n_batches):\n\t\t\tX_batch, Y_batch = mnist.train.next_batch(batch_size)\n\t\t\t_, loss_batch = sess.run([optimizer, loss], {X: X_batch, Y:Y_batch}) \n\t\t\ttotal_loss += loss_batch\n\t\tprint(\'Average loss epoch {0}: {1}\'.format(i, total_loss/n_batches))\n\tprint(\'Total time: {0} seconds\'.format(time.time() - start_time))\n\n\t# test the model\n\tn_batches = int(mnist.test.num_examples/batch_size)\n\ttotal_correct_preds = 0\n\n\tfor i in range(n_batches):\n\t\tX_batch, Y_batch = mnist.test.next_batch(batch_size)\n\t\taccuracy_batch = sess.run(accuracy, {X: X_batch, Y:Y_batch})\n\t\ttotal_correct_preds += accuracy_batch\t\n\n\tprint(\'Accuracy {0}\'.format(total_correct_preds/mnist.test.num_examples))\n\nwriter.close()\n'"
examples/03_logreg_starter.py,12,"b'"""""" Starter code for simple logistic regression model for MNIST\nwith tf.data module\nMNIST dataset: yann.lecun.com/exdb/mnist/\nCreated by Chip Huyen (chiphuyen@cs.stanford.edu)\nCS20: ""TensorFlow for Deep Learning Research""\ncs20.stanford.edu\nLecture 03\n""""""\nimport os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\n\nimport numpy as np\nimport tensorflow as tf\nimport time\n\nimport utils\n\n# Define paramaters for the model\nlearning_rate = 0.01\nbatch_size = 128\nn_epochs = 30\nn_train = 60000\nn_test = 10000\n\n# Step 1: Read in data\nmnist_folder = \'data/mnist\'\nutils.download_mnist(mnist_folder)\ntrain, val, test = utils.read_mnist(mnist_folder, flatten=True)\n\n# Step 2: Create datasets and iterator\n# create training Dataset and batch it\ntrain_data = tf.data.Dataset.from_tensor_slices(train)\ntrain_data = train_data.shuffle(10000) # if you want to shuffle your data\ntrain_data = train_data.batch(batch_size)\n\n# create testing Dataset and batch it\ntest_data = None\n#############################\n########## TO DO ############\n#############################\n\n\n# create one iterator and initialize it with different datasets\niterator = tf.data.Iterator.from_structure(train_data.output_types, \n                                           train_data.output_shapes)\nimg, label = iterator.get_next()\n\ntrain_init = iterator.make_initializer(train_data)\t# initializer for train_data\ntest_init = iterator.make_initializer(test_data)\t# initializer for train_data\n\n# Step 3: create weights and bias\n# w is initialized to random variables with mean of 0, stddev of 0.01\n# b is initialized to 0\n# shape of w depends on the dimension of X and Y so that Y = tf.matmul(X, w)\n# shape of b depends on Y\nw, b = None, None\n#############################\n########## TO DO ############\n#############################\n\n\n# Step 4: build model\n# the model that returns the logits.\n# this logits will be later passed through softmax layer\nlogits = None\n#############################\n########## TO DO ############\n#############################\n\n\n# Step 5: define loss function\n# use cross entropy of softmax of logits as the loss function\nloss = None\n#############################\n########## TO DO ############\n#############################\n\n\n# Step 6: define optimizer\n# using Adamn Optimizer with pre-defined learning rate to minimize loss\noptimizer = None\n#############################\n########## TO DO ############\n#############################\n\n\n# Step 7: calculate accuracy with test set\npreds = tf.nn.softmax(logits)\ncorrect_preds = tf.equal(tf.argmax(preds, 1), tf.argmax(label, 1))\naccuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32))\n\nwriter = tf.summary.FileWriter(\'./graphs/logreg\', tf.get_default_graph())\nwith tf.Session() as sess:\n   \n    start_time = time.time()\n    sess.run(tf.global_variables_initializer())\n\n    # train the model n_epochs times\n    for i in range(n_epochs): \t\n        sess.run(train_init)\t# drawing samples from train_data\n        total_loss = 0\n        n_batches = 0\n        try:\n            while True:\n                _, l = sess.run([optimizer, loss])\n                total_loss += l\n                n_batches += 1\n        except tf.errors.OutOfRangeError:\n            pass\n        print(\'Average loss epoch {0}: {1}\'.format(i, total_loss/n_batches))\n    print(\'Total time: {0} seconds\'.format(time.time() - start_time))\n\n    # test the model\n    sess.run(test_init)\t\t\t# drawing samples from test_data\n    total_correct_preds = 0\n    try:\n        while True:\n            accuracy_batch = sess.run(accuracy)\n            total_correct_preds += accuracy_batch\n    except tf.errors.OutOfRangeError:\n        pass\n\n    print(\'Accuracy {0}\'.format(total_correct_preds/n_test))\nwriter.close()'"
examples/04_linreg_eager.py,4,"b'"""""" Starter code for a simple regression example using eager execution.\nCreated by Akshay Agrawal (akshayka@cs.stanford.edu)\nCS20: ""TensorFlow for Deep Learning Research""\ncs20.stanford.edu\nLecture 04\n""""""\nimport time\n\nimport tensorflow as tf\nimport tensorflow.contrib.eager as tfe\nimport matplotlib.pyplot as plt\n\nimport utils\n\nDATA_FILE = \'data/birth_life_2010.txt\'\n\n# In order to use eager execution, `tfe.enable_eager_execution()` must be\n# called at the very beginning of a TensorFlow program.\ntfe.enable_eager_execution()\n\n# Read the data into a dataset.\ndata, n_samples = utils.read_birth_life_data(DATA_FILE)\ndataset = tf.data.Dataset.from_tensor_slices((data[:,0], data[:,1]))\n\n# Create variables.\nw = tfe.Variable(0.0)\nb = tfe.Variable(0.0)\n\n# Define the linear predictor.\ndef prediction(x):\n  return x * w + b\n\n# Define loss functions of the form: L(y, y_predicted)\ndef squared_loss(y, y_predicted):\n  return (y - y_predicted) ** 2\n\ndef huber_loss(y, y_predicted, m=1.0):\n  """"""Huber loss.""""""\n  t = y - y_predicted\n  # Note that enabling eager execution lets you use Python control flow and\n  # specificy dynamic TensorFlow computations. Contrast this implementation\n  # to the graph-construction one found in `utils`, which uses `tf.cond`.\n  return t ** 2 if tf.abs(t) <= m else m * (2 * tf.abs(t) - m)\n\ndef train(loss_fn):\n  """"""Train a regression model evaluated using `loss_fn`.""""""\n  print(\'Training; loss function: \' + loss_fn.__name__)\n  optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n\n  # Define the function through which to differentiate.\n  def loss_for_example(x, y):\n    return loss_fn(y, prediction(x))\n\n  # `grad_fn(x_i, y_i)` returns (1) the value of `loss_for_example`\n  # evaluated at `x_i`, `y_i` and (2) the gradients of any variables used in\n  # calculating it.\n  grad_fn = tfe.implicit_value_and_gradients(loss_for_example)\n\n  start = time.time()\n  for epoch in range(100):\n    total_loss = 0.0\n    for x_i, y_i in tfe.Iterator(dataset):\n      loss, gradients = grad_fn(x_i, y_i)\n      # Take an optimization step and update variables.\n      optimizer.apply_gradients(gradients)\n      total_loss += loss\n    if epoch % 10 == 0:\n      print(\'Epoch {0}: {1}\'.format(epoch, total_loss / n_samples))\n  print(\'Took: %f seconds\' % (time.time() - start))\n  print(\'Eager execution exhibits significant overhead per operation. \'\n        \'As you increase your batch size, the impact of the overhead will \'\n        \'become less noticeable. Eager execution is under active development: \'\n        \'expect performance to increase substantially in the near future!\')\n\ntrain(huber_loss)\nplt.plot(data[:,0], data[:,1], \'bo\')\n# The `.numpy()` method of a tensor retrieves the NumPy array backing it.\n# In future versions of eager, you won\'t need to call `.numpy()` and will\n# instead be able to, in most cases, pass Tensors wherever NumPy arrays are\n# expected.\nplt.plot(data[:,0], data[:,0] * w.numpy() + b.numpy(), \'r\',\n         label=""huber regression"")\nplt.legend()\nplt.show()\n'"
examples/04_linreg_eager_starter.py,2,"b'"""""" Starter code for a simple regression example using eager execution.\nCreated by Akshay Agrawal (akshayka@cs.stanford.edu)\nCS20: ""TensorFlow for Deep Learning Research""\ncs20.stanford.edu\nLecture 04\n""""""\nimport time\n\nimport tensorflow as tf\nimport tensorflow.contrib.eager as tfe\nimport matplotlib.pyplot as plt\n\nimport utils\n\nDATA_FILE = \'data/birth_life_2010.txt\'\n\n# In order to use eager execution, `tfe.enable_eager_execution()` must be\n# called at the very beginning of a TensorFlow program.\n#############################\n########## TO DO ############\n#############################\n\n# Read the data into a dataset.\ndata, n_samples = utils.read_birth_life_data(DATA_FILE)\ndataset = tf.data.Dataset.from_tensor_slices((data[:,0], data[:,1]))\n\n# Create weight and bias variables, initialized to 0.0.\n#############################\n########## TO DO ############\n#############################\nw = None\nb = None\n\n# Define the linear predictor.\ndef prediction(x):\n  #############################\n  ########## TO DO ############\n  #############################\n  pass\n\n# Define loss functions of the form: L(y, y_predicted)\ndef squared_loss(y, y_predicted):\n  #############################\n  ########## TO DO ############\n  #############################\n  pass\n\ndef huber_loss(y, y_predicted):\n  """"""Huber loss with `m` set to `1.0`.""""""\n  #############################\n  ########## TO DO ############\n  #############################\n  pass\n\ndef train(loss_fn):\n  """"""Train a regression model evaluated using `loss_fn`.""""""\n  print(\'Training; loss function: \' + loss_fn.__name__)\n  optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n\n  # Define the function through which to differentiate.\n  #############################\n  ########## TO DO ############\n  #############################\n  def loss_for_example(x, y):\n    pass\n\n  # Obtain a gradients function using `tfe.implicit_value_and_gradients`.\n  #############################\n  ########## TO DO ############\n  #############################\n  grad_fn = None\n\n  start = time.time()\n  for epoch in range(100):\n    total_loss = 0.0\n    for x_i, y_i in tfe.Iterator(dataset):\n      # Compute the loss and gradient, and take an optimization step.\n      #############################\n      ########## TO DO ############\n      #############################\n      optimizer.apply_gradients(gradients)\n      total_loss += loss\n    if epoch % 10 == 0:\n      print(\'Epoch {0}: {1}\'.format(epoch, total_loss / n_samples))\n  print(\'Took: %f seconds\' % (time.time() - start))\n  print(\'Eager execution exhibits significant overhead per operation. \'\n        \'As you increase your batch size, the impact of the overhead will \'\n        \'become less noticeable. Eager execution is under active development: \'\n        \'expect performance to increase substantially in the near future!\')\n\ntrain(huber_loss)\nplt.plot(data[:,0], data[:,1], \'bo\')\n# The `.numpy()` method of a tensor retrieves the NumPy array backing it.\n# In future versions of eager, you won\'t need to call `.numpy()` and will\n# instead be able to, in most cases, pass Tensors wherever NumPy arrays are\n# expected.\nplt.plot(data[:,0], data[:,0] * w.numpy() + b.numpy(), \'r\',\n         label=""huber regression"")\nplt.legend()\nplt.show()\n'"
examples/04_word2vec.py,19,"b'"""""" starter code for word2vec skip-gram model with NCE loss\nCS 20: ""TensorFlow for Deep Learning Research""\ncs20.stanford.edu\nChip Huyen (chiphuyen@cs.stanford.edu)\nLecture 04\n""""""\n\nimport os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\n\nimport numpy as np\nfrom tensorflow.contrib.tensorboard.plugins import projector\nimport tensorflow as tf\n\nimport utils\nimport word2vec_utils\n\n# Model hyperparameters\nVOCAB_SIZE = 50000\nBATCH_SIZE = 128\nEMBED_SIZE = 128            # dimension of the word embedding vectors\nSKIP_WINDOW = 1             # the context window\nNUM_SAMPLED = 64            # number of negative examples to sample\nLEARNING_RATE = 1.0\nNUM_TRAIN_STEPS = 100000\nVISUAL_FLD = \'visualization\'\nSKIP_STEP = 5000\n\n# Parameters for downloading data\nDOWNLOAD_URL = \'http://mattmahoney.net/dc/text8.zip\'\nEXPECTED_BYTES = 31344016\nNUM_VISUALIZE = 3000        # number of tokens to visualize\n\n\ndef word2vec(dataset):\n    """""" Build the graph for word2vec model and train it """"""\n    # Step 1: get input, output from the dataset\n    with tf.name_scope(\'data\'):\n        iterator = dataset.make_initializable_iterator()\n        center_words, target_words = iterator.get_next()\n\n    """""" Step 2 + 3: define weights and embedding lookup.\n    In word2vec, it\'s actually the weights that we care about \n    """"""\n    with tf.name_scope(\'embed\'):\n        embed_matrix = tf.get_variable(\'embed_matrix\', \n                                        shape=[VOCAB_SIZE, EMBED_SIZE],\n                                        initializer=tf.random_uniform_initializer())\n        embed = tf.nn.embedding_lookup(embed_matrix, center_words, name=\'embedding\')\n\n    # Step 4: construct variables for NCE loss and define loss function\n    with tf.name_scope(\'loss\'):\n        nce_weight = tf.get_variable(\'nce_weight\', shape=[VOCAB_SIZE, EMBED_SIZE],\n                        initializer=tf.truncated_normal_initializer(stddev=1.0 / (EMBED_SIZE ** 0.5)))\n        nce_bias = tf.get_variable(\'nce_bias\', initializer=tf.zeros([VOCAB_SIZE]))\n\n        # define loss function to be NCE loss function\n        loss = tf.reduce_mean(tf.nn.nce_loss(weights=nce_weight, \n                                            biases=nce_bias, \n                                            labels=target_words, \n                                            inputs=embed, \n                                            num_sampled=NUM_SAMPLED, \n                                            num_classes=VOCAB_SIZE), name=\'loss\')\n\n    # Step 5: define optimizer\n    with tf.name_scope(\'optimizer\'):\n        optimizer = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(loss)\n    \n    utils.safe_mkdir(\'checkpoints\')\n\n    with tf.Session() as sess:\n        sess.run(iterator.initializer)\n        sess.run(tf.global_variables_initializer())\n\n        total_loss = 0.0 # we use this to calculate late average loss in the last SKIP_STEP steps\n        writer = tf.summary.FileWriter(\'graphs/word2vec_simple\', sess.graph)\n\n        for index in range(NUM_TRAIN_STEPS):\n            try:\n                loss_batch, _ = sess.run([loss, optimizer])\n                total_loss += loss_batch\n                if (index + 1) % SKIP_STEP == 0:\n                    print(\'Average loss at step {}: {:5.1f}\'.format(index, total_loss / SKIP_STEP))\n                    total_loss = 0.0\n            except tf.errors.OutOfRangeError:\n                sess.run(iterator.initializer)\n        writer.close()\n\ndef gen():\n    yield from word2vec_utils.batch_gen(DOWNLOAD_URL, EXPECTED_BYTES, VOCAB_SIZE, \n                                        BATCH_SIZE, SKIP_WINDOW, VISUAL_FLD)\n\ndef main():\n    dataset = tf.data.Dataset.from_generator(gen, \n                                (tf.int32, tf.int32), \n                                (tf.TensorShape([BATCH_SIZE]), tf.TensorShape([BATCH_SIZE, 1])))\n    word2vec(dataset)\n\nif __name__ == \'__main__\':\n    main()\n'"
examples/04_word2vec_eager.py,9,"b'"""""" starter code for word2vec skip-gram model with NCE loss\nEager execution\nCS 20: ""TensorFlow for Deep Learning Research""\ncs20.stanford.edu\nChip Huyen (chiphuyen@cs.stanford.edu) & Akshay Agrawal (akshayka@cs.stanford.edu)\nLecture 04\n""""""\n\nimport os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\n\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow.contrib.eager as tfe\n\nimport utils\nimport word2vec_utils\n\ntfe.enable_eager_execution()\n\n# Model hyperparameters\nVOCAB_SIZE = 50000\nBATCH_SIZE = 128\nEMBED_SIZE = 128            # dimension of the word embedding vectors\nSKIP_WINDOW = 1             # the context window\nNUM_SAMPLED = 64            # number of negative examples to sample\nLEARNING_RATE = 1.0\nNUM_TRAIN_STEPS = 100000\nVISUAL_FLD = \'visualization\'\nSKIP_STEP = 5000\n\n# Parameters for downloading data\nDOWNLOAD_URL = \'http://mattmahoney.net/dc/text8.zip\'\nEXPECTED_BYTES = 31344016\n\nclass Word2Vec(object):\n  def __init__(self, vocab_size, embed_size, num_sampled=NUM_SAMPLED):\n    self.vocab_size = vocab_size\n    self.num_sampled = num_sampled\n    self.embed_matrix = tfe.Variable(tf.random_uniform(\n                                      [vocab_size, embed_size]))\n    self.nce_weight = tfe.Variable(tf.truncated_normal(\n                                    [vocab_size, embed_size],\n                                    stddev=1.0 / (embed_size ** 0.5)))\n    self.nce_bias = tfe.Variable(tf.zeros([vocab_size]))\n\n  def compute_loss(self, center_words, target_words):\n    """"""Computes the forward pass of word2vec with the NCE loss."""""" \n    embed = tf.nn.embedding_lookup(self.embed_matrix, center_words)\n    loss = tf.reduce_mean(tf.nn.nce_loss(weights=self.nce_weight, \n                                        biases=self.nce_bias, \n                                        labels=target_words, \n                                        inputs=embed, \n                                        num_sampled=self.num_sampled, \n                                        num_classes=self.vocab_size))\n    return loss\n\n\ndef gen():\n  yield from word2vec_utils.batch_gen(DOWNLOAD_URL, EXPECTED_BYTES,\n                                      VOCAB_SIZE, BATCH_SIZE, SKIP_WINDOW,\n                                      VISUAL_FLD)\n\ndef main():\n  dataset = tf.data.Dataset.from_generator(gen, (tf.int32, tf.int32),\n                              (tf.TensorShape([BATCH_SIZE]),\n                              tf.TensorShape([BATCH_SIZE, 1])))\n  optimizer = tf.train.GradientDescentOptimizer(LEARNING_RATE)\n  model = Word2Vec(vocab_size=VOCAB_SIZE, embed_size=EMBED_SIZE)\n  grad_fn = tfe.implicit_value_and_gradients(model.compute_loss)\n  total_loss = 0.0  # for average loss in the last SKIP_STEP steps\n  num_train_steps = 0\n  while num_train_steps < NUM_TRAIN_STEPS:\n    for center_words, target_words in tfe.Iterator(dataset):\n      if num_train_steps >= NUM_TRAIN_STEPS:\n        break\n      loss_batch, grads = grad_fn(center_words, target_words)\n      total_loss += loss_batch\n      optimizer.apply_gradients(grads)\n      if (num_train_steps + 1) % SKIP_STEP == 0:\n        print(\'Average loss at step {}: {:5.1f}\'.format(\n                num_train_steps, total_loss / SKIP_STEP))\n        total_loss = 0.0\n      num_train_steps += 1\n\n\nif __name__ == \'__main__\':\n    main()\n'"
examples/04_word2vec_eager_starter.py,5,"b'"""""" starter code for word2vec skip-gram model with NCE loss\nEager execution\nCS 20: ""TensorFlow for Deep Learning Research""\ncs20.stanford.edu\nChip Huyen (chiphuyen@cs.stanford.edu) & Akshay Agrawal (akshayka@cs.stanford.edu)\nLecture 04\n""""""\n\nimport os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\n\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow.contrib.eager as tfe\n\nimport utils\nimport word2vec_utils\n\n# Enable eager execution!\n#############################\n########## TO DO ############\n#############################\n\n# Model hyperparameters\nVOCAB_SIZE = 50000\nBATCH_SIZE = 128\nEMBED_SIZE = 128            # dimension of the word embedding vectors\nSKIP_WINDOW = 1             # the context window\nNUM_SAMPLED = 64            # number of negative examples to sample\nLEARNING_RATE = 1.0\nNUM_TRAIN_STEPS = 100000\nVISUAL_FLD = \'visualization\'\nSKIP_STEP = 5000\n\n# Parameters for downloading data\nDOWNLOAD_URL = \'http://mattmahoney.net/dc/text8.zip\'\nEXPECTED_BYTES = 31344016\n\nclass Word2Vec(object):\n  def __init__(self, vocab_size, embed_size, num_sampled=NUM_SAMPLED):\n    self.vocab_size = vocab_size\n    self.num_sampled = num_sampled\n    # Create the variables: an embedding matrix, nce_weight, and nce_bias\n    #############################\n    ########## TO DO ############\n    #############################\n    self.embed_matrix = None\n    self.nce_weight = None\n    self.nce_bias = None\n\n  def compute_loss(self, center_words, target_words):\n    """"""Computes the forward pass of word2vec with the NCE loss."""""" \n    # Look up the embeddings for the center words\n    #############################\n    ########## TO DO ############\n    #############################\n    embed = None\n\n    # Compute the loss, using tf.reduce_mean and tf.nn.nce_loss\n    #############################\n    ########## TO DO ############\n    #############################\n    loss = None\n    return loss\n\n\ndef gen():\n  yield from word2vec_utils.batch_gen(DOWNLOAD_URL, EXPECTED_BYTES,\n                                      VOCAB_SIZE, BATCH_SIZE, SKIP_WINDOW,\n                                      VISUAL_FLD)\n\ndef main():\n  dataset = tf.data.Dataset.from_generator(gen, (tf.int32, tf.int32),\n                              (tf.TensorShape([BATCH_SIZE]),\n                              tf.TensorShape([BATCH_SIZE, 1])))\n  optimizer = tf.train.GradientDescentOptimizer(LEARNING_RATE)\n  # Create the model\n  #############################\n  ########## TO DO ############\n  #############################\n  model = None\n\n  # Create the gradients function, using `tfe.implicit_value_and_gradients`\n  #############################\n  ########## TO DO ############\n  #############################\n  grad_fn = None\n\n  total_loss = 0.0  # for average loss in the last SKIP_STEP steps\n  num_train_steps = 0\n  while num_train_steps < NUM_TRAIN_STEPS:\n    for center_words, target_words in tfe.Iterator(dataset):\n      if num_train_steps >= NUM_TRAIN_STEPS:\n        break\n\n      # Compute the loss and gradients, and take an optimization step.\n      #############################\n      ########## TO DO ############\n      #############################\n      \n      if (num_train_steps + 1) % SKIP_STEP == 0:\n        print(\'Average loss at step {}: {:5.1f}\'.format(\n                num_train_steps, total_loss / SKIP_STEP))\n        total_loss = 0.0\n      num_train_steps += 1\n\n\nif __name__ == \'__main__\':\n    main()\n'"
examples/04_word2vec_visualize.py,32,"b'"""""" word2vec skip-gram model with NCE loss and \ncode to visualize the embeddings on TensorBoard\nCS 20: ""TensorFlow for Deep Learning Research""\ncs20.stanford.edu\nChip Huyen (chiphuyen@cs.stanford.edu)\nLecture 04\n""""""\n\nimport os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\n\nimport numpy as np\nfrom tensorflow.contrib.tensorboard.plugins import projector\nimport tensorflow as tf\n\nimport utils\nimport word2vec_utils\n\n# Model hyperparameters\nVOCAB_SIZE = 50000\nBATCH_SIZE = 128\nEMBED_SIZE = 128            # dimension of the word embedding vectors\nSKIP_WINDOW = 1             # the context window\nNUM_SAMPLED = 64            # number of negative examples to sample\nLEARNING_RATE = 1.0\nNUM_TRAIN_STEPS = 100000\nVISUAL_FLD = \'visualization\'\nSKIP_STEP = 5000\n\n# Parameters for downloading data\nDOWNLOAD_URL = \'http://mattmahoney.net/dc/text8.zip\'\nEXPECTED_BYTES = 31344016\nNUM_VISUALIZE = 3000        # number of tokens to visualize\n\nclass SkipGramModel:\n    """""" Build the graph for word2vec model """"""\n    def __init__(self, dataset, vocab_size, embed_size, batch_size, num_sampled, learning_rate):\n        self.vocab_size = vocab_size\n        self.embed_size = embed_size\n        self.batch_size = batch_size\n        self.num_sampled = num_sampled\n        self.lr = learning_rate\n        self.global_step = tf.get_variable(\'global_step\', initializer=tf.constant(0), trainable=False)\n        self.skip_step = SKIP_STEP\n        self.dataset = dataset\n\n    def _import_data(self):\n        """""" Step 1: import data\n        """"""\n        with tf.name_scope(\'data\'):\n            self.iterator = self.dataset.make_initializable_iterator()\n            self.center_words, self.target_words = self.iterator.get_next()\n\n    def _create_embedding(self):\n        """""" Step 2 + 3: define weights and embedding lookup.\n        In word2vec, it\'s actually the weights that we care about \n        """"""\n        with tf.name_scope(\'embed\'):\n            self.embed_matrix = tf.get_variable(\'embed_matrix\', \n                                                shape=[self.vocab_size, self.embed_size],\n                                                initializer=tf.random_uniform_initializer())\n            self.embed = tf.nn.embedding_lookup(self.embed_matrix, self.center_words, name=\'embedding\')\n\n    def _create_loss(self):\n        """""" Step 4: define the loss function """"""\n        with tf.name_scope(\'loss\'):\n            # construct variables for NCE loss\n            nce_weight = tf.get_variable(\'nce_weight\', \n                        shape=[self.vocab_size, self.embed_size],\n                        initializer=tf.truncated_normal_initializer(stddev=1.0 / (self.embed_size ** 0.5)))\n            nce_bias = tf.get_variable(\'nce_bias\', initializer=tf.zeros([VOCAB_SIZE]))\n\n            # define loss function to be NCE loss function\n            self.loss = tf.reduce_mean(tf.nn.nce_loss(weights=nce_weight, \n                                                biases=nce_bias, \n                                                labels=self.target_words, \n                                                inputs=self.embed, \n                                                num_sampled=self.num_sampled, \n                                                num_classes=self.vocab_size), name=\'loss\')\n    def _create_optimizer(self):\n        """""" Step 5: define optimizer """"""\n        self.optimizer = tf.train.GradientDescentOptimizer(self.lr).minimize(self.loss, \n                                                              global_step=self.global_step)\n\n    def _create_summaries(self):\n        with tf.name_scope(\'summaries\'):\n            tf.summary.scalar(\'loss\', self.loss)\n            tf.summary.histogram(\'histogram loss\', self.loss)\n            # because you have several summaries, we should merge them all\n            # into one op to make it easier to manage\n            self.summary_op = tf.summary.merge_all()\n\n    def build_graph(self):\n        """""" Build the graph for our model """"""\n        self._import_data()\n        self._create_embedding()\n        self._create_loss()\n        self._create_optimizer()\n        self._create_summaries()\n\n    def train(self, num_train_steps):\n        saver = tf.train.Saver() # defaults to saving all variables - in this case embed_matrix, nce_weight, nce_bias\n\n        initial_step = 0\n        utils.safe_mkdir(\'checkpoints\')\n        with tf.Session() as sess:\n            sess.run(self.iterator.initializer)\n            sess.run(tf.global_variables_initializer())\n            ckpt = tf.train.get_checkpoint_state(os.path.dirname(\'checkpoints/checkpoint\'))\n\n            # if that checkpoint exists, restore from checkpoint\n            if ckpt and ckpt.model_checkpoint_path:\n                saver.restore(sess, ckpt.model_checkpoint_path)\n\n            total_loss = 0.0 # we use this to calculate late average loss in the last SKIP_STEP steps\n            writer = tf.summary.FileWriter(\'graphs/word2vec/lr\' + str(self.lr), sess.graph)\n            initial_step = self.global_step.eval()\n\n            for index in range(initial_step, initial_step + num_train_steps):\n                try:\n                    loss_batch, _, summary = sess.run([self.loss, self.optimizer, self.summary_op])\n                    writer.add_summary(summary, global_step=index)\n                    total_loss += loss_batch\n                    if (index + 1) % self.skip_step == 0:\n                        print(\'Average loss at step {}: {:5.1f}\'.format(index, total_loss / self.skip_step))\n                        total_loss = 0.0\n                        saver.save(sess, \'checkpoints/skip-gram\', index)\n                except tf.errors.OutOfRangeError:\n                    sess.run(self.iterator.initializer)\n            writer.close()\n\n    def visualize(self, visual_fld, num_visualize):\n        """""" run ""\'tensorboard --logdir=\'visualization\'"" to see the embeddings """"""\n        \n        # create the list of num_variable most common words to visualize\n        word2vec_utils.most_common_words(visual_fld, num_visualize)\n\n        saver = tf.train.Saver()\n        with tf.Session() as sess:\n            sess.run(tf.global_variables_initializer())\n            ckpt = tf.train.get_checkpoint_state(os.path.dirname(\'checkpoints/checkpoint\'))\n\n            # if that checkpoint exists, restore from checkpoint\n            if ckpt and ckpt.model_checkpoint_path:\n                saver.restore(sess, ckpt.model_checkpoint_path)\n\n            final_embed_matrix = sess.run(self.embed_matrix)\n            \n            # you have to store embeddings in a new variable\n            embedding_var = tf.Variable(final_embed_matrix[:num_visualize], name=\'embedding\')\n            sess.run(embedding_var.initializer)\n\n            config = projector.ProjectorConfig()\n            summary_writer = tf.summary.FileWriter(visual_fld)\n\n            # add embedding to the config file\n            embedding = config.embeddings.add()\n            embedding.tensor_name = embedding_var.name\n            \n            # link this tensor to its metadata file, in this case the first NUM_VISUALIZE words of vocab\n            embedding.metadata_path = \'vocab_\' + str(num_visualize) + \'.tsv\'\n\n            # saves a configuration file that TensorBoard will read during startup.\n            projector.visualize_embeddings(summary_writer, config)\n            saver_embed = tf.train.Saver([embedding_var])\n            saver_embed.save(sess, os.path.join(visual_fld, \'model.ckpt\'), 1)\n\ndef gen():\n    yield from word2vec_utils.batch_gen(DOWNLOAD_URL, EXPECTED_BYTES, VOCAB_SIZE, \n                                        BATCH_SIZE, SKIP_WINDOW, VISUAL_FLD)\n\ndef main():\n    dataset = tf.data.Dataset.from_generator(gen, \n                                (tf.int32, tf.int32), \n                                (tf.TensorShape([BATCH_SIZE]), tf.TensorShape([BATCH_SIZE, 1])))\n    model = SkipGramModel(dataset, VOCAB_SIZE, EMBED_SIZE, BATCH_SIZE, NUM_SAMPLED, LEARNING_RATE)\n    model.build_graph()\n    model.train(NUM_TRAIN_STEPS)\n    model.visualize(VISUAL_FLD, NUM_VISUALIZE)\n\nif __name__ == \'__main__\':\n    main()'"
examples/05_randomization.py,12,"b'"""""" Examples to demonstrate ops level randomization\nCS 20: ""TensorFlow for Deep Learning Research""\ncs20.stanford.edu\nChip Huyen (chiphuyen@cs.stanford.edu)\nLecture 05\n""""""\nimport os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\n\nimport tensorflow as tf\n\n# Example 1: session keeps track of the random state\nc = tf.random_uniform([], -10, 10, seed=2)\n\nwith tf.Session() as sess:\n    print(sess.run(c)) # >> 3.574932\n    print(sess.run(c)) # >> -5.9731865\n\n# Example 2: each new session will start the random state all over again.\nc = tf.random_uniform([], -10, 10, seed=2)\n\nwith tf.Session() as sess:\n    print(sess.run(c)) # >> 3.574932\n\nwith tf.Session() as sess:\n    print(sess.run(c)) # >> 3.574932\n\n# Example 3: with operation level random seed, each op keeps its own seed.\nc = tf.random_uniform([], -10, 10, seed=2)\nd = tf.random_uniform([], -10, 10, seed=2)\n\nwith tf.Session() as sess:\n    print(sess.run(c)) # >> 3.574932\n    print(sess.run(d)) # >> 3.574932\n\n# Example 4: graph level random seed\ntf.set_random_seed(2)\nc = tf.random_uniform([], -10, 10)\nd = tf.random_uniform([], -10, 10)\n\nwith tf.Session() as sess:\n    print(sess.run(c)) # >> 9.123926\n    print(sess.run(d)) # >> -4.5340395\n    '"
examples/05_variable_sharing.py,22,"b'"""""" Examples to demonstrate variable sharing\nCS 20: \'TensorFlow for Deep Learning Research\'\ncs20.stanford.edu\nChip Huyen (chiphuyen@cs.stanford.edu)\nLecture 05\n""""""\nimport os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\n\nimport tensorflow as tf\n\nx1 = tf.truncated_normal([200, 100], name=\'x1\')\nx2 = tf.truncated_normal([200, 100], name=\'x2\')\n\ndef two_hidden_layers(x):\n    assert x.shape.as_list() == [200, 100]\n    w1 = tf.Variable(tf.random_normal([100, 50]), name=\'h1_weights\')\n    b1 = tf.Variable(tf.zeros([50]), name=\'h1_biases\')\n    h1 = tf.matmul(x, w1) + b1\n    assert h1.shape.as_list() == [200, 50]  \n    w2 = tf.Variable(tf.random_normal([50, 10]), name=\'h2_weights\')\n    b2 = tf.Variable(tf.zeros([10]), name=\'2_biases\')\n    logits = tf.matmul(h1, w2) + b2\n    return logits\n\ndef two_hidden_layers_2(x):\n    assert x.shape.as_list() == [200, 100]\n    w1 = tf.get_variable(\'h1_weights\', [100, 50], initializer=tf.random_normal_initializer())\n    b1 = tf.get_variable(\'h1_biases\', [50], initializer=tf.constant_initializer(0.0))\n    h1 = tf.matmul(x, w1) + b1\n    assert h1.shape.as_list() == [200, 50]  \n    w2 = tf.get_variable(\'h2_weights\', [50, 10], initializer=tf.random_normal_initializer())\n    b2 = tf.get_variable(\'h2_biases\', [10], initializer=tf.constant_initializer(0.0))\n    logits = tf.matmul(h1, w2) + b2\n    return logits\n\n# logits1 = two_hidden_layers(x1)\n# logits2 = two_hidden_layers(x2)\n\n# logits1 = two_hidden_layers_2(x1)\n# logits2 = two_hidden_layers_2(x2)\n\n# with tf.variable_scope(\'two_layers\') as scope:\n#     logits1 = two_hidden_layers_2(x1)\n#     scope.reuse_variables()\n#     logits2 = two_hidden_layers_2(x2)\n\n# with tf.variable_scope(\'two_layers\') as scope:\n#     logits1 = two_hidden_layers_2(x1)\n#     scope.reuse_variables()\n#     logits2 = two_hidden_layers_2(x2)\n\ndef fully_connected(x, output_dim, scope):\n    with tf.variable_scope(scope, reuse=tf.AUTO_REUSE) as scope:\n        w = tf.get_variable(\'weights\', [x.shape[1], output_dim], initializer=tf.random_normal_initializer())\n        b = tf.get_variable(\'biases\', [output_dim], initializer=tf.constant_initializer(0.0))\n        return tf.matmul(x, w) + b\n\ndef two_hidden_layers(x):\n    h1 = fully_connected(x, 50, \'h1\')\n    h2 = fully_connected(h1, 10, \'h2\')\n\nwith tf.variable_scope(\'two_layers\') as scope:\n    logits1 = two_hidden_layers(x1)\n    # scope.reuse_variables()\n    logits2 = two_hidden_layers(x2)\n\nwriter = tf.summary.FileWriter(\'./graphs/cool_variables\', tf.get_default_graph())\nwriter.close()'"
examples/07_convnet_layers.py,36,"b'"""""" Using convolutional net on MNIST dataset of handwritten digits\nMNIST dataset: http://yann.lecun.com/exdb/mnist/\nCS 20: ""TensorFlow for Deep Learning Research""\ncs20.stanford.edu\nChip Huyen (chiphuyen@cs.stanford.edu)\nLecture 07\n""""""\nimport os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\nimport time \n\nimport tensorflow as tf\n\nimport utils\n\nclass ConvNet(object):\n    def __init__(self):\n        self.lr = 0.001\n        self.batch_size = 128\n        self.keep_prob = tf.constant(0.75)\n        self.gstep = tf.Variable(0, dtype=tf.int32, \n                                trainable=False, name=\'global_step\')\n        self.n_classes = 10\n        self.skip_step = 20\n        self.n_test = 10000\n        self.training=False\n\n    def get_data(self):\n        with tf.name_scope(\'data\'):\n            train_data, test_data = utils.get_mnist_dataset(self.batch_size)\n            iterator = tf.data.Iterator.from_structure(train_data.output_types, \n                                                   train_data.output_shapes)\n            img, self.label = iterator.get_next()\n            self.img = tf.reshape(img, shape=[-1, 28, 28, 1])\n            # reshape the image to make it work with tf.nn.conv2d\n\n            self.train_init = iterator.make_initializer(train_data)  # initializer for train_data\n            self.test_init = iterator.make_initializer(test_data)    # initializer for train_data\n\n    def inference(self):\n        conv1 = tf.layers.conv2d(inputs=self.img,\n                                  filters=32,\n                                  kernel_size=[5, 5],\n                                  padding=\'SAME\',\n                                  activation=tf.nn.relu,\n                                  name=\'conv1\')\n        pool1 = tf.layers.max_pooling2d(inputs=conv1, \n                                        pool_size=[2, 2], \n                                        strides=2,\n                                        name=\'pool1\')\n\n        conv2 = tf.layers.conv2d(inputs=pool1,\n                                  filters=64,\n                                  kernel_size=[5, 5],\n                                  padding=\'SAME\',\n                                  activation=tf.nn.relu,\n                                  name=\'conv2\')\n        pool2 = tf.layers.max_pooling2d(inputs=conv2, \n                                        pool_size=[2, 2], \n                                        strides=2,\n                                        name=\'pool2\')\n\n        feature_dim = pool2.shape[1] * pool2.shape[2] * pool2.shape[3]\n        pool2 = tf.reshape(pool2, [-1, feature_dim])\n        fc = tf.layers.dense(pool2, 1024, activation=tf.nn.relu, name=\'fc\')\n        dropout = tf.layers.dropout(fc, \n                                    self.keep_prob, \n                                    training=self.training, \n                                    name=\'dropout\')\n        self.logits = tf.layers.dense(dropout, self.n_classes, name=\'logits\')\n\n    def loss(self):\n        \'\'\'\n        define loss function\n        use softmax cross entropy with logits as the loss function\n        compute mean cross entropy, softmax is applied internally\n        \'\'\'\n        # \n        with tf.name_scope(\'loss\'):\n            entropy = tf.nn.softmax_cross_entropy_with_logits(labels=self.label, logits=self.logits)\n            self.loss = tf.reduce_mean(entropy, name=\'loss\')\n    \n    def optimize(self):\n        \'\'\'\n        Define training op\n        using Adam Gradient Descent to minimize cost\n        \'\'\'\n        self.opt = tf.train.AdamOptimizer(self.lr).minimize(self.loss, \n                                                global_step=self.gstep)\n\n    def summary(self):\n        \'\'\'\n        Create summaries to write on TensorBoard\n        \'\'\'\n        with tf.name_scope(\'summaries\'):\n            tf.summary.scalar(\'loss\', self.loss)\n            tf.summary.scalar(\'accuracy\', self.accuracy)\n            tf.summary.histogram(\'histogram loss\', self.loss)\n            self.summary_op = tf.summary.merge_all()\n    \n    def eval(self):\n        \'\'\'\n        Count the number of right predictions in a batch\n        \'\'\'\n        with tf.name_scope(\'predict\'):\n            preds = tf.nn.softmax(self.logits)\n            correct_preds = tf.equal(tf.argmax(preds, 1), tf.argmax(self.label, 1))\n            self.accuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32))\n\n    def build(self):\n        \'\'\'\n        Build the computation graph\n        \'\'\'\n        self.get_data()\n        self.inference()\n        self.loss()\n        self.optimize()\n        self.eval()\n        self.summary()\n\n    def train_one_epoch(self, sess, saver, init, writer, epoch, step):\n        start_time = time.time()\n        sess.run(init) \n        self.training = True\n        total_loss = 0\n        n_batches = 0\n        try:\n            while True:\n                _, l, summaries = sess.run([self.opt, self.loss, self.summary_op])\n                writer.add_summary(summaries, global_step=step)\n                if (step + 1) % self.skip_step == 0:\n                    print(\'Loss at step {0}: {1}\'.format(step, l))\n                step += 1\n                total_loss += l\n                n_batches += 1\n        except tf.errors.OutOfRangeError:\n            pass\n        saver.save(sess, \'checkpoints/convnet_layers/mnist-convnet\', step)\n        print(\'Average loss at epoch {0}: {1}\'.format(epoch, total_loss/n_batches))\n        print(\'Took: {0} seconds\'.format(time.time() - start_time))\n        return step\n\n    def eval_once(self, sess, init, writer, epoch, step):\n        start_time = time.time()\n        sess.run(init)\n        self.training = False\n        total_correct_preds = 0\n        try:\n            while True:\n                accuracy_batch, summaries = sess.run([self.accuracy, self.summary_op])\n                writer.add_summary(summaries, global_step=step)\n                total_correct_preds += accuracy_batch\n        except tf.errors.OutOfRangeError:\n            pass\n\n        print(\'Accuracy at epoch {0}: {1} \'.format(epoch, total_correct_preds/self.n_test))\n        print(\'Took: {0} seconds\'.format(time.time() - start_time))\n\n    def train(self, n_epochs):\n        \'\'\'\n        The train function alternates between training one epoch and evaluating\n        \'\'\'\n        utils.safe_mkdir(\'checkpoints\')\n        utils.safe_mkdir(\'checkpoints/convnet_layers\')\n        writer = tf.summary.FileWriter(\'./graphs/convnet_layers\', tf.get_default_graph())\n\n        with tf.Session() as sess:\n            sess.run(tf.global_variables_initializer())\n            saver = tf.train.Saver()\n            ckpt = tf.train.get_checkpoint_state(os.path.dirname(\'checkpoints/convnet_layers/checkpoint\'))\n            if ckpt and ckpt.model_checkpoint_path:\n                saver.restore(sess, ckpt.model_checkpoint_path)\n            \n            step = self.gstep.eval()\n\n            for epoch in range(n_epochs):\n                step = self.train_one_epoch(sess, saver, self.train_init, writer, epoch, step)\n                self.eval_once(sess, self.test_init, writer, epoch, step)\n        writer.close()\n\nif __name__ == \'__main__\':\n    model = ConvNet()\n    model.build()\n    model.train(n_epochs=15)'"
examples/07_convnet_mnist.py,43,"b'"""""" Using convolutional net on MNIST dataset of handwritten digits\nMNIST dataset: http://yann.lecun.com/exdb/mnist/\nCS 20: ""TensorFlow for Deep Learning Research""\ncs20.stanford.edu\nChip Huyen (chiphuyen@cs.stanford.edu)\nLecture 07\n""""""\nimport os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\nimport time \n\nimport tensorflow as tf\n\nimport utils\n\ndef conv_relu(inputs, filters, k_size, stride, padding, scope_name):\n    \'\'\'\n    A method that does convolution + relu on inputs\n    \'\'\'\n    with tf.variable_scope(scope_name, reuse=tf.AUTO_REUSE) as scope:\n        in_channels = inputs.shape[-1]\n        kernel = tf.get_variable(\'kernel\', \n                                [k_size, k_size, in_channels, filters], \n                                initializer=tf.truncated_normal_initializer())\n        biases = tf.get_variable(\'biases\', \n                                [filters],\n                                initializer=tf.random_normal_initializer())\n        conv = tf.nn.conv2d(inputs, kernel, strides=[1, stride, stride, 1], padding=padding)\n    return tf.nn.relu(conv + biases, name=scope.name)\n\ndef maxpool(inputs, ksize, stride, padding=\'VALID\', scope_name=\'pool\'):\n    \'\'\'A method that does max pooling on inputs\'\'\'\n    with tf.variable_scope(scope_name, reuse=tf.AUTO_REUSE) as scope:\n        pool = tf.nn.max_pool(inputs, \n                            ksize=[1, ksize, ksize, 1], \n                            strides=[1, stride, stride, 1],\n                            padding=padding)\n    return pool\n\ndef fully_connected(inputs, out_dim, scope_name=\'fc\'):\n    \'\'\'\n    A fully connected linear layer on inputs\n    \'\'\'\n    with tf.variable_scope(scope_name, reuse=tf.AUTO_REUSE) as scope:\n        in_dim = inputs.shape[-1]\n        w = tf.get_variable(\'weights\', [in_dim, out_dim],\n                            initializer=tf.truncated_normal_initializer())\n        b = tf.get_variable(\'biases\', [out_dim],\n                            initializer=tf.constant_initializer(0.0))\n        out = tf.matmul(inputs, w) + b\n    return out\n\nclass ConvNet(object):\n    def __init__(self):\n        self.lr = 0.001\n        self.batch_size = 128\n        self.keep_prob = tf.constant(0.75)\n        self.gstep = tf.Variable(0, dtype=tf.int32, \n                                trainable=False, name=\'global_step\')\n        self.n_classes = 10\n        self.skip_step = 20\n        self.n_test = 10000\n        self.training = True\n\n    def get_data(self):\n        with tf.name_scope(\'data\'):\n            train_data, test_data = utils.get_mnist_dataset(self.batch_size)\n            iterator = tf.data.Iterator.from_structure(train_data.output_types, \n                                                   train_data.output_shapes)\n            img, self.label = iterator.get_next()\n            self.img = tf.reshape(img, shape=[-1, 28, 28, 1])\n            # reshape the image to make it work with tf.nn.conv2d\n\n            self.train_init = iterator.make_initializer(train_data)  # initializer for train_data\n            self.test_init = iterator.make_initializer(test_data)    # initializer for train_data\n\n    def inference(self):\n        conv1 = conv_relu(inputs=self.img,\n                        filters=32,\n                        k_size=5,\n                        stride=1,\n                        padding=\'SAME\',\n                        scope_name=\'conv1\')\n        pool1 = maxpool(conv1, 2, 2, \'VALID\', \'pool1\')\n        conv2 = conv_relu(inputs=pool1,\n                        filters=64,\n                        k_size=5,\n                        stride=1,\n                        padding=\'SAME\',\n                        scope_name=\'conv2\')\n        pool2 = maxpool(conv2, 2, 2, \'VALID\', \'pool2\')\n        feature_dim = pool2.shape[1] * pool2.shape[2] * pool2.shape[3]\n        pool2 = tf.reshape(pool2, [-1, feature_dim])\n        fc = fully_connected(pool2, 1024, \'fc\')\n        dropout = tf.nn.dropout(tf.nn.relu(fc), self.keep_prob, name=\'relu_dropout\')\n        self.logits = fully_connected(dropout, self.n_classes, \'logits\')\n\n    def loss(self):\n        \'\'\'\n        define loss function\n        use softmax cross entropy with logits as the loss function\n        compute mean cross entropy, softmax is applied internally\n        \'\'\'\n        # \n        with tf.name_scope(\'loss\'):\n            entropy = tf.nn.softmax_cross_entropy_with_logits(labels=self.label, logits=self.logits)\n            self.loss = tf.reduce_mean(entropy, name=\'loss\')\n    \n    def optimize(self):\n        \'\'\'\n        Define training op\n        using Adam Gradient Descent to minimize cost\n        \'\'\'\n        self.opt = tf.train.AdamOptimizer(self.lr).minimize(self.loss, \n                                                global_step=self.gstep)\n\n    def summary(self):\n        \'\'\'\n        Create summaries to write on TensorBoard\n        \'\'\'\n        with tf.name_scope(\'summaries\'):\n            tf.summary.scalar(\'loss\', self.loss)\n            tf.summary.scalar(\'accuracy\', self.accuracy)\n            tf.summary.histogram(\'histogram loss\', self.loss)\n            self.summary_op = tf.summary.merge_all()\n    \n    def eval(self):\n        \'\'\'\n        Count the number of right predictions in a batch\n        \'\'\'\n        with tf.name_scope(\'predict\'):\n            preds = tf.nn.softmax(self.logits)\n            correct_preds = tf.equal(tf.argmax(preds, 1), tf.argmax(self.label, 1))\n            self.accuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32))\n\n    def build(self):\n        \'\'\'\n        Build the computation graph\n        \'\'\'\n        self.get_data()\n        self.inference()\n        self.loss()\n        self.optimize()\n        self.eval()\n        self.summary()\n\n    def train_one_epoch(self, sess, saver, init, writer, epoch, step):\n        start_time = time.time()\n        sess.run(init) \n        self.training = True\n        total_loss = 0\n        n_batches = 0\n        try:\n            while True:\n                _, l, summaries = sess.run([self.opt, self.loss, self.summary_op])\n                writer.add_summary(summaries, global_step=step)\n                if (step + 1) % self.skip_step == 0:\n                    print(\'Loss at step {0}: {1}\'.format(step, l))\n                step += 1\n                total_loss += l\n                n_batches += 1\n        except tf.errors.OutOfRangeError:\n            pass\n        saver.save(sess, \'checkpoints/convnet_mnist/mnist-convnet\', step)\n        print(\'Average loss at epoch {0}: {1}\'.format(epoch, total_loss/n_batches))\n        print(\'Took: {0} seconds\'.format(time.time() - start_time))\n        return step\n\n    def eval_once(self, sess, init, writer, epoch, step):\n        start_time = time.time()\n        sess.run(init)\n        self.training = False\n        total_correct_preds = 0\n        try:\n            while True:\n                accuracy_batch, summaries = sess.run([self.accuracy, self.summary_op])\n                writer.add_summary(summaries, global_step=step)\n                total_correct_preds += accuracy_batch\n        except tf.errors.OutOfRangeError:\n            pass\n\n        print(\'Accuracy at epoch {0}: {1} \'.format(epoch, total_correct_preds/self.n_test))\n        print(\'Took: {0} seconds\'.format(time.time() - start_time))\n\n    def train(self, n_epochs):\n        \'\'\'\n        The train function alternates between training one epoch and evaluating\n        \'\'\'\n        utils.safe_mkdir(\'checkpoints\')\n        utils.safe_mkdir(\'checkpoints/convnet_mnist\')\n        writer = tf.summary.FileWriter(\'./graphs/convnet\', tf.get_default_graph())\n\n        with tf.Session() as sess:\n            sess.run(tf.global_variables_initializer())\n            saver = tf.train.Saver()\n            ckpt = tf.train.get_checkpoint_state(os.path.dirname(\'checkpoints/convnet_mnist/checkpoint\'))\n            if ckpt and ckpt.model_checkpoint_path:\n                saver.restore(sess, ckpt.model_checkpoint_path)\n            \n            step = self.gstep.eval()\n\n            for epoch in range(n_epochs):\n                step = self.train_one_epoch(sess, saver, self.train_init, writer, epoch, step)\n                self.eval_once(sess, self.test_init, writer, epoch, step)\n        writer.close()\n\nif __name__ == \'__main__\':\n    model = ConvNet()\n    model.build()\n    model.train(n_epochs=30)\n'"
examples/07_convnet_mnist_starter.py,18,"b'"""""" Using convolutional net on MNIST dataset of handwritten digits\nMNIST dataset: http://yann.lecun.com/exdb/mnist/\nCS 20: ""TensorFlow for Deep Learning Research""\ncs20.stanford.edu\nChip Huyen (chiphuyen@cs.stanford.edu)\nLecture 07\n""""""\nimport os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\nimport time \n\nimport tensorflow as tf\n\nimport utils\n\ndef conv_relu(inputs, filters, k_size, stride, padding, scope_name):\n    \'\'\'\n    A method that does convolution + relu on inputs\n    \'\'\'\n    #############################\n    ########## TO DO ############\n    #############################\n    return None\n\ndef maxpool(inputs, ksize, stride, padding=\'VALID\', scope_name=\'pool\'):\n    \'\'\'A method that does max pooling on inputs\'\'\'\n    #############################\n    ########## TO DO ############\n    #############################\n    return None\n\ndef fully_connected(inputs, out_dim, scope_name=\'fc\'):\n    \'\'\'\n    A fully connected linear layer on inputs\n    \'\'\'\n    #############################\n    ########## TO DO ############\n    #############################\n    return None\n\nclass ConvNet(object):\n    def __init__(self):\n        self.lr = 0.001\n        self.batch_size = 128\n        self.keep_prob = tf.constant(0.75)\n        self.gstep = tf.Variable(0, dtype=tf.int32, \n                                trainable=False, name=\'global_step\')\n        self.n_classes = 10\n        self.skip_step = 20\n        self.n_test = 10000\n\n    def get_data(self):\n        with tf.name_scope(\'data\'):\n            train_data, test_data = utils.get_mnist_dataset(self.batch_size)\n            iterator = tf.data.Iterator.from_structure(train_data.output_types, \n                                                   train_data.output_shapes)\n            img, self.label = iterator.get_next()\n            self.img = tf.reshape(img, shape=[-1, 28, 28, 1])\n            # reshape the image to make it work with tf.nn.conv2d\n\n            self.train_init = iterator.make_initializer(train_data)  # initializer for train_data\n            self.test_init = iterator.make_initializer(test_data)    # initializer for train_data\n\n    def inference(self):\n        \'\'\'\n        Build the model according to the description we\'ve shown in class\n        \'\'\'\n        #############################\n        ########## TO DO ############\n        #############################\n        self.logits = None\n\n    def loss(self):\n        \'\'\'\n        define loss function\n        use softmax cross entropy with logits as the loss function\n        tf.nn.softmax_cross_entropy_with_logits\n        softmax is applied internally\n        don\'t forget to compute mean cross all sample in a batch\n        \'\'\'\n        #############################\n        ########## TO DO ############\n        #############################\n        self.loss = None\n    \n    def optimize(self):\n        \'\'\'\n        Define training op\n        using Adam Gradient Descent to minimize cost\n        Don\'t forget to use global step\n        \'\'\'\n        #############################\n        ########## TO DO ############\n        #############################\n        self.opt = None\n\n    def summary(self):\n        \'\'\'\n        Create summaries to write on TensorBoard\n        Remember to track both training loss and test accuracy\n        \'\'\'\n        #############################\n        ########## TO DO ############\n        #############################\n        self.summary_op = None\n        \n    def eval(self):\n        \'\'\'\n        Count the number of right predictions in a batch\n        \'\'\'\n        with tf.name_scope(\'predict\'):\n            preds = tf.nn.softmax(self.logits)\n            correct_preds = tf.equal(tf.argmax(preds, 1), tf.argmax(self.label, 1))\n            self.accuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32))\n\n    def build(self):\n        \'\'\'\n        Build the computation graph\n        \'\'\'\n        self.get_data()\n        self.inference()\n        self.loss()\n        self.optimize()\n        self.eval()\n        self.summary()\n\n    def train_one_epoch(self, sess, saver, init, writer, epoch, step):\n        start_time = time.time()\n        sess.run(init) \n        total_loss = 0\n        n_batches = 0\n        try:\n            while True:\n                _, l, summaries = sess.run([self.opt, self.loss, self.summary_op])\n                writer.add_summary(summaries, global_step=step)\n                if (step + 1) % self.skip_step == 0:\n                    print(\'Loss at step {0}: {1}\'.format(step, l))\n                step += 1\n                total_loss += l\n                n_batches += 1\n        except tf.errors.OutOfRangeError:\n            pass\n        saver.save(sess, \'checkpoints/convnet_starter/mnist-convnet\', step)\n        print(\'Average loss at epoch {0}: {1}\'.format(epoch, total_loss/n_batches))\n        print(\'Took: {0} seconds\'.format(time.time() - start_time))\n        return step\n\n    def eval_once(self, sess, init, writer, epoch, step):\n        start_time = time.time()\n        sess.run(init)\n        total_correct_preds = 0\n        try:\n            while True:\n                accuracy_batch, summaries = sess.run([self.accuracy, self.summary_op])\n                writer.add_summary(summaries, global_step=step)\n                total_correct_preds += accuracy_batch\n        except tf.errors.OutOfRangeError:\n            pass\n\n        print(\'Accuracy at epoch {0}: {1} \'.format(epoch, total_correct_preds/self.n_test))\n        print(\'Took: {0} seconds\'.format(time.time() - start_time))\n\n    def train(self, n_epochs):\n        \'\'\'\n        The train function alternates between training one epoch and evaluating\n        \'\'\'\n        utils.safe_mkdir(\'checkpoints\')\n        utils.safe_mkdir(\'checkpoints/convnet_starter\')\n        writer = tf.summary.FileWriter(\'./graphs/convnet_starter\', tf.get_default_graph())\n\n        with tf.Session() as sess:\n            sess.run(tf.global_variables_initializer())\n            saver = tf.train.Saver()\n            ckpt = tf.train.get_checkpoint_state(os.path.dirname(\'checkpoints/convnet_starter/checkpoint\'))\n            if ckpt and ckpt.model_checkpoint_path:\n                saver.restore(sess, ckpt.model_checkpoint_path)\n            \n            step = self.gstep.eval()\n\n            for epoch in range(n_epochs):\n                step = self.train_one_epoch(sess, saver, self.train_init, writer, epoch, step)\n                self.eval_once(sess, self.test_init, writer, epoch, step)\n        writer.close()\n\nif __name__ == \'__main__\':\n    model = ConvNet()\n    model.build()\n    model.train(n_epochs=15)'"
examples/07_run_kernels.py,8,"b'""""""\nSimple examples of convolution to do some basic filters\nAlso demonstrates the use of TensorFlow data readers.\n\nWe will use some popular filters for our image.\nIt seems to be working with grayscale images, but not with rgb images.\nIt\'s probably because I didn\'t choose the right kernels for rgb images.\n\nkernels for rgb images have dimensions 3 x 3 x 3 x 3\nkernels for grayscale images have dimensions 3 x 3 x 1 x 1\n\nCS 20: ""TensorFlow for Deep Learning Research""\ncs20.stanford.edu\nChip Huyen (chiphuyen@cs.stanford.edu)\nLecture 07\n""""""\nimport os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\n\nimport sys\nsys.path.append(\'..\')\n\nfrom matplotlib import gridspec as gridspec\nfrom matplotlib import pyplot as plt\nimport tensorflow as tf\n\nimport kernels\n\ndef read_one_image(filename):\n    \'\'\' This method is to show how to read image from a file into a tensor.\n    The output is a tensor object.\n    \'\'\'\n    image_string = tf.read_file(filename)\n    image_decoded = tf.image.decode_image(image_string)\n    image = tf.cast(image_decoded, tf.float32) / 256.0\n    return image\n\ndef convolve(image, kernels, rgb=True, strides=[1, 3, 3, 1], padding=\'SAME\'):\n    images = [image[0]]\n    for i, kernel in enumerate(kernels):\n        filtered_image = tf.nn.conv2d(image, \n                                      kernel, \n                                      strides=strides,\n                                      padding=padding)[0]\n        if i == 2:\n            filtered_image = tf.minimum(tf.nn.relu(filtered_image), 255)\n        images.append(filtered_image)\n    return images\n\ndef show_images(images, rgb=True):\n    gs = gridspec.GridSpec(1, len(images))\n    for i, image in enumerate(images):\n        plt.subplot(gs[0, i])\n        if rgb:\n            plt.imshow(image)\n        else: \n            image = image.reshape(image.shape[0], image.shape[1])\n            plt.imshow(image, cmap=\'gray\')\n        plt.axis(\'off\')\n    plt.show()\n\ndef main():\n    rgb = False\n    if rgb:\n        kernels_list = [kernels.BLUR_FILTER_RGB, \n                        kernels.SHARPEN_FILTER_RGB, \n                        kernels.EDGE_FILTER_RGB,\n                        kernels.TOP_SOBEL_RGB,\n                        kernels.EMBOSS_FILTER_RGB]\n    else:\n        kernels_list = [kernels.BLUR_FILTER,\n                        kernels.SHARPEN_FILTER,\n                        kernels.EDGE_FILTER,\n                        kernels.TOP_SOBEL,\n                        kernels.EMBOSS_FILTER]\n\n    kernels_list = kernels_list[1:]\n    image = read_one_image(\'data/friday.jpg\')\n    if not rgb:\n        image = tf.image.rgb_to_grayscale(image)\n    image = tf.expand_dims(image, 0) # make it into a batch of 1 element\n    images = convolve(image, kernels_list, rgb)\n    with tf.Session() as sess:\n        images = sess.run(images) # convert images from tensors to float values\n    show_images(images, rgb)\n\nif __name__ == \'__main__\':\n    main()'"
examples/11_char_rnn.py,22,"b'"""""" A clean, no_frills character-level generative language model.\n\nCS 20: ""TensorFlow for Deep Learning Research""\ncs20.stanford.edu\nDanijar Hafner (mail@danijar.com)\n& Chip Huyen (chiphuyen@cs.stanford.edu)\nLecture 11\n""""""\nimport os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\nimport random\nimport sys\nsys.path.append(\'..\')\nimport time\n\nimport tensorflow as tf\n\nimport utils\n\ndef vocab_encode(text, vocab):\n    return [vocab.index(x) + 1 for x in text if x in vocab]\n\ndef vocab_decode(array, vocab):\n    return \'\'.join([vocab[x - 1] for x in array])\n\ndef read_data(filename, vocab, window, overlap):\n    lines = [line.strip() for line in open(filename, \'r\').readlines()]\n    while True:\n        random.shuffle(lines)\n\n        for text in lines:\n            text = vocab_encode(text, vocab)\n            for start in range(0, len(text) - window, overlap):\n                chunk = text[start: start + window]\n                chunk += [0] * (window - len(chunk))\n                yield chunk\n\ndef read_batch(stream, batch_size):\n    batch = []\n    for element in stream:\n        batch.append(element)\n        if len(batch) == batch_size:\n            yield batch\n            batch = []\n    yield batch\n\nclass CharRNN(object):\n    def __init__(self, model):\n        self.model = model\n        self.path = \'data/\' + model + \'.txt\'\n        if \'trump\' in model:\n            self.vocab = (""$%\'()+,-./0123456789:;=?ABCDEFGHIJKLMNOPQRSTUVWXYZ""\n                    "" \'\\""_abcdefghijklmnopqrstuvwxyz{|}@#\xe2\x9e\xa1\xf0\x9f\x93\x88"")\n        else:\n            self.vocab = ("" $%\'()+,-./0123456789:;=?ABCDEFGHIJKLMNOPQRSTUVWXYZ""\n                    ""\\\\^_abcdefghijklmnopqrstuvwxyz{|}"")\n\n        self.seq = tf.placeholder(tf.int32, [None, None])\n        self.temp = tf.constant(1.5)\n        self.hidden_sizes = [128, 256]\n        self.batch_size = 64\n        self.lr = 0.0003\n        self.skip_step = 1\n        self.num_steps = 50 # for RNN unrolled\n        self.len_generated = 200\n        self.gstep = tf.Variable(0, dtype=tf.int32, trainable=False, name=\'global_step\')\n\n    def create_rnn(self, seq):\n        layers = [tf.nn.rnn_cell.GRUCell(size) for size in self.hidden_sizes]\n        cells = tf.nn.rnn_cell.MultiRNNCell(layers)\n        batch = tf.shape(seq)[0]\n        zero_states = cells.zero_state(batch, dtype=tf.float32)\n        self.in_state = tuple([tf.placeholder_with_default(state, [None, state.shape[1]]) \n                                for state in zero_states])\n        # this line to calculate the real length of seq\n        # all seq are padded to be of the same length, which is num_steps\n        length = tf.reduce_sum(tf.reduce_max(tf.sign(seq), 2), 1)\n        self.output, self.out_state = tf.nn.dynamic_rnn(cells, seq, length, self.in_state)\n\n    def create_model(self):\n        seq = tf.one_hot(self.seq, len(self.vocab))\n        self.create_rnn(seq)\n        self.logits = tf.layers.dense(self.output, len(self.vocab), None)\n        loss = tf.nn.softmax_cross_entropy_with_logits(logits=self.logits[:, :-1], \n                                                        labels=seq[:, 1:])\n        self.loss = tf.reduce_sum(loss)\n        # sample the next character from Maxwell-Boltzmann Distribution \n        # with temperature temp. It works equally well without tf.exp\n        self.sample = tf.multinomial(tf.exp(self.logits[:, -1] / self.temp), 1)[:, 0] \n        self.opt = tf.train.AdamOptimizer(self.lr).minimize(self.loss, global_step=self.gstep)\n\n    def train(self):\n        saver = tf.train.Saver()\n        start = time.time()\n        min_loss = None\n        with tf.Session() as sess:\n            writer = tf.summary.FileWriter(\'graphs/gist\', sess.graph)\n            sess.run(tf.global_variables_initializer())\n            \n            ckpt = tf.train.get_checkpoint_state(os.path.dirname(\'checkpoints/\' + self.model + \'/checkpoint\'))\n            if ckpt and ckpt.model_checkpoint_path:\n                saver.restore(sess, ckpt.model_checkpoint_path)\n            \n            iteration = self.gstep.eval()\n            stream = read_data(self.path, self.vocab, self.num_steps, overlap=self.num_steps//2)\n            data = read_batch(stream, self.batch_size)\n            while True:\n                batch = next(data)\n\n            # for batch in read_batch(read_data(DATA_PATH, vocab)):\n                batch_loss, _ = sess.run([self.loss, self.opt], {self.seq: batch})\n                if (iteration + 1) % self.skip_step == 0:\n                    print(\'Iter {}. \\n    Loss {}. Time {}\'.format(iteration, batch_loss, time.time() - start))\n                    self.online_infer(sess)\n                    start = time.time()\n                    checkpoint_name = \'checkpoints/\' + self.model + \'/char-rnn\'\n                    if min_loss is None:\n                        saver.save(sess, checkpoint_name, iteration)\n                    elif batch_loss < min_loss:\n                        saver.save(sess, checkpoint_name, iteration)\n                        min_loss = batch_loss\n                iteration += 1\n\n    def online_infer(self, sess):\n        """""" Generate sequence one character at a time, based on the previous character\n        """"""\n        for seed in [\'Hillary\', \'I\', \'R\', \'T\', \'@\', \'N\', \'M\', \'.\', \'G\', \'A\', \'W\']:\n            sentence = seed\n            state = None\n            for _ in range(self.len_generated):\n                batch = [vocab_encode(sentence[-1], self.vocab)]\n                feed = {self.seq: batch}\n                if state is not None: # for the first decoder step, the state is None\n                    for i in range(len(state)):\n                        feed.update({self.in_state[i]: state[i]})\n                index, state = sess.run([self.sample, self.out_state], feed)\n                sentence += vocab_decode(index, self.vocab)\n            print(\'\\t\' + sentence)\n\ndef main():\n    model = \'trump_tweets\'\n    utils.safe_mkdir(\'checkpoints\')\n    utils.safe_mkdir(\'checkpoints/\' + model)\n\n    lm = CharRNN(model)\n    lm.create_model()\n    lm.train()\n    \nif __name__ == \'__main__\':\n    main()'"
examples/kernels.py,11,"b'import numpy as np\nimport tensorflow as tf\n\na = np.zeros([3, 3, 3, 3])\na[1, 1, :, :] = 0.25\na[0, 1, :, :] = 0.125\na[1, 0, :, :] = 0.125\na[2, 1, :, :] = 0.125\na[1, 2, :, :] = 0.125\na[0, 0, :, :] = 0.0625\na[0, 2, :, :] = 0.0625\na[2, 0, :, :] = 0.0625\na[2, 2, :, :] = 0.0625\n\nBLUR_FILTER_RGB = tf.constant(a, dtype=tf.float32)\n\na = np.zeros([3, 3, 1, 1])\n# a[1, 1, :, :] = 0.25\n# a[0, 1, :, :] = 0.125\n# a[1, 0, :, :] = 0.125\n# a[2, 1, :, :] = 0.125\n# a[1, 2, :, :] = 0.125\n# a[0, 0, :, :] = 0.0625\n# a[0, 2, :, :] = 0.0625\n# a[2, 0, :, :] = 0.0625\n# a[2, 2, :, :] = 0.0625\na[1, 1, :, :] = 1.0\na[0, 1, :, :] = 1.0\na[1, 0, :, :] = 1.0\na[2, 1, :, :] = 1.0\na[1, 2, :, :] = 1.0\na[0, 0, :, :] = 1.0\na[0, 2, :, :] = 1.0\na[2, 0, :, :] = 1.0\na[2, 2, :, :] = 1.0\nBLUR_FILTER = tf.constant(a, dtype=tf.float32)\n\na = np.zeros([3, 3, 3, 3])\na[1, 1, :, :] = 5\na[0, 1, :, :] = -1\na[1, 0, :, :] = -1\na[2, 1, :, :] = -1\na[1, 2, :, :] = -1\n\nSHARPEN_FILTER_RGB = tf.constant(a, dtype=tf.float32)\n\na = np.zeros([3, 3, 1, 1])\na[1, 1, :, :] = 5\na[0, 1, :, :] = -1\na[1, 0, :, :] = -1\na[2, 1, :, :] = -1\na[1, 2, :, :] = -1\n\nSHARPEN_FILTER = tf.constant(a, dtype=tf.float32)\n\n# a = np.zeros([3, 3, 3, 3])\n# a[:, :, :, :] = -1\n# a[1, 1, :, :] = 8\n\n# EDGE_FILTER_RGB = tf.constant(a, dtype=tf.float32)\n\nEDGE_FILTER_RGB = tf.constant([\n\t\t\t[[[ -1., 0., 0.], [ 0., -1., 0.], [ 0., 0., -1.]],\n            [[ -1., 0., 0.], [ 0., -1., 0.], [ 0., 0., -1.]],\n            [[ -1., 0., 0.], [ 0., -1., 0.], [ 0., 0., -1.]]],\n            [[[ -1., 0., 0.], [ 0., -1., 0.], [ 0., 0., -1.]],\n\t\t\t[[ 8., 0., 0.], [ 0., 8., 0.], [ 0., 0., 8.]],\n\t\t\t[[ -1., 0., 0.], [ 0., -1., 0.], [ 0., 0., -1.]]],\n\t\t\t[[[ -1., 0., 0.], [ 0., -1., 0.], [ 0., 0., -1.]],\n\t\t\t[[ -1., 0., 0.], [ 0., -1., 0.], [ 0., 0., -1.]],\n\t\t\t[[ -1., 0., 0.], [ 0., -1., 0.], [ 0., 0., -1.]]]\n])\n\na = np.zeros([3, 3, 1, 1])\n# a[:, :, :, :] = -1\n# a[1, 1, :, :] = 8\na[0, 1, :, :] = -1\na[1, 0, :, :] = -1\na[1, 2, :, :] = -1\na[2, 1, :, :] = -1\na[1, 1, :, :] = 4\n\nEDGE_FILTER = tf.constant(a, dtype=tf.float32)\n\na = np.zeros([3, 3, 3, 3])\na[0, :, :, :] = 1\na[0, 1, :, :] = 2 # originally 2\na[2, :, :, :] = -1\na[2, 1, :, :] = -2\n\nTOP_SOBEL_RGB = tf.constant(a, dtype=tf.float32)\n\na = np.zeros([3, 3, 1, 1])\na[0, :, :, :] = 1\na[0, 1, :, :] = 2 # originally 2\na[2, :, :, :] = -1\na[2, 1, :, :] = -2\n\nTOP_SOBEL = tf.constant(a, dtype=tf.float32)\n\na = np.zeros([3, 3, 3, 3])\na[0, 0, :, :] = -2\na[0, 1, :, :] = -1 \na[1, 0, :, :] = -1\na[1, 1, :, :] = 1\na[1, 2, :, :] = 1\na[2, 1, :, :] = 1\na[2, 2, :, :] = 2\n\nEMBOSS_FILTER_RGB = tf.constant(a, dtype=tf.float32)\n\na = np.zeros([3, 3, 1, 1])\na[0, 0, :, :] = -2\na[0, 1, :, :] = -1 \na[1, 0, :, :] = -1\na[1, 1, :, :] = 1\na[1, 2, :, :] = 1\na[2, 1, :, :] = 1\na[2, 2, :, :] = 2\nEMBOSS_FILTER = tf.constant(a, dtype=tf.float32)'"
examples/utils.py,6,"b'import os\nimport gzip\nimport shutil\nimport struct\nimport urllib\n\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\n\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport tensorflow as tf\n\ndef huber_loss(labels, predictions, delta=14.0):\n    residual = tf.abs(labels - predictions)\n    def f1(): return 0.5 * tf.square(residual)\n    def f2(): return delta * residual - 0.5 * tf.square(delta)\n    return tf.cond(residual < delta, f1, f2)\n\ndef safe_mkdir(path):\n    """""" Create a directory if there isn\'t one already. """"""\n    try:\n        os.mkdir(path)\n    except OSError:\n        pass\n\ndef read_birth_life_data(filename):\n    """"""\n    Read in birth_life_2010.txt and return:\n    data in the form of NumPy array\n    n_samples: number of samples\n    """"""\n    text = open(filename, \'r\').readlines()[1:]\n    data = [line[:-1].split(\'\\t\') for line in text]\n    births = [float(line[1]) for line in data]\n    lifes = [float(line[2]) for line in data]\n    data = list(zip(births, lifes))\n    n_samples = len(data)\n    data = np.asarray(data, dtype=np.float32)\n    return data, n_samples\n\ndef download_one_file(download_url, \n                    local_dest, \n                    expected_byte=None, \n                    unzip_and_remove=False):\n    """""" \n    Download the file from download_url into local_dest\n    if the file doesn\'t already exists.\n    If expected_byte is provided, check if \n    the downloaded file has the same number of bytes.\n    If unzip_and_remove is True, unzip the file and remove the zip file\n    """"""\n    if os.path.exists(local_dest) or os.path.exists(local_dest[:-3]):\n        print(\'%s already exists\' %local_dest)\n    else:\n        print(\'Downloading %s\' %download_url)\n        local_file, _ = urllib.request.urlretrieve(download_url, local_dest)\n        file_stat = os.stat(local_dest)\n        if expected_byte:\n            if file_stat.st_size == expected_byte:\n                print(\'Successfully downloaded %s\' %local_dest)\n                if unzip_and_remove:\n                    with gzip.open(local_dest, \'rb\') as f_in, open(local_dest[:-3],\'wb\') as f_out:\n                        shutil.copyfileobj(f_in, f_out)\n                    os.remove(local_dest)\n            else:\n                print(\'The downloaded file has unexpected number of bytes\')\n\ndef download_mnist(path):\n    """""" \n    Download and unzip the dataset mnist if it\'s not already downloaded \n    Download from http://yann.lecun.com/exdb/mnist\n    """"""\n    safe_mkdir(path)\n    url = \'http://yann.lecun.com/exdb/mnist\'\n    filenames = [\'train-images-idx3-ubyte.gz\',\n                \'train-labels-idx1-ubyte.gz\',\n                \'t10k-images-idx3-ubyte.gz\',\n                \'t10k-labels-idx1-ubyte.gz\']\n    expected_bytes = [9912422, 28881, 1648877, 4542]\n\n    for filename, byte in zip(filenames, expected_bytes):\n        download_url = os.path.join(url, filename)\n        local_dest = os.path.join(path, filename)\n        download_one_file(download_url, local_dest, byte, True)\n\ndef parse_data(path, dataset, flatten):\n    if dataset != \'train\' and dataset != \'t10k\':\n        raise NameError(\'dataset must be train or t10k\')\n\n    label_file = os.path.join(path, dataset + \'-labels-idx1-ubyte\')\n    with open(label_file, \'rb\') as file:\n        _, num = struct.unpack("">II"", file.read(8))\n        labels = np.fromfile(file, dtype=np.int8) #int8\n        new_labels = np.zeros((num, 10))\n        new_labels[np.arange(num), labels] = 1\n    \n    img_file = os.path.join(path, dataset + \'-images-idx3-ubyte\')\n    with open(img_file, \'rb\') as file:\n        _, num, rows, cols = struct.unpack("">IIII"", file.read(16))\n        imgs = np.fromfile(file, dtype=np.uint8).reshape(num, rows, cols) #uint8\n        imgs = imgs.astype(np.float32) / 255.0\n        if flatten:\n            imgs = imgs.reshape([num, -1])\n\n    return imgs, new_labels\n\ndef read_mnist(path, flatten=True, num_train=55000):\n    """"""\n    Read in the mnist dataset, given that the data is stored in path\n    Return two tuples of numpy arrays\n    ((train_imgs, train_labels), (test_imgs, test_labels))\n    """"""\n    imgs, labels = parse_data(path, \'train\', flatten)\n    indices = np.random.permutation(labels.shape[0])\n    train_idx, val_idx = indices[:num_train], indices[num_train:]\n    train_img, train_labels = imgs[train_idx, :], labels[train_idx, :]\n    val_img, val_labels = imgs[val_idx, :], labels[val_idx, :]\n    test = parse_data(path, \'t10k\', flatten)\n    return (train_img, train_labels), (val_img, val_labels), test\n\ndef get_mnist_dataset(batch_size):\n    # Step 1: Read in data\n    mnist_folder = \'data/mnist\'\n    download_mnist(mnist_folder)\n    train, val, test = read_mnist(mnist_folder, flatten=False)\n\n    # Step 2: Create datasets and iterator\n    train_data = tf.data.Dataset.from_tensor_slices(train)\n    train_data = train_data.shuffle(10000) # if you want to shuffle your data\n    train_data = train_data.batch(batch_size)\n\n    test_data = tf.data.Dataset.from_tensor_slices(test)\n    test_data = test_data.batch(batch_size)\n\n    return train_data, test_data\n    \ndef show(image):\n    """"""\n    Render a given numpy.uint8 2D array of pixel data.\n    """"""\n    plt.imshow(image, cmap=\'gray\')\n    plt.show()'"
examples/word2vec_utils.py,1,"b'from collections import Counter\nimport random\nimport os\nimport sys\nsys.path.append(\'..\')\nimport zipfile\n\nimport numpy as np\nfrom six.moves import urllib\nimport tensorflow as tf\n\nimport utils\n\ndef read_data(file_path):\n    """""" Read data into a list of tokens \n    There should be 17,005,207 tokens\n    """"""\n    with zipfile.ZipFile(file_path) as f:\n        words = tf.compat.as_str(f.read(f.namelist()[0])).split() \n    return words\n\ndef build_vocab(words, vocab_size, visual_fld):\n    """""" Build vocabulary of VOCAB_SIZE most frequent words and write it to\n    visualization/vocab.tsv\n    """"""\n    utils.safe_mkdir(visual_fld)\n    file = open(os.path.join(visual_fld, \'vocab.tsv\'), \'w\')\n    \n    dictionary = dict()\n    count = [(\'UNK\', -1)]\n    index = 0\n    count.extend(Counter(words).most_common(vocab_size - 1))\n    \n    for word, _ in count:\n        dictionary[word] = index\n        index += 1\n        file.write(word + \'\\n\')\n    \n    index_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n    file.close()\n    return dictionary, index_dictionary\n\ndef convert_words_to_index(words, dictionary):\n    """""" Replace each word in the dataset with its index in the dictionary """"""\n    return [dictionary[word] if word in dictionary else 0 for word in words]\n\ndef generate_sample(index_words, context_window_size):\n    """""" Form training pairs according to the skip-gram model. """"""\n    for index, center in enumerate(index_words):\n        context = random.randint(1, context_window_size)\n        # get a random target before the center word\n        for target in index_words[max(0, index - context): index]:\n            yield center, target\n        # get a random target after the center wrod\n        for target in index_words[index + 1: index + context + 1]:\n            yield center, target\n\ndef most_common_words(visual_fld, num_visualize):\n    """""" create a list of num_visualize most frequent words to visualize on TensorBoard.\n    saved to visualization/vocab_[num_visualize].tsv\n    """"""\n    words = open(os.path.join(visual_fld, \'vocab.tsv\'), \'r\').readlines()[:num_visualize]\n    words = [word for word in words]\n    file = open(os.path.join(visual_fld, \'vocab_\' + str(num_visualize) + \'.tsv\'), \'w\')\n    for word in words:\n        file.write(word)\n    file.close()\n\ndef batch_gen(download_url, expected_byte, vocab_size, batch_size, \n                skip_window, visual_fld):\n    local_dest = \'data/text8.zip\'\n    utils.download_one_file(download_url, local_dest, expected_byte)\n    words = read_data(local_dest)\n    dictionary, _ = build_vocab(words, vocab_size, visual_fld)\n    index_words = convert_words_to_index(words, dictionary)\n    del words           # to save memory\n    single_gen = generate_sample(index_words, skip_window)\n    \n    while True:\n        center_batch = np.zeros(batch_size, dtype=np.int32)\n        target_batch = np.zeros([batch_size, 1])\n        for index in range(batch_size):\n            center_batch[index], target_batch[index] = next(single_gen)\n        yield center_batch, target_batch\n'"
2017/examples/02_feed_dict.py,7,"b'"""""" Example to demonstrate the use of feed_dict\nAuthor: Chip Huyen\nPrepared for the class CS 20SI: ""TensorFlow for Deep Learning Research""\ncs20si.stanford.edu\n""""""\nimport os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\n\nimport tensorflow as tf\n\n# Example 1: feed_dict with placeholder\n# create a placeholder of type float 32-bit, value is a vector of 3 elements\na = tf.placeholder(tf.float32, shape=[3])\n\n# create a constant of type float 32-bit, value is a vector of 3 elements\nb = tf.constant([5, 5, 5], tf.float32)\n\n# use the placeholder as you would a constant\nc = a + b  # short for tf.add(a, b)\n\nwith tf.Session() as sess:\n\t# print(sess.run(c)) # InvalidArgumentError because a doesn\xe2\x80\x99t have any value\n\n\t# feed [1, 2, 3] to placeholder a via the dict {a: [1, 2, 3]}\n\t# fetch value of c\n\tprint(sess.run(c, {a: [1, 2, 3]})) # >> [6. 7. 8.]\n\n\n# Example 2: feed_dict with variables\na = tf.add(2, 5)\nb = tf.multiply(a, 3)\n\nwith tf.Session() as sess:\n\t# define a dictionary that says to replace the value of \'a\' with 15\n\treplace_dict = {a: 15}\n\n\t# Run the session, passing in \'replace_dict\' as the value to \'feed_dict\'\n\tprint(sess.run(b, feed_dict=replace_dict)) # >> 45'"
2017/examples/02_lazy_loading.py,14,"b'"""""" Example to demonstrate how the graph definition gets\nbloated because of lazy loading\nAuthor: Chip Huyen\nPrepared for the class CS 20SI: ""TensorFlow for Deep Learning Research""\ncs20si.stanford.edu\n""""""\nimport os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\n\nimport tensorflow as tf \n\n######################################## \n## NORMAL LOADING   \t\t\t      ##\n## print out a graph with 1 Add node  ## \n########################################\n\nx = tf.Variable(10, name=\'x\')\ny = tf.Variable(20, name=\'y\')\nz = tf.add(x, y)\n\nwith tf.Session() as sess:\n\tsess.run(tf.global_variables_initializer())\n\twriter = tf.summary.FileWriter(\'./graphs/l2\', sess.graph)\n\tfor _ in range(10):\n\t\tsess.run(z)\n\tprint(tf.get_default_graph().as_graph_def())\n\twriter.close()\n\n######################################## \n## LAZY LOADING   \t\t\t\t\t  ##\n## print out a graph with 10 Add nodes## \n########################################\n\nx = tf.Variable(10, name=\'x\')\ny = tf.Variable(20, name=\'y\')\n\nwith tf.Session() as sess:\n\tsess.run(tf.global_variables_initializer())\n\twriter = tf.summary.FileWriter(\'./graphs/l2\', sess.graph)\n\tfor _ in range(10):\n\t\tsess.run(tf.add(x, y))\n\tprint(tf.get_default_graph().as_graph_def()) \n\twriter.close()'"
2017/examples/02_simple_tf.py,34,"b'"""""" Some simple TensorFlow\'s ops\nAuthor: Chip Huyen\nPrepared for the class CS 20SI: ""TensorFlow for Deep Learning Research""\ncs20si.stanford.edu\n""""""\nimport os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\n\nimport numpy as np\nimport tensorflow as tf\n\n\na = tf.constant(2)\nb = tf.constant(3)\nx = tf.add(a, b)\nwith tf.Session() as sess:\n\twriter = tf.summary.FileWriter(\'./graphs\', sess.graph) \n\tprint(sess.run(x))\nwriter.close() # close the writer when you\xe2\x80\x99re done using it\n\n\na = tf.constant([2, 2], name=\'a\')\nb = tf.constant([[0, 1], [2, 3]], name=\'b\')\nx = tf.multiply(a, b, name=\'dot_product\')\nwith tf.Session() as sess:\n\tprint(sess.run(x))\n# >> [[0 2]\n#\t [4 6]]\n\ntf.zeros(shape, dtype=tf.float32, name=None)\n#creates a tensor of shape and all elements will be zeros (when ran in session)\n\nx = tf.zeros([2, 3], tf.int32) \ny = tf.zeros_like(x, optimize=True)\nprint(y)\nprint(tf.get_default_graph().as_graph_def())\nwith tf.Session() as sess:\n\ty = sess.run(y)\n\n\nwith tf.Session() as sess:\n\tprint(sess.run(tf.linspace(10.0, 13.0, 4)))\n\tprint(sess.run(tf.range(5)))\n\tfor i in np.arange(5):\n\t\tprint(i)\n\nsamples = tf.multinomial(tf.constant([[1., 3., 1]]), 5)\n\nwith tf.Session() as sess:\n\tfor _ in range(10):\n\t\tprint(sess.run(samples))\n\nt_0 = 19 \nx = tf.zeros_like(t_0) # ==> 0\ny = tf.ones_like(t_0) # ==> 1\n\nwith tf.Session() as sess:\n\tprint(sess.run([x, y]))\n\nt_1 = [\'apple\', \'peach\', \'banana\']\nx = tf.zeros_like(t_1) # ==> [\'\' \'\' \'\']\ny = tf.ones_like(t_1) # ==> TypeError: Expected string, got 1 of type \'int\' instead.\n\nt_2 = [[True, False, False],\n       [False, False, True],\n       [False, True, False]] \nx = tf.zeros_like(t_2) # ==> 2x2 tensor, all elements are False\ny = tf.ones_like(t_2) # ==> 2x2 tensor, all elements are True\nwith tf.Session() as sess:\n\tprint(sess.run([x, y]))\n\nwith tf.variable_scope(\'meh\') as scope:\n\ta = tf.get_variable(\'a\', [10])\n\tb = tf.get_variable(\'b\', [100])\n\nwriter = tf.summary.FileWriter(\'test\', tf.get_default_graph())\n\n\nx = tf.Variable(2.0)\ny = 2.0 * (x ** 3)\nz = 3.0 + y ** 2\ngrad_z = tf.gradients(z, [x, y])\nwith tf.Session() as sess:\n\tsess.run(x.initializer)\n\tprint(sess.run(grad_z))\n'"
2017/examples/02_variables.py,9,"b'""""""\nExample to demonstrate the ops of tf.Variables()\n""""""\nimport os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\n\nimport tensorflow as tf\n\n# Example 1: how to run assign op\nW = tf.Variable(10)\nassign_op = W.assign(100)\n\nwith tf.Session() as sess:\n\tsess.run(W.initializer)\n\tprint(W.eval()) # >> 10\n\tprint(sess.run(assign_op)) # >> 100\n\n# Example 2: tricky example\n# create a variable whose original value is 2\nmy_var = tf.Variable(2, name=""my_var"") \n\n# assign 2 * my_var to my_var and run the op my_var_times_two\nmy_var_times_two = my_var.assign(2 * my_var)\n\nwith tf.Session() as sess:\n\tsess.run(tf.global_variables_initializer())\n\tprint(sess.run(my_var_times_two)) # >> 4\n\tprint(sess.run(my_var_times_two)) # >> 8\n\tprint(sess.run(my_var_times_two)) # >> 16\n\n# Example 3: each session maintains its own copy of variables\nW = tf.Variable(10)\nsess1 = tf.Session()\nsess2 = tf.Session()\n\n# You have to initialize W at each session\nsess1.run(W.initializer)\nsess2.run(W.initializer)\n\nprint(sess1.run(W.assign_add(10))) # >> 20\nprint(sess2.run(W.assign_sub(2))) # >> 8\n\nprint(sess1.run(W.assign_add(100))) # >> 120\nprint(sess2.run(W.assign_sub(50))) # >> -42\n\nsess1.close()\nsess2.close()'"
2017/examples/03_linear_regression_sol.py,9,"b'"""""" Simple linear regression example in TensorFlow\nThis program tries to predict the number of thefts from \nthe number of fire in the city of Chicago\nAuthor: Chip Huyen\nPrepared for the class CS 20SI: ""TensorFlow for Deep Learning Research""\ncs20si.stanford.edu\n""""""\nimport os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport xlrd\n\nimport utils\n\nDATA_FILE = \'data/fire_theft.xls\'\n\n# Step 1: read in data from the .xls file\nbook = xlrd.open_workbook(DATA_FILE, encoding_override=""utf-8"")\nsheet = book.sheet_by_index(0)\ndata = np.asarray([sheet.row_values(i) for i in range(1, sheet.nrows)])\nn_samples = sheet.nrows - 1\n\n# Step 2: create placeholders for input X (number of fire) and label Y (number of theft)\nX = tf.placeholder(tf.float32, name=\'X\')\nY = tf.placeholder(tf.float32, name=\'Y\')\n\n# Step 3: create weight and bias, initialized to 0\nw = tf.Variable(0.0, name=\'weights\')\nb = tf.Variable(0.0, name=\'bias\')\n\n# Step 4: build model to predict Y\nY_predicted = X * w + b \n\n# Step 5: use the square error as the loss function\nloss = tf.square(Y - Y_predicted, name=\'loss\')\n# loss = utils.huber_loss(Y, Y_predicted)\n\n# Step 6: using gradient descent with learning rate of 0.01 to minimize loss\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(loss)\n\nwith tf.Session() as sess:\n\t# Step 7: initialize the necessary variables, in this case, w and b\n\tsess.run(tf.global_variables_initializer()) \n\t\n\twriter = tf.summary.FileWriter(\'./graphs/linear_reg\', sess.graph)\n\t\n\t# Step 8: train the model\n\tfor i in range(50): # train the model 100 epochs\n\t\ttotal_loss = 0\n\t\tfor x, y in data:\n\t\t\t# Session runs train_op and fetch values of loss\n\t\t\t_, l = sess.run([optimizer, loss], feed_dict={X: x, Y:y}) \n\t\t\ttotal_loss += l\n\t\tprint(\'Epoch {0}: {1}\'.format(i, total_loss/n_samples))\n\n\t# close the writer when you\'re done using it\n\twriter.close() \n\t\n\t# Step 9: output the values of w and b\n\tw, b = sess.run([w, b]) \n\n# plot the results\nX, Y = data.T[0], data.T[1]\nplt.plot(X, Y, \'bo\', label=\'Real data\')\nplt.plot(X, X * w + b, \'r\', label=\'Predicted data\')\nplt.legend()\nplt.show()'"
2017/examples/03_linear_regression_starter.py,1,"b'"""""" Simple linear regression example in TensorFlow\nThis program tries to predict the number of thefts from \nthe number of fire in the city of Chicago\nAuthor: Chip Huyen\nPrepared for the class CS 20SI: ""TensorFlow for Deep Learning Research""\ncs20si.stanford.edu\n""""""\nimport os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport xlrd\n\nimport utils\n\nDATA_FILE = \'data/fire_theft.xls\'\n\n# Phase 1: Assemble the graph\n# Step 1: read in data from the .xls file\nbook = xlrd.open_workbook(DATA_FILE, encoding_override=\'utf-8\')\nsheet = book.sheet_by_index(0)\ndata = np.asarray([sheet.row_values(i) for i in range(1, sheet.nrows)])\nn_samples = sheet.nrows - 1\n\n# Step 2: create placeholders for input X (number of fire) and label Y (number of theft)\n# Both have the type float32\n\n\n# Step 3: create weight and bias, initialized to 0\n# name your variables w and b\n\n\n# Step 4: predict Y (number of theft) from the number of fire\n# name your variable Y_predicted\n\n\n# Step 5: use the square error as the loss function\n# name your variable loss\n\n\n# Step 6: using gradient descent with learning rate of 0.01 to minimize loss\n \n# Phase 2: Train our model\nwith tf.Session() as sess:\n\t# Step 7: initialize the necessary variables, in this case, w and b\n\t# TO - DO\t\n\n\n\t# Step 8: train the model\n\tfor i in range(50): # run 100 epochs\n\t\ttotal_loss = 0\n\t\tfor x, y in data:\n\t\t\t# Session runs optimizer to minimize loss and fetch the value of loss. Name the received value as l\n\t\t\t# TO DO: write sess.run()\n\n\t\t\ttotal_loss += l\n\t\tprint(""Epoch {0}: {1}"".format(i, total_loss/n_samples))\n\t\n# plot the results\n# X, Y = data.T[0], data.T[1]\n# plt.plot(X, Y, \'bo\', label=\'Real data\')\n# plt.plot(X, X * w + b, \'r\', label=\'Predicted data\')\n# plt.legend()\n# plt.show()'"
2017/examples/03_logistic_regression_mnist_sol.py,15,"b'"""""" Simple logistic regression model to solve OCR task \nwith MNIST in TensorFlow\nMNIST dataset: yann.lecun.com/exdb/mnist/\nAuthor: Chip Huyen\nPrepared for the class CS 20SI: ""TensorFlow for Deep Learning Research""\ncs20si.stanford.edu\n""""""\nimport os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\n\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.examples.tutorials.mnist import input_data\nimport time\n\n# Define paramaters for the model\nlearning_rate = 0.01\nbatch_size = 128\nn_epochs = 30\n\n# Step 1: Read in data\n# using TF Learn\'s built in function to load MNIST data to the folder data/mnist\nmnist = input_data.read_data_sets(\'/data/mnist\', one_hot=True) \n\n# Step 2: create placeholders for features and labels\n# each image in the MNIST data is of shape 28*28 = 784\n# therefore, each image is represented with a 1x784 tensor\n# there are 10 classes for each image, corresponding to digits 0 - 9. \n# each lable is one hot vector.\nX = tf.placeholder(tf.float32, [batch_size, 784], name=\'X_placeholder\') \nY = tf.placeholder(tf.int32, [batch_size, 10], name=\'Y_placeholder\')\n\n# Step 3: create weights and bias\n# w is initialized to random variables with mean of 0, stddev of 0.01\n# b is initialized to 0\n# shape of w depends on the dimension of X and Y so that Y = tf.matmul(X, w)\n# shape of b depends on Y\nw = tf.Variable(tf.random_normal(shape=[784, 10], stddev=0.01), name=\'weights\')\nb = tf.Variable(tf.zeros([1, 10]), name=""bias"")\n\n# Step 4: build model\n# the model that returns the logits.\n# this logits will be later passed through softmax layer\nlogits = tf.matmul(X, w) + b \n\n# Step 5: define loss function\n# use cross entropy of softmax of logits as the loss function\nentropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y, name=\'loss\')\nloss = tf.reduce_mean(entropy) # computes the mean over all the examples in the batch\n\n# Step 6: define training op\n# using gradient descent with learning rate of 0.01 to minimize loss\noptimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n\nwith tf.Session() as sess:\n\t# to visualize using TensorBoard\n\twriter = tf.summary.FileWriter(\'./graphs/logistic_reg\', sess.graph)\n\n\tstart_time = time.time()\n\tsess.run(tf.global_variables_initializer())\t\n\tn_batches = int(mnist.train.num_examples/batch_size)\n\tfor i in range(n_epochs): # train the model n_epochs times\n\t\ttotal_loss = 0\n\n\t\tfor _ in range(n_batches):\n\t\t\tX_batch, Y_batch = mnist.train.next_batch(batch_size)\n\t\t\t_, loss_batch = sess.run([optimizer, loss], feed_dict={X: X_batch, Y:Y_batch}) \n\t\t\ttotal_loss += loss_batch\n\t\tprint(\'Average loss epoch {0}: {1}\'.format(i, total_loss/n_batches))\n\n\tprint(\'Total time: {0} seconds\'.format(time.time() - start_time))\n\n\tprint(\'Optimization Finished!\') # should be around 0.35 after 25 epochs\n\n\t# test the model\n\t\n\tpreds = tf.nn.softmax(logits)\n\tcorrect_preds = tf.equal(tf.argmax(preds, 1), tf.argmax(Y, 1))\n\taccuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32)) # need numpy.count_nonzero(boolarr) :(\n\t\n\tn_batches = int(mnist.test.num_examples/batch_size)\n\ttotal_correct_preds = 0\n\t\n\tfor i in range(n_batches):\n\t\tX_batch, Y_batch = mnist.test.next_batch(batch_size)\n\t\taccuracy_batch = sess.run([accuracy], feed_dict={X: X_batch, Y:Y_batch}) \n\t\ttotal_correct_preds += accuracy_batch\t\n\t\n\tprint(\'Accuracy {0}\'.format(total_correct_preds/mnist.test.num_examples))\n\n\twriter.close()\n'"
2017/examples/03_logistic_regression_mnist_starter.py,7,"b'"""""" Starter code for logistic regression model to solve OCR task \nwith MNIST in TensorFlow\nMNIST dataset: yann.lecun.com/exdb/mnist/\nAuthor: Chip Huyen\nPrepared for the class CS 20SI: ""TensorFlow for Deep Learning Research""\ncs20si.stanford.edu\n""""""\nimport os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\n\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.examples.tutorials.mnist import input_data\nimport time\n\n# Define paramaters for the model\nlearning_rate = 0.01\nbatch_size = 128\nn_epochs = 10\n\n# Step 1: Read in data\n# using TF Learn\'s built in function to load MNIST data to the folder data/mnist\nmnist = input_data.read_data_sets(\'/data/mnist\', one_hot=True) \n\n# Step 2: create placeholders for features and labels\n# each image in the MNIST data is of shape 28*28 = 784\n# therefore, each image is represented with a 1x784 tensor\n# there are 10 classes for each image, corresponding to digits 0 - 9. \n# Features are of the type float, and labels are of the type int\n\n\n# Step 3: create weights and bias\n# weights and biases are initialized to 0\n# shape of w depends on the dimension of X and Y so that Y = X * w + b\n# shape of b depends on Y\n\n\n# Step 4: build model\n# the model that returns the logits.\n# this logits will be later passed through softmax layer\n# to get the probability distribution of possible label of the image\n# DO NOT DO SOFTMAX HERE\n\n\n# Step 5: define loss function\n# use cross entropy loss of the real labels with the softmax of logits\n# use the method:\n# tf.nn.softmax_cross_entropy_with_logits(logits, Y)\n# then use tf.reduce_mean to get the mean loss of the batch\n\n\n# Step 6: define training op\n# using gradient descent to minimize loss\n\n\nwith tf.Session() as sess:\n\tstart_time = time.time()\n\tsess.run(tf.global_variables_initializer())\t\n\tn_batches = int(mnist.train.num_examples/batch_size)\n\tfor i in range(n_epochs): # train the model n_epochs times\n\t\ttotal_loss = 0\n\n\t\tfor _ in range(n_batches):\n\t\t\tX_batch, Y_batch = mnist.train.next_batch(batch_size)\n\t\t\t# TO-DO: run optimizer + fetch loss_batch\n\t\t\t# \n\t\t\t# \n\t\t\ttotal_loss += loss_batch\n\t\tprint(\'Average loss epoch {0}: {1}\'.format(i, total_loss/n_batches))\n\n\tprint(\'Total time: {0} seconds\'.format(time.time() - start_time))\n\n\tprint(\'Optimization Finished!\') # should be around 0.35 after 25 epochs\n\n\t# test the model\n\tpreds = tf.nn.softmax(logits)\n\tcorrect_preds = tf.equal(tf.argmax(preds, 1), tf.argmax(Y, 1))\n\taccuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32)) # need numpy.count_nonzero(boolarr) :(\n\t\n\tn_batches = int(mnist.test.num_examples/batch_size)\n\ttotal_correct_preds = 0\n\t\n\tfor i in range(n_batches):\n\t\tX_batch, Y_batch = mnist.test.next_batch(batch_size)\n\t\taccuracy_batch = sess.run([accuracy], feed_dict={X: X_batch, Y:Y_batch}) \n\t\ttotal_correct_preds += accuracy_batch\t\n\t\n\tprint(\'Accuracy {0}\'.format(total_correct_preds/mnist.test.num_examples))\n'"
2017/examples/04_word2vec_no_frills.py,14,"b'"""""" The no frills implementation of word2vec skip-gram model using NCE loss.\nAuthor: Chip Huyen\nPrepared for the class CS 20SI: ""TensorFlow for Deep Learning Research""\ncs20si.stanford.edu\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\n\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.contrib.tensorboard.plugins import projector\n\nfrom process_data import process_data\n\nVOCAB_SIZE = 50000\nBATCH_SIZE = 128\nEMBED_SIZE = 128 # dimension of the word embedding vectors\nSKIP_WINDOW = 1 # the context window\nNUM_SAMPLED = 64    # Number of negative examples to sample.\nLEARNING_RATE = 1.0\nNUM_TRAIN_STEPS = 10000\nSKIP_STEP = 2000 # how many steps to skip before reporting the loss\n\ndef word2vec(batch_gen):\n    """""" Build the graph for word2vec model and train it """"""\n    # Step 1: define the placeholders for input and output\n    with tf.name_scope(\'data\'):\n        center_words = tf.placeholder(tf.int32, shape=[BATCH_SIZE], name=\'center_words\')\n        target_words = tf.placeholder(tf.int32, shape=[BATCH_SIZE, 1], name=\'target_words\')\n\n    # Assemble this part of the graph on the CPU. You can change it to GPU if you have GPU\n    # Step 2: define weights. In word2vec, it\'s actually the weights that we care about\n\n    with tf.name_scope(\'embedding_matrix\'):\n        embed_matrix = tf.Variable(tf.random_uniform([VOCAB_SIZE, EMBED_SIZE], -1.0, 1.0), \n                            name=\'embed_matrix\')\n\n    # Step 3: define the inference\n    with tf.name_scope(\'loss\'):\n        embed = tf.nn.embedding_lookup(embed_matrix, center_words, name=\'embed\')\n\n        # Step 4: construct variables for NCE loss\n        nce_weight = tf.Variable(tf.truncated_normal([VOCAB_SIZE, EMBED_SIZE],\n                                                    stddev=1.0 / (EMBED_SIZE ** 0.5)), \n                                                    name=\'nce_weight\')\n        nce_bias = tf.Variable(tf.zeros([VOCAB_SIZE]), name=\'nce_bias\')\n\n        # define loss function to be NCE loss function\n        loss = tf.reduce_mean(tf.nn.nce_loss(weights=nce_weight, \n                                            biases=nce_bias, \n                                            labels=target_words, \n                                            inputs=embed, \n                                            num_sampled=NUM_SAMPLED, \n                                            num_classes=VOCAB_SIZE), name=\'loss\')\n\n    # Step 5: define optimizer\n    optimizer = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(loss)\n    \n    with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n\n        total_loss = 0.0 # we use this to calculate late average loss in the last SKIP_STEP steps\n        writer = tf.summary.FileWriter(\'./graphs/no_frills/\', sess.graph)\n        for index in range(NUM_TRAIN_STEPS):\n            centers, targets = next(batch_gen)\n            loss_batch, _ = sess.run([loss, optimizer], \n                                    feed_dict={center_words: centers, target_words: targets})\n            total_loss += loss_batch\n            if (index + 1) % SKIP_STEP == 0:\n                print(\'Average loss at step {}: {:5.1f}\'.format(index, total_loss / SKIP_STEP))\n                total_loss = 0.0\n        writer.close()\n\ndef main():\n    batch_gen = process_data(VOCAB_SIZE, BATCH_SIZE, SKIP_WINDOW)\n    word2vec(batch_gen)\n\nif __name__ == \'__main__\':\n    main()'"
2017/examples/04_word2vec_starter.py,6,"b'"""""" The mo frills implementation of word2vec skip-gram model using NCE loss. \nAuthor: Chip Huyen\nPrepared for the class CS 20SI: ""TensorFlow for Deep Learning Research""\ncs20si.stanford.edu\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\n\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.contrib.tensorboard.plugins import projector\n\nfrom process_data import process_data\n\nVOCAB_SIZE = 50000\nBATCH_SIZE = 128\nEMBED_SIZE = 128 # dimension of the word embedding vectors\nSKIP_WINDOW = 1 # the context window\nNUM_SAMPLED = 64    # Number of negative examples to sample.\nLEARNING_RATE = 1.0\nNUM_TRAIN_STEPS = 20000\nSKIP_STEP = 2000 # how many steps to skip before reporting the loss\n\ndef word2vec(batch_gen):\n    """""" Build the graph for word2vec model and train it """"""\n    # Step 1: define the placeholders for input and output\n    # center_words have to be int to work on embedding lookup\n\n    # TO DO\n\n\n    # Step 2: define weights. In word2vec, it\'s actually the weights that we care about\n    # vocab size x embed size\n    # initialized to random uniform -1 to 1\n\n    # TOO DO\n\n\n    # Step 3: define the inference\n    # get the embed of input words using tf.nn.embedding_lookup\n    # embed = tf.nn.embedding_lookup(embed_matrix, center_words, name=\'embed\')\n\n    # TO DO\n\n\n        # Step 4: construct variables for NCE loss\n        # tf.nn.nce_loss(weights, biases, labels, inputs, num_sampled, num_classes, ...)\n        # nce_weight (vocab size x embed size), intialized to truncated_normal stddev=1.0 / (EMBED_SIZE ** 0.5)\n        # bias: vocab size, initialized to 0\n\n        # TO DO\n\n\n        # define loss function to be NCE loss function\n        # tf.nn.nce_loss(weights, biases, labels, inputs, num_sampled, num_classes, ...)\n        # need to get the mean accross the batch\n        # note: you should use embedding of center words for inputs, not center words themselves\n\n        # TO DO\n\n        \n    # Step 5: define optimizer\n    \n    # TO DO\n\n\n\n    with tf.Session() as sess:\n        # TO DO: initialize variables\n\n\n        total_loss = 0.0 # we use this to calculate the average loss in the last SKIP_STEP steps\n        writer = tf.summary.FileWriter(\'./graphs/no_frills/\', sess.graph)\n        for index in range(NUM_TRAIN_STEPS):\n            centers, targets = next(batch_gen)\n            # TO DO: create feed_dict, run optimizer, fetch loss_batch\n\n            total_loss += loss_batch\n            if (index + 1) % SKIP_STEP == 0:\n                print(\'Average loss at step {}: {:5.1f}\'.format(index, total_loss / SKIP_STEP))\n                total_loss = 0.0\n        writer.close()\n\ndef main():\n    batch_gen = process_data(VOCAB_SIZE, BATCH_SIZE, SKIP_WINDOW)\n    word2vec(batch_gen)\n\nif __name__ == \'__main__\':\n    main()\n'"
2017/examples/04_word2vec_visualize.py,27,"b'"""""" word2vec with NCE loss and code to visualize the embeddings on TensorBoard\nAuthor: Chip Huyen\nPrepared for the class CS 20SI: ""TensorFlow for Deep Learning Research""\ncs20si.stanford.edu\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\n\nimport numpy as np\nfrom tensorflow.contrib.tensorboard.plugins import projector\nimport tensorflow as tf\n\nfrom process_data import process_data\nimport utils\n\nVOCAB_SIZE = 50000\nBATCH_SIZE = 128\nEMBED_SIZE = 128 # dimension of the word embedding vectors\nSKIP_WINDOW = 1 # the context window\nNUM_SAMPLED = 64    # Number of negative examples to sample.\nLEARNING_RATE = 1.0\nNUM_TRAIN_STEPS = 100000\nWEIGHTS_FLD = \'processed/\'\nSKIP_STEP = 2000\n\nclass SkipGramModel:\n    """""" Build the graph for word2vec model """"""\n    def __init__(self, vocab_size, embed_size, batch_size, num_sampled, learning_rate):\n        self.vocab_size = vocab_size\n        self.embed_size = embed_size\n        self.batch_size = batch_size\n        self.num_sampled = num_sampled\n        self.lr = learning_rate\n        self.global_step = tf.Variable(0, dtype=tf.int32, trainable=False, name=\'global_step\')\n\n    def _create_placeholders(self):\n        """""" Step 1: define the placeholders for input and output """"""\n        with tf.name_scope(""data""):\n            self.center_words = tf.placeholder(tf.int32, shape=[self.batch_size], name=\'center_words\')\n            self.target_words = tf.placeholder(tf.int32, shape=[self.batch_size, 1], name=\'target_words\')\n\n    def _create_embedding(self):\n        """""" Step 2: define weights. In word2vec, it\'s actually the weights that we care about """"""\n        # Assemble this part of the graph on the CPU. You can change it to GPU if you have GPU\n        with tf.device(\'/cpu:0\'):\n            with tf.name_scope(""embed""):\n                self.embed_matrix = tf.Variable(tf.random_uniform([self.vocab_size, \n                                                                    self.embed_size], -1.0, 1.0), \n                                                                    name=\'embed_matrix\')\n\n    def _create_loss(self):\n        """""" Step 3 + 4: define the model + the loss function """"""\n        with tf.device(\'/cpu:0\'):\n            with tf.name_scope(""loss""):\n                # Step 3: define the inference\n                embed = tf.nn.embedding_lookup(self.embed_matrix, self.center_words, name=\'embed\')\n\n                # Step 4: define loss function\n                # construct variables for NCE loss\n                nce_weight = tf.Variable(tf.truncated_normal([self.vocab_size, self.embed_size],\n                                                            stddev=1.0 / (self.embed_size ** 0.5)), \n                                                            name=\'nce_weight\')\n                nce_bias = tf.Variable(tf.zeros([VOCAB_SIZE]), name=\'nce_bias\')\n\n                # define loss function to be NCE loss function\n                self.loss = tf.reduce_mean(tf.nn.nce_loss(weights=nce_weight, \n                                                    biases=nce_bias, \n                                                    labels=self.target_words, \n                                                    inputs=embed, \n                                                    num_sampled=self.num_sampled, \n                                                    num_classes=self.vocab_size), name=\'loss\')\n    def _create_optimizer(self):\n        """""" Step 5: define optimizer """"""\n        with tf.device(\'/cpu:0\'):\n            self.optimizer = tf.train.GradientDescentOptimizer(self.lr).minimize(self.loss, \n                                                              global_step=self.global_step)\n\n    def _create_summaries(self):\n        with tf.name_scope(""summaries""):\n            tf.summary.scalar(""loss"", self.loss)\n            tf.summary.histogram(""histogram loss"", self.loss)\n            # because you have several summaries, we should merge them all\n            # into one op to make it easier to manage\n            self.summary_op = tf.summary.merge_all()\n\n    def build_graph(self):\n        """""" Build the graph for our model """"""\n        self._create_placeholders()\n        self._create_embedding()\n        self._create_loss()\n        self._create_optimizer()\n        self._create_summaries()\n\ndef train_model(model, batch_gen, num_train_steps, weights_fld):\n    saver = tf.train.Saver() # defaults to saving all variables - in this case embed_matrix, nce_weight, nce_bias\n\n    initial_step = 0\n    utils.make_dir(\'checkpoints\')\n    with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n        ckpt = tf.train.get_checkpoint_state(os.path.dirname(\'checkpoints/checkpoint\'))\n        # if that checkpoint exists, restore from checkpoint\n        if ckpt and ckpt.model_checkpoint_path:\n            saver.restore(sess, ckpt.model_checkpoint_path)\n\n        total_loss = 0.0 # we use this to calculate late average loss in the last SKIP_STEP steps\n        writer = tf.summary.FileWriter(\'improved_graph/lr\' + str(LEARNING_RATE), sess.graph)\n        initial_step = model.global_step.eval()\n        for index in range(initial_step, initial_step + num_train_steps):\n            centers, targets = next(batch_gen)\n            feed_dict={model.center_words: centers, model.target_words: targets}\n            loss_batch, _, summary = sess.run([model.loss, model.optimizer, model.summary_op], \n                                              feed_dict=feed_dict)\n            writer.add_summary(summary, global_step=index)\n            total_loss += loss_batch\n            if (index + 1) % SKIP_STEP == 0:\n                print(\'Average loss at step {}: {:5.1f}\'.format(index, total_loss / SKIP_STEP))\n                total_loss = 0.0\n                saver.save(sess, \'checkpoints/skip-gram\', index)\n        \n        ####################\n        # code to visualize the embeddings. uncomment the below to visualize embeddings\n        # run ""\'tensorboard --logdir=\'processed\'"" to see the embeddings\n        # final_embed_matrix = sess.run(model.embed_matrix)\n        \n        # # it has to variable. constants don\'t work here. you can\'t reuse model.embed_matrix\n        # embedding_var = tf.Variable(final_embed_matrix[:1000], name=\'embedding\')\n        # sess.run(embedding_var.initializer)\n\n        # config = projector.ProjectorConfig()\n        # summary_writer = tf.summary.FileWriter(\'processed\')\n\n        # # add embedding to the config file\n        # embedding = config.embeddings.add()\n        # embedding.tensor_name = embedding_var.name\n        \n        # # link this tensor to its metadata file, in this case the first 500 words of vocab\n        # embedding.metadata_path = \'processed/vocab_1000.tsv\'\n\n        # # saves a configuration file that TensorBoard will read during startup.\n        # projector.visualize_embeddings(summary_writer, config)\n        # saver_embed = tf.train.Saver([embedding_var])\n        # saver_embed.save(sess, \'processed/model3.ckpt\', 1)\n\ndef main():\n    model = SkipGramModel(VOCAB_SIZE, EMBED_SIZE, BATCH_SIZE, NUM_SAMPLED, LEARNING_RATE)\n    model.build_graph()\n    batch_gen = process_data(VOCAB_SIZE, BATCH_SIZE, SKIP_WINDOW)\n    train_model(model, batch_gen, NUM_TRAIN_STEPS, WEIGHTS_FLD)\n\nif __name__ == \'__main__\':\n    main()'"
2017/examples/05_csv_reader.py,9,"b'"""""" Some people tried to use TextLineReader for the assignment 1\nbut seem to have problems getting it work, so here is a short \nscript demonstrating the use of CSV reader on the heart dataset.\nNote that the heart dataset is originally in txt so I first\nconverted it to csv to take advantage of the already laid out columns.\n\nYou can download heart.csv in the data folder.\nAuthor: Chip Huyen\nPrepared for the class CS 20SI: ""TensorFlow for Deep Learning Research""\ncs20si.stanford.edu\n""""""\nimport os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\n\nimport sys\nsys.path.append(\'..\')\n\nimport tensorflow as tf\n\nDATA_PATH = \'data/heart.csv\'\nBATCH_SIZE = 2\nN_FEATURES = 9\n\ndef batch_generator(filenames):\n    """""" filenames is the list of files you want to read from. \n    In this case, it contains only heart.csv\n    """"""\n    filename_queue = tf.train.string_input_producer(filenames)\n    reader = tf.TextLineReader(skip_header_lines=1) # skip the first line in the file\n    _, value = reader.read(filename_queue)\n\n    # record_defaults are the default values in case some of our columns are empty\n    # This is also to tell tensorflow the format of our data (the type of the decode result)\n    # for this dataset, out of 9 feature columns, \n    # 8 of them are floats (some are integers, but to make our features homogenous, \n    # we consider them floats), and 1 is string (at position 5)\n    # the last column corresponds to the lable is an integer\n\n    record_defaults = [[1.0] for _ in range(N_FEATURES)]\n    record_defaults[4] = [\'\']\n    record_defaults.append([1])\n\n    # read in the 10 rows of data\n    content = tf.decode_csv(value, record_defaults=record_defaults) \n\n    # convert the 5th column (present/absent) to the binary value 0 and 1\n    content[4] = tf.cond(tf.equal(content[4], tf.constant(\'Present\')), lambda: tf.constant(1.0), lambda: tf.constant(0.0))\n\n    # pack all 9 features into a tensor\n    features = tf.stack(content[:N_FEATURES])\n\n    # assign the last column to label\n    label = content[-1]\n\n    # minimum number elements in the queue after a dequeue, used to ensure \n    # that the samples are sufficiently mixed\n    # I think 10 times the BATCH_SIZE is sufficient\n    min_after_dequeue = 10 * BATCH_SIZE\n\n    # the maximum number of elements in the queue\n    capacity = 20 * BATCH_SIZE\n\n    # shuffle the data to generate BATCH_SIZE sample pairs\n    data_batch, label_batch = tf.train.shuffle_batch([features, label], batch_size=BATCH_SIZE, \n                                        capacity=capacity, min_after_dequeue=min_after_dequeue)\n\n    return data_batch, label_batch\n\ndef generate_batches(data_batch, label_batch):\n    with tf.Session() as sess:\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(coord=coord)\n        for _ in range(10): # generate 10 batches\n            features, labels = sess.run([data_batch, label_batch])\n            print(features)\n        coord.request_stop()\n        coord.join(threads)\n\ndef main():\n    data_batch, label_batch = batch_generator([DATA_PATH])\n    generate_batches(data_batch, label_batch)\n\nif __name__ == \'__main__\':\n    main()\n'"
2017/examples/05_randomization.py,12,"b'"""""" Examples to demonstrate ops level randomization\nAuthor: Chip Huyen\nPrepared for the class CS 20SI: ""TensorFlow for Deep Learning Research""\ncs20si.stanford.edu\n""""""\nimport os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\n\nimport tensorflow as tf\n\n# Example 1: session is the thing that keeps track of random state\nc = tf.random_uniform([], -10, 10, seed=2)\n\nwith tf.Session() as sess:\n    print(sess.run(c)) # >> 3.57493\n    print(sess.run(c)) # >> -5.97319\n\n# Example 2: each new session will start the random state all over again.\nc = tf.random_uniform([], -10, 10, seed=2)\n\nwith tf.Session() as sess:\n    print(sess.run(c)) # >> 3.57493\n\nwith tf.Session() as sess:\n    print(sess.run(c)) # >> 3.57493\n\n# Example 3: with operation level random seed, each op keeps its own seed.\nc = tf.random_uniform([], -10, 10, seed=2)\nd = tf.random_uniform([], -10, 10, seed=2)\n\nwith tf.Session() as sess:\n    print(sess.run(c)) # >> 3.57493\n    print(sess.run(d)) # >> 3.57493\n\n# Example 4: graph level random seed\ntf.set_random_seed(2)\nc = tf.random_uniform([], -10, 10)\nd = tf.random_uniform([], -10, 10)\n\nwith tf.Session() as sess:\n    print(sess.run(c)) # >> 9.12393\n    print(sess.run(d)) # >> -4.53404\n    '"
2017/examples/07_basic_filters.py,14,"b'""""""\nSimple examples of convolution to do some basic filters\nAlso demonstrates the use of TensorFlow data readers.\n\nWe will use some popular filters for our image.\nIt seems to be working with grayscale images, but not with rgb images.\nIt\'s probably because I didn\'t choose the right kernels for rgb images.\n\nkernels for rgb images have dimensions 3 x 3 x 3 x 3\nkernels for grayscale images have dimensions 3 x 3 x 1 x 1\n\nNote:\nWhen you call tf.train.string_input_producer,\na tf.train.QueueRunner is added to the graph, which must be run using\ne.g. tf.train.start_queue_runners() else your session will run into deadlock\nand your program will crash.\n\nAnd to run QueueRunner, you need a coordinator to close to your queue for you.\nWithout coordinator, your threads will keep on running outside session and you will have the error:\nERROR:tensorflow:Exception in QueueRunner: Attempted to use a closed Session.\n\nAuthor: Chip Huyen\nPrepared for the class CS 20SI: ""TensorFlow for Deep Learning Research""\ncs20si.stanford.edu\n\n""""""\nimport os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\n\nimport sys\nsys.path.append(\'..\')\n\nfrom matplotlib import gridspec as gridspec\nfrom matplotlib import pyplot as plt\nimport tensorflow as tf\n\nimport kernels\n\nFILENAME = \'data/friday.jpg\'\n\ndef read_one_image(filename):\n    """""" This is just to demonstrate how to open an image in TensorFlow,\n    but it\'s actually a lot easier to use Pillow \n    """"""\n    filename_queue = tf.train.string_input_producer([filename])\n    image_reader = tf.WholeFileReader()\n    _, image_file = image_reader.read(filename_queue)\n    image = tf.image.decode_jpeg(image_file, channels=3)\n    image = tf.cast(image, tf.float32) / 256.0 # cast to float to make conv2d work\n    return image\n\ndef convolve(image, kernels, rgb=True, strides=[1, 3, 3, 1], padding=\'SAME\'):\n    images = [image[0]]\n    for i, kernel in enumerate(kernels):\n        filtered_image = tf.nn.conv2d(image, kernel, strides=strides, padding=padding)[0]\n        if i == 2:\n            filtered_image = tf.minimum(tf.nn.relu(filtered_image), 255)\n        images.append(filtered_image)\n    return images\n\ndef get_real_images(images):\n    with tf.Session() as sess:\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(coord=coord)\n        images = sess.run(images)\n        coord.request_stop()\n        coord.join(threads)\n    return images\n\ndef show_images(images, rgb=True):\n    gs = gridspec.GridSpec(1, len(images))\n    for i, image in enumerate(images):\n        plt.subplot(gs[0, i])\n        if rgb:\n            plt.imshow(image)\n        else: \n            image = image.reshape(image.shape[0], image.shape[1])\n            plt.imshow(image, cmap=\'gray\')\n        plt.axis(\'off\')\n    plt.show()\n\ndef main():\n    rgb = False\n    if rgb:\n        kernels_list = [kernels.BLUR_FILTER_RGB, kernels.SHARPEN_FILTER_RGB, kernels.EDGE_FILTER_RGB, \n                    kernels.TOP_SOBEL_RGB, kernels.EMBOSS_FILTER_RGB]\n    else:\n        kernels_list = [kernels.BLUR_FILTER, kernels.SHARPEN_FILTER, kernels.EDGE_FILTER, \n                    kernels.TOP_SOBEL, kernels.EMBOSS_FILTER]\n\n    image = read_one_image(FILENAME)\n    if not rgb:\n        image = tf.image.rgb_to_grayscale(image)\n    image = tf.expand_dims(image, 0) # to make it into a batch of 1 element\n    images = convolve(image, kernels_list, rgb)\n    images = get_real_images(images)\n    show_images(images, rgb)\n\nif __name__ == \'__main__\':\n    main()'"
2017/examples/07_convnet_mnist.py,59,"b'"""""" Using convolutional net on MNIST dataset of handwritten digit\n(http://yann.lecun.com/exdb/mnist/)\nAuthor: Chip Huyen\nPrepared for the class CS 20SI: ""TensorFlow for Deep Learning Research""\ncs20si.stanford.edu\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\n\nimport time \n\nimport tensorflow as tf\nimport tf.contrib.layers as layers\nfrom tensorflow.examples.tutorials.mnist import input_data\n\nimport utils\n\nN_CLASSES = 10\n\n# Step 1: Read in data\n# using TF Learn\'s built in function to load MNIST data to the folder data/mnist\nmnist = input_data.read_data_sets(""/data/mnist"", one_hot=True)\n\n# Step 2: Define paramaters for the model\nLEARNING_RATE = 0.001\nBATCH_SIZE = 128\nSKIP_STEP = 10\nDROPOUT = 0.75\nN_EPOCHS = 1\n\n# Step 3: create placeholders for features and labels\n# each image in the MNIST data is of shape 28*28 = 784\n# therefore, each image is represented with a 1x784 tensor\n# We\'ll be doing dropout for hidden layer so we\'ll need a placeholder\n# for the dropout probability too\n# Use None for shape so we can change the batch_size once we\'ve built the graph\nwith tf.name_scope(\'data\'):\n    X = tf.placeholder(tf.float32, [None, 784], name=""X_placeholder"")\n    Y = tf.placeholder(tf.float32, [None, 10], name=""Y_placeholder"")\n\ndropout = tf.placeholder(tf.float32, name=\'dropout\')\n\n# Step 4 + 5: create weights + do inference\n# the model is conv -> relu -> pool -> conv -> relu -> pool -> fully connected -> softmax\n\nglobal_step = tf.Variable(0, dtype=tf.int32, trainable=False, name=\'global_step\')\n\nwith tf.variable_scope(\'conv1\') as scope:\n    # first, reshape the image to [BATCH_SIZE, 28, 28, 1] to make it work with tf.nn.conv2d\n    images = tf.reshape(X, shape=[-1, 28, 28, 1]) \n    kernel = tf.get_variable(\'kernel\', [5, 5, 1, 32], \n                            initializer=tf.truncated_normal_initializer())\n    biases = tf.get_variable(\'biases\', [32],\n                        initializer=tf.random_normal_initializer())\n    conv = tf.nn.conv2d(images, kernel, strides=[1, 1, 1, 1], padding=\'SAME\')\n    conv1 = tf.nn.relu(conv + biases, name=scope.name)\n\n    # output is of dimension BATCH_SIZE x 28 x 28 x 32\n    conv1 = layers.conv2d(images, 32, 5, 1, activation_fn=tf.nn.relu, padding=\'SAME\')\n\nwith tf.variable_scope(\'pool1\') as scope:\n    pool1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1],\n                           padding=\'SAME\')\n\n    # output is of dimension BATCH_SIZE x 14 x 14 x 32\n\nwith tf.variable_scope(\'conv2\') as scope:\n    # similar to conv1, except kernel now is of the size 5 x 5 x 32 x 64\n    kernel = tf.get_variable(\'kernels\', [5, 5, 32, 64], \n                        initializer=tf.truncated_normal_initializer())\n    biases = tf.get_variable(\'biases\', [64],\n                        initializer=tf.random_normal_initializer())\n    conv = tf.nn.conv2d(pool1, kernel, strides=[1, 1, 1, 1], padding=\'SAME\')\n    conv2 = tf.nn.relu(conv + biases, name=scope.name)\n\n    # output is of dimension BATCH_SIZE x 14 x 14 x 64\n    # layers.conv2d(images, 64, 5, 1, activation_fn=tf.nn.relu, padding=\'SAME\')\n\nwith tf.variable_scope(\'pool2\') as scope:\n    # similar to pool1\n    pool2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1],\n                            padding=\'SAME\')\n\n    # output is of dimension BATCH_SIZE x 7 x 7 x 64\n\nwith tf.variable_scope(\'fc\') as scope:\n    # use weight of dimension 7 * 7 * 64 x 1024\n    input_features = 7 * 7 * 64\n    w = tf.get_variable(\'weights\', [input_features, 1024],\n                        initializer=tf.truncated_normal_initializer())\n    b = tf.get_variable(\'biases\', [1024],\n                        initializer=tf.constant_initializer(0.0))\n\n    # reshape pool2 to 2 dimensional\n    pool2 = tf.reshape(pool2, [-1, input_features])\n    fc = tf.nn.relu(tf.matmul(pool2, w) + b, name=\'relu\')\n    \n    # pool2 = layers.flatten(pool2)\n    # fc = layers.fully_connected(pool2, 1024, tf.nn.relu)\n\n    fc = tf.nn.dropout(fc, dropout, name=\'relu_dropout\')\n\nwith tf.variable_scope(\'softmax_linear\') as scope:\n    w = tf.get_variable(\'weights\', [1024, N_CLASSES],\n                        initializer=tf.truncated_normal_initializer())\n    b = tf.get_variable(\'biases\', [N_CLASSES],\n                        initializer=tf.random_normal_initializer())\n    logits = tf.matmul(fc, w) + b\n\n    \n\n\n# Step 6: define loss function\n# use softmax cross entropy with logits as the loss function\n# compute mean cross entropy, softmax is applied internally\nwith tf.name_scope(\'loss\'):\n    entropy = tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=logits)\n    loss = tf.reduce_mean(entropy, name=\'loss\')\n\nwith tf.name_scope(\'summaries\'):\n    tf.summary.scalar(\'loss\', loss)\n    tf.summary.histogram(\'histogram loss\', loss)\n    summary_op = tf.summary.merge_all()\n\n# Step 7: define training op\n# using gradient descent with learning rate of LEARNING_RATE to minimize cost\noptimizer = tf.train.AdamOptimizer(LEARNING_RATE).minimize(loss, \n                                        global_step=global_step)\n\nutils.make_dir(\'checkpoints\')\nutils.make_dir(\'checkpoints/convnet_mnist\')\n\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    saver = tf.train.Saver()\n    # to visualize using TensorBoard\n    writer = tf.summary.FileWriter(\'./graphs/convnet\', sess.graph)\n    ckpt = tf.train.get_checkpoint_state(os.path.dirname(\'checkpoints/convnet_mnist/checkpoint\'))\n    # if that checkpoint exists, restore from checkpoint\n    if ckpt and ckpt.model_checkpoint_path:\n        saver.restore(sess, ckpt.model_checkpoint_path)\n    \n    initial_step = global_step.eval()\n\n    start_time = time.time()\n    n_batches = int(mnist.train.num_examples / BATCH_SIZE)\n\n    total_loss = 0.0\n    for index in range(initial_step, n_batches * N_EPOCHS): # train the model n_epochs times\n        X_batch, Y_batch = mnist.train.next_batch(BATCH_SIZE)\n        _, loss_batch, summary = sess.run([optimizer, loss, summary_op], \n                                feed_dict={X: X_batch, Y:Y_batch, dropout: DROPOUT}) \n        writer.add_summary(summary, global_step=index)\n        total_loss += loss_batch\n        if (index + 1) % SKIP_STEP == 0:\n            print(\'Average loss at step {}: {:5.1f}\'.format(index + 1, total_loss / SKIP_STEP))\n            total_loss = 0.0\n            saver.save(sess, \'checkpoints/convnet_mnist/mnist-convnet\', index)\n    \n    print(""Optimization Finished!"") # should be around 0.35 after 25 epochs\n    print(""Total time: {0} seconds"".format(time.time() - start_time))\n    \n    # test the model\n    n_batches = int(mnist.test.num_examples/BATCH_SIZE)\n    total_correct_preds = 0\n    for i in range(n_batches):\n        X_batch, Y_batch = mnist.test.next_batch(BATCH_SIZE)\n        _, loss_batch, logits_batch = sess.run([optimizer, loss, logits], \n                                        feed_dict={X: X_batch, Y:Y_batch, dropout: 1.0}) \n        preds = tf.nn.softmax(logits_batch)\n        correct_preds = tf.equal(tf.argmax(preds, 1), tf.argmax(Y_batch, 1))\n        accuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32))\n        total_correct_preds += sess.run(accuracy)   \n    \n    print(""Accuracy {0}"".format(total_correct_preds/mnist.test.num_examples))'"
2017/examples/07_convnet_mnist_starter.py,35,"b'"""""" Using convolutional net on MNIST dataset of handwritten digit\n(http://yann.lecun.com/exdb/mnist/)\nAuthor: Chip Huyen\nPrepared for the class CS 20SI: ""TensorFlow for Deep Learning Research""\ncs20si.stanford.edu\n""""""\nfrom __future__ import print_function\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\n\nimport time \n\nimport tensorflow as tf\nfrom tensorflow.examples.tutorials.mnist import input_data\n\nimport utils\n\nN_CLASSES = 10\n\n# Step 1: Read in data\n# using TF Learn\'s built in function to load MNIST data to the folder data/mnist\nmnist = input_data.read_data_sets(""/data/mnist"", one_hot=True)\n\n# Step 2: Define paramaters for the model\nLEARNING_RATE = 0.001\nBATCH_SIZE = 128\nSKIP_STEP = 10\nDROPOUT = 0.75\nN_EPOCHS = 1\n\n# Step 3: create placeholders for features and labels\n# each image in the MNIST data is of shape 28*28 = 784\n# therefore, each image is represented with a 1x784 tensor\n# We\'ll be doing dropout for hidden layer so we\'ll need a placeholder\n# for the dropout probability too\n# Use None for shape so we can change the batch_size once we\'ve built the graph\nwith tf.name_scope(\'data\'):\n    X = tf.placeholder(tf.float32, [None, 784], name=""X_placeholder"")\n    Y = tf.placeholder(tf.float32, [None, 10], name=""Y_placeholder"")\n\ndropout = tf.placeholder(tf.float32, name=\'dropout\')\n\n# Step 4 + 5: create weights + do inference\n# the model is conv -> relu -> pool -> conv -> relu -> pool -> fully connected -> softmax\n\nglobal_step = tf.Variable(0, dtype=tf.int32, trainable=False, name=\'global_step\')\n\nutils.make_dir(\'checkpoints\')\nutils.make_dir(\'checkpoints/convnet_mnist\')\n\nwith tf.variable_scope(\'conv1\') as scope:\n    # first, reshape the image to [BATCH_SIZE, 28, 28, 1] to make it work with tf.nn.conv2d\n    # use the dynamic dimension -1\n    images = tf.reshape(X, shape=[-1, 28, 28, 1])\n    \n    # TO DO\n\n    # create kernel variable of dimension [5, 5, 1, 32]\n    # use tf.truncated_normal_initializer()\n    \n    # TO DO\n\n    # create biases variable of dimension [32]\n    # use tf.constant_initializer(0.0)\n    \n    # TO DO \n\n    # apply tf.nn.conv2d. strides [1, 1, 1, 1], padding is \'SAME\'\n    \n    # TO DO\n\n    # apply relu on the sum of convolution output and biases\n    \n    # TO DO \n\n    # output is of dimension BATCH_SIZE x 28 x 28 x 32\n\nwith tf.variable_scope(\'pool1\') as scope:\n    # apply max pool with ksize [1, 2, 2, 1], and strides [1, 2, 2, 1], padding \'SAME\'\n    \n    # TO DO\n\n    # output is of dimension BATCH_SIZE x 14 x 14 x 32\n\nwith tf.variable_scope(\'conv2\') as scope:\n    # similar to conv1, except kernel now is of the size 5 x 5 x 32 x 64\n    kernel = tf.get_variable(\'kernels\', [5, 5, 32, 64], \n                        initializer=tf.truncated_normal_initializer())\n    biases = tf.get_variable(\'biases\', [64],\n                        initializer=tf.random_normal_initializer())\n    conv = tf.nn.conv2d(pool1, kernel, strides=[1, 1, 1, 1], padding=\'SAME\')\n    conv2 = tf.nn.relu(conv + biases, name=scope.name)\n\n    # output is of dimension BATCH_SIZE x 14 x 14 x 64\n\nwith tf.variable_scope(\'pool2\') as scope:\n    # similar to pool1\n    pool2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1],\n                            padding=\'SAME\')\n\n    # output is of dimension BATCH_SIZE x 7 x 7 x 64\n\nwith tf.variable_scope(\'fc\') as scope:\n    # use weight of dimension 7 * 7 * 64 x 1024\n    input_features = 7 * 7 * 64\n    \n    # create weights and biases\n\n    # TO DO\n\n    # reshape pool2 to 2 dimensional\n    pool2 = tf.reshape(pool2, [-1, input_features])\n\n    # apply relu on matmul of pool2 and w + b\n    fc = tf.nn.relu(tf.matmul(pool2, w) + b, name=\'relu\')\n    \n    # TO DO\n\n    # apply dropout\n    fc = tf.nn.dropout(fc, dropout, name=\'relu_dropout\')\n\nwith tf.variable_scope(\'softmax_linear\') as scope:\n    # this you should know. get logits without softmax\n    # you need to create weights and biases\n\n    # TO DO\n\n# Step 6: define loss function\n# use softmax cross entropy with logits as the loss function\n# compute mean cross entropy, softmax is applied internally\nwith tf.name_scope(\'loss\'):\n    # you should know how to do this too\n    \n    # TO DO\n\n# Step 7: define training op\n# using gradient descent with learning rate of LEARNING_RATE to minimize cost\n# don\'t forgot to pass in global_step\n\n# TO DO\n\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    saver = tf.train.Saver()\n    # to visualize using TensorBoard\n    writer = tf.summary.FileWriter(\'./my_graph/mnist\', sess.graph)\n    ##### You have to create folders to store checkpoints\n    ckpt = tf.train.get_checkpoint_state(os.path.dirname(\'checkpoints/convnet_mnist/checkpoint\'))\n    # if that checkpoint exists, restore from checkpoint\n    if ckpt and ckpt.model_checkpoint_path:\n        saver.restore(sess, ckpt.model_checkpoint_path)\n    \n    initial_step = global_step.eval()\n\n    start_time = time.time()\n    n_batches = int(mnist.train.num_examples / BATCH_SIZE)\n\n    total_loss = 0.0\n    for index in range(initial_step, n_batches * N_EPOCHS): # train the model n_epochs times\n        X_batch, Y_batch = mnist.train.next_batch(BATCH_SIZE)\n        _, loss_batch = sess.run([optimizer, loss], \n                                feed_dict={X: X_batch, Y:Y_batch, dropout: DROPOUT}) \n        total_loss += loss_batch\n        if (index + 1) % SKIP_STEP == 0:\n            print(\'Average loss at step {}: {:5.1f}\'.format(index + 1, total_loss / SKIP_STEP))\n            total_loss = 0.0\n            saver.save(sess, \'checkpoints/convnet_mnist/mnist-convnet\', index)\n    \n    print(""Optimization Finished!"") # should be around 0.35 after 25 epochs\n    print(""Total time: {0} seconds"".format(time.time() - start_time))\n    \n    # test the model\n    n_batches = int(mnist.test.num_examples/BATCH_SIZE)\n    total_correct_preds = 0\n    for i in range(n_batches):\n        X_batch, Y_batch = mnist.test.next_batch(BATCH_SIZE)\n        _, loss_batch, logits_batch = sess.run([optimizer, loss, logits], \n                                        feed_dict={X: X_batch, Y:Y_batch, dropout: DROPOUT}) \n        preds = tf.nn.softmax(logits_batch)\n        correct_preds = tf.equal(tf.argmax(preds, 1), tf.argmax(Y_batch, 1))\n        accuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32))\n        total_correct_preds += sess.run(accuracy)   \n    \n    print(""Accuracy {0}"".format(total_correct_preds/mnist.test.num_examples))'"
2017/examples/09_queue_example.py,4,"b'"""""" Example to demonstrate how to use queues\nAuthor: Chip Huyen\nPrepared for the class CS 20SI: ""TensorFlow for Deep Learning Research""\ncs20si.stanford.edu\n""""""\nimport os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\n\nimport numpy as np\nimport tensorflow as tf\n\nN_SAMPLES = 1000\nNUM_THREADS = 4\n# Generating some simple data\n# create 1000 random samples, each is a 1D array from the normal distribution (10, 1)\ndata = 10 * np.random.randn(N_SAMPLES, 4) + 1 \n# create 1000 random labels of 0 and 1\ntarget = np.random.randint(0, 2, size=N_SAMPLES) \n\nqueue = tf.FIFOQueue(capacity=50, dtypes=[tf.float32, tf.int32], shapes=[[4], []])\n\nenqueue_op = queue.enqueue_many([data, target])\ndata_sample, label_sample = queue.dequeue()\n\n# create ops that do something with data_sample and label_sample\n\n# create NUM_THREADS to do enqueue\nqr = tf.train.QueueRunner(queue, [enqueue_op] * NUM_THREADS)\nwith tf.Session() as sess:\n\t# create a coordinator, launch the queue runner threads.\n\tcoord = tf.train.Coordinator()\n\tenqueue_threads = qr.create_threads(sess, coord=coord, start=True)\n\ttry:\n\t\tfor step in range(100): # do to 100 iterations\n\t\t\tif coord.should_stop():\n\t\t\t\tbreak\n\t\t\tdata_batch, label_batch = sess.run([data_sample, label_sample])\n\t\t\tprint(data_batch)\n\t\t\tprint(label_batch)\n\texcept Exception as e:\n\t\tcoord.request_stop(e)\n\tfinally:\n\t\tcoord.request_stop()\n\t\tcoord.join(enqueue_threads)'"
2017/examples/09_tfrecord_example.py,17,"b'"""""" Examples to demonstrate how to write an image file to a TFRecord,\nand how to read a TFRecord file using TFRecordReader.\nAuthor: Chip Huyen\nPrepared for the class CS 20SI: ""TensorFlow for Deep Learning Research""\ncs20si.stanford.edu\n""""""\nimport os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\n\nimport sys\nsys.path.append(\'..\')\n\nfrom PIL import Image\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\n# image supposed to have shape: 480 x 640 x 3 = 921600\nIMAGE_PATH = \'data/\'\n\ndef _int64_feature(value):\n  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n\ndef _bytes_feature(value):\n  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef get_image_binary(filename):\n    """""" You can read in the image using tensorflow too, but it\'s a drag\n        since you have to create graphs. It\'s much easier using Pillow and NumPy\n    """"""\n    image = Image.open(filename)\n    image = np.asarray(image, np.uint8)\n    shape = np.array(image.shape, np.int32)\n    return shape.tobytes(), image.tobytes() # convert image to raw data bytes in the array.\n\ndef write_to_tfrecord(label, shape, binary_image, tfrecord_file):\n    """""" This example is to write a sample to TFRecord file. If you want to write\n    more samples, just use a loop.\n    """"""\n    writer = tf.python_io.TFRecordWriter(tfrecord_file)\n    # write label, shape, and image content to the TFRecord file\n    example = tf.train.Example(features=tf.train.Features(feature={\n                \'label\': _int64_feature(label),\n                \'shape\': _bytes_feature(shape),\n                \'image\': _bytes_feature(binary_image)\n                }))\n    writer.write(example.SerializeToString())\n    writer.close()\n\ndef write_tfrecord(label, image_file, tfrecord_file):\n    shape, binary_image = get_image_binary(image_file)\n    write_to_tfrecord(label, shape, binary_image, tfrecord_file)\n\ndef read_from_tfrecord(filenames):\n    tfrecord_file_queue = tf.train.string_input_producer(filenames, name=\'queue\')\n    reader = tf.TFRecordReader()\n    _, tfrecord_serialized = reader.read(tfrecord_file_queue)\n\n    # label and image are stored as bytes but could be stored as \n    # int64 or float64 values in a serialized tf.Example protobuf.\n    tfrecord_features = tf.parse_single_example(tfrecord_serialized,\n                        features={\n                            \'label\': tf.FixedLenFeature([], tf.int64),\n                            \'shape\': tf.FixedLenFeature([], tf.string),\n                            \'image\': tf.FixedLenFeature([], tf.string),\n                        }, name=\'features\')\n    # image was saved as uint8, so we have to decode as uint8.\n    image = tf.decode_raw(tfrecord_features[\'image\'], tf.uint8)\n    shape = tf.decode_raw(tfrecord_features[\'shape\'], tf.int32)\n    # the image tensor is flattened out, so we have to reconstruct the shape\n    image = tf.reshape(image, shape)\n    label = tfrecord_features[\'label\']\n    return label, shape, image\n\ndef read_tfrecord(tfrecord_file):\n    label, shape, image = read_from_tfrecord([tfrecord_file])\n\n    with tf.Session() as sess:\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(coord=coord)\n        label, image, shape = sess.run([label, image, shape])\n        coord.request_stop()\n        coord.join(threads)\n    print(label)\n    print(shape)\n    plt.imshow(image)\n    plt.show() \n\ndef main():\n    # assume the image has the label Chihuahua, which corresponds to class number 1\n    label = 1 \n    image_file = IMAGE_PATH + \'friday.jpg\'\n    tfrecord_file = IMAGE_PATH + \'friday.tfrecord\'\n    write_tfrecord(label, image_file, tfrecord_file)\n    read_tfrecord(tfrecord_file)\n\nif __name__ == \'__main__\':\n    main()\n\n'"
2017/examples/11_char_rnn_gist.py,20,"b'"""""" A clean, no_frills character-level generative language model.\nCreated by Danijar Hafner (danijar.com), edited by Chip Huyen\nfor the class CS 20SI: ""TensorFlow for Deep Learning Research""\n\nBased on Andrej Karpathy\'s blog: \nhttp://karpathy.github.io/2015/05/21/rnn-effectiveness/\n""""""\nimport os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\nimport sys\nsys.path.append(\'..\')\n\nimport time\n\nimport tensorflow as tf\n\nimport utils\n\nDATA_PATH = \'data/arvix_abstracts.txt\'\nHIDDEN_SIZE = 200\nBATCH_SIZE = 64\nNUM_STEPS = 50\nSKIP_STEP = 40\nTEMPRATURE = 0.7\nLR = 0.003\nLEN_GENERATED = 300\n\ndef vocab_encode(text, vocab):\n    return [vocab.index(x) + 1 for x in text if x in vocab]\n\ndef vocab_decode(array, vocab):\n    return \'\'.join([vocab[x - 1] for x in array])\n\ndef read_data(filename, vocab, window=NUM_STEPS, overlap=NUM_STEPS//2):\n    for text in open(filename):\n        text = vocab_encode(text, vocab)\n        for start in range(0, len(text) - window, overlap):\n            chunk = text[start: start + window]\n            chunk += [0] * (window - len(chunk))\n            yield chunk\n\ndef read_batch(stream, batch_size=BATCH_SIZE):\n    batch = []\n    for element in stream:\n        batch.append(element)\n        if len(batch) == batch_size:\n            yield batch\n            batch = []\n    yield batch\n\ndef create_rnn(seq, hidden_size=HIDDEN_SIZE):\n    cell = tf.contrib.rnn.GRUCell(hidden_size)\n    in_state = tf.placeholder_with_default(\n            cell.zero_state(tf.shape(seq)[0], tf.float32), [None, hidden_size])\n    # this line to calculate the real length of seq\n    # all seq are padded to be of the same length which is NUM_STEPS\n    length = tf.reduce_sum(tf.reduce_max(tf.sign(seq), 2), 1)\n    output, out_state = tf.nn.dynamic_rnn(cell, seq, length, in_state)\n    return output, in_state, out_state\n\ndef create_model(seq, temp, vocab, hidden=HIDDEN_SIZE):\n    seq = tf.one_hot(seq, len(vocab))\n    output, in_state, out_state = create_rnn(seq, hidden)\n    # fully_connected is syntactic sugar for tf.matmul(w, output) + b\n    # it will create w and b for us\n    logits = tf.contrib.layers.fully_connected(output, len(vocab), None)\n    loss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(logits=logits[:, :-1], labels=seq[:, 1:]))\n    # sample the next character from Maxwell-Boltzmann Distribution with temperature temp\n    # it works equally well without tf.exp\n    sample = tf.multinomial(tf.exp(logits[:, -1] / temp), 1)[:, 0] \n    return loss, sample, in_state, out_state\n\ndef training(vocab, seq, loss, optimizer, global_step, temp, sample, in_state, out_state):\n    saver = tf.train.Saver()\n    start = time.time()\n    with tf.Session() as sess:\n        writer = tf.summary.FileWriter(\'graphs/gist\', sess.graph)\n        sess.run(tf.global_variables_initializer())\n        \n        ckpt = tf.train.get_checkpoint_state(os.path.dirname(\'checkpoints/arvix/checkpoint\'))\n        if ckpt and ckpt.model_checkpoint_path:\n            saver.restore(sess, ckpt.model_checkpoint_path)\n        \n        iteration = global_step.eval()\n        for batch in read_batch(read_data(DATA_PATH, vocab)):\n            batch_loss, _ = sess.run([loss, optimizer], {seq: batch})\n            if (iteration + 1) % SKIP_STEP == 0:\n                print(\'Iter {}. \\n    Loss {}. Time {}\'.format(iteration, batch_loss, time.time() - start))\n                online_inference(sess, vocab, seq, sample, temp, in_state, out_state)\n                start = time.time()\n                saver.save(sess, \'checkpoints/arvix/char-rnn\', iteration)\n            iteration += 1\n\ndef online_inference(sess, vocab, seq, sample, temp, in_state, out_state, seed=\'T\'):\n    """""" Generate sequence one character at a time, based on the previous character\n    """"""\n    sentence = seed\n    state = None\n    for _ in range(LEN_GENERATED):\n        batch = [vocab_encode(sentence[-1], vocab)]\n        feed = {seq: batch, temp: TEMPRATURE}\n        # for the first decoder step, the state is None\n        if state is not None:\n            feed.update({in_state: state})\n        index, state = sess.run([sample, out_state], feed)\n        sentence += vocab_decode(index, vocab)\n    print(sentence)\n\ndef main():\n    vocab = (\n            "" $%\'()+,-./0123456789:;=?ABCDEFGHIJKLMNOPQRSTUVWXYZ""\n            ""\\\\^_abcdefghijklmnopqrstuvwxyz{|}"")\n    seq = tf.placeholder(tf.int32, [None, None])\n    temp = tf.placeholder(tf.float32)\n    loss, sample, in_state, out_state = create_model(seq, temp, vocab)\n    global_step = tf.Variable(0, dtype=tf.int32, trainable=False, name=\'global_step\')\n    optimizer = tf.train.AdamOptimizer(LR).minimize(loss, global_step=global_step)\n    utils.make_dir(\'checkpoints\')\n    utils.make_dir(\'checkpoints/arvix\')\n    training(vocab, seq, loss, optimizer, global_step, temp, sample, in_state, out_state)\n    \nif __name__ == \'__main__\':\n    main()'"
2017/examples/kernels.py,11,"b'import numpy as np\nimport tensorflow as tf\n\na = np.zeros([3, 3, 3, 3])\na[1, 1, :, :] = 0.25\na[0, 1, :, :] = 0.125\na[1, 0, :, :] = 0.125\na[2, 1, :, :] = 0.125\na[1, 2, :, :] = 0.125\na[0, 0, :, :] = 0.0625\na[0, 2, :, :] = 0.0625\na[2, 0, :, :] = 0.0625\na[2, 2, :, :] = 0.0625\n\nBLUR_FILTER_RGB = tf.constant(a, dtype=tf.float32)\n\na = np.zeros([3, 3, 1, 1])\n# a[1, 1, :, :] = 0.25\n# a[0, 1, :, :] = 0.125\n# a[1, 0, :, :] = 0.125\n# a[2, 1, :, :] = 0.125\n# a[1, 2, :, :] = 0.125\n# a[0, 0, :, :] = 0.0625\n# a[0, 2, :, :] = 0.0625\n# a[2, 0, :, :] = 0.0625\n# a[2, 2, :, :] = 0.0625\na[1, 1, :, :] = 1.0\na[0, 1, :, :] = 1.0\na[1, 0, :, :] = 1.0\na[2, 1, :, :] = 1.0\na[1, 2, :, :] = 1.0\na[0, 0, :, :] = 1.0\na[0, 2, :, :] = 1.0\na[2, 0, :, :] = 1.0\na[2, 2, :, :] = 1.0\nBLUR_FILTER = tf.constant(a, dtype=tf.float32)\n\na = np.zeros([3, 3, 3, 3])\na[1, 1, :, :] = 5\na[0, 1, :, :] = -1\na[1, 0, :, :] = -1\na[2, 1, :, :] = -1\na[1, 2, :, :] = -1\n\nSHARPEN_FILTER_RGB = tf.constant(a, dtype=tf.float32)\n\na = np.zeros([3, 3, 1, 1])\na[1, 1, :, :] = 5\na[0, 1, :, :] = -1\na[1, 0, :, :] = -1\na[2, 1, :, :] = -1\na[1, 2, :, :] = -1\n\nSHARPEN_FILTER = tf.constant(a, dtype=tf.float32)\n\n# a = np.zeros([3, 3, 3, 3])\n# a[:, :, :, :] = -1\n# a[1, 1, :, :] = 8\n\n# EDGE_FILTER_RGB = tf.constant(a, dtype=tf.float32)\n\nEDGE_FILTER_RGB = tf.constant([\n\t\t\t[[[ -1., 0., 0.], [ 0., -1., 0.], [ 0., 0., -1.]],\n            [[ -1., 0., 0.], [ 0., -1., 0.], [ 0., 0., -1.]],\n            [[ -1., 0., 0.], [ 0., -1., 0.], [ 0., 0., -1.]]],\n            [[[ -1., 0., 0.], [ 0., -1., 0.], [ 0., 0., -1.]],\n\t\t\t[[ 8., 0., 0.], [ 0., 8., 0.], [ 0., 0., 8.]],\n\t\t\t[[ -1., 0., 0.], [ 0., -1., 0.], [ 0., 0., -1.]]],\n\t\t\t[[[ -1., 0., 0.], [ 0., -1., 0.], [ 0., 0., -1.]],\n\t\t\t[[ -1., 0., 0.], [ 0., -1., 0.], [ 0., 0., -1.]],\n\t\t\t[[ -1., 0., 0.], [ 0., -1., 0.], [ 0., 0., -1.]]]\n])\n\na = np.zeros([3, 3, 1, 1])\n# a[:, :, :, :] = -1\n# a[1, 1, :, :] = 8\na[0, 1, :, :] = -1\na[1, 0, :, :] = -1\na[1, 2, :, :] = -1\na[2, 1, :, :] = -1\na[1, 1, :, :] = 4\n\nEDGE_FILTER = tf.constant(a, dtype=tf.float32)\n\na = np.zeros([3, 3, 3, 3])\na[0, :, :, :] = 1\na[0, 1, :, :] = 2 # originally 2\na[2, :, :, :] = -1\na[2, 1, :, :] = -2\n\nTOP_SOBEL_RGB = tf.constant(a, dtype=tf.float32)\n\na = np.zeros([3, 3, 1, 1])\na[0, :, :, :] = 1\na[0, 1, :, :] = 2 # originally 2\na[2, :, :, :] = -1\na[2, 1, :, :] = -2\n\nTOP_SOBEL = tf.constant(a, dtype=tf.float32)\n\na = np.zeros([3, 3, 3, 3])\na[0, 0, :, :] = -2\na[0, 1, :, :] = -1 \na[1, 0, :, :] = -1\na[1, 1, :, :] = 1\na[1, 2, :, :] = 1\na[2, 1, :, :] = 1\na[2, 2, :, :] = 2\n\nEMBOSS_FILTER_RGB = tf.constant(a, dtype=tf.float32)\n\na = np.zeros([3, 3, 1, 1])\na[0, 0, :, :] = -2\na[0, 1, :, :] = -1 \na[1, 0, :, :] = -1\na[1, 1, :, :] = 1\na[1, 2, :, :] = 1\na[2, 1, :, :] = 1\na[2, 2, :, :] = 2\nEMBOSS_FILTER = tf.constant(a, dtype=tf.float32)'"
2017/examples/process_data.py,2,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom collections import Counter\nimport random\nimport os\nimport sys\nsys.path.append(\'..\')\nimport zipfile\n\nimport numpy as np\nfrom six.moves import urllib\nimport tensorflow as tf\n\nimport utils\n\n# Parameters for downloading data\nDOWNLOAD_URL = \'http://mattmahoney.net/dc/\'\nEXPECTED_BYTES = 31344016\nDATA_FOLDER = \'data/\'\nFILE_NAME = \'text8.zip\'\n\ndef download(file_name, expected_bytes):\n    """""" Download the dataset text8 if it\'s not already downloaded """"""\n    file_path = DATA_FOLDER + file_name\n    if os.path.exists(file_path):\n        print(""Dataset ready"")\n        return file_path\n    file_name, _ = urllib.request.urlretrieve(DOWNLOAD_URL + file_name, file_path)\n    file_stat = os.stat(file_path)\n    if file_stat.st_size == expected_bytes:\n        print(\'Successfully downloaded the file\', file_name)\n    else:\n        raise Exception(\'File \' + file_name +\n                        \' might be corrupted. You should try downloading it with a browser.\')\n    return file_path\n\ndef read_data(file_path):\n    """""" Read data into a list of tokens \n    There should be 17,005,207 tokens\n    """"""\n    with zipfile.ZipFile(file_path) as f:\n        words = tf.compat.as_str(f.read(f.namelist()[0])).split() \n        # tf.compat.as_str() converts the input into the string\n    return words\n\ndef build_vocab(words, vocab_size):\n    """""" Build vocabulary of VOCAB_SIZE most frequent words """"""\n    dictionary = dict()\n    count = [(\'UNK\', -1)]\n    count.extend(Counter(words).most_common(vocab_size - 1))\n    index = 0\n    utils.make_dir(\'processed\')\n    with open(\'processed/vocab_1000.tsv\', ""w"") as f:\n        for word, _ in count:\n            dictionary[word] = index\n            if index < 1000:\n                f.write(word + ""\\n"")\n            index += 1\n    index_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n    return dictionary, index_dictionary\n\ndef convert_words_to_index(words, dictionary):\n    """""" Replace each word in the dataset with its index in the dictionary """"""\n    return [dictionary[word] if word in dictionary else 0 for word in words]\n\ndef generate_sample(index_words, context_window_size):\n    """""" Form training pairs according to the skip-gram model. """"""\n    for index, center in enumerate(index_words):\n        context = random.randint(1, context_window_size)\n        # get a random target before the center word\n        for target in index_words[max(0, index - context): index]:\n            yield center, target\n        # get a random target after the center wrod\n        for target in index_words[index + 1: index + context + 1]:\n            yield center, target\n\ndef get_batch(iterator, batch_size):\n    """""" Group a numerical stream into batches and yield them as Numpy arrays. """"""\n    while True:\n        center_batch = np.zeros(batch_size, dtype=np.int32)\n        target_batch = np.zeros([batch_size, 1])\n        for index in range(batch_size):\n            center_batch[index], target_batch[index] = next(iterator)\n        yield center_batch, target_batch\n\ndef process_data(vocab_size, batch_size, skip_window):\n    file_path = download(FILE_NAME, EXPECTED_BYTES)\n    words = read_data(file_path)\n    dictionary, _ = build_vocab(words, vocab_size)\n    index_words = convert_words_to_index(words, dictionary)\n    del words # to save memory\n    single_gen = generate_sample(index_words, skip_window)\n    return get_batch(single_gen, batch_size)\n\ndef get_index_vocab(vocab_size):\n    file_path = download(FILE_NAME, EXPECTED_BYTES)\n    words = read_data(file_path)\n    return build_vocab(words, vocab_size)\n'"
2017/examples/utils.py,4,"b'import os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\nimport tensorflow as tf\n\ndef huber_loss(labels, predictions, delta=1.0):\n    residual = tf.abs(predictions - labels)\n    def f1(): return 0.5 * tf.square(residual)\n    def f2(): return delta * residual - 0.5 * tf.square(delta)\n    return tf.cond(residual < delta, f1, f2)\n\ndef make_dir(path):\n    """""" Create a directory if there isn\'t one already. """"""\n    try:\n        os.mkdir(path)\n    except OSError:\n    \tpass'"
assignments/01/q1.py,13,"b'""""""\nSimple exercises to get used to TensorFlow API\nYou should thoroughly test your code.\nTensorFlow\'s official documentation should be your best friend here\nCS20: ""TensorFlow for Deep Learning Research""\ncs20.stanford.edu\nCreated by Chip Huyen (chiphuyen@cs.stanford.edu)\n""""""\nimport os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\n\nimport tensorflow as tf\n\nsess = tf.InteractiveSession()\n###############################################################################\n# 1a: Create two random 0-d tensors x and y of any distribution.\n# Create a TensorFlow object that returns x + y if x > y, and x - y otherwise.\n# Hint: look up tf.cond()\n# I do the first problem for you\n###############################################################################\n\nx = tf.random_uniform([])  # Empty array as shape creates a scalar.\ny = tf.random_uniform([])\nout = tf.cond(tf.greater(x, y), lambda: x + y, lambda: x - y)\nprint(sess.run(out))\n\n###############################################################################\n# 1b: Create two 0-d tensors x and y randomly selected from the range [-1, 1).\n# Return x + y if x < y, x - y if x > y, 0 otherwise.\n# Hint: Look up tf.case().\n###############################################################################\n\n# YOUR CODE\n\n###############################################################################\n# 1c: Create the tensor x of the value [[0, -2, -1], [0, 1, 2]] \n# and y as a tensor of zeros with the same shape as x.\n# Return a boolean tensor that yields Trues if x equals y element-wise.\n# Hint: Look up tf.equal().\n###############################################################################\n\n# YOUR CODE\n\n###############################################################################\n# 1d: Create the tensor x of value \n# [29.05088806,  27.61298943,  31.19073486,  29.35532951,\n#  30.97266006,  26.67541885,  38.08450317,  20.74983215,\n#  34.94445419,  34.45999146,  29.06485367,  36.01657104,\n#  27.88236427,  20.56035233,  30.20379066,  29.51215172,\n#  33.71149445,  28.59134293,  36.05556488,  28.66994858].\n# Get the indices of elements in x whose values are greater than 30.\n# Hint: Use tf.where().\n# Then extract elements whose values are greater than 30.\n# Hint: Use tf.gather().\n###############################################################################\n\n# YOUR CODE\n\n###############################################################################\n# 1e: Create a diagnoal 2-d tensor of size 6 x 6 with the diagonal values of 1,\n# 2, ..., 6\n# Hint: Use tf.range() and tf.diag().\n###############################################################################\n\n# YOUR CODE\n\n###############################################################################\n# 1f: Create a random 2-d tensor of size 10 x 10 from any distribution.\n# Calculate its determinant.\n# Hint: Look at tf.matrix_determinant().\n###############################################################################\n\n# YOUR CODE\n\n###############################################################################\n# 1g: Create tensor x with value [5, 2, 3, 5, 10, 6, 2, 3, 4, 2, 1, 1, 0, 9].\n# Return the unique elements in x\n# Hint: use tf.unique(). Keep in mind that tf.unique() returns a tuple.\n###############################################################################\n\n# YOUR CODE\n\n###############################################################################\n# 1h: Create two tensors x and y of shape 300 from any normal distribution,\n# as long as they are from the same distribution.\n# Use tf.cond() to return:\n# - The mean squared error of (x - y) if the average of all elements in (x - y)\n#   is negative, or\n# - The sum of absolute value of all elements in the tensor (x - y) otherwise.\n# Hint: see the Huber loss function in the lecture slides 3.\n###############################################################################\n\n# YOUR CODE'"
assignments/01/q1_sol.py,36,"b'""""""\nSolution to simple exercises to get used to TensorFlow API\nYou should thoroughly test your code.\nTensorFlow\'s official documentation should be your best friend here\nCS20: ""TensorFlow for Deep Learning Research""\ncs20.stanford.edu\nCreated by Chip Huyen (chiphuyen@cs.stanford.edu)\n""""""\nimport os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\n\nimport tensorflow as tf\n\nsess = tf.InteractiveSession()\n###############################################################################\n# 1a: Create two random 0-d tensors x and y of any distribution.\n# Create a TensorFlow object that returns x + y if x > y, and x - y otherwise.\n# Hint: look up tf.cond()\n# I do the first problem for you\n###############################################################################\n\nx = tf.random_uniform([])  # Empty array as shape creates a scalar.\ny = tf.random_uniform([])\nout = tf.cond(tf.greater(x, y), lambda: tf.add(x, y), lambda: tf.subtract(x, y))\n\n###############################################################################\n# 1b: Create two 0-d tensors x and y randomly selected from the range [-1, 1).\n# Return x + y if x < y, x - y if x > y, 0 otherwise.\n# Hint: Look up tf.case().\n###############################################################################\n\nx = tf.random_uniform([], -1, 1, dtype=tf.float32)\ny = tf.random_uniform([], -1, 1, dtype=tf.float32)\nout = tf.case({tf.less(x, y): lambda: tf.add(x, y), \n\t\t\ttf.greater(x, y): lambda: tf.subtract(x, y)}, \n\t\t\tdefault=lambda: tf.constant(0.0), exclusive=True)\n\n\n###############################################################################\n# 1c: Create the tensor x of the value [[0, -2, -1], [0, 1, 2]] \n# and y as a tensor of zeros with the same shape as x.\n# Return a boolean tensor that yields Trues if x equals y element-wise.\n# Hint: Look up tf.equal().\n###############################################################################\n\nx = tf.constant([[0, -2, -1], [0, 1, 2]])\ny = tf.zeros_like(x)\nout = tf.equal(x, y)\n\n###############################################################################\n# 1d: Create the tensor x of value \n# [29.05088806,  27.61298943,  31.19073486,  29.35532951,\n#  30.97266006,  26.67541885,  38.08450317,  20.74983215,\n#  34.94445419,  34.45999146,  29.06485367,  36.01657104,\n#  27.88236427,  20.56035233,  30.20379066,  29.51215172,\n#  33.71149445,  28.59134293,  36.05556488,  28.66994858].\n# Get the indices of elements in x whose values are greater than 30.\n# Hint: Use tf.where().\n# Then extract elements whose values are greater than 30.\n# Hint: Use tf.gather().\n###############################################################################\n\nx = tf.constant([29.05088806,  27.61298943,  31.19073486,  29.35532951,\n\t\t        30.97266006,  26.67541885,  38.08450317,  20.74983215,\n\t\t        34.94445419,  34.45999146,  29.06485367,  36.01657104,\n\t\t        27.88236427,  20.56035233,  30.20379066,  29.51215172,\n\t\t        33.71149445,  28.59134293,  36.05556488,  28.66994858])\nindices = tf.where(x > 30)\nout = tf.gather(x, indices)\n\n###############################################################################\n# 1e: Create a diagnoal 2-d tensor of size 6 x 6 with the diagonal values of 1,\n# 2, ..., 6\n# Hint: Use tf.range() and tf.diag().\n###############################################################################\n\nvalues = tf.range(1, 7)\nout = tf.diag(values)\n\n###############################################################################\n# 1f: Create a random 2-d tensor of size 10 x 10 from any distribution.\n# Calculate its determinant.\n# Hint: Look at tf.matrix_determinant().\n###############################################################################\n\nm = tf.random_normal([10, 10], mean=10, stddev=1)\nout = tf.matrix_determinant(m)\n\n###############################################################################\n# 1g: Create tensor x with value [5, 2, 3, 5, 10, 6, 2, 3, 4, 2, 1, 1, 0, 9].\n# Return the unique elements in x\n# Hint: use tf.unique(). Keep in mind that tf.unique() returns a tuple.\n###############################################################################\n\nx = tf.constant([5, 2, 3, 5, 10, 6, 2, 3, 4, 2, 1, 1, 0, 9])\nunique_values, indices = tf.unique(x)\n\n###############################################################################\n# 1h: Create two tensors x and y of shape 300 from any normal distribution,\n# as long as they are from the same distribution.\n# Use tf.cond() to return:\n# - The mean squared error of (x - y) if the average of all elements in (x - y)\n#   is negative, or\n# - The sum of absolute value of all elements in the tensor (x - y) otherwise.\n# Hint: see the Huber loss function in the lecture slides 3.\n###############################################################################\n\nx = tf.random_normal([300], mean=5, stddev=1)\ny = tf.random_normal([300], mean=5, stddev=1)\naverage = tf.reduce_mean(x - y)\ndef f1(): return tf.reduce_mean(tf.square(x - y))\ndef f2(): return tf.reduce_sum(tf.abs(x - y))\nout = tf.cond(average < 0, f1, f2)'"
assignments/02_style_transfer/load_vgg.py,0,"b'"""""" Load VGGNet weights needed for the implementation in TensorFlow\nof the paper A Neural Algorithm of Artistic Style (Gatys et al., 2016) \n\nCreated by Chip Huyen (chiphuyen@cs.stanford.edu)\nCS20: ""TensorFlow for Deep Learning Research""\ncs20.stanford.edu\n\nFor more details, please read the assignment handout:\nhttps://docs.google.com/document/d/1FpueD-3mScnD0SJQDtwmOb1FrSwo1NGowkXzMwPoLH4/edit?usp=sharing\n\n""""""\nimport numpy as np\nimport scipy.io\nimport tensorflow as tf\n\nimport utils\n\n# VGG-19 parameters file\nVGG_DOWNLOAD_LINK = \'http://www.vlfeat.org/matconvnet/models/imagenet-vgg-verydeep-19.mat\'\nVGG_FILENAME = \'imagenet-vgg-verydeep-19.mat\'\nEXPECTED_BYTES = 534904783\n\nclass VGG(object):\n    def __init__(self, input_img):\n        utils.download(VGG_DOWNLOAD_LINK, VGG_FILENAME, EXPECTED_BYTES)\n        self.vgg_layers = scipy.io.loadmat(VGG_FILENAME)[\'layers\']\n        self.input_img = input_img\n        self.mean_pixels = np.array([123.68, 116.779, 103.939]).reshape((1,1,1,3))\n\n    def _weights(self, layer_idx, expected_layer_name):\n        """""" Return the weights and biases at layer_idx already trained by VGG\n        """"""\n        W = self.vgg_layers[0][layer_idx][0][0][2][0][0]\n        b = self.vgg_layers[0][layer_idx][0][0][2][0][1]\n        layer_name = self.vgg_layers[0][layer_idx][0][0][0][0]\n        assert layer_name == expected_layer_name\n        return W, b.reshape(b.size)\n\n    def conv2d_relu(self, prev_layer, layer_idx, layer_name):\n        """""" Create a convolution layer with RELU using the weights and\n        biases extracted from the VGG model at \'layer_idx\'. You should use\n        the function _weights() defined above to extract weights and biases.\n\n        _weights() returns numpy arrays, so you have to convert them to TF tensors.\n\n        Don\'t forget to apply relu to the output from the convolution.\n        Inputs:\n            prev_layer: the output tensor from the previous layer\n            layer_idx: the index to current layer in vgg_layers\n            layer_name: the string that is the name of the current layer.\n                        It\'s used to specify variable_scope.\n        Hint for choosing strides size: \n            for small images, you probably don\'t want to skip any pixel\n        """"""\n        ###############################\n        ## TO DO\n        out = None\n        ###############################\n        setattr(self, layer_name, out)\n\n    def avgpool(self, prev_layer, layer_name):\n        """""" Create the average pooling layer. The paper suggests that \n        average pooling works better than max pooling.\n        \n        Input:\n            prev_layer: the output tensor from the previous layer\n            layer_name: the string that you want to name the layer.\n                        It\'s used to specify variable_scope.\n\n        Hint for choosing strides and kszie: choose what you feel appropriate\n        """"""\n        ###############################\n        ## TO DO\n        out = None\n        ###############################\n        setattr(self, layer_name, out)\n\n    def load(self):\n        self.conv2d_relu(self.input_img, 0, \'conv1_1\')\n        self.conv2d_relu(self.conv1_1, 2, \'conv1_2\')\n        self.avgpool(self.conv1_2, \'avgpool1\')\n        self.conv2d_relu(self.avgpool1, 5, \'conv2_1\')\n        self.conv2d_relu(self.conv2_1, 7, \'conv2_2\')\n        self.avgpool(self.conv2_2, \'avgpool2\')\n        self.conv2d_relu(self.avgpool2, 10, \'conv3_1\')\n        self.conv2d_relu(self.conv3_1, 12, \'conv3_2\')\n        self.conv2d_relu(self.conv3_2, 14, \'conv3_3\')\n        self.conv2d_relu(self.conv3_3, 16, \'conv3_4\')\n        self.avgpool(self.conv3_4, \'avgpool3\')\n        self.conv2d_relu(self.avgpool3, 19, \'conv4_1\')\n        self.conv2d_relu(self.conv4_1, 21, \'conv4_2\')\n        self.conv2d_relu(self.conv4_2, 23, \'conv4_3\')\n        self.conv2d_relu(self.conv4_3, 25, \'conv4_4\')\n        self.avgpool(self.conv4_4, \'avgpool4\')\n        self.conv2d_relu(self.avgpool4, 28, \'conv5_1\')\n        self.conv2d_relu(self.conv5_1, 30, \'conv5_2\')\n        self.conv2d_relu(self.conv5_2, 32, \'conv5_3\')\n        self.conv2d_relu(self.conv5_3, 34, \'conv5_4\')\n        self.avgpool(self.conv5_4, \'avgpool5\')'"
assignments/02_style_transfer/load_vgg_sol.py,8,"b'"""""" Load VGGNet weights needed for the implementation in TensorFlow\nof the paper A Neural Algorithm of Artistic Style (Gatys et al., 2016) \n\nCreated by Chip Huyen (chiphuyen@cs.stanford.edu)\nCS20: ""TensorFlow for Deep Learning Research""\ncs20.stanford.edu\n\nFor more details, please read the assignment handout:\n\n""""""\nimport numpy as np\nimport scipy.io\nimport tensorflow as tf\n\nimport utils\n\n# VGG-19 parameters file\nVGG_DOWNLOAD_LINK = \'http://www.vlfeat.org/matconvnet/models/imagenet-vgg-verydeep-19.mat\'\nVGG_FILENAME = \'imagenet-vgg-verydeep-19.mat\'\nEXPECTED_BYTES = 534904783\n\nclass VGG(object):\n    def __init__(self, input_img):\n        utils.download(VGG_DOWNLOAD_LINK, VGG_FILENAME, EXPECTED_BYTES)\n        self.vgg_layers = scipy.io.loadmat(VGG_FILENAME)[\'layers\']\n        self.input_img = input_img\n        self.mean_pixels = np.array([123.68, 116.779, 103.939]).reshape((1,1,1,3))\n\n    def _weights(self, layer_idx, expected_layer_name):\n        """""" Return the weights and biases at layer_idx already trained by VGG\n        """"""\n        W = self.vgg_layers[0][layer_idx][0][0][2][0][0]\n        b = self.vgg_layers[0][layer_idx][0][0][2][0][1]\n        layer_name = self.vgg_layers[0][layer_idx][0][0][0][0]\n        assert layer_name == expected_layer_name\n        return W, b.reshape(b.size)\n\n    def conv2d_relu(self, prev_layer, layer_idx, layer_name):\n        """""" Return the Conv2D layer with RELU using the weights, \n        biases from the VGG model at \'layer_idx\'.\n        Don\'t forget to apply relu to the output from the convolution.\n        Inputs:\n            prev_layer: the output tensor from the previous layer\n            layer_idx: the index to current layer in vgg_layers\n            layer_name: the string that is the name of the current layer.\n                        It\'s used to specify variable_scope.\n\n\n        Note that you first need to obtain W and b from from the corresponding VGG\'s layer \n        using the function _weights() defined above.\n        W and b returned from _weights() are numpy arrays, so you have\n        to convert them to TF tensors. One way to do it is with tf.constant.\n\n        Hint for choosing strides size: \n            for small images, you probably don\'t want to skip any pixel\n        """"""\n        ###############################\n        ## TO DO\n        with tf.variable_scope(layer_name) as scope:\n            W, b = self._weights(layer_idx, layer_name)\n            W = tf.constant(W, name=\'weights\')\n            b = tf.constant(b, name=\'bias\')\n            conv2d = tf.nn.conv2d(prev_layer, \n                                filter=W, \n                                strides=[1, 1, 1, 1], \n                                padding=\'SAME\')\n            out = tf.nn.relu(conv2d + b)\n        ###############################\n        setattr(self, layer_name, out)\n\n    def avgpool(self, prev_layer, layer_name):\n        """""" Return the average pooling layer. The paper suggests that \n        average pooling works better than max pooling.\n        Input:\n            prev_layer: the output tensor from the previous layer\n            layer_name: the string that you want to name the layer.\n                        It\'s used to specify variable_scope.\n\n        Hint for choosing strides and kszie: choose what you feel appropriate\n        """"""\n        ###############################\n        ## TO DO\n        with tf.variable_scope(layer_name):\n            out = tf.nn.avg_pool(prev_layer, \n                                ksize=[1, 2, 2, 1], \n                                strides=[1, 2, 2, 1],\n                                padding=\'SAME\')\n        ###############################\n        setattr(self, layer_name, out)\n\n    def load(self):\n        self.conv2d_relu(self.input_img, 0, \'conv1_1\')\n        self.conv2d_relu(self.conv1_1, 2, \'conv1_2\')\n        self.avgpool(self.conv1_2, \'avgpool1\')\n        self.conv2d_relu(self.avgpool1, 5, \'conv2_1\')\n        self.conv2d_relu(self.conv2_1, 7, \'conv2_2\')\n        self.avgpool(self.conv2_2, \'avgpool2\')\n        self.conv2d_relu(self.avgpool2, 10, \'conv3_1\')\n        self.conv2d_relu(self.conv3_1, 12, \'conv3_2\')\n        self.conv2d_relu(self.conv3_2, 14, \'conv3_3\')\n        self.conv2d_relu(self.conv3_3, 16, \'conv3_4\')\n        self.avgpool(self.conv3_4, \'avgpool3\')\n        self.conv2d_relu(self.avgpool3, 19, \'conv4_1\')\n        self.conv2d_relu(self.conv4_1, 21, \'conv4_2\')\n        self.conv2d_relu(self.conv4_2, 23, \'conv4_3\')\n        self.conv2d_relu(self.conv4_3, 25, \'conv4_4\')\n        self.avgpool(self.conv4_4, \'avgpool4\')\n        self.conv2d_relu(self.avgpool4, 28, \'conv5_1\')\n        self.conv2d_relu(self.conv5_1, 30, \'conv5_2\')\n        self.conv2d_relu(self.conv5_2, 32, \'conv5_3\')\n        self.conv2d_relu(self.conv5_3, 34, \'conv5_4\')\n        self.avgpool(self.conv5_4, \'avgpool5\')'"
assignments/02_style_transfer/style_transfer.py,8,"b'"""""" Implementation in TensorFlow of the paper \nA Neural Algorithm of Artistic Style (Gatys et al., 2016) \n\nCreated by Chip Huyen (chiphuyen@cs.stanford.edu)\nCS20: ""TensorFlow for Deep Learning Research""\ncs20.stanford.edu\n\nFor more details, please read the assignment handout:\nhttps://docs.google.com/document/d/1FpueD-3mScnD0SJQDtwmOb1FrSwo1NGowkXzMwPoLH4/edit?usp=sharing\n""""""\nimport os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\nimport time\n\nimport numpy as np\nimport tensorflow as tf\n\nimport load_vgg\nimport utils\n\ndef setup():\n    utils.safe_mkdir(\'checkpoints\')\n    utils.safe_mkdir(\'outputs\')\n\nclass StyleTransfer(object):\n    def __init__(self, content_img, style_img, img_width, img_height):\n        \'\'\'\n        img_width and img_height are the dimensions we expect from the generated image.\n        We will resize input content image and input style image to match this dimension.\n        Feel free to alter any hyperparameter here and see how it affects your training.\n        \'\'\'\n        self.img_width = img_width\n        self.img_height = img_height\n        self.content_img = utils.get_resized_image(content_img, img_width, img_height)\n        self.style_img = utils.get_resized_image(style_img, img_width, img_height)\n        self.initial_img = utils.generate_noise_image(self.content_img, img_width, img_height)\n\n        ###############################\n        ## TO DO\n        ## create global step (gstep) and hyperparameters for the model\n        self.content_layer = \'conv4_2\'\n        self.style_layers = [\'conv1_1\', \'conv2_1\', \'conv3_1\', \'conv4_1\', \'conv5_1\']\n        # content_w, style_w: corresponding weights for content loss and style loss\n        self.content_w = None\n        self.style_w = None\n        # style_layer_w: weights for different style layers. deep layers have more weights\n        self.style_layer_w = [0.5, 1.0, 1.5, 3.0, 4.0] \n        self.gstep = None # global step\n        self.lr = None\n        ###############################\n\n    def create_input(self):\n        \'\'\'\n        We will use one input_img as a placeholder for the content image, \n        style image, and generated image, because:\n            1. they have the same dimension\n            2. we have to extract the same set of features from them\n        We use a variable instead of a placeholder because we\'re, at the same time, \n        training the generated image to get the desirable result.\n\n        Note: image height corresponds to number of rows, not columns.\n        \'\'\'\n        with tf.variable_scope(\'input\') as scope:\n            self.input_img = tf.get_variable(\'in_img\', \n                                        shape=([1, self.img_height, self.img_width, 3]),\n                                        dtype=tf.float32,\n                                        initializer=tf.zeros_initializer())\n    def load_vgg(self):\n        \'\'\'\n        Load the saved model parameters of VGG-19, using the input_img\n        as the input to compute the output at each layer of vgg.\n\n        During training, VGG-19 mean-centered all images and found the mean pixels\n        to be [123.68, 116.779, 103.939] along RGB dimensions. We have to subtract\n        this mean from our images.\n\n        \'\'\'\n        self.vgg = load_vgg.VGG(self.input_img)\n        self.vgg.load()\n        self.content_img -= self.vgg.mean_pixels\n        self.style_img -= self.vgg.mean_pixels\n\n    def _content_loss(self, P, F):\n        \'\'\' Calculate the loss between the feature representation of the\n        content image and the generated image.\n        \n        Inputs: \n            P: content representation of the content image\n            F: content representation of the generated image\n            Read the assignment handout for more details\n\n            Note: Don\'t use the coefficient 0.5 as defined in the paper.\n            Use the coefficient defined in the assignment handout.\n        \'\'\'\n        ###############################\n        ## TO DO\n        self.content_loss = None\n        ###############################\n        \n    def _gram_matrix(self, F, N, M):\n        """""" Create and return the gram matrix for tensor F\n            Hint: you\'ll first have to reshape F\n        """"""\n        ###############################\n        ## TO DO\n        return None\n        ###############################\n\n    def _single_style_loss(self, a, g):\n        """""" Calculate the style loss at a certain layer\n        Inputs:\n            a is the feature representation of the style image at that layer\n            g is the feature representation of the generated image at that layer\n        Output:\n            the style loss at a certain layer (which is E_l in the paper)\n\n        Hint: 1. you\'ll have to use the function _gram_matrix()\n            2. we\'ll use the same coefficient for style loss as in the paper\n            3. a and g are feature representation, not gram matrices\n        """"""\n        ###############################\n        ## TO DO\n        return None\n        ###############################\n\n    def _style_loss(self, A):\n        """""" Calculate the total style loss as a weighted sum \n        of style losses at all style layers\n        Hint: you\'ll have to use _single_style_loss()\n        """"""\n        ###############################\n        ## TO DO\n        self.style_loss = None\n        ###############################\n\n    def losses(self):\n        with tf.variable_scope(\'losses\') as scope:\n            with tf.Session() as sess:\n                # assign content image to the input variable\n                sess.run(self.input_img.assign(self.content_img)) \n                gen_img_content = getattr(self.vgg, self.content_layer)\n                content_img_content = sess.run(gen_img_content)\n            self._content_loss(content_img_content, gen_img_content)\n\n            with tf.Session() as sess:\n                sess.run(self.input_img.assign(self.style_img))\n                style_layers = sess.run([getattr(self.vgg, layer) for layer in self.style_layers])                              \n            self._style_loss(style_layers)\n\n            ##########################################\n            ## TO DO: create total loss. \n            ## Hint: don\'t forget the weights for the content loss and style loss\n            self.total_loss = None\n            ##########################################\n\n    def optimize(self):\n        ###############################\n        ## TO DO: create optimizer\n        self.opt = None\n        ###############################\n\n    def create_summary(self):\n        ###############################\n        ## TO DO: create summaries for all the losses\n        ## Hint: don\'t forget to merge them\n        self.summary_op = None\n        ###############################\n\n\n    def build(self):\n        self.create_input()\n        self.load_vgg()\n        self.losses()\n        self.optimize()\n        self.create_summary()\n\n    def train(self, n_iters):\n        skip_step = 1\n        with tf.Session() as sess:\n            \n            ###############################\n            ## TO DO: \n            ## 1. initialize your variables\n            ## 2. create writer to write your grapp\n            ###############################\n            \n            sess.run(self.input_img.assign(self.initial_img))\n\n            ###############################\n            ## TO DO: \n            ## 1. create a saver object\n            ## 2. check if a checkpoint exists, restore the variables\n            ##############################\n\n            initial_step = self.gstep.eval()\n            \n            start_time = time.time()\n            for index in range(initial_step, n_iters):\n                if index >= 5 and index < 20:\n                    skip_step = 10\n                elif index >= 20:\n                    skip_step = 20\n                \n                sess.run(self.opt)\n                if (index + 1) % skip_step == 0:\n                    ###############################\n                    ## TO DO: obtain generated image, loss, and summary\n                    gen_image, total_loss, summary = None, None, None\n                    ###############################\n                    \n                    # add back the mean pixels we subtracted before\n                    gen_image = gen_image + self.vgg.mean_pixels \n                    writer.add_summary(summary, global_step=index)\n                    print(\'Step {}\\n   Sum: {:5.1f}\'.format(index + 1, np.sum(gen_image)))\n                    print(\'   Loss: {:5.1f}\'.format(total_loss))\n                    print(\'   Took: {} seconds\'.format(time.time() - start_time))\n                    start_time = time.time()\n\n                    filename = \'outputs/%d.png\' % (index)\n                    utils.save_image(filename, gen_image)\n\n                    if (index + 1) % 20 == 0:\n                        ###############################\n                        ## TO DO: save the variables into a checkpoint\n                        ###############################\n                        pass\n\nif __name__ == \'__main__\':\n    setup()\n    machine = StyleTransfer(\'content/deadpool.jpg\', \'styles/guernica.jpg\', 333, 250)\n    machine.build()\n    machine.train(300)'"
assignments/02_style_transfer/style_transfer_sol.py,23,"b'import os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\nimport time\n\nimport numpy as np\nimport tensorflow as tf\n\nimport load_vgg_sol\nimport utils\n\ndef setup():\n    utils.safe_mkdir(\'checkpoints\')\n    utils.safe_mkdir(\'outputs\')\n\nclass StyleTransfer(object):\n    def __init__(self, content_img, style_img, img_width, img_height):\n        \'\'\'\n        img_width and img_height are the dimensions we expect from the generated image.\n        We will resize input content image and input style image to match this dimension.\n        Feel free to alter any hyperparameter here and see how it affects your training.\n        \'\'\'\n        self.img_width = img_width\n        self.img_height = img_height\n        self.content_img = utils.get_resized_image(content_img, img_width, img_height)\n        self.style_img = utils.get_resized_image(style_img, img_width, img_height)\n        self.initial_img = utils.generate_noise_image(self.content_img, img_width, img_height)\n\n        ###############################\n        ## TO DO\n        ## create global step (gstep) and hyperparameters for the model\n        self.content_layer = \'conv4_2\'\n        self.style_layers = [\'conv1_1\', \'conv2_1\', \'conv3_1\', \'conv4_1\', \'conv5_1\']\n        self.content_w = 0.01\n        self.style_w = 1\n        self.style_layer_w = [0.5, 1.0, 1.5, 3.0, 4.0] \n        self.gstep = tf.Variable(0, dtype=tf.int32, \n                                trainable=False, name=\'global_step\')\n        self.lr = 2.0\n        ###############################\n\n    def create_input(self):\n        \'\'\'\n        We will use one input_img as a placeholder for the content image, \n        style image, and generated image, because:\n            1. they have the same dimension\n            2. we have to extract the same set of features from them\n        We use a variable instead of a placeholder because we\'re, at the same time, \n        training the generated image to get the desirable result.\n\n        Note: image height corresponds to number of rows, not columns.\n        \'\'\'\n        with tf.variable_scope(\'input\') as scope:\n            self.input_img = tf.get_variable(\'in_img\', \n                                        shape=([1, self.img_height, self.img_width, 3]),\n                                        dtype=tf.float32,\n                                        initializer=tf.zeros_initializer())\n    def load_vgg(self):\n        \'\'\'\n        Load the saved model parameters of VGG-19, using the input_img\n        as the input to compute the output at each layer of vgg.\n\n        During training, VGG-19 mean-centered all images and found the mean pixels\n        to be [123.68, 116.779, 103.939] along RGB dimensions. We have to subtract\n        this mean from our images.\n\n        \'\'\'\n        self.vgg = load_vgg_sol.VGG(self.input_img)\n        self.vgg.load()\n        self.content_img -= self.vgg.mean_pixels\n        self.style_img -= self.vgg.mean_pixels\n\n    def _content_loss(self, P, F):\n        \'\'\' Calculate the loss between the feature representation of the\n        content image and the generated image.\n        \n        Inputs: \n            P: content representation of the content image\n            F: content representation of the generated image\n            Read the assignment handout for more details\n\n            Note: Don\'t use the coefficient 0.5 as defined in the paper.\n            Use the coefficient defined in the assignment handout.\n        \'\'\'\n        # self.content_loss = None\n        ###############################\n        ## TO DO\n        self.content_loss = tf.reduce_sum((F - P) ** 2) / (4.0 * P.size)\n        ###############################\n    \n    def _gram_matrix(self, F, N, M):\n        """""" Create and return the gram matrix for tensor F\n            Hint: you\'ll first have to reshape F\n        """"""\n        ###############################\n        ## TO DO\n        F = tf.reshape(F, (M, N))\n        return tf.matmul(tf.transpose(F), F)\n        ###############################\n\n    def _single_style_loss(self, a, g):\n        """""" Calculate the style loss at a certain layer\n        Inputs:\n            a is the feature representation of the style image at that layer\n            g is the feature representation of the generated image at that layer\n        Output:\n            the style loss at a certain layer (which is E_l in the paper)\n\n        Hint: 1. you\'ll have to use the function _gram_matrix()\n            2. we\'ll use the same coefficient for style loss as in the paper\n            3. a and g are feature representation, not gram matrices\n        """"""\n        ###############################\n        ## TO DO\n        N = a.shape[3] # number of filters\n        M = a.shape[1] * a.shape[2] # height times width of the feature map\n        A = self._gram_matrix(a, N, M)\n        G = self._gram_matrix(g, N, M)\n        return tf.reduce_sum((G - A) ** 2 / ((2 * N * M) ** 2))\n        ###############################\n\n    def _style_loss(self, A):\n        """""" Calculate the total style loss as a weighted sum \n        of style losses at all style layers\n        Hint: you\'ll have to use _single_style_loss()\n        """"""\n        n_layers = len(A)\n        E = [self._single_style_loss(A[i], getattr(self.vgg, self.style_layers[i])) for i in range(n_layers)]\n        \n        ###############################\n        ## TO DO\n        self.style_loss = sum([self.style_layer_w[i] * E[i] for i in range(n_layers)])\n        ###############################\n\n    def losses(self):\n        with tf.variable_scope(\'losses\') as scope:\n            with tf.Session() as sess:\n                # assign content image to the input variable\n                sess.run(self.input_img.assign(self.content_img)) \n                gen_img_content = getattr(self.vgg, self.content_layer)\n                content_img_content = sess.run(gen_img_content)\n            self._content_loss(content_img_content, gen_img_content)\n\n            with tf.Session() as sess:\n                sess.run(self.input_img.assign(self.style_img))\n                style_layers = sess.run([getattr(self.vgg, layer) for layer in self.style_layers])                              \n            self._style_loss(style_layers)\n\n            ##########################################\n            ## TO DO: create total loss. \n            ## Hint: don\'t forget the weights for the content loss and style loss\n            self.total_loss = self.content_w * self.content_loss + self.style_w * self.style_loss\n            ##########################################\n\n    def optimize(self):\n        ###############################\n        ## TO DO: create optimizer\n        self.opt = tf.train.AdamOptimizer(self.lr).minimize(self.total_loss,\n                                                            global_step=self.gstep)\n        ###############################\n\n    def create_summary(self):\n        ###############################\n        ## TO DO: create summaries for all the losses\n        ## Hint: don\'t forget to merge them\n        with tf.name_scope(\'summaries\'):\n            tf.summary.scalar(\'content loss\', self.content_loss)\n            tf.summary.scalar(\'style loss\', self.style_loss)\n            tf.summary.scalar(\'total loss\', self.total_loss)\n            self.summary_op = tf.summary.merge_all()\n        ###############################\n\n\n    def build(self):\n        self.create_input()\n        self.load_vgg()\n        self.losses()\n        self.optimize()\n        self.create_summary()\n\n    def train(self, n_iters):\n        skip_step = 1\n        with tf.Session() as sess:\n            \n            ###############################\n            ## TO DO: \n            ## 1. initialize your variables\n            ## 2. create writer to write your graph\n            sess.run(tf.global_variables_initializer())\n            writer = tf.summary.FileWriter(\'graphs/style_stranfer\', sess.graph)\n            ###############################\n            sess.run(self.input_img.assign(self.initial_img))\n\n\n            ###############################\n            ## TO DO: \n            ## 1. create a saver object\n            ## 2. check if a checkpoint exists, restore the variables\n            saver = tf.train.Saver()\n            ckpt = tf.train.get_checkpoint_state(os.path.dirname(\'checkpoints/style_transfer/checkpoint\'))\n            if ckpt and ckpt.model_checkpoint_path:\n                saver.restore(sess, ckpt.model_checkpoint_path)\n            ##############################\n\n            initial_step = self.gstep.eval()\n            \n            start_time = time.time()\n            for index in range(initial_step, n_iters):\n                if index >= 5 and index < 20:\n                    skip_step = 10\n                elif index >= 20:\n                    skip_step = 20\n                \n                sess.run(self.opt)\n                if (index + 1) % skip_step == 0:\n                    ###############################\n                    ## TO DO: obtain generated image, loss, and summary\n                    gen_image, total_loss, summary = sess.run([self.input_img,\n                                                                self.total_loss,\n                                                                self.summary_op])\n\n                    ###############################\n                    \n                    # add back the mean pixels we subtracted before\n                    gen_image = gen_image + self.vgg.mean_pixels \n                    writer.add_summary(summary, global_step=index)\n                    print(\'Step {}\\n   Sum: {:5.1f}\'.format(index + 1, np.sum(gen_image)))\n                    print(\'   Loss: {:5.1f}\'.format(total_loss))\n                    print(\'   Took: {} seconds\'.format(time.time() - start_time))\n                    start_time = time.time()\n\n                    filename = \'outputs/%d.png\' % (index)\n                    utils.save_image(filename, gen_image)\n\n                    if (index + 1) % 20 == 0:\n                        ###############################\n                        ## TO DO: save the variables into a checkpoint\n                        saver.save(sess, \'checkpoints/style_stranfer/style_transfer\', index)\n                        ###############################\n\nif __name__ == \'__main__\':\n    setup()\n    machine = StyleTransfer(\'content/deadpool.jpg\', \'styles/guernica.jpg\', 333, 250)\n    machine.build()\n    machine.train(300)'"
assignments/02_style_transfer/utils.py,0,"b'"""""" Utils needed for the implementation in TensorFlow\nof the paper A Neural Algorithm of Artistic Style (Gatys et al., 2016) \n\nCreated by Chip Huyen (chiphuyen@cs.stanford.edu)\nCS20: ""TensorFlow for Deep Learning Research""\ncs20.stanford.edu\n\nFor more details, please read the assignment handout:\nhttps://docs.google.com/document/d/1FpueD-3mScnD0SJQDtwmOb1FrSwo1NGowkXzMwPoLH4/edit?usp=sharing\n\n""""""\n\nimport os\n\nfrom PIL import Image, ImageOps\nimport numpy as np\nimport scipy.misc\nfrom six.moves import urllib\n\ndef download(download_link, file_name, expected_bytes):\n    """""" Download the pretrained VGG-19 model if it\'s not already downloaded """"""\n    if os.path.exists(file_name):\n        print(""VGG-19 pre-trained model is ready"")\n        return\n    print(""Downloading the VGG pre-trained model. This might take a while ..."")\n    file_name, _ = urllib.request.urlretrieve(download_link, file_name)\n    file_stat = os.stat(file_name)\n    if file_stat.st_size == expected_bytes:\n        print(\'Successfully downloaded VGG-19 pre-trained model\', file_name)\n    else:\n        raise Exception(\'File \' + file_name +\n                        \' might be corrupted. You should try downloading it with a browser.\')\n\ndef get_resized_image(img_path, width, height, save=True):\n    image = Image.open(img_path)\n    # PIL is column major so you have to swap the places of width and height\n    image = ImageOps.fit(image, (width, height), Image.ANTIALIAS)\n    if save:\n        image_dirs = img_path.split(\'/\')\n        image_dirs[-1] = \'resized_\' + image_dirs[-1]\n        out_path = \'/\'.join(image_dirs)\n        if not os.path.exists(out_path):\n            image.save(out_path)\n    image = np.asarray(image, np.float32)\n    return np.expand_dims(image, 0)\n\ndef generate_noise_image(content_image, width, height, noise_ratio=0.6):\n    noise_image = np.random.uniform(-20, 20, (1, height, width, 3)).astype(np.float32)\n    return noise_image * noise_ratio + content_image * (1 - noise_ratio)\n\ndef save_image(path, image):\n    image = image[0]\n    image = np.clip(image, 0, 255).astype(\'uint8\')\n    scipy.misc.imsave(path, image)\n\ndef safe_mkdir(path):\n    """""" Create a directory if there isn\'t one already. """"""\n    try:\n        os.mkdir(path)\n    except OSError:\n        pass'"
assignments/chatbot/chatbot.py,8,"b'"""""" A neural chatbot using sequence to sequence model with\nattentional decoder. \n\nThis is based on Google Translate Tensorflow model \nhttps://github.com/tensorflow/models/blob/master/tutorials/rnn/translate/\n\nSequence to sequence model by Cho et al.(2014)\n\nCreated by Chip Huyen (chiphuyen@cs.stanford.edu)\nCS20: ""TensorFlow for Deep Learning Research""\ncs20.stanford.edu\n\nThis file contains the code to run the model.\n\nSee README.md for instruction on how to run the starter code.\n""""""\nimport argparse\nimport os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\nimport random\nimport sys\nimport time\n\nimport numpy as np\nimport tensorflow as tf\n\nfrom model import ChatBotModel\nimport config\nimport data\n\ndef _get_random_bucket(train_buckets_scale):\n    """""" Get a random bucket from which to choose a training sample """"""\n    rand = random.random()\n    return min([i for i in range(len(train_buckets_scale))\n                if train_buckets_scale[i] > rand])\n\ndef _assert_lengths(encoder_size, decoder_size, encoder_inputs, decoder_inputs, decoder_masks):\n    """""" Assert that the encoder inputs, decoder inputs, and decoder masks are\n    of the expected lengths """"""\n    if len(encoder_inputs) != encoder_size:\n        raise ValueError(""Encoder length must be equal to the one in bucket,""\n                        "" %d != %d."" % (len(encoder_inputs), encoder_size))\n    if len(decoder_inputs) != decoder_size:\n        raise ValueError(""Decoder length must be equal to the one in bucket,""\n                       "" %d != %d."" % (len(decoder_inputs), decoder_size))\n    if len(decoder_masks) != decoder_size:\n        raise ValueError(""Weights length must be equal to the one in bucket,""\n                       "" %d != %d."" % (len(decoder_masks), decoder_size))\n\ndef run_step(sess, model, encoder_inputs, decoder_inputs, decoder_masks, bucket_id, forward_only):\n    """""" Run one step in training.\n    @forward_only: boolean value to decide whether a backward path should be created\n    forward_only is set to True when you just want to evaluate on the test set,\n    or when you want to the bot to be in chat mode. """"""\n    encoder_size, decoder_size = config.BUCKETS[bucket_id]\n    _assert_lengths(encoder_size, decoder_size, encoder_inputs, decoder_inputs, decoder_masks)\n\n    # input feed: encoder inputs, decoder inputs, target_weights, as provided.\n    input_feed = {}\n    for step in range(encoder_size):\n        input_feed[model.encoder_inputs[step].name] = encoder_inputs[step]\n    for step in range(decoder_size):\n        input_feed[model.decoder_inputs[step].name] = decoder_inputs[step]\n        input_feed[model.decoder_masks[step].name] = decoder_masks[step]\n\n    last_target = model.decoder_inputs[decoder_size].name\n    input_feed[last_target] = np.zeros([model.batch_size], dtype=np.int32)\n\n    # output feed: depends on whether we do a backward step or not.\n    if not forward_only:\n        output_feed = [model.train_ops[bucket_id],  # update op that does SGD.\n                       model.gradient_norms[bucket_id],  # gradient norm.\n                       model.losses[bucket_id]]  # loss for this batch.\n    else:\n        output_feed = [model.losses[bucket_id]]  # loss for this batch.\n        for step in range(decoder_size):  # output logits.\n            output_feed.append(model.outputs[bucket_id][step])\n\n    outputs = sess.run(output_feed, input_feed)\n    if not forward_only:\n        return outputs[1], outputs[2], None  # Gradient norm, loss, no outputs.\n    else:\n        return None, outputs[0], outputs[1:]  # No gradient norm, loss, outputs.\n\ndef _get_buckets():\n    """""" Load the dataset into buckets based on their lengths.\n    train_buckets_scale is the inverval that\'ll help us \n    choose a random bucket later on.\n    """"""\n    test_buckets = data.load_data(\'test_ids.enc\', \'test_ids.dec\')\n    data_buckets = data.load_data(\'train_ids.enc\', \'train_ids.dec\')\n    train_bucket_sizes = [len(data_buckets[b]) for b in range(len(config.BUCKETS))]\n    print(""Number of samples in each bucket:\\n"", train_bucket_sizes)\n    train_total_size = sum(train_bucket_sizes)\n    # list of increasing numbers from 0 to 1 that we\'ll use to select a bucket.\n    train_buckets_scale = [sum(train_bucket_sizes[:i + 1]) / train_total_size\n                           for i in range(len(train_bucket_sizes))]\n    print(""Bucket scale:\\n"", train_buckets_scale)\n    return test_buckets, data_buckets, train_buckets_scale\n\ndef _get_skip_step(iteration):\n    """""" How many steps should the model train before it saves all the weights. """"""\n    if iteration < 100:\n        return 30\n    return 100\n\ndef _check_restore_parameters(sess, saver):\n    """""" Restore the previously trained parameters if there are any. """"""\n    ckpt = tf.train.get_checkpoint_state(os.path.dirname(config.CPT_PATH + \'/checkpoint\'))\n    if ckpt and ckpt.model_checkpoint_path:\n        print(""Loading parameters for the Chatbot"")\n        saver.restore(sess, ckpt.model_checkpoint_path)\n    else:\n        print(""Initializing fresh parameters for the Chatbot"")\n\ndef _eval_test_set(sess, model, test_buckets):\n    """""" Evaluate on the test set. """"""\n    for bucket_id in range(len(config.BUCKETS)):\n        if len(test_buckets[bucket_id]) == 0:\n            print(""  Test: empty bucket %d"" % (bucket_id))\n            continue\n        start = time.time()\n        encoder_inputs, decoder_inputs, decoder_masks = data.get_batch(test_buckets[bucket_id], \n                                                                        bucket_id,\n                                                                        batch_size=config.BATCH_SIZE)\n        _, step_loss, _ = run_step(sess, model, encoder_inputs, decoder_inputs, \n                                   decoder_masks, bucket_id, True)\n        print(\'Test bucket {}: loss {}, time {}\'.format(bucket_id, step_loss, time.time() - start))\n\ndef train():\n    """""" Train the bot """"""\n    test_buckets, data_buckets, train_buckets_scale = _get_buckets()\n    # in train mode, we need to create the backward path, so forwrad_only is False\n    model = ChatBotModel(False, config.BATCH_SIZE)\n    model.build_graph()\n\n    saver = tf.train.Saver()\n\n    with tf.Session() as sess:\n        print(\'Running session\')\n        sess.run(tf.global_variables_initializer())\n        _check_restore_parameters(sess, saver)\n\n        iteration = model.global_step.eval()\n        total_loss = 0\n        while True:\n            skip_step = _get_skip_step(iteration)\n            bucket_id = _get_random_bucket(train_buckets_scale)\n            encoder_inputs, decoder_inputs, decoder_masks = data.get_batch(data_buckets[bucket_id], \n                                                                           bucket_id,\n                                                                           batch_size=config.BATCH_SIZE)\n            start = time.time()\n            _, step_loss, _ = run_step(sess, model, encoder_inputs, decoder_inputs, decoder_masks, bucket_id, False)\n            total_loss += step_loss\n            iteration += 1\n\n            if iteration % skip_step == 0:\n                print(\'Iter {}: loss {}, time {}\'.format(iteration, total_loss/skip_step, time.time() - start))\n                start = time.time()\n                total_loss = 0\n                saver.save(sess, os.path.join(config.CPT_PATH, \'chatbot\'), global_step=model.global_step)\n                if iteration % (10 * skip_step) == 0:\n                    # Run evals on development set and print their loss\n                    _eval_test_set(sess, model, test_buckets)\n                    start = time.time()\n                sys.stdout.flush()\n\ndef _get_user_input():\n    """""" Get user\'s input, which will be transformed into encoder input later """"""\n    print(""> "", end="""")\n    sys.stdout.flush()\n    return sys.stdin.readline()\n\ndef _find_right_bucket(length):\n    """""" Find the proper bucket for an encoder input based on its length """"""\n    return min([b for b in range(len(config.BUCKETS))\n                if config.BUCKETS[b][0] >= length])\n\ndef _construct_response(output_logits, inv_dec_vocab):\n    """""" Construct a response to the user\'s encoder input.\n    @output_logits: the outputs from sequence to sequence wrapper.\n    output_logits is decoder_size np array, each of dim 1 x DEC_VOCAB\n    \n    This is a greedy decoder - outputs are just argmaxes of output_logits.\n    """"""\n    print(output_logits[0])\n    outputs = [int(np.argmax(logit, axis=1)) for logit in output_logits]\n    # If there is an EOS symbol in outputs, cut them at that point.\n    if config.EOS_ID in outputs:\n        outputs = outputs[:outputs.index(config.EOS_ID)]\n    # Print out sentence corresponding to outputs.\n    return "" "".join([tf.compat.as_str(inv_dec_vocab[output]) for output in outputs])\n\ndef chat():\n    """""" in test mode, we don\'t to create the backward path\n    """"""\n    _, enc_vocab = data.load_vocab(os.path.join(config.PROCESSED_PATH, \'vocab.enc\'))\n    inv_dec_vocab, _ = data.load_vocab(os.path.join(config.PROCESSED_PATH, \'vocab.dec\'))\n\n    model = ChatBotModel(True, batch_size=1)\n    model.build_graph()\n\n    saver = tf.train.Saver()\n\n    with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n        _check_restore_parameters(sess, saver)\n        output_file = open(os.path.join(config.PROCESSED_PATH, config.OUTPUT_FILE), \'a+\')\n        # Decode from standard input.\n        max_length = config.BUCKETS[-1][0]\n        print(\'Welcome to TensorBro. Say something. Enter to exit. Max length is\', max_length)\n        while True:\n            line = _get_user_input()\n            if len(line) > 0 and line[-1] == \'\\n\':\n                line = line[:-1]\n            if line == \'\':\n                break\n            output_file.write(\'HUMAN ++++ \' + line + \'\\n\')\n            # Get token-ids for the input sentence.\n            token_ids = data.sentence2id(enc_vocab, str(line))\n            if (len(token_ids) > max_length):\n                print(\'Max length I can handle is:\', max_length)\n                line = _get_user_input()\n                continue\n            # Which bucket does it belong to?\n            bucket_id = _find_right_bucket(len(token_ids))\n            # Get a 1-element batch to feed the sentence to the model.\n            encoder_inputs, decoder_inputs, decoder_masks = data.get_batch([(token_ids, [])], \n                                                                            bucket_id,\n                                                                            batch_size=1)\n            # Get output logits for the sentence.\n            _, _, output_logits = run_step(sess, model, encoder_inputs, decoder_inputs,\n                                           decoder_masks, bucket_id, True)\n            response = _construct_response(output_logits, inv_dec_vocab)\n            print(response)\n            output_file.write(\'BOT ++++ \' + response + \'\\n\')\n        output_file.write(\'=============================================\\n\')\n        output_file.close()\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'--mode\', choices={\'train\', \'chat\'},\n                        default=\'train\', help=""mode. if not specified, it\'s in the train mode"")\n    args = parser.parse_args()\n\n    if not os.path.isdir(config.PROCESSED_PATH):\n        data.prepare_raw_data()\n        data.process_data()\n    print(\'Data ready!\')\n    # create checkpoints folder if there isn\'t one already\n    data.make_dir(config.CPT_PATH)\n\n    if args.mode == \'train\':\n        train()\n    elif args.mode == \'chat\':\n        chat()\n\nif __name__ == \'__main__\':\n    main()\n'"
assignments/chatbot/config.py,0,"b'"""""" A neural chatbot using sequence to sequence model with\nattentional decoder. \n\nThis is based on Google Translate Tensorflow model \nhttps://github.com/tensorflow/models/blob/master/tutorials/rnn/translate/\n\nSequence to sequence model by Cho et al.(2014)\n\nCreated by Chip Huyen (chiphuyen@cs.stanford.edu)\nCS20: ""TensorFlow for Deep Learning Research""\ncs20.stanford.edu\n\nThis file contains the hyperparameters for the model.\n\nSee README.md for instruction on how to run the starter code.\n""""""\n\n# parameters for processing the dataset\nDATA_PATH = \'data/cornell movie-dialogs corpus\'\nCONVO_FILE = \'movie_conversations.txt\'\nLINE_FILE = \'movie_lines.txt\'\nOUTPUT_FILE = \'output_convo.txt\'\nPROCESSED_PATH = \'processed\'\nCPT_PATH = \'checkpoints\'\n\nTHRESHOLD = 2\n\nPAD_ID = 0\nUNK_ID = 1\nSTART_ID = 2\nEOS_ID = 3\n\nTESTSET_SIZE = 25000\n\nBUCKETS = [(19, 19), (28, 28), (33, 33), (40, 43), (50, 53), (60, 63)]\n\n\nCONTRACTIONS = [(""i \' m "", ""i \'m ""), (""\' d "", ""\'d ""), (""\' s "", ""\'s ""), \n\t\t\t\t(""don \' t "", ""do n\'t ""), (""didn \' t "", ""did n\'t ""), (""doesn \' t "", ""does n\'t ""),\n\t\t\t\t(""can \' t "", ""ca n\'t ""), (""shouldn \' t "", ""should n\'t ""), (""wouldn \' t "", ""would n\'t ""),\n\t\t\t\t(""\' ve "", ""\'ve ""), (""\' re "", ""\'re ""), (""in \' "", ""in\' "")]\n\nNUM_LAYERS = 3\nHIDDEN_SIZE = 256\nBATCH_SIZE = 64\n\nLR = 0.5\nMAX_GRAD_NORM = 5.0\n\nNUM_SAMPLES = 512\n'"
assignments/chatbot/data.py,0,"b'"""""" A neural chatbot using sequence to sequence model with\nattentional decoder. \n\nThis is based on Google Translate Tensorflow model \nhttps://github.com/tensorflow/models/blob/master/tutorials/rnn/translate/\n\nSequence to sequence model by Cho et al.(2014)\n\nCreated by Chip Huyen (chiphuyen@cs.stanford.edu)\nCS20: ""TensorFlow for Deep Learning Research""\ncs20.stanford.edu\n\nThis file contains the code to do the pre-processing for the\nCornell Movie-Dialogs Corpus.\n\nSee readme.md for instruction on how to run the starter code.\n""""""\nimport os\nimport random\nimport re\n\nimport numpy as np\n\nimport config\n\ndef get_lines():\n    id2line = {}\n    file_path = os.path.join(config.DATA_PATH, config.LINE_FILE)\n    print(config.LINE_FILE)\n    with open(file_path, \'r\', errors=\'ignore\') as f:\n        # lines = f.readlines()\n        # for line in lines:\n        i = 0\n        try:\n            for line in f:\n                parts = line.split(\' +++$+++ \')\n                if len(parts) == 5:\n                    if parts[4][-1] == \'\\n\':\n                        parts[4] = parts[4][:-1]\n                    id2line[parts[0]] = parts[4]\n                i += 1\n        except UnicodeDecodeError:\n            print(i, line)\n    return id2line\n\ndef get_convos():\n    """""" Get conversations from the raw data """"""\n    file_path = os.path.join(config.DATA_PATH, config.CONVO_FILE)\n    convos = []\n    with open(file_path, \'r\') as f:\n        for line in f.readlines():\n            parts = line.split(\' +++$+++ \')\n            if len(parts) == 4:\n                convo = []\n                for line in parts[3][1:-2].split(\', \'):\n                    convo.append(line[1:-1])\n                convos.append(convo)\n\n    return convos\n\ndef question_answers(id2line, convos):\n    """""" Divide the dataset into two sets: questions and answers. """"""\n    questions, answers = [], []\n    for convo in convos:\n        for index, line in enumerate(convo[:-1]):\n            questions.append(id2line[convo[index]])\n            answers.append(id2line[convo[index + 1]])\n    assert len(questions) == len(answers)\n    return questions, answers\n\ndef prepare_dataset(questions, answers):\n    # create path to store all the train & test encoder & decoder\n    make_dir(config.PROCESSED_PATH)\n    \n    # random convos to create the test set\n    test_ids = random.sample([i for i in range(len(questions))],config.TESTSET_SIZE)\n    \n    filenames = [\'train.enc\', \'train.dec\', \'test.enc\', \'test.dec\']\n    files = []\n    for filename in filenames:\n        files.append(open(os.path.join(config.PROCESSED_PATH, filename),\'w\'))\n\n    for i in range(len(questions)):\n        if i in test_ids:\n            files[2].write(questions[i] + \'\\n\')\n            files[3].write(answers[i] + \'\\n\')\n        else:\n            files[0].write(questions[i] + \'\\n\')\n            files[1].write(answers[i] + \'\\n\')\n\n    for file in files:\n        file.close()\n\ndef make_dir(path):\n    """""" Create a directory if there isn\'t one already. """"""\n    try:\n        os.mkdir(path)\n    except OSError:\n        pass\n\ndef basic_tokenizer(line, normalize_digits=True):\n    """""" A basic tokenizer to tokenize text into tokens.\n    Feel free to change this to suit your need. """"""\n    line = re.sub(\'<u>\', \'\', line)\n    line = re.sub(\'</u>\', \'\', line)\n    line = re.sub(\'\\[\', \'\', line)\n    line = re.sub(\'\\]\', \'\', line)\n    words = []\n    _WORD_SPLIT = re.compile(""([.,!?\\""\'-<>:;)(])"")\n    _DIGIT_RE = re.compile(r""\\d"")\n    for fragment in line.strip().lower().split():\n        for token in re.split(_WORD_SPLIT, fragment):\n            if not token:\n                continue\n            if normalize_digits:\n                token = re.sub(_DIGIT_RE, \'#\', token)\n            words.append(token)\n    return words\n\ndef build_vocab(filename, normalize_digits=True):\n    in_path = os.path.join(config.PROCESSED_PATH, filename)\n    out_path = os.path.join(config.PROCESSED_PATH, \'vocab.{}\'.format(filename[-3:]))\n\n    vocab = {}\n    with open(in_path, \'r\') as f:\n        for line in f.readlines():\n            for token in basic_tokenizer(line):\n                if not token in vocab:\n                    vocab[token] = 0\n                vocab[token] += 1\n\n    sorted_vocab = sorted(vocab, key=vocab.get, reverse=True)\n    with open(out_path, \'w\') as f:\n        f.write(\'<pad>\' + \'\\n\')\n        f.write(\'<unk>\' + \'\\n\')\n        f.write(\'<s>\' + \'\\n\')\n        f.write(\'<\\s>\' + \'\\n\') \n        index = 4\n        for word in sorted_vocab:\n            if vocab[word] < config.THRESHOLD:\n                break\n            f.write(word + \'\\n\')\n            index += 1\n        with open(\'config.py\', \'a\') as cf:\n            if filename[-3:] == \'enc\':\n                cf.write(\'ENC_VOCAB = \' + str(index) + \'\\n\')\n            else:\n                cf.write(\'DEC_VOCAB = \' + str(index) + \'\\n\')\n\ndef load_vocab(vocab_path):\n    with open(vocab_path, \'r\') as f:\n        words = f.read().splitlines()\n    return words, {words[i]: i for i in range(len(words))}\n\ndef sentence2id(vocab, line):\n    return [vocab.get(token, vocab[\'<unk>\']) for token in basic_tokenizer(line)]\n\ndef token2id(data, mode):\n    """""" Convert all the tokens in the data into their corresponding\n    index in the vocabulary. """"""\n    vocab_path = \'vocab.\' + mode\n    in_path = data + \'.\' + mode\n    out_path = data + \'_ids.\' + mode\n\n    _, vocab = load_vocab(os.path.join(config.PROCESSED_PATH, vocab_path))\n    in_file = open(os.path.join(config.PROCESSED_PATH, in_path), \'r\')\n    out_file = open(os.path.join(config.PROCESSED_PATH, out_path), \'w\')\n    \n    lines = in_file.read().splitlines()\n    for line in lines:\n        if mode == \'dec\': # we only care about \'<s>\' and </s> in encoder\n            ids = [vocab[\'<s>\']]\n        else:\n            ids = []\n        ids.extend(sentence2id(vocab, line))\n        # ids.extend([vocab.get(token, vocab[\'<unk>\']) for token in basic_tokenizer(line)])\n        if mode == \'dec\':\n            ids.append(vocab[\'<\\s>\'])\n        out_file.write(\' \'.join(str(id_) for id_ in ids) + \'\\n\')\n\ndef prepare_raw_data():\n    print(\'Preparing raw data into train set and test set ...\')\n    id2line = get_lines()\n    convos = get_convos()\n    questions, answers = question_answers(id2line, convos)\n    prepare_dataset(questions, answers)\n\ndef process_data():\n    print(\'Preparing data to be model-ready ...\')\n    build_vocab(\'train.enc\')\n    build_vocab(\'train.dec\')\n    token2id(\'train\', \'enc\')\n    token2id(\'train\', \'dec\')\n    token2id(\'test\', \'enc\')\n    token2id(\'test\', \'dec\')\n\ndef load_data(enc_filename, dec_filename, max_training_size=None):\n    encode_file = open(os.path.join(config.PROCESSED_PATH, enc_filename), \'r\')\n    decode_file = open(os.path.join(config.PROCESSED_PATH, dec_filename), \'r\')\n    encode, decode = encode_file.readline(), decode_file.readline()\n    data_buckets = [[] for _ in config.BUCKETS]\n    i = 0\n    while encode and decode:\n        if (i + 1) % 10000 == 0:\n            print(""Bucketing conversation number"", i)\n        encode_ids = [int(id_) for id_ in encode.split()]\n        decode_ids = [int(id_) for id_ in decode.split()]\n        for bucket_id, (encode_max_size, decode_max_size) in enumerate(config.BUCKETS):\n            if len(encode_ids) <= encode_max_size and len(decode_ids) <= decode_max_size:\n                data_buckets[bucket_id].append([encode_ids, decode_ids])\n                break\n        encode, decode = encode_file.readline(), decode_file.readline()\n        i += 1\n    return data_buckets\n\ndef _pad_input(input_, size):\n    return input_ + [config.PAD_ID] * (size - len(input_))\n\ndef _reshape_batch(inputs, size, batch_size):\n    """""" Create batch-major inputs. Batch inputs are just re-indexed inputs\n    """"""\n    batch_inputs = []\n    for length_id in range(size):\n        batch_inputs.append(np.array([inputs[batch_id][length_id]\n                                    for batch_id in range(batch_size)], dtype=np.int32))\n    return batch_inputs\n\n\ndef get_batch(data_bucket, bucket_id, batch_size=1):\n    """""" Return one batch to feed into the model """"""\n    # only pad to the max length of the bucket\n    encoder_size, decoder_size = config.BUCKETS[bucket_id]\n    encoder_inputs, decoder_inputs = [], []\n\n    for _ in range(batch_size):\n        encoder_input, decoder_input = random.choice(data_bucket)\n        # pad both encoder and decoder, reverse the encoder\n        encoder_inputs.append(list(reversed(_pad_input(encoder_input, encoder_size))))\n        decoder_inputs.append(_pad_input(decoder_input, decoder_size))\n\n    # now we create batch-major vectors from the data selected above.\n    batch_encoder_inputs = _reshape_batch(encoder_inputs, encoder_size, batch_size)\n    batch_decoder_inputs = _reshape_batch(decoder_inputs, decoder_size, batch_size)\n\n    # create decoder_masks to be 0 for decoders that are padding.\n    batch_masks = []\n    for length_id in range(decoder_size):\n        batch_mask = np.ones(batch_size, dtype=np.float32)\n        for batch_id in range(batch_size):\n            # we set mask to 0 if the corresponding target is a PAD symbol.\n            # the corresponding decoder is decoder_input shifted by 1 forward.\n            if length_id < decoder_size - 1:\n                target = decoder_inputs[batch_id][length_id + 1]\n            if length_id == decoder_size - 1 or target == config.PAD_ID:\n                batch_mask[batch_id] = 0.0\n        batch_masks.append(batch_mask)\n    return batch_encoder_inputs, batch_decoder_inputs, batch_masks\n\nif __name__ == \'__main__\':\n    prepare_raw_data()\n    process_data()'"
assignments/chatbot/model.py,20,"b'import time\n\nimport numpy as np\nimport tensorflow as tf\n\nimport config\n\nclass ChatBotModel:\n    def __init__(self, forward_only, batch_size):\n        """"""forward_only: if set, we do not construct the backward pass in the model.\n        """"""\n        print(\'Initialize new model\')\n        self.fw_only = forward_only\n        self.batch_size = batch_size\n\n    def _create_placeholders(self):\n        # Feeds for inputs. It\'s a list of placeholders\n        print(\'Create placeholders\')\n        self.encoder_inputs = [tf.placeholder(tf.int32, shape=[None], name=\'encoder{}\'.format(i))\n                               for i in range(config.BUCKETS[-1][0])]\n        self.decoder_inputs = [tf.placeholder(tf.int32, shape=[None], name=\'decoder{}\'.format(i))\n                               for i in range(config.BUCKETS[-1][1] + 1)]\n        self.decoder_masks = [tf.placeholder(tf.float32, shape=[None], name=\'mask{}\'.format(i))\n                              for i in range(config.BUCKETS[-1][1] + 1)]\n\n        # Our targets are decoder inputs shifted by one (to ignore <GO> symbol)\n        self.targets = self.decoder_inputs[1:]\n\n    def _inference(self):\n        print(\'Create inference\')\n        # If we use sampled softmax, we need an output projection.\n        # Sampled softmax only makes sense if we sample less than vocabulary size.\n        if config.NUM_SAMPLES > 0 and config.NUM_SAMPLES < config.DEC_VOCAB:\n            w = tf.get_variable(\'proj_w\', [config.HIDDEN_SIZE, config.DEC_VOCAB])\n            b = tf.get_variable(\'proj_b\', [config.DEC_VOCAB])\n            self.output_projection = (w, b)\n\n        def sampled_loss(logits, labels):\n            labels = tf.reshape(labels, [-1, 1])\n            return tf.nn.sampled_softmax_loss(weights=tf.transpose(w), \n                                              biases=b, \n                                              inputs=logits, \n                                              labels=labels, \n                                              num_sampled=config.NUM_SAMPLES, \n                                              num_classes=config.DEC_VOCAB)\n        self.softmax_loss_function = sampled_loss\n\n        single_cell = tf.contrib.rnn.GRUCell(config.HIDDEN_SIZE)\n        self.cell = tf.contrib.rnn.MultiRNNCell([single_cell for _ in range(config.NUM_LAYERS)])\n\n    def _create_loss(self):\n        print(\'Creating loss... \\nIt might take a couple of minutes depending on how many buckets you have.\')\n        start = time.time()\n        def _seq2seq_f(encoder_inputs, decoder_inputs, do_decode):\n            setattr(tf.contrib.rnn.GRUCell, \'__deepcopy__\', lambda self, _: self)\n            setattr(tf.contrib.rnn.MultiRNNCell, \'__deepcopy__\', lambda self, _: self)\n            return tf.contrib.legacy_seq2seq.embedding_attention_seq2seq(\n                    encoder_inputs, decoder_inputs, self.cell,\n                    num_encoder_symbols=config.ENC_VOCAB,\n                    num_decoder_symbols=config.DEC_VOCAB,\n                    embedding_size=config.HIDDEN_SIZE,\n                    output_projection=self.output_projection,\n                    feed_previous=do_decode)\n\n        if self.fw_only:\n            self.outputs, self.losses = tf.contrib.legacy_seq2seq.model_with_buckets(\n                                        self.encoder_inputs, \n                                        self.decoder_inputs, \n                                        self.targets,\n                                        self.decoder_masks, \n                                        config.BUCKETS, \n                                        lambda x, y: _seq2seq_f(x, y, True),\n                                        softmax_loss_function=self.softmax_loss_function)\n            # If we use output projection, we need to project outputs for decoding.\n            if self.output_projection:\n                for bucket in range(len(config.BUCKETS)):\n                    self.outputs[bucket] = [tf.matmul(output, \n                                            self.output_projection[0]) + self.output_projection[1]\n                                            for output in self.outputs[bucket]]\n        else:\n            self.outputs, self.losses = tf.contrib.legacy_seq2seq.model_with_buckets(\n                                        self.encoder_inputs, \n                                        self.decoder_inputs, \n                                        self.targets,\n                                        self.decoder_masks,\n                                        config.BUCKETS,\n                                        lambda x, y: _seq2seq_f(x, y, False),\n                                        softmax_loss_function=self.softmax_loss_function)\n        print(\'Time:\', time.time() - start)\n\n    def _creat_optimizer(self):\n        print(\'Create optimizer... \\nIt might take a couple of minutes depending on how many buckets you have.\')\n        with tf.variable_scope(\'training\') as scope:\n            self.global_step = tf.Variable(0, dtype=tf.int32, trainable=False, name=\'global_step\')\n\n            if not self.fw_only:\n                self.optimizer = tf.train.GradientDescentOptimizer(config.LR)\n                trainables = tf.trainable_variables()\n                self.gradient_norms = []\n                self.train_ops = []\n                start = time.time()\n                for bucket in range(len(config.BUCKETS)):\n                    \n                    clipped_grads, norm = tf.clip_by_global_norm(tf.gradients(self.losses[bucket], \n                                                                 trainables),\n                                                                 config.MAX_GRAD_NORM)\n                    self.gradient_norms.append(norm)\n                    self.train_ops.append(self.optimizer.apply_gradients(zip(clipped_grads, trainables), \n                                                            global_step=self.global_step))\n                    print(\'Creating opt for bucket {} took {} seconds\'.format(bucket, time.time() - start))\n                    start = time.time()\n\n\n    def _create_summary(self):\n        pass\n\n    def build_graph(self):\n        self._create_placeholders()\n        self._inference()\n        self._create_loss()\n        self._creat_optimizer()\n        self._create_summary()'"
2017/assignments/chatbot/chatbot.py,8,"b'"""""" A neural chatbot using sequence to sequence model with\nattentional decoder. \n\nThis is based on Google Translate Tensorflow model \nhttps://github.com/tensorflow/models/blob/master/tutorials/rnn/translate/\n\nSequence to sequence model by Cho et al.(2014)\n\nCreated by Chip Huyen as the starter code for assignment 3,\nclass CS 20SI: ""TensorFlow for Deep Learning Research""\ncs20si.stanford.edu\n\nThis file contains the code to run the model.\n\nSee readme.md for instruction on how to run the starter code.\n""""""\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport argparse\nimport os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\nimport random\nimport sys\nimport time\n\nimport numpy as np\nimport tensorflow as tf\n\nfrom model import ChatBotModel\nimport config\nimport data\n\ndef _get_random_bucket(train_buckets_scale):\n    """""" Get a random bucket from which to choose a training sample """"""\n    rand = random.random()\n    return min([i for i in range(len(train_buckets_scale))\n                if train_buckets_scale[i] > rand])\n\ndef _assert_lengths(encoder_size, decoder_size, encoder_inputs, decoder_inputs, decoder_masks):\n    """""" Assert that the encoder inputs, decoder inputs, and decoder masks are\n    of the expected lengths """"""\n    if len(encoder_inputs) != encoder_size:\n        raise ValueError(""Encoder length must be equal to the one in bucket,""\n                        "" %d != %d."" % (len(encoder_inputs), encoder_size))\n    if len(decoder_inputs) != decoder_size:\n        raise ValueError(""Decoder length must be equal to the one in bucket,""\n                       "" %d != %d."" % (len(decoder_inputs), decoder_size))\n    if len(decoder_masks) != decoder_size:\n        raise ValueError(""Weights length must be equal to the one in bucket,""\n                       "" %d != %d."" % (len(decoder_masks), decoder_size))\n\ndef run_step(sess, model, encoder_inputs, decoder_inputs, decoder_masks, bucket_id, forward_only):\n    """""" Run one step in training.\n    @forward_only: boolean value to decide whether a backward path should be created\n    forward_only is set to True when you just want to evaluate on the test set,\n    or when you want to the bot to be in chat mode. """"""\n    encoder_size, decoder_size = config.BUCKETS[bucket_id]\n    _assert_lengths(encoder_size, decoder_size, encoder_inputs, decoder_inputs, decoder_masks)\n\n    # input feed: encoder inputs, decoder inputs, target_weights, as provided.\n    input_feed = {}\n    for step in range(encoder_size):\n        input_feed[model.encoder_inputs[step].name] = encoder_inputs[step]\n    for step in range(decoder_size):\n        input_feed[model.decoder_inputs[step].name] = decoder_inputs[step]\n        input_feed[model.decoder_masks[step].name] = decoder_masks[step]\n\n    last_target = model.decoder_inputs[decoder_size].name\n    input_feed[last_target] = np.zeros([model.batch_size], dtype=np.int32)\n\n    # output feed: depends on whether we do a backward step or not.\n    if not forward_only:\n        output_feed = [model.train_ops[bucket_id],  # update op that does SGD.\n                       model.gradient_norms[bucket_id],  # gradient norm.\n                       model.losses[bucket_id]]  # loss for this batch.\n    else:\n        output_feed = [model.losses[bucket_id]]  # loss for this batch.\n        for step in range(decoder_size):  # output logits.\n            output_feed.append(model.outputs[bucket_id][step])\n\n    outputs = sess.run(output_feed, input_feed)\n    if not forward_only:\n        return outputs[1], outputs[2], None  # Gradient norm, loss, no outputs.\n    else:\n        return None, outputs[0], outputs[1:]  # No gradient norm, loss, outputs.\n\ndef _get_buckets():\n    """""" Load the dataset into buckets based on their lengths.\n    train_buckets_scale is the inverval that\'ll help us \n    choose a random bucket later on.\n    """"""\n    test_buckets = data.load_data(\'test_ids.enc\', \'test_ids.dec\')\n    data_buckets = data.load_data(\'train_ids.enc\', \'train_ids.dec\')\n    train_bucket_sizes = [len(data_buckets[b]) for b in range(len(config.BUCKETS))]\n    print(""Number of samples in each bucket:\\n"", train_bucket_sizes)\n    train_total_size = sum(train_bucket_sizes)\n    # list of increasing numbers from 0 to 1 that we\'ll use to select a bucket.\n    train_buckets_scale = [sum(train_bucket_sizes[:i + 1]) / train_total_size\n                           for i in range(len(train_bucket_sizes))]\n    print(""Bucket scale:\\n"", train_buckets_scale)\n    return test_buckets, data_buckets, train_buckets_scale\n\ndef _get_skip_step(iteration):\n    """""" How many steps should the model train before it saves all the weights. """"""\n    if iteration < 100:\n        return 30\n    return 100\n\ndef _check_restore_parameters(sess, saver):\n    """""" Restore the previously trained parameters if there are any. """"""\n    ckpt = tf.train.get_checkpoint_state(os.path.dirname(config.CPT_PATH + \'/checkpoint\'))\n    if ckpt and ckpt.model_checkpoint_path:\n        print(""Loading parameters for the Chatbot"")\n        saver.restore(sess, ckpt.model_checkpoint_path)\n    else:\n        print(""Initializing fresh parameters for the Chatbot"")\n\ndef _eval_test_set(sess, model, test_buckets):\n    """""" Evaluate on the test set. """"""\n    for bucket_id in range(len(config.BUCKETS)):\n        if len(test_buckets[bucket_id]) == 0:\n            print(""  Test: empty bucket %d"" % (bucket_id))\n            continue\n        start = time.time()\n        encoder_inputs, decoder_inputs, decoder_masks = data.get_batch(test_buckets[bucket_id], \n                                                                        bucket_id,\n                                                                        batch_size=config.BATCH_SIZE)\n        _, step_loss, _ = run_step(sess, model, encoder_inputs, decoder_inputs, \n                                   decoder_masks, bucket_id, True)\n        print(\'Test bucket {}: loss {}, time {}\'.format(bucket_id, step_loss, time.time() - start))\n\ndef train():\n    """""" Train the bot """"""\n    test_buckets, data_buckets, train_buckets_scale = _get_buckets()\n    # in train mode, we need to create the backward path, so forwrad_only is False\n    model = ChatBotModel(False, config.BATCH_SIZE)\n    model.build_graph()\n\n    saver = tf.train.Saver()\n\n    with tf.Session() as sess:\n        print(\'Running session\')\n        sess.run(tf.global_variables_initializer())\n        _check_restore_parameters(sess, saver)\n\n        iteration = model.global_step.eval()\n        total_loss = 0\n        while True:\n            skip_step = _get_skip_step(iteration)\n            bucket_id = _get_random_bucket(train_buckets_scale)\n            encoder_inputs, decoder_inputs, decoder_masks = data.get_batch(data_buckets[bucket_id], \n                                                                           bucket_id,\n                                                                           batch_size=config.BATCH_SIZE)\n            start = time.time()\n            _, step_loss, _ = run_step(sess, model, encoder_inputs, decoder_inputs, decoder_masks, bucket_id, False)\n            total_loss += step_loss\n            iteration += 1\n\n            if iteration % skip_step == 0:\n                print(\'Iter {}: loss {}, time {}\'.format(iteration, total_loss/skip_step, time.time() - start))\n                start = time.time()\n                total_loss = 0\n                saver.save(sess, os.path.join(config.CPT_PATH, \'chatbot\'), global_step=model.global_step)\n                if iteration % (10 * skip_step) == 0:\n                    # Run evals on development set and print their loss\n                    _eval_test_set(sess, model, test_buckets)\n                    start = time.time()\n                sys.stdout.flush()\n\ndef _get_user_input():\n    """""" Get user\'s input, which will be transformed into encoder input later """"""\n    print(""> "", end="""")\n    sys.stdout.flush()\n    return sys.stdin.readline()\n\ndef _find_right_bucket(length):\n    """""" Find the proper bucket for an encoder input based on its length """"""\n    return min([b for b in range(len(config.BUCKETS))\n                if config.BUCKETS[b][0] >= length])\n\ndef _construct_response(output_logits, inv_dec_vocab):\n    """""" Construct a response to the user\'s encoder input.\n    @output_logits: the outputs from sequence to sequence wrapper.\n    output_logits is decoder_size np array, each of dim 1 x DEC_VOCAB\n    \n    This is a greedy decoder - outputs are just argmaxes of output_logits.\n    """"""\n    print(output_logits[0])\n    outputs = [int(np.argmax(logit, axis=1)) for logit in output_logits]\n    # If there is an EOS symbol in outputs, cut them at that point.\n    if config.EOS_ID in outputs:\n        outputs = outputs[:outputs.index(config.EOS_ID)]\n    # Print out sentence corresponding to outputs.\n    return "" "".join([tf.compat.as_str(inv_dec_vocab[output]) for output in outputs])\n\ndef chat():\n    """""" in test mode, we don\'t to create the backward path\n    """"""\n    _, enc_vocab = data.load_vocab(os.path.join(config.PROCESSED_PATH, \'vocab.enc\'))\n    inv_dec_vocab, _ = data.load_vocab(os.path.join(config.PROCESSED_PATH, \'vocab.dec\'))\n\n    model = ChatBotModel(True, batch_size=1)\n    model.build_graph()\n\n    saver = tf.train.Saver()\n\n    with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n        _check_restore_parameters(sess, saver)\n        output_file = open(os.path.join(config.PROCESSED_PATH, config.OUTPUT_FILE), \'a+\')\n        # Decode from standard input.\n        max_length = config.BUCKETS[-1][0]\n        print(\'Welcome to TensorBro. Say something. Enter to exit. Max length is\', max_length)\n        while True:\n            line = _get_user_input()\n            if len(line) > 0 and line[-1] == \'\\n\':\n                line = line[:-1]\n            if line == \'\':\n                break\n            output_file.write(\'HUMAN ++++ \' + line + \'\\n\')\n            # Get token-ids for the input sentence.\n            token_ids = data.sentence2id(enc_vocab, str(line))\n            if (len(token_ids) > max_length):\n                print(\'Max length I can handle is:\', max_length)\n                line = _get_user_input()\n                continue\n            # Which bucket does it belong to?\n            bucket_id = _find_right_bucket(len(token_ids))\n            # Get a 1-element batch to feed the sentence to the model.\n            encoder_inputs, decoder_inputs, decoder_masks = data.get_batch([(token_ids, [])], \n                                                                            bucket_id,\n                                                                            batch_size=1)\n            # Get output logits for the sentence.\n            _, _, output_logits = run_step(sess, model, encoder_inputs, decoder_inputs,\n                                           decoder_masks, bucket_id, True)\n            response = _construct_response(output_logits, inv_dec_vocab)\n            print(response)\n            output_file.write(\'BOT ++++ \' + response + \'\\n\')\n        output_file.write(\'=============================================\\n\')\n        output_file.close()\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'--mode\', choices={\'train\', \'chat\'},\n                        default=\'train\', help=""mode. if not specified, it\'s in the train mode"")\n    args = parser.parse_args()\n\n    if not os.path.isdir(config.PROCESSED_PATH):\n        data.prepare_raw_data()\n        data.process_data()\n    print(\'Data ready!\')\n    # create checkpoints folder if there isn\'t one already\n    data.make_dir(config.CPT_PATH)\n\n    if args.mode == \'train\':\n        train()\n    elif args.mode == \'chat\':\n        chat()\n\nif __name__ == \'__main__\':\n    main()\n'"
2017/assignments/chatbot/config.py,0,"b'"""""" A neural chatbot using sequence to sequence model with\nattentional decoder. \n\nThis is based on Google Translate Tensorflow model \nhttps://github.com/tensorflow/models/blob/master/tutorials/rnn/translate/\n\nSequence to sequence model by Cho et al.(2014)\n\nCreated by Chip Huyen as the starter code for assignment 3,\nclass CS 20SI: ""TensorFlow for Deep Learning Research""\ncs20si.stanford.edu\n\nThis file contains the hyperparameters for the model.\n\nSee readme.md for instruction on how to run the starter code.\n""""""\n\n# parameters for processing the dataset\nDATA_PATH = \'/Users/Chip/data/cornell movie-dialogs corpus\'\nCONVO_FILE = \'movie_conversations.txt\'\nLINE_FILE = \'movie_lines.txt\'\nOUTPUT_FILE = \'output_convo.txt\'\nPROCESSED_PATH = \'processed\'\nCPT_PATH = \'checkpoints\'\n\nTHRESHOLD = 2\n\nPAD_ID = 0\nUNK_ID = 1\nSTART_ID = 2\nEOS_ID = 3\n\nTESTSET_SIZE = 25000\n\n# model parameters\n"""""" Train encoder length distribution:\n[175, 92, 11883, 8387, 10656, 13613, 13480, 12850, 11802, 10165, \n8973, 7731, 7005, 6073, 5521, 5020, 4530, 4421, 3746, 3474, 3192, \n2724, 2587, 2413, 2252, 2015, 1816, 1728, 1555, 1392, 1327, 1248, \n1128, 1084, 1010, 884, 843, 755, 705, 660, 649, 594, 558, 517, 475, \n426, 444, 388, 349, 337]\nThese buckets size seem to work the best\n""""""\n# [19530, 17449, 17585, 23444, 22884, 16435, 17085, 18291, 18931]\n# BUCKETS = [(6, 8), (8, 10), (10, 12), (13, 15), (16, 19), (19, 22), (23, 26), (29, 32), (39, 44)]\n\n# [37049, 33519, 30223, 33513, 37371]\n# BUCKETS = [(8, 10), (12, 14), (16, 19), (23, 26), (39, 43)]\n\n# BUCKETS = [(8, 10), (12, 14), (16, 19)]\nBUCKETS = [(16, 19)]\n\nNUM_LAYERS = 3\nHIDDEN_SIZE = 256\nBATCH_SIZE = 64\n\nLR = 0.5\nMAX_GRAD_NORM = 5.0\n\nNUM_SAMPLES = 512\n'"
2017/assignments/chatbot/data.py,0,"b'"""""" A neural chatbot using sequence to sequence model with\nattentional decoder. \n\nThis is based on Google Translate Tensorflow model \nhttps://github.com/tensorflow/models/blob/master/tutorials/rnn/translate/\n\nSequence to sequence model by Cho et al.(2014)\n\nCreated by Chip Huyen as the starter code for assignment 3,\nclass CS 20SI: ""TensorFlow for Deep Learning Research""\ncs20si.stanford.edu\n\nThis file contains the code to do the pre-processing for the\nCornell Movie-Dialogs Corpus.\n\nSee readme.md for instruction on how to run the starter code.\n""""""\nfrom __future__ import print_function\n\nimport os\nimport random\nimport re\n\nimport numpy as np\n\nimport config\n\ndef get_lines():\n    id2line = {}\n    file_path = os.path.join(config.DATA_PATH, config.LINE_FILE)\n    with open(file_path, \'rb\') as f:\n        lines = f.readlines()\n        for line in lines:\n            parts = line.split(\' +++$+++ \')\n            if len(parts) == 5:\n                if parts[4][-1] == \'\\n\':\n                    parts[4] = parts[4][:-1]\n                id2line[parts[0]] = parts[4]\n    return id2line\n\ndef get_convos():\n    """""" Get conversations from the raw data """"""\n    file_path = os.path.join(config.DATA_PATH, config.CONVO_FILE)\n    convos = []\n    with open(file_path, \'rb\') as f:\n        for line in f.readlines():\n            parts = line.split(\' +++$+++ \')\n            if len(parts) == 4:\n                convo = []\n                for line in parts[3][1:-2].split(\', \'):\n                    convo.append(line[1:-1])\n                convos.append(convo)\n\n    return convos\n\ndef question_answers(id2line, convos):\n    """""" Divide the dataset into two sets: questions and answers. """"""\n    questions, answers = [], []\n    for convo in convos:\n        for index, line in enumerate(convo[:-1]):\n            questions.append(id2line[convo[index]])\n            answers.append(id2line[convo[index + 1]])\n    assert len(questions) == len(answers)\n    return questions, answers\n\ndef prepare_dataset(questions, answers):\n    # create path to store all the train & test encoder & decoder\n    make_dir(config.PROCESSED_PATH)\n    \n    # random convos to create the test set\n    test_ids = random.sample([i for i in range(len(questions))],config.TESTSET_SIZE)\n    \n    filenames = [\'train.enc\', \'train.dec\', \'test.enc\', \'test.dec\']\n    files = []\n    for filename in filenames:\n        files.append(open(os.path.join(config.PROCESSED_PATH, filename),\'wb\'))\n\n    for i in range(len(questions)):\n        if i in test_ids:\n            files[2].write(questions[i] + \'\\n\')\n            files[3].write(answers[i] + \'\\n\')\n        else:\n            files[0].write(questions[i] + \'\\n\')\n            files[1].write(answers[i] + \'\\n\')\n\n    for file in files:\n        file.close()\n\ndef make_dir(path):\n    """""" Create a directory if there isn\'t one already. """"""\n    try:\n        os.mkdir(path)\n    except OSError:\n        pass\n\ndef basic_tokenizer(line, normalize_digits=True):\n    """""" A basic tokenizer to tokenize text into tokens.\n    Feel free to change this to suit your need. """"""\n    line = re.sub(\'<u>\', \'\', line)\n    line = re.sub(\'</u>\', \'\', line)\n    line = re.sub(\'\\[\', \'\', line)\n    line = re.sub(\'\\]\', \'\', line)\n    words = []\n    _WORD_SPLIT = re.compile(b""([.,!?\\""\'-<>:;)(])"")\n    _DIGIT_RE = re.compile(r""\\d"")\n    for fragment in line.strip().lower().split():\n        for token in re.split(_WORD_SPLIT, fragment):\n            if not token:\n                continue\n            if normalize_digits:\n                token = re.sub(_DIGIT_RE, b\'#\', token)\n            words.append(token)\n    return words\n\ndef build_vocab(filename, normalize_digits=True):\n    in_path = os.path.join(config.PROCESSED_PATH, filename)\n    out_path = os.path.join(config.PROCESSED_PATH, \'vocab.{}\'.format(filename[-3:]))\n\n    vocab = {}\n    with open(in_path, \'rb\') as f:\n        for line in f.readlines():\n            for token in basic_tokenizer(line):\n                if not token in vocab:\n                    vocab[token] = 0\n                vocab[token] += 1\n\n    sorted_vocab = sorted(vocab, key=vocab.get, reverse=True)\n    with open(out_path, \'wb\') as f:\n        f.write(\'<pad>\' + \'\\n\')\n        f.write(\'<unk>\' + \'\\n\')\n        f.write(\'<s>\' + \'\\n\')\n        f.write(\'<\\s>\' + \'\\n\') \n        index = 4\n        for word in sorted_vocab:\n            if vocab[word] < config.THRESHOLD:\n                with open(\'config.py\', \'ab\') as cf:\n                    if filename[-3:] == \'enc\':\n                        cf.write(\'ENC_VOCAB = \' + str(index) + \'\\n\')\n                    else:\n                        cf.write(\'DEC_VOCAB = \' + str(index) + \'\\n\')\n                break\n            f.write(word + \'\\n\')\n            index += 1\n\ndef load_vocab(vocab_path):\n    with open(vocab_path, \'rb\') as f:\n        words = f.read().splitlines()\n    return words, {words[i]: i for i in range(len(words))}\n\ndef sentence2id(vocab, line):\n    return [vocab.get(token, vocab[\'<unk>\']) for token in basic_tokenizer(line)]\n\ndef token2id(data, mode):\n    """""" Convert all the tokens in the data into their corresponding\n    index in the vocabulary. """"""\n    vocab_path = \'vocab.\' + mode\n    in_path = data + \'.\' + mode\n    out_path = data + \'_ids.\' + mode\n\n    _, vocab = load_vocab(os.path.join(config.PROCESSED_PATH, vocab_path))\n    in_file = open(os.path.join(config.PROCESSED_PATH, in_path), \'rb\')\n    out_file = open(os.path.join(config.PROCESSED_PATH, out_path), \'wb\')\n    \n    lines = in_file.read().splitlines()\n    for line in lines:\n        if mode == \'dec\': # we only care about \'<s>\' and </s> in encoder\n            ids = [vocab[\'<s>\']]\n        else:\n            ids = []\n        ids.extend(sentence2id(vocab, line))\n        # ids.extend([vocab.get(token, vocab[\'<unk>\']) for token in basic_tokenizer(line)])\n        if mode == \'dec\':\n            ids.append(vocab[\'<\\s>\'])\n        out_file.write(\' \'.join(str(id_) for id_ in ids) + \'\\n\')\n\ndef prepare_raw_data():\n    print(\'Preparing raw data into train set and test set ...\')\n    id2line = get_lines()\n    convos = get_convos()\n    questions, answers = question_answers(id2line, convos)\n    prepare_dataset(questions, answers)\n\ndef process_data():\n    print(\'Preparing data to be model-ready ...\')\n    build_vocab(\'train.enc\')\n    build_vocab(\'train.dec\')\n    token2id(\'train\', \'enc\')\n    token2id(\'train\', \'dec\')\n    token2id(\'test\', \'enc\')\n    token2id(\'test\', \'dec\')\n\ndef load_data(enc_filename, dec_filename, max_training_size=None):\n    encode_file = open(os.path.join(config.PROCESSED_PATH, enc_filename), \'rb\')\n    decode_file = open(os.path.join(config.PROCESSED_PATH, dec_filename), \'rb\')\n    encode, decode = encode_file.readline(), decode_file.readline()\n    data_buckets = [[] for _ in config.BUCKETS]\n    i = 0\n    while encode and decode:\n        if (i + 1) % 10000 == 0:\n            print(""Bucketing conversation number"", i)\n        encode_ids = [int(id_) for id_ in encode.split()]\n        decode_ids = [int(id_) for id_ in decode.split()]\n        for bucket_id, (encode_max_size, decode_max_size) in enumerate(config.BUCKETS):\n            if len(encode_ids) <= encode_max_size and len(decode_ids) <= decode_max_size:\n                data_buckets[bucket_id].append([encode_ids, decode_ids])\n                break\n        encode, decode = encode_file.readline(), decode_file.readline()\n        i += 1\n    return data_buckets\n\ndef _pad_input(input_, size):\n    return input_ + [config.PAD_ID] * (size - len(input_))\n\ndef _reshape_batch(inputs, size, batch_size):\n    """""" Create batch-major inputs. Batch inputs are just re-indexed inputs\n    """"""\n    batch_inputs = []\n    for length_id in range(size):\n        batch_inputs.append(np.array([inputs[batch_id][length_id]\n                                    for batch_id in range(batch_size)], dtype=np.int32))\n    return batch_inputs\n\n\ndef get_batch(data_bucket, bucket_id, batch_size=1):\n    """""" Return one batch to feed into the model """"""\n    # only pad to the max length of the bucket\n    encoder_size, decoder_size = config.BUCKETS[bucket_id]\n    encoder_inputs, decoder_inputs = [], []\n\n    for _ in range(batch_size):\n        encoder_input, decoder_input = random.choice(data_bucket)\n        # pad both encoder and decoder, reverse the encoder\n        encoder_inputs.append(list(reversed(_pad_input(encoder_input, encoder_size))))\n        decoder_inputs.append(_pad_input(decoder_input, decoder_size))\n\n    # now we create batch-major vectors from the data selected above.\n    batch_encoder_inputs = _reshape_batch(encoder_inputs, encoder_size, batch_size)\n    batch_decoder_inputs = _reshape_batch(decoder_inputs, decoder_size, batch_size)\n\n    # create decoder_masks to be 0 for decoders that are padding.\n    batch_masks = []\n    for length_id in range(decoder_size):\n        batch_mask = np.ones(batch_size, dtype=np.float32)\n        for batch_id in range(batch_size):\n            # we set mask to 0 if the corresponding target is a PAD symbol.\n            # the corresponding decoder is decoder_input shifted by 1 forward.\n            if length_id < decoder_size - 1:\n                target = decoder_inputs[batch_id][length_id + 1]\n            if length_id == decoder_size - 1 or target == config.PAD_ID:\n                batch_mask[batch_id] = 0.0\n        batch_masks.append(batch_mask)\n    return batch_encoder_inputs, batch_decoder_inputs, batch_masks\n\nif __name__ == \'__main__\':\n    prepare_raw_data()\n    process_data()'"
2017/assignments/chatbot/model.py,18,"b'"""""" A neural chatbot using sequence to sequence model with\nattentional decoder. \n\nThis is based on Google Translate Tensorflow model \nhttps://github.com/tensorflow/models/blob/master/tutorials/rnn/translate/\n\nSequence to sequence model by Cho et al.(2014)\n\nCreated by Chip Huyen as the starter code for assignment 3,\nclass CS 20SI: ""TensorFlow for Deep Learning Research""\ncs20si.stanford.edu\n\nThis file contains the code to build the model\n\nSee readme.md for instruction on how to run the starter code.\n""""""\nfrom __future__ import print_function\n\nimport time\n\nimport numpy as np\nimport tensorflow as tf\n\nimport config\n\nclass ChatBotModel(object):\n    def __init__(self, forward_only, batch_size):\n        """"""forward_only: if set, we do not construct the backward pass in the model.\n        """"""\n        print(\'Initialize new model\')\n        self.fw_only = forward_only\n        self.batch_size = batch_size\n    \n    def _create_placeholders(self):\n        # Feeds for inputs. It\'s a list of placeholders\n        print(\'Create placeholders\')\n        self.encoder_inputs = [tf.placeholder(tf.int32, shape=[None], name=\'encoder{}\'.format(i))\n                               for i in range(config.BUCKETS[-1][0])]\n        self.decoder_inputs = [tf.placeholder(tf.int32, shape=[None], name=\'decoder{}\'.format(i))\n                               for i in range(config.BUCKETS[-1][1] + 1)]\n        self.decoder_masks = [tf.placeholder(tf.float32, shape=[None], name=\'mask{}\'.format(i))\n                              for i in range(config.BUCKETS[-1][1] + 1)]\n\n        # Our targets are decoder inputs shifted by one (to ignore <s> symbol)\n        self.targets = self.decoder_inputs[1:]\n        \n    def _inference(self):\n        print(\'Create inference\')\n        # If we use sampled softmax, we need an output projection.\n        # Sampled softmax only makes sense if we sample less than vocabulary size.\n        if config.NUM_SAMPLES > 0 and config.NUM_SAMPLES < config.DEC_VOCAB:\n            w = tf.get_variable(\'proj_w\', [config.HIDDEN_SIZE, config.DEC_VOCAB])\n            b = tf.get_variable(\'proj_b\', [config.DEC_VOCAB])\n            self.output_projection = (w, b)\n\n        def sampled_loss(inputs, labels):\n            labels = tf.reshape(labels, [-1, 1])\n            return tf.nn.sampled_softmax_loss(tf.transpose(w), b, inputs, labels, \n                                              config.NUM_SAMPLES, config.DEC_VOCAB)\n        self.softmax_loss_function = sampled_loss\n\n        single_cell = tf.nn.rnn_cell.GRUCell(config.HIDDEN_SIZE)\n        self.cell = tf.nn.rnn_cell.MultiRNNCell([single_cell] * config.NUM_LAYERS)\n\n    def _create_loss(self):\n        print(\'Creating loss... \\nIt might take a couple of minutes depending on how many buckets you have.\')\n        start = time.time()\n        def _seq2seq_f(encoder_inputs, decoder_inputs, do_decode):\n            return tf.nn.seq2seq.embedding_attention_seq2seq(\n                    encoder_inputs, decoder_inputs, self.cell,\n                    num_encoder_symbols=config.ENC_VOCAB,\n                    num_decoder_symbols=config.DEC_VOCAB,\n                    embedding_size=config.HIDDEN_SIZE,\n                    output_projection=self.output_projection,\n                    feed_previous=do_decode)\n\n        if self.fw_only:\n            self.outputs, self.losses = tf.nn.seq2seq.model_with_buckets(\n                                        self.encoder_inputs, \n                                        self.decoder_inputs, \n                                        self.targets,\n                                        self.decoder_masks, \n                                        config.BUCKETS, \n                                        lambda x, y: _seq2seq_f(x, y, True),\n                                        softmax_loss_function=self.softmax_loss_function)\n            # If we use output projection, we need to project outputs for decoding.\n            if self.output_projection:\n                for bucket in range(len(config.BUCKETS)):\n                    self.outputs[bucket] = [tf.matmul(output, \n                                            self.output_projection[0]) + self.output_projection[1]\n                                            for output in self.outputs[bucket]]\n        else:\n            self.outputs, self.losses = tf.nn.seq2seq.model_with_buckets(\n                                        self.encoder_inputs, \n                                        self.decoder_inputs, \n                                        self.targets,\n                                        self.decoder_masks,\n                                        config.BUCKETS,\n                                        lambda x, y: _seq2seq_f(x, y, False),\n                                        softmax_loss_function=self.softmax_loss_function)\n        print(\'Time:\', time.time() - start)\n\n    def _creat_optimizer(self):\n        print(\'Create optimizer... \\nIt might take a couple of minutes depending on how many buckets you have.\')\n        with tf.variable_scope(\'training\') as scope:\n            self.global_step = tf.Variable(0, dtype=tf.int32, trainable=False, name=\'global_step\')\n\n            if not self.fw_only:\n                self.optimizer = tf.train.GradientDescentOptimizer(config.LR)\n                trainables = tf.trainable_variables()\n                self.gradient_norms = []\n                self.train_ops = []\n                start = time.time()\n                for bucket in range(len(config.BUCKETS)):\n                    \n                    clipped_grads, norm = tf.clip_by_global_norm(tf.gradients(self.losses[bucket], \n                                                                 trainables),\n                                                                 config.MAX_GRAD_NORM)\n                    self.gradient_norms.append(norm)\n                    self.train_ops.append(self.optimizer.apply_gradients(zip(clipped_grads, trainables), \n                                                            global_step=self.global_step))\n                    print(\'Creating opt for bucket {} took {} seconds\'.format(bucket, time.time() - start))\n                    start = time.time()\n\n\n    def _create_summary(self):\n        pass\n\n    def build_graph(self):\n        self._create_placeholders()\n        self._inference()\n        self._create_loss()\n        self._creat_optimizer()\n        self._create_summary()\n'"
2017/assignments/exercises/e01.py,13,"b'""""""\nSimple exercises to get used to TensorFlow API\nYou should thoroughly test your code\n""""""\nimport os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\n\nimport tensorflow as tf\n\nsess = tf.InteractiveSession()\n###############################################################################\n# 1a: Create two random 0-d tensors x and y of any distribution.\n# Create a TensorFlow object that returns x + y if x > y, and x - y otherwise.\n# Hint: look up tf.cond()\n# I do the first problem for you\n###############################################################################\n\nx = tf.random_uniform([])  # Empty array as shape creates a scalar.\ny = tf.random_uniform([])\nout = tf.cond(tf.greater(x, y), lambda: tf.add(x, y), lambda: tf.subtract(x, y))\nprint(sess.run(out))\n\n###############################################################################\n# 1b: Create two 0-d tensors x and y randomly selected from the range [-1, 1).\n# Return x + y if x < y, x - y if x > y, 0 otherwise.\n# Hint: Look up tf.case().\n###############################################################################\n\n# YOUR CODE\n\n###############################################################################\n# 1c: Create the tensor x of the value [[0, -2, -1], [0, 1, 2]] \n# and y as a tensor of zeros with the same shape as x.\n# Return a boolean tensor that yields Trues if x equals y element-wise.\n# Hint: Look up tf.equal().\n###############################################################################\n\n# YOUR CODE\n\n###############################################################################\n# 1d: Create the tensor x of value \n# [29.05088806,  27.61298943,  31.19073486,  29.35532951,\n#  30.97266006,  26.67541885,  38.08450317,  20.74983215,\n#  34.94445419,  34.45999146,  29.06485367,  36.01657104,\n#  27.88236427,  20.56035233,  30.20379066,  29.51215172,\n#  33.71149445,  28.59134293,  36.05556488,  28.66994858].\n# Get the indices of elements in x whose values are greater than 30.\n# Hint: Use tf.where().\n# Then extract elements whose values are greater than 30.\n# Hint: Use tf.gather().\n###############################################################################\n\n# YOUR CODE\n\n###############################################################################\n# 1e: Create a diagnoal 2-d tensor of size 6 x 6 with the diagonal values of 1,\n# 2, ..., 6\n# Hint: Use tf.range() and tf.diag().\n###############################################################################\n\n# YOUR CODE\n\n###############################################################################\n# 1f: Create a random 2-d tensor of size 10 x 10 from any distribution.\n# Calculate its determinant.\n# Hint: Look at tf.matrix_determinant().\n###############################################################################\n\n# YOUR CODE\n\n###############################################################################\n# 1g: Create tensor x with value [5, 2, 3, 5, 10, 6, 2, 3, 4, 2, 1, 1, 0, 9].\n# Return the unique elements in x\n# Hint: use tf.unique(). Keep in mind that tf.unique() returns a tuple.\n###############################################################################\n\n# YOUR CODE\n\n###############################################################################\n# 1h: Create two tensors x and y of shape 300 from any normal distribution,\n# as long as they are from the same distribution.\n# Use tf.cond() to return:\n# - The mean squared error of (x - y) if the average of all elements in (x - y)\n#   is negative, or\n# - The sum of absolute value of all elements in the tensor (x - y) otherwise.\n# Hint: see the Huber loss function in the lecture slides 3.\n###############################################################################\n\n# YOUR CODE'"
2017/assignments/exercises/e01_sol.py,36,"b'""""""\nSolution to simple TensorFlow exercises\nFor the problems \n""""""\nimport tensorflow as tf\n\n###############################################################################\n# 1a: Create two random 0-d tensors x and y of any distribution.\n# Create a TensorFlow object that returns x + y if x > y, and x - y otherwise.\n# Hint: look up tf.cond()\n# I do the first problem for you\n###############################################################################\n\nx = tf.random_uniform([])  # Empty array as shape creates a scalar.\ny = tf.random_uniform([])\nout = tf.cond(tf.greater(x, y), lambda: tf.add(x, y), lambda: tf.subtract(x, y))\n\n###############################################################################\n# 1b: Create two 0-d tensors x and y randomly selected from the range [-1, 1).\n# Return x + y if x < y, x - y if x > y, 0 otherwise.\n# Hint: Look up tf.case().\n###############################################################################\n\nx = tf.random_uniform([], -1, 1, dtype=tf.float32)\ny = tf.random_uniform([], -1, 1, dtype=tf.float32)\nout = tf.case({tf.less(x, y): lambda: tf.add(x, y), \n\t\t\ttf.greater(x, y): lambda: tf.subtract(x, y)}, \n\t\t\tdefault=lambda: tf.constant(0.0), exclusive=True)\nprint(x)\nsess = tf.InteractiveSession()\nprint(sess.run(x))\n\n###############################################################################\n# 1c: Create the tensor x of the value [[0, -2, -1], [0, 1, 2]] \n# and y as a tensor of zeros with the same shape as x.\n# Return a boolean tensor that yields Trues if x equals y element-wise.\n# Hint: Look up tf.equal().\n###############################################################################\n\nx = tf.constant([[0, -2, -1], [0, 1, 2]])\ny = tf.zeros_like(x)\nout = tf.equal(x, y)\n\n###############################################################################\n# 1d: Create the tensor x of value \n# [29.05088806,  27.61298943,  31.19073486,  29.35532951,\n#  30.97266006,  26.67541885,  38.08450317,  20.74983215,\n#  34.94445419,  34.45999146,  29.06485367,  36.01657104,\n#  27.88236427,  20.56035233,  30.20379066,  29.51215172,\n#  33.71149445,  28.59134293,  36.05556488,  28.66994858].\n# Get the indices of elements in x whose values are greater than 30.\n# Hint: Use tf.where().\n# Then extract elements whose values are greater than 30.\n# Hint: Use tf.gather().\n###############################################################################\n\nx = tf.constant([29.05088806,  27.61298943,  31.19073486,  29.35532951,\n\t\t        30.97266006,  26.67541885,  38.08450317,  20.74983215,\n\t\t        34.94445419,  34.45999146,  29.06485367,  36.01657104,\n\t\t        27.88236427,  20.56035233,  30.20379066,  29.51215172,\n\t\t        33.71149445,  28.59134293,  36.05556488,  28.66994858])\nindices = tf.where(x > 30)\nout = tf.gather(x, indices)\n\n###############################################################################\n# 1e: Create a diagnoal 2-d tensor of size 6 x 6 with the diagonal values of 1,\n# 2, ..., 6\n# Hint: Use tf.range() and tf.diag().\n###############################################################################\n\nvalues = tf.range(1, 7)\nout = tf.diag(values)\n\n###############################################################################\n# 1f: Create a random 2-d tensor of size 10 x 10 from any distribution.\n# Calculate its determinant.\n# Hint: Look at tf.matrix_determinant().\n###############################################################################\n\nm = tf.random_normal([10, 10], mean=10, stddev=1)\nout = tf.matrix_determinant(m)\n\n###############################################################################\n# 1g: Create tensor x with value [5, 2, 3, 5, 10, 6, 2, 3, 4, 2, 1, 1, 0, 9].\n# Return the unique elements in x\n# Hint: use tf.unique(). Keep in mind that tf.unique() returns a tuple.\n###############################################################################\n\nx = tf.constant([5, 2, 3, 5, 10, 6, 2, 3, 4, 2, 1, 1, 0, 9])\nunique_values, indices = tf.unique(x)\n\n###############################################################################\n# 1h: Create two tensors x and y of shape 300 from any normal distribution,\n# as long as they are from the same distribution.\n# Use tf.cond() to return:\n# - The mean squared error of (x - y) if the average of all elements in (x - y)\n#   is negative, or\n# - The sum of absolute value of all elements in the tensor (x - y) otherwise.\n# Hint: see the Huber loss function in the lecture slides 3.\n###############################################################################\n\nx = tf.random_normal([300], mean=5, stddev=1)\ny = tf.random_normal([300], mean=5, stddev=1)\naverage = tf.reduce_mean(x - y)\ndef f1(): return tf.reduce_mean(tf.square(x - y))\ndef f2(): return tf.reduce_sum(tf.abs(x - y))\nout = tf.cond(average < 0, f1, f2)'"
2017/assignments/style_transfer/style_transfer.py,25,"b'"""""" An implementation of the paper ""A Neural Algorithm of Artistic Style""\nby Gatys et al. in TensorFlow.\n\nAuthor: Chip Huyen (huyenn@stanford.edu)\nPrepared for the class CS 20SI: ""TensorFlow for Deep Learning Research""\nFor more details, please read the assignment handout:\nhttp://web.stanford.edu/class/cs20si/assignments/a2.pdf\n""""""\nfrom __future__ import print_function\n\nimport os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\nimport time\n\nimport numpy as np\nimport tensorflow as tf\n\nimport vgg_model\nimport utils\n\n# parameters to manage experiments\nSTYLE = \'guernica\'\nCONTENT = \'deadpool\'\nSTYLE_IMAGE = \'styles/\' + STYLE + \'.jpg\'\nCONTENT_IMAGE = \'content/\' + CONTENT + \'.jpg\'\nIMAGE_HEIGHT = 250\nIMAGE_WIDTH = 333\nNOISE_RATIO = 0.6 # percentage of weight of the noise for intermixing with the content image\n\nCONTENT_WEIGHT = 0.01\nSTYLE_WEIGHT = 1\n\n# Layers used for style features. You can change this.\nSTYLE_LAYERS = [\'conv1_1\', \'conv2_1\', \'conv3_1\', \'conv4_1\', \'conv5_1\']\nW = [0.5, 1.0, 1.5, 3.0, 4.0] # give more weights to deeper layers.\n\n# Layer used for content features. You can change this.\nCONTENT_LAYER = \'conv4_2\'\n\nITERS = 300\nLR = 2.0\n\nMEAN_PIXELS = np.array([123.68, 116.779, 103.939]).reshape((1,1,1,3))\n"""""" MEAN_PIXELS is defined according to description on their github:\nhttps://gist.github.com/ksimonyan/211839e770f7b538e2d8\n\'In the paper, the model is denoted as the configuration D trained with scale jittering. \nThe input images should be zero-centered by mean pixel (rather than mean image) subtraction. \nNamely, the following BGR values should be subtracted: [103.939, 116.779, 123.68].\'\n""""""\n\n# VGG-19 parameters file\nVGG_DOWNLOAD_LINK = \'http://www.vlfeat.org/matconvnet/models/imagenet-vgg-verydeep-19.mat\'\nVGG_MODEL = \'imagenet-vgg-verydeep-19.mat\'\nEXPECTED_BYTES = 534904783\n\ndef _create_content_loss(p, f):\n    """""" Calculate the loss between the feature representation of the\n    content image and the generated image.\n    \n    Inputs: \n        p, f are just P, F in the paper \n        (read the assignment handout if you\'re confused)\n        Note: we won\'t use the coefficient 0.5 as defined in the paper\n        but the coefficient as defined in the assignment handout.\n    Output:\n        the content loss\n\n    """"""\n    return tf.reduce_sum((f - p) ** 2) / (4.0 * p.size)\n\ndef _gram_matrix(F, N, M):\n    """""" Create and return the gram matrix for tensor F\n        Hint: you\'ll first have to reshape F\n    """"""\n    F = tf.reshape(F, (M, N))\n    return tf.matmul(tf.transpose(F), F)\n\ndef _single_style_loss(a, g):\n    """""" Calculate the style loss at a certain layer\n    Inputs:\n        a is the feature representation of the real image\n        g is the feature representation of the generated image\n    Output:\n        the style loss at a certain layer (which is E_l in the paper)\n\n    Hint: 1. you\'ll have to use the function _gram_matrix()\n        2. we\'ll use the same coefficient for style loss as in the paper\n        3. a and g are feature representation, not gram matrices\n    """"""\n    N = a.shape[3] # number of filters\n    M = a.shape[1] * a.shape[2] # height times width of the feature map\n    A = _gram_matrix(a, N, M)\n    G = _gram_matrix(g, N, M)\n    return tf.reduce_sum((G - A) ** 2 / ((2 * N * M) ** 2))\n\ndef _create_style_loss(A, model):\n    """""" Return the total style loss\n    """"""\n    n_layers = len(STYLE_LAYERS)\n    E = [_single_style_loss(A[i], model[STYLE_LAYERS[i]]) for i in range(n_layers)]\n    \n    ###############################\n    ## TO DO: return total style loss\n    return sum([W[i] * E[i] for i in range(n_layers)])\n    ###############################\n\ndef _create_losses(model, input_image, content_image, style_image):\n    with tf.variable_scope(\'loss\') as scope:\n        with tf.Session() as sess:\n            sess.run(input_image.assign(content_image)) # assign content image to the input variable\n            p = sess.run(model[CONTENT_LAYER])\n        content_loss = _create_content_loss(p, model[CONTENT_LAYER])\n\n        with tf.Session() as sess:\n            sess.run(input_image.assign(style_image))\n            A = sess.run([model[layer_name] for layer_name in STYLE_LAYERS])                              \n        style_loss = _create_style_loss(A, model)\n\n        ##########################################\n        ## TO DO: create total loss. \n        ## Hint: don\'t forget the content loss and style loss weights\n        total_loss = CONTENT_WEIGHT * content_loss + STYLE_WEIGHT * style_loss\n        ##########################################\n\n    return content_loss, style_loss, total_loss\n\ndef _create_summary(model):\n    """""" Create summary ops necessary\n        Hint: don\'t forget to merge them\n    """"""\n    with tf.name_scope(\'summaries\'):\n        tf.summary.scalar(\'content loss\', model[\'content_loss\'])\n        tf.summary.scalar(\'style loss\', model[\'style_loss\'])\n        tf.summary.scalar(\'total loss\', model[\'total_loss\'])\n        tf.summary.histogram(\'histogram content loss\', model[\'content_loss\'])\n        tf.summary.histogram(\'histogram style loss\', model[\'style_loss\'])\n        tf.summary.histogram(\'histogram total loss\', model[\'total_loss\'])\n        return tf.summary.merge_all()\n\ndef train(model, generated_image, initial_image):\n    """""" Train your model.\n    Don\'t forget to create folders for checkpoints and outputs.\n    """"""\n    skip_step = 1\n    with tf.Session() as sess:\n        saver = tf.train.Saver()\n        ###############################\n        ## TO DO: \n        ## 1. initialize your variables\n        ## 2. create writer to write your graph\n        saver = tf.train.Saver()\n        sess.run(tf.global_variables_initializer())\n        writer = tf.summary.FileWriter(\'graphs\', sess.graph)\n        ###############################\n        sess.run(generated_image.assign(initial_image))\n        ckpt = tf.train.get_checkpoint_state(os.path.dirname(\'checkpoints/checkpoint\'))\n        if ckpt and ckpt.model_checkpoint_path:\n            saver.restore(sess, ckpt.model_checkpoint_path)\n        initial_step = model[\'global_step\'].eval()\n        \n        start_time = time.time()\n        for index in range(initial_step, ITERS):\n            if index >= 5 and index < 20:\n                skip_step = 10\n            elif index >= 20:\n                skip_step = 20\n            \n            sess.run(model[\'optimizer\'])\n            if (index + 1) % skip_step == 0:\n                ###############################\n                ## TO DO: obtain generated image and loss\n                gen_image, total_loss, summary = sess.run([generated_image, model[\'total_loss\'], \n                                                             model[\'summary_op\']])\n\n                ###############################\n                gen_image = gen_image + MEAN_PIXELS\n                writer.add_summary(summary, global_step=index)\n                print(\'Step {}\\n   Sum: {:5.1f}\'.format(index + 1, np.sum(gen_image)))\n                print(\'   Loss: {:5.1f}\'.format(total_loss))\n                print(\'   Time: {}\'.format(time.time() - start_time))\n                start_time = time.time()\n\n                filename = \'outputs/%d.png\' % (index)\n                utils.save_image(filename, gen_image)\n\n                if (index + 1) % 20 == 0:\n                    saver.save(sess, \'checkpoints/style_transfer\', index)\n\ndef main():\n    with tf.variable_scope(\'input\') as scope:\n        # use variable instead of placeholder because we\'re training the intial image to make it\n        # look like both the content image and the style image\n        input_image = tf.Variable(np.zeros([1, IMAGE_HEIGHT, IMAGE_WIDTH, 3]), dtype=tf.float32)\n    \n    utils.download(VGG_DOWNLOAD_LINK, VGG_MODEL, EXPECTED_BYTES)\n    utils.make_dir(\'checkpoints\')\n    utils.make_dir(\'outputs\')\n    model = vgg_model.load_vgg(VGG_MODEL, input_image)\n    model[\'global_step\'] = tf.Variable(0, dtype=tf.int32, trainable=False, name=\'global_step\')\n\n    content_image = utils.get_resized_image(CONTENT_IMAGE, IMAGE_HEIGHT, IMAGE_WIDTH)\n    content_image = content_image - MEAN_PIXELS\n    style_image = utils.get_resized_image(STYLE_IMAGE, IMAGE_HEIGHT, IMAGE_WIDTH)\n    style_image = style_image - MEAN_PIXELS\n\n    model[\'content_loss\'], model[\'style_loss\'], model[\'total_loss\'] = _create_losses(model, \n                                                    input_image, content_image, style_image)\n    ###############################\n    ## TO DO: create optimizer\n    model[\'optimizer\'] = tf.train.AdamOptimizer(LR).minimize(model[\'total_loss\'], \n                                                            global_step=model[\'global_step\'])\n    ###############################\n    model[\'summary_op\'] = _create_summary(model)\n\n    initial_image = utils.generate_noise_image(content_image, IMAGE_HEIGHT, IMAGE_WIDTH, NOISE_RATIO)\n    train(model, input_image, initial_image)\n\nif __name__ == \'__main__\':\n    main()\n'"
2017/assignments/style_transfer/utils.py,0,"b'"""""" Utils needed for the implementation of the paper ""A Neural Algorithm of Artistic Style""\nby Gatys et al. in TensorFlow.\n\nAuthor: Chip Huyen (huyenn@stanford.edu)\nPrepared for the class CS 20SI: ""TensorFlow for Deep Learning Research""\nFor more details, please read the assignment handout:\nhttp://web.stanford.edu/class/cs20si/assignments/a2.pdf\n""""""\nfrom __future__ import print_function\n\nimport os\n\nfrom PIL import Image, ImageOps\nimport numpy as np\nimport scipy.misc\nfrom six.moves import urllib\n\ndef download(download_link, file_name, expected_bytes):\n    """""" Download the pretrained VGG-19 model if it\'s not already downloaded """"""\n    if os.path.exists(file_name):\n        print(""VGG-19 pre-trained model ready"")\n        return\n    print(""Downloading the VGG pre-trained model. This might take a while ..."")\n    file_name, _ = urllib.request.urlretrieve(download_link, file_name)\n    file_stat = os.stat(file_name)\n    if file_stat.st_size == expected_bytes:\n        print(\'Successfully downloaded VGG-19 pre-trained model\', file_name)\n    else:\n        raise Exception(\'File \' + file_name +\n                        \' might be corrupted. You should try downloading it with a browser.\')\n\ndef get_resized_image(img_path, height, width, save=True):\n    image = Image.open(img_path)\n    # it\'s because PIL is column major so you have to change place of width and height\n    # this is stupid, i know\n    image = ImageOps.fit(image, (width, height), Image.ANTIALIAS)\n    if save:\n        image_dirs = img_path.split(\'/\')\n        image_dirs[-1] = \'resized_\' + image_dirs[-1]\n        out_path = \'/\'.join(image_dirs)\n        if not os.path.exists(out_path):\n            image.save(out_path)\n    image = np.asarray(image, np.float32)\n    return np.expand_dims(image, 0)\n\ndef generate_noise_image(content_image, height, width, noise_ratio=0.6):\n    noise_image = np.random.uniform(-20, 20, \n                                    (1, height, width, 3)).astype(np.float32)\n    return noise_image * noise_ratio + content_image * (1 - noise_ratio)\n\ndef save_image(path, image):\n    # Output should add back the mean pixels we subtracted at the beginning\n    image = image[0] # the image\n    image = np.clip(image, 0, 255).astype(\'uint8\')\n    scipy.misc.imsave(path, image)\n\ndef make_dir(path):\n    """""" Create a directory if there isn\'t one already. """"""\n    try:\n        os.mkdir(path)\n    except OSError:\n        pass'"
2017/assignments/style_transfer/vgg_model.py,8,"b'"""""" Load VGGNet weights needed for the implementation of the paper \n""A Neural Algorithm of Artistic Style"" by Gatys et al. in TensorFlow.\n\nAuthor: Chip Huyen (huyenn@stanford.edu)\nPrepared for the class CS 20SI: ""TensorFlow for Deep Learning Research""\nFor more details, please read the assignment handout:\nhttp://web.stanford.edu/class/cs20si/assignments/a2.pdf\n""""""\n\nimport numpy as np\nimport tensorflow as tf\nimport scipy.io\n\ndef _weights(vgg_layers, layer, expected_layer_name):\n    """""" Return the weights and biases already trained by VGG\n    """"""\n    W = vgg_layers[0][layer][0][0][2][0][0]\n    b = vgg_layers[0][layer][0][0][2][0][1]\n    layer_name = vgg_layers[0][layer][0][0][0][0]\n    assert layer_name == expected_layer_name\n    return W, b.reshape(b.size)\n\ndef _conv2d_relu(vgg_layers, prev_layer, layer, layer_name):\n    """""" Return the Conv2D layer with RELU using the weights, biases from the VGG\n    model at \'layer\'.\n    Inputs:\n        vgg_layers: holding all the layers of VGGNet\n        prev_layer: the output tensor from the previous layer\n        layer: the index to current layer in vgg_layers\n        layer_name: the string that is the name of the current layer.\n                    It\'s used to specify variable_scope.\n\n    Output:\n        relu applied on the convolution.\n\n    Note that you first need to obtain W and b from vgg-layers using the function\n    _weights() defined above.\n    W and b returned from _weights() are numpy arrays, so you have\n    to convert them to TF tensors using tf.constant.\n    Note that you\'ll have to do apply relu on the convolution.\n    Hint for choosing strides size: \n        for small images, you probably don\'t want to skip any pixel\n    """"""\n    with tf.variable_scope(layer_name) as scope:\n        W, b = _weights(vgg_layers, layer, layer_name)\n        W = tf.constant(W, name=\'weights\')\n        b = tf.constant(b, name=\'bias\')\n        conv2d = tf.nn.conv2d(prev_layer, filter=W, strides=[1, 1, 1, 1], padding=\'SAME\')\n    return tf.nn.relu(conv2d + b)\n\ndef _avgpool(prev_layer):\n    """""" Return the average pooling layer. The paper suggests that average pooling\n    actually works better than max pooling.\n    Input:\n        prev_layer: the output tensor from the previous layer\n\n    Output:\n        the output of the tf.nn.avg_pool() function.\n    Hint for choosing strides and kszie: choose what you feel appropriate\n    """"""\n    return tf.nn.avg_pool(prev_layer, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], \n                          padding=\'SAME\', name=\'avg_pool_\')\n\ndef load_vgg(path, input_image):\n    """""" Load VGG into a TensorFlow model.\n    Use a dictionary to hold the model instead of using a Python class\n    """"""\n    vgg = scipy.io.loadmat(path)\n    vgg_layers = vgg[\'layers\']\n\n    graph = {} \n    graph[\'conv1_1\']  = _conv2d_relu(vgg_layers, input_image, 0, \'conv1_1\')\n    graph[\'conv1_2\']  = _conv2d_relu(vgg_layers, graph[\'conv1_1\'], 2, \'conv1_2\')\n    graph[\'avgpool1\'] = _avgpool(graph[\'conv1_2\'])\n    graph[\'conv2_1\']  = _conv2d_relu(vgg_layers, graph[\'avgpool1\'], 5, \'conv2_1\')\n    graph[\'conv2_2\']  = _conv2d_relu(vgg_layers, graph[\'conv2_1\'], 7, \'conv2_2\')\n    graph[\'avgpool2\'] = _avgpool(graph[\'conv2_2\'])\n    graph[\'conv3_1\']  = _conv2d_relu(vgg_layers, graph[\'avgpool2\'], 10, \'conv3_1\')\n    graph[\'conv3_2\']  = _conv2d_relu(vgg_layers, graph[\'conv3_1\'], 12, \'conv3_2\')\n    graph[\'conv3_3\']  = _conv2d_relu(vgg_layers, graph[\'conv3_2\'], 14, \'conv3_3\')\n    graph[\'conv3_4\']  = _conv2d_relu(vgg_layers, graph[\'conv3_3\'], 16, \'conv3_4\')\n    graph[\'avgpool3\'] = _avgpool(graph[\'conv3_4\'])\n    graph[\'conv4_1\']  = _conv2d_relu(vgg_layers, graph[\'avgpool3\'], 19, \'conv4_1\')\n    graph[\'conv4_2\']  = _conv2d_relu(vgg_layers, graph[\'conv4_1\'], 21, \'conv4_2\')\n    graph[\'conv4_3\']  = _conv2d_relu(vgg_layers, graph[\'conv4_2\'], 23, \'conv4_3\')\n    graph[\'conv4_4\']  = _conv2d_relu(vgg_layers, graph[\'conv4_3\'], 25, \'conv4_4\')\n    graph[\'avgpool4\'] = _avgpool(graph[\'conv4_4\'])\n    graph[\'conv5_1\']  = _conv2d_relu(vgg_layers, graph[\'avgpool4\'], 28, \'conv5_1\')\n    graph[\'conv5_2\']  = _conv2d_relu(vgg_layers, graph[\'conv5_1\'], 30, \'conv5_2\')\n    graph[\'conv5_3\']  = _conv2d_relu(vgg_layers, graph[\'conv5_2\'], 32, \'conv5_3\')\n    graph[\'conv5_4\']  = _conv2d_relu(vgg_layers, graph[\'conv5_3\'], 34, \'conv5_4\')\n    graph[\'avgpool5\'] = _avgpool(graph[\'conv5_4\'])\n    \n    return graph'"
2017/assignments/style_transfer_starter/style_transfer.py,9,"b'"""""" An implementation of the paper ""A Neural Algorithm of Artistic Style""\nby Gatys et al. in TensorFlow.\n\nAuthor: Chip Huyen (huyenn@stanford.edu)\nPrepared for the class CS 20SI: ""TensorFlow for Deep Learning Research""\nFor more details, please read the assignment handout:\nhttp://web.stanford.edu/class/cs20si/assignments/a2.pdf\n""""""\nfrom __future__ import print_function\n\nimport os\nos.environ[\'TF_CPP_MIN_LOG_LEVEL\']=\'2\'\nimport time\n\nimport numpy as np\nimport tensorflow as tf\n\nimport vgg_model\nimport utils\n\n# parameters to manage experiments\nSTYLE = \'guernica\'\nCONTENT = \'deadpool\'\nSTYLE_IMAGE = \'styles/\' + STYLE + \'.jpg\'\nCONTENT_IMAGE = \'content/\' + CONTENT + \'.jpg\'\nIMAGE_HEIGHT = 250\nIMAGE_WIDTH = 333\nNOISE_RATIO = 0.6 # percentage of weight of the noise for intermixing with the content image\n\n# Layers used for style features. You can change this.\nSTYLE_LAYERS = [\'conv1_1\', \'conv2_1\', \'conv3_1\', \'conv4_1\', \'conv5_1\']\nW = [0.5, 1.0, 1.5, 3.0, 4.0] # give more weights to deeper layers.\n\n# Layer used for content features. You can change this.\nCONTENT_LAYER = \'conv4_2\'\n\nITERS = 300\nLR = 2.0\n\nSAVE_EVERY = 20\n\nMEAN_PIXELS = np.array([123.68, 116.779, 103.939]).reshape((1,1,1,3))\n"""""" MEAN_PIXELS is defined according to description on their github:\nhttps://gist.github.com/ksimonyan/211839e770f7b538e2d8\n\'In the paper, the model is denoted as the configuration D trained with scale jittering. \nThe input images should be zero-centered by mean pixel (rather than mean image) subtraction. \nNamely, the following BGR values should be subtracted: [103.939, 116.779, 123.68].\'\n""""""\n\n# VGG-19 parameters file\nVGG_DOWNLOAD_LINK = \'http://www.vlfeat.org/matconvnet/models/imagenet-vgg-verydeep-19.mat\'\nVGG_MODEL = \'imagenet-vgg-verydeep-19.mat\'\nEXPECTED_BYTES = 534904783\n\ndef _create_content_loss(p, f):\n    """""" Calculate the loss between the feature representation of the\n    content image and the generated image.\n    \n    Inputs: \n        p, f are just P, F in the paper \n        (read the assignment handout if you\'re confused)\n        Note: we won\'t use the coefficient 0.5 as defined in the paper\n        but the coefficient as defined in the assignment handout.\n    Output:\n        the content loss\n\n    """"""\n    pass\n\ndef _gram_matrix(F, N, M):\n    """""" Create and return the gram matrix for tensor F\n        Hint: you\'ll first have to reshape F\n    """"""\n    pass\n\ndef _single_style_loss(a, g):\n    """""" Calculate the style loss at a certain layer\n    Inputs:\n        a is the feature representation of the real image\n        g is the feature representation of the generated image\n    Output:\n        the style loss at a certain layer (which is E_l in the paper)\n\n    Hint: 1. you\'ll have to use the function _gram_matrix()\n        2. we\'ll use the same coefficient for style loss as in the paper\n        3. a and g are feature representation, not gram matrices\n    """"""\n    pass\n\ndef _create_style_loss(A, model):\n    """""" Return the total style loss\n    """"""\n    n_layers = len(STYLE_LAYERS)\n    E = [_single_style_loss(A[i], model[STYLE_LAYERS[i]]) for i in range(n_layers)]\n    \n    ###############################\n    ## TO DO: return total style loss\n    pass\n    ###############################\n\ndef _create_losses(model, input_image, content_image, style_image):\n    with tf.variable_scope(\'loss\') as scope:\n        with tf.Session() as sess:\n            sess.run(input_image.assign(content_image)) # assign content image to the input variable\n            p = sess.run(model[CONTENT_LAYER])\n        content_loss = _create_content_loss(p, model[CONTENT_LAYER])\n\n        with tf.Session() as sess:\n            sess.run(input_image.assign(style_image))\n            A = sess.run([model[layer_name] for layer_name in STYLE_LAYERS])                              \n        style_loss = _create_style_loss(A, model)\n\n        ##########################################\n        ## TO DO: create total loss. \n        ## Hint: don\'t forget the content loss and style loss weights\n        \n        ##########################################\n\n    return content_loss, style_loss, total_loss\n\ndef _create_summary(model):\n    """""" Create summary ops necessary\n        Hint: don\'t forget to merge them\n    """"""\n    pass\n\ndef train(model, generated_image, initial_image):\n    """""" Train your model.\n    Don\'t forget to create folders for checkpoints and outputs.\n    """"""\n    skip_step = 1\n    with tf.Session() as sess:\n        saver = tf.train.Saver()\n        ###############################\n        ## TO DO: \n        ## 1. initialize your variables\n        ## 2. create writer to write your graph\n        ###############################\n        sess.run(generated_image.assign(initial_image))\n        ckpt = tf.train.get_checkpoint_state(os.path.dirname(\'checkpoints/checkpoint\'))\n        if ckpt and ckpt.model_checkpoint_path:\n            saver.restore(sess, ckpt.model_checkpoint_path)\n        initial_step = model[\'global_step\'].eval()\n        \n        start_time = time.time()\n        for index in range(initial_step, ITERS):\n            if index >= 5 and index < 20:\n                skip_step = 10\n            elif index >= 20:\n                skip_step = 20\n            \n            sess.run(model[\'optimizer\'])\n            if (index + 1) % skip_step == 0:\n                ###############################\n                ## TO DO: obtain generated image and loss\n\n                ###############################\n                gen_image = gen_image + MEAN_PIXELS\n                writer.add_summary(summary, global_step=index)\n                print(\'Step {}\\n   Sum: {:5.1f}\'.format(index + 1, np.sum(gen_image)))\n                print(\'   Loss: {:5.1f}\'.format(total_loss))\n                print(\'   Time: {}\'.format(time.time() - start_time))\n                start_time = time.time()\n\n                filename = \'outputs/%d.png\' % (index)\n                utils.save_image(filename, gen_image)\n\n                if (index + 1) % SAVE_EVERY == 0:\n                    saver.save(sess, \'checkpoints/style_transfer\', index)\n\ndef main():\n    with tf.variable_scope(\'input\') as scope:\n        # use variable instead of placeholder because we\'re training the intial image to make it\n        # look like both the content image and the style image\n        input_image = tf.Variable(np.zeros([1, IMAGE_HEIGHT, IMAGE_WIDTH, 3]), dtype=tf.float32)\n    \n    utils.download(VGG_DOWNLOAD_LINK, VGG_MODEL, EXPECTED_BYTES)\n    utils.make_dir(\'checkpoints\')\n    utils.make_dir(\'outputs\')\n    model = vgg_model.load_vgg(VGG_MODEL, input_image)\n    model[\'global_step\'] = tf.Variable(0, dtype=tf.int32, trainable=False, name=\'global_step\')\n    \n    content_image = utils.get_resized_image(CONTENT_IMAGE, IMAGE_HEIGHT, IMAGE_WIDTH)\n    content_image = content_image - MEAN_PIXELS\n    style_image = utils.get_resized_image(STYLE_IMAGE, IMAGE_HEIGHT, IMAGE_WIDTH)\n    style_image = style_image - MEAN_PIXELS\n\n    model[\'content_loss\'], model[\'style_loss\'], model[\'total_loss\'] = _create_losses(model, \n                                                    input_image, content_image, style_image)\n    ###############################\n    ## TO DO: create optimizer\n    ## model[\'optimizer\'] = ...\n    ###############################\n    model[\'summary_op\'] = _create_summary(model)\n\n    initial_image = utils.generate_noise_image(content_image, IMAGE_HEIGHT, IMAGE_WIDTH, NOISE_RATIO)\n    train(model, input_image, initial_image)\n\nif __name__ == \'__main__\':\n    main()\n'"
2017/assignments/style_transfer_starter/utils.py,0,"b'"""""" Utils needed for the implementation of the paper ""A Neural Algorithm of Artistic Style""\nby Gatys et al. in TensorFlow.\n\nAuthor: Chip Huyen (huyenn@stanford.edu)\nPrepared for the class CS 20SI: ""TensorFlow for Deep Learning Research""\nFor more details, please read the assignment handout:\nhttp://web.stanford.edu/class/cs20si/assignments/a2.pdf\n""""""\nfrom __future__ import print_function\n\nimport os\n\nfrom PIL import Image, ImageOps\nimport numpy as np\nimport scipy.misc\nfrom six.moves import urllib\n\ndef download(download_link, file_name, expected_bytes):\n    """""" Download the pretrained VGG-19 model if it\'s not already downloaded """"""\n    if os.path.exists(file_name):\n        print(""VGG-19 pre-trained model ready"")\n        return\n    print(""Downloading the VGG pre-trained model. This might take a while ..."")\n    file_name, _ = urllib.request.urlretrieve(download_link, file_name)\n    file_stat = os.stat(file_name)\n    if file_stat.st_size == expected_bytes:\n        print(\'Successfully downloaded VGG-19 pre-trained model\', file_name)\n    else:\n        raise Exception(\'File \' + file_name +\n                        \' might be corrupted. You should try downloading it with a browser.\')\n\ndef get_resized_image(img_path, height, width, save=True):\n    image = Image.open(img_path)\n    # it\'s because PIL is column major so you have to change place of width and height\n    # this is stupid, i know\n    image = ImageOps.fit(image, (width, height), Image.ANTIALIAS)\n    if save:\n        image_dirs = img_path.split(\'/\')\n        image_dirs[-1] = \'resized_\' + image_dirs[-1]\n        out_path = \'/\'.join(image_dirs)\n        if not os.path.exists(out_path):\n            image.save(out_path)\n    image = np.asarray(image, np.float32)\n    return np.expand_dims(image, 0)\n\ndef generate_noise_image(content_image, height, width, noise_ratio=0.6):\n    noise_image = np.random.uniform(-20, 20, \n                                    (1, height, width, 3)).astype(np.float32)\n    return noise_image * noise_ratio + content_image * (1 - noise_ratio)\n\ndef save_image(path, image):\n    # Output should add back the mean pixels we subtracted at the beginning\n    image = image[0] # the image\n    image = np.clip(image, 0, 255).astype(\'uint8\')\n    scipy.misc.imsave(path, image)\n\ndef make_dir(path):\n    """""" Create a directory if there isn\'t one already. """"""\n    try:\n        os.mkdir(path)\n    except OSError:\n        pass'"
2017/assignments/style_transfer_starter/vgg_model.py,2,"b'"""""" Load VGGNet weights needed for the implementation of the paper \n""A Neural Algorithm of Artistic Style"" by Gatys et al. in TensorFlow.\n\nAuthor: Chip Huyen (huyenn@stanford.edu)\nPrepared for the class CS 20SI: ""TensorFlow for Deep Learning Research""\nFor more details, please read the assignment handout:\nhttp://web.stanford.edu/class/cs20si/assignments/a2.pdf\n""""""\n\nimport numpy as np\nimport tensorflow as tf\nimport scipy.io\n\ndef _weights(vgg_layers, layer, expected_layer_name):\n    """""" Return the weights and biases already trained by VGG\n    """"""\n    W = vgg_layers[0][layer][0][0][2][0][0]\n    b = vgg_layers[0][layer][0][0][2][0][1]\n    layer_name = vgg_layers[0][layer][0][0][0][0]\n    assert layer_name == expected_layer_name\n    return W, b.reshape(b.size)\n\ndef _conv2d_relu(vgg_layers, prev_layer, layer, layer_name):\n    """""" Return the Conv2D layer with RELU using the weights, biases from the VGG\n    model at \'layer\'.\n    Inputs:\n        vgg_layers: holding all the layers of VGGNet\n        prev_layer: the output tensor from the previous layer\n        layer: the index to current layer in vgg_layers\n        layer_name: the string that is the name of the current layer.\n                    It\'s used to specify variable_scope.\n\n    Output:\n        relu applied on the convolution.\n\n    Note that you first need to obtain W and b from vgg-layers using the function\n    _weights() defined above.\n    W and b returned from _weights() are numpy arrays, so you have\n    to convert them to TF tensors using tf.constant.\n    Note that you\'ll have to do apply relu on the convolution.\n    Hint for choosing strides size: \n        for small images, you probably don\'t want to skip any pixel\n    """"""\n    pass\n\ndef _avgpool(prev_layer):\n    """""" Return the average pooling layer. The paper suggests that average pooling\n    actually works better than max pooling.\n    Input:\n        prev_layer: the output tensor from the previous layer\n\n    Output:\n        the output of the tf.nn.avg_pool() function.\n    Hint for choosing strides and kszie: choose what you feel appropriate\n    """"""\n    pass\n\ndef load_vgg(path, input_image):\n    """""" Load VGG into a TensorFlow model.\n    Use a dictionary to hold the model instead of using a Python class\n    """"""\n    vgg = scipy.io.loadmat(path)\n    vgg_layers = vgg[\'layers\']\n\n    graph = {} \n    graph[\'conv1_1\']  = _conv2d_relu(vgg_layers, input_image, 0, \'conv1_1\')\n    graph[\'conv1_2\']  = _conv2d_relu(vgg_layers, graph[\'conv1_1\'], 2, \'conv1_2\')\n    graph[\'avgpool1\'] = _avgpool(graph[\'conv1_2\'])\n    graph[\'conv2_1\']  = _conv2d_relu(vgg_layers, graph[\'avgpool1\'], 5, \'conv2_1\')\n    graph[\'conv2_2\']  = _conv2d_relu(vgg_layers, graph[\'conv2_1\'], 7, \'conv2_2\')\n    graph[\'avgpool2\'] = _avgpool(graph[\'conv2_2\'])\n    graph[\'conv3_1\']  = _conv2d_relu(vgg_layers, graph[\'avgpool2\'], 10, \'conv3_1\')\n    graph[\'conv3_2\']  = _conv2d_relu(vgg_layers, graph[\'conv3_1\'], 12, \'conv3_2\')\n    graph[\'conv3_3\']  = _conv2d_relu(vgg_layers, graph[\'conv3_2\'], 14, \'conv3_3\')\n    graph[\'conv3_4\']  = _conv2d_relu(vgg_layers, graph[\'conv3_3\'], 16, \'conv3_4\')\n    graph[\'avgpool3\'] = _avgpool(graph[\'conv3_4\'])\n    graph[\'conv4_1\']  = _conv2d_relu(vgg_layers, graph[\'avgpool3\'], 19, \'conv4_1\')\n    graph[\'conv4_2\']  = _conv2d_relu(vgg_layers, graph[\'conv4_1\'], 21, \'conv4_2\')\n    graph[\'conv4_3\']  = _conv2d_relu(vgg_layers, graph[\'conv4_2\'], 23, \'conv4_3\')\n    graph[\'conv4_4\']  = _conv2d_relu(vgg_layers, graph[\'conv4_3\'], 25, \'conv4_4\')\n    graph[\'avgpool4\'] = _avgpool(graph[\'conv4_4\'])\n    graph[\'conv5_1\']  = _conv2d_relu(vgg_layers, graph[\'avgpool4\'], 28, \'conv5_1\')\n    graph[\'conv5_2\']  = _conv2d_relu(vgg_layers, graph[\'conv5_1\'], 30, \'conv5_2\')\n    graph[\'conv5_3\']  = _conv2d_relu(vgg_layers, graph[\'conv5_2\'], 32, \'conv5_3\')\n    graph[\'conv5_4\']  = _conv2d_relu(vgg_layers, graph[\'conv5_3\'], 34, \'conv5_4\')\n    graph[\'avgpool5\'] = _avgpool(graph[\'conv5_4\'])\n    \n    return graph'"
2017/examples/autoencoder/autoencoder.py,1,"b""import tensorflow as tf\n\nfrom layers import *\n\ndef encoder(input):\n    # Create a conv network with 3 conv layers and 1 FC layer\n    # Conv 1: filter: [3, 3, 1], stride: [2, 2], relu\n    \n    # Conv 2: filter: [3, 3, 8], stride: [2, 2], relu\n    \n    # Conv 3: filter: [3, 3, 8], stride: [2, 2], relu\n    \n    # FC: output_dim: 100, no non-linearity\n    raise NotImplementedError\n\ndef decoder(input):\n    # Create a deconv network with 1 FC layer and 3 deconv layers\n    # FC: output dim: 128, relu\n    \n    # Reshape to [batch_size, 4, 4, 8]\n    \n    # Deconv 1: filter: [3, 3, 8], stride: [2, 2], relu\n    \n    # Deconv 2: filter: [8, 8, 1], stride: [2, 2], padding: valid, relu\n    \n    # Deconv 3: filter: [7, 7, 1], stride: [1, 1], padding: valid, sigmoid\n    raise NotImplementedError\n\ndef autoencoder(input_shape):\n    # Define place holder with input shape\n\n    # Define variable scope for autoencoder\n    with tf.variable_scope('autoencoder') as scope:\n        # Pass input to encoder to obtain encoding\n        \n        # Pass encoding into decoder to obtain reconstructed image\n        \n        # Return input image (placeholder) and reconstructed image\n        pass\n"""
2017/examples/autoencoder/layer_utils.py,0,"b""import tensorflow as tf\n\ndef get_deconv2d_output_dims(input_dims, filter_dims, stride_dims, padding):\n    # Returns the height and width of the output of a deconvolution layer.\n    batch_size, input_h, input_w, num_channels_in = input_dims\n    filter_h, filter_w, num_channels_out  = filter_dims\n    stride_h, stride_w = stride_dims\n\n    # Compute the height in the output, based on the padding.\n    if padding == 'SAME':\n      out_h = input_h * stride_h\n    elif padding == 'VALID':\n      out_h = (input_h - 1) * stride_h + filter_h\n\n    # Compute the width in the output, based on the padding.\n    if padding == 'SAME':\n      out_w = input_w * stride_w\n    elif padding == 'VALID':\n      out_w = (input_w - 1) * stride_w + filter_w\n\n    return [batch_size, out_h, out_w, num_channels_out]\n"""
2017/examples/autoencoder/layers.py,7,"b""import tensorflow as tf\n\nfrom layer_utils import get_deconv2d_output_dims\n\ndef conv(input, name, filter_dims, stride_dims, padding='SAME',\n         non_linear_fn=tf.nn.relu):\n    input_dims = input.get_shape().as_list()\n    assert(len(input_dims) == 4) # batch_size, height, width, num_channels_in\n    assert(len(filter_dims) == 3) # height, width and num_channels out\n    assert(len(stride_dims) == 2) # stride height and width\n\n    num_channels_in = input_dims[-1]\n    filter_h, filter_w, num_channels_out = filter_dims\n    stride_h, stride_w = stride_dims\n\n    # Define a variable scope for the conv layer\n    with tf.variable_scope(name) as scope:\n        # Create filter weight variable\n        \n        # Create bias variable\n        \n        # Define the convolution flow graph\n        \n        # Add bias to conv output\n        \n        # Apply non-linearity (if asked) and return output\n        pass\n\ndef deconv(input, name, filter_dims, stride_dims, padding='SAME',\n           non_linear_fn=tf.nn.relu):\n    input_dims = input.get_shape().as_list()\n    assert(len(input_dims) == 4) # batch_size, height, width, num_channels_in\n    assert(len(filter_dims) == 3) # height, width and num_channels out\n    assert(len(stride_dims) == 2) # stride height and width\n\n    num_channels_in = input_dims[-1]\n    filter_h, filter_w, num_channels_out = filter_dims\n    stride_h, stride_w = stride_dims\n    # Let's step into this function\n    output_dims = get_deconv2d_output_dims(input_dims,\n                                           filter_dims,\n                                           stride_dims,\n                                           padding)\n\n    # Define a variable scope for the deconv layer\n    with tf.variable_scope(name) as scope:\n        # Create filter weight variable\n        # Note that num_channels_out and in positions are flipped for deconv.\n        \n        # Create bias variable\n        \n        # Define the deconv flow graph\n        \n        # Add bias to deconv output\n        \n        # Apply non-linearity (if asked) and return output\n        pass\n\ndef max_pool(input, name, filter_dims, stride_dims, padding='SAME'):\n    assert(len(filter_dims) == 2) # filter height and width\n    assert(len(stride_dims) == 2) # stride height and width\n\n    filter_h, filter_w = filter_dims\n    stride_h, stride_w = stride_dims\n    \n    # Define the max pool flow graph and return output\n    pass\n\ndef fc(input, name, out_dim, non_linear_fn=tf.nn.relu):\n    assert(type(out_dim) == int)\n\n    # Define a variable scope for the FC layer\n    with tf.variable_scope(name) as scope:\n        input_dims = input.get_shape().as_list()\n        # the input to the fc layer should be flattened\n        if len(input_dims) == 4:\n            # for eg. the output of a conv layer\n            batch_size, input_h, input_w, num_channels = input_dims\n            # ignore the batch dimension\n            in_dim = input_h * input_w * num_channels\n            flat_input = tf.reshape(input, [batch_size, in_dim])\n        else:\n            in_dim = input_dims[-1]\n            flat_input = input\n\n        # Create weight variable\n        \n        # Create bias variable\n        \n        # Define FC flow graph\n        \n        # Apply non-linearity (if asked) and return output\n        pass\n"""
2017/examples/autoencoder/train.py,5,"b'import tensorflow as tf\n\nfrom utils import *\nfrom autoencoder import *\n\nbatch_size = 100\nbatch_shape = (batch_size, 28, 28, 1)\nnum_visualize = 10\n\nlr = 0.01\nnum_epochs = 50\n\ndef calculate_loss(original, reconstructed):\n    return tf.div(tf.reduce_sum(tf.square(tf.sub(reconstructed,\n                                                 original))), \n                  tf.constant(float(batch_size)))\n\ndef train(dataset):\n    input_image, reconstructed_image = autoencoder(batch_shape)\n    loss = calculate_loss(input_image, reconstructed_image)\n    optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)\n\n    init = tf.global_variables_initializer()\n    with tf.Session() as session:\n        session.run(init)\n\n        dataset_size = len(dataset.train.images)\n        print ""Dataset size:"", dataset_size\n        num_iters = (num_epochs * dataset_size)/batch_size\n        print ""Num iters:"", num_iters\n        for step in xrange(num_iters):\n            input_batch  = get_next_batch(dataset.train, batch_size)\n            loss_val,  _ = session.run([loss, optimizer], \n                                       feed_dict={input_image: input_batch})\n            if step % 1000 == 0:\n                print ""Loss at step"", step, "":"", loss_val\n\n        test_batch = get_next_batch(dataset.test, batch_size)\n        reconstruction = session.run(reconstructed_image,\n                                     feed_dict={input_image: test_batch})\n        visualize(test_batch, reconstruction, num_visualize)\n\nif __name__ == \'__main__\':\n    dataset = load_dataset()\n    train(dataset)\n    \n'"
2017/examples/autoencoder/utils.py,0,"b'import os\nimport sys\nimport tensorflow\nimport numpy as np\n\nimport matplotlib\nmatplotlib.use(\'TKAgg\')\nfrom matplotlib import pyplot as plt\n\nfrom tensorflow.examples.tutorials.mnist import input_data\n\nmnist_image_shape = [28, 28, 1]\n\ndef load_dataset():\n    return input_data.read_data_sets(\'MNIST_data\')\n\ndef get_next_batch(dataset, batch_size):\n    # dataset should be mnist.(train/val/test)\n    batch, _ = dataset.next_batch(batch_size)\n    batch_shape = [batch_size] + mnist_image_shape\n    return np.reshape(batch, batch_shape)\n\ndef visualize(_original, _reconstructions, num_visualize):\n    vis_folder = \'./vis/\'\n    if not os.path.exists(vis_folder):\n          os.makedirs(vis_folder)\n\n    original = _original[:num_visualize]\n    reconstructions = _reconstructions[:num_visualize]\n    \n    count = 1\n    for (orig, rec) in zip(original, reconstructions):\n        orig = np.reshape(orig, (mnist_image_shape[0],\n                                 mnist_image_shape[1]))\n        rec = np.reshape(rec, (mnist_image_shape[0],\n                               mnist_image_shape[1]))\n        f, ax = plt.subplots(1,2)\n        ax[0].imshow(orig, cmap=\'gray\')\n        ax[1].imshow(rec, cmap=\'gray\')\n        plt.savefig(vis_folder + ""test_%d.png"" % count)\n        count += 1\n'"
2017/examples/cgru/custom_getter.py,1,"b'# From [github]/tensorflow/python/kernel_tests/variable_scope_test.py\n  def testGetterThatCreatesTwoVariablesAndSumsThem(self):\n\n    def custom_getter(getter, name, *args, **kwargs):\n      g_0 = getter(""%s/0"" % name, *args, **kwargs)\n      g_1 = getter(""%s/1"" % name, *args, **kwargs)\n      with tf.name_scope(""custom_getter""):\n        return g_0 + g_1  # or g_0 * const / ||g_0|| or anything you want\n\n    with variable_scope.variable_scope(""scope"", custom_getter=custom_getter):\n      v = variable_scope.get_variable(""v"", [1, 2, 3])\n      # Or a full model if you wish. OO layers are ok.\n\n    self.assertEqual([1, 2, 3], v.get_shape())\n    true_vars = variables_lib.trainable_variables()\n    self.assertEqual(2, len(true_vars))\n    self.assertEqual(""scope/v/0:0"", true_vars[0].name)\n    self.assertEqual(""scope/v/1:0"", true_vars[1].name)\n    self.assertEqual(""custom_getter/add:0"", v.name)\n    with self.test_session() as sess:\n      variables_lib.global_variables_initializer().run()\n      np_vars, np_v = sess.run([true_vars, v])\n      self.assertAllClose(np_v, sum(np_vars))\n'"
2017/examples/cgru/data_reader.py,20,"b'def examples_queue(data_sources, data_fields_to_features, training,\n                   data_items_to_decoders=None, data_items_to_decode=None):\n  """"""Contruct a queue of training or evaluation examples.\n\n  This function will create a reader from files given by data_sources,\n  then enqueue the tf.Examples from these files, shuffling if training\n  is true, and finally parse these tf.Examples to tensors.\n\n  The dictionary data_fields_to_features for an image dataset can be this:\n\n  data_fields_to_features = {\n    \'image/encoded\': tf.FixedLenFeature((), tf.string, default_value=\'\'),\n    \'image/format\': tf.FixedLenFeature((), tf.string, default_value=\'raw\'),\n    \'image/class/label\': tf.FixedLenFeature(\n        [1], tf.int64, default_value=tf.zeros([1], dtype=tf.int64)),\n  }\n\n  and for a simple algorithmic dataset with variable-length data it is this:\n\n  data_fields_to_features = {\n    \'inputs\': tf.VarLenFeature(tf.int64),\n    \'targets\': tf.VarLenFeature(tf.int64),\n  }\n\n  The data_items_to_decoders dictionary argument can be left as None if there\n  is no decoding to be performed. But, e.g. for images, it should be set so that\n  the images are decoded from the features, e.g., like this for MNIST:\n\n  data_items_to_decoders = {\n    \'image\': tfexample_decoder.Image(\n      image_key = \'image/encoded\',\n      format_key = \'image/format\',\n      shape=[28, 28],\n      channels=1),\n    \'label\': tfexample_decoder.Tensor(\'image/class/label\'),\n  }\n\n  These arguments are compatible with the use of tf.contrib.slim.data module,\n  see there for more documentation.\n\n  Args:\n    data_sources: a list or tuple of sources from which the data will be read,\n      for example [/path/to/train@128, /path/to/train2*, /tmp/.../train3*]\n    data_fields_to_features: a dictionary from data fields in the data sources\n      to features, such as tf.VarLenFeature(tf.int64), see above for examples.\n    training: a Boolean, whether to read for training or evaluation.\n    data_items_to_decoders: a dictionary mapping data items (that will be\n      in the returned result) to decoders that will decode them using features\n      defined in data_fields_to_features; see above for examples. By default\n      (if this is None), we grab the tensor from every feature.\n    data_items_to_decode: a subset of data items that will be decoded;\n      by default (if this is None), we decode all items.\n\n  Returns:\n    A dictionary mapping each data_field to a corresponding 1D int64 tensor\n    read from the created queue.\n\n  Raises:\n    ValueError: if no files are found with the provided data_prefix or no data\n      fields were provided.\n  """"""\n  with tf.name_scope(""examples_queue""):\n    # Read serialized examples using slim parallel_reader.\n    _, example_serialized = tf.contrib.slim.parallel_reader.parallel_read(\n        data_sources, tf.TFRecordReader, shuffle=training,\n        num_readers=4 if training else 1)\n\n    if data_items_to_decoders is None:\n      data_items_to_decoders = {\n          field: tf.contrib.slim.tfexample_decoder.Tensor(field)\n          for field in data_fields_to_features\n      }\n\n    decoder = tf.contrib.slim.tfexample_decoder.TFExampleDecoder(\n        data_fields_to_features, data_items_to_decoders)\n\n    if data_items_to_decode is None:\n      data_items_to_decode = data_items_to_decoders.keys()\n\n    decoded = decoder.decode(example_serialized, items=data_items_to_decode)\n    return {field: tensor\n            for (field, tensor) in zip(data_items_to_decode, decoded)}\n\n\ndef batch_examples(examples, batch_size, bucket_boundaries=None):\n  """"""Given a queue of examples, create batches of examples with similar lengths.\n\n  We assume that examples is a dictionary with string keys and tensor values,\n  possibly coming from a queue, e.g., constructed by examples_queue above.\n  Each tensor in examples is assumed to be 1D. We will put tensors of similar\n  length into batches togeter. We return a dictionary with the same keys as\n  examples, and with values being batches of size batch_size. If elements have\n  different lengths, they are padded with 0s. This function is based on\n  tf.contrib.training.bucket_by_sequence_length so see there for details.\n\n  For example, if examples is a queue containing [1, 2, 3] and [4], then\n  this function with batch_size=2 will return a batch [[1, 2, 3], [4, 0, 0]].\n\n  Args:\n    examples: a dictionary with string keys and 1D tensor values.\n    batch_size: a python integer or a scalar int32 tensor.\n    bucket_boundaries: a list of integers for the boundaries that will be\n      used for bucketing; see tf.contrib.training.bucket_by_sequence_length\n      for more details; if None, we create a default set of buckets.\n\n  Returns:\n    A dictionary with the same keys as examples and with values being batches\n    of examples padded with 0s, i.e., [batch_size x length] tensors.\n  """"""\n  # Create default buckets if none were provided.\n  if bucket_boundaries is None:\n    # Small buckets -- go in steps of 8 until 64.\n    small_buckets = [8 * (i + 1) for i in xrange(8)]\n    # Medium buckets -- go in steps of 32 until 256.\n    medium_buckets = [32 * (i + 3) for i in xrange(6)]\n    # Large buckets -- go in steps of 128 until maximum of 1024.\n    large_buckets = [128 * (i + 3) for i in xrange(6)]\n    # By default use the above 20 bucket boundaries (21 queues in total).\n    bucket_boundaries = small_buckets + medium_buckets + large_buckets\n  with tf.name_scope(""batch_examples""):\n    # The queue to bucket on will be chosen based on maximum length.\n    max_length = 0\n    for v in examples.values():  # We assume 0-th dimension is the length.\n      max_length = tf.maximum(max_length, tf.shape(v)[0])\n    (_, outputs) = tf.contrib.training.bucket_by_sequence_length(\n        max_length, examples, batch_size, bucket_boundaries,\n        capacity=2 * batch_size, dynamic_pad=True)\n    return outputs\n'"
2017/examples/cgru/my_layers.py,10,"b'def saturating_sigmoid(x):\n  """"""Saturating sigmoid: 1.2 * sigmoid(x) - 0.1 cut to [0, 1].""""""\n  with tf.name_scope(""saturating_sigmoid"", [x]):\n    y = tf.sigmoid(x)\n    return tf.minimum(1.0, tf.maximum(0.0, 1.2 * y - 0.1))\n\n\ndef embedding(x, vocab_size, dense_size, name=None, reuse=None):\n  """"""Embed x of type int64 into dense vectors, reducing to max 4 dimensions.""""""\n  with tf.variable_scope(name, default_name=""embedding"",\n                         values=[x], reuse=reuse):\n    embedding_var = tf.get_variable(""kernel"", [vocab_size, dense_size])\n    return tf.gather(embedding_var, x)\n\n\ndef conv_gru(x, kernel_size, filters, padding=""same"", dilation_rate=1,\n             name=None, reuse=None):\n  """"""Convolutional GRU in 1 dimension.""""""\n  # Let\'s make a shorthand for conv call first.\n  def do_conv(args, name, bias_start, padding):\n    return tf.layers.conv1d(args, filters, kernel_size,\n                padding=padding, dilation_rate=dilation_rate,\n                bias_initializer=tf.constant_initializer(bias_start), name=name)\n  # Here comes the GRU gate.\n  with tf.variable_scope(name, default_name=""conv_gru"",\n                         values=[x], reuse=reuse):\n    reset = saturating_sigmoid(do_conv(x, ""reset"", 1.0, padding))\n    gate = saturating_sigmoid(do_conv(x, ""gate"", 1.0, padding))\n    candidate = tf.tanh(do_conv(reset * x, ""candidate"", 0.0, padding))\n    return gate * x + (1 - gate) * candidate\n'"
2017/examples/cgru/neural_gpu_v3.py,17,"b'def neural_gpu(features, hparams, name=None):\n  """"""The core Neural GPU.""""""\n  with tf.variable_scope(name, ""neural_gpu""):\n    inputs = features[""inputs""]\n    emb_inputs = common_layers.embedding(\n        inputs, hparams.vocab_size, hparams.hidden_size)\n\n    def step(state, inp):\n      x = tf.nn.dropout(state, 1.0 - hparams.dropout)\n      for layer in xrange(hparams.num_hidden_layers):\n        x = common_layers.conv_gru(\n            x, hparams.kernel_size, hparams.hidden_size, name=""cgru_%d"" % layer)\n      return tf.where(inp == 0, state, x)  # No-op where inp is just padding=0.\n\n    final = tf.foldl(step, tf.transpose(inputs, [1, 0]),\n                     initializer=emb_inputs,\n                     parallel_iterations=1, swap_memory=True)\n    return common_layers.conv(final, hparams.vocab_size, 3, padding=""same"")\n\n\ndef mixed_curriculum(inputs, hparams):\n  """"""Mixed curriculum: skip short sequences, but only with some probability.""""""\n  with tf.name_scope(""mixed_curriculum""):\n    inputs_length = tf.to_float(tf.shape(inputs)[1])\n    used_length = tf.cond(tf.less(tf.random_uniform([]),\n                                  hparams.curriculum_mixing_probability),\n                          lambda: tf.constant(0.0),\n                          lambda: inputs_length)\n    step = tf.to_float(tf.contrib.framework.get_global_step())\n    relative_step = step / hparams.curriculum_lengths_per_step\n    return used_length - hparams.curriculum_min_length > relative_step\n\n\ndef neural_gpu_curriculum(features, hparams, mode):\n  """"""The Neural GPU model with curriculum.""""""\n  with tf.name_scope(""neural_gpu_with_curriculum""):\n    inputs = features[""inputs""]\n    is_training = mode == tf.contrib.learn.ModeKeys.TRAIN\n    should_skip = tf.logical_and(is_training, mixed_curriculum(inputs, hparams))\n    final_shape = tf.concat([tf.shape(inputs),\n                             tf.constant([hparams.vocab_size])], axis=0)\n    outputs = tf.cond(should_skip,\n                      lambda: tf.zeros(final_shape),\n                      lambda: neural_gpu(features, hparams))\n    return outputs, should_skip\n\n\ndef basic_params1():\n  """"""A set of basic hyperparameters.""""""\n  return tf.HParams(batch_size=32,\n                    num_hidden_layers=4,\n                    kernel_size=3,\n                    hidden_size=64,\n                    vocab_size=256,\n                    dropout=0.2,\n                    clip_grad_norm=2.0,\n                    initializer=""orthogonal"",\n                    initializer_gain=1.5,\n                    label_smoothing=0.1,\n                    optimizer=""Adam"",\n                    optimizer_adam_epsilon=1e-4,\n                    optimizer_momentum_momentum=0.9,\n                    max_train_length=512,\n                    learning_rate_decay_scheme=""none"",\n                    learning_rate_warmup_steps=100,\n                    learning_rate=0.1)\n\n\ndef curriculum_params1():\n  """"""Set of hyperparameters with curriculum settings.""""""\n  hparams = common_hparams.basic_params1()\n  hparams.add_hparam(""curriculum_mixing_probability"", 0.1)\n  hparams.add_hparam(""curriculum_lengths_per_step"", 1000.0)\n  hparams.add_hparam(""curriculum_min_length"", 10)\n  return hparams\n'"
2017/examples/deepdream/deepdream_exercise.py,15,"b'""""""DeepDream.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os.path\nimport zipfile\n\nimport numpy as np\nimport PIL.Image\n\nimport tensorflow as tf\n\nFLAGS = tf.app.flags.FLAGS\n\n\ntf.app.flags.DEFINE_string(\'data_dir\',\n                           \'/tmp/inception/\',\n                           \'Directory for storing Inception network.\')\n\ntf.app.flags.DEFINE_string(\'jpeg_file\',\n                           \'output.jpg\',\n                           \'Where to save the resulting JPEG.\')\n\n\ndef get_layer(layer):\n  """"""Helper for getting layer output Tensor in model Graph.\n\n  Args:\n   layer: string, layer name\n\n  Returns:\n    Tensor for that layer.\n  """"""\n  graph = tf.get_default_graph()\n  return graph.get_tensor_by_name(\'import/%s:0\' % layer)\n\n\ndef maybe_download(data_dir):\n  """"""Maybe download pretrained Inception network.\n\n  Args:\n    data_dir: string, path to data\n  """"""\n  url = (\'https://storage.googleapis.com/download.tensorflow.org/models/\'\n         \'inception5h.zip\')\n  basename = \'inception5h.zip\'\n  local_file = tf.contrib.learn.python.learn.datasets.base.maybe_download(\n      basename, data_dir, url)\n\n  # Uncompress the pretrained Inception network.\n  print(\'Extracting\', local_file)\n  zip_ref = zipfile.ZipFile(local_file, \'r\')\n  zip_ref.extractall(FLAGS.data_dir)\n  zip_ref.close()\n\n\ndef normalize_image(image):\n  """"""Stretch the range and prepare the image for saving as a JPEG.\n\n  Args:\n    image: numpy array\n\n  Returns:\n    numpy array of image in uint8\n  """"""\n  # Clip to [0, 1] and then convert to uint8.\n  image = np.clip(image, 0, 1)\n  image = np.uint8(image * 255)\n  return image\n\n\ndef save_jpeg(jpeg_file, image):\n  pil_image = PIL.Image.fromarray(image)\n  pil_image.save(jpeg_file)\n  print(\'Saved to file: \', jpeg_file)\n\n\ndef main(unused_argv):\n  # Maybe download and uncompress pretrained Inception network.\n  maybe_download(FLAGS.data_dir)\n\n  model_fn = os.path.join(FLAGS.data_dir, \'tensorflow_inception_graph.pb\')\n\n  # Load the pretrained Inception model as a GraphDef.\n  with tf.gfile.FastGFile(model_fn, \'rb\') as f:\n    graph_def = tf.GraphDef()\n    graph_def.ParseFromString(f.read())\n\n  with tf.Graph().as_default():\n    # Input for the network.\n    input_image = tf.placeholder(np.float32, name=\'input\')\n    pixel_mean = 117.0\n    input_preprocessed = tf.expand_dims(input_image - pixel_mean, 0)\n    tf.import_graph_def(graph_def, {\'input\': input_preprocessed})\n\n    # Grab a list of the names of Tensor\'s that are the output of convolutions.\n    graph = tf.get_default_graph()\n    layers = [op.name for op in graph.get_operations()\n              if op.type == \'Conv2D\' and \'import/\' in op.name]\n    feature_nums = [int(graph.get_tensor_by_name(name+\':0\').get_shape()[-1])\n                    for name in layers]\n    # print(\'Layers available: %s\' % \',\'.join(layers))\n    print(\'Number of layers\', len(layers))\n    print(\'Number of features:\', sum(feature_nums))\n\n    # Pick an internal layer and node to visualize.\n    # Note that we use outputs before applying the ReLU nonlinearity to\n    # have non-zero gradients for features with negative initial activations.\n    layer = \'mixed4d_3x3_bottleneck_pre_relu\'\n    channel = 139\n    layer_channel = get_layer(layer)[:, :, :, channel]\n    print(\'layer %s, channel %d: %s\' % (layer, channel, layer_channel))\n\n    # Define the optimization as the average across all spatial locations.\n    score = tf.reduce_mean(layer_channel)\n\n    # Automatic differentiation with TensorFlow. Magic!\n    input_gradient = tf.gradients(score, input_image)[0]\n\n    # Employ random noise as a image.\n    noise_image = np.random.uniform(size=(224, 224, 3)) + 100.0\n    image = noise_image.copy()\n\n    ################################################################\n    # EXERCISE: Implemement the Deep Dream algorithm here!\n    ################################################################\n\n  # Save the image.\n  stddev = 0.1\n  image = (image - image.mean()) / max(image.std(), 1e-4) * stddev + 0.5\n  image = normalize_image(image)\n  save_jpeg(FLAGS.jpeg_file, image)\n\n\nif __name__ == \'__main__\':\n  tf.app.run()'"
2017/examples/deepdream/deepdream_solution.py,16,"b'""""""DeepDream.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os.path\nimport zipfile\n\nimport sys\nsys.path.extend([\'\', \'/Users/shlens/Desktop/Neural-Art/homebrew/Cellar/python/2.7.13/Frameworks/Python.framework/Versions/2.7/lib/python27.zip\', \'/Users/shlens/Desktop/Neural-Art/homebrew/Cellar/python/2.7.13/Frameworks/Python.framework/Versions/2.7/lib/python2.7\', \'/Users/shlens/Desktop/Neural-Art/homebrew/Cellar/python/2.7.13/Frameworks/Python.framework/Versions/2.7/lib/python2.7/plat-darwin\', \'/Users/shlens/Desktop/Neural-Art/homebrew/Cellar/python/2.7.13/Frameworks/Python.framework/Versions/2.7/lib/python2.7/plat-mac\', \'/Users/shlens/Desktop/Neural-Art/homebrew/Cellar/python/2.7.13/Frameworks/Python.framework/Versions/2.7/lib/python2.7/plat-mac/lib-scriptpackages\', \'/Users/shlens/Desktop/Neural-Art/homebrew/Cellar/python/2.7.13/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-tk\', \'/Users/shlens/Desktop/Neural-Art/homebrew/Cellar/python/2.7.13/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-old\', \'/Users/shlens/Desktop/Neural-Art/homebrew/Cellar/python/2.7.13/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload\', \'/Users/shlens/Desktop/Neural-Art/homebrew/lib/python2.7/site-packages\', \'/Users/shlens/Desktop/Neural-Art/homebrew/lib/python2.7/site-packages/gtk-2.0\', \'/Users/shlens/Desktop/Neural-Art/homebrew/lib/python2.7/site-packages/gtk-2.0\'])\n\n\nimport numpy as np\nimport PIL.Image\n\nimport tensorflow as tf\n\nFLAGS = tf.app.flags.FLAGS\n\n\ntf.app.flags.DEFINE_string(\'data_dir\',\n                           \'/tmp/inception/\',\n                           \'Directory for storing Inception network.\')\n\ntf.app.flags.DEFINE_string(\'jpeg_file\',\n                           \'output.jpg\',\n                           \'Where to save the resulting JPEG.\')\n\n\ndef get_layer(layer):\n  """"""Helper for getting layer output Tensor in model Graph.\n\n  Args:\n   layer: string, layer name\n\n  Returns:\n    Tensor for that layer.\n  """"""\n  graph = tf.get_default_graph()\n  return graph.get_tensor_by_name(\'import/%s:0\' % layer)\n\n\ndef maybe_download(data_dir):\n  """"""Maybe download pretrained Inception network.\n\n  Args:\n    data_dir: string, path to data\n  """"""\n  url = (\'https://storage.googleapis.com/download.tensorflow.org/models/\'\n         \'inception5h.zip\')\n  basename = \'inception5h.zip\'\n  local_file = tf.contrib.learn.python.learn.datasets.base.maybe_download(\n      basename, data_dir, url)\n\n  # Uncompress the pretrained Inception network.\n  print(\'Extracting\', local_file)\n  zip_ref = zipfile.ZipFile(local_file, \'r\')\n  zip_ref.extractall(FLAGS.data_dir)\n  zip_ref.close()\n\n\ndef normalize_image(image):\n  """"""Stretch the range and prepare the image for saving as a JPEG.\n\n  Args:\n    image: numpy array\n\n  Returns:\n    numpy array of image in uint8\n  """"""\n  # Clip to [0, 1] and then convert to uint8.\n  image = np.clip(image, 0, 1)\n  image = np.uint8(image * 255)\n  return image\n\n\ndef save_jpeg(jpeg_file, image):\n  pil_image = PIL.Image.fromarray(image)\n  pil_image.save(jpeg_file)\n  print(\'Saved to file: \', jpeg_file)\n\n\ndef main(unused_argv):\n  # Maybe download and uncompress pretrained Inception network.\n  maybe_download(FLAGS.data_dir)\n\n  model_fn = os.path.join(FLAGS.data_dir, \'tensorflow_inception_graph.pb\')\n\n  # Load the pretrained Inception model as a GraphDef.\n  with tf.gfile.FastGFile(model_fn, \'rb\') as f:\n    graph_def = tf.GraphDef()\n    graph_def.ParseFromString(f.read())\n\n  with tf.Graph().as_default():\n    # Input for the network.\n    input_image = tf.placeholder(np.float32, name=\'input\')\n    pixel_mean = 117.0\n    input_preprocessed = tf.expand_dims(input_image - pixel_mean, 0)\n    tf.import_graph_def(graph_def, {\'input\': input_preprocessed})\n\n    # Grab a list of the names of Tensor\'s that are the output of convolutions.\n    graph = tf.get_default_graph()\n    layers = [op.name for op in graph.get_operations()\n              if op.type == \'Conv2D\' and \'import/\' in op.name]\n    feature_nums = [int(graph.get_tensor_by_name(name+\':0\').get_shape()[-1])\n                    for name in layers]\n    # print(\'Layers available: %s\' % \',\'.join(layers))\n    print(\'Number of layers\', len(layers))\n    print(\'Number of features:\', sum(feature_nums))\n\n    # Pick an internal layer and node to visualize.\n    # Note that we use outputs before applying the ReLU nonlinearity to\n    # have non-zero gradients for features with negative initial activations.\n    layer = \'mixed4d_3x3_bottleneck_pre_relu\'\n    channel = 139\n    layer_channel = get_layer(layer)[:, :, :, channel]\n    print(\'layer %s, channel %d: %s\' % (layer, channel, layer_channel))\n\n    # Define the optimization as the average across all spatial locations.\n    score = tf.reduce_mean(layer_channel)\n\n    # Automatic differentiation with TensorFlow. Magic!\n    input_gradient = tf.gradients(score, input_image)[0]\n\n    # Employ random noise as a image.\n    noise_image = np.random.uniform(size=(224, 224, 3)) + 100.0\n    image = noise_image.copy()\n    \n    ################################################################\n    ### BEGIN SOLUTION #####\n    ################################################################\n    step_scale = 1.0\n    num_iter = 20\n    with tf.Session() as sess:\n      for i in xrange(num_iter):\n        image_gradient, score_value = sess.run([input_gradient, score], {input_image:image})\n        # Normalize the gradient, so the same step size should work \n        image_gradient /= image_gradient.std() + 1e-8 \n        image += image_gradient * step_scale\n        print(\'At step = %d, score = %.3f\' % (i, score_value))\n\n  # Save the image.\n  stddev = 0.1\n  image = (image - image.mean()) / max(image.std(), 1e-4) * stddev + 0.5\n  image = normalize_image(image)\n  save_jpeg(FLAGS.jpeg_file, image)\n  ##################################################################\n  ### END SOLUTION #####\n  ##################################################################\n\n\nif __name__ == \'__main__\':\n  tf.app.run()'"
