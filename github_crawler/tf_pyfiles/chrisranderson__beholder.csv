file_path,api_count,code
setup.py,0,"b""from setuptools import setup\n\nsetup(\n    name='beholder',\n    version='0.0.1',\n    packages=['beholder'],\n    package_data={'beholder': ['resources/*']},\n    url='https://github.com/chrisranderson/beholder',\n    author='Chris Anderson',\n    install_requires=[\n      'futures',\n      'grpcio'\n    ],\n)\n"""
beholder/__init__.py,0,b''
beholder/beholder.py,6,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport time\n\nimport tensorflow as tf\n\nfrom beholder import im_util\nfrom beholder.file_system_tools import read_pickle, write_pickle, write_file\nfrom beholder.shared_config import PLUGIN_NAME, TAG_NAME, SUMMARY_FILENAME,\\\n  DEFAULT_CONFIG, CONFIG_FILENAME\nfrom beholder import video_writing\nfrom beholder.visualizer import Visualizer\n\nclass Beholder(object):\n\n  def __init__(self, session, logdir):\n    self.video_writer = None\n\n    self.PLUGIN_LOGDIR = logdir + \'/plugins/\' + PLUGIN_NAME\n    self.SESSION = session\n\n    self.frame_placeholder = None\n    self.summary_op = None\n\n    self.last_image_shape = []\n    self.last_update_time = time.time()\n    self.config_last_modified_time = -1\n    self.previous_config = dict(DEFAULT_CONFIG)\n\n    if not tf.gfile.Exists(self.PLUGIN_LOGDIR + \'/config.pkl\'):\n      tf.gfile.MakeDirs(self.PLUGIN_LOGDIR)\n      write_pickle(DEFAULT_CONFIG, \'{}/{}\'.format(self.PLUGIN_LOGDIR,\n                                                  CONFIG_FILENAME))\n\n    self.visualizer = Visualizer(self.PLUGIN_LOGDIR)\n\n\n  def _get_config(self):\n    \'\'\'Reads the config file from disk or creates a new one.\'\'\'\n    filename = \'{}/{}\'.format(self.PLUGIN_LOGDIR, CONFIG_FILENAME)\n    modified_time = os.path.getmtime(filename)\n\n    if modified_time != self.config_last_modified_time:\n      config = read_pickle(filename, default=self.previous_config)\n      self.previous_config = config\n    else:\n      config = self.previous_config\n\n    self.config_last_modified_time = modified_time\n    return config\n\n\n  def _write_summary(self, frame):\n    \'\'\'Writes the frame to disk as a tensor summary.\'\'\'\n    summary = self.SESSION.run(self.summary_op, feed_dict={\n        self.frame_placeholder: frame\n    })\n    path = \'{}/{}\'.format(self.PLUGIN_LOGDIR, SUMMARY_FILENAME)\n    write_file(summary, path)\n\n\n\n  def _get_final_image(self, config, arrays=None, frame=None):\n    if config[\'values\'] == \'frames\':\n      if frame is None:\n        final_image = im_util.get_image_relative_to_script(\'frame-missing.png\')\n      else:\n        frame = frame() if callable(frame) else frame\n        final_image = im_util.scale_image_for_display(frame)\n\n    elif config[\'values\'] == \'arrays\':\n      if arrays is None:\n        final_image = im_util.get_image_relative_to_script(\'arrays-missing.png\')\n        # TODO: hack to clear the info. Should be cleaner.\n        self.visualizer._save_section_info([], [])\n      else:\n        final_image = self.visualizer.build_frame(arrays)\n\n    elif config[\'values\'] == \'trainable_variables\':\n      arrays = [self.SESSION.run(x) for x in tf.trainable_variables()]\n      final_image = self.visualizer.build_frame(arrays)\n\n    return final_image\n\n\n  def _enough_time_has_passed(self, FPS):\n    \'\'\'For limiting how often frames are computed.\'\'\'\n    if FPS == 0:\n      return False\n    else:\n      earliest_time = self.last_update_time + (1.0 / FPS)\n      return time.time() >= earliest_time\n\n\n  def _update_frame(self, arrays, frame, config):\n    final_image = self._get_final_image(config, arrays, frame)\n\n    if self.summary_op is None or self.last_image_shape != final_image.shape:\n      self.frame_placeholder = tf.placeholder(tf.uint8, final_image.shape)\n      self.summary_op = tf.summary.tensor_summary(TAG_NAME,\n                                                  self.frame_placeholder)\n    self._write_summary(final_image)\n    self.last_image_shape = final_image.shape\n\n    return final_image\n\n\n  def _update_recording(self, frame, config):\n    \'\'\'Adds a frame to the video using ffmpeg if possible. If not, writes\n    individual frames as png files in a directory.\n    \'\'\'\n    # pylint: disable=redefined-variable-type\n    is_recording = config[\'is_recording\']\n    filename = self.PLUGIN_LOGDIR + \'/video-{}.mp4\'.format(time.time())\n\n    if is_recording:\n      if self.video_writer is None or frame.shape != self.video_writer.size:\n        try:\n          self.video_writer = video_writing.FFMPEG_VideoWriter(filename,\n                                                               frame.shape,\n                                                               15)\n        except OSError:\n          message = (\'Either ffmpeg is not installed, or something else went \'\n                     \'wrong. Saving individual frames to disk instead.\')\n          print(message)\n          self.video_writer = video_writing.PNGWriter(self.PLUGIN_LOGDIR,\n                                                      frame.shape)\n      self.video_writer.write_frame(frame)\n    elif not is_recording and self.video_writer is not None:\n      self.video_writer.close()\n      self.video_writer = None\n\n\n  # TODO: blanket try and except for production? I don\'t someone\'s script to die\n  #       after weeks of running because of a visualization.\n  def update(self, arrays=None, frame=None):\n    \'\'\'Creates a frame and writes it to disk.\n\n    Args:\n      arrays: a list of np arrays. Use the ""custom"" option in the client.\n      frame: a 2D np array. This way the plugin can be used for video of any\n             kind, not just the visualization that comes with the plugin.\n\n             frame can also be a function, which only is evaluated when the\n             ""frame"" option is selected by the client.\n    \'\'\'\n    new_config = self._get_config()\n\n    if self._enough_time_has_passed(self.previous_config[\'FPS\']):\n      self.visualizer.update(new_config)\n      self.last_update_time = time.time()\n      final_image = self._update_frame(arrays, frame, new_config)\n      self._update_recording(final_image, new_config)\n\n\n  ##############################################################################\n\n  @staticmethod\n  def gradient_helper(optimizer, loss, var_list=None):\n    \'\'\'A helper to get the gradients out at each step.\n\n    Args:\n      optimizer: the optimizer op.\n      loss: the op that computes your loss value.\n\n    Returns: the gradient tensors and the train_step op.\n    \'\'\'\n    if var_list is None:\n      var_list = tf.trainable_variables()\n\n    grads_and_vars = optimizer.compute_gradients(loss, var_list=var_list)\n    grads = [pair[0] for pair in grads_and_vars]\n\n    return grads, optimizer.apply_gradients(grads_and_vars)\n'"
beholder/file_system_tools.py,7,"b""from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport pickle\n\nfrom google.protobuf import message\nimport tensorflow as tf\n\ndef write_file(contents, path, mode='wb'):\n  with tf.gfile.Open(path, mode) as new_file:\n    new_file.write(contents)\n\n\ndef read_tensor_summary(path):\n  with tf.gfile.Open(path, 'rb') as summary_file:\n    summary_string = summary_file.read()\n\n  if not summary_string:\n    raise message.DecodeError('Empty summary.')\n\n  summary_proto = tf.Summary()\n  summary_proto.ParseFromString(summary_string)\n  tensor_proto = summary_proto.value[0].tensor\n  array = tf.make_ndarray(tensor_proto)\n\n  return array\n\n\ndef write_pickle(obj, path):\n  with tf.gfile.Open(path, 'wb') as new_file:\n    pickle.dump(obj, new_file)\n\n\ndef read_pickle(path, default=None):\n  try:\n    with tf.gfile.Open(path, 'rb') as pickle_file:\n      result = pickle.load(pickle_file)\n\n  except (IOError, EOFError, ValueError, tf.errors.NotFoundError) as e:\n    # TODO: log this somehow? Could swallow errors I don't intend.\n    if default is not None:\n      result = default\n    else:\n      raise e\n\n  return result\n\n\ndef resources_path():\n  script_directory = os.path.dirname(__file__)\n  filename = os.path.join(script_directory, 'resources')\n  return filename\n"""
beholder/im_util.py,13,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport threading\n\nimport numpy as np\nimport tensorflow as tf\n\nfrom beholder.file_system_tools import resources_path\n\n# pylint: disable=not-context-manager\n\ndef global_extrema(arrays):\n  return min([x.min() for x in arrays]), max([x.max() for x in arrays])\n\n\ndef scale_sections(sections, scaling_scope):\n  \'\'\'\n  input: unscaled sections.\n  returns: sections scaled to [0, 255]\n  \'\'\'\n  new_sections = []\n\n  if scaling_scope == \'layer\':\n    for section in sections:\n      new_sections.append(scale_image_for_display(section))\n\n  elif scaling_scope == \'network\':\n    global_min, global_max = global_extrema(sections)\n\n    for section in sections:\n      new_sections.append(scale_image_for_display(section,\n                                                  global_min,\n                                                  global_max))\n  return new_sections\n\n\ndef scale_image_for_display(image, minimum=None, maximum=None):\n  image = image.astype(float)\n\n  minimum = image.min() if minimum is None else minimum\n  image -= minimum\n\n  maximum = image.max() if maximum is None else maximum\n\n  if maximum == 0:\n    return image\n  else:\n    image *= 255 / maximum\n    return image.astype(np.uint8)\n\n\ndef pad_to_shape(array, shape, constant=245):\n  padding = []\n\n  for actual_dim, target_dim in zip(array.shape, shape):\n    start_padding = 0\n    end_padding = target_dim - actual_dim\n\n    padding.append((start_padding, end_padding))\n\n  return np.pad(array, padding, mode=\'constant\', constant_values=constant)\n\n# New matplotlib colormaps by Nathaniel J. Smith, Stefan van der Walt,\n# and (in the case of viridis) Eric Firing.\n#\n# This file and the colormaps in it are released under the CC0 license /\n# public domain dedication. We would appreciate credit if you use or\n# redistribute these colormaps, but do not impose any legal restrictions.\n#\n# To the extent possible under law, the persons who associated CC0 with\n# mpl-colormaps have waived all copyright and related or neighboring rights\n# to mpl-colormaps.\n#\n# You should have received a copy of the CC0 legalcode along with this\n# work.  If not, see <http://creativecommons.org/publicdomain/zero/1.0/>.\ncolormaps = np.load(\'{}/colormaps.npy\'.format(resources_path()))\nmagma_data, inferno_data, plasma_data, viridis_data = colormaps\n\n\ndef apply_colormap(image, colormap=\'magma\'):\n  if colormap == \'grayscale\':\n    return image\n\n  data_map = {\n      \'magma\': magma_data,\n      \'inferno\': inferno_data,\n      \'plasma\': plasma_data,\n      \'viridis\': viridis_data,\n  }\n\n  colormap_data = data_map[colormap]\n  return (colormap_data[image]*255).astype(np.uint8)\n\n# Taken from https://github.com/tensorflow/tensorboard/blob/\n#            /28f58888ebb22e2db0f4f1f60cd96138ef72b2ef/tensorboard/util.py\n\n# Modified by Chris Anderson to not use the GPU.\nclass PersistentOpEvaluator(object):\n  """"""Evaluate a fixed TensorFlow graph repeatedly, safely, efficiently.\n  Extend this class to create a particular kind of op evaluator, like an\n  image encoder. In `initialize_graph`, create an appropriate TensorFlow\n  graph with placeholder inputs. In `run`, evaluate this graph and\n  return its result. This class will manage a singleton graph and\n  session to preserve memory usage, and will ensure that this graph and\n  session do not interfere with other concurrent sessions.\n  A subclass of this class offers a threadsafe, highly parallel Python\n  entry point for evaluating a particular TensorFlow graph.\n  Example usage:\n      class FluxCapacitanceEvaluator(PersistentOpEvaluator):\n        \\""\\""\\""Compute the flux capacitance required for a system.\n        Arguments:\n          x: Available power input, as a `float`, in jigawatts.\n        Returns:\n          A `float`, in nanofarads.\n        \\""\\""\\""\n        def initialize_graph(self):\n          self._placeholder = tf.placeholder(some_dtype)\n          self._op = some_op(self._placeholder)\n        def run(self, x):\n          return self._op.eval(feed_dict: {self._placeholder: x})\n      evaluate_flux_capacitance = FluxCapacitanceEvaluator()\n      for x in xs:\n        evaluate_flux_capacitance(x)\n  """"""\n\n  def __init__(self):\n    super(PersistentOpEvaluator, self).__init__()\n    self._session = None\n    self._initialization_lock = threading.Lock()\n\n\n  def _lazily_initialize(self):\n    """"""Initialize the graph and session, if this has not yet been done.""""""\n    with self._initialization_lock:\n      if self._session:\n        return\n      graph = tf.Graph()\n      with graph.as_default():\n        self.initialize_graph()\n\n      config = tf.ConfigProto(device_count={\'GPU\': 0})\n      self._session = tf.Session(graph=graph, config=config)\n\n\n  def initialize_graph(self):\n    """"""Create the TensorFlow graph needed to compute this operation.\n    This should write ops to the default graph and return `None`.\n    """"""\n    raise NotImplementedError(\'Subclasses must implement ""initialize_graph"".\')\n\n\n  def run(self, *args, **kwargs):\n    """"""Evaluate the ops with the given input.\n    When this function is called, the default session will have the\n    graph defined by a previous call to `initialize_graph`. This\n    function should evaluate any ops necessary to compute the result of\n    the query for the given *args and **kwargs, likely returning the\n    result of a call to `some_op.eval(...)`.\n    """"""\n    raise NotImplementedError(\'Subclasses must implement ""run"".\')\n\n\n  def __call__(self, *args, **kwargs):\n    self._lazily_initialize()\n    with self._session.as_default():\n      return self.run(*args, **kwargs)\n\n\nclass PNGDecoder(PersistentOpEvaluator):\n\n  def __init__(self):\n    super(PNGDecoder, self).__init__()\n    self._image_placeholder = None\n    self._decode_op = None\n\n\n  def initialize_graph(self):\n    self._image_placeholder = tf.placeholder(dtype=tf.string)\n    self._decode_op = tf.image.decode_png(self._image_placeholder)\n\n\n  # pylint: disable=arguments-differ\n  def run(self, image):\n    return self._decode_op.eval(feed_dict={\n        self._image_placeholder: image,\n    })\n\n\nclass PNGEncoder(PersistentOpEvaluator):\n\n  def __init__(self):\n    super(PNGEncoder, self).__init__()\n    self._image_placeholder = None\n    self._encode_op = None\n\n\n  def initialize_graph(self):\n    self._image_placeholder = tf.placeholder(dtype=tf.uint8)\n    self._encode_op = tf.image.encode_png(self._image_placeholder)\n\n\n  # pylint: disable=arguments-differ\n  def run(self, image):\n    if len(image.shape) == 2:\n      image = image.reshape([image.shape[0], image.shape[1], 1])\n\n    return self._encode_op.eval(feed_dict={\n        self._image_placeholder: image,\n    })\n\n\nclass Resizer(PersistentOpEvaluator):\n\n  def __init__(self):\n    super(Resizer, self).__init__()\n    self._image_placeholder = None\n    self._size_placeholder = None\n    self._resize_op = None\n\n\n  def initialize_graph(self):\n    self._image_placeholder = tf.placeholder(dtype=tf.float32)\n    self._size_placeholder = tf.placeholder(dtype=tf.int32)\n    self._resize_op = tf.image.resize_nearest_neighbor(self._image_placeholder,\n                                                       self._size_placeholder)\n\n  # pylint: disable=arguments-differ\n  def run(self, image, height, width):\n    if len(image.shape) == 2:\n      image = image.reshape([image.shape[0], image.shape[1], 1])\n\n    resized = np.squeeze(self._resize_op.eval(feed_dict={\n        self._image_placeholder: [image],\n        self._size_placeholder: [height, width]\n    }))\n\n    return resized\n\n\ndecode_png = PNGDecoder()\nencode_png = PNGEncoder()\nresize = Resizer()\n\n\ndef read_image(filename):\n  with tf.gfile.Open(filename, \'rb\') as image_file:\n    return np.array(decode_png(image_file.read()))\n\n\ndef write_image(array, filename):\n  with tf.gfile.Open(filename, \'w\') as image_file:\n    image_file.write(encode_png(array))\n\n\ndef get_image_relative_to_script(filename):\n  script_directory = os.path.dirname(__file__)\n  filename = os.path.join(script_directory, \'resources\', filename)\n\n  return read_image(filename)\n'"
beholder/shared_config.py,0,"b""from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nPLUGIN_NAME = 'beholder'\nTAG_NAME = 'beholder-frame'\nSUMMARY_FILENAME = 'frame.summary'\nCONFIG_FILENAME = 'config.pkl'\nSECTION_INFO_FILENAME = 'section-info.pkl'\n\nDEFAULT_CONFIG = {\n    'values': 'trainable_variables',\n    'mode': 'variance',\n    'scaling': 'layer',\n    'window_size': 15,\n    'FPS': 10,\n    'is_recording': False,\n    'show_all': False,\n    'colormap': 'magma'\n}\n\nSECTION_HEIGHT = 128\nIMAGE_WIDTH = 512 + 256\n\nTB_WHITE = 245\n"""
beholder/video_writing.py,1,"b'\'\'\'\nfrom https://github.com/Zulko/moviepy/blob/\n  5a3cb6e78cd473a9b73f19b7cd0a31e371077da7/moviepy/video/io/ffmpeg_writer.py\n\nThe MIT License (MIT)\n[OSI Approved License]\n\nThe MIT License (MIT)\n\nCopyright (c) 2015 Zulko\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the ""Software""), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n\nOn the long term this will implement several methods to make videos\nout of VideoClips\n\'\'\'\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom abc import ABCMeta\nfrom abc import abstractmethod\nimport os\nimport subprocess as sp\nimport sys\nimport time\n\nimport numpy as np\nimport tensorflow as tf\n\nfrom beholder import im_util\n\nDEVNULL = open(os.devnull, \'wb\')\nPY3 = sys.version_info.major >= 3\n\n\nclass BaseVideoWriter(object):\n  __metaclass__ = ABCMeta\n\n  @abstractmethod\n  def write_frame(self, img_array):\n    raise NotImplementedError()\n\n  @abstractmethod\n  def close(self):\n    raise NotImplementedError()\n\n\nclass FFMPEG_VideoWriter(BaseVideoWriter):\n  """""" A class for FFMPEG-based video writing.\n\n  A class to write videos using ffmpeg. ffmpeg will write in a large\n  choice of formats.\n\n  Parameters\n  -----------\n\n  filename\n    Any filename like \'video.mp4\' etc. but if you want to avoid\n    complications it is recommended to use the generic extension\n    \'.avi\' for all your videos.\n\n  size\n    Size (width,height) of the output video in pixels.\n\n  fps\n    Frames per second in the output video file.\n\n  codec\n    FFMPEG codec. It seems that in terms of quality the hierarchy is\n    \'rawvideo\' = \'png\' > \'mpeg4\' > \'libx264\'\n    \'png\' manages the same lossless quality as \'rawvideo\' but yields\n    smaller files. Type ``ffmpeg -codecs`` in a terminal to get a list\n    of accepted codecs.\n\n    Note for default \'libx264\': by default the pixel format yuv420p\n    is used. If the video dimensions are not both even (e.g. 720x405)\n    another pixel format is used, and this can cause problem in some\n    video readers.\n\n  preset\n    Sets the time that FFMPEG will take to compress the video. The slower,\n    the better the compression rate. Possibilities are: ultrafast,superfast,\n    veryfast, faster, fast, medium (default), slow, slower, veryslow,\n    placebo.\n\n  bitrate\n    Only relevant for codecs which accept a bitrate. ""5000k"" offers\n    nice results in general.\n\n  withmask\n    Boolean. Set to ``True`` if there is a mask in the video to be\n    encoded.\n\n  """"""\n\n  def __init__(self, filename, size, fps, codec=""libx264"", preset=""medium"",\n               bitrate=None, logfile=None, threads=None, ffmpeg_params=None):\n\n    if logfile is None:\n      logfile = sp.PIPE\n\n    self.size = size\n    self.filename = filename\n    self.codec = codec\n    self.ext = self.filename.split(""."")[-1]\n\n    # order is important\n    cmd = [\n        \'ffmpeg\',\n        \'-y\',\n        \'-loglevel\', \'error\' if logfile == sp.PIPE else \'info\',\n        \'-f\', \'rawvideo\',\n        \'-vcodec\', \'rawvideo\',\n        \'-s\', \'%dx%d\' % (size[1], size[0]),\n        \'-pix_fmt\', \'gray\' if len(size) == 2 else \'rgb24\',\n        \'-r\', \'%.02f\' % fps,\n        \'-i\', \'-\', \'-an\',\n    ]\n\n    cmd.extend([\n        \'-vcodec\', codec,\n        \'-preset\', preset,\n    ])\n\n    if ffmpeg_params is not None:\n      cmd.extend(ffmpeg_params)\n    if bitrate is not None:\n      cmd.extend([\n          \'-b\', bitrate\n      ])\n\n    if threads is not None:\n      cmd.extend([""-threads"", str(threads)])\n\n    if ((codec == \'libx264\') and\n        (size[1] % 2 == 0) and\n        (size[0] % 2 == 0)):\n      cmd.extend([\n          \'-pix_fmt\', \'gray\' # \'yuv420p\'\n      ])\n    cmd.extend([\n        filename\n    ])\n\n    popen_params = {\n        ""stdout"": DEVNULL,\n        ""stderr"": logfile,\n        ""stdin"": sp.PIPE\n    }\n\n    # This was added so that no extra unwanted window opens on windows\n    # when the child process is created\n    if os.name == ""nt"":\n      popen_params[""creationflags""] = 0x08000000\n\n    self.proc = sp.Popen(cmd, **popen_params)\n\n\n  def write_frame(self, img_array):\n    """""" Writes one frame in the file.""""""\n    try:\n      if PY3:\n        self.proc.stdin.write(img_array.tobytes())\n      else:\n        self.proc.stdin.write(img_array.tostring())\n    except IOError as err:\n      _, ffmpeg_error = self.proc.communicate()\n      error = (str(err) + (""\\n\\nMoviePy error: FFMPEG encountered ""\n                           ""the following error while writing file %s:""\n                           ""\\n\\n %s"" % (self.filename, str(ffmpeg_error))))\n\n      if b""Unknown encoder"" in ffmpeg_error:\n        message = (""\\n\\nThe video export ""\n                   ""failed because FFMPEG didn\'t find the specified ""\n                   ""codec for video encoding (%s). Please install ""\n                   ""this codec or change the codec when calling ""\n                   ""write_videofile. For instance:\\n""\n                   ""  >>> clip.write_videofile(\'myvid.webm\', codec=\'libvpx\')"")\n\n        error = error + message % (self.codec)\n\n      elif b""incorrect codec parameters ?"" in ffmpeg_error:\n        message = (""\\n\\nThe video export ""\n                   ""failed, possibly because the codec specified for ""\n                   ""the video (%s) is not compatible with the given ""\n                   ""extension (%s). Please specify a valid \'codec\' ""\n                   ""argument in write_videofile. This would be \'libx264\' ""\n                   ""or \'mpeg4\' for mp4, \'libtheora\' for ogv, \'libvpx for webm. ""\n                   ""Another possible reason is that the audio codec was not ""\n                   ""compatible with the video codec. For instance the video ""\n                   ""extensions \'ogv\' and \'webm\' only allow \'libvorbis\'""\n                   "" (default) as avideo codec."")\n\n        error = error + message % (self.codec, self.ext)\n\n      elif  b""encoder setup failed"" in ffmpeg_error:\n\n        error = error+(""\\n\\nThe video export ""\n                       ""failed, possibly because the bitrate you specified ""\n                       ""was too high or too low for the video codec."")\n\n      elif b""Invalid encoder type"" in ffmpeg_error:\n\n        error = error + (""\\n\\nThe video export failed because the codec ""\n                         ""or file extension you provided is not a video"")\n\n\n      raise IOError(error)\n\n  def close(self):\n    self.proc.stdin.close()\n    if self.proc.stderr is not None:\n      self.proc.stderr.close()\n    self.proc.wait()\n\n    del self.proc\n\n\nclass PNGWriter(BaseVideoWriter):\n  def __init__(self, logdir, size):\n    self.frame_directory = logdir + \'/video-frames-{}\'.format(time.time())\n    tf.gfile.MakeDirs(self.frame_directory)\n\n    self.size = size\n    self.frame_number = 0\n\n  def write_frame(self, img_array):\n    filename = \'{}/{}.png\'.format(self.frame_directory,\n                                  str(self.frame_number).zfill(5))\n    im_util.write_image(img_array.astype(np.uint8), filename)\n    self.frame_number += 1\n\n  def close(self):\n    pass\n'"
beholder/visualizer.py,1,"b""from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom collections import deque\nfrom math import floor, sqrt\n\nimport numpy as np\nimport tensorflow as tf\n\nfrom beholder import im_util\nfrom beholder.shared_config import SECTION_HEIGHT, IMAGE_WIDTH, DEFAULT_CONFIG,\\\n  SECTION_INFO_FILENAME\nfrom beholder.file_system_tools import write_pickle\n\nMIN_SQUARE_SIZE = 3\n\nclass Visualizer(object):\n\n  def __init__(self, logdir):\n    self.logdir = logdir\n    self.sections_over_time = deque([], DEFAULT_CONFIG['window_size'])\n    self.config = dict(DEFAULT_CONFIG)\n    self.old_config = dict(DEFAULT_CONFIG)\n\n\n  def _reshape_conv_array(self, array, section_height, image_width):\n    '''Reshape a rank 4 array to be rank 2, where each column of block_width is\n    a filter, and each row of block height is an input channel. For example:\n\n    [[[[ 11,  21,  31,  41],\n       [ 51,  61,  71,  81],\n       [ 91, 101, 111, 121]],\n      [[ 12,  22,  32,  42],\n       [ 52,  62,  72,  82],\n       [ 92, 102, 112, 122]],\n      [[ 13,  23,  33,  43],\n       [ 53,  63,  73,  83],\n       [ 93, 103, 113, 123]]],\n     [[[ 14,  24,  34,  44],\n       [ 54,  64,  74,  84],\n       [ 94, 104, 114, 124]],\n      [[ 15,  25,  35,  45],\n       [ 55,  65,  75,  85],\n       [ 95, 105, 115, 125]],\n      [[ 16,  26,  36,  46],\n       [ 56,  66,  76,  86],\n       [ 96, 106, 116, 126]]],\n     [[[ 17,  27,  37,  47],\n       [ 57,  67,  77,  87],\n       [ 97, 107, 117, 127]],\n      [[ 18,  28,  38,  48],\n       [ 58,  68,  78,  88],\n       [ 98, 108, 118, 128]],\n      [[ 19,  29,  39,  49],\n       [ 59,  69,  79,  89],\n       [ 99, 109, 119, 129]]]]\n\n       should be reshaped to:\n\n       [[ 11,  12,  13,  21,  22,  23,  31,  32,  33,  41,  42,  43],\n        [ 14,  15,  16,  24,  25,  26,  34,  35,  36,  44,  45,  46],\n        [ 17,  18,  19,  27,  28,  29,  37,  38,  39,  47,  48,  49],\n        [ 51,  52,  53,  61,  62,  63,  71,  72,  73,  81,  82,  83],\n        [ 54,  55,  56,  64,  65,  66,  74,  75,  76,  84,  85,  86],\n        [ 57,  58,  59,  67,  68,  69,  77,  78,  79,  87,  88,  89],\n        [ 91,  92,  93, 101, 102, 103, 111, 112, 113, 121, 122, 123],\n        [ 94,  95,  96, 104, 105, 106, 114, 115, 116, 124, 125, 126],\n        [ 97,  98,  99, 107, 108, 109, 117, 118, 119, 127, 128, 129]]\n    '''\n\n    # E.g. [100, 24, 24, 10]: this shouldn't be reshaped like normal.\n    if array.shape[1] == array.shape[2] and array.shape[0] != array.shape[1]:\n      array = np.rollaxis(np.rollaxis(array, 2), 2)\n\n    block_height, block_width, in_channels = array.shape[:3]\n    rows = []\n\n    max_element_count = section_height * int(image_width / MIN_SQUARE_SIZE)\n    element_count = 0\n\n    for i in range(in_channels):\n      rows.append(array[:, :, i, :].reshape(block_height, -1, order='F'))\n\n      # This line should be left in this position. Gives it one extra row.\n      if element_count >= max_element_count and not self.config['show_all']:\n        break\n\n      element_count += block_height * in_channels * block_width\n\n    return np.vstack(rows)\n\n\n  def _reshape_irregular_array(self, array, section_height, image_width):\n    '''Reshapes arrays of ranks not in {1, 2, 4}\n    '''\n    section_area = section_height * image_width\n    flattened_array = np.ravel(array)\n\n    if not self.config['show_all']:\n      flattened_array = flattened_array[:int(section_area/MIN_SQUARE_SIZE)]\n\n    cell_count = np.prod(flattened_array.shape)\n    cell_area = section_area / cell_count\n\n    cell_side_length = max(1, floor(sqrt(cell_area)))\n    row_count = max(1, int(section_height / cell_side_length))\n    col_count = int(cell_count / row_count)\n\n    # Reshape the truncated array so that it has the same aspect ratio as\n    # the section.\n\n    # Truncate whatever remaining values there are that don't fit. Hopefully\n    # it doesn't matter that the last few (< section count) aren't there.\n    section = np.reshape(flattened_array[:row_count * col_count],\n                         (row_count, col_count))\n\n    return section\n\n\n  def _determine_image_width(self, arrays, show_all):\n    final_width = IMAGE_WIDTH\n\n    if show_all:\n      for array in arrays:\n        rank = len(array.shape)\n\n        if rank == 1:\n          width = len(array)\n        elif rank == 2:\n          width = array.shape[1]\n        elif rank == 4:\n          width = array.shape[1] * array.shape[3]\n        else:\n          width = IMAGE_WIDTH\n\n        if width > final_width:\n          final_width = width\n\n    return final_width\n\n\n  def _determine_section_height(self, array, show_all):\n    rank = len(array.shape)\n    height = SECTION_HEIGHT\n\n    if show_all:\n      if rank == 1:\n        height = SECTION_HEIGHT\n      if rank == 2:\n        height = max(SECTION_HEIGHT, array.shape[0])\n      elif rank == 4:\n        height = max(SECTION_HEIGHT, array.shape[0] * array.shape[2])\n      else:\n        height = max(SECTION_HEIGHT, np.prod(array.shape) // IMAGE_WIDTH)\n\n    return height\n\n\n  def _arrays_to_sections(self, arrays):\n    '''\n    input: unprocessed numpy arrays.\n    returns: columns of the size that they will appear in the image, not scaled\n             for display. That needs to wait until after variance is computed.\n    '''\n    sections = []\n    sections_to_resize_later = {}\n    show_all = self.config['show_all']\n    image_width = self._determine_image_width(arrays, show_all)\n\n    for array_number, array in enumerate(arrays):\n      rank = len(array.shape)\n      section_height = self._determine_section_height(array, show_all)\n\n      if rank == 1:\n        section = np.atleast_2d(array)\n      elif rank == 2:\n        section = array\n      elif rank == 4:\n        section = self._reshape_conv_array(array, section_height, image_width)\n      else:\n        section = self._reshape_irregular_array(array,\n                                                section_height,\n                                                image_width)\n      # Only calculate variance for what we have to. In some cases (biases),\n      # the section is larger than the array, so we don't want to calculate\n      # variance for the same value over and over - better to resize later.\n      # About a 6-7x speedup for a big network with a big variance window.\n      section_size = section_height * image_width\n      array_size = np.prod(array.shape)\n\n      if section_size > array_size:\n        sections.append(section)\n        sections_to_resize_later[array_number] = section_height\n      else:\n        sections.append(im_util.resize(section, section_height, image_width))\n\n    self.sections_over_time.append(sections)\n\n    if self.config['mode'] == 'variance':\n      sections = self._sections_to_variance_sections(self.sections_over_time)\n\n    for array_number, height in sections_to_resize_later.items():\n      sections[array_number] = im_util.resize(sections[array_number],\n                                              height,\n                                              image_width)\n    return sections\n\n\n  def _sections_to_variance_sections(self, sections_over_time):\n    '''Computes the variance of corresponding sections over time.\n\n    Returns:\n      a list of np arrays.\n    '''\n    variance_sections = []\n\n    for i in range(len(sections_over_time[0])):\n      time_sections = [sections[i] for sections in sections_over_time]\n      variance = np.var(time_sections, axis=0)\n      variance_sections.append(variance)\n\n    return variance_sections\n\n\n  def _sections_to_image(self, sections):\n    padding_size = 5\n\n    sections = im_util.scale_sections(sections, self.config['scaling'])\n\n    final_stack = [sections[0]]\n    padding = np.zeros((padding_size, sections[0].shape[1]))\n\n    for section in sections[1:]:\n      final_stack.append(padding)\n      final_stack.append(section)\n\n    return np.vstack(final_stack).astype(np.uint8)\n\n\n  def _maybe_clear_deque(self):\n    '''Clears the deque if certain parts of the config have changed.'''\n\n    for config_item in ['values', 'mode', 'show_all']:\n      if self.config[config_item] != self.old_config[config_item]:\n        self.sections_over_time.clear()\n        break\n\n    self.old_config = self.config\n\n    window_size = self.config['window_size']\n    if window_size != self.sections_over_time.maxlen:\n      self.sections_over_time = deque(self.sections_over_time, window_size)\n\n\n  def _save_section_info(self, arrays, sections):\n    infos = []\n\n    if self.config['values'] == 'trainable_variables':\n      names = [x.name for x in tf.trainable_variables()]\n    else:\n      names = range(len(arrays))\n\n    for array, section, name in zip(arrays, sections, names):\n      info = {}\n\n      info['name'] = name\n      info['shape'] = str(array.shape)\n      info['min'] = '{:.3e}'.format(section.min())\n      info['mean'] = '{:.3e}'.format(section.mean())\n      info['max'] = '{:.3e}'.format(section.max())\n      info['range'] = '{:.3e}'.format(section.max() - section.min())\n      info['height'] = section.shape[0]\n\n      infos.append(info)\n\n    write_pickle(infos, '{}/{}'.format(self.logdir, SECTION_INFO_FILENAME))\n\n\n  def build_frame(self, arrays):\n    self._maybe_clear_deque()\n\n    arrays = arrays if isinstance(arrays, list) else [arrays]\n\n    sections = self._arrays_to_sections(arrays)\n    self._save_section_info(arrays, sections)\n    final_image = self._sections_to_image(sections)\n    final_image = im_util.apply_colormap(final_image, self.config['colormap'])\n\n    return final_image\n\n  def update(self, config):\n    self.config = config\n"""
beholder/server_side/beholder_plugin.py,3,"b""from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport io\nimport time\n\nfrom google.protobuf import message\nimport numpy as np\nimport tensorboard\nfrom tensorboard.backend import http_util\nfrom tensorboard.backend.event_processing import plugin_asset_util as pau\nfrom tensorboard.plugins import base_plugin\nimport tensorflow as tf\nfrom werkzeug import wrappers\n\nfrom beholder.im_util import get_image_relative_to_script, encode_png\nfrom beholder.shared_config import PLUGIN_NAME, SECTION_HEIGHT, IMAGE_WIDTH\nfrom beholder.shared_config import SECTION_INFO_FILENAME, CONFIG_FILENAME,\\\n  TAG_NAME, SUMMARY_FILENAME, DEFAULT_CONFIG\nfrom beholder.file_system_tools import read_tensor_summary, read_pickle,\\\n  write_pickle\n\nimport sys\nprint(sys.version)\n\nclass BeholderPlugin(base_plugin.TBPlugin):\n\n  plugin_name = PLUGIN_NAME\n\n  def __init__(self, context):\n    self._MULTIPLEXER = context.multiplexer\n    self.PLUGIN_LOGDIR = pau.PluginDirectory(context.logdir, PLUGIN_NAME)\n    self.FPS = 10\n    self.most_recent_frame = get_image_relative_to_script('no-data.png')\n    self.most_recent_info = [{\n        'name': 'Waiting for data...',\n    }]\n\n    if not tf.gfile.Exists(self.PLUGIN_LOGDIR):\n      tf.gfile.MakeDirs(self.PLUGIN_LOGDIR)\n      write_pickle(DEFAULT_CONFIG, '{}/{}'.format(self.PLUGIN_LOGDIR,\n                                                  CONFIG_FILENAME))\n\n  def get_plugin_apps(self):\n    return {\n        '/change-config': self._serve_change_config,\n        '/beholder-frame': self._serve_beholder_frame,\n        '/section-info': self._serve_section_info,\n        '/ping': self._serve_ping,\n        '/tags': self._serve_tags\n    }\n\n\n  def is_active(self):\n    return True\n\n\n  def _fetch_current_frame(self):\n    path = '{}/{}'.format(self.PLUGIN_LOGDIR, SUMMARY_FILENAME)\n\n    try:\n      frame = read_tensor_summary(path).astype(np.uint8)\n      self.most_recent_frame = frame\n      return frame\n\n    except (message.DecodeError, IOError, tf.errors.NotFoundError):\n      return self.most_recent_frame\n\n\n  @wrappers.Request.application\n  def _serve_tags(self, request):\n    if self.is_active:\n      runs_and_tags = {\n          'plugins/{}'.format(PLUGIN_NAME): {'tensors': [TAG_NAME]}\n      }\n    else:\n      runs_and_tags = {}\n\n    return http_util.Respond(request,\n                             runs_and_tags,\n                             'application/json')\n\n\n  @wrappers.Request.application\n  def _serve_change_config(self, request):\n    config = {}\n\n    for key, value in request.form.items():\n      try:\n        config[key] = int(value)\n      except ValueError:\n        if value == 'false':\n          config[key] = False\n        elif value == 'true':\n          config[key] = True\n        else:\n          config[key] = value\n\n    self.FPS = config['FPS']\n\n    write_pickle(config, '{}/{}'.format(self.PLUGIN_LOGDIR, CONFIG_FILENAME))\n    return http_util.Respond(request, {'config': config}, 'application/json')\n\n\n  @wrappers.Request.application\n  def _serve_section_info(self, request):\n    path = '{}/{}'.format(self.PLUGIN_LOGDIR, SECTION_INFO_FILENAME)\n    info = read_pickle(path, default=self.most_recent_info)\n    self.most_recent_info = info\n    return http_util.Respond(request, info, 'application/json')\n\n\n  def _frame_generator(self):\n\n    while True:\n      last_duration = 0\n\n      if self.FPS == 0:\n        continue\n      else:\n        time.sleep(max(0, 1/(self.FPS) - last_duration))\n\n      start_time = time.time()\n      array = self._fetch_current_frame()\n      image_bytes = encode_png(array)\n\n      frame_text = b'--frame\\r\\n'\n      content_type = b'Content-Type: image/png\\r\\n\\r\\n'\n\n      response_content = frame_text + content_type + image_bytes + b'\\r\\n\\r\\n'\n\n      last_duration = time.time() - start_time\n      yield response_content\n\n\n  @wrappers.Request.application\n  def _serve_beholder_frame(self, request): # pylint: disable=unused-argument\n    # Thanks to Miguel Grinberg for this technique:\n    # https://blog.miguelgrinberg.com/post/video-streaming-with-flask\n    mimetype = 'multipart/x-mixed-replace; boundary=frame'\n    return wrappers.Response(response=self._frame_generator(),\n                             status=200,\n                             mimetype=mimetype)\n\n  @wrappers.Request.application\n  def _serve_ping(self, request): # pylint: disable=unused-argument\n    return http_util.Respond(request, {'status': 'alive'}, 'application/json')\n"""
beholder/tensorboard_x/main.py,2,"b'# Copyright 2017 Google Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport logging\nimport os\n\nfrom tensorboard import util\nfrom tensorboard import main as tb_main\nfrom tensorboard.plugins.audio import audio_plugin\nfrom tensorboard.plugins.core import core_plugin\nfrom tensorboard.plugins.distribution import distributions_plugin\nfrom tensorboard.plugins.graph import graphs_plugin\nfrom tensorboard.plugins.histogram import histograms_plugin\nfrom tensorboard.plugins.image import images_plugin\nfrom tensorboard.plugins.profile import profile_plugin\nfrom tensorboard.plugins.projector import projector_plugin\nfrom tensorboard.plugins.scalar import scalars_plugin\nfrom tensorboard.plugins.text import text_plugin\nimport tensorflow as tf\n\nfrom beholder.server_side import beholder_plugin\n\n\ndef get_assets_zip_provider():\n  path = os.path.join(tf.resource_loader.get_data_files_path(), \'assets.zip\')\n  return lambda: open(path, \'rb\')\n\n\ndef get_plugins():\n  return [\n      beholder_plugin.BeholderPlugin,\n      core_plugin.CorePlugin,\n      scalars_plugin.ScalarsPlugin,\n      images_plugin.ImagesPlugin,\n      audio_plugin.AudioPlugin,\n      graphs_plugin.GraphsPlugin,\n      distributions_plugin.DistributionsPlugin,\n      histograms_plugin.HistogramsPlugin,\n      projector_plugin.ProjectorPlugin,\n      text_plugin.TextPlugin,\n      profile_plugin.ProfilePlugin,\n  ]\n\n\ndef main(unused_argv=None):\n  util.setup_logging()\n  tb_app = tb_main.create_tb_app(\n      assets_zip_provider=get_assets_zip_provider(),\n      plugins=get_plugins())\n\n  server, url = tb_main.make_simple_server(tb_app)\n\n  logger = logging.getLogger(\'tensorflow\' + util.LogHandler.EPHEMERAL)\n  logger.setLevel(logging.INFO)\n  logger.info(\'TensorBoard-X (Beholder) 0.1 at %s (CTRL+C to quit)\', url)\n\n  try:\n    server.serve_forever()\n  finally:\n    logger.info(\'\')\n\n\nif __name__ == \'__main__\':\n  tf.app.run()\n'"
beholder/tests/beholder_test.py,20,"b""from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport time\n\nimport numpy as np\nimport tensorflow as tf\n\nfrom beholder.beholder import Beholder\nfrom beholder.shared_config import DEFAULT_CONFIG, IMAGE_WIDTH, SECTION_HEIGHT\nfrom beholder.file_system_tools import write_pickle\n\n\n\nclass BeholderTest(tf.test.TestCase):\n  def _write_config(self):\n    write_pickle(self.config, '/tmp/beholder-test/plugins/beholder/config.pkl')\n\n  def _dummy_frame(self):\n    frame = np.random.randint(0, 255, (SECTION_HEIGHT * 2,\n                                       IMAGE_WIDTH)).astype(np.uint8)\n    return frame\n\n  def setUp(self):\n    conv_weights_small = tf.Variable(tf.truncated_normal([3, 3, 1, 5],\n                                                         dtype=tf.float32,\n                                                         stddev=1e-1))\n    fc_weights_small = tf.Variable(tf.truncated_normal([10, 500],\n                                                       dtype=tf.float32,\n                                                       stddev=1e-1))\n    bias_small = tf.Variable(tf.truncated_normal([2],\n                                                 dtype=tf.float32,\n                                                 stddev=1e-1))\n    weird_shape_small = tf.Variable(tf.truncated_normal([1, 2, 3],\n                                                        dtype=tf.float32,\n                                                        stddev=1e-1))\n\n    conv_weights_big = tf.Variable(tf.truncated_normal([3, 3, SECTION_HEIGHT, IMAGE_WIDTH],\n                                                       dtype=tf.float32,\n                                                       stddev=1e-1))\n    fc_weights_big = tf.Variable(tf.truncated_normal([SECTION_HEIGHT, IMAGE_WIDTH + 10],\n                                                     dtype=tf.float32,\n                                                     stddev=1e-1))\n    bias_big = tf.Variable(tf.truncated_normal([SECTION_HEIGHT * IMAGE_WIDTH + 100],\n                                               dtype=tf.float32,\n                                               stddev=1e-1))\n    weird_shape_big = tf.Variable(tf.truncated_normal([SECTION_HEIGHT, IMAGE_WIDTH, 3],\n                                                      dtype=tf.float32,\n                                                      stddev=1e-1))\n    self.sess = tf.Session()\n    self.sess.run(tf.global_variables_initializer())\n\n    self.beholder = Beholder(self.sess, '/tmp/beholder-test')\n    self.config = dict(DEFAULT_CONFIG)\n    self.config['FPS'] = 100000000000\n    self._write_config()\n\n\n  def test_update_trainable_variables(self):\n    self.config['values'] = 'trainable_variables'\n    self._write_config()\n    self.beholder.update()\n\n\n  def test_update_arrays(self):\n    self.config['values'] = 'arrays'\n    self._write_config()\n    self.beholder.update(arrays=None)\n    self.beholder.update(arrays=[np.random.randint(0, 100, (IMAGE_WIDTH,\n                                                            SECTION_HEIGHT*2))])\n\n\n  def test_update_frame(self):\n    self.config['values'] = 'frames'\n    self._write_config()\n    self.beholder.update(frame=None)\n    self.beholder.update(frame=self._dummy_frame())\n\n\n  def test_update_recording(self):\n    self.config['is_recording'] = False\n    self.beholder._update_recording(self._dummy_frame(), self.config)\n    self.beholder._update_recording(self._dummy_frame(), self.config)\n    self.config['is_recording'] = True\n    self.beholder._update_recording(self._dummy_frame(), self.config)\n    self.beholder._update_recording(self._dummy_frame(), self.config)\n    self.config['is_recording'] = False\n    self.beholder._update_recording(self._dummy_frame(), self.config)\n\n\n  def test_enough_time_has_passed(self):\n    self.assertFalse(self.beholder._enough_time_has_passed(0))\n\n    self.beholder.update()\n    time.sleep(1)\n    self.assertTrue(self.beholder._enough_time_has_passed(30))\n\n    self.beholder.update()\n    self.assertFalse(self.beholder._enough_time_has_passed(1))\n\n\n\nif __name__ == '__main__':\n  tf.test.main()\n"""
beholder/tests/plugin_test.py,3,"b""from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\n\nfrom tensorboard.backend import application\n\nimport tensorflow as tf\nfrom werkzeug import test as werkzeug_test\nfrom werkzeug import wrappers\n\nfrom beholder.tensorboard_x.main import get_plugins\nfrom beholder.file_system_tools import write_pickle\n\nURL_PREFIX = 'data/plugin/beholder'\n\nclass PluginTest(tf.test.TestCase):\n\n  def _write_dummy_files(self):\n    plugin_dir = '/tmp/beholder-test/plugins/beholder'\n    tf.gfile.MakeDirs(plugin_dir)\n\n    info_path = plugin_dir + '/section-info.pkl'\n    config_path = plugin_dir + '/config.pkl'\n\n    write_pickle([{\n        'shape': '(3, 3, 3, 64)',\n        'mean': '1.131e-07',\n        'min': '2.022e-11',\n        'range': '3.949e-07',\n        'name': 'conv1_1/weights:0',\n        'max': '3.949e-07'\n    }], info_path)\n\n    write_pickle({\n        'values': 'trainable_variables',\n        'mode': 'variance',\n        'scaling': 'layer',\n        'window_size': 10,\n        'FPS': 10,\n        'is_recording': False,\n        'show_all': False,\n        'colormap': 'grayscale'\n    }, config_path)\n\n  def setUp(self):\n    self._write_dummy_files()\n\n    app = application.standard_tensorboard_wsgi(\n        '/tmp/beholder-demo',\n        True,\n        5,\n        get_plugins()\n    )\n    self.server = werkzeug_test.Client(app, wrappers.BaseResponse)\n\n\n\n  def _make_url(self, path):\n    return URL_PREFIX + '/' + path\n\n\n  def _post(self, path, data):\n    response = self.server.post(self._make_url(path), data=data)\n    self.assertEqual(200, response.status_code)\n    return json.loads(response.get_data().decode('utf-8'))\n\n\n  def _get_json(self, path):\n    path = self._make_url(path)\n    response = self.server.get(path)\n    self.assertEqual(200, response.status_code)\n    self.assertEqual('application/json', response.headers.get('Content-Type'))\n    return json.loads(response.get_data().decode('utf-8'))\n\n\n  def test_section_info(self):\n    response = self._get_json('section-info')\n    info = response[0]\n    self.assertIn('name', info)\n\n\n  def test_change_config(self):\n    response = self._post('change-config', data={\n        'values': 'trainable_variables',\n        'mode': 'variance',\n        'scaling': 'layer',\n        'window_size': 15,\n        'FPS': 10,\n        'is_recording': False,\n        'show_all': False,\n        'colormap': 'grayscale'\n    })\n    self.assertIn('window_size', response['config'])\n\n\n  def test_beholder_frame(self):\n    response = self.server.get(self._make_url('beholder-frame'))\n    self.assertEqual(200, response.status_code)\n\n\n\nif __name__ == '__main__':\n  tf.test.main()\n"""
beholder/tests/visualizer_test.py,3,"b""from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nimport tensorflow as tf\n\nfrom beholder import visualizer\nfrom beholder.shared_config import SECTION_HEIGHT,\\\n  IMAGE_WIDTH\n\nclass VisualizerTest(tf.test.TestCase):\n\n  def setUp(self):\n    session = tf.Session()\n    visualizer.MIN_SQUARE_SIZE = 1\n    path = '/tmp/beholder-test/plugins/beholder/'\n    self.visualizer = visualizer.Visualizer(path)\n    self.visualizer.config['mode'] = 'current'\n\n\n  def test_reshape_conv_array(self):\n    max_size = 5\n\n    for height in range(1, max_size): # pylint:disable=too-many-nested-blocks\n      # for width in range(1, max_size):\n      width = height\n      for in_channel in range(1, max_size):\n        for out_channel in range(1, max_size):\n          shape = [height, width, in_channel, out_channel]\n          array = np.reshape(range(np.prod(shape)), shape)\n          reshaped = self.visualizer._reshape_conv_array(array,\n                                                         SECTION_HEIGHT,\n                                                         IMAGE_WIDTH)\n\n          for in_number in range(in_channel):\n            for out_number in range(out_channel):\n              start_row = in_number * height\n              start_col = out_number * width\n              to_test = reshaped[start_row: start_row + height,\n                                 start_col: start_col + width]\n              true = array[:, :, in_number, out_number]\n              self.assertAllEqual(true, to_test)\n\n\n  def test_arrays_to_sections(self):\n    array_1 = np.array(range(0, 100)).reshape(10, 10).astype(float)\n    section = self.visualizer._arrays_to_sections([array_1])[0]\n    self.assertEqual(section[0, 0], 0)\n    self.assertEqual(section[-1, -1], 99)\n\n\n  def test_sections_to_variance_sections(self):\n    sections_over_time = [\n        [[[1.0, 2.0, 3.0]]],\n        [[[0.0, 2.0, 4.0]]]\n    ]\n\n    sec = self.visualizer._sections_to_variance_sections(sections_over_time)[0]\n    self.assertEqual(.25, sec[0, 0])\n    self.assertEqual(0, sec[0, 1])\n    self.assertEqual(.25, sec[0, 2])\n\n\n  def test_sections_to_image(self):\n    image = self.visualizer._sections_to_image([\n        np.random.random((10, 10))\n    ])\n\n    # To allow for floating point issues.\n    # x = np.array([254.9999999995])\n    # x.max() == 255.0\n    # x.astype(np.uint8).max() == 254\n    self.assertLessEqual(image.min(), 1)\n    self.assertGreaterEqual(image.max(), 254)\n\n\nif __name__ == '__main__':\n  tf.test.main()\n"""
beholder/demos/demo/__init__.py,0,b''
beholder/demos/demo/demo.py,67,"b'# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \'License\');\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \'AS IS\' BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""A simple MNIST classifier which displays summaries in TensorBoard.\n\nThis is an unimpressive MNIST model, but it is a good example of using\ntf.name_scope to make a graph legible in the TensorBoard graph explorer, and of\nnaming summary tags so that they are grouped meaningfully in TensorBoard.\n\nIt demonstrates the functionality of every TensorBoard dashboard.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport argparse\nimport sys\n\nimport numpy as np\nimport tensorflow as tf\n\nfrom tensorflow.examples.tutorials.mnist import input_data\n\nfrom beholder.beholder import Beholder\n\nFLAGS = None\n\nLOG_DIRECTORY = \'/tmp/beholder-demo\'\n\ndef train():\n  mnist = input_data.read_data_sets(FLAGS.data_dir,\n                                    one_hot=True,\n                                    fake_data=FLAGS.fake_data)\n\n  sess = tf.InteractiveSession()\n\n  with tf.name_scope(\'input\'):\n    x = tf.placeholder(tf.float32, [None, 784], name=\'x-input\')\n    y_ = tf.placeholder(tf.float32, [None, 10], name=\'y-input\')\n\n  with tf.name_scope(\'input_reshape\'):\n    image_shaped_input = tf.reshape(x, [-1, 28, 28, 1])\n    tf.summary.image(\'input\', image_shaped_input, 10)\n\n  def weight_variable(shape):\n    """"""Create a weight variable with appropriate initialization.""""""\n    initial = tf.truncated_normal(shape, stddev=0.01)\n    return tf.Variable(initial)\n\n  def bias_variable(shape):\n    """"""Create a bias variable with appropriate initialization.""""""\n    initial = tf.constant(0.1, shape=shape)\n    return tf.Variable(initial)\n\n  def variable_summaries(var):\n    """"""Attach a lot of summaries to a Tensor (for TensorBoard visualization).""""""\n    with tf.name_scope(\'summaries\'):\n      mean = tf.reduce_mean(var)\n      tf.summary.scalar(\'mean\', mean)\n      with tf.name_scope(\'stddev\'):\n        stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n      tf.summary.scalar(\'stddev\', stddev)\n      tf.summary.scalar(\'max\', tf.reduce_max(var))\n      tf.summary.scalar(\'min\', tf.reduce_min(var))\n      tf.summary.histogram(\'histogram\', var)\n\n  def nn_layer(input_tensor, input_dim, output_dim, layer_name, act=tf.nn.relu):\n    """"""Reusable code for making a simple neural net layer.\n\n    It does a matrix multiply, bias add, and then uses ReLU to nonlinearize.\n    It also sets up name scoping so that the resultant graph is easy to read,\n    and adds a number of summary ops.\n    """"""\n    # Adding a name scope ensures logical grouping of the layers in the graph.\n    with tf.name_scope(layer_name):\n      # This Variable will hold the state of the weights for the layer\n      with tf.name_scope(\'weights\'):\n        weights = weight_variable([input_dim, output_dim])\n        variable_summaries(weights)\n      with tf.name_scope(\'biases\'):\n        biases = bias_variable([output_dim])\n        variable_summaries(biases)\n      with tf.name_scope(\'Wx_plus_b\'):\n        preactivate = tf.matmul(input_tensor, weights) + biases\n        tf.summary.histogram(\'pre_activations\', preactivate)\n      activations = act(preactivate, name=\'activation\')\n      tf.summary.histogram(\'activations\', activations)\n      return activations\n\n  #conv1\n  kernel = tf.Variable(tf.truncated_normal([5, 5, 1, 10], dtype=tf.float32,\n                                                     stddev=1e-1), name=\'conv-weights\')\n  conv = tf.nn.conv2d(image_shaped_input, kernel, [1, 1, 1, 1], padding=\'VALID\')\n  biases = tf.Variable(tf.constant(0.0, shape=[kernel.get_shape().as_list()[-1]], dtype=tf.float32),\n                       trainable=True, name=\'biases\')\n  out = tf.nn.bias_add(conv, biases)\n  conv1 = tf.nn.relu(out, name=\'relu\')\n\n  #conv2\n  kernel2 = tf.Variable(tf.truncated_normal([3, 3, 10, 20], dtype=tf.float32,\n                                                     stddev=1e-1), name=\'conv-weights2\')\n  conv2 = tf.nn.conv2d(conv1, kernel2, [1, 1, 1, 1], padding=\'VALID\')\n  biases2 = tf.Variable(tf.constant(0.0, shape=[kernel2.get_shape().as_list()[-1]], dtype=tf.float32),\n                       trainable=True, name=\'biases\')\n  out2 = tf.nn.bias_add(conv2, biases2)\n  conv2 = tf.nn.relu(out2, name=\'relu\')\n\n  flattened = tf.contrib.layers.flatten(conv2)\n\n\n  # hidden1 = nn_layer(x, x.get_shape().as_list()[1], 10, \'layer1\')\n  hidden1 = nn_layer(flattened, flattened.get_shape().as_list()[1], 10, \'layer1\')\n\n  with tf.name_scope(\'dropout\'):\n    keep_prob = tf.placeholder(tf.float32)\n    tf.summary.scalar(\'dropout_keep_probability\', keep_prob)\n    dropped = tf.nn.dropout(hidden1, keep_prob)\n\n  y = nn_layer(dropped, 10, 10, \'layer2\', act=tf.identity)\n\n  with tf.name_scope(\'cross_entropy\'):\n    diff = tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y)\n    with tf.name_scope(\'total\'):\n      cross_entropy = tf.reduce_mean(diff)\n  tf.summary.scalar(\'cross_entropy\', cross_entropy)\n\n  with tf.name_scope(\'train\'):\n    optimizer = tf.train.AdamOptimizer(FLAGS.learning_rate)\n    gradients, train_step = Beholder.gradient_helper(optimizer, cross_entropy)\n\n  with tf.name_scope(\'accuracy\'):\n    with tf.name_scope(\'correct_prediction\'):\n      correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n    with tf.name_scope(\'accuracy\'):\n      accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n  tf.summary.scalar(\'accuracy\', accuracy)\n\n  merged = tf.summary.merge_all()\n  train_writer = tf.summary.FileWriter(LOG_DIRECTORY + \'/train\', sess.graph)\n  test_writer = tf.summary.FileWriter(LOG_DIRECTORY + \'/test\')\n  tf.global_variables_initializer().run()\n\n  visualizer = Beholder(session=sess,\n                        logdir=LOG_DIRECTORY)\n\n\n  def feed_dict(train):\n    if train or FLAGS.fake_data:\n      xs, ys = mnist.train.next_batch(100, fake_data=FLAGS.fake_data)\n      k = FLAGS.dropout\n    else:\n      xs, ys = mnist.test.images, mnist.test.labels\n      k = 1.0\n    return {x: xs, y_: ys, keep_prob: k}\n\n  for i in range(FLAGS.max_steps):\n    # if i % 10 == 0:  # Record summaries and test-set accuracy\n        summary, acc = sess.run([merged, accuracy], feed_dict=feed_dict(False))\n        test_writer.add_summary(summary, i)\n        print(\'Accuracy at step %s: %s\' % (i, acc))\n    # else:  # Record train set summaries, and train\n    #   if i % 100 == 99:  # Record execution stats\n    #     run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n    #     run_metadata = tf.RunMetadata()\n    #     summary, _ = sess.run([merged, train_step],\n    #                           feed_dict=feed_dict(True),\n    #                           options=run_options,\n    #                           run_metadata=run_metadata)\n    #     train_writer.add_run_metadata(run_metadata, \'step%03d\' % i)\n    #     train_writer.add_summary(summary, i)\n    #     print(\'Adding run metadata for\', i)\n    #   else:  # Record a summary\n        print(\'i\', i)\n        feed_dictionary = feed_dict(True)\n        summary, gradient_arrays, activations, _ = sess.run([merged, gradients, [image_shaped_input, conv1, conv2, hidden1, y], train_step], feed_dict=feed_dictionary)\n        first_of_batch = sess.run(x, feed_dict=feed_dictionary)[0].reshape(28, 28)\n\n        visualizer.update(\n          arrays=activations + [first_of_batch] + gradient_arrays,\n          frame=first_of_batch,\n        )\n        train_writer.add_summary(summary, i)\n\n  train_writer.close()\n  test_writer.close()\n\ndef main(_):\n  if not tf.gfile.Exists(LOG_DIRECTORY):\n    tf.gfile.MakeDirs(LOG_DIRECTORY)\n  train()\n\nif __name__ == \'__main__\':\n  parser = argparse.ArgumentParser()\n  parser.add_argument(\'--fake_data\', nargs=\'?\', const=True, type=bool,\n                      default=False,\n                      help=\'If true, uses fake data for unit testing.\')\n  parser.add_argument(\'--max_steps\', type=int, default=1000000,\n                      help=\'Number of steps to run trainer.\')\n  parser.add_argument(\'--learning_rate\', type=float, default=0.001,\n                      help=\'Initial learning rate\')\n  parser.add_argument(\'--dropout\', type=float, default=0.9,\n                      help=\'Keep probability for training dropout.\')\n  parser.add_argument(\n      \'--data_dir\',\n      type=str,\n      default=\'/tmp/tensorflow/mnist/input_data\',\n      help=\'Directory for storing input data\')\n  parser.add_argument(\n      \'--log_dir\',\n      type=str,\n      default=\'/tmp/tensorflow/mnist/logs/mnist_with_summaries\',\n      help=\'Summaries log directory\')\n  FLAGS, unparsed = parser.parse_known_args()\n  tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\n'"
