file_path,api_count,code
examples/inception_cifar.py,10,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# File: inception_cifar.py\n# Author: Qian Ge <geqian1001@gmail.com>\n\nimport os\nimport sys\nimport platform\nimport argparse\nimport numpy as np\nimport tensorflow as tf\n\nsys.path.append(\'../\')\nimport loader as loader\nfrom src.nets.googlenet import GoogLeNet_cifar\nfrom src.helper.trainer import Trainer\nfrom src.helper.evaluator import Evaluator\n\n\nDATA_PATH = \'/home/qge2/workspace/data/dataset/cifar/\'\nSAVE_PATH = \'/home/qge2/workspace/data/out/googlenet/cifar/\'\nPRETRINED_PATH = \'/home/qge2/workspace/data/pretrain/inception/googlenet.npy\'\nIM_PATH = \'../data/cifar/\'\n\n\ndef get_args():\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument(\'--train\', action=\'store_true\',\n                        help=\'Train the model\')\n    parser.add_argument(\'--eval\', action=\'store_true\',\n                        help=\'Evaluate the model\')\n    parser.add_argument(\'--predict\', action=\'store_true\',\n                        help=\'Get prediction result\')\n    parser.add_argument(\'--finetune\', action=\'store_true\',\n                        help=\'Fine tuning the model\')\n    parser.add_argument(\'--load\', type=int, default=99,\n                        help=\'Epoch id of pre-trained model\')\n\n    parser.add_argument(\'--lr\', type=float, default=1e-3,\n                        help=\'Initial learning rate\')\n    parser.add_argument(\'--bsize\', type=int, default=128,\n                        help=\'Batch size\')\n    parser.add_argument(\'--keep_prob\', type=float, default=0.4,\n                        help=\'Keep probability for dropout\')\n    parser.add_argument(\'--maxepoch\', type=int, default=100,\n                        help=\'Max number of epochs for training\')\n\n    parser.add_argument(\'--im_name\', type=str, default=\'.png\',\n                        help=\'Part of image name\')\n\n    return parser.parse_args()\n\ndef train():\n    FLAGS = get_args()\n    # Create Dataflow object for training and testing set\n    train_data, valid_data = loader.load_cifar(\n        cifar_path=DATA_PATH, batch_size=FLAGS.bsize, subtract_mean=True)\n\n    pre_trained_path=None\n    if FLAGS.finetune:\n        # Load the pre-trained model (on ImageNet)\n        # for convolutional layers if fine tuning\n        pre_trained_path = PRETRINED_PATH\n\n    # Create a training model\n    train_model = GoogLeNet_cifar(\n        n_channel=3, n_class=10, pre_trained_path=pre_trained_path,\n        bn=True, wd=0, sub_imagenet_mean=False,\n        conv_trainable=True, fc_trainable=True)\n    train_model.create_train_model()\n    # Create a validation model\n    valid_model = GoogLeNet_cifar(\n        n_channel=3, n_class=10, bn=True, sub_imagenet_mean=False)\n    valid_model.create_test_model()\n\n    # create a Trainer object for training control\n    trainer = Trainer(train_model, valid_model, train_data, init_lr=FLAGS.lr)\n\n    with tf.Session() as sess:\n        writer = tf.summary.FileWriter(SAVE_PATH)\n        saver = tf.train.Saver()\n        sess.run(tf.global_variables_initializer())\n        writer.add_graph(sess.graph)\n        for epoch_id in range(FLAGS.maxepoch):\n            # train one epoch\n            trainer.train_epoch(sess, keep_prob=FLAGS.keep_prob, summary_writer=writer)\n            # test the model on validation set after each epoch\n            trainer.valid_epoch(sess, dataflow=valid_data, summary_writer=writer)\n            saver.save(sess, \'{}inception-cifar-epoch-{}\'.format(SAVE_PATH, epoch_id))\n        saver.save(sess, \'{}inception-cifar-epoch-{}\'.format(SAVE_PATH, epoch_id))\n        writer.close()\n\ndef evaluate():\n    FLAGS = get_args()\n    # Create Dataflow object for training and testing set\n    train_data, valid_data = loader.load_cifar(\n        cifar_path=DATA_PATH, batch_size=FLAGS.bsize, subtract_mean=True)\n    # Create a validation model\n    valid_model = GoogLeNet_cifar(\n        n_channel=3, n_class=10, bn=True, sub_imagenet_mean=False)\n    valid_model.create_test_model()\n\n    # create a Evaluator object for evaluation\n    evaluator = Evaluator(valid_model)\n\n    with tf.Session() as sess:\n        saver = tf.train.Saver()\n        sess.run(tf.global_variables_initializer())\n        # load pre-trained model cifar\n        saver.restore(sess, \'{}inception-cifar-epoch-{}\'.format(SAVE_PATH, FLAGS.load))\n        print(\'training set:\', end=\'\')\n        evaluator.accuracy(sess, train_data)\n        print(\'testing set:\', end=\'\')\n        evaluator.accuracy(sess, valid_data)\n\ndef predict():\n    FLAGS = get_args()\n    # Read Cifar label into a dictionary\n    label_dict = loader.load_label_dict(dataset=\'cifar\')\n    # Create a Dataflow object for test images\n    image_data = loader.read_image(\n        im_name=FLAGS.im_name, n_channel=3,\n        data_dir=IM_PATH, batch_size=1, rescale=False)\n\n    # Create a testing GoogLeNet model\n    test_model = GoogLeNet_cifar(\n        n_channel=3, n_class=10, bn=True, sub_imagenet_mean=False)\n    test_model.create_test_model()\n\n    with tf.Session() as sess:\n        saver = tf.train.Saver()\n        sess.run(tf.global_variables_initializer())\n        saver.restore(sess, \'{}inception-cifar-epoch-{}\'.format(SAVE_PATH, FLAGS.load))\n        while image_data.epochs_completed < 1:\n            # read batch files\n            batch_data = image_data.next_batch_dict()\n            # get batch file names\n            batch_file_name = image_data.get_batch_file_name()[0]\n            # get prediction results\n            pred = sess.run(test_model.layers[\'top_5\'],\n                            feed_dict={test_model.image: batch_data[\'image\']})\n            # display results\n            for re_prob, re_label, file_name in zip(pred[0], pred[1], batch_file_name):\n                print(\'===============================\')\n                print(\'[image]: {}\'.format(file_name))\n                for i in range(5):\n                    print(\'{}: probability: {:.02f}, label: {}\'\n                          .format(i+1, re_prob[i], label_dict[re_label[i]]))\n\nif __name__ == ""__main__"":\n    FLAGS = get_args()\n\n    if FLAGS.train:\n        train()\n    if FLAGS.eval:\n        evaluate()\n    if FLAGS.predict:\n        predict()\n'"
examples/inception_pretrained.py,2,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# File: inception_pretrained.py\n# Author: Qian Ge <geqian1001@gmail.com>\n\nimport os\nimport sys\nimport platform\nimport argparse\nimport numpy as np\nimport tensorflow as tf\n\nsys.path.append(\'../\')\nimport loader as loader\nfrom src.nets.googlenet import GoogLeNet\n\nPRETRINED_PATH = \'/home/qge2/workspace/data/pretrain/inception/googlenet.npy\'\nDATA_PATH = \'../data/\'\nIM_CHANNEL = 3\n\n\ndef get_args():\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument(\'--pretrained_path\', type=str, default=PRETRINED_PATH,\n                        help=\'Directory of pretrain model\')\n    parser.add_argument(\'--im_name\', type=str, default=\'.jpg\',\n                        help=\'Part of image name\')\n    parser.add_argument(\'--data_path\', type=str, default=DATA_PATH,\n                        help=\'Directory of test images\')\n    \n    return parser.parse_args()\n\ndef test_pre_trained():\n    FLAGS = get_args()\n    # Read ImageNet label into a dictionary\n    label_dict = loader.load_label_dict()\n    # Create a Dataflow object for test images\n    image_data = loader.read_image(\n        im_name=FLAGS.im_name, n_channel=IM_CHANNEL,\n        data_dir=FLAGS.data_path, batch_size=1)\n\n    # Create a testing GoogLeNet model\n    test_model = GoogLeNet(\n        n_channel=IM_CHANNEL, n_class=1000, pre_trained_path=FLAGS.pretrained_path)\n    test_model.create_test_model()\n\n    with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n        while image_data.epochs_completed < 1:\n            # read batch files\n            batch_data = image_data.next_batch_dict()\n            # get batch file names\n            batch_file_name = image_data.get_batch_file_name()[0]\n            # get prediction results\n            pred = sess.run(test_model.layers[\'top_5\'],\n                            feed_dict={test_model.image: batch_data[\'image\']})\n            # display results\n            for re_prob, re_label, file_name in zip(pred[0], pred[1], batch_file_name):\n                print(\'===============================\')\n                print(\'[image]: {}\'.format(file_name))\n                for i in range(5):\n                    print(\'{}: probability: {:.02f}, label: {}\'\n                          .format(i+1, re_prob[i], label_dict[re_label[i]]))\n\nif __name__ == ""__main__"":\n    test_pre_trained()\n\n'"
examples/loader.py,0,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# File: loader.py\n# Author: Qian Ge <geqian1001@gmail.com>\n\nimport sys\nimport numpy as np\nimport tensorflow as tf\nimport skimage.transform\n\nsys.path.append(\'../\')\nfrom src.dataflow.images import Image\nfrom src.dataflow.cifar import CIFAR \n\ndef load_label_dict(dataset=\'imagenet\'):\n    """""" \n        Function to read the ImageNet label file.\n        Used for testing the pre-trained model.\n\n        dataset (str): name of data set. \'imagenet\', \'cifar\'\n    """"""\n    label_dict = {}\n    if dataset == \'cifar\':\n        file_path = \'../data/cifarLabel.txt\'\n    else:\n        file_path = \'../data/imageNetLabel.txt\'\n    with open(file_path, \'r\') as f:\n        for idx, line in enumerate(f):\n            if dataset == \'cifar\':\n                names = line.rstrip()\n            else:\n                # point to the class label string\n                names = line.rstrip()[10:]\n            label_dict[idx] = names\n    return label_dict\n\ndef read_image(im_name, n_channel, data_dir=\'\', batch_size=1, rescale=True):\n    """""" function for create a Dataflow for reading images from a folder\n        This function returns a Dataflow object for images with file \n        name containing \'im_name\' in directory \'data_dir\'.\n\n        Args:\n            im_name (str): part of image names (i.e. \'jpg\' or \'im_\').\n            n_channel (int): number of channels (3 for color images and 1 for grayscale images)\n            data_dir (str): directory of images\n            batch_size (int): number of images read from Dataflow for each batch\n            rescale (bool): whether rescale image to 224 or not\n\n        Returns:\n            Image (object): batch images can be access by Image.next_batch_dict()[\'image\']\n    """"""\n\n    def rescale_im(im):\n        """""" Pre-process for images \n            images are rescaled so that the shorter side = 224\n        """"""\n        im = np.array(im)\n        h, w = im.shape[0], im.shape[1]\n        if h >= w:\n            new_w = 224\n            im = skimage.transform.resize(im, (int(h * new_w / w), 224),\n                                          preserve_range=True)\n        else:\n            new_h = 224\n            im = skimage.transform.resize(im, (224, int(w * new_h / h)),\n                                          preserve_range=True)\n        return im.astype(\'uint8\')\n\n    if rescale:\n        pf_fnc = rescale_im\n    else:\n        pf_fnc = None\n\n    image_data = Image(\n        im_name=im_name,\n        data_dir=data_dir,\n        n_channel=n_channel,\n        shuffle=False,\n        batch_dict_name=[\'image\'],\n        pf_list=pf_fnc)\n    image_data.setup(epoch_val=0, batch_size=batch_size)\n\n    return image_data\n\ndef load_cifar(cifar_path, batch_size=64, subtract_mean=True):\n    """""" function for create Dataflow objects for CIFAR-10\n\n        Args:\n            cifar_path (str): directory of CIFAR-10 data\n            batch_size (int): number of images read from Dataflow for each batch\n            substract_mean (bool): whether subtract each channel by average of training set\n\n        Returns:\n            CIFAR (object) of training and testing set.\n            Batch images and label can be access by\n            CIFAR.next_batch_dict()[\'image\'] and \n            CIFAR.next_batch_dict()[\'label\']\n    """"""\n\n    train_data = CIFAR(\n        data_dir=cifar_path,\n        shuffle=True,\n        batch_dict_name=[\'image\', \'label\'],\n        data_type=\'train\',\n        channel_mean=None,\n        subtract_mean=subtract_mean,\n        augment=True,\n        # pf=preprocess,\n        )\n    train_data.setup(epoch_val=0, batch_size=batch_size)\n\n    valid_data = CIFAR(\n        data_dir=cifar_path,\n        shuffle=False,\n        batch_dict_name=[\'image\', \'label\'],\n        data_type=\'valid\',\n        channel_mean=train_data.channel_mean,\n        subtract_mean=subtract_mean,\n        augment=False,\n        # pf=pf_test,\n        )\n    valid_data.setup(epoch_val=0, batch_size=batch_size)\n\n    return train_data, valid_data\n\nif __name__ == ""__main__"":\n    import matplotlib.pyplot as plt\n\n    image_data, test_data = load_cifar(\n        \'E:/Dataset/cifar/\', batch_size=100, subtract_mean=True)\n    batch_data = image_data.next_batch_dict()\n    print(batch_data[\'image\'].shape)\n    plt.figure()\n    plt.imshow(np.squeeze(batch_data[\'image\'][0]))\n    print(type(batch_data[\'image\'][0]))\n\n    plt.figure()\n    plt.imshow(np.squeeze(batch_data[\'image\'][1]))\n\n\n    batch_data = image_data.next_batch_dict()\n    plt.figure()\n    plt.imshow(np.squeeze(batch_data[\'image\'][0]))\n    print(type(batch_data[\'image\'][0]))\n    plt.figure()\n    plt.imshow(np.squeeze(batch_data[\'image\'][1]))\n\n    plt.show()\n    '"
src/__init__.py,0,b''
src/dataflow/__init__.py,0,b''
src/dataflow/base.py,0,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# File: base.py\n# Author: Qian Ge <geqian1001@gmail.com>\n\nimport numpy as np \nimport src.utils.utils as utils\nfrom src.utils.dataflow import get_rng, get_file_list\n\n\nclass DataFlow(object):\n    def __init__(self,\n                 data_name_list,\n                 data_dir=\'\',\n                 shuffle=True,\n                 batch_dict_name=None,\n                 load_fnc_list=None,\n                 ):\n        data_name_list = utils.make_list(data_name_list)\n        load_fnc_list = utils.make_list(load_fnc_list)\n        data_dir = utils.make_list(data_dir)\n\n        if len(data_dir) == 1:\n            data_dir_list = [data_dir[0] for i in range(len(load_fnc_list))]\n            data_dir = data_dir_list\n\n        dataflow_list = []\n        self._load_fnc_list = []\n        for data_name, load_fnc in zip(data_name_list, load_fnc_list):\n            if data_name is not None and load_fnc is not None:\n                dataflow_list.append(data_name)\n                self._load_fnc_list.append(load_fnc)\n            else:\n                break\n        self._n_dataflow = len(dataflow_list)\n\n        # pf_list = utils.make_list(pf_list)\n\n        # utils.assert_len([data_name_list, load_fnc_list])\n        # self._n_dataflow = len(data_name_list)\n        # self._load_fnc_list = load_fnc_list\n\n        # self._data_dir = data_dir\n        self._shuffle = shuffle\n        self._batch_dict_name = batch_dict_name\n\n        self._data_id = 0\n        self.setup(epoch_val=0, batch_size=1)\n        self._load_file_list(dataflow_list, data_dir)\n        self._cur_file_name = [[] for i in range(len(self._file_name_list))]\n\n    def setup(self, epoch_val, batch_size, **kwargs):\n        self._epochs_completed  = epoch_val\n        self._batch_size = batch_size\n        self.rng = get_rng(self)\n        self._setup()\n\n    def reset_epoch(self):\n        self._epochs_completed = 0\n\n    def _setup(self):\n        pass\n\n    def size(self):\n        return len(self._file_name_list[0])\n\n    def _load_file_list(self, data_name_list, data_dir_list):\n        self._file_name_list = []\n        for data_name, data_dir in zip(data_name_list, data_dir_list):\n            self._file_name_list.append(get_file_list(data_dir, data_name))\n        if self._shuffle:\n            self._suffle_file_list()\n\n\n    def _suffle_file_list(self):\n        idxs = np.arange(self.size())\n        self.rng.shuffle(idxs)\n        for idx, file_list in enumerate(self._file_name_list):\n            self._file_name_list[idx] = file_list[idxs]\n\n    def next_batch(self):\n        assert self._batch_size <= self.size(), \\\n        ""batch_size cannot be larger than data size""\n\n        if self._data_id + self._batch_size > self.size():\n            start = self._data_id\n            end = self.size()\n        else:\n            start = self._data_id\n            self._data_id += self._batch_size\n            end = self._data_id\n        batch_data = self._load_data(start, end)\n\n        for flow_id in range(len(self._file_name_list)):\n            self._cur_file_name[flow_id] = self._file_name_list[flow_id][start: end]\n\n        if end == self.size():\n            self._epochs_completed += 1\n            self._data_id = 0\n            if self._shuffle:\n                self._suffle_file_list()\n        return batch_data\n\n    def _load_data(self, start, end):\n        data_list = [[] for i in range(0, self._n_dataflow)]\n        for k in range(start, end):\n            for read_idx, read_fnc in enumerate(self._load_fnc_list):\n                data = read_fnc(self._file_name_list[read_idx][k])\n                data_list[read_idx].append(data)\n\n        for idx, data in enumerate(data_list):\n            data_list[idx] = np.array(data)\n\n        return data_list\n\n    def next_batch_dict(self):\n        batch_data = self.next_batch()\n        return {key: data for key, data in zip(self._batch_dict_name, batch_data)} \n\n    def get_batch_file_name(self):\n        return self._cur_file_name\n\n    @property\n    def epochs_completed(self):\n        return self._epochs_completed\n'"
src/dataflow/cifar.py,1,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# File: cifar.py\n# Author: Qian Ge <geqian1001@gmail.com>\n\nimport os\nimport pickle\nimport numpy as np\nimport tensorflow as tf\n\nfrom src.dataflow.base import DataFlow\n\n\nclass CIFAR(DataFlow):\n    def __init__(self,\n                 data_dir=\'\',\n                 shuffle=True,\n                 batch_dict_name=None,\n                 data_type=\'train\',\n                 channel_mean=None,\n                 subtract_mean=True,\n                 pf=None,\n                 augment=False):\n        self._mean = channel_mean\n        self._subtract = subtract_mean\n        self._pf = pf\n\n        self._augment = augment\n        if augment:\n            self._augment_flow = tf.keras.preprocessing.image.ImageDataGenerator(\n                featurewise_center=False,\n                samplewise_center=False,\n                featurewise_std_normalization=False,\n                samplewise_std_normalization=False,\n                zca_whitening=False,\n                zca_epsilon=1e-06,\n                rotation_range=20.0,\n                width_shift_range=0.1,\n                height_shift_range=0.1,\n                brightness_range=None,\n                shear_range=0.0,\n                zoom_range=0.0,\n                channel_shift_range=0.0,\n                fill_mode=\'nearest\',\n                cval=0.0,\n                horizontal_flip=True,\n                vertical_flip=False,\n                rescale=None,\n                preprocessing_function=None,\n                data_format=None,\n                validation_split=0.0)\n        # self.num_channels = 3\n        # self.im_size = [32, 32]\n\n        # assert os.path.isdir(data_dir)\n        # self.data_dir = data_dir\n\n        assert batch_dict_name is not None\n        if not isinstance(batch_dict_name, list):\n            batch_dict_name = [batch_dict_name]\n        self._batch_dict_name = batch_dict_name\n\n        if data_type == \'train\':\n            self._file_list = [os.path.join(data_dir, \'data_batch_{}\'.format(i)) for i in range(1, 6)]\n        else:\n            self._file_list = [os.path.join(data_dir, \'test_batch\')]\n\n        self.shuffle = shuffle\n\n        self.setup(epoch_val=0, batch_size=1)\n        # if not isinstance(batch_file_list, list):\n        #     batch_file_list = [batch_file_list]\n        # self._file_list = [os.path.join(data_dir, \'data_batch_\' + str(batch_id)) for batch_id in batch_file_list]\n\n        # self._load_files()\n        # self._num_image = self.size()\n\n        self._image_id = 0\n        self._batch_file_id = -1\n        self._image = []\n        self._next_batch_file()\n\n        print(\'Data Loaded! Size of data: {}\'.format(self.size()))\n\n    def _next_batch_file(self):\n        if self._batch_file_id >= len(self._file_list) - 1:\n            self._batch_file_id = 0\n            self._epochs_completed += 1\n        else:\n            self._batch_file_id += 1\n        data_dict = unpickle(self._file_list[self._batch_file_id])\n        self._image = np.array(data_dict[\'image\'])\n        if self._pf:\n            self._image = [self._pf(im) for im in self._image]\n            self._image = np.array(self._image )\n        self._label = np.array(data_dict[\'label\'])\n\n        if self.shuffle:\n            self._suffle_files()\n\n    def _suffle_files(self):\n        idxs = np.arange(len(self._image))\n\n        self.rng.shuffle(idxs)\n        self._image = self._image[idxs]\n        self._label = self._label[idxs]\n\n    @property\n    def batch_step(self):\n        return int(self.size() * 1.0 / self._batch_size)\n\n    @property\n    def channel_mean(self):\n        if self._mean == None:\n            self._mean = self._comp_channel_mean()\n        return self._mean\n\n    def subtract_channel_mean(self, im_list):\n        """"""\n        Args:\n            im_list: [batch, h, w, c]\n        """"""\n        mean = self.channel_mean\n        for c_id in range(0, im_list.shape[-1]):\n            im_list[:, :, :, c_id] = im_list[:, :, :, c_id] - mean[c_id]\n        return im_list\n\n    def _comp_channel_mean(self):\n        im_list = []\n        for k in range(len(self._file_list)):\n            cur_im = unpickle(self._file_list[k])[\'image\']\n            im_list.extend(cur_im)\n        im_list = np.array(im_list)\n\n        mean_list = []\n        for c_id in range(0, im_list.shape[-1]):\n            mean_list.append(np.mean(im_list[:,:,:,c_id]))\n        return mean_list\n\n    def size(self):\n        try:\n            return self.data_size\n        except AttributeError:\n            data_size = 0\n            for k in range(len(self._file_list)):\n                tmp_image = unpickle(self._file_list[k])[\'image\']\n                data_size += len(tmp_image)\n            self.data_size = data_size\n            return self.data_size\n        \n    def next_batch(self):\n        assert self._batch_size <= self.size(), \\\n          ""batch_size {} cannot be larger than data size {}"".\\\n           format(self._batch_size, self.size())\n\n        start = self._image_id\n        self._image_id += self._batch_size\n        end = self._image_id\n        batch_image = np.array(self._image[start:end])\n        batch_label = np.array(self._label[start:end])\n\n        if self._image_id + self._batch_size > len(self._image):\n            self._next_batch_file()\n            self._image_id = 0\n            if self.shuffle:\n                self._suffle_files()\n        if self._augment:\n            self._augment_flow.fit(batch_image)\n            batch_image, batch_label = self._augment_flow.flow(batch_image, batch_label, batch_size=self._batch_size)[0]\n        if self._subtract:\n            batch_image = self.subtract_channel_mean(batch_image)\n        # batch_image = batch_image.astype(\'float32\')\n        # batch_image = batch_image / 255. * 2. - 1.\n        return batch_image.astype(\'float32\'), batch_label\n\n    def next_batch_dict(self):\n        re_dict = {}\n        batch_data = self.next_batch()\n        for key, data in zip(self._batch_dict_name, batch_data):\n            re_dict[key] = data\n        return re_dict\n\n\ndef unpickle(file):\n    with open(file, \'rb\') as fo:\n        dict = pickle.load(fo, encoding=\'bytes\')\n    image = dict[b\'data\']\n    labels = dict[b\'labels\']\n\n    r = image[:,:32*32].reshape(-1,32,32)\n    g = image[:,32*32: 2*32*32].reshape(-1,32,32)\n    b = image[:,2*32*32:].reshape(-1,32,32)\n\n    image = np.stack((r,g,b),axis=-1)\n\n    return {\'image\': image.astype(float), \'label\': labels}\n\n'"
src/dataflow/images.py,0,"b""#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# File: images.py\n# Author: Qian Ge <geqian1001@gmail.com>\n\nfrom src.dataflow.base import DataFlow\nfrom src.utils.dataflow import load_image, identity, fill_pf_list\n\n\nclass Image(DataFlow):\n    def __init__(self,\n                 im_name,\n                 data_dir='',\n                 n_channel=3,\n                 shuffle=True,\n                 batch_dict_name=None,\n                 pf_list=None):\n        pf_list = fill_pf_list(\n            pf_list, n_pf=1, fill_with_fnc=identity)\n\n        def read_image(file_name):\n            im = load_image(file_name, read_channel=n_channel,  pf=pf_list[0])\n            return im\n\n        super(Image, self).__init__(\n            data_name_list=[im_name],\n            data_dir=data_dir,\n            shuffle=shuffle,\n            batch_dict_name=batch_dict_name,\n            load_fnc_list=[read_image],\n            ) """
src/helper/__init__.py,0,b''
src/helper/evaluator.py,0,"b""#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# File: evaluator.py\n# Author: Qian Ge <geqian1001@gmail.com>\n\nimport os\nimport numpy as np\nimport tensorflow as tf\n\n\nclass Evaluator(object):\n    def __init__(self, model):\n\n        self._model = model\n        self._accuracy_op = model.get_accuracy()\n\n    def accuracy(self, sess, dataflow):\n        dataflow.reset_epoch()\n\n        step = 0\n        acc_sum = 0\n        while dataflow.epochs_completed < 1:\n            step += 1\n\n            batch_data = dataflow.next_batch_dict()\n            im = batch_data['image']\n            label = batch_data['label']\n            acc = sess.run(\n                self._accuracy_op, \n                feed_dict={self._model.image: im,\n                           self._model.label: label})\n            acc_sum += acc\n        print('[accuracy]: {:.04f}'.format(acc_sum / step))\n"""
src/helper/trainer.py,1,"b""#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# File: trainer.py\n# Author: Qian Ge <geqian1001@gmail.com>\n\nimport os\nimport numpy as np\nimport tensorflow as tf\n\n\ndef display(global_step,\n            step,\n            scaler_sum_list,\n            name_list,\n            collection,\n            summary_val=None,\n            summary_writer=None,\n            ):\n    print('[step: {}]'.format(global_step), end='')\n    for val, name in zip(scaler_sum_list, name_list):\n        print(' {}: {:.4f}'.format(name, val * 1. / step), end='')\n    print('')\n    if summary_writer is not None:\n        s = tf.Summary()\n        for val, name in zip(scaler_sum_list, name_list):\n            s.value.add(tag='{}/{}'.format(collection, name),\n                        simple_value=val * 1. / step)\n        summary_writer.add_summary(s, global_step)\n        if summary_val is not None:\n            summary_writer.add_summary(summary_val, global_step)\n\nclass Trainer(object):\n    def __init__(self, train_model, valid_model, train_data, init_lr=1e-3):\n\n        self._t_model = train_model\n        self._v_model = valid_model\n        self._train_data = train_data\n        self._init_lr = init_lr\n\n        self._train_op = train_model.get_train_op()\n        self._train_loss_op = train_model.get_loss()\n        self._train_accuracy_op = train_model.get_accuracy()\n\n        self._valid_loss_op = valid_model.get_loss()\n        self._valid_accuracy_op = valid_model.get_accuracy()\n        # self._train_summary_op = train_model.get_train_summary()\n        # self._valid_summary_op = train_model.get_valid_summary()\n\n        self.global_step = 0\n        self.epoch_id = 0\n\n    def train_epoch(self, sess, keep_prob=1., summary_writer=None):\n        if self.epoch_id < 35:\n            self._lr = self._init_lr\n        elif self.epoch_id < 50:\n            self._lr = self._init_lr / 10.\n        else:\n            self._lr = self._init_lr / 100.\n        # self._t_model.set_is_training(True)\n        display_name_list = ['loss', 'accuracy']\n        cur_summary = None\n\n        cur_epoch = self._train_data.epochs_completed\n\n        step = 0\n        loss_sum = 0\n        acc_sum = 0\n        self.epoch_id += 1\n        while cur_epoch == self._train_data.epochs_completed:\n            self.global_step += 1\n            step += 1\n\n            batch_data = self._train_data.next_batch_dict()\n            im = batch_data['image']\n            label = batch_data['label']\n            _, loss, acc = sess.run(\n                [self._train_op, self._train_loss_op, self._train_accuracy_op], \n                feed_dict={self._t_model.image: im,\n                           self._t_model.label: label,\n                           self._t_model.lr: self._lr,\n                           self._t_model.keep_prob: keep_prob})\n\n            loss_sum += loss\n            acc_sum += acc\n\n            if step % 100 == 0:\n                display(self.global_step,\n                    step,\n                    [loss_sum, acc_sum],\n                    display_name_list,\n                    'train',\n                    summary_val=cur_summary,\n                    summary_writer=summary_writer)\n\n        print('==== epoch: {}, lr:{} ===='.format(cur_epoch, self._lr))\n        display(self.global_step,\n                step,\n                [loss_sum, acc_sum],\n                display_name_list,\n                'train',\n                summary_val=cur_summary,\n                summary_writer=summary_writer)\n\n    def valid_epoch(self, sess, dataflow, summary_writer=None):\n        display_name_list = ['loss', 'accuracy']\n        cur_summary = None\n        dataflow.reset_epoch()\n\n        step = 0\n        loss_sum = 0\n        acc_sum = 0\n        while dataflow.epochs_completed < 1:\n            step += 1\n\n            batch_data = dataflow.next_batch_dict()\n            im = batch_data['image']\n            label = batch_data['label']\n            loss, acc = sess.run(\n                [self._valid_loss_op, self._valid_accuracy_op], \n                feed_dict={self._v_model.image: im,\n                           self._v_model.label: label})\n\n            loss_sum += loss\n            acc_sum += acc\n\n        print('[Valid]: ', end='')\n        display(self.global_step,\n                step,\n                [loss_sum, acc_sum],\n                display_name_list,\n                'valid',\n                summary_val=cur_summary,\n                summary_writer=summary_writer)\n"""
src/models/__init__.py,0,b''
src/models/inception_module.py,24,"b""#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# File: inception_module.py\n# Author: Qian Ge <geqian1001@gmail.com>\n\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.contrib.framework import add_arg_scope\n\nimport src.models.layers as L\n\n\ndef sub_rgb2bgr_mean(inputs):\n    with tf.name_scope('sub_mean'):\n        red, green, blue = tf.split(axis=3,\n                                    num_or_size_splits=3,\n                                    value=inputs)\n\n        imagenet_mean = [103.939, 116.779, 123.68]\n\n        input_bgr = tf.concat(axis=3, values=[\n            blue - imagenet_mean[0],\n            green - imagenet_mean[1],\n            red - imagenet_mean[2],\n        ])\n        return input_bgr\n\n@add_arg_scope\ndef inception_layer(conv_11_size, conv_33_reduce_size, conv_33_size,\n                    conv_55_reduce_size, conv_55_size, pool_size,\n                    layer_dict, inputs=None,\n                    bn=False, wd=0, init_w=None,\n                    pretrained_dict=None, trainable=True, is_training=True,\n                    name='inception'):\n    \n    if inputs is None:\n        inputs = layer_dict['cur_input']\n    layer_dict['cur_input'] = inputs\n\n    arg_scope = tf.contrib.framework.arg_scope\n    with arg_scope([L.conv], layer_dict=layer_dict, pretrained_dict=pretrained_dict,\n                   bn=bn, nl=tf.nn.relu, init_w=init_w, trainable=trainable,\n                   is_training=is_training, wd=wd, add_summary=False):\n\n\n        conv_11 = L.conv(filter_size=1, out_dim=conv_11_size,\n                         inputs=inputs, name='{}_1x1'.format(name))\n\n        L.conv(filter_size=1, out_dim=conv_33_reduce_size,\n               inputs=inputs, name='{}_3x3_reduce'.format(name))\n        conv_33 = L.conv(filter_size=3, out_dim=conv_33_size,\n                         name='{}_3x3'.format(name))\n\n        L.conv(filter_size=1, out_dim=conv_55_reduce_size,\n               inputs=inputs, name='{}_5x5_reduce'.format(name))\n        conv_55 = L.conv(filter_size=5, out_dim=conv_55_size,\n                         name='{}_5x5'.format(name))\n\n        L.max_pool(layer_dict=layer_dict, inputs=inputs, stride=1,\n                   filter_size=3, padding='SAME', name='{}_pool'.format(name))\n        convpool = L.conv(filter_size=1, out_dim=pool_size,\n                          name='{}_pool_proj'.format(name))\n\n        output = tf.concat([conv_11, conv_33, conv_55, convpool], 3,\n                           name='{}_concat'.format(name))\n        layer_dict['cur_input'] = output\n        layer_dict[name] = output\n    return output\n\ndef inception_conv_layers(layer_dict, inputs=None, pretrained_dict=None,\n                          bn=False, wd=0, init_w=None,\n                          is_training=True, trainable=True,\n                          conv_stride=2):\n    if inputs is None:\n        inputs = layer_dict['cur_input']\n    layer_dict['cur_input'] = inputs\n    \n    arg_scope = tf.contrib.framework.arg_scope\n    with arg_scope([L.conv], layer_dict=layer_dict, pretrained_dict=pretrained_dict,\n                   bn=bn, nl=tf.nn.relu, init_w=init_w, trainable=trainable,\n                   is_training=is_training, wd=wd, add_summary=False):\n\n        conv1 = L.conv(7, 64, inputs=inputs, name='conv1_7x7_s2', stride=conv_stride)\n        padding1 = tf.constant([[0, 0], [0, 1], [0, 1], [0, 0]])\n        conv1_pad = tf.pad(conv1, padding1, 'CONSTANT')\n        pool1, _ = L.max_pool(\n            layer_dict=layer_dict, inputs=conv1_pad, stride=2,\n            filter_size=3, padding='VALID', name='pool1')\n        pool1_lrn = tf.nn.local_response_normalization(\n            pool1, depth_radius=2, alpha=2e-05, beta=0.75,\n            name='pool1_lrn')\n\n        conv2_reduce = L.conv(1, 64, inputs=pool1_lrn, name='conv2_3x3_reduce')\n        conv2 = L.conv(3, 192, inputs=conv2_reduce, name='conv2_3x3')\n        padding2 = tf.constant([[0, 0], [0, 1], [0, 1], [0, 0]])\n        conv2_pad = tf.pad(conv2, padding2, 'CONSTANT')\n        pool2, _ = L.max_pool(\n            layer_dict=layer_dict, inputs=conv2_pad, stride=2,\n            filter_size=3, padding='VALID', name='pool2')\n        pool2_lrn = tf.nn.local_response_normalization(\n            pool2, depth_radius=2, alpha=2e-05, beta=0.75,\n            name='pool2_lrn')\n    layer_dict['cur_input'] = pool2_lrn\n    return pool2_lrn\n\ndef inception_layers(layer_dict, inputs=None, pretrained_dict=None,\n                     bn=False, init_w=None, wd=0,\n                     trainable=True, is_training=True):\n    if inputs is not None:\n        layer_dict['cur_input'] = inputs\n\n    arg_scope = tf.contrib.framework.arg_scope\n    with arg_scope([inception_layer], layer_dict=layer_dict,\n                   pretrained_dict=pretrained_dict,\n                   bn=bn, init_w=init_w, trainable=trainable,\n                   is_training=is_training, wd=wd):\n\n        inception_layer(64, 96, 128, 16, 32, 32, name='inception_3a')\n        inception_layer(128, 128, 192, 32, 96, 64, name='inception_3b')\n        L.max_pool(layer_dict, stride=2, filter_size=3, name='pool3')\n\n        inception_layer(192, 96, 208, 16, 48, 64, name='inception_4a')\n        inception_layer(160, 112, 224, 24, 64, 64, name='inception_4b')\n        inception_layer(128, 128, 256, 24, 64, 64, name='inception_4c')\n        inception_layer(112, 144, 288, 32, 64, 64, name='inception_4d')\n        inception_layer(256, 160, 320, 32, 128, 128, name='inception_4e')\n        L.max_pool(layer_dict, stride=2, filter_size=3, name='pool4')\n\n        inception_layer(256, 160, 320, 32, 128, 128, name='inception_5a')\n        inception_layer(384, 192, 384, 48, 128, 128, name='inception_5b')\n\n    return layer_dict['cur_input']\n\ndef inception_fc(layer_dict, n_class, keep_prob=1., inputs=None,\n                 pretrained_dict=None, is_training=True,\n                 bn=False, init_w=None, trainable=True, wd=0):\n\n    if inputs is not None:\n        layer_dict['cur_input'] = inputs\n\n    layer_dict['cur_input'] = L.global_avg_pool(layer_dict['cur_input'], keepdims=True)\n    # layer_dict['cur_input'] = tf.expand_dims(layer_dict['cur_input'], [1, 2])\n    L.drop_out(layer_dict, is_training, keep_prob=keep_prob)\n    L.conv(filter_size=1, out_dim=n_class, layer_dict=layer_dict,\n           pretrained_dict=pretrained_dict, trainable=trainable,\n           bn=False, init_w=init_w, wd=wd, is_training=is_training,\n           name='loss3_classifier')\n    layer_dict['cur_input'] = tf.squeeze(layer_dict['cur_input'], [1, 2])\n\n    return layer_dict['cur_input']\n\ndef inception_conv_layers_cifar(layer_dict, inputs=None, pretrained_dict=None,\n                                bn=False, wd=0, init_w=None,\n                                is_training=True, trainable=True,\n                                conv_stride=2):\n    if inputs is None:\n        inputs = layer_dict['cur_input']\n    layer_dict['cur_input'] = inputs\n    \n    arg_scope = tf.contrib.framework.arg_scope\n    with arg_scope([L.conv], layer_dict=layer_dict, pretrained_dict=pretrained_dict,\n                   bn=bn, nl=tf.nn.relu, init_w=init_w, trainable=trainable,\n                   is_training=is_training, wd=wd, add_summary=False):\n\n        L.conv(7, 64, name='conv1_7x7_s2', stride=conv_stride)\n        # L.max_pool(layer_dict=layer_dict, stride=2,\n        #            filter_size=3, padding='VALID', name='pool1')\n\n        L.conv(1, 64, name='conv2_3x3_reduce')\n        L.conv(3, 192, name='conv2_3x3')\n        # L.max_pool(layer_dict=layer_dict, stride=2,\n        #            filter_size=3, padding='VALID', name='pool2')\n\n    return layer_dict['cur_input']\n\ndef auxiliary_classifier(layer_dict, n_class, keep_prob=1., inputs=None,\n                               pretrained_dict=None, is_training=True,\n                               bn=False, init_w=None, trainable=True, wd=0):\n    \n    if inputs is not None:\n        layer_dict['cur_input'] = inputs\n\n    # layer_dict['cur_input'] = tf.layers.average_pooling2d(\n    #     inputs=layer_dict['cur_input'],\n    #     pool_size=5, strides=3,\n    #     padding='valid', name='averagepool')\n    layer_dict['cur_input'] = L.global_avg_pool(layer_dict['cur_input'], keepdims=True)\n\n    arg_scope = tf.contrib.framework.arg_scope\n    with arg_scope([L.conv, L.linear], layer_dict=layer_dict,\n                   bn=bn, init_w=init_w, trainable=trainable,\n                   is_training=is_training, wd=wd, add_summary=False):\n\n        L.conv(1, 128, name='conv', stride=1, nl=tf.nn.relu)\n        L.linear(out_dim=512, name='fc_1', nl=tf.nn.relu)\n        L.drop_out(layer_dict, is_training, keep_prob=keep_prob)\n        L.linear(out_dim=512, name='fc_2', nl=tf.nn.relu)\n        L.drop_out(layer_dict, is_training, keep_prob=keep_prob)\n        L.linear(out_dim=n_class, name='classifier', bn=False)\n\n    return layer_dict['cur_input']\n\n"""
src/models/layers.py,53,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# File: layers.py\n# Author: Qian Ge <geqian1001@gmail.com>\n\nimport math\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.contrib.framework import add_arg_scope\n\n\ndef get_shape4D(in_val):\n    """"""\n    Return a 4D shape\n    Args:\n        in_val (int or list with length 2)\n    Returns:\n        list with length 4\n    """"""\n    # if isinstance(in_val, int):\n    return [1] + get_shape2D(in_val) + [1]\n\ndef get_shape2D(in_val):\n    """"""\n    Return a 2D shape \n    Args:\n        in_val (int or list with length 2) \n    Returns:\n        list with length 2\n    """"""\n    # in_val = int(in_val)\n    if isinstance(in_val, int):\n        return [in_val, in_val]\n    if isinstance(in_val, list):\n        assert len(in_val) == 2\n        return in_val\n    raise RuntimeError(\'Illegal shape: {}\'.format(in_val))\n\ndef deconv_size(input_height, input_width, stride=2):\n    """"""\n    Compute the feature size (height and width) after filtering with\n    a specific stride. Mostly used for setting the shape for deconvolution.\n    Args:\n        input_height (int): height of input feature\n        input_width (int): width of input feature\n        stride (int): stride of the filter\n    Return:\n        (int, int): Height and width of feature after filtering.\n    """"""\n    return int(math.ceil(float(input_height) / float(stride))),\\\n           int(math.ceil(float(input_width) / float(stride)))\n\ndef batch_flatten(x):\n    """"""\n    Flatten the tensor except the first dimension.\n    """"""\n    shape = x.get_shape().as_list()[1:]\n    if None not in shape:\n        return tf.reshape(x, [-1, int(np.prod(shape))])\n    return tf.reshape(x, tf.stack([tf.shape(x)[0], -1]))\n\ndef softplus(inputs, name):\n    return tf.log(1 + tf.exp(inputs), name=name)\n\ndef softmax(logits, axis=-1, name=\'softmax\'):\n    with tf.name_scope(name):\n        max_in = tf.reduce_max(logits, axis=axis, keepdims=True)\n        stable_in = logits - max_in\n        normal_p = tf.reduce_sum(tf.exp(stable_in), axis=axis, keepdims=True)\n \n        return tf.exp(stable_in) / normal_p\n\ndef leaky_relu(x, leak=0.2, name=\'LeakyRelu\'):\n    """""" \n    leaky_relu \n        Allow a small non-zero gradient when the unit is not active\n    Args:\n        x (tf.tensor): a tensor \n        leak (float): Default to 0.2\n    Returns:\n        tf.tensor with name \'name\'\n    """"""\n    return tf.maximum(x, leak*x, name=name)\n\ndef batch_norm(x, train=True, name=\'bn\'):\n    """""" \n    batch normal \n    Args:\n        x (tf.tensor): a tensor \n        name (str): name scope\n        train (bool): whether training or not\n    Returns:\n        tf.tensor with name \'name\'\n    """"""\n    return tf.contrib.layers.batch_norm(\n        x, decay=0.9, updates_collections=None,\n        epsilon=1e-5, scale=False,\n        is_training=train, scope=name)\n\n\n@add_arg_scope\ndef linear(out_dim,\n           layer_dict=None,\n           inputs=None,\n           init_w=None,\n           init_b=tf.zeros_initializer(),\n           wd=0,\n           bn=False,\n           is_training=True,\n           trainable=True,\n           name=\'Linear\',\n           nl=tf.identity,\n           add_summary=False):\n    with tf.variable_scope(name):\n        if inputs is None:\n            assert layer_dict is not None\n            inputs = layer_dict[\'cur_input\']\n        inputs = batch_flatten(inputs)\n        in_dim = inputs.get_shape().as_list()[1]\n        if wd > 0:\n            regularizer = tf.contrib.layers.l2_regularizer(scale=wd)\n        else:\n            regularizer=None\n        weights = tf.get_variable(\'weights\',\n                                  shape=[in_dim, out_dim],\n                                  # dtype=None,\n                                  initializer=init_w,\n                                  regularizer=regularizer,\n                                  trainable=trainable)\n        biases = tf.get_variable(\'biases\',\n                                  shape=[out_dim],\n                                  # dtype=None,\n                                  initializer=init_b,\n                                  regularizer=None,\n                                  trainable=trainable)\n\n        if add_summary:\n            tf.summary.histogram(\n                \'weights/{}\'.format(name), weights, collections = [\'train\'])\n\n        # print(\'init: {}\'.format(weights))\n        act = tf.nn.xw_plus_b(inputs, weights, biases)\n        if bn is True:\n            act = batch_norm(act, train=is_training, name=\'bn\')\n        result = nl(act, name=\'output\')\n        if layer_dict is not None:\n            layer_dict[\'cur_input\'] = result\n\n        layer_dict[name] = result\n            \n        return result\n\n@add_arg_scope\ndef transpose_conv(\n                   filter_size,\n                   layer_dict,\n                   inputs=None,\n                   out_dim=None,\n                   out_shape=None,\n                   stride=2,\n                   padding=\'SAME\',\n                   trainable=True,\n                   nl=tf.identity,\n                   init_w=None,\n                   init_b=tf.zeros_initializer(),\n                   wd=0,\n                   bn=False,\n                   is_training=True,\n                   constant_init=False,\n                   name=\'dconv\',\n                   add_summary=False):\n    if inputs is None:\n        inputs = layer_dict[\'cur_input\']\n    stride = get_shape4D(stride)\n    in_dim = inputs.get_shape().as_list()[-1]\n\n    # TODO other ways to determine the output shape \n    x_shape = tf.shape(inputs)\n    # assume output shape is input_shape*stride\n    if out_shape is None:\n        out_shape = tf.stack([x_shape[0],\n                              tf.multiply(x_shape[1], stride[1]), \n                              tf.multiply(x_shape[2], stride[2]),\n                              out_dim])\n    if out_dim is None:\n        out_dim = out_shape[-1] \n\n    filter_shape = get_shape2D(filter_size) + [out_dim, in_dim]\n\n    with tf.variable_scope(name) as scope:\n        if wd > 0:\n            regularizer = tf.contrib.layers.l2_regularizer(scale=wd)\n        else:\n            regularizer=None\n        weights = tf.get_variable(\'weights\',\n                                  filter_shape,\n                                  initializer=init_w,\n                                  trainable=trainable,\n                                  regularizer=regularizer)\n        biases = tf.get_variable(\'biases\',\n                                 [out_dim],\n                                 initializer=init_b,\n                                 trainable=trainable)\n        \n        output = tf.nn.conv2d_transpose(inputs,\n                                        weights, \n                                        output_shape=out_shape, \n                                        strides=stride, \n                                        padding=padding, \n                                        name=scope.name)\n        if add_summary:\n            tf.summary.histogram(\n                \'weights/{}\'.format(name), weights, collections = [\'train\'])\n\n        output = tf.nn.bias_add(output, biases)\n        output.set_shape([None, None, None, out_dim])\n        if bn is True:\n            output = batch_norm(output, train=is_training, name=\'bn\')\n        output = nl(output, name=\'output\')\n        layer_dict[\'cur_input\'] = output\n        layer_dict[name] = output\n        return output\n\ndef max_pool(layer_dict,\n             inputs=None,\n             name=\'max_pool\',\n             filter_size=2,\n             stride=None,\n             padding=\'SAME\',\n             switch=False):\n    """""" \n    Max pooling layer \n    Args:\n        x (tf.tensor): a tensor \n        name (str): name scope of the layer\n        filter_size (int or list with length 2): size of filter\n        stride (int or list with length 2): Default to be the same as shape\n        padding (str): \'VALID\' or \'SAME\'. Use \'SAME\' for FCN.\n    Returns:\n        tf.tensor with name \'name\'\n    """"""\n    if inputs is not None:\n        layer_dict[\'cur_input\'] = inputs\n    padding = padding.upper()\n    filter_shape = get_shape4D(filter_size)\n    if stride is None:\n        stride = filter_shape\n    else:\n        stride = get_shape4D(stride)\n\n    if switch == True:\n        layer_dict[\'cur_input\'], switch_s = tf.nn.max_pool_with_argmax(\n            layer_dict[\'cur_input\'],\n            ksize=filter_shape, \n            strides=stride, \n            padding=padding,\n            Targmax=tf.int64,\n            name=name)\n        return layer_dict[\'cur_input\'], switch_s\n    else:\n        layer_dict[\'cur_input\'] = tf.nn.max_pool(\n            layer_dict[\'cur_input\'],\n            ksize=filter_shape, \n            strides=stride, \n            padding=padding,\n            name=name)\n        return layer_dict[\'cur_input\'], None\n\n@add_arg_scope\ndef conv(filter_size,\n         out_dim,\n         layer_dict,\n         inputs=None,\n         pretrained_dict=None,\n         stride=1,\n         dilations=[1, 1, 1, 1],\n         bn=False,\n         nl=tf.identity,\n         init_w=None,\n         init_b=tf.zeros_initializer(),\n         use_bias=True,\n         padding=\'SAME\',\n         pad_type=\'ZERO\',\n         trainable=True,\n         is_training=None,\n         wd=0,\n         name=\'conv\',\n         add_summary=False):\n    if inputs is None:\n        inputs = layer_dict[\'cur_input\']\n    stride = get_shape4D(stride)\n    in_dim = inputs.get_shape().as_list()[-1]\n    filter_shape = get_shape2D(filter_size) + [in_dim, out_dim]\n\n    if padding == \'SAME\' and pad_type == \'REFLECT\':\n        pad_size_1 = int((filter_shape[0] - 1) / 2)\n        pad_size_2 = int((filter_shape[1] - 1) / 2)\n        inputs = tf.pad(\n            inputs,\n            [[0, 0], [pad_size_1, pad_size_1], [pad_size_2, pad_size_2], [0, 0]],\n            ""REFLECT"")\n        padding = \'VALID\'\n\n    with tf.variable_scope(name):\n        if wd > 0:\n            regularizer = tf.contrib.layers.l2_regularizer(scale=wd)\n        else:\n            regularizer=None\n\n        if pretrained_dict is not None and name in pretrained_dict:\n            try:\n                load_w = pretrained_dict[name][0]\n            except KeyError:\n                load_w = pretrained_dict[name][\'weights\']\n            print(\'Load {} weights!\'.format(name))\n\n            load_w = np.reshape(load_w, filter_shape)\n            init_w = tf.constant_initializer(load_w)\n\n        weights = tf.get_variable(\'weights\',\n                                  filter_shape,\n                                  initializer=init_w,\n                                  trainable=trainable,\n                                  regularizer=regularizer)\n        if add_summary:\n            tf.summary.histogram(\n                \'weights/{}\'.format(name), weights, collections = [\'train\'])\n\n        outputs = tf.nn.conv2d(inputs,\n                               filter=weights,\n                               strides=stride,\n                               padding=padding,\n                               use_cudnn_on_gpu=True,\n                               data_format=""NHWC"",\n                               dilations=dilations,\n                               name=\'conv2d\')\n\n        if use_bias:\n            if pretrained_dict is not None and name in pretrained_dict:\n                try:\n                    load_b = pretrained_dict[name][1]\n                except KeyError:\n                    load_b = pretrained_dict[name][\'biases\']\n                print(\'Load {} biases!\'.format(name))\n\n                load_b = np.reshape(load_b, [out_dim])\n                init_b = tf.constant_initializer(load_b)\n\n            biases = tf.get_variable(\'biases\',\n                                 [out_dim],\n                                 initializer=init_b,\n                                 trainable=trainable)\n            outputs += biases\n\n        if bn is True:\n            outputs = batch_norm(outputs, train=is_training, name=\'bn\')\n\n        layer_dict[\'cur_input\'] = nl(outputs)\n        layer_dict[name] = layer_dict[\'cur_input\']\n        return layer_dict[\'cur_input\']\n\ndef drop_out(layer_dict, is_training, inputs=None, keep_prob=0.5):\n    if inputs is None:\n        inputs = layer_dict[\'cur_input\']\n    if is_training:\n        layer_dict[\'cur_input\'] = tf.nn.dropout(inputs, keep_prob=keep_prob)\n    else:\n        layer_dict[\'cur_input\'] = inputs\n    return layer_dict[\'cur_input\']\n\ndef global_avg_pool(x, name=\'global_avg_pool\', data_format=\'NHWC\', keepdims=None):\n    assert x.shape.ndims == 4\n    assert data_format in [\'NHWC\', \'NCHW\']\n    with tf.name_scope(name):\n        axis = [1, 2] if data_format == \'NHWC\' else [2, 3]\n        return tf.reduce_mean(x, axis, keepdims=keepdims)\n\n'"
src/nets/__init__.py,0,b''
src/nets/base.py,6,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# File: base.py\n# Author: Qian Ge <geqian1001@gmail.com>\n\nimport tensorflow as tf\nfrom abc import abstractmethod\n\n\nclass BaseModel(object):\n    """""" Base model """"""\n\n    def set_is_training(self, is_training=True):\n        self.is_training = is_training\n\n    def get_loss(self):\n        try:\n            return self._loss\n        except AttributeError:\n            self._loss = self._get_loss()\n        return self._loss\n\n    def _get_loss(self):\n        raise NotImplementedError()\n\n    def get_optimizer(self):\n        try:\n            return self._opt\n        except AttributeError:\n            self._opt = self._get_optimizer()\n        return self._opt\n\n    def _get_optimizer(self):\n        raise NotImplementedError()\n\n    def get_train_op(self, moniter=False):\n        with tf.name_scope(\'train\'):\n            opt = self.get_optimizer()\n            loss = self.get_loss()\n            var_list = tf.trainable_variables()\n            grads = tf.gradients(loss, var_list)\n            if moniter:\n                [tf.summary.histogram(\'generator_gradient/\' + var.name, grad, \n                    collections=[\'train\']) for grad, var in zip(grads, var_list)]\n\n            update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n            with tf.control_dependencies(update_ops):\n                train_op = opt.apply_gradients(zip(grads, var_list))\n            return train_op\n'"
src/nets/googlenet.py,31,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# File: googlenet.py\n# Author: Qian Ge <geqian1001@gmail.com>\n\nimport numpy as np\nimport tensorflow as tf\n\nfrom src.nets.base import BaseModel\nimport src.models.layers as L\nimport src.models.inception_module as module\n\n\nINIT_W = tf.keras.initializers.he_normal()\n\nclass GoogLeNet(BaseModel):\n    """""" base model of GoogleNet for image classification """"""\n\n    def __init__(self, n_channel, n_class, pre_trained_path=None,\n                 bn=False, wd=0, conv_trainable=True, fc_trainable=True,\n                 sub_imagenet_mean=True):\n        self._n_channel = n_channel\n        self.n_class = n_class\n        self._bn = bn\n        self._wd = wd\n        self._conv_trainable = conv_trainable\n        self._fc_trainable = fc_trainable\n        self._sub_imagenet_mean = sub_imagenet_mean\n\n        self._pretrained_dict = None\n        if pre_trained_path:\n            self._pretrained_dict = np.load(\n                pre_trained_path, encoding=\'latin1\', allow_pickle=True).item()\n\n        self.layers = {}\n\n    def _create_train_input(self):\n        self.image = tf.placeholder(\n            tf.float32, [None, None, None, self._n_channel], name=\'image\')\n        self.label = tf.placeholder(tf.int64, [None], \'label\')\n        self.keep_prob = tf.placeholder(tf.float32, name=\'keep_prob\')\n        self.lr = tf.placeholder(tf.float32, name=\'lr\')\n\n    def _create_test_input(self):\n        self.image = tf.placeholder(\n            tf.float32, [None, None, None, self._n_channel], name=\'image\')\n        self.label = tf.placeholder(tf.int64, [None], \'label\')\n        self.keep_prob = 1.\n\n    def create_train_model(self):\n        self.set_is_training(is_training=True)\n        self._create_train_input()\n        if self._sub_imagenet_mean:\n            net_input = module.sub_rgb2bgr_mean(self.image)\n        else:\n            net_input = self.image\n\n        with tf.variable_scope(\'conv_layers\', reuse=tf.AUTO_REUSE):\n            self.layers[\'conv_out\'] = self._conv_layers(net_input)\n        with tf.variable_scope(\'inception_layers\', reuse=tf.AUTO_REUSE):\n            self.layers[\'inception_out\'] = self._inception_layers(self.layers[\'conv_out\'])\n        with tf.variable_scope(\'fc_layers\', reuse=tf.AUTO_REUSE):   \n            self.layers[\'logits\'] = self._fc_layers(self.layers[\'inception_out\'])\n\n        with tf.variable_scope(\'auxiliary_classifier_0\'):\n            self.layers[\'auxiliary_logits_0\'] = self._auxiliary_classifier(\n                self.layers[\'inception_4a\'])\n        with tf.variable_scope(\'auxiliary_classifier_1\'):\n            self.layers[\'auxiliary_logits_1\'] = self._auxiliary_classifier(\n                self.layers[\'inception_4d\'])\n\n    def create_test_model(self):\n        self.set_is_training(is_training=False)\n        self._create_test_input()\n        if self._sub_imagenet_mean:\n            net_input = module.sub_rgb2bgr_mean(self.image)\n        else:\n            net_input = self.image\n\n        with tf.variable_scope(\'conv_layers\', reuse=tf.AUTO_REUSE):\n            self.layers[\'conv_out\'] = self._conv_layers(net_input)\n        with tf.variable_scope(\'inception_layers\', reuse=tf.AUTO_REUSE):\n            self.layers[\'inception_out\'] = self._inception_layers(self.layers[\'conv_out\'])\n        with tf.variable_scope(\'fc_layers\', reuse=tf.AUTO_REUSE):   \n            self.layers[\'logits\'] = self._fc_layers(self.layers[\'inception_out\'])\n            self.layers[\'top_5\'] = tf.nn.top_k(\n                tf.nn.softmax(self.layers[\'logits\']), k=5, sorted=True)\n\n    def _conv_layers(self, inputs):\n        conv_out = module.inception_conv_layers(\n            layer_dict=self.layers, inputs=inputs,\n            pretrained_dict=self._pretrained_dict,\n            bn=self._bn, wd=self._wd, init_w=INIT_W,\n            is_training=self.is_training, trainable=self._conv_trainable)\n        return conv_out\n\n    def _inception_layers(self, inputs):\n        inception_out = module.inception_layers(\n            layer_dict=self.layers, inputs=inputs,\n            pretrained_dict=self._pretrained_dict,\n            bn=self._bn, wd=self._wd, init_w=INIT_W,\n            is_training=self.is_training, trainable=self._conv_trainable)\n        return inception_out\n\n    def _fc_layers(self, inputs):\n        fc_out = module.inception_fc(\n            layer_dict=self.layers, n_class=self.n_class, keep_prob=self.keep_prob,\n            inputs=inputs, pretrained_dict=self._pretrained_dict,\n            bn=self._bn, init_w=INIT_W, trainable=self._fc_trainable,\n            is_training=self.is_training, wd=self._wd)\n        return fc_out\n\n    def _auxiliary_classifier(self, inputs):\n        logits = module.auxiliary_classifier(\n            layer_dict=self.layers, n_class=self.n_class, keep_prob=self.keep_prob,\n            inputs=inputs, pretrained_dict=None, is_training=self.is_training,\n            bn=self._bn, init_w=INIT_W, trainable=self._fc_trainable, wd=self._wd)\n        return logits\n\n    def _get_loss(self):\n        with tf.name_scope(\'loss\'):\n            labels = self.label\n            logits = self.layers[\'logits\']\n            cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n                labels=labels,\n                logits=logits,\n                name=\'cross_entropy\')\n            cross_entropy = tf.reduce_mean(cross_entropy)\n        if self.is_training:\n            auxilarity_loss = self._get_auxiliary_loss(0) + self._get_auxiliary_loss(1)\n            return cross_entropy + 0.3 * auxilarity_loss\n        else:\n            return cross_entropy\n\n    def _get_auxiliary_loss(self, loss_id):\n        with tf.name_scope(\'auxilarity_loss_{}\'.format(loss_id)):\n            labels = self.label\n            logits = self.layers[\'auxiliary_logits_{}\'.format(loss_id)]\n            cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n                labels=labels,\n                logits=logits,\n                name=\'cross_entropy\')\n        return tf.reduce_mean(cross_entropy)\n\n    def _get_optimizer(self):\n        return tf.train.AdamOptimizer(self.lr)\n\n    def get_accuracy(self):\n        with tf.name_scope(\'accuracy\'):\n            prediction = tf.argmax(self.layers[\'logits\'], axis=1)\n            correct_prediction = tf.equal(prediction, self.label)\n            return tf.reduce_mean(\n                tf.cast(correct_prediction, tf.float32), \n                name = \'result\')\n\nclass GoogLeNet_cifar(GoogLeNet):\n    def _fc_layers(self, inputs):\n        fc_out = module.inception_fc(\n            layer_dict=self.layers, n_class=self.n_class, keep_prob=self.keep_prob,\n            inputs=inputs, pretrained_dict=None,\n            bn=self._bn, init_w=INIT_W, trainable=self._fc_trainable,\n            is_training=self.is_training, wd=self._wd)\n        return fc_out\n\n    def _conv_layers(self, inputs):\n        conv_out = module.inception_conv_layers_cifar(\n            layer_dict=self.layers, inputs=inputs,\n            pretrained_dict=None,\n            bn=self._bn, wd=self._wd, init_w=INIT_W,\n            is_training=self.is_training, trainable=self._conv_trainable,\n            conv_stride=1)\n        return conv_out\n\n'"
src/utils/__init__.py,0,b''
src/utils/dataflow.py,0,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# File: dataflow.py\n# Author: Qian Ge <geqian1001@gmail.com>\n\nimport os\nimport imageio\nimport numpy as np\nfrom datetime import datetime\n\nimport src.utils.utils as utils\n\n\ndef identity(inputs):\n    return inputs\n\ndef load_image(im_path, read_channel=None, pf=identity):\n    if read_channel is None:\n        im = scipy.misc.imread(im_path)\n    elif read_channel == 3:\n        im = imageio.imread(im_path, pilmode=\'RGB\')\n    else:\n        im = imageio.imread(im_path, flatten=True)\n\n    if len(im.shape) < 3:\n        im = pf(im)\n        im = np.reshape(im, [im.shape[0], im.shape[1], 1])\n    else:\n        im = pf(im)\n    return im\n\n\n_RNG_SEED = None\n\ndef get_rng(obj=None):\n    """"""\n    This function is copied from `tensorpack\n    <https://github.com/ppwwyyxx/tensorpack/blob/master/tensorpack/utils/utils.py>`__.\n    Get a good RNG seeded with time, pid and the object.\n    Args:\n        obj: some object to use to generate random seed.\n    Returns:\n        np.random.RandomState: the RNG.\n    """"""\n    seed = (id(obj) + os.getpid() +\n            int(datetime.now().strftime(""%Y%m%d%H%M%S%f""))) % 4294967295\n    if _RNG_SEED is not None:\n        seed = _RNG_SEED\n    return np.random.RandomState(seed)\n\n\ndef get_file_list(file_dir, file_ext, sub_name=None):\n    re_list = []\n\n    if sub_name is None:\n        return np.array([os.path.join(root, name)\n            for root, dirs, files in os.walk(file_dir) \n            for name in sorted(files) if name.endswith(file_ext)])\n    else:\n        return np.array([os.path.join(root, name)\n            for root, dirs, files in os.walk(file_dir) \n            for name in sorted(files) if name.endswith(file_ext) and sub_name in name])\n\ndef fill_pf_list(pf_list, n_pf, fill_with_fnc=identity):\n    if pf_list == None:\n        return [identity for i in range(n_pf)]\n    # pf_list = [pf for pf in pf_list if pf is not None else identity]\n    pf_list = utils.make_list(pf_list)\n\n    new_list = []\n    for pf in pf_list:\n        if not pf:\n            pf = identity\n        new_list.append(pf)\n    pf_list = new_list\n    \n    if len(pf_list) > n_pf:\n        raise ValueError(\'Invalid number of preprocessing functions\')\n    pf_list = pf_list + [fill_with_fnc for i in range(n_pf - len(pf_list))]\n    return pf_list\n'"
src/utils/utils.py,0,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# File: utils.py\n# Author: Qian Ge <geqian1001@gmail.com>\n\n\ndef make_list(inputs):\n    if not isinstance(inputs, list):\n        return [inputs]\n    else:\n        return inputs\n\ndef assert_len(check_list):\n    for ele in check_list[1:]:\n        assert len(check_list[0]) == len(ele)'"
