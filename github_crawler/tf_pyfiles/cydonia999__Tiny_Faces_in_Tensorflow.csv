file_path,api_count,code
matconvnet_hr101_to_pickle.py,1,"b'# -*- coding: utf-8 -*-\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nimport scipy.io as sio\nimport os\nimport pickle\nfrom argparse import ArgumentParser\n\nargparse = ArgumentParser()\nargparse.add_argument(\'--matlab_model_path\', type=str, help=\'Matlab pretrained model.\',\n                      default=\'/path/to/hr_res101.mat\')\nargparse.add_argument(\'--weight_file_path\', type=str, help=\'Weight file for Tensorflow.\',\n                      default=\'/path/to/mat2tf.pkl\')\n\nargs = argparse.parse_args()\n\n# check arguments\nassert os.path.exists(args.matlab_model_path), \\\n    ""Matlab pretrained model: "" + args.matlab_model_path + "" not found.""\nassert os.path.exists(os.path.dirname((args.weight_file_path))),\\\n    ""Directory for weight file for Tensorflow: "" + args.weight_file_path + "" not found.""\n\nmat_params_dict = {}\nmat_blocks_dict = {}\n\nf = sio.loadmat(args.matlab_model_path)\nnet = f[\'net\']\nclusters = np.copy(net[\'meta\'][0][0][0][0][6])\naverage_image = np.copy(net[\'meta\'][0][0][0][0][2][0][0][2])[:, 0]\nmat_params_dict[""clusters""] = clusters\nmat_params_dict[""average_image""] = average_image\n\nlayers = net[\'layers\'][0][0][0]\nmat_params = net[\'params\'][0][0][0]\nfor p in mat_params:\n    mat_params_dict[p[0][0]] = p[1]\n\nfor k, layer in enumerate(layers):\n    type_string = \'\'\n    param_string = \'\'\n\n    layer_name, layer_type = layer[0][0], layer[1][0]\n    layer_inputs = []\n    layer_outputs = []\n    layer_params = []\n\n    layer_inputs_count = layer[2][0].shape[0]\n    for i in range(layer_inputs_count):\n        layer_inputs.append(layer[2][0][i][0])\n\n    layer_outputs_count = layer[3][0].shape[0]\n    for i in range(layer_outputs_count):\n        layer_outputs.append(layer[3][0][i][0])\n\n    if layer[4].shape[0] > 0:\n        layer_params_count = layer[4][0].shape[0]\n        for i in range(layer_params_count):\n            layer_params.append(layer[4][0][i][0])\n\n    mat_blocks_dict[layer_name + \'_type\'] = layer_type\n    mat_params_dict[layer_name + \'_type\'] = layer_type\n    if layer_type == u\'dagnn.Conv\':\n        nchw = layer[5][0][0][0][0]\n        has_bias = layer[5][0][0][1][0][0]\n        pad = layer[5][0][0][3][0]\n        stride = layer[5][0][0][4][0]\n        dilate = layer[5][0][0][5][0]\n        mat_blocks_dict[layer_name + \'_nchw\'] = nchw\n        mat_blocks_dict[layer_name + \'_has_bias\'] = has_bias\n        mat_blocks_dict[layer_name + \'_pad\'] = pad\n        mat_blocks_dict[layer_name + \'_stride\'] = stride\n        mat_blocks_dict[layer_name + \'_dilate\'] = dilate\n        if has_bias:\n            bias = mat_params_dict[layer_name + \'_bias\'][0] # (1, N) -> (N,)\n            mat_params_dict[layer_name + \'_bias\'] = bias\n    elif layer_type == u\'dagnn.BatchNorm\':\n        epsilon = layer[5][0][0][1][0][0]\n        gamma = mat_params_dict[layer_name + \'_mult\'][:, 0] # (N, 1) -> (N,)\n        beta = mat_params_dict[layer_name + \'_bias\'][:, 0] # (N, 1) -> (N,)\n        moments = mat_params_dict[layer_name + \'_moments\'] # (N, 2) -> (N,), (N,)\n        moving_mean = moments[:, 0]\n        moving_var = moments[:, 1] * moments[:, 1] - epsilon\n\n        mat_blocks_dict[layer_name + \'_variance_epsilon\'] = epsilon\n        mat_params_dict[layer_name + \'_scale\'] = gamma\n        mat_params_dict[layer_name + \'_offset\'] = beta\n        mat_params_dict[layer_name + \'_mean\'] = moving_mean\n        mat_params_dict[layer_name + \'_variance\'] = moving_var\n    elif layer_type == u\'dagnn.ConvTranspose\':\n        nchw = layer[5][0][0][0][0]\n        has_bias = layer[5][0][0][1][0][0]\n        upsample = layer[5][0][0][2][0]\n        crop = layer[5][0][0][3][0]\n        mat_blocks_dict[layer_name + \'_nchw\'] = nchw\n        mat_blocks_dict[layer_name + \'_has_bias\'] = has_bias\n        mat_blocks_dict[layer_name + \'_upsample\'] = upsample\n        mat_blocks_dict[layer_name + \'_crop\'] = crop\n        wmat = mat_params_dict[layer_name + \'f\']\n        mat_params_dict[layer_name + \'_filter\'] = wmat\n    elif layer_type == u\'dagnn.Pooling\':\n        method = layer[5][0][0][0][0]\n        pool_size = layer[5][0][0][1][0]\n        pad = layer[5][0][0][3][0]\n        stride = layer[5][0][0][4][0]\n        mat_blocks_dict[layer_name + \'_method\'] = method\n        mat_blocks_dict[layer_name + \'_pool_size\'] = pool_size\n        mat_blocks_dict[layer_name + \'_pad\'] = pad\n        mat_blocks_dict[layer_name + \'_stride\'] = stride\n    elif layer_type == u\'dagnn.ReLU\':\n        pass\n    elif layer_type == u\'dagnn.Sum\':\n        pass\n    else:\n        pass\n\nwith open(args.weight_file_path, \'wb\') as f:\n    pickle.dump([mat_blocks_dict, mat_params_dict], f, pickle.HIGHEST_PROTOCOL)\n'"
tiny_face_eval.py,8,"b'# -*- coding: utf-8 -*-\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\nimport tiny_face_model\nimport util\nfrom argparse import ArgumentParser\nimport cv2\nimport scipy.io\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\nimport pickle\n\nimport pylab as pl\nimport time\nimport os\nimport sys\nfrom scipy.special import expit\nimport glob\n\nMAX_INPUT_DIM = 5000.0\n\ndef overlay_bounding_boxes(raw_img, refined_bboxes, lw):\n  """"""Overlay bounding boxes of face on images.\n    Args:\n      raw_img:\n        A target image.\n      refined_bboxes:\n        Bounding boxes of detected faces.\n      lw: \n        Line width of bounding boxes. If zero specified,\n        this is determined based on confidence of each detection.\n    Returns:\n      None.\n  """"""\n\n  # Overlay bounding boxes on an image with the color based on the confidence.\n  for r in refined_bboxes:\n    _score = expit(r[4])\n    cm_idx = int(np.ceil(_score * 255))\n    rect_color = [int(np.ceil(x * 255)) for x in util.cm_data[cm_idx]]  # parula\n    _lw = lw\n    if lw == 0:  # line width of each bounding box is adaptively determined.\n      bw, bh = r[2] - r[0] + 1, r[3] - r[0] + 1\n      _lw = 1 if min(bw, bh) <= 20 else max(2, min(3, min(bh / 20, bw / 20)))\n      _lw = int(np.ceil(_lw * _score))\n\n    _r = [int(x) for x in r[:4]]\n    cv2.rectangle(raw_img, (_r[0], _r[1]), (_r[2], _r[3]), rect_color, _lw)\n    \n    \ndef evaluate(weight_file_path, data_dir, output_dir, prob_thresh=0.5, nms_thresh=0.1, lw=3, display=False):\n  """"""Detect faces in images.\n  Args:\n    prob_thresh:\n        The threshold of detection confidence.\n    nms_thresh:\n        The overlap threshold of non maximum suppression\n    weight_file_path: \n        A pretrained weight file in the pickle format \n        generated by matconvnet_hr101_to_tf.py.\n    data_dir: \n        A directory which contains images.\n    output_dir: \n        A directory into which images with detected faces are output.\n    lw: \n        Line width of bounding boxes. If zero specified,\n        this is determined based on confidence of each detection.\n    display:\n        Display tiny face images on window.\n  Returns:\n    None.\n  """"""\n\n  # placeholder of input images. Currently batch size of one is supported.\n  x = tf.placeholder(tf.float32, [1, None, None, 3]) # n, h, w, c\n\n  # Create the tiny face model which weights are loaded from a pretrained model.\n  model = tiny_face_model.Model(weight_file_path)\n  score_final = model.tiny_face(x)\n\n  # Find image files in data_dir.\n  filenames = []\n  for ext in (\'*.png\', \'*.gif\', \'*.jpg\', \'*.jpeg\'):\n    filenames.extend(glob.glob(os.path.join(data_dir, ext)))\n\n  # Load an average image and clusters(reference boxes of templates).\n  with open(weight_file_path, ""rb"") as f:\n    _, mat_params_dict = pickle.load(f)\n\n  average_image = model.get_data_by_key(""average_image"")\n  clusters = model.get_data_by_key(""clusters"")\n  clusters_h = clusters[:, 3] - clusters[:, 1] + 1\n  clusters_w = clusters[:, 2] - clusters[:, 0] + 1\n  normal_idx = np.where(clusters[:, 4] == 1)\n\n  # main\n  with tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n\n    for filename in filenames:\n      fname = filename.split(os.sep)[-1]\n      raw_img = cv2.imread(filename)\n      raw_img = cv2.cvtColor(raw_img, cv2.COLOR_BGR2RGB)\n      raw_img_f = raw_img.astype(np.float32)\n\n      def _calc_scales():\n        raw_h, raw_w = raw_img.shape[0], raw_img.shape[1]\n        min_scale = min(np.floor(np.log2(np.max(clusters_w[normal_idx] / raw_w))),\n                        np.floor(np.log2(np.max(clusters_h[normal_idx] / raw_h))))\n        max_scale = min(1.0, -np.log2(max(raw_h, raw_w) / MAX_INPUT_DIM))\n        scales_down = pl.frange(min_scale, 0, 1.)\n        scales_up = pl.frange(0.5, max_scale, 0.5)\n        scales_pow = np.hstack((scales_down, scales_up))\n        scales = np.power(2.0, scales_pow)\n        return scales\n\n      scales = _calc_scales()\n      start = time.time()\n\n      # initialize output\n      bboxes = np.empty(shape=(0, 5))\n\n      # process input at different scales\n      for s in scales:\n        print(""Processing {} at scale {:.4f}"".format(fname, s))\n        img = cv2.resize(raw_img_f, (0, 0), fx=s, fy=s, interpolation=cv2.INTER_LINEAR)\n        img = img - average_image\n        img = img[np.newaxis, :]\n\n        # we don\'t run every template on every scale ids of templates to ignore\n        tids = list(range(4, 12)) + ([] if s <= 1.0 else list(range(18, 25)))\n        ignoredTids = list(set(range(0, clusters.shape[0])) - set(tids))\n\n        # run through the net\n        score_final_tf = sess.run(score_final, feed_dict={x: img})\n\n        # collect scores\n        score_cls_tf, score_reg_tf = score_final_tf[:, :, :, :25], score_final_tf[:, :, :, 25:125]\n        prob_cls_tf = expit(score_cls_tf)\n        prob_cls_tf[0, :, :, ignoredTids] = 0.0\n\n        def _calc_bounding_boxes():\n          # threshold for detection\n          _, fy, fx, fc = np.where(prob_cls_tf > prob_thresh)\n\n          # interpret heatmap into bounding boxes\n          cy = fy * 8 - 1\n          cx = fx * 8 - 1\n          ch = clusters[fc, 3] - clusters[fc, 1] + 1\n          cw = clusters[fc, 2] - clusters[fc, 0] + 1\n\n          # extract bounding box refinement\n          Nt = clusters.shape[0]\n          tx = score_reg_tf[0, :, :, 0:Nt]\n          ty = score_reg_tf[0, :, :, Nt:2*Nt]\n          tw = score_reg_tf[0, :, :, 2*Nt:3*Nt]\n          th = score_reg_tf[0, :, :, 3*Nt:4*Nt]\n\n          # refine bounding boxes\n          dcx = cw * tx[fy, fx, fc]\n          dcy = ch * ty[fy, fx, fc]\n          rcx = cx + dcx\n          rcy = cy + dcy\n          rcw = cw * np.exp(tw[fy, fx, fc])\n          rch = ch * np.exp(th[fy, fx, fc])\n\n          scores = score_cls_tf[0, fy, fx, fc]\n          tmp_bboxes = np.vstack((rcx - rcw / 2, rcy - rch / 2, rcx + rcw / 2, rcy + rch / 2))\n          tmp_bboxes = np.vstack((tmp_bboxes / s, scores))\n          tmp_bboxes = tmp_bboxes.transpose()\n          return tmp_bboxes\n\n        tmp_bboxes = _calc_bounding_boxes()\n        bboxes = np.vstack((bboxes, tmp_bboxes)) # <class \'tuple\'>: (5265, 5)\n\n\n      print(""time {:.2f} secs for {}"".format(time.time() - start, fname))\n\n      # non maximum suppression\n      # refind_idx = util.nms(bboxes, nms_thresh)\n      refind_idx = tf.image.non_max_suppression(tf.convert_to_tensor(bboxes[:, :4], dtype=tf.float32),\n                                                   tf.convert_to_tensor(bboxes[:, 4], dtype=tf.float32),\n                                                   max_output_size=bboxes.shape[0], iou_threshold=nms_thresh)\n      refind_idx = sess.run(refind_idx)\n      refined_bboxes = bboxes[refind_idx]\n      overlay_bounding_boxes(raw_img, refined_bboxes, lw)\n\n      if display:\n        # plt.axis(\'off\')\n        plt.imshow(raw_img)\n        plt.show()\n\n      # save image with bounding boxes\n      raw_img = cv2.cvtColor(raw_img, cv2.COLOR_RGB2BGR)\n      cv2.imwrite(os.path.join(output_dir, fname), raw_img)\n\ndef main():\n\n  argparse = ArgumentParser()\n  argparse.add_argument(\'--weight_file_path\', type=str, help=\'Pretrained weight file.\', default=""/path/to/mat2tf.pkl"")\n  argparse.add_argument(\'--data_dir\', type=str, help=\'Image data directory.\', default=""/path/to/input_image_directory"")\n  argparse.add_argument(\'--output_dir\', type=str, help=\'Output directory for images with faces detected.\', default=""/path/to/output_directory"")\n  argparse.add_argument(\'--prob_thresh\', type=float, help=\'The threshold of detection confidence(default: 0.5).\', default=0.5)\n  argparse.add_argument(\'--nms_thresh\', type=float, help=\'The overlap threshold of non maximum suppression(default: 0.1).\', default=0.1)\n  argparse.add_argument(\'--line_width\', type=int, help=\'Line width of bounding boxes(0: auto).\', default=3)\n  argparse.add_argument(\'--display\', type=bool, help=\'Display each image on window.\', default=False)\n\n  args = argparse.parse_args()\n\n  # check arguments\n  assert os.path.exists(args.weight_file_path), ""weight file: "" + args.weight_file_path + "" not found.""\n  assert os.path.exists(args.data_dir), ""data directory: "" + args.data_dir + "" not found.""\n  assert os.path.exists(args.output_dir), ""output directory: "" + args.output_dir + "" not found.""\n  assert args.line_width >= 0, ""line_width should be >= 0.""\n\n  with tf.Graph().as_default():\n    evaluate(\n      weight_file_path=args.weight_file_path, data_dir=args.data_dir, output_dir=args.output_dir,\n      prob_thresh=args.prob_thresh, nms_thresh=args.nms_thresh,\n      lw=args.line_width, display=args.display)\n\nif __name__ == \'__main__\':\n  main()\n'"
tiny_face_model.py,32,"b'# -*- coding: utf-8 -*-\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\nimport numpy as np\nimport pickle\n\nclass Model():\n    def __init__(self, weight_file_path):\n      """"""Overlay bounding boxes of face on images.\n        Args:\n          weight_file_path: \n              A pretrained weight file in the pickle format \n              generated by matconvnet_hr101_to_tf.py.\n        Returns:\n          None.\n      """"""\n      self.dtype = tf.float32\n      self.weight_file_path = weight_file_path\n      with open(self.weight_file_path, ""rb"") as f:\n        self.mat_blocks_dict, self.mat_params_dict = pickle.load(f)\n\n    def get_data_by_key(self, key):\n      """"""Helper to access a pretrained model data through a key.""""""\n      assert key in self.mat_params_dict, ""key: "" + key + "" not found.""\n      return self.mat_params_dict[key]\n\n    def _weight_variable_on_cpu(self, name, shape):\n      """"""Helper to create a weight Variable stored on CPU memory.\n\n      Args:\n        name: name of the variable.\n        shape: list of ints: (height, width, channel, filter).\n\n      Returns:\n        initializer for Variable.\n      """"""\n      assert len(shape) == 4\n\n      weights = self.get_data_by_key(name + ""_filter"")  # (h, w, channel, filter)\n      assert list(weights.shape) == shape\n      initializer = tf.constant_initializer(weights, dtype=self.dtype)\n\n      with tf.device(\'/cpu:0\'):\n        var = tf.get_variable(name + ""_w"", shape, initializer=initializer, dtype=self.dtype)\n      return var\n\n    def _bias_variable_on_cpu(self, name, shape):\n      """"""Helper to create a bias Variable stored on CPU memory.\n\n      Args:\n        name: name of the variable.\n        shape: int, filter size.\n\n      Returns:\n        initializer for Variable.\n      """"""\n      assert isinstance(shape, int)\n      bias = self.get_data_by_key(name + ""_bias"")\n      assert len(bias) == shape\n      initializer = tf.constant_initializer(bias, dtype=self.dtype)\n\n      with tf.device(\'/cpu:0\'):\n        var = tf.get_variable(name + ""_b"", shape, initializer=initializer, dtype=self.dtype)\n      return var\n\n\n    def _bn_variable_on_cpu(self, name, shape):\n      """"""Helper to create a batch normalization Variable stored on CPU memory.\n\n      Args:\n        name: name of the variable.\n        shape: int, filter size.\n\n      Returns:\n        initializer for Variable.\n      """"""\n      assert isinstance(shape, int)\n\n      name2 = ""bn"" + name[3:]\n      if name.startswith(""conv""):\n        name2 = ""bn_"" + name\n\n      scale = self.get_data_by_key(name2 + \'_scale\')\n      offset = self.get_data_by_key(name2 + \'_offset\')\n      mean = self.get_data_by_key(name2 + \'_mean\')\n      variance = self.get_data_by_key(name2 + \'_variance\')\n\n      with tf.device(\'/cpu:0\'):\n        initializer = tf.constant_initializer(scale, dtype=self.dtype)\n        scale = tf.get_variable(name2 + ""_scale"", shape, initializer=initializer, dtype=self.dtype)\n        initializer = tf.constant_initializer(offset, dtype=self.dtype)\n        offset = tf.get_variable(name2 + ""_offset"", shape, initializer=initializer, dtype=self.dtype)\n        initializer = tf.constant_initializer(mean, dtype=self.dtype)\n        mean = tf.get_variable(name2 + ""_mean"", shape, initializer=initializer, dtype=self.dtype)\n        initializer = tf.constant_initializer(variance, dtype=self.dtype)\n        variance = tf.get_variable(name2 + ""_variance"", shape, initializer=initializer, dtype=self.dtype)\n\n      return scale, offset, mean, variance\n\n\n    def conv_block(self, bottom, name, shape, strides=[1,1,1,1], padding=""SAME"",\n                   has_bias=False, add_relu=True, add_bn=True, eps=1.0e-5):\n      """"""Create a block composed of multiple layers:\n            a conv layer\n            a batch normalization layer\n            an activation layer\n\n      Args:\n        bottom: A layer before this block.\n        name: Name of the block.\n        shape: List of ints: (height, width, channel, filter).\n        strides: Strides of conv layer.\n        padding: Padding of conv layer.\n        has_bias: Whether a bias term is added.\n        add_relu: Whether a ReLU layer is added.\n        add_bn: Whether a batch normalization layer is added.\n        eps: A small float number to avoid dividing by 0, used in a batch normalization layer.\n      Returns:\n        a block of layers\n      """"""\n      assert len(shape) == 4\n\n      weight = self._weight_variable_on_cpu(name, shape)\n      conv = tf.nn.conv2d(bottom, weight, strides, padding=padding)\n      if has_bias:\n        bias = self._bias_variable_on_cpu(name, shape[3])\n\n      pre_activation = tf.nn.bias_add(conv, bias) if has_bias else conv\n\n      if add_bn:\n        # scale, offset, mean, variance = self._bn_variable_on_cpu(""bn_"" + name, shape[-1])\n        scale, offset, mean, variance = self._bn_variable_on_cpu(name, shape[-1])\n        pre_activation = tf.nn.batch_normalization(pre_activation, mean, variance, offset, scale, variance_epsilon=eps)\n\n      relu = tf.nn.relu(pre_activation) if add_relu else pre_activation\n\n      return relu\n\n\n    def conv_trans_layer(self, bottom, name, shape, strides=[1,1,1,1], padding=""SAME"", has_bias=False):\n      """"""Create a block composed of multiple layers:\n            a transpose of conv layer\n            an activation layer\n\n      Args:\n        bottom: A layer before this block.\n        name: Name of the block.\n        shape: List of ints: (height, width, channel, filter).\n        strides: Strides of conv layer.\n        padding: Padding of conv layer.\n        has_bias: Whether a bias term is added.\n        add_relu: Whether a ReLU layer is added.\n      Returns:\n        a block of layers\n      """"""\n      assert len(shape) == 4\n\n      weight = self._weight_variable_on_cpu(name, shape)\n      nb, h, w, nc = tf.split(tf.shape(bottom), num_or_size_splits=4)\n      output_shape = tf.stack([nb, (h - 1) * strides[1] - 3 + shape[0], (w - 1) * strides[2] - 3 + shape[1], nc])[:, 0]\n      conv = tf.nn.conv2d_transpose(bottom, weight, output_shape, strides, padding=padding)\n      if has_bias:\n        bias = self._bias_variable_on_cpu(name, shape[3])\n\n      conv = tf.nn.bias_add(conv, bias) if has_bias else conv\n\n      return conv\n\n    def residual_block(self, bottom, name, in_channel, neck_channel, out_channel, trunk):\n      """"""Create a residual block.\n\n      Args:\n        bottom: A layer before this block.\n        name: Name of the block.\n        in_channel: number of channels in a input tensor.\n        neck_channel: number of channels in a bottleneck block.\n        out_channel: number of channels in a output tensor.\n        trunk: a tensor in a identity path.\n      Returns:\n        a block of layers\n      """"""\n      _strides = [1, 2, 2, 1] if name.startswith(""res3a"") or name.startswith(""res4a"") else [1, 1, 1, 1]\n      res = self.conv_block(bottom, name + \'_branch2a\', shape=[1, 1, in_channel, neck_channel],\n                            strides=_strides, padding=""VALID"", add_relu=True)\n      res = self.conv_block(res, name + \'_branch2b\', shape=[3, 3, neck_channel, neck_channel],\n                            padding=""SAME"", add_relu=True)\n      res = self.conv_block(res, name + \'_branch2c\', shape=[1, 1, neck_channel, out_channel],\n                            padding=""VALID"", add_relu=False)\n\n      res = trunk + res\n      res = tf.nn.relu(res)\n\n      return res\n\n    def tiny_face(self, image):\n        """"""Create a tiny face model.\n  \n        Args:\n          image: an input image.\n        Returns:\n          a score tensor\n        """"""\n        img = tf.pad(image, [[0, 0], [3, 3], [3, 3], [0, 0]], ""CONSTANT"")\n        conv = self.conv_block(img, \'conv1\', shape=[7, 7, 3, 64], strides=[1, 2, 2, 1], padding=""VALID"", add_relu=True)\n        pool1 = tf.nn.max_pool(conv, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding=\'SAME\')\n\n        res2a_branch1 = self.conv_block(pool1, \'res2a_branch1\', shape=[1, 1, 64, 256], padding=""VALID"", add_relu=False)\n        res2a = self.residual_block(pool1, \'res2a\', 64, 64, 256, res2a_branch1)\n        res2b = self.residual_block(res2a, \'res2b\', 256, 64, 256, res2a)\n        res2c = self.residual_block(res2b, \'res2c\', 256, 64, 256, res2b)\n\n        res3a_branch1 = self.conv_block(res2c, \'res3a_branch1\', shape=[1, 1, 256, 512], strides=[1, 2, 2, 1], padding=""VALID"", add_relu=False)\n        res3a = self.residual_block(res2c, \'res3a\', 256, 128, 512, res3a_branch1)\n\n        res3b1 = self.residual_block(res3a, \'res3b1\', 512, 128, 512, res3a)\n        res3b2 = self.residual_block(res3b1, \'res3b2\', 512, 128, 512, res3b1)\n        res3b3 = self.residual_block(res3b2, \'res3b3\', 512, 128, 512, res3b2)\n\n        res4a_branch1 = self.conv_block(res3b3, \'res4a_branch1\', shape=[1, 1, 512, 1024], strides=[1, 2, 2, 1], padding=""VALID"", add_relu=False)\n        res4a = self.residual_block(res3b3, \'res4a\', 512, 256, 1024, res4a_branch1)\n\n        res4b = res4a\n        for i in range(1, 23):\n          res4b = self.residual_block(res4b, \'res4b\' + str(i), 1024, 256, 1024, res4b)\n\n        score_res4 = self.conv_block(res4b, \'score_res4\', shape=[1, 1, 1024, 125], padding=""VALID"",\n                                     has_bias=True, add_relu=False, add_bn=False)\n        score4 = self.conv_trans_layer(score_res4, \'score4\', shape=[4, 4, 125, 125], strides=[1, 2, 2, 1], padding=""SAME"")\n        score_res3 = self.conv_block(res3b3, \'score_res3\', shape=[1, 1, 512, 125], padding=""VALID"",\n                                     has_bias=True, add_bn=False, add_relu=False)\n\n        bs, height, width = tf.split(tf.shape(score4), num_or_size_splits=4)[0:3]\n        _size = tf.convert_to_tensor([height[0], width[0]])\n        _offsets = tf.zeros([bs[0], 2])\n        score_res3c = tf.image.extract_glimpse(score_res3, _size, _offsets, centered=True, normalized=False)\n\n        score_final = score4 + score_res3c\n        return score_final\n'"
util.py,0,"b'# -*- coding: utf-8 -*-\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\n\ndef nms(dets, prob_thresh):\n    x1 = dets[:, 0]\n    y1 = dets[:, 1]\n    x2 = dets[:, 2]\n    y2 = dets[:, 3]\n    scores = dets[:, 4]\n\n    areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n\n    order = scores.argsort()[::-1]\n\n    keep = []\n    while order.size > 0:\n        i = order[0]\n        keep.append(i)\n        xx1 = np.maximum(x1[i], x1[order[1:]])\n        yy1 = np.maximum(y1[i], y1[order[1:]])\n        xx2 = np.minimum(x2[i], x2[order[1:]])\n        yy2 = np.minimum(y2[i], y2[order[1:]])\n        w = np.maximum(0.0, xx2 - xx1 + 1)\n        h = np.maximum(0.0, yy2 - yy1 + 1)\n        inter = w * h\n\n        ovr = inter / (areas[i] + areas[order[1:]] - inter)\n        inds = np.where(ovr <= prob_thresh)[0]\n\n        order = order[inds + 1]\n    return keep\n\n# colormap parula borrowed from\n# https://github.com/BIDS/colormap/blob/master/fake_parula.py\ncm_data = [[ 0.26710521,  0.03311059,  0.6188155 ],\n       [ 0.26493929,  0.04780926,  0.62261795],\n       [ 0.26260545,  0.06084214,  0.62619176],\n       [ 0.26009691,  0.07264411,  0.62951561],\n       [ 0.25740785,  0.08360391,  0.63256745],\n       [ 0.25453369,  0.09395358,  0.63532497],\n       [ 0.25147146,  0.10384228,  0.6377661 ],\n       [ 0.24822014,  0.11337029,  0.6398697 ],\n       [ 0.24478105,  0.12260661,  0.64161629],\n       [ 0.24115816,  0.131599  ,  0.6429888 ],\n       [ 0.23735836,  0.14038009,  0.64397346],\n       [ 0.23339166,  0.14897137,  0.64456048],\n       [ 0.22927127,  0.15738602,  0.64474476],\n       [ 0.22501278,  0.16563165,  0.64452595],\n       [ 0.22063349,  0.17371215,  0.64390834],\n       [ 0.21616055,  0.18162302,  0.64290515],\n       [ 0.21161851,  0.18936156,  0.64153295],\n       [ 0.20703353,  0.19692415,  0.63981287],\n       [ 0.20243273,  0.20430706,  0.63776986],\n       [ 0.19784363,  0.211507  ,  0.63543183],\n       [ 0.19329361,  0.21852157,  0.63282872],\n       [ 0.18880937,  0.2253495 ,  0.62999156],\n       [ 0.18442119,  0.23198815,  0.62695569],\n       [ 0.18014936,  0.23844124,  0.62374886],\n       [ 0.17601569,  0.24471172,  0.62040016],\n       [ 0.17204028,  0.25080356,  0.61693715],\n       [ 0.16824123,  0.25672163,  0.6133854 ],\n       [ 0.16463462,  0.26247158,  0.60976836],\n       [ 0.16123449,  0.26805963,  0.60610723],\n       [ 0.15805279,  0.27349243,  0.60242099],\n       [ 0.15509948,  0.27877688,  0.59872645],\n       [ 0.15238249,  0.28392004,  0.59503836],\n       [ 0.14990781,  0.28892902,  0.59136956],\n       [ 0.14767951,  0.29381086,  0.58773113],\n       [ 0.14569979,  0.29857245,  0.58413255],\n       [ 0.1439691 ,  0.30322055,  0.58058191],\n       [ 0.14248613,  0.30776167,  0.57708599],\n       [ 0.14124797,  0.31220208,  0.57365049],\n       [ 0.14025018,  0.31654779,  0.57028011],\n       [ 0.13948691,  0.32080454,  0.5669787 ],\n       [ 0.13895174,  0.32497744,  0.56375063],\n       [ 0.13863958,  0.32907012,  0.56060453],\n       [ 0.138537  ,  0.3330895 ,  0.55753513],\n       [ 0.13863384,  0.33704026,  0.55454374],\n       [ 0.13891931,  0.34092684,  0.55163126],\n       [ 0.13938212,  0.34475344,  0.54879827],\n       [ 0.14001061,  0.34852402,  0.54604503],\n       [ 0.14079292,  0.35224233,  0.54337156],\n       [ 0.14172091,  0.35590982,  0.54078769],\n       [ 0.14277848,  0.35953205,  0.53828312],\n       [ 0.14395358,  0.36311234,  0.53585661],\n       [ 0.1452346 ,  0.36665374,  0.5335074 ],\n       [ 0.14661019,  0.3701591 ,  0.5312346 ],\n       [ 0.14807104,  0.37363011,  0.52904278],\n       [ 0.1496059 ,  0.3770697 ,  0.52692951],\n       [ 0.15120289,  0.3804813 ,  0.52488853],\n       [ 0.15285214,  0.38386729,  0.52291854],\n       [ 0.15454421,  0.38722991,  0.52101815],\n       [ 0.15627225,  0.39056998,  0.5191937 ],\n       [ 0.15802555,  0.39389087,  0.5174364 ],\n       [ 0.15979549,  0.39719482,  0.51574311],\n       [ 0.16157425,  0.40048375,  0.51411214],\n       [ 0.16335571,  0.40375871,  0.51254622],\n       [ 0.16513234,  0.40702178,  0.51104174],\n       [ 0.1668964 ,  0.41027528,  0.50959299],\n       [ 0.16864151,  0.41352084,  0.50819797],\n       [ 0.17036277,  0.41675941,  0.50685814],\n       [ 0.1720542 ,  0.41999269,  0.50557008],\n       [ 0.17370932,  0.42322271,  0.50432818],\n       [ 0.17532301,  0.42645082,  0.50313007],\n       [ 0.17689176,  0.42967776,  0.50197686],\n       [ 0.17841013,  0.43290523,  0.5008633 ],\n       [ 0.17987314,  0.43613477,  0.49978492],\n       [ 0.18127676,  0.43936752,  0.49873901],\n       [ 0.18261885,  0.44260392,  0.49772638],\n       [ 0.18389409,  0.44584578,  0.49673978],\n       [ 0.18509911,  0.44909409,  0.49577605],\n       [ 0.18623135,  0.4523496 ,  0.494833  ],\n       [ 0.18728844,  0.45561305,  0.49390803],\n       [ 0.18826671,  0.45888565,  0.49299567],\n       [ 0.18916393,  0.46216809,  0.49209268],\n       [ 0.18997879,  0.46546084,  0.49119678],\n       [ 0.19070881,  0.46876472,  0.49030328],\n       [ 0.19135221,  0.47208035,  0.48940827],\n       [ 0.19190791,  0.47540815,  0.48850845],\n       [ 0.19237491,  0.47874852,  0.4876002 ],\n       [ 0.19275204,  0.48210192,  0.48667935],\n       [ 0.19303899,  0.48546858,  0.48574251],\n       [ 0.19323526,  0.48884877,  0.48478573],\n       [ 0.19334062,  0.49224271,  0.48380506],\n       [ 0.19335574,  0.49565037,  0.4827974 ],\n       [ 0.19328143,  0.49907173,  0.48175948],\n       [ 0.19311664,  0.50250719,  0.48068559],\n       [ 0.192864  ,  0.50595628,  0.47957408],\n       [ 0.19252521,  0.50941877,  0.47842186],\n       [ 0.19210087,  0.51289469,  0.47722441],\n       [ 0.19159194,  0.516384  ,  0.47597744],\n       [ 0.19100267,  0.51988593,  0.47467988],\n       [ 0.19033595,  0.52340005,  0.47332894],\n       [ 0.18959113,  0.5269267 ,  0.47191795],\n       [ 0.18877336,  0.530465  ,  0.47044603],\n       [ 0.18788765,  0.53401416,  0.46891178],\n       [ 0.18693822,  0.53757359,  0.46731272],\n       [ 0.18592276,  0.54114404,  0.46563962],\n       [ 0.18485204,  0.54472367,  0.46389595],\n       [ 0.18373148,  0.5483118 ,  0.46207951],\n       [ 0.18256585,  0.55190791,  0.4601871 ],\n       [ 0.18135481,  0.55551253,  0.45821002],\n       [ 0.18011172,  0.55912361,  0.45615277],\n       [ 0.17884392,  0.56274038,  0.45401341],\n       [ 0.17755858,  0.56636217,  0.45178933],\n       [ 0.17625543,  0.56998972,  0.44946971],\n       [ 0.174952  ,  0.57362064,  0.44706119],\n       [ 0.17365805,  0.57725408,  0.44456198],\n       [ 0.17238403,  0.58088916,  0.4419703 ],\n       [ 0.17113321,  0.58452637,  0.43927576],\n       [ 0.1699221 ,  0.58816399,  0.43648119],\n       [ 0.1687662 ,  0.5918006 ,  0.43358772],\n       [ 0.16767908,  0.59543526,  0.43059358],\n       [ 0.16667511,  0.59906699,  0.42749697],\n       [ 0.16575939,  0.60269653,  0.42428344],\n       [ 0.16495764,  0.6063212 ,  0.42096245],\n       [ 0.16428695,  0.60993988,  0.41753246],\n       [ 0.16376481,  0.61355147,  0.41399151],\n       [ 0.16340924,  0.61715487,  0.41033757],\n       [ 0.16323549,  0.62074951,  0.40656329],\n       [ 0.16326148,  0.62433443,  0.40266378],\n       [ 0.16351136,  0.62790748,  0.39864431],\n       [ 0.16400433,  0.63146734,  0.39450263],\n       [ 0.16475937,  0.63501264,  0.39023638],\n       [ 0.16579502,  0.63854196,  0.38584309],\n       [ 0.16712921,  0.64205381,  0.38132023],\n       [ 0.168779  ,  0.64554661,  0.37666513],\n       [ 0.17075915,  0.64901912,  0.37186962],\n       [ 0.17308572,  0.65246934,  0.36693299],\n       [ 0.1757732 ,  0.65589512,  0.36185643],\n       [ 0.17883344,  0.65929449,  0.3566372 ],\n       [ 0.18227669,  0.66266536,  0.35127251],\n       [ 0.18611159,  0.66600553,  0.34575959],\n       [ 0.19034516,  0.66931265,  0.34009571],\n       [ 0.19498285,  0.67258423,  0.3342782 ],\n       [ 0.20002863,  0.67581761,  0.32830456],\n       [ 0.20548509,  0.67900997,  0.3221725 ],\n       [ 0.21135348,  0.68215834,  0.31587999],\n       [ 0.2176339 ,  0.68525954,  0.30942543],\n       [ 0.22432532,  0.68831023,  0.30280771],\n       [ 0.23142568,  0.69130688,  0.29602636],\n       [ 0.23893914,  0.69424565,  0.28906643],\n       [ 0.2468574 ,  0.69712255,  0.28194103],\n       [ 0.25517514,  0.69993351,  0.27465372],\n       [ 0.26388625,  0.70267437,  0.26720869],\n       [ 0.27298333,  0.70534087,  0.25961196],\n       [ 0.28246016,  0.70792854,  0.25186761],\n       [ 0.29232159,  0.71043184,  0.2439642 ],\n       [ 0.30253943,  0.71284765,  0.23594089],\n       [ 0.31309875,  0.71517209,  0.22781515],\n       [ 0.32399522,  0.71740028,  0.21959115],\n       [ 0.33520729,  0.71952906,  0.21129816],\n       [ 0.3467003 ,  0.72155723,  0.20298257],\n       [ 0.35846225,  0.72348143,  0.19466318],\n       [ 0.3704552 ,  0.72530195,  0.18639333],\n       [ 0.38264126,  0.72702007,  0.17822762],\n       [ 0.39499483,  0.72863609,  0.17020921],\n       [ 0.40746591,  0.73015499,  0.1624122 ],\n       [ 0.42001969,  0.73158058,  0.15489659],\n       [ 0.43261504,  0.73291878,  0.14773267],\n       [ 0.44521378,  0.73417623,  0.14099043],\n       [ 0.45777768,  0.73536072,  0.13474173],\n       [ 0.47028295,  0.73647823,  0.1290455 ],\n       [ 0.48268544,  0.73753985,  0.12397794],\n       [ 0.49497773,  0.73854983,  0.11957878],\n       [ 0.5071369 ,  0.73951621,  0.11589589],\n       [ 0.51913764,  0.74044827,  0.11296861],\n       [ 0.53098624,  0.74134823,  0.11080237],\n       [ 0.5426701 ,  0.74222288,  0.10940411],\n       [ 0.55417235,  0.74308049,  0.10876749],\n       [ 0.56550904,  0.74392086,  0.10885609],\n       [ 0.57667994,  0.74474781,  0.10963233],\n       [ 0.58767906,  0.74556676,  0.11105089],\n       [ 0.59850723,  0.74638125,  0.1130567 ],\n       [ 0.609179  ,  0.74719067,  0.11558918],\n       [ 0.61969877,  0.74799703,  0.11859042],\n       [ 0.63007148,  0.74880206,  0.12200388],\n       [ 0.64030249,  0.74960714,  0.12577596],\n       [ 0.65038997,  0.75041586,  0.12985641],\n       [ 0.66034774,  0.75122659,  0.1342004 ],\n       [ 0.67018264,  0.75203968,  0.13876817],\n       [ 0.67990043,  0.75285567,  0.14352456],\n       [ 0.68950682,  0.75367492,  0.14843886],\n       [ 0.69900745,  0.75449768,  0.15348445],\n       [ 0.70840781,  0.75532408,  0.15863839],\n       [ 0.71771325,  0.75615416,  0.16388098],\n       [ 0.72692898,  0.75698787,  0.1691954 ],\n       [ 0.73606001,  0.75782508,  0.17456729],\n       [ 0.74511119,  0.75866562,  0.17998443],\n       [ 0.75408719,  0.75950924,  0.18543644],\n       [ 0.76299247,  0.76035568,  0.19091446],\n       [ 0.77183123,  0.76120466,  0.19641095],\n       [ 0.78060815,  0.76205561,  0.20191973],\n       [ 0.78932717,  0.76290815,  0.20743538],\n       [ 0.79799213,  0.76376186,  0.21295324],\n       [ 0.8066067 ,  0.76461631,  0.21846931],\n       [ 0.81517444,  0.76547101,  0.22398014],\n       [ 0.82369877,  0.76632547,  0.2294827 ],\n       [ 0.832183  ,  0.7671792 ,  0.2349743 ],\n       [ 0.8406303 ,  0.76803167,  0.24045248],\n       [ 0.84904371,  0.76888236,  0.24591492],\n       [ 0.85742615,  0.76973076,  0.25135935],\n       [ 0.86578037,  0.77057636,  0.25678342],\n       [ 0.87410891,  0.77141875,  0.2621846 ],\n       [ 0.88241406,  0.77225757,  0.26755999],\n       [ 0.89070781,  0.77308772,  0.27291122],\n       [ 0.89898836,  0.77391069,  0.27823228],\n       [ 0.90725475,  0.77472764,  0.28351668],\n       [ 0.91550775,  0.77553893,  0.28875751],\n       [ 0.92375722,  0.7763404 ,  0.29395046],\n       [ 0.9320227 ,  0.77712286,  0.29909267],\n       [ 0.94027715,  0.7779011 ,  0.30415428],\n       [ 0.94856742,  0.77865213,  0.3091325 ],\n       [ 0.95686038,  0.7793949 ,  0.31397459],\n       [ 0.965222  ,  0.7800975 ,  0.31864342],\n       [ 0.97365189,  0.78076521,  0.32301107],\n       [ 0.98227405,  0.78134549,  0.32678728],\n       [ 0.99136564,  0.78176999,  0.3281624 ],\n       [ 0.99505988,  0.78542889,  0.32106514],\n       [ 0.99594185,  0.79046888,  0.31648808],\n       [ 0.99646635,  0.79566972,  0.31244662],\n       [ 0.99681528,  0.80094905,  0.30858532],\n       [ 0.9970578 ,  0.80627441,  0.30479247],\n       [ 0.99724883,  0.81161757,  0.30105328],\n       [ 0.99736711,  0.81699344,  0.29725528],\n       [ 0.99742254,  0.82239736,  0.29337235],\n       [ 0.99744736,  0.82781159,  0.28943391],\n       [ 0.99744951,  0.83323244,  0.28543062],\n       [ 0.9973953 ,  0.83867931,  0.2812767 ],\n       [ 0.99727248,  0.84415897,  0.27692897],\n       [ 0.99713953,  0.84963903,  0.27248698],\n       [ 0.99698641,  0.85512544,  0.26791703],\n       [ 0.99673736,  0.86065927,  0.26304767],\n       [ 0.99652358,  0.86616957,  0.25813608],\n       [ 0.99622774,  0.87171946,  0.25292044],\n       [ 0.99590494,  0.87727931,  0.24750009],\n       [ 0.99555225,  0.88285068,  0.2418514 ],\n       [ 0.99513763,  0.8884501 ,  0.23588062],\n       [ 0.99471252,  0.89405076,  0.2296837 ],\n       [ 0.99421873,  0.89968246,  0.2230963 ],\n       [ 0.99370185,  0.90532165,  0.21619768],\n       [ 0.99313786,  0.91098038,  0.2088926 ],\n       [ 0.99250707,  0.91666811,  0.20108214],\n       [ 0.99187888,  0.92235023,  0.19290417],\n       [ 0.99110991,  0.92809686,  0.18387963],\n       [ 0.99042108,  0.93379995,  0.17458127],\n       [ 0.98958484,  0.93956962,  0.16420166],\n       [ 0.98873988,  0.94533859,  0.15303117],\n       [ 0.98784836,  0.95112482,  0.14074826],\n       [ 0.98680727,  0.95697596,  0.12661626]]\n'"
