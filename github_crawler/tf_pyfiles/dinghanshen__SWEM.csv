file_path,api_count,code
data_utils.py,3,"b'# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\n""""""Utilities for downloading data from WMT, tokenizing, vocabularies.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport gzip\nimport os\nimport re\nimport tarfile\nimport pdb\n\nfrom six.moves import urllib\n\nfrom tensorflow.python.platform import gfile\nimport tensorflow as tf\n\n# Special vocabulary symbols - we always put them at the start.\n_PAD = b""_PAD""\n_GO = b""_GO""\n_EOS = b""_EOS""\n_UNK = b""_UNK""\n_START_VOCAB = [_PAD, _GO, _EOS, _UNK]\n\nPAD_ID = 0\nGO_ID = 1\nEOS_ID = 2\nUNK_ID = 3\n\n# Regular expressions used to tokenize.\n_WORD_SPLIT = re.compile(b""([.,!?\\""\':;)(])"")\n_DIGIT_RE = re.compile(br""\\d"")\n\n# URLs for WMT data.\n_WMT_ENFR_TRAIN_URL = ""http://www.statmt.org/wmt10/training-giga-fren.tar""\n_WMT_ENFR_DEV_URL = ""http://www.statmt.org/wmt15/dev-v2.tgz""\n\n\ndef maybe_download(directory, filename, url):\n  """"""Download filename from url unless it\'s already in directory.""""""\n  if not os.path.exists(directory):\n    print(""Creating directory %s"" % directory)\n    os.mkdir(directory)\n  filepath = os.path.join(directory, filename)\n  if not os.path.exists(filepath):\n    print(""Downloading %s to %s"" % (url, filepath))\n    filepath, _ = urllib.request.urlretrieve(url, filepath)\n    statinfo = os.stat(filepath)\n    print(""Successfully downloaded"", filename, statinfo.st_size, ""bytes"")\n  return filepath\n\n\ndef gunzip_file(gz_path, new_path):\n  """"""Unzips from gz_path into new_path.""""""\n  print(""Unpacking %s to %s"" % (gz_path, new_path))\n  with gzip.open(gz_path, ""rb"") as gz_file:\n    with open(new_path, ""wb"") as new_file:\n      for line in gz_file:\n        new_file.write(line)\n\n\ndef get_wmt_enfr_train_set(directory):\n  """"""Download the WMT en-fr training corpus to directory unless it\'s there.""""""\n  train_path = os.path.join(directory, ""giga-fren.release2.fixed"")\n  if not (gfile.Exists(train_path +"".fr"") and gfile.Exists(train_path +"".en"")):\n    corpus_file = maybe_download(directory, ""training-giga-fren.tar"",\n                                 _WMT_ENFR_TRAIN_URL)\n    print(""Extracting tar file %s"" % corpus_file)\n    with tarfile.open(corpus_file, ""r"") as corpus_tar:\n      corpus_tar.extractall(directory)\n    gunzip_file(train_path + "".fr.gz"", train_path + "".fr"")\n    gunzip_file(train_path + "".en.gz"", train_path + "".en"")\n  return train_path\n\n\ndef get_wmt_enfr_dev_set(directory):\n  """"""Download the WMT en-fr training corpus to directory unless it\'s there.""""""\n  dev_name = ""newstest2013""\n  dev_path = os.path.join(directory, dev_name)\n  if not (gfile.Exists(dev_path + "".fr"") and gfile.Exists(dev_path + "".en"")):\n    dev_file = maybe_download(directory, ""dev-v2.tgz"", _WMT_ENFR_DEV_URL)\n    print(""Extracting tgz file %s"" % dev_file)\n    with tarfile.open(dev_file, ""r:gz"") as dev_tar:\n      fr_dev_file = dev_tar.getmember(""dev/"" + dev_name + "".fr"")\n      en_dev_file = dev_tar.getmember(""dev/"" + dev_name + "".en"")\n      fr_dev_file.name = dev_name + "".fr""  # Extract without ""dev/"" prefix.\n      en_dev_file.name = dev_name + "".en""\n      dev_tar.extract(fr_dev_file, directory)\n      dev_tar.extract(en_dev_file, directory)\n  return dev_path\n\n\ndef basic_tokenizer(sentence):\n  """"""Very basic tokenizer: split the sentence into a list of tokens.""""""\n  words = []\n  for space_separated_fragment in sentence.strip().split():\n    words.extend(_WORD_SPLIT.split(space_separated_fragment))\n  return [w for w in words if w]\n\n\ndef create_vocabulary(vocabulary_path, data_path, max_vocabulary_size,\n                      tokenizer=None, normalize_digits=True):\n  """"""Create vocabulary file (if it does not exist yet) from data file.\n\n  Data file is assumed to contain one sentence per line. Each sentence is\n  tokenized and digits are normalized (if normalize_digits is set).\n  Vocabulary contains the most-frequent tokens up to max_vocabulary_size.\n  We write it to vocabulary_path in a one-token-per-line format, so that later\n  token in the first line gets id=0, second line gets id=1, and so on.\n\n  Args:\n    vocabulary_path: path where the vocabulary will be created.\n    data_path: data file that will be used to create vocabulary.\n    max_vocabulary_size: limit on the size of the created vocabulary.\n    tokenizer: a function to use to tokenize each data sentence;\n      if None, basic_tokenizer will be used.\n    normalize_digits: Boolean; if true, all digits are replaced by 0s.\n  """"""\n  if not gfile.Exists(vocabulary_path):\n    print(""Creating vocabulary %s from data %s"" % (vocabulary_path, data_path))\n    vocab = {}\n    #pdb.set_trace()\n    with gfile.GFile(data_path, mode=""rb"") as f:\n      counter = 0\n      for line in f:\n        counter += 1\n        if counter % 100000 == 0:\n          print(""  processing line %d"" % counter)\n        line = tf.compat.as_bytes(line)\n        tokens = tokenizer(line) if tokenizer else basic_tokenizer(line)\n        for w in tokens:\n          word = _DIGIT_RE.sub(b""0"", w) if normalize_digits else w\n          if word in vocab:\n            vocab[word] += 1\n          else:\n            vocab[word] = 1\n      vocab_list = _START_VOCAB + sorted(vocab, key=vocab.get, reverse=True)\n      if len(vocab_list) > max_vocabulary_size:\n        vocab_list = vocab_list[:max_vocabulary_size]\n      with gfile.GFile(vocabulary_path, mode=""wb"") as vocab_file:\n        for w in vocab_list:\n          vocab_file.write(w + b""\\n"")\n\n\ndef initialize_vocabulary(vocabulary_path):\n  """"""Initialize vocabulary from file.\n\n  We assume the vocabulary is stored one-item-per-line, so a file:\n    dog\n    cat\n  will result in a vocabulary {""dog"": 0, ""cat"": 1}, and this function will\n  also return the reversed-vocabulary [""dog"", ""cat""].\n\n  Args:\n    vocabulary_path: path to the file containing the vocabulary.\n\n  Returns:\n    a pair: the vocabulary (a dictionary mapping string to integers), and\n    the reversed vocabulary (a list, which reverses the vocabulary mapping).\n\n  Raises:\n    ValueError: if the provided vocabulary_path does not exist.\n  """"""\n  if gfile.Exists(vocabulary_path):\n    rev_vocab = []\n    with gfile.GFile(vocabulary_path, mode=""rb"") as f:\n      rev_vocab.extend(f.readlines())\n    rev_vocab = [tf.compat.as_bytes(line.strip()) for line in rev_vocab]\n    vocab = dict([(x, y) for (y, x) in enumerate(rev_vocab)])\n    idtoword = dict([(y, x) for (y, x) in enumerate(rev_vocab)])\n    return vocab, idtoword\n  else:\n    raise ValueError(""Vocabulary file %s not found."", vocabulary_path)\n\n\ndef sentence_to_token_ids(sentence, vocabulary,\n                          tokenizer=None, normalize_digits=True):\n  """"""Convert a string to list of integers representing token-ids.\n\n  For example, a sentence ""I have a dog"" may become tokenized into\n  [""I"", ""have"", ""a"", ""dog""] and with vocabulary {""I"": 1, ""have"": 2,\n  ""a"": 4, ""dog"": 7""} this function will return [1, 2, 4, 7].\n\n  Args:\n    sentence: the sentence in bytes format to convert to token-ids.\n    vocabulary: a dictionary mapping tokens to integers.\n    tokenizer: a function to use to tokenize each sentence;\n      if None, basic_tokenizer will be used.\n    normalize_digits: Boolean; if true, all digits are replaced by 0s.\n\n  Returns:\n    a list of integers, the token-ids for the sentence.\n  """"""\n\n  if tokenizer:\n    words = tokenizer(sentence)\n  else:\n    words = basic_tokenizer(sentence)\n  if not normalize_digits:\n    return [vocabulary.get(w, UNK_ID) for w in words]\n  # Normalize digits by 0 before looking words up in the vocabulary.\n  return [vocabulary.get(_DIGIT_RE.sub(b""0"", w), UNK_ID) for w in words]\n\n\ndef data_to_token_ids(data_path, target_path, vocabulary_path,\n                      tokenizer=None, normalize_digits=True):\n  """"""Tokenize data file and turn into token-ids using given vocabulary file.\n\n  This function loads data line-by-line from data_path, calls the above\n  sentence_to_token_ids, and saves the result to target_path. See comment\n  for sentence_to_token_ids on the details of token-ids format.\n\n  Args:\n    data_path: path to the data file in one-sentence-per-line format.\n    target_path: path where the file with token-ids will be created.\n    vocabulary_path: path to the vocabulary file.\n    tokenizer: a function to use to tokenize each sentence;\n      if None, basic_tokenizer will be used.\n    normalize_digits: Boolean; if true, all digits are replaced by 0s.\n  """"""\n  if not gfile.Exists(target_path):\n    print(""Tokenizing data in %s"" % data_path)\n    vocab, _ = initialize_vocabulary(vocabulary_path)\n    with gfile.GFile(data_path, mode=""rb"") as data_file:\n      with gfile.GFile(target_path, mode=""w"") as tokens_file:\n        counter = 0\n        for line in data_file:\n          counter += 1\n          if counter % 100000 == 0:\n            print(""  tokenizing line %d"" % counter)\n          token_ids = sentence_to_token_ids(tf.compat.as_bytes(line), vocab,\n                                            tokenizer, normalize_digits)\n          tokens_file.write("" "".join([str(tok) for tok in token_ids]) + ""\\n"")\n\n\ndef prepare_wmt_data(data_dir, en_vocabulary_size, fr_vocabulary_size, tokenizer=None):\n  """"""Get WMT data into data_dir, create vocabularies and tokenize data.\n\n  Args:\n    data_dir: directory in which the data sets will be stored.\n    en_vocabulary_size: size of the English vocabulary to create and use.\n    fr_vocabulary_size: size of the French vocabulary to create and use.\n    tokenizer: a function to use to tokenize each data sentence;\n      if None, basic_tokenizer will be used.\n\n  Returns:\n    A tuple of 6 elements:\n      (1) path to the token-ids for English training data-set,\n      (2) path to the token-ids for French training data-set,\n      (3) path to the token-ids for English development data-set,\n      (4) path to the token-ids for French development data-set,\n      (5) path to the English vocabulary file,\n      (6) path to the French vocabulary file.\n  """"""\n  # Get wmt data to the specified directory.\n  train_path = get_wmt_enfr_train_set(data_dir)\n  dev_path = get_wmt_enfr_dev_set(data_dir)\n\n  from_train_path = train_path + "".en""\n  to_train_path = train_path + "".fr""\n  from_dev_path = dev_path + "".en""\n  to_dev_path = dev_path + "".fr""\n  return prepare_data(data_dir, from_train_path, to_train_path, from_dev_path, to_dev_path, en_vocabulary_size,\n                      fr_vocabulary_size, tokenizer)\n\n\ndef prepare_data(data_dir, from_train_path, to_train_path, from_dev_path, to_dev_path, from_vocabulary_size,\n                 to_vocabulary_size, tokenizer=None):\n  """"""Preapre all necessary files that are required for the training.\n\n    Args:\n      data_dir: directory in which the data sets will be stored.\n      from_train_path: path to the file that includes ""from"" training samples.\n      to_train_path: path to the file that includes ""to"" training samples.\n      from_dev_path: path to the file that includes ""from"" dev samples.\n      to_dev_path: path to the file that includes ""to"" dev samples.\n      from_vocabulary_size: size of the ""from language"" vocabulary to create and use.\n      to_vocabulary_size: size of the ""to language"" vocabulary to create and use.\n      tokenizer: a function to use to tokenize each data sentence;\n        if None, basic_tokenizer will be used.\n\n    Returns:\n      A tuple of 6 elements:\n        (1) path to the token-ids for ""from language"" training data-set,\n        (2) path to the token-ids for ""to language"" training data-set,\n        (3) path to the token-ids for ""from language"" development data-set,\n        (4) path to the token-ids for ""to language"" development data-set,\n        (5) path to the ""from language"" vocabulary file,\n        (6) path to the ""to language"" vocabulary file.\n    """"""\n  # Create vocabularies of the appropriate sizes.\n  to_vocab_path = os.path.join(data_dir, ""vocab%d.to"" % to_vocabulary_size)\n  from_vocab_path = os.path.join(data_dir, ""vocab%d.from"" % from_vocabulary_size)\n  create_vocabulary(to_vocab_path, to_train_path , to_vocabulary_size, tokenizer)\n  create_vocabulary(from_vocab_path, from_train_path , from_vocabulary_size, tokenizer)\n\n  # Create token ids for the training data.\n  to_train_ids_path = to_train_path + ("".ids%d"" % to_vocabulary_size)\n  from_train_ids_path = from_train_path + ("".ids%d"" % from_vocabulary_size)\n  data_to_token_ids(to_train_path, to_train_ids_path, to_vocab_path, tokenizer)\n  data_to_token_ids(from_train_path, from_train_ids_path, from_vocab_path, tokenizer)\n\n  # Create token ids for the development data.\n  to_dev_ids_path = to_dev_path + ("".ids%d"" % to_vocabulary_size)\n  from_dev_ids_path = from_dev_path + ("".ids%d"" % from_vocabulary_size)\n  data_to_token_ids(to_dev_path, to_dev_ids_path, to_vocab_path, tokenizer)\n  data_to_token_ids(from_dev_path, from_dev_ids_path, from_vocab_path, tokenizer)\n\n  return (from_train_ids_path, to_train_ids_path,\n          from_dev_ids_path, to_dev_ids_path,\n          from_vocab_path, to_vocab_path)\n'"
eval_dbpedia_emb.py,34,"b'# -*- coding: utf-8 -*-\n""""""\nDinghan Shen\n\nBaseline Needs More Love: On Simple Word-Embedding-Based Models and Associated Pooling Mechanisms (ACL 2018)\n""""""\n## 152.3.214.203/6006\nimport os\nGPUID = 0\nos.environ[\'CUDA_VISIBLE_DEVICES\'] = str(GPUID)\n\nimport tensorflow as tf\nfrom tensorflow.contrib import learn\nfrom tensorflow.contrib import layers\n# from tensorflow.contrib import metrics\n# from tensorflow.contrib.learn import monitors\nfrom tensorflow.contrib import framework\nfrom tensorflow.contrib.learn.python.learn import learn_runner\nfrom tensorflow.python.platform import tf_logging as logging\n# from tensorflow.contrib.learn.python.learn.metric_spec import MetricSpec\nimport cPickle\nimport numpy as np\nimport os\nimport sys\nimport scipy.io as sio\nfrom math import floor\nimport pdb\n\nfrom model import *\nfrom utils import prepare_data_for_cnn, prepare_data_for_rnn, get_minibatches_idx, normalizing, restore_from_save, \\\n    prepare_for_bleu, cal_BLEU, sent2idx, tensors_key_in_file, prepare_data_for_emb\n\n# import tempfile\n# from tensorflow.examples.tutorials.mnist import input_data\n\nlogging.set_verbosity(logging.INFO)\n# Basic model parameters as external flags.\nflags = tf.app.flags\nFLAGS = flags.FLAGS\n\n# flags.DEFINE_string(\'train_dir\', \'data\', \'Directory to put the training data.\')\n\nclass Options(object):\n    def __init__(self):\n        self.fix_emb = False\n        self.reuse_w = True\n        self.reuse_cnn = False\n        self.reuse_discrimination = True  # reuse cnn for discrimination\n        self.restore = True\n        self.tanh = True  # activation fun for the top layer of cnn, otherwise relu\n        self.model = \'cnn_rnn\'  # \'cnn_rnn\', \'rnn_rnn\' , default: cnn_deconv\n\n        self.permutation = 0\n        self.substitution = \'s\'  # Deletion(d), Insertion(a), Substitution(s) and Permutation(p)\n\n        self.W_emb = None\n        self.cnn_W = None\n        self.cnn_b = None\n        self.maxlen = 153  # ae value\n        self.n_words = None\n        self.filter_shape = 5\n        self.filter_size = 100\n        self.embed_size = 300\n        self.lr = 2e-4\n        self.layer = 3\n        self.stride = [2, 2]  # for two layer cnn/deconv , use self.stride[0]\n        self.batch_size = 50\n        self.max_epochs = 1000\n        self.n_gan = 500  # self.filter_size * 3\n        self.L = 100\n        self.drop_rate = 0.8\n\n        self.part_data = False\n        self.portion = 1.0  # 10%  1%\n\n        self.save_path = ""./save/dbpedia_500_new_""\n        self.log_path = ""./log""\n        self.print_freq = 100\n        self.valid_freq = 100\n\n        self.discrimination = False\n        self.dropout = 0.5\n        self.H_dis = 300\n\n        self.sent_len = self.maxlen + 2 * (self.filter_shape - 1)\n        self.sent_len2 = np.int32(floor((self.sent_len - self.filter_shape) / self.stride[0]) + 1)\n        self.sent_len3 = np.int32(floor((self.sent_len2 - self.filter_shape) / self.stride[1]) + 1)\n        # self.sent_len4 = np.int32(floor((self.sent_len3 - self.filter_shape)/self.stride[2]) + 1)\n        print (\'Use model %s\' % self.model)\n        print (\'Use %d conv/deconv layers\' % self.layer)\n\n    def __iter__(self):\n        for attr, value in self.__dict__.iteritems():\n            yield attr, value\n\ndef auto_encoder(x, x_mask, y, dropout, opt):\n    # print x.get_shape()  # batch L\n    x_emb, W_norm = embedding(x, opt)  # batch L emb\n    x_emb = tf.expand_dims(x_emb, 3)  # batch L emb 1\n    x_emb = tf.nn.dropout(x_emb, dropout)\n\n    x_mask = tf.expand_dims(x_mask, axis=-1)\n    x_mask = tf.expand_dims(x_mask, axis=-1)  # batch L 1 1\n\n    x_sum = tf.multiply(x_emb, x_mask)  # batch L emb 1\n    H_enc = tf.reduce_sum(x_sum, axis=1, keep_dims=True)  # batch 1 emb 1\n    H_enc = tf.squeeze(H_enc)  # batch emb\n    x_mask_sum = tf.reduce_sum(x_mask, axis=1, keep_dims=True)  # batch 1 1 1\n    x_mask_sum = tf.squeeze(x_mask_sum, [2, 3])  # batch 1\n\n    H_enc_1 = H_enc / x_mask_sum  # batch emb\n\n    H_enc_2 = tf.nn.max_pool(x_emb, [1, opt.maxlen, 1, 1], [1, 1, 1, 1], \'VALID\')\n    H_enc_2 = tf.squeeze(H_enc_2)\n\n    H_enc = tf.concat([H_enc_1, H_enc_2], 1)\n\n    H_enc = tf.squeeze(H_enc)\n    logits = discriminator_2layer(H_enc, opt, dropout, prefix=\'classify_\', num_outputs=14, is_reuse=None)  # batch * 1\n    prob = tf.nn.softmax(logits)\n\n    correct_prediction = tf.equal(tf.argmax(prob, 1), tf.argmax(y, 1))\n    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\n    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=logits))\n\n    train_op = layers.optimize_loss(\n        loss,\n        framework.get_global_step(),\n        optimizer=\'Adam\',\n        #variables=d_vars,\n        learning_rate=opt.lr)\n\n    return accuracy, loss, train_op\n\n\ndef main():\n    # global n_words\n    # Prepare training and testing data\n    loadpath = ""./data/dbpedia.p""\n    x = cPickle.load(open(loadpath, ""rb""))\n    train, val, test = x[0], x[1], x[2]\n    train_lab, val_lab, test_lab = x[3], x[4], x[5]\n    wordtoix, ixtoword = x[6], x[7]\n\n    train_lab = np.array(train_lab, dtype=\'float32\')\n    val_lab = np.array(val_lab, dtype=\'float32\')\n    test_lab = np.array(test_lab, dtype=\'float32\')\n\n    #pdb.set_trace()\n\n    opt = Options()\n    opt.n_words = len(ixtoword)\n\n    del x\n\n    print(dict(opt))\n    print(\'Total words: %d\' % opt.n_words)\n\n    if opt.part_data:\n        np.random.seed(123)\n        train_ind = np.random.choice(len(train), int(len(train)*opt.portion), replace=False)\n        train = [train[t] for t in train_ind]\n        train_lab = [train_lab[t] for t in train_ind]\n\n    try:\n        params = np.load(\'./param_g.npz\')\n        if params[\'Wemb\'].shape == (opt.n_words, opt.embed_size):\n            print(\'Use saved embedding.\')\n            opt.W_emb = params[\'Wemb\']\n        else:\n            print(\'Emb Dimension mismatch: param_g.npz:\' + str(params[\'Wemb\'].shape) + \' opt: \' + str(\n                (opt.n_words, opt.embed_size)))\n            opt.fix_emb = False\n    except IOError:\n        print(\'No embedding file found.\')\n        opt.fix_emb = False\n\n    with tf.device(\'/gpu:1\'):\n        x_ = tf.placeholder(tf.int32, shape=[opt.batch_size, opt.maxlen])\n        x_mask_ = tf.placeholder(tf.float32, shape=[opt.batch_size, opt.maxlen])\n        keep_prob = tf.placeholder(tf.float32)\n        y_ = tf.placeholder(tf.float32, shape=[opt.batch_size, 14])\n        accuracy_, loss_, train_op = auto_encoder(x_, x_mask_, y_, keep_prob, opt)\n        # merged = tf.summary.merge_all()\n\n    uidx = 0\n    max_val_accuracy = 0.\n    max_test_accuracy = 0.\n    # gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=1)\n    config = tf.ConfigProto(log_device_placement=False, allow_soft_placement=True)\n    config.gpu_options.allow_growth = True\n    np.set_printoptions(precision=3)\n    np.set_printoptions(threshold=np.inf)\n    saver = tf.train.Saver()\n\n    with tf.Session(config=config) as sess:\n        train_writer = tf.summary.FileWriter(opt.log_path + \'/train\', sess.graph)\n        test_writer = tf.summary.FileWriter(opt.log_path + \'/test\', sess.graph)\n        sess.run(tf.global_variables_initializer())\n        if opt.restore:\n            try:\n\n                t_vars = tf.trainable_variables()\n                # print([var.name[:-2] for var in t_vars])\n                save_keys = tensors_key_in_file(opt.save_path)\n                # print(save_keys.keys())\n                ss = set([var.name for var in t_vars]) & set([s + "":0"" for s in save_keys.keys()])\n                cc = {var.name: var for var in t_vars}\n                # only restore variables with correct shape\n                ss_right_shape = set([s for s in ss if cc[s].get_shape() == save_keys[s[:-2]]])\n\n                loader = tf.train.Saver(var_list=[var for var in t_vars if var.name in ss_right_shape])\n                loader.restore(sess, opt.save_path)\n\n                print(""Loading variables from \'%s\'."" % opt.save_path)\n                print(""Loaded variables:"" + str(ss))\n\n            except:\n                print(""No saving session, using random initialization"")\n                sess.run(tf.global_variables_initializer())\n\n        try:\n            for epoch in range(opt.max_epochs):\n                print(""Starting epoch %d"" % epoch)\n                kf = get_minibatches_idx(len(train), opt.batch_size, shuffle=True)\n                for _, train_index in kf:\n                    uidx += 1\n                    sents = [train[t] for t in train_index]\n                    x_labels = [train_lab[t] for t in train_index]\n                    x_labels = np.array(x_labels)\n                    x_labels = x_labels.reshape((len(x_labels), 14))\n\n                    x_batch, x_batch_mask = prepare_data_for_emb(sents, opt)  # Batch L\n                    # x_print = sess.run([x_emb],feed_dict={x_: x_train} )\n                    # print x_print\n\n                    _, loss = sess.run([train_op, loss_], feed_dict={x_: x_batch, x_mask_: x_batch_mask, y_: x_labels,\n                                                                     keep_prob: opt.drop_rate})\n\n                    if uidx % opt.valid_freq == 0:\n                        train_correct = 0.0\n                        kf_train = get_minibatches_idx(400, opt.batch_size, shuffle=True)\n                        for _, train_index in kf_train:\n                            train_sents = [train[t] for t in train_index]\n                            train_labels = [train_lab[t] for t in train_index]\n                            train_labels = np.array(train_labels)\n                            train_labels = train_labels.reshape((len(train_labels), 14))\n                            x_train_batch, x_train_batch_mask = prepare_data_for_emb(train_sents, opt)\n\n                            train_accuracy = sess.run(accuracy_,\n                                                      feed_dict={x_: x_train_batch, x_mask_: x_train_batch_mask,\n                                                                 y_: train_labels, keep_prob: 1.0})\n\n                            train_correct += train_accuracy * len(train_index)\n\n                        train_accuracy = train_correct / 400\n\n                        print(""Iteration %d: Training loss %f "" % (uidx, loss))\n                        print(""Train accuracy %f "" % train_accuracy)\n\n                        val_correct = 0.0\n                        kf_val = get_minibatches_idx(20000, opt.batch_size, shuffle=True)\n                        for _, val_index in kf_val:\n                            val_sents = [val[t] for t in val_index]\n                            val_labels = [val_lab[t] for t in val_index]\n                            val_labels = np.array(val_labels)\n                            val_labels = val_labels.reshape((len(val_labels), 14))\n                            x_val_batch, x_val_batch_mask = prepare_data_for_emb(val_sents, opt)\n\n                            val_accuracy = sess.run(accuracy_, feed_dict={x_: x_val_batch, x_mask_: x_val_batch_mask,\n                                                                          y_: val_labels, keep_prob: 1.0})\n                            val_correct += val_accuracy * len(val_index)\n\n                        val_accuracy = val_correct / 20000\n\n                        print(""Validation accuracy %f "" % val_accuracy)\n\n                        if val_accuracy > max_val_accuracy:\n                            max_val_accuracy = val_accuracy\n\n                            test_correct = 0.0\n                            kf_test = get_minibatches_idx(len(test), opt.batch_size, shuffle=True)\n                            for _, test_index in kf_test:\n                                test_sents = [test[t] for t in test_index]\n                                test_labels = [test_lab[t] for t in test_index]\n                                test_labels = np.array(test_labels)\n                                test_labels = test_labels.reshape((len(test_labels), 14))\n                                x_test_batch, x_test_batch_mask = prepare_data_for_emb(test_sents, opt)\n\n                                test_accuracy = sess.run(accuracy_,\n                                                         feed_dict={x_: x_test_batch, x_mask_: x_test_batch_mask,\n                                                                    y_: test_labels, keep_prob: 1.0})\n\n                                test_correct += test_accuracy * len(test_index)\n\n                            test_accuracy = test_correct / len(test)\n\n                            print(""Test accuracy %f "" % test_accuracy)\n\n                            max_test_accuracy = test_accuracy\n\n                print(""Epoch %d: Max Test accuracy %f"" % (epoch, max_test_accuracy))\n\n                saver.save(sess, opt.save_path, global_step=epoch)\n\n            print(""Max Test accuracy %f "" % max_test_accuracy)\n\n        except KeyboardInterrupt:\n            # print \'Training interupted\'\n            print(\'Training interupted\')\n            print(""Max Test accuracy %f "" % max_test_accuracy)\n\nif __name__ == \'__main__\':\n    main()\n\n'"
eval_snli_emb.py,39,"b'# -*- coding: utf-8 -*-\n""""""\nDinghan Shen\n\nBaseline Needs More Love: On Simple Word-Embedding-Based Models and Associated Pooling Mechanisms (ACL 2018)\n""""""\n\nimport os\nGPUID = 0\nos.environ[\'CUDA_VISIBLE_DEVICES\'] = str(GPUID)\n\nimport tensorflow as tf\nfrom tensorflow.contrib import learn\nfrom tensorflow.contrib import layers\n# from tensorflow.contrib import metrics\n# from tensorflow.contrib.learn import monitors\nfrom tensorflow.contrib import framework\nfrom tensorflow.contrib.learn.python.learn import learn_runner\nfrom tensorflow.python.platform import tf_logging as logging\n# from tensorflow.contrib.learn.python.learn.metric_spec import MetricSpec\nimport cPickle\nimport numpy as np\nimport os\nimport scipy.io as sio\nfrom math import floor\nimport pdb\n\nfrom model import *\nfrom utils import prepare_data_for_cnn, prepare_data_for_rnn, get_minibatches_idx, normalizing, restore_from_save\\\n    , _clip_gradients_seperate_norm, tensors_key_in_file, prepare_data_for_emb\n\n# import tempfile\n# from tensorflow.examples.tutorials.mnist import input_data\n\nlogging.set_verbosity(logging.INFO)\n# Basic model parameters as external flags.\nflags = tf.app.flags\nFLAGS = flags.FLAGS\n\n\n# flags.DEFINE_string(\'train_dir\', \'data\', \'Directory to put the training data.\')\n\nclass Options(object):\n    def __init__(self):\n        self.fix_emb = True\n        #self.relu_w = True\n        #self.reuse_w = False\n        self.reuse_cnn = False\n        self.reuse_discrimination = True  # reuse cnn for discrimination\n        self.restore = True\n        self.tanh = False  # activation fun for the top layer of cnn, otherwise relu\n        self.model = \'cnn_deconv\'  # \'cnn_rnn\', \'rnn_rnn\' , default: cnn_deconv\n\n        self.permutation = 0\n        self.substitution = None  # Deletion(d), Insertion(a), Substitution(s) and Permutation(p)\n\n        self.W_emb = None\n        self.cnn_W = None\n        self.cnn_b = None\n        self.maxlen = 69\n        self.n_words = None\n        self.filter_shape = 5\n        self.filter_size = 300\n        self.multiplier = 2  # filtersize multiplier\n        self.embed_size = 300\n        self.lr = 3e-4\n        self.layer = 3\n        self.stride = [2, 2, 2]  # for two layer cnn/deconv, use self.stride[0]\n        self.batch_size = 307  # 9824\n        self.max_epochs = 5000\n        self.n_gan = 500  # self.filter_size * 3\n        self.L = 100\n        self.encoder = \'max\'  # \'max\' \'concat\'\n        self.combine_enc = \'mix\'\n        self.category = 3  # \'1\' for binary\n\n        self.optimizer = \'RMSProp\'  # tf.train.AdamOptimizer(beta1=0.9) #\'Adam\' # \'Momentum\' , \'RMSProp\'\n        self.dropout_ratio = 0.8\n\n        # self.save_path = ""./save/snli_emb_10""\n        self.save_path = ""./save/snli_emb_10""\n        self.log_path = ""./log""\n        self.valid_freq = 100\n\n        # partially use labeled data\n        self.part_data = False\n        self.portion = 0.01  # 10%  1%\n\n        self.discrimination = False\n        self.H_dis = 300\n\n        self.sent_len = self.maxlen + 2 * (self.filter_shape - 1)\n        self.sent_len2 = np.int32(floor((self.sent_len - self.filter_shape) / self.stride[0]) + 1)\n        self.sent_len3 = np.int32(floor((self.sent_len2 - self.filter_shape) / self.stride[1]) + 1)\n        self.sent_len4 = np.int32(floor((self.sent_len3 - self.filter_shape) / self.stride[2]) + 1)\n        print (\'Use model %s\' % self.model)\n        print (\'Use %d conv/deconv layers\' % self.layer)\n\n    def __iter__(self):\n        for attr, value in self.__dict__.iteritems():\n            yield attr, value\n\n\ndef auto_encoder(x_1, x_2, x_mask_1, x_mask_2, y, dropout, opt):\n    x_1_emb, W_emb = embedding(x_1, opt)  # batch L emb\n    x_2_emb = tf.nn.embedding_lookup(W_emb, x_2)\n\n    x_1_emb = tf.nn.dropout(x_1_emb, dropout)  # batch L emb\n    x_2_emb = tf.nn.dropout(x_2_emb, dropout)  # batch L emb\n\n    biasInit = tf.constant_initializer(0.001, dtype=tf.float32)\n    x_1_emb = layers.fully_connected(tf.squeeze(x_1_emb), num_outputs=opt.embed_size, biases_initializer=biasInit, activation_fn=tf.nn.relu, scope=\'trans\', reuse=None)  # batch L emb\n    x_2_emb = layers.fully_connected(tf.squeeze(x_2_emb), num_outputs=opt.embed_size, biases_initializer=biasInit, activation_fn=tf.nn.relu, scope=\'trans\', reuse=True)\n\n    x_1_emb = tf.expand_dims(x_1_emb, 3)  # batch L emb 1\n    x_2_emb = tf.expand_dims(x_2_emb, 3)\n\n    if opt.encoder == \'aver\':\n        H_enc_1 = aver_emb_encoder(x_1_emb, x_mask_1)\n        H_enc_2 = aver_emb_encoder(x_2_emb, x_mask_2)\n\n    elif opt.encoder == \'max\':\n        H_enc_1 = max_emb_encoder(x_1_emb, x_mask_1, opt)\n        H_enc_2 = max_emb_encoder(x_2_emb, x_mask_2, opt)\n\n    elif opt.encoder == \'concat\':\n        H_enc_1 = concat_emb_encoder(x_1_emb, x_mask_1, opt)\n        H_enc_2 = concat_emb_encoder(x_2_emb, x_mask_2, opt)\n\n    # discriminative loss term\n    if opt.combine_enc == \'mult\':\n        H_enc = tf.multiply(H_enc_1, H_enc_2)  # batch * n_gan\n\n    if opt.combine_enc == \'concat\':\n        H_enc = tf.concat([H_enc_1, H_enc_2], 1)\n\n    if opt.combine_enc == \'sub\':\n        H_enc = tf.subtract(H_enc_1, H_enc_2)\n\n    if opt.combine_enc == \'mix\':\n        H_1 = tf.multiply(H_enc_1, H_enc_2)\n        H_2 = tf.concat([H_enc_1, H_enc_2], 1)\n        H_3 = tf.subtract(H_enc_1, H_enc_2)\n        H_enc = tf.concat([H_1, H_2, H_3], 1)\n\n    # calculate the accuracy\n    logits = discriminator_2layer(H_enc, opt, dropout, prefix=\'classify_\', num_outputs=opt.category, is_reuse=None)\n    prob = tf.nn.softmax(logits)\n\n    correct_prediction = tf.equal(tf.argmax(prob, 1), tf.argmax(y, 1))\n    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=logits))\n\n    train_op = layers.optimize_loss(\n        loss,\n        framework.get_global_step(),\n        optimizer=\'Adam\',\n        # variables=d_vars,\n        learning_rate=opt.lr)\n\n    return accuracy, loss, train_op, W_emb\n\ndef main():\n    loadpath = ""./data/snli.p""\n    x = cPickle.load(open(loadpath, ""rb""))\n\n    train, val, test = x[0], x[1], x[2]\n    wordtoix, ixtoword = x[4], x[5]\n\n    train_q, train_a, train_lab = train[0], train[1], train[2]\n    val_q, val_a, val_lab = val[0], val[1], val[2]\n    test_q, test_a, test_lab = test[0], test[1], test[2]\n\n    train_lab = np.array(train_lab, dtype=\'float32\')\n    val_lab = np.array(val_lab, dtype=\'float32\')\n    test_lab = np.array(test_lab, dtype=\'float32\')\n\n    opt = Options()\n    opt.n_words = len(ixtoword)\n\n    del x\n\n    print(dict(opt))\n    print(\'Total words: %d\' % opt.n_words)\n\n    if opt.part_data:\n        np.random.seed(123)\n        train_ind = np.random.choice(len(train_q), int(len(train_q)*opt.portion), replace=False)\n        train_q = [train_q[t] for t in train_ind]\n        train_a = [train_a[t] for t in train_ind]\n        train_lab = [train_lab[t] for t in train_ind]\n\n    try:\n        params = np.load(\'./data/snli_emb.p\')\n        if params[0].shape == (opt.n_words, opt.embed_size):\n            print(\'Use saved embedding.\')\n            #pdb.set_trace()\n            opt.W_emb = np.array(params[0], dtype=\'float32\')\n        else:\n            print(\'Emb Dimension mismatch: param_g.npz:\' + str(params[0].shape) + \' opt: \' + str(\n                (opt.n_words, opt.embed_size)))\n            opt.fix_emb = False\n    except IOError:\n        print(\'No embedding file found.\')\n        opt.fix_emb = False\n\n    with tf.device(\'/gpu:1\'):\n        x_1_ = tf.placeholder(tf.int32, shape=[opt.batch_size, opt.maxlen])\n        x_2_ = tf.placeholder(tf.int32, shape=[opt.batch_size, opt.maxlen])\n        x_mask_1_ = tf.placeholder(tf.float32, shape=[opt.batch_size, opt.maxlen])\n        x_mask_2_ = tf.placeholder(tf.float32, shape=[opt.batch_size, opt.maxlen])\n        y_ = tf.placeholder(tf.float32, shape=[opt.batch_size, opt.category])\n        keep_prob = tf.placeholder(tf.float32)\n        accuracy_, loss_, train_op_, W_emb_ = auto_encoder(x_1_, x_2_, x_mask_1_, x_mask_2_, y_, keep_prob, opt)\n        merged = tf.summary.merge_all()\n\n    uidx = 0\n    max_val_accuracy = 0.\n    max_test_accuracy = 0.\n    # gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=1)\n    config = tf.ConfigProto(log_device_placement=False, allow_soft_placement=True)\n    config.gpu_options.allow_growth = True\n    np.set_printoptions(precision=3)\n    np.set_printoptions(threshold=np.inf)\n    saver = tf.train.Saver()\n\n    with tf.Session(config=config) as sess:\n        train_writer = tf.summary.FileWriter(opt.log_path + \'/train\', sess.graph)\n        test_writer = tf.summary.FileWriter(opt.log_path + \'/test\', sess.graph)\n        sess.run(tf.global_variables_initializer())\n        if opt.restore:\n            try:\n                #pdb.set_trace()\n                t_vars = tf.trainable_variables()\n                # print([var.name[:-2] for var in t_vars])\n                save_keys = tensors_key_in_file(opt.save_path)\n\n                # pdb.set_trace()\n                # print(save_keys.keys())\n                ss = set([var.name for var in t_vars]) & set([s + "":0"" for s in save_keys.keys()])\n                cc = {var.name: var for var in t_vars}\n                #pdb.set_trace()\n\n                # only restore variables with correct shape\n                ss_right_shape = set([s for s in ss if cc[s].get_shape() == save_keys[s[:-2]]])\n\n                loader = tf.train.Saver(var_list=[var for var in t_vars if var.name in ss_right_shape])\n                loader.restore(sess, opt.save_path)\n\n                print(""Loading variables from \'%s\'."" % opt.save_path)\n                print(""Loaded variables:"" + str(ss))\n\n            except:\n                print(""No saving session, using random initialization"")\n                sess.run(tf.global_variables_initializer())\n\n        try:\n            for epoch in range(opt.max_epochs):\n                print(""Starting epoch %d"" % epoch)\n                kf = get_minibatches_idx(len(train_q), opt.batch_size, shuffle=True)\n                for _, train_index in kf:\n\n                    uidx += 1\n                    sents_1 = [train_q[t] for t in train_index]\n                    sents_2 = [train_a[t] for t in train_index]\n                    x_labels = [train_lab[t] for t in train_index]\n                    x_labels = np.array(x_labels)\n                    x_labels = x_labels.reshape((len(x_labels), opt.category))\n\n                    x_batch_1, x_batch_mask_1 = prepare_data_for_emb(sents_1, opt)\n                    x_batch_2, x_batch_mask_2 = prepare_data_for_emb(sents_2, opt)\n\n                    _, loss = sess.run([train_op_, loss_], feed_dict={x_1_: x_batch_1, x_2_: x_batch_2,\n                                       x_mask_1_: x_batch_mask_1, x_mask_2_: x_batch_mask_2, y_: x_labels, keep_prob: opt.dropout_ratio})\n\n                    if uidx % opt.valid_freq == 0:\n\n                        train_correct = 0.0\n                        kf_train = get_minibatches_idx(3070, opt.batch_size, shuffle=True)\n                        for _, train_index in kf_train:\n                            train_sents_1 = [train_q[t] for t in train_index]\n                            train_sents_2 = [train_a[t] for t in train_index]\n                            train_labels = [train_lab[t] for t in train_index]\n                            train_labels = np.array(train_labels)\n                            train_labels = train_labels.reshape((len(train_labels), opt.category))\n                            x_train_batch_1, x_train_mask_1 = prepare_data_for_emb(train_sents_1, opt)\n                            x_train_batch_2, x_train_mask_2 = prepare_data_for_emb(train_sents_2, opt)\n\n                            train_accuracy = sess.run(accuracy_,\n                                                      feed_dict={x_1_: x_train_batch_1, x_2_: x_train_batch_2, x_mask_1_: x_train_mask_1, x_mask_2_: x_train_mask_2,\n                                                                 y_: train_labels, keep_prob: 1.0})\n\n                            train_correct += train_accuracy * len(train_index)\n\n                        train_accuracy = train_correct / 3070\n\n                        # print(""Iteration %d: Training loss %f, dis loss %f, rec loss %f"" % (uidx,\n                        #                                                                     loss, dis_loss, rec_loss))\n                        print(""Train accuracy %f "" % train_accuracy)\n\n                        val_correct = 0.0\n                        is_train = True\n                        kf_val = get_minibatches_idx(len(val_q), opt.batch_size, shuffle=True)\n                        for _, val_index in kf_val:\n                            val_sents_1 = [val_q[t] for t in val_index]\n                            val_sents_2 = [val_a[t] for t in val_index]\n                            val_labels = [val_lab[t] for t in val_index]\n                            val_labels = np.array(val_labels)\n                            val_labels = val_labels.reshape((len(val_labels), opt.category))\n                            x_val_batch_1, x_val_mask_1 = prepare_data_for_emb(val_sents_1, opt)\n                            x_val_batch_2, x_val_mask_2 = prepare_data_for_emb(val_sents_2, opt)\n\n                            val_accuracy = sess.run(accuracy_, feed_dict={x_1_: x_val_batch_1, x_2_: x_val_batch_2,\n                                                                          x_mask_1_: x_val_mask_1, x_mask_2_: x_val_mask_2, y_: val_labels, keep_prob: 1.0})\n\n                            val_correct += val_accuracy * len(val_index)\n\n                        val_accuracy = val_correct / len(val_q)\n\n                        print(""Validation accuracy %f "" % val_accuracy)\n\n                        if val_accuracy > max_val_accuracy:\n                            max_val_accuracy = val_accuracy\n\n                            test_correct = 0.0\n                            kf_test = get_minibatches_idx(len(test_q), opt.batch_size, shuffle=True)\n                            for _, test_index in kf_test:\n                                test_sents_1 = [test_q[t] for t in test_index]\n                                test_sents_2 = [test_a[t] for t in test_index]\n                                test_labels = [test_lab[t] for t in test_index]\n                                test_labels = np.array(test_labels)\n                                test_labels = test_labels.reshape((len(test_labels), opt.category))\n                                x_test_batch_1, x_test_mask_1 = prepare_data_for_emb(test_sents_1, opt)\n                                x_test_batch_2, x_test_mask_2 = prepare_data_for_emb(test_sents_2, opt)\n\n                                test_accuracy = sess.run(accuracy_, feed_dict={x_1_: x_test_batch_1, x_2_: x_test_batch_2,\n                                                                               x_mask_1_: x_test_mask_1, x_mask_2_: x_test_mask_2,\n                                                                               y_: test_labels, keep_prob: 1.0})\n\n                                test_correct += test_accuracy * len(test_index)\n\n                            test_accuracy = test_correct / len(test_q)\n\n                            print(""Test accuracy %f "" % test_accuracy)\n\n                            max_test_accuracy = test_accuracy\n\n                print(""Epoch %d: Max Test accuracy %f"" % (epoch, max_test_accuracy))\n\n            print(""Max Test accuracy %f "" % max_test_accuracy)\n\n        except KeyboardInterrupt:\n            print(\'Training interupted\')\n            print(""Max Test accuracy %f "" % max_test_accuracy)\n\nif __name__ == \'__main__\':\n    main()'"
eval_yahoo_emb.py,34,"b'# -*- coding: utf-8 -*-\n""""""\nDinghan Shen\n\nBaseline Needs More Love: On Simple Word-Embedding-Based Models and Associated Pooling Mechanisms (ACL 2018)\n""""""\n\nimport os\nGPUID = 1\nos.environ[\'CUDA_VISIBLE_DEVICES\'] = str(GPUID)\n\nimport tensorflow as tf\nfrom tensorflow.contrib import learn\nfrom tensorflow.contrib import layers\n# from tensorflow.contrib import metrics\n# from tensorflow.contrib.learn import monitors\nfrom tensorflow.contrib import framework\nfrom tensorflow.contrib.learn.python.learn import learn_runner\nfrom tensorflow.python.platform import tf_logging as logging\n# from tensorflow.contrib.learn.python.learn.metric_spec import MetricSpec\nimport cPickle\nimport numpy as np\nimport os\nimport sys\nimport scipy.io as sio\nfrom math import floor\nimport pdb\n\nfrom model import *\nfrom utils import prepare_data_for_cnn, prepare_data_for_rnn, get_minibatches_idx, normalizing, restore_from_save, \\\n    prepare_for_bleu, cal_BLEU, sent2idx, tensors_key_in_file, prepare_data_for_emb\n\n# import tempfile\n# from tensorflow.examples.tutorials.mnist import input_data\n\nlogging.set_verbosity(logging.INFO)\n# Basic model parameters as external flags.\nflags = tf.app.flags\nFLAGS = flags.FLAGS\n\n\n# flags.DEFINE_string(\'train_dir\', \'data\', \'Directory to put the training data.\')\n\nclass Options(object):\n    def __init__(self):\n        self.fix_emb = False\n        self.reuse_w = True\n        self.reuse_cnn = False\n        self.reuse_discrimination = True  # reuse cnn for discrimination\n        self.restore = True\n        self.tanh = True  # activation fun for the top layer of cnn, otherwise relu\n        self.model = \'cnn_deconv\'  # \'cnn_rnn\', \'rnn_rnn\' , default: cnn_deconv\n\n        self.permutation = 0\n        self.substitution = \'s\'  # Deletion(d), Insertion(a), Substitution(s) and Permutation(p)\n\n        self.W_emb = None\n        self.cnn_W = None\n        self.cnn_b = None\n        self.maxlen = 305\n        self.n_words = None\n        self.filter_shape = 5\n        self.embed_size = 300\n        self.lr = 3e-4\n        self.layer = 3\n        self.stride = [2, 2]  # for two layer cnn/deconv , use self.stride[0]\n        self.batch_size = 128\n        self.max_epochs = 1000\n        self.n_gan = 500  # self.filter_size * 3\n        self.L = 100\n        self.drop_rate = 0.8\n        self.encoder = \'concat\'  # \'max\' \'concat\'\n\n        self.part_data = False\n        self.portion = 0.001   # 10%  1%  float(sys.argv[1])\n\n        self.save_path = ""./save/yahoo_emb""\n        self.log_path = ""./log""\n        self.print_freq = 500\n        self.valid_freq = 500\n\n        self.discrimination = False\n        self.dropout = 0.5\n        self.H_dis = 300\n\n        self.sent_len = self.maxlen + 2 * (self.filter_shape - 1)\n        self.sent_len2 = np.int32(floor((self.sent_len - self.filter_shape) / self.stride[0]) + 1)\n        self.sent_len3 = np.int32(floor((self.sent_len2 - self.filter_shape) / self.stride[1]) + 1)\n        # self.sent_len4 = np.int32(floor((self.sent_len3 - self.filter_shape)/self.stride[2]) + 1)\n        print (\'Use model %s\' % self.model)\n        print (\'Use %d conv/deconv layers\' % self.layer)\n\n    def __iter__(self):\n        for attr, value in self.__dict__.iteritems():\n            yield attr, value\n\n\ndef emb_classifier(x, x_mask, y, dropout, opt):\n    # print x.get_shape()  # batch L\n    x_emb, W_emb = embedding(x, opt)  # batch L emb\n    x_emb = tf.expand_dims(x_emb, 3)  # batch L emb 1\n    x_emb = tf.nn.dropout(x_emb, dropout)   # batch L emb 1\n\n    x_mask = tf.expand_dims(x_mask, axis=-1)\n    x_mask = tf.expand_dims(x_mask, axis=-1)  # batch L 1 1\n\n    x_sum = tf.multiply(x_emb, x_mask)  # batch L emb 1\n    H_enc = tf.reduce_sum(x_sum, axis=1, keep_dims=True)  # batch 1 emb 1\n    H_enc = tf.squeeze(H_enc)  # batch emb\n    x_mask_sum = tf.reduce_sum(x_mask, axis=1, keep_dims=True)  # batch 1 1 1\n    x_mask_sum = tf.squeeze(x_mask_sum, [2, 3])  # batch 1\n    H_enc_1 = H_enc / x_mask_sum  # batch emb\n\n    H_enc_2 = tf.nn.max_pool(x_emb, [1, opt.maxlen, 1, 1], [1, 1, 1, 1], \'VALID\')\n    H_enc_2 = tf.squeeze(H_enc_2)\n\n    H_enc = tf.concat([H_enc_1, H_enc_2], 1)\n\n    H_enc = tf.squeeze(H_enc)\n    logits = discriminator_2layer(H_enc, opt, dropout, prefix=\'classify_\', num_outputs=10, is_reuse=None)  # batch * 10\n    prob = tf.nn.softmax(logits)\n\n    correct_prediction = tf.equal(tf.argmax(prob, 1), tf.argmax(y, 1))\n    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\n    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=logits))\n\n    train_op = layers.optimize_loss(\n        loss,\n        framework.get_global_step(),\n        optimizer=\'Adam\',\n        learning_rate=opt.lr)\n\n    return accuracy, loss, train_op, W_emb\n\n\ndef main():\n    # global n_words\n    # Prepare training and testing data\n    loadpath = ""./data/yahoo.p""\n    x = cPickle.load(open(loadpath, ""rb""))\n    train, val, test = x[0], x[1], x[2]\n    train_lab, val_lab, test_lab = x[3], x[4], x[5]\n    wordtoix, ixtoword = x[6], x[7]\n\n    train_lab = np.array(train_lab, dtype=\'float32\')\n    val_lab = np.array(val_lab, dtype=\'float32\')\n    test_lab = np.array(test_lab, dtype=\'float32\')\n\n    opt = Options()\n    opt.n_words = len(ixtoword)\n\n    del x\n\n    print(dict(opt))\n    print(\'Total words: %d\' % opt.n_words)\n\n    if opt.part_data:\n        np.random.seed(123)\n        train_ind = np.random.choice(len(train), int(len(train)*opt.portion), replace=False)\n        train = [train[t] for t in train_ind]\n        train_lab = [train_lab[t] for t in train_ind]\n\n    try:\n        params = np.load(\'./param_g.npz\')\n        if params[\'Wemb\'].shape == (opt.n_words, opt.embed_size):\n            print(\'Use saved embedding.\')\n            opt.W_emb = params[\'Wemb\']\n        else:\n            print(\'Emb Dimension mismatch: param_g.npz:\' + str(params[\'Wemb\'].shape) + \' opt: \' + str(\n                (opt.n_words, opt.embed_size)))\n            opt.fix_emb = False\n    except IOError:\n        print(\'No embedding file found.\')\n        opt.fix_emb = False\n\n    with tf.device(\'/gpu:1\'):\n        x_ = tf.placeholder(tf.int32, shape=[opt.batch_size, opt.maxlen])\n        x_mask_ = tf.placeholder(tf.float32, shape=[opt.batch_size, opt.maxlen])\n        keep_prob = tf.placeholder(tf.float32)\n        y_ = tf.placeholder(tf.float32, shape=[opt.batch_size, 10])\n        accuracy_, loss_, train_op, W_emb_ = emb_classifier(x_, x_mask_, y_, keep_prob, opt)\n        # merged = tf.summary.merge_all()\n\n    uidx = 0\n    max_val_accuracy = 0.\n    max_test_accuracy = 0.\n    # gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=1)\n    config = tf.ConfigProto(log_device_placement=False, allow_soft_placement=True)\n    config.gpu_options.allow_growth = True\n    np.set_printoptions(precision=3)\n    np.set_printoptions(threshold=np.inf)\n    saver = tf.train.Saver()\n\n    with tf.Session(config=config) as sess:\n        train_writer = tf.summary.FileWriter(opt.log_path + \'/train\', sess.graph)\n        test_writer = tf.summary.FileWriter(opt.log_path + \'/test\', sess.graph)\n        sess.run(tf.global_variables_initializer())\n        if opt.restore:\n            try:\n\n                t_vars = tf.trainable_variables()\n                # print([var.name[:-2] for var in t_vars])\n                save_keys = tensors_key_in_file(opt.save_path)\n                # print(save_keys.keys())\n                ss = set([var.name for var in t_vars]) & set([s + "":0"" for s in save_keys.keys()])\n                cc = {var.name: var for var in t_vars}\n                # only restore variables with correct shape\n                ss_right_shape = set([s for s in ss if cc[s].get_shape() == save_keys[s[:-2]]])\n\n                loader = tf.train.Saver(var_list=[var for var in t_vars if var.name in ss_right_shape])\n                loader.restore(sess, opt.save_path)\n\n                print(""Loading variables from \'%s\'."" % opt.save_path)\n                print(""Loaded variables:"" + str(ss))\n\n            except:\n                print(""No saving session, using random initialization"")\n                sess.run(tf.global_variables_initializer())\n\n        try:\n            for epoch in range(opt.max_epochs):\n                print(""Starting epoch %d"" % epoch)\n                kf = get_minibatches_idx(len(train), opt.batch_size, shuffle=True)\n                for _, train_index in kf:\n                    uidx += 1\n                    sents = [train[t] for t in train_index]\n                    x_labels = [train_lab[t] for t in train_index]\n                    x_labels = np.array(x_labels)\n                    x_labels = x_labels.reshape((len(x_labels), 10))\n\n                    x_batch, x_batch_mask = prepare_data_for_emb(sents, opt)\n\n                    _, loss = sess.run([train_op, loss_], feed_dict={x_: x_batch, x_mask_: x_batch_mask, y_: x_labels, keep_prob: opt.drop_rate})\n\n                    if uidx % opt.valid_freq == 0:\n                        train_correct = 0.0\n                        kf_train = get_minibatches_idx(500, opt.batch_size, shuffle=True)\n                        for _, train_index in kf_train:\n                            train_sents = [train[t] for t in train_index]\n                            train_labels = [train_lab[t] for t in train_index]\n                            train_labels = np.array(train_labels)\n                            train_labels = train_labels.reshape((len(train_labels), 10))\n                            x_train_batch, x_train_batch_mask = prepare_data_for_emb(train_sents, opt)  # Batch L\n\n                            train_accuracy = sess.run(accuracy_, feed_dict={x_: x_train_batch, x_mask_: x_train_batch_mask, y_: train_labels, keep_prob: 1.0})\n\n                            train_correct += train_accuracy * len(train_index)\n\n                        train_accuracy = train_correct / 500\n\n                        print(""Iteration %d: Training loss %f "" % (uidx, loss))\n                        print(""Train accuracy %f "" % train_accuracy)\n\n                        val_correct = 0.0\n                        kf_val = get_minibatches_idx(20000, opt.batch_size, shuffle=True)\n                        for _, val_index in kf_val:\n                            val_sents = [val[t] for t in val_index]\n                            val_labels = [val_lab[t] for t in val_index]\n                            val_labels = np.array(val_labels)\n                            val_labels = val_labels.reshape((len(val_labels), 10))\n                            x_val_batch, x_val_batch_mask = prepare_data_for_emb(val_sents, opt)\n\n                            val_accuracy = sess.run(accuracy_, feed_dict={x_: x_val_batch, x_mask_: x_val_batch_mask,\n                                                                          y_: val_labels, keep_prob: 1.0})\n\n                            val_correct += val_accuracy * len(val_index)\n\n                        val_accuracy = val_correct / 20000\n                        print(""Validation accuracy %f "" % val_accuracy)\n\n                        if val_accuracy > max_val_accuracy:\n                            max_val_accuracy = val_accuracy\n\n                            test_correct = 0.0\n                            kf_test = get_minibatches_idx(len(test), opt.batch_size, shuffle=True)\n                            for _, test_index in kf_test:\n                                test_sents = [test[t] for t in test_index]\n                                test_labels = [test_lab[t] for t in test_index]\n                                test_labels = np.array(test_labels)\n                                test_labels = test_labels.reshape((len(test_labels), 10))\n                                x_test_batch, x_test_batch_mask = prepare_data_for_emb(test_sents, opt)\n\n                                test_accuracy = sess.run(accuracy_,\n                                                         feed_dict={x_: x_test_batch, x_mask_: x_test_batch_mask,\n                                                                    y_: test_labels, keep_prob: 1.0})\n\n                                test_correct += test_accuracy * len(test_index)\n\n                            test_accuracy = test_correct / len(test)\n\n                            print(""Test accuracy %f "" % test_accuracy)\n\n                            max_test_accuracy = test_accuracy\n\n                print(""Epoch %d: Max Test accuracy %f"" % (epoch, max_test_accuracy))\n\n                emb = sess.run(W_emb_, feed_dict={x_: x_test_batch})\n\n                cPickle.dump([emb], open(""yahoo_emb_max_300.p"", ""wb""))\n\n            print(""Max Test accuracy %f "" % max_test_accuracy)\n\n        except KeyboardInterrupt:\n            # print \'Training interupted\'\n            print(\'Training interupted\')\n            print(""Max Test accuracy %f "" % max_test_accuracy)\n\nif __name__ == \'__main__\':\n    main()\n\n'"
model.py,62,"b'# -*- coding: utf-8 -*-\n""""""\nDinghan Shen\n\nBaseline Needs More Love: On Simple Word-Embedding-Based Models and Associated Pooling Mechanisms (ACL 2018)\n""""""\n\n\nimport tensorflow as tf\nfrom tensorflow.contrib import layers\nfrom tensorflow.contrib import learn\nfrom tensorflow.contrib import metrics\nfrom tensorflow.contrib import slim\n# from tensorflow.contrib.learn import monitors\nfrom tensorflow.contrib import framework\nfrom tensorflow.contrib.learn.python.learn import learn_runner\nfrom tensorflow.python.platform import tf_logging as logging\nfrom tensorflow.contrib.learn.python.learn.metric_spec import MetricSpec\nfrom tensorflow.contrib.legacy_seq2seq import embedding_rnn_decoder, sequence_loss, embedding_rnn_seq2seq, \\\n    embedding_tied_rnn_seq2seq\nimport pdb\nimport copy\nfrom utils import normalizing\nfrom tensorflow.python.ops import nn_ops, math_ops\nimport numpy as np\n\n\ndef embedding(features, opt, prefix=\'\', is_reuse=None):\n    """"""Customized function to transform batched x into embeddings.""""""\n    # Convert indexes of words into embeddings.\n    #  b = tf.get_variable(\'b\', [opt.embed_size], initializer = tf,random_uniform_initializer(-0.01, 0.01))\n    with tf.variable_scope(prefix + \'embed\', reuse=is_reuse):\n        if opt.fix_emb:\n            assert (hasattr(opt, \'W_emb\'))\n            assert (np.shape(np.array(opt.W_emb)) == (opt.n_words, opt.embed_size))\n            W = tf.get_variable(\'W\', initializer=opt.W_emb, trainable=True)\n            #pdb.set_trace()\n            print(""initialize word embedding finished"")\n        else:\n            weightInit = tf.random_uniform_initializer(-0.001, 0.001)\n            W = tf.get_variable(\'W\', [opt.n_words, opt.embed_size], initializer=weightInit)\n            # tf.stop_gradient(W)\n    if hasattr(opt, \'relu_w\') and opt.relu_w:\n        W = tf.nn.relu(W)\n\n    # W_norm = normalizing(W, 1)\n    word_vectors = tf.nn.embedding_lookup(W, features)\n\n    return word_vectors, W\n\n\ndef aver_emb_encoder(x_emb, x_mask):\n    """""" compute the average over all word embeddings """"""\n    x_mask = tf.expand_dims(x_mask, axis=-1)\n    x_mask = tf.expand_dims(x_mask, axis=-1)  # batch L 1 1\n\n    x_sum = tf.multiply(x_emb, x_mask)  # batch L emb 1\n    H_enc_0 = tf.reduce_sum(x_sum, axis=1, keep_dims=True)  # batch 1 emb 1\n    H_enc = tf.squeeze(H_enc_0, [1, 3])  # batch emb\n    x_mask_sum = tf.reduce_sum(x_mask, axis=1, keep_dims=True)  # batch 1 1 1\n    x_mask_sum = tf.squeeze(x_mask_sum, [2, 3])  # batch 1\n\n    H_enc = H_enc / x_mask_sum  # batch emb\n\n    return H_enc\n\n\ndef max_emb_encoder(x_emb, x_mask, opt):\n    """""" compute the max over every dimension of word embeddings """"""\n    x_mask_1 = tf.expand_dims(x_mask, axis=-1)\n    x_mask_1 = tf.expand_dims(x_mask_1, axis=-1)\n    H_enc = tf.nn.max_pool(tf.multiply(x_emb, x_mask_1), [1, opt.maxlen, 1, 1], [1, 1, 1, 1], \'VALID\')\n    H_enc = tf.squeeze(H_enc)\n\n    return H_enc\n\ndef concat_emb_encoder(x_emb, x_mask, opt):\n    """""" concat both the average and max over all word embeddings """"""\n    x_mask = tf.expand_dims(x_mask, axis=-1)\n    x_mask = tf.expand_dims(x_mask, axis=-1)  # batch L 1 1\n\n    x_sum = tf.multiply(x_emb, x_mask)  # batch L emb 1\n    H_enc = tf.reduce_sum(x_sum, axis=1, keep_dims=True)  # batch 1 emb 1\n    H_enc = tf.squeeze(H_enc, [1, 3])  # batch emb\n    x_mask_sum = tf.reduce_sum(x_mask, axis=1, keep_dims=True)  # batch 1 1 1\n    x_mask_sum = tf.squeeze(x_mask_sum, [2, 3])  # batch 1\n\n    H_enc_1 = H_enc / x_mask_sum  # batch emb\n\n    H_enc_2 = tf.nn.max_pool(x_emb, [1, opt.maxlen, 1, 1], [1, 1, 1, 1], \'VALID\')\n    H_enc_2 = tf.squeeze(H_enc_2, [1, 3])\n\n    H_enc = tf.concat([H_enc_1, H_enc_2], 1)\n\n    return H_enc\n\n\ndef discriminator_1layer(H, opt, dropout, prefix=\'\', num_outputs=1, is_reuse=None):\n    # last layer must be linear\n    H = tf.squeeze(H)\n    biasInit = tf.constant_initializer(0.001, dtype=tf.float32)\n    H_dis = layers.fully_connected(tf.nn.dropout(H, keep_prob=dropout), num_outputs=opt.H_dis,\n                                   biases_initializer=biasInit, activation_fn=tf.nn.relu, scope=prefix + \'dis_1\',\n                                   reuse=is_reuse)\n    return H_dis\n\n\ndef discriminator_0layer(H, opt, dropout, prefix=\'\', num_outputs=1, is_reuse=None):\n    H = tf.squeeze(H)\n    biasInit = tf.constant_initializer(0.001, dtype=tf.float32)\n    logits = layers.linear(tf.nn.dropout(H, keep_prob=dropout), num_outputs=num_outputs, biases_initializer=biasInit,\n                           scope=prefix + \'dis\', reuse=is_reuse)\n    return logits\n\n\ndef linear_layer(x, output_dim):\n    input_dim = x.get_shape().as_list()[1]\n    thres = np.sqrt(6.0 / (input_dim + output_dim))\n    W = tf.get_variable(""W"", [input_dim, output_dim], scope=prefix + \'_W\',\n                        initializer=tf.random_uniform_initializer(minval=-thres, maxval=thres))\n    b = tf.get_variable(""b"", [output_dim], scope=prefix + \'_b\', initializer=tf.constant_initializer(0.0))\n    return tf.matmul(x, W) + b\n\n\ndef discriminator_2layer(H, opt, dropout, prefix=\'\', num_outputs=1, is_reuse=None):\n    # last layer must be linear\n    # H = tf.squeeze(H, [1,2])\n    # pdb.set_trace()\n    biasInit = tf.constant_initializer(0.001, dtype=tf.float32)\n    H_dis = layers.fully_connected(tf.nn.dropout(H, keep_prob=dropout), num_outputs=opt.H_dis,\n                                   biases_initializer=biasInit, activation_fn=tf.nn.relu, scope=prefix + \'dis_1\',\n                                   reuse=is_reuse)\n    logits = layers.linear(tf.nn.dropout(H_dis, keep_prob=dropout), num_outputs=num_outputs,\n                           biases_initializer=biasInit, scope=prefix + \'dis_2\', reuse=is_reuse)\n    return logits\n\ndef discriminator_3layer(H, opt, dropout, prefix=\'\', num_outputs=1, is_reuse=None):\n    # last layer must be linear\n    # H = tf.squeeze(H, [1,2])\n    # pdb.set_trace()\n    biasInit = tf.constant_initializer(0.001, dtype=tf.float32)\n    H_dis = layers.fully_connected(tf.nn.dropout(H, keep_prob=dropout), num_outputs=opt.H_dis,\n                                   biases_initializer=biasInit, activation_fn=tf.nn.relu, scope=prefix + \'dis_1\',\n                                   reuse=is_reuse)\n    H_dis = layers.fully_connected(tf.nn.dropout(H_dis, keep_prob=dropout), num_outputs=opt.H_dis,\n                                   biases_initializer=biasInit, activation_fn=tf.nn.relu, scope=prefix + \'dis_2\',\n                                   reuse=is_reuse)\n    logits = layers.linear(tf.nn.dropout(H_dis, keep_prob=dropout), num_outputs=num_outputs,\n                           biases_initializer=biasInit, scope=prefix + \'dis_3\', reuse=is_reuse)\n    return logits\n\ndef discriminator_res(H, opt, dropout, prefix=\'\', num_outputs=1, is_reuse=None):\n    # last layer must be linear\n    # H = tf.squeeze(H, [1,2])\n    # pdb.set_trace()\n    biasInit = tf.constant_initializer(0.001, dtype=tf.float32)\n    H_dis_0 = layers.fully_connected(tf.nn.dropout(H, keep_prob=dropout), num_outputs=opt.embed_size,\n                                   biases_initializer=biasInit, activation_fn=None, scope=prefix + \'dis_1\',\n                                   reuse=is_reuse)\n    H_dis_0n = tf.nn.relu(H_dis_0)                               \n    H_dis_1 = layers.fully_connected(tf.nn.dropout(H_dis_0n, keep_prob=dropout), num_outputs=opt.embed_size,\n                                   biases_initializer=biasInit, activation_fn=None, scope=prefix + \'dis_2\',\n                                   reuse=is_reuse)\n    H_dis_1n = tf.nn.relu(H_dis_1) + H_dis_0\n    H_dis_2 = layers.fully_connected(tf.nn.dropout(H_dis_1n, keep_prob=dropout), num_outputs=opt.embed_size,\n                                   biases_initializer=biasInit, activation_fn=None, scope=prefix + \'dis_3\',\n                                   reuse=is_reuse)\n    H_dis_2n = tf.nn.relu(H_dis_2) + H_dis_1\n    H_dis_3 = layers.fully_connected(tf.nn.dropout(H_dis_2n, keep_prob=dropout), num_outputs=opt.embed_size,\n                                   biases_initializer=biasInit, activation_fn=None, scope=prefix + \'dis_4\',\n                                   reuse=is_reuse)\n\n    logits = layers.linear(tf.nn.dropout(H_dis_3, keep_prob=dropout), num_outputs=num_outputs,\n                           biases_initializer=biasInit, scope=prefix + \'dis_10\', reuse=is_reuse)\n    return logits\n'"
utils.py,10,"b'# -*- coding: utf-8 -*-\n""""""\nDinghan Shen\n\nBaseline Needs More Love: On Simple Word-Embedding-Based Models and Associated Pooling Mechanisms (ACL 2018)\n""""""\n\n\nimport numpy as np\nimport tensorflow as tf\nfrom collections import OrderedDict\nimport nltk\nfrom pycocoevalcap.bleu.bleu import Bleu\nfrom tensorflow.python import pywrap_tensorflow\nimport pdb\nimport data_utils\nimport sys\nfrom tensorflow.python.ops import clip_ops\nimport gensim\nfrom tensorflow.contrib.tensorboard.plugins import projector\nimport os\n\nimport matplotlib\nmatplotlib.use(\'Agg\')\nimport matplotlib.pyplot as plt\n\ndef sent2idx(text, wordtoix, opt, is_cnn = True):\n    \n    sent = [wordtoix[x] for x in text.split()]\n    \n    return prepare_data_for_cnn([sent for i in range(opt.batch_size)], opt)\n\n\ndef average_precision(actual, predicted):\n    """"""\n        Computes the average precision.\n        This function computes the average prescision between two lists of\n        items.\n        Parameters\n        ----------\n        actual : list\n                 A list of elements that are to be predicted (order doesn\'t matter)\n        predicted : list\n                    A list of predicted elements (order does matter)\n        Returns\n        -------\n        score : double\n                The average precision over the input lists\n    """"""\n\n    score = 0.0\n    num_hits = 0.0\n\n    for i, p in enumerate(predicted):\n        if p in actual and p not in predicted[:i]:\n            num_hits += 1.0\n            score += num_hits / (i + 1.0)\n\n    if not actual:\n        return 0.0\n\n    return score / len(actual)\n\n\ndef type_mean_average_precision(ixtoword, query, actual, predicted):\n    map_vocab = {}\n    map = [average_precision(a, p) for a, p in zip(actual, predicted)]\n    for i in range(len(query)):\n        q = query[i][0]\n        #pdb.set_trace()\n        if q[0] not in map_vocab.keys():\n            map_vocab[q[0]] = [map[i]]\n        else:\n            map_vocab[q[0]].append(map[i])\n\n    map_aver = {}\n    for k in map_vocab.keys():\n        map_aver[k] = np.mean(map_vocab[k])\n\n    return map_aver\n\ndef mean_average_precision(actual, predicted):\n    """"""\n        Computes the mean average precision.\n        This function computes the mean average precision between two lists\n        of lists of items.\n        Parameters\n        ----------\n        actual : list\n                 A list of lists of elements that are to be predicted\n                 (order doesn\'t matter in the lists)\n        predicted : list\n                    A list of lists of predicted elements\n                    (order matters in the lists)\n        Returns\n        -------\n        score : double\n                The mean average precision over the input lists\n        """"""\n\n    return np.mean([average_precision(a, p) for a, p in zip(actual, predicted)])\n\n\ndef reciprocal_rank(actual, predicted):\n    """"""\n        Computes the average precision.\n        This function computes the reciprocal rank between two lists of items.\n\n        Parameters\n        ----------\n        actual : list\n                 A list of elements that are to be predicted (order doesn\'t matter)\n        predicted : list\n                    A list of predicted elements (order does matter)\n        Returns\n        -------\n        score : double\n                The average precision over the input lists\n    """"""\n    for i, p in enumerate(predicted):\n        if p in actual:\n            score = 1.0/(i + 1.0)\n            break\n\n    if not actual:\n        return 0.0\n\n    return score\n\n\ndef mean_reciprocal_rank(actual, predicted):\n    """"""\n        Computes the mean average precision.\n        This function computes the mean average precision between two lists\n        of lists of items.\n        Parameters\n        ----------\n        actual : list\n                 A list of lists of elements that are to be predicted\n                 (order doesn\'t matter in the lists)\n        predicted : list\n                    A list of lists of predicted elements\n                    (order matters in the lists)\n        Returns\n        -------\n        score : double\n                The mean average precision over the input lists\n        """"""\n\n    return np.mean([reciprocal_rank(a, p) for a, p in zip(actual, predicted)])\n\n\ndef prepare_data_for_rank(q, a, opt):\n    new_q = prepare_data_for_cnn(q, opt)\n    new_a = prepare_data_for_cnn(a, opt)\n\n    return new_q, new_a\n\ndef prepare_data_for_emb_rank(q, a, opt):\n    new_q, new_q_mask = prepare_data_for_emb(q, opt)\n    new_a, new_a_mask = prepare_data_for_emb(a, opt)\n\n    return new_q, new_a, new_q_mask, new_a_mask\n\n\n\ndef prepare_data_for_cnn(seqs_x, opt):\n    maxlen=opt.maxlen\n    filter_h=opt.filter_shape\n    lengths_x = [len(s) for s in seqs_x]\n    # print lengths_x\n    if maxlen != None:\n        new_seqs_x = []\n        new_lengths_x = []\n        for l_x, s_x in zip(lengths_x, seqs_x):\n            if l_x < maxlen:\n                new_seqs_x.append(s_x)\n                new_lengths_x.append(l_x)\n        lengths_x = new_lengths_x\n        seqs_x = new_seqs_x\n        \n        if len(lengths_x) < 1:\n            return None, None\n    \n    pad = filter_h -1\n    x = []   \n    for rev in seqs_x:    \n        xx = []\n        for i in xrange(pad):\n            xx.append(0)\n        for idx in rev:\n            xx.append(idx)\n        while len(xx) < maxlen + 2*pad:\n            xx.append(0)\n        x.append(xx)\n    x = np.array(x, dtype=\'int32\')\n    return x\n\ndef prepare_data_for_rnn(seqs_x, opt, is_add_GO = True):\n    maxlen=opt.maxlen\n    lengths_x = [len(s) for s in seqs_x]\n    # print lengths_x\n    if maxlen != None:\n        new_seqs_x = []\n        new_lengths_x = []\n        for l_x, s_x in zip(lengths_x, seqs_x):\n            if l_x < maxlen:\n                new_seqs_x.append(s_x)\n                new_lengths_x.append(l_x)\n        lengths_x = new_lengths_x\n        seqs_x = new_seqs_x\n        \n        if len(lengths_x) < 1:\n            return None, None\n\n    n_samples = len(seqs_x)\n    maxlen_x = np.max(lengths_x)\n    x = np.zeros((n_samples, opt.sent_len)).astype(\'int32\')\n    for idx, s_x in enumerate(seqs_x):\n        if is_add_GO:\n            x[idx, 0] = opt.n_words-1  # GO symbol\n            x[idx, 1:lengths_x[idx]+1] = s_x\n        else:\n            x[idx, :lengths_x[idx]] = s_x\n    return x\n\ndef prepare_data_for_emb(seqs_x, opt):\n    maxlen = opt.maxlen\n    lengths_x = [len(s) for s in seqs_x]\n    if maxlen != None:\n        new_seqs_x = []\n        new_lengths_x = []\n        for l_x, s_x in zip(lengths_x, seqs_x):\n            if l_x < maxlen:\n                new_seqs_x.append(s_x)\n                new_lengths_x.append(l_x)\n            else:\n                new_seqs_x.append(s_x[:maxlen])\n                new_lengths_x.append(maxlen)\n        lengths_x = new_lengths_x\n        seqs_x = new_seqs_x\n\n        if len(lengths_x) < 1:\n            return None, None\n\n    n_samples = len(seqs_x)\n    maxlen_x = np.max(lengths_x)\n    x = np.zeros((n_samples, maxlen)).astype(\'int32\')\n    #x = np.zeros((maxlen_x, n_samples)).astype(\'int32\')\n    x_mask = np.zeros((n_samples, maxlen)).astype(\'float32\')\n    for idx, s_x in enumerate(seqs_x):\n        x[idx, :lengths_x[idx]] = s_x\n        # x_mask[idx, :lengths_x[idx]] = 1.\n        x_mask[idx, :lengths_x[idx]] = 1. # change to remove the real END token\n\n    return x, x_mask\n\ndef prepare_data_for_emb_cut(seqs_x, opt):\n    maxlen = opt.maxlen\n    lengths_x = [len(s) for s in seqs_x]\n    if maxlen != None:\n        new_seqs_x = []\n        new_lengths_x = []\n        for l_x, s_x in zip(lengths_x, seqs_x):\n            if l_x < maxlen:\n                new_seqs_x.append(s_x)\n                new_lengths_x.append(l_x)\n            else:\n                new_seqs_x.append(s_x[:maxlen])\n                new_lengths_x.append(maxlen)\n\n        lengths_x = new_lengths_x\n        seqs_x = new_seqs_x\n\n        if len(lengths_x) < 1:\n            return None, None\n\n    n_samples = len(seqs_x)\n    maxlen_x = np.max(lengths_x)\n    x = np.zeros((n_samples, maxlen)).astype(\'int32\')\n    #x = np.zeros((maxlen_x, n_samples)).astype(\'int32\')\n    x_mask = np.zeros((n_samples, maxlen)).astype(\'float32\')\n    for idx, s_x in enumerate(seqs_x):\n        x[idx, :lengths_x[idx]] = s_x\n        # x_mask[idx, :lengths_x[idx]] = 1.\n        x_mask[idx, :lengths_x[idx]-1] = 1. # change to remove the real END token\n\n    return x, x_mask\n\ndef restore_from_save(t_vars, sess, opt):\n    save_keys = tensors_key_in_file(opt.save_path)\n    #print(save_keys.keys()) \n    ss = set([var.name for var in t_vars])&set([s+"":0"" for s in save_keys.keys()])\n    cc = {var.name:var for var in t_vars}\n    ss_right_shape = set([s for s in ss if cc[s].get_shape() == save_keys[s[:-2]]])  # only restore variables with correct shape\n\n    #pdb.set_trace()\n    \n    if opt.reuse_discrimination:\n        ss2 = set([var.name[2:] for var in t_vars])&set([s+"":0"" for s in save_keys.keys()])\n        cc2 = {var.name[2:][:-2]:var for var in t_vars if var.name[2:] in ss2 if var.get_shape() == save_keys[var.name[2:][:-2]]}\n        for s_iter in ss_right_shape:\n            cc2[s_iter[:-2]] = cc[s_iter]\n        \n        loader = tf.train.Saver(var_list=cc2)\n        loader.restore(sess, opt.save_path)\n        print(""Loaded variables for discriminator:""+str(cc2.keys()))\n    \n    else:    \n        # for var in t_vars:\n        #     if var.name[:-2] in ss:\n        #         tf.assign(t_vars, save_keys[var.name[:-2]])\n        loader = tf.train.Saver(var_list= [var for var in t_vars if var.name in ss_right_shape])\n        loader.restore(sess, opt.save_path)\n        print(""Loading variables from \'%s\'."" % opt.save_path)\n        print(""Loaded variables:""+str(ss_right_shape))\n    \n    return loader\n    \n    \n_buckets = [(60,60)]    \n    \ndef read_data(source_path, target_path, opt):\n    """"""\n    From tensorflow tutorial translate.py\n    Read data from source and target files and put into buckets.\n    Args:\n    source_path: path to the files with token-ids for the source language.\n    target_path: path to the file with token-ids for the target language;\n      it must be aligned with the source file: n-th line contains the desired\n      output for n-th line from the source_path.\n    max_size: maximum number of lines to read, all other will be ignored;\n      if 0 or None, data files will be read completely (no limit).\n\n    Returns:\n    data_set: a list of length len(_buckets); data_set[n] contains a list of\n      (source, target) pairs read from the provided data files that fit\n      into the n-th bucket, i.e., such that len(source) < _buckets[n][0] and\n      len(target) < _buckets[n][1]; source and target are lists of token-ids.\n    """"""\n    data_set = [[] for _ in _buckets]\n    with tf.gfile.GFile(source_path, mode=""r"") as source_file:\n        with tf.gfile.GFile(target_path, mode=""r"") as target_file:\n            source, target = source_file.readline(), target_file.readline()            \n            counter = 0\n            while source and target and (not opt.max_train_data_size or counter < opt.max_train_data_size):\n                counter += 1\n                if counter % 100000 == 0:\n                    print(""  reading data line %d"" % counter)\n                    sys.stdout.flush()\n                source_ids = [int(x) for x in source.split()]\n                target_ids = [int(x) for x in target.split()]\n                target_ids.append(data_utils.EOS_ID)\n                for bucket_id, (source_size, target_size) in enumerate(_buckets):\n                    if opt.minlen <len(source_ids) < min(source_size, opt.maxlen) and opt.minlen <len(target_ids) < min(target_size, opt.maxlen):\n                        data_set[bucket_id].append([source_ids, target_ids])\n                        break\n                source, target = source_file.readline(), target_file.readline()\n            \n            \n            \n    return data_set    \n    \n    \n    \ndef prepare_data_for_cnn(seqs_x, opt): \n    maxlen=opt.maxlen\n    filter_h=opt.filter_shape\n    lengths_x = [len(s) for s in seqs_x]\n    # print lengths_x\n    if maxlen != None:\n        new_seqs_x = []\n        new_lengths_x = []\n        for l_x, s_x in zip(lengths_x, seqs_x):\n            if l_x < maxlen:\n                new_seqs_x.append(s_x)\n                new_lengths_x.append(l_x)\n        lengths_x = new_lengths_x\n        seqs_x = new_seqs_x\n        \n        if len(lengths_x) < 1  :\n            return None, None\n    \n    pad = filter_h -1\n    x = []   \n    for rev in seqs_x:    \n        xx = []\n        for i in xrange(pad):\n            xx.append(0)\n        for idx in rev:\n            xx.append(idx)\n        while len(xx) < maxlen + 2*pad:\n            xx.append(0)\n        x.append(xx)\n    x = np.array(x,dtype=\'int32\')\n    return x\n    \n    \n# def prepare_data_for_machine_translation(pair_x, opt):\n#     maxlen=opt.maxlen\n#     filter_h=opt.filter_shape\n#     def padding(p):\n#         pad = filter_h -1\n#         new_p = []\n#         pdb.set_trace()\n#         for it in p:\n#             if len(it)>= maxlen:\n#                 return None\n#             else:\n#                 new_p.append([0]*pad + it + [0]*(maxlen-len(it)+pad))\n#         return np.array(new_p)\n#     return [padding(pair) for pair in pair_x]\n    \n    \n    \n    \n\n    \n    \n          \n    \n\ndef tensors_key_in_file(file_name):\n    """"""Return tensors key in a checkpoint file.\n    Args:\n    file_name: Name of the checkpoint file.\n    """"""\n    try:\n        reader = pywrap_tensorflow.NewCheckpointReader(file_name)\n        return reader.get_variable_to_shape_map()\n    except Exception as e:  # pylint: disable=broad-except\n        print(str(e))\n        return None\n\n     \ndef get_minibatches_idx(n, minibatch_size, shuffle=False):\n    idx_list = np.arange(n, dtype=""int32"")\n\n    if shuffle:\n        np.random.shuffle(idx_list)\n\n    minibatches = []\n    minibatch_start = 0\n    for i in range(n // minibatch_size):\n        minibatches.append(idx_list[minibatch_start:\n                                    minibatch_start + minibatch_size])\n        minibatch_start += minibatch_size\n\n    # if (minibatch_start != n):\n    #     # Make a minibatch out of what is left\n    #     minibatches.append(idx_list[minibatch_start:])\n\n    return zip(range(len(minibatches)), minibatches)\n    \n    \n# def normalizing_L1(x, axis):\n#     norm = tf.sqrt(tf.reduce_sum(tf.square(x), axis=axis, keep_dims=True))\n#     normalized = x / (norm)\n#     return normalized   \n    \ndef normalizing(x, axis):    \n    norm = tf.sqrt(tf.reduce_sum(tf.square(x), axis=axis, keep_dims=True))\n    normalized = x / (norm)\n    return normalized\n    \ndef _p(pp, name):\n    return \'%s_%s\' % (pp, name)\n\ndef dropout(X, trng, p=0.):\n    if p != 0:\n        retain_prob = 1 - p\n        X = X / retain_prob * trng.binomial(X.shape, p=retain_prob, dtype=theano.config.floatX)\n    return X\n\n"""""" used for initialization of the parameters. """"""\n\ndef ortho_weight(ndim):\n    W = np.random.randn(ndim, ndim)\n    u, s, v = np.linalg.svd(W)\n    return u.astype(config.floatX)\n    \ndef uniform_weight(nin,nout=None, scale=0.05):\n    if nout == None:\n        nout = nin\n    W = np.random.uniform(low=-scale, high=scale, size=(nin, nout))\n    return W.astype(config.floatX)\n    \ndef normal_weight(nin,nout=None, scale=0.05):\n    if nout == None:\n        nout = nin\n    W = np.random.randn(nin, nout) * scale\n    return W.astype(config.floatX)\n    \ndef zero_bias(ndim):\n    b = np.zeros((ndim,))\n    return b.astype(config.floatX)\n\n""""""auxiliary function for KDE""""""\ndef log_mean_exp(A,b,sigma):\n    a=-0.5*((A-theano.tensor.tile(b,[A.shape[0],1]))**2).sum(1)/(sigma**2)\n    max_=a.max()\n    return max_+theano.tensor.log(theano.tensor.exp(a-theano.tensor.tile(max_,a.shape[0])).mean())\n\n\'\'\'calculate KDE\'\'\'\ndef cal_nkde(X,mu,sigma):\n    s1,updates=theano.scan(lambda i,s: s+log_mean_exp(mu,X[i,:],sigma), sequences=[theano.tensor.arange(X.shape[0])],outputs_info=[np.asarray(0.,dtype=""float32"")])\n    E=s1[-1]\n    Z=mu.shape[0]*theano.tensor.log(sigma*np.sqrt(np.pi*2))\n    return (Z-E)/mu.shape[0]\n\n\n"""""" BLEU score""""""\n# def cal_BLEU(generated, reference):\n#     #the maximum is bigram, so assign the weight into 2 half.\n#     BLEUscore = 0.0\n#     for g in generated:\n#         BLEUscore += nltk.translate.bleu_score.sentence_bleu(reference, g)\n#     BLEUscore = BLEUscore/len(generated)\n#     return BLEUscore\n\ndef cal_BLEU(generated, reference, is_corpus = False):\n    #print \'in BLEU score calculation\'\n    #the maximum is bigram, so assign the weight into 2 half.\n    BLEUscore = [0.0,0.0,0.0]\n    for idx, g in enumerate(generated):\n        if is_corpus:\n            score, scores = Bleu(4).compute_score(reference, {0: [g]})\n        else:\n            score, scores = Bleu(4).compute_score({0: [reference[0][idx]]} , {0: [g]})\n        #print g, score\n        for i, s in zip([0,1,2],score[1:]):\n            BLEUscore[i]+=s\n        #BLEUscore += nltk.translate.bleu_score.sentence_bleu(reference, g, weight)\n    BLEUscore[0] = BLEUscore[0]/len(generated)\n    BLEUscore[1] = BLEUscore[1]/len(generated)\n    BLEUscore[2] = BLEUscore[2]/len(generated)\n    return BLEUscore\n \ndef prepare_for_bleu(sentence):\n    sent=[x for x in sentence if x!=0]\n    while len(sent)<4:\n        sent.append(0)\n    #sent = \' \'.join([ixtoword[x] for x in sent])\n    sent = \' \'.join([str(x) for x in sent])\n    return sent\n\ndef _clip_gradients_seperate_norm(grads_and_vars, clip_gradients):\n  """"""Clips gradients by global norm.""""""\n  gradients, variables = zip(*grads_and_vars)\n  clipped_gradients = [clip_ops.clip_by_norm(grad, clip_gradients) for grad in gradients]\n  return list(zip(clipped_gradients, variables))\n\ndef load_embedding_vectors_glove_gensim(vocabulary, filename):\n    print(""loading embedding"")\n    model = gensim.models.KeyedVectors.load_word2vec_format(filename)\n    vector_size = model.vector_size\n    embedding_vectors = np.random.uniform(-0.25, 0.25, (len(vocabulary), vector_size))\n    glove_vocab = list(model.vocab.keys())\n    count = 0\n    mis_count = 0\n    for word in vocabulary.keys():\n        idx = vocabulary.get(word)\n        if word in glove_vocab:\n            embedding_vectors[idx] = model.wv[word]\n            count += 1\n        else:\n            mis_count += 1\n    print(""num of vocab in glove: {}"".format(count))\n    print(""num of vocab not in glove: {}"".format(mis_count))\n    return embedding_vectors\n\ndef load_class_embedding( wordtoidx, opt):\n    print(""load class embedding"")\n    name_list = [ k.lower().split(\' \') for k in opt.class_name]\n    id_list = [ [ wordtoidx[i] for i in l] for l in name_list]\n    value_list = [ [ opt.W_emb[i] for i in l]    for l in id_list]\n    value_mean = [ np.mean(l,0)  for l in value_list]\n    return np.asarray(value_mean)\n\ndef load_class_embedding_missing( wordtoidx, opt):\n    print(""load class embedding"")\n    name_list = [ k.lower().split(\' \') for k in opt.class_name]\n    # id_list = [ wordtoidx[i] for i in l if i in wordtoidx.keys() for l in name_list]\n    id_list = [ [ wordtoidx.get(i,-1) for i in l] for l in name_list]\n    # id_list_nomissing = [ [  for i in l]    for l in id_list]\n    value_list = [ [ opt.W_emb[i] if i >= 0 else np.random.normal(np.zeros([opt.embed_size] ,dtype=np.float32), 0.5 * np.ones([ opt.embed_size], dtype=np.float32 )) for i in l ]    for l in id_list]\n    # value_list = [ opt.W_emb[l] for l in id_list]\n    value_mean = [ np.mean(l,0)  for l in value_list]\n    return np.asarray(value_mean)\n    # return np.asarray(value_list)\n\ndef load_class_embedding_total( wordtoidx, opt):\n    print(""load class embedding"")\n    name_list = [ k.lower().split(\' \') for k in opt.class_name]\n    id_list = [ [ wordtoidx[i] for i in l] for l in name_list]\n    value_list = [ [ opt.W_emb[i] for i in l]    for l in id_list]\n\n    value_total = []\n    for i in value_list:\n        for j in i:\n            value_total.append(j)\n    \n    return np.asarray(value_total)\n\n\ndef embedding_view(EMB, y, EMB_C, sess, opt):\n\n    EMB = [(x / np.linalg.norm(x)).tolist()  for x in EMB]\n    EMB_C = [(x / np.linalg.norm(x) ).tolist() for x in EMB_C]\n\n\n    \n    embedding_var = tf.Variable(EMB + EMB_C,  name=\'Embedding_of_sentence\')\n    sess.run(embedding_var.initializer)\n    EB_summary_writer = tf.summary.FileWriter(opt.log_path)\n    config = projector.ProjectorConfig()\n    embedding = config.embeddings.add()\n    embedding.metadata_path = os.path.join(opt.log_path, \'metadata.tsv\')\n    projector.visualize_embeddings(EB_summary_writer, config)\n    saver = tf.train.Saver([embedding_var])\n    saver.save(sess, os.path.join(opt.log_path, \'model2.ckpt\'), 1)\n    metadata_file = open(os.path.join(opt.log_path, \'metadata.tsv\'), \'w\')\n    metadata_file.write(\'ClassID\\tClass\\n\')\n    for i in range(len(y)):\n        metadata_file.write(\'%06d\\t%s\\n\' % (y[i], opt.class_name[y[i]]))\n    for i in range(opt.num_class):\n        metadata_file.write(\'%06d\\t%s\\n\' % (i, ""class_""+opt.class_name[i]))\n    metadata_file.close()\n    print(""embedding created"")\n\ndef embedding_center(EMB, y, EMB_C, opt):\n\n    # EMB = [(x / np.linalg.norm(x)).tolist()  for x in EMB]\n    # EMB_C = [(x / np.linalg.norm(x) ).tolist() for x in EMB_C]\n\n    EMB_array = np.asarray(EMB)\n    EMB_C_array = np.asarray(EMB_C)\n\n    EMB_mean = np.mean(EMB_array, 0)\n    EMB_C_mean = np.mean(EMB_C_array, 0)\n\n\n    num_class = opt.num_class\n    emb_sep = [[] for i in range(num_class)]\n    for ie, iy in zip(EMB, y):\n        emb_sep[iy].append(ie)\n    emb_array = np.asarray(emb_sep)\n    emb_center = np.mean(emb_array, 1)\n\n    emb_center_norm = np.apply_along_axis(lambda x: (x)/np.linalg.norm(x ), 1, emb_center )\n    class_norm = np.apply_along_axis(lambda x: (x )/np.linalg.norm(x), 1, np.asarray(EMB_C) )\n\n    # emb_center_norm = np.apply_along_axis(lambda x: (x)/np.linalg.norm(x ), 1, emb_center - EMB_mean)\n    # class_norm = np.apply_along_axis(lambda x: (x )/np.linalg.norm(x), 1, np.asarray(EMB_C) - EMB_C_mean)\n\n    # emb_center_norm = np.apply_along_axis(lambda x: (x- EMB_mean)/np.linalg.norm(x -EMB_mean), 1, emb_center)\n    # class_norm = np.apply_along_axis(lambda x: (x - EMB_mean)/np.linalg.norm(x-EMB_mean), 1, np.asarray(EMB_C))\n\n    # corr_matrix = np.matmul( emb_center,   np.asarray(EMB_C))\n    \n    \n\n    corr_matrix = np.matmul( emb_center_norm,   class_norm.T)\n    # corr_matrix = np.matmul( emb_center,  np.asarray(EMB_C).T)\n\n    plt.matshow(corr_matrix)\n    plt.colorbar()\n    plt.savefig(opt.log_path+\'/covariance.pdf\')\n    np.save(opt.log_path + \'/covariance.npy\', corr_matrix)\n\n    \n\n\n\n\n\n\n\n'"
pycocoevalcap/__init__.py,0,"b""__author__ = 'tylin'\n"""
pycocoevalcap/eval.py,0,"b'__author__ = \'tylin\'\nfrom tokenizer.ptbtokenizer import PTBTokenizer\nfrom bleu.bleu import Bleu\nfrom meteor.meteor import Meteor\nfrom cider.cider import Cider\nfrom rouge.rouge import Rouge\n\nclass COCOEvalCap:\n    def __init__(self, coco, cocoRes):\n        self.evalImgs = []\n        self.eval = {}\n        self.imgToEval = {}\n        self.coco = coco\n        self.cocoRes = cocoRes\n        self.params = {\'image_id\': coco.getImgIds()}\n\n    def evaluate(self):\n        imgIds = self.params[\'image_id\']\n        # imgIds = self.coco.getImgIds()\n        gts = {}\n        res = {}\n        for imgId in imgIds:\n            gts[imgId] = self.coco.imgToAnns[imgId]\n            res[imgId] = self.cocoRes.imgToAnns[imgId]\n\n        # =================================================\n        # Set up scorers\n        # =================================================\n        print \'tokenization...\'\n        tokenizer = PTBTokenizer()\n        gts  = tokenizer.tokenize(gts)\n        res = tokenizer.tokenize(res)\n\n        # =================================================\n        # Set up scorers\n        # =================================================\n        print \'setting up scorers...\'\n        scorers = [\n            (Bleu(4), [""Bleu_1"", ""Bleu_2"", ""Bleu_3"", ""Bleu_4""]),\n            (Meteor(),""METEOR""),\n            (Rouge(), ""ROUGE_L""),\n            (Cider(), ""CIDEr"")\n        ]\n\n        # =================================================\n        # Compute scores\n        # =================================================\n        for scorer, method in scorers:\n            print \'computing %s score...\'%(scorer.method())\n            score, scores = scorer.compute_score(gts, res)\n            if type(method) == list:\n                for sc, scs, m in zip(score, scores, method):\n                    self.setEval(sc, m)\n                    self.setImgToEvalImgs(scs, gts.keys(), m)\n                    print ""%s: %0.3f""%(m, sc)\n            else:\n                self.setEval(score, method)\n                self.setImgToEvalImgs(scores, gts.keys(), method)\n                print ""%s: %0.3f""%(method, score)\n        self.setEvalImgs()\n\n    def setEval(self, score, method):\n        self.eval[method] = score\n\n    def setImgToEvalImgs(self, scores, imgIds, method):\n        for imgId, score in zip(imgIds, scores):\n            if not imgId in self.imgToEval:\n                self.imgToEval[imgId] = {}\n                self.imgToEval[imgId][""image_id""] = imgId\n            self.imgToEval[imgId][method] = score\n\n    def setEvalImgs(self):\n        self.evalImgs = [eval for imgId, eval in self.imgToEval.items()]'"
intrinsic_dimension/general/__init__.py,0,b''
intrinsic_dimension/general/image_preproc.py,0,"b""import numpy as np\n\n\n\nclass ImagePreproc(object):\n    '''Class to handle common image preprocessing (center crops or\n    random crops with random flips).\n    '''\n    \n    def __init__(self):\n        self.buf = None\n\n    def get_buffer(self, shape, dtype):\n        if self.buf is None or self.buf.shape != shape or self.buf.dtype != dtype:\n            print 'ImagePreproc: creating new buffer'\n            self.buf = np.zeros(shape, dtype)\n        return self.buf\n        \n    def center_crops(self, dat, crop_size):\n        '''Returns the center crops.\n        dat: (b, 0, 1, c)\n        crop_size: e.g. (227,227)\n        '''\n\n        nims = dat.shape[0]\n        #nch = 3\n        nch = dat.shape[-1]\n        ret_shape = (nims, crop_size[0], crop_size[1], nch)\n        ret = self.get_buffer(ret_shape, dtype=dat.dtype)   # Reuse buffer if possible\n        off0 = (dat.shape[1]-crop_size[0])/2\n        off1 = (dat.shape[2]-crop_size[1])/2\n        ret = dat[:, off0:off0+crop_size[0], off1:off1+crop_size[1], :]\n        return ret\n\n    def random_crops(self, dat, crop_size, mirror=True):\n        '''Returns random crops of the given size\n        dat: (b, 0, 1, c)\n        crop_size: e.g. (227,227)\n        '''\n\n        nims = dat.shape[0]\n        #nch = 3 \n        nch = dat.shape[-1]\n        ret_shape = (nims, crop_size[0], crop_size[1], nch)\n        ret = self.get_buffer(ret_shape, dtype=dat.dtype)   # Reuse buffer if possible\n        maxoff0 = dat.shape[1]-crop_size[0]\n        maxoff1 = dat.shape[2]-crop_size[1]\n        off0s = np.random.randint(0,maxoff0,nims)\n        off1s = np.random.randint(0,maxoff1,nims)\n        domirror = np.random.randint(0,2,nims)\n        for ii in xrange(nims):\n            off0 = off0s[ii]\n            off1 = off1s[ii]\n            if mirror and domirror[ii] == 0:\n                ret[ii] = dat[ii, off0:off0+crop_size[0], off1:off1+crop_size[1], :][:,::-1]    # reverse column dimension\n            else:\n                ret[ii] = dat[ii, off0:off0+crop_size[0], off1:off1+crop_size[1], :]\n        return ret\n\n\n    def color_normalize(self, dat, mean, std):\n        '''normalize each color channel with provided mean and std'''\n        nims = dat.shape[0]\n        nch = 3\n        ret_shape = (nims, dat.shape[1], dat.shape[2], nch)\n        ret = self.get_buffer(ret_shape, dtype=dat.dtype)   # Reuse buffer if possible\n        \n        for ii in xrange(nch):\n            ret[:,:,:,ii] = (dat[:,:,:,ii] - mean[ii]) / std[ii]\n        return ret\n\n"""
intrinsic_dimension/general/stats_buddy.py,0,"b'import re\nimport bisect\nfrom colorama import Style\nimport numpy as np\nimport time\n\n\nclass StatsBuddy(object):\n    \'\'\'Your training stat collecting buddy!\n\n    epochs: epoch E is after seeing and updating from the entire training set E times.\n    train_iter: train iter T is after seeing and updating from T train mini-batches.\n\n    Both start at 0, which implies zero training.\'\'\'\n\n    def __init__(self, pretty_replaces=None, default_pretty_replaces=True):\n        self._epoch = 0\n        self._train_iter = 0\n        self._wall = None\n        self._wall_total = 0      # Saved time, perhaps from other runs\n        self._pretty_replaces = []\n        if default_pretty_replaces:\n            self._pretty_replaces.extend([\n                (\'train_\', \'\'),\n                (\'val_\', \'\'),\n                (\'test_\', \'\'),\n                (\'loss\', \'l\'),\n                (\'accuracy\', \'acc\'),\n                (\'cross_entropy\',\'xe\'),\n                (\'cross_ent\',\'xe\'),\n                (\'euclidean\',\'euc\'),\n                (\':0\',\'\'),\n            ])\n        if pretty_replaces:\n            self._pretty_replaces.extend(pretty_replaces)\n\n        # Data is stored as dict of four lists: [epoch_list, train_iter_list, weight_list, value_list]\n        # Each of the four lists is the same length.\n        self._data = {}\n\n    def _get_fetch_kwargs(self, raise_on_empty=True, empty_val=-123, assert_sync_epoch=True):\n        return raise_on_empty, empty_val, assert_sync_epoch\n \n    @property\n    def epoch(self):\n        return self._epoch\n        \n    @property\n    def train_iter(self):\n        return self._train_iter\n        \n    def tic(self):\n        # Just need to call once on model creation.\n        # Must also be called when loading a saved StatsBuddy from disk and resuming run!\n        self._wall = time.time()\n        \n    def toc(self):\n        assert self._wall, \'toc called without tic\'\n        elapsed = time.time() - self._wall\n        self._wall_total += elapsed\n        self._wall = time.time()\n        return self._wall_total\n        \n    def inc_epoch(self):\n        self._epoch += 1\n\n    def inc_train_iter(self):\n        self._train_iter += 1\n    \n    def note(self, **kwargs):\n        \'\'\'Main stat collection function. See below for methods providing various syntactic sugar.\'\'\'\n        weight = kwargs[\'_weight\'] if \'_weight\' in kwargs else 1.0\n        for key in sorted(kwargs.keys()):\n            if key == \'_weight\':\n                continue\n            value = kwargs[key]\n            #print key, value\n            self.note_one(key, value, weight=weight)\n            \n    def note_weighted(self, _weight, **kwargs):\n        \'\'\'Convenience function to call note with explicit weight.\'\'\'\n        assert \'_weight\' not in kwargs, \'Provided weight twice (via positional arg and kwarg)\'\n        self.note(_weight=_weight, **kwargs)\n\n    def note_weighted_list(self, _weight, name_list, value_list, prefix=\'\', suffix=\'\'):\n        \'\'\'Convenience function to call note with explicit weight and\n        list of names and values. Prefix and/or suffix, if given, are\n        concatenated to the beginnning and/or end of each name.\n        \'\'\'\n        assert len(name_list) == len(value_list), \'length mismatch\'\n        for name,value in zip(name_list, value_list):\n            final_name = prefix + name + suffix\n            self.note_one(final_name, value, weight=_weight)\n\n    def note_list(self, name_list, value_list, prefix=\'\', suffix=\'\'):\n        \'\'\'Convenience function to call weighted_note_list with a\n        weight of 1.0\n        \'\'\'\n        self.note_weighted_list(1.0, name_list, value_list, prefix=prefix, suffix=suffix)\n\n    def note_one(self, key, value, weight=1.0):\n        epoch_list, train_iter_list, weight_list, value_list = self._data.setdefault(key, [[], [], [], []])\n        epoch_list.append(self.epoch)\n        train_iter_list.append(self.train_iter)\n        weight_list.append(weight)\n        value_list.append(value)\n        #print \'Noted: %20s, e: %d, ti: %d, w: %g, v: %g\' % (key, self.epoch, self.train_iter, weight, value)\n\n    def last(self, *args, **kwargs):\n        \'\'\'Get last values as list\'\'\'\n        raise_on_empty, empty_val, assert_sync_epoch = self._get_fetch_kwargs(**kwargs)\n        last_as_dict = self.last_as_dict(*args, raise_on_empty=raise_on_empty, empty_val=empty_val)\n        return [last_as_dict[key] for key in args]\n\n    def last_as_dict(self, *args, **kwargs):\n        \'\'\'Get last values as dict. Not guaranteed for each value to be at the same epoch or training iteration!\'\'\'\n        raise_on_empty, empty_val, assert_sync_epoch = self._get_fetch_kwargs(**kwargs)\n        ret = {}\n        for key in args:\n            epoch_list, train_iter_list, weight_list, value_list = self._data.setdefault(key, [[], [], [], []])\n            if value_list:\n                ret[key] = value_list[-1]\n            else:\n                if raise_on_empty:\n                    raise Exception(\'No value for %s yet recorded\' % key)\n                else:\n                    ret[key] = empty_val\n        return ret\n\n    def last_list_re(self, regex, **kwargs):\n        ret = []\n        for key in sorted(self._data.keys()):\n            if re.search(regex, key):\n                ret.append((key, self.last(key, **kwargs)[0]))\n        return ret\n\n    def last_pretty_re(self, regex, style=\'\', **kwargs):\n        keys_values = self.last_list_re(regex, **kwargs)\n        return self._summary_pretty_re(keys_values, style=style)\n        \n    def epoch_mean(self, *args, **kwargs):\n        raise_on_empty, empty_val, assert_sync_epoch = self._get_fetch_kwargs(**kwargs)\n        means_as_dict = self.epoch_mean_as_dict(*args, raise_on_empty=raise_on_empty, empty_val=empty_val)\n        return [means_as_dict[key] for key in args]\n        \n    def epoch_mean_as_dict(self, *args, **kwargs):\n        \'\'\'Get mean of each field over most recently recorded epoch,\n        as dict. Not guaranteed to be the same epoch for each value\n        unless assert_sync_epoch is True.\n        \'\'\'\n        raise_on_empty, empty_val, assert_sync_epoch = self._get_fetch_kwargs(**kwargs)\n        ret = {}\n        ep = None\n        for key in args:\n            epoch_list, train_iter_list, weight_list, value_list = self._data.setdefault(key, [[], [], [], []])\n            if value_list:\n                if ep is None:\n                    ep = epoch_list[-1]\n                if assert_sync_epoch:\n                    assert ep == epoch_list[-1], \'Epoch mismatch between requested epoch means\'\n                else:\n                    ep = epoch_list[-1]\n                ep_end = len(epoch_list)\n                ep_begin = bisect.bisect_left(epoch_list, ep)\n                #print \'Taking epoch mean over %d records\' % (ep_end - ep_begin)\n                assert ep_begin != ep_end, \'Logic error with bisect_left or data insertion order.\'\n                values = np.array(value_list[ep_begin:ep_end])\n                weights = np.array(weight_list[ep_begin:ep_end])\n                \n                # remove nan from `values` and `weights` array\n                valid_ids = np.where(~np.isnan(values))[0]\n                values = values[valid_ids]\n                weights = weights[valid_ids]\n\n                if len(valid_ids) == 0:\n                    ret[key] = np.nan\n                else:\n                    weights = weights / float(max(1e-6, weights.sum()))\n                    assert len(values.shape) == 1, \'expected vector\'\n                    assert len(weights.shape) == 1, \'expected vector\'\n                    ret[key] = np.dot(values, weights)\n            else:\n                if raise_on_empty:\n                    raise Exception(\'No value for %s yet recorded\' % key)\n                else:\n                    ret[key] = empty_val\n        return ret\n        \n    def epoch_mean_summary_re(self, regex, **kwargs):\n        return \', \'.join(self.epoch_mean_list_re(regex, **kwargs))\n\n    def epoch_mean_pretty_re(self, regex, style=\'\', **kwargs):\n        keys_values = self.epoch_mean_list_re(regex, **kwargs)\n        return self._summary_pretty_re(keys_values, style=style)\n        \n    def epoch_mean_list_re(self, regex, **kwargs):\n        ret = []\n        for key in sorted(self._data.keys()):\n            if re.search(regex, key):\n                ret.append((key, self.epoch_mean(key, **kwargs)[0]))\n        return ret\n\n    def epoch_mean_list_all(self, **kwargs):\n        ret = []\n        for key in sorted(self._data.keys()):\n            ret.append((key, self.epoch_mean(key, **kwargs)[0]))\n        return ret\n\n    def _summary_pretty_re(self, keys_values, style=\'\'):\n        \'\'\'Produce a short, printable summary. Strips ""train_"" and ""test_"" strings assuming they will be printed elsewhere.\'\'\'\n        ret = []\n        losses_seen = 0\n        for key, value in keys_values:\n            short = key\n            for orig,new in self._pretty_replaces:\n                short = short.replace(orig, new)\n            tup = (short, value)\n            if key in (\'loss\', \'train_loss\', \'val_loss\', \'test_loss\'):\n                ret.insert(0, tup)\n                losses_seen += 1\n            elif \'loss\' in key:\n                ret.insert(losses_seen, tup)\n                losses_seen += 1\n            else:\n                ret.append(tup)\n        if style:\n            return \', \'.join([\'%s: %s%7s%s\' % (tt[0], style, \'%.4f\' % tt[1], Style.RESET_ALL) for tt in ret])\n        else:\n            return \', \'.join([\'%s: %.4f\' % (tt[0], tt[1]) for tt in ret])\n\n    def data_per_iter(self):\n        ret = {}\n        for key in self._data.keys():\n            ret[key] = {}\n            ret[key][\'iter\'] = np.array(self._data[key][1])\n            ret[key][\'val\'] = np.array(self._data[key][3])\n        return ret\n'"
intrinsic_dimension/general/tfutil.py,45,"b""import os\nimport numpy as np\nfrom orderedset import OrderedSet\nimport pdb\nfrom IPython import embed\n\nimport tensorflow as tf\n\n\n\n########################\n# Logging helpers\n########################\n\ndef get_ptt_names(name):\n    '''Gets param/train/test summary names. Just converts, e.g.,\n    foo       ->       foo,       foo__train,       foo__test\n    scope/foo -> scope/foo, scope/foo__train, scope/foo__test\n    '''\n    splits = tuple(name.rsplit('/',1))\n    if len(splits) == 1:\n        return '%s' % name, '%s__train' % name, '%s__test' % name\n    else:\n        # len 2\n        return '%s/%s' % splits, '%s/%s__train' % splits, '%s/%s__test' % splits\n    \n\ndef normalize_name(name):\n    '''Returns a normalized form of name, replacing : with _'''\n    return name.replace(':', '_')\n\n\ndef hist_summaries(*args, **kwargs):\n    '''Add tf.histogram_summary for each variable in variables'''\n    for var in args:\n        hist_summary(var, **kwargs)\n\ndef hist_summaries_param(*args, **kwargs):\n    kwargs['param'] = True\n    hist_summaries(*args, **kwargs)\n\ndef hist_summaries_traintest(*args, **kwargs):\n    kwargs['traintest'] = True\n    hist_summaries(*args, **kwargs)\n\ndef hist_summaries_train(*args, **kwargs):\n    kwargs['train'] = True\n    hist_summaries(*args, **kwargs)\n\ndef hist_summaries_test(*args, **kwargs):\n    kwargs['test'] = True\n    hist_summaries(*args, **kwargs)\n\n\ndef hist_summary(var, name=None, traintest=False, param=False, train=False, test=False, orig_collection='orig_histogram'):\n    assert sum([int(v) for v in (traintest, param, train, test)]) == 1, 'exactly one of {traintest,train,test,param} should be true'\n    if name is None:\n        name = var.name\n    param_name,train_name,test_name = get_ptt_names(name)\n    if traintest:\n        train = True\n        test = True\n    if param:\n        tf.summary.histogram(normalize_name(param_name), var, collections=['param_collection', orig_collection])\n        #print 'Adding summary.histogram for %s in collections %s, %s' % (var, 'param_collection', orig_collection)\n    if train:\n        tf.summary.histogram(normalize_name(train_name), var, collections=['train_collection', orig_collection])\n        #print 'Adding summary.histogram for %s in collections %s, %s' % (var, 'train_collection', orig_collection)\n    if test:\n        tf.summary.histogram(normalize_name(test_name), var, collections=['test_collection', orig_collection])\n        #print 'Adding summary.histograms for %s in collections %s, %s' % (var, 'test_collection', orig_collection)\n        \ndef scalar_summaries(*args, **kwargs):\n    '''Add tf.summary.scalar for each variable in variables'''\n    for var in args:\n        scalar_summary(var, **kwargs)\n\ndef scalar_summaries_param(*args, **kwargs):\n    kwargs['param'] = True\n    scalar_summaries(*args, **kwargs)\n\ndef scalar_summaries_traintest(*args, **kwargs):\n    kwargs['traintest'] = True\n    scalar_summaries(*args, **kwargs)\n\ndef scalar_summary(var, name=None, traintest=False, param=False, also_hist=False, orig_collection='orig_scalar'):\n    '''Add tf.summary.scalar for each variable in variables'''\n    assert traintest or param, 'one should be true'\n    if name is None:\n        name = var.name\n    param_name, train_name, test_name = get_ptt_names(name)\n    if param:\n        tf.summary.scalar(normalize_name(param_name), var, collections=['param_collection', orig_collection])\n        #print 'Adding summary.scalar for %s in collections %s, %s' % (var, 'param_collection', orig_collection)\n    if traintest:\n        tf.summary.scalar(normalize_name(train_name), var, collections=['train_collection', orig_collection])\n        #print 'Adding summary.scalar for %s in collections %s, %s' % (var, 'train_collection', orig_collection)\n        tf.summary.scalar(normalize_name(test_name), var, collections=['test_collection', orig_collection])\n        #print 'Adding summary.scalar for %s in collections %s, %s' % (var, 'test_collection', orig_collection)\n\n    if also_hist:\n        # HACK: also add hist summary for scalars to show them also on the\n        # Histogram pane. Need to provide a unique name so the histogram\n        # summary doesn't conflict with the scalar summary\n        hist_summary(var, name=normalize_name(name + '_(scalar)'), traintest=traintest, param=param, orig_collection=orig_collection)\n\n\ndef log_scalars(writer, iters, scalars_dict, prefix=None):\n    '''Manually log scalar values. Use like this:\n\n    log_scalars(writer, iters, {'test_loss': mean_test_loss,\n                                'test_loss_spring': mean_test_loss_spring,\n                                'test_loss_cross_ent': mean_test_loss_cross_ent,\n                                'test_accuracy': mean_test_acc})\n    '''\n\n    if not prefix:\n        prefix = ''\n\n    if len(prefix) > 0 and not prefix.endswith('/'):\n        prefix = prefix + '/'\n        \n    for key, val in scalars_dict.iteritems():\n        if hasattr(val, 'dtype'):\n            val = np.asscalar(val)   # Convert, e.g., numpy.float32 -> float\n        writer.add_summary(tf.Summary(value=[tf.Summary.Value(tag='%s%s' % (prefix, key), simple_value=val)]).SerializeToString(), iters)\n\n\ndef image_summaries(*args, **kwargs):\n    '''Add tf.image_summary for each variable in variables'''\n    for var in args:\n        image_summary(var, **kwargs)\n\ndef image_summaries_param(*args, **kwargs):\n    kwargs['param'] = True\n    image_summaries(*args, **kwargs)\n\ndef image_summaries_traintest(*args, **kwargs):\n    kwargs['traintest'] = True\n    image_summaries(*args, **kwargs)\n\ndef image_summaries_train(*args, **kwargs):\n    kwargs['train'] = True\n    image_summaries(*args, **kwargs)\n\ndef image_summaries_test(*args, **kwargs):\n    kwargs['test'] = True\n    image_summaries(*args, **kwargs)\n\n\ndef image_summary(var, name=None, traintest=False, param=False, train=False, test=False, orig_collection='orig_image'):\n    assert sum([int(v) for v in (traintest, param, train, test)]) == 1, 'exactly one of {traintest,train,test,param} should be true'\n    if name is None:\n        name = var.name\n    param_name,train_name,test_name = get_ptt_names(name)\n    if traintest:\n        train = True\n        test = True\n    if param:\n        tf.image_summary(normalize_name(param_name), var, collections=['param_collection', orig_collection])\n        #print 'Adding image_summary for %s in collections %s, %s' % (var, 'param_collection', orig_collection)\n    if train:\n        tf.image_summary(normalize_name(train_name), var, collections=['train_collection', orig_collection])\n        #print 'Adding image_summary for %s in collections %s, %s' % (var, 'train_collection', orig_collection)\n    if test:\n        tf.image_summary(normalize_name(test_name), var, collections=['test_collection', orig_collection])\n        #print 'Adding image_summary for %s in collections %s, %s' % (var, 'test_collection', orig_collection)\n        \n\ndef add_grads_and_vars_hist_summaries(grads_and_vars):\n    '''Adds param summary of var and hist summaries of grad values for\n    the given list of (grad,var) tuples. Usually these tuples will\n    come from the optimizer, e.g. via:\n\n    grads_and_vars = opt_rest.compute_gradients(model.v.loss, model.trainable_weights())\n    '''\n\n    for grad, var in grads_and_vars:\n        if grad is None:\n            continue\n        grad_name = '%s__grad' % var.name\n        hist_summaries_train(grad, name=grad_name)\n        hist_summaries_param(var)\n\n\ndef add_grad_summaries(grads_and_vars, add_summaries_train=True, quiet=False):\n    # Add summary nodes for grad values and prints a summary as well\n    if not quiet:\n        print '\\nGrads:'\n    for grad, var in grads_and_vars:\n        if grad is None:\n            continue   # skip grads that are None (corner case: not computed because model.loss has no dependence?)\n        grad_name = '%s/%s__grad' % tuple(var.name.rsplit('/', 1))\n        if not quiet:\n            print '  ', grad_name, grad\n        if add_summaries_train:\n            hist_summaries_train(grad, name=grad_name)\n    if not quiet:\n        print\n\n\n########################\n# TF operation helpers\n########################\n\ndef hacked_tf_one_hot(indices, depth, on_value, off_value, name=None):\n    '''Emulates new tf.one_hot in master.\n    # Real signature:    tf.one_hot(indices, depth, on_value, off_value, axis=None, name=None)\n    # Assumed signature: tf.one_hot(indices, depth, on_value, off_value, axis=-1,   name=None)\n\n    Not needed if using newer versions of TensorFlow.\n    '''\n    \n    N = tf.shape(indices)[0]\n    range_Nx1 = tf.expand_dims(tf.to_int64(tf.range(N)), 1)\n    indices_Nx1 = tf.expand_dims(indices, 1)\n    concat = tf.concat(1, [range_Nx1, indices_Nx1])\n    as_dense = tf.sparse_to_dense(concat,\n                                  tf.to_int64(tf.pack([N, depth])), # Assumption: axis=-1\n                                  on_value, off_value)\n    one_hot = tf.reshape(as_dense, (-1, depth), name=name)\n    \n    return one_hot\n\n\ndef hacked_tf_nn_softmax(logits, name=None):\n    '''Like tf.nn.softmax but casts to float64 first as a workaround for this bug:\n    https://github.com/tensorflow/tensorflow/issues/4425\n    '''\n\n    logits_64 = tf.cast(logits, tf.float64)\n    out_64 = tf.nn.softmax(logits_64)\n    out_32 = tf.cast(out_64, tf.float32, name=name)\n    return out_32\n\n\ndef smooth_l1(x, name=None):\n    '''Pointwise smooth abs function'''\n    absx = tf.abs(x)\n    big = tf.cast(tf.greater(absx, tf.ones_like(absx)), tf.float32)\n    activation = tf.add(tf.mul(big, absx-.5), tf.mul((1-big), .5*tf.square(x)), name=name)\n    return activation\n    \n\n########################\n# Misc helpers\n########################\n        \ndef sess_run_dict(sess, fetch_names, fetch_vars=None, feed_dict=None, options=None, run_metadata=None, **other_kwargs):\n    '''\n    Like sess.run but returns a dictionary of results\n    Usage:\n    sess_run_dict(sess, fetch_names, fetch_vars, ...)\n    sess_run_dict(sess, fetch_dict, ...)\n    '''\n    \n    dict_mode = isinstance(fetch_names, dict)\n\n    if dict_mode:\n        assert fetch_vars is None, 'provide either dict or list of names and vars, not both'\n        fetch_dict = fetch_names\n        fetch_names = fetch_dict.keys()\n        fetch_vars = fetch_dict.values()\n    \n    assert len(fetch_names) == len(fetch_vars), 'length of fetch_names must match length of fetch_vars'\n    assert isinstance(fetch_vars, list) or isinstance(fetch_vars, tuple), 'fetch_vars should be list or tuple'\n    result = sess.run(fetch_vars, feed_dict=feed_dict, options=options, run_metadata=run_metadata, **other_kwargs)\n    ret = {k:v for k,v in zip(fetch_names, result)}\n    return ret\n\n\ndef get_collection_intersection(*args):\n    ret = []\n    for ii,arg in enumerate(args):\n        if ii == 0:\n            ret = OrderedSet(tf.get_collection(arg))\n        else:\n            ret = ret.intersection(OrderedSet(tf.get_collection(arg)))\n    return list(ret)\n\n\ndef get_collection_intersection_summary(*args):\n    '''Returns a tf.merge_summary of the given collection intersection, or None if the intersection is empty.'''\n    col_int = get_collection_intersection(*args)\n    if col_int:\n        return tf.summary.merge(col_int)\n\n\ndef summarize_weights(weights, sess=None):\n    '''Print summary of each weight tensor in a list of weight tensors.\n    Example usage:\n    summarize_weights(model.trainable_weights)\n\n    if sess is provided, also print weight min, max, and RMS\n    '''\n\n    if sess:\n        vals = sess.run(weights)\n    total_params = 0\n    titl = '  %50s: %10s %-20s' % ('NAME', 'SIZE', 'SHAPE')\n    if sess:\n        titl += ' %10s, %10s, %10s' % ('MIN', 'MAX', 'RMS')\n    print titl\n    for ii,var in enumerate(weights):\n        st = '  %50s: %10d %-20s' % (var.name, np.prod(var.get_shape().as_list()), var.get_shape().as_list())\n        if sess:\n            val = vals[ii]\n            st += ' %10s, %10s, %10s' % ('%.3g' % val.min(), '%.3g' % val.max(), '%.3g' % np.sqrt((val**2).mean()))\n        print st\n        total_params += np.prod(var.get_shape().as_list())\n    print '  %50s: %10d' % ('Total', total_params)\n    return total_params\n\n\ndef val_or_dynamic(vord):\n    return '<dynamic>' if isinstance(vord, tf.Tensor) else repr(vord)\n\n\ndef summarize_opt(opt):\n    print 'Optimizer:'\n    print '   ', opt\n    if isinstance(opt, tf.train.MomentumOptimizer):\n        print '   LR: %s, momentum: %g, use_nesterov: %s' % (val_or_dynamic(opt._learning_rate), opt._momentum, opt._use_nesterov)\n    elif isinstance(opt, tf.train.RMSPropOptimizer):\n        print '   LR: %s, momentum: %g, decay: %g, epsilon: %g' % (val_or_dynamic(opt._learning_rate), opt._momentum, opt._decay, opt._epsilon)\n    elif isinstance(opt, tf.train.AdamOptimizer):\n        print '   LR: %s, beta1: %g, beta2: %g, epsilon: %g' % (val_or_dynamic(opt._lr), opt._beta1, opt._beta2, opt._epsilon)\n    else:\n        print '   (cannot summarize unknown type of optimizer)'\n\n\ndef tf_assert_gpu(sess):\n    with tf.device('/gpu:0'):\n        foo = tf.placeholder(tf.float32, name='assert_gpu')\n        bar = tf.add(foo, 1, name='assert_gpu')\n    try:\n        sess.run(bar, {foo: 1})\n    except:\n        print '\\n\\n\\ntf_assert_gpu: no GPU is present! In case it helps, CUDA_VISIBLE_DEVICES is %s' % repr(os.environ.get('CUDA_VISIBLE_DEVICES', None))\n        print 'See error below:\\n\\n\\n'\n        raise\n\n\ndef tf_assert_all_init(sess):\n    uninit_vars = sess.run(tf.report_uninitialized_variables())\n    assert len(uninit_vars) == 0, 'Expected all variables to have been initialized, but these have not been: %s' % uninit_vars\n\n\ndef tf_get_uninitialized_variables(sess):\n    '''A bit of a hack from\n    https://stackoverflow.com/questions/35164529/in-tensorflow-is-there-any-way-to-just-initialize-uninitialised-variables\n    to get a list of all uninitialized Variable objects from the\n    graph\n    '''\n\n    uninitialized_vars = []\n    for var in tf.global_variables():\n        try:\n            sess.run(var)\n        except tf.errors.FailedPreconditionError:\n            uninitialized_vars.append(var)\n    return uninitialized_vars\n"""
intrinsic_dimension/general/util.py,0,"b'import os\nimport errno\nimport time\n\nclass DotDict(dict):\n    """"""\n    Example:\n    mm = DotDict({\'first_name\': \'Eduardo\'}, last_name=\'Pool\', age=24, sports=[\'Soccer\'])\n    """"""\n    def __init__(self, *args, **kwargs):\n        super(DotDict, self).__init__(*args, **kwargs)\n        for arg in args:\n            if isinstance(arg, dict):\n                for k, v in arg.iteritems():\n                    self[k] = v\n        if kwargs:\n            for k, v in kwargs.iteritems():\n                self[k] = v\n\n    def __getattr__(self, attr):\n        if not attr in self:\n            raise AttributeError(attr)\n        return self.get(attr)\n\n    def __setattr__(self, key, value):\n        self.__setitem__(key, value)\n\n    def __setitem__(self, key, value):\n        super(DotDict, self).__setitem__(key, value)\n        self.__dict__.update({key: value})\n\n    def __delattr__(self, attr):\n        if not attr in self:\n            raise AttributeError(attr)\n        self.__delitem__(attr)\n\n    def __delitem__(self, key):\n        super(DotDict, self).__delitem__(key)\n        del self.__dict__[key]\n\n    def __repr__(self):\n        dict_rep = super(DotDict, self).__repr__()\n        return \'DotDict(%s)\' % dict_rep\n\n\nclass WithTimer(object):\n    def __init__(self, title = \'\', quiet = False):\n        self.title = title\n        self.quiet = quiet\n        \n    def elapsed(self):\n        return time.time() - self.wall, time.clock() - self.proc\n\n    def enter(self):\n        \'\'\'Manually trigger enter\'\'\'\n        self.__enter__()\n    \n    def __enter__(self):\n        self.proc = time.clock()\n        self.wall = time.time()\n        return self\n        \n    def __exit__(self, *args):\n        if not self.quiet:\n            titlestr = (\' \' + self.title) if self.title else \'\'\n            print \'Elapsed%s: wall: %.06f, sys: %.06f\' % ((titlestr,) + self.elapsed())\n\n\nclass TicToc(object):\n    def __init__(self):\n        self.reset()\n        \n    def reset(self):\n        self._proc = time.clock()\n        self._wall = time.time()\n        \n    def elapsed(self):\n        return self.wall(), self.proc()\n\n    def wall(self):\n        return time.time() - self._wall\n\n    def proc(self):\n        return time.clock() - self._proc\n\n\nglobalTicToc = TicToc()\nglobalTicToc2 = TicToc()\nglobalTicToc3 = TicToc()\n\ndef tic():\n    \'\'\'Like Matlab tic/toc for wall time and processor time\'\'\'\n    globalTicToc.reset()\n\ndef toc():\n    \'\'\'Like Matlab tic/toc for wall time\'\'\'\n    return globalTicToc.wall()\n\ndef tocproc():\n    \'\'\'Like Matlab tic/toc, but for processor time\'\'\'\n    return globalTicToc.proc()\n\ndef tic2():\n    globalTicToc2.reset()\ndef toc2():\n    return globalTicToc2.wall()\ndef tocproc2():\n    return globalTicToc2.proc()\ndef tic3():\n    globalTicToc3.reset()\ndef toc3():\n    return globalTicToc3.wall()\ndef tocproc3():\n    return globalTicToc3.proc()\n\n\n                \ndef mkdir_p(path):\n    # From https://stackoverflow.com/questions/600268/mkdir-p-functionality-in-python\n    try:\n        os.makedirs(path)\n    except OSError as exc: # Python >2.5\n        if exc.errno == errno.EEXIST and os.path.isdir(path):\n            pass\n        else:\n            raise\n\n'"
intrinsic_dimension/intrinsic_dim/__init__.py,0,b''
intrinsic_dimension/intrinsic_dim/load_glove_embeddings.py,0,"b'# coding: utf-8\n\nimport numpy as np\n\n\ndef load_glove_embeddings(fp, embedding_dim, include_empty_char=True):\n    """"""\n    Loads pre-trained word embeddings (GloVe embeddings)\n        Inputs: - fp: filepath of pre-trained glove embeddings\n                - embedding_dim: dimension of each vector embedding\n                - generate_matrix: whether to generate an embedding matrix\n        Outputs:\n                - word2coefs: Dictionary. Word to its corresponding coefficients\n                - word2index: Dictionary. Word to word-index\n                - embedding_matrix: Embedding matrix for Keras Embedding layer\n    """"""\n    # First, build the ""word2coefs"" and ""word2index""\n    word2coefs = {} # word to its corresponding coefficients\n    word2index = {} # word to word-index\n    with open(fp) as f:\n        for idx, line in enumerate(f):\n            try:\n                data = [x.strip().lower() for x in line.split()]\n                word = data[0]\n                coefs = np.asarray(data[1:embedding_dim+1], dtype=\'float32\')\n                word2coefs[word] = coefs\n                if word not in word2index:\n                    word2index[word] = len(word2index)\n            except Exception as e:\n                print(\'Exception occurred in `load_glove_embeddings`:\', e)\n                continue\n        # End of for loop.\n    # End of with open\n    if include_empty_char:\n        word2index[\'\'] = len(word2index)\n    # Second, build the ""embedding_matrix""\n    # Words not found in embedding index will be all-zeros. Hence, the ""+1"".\n    vocab_size = len(word2coefs)+1 if include_empty_char else len(word2coefs)\n    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n    for word, idx in word2index.items():\n        embedding_vec = word2coefs.get(word)\n        if embedding_vec is not None and embedding_vec.shape[0]==embedding_dim:\n            embedding_matrix[idx] = np.asarray(embedding_vec)\n    # return word2coefs, word2index, embedding_matrix\n    return word2index, np.asarray(embedding_matrix)\n'"
intrinsic_dimension/intrinsic_dim/model_builders.py,28,"b""import numpy as np\nfrom IPython import embed\nimport pdb\n\nimport tensorflow as tf\nfrom keras.layers import (Dense, Flatten, Input, Activation, Conv1D, MaxPooling1D,\n                          Reshape, Dropout, Convolution2D, \n                          MaxPooling2D, BatchNormalization, \n                          Conv2D, GlobalAveragePooling2D, \n                          Concatenate, AveragePooling2D, \n                          LocallyConnected2D, Embedding, Lambda)\nimport keras.backend as K\n\nfrom general.tfutil import hist_summaries_traintest, scalar_summaries_traintest\n\nfrom keras_ext.engine import ExtendedModel\nfrom keras_ext.layers import (RProjDense, \n                              RProjConv2D, \n                              RProjBatchNormalization, \n                              RProjLocallyConnected2D)\nfrom keras_ext.rproj_layers_util import (OffsetCreatorDenseProj, \n                                         OffsetCreatorSparseProj, \n                                         OffsetCreatorFastfoodProj, \n                                         FastWalshHadamardProjector, \n                                         ThetaPrime)\nfrom keras_ext.util import make_image_input_preproc\nfrom densenet import transition, denseblock, transition_RProj, denseblock_RProj\nfrom keras.regularizers import l2\n\n\ndef make_and_add_losses(model, input_labels):\n    '''Add classification and L2 losses'''\n\n    with tf.name_scope('losses') as scope:\n        prob = tf.nn.softmax(model.v.logits, name='prob')\n        cross_ent = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=model.v.logits, labels=input_labels, name='cross_ent')\n        loss_cross_ent = tf.reduce_mean(cross_ent, name='loss_cross_ent')\n        model.add_trackable('loss_cross_ent', loss_cross_ent)\n        class_prediction = tf.argmax(prob, 1)\n\n        prediction_correct = tf.equal(class_prediction, input_labels, name='prediction_correct')\n        accuracy = tf.reduce_mean(tf.to_float(prediction_correct), name='accuracy')\n        model.add_trackable('accuracy', accuracy)\n        hist_summaries_traintest(prob, cross_ent)\n        scalar_summaries_traintest(accuracy)\n\n        model.add_loss_reg()\n        if 'loss_reg' in model.v:\n            loss = tf.add_n((\n                model.v.loss_cross_ent,\n                model.v.loss_reg,\n            ), name='loss')\n        else:\n            loss = model.v.loss_cross_ent\n        model.add_trackable('loss', loss)\n\n    nontrackable_fields = ['prob', 'cross_ent', 'class_prediction', 'prediction_correct']\n    for field in nontrackable_fields:\n        model.add_var(field, locals()[field])\n\n\ndef build_model_text_swem_dir(embedding_matrix, weight_decay=0,n_words=1000,depth=2, width=100, seq_length=100, embed_dim=300, n_label=2):\n    #im_shape = (28, 28, 1)\n    MAX_SEQUENCE_LENGTH = seq_length # 108\n    EMBEDDING_DIM = embed_dim\n    n_label = n_label\n    im_dtype = 'float32'\n\n    # embedding_matrix = # TODO: load pre-train embeddings\n\n    with tf.name_scope('inputs'):\n        # input_images, preproc_images = make_image_input_preproc(im_shape, im_dtype, shift_in=shift_in)\n        # input_labels = Input(batch_shape=(None,), dtype='int64')\n        input_sequences = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int64')\n\n        input_labels = Input(batch_shape=(None,), dtype='int64')\n        \n\n    with tf.name_scope('net') as scope:\n        embedding_layer = Embedding(n_words, #400002,\n                                    EMBEDDING_DIM,\n                                    # embeddings_initializer='uniform',\n                                    weights=[embedding_matrix], \n                                    input_length=MAX_SEQUENCE_LENGTH,\n                                    trainable=False)\n\n        def average_emb(input_seq):\n\n            H_enc = tf.reduce_max(input_seq, axis=1)  # batch 1 emb\n\n            embedded_sequences = H_enc\n            return embedded_sequences\n\n        xx = embedding_layer(input_sequences)\n        \n        for _ in range(depth):\n            xx = Dense(width, activation='relu', kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay))(xx)\n        xx = Lambda(average_emb)(xx)\n        logits = Dense(n_label, kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay))(xx)\n\n        #pdb.set_trace()\n\n        model = ExtendedModel(input=input_sequences, output=logits)\n\n    nontrackable_fields = ['input_sequences','input_labels', 'logits']\n    for field in nontrackable_fields:\n        model.add_var(field, locals()[field])\n    \n    make_and_add_losses(model, input_labels)\n    \n    return model\n\n\ndef build_model_text_swem(embedding_matrix, weight_decay=0,n_words=1000, vsize=100, depth=2, width=100, proj_type='sparse', seq_length=100, embed_dim=300, n_label=2):\n    #im_shape = (28, 28, 1)\n    MAX_SEQUENCE_LENGTH = seq_length # 108\n    EMBEDDING_DIM = embed_dim\n    n_label = n_label\n    im_dtype = 'float32'\n\n    assert proj_type in ('dense', 'sparse')\n    if proj_type == 'dense':\n        offset_creator_class = OffsetCreatorDenseProj\n    else:\n        # sparse\n        offset_creator_class = OffsetCreatorSparseProj\n\n    with tf.name_scope('inputs'):\n        # input_images, preproc_images = make_image_input_preproc(im_shape, im_dtype, shift_in=shift_in)\n        # input_labels = Input(batch_shape=(None,), dtype='int64')\n        input_sequences = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int64')\n\n        input_labels = Input(batch_shape=(None,), dtype='int64')\n\n\n    with tf.name_scope('net') as scope:\n        vv = ThetaPrime(vsize)\n\n\n        embedding_layer = Embedding(n_words,\n                                    EMBEDDING_DIM,\n                                    # embeddings_initializer='uniform',\n                                    weights=[embedding_matrix], \n                                    input_length=MAX_SEQUENCE_LENGTH,\n                                    trainable=False)\n\n        def average_emb(input_seq):\n\n            H_enc = tf.reduce_max(input_seq, axis=1)  # batch 1 emb\n\n            embedded_sequences = H_enc\n            return embedded_sequences\n\n        xx = embedding_layer(input_sequences)\n        xx = Lambda(average_emb)(xx)\n\n        for _ in range(depth):\n            xx = RProjDense(offset_creator_class, vv, width, activation='relu', kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay))(xx)\n        logits = RProjDense(offset_creator_class, vv, n_label, kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay))(xx)\n        model = ExtendedModel(input=input_sequences, output=logits)\n\n        model.add_extra_trainable_weight(vv.var)\n\n    nontrackable_fields = ['input_sequences','input_labels', 'logits']\n    for field in nontrackable_fields:\n        model.add_var(field, locals()[field])\n    \n    make_and_add_losses(model, input_labels)\n    \n    return model\n\n\n\ndef build_model_text_swem_fastfood(embedding_matrix, weight_decay=0,n_words=1000, vsize=100, depth=2, width=100, seq_length=100, embed_dim=300, n_label=2, DD=None):\n    '''If DD is not specified, it will be computed.'''\n\n    MAX_SEQUENCE_LENGTH = seq_length # 108\n    EMBEDDING_DIM = embed_dim\n    n_label = n_label\n    im_dtype = 'float32'\n\n    with tf.name_scope('inputs'):\n        input_sequences = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int64')\n        input_labels = Input(batch_shape=(None,), dtype='int64')\n\n\n    def define_model(input_sequences, DenseLayer, Conv2DLayer):\n        vv = ThetaPrime(vsize)\n        embedding_layer = Embedding(n_words,\n                                    EMBEDDING_DIM,\n                                    # embeddings_initializer='uniform',\n                                    weights=[embedding_matrix], \n                                    input_length=MAX_SEQUENCE_LENGTH,\n                                    trainable=False)\n\n        def average_emb(input_seq):\n            H_enc = tf.reduce_max(input_seq, axis=1)  # batch 1 emb\n            embedded_sequences = H_enc\n            return embedded_sequences\n\n        xx = embedding_layer(input_sequences)\n        xx = Lambda(average_emb)(xx)\n        for _ in range(depth):\n            xx = DenseLayer(width, activation='relu', kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay))(xx)\n        logits = DenseLayer(n_label, kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay))(xx)\n\n        model = ExtendedModel(input=input_sequences, output=logits)\n        nontrackable_fields = ['input_sequences', 'input_labels', 'logits']\n        for field in ['logits']:\n            model.add_var(field, locals()[field])\n        return model\n\n    if not DD:\n        with tf.name_scope('net_disposable'):\n            # Make disposable direct model\n            model_disposable = define_model(input_sequences, Dense, Conv2D)\n\n            DD = np.sum([np.prod(var.get_shape().as_list()) for var in model_disposable.trainable_weights])\n            del model_disposable\n\n    print '\\nProjecting from d = %d to D = %d parameters\\n' % (vsize, DD)\n\n    with tf.name_scope('net'):\n        # Make real RProj FWH model\n        fwh_projector = FastWalshHadamardProjector(vsize, DD)\n\n        DenseLayer = lambda *args, **kwargs: RProjDense(OffsetCreatorFastfoodProj, fwh_projector, *args, **kwargs)\n        Conv2DLayer = lambda *args, **kwargs: RProjConv2D(OffsetCreatorFastfoodProj, fwh_projector, *args, **kwargs)\n\n        model = define_model(input_sequences, DenseLayer, Conv2DLayer)\n        fwh_projector.check_usage()\n\n        for ww in fwh_projector.trainable_weights:\n            model.add_extra_trainable_weight(ww)\n        for ww in fwh_projector.non_trainable_weights:\n            model.add_extra_non_trainable_weight(ww)\n\n    nontrackable_fields = ['input_sequences', 'input_labels']\n    for field in nontrackable_fields:\n        model.add_var(field, locals()[field])\n\n    make_and_add_losses(model, input_labels)\n\n    return model\n\n\n\ndef build_model_text_cnn_dir(embedding_matrix, weight_decay=0, n_words=1000, depth=2, width=100, seq_length=100, embed_dim=300, n_label=2, n_max_pool=52, n_stride=1):\n    # im_shape = (28, 28, 1)\n    MAX_SEQUENCE_LENGTH = seq_length # 108\n    EMBEDDING_DIM = embed_dim\n    n_label = n_label\n    im_dtype = 'float32'\n\n    # embedding_matrix = # TODO: load pre-train embeddings\n\n    with tf.name_scope('inputs'):\n        # input_images, preproc_images = make_image_input_preproc(im_shape, im_dtype, shift_in=shift_in)\n        # input_labels = Input(batch_shape=(None,), dtype='int64')\n        input_sequences = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int64')\n\n        input_labels = Input(batch_shape=(None,), dtype='int64')\n\n    with tf.name_scope('net') as scope:\n        embedding_layer = Embedding(n_words,\n                                    EMBEDDING_DIM,\n                                    # embeddings_initializer='uniform',\n                                    weights=[embedding_matrix], \n                                    input_length=MAX_SEQUENCE_LENGTH,\n                                    trainable=False)\n\n        def pool_emb(input_seq):\n            embedded_sequences = tf.expand_dims(input_seq,-1)\n            return embedded_sequences\n\n\n        xx = embedding_layer(input_sequences)\n        xx = Lambda(pool_emb)(xx)\n\n        xx = Convolution2D(128, kernel_size=(5,EMBEDDING_DIM), strides=n_stride, init='he_normal', padding='valid', activation='relu', kernel_regularizer=l2(weight_decay))(xx)\n        xx = MaxPooling2D((n_max_pool, 1))(xx)# 52\n        # xx = Convolution2D(32, kernel_size=(5,1), strides=1, init='he_normal', padding='valid', activation='relu', kernel_regularizer=l2(weight_decay))(xx)\n        # xx = MaxPooling2D((3, 1))(xx)\n        # xx = Convolution2D(32, kernel_size=(5,1), strides=1, init='he_normal', padding='valid', activation='relu', kernel_regularizer=l2(weight_decay))(xx)\n        # xx = MaxPooling2D((3, 1))(xx)\n\n        # l_cov1 = Conv1D(128, 5, activation='relu')(xx)\n        # l_pool1 = MaxPooling1D(3)(l_cov1)\n        # l_cov2 = Conv1D(128, 5, activation='relu')(l_pool1)\n        # l_pool2 = MaxPooling1D(3)(l_cov2)\n        # xx = Conv1D(128, 5, activation='relu')(l_pool2)\n        # xx = MaxPooling1D(6)(xx)  # global max pooling\n        xx = Flatten()(xx)\n\n\n        for _ in range(depth):\n            xx = Dense(width, activation='relu', kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay))(\n                xx)\n        logits = Dense(n_label, kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay))(xx)\n\n        # pdb.set_trace()\n\n        model = ExtendedModel(input=input_sequences, output=logits)\n\n    nontrackable_fields = ['input_sequences', 'input_labels', 'logits']\n    for field in nontrackable_fields:\n        model.add_var(field, locals()[field])\n\n    make_and_add_losses(model, input_labels)\n\n    return model\n\n\ndef build_model_text_cnn(embedding_matrix, weight_decay=0, n_words=1000,  vsize=100, depth=2, width=100, proj_type='sparse', seq_length=100, embed_dim=300, n_label=2, n_max_pool=52, n_stride=1):\n    # im_shape = (28, 28, 1)\n    MAX_SEQUENCE_LENGTH = seq_length # 108\n    EMBEDDING_DIM = embed_dim\n    n_label = n_label\n\n    im_dtype = 'float32'\n\n    # embedding_matrix = # TODO: load pre-train embeddings\n\n    assert proj_type in ('dense', 'sparse')\n    if proj_type == 'dense':\n        offset_creator_class = OffsetCreatorDenseProj\n    else:\n        # sparse\n        offset_creator_class = OffsetCreatorSparseProj\n\n\n    with tf.name_scope('inputs'):\n        # input_images, preproc_images = make_image_input_preproc(im_shape, im_dtype, shift_in=shift_in)\n        # input_labels = Input(batch_shape=(None,), dtype='int64')\n        input_sequences = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int64')\n\n        input_labels = Input(batch_shape=(None,), dtype='int64')\n\n\n    with tf.name_scope('net') as scope:\n\n        vv = ThetaPrime(vsize)\n\n        embedding_layer = Embedding(n_words,\n                                    EMBEDDING_DIM,\n                                    # embeddings_initializer='uniform',\n                                    weights=[embedding_matrix], \n                                    input_length=MAX_SEQUENCE_LENGTH,\n                                    trainable=False)\n\n        def pool_emb(input_seq):\n            embedded_sequences = tf.expand_dims(input_seq,-1)\n            return embedded_sequences\n\n        xx = embedding_layer(input_sequences)\n        xx = Lambda(pool_emb)(xx)\n\n        xx = RProjConv2D(offset_creator_class, vv, 128, kernel_size=(5,EMBEDDING_DIM), strides=n_stride, kernel_initializer='he_normal', padding='valid', activation='relu', kernel_regularizer=l2(weight_decay))(xx)\n        xx = MaxPooling2D((n_max_pool, 1))(xx)\n        # xx = RProjConv2D(offset_creator_class, vv, 32, kernel_size=(5,1), strides=1, kernel_initializer='he_normal', padding='valid', activation='relu', kernel_regularizer=l2(weight_decay))(xx)\n        # xx = MaxPooling2D((3, 1))(xx)\n        # xx = RProjConv2D(offset_creator_class, vv, 32, kernel_size=(5,1), strides=1, kernel_initializer='he_normal', padding='valid', activation='relu', kernel_regularizer=l2(weight_decay))(xx)\n        # xx = MaxPooling2D((3, 1))(xx)\n\n        xx = Flatten()(xx)\n\n\n        for _ in range(depth):\n            xx = RProjDense(offset_creator_class, vv, width, activation='relu', kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay))(\n                xx)\n        logits = RProjDense(offset_creator_class, vv, n_label, kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay))(xx)\n\n        # pdb.set_trace()\n\n        model = ExtendedModel(input=input_sequences, output=logits)\n\n        model.add_extra_trainable_weight(vv.var)\n\n\n\n\n\n    nontrackable_fields = ['input_sequences', 'input_labels', 'logits']\n    for field in nontrackable_fields:\n        model.add_var(field, locals()[field])\n\n    make_and_add_losses(model, input_labels)\n\n    return model\n\n\n\n\n\ndef build_model_text_cnn_fastfood(embedding_matrix, weight_decay=0,n_words=1000, vsize=100, depth=2, width=100, seq_length=100, embed_dim=300, n_label=2, n_max_pool=52, n_stride=1, DD=None):\n    '''If DD is not specified, it will be computed.'''\n\n    MAX_SEQUENCE_LENGTH = seq_length # 108\n    EMBEDDING_DIM = embed_dim\n    n_label = n_label\n    im_dtype = 'float32'\n\n    with tf.name_scope('inputs'):\n        input_sequences = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int64')\n        input_labels = Input(batch_shape=(None,), dtype='int64')\n\n\n    def define_model(input_sequences, DenseLayer, Conv2DLayer):\n        vv = ThetaPrime(vsize)\n        embedding_layer = Embedding(n_words,\n                                    EMBEDDING_DIM,\n                                    # embeddings_initializer='uniform',\n                                    weights=[embedding_matrix], \n                                    input_length=MAX_SEQUENCE_LENGTH,\n                                    trainable=False)\n\n        def pool_emb(input_seq):\n            embedded_sequences = tf.expand_dims(input_seq,-1)\n            return embedded_sequences\n\n        xx = embedding_layer(input_sequences)\n        xx = Lambda(pool_emb)(xx)\n        xx = Conv2DLayer(128, kernel_size=(5,EMBEDDING_DIM), strides=n_stride, kernel_initializer='he_normal', padding='valid', activation='relu', kernel_regularizer=l2(weight_decay))(xx)\n        xx = MaxPooling2D((n_max_pool, 1))(xx)\n        xx = Flatten()(xx)\n\n        for _ in range(depth):\n            xx = DenseLayer(width, activation='relu', kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay))(xx)\n        logits = DenseLayer(n_label, kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay))(xx)\n\n        model = ExtendedModel(input=input_sequences, output=logits)\n        nontrackable_fields = ['input_sequences', 'input_labels', 'logits']\n        for field in ['logits']:\n            model.add_var(field, locals()[field])\n        return model\n\n    if not DD:\n        with tf.name_scope('net_disposable'):\n            # Make disposable direct model\n            model_disposable = define_model(input_sequences, Dense, Conv2D)\n\n            DD = np.sum([np.prod(var.get_shape().as_list()) for var in model_disposable.trainable_weights])\n            del model_disposable\n\n    print '\\nProjecting from d = %d to D = %d parameters\\n' % (vsize, DD)\n\n    with tf.name_scope('net'):\n        # Make real RProj FWH model\n        fwh_projector = FastWalshHadamardProjector(vsize, DD)\n\n        DenseLayer = lambda *args, **kwargs: RProjDense(OffsetCreatorFastfoodProj, fwh_projector, *args, **kwargs)\n        Conv2DLayer = lambda *args, **kwargs: RProjConv2D(OffsetCreatorFastfoodProj, fwh_projector, *args, **kwargs)\n\n        model = define_model(input_sequences, DenseLayer, Conv2DLayer)\n        fwh_projector.check_usage()\n\n        for ww in fwh_projector.trainable_weights:\n            model.add_extra_trainable_weight(ww)\n        for ww in fwh_projector.non_trainable_weights:\n            model.add_extra_non_trainable_weight(ww)\n\n    nontrackable_fields = ['input_sequences', 'input_labels']\n    for field in nontrackable_fields:\n        model.add_var(field, locals()[field])\n\n    make_and_add_losses(model, input_labels)\n\n    return model\n\n\n\n\n\n\n"""
intrinsic_dimension/intrinsic_dim/rand_args.py,0,"b""#! /usr/bin/env python\n\nimport numpy as np\nimport argparse\n\n\ndef main():\n    parser = argparse.ArgumentParser(description='Generate command line args corresponding to randomly sampled network architectures',\n                                     formatter_class=lambda prog: argparse.ArgumentDefaultsHelpFormatter(prog)\n    )\n    parser.add_argument('--lenet', action='store_true', help='Output args for lenet models')\n    parser.add_argument('--l2', action='store_true', help='Output l2 as well')\n    parser.add_argument('--seed', '-s', type=int, default=None, help='Seed for random number generator. If not specified, use a randomly sampled seed for each run')\n\n    args = parser.parse_args()\n\n    if args.seed is not None:\n        np.random.seed(args.seed)\n\n    argstrs = []\n\n    if args.lenet:\n        argstrs.append('--c1 %s' % np.random.choice([1, 2, 3, 4, 6, 10]))\n        argstrs.append('--c2 %s' % np.random.choice([1, 2, 3, 4, 6, 10, 16]))\n        argstrs.append('--d1 %s' % np.random.choice([2, 3, 5, 10, 20, 50, 100, 120]))\n        argstrs.append('--d2 %s' % np.random.choice([2, 3, 5, 10, 20, 50, 84]))\n    else:\n        depth_choices = [1, 2, 3, 4, 5]\n        argstrs.append('--depth %s' % np.random.choice(depth_choices))\n\n        width_choices = [2, 3, 5, 8, 10, 15, 20, 25]\n        argstrs.append('--width %s' % np.random.choice(width_choices))\n\n    if args.l2:\n        argstrs.append('--l2 %s' % np.random.choice([0, 1e-9, 1e-8, 1e-7, 1e-6, 1e-5]))\n\n    print ' '.join(argstrs)\n\n\nif __name__ == '__main__':\n    main()\n"""
intrinsic_dimension/intrinsic_dim/standard_parser.py,0,"b'import os\nimport argparse\n\nDEFAULT_ARCH_CHOICES = [\'mnist\']\n\ndef make_standard_parser(description=\'No decription provided\', arch_choices=DEFAULT_ARCH_CHOICES):\n    \'\'\'Make a standard parser, probably good for many experiments.\n\n    Arguments:\n\n      description: just used for help\n\n      arch_choices: list of strings that may be specified when\n         selecting architecture type. For example, (\'mnist\', \'cifar\')\n         would allow selection of different networks for each\n         dataset. architecture may also be toggled via the --conv and\n         --xprop switches. Default architecture is the first in the\n         list.\n    \'\'\'\n    \n    parser = argparse.ArgumentParser(description=description,\n                                     formatter_class=lambda prog: argparse.ArgumentDefaultsHelpFormatter(prog)\n    )\n\n    # Optimization\n    parser.add_argument(\'--opt\', type=str, default=\'sgd\', choices=(\'sgd\', \'rmsprop\', \'adam\'), help=\'Which optimizer to use\')\n    parser.add_argument(\'--lr\', \'-L\', type=float, default=.001, help=\'learning rate\')\n    parser.add_argument(\'--mom\', \'-M\', type=float, default=.9, help=\'momentum (only has effect for sgd/rmsprop)\')\n    parser.add_argument(\'--beta1\', type=float, default=.9, help=\'beta1 for adam opt\')\n    parser.add_argument(\'--beta2\', type=float, default=.99, help=\'beta2 for adam opt\')\n    parser.add_argument(\'--adameps\', type=float, default=1e-8, help=\'epsilon for adam opt\')\n    parser.add_argument(\'--epochs\', \'-E\',type=int, default=5, help=\'number of epochs.\')\n\n    # Model\n    parser.add_argument(\'--arch\', type=str, default=arch_choices[0],\n                        choices=arch_choices, help=\'Which architecture to use (choices: %s).\' % arch_choices)\n    parser.add_argument(\'--conv\', \'-C\', action=\'store_true\', help=\'Use a conv model.\')\n    parser.add_argument(\'--xprop\', \'-X\', action=\'store_true\', help=\'Use an xprop model\')\n    parser.add_argument(\'--springprop\', \'-S\', action=\'store_true\', help=\'Use an springprop model\')\n    parser.add_argument(\'--springt\', \'-t\', type=float, default=0.5, help=\'T value to use for springs\')\n    parser.add_argument(\'--learncoords\', \'--lc\', action=\'store_true\', help=\'Learn coordinates (update them during training) instead of keeping them fixed.\')\n    parser.add_argument(\'--l2\', type=float, default=0.0, help=\'L2 regularization to apply to direct parameters.\')\n    parser.add_argument(\'--l2i\', type=float, default=0.0, help=\'L2 regularization to apply to indirect parameters.\')\n\n    # Experimental setup\n    parser.add_argument(\'--seed\', type=int, default=0, help=\'random number seed for intial params and tf graph\')\n    parser.add_argument(\'--test\', action=\'store_true\', help=\'Use test data instead of validation data (for final run).\')\n    parser.add_argument(\'--shuffletrain\', \'--st\', dest=\'shuffletrain\', action=\'store_true\', help=\'Shuffle training set each epoch.\')\n    parser.add_argument(\'--noshuffletrain\', \'--nst\', dest=\'shuffletrain\', action=\'store_false\', help=\'Do not shuffle training set each epoch. Ignore the following ""default"" value:\')\n    parser.set_defaults(shuffletrain=True)\n    \n    # Misc\n    parser.add_argument(\'--ipy\', \'-I\', action=\'store_true\', help=\'drop into embedded iPython for debugging.\')\n    parser.add_argument(\'--nocolor\', \'--nc\', action=\'store_true\', help=\'Do not use color output (for scripts).\')\n    parser.add_argument(\'--skipval\', action=\'store_true\', help=\'Skip validation set entirely.\')\n    parser.add_argument(\'--verbose\', \'-V\', action=\'store_true\', help=\'Verbose mode (print some extra stuff)\')\n\n    # Saving a loading\n    parser.add_argument(\'--snapshot-to\', type=str, default=\'net\', help=\'Where to snapshot to. --snapshot-to NAME produces NAME_iter.h5 and NAME.json\')\n    parser.add_argument(\'--snapshot-every\', type=int, default=-1, help=\'Snapshot every N minibatches. 0 to disable snapshots, -1 to snapshot only on last iteration.\')\n    parser.add_argument(\'--load\', type=str, default=None, help=\'Snapshot to load from: specify as H5_FILE:MISC_FILE.\')\n    parser.add_argument(\'--output\', \'-O\', type=str, default=None, help=\'directory output TF results to. If nothing else: skips output.\')\n\n    return parser\n'"
intrinsic_dimension/intrinsic_dim/train.py,13,"b'#! /usr/bin/env python\n\nimport sys\nimport os\nimport gzip\nimport cPickle as pickle\nimport numpy as np\nimport h5py\nfrom IPython import embed\nimport colorama\nimport tensorflow as tf\nimport keras.backend as K\nfrom keras.preprocessing.sequence import pad_sequences\nimport cPickle\nimport pdb\nfrom keras.datasets import imdb\nfrom load_glove_embeddings import load_glove_embeddings\n\nlab_root = os.path.join(os.path.abspath(os.path.dirname(__file__)), \'..\')\nsys.path.insert(1, lab_root)\n\nfrom general.util import tic, toc, tic2, toc2, tic3, toc3, mkdir_p, WithTimer\nfrom general.image_preproc import ImagePreproc\nfrom general.stats_buddy import StatsBuddy\nfrom general.tfutil import (get_collection_intersection_summary,\n                           log_scalars, sess_run_dict, \n                           summarize_weights, summarize_opt,\n                           tf_assert_all_init, \n                           tf_get_uninitialized_variables, \n                           add_grad_summaries)\nfrom keras_ext.util import setup_session_and_seeds, warn_misaligned_shapes\nfrom model_builders import (build_model_text_swem_dir,\n                            build_model_text_swem,\n                            build_model_text_swem_fastfood,\n                            build_model_text_cnn_dir,\n                            build_model_text_cnn,\n                            build_model_text_cnn_fastfood)\nfrom standard_parser import make_standard_parser\n\n\narch_choices_direct = [\'swem_dir\',\'cnn_dir\']\narch_choices_projected = [\'swem\',\'cnn\']\ndataset_choices = [\'agnews\',\'yelp\']\narch_choices = arch_choices_direct + arch_choices_projected\n\nclass LRStepper(object):\n    def __init__(self, lr_init, lr_ratio, lr_epochs, lr_steps):\n        self.lr_init = lr_init\n        self.lr_ratio = lr_ratio\n        self.lr_epochs = lr_epochs\n        self.lr_steps = lr_steps\n        self.last_printed = None\n\n    def lr(self, buddy):\n        if self.lr_ratio == 0 or self.lr_epochs == 0:\n            return self.lr_init\n        ret = self.lr_init * self.lr_ratio ** int(min(buddy.epoch / self.lr_epochs, self.lr_steps))\n        if ret != self.last_printed:\n            print \'At epoch %d setting LR to %g\' % (buddy.epoch, ret)\n            self.last_printed = ret\n        return ret\n\ndef main():\n    parser = make_standard_parser(\'Random Projection Experiments.\', arch_choices=arch_choices)\n\n    parser.add_argument(\'--dataset\', type=str, default=dataset_choices[0], choices=dataset_choices, help=\'Dataset to choose from.\')\n    parser.add_argument(\'--vsize\', type=int, default=100, help=\'Dimension of intrinsic parmaeter space.\')\n    parser.add_argument(\'--d_rate\', \'--dr\', type=float, default=0.0, help=\'Dropout rate.\')\n    parser.add_argument(\'--depth\', type=int, default=2, help=\'Number of layers in FNN.\')\n    parser.add_argument(\'--width\', type=int, default=100, help=\'Width of  layers in FNN.\')\n    parser.add_argument(\'--minibatch\', \'--mb\', type=int, default=128, help=\'Size of minibatch.\')\n    parser.add_argument(\'--lr_ratio\', \'--lrr\', type=float, default=.1, help=\'Ratio to decay LR by every LR_EPSTEP epochs.\')\n    parser.add_argument(\'--lr_epochs\', \'--lrep\', type=float, default=0, help=\'Decay LR every LR_EPSTEP epochs. 0 to turn off decay.\')\n    parser.add_argument(\'--lr_steps\', \'--lrst\', type=float, default=3, help=\'Max LR steps.\')\n\n    parser.add_argument(\'--c1\', type=int, default=6, help=\'Channels in first conv layer, for LeNet.\')\n    parser.add_argument(\'--c2\', type=int, default=16, help=\'Channels in second conv layer, for LeNet.\')\n    parser.add_argument(\'--d1\', type=int, default=120, help=\'Channels in first dense layer, for LeNet.\')\n    parser.add_argument(\'--d2\', type=int, default=84, help=\'Channels in second dense layer, for LeNet.\')\n    \n    parser.add_argument(\'--denseproj\', action=\'store_true\', help=\'Use a dense projection.\')\n    parser.add_argument(\'--sparseproj\', action=\'store_true\', help=\'Use a sparse projection.\')\n    parser.add_argument(\'--fastfoodproj\', action=\'store_true\', help=\'Use a fastfood projection.\')\n\n    parser.add_argument(\'--partial_data\', \'--pd\', type=float, default=1.0, help=\'Percentage of dataset.\')\n\n    parser.add_argument(\'--skiptfevents\', action=\'store_true\', help=\'Skip writing tf events files even if output is used.\')\n\n    args = parser.parse_args()\n\n    n_proj_specified = sum([args.denseproj, args.sparseproj, args.fastfoodproj])\n    if args.arch in arch_choices_projected:\n        assert n_proj_specified == 1, \'Arch ""%s"" requires projection. Specify exactly one of {denseproj, sparseproj, fastfoodproj} options.\' % args.arch\n    else:\n        assert n_proj_specified == 0, \'Arch ""%s"" does not require projection, so do not specify any of {denseproj, sparseproj, fastfoodproj} options.\' % args.arch\n\n    if args.denseproj:\n        proj_type = \'dense\'\n    elif args.sparseproj:\n        proj_type = \'sparse\'\n    else:\n        proj_type = \'fastfood\'\n\n    train_style, val_style = (\'\', \'\') if args.nocolor else (colorama.Fore.BLUE, colorama.Fore.MAGENTA)\n\n    # Get a TF session registered with Keras and set numpy and TF seeds\n    sess = setup_session_and_seeds(args.seed)\n\n    # 0. LOAD DATA\n\n    if args.dataset==\'agnews\':\n        loadpath = ""./dataset/ag_news.p""\n        x = cPickle.load(open(loadpath, ""rb""))\n        train, val, test = x[0], x[1], x[2]\n        train_lab, val_lab, test_lab = x[3], x[4], x[5]\n        wordtoix, ixtoword = x[6], x[7]\n        MAX_SEQUENCE_LENGTH = 108\n        n_label = 4\n        n_max_pool = 52\n        n_stride = 1\n\n        loadpath = ""./dataset/ag_news_glove.p""\n        x = cPickle.load(open(loadpath, ""rb""))\n        embedding_matrix = x[0]\n\n        n_train, n_test = len(train_lab), len(test_lab)\n        train_y_,  test_y_= np.zeros(n_train), np.zeros(n_test)\n        for i in range(n_train):\n            train_y_[i] = np.argmax(train_lab[i][:,0])\n        for i in range(n_test):\n            test_y_[i] = np.argmax(test_lab[i][:,0])\n\n        train_x = train\n        train_y = train_y_\n        val_x = test\n        val_y = test_y_\n\n    elif args.dataset==\'yelp\':\n        loadpath = ""./dataset/yelp.p""\n        x = cPickle.load(open(loadpath, ""rb""))\n        train, val, test = x[0], x[1], x[2]\n        train_lab, val_lab, test_lab = x[3], x[4], x[5]\n        wordtoix, ixtoword = x[6], x[7]\n        del x\n\n        loadpath = ""./dataset/yelp_glove.p""\n        x = cPickle.load(open(loadpath, ""rb""))\n        embedding_matrix = x[0]\n\n        MAX_SEQUENCE_LENGTH = 305\n        n_label = 2\n        n_max_pool = 151\n        n_stride = 2\n\n        train_x = train\n        train_y = train_lab\n        val_x = test\n        val_y = test_lab\n    else:\n        raise Exception(\'Unknown dataset: %s\' % args.dataset)  \n    #pdb.set_trace()\n\n    EMBED_DIM= 300\n    train_x = pad_sequences(train_x, maxlen=MAX_SEQUENCE_LENGTH)\n    val_x = pad_sequences(val_x, maxlen=MAX_SEQUENCE_LENGTH)\n    n_words = len(ixtoword)\n    del x\n    print(\'Total words: %d\' % n_words)\n\n\n    if args.partial_data < 1.0:\n        n_train_ = int(train_y.size*args.partial_data)       \n        n_test_  = int(val_y.size*args.partial_data)       \n        train_x = train_x[:n_train_]\n        train_y = train_y[:n_train_]\n        val_x = val_x[:n_test_]\n        val_y = val_y[:n_test_]\n\n    # load into memory if less than 1 GB\n    if len(train_x) * 4 + len(val_x) * 4 < 1e9:\n        train_x, train_y = np.array(train_x), np.array(train_y)\n        val_x, val_y = np.array(val_x), np.array(val_y)\n\n    # 1. CREATE MODEL\n    randmirrors = False\n    randcrops = False\n    cropsize = None\n\n    with WithTimer(\'Make model\'):\n        if args.arch == \'mnistfc_dir\':\n            model = build_model_mnist_fc_dir(weight_decay=args.l2, depth=args.depth, width=args.width)\n        elif args.arch == \'mnistfc\':\n            if proj_type == \'fastfood\':\n                model = build_model_mnist_fc_fastfood(weight_decay=args.l2, vsize=args.vsize, depth=args.depth, width=args.width)\n            else:\n                model = build_model_mnist_fc(weight_decay=args.l2, vsize=args.vsize, depth=args.depth, width=args.width, proj_type=proj_type)\n        elif args.arch == \'swem_dir\':  \n            model = build_model_text_swem_dir(embedding_matrix=embedding_matrix, weight_decay=args.l2, n_words=n_words, depth=args.depth, width=args.width, seq_length=MAX_SEQUENCE_LENGTH, embed_dim=EMBED_DIM, n_label=n_label)\n        elif args.arch == \'swem\':\n            if proj_type == \'fastfood\':\n                model = build_model_text_swem_fastfood(embedding_matrix=embedding_matrix, weight_decay=args.l2, vsize=args.vsize, n_words=n_words, depth=args.depth, width=args.width, seq_length=MAX_SEQUENCE_LENGTH, embed_dim=EMBED_DIM, n_label=n_label)\n            else:\n                model = build_model_text_swem(embedding_matrix=embedding_matrix, weight_decay=args.l2, vsize=args.vsize, n_words=n_words, depth=args.depth, width=args.width, proj_type=proj_type, seq_length=MAX_SEQUENCE_LENGTH, embed_dim=EMBED_DIM, n_label=n_label)\n        elif args.arch == \'cnn_dir\':\n            model = build_model_text_cnn_dir(embedding_matrix=embedding_matrix, weight_decay=args.l2, n_words=n_words, depth=args.depth, width=args.width, seq_length=MAX_SEQUENCE_LENGTH, embed_dim=EMBED_DIM, n_label=n_label, n_max_pool=n_max_pool, n_stride=n_stride)   \n        elif args.arch == \'cnn\':\n            if proj_type == \'fastfood\':\n                model = build_model_text_cnn_fastfood(embedding_matrix=embedding_matrix, weight_decay=args.l2, vsize=args.vsize, n_words=n_words, depth=args.depth, width=args.width, seq_length=MAX_SEQUENCE_LENGTH, embed_dim=EMBED_DIM, n_label=n_label, n_max_pool=n_max_pool, n_stride=n_stride)\n            else:\n                model = build_model_text_cnn(embedding_matrix=embedding_matrix, weight_decay=args.l2, vsize=args.vsize, n_words=n_words, depth=args.depth, width=args.width, proj_type=proj_type, seq_length=MAX_SEQUENCE_LENGTH, embed_dim=EMBED_DIM, n_label=n_label, n_max_pool=n_max_pool, n_stride=n_stride)     \n        else:\n            raise Exception(\'Unknown network architecture: %s\' % args.arch)\n\n    print \'All model weights:\'\n    total_params = summarize_weights(model.trainable_weights)\n    print \'Model summary:\'\n    model.summary()\n\n    model.print_trainable_warnings()\n\n    input_lr = tf.placeholder(tf.float32, shape=[])\n    lr_stepper = LRStepper(args.lr, args.lr_ratio, args.lr_epochs, args.lr_steps)\n    \n    # 2. COMPUTE GRADS AND CREATE OPTIMIZER\n    if args.opt == \'sgd\':\n        opt = tf.train.MomentumOptimizer(input_lr, args.mom)\n    elif args.opt == \'rmsprop\':\n        opt = tf.train.RMSPropOptimizer(input_lr, momentum=args.mom)\n    elif args.opt == \'adam\':\n        opt = tf.train.AdamOptimizer(input_lr, args.beta1, args.beta2)\n\n    # Optimize w.r.t all trainable params in the model\n    grads_and_vars = opt.compute_gradients(model.v.loss, model.trainable_weights, gate_gradients=tf.train.Optimizer.GATE_GRAPH)\n    train_step = opt.apply_gradients(grads_and_vars)\n    add_grad_summaries(grads_and_vars)\n    summarize_opt(opt)\n\n    # 3. OPTIONALLY SAVE OR LOAD VARIABLES (e.g. model params, model running BN means, optimization momentum, ...) and then finalize initialization\n    saver = tf.train.Saver(max_to_keep=None) if (args.output or args.load) else None\n    if args.load:\n        ckptfile, miscfile = args.load.split(\':\')\n        # Restore values directly to graph\n        saver.restore(sess, ckptfile)\n        with gzip.open(miscfile) as ff:\n            saved = pickle.load(ff)\n            buddy = saved[\'buddy\']\n    else:\n        buddy = StatsBuddy()\n    buddy.tic()    # call if new run OR resumed run\n\n    # Initialize any missed vars (e.g. optimization momentum, ... if not loaded from checkpoint)\n    uninitialized_vars = tf_get_uninitialized_variables(sess)\n    init_missed_vars = tf.variables_initializer(uninitialized_vars, \'init_missed_vars\')\n\n    sess.run(init_missed_vars)\n\n    # Print warnings about any TF vs. Keras shape mismatches\n    warn_misaligned_shapes(model)\n    # Make sure all variables, which are model variables, have been initialized (e.g. model params and model running BN means)\n    tf_assert_all_init(sess)\n\n    # 3.5 Normalize the overall basis matrix across the (multiple) unnormalized basis matrices for each layer\n    basis_matrices = []\n    normalizers = []\n    \n    for layer in model.layers:\n        try:\n            basis_matrices.extend(layer.offset_creator.basis_matrices)\n        except AttributeError:\n            continue\n        try:\n            normalizers.extend(layer.offset_creator.basis_matrix_normalizers)\n        except AttributeError:\n            continue\n\n    if len(basis_matrices) > 0 and not args.load:\n\n        if proj_type == \'sparse\':\n\n            # Norm of overall basis matrix rows (num elements in each sum == total parameters in model)\n            bm_row_norms = tf.sqrt(tf.add_n([tf.sparse_reduce_sum(tf.square(bm), 1) for bm in basis_matrices]))\n            # Assign `normalizer` Variable to these row norms to achieve normalization of the basis matrix\n            # in the TF computational graph\n            rescale_basis_matrices = [tf.assign(var, tf.reshape(bm_row_norms,var.shape)) for var in normalizers]\n            _ = sess.run(rescale_basis_matrices)\n        elif proj_type == \'dense\':\n            bm_sums = [tf.reduce_sum(tf.square(bm), 1) for bm in basis_matrices]\n            divisor = tf.expand_dims(tf.sqrt(tf.add_n(bm_sums)), 1)\n            rescale_basis_matrices = [tf.assign(var, var / divisor) for var in basis_matrices]\n            _ = sess.run(rescale_basis_matrices)\n        else:\n            print \'\\nhere\\n\'\n            embed()\n\n            assert False, \'what to do with fastfood?\'\n\n    # 4. SETUP TENSORBOARD LOGGING\n    train_histogram_summaries = get_collection_intersection_summary(\'train_collection\', \'orig_histogram\')\n    train_scalar_summaries    = get_collection_intersection_summary(\'train_collection\', \'orig_scalar\')\n    val_histogram_summaries   = get_collection_intersection_summary(\'val_collection\', \'orig_histogram\')\n    val_scalar_summaries      = get_collection_intersection_summary(\'val_collection\', \'orig_scalar\')\n    param_histogram_summaries = get_collection_intersection_summary(\'param_collection\', \'orig_histogram\')\n\n    writer = None\n    if args.output:\n        mkdir_p(args.output)\n        if not args.skiptfevents:\n            writer = tf.summary.FileWriter(args.output, sess.graph)\n\n\n\n    # 5. TRAIN\n    train_iters = (len(train_y) - 1) / args.minibatch + 1\n    val_iters = (len(val_y) - 1) / args.minibatch + 1\n    impreproc = ImagePreproc()\n\n    if args.ipy:\n        print \'Embed: before train / val loop (Ctrl-D to continue)\'\n        embed()\n\n    fastest_avg_iter_time = 1e9\n    \n    while buddy.epoch < args.epochs + 1:\n        # How often to log data\n        do_log_params = lambda ep, it, ii: False\n        do_log_val = lambda ep, it, ii: True\n        do_log_train = lambda ep, it, ii: (it < train_iters and it & it-1 == 0 or it>=train_iters and it%train_iters == 0)  # Log on powers of two then every epoch\n\n        # 0. Log params\n        if args.output and do_log_params(buddy.epoch, buddy.train_iter, 0) and param_histogram_summaries is not None and not args.skiptfevents:\n            params_summary_str, = sess.run([param_histogram_summaries])\n            writer.add_summary(params_summary_str, buddy.train_iter)\n\n        # 1. Evaluate val set performance\n        if not args.skipval:\n            tic2()\n            for ii in xrange(val_iters):\n                start_idx = ii * args.minibatch\n                batch_x = val_x[start_idx:start_idx + args.minibatch]\n                batch_y = val_y[start_idx:start_idx + args.minibatch]\n\n                if randcrops:\n                    batch_x = impreproc.center_crops(batch_x, cropsize)\n                feed_dict = {\n                    model.v.input_sequences: batch_x,\n                    # model.v.input_masks: batch_mask,\n                    model.v.input_labels: batch_y,\n                    K.learning_phase(): 0,\n                }\n                fetch_dict = model.trackable_dict\n                with WithTimer(\'sess.run val iter\', quiet=not args.verbose):\n                    result_val = sess_run_dict(sess, fetch_dict, feed_dict=feed_dict)\n                \n                buddy.note_weighted_list(batch_x.shape[0], model.trackable_names, [result_val[k] for k in model.trackable_names], prefix=\'val_\')\n\n            if args.output and not args.skiptfevents and do_log_val(buddy.epoch, buddy.train_iter, 0):\n                log_scalars(writer, buddy.train_iter,\n                            {\'mean_%s\' % name: value for name, value in buddy.epoch_mean_list_re(\'^val_\')},\n                            prefix=\'buddy\')\n\n            print (\'\\ntime: %f. after training for %d epochs:\\n%3d val:   %s (%.3gs/i)\'\n                   % (buddy.toc(), buddy.epoch, buddy.train_iter, buddy.epoch_mean_pretty_re(\'^val_\', style=val_style), toc2() / val_iters))\n\n        # 2. Possiby Snapshot, possibly quit\n        if args.output and args.snapshot_to and args.snapshot_every:\n            snap_intermed = args.snapshot_every > 0 and buddy.train_iter % args.snapshot_every == 0\n            snap_end = buddy.epoch == args.epochs\n            if snap_intermed or snap_end:\n                # Snapshot\n                save_path = saver.save(sess, \'%s/%s_%04d.ckpt\' % (args.output, args.snapshot_to, buddy.epoch))\n                print \'snappshotted model to\', save_path\n                with gzip.open(\'%s/%s_misc_%04d.pkl.gz\' % (args.output, args.snapshot_to, buddy.epoch), \'w\') as ff:\n                    saved = {\'buddy\': buddy}\n                    pickle.dump(saved, ff)\n\n        if buddy.epoch == args.epochs:\n            if args.ipy:\n                print \'Embed: at end of training (Ctrl-D to exit)\'\n                embed()\n            break   # Extra pass at end: just report val stats and skip training\n\n        # 3. Train on training set\n        #train_order = range(train_x.shape[0])\n        if args.shuffletrain:\n            train_order = np.random.permutation(train_x.shape[0])\n\n        tic3()\n        for ii in xrange(train_iters):\n            tic2()\n            start_idx = ii * args.minibatch\n\n            if args.shuffletrain:\n                batch_x = train_x[train_order[start_idx:start_idx + args.minibatch]]\n                batch_y = train_y[train_order[start_idx:start_idx + args.minibatch]]\n            else:\n                batch_x = train_x[start_idx:start_idx + args.minibatch]\n                batch_y = train_y[start_idx:start_idx + args.minibatch]\n            if randcrops:\n                batch_x = impreproc.random_crops(batch_x, cropsize, randmirrors)\n\n\n            feed_dict = {\n                model.v.input_sequences: batch_x,\n                # model.v.input_masks: batch_mask,\n                model.v.input_labels: batch_y,\n                input_lr: lr_stepper.lr(buddy),\n                K.learning_phase(): 1,\n            }\n\n            fetch_dict = {\'train_step\': train_step}\n            fetch_dict.update(model.trackable_and_update_dict)\n\n            if args.output and not args.skiptfevents and do_log_train(buddy.epoch, buddy.train_iter, ii):\n                if param_histogram_summaries is not None:\n                    fetch_dict.update({\'param_histogram_summaries\': param_histogram_summaries})\n                if train_histogram_summaries is not None:\n                    fetch_dict.update({\'train_histogram_summaries\': train_histogram_summaries})\n                if train_scalar_summaries is not None:\n                    fetch_dict.update({\'train_scalar_summaries\': train_scalar_summaries})\n\n            with WithTimer(\'sess.run train iter\', quiet=not args.verbose):\n                result_train = sess_run_dict(sess, fetch_dict, feed_dict=feed_dict)\n\n            buddy.note_weighted_list(batch_x.shape[0], model.trackable_names, [result_train[k] for k in model.trackable_names], prefix=\'train_\')\n\n            if do_log_train(buddy.epoch, buddy.train_iter, ii):\n                print (\'%3d train: %s (%.3gs/i)\' % (buddy.train_iter, buddy.epoch_mean_pretty_re(\'^train_\', style=train_style), toc2()))\n                if args.output and not args.skiptfevents:\n                    if param_histogram_summaries is not None:\n                        hist_summary_str = result_train[\'param_histogram_summaries\']\n                        writer.add_summary(hist_summary_str, buddy.train_iter)\n                    if train_histogram_summaries is not None:\n                        hist_summary_str = result_train[\'train_histogram_summaries\']\n                        writer.add_summary(hist_summary_str, buddy.train_iter)\n                    if train_scalar_summaries is not None:\n                        scalar_summary_str = result_train[\'train_scalar_summaries\']\n                        writer.add_summary(scalar_summary_str, buddy.train_iter)\n                    log_scalars(writer, buddy.train_iter,\n                                {\'batch_%s\' % name: value for name, value in buddy.last_list_re(\'^train_\')},\n                                prefix=\'buddy\')\n\n            if ii > 0 and ii % 100 == 0:\n                avg_iter_time = toc3() / 100; tic3()\n                fastest_avg_iter_time = min(fastest_avg_iter_time, avg_iter_time)\n                print \'  %d: Average iteration time over last 100 train iters: %.3gs\' % (ii, avg_iter_time)\n\n            buddy.inc_train_iter()   # after finished training a mini-batch\n\n        buddy.inc_epoch()   # after finished training whole pass through set\n\n        if args.output and not args.skiptfevents and do_log_train(buddy.epoch, buddy.train_iter, 0):\n            log_scalars(writer, buddy.train_iter,\n                        {\'mean_%s\' % name: value for name,value in buddy.epoch_mean_list_re(\'^train_\')},\n                        prefix=\'buddy\')\n\n    print \'\\nFinal\'\n    print \'%02d:%d val:   %s\' % (buddy.epoch, buddy.train_iter, buddy.epoch_mean_pretty_re(\'^val_\', style=val_style))\n    print \'%02d:%d train: %s\' % (buddy.epoch, buddy.train_iter, buddy.epoch_mean_pretty_re(\'^train_\', style=train_style))\n\n    print \'\\nfinal_stats epochs %g\' % buddy.epoch\n    print \'final_stats iters %g\' % buddy.train_iter\n    print \'final_stats time %g\' % buddy.toc()\n    print \'final_stats total_params %g\' % total_params\n    print \'final_stats fastest_avg_iter_time %g\' % fastest_avg_iter_time\n    for name, value in buddy.epoch_mean_list_all():\n        print \'final_stats %s %g\' % (name, value)\n\n    if args.output and not args.skiptfevents:\n        writer.close()   # Flush and close\n\n\nif __name__ == \'__main__\':\n    main()\n'"
intrinsic_dimension/intrinsic_dim/train_text.py,15,"b'#! /usr/bin/env python\n\nimport sys\nimport os\nimport gzip\nimport cPickle as pickle\nimport numpy as np\nimport h5py\nfrom IPython import embed\nimport colorama\nimport tensorflow as tf\nimport keras.backend as K\nimport pdb\n\nlab_root = os.path.join(os.path.abspath(os.path.dirname(__file__)), \'..\')\nsys.path.insert(1, lab_root)\n\nfrom general.util import tic, toc, tic2, toc2, tic3, toc3, mkdir_p, WithTimer\nfrom general.image_preproc import ImagePreproc\nfrom general.stats_buddy import StatsBuddy\nfrom general.tfutil import (get_collection_intersection_summary,\n                           log_scalars, sess_run_dict, \n                           summarize_weights, summarize_opt,\n                           tf_assert_all_init, \n                           tf_get_uninitialized_variables, \n                           add_grad_summaries)\nfrom keras_ext.util import setup_session_and_seeds, warn_misaligned_shapes\nfrom model_builders import (build_model_mnist_fc_dir, \n                            build_model_mnist_fc, \n                            build_cnn_model_direct_mnist, \n                            build_cnn_model_mnist, \n                            build_LeNet_direct_mnist, \n                            build_LeNet_mnist, \n                            build_LeNet_direct_cifar, \n                            build_LeNet_cifar, \n                            build_DenseNet_direct_cifar, \n                            build_model_cifar_fc_dir, \n                            build_model_cifar_fc,\n                            build_model_mnist_fc_fastfood, \n                            build_model_cifar_fc_fastfood, \n                            build_model_cifar_LeNet_fastfood, \n                            build_alexnet_direct, \n                            build_alexnet_fastfood, \n                            build_squeezenet_direct, \n                            build_model_mnist_LeNet_fastfood,\n                            build_DenseNet_cifar_fastfood,\n                            build_MLPLeNet_direct_mnist,\n                            build_model_mnist_MLPLeNet_fastfood,\n                            build_MLPLeNet_direct_cifar,\n                            build_model_cifar_MLPLeNet_fastfood,\n                            build_UntiedLeNet_direct_mnist,\n                            build_model_mnist_UntiedLeNet_fastfood,\n                            build_UntiedLeNet_direct_cifar,\n                            build_model_cifar_UntiedLeNet_fastfood)\nfrom standard_parser import make_standard_parser\n\n\narch_choices_direct = [\'mnistfc_dir\', \'cifarfc_dir\', \'mnistconv_dir\', \'mnistlenet_dir\', \'cifarlenet_dir\', \'cifarDenseNet_dir\', \'alexnet_dir\', \'squeeze_dir\', \'mnistMLPlenet_dir\', \'cifarMLPlenet_dir\', \'mnistUntiedlenet_dir\', \'cifarUntiedlenet_dir\']\narch_choices_projected = [\'mnistfc\', \'cifarfc\', \'mnistconv\', \'mnistlenet\', \'cifar\', \'cifarlenet\', \'cifarDenseNet\', \'alexnet\', \'mnistMLPlenet\', \'cifarMLPlenet\', \'mnistUntiedlenet\', \'cifarUntiedlenet\']\narch_choices = arch_choices_direct + arch_choices_projected\n\nclass LRStepper(object):\n    def __init__(self, lr_init, lr_ratio, lr_epochs, lr_steps):\n        self.lr_init = lr_init\n        self.lr_ratio = lr_ratio\n        self.lr_epochs = lr_epochs\n        self.lr_steps = lr_steps\n        self.last_printed = None\n\n    def lr(self, buddy):\n        if self.lr_ratio == 0 or self.lr_epochs == 0:\n            return self.lr_init\n        ret = self.lr_init * self.lr_ratio ** int(min(buddy.epoch / self.lr_epochs, self.lr_steps))\n        if ret != self.last_printed:\n            print \'At epoch %d setting LR to %g\' % (buddy.epoch, ret)\n            self.last_printed = ret\n        return ret\n\n\ndef prepare_data_for_cnn(seqs_x, maxlen, filter_shape):\n    maxlen = maxlen\n    filter_h = filter_shape\n    lengths_x = [len(s) for s in seqs_x]\n    # print lengths_x\n    if maxlen != None:\n        new_seqs_x = []\n        new_lengths_x = []\n        for l_x, s_x in zip(lengths_x, seqs_x):\n            if l_x < maxlen:\n                new_seqs_x.append(s_x)\n                new_lengths_x.append(l_x)\n            else:\n                new_seqs_x.append(s_x[:maxlen - 1])\n                new_lengths_x.append(maxlen - 1)\n        lengths_x = new_lengths_x\n\n        if len(seqs_x) != len(new_seqs_x):\n            pdb.set_trace()\n\n        seqs_x = new_seqs_x\n\n        if len(lengths_x) < 1:\n            return None, None\n\n    pad = filter_h - 1\n    x = []\n    for rev in seqs_x:\n        xx = []\n        for i in xrange(pad):\n            xx.append(0)\n        for idx in rev:\n            xx.append(idx)\n        while len(xx) < maxlen + 2 * pad:\n            xx.append(0)\n        x.append(xx)\n    x = np.array(x, dtype=\'int32\')\n    #pdb.set_trace()\n    return x\n\ndef main():\n    parser = make_standard_parser(\'Random Projection Experiments.\', arch_choices=arch_choices)\n\n    parser.add_argument(\'--vsize\', type=int, default=100, help=\'Dimension of intrinsic parmaeter space.\')\n    parser.add_argument(\'--d_rate\', \'--dr\', type=float, default=0.0, help=\'Dropout rate.\')\n    parser.add_argument(\'--depth\', type=int, default=2, help=\'Number of layers in FNN.\')\n    parser.add_argument(\'--width\', type=int, default=100, help=\'Width of  layers in FNN.\')\n    parser.add_argument(\'--minibatch\', \'--mb\', type=int, default=128, help=\'Size of minibatch.\')\n    parser.add_argument(\'--lr_ratio\', \'--lrr\', type=float, default=.1, help=\'Ratio to decay LR by every LR_EPSTEP epochs.\')\n    parser.add_argument(\'--lr_epochs\', \'--lrep\', type=float, default=0, help=\'Decay LR every LR_EPSTEP epochs. 0 to turn off decay.\')\n    parser.add_argument(\'--lr_steps\', \'--lrst\', type=float, default=3, help=\'Max LR steps.\')\n\n    parser.add_argument(\'--c1\', type=int, default=6, help=\'Channels in first conv layer, for LeNet.\')\n    parser.add_argument(\'--c2\', type=int, default=16, help=\'Channels in second conv layer, for LeNet.\')\n    parser.add_argument(\'--d1\', type=int, default=120, help=\'Channels in first dense layer, for LeNet.\')\n    parser.add_argument(\'--d2\', type=int, default=84, help=\'Channels in second dense layer, for LeNet.\')\n    \n    parser.add_argument(\'--denseproj\', action=\'store_true\', help=\'Use a dense projection.\')\n    parser.add_argument(\'--sparseproj\', action=\'store_true\', help=\'Use a sparse projection.\')\n    parser.add_argument(\'--fastfoodproj\', action=\'store_true\', help=\'Use a fastfood projection.\')\n\n    parser.add_argument(\'--partial_data\', \'--pd\', type=float, default=1.0, help=\'Percentage of dataset.\')\n\n    parser.add_argument(\'--skiptfevents\', action=\'store_true\', help=\'Skip writing tf events files even if output is used.\')\n\n    args = parser.parse_args()\n\n    n_proj_specified = sum([args.denseproj, args.sparseproj, args.fastfoodproj])\n    if args.arch in arch_choices_projected:\n        assert n_proj_specified == 1, \'Arch ""%s"" requires projection. Specify exactly one of {denseproj, sparseproj, fastfoodproj} options.\' % args.arch\n    else:\n        assert n_proj_specified == 0, \'Arch ""%s"" does not require projection, so do not specify any of {denseproj, sparseproj, fastfoodproj} options.\' % args.arch\n\n    if args.denseproj:\n        proj_type = \'dense\'\n    elif args.sparseproj:\n        proj_type = \'sparse\'\n    else:\n        proj_type = \'fastfood\'\n\n    train_style, val_style = (\'\', \'\') if args.nocolor else (colorama.Fore.BLUE, colorama.Fore.MAGENTA)\n\n    # Get a TF session registered with Keras and set numpy and TF seeds\n    sess = setup_session_and_seeds(args.seed)\n\n    # 0. LOAD DATA\n    train_h5 = h5py.File(args.train_h5, \'r\')\n    train_x = train_h5[\'images\']\n    train_y = train_h5[\'labels\']\n    val_h5 = h5py.File(args.val_h5, \'r\')\n    val_x = val_h5[\'images\']\n    val_y = val_h5[\'labels\']\n\n    # loadpath = ""./dataset/ag_news.p""\n    # x = pickle.load(open(loadpath, ""rb""))\n    # train_x, val_x, test_x = x[0], x[1], x[2]\n    # train_y, val_y, test_y = x[3], x[4], x[5]\n    # wordtoix, ixtoword = x[6], x[7]\n\n    # train_x = prepare_data_for_cnn(train_x, 100, 5)\n    # val_x = prepare_data_for_cnn(val_x, 100, 5)\n\n    # #weightInit = tf.random_uniform_initializer(-0.001, 0.001)\n    # #W = tf.get_variable(\'W\', [13010, 300], initializer=weightInit)\n\n    # W = np.random.rand(13010, 300)\n\n    # #pdb.set_trace()\n\n    # train_x = [np.take(W, i, axis=0) for i in train_x]\n    # train_x = np.array(train_x, dtype=\'float32\')\n\n    # val_x = [np.take(W, i, axis=0) for i in val_x]\n    # val_x = np.array(val_x, dtype=\'float32\')\n\n    #pdb.set_trace()\n\n    train_x = np.array(train_x, dtype=\'float32\')\n    val_x = np.array(val_x, dtype=\'float32\')\n\n    if args.partial_data < 1.0:\n        n_train_ = int(train_y.size*args.partial_data)       \n        n_test_  = int(val_y.size*args.partial_data)       \n        train_x = train_x[:n_train_]\n        train_y = train_y[:n_train_]\n        val_x = val_x[:n_test_]\n        val_y = val_y[:n_test_]\n\n    # load into memory if less than 1 GB\n    if train_x.size * 4 + val_x.size * 4 < 1e9:\n        train_x, train_y = np.array(train_x), np.array(train_y)\n        val_x, val_y = np.array(val_x), np.array(val_y)\n\n    # 1. CREATE MODEL\n    randmirrors = False\n    randcrops = False\n    cropsize = None\n\n    with WithTimer(\'Make model\'):\n        if args.arch == \'mnistfc_dir\':\n            model = build_model_mnist_fc_dir(weight_decay=args.l2, depth=args.depth, width=args.width)\n        elif args.arch == \'mnistfc\':\n            if proj_type == \'fastfood\':\n                model = build_model_mnist_fc_fastfood(weight_decay=args.l2, vsize=args.vsize, depth=args.depth, width=args.width)\n            else:\n                model = build_model_mnist_fc(weight_decay=args.l2, vsize=args.vsize, depth=args.depth, width=args.width, proj_type=proj_type)\n        elif args.arch == \'mnistconv\':\n            model = build_cnn_model_mnist(weight_decay=args.l2, vsize=args.vsize)\n        elif args.arch == \'mnistconv_dir\':\n            model = build_cnn_model_direct_mnist(weight_decay=args.l2)\n        elif args.arch == \'cifarfc_dir\':\n            model = build_model_cifar_fc_dir(weight_decay=args.l2, depth=args.depth, width=args.width)\n        elif args.arch == \'cifarfc\':\n            if proj_type == \'fastfood\':\n                model = build_model_cifar_fc_fastfood(weight_decay=args.l2, vsize=args.vsize, depth=args.depth, width=args.width)\n            else:\n                model = build_model_cifar_fc(weight_decay=args.l2, vsize=args.vsize, depth=args.depth, width=args.width, proj_type=proj_type)\n        elif args.arch == \'mnistlenet_dir\':\n            model = build_LeNet_direct_mnist(weight_decay=args.l2, c1=args.c1, c2=args.c2, d1=args.d1, d2=args.d2)\n\n        elif args.arch == \'mnistMLPlenet_dir\':\n            model = build_MLPLeNet_direct_mnist(weight_decay=args.l2)\n        elif args.arch == \'mnistMLPlenet\':\n            if proj_type == \'fastfood\':\n                model = build_model_mnist_MLPLeNet_fastfood(weight_decay=args.l2, vsize=args.vsize)\n\n        elif args.arch == \'mnistUntiedlenet_dir\':\n            model = build_UntiedLeNet_direct_mnist(weight_decay=args.l2)\n        elif args.arch == \'mnistUntiedlenet\':\n            if proj_type == \'fastfood\':\n                model = build_model_mnist_UntiedLeNet_fastfood(weight_decay=args.l2, vsize=args.vsize)\n\n\n        elif args.arch == \'cifarMLPlenet_dir\':\n            model = build_MLPLeNet_direct_cifar(weight_decay=args.l2)\n        elif args.arch == \'cifarMLPlenet\':\n            if proj_type == \'fastfood\':\n                model = build_model_cifar_MLPLeNet_fastfood(weight_decay=args.l2, vsize=args.vsize)\n\n\n        elif args.arch == \'cifarUntiedlenet_dir\':\n            model = build_UntiedLeNet_direct_cifar(weight_decay=args.l2)\n        elif args.arch == \'cifarUntiedlenet\':\n            if proj_type == \'fastfood\':\n                model = build_model_cifar_UntiedLeNet_fastfood(weight_decay=args.l2, vsize=args.vsize)\n\n\n        elif args.arch == \'mnistlenet\':\n            if proj_type == \'fastfood\':\n                model = build_model_mnist_LeNet_fastfood(weight_decay=args.l2, vsize=args.vsize)\n            else:\n                model = build_LeNet_mnist(weight_decay=args.l2, vsize=args.vsize, proj_type=proj_type)\n            \n        elif args.arch == \'cifarlenet_dir\':\n            model = build_LeNet_direct_cifar(weight_decay=args.l2,  d_rate=args.d_rate, c1=args.c1, c2=args.c2, d1=args.d1, d2=args.d2)\n        elif args.arch == \'cifarlenet\':\n            if proj_type == \'fastfood\':\n                model = build_model_cifar_LeNet_fastfood(weight_decay=args.l2, vsize=args.vsize, d_rate=args.d_rate, c1=args.c1, c2=args.c2, d1=args.d1, d2=args.d2)\n            else:\n                model = build_LeNet_cifar(weight_decay=args.l2, vsize=args.vsize, proj_type=proj_type, d_rate=args.d_rate)\n        elif args.arch == \'cifarDenseNet_dir\':\n            model = build_DenseNet_direct_cifar(weight_decay=args.l2,  depth=25, nb_dense_block=1, growth_rate=12)\n        elif args.arch == \'cifarDenseNet\':\n            if proj_type == \'fastfood\':\n                model = build_DenseNet_cifar_fastfood(weight_decay=args.l2, vsize=args.vsize, depth=25, nb_dense_block=1, growth_rate=12)\n        \n        elif args.arch == \'alexnet_dir\':\n            model = build_alexnet_direct(weight_decay=args.l2, shift_in=np.array([104, 117, 123]))\n            args.shuffletrain = False\n            randmirrors = True\n            randcrops = True\n            cropsize = (227,227)\n        \n        elif args.arch == \'squeeze_dir\':\n            model = build_squeezenet_direct(weight_decay=args.l2, shift_in=np.array([104, 117, 123]))\n            args.shuffletrain = False\n            randmirrors = True\n            randcrops = True\n            cropsize = (224,224)\n        \n        elif args.arch == \'alexnet\':\n            if proj_type == \'fastfood\':\n                model = build_alexnet_fastfood(weight_decay=args.l2, shift_in=np.array([104, 117, 123]), vsize=args.vsize)\n            else:\n                raise Exception(\'not implemented\')\n            args.shuffletrain = False\n            randmirrors = True\n            randcrops = True\n            cropsize = (227,227)\n        else:\n            raise Exception(\'Unknown network architecture: %s\' % args.arch)\n\n    print \'All model weights:\'\n    total_params = summarize_weights(model.trainable_weights)\n    print \'Model summary:\'\n    model.summary()\n\n    model.print_trainable_warnings()\n\n    input_lr = tf.placeholder(tf.float32, shape=[])\n    lr_stepper = LRStepper(args.lr, args.lr_ratio, args.lr_epochs, args.lr_steps)\n    \n    # 2. COMPUTE GRADS AND CREATE OPTIMIZER\n    if args.opt == \'sgd\':\n        opt = tf.train.MomentumOptimizer(input_lr, args.mom)\n    elif args.opt == \'rmsprop\':\n        opt = tf.train.RMSPropOptimizer(input_lr, momentum=args.mom)\n    elif args.opt == \'adam\':\n        opt = tf.train.AdamOptimizer(input_lr, args.beta1, args.beta2)\n\n    # Optimize w.r.t all trainable params in the model\n    grads_and_vars = opt.compute_gradients(model.v.loss, model.trainable_weights, gate_gradients=tf.train.Optimizer.GATE_GRAPH)\n    train_step = opt.apply_gradients(grads_and_vars)\n    add_grad_summaries(grads_and_vars)\n    summarize_opt(opt)\n\n    # 3. OPTIONALLY SAVE OR LOAD VARIABLES (e.g. model params, model running BN means, optimization momentum, ...) and then finalize initialization\n    saver = tf.train.Saver(max_to_keep=None) if (args.output or args.load) else None\n    if args.load:\n        ckptfile, miscfile = args.load.split(\':\')\n        # Restore values directly to graph\n        saver.restore(sess, ckptfile)\n        with gzip.open(miscfile) as ff:\n            saved = pickle.load(ff)\n            buddy = saved[\'buddy\']\n    else:\n        buddy = StatsBuddy()\n    buddy.tic()    # call if new run OR resumed run\n\n    # Initialize any missed vars (e.g. optimization momentum, ... if not loaded from checkpoint)\n    uninitialized_vars = tf_get_uninitialized_variables(sess)\n    init_missed_vars = tf.variables_initializer(uninitialized_vars, \'init_missed_vars\')\n\n    sess.run(init_missed_vars)\n\n    # Print warnings about any TF vs. Keras shape mismatches\n    warn_misaligned_shapes(model)\n    # Make sure all variables, which are model variables, have been initialized (e.g. model params and model running BN means)\n    tf_assert_all_init(sess)\n\n    # 3.5 Normalize the overall basis matrix across the (multiple) unnormalized basis matrices for each layer\n    basis_matrices = []\n    normalizers = []\n    \n    for layer in model.layers:\n        try:\n            basis_matrices.extend(layer.offset_creator.basis_matrices)\n        except AttributeError:\n            continue\n        try:\n            normalizers.extend(layer.offset_creator.basis_matrix_normalizers)\n        except AttributeError:\n            continue\n\n    if len(basis_matrices) > 0 and not args.load:\n\n        if proj_type == \'sparse\':\n\n            # Norm of overall basis matrix rows (num elements in each sum == total parameters in model)\n            bm_row_norms = tf.sqrt(tf.add_n([tf.sparse_reduce_sum(tf.square(bm), 1) for bm in basis_matrices]))\n            # Assign `normalizer` Variable to these row norms to achieve normalization of the basis matrix\n            # in the TF computational graph\n            rescale_basis_matrices = [tf.assign(var, tf.reshape(bm_row_norms,var.shape)) for var in normalizers]\n            _ = sess.run(rescale_basis_matrices)\n        elif proj_type == \'dense\':\n            bm_sums = [tf.reduce_sum(tf.square(bm), 1) for bm in basis_matrices]\n            divisor = tf.expand_dims(tf.sqrt(tf.add_n(bm_sums)), 1)\n            rescale_basis_matrices = [tf.assign(var, var / divisor) for var in basis_matrices]\n            _ = sess.run(rescale_basis_matrices)\n        else:\n            print \'\\nhere\\n\'\n            embed()\n\n            assert False, \'what to do with fastfood?\'\n\n    # 4. SETUP TENSORBOARD LOGGING\n    train_histogram_summaries = get_collection_intersection_summary(\'train_collection\', \'orig_histogram\')\n    train_scalar_summaries    = get_collection_intersection_summary(\'train_collection\', \'orig_scalar\')\n    val_histogram_summaries   = get_collection_intersection_summary(\'val_collection\', \'orig_histogram\')\n    val_scalar_summaries      = get_collection_intersection_summary(\'val_collection\', \'orig_scalar\')\n    param_histogram_summaries = get_collection_intersection_summary(\'param_collection\', \'orig_histogram\')\n\n    writer = None\n    if args.output:\n        mkdir_p(args.output)\n        if not args.skiptfevents:\n            writer = tf.summary.FileWriter(args.output, sess.graph)\n\n\n\n    # 5. TRAIN\n    train_iters = (train_y.shape[0] - 1) / args.minibatch + 1\n    val_iters = (val_y.shape[0] - 1) / args.minibatch + 1\n    impreproc = ImagePreproc()\n\n    if args.ipy:\n        print \'Embed: before train / val loop (Ctrl-D to continue)\'\n        embed()\n\n    fastest_avg_iter_time = 1e9\n    \n    while buddy.epoch < args.epochs + 1:\n        # How often to log data\n        do_log_params = lambda ep, it, ii: False\n        do_log_val = lambda ep, it, ii: True\n        do_log_train = lambda ep, it, ii: (it < train_iters and it & it-1 == 0 or it>=train_iters and it%train_iters == 0)  # Log on powers of two then every epoch\n\n        # 0. Log params\n        if args.output and do_log_params(buddy.epoch, buddy.train_iter, 0) and param_histogram_summaries is not None and not args.skiptfevents:\n            params_summary_str, = sess.run([param_histogram_summaries])\n            writer.add_summary(params_summary_str, buddy.train_iter)\n\n        # 1. Evaluate val set performance\n        if not args.skipval:\n            tic2()\n            for ii in xrange(val_iters):\n                start_idx = ii * args.minibatch\n                batch_x = val_x[start_idx:start_idx + args.minibatch]\n                batch_y = val_y[start_idx:start_idx + args.minibatch]\n                if randcrops:\n                    batch_x = impreproc.center_crops(batch_x, cropsize)\n                feed_dict = {\n                    model.v.input_images: batch_x,\n                    model.v.input_labels: batch_y,\n                    K.learning_phase(): 0,\n                }\n                fetch_dict = model.trackable_dict\n                with WithTimer(\'sess.run val iter\', quiet=not args.verbose):\n                    result_val = sess_run_dict(sess, fetch_dict, feed_dict=feed_dict)\n                \n                buddy.note_weighted_list(batch_x.shape[0], model.trackable_names, [result_val[k] for k in model.trackable_names], prefix=\'val_\')\n\n            if args.output and not args.skiptfevents and do_log_val(buddy.epoch, buddy.train_iter, 0):\n                log_scalars(writer, buddy.train_iter,\n                            {\'mean_%s\' % name: value for name, value in buddy.epoch_mean_list_re(\'^val_\')},\n                            prefix=\'buddy\')\n\n            print (\'\\ntime: %f. after training for %d epochs:\\n%3d val:   %s (%.3gs/i)\'\n                   % (buddy.toc(), buddy.epoch, buddy.train_iter, buddy.epoch_mean_pretty_re(\'^val_\', style=val_style), toc2() / val_iters))\n\n        # 2. Possiby Snapshot, possibly quit\n        if args.output and args.snapshot_to and args.snapshot_every:\n            snap_intermed = args.snapshot_every > 0 and buddy.train_iter % args.snapshot_every == 0\n            snap_end = buddy.epoch == args.epochs\n            if snap_intermed or snap_end:\n                # Snapshot\n                save_path = saver.save(sess, \'%s/%s_%04d.ckpt\' % (args.output, args.snapshot_to, buddy.epoch))\n                print \'snappshotted model to\', save_path\n                with gzip.open(\'%s/%s_misc_%04d.pkl.gz\' % (args.output, args.snapshot_to, buddy.epoch), \'w\') as ff:\n                    saved = {\'buddy\': buddy}\n                    pickle.dump(saved, ff)\n\n        if buddy.epoch == args.epochs:\n            if args.ipy:\n                print \'Embed: at end of training (Ctrl-D to exit)\'\n                embed()\n            break   # Extra pass at end: just report val stats and skip training\n\n        # 3. Train on training set\n        #train_order = range(train_x.shape[0])\n        if args.shuffletrain:\n            train_order = np.random.permutation(train_x.shape[0])\n\n        tic3()\n        for ii in xrange(train_iters):\n            tic2()\n            start_idx = ii * args.minibatch\n\n            if args.shuffletrain:\n                batch_x = train_x[train_order[start_idx:start_idx + args.minibatch]]\n                batch_y = train_y[train_order[start_idx:start_idx + args.minibatch]]\n            else:\n                batch_x = train_x[start_idx:start_idx + args.minibatch]\n                batch_y = train_y[start_idx:start_idx + args.minibatch]\n            if randcrops:\n                batch_x = impreproc.random_crops(batch_x, cropsize, randmirrors)\n            feed_dict = {\n                model.v.input_images: batch_x,\n                model.v.input_labels: batch_y,\n                input_lr: lr_stepper.lr(buddy),\n                K.learning_phase(): 1,\n            }\n\n            fetch_dict = {\'train_step\': train_step}\n            fetch_dict.update(model.trackable_and_update_dict)\n\n            if args.output and not args.skiptfevents and do_log_train(buddy.epoch, buddy.train_iter, ii):\n                if param_histogram_summaries is not None:\n                    fetch_dict.update({\'param_histogram_summaries\': param_histogram_summaries})\n                if train_histogram_summaries is not None:\n                    fetch_dict.update({\'train_histogram_summaries\': train_histogram_summaries})\n                if train_scalar_summaries is not None:\n                    fetch_dict.update({\'train_scalar_summaries\': train_scalar_summaries})\n\n            with WithTimer(\'sess.run train iter\', quiet=not args.verbose):\n                result_train = sess_run_dict(sess, fetch_dict, feed_dict=feed_dict)\n\n            buddy.note_weighted_list(batch_x.shape[0], model.trackable_names, [result_train[k] for k in model.trackable_names], prefix=\'train_\')\n\n            if do_log_train(buddy.epoch, buddy.train_iter, ii):\n                print (\'%3d train: %s (%.3gs/i)\' % (buddy.train_iter, buddy.epoch_mean_pretty_re(\'^train_\', style=train_style), toc2()))\n                if args.output and not args.skiptfevents:\n                    if param_histogram_summaries is not None:\n                        hist_summary_str = result_train[\'param_histogram_summaries\']\n                        writer.add_summary(hist_summary_str, buddy.train_iter)\n                    if train_histogram_summaries is not None:\n                        hist_summary_str = result_train[\'train_histogram_summaries\']\n                        writer.add_summary(hist_summary_str, buddy.train_iter)\n                    if train_scalar_summaries is not None:\n                        scalar_summary_str = result_train[\'train_scalar_summaries\']\n                        writer.add_summary(scalar_summary_str, buddy.train_iter)\n                    log_scalars(writer, buddy.train_iter,\n                                {\'batch_%s\' % name: value for name, value in buddy.last_list_re(\'^train_\')},\n                                prefix=\'buddy\')\n\n            if ii > 0 and ii % 100 == 0:\n                avg_iter_time = toc3() / 100; tic3()\n                fastest_avg_iter_time = min(fastest_avg_iter_time, avg_iter_time)\n                print \'  %d: Average iteration time over last 100 train iters: %.3gs\' % (ii, avg_iter_time)\n\n            buddy.inc_train_iter()   # after finished training a mini-batch\n\n        buddy.inc_epoch()   # after finished training whole pass through set\n\n        if args.output and not args.skiptfevents and do_log_train(buddy.epoch, buddy.train_iter, 0):\n            log_scalars(writer, buddy.train_iter,\n                        {\'mean_%s\' % name: value for name,value in buddy.epoch_mean_list_re(\'^train_\')},\n                        prefix=\'buddy\')\n\n    print \'\\nFinal\'\n    print \'%02d:%d val:   %s\' % (buddy.epoch, buddy.train_iter, buddy.epoch_mean_pretty_re(\'^val_\', style=val_style))\n    print \'%02d:%d train: %s\' % (buddy.epoch, buddy.train_iter, buddy.epoch_mean_pretty_re(\'^train_\', style=train_style))\n\n    print \'\\nfinal_stats epochs %g\' % buddy.epoch\n    print \'final_stats iters %g\' % buddy.train_iter\n    print \'final_stats time %g\' % buddy.toc()\n    print \'final_stats total_params %g\' % total_params\n    print \'final_stats fastest_avg_iter_time %g\' % fastest_avg_iter_time\n    for name, value in buddy.epoch_mean_list_all():\n        print \'final_stats %s %g\' % (name, value)\n\n    if args.output and not args.skiptfevents:\n        writer.close()   # Flush and close\n\n\nif __name__ == \'__main__\':\n    main()\n'"
intrinsic_dimension/keras_ext/__init__.py,0,b''
intrinsic_dimension/keras_ext/engine.py,0,"b'from engine_training import ExtendedModel, LazyModel\nfrom engine_topology import LazyContainer\n'"
intrinsic_dimension/keras_ext/engine_topology.py,0,"b""from keras.layers import Input\nfrom keras.engine.topology import Container\n\nfrom .util import full_static_shape\n\n\n\nclass LazyContainer(Container):\n    '''Like Container. But lazy.'''\n    \n    def __init__(self, container_function, use_method_disposable=True):\n        self._container_function = container_function\n        self._lazy_has_run = False\n        self.use_method_disposable = use_method_disposable\n        # Delay rest of construction until first call\n        \n    def __call__(self, x, mask=None):\n        if not self._lazy_has_run:\n            # Make short-lived Input Layers for each x this was called with\n            # TODO: handle tuple or list x\n            x_shape = full_static_shape(x)   # Uses var._keras_shape or var.get_shape()\n            if self.use_method_disposable:\n                inp_layer = Input(batch_shape=x_shape,\n                                  dtype=x.dtype,\n                                  name='tmp_input_from__%s' % x.name.replace('/','_').replace(':','_'))\n            else:\n                print 'Warning: using non-disposable approach. May not work yet.'\n                inp_layer = Input(tensor=x,\n                                  batch_shape=x_shape,\n                                  dtype=x.dtype, name='real_input_from__%s' % x.name.replace('/','_').replace(':','_'))\n\n            # Call function of inputs to get output tensors\n            outputs = self._container_function(inp_layer)\n\n            # Initialize entire Container object here (finally)\n            super(LazyContainer, self).__init__(inp_layer, outputs)\n            \n            self._lazy_has_run = True\n            if not self.use_method_disposable:\n                return outputs\n\n        # Non-disposable mode: actually call the Container only the *second* and later times\n        # Disposable mode: call the Container now\n        ret = super(LazyContainer, self).__call__(x, mask=mask)\n        return ret\n"""
intrinsic_dimension/keras_ext/engine_training.py,7,"b'#from IPython import embed\nimport tensorflow as tf\nfrom keras.models import Model\nfrom keras.layers import Input\n\nfrom general.util import DotDict\nfrom .util import full_static_shape\n\n\n\nclass ExtendedModel(Model):\n    \'\'\'Slight extensions of the Keras model class.\'\'\'\n    \n    def __init__(self, input, output, name=None):\n        super(ExtendedModel, self).__init__(input, output, name=name)\n        self.v = DotDict()\n        #self._vars = OrderedDict()\n        self._trackable = set()\n        self._extra_trainable_weights = []\n        self._extra_non_trainable_weights = []\n\n    def add_loss_reg(self):\n        \'\'\'Adds losses for all attached regularizers\'\'\'\n\n        # New Keras interface for regularization / etc layer losses\n        losses = []\n        for loss in self.losses:\n            if loss is None or loss == 0 or loss == 0.0:\n                continue\n            losses.append(loss)\n\n        if len(losses) > 0:\n            print \'Regularizer and other internal losses from model: %d losses\' % len(losses)\n            for loss in losses:\n                print \'   loss var=%s\' % loss\n            self.add_trackable(\'loss_reg\', tf.add_n(losses, name=\'loss_reg\'))\n        if \'loss_reg\' not in self.v:\n            print \'Regularizer and other internal losses from model: none to add.\'\n        \n    def add_var(self, name_or_var, var=None, trackable=False):\n        \'\'\'Call like self.add_var(\'name\', var) or self.add_var(var) to use var.name as name.\'\'\'\n        if var is None:\n            var = name_or_var\n            name = var.name\n        else:\n            name = name_or_var\n        self.v[name] = var\n        if trackable:\n            self._trackable.add(name)\n        elif name in self._trackable:\n            self._trackable.remove(name)\n\n    def add_vars(self, names_or_vars, varss=None, trackable=False):\n        \'\'\'Call with:\n         - one list of vars\n         - equal length lists of names and vars\n         - dict of name: var pairs\n        \'\'\'\n        if isinstance(names_or_vars, dict):\n            for name,var in names_or_vars.iteritems():\n                self.add_var(name, var, trackable=trackable)\n        elif varss is None:\n            for var in names_or_vars:\n                self.add_var(var, var=None, trackable=trackable)\n        else:\n            assert len(names_or_vars) == len(varss), \'should be two lists of equal length\'\n            for name,var in zip(names_or_vars, varss):\n                self.add_var(name, var, trackable=trackable)\n\n    def add_trackable(self, name_or_var, var=None):\n        self.add_var(name_or_var, var=var, trackable=True)\n\n    def add_trackables(self, names_or_vars, varss=None):\n        self.add_vars(names_or_vars, varss=varss, trackable=True)\n\n    def del_var(self, name):\n        \'\'\'Remove var if it exists\'\'\'\n        if name in self.v:\n            del self.v[name]\n            if name in self._trackable:\n                self._trackable.remove(name)\n\n    @property\n    def var_names(self):\n        return self.v.keys()\n\n    @property\n    def trackable_names(self):\n        return [k for k in self.var_names if k in self._trackable]\n\n    @property\n    def vars(self):\n        return self.get_vars()\n\n    def get_vars(self, var_names=None):\n        if var_names is None:\n            var_names = self.var_names\n        return [self.v[name] for name in var_names]\n\n    @property\n    def tensors(self):\n        return self.get_tensors()\n            \n    def get_tensors(self, tensor_names=None):\n        return [vv for vv in self.get_vars(var_names=tensor_names) if isinstance(vv, tf.Tensor)]\n    \n    @property\n    def trackable_vars(self):\n        return [self.v[k] for k in self.var_names if k in self._trackable]\n    \n    @property\n    def trackable_dict(self):\n        return self.get_tensor_dict(self.trackable_names)\n\n    @property\n    def update_dict(self):\n        return {\'update__%d\' % ii: update for ii, update in enumerate(self.updates)}\n\n    @property\n    def trackable_and_update_dict(self):\n        \'\'\'Returns a dict of all trackables and updates. Useful for\n        training when you want to fetch all trackables and also ensure\n        any updates (e.g. for rolling average BatchNormalization\n        layers) are fetched.\n        \'\'\'\n\n        ret = self.trackable_dict\n        ret.update(self.update_dict)\n        return ret\n\n    def get_tensor_dict(self, tensor_names=None):\n        if tensor_names is None:\n            tensor_names = self.var_names\n        filtered_names = [nn for nn in tensor_names if isinstance(self.v[nn], tf.Tensor)]\n        return {kk:self.v[kk] for kk in filtered_names}\n\n    def print_trainable_warnings(self, graph=None):\n        \'\'\'Print warnings for any vars marked as trainable in the\n        model but not graph, and vice versa. A common case where this\n        occurs is in BatchNormalization layers, where internal\n        variables are updated but not marked as trainable.\n        \'\'\'\n\n        if graph is None:\n            try:\n                graph = tf.python.get_default_graph()\n            except AttributeError:\n                graph = tf.get_default_graph()\n\n        def tag(name):\n            if \'batchnormalization\' in name and \'running\' in name:\n                # Keras 1.2.2\n                return \' . \'\n            elif \'batch_normalization\' in name and \'moving\' in name:\n                # Keras 2+\n                return \' . \'\n            else:\n                return \'***\'\n        \n        # Check which vars are trainable\n        trainable_vars_from_graph = graph.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n        trainable_vars_from_model = self.trainable_weights\n    \n        in_graph_not_model = set(trainable_vars_from_graph).difference(set(trainable_vars_from_model))\n        if in_graph_not_model:\n            print \'Warning: the following vars are marked as trainable in the graph but not in model.trainable_weights (typical for BatchNormalization layers. ""."" if expected, ""***"" if not):\'\n            print \'\\n\'.join([\'   %4s %s: %s\' % (tag(vv.name), vv.name, vv) for vv in in_graph_not_model])\n        in_model_not_graph = set(trainable_vars_from_model).difference(set(trainable_vars_from_graph))\n        if in_model_not_graph:\n            print \'Warning: the following vars are in model.trainable_weights but not marked as trainable in the graph:\'\n            print \'\\n\'.join([\'   %4s %s: %s\' % (tag(vv.name), vv.name, vv) for vv in in_model_not_graph])\n            \n    def add_extra_trainable_weight(self, weight):\n        self._extra_trainable_weights.append(weight)\n\n    @property\n    def extra_trainable_weights(self):\n        return self._extra_trainable_weights\n\n    @property\n    def trainable_weights(self):\n        tw = super(ExtendedModel, self).trainable_weights\n        tw.extend(self.extra_trainable_weights)\n        return tw\n\n    def add_extra_non_trainable_weight(self, weight):\n        self._extra_non_trainable_weights.append(weight)\n\n    @property\n    def extra_non_trainable_weights(self):\n        return self._extra_non_trainable_weights\n\n    @property\n    def non_trainable_weights(self):\n        ntw = super(ExtendedModel, self).non_trainable_weights\n        ntw.extend(self.extra_non_trainable_weights)\n        return ntw\n\n\nclass LazyModel(ExtendedModel):\n    \'\'\'Like ExtendedModel. But lazy and nestable.\n\n    In general, we would like to be able to encapsulate functionality\n    in larger containers than single layers. However, this is\n    difficult because when using the standard Model (and\n    ExtendedModel), you must know the input shape in order to make a\n    placeholder Input layer. This is far less convenient than, say,\n    just being able to call a Dense(123) layer on an input of unknown\n    width and having the shape inferred at build time. LazyModel\n    solves this problem by delaying the model build until the first\n    time it is actually called on a real node in the graph, at which\n    point an internal Input layer is constructed on the fly (and\n    generally then not used).\n\n    Known issues:\n\n      - BatchNormalization layers fail in mode 0 (because they are\n        called twice). Workaround: use in mode 1 or 2 or outside\n        LazyModel.\n\n      - Layer activity_regularizers do not work well, because then\n        there end up being two copies (one on the activation resulting\n        from the internal Input layer). Workaround: use\n        activity_regularizers only outside the LazyModel.\n\n      - There still ends up being a dangling tf.placeholder in the\n        graph. See notes in exp/model_keras_hacking/ for failed\n        more elegant solutions.\n    \'\'\'\n\n    def __init__(self, model_function):\n        self._model_function = model_function\n        self._lazy_has_run = False\n        # Delay rest of construction until first call\n\n    def __call__(self, inputs, mask=None):\n        if not self._lazy_has_run:\n            input_was_list_tuple = isinstance(inputs, list) or isinstance(inputs, tuple)\n            if input_was_list_tuple:\n                input_list = inputs\n            else:\n                input_list = [inputs]\n            # Make short-lived Input Layers for each x this was called with\n            input_layers = []\n            warn_prefix = \'if_you_get_a_must_feed_placeholder_error_here_it_is_because_you_used_an_activity_regularizer._ask_jason\'\n            for inp in input_list:\n                #ll = Input(tensor=inp, batch_shape=inp._keras_shape, dtype=inp.dtype, name=\'real_input_from__%s\' % inp.name.replace(\'/\',\'_\').replace(\':\',\'_\'))\n                #ll = Input(batch_shape=inp.get_shape().as_list(), dtype=inp.dtype, name=\'%s.%s\' % (warn_prefix, inp.name.replace(\'/\',\'_\').replace(\':\',\'_\')))\n                shape = full_static_shape(inp)\n                ll = Input(batch_shape=shape, dtype=inp.dtype, name=\'%s.%s\' % (warn_prefix, inp.name.replace(\'/\',\'_\').replace(\':\',\'_\')))\n                input_layers.append(ll)\n\n            if not input_was_list_tuple:\n                input_layers = input_layers[0]\n\n            # Call function of inputs to get output tensors\n            # And then initialize the entire model.\n            outputs = self._model_function(input_layers)\n            super(LazyModel, self).__init__(input_layers, outputs)\n\n            self._lazy_has_run = True\n\n        # Now actually call the model and return the outputs\n        return super(LazyModel, self).__call__(inputs, mask=mask)\n\n\n'"
intrinsic_dimension/keras_ext/fast_walsh_hadamard.py,0,b''
intrinsic_dimension/keras_ext/layers.py,0,"b""''' Extended Keras Layers\n'''\n\nfrom rproj_layers import RProjDense, RProjConv2D, RProjBatchNormalization, RProjLocallyConnected2D\n"""
intrinsic_dimension/keras_ext/regularizers.py,0,"b""'''Custom Keras regularizers.'''\n\nimport keras\nimport keras.backend as K\n\n\n\nclass WeightRegularizer(keras.regularizers.WeightRegularizer):\n    '''Subclass of Keras WeightRegularizer that doesn't use\n    K.in_train_phase, so that total loss can easily be compared\n    between train and val modes.\n    '''\n\n    def __init__(self, l1=0., l2=0.):\n        self.l1 = K.cast_to_floatx(l1)\n        self.l2 = K.cast_to_floatx(l2)\n        self.uses_learning_phase = False\n        self.p = None\n\n    def get_loss(self):\n        loss = 0.0\n        if self.l1:\n            loss += K.sum(K.abs(self.p)) * self.l1\n        if self.l2:\n            loss += K.sum(K.square(self.p)) * self.l2\n        return loss\n\nclass WeightRegularizerMean(keras.regularizers.WeightRegularizer):\n    '''Subclass of Keras WeightRegularizer that doesn't use\n    K.in_train_phase, so that total loss can easily be compared\n    between train and val modes.\n\n    Uses mean instead of sum above.\n    '''\n\n    def __init__(self, l1=0., l2=0.):\n        self.l1 = K.cast_to_floatx(l1)\n        self.l2 = K.cast_to_floatx(l2)\n        self.uses_learning_phase = False\n        self.p = None\n\n    def get_loss(self):\n        loss = 0.0\n        if self.l1:\n            loss += K.mean(K.abs(self.p)) * self.l1\n        if self.l2:\n            loss += K.mean(K.square(self.p)) * self.l2\n        return loss\n\n\nclass ActivityRegularizer(keras.regularizers.ActivityRegularizer):\n    '''Subclass of Keras ActivityRegularizer that doesn't use\n    K.in_train_phase, so that total loss can easily be compared\n    between train and val modes.\n    '''\n\n    def __init__(self, l1=0., l2=0.):\n        self.l1 = K.cast_to_floatx(l1)\n        self.l2 = K.cast_to_floatx(l2)\n        self.uses_learning_phase = False\n        self.layer = None\n\n    def get_loss(self):\n        if self.layer is None:\n            raise Exception('Need to call `set_layer` on '\n                            'ActivityRegularizer instance '\n                            'before calling the instance.')\n        loss = 0.0\n        for i in range(len(self.layer.inbound_nodes)):\n            output = self.layer.get_output_at(i)\n            if self.l1:\n                loss += K.sum(self.l1 * K.abs(output))\n            if self.l2:\n                loss += K.sum(self.l2 * K.square(output))\n        return loss\n\n\ndef l1(l=0.01):\n    return WeightRegularizer(l1=l)\n\n\ndef l2(l=0.01):\n    return WeightRegularizer(l2=l)\n\n\ndef l1l2(l1=0.01, l2=0.01):\n    return WeightRegularizer(l1=l1, l2=l2)\n\n\ndef activity_l1(l=0.01):\n    return ActivityRegularizer(l1=l)\n\n\ndef activity_l2(l=0.01):\n    return ActivityRegularizer(l2=l)\n\n\ndef activity_l1l2(l1=0.01, l2=0.01):\n    return ActivityRegularizer(l1=l1, l2=l2)\n"""
intrinsic_dimension/keras_ext/rproj_fwh_layers.py,2,"b'#! /usr/bin/env python\n\nimport numpy as np\nimport tensorflow as tf\nfrom keras.engine import Layer, InputSpec\nimport keras.backend as K\nfrom keras.utils import conv_utils\nfrom keras.backend.tensorflow_backend import _convert_string_dtype\nfrom keras import regularizers, constraints, initializers, activations\n\nimport os, sys\nlab_root = os.path.join(os.path.abspath(os.path.dirname(__file__)), \'..\')\nsys.path.insert(1, lab_root)\n\nfrom keras_ext.fast_walsh_hadamard import tf_fastfood_transform\nfrom brook.tfutil import tf_shape_last\nfrom keras.legacy import interfaces\nfrom IPython import embed\n\nfrom sklearn.random_projection import SparseRandomProjection as SRP\nfrom scipy.sparse import find\n\n\nclass LowRankBasisFWHLayer(Layer):\n    \'\'\'Smarter version of Layer...\'\'\'\n\n    def __init__(self, **kwargs):\n        super(LowRankBasisFWHLayer, self).__init__(**kwargs)\n        self._base_thetas = []\n        #self._basis_matrices = []\n        #self._basis_matrix_normalizers = []\n\n    @property\n    def base_thetas(self):\n        assert False, \'is this used?\'\n        return self._base_thetas\n\n    @property\n    def basis_matrices(self):\n        assert False, \'is this used?\'\n        return self._basis_matrices\n\n    @property\n    def basis_matrix_normalizers(self):\n        assert False, \'is this used?\'\n        return self._basis_matrix_normalizers\n\n    def _make_theta_offset(self, shape):\n        # Get offset from theta_0 (offset is initially 0)\n        assert isinstance(self.weight_basis, FastWalshHadamardProjector), \'weight_basis should be a FastWalshHadamardProjector instance\'\n        return self.weight_basis.get_projected_tensor(shape)\n\n    def add_weight(self,\n                   name,\n                   shape,\n                   dtype=None,\n                   initializer=None,\n                   regularizer=None,\n                   trainable=True,\n                   constraint=None):\n        \'\'\'Adds a weight variable to the layer.\n\n        # Arguments\n            name: String, the name for the weight variable.\n            shape: The shape tuple of the weight.\n            dtype: The dtype of the weight.\n            initializer: An Initializer instance (callable).\n            regularizer: An optional Regularizer instance.\n            trainable: A boolean, whether the weight should\n                be trained via backprop or not (assuming\n                that the layer itself is also trainable).\n            constraint: An optional Constraint instance.\n\n        # Returns\n            The created weight variable.\n        \'\'\'\n        initializer = initializers.get(initializer)\n        if dtype is None:\n            dtype = K.floatx()\n\n        # Create Theta_0\n        value_0 = initializer(shape)\n        theta_0 = tf.Variable(value_0, trainable=False, dtype=_convert_string_dtype(dtype), name=\'%s_theta0\' % name)\n        if isinstance(value_0, np.ndarray):\n            theta_0._keras_shape = value_0.shape\n        elif hasattr(value_0, \'get_shape\'):\n            theta_0._keras_shape = tuple(map(int, value_0.get_shape()))\n        theta_0._uses_learning_phase = False\n\n        # Call subclass offset creator\n        theta_offset = self._make_theta_offset(theta_0.get_shape())\n\n        # Compute final theta to be used in network\n        theta = tf.add(theta_0, theta_offset, name=name)\n        \n        if regularizer is not None:\n            self.add_loss(regularizer(theta))\n        if constraint is not None:\n            self.constraints[theta] = constraint\n        self._base_thetas.append(theta_0)\n        self._non_trainable_weights.extend([theta_0])\n        return theta\n\n\n    def add_non_trainable_weight(self,\n                                 name,\n                                 shape,\n                                 dtype=None,\n                                 initializer=None,\n                                 regularizer=None,\n                                 constraint=None):\n        """"""Adds a weight variable to the layer.\n        # Arguments\n            name: String, the name for the weight variable.\n            shape: The shape tuple of the weight.\n            dtype: The dtype of the weight.\n            initializer: An Initializer instance (callable).\n            regularizer: An optional Regularizer instance.\n            trainable: A boolean, whether the weight should\n                be trained via backprop or not (assuming\n                that the layer itself is also trainable).\n            constraint: An optional Constraint instance.\n        # Returns\n            The created weight variable.\n        """"""\n        initializer = initializers.get(initializer)\n        if dtype is None:\n            dtype = K.floatx()\n        weight = K.variable(initializer(shape), dtype=dtype, name=name)\n        if regularizer is not None:\n            self.add_loss(regularizer(weight))\n        if constraint is not None:\n            self.constraints[weight] = constraint\n        self._non_trainable_weights.append(weight)\n        return weight\n\n\n\nclass RProjFWHDense(LowRankBasisFWHLayer):\n    \'\'\'Just your regular densely-connected NN layer.\n\n    `Dense` implements the operation:\n    `output = activation(dot(input, kernel) + bias)`\n    where `activation` is the element-wise activation function\n    passed as the `activation` argument, `kernel` is a weights matrix\n    created by the layer, and `bias` is a bias vector created by the layer\n    (only applicable if `use_bias` is `True`).\n\n    Note: if the input to the layer has a rank greater than 2, then\n    it is flattened prior to the initial dot product with `kernel`.\n\n    # Example\n\n    ```python\n        # as first layer in a sequential model:\n        model = Sequential()\n        model.add(Dense(32, input_shape=(16,)))\n        # now the model will take as input arrays of shape (*, 16)\n        # and output arrays of shape (*, 32)\n\n        # after the first layer, you don\'t need to specify\n        # the size of the input anymore:\n        model.add(Dense(32))\n    ```\n\n    # Arguments\n        units: Positive integer, dimensionality of the output space.\n        activation: Activation function to use\n            (see [activations](../activations.md)).\n            If you don\'t specify anything, no activation is applied\n            (ie. ""linear"" activation: `a(x) = x`).\n        use_bias: Boolean, whether the layer uses a bias vector.\n        kernel_initializer: Initializer for the `kernel` weights matrix\n            (see [initializers](../initializers.md)).\n        bias_initializer: Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n        kernel_regularizer: Regularizer function applied to\n            the `kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n        bias_regularizer: Regularizer function applied to the bias vector\n            (see [regularizer](../regularizers.md)).\n        activity_regularizer: Regularizer function applied to\n            the output of the layer (its ""activation"").\n            (see [regularizer](../regularizers.md)).\n        kernel_constraint: Constraint function applied to\n            the `kernel` weights matrix\n            (see [constraints](../constraints.md)).\n        bias_constraint: Constraint function applied to the bias vector\n            (see [constraints](../constraints.md)).\n\n    # Input shape\n        nD tensor with shape: `(batch_size, ..., input_dim)`.\n        The most common situation would be\n        a 2D input with shape `(batch_size, input_dim)`.\n\n    # Output shape\n        nD tensor with shape: `(batch_size, ..., units)`.\n        For instance, for a 2D input with shape `(batch_size, input_dim)`,\n        the output would have shape `(batch_size, units)`.\n    \'\'\'\n\n    def __init__(self, fwh_projector, units,\n                 activation=None,\n                 use_bias=True,\n                 kernel_initializer=\'glorot_uniform\',\n                 bias_initializer=\'zeros\',\n                 kernel_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        if \'input_shape\' not in kwargs and \'input_dim\' in kwargs:\n            kwargs[\'input_shape\'] = (kwargs.pop(\'input_dim\'),)\n        super(RProjFWHDense, self).__init__(**kwargs)\n        self.fwh_projector = fwh_projector\n        self.units = units\n        self.activation = activations.get(activation)\n        self.use_bias = use_bias\n        self.kernel_initializer = initializers.get(kernel_initializer)\n        self.bias_initializer = initializers.get(bias_initializer)\n        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n        self.activity_regularizer = regularizers.get(activity_regularizer)\n        self.kernel_constraint = constraints.get(kernel_constraint)\n        self.bias_constraint = constraints.get(bias_constraint)\n        self.input_spec = InputSpec(min_ndim=2)\n        self.supports_masking = True\n\n    def build(self, input_shape):\n        assert len(input_shape) >= 2\n        input_dim = input_shape[-1]\n\n        self.kernel = self.add_weight(self.fwh_projector,\n                                      shape=(input_dim, self.units),\n                                      initializer=self.kernel_initializer,\n                                      name=\'kernel\',\n                                      regularizer=self.kernel_regularizer,\n                                      constraint=self.kernel_constraint)\n        if self.use_bias:\n            self.bias = self.add_weight(self.fwh_projector,\n                                        shape=(self.units,),\n                                        initializer=self.bias_initializer,\n                                        name=\'bias\',\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n        else:\n            self.bias = None\n        self.input_spec = InputSpec(min_ndim=2, axes={-1: input_dim})\n        self.built = True\n\n    def call(self, inputs):\n        output = K.dot(inputs, self.kernel)\n        if self.use_bias:\n            output = K.bias_add(output, self.bias)\n        if self.activation is not None:\n            output = self.activation(output)\n        return output\n\n    def compute_output_shape(self, input_shape):\n        assert input_shape and len(input_shape) >= 2\n        assert input_shape[-1]\n        output_shape = list(input_shape)\n        output_shape[-1] = self.units\n        return tuple(output_shape)\n\n\n\nclass _RProjFWHConv(LowRankBasisFWHLayer):\n    """"""Abstract nD convolution layer (private, used as implementation base).\n\n    ----- Only the intrinsic parameters (RProj) are Trainable ------\n\n    This layer creates a convolution kernel that is convolved\n    with the layer input to produce a tensor of outputs.\n    If `use_bias` is True, a bias vector is created and added to the outputs.\n    Finally, if `activation` is not `None`,\n    it is applied to the outputs as well.\n    # Arguments\n        rank: An integer, the rank of the convolution,\n            e.g. ""2"" for 2D convolution.\n        filters: Integer, the dimensionality of the output space\n            (i.e. the number output of filters in the convolution).\n        kernel_size: An integer or tuple/list of n integers, specifying the\n            dimensions of the convolution window.\n        strides: An integer or tuple/list of n integers,\n            specifying the strides of the convolution.\n            Specifying any stride value != 1 is incompatible with specifying\n            any `dilation_rate` value != 1.\n        padding: One of `""valid""` or `""same""` (case-insensitive).\n        data_format: A string,\n            one of `channels_last` (default) or `channels_first`.\n            The ordering of the dimensions in the inputs.\n            `channels_last` corresponds to inputs with shape\n            `(batch, ..., channels)` while `channels_first` corresponds to\n            inputs with shape `(batch, channels, ...)`.\n            It defaults to the `image_data_format` value found in your\n            Keras config file at `~/.keras/keras.json`.\n            If you never set it, then it will be ""channels_last"".\n        dilation_rate: An integer or tuple/list of n integers, specifying\n            the dilation rate to use for dilated convolution.\n            Currently, specifying any `dilation_rate` value != 1 is\n            incompatible with specifying any `strides` value != 1.\n        activation: Activation function to use\n            (see [activations](../activations.md)).\n            If you don\'t specify anything, no activation is applied\n            (ie. ""linear"" activation: `a(x) = x`).\n        use_bias: Boolean, whether the layer uses a bias vector.\n        kernel_initializer: Initializer for the `kernel` weights matrix\n            (see [initializers](../initializers.md)).\n        bias_initializer: Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n        kernel_regularizer: Regularizer function applied to\n            the `kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n        bias_regularizer: Regularizer function applied to the bias vector\n            (see [regularizer](../regularizers.md)).\n        activity_regularizer: Regularizer function applied to\n            the output of the layer (its ""activation"").\n            (see [regularizer](../regularizers.md)).\n        kernel_constraint: Constraint function applied to the kernel matrix\n            (see [constraints](../constraints.md)).\n        bias_constraint: Constraint function applied to the bias vector\n            (see [constraints](../constraints.md)).\n    """"""\n\n    def __init__(self, fwh_projector, rank,\n                 filters,\n                 kernel_size,\n                 strides=1,\n                 padding=\'valid\',\n                 data_format=None,\n                 dilation_rate=1,\n                 activation=None,\n                 use_bias=True,\n                 kernel_initializer=\'glorot_uniform\',\n                 bias_initializer=\'zeros\',\n                 kernel_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        # embed()\n        super(_RProjFWHConv, self).__init__(**kwargs)\n        self.fwh_projector = fwh_projector\n        self.rank = rank\n        self.filters = filters\n        self.kernel_size = conv_utils.normalize_tuple(kernel_size, rank, \'kernel_size\')\n        self.strides = conv_utils.normalize_tuple(strides, rank, \'strides\')\n        self.padding = conv_utils.normalize_padding(padding)\n        self.data_format = conv_utils.normalize_data_format(data_format)\n        self.dilation_rate = conv_utils.normalize_tuple(dilation_rate, rank, \'dilation_rate\')\n        self.activation = activations.get(activation)\n        self.use_bias = use_bias\n        self.kernel_initializer = initializers.get(kernel_initializer)\n        self.bias_initializer = initializers.get(bias_initializer)\n        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n        self.activity_regularizer = regularizers.get(activity_regularizer)\n        self.kernel_constraint = constraints.get(kernel_constraint)\n        self.bias_constraint = constraints.get(bias_constraint)\n        self.input_spec = InputSpec(ndim=self.rank + 2)\n\n    def build(self, input_shape):\n        if self.data_format == \'channels_first\':\n            channel_axis = 1\n        else:\n            channel_axis = -1\n        if input_shape[channel_axis] is None:\n            raise ValueError(\'The channel dimension of the inputs \'\n                             \'should be defined. Found `None`.\')\n        input_dim = input_shape[channel_axis]\n        kernel_shape = self.kernel_size + (input_dim, self.filters)\n\n        self.kernel = self.add_weight(fwh_projector=self.fwh_projector,\n                                      shape=kernel_shape,\n                                      initializer=self.kernel_initializer,\n                                      name=\'kernel\',\n                                      regularizer=self.kernel_regularizer,\n                                      constraint=self.kernel_constraint)\n        if self.use_bias:\n            self.bias = self.add_weight(fwh_projector=self.fwh_projector,\n                                        shape=(self.filters,),\n                                        initializer=self.bias_initializer,\n                                        name=\'bias\',\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n        else:\n            self.bias = None\n        # Set input spec.\n        self.input_spec = InputSpec(ndim=self.rank + 2,\n                                    axes={channel_axis: input_dim})\n        self.built = True\n\n    def call(self, inputs):\n        if self.rank == 1:\n            outputs = K.conv1d(\n                inputs,\n                self.kernel,\n                strides=self.strides[0],\n                padding=self.padding,\n                data_format=self.data_format,\n                dilation_rate=self.dilation_rate[0])\n        if self.rank == 2:\n            outputs = K.conv2d(\n                inputs,\n                self.kernel,\n                strides=self.strides,\n                padding=self.padding,\n                data_format=self.data_format,\n                dilation_rate=self.dilation_rate)\n        if self.rank == 3:\n            outputs = K.conv3d(\n                inputs,\n                self.kernel,\n                strides=self.strides,\n                padding=self.padding,\n                data_format=self.data_format,\n                dilation_rate=self.dilation_rate)\n\n        if self.use_bias:\n            outputs = K.bias_add(\n                outputs,\n                self.bias,\n                data_format=self.data_format)\n\n        if self.activation is not None:\n            return self.activation(outputs)\n        return outputs\n\n    def compute_output_shape(self, input_shape):\n        if self.data_format == \'channels_last\':\n            space = input_shape[1:-1]\n            new_space = []\n            for i in range(len(space)):\n                new_dim = conv_utils.conv_output_length(\n                    space[i],\n                    self.kernel_size[i],\n                    padding=self.padding,\n                    stride=self.strides[i],\n                    dilation=self.dilation_rate[i])\n                new_space.append(new_dim)\n            return (input_shape[0],) + tuple(new_space) + (self.filters,)\n        if self.data_format == \'channels_first\':\n            space = input_shape[2:]\n            new_space = []\n            for i in range(len(space)):\n                new_dim = conv_utils.conv_output_length(\n                    space[i],\n                    self.kernel_size[i],\n                    padding=self.padding,\n                    stride=self.strides[i],\n                    dilation=self.dilation_rate[i])\n                new_space.append(new_dim)\n            return (input_shape[0], self.filters) + tuple(new_space)\n\n    def get_config(self):\n        config = {\n            \'rank\': self.rank,\n            \'filters\': self.filters,\n            \'kernel_size\': self.kernel_size,\n            \'strides\': self.strides,\n            \'padding\': self.padding,\n            \'data_format\': self.data_format,\n            \'dilation_rate\': self.dilation_rate,\n            \'activation\': activations.serialize(self.activation),\n            \'use_bias\': self.use_bias,\n            \'kernel_initializer\': initializers.serialize(self.kernel_initializer),\n            \'bias_initializer\': initializers.serialize(self.bias_initializer),\n            \'kernel_regularizer\': regularizers.serialize(self.kernel_regularizer),\n            \'bias_regularizer\': regularizers.serialize(self.bias_regularizer),\n            \'activity_regularizer\': regularizers.serialize(self.activity_regularizer),\n            \'kernel_constraint\': constraints.serialize(self.kernel_constraint),\n            \'bias_constraint\': constraints.serialize(self.bias_constraint)\n        }\n        base_config = super(_RProjFWHConv, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\n\n\nclass RProjFWHConv2D(_RProjFWHConv):\n    \'\'\'Low Rank Basis Conv2D\n    Filters if number of filters, output dimension is filters\n    TODO: Documentation / unit tests\n    \'\'\'\n\n    #@interfaces.legacy_conv2d_support\n    def __init__(self, fwh_projector, filters,\n                 kernel_size,\n                 strides=(1, 1),\n                 padding=\'valid\',\n                 data_format=None,\n                 dilation_rate=(1, 1),\n                 activation=None,\n                 use_bias=True,\n                 kernel_initializer=\'glorot_uniform\',\n                 bias_initializer=\'zeros\',\n                 kernel_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        # embed()\n        super(RProjFWHConv2D, self).__init__(\n            rank=2,\n            fwh_projector=fwh_projector,\n            filters=filters,\n            kernel_size=kernel_size,\n            strides=strides,\n            padding=padding,\n            data_format=data_format,\n            dilation_rate=dilation_rate,\n            activation=activation,\n            use_bias=use_bias,\n            kernel_initializer=kernel_initializer,\n            bias_initializer=bias_initializer,\n            kernel_regularizer=kernel_regularizer,\n            bias_regularizer=bias_regularizer,\n            activity_regularizer=activity_regularizer,\n            kernel_constraint=kernel_constraint,\n            bias_constraint=bias_constraint,\n            **kwargs)\n        self.input_spec = InputSpec(ndim=4)\n\n\n    def build(self, input_shape):\n        assert self.data_format != \'channels_first\',\'only b01c supported\'\n        channel_axis = -1\n        if input_shape[channel_axis] is None:\n            raise ValueError(\'The channel dimension of the inputs \'\n                             \'should be defined. Found `None`.\')\n\n        input_dim = input_shape[-1]\n\n        self.units = self.filters\n\n        kernel_shape = self.kernel_size + (input_dim, self.filters)\n        self.kernel = self.add_weight(fwh_projector=self.fwh_projector,\n                                      shape=kernel_shape,\n                                      initializer=self.kernel_initializer,\n                                      name=\'kernel\',\n                                      regularizer=self.kernel_regularizer,\n                                      constraint=self.kernel_constraint)\n\n        if self.use_bias:\n            self.bias = self.add_weight(fwh_projector=self.fwh_projector,\n                                        shape=(self.filters,),\n                                        initializer=self.bias_initializer,\n                                        name=\'bias\',\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n        else:\n            self.bias = None\n        # Set input spec.\n        self.input_spec = InputSpec(ndim=self.rank + 2,\n                                    axes={channel_axis: input_dim})\n        self.built = True\n\n    def call(self, inputs):\n        assert self.rank == 2, \'only conv2d supported for now...\'\n        if self.rank == 2:\n            outputs = K.conv2d(\n                inputs,\n                self.kernel,\n                strides=self.strides,\n                padding=self.padding,\n                data_format=self.data_format,\n                dilation_rate=self.dilation_rate)\n\n        if self.use_bias:\n            outputs = K.bias_add(\n                outputs,\n                self.bias,\n                data_format=self.data_format)\n\n\n        #if self.activation is not None:\n        #    assert False,\'activation functions not supported\'\n        #    return self.activation(outputs)\n        return outputs\n\n    def compute_output_shape(self, input_shape):\n        if self.data_format == \'channels_last\':\n            space = input_shape[1:-1]\n            new_space = []\n            for i in range(len(space)):\n                new_dim = conv_utils.conv_output_length(\n                    space[i],\n                    self.kernel_size[i],\n                    padding=self.padding,\n                    stride=self.strides[i],\n                    dilation=self.dilation_rate[i])\n                new_space.append(new_dim)\n            #self.filters*2 to accomodate LU representation\n            return (input_shape[0],) + tuple(new_space) + (self.filters,)\n\n    def get_config(self):\n        config = {\n            \'rank\': self.rank,\n            \'filters\': self.filters,\n            \'kernel_size\': self.kernel_size,\n            \'strides\': self.strides,\n            \'padding\': self.padding,\n            \'data_format\': self.data_format,\n            \'dilation_rate\': self.dilation_rate,\n            \'activation\': activations.serialize(self.activation),\n            \'use_bias\': self.use_bias,\n            \'kernel_initializer\': initializers.serialize(self.kernel_initializer),\n            \'bias_initializer\': initializers.serialize(self.bias_initializer),\n            \'kernel_regularizer\': regularizers.serialize(self.kernel_regularizer),\n            \'bias_regularizer\': regularizers.serialize(self.bias_regularizer),\n            \'activity_regularizer\': regularizers.serialize(self.activity_regularizer),\n            \'kernel_constraint\': constraints.serialize(self.kernel_constraint),\n            \'bias_constraint\': constraints.serialize(self.bias_constraint)\n        }\n        base_config = super(RProjFWHConv2D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\n\n\nclass RProjFWH_BatchNormalization(LowRankBasisFWHLayer):\n    """"""Batch normalization layer (Ioffe and Szegedy, 2014).\n    Normalize the activations of the previous layer at each batch,\n    i.e. applies a transformation that maintains the mean activation\n    close to 0 and the activation standard deviation close to 1.\n    # Arguments\n        axis: Integer, the axis that should be normalized\n            (typically the features axis).\n            For instance, after a `Conv2D` layer with\n            `data_format=""channels_first""`,\n            set `axis=1` in `BatchNormalization`.\n        momentum: Momentum for the moving average.\n        epsilon: Small float added to variance to avoid dividing by zero.\n        center: If True, add offset of `beta` to normalized tensor.\n            If False, `beta` is ignored.\n        scale: If True, multiply by `gamma`.\n            If False, `gamma` is not used.\n            When the next layer is linear (also e.g. `nn.relu`),\n            this can be disabled since the scaling\n            will be done by the next layer.\n        beta_initializer: Initializer for the beta weight.\n        gamma_initializer: Initializer for the gamma weight.\n        moving_mean_initializer: Initializer for the moving mean.\n        moving_variance_initializer: Initializer for the moving variance.\n        beta_regularizer: Optional regularizer for the beta weight.\n        gamma_regularizer: Optional regularizer for the gamma weight.\n        beta_constraint: Optional constraint for the beta weight.\n        gamma_constraint: Optional constraint for the gamma weight.\n    # Input shape\n        Arbitrary. Use the keyword argument `input_shape`\n        (tuple of integers, does not include the samples axis)\n        when using this layer as the first layer in a model.\n    # Output shape\n        Same shape as input.\n    # References\n        - [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/abs/1502.03167)\n    """"""\n\n    @interfaces.legacy_batchnorm_support\n    def __init__(self,\n                 fwh_projector,\n                 axis=-1,\n                 momentum=0.99,\n                 epsilon=1e-3,\n                 center=True,\n                 scale=True,\n                 beta_initializer=\'zeros\',\n                 gamma_initializer=\'ones\',\n                 moving_mean_initializer=\'zeros\',\n                 moving_variance_initializer=\'ones\',\n                 beta_regularizer=None,\n                 gamma_regularizer=None,\n                 beta_constraint=None,\n                 gamma_constraint=None,\n                 **kwargs):\n        super(RProjFWH_BatchNormalization, self).__init__(**kwargs)\n        self.fwh_projector = fwh_projector\n        self.supports_masking = True\n        self.axis = axis\n        self.momentum = momentum\n        self.epsilon = epsilon\n        self.center = center\n        self.scale = scale\n        self.beta_initializer = initializers.get(beta_initializer)\n        self.gamma_initializer = initializers.get(gamma_initializer)\n        self.moving_mean_initializer = initializers.get(moving_mean_initializer)\n        self.moving_variance_initializer = initializers.get(moving_variance_initializer)\n        self.beta_regularizer = regularizers.get(beta_regularizer)\n        self.gamma_regularizer = regularizers.get(gamma_regularizer)\n        self.beta_constraint = constraints.get(beta_constraint)\n        self.gamma_constraint = constraints.get(gamma_constraint)\n\n    def build(self, input_shape):\n        dim = input_shape[self.axis]\n        if dim is None:\n            raise ValueError(\'Axis \' + str(self.axis) + \' of \'\n                             \'input tensor should have a defined dimension \'\n                             \'but the layer received an input with shape \' +\n                             str(input_shape) + \'.\')\n        self.input_spec = InputSpec(ndim=len(input_shape),\n                                    axes={self.axis: dim})\n        shape = (dim,)\n\n        if self.scale:\n            self.gamma = self.add_weight(fwh_projector=self.fwh_projector,\n                                         shape=shape,\n                                         name=\'gamma\',\n                                         initializer=self.gamma_initializer,\n                                         regularizer=self.gamma_regularizer,\n                                         constraint=self.gamma_constraint)\n        else:\n            self.gamma = None\n        if self.center:\n            self.beta = self.add_weight(fwh_projector=self.fwh_projector,\n                                        shape=shape,\n                                        name=\'beta\',\n                                        initializer=self.beta_initializer,\n                                        regularizer=self.beta_regularizer,\n                                        constraint=self.beta_constraint)\n        else:\n            self.beta = None\n        self.moving_mean = self.add_non_trainable_weight(\n            shape=shape,\n            name=\'moving_mean\',\n            initializer=self.moving_mean_initializer)\n        self.moving_variance = self.add_non_trainable_weight(\n            shape=shape,\n            name=\'moving_variance\',\n            initializer=self.moving_variance_initializer)\n        self.built = True\n\n    def call(self, inputs, training=None):\n        input_shape = K.int_shape(inputs)\n        # Prepare broadcasting shape.\n        ndim = len(input_shape)\n        reduction_axes = list(range(len(input_shape)))\n        del reduction_axes[self.axis]\n        broadcast_shape = [1] * len(input_shape)\n        broadcast_shape[self.axis] = input_shape[self.axis]\n\n        # Determines whether broadcasting is needed.\n        needs_broadcasting = (sorted(reduction_axes) != list(range(ndim))[:-1])\n\n        def normalize_inference():\n            if needs_broadcasting:\n                # In this case we must explicitly broadcast all parameters.\n                broadcast_moving_mean = K.reshape(self.moving_mean,\n                                                  broadcast_shape)\n                broadcast_moving_variance = K.reshape(self.moving_variance,\n                                                      broadcast_shape)\n                if self.center:\n                    broadcast_beta = K.reshape(self.beta, broadcast_shape)\n                else:\n                    broadcast_beta = None\n                if self.scale:\n                    broadcast_gamma = K.reshape(self.gamma,\n                                                broadcast_shape)\n                else:\n                    broadcast_gamma = None\n                return K.batch_normalization(\n                    inputs,\n                    broadcast_moving_mean,\n                    broadcast_moving_variance,\n                    broadcast_beta,\n                    broadcast_gamma,\n                    epsilon=self.epsilon)\n            else:\n                return K.batch_normalization(\n                    inputs,\n                    self.moving_mean,\n                    self.moving_variance,\n                    self.beta,\n                    self.gamma,\n                    epsilon=self.epsilon)\n\n        # If the learning phase is *static* and set to inference:\n        if training in {0, False}:\n            return normalize_inference()\n\n        # If the learning is either dynamic, or set to training:\n        normed_training, mean, variance = K.normalize_batch_in_training(\n            inputs, self.gamma, self.beta, reduction_axes,\n            epsilon=self.epsilon)\n\n        self.add_update([K.moving_average_update(self.moving_mean,\n                                                 mean,\n                                                 self.momentum),\n                         K.moving_average_update(self.moving_variance,\n                                                 variance,\n                                                 self.momentum)],\n                        inputs)\n\n        # Pick the normalized form corresponding to the training phase.\n        return K.in_train_phase(normed_training,\n                                normalize_inference,\n                                training=training)\n\n    def get_config(self):\n        config = {\n            \'vv_theta\': self.vv,\n            \'axis\': self.axis,\n            \'momentum\': self.momentum,\n            \'epsilon\': self.epsilon,\n            \'center\': self.center,\n            \'scale\': self.scale,\n            \'beta_initializer\': initializers.serialize(self.beta_initializer),\n            \'gamma_initializer\': initializers.serialize(self.gamma_initializer),\n            \'moving_mean_initializer\': initializers.serialize(self.moving_mean_initializer),\n            \'moving_variance_initializer\': initializers.serialize(self.moving_variance_initializer),\n            \'beta_regularizer\': regularizers.serialize(self.beta_regularizer),\n            \'gamma_regularizer\': regularizers.serialize(self.gamma_regularizer),\n            \'beta_constraint\': constraints.serialize(self.beta_constraint),\n            \'gamma_constraint\': constraints.serialize(self.gamma_constraint)\n        }\n        base_config = super(RProjFWH_BatchNormalization, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\n\nif __name__ == \'__main__\':\n    import doctest\n    doctest.testmod()\n'"
intrinsic_dimension/keras_ext/rproj_layers.py,2,"b'import numpy as np\nimport tensorflow as tf\nfrom keras.engine import Layer, InputSpec\nimport keras.backend as K\nfrom keras.utils import conv_utils\nfrom rproj_layers_util import _convert_string_dtype\n# from keras.backend.tensorflow_backend import _convert_string_dtype\nfrom keras import regularizers, constraints, initializers, activations\nfrom IPython import embed\n\nfrom keras.legacy import interfaces\n\n\n\n###########\n#\n# Low Rank Basis Layers\n#\n# These layers are modified versions of standard Keras layers that\n# accept an OffsetCreator*Proj to create offsets from a weight basis\n# in a Dense/Sparse/Fastfood agnostic manner.\n#\n###########\n\nclass LowRankBasisLayer(Layer):\n    \'\'\'Smarter version of Layer...\'\'\'\n\n    def __init__(self, offset_creator_class, weight_basis, *args, **kwargs):\n        super(LowRankBasisLayer, self).__init__(*args, **kwargs)\n        # offset_creator is an object that creates theta offsets\n        self.offset_creator = offset_creator_class()\n        self.weight_basis = weight_basis\n\n        # These may or may not be used by subclasses\n        #self._basis_matrices = []\n        #self._basis_matrix_normalizers = []\n\n    # TODO check for use of basis_matrices\n\n    @property\n    def basis_matrices(self):\n        print \'USED HERE basis_matrices\'\n        return self._basis_matrices\n\n    # TODO check for use of basis_matrix_normalizers\n    @property\n    def basis_matrix_normalizers(self):\n        print \'USED HERE basis_matrix_normalizers\'\n        return self._basis_matrix_normalizers\n    \n    def add_weight(self,\n                   name,\n                   shape,\n                   dtype=None,\n                   initializer=None,\n                   regularizer=None,\n                   trainable=True,\n                   constraint=None):\n        \'\'\'Version of add_weight that creates a weight theta by instantiating\n        theta_0 and then adding to it an offset from the member\n        offset_creator.\n        \'\'\'\n        initializer = initializers.get(initializer)\n        if dtype is None:\n            dtype = K.floatx()\n\n        # Create Theta_0\n        value_0 = initializer(shape)\n        theta_0 = tf.Variable(value_0, trainable=False, dtype=_convert_string_dtype(dtype), name=\'%s_theta0\' % name)\n        if isinstance(value_0, np.ndarray):\n            theta_0._keras_shape = value_0.shape\n        elif hasattr(value_0, \'get_shape\'):\n            theta_0._keras_shape = tuple(map(int, value_0.get_shape()))\n        theta_0._uses_learning_phase = False\n\n        # Call offset creator\n        theta_offset, non_trainable_weights = self.offset_creator.create_theta_offset(self.weight_basis,\n                                                                                      theta_0.get_shape(),\n                                                                                      dtype=dtype,\n                                                                                      name=name)\n\n        theta = tf.add(theta_0, theta_offset, name=name)\n\n        if regularizer is not None:\n            self.add_loss(regularizer(theta))\n        if constraint is not None:\n            self.constraints[theta] = constraint\n        #self._base_thetas.append(theta_0)\n        #self._basis_matrices.append(ww)\n        #self._non_trainable_weights.extend([theta_0, ww])\n        self._non_trainable_weights.extend([theta_0] + non_trainable_weights)\n        return theta\n\n    def add_non_trainable_weight(self,\n                                 name,\n                                 shape,\n                                 dtype=None,\n                                 initializer=None,\n                                 regularizer=None,\n                                 constraint=None):\n        \'\'\'Adds a weight variable to the layer.\n        # Arguments\n            name: String, the name for the weight variable.\n            shape: The shape tuple of the weight.\n            dtype: The dtype of the weight.\n            initializer: An Initializer instance (callable).\n            regularizer: An optional Regularizer instance.\n            trainable: A boolean, whether the weight should\n                be trained via backprop or not (assuming\n                that the layer itself is also trainable).\n            constraint: An optional Constraint instance.\n        # Returns\n            The created weight variable.\n        \'\'\'\n        initializer = initializers.get(initializer)\n        if dtype is None:\n            dtype = K.floatx()\n        weight = K.variable(initializer(shape), dtype=dtype, name=name)\n        if regularizer is not None:\n            self.add_loss(regularizer(weight))\n        if constraint is not None:\n            self.constraints[weight] = constraint\n        self._non_trainable_weights.append(weight)\n        return weight\n\n\nclass RProjDense(LowRankBasisLayer):\n    \'\'\'RProj version of Dense.\'\'\'\n\n    def __init__(self, offset_creator_class, weight_basis,\n                 units,\n                 activation=None,\n                 use_bias=True,\n                 kernel_initializer=\'glorot_uniform\',\n                 bias_initializer=\'zeros\',\n                 kernel_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        if \'input_shape\' not in kwargs and \'input_dim\' in kwargs:\n            kwargs[\'input_shape\'] = (kwargs.pop(\'input_dim\'),)\n        super(RProjDense, self).__init__(offset_creator_class, weight_basis, **kwargs)\n        self.units = units\n        self.activation = activations.get(activation)\n        self.use_bias = use_bias\n        self.kernel_initializer = initializers.get(kernel_initializer)\n        self.bias_initializer = initializers.get(bias_initializer)\n        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n        self.activity_regularizer = regularizers.get(activity_regularizer)\n        self.kernel_constraint = constraints.get(kernel_constraint)\n        self.bias_constraint = constraints.get(bias_constraint)\n        self.input_spec = InputSpec(min_ndim=2)\n        self.supports_masking = True\n\n    def build(self, input_shape):\n        assert len(input_shape) >= 2\n        input_dim = input_shape[-1]\n\n        self.kernel = self.add_weight(shape=(input_dim, self.units),\n                                      initializer=self.kernel_initializer,\n                                      name=\'kernel\',\n                                      regularizer=self.kernel_regularizer,\n                                      constraint=self.kernel_constraint)\n        if self.use_bias:\n            self.bias = self.add_weight(shape=(self.units,),\n                                        initializer=self.bias_initializer,\n                                        name=\'bias\',\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n        else:\n            self.bias = None\n        self.input_spec = InputSpec(min_ndim=2, axes={-1: input_dim})\n        self.built = True\n\n    def call(self, inputs):\n        output = K.dot(inputs, self.kernel)\n        if self.use_bias:\n            output = K.bias_add(output, self.bias)\n        if self.activation is not None:\n            output = self.activation(output)\n        return output\n\n    def compute_output_shape(self, input_shape):\n        assert input_shape and len(input_shape) >= 2\n        assert input_shape[-1]\n        output_shape = list(input_shape)\n        output_shape[-1] = self.units\n        return tuple(output_shape)\n\n\n\nclass _RProjConv(LowRankBasisLayer):\n    \'\'\'Abstract nD convolution layer (private, used as implementation base).\n\n    Only the intrinsic parameters (RProj) are Trainable.\'\'\'\n\n    def __init__(self, offset_creator_class, weight_basis,\n                 rank,\n                 filters,\n                 kernel_size,\n                 strides=1,\n                 padding=\'valid\',\n                 data_format=None,\n                 dilation_rate=1,\n                 activation=None,\n                 use_bias=True,\n                 kernel_initializer=\'glorot_uniform\',\n                 bias_initializer=\'zeros\',\n                 kernel_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        super(_RProjConv, self).__init__(offset_creator_class, weight_basis, **kwargs)\n        self.rank = rank\n        self.filters = filters\n        self.kernel_size = conv_utils.normalize_tuple(kernel_size, rank, \'kernel_size\')\n        self.strides = conv_utils.normalize_tuple(strides, rank, \'strides\')\n        self.padding = conv_utils.normalize_padding(padding)\n        self.data_format = conv_utils.normalize_data_format(data_format)\n        self.dilation_rate = conv_utils.normalize_tuple(dilation_rate, rank, \'dilation_rate\')\n        self.activation = activations.get(activation)\n        self.use_bias = use_bias\n        self.kernel_initializer = initializers.get(kernel_initializer)\n        self.bias_initializer = initializers.get(bias_initializer)\n        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n        self.activity_regularizer = regularizers.get(activity_regularizer)\n        self.kernel_constraint = constraints.get(kernel_constraint)\n        self.bias_constraint = constraints.get(bias_constraint)\n        self.input_spec = InputSpec(ndim=self.rank + 2)\n\n    def build(self, input_shape):\n        if self.data_format == \'channels_first\':\n            channel_axis = 1\n        else:\n            channel_axis = -1\n        if input_shape[channel_axis] is None:\n            raise ValueError(\'The channel dimension of the inputs \'\n                             \'should be defined. Found `None`.\')\n        input_dim = input_shape[channel_axis]\n        kernel_shape = self.kernel_size + (input_dim, self.filters)\n\n        self.kernel = self.add_weight(shape=kernel_shape,\n                                      initializer=self.kernel_initializer,\n                                      name=\'kernel\',\n                                      regularizer=self.kernel_regularizer,\n                                      constraint=self.kernel_constraint)\n        if self.use_bias:\n            self.bias = self.add_weight(shape=(self.filters,),\n                                        initializer=self.bias_initializer,\n                                        name=\'bias\',\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n        else:\n            self.bias = None\n        # Set input spec.\n        self.input_spec = InputSpec(ndim=self.rank + 2,\n                                    axes={channel_axis: input_dim})\n        self.built = True\n\n    def call(self, inputs):\n        if self.rank == 1:\n            outputs = K.conv1d(\n                inputs,\n                self.kernel,\n                strides=self.strides[0],\n                padding=self.padding,\n                data_format=self.data_format,\n                dilation_rate=self.dilation_rate[0])\n        if self.rank == 2:\n            outputs = K.conv2d(\n                inputs,\n                self.kernel,\n                strides=self.strides,\n                padding=self.padding,\n                data_format=self.data_format,\n                dilation_rate=self.dilation_rate)\n        if self.rank == 3:\n            outputs = K.conv3d(\n                inputs,\n                self.kernel,\n                strides=self.strides,\n                padding=self.padding,\n                data_format=self.data_format,\n                dilation_rate=self.dilation_rate)\n\n        if self.use_bias:\n            outputs = K.bias_add(\n                outputs,\n                self.bias,\n                data_format=self.data_format)\n\n        if self.activation is not None:\n            return self.activation(outputs)\n        return outputs\n\n    def compute_output_shape(self, input_shape):\n        if self.data_format == \'channels_last\':\n            space = input_shape[1:-1]\n            new_space = []\n            for i in range(len(space)):\n                new_dim = conv_utils.conv_output_length(\n                    space[i],\n                    self.kernel_size[i],\n                    padding=self.padding,\n                    stride=self.strides[i],\n                    dilation=self.dilation_rate[i])\n                new_space.append(new_dim)\n            return (input_shape[0],) + tuple(new_space) + (self.filters,)\n        if self.data_format == \'channels_first\':\n            space = input_shape[2:]\n            new_space = []\n            for i in range(len(space)):\n                new_dim = conv_utils.conv_output_length(\n                    space[i],\n                    self.kernel_size[i],\n                    padding=self.padding,\n                    stride=self.strides[i],\n                    dilation=self.dilation_rate[i])\n                new_space.append(new_dim)\n            return (input_shape[0], self.filters) + tuple(new_space)\n\n\nclass RProjConv2D(_RProjConv):\n    \'\'\'Low Rank Basis Conv2D\n    Filters if number of filters, output dimension is filters\n    TODO: Documentation / unit tests\n    \'\'\'\n\n    def __init__(self, offset_creator_class, weight_basis,\n                 filters,\n                 kernel_size,\n                 strides=(1, 1),\n                 padding=\'valid\',\n                 data_format=None,\n                 dilation_rate=(1, 1),\n                 activation=None,\n                 use_bias=True,\n                 kernel_initializer=\'glorot_uniform\',\n                 bias_initializer=\'zeros\',\n                 kernel_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        super(RProjConv2D, self).__init__(\n            offset_creator_class=offset_creator_class,\n            weight_basis=weight_basis,\n            rank=2,\n            filters=filters,\n            kernel_size=kernel_size,\n            strides=strides,\n            padding=padding,\n            data_format=data_format,\n            dilation_rate=dilation_rate,\n            activation=activation,\n            use_bias=use_bias,\n            kernel_initializer=kernel_initializer,\n            bias_initializer=bias_initializer,\n            kernel_regularizer=kernel_regularizer,\n            bias_regularizer=bias_regularizer,\n            activity_regularizer=activity_regularizer,\n            kernel_constraint=kernel_constraint,\n            bias_constraint=bias_constraint,\n            **kwargs)\n        self.input_spec = InputSpec(ndim=4)\n\n    def build(self, input_shape):\n        assert self.data_format != \'channels_first\',\'only b01c supported\'\n        channel_axis = -1\n        if input_shape[channel_axis] is None:\n            raise ValueError(\'The channel dimension of the inputs \'\n                             \'should be defined. Found `None`.\')\n\n        input_dim = input_shape[-1]\n\n        self.units = self.filters\n\n        kernel_shape = self.kernel_size + (input_dim, self.filters)\n        self.kernel = self.add_weight(shape=kernel_shape,\n                                      initializer=self.kernel_initializer,\n                                      name=\'kernel\',\n                                      regularizer=self.kernel_regularizer,\n                                      constraint=self.kernel_constraint)\n\n        if self.use_bias:\n            self.bias = self.add_weight(shape=(self.filters,),\n                                        initializer=self.bias_initializer,\n                                        name=\'bias\',\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n        else:\n            self.bias = None\n        # Set input spec.\n        self.input_spec = InputSpec(ndim=self.rank + 2,\n                                    axes={channel_axis: input_dim})\n        self.built = True\n\n    def call(self, inputs):\n        assert self.rank == 2, \'only conv2d supported for now...\'\n        if self.rank == 2:\n            outputs = K.conv2d(\n                inputs,\n                self.kernel,\n                strides=self.strides,\n                padding=self.padding,\n                data_format=self.data_format,\n                dilation_rate=self.dilation_rate)\n\n        if self.use_bias:\n            outputs = K.bias_add(\n                outputs,\n                self.bias,\n                data_format=self.data_format)\n\n\n        #if self.activation is not None:\n        #    assert False,\'activation functions not supported\'\n        #    return self.activation(outputs)\n        return outputs\n\n    def compute_output_shape(self, input_shape):\n        if self.data_format == \'channels_last\':\n            space = input_shape[1:-1]\n            new_space = []\n            for i in range(len(space)):\n                new_dim = conv_utils.conv_output_length(\n                    space[i],\n                    self.kernel_size[i],\n                    padding=self.padding,\n                    stride=self.strides[i],\n                    dilation=self.dilation_rate[i])\n                new_space.append(new_dim)\n            #self.filters*2 to accomodate LU representation\n            return (input_shape[0],) + tuple(new_space) + (self.filters,)\n\n\nclass RProjBatchNormalization(LowRankBasisLayer):\n    \'\'\'RProj version of BatchNormalization.\'\'\'\n\n    def __init__(self, offset_creator_class, weight_basis,\n                 axis=-1,\n                 momentum=0.99,\n                 epsilon=1e-3,\n                 center=True,\n                 scale=True,\n                 beta_initializer=\'zeros\',\n                 gamma_initializer=\'ones\',\n                 moving_mean_initializer=\'zeros\',\n                 moving_variance_initializer=\'ones\',\n                 beta_regularizer=None,\n                 gamma_regularizer=None,\n                 beta_constraint=None,\n                 gamma_constraint=None,\n                 **kwargs):\n        super(RProjBatchNormalization, self).__init__(offset_creator_class, weight_basis, **kwargs)\n        self.supports_masking = True\n        self.axis = axis\n        self.momentum = momentum\n        self.epsilon = epsilon\n        self.center = center\n        self.scale = scale\n        self.beta_initializer = initializers.get(beta_initializer)\n        self.gamma_initializer = initializers.get(gamma_initializer)\n        self.moving_mean_initializer = initializers.get(moving_mean_initializer)\n        self.moving_variance_initializer = initializers.get(moving_variance_initializer)\n        self.beta_regularizer = regularizers.get(beta_regularizer)\n        self.gamma_regularizer = regularizers.get(gamma_regularizer)\n        self.beta_constraint = constraints.get(beta_constraint)\n        self.gamma_constraint = constraints.get(gamma_constraint)\n\n    def build(self, input_shape):\n        dim = input_shape[self.axis]\n        if dim is None:\n            raise ValueError(\'Axis \' + str(self.axis) + \' of \'\n                             \'input tensor should have a defined dimension \'\n                             \'but the layer received an input with shape \' +\n                             str(input_shape) + \'.\')\n        self.input_spec = InputSpec(ndim=len(input_shape),\n                                    axes={self.axis: dim})\n        shape = (dim,)\n\n        if self.scale:\n            self.gamma = self.add_weight(shape=shape,\n                                         name=\'gamma\',\n                                         initializer=self.gamma_initializer,\n                                         regularizer=self.gamma_regularizer,\n                                         constraint=self.gamma_constraint)\n        else:\n            self.gamma = None\n        if self.center:\n            self.beta = self.add_weight(shape=shape,\n                                        name=\'beta\',\n                                        initializer=self.beta_initializer,\n                                        regularizer=self.beta_regularizer,\n                                        constraint=self.beta_constraint)\n        else:\n            self.beta = None\n        self.moving_mean = self.add_non_trainable_weight(\n            shape=shape,\n            name=\'moving_mean\',\n            initializer=self.moving_mean_initializer)\n        self.moving_variance = self.add_non_trainable_weight(\n            shape=shape,\n            name=\'moving_variance\',\n            initializer=self.moving_variance_initializer)\n        self.built = True\n\n    def call(self, inputs, training=None):\n        input_shape = K.int_shape(inputs)\n        # Prepare broadcasting shape.\n        ndim = len(input_shape)\n        reduction_axes = list(range(len(input_shape)))\n        del reduction_axes[self.axis]\n        broadcast_shape = [1] * len(input_shape)\n        broadcast_shape[self.axis] = input_shape[self.axis]\n\n        # Determines whether broadcasting is needed.\n        needs_broadcasting = (sorted(reduction_axes) != list(range(ndim))[:-1])\n\n        def normalize_inference():\n            if needs_broadcasting:\n                # In this case we must explicitly broadcast all parameters.\n                broadcast_moving_mean = K.reshape(self.moving_mean,\n                                                  broadcast_shape)\n                broadcast_moving_variance = K.reshape(self.moving_variance,\n                                                      broadcast_shape)\n                if self.center:\n                    broadcast_beta = K.reshape(self.beta, broadcast_shape)\n                else:\n                    broadcast_beta = None\n                if self.scale:\n                    broadcast_gamma = K.reshape(self.gamma,\n                                                broadcast_shape)\n                else:\n                    broadcast_gamma = None\n                return K.batch_normalization(\n                    inputs,\n                    broadcast_moving_mean,\n                    broadcast_moving_variance,\n                    broadcast_beta,\n                    broadcast_gamma,\n                    epsilon=self.epsilon)\n            else:\n                return K.batch_normalization(\n                    inputs,\n                    self.moving_mean,\n                    self.moving_variance,\n                    self.beta,\n                    self.gamma,\n                    epsilon=self.epsilon)\n\n        # If the learning phase is *static* and set to inference:\n        if training in {0, False}:\n            return normalize_inference()\n\n        # If the learning is either dynamic, or set to training:\n        normed_training, mean, variance = K.normalize_batch_in_training(\n            inputs, self.gamma, self.beta, reduction_axes,\n            epsilon=self.epsilon)\n\n        self.add_update([K.moving_average_update(self.moving_mean,\n                                                 mean,\n                                                 self.momentum),\n                         K.moving_average_update(self.moving_variance,\n                                                 variance,\n                                                 self.momentum)],\n                        inputs)\n\n        # Pick the normalized form corresponding to the training phase.\n        return K.in_train_phase(normed_training,\n                                normalize_inference,\n                                training=training)\n\n\n\nclass RProjLocallyConnected2D(LowRankBasisLayer):\n    """"""Locally-connected layer for 2D inputs.\n    The `LocallyConnected2D` layer works similarly\n    to the `Conv2D` layer, except that weights are unshared,\n    that is, a different set of filters is applied at each\n    different patch of the input.\n    """"""\n\n    # @interfaces.legacy_conv2d_support\n    def __init__(self, offset_creator_class, weight_basis,\n                 filters,\n                 kernel_size,\n                 strides=(1, 1),\n                 padding=\'valid\',\n                 data_format=None,\n                 activation=None,\n                 use_bias=True,\n                 kernel_initializer=\'glorot_uniform\',\n                 bias_initializer=\'zeros\',\n                 kernel_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        super(RProjLocallyConnected2D, self).__init__(offset_creator_class, weight_basis, **kwargs)\n        self.filters = filters\n        self.kernel_size = conv_utils.normalize_tuple(kernel_size, 2, \'kernel_size\')\n        self.strides = conv_utils.normalize_tuple(strides, 2, \'strides\')\n        self.padding = conv_utils.normalize_padding(padding)\n        if self.padding != \'valid\':\n            raise ValueError(\'Invalid border mode for LocallyConnected2D \'\n                             \'(only ""valid"" is supported): \' + padding)\n        self.data_format = conv_utils.normalize_data_format(data_format)\n        self.activation = activations.get(activation)\n        self.use_bias = use_bias\n        self.kernel_initializer = initializers.get(kernel_initializer)\n        self.bias_initializer = initializers.get(bias_initializer)\n        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n        self.activity_regularizer = regularizers.get(activity_regularizer)\n        self.kernel_constraint = constraints.get(kernel_constraint)\n        self.bias_constraint = constraints.get(bias_constraint)\n        self.input_spec = InputSpec(ndim=4)\n\n    def build(self, input_shape):\n        if self.data_format == \'channels_last\':\n            input_row, input_col = input_shape[1:-1]\n            input_filter = input_shape[3]\n        else:\n            input_row, input_col = input_shape[2:]\n            input_filter = input_shape[1]\n        if input_row is None or input_col is None:\n            raise ValueError(\'The spatial dimensions of the inputs to \'\n                             \' a LocallyConnected2D layer \'\n                             \'should be fully-defined, but layer received \'\n                             \'the inputs shape \' + str(input_shape))\n        output_row = conv_utils.conv_output_length(input_row, self.kernel_size[0],\n                                                   self.padding, self.strides[0])\n        output_col = conv_utils.conv_output_length(input_col, self.kernel_size[1],\n                                                   self.padding, self.strides[1])\n        self.output_row = output_row\n        self.output_col = output_col\n        self.kernel_shape = (output_row * output_col,\n                             self.kernel_size[0] * self.kernel_size[1] * input_filter,\n                             self.filters)\n        self.kernel = self.add_weight(shape=self.kernel_shape,\n                                      initializer=self.kernel_initializer,\n                                      name=\'kernel\',\n                                      regularizer=self.kernel_regularizer,\n                                      constraint=self.kernel_constraint)\n        if self.use_bias:\n            self.bias = self.add_weight(shape=(output_row, output_col, self.filters),\n                                        initializer=self.bias_initializer,\n                                        name=\'bias\',\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n        else:\n            self.bias = None\n        if self.data_format == \'channels_first\':\n            self.input_spec = InputSpec(ndim=4, axes={1: input_filter})\n        else:\n            self.input_spec = InputSpec(ndim=4, axes={-1: input_filter})\n        self.built = True\n\n    def compute_output_shape(self, input_shape):\n        if self.data_format == \'channels_first\':\n            rows = input_shape[2]\n            cols = input_shape[3]\n        elif self.data_format == \'channels_last\':\n            rows = input_shape[1]\n            cols = input_shape[2]\n\n        rows = conv_utils.conv_output_length(rows, self.kernel_size[0],\n                                             self.padding, self.strides[0])\n        cols = conv_utils.conv_output_length(cols, self.kernel_size[1],\n                                             self.padding, self.strides[1])\n\n        if self.data_format == \'channels_first\':\n            return (input_shape[0], self.filters, rows, cols)\n        elif self.data_format == \'channels_last\':\n            return (input_shape[0], rows, cols, self.filters)\n\n    def call(self, inputs):\n        _, _, filters = self.kernel_shape\n\n        output = K.local_conv2d(inputs,\n                                self.kernel,\n                                self.kernel_size,\n                                self.strides,\n                                (self.output_row, self.output_col),\n                                self.data_format)\n\n        if self.use_bias:\n            if self.data_format == \'channels_first\' or self.data_format == \'channels_last\':\n                output = K.bias_add(output, self.bias, data_format=self.data_format)\n\n        output = self.activation(output)\n        return output\n\n    def get_config(self):\n        config = {\n            \'filters\': self.filters,\n            \'kernel_size\': self.kernel_size,\n            \'strides\': self.strides,\n            \'padding\': self.padding,\n            \'data_format\': self.data_format,\n            \'activation\': activations.serialize(self.activation),\n            \'use_bias\': self.use_bias,\n            \'kernel_initializer\': initializers.serialize(self.kernel_initializer),\n            \'bias_initializer\': initializers.serialize(self.bias_initializer),\n            \'kernel_regularizer\': regularizers.serialize(self.kernel_regularizer),\n            \'bias_regularizer\': regularizers.serialize(self.bias_regularizer),\n            \'activity_regularizer\': regularizers.serialize(self.activity_regularizer),\n            \'kernel_constraint\': constraints.serialize(self.kernel_constraint),\n            \'bias_constraint\': constraints.serialize(self.bias_constraint)\n        }\n        base_config = super(LocallyConnected2D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n'"
intrinsic_dimension/keras_ext/rproj_layers_util.py,87,"b'#! /usr/bin/env python\n\nimport numpy as np\nimport tensorflow as tf\nfrom keras.engine import Layer\n# from keras.backend.tensorflow_backend import _convert_string_dtype\nfrom keras import regularizers, constraints, initializers, activations\nfrom IPython import embed\nfrom sklearn.random_projection import SparseRandomProjection as SRP\nfrom scipy.sparse import find\nimport time\n\nimport os\nimport sys\nlab_root = os.path.join(os.path.abspath(os.path.dirname(__file__)), \'..\')\nsys.path.insert(1, lab_root)\n\n#from ops.fwh import fast_walsh_hadamard as c_fast_walsh_hadamard\n\n\n\n###########\n# \n# A quick fix for the following error\n# from keras.backend.tensorflow_backend import _convert_string_dtype\n# Keras 2.0.8 NameError: global name \'_convert_string_dtype\' is not defined\n# Also called in rproj_layers.py\n\ndef _convert_string_dtype(dtype):\n    if dtype == \'float16\':\n        return tf.float16\n    if dtype == \'float32\':\n        return tf.float32\n    elif dtype == \'float64\':\n        return tf.float64\n    elif dtype == \'int16\':\n        return tf.int16\n    elif dtype == \'int32\':\n        return tf.int32\n    elif dtype == \'int64\':\n        return tf.int64\n    elif dtype == \'uint8\':\n        return tf.int8\n    elif dtype == \'uint16\':\n        return tf.uint16\n    else:\n        raise ValueError(\'Unsupported dtype:\', dtype)\n\n###########\n\nclass ThetaPrime(object):\n    def __init__(self, size):\n        self.var = tf.Variable(np.zeros((size), dtype=\'float32\'))\n        self.var_2d = tf.expand_dims(self.var, 0)\n        self.size = size\n\n\n###########\n#\n# OffsetCreator{Dense,Sparse,Fastfood}Proj\n#\n# These classes create offsets. Each layer is given a projector on\n# construction and uses it as needed to create weight/bias/etc\n# offsets.\n#\n###########\n\nclass OffsetCreatorDenseProj(object):\n    def __init__(self):\n        self.basis_matrices = []\n\n    def create_theta_offset(self, weight_basis, shape, dtype, name=None):\n        assert isinstance(weight_basis, ThetaPrime), \'weight_basis should be a ThetaPrime\'\n\n        if isinstance(shape, tf.TensorShape):\n            shape = shape.as_list()\n        \n        # Create projection matrix ww\n        total_dim = 1\n        for dim in shape:\n            assert dim is not None and dim > 0, \'dimensions must be known\'\n            total_dim *= dim\n        seed = np.random.randint(10e8)\n\n        ww_shape = (weight_basis.size, total_dim)\n        ww_0 = tf.random_normal_initializer(0.0, 1.0, dtype=_convert_string_dtype(dtype), seed=seed)(ww_shape)\n        ww = tf.Variable(ww_0, trainable=False, dtype=_convert_string_dtype(dtype), name=\'%s_ww\' % name)\n        theta_offset = tf.reshape(tf.matmul(weight_basis.var_2d, ww), shape)\n\n        self.basis_matrices.append(ww)\n\n        return theta_offset, [ww]\n\n\n\nclass OffsetCreatorSparseProj(object):\n    def __init__(self):\n        self.basis_matrices = []\n        self.basis_matrix_normalizers = []\n\n    def create_theta_offset(self, weight_basis, shape, dtype, name=None):\n        assert isinstance(weight_basis, ThetaPrime), \'weight_basis should be a ThetaPrime\'\n\n        if isinstance(shape, tf.TensorShape):\n            shape = shape.as_list()\n        \n        # Create projection matrix ww\n        total_dim = 1\n        for dim in shape:\n            assert dim is not None and dim > 0, \'dimensions must be known\'\n            total_dim *= dim\n\n        # Generate location and relative scale of non zero elements\n        M = SRP(weight_basis.size)._make_random_matrix(weight_basis.size,total_dim)\n        fm=find(M)\n\n        # Create sparse projection matrix from small vv to full theta space\n        ww0 = tf.SparseTensor(indices=np.array([fm[0],fm[1]]).T, values=fm[2], dense_shape=[weight_basis.size, total_dim])\n        ww = tf.cast(ww0, _convert_string_dtype(dtype))\n\n        # Create diagonal normalization matrix that will be filled in when all layers are created, so that we can normalize each\n        # row of the projection matrix (with length equal to the total number of parameters in the model) once we have all its elements.\n        # This will hold the norms of the rows of the un-normalized projection matrix.\n        normalizer = tf.Variable(tf.zeros(weight_basis.size,_convert_string_dtype(dtype)),\n                                 trainable=False, name=\'%s_normalizer\' % name)\n\n        # Pre-multiply the normalizer by the low-rank parameter vector to avoid a sparse matrix - sparse matrix product,\n        # which is not well-supported in Tensorflow (instead of theta_full = (P*N^-1)*theta_small where P*N^-1 is a row-normalized\n        # projection matrix, do P*(N^-1*theta_small)). (N^-1*theta_small) can be written as simply an element-wise vector division.\n        theta_small_norm = tf.divide(weight_basis.var_2d, normalizer)\n\n        # Compute delta from theta_0 using sparse projection\n        # Note: sparse matrix must be first argument\n        delta_theta_flat = tf.sparse_tensor_dense_matmul(ww, theta_small_norm, adjoint_a=True, adjoint_b=True)\n\n        # Create theta\n        theta_offset = tf.reshape(delta_theta_flat, shape)\n\n        self.basis_matrices.append(ww)\n        self.basis_matrix_normalizers.append(normalizer)\n\n        # Note: previous versions added only ww0 to _non_trainable_weights but skipped normalizer. Here we more correctly return both.\n        # return theta_offset, [ww0]\n        return theta_offset, [ww0, normalizer]\n\n\n\nclass OffsetCreatorFastfoodProj(object):\n    def __init__(self):\n        pass\n\n    def create_theta_offset(self, weight_basis, shape, dtype, name=None):\n        # Get offset from theta_0 (offset is initially 0)\n        assert isinstance(weight_basis, FastWalshHadamardProjector), \'weight_basis should be a FastWalshHadamardProjector instance\'\n        proj_tensor = weight_basis.get_projected_tensor(shape)\n        return proj_tensor, []\n\n\n###########\n#\n# FastWalshHadamardProjector\n#\n# This class is instantiated once per network and manages the whole\n# projection from d to D.\n#\n###########\n\nclass FastWalshHadamardProjector(Layer):\n    \'\'\'FastWalshHadamardProjector owns the d trainable parameters and\n    generates the D projected parameters.\n\n    FastWalshHadamardProjector must be instantiated before the model\n    is built with d (known) and D (possibly hard to find before model\n    is built). Thus some trickiness is necessary.\n    \'\'\'\n\n    def __init__(self, dd, DD, **kwargs):\n        super(FastWalshHadamardProjector, self).__init__(**kwargs)\n        self.dd = dd\n        self.DD = DD\n        self.index = 0\n        self.d_vec = self.add_weight(\'d_vec\', (self.dd,), initializer=\'zeros\')\n        self.project_vars, self.D_vec = tf_fastfood_transform(self.d_vec, self.dd, self.DD)\n        for vv in self.project_vars:\n            self._non_trainable_weights.append(vv)\n\n    def get_projected_tensor(self, shape):\n        if isinstance(shape, tf.TensorShape):\n            shape = shape.as_list()\n        total_size = np.prod(shape)\n        assert self.index + total_size <= self.DD, \'Overrun D vector; requested too many projected tensors\'\n        #ret = self.D_vec[self.index:self.index + total_size]\n        retflat = tf.slice(self.D_vec, [self.index], [total_size])\n        #print \'D_vec is\', self.D_vec, \'and ret is\', retflat\n        ret = tf.reshape(retflat, shape)\n        #print \'      ... now ret is\', ret\n        #print \'Sliced from %d to %d and reshaped to %s\' % (self.index, total_size, repr(shape))\n        self.index += total_size\n        return ret\n\n    def check_usage(self):\n        if self.index == self.DD:\n            print \'FastWalshHadamardProjector usage is perfect: %d out of %d dimensions used\' % (self.index, self.DD)\n        else:\n            raise Exception(\'FastWalshHadamardProjector usage is off: %d out of %d dimensions used\' % (self.index, self.DD))\n\n\n\n\n\n###########\n#\n# Fast Walsh Hadamard functions\n#\n###########\n\ndef np_fast_walsh_hadamard(x, axis, normalize=True):\n    \'\'\'Compute Fast Walsh-Hadamard transform in numpy.\n\n    Args:\n        x: tensor of shape (a0, a1, ... aN, L, b0, b1, ..., bN).\n            L must be a power of two.\n\n        axis: the ""L"" axis above, aka the axis over which to do the\n            Hadamard transform. All other dimensions are left alone;\n            data on those dimension do not interact.\n\n        normalize: Whether to normalize the results such that applying\n            the transform twice returns to the original input\n            value. If True, return values are floats even if input was\n            int.\n\n    Returns:\n        ret: transformed tensor with same shape as x\n\n\n    Tests:\n\n    Wikipedia case\n\n    >>> x = np.array([1,0,1,0,0,1,1,0])\n\n    >>> np_fast_walsh_hadamard(x, 0, False)\n    array([ 4,  2,  0, -2,  0,  2,  0,  2])\n\n    >>> np_fast_walsh_hadamard(np_fast_walsh_hadamard(x, 0), 0)\n    array([ 1.,  0.,  1.,  0.,  0.,  1.,  1.,  0.])\n    \'\'\'\n\n    orig_shape = x.shape\n    assert axis >= 0 and axis < len(orig_shape), (\n        \'For a vector of shape %s, axis must be in [0, %d] but it is %d\'\n        % (orig_shape, len(orig_shape) - 1, axis))\n    h_dim = orig_shape[axis]\n    h_dim_exp = int(round(np.log(h_dim) / np.log(2)))\n    assert h_dim == 2 ** h_dim_exp, (\n        \'hadamard can only be computed over axis with size that is a power of two, but\'\n        \' chosen axis %d has size %d\' % (axis, h_dim))\n    working_shape_pre = [int(np.prod(orig_shape[:axis]))]     # prod of empty array is 1 :)\n    working_shape_post = [int(np.prod(orig_shape[axis+1:]))]  # prod of empty array is 1 :)\n    working_shape_mid = [2] * h_dim_exp\n    working_shape = working_shape_pre + working_shape_mid + working_shape_post\n    #print \'working_shape is\', working_shape\n    ret = x.reshape(working_shape)\n\n    for ii in range(h_dim_exp):\n        dim = ii + 1\n        arrs = np.split(ret, 2, axis=dim)\n        assert len(arrs) == 2\n        ret = np.concatenate((arrs[0] + arrs[1], arrs[0] - arrs[1]), axis=dim)\n\n    if normalize:\n        ret = ret / np.sqrt(float(h_dim))\n\n    ret = ret.reshape(orig_shape)\n\n    return ret\n\n\ndef _fast_walsh_hadamard_one_step(xx, axis):\n    aa, bb = tf.split(xx, 2, axis=axis)\n    ret = tf.concat((aa + bb, aa - bb), axis=axis)\n    return ret\n\n\ndef _fast_walsh_hadamard_one_step_method2(xx, pre, d1, d2, d3, post):\n    working_shape = tf.concat((pre, d1, d2, d3, post), axis=0)\n    xx = tf.reshape(xx, working_shape)\n    aa, bb = tf.split(xx, 2, axis=2)\n    ret = tf.concat((aa + bb, aa - bb), axis=2)\n    return ret\n\n\ndef tf_fast_walsh_hadamard(in_x, axis, normalize=True, method=\'two\'):\n    \'\'\'Compute Fast Walsh-Hadamard transform in tensorflow.\n\n    Args:\n        x: tensor of shape (a0, a1, ... aN, L, b0, b1, ..., bN).\n            L must be a power of two.\n\n        axis: the ""L"" axis above, aka the axis over which to do the\n            Hadamard transform. All other dimensions are left alone;\n            data on those dimension do not interact.\n\n        normalize: Whether to normalize the results such that applying\n            the transform twice returns to the original input\n            value.\n\n        method:\n            \'one\': Original reshape to [2]*ll version\n            \'two\': Deal with TF ""UnimplementedError: SliceOp : Unhandled input dimensions"" error...\n            \'c\':   Use C++ FWH Op.\n\n    Returns:\n        ret: transformed tensor with same shape as x. Returned\n            tensor is always float even if input was int.\n\n\n    Tests:\n\n    >>> in_x = tf.placeholder(\'float32\')\n    >>> in_x\n    <tf.Tensor \'Placeholder:0\' shape=<unknown> dtype=float32>\n    >>> sess = tf.InteractiveSession()\n\n\n    Wikipedia case:\n\n    >>> x = np.array([1,0,1,0,0,1,1,0])\n\n    >>> sess.run(tf_fast_walsh_hadamard(in_x, 0, False), feed_dict={in_x: x})\n    array([ 4.,  2.,  0., -2.,  0.,  2.,  0.,  2.], dtype=float32)\n\n    >>> sess.run(tf_fast_walsh_hadamard(in_x, 0, False, method=\'two\'), feed_dict={in_x: x})\n    array([ 4.,  2.,  0., -2.,  0.,  2.,  0.,  2.], dtype=float32)\n\n    >>> sess.run(tf_fast_walsh_hadamard(tf_fast_walsh_hadamard(in_x, 0), 0), feed_dict={in_x: x})\n    array([ 1.,  0.,  1.,  0.,  0.,  1.,  1.,  0.], dtype=float32)\n\n\n    Verify equivalence with numpy approach:\n\n    >>> np.random.seed(123)\n    >>> x = np.random.uniform(0, 1, (3, 64, 5))\n\n    >>> h_np = np_fast_walsh_hadamard(x, 1)\n    >>> h_tf_ = tf_fast_walsh_hadamard(in_x, 1)\n    >>> h_tf2_ = tf_fast_walsh_hadamard(in_x, 1, method=\'two\')\n    >>> h_tf = sess.run(h_tf_, feed_dict={in_x: x})\n    >>> h_tf2 = sess.run(h_tf2_, feed_dict={in_x: x})\n\n    >>> x.shape\n    (3, 64, 5)\n    >>> h_np.shape\n    (3, 64, 5)\n    >>> h_tf.shape\n    (3, 64, 5)\n    >>> h_tf2.shape\n    (3, 64, 5)\n\n    >>> abs(h_np - h_tf).max() < 1e-6\n    True\n    >>> abs(h_np - h_tf2).max() < 1e-6\n    True\n\n    Try a few other shapes / axes\n\n    >>> sess.run(tf_fast_walsh_hadamard(in_x, 0), feed_dict={in_x: x[0]}).shape == x[0].shape\n    True\n    >>> sess.run(tf_fast_walsh_hadamard(in_x, 1), feed_dict={in_x: x[:, :, 0]}).shape == x[:, :, 0].shape\n    True\n    >>> sess.run(tf_fast_walsh_hadamard(in_x, 0), feed_dict={in_x: x[0, :, 0]}).shape == x[0, :, 0].shape\n    True\n    \'\'\'\n\n    orig_shape = tf.shape(in_x)\n    h_dim = orig_shape[axis]\n    h_dim_exp = tf.cast(tf.round(tf.log(tf.to_float(h_dim)) / np.log(2)), \'int32\')\n\n    assert_pow2 = tf.assert_equal(h_dim, tf.pow(2, h_dim_exp),\n                                  message=\'hadamard can only be computed over axis with size that is a power of two\')\n\n    with tf.control_dependencies([assert_pow2]):\n        working_shape_pre = tf.expand_dims(tf.reduce_prod(orig_shape[:axis]), axis=0)        # reduce_prod of empty array is 1\n        working_shape_post = tf.expand_dims(tf.reduce_prod(orig_shape[axis + 1:]), axis=0)   # reduce_prod of empty array is 1\n\n    ii = tf.constant(0)\n    assert method in (\'one\', \'two\', \'c\')\n    if method == \'one\':\n        # expand to working dims [pre, 2, 2, 2, ..., 2, 2, post]\n        working_shape_mid = tf.tile([2], [h_dim_exp])\n\n        working_shape = tf.concat((working_shape_pre, working_shape_mid, working_shape_post),\n                                  axis=0)\n\n        ret_0 = tf.reshape(in_x, working_shape)\n\n        cond = lambda i, x: tf.less(i, h_dim_exp)\n        body = lambda i, x: (tf.add(i, 1), _fast_walsh_hadamard_one_step(x, i + 1))\n\n        ii_final, ret = tf.while_loop(\n            cond,\n            body,\n            [ii, ret_0],\n            parallel_iterations=1     # check on this?\n        )\n    elif method == \'two\':\n        # Never expand to high rank. Roll dimensions instead. This is\n        # needed because backprop through the slice operator only\n        # supports up to rank 7 tensors in TF 1.3\n        # [pre, 1, 2, h_dim/2, post] ->\n        # [pre, 2, 2, h_dim/4, post] -> ...\n        # [pre, h_dim/2, 2, 1, post]\n\n        d1 = tf.expand_dims(tf.constant(1), axis=0)\n        d2 = tf.expand_dims(tf.constant(2), axis=0)   # always 2\n        d3 = tf.expand_dims(h_dim / 2, axis=0)\n\n        working_shape_0 = tf.concat((working_shape_pre, d1, d2, d3, working_shape_post), axis=0)\n        ret_0 = tf.reshape(in_x, working_shape_0)\n\n        cond = lambda i, d1, d3, x: tf.less(i, h_dim_exp)\n        body = lambda i, d1, d3, x: (tf.add(i, 1),\n                                     d1 * 2,\n                                     d3 / 2,\n                                     _fast_walsh_hadamard_one_step_method2(x, working_shape_pre, d1, d2, d3, working_shape_post))\n\n        ii_final, d1_final, d3_final, ret = tf.while_loop(\n            cond,\n            body,\n            [ii, d1, d3, ret_0],\n            parallel_iterations=1     # check on this?\n        )\n    else:\n        # \'c\' version\n        # Only works for rank-1 (vector) input\n\n        assert False, \'c version disabled for now\'\n\n        assert axis == 0, \'axis must be 0 for the c version of tf_fast_walsh_hadamard\'\n        assert normalize, \'for c version normalize must be True\'\n        assert_rank1 = tf.assert_rank(in_x, 1)\n\n        with tf.control_dependencies([assert_rank1, assert_pow2]):\n            ret = c_fast_walsh_hadamard(in_x)\n\n    if normalize and method != \'c\':\n        ret = ret / tf.sqrt(tf.to_float(h_dim))\n\n    ret = tf.reshape(ret, orig_shape)\n\n    return ret\n\n\ndef tf_fastfood_transform(in_x, dd, DD, use_get=False, use_C=False):\n    \'\'\'Transform from d to D. Pads as necessary.\n\n    For now: assume dd and DD are known in python.\'\'\'\n\n    # Tensor d and D\n    #assert_D_big = tf.assert_greater_equal(DD, dd, message=\'d cannot be larger than D\')\n    #with tf.control_dependencies([assert_D_big]):\n    #    ll = tf.cast(tf.round(tf.log(tf.to_float(DD)) / np.log(2)), \'int32\')\n    #    LL = tf.pow(2, ll)\n\n    # Python d and D\n    assert isinstance(dd, int), \'d should be int\'\n    assert isinstance(DD, int), \'D should be int\'\n    assert DD >= dd, \'d cannot be larger than D\'\n    assert dd > 0, \'d and D must be positive\'\n\n    ll = int(np.ceil(np.log(DD) / np.log(2)))\n    LL = 2 ** ll\n\n    # Make vars\n    init_BB = tf.to_float(tf.random_uniform((LL,), 0, 2, dtype=\'int32\')) * 2 - 1\n    init_Pi = tf.random_shuffle(tf.range(LL))\n    init_GG = tf.random_normal((LL,))\n    init_divisor = lambda GG: tf.sqrt(LL * tf.reduce_sum(tf.pow(GG.initialized_value(), 2)))\n    if use_get:\n        BB = tf.get_variable(\'B\', initializer=init_BB, trainable=False)\n        Pi = tf.get_variable(\'Pi\', initializer=init_Pi, trainable=False)\n        GG = tf.get_variable(\'G\', initializer=init_GG, trainable=False)\n        divisor = tf.get_variable(\'divisor\', initializer=init_divisor(GG), trainable=False)\n    else:\n        BB = tf.Variable(init_BB, name=\'B\', trainable=False)\n        Pi = tf.Variable(init_Pi, name=\'Pi\', trainable=False)\n        GG = tf.Variable(init_GG, name=\'G\', trainable=False)\n        divisor = tf.Variable(init_divisor(GG), name=\'divisor\', trainable=False)\n\n    fastfood_vars = [BB, Pi, GG, divisor]\n\n    # Implement transform\n    dd_pad = tf.pad(in_x, [[0, LL - dd]])\n    mul_1 = tf.multiply(BB, dd_pad)\n    if use_C:\n        mul_2 = tf_fast_walsh_hadamard(mul_1, 0, method=\'c\', normalize=True)\n    else:\n        mul_2 = tf_fast_walsh_hadamard(mul_1, 0, method=\'two\', normalize=False)\n    mul_3 = tf.gather(mul_2, Pi)\n    mul_4 = tf.multiply(mul_3, GG)\n    if use_C:\n        mul_5 = tf_fast_walsh_hadamard(mul_4, 0, method=\'c\', normalize=True)\n        print \'\\nWARNING: check normalization on this next line more carefully\\n\'\n        ret = tf.divide(tf.slice(mul_5, [0], [DD]), divisor * np.sqrt(float(DD) / LL / ll))\n    else:\n        mul_5 = tf_fast_walsh_hadamard(mul_4, 0, method=\'two\', normalize=False)\n        ret = tf.divide(tf.slice(mul_5, [0], [DD]), divisor * np.sqrt(float(DD) / LL))\n\n    return fastfood_vars, ret\n\n\ndef test_timing():\n    N = 29\n\n    in_x = tf.placeholder(\'float32\')\n    sum_x = tf.reduce_sum(in_x)\n    hh = tf_fast_walsh_hadamard(in_x, 1, True)\n    sum_h = tf.reduce_sum(hh)\n    sess = tf.InteractiveSession()\n\n    for ll in range(1, N):\n        L = 2**ll\n        print \'\\n%d, H dim %d\' % (ll, L)\n\n        x = np.random.uniform(0, 1, (1, L, 1))\n\n        if L < 33554432:\n            start = time.time()\n            np_fast_walsh_hadamard(x, 1)\n            end = time.time()\n            print \'  np                %14s elems:  %16s\' % (\'%d\' % L, \'%f\' % (end - start))\n        else:\n            print \'  np                     <skipped>\'\n\n        start = time.time()\n        sess.run(sum_h, feed_dict={in_x: x})\n        end = time.time()\n        print \'  tf                %14s elems:  %16s\' % (\'%d\' % L, \'%f\' % (end - start))\n\n        # Time each op the third time (ignore CUDA tuning time) then subtract data transfer time\n        sess.run(sum_x, feed_dict={in_x: x})\n        sess.run(sum_x, feed_dict={in_x: x})\n        start = time.time()\n        sess.run(sum_x, feed_dict={in_x: x})\n        elap_data = time.time() - start\n        sess.run(sum_h, feed_dict={in_x: x})\n        sess.run(sum_h, feed_dict={in_x: x})\n        start = time.time()\n        sess.run(sum_h, feed_dict={in_x: x})\n        elap_had = time.time() - start\n        print \'  tf just H         %14s elems:  %16s\' % (\'%d\' % (L), \'%f\' % (elap_had - elap_data))\n\n        DD = max(5, int(np.ceil(L * .8)))\n        dd = max(3, int(np.ceil(DD * .001)))\n        if x.shape[1] >= dd:\n            for use_C in [False, True]:\n                st = \'(C) \' if use_C else \'(TF)\'\n                ffvars, xform = tf_fastfood_transform(in_x, dd, DD, use_C=use_C)\n                sum_xf = tf.reduce_sum(xform)\n                sess.run(tf.global_variables_initializer())\n\n                sess.run(sum_xf, feed_dict={in_x: x[0, :dd, 0]})\n                start = time.time()\n                sess.run(sum_xf, feed_dict={in_x: x[0, :dd, 0]})\n                end = time.time()\n                print \'  tf %s fastf     %14s elems:  %16s\' % (st, \'%d\' % L, \'%f\' % (end - start))\n\n                sess.run(sum_x, feed_dict={in_x: x[0, :dd, 0]})\n                sess.run(sum_x, feed_dict={in_x: x[0, :dd, 0]})\n                start = time.time()\n                sess.run(sum_x, feed_dict={in_x: x[0, :dd, 0]})\n                elap_data = time.time() - start\n                sess.run(sum_xf, feed_dict={in_x: x[0, :dd, 0]})\n                sess.run(sum_xf, feed_dict={in_x: x[0, :dd, 0]})\n                start = time.time()\n                sess.run(sum_xf, feed_dict={in_x: x[0, :dd, 0]})\n                elap_had = time.time() - start\n                print \'  tf %s just fastf%14s elems:  %16s\' % (st, \'%d\' % (L), \'%f\' % (elap_had - elap_data))\n\n        else:\n            print \'  tf fastfood       %14s elems:  <skipped, too small>\' % (\'%d\' % L)\n\n\n\n        if L > 32768:\n            print \'                        <skipped large batch cases>\'\n            continue\n\n        x2 = np.random.uniform(0, 1, (10, L, 100))\n\n        start = time.time()\n        np_fast_walsh_hadamard(x2, 1)\n        end = time.time()\n        print \'  np                %14s elems:  %16s\' % (\'%d\' % (L*1000), \'%f\' % (end - start))\n\n        start = time.time()\n        sess.run(sum_h, feed_dict={in_x: x2})\n        end = time.time()\n        print \'  tf                %14s elems:  %16s\' % (\'%d\' % (L*1000), \'%f\' % (end - start))\n\n        # Time each op the third time (ignore CUDA tuning time) then subtract data transfer time\n        sess.run(sum_x, feed_dict={in_x: x2})\n        sess.run(sum_x, feed_dict={in_x: x2})\n        start = time.time()\n        sess.run(sum_x, feed_dict={in_x: x2})\n        elap_data = time.time() - start\n        sess.run(sum_h, feed_dict={in_x: x2})\n        sess.run(sum_h, feed_dict={in_x: x2})\n        start = time.time()\n        sess.run(sum_h, feed_dict={in_x: x2})\n        elap_had = time.time() - start\n        print \'  tf just H         %14s elems:  %16s\' % (\'%d\' % (L*1000), \'%f\' % (elap_had - elap_data))\n\n    print \'The next dim, 2**29 ==\', 2**29, \'crashes with OOM on a TitanX\'\n\n\n\nif __name__ == \'__main__\':\n    import doctest\n    doctest.testmod()\n\n    test_timing()\n'"
intrinsic_dimension/keras_ext/test_layers.py,8,"b'#! /usr/bin/env python\n\nimport os, sys\nimport skimage\nimport skimage.io\nimport skimage.transform\nimport numpy as np\nfrom IPython import embed\nimport tensorflow as tf\nfrom keras.layers import Input\nimport keras.backend as K\nfrom keras.models import Sequential, Model\n\n#pack_root = os.path.join(os.path.dirname(__file__), \'..\', \'..\')\n#sys.path.insert(1, pack_root)\n\n# extended Keras layers\nfrom keras_layers import *\n\n\ndef sample_box(proposed_box, target_box,high_thresh, low_thresh,batch_size):\n    """""" Compute Box IOU and sample positive/negative boxes and targe boxes\n        Input:\n            - proposed_box: tensor, all of the proposed boxes from RPN model.\n            - target_box: tensor, groudtruth box from input dataset.\n            - high_thresh: float, iou threshold to pick positive samples.\n            - low_thresh: float, iou threshold to pick negative samples.\n            - batch_sizes: output sample size.\n        Output:\n            - packed_pos_samples: tensor, packed with pos_samples and neg_samples.\n            - negative_samples: tensor.\n    """"""\n    # NOTE: this function should goes to model_builder.py later.\n    out_iou = BoxIoU()([proposed_box, target_box])\n    \n    sample_idx = BoxSamplerPosNeg(high_thresh, low_thresh, batch_size)(out_iou)\n    ## NOTE: pos_samples is packed with pos_samples and tar_samples. Do NOT unpack here, \n    ##       otherwise keras cannot recognize the tensor size. \n    #packed_pos_samples = BoxSamplerPositive(high_thresh, batch_size)(\n    #        [proposed_box, target_box,out_iou])\n    #neg_samples = BoxSamplerNegative(low_thresh, batch_size)([proposed_box, out_iou])\n\n    model = Model(input=[proposed_box, target_box], output=[\n                         sample_idx])\n    return model\n\n\ndef test_box_sampling():\n    print \'Test box sampling module ...\'\n    # build keras model graph\n    in_box1 = Input(batch_shape=(1,3, 4)) # proposed box\n    in_box2 = Input(batch_shape=(1,2, 4)) # target box\n    model = sample_box(in_box1, in_box2, 0.1, 0.1, 2)\n\n\n    # create testing input values\n    in_box1_val = np.array([[20., 10., 5., 5.],\n                         [80., 10., 5., 20.],\n                         [80., 80., 10., 5.]])\n    in_box1_val = np.tile(in_box1_val, (1,1,1))\n    in_box2_val = np.array([[20., 10., 20., 10.],\n                         [80., 80., 10., 10.]])\n    in_box2_val = np.tile(in_box2_val, (1,1,1))\n\n    # run graph\n    init = tf.initialize_all_variables()\n    sess = tf.Session()\n    sess.run(init)\n\n    out_vals = sess.run(model.output, feed_dict={\n        model.input[0]: in_box1_val,\n        model.input[1]: in_box2_val})\n    \n    print \'box sampling OK!\'\n    embed()\n\ndef test_boxiou():\n    print \'Test Box IOU layer...\'\n    # build keras model graph\n    in_box1 = Input(batch_shape=(1,3, 4)) # proposed box\n    in_box2 = Input(batch_shape=(1,2, 4)) # target box\n    out_iou = BoxIoU()([in_box1, in_box2])\n    model = Model(input=[in_box1, in_box2], output=out_iou)\n\n    # create testing input values\n    in_box1_val = np.array([[20., 10., 5., 5.],\n                         [80., 10., 5., 20.],\n                         [80., 80., 10., 5.]])\n    in_box1_val = np.tile(in_box1_val, (1,1,1))\n    in_box2_val = np.array([[20., 10., 20., 10.],\n                         [80., 80., 10., 10.]])\n    in_box2_val = np.tile(in_box2_val, (1,1,1))\n\n    # run graph\n    init = tf.initialize_all_variables()\n    sess = tf.Session()\n    sess.run(init)\n\n    out_iou_val = sess.run(model.output, feed_dict={\n        model.input[0]: in_box1_val,\n        model.input[1]: in_box2_val})\n    \n    print \'Box IOU OK!\'\n    print out_iou_val\n\ndef test_selectpos():\n    print \'Test SelectPosMakeTheta layer...\'\n    in_sample_index = Input(batch_shape=(5,3))  # sample index\n    in_box_coords = Input(batch_shape=(6,4))\n\n    out_theta = SelectPosMakeTheta(64,64)([in_sample_index, in_box_coords])\n    model = Model(input=[in_sample_index, in_box_coords], output = out_theta)\n\n    # create some data\n    sample_index = np.array([[1, 2, 1],\n                            [1, 0, 3],\n                            [1, 4, 2],\n                            [-1,1, -1],\n                            [-1,3, -1]])\n    box_coords = np.array([[0., 0., 12., 14.],\n                        [1., 2., 15., 15.],\n                        [1.5, 2., 4., 10.],\n                        [5., 8., 4., 10.],\n                        [5.5, 3., 6., 8.],\n                        [3., 4., 9., 9.]])\n    # run graph\n    init = tf.initialize_all_variables()\n    sess = tf.Session()\n    sess.run(init)\n\n    out_theta_val = sess.run(model.output, feed_dict={\n        model.input[0]: sample_index,\n        model.input[1]: box_coords})\n    \n    print \'SelectPosMakeTheta works!\'\n    print out_theta_val\n        \ndef test_tile():\n    in_x = Input(batch_shape = (1,13,13,5))\n    in_y = Input(batch_shape = (12,6))\n\n    out_x = TileTensorLike()([in_x, in_y])\n    model = Model(input=[in_x,in_y], output=out_x)\n\n    in_x_val = np.random.rand(1,13,13,5)\n    in_y_val = np.random.rand(12,6)\n\n    # run graph\n    init = tf.initialize_all_variables()\n    sess = tf.Session()\n    sess.run(init)\n\n    out_x_val = sess.run(model.output, feed_dict={\n        model.input[0]: in_x_val,\n        model.input[1]: in_y_val})\n    \n    print \'Tile works!\'\n    print out_x_val.shape\n\nif __name__ == \'__main__\':\n    #test_boxiou()\n    #test_box_sampling()\n    #test_selectpos()\n    test_tile()\n\n\n'"
intrinsic_dimension/keras_ext/util.py,4,"b""import os\nimport numpy as np\nimport tensorflow as tf\nimport keras.backend as K\nfrom keras.layers import Flatten, Input, Lambda\n\nfrom general.tfutil import tf_assert_gpu, hist_summaries_traintest\n\n\n########################\n# General Keras helpers\n########################\n\ndef make_image_input_preproc(im_dims, dtype='float32', flatten_in=False, shift_in=None, name=None):\n    '''Make an input for images and (optionally preprocess). Returns\n    both the Input layer (which should be used as Model input) and the\n    preproc version (which should be passed to the first layer of the\n    model). If no preprocessing is done, the Input layer and preproc\n    will be the same.\n    '''\n    \n    assert isinstance(im_dims, tuple) and len(im_dims) == 3, 'should be tuple of 3 dims (0,1,c)'\n    assert dtype in ('float32', 'uint8'), 'unknown dtype'\n\n    input_images = Input(shape=im_dims, dtype=dtype, name=name)\n    preproc_images = input_images\n    if dtype == 'uint8':\n        preproc_images = Lambda(lambda x: K.cast(x, 'float32'))(preproc_images)\n    if shift_in is not None:\n        print 'subtracting from each input:', shift_in\n        preproc_images = Lambda(lambda x: x - shift_in)(preproc_images)\n    if flatten_in:\n        preproc_images = Flatten()(preproc_images)\n    return input_images, preproc_images\n\n\ndef make_classlabel_input(n_label_vals):\n    return Input(batch_shape=(None,), dtype='int64')\n\n\ndef setup_session_and_seeds(seed, assert_gpu=True, mem_fraction=None):\n    '''Start TF and register session with Keras'''\n\n    # Use InteractiveSession instead of Session so the default session will be set\n    if mem_fraction is not None:\n        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=mem_fraction)\n        sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options))\n    else:\n        sess = tf.InteractiveSession()\n    K.set_session(sess)\n    np.random.seed(seed)\n    tf.set_random_seed(seed)\n    print 'Set numpy and tensorflow random seeds to: %s' % repr(seed)\n    print 'My PID is %d' % os.getpid()\n    if assert_gpu:\n        tf_assert_gpu(sess)\n    return sess\n\n\ndef add_act_summaries(model, quiet=False):\n    tensors = []\n    if not quiet:\n        print '\\nActivations:'\n    for layer in model.layers:\n        for node in layer._inbound_nodes:\n            for tensor in node.output_tensors:\n                tensors.append(tensor)\n    tdict = {tt.name: tt for tt in set(tensors)}\n    for tname in sorted(tdict.keys()):\n        hist_summaries_traintest(tdict[tname], name=tname + '__act')\n        if not quiet:\n            print '  ', tname, tdict[tname]\n\n\ndef get_model_tensors(model, with_layers_nodes=False):\n    tensor_set = set()\n    tensor_list = []\n    layer_list = []\n    node_list = []\n    for layer in model.layers:\n        for node in layer._inbound_nodes:\n            for tensor in node.output_tensors:\n                if tensor not in tensor_set:\n                    # Make a list with deteministic order, but check membership using a fast set\n                    tensor_set.add(tensor)\n                    tensor_list.append(tensor)\n                    layer_list.append(layer)\n                    node_list.append(node)\n    if with_layers_nodes:\n        return tensor_list, layer_list, node_list\n    else:\n        return tensor_list\n\n\ndef warn_misaligned_shapes(model):\n    printed = False\n    tlns = get_model_tensors(model, with_layers_nodes=True)\n    for tln in zip(tlns[0], tlns[1], tlns[2]):\n        tensor, layer, node = tln\n        tf_shape = tuple(tensor.get_shape().as_list())\n        try:\n            keras_shape = tensor._keras_shape\n        except AttributeError:\n            continue\n        if tf_shape != keras_shape:\n            if not printed:\n                print '\\nWarning: found the following tensor shape mismatches, may indicate problems.'\n                print '   %-40s %-22s %-22s' % ('LAYER NAME', '', '')\n                print '   %-40s %-22s %-22s' % ('TENSOR NAME', 'KERAS SHAPE', 'TF SHAPE')\n                printed = True\n            print '   %-40s %-22s %-22s' % (layer.name, '', '')\n            print '   %-40s %-22s %-22s' % (tensor.name, keras_shape, tf_shape)\n\n\ndef full_static_shape(var):\n    '''Returns the most fully-specified static shape possible for var (at\n    graph build time, not run time). Uses information in\n    var.get_shape() as well as var._keras_shape. Raises an Exception\n    if the two shapes are incompatible with each other.\n    '''\n\n    try:\n        tf_shape = [val.__int__() for val in var.get_shape()]\n    except ValueError:\n        raise Exception('Unclear why this would ever be encountered. If it pops up, debug here.')\n            \n    if not hasattr(var, '_keras_shape'):\n        return tf_shape\n\n    k_shape = var._keras_shape\n    assert len(tf_shape) == len(k_shape), 'Shape lengths different; this probably should not occur'\n\n    shape = []\n    for tt, kk in zip(tf_shape, k_shape):\n        if tt == kk:\n            shape.append(tt)\n        else:\n            if tt is None:\n                shape.append(kk)\n            elif kk is None:\n                shape.append(tt)\n            else:\n                raise Exception('tf shape and Keras shape are contradictory: %s vs %s' % (tf_shape, k_shape))\n    return shape\n"""
intrinsic_dimension/ops/__init__.py,0,b''
intrinsic_dimension/ops/fast_walsh_hadamard_test.py,5,"b'import tensorflow as tf\nfrom fwh import fast_walsh_hadamard as c_fast_walsh_hadamard\nimport numpy as np\nimport time\n\nclass FastWalshHadamardTest(tf.test.TestCase):\n    def testFastWalshHadamard(self):\n        with self.test_session():\n            for i in range(20, 30):\n                V = np.random.RandomState(123).randn(2 ** i).astype(np.float32)\n                V = tf.constant(V, tf.float32)\n\n                with tf.device(\'/cpu\'):\n                    cpu_out = c_fast_walsh_hadamard(V)\n                with tf.device(\'/gpu\'):\n                    gpu_out = c_fast_walsh_hadamard(V)\n\n                a_start = time.time()\n                a = cpu_out.eval();\n                a_end = time.time()\n                b = gpu_out.eval();\n                b_end = time.time()\n                print(\'Size: 2**{} = {} CPU: {} GPU: {} Speedup: {}\'.format(i, 2 ** i, a_end-a_start, b_end-a_end, (a_end-a_start)/(b_end-a_end)))\n                self.assertAllClose(a, b, rtol=1e-02, atol=1e-02)\n\nif __name__ == ""__main__"":\n    tf.test.main()\n'"
intrinsic_dimension/ops/fwh.py,2,"b'import os\nimport tensorflow as tf\nfrom tensorflow.python.framework import ops\n\nfwh_so = os.path.join(os.path.dirname(__file__), \'fast_walsh_hadamard.so\')\n\ntry:\n    fast_walsh_hadamard_module = tf.load_op_library(fwh_so)\nexcept tf.errors.NotFoundError:\n    print \'\\n\\nError: could not find compiled fast_walsh_hadamard.so file. Tried loading from this location:\\n\\n    %s\\n\\nRun ""make all"" in lab/ops first.\\n\\n\' % fwh_so\n    raise\n\nfast_walsh_hadamard = fast_walsh_hadamard_module.fast_walsh_hadamard\n\n\n@ops.RegisterGradient(""FastWalshHadamard"")\ndef _fast_walsh_hadamard_grad(op, grad):\n    \'\'\'The gradients for `fast_walsh_hadamard`.\n  \n    Args:\n      op: The `fast_walsh_hadamard` `Operation` that we are differentiating, which we can use\n        to find the inputs and outputs of the original op.\n      grad: Gradient with respect to the output of the `fast_walsh_hadamard` op.\n  \n    Returns:\n      Gradients with respect to the input of `fast_walsh_hadamard`.\n    \'\'\'\n\n    gg = fast_walsh_hadamard(grad)\n    return [gg]\n'"
intrinsic_dimension/ops/py_zero_out.py,1,"b'import tensorflow as tf\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.ops import array_ops\nfrom tensorflow.python.ops import sparse_ops\n\nzero_out_module = tf.load_op_library(\'./zero_out.so\')\nzero_out = zero_out_module.zero_out\nzero_out_float = zero_out_module.zero_out_float\n\n@ops.RegisterGradient(""ZeroOut"")\ndef _zero_out_grad(op, grad):\n    """"""The gradients for `zero_out`.\n\n  Args:\n    op: The `zero_out` `Operation` that we are differentiating, which we can use\n      to find the inputs and outputs of the original op.\n    grad: Gradient with respect to the output of the `zero_out` op.\n\n  Returns:\n    Gradients with respect to the input of `zero_out`.\n  """"""\n    to_zero = op.inputs[0]\n    shape = array_ops.shape(to_zero)\n    index = array_ops.zeros_like(shape)\n    first_grad = array_ops.reshape(grad, [-1])[0]\n    to_zero_grad = sparse_ops.sparse_to_dense([index], shape, first_grad, 0)\n    return [to_zero_grad]  # List of one Tensor, since we have one input\n\n@ops.RegisterGradient(""ZeroOutFloat"")\ndef _zero_out_float_grad(op, grad):\n    """"""The gradients for `zero_out_float`.\n\n  Args:\n    op: The `zero_out_float` `Operation` that we are differentiating, which we can use\n      to find the inputs and outputs of the original op.\n    grad: Gradient with respect to the output of the `zero_out_float` op.\n\n  Returns:\n    Gradients with respect to the input of `zero_out_float`.\n  """"""\n    to_zero = op.inputs[0]\n    shape = array_ops.shape(to_zero)\n    index = array_ops.zeros_like(shape)\n    first_grad = array_ops.reshape(grad, [-1])[0]\n    to_zero_grad = sparse_ops.sparse_to_dense([index], shape, first_grad, 0)\n    return [to_zero_grad]  # List of one Tensor, since we have one input\n'"
intrinsic_dimension/ops/zero_out_op_test.py,3,"b'import tensorflow as tf\n\nclass ZeroOutTest(tf.test.TestCase):\n    def testZeroOut(self):\n        zero_out_module = tf.load_op_library(\'./zero_out.so\')\n        with self.test_session():\n            result = zero_out_module.zero_out([5, 4, 3, 2, 1])\n            self.assertAllEqual(result.eval(), [5, 0, 0, 0, 0])\n\n\nif __name__ == ""__main__"":\n    tf.test.main()\n'"
pycocoevalcap/bleu/__init__.py,0,"b""__author__ = 'tylin'\n"""
pycocoevalcap/bleu/bleu.py,0,"b'#!/usr/bin/env python\n# \n# File Name : bleu.py\n#\n# Description : Wrapper for BLEU scorer.\n#\n# Creation Date : 06-01-2015\n# Last Modified : Thu 19 Mar 2015 09:13:28 PM PDT\n# Authors : Hao Fang <hfang@uw.edu> and Tsung-Yi Lin <tl483@cornell.edu>\n\nfrom bleu_scorer import BleuScorer\n\n\nclass Bleu:\n    def __init__(self, n=4):\n        # default compute Blue score up to 4\n        self._n = n\n        self._hypo_for_image = {}\n        self.ref_for_image = {}\n\n    def compute_score(self, gts, res):\n\n        assert(gts.keys() == res.keys())\n        imgIds = gts.keys()\n\n        bleu_scorer = BleuScorer(n=self._n)\n        for id in imgIds:\n            hypo = res[id]\n            ref = gts[id]\n\n            # Sanity check.\n            assert(type(hypo) is list)\n            assert(len(hypo) == 1)\n            assert(type(ref) is list)\n            #print(ref)\n            #assert(len(ref) > 1)\n\n            bleu_scorer += (hypo[0], ref)\n\n        #score, scores = bleu_scorer.compute_score(option=\'shortest\')\n        score, scores = bleu_scorer.compute_score(option=\'closest\', verbose=1)\n        #score, scores = bleu_scorer.compute_score(option=\'average\', verbose=1)\n\n        # return (bleu, bleu_info)\n        return score, scores\n\n    def method(self):\n        return ""Bleu""\n'"
pycocoevalcap/bleu/bleu_scorer.py,0,"b'#!/usr/bin/env python\n\n# bleu_scorer.py\n# David Chiang <chiang@isi.edu>\n\n# Copyright (c) 2004-2006 University of Maryland. All rights\n# reserved. Do not redistribute without permission from the\n# author. Not for commercial use.\n\n# Modified by: \n# Hao Fang <hfang@uw.edu>\n# Tsung-Yi Lin <tl483@cornell.edu>\n\n\'\'\'Provides:\ncook_refs(refs, n=4): Transform a list of reference sentences as strings into a form usable by cook_test().\ncook_test(test, refs, n=4): Transform a test sentence as a string (together with the cooked reference sentences) into a form usable by score_cooked().\n\'\'\'\n\nimport copy\nimport sys, math, re\nfrom collections import defaultdict\n\ndef precook(s, n=4, out=False):\n    """"""Takes a string as input and returns an object that can be given to\n    either cook_refs or cook_test. This is optional: cook_refs and cook_test\n    can take string arguments as well.""""""\n    words = s.split()\n    counts = defaultdict(int)\n    for k in xrange(1,n+1):\n        for i in xrange(len(words)-k+1):\n            ngram = tuple(words[i:i+k])\n            counts[ngram] += 1\n    return (len(words), counts)\n\ndef cook_refs(refs, eff=None, n=4): ## lhuang: oracle will call with ""average""\n    \'\'\'Takes a list of reference sentences for a single segment\n    and returns an object that encapsulates everything that BLEU\n    needs to know about them.\'\'\'\n\n    reflen = []\n    maxcounts = {}\n    for ref in refs:\n        rl, counts = precook(ref, n)\n        reflen.append(rl)\n        for (ngram,count) in counts.iteritems():\n            maxcounts[ngram] = max(maxcounts.get(ngram,0), count)\n\n    # Calculate effective reference sentence length.\n    if eff == ""shortest"":\n        reflen = min(reflen)\n    elif eff == ""average"":\n        reflen = float(sum(reflen))/len(reflen)\n\n    ## lhuang: N.B.: leave reflen computaiton to the very end!!\n    \n    ## lhuang: N.B.: in case of ""closest"", keep a list of reflens!! (bad design)\n\n    return (reflen, maxcounts)\n\ndef cook_test(test, (reflen, refmaxcounts), eff=None, n=4):\n    \'\'\'Takes a test sentence and returns an object that\n    encapsulates everything that BLEU needs to know about it.\'\'\'\n\n    testlen, counts = precook(test, n, True)\n\n    result = {}\n\n    # Calculate effective reference sentence length.\n    \n    if eff == ""closest"":\n        result[""reflen""] = min((abs(l-testlen), l) for l in reflen)[1]\n    else: ## i.e., ""average"" or ""shortest"" or None\n        result[""reflen""] = reflen\n\n    result[""testlen""] = testlen\n\n    result[""guess""] = [max(0,testlen-k+1) for k in xrange(1,n+1)]\n\n    result[\'correct\'] = [0]*n\n    for (ngram, count) in counts.iteritems():\n        result[""correct""][len(ngram)-1] += min(refmaxcounts.get(ngram,0), count)\n\n    return result\n\nclass BleuScorer(object):\n    """"""Bleu scorer.\n    """"""\n\n    __slots__ = ""n"", ""crefs"", ""ctest"", ""_score"", ""_ratio"", ""_testlen"", ""_reflen"", ""special_reflen""\n    # special_reflen is used in oracle (proportional effective ref len for a node).\n\n    def copy(self):\n        \'\'\' copy the refs.\'\'\'\n        new = BleuScorer(n=self.n)\n        new.ctest = copy.copy(self.ctest)\n        new.crefs = copy.copy(self.crefs)\n        new._score = None\n        return new\n\n    def __init__(self, test=None, refs=None, n=4, special_reflen=None):\n        \'\'\' singular instance \'\'\'\n\n        self.n = n\n        self.crefs = []\n        self.ctest = []\n        self.cook_append(test, refs)\n        self.special_reflen = special_reflen\n\n    def cook_append(self, test, refs):\n        \'\'\'called by constructor and __iadd__ to avoid creating new instances.\'\'\'\n        \n        if refs is not None:\n            self.crefs.append(cook_refs(refs))\n            if test is not None:\n                cooked_test = cook_test(test, self.crefs[-1])\n                self.ctest.append(cooked_test) ## N.B.: -1\n            else:\n                self.ctest.append(None) # lens of crefs and ctest have to match\n\n        self._score = None ## need to recompute\n\n    def ratio(self, option=None):\n        self.compute_score(option=option)\n        return self._ratio\n\n    def score_ratio(self, option=None):\n        \'\'\'return (bleu, len_ratio) pair\'\'\'\n        return (self.fscore(option=option), self.ratio(option=option))\n\n    def score_ratio_str(self, option=None):\n        return ""%.4f (%.2f)"" % self.score_ratio(option)\n\n    def reflen(self, option=None):\n        self.compute_score(option=option)\n        return self._reflen\n\n    def testlen(self, option=None):\n        self.compute_score(option=option)\n        return self._testlen        \n\n    def retest(self, new_test):\n        if type(new_test) is str:\n            new_test = [new_test]\n        assert len(new_test) == len(self.crefs), new_test\n        self.ctest = []\n        for t, rs in zip(new_test, self.crefs):\n            self.ctest.append(cook_test(t, rs))\n        self._score = None\n\n        return self\n\n    def rescore(self, new_test):\n        \'\'\' replace test(s) with new test(s), and returns the new score.\'\'\'\n        \n        return self.retest(new_test).compute_score()\n\n    def size(self):\n        assert len(self.crefs) == len(self.ctest), ""refs/test mismatch! %d<>%d"" % (len(self.crefs), len(self.ctest))\n        return len(self.crefs)\n\n    def __iadd__(self, other):\n        \'\'\'add an instance (e.g., from another sentence).\'\'\'\n\n        if type(other) is tuple:\n            ## avoid creating new BleuScorer instances\n            self.cook_append(other[0], other[1])\n        else:\n            assert self.compatible(other), ""incompatible BLEUs.""\n            self.ctest.extend(other.ctest)\n            self.crefs.extend(other.crefs)\n            self._score = None ## need to recompute\n\n        return self        \n\n    def compatible(self, other):\n        return isinstance(other, BleuScorer) and self.n == other.n\n\n    def single_reflen(self, option=""average""):\n        return self._single_reflen(self.crefs[0][0], option)\n\n    def _single_reflen(self, reflens, option=None, testlen=None):\n        \n        if option == ""shortest"":\n            reflen = min(reflens)\n        elif option == ""average"":\n            reflen = float(sum(reflens))/len(reflens)\n        elif option == ""closest"":\n            reflen = min((abs(l-testlen), l) for l in reflens)[1]\n        else:\n            assert False, ""unsupported reflen option %s"" % option\n\n        return reflen\n\n    def recompute_score(self, option=None, verbose=0):\n        self._score = None\n        return self.compute_score(option, verbose)\n        \n    def compute_score(self, option=None, verbose=0):\n        n = self.n\n        small = 1e-9\n        tiny = 1e-15 ## so that if guess is 0 still return 0\n        bleu_list = [[] for _ in range(n)]\n\n        if self._score is not None:\n            return self._score\n\n        if option is None:\n            option = ""average"" if len(self.crefs) == 1 else ""closest""\n\n        self._testlen = 0\n        self._reflen = 0\n        totalcomps = {\'testlen\':0, \'reflen\':0, \'guess\':[0]*n, \'correct\':[0]*n}\n\n        # for each sentence\n        for comps in self.ctest:            \n            testlen = comps[\'testlen\']\n            self._testlen += testlen\n\n            if self.special_reflen is None: ## need computation\n                reflen = self._single_reflen(comps[\'reflen\'], option, testlen)\n            else:\n                reflen = self.special_reflen\n\n            self._reflen += reflen\n                \n            for key in [\'guess\',\'correct\']:\n                for k in xrange(n):\n                    totalcomps[key][k] += comps[key][k]\n\n            # append per image bleu score\n            bleu = 1.\n            for k in xrange(n):\n                bleu *= (float(comps[\'correct\'][k]) + tiny) \\\n                        /(float(comps[\'guess\'][k]) + small) \n                bleu_list[k].append(bleu ** (1./(k+1)))\n            ratio = (testlen + tiny) / (reflen + small) ## N.B.: avoid zero division\n            if ratio < 1:\n                for k in xrange(n):\n                    bleu_list[k][-1] *= math.exp(1 - 1/ratio)\n\n            if verbose > 1:\n                print comps, reflen\n\n        totalcomps[\'reflen\'] = self._reflen\n        totalcomps[\'testlen\'] = self._testlen\n\n        bleus = []\n        bleu = 1.\n        for k in xrange(n):\n            bleu *= float(totalcomps[\'correct\'][k] + tiny) \\\n                    / (totalcomps[\'guess\'][k] + small)\n            bleus.append(bleu ** (1./(k+1)))\n        ratio = (self._testlen + tiny) / (self._reflen + small) ## N.B.: avoid zero division\n        if ratio < 1:\n            for k in xrange(n):\n                bleus[k] *= math.exp(1 - 1/ratio)\n\n        #if verbose > 0:\n        #    print totalcomps\n        #    print ""ratio:"", ratio\n\n        self._score = bleus\n        return self._score, bleu_list\n'"
pycocoevalcap/cider/__init__.py,0,"b""__author__ = 'tylin'\n"""
pycocoevalcap/cider/cider.py,0,"b'# Filename: cider.py\n#\n# Description: Describes the class to compute the CIDEr (Consensus-Based Image Description Evaluation) Metric \n#               by Vedantam, Zitnick, and Parikh (http://arxiv.org/abs/1411.5726)\n#\n# Creation Date: Sun Feb  8 14:16:54 2015\n#\n# Authors: Ramakrishna Vedantam <vrama91@vt.edu> and Tsung-Yi Lin <tl483@cornell.edu>\n\nfrom cider_scorer import CiderScorer\nimport pdb\n\nclass Cider:\n    """"""\n    Main Class to compute the CIDEr metric \n\n    """"""\n    def __init__(self, test=None, refs=None, n=4, sigma=6.0):\n        # set cider to sum over 1 to 4-grams\n        self._n = n\n        # set the standard deviation parameter for gaussian penalty\n        self._sigma = sigma\n\n    def compute_score(self, gts, res):\n        """"""\n        Main function to compute CIDEr score\n        :param  hypo_for_image (dict) : dictionary with key <image> and value <tokenized hypothesis / candidate sentence>\n                ref_for_image (dict)  : dictionary with key <image> and value <tokenized reference sentence>\n        :return: cider (float) : computed CIDEr score for the corpus \n        """"""\n\n        assert(gts.keys() == res.keys())\n        imgIds = gts.keys()\n\n        cider_scorer = CiderScorer(n=self._n, sigma=self._sigma)\n\n        for id in imgIds:\n            hypo = res[id]\n            ref = gts[id]\n\n            # Sanity check.\n            assert(type(hypo) is list)\n            assert(len(hypo) == 1)\n            assert(type(ref) is list)\n            assert(len(ref) > 0)\n\n            cider_scorer += (hypo[0], ref)\n\n        (score, scores) = cider_scorer.compute_score()\n\n        return score, scores\n\n    def method(self):\n        return ""CIDEr""'"
pycocoevalcap/cider/cider_scorer.py,0,"b'#!/usr/bin/env python\n# Tsung-Yi Lin <tl483@cornell.edu>\n# Ramakrishna Vedantam <vrama91@vt.edu>\n\nimport copy\nfrom collections import defaultdict\nimport numpy as np\nimport pdb\nimport math\n\ndef precook(s, n=4, out=False):\n    """"""\n    Takes a string as input and returns an object that can be given to\n    either cook_refs or cook_test. This is optional: cook_refs and cook_test\n    can take string arguments as well.\n    :param s: string : sentence to be converted into ngrams\n    :param n: int    : number of ngrams for which representation is calculated\n    :return: term frequency vector for occuring ngrams\n    """"""\n    words = s.split()\n    counts = defaultdict(int)\n    for k in xrange(1,n+1):\n        for i in xrange(len(words)-k+1):\n            ngram = tuple(words[i:i+k])\n            counts[ngram] += 1\n    return counts\n\ndef cook_refs(refs, n=4): ## lhuang: oracle will call with ""average""\n    \'\'\'Takes a list of reference sentences for a single segment\n    and returns an object that encapsulates everything that BLEU\n    needs to know about them.\n    :param refs: list of string : reference sentences for some image\n    :param n: int : number of ngrams for which (ngram) representation is calculated\n    :return: result (list of dict)\n    \'\'\'\n    return [precook(ref, n) for ref in refs]\n\ndef cook_test(test, n=4):\n    \'\'\'Takes a test sentence and returns an object that\n    encapsulates everything that BLEU needs to know about it.\n    :param test: list of string : hypothesis sentence for some image\n    :param n: int : number of ngrams for which (ngram) representation is calculated\n    :return: result (dict)\n    \'\'\'\n    return precook(test, n, True)\n\nclass CiderScorer(object):\n    """"""CIDEr scorer.\n    """"""\n\n    def copy(self):\n        \'\'\' copy the refs.\'\'\'\n        new = CiderScorer(n=self.n)\n        new.ctest = copy.copy(self.ctest)\n        new.crefs = copy.copy(self.crefs)\n        return new\n\n    def __init__(self, test=None, refs=None, n=4, sigma=6.0):\n        \'\'\' singular instance \'\'\'\n        self.n = n\n        self.sigma = sigma\n        self.crefs = []\n        self.ctest = []\n        self.document_frequency = defaultdict(float)\n        self.cook_append(test, refs)\n        self.ref_len = None\n\n    def cook_append(self, test, refs):\n        \'\'\'called by constructor and __iadd__ to avoid creating new instances.\'\'\'\n\n        if refs is not None:\n            self.crefs.append(cook_refs(refs))\n            if test is not None:\n                self.ctest.append(cook_test(test)) ## N.B.: -1\n            else:\n                self.ctest.append(None) # lens of crefs and ctest have to match\n\n    def size(self):\n        assert len(self.crefs) == len(self.ctest), ""refs/test mismatch! %d<>%d"" % (len(self.crefs), len(self.ctest))\n        return len(self.crefs)\n\n    def __iadd__(self, other):\n        \'\'\'add an instance (e.g., from another sentence).\'\'\'\n\n        if type(other) is tuple:\n            ## avoid creating new CiderScorer instances\n            self.cook_append(other[0], other[1])\n        else:\n            self.ctest.extend(other.ctest)\n            self.crefs.extend(other.crefs)\n\n        return self\n    def compute_doc_freq(self):\n        \'\'\'\n        Compute term frequency for reference data.\n        This will be used to compute idf (inverse document frequency later)\n        The term frequency is stored in the object\n        :return: None\n        \'\'\'\n        for refs in self.crefs:\n            # refs, k ref captions of one image\n            for ngram in set([ngram for ref in refs for (ngram,count) in ref.iteritems()]):\n                self.document_frequency[ngram] += 1\n            # maxcounts[ngram] = max(maxcounts.get(ngram,0), count)\n\n    def compute_cider(self):\n        def counts2vec(cnts):\n            """"""\n            Function maps counts of ngram to vector of tfidf weights.\n            The function returns vec, an array of dictionary that store mapping of n-gram and tf-idf weights.\n            The n-th entry of array denotes length of n-grams.\n            :param cnts:\n            :return: vec (array of dict), norm (array of float), length (int)\n            """"""\n            vec = [defaultdict(float) for _ in range(self.n)]\n            length = 0\n            norm = [0.0 for _ in range(self.n)]\n            for (ngram,term_freq) in cnts.iteritems():\n                # give word count 1 if it doesn\'t appear in reference corpus\n                df = np.log(max(1.0, self.document_frequency[ngram]))\n                # ngram index\n                n = len(ngram)-1\n                # tf (term_freq) * idf (precomputed idf) for n-grams\n                vec[n][ngram] = float(term_freq)*(self.ref_len - df)\n                # compute norm for the vector.  the norm will be used for computing similarity\n                norm[n] += pow(vec[n][ngram], 2)\n\n                if n == 1:\n                    length += term_freq\n            norm = [np.sqrt(n) for n in norm]\n            return vec, norm, length\n\n        def sim(vec_hyp, vec_ref, norm_hyp, norm_ref, length_hyp, length_ref):\n            \'\'\'\n            Compute the cosine similarity of two vectors.\n            :param vec_hyp: array of dictionary for vector corresponding to hypothesis\n            :param vec_ref: array of dictionary for vector corresponding to reference\n            :param norm_hyp: array of float for vector corresponding to hypothesis\n            :param norm_ref: array of float for vector corresponding to reference\n            :param length_hyp: int containing length of hypothesis\n            :param length_ref: int containing length of reference\n            :return: array of score for each n-grams cosine similarity\n            \'\'\'\n            delta = float(length_hyp - length_ref)\n            # measure consine similarity\n            val = np.array([0.0 for _ in range(self.n)])\n            for n in range(self.n):\n                # ngram\n                for (ngram,count) in vec_hyp[n].iteritems():\n                    # vrama91 : added clipping\n                    val[n] += min(vec_hyp[n][ngram], vec_ref[n][ngram]) * vec_ref[n][ngram]\n\n                if (norm_hyp[n] != 0) and (norm_ref[n] != 0):\n                    val[n] /= (norm_hyp[n]*norm_ref[n])\n\n                assert(not math.isnan(val[n]))\n                # vrama91: added a length based gaussian penalty\n                val[n] *= np.e**(-(delta**2)/(2*self.sigma**2))\n            return val\n\n        # compute log reference length\n        self.ref_len = np.log(float(len(self.crefs)))\n\n        scores = []\n        for test, refs in zip(self.ctest, self.crefs):\n            # compute vector for test captions\n            vec, norm, length = counts2vec(test)\n            # compute vector for ref captions\n            score = np.array([0.0 for _ in range(self.n)])\n            for ref in refs:\n                vec_ref, norm_ref, length_ref = counts2vec(ref)\n                score += sim(vec, vec_ref, norm, norm_ref, length, length_ref)\n            # change by vrama91 - mean of ngram scores, instead of sum\n            score_avg = np.mean(score)\n            # divide by number of references\n            score_avg /= len(refs)\n            # multiply score by 10\n            score_avg *= 10.0\n            # append score of an image to the score list\n            scores.append(score_avg)\n        return scores\n\n    def compute_score(self, option=None, verbose=0):\n        # compute idf\n        self.compute_doc_freq()\n        # assert to check document frequency\n        assert(len(self.ctest) >= max(self.document_frequency.values()))\n        # compute cider score\n        score = self.compute_cider()\n        # debug\n        # print score\n        return np.mean(np.array(score)), np.array(score)'"
pycocoevalcap/meteor/__init__.py,0,"b""__author__ = 'tylin'\n"""
pycocoevalcap/meteor/meteor.py,0,"b'#!/usr/bin/env python\n\n# Python wrapper for METEOR implementation, by Xinlei Chen\n# Acknowledge Michael Denkowski for the generous discussion and help \n\nimport os\nimport sys\nimport subprocess\nimport threading\n\n# Assumes meteor-1.5.jar is in the same directory as meteor.py.  Change as needed.\nMETEOR_JAR = \'meteor-1.5.jar\'\n# print METEOR_JAR\n\nclass Meteor:\n\n    def __init__(self):\n        self.meteor_cmd = [\'java\', \'-jar\', \'-Xmx2G\', METEOR_JAR, \\\n                \'-\', \'-\', \'-stdio\', \'-l\', \'en\', \'-norm\']\n        self.meteor_p = subprocess.Popen(self.meteor_cmd, \\\n                cwd=os.path.dirname(os.path.abspath(__file__)), \\\n                stdin=subprocess.PIPE, \\\n                stdout=subprocess.PIPE, \\\n                stderr=subprocess.PIPE)\n        # Used to guarantee thread safety\n        self.lock = threading.Lock()\n\n    def compute_score(self, gts, res):\n        assert(gts.keys() == res.keys())\n        imgIds = gts.keys()\n        scores = []\n\n        eval_line = \'EVAL\'\n        self.lock.acquire()\n        for i in imgIds:\n            assert(len(res[i]) == 1)\n            stat = self._stat(res[i][0], gts[i])\n            eval_line += \' ||| {}\'.format(stat)\n\n        self.meteor_p.stdin.write(\'{}\\n\'.format(eval_line))\n        for i in range(0,len(imgIds)):\n            scores.append(float(self.meteor_p.stdout.readline().strip()))\n        score = float(self.meteor_p.stdout.readline().strip())\n        self.lock.release()\n\n        return score, scores\n\n    def method(self):\n        return ""METEOR""\n\n    def _stat(self, hypothesis_str, reference_list):\n        # SCORE ||| reference 1 words ||| reference n words ||| hypothesis words\n        hypothesis_str = hypothesis_str.replace(\'|||\',\'\').replace(\'  \',\' \')\n        score_line = \' ||| \'.join((\'SCORE\', \' ||| \'.join(reference_list), hypothesis_str))\n        self.meteor_p.stdin.write(\'{}\\n\'.format(score_line))\n        return self.meteor_p.stdout.readline().strip()\n\n    def _score(self, hypothesis_str, reference_list):\n        self.lock.acquire()\n        # SCORE ||| reference 1 words ||| reference n words ||| hypothesis words\n        hypothesis_str = hypothesis_str.replace(\'|||\',\'\').replace(\'  \',\' \')\n        score_line = \' ||| \'.join((\'SCORE\', \' ||| \'.join(reference_list), hypothesis_str))\n        self.meteor_p.stdin.write(\'{}\\n\'.format(score_line))\n        stats = self.meteor_p.stdout.readline().strip()\n        eval_line = \'EVAL ||| {}\'.format(stats)\n        # EVAL ||| stats \n        self.meteor_p.stdin.write(\'{}\\n\'.format(eval_line))\n        score = float(self.meteor_p.stdout.readline().strip())\n        # bug fix: there are two values returned by the jar file, one average, and one all, so do it twice\n        # thanks for Andrej for pointing this out\n        score = float(self.meteor_p.stdout.readline().strip())\n        self.lock.release()\n        return score\n \n    def __exit__(self):\n        self.lock.acquire()\n        self.meteor_p.stdin.close()\n        self.meteor_p.kill()\n        self.meteor_p.wait()\n        self.lock.release()\n'"
pycocoevalcap/rouge/__init__.py,0,"b""__author__ = 'vrama91'\n"""
pycocoevalcap/rouge/rouge.py,0,"b'#!/usr/bin/env python\n# \n# File Name : rouge.py\n#\n# Description : Computes ROUGE-L metric as described by Lin and Hovey (2004)\n#\n# Creation Date : 2015-01-07 06:03\n# Author : Ramakrishna Vedantam <vrama91@vt.edu>\n\nimport numpy as np\nimport pdb\n\ndef my_lcs(string, sub):\n    """"""\n    Calculates longest common subsequence for a pair of tokenized strings\n    :param string : list of str : tokens from a string split using whitespace\n    :param sub : list of str : shorter string, also split using whitespace\n    :returns: length (list of int): length of the longest common subsequence between the two strings\n\n    Note: my_lcs only gives length of the longest common subsequence, not the actual LCS\n    """"""\n    if(len(string)< len(sub)):\n        sub, string = string, sub\n\n    lengths = [[0 for i in range(0,len(sub)+1)] for j in range(0,len(string)+1)]\n\n    for j in range(1,len(sub)+1):\n        for i in range(1,len(string)+1):\n            if(string[i-1] == sub[j-1]):\n                lengths[i][j] = lengths[i-1][j-1] + 1\n            else:\n                lengths[i][j] = max(lengths[i-1][j] , lengths[i][j-1])\n\n    return lengths[len(string)][len(sub)]\n\nclass Rouge():\n    \'\'\'\n    Class for computing ROUGE-L score for a set of candidate sentences for the MS COCO test set\n\n    \'\'\'\n    def __init__(self):\n        # vrama91: updated the value below based on discussion with Hovey\n        self.beta = 1.2\n\n    def calc_score(self, candidate, refs):\n        """"""\n        Compute ROUGE-L score given one candidate and references for an image\n        :param candidate: str : candidate sentence to be evaluated\n        :param refs: list of str : COCO reference sentences for the particular image to be evaluated\n        :returns score: int (ROUGE-L score for the candidate evaluated against references)\n        """"""\n        assert(len(candidate)==1)\t\n        assert(len(refs)>0)         \n        prec = []\n        rec = []\n\n        # split into tokens\n        token_c = candidate[0].split("" "")\n    \t\n        for reference in refs:\n            # split into tokens\n            token_r = reference.split("" "")\n            # compute the longest common subsequence\n            lcs = my_lcs(token_r, token_c)\n            prec.append(lcs/float(len(token_c)))\n            rec.append(lcs/float(len(token_r)))\n\n        prec_max = max(prec)\n        rec_max = max(rec)\n\n        if(prec_max!=0 and rec_max !=0):\n            score = ((1 + self.beta**2)*prec_max*rec_max)/float(rec_max + self.beta**2*prec_max)\n        else:\n            score = 0.0\n        return score\n\n    def compute_score(self, gts, res):\n        """"""\n        Computes Rouge-L score given a set of reference and candidate sentences for the dataset\n        Invoked by evaluate_captions.py \n        :param hypo_for_image: dict : candidate / test sentences with ""image name"" key and ""tokenized sentences"" as values \n        :param ref_for_image: dict : reference MS-COCO sentences with ""image name"" key and ""tokenized sentences"" as values\n        :returns: average_score: float (mean ROUGE-L score computed by averaging scores for all the images)\n        """"""\n        assert(gts.keys() == res.keys())\n        imgIds = gts.keys()\n\n        score = []\n        for id in imgIds:\n            hypo = res[id]\n            ref  = gts[id]\n\n            score.append(self.calc_score(hypo, ref))\n\n            # Sanity check.\n            assert(type(hypo) is list)\n            assert(len(hypo) == 1)\n            assert(type(ref) is list)\n            assert(len(ref) > 0)\n\n        average_score = np.mean(np.array(score))\n        return average_score, np.array(score)\n\n    def method(self):\n        return ""Rouge""\n'"
pycocoevalcap/tokenizer/__init__.py,0,"b""__author__ = 'hfang'\n"""
pycocoevalcap/tokenizer/ptbtokenizer.py,0,"b'#!/usr/bin/env python\n# \n# File Name : ptbtokenizer.py\n#\n# Description : Do the PTB Tokenization and remove punctuations.\n#\n# Creation Date : 29-12-2014\n# Last Modified : Thu Mar 19 09:53:35 2015\n# Authors : Hao Fang <hfang@uw.edu> and Tsung-Yi Lin <tl483@cornell.edu>\n\nimport os\nimport sys\nimport subprocess\nimport tempfile\nimport itertools\n\n# path to the stanford corenlp jar\nSTANFORD_CORENLP_3_4_1_JAR = \'stanford-corenlp-3.4.1.jar\'\n\n# punctuations to be removed from the sentences\nPUNCTUATIONS = [""\'\'"", ""\'"", ""``"", ""`"", ""-LRB-"", ""-RRB-"", ""-LCB-"", ""-RCB-"", \\\n        ""."", ""?"", ""!"", "","", "":"", ""-"", ""--"", ""..."", "";""] \n\nclass PTBTokenizer:\n    """"""Python wrapper of Stanford PTBTokenizer""""""\n\n    def tokenize(self, captions_for_image):\n        cmd = [\'java\', \'-cp\', STANFORD_CORENLP_3_4_1_JAR, \\\n                \'edu.stanford.nlp.process.PTBTokenizer\', \\\n                \'-preserveLines\', \'-lowerCase\']\n\n        # ======================================================\n        # prepare data for PTB Tokenizer\n        # ======================================================\n        final_tokenized_captions_for_image = {}\n        image_id = [k for k, v in captions_for_image.items() for _ in range(len(v))]\n        sentences = \'\\n\'.join([c[\'caption\'].replace(\'\\n\', \' \') for k, v in captions_for_image.items() for c in v])\n\n        # ======================================================\n        # save sentences to temporary file\n        # ======================================================\n        path_to_jar_dirname=os.path.dirname(os.path.abspath(__file__))\n        tmp_file = tempfile.NamedTemporaryFile(delete=False, dir=path_to_jar_dirname)\n        tmp_file.write(sentences)\n        tmp_file.close()\n\n        # ======================================================\n        # tokenize sentence\n        # ======================================================\n        cmd.append(os.path.basename(tmp_file.name))\n        p_tokenizer = subprocess.Popen(cmd, cwd=path_to_jar_dirname, \\\n                stdout=subprocess.PIPE)\n        token_lines = p_tokenizer.communicate(input=sentences.rstrip())[0]\n        lines = token_lines.split(\'\\n\')\n        # remove temp file\n        os.remove(tmp_file.name)\n\n        # ======================================================\n        # create dictionary for tokenized captions\n        # ======================================================\n        for k, line in zip(image_id, lines):\n            if not k in final_tokenized_captions_for_image:\n                final_tokenized_captions_for_image[k] = []\n            tokenized_caption = \' \'.join([w for w in line.rstrip().split(\' \') \\\n                    if w not in PUNCTUATIONS])\n            final_tokenized_captions_for_image[k].append(tokenized_caption)\n\n        return final_tokenized_captions_for_image\n'"
